<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>159 acl-2012-Pattern Learning for Relation Extraction with a Hierarchical Topic Model</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-159" href="#">acl2012-159</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>159 acl-2012-Pattern Learning for Relation Extraction with a Hierarchical Topic Model</h1>
<br/><p>Source: <a title="acl-2012-159-pdf" href="http://aclweb.org/anthology//P/P12/P12-2011.pdf">pdf</a></p><p>Author: Enrique Alfonseca ; Katja Filippova ; Jean-Yves Delort ; Guillermo Garrido</p><p>Abstract: We describe the use of a hierarchical topic model for automatically identifying syntactic and lexical patterns that explicitly state ontological relations. We leverage distant supervision using relations from the knowledge base FreeBase, but do not require any manual heuristic nor manual seed list selections. Results show that the learned patterns can be used to extract new relations with good precision.</p><p>Reference: <a title="acl-2012-159-reference" href="../acl2012_reference/acl-2012-Pattern_Learning_for_Relation_Extraction_with_a_Hierarchical_Topic_Model_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Abstract We describe the use of a hierarchical topic model for automatically identifying syntactic and lexical patterns that explicitly state ontological relations. [sent-5, score-0.311]
</p><p>2 We leverage distant supervision using relations from the knowledge base FreeBase, but do not require any manual heuristic nor manual seed list selections. [sent-6, score-0.726]
</p><p>3 Results show that the learned patterns can be used to extract new relations with good precision. [sent-7, score-0.381]
</p><p>4 1 Introduction The detection of relations between entities for the automatic population of knowledge bases is very useful for solving tasks such as Entity Disambiguation, Information Retrieval and Question Answering. [sent-8, score-0.56]
</p><p>5 The availability of high-coverage, generalpurpose knowledge bases enable the automatic iden-  tification and disambiguation of entities in text and its applications (Bunescu and Pasca, 2006; Cucerzan, 2007; McNamee and Dang, 2009; Kwok et al. [sent-9, score-0.371]
</p><p>6 , 2010) started as an effort to approach relation extraction in ∗Work done during  an  internship  at  Google Zurich. [sent-20, score-0.379]
</p><p>7 54 a completely unsupervised way, by learning regularities and patterns from the web. [sent-21, score-0.265]
</p><p>8 These systems do not need any manual data or rules, but the relational facts they extract are not immediately disambiguated to entities and relations from a knowledge base. [sent-25, score-0.691]
</p><p>9 A different family of unsupervised methods for relation extraction is unsupervised semantic parsing, which aims at clustering entity mentions and relation surface forms, thus generating a semantic representation of the texts on which inference may be used. [sent-26, score-0.918]
</p><p>10 Some techniques that have been used are Markov Random Fields (Poon and Domingos, 2009) and Bayesian generative models (Titov and Klementiev, 2011). [sent-27, score-0.048]
</p><p>11 A usual problem is that two related entities may co-occur in one sentence for many unrelated reasons. [sent-36, score-0.232]
</p><p>12 For example, Barack Obama is the president of the United States, but not every sentence including the two entities supports and states this relation. [sent-37, score-0.342]
</p><p>13 extracting sentences only from encyclopedic entries (Mintz et al. [sent-40, score-0.058]
</p><p>14 , 2011), or syntactic restrictions on the sentences and the entity mentions (Wu and Weld, 2010). [sent-45, score-0.153]
</p><p>15 The main contribution of this work is presenting a variant of distance supervision for relation extraction where we do not use heuristics in the selection of the training data. [sent-48, score-0.545]
</p><p>16 Instead, we use topic models to discriminate between the patterns that are expressing the relation and those that are ambiguous and can be applied across relations. [sent-49, score-0.6]
</p><p>17 In this way, high-precision extraction patterns can be learned without the need of any manual intervention. [sent-50, score-0.379]
</p><p>18 2  Unsupervised relational pattern learning  Similar to other distant supervision methods, our approach takes as input an existing knowledge base  containing entities and relations, and a textual corpus. [sent-51, score-0.897]
</p><p>19 In this work it is not necessary for the corpus to be related to the knowledge base. [sent-52, score-0.059]
</p><p>20 In what follows we assume that all the relations studied are binary and hold between exactly two entities in the knowledge base. [sent-53, score-0.474]
</p><p>21 We also assume a dependency parser is available, and that the entities have been automatically disambiguated using the knowledge base as sense inventory. [sent-54, score-0.512]
</p><p>22 One of the most important problems to solve in distant supervision approaches is to be able to distinguish which of the textual examples that include two related entities, ei and ej, are supporting the relation. [sent-55, score-0.438]
</p><p>23 This section describes a fully unsupervised solution to this problem, computing the probability that a pattern supports a given relation, which will allow us to determine the most likely relation expressed in any sentence. [sent-56, score-0.503]
</p><p>24 Specifically, if a sentence contains two entities, ei and ej, connected through a pattern w, our model computes the probability that the pattern is expressing any relation –P(r|w)– for any praeltatetirnon i r dxepfrineessdi ning tahney knowledge b(ars|ew. [sent-57, score-0.68]
</p><p>25 –N footer that we refer to patterns with the symbol w, as they are the words in our topic models. [sent-58, score-0.311]
</p><p>26 Preprocessing As a first step, the textual corpus is processed and the data is transformed in the following way: (a) the input corpus is parsed and en55  Figure 1: Example of a generated set of document collections from a news corpus for relation extraction. [sent-59, score-0.535]
</p><p>27 Larger boxes are document collections (relations), and inner boxes are documents (entity pairs). [sent-60, score-0.346]
</p><p>28 Document contain dependency patterns, which are words in the topic model. [sent-61, score-0.164]
</p><p>29 This context may be a complex structure, such as the dependency path joining the two entities, but it is considered for our purposes as a single term; (e) for each relation r  relating ei with ej, document Dij is added to collection Cr. [sent-63, score-0.593]
</p><p>30 Note that if the two entities are related in different ways at the same time, an identical copy of the document Dij will be added to the collection for all those relations. [sent-64, score-0.388]
</p><p>31 Figure 1 shows a set of document collections gen-  Figure 2: Plate diagram of the generative model used. [sent-65, score-0.288]
</p><p>32 Each relation r has associated a different document collection, which contains one document associated to each entity pair from the knowledge base which is in relation r. [sent-67, score-0.965]
</p><p>33 The words in each document can be, for example, all the dependency paths that have been observed in the input textual corpus between the two related entities. [sent-68, score-0.207]
</p><p>34 Each document will contain some very generic paths (e. [sent-69, score-0.113]
</p><p>35 the two entities consecutive in the text) and some more specific paths. [sent-71, score-0.232]
</p><p>36 Generative model Once these collections are built, we use the generative model from Figure 2 to learn the probability that a dependency path is conveying some relation between the entities it connects. [sent-72, score-0.75]
</p><p>37 w (the observed variable) represents a pattern between two entities. [sent-74, score-0.119]
</p><p>38 The topic model φG captures general patterns that appear for all relations. [sent-75, score-0.311]
</p><p>39 φD captures patterns that are specific about a certain entity pair, but which are not generalizable across all pairs with the same relation. [sent-76, score-0.299]
</p><p>40 Finally φA contains the patterns that are observed  across most pairs related with the same relation. [sent-77, score-0.198]
</p><p>41 The topic assignments (for each pattern) that are the output of this process are used to estimate P(r|w) : when we observe pataterern u w, dth teo probability (thr|awt )it: conveys reel oabtiseornv r. [sent-80, score-0.158]
</p><p>42 56 3  Experiments and results  Settings We use Freebase as our knowledge base. [sent-81, score-0.059]
</p><p>43 text corpus used contains 33 million English news articles that we downloaded between January 2004 and December 2011. [sent-83, score-0.037]
</p><p>44 A random sample of 3M of them is used for building the document collections on which to train the topic models, and the remaining 30M is used for testing. [sent-84, score-0.353]
</p><p>45 The corpus is preprocessed by identifying Freebase entity mentions, using an approach similar to (Milne and Witten, 2008), and parsing it with an inductive dependency parser (Nivre, 2006). [sent-85, score-0.21]
</p><p>46 From the three million training documents, a set of document collections (one per relation) has been  generated, by considering the sentences that contain two entities which are related in FreeBase through any binary relation and restricting to high-frequency 200 relations. [sent-86, score-0.761]
</p><p>47 Two ways of extracting patterns have been used: (a) Syntactic, taking the dependency path between the two entities, and (b) Intertext, taking the text between the two. [sent-87, score-0.289]
</p><p>48 In both cases, a topic model has been trained to learn the probability of a relation given a pattern w: p(r|w). [sent-88, score-0.484]
</p><p>49 For λ we use symmetric Deniri ach plaettt priors λG = 0. [sent-89, score-0.036]
</p><p>50 001, following the intuition that for the background the probability mass across patterns should be more evenly distributed. [sent-92, score-0.198]
</p><p>51 γ is set as (15, 15, 1), indicating in the prior that we expect more patterns to belong to the background and entity-pairspecific distributions due to the very noisy nature of the input data. [sent-93, score-0.198]
</p><p>52 As a baseline, using the same training corpus, we have calculated p(r|w) using the maximum likelihhoavode ecastlicmulaatete:d dth pe( rn|uwm)b uersi nofg t ithmees m thaxaitm a pattern w has been seen connecting two entities for which r holds divided by the total frequency of the pattern. [sent-95, score-0.435]
</p><p>53 Extractions  evaluation  The patterns have been  applied to the 30 million documents left for testing. [sent-96, score-0.235]
</p><p>54 For each pair of entities disambiguated as FreeBase entities, if they are connected through a known pattern, they are assigned arg maxr p(r|w). [sent-97, score-0.327]
</p><p>55 An extraction is to be judged correct if both it is correct in real life and the sentence from which it was extracted really supports it. [sent-100, score-0.192]
</p><p>56 4% of the items on whether the sentence supports the relation, and for 20% of the items on whether the relation holds in the real world. [sent-105, score-0.317]
</p><p>57 fAfesr can hb ere seen, tsh oef M p(Lr|Ew b)a aserelines (in red with syntactic patterns and green with intertext) perform consistently worse than the models learned using the topic models (in pink and blue). [sent-107, score-0.311]
</p><p>58 The difference in precision, aggregated across all relations, is statistically significant at 95% confidence for most of the thresholds. [sent-108, score-0.053]
</p><p>59 Extractions aggregation We can take advantage of redundancy on the web to calculate a support metric for the extractions. [sent-109, score-0.056]
</p><p>60 In this experiment, for every extracted relation (r, e1, e2), for every occurrence of a pattern wi connecting e1 and e2, we add up p(r|wi). [sent-110, score-0.41]
</p><p>61 Extractions that are obtained many times apn(rd| fwrom high-precision patterns will rank higher. [sent-111, score-0.198]
</p><p>62 We have considered the top four highest-frequency relations for people. [sent-113, score-0.183]
</p><p>63 For each of these, both syntactic patterns and intermediate-text patterns have been evaluated. [sent-115, score-0.396]
</p><p>64 The results are very interesting: using syntax, Death place appears easy to extract new relations  and to find support. [sent-116, score-0.243]
</p><p>65 subj  prep vv  **  ARG1  died  pobj ww  at  prep uu home  pobj ww in  ARG2 57  RelationUnknown relationsKnown relations  Correct relation P@50 Syntax Intertext  Sentence Syntax  P@50 Intertext  support  Parent0. [sent-119, score-0.827]
</p><p>66 On the other hand, birth place and nationality have very different results for new relation acquisition vs. [sent-136, score-0.592]
</p><p>67 The reason is that these relations are very correlated to other relations that we did not have in our training set. [sent-138, score-0.366]
</p><p>68 In the case of birth place, many relations refer to having an official position in the city, such as mayor; and for nationality, many of the patterns extract presidents or ministers. [sent-139, score-0.563]
</p><p>69 Not having mayor or president in our initial collection (see Figure 1), the  support for these patterns is incorrectly learned. [sent-140, score-0.425]
</p><p>70 In the case of nationality, however, even though the extracted sentences do not support the relation (P@50 = 0. [sent-141, score-0.308]
</p><p>71 34 for intertext), the new relations extracted are mostly correct (P@50 = 0. [sent-142, score-0.183]
</p><p>72 86) as most presidents and ministers in the real world have the nationality of the country where they govern. [sent-143, score-0.305]
</p><p>73 4  Conclusions  We have described a new distant supervision model with which to learn patterns for relation extraction with no manual intervention. [sent-144, score-0.932]
</p><p>74 Results are promising, we could obtain new relations that are not in FreeBase with a high precision for some relation types. [sent-145, score-0.435]
</p><p>75 It is also useful to extract support sentences for known relations. [sent-146, score-0.056]
</p><p>76 More work is needed in understanding which relations are compatible or overlapping and which ones can partially imply each other (such as president-country or born in-mayor). [sent-147, score-0.183]
</p><p>77 Relational duality: Unsupervised extraction of semantic relations between entities on the web. [sent-166, score-0.542]
</p><p>78 In Proceedings of the 19th international conference on World wide web, pages 15 1–160. [sent-167, score-0.052]
</p><p>79 The automatic content extraction (ace) program–tasks, data, and evaluation. [sent-188, score-0.127]
</p><p>80 In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,  pages 362–370. [sent-203, score-0.052]
</p><p>81 In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 286–295. [sent-212, score-0.052]
</p><p>82 Knowledge-based weak supervision for information extraction of overlapping relations. [sent-222, score-0.293]
</p><p>83 In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pages 541–550. [sent-223, score-0.052]
</p><p>84 Learning arguments and supertypes of semantic relations using recursive patterns. [sent-237, score-0.183]
</p><p>85 In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, 58 pages 1482–1491. [sent-238, score-0.052]
</p><p>86 A combination of topic models with max-margin learning for relation detection. [sent-253, score-0.365]
</p><p>87 Overview of the tac 2009 knowledge base population track. [sent-259, score-0.23]
</p><p>88 In Proceeding of the 1 ACM conference 7th on Information and knowledge management, pages 509–518. [sent-267, score-0.111]
</p><p>89 In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2, pages 1003– 1011. [sent-276, score-0.052]
</p><p>90 Organizing and searching the world wide web of facts-step one: the one-million fact extraction challenge. [sent-291, score-0.168]
</p><p>91 In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1-Volume 1, pages 1–10. [sent-309, score-0.052]
</p><p>92 Learning surface text patterns for a question answering system. [sent-315, score-0.243]
</p><p>93 In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pages 41–47. [sent-316, score-0.052]
</p><p>94 In Proceedings of the COLING/ACL on Main conference poster sessions, pages 73 1–738. [sent-322, score-0.052]
</p><p>95 In Proceedings of the 23rd national conference on Artificial intelligence, pages 1609–1614. [sent-348, score-0.052]
</p><p>96 In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 118–127. [sent-356, score-0.052]
</p><p>97 In Proceedings of Human Language Technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations, pages 25–26. [sent-375, score-0.052]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('relation', 0.252), ('freebase', 0.25), ('entities', 0.232), ('intertext', 0.208), ('patterns', 0.198), ('relations', 0.183), ('nationality', 0.181), ('supervision', 0.166), ('hoffmann', 0.16), ('dij', 0.145), ('distant', 0.135), ('collections', 0.127), ('extraction', 0.127), ('pattern', 0.119), ('document', 0.113), ('topic', 0.113), ('ej', 0.112), ('extractions', 0.106), ('entity', 0.101), ('birth', 0.099), ('weld', 0.095), ('disambiguated', 0.095), ('ei', 0.094), ('pasca', 0.088), ('mayor', 0.083), ('milne', 0.083), ('presidents', 0.083), ('banko', 0.08), ('base', 0.075), ('ace', 0.074), ('uned', 0.073), ('yao', 0.071), ('relational', 0.068), ('unsupervised', 0.067), ('mcnamee', 0.066), ('kasneci', 0.066), ('textrunner', 0.066), ('kozareva', 0.066), ('pobj', 0.066), ('kwok', 0.066), ('supports', 0.065), ('association', 0.064), ('doddington', 0.062), ('sundheim', 0.062), ('mintz', 0.062), ('place', 0.06), ('knowledge', 0.059), ('inductive', 0.058), ('fader', 0.058), ('encyclopedic', 0.058), ('bollegala', 0.058), ('haghighi', 0.057), ('support', 0.056), ('prep', 0.056), ('yates', 0.056), ('death', 0.056), ('manual', 0.054), ('broadhead', 0.053), ('boxes', 0.053), ('poon', 0.053), ('aggregated', 0.053), ('mentions', 0.052), ('pages', 0.052), ('cafarella', 0.051), ('tac', 0.051), ('dependency', 0.051), ('wu', 0.05), ('titov', 0.049), ('volume', 0.048), ('generative', 0.048), ('bunescu', 0.048), ('ravichandran', 0.048), ('ww', 0.046), ('president', 0.045), ('dth', 0.045), ('population', 0.045), ('answering', 0.045), ('soderland', 0.044), ('collection', 0.043), ('textual', 0.043), ('etzioni', 0.042), ('annual', 0.042), ('bases', 0.041), ('world', 0.041), ('path', 0.04), ('syntax', 0.04), ('pereira', 0.039), ('connecting', 0.039), ('open', 0.039), ('disambiguation', 0.039), ('meeting', 0.037), ('million', 0.037), ('expressing', 0.037), ('strassel', 0.036), ('ach', 0.036), ('ars', 0.036), ('amershi', 0.036), ('fogarty', 0.036), ('patel', 0.036), ('bigham', 0.036)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="159-tfidf-1" href="./acl-2012-Pattern_Learning_for_Relation_Extraction_with_a_Hierarchical_Topic_Model.html">159 acl-2012-Pattern Learning for Relation Extraction with a Hierarchical Topic Model</a></p>
<p>Author: Enrique Alfonseca ; Katja Filippova ; Jean-Yves Delort ; Guillermo Garrido</p><p>Abstract: We describe the use of a hierarchical topic model for automatically identifying syntactic and lexical patterns that explicitly state ontological relations. We leverage distant supervision using relations from the knowledge base FreeBase, but do not require any manual heuristic nor manual seed list selections. Results show that the learned patterns can be used to extract new relations with good precision.</p><p>2 0.33757812 <a title="159-tfidf-2" href="./acl-2012-Big_Data_versus_the_Crowd%3A_Looking_for_Relationships_in_All_the_Right_Places.html">40 acl-2012-Big Data versus the Crowd: Looking for Relationships in All the Right Places</a></p>
<p>Author: Ce Zhang ; Feng Niu ; Christopher Re ; Jude Shavlik</p><p>Abstract: Classically, training relation extractors relies on high-quality, manually annotated training data, which can be expensive to obtain. To mitigate this cost, NLU researchers have considered two newly available sources of less expensive (but potentially lower quality) labeled data from distant supervision and crowd sourcing. There is, however, no study comparing the relative impact of these two sources on the precision and recall of post-learning answers. To fill this gap, we empirically study how state-of-the-art techniques are affected by scaling these two sources. We use corpus sizes of up to 100 million documents and tens of thousands of crowd-source labeled examples. Our experiments show that increasing the corpus size for distant supervision has a statistically significant, positive impact on quality (F1 score). In contrast, human feedback has a positive and statistically significant, but lower, impact on precision and recall.</p><p>3 0.2901493 <a title="159-tfidf-3" href="./acl-2012-Unsupervised_Relation_Discovery_with_Sense_Disambiguation.html">208 acl-2012-Unsupervised Relation Discovery with Sense Disambiguation</a></p>
<p>Author: Limin Yao ; Sebastian Riedel ; Andrew McCallum</p><p>Abstract: To discover relation types from text, most methods cluster shallow or syntactic patterns of relation mentions, but consider only one possible sense per pattern. In practice this assumption is often violated. In this paper we overcome this issue by inducing clusters of pattern senses from feature representations of patterns. In particular, we employ a topic model to partition entity pairs associated with patterns into sense clusters using local and global features. We merge these sense clusters into semantic relations using hierarchical agglomerative clustering. We compare against several baselines: a generative latent-variable model, a clustering method that does not disambiguate between path senses, and our own approach but with only local features. Experimental results show our proposed approach discovers dramatically more accurate clusters than models without sense disambiguation, and that incorporating global features, such as the document theme, is crucial.</p><p>4 0.27539513 <a title="159-tfidf-4" href="./acl-2012-Reducing_Wrong_Labels_in_Distant_Supervision_for_Relation_Extraction.html">169 acl-2012-Reducing Wrong Labels in Distant Supervision for Relation Extraction</a></p>
<p>Author: Shingo Takamatsu ; Issei Sato ; Hiroshi Nakagawa</p><p>Abstract: In relation extraction, distant supervision seeks to extract relations between entities from text by using a knowledge base, such as Freebase, as a source of supervision. When a sentence and a knowledge base refer to the same entity pair, this approach heuristically labels the sentence with the corresponding relation in the knowledge base. However, this heuristic can fail with the result that some sentences are labeled wrongly. This noisy labeled data causes poor extraction performance. In this paper, we propose a method to reduce the number of wrong labels. We present a novel generative model that directly models the heuristic labeling process of distant supervision. The model predicts whether assigned labels are correct or wrong via its hidden variables. Our experimental results show that this model detected wrong labels with higher performance than baseline methods. In the ex- periment, we also found that our wrong label reduction boosted the performance of relation extraction.</p><p>5 0.20879154 <a title="159-tfidf-5" href="./acl-2012-Temporally_Anchored_Relation_Extraction.html">191 acl-2012-Temporally Anchored Relation Extraction</a></p>
<p>Author: Guillermo Garrido ; Anselmo Penas ; Bernardo Cabaleiro ; Alvaro Rodrigo</p><p>Abstract: Although much work on relation extraction has aimed at obtaining static facts, many of the target relations are actually fluents, as their validity is naturally anchored to a certain time period. This paper proposes a methodological approach to temporally anchored relation extraction. Our proposal performs distant supervised learning to extract a set of relations from a natural language corpus, and anchors each of them to an interval of temporal validity, aggregating evidence from documents supporting the relation. We use a rich graphbased document-level representation to generate novel features for this task. Results show that our implementation for temporal anchoring is able to achieve a 69% of the upper bound performance imposed by the relation extraction step. Compared to the state of the art, the overall system achieves the highest precision reported.</p><p>6 0.17135753 <a title="159-tfidf-6" href="./acl-2012-A_Graph-based_Cross-lingual_Projection_Approach_for_Weakly_Supervised_Relation_Extraction.html">12 acl-2012-A Graph-based Cross-lingual Projection Approach for Weakly Supervised Relation Extraction</a></p>
<p>7 0.1465584 <a title="159-tfidf-7" href="./acl-2012-Discriminative_Learning_for_Joint_Template_Filling.html">73 acl-2012-Discriminative Learning for Joint Template Filling</a></p>
<p>8 0.1360528 <a title="159-tfidf-8" href="./acl-2012-Towards_the_Unsupervised_Acquisition_of_Discourse_Relations.html">201 acl-2012-Towards the Unsupervised Acquisition of Discourse Relations</a></p>
<p>9 0.13190705 <a title="159-tfidf-9" href="./acl-2012-Mining_Entity_Types_from_Query_Logs_via_User_Intent_Modeling.html">142 acl-2012-Mining Entity Types from Query Logs via User Intent Modeling</a></p>
<p>10 0.12288015 <a title="159-tfidf-10" href="./acl-2012-Coupling_Label_Propagation_and_Constraints_for_Temporal_Fact_Extraction.html">60 acl-2012-Coupling Label Propagation and Constraints for Temporal Fact Extraction</a></p>
<p>11 0.11150713 <a title="159-tfidf-11" href="./acl-2012-A_Topic_Similarity_Model_for_Hierarchical_Phrase-based_Translation.html">22 acl-2012-A Topic Similarity Model for Hierarchical Phrase-based Translation</a></p>
<p>12 0.10736392 <a title="159-tfidf-12" href="./acl-2012-A_Probabilistic_Model_for_Canonicalizing_Named_Entity_Mentions.html">18 acl-2012-A Probabilistic Model for Canonicalizing Named Entity Mentions</a></p>
<p>13 0.10257109 <a title="159-tfidf-13" href="./acl-2012-Named_Entity_Disambiguation_in_Streaming_Data.html">153 acl-2012-Named Entity Disambiguation in Streaming Data</a></p>
<p>14 0.10177377 <a title="159-tfidf-14" href="./acl-2012-Labeling_Documents_with_Timestamps%3A_Learning_from_their_Time_Expressions.html">126 acl-2012-Labeling Documents with Timestamps: Learning from their Time Expressions</a></p>
<p>15 0.099857926 <a title="159-tfidf-15" href="./acl-2012-A_Discriminative_Hierarchical_Model_for_Fast_Coreference_at_Large_Scale.html">10 acl-2012-A Discriminative Hierarchical Model for Fast Coreference at Large Scale</a></p>
<p>16 0.097153813 <a title="159-tfidf-16" href="./acl-2012-Cross-Domain_Co-Extraction_of_Sentiment_and_Topic_Lexicons.html">61 acl-2012-Cross-Domain Co-Extraction of Sentiment and Topic Lexicons</a></p>
<p>17 0.095798977 <a title="159-tfidf-17" href="./acl-2012-Multilingual_Named_Entity_Recognition_using_Parallel_Data_and_Metadata_from_Wikipedia.html">150 acl-2012-Multilingual Named Entity Recognition using Parallel Data and Metadata from Wikipedia</a></p>
<p>18 0.093656875 <a title="159-tfidf-18" href="./acl-2012-Sentence_Dependency_Tagging_in_Online_Question_Answering_Forums.html">177 acl-2012-Sentence Dependency Tagging in Online Question Answering Forums</a></p>
<p>19 0.085468024 <a title="159-tfidf-19" href="./acl-2012-A_Comparison_of_Chinese_Parsers_for_Stanford_Dependencies.html">5 acl-2012-A Comparison of Chinese Parsers for Stanford Dependencies</a></p>
<p>20 0.084368289 <a title="159-tfidf-20" href="./acl-2012-Topic_Models_for_Dynamic_Translation_Model_Adaptation.html">199 acl-2012-Topic Models for Dynamic Translation Model Adaptation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.271), (1, 0.217), (2, -0.036), (3, 0.215), (4, -0.007), (5, 0.043), (6, -0.196), (7, 0.016), (8, 0.038), (9, -0.079), (10, 0.299), (11, -0.048), (12, -0.143), (13, -0.138), (14, 0.106), (15, 0.108), (16, -0.215), (17, -0.162), (18, 0.08), (19, 0.01), (20, 0.09), (21, -0.049), (22, -0.014), (23, -0.017), (24, -0.011), (25, -0.037), (26, 0.016), (27, 0.031), (28, 0.09), (29, -0.051), (30, 0.107), (31, -0.045), (32, -0.053), (33, -0.031), (34, 0.018), (35, -0.037), (36, 0.022), (37, -0.04), (38, 0.014), (39, 0.007), (40, 0.003), (41, -0.025), (42, -0.015), (43, 0.02), (44, -0.049), (45, 0.014), (46, 0.022), (47, -0.012), (48, 0.003), (49, 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96119636 <a title="159-lsi-1" href="./acl-2012-Pattern_Learning_for_Relation_Extraction_with_a_Hierarchical_Topic_Model.html">159 acl-2012-Pattern Learning for Relation Extraction with a Hierarchical Topic Model</a></p>
<p>Author: Enrique Alfonseca ; Katja Filippova ; Jean-Yves Delort ; Guillermo Garrido</p><p>Abstract: We describe the use of a hierarchical topic model for automatically identifying syntactic and lexical patterns that explicitly state ontological relations. We leverage distant supervision using relations from the knowledge base FreeBase, but do not require any manual heuristic nor manual seed list selections. Results show that the learned patterns can be used to extract new relations with good precision.</p><p>2 0.90760285 <a title="159-lsi-2" href="./acl-2012-Reducing_Wrong_Labels_in_Distant_Supervision_for_Relation_Extraction.html">169 acl-2012-Reducing Wrong Labels in Distant Supervision for Relation Extraction</a></p>
<p>Author: Shingo Takamatsu ; Issei Sato ; Hiroshi Nakagawa</p><p>Abstract: In relation extraction, distant supervision seeks to extract relations between entities from text by using a knowledge base, such as Freebase, as a source of supervision. When a sentence and a knowledge base refer to the same entity pair, this approach heuristically labels the sentence with the corresponding relation in the knowledge base. However, this heuristic can fail with the result that some sentences are labeled wrongly. This noisy labeled data causes poor extraction performance. In this paper, we propose a method to reduce the number of wrong labels. We present a novel generative model that directly models the heuristic labeling process of distant supervision. The model predicts whether assigned labels are correct or wrong via its hidden variables. Our experimental results show that this model detected wrong labels with higher performance than baseline methods. In the ex- periment, we also found that our wrong label reduction boosted the performance of relation extraction.</p><p>3 0.8932789 <a title="159-lsi-3" href="./acl-2012-Big_Data_versus_the_Crowd%3A_Looking_for_Relationships_in_All_the_Right_Places.html">40 acl-2012-Big Data versus the Crowd: Looking for Relationships in All the Right Places</a></p>
<p>Author: Ce Zhang ; Feng Niu ; Christopher Re ; Jude Shavlik</p><p>Abstract: Classically, training relation extractors relies on high-quality, manually annotated training data, which can be expensive to obtain. To mitigate this cost, NLU researchers have considered two newly available sources of less expensive (but potentially lower quality) labeled data from distant supervision and crowd sourcing. There is, however, no study comparing the relative impact of these two sources on the precision and recall of post-learning answers. To fill this gap, we empirically study how state-of-the-art techniques are affected by scaling these two sources. We use corpus sizes of up to 100 million documents and tens of thousands of crowd-source labeled examples. Our experiments show that increasing the corpus size for distant supervision has a statistically significant, positive impact on quality (F1 score). In contrast, human feedback has a positive and statistically significant, but lower, impact on precision and recall.</p><p>4 0.72277927 <a title="159-lsi-4" href="./acl-2012-Unsupervised_Relation_Discovery_with_Sense_Disambiguation.html">208 acl-2012-Unsupervised Relation Discovery with Sense Disambiguation</a></p>
<p>Author: Limin Yao ; Sebastian Riedel ; Andrew McCallum</p><p>Abstract: To discover relation types from text, most methods cluster shallow or syntactic patterns of relation mentions, but consider only one possible sense per pattern. In practice this assumption is often violated. In this paper we overcome this issue by inducing clusters of pattern senses from feature representations of patterns. In particular, we employ a topic model to partition entity pairs associated with patterns into sense clusters using local and global features. We merge these sense clusters into semantic relations using hierarchical agglomerative clustering. We compare against several baselines: a generative latent-variable model, a clustering method that does not disambiguate between path senses, and our own approach but with only local features. Experimental results show our proposed approach discovers dramatically more accurate clusters than models without sense disambiguation, and that incorporating global features, such as the document theme, is crucial.</p><p>5 0.59056896 <a title="159-lsi-5" href="./acl-2012-Discriminative_Learning_for_Joint_Template_Filling.html">73 acl-2012-Discriminative Learning for Joint Template Filling</a></p>
<p>Author: Einat Minkov ; Luke Zettlemoyer</p><p>Abstract: This paper presents a joint model for template filling, where the goal is to automatically specify the fields of target relations such as seminar announcements or corporate acquisition events. The approach models mention detection, unification and field extraction in a flexible, feature-rich model that allows for joint modeling of interdependencies at all levels and across fields. Such an approach can, for example, learn likely event durations and the fact that start times should come before end times. While the joint inference space is large, we demonstrate effective learning with a Perceptron-style approach that uses simple, greedy beam decoding. Empirical results in two benchmark domains demonstrate consistently strong performance on both mention de- tection and template filling tasks.</p><p>6 0.56251138 <a title="159-lsi-6" href="./acl-2012-Temporally_Anchored_Relation_Extraction.html">191 acl-2012-Temporally Anchored Relation Extraction</a></p>
<p>7 0.54264158 <a title="159-lsi-7" href="./acl-2012-A_Graph-based_Cross-lingual_Projection_Approach_for_Weakly_Supervised_Relation_Extraction.html">12 acl-2012-A Graph-based Cross-lingual Projection Approach for Weakly Supervised Relation Extraction</a></p>
<p>8 0.49344873 <a title="159-lsi-8" href="./acl-2012-Learning_High-Level_Planning_from_Text.html">129 acl-2012-Learning High-Level Planning from Text</a></p>
<p>9 0.49090424 <a title="159-lsi-9" href="./acl-2012-Learning_to_%22Read_Between_the_Lines%22_using_Bayesian_Logic_Programs.html">133 acl-2012-Learning to "Read Between the Lines" using Bayesian Logic Programs</a></p>
<p>10 0.44532663 <a title="159-lsi-10" href="./acl-2012-Coupling_Label_Propagation_and_Constraints_for_Temporal_Fact_Extraction.html">60 acl-2012-Coupling Label Propagation and Constraints for Temporal Fact Extraction</a></p>
<p>11 0.44064265 <a title="159-lsi-11" href="./acl-2012-Towards_the_Unsupervised_Acquisition_of_Discourse_Relations.html">201 acl-2012-Towards the Unsupervised Acquisition of Discourse Relations</a></p>
<p>12 0.43414435 <a title="159-lsi-12" href="./acl-2012-Named_Entity_Disambiguation_in_Streaming_Data.html">153 acl-2012-Named Entity Disambiguation in Streaming Data</a></p>
<p>13 0.41185129 <a title="159-lsi-13" href="./acl-2012-Mining_Entity_Types_from_Query_Logs_via_User_Intent_Modeling.html">142 acl-2012-Mining Entity Types from Query Logs via User Intent Modeling</a></p>
<p>14 0.40886202 <a title="159-lsi-14" href="./acl-2012-A_Joint_Model_for_Discovery_of_Aspects_in_Utterances.html">14 acl-2012-A Joint Model for Discovery of Aspects in Utterances</a></p>
<p>15 0.40540618 <a title="159-lsi-15" href="./acl-2012-A_Probabilistic_Model_for_Canonicalizing_Named_Entity_Mentions.html">18 acl-2012-A Probabilistic Model for Canonicalizing Named Entity Mentions</a></p>
<p>16 0.40313122 <a title="159-lsi-16" href="./acl-2012-Labeling_Documents_with_Timestamps%3A_Learning_from_their_Time_Expressions.html">126 acl-2012-Labeling Documents with Timestamps: Learning from their Time Expressions</a></p>
<p>17 0.35012934 <a title="159-lsi-17" href="./acl-2012-A_Comprehensive_Gold_Standard_for_the_Enron_Organizational_Hierarchy.html">6 acl-2012-A Comprehensive Gold Standard for the Enron Organizational Hierarchy</a></p>
<p>18 0.34983182 <a title="159-lsi-18" href="./acl-2012-Joint_Inference_of_Named_Entity_Recognition_and_Normalization_for_Tweets.html">124 acl-2012-Joint Inference of Named Entity Recognition and Normalization for Tweets</a></p>
<p>19 0.34370583 <a title="159-lsi-19" href="./acl-2012-A_Discriminative_Hierarchical_Model_for_Fast_Coreference_at_Large_Scale.html">10 acl-2012-A Discriminative Hierarchical Model for Fast Coreference at Large Scale</a></p>
<p>20 0.3377603 <a title="159-lsi-20" href="./acl-2012-Multilingual_Named_Entity_Recognition_using_Parallel_Data_and_Metadata_from_Wikipedia.html">150 acl-2012-Multilingual Named Entity Recognition using Parallel Data and Metadata from Wikipedia</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(25, 0.025), (26, 0.054), (28, 0.026), (30, 0.027), (37, 0.032), (39, 0.086), (59, 0.021), (74, 0.015), (82, 0.026), (84, 0.025), (85, 0.024), (90, 0.119), (92, 0.081), (94, 0.016), (96, 0.22), (99, 0.144)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.85626453 <a title="159-lda-1" href="./acl-2012-Collective_Classification_for_Fine-grained_Information_Status.html">50 acl-2012-Collective Classification for Fine-grained Information Status</a></p>
<p>Author: Katja Markert ; Yufang Hou ; Michael Strube</p><p>Abstract: Previous work on classifying information status (Nissim, 2006; Rahman and Ng, 2011) is restricted to coarse-grained classification and focuses on conversational dialogue. We here introduce the task of classifying finegrained information status and work on written text. We add a fine-grained information status layer to the Wall Street Journal portion of the OntoNotes corpus. We claim that the information status of a mention depends not only on the mention itself but also on other mentions in the vicinity and solve the task by collectively classifying the information status ofall mentions. Our approach strongly outperforms reimplementations of previous work.</p><p>same-paper 2 0.80552661 <a title="159-lda-2" href="./acl-2012-Pattern_Learning_for_Relation_Extraction_with_a_Hierarchical_Topic_Model.html">159 acl-2012-Pattern Learning for Relation Extraction with a Hierarchical Topic Model</a></p>
<p>Author: Enrique Alfonseca ; Katja Filippova ; Jean-Yves Delort ; Guillermo Garrido</p><p>Abstract: We describe the use of a hierarchical topic model for automatically identifying syntactic and lexical patterns that explicitly state ontological relations. We leverage distant supervision using relations from the knowledge base FreeBase, but do not require any manual heuristic nor manual seed list selections. Results show that the learned patterns can be used to extract new relations with good precision.</p><p>3 0.66657388 <a title="159-lda-3" href="./acl-2012-Temporally_Anchored_Relation_Extraction.html">191 acl-2012-Temporally Anchored Relation Extraction</a></p>
<p>Author: Guillermo Garrido ; Anselmo Penas ; Bernardo Cabaleiro ; Alvaro Rodrigo</p><p>Abstract: Although much work on relation extraction has aimed at obtaining static facts, many of the target relations are actually fluents, as their validity is naturally anchored to a certain time period. This paper proposes a methodological approach to temporally anchored relation extraction. Our proposal performs distant supervised learning to extract a set of relations from a natural language corpus, and anchors each of them to an interval of temporal validity, aggregating evidence from documents supporting the relation. We use a rich graphbased document-level representation to generate novel features for this task. Results show that our implementation for temporal anchoring is able to achieve a 69% of the upper bound performance imposed by the relation extraction step. Compared to the state of the art, the overall system achieves the highest precision reported.</p><p>4 0.66590106 <a title="159-lda-4" href="./acl-2012-Robust_Conversion_of_CCG_Derivations_to_Phrase_Structure_Trees.html">170 acl-2012-Robust Conversion of CCG Derivations to Phrase Structure Trees</a></p>
<p>Author: Jonathan K. Kummerfeld ; Dan Klein ; James R. Curran</p><p>Abstract: We propose an improved, bottom-up method for converting CCG derivations into PTB-style phrase structure trees. In contrast with past work (Clark and Curran, 2009), which used simple transductions on category pairs, our approach uses richer transductions attached to single categories. Our conversion preserves more sentences under round-trip conversion (5 1.1% vs. 39.6%) and is more robust. In particular, unlike past methods, ours does not require ad-hoc rules over non-local features, and so can be easily integrated into a parser.</p><p>5 0.66509247 <a title="159-lda-5" href="./acl-2012-Fully_Abstractive_Approach_to_Guided_Summarization.html">101 acl-2012-Fully Abstractive Approach to Guided Summarization</a></p>
<p>Author: Pierre-Etienne Genest ; Guy Lapalme</p><p>Abstract: This paper shows that full abstraction can be accomplished in the context of guided summarization. We describe a work in progress that relies on Information Extraction, statistical content selection and Natural Language Generation. Early results already demonstrate the effectiveness of the approach.</p><p>6 0.65832889 <a title="159-lda-6" href="./acl-2012-A_System_for_Real-time_Twitter_Sentiment_Analysis_of_2012_U.S._Presidential_Election_Cycle.html">21 acl-2012-A System for Real-time Twitter Sentiment Analysis of 2012 U.S. Presidential Election Cycle</a></p>
<p>7 0.65677136 <a title="159-lda-7" href="./acl-2012-Estimating_Compact_Yet_Rich_Tree_Insertion_Grammars.html">84 acl-2012-Estimating Compact Yet Rich Tree Insertion Grammars</a></p>
<p>8 0.65674305 <a title="159-lda-8" href="./acl-2012-Combining_Textual_Entailment_and_Argumentation_Theory_for_Supporting_Online_Debates_Interactions.html">53 acl-2012-Combining Textual Entailment and Argumentation Theory for Supporting Online Debates Interactions</a></p>
<p>9 0.65572923 <a title="159-lda-9" href="./acl-2012-Big_Data_versus_the_Crowd%3A_Looking_for_Relationships_in_All_the_Right_Places.html">40 acl-2012-Big Data versus the Crowd: Looking for Relationships in All the Right Places</a></p>
<p>10 0.65493912 <a title="159-lda-10" href="./acl-2012-Assessing_the_Effect_of_Inconsistent_Assessors_on_Summarization_Evaluation.html">29 acl-2012-Assessing the Effect of Inconsistent Assessors on Summarization Evaluation</a></p>
<p>11 0.65428227 <a title="159-lda-11" href="./acl-2012-Movie-DiC%3A_a_Movie_Dialogue_Corpus_for_Research_and_Development.html">149 acl-2012-Movie-DiC: a Movie Dialogue Corpus for Research and Development</a></p>
<p>12 0.64703923 <a title="159-lda-12" href="./acl-2012-UWN%3A_A_Large_Multilingual_Lexical_Knowledge_Base.html">206 acl-2012-UWN: A Large Multilingual Lexical Knowledge Base</a></p>
<p>13 0.64032954 <a title="159-lda-13" href="./acl-2012-Genre_Independent_Subgroup_Detection_in_Online_Discussion_Threads%3A_A_Study_of_Implicit_Attitude_using_Textual_Latent_Semantics.html">102 acl-2012-Genre Independent Subgroup Detection in Online Discussion Threads: A Study of Implicit Attitude using Textual Latent Semantics</a></p>
<p>14 0.6393255 <a title="159-lda-14" href="./acl-2012-Cross-Lingual_Mixture_Model_for_Sentiment_Classification.html">62 acl-2012-Cross-Lingual Mixture Model for Sentiment Classification</a></p>
<p>15 0.63612705 <a title="159-lda-15" href="./acl-2012-Topic_Models%2C_Latent_Space_Models%2C_Sparse_Coding%2C_and_All_That%3A_A_Systematic_Understanding_of_Probabilistic_Semantic_Extraction_in_Large_Corpus.html">198 acl-2012-Topic Models, Latent Space Models, Sparse Coding, and All That: A Systematic Understanding of Probabilistic Semantic Extraction in Large Corpus</a></p>
<p>16 0.63334352 <a title="159-lda-16" href="./acl-2012-Aspect_Extraction_through_Semi-Supervised_Modeling.html">28 acl-2012-Aspect Extraction through Semi-Supervised Modeling</a></p>
<p>17 0.63016146 <a title="159-lda-17" href="./acl-2012-Subgroup_Detection_in_Ideological_Discussions.html">187 acl-2012-Subgroup Detection in Ideological Discussions</a></p>
<p>18 0.62945175 <a title="159-lda-18" href="./acl-2012-MIX_Is_Not_a_Tree-Adjoining_Language.html">139 acl-2012-MIX Is Not a Tree-Adjoining Language</a></p>
<p>19 0.62754875 <a title="159-lda-19" href="./acl-2012-QuickView%3A_NLP-based_Tweet_Search.html">167 acl-2012-QuickView: NLP-based Tweet Search</a></p>
<p>20 0.62595034 <a title="159-lda-20" href="./acl-2012-Online_Plagiarized_Detection_Through_Exploiting_Lexical%2C_Syntax%2C_and_Semantic_Information.html">156 acl-2012-Online Plagiarized Detection Through Exploiting Lexical, Syntax, and Semantic Information</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
