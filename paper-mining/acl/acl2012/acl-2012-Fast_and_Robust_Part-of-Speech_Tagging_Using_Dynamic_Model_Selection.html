<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>96 acl-2012-Fast and Robust Part-of-Speech Tagging Using Dynamic Model Selection</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-96" href="#">acl2012-96</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>96 acl-2012-Fast and Robust Part-of-Speech Tagging Using Dynamic Model Selection</h1>
<br/><p>Source: <a title="acl-2012-96-pdf" href="http://aclweb.org/anthology//P/P12/P12-2071.pdf">pdf</a></p><p>Author: Jinho D. Choi ; Martha Palmer</p><p>Abstract: This paper presents a novel way of improving POS tagging on heterogeneous data. First, two separate models are trained (generalized and domain-specific) from the same data set by controlling lexical items with different document frequencies. During decoding, one of the models is selected dynamically given the cosine similarity between each sentence and the training data. This dynamic model selection approach, coupled with a one-pass, leftto-right POS tagging algorithm, is evaluated on corpora from seven different genres. Even with this simple tagging algorithm, our system shows comparable results against other state-of-the-art systems, and gives higher accuracies when evaluated on a mixture of the data. Furthermore, our system is able to tag about 32K tokens per second. this model selection approach to more sophisticated tagging improve their robustness even We believe that can be applied algorithms and further.</p><p>Reference: <a title="acl-2012-96-reference" href="../acl2012_reference/acl-2012-Fast_and_Robust_Part-of-Speech_Tagging_Using_Dynamic_Model_Selection_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Choi Department of Computer Science University of Colorado Boulder cho i d@ co l j orado  . [sent-2, score-0.041]
</p><p>2 edu  Abstract This paper presents a novel way of improving POS tagging on heterogeneous data. [sent-3, score-0.417]
</p><p>3 First, two separate models are trained (generalized and domain-specific) from the same data set by controlling lexical items with different document frequencies. [sent-4, score-0.112]
</p><p>4 During decoding, one of the models is selected dynamically given the cosine similarity between each sentence and the training data. [sent-5, score-0.4]
</p><p>5 This dynamic model selection approach, coupled with a one-pass, leftto-right POS tagging algorithm, is evaluated on corpora from seven different genres. [sent-6, score-0.796]
</p><p>6 Even with this simple tagging algorithm, our system shows comparable results against other state-of-the-art systems, and gives higher accuracies when evaluated on a mixture of the data. [sent-7, score-0.552]
</p><p>7 Furthermore, our system is able to tag  about 32K tokens per second. [sent-8, score-0.089]
</p><p>8 this model selection approach to more sophisticated tagging improve their robustness even  We believe that can be applied algorithms and further. [sent-9, score-0.69]
</p><p>9 First, a POS tagger needs to be tested for its robustness in handling heterogeneous data. [sent-11, score-0.348]
</p><p>10 1 Statistical POS taggers perform very well when their training and testing data are from the same source, achieving over 97% tagging accuracy (Toutanova et al. [sent-12, score-0.372]
</p><p>11 However, the performance degrades increasingly as the discrepancy between the training 1We use the term “heterogeneous data” as a mixture of data collected from several different sources. [sent-15, score-0.189]
</p><p>12 363 Martha Palmer Department of Linguistics University of Colorado Boulder mpalmer@ colorado edu  . [sent-16, score-0.073]
</p><p>13 Thus, to ensure robustness, a tagger needs to be evaluated on several different kinds of data. [sent-18, score-0.177]
</p><p>14 Second, a POS tagger should be tested for its speed. [sent-19, score-0.126]
</p><p>15 POS tagging is often performed as a pre-processing step to other tasks (e. [sent-20, score-0.322]
</p><p>16 Moreover, recent NLP tasks deal with very large-scale data where tagging speed is critical. [sent-23, score-0.398]
</p><p>17 To improve robustness, we first train two separate models; one is optimized for a general domain and the other is optimized for a domain specific to the training data. [sent-24, score-0.18]
</p><p>18 During decoding, we dynamically select one of the models by measuring similarities between input sentences and the training data. [sent-25, score-0.243]
</p><p>19 Our hypothesis is that the domain-specific and generalized models perform better for sentences similar and not similar to the training data, respectively. [sent-26, score-0.343]
</p><p>20 In this paper, we describe how to build both models using the same training data and select an appropriate model given input sentences during decoding. [sent-27, score-0.159]
</p><p>21 Each model uses a one-pass, left-to-right POS tagging algorithm. [sent-28, score-0.374]
</p><p>22 Even with the simple tagging algorithm, our system gives results that are comparable to two other state-  of-the-art systems when coupled with this dynamic model selection approach. [sent-29, score-0.68]
</p><p>23 Furthermore, our system shows noticeably faster tagging speed compared to the other two systems. [sent-30, score-0.509]
</p><p>24 For our experiments, we use corpora from seven different genres (Weischedel et al. [sent-31, score-0.16]
</p><p>25 To the best of our knowledge, this is the first time that a POS tagger has been evaluated on such a wide variety of data in English. [sent-35, score-0.177]
</p><p>26 1 Training generalized and domain-specific models using document frequency Consider training data as a collection of documents where each document contains sentences focusing on a similar topic. [sent-39, score-0.489]
</p><p>27 For instance, in the Wall Street Journal corpus, a document can be an individual file or all files within each section. [sent-40, score-0.1]
</p><p>28 , n-gram wordforms) that are too specific to individual documents should be avoided so that a classifier can place more  weight on features common to all documents. [sent-43, score-0.081]
</p><p>29 To filter out these document-specific features, a threshold is set for the document frequency of each lowercase simplified word-form (LSW) in the training data. [sent-44, score-0.265]
</p><p>30 A simplified word-form (SW) is derived by applying the following regular expressions sequentially to the original word-form, w. [sent-45, score-0.101]
</p><p>31 In a simplified word, all numerical expressions are replaced with 0. [sent-47, score-0.062]
</p><p>32 Given a set of LSW’s whose document frequencies are greater than a certain threshold, a model is trained by using only lexical features associated with these LSW’s. [sent-73, score-0.107]
</p><p>33 For a generalized model, we use a threshold of 2, meaning  that only lexical features whose LSW’s occur in at least 3 documents of the training data are used. [sent-74, score-0.42]
</p><p>34 For a domain-specific model, we use a threshold of 1. [sent-75, score-0.098]
</p><p>35 The generalized and domain-specific models are trained separately; their learning parameters are optimized by running n-fold cross-validation where n is the total number of documents in the training data and grid search on Liblinear parameters c and B (see Section 2. [sent-76, score-0.501]
</p><p>36 2 Dynamic model selection during decoding Once both generalized and domain-specific models are trained, alternative approaches can be adapted for decoding. [sent-80, score-0.545]
</p><p>37 One is to run both models and merge their outputs. [sent-81, score-0.057]
</p><p>38 This approach can produce output that is potentially more accurate than output from either model, but takes longer to decode because the merging cannot be processed until both models are finished. [sent-82, score-0.057]
</p><p>39 Instead, we take an alternative approach, that is to select one of the models dynamically given the input sentence. [sent-83, score-0.139]
</p><p>40 If the model selection is done ef-  ficiently, this approach runs as fast as running just one model, yet can give more robust performance. [sent-84, score-0.243]
</p><p>41 The premise of this dynamic model selection is that the domain-specific model performs better for input sentences similar to its training space, whereas the generalized model performs better for ones that are dissimilar. [sent-85, score-0.878]
</p><p>42 To measure similarity, a set of SW’s, say T, used for training the domain-specific model is collected. [sent-86, score-0.102]
</p><p>43 If the cosine similarity between T and S is greater than a certain threshold, the domain-specific model is selected for decoding; otherwise, the generalized model is selected. [sent-88, score-0.551]
</p><p>44 Cosine Similarity  Figure 1: Cosine similarity distribution: the y-axis shows the number of occurrences for each cosine similarity during cross-validation. [sent-89, score-0.279]
</p><p>45 The threshold is derived automatically by running cross-validation; for each fold, both models are run simultaneously and cosine similarities of sentences on which the domain-specific model performs better are extracted. [sent-90, score-0.553]
</p><p>46 Figure 1 shows the distribution of cosine similarities extracted during our crossvalidation. [sent-91, score-0.197]
</p><p>47 Given the cosine similarity distribution, the similarity at the first 5% area (in this case, 0. [sent-92, score-0.279]
</p><p>48 3 Tagging algorithm and features Each model uses a one-pass, left-to-right POS tagging algorithm. [sent-95, score-0.414]
</p><p>49 The motivation is to analyze how dynamic model selection works with a simple algorithm first and then apply it to more sophisticated ones later (e. [sent-96, score-0.439]
</p><p>50 Our feature set (Table 1) is inspired by Gim e´nez and M `arquez (2004) although ambiguity classes are derived selectively for our case. [sent-99, score-0.096]
</p><p>51 Given a word-form, we count how often each POS tag is used with the form and keep only ones above a certain threshold. [sent-100, score-0.036]
</p><p>52 For both generalized and domain-specific models, a  threshold of 0. [sent-101, score-0.334]
</p><p>53 From our experiments, we find this to be more useful than expanding ambiguity classes with lower thresholds. [sent-103, score-0.057]
</p><p>54 word, f: SW, m: LSW, p: POS, a: ambiguity class, c∗ : character sequence in wi (e. [sent-104, score-0.108]
</p><p>55 (2003) introduced a POS tagging algorithm using bidirectional dependency networks, and showed the best contemporary results. [sent-119, score-0.525]
</p><p>56 Gim e´nez and M `arquez (2004) used one-pass, left-to-right and right-to-left combined tagging algorithm and achieved near state-of-the-art results. [sent-120, score-0.362]
</p><p>57 365 (2007) presented a tagging approach using guided learning for bidirectional sequence classification and showed current state-of-the-art results. [sent-122, score-0.497]
</p><p>58 3 Our individual models (generalized and domainspecific) are similar to Gim e´nez and M `arquez (2004) in that we use a subset of their features and take onepass, left-to-right tagging approach, which is a simpler version of theirs. [sent-123, score-0.424]
</p><p>59 However, we use Liblinear for learning, which trains much faster than their classifier, Support Vector Machines. [sent-124, score-0.044]
</p><p>60 The entire training data consists of 30,060 sentences with 73 1,677 tokens. [sent-129, score-0.05]
</p><p>61 For evaluation, corpora from seven different genres are used: the MSNBC broadcasting conversation (BC), the CNN broadcasting news (BN), the Sinorama news magazine (MZ), the WSJ newswire (NW), and the GALE web-text (WB), all from OntoNotes v4. [sent-130, score-0.312]
</p><p>62 Additionally, the Mipacq clinical notes (CN) and the Medpedia articles (MD) are used for evaluation of medical domains (Nielsen et al. [sent-132, score-0.063]
</p><p>63 2 Accuracy comparisons Our models are compared with two other state-ofthe-art systems, the Stanford tagger (Toutanova et al. [sent-136, score-0.271]
</p><p>64 Both systems are trained with the same training data and use configurations optimized for their best reported results. [sent-138, score-0.115]
</p><p>65 Tables 3 and 4 show tagging accuracies of all tokens and unknown tokens, respectively. [sent-139, score-0.546]
</p><p>66 Our individual models (Models D and  G) give comparable  results to the other systems. [sent-140, score-0.102]
</p><p>67 Model G performs better than Model D for BC, CN, and MD, which are very different from the WSJ. [sent-141, score-0.053]
</p><p>68 This implies that the generalized  model shows its  strength in tagging data that differs from the training data. [sent-142, score-0.66]
</p><p>69 The dynamic  model selection approach  (Model S) shows the most robust results across genres, although Models  D and G still can perform  3Some semi-supervised and domain-adaptation approaches using external data had shown better performance (Daume III, 2007; Spoustov a´ et al. [sent-143, score-0.308]
</p><p>70 The Total column indicates  a  mixture of data from all genres. [sent-170, score-0.101]
</p><p>71 BCBNCNMDMZNWWBTotal  Table 3: Tagging accuracies of all tokens (in %). [sent-171, score-0.167]
</p><p>72 Models D and G indicate domain-specific and generalized models, respectively and Model S indicates the dynamic model selection approach. [sent-172, score-0.544]
</p><p>73 “G over D” shows how often Model G is selected over Model D using the dynamic selection (in %). [sent-173, score-0.256]
</p><p>74 356245 Table 4: Tagging accuracies of unknown tokens (in %). [sent-182, score-0.224]
</p><p>75 better for individual genres (except for NW, where Model S performs better than any other model). [sent-183, score-0.193]
</p><p>76 For both all and unknown token experiments, Model S performs better than the other systems when evaluated on a mixture of the data (the Total column). [sent-184, score-0.262]
</p><p>77 The Stanford tagger gives significantly better results for unknown tokens in BN; we suspect that this is where their bidirectional tagging algorithm has an advantage over our simple left-to-right algorithm. [sent-187, score-0.759]
</p><p>78 3 Speed comparisons Tagging speeds are measured by running each system on the mixture of all data. [sent-189, score-0.246]
</p><p>79 Our system and the Stanford system are both written in Java; the Stanford tagger provides APIs that allow us to make fair comparisons between the two systems. [sent-190, score-0.214]
</p><p>80 All experiments are evaluated on an Intel Xeon 2. [sent-193, score-0.051]
</p><p>81 03 milliseconds per to366 ken), which includes run-time for both POS tagging  and model selection. [sent-196, score-0.412]
</p><p>82 5  Conclusion  We present a dynamic model selection approach that improves the robustness of POS tagging on heterogeneous data. [sent-199, score-0.852]
</p><p>83 We believe that this approach can be applied to more sophisticated algorithms and improve their robustness even further. [sent-200, score-0.182]
</p><p>84 Our system also shows noticeably faster tagging speed against two other state-of-the-art systems. [sent-201, score-0.509]
</p><p>85 For future work, we will experiment with more diverse training and testing data and also more sophisticated algorithms. [sent-202, score-0.105]
</p><p>86 SVMTool: A general POS tagger generator based on Support Vector Machines. [sent-211, score-0.126]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tagging', 0.322), ('lsw', 0.285), ('generalized', 0.236), ('gim', 0.233), ('nez', 0.233), ('arquez', 0.163), ('pos', 0.156), ('svmtool', 0.151), ('cosine', 0.143), ('bcbncnmdmznwwbtotal', 0.143), ('selection', 0.134), ('robustness', 0.127), ('tagger', 0.126), ('bidirectional', 0.125), ('nielsen', 0.124), ('dynamic', 0.122), ('mixture', 0.101), ('threshold', 0.098), ('weischedel', 0.095), ('genres', 0.095), ('heterogeneous', 0.095), ('ontonotes', 0.091), ('tokens', 0.089), ('toutanova', 0.088), ('comparisons', 0.088), ('liblinear', 0.088), ('sw', 0.084), ('spoustov', 0.083), ('dynamically', 0.082), ('accuracies', 0.078), ('speed', 0.076), ('broadcasting', 0.076), ('colorado', 0.073), ('wall', 0.073), ('martha', 0.073), ('similarity', 0.068), ('street', 0.068), ('noticeably', 0.067), ('decoding', 0.066), ('optimized', 0.065), ('seven', 0.065), ('bc', 0.063), ('daume', 0.063), ('clinical', 0.063), ('cn', 0.062), ('simplified', 0.062), ('bn', 0.061), ('running', 0.057), ('ambiguity', 0.057), ('models', 0.057), ('stanford', 0.057), ('unknown', 0.057), ('nw', 0.056), ('document', 0.055), ('sophisticated', 0.055), ('similarities', 0.054), ('hsieh', 0.053), ('performs', 0.053), ('model', 0.052), ('md', 0.051), ('wi', 0.051), ('evaluated', 0.051), ('training', 0.05), ('guided', 0.05), ('coupled', 0.05), ('palmer', 0.047), ('shen', 0.046), ('individual', 0.045), ('boulder', 0.044), ('wsj', 0.044), ('faster', 0.044), ('jan', 0.043), ('ken', 0.041), ('condensed', 0.041), ('drahom', 0.041), ('johanka', 0.041), ('raab', 0.041), ('wordforms', 0.041), ('guergana', 0.041), ('masanz', 0.041), ('orado', 0.041), ('perl', 0.041), ('savova', 0.041), ('sinorama', 0.041), ('algorithm', 0.04), ('derived', 0.039), ('gaard', 0.038), ('miroslav', 0.038), ('belvin', 0.038), ('milliseconds', 0.038), ('discrepancy', 0.038), ('cnn', 0.038), ('contemporary', 0.038), ('mpalmer', 0.038), ('premise', 0.038), ('sathiya', 0.038), ('documents', 0.036), ('ones', 0.036), ('wb', 0.035), ('coordinate', 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="96-tfidf-1" href="./acl-2012-Fast_and_Robust_Part-of-Speech_Tagging_Using_Dynamic_Model_Selection.html">96 acl-2012-Fast and Robust Part-of-Speech Tagging Using Dynamic Model Selection</a></p>
<p>Author: Jinho D. Choi ; Martha Palmer</p><p>Abstract: This paper presents a novel way of improving POS tagging on heterogeneous data. First, two separate models are trained (generalized and domain-specific) from the same data set by controlling lexical items with different document frequencies. During decoding, one of the models is selected dynamically given the cosine similarity between each sentence and the training data. This dynamic model selection approach, coupled with a one-pass, leftto-right POS tagging algorithm, is evaluated on corpora from seven different genres. Even with this simple tagging algorithm, our system shows comparable results against other state-of-the-art systems, and gives higher accuracies when evaluated on a mixture of the data. Furthermore, our system is able to tag about 32K tokens per second. this model selection approach to more sophisticated tagging improve their robustness even We believe that can be applied algorithms and further.</p><p>2 0.23831218 <a title="96-tfidf-2" href="./acl-2012-A_Cost_Sensitive_Part-of-Speech_Tagging%3A_Differentiating_Serious_Errors_from_Minor_Errors.html">9 acl-2012-A Cost Sensitive Part-of-Speech Tagging: Differentiating Serious Errors from Minor Errors</a></p>
<p>Author: Hyun-Je Song ; Jeong-Woo Son ; Tae-Gil Noh ; Seong-Bae Park ; Sang-Jo Lee</p><p>Abstract: All types of part-of-speech (POS) tagging errors have been equally treated by existing taggers. However, the errors are not equally important, since some errors affect the performance of subsequent natural language processing (NLP) tasks seriously while others do not. This paper aims to minimize these serious errors while retaining the overall performance of POS tagging. Two gradient loss functions are proposed to reflect the different types of errors. They are designed to assign a larger cost to serious errors and a smaller one to minor errors. Through a set of POS tagging experiments, it is shown that the classifier trained with the proposed loss functions reduces serious errors compared to state-of-the-art POS taggers. In addition, the experimental result on text chunking shows that fewer serious errors help to improve the performance of sub- sequent NLP tasks.</p><p>3 0.19741 <a title="96-tfidf-3" href="./acl-2012-Capturing_Paradigmatic_and_Syntagmatic_Lexical_Relations%3A_Towards_Accurate_Chinese_Part-of-Speech_Tagging.html">45 acl-2012-Capturing Paradigmatic and Syntagmatic Lexical Relations: Towards Accurate Chinese Part-of-Speech Tagging</a></p>
<p>Author: Weiwei Sun ; Hans Uszkoreit</p><p>Abstract: From the perspective of structural linguistics, we explore paradigmatic and syntagmatic lexical relations for Chinese POS tagging, an important and challenging task for Chinese language processing. Paradigmatic lexical relations are explicitly captured by word clustering on large-scale unlabeled data and are used to design new features to enhance a discriminative tagger. Syntagmatic lexical relations are implicitly captured by constituent parsing and are utilized via system combination. Experiments on the Penn Chinese Treebank demonstrate the importance of both paradigmatic and syntagmatic relations. Our linguistically motivated approaches yield a relative error reduction of 18% in total over a stateof-the-art baseline.</p><p>4 0.15181586 <a title="96-tfidf-4" href="./acl-2012-Reducing_Approximation_and_Estimation_Errors_for_Chinese_Lexical_Processing_with_Heterogeneous_Annotations.html">168 acl-2012-Reducing Approximation and Estimation Errors for Chinese Lexical Processing with Heterogeneous Annotations</a></p>
<p>Author: Weiwei Sun ; Xiaojun Wan</p><p>Abstract: We address the issue of consuming heterogeneous annotation data for Chinese word segmentation and part-of-speech tagging. We empirically analyze the diversity between two representative corpora, i.e. Penn Chinese Treebank (CTB) and PKU’s People’s Daily (PPD), on manually mapped data, and show that their linguistic annotations are systematically different and highly compatible. The analysis is further exploited to improve processing accuracy by (1) integrating systems that are respectively trained on heterogeneous annotations to reduce the approximation error, and (2) re-training models with high quality automatically converted data to reduce the estimation error. Evaluation on the CTB and PPD data shows that our novel model achieves a relative error reduction of 11% over the best reported result in the literature.</p><p>5 0.14366685 <a title="96-tfidf-5" href="./acl-2012-Incremental_Joint_Approach_to_Word_Segmentation%2C_POS_Tagging%2C_and_Dependency_Parsing_in_Chinese.html">119 acl-2012-Incremental Joint Approach to Word Segmentation, POS Tagging, and Dependency Parsing in Chinese</a></p>
<p>Author: Jun Hatori ; Takuya Matsuzaki ; Yusuke Miyao ; Jun'ichi Tsujii</p><p>Abstract: We propose the first joint model for word segmentation, POS tagging, and dependency parsing for Chinese. Based on an extension of the incremental joint model for POS tagging and dependency parsing (Hatori et al., 2011), we propose an efficient character-based decoding method that can combine features from state-of-the-art segmentation, POS tagging, and dependency parsing models. We also describe our method to align comparable states in the beam, and how we can combine features of different characteristics in our incremental framework. In experiments using the Chinese Treebank (CTB), we show that the accuracies of the three tasks can be improved significantly over the baseline models, particularly by 0.6% for POS tagging and 2.4% for dependency parsing. We also perform comparison experiments with the partially joint models.</p><p>6 0.13232426 <a title="96-tfidf-6" href="./acl-2012-A_Graphical_Interface_for_MT_Evaluation_and_Error_Analysis.html">13 acl-2012-A Graphical Interface for MT Evaluation and Error Analysis</a></p>
<p>7 0.10730097 <a title="96-tfidf-7" href="./acl-2012-Exploring_Deterministic_Constraints%3A_from_a_Constrained_English_POS_Tagger_to_an_Efficient_ILP_Solution_to_Chinese_Word_Segmentation.html">89 acl-2012-Exploring Deterministic Constraints: from a Constrained English POS Tagger to an Efficient ILP Solution to Chinese Word Segmentation</a></p>
<p>8 0.10223936 <a title="96-tfidf-8" href="./acl-2012-Sentence_Dependency_Tagging_in_Online_Question_Answering_Forums.html">177 acl-2012-Sentence Dependency Tagging in Online Question Answering Forums</a></p>
<p>9 0.097894534 <a title="96-tfidf-9" href="./acl-2012-A_Comparison_of_Chinese_Parsers_for_Stanford_Dependencies.html">5 acl-2012-A Comparison of Chinese Parsers for Stanford Dependencies</a></p>
<p>10 0.097795613 <a title="96-tfidf-10" href="./acl-2012-A_Class-Based_Agreement_Model_for_Generating_Accurately_Inflected_Translations.html">3 acl-2012-A Class-Based Agreement Model for Generating Accurately Inflected Translations</a></p>
<p>11 0.095290825 <a title="96-tfidf-11" href="./acl-2012-Lemmatisation_as_a_Tagging_Task.html">137 acl-2012-Lemmatisation as a Tagging Task</a></p>
<p>12 0.094159484 <a title="96-tfidf-12" href="./acl-2012-Mixing_Multiple_Translation_Models_in_Statistical_Machine_Translation.html">143 acl-2012-Mixing Multiple Translation Models in Statistical Machine Translation</a></p>
<p>13 0.093083918 <a title="96-tfidf-13" href="./acl-2012-Using_Search-Logs_to_Improve_Query_Tagging.html">212 acl-2012-Using Search-Logs to Improve Query Tagging</a></p>
<p>14 0.084388055 <a title="96-tfidf-14" href="./acl-2012-Fast_Syntactic_Analysis_for_Statistical_Language_Modeling_via_Substructure_Sharing_and_Uptraining.html">95 acl-2012-Fast Syntactic Analysis for Statistical Language Modeling via Substructure Sharing and Uptraining</a></p>
<p>15 0.080051951 <a title="96-tfidf-15" href="./acl-2012-Iterative_Viterbi_A%2A_Algorithm_for_K-Best_Sequential_Decoding.html">121 acl-2012-Iterative Viterbi A* Algorithm for K-Best Sequential Decoding</a></p>
<p>16 0.075663671 <a title="96-tfidf-16" href="./acl-2012-Multilingual_Named_Entity_Recognition_using_Parallel_Data_and_Metadata_from_Wikipedia.html">150 acl-2012-Multilingual Named Entity Recognition using Parallel Data and Metadata from Wikipedia</a></p>
<p>17 0.070479922 <a title="96-tfidf-17" href="./acl-2012-Building_Trainable_Taggers_in_a_Web-based%2C_UIMA-Supported_NLP_Workbench.html">43 acl-2012-Building Trainable Taggers in a Web-based, UIMA-Supported NLP Workbench</a></p>
<p>18 0.066786781 <a title="96-tfidf-18" href="./acl-2012-NiuTrans%3A_An_Open_Source_Toolkit_for_Phrase-based_and_Syntax-based_Machine_Translation.html">155 acl-2012-NiuTrans: An Open Source Toolkit for Phrase-based and Syntax-based Machine Translation</a></p>
<p>19 0.065234058 <a title="96-tfidf-19" href="./acl-2012-Exploiting_Multiple_Treebanks_for_Parsing_with_Quasi-synchronous_Grammars.html">87 acl-2012-Exploiting Multiple Treebanks for Parsing with Quasi-synchronous Grammars</a></p>
<p>20 0.065204576 <a title="96-tfidf-20" href="./acl-2012-Verb_Classification_using_Distributional_Similarity_in_Syntactic_and_Semantic_Structures.html">214 acl-2012-Verb Classification using Distributional Similarity in Syntactic and Semantic Structures</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.213), (1, 0.012), (2, -0.101), (3, -0.077), (4, -0.005), (5, 0.138), (6, 0.086), (7, -0.16), (8, -0.019), (9, -0.03), (10, -0.033), (11, 0.03), (12, 0.118), (13, -0.008), (14, 0.062), (15, 0.196), (16, 0.088), (17, 0.054), (18, 0.137), (19, -0.057), (20, 0.066), (21, 0.116), (22, -0.084), (23, 0.119), (24, 0.196), (25, 0.076), (26, -0.025), (27, -0.006), (28, 0.015), (29, 0.118), (30, 0.129), (31, 0.053), (32, 0.024), (33, 0.076), (34, 0.099), (35, -0.032), (36, -0.207), (37, -0.04), (38, 0.069), (39, 0.024), (40, -0.029), (41, -0.054), (42, 0.056), (43, -0.053), (44, -0.102), (45, -0.003), (46, 0.03), (47, -0.025), (48, 0.023), (49, -0.1)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95741034 <a title="96-lsi-1" href="./acl-2012-Fast_and_Robust_Part-of-Speech_Tagging_Using_Dynamic_Model_Selection.html">96 acl-2012-Fast and Robust Part-of-Speech Tagging Using Dynamic Model Selection</a></p>
<p>Author: Jinho D. Choi ; Martha Palmer</p><p>Abstract: This paper presents a novel way of improving POS tagging on heterogeneous data. First, two separate models are trained (generalized and domain-specific) from the same data set by controlling lexical items with different document frequencies. During decoding, one of the models is selected dynamically given the cosine similarity between each sentence and the training data. This dynamic model selection approach, coupled with a one-pass, leftto-right POS tagging algorithm, is evaluated on corpora from seven different genres. Even with this simple tagging algorithm, our system shows comparable results against other state-of-the-art systems, and gives higher accuracies when evaluated on a mixture of the data. Furthermore, our system is able to tag about 32K tokens per second. this model selection approach to more sophisticated tagging improve their robustness even We believe that can be applied algorithms and further.</p><p>2 0.83659267 <a title="96-lsi-2" href="./acl-2012-A_Cost_Sensitive_Part-of-Speech_Tagging%3A_Differentiating_Serious_Errors_from_Minor_Errors.html">9 acl-2012-A Cost Sensitive Part-of-Speech Tagging: Differentiating Serious Errors from Minor Errors</a></p>
<p>Author: Hyun-Je Song ; Jeong-Woo Son ; Tae-Gil Noh ; Seong-Bae Park ; Sang-Jo Lee</p><p>Abstract: All types of part-of-speech (POS) tagging errors have been equally treated by existing taggers. However, the errors are not equally important, since some errors affect the performance of subsequent natural language processing (NLP) tasks seriously while others do not. This paper aims to minimize these serious errors while retaining the overall performance of POS tagging. Two gradient loss functions are proposed to reflect the different types of errors. They are designed to assign a larger cost to serious errors and a smaller one to minor errors. Through a set of POS tagging experiments, it is shown that the classifier trained with the proposed loss functions reduces serious errors compared to state-of-the-art POS taggers. In addition, the experimental result on text chunking shows that fewer serious errors help to improve the performance of sub- sequent NLP tasks.</p><p>3 0.7513383 <a title="96-lsi-3" href="./acl-2012-Capturing_Paradigmatic_and_Syntagmatic_Lexical_Relations%3A_Towards_Accurate_Chinese_Part-of-Speech_Tagging.html">45 acl-2012-Capturing Paradigmatic and Syntagmatic Lexical Relations: Towards Accurate Chinese Part-of-Speech Tagging</a></p>
<p>Author: Weiwei Sun ; Hans Uszkoreit</p><p>Abstract: From the perspective of structural linguistics, we explore paradigmatic and syntagmatic lexical relations for Chinese POS tagging, an important and challenging task for Chinese language processing. Paradigmatic lexical relations are explicitly captured by word clustering on large-scale unlabeled data and are used to design new features to enhance a discriminative tagger. Syntagmatic lexical relations are implicitly captured by constituent parsing and are utilized via system combination. Experiments on the Penn Chinese Treebank demonstrate the importance of both paradigmatic and syntagmatic relations. Our linguistically motivated approaches yield a relative error reduction of 18% in total over a stateof-the-art baseline.</p><p>4 0.70738518 <a title="96-lsi-4" href="./acl-2012-Reducing_Approximation_and_Estimation_Errors_for_Chinese_Lexical_Processing_with_Heterogeneous_Annotations.html">168 acl-2012-Reducing Approximation and Estimation Errors for Chinese Lexical Processing with Heterogeneous Annotations</a></p>
<p>Author: Weiwei Sun ; Xiaojun Wan</p><p>Abstract: We address the issue of consuming heterogeneous annotation data for Chinese word segmentation and part-of-speech tagging. We empirically analyze the diversity between two representative corpora, i.e. Penn Chinese Treebank (CTB) and PKU’s People’s Daily (PPD), on manually mapped data, and show that their linguistic annotations are systematically different and highly compatible. The analysis is further exploited to improve processing accuracy by (1) integrating systems that are respectively trained on heterogeneous annotations to reduce the approximation error, and (2) re-training models with high quality automatically converted data to reduce the estimation error. Evaluation on the CTB and PPD data shows that our novel model achieves a relative error reduction of 11% over the best reported result in the literature.</p><p>5 0.68377125 <a title="96-lsi-5" href="./acl-2012-Lemmatisation_as_a_Tagging_Task.html">137 acl-2012-Lemmatisation as a Tagging Task</a></p>
<p>Author: Andrea Gesmundo ; Tanja Samardzic</p><p>Abstract: We present a novel approach to the task of word lemmatisation. We formalise lemmatisation as a category tagging task, by describing how a word-to-lemma transformation rule can be encoded in a single label and how a set of such labels can be inferred for a specific language. In this way, a lemmatisation system can be trained and tested using any supervised tagging model. In contrast to previous approaches, the proposed technique allows us to easily integrate relevant contextual information. We test our approach on eight languages reaching a new state-of-the-art level for the lemmatisation task.</p><p>6 0.5822717 <a title="96-lsi-6" href="./acl-2012-Incremental_Joint_Approach_to_Word_Segmentation%2C_POS_Tagging%2C_and_Dependency_Parsing_in_Chinese.html">119 acl-2012-Incremental Joint Approach to Word Segmentation, POS Tagging, and Dependency Parsing in Chinese</a></p>
<p>7 0.54731661 <a title="96-lsi-7" href="./acl-2012-Exploring_Deterministic_Constraints%3A_from_a_Constrained_English_POS_Tagger_to_an_Efficient_ILP_Solution_to_Chinese_Word_Segmentation.html">89 acl-2012-Exploring Deterministic Constraints: from a Constrained English POS Tagger to an Efficient ILP Solution to Chinese Word Segmentation</a></p>
<p>8 0.53129691 <a title="96-lsi-8" href="./acl-2012-Syntactic_Annotations_for_the_Google_Books_NGram_Corpus.html">189 acl-2012-Syntactic Annotations for the Google Books NGram Corpus</a></p>
<p>9 0.49615097 <a title="96-lsi-9" href="./acl-2012-Building_Trainable_Taggers_in_a_Web-based%2C_UIMA-Supported_NLP_Workbench.html">43 acl-2012-Building Trainable Taggers in a Web-based, UIMA-Supported NLP Workbench</a></p>
<p>10 0.4567115 <a title="96-lsi-10" href="./acl-2012-Coarse_Lexical_Semantic_Annotation_with_Supersenses%3A_An_Arabic_Case_Study.html">49 acl-2012-Coarse Lexical Semantic Annotation with Supersenses: An Arabic Case Study</a></p>
<p>11 0.45049801 <a title="96-lsi-11" href="./acl-2012-Using_Search-Logs_to_Improve_Query_Tagging.html">212 acl-2012-Using Search-Logs to Improve Query Tagging</a></p>
<p>12 0.43273818 <a title="96-lsi-12" href="./acl-2012-Exploiting_Multiple_Treebanks_for_Parsing_with_Quasi-synchronous_Grammars.html">87 acl-2012-Exploiting Multiple Treebanks for Parsing with Quasi-synchronous Grammars</a></p>
<p>13 0.41114509 <a title="96-lsi-13" href="./acl-2012-A_Graphical_Interface_for_MT_Evaluation_and_Error_Analysis.html">13 acl-2012-A Graphical Interface for MT Evaluation and Error Analysis</a></p>
<p>14 0.38595518 <a title="96-lsi-14" href="./acl-2012-Fast_Syntactic_Analysis_for_Statistical_Language_Modeling_via_Substructure_Sharing_and_Uptraining.html">95 acl-2012-Fast Syntactic Analysis for Statistical Language Modeling via Substructure Sharing and Uptraining</a></p>
<p>15 0.37725961 <a title="96-lsi-15" href="./acl-2012-A_Feature-Rich_Constituent_Context_Model_for_Grammar_Induction.html">11 acl-2012-A Feature-Rich Constituent Context Model for Grammar Induction</a></p>
<p>16 0.34861878 <a title="96-lsi-16" href="./acl-2012-A_Class-Based_Agreement_Model_for_Generating_Accurately_Inflected_Translations.html">3 acl-2012-A Class-Based Agreement Model for Generating Accurately Inflected Translations</a></p>
<p>17 0.34256765 <a title="96-lsi-17" href="./acl-2012-Large-Scale_Syntactic_Language_Modeling_with_Treelets.html">127 acl-2012-Large-Scale Syntactic Language Modeling with Treelets</a></p>
<p>18 0.33590168 <a title="96-lsi-18" href="./acl-2012-Discriminative_Strategies_to_Integrate_Multiword_Expression_Recognition_and_Parsing.html">75 acl-2012-Discriminative Strategies to Integrate Multiword Expression Recognition and Parsing</a></p>
<p>19 0.33467504 <a title="96-lsi-19" href="./acl-2012-Error_Mining_on_Dependency_Trees.html">83 acl-2012-Error Mining on Dependency Trees</a></p>
<p>20 0.33047161 <a title="96-lsi-20" href="./acl-2012-Sentence_Dependency_Tagging_in_Online_Question_Answering_Forums.html">177 acl-2012-Sentence Dependency Tagging in Online Question Answering Forums</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(25, 0.013), (26, 0.028), (28, 0.033), (30, 0.011), (37, 0.018), (39, 0.023), (74, 0.017), (84, 0.015), (85, 0.545), (90, 0.157), (92, 0.03), (94, 0.013), (99, 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.89620847 <a title="96-lda-1" href="./acl-2012-Entailment-based_Text_Exploration_with_Application_to_the_Health-care_Domain.html">82 acl-2012-Entailment-based Text Exploration with Application to the Health-care Domain</a></p>
<p>Author: Meni Adler ; Jonathan Berant ; Ido Dagan</p><p>Abstract: We present a novel text exploration model, which extends the scope of state-of-the-art technologies by moving from standard concept-based exploration to statement-based exploration. The proposed scheme utilizes the textual entailment relation between statements as the basis of the exploration process. A user of our system can explore the result space of a query by drilling down/up from one statement to another, according to entailment relations specified by an entailment graph and an optional concept taxonomy. As a prominent use case, we apply our exploration system and illustrate its benefit on the health-care domain. To the best of our knowledge this is the first implementation of an exploration system at the statement level that is based on the textual entailment relation. 1</p><p>2 0.88305306 <a title="96-lda-2" href="./acl-2012-A_Graphical_Interface_for_MT_Evaluation_and_Error_Analysis.html">13 acl-2012-A Graphical Interface for MT Evaluation and Error Analysis</a></p>
<p>Author: Meritxell Gonzalez ; Jesus Gimenez ; Lluis Marquez</p><p>Abstract: Error analysis in machine translation is a necessary step in order to investigate the strengths and weaknesses of the MT systems under development and allow fair comparisons among them. This work presents an application that shows how a set of heterogeneous automatic metrics can be used to evaluate a test bed of automatic translations. To do so, we have set up an online graphical interface for the ASIYA toolkit, a rich repository of evaluation measures working at different linguistic levels. The current implementation of the interface shows constituency and dependency trees as well as shallow syntactic and semantic annotations, and word alignments. The intelligent visualization of the linguistic structures used by the metrics, as well as a set of navigational functionalities, may lead towards advanced methods for automatic error analysis.</p><p>3 0.84622359 <a title="96-lda-3" href="./acl-2012-Probabilistic_Integration_of_Partial_Lexical_Information_for_Noise_Robust_Haptic_Voice_Recognition.html">165 acl-2012-Probabilistic Integration of Partial Lexical Information for Noise Robust Haptic Voice Recognition</a></p>
<p>Author: Khe Chai Sim</p><p>Abstract: This paper presents a probabilistic framework that combines multiple knowledge sources for Haptic Voice Recognition (HVR), a multimodal input method designed to provide efficient text entry on modern mobile devices. HVR extends the conventional voice input by allowing users to provide complementary partial lexical information via touch input to improve the efficiency and accuracy of voice recognition. This paper investigates the use of the initial letter of the words in the utterance as the partial lexical information. In addition to the acoustic and language models used in automatic speech recognition systems, HVR uses the haptic and partial lexical models as additional knowledge sources to reduce the recognition search space and suppress confusions. Experimental results show that both the word error rate and runtime factor can be re- duced by a factor of two using HVR.</p><p>same-paper 4 0.84367234 <a title="96-lda-4" href="./acl-2012-Fast_and_Robust_Part-of-Speech_Tagging_Using_Dynamic_Model_Selection.html">96 acl-2012-Fast and Robust Part-of-Speech Tagging Using Dynamic Model Selection</a></p>
<p>Author: Jinho D. Choi ; Martha Palmer</p><p>Abstract: This paper presents a novel way of improving POS tagging on heterogeneous data. First, two separate models are trained (generalized and domain-specific) from the same data set by controlling lexical items with different document frequencies. During decoding, one of the models is selected dynamically given the cosine similarity between each sentence and the training data. This dynamic model selection approach, coupled with a one-pass, leftto-right POS tagging algorithm, is evaluated on corpora from seven different genres. Even with this simple tagging algorithm, our system shows comparable results against other state-of-the-art systems, and gives higher accuracies when evaluated on a mixture of the data. Furthermore, our system is able to tag about 32K tokens per second. this model selection approach to more sophisticated tagging improve their robustness even We believe that can be applied algorithms and further.</p><p>5 0.8340506 <a title="96-lda-5" href="./acl-2012-Multilingual_WSD_with_Just_a_Few_Lines_of_Code%3A_the_BabelNet_API.html">152 acl-2012-Multilingual WSD with Just a Few Lines of Code: the BabelNet API</a></p>
<p>Author: Roberto Navigli ; Simone Paolo Ponzetto</p><p>Abstract: In this paper we present an API for programmatic access to BabelNet a wide-coverage multilingual lexical knowledge base and multilingual knowledge-rich Word Sense Disambiguation (WSD). Our aim is to provide the research community with easy-to-use tools to perform multilingual lexical semantic analysis and foster further research in this direction. – –</p><p>6 0.74113297 <a title="96-lda-6" href="./acl-2012-Post-ordering_by_Parsing_for_Japanese-English_Statistical_Machine_Translation.html">162 acl-2012-Post-ordering by Parsing for Japanese-English Statistical Machine Translation</a></p>
<p>7 0.55763394 <a title="96-lda-7" href="./acl-2012-PORT%3A_a_Precision-Order-Recall_MT_Evaluation_Metric_for_Tuning.html">158 acl-2012-PORT: a Precision-Order-Recall MT Evaluation Metric for Tuning</a></p>
<p>8 0.51377338 <a title="96-lda-8" href="./acl-2012-UWN%3A_A_Large_Multilingual_Lexical_Knowledge_Base.html">206 acl-2012-UWN: A Large Multilingual Lexical Knowledge Base</a></p>
<p>9 0.51303864 <a title="96-lda-9" href="./acl-2012-Learning_to_Translate_with_Multiple_Objectives.html">136 acl-2012-Learning to Translate with Multiple Objectives</a></p>
<p>10 0.5066191 <a title="96-lda-10" href="./acl-2012-Combining_Coherence_Models_and_Machine_Translation_Evaluation_Metrics_for_Summarization_Evaluation.html">52 acl-2012-Combining Coherence Models and Machine Translation Evaluation Metrics for Summarization Evaluation</a></p>
<p>11 0.50012231 <a title="96-lda-11" href="./acl-2012-Character-Level_Machine_Translation_Evaluation_for_Languages_with_Ambiguous_Word_Boundaries.html">46 acl-2012-Character-Level Machine Translation Evaluation for Languages with Ambiguous Word Boundaries</a></p>
<p>12 0.49412197 <a title="96-lda-12" href="./acl-2012-Assessing_the_Effect_of_Inconsistent_Assessors_on_Summarization_Evaluation.html">29 acl-2012-Assessing the Effect of Inconsistent Assessors on Summarization Evaluation</a></p>
<p>13 0.4936249 <a title="96-lda-13" href="./acl-2012-Detecting_Semantic_Equivalence_and_Information_Disparity_in_Cross-lingual_Documents.html">72 acl-2012-Detecting Semantic Equivalence and Information Disparity in Cross-lingual Documents</a></p>
<p>14 0.48025218 <a title="96-lda-14" href="./acl-2012-Verb_Classification_using_Distributional_Similarity_in_Syntactic_and_Semantic_Structures.html">214 acl-2012-Verb Classification using Distributional Similarity in Syntactic and Semantic Structures</a></p>
<p>15 0.47405148 <a title="96-lda-15" href="./acl-2012-LetsMT%21%3A_Cloud-Based_Platform_for_Do-It-Yourself_Machine_Translation.html">138 acl-2012-LetsMT!: Cloud-Based Platform for Do-It-Yourself Machine Translation</a></p>
<p>16 0.47081316 <a title="96-lda-16" href="./acl-2012-Learning_the_Latent_Semantics_of_a_Concept_from_its_Definition.html">132 acl-2012-Learning the Latent Semantics of a Concept from its Definition</a></p>
<p>17 0.46416321 <a title="96-lda-17" href="./acl-2012-langid.py%3A_An_Off-the-shelf_Language_Identification_Tool.html">219 acl-2012-langid.py: An Off-the-shelf Language Identification Tool</a></p>
<p>18 0.46408594 <a title="96-lda-18" href="./acl-2012-Cross-lingual_Parse_Disambiguation_based_on_Semantic_Correspondence.html">63 acl-2012-Cross-lingual Parse Disambiguation based on Semantic Correspondence</a></p>
<p>19 0.45335591 <a title="96-lda-19" href="./acl-2012-Classifying_French_Verbs_Using_French_and_English_Lexical_Resources.html">48 acl-2012-Classifying French Verbs Using French and English Lexical Resources</a></p>
<p>20 0.44923273 <a title="96-lda-20" href="./acl-2012-A_Web-based_Evaluation_Framework_for_Spatial_Instruction-Giving_Systems.html">24 acl-2012-A Web-based Evaluation Framework for Spatial Instruction-Giving Systems</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
