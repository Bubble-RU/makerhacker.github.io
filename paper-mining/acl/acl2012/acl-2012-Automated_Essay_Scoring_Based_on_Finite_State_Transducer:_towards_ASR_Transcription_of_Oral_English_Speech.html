<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>32 acl-2012-Automated Essay Scoring Based on Finite State Transducer: towards ASR Transcription of Oral English Speech</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-32" href="#">acl2012-32</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>32 acl-2012-Automated Essay Scoring Based on Finite State Transducer: towards ASR Transcription of Oral English Speech</h1>
<br/><p>Source: <a title="acl-2012-32-pdf" href="http://aclweb.org/anthology//P/P12/P12-1006.pdf">pdf</a></p><p>Author: Xingyuan Peng ; Dengfeng Ke ; Bo Xu</p><p>Abstract: Conventional Automated Essay Scoring (AES) measures may cause severe problems when directly applied in scoring Automatic Speech Recognition (ASR) transcription as they are error sensitive and unsuitable for the characteristic of ASR transcription. Therefore, we introduce a framework of Finite State Transducer (FST) to avoid the shortcomings. Compared with the Latent Semantic Analysis with Support Vector Regression (LSA-SVR) method (stands for the conventional measures), our FST method shows better performance especially towards the ASR transcription. In addition, we apply the synonyms similarity to expand the FST model. The final scoring performance reaches an acceptable level of 0.80 which is only 0.07 lower than the correlation (0.87) between human raters.</p><p>Reference: <a title="acl-2012-32-reference" href="../acl2012_reference/acl-2012-Automated_Essay_Scoring_Based_on_Finite_State_Transducer%3A_towards_ASR_Transcription_of_Oral_English_Speech_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 cn a  Abstract Conventional Automated Essay Scoring (AES) measures may cause severe problems when directly applied in scoring Automatic Speech Recognition (ASR) transcription as they are error sensitive and unsuitable for the characteristic of ASR transcription. [sent-6, score-0.457]
</p><p>2 The final scoring performance reaches an acceptable level of 0. [sent-10, score-0.136]
</p><p>3 Efforts in speech assessment usually fo50 cus on the integrality, fluency, pronunciation, and prosody (Cucchiarini et al. [sent-18, score-0.093]
</p><p>4 In this paper, our evaluation objects are the oral English picture compositions in English as a Second Language (ESL) examination. [sent-32, score-0.151]
</p><p>5 This examination requires students to talk about four successive pictures with at least five sentences in one minute, and the beginning sentence is given. [sent-33, score-0.233]
</p><p>6 This examination form combines both of the two forms described above. [sent-34, score-0.086]
</p><p>7 Therefore, we need two steps in the scoring task. [sent-35, score-0.111]
</p><p>8 The first step is Automatic Speech Recognition (ASR), in which we get the speech scoring features as well as the textual transcriptions of the speeches. [sent-36, score-0.261]
</p><p>9 Then, the second step could grade the text-free transcription in an (conventional) AES system. [sent-37, score-0.3]
</p><p>10 The present work is mainly about the AES system under the certain situation as the examination grading criterion is more concerned about the integrated con-  tent of the speech (the reason will be given in subsection 3. [sent-38, score-0.358]
</p><p>11 c s 2o0c1ia2ti Aosns fo cria Ctio nm fpourta Ctoiomnpault Laitniognuaislt Licisn,g puaigsteiscs 50–59, applying them in this task will cause two different problems as the scoring objects are the ASR output results. [sent-42, score-0.111]
</p><p>12 The first problem is that the inevitable recognition errors of the ASR will affect the performance of the feature extractions and scoring system. [sent-43, score-0.143]
</p><p>13 Improving the performance of the ASR is not what we concern about, so building an error insensitive AES system is what we care about in this paper. [sent-47, score-0.086]
</p><p>14 The BOW are very useful in measuring the content features and are usually robust even if there are some errors in the scoring transcription. [sent-50, score-0.166]
</p><p>15 It means that more meaningless parts of the oral speeches would be recognized as the words quite related to the topic content. [sent-53, score-0.133]
</p><p>16 As the evaluating objects are from an oral English picture composition examination, it has two important features that make the FST algorithm quite suitable. [sent-57, score-0.234]
</p><p>17 •  The sentences for describing the same picture are very eindecnesti fcaolr dine expression, so thee preic tisu a hierarchy between the word sequences in the 51 sentences (the expression) and the sense for the same picture. [sent-59, score-0.094]
</p><p>18 It is very useful in expressing the sequences and the hierarchy in picture composition. [sent-61, score-0.094]
</p><p>19 Therefore, we build a FST-based model to extract features related to the transcription assessment in this paper. [sent-62, score-0.379]
</p><p>20 In a word, the FST model can not only be  insensitive to the recognition error in the ASR system, but also remedy the weakness ofBOW methods in ASR result scoring. [sent-67, score-0.087]
</p><p>21 The details ofthe speech corpus and the examination grading criterion are introduced in section 3. [sent-69, score-0.286]
</p><p>22 2  Related Work  Conventional AES systems usually exploit textual features to assess the quality of writing mainly in three different facets: the content facet, the arrangement facet and the language usage facet. [sent-73, score-0.172]
</p><p>23 In the content facet, many existing BOW techniques have been applied, such as the content vector analysis (Attaliand Burstein, 2006; Attali, 2011) and the LSA to reduce the dimension of content vector (Landauer et al. [sent-74, score-0.163]
</p><p>24 The cosine similarity is one of the most common used similarity measures (Landauer et al. [sent-84, score-0.112]
</p><p>25 Also, the regression or the classification method is a good choice for scoring (Rudner and Liang, 2002; Peng et al. [sent-86, score-0.111]
</p><p>26 The rank preference techniques show excellent performance in grading essays (Yannakoudakis et al. [sent-88, score-0.135]
</p><p>27 In the LSA-SVR method, each essay transcription is represented by a latent semantic space vector, which is regarded as the features in the SVR model. [sent-94, score-0.463]
</p><p>28 , 1990) considers the relations between the dimensions in conventional vector space model (VSM) (Salton et al. [sent-96, score-0.09]
</p><p>29 Each test transcription represented by the LSS vector can be scored by the model. [sent-101, score-0.335]
</p><p>30 Our experimental data is acquired in an oral English examination for ESL students. [sent-103, score-0.165]
</p><p>31 45 Table 2: WER and MR of ASR result classes of students participated in the exam and 417 valid speeches are obtained in the examination. [sent-112, score-0.1]
</p><p>32 As the paper mainly focuses on scoring the text transcriptions, we have two ways to obtain them. [sent-113, score-0.141]
</p><p>33 One is manually typing the text transcriptions which we regarded as the Correct Recognition Result (CRR) transcription, and another is the ASR result which we named ASR transcription. [sent-114, score-0.088]
</p><p>34 A better understanding of the difference in the CRR transcription and the ASR  transcription from the low score to the high score is shown in Table 2, where WER is the word error rate and MR is the match rate which is the words’ correct rate. [sent-118, score-0.73]
</p><p>35 1 Criterion of Grading According to the Grading Criterion of the examination, the score of the examination ranges from 0 to 20, and the grading score is divided into 7 levels with 3 points’ interval for each level. [sent-120, score-0.195]
</p><p>36 The criterion mainly concerns about two facets of the speech: the acoustic level and the content integrity. [sent-121, score-0.154]
</p><p>37 The acoustic level only works well in excellent speeches (Huang et al. [sent-124, score-0.094]
</p><p>38 The Open Correlation (OC) is the correlation between human rater scores and the final scores, which are not related to the human scores themselves (average of the other two scores). [sent-147, score-0.122]
</p><p>39 As most students are supposed to pass the examination, the expert scores are mostly distributed above 12 points, as shown in Figure 1. [sent-148, score-0.112]
</p><p>40 4  Approach  The approach used in this paper is to build a standard FST for the current examination topic. [sent-150, score-0.086]
</p><p>41 The automated machine score is computed from the features at last. [sent-153, score-0.097]
</p><p>42 According to the characteristics of the  picture composition examination, each composition can be held as an orderly combination of the senses of pictures. [sent-162, score-0.19]
</p><p>43 We define a sense-group as one sentence either describing the same one or two pictures or elaborating on the same pictures. [sent-164, score-0.123]
</p><p>44 The first given sentence in the examination is labeled with 0m and the other describing sentences for the 1to 4 pictures are labeled with 1m to 4m, while the elaboration ones for the 4 pictures are labeled with 1s to 4s. [sent-166, score-0.404]
</p><p>45 For the entire 417 CRR transcriptions, we manually labeled 274 transcriptions whose scores are higher than 15 points. [sent-168, score-0.14]
</p><p>46 There are 1679 sentences in the 274 CRR  Figure 3: FST Building transcriptions and 1667 are labeled in the eight symbols. [sent-173, score-0.112]
</p><p>47 2 FST Building In this paper, we build three types of FST to extract scoring features with the help of openFST tool (Allauzen et al. [sent-175, score-0.135]
</p><p>48 The sense-group FST can describe all the possible proper sense-group sequences of the current picture composition topic. [sent-181, score-0.153]
</p><p>49 We use manually labeled corpus, which are the sequences of sense-groups of the CRR transcriptions with expert scores higher than 15 points, to build the sensegroup FST. [sent-183, score-0.272]
</p><p>50 In the process, each CRR transcription sense-group sequence is a simple sense-group FST. [sent-184, score-0.326]
</p><p>51 Later, we unite these sense-group FSTs to get the final FST which considers every situation of sensegroup sequences in the train corpus. [sent-185, score-0.122]
</p><p>52 Meanwhile, it can transform the word sequence into the sense-group label sequence which is very useful in extracting the scoring features (details will be presented in subsection 4. [sent-196, score-0.229]
</p><p>53 Here, we apply the edit distance to measure how best the path is. [sent-204, score-0.182]
</p><p>54 This means the best path is the word sequence path in the FST which has the smallest edit distance compared with the to-be-scored transcription’s word sequences . [sent-205, score-0.298]
</p><p>55 The best path can be described as  path = aaprlaglptmaht∈ihnEDcost(path,transcription) EDcost = ins + del + sub  (1) (2)  EDcost is the edit distance from the transcription to the paths which start at state 0 and end at the end  Figure 4: Search the Best Path in the FST by DP state. [sent-208, score-0.579]
</p><p>56 ,Xp−1  (3) The minEDcost(j) is the accumulated minimum edit distance from state 0 to state j, and the cost(i,j) is the cost of insertion, deletion or substitution from s-  tate j to state i. [sent-212, score-0.234]
</p><p>57 bIne phrase p, we compute tXhe best path a}n idn its edit distance from the transcription for all the tobe-calculated states which is the Xp shown in Figure 4. [sent-218, score-0.482]
</p><p>58 After computing all the phrases, the best path and its edit distances of the end states are obtained. [sent-219, score-0.143]
</p><p>59 Then the final best path is the one with the smallest edit distance. [sent-220, score-0.168]
</p><p>60 4 Feature Extraction After building the FST and finding the best path for the to-be-scored transcription, we can extract some effective features from the path information and the transcription. [sent-222, score-0.191]
</p><p>61 Inspired by the similarity scoring measures, our proposed features represent the similarity between the best path’s word sequence and the to-be-scored transcription. [sent-223, score-0.273]
</p><p>62 The features used for the scoring model are as follows: • The Edit Distance (ED): The edit distance is the linear combination of  the weights of insertion, deletion and substitution. [sent-224, score-0.249]
</p><p>63 NEDcost = EDcost/length (4) The Match Number(MN): The match number is the number of words matched between the best path and the transcription. [sent-228, score-0.126]
</p><p>64 The Match Rate(MR): The match rate is the match number normalized with the transcription’s length. [sent-229, score-0.141]
</p><p>65 MR = MN/length (5) The Continuous Match Value(CMV): Continuous match should be better than the  fragmentary match, so a higher value is given for the continuous situation. [sent-230, score-0.087]
</p><p>66 CMV = XOM + 2XSM + 3XLM (6)  •  •  where OMX X(One MatXch) is the fXragmentary match number, SM (Short Match) is the continuous match number which is no more than 4, and LM (Long Match) is the continuous match number which is more than 4. [sent-231, score-0.232]
</p><p>67 Length is always a very effective feature in essay scoring (Attali and Burstein, 2006). [sent-233, score-0.25]
</p><p>68 The match rate of each sense-group can be regarded as one feature so that all the sensegroup match rate in the transcription will be combined to a feature vector (called the Sensegroup Match Rate vector (SMRv)), which is  an 8-dimensional vector in the present experiments. [sent-236, score-0.621]
</p><p>69 After that, we applied the SVR algorithm to train a sense-group scoring model with the vectors and scores, and the transcription gets its SSF from the model. [sent-237, score-0.411]
</p><p>70 5 Extend the FST model with the similarity of synonym Because the FST is trained from the limited corpus, it does not contain all the possible situations proper for the current composition topic. [sent-239, score-0.142]
</p><p>71 The extension of the FST model is mainly reflected in calculation of the edit distance of the best path. [sent-241, score-0.144]
</p><p>72 The previous edit distance, in equation (2), refers to the Levenshtein distance in which the insertions, deletions and substitutions have equal cost, but in the edit distance in this section, the cost of substitutions is less than that of insertions and deletions. [sent-242, score-0.347]
</p><p>73 Here, we assume that the cost of substitutions is based on the similarity of the two words. [sent-243, score-0.132]
</p><p>74 Then with the help of different cost of substitutions, each word edge is extended to some of its synonym word edges  ×  under the cost of similarity. [sent-244, score-0.093]
</p><p>75 The new edit distance is calculated by equation (7) as follows: EDcost = ins + del + sub  (1 − sim)  (7)  where, sim is the similarity of two words. [sent-245, score-0.17]
</p><p>76 With the help of manual typing and the ASR system, 417 CRR transcriptions and 417 ASR transcriptions are obtained from the speeches after preprocessing 56 FSTSVRSVRCRRASR build train test transcription transcription  SSeett23SSeett32Set100. [sent-256, score-0.83]
</p><p>77 The FST building only uses the CRR transcriptions whose expert scores are higher  than 15 points. [sent-267, score-0.207]
</p><p>78 Also, we presented the result of using LSA-SVR approach as a contrast experiment to show the improvement of our FST model in scoring oral English picture composition. [sent-272, score-0.262]
</p><p>79 To quantitatively assess the effectiveness of the methods, the Pearson correlation between the expert scores and the automated results is adopted as the performance measure. [sent-273, score-0.202]
</p><p>80 2  Correlation of Features  The correlations between the seven features and the final expert scores are shown in Tables 4 and 5 on the three sets. [sent-275, score-0.167]
</p><p>81 When scoring the speech, human raters concern more about how much valid information it contains and irrelevant contents are not taken for penalty. [sent-278, score-0.139]
</p><p>82 Therefore, the match features are more reasonable than the edit distance features. [sent-279, score-0.196]
</p><p>83 The decline of it in different transcriptions is mainly because of the ASR error. [sent-367, score-0.168]
</p><p>84 We use the linear regression to combine these 12 features to the final automated score. [sent-373, score-0.122]
</p><p>85 After the weight of each feature and the linear bias are gained, we calculate the automated score of each transcription by the FST features. [sent-375, score-0.373]
</p><p>86 However, the increase is not significant in the AS-  R transcription (shown in Table 7). [sent-404, score-0.3]
</p><p>87 The performance correlation of our FST model in the CRR transcription is about 0. [sent-407, score-0.341]
</p><p>88 Even though the performance correlation in the ASR transcription declines compared with that in the CRR transcription, the FST methods still perform very well under the current recognition errors of the ARS system. [sent-409, score-0.398]
</p><p>89 In regular text essay scoring, the BOW algorithm can have excellent performance. [sent-412, score-0.139]
</p><p>90 However, in certain situations, such as towards ASR transcription of oral English speech, its weakness of sequence neglect will be magnified, leading to drastic decline of performance. [sent-413, score-0.455]
</p><p>91 It is an error insensitive model under the task of automated oral English picture  composition scoring. [sent-415, score-0.338]
</p><p>92 As we expected, the performance of the FST model is more outstanding than that of the BOW metrics in CRR transcription, and the decline of performance is acceptable in ASR transcription scoring. [sent-417, score-0.375]
</p><p>93 Second, as the task is speech evaluation, considering the acoustic features may give more information to the automated scoring system. [sent-422, score-0.286]
</p><p>94 Therefore, the features at the acoustic level could be introduced to complete the scoring model. [sent-423, score-0.175]
</p><p>95 Third, the decline of the  performance in ASR transcription is derived from the recognition error of ASR system. [sent-424, score-0.404]
</p><p>96 Therefore, improving the performance of the ASR system or making full use of the N-best lists may give more accurate transcription for the AES system. [sent-425, score-0.3]
</p><p>97 A differential word use measure for content analysis in automated essay scoring. [sent-436, score-0.243]
</p><p>98 Quantitative assessment of second language learners’ fluency by means of automatic speech recognition technology. [sent-462, score-0.125]
</p><p>99 Automated Chinese essay scoring using 59 In Proceedings of IUCS, 149-  vector space models. [sent-515, score-0.285]
</p><p>100 A new dataset and method for automatically grading ESOL texts. [sent-546, score-0.109]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('fst', 0.608), ('asr', 0.385), ('transcription', 0.3), ('crr', 0.262), ('essay', 0.139), ('pictures', 0.123), ('aes', 0.121), ('scoring', 0.111), ('grading', 0.109), ('attali', 0.1), ('bow', 0.093), ('transcriptions', 0.088), ('svr', 0.087), ('burstein', 0.087), ('examination', 0.086), ('mr', 0.084), ('oral', 0.079), ('edit', 0.075), ('ssf', 0.075), ('automated', 0.073), ('picture', 0.072), ('path', 0.068), ('cmv', 0.062), ('ishioka', 0.062), ('expert', 0.06), ('ned', 0.06), ('composition', 0.059), ('match', 0.058), ('similarity', 0.056), ('conventional', 0.055), ('assessment', 0.055), ('facet', 0.054), ('fsts', 0.054), ('speeches', 0.054), ('criterion', 0.053), ('landauer', 0.05), ('kameda', 0.05), ('minedcost', 0.05), ('sensegroup', 0.05), ('sseet', 0.05), ('decline', 0.05), ('substitutions', 0.043), ('subsection', 0.042), ('correlation', 0.041), ('peng', 0.04), ('acoustic', 0.04), ('distance', 0.039), ('speech', 0.038), ('edcost', 0.037), ('htk', 0.037), ('kakkonen', 0.037), ('lss', 0.037), ('persing', 0.037), ('sensegroups', 0.037), ('xingyuan', 0.037), ('vector', 0.035), ('wer', 0.033), ('insensitive', 0.033), ('yannakoudakis', 0.033), ('arrangement', 0.033), ('cost', 0.033), ('recognition', 0.032), ('building', 0.031), ('mn', 0.031), ('content', 0.031), ('correlations', 0.03), ('mainly', 0.03), ('transducer', 0.03), ('continuous', 0.029), ('state', 0.029), ('scores', 0.028), ('openfst', 0.028), ('raters', 0.028), ('synonym', 0.027), ('essays', 0.026), ('sequence', 0.026), ('final', 0.025), ('rate', 0.025), ('cucchiarini', 0.025), ('declines', 0.025), ('dengfeng', 0.025), ('determinize', 0.025), ('lonsdale', 0.025), ('neumeyer', 0.025), ('outstanding', 0.025), ('rudner', 0.025), ('unite', 0.025), ('yigal', 0.025), ('students', 0.024), ('labeled', 0.024), ('esl', 0.024), ('features', 0.024), ('characteristic', 0.024), ('error', 0.022), ('sequences', 0.022), ('ed', 0.022), ('jill', 0.022), ('ets', 0.022), ('exam', 0.022), ('maier', 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="32-tfidf-1" href="./acl-2012-Automated_Essay_Scoring_Based_on_Finite_State_Transducer%3A_towards_ASR_Transcription_of_Oral_English_Speech.html">32 acl-2012-Automated Essay Scoring Based on Finite State Transducer: towards ASR Transcription of Oral English Speech</a></p>
<p>Author: Xingyuan Peng ; Dengfeng Ke ; Bo Xu</p><p>Abstract: Conventional Automated Essay Scoring (AES) measures may cause severe problems when directly applied in scoring Automatic Speech Recognition (ASR) transcription as they are error sensitive and unsuitable for the characteristic of ASR transcription. Therefore, we introduce a framework of Finite State Transducer (FST) to avoid the shortcomings. Compared with the Latent Semantic Analysis with Support Vector Regression (LSA-SVR) method (stands for the conventional measures), our FST method shows better performance especially towards the ASR transcription. In addition, we apply the synonyms similarity to expand the FST model. The final scoring performance reaches an acceptable level of 0.80 which is only 0.07 lower than the correlation (0.87) between human raters.</p><p>2 0.1343527 <a title="32-tfidf-2" href="./acl-2012-Fast_Syntactic_Analysis_for_Statistical_Language_Modeling_via_Substructure_Sharing_and_Uptraining.html">95 acl-2012-Fast Syntactic Analysis for Statistical Language Modeling via Substructure Sharing and Uptraining</a></p>
<p>Author: Ariya Rastrow ; Mark Dredze ; Sanjeev Khudanpur</p><p>Abstract: Long-span features, such as syntax, can improve language models for tasks such as speech recognition and machine translation. However, these language models can be difficult to use in practice because of the time required to generate features for rescoring a large hypothesis set. In this work, we propose substructure sharing, which saves duplicate work in processing hypothesis sets with redundant hypothesis structures. We apply substructure sharing to a dependency parser and part of speech tagger to obtain significant speedups, and further improve the accuracy of these tools through up-training. When using these improved tools in a language model for speech recognition, we obtain significant speed improvements with both N-best and hill climbing rescoring, and show that up-training leads to WER reduction.</p><p>3 0.10528067 <a title="32-tfidf-3" href="./acl-2012-Probabilistic_Integration_of_Partial_Lexical_Information_for_Noise_Robust_Haptic_Voice_Recognition.html">165 acl-2012-Probabilistic Integration of Partial Lexical Information for Noise Robust Haptic Voice Recognition</a></p>
<p>Author: Khe Chai Sim</p><p>Abstract: This paper presents a probabilistic framework that combines multiple knowledge sources for Haptic Voice Recognition (HVR), a multimodal input method designed to provide efficient text entry on modern mobile devices. HVR extends the conventional voice input by allowing users to provide complementary partial lexical information via touch input to improve the efficiency and accuracy of voice recognition. This paper investigates the use of the initial letter of the words in the utterance as the partial lexical information. In addition to the acoustic and language models used in automatic speech recognition systems, HVR uses the haptic and partial lexical models as additional knowledge sources to reduce the recognition search space and suppress confusions. Experimental results show that both the word error rate and runtime factor can be re- duced by a factor of two using HVR.</p><p>4 0.10479038 <a title="32-tfidf-4" href="./acl-2012-The_OpenGrm_open-source_finite-state_grammar_software_libraries.html">196 acl-2012-The OpenGrm open-source finite-state grammar software libraries</a></p>
<p>Author: Brian Roark ; Richard Sproat ; Cyril Allauzen ; Michael Riley ; Jeffrey Sorensen ; Terry Tai</p><p>Abstract: In this paper, we present a new collection of open-source software libraries that provides command line binary utilities and library classes and functions for compiling regular expression and context-sensitive rewrite rules into finite-state transducers, and for n-gram language modeling. The OpenGrm libraries use the OpenFst library to provide an efficient encoding of grammars and general algorithms for building, modifying and applying models.</p><p>5 0.076345257 <a title="32-tfidf-5" href="./acl-2012-Semantic_Parsing_with_Bayesian_Tree_Transducers.html">174 acl-2012-Semantic Parsing with Bayesian Tree Transducers</a></p>
<p>Author: Bevan Jones ; Mark Johnson ; Sharon Goldwater</p><p>Abstract: Many semantic parsing models use tree transformations to map between natural language and meaning representation. However, while tree transformations are central to several state-of-the-art approaches, little use has been made of the rich literature on tree automata. This paper makes the connection concrete with a tree transducer based semantic parsing model and suggests that other models can be interpreted in a similar framework, increasing the generality of their contributions. In particular, this paper further introduces a variational Bayesian inference algorithm that is applicable to a wide class of tree transducers, producing state-of-the-art semantic parsing results while remaining applicable to any domain employing probabilistic tree transducers.</p><p>6 0.070829347 <a title="32-tfidf-6" href="./acl-2012-A_Corpus_of_Textual_Revisions_in_Second_Language_Writing.html">8 acl-2012-A Corpus of Textual Revisions in Second Language Writing</a></p>
<p>7 0.054180186 <a title="32-tfidf-7" href="./acl-2012-Bootstrapping_a_Unified_Model_of_Lexical_and_Phonetic_Acquisition.html">41 acl-2012-Bootstrapping a Unified Model of Lexical and Phonetic Acquisition</a></p>
<p>8 0.052008472 <a title="32-tfidf-8" href="./acl-2012-Collective_Generation_of_Natural_Image_Descriptions.html">51 acl-2012-Collective Generation of Natural Image Descriptions</a></p>
<p>9 0.045141514 <a title="32-tfidf-9" href="./acl-2012-Discriminative_Pronunciation_Modeling%3A_A_Large-Margin%2C_Feature-Rich_Approach.html">74 acl-2012-Discriminative Pronunciation Modeling: A Large-Margin, Feature-Rich Approach</a></p>
<p>10 0.044140048 <a title="32-tfidf-10" href="./acl-2012-A_Nonparametric_Bayesian_Approach_to_Acoustic_Model_Discovery.html">16 acl-2012-A Nonparametric Bayesian Approach to Acoustic Model Discovery</a></p>
<p>11 0.039553121 <a title="32-tfidf-11" href="./acl-2012-How_Are_Spelling_Errors_Generated_and_Corrected%3F_A_Study_of_Corrected_and_Uncorrected_Spelling_Errors_Using_Keystroke_Logs.html">111 acl-2012-How Are Spelling Errors Generated and Corrected? A Study of Corrected and Uncorrected Spelling Errors Using Keystroke Logs</a></p>
<p>12 0.039345164 <a title="32-tfidf-12" href="./acl-2012-Computational_Approaches_to_Sentence_Completion.html">56 acl-2012-Computational Approaches to Sentence Completion</a></p>
<p>13 0.038884081 <a title="32-tfidf-13" href="./acl-2012-Deciphering_Foreign_Language_by_Combining_Language_Models_and_Context_Vectors.html">67 acl-2012-Deciphering Foreign Language by Combining Language Models and Context Vectors</a></p>
<p>14 0.038353652 <a title="32-tfidf-14" href="./acl-2012-Unsupervised_Relation_Discovery_with_Sense_Disambiguation.html">208 acl-2012-Unsupervised Relation Discovery with Sense Disambiguation</a></p>
<p>15 0.038317863 <a title="32-tfidf-15" href="./acl-2012-Efficient_Search_for_Transformation-based_Inference.html">78 acl-2012-Efficient Search for Transformation-based Inference</a></p>
<p>16 0.035940036 <a title="32-tfidf-16" href="./acl-2012-Modeling_Sentences_in_the_Latent_Space.html">145 acl-2012-Modeling Sentences in the Latent Space</a></p>
<p>17 0.035427883 <a title="32-tfidf-17" href="./acl-2012-Improving_Word_Representations_via_Global_Context_and_Multiple_Word_Prototypes.html">117 acl-2012-Improving Word Representations via Global Context and Multiple Word Prototypes</a></p>
<p>18 0.035388067 <a title="32-tfidf-18" href="./acl-2012-Grammar_Error_Correction_Using_Pseudo-Error_Sentences_and_Domain_Adaptation.html">103 acl-2012-Grammar Error Correction Using Pseudo-Error Sentences and Domain Adaptation</a></p>
<p>19 0.03482547 <a title="32-tfidf-19" href="./acl-2012-Tense_and_Aspect_Error_Correction_for_ESL_Learners_Using_Global_Context.html">192 acl-2012-Tense and Aspect Error Correction for ESL Learners Using Global Context</a></p>
<p>20 0.034809686 <a title="32-tfidf-20" href="./acl-2012-Syntactic_Stylometry_for_Deception_Detection.html">190 acl-2012-Syntactic Stylometry for Deception Detection</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.112), (1, 0.021), (2, -0.022), (3, 0.0), (4, -0.023), (5, 0.068), (6, 0.013), (7, 0.022), (8, -0.015), (9, -0.006), (10, -0.047), (11, 0.009), (12, -0.021), (13, 0.054), (14, -0.019), (15, -0.016), (16, 0.07), (17, 0.01), (18, 0.032), (19, -0.006), (20, 0.035), (21, -0.173), (22, -0.007), (23, -0.038), (24, -0.121), (25, 0.008), (26, 0.157), (27, 0.061), (28, 0.005), (29, 0.041), (30, 0.083), (31, -0.04), (32, -0.083), (33, -0.01), (34, -0.091), (35, 0.033), (36, -0.154), (37, 0.093), (38, 0.281), (39, 0.162), (40, 0.074), (41, -0.134), (42, -0.007), (43, -0.013), (44, 0.196), (45, -0.059), (46, 0.008), (47, 0.028), (48, -0.07), (49, 0.084)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92952996 <a title="32-lsi-1" href="./acl-2012-Automated_Essay_Scoring_Based_on_Finite_State_Transducer%3A_towards_ASR_Transcription_of_Oral_English_Speech.html">32 acl-2012-Automated Essay Scoring Based on Finite State Transducer: towards ASR Transcription of Oral English Speech</a></p>
<p>Author: Xingyuan Peng ; Dengfeng Ke ; Bo Xu</p><p>Abstract: Conventional Automated Essay Scoring (AES) measures may cause severe problems when directly applied in scoring Automatic Speech Recognition (ASR) transcription as they are error sensitive and unsuitable for the characteristic of ASR transcription. Therefore, we introduce a framework of Finite State Transducer (FST) to avoid the shortcomings. Compared with the Latent Semantic Analysis with Support Vector Regression (LSA-SVR) method (stands for the conventional measures), our FST method shows better performance especially towards the ASR transcription. In addition, we apply the synonyms similarity to expand the FST model. The final scoring performance reaches an acceptable level of 0.80 which is only 0.07 lower than the correlation (0.87) between human raters.</p><p>2 0.75092292 <a title="32-lsi-2" href="./acl-2012-Probabilistic_Integration_of_Partial_Lexical_Information_for_Noise_Robust_Haptic_Voice_Recognition.html">165 acl-2012-Probabilistic Integration of Partial Lexical Information for Noise Robust Haptic Voice Recognition</a></p>
<p>Author: Khe Chai Sim</p><p>Abstract: This paper presents a probabilistic framework that combines multiple knowledge sources for Haptic Voice Recognition (HVR), a multimodal input method designed to provide efficient text entry on modern mobile devices. HVR extends the conventional voice input by allowing users to provide complementary partial lexical information via touch input to improve the efficiency and accuracy of voice recognition. This paper investigates the use of the initial letter of the words in the utterance as the partial lexical information. In addition to the acoustic and language models used in automatic speech recognition systems, HVR uses the haptic and partial lexical models as additional knowledge sources to reduce the recognition search space and suppress confusions. Experimental results show that both the word error rate and runtime factor can be re- duced by a factor of two using HVR.</p><p>3 0.70273066 <a title="32-lsi-3" href="./acl-2012-The_OpenGrm_open-source_finite-state_grammar_software_libraries.html">196 acl-2012-The OpenGrm open-source finite-state grammar software libraries</a></p>
<p>Author: Brian Roark ; Richard Sproat ; Cyril Allauzen ; Michael Riley ; Jeffrey Sorensen ; Terry Tai</p><p>Abstract: In this paper, we present a new collection of open-source software libraries that provides command line binary utilities and library classes and functions for compiling regular expression and context-sensitive rewrite rules into finite-state transducers, and for n-gram language modeling. The OpenGrm libraries use the OpenFst library to provide an efficient encoding of grammars and general algorithms for building, modifying and applying models.</p><p>4 0.47791114 <a title="32-lsi-4" href="./acl-2012-Fast_Syntactic_Analysis_for_Statistical_Language_Modeling_via_Substructure_Sharing_and_Uptraining.html">95 acl-2012-Fast Syntactic Analysis for Statistical Language Modeling via Substructure Sharing and Uptraining</a></p>
<p>Author: Ariya Rastrow ; Mark Dredze ; Sanjeev Khudanpur</p><p>Abstract: Long-span features, such as syntax, can improve language models for tasks such as speech recognition and machine translation. However, these language models can be difficult to use in practice because of the time required to generate features for rescoring a large hypothesis set. In this work, we propose substructure sharing, which saves duplicate work in processing hypothesis sets with redundant hypothesis structures. We apply substructure sharing to a dependency parser and part of speech tagger to obtain significant speedups, and further improve the accuracy of these tools through up-training. When using these improved tools in a language model for speech recognition, we obtain significant speed improvements with both N-best and hill climbing rescoring, and show that up-training leads to WER reduction.</p><p>5 0.33568251 <a title="32-lsi-5" href="./acl-2012-A_Corpus_of_Textual_Revisions_in_Second_Language_Writing.html">8 acl-2012-A Corpus of Textual Revisions in Second Language Writing</a></p>
<p>Author: John Lee ; Jonathan Webster</p><p>Abstract: This paper describes the creation of the first large-scale corpus containing drafts and final versions of essays written by non-native speakers, with the sentences aligned across different versions. Furthermore, the sentences in the drafts are annotated with comments from teachers. The corpus is intended to support research on textual revision by language learners, and how it is influenced by feedback. This corpus has been converted into an XML format conforming to the standards of the Text Encoding Initiative (TEI).</p><p>6 0.32801422 <a title="32-lsi-6" href="./acl-2012-Bootstrapping_a_Unified_Model_of_Lexical_and_Phonetic_Acquisition.html">41 acl-2012-Bootstrapping a Unified Model of Lexical and Phonetic Acquisition</a></p>
<p>7 0.32617542 <a title="32-lsi-7" href="./acl-2012-Semantic_Parsing_with_Bayesian_Tree_Transducers.html">174 acl-2012-Semantic Parsing with Bayesian Tree Transducers</a></p>
<p>8 0.28444079 <a title="32-lsi-8" href="./acl-2012-Computational_Approaches_to_Sentence_Completion.html">56 acl-2012-Computational Approaches to Sentence Completion</a></p>
<p>9 0.28213885 <a title="32-lsi-9" href="./acl-2012-A_Nonparametric_Bayesian_Approach_to_Acoustic_Model_Discovery.html">16 acl-2012-A Nonparametric Bayesian Approach to Acoustic Model Discovery</a></p>
<p>10 0.28103036 <a title="32-lsi-10" href="./acl-2012-How_Are_Spelling_Errors_Generated_and_Corrected%3F_A_Study_of_Corrected_and_Uncorrected_Spelling_Errors_Using_Keystroke_Logs.html">111 acl-2012-How Are Spelling Errors Generated and Corrected? A Study of Corrected and Uncorrected Spelling Errors Using Keystroke Logs</a></p>
<p>11 0.27080724 <a title="32-lsi-11" href="./acl-2012-Discriminative_Pronunciation_Modeling%3A_A_Large-Margin%2C_Feature-Rich_Approach.html">74 acl-2012-Discriminative Pronunciation Modeling: A Large-Margin, Feature-Rich Approach</a></p>
<p>12 0.26704544 <a title="32-lsi-12" href="./acl-2012-Automatically_Learning_Measures_of_Child_Language_Development.html">34 acl-2012-Automatically Learning Measures of Child Language Development</a></p>
<p>13 0.25567573 <a title="32-lsi-13" href="./acl-2012-Sentence_Simplification_by_Monolingual_Machine_Translation.html">178 acl-2012-Sentence Simplification by Monolingual Machine Translation</a></p>
<p>14 0.25334248 <a title="32-lsi-14" href="./acl-2012-A_Graphical_Interface_for_MT_Evaluation_and_Error_Analysis.html">13 acl-2012-A Graphical Interface for MT Evaluation and Error Analysis</a></p>
<p>15 0.24967358 <a title="32-lsi-15" href="./acl-2012-Modeling_Sentences_in_the_Latent_Space.html">145 acl-2012-Modeling Sentences in the Latent Space</a></p>
<p>16 0.24266207 <a title="32-lsi-16" href="./acl-2012-Demonstration_of_IlluMe%3A_Creating_Ambient_According_to_Instant_Message_Logs.html">70 acl-2012-Demonstration of IlluMe: Creating Ambient According to Instant Message Logs</a></p>
<p>17 0.24249837 <a title="32-lsi-17" href="./acl-2012-Improving_Word_Representations_via_Global_Context_and_Multiple_Word_Prototypes.html">117 acl-2012-Improving Word Representations via Global Context and Multiple Word Prototypes</a></p>
<p>18 0.2331719 <a title="32-lsi-18" href="./acl-2012-Deciphering_Foreign_Language_by_Combining_Language_Models_and_Context_Vectors.html">67 acl-2012-Deciphering Foreign Language by Combining Language Models and Context Vectors</a></p>
<p>19 0.23315799 <a title="32-lsi-19" href="./acl-2012-Fast_and_Scalable_Decoding_with_Language_Model_Look-Ahead_for_Phrase-based_Statistical_Machine_Translation.html">97 acl-2012-Fast and Scalable Decoding with Language Model Look-Ahead for Phrase-based Statistical Machine Translation</a></p>
<p>20 0.23024115 <a title="32-lsi-20" href="./acl-2012-A_Broad-Coverage_Normalization_System_for_Social_Media_Language.html">2 acl-2012-A Broad-Coverage Normalization System for Social Media Language</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(25, 0.027), (26, 0.032), (28, 0.032), (30, 0.028), (37, 0.028), (39, 0.048), (59, 0.023), (74, 0.038), (82, 0.023), (84, 0.033), (85, 0.039), (86, 0.362), (90, 0.085), (92, 0.055), (94, 0.023), (99, 0.037)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.69728309 <a title="32-lda-1" href="./acl-2012-Automated_Essay_Scoring_Based_on_Finite_State_Transducer%3A_towards_ASR_Transcription_of_Oral_English_Speech.html">32 acl-2012-Automated Essay Scoring Based on Finite State Transducer: towards ASR Transcription of Oral English Speech</a></p>
<p>Author: Xingyuan Peng ; Dengfeng Ke ; Bo Xu</p><p>Abstract: Conventional Automated Essay Scoring (AES) measures may cause severe problems when directly applied in scoring Automatic Speech Recognition (ASR) transcription as they are error sensitive and unsuitable for the characteristic of ASR transcription. Therefore, we introduce a framework of Finite State Transducer (FST) to avoid the shortcomings. Compared with the Latent Semantic Analysis with Support Vector Regression (LSA-SVR) method (stands for the conventional measures), our FST method shows better performance especially towards the ASR transcription. In addition, we apply the synonyms similarity to expand the FST model. The final scoring performance reaches an acceptable level of 0.80 which is only 0.07 lower than the correlation (0.87) between human raters.</p><p>2 0.66027045 <a title="32-lda-2" href="./acl-2012-Event_Linking%3A_Grounding_Event_Reference_in_a_News_Archive.html">85 acl-2012-Event Linking: Grounding Event Reference in a News Archive</a></p>
<p>Author: Joel Nothman ; Matthew Honnibal ; Ben Hachey ; James R. Curran</p><p>Abstract: Interpreting news requires identifying its constituent events. Events are complex linguistically and ontologically, so disambiguating their reference is challenging. We introduce event linking, which canonically labels an event reference with the article where it was first reported. This implicitly relaxes coreference to co-reporting, and will practically enable augmenting news archives with semantic hyperlinks. We annotate and analyse a corpus of 150 documents, extracting 501 links to a news archive with reasonable inter-annotator agreement.</p><p>3 0.60054064 <a title="32-lda-3" href="./acl-2012-Detecting_Semantic_Equivalence_and_Information_Disparity_in_Cross-lingual_Documents.html">72 acl-2012-Detecting Semantic Equivalence and Information Disparity in Cross-lingual Documents</a></p>
<p>Author: Yashar Mehdad ; Matteo Negri ; Marcello Federico</p><p>Abstract: We address a core aspect of the multilingual content synchronization task: the identification of novel, more informative or semantically equivalent pieces of information in two documents about the same topic. This can be seen as an application-oriented variant of textual entailment recognition where: i) T and H are in different languages, and ii) entailment relations between T and H have to be checked in both directions. Using a combination of lexical, syntactic, and semantic features to train a cross-lingual textual entailment system, we report promising results on different datasets.</p><p>4 0.43623373 <a title="32-lda-4" href="./acl-2012-Multilingual_Named_Entity_Recognition_using_Parallel_Data_and_Metadata_from_Wikipedia.html">150 acl-2012-Multilingual Named Entity Recognition using Parallel Data and Metadata from Wikipedia</a></p>
<p>Author: Sungchul Kim ; Kristina Toutanova ; Hwanjo Yu</p><p>Abstract: In this paper we propose a method to automatically label multi-lingual data with named entity tags. We build on prior work utilizing Wikipedia metadata and show how to effectively combine the weak annotations stemming from Wikipedia metadata with information obtained through English-foreign language parallel Wikipedia sentences. The combination is achieved using a novel semi-CRF model for foreign sentence tagging in the context of a parallel English sentence. The model outperforms both standard annotation projection methods and methods based solely on Wikipedia metadata.</p><p>5 0.35371956 <a title="32-lda-5" href="./acl-2012-Semantic_Parsing_with_Bayesian_Tree_Transducers.html">174 acl-2012-Semantic Parsing with Bayesian Tree Transducers</a></p>
<p>Author: Bevan Jones ; Mark Johnson ; Sharon Goldwater</p><p>Abstract: Many semantic parsing models use tree transformations to map between natural language and meaning representation. However, while tree transformations are central to several state-of-the-art approaches, little use has been made of the rich literature on tree automata. This paper makes the connection concrete with a tree transducer based semantic parsing model and suggests that other models can be interpreted in a similar framework, increasing the generality of their contributions. In particular, this paper further introduces a variational Bayesian inference algorithm that is applicable to a wide class of tree transducers, producing state-of-the-art semantic parsing results while remaining applicable to any domain employing probabilistic tree transducers.</p><p>6 0.35347354 <a title="32-lda-6" href="./acl-2012-Efficient_Tree-based_Approximation_for_Entailment_Graph_Learning.html">80 acl-2012-Efficient Tree-based Approximation for Entailment Graph Learning</a></p>
<p>7 0.35187331 <a title="32-lda-7" href="./acl-2012-Verb_Classification_using_Distributional_Similarity_in_Syntactic_and_Semantic_Structures.html">214 acl-2012-Verb Classification using Distributional Similarity in Syntactic and Semantic Structures</a></p>
<p>8 0.3513079 <a title="32-lda-8" href="./acl-2012-Learning_the_Latent_Semantics_of_a_Concept_from_its_Definition.html">132 acl-2012-Learning the Latent Semantics of a Concept from its Definition</a></p>
<p>9 0.35037202 <a title="32-lda-9" href="./acl-2012-UWN%3A_A_Large_Multilingual_Lexical_Knowledge_Base.html">206 acl-2012-UWN: A Large Multilingual Lexical Knowledge Base</a></p>
<p>10 0.34702724 <a title="32-lda-10" href="./acl-2012-Learning_Syntactic_Verb_Frames_using_Graphical_Models.html">130 acl-2012-Learning Syntactic Verb Frames using Graphical Models</a></p>
<p>11 0.34690946 <a title="32-lda-11" href="./acl-2012-Cross-lingual_Parse_Disambiguation_based_on_Semantic_Correspondence.html">63 acl-2012-Cross-lingual Parse Disambiguation based on Semantic Correspondence</a></p>
<p>12 0.34686396 <a title="32-lda-12" href="./acl-2012-langid.py%3A_An_Off-the-shelf_Language_Identification_Tool.html">219 acl-2012-langid.py: An Off-the-shelf Language Identification Tool</a></p>
<p>13 0.34671113 <a title="32-lda-13" href="./acl-2012-Learning_to_Translate_with_Multiple_Objectives.html">136 acl-2012-Learning to Translate with Multiple Objectives</a></p>
<p>14 0.34670448 <a title="32-lda-14" href="./acl-2012-QuickView%3A_NLP-based_Tweet_Search.html">167 acl-2012-QuickView: NLP-based Tweet Search</a></p>
<p>15 0.34600827 <a title="32-lda-15" href="./acl-2012-Temporally_Anchored_Relation_Extraction.html">191 acl-2012-Temporally Anchored Relation Extraction</a></p>
<p>16 0.34599391 <a title="32-lda-16" href="./acl-2012-Modified_Distortion_Matrices_for_Phrase-Based_Statistical_Machine_Translation.html">148 acl-2012-Modified Distortion Matrices for Phrase-Based Statistical Machine Translation</a></p>
<p>17 0.34583059 <a title="32-lda-17" href="./acl-2012-Online_Plagiarized_Detection_Through_Exploiting_Lexical%2C_Syntax%2C_and_Semantic_Information.html">156 acl-2012-Online Plagiarized Detection Through Exploiting Lexical, Syntax, and Semantic Information</a></p>
<p>18 0.34563974 <a title="32-lda-18" href="./acl-2012-Semi-supervised_Dependency_Parsing_using_Lexical_Affinities.html">175 acl-2012-Semi-supervised Dependency Parsing using Lexical Affinities</a></p>
<p>19 0.34550643 <a title="32-lda-19" href="./acl-2012-Estimating_Compact_Yet_Rich_Tree_Insertion_Grammars.html">84 acl-2012-Estimating Compact Yet Rich Tree Insertion Grammars</a></p>
<p>20 0.34476849 <a title="32-lda-20" href="./acl-2012-Finding_Salient_Dates_for_Building_Thematic_Timelines.html">99 acl-2012-Finding Salient Dates for Building Thematic Timelines</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
