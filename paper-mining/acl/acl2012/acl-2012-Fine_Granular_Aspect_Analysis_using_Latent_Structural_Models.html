<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>100 acl-2012-Fine Granular Aspect Analysis using Latent Structural Models</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-100" href="#">acl2012-100</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>100 acl-2012-Fine Granular Aspect Analysis using Latent Structural Models</h1>
<br/><p>Source: <a title="acl-2012-100-pdf" href="http://aclweb.org/anthology//P/P12/P12-2065.pdf">pdf</a></p><p>Author: Lei Fang ; Minlie Huang</p><p>Abstract: In this paper, we present a structural learning model forjoint sentiment classification and aspect analysis of text at various levels of granularity. Our model aims to identify highly informative sentences that are aspect-specific in online custom reviews. The primary advantages of our model are two-fold: first, it performs document-level and sentence-level sentiment polarity classification jointly; second, it is able to find informative sentences that are closely related to some respects in a review, which may be helpful for aspect-level sentiment analysis such as aspect-oriented summarization. The proposed method was evaluated with 9,000 Chinese restaurant reviews. Preliminary experiments demonstrate that our model obtains promising performance. 1</p><p>Reference: <a title="acl-2012-100-reference" href="../acl2012_reference/acl-2012-Fine_Granular_Aspect_Analysis_using_Latent_Structural_Models_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('senty', 0.52), ('aspect', 0.422), ('pol', 0.306), ('yessenalin', 0.255), ('xj', 0.232), ('review', 0.139), ('subs', 0.125), ('structural', 0.107), ('multilevel', 0.093), ('sent', 0.091), ('xl', 0.087), ('msa', 0.079), ('xxi', 0.079), ('aj', 0.079), ('resta', 0.077), ('svms', 0.077), ('yi', 0.073), ('cccp', 0.071), ('dtoc', 0.071), ('grief', 0.071)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999997 <a title="100-tfidf-1" href="./acl-2012-Fine_Granular_Aspect_Analysis_using_Latent_Structural_Models.html">100 acl-2012-Fine Granular Aspect Analysis using Latent Structural Models</a></p>
<p>Author: Lei Fang ; Minlie Huang</p><p>Abstract: In this paper, we present a structural learning model forjoint sentiment classification and aspect analysis of text at various levels of granularity. Our model aims to identify highly informative sentences that are aspect-specific in online custom reviews. The primary advantages of our model are two-fold: first, it performs document-level and sentence-level sentiment polarity classification jointly; second, it is able to find informative sentences that are closely related to some respects in a review, which may be helpful for aspect-level sentiment analysis such as aspect-oriented summarization. The proposed method was evaluated with 9,000 Chinese restaurant reviews. Preliminary experiments demonstrate that our model obtains promising performance. 1</p><p>2 0.51996326 <a title="100-tfidf-2" href="./acl-2012-Aspect_Extraction_through_Semi-Supervised_Modeling.html">28 acl-2012-Aspect Extraction through Semi-Supervised Modeling</a></p>
<p>Author: Arjun Mukherjee ; Bing Liu</p><p>Abstract: Aspect extraction is a central problem in sentiment analysis. Current methods either extract aspects without categorizing them, or extract and categorize them using unsupervised topic modeling. By categorizing, we mean the synonymous aspects should be clustered into the same category. In this paper, we solve the problem in a different setting where the user provides some seed words for a few aspect categories and the model extracts and clusters aspect terms into categories simultaneously. This setting is important because categorizing aspects is a subjective task. For different application purposes, different categorizations may be needed. Some form of user guidance is desired. In this paper, we propose two statistical models to solve this seeded problem, which aim to discover exactly what the user wants. Our experimental results show that the two proposed models are indeed able to perform the task effectively. 1</p><p>3 0.41685173 <a title="100-tfidf-3" href="./acl-2012-Cross-Domain_Co-Extraction_of_Sentiment_and_Topic_Lexicons.html">61 acl-2012-Cross-Domain Co-Extraction of Sentiment and Topic Lexicons</a></p>
<p>Author: Fangtao Li ; Sinno Jialin Pan ; Ou Jin ; Qiang Yang ; Xiaoyan Zhu</p><p>Abstract: Extracting sentiment and topic lexicons is important for opinion mining. Previous works have showed that supervised learning methods are superior for this task. However, the performance of supervised methods highly relies on manually labeled training data. In this paper, we propose a domain adaptation framework for sentiment- and topic- lexicon co-extraction in a domain of interest where we do not require any labeled data, but have lots of labeled data in another related domain. The framework is twofold. In the first step, we generate a few high-confidence sentiment and topic seeds in the target domain. In the second step, we propose a novel Relational Adaptive bootstraPping (RAP) algorithm to expand the seeds in the target domain by exploiting the labeled source domain data and the relationships between topic and sentiment words. Experimental results show that our domain adaptation framework can extract precise lexicons in the target domain without any annotation.</p><p>4 0.35489404 <a title="100-tfidf-4" href="./acl-2012-Polarity_Consistency_Checking_for_Sentiment_Dictionaries.html">161 acl-2012-Polarity Consistency Checking for Sentiment Dictionaries</a></p>
<p>Author: Eduard Dragut ; Hong Wang ; Clement Yu ; Prasad Sistla ; Weiyi Meng</p><p>Abstract: Polarity classification of words is important for applications such as Opinion Mining and Sentiment Analysis. A number of sentiment word/sense dictionaries have been manually or (semi)automatically constructed. The dictionaries have substantial inaccuracies. Besides obvious instances, where the same word appears with different polarities in different dictionaries, the dictionaries exhibit complex cases, which cannot be detected by mere manual inspection. We introduce the concept of polarity consistency of words/senses in sentiment dictionaries in this paper. We show that the consistency problem is NP-complete. We reduce the polarity consistency problem to the satisfiability problem and utilize a fast SAT solver to detect inconsistencies in a sentiment dictionary. We perform experiments on four sentiment dictionaries and WordNet.</p><p>5 0.31459042 <a title="100-tfidf-5" href="./acl-2012-Cross-Lingual_Mixture_Model_for_Sentiment_Classification.html">62 acl-2012-Cross-Lingual Mixture Model for Sentiment Classification</a></p>
<p>Author: Xinfan Meng ; Furu Wei ; Xiaohua Liu ; Ming Zhou ; Ge Xu ; Houfeng Wang</p><p>Abstract: The amount of labeled sentiment data in English is much larger than that in other languages. Such a disproportion arouse interest in cross-lingual sentiment classification, which aims to conduct sentiment classification in the target language (e.g. Chinese) using labeled data in the source language (e.g. English). Most existing work relies on machine translation engines to directly adapt labeled data from the source language to the target language. This approach suffers from the limited coverage of vocabulary in the machine translation results. In this paper, we propose a generative cross-lingual mixture model (CLMM) to leverage unlabeled bilingual parallel data. By fitting parameters to maximize the likelihood of the bilingual parallel data, the proposed model learns previously unseen sentiment words from the large bilingual parallel data and improves vocabulary coverage signifi- cantly. Experiments on multiple data sets show that CLMM is consistently effective in two settings: (1) labeled data in the target language are unavailable; and (2) labeled data in the target language are also available.</p><p>6 0.26376912 <a title="100-tfidf-6" href="./acl-2012-Multilingual_Subjectivity_and_Sentiment_Analysis.html">151 acl-2012-Multilingual Subjectivity and Sentiment Analysis</a></p>
<p>7 0.23916931 <a title="100-tfidf-7" href="./acl-2012-Identifying_High-Impact_Sub-Structures_for_Convolution_Kernels_in_Document-level_Sentiment_Classification.html">115 acl-2012-Identifying High-Impact Sub-Structures for Convolution Kernels in Document-level Sentiment Classification</a></p>
<p>8 0.23567052 <a title="100-tfidf-8" href="./acl-2012-A_System_for_Real-time_Twitter_Sentiment_Analysis_of_2012_U.S._Presidential_Election_Cycle.html">21 acl-2012-A System for Real-time Twitter Sentiment Analysis of 2012 U.S. Presidential Election Cycle</a></p>
<p>9 0.21239905 <a title="100-tfidf-9" href="./acl-2012-Baselines_and_Bigrams%3A_Simple%2C_Good_Sentiment_and_Topic_Classification.html">37 acl-2012-Baselines and Bigrams: Simple, Good Sentiment and Topic Classification</a></p>
<p>10 0.19863749 <a title="100-tfidf-10" href="./acl-2012-Modeling_Review_Comments.html">144 acl-2012-Modeling Review Comments</a></p>
<p>11 0.18306352 <a title="100-tfidf-11" href="./acl-2012-Social_Event_Radar%3A_A_Bilingual_Context_Mining_and_Sentiment_Analysis_Summarization_System.html">180 acl-2012-Social Event Radar: A Bilingual Context Mining and Sentiment Analysis Summarization System</a></p>
<p>12 0.17585848 <a title="100-tfidf-12" href="./acl-2012-Subgroup_Detection_in_Ideological_Discussions.html">187 acl-2012-Subgroup Detection in Ideological Discussions</a></p>
<p>13 0.16694051 <a title="100-tfidf-13" href="./acl-2012-Genre_Independent_Subgroup_Detection_in_Online_Discussion_Threads%3A_A_Study_of_Implicit_Attitude_using_Textual_Latent_Semantics.html">102 acl-2012-Genre Independent Subgroup Detection in Online Discussion Threads: A Study of Implicit Attitude using Textual Latent Semantics</a></p>
<p>14 0.13050336 <a title="100-tfidf-14" href="./acl-2012-Spice_it_up%3F_Mining_Refinements_to_Online_Instructions_from_User_Generated_Content.html">182 acl-2012-Spice it up? Mining Refinements to Online Instructions from User Generated Content</a></p>
<p>15 0.12760751 <a title="100-tfidf-15" href="./acl-2012-Subgroup_Detector%3A_A_System_for_Detecting_Subgroups_in_Online_Discussions.html">188 acl-2012-Subgroup Detector: A System for Detecting Subgroups in Online Discussions</a></p>
<p>16 0.093815632 <a title="100-tfidf-16" href="./acl-2012-A_Cost_Sensitive_Part-of-Speech_Tagging%3A_Differentiating_Serious_Errors_from_Minor_Errors.html">9 acl-2012-A Cost Sensitive Part-of-Speech Tagging: Differentiating Serious Errors from Minor Errors</a></p>
<p>17 0.089503288 <a title="100-tfidf-17" href="./acl-2012-Deep_Learning_for_NLP_%28without_Magic%29.html">69 acl-2012-Deep Learning for NLP (without Magic)</a></p>
<p>18 0.080949321 <a title="100-tfidf-18" href="./acl-2012-Automatic_Event_Extraction_with_Structured_Preference_Modeling.html">33 acl-2012-Automatic Event Extraction with Structured Preference Modeling</a></p>
<p>19 0.076552764 <a title="100-tfidf-19" href="./acl-2012-Fully_Abstractive_Approach_to_Guided_Summarization.html">101 acl-2012-Fully Abstractive Approach to Guided Summarization</a></p>
<p>20 0.070467345 <a title="100-tfidf-20" href="./acl-2012-Joint_Feature_Selection_in_Distributed_Stochastic_Learning_for_Large-Scale_Discriminative_Training_in_SMT.html">123 acl-2012-Joint Feature Selection in Distributed Stochastic Learning for Large-Scale Discriminative Training in SMT</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.23), (1, 0.337), (2, 0.365), (3, -0.316), (4, 0.02), (5, 0.017), (6, -0.014), (7, 0.076), (8, -0.202), (9, -0.073), (10, -0.118), (11, 0.089), (12, 0.17), (13, -0.139), (14, 0.053), (15, -0.048), (16, -0.005), (17, -0.042), (18, -0.137), (19, 0.027), (20, 0.005), (21, 0.126), (22, 0.009), (23, 0.028), (24, 0.002), (25, -0.062), (26, -0.101), (27, 0.018), (28, -0.001), (29, 0.013), (30, 0.002), (31, -0.005), (32, -0.048), (33, -0.004), (34, 0.035), (35, 0.051), (36, 0.05), (37, -0.056), (38, 0.01), (39, -0.07), (40, 0.045), (41, -0.038), (42, -0.006), (43, -0.039), (44, 0.073), (45, 0.009), (46, 0.085), (47, -0.011), (48, -0.0), (49, -0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95456296 <a title="100-lsi-1" href="./acl-2012-Fine_Granular_Aspect_Analysis_using_Latent_Structural_Models.html">100 acl-2012-Fine Granular Aspect Analysis using Latent Structural Models</a></p>
<p>Author: Lei Fang ; Minlie Huang</p><p>Abstract: In this paper, we present a structural learning model forjoint sentiment classification and aspect analysis of text at various levels of granularity. Our model aims to identify highly informative sentences that are aspect-specific in online custom reviews. The primary advantages of our model are two-fold: first, it performs document-level and sentence-level sentiment polarity classification jointly; second, it is able to find informative sentences that are closely related to some respects in a review, which may be helpful for aspect-level sentiment analysis such as aspect-oriented summarization. The proposed method was evaluated with 9,000 Chinese restaurant reviews. Preliminary experiments demonstrate that our model obtains promising performance. 1</p><p>2 0.87431788 <a title="100-lsi-2" href="./acl-2012-Aspect_Extraction_through_Semi-Supervised_Modeling.html">28 acl-2012-Aspect Extraction through Semi-Supervised Modeling</a></p>
<p>Author: Arjun Mukherjee ; Bing Liu</p><p>Abstract: Aspect extraction is a central problem in sentiment analysis. Current methods either extract aspects without categorizing them, or extract and categorize them using unsupervised topic modeling. By categorizing, we mean the synonymous aspects should be clustered into the same category. In this paper, we solve the problem in a different setting where the user provides some seed words for a few aspect categories and the model extracts and clusters aspect terms into categories simultaneously. This setting is important because categorizing aspects is a subjective task. For different application purposes, different categorizations may be needed. Some form of user guidance is desired. In this paper, we propose two statistical models to solve this seeded problem, which aim to discover exactly what the user wants. Our experimental results show that the two proposed models are indeed able to perform the task effectively. 1</p><p>3 0.77472591 <a title="100-lsi-3" href="./acl-2012-Cross-Domain_Co-Extraction_of_Sentiment_and_Topic_Lexicons.html">61 acl-2012-Cross-Domain Co-Extraction of Sentiment and Topic Lexicons</a></p>
<p>Author: Fangtao Li ; Sinno Jialin Pan ; Ou Jin ; Qiang Yang ; Xiaoyan Zhu</p><p>Abstract: Extracting sentiment and topic lexicons is important for opinion mining. Previous works have showed that supervised learning methods are superior for this task. However, the performance of supervised methods highly relies on manually labeled training data. In this paper, we propose a domain adaptation framework for sentiment- and topic- lexicon co-extraction in a domain of interest where we do not require any labeled data, but have lots of labeled data in another related domain. The framework is twofold. In the first step, we generate a few high-confidence sentiment and topic seeds in the target domain. In the second step, we propose a novel Relational Adaptive bootstraPping (RAP) algorithm to expand the seeds in the target domain by exploiting the labeled source domain data and the relationships between topic and sentiment words. Experimental results show that our domain adaptation framework can extract precise lexicons in the target domain without any annotation.</p><p>4 0.75153327 <a title="100-lsi-4" href="./acl-2012-Baselines_and_Bigrams%3A_Simple%2C_Good_Sentiment_and_Topic_Classification.html">37 acl-2012-Baselines and Bigrams: Simple, Good Sentiment and Topic Classification</a></p>
<p>Author: Sida Wang ; Christopher Manning</p><p>Abstract: Variants of Naive Bayes (NB) and Support Vector Machines (SVM) are often used as baseline methods for text classification, but their performance varies greatly depending on the model variant, features used and task/ dataset. We show that: (i) the inclusion of word bigram features gives consistent gains on sentiment analysis tasks; (ii) for short snippet sentiment tasks, NB actually does better than SVMs (while for longer documents the opposite result holds); (iii) a simple but novel SVM variant using NB log-count ratios as feature values consistently performs well across tasks and datasets. Based on these observations, we identify simple NB and SVM variants which outperform most published results on sentiment analysis datasets, sometimes providing a new state-of-the-art performance level.</p><p>5 0.73841184 <a title="100-lsi-5" href="./acl-2012-Polarity_Consistency_Checking_for_Sentiment_Dictionaries.html">161 acl-2012-Polarity Consistency Checking for Sentiment Dictionaries</a></p>
<p>Author: Eduard Dragut ; Hong Wang ; Clement Yu ; Prasad Sistla ; Weiyi Meng</p><p>Abstract: Polarity classification of words is important for applications such as Opinion Mining and Sentiment Analysis. A number of sentiment word/sense dictionaries have been manually or (semi)automatically constructed. The dictionaries have substantial inaccuracies. Besides obvious instances, where the same word appears with different polarities in different dictionaries, the dictionaries exhibit complex cases, which cannot be detected by mere manual inspection. We introduce the concept of polarity consistency of words/senses in sentiment dictionaries in this paper. We show that the consistency problem is NP-complete. We reduce the polarity consistency problem to the satisfiability problem and utilize a fast SAT solver to detect inconsistencies in a sentiment dictionary. We perform experiments on four sentiment dictionaries and WordNet.</p><p>6 0.73669726 <a title="100-lsi-6" href="./acl-2012-Multilingual_Subjectivity_and_Sentiment_Analysis.html">151 acl-2012-Multilingual Subjectivity and Sentiment Analysis</a></p>
<p>7 0.70890898 <a title="100-lsi-7" href="./acl-2012-Cross-Lingual_Mixture_Model_for_Sentiment_Classification.html">62 acl-2012-Cross-Lingual Mixture Model for Sentiment Classification</a></p>
<p>8 0.57106066 <a title="100-lsi-8" href="./acl-2012-A_System_for_Real-time_Twitter_Sentiment_Analysis_of_2012_U.S._Presidential_Election_Cycle.html">21 acl-2012-A System for Real-time Twitter Sentiment Analysis of 2012 U.S. Presidential Election Cycle</a></p>
<p>9 0.55916804 <a title="100-lsi-9" href="./acl-2012-Identifying_High-Impact_Sub-Structures_for_Convolution_Kernels_in_Document-level_Sentiment_Classification.html">115 acl-2012-Identifying High-Impact Sub-Structures for Convolution Kernels in Document-level Sentiment Classification</a></p>
<p>10 0.50300139 <a title="100-lsi-10" href="./acl-2012-Modeling_Review_Comments.html">144 acl-2012-Modeling Review Comments</a></p>
<p>11 0.49032703 <a title="100-lsi-11" href="./acl-2012-Social_Event_Radar%3A_A_Bilingual_Context_Mining_and_Sentiment_Analysis_Summarization_System.html">180 acl-2012-Social Event Radar: A Bilingual Context Mining and Sentiment Analysis Summarization System</a></p>
<p>12 0.37739077 <a title="100-lsi-12" href="./acl-2012-Spice_it_up%3F_Mining_Refinements_to_Online_Instructions_from_User_Generated_Content.html">182 acl-2012-Spice it up? Mining Refinements to Online Instructions from User Generated Content</a></p>
<p>13 0.36489514 <a title="100-lsi-13" href="./acl-2012-Genre_Independent_Subgroup_Detection_in_Online_Discussion_Threads%3A_A_Study_of_Implicit_Attitude_using_Textual_Latent_Semantics.html">102 acl-2012-Genre Independent Subgroup Detection in Online Discussion Threads: A Study of Implicit Attitude using Textual Latent Semantics</a></p>
<p>14 0.34937063 <a title="100-lsi-14" href="./acl-2012-Subgroup_Detection_in_Ideological_Discussions.html">187 acl-2012-Subgroup Detection in Ideological Discussions</a></p>
<p>15 0.32975307 <a title="100-lsi-15" href="./acl-2012-Syntactic_Stylometry_for_Deception_Detection.html">190 acl-2012-Syntactic Stylometry for Deception Detection</a></p>
<p>16 0.29557526 <a title="100-lsi-16" href="./acl-2012-Structuring_E-Commerce_Inventory.html">186 acl-2012-Structuring E-Commerce Inventory</a></p>
<p>17 0.27671725 <a title="100-lsi-17" href="./acl-2012-Subgroup_Detector%3A_A_System_for_Detecting_Subgroups_in_Online_Discussions.html">188 acl-2012-Subgroup Detector: A System for Detecting Subgroups in Online Discussions</a></p>
<p>18 0.26089457 <a title="100-lsi-18" href="./acl-2012-Fully_Abstractive_Approach_to_Guided_Summarization.html">101 acl-2012-Fully Abstractive Approach to Guided Summarization</a></p>
<p>19 0.25873306 <a title="100-lsi-19" href="./acl-2012-WizIE%3A_A_Best_Practices_Guided_Development_Environment_for_Information_Extraction.html">215 acl-2012-WizIE: A Best Practices Guided Development Environment for Information Extraction</a></p>
<p>20 0.24420932 <a title="100-lsi-20" href="./acl-2012-Humor_as_Circuits_in_Semantic_Networks.html">112 acl-2012-Humor as Circuits in Semantic Networks</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.038), (8, 0.067), (22, 0.054), (31, 0.027), (38, 0.03), (47, 0.036), (58, 0.093), (77, 0.045), (91, 0.166), (92, 0.046), (96, 0.041), (98, 0.263)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.77925867 <a title="100-lda-1" href="./acl-2012-Labeling_Documents_with_Timestamps%3A_Learning_from_their_Time_Expressions.html">126 acl-2012-Labeling Documents with Timestamps: Learning from their Time Expressions</a></p>
<p>Author: Nathanael Chambers</p><p>Abstract: Temporal reasoners for document understanding typically assume that a document’s creation date is known. Algorithms to ground relative time expressions and order events often rely on this timestamp to assist the learner. Unfortunately, the timestamp is not always known, particularly on the Web. This paper addresses the task of automatic document timestamping, presenting two new models that incorporate rich linguistic features about time. The first is a discriminative classifier with new features extracted from the text’s time expressions (e.g., ‘since 1999’). This model alone improves on previous generative models by 77%. The second model learns probabilistic constraints between time expressions and the unknown document time. Imposing these learned constraints on the discriminative model further improves its accuracy. Finally, we present a new experiment design that facil- itates easier comparison by future work.</p><p>same-paper 2 0.77425551 <a title="100-lda-2" href="./acl-2012-Fine_Granular_Aspect_Analysis_using_Latent_Structural_Models.html">100 acl-2012-Fine Granular Aspect Analysis using Latent Structural Models</a></p>
<p>Author: Lei Fang ; Minlie Huang</p><p>Abstract: In this paper, we present a structural learning model forjoint sentiment classification and aspect analysis of text at various levels of granularity. Our model aims to identify highly informative sentences that are aspect-specific in online custom reviews. The primary advantages of our model are two-fold: first, it performs document-level and sentence-level sentiment polarity classification jointly; second, it is able to find informative sentences that are closely related to some respects in a review, which may be helpful for aspect-level sentiment analysis such as aspect-oriented summarization. The proposed method was evaluated with 9,000 Chinese restaurant reviews. Preliminary experiments demonstrate that our model obtains promising performance. 1</p><p>3 0.64995015 <a title="100-lda-3" href="./acl-2012-Sentence_Dependency_Tagging_in_Online_Question_Answering_Forums.html">177 acl-2012-Sentence Dependency Tagging in Online Question Answering Forums</a></p>
<p>Author: Zhonghua Qu ; Yang Liu</p><p>Abstract: Online forums are becoming a popular resource in the state of the art question answering (QA) systems. Because of its nature as an online community, it contains more updated knowledge than other places. However, going through tedious and redundant posts to look for answers could be very time consuming. Most prior work focused on extracting only question answering sentences from user conversations. In this paper, we introduce the task of sentence dependency tagging. Finding dependency structure can not only help find answer quickly but also allow users to trace back how the answer is concluded through user conversations. We use linear-chain conditional random fields (CRF) for sentence type tagging, and a 2D CRF to label the dependency relation between sentences. Our experimental results show that our proposed approach performs well for sentence dependency tagging. This dependency information can benefit other tasks such as thread ranking and answer summarization in online forums.</p><p>4 0.64395523 <a title="100-lda-4" href="./acl-2012-Aspect_Extraction_through_Semi-Supervised_Modeling.html">28 acl-2012-Aspect Extraction through Semi-Supervised Modeling</a></p>
<p>Author: Arjun Mukherjee ; Bing Liu</p><p>Abstract: Aspect extraction is a central problem in sentiment analysis. Current methods either extract aspects without categorizing them, or extract and categorize them using unsupervised topic modeling. By categorizing, we mean the synonymous aspects should be clustered into the same category. In this paper, we solve the problem in a different setting where the user provides some seed words for a few aspect categories and the model extracts and clusters aspect terms into categories simultaneously. This setting is important because categorizing aspects is a subjective task. For different application purposes, different categorizations may be needed. Some form of user guidance is desired. In this paper, we propose two statistical models to solve this seeded problem, which aim to discover exactly what the user wants. Our experimental results show that the two proposed models are indeed able to perform the task effectively. 1</p><p>5 0.63660544 <a title="100-lda-5" href="./acl-2012-Cross-Lingual_Mixture_Model_for_Sentiment_Classification.html">62 acl-2012-Cross-Lingual Mixture Model for Sentiment Classification</a></p>
<p>Author: Xinfan Meng ; Furu Wei ; Xiaohua Liu ; Ming Zhou ; Ge Xu ; Houfeng Wang</p><p>Abstract: The amount of labeled sentiment data in English is much larger than that in other languages. Such a disproportion arouse interest in cross-lingual sentiment classification, which aims to conduct sentiment classification in the target language (e.g. Chinese) using labeled data in the source language (e.g. English). Most existing work relies on machine translation engines to directly adapt labeled data from the source language to the target language. This approach suffers from the limited coverage of vocabulary in the machine translation results. In this paper, we propose a generative cross-lingual mixture model (CLMM) to leverage unlabeled bilingual parallel data. By fitting parameters to maximize the likelihood of the bilingual parallel data, the proposed model learns previously unseen sentiment words from the large bilingual parallel data and improves vocabulary coverage signifi- cantly. Experiments on multiple data sets show that CLMM is consistently effective in two settings: (1) labeled data in the target language are unavailable; and (2) labeled data in the target language are also available.</p><p>6 0.63565648 <a title="100-lda-6" href="./acl-2012-A_Feature-Rich_Constituent_Context_Model_for_Grammar_Induction.html">11 acl-2012-A Feature-Rich Constituent Context Model for Grammar Induction</a></p>
<p>7 0.63549083 <a title="100-lda-7" href="./acl-2012-Attacking_Parsing_Bottlenecks_with_Unlabeled_Data_and_Relevant_Factorizations.html">30 acl-2012-Attacking Parsing Bottlenecks with Unlabeled Data and Relevant Factorizations</a></p>
<p>8 0.6354261 <a title="100-lda-8" href="./acl-2012-ACCURAT_Toolkit_for_Multi-Level_Alignment_and_Information_Extraction_from_Comparable_Corpora.html">1 acl-2012-ACCURAT Toolkit for Multi-Level Alignment and Information Extraction from Comparable Corpora</a></p>
<p>9 0.635068 <a title="100-lda-9" href="./acl-2012-Cross-lingual_Parse_Disambiguation_based_on_Semantic_Correspondence.html">63 acl-2012-Cross-lingual Parse Disambiguation based on Semantic Correspondence</a></p>
<p>10 0.63504541 <a title="100-lda-10" href="./acl-2012-Bootstrapping_a_Unified_Model_of_Lexical_and_Phonetic_Acquisition.html">41 acl-2012-Bootstrapping a Unified Model of Lexical and Phonetic Acquisition</a></p>
<p>11 0.63413119 <a title="100-lda-11" href="./acl-2012-Exploiting_Social_Information_in_Grounded_Language_Learning_via_Grammatical_Reduction.html">88 acl-2012-Exploiting Social Information in Grounded Language Learning via Grammatical Reduction</a></p>
<p>12 0.63408005 <a title="100-lda-12" href="./acl-2012-A_Ranking-based_Approach_to_Word_Reordering_for_Statistical_Machine_Translation.html">19 acl-2012-A Ranking-based Approach to Word Reordering for Statistical Machine Translation</a></p>
<p>13 0.63321382 <a title="100-lda-13" href="./acl-2012-Lemmatisation_as_a_Tagging_Task.html">137 acl-2012-Lemmatisation as a Tagging Task</a></p>
<p>14 0.63268226 <a title="100-lda-14" href="./acl-2012-Exploiting_Multiple_Treebanks_for_Parsing_with_Quasi-synchronous_Grammars.html">87 acl-2012-Exploiting Multiple Treebanks for Parsing with Quasi-synchronous Grammars</a></p>
<p>15 0.63174474 <a title="100-lda-15" href="./acl-2012-Word_Epoch_Disambiguation%3A_Finding_How_Words_Change_Over_Time.html">216 acl-2012-Word Epoch Disambiguation: Finding How Words Change Over Time</a></p>
<p>16 0.63146842 <a title="100-lda-16" href="./acl-2012-Semi-supervised_Dependency_Parsing_using_Lexical_Affinities.html">175 acl-2012-Semi-supervised Dependency Parsing using Lexical Affinities</a></p>
<p>17 0.63068122 <a title="100-lda-17" href="./acl-2012-Community_Answer_Summarization_for_Multi-Sentence_Question_with_Group_L1_Regularization.html">55 acl-2012-Community Answer Summarization for Multi-Sentence Question with Group L1 Regularization</a></p>
<p>18 0.63054234 <a title="100-lda-18" href="./acl-2012-A_Two-step_Approach_to_Sentence_Compression_of_Spoken_Utterances.html">23 acl-2012-A Two-step Approach to Sentence Compression of Spoken Utterances</a></p>
<p>19 0.62969691 <a title="100-lda-19" href="./acl-2012-Authorship_Attribution_with_Author-aware_Topic_Models.html">31 acl-2012-Authorship Attribution with Author-aware Topic Models</a></p>
<p>20 0.62895977 <a title="100-lda-20" href="./acl-2012-Identifying_High-Impact_Sub-Structures_for_Convolution_Kernels_in_Document-level_Sentiment_Classification.html">115 acl-2012-Identifying High-Impact Sub-Structures for Convolution Kernels in Document-level Sentiment Classification</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
