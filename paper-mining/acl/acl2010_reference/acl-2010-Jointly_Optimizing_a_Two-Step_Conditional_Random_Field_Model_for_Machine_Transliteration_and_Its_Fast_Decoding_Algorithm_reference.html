<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>154 acl-2010-Jointly Optimizing a Two-Step Conditional Random Field Model for Machine Transliteration and Its Fast Decoding Algorithm</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-154" href="../acl2010/acl-2010-Jointly_Optimizing_a_Two-Step_Conditional_Random_Field_Model_for_Machine_Transliteration_and_Its_Fast_Decoding_Algorithm.html">acl2010-154</a> <a title="acl-2010-154-reference" href="#">acl2010-154-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>154 acl-2010-Jointly Optimizing a Two-Step Conditional Random Field Model for Machine Transliteration and Its Fast Decoding Algorithm</h1>
<br/><p>Source: <a title="acl-2010-154-pdf" href="http://aclweb.org/anthology//P/P10/P10-2051.pdf">pdf</a></p><p>Author: Dong Yang ; Paul Dixon ; Sadaoki Furui</p><p>Abstract: This paper presents a joint optimization method of a two-step conditional random field (CRF) model for machine transliteration and a fast decoding algorithm for the proposed method. Our method lies in the category of direct orthographical mapping (DOM) between two languages without using any intermediate phonemic mapping. In the two-step CRF model, the first CRF segments an input word into chunks and the second one converts each chunk into one unit in the target language. In this paper, we propose a method to jointly optimize the two-step CRFs and also a fast algorithm to realize it. Our experiments show that the proposed method outper- forms the well-known joint source channel model (JSCM) and our proposed fast algorithm decreases the decoding time significantly. Furthermore, combination of the proposed method and the JSCM gives further improvement, which outperforms state-of-the-art results in terms of top-1 accuracy.</p><br/>
<h2>reference text</h2><p>Dong Yang, Paul Dixon, Yi-Cheng Pan, Tasuku Oonishi, Masanobu Nakamura and Sadaoki Furui 2009.  CytrjdGicouelnc AeaorhlfaSCLAluokibzanuertfanode,mrnEyeMnd.atfciMeP,h(riCeoa hnclrItAeyRIWemaAidrelp)inMgyl,eh pmoastJhegordnhefista 2Fn1th0ineoS0-in7c2tNhe.3a-iSnOlktdahpwtAeIynpkFTt,erslWaticn: oasA- ecCNMrhoa itmndioe blnidTaE(irNnadgnEtsiWaltieJSsTowri2Wano0ti-osr9Snkt)eos,phuorCcapPgeo:rnSCosdch7iaet2irno-de7n i5aneTlgasMRkoadfnelotThfmroeanF2Msi0leatd9Diamantino Caseiro, Isabel Trancosoo, Luis Oliveira and Ceu Viana 2002. Grapheme-to-phone using finite state transducers. Proceedings IEEE Workshop on Speech Synthesis. Asif Ekbal, Sudip Kumar Naskar and Sivaji Bandyopadhyay. 2006. A modified joint source-channel model for transliteration, Proceedings of the COLING/ACL, pages 191-198. Bo-June Hsu and James Glass 2008. Iterative Language Model Estimation: Efficient Data Structure & Algorithms. Proceedings Interspeech, pages 841844. Kevin Knight and Jonathan Graehl. 1998. Machine Transliteration, Association for Computational Linguistics. John Lafferty, Andrew McCallum, and Fernando Pereira 2001. Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data., Proceedings of International Conference on Machine Learning, pages 282-289. Haizhou Li, Min Zhang and Jian Su. 2004. A joint source-channel model for machine transliteration, Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics. Haizhou Li, A. Kumaran, Vladimir Pervouchine and Min Zhang 2009. Report of NEWS 2009 Machine Transliteration Shared Task, Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration (NEWS 2009), pages 1-18  Jong-Hoon Oh, Key-Sun Choi and Hitoshi Isahara. 2006. A comparison of different machine transliteration models , Journal of Artificial Intelligence Research, 27, pages 119-151 . Richard Sproat 2000. Corpus-Based Methods and Hand-Built Methods. Proceedings of International Conference on Spoken Language Processing, pages 426-428. Andrew J. Viterbi 1967. Error Bounds for Convolutional Codes and an Asymptotically Optimum Decoding Algorithm. IEEE Transactions on Information Theory, Volume IT-13, pages 260-269. Hanna Wallach 2002. Efficient Training of Conditional Random Fields. M. Thesis, University of Edinburgh. 280</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
