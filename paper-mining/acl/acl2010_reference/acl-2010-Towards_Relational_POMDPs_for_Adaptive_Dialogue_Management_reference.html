<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>239 acl-2010-Towards Relational POMDPs for Adaptive Dialogue Management</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-239" href="../acl2010/acl-2010-Towards_Relational_POMDPs_for_Adaptive_Dialogue_Management.html">acl2010-239</a> <a title="acl-2010-239-reference" href="#">acl2010-239-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>239 acl-2010-Towards Relational POMDPs for Adaptive Dialogue Management</h1>
<br/><p>Source: <a title="acl-2010-239-pdf" href="http://aclweb.org/anthology//P/P10/P10-3002.pdf">pdf</a></p><p>Author: Pierre Lison</p><p>Abstract: Open-ended spoken interactions are typically characterised by both structural complexity and high levels of uncertainty, making dialogue management in such settings a particularly challenging problem. Traditional approaches have focused on providing theoretical accounts for either the uncertainty or the complexity of spoken dialogue, but rarely considered the two issues simultaneously. This paper describes ongoing work on a new approach to dialogue management which attempts to fill this gap. We represent the interaction as a Partially Observable Markov Decision Process (POMDP) over a rich state space incorporating both dialogue, user, and environment models. The tractability of the resulting POMDP can be preserved using a mechanism for dynamically constraining the action space based on prior knowledge over locally relevant dialogue structures. These constraints are encoded in a small set of general rules expressed as a Markov Logic network. The first-order expressivity of Markov Logic enables us to leverage the rich relational structure of the problem and efficiently abstract over large regions ofthe state and action spaces.</p><br/>
<h2>reference text</h2><br/>
<br/><br/><br/></body>
</html>
