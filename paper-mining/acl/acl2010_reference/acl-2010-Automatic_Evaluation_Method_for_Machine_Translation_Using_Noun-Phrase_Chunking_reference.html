<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>37 acl-2010-Automatic Evaluation Method for Machine Translation Using Noun-Phrase Chunking</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-37" href="../acl2010/acl-2010-Automatic_Evaluation_Method_for_Machine_Translation_Using_Noun-Phrase_Chunking.html">acl2010-37</a> <a title="acl-2010-37-reference" href="#">acl2010-37-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>37 acl-2010-Automatic Evaluation Method for Machine Translation Using Noun-Phrase Chunking</h1>
<br/><p>Source: <a title="acl-2010-37-pdf" href="http://aclweb.org/anthology//P/P10/P10-1012.pdf">pdf</a></p><p>Author: Hiroshi Echizen-ya ; Kenji Araki</p><p>Abstract: As described in this paper, we propose a new automatic evaluation method for machine translation using noun-phrase chunking. Our method correctly determines the matching words between two sentences using corresponding noun phrases. Moreover, our method determines the similarity between two sentences in terms of the noun-phrase order of appearance. Evaluation experiments were conducted to calculate the correlation among human judgments, along with the scores produced us- ing automatic evaluation methods for MT outputs obtained from the 12 machine translation systems in NTCIR7. Experimental results show that our method obtained the highest correlations among the methods in both sentence-level adequacy and fluency.</p><br/>
<h2>reference text</h2><p>Satanjeev Banerjee and Alon Lavie. 2005. METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments. In Proc. of A CL Workshop  on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, 65–72. Deborah Coughlin. 2003. Correlating Automated and Human Assessments of Machine Translation Quality. In Proc. of MT Summit IX, 63–70. Hiroshi Echizen-ya and Kenji Araki. 2007. Automatic Evaluation of Machine Translation based on Recursive Acquisition of an Intuitive Common Parts Continuum. In Proc. of MT Summit XII, 151–158. Hiroshi Echizen-ya, Terumasa Ehara, Sayori Shimohata, Atsushi Fujii, Masao Utiyama, Mikio Yamamoto, Takehito Utsuro and Noriko Kando. 2009. Meta-Evaluation of Automatic Evaluation Methods for Machine Translation using Patent Translation Data in NTCIR-7. In Proc. of the 3rd Workshop on Patent Translation, 9–16. Terumasa Ehara. 2007. Rule Based Translation Combined with Statistical itor for Japanese to English Patent tion. In Proc. of MT Summit XII on Patent Translation, 13–18.  Machine Post EdTranslaWorkshop  Atsushi Fujii, Masao Utiyama, Mikio Yamamoto  and Takehito Utsuro. 2008. Overview of the Patent Translation Task at the NTCIR-7 Workshop. In Proc. of 7th NTCIR Workshop Meeting on Evaluation of Information Access Technologies: Information Retrieval, Question Answering and Cross-lingual Information Access, 389– 400. Gregor Leusch, Nicola Ueffing and Hermann Ney. 2003. A Novel String-to-String Distance Measure with Applications to Machine Translation Evaluation. In Proc. of MT Summit IX, 240– 247. Chin-Yew Lin and Franz Josef matic Evaluation of Machine ity Using Longest Common Skip-Bigram Statistics. In 606–613.  Och. 2004. AutoTranslation QualSubsequence and Proc. of A CL’ ’04,  Dennis  N. Mehay and Chris Brew. 2007. Flattening Syntactic Dependencies for MT Evaluation. In Proc. of MT Summit XII, 122–131.  BLEUAˆTRE:  Andrew Mutton, Mark Dras, Stephen Wan and Robert Dale. 2007. GLEU: Automatic Evaluation of Sentence-Level Fluency. In Proc. of ACL ’07, 344–351.  NIST. 2002. Automatic Evaluation of Machine Translation Quality Using N-gram Co-Occurrence Statistics. http://www.nist.gov/speech/tests/mt/doc/ ngram-study.pdf. Takashi Oyamada, Hiroshi Echizen-ya and Kenji Araki. 2010. Automatic Evaluation of Machine Translation Using both Words Information and Comprehensive Phrases Information. In IPSJ SIG Technical Report, Vol.2010-NL-195, No. 3 (in Japanese). Kishore Papineni, Salim Roukos, Todd Ward and Wei-Jing Zhu. 2002. BLEU: a Method for Automatic Evaluation of Machine Translation. In Proc. of ACL’ ’02, 311–318. Michael Pozar and Eugene Charniak. 2006. Bllip: An Improved Evaluation Metric for Machine Translation. Brown University Master Thesis. Fei Sha and Fernando Pereira. 2003. Shallow Parsing with Conditional Random Fields. In Proc. of HLT-NAACL 2003, 134–141. Keh-Yih Su, Ming-Wen Wu and Jing-Shin Chang. 1992. A New Quantitative Quality Measure for Machine Translation Systems. In Proc. of GOL-  ING’92, 433–439. Masao Utiyama and Hitoshi Isahara. 2003. Reliable Measures for Aligning Japanese–English News Articles and Sentences. In Proc. of the ACL ’03, pp.72–79. 117</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
