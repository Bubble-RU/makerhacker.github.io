<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>159 acl-2010-Learning 5000 Relational Extractors</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-159" href="../acl2010/acl-2010-Learning_5000_Relational_Extractors.html">acl2010-159</a> <a title="acl-2010-159-reference" href="#">acl2010-159-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>159 acl-2010-Learning 5000 Relational Extractors</h1>
<br/><p>Source: <a title="acl-2010-159-pdf" href="http://aclweb.org/anthology//P/P10/P10-1030.pdf">pdf</a></p><p>Author: Raphael Hoffmann ; Congle Zhang ; Daniel S. Weld</p><p>Abstract: Many researchers are trying to use information extraction (IE) to create large-scale knowledge bases from natural language text on the Web. However, the primary approach (supervised learning of relation-specific extractors) requires manually-labeled training data for each relation and doesn’t scale to the thousands of relations encoded in Web text. This paper presents LUCHS, a self-supervised, relation-specific IE system which learns 5025 relations more than an order of magnitude greater than any previous approach with an average F1 score of 61%. Crucial to LUCHS’s performance is an automated system for dynamic lexicon learning, which allows it to learn accurately from heuristically-generated training data, which is often noisy and sparse. — —</p><br/>
<h2>reference text</h2><br/>
<br/><br/><br/></body>
</html>
