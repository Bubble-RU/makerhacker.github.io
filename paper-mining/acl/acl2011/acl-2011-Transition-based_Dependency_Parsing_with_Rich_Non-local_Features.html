<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>309 acl-2011-Transition-based Dependency Parsing with Rich Non-local Features</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-309" href="#">acl2011-309</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>309 acl-2011-Transition-based Dependency Parsing with Rich Non-local Features</h1>
<br/><p>Source: <a title="acl-2011-309-pdf" href="http://aclweb.org/anthology//P/P11/P11-2033.pdf">pdf</a></p><p>Author: Yue Zhang ; Joakim Nivre</p><p>Abstract: Transition-based dependency parsers generally use heuristic decoding algorithms but can accommodate arbitrarily rich feature representations. In this paper, we show that we can improve the accuracy of such parsers by considering even richer feature sets than those employed in previous systems. In the standard Penn Treebank setup, our novel features improve attachment score form 91.4% to 92.9%, giving the best results so far for transitionbased parsing and rivaling the best results overall. For the Chinese Treebank, they give a signficant improvement of the state of the art. An open source release of our parser is freely available.</p><p>Reference: <a title="acl-2011-309-reference" href="../acl2011_reference/acl-2011-Transition-based_Dependency_Parsing_with_Rich_Non-local_Features_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Transition-based Dependency Parsing with Rich Non-local Features  Yue Zhang University of Cambridge Computer Laboratory yue  . [sent-1, score-0.104]
</p><p>2 uk  Abstract Transition-based dependency parsers generally use heuristic decoding algorithms but can accommodate arbitrarily rich feature representations. [sent-5, score-0.488]
</p><p>3 In this paper, we show that we can improve the accuracy of such parsers by considering even richer feature sets than those employed in previous systems. [sent-6, score-0.166]
</p><p>4 In the standard Penn Treebank setup, our novel features improve attachment score form 91. [sent-7, score-0.216]
</p><p>5 9%, giving the best results so far for transitionbased parsing and rivaling the best results overall. [sent-9, score-0.228]
</p><p>6 An open source release of our parser is freely available. [sent-11, score-0.202]
</p><p>7 1 Introduction  Transition-based dependency parsing (Yamada and Matsumoto, 2003; Nivre et al. [sent-12, score-0.39]
</p><p>8 Compared to graph-based dependency parsing, it typically offers linear time complexity and the comparative freedom to define non-local features, as exemplified by the comparison between MaltParser and MSTParser (Nivre et al. [sent-14, score-0.308]
</p><p>9 In the aspect of decoding, beam-search (Johansson and Nugues, 2007; Zhang and Clark, 2008; Huang et al. [sent-18, score-0.052]
</p><p>10 In the aspect of training, global structural  learning has been used to replace local learning on each decision (Zhang and Clark, 2008; Huang et al. [sent-23, score-0.106]
</p><p>11 , 2009), although the effect of global learning has not been separated out and studied alone. [sent-24, score-0.093]
</p><p>12 In this short paper, we study a third aspect in a statistical system: feature definition. [sent-25, score-0.139]
</p><p>13 Representing the type of information a statistical system uses to make predictions, feature templates can be one of the most important factors determining parsing accuracy. [sent-26, score-0.431]
</p><p>14 Various recent attempts have been made to include non-local features into graph-based dependency parsing (Smith and Eisner, 2008; Martins et al. [sent-27, score-0.44]
</p><p>15 Transitionbased parsing, by contrast, can easily accommodate arbitrarily complex representations involving nonlocal features. [sent-29, score-0.168]
</p><p>16 Complex non-local features, such as bracket matching and rhythmic patterns, are used in transition-based constituency parsing (Zhang and Clark, 2009; Wang et al. [sent-30, score-0.147]
</p><p>17 , 2006), and most transitionbased dependency parsers incorporate some nonlocal features, but current practice is nevertheless to use a rather restricted set of features, as exemplified by the default feature models in MaltParser (Nivre et al. [sent-31, score-0.644]
</p><p>18 We explore considerably richer feature  representations and show that they improve parsing accuracy significantly. [sent-33, score-0.234]
</p><p>19 In standard experiments using the Penn Treebank, our parser gets an unlabeled attachment score of 92. [sent-34, score-0.436]
</p><p>20 9%, which is the best result achieved with a transition-based parser and comparable to the state of the art. [sent-35, score-0.166]
</p><p>21 For the Chinese Treebank, our parser gets a score of 86. [sent-36, score-0.166]
</p><p>22 i ac t2io0n11 fo Ar Cssoocmiaptuiotanti foonra Clo Lminpguutiast i ocns:aslh Loirntpgaupisetrics , pages 188–193, 2  The Transition-based Parsing Algorithm  In a typical transition-based parsing process, the input words are put into a queue and partially built structures are organized by a stack. [sent-40, score-0.322]
</p><p>23 A set of shiftreduce actions are defined, which consume words from the queue and build the output parse. [sent-41, score-0.228]
</p><p>24 Recent research have focused on action sets that build projective dependency trees in an arc-eager (Nivre et al. [sent-42, score-0.368]
</p><p>25 (2009) and use the generalized perceptron (Collins, 2002) for global learning and beamsearch for decoding. [sent-46, score-0.054]
</p><p>26 Unlike both earlier globallearning parsers, which only perform unlabeled parsing, we perform labeled parsing by augmenting the Le ftArc and RightArc actions with the set of dependency labels. [sent-47, score-0.585]
</p><p>27 Hence our work is in line with Titov and Henderson (2007) in using labeled transitions with global learning. [sent-48, score-0.092]
</p><p>28 3  Feature Templates  At each step during a parsing process, the parser configuration can be represented by a tuple hS, N, Ai, where S is the stack, N is the queue of incoming words, San ids tAh ei ss tachek s Net iosf dependency arcs that have been built. [sent-50, score-0.769]
</p><p>29 Denoting the top of stack 1It is very likely that the type of features explored in this paper would be beneficial also for the arc-standard system, although the exact same feature templates would not be applicable because of differences in the parsing order. [sent-51, score-0.63]
</p><p>30 duvSS na0i0rishlwgwtera;nvadmN;Src y00sS0ewrhp0dp;;SS0v;r0rNl;pSSNN0w0lwdp;v;lSN;N00Spl pdl;v;lNS0wNvl0;Nl0p;vll; tlS ha0 bipwrhe2dSwsl-0ro;ehlpSd t e0 rhpl2 s rp;S 0N rhpw20lSs;NrpS0l2p0wNrs;2lpSN;0pl2w;pslS0N2l;ps w  –  Table 2: New feature templates. [sent-54, score-0.087]
</p><p>31 word; p POS-tag; vl, vr valency; l dependency label, sl, sr labelset. [sent-55, score-0.349]
</p><p>32 –  –  –  –  with S0, the front items from the queue with N0, N1, and N2, the head of S0 (if any) with S0h, the leftmost and rightmost modifiers of S0 (if any) with  S0l and S0r, respectively, and the leftmost modifier of N0 (if any) with N0l, the baseline features are shown in Table 1. [sent-56, score-0.911]
</p><p>33 These features are mostly taken from Zhang and Clark (2008) and Huang and Sagae (2010), and our parser reproduces the same accuracies as reported by both papers. [sent-57, score-0.268]
</p><p>34 For example, S0pN0wp represents the feature template that takes the word and POS-tag of N0, and combines it with the word of S0. [sent-59, score-0.087]
</p><p>35 In this short paper, we extend the baseline feature templates with the following: Distance between S0 and N0 Direction and distance between a pair of head and modifier have been used in the standard feature templates for maximum spanning tree parsing (McDonald et al. [sent-60, score-1.013]
</p><p>36 Distance information has also been used in the easy-first parser of (Goldberg and Elhadad, 2010). [sent-62, score-0.166]
</p><p>37 We add the distance between S0 and N0 to the feature set by combining it with the word and POS-tag of S0 and N0, as shown in Table 2. [sent-64, score-0.162]
</p><p>38 It is worth noticing that the use of distance information in our transition-based model is different from that in a typical graph-based parser such as MSTParser. [sent-65, score-0.241]
</p><p>39 The distance between S0 and N0 will correspond to the distance between a pair of head and modifier when an Le ftArc action is taken, for example, but not when a Shi ft action is taken. [sent-66, score-0.499]
</p><p>40 Valency of S0 and N0 The number of modifiers to a given head is used by the graph-based submodel of Zhang and Clark (2008) and the models of Martins et al. [sent-67, score-0.243]
</p><p>41 In particular, we calculate the number of left and right modifiers separately, calling them left valency and right valency, respectively. [sent-70, score-0.419]
</p><p>42 Left and right valencies are represented by vl and vr in Table 2, respectively. [sent-71, score-0.117]
</p><p>43 They are combined with the word and POS-tag of S0 and N0 to form new feature templates. [sent-72, score-0.087]
</p><p>44 Again, the use of valency information in our transition-based parser is different from the aforementioned graph-based models. [sent-73, score-0.476]
</p><p>45 In our case, valency information is put into the context of the  shift-reduce process, and used together with each action to give a score to the local decision. [sent-74, score-0.373]
</p><p>46 Unigram information for S0h, S0l, S0r and N0l The head, left/rightmost modifiers of S0 and the leftmost modifier of N0 have been used by most arc-eager transition-based parsers we are aware of through the combination of their POS-tag with information from S0 and N0. [sent-75, score-0.466]
</p><p>47 Such use is exemplified by 190 the feature templates “from three words” in Table 1. [sent-76, score-0.349]
</p><p>48 We further use their word and POS-tag information as “unigram” features in Table 2. [sent-77, score-0.05]
</p><p>49 Moreover, we include the dependency label information in the unigram features, represented by lin the table. [sent-78, score-0.318]
</p><p>50 Third-order features of S0 and N0 Higher-order context features have been used by graph-based dependency parsers to improve accuracies (Carreras, 2007; Koo and Collins, 2010). [sent-81, score-0.474]
</p><p>51 We include information of third order dependency arcs in our new feature templates, when available. [sent-82, score-0.368]
</p><p>52 In  Table 2, S0h2, S0l2, S0r2 and N0l2 refer to the head of S0h, the second leftmost modifier and the second rightmost modifier of S0, and the second leftmost modifier of N0, respectively. [sent-83, score-0.824]
</p><p>53 The new templates include unigram word, POS-tag and dependency labels of S0h2, S0l2, S0r2 and N0l2, as well as POS-tag combinations with S0 and N0. [sent-84, score-0.515]
</p><p>54 Set of dependency labels with S0 and N0 As a more global feature, we include the set of unique dependency labels from the modifiers of S0 and N0. [sent-85, score-0.649]
</p><p>55 This information is combined with the word and POS-tag of S0 and N0 to make feature templates. [sent-86, score-0.087]
</p><p>56 In Table 2, sl and sr stands for the set of labels on the left and right of the head, respectively. [sent-87, score-0.086]
</p><p>57 Bracketed sentences from PTB were transformed into dependency formats using the Penn2Malt tool. [sent-90, score-0.243]
</p><p>58 For all experiments, we set the beam size to 64 for the parser, and report unlabeled and labeled attachment scores (UAS, LAS) and unlabeled exact match (UEM) for evaluation. [sent-94, score-0.457]
</p><p>59 UAS = unlabeled attachment score; UEM = unlabeled exact match. [sent-102, score-0.419]
</p><p>60 UASUEMLAS  beled attachment score; UEM = unlabeled exact match; LAS = labeled attachment score. [sent-103, score-0.519]
</p><p>61 1 Development Experiments Table 3 shows the effect of new features on the development test data for English. [sent-105, score-0.089]
</p><p>62 We start with the baseline features in Table 1, and incrementally add the distance, valency, unigram, third-order and label set feature templates in Table 2. [sent-106, score-0.334]
</p><p>63 Each group of new feature templates improved the accuracies over the previous system, and the final accuracy with all new features was 93. [sent-107, score-0.386]
</p><p>64 2 Table  Final Test Results 4 shows  the final test results  of our  parser for English. [sent-110, score-0.166]
</p><p>65 Our extended parser significantly outperformed the baseline parser, achiev191  UASUEMLAS  ZH&&CS0108; transition8845. [sent-113, score-0.166]
</p><p>66 UAS = unlabeled attachment score; UEM = unlabeled exact match; LAS = labeled attachment score. [sent-121, score-0.623]
</p><p>67 ing the highest attachment score reported for a transition-based parser, comparable to those of the  best graph-based parsers. [sent-122, score-0.166]
</p><p>68 The speed of our baseline parser was 50 sentences per second. [sent-124, score-0.202]
</p><p>69 With all new features added, the speed dropped to 29 sentences per second. [sent-125, score-0.086]
</p><p>70 As an alternative to Penn2Malt, bracketed sentences can also be transformed into Stanford dependencies (De Marneffe et al. [sent-126, score-0.094]
</p><p>71 1% UEM when trained and evaluated on Stanford basic dependencies, which are projective dependency trees. [sent-131, score-0.305]
</p><p>72 (2010) report results on Stanford collapsed dependencies, which allow a word to have multiple heads and therefore cannot be produced by a regular dependency parser. [sent-133, score-0.243]
</p><p>73 3 Chinese Test Results Table 5 shows the results of our final parser, the pure transition-based parser of Zhang and Clark (2008), and the parser of Huang and Sagae (2010) on Chinese. [sent-136, score-0.377]
</p><p>74 5  Conclusion  We have shown that enriching the feature representation significantly improves the accuracy of our transition-based dependency parser. [sent-139, score-0.33]
</p><p>75 The effect of the new features appears to outweigh the effect of combining transition-based and graph-based models, reported by Zhang and Clark (2008), as well as the effect of using dynamic programming, as inHuang and Sagae (2010). [sent-140, score-0.214]
</p><p>76 This shows that feature definition is a crucial aspect of transition-based parsing. [sent-141, score-0.139]
</p><p>77 In fact, some of the new feature templates in this paper, such as distance and valency, are among those which are in the graph-based submodel of Zhang and Clark (2008), but not the transition-based submodel. [sent-142, score-0.427]
</p><p>78 Therefore our new features to some extent achieved the same effect as their model combination. [sent-143, score-0.089]
</p><p>79 The new features are also hard to use in dynamic programming because they add considerable complexity to the parse items. [sent-144, score-0.16]
</p><p>80 Enriched feature representations have been studied as an important factor for improving the accu-  racies of graph-based dependency parsing also. [sent-145, score-0.477]
</p><p>81 Recent research including the use of loopy belief network (Smith and Eisner, 2008), integer linear programming (Martins et al. [sent-146, score-0.101]
</p><p>82 , 2009) and an improved dynamic programming algorithm (Koo and Collins, 2010) can be seen as methods to incorporate nonlocal features into a graph-based model. [sent-147, score-0.249]
</p><p>83 An open source release of our parser, together with trained models for English and Chinese, are freely available. [sent-148, score-0.036]
</p><p>84 Parsing to stan-  ford dependencies: Trade-offs between speed and accuracy. [sent-158, score-0.036]
</p><p>85 Dependency parsing and domain adaptation with LR models and parser ensembles. [sent-228, score-0.313]
</p><p>86 A tale of two parsers: investigating and combining graph-based and transition-based dependency parsing using beamsearch. [sent-249, score-0.39]
</p><p>87 Transition-based parsing of the Chinese Treebank using a global discriminative model. [sent-253, score-0.201]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('valency', 0.31), ('dependency', 0.243), ('sagae', 0.223), ('templates', 0.197), ('clark', 0.18), ('queue', 0.175), ('nivre', 0.166), ('attachment', 0.166), ('parser', 0.166), ('uem', 0.157), ('modifier', 0.157), ('ftarc', 0.155), ('zhang', 0.148), ('parsing', 0.147), ('koo', 0.145), ('huang', 0.139), ('leftmost', 0.121), ('modifiers', 0.109), ('unlabeled', 0.104), ('stack', 0.104), ('yue', 0.104), ('uas', 0.091), ('mcdonald', 0.091), ('nonlocal', 0.089), ('joakim', 0.088), ('las', 0.087), ('maltparser', 0.087), ('feature', 0.087), ('martins', 0.081), ('treebank', 0.081), ('transitionbased', 0.081), ('parsers', 0.079), ('rightarc', 0.078), ('uasuemlas', 0.078), ('unigram', 0.075), ('distance', 0.075), ('collins', 0.074), ('submodel', 0.068), ('front', 0.067), ('head', 0.066), ('iwpt', 0.065), ('exemplified', 0.065), ('chinese', 0.064), ('marneffe', 0.064), ('programming', 0.063), ('action', 0.063), ('vr', 0.063), ('pops', 0.063), ('projective', 0.062), ('yamada', 0.06), ('hoef', 0.056), ('prague', 0.056), ('czech', 0.055), ('global', 0.054), ('pushes', 0.054), ('vl', 0.054), ('actions', 0.053), ('accuracies', 0.052), ('bracketed', 0.052), ('aspect', 0.052), ('features', 0.05), ('cer', 0.05), ('ctb', 0.048), ('mstparser', 0.048), ('dynamic', 0.047), ('smith', 0.046), ('exact', 0.045), ('penn', 0.045), ('pure', 0.045), ('titov', 0.045), ('rightmost', 0.045), ('ptb', 0.045), ('shi', 0.045), ('accommodate', 0.043), ('carreras', 0.043), ('sl', 0.043), ('sr', 0.043), ('le', 0.043), ('xavier', 0.042), ('dependencies', 0.042), ('goldberg', 0.042), ('terry', 0.041), ('johan', 0.041), ('conll', 0.04), ('johansson', 0.04), ('uppsala', 0.04), ('effect', 0.039), ('arcs', 0.038), ('belief', 0.038), ('jens', 0.038), ('hawaii', 0.038), ('ryan', 0.038), ('labeled', 0.038), ('removes', 0.038), ('matsumoto', 0.036), ('speed', 0.036), ('freely', 0.036), ('arbitrarily', 0.036), ('row', 0.036), ('kenji', 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="309-tfidf-1" href="./acl-2011-Transition-based_Dependency_Parsing_with_Rich_Non-local_Features.html">309 acl-2011-Transition-based Dependency Parsing with Rich Non-local Features</a></p>
<p>Author: Yue Zhang ; Joakim Nivre</p><p>Abstract: Transition-based dependency parsers generally use heuristic decoding algorithms but can accommodate arbitrarily rich feature representations. In this paper, we show that we can improve the accuracy of such parsers by considering even richer feature sets than those employed in previous systems. In the standard Penn Treebank setup, our novel features improve attachment score form 91.4% to 92.9%, giving the best results so far for transitionbased parsing and rivaling the best results overall. For the Chinese Treebank, they give a signficant improvement of the state of the art. An open source release of our parser is freely available.</p><p>2 0.30236697 <a title="309-tfidf-2" href="./acl-2011-Shift-Reduce_CCG_Parsing.html">282 acl-2011-Shift-Reduce CCG Parsing</a></p>
<p>Author: Yue Zhang ; Stephen Clark</p><p>Abstract: CCGs are directly compatible with binarybranching bottom-up parsing algorithms, in particular CKY and shift-reduce algorithms. While the chart-based approach has been the dominant approach for CCG, the shift-reduce method has been little explored. In this paper, we develop a shift-reduce CCG parser using a discriminative model and beam search, and compare its strengths and weaknesses with the chart-based C&C; parser. We study different errors made by the two parsers, and show that the shift-reduce parser gives competitive accuracies compared to C&C.; Considering our use of a small beam, and given the high ambiguity levels in an automatically-extracted grammar and the amount of information in the CCG lexical categories which form the shift actions, this is a surprising result.</p><p>3 0.29905745 <a title="309-tfidf-3" href="./acl-2011-Getting_the_Most_out_of_Transition-based_Dependency_Parsing.html">143 acl-2011-Getting the Most out of Transition-based Dependency Parsing</a></p>
<p>Author: Jinho D. Choi ; Martha Palmer</p><p>Abstract: This paper suggests two ways of improving transition-based, non-projective dependency parsing. First, we add a transition to an existing non-projective parsing algorithm, so it can perform either projective or non-projective parsing as needed. Second, we present a bootstrapping technique that narrows down discrepancies between gold-standard and automatic parses used as features. The new addition to the algorithm shows a clear advantage in parsing speed. The bootstrapping technique gives a significant improvement to parsing accuracy, showing near state-of-theart performance with respect to other parsing approaches evaluated on the same data set.</p><p>4 0.28950498 <a title="309-tfidf-4" href="./acl-2011-An_Ensemble_Model_that_Combines_Syntactic_and_Semantic_Clustering_for_Discriminative_Dependency_Parsing.html">39 acl-2011-An Ensemble Model that Combines Syntactic and Semantic Clustering for Discriminative Dependency Parsing</a></p>
<p>Author: Gholamreza Haffari ; Marzieh Razavi ; Anoop Sarkar</p><p>Abstract: We combine multiple word representations based on semantic clusters extracted from the (Brown et al., 1992) algorithm and syntactic clusters obtained from the Berkeley parser (Petrov et al., 2006) in order to improve discriminative dependency parsing in the MSTParser framework (McDonald et al., 2005). We also provide an ensemble method for combining diverse cluster-based models. The two contributions together significantly improves unlabeled dependency accuracy from 90.82% to 92. 13%.</p><p>5 0.26870847 <a title="309-tfidf-5" href="./acl-2011-Improving_Dependency_Parsing_with_Semantic_Classes.html">167 acl-2011-Improving Dependency Parsing with Semantic Classes</a></p>
<p>Author: Eneko Agirre ; Kepa Bengoetxea ; Koldo Gojenola ; Joakim Nivre</p><p>Abstract: This paper presents the introduction of WordNet semantic classes in a dependency parser, obtaining improvements on the full Penn Treebank for the first time. We tried different combinations of some basic semantic classes and word sense disambiguation algorithms. Our experiments show that selecting the adequate combination of semantic features on development data is key for success. Given the basic nature of the semantic classes and word sense disambiguation algorithms used, we think there is ample room for future improvements. 1</p><p>6 0.24661343 <a title="309-tfidf-6" href="./acl-2011-Exploiting_Web-Derived_Selectional_Preference_to_Improve_Statistical_Dependency_Parsing.html">127 acl-2011-Exploiting Web-Derived Selectional Preference to Improve Statistical Dependency Parsing</a></p>
<p>7 0.20992114 <a title="309-tfidf-7" href="./acl-2011-Web-Scale_Features_for_Full-Scale_Parsing.html">333 acl-2011-Web-Scale Features for Full-Scale Parsing</a></p>
<p>8 0.19418043 <a title="309-tfidf-8" href="./acl-2011-Effects_of_Noun_Phrase_Bracketing_in_Dependency_Parsing_and_Machine_Translation.html">111 acl-2011-Effects of Noun Phrase Bracketing in Dependency Parsing and Machine Translation</a></p>
<p>9 0.16517845 <a title="309-tfidf-9" href="./acl-2011-Dynamic_Programming_Algorithms_for_Transition-Based_Dependency_Parsers.html">107 acl-2011-Dynamic Programming Algorithms for Transition-Based Dependency Parsers</a></p>
<p>10 0.1645636 <a title="309-tfidf-10" href="./acl-2011-Better_Automatic_Treebank_Conversion_Using_A_Feature-Based_Approach.html">59 acl-2011-Better Automatic Treebank Conversion Using A Feature-Based Approach</a></p>
<p>11 0.1642139 <a title="309-tfidf-11" href="./acl-2011-Automatic_Detection_and_Correction_of_Errors_in_Dependency_Treebanks.html">48 acl-2011-Automatic Detection and Correction of Errors in Dependency Treebanks</a></p>
<p>12 0.13166934 <a title="309-tfidf-12" href="./acl-2011-Ordering_Prenominal_Modifiers_with_a_Reranking_Approach.html">237 acl-2011-Ordering Prenominal Modifiers with a Reranking Approach</a></p>
<p>13 0.13161957 <a title="309-tfidf-13" href="./acl-2011-Neutralizing_Linguistically_Problematic_Annotations_in_Unsupervised_Dependency_Parsing_Evaluation.html">230 acl-2011-Neutralizing Linguistically Problematic Annotations in Unsupervised Dependency Parsing Evaluation</a></p>
<p>14 0.13098803 <a title="309-tfidf-14" href="./acl-2011-Parsing_the_Internal_Structure_of_Words%3A_A_New_Paradigm_for_Chinese_Word_Segmentation.html">241 acl-2011-Parsing the Internal Structure of Words: A New Paradigm for Chinese Word Segmentation</a></p>
<p>15 0.12352093 <a title="309-tfidf-15" href="./acl-2011-Semi-Supervised_Modeling_for_Prenominal_Modifier_Ordering.html">275 acl-2011-Semi-Supervised Modeling for Prenominal Modifier Ordering</a></p>
<p>16 0.12098935 <a title="309-tfidf-16" href="./acl-2011-Improving_Arabic_Dependency_Parsing_with_Form-based_and_Functional_Morphological_Features.html">164 acl-2011-Improving Arabic Dependency Parsing with Form-based and Functional Morphological Features</a></p>
<p>17 0.11659877 <a title="309-tfidf-17" href="./acl-2011-Partial_Parsing_from_Bitext_Projections.html">243 acl-2011-Partial Parsing from Bitext Projections</a></p>
<p>18 0.11465282 <a title="309-tfidf-18" href="./acl-2011-A_Comparison_of_Loopy_Belief_Propagation_and_Dual_Decomposition_for_Integrated_CCG_Supertagging_and_Parsing.html">5 acl-2011-A Comparison of Loopy Belief Propagation and Dual Decomposition for Integrated CCG Supertagging and Parsing</a></p>
<p>19 0.1120014 <a title="309-tfidf-19" href="./acl-2011-Joint_Training_of_Dependency_Parsing_Filters_through_Latent_Support_Vector_Machines.html">186 acl-2011-Joint Training of Dependency Parsing Filters through Latent Support Vector Machines</a></p>
<p>20 0.1087886 <a title="309-tfidf-20" href="./acl-2011-A_Discriminative_Model_for_Joint_Morphological_Disambiguation_and_Dependency_Parsing.html">10 acl-2011-A Discriminative Model for Joint Morphological Disambiguation and Dependency Parsing</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.235), (1, -0.066), (2, -0.079), (3, -0.402), (4, -0.042), (5, -0.068), (6, 0.063), (7, 0.128), (8, 0.146), (9, -0.012), (10, 0.092), (11, 0.077), (12, 0.037), (13, -0.24), (14, -0.038), (15, 0.071), (16, 0.036), (17, 0.037), (18, -0.009), (19, -0.052), (20, -0.095), (21, -0.015), (22, 0.007), (23, 0.045), (24, 0.073), (25, -0.176), (26, 0.029), (27, 0.027), (28, 0.015), (29, 0.05), (30, -0.027), (31, -0.035), (32, -0.002), (33, 0.018), (34, -0.058), (35, 0.054), (36, 0.003), (37, 0.035), (38, 0.054), (39, 0.151), (40, 0.05), (41, 0.048), (42, 0.012), (43, 0.049), (44, -0.031), (45, 0.014), (46, -0.021), (47, 0.024), (48, 0.001), (49, -0.003)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97153699 <a title="309-lsi-1" href="./acl-2011-Transition-based_Dependency_Parsing_with_Rich_Non-local_Features.html">309 acl-2011-Transition-based Dependency Parsing with Rich Non-local Features</a></p>
<p>Author: Yue Zhang ; Joakim Nivre</p><p>Abstract: Transition-based dependency parsers generally use heuristic decoding algorithms but can accommodate arbitrarily rich feature representations. In this paper, we show that we can improve the accuracy of such parsers by considering even richer feature sets than those employed in previous systems. In the standard Penn Treebank setup, our novel features improve attachment score form 91.4% to 92.9%, giving the best results so far for transitionbased parsing and rivaling the best results overall. For the Chinese Treebank, they give a signficant improvement of the state of the art. An open source release of our parser is freely available.</p><p>2 0.89799124 <a title="309-lsi-2" href="./acl-2011-Getting_the_Most_out_of_Transition-based_Dependency_Parsing.html">143 acl-2011-Getting the Most out of Transition-based Dependency Parsing</a></p>
<p>Author: Jinho D. Choi ; Martha Palmer</p><p>Abstract: This paper suggests two ways of improving transition-based, non-projective dependency parsing. First, we add a transition to an existing non-projective parsing algorithm, so it can perform either projective or non-projective parsing as needed. Second, we present a bootstrapping technique that narrows down discrepancies between gold-standard and automatic parses used as features. The new addition to the algorithm shows a clear advantage in parsing speed. The bootstrapping technique gives a significant improvement to parsing accuracy, showing near state-of-theart performance with respect to other parsing approaches evaluated on the same data set.</p><p>3 0.86403304 <a title="309-lsi-3" href="./acl-2011-Exploiting_Web-Derived_Selectional_Preference_to_Improve_Statistical_Dependency_Parsing.html">127 acl-2011-Exploiting Web-Derived Selectional Preference to Improve Statistical Dependency Parsing</a></p>
<p>Author: Guangyou Zhou ; Jun Zhao ; Kang Liu ; Li Cai</p><p>Abstract: In this paper, we present a novel approach which incorporates the web-derived selectional preferences to improve statistical dependency parsing. Conventional selectional preference learning methods have usually focused on word-to-class relations, e.g., a verb selects as its subject a given nominal class. This paper extends previous work to wordto-word selectional preferences by using webscale data. Experiments show that web-scale data improves statistical dependency parsing, particularly for long dependency relationships. There is no data like more data, performance improves log-linearly with the number of parameters (unique N-grams). More importantly, when operating on new domains, we show that using web-derived selectional preferences is essential for achieving robust performance.</p><p>4 0.84190267 <a title="309-lsi-4" href="./acl-2011-An_Ensemble_Model_that_Combines_Syntactic_and_Semantic_Clustering_for_Discriminative_Dependency_Parsing.html">39 acl-2011-An Ensemble Model that Combines Syntactic and Semantic Clustering for Discriminative Dependency Parsing</a></p>
<p>Author: Gholamreza Haffari ; Marzieh Razavi ; Anoop Sarkar</p><p>Abstract: We combine multiple word representations based on semantic clusters extracted from the (Brown et al., 1992) algorithm and syntactic clusters obtained from the Berkeley parser (Petrov et al., 2006) in order to improve discriminative dependency parsing in the MSTParser framework (McDonald et al., 2005). We also provide an ensemble method for combining diverse cluster-based models. The two contributions together significantly improves unlabeled dependency accuracy from 90.82% to 92. 13%.</p><p>5 0.76972032 <a title="309-lsi-5" href="./acl-2011-Dynamic_Programming_Algorithms_for_Transition-Based_Dependency_Parsers.html">107 acl-2011-Dynamic Programming Algorithms for Transition-Based Dependency Parsers</a></p>
<p>Author: Marco Kuhlmann ; Carlos Gomez-Rodriguez ; Giorgio Satta</p><p>Abstract: We develop a general dynamic programming technique for the tabulation of transition-based dependency parsers, and apply it to obtain novel, polynomial-time algorithms for parsing with the arc-standard and arc-eager models. We also show how to reverse our technique to obtain new transition-based dependency parsers from existing tabular methods. Additionally, we provide a detailed discussion of the conditions under which the feature models commonly used in transition-based parsing can be integrated into our algorithms.</p><p>6 0.76608628 <a title="309-lsi-6" href="./acl-2011-Effects_of_Noun_Phrase_Bracketing_in_Dependency_Parsing_and_Machine_Translation.html">111 acl-2011-Effects of Noun Phrase Bracketing in Dependency Parsing and Machine Translation</a></p>
<p>7 0.73297971 <a title="309-lsi-7" href="./acl-2011-Neutralizing_Linguistically_Problematic_Annotations_in_Unsupervised_Dependency_Parsing_Evaluation.html">230 acl-2011-Neutralizing Linguistically Problematic Annotations in Unsupervised Dependency Parsing Evaluation</a></p>
<p>8 0.72998214 <a title="309-lsi-8" href="./acl-2011-Shift-Reduce_CCG_Parsing.html">282 acl-2011-Shift-Reduce CCG Parsing</a></p>
<p>9 0.72491193 <a title="309-lsi-9" href="./acl-2011-Partial_Parsing_from_Bitext_Projections.html">243 acl-2011-Partial Parsing from Bitext Projections</a></p>
<p>10 0.71456242 <a title="309-lsi-10" href="./acl-2011-Web-Scale_Features_for_Full-Scale_Parsing.html">333 acl-2011-Web-Scale Features for Full-Scale Parsing</a></p>
<p>11 0.71319878 <a title="309-lsi-11" href="./acl-2011-Improving_Dependency_Parsing_with_Semantic_Classes.html">167 acl-2011-Improving Dependency Parsing with Semantic Classes</a></p>
<p>12 0.70640105 <a title="309-lsi-12" href="./acl-2011-Optimistic_Backtracking_-_A_Backtracking_Overlay_for_Deterministic_Incremental_Parsing.html">236 acl-2011-Optimistic Backtracking - A Backtracking Overlay for Deterministic Incremental Parsing</a></p>
<p>13 0.68375403 <a title="309-lsi-13" href="./acl-2011-Automatic_Detection_and_Correction_of_Errors_in_Dependency_Treebanks.html">48 acl-2011-Automatic Detection and Correction of Errors in Dependency Treebanks</a></p>
<p>14 0.67648762 <a title="309-lsi-14" href="./acl-2011-Better_Automatic_Treebank_Conversion_Using_A_Feature-Based_Approach.html">59 acl-2011-Better Automatic Treebank Conversion Using A Feature-Based Approach</a></p>
<p>15 0.64751917 <a title="309-lsi-15" href="./acl-2011-Temporal_Restricted_Boltzmann_Machines_for_Dependency_Parsing.html">295 acl-2011-Temporal Restricted Boltzmann Machines for Dependency Parsing</a></p>
<p>16 0.60518622 <a title="309-lsi-16" href="./acl-2011-Joint_Training_of_Dependency_Parsing_Filters_through_Latent_Support_Vector_Machines.html">186 acl-2011-Joint Training of Dependency Parsing Filters through Latent Support Vector Machines</a></p>
<p>17 0.55440956 <a title="309-lsi-17" href="./acl-2011-Joint_Hebrew_Segmentation_and_Parsing_using_a_PCFGLA_Lattice_Parser.html">184 acl-2011-Joint Hebrew Segmentation and Parsing using a PCFGLA Lattice Parser</a></p>
<p>18 0.53605741 <a title="309-lsi-18" href="./acl-2011-Learning_Condensed_Feature_Representations_from_Large_Unsupervised_Data_Sets_for_Supervised_Learning.html">199 acl-2011-Learning Condensed Feature Representations from Large Unsupervised Data Sets for Supervised Learning</a></p>
<p>19 0.51804698 <a title="309-lsi-19" href="./acl-2011-Reversible_Stochastic_Attribute-Value_Grammars.html">267 acl-2011-Reversible Stochastic Attribute-Value Grammars</a></p>
<p>20 0.51655543 <a title="309-lsi-20" href="./acl-2011-Data_point_selection_for_cross-language_adaptation_of_dependency_parsers.html">92 acl-2011-Data point selection for cross-language adaptation of dependency parsers</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.017), (17, 0.061), (26, 0.017), (28, 0.193), (37, 0.174), (39, 0.115), (41, 0.069), (55, 0.042), (59, 0.034), (72, 0.014), (91, 0.027), (96, 0.113), (97, 0.048), (98, 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.83668905 <a title="309-lda-1" href="./acl-2011-Transition-based_Dependency_Parsing_with_Rich_Non-local_Features.html">309 acl-2011-Transition-based Dependency Parsing with Rich Non-local Features</a></p>
<p>Author: Yue Zhang ; Joakim Nivre</p><p>Abstract: Transition-based dependency parsers generally use heuristic decoding algorithms but can accommodate arbitrarily rich feature representations. In this paper, we show that we can improve the accuracy of such parsers by considering even richer feature sets than those employed in previous systems. In the standard Penn Treebank setup, our novel features improve attachment score form 91.4% to 92.9%, giving the best results so far for transitionbased parsing and rivaling the best results overall. For the Chinese Treebank, they give a signficant improvement of the state of the art. An open source release of our parser is freely available.</p><p>2 0.81008714 <a title="309-lda-2" href="./acl-2011-Reversible_Stochastic_Attribute-Value_Grammars.html">267 acl-2011-Reversible Stochastic Attribute-Value Grammars</a></p>
<p>Author: Daniel de Kok ; Barbara Plank ; Gertjan van Noord</p><p>Abstract: An attractive property of attribute-value grammars is their reversibility. Attribute-value grammars are usually coupled with separate statistical components for parse selection and fluency ranking. We propose reversible stochastic attribute-value grammars, in which a single statistical model is employed both for parse selection and fluency ranking.</p><p>3 0.78990149 <a title="309-lda-3" href="./acl-2011-Judging_Grammaticality_with_Tree_Substitution_Grammar_Derivations.html">188 acl-2011-Judging Grammaticality with Tree Substitution Grammar Derivations</a></p>
<p>Author: Matt Post</p><p>Abstract: In this paper, we show that local features computed from the derivations of tree substitution grammars such as the identify of particular fragments, and a count of large and small fragments are useful in binary grammatical classification tasks. Such features outperform n-gram features and various model scores by a wide margin. Although they fall short of the performance of the hand-crafted feature set of Charniak and Johnson (2005) developed for parse tree reranking, they do so with an order of magnitude fewer features. Furthermore, since the TSGs employed are learned in a Bayesian setting, the use of their derivations can be viewed as the automatic discovery of tree patterns useful for classification. On the BLLIP dataset, we achieve an accuracy of 89.9% in discriminating between grammatical text and samples from an n-gram language model. — —</p><p>4 0.76208335 <a title="309-lda-4" href="./acl-2011-Optimal_and_Syntactically-Informed_Decoding_for_Monolingual_Phrase-Based_Alignment.html">235 acl-2011-Optimal and Syntactically-Informed Decoding for Monolingual Phrase-Based Alignment</a></p>
<p>Author: Kapil Thadani ; Kathleen McKeown</p><p>Abstract: The task of aligning corresponding phrases across two related sentences is an important component of approaches for natural language problems such as textual inference, paraphrase detection and text-to-text generation. In this work, we examine a state-of-the-art structured prediction model for the alignment task which uses a phrase-based representation and is forced to decode alignments using an approximate search approach. We propose instead a straightforward exact decoding technique based on integer linear programming that yields order-of-magnitude improvements in decoding speed. This ILP-based decoding strategy permits us to consider syntacticallyinformed constraints on alignments which significantly increase the precision of the model.</p><p>5 0.75157976 <a title="309-lda-5" href="./acl-2011-A_Discriminative_Model_for_Joint_Morphological_Disambiguation_and_Dependency_Parsing.html">10 acl-2011-A Discriminative Model for Joint Morphological Disambiguation and Dependency Parsing</a></p>
<p>Author: John Lee ; Jason Naradowsky ; David A. Smith</p><p>Abstract: Most previous studies of morphological disambiguation and dependency parsing have been pursued independently. Morphological taggers operate on n-grams and do not take into account syntactic relations; parsers use the “pipeline” approach, assuming that morphological information has been separately obtained. However, in morphologically-rich languages, there is often considerable interaction between morphology and syntax, such that neither can be disambiguated without the other. In this paper, we propose a discriminative model that jointly infers morphological properties and syntactic structures. In evaluations on various highly-inflected languages, this joint model outperforms both a baseline tagger in morphological disambiguation, and a pipeline parser in head selection.</p><p>6 0.74110425 <a title="309-lda-6" href="./acl-2011-Joint_Training_of_Dependency_Parsing_Filters_through_Latent_Support_Vector_Machines.html">186 acl-2011-Joint Training of Dependency Parsing Filters through Latent Support Vector Machines</a></p>
<p>7 0.73623461 <a title="309-lda-7" href="./acl-2011-Shift-Reduce_CCG_Parsing.html">282 acl-2011-Shift-Reduce CCG Parsing</a></p>
<p>8 0.73622948 <a title="309-lda-8" href="./acl-2011-Data_point_selection_for_cross-language_adaptation_of_dependency_parsers.html">92 acl-2011-Data point selection for cross-language adaptation of dependency parsers</a></p>
<p>9 0.73326045 <a title="309-lda-9" href="./acl-2011-Effects_of_Noun_Phrase_Bracketing_in_Dependency_Parsing_and_Machine_Translation.html">111 acl-2011-Effects of Noun Phrase Bracketing in Dependency Parsing and Machine Translation</a></p>
<p>10 0.73152649 <a title="309-lda-10" href="./acl-2011-The_Surprising_Variance_in_Shortest-Derivation_Parsing.html">300 acl-2011-The Surprising Variance in Shortest-Derivation Parsing</a></p>
<p>11 0.73123085 <a title="309-lda-11" href="./acl-2011-Prefix_Probability_for_Probabilistic_Synchronous_Context-Free_Grammars.html">250 acl-2011-Prefix Probability for Probabilistic Synchronous Context-Free Grammars</a></p>
<p>12 0.73012 <a title="309-lda-12" href="./acl-2011-Event_Extraction_as_Dependency_Parsing.html">122 acl-2011-Event Extraction as Dependency Parsing</a></p>
<p>13 0.72965479 <a title="309-lda-13" href="./acl-2011-Using_Multiple_Sources_to_Construct_a_Sentiment_Sensitive_Thesaurus_for_Cross-Domain_Sentiment_Classification.html">332 acl-2011-Using Multiple Sources to Construct a Sentiment Sensitive Thesaurus for Cross-Domain Sentiment Classification</a></p>
<p>14 0.72451019 <a title="309-lda-14" href="./acl-2011-Coreference_Resolution_with_World_Knowledge.html">85 acl-2011-Coreference Resolution with World Knowledge</a></p>
<p>15 0.72247177 <a title="309-lda-15" href="./acl-2011-Automatically_Extracting_Polarity-Bearing_Topics_for_Cross-Domain_Sentiment_Classification.html">54 acl-2011-Automatically Extracting Polarity-Bearing Topics for Cross-Domain Sentiment Classification</a></p>
<p>16 0.7208485 <a title="309-lda-16" href="./acl-2011-Domain_Adaptation_by_Constraining_Inter-Domain_Variability_of_Latent_Feature_Representation.html">103 acl-2011-Domain Adaptation by Constraining Inter-Domain Variability of Latent Feature Representation</a></p>
<p>17 0.71879792 <a title="309-lda-17" href="./acl-2011-Learning_Hierarchical_Translation_Structure_with_Linguistic_Annotations.html">202 acl-2011-Learning Hierarchical Translation Structure with Linguistic Annotations</a></p>
<p>18 0.71821892 <a title="309-lda-18" href="./acl-2011-Exploiting_Syntactico-Semantic_Structures_for_Relation_Extraction.html">126 acl-2011-Exploiting Syntactico-Semantic Structures for Relation Extraction</a></p>
<p>19 0.71646482 <a title="309-lda-19" href="./acl-2011-Which_Noun_Phrases_Denote_Which_Concepts%3F.html">334 acl-2011-Which Noun Phrases Denote Which Concepts?</a></p>
<p>20 0.71359456 <a title="309-lda-20" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
