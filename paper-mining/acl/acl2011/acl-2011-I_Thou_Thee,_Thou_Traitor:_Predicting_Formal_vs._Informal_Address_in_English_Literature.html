<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>157 acl-2011-I Thou Thee, Thou Traitor: Predicting Formal vs. Informal Address in English Literature</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-157" href="#">acl2011-157</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>157 acl-2011-I Thou Thee, Thou Traitor: Predicting Formal vs. Informal Address in English Literature</h1>
<br/><p>Source: <a title="acl-2011-157-pdf" href="http://aclweb.org/anthology//P/P11/P11-2082.pdf">pdf</a></p><p>Author: Manaal Faruqui ; Sebastian Pado</p><p>Abstract: In contrast to many languages (like Russian or French), modern English does not distinguish formal and informal (“T/V”) address overtly, for example by pronoun choice. We describe an ongoing study which investigates to what degree the T/V distinction is recoverable in English text, and with what textual features it correlates. Our findings are: (a) human raters can label English utterances as T or V fairly well, given sufficient context; (b), lexical cues can predict T/V almost at human level.</p><p>Reference: <a title="acl-2011-157-reference" href="../acl2011_reference/acl-2011-I_Thou_Thee%2C_Thou_Traitor%3A_Predicting_Formal_vs._Informal_Address_in_English_Literature_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 manaal far@ gmai l com Abstract In contrast to many languages (like Russian or French), modern English does not distinguish formal and informal (“T/V”) address overtly, for example by pronoun choice. [sent-3, score-0.802]
</p><p>2 We describe an ongoing study which investigates to what degree the T/V distinction is recoverable in English text, and with what textual features it correlates. [sent-4, score-0.333]
</p><p>3 Our findings are: (a) human raters can label English utterances as T or V fairly well, given sufficient context; (b), lexical cues can predict T/V almost at human level. [sent-5, score-0.355]
</p><p>4 1 Introduction In many Indo-European languages, such as French,  German, or Hindi, there are two pronouns corresponding to the English you. [sent-6, score-0.277]
</p><p>5 This distinction is generally referred to as the T/V dichotomy, from the Latin pronouns tu (informal, T) and vos (formal, V) (Brown and Gilman, 1960). [sent-7, score-0.608]
</p><p>6 The V form can express neutrality or polite distance and is used to address socially superiors. [sent-8, score-0.145]
</p><p>7 The T form is employed for friends or addressees of lower social standing, and implies solidarity or lack of formality. [sent-9, score-0.187]
</p><p>8 Some examples for V pronouns in different languages are Sie (German), Vous (French), and aAp [Aap] (Hindi). [sent-10, score-0.351]
</p><p>9 English used to have a T/V distinction until the 18th century, using you as V and thou as T pronoun. [sent-13, score-0.432]
</p><p>10 However, in contemporary English, you has taken over both uses, and the T/V distinction is not marked morphosyntactically any more. [sent-14, score-0.285]
</p><p>11 This makes generation in English and translation into English easy. [sent-15, score-0.075]
</p><p>12 de Conversely, the extraction of social information from texts, and translation from English into languages with a T/V distinction is very difficult. [sent-18, score-0.536]
</p><p>13 In this paper, we investigate the possibility to recover the T/V distinction based on monolingual English text. [sent-19, score-0.285]
</p><p>14 We first demonstrate that annotators can assign T/V labels to English utterances fairly well (but not perfectly). [sent-20, score-0.217]
</p><p>15 To identify features that indicate T and V, we create a parallel English–German corpus of literary texts and preliminarily identify features that correlate with formal address (like titles, and formulaic language) as well as informal address. [sent-21, score-0.716]
</p><p>16 Our results could be useful, for example, for MT from English into languages that distinguish T and V, although we did not test this prediction with the limits of a short paper. [sent-22, score-0.074]
</p><p>17 Other examples from the literature include morphology (Fraser, 2009) and tense (Schiehlen, 1998). [sent-24, score-0.042]
</p><p>18 The particular problem of T/V address has been considered in the context of translation into Japanese (Hobbs and Kameyama, 1990; Kanayama, 2003) and generation (Bateman, 1988), but only on the context of knowledge-rich methods. [sent-25, score-0.183]
</p><p>19 As for data-driven studies, we are only aware of Li and Yarowsky’s (2008) work, who learn pairs of formal and informal constructions in Chinese where T/V is expressed mainly in construction choice. [sent-26, score-0.357]
</p><p>20 However, these studies are generally not computational in nature, and most of their observations and predictions are difficult to operationalize. [sent-32, score-0.039]
</p><p>21 1 Data Selection We chose literary texts to build a parallel corpus for the investigation of the T/V distinction. [sent-34, score-0.22]
</p><p>22 The main reason is that commonly used non-literary collections like EUROPARL (Koehn, 2005) consist almost exclusively of formal interactions and are therefore of no use to us. [sent-35, score-0.148]
</p><p>23 Fortunately, many 18th and 19th century texts are freely available in several languages. [sent-36, score-0.117]
</p><p>24 We identified 115 novels among the texts provided by Project Gutenberg (English) and Project Gutenberg-DE (German) that were available in both languages, with a total of 0. [sent-37, score-0.292]
</p><p>25 We decided to exclude plays and poems as they often include partial sentences and structures that are difficult to align. [sent-40, score-0.151]
</p><p>26 2 Data Preparation As the German and English novels come from two different websites, they were not coherent in their structure. [sent-42, score-0.231]
</p><p>27 To  some extent the chapter numbers and titles occurring at the beginning of each chapter were cleared as well. [sent-44, score-0.089]
</p><p>28 The files were then formatted to contain one sentence per line and a blank line was inserted to preserve the segmentation information. [sent-45, score-0.037]
</p><p>29 We obtained a comparable corpus of English and German novels using the above pre-processing. [sent-47, score-0.231]
</p><p>30 The files in the corpus were sentence-aligned using Gargantuan (Braune and Fraser, 2010), an aligner that supports one-to-many alignments. [sent-48, score-0.048]
</p><p>31 In order to do this, we need to decide for as many English utterances in our corpus as possible whether they instantiate formal or informal address. [sent-59, score-0.406]
</p><p>32 Given that we have a parallel corpus where the German side overtly realizes T and V, this is a classical case of annotation projection (Yarowsky and Ngai, 2001): We transfer the German T/V information onto the English side to create an annotated English corpus. [sent-60, score-0.375]
</p><p>33 These pronouns indicate T and V, but due to their ambiguity, it is impossible to simply interpret their presence or absense as T or V. [sent-64, score-0.277]
</p><p>34 The only unambiguous pronoun is du, which expresses (singular) T (Rule 1). [sent-66, score-0.107]
</p><p>35 The V pronoun for singular, sie, doubles as the pronoun for third person (singular and plural), which is neutral with respect to T/V. [sent-67, score-0.263]
</p><p>36 Since TreeTagger does not provide person information, the only indicator that is available is capitalization: Sie is 2nd person V. [sent-68, score-0.098]
</p><p>37 However, since all words are capitalized in utterance-initial positions, we only assign the label V in non-initial positions (Rule 2). [sent-69, score-0.12]
</p><p>38 2 Finally, ihr is also ambiguous: non-capitalized, it is used as T plural (Rule 3); capitalized, it is used as an archaic alternative to Sie for V plural (Rule 4). [sent-70, score-0.297]
</p><p>39 These rules leave a substantial number of instances of German second person pronouns unlabeled; we cover somewhat more than half of all pronouns. [sent-71, score-0.326]
</p><p>40 5M German sentences we  obtained about 15% labeled sentences (45K for V and 30K for T). [sent-73, score-0.146]
</p><p>41 On the German side, we assign the T/V labels to pronouns, and the most straightforward way of setting up annotation projection would be to label their word-aligned English pronouns as T/V. [sent-76, score-0.447]
</p><p>42 However, pronouns are not necessarily translated into pronouns; additionally, we found word alignment accuracy for pronouns, as a function of word class, to be far from perfect. [sent-77, score-0.277]
</p><p>43 For these reasons, we decided to treat complete sentences as either T or V. [sent-78, score-0.112]
</p><p>44 This means that sentence alignment is sufficient for projection, but English sentences can receive conflicting labels, if a German sentence contains both a T and a V label. [sent-79, score-0.073]
</p><p>45 However, this occurs very rarely: of the 76K German sentences with T or V pronouns, only 515, or less than 1%, contain both. [sent-80, score-0.073]
</p><p>46 Our projection on the English side results in 53K V and 35K T sentences, of which 73 1 are labeled as both T and V. [sent-81, score-0.128]
</p><p>47 3 Finally, from the English labeled sentences we ex-  tracted a training set with 72 novels (63K sentences) and a test set with 21 novels (15K  sentences). [sent-82, score-0.535]
</p><p>48 4  3  Experiment 1: Human Annotation  The purpose of our first experiment is to investigate how well the T/V distinction can be made in English by human raters, and on the basis ofwhat information. [sent-83, score-0.327]
</p><p>49 We extracted 100 random sentences from the training set. [sent-84, score-0.073]
</p><p>50 Two annotators with advanced knowledge of 2An initial position is defined as a position after a sentence boundary (POS “$. [sent-85, score-0.075]
</p><p>51 3Our sentence aligner supports one-to-many alignments and often aligns single German to multiple English sentences. [sent-87, score-0.048]
</p><p>52 469 Acc (Ann1)  Acc (Ann2)  IAA  No context636568 In context  70  69  81  Table 2: Manual annotation for T/V on a 100-sentence sample (Acc: Accuracy, IAA: Inter-annotator agreement)  English were asked to label these sentences as T or V. [sent-92, score-0.156]
</p><p>53 In a first round, the sentences were presented in isolation. [sent-93, score-0.073]
</p><p>54 In a second round, the sentences were presented with three sentences pre-context and three sentences post-context. [sent-94, score-0.219]
</p><p>55 The results in Table 2 show that it is fairly difficult to annotate the T/V distinction on individual sentences since it is not expressed systematically. [sent-95, score-0.49]
</p><p>56 At the level of small discourses, the distinction can be made much more confidently: In context, average agreement with the gold standard rises from 64% to 70%, and raw inter-annotator agreement goes up from 68% to 81%. [sent-96, score-0.285]
</p><p>57 Concerning the interpretation of these findings, we note that the two taggers were both native speakers of languages which make an overt T/V distinction. [sent-97, score-0.311]
</p><p>58 Thus, our present findings cannot be construed as firm evidence that English speakers make a distinction, even if implicitly. [sent-98, score-0.088]
</p><p>59 However, they demonstrate at least that native speakers of such languages can recover the distinction based solely on the clues in English text. [sent-99, score-0.494]
</p><p>60 An analysis of the annotation errors showed that many individual sentences can be uttered in both T and V situations, making it impossible to label them  in isolation: (1)  “And perhaps sometime you may see her. [sent-100, score-0.156]
</p><p>61 ”  This case (gold label: V) is however disambiguated by looking at the previous sentence, which indicates the social relation between speaker and addressee: (2)  “And she is a sort of relation of your lordship’s,” said Dawson. [sent-101, score-0.102]
</p><p>62 Still, a three-sentence window is often not sufficient, since the surrounding sentences may be just as uninformative. [sent-102, score-0.073]
</p><p>63 They are often difficult to label because they talk about social situations that are unfamiliar to modern speakers (as between aristocratic friends) or where the usage has changed (as in married couples). [sent-105, score-0.339]
</p><p>64 In this pilot modeling experiment, we explore a (limited) set of cues which can be used to predict the V vs. [sent-107, score-0.115]
</p><p>65 information present within the current sentence similar to the information available to the human annotators in the “No context” condition of Experiment 1). [sent-111, score-0.075]
</p><p>66 We approach the task by supervised classification, applying a model acquired from the training set on the test set. [sent-112, score-0.037]
</p><p>67 Note, however, that the labeled training data are acquired automatically through the parallel corpus, without the need for human annotation. [sent-113, score-0.107]
</p><p>68 It predicts the class c for a sentence s by maximising the product of the probabilities for the features f given the class, multiplied by the class probability:  c = argmax c  P(c|s) = argmax P(c)P(s|c)  = argmcaxP(c)fY∈sP(f|c)  (3)  cm  (4)  We experiment with three sets of features. [sent-116, score-0.232]
</p><p>69 The first set consists of words, following the intuition that some words should be correlated with formal address (like titles), while others should indicate infor-  mal address (like first names). [sent-117, score-0.364]
</p><p>70 The third set consists of one feature that represents a semantic class, namely a set of 25 archaic verbs and pronouns (like hadst or thyself), which we expect to correlate with old-fashioned T use. [sent-119, score-0.446]
</p><p>71 A random baseline is at 50%, and the majority class (V) corresponds to 60%. [sent-123, score-0.043]
</p><p>72 Thus, POS features tend to hurt, and the archaic feature helps, even though it technically overcounts evidence. [sent-126, score-0.169]
</p><p>73 5 The Naive Bayes model notably performs at a roughly human level, better than human annotators on the same setup (no context sentences), but worse than humans that have more context at their disposal. [sent-127, score-0.075]
</p><p>74 Overall, however, the T/V distinction appears to be a fairly difficult one. [sent-128, score-0.38]
</p><p>75 An important part of the problem is the absence of strong indicators in many sentences, in particular short ones (cf. [sent-129, score-0.056]
</p><p>76 In particular, we observe titles among the V-indicators (gentlemen, madam, ma+ ’am) as well as formulaic language (Permit (me)). [sent-134, score-0.157]
</p><p>77 Indicators for T seem to be much more general, with the expected exception of archaic thou forms. [sent-135, score-0.316]
</p><p>78 modern English, where it is not determined through pronoun choice or other overt means. [sent-137, score-0.235]
</p><p>79 We see this task as an instance of the general problem of recovering “hidden” information that is not expressed overtly. [sent-138, score-0.037]
</p><p>80 We have created a parallel German-English corpus and have used the information provided by the German pronouns to induce T/V labels for English sentences. [sent-139, score-0.347]
</p><p>81 In a manual annotation study for English,  annotators find the form of address very difficult to determine for individual sentences, but can draw this information from broader English discourse context. [sent-140, score-0.263]
</p><p>82 In a first statistical analysis, we found that lexical cues from the sentence can be used to predict the form of address automatically, although not yet on a very satisfactory level. [sent-142, score-0.223]
</p><p>83 On the technical level, we would like to apply a sequence model to account for the dependecies among sentences, and obtain more meaningful features for formal and informal address. [sent-144, score-0.32]
</p><p>84 In order to remove idiosyncratic features like names, we will only consider features that occur in several novels; furthermore, we will group words using distributional clustering methods (Clark, 2003) and predict T/V based on cluster probabilities. [sent-145, score-0.047]
</p><p>85 The conceptually most promising direction, how-  471 ever, is the induction of social networks in such novels (Elson et al. [sent-146, score-0.333]
</p><p>86 , 2010): Information on the social relationship between a speaker and an addressee should provide global constraints on all instances of communications between them, and predict the form of address much more reliably than word features can. [sent-147, score-0.325]
</p><p>87 Improved unsupervised sentence alignment for symmetrical and  asymmetrical parallel corpora. [sent-160, score-0.07]
</p><p>88 Paraphrasing rules for automatic evaluation of translation into japanese. [sent-191, score-0.075]
</p><p>89 Address pronouns as a problem in French-Swedish translation and translation revision. [sent-206, score-0.427]
</p><p>90 Mining and modeling relations between formal and informal Chinese phrases from web corpora. [sent-210, score-0.32]
</p><p>91 A cross-linguistic comparison ofaddress pronoun use in four European languages: Intralingual and interlingual dimensions. [sent-226, score-0.107]
</p><p>92 Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora. [sent-230, score-0.129]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('distinction', 0.285), ('pronouns', 0.277), ('german', 0.248), ('novels', 0.231), ('sie', 0.184), ('informal', 0.172), ('archaic', 0.169), ('formal', 0.148), ('thou', 0.147), ('english', 0.139), ('kretzenbacher', 0.125), ('manaal', 0.125), ('address', 0.108), ('pronoun', 0.107), ('social', 0.102), ('overtly', 0.095), ('literary', 0.089), ('titles', 0.089), ('speakers', 0.088), ('projection', 0.087), ('acc', 0.087), ('utterances', 0.086), ('aap', 0.083), ('clyne', 0.083), ('doris', 0.083), ('faruqui', 0.083), ('pbach', 0.083), ('du', 0.078), ('capitalized', 0.078), ('translation', 0.075), ('annotators', 0.075), ('languages', 0.074), ('braune', 0.074), ('dichotomy', 0.074), ('elson', 0.074), ('gutenberg', 0.074), ('sentences', 0.073), ('parallel', 0.07), ('cues', 0.068), ('modern', 0.068), ('formulaic', 0.068), ('addressee', 0.068), ('plural', 0.064), ('heidelberg', 0.064), ('europarl', 0.061), ('yarowsky', 0.061), ('texts', 0.061), ('iaa', 0.06), ('overt', 0.06), ('australian', 0.058), ('heinz', 0.058), ('alexander', 0.057), ('indicators', 0.056), ('hobbs', 0.056), ('century', 0.056), ('raters', 0.056), ('fairly', 0.056), ('singular', 0.054), ('sch', 0.054), ('naive', 0.054), ('treetagger', 0.052), ('argmax', 0.052), ('domingos', 0.049), ('india', 0.049), ('hindi', 0.049), ('person', 0.049), ('ongoing', 0.048), ('friends', 0.048), ('aligner', 0.048), ('predict', 0.047), ('native', 0.047), ('capitalization', 0.047), ('tu', 0.046), ('round', 0.044), ('fraser', 0.044), ('french', 0.044), ('class', 0.043), ('label', 0.042), ('bayes', 0.042), ('taggers', 0.042), ('tense', 0.042), ('experiment', 0.042), ('annotation', 0.041), ('side', 0.041), ('pos', 0.04), ('paraphrasing', 0.04), ('names', 0.039), ('difficult', 0.039), ('decided', 0.039), ('expressed', 0.037), ('acquired', 0.037), ('kameyama', 0.037), ('fabienne', 0.037), ('schiehlen', 0.037), ('dickens', 0.037), ('solidarity', 0.037), ('polite', 0.037), ('blank', 0.037), ('dames', 0.037), ('discourses', 0.037)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="157-tfidf-1" href="./acl-2011-I_Thou_Thee%2C_Thou_Traitor%3A_Predicting_Formal_vs._Informal_Address_in_English_Literature.html">157 acl-2011-I Thou Thee, Thou Traitor: Predicting Formal vs. Informal Address in English Literature</a></p>
<p>Author: Manaal Faruqui ; Sebastian Pado</p><p>Abstract: In contrast to many languages (like Russian or French), modern English does not distinguish formal and informal (“T/V”) address overtly, for example by pronoun choice. We describe an ongoing study which investigates to what degree the T/V distinction is recoverable in English text, and with what textual features it correlates. Our findings are: (a) human raters can label English utterances as T or V fairly well, given sufficient context; (b), lexical cues can predict T/V almost at human level.</p><p>2 0.12492356 <a title="157-tfidf-2" href="./acl-2011-A_Joint_Sequence_Translation_Model_with_Integrated_Reordering.html">16 acl-2011-A Joint Sequence Translation Model with Integrated Reordering</a></p>
<p>Author: Nadir Durrani ; Helmut Schmid ; Alexander Fraser</p><p>Abstract: We present a novel machine translation model which models translation by a linear sequence of operations. In contrast to the “N-gram” model, this sequence includes not only translation but also reordering operations. Key ideas of our model are (i) a new reordering approach which better restricts the position to which a word or phrase can be moved, and is able to handle short and long distance reorderings in a unified way, and (ii) a joint sequence model for the translation and reordering probabilities which is more flexible than standard phrase-based MT. We observe statistically significant improvements in BLEU over Moses for German-to-English and Spanish-to-English tasks, and comparable results for a French-to-English task.</p><p>3 0.11281525 <a title="157-tfidf-3" href="./acl-2011-Social_Network_Extraction_from_Texts%3A_A_Thesis_Proposal.html">286 acl-2011-Social Network Extraction from Texts: A Thesis Proposal</a></p>
<p>Author: Apoorv Agarwal</p><p>Abstract: In my thesis, Ipropose to build a system that would enable extraction of social interactions from texts. To date Ihave defined a comprehensive set of social events and built a preliminary system that extracts social events from news articles. Iplan to improve the performance of my current system by incorporating semantic information. Using domain adaptation techniques, Ipropose to apply my system to a wide range of genres. By extracting linguistic constructs relevant to social interactions, I will be able to empirically analyze different kinds of linguistic constructs that people use to express social interactions. Lastly, I will attempt to make convolution kernels more scalable and interpretable.</p><p>4 0.10036992 <a title="157-tfidf-4" href="./acl-2011-ParaSense_or_How_to_Use_Parallel_Corpora_for_Word_Sense_Disambiguation.html">240 acl-2011-ParaSense or How to Use Parallel Corpora for Word Sense Disambiguation</a></p>
<p>Author: Els Lefever ; Veronique Hoste ; Martine De Cock</p><p>Abstract: This paper describes a set of exploratory experiments for a multilingual classificationbased approach to Word Sense Disambiguation. Instead of using a predefined monolingual sense-inventory such as WordNet, we use a language-independent framework where the word senses are derived automatically from word alignments on a parallel corpus. We built five classifiers with English as an input language and translations in the five supported languages (viz. French, Dutch, Italian, Spanish and German) as classification output. The feature vectors incorporate both the more traditional local context features, as well as binary bag-of-words features that are extracted from the aligned translations. Our results show that the ParaSense multilingual WSD system shows very competitive results compared to the best systems that were evaluated on the SemEval-2010 Cross-Lingual Word Sense Disambiguation task for all five target languages.</p><p>5 0.098791108 <a title="157-tfidf-5" href="./acl-2011-Domain_Adaptation_for_Machine_Translation_by_Mining_Unseen_Words.html">104 acl-2011-Domain Adaptation for Machine Translation by Mining Unseen Words</a></p>
<p>Author: Hal Daume III ; Jagadeesh Jagarlamudi</p><p>Abstract: We show that unseen words account for a large part of the translation error when moving to new domains. Using an extension of a recent approach to mining translations from comparable corpora (Haghighi et al., 2008), we are able to find translations for otherwise OOV terms. We show several approaches to integrating such translations into a phrasebased translation system, yielding consistent improvements in translations quality (between 0.5 and 1.5 Bleu points) on four domains and two language pairs.</p><p>6 0.097970121 <a title="157-tfidf-6" href="./acl-2011-Translationese_and_Its_Dialects.html">311 acl-2011-Translationese and Its Dialects</a></p>
<p>7 0.094135083 <a title="157-tfidf-7" href="./acl-2011-How_Much_Can_We_Gain_from_Supervised_Word_Alignment%3F.html">152 acl-2011-How Much Can We Gain from Supervised Word Alignment?</a></p>
<p>8 0.093992852 <a title="157-tfidf-8" href="./acl-2011-Joint_Bilingual_Sentiment_Classification_with_Unlabeled_Parallel_Corpora.html">183 acl-2011-Joint Bilingual Sentiment Classification with Unlabeled Parallel Corpora</a></p>
<p>9 0.090532459 <a title="157-tfidf-9" href="./acl-2011-Rare_Word_Translation_Extraction_from_Aligned_Comparable_Documents.html">259 acl-2011-Rare Word Translation Extraction from Aligned Comparable Documents</a></p>
<p>10 0.090238541 <a title="157-tfidf-10" href="./acl-2011-A_Pronoun_Anaphora_Resolution_System_based_on_Factorial_Hidden_Markov_Models.html">23 acl-2011-A Pronoun Anaphora Resolution System based on Factorial Hidden Markov Models</a></p>
<p>11 0.088300884 <a title="157-tfidf-11" href="./acl-2011-Scaling_up_Automatic_Cross-Lingual_Semantic_Role_Annotation.html">269 acl-2011-Scaling up Automatic Cross-Lingual Semantic Role Annotation</a></p>
<p>12 0.087031931 <a title="157-tfidf-12" href="./acl-2011-Language_Use%3A_What_can_it_tell_us%3F.html">194 acl-2011-Language Use: What can it tell us?</a></p>
<p>13 0.085732624 <a title="157-tfidf-13" href="./acl-2011-An_exponential_translation_model_for_target_language_morphology.html">44 acl-2011-An exponential translation model for target language morphology</a></p>
<p>14 0.085343376 <a title="157-tfidf-14" href="./acl-2011-Two_Easy_Improvements_to_Lexical_Weighting.html">313 acl-2011-Two Easy Improvements to Lexical Weighting</a></p>
<p>15 0.084852792 <a title="157-tfidf-15" href="./acl-2011-Pre-_and_Postprocessing_for_Statistical_Machine_Translation_into_Germanic_Languages.html">247 acl-2011-Pre- and Postprocessing for Statistical Machine Translation into Germanic Languages</a></p>
<p>16 0.084248535 <a title="157-tfidf-16" href="./acl-2011-Unsupervised_Part-of-Speech_Tagging_with_Bilingual_Graph-Based_Projections.html">323 acl-2011-Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</a></p>
<p>17 0.081770875 <a title="157-tfidf-17" href="./acl-2011-Learning_Hierarchical_Translation_Structure_with_Linguistic_Annotations.html">202 acl-2011-Learning Hierarchical Translation Structure with Linguistic Annotations</a></p>
<p>18 0.080168664 <a title="157-tfidf-18" href="./acl-2011-A_Word-Class_Approach_to_Labeling_PSCFG_Rules_for_Machine_Translation.html">29 acl-2011-A Word-Class Approach to Labeling PSCFG Rules for Machine Translation</a></p>
<p>19 0.078482829 <a title="157-tfidf-19" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<p>20 0.07702215 <a title="157-tfidf-20" href="./acl-2011-Extracting_Social_Power_Relationships_from_Natural_Language.html">133 acl-2011-Extracting Social Power Relationships from Natural Language</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.235), (1, -0.035), (2, 0.014), (3, 0.045), (4, -0.029), (5, 0.07), (6, 0.102), (7, -0.036), (8, -0.026), (9, 0.027), (10, -0.037), (11, -0.04), (12, -0.024), (13, -0.009), (14, 0.012), (15, -0.06), (16, -0.006), (17, 0.019), (18, 0.043), (19, -0.063), (20, 0.027), (21, 0.014), (22, -0.083), (23, 0.021), (24, -0.064), (25, 0.095), (26, -0.006), (27, 0.042), (28, -0.015), (29, -0.098), (30, 0.057), (31, -0.023), (32, 0.029), (33, -0.0), (34, -0.024), (35, 0.012), (36, -0.03), (37, 0.034), (38, -0.135), (39, 0.048), (40, -0.028), (41, -0.002), (42, -0.003), (43, -0.134), (44, -0.054), (45, 0.033), (46, -0.143), (47, -0.031), (48, -0.052), (49, 0.087)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93009079 <a title="157-lsi-1" href="./acl-2011-I_Thou_Thee%2C_Thou_Traitor%3A_Predicting_Formal_vs._Informal_Address_in_English_Literature.html">157 acl-2011-I Thou Thee, Thou Traitor: Predicting Formal vs. Informal Address in English Literature</a></p>
<p>Author: Manaal Faruqui ; Sebastian Pado</p><p>Abstract: In contrast to many languages (like Russian or French), modern English does not distinguish formal and informal (“T/V”) address overtly, for example by pronoun choice. We describe an ongoing study which investigates to what degree the T/V distinction is recoverable in English text, and with what textual features it correlates. Our findings are: (a) human raters can label English utterances as T or V fairly well, given sufficient context; (b), lexical cues can predict T/V almost at human level.</p><p>2 0.8132962 <a title="157-lsi-2" href="./acl-2011-Translationese_and_Its_Dialects.html">311 acl-2011-Translationese and Its Dialects</a></p>
<p>Author: Moshe Koppel ; Noam Ordan</p><p>Abstract: While it is has often been observed that the product of translation is somehow different than non-translated text, scholars have emphasized two distinct bases for such differences. Some have noted interference from the source language spilling over into translation in a source-language-specific way, while others have noted general effects of the process of translation that are independent of source language. Using a series of text categorization experiments, we show that both these effects exist and that, moreover, there is a continuum between them. There are many effects of translation that are consistent among texts translated from a given source language, some of which are consistent even among texts translated from families of source languages. Significantly, we find that even for widely unrelated source languages and multiple genres, differences between translated texts and non-translated texts are sufficient for a learned classifier to accurately determine if a given text is translated or original.</p><p>3 0.6625551 <a title="157-lsi-3" href="./acl-2011-Tier-based_Strictly_Local_Constraints_for_Phonology.html">303 acl-2011-Tier-based Strictly Local Constraints for Phonology</a></p>
<p>Author: Jeffrey Heinz ; Chetan Rawal ; Herbert G. Tanner</p><p>Abstract: Beginning with Goldsmith (1976), the phonological tier has a long history in phonological theory to describe non-local phenomena. This paper defines a class of formal languages, the Tier-based Strictly Local languages, which begin to describe such phenomena. Then this class is located within the Subregular Hierarchy (McNaughton and Papert, 1971). It is found that these languages contain the Strictly Local languages, are star-free, are incomparable with other known sub-star-free classes, and have other interesting properties.</p><p>4 0.6426419 <a title="157-lsi-4" href="./acl-2011-Lost_in_Translation%3A_Authorship_Attribution_using_Frame_Semantics.html">214 acl-2011-Lost in Translation: Authorship Attribution using Frame Semantics</a></p>
<p>Author: Steffen Hedegaard ; Jakob Grue Simonsen</p><p>Abstract: We investigate authorship attribution using classifiers based on frame semantics. The purpose is to discover whether adding semantic information to lexical and syntactic methods for authorship attribution will improve them, specifically to address the difficult problem of authorship attribution of translated texts. Our results suggest (i) that frame-based classifiers are usable for author attribution of both translated and untranslated texts; (ii) that framebased classifiers generally perform worse than the baseline classifiers for untranslated texts, but (iii) perform as well as, or superior to the baseline classifiers on translated texts; (iv) that—contrary to current belief—naïve clas- sifiers based on lexical markers may perform tolerably on translated texts if the combination of author and translator is present in the training set of a classifier.</p><p>5 0.60548669 <a title="157-lsi-5" href="./acl-2011-Extracting_Social_Power_Relationships_from_Natural_Language.html">133 acl-2011-Extracting Social Power Relationships from Natural Language</a></p>
<p>Author: Philip Bramsen ; Martha Escobar-Molano ; Ami Patel ; Rafael Alonso</p><p>Abstract: Sociolinguists have long argued that social context influences language use in all manner of ways, resulting in lects 1. This paper explores a text classification problem we will call lect modeling, an example of what has been termed computational sociolinguistics. In particular, we use machine learning techniques to identify social power relationships between members of a social network, based purely on the content of their interpersonal communication. We rely on statistical methods, as opposed to language-specific engineering, to extract features which represent vocabulary and grammar usage indicative of social power lect. We then apply support vector machines to model the social power lects representing superior-subordinate communication in the Enron email corpus. Our results validate the treatment of lect modeling as a text classification problem – albeit a hard one – and constitute a case for future research in computational sociolinguistics. 1</p><p>6 0.59719491 <a title="157-lsi-6" href="./acl-2011-Combining_Indicators_of_Allophony.html">74 acl-2011-Combining Indicators of Allophony</a></p>
<p>7 0.59268463 <a title="157-lsi-7" href="./acl-2011-An_Interface_for_Rapid_Natural_Language_Processing_Development_in_UIMA.html">42 acl-2011-An Interface for Rapid Natural Language Processing Development in UIMA</a></p>
<p>8 0.57891357 <a title="157-lsi-8" href="./acl-2011-Language_Use%3A_What_can_it_tell_us%3F.html">194 acl-2011-Language Use: What can it tell us?</a></p>
<p>9 0.56998873 <a title="157-lsi-9" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<p>10 0.56076151 <a title="157-lsi-10" href="./acl-2011-Hindi_to_Punjabi_Machine_Translation_System.html">151 acl-2011-Hindi to Punjabi Machine Translation System</a></p>
<p>11 0.5589478 <a title="157-lsi-11" href="./acl-2011-Rare_Word_Translation_Extraction_from_Aligned_Comparable_Documents.html">259 acl-2011-Rare Word Translation Extraction from Aligned Comparable Documents</a></p>
<p>12 0.55547637 <a title="157-lsi-12" href="./acl-2011-P11-5002_k2opt.pdf.html">239 acl-2011-P11-5002 k2opt.pdf</a></p>
<p>13 0.54854012 <a title="157-lsi-13" href="./acl-2011-Language-independent_compound_splitting_with_morphological_operations.html">193 acl-2011-Language-independent compound splitting with morphological operations</a></p>
<p>14 0.54808575 <a title="157-lsi-14" href="./acl-2011-Towards_Style_Transformation_from_Written-Style_to_Audio-Style.html">306 acl-2011-Towards Style Transformation from Written-Style to Audio-Style</a></p>
<p>15 0.54351783 <a title="157-lsi-15" href="./acl-2011-ParaSense_or_How_to_Use_Parallel_Corpora_for_Word_Sense_Disambiguation.html">240 acl-2011-ParaSense or How to Use Parallel Corpora for Word Sense Disambiguation</a></p>
<p>16 0.5400207 <a title="157-lsi-16" href="./acl-2011-That%27s_What_She_Said%3A_Double_Entendre_Identification.html">297 acl-2011-That's What She Said: Double Entendre Identification</a></p>
<p>17 0.53824151 <a title="157-lsi-17" href="./acl-2011-Subjective_Natural_Language_Problems%3A_Motivations%2C_Applications%2C_Characterizations%2C_and_Implications.html">288 acl-2011-Subjective Natural Language Problems: Motivations, Applications, Characterizations, and Implications</a></p>
<p>18 0.530909 <a title="157-lsi-18" href="./acl-2011-A_Joint_Sequence_Translation_Model_with_Integrated_Reordering.html">16 acl-2011-A Joint Sequence Translation Model with Integrated Reordering</a></p>
<p>19 0.52847385 <a title="157-lsi-19" href="./acl-2011-Disambiguating_temporal-contrastive_connectives_for_machine_translation.html">96 acl-2011-Disambiguating temporal-contrastive connectives for machine translation</a></p>
<p>20 0.52623272 <a title="157-lsi-20" href="./acl-2011-Domain_Adaptation_for_Machine_Translation_by_Mining_Unseen_Words.html">104 acl-2011-Domain Adaptation for Machine Translation by Mining Unseen Words</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.024), (17, 0.046), (26, 0.036), (31, 0.02), (37, 0.068), (39, 0.063), (41, 0.091), (53, 0.01), (55, 0.026), (57, 0.261), (59, 0.038), (72, 0.058), (91, 0.05), (96, 0.144), (97, 0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.82275665 <a title="157-lda-1" href="./acl-2011-Partial_Parsing_from_Bitext_Projections.html">243 acl-2011-Partial Parsing from Bitext Projections</a></p>
<p>Author: Prashanth Mannem ; Aswarth Dara</p><p>Abstract: Recent work has shown how a parallel corpus can be leveraged to build syntactic parser for a target language by projecting automatic source parse onto the target sentence using word alignments. The projected target dependency parses are not always fully connected to be useful for training traditional dependency parsers. In this paper, we present a greedy non-directional parsing algorithm which doesn’t need a fully connected parse and can learn from partial parses by utilizing available structural and syntactic information in them. Our parser achieved statistically significant improvements over a baseline system that trains on only fully connected parses for Bulgarian, Spanish and Hindi. It also gave a significant improvement over previously reported results for Bulgarian and set a benchmark for Hindi.</p><p>2 0.80911952 <a title="157-lda-2" href="./acl-2011-Simple_supervised_document_geolocation_with_geodesic_grids.html">285 acl-2011-Simple supervised document geolocation with geodesic grids</a></p>
<p>Author: Benjamin Wing ; Jason Baldridge</p><p>Abstract: We investigate automatic geolocation (i.e. identification of the location, expressed as latitude/longitude coordinates) of documents. Geolocation can be an effective means of summarizing large document collections and it is an important component of geographic information retrieval. We describe several simple supervised methods for document geolocation using only the document’s raw text as evidence. All of our methods predict locations in the context of geodesic grids of varying degrees of resolution. We evaluate the methods on geotagged Wikipedia articles and Twitter feeds. For Wikipedia, our best method obtains a median prediction error of just 11.8 kilometers. Twitter geolocation is more challenging: we obtain a median error of 479 km, an improvement on previous results for the dataset.</p><p>same-paper 3 0.79244787 <a title="157-lda-3" href="./acl-2011-I_Thou_Thee%2C_Thou_Traitor%3A_Predicting_Formal_vs._Informal_Address_in_English_Literature.html">157 acl-2011-I Thou Thee, Thou Traitor: Predicting Formal vs. Informal Address in English Literature</a></p>
<p>Author: Manaal Faruqui ; Sebastian Pado</p><p>Abstract: In contrast to many languages (like Russian or French), modern English does not distinguish formal and informal (“T/V”) address overtly, for example by pronoun choice. We describe an ongoing study which investigates to what degree the T/V distinction is recoverable in English text, and with what textual features it correlates. Our findings are: (a) human raters can label English utterances as T or V fairly well, given sufficient context; (b), lexical cues can predict T/V almost at human level.</p><p>4 0.78348386 <a title="157-lda-4" href="./acl-2011-Towards_Style_Transformation_from_Written-Style_to_Audio-Style.html">306 acl-2011-Towards Style Transformation from Written-Style to Audio-Style</a></p>
<p>Author: Amjad Abu-Jbara ; Barbara Rosario ; Kent Lyons</p><p>Abstract: In this paper, we address the problem of optimizing the style of textual content to make it more suitable to being listened to by a user as opposed to being read. We study the differences between the written style and the audio style by consulting the linguistics andjour- nalism literatures. Guided by this study, we suggest a number of linguistic features to distinguish between the two styles. We show the correctness of our features and the impact of style transformation on the user experience through statistical analysis, a style classification task, and a user study.</p><p>5 0.7792666 <a title="157-lda-5" href="./acl-2011-Topical_Keyphrase_Extraction_from_Twitter.html">305 acl-2011-Topical Keyphrase Extraction from Twitter</a></p>
<p>Author: Xin Zhao ; Jing Jiang ; Jing He ; Yang Song ; Palakorn Achanauparp ; Ee-Peng Lim ; Xiaoming Li</p><p>Abstract: Summarizing and analyzing Twitter content is an important and challenging task. In this paper, we propose to extract topical keyphrases as one way to summarize Twitter. We propose a context-sensitive topical PageRank method for keyword ranking and a probabilistic scoring function that considers both relevance and interestingness of keyphrases for keyphrase ranking. We evaluate our proposed methods on a large Twitter data set. Experiments show that these methods are very effective for topical keyphrase extraction.</p><p>6 0.61764443 <a title="157-lda-6" href="./acl-2011-Fine-Grained_Class_Label_Markup_of_Search_Queries.html">137 acl-2011-Fine-Grained Class Label Markup of Search Queries</a></p>
<p>7 0.61714369 <a title="157-lda-7" href="./acl-2011-Large-Scale_Cross-Document_Coreference_Using_Distributed_Inference_and_Hierarchical_Models.html">196 acl-2011-Large-Scale Cross-Document Coreference Using Distributed Inference and Hierarchical Models</a></p>
<p>8 0.61683434 <a title="157-lda-8" href="./acl-2011-Disentangling_Chat_with_Local_Coherence_Models.html">101 acl-2011-Disentangling Chat with Local Coherence Models</a></p>
<p>9 0.61414629 <a title="157-lda-9" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>10 0.6139257 <a title="157-lda-10" href="./acl-2011-Beam-Width_Prediction_for_Efficient_Context-Free_Parsing.html">58 acl-2011-Beam-Width Prediction for Efficient Context-Free Parsing</a></p>
<p>11 0.61376506 <a title="157-lda-11" href="./acl-2011-Can_Document_Selection_Help_Semi-supervised_Learning%3F_A_Case_Study_On_Event_Extraction.html">65 acl-2011-Can Document Selection Help Semi-supervised Learning? A Case Study On Event Extraction</a></p>
<p>12 0.61308169 <a title="157-lda-12" href="./acl-2011-Evaluating_the_Impact_of_Coder_Errors_on_Active_Learning.html">119 acl-2011-Evaluating the Impact of Coder Errors on Active Learning</a></p>
<p>13 0.61296695 <a title="157-lda-13" href="./acl-2011-Creating_a_manually_error-tagged_and_shallow-parsed_learner_corpus.html">88 acl-2011-Creating a manually error-tagged and shallow-parsed learner corpus</a></p>
<p>14 0.61230206 <a title="157-lda-14" href="./acl-2011-An_Error_Analysis_of_Relation_Extraction_in_Social_Media_Documents.html">40 acl-2011-An Error Analysis of Relation Extraction in Social Media Documents</a></p>
<p>15 0.61197615 <a title="157-lda-15" href="./acl-2011-Scaling_up_Automatic_Cross-Lingual_Semantic_Role_Annotation.html">269 acl-2011-Scaling up Automatic Cross-Lingual Semantic Role Annotation</a></p>
<p>16 0.61173725 <a title="157-lda-16" href="./acl-2011-Lexically-Triggered_Hidden_Markov_Models_for_Clinical_Document_Coding.html">209 acl-2011-Lexically-Triggered Hidden Markov Models for Clinical Document Coding</a></p>
<p>17 0.61172557 <a title="157-lda-17" href="./acl-2011-Good_Seed_Makes_a_Good_Crop%3A_Accelerating_Active_Learning_Using_Language_Modeling.html">145 acl-2011-Good Seed Makes a Good Crop: Accelerating Active Learning Using Language Modeling</a></p>
<p>18 0.61125302 <a title="157-lda-18" href="./acl-2011-An_Empirical_Evaluation_of_Data-Driven_Paraphrase_Generation_Techniques.html">37 acl-2011-An Empirical Evaluation of Data-Driven Paraphrase Generation Techniques</a></p>
<p>19 0.61100584 <a title="157-lda-19" href="./acl-2011-Exploiting_Syntactico-Semantic_Structures_for_Relation_Extraction.html">126 acl-2011-Exploiting Syntactico-Semantic Structures for Relation Extraction</a></p>
<p>20 0.60915655 <a title="157-lda-20" href="./acl-2011-A_Fast_and_Accurate_Method_for_Approximate_String_Search.html">11 acl-2011-A Fast and Accurate Method for Approximate String Search</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
