<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>297 acl-2011-That's What She Said: Double Entendre Identification</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-297" href="#">acl2011-297</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>297 acl-2011-That's What She Said: Double Entendre Identification</h1>
<br/><p>Source: <a title="acl-2011-297-pdf" href="http://aclweb.org/anthology//P/P11/P11-2016.pdf">pdf</a></p><p>Author: Chloe Kiddon ; Yuriy Brun</p><p>Abstract: Humor identification is a hard natural language understanding problem. We identify a subproblem — the “that’s what she said” problem with two distinguishing characteristics: (1) use of nouns that are euphemisms for sexually explicit nouns and (2) structure common in the erotic domain. We address this problem in a classification approach that includes features that model those two characteristics. Experiments on web data demonstrate that our approach improves precision by 12% over baseline techniques that use only word-based features. —</p><p>Reference: <a title="acl-2011-297-reference" href="../acl2011_reference/acl-2011-That%27s_What_She_Said%3A_Double_Entendre_Identification_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('twss', 0.668), ('devy', 0.301), ('erot', 0.297), ('twsss', 0.223), ('euphem', 0.204), ('entendr', 0.167), ('noun', 0.163), ('sex', 0.148), ('metaph', 0.131), ('metacost', 0.13), ('sn', 0.122), ('erotic', 0.111), ('nonerot', 0.111), ('doubl', 0.094), ('jok', 0.082), ('adject', 0.077), ('said', 0.076), ('sexy', 0.074), ('fals', 0.059), ('bool', 0.057)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="297-tfidf-1" href="./acl-2011-That%27s_What_She_Said%3A_Double_Entendre_Identification.html">297 acl-2011-That's What She Said: Double Entendre Identification</a></p>
<p>Author: Chloe Kiddon ; Yuriy Brun</p><p>Abstract: Humor identification is a hard natural language understanding problem. We identify a subproblem — the “that’s what she said” problem with two distinguishing characteristics: (1) use of nouns that are euphemisms for sexually explicit nouns and (2) structure common in the erotic domain. We address this problem in a classification approach that includes features that model those two characteristics. Experiments on web data demonstrate that our approach improves precision by 12% over baseline techniques that use only word-based features. —</p><p>2 0.066348143 <a title="297-tfidf-2" href="./acl-2011-Identifying_Noun_Product_Features_that_Imply_Opinions.html">159 acl-2011-Identifying Noun Product Features that Imply Opinions</a></p>
<p>Author: Lei Zhang ; Bing Liu</p><p>Abstract: Identifying domain-dependent opinion words is a key problem in opinion mining and has been studied by several researchers. However, existing work has been focused on adjectives and to some extent verbs. Limited work has been done on nouns and noun phrases. In our work, we used the feature-based opinion mining model, and we found that in some domains nouns and noun phrases that indicate product features may also imply opinions. In many such cases, these nouns are not subjective but objective. Their involved sentences are also objective sentences and imply positive or negative opinions. Identifying such nouns and noun phrases and their polarities is very challenging but critical for effective opinion mining in these domains. To the best of our knowledge, this problem has not been studied in the literature. This paper proposes a method to deal with the problem. Experimental results based on real-life datasets show promising results. 1</p><p>3 0.062970631 <a title="297-tfidf-3" href="./acl-2011-Effects_of_Noun_Phrase_Bracketing_in_Dependency_Parsing_and_Machine_Translation.html">111 acl-2011-Effects of Noun Phrase Bracketing in Dependency Parsing and Machine Translation</a></p>
<p>Author: Nathan Green</p><p>Abstract: Flat noun phrase structure was, up until recently, the standard in annotation for the Penn Treebanks. With the recent addition of internal noun phrase annotation, dependency parsing and applications down the NLP pipeline are likely affected. Some machine translation systems, such as TectoMT, use deep syntax as a language transfer layer. It is proposed that changes to the noun phrase dependency parse will have a cascading effect down the NLP pipeline and in the end, improve machine translation output, even with a reduction in parser accuracy that the noun phrase structure might cause. This paper examines this noun phrase structure’s effect on dependency parsing, in English, with a maximum spanning tree parser and shows a 2.43%, 0.23 Bleu score, improvement for English to Czech machine translation. .</p><p>4 0.062537044 <a title="297-tfidf-4" href="./acl-2011-Part-of-Speech_Tagging_for_Twitter%3A_Annotation%2C_Features%2C_and_Experiments.html">242 acl-2011-Part-of-Speech Tagging for Twitter: Annotation, Features, and Experiments</a></p>
<p>Author: Kevin Gimpel ; Nathan Schneider ; Brendan O'Connor ; Dipanjan Das ; Daniel Mills ; Jacob Eisenstein ; Michael Heilman ; Dani Yogatama ; Jeffrey Flanigan ; Noah A. Smith</p><p>Abstract: We address the problem of part-of-speech tagging for English data from the popular microblogging service Twitter. We develop a tagset, annotate data, develop features, and report tagging results nearing 90% accuracy. The data and tools have been made available to the research community with the goal of enabling richer text analysis of Twitter and related social media data sets.</p><p>5 0.06242428 <a title="297-tfidf-5" href="./acl-2011-Creative_Language_Retrieval%3A_A_Robust_Hybrid_of_Information_Retrieval_and_Linguistic_Creativity.html">89 acl-2011-Creative Language Retrieval: A Robust Hybrid of Information Retrieval and Linguistic Creativity</a></p>
<p>Author: Tony Veale</p><p>Abstract: Information retrieval (IR) and figurative language processing (FLP) could scarcely be more different in their treatment of language and meaning. IR views language as an open-ended set of mostly stable signs with which texts can be indexed and retrieved, focusing more on a text’s potential relevance than its potential meaning. In contrast, FLP views language as a system of unstable signs that can be used to talk about the world in creative new ways. There is another key difference: IR is practical, scalable and robust, and in daily use by millions of casual users. FLP is neither scalable nor robust, and not yet practical enough to migrate beyond the lab. This paper thus presents a mutually beneficial hybrid of IR and FLP, one that enriches IR with new operators to enable the non-literal retrieval of creative expressions, and which also transplants FLP into a robust, scalable framework in which practical applications of linguistic creativity can be implemented. 1</p><p>6 0.044802532 <a title="297-tfidf-6" href="./acl-2011-An_exponential_translation_model_for_target_language_morphology.html">44 acl-2011-An exponential translation model for target language morphology</a></p>
<p>7 0.044533849 <a title="297-tfidf-7" href="./acl-2011-Collective_Classification_of_Congressional_Floor-Debate_Transcripts.html">73 acl-2011-Collective Classification of Congressional Floor-Debate Transcripts</a></p>
<p>8 0.043957483 <a title="297-tfidf-8" href="./acl-2011-Unsupervised_Part-of-Speech_Tagging_with_Bilingual_Graph-Based_Projections.html">323 acl-2011-Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</a></p>
<p>9 0.041744441 <a title="297-tfidf-9" href="./acl-2011-Latent_Semantic_Word_Sense_Induction_and_Disambiguation.html">198 acl-2011-Latent Semantic Word Sense Induction and Disambiguation</a></p>
<p>10 0.040626504 <a title="297-tfidf-10" href="./acl-2011-I_Thou_Thee%2C_Thou_Traitor%3A_Predicting_Formal_vs._Informal_Address_in_English_Literature.html">157 acl-2011-I Thou Thee, Thou Traitor: Predicting Formal vs. Informal Address in English Literature</a></p>
<p>11 0.037479214 <a title="297-tfidf-11" href="./acl-2011-Better_Hypothesis_Testing_for_Statistical_Machine_Translation%3A_Controlling_for_Optimizer_Instability.html">60 acl-2011-Better Hypothesis Testing for Statistical Machine Translation: Controlling for Optimizer Instability</a></p>
<p>12 0.037337404 <a title="297-tfidf-12" href="./acl-2011-Which_Noun_Phrases_Denote_Which_Concepts%3F.html">334 acl-2011-Which Noun Phrases Denote Which Concepts?</a></p>
<p>13 0.036941856 <a title="297-tfidf-13" href="./acl-2011-Exploiting_Web-Derived_Selectional_Preference_to_Improve_Statistical_Dependency_Parsing.html">127 acl-2011-Exploiting Web-Derived Selectional Preference to Improve Statistical Dependency Parsing</a></p>
<p>14 0.036774475 <a title="297-tfidf-14" href="./acl-2011-Web-Scale_Features_for_Full-Scale_Parsing.html">333 acl-2011-Web-Scale Features for Full-Scale Parsing</a></p>
<p>15 0.036544185 <a title="297-tfidf-15" href="./acl-2011-NULEX%3A_An_Open-License_Broad_Coverage_Lexicon.html">229 acl-2011-NULEX: An Open-License Broad Coverage Lexicon</a></p>
<p>16 0.036410734 <a title="297-tfidf-16" href="./acl-2011-Lexical_Normalisation_of_Short_Text_Messages%3A_Makn_Sens_a_%23twitter.html">208 acl-2011-Lexical Normalisation of Short Text Messages: Makn Sens a #twitter</a></p>
<p>17 0.035847545 <a title="297-tfidf-17" href="./acl-2011-A_Corpus_for_Modeling_Morpho-Syntactic_Agreement_in_Arabic%3A_Gender%2C_Number_and_Rationality.html">7 acl-2011-A Corpus for Modeling Morpho-Syntactic Agreement in Arabic: Gender, Number and Rationality</a></p>
<p>18 0.03562139 <a title="297-tfidf-18" href="./acl-2011-Semi-Supervised_Modeling_for_Prenominal_Modifier_Ordering.html">275 acl-2011-Semi-Supervised Modeling for Prenominal Modifier Ordering</a></p>
<p>19 0.035183031 <a title="297-tfidf-19" href="./acl-2011-Predicting_Relative_Prominence_in_Noun-Noun_Compounds.html">249 acl-2011-Predicting Relative Prominence in Noun-Noun Compounds</a></p>
<p>20 0.034728292 <a title="297-tfidf-20" href="./acl-2011-Using_Multiple_Sources_to_Construct_a_Sentiment_Sensitive_Thesaurus_for_Cross-Domain_Sentiment_Classification.html">332 acl-2011-Using Multiple Sources to Construct a Sentiment Sensitive Thesaurus for Cross-Domain Sentiment Classification</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.093), (1, 0.035), (2, 0.017), (3, 0.013), (4, -0.018), (5, 0.021), (6, 0.024), (7, -0.021), (8, 0.008), (9, -0.011), (10, 0.006), (11, 0.02), (12, -0.005), (13, -0.02), (14, -0.02), (15, 0.015), (16, -0.0), (17, -0.032), (18, -0.009), (19, 0.006), (20, -0.022), (21, 0.012), (22, -0.002), (23, 0.069), (24, -0.029), (25, 0.017), (26, -0.02), (27, -0.003), (28, -0.024), (29, 0.001), (30, 0.016), (31, -0.058), (32, -0.009), (33, 0.006), (34, 0.014), (35, -0.004), (36, -0.019), (37, -0.01), (38, 0.074), (39, -0.002), (40, -0.051), (41, -0.017), (42, 0.018), (43, -0.084), (44, 0.029), (45, -0.058), (46, -0.024), (47, -0.09), (48, -0.012), (49, 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.86737138 <a title="297-lsi-1" href="./acl-2011-That%27s_What_She_Said%3A_Double_Entendre_Identification.html">297 acl-2011-That's What She Said: Double Entendre Identification</a></p>
<p>Author: Chloe Kiddon ; Yuriy Brun</p><p>Abstract: Humor identification is a hard natural language understanding problem. We identify a subproblem — the “that’s what she said” problem with two distinguishing characteristics: (1) use of nouns that are euphemisms for sexually explicit nouns and (2) structure common in the erotic domain. We address this problem in a classification approach that includes features that model those two characteristics. Experiments on web data demonstrate that our approach improves precision by 12% over baseline techniques that use only word-based features. —</p><p>2 0.65644693 <a title="297-lsi-2" href="./acl-2011-Exploiting_Readymades_in_Linguistic_Creativity%3A_A_System_Demonstration_of_the_Jigsaw_Bard.html">125 acl-2011-Exploiting Readymades in Linguistic Creativity: A System Demonstration of the Jigsaw Bard</a></p>
<p>Author: Tony Veale ; Yanfen Hao</p><p>Abstract: Large lexical resources, such as corpora and databases of Web ngrams, are a rich source of pre-fabricated phrases that can be reused in many different contexts. However, one must be careful in how these resources are used, and noted writers such as George Orwell have argued that the use of canned phrases encourages sloppy thinking and results in poor communication. Nonetheless, while Orwell prized home-made phrases over the readymade variety, there is a vibrant movement in modern art which shifts artistic creation from the production of novel artifacts to the clever reuse of readymades or objets trouvés. We describe here a system that makes creative reuse of the linguistic readymades in the Google ngrams. Our system, the Jigsaw Bard, thus owes more to Marcel Duchamp than to George Orwell. We demonstrate how textual readymades can be identified and harvested on a large scale, and used to drive a modest form of linguistic creativity. 1</p><p>3 0.65252954 <a title="297-lsi-3" href="./acl-2011-Ordering_Prenominal_Modifiers_with_a_Reranking_Approach.html">237 acl-2011-Ordering Prenominal Modifiers with a Reranking Approach</a></p>
<p>Author: Jenny Liu ; Aria Haghighi</p><p>Abstract: In this work, we present a novel approach to the generation task of ordering prenominal modifiers. We take a maximum entropy reranking approach to the problem which admits arbitrary features on a permutation of modifiers, exploiting hundreds ofthousands of features in total. We compare our error rates to the state-of-the-art and to a strong Google ngram count baseline. We attain a maximum error reduction of 69.8% and average error reduction across all test sets of 59. 1% compared to the state-of-the-art and a maximum error reduction of 68.4% and average error reduction across all test sets of 41.8% compared to our Google n-gram count baseline.</p><p>4 0.58578438 <a title="297-lsi-4" href="./acl-2011-Semi-Supervised_Modeling_for_Prenominal_Modifier_Ordering.html">275 acl-2011-Semi-Supervised Modeling for Prenominal Modifier Ordering</a></p>
<p>Author: Margaret Mitchell ; Aaron Dunlop ; Brian Roark</p><p>Abstract: In this paper, we argue that ordering prenominal modifiers typically pursued as a supervised modeling task is particularly wellsuited to semi-supervised approaches. By relying on automatic parses to extract noun phrases, we can scale up the training data by orders of magnitude. This minimizes the predominant issue of data sparsity that has informed most previous approaches. We compare several recent approaches, and find improvements from additional training data across the board; however, none outperform a simple n-gram model. – –</p><p>5 0.56581891 <a title="297-lsi-5" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<p>Author: Shane Bergsma ; David Yarowsky ; Kenneth Church</p><p>Abstract: Resolving coordination ambiguity is a classic hard problem. This paper looks at coordination disambiguation in complex noun phrases (NPs). Parsers trained on the Penn Treebank are reporting impressive numbers these days, but they don’t do very well on this problem (79%). We explore systems trained using three types of corpora: (1) annotated (e.g. the Penn Treebank), (2) bitexts (e.g. Europarl), and (3) unannotated monolingual (e.g. Google N-grams). Size matters: (1) is a million words, (2) is potentially billions of words and (3) is potentially trillions of words. The unannotated monolingual data is helpful when the ambiguity can be resolved through associations among the lexical items. The bilingual data is helpful when the ambiguity can be resolved by the order of words in the translation. We train separate classifiers with monolingual and bilingual features and iteratively improve them via achieves data and pervised tations. co-training. The co-trained classifier close to 96% accuracy on Treebank makes 20% fewer errors than a susystem trained with Treebank anno-</p><p>6 0.5540067 <a title="297-lsi-6" href="./acl-2011-Improving_Classification_of_Medical_Assertions_in_Clinical_Notes.html">165 acl-2011-Improving Classification of Medical Assertions in Clinical Notes</a></p>
<p>7 0.55030745 <a title="297-lsi-7" href="./acl-2011-Part-of-Speech_Tagging_for_Twitter%3A_Annotation%2C_Features%2C_and_Experiments.html">242 acl-2011-Part-of-Speech Tagging for Twitter: Annotation, Features, and Experiments</a></p>
<p>8 0.53369725 <a title="297-lsi-8" href="./acl-2011-Unsupervised_Part-of-Speech_Tagging_with_Bilingual_Graph-Based_Projections.html">323 acl-2011-Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</a></p>
<p>9 0.52604133 <a title="297-lsi-9" href="./acl-2011-The_impact_of_language_models_and_loss_functions_on_repair_disfluency_detection.html">301 acl-2011-The impact of language models and loss functions on repair disfluency detection</a></p>
<p>10 0.5181905 <a title="297-lsi-10" href="./acl-2011-Learning_Condensed_Feature_Representations_from_Large_Unsupervised_Data_Sets_for_Supervised_Learning.html">199 acl-2011-Learning Condensed Feature Representations from Large Unsupervised Data Sets for Supervised Learning</a></p>
<p>11 0.5151189 <a title="297-lsi-11" href="./acl-2011-Tier-based_Strictly_Local_Constraints_for_Phonology.html">303 acl-2011-Tier-based Strictly Local Constraints for Phonology</a></p>
<p>12 0.51185828 <a title="297-lsi-12" href="./acl-2011-Creative_Language_Retrieval%3A_A_Robust_Hybrid_of_Information_Retrieval_and_Linguistic_Creativity.html">89 acl-2011-Creative Language Retrieval: A Robust Hybrid of Information Retrieval and Linguistic Creativity</a></p>
<p>13 0.51067513 <a title="297-lsi-13" href="./acl-2011-An_ERP-based_Brain-Computer_Interface_for_text_entry_using_Rapid_Serial_Visual_Presentation_and_Language_Modeling.html">35 acl-2011-An ERP-based Brain-Computer Interface for text entry using Rapid Serial Visual Presentation and Language Modeling</a></p>
<p>14 0.50965935 <a title="297-lsi-14" href="./acl-2011-NULEX%3A_An_Open-License_Broad_Coverage_Lexicon.html">229 acl-2011-NULEX: An Open-License Broad Coverage Lexicon</a></p>
<p>15 0.4999789 <a title="297-lsi-15" href="./acl-2011-Web-Scale_Features_for_Full-Scale_Parsing.html">333 acl-2011-Web-Scale Features for Full-Scale Parsing</a></p>
<p>16 0.4852117 <a title="297-lsi-16" href="./acl-2011-Does_Size_Matter_-_How_Much_Data_is_Required_to_Train_a_REG_Algorithm%3F.html">102 acl-2011-Does Size Matter - How Much Data is Required to Train a REG Algorithm?</a></p>
<p>17 0.48500931 <a title="297-lsi-17" href="./acl-2011-Extracting_Social_Power_Relationships_from_Natural_Language.html">133 acl-2011-Extracting Social Power Relationships from Natural Language</a></p>
<p>18 0.47954524 <a title="297-lsi-18" href="./acl-2011-Semi-supervised_condensed_nearest_neighbor_for_part-of-speech_tagging.html">278 acl-2011-Semi-supervised condensed nearest neighbor for part-of-speech tagging</a></p>
<p>19 0.47736245 <a title="297-lsi-19" href="./acl-2011-Piggyback%3A_Using_Search_Engines_for_Robust_Cross-Domain_Named_Entity_Recognition.html">246 acl-2011-Piggyback: Using Search Engines for Robust Cross-Domain Named Entity Recognition</a></p>
<p>20 0.47269893 <a title="297-lsi-20" href="./acl-2011-Language_Use%3A_What_can_it_tell_us%3F.html">194 acl-2011-Language Use: What can it tell us?</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(8, 0.058), (12, 0.31), (15, 0.01), (26, 0.016), (31, 0.074), (36, 0.019), (41, 0.014), (43, 0.025), (53, 0.033), (69, 0.083), (78, 0.083), (79, 0.037), (88, 0.019), (90, 0.067), (97, 0.036)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.67508745 <a title="297-lda-1" href="./acl-2011-That%27s_What_She_Said%3A_Double_Entendre_Identification.html">297 acl-2011-That's What She Said: Double Entendre Identification</a></p>
<p>Author: Chloe Kiddon ; Yuriy Brun</p><p>Abstract: Humor identification is a hard natural language understanding problem. We identify a subproblem — the “that’s what she said” problem with two distinguishing characteristics: (1) use of nouns that are euphemisms for sexually explicit nouns and (2) structure common in the erotic domain. We address this problem in a classification approach that includes features that model those two characteristics. Experiments on web data demonstrate that our approach improves precision by 12% over baseline techniques that use only word-based features. —</p><p>2 0.52848053 <a title="297-lda-2" href="./acl-2011-IMASS%3A_An_Intelligent_Microblog_Analysis_and_Summarization_System.html">156 acl-2011-IMASS: An Intelligent Microblog Analysis and Summarization System</a></p>
<p>Author: Jui-Yu Weng ; Cheng-Lun Yang ; Bo-Nian Chen ; Yen-Kai Wang ; Shou-De Lin</p><p>Abstract: This paper presents a system to summarize a Microblog post and its responses with the goal to provide readers a more constructive and concise set of information for efficient digestion. We introduce a novel two-phase summarization scheme. In the first phase, the post plus its responses are classified into four categories based on the intention, interrogation, sharing, discussion and chat. For each type of post, in the second phase, we exploit different strategies, including opinion analysis, response pair identification, and response relevancy detection, to summarize and highlight critical information to display. This system provides an alternative thinking about machinesummarization: by utilizing AI approaches, computers are capable of constructing deeper and more user-friendly abstraction. 1</p><p>3 0.52345359 <a title="297-lda-3" href="./acl-2011-Reordering_Modeling_using_Weighted_Alignment_Matrices.html">265 acl-2011-Reordering Modeling using Weighted Alignment Matrices</a></p>
<p>Author: Wang Ling ; Tiago Luis ; Joao Graca ; Isabel Trancoso ; Luisa Coheur</p><p>Abstract: In most statistical machine translation systems, the phrase/rule extraction algorithm uses alignments in the 1-best form, which might contain spurious alignment points. The usage ofweighted alignment matrices that encode all possible alignments has been shown to generate better phrase tables for phrase-based systems. We propose two algorithms to generate the well known MSD reordering model using weighted alignment matrices. Experiments on the IWSLT 2010 evaluation datasets for two language pairs with different alignment algorithms show that our methods produce more accurate reordering models, as can be shown by an increase over the regular MSD models of 0.4 BLEU points in the BTEC French to English test set, and of 1.5 BLEU points in the DIALOG Chinese to English test set.</p><p>4 0.47708529 <a title="297-lda-4" href="./acl-2011-Word_Alignment_via_Submodular_Maximization_over_Matroids.html">340 acl-2011-Word Alignment via Submodular Maximization over Matroids</a></p>
<p>Author: Hui Lin ; Jeff Bilmes</p><p>Abstract: We cast the word alignment problem as maximizing a submodular function under matroid constraints. Our framework is able to express complex interactions between alignment components while remaining computationally efficient, thanks to the power and generality of submodular functions. We show that submodularity naturally arises when modeling word fertility. Experiments on the English-French Hansards alignment task show that our approach achieves lower alignment error rates compared to conventional matching based approaches.</p><p>5 0.46544752 <a title="297-lda-5" href="./acl-2011-Underspecifying_and_Predicting_Voice_for_Surface_Realisation_Ranking.html">317 acl-2011-Underspecifying and Predicting Voice for Surface Realisation Ranking</a></p>
<p>Author: Sina Zarriess ; Aoife Cahill ; Jonas Kuhn</p><p>Abstract: This paper addresses a data-driven surface realisation model based on a large-scale reversible grammar of German. We investigate the relationship between the surface realisation performance and the character of the input to generation, i.e. its degree of underspecification. We extend a syntactic surface realisation system, which can be trained to choose among word order variants, such that the candidate set includes active and passive variants. This allows us to study the interaction of voice and word order alternations in realistic German corpus data. We show that with an appropriately underspecified input, a linguistically informed realisation model trained to regenerate strings from the underlying semantic representation achieves 91.5% accuracy (over a baseline of 82.5%) in the prediction of the original voice. 1</p><p>6 0.45393875 <a title="297-lda-6" href="./acl-2011-Sentence_Ordering_Driven_by_Local_and_Global_Coherence_for_Summary_Generation.html">280 acl-2011-Sentence Ordering Driven by Local and Global Coherence for Summary Generation</a></p>
<p>7 0.45364895 <a title="297-lda-7" href="./acl-2011-Subjective_Natural_Language_Problems%3A_Motivations%2C_Applications%2C_Characterizations%2C_and_Implications.html">288 acl-2011-Subjective Natural Language Problems: Motivations, Applications, Characterizations, and Implications</a></p>
<p>8 0.45273381 <a title="297-lda-8" href="./acl-2011-Predicting_Relative_Prominence_in_Noun-Noun_Compounds.html">249 acl-2011-Predicting Relative Prominence in Noun-Noun Compounds</a></p>
<p>9 0.45197296 <a title="297-lda-9" href="./acl-2011-Metagrammar_engineering%3A_Towards_systematic_exploration_of_implemented_grammars.html">219 acl-2011-Metagrammar engineering: Towards systematic exploration of implemented grammars</a></p>
<p>10 0.45169356 <a title="297-lda-10" href="./acl-2011-Integrating_surprisal_and_uncertain-input_models_in_online_sentence_comprehension%3A_formal_techniques_and_empirical_results.html">176 acl-2011-Integrating surprisal and uncertain-input models in online sentence comprehension: formal techniques and empirical results</a></p>
<p>11 0.45157802 <a title="297-lda-11" href="./acl-2011-An_Affect-Enriched_Dialogue_Act_Classification_Model_for_Task-Oriented_Dialogue.html">33 acl-2011-An Affect-Enriched Dialogue Act Classification Model for Task-Oriented Dialogue</a></p>
<p>12 0.44982985 <a title="297-lda-12" href="./acl-2011-Beam-Width_Prediction_for_Efficient_Context-Free_Parsing.html">58 acl-2011-Beam-Width Prediction for Efficient Context-Free Parsing</a></p>
<p>13 0.44658896 <a title="297-lda-13" href="./acl-2011-Prototyping_virtual_instructors_from_human-human_corpora.html">252 acl-2011-Prototyping virtual instructors from human-human corpora</a></p>
<p>14 0.44587079 <a title="297-lda-14" href="./acl-2011-Ordering_Prenominal_Modifiers_with_a_Reranking_Approach.html">237 acl-2011-Ordering Prenominal Modifiers with a Reranking Approach</a></p>
<p>15 0.44535634 <a title="297-lda-15" href="./acl-2011-Unary_Constraints_for_Efficient_Context-Free_Parsing.html">316 acl-2011-Unary Constraints for Efficient Context-Free Parsing</a></p>
<p>16 0.44487178 <a title="297-lda-16" href="./acl-2011-Towards_Tracking_Semantic_Change_by_Visual_Analytics.html">307 acl-2011-Towards Tracking Semantic Change by Visual Analytics</a></p>
<p>17 0.44477731 <a title="297-lda-17" href="./acl-2011-A_Class_of_Submodular_Functions_for_Document_Summarization.html">4 acl-2011-A Class of Submodular Functions for Document Summarization</a></p>
<p>18 0.44460714 <a title="297-lda-18" href="./acl-2011-Turn-Taking_Cues_in_a_Human_Tutoring_Corpus.html">312 acl-2011-Turn-Taking Cues in a Human Tutoring Corpus</a></p>
<p>19 0.44442135 <a title="297-lda-19" href="./acl-2011-Prefix_Probability_for_Probabilistic_Synchronous_Context-Free_Grammars.html">250 acl-2011-Prefix Probability for Probabilistic Synchronous Context-Free Grammars</a></p>
<p>20 0.44406229 <a title="297-lda-20" href="./acl-2011-Semantic_Representation_of_Negation_Using_Focus_Detection.html">273 acl-2011-Semantic Representation of Negation Using Focus Detection</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
