<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>329 acl-2011-Using Deep Morphology to Improve Automatic Error Detection in Arabic Handwriting Recognition</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-329" href="#">acl2011-329</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>329 acl-2011-Using Deep Morphology to Improve Automatic Error Detection in Arabic Handwriting Recognition</h1>
<br/><p>Source: <a title="acl-2011-329-pdf" href="http://aclweb.org/anthology//P/P11/P11-1088.pdf">pdf</a></p><p>Author: Nizar Habash ; Ryan Roth</p><p>Abstract: Arabic handwriting recognition (HR) is a challenging problem due to Arabic’s connected letter forms, consonantal diacritics and rich morphology. In this paper we isolate the task of identification of erroneous words in HR from the task of producing corrections for these words. We consider a variety of linguistic (morphological and syntactic) and non-linguistic features to automatically identify these errors. Our best approach achieves a roughly ∼15% absolute increase in F-score aov reoru ag hsliym ∼pl1e5 b%ut a rbesaoslounteab inlec breaasseeli inne. F -Asc doreetailed error analysis shows that linguistic features, such as lemma (i.e., citation form) models, help improve HR-error detection precisely where we expect them to: semantically incoherent error words.</p><p>Reference: <a title="acl-2011-329-reference" href="../acl2011_reference/acl-2011-Using_Deep_Morphology_to_Improve_Automatic_Error_Detection_in_Arabic_Handwriting_Recognition_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Roth Center for Computational Learning Systems Columbia University { habash ,ryanr } @ ccl s . [sent-2, score-0.11]
</p><p>2 edu  Abstract Arabic handwriting recognition (HR) is a challenging problem due to Arabic’s connected letter forms, consonantal diacritics and rich morphology. [sent-4, score-0.301]
</p><p>3 F -Asc doreetailed error analysis shows that linguistic features, such as lemma (i. [sent-8, score-0.222]
</p><p>4 , citation form) models, help improve HR-error detection precisely where we expect them to: semantically incoherent error words. [sent-10, score-0.181]
</p><p>5 Arabic, however, possesses a complex orthography and morphology that makes OCR more difficult (Märgner and Abed, 2009; Halima and Alimi, 2009; Magdy and Darwish, 2006). [sent-12, score-0.068]
</p><p>6 OCR of Arabic handwritten text (handwriting recognition, or HR), whether online or offline, is even more challenging compared to printed Arabic OCR, where the uniformity of letter shapes and other factors allow for easier recognition (Biadsy et al. [sent-14, score-0.141]
</p><p>7 In this paper, we present a HR error detection system that uses deep lexical and morphological feature models to locate  possible "problem zones" words or phrases that are likely incorrect in Arabic HR output. [sent-20, score-0.334]
</p><p>8 , 2009) to generate an N-best list of hypotheses for each of several scanned segments of Arabic handwriting. [sent-23, score-0.109]
</p><p>9 Our problem zone detection (PZD) system then tags the potentially erroneous (problem) words. [sent-24, score-0.104]
</p><p>10 Section 3 presents an analysis of HR errors and defines what is considered a problem zone to be tagged. [sent-29, score-0.118]
</p><p>11 –  –  2  Arabic Handwriting Recognition Challenges  Arabic has several orthographic and morphological properties that make HR challenging (Darwish and Oard, 2002; Magdy and Darwish, 2006; Märgner and Abed, 2009). [sent-34, score-0.193]
</p><p>12 A lemma is a particular word form used to represent the lexeme word set a citation form that stands in for the class (Habash, 2010). [sent-66, score-0.123]
</p><p>13 the lemma abstracts over inflectional morphology, the root abstracts over both inflectional and derivational morphology and thus provides a very high level of lexical abstraction, indicating the “core” meaning of the word. [sent-87, score-0.307]
</p><p>14 Arabic morphology allows for tens of billions of potential, legal words (Magdy and Darwish, 2006; Moftah et al. [sent-105, score-0.104]
</p><p>15 In this paper we consider the value of morpho-  lexical and morpho-syntactic features such as lemmas and part-of-speech tags, respectively, that may allow machine learning algorithms to learn generalizations. [sent-108, score-0.09]
</p><p>16 Other researchers have used stems for OCR correction (Magdy and Darwish, 2006); we discuss their work and compare to it in Section 6, but we do not present a direct experimental comparison. [sent-111, score-0.086]
</p><p>17 1 HR Error Classifications We can classify three types of HR errors: substitutions, insertions and deletions. [sent-113, score-0.072]
</p><p>18 An insertion error is typically paired with a substitution error, where the two errors reflect a mis-identification of a single word as two words. [sent-116, score-0.25]
</p><p>19 In the dev set that we study here (see Section 4. [sent-119, score-0.121]
</p><p>20 The second row shows an automatically  which words in the hypothesis  generated hypothesis of the same sentence. [sent-162, score-0.116]
</p><p>21 The hypothesis roughly translates as ‘I loan then O ’Moslems Pattani Constantinople, and Persia and taking from whom that you spend on him N Yeoh high quality’ . [sent-167, score-0.093]
</p><p>22 of all deletion errors, almost 22% of all insertion errors and less than 5% of substitution errors. [sent-168, score-0.187]
</p><p>23 5% of all errors, are almost 14% of deletions, 7% of insertions and just over 2% of all substitutions. [sent-170, score-0.072]
</p><p>24 Punctuation and digits bring different challenges: whereas punctuation marks are a small class, their shape is often confusable with Arabic letters or letter components, e. [sent-171, score-0.125]
</p><p>25 5% are simple orthographic variants that are often normalized in Arabic NLP because they result from frequ? [sent-182, score-0.09]
</p><p>26 9% can be added to the orthographic variant sum (since all of these cases can share the same lemmas). [sent-192, score-0.09]
</p><p>27 The large proportion of errors involving lemma dif-  877  ferences is consistent with the perception that most OCR/HR errors create semantically incoherent sentences. [sent-198, score-0.28]
</p><p>28 This suggests that lemma models can be helpful in identifying such errors. [sent-199, score-0.161]
</p><p>29 3 We decided in this paper to use a simple binary problem tag: a hypothesis word is tagged as "PROB" if it is the result of an insertion or substitution of a word. [sent-203, score-0.148]
</p><p>30 This data consists of high-resolution (600 dpi) handwriting scans of Arabic text taken from newswire articles, web logs and 3For clarity, we refer to these tags as ‘gold’, whereas the correct segment for a given hypothesis set is called the ‘reference’ . [sent-211, score-0.362]
</p><p>31 4 For training, we consider two sets of size 2000 and 4000 segments  (S) with the 10 top-ranked hypotheses (H) for each segment to provide additional variations. [sent-221, score-0.15]
</p><p>32 The dev and test sets use 500 segments with one top-ranked hypothesis each {H=1 }. [sent-223, score-0.239]
</p><p>33 2  PZD Models and Features  The PZD system relies on a set of SVM classifiers trained using morphological and lexical features. [sent-231, score-0.103]
</p><p>34 For the models presented in this paper, the static feature window context size is set to +/- 2 words; the previous two (dynamic) classifications (i. [sent-234, score-0.085]
</p><p>35 5We conducted additional experiments where we varied the number of segments and hypotheses and found that the system benefited from added variety of segments more than hypotheses. [sent-239, score-0.169]
</p><p>36 In order to obtain the morphological features, all of the training and test data is passed through MADA 3. [sent-245, score-0.103]
</p><p>37 0, a software tool for Arabic morphological analysis disambiguation (Habash and Rambow, 2005; Roth et al. [sent-246, score-0.103]
</p><p>38 For these experiments, MADA provides the pos (using MADA’s native 34-tag set) and the lemma for each word. [sent-249, score-0.123]
</p><p>39 In addition to using the MADA features directly, we also develop a set of nine N-gram models (where N=1, 2, and 3) for the nw, pos, and lem features defined in Table 2. [sent-251, score-0.179]
</p><p>40 The conf is defined here as the ratio of the number of hypotheses in the N-  best list that the word appears in to the total number of hypotheses. [sent-259, score-0.22]
</p><p>41 We present the results in terms of F-score only for simplicity; we then conduct an error analysis that examines precision and recall. [sent-265, score-0.099]
</p><p>42 Rather then exhaustively test every possible feature combination, we selectively choose feature subsets that can be compared to gain a sense of the incremental benefit provided  by individual features. [sent-269, score-0.094]
</p><p>43 1 Simple Features Table 3 illustrates the result of taking a baseline feature set (containing word as the only feature) and adding a single feature from the Simple set to it. [sent-272, score-0.094]
</p><p>44 The training set used was { S=2000, H=10} and the models were evaluated on the dev set. [sent-282, score-0.159]
</p><p>45 The training set used was { S=2000, H=10} and the models were evaluated on the dev set. [sent-286, score-0.159]
</p><p>46 Here, the best performer is the model which utilizes the word, nw N-grams,  Table 5: PZD F-scores for models when word confidence is added to the feature set. [sent-296, score-0.12]
</p><p>47 The training set used was { S=2000, H=10} and the models were evaluated on the dev set. [sent-297, score-0.159]
</p><p>48 %Imp is the relative improvement gained by adding the conf feature. [sent-301, score-0.171]
</p><p>49 However, the differences among this model and the other models using lem Table 4 are not statistically significant. [sent-303, score-0.109]
</p><p>50 3 Word Confidence The conf feature deserves special consideration because it is the only feature which draws on information from across the entire hypothesis set. [sent-308, score-0.323]
</p><p>51 In Table 5, we show the effect of adding conf as a feature to several base feature sets taken from Table 4. [sent-309, score-0.265]
</p><p>52 Except for the baseline case, conf provides a relatively consistent benefit. [sent-310, score-0.171]
</p><p>53 3%) improvement  gained by adding conf to the word baseline shows that conf is a valuable feature, but the smaller improvements in the other models indicate that the information it provides largely overlaps with the information already present in those models. [sent-312, score-0.38]
</p><p>54 With this decision comes the implicit as880  Table 6: PZD F-scores for selected models when the number of training segments (S) is doubled. [sent-318, score-0.098]
</p><p>55 The training set used was { S=2000, H=10} and { S=4000, H=10}, and the models were evaluated on the dev set. [sent-319, score-0.159]
</p><p>56 We test this assumption by taking the best-performing feature sets from Table 5 and training new models using twice the training data { S=4000} . [sent-323, score-0.085]
</p><p>57 In each case, the improvements are relatively consistent (and on the order of the gains provided by the  inclusion of conf as seen in Table 5), indicating that the model performance does scale with data size. [sent-325, score-0.171]
</p><p>58 We note that the value of doubling S is roughly 3-6x times greater for the word baseline than the others; however, simply adding conf to the baseline provides an even greater improvement than doubling S. [sent-327, score-0.206]
</p><p>59 The differences between these models and the first two models in the table are statistically significant (p<0. [sent-329, score-0.076]
</p><p>60 For convenience, in the next section we refer to the third model listed in Table 6 as the best system (because it has the highest absolute F-score on the large data set), but readers should recall that these four models are roughly equivalent in performance. [sent-331, score-0.073]
</p><p>61 %Prob shows the distribution of problem words into different word types (word, punctuation and digit) and error types. [sent-354, score-0.146]
</p><p>62 INS, DEL and SUB stand for insertion, deletion and substitution error types, respectively. [sent-355, score-0.183]
</p><p>63 We also consider the percentage of recall per error type, such as word/punctuation/digit or deletion/insertion/substitution and different types of substitution errors see Table 7 (b). [sent-361, score-0.208]
</p><p>64 The second column in this table (%Prob) shows the distribution of gold-tagged problem words into word and error type categories. [sent-362, score-0.099]
</p><p>65 In terms of error type, the performance on substitutions is better than insertions, which is in turn better than deletions, for all systems compared. [sent-366, score-0.159]
</p><p>66 This makes sense since deletions are rather hard to detect and they are marked on possibly correct adjacent words, which may confuse the classifiers. [sent-367, score-0.097]
</p><p>67 Considering substitutions in more detail, we see that surprisingly, the simple approach of using the word feature only (without conf) correctly recalls a bigger proportion of problems involving orthographic variants than other settings. [sent-369, score-0.197]
</p><p>68 Error types that include semantic variations (different lemmas) or shared lemmas (but not explained by orthographic variation), are by contrast much harder for the simple models. [sent-371, score-0.145]
</p><p>69 The more complex models do quite well recalling errors involving semantically incoherent substitutions (around 77. [sent-372, score-0.194]
</p><p>70 7% of those cases)  and words that share the same lemma but vary in inflectional features (63% of those cases). [sent-373, score-0.216]
</p><p>71 The simple addition of data seems to contribute more towards the orthographic variation errors and less towards semantic errors. [sent-375, score-0.151]
</p><p>72 1, the trivial baseline of the test set is comparable to the dev set. [sent-382, score-0.167]
</p><p>73 However, the test set is harder to tag than the dev set; this can be seen in the overall lower F-scores. [sent-383, score-0.171]
</p><p>74 That said, the relative order of performing features is the same as with the dev set, confirming that our best model is optimal for test too. [sent-384, score-0.156]
</p><p>75 l84163  Table 8: Results on test set of 500 segments with one hypothesis each. [sent-389, score-0.118]
</p><p>76 train is less than dev and train: 63% versus 81%, respectively on { S=4000}. [sent-391, score-0.121]
</p><p>77 We restricted the search to the systems in the error analysis (Table 7). [sent-394, score-0.099]
</p><p>78 6 Preliminary Tag Set Exploration In all of the experiments described so far, the PZD models tag words using a binary tag set of PROB/OK. [sent-416, score-0.138]
</p><p>79 We may also consider more complex tag sets based on problem subtypes, such  882 as SUB/INS/DEL/OK (where all the problem subtypes are differentiated), SUB/INS/OK (ignores deletions), and SUB/OK (ignores deletions and insertions). [sent-417, score-0.147]
</p><p>80 Therefore we compare the % error reduction over the trivial baseline achieved in each case. [sent-419, score-0.145]
</p><p>81 3% error reduction over its trivial baseline (using the dev set). [sent-421, score-0.266]
</p><p>82 We suspect that the very low relative number of deletions (7. [sent-428, score-0.097]
</p><p>83 9% in the dev data) and the awkwardness of a DEL tag indicating a neighboring deletion (rather than the current word) may be confusing the models, and so ignoring them seems to result in a clearer picture. [sent-429, score-0.207]
</p><p>84 6  Related Work  Common OCR/HR post-processing strategies are similar to spelling correction solutions involving dictionary lookup (Kukich, 1992; Jurafsky and Martin, 2000) and morphological restrictions (Domeij et al. [sent-430, score-0.263]
</p><p>85 Error detection systems using dictionary lookup can sometimes be improved by adding entries representing morphological variations of root words, particularly if the language involved has a complex morphology (Pal et al. [sent-432, score-0.254]
</p><p>86 Alternatively, morphological information can be used to construct supplemental lexicons or language models (Sari and Sellami, 2002; Magdy and Darwish, 2006). [sent-434, score-0.141]
</p><p>87 In essence, their method of detection is the same as our trivial baseline. [sent-436, score-0.093]
</p><p>88 The morphological features they use are shallow and restricted to breaking up a word into prefix+stem+suffix; whereas we analyze words into their lemmas, abstracting away over  a large number of variations. [sent-437, score-0.138]
</p><p>89 In their work, the morphological features did not help (and even hurt a little), whereas for us, the lemma feature actually helped. [sent-439, score-0.308]
</p><p>90 Perhaps a combination of the two kinds of efforts can push the perfomance on correction even further by biasing towards problematic words and avoiding incorrectly changing correct words. [sent-442, score-0.086]
</p><p>91 7  Conclusions and Future Work  We presented a study with various settings (linguistic and non-linguistic features and learning curve) for automatically detecting problem words in Arabic handwriting recognition. [sent-444, score-0.249]
</p><p>92 Aso lduetteail inedcr error ianna Fl-ysis shows that linguistic features, such as lemma models, help improve HR-error detection specifically where we expect them to: identifying semantically inconsistent error words. [sent-446, score-0.368]
</p><p>93 In the future, we plan to continue improving our system by considering smarter trainable combination techniques and by separating the training for different types of errors, particularly deletions from insertions and substitutions. [sent-447, score-0.169]
</p><p>94 We would also like to conduct an extended evaluation comparing other types of morphological features, such as roots and stems, directly. [sent-448, score-0.103]
</p><p>95 One additional idea is to implement a lemma-confidence feature that examines lemma use in hypotheses across the document. [sent-449, score-0.219]
</p><p>96 We also plan to integrate our system with a system  883 for producing correction hypotheses. [sent-451, score-0.086]
</p><p>97 We also will consider different uses for the basic system setup we developed to identify other types of text errors, such as spelling errors or code-switching between languages and dialects. [sent-452, score-0.099]
</p><p>98 Detection of spelling errors in Swedish not using a word list en clair. [sent-467, score-0.099]
</p><p>99 Error-tolerant finite-state recognition with applications to morphological analysis and spelling correction. [sent-547, score-0.194]
</p><p>100 OCR error correction of an inflectional Indian language using morphological parsing. [sent-556, score-0.346]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('arabic', 0.398), ('pzd', 0.337), ('hr', 0.304), ('handwriting', 0.214), ('ocr', 0.181), ('conf', 0.171), ('darwish', 0.167), ('magdy', 0.15), ('mada', 0.132), ('saleem', 0.131), ('lemma', 0.123), ('dev', 0.121), ('natarajan', 0.115), ('habash', 0.11), ('morphological', 0.103), ('prob', 0.1), ('binned', 0.1), ('error', 0.099), ('deletions', 0.097), ('rgner', 0.094), ('orthographic', 0.09), ('correction', 0.086), ('nizar', 0.079), ('bente', 0.076), ('choukri', 0.076), ('khalid', 0.076), ('maegaard', 0.076), ('abed', 0.075), ('insertions', 0.072), ('lem', 0.071), ('morphology', 0.068), ('medar', 0.066), ('errors', 0.061), ('substitutions', 0.06), ('segments', 0.06), ('hypothesis', 0.058), ('inflectional', 0.058), ('cairo', 0.057), ('zone', 0.057), ('egypt', 0.057), ('indentation', 0.056), ('shirin', 0.056), ('lemmas', 0.055), ('printed', 0.054), ('recognition', 0.053), ('tag', 0.05), ('accumulative', 0.049), ('scans', 0.049), ('hypotheses', 0.049), ('substitution', 0.048), ('feature', 0.047), ('detection', 0.047), ('punctuation', 0.047), ('office', 0.046), ('rohit', 0.046), ('oard', 0.046), ('digit', 0.046), ('trivial', 0.046), ('digits', 0.044), ('insertion', 0.042), ('segment', 0.041), ('models', 0.038), ('spelling', 0.038), ('byblos', 0.037), ('constantinople', 0.037), ('cursive', 0.037), ('domeij', 0.037), ('halima', 0.037), ('imp', 0.037), ('iwfhr', 0.037), ('kamali', 0.037), ('kolak', 0.037), ('mkatb', 0.037), ('mktb', 0.037), ('moftah', 0.037), ('mohsen', 0.037), ('moslems', 0.037), ('persia', 0.037), ('premkumar', 0.037), ('sari', 0.037), ('subramanian', 0.037), ('lookup', 0.036), ('prasad', 0.036), ('legal', 0.036), ('deletion', 0.036), ('nw', 0.035), ('features', 0.035), ('incoherent', 0.035), ('roughly', 0.035), ('bin', 0.034), ('owen', 0.034), ('rambow', 0.034), ('letter', 0.034), ('editors', 0.033), ('soudi', 0.033), ('kareem', 0.033), ('larkey', 0.033), ('krishna', 0.033), ('pursuing', 0.033), ('zones', 0.033)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000008 <a title="329-tfidf-1" href="./acl-2011-Using_Deep_Morphology_to_Improve_Automatic_Error_Detection_in_Arabic_Handwriting_Recognition.html">329 acl-2011-Using Deep Morphology to Improve Automatic Error Detection in Arabic Handwriting Recognition</a></p>
<p>Author: Nizar Habash ; Ryan Roth</p><p>Abstract: Arabic handwriting recognition (HR) is a challenging problem due to Arabic’s connected letter forms, consonantal diacritics and rich morphology. In this paper we isolate the task of identification of erroneous words in HR from the task of producing corrections for these words. We consider a variety of linguistic (morphological and syntactic) and non-linguistic features to automatically identify these errors. Our best approach achieves a roughly ∼15% absolute increase in F-score aov reoru ag hsliym ∼pl1e5 b%ut a rbesaoslounteab inlec breaasseeli inne. F -Asc doreetailed error analysis shows that linguistic features, such as lemma (i.e., citation form) models, help improve HR-error detection precisely where we expect them to: semantically incoherent error words.</p><p>2 0.27313983 <a title="329-tfidf-2" href="./acl-2011-A_Corpus_for_Modeling_Morpho-Syntactic_Agreement_in_Arabic%3A_Gender%2C_Number_and_Rationality.html">7 acl-2011-A Corpus for Modeling Morpho-Syntactic Agreement in Arabic: Gender, Number and Rationality</a></p>
<p>Author: Sarah Alkuhlani ; Nizar Habash</p><p>Abstract: We present an enriched version of the Penn Arabic Treebank (Maamouri et al., 2004), where latent features necessary for modeling morpho-syntactic agreement in Arabic are manually annotated. We describe our process for efficient annotation, and present the first quantitative analysis of Arabic morphosyntactic phenomena.</p><p>3 0.24635389 <a title="329-tfidf-3" href="./acl-2011-Improving_Arabic_Dependency_Parsing_with_Form-based_and_Functional_Morphological_Features.html">164 acl-2011-Improving Arabic Dependency Parsing with Form-based and Functional Morphological Features</a></p>
<p>Author: Yuval Marton ; Nizar Habash ; Owen Rambow</p><p>Abstract: We explore the contribution of morphological features both lexical and inflectional to dependency parsing of Arabic, a morphologically rich language. Using controlled experiments, we find that definiteness, person, number, gender, and the undiacritzed lemma are most helpful for parsing on automatically tagged input. We further contrast the contribution of form-based and functional features, and show that functional gender and number (e.g., “broken plurals”) and the related rationality feature improve over form-based features. It is the first time functional morphological features are used for Arabic NLP. – –</p><p>4 0.16948442 <a title="329-tfidf-4" href="./acl-2011-The_Arabic_Online_Commentary_Dataset%3A_an_Annotated_Dataset_of_Informal_Arabic_with_High_Dialectal_Content.html">299 acl-2011-The Arabic Online Commentary Dataset: an Annotated Dataset of Informal Arabic with High Dialectal Content</a></p>
<p>Author: Omar F. Zaidan ; Chris Callison-Burch</p><p>Abstract: The written form of Arabic, Modern Standard Arabic (MSA), differs quite a bit from the spoken dialects of Arabic, which are the true “native” languages of Arabic speakers used in daily life. However, due to MSA’s prevalence in written form, almost all Arabic datasets have predominantly MSA content. We present the Arabic Online Commentary Dataset, a 52M-word monolingual dataset rich in dialectal content, and we describe our long-term annotation effort to identify the dialect level (and dialect itself) in each sentence of the dataset. So far, we have labeled 108K sentences, 41% of which as having dialectal content. We also present experimental results on the task of automatic dialect identification, using the collected labels for training and evaluation.</p><p>5 0.14498292 <a title="329-tfidf-5" href="./acl-2011-Subjectivity_and_Sentiment_Analysis_of_Modern_Standard_Arabic.html">289 acl-2011-Subjectivity and Sentiment Analysis of Modern Standard Arabic</a></p>
<p>Author: Muhammad Abdul-Mageed ; Mona Diab ; Mohammed Korayem</p><p>Abstract: Although Subjectivity and Sentiment Analysis (SSA) has been witnessing a flurry of novel research, there are few attempts to build SSA systems for Morphologically-Rich Languages (MRL). In the current study, we report efforts to partially fill this gap. We present a newly developed manually annotated corpus ofModern Standard Arabic (MSA) together with a new polarity lexicon.The corpus is a collection of newswire documents annotated on the sentence level. We also describe an automatic SSA tagging system that exploits the annotated data. We investigate the impact of different levels ofpreprocessing settings on the SSA classification task. We show that by explicitly accounting for the rich morphology the system is able to achieve significantly higher levels of performance.</p><p>6 0.13736849 <a title="329-tfidf-6" href="./acl-2011-Automatic_Headline_Generation_using_Character_Cross-Correlation.html">51 acl-2011-Automatic Headline Generation using Character Cross-Correlation</a></p>
<p>7 0.13236724 <a title="329-tfidf-7" href="./acl-2011-Unsupervised_Bilingual_Morpheme_Segmentation_and_Alignment_with_Context-rich_Hidden_Semi-Markov_Models.html">318 acl-2011-Unsupervised Bilingual Morpheme Segmentation and Alignment with Context-rich Hidden Semi-Markov Models</a></p>
<p>8 0.093941361 <a title="329-tfidf-8" href="./acl-2011-Data_point_selection_for_cross-language_adaptation_of_dependency_parsers.html">92 acl-2011-Data point selection for cross-language adaptation of dependency parsers</a></p>
<p>9 0.092261724 <a title="329-tfidf-9" href="./acl-2011-Automated_Whole_Sentence_Grammar_Correction_Using_a_Noisy_Channel_Model.html">46 acl-2011-Automated Whole Sentence Grammar Correction Using a Noisy Channel Model</a></p>
<p>10 0.088589199 <a title="329-tfidf-10" href="./acl-2011-A_Discriminative_Model_for_Joint_Morphological_Disambiguation_and_Dependency_Parsing.html">10 acl-2011-A Discriminative Model for Joint Morphological Disambiguation and Dependency Parsing</a></p>
<p>11 0.084408775 <a title="329-tfidf-11" href="./acl-2011-Contrasting_Multi-Lingual_Prosodic_Cues_to_Predict_Verbal_Feedback_for_Rapport.html">83 acl-2011-Contrasting Multi-Lingual Prosodic Cues to Predict Verbal Feedback for Rapport</a></p>
<p>12 0.082262844 <a title="329-tfidf-12" href="./acl-2011-Combining_Morpheme-based_Machine_Translation_with_Post-processing_Morpheme_Prediction.html">75 acl-2011-Combining Morpheme-based Machine Translation with Post-processing Morpheme Prediction</a></p>
<p>13 0.079366401 <a title="329-tfidf-13" href="./acl-2011-Two_Easy_Improvements_to_Lexical_Weighting.html">313 acl-2011-Two Easy Improvements to Lexical Weighting</a></p>
<p>14 0.078246325 <a title="329-tfidf-14" href="./acl-2011-Improved_Modeling_of_Out-Of-Vocabulary_Words_Using_Morphological_Classes.html">163 acl-2011-Improved Modeling of Out-Of-Vocabulary Words Using Morphological Classes</a></p>
<p>15 0.073001668 <a title="329-tfidf-15" href="./acl-2011-Identifying_the_Semantic_Orientation_of_Foreign_Words.html">162 acl-2011-Identifying the Semantic Orientation of Foreign Words</a></p>
<p>16 0.068072416 <a title="329-tfidf-16" href="./acl-2011-An_exponential_translation_model_for_target_language_morphology.html">44 acl-2011-An exponential translation model for target language morphology</a></p>
<p>17 0.067225978 <a title="329-tfidf-17" href="./acl-2011-Automatic_Detection_and_Correction_of_Errors_in_Dependency_Treebanks.html">48 acl-2011-Automatic Detection and Correction of Errors in Dependency Treebanks</a></p>
<p>18 0.06597624 <a title="329-tfidf-18" href="./acl-2011-Goodness%3A_A_Method_for_Measuring_Machine_Translation_Confidence.html">146 acl-2011-Goodness: A Method for Measuring Machine Translation Confidence</a></p>
<p>19 0.065885909 <a title="329-tfidf-19" href="./acl-2011-A_Fast_and_Accurate_Method_for_Approximate_String_Search.html">11 acl-2011-A Fast and Accurate Method for Approximate String Search</a></p>
<p>20 0.0647659 <a title="329-tfidf-20" href="./acl-2011-EdIt%3A_A_Broad-Coverage_Grammar_Checker_Using_Pattern_Grammar.html">108 acl-2011-EdIt: A Broad-Coverage Grammar Checker Using Pattern Grammar</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.174), (1, -0.024), (2, -0.002), (3, -0.05), (4, -0.087), (5, 0.009), (6, 0.176), (7, -0.022), (8, 0.052), (9, 0.142), (10, -0.148), (11, -0.025), (12, -0.243), (13, 0.134), (14, 0.146), (15, -0.092), (16, 0.061), (17, -0.032), (18, -0.167), (19, -0.079), (20, -0.069), (21, 0.052), (22, 0.098), (23, 0.04), (24, -0.066), (25, 0.002), (26, -0.059), (27, -0.021), (28, 0.074), (29, -0.006), (30, -0.078), (31, 0.02), (32, 0.007), (33, 0.024), (34, -0.069), (35, -0.084), (36, 0.01), (37, 0.008), (38, 0.086), (39, -0.057), (40, 0.046), (41, 0.033), (42, -0.036), (43, 0.13), (44, -0.019), (45, 0.002), (46, 0.049), (47, -0.035), (48, 0.003), (49, 0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.91827118 <a title="329-lsi-1" href="./acl-2011-A_Corpus_for_Modeling_Morpho-Syntactic_Agreement_in_Arabic%3A_Gender%2C_Number_and_Rationality.html">7 acl-2011-A Corpus for Modeling Morpho-Syntactic Agreement in Arabic: Gender, Number and Rationality</a></p>
<p>Author: Sarah Alkuhlani ; Nizar Habash</p><p>Abstract: We present an enriched version of the Penn Arabic Treebank (Maamouri et al., 2004), where latent features necessary for modeling morpho-syntactic agreement in Arabic are manually annotated. We describe our process for efficient annotation, and present the first quantitative analysis of Arabic morphosyntactic phenomena.</p><p>same-paper 2 0.90106547 <a title="329-lsi-2" href="./acl-2011-Using_Deep_Morphology_to_Improve_Automatic_Error_Detection_in_Arabic_Handwriting_Recognition.html">329 acl-2011-Using Deep Morphology to Improve Automatic Error Detection in Arabic Handwriting Recognition</a></p>
<p>Author: Nizar Habash ; Ryan Roth</p><p>Abstract: Arabic handwriting recognition (HR) is a challenging problem due to Arabic’s connected letter forms, consonantal diacritics and rich morphology. In this paper we isolate the task of identification of erroneous words in HR from the task of producing corrections for these words. We consider a variety of linguistic (morphological and syntactic) and non-linguistic features to automatically identify these errors. Our best approach achieves a roughly ∼15% absolute increase in F-score aov reoru ag hsliym ∼pl1e5 b%ut a rbesaoslounteab inlec breaasseeli inne. F -Asc doreetailed error analysis shows that linguistic features, such as lemma (i.e., citation form) models, help improve HR-error detection precisely where we expect them to: semantically incoherent error words.</p><p>3 0.86191827 <a title="329-lsi-3" href="./acl-2011-The_Arabic_Online_Commentary_Dataset%3A_an_Annotated_Dataset_of_Informal_Arabic_with_High_Dialectal_Content.html">299 acl-2011-The Arabic Online Commentary Dataset: an Annotated Dataset of Informal Arabic with High Dialectal Content</a></p>
<p>Author: Omar F. Zaidan ; Chris Callison-Burch</p><p>Abstract: The written form of Arabic, Modern Standard Arabic (MSA), differs quite a bit from the spoken dialects of Arabic, which are the true “native” languages of Arabic speakers used in daily life. However, due to MSA’s prevalence in written form, almost all Arabic datasets have predominantly MSA content. We present the Arabic Online Commentary Dataset, a 52M-word monolingual dataset rich in dialectal content, and we describe our long-term annotation effort to identify the dialect level (and dialect itself) in each sentence of the dataset. So far, we have labeled 108K sentences, 41% of which as having dialectal content. We also present experimental results on the task of automatic dialect identification, using the collected labels for training and evaluation.</p><p>4 0.8075161 <a title="329-lsi-4" href="./acl-2011-Improving_Arabic_Dependency_Parsing_with_Form-based_and_Functional_Morphological_Features.html">164 acl-2011-Improving Arabic Dependency Parsing with Form-based and Functional Morphological Features</a></p>
<p>Author: Yuval Marton ; Nizar Habash ; Owen Rambow</p><p>Abstract: We explore the contribution of morphological features both lexical and inflectional to dependency parsing of Arabic, a morphologically rich language. Using controlled experiments, we find that definiteness, person, number, gender, and the undiacritzed lemma are most helpful for parsing on automatically tagged input. We further contrast the contribution of form-based and functional features, and show that functional gender and number (e.g., “broken plurals”) and the related rationality feature improve over form-based features. It is the first time functional morphological features are used for Arabic NLP. – –</p><p>5 0.77854604 <a title="329-lsi-5" href="./acl-2011-Automatic_Headline_Generation_using_Character_Cross-Correlation.html">51 acl-2011-Automatic Headline Generation using Character Cross-Correlation</a></p>
<p>Author: Fahad Alotaiby</p><p>Abstract: Arabic language is a morphologically complex language. Affixes and clitics are regularly attached to stems which make direct comparison between words not practical. In this paper we propose a new automatic headline generation technique that utilizes character cross-correlation to extract best headlines and to overcome the Arabic language complex morphology. The system that uses character cross-correlation achieves ROUGE-L score of 0. 19384 while the exact word matching scores only 0. 17252 for the same set of documents. 1</p><p>6 0.64001763 <a title="329-lsi-6" href="./acl-2011-Subjectivity_and_Sentiment_Analysis_of_Modern_Standard_Arabic.html">289 acl-2011-Subjectivity and Sentiment Analysis of Modern Standard Arabic</a></p>
<p>7 0.44862914 <a title="329-lsi-7" href="./acl-2011-Contrasting_Multi-Lingual_Prosodic_Cues_to_Predict_Verbal_Feedback_for_Rapport.html">83 acl-2011-Contrasting Multi-Lingual Prosodic Cues to Predict Verbal Feedback for Rapport</a></p>
<p>8 0.42709237 <a title="329-lsi-8" href="./acl-2011-Unsupervised_Bilingual_Morpheme_Segmentation_and_Alignment_with_Context-rich_Hidden_Semi-Markov_Models.html">318 acl-2011-Unsupervised Bilingual Morpheme Segmentation and Alignment with Context-rich Hidden Semi-Markov Models</a></p>
<p>9 0.40818763 <a title="329-lsi-9" href="./acl-2011-Data_point_selection_for_cross-language_adaptation_of_dependency_parsers.html">92 acl-2011-Data point selection for cross-language adaptation of dependency parsers</a></p>
<p>10 0.37325725 <a title="329-lsi-10" href="./acl-2011-Using_Derivation_Trees_for_Treebank_Error_Detection.html">330 acl-2011-Using Derivation Trees for Treebank Error Detection</a></p>
<p>11 0.37262836 <a title="329-lsi-11" href="./acl-2011-Language_Use%3A_What_can_it_tell_us%3F.html">194 acl-2011-Language Use: What can it tell us?</a></p>
<p>12 0.36854416 <a title="329-lsi-12" href="./acl-2011-A_Discriminative_Model_for_Joint_Morphological_Disambiguation_and_Dependency_Parsing.html">10 acl-2011-A Discriminative Model for Joint Morphological Disambiguation and Dependency Parsing</a></p>
<p>13 0.34771979 <a title="329-lsi-13" href="./acl-2011-Unsupervised_Discovery_of_Rhyme_Schemes.html">321 acl-2011-Unsupervised Discovery of Rhyme Schemes</a></p>
<p>14 0.34601375 <a title="329-lsi-14" href="./acl-2011-Exploiting_Morphology_in_Turkish_Named_Entity_Recognition_System.html">124 acl-2011-Exploiting Morphology in Turkish Named Entity Recognition System</a></p>
<p>15 0.33621013 <a title="329-lsi-15" href="./acl-2011-Automated_Whole_Sentence_Grammar_Correction_Using_a_Noisy_Channel_Model.html">46 acl-2011-Automated Whole Sentence Grammar Correction Using a Noisy Channel Model</a></p>
<p>16 0.33537546 <a title="329-lsi-16" href="./acl-2011-Improved_Modeling_of_Out-Of-Vocabulary_Words_Using_Morphological_Classes.html">163 acl-2011-Improved Modeling of Out-Of-Vocabulary Words Using Morphological Classes</a></p>
<p>17 0.32579252 <a title="329-lsi-17" href="./acl-2011-Combining_Morpheme-based_Machine_Translation_with_Post-processing_Morpheme_Prediction.html">75 acl-2011-Combining Morpheme-based Machine Translation with Post-processing Morpheme Prediction</a></p>
<p>18 0.32500881 <a title="329-lsi-18" href="./acl-2011-An_exponential_translation_model_for_target_language_morphology.html">44 acl-2011-An exponential translation model for target language morphology</a></p>
<p>19 0.32359672 <a title="329-lsi-19" href="./acl-2011-Two_Easy_Improvements_to_Lexical_Weighting.html">313 acl-2011-Two Easy Improvements to Lexical Weighting</a></p>
<p>20 0.32242408 <a title="329-lsi-20" href="./acl-2011-NULEX%3A_An_Open-License_Broad_Coverage_Lexicon.html">229 acl-2011-NULEX: An Open-License Broad Coverage Lexicon</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.028), (17, 0.034), (26, 0.014), (31, 0.01), (37, 0.062), (39, 0.037), (41, 0.031), (55, 0.032), (59, 0.465), (72, 0.038), (91, 0.042), (96, 0.116), (97, 0.015)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.92291415 <a title="329-lda-1" href="./acl-2011-Unsupervised_Learning_of_Semantic_Relation_Composition.html">322 acl-2011-Unsupervised Learning of Semantic Relation Composition</a></p>
<p>Author: Eduardo Blanco ; Dan Moldovan</p><p>Abstract: This paper presents an unsupervised method for deriving inference axioms by composing semantic relations. The method is independent of any particular relation inventory. It relies on describing semantic relations using primitives and manipulating these primitives according to an algebra. The method was tested using a set of eight semantic relations yielding 78 inference axioms which were evaluated over PropBank.</p><p>2 0.87498945 <a title="329-lda-2" href="./acl-2011-Does_Size_Matter_-_How_Much_Data_is_Required_to_Train_a_REG_Algorithm%3F.html">102 acl-2011-Does Size Matter - How Much Data is Required to Train a REG Algorithm?</a></p>
<p>Author: Mariet Theune ; Ruud Koolen ; Emiel Krahmer ; Sander Wubben</p><p>Abstract: In this paper we investigate how much data is required to train an algorithm for attribute selection, a subtask of Referring Expressions Generation (REG). To enable comparison between different-sized training sets, a systematic training method was developed. The results show that depending on the complexity of the domain, training on 10 to 20 items may already lead to a good performance.</p><p>3 0.86768425 <a title="329-lda-3" href="./acl-2011-Semi-supervised_latent_variable_models_for_sentence-level_sentiment_analysis.html">279 acl-2011-Semi-supervised latent variable models for sentence-level sentiment analysis</a></p>
<p>Author: Oscar Tackstrom ; Ryan McDonald</p><p>Abstract: We derive two variants of a semi-supervised model for fine-grained sentiment analysis. Both models leverage abundant natural supervision in the form of review ratings, as well as a small amount of manually crafted sentence labels, to learn sentence-level sentiment classifiers. The proposed model is a fusion of a fully supervised structured conditional model and its partially supervised counterpart. This allows for highly efficient estimation and inference algorithms with rich feature definitions. We describe the two variants as well as their component models and verify experimentally that both variants give significantly improved results for sentence-level sentiment analysis compared to all baselines. 1 Sentence-level sentiment analysis In this paper, we demonstrate how combining coarse-grained and fine-grained supervision benefits sentence-level sentiment analysis an important task in the field of opinion classification and retrieval (Pang and Lee, 2008). Typical supervised learning approaches to sentence-level sentiment analysis rely on sentence-level supervision. While such fine-grained supervision rarely exist naturally, and thus requires labor intensive manual annotation effort (Wiebe et al., 2005), coarse-grained supervision is naturally abundant in the form of online review ratings. This coarse-grained supervision is, of course, less informative compared to fine-grained supervision, however, by combining a small amount of sentence-level supervision with a large amount of document-level supervision, we are able to substantially improve on the sentence-level classification task. Our work combines two strands of research: models for sentiment analysis that take document structure into account; – 569 Ryan McDonald Google, Inc., New York ryanmcd@ google com . and models that use latent variables to learn unobserved phenomena from that which can be observed. Exploiting document structure for sentiment analysis has attracted research attention since the early work of Pang and Lee (2004), who performed minimal cuts in a sentence graph to select subjective sentences. McDonald et al. (2007) later showed that jointly learning fine-grained (sentence) and coarsegrained (document) sentiment improves predictions at both levels. More recently, Yessenalina et al. (2010) described how sentence-level latent variables can be used to improve document-level prediction and Nakagawa et al. (2010) used latent variables over syntactic dependency trees to improve sentence-level prediction, using only labeled sentences for training. In a similar vein, Sauper et al. (2010) integrated generative content structure models with discriminative models for multi-aspect sentiment summarization and ranking. These approaches all rely on the availability of fine-grained annotations, but Ta¨ckstro¨m and McDonald (201 1) showed that latent variables can be used to learn fine-grained sentiment using only coarse-grained supervision. While this model was shown to beat a set of natural baselines with quite a wide margin, it has its shortcomings. Most notably, due to the loose constraints provided by the coarse supervision, it tends to only predict the two dominant fine-grained sentiment categories well for each document sentiment category, so that almost all sentences in positive documents are deemed positive or neutral, and vice versa for negative documents. As a way of overcoming these shortcomings, we propose to fuse a coarsely supervised model with a fully supervised model. Below, we describe two ways of achieving such a combined model in the framework of structured conditional latent variable models. Contrary to (generative) topic models (Mei et al., 2007; Titov and Proceedings ofP thoer t4l9atnhd A, Onrnuegaoln M,e Jeuntineg 19 o-f2 t4h,e 2 A0s1s1o.c?i ac t2io0n11 fo Ar Cssoocmiaptuiotanti foonra Clo Lminpguutiast i ocns:aslh Loirntpgaupisetrics , pages 569–574, Figure 1: a) Factor graph of the fully observed graphical model. b) Factor graph of the corresponding latent variable model. During training, shaded nodes are observed, while non-shaded nodes are unobserved. The input sentences si are always observed. Note that there are no factors connecting the document node, yd, with the input nodes, s, so that the sentence-level variables, ys, in effect form a bottleneck between the document sentiment and the input sentences. McDonald, 2008; Lin and He, 2009), structured conditional models can handle rich and overlapping features and allow for exact inference and simple gradient based estimation. The former models are largely orthogonal to the one we propose in this work and combining their merits might be fruitful. As shown by Sauper et al. (2010), it is possible to fuse generative document structure models and task specific structured conditional models. While we do model document structure in terms of sentiment transitions, we do not model topical structure. An interesting avenue for future work would be to extend the model of Sauper et al. (2010) to take coarse-grained taskspecific supervision into account, while modeling fine-grained task-specific aspects with latent variables. Note also that the proposed approach is orthogonal to semi-supervised and unsupervised induction of context independent (prior polarity) lexicons (Turney, 2002; Kim and Hovy, 2004; Esuli and Sebastiani, 2009; Rao and Ravichandran, 2009; Velikovich et al., 2010). The output of such models could readily be incorporated as features in the proposed model. 1.1 Preliminaries Let d be a document consisting of n sentences, s = (si)in=1, with a document–sentence-sequence pair denoted d = (d, s). Let yd = (yd, ys) denote random variables1 the document level sentiment, yd, and the sequence of sentence level sentiment, = (ysi)in=1 . – ys 1We are abusing notation throughout by using the same symbols to refer to random variables and their particular assignments. 570 In what follows, we assume that we have access to two training sets: a small set of fully labeled instances, DF = {(dj, and a large set of ydj)}jm=f1, coarsely labeled instances DC = {(dj, yjd)}jm=fm+fm+c1. Furthermore, we assume that yd and all yis take values in {POS, NEG, NEU}. We focus on structured conditional models in the exponential family, with the standard parametrization pθ(yd,ys|s) = expnhφ(yd,ys,s),θi − Aθ(s)o</p><p>4 0.86045712 <a title="329-lda-4" href="./acl-2011-Template-Based_Information_Extraction_without_the_Templates.html">293 acl-2011-Template-Based Information Extraction without the Templates</a></p>
<p>Author: Nathanael Chambers ; Dan Jurafsky</p><p>Abstract: Standard algorithms for template-based information extraction (IE) require predefined template schemas, and often labeled data, to learn to extract their slot fillers (e.g., an embassy is the Target of a Bombing template). This paper describes an approach to template-based IE that removes this requirement and performs extraction without knowing the template structure in advance. Our algorithm instead learns the template structure automatically from raw text, inducing template schemas as sets of linked events (e.g., bombings include detonate, set off, and destroy events) associated with semantic roles. We also solve the standard IE task, using the induced syntactic patterns to extract role fillers from specific documents. We evaluate on the MUC-4 terrorism dataset and show that we induce template structure very similar to handcreated gold structure, and we extract role fillers with an F1 score of .40, approaching the performance of algorithms that require full knowledge of the templates.</p><p>5 0.82023352 <a title="329-lda-5" href="./acl-2011-Models_and_Training_for_Unsupervised_Preposition_Sense_Disambiguation.html">224 acl-2011-Models and Training for Unsupervised Preposition Sense Disambiguation</a></p>
<p>Author: Dirk Hovy ; Ashish Vaswani ; Stephen Tratz ; David Chiang ; Eduard Hovy</p><p>Abstract: We present a preliminary study on unsupervised preposition sense disambiguation (PSD), comparing different models and training techniques (EM, MAP-EM with L0 norm, Bayesian inference using Gibbs sampling). To our knowledge, this is the first attempt at unsupervised preposition sense disambiguation. Our best accuracy reaches 56%, a significant improvement (at p <.001) of 16% over the most-frequent-sense baseline.</p><p>same-paper 6 0.79272294 <a title="329-lda-6" href="./acl-2011-Using_Deep_Morphology_to_Improve_Automatic_Error_Detection_in_Arabic_Handwriting_Recognition.html">329 acl-2011-Using Deep Morphology to Improve Automatic Error Detection in Arabic Handwriting Recognition</a></p>
<p>7 0.72361755 <a title="329-lda-7" href="./acl-2011-Automatic_Headline_Generation_using_Character_Cross-Correlation.html">51 acl-2011-Automatic Headline Generation using Character Cross-Correlation</a></p>
<p>8 0.61475402 <a title="329-lda-8" href="./acl-2011-Relation_Guided_Bootstrapping_of_Semantic_Lexicons.html">262 acl-2011-Relation Guided Bootstrapping of Semantic Lexicons</a></p>
<p>9 0.61175907 <a title="329-lda-9" href="./acl-2011-Improving_Arabic_Dependency_Parsing_with_Form-based_and_Functional_Morphological_Features.html">164 acl-2011-Improving Arabic Dependency Parsing with Form-based and Functional Morphological Features</a></p>
<p>10 0.5767051 <a title="329-lda-10" href="./acl-2011-A_Corpus_for_Modeling_Morpho-Syntactic_Agreement_in_Arabic%3A_Gender%2C_Number_and_Rationality.html">7 acl-2011-A Corpus for Modeling Morpho-Syntactic Agreement in Arabic: Gender, Number and Rationality</a></p>
<p>11 0.57345593 <a title="329-lda-11" href="./acl-2011-In-domain_Relation_Discovery_with_Meta-constraints_via_Posterior_Regularization.html">170 acl-2011-In-domain Relation Discovery with Meta-constraints via Posterior Regularization</a></p>
<p>12 0.56242889 <a title="329-lda-12" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>13 0.54420078 <a title="329-lda-13" href="./acl-2011-Scaling_up_Automatic_Cross-Lingual_Semantic_Role_Annotation.html">269 acl-2011-Scaling up Automatic Cross-Lingual Semantic Role Annotation</a></p>
<p>14 0.53849149 <a title="329-lda-14" href="./acl-2011-Improving_Dependency_Parsing_with_Semantic_Classes.html">167 acl-2011-Improving Dependency Parsing with Semantic Classes</a></p>
<p>15 0.53119171 <a title="329-lda-15" href="./acl-2011-A_Bayesian_Model_for_Unsupervised_Semantic_Parsing.html">3 acl-2011-A Bayesian Model for Unsupervised Semantic Parsing</a></p>
<p>16 0.52492011 <a title="329-lda-16" href="./acl-2011-NULEX%3A_An_Open-License_Broad_Coverage_Lexicon.html">229 acl-2011-NULEX: An Open-License Broad Coverage Lexicon</a></p>
<p>17 0.5248338 <a title="329-lda-17" href="./acl-2011-Coreference_for_Learning_to_Extract_Relations%3A_Yes_Virginia%2C_Coreference_Matters.html">86 acl-2011-Coreference for Learning to Extract Relations: Yes Virginia, Coreference Matters</a></p>
<p>18 0.52421296 <a title="329-lda-18" href="./acl-2011-Knowledge-Based_Weak_Supervision_for_Information_Extraction_of_Overlapping_Relations.html">190 acl-2011-Knowledge-Based Weak Supervision for Information Extraction of Overlapping Relations</a></p>
<p>19 0.52337956 <a title="329-lda-19" href="./acl-2011-Insights_from_Network_Structure_for_Text_Mining.html">174 acl-2011-Insights from Network Structure for Text Mining</a></p>
<p>20 0.52231348 <a title="329-lda-20" href="./acl-2011-Latent_Semantic_Word_Sense_Induction_and_Disambiguation.html">198 acl-2011-Latent Semantic Word Sense Induction and Disambiguation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
