<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>278 acl-2011-Semi-supervised condensed nearest neighbor for part-of-speech tagging</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-278" href="#">acl2011-278</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>278 acl-2011-Semi-supervised condensed nearest neighbor for part-of-speech tagging</h1>
<br/><p>Source: <a title="acl-2011-278-pdf" href="http://aclweb.org/anthology//P/P11/P11-2009.pdf">pdf</a></p><p>Author: Anders Sgaard</p><p>Abstract: This paper introduces a new training set condensation technique designed for mixtures of labeled and unlabeled data. It finds a condensed set of labeled and unlabeled data points, typically smaller than what is obtained using condensed nearest neighbor on the labeled data only, and improves classification accuracy. We evaluate the algorithm on semisupervised part-of-speech tagging and present the best published result on the Wall Street Journal data set.</p><p>Reference: <a title="acl-2011-278-reference" href="../acl2011_reference/acl-2011-Semi-supervised_condensed_nearest_neighbor_for_part-of-speech_tagging_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Semisupervised condensed nearest neighbor for part-of-speech tagging Anders Søgaard Center for Language Technology University of Copenhagen Njalsgade 142, DK-2300 Copenhagen S s oegaard@hum . [sent-1, score-1.188]
</p><p>2 dk  Abstract This paper introduces a new training set condensation technique designed for mixtures of labeled and unlabeled data. [sent-3, score-0.53]
</p><p>3 It finds a condensed set of labeled and unlabeled data points, typically smaller than what is obtained using condensed nearest neighbor on the labeled data only, and improves classification accuracy. [sent-4, score-2.078]
</p><p>4 We evaluate the algorithm on semisupervised part-of-speech tagging and present the best published result on the Wall Street Journal data set. [sent-5, score-0.157]
</p><p>5 1 Introduction Labeled data for natural language processing tasks such as part-of-speech tagging is often in short supply. [sent-6, score-0.09]
</p><p>6 Semi-supervised learning algorithms are designed to learn from a mixture of labeled and unlabeled data. [sent-7, score-0.358]
</p><p>7 Many different semi-supervised algo-  rithms have been applied to natural language processing tasks, but the simplest algorithm, namely self-training, is the one that has attracted most attention, together with expectation maximization (Abney, 2008). [sent-8, score-0.023]
</p><p>8 The idea behind self-training is simply to let a model trained on the labeled data label the unlabeled data points and then to retrain the model on the mixture of the original labeled data and the newly labeled data. [sent-9, score-0.986]
</p><p>9 The nearest neighbor algorithm (Cover and Hart, 1967) is a memory-based or so-called lazy learning algorithm. [sent-10, score-0.807]
</p><p>10 It is one of the most extensively used nonparametric classification algorithms, simple to implement yet powerful, owing to its theoretical properties guaranteeing that for all distribu48 tions, its probability of error is bound by twice the Bayes probability of error (Cover and Hart, 1967). [sent-11, score-0.046]
</p><p>11 Memory-based learning has been applied to a wide range of natural language processing tasks including part-of-speech tagging (Daelemans et al. [sent-12, score-0.058]
</p><p>12 , 1996), dependency parsing (Nivre, 2003) and word sense dis-  ambiguation (K¨ ubler and Zhekova, 2009). [sent-13, score-0.036]
</p><p>13 Memorybased learning algorithms are said to be lazy because no model is learned from the labeled data points. [sent-14, score-0.255]
</p><p>14 Consequently, classification time is proportional to the number of labeled data points. [sent-16, score-0.211]
</p><p>15 Many algorithms have been proposed to make memory-based learning more efficient. [sent-18, score-0.024]
</p><p>16 The intuition behind many of them is that the set of labeled data points can be reduced or condensed, since many labeled data points are more or less redundant. [sent-19, score-0.812]
</p><p>17 The algorithms try to extract a subset of the overall training set that correctly classifies all the discarded data points through the nearest neighbor rule. [sent-20, score-1.059]
</p><p>18 Intuitively, the model finds good representatives of clusters in the data or discards the data points that are far from the decision boundaries. [sent-21, score-0.42]
</p><p>19 The need for training set condensation is particularly important in semi-supervised learning where we rely on a mixture of labeled and unlabeled data points. [sent-23, score-0.586]
</p><p>20 While the number of labeled data points is typically limited, the number of unlabeled data points is typically high. [sent-24, score-0.781]
</p><p>21 2  Semi-supervised condensed nearest neighbor  The nearest neighbor (NN) algorithm (Cover and Hart, 1967) is conceptually simple, yet very powerful. [sent-28, score-1.893]
</p><p>22 Given a set of labeled data points T, label any new data point (feature vector) x with y where x′ is the data point in T most similar to x and hx′, yi. [sent-29, score-0.497]
</p><p>23 Similarity i sp usually Tm meaossutr esdim iinl terms xo fa nEduc hlxid,eyain. [sent-30, score-0.024]
</p><p>24 The generalization of the nearest neighbor algorithm, k nearest neighbor, finds the k most similar data points Tk to x and assigns x the label ˆy such that:  yˆ = argy m′′a∈xYΣhx′,y′i∈TkE(x,x′)||y′ = y′′|| with E(·, ·) Euclidean distance and | | · || = 1if the  argument ·is) true (else 0). [sent-32, score-1.475]
</p><p>25 Itna noctehe arn words, t =he 1k most similar points take a weighted vote on the class of x. [sent-33, score-0.219]
</p><p>26 Naive implementations of the algorithm store all the labeled data points and compare each of them to the data point that is to be classified. [sent-34, score-0.495]
</p><p>27 Several strategies have been proposed to make nearest neighbor classification more efficient (Angiulli, 2005). [sent-35, score-0.756]
</p><p>28 In particular, training set condensation techniques have been much studied. [sent-36, score-0.22]
</p><p>29 The condensed nearest neighbor (CNN) algorithm was first introduced in Hart (1968). [sent-37, score-1.161]
</p><p>30 Finding a subset of the labeled data points may lead to faster and more accurate classification, but finding the best subset is an intractable problem (Wilfong, 1992). [sent-38, score-0.46]
</p><p>31 CNN can be seen as a simple technique for approximating such a subset of labeled data points. [sent-39, score-0.214]
</p><p>32 The CNN algorithm is defined in Figure 1with T the set of labeled data points and T(t) is label predicted for t by a nearest neighbor classifier ”trained” on T. [sent-40, score-1.232]
</p><p>33 Essentially we discard all labeled data points whose label we can already predict with the current subset of labeled data points. [sent-41, score-0.647]
</p><p>34 Note that we have simplified the CNN algorithm a bit compared  to Hart (1968), as suggested, for example, in Alpaydin (1997), iterating only once over data rather than waiting for convergence. [sent-42, score-0.063]
</p><p>35 This will give us a smaller set of labeled data points, and therefore classification requires less space and time. [sent-43, score-0.211]
</p><p>36 o, rif h C(xi) yi tdhoen C = )C6 = =∪ y {hxi, yii} endC i f= end for return C  =  Figure 1: CONDENSED  NEAREST  NEIGHBOR. [sent-50, score-0.205]
</p><p>37 55 then C = )C6 = =∪ y {hxi, yii} endC i f= end for  =  return C Figure 2: WEAKENED  CONDENSED  NEAREST  NEIGH-  BOR. [sent-58, score-0.046]
</p><p>38 techniques such as bagging (Breiman, 1996), CNN is unstable (Alpaydin, 1997). [sent-59, score-0.039]
</p><p>39 We also introduce a weakened version of the algorithm which not only includes misclassified data points in the classifier C, but also correctly classified data points which were labeled with relatively low confidence. [sent-60, score-0.84]
</p><p>40 So C includes all data points that were misclassified and those whose correct label was predicted with low confidence. [sent-61, score-0.313]
</p><p>41 The weakened condensed nearest neighbor (WCNN) algorithm is sketched in Figure 2. [sent-62, score-1.242]
</p><p>42 C inspects k nearest neighbors when labeling new data points, where k is estimated by crossvalidation. [sent-63, score-0.485]
</p><p>43 Two related condensation techniques, namely removing typical elements and removing elements by class prediction strength, were argued not to be useful for most problems in natural language pro-  cessing in Daelemans et al. [sent-65, score-0.432]
</p><p>44 (1999), but our experiments showed that CNN often perform about as well as NN, and our semi-supervised CNN algorithm leads to substantial improvements. [sent-66, score-0.031]
</p><p>45 ally only removes elements close to decision boundaries when the classifier has no use of them. [sent-68, score-0.075]
</p><p>46 mixtures of Gaussians, CNN and WCNN try to find the best possible representatives for each cluster in the distribution of data, i. [sent-71, score-0.163]
</p><p>47 finding the points closest to the center of each cluster. [sent-73, score-0.25]
</p><p>48 Ideally, CNN returns one point for each cluster, namely the center of each cluster. [sent-74, score-0.054]
</p><p>49 However, a sample of labeled data may not include data points that are near the center of a cluster. [sent-75, score-0.469]
</p><p>50 Consequently, CNN sometimes needs several points to stabilize the representation of a cluster; e. [sent-76, score-0.241]
</p><p>51 When a large number of unlabeled data points that are labeled according to nearest neighbors populates the clusters, chances increase that we find data points near the centers of our clusters, e. [sent-79, score-1.282]
</p><p>52 Of course the centers of our clusters may move, but the positive results obtained experimentally below suggest that it is more likely that labeling unlabeled data by nearest neighbors will enable us to do better training set condensation. [sent-82, score-0.7]
</p><p>53 This is exactly what semi-supervised condensed nearest neighbor (SCNN) does. [sent-83, score-1.13]
</p><p>54 We first run a WCNN C and obtain a condensed set of labeled data points. [sent-84, score-0.585]
</p><p>55 To this set of labeled data points we add a  large number of unlabeled data points labeled by a NN classifier T on the original data set. [sent-85, score-1.004]
</p><p>56 We use a simple selection criterion and include all data points  1: 2: 3: 4: 5: 6: 7: 8: 9: 10: 11: 12: 13: 14: 15: 16: 17: 18:  50 T = {hx1, y1i , . [sent-86, score-0.251]
</p><p>57 , hx′mi} # ui}nl,a Cbe =led ∅ d, aCta fUor = hxi, yii ∈ . [sent-92, score-0.22]
</p><p>58 55 then C = C ∪ {hxi, yii} endC i f= end for for hx′ii ∈ U do rif h PT(hx′i, T(x′i)i |wi) > 0. [sent-95, score-0.143]
</p><p>59 90 then C = xC ∪ {hx′i, T(x′i)i} endC i f= end for for hxi, yii ∈ C do rif h C′(xi) yi dthoen C′ = )C6 =′ ∪ y {hxi, yii} end if end for return C′  =  =  Figure 4: SEMI-SUPERVISED  CONDENSED  NEAREST  NEIGHBOR. [sent-96, score-0.471]
</p><p>60 that are labeled with confidence greater than 90%. [sent-97, score-0.155]
</p><p>61 We then obtain a new WCNN C′ from the new data set which is a mixture of labeled and unlabeled data points. [sent-98, score-0.398]
</p><p>62 3  Part-of-speech tagging  Our part-of-speech tagging data set is the standard data set from Wall Street Journal included in PennIII (Marcus et al. [sent-100, score-0.18]
</p><p>63 0–18, and xi2 is a prediction on wi from an unsupervised part-ofspeech tagger (a cluster label), in our case Unsupos (Biemann, 2006) trained on the British National Corpus. [sent-103, score-0.153]
</p><p>64 2 We train a semi-supervised condensed nearest neighbor classifier on Sect. [sent-104, score-1.166]
</p><p>65 19 of the devel-  opment data and unlabeled data from the Brown corpus and apply it to Sect. [sent-105, score-0.21]
</p><p>66 The unsupervised tagger is used to cluster tokens in a meaningful way. [sent-119, score-0.096]
</p><p>67 Intuitively, we try to learn part-of-speech tagging by learning when to rely on SVMTool. [sent-120, score-0.083]
</p><p>68 Our semi-supervised condensed nearest neighbor classifier achieves an accuracy of 97. [sent-127, score-1.166]
</p><p>69 Equally importantly it condensates the available data points, from Sect. [sent-129, score-0.086]
</p><p>70 2M data points, to only 2249 data points, making the classifier very fast. [sent-131, score-0.1]
</p><p>71 6ry%the  amount of unlabeled data points, we only train our ensemble on the first 5000 words in Sect. [sent-139, score-0.156]
</p><p>72 The immediate drop  in the red scatter plot illustrates the condensation effect of semi-supervised learning: when we begin to add unlabeled data, accuracy increases by more than 1. [sent-143, score-0.368]
</p><p>73 Semi-supervised learning means that we populate 51  Figure 5: Normalized accuracy (range: 92. [sent-145, score-0.024]
</p><p>74 clusters in the data, making it easier to identify representative data points. [sent-148, score-0.106]
</p><p>75 Since we can easier identify  representative data points, training set condensation becomes more effective. [sent-149, score-0.283]
</p><p>76 In particular, we made use of the implementations of Euclidean distance and random sampling in their package. [sent-152, score-0.026]
</p><p>77 dk/ anders / s ccn/ 5  Conclusions  We have introduced a new learning algorithm that simultaneously condensates labeled data and learns from a mixture of labeled and unlabeled data. [sent-154, score-0.672]
</p><p>78 We have compared the algorithm to condensed nearest neighbor (Hart, 1968; Alpaydin, 1997) and showed that the algorithm leads to more condensed models, and that it performs significantly better than condensed nearest neighbor. [sent-155, score-2.401]
</p><p>79 For part-of-speech tagging, the error reduction over condensed nearest neighbor is more than 40%, and our model is 40% smaller than the one induced by condensed nearest  neighbor. [sent-156, score-1.941]
</p><p>80 While we have provided no theory for semi-supervised condensed nearest neighbor, we believe that these results demonstrate the potential of the proposed method. [sent-157, score-0.835]
</p><p>81 SVMTool: a general POS tagger generator based on support vector machines. [sent-201, score-0.055]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('nearest', 0.413), ('condensed', 0.398), ('neighbor', 0.319), ('cnn', 0.311), ('condensation', 0.22), ('yii', 0.22), ('hxi', 0.22), ('points', 0.219), ('labeled', 0.155), ('hx', 0.127), ('unlabeled', 0.124), ('rif', 0.12), ('hart', 0.113), ('wcnn', 0.109), ('endc', 0.096), ('alpaydin', 0.081), ('hxn', 0.081), ('weakened', 0.081), ('yni', 0.072), ('daelemans', 0.068), ('representatives', 0.066), ('anders', 0.066), ('gaard', 0.066), ('xi', 0.061), ('tagging', 0.058), ('tagger', 0.055), ('mixture', 0.055), ('condensates', 0.054), ('gimenez', 0.054), ('jakub', 0.054), ('spoustova', 0.054), ('svmtool', 0.048), ('centers', 0.048), ('lazy', 0.044), ('ftor', 0.044), ('removing', 0.043), ('clusters', 0.043), ('cluster', 0.041), ('neighbors', 0.04), ('bagging', 0.039), ('yi', 0.039), ('elements', 0.039), ('ubler', 0.036), ('copenhagen', 0.036), ('nns', 0.036), ('nn', 0.036), ('semisupervised', 0.036), ('classifier', 0.036), ('misclassified', 0.035), ('cover', 0.035), ('transactions', 0.034), ('walter', 0.033), ('data', 0.032), ('wall', 0.032), ('euclidean', 0.032), ('wi', 0.032), ('center', 0.031), ('mixtures', 0.031), ('algorithm', 0.031), ('representative', 0.031), ('street', 0.029), ('pc', 0.028), ('finds', 0.028), ('label', 0.027), ('ieee', 0.027), ('intuitively', 0.027), ('subset', 0.027), ('jan', 0.026), ('strength', 0.026), ('suzuki', 0.026), ('implementations', 0.026), ('try', 0.025), ('british', 0.025), ('column', 0.025), ('prediction', 0.025), ('theory', 0.024), ('hum', 0.024), ('oegaard', 0.024), ('argy', 0.024), ('scatter', 0.024), ('xo', 0.024), ('cbe', 0.024), ('mbt', 0.024), ('populate', 0.024), ('classification', 0.024), ('algorithms', 0.024), ('jj', 0.023), ('end', 0.023), ('return', 0.023), ('namely', 0.023), ('dt', 0.023), ('stabilize', 0.022), ('antal', 0.022), ('opment', 0.022), ('lluis', 0.022), ('marquez', 0.022), ('njalsgade', 0.022), ('hajic', 0.022), ('duce', 0.022), ('owing', 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="278-tfidf-1" href="./acl-2011-Semi-supervised_condensed_nearest_neighbor_for_part-of-speech_tagging.html">278 acl-2011-Semi-supervised condensed nearest neighbor for part-of-speech tagging</a></p>
<p>Author: Anders Sgaard</p><p>Abstract: This paper introduces a new training set condensation technique designed for mixtures of labeled and unlabeled data. It finds a condensed set of labeled and unlabeled data points, typically smaller than what is obtained using condensed nearest neighbor on the labeled data only, and improves classification accuracy. We evaluate the algorithm on semisupervised part-of-speech tagging and present the best published result on the Wall Street Journal data set.</p><p>2 0.14660951 <a title="278-tfidf-2" href="./acl-2011-Learning_Condensed_Feature_Representations_from_Large_Unsupervised_Data_Sets_for_Supervised_Learning.html">199 acl-2011-Learning Condensed Feature Representations from Large Unsupervised Data Sets for Supervised Learning</a></p>
<p>Author: Jun Suzuki ; Hideki Isozaki ; Masaaki Nagata</p><p>Abstract: This paper proposes a novel approach for effectively utilizing unsupervised data in addition to supervised data for supervised learning. We use unsupervised data to generate informative ‘condensed feature representations’ from the original feature set used in supervised NLP systems. The main contribution of our method is that it can offer dense and low-dimensional feature spaces for NLP tasks while maintaining the state-ofthe-art performance provided by the recently developed high-performance semi-supervised learning technique. Our method matches the results of current state-of-the-art systems with very few features, i.e., F-score 90.72 with 344 features for CoNLL-2003 NER data, and UAS 93.55 with 12.5K features for dependency parsing data derived from PTB-III. ,</p><p>3 0.10879228 <a title="278-tfidf-3" href="./acl-2011-Joint_Bilingual_Sentiment_Classification_with_Unlabeled_Parallel_Corpora.html">183 acl-2011-Joint Bilingual Sentiment Classification with Unlabeled Parallel Corpora</a></p>
<p>Author: Bin Lu ; Chenhao Tan ; Claire Cardie ; Benjamin K. Tsou</p><p>Abstract: Most previous work on multilingual sentiment analysis has focused on methods to adapt sentiment resources from resource-rich languages to resource-poor languages. We present a novel approach for joint bilingual sentiment classification at the sentence level that augments available labeled data in each language with unlabeled parallel data. We rely on the intuition that the sentiment labels for parallel sentences should be similar and present a model that jointly learns improved monolingual sentiment classifiers for each language. Experiments on multiple data sets show that the proposed approach (1) outperforms the monolingual baselines, significantly improving the accuracy for both languages by 3.44%-8. 12%; (2) outperforms two standard approaches for leveraging unlabeled data; and (3) produces (albeit smaller) performance gains when employing pseudo-parallel data from machine translation engines. 1</p><p>4 0.056246568 <a title="278-tfidf-4" href="./acl-2011-Data_point_selection_for_cross-language_adaptation_of_dependency_parsers.html">92 acl-2011-Data point selection for cross-language adaptation of dependency parsers</a></p>
<p>Author: Anders Sgaard</p><p>Abstract: We consider a very simple, yet effective, approach to cross language adaptation of dependency parsers. We first remove lexical items from the treebanks and map part-of-speech tags into a common tagset. We then train a language model on tag sequences in otherwise unlabeled target data and rank labeled source data by perplexity per word of tag sequences from less similar to most similar to the target. We then train our target language parser on the most similar data points in the source labeled data. The strategy achieves much better results than a non-adapted baseline and stateof-the-art unsupervised dependency parsing, and results are comparable to more complex projection-based cross language adaptation algorithms.</p><p>5 0.053913068 <a title="278-tfidf-5" href="./acl-2011-An_Ensemble_Model_that_Combines_Syntactic_and_Semantic_Clustering_for_Discriminative_Dependency_Parsing.html">39 acl-2011-An Ensemble Model that Combines Syntactic and Semantic Clustering for Discriminative Dependency Parsing</a></p>
<p>Author: Gholamreza Haffari ; Marzieh Razavi ; Anoop Sarkar</p><p>Abstract: We combine multiple word representations based on semantic clusters extracted from the (Brown et al., 1992) algorithm and syntactic clusters obtained from the Berkeley parser (Petrov et al., 2006) in order to improve discriminative dependency parsing in the MSTParser framework (McDonald et al., 2005). We also provide an ensemble method for combining diverse cluster-based models. The two contributions together significantly improves unlabeled dependency accuracy from 90.82% to 92. 13%.</p><p>6 0.053249694 <a title="278-tfidf-6" href="./acl-2011-Using_Multiple_Sources_to_Construct_a_Sentiment_Sensitive_Thesaurus_for_Cross-Domain_Sentiment_Classification.html">332 acl-2011-Using Multiple Sources to Construct a Sentiment Sensitive Thesaurus for Cross-Domain Sentiment Classification</a></p>
<p>7 0.052062217 <a title="278-tfidf-7" href="./acl-2011-Discriminative_Feature-Tied_Mixture_Modeling_for_Statistical_Machine_Translation.html">100 acl-2011-Discriminative Feature-Tied Mixture Modeling for Statistical Machine Translation</a></p>
<p>8 0.050951466 <a title="278-tfidf-8" href="./acl-2011-Collective_Classification_of_Congressional_Floor-Debate_Transcripts.html">73 acl-2011-Collective Classification of Congressional Floor-Debate Transcripts</a></p>
<p>9 0.049635824 <a title="278-tfidf-9" href="./acl-2011-Domain_Adaptation_by_Constraining_Inter-Domain_Variability_of_Latent_Feature_Representation.html">103 acl-2011-Domain Adaptation by Constraining Inter-Domain Variability of Latent Feature Representation</a></p>
<p>10 0.04882618 <a title="278-tfidf-10" href="./acl-2011-Unsupervised_Part-of-Speech_Tagging_with_Bilingual_Graph-Based_Projections.html">323 acl-2011-Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</a></p>
<p>11 0.048576463 <a title="278-tfidf-11" href="./acl-2011-A_Stacked_Sub-Word_Model_for_Joint_Chinese_Word_Segmentation_and_Part-of-Speech_Tagging.html">27 acl-2011-A Stacked Sub-Word Model for Joint Chinese Word Segmentation and Part-of-Speech Tagging</a></p>
<p>12 0.04573036 <a title="278-tfidf-12" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>13 0.042948376 <a title="278-tfidf-13" href="./acl-2011-ParaSense_or_How_to_Use_Parallel_Corpora_for_Word_Sense_Disambiguation.html">240 acl-2011-ParaSense or How to Use Parallel Corpora for Word Sense Disambiguation</a></p>
<p>14 0.042482655 <a title="278-tfidf-14" href="./acl-2011-Piggyback%3A_Using_Search_Engines_for_Robust_Cross-Domain_Named_Entity_Recognition.html">246 acl-2011-Piggyback: Using Search Engines for Robust Cross-Domain Named Entity Recognition</a></p>
<p>15 0.041740812 <a title="278-tfidf-15" href="./acl-2011-Towards_a_Framework_for_Abstractive_Summarization_of_Multimodal_Documents.html">308 acl-2011-Towards a Framework for Abstractive Summarization of Multimodal Documents</a></p>
<p>16 0.040209264 <a title="278-tfidf-16" href="./acl-2011-A_Word-Class_Approach_to_Labeling_PSCFG_Rules_for_Machine_Translation.html">29 acl-2011-A Word-Class Approach to Labeling PSCFG Rules for Machine Translation</a></p>
<p>17 0.038711663 <a title="278-tfidf-17" href="./acl-2011-Effective_Measures_of_Domain_Similarity_for_Parsing.html">109 acl-2011-Effective Measures of Domain Similarity for Parsing</a></p>
<p>18 0.037910931 <a title="278-tfidf-18" href="./acl-2011-Good_Seed_Makes_a_Good_Crop%3A_Accelerating_Active_Learning_Using_Language_Modeling.html">145 acl-2011-Good Seed Makes a Good Crop: Accelerating Active Learning Using Language Modeling</a></p>
<p>19 0.03689456 <a title="278-tfidf-19" href="./acl-2011-Is_Machine_Translation_Ripe_for_Cross-Lingual_Sentiment_Classification%3F.html">179 acl-2011-Is Machine Translation Ripe for Cross-Lingual Sentiment Classification?</a></p>
<p>20 0.036856685 <a title="278-tfidf-20" href="./acl-2011-Extracting_Opinion_Expressions_and_Their_Polarities_-_Exploration_of_Pipelines_and_Joint_Models.html">131 acl-2011-Extracting Opinion Expressions and Their Polarities - Exploration of Pipelines and Joint Models</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.102), (1, 0.023), (2, -0.012), (3, -0.04), (4, -0.007), (5, -0.014), (6, 0.027), (7, 0.009), (8, -0.013), (9, 0.035), (10, 0.043), (11, -0.013), (12, 0.027), (13, 0.016), (14, 0.001), (15, -0.011), (16, -0.059), (17, -0.003), (18, 0.033), (19, -0.059), (20, -0.036), (21, -0.104), (22, 0.003), (23, 0.059), (24, 0.014), (25, -0.004), (26, -0.007), (27, -0.01), (28, 0.043), (29, 0.021), (30, 0.033), (31, 0.043), (32, 0.026), (33, 0.012), (34, 0.012), (35, -0.016), (36, 0.057), (37, -0.057), (38, 0.003), (39, 0.071), (40, 0.077), (41, 0.027), (42, -0.026), (43, -0.03), (44, 0.086), (45, -0.043), (46, 0.035), (47, 0.07), (48, -0.113), (49, 0.068)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93264157 <a title="278-lsi-1" href="./acl-2011-Semi-supervised_condensed_nearest_neighbor_for_part-of-speech_tagging.html">278 acl-2011-Semi-supervised condensed nearest neighbor for part-of-speech tagging</a></p>
<p>Author: Anders Sgaard</p><p>Abstract: This paper introduces a new training set condensation technique designed for mixtures of labeled and unlabeled data. It finds a condensed set of labeled and unlabeled data points, typically smaller than what is obtained using condensed nearest neighbor on the labeled data only, and improves classification accuracy. We evaluate the algorithm on semisupervised part-of-speech tagging and present the best published result on the Wall Street Journal data set.</p><p>2 0.78368175 <a title="278-lsi-2" href="./acl-2011-Learning_Condensed_Feature_Representations_from_Large_Unsupervised_Data_Sets_for_Supervised_Learning.html">199 acl-2011-Learning Condensed Feature Representations from Large Unsupervised Data Sets for Supervised Learning</a></p>
<p>Author: Jun Suzuki ; Hideki Isozaki ; Masaaki Nagata</p><p>Abstract: This paper proposes a novel approach for effectively utilizing unsupervised data in addition to supervised data for supervised learning. We use unsupervised data to generate informative ‘condensed feature representations’ from the original feature set used in supervised NLP systems. The main contribution of our method is that it can offer dense and low-dimensional feature spaces for NLP tasks while maintaining the state-ofthe-art performance provided by the recently developed high-performance semi-supervised learning technique. Our method matches the results of current state-of-the-art systems with very few features, i.e., F-score 90.72 with 344 features for CoNLL-2003 NER data, and UAS 93.55 with 12.5K features for dependency parsing data derived from PTB-III. ,</p><p>3 0.59821469 <a title="278-lsi-3" href="./acl-2011-Improving_Classification_of_Medical_Assertions_in_Clinical_Notes.html">165 acl-2011-Improving Classification of Medical Assertions in Clinical Notes</a></p>
<p>Author: Youngjun Kim ; Ellen Riloff ; Stephane Meystre</p><p>Abstract: We present an NLP system that classifies the assertion type of medical problems in clinical notes used for the Fourth i2b2/VA Challenge. Our classifier uses a variety of linguistic features, including lexical, syntactic, lexicosyntactic, and contextual features. To overcome an extremely unbalanced distribution of assertion types in the data set, we focused our efforts on adding features specifically to improve the performance of minority classes. As a result, our system reached 94. 17% micro-averaged and 79.76% macro-averaged F1-measures, and showed substantial recall gains on the minority classes. 1</p><p>4 0.52788138 <a title="278-lsi-4" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<p>Author: Shane Bergsma ; David Yarowsky ; Kenneth Church</p><p>Abstract: Resolving coordination ambiguity is a classic hard problem. This paper looks at coordination disambiguation in complex noun phrases (NPs). Parsers trained on the Penn Treebank are reporting impressive numbers these days, but they don’t do very well on this problem (79%). We explore systems trained using three types of corpora: (1) annotated (e.g. the Penn Treebank), (2) bitexts (e.g. Europarl), and (3) unannotated monolingual (e.g. Google N-grams). Size matters: (1) is a million words, (2) is potentially billions of words and (3) is potentially trillions of words. The unannotated monolingual data is helpful when the ambiguity can be resolved through associations among the lexical items. The bilingual data is helpful when the ambiguity can be resolved by the order of words in the translation. We train separate classifiers with monolingual and bilingual features and iteratively improve them via achieves data and pervised tations. co-training. The co-trained classifier close to 96% accuracy on Treebank makes 20% fewer errors than a susystem trained with Treebank anno-</p><p>5 0.52396178 <a title="278-lsi-5" href="./acl-2011-A_Scalable_Probabilistic_Classifier_for_Language_Modeling.html">24 acl-2011-A Scalable Probabilistic Classifier for Language Modeling</a></p>
<p>Author: Joel Lang</p><p>Abstract: We present a novel probabilistic classifier, which scales well to problems that involve a large number ofclasses and require training on large datasets. A prominent example of such a problem is language modeling. Our classifier is based on the assumption that each feature is associated with a predictive strength, which quantifies how well the feature can predict the class by itself. The predictions of individual features can then be combined according to their predictive strength, resulting in a model, whose parameters can be reliably and efficiently estimated. We show that a generative language model based on our classifier consistently matches modified Kneser-Ney smoothing and can outperform it if sufficiently rich features are incorporated.</p><p>6 0.51596689 <a title="278-lsi-6" href="./acl-2011-Piggyback%3A_Using_Search_Engines_for_Robust_Cross-Domain_Named_Entity_Recognition.html">246 acl-2011-Piggyback: Using Search Engines for Robust Cross-Domain Named Entity Recognition</a></p>
<p>7 0.51066327 <a title="278-lsi-7" href="./acl-2011-Unsupervised_Decomposition_of_a_Document_into_Authorial_Components.html">319 acl-2011-Unsupervised Decomposition of a Document into Authorial Components</a></p>
<p>8 0.49853709 <a title="278-lsi-8" href="./acl-2011-Unsupervised_Part-of-Speech_Tagging_with_Bilingual_Graph-Based_Projections.html">323 acl-2011-Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</a></p>
<p>9 0.48408481 <a title="278-lsi-9" href="./acl-2011-Discovering_Sociolinguistic_Associations_with_Structured_Sparsity.html">97 acl-2011-Discovering Sociolinguistic Associations with Structured Sparsity</a></p>
<p>10 0.48132446 <a title="278-lsi-10" href="./acl-2011-Nonlinear_Evidence_Fusion_and_Propagation_for_Hyponymy_Relation_Mining.html">231 acl-2011-Nonlinear Evidence Fusion and Propagation for Hyponymy Relation Mining</a></p>
<p>11 0.47920123 <a title="278-lsi-11" href="./acl-2011-Lexically-Triggered_Hidden_Markov_Models_for_Clinical_Document_Coding.html">209 acl-2011-Lexically-Triggered Hidden Markov Models for Clinical Document Coding</a></p>
<p>12 0.47277841 <a title="278-lsi-12" href="./acl-2011-Exploiting_Web-Derived_Selectional_Preference_to_Improve_Statistical_Dependency_Parsing.html">127 acl-2011-Exploiting Web-Derived Selectional Preference to Improve Statistical Dependency Parsing</a></p>
<p>13 0.47156328 <a title="278-lsi-13" href="./acl-2011-Domain_Adaptation_by_Constraining_Inter-Domain_Variability_of_Latent_Feature_Representation.html">103 acl-2011-Domain Adaptation by Constraining Inter-Domain Variability of Latent Feature Representation</a></p>
<p>14 0.4698064 <a title="278-lsi-14" href="./acl-2011-Automatically_Predicting_Peer-Review_Helpfulness.html">55 acl-2011-Automatically Predicting Peer-Review Helpfulness</a></p>
<p>15 0.44985598 <a title="278-lsi-15" href="./acl-2011-Modeling_Wisdom_of_Crowds_Using_Latent_Mixture_of_Discriminative_Experts.html">223 acl-2011-Modeling Wisdom of Crowds Using Latent Mixture of Discriminative Experts</a></p>
<p>16 0.4443402 <a title="278-lsi-16" href="./acl-2011-Discriminative_Feature-Tied_Mixture_Modeling_for_Statistical_Machine_Translation.html">100 acl-2011-Discriminative Feature-Tied Mixture Modeling for Statistical Machine Translation</a></p>
<p>17 0.4437319 <a title="278-lsi-17" href="./acl-2011-Recognizing_Named_Entities_in_Tweets.html">261 acl-2011-Recognizing Named Entities in Tweets</a></p>
<p>18 0.44318613 <a title="278-lsi-18" href="./acl-2011-Data_point_selection_for_cross-language_adaptation_of_dependency_parsers.html">92 acl-2011-Data point selection for cross-language adaptation of dependency parsers</a></p>
<p>19 0.44014534 <a title="278-lsi-19" href="./acl-2011-Combining_Indicators_of_Allophony.html">74 acl-2011-Combining Indicators of Allophony</a></p>
<p>20 0.43842837 <a title="278-lsi-20" href="./acl-2011-Effective_Measures_of_Domain_Similarity_for_Parsing.html">109 acl-2011-Effective Measures of Domain Similarity for Parsing</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.022), (5, 0.01), (17, 0.045), (37, 0.11), (39, 0.051), (40, 0.364), (41, 0.07), (55, 0.022), (59, 0.016), (72, 0.026), (91, 0.05), (96, 0.109)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.75528342 <a title="278-lda-1" href="./acl-2011-Semi-supervised_condensed_nearest_neighbor_for_part-of-speech_tagging.html">278 acl-2011-Semi-supervised condensed nearest neighbor for part-of-speech tagging</a></p>
<p>Author: Anders Sgaard</p><p>Abstract: This paper introduces a new training set condensation technique designed for mixtures of labeled and unlabeled data. It finds a condensed set of labeled and unlabeled data points, typically smaller than what is obtained using condensed nearest neighbor on the labeled data only, and improves classification accuracy. We evaluate the algorithm on semisupervised part-of-speech tagging and present the best published result on the Wall Street Journal data set.</p><p>2 0.55605429 <a title="278-lda-2" href="./acl-2011-Can_Document_Selection_Help_Semi-supervised_Learning%3F_A_Case_Study_On_Event_Extraction.html">65 acl-2011-Can Document Selection Help Semi-supervised Learning? A Case Study On Event Extraction</a></p>
<p>Author: Shasha Liao ; Ralph Grishman</p><p>Abstract: Annotating training data for event extraction is tedious and labor-intensive. Most current event extraction tasks rely on hundreds of annotated documents, but this is often not enough. In this paper, we present a novel self-training strategy, which uses Information Retrieval (IR) to collect a cluster of related documents as the resource for bootstrapping. Also, based on the particular characteristics of this corpus, global inference is applied to provide more confident and informative data selection. We compare this approach to self-training on a normal newswire corpus and show that IR can provide a better corpus for bootstrapping and that global inference can further improve instance selection. We obtain gains of 1.7% in trigger labeling and 2.3% in role labeling through IR and an additional 1.1% in trigger labeling and 1.3% in role labeling by applying global inference. 1</p><p>3 0.45265639 <a title="278-lda-3" href="./acl-2011-Exploiting_Syntactico-Semantic_Structures_for_Relation_Extraction.html">126 acl-2011-Exploiting Syntactico-Semantic Structures for Relation Extraction</a></p>
<p>Author: Yee Seng Chan ; Dan Roth</p><p>Abstract: In this paper, we observe that there exists a second dimension to the relation extraction (RE) problem that is orthogonal to the relation type dimension. We show that most of these second dimensional structures are relatively constrained and not difficult to identify. We propose a novel algorithmic approach to RE that starts by first identifying these structures and then, within these, identifying the semantic type of the relation. In the real RE problem where relation arguments need to be identified, exploiting these structures also allows reducing pipelined propagated errors. We show that this RE framework provides significant improvement in RE performance.</p><p>4 0.44874823 <a title="278-lda-4" href="./acl-2011-Effects_of_Noun_Phrase_Bracketing_in_Dependency_Parsing_and_Machine_Translation.html">111 acl-2011-Effects of Noun Phrase Bracketing in Dependency Parsing and Machine Translation</a></p>
<p>Author: Nathan Green</p><p>Abstract: Flat noun phrase structure was, up until recently, the standard in annotation for the Penn Treebanks. With the recent addition of internal noun phrase annotation, dependency parsing and applications down the NLP pipeline are likely affected. Some machine translation systems, such as TectoMT, use deep syntax as a language transfer layer. It is proposed that changes to the noun phrase dependency parse will have a cascading effect down the NLP pipeline and in the end, improve machine translation output, even with a reduction in parser accuracy that the noun phrase structure might cause. This paper examines this noun phrase structure’s effect on dependency parsing, in English, with a maximum spanning tree parser and shows a 2.43%, 0.23 Bleu score, improvement for English to Czech machine translation. .</p><p>5 0.44618893 <a title="278-lda-5" href="./acl-2011-Beam-Width_Prediction_for_Efficient_Context-Free_Parsing.html">58 acl-2011-Beam-Width Prediction for Efficient Context-Free Parsing</a></p>
<p>Author: Nathan Bodenstab ; Aaron Dunlop ; Keith Hall ; Brian Roark</p><p>Abstract: Efficient decoding for syntactic parsing has become a necessary research area as statistical grammars grow in accuracy and size and as more NLP applications leverage syntactic analyses. We review prior methods for pruning and then present a new framework that unifies their strengths into a single approach. Using a log linear model, we learn the optimal beam-search pruning parameters for each CYK chart cell, effectively predicting the most promising areas of the model space to explore. We demonstrate that our method is faster than coarse-to-fine pruning, exemplified in both the Charniak and Berkeley parsers, by empirically comparing our parser to the Berkeley parser using the same grammar and under identical operating conditions.</p><p>6 0.44543773 <a title="278-lda-6" href="./acl-2011-Data_point_selection_for_cross-language_adaptation_of_dependency_parsers.html">92 acl-2011-Data point selection for cross-language adaptation of dependency parsers</a></p>
<p>7 0.44318032 <a title="278-lda-7" href="./acl-2011-Domain_Adaptation_by_Constraining_Inter-Domain_Variability_of_Latent_Feature_Representation.html">103 acl-2011-Domain Adaptation by Constraining Inter-Domain Variability of Latent Feature Representation</a></p>
<p>8 0.44273907 <a title="278-lda-8" href="./acl-2011-Semi-supervised_Relation_Extraction_with_Large-scale_Word_Clustering.html">277 acl-2011-Semi-supervised Relation Extraction with Large-scale Word Clustering</a></p>
<p>9 0.44106239 <a title="278-lda-9" href="./acl-2011-A_Comparison_of_Loopy_Belief_Propagation_and_Dual_Decomposition_for_Integrated_CCG_Supertagging_and_Parsing.html">5 acl-2011-A Comparison of Loopy Belief Propagation and Dual Decomposition for Integrated CCG Supertagging and Parsing</a></p>
<p>10 0.44105244 <a title="278-lda-10" href="./acl-2011-Parsing_the_Internal_Structure_of_Words%3A_A_New_Paradigm_for_Chinese_Word_Segmentation.html">241 acl-2011-Parsing the Internal Structure of Words: A New Paradigm for Chinese Word Segmentation</a></p>
<p>11 0.44097593 <a title="278-lda-11" href="./acl-2011-Collective_Classification_of_Congressional_Floor-Debate_Transcripts.html">73 acl-2011-Collective Classification of Congressional Floor-Debate Transcripts</a></p>
<p>12 0.44087863 <a title="278-lda-12" href="./acl-2011-Learning_Hierarchical_Translation_Structure_with_Linguistic_Annotations.html">202 acl-2011-Learning Hierarchical Translation Structure with Linguistic Annotations</a></p>
<p>13 0.43956274 <a title="278-lda-13" href="./acl-2011-Piggyback%3A_Using_Search_Engines_for_Robust_Cross-Domain_Named_Entity_Recognition.html">246 acl-2011-Piggyback: Using Search Engines for Robust Cross-Domain Named Entity Recognition</a></p>
<p>14 0.43949437 <a title="278-lda-14" href="./acl-2011-Transition-based_Dependency_Parsing_with_Rich_Non-local_Features.html">309 acl-2011-Transition-based Dependency Parsing with Rich Non-local Features</a></p>
<p>15 0.43939459 <a title="278-lda-15" href="./acl-2011-Exploring_Entity_Relations_for_Named_Entity_Disambiguation.html">128 acl-2011-Exploring Entity Relations for Named Entity Disambiguation</a></p>
<p>16 0.43923825 <a title="278-lda-16" href="./acl-2011-Evaluating_the_Impact_of_Coder_Errors_on_Active_Learning.html">119 acl-2011-Evaluating the Impact of Coder Errors on Active Learning</a></p>
<p>17 0.43923646 <a title="278-lda-17" href="./acl-2011-Lexically-Triggered_Hidden_Markov_Models_for_Clinical_Document_Coding.html">209 acl-2011-Lexically-Triggered Hidden Markov Models for Clinical Document Coding</a></p>
<p>18 0.43915012 <a title="278-lda-18" href="./acl-2011-A_Statistical_Tree_Annotator_and_Its_Applications.html">28 acl-2011-A Statistical Tree Annotator and Its Applications</a></p>
<p>19 0.43902892 <a title="278-lda-19" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<p>20 0.43839657 <a title="278-lda-20" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
