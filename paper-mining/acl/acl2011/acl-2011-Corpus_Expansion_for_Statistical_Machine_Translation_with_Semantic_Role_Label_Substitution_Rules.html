<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>87 acl-2011-Corpus Expansion for Statistical Machine Translation with Semantic Role Label Substitution Rules</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-87" href="#">acl2011-87</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>87 acl-2011-Corpus Expansion for Statistical Machine Translation with Semantic Role Label Substitution Rules</h1>
<br/><p>Source: <a title="acl-2011-87-pdf" href="http://aclweb.org/anthology//P/P11/P11-2051.pdf">pdf</a></p><p>Author: Qin Gao ; Stephan Vogel</p><p>Abstract: We present an approach of expanding parallel corpora for machine translation. By utilizing Semantic role labeling (SRL) on one side of the language pair, we extract SRL substitution rules from existing parallel corpus. The rules are then used for generating new sentence pairs. An SVM classifier is built to filter the generated sentence pairs. The filtered corpus is used for training phrase-based translation models, which can be used directly in translation tasks or combined with baseline models. Experimental results on ChineseEnglish machine translation tasks show an average improvement of 0.45 BLEU and 1.22 TER points across 5 different NIST test sets.</p><p>Reference: <a title="acl-2011-87-reference" href="../acl2011_reference/acl-2011-Corpus_Expansion_for_Statistical_Machine_Translation_with_Semantic_Role_Label_Substitution_Rules_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 By utilizing Semantic role labeling (SRL) on one side of the language pair, we extract SRL substitution rules from existing parallel corpus. [sent-2, score-0.647]
</p><p>2 The rules are then used for generating new sentence pairs. [sent-3, score-0.195]
</p><p>3 An SVM classifier is built to filter the generated sentence pairs. [sent-4, score-0.327]
</p><p>4 The filtered corpus is used for training phrase-based translation models, which can be used directly in translation tasks or combined with baseline models. [sent-5, score-0.36]
</p><p>5 Experimental results on ChineseEnglish machine translation tasks show an average improvement of 0. [sent-6, score-0.145]
</p><p>6 1 Introduction Statistical machine translation (SMT) relies on par-  . [sent-9, score-0.104]
</p><p>7 Aside from collecting parallel corpus, we have seen interesting research on automatically generating corpus from existing resources. [sent-11, score-0.248]
</p><p>8 In this paper, we propose a different methodology of generating additional parallel corpus. [sent-15, score-0.154]
</p><p>9 The basic idea of paraphrasing is to find alternative ways that convey the same information. [sent-16, score-0.105]
</p><p>10 In contrast, we propose to build new parallel sentences that convey different information, yet retain correct grammatical and semantic structures. [sent-17, score-0.33]
</p><p>11 The basic idea of the proposed method is to substitute source and target phrase pairs in a sentence pair with phrase pairs from other sentences. [sent-18, score-1.111]
</p><p>12 The problem is how to identify where a substitution should happen and which phrase pairs are valid candidates for the substitution. [sent-19, score-0.618]
</p><p>13 edu good paraphrases (Callison-Burch, 2008), it is insufficient in our task because it cannot properly filter  the candidates for the replacement. [sent-22, score-0.16]
</p><p>14 If we allow all the NPs to be replaced with other NPs, each sentence pair can generate huge number of new sentences. [sent-23, score-0.182]
</p><p>15 , 2005) to provide more lexicalized and semantic constraints to select the candidates. [sent-25, score-0.155]
</p><p>16 The method only requires running SRL labeling on either side of the language pair, and that enables applications on low resource languages. [sent-26, score-0.152]
</p><p>17 Even with the SRL constraints, the generated corpus may still be large and noisy. [sent-27, score-0.171]
</p><p>18 Hence, we apply an additional filtering stage on the generated corpus. [sent-28, score-0.159]
</p><p>19 We used an SVM classifier with features derived from standard phrase based translation models and bilingual language models to identify high quality sentence pairs, and use these sentence pairs in the SMT training. [sent-29, score-0.773]
</p><p>20 2 The Proposed Approach The objective of the method is to generate new syntactically and semantically well-formed parallel sentences from existing corpus. [sent-31, score-0.203]
</p><p>21 To achieve this, we first  collect a set of rules as the candidates for the substitution. [sent-32, score-0.132]
</p><p>22 We also need to know where we should put in the replacements and whether the resulting sentence pairs are grammatical. [sent-33, score-0.19]
</p><p>23 First, standard word alignment and phrase extraction are performed on existing corpus. [sent-34, score-0.466]
</p><p>24 Afterwards, we apply an SRL labeler on either the source or target language, whichever has a better SRL labeler. [sent-35, score-0.17]
</p><p>25 Third, we extract SRL substitution rules (SSRs) from the corpus. [sent-36, score-0.192]
</p><p>26 The rules carry information of semantic frames, semantic roles, and corresponding Proceedings ofP thoer t4l9atnhd A, Onrnuegaoln M,e Jeuntineg 19 o-f2 t4h,e 2 A0s1s1o. [sent-37, score-0.314]
</p><p>27 New phrases that will otherwise not be included in the phrase table are shown on the bottom. [sent-40, score-0.459]
</p><p>28 Fourth, we replace phrase pairs in existing sentences with the SSR if they have the same semantic frames and semantic roles. [sent-42, score-0.805]
</p><p>29 The newly generated sentence pairs will pass through a classifier to determine whether they are acceptable parallel sentences. [sent-43, score-0.492]
</p><p>30 The resulting phrase table can either be used directly in translation tasks or be interpolated with baseline phrase tables. [sent-45, score-0.996]
</p><p>31 3 SRL Substitution Rules Swapping phrase pairs that serve as the same semantic role ofthe same semantic frame can provide more combinations of words and phrases. [sent-46, score-0.783]
</p><p>32 In this paper, we call a tuple of semantic frame and semantic role a semantic signature. [sent-50, score-0.446]
</p><p>33 Two phrase pairs with the same semantic signature are considered valid substitutions of each other. [sent-51, score-0.65]
</p><p>34 The extraction of SSRs is similar to the wellknown phrase extraction algorithm (Och and Ney, 2004). [sent-52, score-0.343]
</p><p>35 The criteria of a phrase pair to be included in the SSR set are1 :  犁  •  The phrase on side A must cover a whole semThaent pich rroaslee constituent, manusdt i ct must not hcoolnetsa ien-  1We call the language which has SRL labels side A, and the other language side B. [sent-53, score-1.192]
</p><p>36 295  •  •  words in any other semantic role constituent of the same frame. [sent-54, score-0.174]
</p><p>37 The phrase on side B must not contain words tThhaet l pihnkra tsoe w onord sisd neo Bt Bin m tuhset phrase on isnid we oArd. [sent-55, score-0.804]
</p><p>38 Both of the two boundary words on side B phrases m thuest hwaove b oatu nledaasrty one rlidnsk o tno a dweo rBd of the phrases on side A. [sent-56, score-0.532]
</p><p>39 The boundary words on side A phrases can be unaligned only if they are inside the semantic role constituent. [sent-57, score-0.472]
</p><p>40 For each semantic structure of each sentence,2 we determine the phrase pair to be replaced by the same criteria as mention above, and search for suitable SSRs with the same semantic signature. [sent-59, score-0.691]
</p><p>41 Finally, we replace the original phrases with the source and target side phrases given by the SSRs. [sent-60, score-0.406]
</p><p>42 First, for frequent semantic frames, the number of substitution candidates can be very large. [sent-63, score-0.281]
</p><p>43 It will generate many new sentence pairs, and can easily exceed the capacity of our system. [sent-64, score-0.114]
</p><p>44 To deal with the problem, we pre-filter the SSRs so that each semantic signature is associated with no more than 100 SSRs. [sent-65, score-0.196]
</p><p>45 As we can see from the criteria for extracting SSRs, all the entries in the SSR rule set satisfies the commonly used phrase extraction heuristics. [sent-66, score-0.422]
</p><p>46 Therefore, the set of SSRs is a subset of the phrase table. [sent-67, score-0.343]
</p><p>47 Because of this, We use the features in the phrase table to sort the rules, and keep 100 rules with highest the arithmetic mean of the feature values. [sent-68, score-0.486]
</p><p>48 The second problem is the phrase boundaries are often inaccurate. [sent-69, score-0.402]
</p><p>49 If the inserted phrase has a prefix or suffix sub-phrase that is the same as the suffix or prefix of the adjacent parts of the original sentence, then the duplication will be removed. [sent-71, score-0.487]
</p><p>50 4  Classification of Generated Sentences  We can expect the generated corpus be noisy, and needs to be filtered. [sent-72, score-0.171]
</p><p>51 First we label a set of 2One sentence can have multiple semantic structures. [sent-74, score-0.196]
</p><p>52 sentence pairs 3 randomly sampled from the generated data. [sent-75, score-0.317]
</p><p>53 Are the two sentences grammatical, especially on the boundaries of substituted phrase pairs? [sent-77, score-0.402]
</p><p>54 If both questions have positive answers, we label the sentence pair as positive. [sent-80, score-0.194]
</p><p>55 Therefore, the features in the phrase table can be used as features. [sent-84, score-0.343]
</p><p>56 It includes the bidirectional phrase and lexicon translation probabilities. [sent-85, score-0.447]
</p><p>57 The language model score of the whole sentence is useless because it is dominated by words not affected by the substitution. [sent-87, score-0.136]
</p><p>58 Given an n-gram language model, we only calculate  the scores in windows with the size 2n −2, centered on t shceo boundary doofw wthse w suithbs tthietut seizde phrases. [sent-92, score-0.133]
</p><p>59 t Finally, there are two additional features: the probability of observing the source/target phrase given the semantic signature. [sent-94, score-0.46]
</p><p>60 They can be calculated by counting the frequencies of source/target phrases and the semantic signature in extracted rules. [sent-95, score-0.312]
</p><p>61 As we have abundant sentence pairs generated, we prefer to apply a more harsh filtering, keeping only the best candidates. [sent-96, score-0.263]
</p><p>62 Therefore, when training the SVM model, we intentionally increase the cost of false positive errors, so as to maximize the precision rate of positive decisions and reduce possible contamination. [sent-97, score-0.147]
</p><p>63 In an experiment, we used 900 of the 1000 labeled sentence pairs as the training set, and the remaining 100 (41 positive and 59 negative samples) sentence pairs as the test set. [sent-98, score-0.427]
</p><p>64 33, we classified 20 of 41 positive samples correctly, and only 3 of the 59 negative samples are classified as positive. [sent-100, score-0.131]
</p><p>65 3We manually labeled 1000 sentence pairs 296  Corpus  Sents. [sent-101, score-0.19]
</p><p>66 5 Utilizing the Generated Corpus With the generated corpus, we perform training and generate a new phrase table. [sent-119, score-0.505]
</p><p>67 There are many ways of utilizing the new phrase table; the simplest way is to use it directly for translation tasks. [sent-120, score-0.525]
</p><p>68 However, the new phrase table may be noisier than the original one. [sent-121, score-0.343]
</p><p>69 To solve this, we interpolate the new phrase table with the baseline phrase table. [sent-122, score-0.788]
</p><p>70 If a phrase pair is only observed in the baseline phrase table, we keep it intact in the interpolated phrase table. [sent-123, score-1.332]
</p><p>71 If a phrase pair is observed only in the new phrase table, we discount all the feature values by a factor of 2. [sent-124, score-0.789]
</p><p>72 And if the phrase pair is in both of the phrase tables, the  feature values will be the arithmetic mean of the corresponding values in the two phrase tables. [sent-125, score-1.16]
</p><p>73 We also noticed that the new corpus may have very different distribution of words comparing to the baseline corpus. [sent-126, score-0.111]
</p><p>74 The word alignment process using generative models is more likely to be affected by the radical change of distributions. [sent-127, score-0.168]
</p><p>75 Therefore, we also experimented with force aligning the generated corpus with the word alignment models trained baseline corpus before building the phrase table. [sent-128, score-0.698]
</p><p>76 The baseline system is trained on the FBIS corpus, the statistics of the corpus is shown in Table 1. [sent-130, score-0.145]
</p><p>77 We aligned the parallel sentences with MGIZA(Gao and Vogel, 2008), and performed experiments with the Moses toolkit (Koehn et al, 2007). [sent-136, score-0.118]
</p><p>78 94  Table 2: Experiment results on Chinese-English translation tasks, the abbreviations for systems are as follows: BL: Baseline system, GS: System trained with only generated sentence pairs, I Interpolated phrase table with T: GS and BL,. [sent-208, score-0.653]
</p><p>79 GA and IA are GS and I systems trained T with baseline word alignment models accordingly. [sent-209, score-0.14]
</p><p>80 6 million sentences from the 387K sentence pairs, and by using the SVM-based classifier, we filter the corpus down to 7. [sent-214, score-0.187]
</p><p>81 We also observed that the average sentence length increases by 15% in the generated corpus. [sent-216, score-0.241]
</p><p>82 Therefore, they have more occurrences in the generated corpus. [sent-218, score-0.127]
</p><p>83 As we can see in the results, by using only the generated sentence pairs, the performance of the system drops. [sent-221, score-0.206]
</p><p>84 When using baseline alignment model, we observe a quite different phenomenon. [sent-227, score-0.18]
</p><p>85 In this case, interpolating the phrase tables no longer show improvements. [sent-228, score-0.51]
</p><p>86 However, using the generated corpus alone achieves 297 PT size BL GS  IT GA IA  LS  C. [sent-229, score-0.171]
</p><p>87 63  Table 3: Statistics of phrase tables and translation outputs, including the phrase tables (PT) size, the coverage of the BL phrase table entries (C. [sent-265, score-1.332]
</p><p>88 ), the number of new source phrases comparing to BL system (N. [sent-269, score-0.172]
</p><p>89 ), the average number of alternative translations of each source phrase (T/S) and the average source phrase length in the output (A. [sent-271, score-0.798]
</p><p>90 An explanation is that using identical alignment model makes the phrases extracted from the baseline and generated corpus similar, which undermines the idea of interpolating two phrase tables. [sent-275, score-0.892]
</p><p>91 As shown in Table 3, it generates less new source phrases and 10% more phrase pairs that  overlaps with the baseline phrase table. [sent-276, score-1.036]
</p><p>92 The expanded corpus performs almost as well as the GALE system even though the large system has a phrase table that is four time larger. [sent-280, score-0.387]
</p><p>93 The statistics of the phrase tables and translation outputs are listed in Table 3. [sent-281, score-0.564]
</p><p>94 7 Conclusion In this paper we explore a novel way of generating new parallel corpus from existing SRL labeled corpus. [sent-283, score-0.248]
</p><p>95 By extracting SRL substitution rules (SSRs) we generate a large set of sentence pairs, and by apply-  ing an SVM-based classifier we can filter the corpus, 4FBIS corpus is included in the GALE dataset keeping only grammatical sentence pairs. [sent-284, score-0.641]
</p><p>96 By interpolating the phrase table with the baseline phrase table, we observed improvement on Chinese-English machine translation tasks and the performance is comparable to system trained with larger manually collected parallel corpus. [sent-285, score-1.135]
</p><p>97 The advantage of the proposed method is that we only need the SRL labels on either side of the language pair, and we can choose the one with a better SRL labeler. [sent-287, score-0.118]
</p><p>98 The features we used in the paper are still primitive, which results in a classifier radically tuned against false positive rate. [sent-288, score-0.192]
</p><p>99 Since the method will only introduce new phrases across the phrase boundaries of phrases in existing phrase table, it is desirable to be integrated with other paraphrasing approaches to further increase the coverage of the generated corpus. [sent-290, score-1.217]
</p><p>100 The proposition bank: An annotated corpus of semantic roles. [sent-318, score-0.161]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('srl', 0.407), ('phrase', 0.343), ('ssrs', 0.305), ('ssr', 0.218), ('bl', 0.174), ('gs', 0.174), ('ga', 0.14), ('gale', 0.135), ('generated', 0.127), ('parallel', 0.118), ('side', 0.118), ('semantic', 0.117), ('phrases', 0.116), ('substitution', 0.112), ('pairs', 0.111), ('ter', 0.106), ('translation', 0.104), ('interpolated', 0.098), ('ls', 0.091), ('ia', 0.088), ('interpolating', 0.084), ('tables', 0.083), ('bleu', 0.082), ('rules', 0.08), ('sentence', 0.079), ('signature', 0.079), ('labeler', 0.079), ('utilizing', 0.078), ('alignment', 0.073), ('pair', 0.068), ('frames', 0.067), ('baseline', 0.067), ('boundary', 0.064), ('filter', 0.064), ('svm', 0.064), ('arithmetic', 0.063), ('pradhan', 0.063), ('fbis', 0.063), ('paraphrasing', 0.063), ('boundaries', 0.059), ('classifier', 0.057), ('role', 0.057), ('affected', 0.057), ('source', 0.056), ('stephan', 0.055), ('qin', 0.054), ('avg', 0.054), ('false', 0.053), ('grammatical', 0.053), ('gao', 0.052), ('candidates', 0.052), ('existing', 0.05), ('nist', 0.048), ('positive', 0.047), ('criteria', 0.046), ('corpus', 0.044), ('paraphrases', 0.044), ('chris', 0.043), ('palmer', 0.042), ('samples', 0.042), ('convey', 0.042), ('nps', 0.042), ('tasks', 0.041), ('ch', 0.041), ('vogel', 0.04), ('observe', 0.04), ('quirk', 0.04), ('frame', 0.038), ('prefix', 0.038), ('mgiza', 0.038), ('pich', 0.038), ('forbes', 0.038), ('ofnew', 0.038), ('radical', 0.038), ('undermines', 0.038), ('voge', 0.038), ('constraints', 0.038), ('keeping', 0.038), ('generating', 0.036), ('scores', 0.036), ('interpolate', 0.035), ('intact', 0.035), ('radically', 0.035), ('assert', 0.035), ('harsh', 0.035), ('kadri', 0.035), ('whichever', 0.035), ('observed', 0.035), ('generate', 0.035), ('koehn', 0.035), ('moses', 0.034), ('statistics', 0.034), ('suffix', 0.034), ('labeling', 0.034), ('centered', 0.033), ('hacioglu', 0.033), ('lion', 0.033), ('wayne', 0.033), ('entries', 0.033), ('filtering', 0.032)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="87-tfidf-1" href="./acl-2011-Corpus_Expansion_for_Statistical_Machine_Translation_with_Semantic_Role_Label_Substitution_Rules.html">87 acl-2011-Corpus Expansion for Statistical Machine Translation with Semantic Role Label Substitution Rules</a></p>
<p>Author: Qin Gao ; Stephan Vogel</p><p>Abstract: We present an approach of expanding parallel corpora for machine translation. By utilizing Semantic role labeling (SRL) on one side of the language pair, we extract SRL substitution rules from existing parallel corpus. The rules are then used for generating new sentence pairs. An SVM classifier is built to filter the generated sentence pairs. The filtered corpus is used for training phrase-based translation models, which can be used directly in translation tasks or combined with baseline models. Experimental results on ChineseEnglish machine translation tasks show an average improvement of 0.45 BLEU and 1.22 TER points across 5 different NIST test sets.</p><p>2 0.25834697 <a title="87-tfidf-2" href="./acl-2011-An_Unsupervised_Model_for_Joint_Phrase_Alignment_and_Extraction.html">43 acl-2011-An Unsupervised Model for Joint Phrase Alignment and Extraction</a></p>
<p>Author: Graham Neubig ; Taro Watanabe ; Eiichiro Sumita ; Shinsuke Mori ; Tatsuya Kawahara</p><p>Abstract: We present an unsupervised model for joint phrase alignment and extraction using nonparametric Bayesian methods and inversion transduction grammars (ITGs). The key contribution is that phrases of many granularities are included directly in the model through the use of a novel formulation that memorizes phrases generated not only by terminal, but also non-terminal symbols. This allows for a completely probabilistic model that is able to create a phrase table that achieves competitive accuracy on phrase-based machine translation tasks directly from unaligned sentence pairs. Experiments on several language pairs demonstrate that the proposed model matches the accuracy of traditional two-step word alignment/phrase extraction approach while reducing the phrase table to a fraction of the original size.</p><p>3 0.22424914 <a title="87-tfidf-3" href="./acl-2011-MEANT%3A_An_inexpensive%2C_high-accuracy%2C_semi-automatic_metric_for_evaluating_translation_utility_based_on_semantic_roles.html">216 acl-2011-MEANT: An inexpensive, high-accuracy, semi-automatic metric for evaluating translation utility based on semantic roles</a></p>
<p>Author: Chi-kiu Lo ; Dekai Wu</p><p>Abstract: We introduce a novel semi-automated metric, MEANT, that assesses translation utility by matching semantic role fillers, producing scores that correlate with human judgment as well as HTER but at much lower labor cost. As machine translation systems improve in lexical choice and fluency, the shortcomings of widespread n-gram based, fluency-oriented MT evaluation metrics such as BLEU, which fail to properly evaluate adequacy, become more apparent. But more accurate, nonautomatic adequacy-oriented MT evaluation metrics like HTER are highly labor-intensive, which bottlenecks the evaluation cycle. We first show that when using untrained monolingual readers to annotate semantic roles in MT output, the non-automatic version of the metric HMEANT achieves a 0.43 correlation coefficient with human adequacyjudgments at the sentence level, far superior to BLEU at only 0.20, and equal to the far more expensive HTER. We then replace the human semantic role annotators with automatic shallow semantic parsing to further automate the evaluation metric, and show that even the semiautomated evaluation metric achieves a 0.34 correlation coefficient with human adequacy judgment, which is still about 80% as closely correlated as HTER despite an even lower labor cost for the evaluation procedure. The results show that our proposed metric is significantly better correlated with human judgment on adequacy than current widespread automatic evaluation metrics, while being much more cost effective than HTER. 1</p><p>4 0.18851902 <a title="87-tfidf-4" href="./acl-2011-A_Word-Class_Approach_to_Labeling_PSCFG_Rules_for_Machine_Translation.html">29 acl-2011-A Word-Class Approach to Labeling PSCFG Rules for Machine Translation</a></p>
<p>Author: Andreas Zollmann ; Stephan Vogel</p><p>Abstract: In this work we propose methods to label probabilistic synchronous context-free grammar (PSCFG) rules using only word tags, generated by either part-of-speech analysis or unsupervised word class induction. The proposals range from simple tag-combination schemes to a phrase clustering model that can incorporate an arbitrary number of features. Our models improve translation quality over the single generic label approach of Chiang (2005) and perform on par with the syntactically motivated approach from Zollmann and Venugopal (2006) on the NIST large Chineseto-English translation task. These results persist when using automatically learned word tags, suggesting broad applicability of our technique across diverse language pairs for which syntactic resources are not available.</p><p>5 0.15387918 <a title="87-tfidf-5" href="./acl-2011-Using_Bilingual_Parallel_Corpora_for_Cross-Lingual_Textual_Entailment.html">327 acl-2011-Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment</a></p>
<p>Author: Yashar Mehdad ; Matteo Negri ; Marcello Federico</p><p>Abstract: This paper explores the use of bilingual parallel corpora as a source of lexical knowledge for cross-lingual textual entailment. We claim that, in spite of the inherent difficulties of the task, phrase tables extracted from parallel data allow to capture both lexical relations between single words, and contextual information useful for inference. We experiment with a phrasal matching method in order to: i) build a system portable across languages, and ii) evaluate the contribution of lexical knowledge in isolation, without interaction with other inference mechanisms. Results achieved on an English-Spanish corpus obtained from the RTE3 dataset support our claim, with an overall accuracy above average scores reported by RTE participants on monolingual data. Finally, we show that using parallel corpora to extract paraphrase tables reveals their potential also in the monolingual setting, improving the results achieved with other sources of lexical knowledge.</p><p>6 0.14403404 <a title="87-tfidf-6" href="./acl-2011-An_exponential_translation_model_for_target_language_morphology.html">44 acl-2011-An exponential translation model for target language morphology</a></p>
<p>7 0.13887773 <a title="87-tfidf-7" href="./acl-2011-How_Much_Can_We_Gain_from_Supervised_Word_Alignment%3F.html">152 acl-2011-How Much Can We Gain from Supervised Word Alignment?</a></p>
<p>8 0.13128865 <a title="87-tfidf-8" href="./acl-2011-Extracting_Paraphrases_from_Definition_Sentences_on_the_Web.html">132 acl-2011-Extracting Paraphrases from Definition Sentences on the Web</a></p>
<p>9 0.12693593 <a title="87-tfidf-9" href="./acl-2011-Consistent_Translation_using_Discriminative_Learning_-_A_Translation_Memory-inspired_Approach.html">81 acl-2011-Consistent Translation using Discriminative Learning - A Translation Memory-inspired Approach</a></p>
<p>10 0.12420171 <a title="87-tfidf-10" href="./acl-2011-Learning_Hierarchical_Translation_Structure_with_Linguistic_Annotations.html">202 acl-2011-Learning Hierarchical Translation Structure with Linguistic Annotations</a></p>
<p>11 0.11855932 <a title="87-tfidf-11" href="./acl-2011-Goodness%3A_A_Method_for_Measuring_Machine_Translation_Confidence.html">146 acl-2011-Goodness: A Method for Measuring Machine Translation Confidence</a></p>
<p>12 0.11656663 <a title="87-tfidf-12" href="./acl-2011-Effects_of_Noun_Phrase_Bracketing_in_Dependency_Parsing_and_Machine_Translation.html">111 acl-2011-Effects of Noun Phrase Bracketing in Dependency Parsing and Machine Translation</a></p>
<p>13 0.11519631 <a title="87-tfidf-13" href="./acl-2011-Effective_Use_of_Function_Words_for_Rule_Generalization_in_Forest-Based_Translation.html">110 acl-2011-Effective Use of Function Words for Rule Generalization in Forest-Based Translation</a></p>
<p>14 0.11519224 <a title="87-tfidf-14" href="./acl-2011-Reordering_Constraint_Based_on_Document-Level_Context.html">263 acl-2011-Reordering Constraint Based on Document-Level Context</a></p>
<p>15 0.11134434 <a title="87-tfidf-15" href="./acl-2011-Domain_Adaptation_for_Machine_Translation_by_Mining_Unseen_Words.html">104 acl-2011-Domain Adaptation for Machine Translation by Mining Unseen Words</a></p>
<p>16 0.10885396 <a title="87-tfidf-16" href="./acl-2011-Two_Easy_Improvements_to_Lexical_Weighting.html">313 acl-2011-Two Easy Improvements to Lexical Weighting</a></p>
<p>17 0.10820309 <a title="87-tfidf-17" href="./acl-2011-An_Empirical_Evaluation_of_Data-Driven_Paraphrase_Generation_Techniques.html">37 acl-2011-An Empirical Evaluation of Data-Driven Paraphrase Generation Techniques</a></p>
<p>18 0.10741486 <a title="87-tfidf-18" href="./acl-2011-Collecting_Highly_Parallel_Data_for_Paraphrase_Evaluation.html">72 acl-2011-Collecting Highly Parallel Data for Paraphrase Evaluation</a></p>
<p>19 0.10477127 <a title="87-tfidf-19" href="./acl-2011-Rare_Word_Translation_Extraction_from_Aligned_Comparable_Documents.html">259 acl-2011-Rare Word Translation Extraction from Aligned Comparable Documents</a></p>
<p>20 0.10046045 <a title="87-tfidf-20" href="./acl-2011-Bayesian_Word_Alignment_for_Statistical_Machine_Translation.html">57 acl-2011-Bayesian Word Alignment for Statistical Machine Translation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.273), (1, -0.151), (2, 0.086), (3, 0.117), (4, 0.07), (5, 0.048), (6, 0.066), (7, -0.007), (8, 0.03), (9, -0.106), (10, 0.035), (11, 0.001), (12, 0.016), (13, -0.008), (14, -0.032), (15, -0.017), (16, -0.052), (17, 0.009), (18, 0.026), (19, -0.006), (20, -0.079), (21, 0.053), (22, -0.066), (23, -0.087), (24, 0.059), (25, 0.073), (26, 0.009), (27, -0.076), (28, -0.0), (29, -0.013), (30, 0.041), (31, -0.016), (32, -0.026), (33, -0.009), (34, -0.015), (35, -0.032), (36, 0.087), (37, -0.047), (38, 0.047), (39, 0.091), (40, -0.104), (41, 0.138), (42, -0.047), (43, 0.021), (44, -0.023), (45, -0.019), (46, 0.05), (47, 0.035), (48, -0.018), (49, -0.015)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97526962 <a title="87-lsi-1" href="./acl-2011-Corpus_Expansion_for_Statistical_Machine_Translation_with_Semantic_Role_Label_Substitution_Rules.html">87 acl-2011-Corpus Expansion for Statistical Machine Translation with Semantic Role Label Substitution Rules</a></p>
<p>Author: Qin Gao ; Stephan Vogel</p><p>Abstract: We present an approach of expanding parallel corpora for machine translation. By utilizing Semantic role labeling (SRL) on one side of the language pair, we extract SRL substitution rules from existing parallel corpus. The rules are then used for generating new sentence pairs. An SVM classifier is built to filter the generated sentence pairs. The filtered corpus is used for training phrase-based translation models, which can be used directly in translation tasks or combined with baseline models. Experimental results on ChineseEnglish machine translation tasks show an average improvement of 0.45 BLEU and 1.22 TER points across 5 different NIST test sets.</p><p>2 0.83385795 <a title="87-lsi-2" href="./acl-2011-An_Unsupervised_Model_for_Joint_Phrase_Alignment_and_Extraction.html">43 acl-2011-An Unsupervised Model for Joint Phrase Alignment and Extraction</a></p>
<p>Author: Graham Neubig ; Taro Watanabe ; Eiichiro Sumita ; Shinsuke Mori ; Tatsuya Kawahara</p><p>Abstract: We present an unsupervised model for joint phrase alignment and extraction using nonparametric Bayesian methods and inversion transduction grammars (ITGs). The key contribution is that phrases of many granularities are included directly in the model through the use of a novel formulation that memorizes phrases generated not only by terminal, but also non-terminal symbols. This allows for a completely probabilistic model that is able to create a phrase table that achieves competitive accuracy on phrase-based machine translation tasks directly from unaligned sentence pairs. Experiments on several language pairs demonstrate that the proposed model matches the accuracy of traditional two-step word alignment/phrase extraction approach while reducing the phrase table to a fraction of the original size.</p><p>3 0.79372829 <a title="87-lsi-3" href="./acl-2011-A_Word-Class_Approach_to_Labeling_PSCFG_Rules_for_Machine_Translation.html">29 acl-2011-A Word-Class Approach to Labeling PSCFG Rules for Machine Translation</a></p>
<p>Author: Andreas Zollmann ; Stephan Vogel</p><p>Abstract: In this work we propose methods to label probabilistic synchronous context-free grammar (PSCFG) rules using only word tags, generated by either part-of-speech analysis or unsupervised word class induction. The proposals range from simple tag-combination schemes to a phrase clustering model that can incorporate an arbitrary number of features. Our models improve translation quality over the single generic label approach of Chiang (2005) and perform on par with the syntactically motivated approach from Zollmann and Venugopal (2006) on the NIST large Chineseto-English translation task. These results persist when using automatically learned word tags, suggesting broad applicability of our technique across diverse language pairs for which syntactic resources are not available.</p><p>4 0.68740088 <a title="87-lsi-4" href="./acl-2011-Consistent_Translation_using_Discriminative_Learning_-_A_Translation_Memory-inspired_Approach.html">81 acl-2011-Consistent Translation using Discriminative Learning - A Translation Memory-inspired Approach</a></p>
<p>Author: Yanjun Ma ; Yifan He ; Andy Way ; Josef van Genabith</p><p>Abstract: We present a discriminative learning method to improve the consistency of translations in phrase-based Statistical Machine Translation (SMT) systems. Our method is inspired by Translation Memory (TM) systems which are widely used by human translators in industrial settings. We constrain the translation of an input sentence using the most similar ‘translation example’ retrieved from the TM. Differently from previous research which used simple fuzzy match thresholds, these constraints are imposed using discriminative learning to optimise the translation performance. We observe that using this method can benefit the SMT system by not only producing consistent translations, but also improved translation outputs. We report a 0.9 point improvement in terms of BLEU score on English–Chinese technical documents.</p><p>5 0.68474853 <a title="87-lsi-5" href="./acl-2011-Using_Bilingual_Parallel_Corpora_for_Cross-Lingual_Textual_Entailment.html">327 acl-2011-Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment</a></p>
<p>Author: Yashar Mehdad ; Matteo Negri ; Marcello Federico</p><p>Abstract: This paper explores the use of bilingual parallel corpora as a source of lexical knowledge for cross-lingual textual entailment. We claim that, in spite of the inherent difficulties of the task, phrase tables extracted from parallel data allow to capture both lexical relations between single words, and contextual information useful for inference. We experiment with a phrasal matching method in order to: i) build a system portable across languages, and ii) evaluate the contribution of lexical knowledge in isolation, without interaction with other inference mechanisms. Results achieved on an English-Spanish corpus obtained from the RTE3 dataset support our claim, with an overall accuracy above average scores reported by RTE participants on monolingual data. Finally, we show that using parallel corpora to extract paraphrase tables reveals their potential also in the monolingual setting, improving the results achieved with other sources of lexical knowledge.</p><p>6 0.67907041 <a title="87-lsi-6" href="./acl-2011-An_exponential_translation_model_for_target_language_morphology.html">44 acl-2011-An exponential translation model for target language morphology</a></p>
<p>7 0.67638439 <a title="87-lsi-7" href="./acl-2011-Translating_from_Morphologically_Complex_Languages%3A_A_Paraphrase-Based_Approach.html">310 acl-2011-Translating from Morphologically Complex Languages: A Paraphrase-Based Approach</a></p>
<p>8 0.65220517 <a title="87-lsi-8" href="./acl-2011-Learning_Hierarchical_Translation_Structure_with_Linguistic_Annotations.html">202 acl-2011-Learning Hierarchical Translation Structure with Linguistic Annotations</a></p>
<p>9 0.64993018 <a title="87-lsi-9" href="./acl-2011-Two_Easy_Improvements_to_Lexical_Weighting.html">313 acl-2011-Two Easy Improvements to Lexical Weighting</a></p>
<p>10 0.64681244 <a title="87-lsi-10" href="./acl-2011-Reordering_Constraint_Based_on_Document-Level_Context.html">263 acl-2011-Reordering Constraint Based on Document-Level Context</a></p>
<p>11 0.64149827 <a title="87-lsi-11" href="./acl-2011-Goodness%3A_A_Method_for_Measuring_Machine_Translation_Confidence.html">146 acl-2011-Goodness: A Method for Measuring Machine Translation Confidence</a></p>
<p>12 0.63646203 <a title="87-lsi-12" href="./acl-2011-Syntax-based_Statistical_Machine_Translation_using_Tree_Automata_and_Tree_Transducers.html">290 acl-2011-Syntax-based Statistical Machine Translation using Tree Automata and Tree Transducers</a></p>
<p>13 0.63413322 <a title="87-lsi-13" href="./acl-2011-Reordering_Modeling_using_Weighted_Alignment_Matrices.html">265 acl-2011-Reordering Modeling using Weighted Alignment Matrices</a></p>
<p>14 0.62327397 <a title="87-lsi-14" href="./acl-2011-MEANT%3A_An_inexpensive%2C_high-accuracy%2C_semi-automatic_metric_for_evaluating_translation_utility_based_on_semantic_roles.html">216 acl-2011-MEANT: An inexpensive, high-accuracy, semi-automatic metric for evaluating translation utility based on semantic roles</a></p>
<p>15 0.61268002 <a title="87-lsi-15" href="./acl-2011-A_Joint_Sequence_Translation_Model_with_Integrated_Reordering.html">16 acl-2011-A Joint Sequence Translation Model with Integrated Reordering</a></p>
<p>16 0.60432255 <a title="87-lsi-16" href="./acl-2011-Unsupervised_Word_Alignment_with_Arbitrary_Features.html">325 acl-2011-Unsupervised Word Alignment with Arbitrary Features</a></p>
<p>17 0.60249436 <a title="87-lsi-17" href="./acl-2011-Bayesian_Word_Alignment_for_Statistical_Machine_Translation.html">57 acl-2011-Bayesian Word Alignment for Statistical Machine Translation</a></p>
<p>18 0.58946967 <a title="87-lsi-18" href="./acl-2011-How_Much_Can_We_Gain_from_Supervised_Word_Alignment%3F.html">152 acl-2011-How Much Can We Gain from Supervised Word Alignment?</a></p>
<p>19 0.57931393 <a title="87-lsi-19" href="./acl-2011-Clause_Restructuring_For_SMT_Not_Absolutely_Helpful.html">69 acl-2011-Clause Restructuring For SMT Not Absolutely Helpful</a></p>
<p>20 0.57525426 <a title="87-lsi-20" href="./acl-2011-Phrase-Based_Translation_Model_for_Question_Retrieval_in_Community_Question_Answer_Archives.html">245 acl-2011-Phrase-Based Translation Model for Question Retrieval in Community Question Answer Archives</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.023), (17, 0.1), (26, 0.021), (31, 0.012), (37, 0.084), (39, 0.05), (41, 0.083), (53, 0.244), (55, 0.024), (59, 0.055), (72, 0.063), (91, 0.032), (96, 0.15)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.8794688 <a title="87-lda-1" href="./acl-2011-Extracting_Paraphrases_from_Definition_Sentences_on_the_Web.html">132 acl-2011-Extracting Paraphrases from Definition Sentences on the Web</a></p>
<p>Author: Chikara Hashimoto ; Kentaro Torisawa ; Stijn De Saeger ; Jun'ichi Kazama ; Sadao Kurohashi</p><p>Abstract: ¶ kuro@i . We propose an automatic method of extracting paraphrases from definition sentences, which are also automatically acquired from the Web. We observe that a huge number of concepts are defined in Web documents, and that the sentences that define the same concept tend to convey mostly the same information using different expressions and thus contain many paraphrases. We show that a large number of paraphrases can be automatically extracted with high precision by regarding the sentences that define the same concept as parallel corpora. Experimental results indicated that with our method it was possible to extract about 300,000 paraphrases from 6 Web docu3m0e0n,t0s0 w0i ptha a precision oramte 6 6o ×f a 1b0out 94%. 108</p><p>2 0.87485975 <a title="87-lda-2" href="./acl-2011-Identifying_Noun_Product_Features_that_Imply_Opinions.html">159 acl-2011-Identifying Noun Product Features that Imply Opinions</a></p>
<p>Author: Lei Zhang ; Bing Liu</p><p>Abstract: Identifying domain-dependent opinion words is a key problem in opinion mining and has been studied by several researchers. However, existing work has been focused on adjectives and to some extent verbs. Limited work has been done on nouns and noun phrases. In our work, we used the feature-based opinion mining model, and we found that in some domains nouns and noun phrases that indicate product features may also imply opinions. In many such cases, these nouns are not subjective but objective. Their involved sentences are also objective sentences and imply positive or negative opinions. Identifying such nouns and noun phrases and their polarities is very challenging but critical for effective opinion mining in these domains. To the best of our knowledge, this problem has not been studied in the literature. This paper proposes a method to deal with the problem. Experimental results based on real-life datasets show promising results. 1</p><p>3 0.83883548 <a title="87-lda-3" href="./acl-2011-Unsupervised_Part-of-Speech_Tagging_with_Bilingual_Graph-Based_Projections.html">323 acl-2011-Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</a></p>
<p>Author: Dipanjan Das ; Slav Petrov</p><p>Abstract: We describe a novel approach for inducing unsupervised part-of-speech taggers for languages that have no labeled training data, but have translated text in a resource-rich language. Our method does not assume any knowledge about the target language (in particular no tagging dictionary is assumed), making it applicable to a wide array of resource-poor languages. We use graph-based label propagation for cross-lingual knowledge transfer and use the projected labels as features in an unsupervised model (BergKirkpatrick et al., 2010). Across eight European languages, our approach results in an average absolute improvement of 10.4% over a state-of-the-art baseline, and 16.7% over vanilla hidden Markov models induced with the Expectation Maximization algorithm.</p><p>4 0.82572776 <a title="87-lda-4" href="./acl-2011-Chinese_sentence_segmentation_as_comma_classification.html">66 acl-2011-Chinese sentence segmentation as comma classification</a></p>
<p>Author: Nianwen Xue ; Yaqin Yang</p><p>Abstract: We describe a method for disambiguating Chinese commas that is central to Chinese sentence segmentation. Chinese sentence segmentation is viewed as the detection of loosely coordinated clauses separated by commas. Trained and tested on data derived from the Chinese Treebank, our model achieves a classification accuracy of close to 90% overall, which translates to an F1 score of 70% for detecting commas that signal sentence boundaries.</p><p>same-paper 5 0.80724227 <a title="87-lda-5" href="./acl-2011-Corpus_Expansion_for_Statistical_Machine_Translation_with_Semantic_Role_Label_Substitution_Rules.html">87 acl-2011-Corpus Expansion for Statistical Machine Translation with Semantic Role Label Substitution Rules</a></p>
<p>Author: Qin Gao ; Stephan Vogel</p><p>Abstract: We present an approach of expanding parallel corpora for machine translation. By utilizing Semantic role labeling (SRL) on one side of the language pair, we extract SRL substitution rules from existing parallel corpus. The rules are then used for generating new sentence pairs. An SVM classifier is built to filter the generated sentence pairs. The filtered corpus is used for training phrase-based translation models, which can be used directly in translation tasks or combined with baseline models. Experimental results on ChineseEnglish machine translation tasks show an average improvement of 0.45 BLEU and 1.22 TER points across 5 different NIST test sets.</p><p>6 0.76402318 <a title="87-lda-6" href="./acl-2011-Monolingual_Alignment_by_Edit_Rate_Computation_on_Sentential_Paraphrase_Pairs.html">225 acl-2011-Monolingual Alignment by Edit Rate Computation on Sentential Paraphrase Pairs</a></p>
<p>7 0.73235071 <a title="87-lda-7" href="./acl-2011-An_Empirical_Evaluation_of_Data-Driven_Paraphrase_Generation_Techniques.html">37 acl-2011-An Empirical Evaluation of Data-Driven Paraphrase Generation Techniques</a></p>
<p>8 0.72547972 <a title="87-lda-8" href="./acl-2011-Using_Bilingual_Parallel_Corpora_for_Cross-Lingual_Textual_Entailment.html">327 acl-2011-Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment</a></p>
<p>9 0.71363997 <a title="87-lda-9" href="./acl-2011-Collecting_Highly_Parallel_Data_for_Paraphrase_Evaluation.html">72 acl-2011-Collecting Highly Parallel Data for Paraphrase Evaluation</a></p>
<p>10 0.70476007 <a title="87-lda-10" href="./acl-2011-Extracting_Opinion_Expressions_and_Their_Polarities_-_Exploration_of_Pipelines_and_Joint_Models.html">131 acl-2011-Extracting Opinion Expressions and Their Polarities - Exploration of Pipelines and Joint Models</a></p>
<p>11 0.69347358 <a title="87-lda-11" href="./acl-2011-Finding_Deceptive_Opinion_Spam_by_Any_Stretch_of_the_Imagination.html">136 acl-2011-Finding Deceptive Opinion Spam by Any Stretch of the Imagination</a></p>
<p>12 0.69323492 <a title="87-lda-12" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<p>13 0.6912061 <a title="87-lda-13" href="./acl-2011-Semi-Supervised_Frame-Semantic_Parsing_for_Unknown_Predicates.html">274 acl-2011-Semi-Supervised Frame-Semantic Parsing for Unknown Predicates</a></p>
<p>14 0.68945134 <a title="87-lda-14" href="./acl-2011-Optimal_and_Syntactically-Informed_Decoding_for_Monolingual_Phrase-Based_Alignment.html">235 acl-2011-Optimal and Syntactically-Informed Decoding for Monolingual Phrase-Based Alignment</a></p>
<p>15 0.67499518 <a title="87-lda-15" href="./acl-2011-Algorithm_Selection_and_Model_Adaptation_for_ESL_Correction_Tasks.html">32 acl-2011-Algorithm Selection and Model Adaptation for ESL Correction Tasks</a></p>
<p>16 0.67257756 <a title="87-lda-16" href="./acl-2011-Model-Based_Aligner_Combination_Using_Dual_Decomposition.html">221 acl-2011-Model-Based Aligner Combination Using Dual Decomposition</a></p>
<p>17 0.67234159 <a title="87-lda-17" href="./acl-2011-Unsupervised_Bilingual_Morpheme_Segmentation_and_Alignment_with_Context-rich_Hidden_Semi-Markov_Models.html">318 acl-2011-Unsupervised Bilingual Morpheme Segmentation and Alignment with Context-rich Hidden Semi-Markov Models</a></p>
<p>18 0.66992539 <a title="87-lda-18" href="./acl-2011-Exploiting_Syntactico-Semantic_Structures_for_Relation_Extraction.html">126 acl-2011-Exploiting Syntactico-Semantic Structures for Relation Extraction</a></p>
<p>19 0.66903782 <a title="87-lda-19" href="./acl-2011-Exploring_Entity_Relations_for_Named_Entity_Disambiguation.html">128 acl-2011-Exploring Entity Relations for Named Entity Disambiguation</a></p>
<p>20 0.66821802 <a title="87-lda-20" href="./acl-2011-Knowledge-Based_Weak_Supervision_for_Information_Extraction_of_Overlapping_Relations.html">190 acl-2011-Knowledge-Based Weak Supervision for Information Extraction of Overlapping Relations</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
