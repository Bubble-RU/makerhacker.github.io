<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>36 acl-2011-An Efficient Indexer for Large N-Gram Corpora</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-36" href="#">acl2011-36</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>36 acl-2011-An Efficient Indexer for Large N-Gram Corpora</h1>
<br/><p>Source: <a title="acl-2011-36-pdf" href="http://aclweb.org/anthology//P/P11/P11-4018.pdf">pdf</a></p><p>Author: Hakan Ceylan ; Rada Mihalcea</p><p>Abstract: We introduce a new publicly available tool that implements efficient indexing and retrieval of large N-gram datasets, such as the Web1T 5-gram corpus. Our tool indexes the entire Web1T dataset with an index size of only 100 MB and performs a retrieval of any N-gram with a single disk access. With an increased index size of 420 MB and duplicate data, it also allows users to issue wild card queries provided that the wild cards in the query are contiguous. Furthermore, we also implement some of the smoothing algorithms that are designed specifically for large datasets and are shown to yield better language models than the traditional ones on the Web1T 5gram corpus (Yuret, 2008). We demonstrate the effectiveness of our tool and the smoothing algorithms on the English Lexical Substi- tution task by a simple implementation that gives considerable improvement over a basic language model.</p><p>Reference: <a title="acl-2011-36-reference" href="../acl2011_reference/acl-2011-An_Efficient_Indexer_for_Large_N-Gram_Corpora_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Abstract We introduce a new publicly available tool that implements efficient indexing and retrieval of large N-gram datasets, such as the Web1T 5-gram corpus. [sent-2, score-0.29]
</p><p>2 Our tool indexes the entire Web1T dataset with an index size of only 100 MB and performs a retrieval of any N-gram with a single disk access. [sent-3, score-0.595]
</p><p>3 With an increased index size of 420 MB and duplicate data, it also allows users to issue wild card queries provided that the wild cards in the query are contiguous. [sent-4, score-1.452]
</p><p>4 Furthermore, we also implement some of the smoothing algorithms that are designed specifically for large datasets and are shown to yield better language models than the traditional ones on the Web1T 5gram corpus (Yuret, 2008). [sent-5, score-0.143]
</p><p>5 We demonstrate the effectiveness of our tool and the smoothing algorithms on the English Lexical Substi-  tution task by a simple implementation that gives considerable improvement over a basic language model. [sent-6, score-0.276]
</p><p>6 Since the access to N-grams is costly for these large data sets, the implementation of further improvements such as smoothing algorithms becomes impractical. [sent-15, score-0.223]
</p><p>7 In this paper, we overcome this problem by implementing a novel, publicly available tool1 that employs an indexing strategy that reduces the access time to any N-gram in the Web1T corpus to a single disk access. [sent-16, score-0.45]
</p><p>8 We also make a second contribution by implementing some ofthe smoothing models that take into account the size of the dataset, and are shown to yield up to 31% perplexity reduction on the Brown corpus (Yuret, 2008). [sent-17, score-0.178]
</p><p>9 However, 1Our tool can be freely downloaded from the download section under http://lit. [sent-21, score-0.133]
</p><p>10 The reason for the missing counts is due to the omission of low frequency N-grams in the corpus. [sent-28, score-0.103]
</p><p>11 (Yuret, 2008) shows that with a modified version of Kneser-Ney smoothing algorithm, named as the Dirichlet-Kneser-Ney, a 31% reduction in perplexity can be obtained on the Brown corpus. [sent-29, score-0.143]
</p><p>12 A tool similar to ours that uses a hashing technique in order to provide a fast access to the Web1T corpus is presented in detail in (Hawker et al. [sent-30, score-0.246]
</p><p>13 The tool provides access to queries with wild card symbols, and the performance of the tool on 106 queries on a 2. [sent-32, score-1.265]
</p><p>14 5 GBytes of memory is given approximately as one hour. [sent-34, score-0.163]
</p><p>15 Another tool, Web1T5-Easy, described in (Evert, 2010), provides indexing of the Web1T corpus via relational database tables implemented in an SQLite engine. [sent-35, score-0.118]
</p><p>16 The indexing time of this tool is reported to be two weeks, while the noncached retrieval time is given to be in order of a few seconds. [sent-37, score-0.319]
</p><p>17 The length ofeach sequence, N, ranges from 1to 5, and the size of the entire corpus is approximately 88GB (25GB in compressed form). [sent-41, score-0.124]
</p><p>18 The unigrams form the vocabulary of the corpus and are stored in a single file which includes around 13 million tokens and their associated counts. [sent-42, score-0.367]
</p><p>19 The remaining N-grams are stored separately across multiple files in lexicographic order. [sent-43, score-0.227]
</p><p>20 For example, there are 977,069,902 distinct trigrams in the dataset, and they are stored consecutively in 98 files in lexicographic order. [sent-44, score-0.261]
</p><p>21 Furthermore, each 104 N-gram file contains 10,000,000 N-grams except the last one, which contains less. [sent-45, score-0.189]
</p><p>22 It is also important to note that N-grams with counts less than 40 are excluded from the dataset for N = 2, 3, 4, 5, and the tokens with less than 200 are excluded from the unigrams. [sent-46, score-0.138]
</p><p>23 A B+-  tree is essentially a balanced search tree where each node has several children. [sent-49, score-0.174]
</p><p>24 Although many variations of B+-trees exist, we use the definition for primary indexing given in (Salzberg, 1988). [sent-51, score-0.118]
</p><p>25 Therefore we assume that the data, which is composed of records, is only stored in the leaves of the tree and the internal nodes store only the keys. [sent-52, score-0.24]
</p><p>26 The data in the leaves of a B+-tree is grouped into buckets, where the size of a bucket is determined by a bucket factor parameter, bkfr. [sent-53, score-0.669]
</p><p>27 Therefore at any given time, each bucket can hold a number of records in the range [1, bkfr] . [sent-54, score-0.402]
</p><p>28 Similarly, the number of keys that each internal node can hold is determined by the order parameter, v. [sent-55, score-0.415]
</p><p>29 By definition, each internal node except the root can have any number of keys in the range [v, 2v], and the root must have at least one key. [sent-56, score-0.489]
</p><p>30 Finally, an internal node with k keys has k + 1children. [sent-57, score-0.415]
</p><p>31 2 Mapping Unigrams to Integer Keys A key in a B+-tree is a lookup value for a record, and a record in our case is an N-gram together with its count. [sent-59, score-0.305]
</p><p>32 Therefore each line of an N-gram file in  the Web1T dataset makes up a record. [sent-60, score-0.246]
</p><p>33 However in order to reduce the storage requirements and make the comparisons faster during a lookup, we map each unigram to an integer, and form the keys of the records using the integer values instead of the tokens themselves. [sent-62, score-0.524]
</p><p>34 2 To map unigrams to integers, we use the unigrams sorted in lexicographic order and assign an integer value to each unigram starting from 1. [sent-63, score-0.567]
</p><p>35 , tm) represent all the unigrams sorted in lexicographic order, 2This method does not give optimal storage, for which one should implement a compression Huffman coding scheme. [sent-67, score-0.349]
</p><p>36 ‚Äù Thus, the comparison of two keys can be done in a similar fashion to the comparison of two N-grams; we first compare the first integer of each key, and in case of equality, we compare the second integers, and so on. [sent-70, score-0.203]
</p><p>37 If all the comparisons result in equality then the two keys (N-grams) are equal. [sent-72, score-0.174]
</p><p>38 3 Searching for a Record We construct a B+-tree for each N-gram file in the  dataset for N = 2, 3, 4, 5, and keep the key of the first N-gram for each file in memory. [sent-74, score-0.554]
</p><p>39 When a query q is issued, we first find the file that contains q by comparing the key of q to the keys in memory. [sent-75, score-0.497]
</p><p>40 Once the correct file is found, we then search the B+-tree constructed for that file for the N-gram q by using its key. [sent-77, score-0.418]
</p><p>41 As is the case with any binary search tree, a search in a B+-tree starts at the root level and ends in the leaves. [sent-78, score-0.148]
</p><p>42 If we let ri and pj represent a key and a pointer to the child of an internal node respectively, for i = 1, 2, . [sent-79, score-0.399]
</p><p>43 Since the keys in an internal node are sorted, a binary search can be performed to find rm. [sent-86, score-0.486]
</p><p>44 Finally, when a leaf node is reached, the entire bucket is read into memory first, then a record with a key value of q is searched. [sent-87, score-0.977]
</p><p>45 4 Constructing a B+-tree The construction of a B+-tree is performed through successive record insertions. [sent-89, score-0.187]
</p><p>46 3 Given a record, we 3Note that this may cause efficiency issues for very large files as memory might become full during the construction process, hence in practice, the file is usually sorted prior to indexing. [sent-90, score-0.612]
</p><p>47 105 first compute its key, find the leaf node it is supposed to be in, and insert it if the bucket is not full. [sent-91, score-0.481]
</p><p>48 Otherwise, the leaf node is split into two nodes, each containing dbkfr/2e , and bbkfr/2c 1records, and the first key of the node containing the larger key values is placed into the parent internal node together with the node‚Äôs pointer. [sent-92, score-0.764]
</p><p>49 The insertion of a key to an internal node is similar, only this time both split nodes contain v values, and the middle key value is sent up to the parent node. [sent-93, score-0.526]
</p><p>50 Note that not all the internal nodes of a B+-tree  +  have to be kept on the disk, and read from there each time we do a search. [sent-94, score-0.286]
</p><p>51 Therefore we do not need to worry about the 69% space utilization, but instead try to make each bucket, and each internal node full. [sent-101, score-0.274]
</p><p>52 Thus, with a bkfr = 1250, and v = 100, an N-gram file with 10,000,000 records would have 8,000 leaf nodes on level 3, 40 internal nodes on level 2, and the root node on level 1. [sent-102, score-0.807]
</p><p>53 Furthermore, let us assume that integers, disk and memory pointers all hold 8 bytes of space. [sent-103, score-0.391]
</p><p>54 Therefore a 5-gram key would require 40 bytes, and a full internal node in level 2 would require (200x40) (201x8) = 9, 608 bytes. [sent-104, score-0.359]
</p><p>55 There are 118 5-gram files in the Web1T dataset, so  +  +  we would need 386x118 ‚âà 46 MBytes of memory space in order to index all of them. [sent-107, score-0.311]
</p><p>56 As a final note, in order to compute a key for a given N-gram quickly, we keep the unigrams in memory, and use a hashing scheme for mapping tokens to integers, which additionally require 178 Mbytes of memory space. [sent-109, score-0.395]
</p><p>57 The choice of the bucket factor and the internal node order parameters depend on the hard-disk speed, and the available memory. [sent-110, score-0.613]
</p><p>58 Recall that even to fetch a single N-gram record from the disk, the entire bucket needs to be read. [sent-112, score-0.525]
</p><p>59 Therefore as the bucket factor parameter is reduced, the size ofthe index will grow, but the access time would be faster as long as the index could be entirely fit in memory. [sent-113, score-0.706]
</p><p>60 On the other hand, with a too large bucket factor, although the index can be made smaller, thereby reducing the memory requirements, the access time may be unacceptable for the application. [sent-114, score-0.635]
</p><p>61 Note that a random reading of a bucket of records from the hard-disk  requires the disk head to first go to the location of the first record, and then do a sequential read. [sent-115, score-0.66]
</p><p>62 5 Assuming a hard-disk having an average transfer rate of 100 MBytes, once the disk head finds the correct location, a 40 bytes N-gram record can be read in 4x10‚àí7 seconds. [sent-116, score-0.525]
</p><p>63 Thus, assumingaseektimearound 8-10 ms, even with a bucket factor of 1,000, it can be seen that the seek time is still the dominating factor. [sent-117, score-0.406]
</p><p>64 Therefore, as the bucket size gets smaller than 1,000, even though the index size will grow, there would be almost no speed up in the access time, which justifies our parameter choices. [sent-118, score-0.554]
</p><p>65 Having found the first record we perform a sequential read until the last read record does not match the query. [sent-122, score-0.542]
</p><p>66 The reason this strategy works is because the N-grams are sorted in lexicographic order in the data set, and also when we map unigram tokens to integers, we preserve their order, i. [sent-123, score-0.409]
</p><p>67 , the first token in the lexicographically sorted unigram list is assigned the value 1, the second is assigned 4We used a 7200 RPM disk-drive with an average read seek time of 8. [sent-125, score-0.418]
</p><p>68 For example, for a given query Our Honorable the record that would be pointed at the end of search in the trigram file 3gm-0041 is the Ngram Our Honorable Court 186, which is the first N-gram in the data set that starts with the bigram Our Honorable. [sent-130, score-0.498]
</p><p>69 Note however that the methodology that is described to handle the queries with wild card symbols will only work if the wild card symbols are the last tokens of the query and they are contiguous. [sent-131, score-1.693]
</p><p>70 For example a query such as Our Court will e ,  not work as N-grams satisfying this query are not stored contiguously in the data set. [sent-132, score-0.216]
</p><p>71 Therefore in order to handle such queries, we need to store additional copies of the N-grams sorted in different orders. [sent-133, score-0.215]
</p><p>72 When the last occurrence of the contiguous wild card symbols is in position p of a query N-gram for p = 0, 1, . [sent-134, score-0.829]
</p><p>73 , N 1, then the N-grams sorted lexicographically starting from position (p + 1)modN needs to be searched. [sent-137, score-0.272]
</p><p>74 Thus, for all the bigrams in the data set, we need one extra copy sorted in position 1, for all the trigrams, we need two extra copies; one sorted in position 1, and another sorted in position 2, and so forth. [sent-142, score-0.726]
</p><p>75 Hence, in order to handle the contiguous wild card queries in any position, in addition to the 88 GBytes of original Web1T data, we need an extra disk space of 265 GBytes. [sent-143, score-1.035]
</p><p>76 Furthermore, the indexing cost of the duplicate data is an additional 320 MBytes. [sent-144, score-0.118]
</p><p>77 Thus, the total disk cost of the system will be approximately 353 GBytes plus the index size of 420 MBytes, and since we keep the entire index in memory, the final memory cost of the system will be 420 MBytes + 178 MBytes = 598 MBytes. [sent-145, score-0.711]
</p><p>78 6  Performance  Given that today‚Äôs commodity hardware comes with at least 4 GBytes of memory and 1 TBytes of harddisk space, the requirements of our tool are reasonable. [sent-147, score-0.324]
</p><p>79 Furthermore, our tool is implemented in a client-server architecture, and it allows multiple clients to submit multiple queries to the server over a network. [sent-148, score-0.324]
</p><p>80 The server can be queried with an Ngram query either for its count in the corpus, or its smoothed probability with a given smoothing method. [sent-149, score-0.243]
</p><p>81 The queries with wild cards can ask for the retrieval of all the N-grams satisfying a query, or only for the total count so the network overhead can be avoided depending on the application needs. [sent-150, score-0.577]
</p><p>82 Note that some of the files in the corpus need to be sorted as many as four times. [sent-152, score-0.27]
</p><p>83 It takes about an hour to construct the index for the 5-grams. [sent-156, score-0.109]
</p><p>84 Once the offline process-  ing is done, it only takes a few minutes to start the server, and from that point the online performance of our tool is very fast. [sent-157, score-0.133]
</p><p>85 It takes about 1-2 seconds to process 1000 randomly picked 5-gram queries (with no wild card symbols), which may or may not exist in the corpus. [sent-158, score-0.784]
</p><p>86 For the queries asking for the frequencies only, our tool implements a small caching mechanism that takes the temporal locality into account. [sent-159, score-0.34]
</p><p>87 The mechanism is very useful for wild card queries involving stop words, such as ‚Äùthe ‚Äù, and ‚Äùof the ‚Äù which occur frequently, and take a long time to process due to the sequential read of a large number of records from the data set. [sent-160, score-1.029]
</p><p>88 5  Lexical Substitution  In this section we demonstrate the effectiveness of our tool by using it on the the English Lexical Substitution task, which was first introduced in SemEval 2007 (McCarthy and Navigli, 2007). [sent-161, score-0.133]
</p><p>89 Two separate datasets were provided with this task: a trial dataset was first provided in order for the participants to get familiar with the task and train their systems. [sent-166, score-0.12]
</p><p>90 The trial data used a lexical sample of 30 words with 10 instances each. [sent-167, score-0.094]
</p><p>91 We start with a simple language model that calculates the probability of the context of a word, and then continue with three smoothing algorithms discussed in (Yuret, 2008), namely Absolute Dis-  counting, Kneser-Ney with Missing Counts, and the Dirichlet-Kneser-Ney Discounting. [sent-181, score-0.143]
</p><p>92 The results on the trial dataset are shown in Table 1, and the results on the test dataset are shown in Table 2. [sent-185, score-0.177]
</p><p>93 On both the trial and the test data, we see that the interpolated smoothing algorithms consistently im-  prove over the naive language modeling, which is an encouraging result. [sent-195, score-0.206]
</p><p>94 This might suggest that the parameters of the smoothing algorithms need adjustments for each task. [sent-197, score-0.143]
</p><p>95 It is important to note that this evaluation is meant as a simple proof of concept to demonstrate the usefulness of our indexing tool. [sent-198, score-0.118]
</p><p>96 6  Conclusions  In this paper we described a new publicly available tool that provides fast access to large N-gram datasets with modest hardware requirements. [sent-201, score-0.251]
</p><p>97 In addition to providing access to individual N-gram records, our tool also handles queries with wild card symbols, provided that the wild cards in the query  are contiguous. [sent-202, score-1.521]
</p><p>98 Furthermore, the tool also implements smoothing algorithms that try to overcome the missing counts that are typical to N-gram corpora due to the omission of low frequencies. [sent-203, score-0.418]
</p><p>99 We tested our tool on the English Lexical Substitution task, and showed that the smoothing algorithms give an improvement over simple language modeling. [sent-204, score-0.276]
</p><p>100 Fbkirst: lexical substitution task exploiting domain and syntagmatic coherence. [sent-234, score-0.098]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('wild', 0.379), ('bucket', 0.295), ('card', 0.27), ('disk', 0.218), ('file', 0.189), ('record', 0.187), ('sorted', 0.185), ('mbytes', 0.182), ('yuret', 0.147), ('keys', 0.141), ('internal', 0.14), ('queries', 0.135), ('node', 0.134), ('tool', 0.133), ('gbytes', 0.13), ('indexing', 0.118), ('memory', 0.117), ('index', 0.109), ('records', 0.107), ('smoothing', 0.105), ('integers', 0.1), ('mccarthy', 0.1), ('lexicographic', 0.09), ('files', 0.085), ('key', 0.085), ('semeval', 0.083), ('query', 0.082), ('access', 0.08), ('unigrams', 0.074), ('substitution', 0.067), ('navigli', 0.067), ('read', 0.064), ('cards', 0.063), ('symbols', 0.063), ('trial', 0.063), ('integer', 0.062), ('rm', 0.059), ('participating', 0.058), ('dataset', 0.057), ('bytes', 0.056), ('server', 0.056), ('mb', 0.054), ('leaf', 0.052), ('tokens', 0.052), ('stored', 0.052), ('bkfr', 0.052), ('hakan', 0.052), ('hawker', 0.052), ('honorable', 0.052), ('lexicographically', 0.052), ('unigram', 0.05), ('brants', 0.05), ('nodes', 0.048), ('approximately', 0.046), ('clarkson', 0.046), ('denton', 0.046), ('indexer', 0.046), ('factor', 0.044), ('storage', 0.044), ('entire', 0.043), ('giuliano', 0.042), ('toolkits', 0.042), ('search', 0.04), ('pointer', 0.04), ('sequential', 0.04), ('implements', 0.039), ('perplexity', 0.038), ('algorithms', 0.038), ('omission', 0.038), ('court', 0.038), ('hardware', 0.038), ('root', 0.037), ('requirements', 0.036), ('missing', 0.036), ('hence', 0.036), ('ms', 0.035), ('position', 0.035), ('symbol', 0.035), ('size', 0.035), ('trigrams', 0.034), ('keep', 0.034), ('time', 0.034), ('equality', 0.033), ('hashing', 0.033), ('lookup', 0.033), ('seek', 0.033), ('frequencies', 0.033), ('extra', 0.033), ('furthermore', 0.033), ('witten', 0.032), ('ngram', 0.032), ('map', 0.032), ('mod', 0.031), ('kneser', 0.031), ('lexical', 0.031), ('binary', 0.031), ('thesaurus', 0.031), ('pm', 0.03), ('copies', 0.03), ('counts', 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="36-tfidf-1" href="./acl-2011-An_Efficient_Indexer_for_Large_N-Gram_Corpora.html">36 acl-2011-An Efficient Indexer for Large N-Gram Corpora</a></p>
<p>Author: Hakan Ceylan ; Rada Mihalcea</p><p>Abstract: We introduce a new publicly available tool that implements efficient indexing and retrieval of large N-gram datasets, such as the Web1T 5-gram corpus. Our tool indexes the entire Web1T dataset with an index size of only 100 MB and performs a retrieval of any N-gram with a single disk access. With an increased index size of 420 MB and duplicate data, it also allows users to issue wild card queries provided that the wild cards in the query are contiguous. Furthermore, we also implement some of the smoothing algorithms that are designed specifically for large datasets and are shown to yield better language models than the traditional ones on the Web1T 5gram corpus (Yuret, 2008). We demonstrate the effectiveness of our tool and the smoothing algorithms on the English Lexical Substi- tution task by a simple implementation that gives considerable improvement over a basic language model.</p><p>2 0.17258322 <a title="36-tfidf-2" href="./acl-2011-Faster_and_Smaller_N-Gram_Language_Models.html">135 acl-2011-Faster and Smaller N-Gram Language Models</a></p>
<p>Author: Adam Pauls ; Dan Klein</p><p>Abstract: N-gram language models are a major resource bottleneck in machine translation. In this paper, we present several language model implementations that are both highly compact and fast to query. Our fastest implementation is as fast as the widely used SRILM while requiring only 25% of the storage. Our most compact representation can store all 4 billion n-grams and associated counts for the Google n-gram corpus in 23 bits per n-gram, the most compact lossless representation to date, and even more compact than recent lossy compression techniques. We also discuss techniques for improving query speed during decoding, including a simple but novel language model caching technique that improves the query speed of our language models (and SRILM) by up to 300%.</p><p>3 0.14822099 <a title="36-tfidf-3" href="./acl-2011-Event_Discovery_in_Social_Media_Feeds.html">121 acl-2011-Event Discovery in Social Media Feeds</a></p>
<p>Author: Edward Benson ; Aria Haghighi ; Regina Barzilay</p><p>Abstract: We present a novel method for record extraction from social streams such as Twitter. Unlike typical extraction setups, these environments are characterized by short, one sentence messages with heavily colloquial speech. To further complicate matters, individual messages may not express the full relation to be uncovered, as is often assumed in extraction tasks. We develop a graphical model that addresses these problems by learning a latent set of records and a record-message alignment simultaneously; the output of our model is a set of canonical records, the values of which are consistent with aligned messages. We demonstrate that our approach is able to accurately induce event records from Twitter messages, evaluated against events from a local city guide. Our method achieves significant error reduction over baseline methods.1</p><p>4 0.11994845 <a title="36-tfidf-4" href="./acl-2011-Jigs_and_Lures%3A_Associating_Web_Queries_with_Structured_Entities.html">181 acl-2011-Jigs and Lures: Associating Web Queries with Structured Entities</a></p>
<p>Author: Patrick Pantel ; Ariel Fuxman</p><p>Abstract: We propose methods for estimating the probability that an entity from an entity database is associated with a web search query. Association is modeled using a query entity click graph, blending general query click logs with vertical query click logs. Smoothing techniques are proposed to address the inherent data sparsity in such graphs, including interpolation using a query synonymy model. A large-scale empirical analysis of the smoothing techniques, over a 2-year click graph collected from a commercial search engine, shows significant reductions in modeling error. The association models are then applied to the task of recommending products to web queries, by annotating queries with products from a large catalog and then mining query- product associations through web search session analysis. Experimental analysis shows that our smoothing techniques improve coverage while keeping precision stable, and overall, that our top-performing model affects 9% of general web queries with 94% precision.</p><p>5 0.10946803 <a title="36-tfidf-5" href="./acl-2011-Joint_Annotation_of_Search_Queries.html">182 acl-2011-Joint Annotation of Search Queries</a></p>
<p>Author: Michael Bendersky ; W. Bruce Croft ; David A. Smith</p><p>Abstract: W. Bruce Croft Dept. of Computer Science University of Massachusetts Amherst, MA cro ft @ c s .uma s s .edu David A. Smith Dept. of Computer Science University of Massachusetts Amherst, MA dasmith@ c s .umas s .edu articles or web pages). As previous research shows, these differences severely limit the applicability of Marking up search queries with linguistic annotations such as part-of-speech tags, capitalization, and segmentation, is an impor- tant part of query processing and understanding in information retrieval systems. Due to their brevity and idiosyncratic structure, search queries pose a challenge to existing NLP tools. To address this challenge, we propose a probabilistic approach for performing joint query annotation. First, we derive a robust set of unsupervised independent annotations, using queries and pseudo-relevance feedback. Then, we stack additional classifiers on the independent annotations, and exploit the dependencies between them to further improve the accuracy, even with a very limited amount of available training data. We evaluate our method using a range of queries extracted from a web search log. Experimental results verify the effectiveness of our approach for both short keyword queries, and verbose natural language queries.</p><p>6 0.10487925 <a title="36-tfidf-6" href="./acl-2011-Search_in_the_Lost_Sense_of_%22Query%22%3A_Question_Formulation_in_Web_Search_Queries_and_its_Temporal_Changes.html">271 acl-2011-Search in the Lost Sense of "Query": Question Formulation in Web Search Queries and its Temporal Changes</a></p>
<p>7 0.094384558 <a title="36-tfidf-7" href="./acl-2011-Ranking_Class_Labels_Using_Query_Sessions.html">258 acl-2011-Ranking Class Labels Using Query Sessions</a></p>
<p>8 0.090488821 <a title="36-tfidf-8" href="./acl-2011-Fine-Grained_Class_Label_Markup_of_Search_Queries.html">137 acl-2011-Fine-Grained Class Label Markup of Search Queries</a></p>
<p>9 0.080631256 <a title="36-tfidf-9" href="./acl-2011-Query_Weighting_for_Ranking_Model_Adaptation.html">256 acl-2011-Query Weighting for Ranking Model Adaptation</a></p>
<p>10 0.065947771 <a title="36-tfidf-10" href="./acl-2011-Engkoo%3A_Mining_the_Web_for_Language_Learning.html">115 acl-2011-Engkoo: Mining the Web for Language Learning</a></p>
<p>11 0.065777443 <a title="36-tfidf-11" href="./acl-2011-A_Fast_and_Accurate_Method_for_Approximate_String_Search.html">11 acl-2011-A Fast and Accurate Method for Approximate String Search</a></p>
<p>12 0.063616253 <a title="36-tfidf-12" href="./acl-2011-Piggyback%3A_Using_Search_Engines_for_Robust_Cross-Domain_Named_Entity_Recognition.html">246 acl-2011-Piggyback: Using Search Engines for Robust Cross-Domain Named Entity Recognition</a></p>
<p>13 0.062901661 <a title="36-tfidf-13" href="./acl-2011-A_Graph_Approach_to_Spelling_Correction_in_Domain-Centric_Search.html">13 acl-2011-A Graph Approach to Spelling Correction in Domain-Centric Search</a></p>
<p>14 0.062438689 <a title="36-tfidf-14" href="./acl-2011-Web-Scale_Features_for_Full-Scale_Parsing.html">333 acl-2011-Web-Scale Features for Full-Scale Parsing</a></p>
<p>15 0.061986044 <a title="36-tfidf-15" href="./acl-2011-Improving_Dependency_Parsing_with_Semantic_Classes.html">167 acl-2011-Improving Dependency Parsing with Semantic Classes</a></p>
<p>16 0.058144864 <a title="36-tfidf-16" href="./acl-2011-Blast%3A_A_Tool_for_Error_Analysis_of_Machine_Translation_Output.html">62 acl-2011-Blast: A Tool for Error Analysis of Machine Translation Output</a></p>
<p>17 0.057761487 <a title="36-tfidf-17" href="./acl-2011-A_Hierarchical_Pitman-Yor_Process_HMM_for_Unsupervised_Part_of_Speech_Induction.html">15 acl-2011-A Hierarchical Pitman-Yor Process HMM for Unsupervised Part of Speech Induction</a></p>
<p>18 0.054590672 <a title="36-tfidf-18" href="./acl-2011-Adjoining_Tree-to-String_Translation.html">30 acl-2011-Adjoining Tree-to-String Translation</a></p>
<p>19 0.053194456 <a title="36-tfidf-19" href="./acl-2011-A_Statistical_Tree_Annotator_and_Its_Applications.html">28 acl-2011-A Statistical Tree Annotator and Its Applications</a></p>
<p>20 0.052956391 <a title="36-tfidf-20" href="./acl-2011-ParaSense_or_How_to_Use_Parallel_Corpora_for_Word_Sense_Disambiguation.html">240 acl-2011-ParaSense or How to Use Parallel Corpora for Word Sense Disambiguation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.165), (1, 0.008), (2, -0.059), (3, 0.014), (4, -0.065), (5, -0.11), (6, -0.039), (7, -0.138), (8, 0.041), (9, -0.025), (10, 0.033), (11, -0.006), (12, 0.017), (13, 0.044), (14, -0.016), (15, -0.031), (16, 0.015), (17, 0.035), (18, -0.027), (19, -0.012), (20, 0.081), (21, 0.017), (22, 0.057), (23, 0.006), (24, 0.028), (25, -0.093), (26, 0.003), (27, 0.012), (28, -0.042), (29, -0.02), (30, 0.052), (31, -0.012), (32, 0.075), (33, 0.08), (34, 0.012), (35, -0.053), (36, -0.004), (37, -0.017), (38, 0.005), (39, -0.065), (40, 0.019), (41, -0.022), (42, 0.066), (43, -0.011), (44, -0.035), (45, 0.025), (46, 0.009), (47, -0.002), (48, 0.044), (49, 0.014)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9359709 <a title="36-lsi-1" href="./acl-2011-An_Efficient_Indexer_for_Large_N-Gram_Corpora.html">36 acl-2011-An Efficient Indexer for Large N-Gram Corpora</a></p>
<p>Author: Hakan Ceylan ; Rada Mihalcea</p><p>Abstract: We introduce a new publicly available tool that implements efficient indexing and retrieval of large N-gram datasets, such as the Web1T 5-gram corpus. Our tool indexes the entire Web1T dataset with an index size of only 100 MB and performs a retrieval of any N-gram with a single disk access. With an increased index size of 420 MB and duplicate data, it also allows users to issue wild card queries provided that the wild cards in the query are contiguous. Furthermore, we also implement some of the smoothing algorithms that are designed specifically for large datasets and are shown to yield better language models than the traditional ones on the Web1T 5gram corpus (Yuret, 2008). We demonstrate the effectiveness of our tool and the smoothing algorithms on the English Lexical Substi- tution task by a simple implementation that gives considerable improvement over a basic language model.</p><p>2 0.82520318 <a title="36-lsi-2" href="./acl-2011-Faster_and_Smaller_N-Gram_Language_Models.html">135 acl-2011-Faster and Smaller N-Gram Language Models</a></p>
<p>Author: Adam Pauls ; Dan Klein</p><p>Abstract: N-gram language models are a major resource bottleneck in machine translation. In this paper, we present several language model implementations that are both highly compact and fast to query. Our fastest implementation is as fast as the widely used SRILM while requiring only 25% of the storage. Our most compact representation can store all 4 billion n-grams and associated counts for the Google n-gram corpus in 23 bits per n-gram, the most compact lossless representation to date, and even more compact than recent lossy compression techniques. We also discuss techniques for improving query speed during decoding, including a simple but novel language model caching technique that improves the query speed of our language models (and SRILM) by up to 300%.</p><p>3 0.70873559 <a title="36-lsi-3" href="./acl-2011-Jigs_and_Lures%3A_Associating_Web_Queries_with_Structured_Entities.html">181 acl-2011-Jigs and Lures: Associating Web Queries with Structured Entities</a></p>
<p>Author: Patrick Pantel ; Ariel Fuxman</p><p>Abstract: We propose methods for estimating the probability that an entity from an entity database is associated with a web search query. Association is modeled using a query entity click graph, blending general query click logs with vertical query click logs. Smoothing techniques are proposed to address the inherent data sparsity in such graphs, including interpolation using a query synonymy model. A large-scale empirical analysis of the smoothing techniques, over a 2-year click graph collected from a commercial search engine, shows significant reductions in modeling error. The association models are then applied to the task of recommending products to web queries, by annotating queries with products from a large catalog and then mining query- product associations through web search session analysis. Experimental analysis shows that our smoothing techniques improve coverage while keeping precision stable, and overall, that our top-performing model affects 9% of general web queries with 94% precision.</p><p>4 0.69324154 <a title="36-lsi-4" href="./acl-2011-Search_in_the_Lost_Sense_of_%22Query%22%3A_Question_Formulation_in_Web_Search_Queries_and_its_Temporal_Changes.html">271 acl-2011-Search in the Lost Sense of "Query": Question Formulation in Web Search Queries and its Temporal Changes</a></p>
<p>Author: Bo Pang ; Ravi Kumar</p><p>Abstract: Web search is an information-seeking activity. Often times, this amounts to a user seeking answers to a question. However, queries, which encode user‚Äôs information need, are typically not expressed as full-length natural language sentences in particular, as questions. Rather, they consist of one or more text fragments. As humans become more searchengine-savvy, do natural-language questions still have a role to play in web search? Through a systematic, large-scale study, we find to our surprise that as time goes by, web users are more likely to use questions to express their search intent. ‚Äî</p><p>5 0.66806108 <a title="36-lsi-5" href="./acl-2011-A_Graph_Approach_to_Spelling_Correction_in_Domain-Centric_Search.html">13 acl-2011-A Graph Approach to Spelling Correction in Domain-Centric Search</a></p>
<p>Author: Zhuowei Bao ; Benny Kimelfeld ; Yunyao Li</p><p>Abstract: Spelling correction for keyword-search queries is challenging in restricted domains such as personal email (or desktop) search, due to the scarcity of query logs, and due to the specialized nature of the domain. For that task, this paper presents an algorithm that is based on statistics from the corpus data (rather than the query log). This algorithm, which employs a simple graph-based approach, can incorporate different types of data sources with different levels of reliability (e.g., email subject vs. email body), and can handle complex spelling errors like splitting and merging of words. An experimental study shows the superiority of the algorithm over existing alternatives in the email domain.</p><p>6 0.58157289 <a title="36-lsi-6" href="./acl-2011-Ranking_Class_Labels_Using_Query_Sessions.html">258 acl-2011-Ranking Class Labels Using Query Sessions</a></p>
<p>7 0.57861453 <a title="36-lsi-7" href="./acl-2011-Efficient_Online_Locality_Sensitive_Hashing_via_Reservoir_Counting.html">113 acl-2011-Efficient Online Locality Sensitive Hashing via Reservoir Counting</a></p>
<p>8 0.56452066 <a title="36-lsi-8" href="./acl-2011-Semi-Supervised_SimHash_for_Efficient_Document_Similarity_Search.html">276 acl-2011-Semi-Supervised SimHash for Efficient Document Similarity Search</a></p>
<p>9 0.56233186 <a title="36-lsi-9" href="./acl-2011-Fine-Grained_Class_Label_Markup_of_Search_Queries.html">137 acl-2011-Fine-Grained Class Label Markup of Search Queries</a></p>
<p>10 0.56224948 <a title="36-lsi-10" href="./acl-2011-Joint_Annotation_of_Search_Queries.html">182 acl-2011-Joint Annotation of Search Queries</a></p>
<p>11 0.55151957 <a title="36-lsi-11" href="./acl-2011-Piggyback%3A_Using_Search_Engines_for_Robust_Cross-Domain_Named_Entity_Recognition.html">246 acl-2011-Piggyback: Using Search Engines for Robust Cross-Domain Named Entity Recognition</a></p>
<p>12 0.54723799 <a title="36-lsi-12" href="./acl-2011-Creative_Language_Retrieval%3A_A_Robust_Hybrid_of_Information_Retrieval_and_Linguistic_Creativity.html">89 acl-2011-Creative Language Retrieval: A Robust Hybrid of Information Retrieval and Linguistic Creativity</a></p>
<p>13 0.54573226 <a title="36-lsi-13" href="./acl-2011-Predicting_Clicks_in_a_Vocabulary_Learning_System.html">248 acl-2011-Predicting Clicks in a Vocabulary Learning System</a></p>
<p>14 0.52847987 <a title="36-lsi-14" href="./acl-2011-A_Fast_and_Accurate_Method_for_Approximate_String_Search.html">11 acl-2011-A Fast and Accurate Method for Approximate String Search</a></p>
<p>15 0.51512241 <a title="36-lsi-15" href="./acl-2011-A_Speech-based_Just-in-Time_Retrieval_System_using_Semantic_Search.html">26 acl-2011-A Speech-based Just-in-Time Retrieval System using Semantic Search</a></p>
<p>16 0.50619507 <a title="36-lsi-16" href="./acl-2011-SystemT%3A_A_Declarative_Information_Extraction_System.html">291 acl-2011-SystemT: A Declarative Information Extraction System</a></p>
<p>17 0.49405736 <a title="36-lsi-17" href="./acl-2011-An_ERP-based_Brain-Computer_Interface_for_text_entry_using_Rapid_Serial_Visual_Presentation_and_Language_Modeling.html">35 acl-2011-An ERP-based Brain-Computer Interface for text entry using Rapid Serial Visual Presentation and Language Modeling</a></p>
<p>18 0.48694983 <a title="36-lsi-18" href="./acl-2011-K-means_Clustering_with_Feature_Hashing.html">189 acl-2011-K-means Clustering with Feature Hashing</a></p>
<p>19 0.48630783 <a title="36-lsi-19" href="./acl-2011-A_Large_Scale_Distributed_Syntactic%2C_Semantic_and_Lexical_Language_Model_for_Machine_Translation.html">17 acl-2011-A Large Scale Distributed Syntactic, Semantic and Lexical Language Model for Machine Translation</a></p>
<p>20 0.47514173 <a title="36-lsi-20" href="./acl-2011-Query_Weighting_for_Ranking_Model_Adaptation.html">256 acl-2011-Query Weighting for Ranking Model Adaptation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.031), (17, 0.055), (26, 0.077), (31, 0.01), (37, 0.088), (39, 0.03), (41, 0.095), (55, 0.044), (59, 0.045), (72, 0.034), (91, 0.051), (92, 0.227), (96, 0.109), (97, 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.78012717 <a title="36-lda-1" href="./acl-2011-An_Efficient_Indexer_for_Large_N-Gram_Corpora.html">36 acl-2011-An Efficient Indexer for Large N-Gram Corpora</a></p>
<p>Author: Hakan Ceylan ; Rada Mihalcea</p><p>Abstract: We introduce a new publicly available tool that implements efficient indexing and retrieval of large N-gram datasets, such as the Web1T 5-gram corpus. Our tool indexes the entire Web1T dataset with an index size of only 100 MB and performs a retrieval of any N-gram with a single disk access. With an increased index size of 420 MB and duplicate data, it also allows users to issue wild card queries provided that the wild cards in the query are contiguous. Furthermore, we also implement some of the smoothing algorithms that are designed specifically for large datasets and are shown to yield better language models than the traditional ones on the Web1T 5gram corpus (Yuret, 2008). We demonstrate the effectiveness of our tool and the smoothing algorithms on the English Lexical Substi- tution task by a simple implementation that gives considerable improvement over a basic language model.</p><p>2 0.76504987 <a title="36-lda-2" href="./acl-2011-An_Affect-Enriched_Dialogue_Act_Classification_Model_for_Task-Oriented_Dialogue.html">33 acl-2011-An Affect-Enriched Dialogue Act Classification Model for Task-Oriented Dialogue</a></p>
<p>Author: Kristy Boyer ; Joseph Grafsgaard ; Eun Young Ha ; Robert Phillips ; James Lester</p><p>Abstract: Dialogue act classification is a central challenge for dialogue systems. Although the importance of emotion in human dialogue is widely recognized, most dialogue act classification models make limited or no use of affective channels in dialogue act classification. This paper presents a novel affect-enriched dialogue act classifier for task-oriented dialogue that models facial expressions of users, in particular, facial expressions related to confusion. The findings indicate that the affectenriched classifiers perform significantly better for distinguishing user requests for feedback and grounding dialogue acts within textual dialogue. The results point to ways in which dialogue systems can effectively leverage affective channels to improve dialogue act classification. 1</p><p>3 0.74954981 <a title="36-lda-3" href="./acl-2011-Lexical_Normalisation_of_Short_Text_Messages%3A_Makn_Sens_a_%23twitter.html">208 acl-2011-Lexical Normalisation of Short Text Messages: Makn Sens a #twitter</a></p>
<p>Author: Bo Han ; Timothy Baldwin</p><p>Abstract: Twitter provides access to large volumes of data in real time, but is notoriously noisy, hampering its utility for NLP. In this paper, we target out-of-vocabulary words in short text messages and propose a method for identifying and normalising ill-formed words. Our method uses a classifier to detect ill-formed words, and generates correction candidates based on morphophonemic similarity. Both word similarity and context are then exploited to select the most probable correction candidate for the word. The proposed method doesn‚Äôt require any annotations, and achieves state-of-the-art performance over an SMS corpus and a novel dataset based on Twitter.</p><p>4 0.66209638 <a title="36-lda-4" href="./acl-2011-Fine-Grained_Class_Label_Markup_of_Search_Queries.html">137 acl-2011-Fine-Grained Class Label Markup of Search Queries</a></p>
<p>Author: Joseph Reisinger ; Marius Pasca</p><p>Abstract: We develop a novel approach to the semantic analysis of short text segments and demonstrate its utility on a large corpus of Web search queries. Extracting meaning from short text segments is difficult as there is little semantic redundancy between terms; hence methods based on shallow semantic analysis may fail to accurately estimate meaning. Furthermore search queries lack explicit syntax often used to determine intent in question answering. In this paper we propose a hybrid model of semantic analysis combining explicit class-label extraction with a latent class PCFG. This class-label correlation (CLC) model admits a robust parallel approximation, allowing it to scale to large amounts of query data. We demonstrate its performance in terms of (1) its predicted label accuracy on polysemous queries and (2) its ability to accurately chunk queries into base constituents.</p><p>5 0.6602037 <a title="36-lda-5" href="./acl-2011-Insertion%2C_Deletion%2C_or_Substitution%3F_Normalizing_Text_Messages_without_Pre-categorization_nor_Supervision.html">172 acl-2011-Insertion, Deletion, or Substitution? Normalizing Text Messages without Pre-categorization nor Supervision</a></p>
<p>Author: Fei Liu ; Fuliang Weng ; Bingqing Wang ; Yang Liu</p><p>Abstract: Most text message normalization approaches are based on supervised learning and rely on human labeled training data. In addition, the nonstandard words are often categorized into different types and specific models are designed to tackle each type. In this paper, we propose a unified letter transformation approach that requires neither pre-categorization nor human supervision. Our approach models the generation process from the dictionary words to nonstandard tokens under a sequence labeling framework, where each letter in the dictionary word can be retained, removed, or substituted by other letters/digits. To avoid the expensive and time consuming hand labeling process, we automatically collected a large set of noisy training pairs using a novel webbased approach and performed character-level . alignment for model training. Experiments on both Twitter and SMS messages show that our system significantly outperformed the stateof-the-art deletion-based abbreviation system and the jazzy spell checker (absolute accuracy gain of 21.69% and 18. 16% over jazzy spell checker on the two test sets respectively).</p><p>6 0.65475994 <a title="36-lda-6" href="./acl-2011-Faster_and_Smaller_N-Gram_Language_Models.html">135 acl-2011-Faster and Smaller N-Gram Language Models</a></p>
<p>7 0.63988924 <a title="36-lda-7" href="./acl-2011-Exact_Decoding_of_Syntactic_Translation_Models_through_Lagrangian_Relaxation.html">123 acl-2011-Exact Decoding of Syntactic Translation Models through Lagrangian Relaxation</a></p>
<p>8 0.63018328 <a title="36-lda-8" href="./acl-2011-Can_Document_Selection_Help_Semi-supervised_Learning%3F_A_Case_Study_On_Event_Extraction.html">65 acl-2011-Can Document Selection Help Semi-supervised Learning? A Case Study On Event Extraction</a></p>
<p>9 0.62704045 <a title="36-lda-9" href="./acl-2011-Translationese_and_Its_Dialects.html">311 acl-2011-Translationese and Its Dialects</a></p>
<p>10 0.62521011 <a title="36-lda-10" href="./acl-2011-Exploiting_Syntactico-Semantic_Structures_for_Relation_Extraction.html">126 acl-2011-Exploiting Syntactico-Semantic Structures for Relation Extraction</a></p>
<p>11 0.62510037 <a title="36-lda-11" href="./acl-2011-Web-Scale_Features_for_Full-Scale_Parsing.html">333 acl-2011-Web-Scale Features for Full-Scale Parsing</a></p>
<p>12 0.62100959 <a title="36-lda-12" href="./acl-2011-Large-Scale_Cross-Document_Coreference_Using_Distributed_Inference_and_Hierarchical_Models.html">196 acl-2011-Large-Scale Cross-Document Coreference Using Distributed Inference and Hierarchical Models</a></p>
<p>13 0.61997491 <a title="36-lda-13" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<p>14 0.6197654 <a title="36-lda-14" href="./acl-2011-Rare_Word_Translation_Extraction_from_Aligned_Comparable_Documents.html">259 acl-2011-Rare Word Translation Extraction from Aligned Comparable Documents</a></p>
<p>15 0.6189124 <a title="36-lda-15" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>16 0.61720055 <a title="36-lda-16" href="./acl-2011-Good_Seed_Makes_a_Good_Crop%3A_Accelerating_Active_Learning_Using_Language_Modeling.html">145 acl-2011-Good Seed Makes a Good Crop: Accelerating Active Learning Using Language Modeling</a></p>
<p>17 0.61585844 <a title="36-lda-17" href="./acl-2011-Piggyback%3A_Using_Search_Engines_for_Robust_Cross-Domain_Named_Entity_Recognition.html">246 acl-2011-Piggyback: Using Search Engines for Robust Cross-Domain Named Entity Recognition</a></p>
<p>18 0.61585021 <a title="36-lda-18" href="./acl-2011-Evaluating_the_Impact_of_Coder_Errors_on_Active_Learning.html">119 acl-2011-Evaluating the Impact of Coder Errors on Active Learning</a></p>
<p>19 0.61372316 <a title="36-lda-19" href="./acl-2011-Lexically-Triggered_Hidden_Markov_Models_for_Clinical_Document_Coding.html">209 acl-2011-Lexically-Triggered Hidden Markov Models for Clinical Document Coding</a></p>
<p>20 0.61180913 <a title="36-lda-20" href="./acl-2011-An_Error_Analysis_of_Relation_Extraction_in_Social_Media_Documents.html">40 acl-2011-An Error Analysis of Relation Extraction in Social Media Documents</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
