<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-331" href="#">acl2011-331</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</h1>
<br/><p>Source: <a title="acl-2011-331-pdf" href="http://aclweb.org/anthology//P/P11/P11-1135.pdf">pdf</a></p><p>Author: Shane Bergsma ; David Yarowsky ; Kenneth Church</p><p>Abstract: Resolving coordination ambiguity is a classic hard problem. This paper looks at coordination disambiguation in complex noun phrases (NPs). Parsers trained on the Penn Treebank are reporting impressive numbers these days, but they don’t do very well on this problem (79%). We explore systems trained using three types of corpora: (1) annotated (e.g. the Penn Treebank), (2) bitexts (e.g. Europarl), and (3) unannotated monolingual (e.g. Google N-grams). Size matters: (1) is a million words, (2) is potentially billions of words and (3) is potentially trillions of words. The unannotated monolingual data is helpful when the ambiguity can be resolved through associations among the lexical items. The bilingual data is helpful when the ambiguity can be resolved by the order of words in the translation. We train separate classifiers with monolingual and bilingual features and iteratively improve them via achieves data and pervised tations. co-training. The co-trained classifier close to 96% accuracy on Treebank makes 20% fewer errors than a susystem trained with Treebank anno-</p><p>Reference: <a title="acl-2011-331-reference" href="../acl2011_reference/acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Abstract Resolving coordination ambiguity is a classic hard problem. [sent-3, score-0.297]
</p><p>2 This paper looks at coordination disambiguation in complex noun phrases (NPs). [sent-4, score-0.207]
</p><p>3 The unannotated monolingual data is helpful when the ambiguity can be resolved through associations among the lexical items. [sent-14, score-0.443]
</p><p>4 The bilingual data is helpful when the ambiguity can be resolved by the order of words in the translation. [sent-15, score-0.357]
</p><p>5 We train separate classifiers with monolingual and bilingual features and iteratively improve  them via achieves data and pervised tations. [sent-16, score-0.598]
</p><p>6 Consider the pair: +ellipsis rocket\w1 and mortar\w2 attacks\h −ellipsis asbestos\w1 and polyvinyl\w2 chloride\h +ellipsis is about both rocket attacks and mortar attacks, unlike −ellipsis which is not about asbestos j hu . [sent-19, score-0.512]
</p><p>7 Natural Language Processing applications need to recognize NP ellipsis in order to make sense of new sentences. [sent-24, score-0.315]
</p><p>8 For example, if an Internet search engine is given the phrase rocket attacks as a query, it  should rank documents containing rocket and mortar attacks highly, even though rocket and attacks are not contiguous in the document. [sent-25, score-0.835]
</p><p>9 Furthermore, NPs with ellipsis often require a distinct type of reordering when translated into a foreign language. [sent-26, score-0.315]
</p><p>10 Since coordination is both complex and productive, parsers and machine translation (MT) systems cannot simply memorize the analysis of coordinate phrases from training text. [sent-27, score-0.515]
</p><p>11 We propose an approach to recognizing ellipsis that could benefit both MT and other NLP technology that relies on shallow or deep syntactic analysis. [sent-28, score-0.315]
</p><p>12 Errors in NP coordination typically account for the majority of parser coordination errors (Hogan, 2007). [sent-30, score-0.348]
</p><p>13 The information needed to resolve coordinate NP ambiguity cannot be derived from hand-annotated data, and we follow previous work in looking for new information sources to apply to this problem (Resnik, 1999; Nakov and Hearst, 2005; Rus et al. [sent-31, score-0.436]
</p><p>14 We first resolve coordinate NP ambiguity in a word-aligned parallel corpus. [sent-34, score-0.501]
</p><p>15 In bitexts, both monolingual and bilingual information can indicate NP  structure. [sent-35, score-0.444]
</p><p>16 We create separate classifiers using monolingual and bilingual feature views. [sent-36, score-0.589]
</p><p>17 c s 2o0ci1a1ti Aonss foocria Ctioomnp fourta Ctioomnaplu Ltaintigouniaslti Lcisn,g puaigsetsic 1s346–1355, initial labeled examples, we are able to train a highly accurate classifier using only monolingual features. [sent-40, score-0.396]
</p><p>18 The monolingual classifier can then be used both within and beyond the aligned bitext. [sent-41, score-0.339]
</p><p>19 In particular, it achieves close to 96% accuracy on both bitext data and on out-of-domain examples in the Treebank. [sent-42, score-0.278]
</p><p>20 We attempt to resolve the ambiguity in all tag sequences matching the expression: [DT|PRP$] (N. [sent-44, score-0.204]
</p><p>21 asbestos and polyvinyl chloride), or 2) The conjunction links something higher up in the parse tree, as in, “farmers are getting older\w1 athned younger\w2 people\h are rreelu gcettatnintg gto o tdaekre\ up farming. [sent-61, score-0.207]
</p><p>22 In addition, these parsers have only evaluated coordination resolution within base NPs, simplifying the task and rendering the aforementioned older/younger problem moot. [sent-76, score-0.326]
</p><p>23 Finally, these custom parsers have only used simple count features; for example, they have not used the paraphrases we describe below. [sent-77, score-0.262]
</p><p>24 3  Supervised Coordination Resolution  We adopt a discriminative approach to resolving coordinate NP ambiguity. [sent-78, score-0.274]
</p><p>25 For each unique coordinate NP in our corpus, we encode relevant information in a feature vector, x¯. [sent-79, score-0.276]
</p><p>26 We use ‘y = a1r’e as athileclass label for NPs with ellipsis and ‘y = 0’ for NPs without. [sent-85, score-0.315]
</p><p>27 The more features we use, the more labeled data we need, since for linear classifiers, the number of examples needed to reach optimum performance is at most linear in the  Table 1: Monolingual and bilingual evidence for ellipsis or lack-of-ellipsis in coordination of [w1 and w2 h] phrases. [sent-95, score-0.899]
</p><p>28 We now describe the particular monolingual and bilingual information we use for this problem. [sent-99, score-0.444]
</p><p>29 Consider the phrase dairy and meat production (Table 1). [sent-105, score-0.459]
</p><p>30 A high count in raw text for the paraphrase “production of dairy and meat” implies ellipsis in the original example. [sent-106, score-0.623]
</p><p>31 pIhnr our experiments, at least 20% of examples have non-zero counts for a 1348 5-gram pattern, while over 70% of examples have counts for a 4-gram pattern. [sent-115, score-0.36]
</p><p>32 seeing asbestos , and polyvinyl chloride or the asbestos and the polyvinyl chloride suggests no ellipsis. [sent-125, score-0.62]
</p><p>33 Finally, patterns involving prepositions look for explicit paraphrasing of the nominal relations; the presence of “h PREP w1 and w2” in a corpus would suggest ellipsis in the original NP. [sent-128, score-0.375]
</p><p>34 We use log-counts as the feature value, and use a separate binary feature to indicate if a particular count is zero. [sent-130, score-0.229]
</p><p>35 Our classifier learns, for exam1349  Table 3: Example of actual instantiated feature vectors for dairy and meat production (in label:value format). [sent-150, score-0.626]
</p><p>36 Example Table 3 provides part of the actual instantiated monolingual feature vector for dairy and meat production. [sent-153, score-0.705]
</p><p>37 Note the count features have logarithmic values, while only the non-zero binary features are included. [sent-154, score-0.207]
</p><p>38 2 Bilingual Features The above features represent the best of the information available to a coordinate NP classifier when operating on an arbitrary text. [sent-166, score-0.374]
</p><p>39 We consider the case where we seek to predict coordinate structure in parallel text: i. [sent-168, score-0.297]
</p><p>40 Given a word-aligned parallel corpus, we can see how the different types of coordinate NPs are translated in the target languages. [sent-172, score-0.297]
</p><p>41 In Romance languages, examples with ellipsis, such as dairy and meat production (Table 1), tend to correspond to translations with the head in the first position, e. [sent-173, score-0.565]
</p><p>42 Another clue for ellipsis is the presence of a dangling hyphen, as in the Finnish maidon- ja lihantuotantoon. [sent-179, score-0.315]
</p><p>43 In addition to language-specific clues, a translation may resolve an ambiguity by paraphrasing the example in the same way it may be paraphrased in English. [sent-181, score-0.234]
</p><p>44 , we see hard and  soft drugs translated into Spanish as drogas blandas y drogas duras with the head, drogas, repeated (akin to soft drugs and hard drugs in English). [sent-184, score-0.274]
</p><p>45 One could imagine manually defining the relationship between English NP coordination and the patterns in each language, but this would need to be repeated for each language pair, and would likely miss many useful patterns. [sent-185, score-0.204]
</p><p>46 For each occurrence of a coordinate NP in a wordaligned bitext, we inspect the alignments and determine the mapping of w1, w2 and h. [sent-187, score-0.276]
</p><p>47 Recall that each of our examples represents all the occurrences of a unique coordinate NP in a corpus. [sent-188, score-0.338]
</p><p>48 The notation indicates that, for a given coordinate NP, we count the frequency of each transla1350  C h sodipremtadlp(nw 1 ,w 2 ,h )i,hL A N G i  Table 4: Real-valued bilingual feature templates. [sent-193, score-0.53]
</p><p>49 Letting ‘*’ stand for the wildcard, the detailed patterns for the translations of dairy and meat production in Table 1 would be [h w1 * w2] (Spanish), [w1- * w2h] (Finnish) and [h * * w1 * * w2] (French). [sent-201, score-0.489]
</p><p>50 Example Table 3 also provides part of the actual instantiated bilingual feature vector for dairy and meat production. [sent-209, score-0.649]
</p><p>51 4  Bilingual Co-training  We exploit the orthogonality of the monolingual and bilingual features using semi-supervised learning. [sent-210, score-0.497]
</p><p>52 If we had enough training data, a good  classifier  could be trained using either monolingual  or bilingual  features  on their own. [sent-212, score-0.586]
</p><p>53 iterations), um taenxdt, ub (size smaller unlabeled pools), nm and nb (num. [sent-214, score-0.285]
</p><p>54 for classifier training Create Lm ← L Create Lb ← ←L L Create a pool Um by choosing um examples randomly from U. [sent-216, score-0.315]
</p><p>55 Create a pool Ub by choosing ub examples randomly from U. [sent-217, score-0.274]
</p><p>56 We use a logistic regression classifier for hm and hb. [sent-225, score-0.261]
</p><p>57 The hyperparameters of the algorithm are 1) k, the number of iterations, 2) um and ub, the size of the smaller unlabeled pools, 3) nm and nb, the number of new labeled examples to include at each iteration, and 4) the regularization parameter of the logistic regression classifier. [sent-227, score-0.362]
</p><p>58 One of our key goals is to 1351 produce an accurate classifier that uses only monolingual features, since only this classifier can be applied to arbitrary monolingual text. [sent-231, score-0.678]
</p><p>59 We thus break the symmetry in the original algorithm and allow hb  to label more examples for hm than vice versa, so that hm will improve faster. [sent-232, score-0.348]
</p><p>60 This is desirable because we don’t have unlimited unlabeled examples to draw from, only those found in our parallel text. [sent-233, score-0.204]
</p><p>61 5  Data  Web-scale text data is used for monolingual feature counts, parallel text is used for classifier co-training, and labeled data is used for training and evaluation. [sent-234, score-0.505]
</p><p>62 1 Word-aligned English-Foreign bitexts are created using the Berkeley aligner. [sent-242, score-0.227]
</p><p>63 The English portions of all bitexts are part-of-speech tagged with CRFTagger (Phan, 2006). [sent-244, score-0.227]
</p><p>64 94K unique coordinate NPs and their translations are then extracted. [sent-245, score-0.232]
</p><p>65 Labeled Data For experiments within the parallel text, we manually labeled 1320 of the 94K coordinate NP examples. [sent-246, score-0.354]
</p><p>66 We use 605 examples to set development parameters, 607 examples as held-out test data, and 2, 10 or 100 examples for training. [sent-247, score-0.318]
</p><p>67 We collect all coordinate NP sequences matching our pattern and collapse them into a single example. [sent-249, score-0.293]
</p><p>68 In only one case did the same coordinate NP  have different labels in different occurrences; this was clearly an error and resolved accordingly. [sent-251, score-0.272]
</p><p>69 We collected 1777 coordinate NPs in total, and divided them into 777 examples for training, 500 for development and 500 as a final held-out test set. [sent-252, score-0.338]
</p><p>70 Tag-Triple is therefore essentially a discriminative, unlexicalized parser for our coordinate NPs. [sent-256, score-0.232]
</p><p>71 At each iteration, i, classifier hm annotates 50 new examples for training hb, from a pool of 750 examples, while hb annotates 50 ∗ inew examples for hm, from a pool oafn 7n5ot0a ∗ is examples. [sent-262, score-0.54]
</p><p>72 We therefore set k separately for each, stopping around 16 iterations for the combined, 51 for the monolingual, and 57 for the bilingual classifier. [sent-274, score-0.228]
</p><p>73 This shows that better monolingual features are very important, but semisupervised training can also make a big difference. [sent-286, score-0.303]
</p><p>74 Of course, the parsers performed very poorly on ellipsis involving two nouns (partly because NP structure is absent from their training corpora (see § 2 and also Vadas and Curran (2008)), tbruati nnineigthe cro repxocreae (dseede 8 §8 %2 on adjective or amnidxe Cd pairs (e2it0h0er8. [sent-289, score-0.458]
</p><p>75 r 7609acy365∆914-% % Table 6: Net benefits of bilingual features and co-training on Bitext data, 100-training-example setting. [sent-292, score-0.247]
</p><p>76 With bilingual features and co-training together, we achieve 96. [sent-296, score-0.247]
</p><p>77 This combined system could be used to very accurately resolve coordinate ambiguity in parallel data prior to training an MT system. [sent-298, score-0.501]
</p><p>78 8  WSJ Experiments  While we can now accurately resolve coordinate NP ambiguity in parallel text, it would be even better if this accuracy carried over to new domains, where bilingual features are not available. [sent-299, score-0.748]
</p><p>79 We test the robustness of our co-trained monolingual classifier by  evaluating it on our labeled WSJ data. [sent-300, score-0.396]
</p><p>80 We can take advantage of the plentiful labeled examples to also test how our co-trained system compares to supervised systems trained with in1353  System Nakov & Hearst  STertaining# NWounSJs AccA. [sent-302, score-0.213]
</p><p>81 We compare these systems to Tag-Triple and also to a supervised system trained on the WSJ using only our monolingual features (MonoWSJ). [sent-318, score-0.353]
</p><p>82 The (out-of-domain) bitext co-trained system is the best system on the WSJ data, both on just the examples where w1 and w2 are nouns (Nouns), and on all examples (All) (Table 7). [sent-319, score-0.418]
</p><p>83 05) and also exceeds the WSJ-trained system using monolingual features (p<0. [sent-322, score-0.303]
</p><p>84 Related 4Nakov and Hearst (2005) use an unsupervised algorithm that predicts ellipsis on the basis of a majority vote over a number of pattern counts and established heuristics. [sent-331, score-0.45]
</p><p>85 (2010) uses a supervised classifier to predict bracketings; their count and binary features are a strict subset of the features used in our Monolingual classifier. [sent-333, score-0.346]
</p><p>86 , 2005), and jointly parsing the two sides of a bitext by leveraging the alignments during training and testing (Smith and Smith, 2004; Burkett and Klein, 2008) or just during training (Snyder et al. [sent-337, score-0.246]
</p><p>87 None of this work has focused on coordination, nor has it combined bitexts with web-scale monolingual information. [sent-339, score-0.477]
</p><p>88 ” Kuhn (2004) used alignments across several Europarl bitexts to devise rules for identifying parse distituents. [sent-343, score-0.271]
</p><p>89 Bannard and Callison-Burch (2005) used multiple bitexts as part of a system for extracting paraphrases. [sent-344, score-0.227]
</p><p>90 Our co-training algorithm is well suited to using multiple bitexts because it automatically learns the value of alignment information in each language. [sent-345, score-0.227]
</p><p>91 In their work, the bilingual view encodes the per-instance agreement between monolingual predictors in two languages, while our bilingual view encodes the alignment and target text together, across multiple instances and languages. [sent-349, score-0.638]
</p><p>92 Our monolingual model is most similar to previous work using counts from web-scale text, both  for resolving coordination ambiguity (Nakov and Hearst, 2005; Rus et al. [sent-352, score-0.663]
</p><p>93 Adding new fea1354 tures without adding new training data is often problematic, but is promising in our framework, since the bitexts provide so much indirect supervision. [sent-358, score-0.227]
</p><p>94 10  Conclusion  Resolving coordination ambiguity is hard. [sent-359, score-0.297]
</p><p>95 In this work, we show how to take advantage of billions of words of bitexts and trillions of words of unlabeled monolingual text. [sent-365, score-0.544]
</p><p>96 Larger corpora make it possible to use associations among lexical items (compare dairy production vs. [sent-366, score-0.33]
</p><p>97 asbestos chloride) and precise paraphrases (production of dairy and meat). [sent-367, score-0.424]
</p><p>98 Bitexts are helpful when the ambiguity can be resolved by some feature in another language (such as word order). [sent-368, score-0.207]
</p><p>99 Using bilingual Chinese-English word alignments to resolve PP-  attachment ambiguity in English. [sent-427, score-0.442]
</p><p>100 Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. [sent-556, score-0.289]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ellipsis', 0.315), ('monolingual', 0.25), ('dairy', 0.248), ('coordinate', 0.232), ('bitexts', 0.227), ('bilingual', 0.194), ('coordination', 0.174), ('bitext', 0.172), ('np', 0.136), ('vadas', 0.134), ('meat', 0.129), ('nakov', 0.129), ('pitler', 0.129), ('ub', 0.127), ('rocket', 0.127), ('asbestos', 0.124), ('ambiguity', 0.123), ('attacks', 0.117), ('parsers', 0.109), ('examples', 0.106), ('chloride', 0.103), ('mortar', 0.103), ('nps', 0.099), ('wsj', 0.098), ('hearst', 0.098), ('conjoined', 0.09), ('classifier', 0.089), ('hm', 0.085), ('polyvinyl', 0.083), ('production', 0.082), ('curran', 0.081), ('resolve', 0.081), ('um', 0.079), ('blum', 0.077), ('counts', 0.074), ('hb', 0.072), ('bergsma', 0.069), ('parallel', 0.065), ('burkett', 0.063), ('drogas', 0.062), ('pattern', 0.061), ('classifiers', 0.061), ('europarl', 0.06), ('yarowsky', 0.06), ('rus', 0.06), ('count', 0.06), ('labeled', 0.057), ('pools', 0.055), ('penn', 0.054), ('treebank', 0.054), ('features', 0.053), ('shane', 0.053), ('paraphrases', 0.052), ('drugs', 0.05), ('supervised', 0.05), ('logistic', 0.049), ('dagan', 0.047), ('wildcards', 0.047), ('nb', 0.046), ('mitchell', 0.046), ('alignments', 0.044), ('feature', 0.044), ('kenneth', 0.043), ('resolution', 0.043), ('resolving', 0.042), ('binary', 0.041), ('hu', 0.041), ('hogan', 0.041), ('minipar', 0.041), ('monowsj', 0.041), ('schwarck', 0.041), ('custom', 0.041), ('finnish', 0.041), ('pool', 0.041), ('separate', 0.04), ('spanish', 0.04), ('resolved', 0.04), ('resnik', 0.039), ('lb', 0.039), ('regression', 0.038), ('emily', 0.036), ('crftagger', 0.036), ('sbergsma', 0.036), ('iteration', 0.035), ('dekang', 0.034), ('nouns', 0.034), ('instantiated', 0.034), ('iterations', 0.034), ('trillions', 0.034), ('unlabeled', 0.033), ('noun', 0.033), ('pr', 0.032), ('hindle', 0.031), ('itai', 0.031), ('annotations', 0.031), ('unannotated', 0.03), ('parsing', 0.03), ('patterns', 0.03), ('fossum', 0.03), ('paraphrasing', 0.03)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999952 <a title="331-tfidf-1" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<p>Author: Shane Bergsma ; David Yarowsky ; Kenneth Church</p><p>Abstract: Resolving coordination ambiguity is a classic hard problem. This paper looks at coordination disambiguation in complex noun phrases (NPs). Parsers trained on the Penn Treebank are reporting impressive numbers these days, but they don’t do very well on this problem (79%). We explore systems trained using three types of corpora: (1) annotated (e.g. the Penn Treebank), (2) bitexts (e.g. Europarl), and (3) unannotated monolingual (e.g. Google N-grams). Size matters: (1) is a million words, (2) is potentially billions of words and (3) is potentially trillions of words. The unannotated monolingual data is helpful when the ambiguity can be resolved through associations among the lexical items. The bilingual data is helpful when the ambiguity can be resolved by the order of words in the translation. We train separate classifiers with monolingual and bilingual features and iteratively improve them via achieves data and pervised tations. co-training. The co-trained classifier close to 96% accuracy on Treebank makes 20% fewer errors than a susystem trained with Treebank anno-</p><p>2 0.21162733 <a title="331-tfidf-2" href="./acl-2011-Web-Scale_Features_for_Full-Scale_Parsing.html">333 acl-2011-Web-Scale Features for Full-Scale Parsing</a></p>
<p>Author: Mohit Bansal ; Dan Klein</p><p>Abstract: Counts from large corpora (like the web) can be powerful syntactic cues. Past work has used web counts to help resolve isolated ambiguities, such as binary noun-verb PP attachments and noun compound bracketings. In this work, we first present a method for generating web count features that address the full range of syntactic attachments. These features encode both surface evidence of lexical affinities as well as paraphrase-based cues to syntactic structure. We then integrate our features into full-scale dependency and constituent parsers. We show relative error reductions of7.0% over the second-order dependency parser of McDonald and Pereira (2006), 9.2% over the constituent parser of Petrov et al. (2006), and 3.4% over a non-local constituent reranker.</p><p>3 0.17668331 <a title="331-tfidf-3" href="./acl-2011-Joint_Bilingual_Sentiment_Classification_with_Unlabeled_Parallel_Corpora.html">183 acl-2011-Joint Bilingual Sentiment Classification with Unlabeled Parallel Corpora</a></p>
<p>Author: Bin Lu ; Chenhao Tan ; Claire Cardie ; Benjamin K. Tsou</p><p>Abstract: Most previous work on multilingual sentiment analysis has focused on methods to adapt sentiment resources from resource-rich languages to resource-poor languages. We present a novel approach for joint bilingual sentiment classification at the sentence level that augments available labeled data in each language with unlabeled parallel data. We rely on the intuition that the sentiment labels for parallel sentences should be similar and present a model that jointly learns improved monolingual sentiment classifiers for each language. Experiments on multiple data sets show that the proposed approach (1) outperforms the monolingual baselines, significantly improving the accuracy for both languages by 3.44%-8. 12%; (2) outperforms two standard approaches for leveraging unlabeled data; and (3) produces (albeit smaller) performance gains when employing pseudo-parallel data from machine translation engines. 1</p><p>4 0.154477 <a title="331-tfidf-4" href="./acl-2011-Effects_of_Noun_Phrase_Bracketing_in_Dependency_Parsing_and_Machine_Translation.html">111 acl-2011-Effects of Noun Phrase Bracketing in Dependency Parsing and Machine Translation</a></p>
<p>Author: Nathan Green</p><p>Abstract: Flat noun phrase structure was, up until recently, the standard in annotation for the Penn Treebanks. With the recent addition of internal noun phrase annotation, dependency parsing and applications down the NLP pipeline are likely affected. Some machine translation systems, such as TectoMT, use deep syntax as a language transfer layer. It is proposed that changes to the noun phrase dependency parse will have a cascading effect down the NLP pipeline and in the end, improve machine translation output, even with a reduction in parser accuracy that the noun phrase structure might cause. This paper examines this noun phrase structure’s effect on dependency parsing, in English, with a maximum spanning tree parser and shows a 2.43%, 0.23 Bleu score, improvement for English to Czech machine translation. .</p><p>5 0.1330542 <a title="331-tfidf-5" href="./acl-2011-Exploiting_Web-Derived_Selectional_Preference_to_Improve_Statistical_Dependency_Parsing.html">127 acl-2011-Exploiting Web-Derived Selectional Preference to Improve Statistical Dependency Parsing</a></p>
<p>Author: Guangyou Zhou ; Jun Zhao ; Kang Liu ; Li Cai</p><p>Abstract: In this paper, we present a novel approach which incorporates the web-derived selectional preferences to improve statistical dependency parsing. Conventional selectional preference learning methods have usually focused on word-to-class relations, e.g., a verb selects as its subject a given nominal class. This paper extends previous work to wordto-word selectional preferences by using webscale data. Experiments show that web-scale data improves statistical dependency parsing, particularly for long dependency relationships. There is no data like more data, performance improves log-linearly with the number of parameters (unique N-grams). More importantly, when operating on new domains, we show that using web-derived selectional preferences is essential for achieving robust performance.</p><p>6 0.12448087 <a title="331-tfidf-6" href="./acl-2011-Using_Bilingual_Parallel_Corpora_for_Cross-Lingual_Textual_Entailment.html">327 acl-2011-Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment</a></p>
<p>7 0.1158171 <a title="331-tfidf-7" href="./acl-2011-ParaSense_or_How_to_Use_Parallel_Corpora_for_Word_Sense_Disambiguation.html">240 acl-2011-ParaSense or How to Use Parallel Corpora for Word Sense Disambiguation</a></p>
<p>8 0.11324304 <a title="331-tfidf-8" href="./acl-2011-Unsupervised_Part-of-Speech_Tagging_with_Bilingual_Graph-Based_Projections.html">323 acl-2011-Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</a></p>
<p>9 0.10743405 <a title="331-tfidf-9" href="./acl-2011-Together_We_Can%3A_Bilingual_Bootstrapping_for_WSD.html">304 acl-2011-Together We Can: Bilingual Bootstrapping for WSD</a></p>
<p>10 0.10396255 <a title="331-tfidf-10" href="./acl-2011-Rare_Word_Translation_Extraction_from_Aligned_Comparable_Documents.html">259 acl-2011-Rare Word Translation Extraction from Aligned Comparable Documents</a></p>
<p>11 0.10246957 <a title="331-tfidf-11" href="./acl-2011-Clustering_Comparable_Corpora_For_Bilingual_Lexicon_Extraction.html">70 acl-2011-Clustering Comparable Corpora For Bilingual Lexicon Extraction</a></p>
<p>12 0.086186349 <a title="331-tfidf-12" href="./acl-2011-Semi-Supervised_Modeling_for_Prenominal_Modifier_Ordering.html">275 acl-2011-Semi-Supervised Modeling for Prenominal Modifier Ordering</a></p>
<p>13 0.085189618 <a title="331-tfidf-13" href="./acl-2011-Engkoo%3A_Mining_the_Web_for_Language_Learning.html">115 acl-2011-Engkoo: Mining the Web for Language Learning</a></p>
<p>14 0.084812306 <a title="331-tfidf-14" href="./acl-2011-An_Empirical_Evaluation_of_Data-Driven_Paraphrase_Generation_Techniques.html">37 acl-2011-An Empirical Evaluation of Data-Driven Paraphrase Generation Techniques</a></p>
<p>15 0.081558846 <a title="331-tfidf-15" href="./acl-2011-From_Bilingual_Dictionaries_to_Interlingual_Document_Representations.html">139 acl-2011-From Bilingual Dictionaries to Interlingual Document Representations</a></p>
<p>16 0.081444398 <a title="331-tfidf-16" href="./acl-2011-Monolingual_Alignment_by_Edit_Rate_Computation_on_Sentential_Paraphrase_Pairs.html">225 acl-2011-Monolingual Alignment by Edit Rate Computation on Sentential Paraphrase Pairs</a></p>
<p>17 0.08041881 <a title="331-tfidf-17" href="./acl-2011-Collecting_Highly_Parallel_Data_for_Paraphrase_Evaluation.html">72 acl-2011-Collecting Highly Parallel Data for Paraphrase Evaluation</a></p>
<p>18 0.080082424 <a title="331-tfidf-18" href="./acl-2011-Hypothesis_Mixture_Decoding_for_Statistical_Machine_Translation.html">155 acl-2011-Hypothesis Mixture Decoding for Statistical Machine Translation</a></p>
<p>19 0.079206236 <a title="331-tfidf-19" href="./acl-2011-An_exponential_translation_model_for_target_language_morphology.html">44 acl-2011-An exponential translation model for target language morphology</a></p>
<p>20 0.078695126 <a title="331-tfidf-20" href="./acl-2011-Domain_Adaptation_for_Machine_Translation_by_Mining_Unseen_Words.html">104 acl-2011-Domain Adaptation for Machine Translation by Mining Unseen Words</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.241), (1, -0.053), (2, -0.005), (3, -0.056), (4, 0.007), (5, -0.015), (6, 0.14), (7, 0.004), (8, 0.019), (9, -0.077), (10, 0.04), (11, 0.012), (12, 0.057), (13, -0.054), (14, 0.065), (15, 0.038), (16, -0.031), (17, 0.088), (18, 0.042), (19, -0.038), (20, -0.041), (21, -0.072), (22, 0.036), (23, 0.1), (24, 0.01), (25, 0.08), (26, -0.024), (27, 0.095), (28, 0.067), (29, -0.103), (30, 0.137), (31, -0.024), (32, 0.029), (33, -0.11), (34, 0.02), (35, 0.044), (36, 0.041), (37, -0.066), (38, -0.047), (39, 0.048), (40, -0.02), (41, 0.117), (42, 0.033), (43, -0.114), (44, 0.049), (45, -0.002), (46, 0.009), (47, 0.018), (48, 0.014), (49, 0.056)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94586045 <a title="331-lsi-1" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<p>Author: Shane Bergsma ; David Yarowsky ; Kenneth Church</p><p>Abstract: Resolving coordination ambiguity is a classic hard problem. This paper looks at coordination disambiguation in complex noun phrases (NPs). Parsers trained on the Penn Treebank are reporting impressive numbers these days, but they don’t do very well on this problem (79%). We explore systems trained using three types of corpora: (1) annotated (e.g. the Penn Treebank), (2) bitexts (e.g. Europarl), and (3) unannotated monolingual (e.g. Google N-grams). Size matters: (1) is a million words, (2) is potentially billions of words and (3) is potentially trillions of words. The unannotated monolingual data is helpful when the ambiguity can be resolved through associations among the lexical items. The bilingual data is helpful when the ambiguity can be resolved by the order of words in the translation. We train separate classifiers with monolingual and bilingual features and iteratively improve them via achieves data and pervised tations. co-training. The co-trained classifier close to 96% accuracy on Treebank makes 20% fewer errors than a susystem trained with Treebank anno-</p><p>2 0.66516322 <a title="331-lsi-2" href="./acl-2011-Clustering_Comparable_Corpora_For_Bilingual_Lexicon_Extraction.html">70 acl-2011-Clustering Comparable Corpora For Bilingual Lexicon Extraction</a></p>
<p>Author: Bo Li ; Eric Gaussier ; Akiko Aizawa</p><p>Abstract: We study in this paper the problem of enhancing the comparability of bilingual corpora in order to improve the quality of bilingual lexicons extracted from comparable corpora. We introduce a clustering-based approach for enhancing corpus comparability which exploits the homogeneity feature of the corpus, and finally preserves most of the vocabulary of the original corpus. Our experiments illustrate the well-foundedness of this method and show that the bilingual lexicons obtained from the homogeneous corpus are of better quality than the lexicons obtained with previous approaches.</p><p>3 0.64248484 <a title="331-lsi-3" href="./acl-2011-Web-Scale_Features_for_Full-Scale_Parsing.html">333 acl-2011-Web-Scale Features for Full-Scale Parsing</a></p>
<p>Author: Mohit Bansal ; Dan Klein</p><p>Abstract: Counts from large corpora (like the web) can be powerful syntactic cues. Past work has used web counts to help resolve isolated ambiguities, such as binary noun-verb PP attachments and noun compound bracketings. In this work, we first present a method for generating web count features that address the full range of syntactic attachments. These features encode both surface evidence of lexical affinities as well as paraphrase-based cues to syntactic structure. We then integrate our features into full-scale dependency and constituent parsers. We show relative error reductions of7.0% over the second-order dependency parser of McDonald and Pereira (2006), 9.2% over the constituent parser of Petrov et al. (2006), and 3.4% over a non-local constituent reranker.</p><p>4 0.64197677 <a title="331-lsi-4" href="./acl-2011-Unsupervised_Part-of-Speech_Tagging_with_Bilingual_Graph-Based_Projections.html">323 acl-2011-Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</a></p>
<p>Author: Dipanjan Das ; Slav Petrov</p><p>Abstract: We describe a novel approach for inducing unsupervised part-of-speech taggers for languages that have no labeled training data, but have translated text in a resource-rich language. Our method does not assume any knowledge about the target language (in particular no tagging dictionary is assumed), making it applicable to a wide array of resource-poor languages. We use graph-based label propagation for cross-lingual knowledge transfer and use the projected labels as features in an unsupervised model (BergKirkpatrick et al., 2010). Across eight European languages, our approach results in an average absolute improvement of 10.4% over a state-of-the-art baseline, and 16.7% over vanilla hidden Markov models induced with the Expectation Maximization algorithm.</p><p>5 0.62776262 <a title="331-lsi-5" href="./acl-2011-Rare_Word_Translation_Extraction_from_Aligned_Comparable_Documents.html">259 acl-2011-Rare Word Translation Extraction from Aligned Comparable Documents</a></p>
<p>Author: Emmanuel Prochasson ; Pascale Fung</p><p>Abstract: We present a first known result of high precision rare word bilingual extraction from comparable corpora, using aligned comparable documents and supervised classification. We incorporate two features, a context-vector similarity and a co-occurrence model between words in aligned documents in a machine learning approach. We test our hypothesis on different pairs of languages and corpora. We obtain very high F-Measure between 80% and 98% for recognizing and extracting correct translations for rare terms (from 1to 5 occurrences). Moreover, we show that our system can be trained on a pair of languages and test on a different pair of languages, obtaining a F-Measure of 77% for the classification of Chinese-English translations using a training corpus of Spanish-French. Our method is therefore even potentially applicable to low resources languages without training data.</p><p>6 0.61547798 <a title="331-lsi-6" href="./acl-2011-Translationese_and_Its_Dialects.html">311 acl-2011-Translationese and Its Dialects</a></p>
<p>7 0.60560673 <a title="331-lsi-7" href="./acl-2011-I_Thou_Thee%2C_Thou_Traitor%3A_Predicting_Formal_vs._Informal_Address_in_English_Literature.html">157 acl-2011-I Thou Thee, Thou Traitor: Predicting Formal vs. Informal Address in English Literature</a></p>
<p>8 0.593153 <a title="331-lsi-8" href="./acl-2011-Joint_Bilingual_Sentiment_Classification_with_Unlabeled_Parallel_Corpora.html">183 acl-2011-Joint Bilingual Sentiment Classification with Unlabeled Parallel Corpora</a></p>
<p>9 0.59086823 <a title="331-lsi-9" href="./acl-2011-That%27s_What_She_Said%3A_Double_Entendre_Identification.html">297 acl-2011-That's What She Said: Double Entendre Identification</a></p>
<p>10 0.58977008 <a title="331-lsi-10" href="./acl-2011-Together_We_Can%3A_Bilingual_Bootstrapping_for_WSD.html">304 acl-2011-Together We Can: Bilingual Bootstrapping for WSD</a></p>
<p>11 0.58727515 <a title="331-lsi-11" href="./acl-2011-Engkoo%3A_Mining_the_Web_for_Language_Learning.html">115 acl-2011-Engkoo: Mining the Web for Language Learning</a></p>
<p>12 0.58066154 <a title="331-lsi-12" href="./acl-2011-ParaSense_or_How_to_Use_Parallel_Corpora_for_Word_Sense_Disambiguation.html">240 acl-2011-ParaSense or How to Use Parallel Corpora for Word Sense Disambiguation</a></p>
<p>13 0.57958066 <a title="331-lsi-13" href="./acl-2011-Data_point_selection_for_cross-language_adaptation_of_dependency_parsers.html">92 acl-2011-Data point selection for cross-language adaptation of dependency parsers</a></p>
<p>14 0.57924342 <a title="331-lsi-14" href="./acl-2011-Semi-supervised_condensed_nearest_neighbor_for_part-of-speech_tagging.html">278 acl-2011-Semi-supervised condensed nearest neighbor for part-of-speech tagging</a></p>
<p>15 0.56339282 <a title="331-lsi-15" href="./acl-2011-Exploiting_Web-Derived_Selectional_Preference_to_Improve_Statistical_Dependency_Parsing.html">127 acl-2011-Exploiting Web-Derived Selectional Preference to Improve Statistical Dependency Parsing</a></p>
<p>16 0.55829179 <a title="331-lsi-16" href="./acl-2011-Using_Bilingual_Parallel_Corpora_for_Cross-Lingual_Textual_Entailment.html">327 acl-2011-Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment</a></p>
<p>17 0.54223949 <a title="331-lsi-17" href="./acl-2011-An_exponential_translation_model_for_target_language_morphology.html">44 acl-2011-An exponential translation model for target language morphology</a></p>
<p>18 0.53921932 <a title="331-lsi-18" href="./acl-2011-Effects_of_Noun_Phrase_Bracketing_in_Dependency_Parsing_and_Machine_Translation.html">111 acl-2011-Effects of Noun Phrase Bracketing in Dependency Parsing and Machine Translation</a></p>
<p>19 0.53792369 <a title="331-lsi-19" href="./acl-2011-Better_Automatic_Treebank_Conversion_Using_A_Feature-Based_Approach.html">59 acl-2011-Better Automatic Treebank Conversion Using A Feature-Based Approach</a></p>
<p>20 0.53690034 <a title="331-lsi-20" href="./acl-2011-From_Bilingual_Dictionaries_to_Interlingual_Document_Representations.html">139 acl-2011-From Bilingual Dictionaries to Interlingual Document Representations</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.022), (17, 0.066), (26, 0.075), (31, 0.012), (37, 0.123), (38, 0.198), (39, 0.065), (41, 0.054), (53, 0.04), (55, 0.03), (59, 0.035), (72, 0.033), (91, 0.043), (96, 0.105), (97, 0.01), (98, 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.80878711 <a title="331-lda-1" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<p>Author: Shane Bergsma ; David Yarowsky ; Kenneth Church</p><p>Abstract: Resolving coordination ambiguity is a classic hard problem. This paper looks at coordination disambiguation in complex noun phrases (NPs). Parsers trained on the Penn Treebank are reporting impressive numbers these days, but they don’t do very well on this problem (79%). We explore systems trained using three types of corpora: (1) annotated (e.g. the Penn Treebank), (2) bitexts (e.g. Europarl), and (3) unannotated monolingual (e.g. Google N-grams). Size matters: (1) is a million words, (2) is potentially billions of words and (3) is potentially trillions of words. The unannotated monolingual data is helpful when the ambiguity can be resolved through associations among the lexical items. The bilingual data is helpful when the ambiguity can be resolved by the order of words in the translation. We train separate classifiers with monolingual and bilingual features and iteratively improve them via achieves data and pervised tations. co-training. The co-trained classifier close to 96% accuracy on Treebank makes 20% fewer errors than a susystem trained with Treebank anno-</p><p>2 0.7501353 <a title="331-lda-2" href="./acl-2011-A_Pronoun_Anaphora_Resolution_System_based_on_Factorial_Hidden_Markov_Models.html">23 acl-2011-A Pronoun Anaphora Resolution System based on Factorial Hidden Markov Models</a></p>
<p>Author: Dingcheng Li ; Tim Miller ; William Schuler</p><p>Abstract: and Wellner, This paper presents a supervised pronoun anaphora resolution system based on factorial hidden Markov models (FHMMs). The basic idea is that the hidden states of FHMMs are an explicit short-term memory with an antecedent buffer containing recently described referents. Thus an observed pronoun can find its antecedent from the hidden buffer, or in terms of a generative model, the entries in the hidden buffer generate the corresponding pronouns. A system implementing this model is evaluated on the ACE corpus with promising performance.</p><p>3 0.70383799 <a title="331-lda-3" href="./acl-2011-Web-Scale_Features_for_Full-Scale_Parsing.html">333 acl-2011-Web-Scale Features for Full-Scale Parsing</a></p>
<p>Author: Mohit Bansal ; Dan Klein</p><p>Abstract: Counts from large corpora (like the web) can be powerful syntactic cues. Past work has used web counts to help resolve isolated ambiguities, such as binary noun-verb PP attachments and noun compound bracketings. In this work, we first present a method for generating web count features that address the full range of syntactic attachments. These features encode both surface evidence of lexical affinities as well as paraphrase-based cues to syntactic structure. We then integrate our features into full-scale dependency and constituent parsers. We show relative error reductions of7.0% over the second-order dependency parser of McDonald and Pereira (2006), 9.2% over the constituent parser of Petrov et al. (2006), and 3.4% over a non-local constituent reranker.</p><p>4 0.69555354 <a title="331-lda-4" href="./acl-2011-Learning_From_Collective_Human_Behavior_to_Introduce_Diversity_in_Lexical_Choice.html">201 acl-2011-Learning From Collective Human Behavior to Introduce Diversity in Lexical Choice</a></p>
<p>Author: Vahed Qazvinian ; Dragomir R. Radev</p><p>Abstract: We analyze collective discourse, a collective human behavior in content generation, and show that it exhibits diversity, a property of general collective systems. Using extensive analysis, we propose a novel paradigm for designing summary generation systems that reflect the diversity of perspectives seen in reallife collective summarization. We analyze 50 sets of summaries written by human about the same story or artifact and investigate the diversity of perspectives across these summaries. We show how different summaries use various phrasal information units (i.e., nuggets) to express the same atomic semantic units, called factoids. Finally, we present a ranker that employs distributional similarities to build a net- work of words, and captures the diversity of perspectives by detecting communities in this network. Our experiments show how our system outperforms a wide range of other document ranking systems that leverage diversity.</p><p>5 0.67591804 <a title="331-lda-5" href="./acl-2011-Joint_Training_of_Dependency_Parsing_Filters_through_Latent_Support_Vector_Machines.html">186 acl-2011-Joint Training of Dependency Parsing Filters through Latent Support Vector Machines</a></p>
<p>Author: Colin Cherry ; Shane Bergsma</p><p>Abstract: Graph-based dependency parsing can be sped up significantly if implausible arcs are eliminated from the search-space before parsing begins. State-of-the-art methods for arc filtering use separate classifiers to make pointwise decisions about the tree; they label tokens with roles such as root, leaf, or attaches-tothe-left, and then filter arcs accordingly. Because these classifiers overlap substantially in their filtering consequences, we propose to train them jointly, so that each classifier can focus on the gaps of the others. We integrate the various pointwise decisions as latent variables in a single arc-level SVM classifier. This novel framework allows us to combine nine pointwise filters, and adjust their sensitivity using a shared threshold based on arc length. Our system filters 32% more arcs than the independently-trained classifiers, without reducing filtering speed. This leads to faster parsing with no reduction in accuracy.</p><p>6 0.6726318 <a title="331-lda-6" href="./acl-2011-Query_Weighting_for_Ranking_Model_Adaptation.html">256 acl-2011-Query Weighting for Ranking Model Adaptation</a></p>
<p>7 0.67208004 <a title="331-lda-7" href="./acl-2011-Exploiting_Syntactico-Semantic_Structures_for_Relation_Extraction.html">126 acl-2011-Exploiting Syntactico-Semantic Structures for Relation Extraction</a></p>
<p>8 0.66926742 <a title="331-lda-8" href="./acl-2011-Exact_Decoding_of_Syntactic_Translation_Models_through_Lagrangian_Relaxation.html">123 acl-2011-Exact Decoding of Syntactic Translation Models through Lagrangian Relaxation</a></p>
<p>9 0.66674393 <a title="331-lda-9" href="./acl-2011-Target-dependent_Twitter_Sentiment_Classification.html">292 acl-2011-Target-dependent Twitter Sentiment Classification</a></p>
<p>10 0.66664994 <a title="331-lda-10" href="./acl-2011-An_Algorithm_for_Unsupervised_Transliteration_Mining_with_an_Application_to_Word_Alignment.html">34 acl-2011-An Algorithm for Unsupervised Transliteration Mining with an Application to Word Alignment</a></p>
<p>11 0.66636598 <a title="331-lda-11" href="./acl-2011-Using_Bilingual_Parallel_Corpora_for_Cross-Lingual_Textual_Entailment.html">327 acl-2011-Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment</a></p>
<p>12 0.66625541 <a title="331-lda-12" href="./acl-2011-Piggyback%3A_Using_Search_Engines_for_Robust_Cross-Domain_Named_Entity_Recognition.html">246 acl-2011-Piggyback: Using Search Engines for Robust Cross-Domain Named Entity Recognition</a></p>
<p>13 0.66339493 <a title="331-lda-13" href="./acl-2011-Exploring_Entity_Relations_for_Named_Entity_Disambiguation.html">128 acl-2011-Exploring Entity Relations for Named Entity Disambiguation</a></p>
<p>14 0.66325516 <a title="331-lda-14" href="./acl-2011-Translationese_and_Its_Dialects.html">311 acl-2011-Translationese and Its Dialects</a></p>
<p>15 0.66249907 <a title="331-lda-15" href="./acl-2011-Joint_Annotation_of_Search_Queries.html">182 acl-2011-Joint Annotation of Search Queries</a></p>
<p>16 0.66095656 <a title="331-lda-16" href="./acl-2011-Effects_of_Noun_Phrase_Bracketing_in_Dependency_Parsing_and_Machine_Translation.html">111 acl-2011-Effects of Noun Phrase Bracketing in Dependency Parsing and Machine Translation</a></p>
<p>17 0.65916401 <a title="331-lda-17" href="./acl-2011-Semi-supervised_Relation_Extraction_with_Large-scale_Word_Clustering.html">277 acl-2011-Semi-supervised Relation Extraction with Large-scale Word Clustering</a></p>
<p>18 0.6590839 <a title="331-lda-18" href="./acl-2011-Data_point_selection_for_cross-language_adaptation_of_dependency_parsers.html">92 acl-2011-Data point selection for cross-language adaptation of dependency parsers</a></p>
<p>19 0.65891087 <a title="331-lda-19" href="./acl-2011-Joint_Bilingual_Sentiment_Classification_with_Unlabeled_Parallel_Corpora.html">183 acl-2011-Joint Bilingual Sentiment Classification with Unlabeled Parallel Corpora</a></p>
<p>20 0.658566 <a title="331-lda-20" href="./acl-2011-Coreference_Resolution_with_World_Knowledge.html">85 acl-2011-Coreference Resolution with World Knowledge</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
