<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>54 acl-2011-Automatically Extracting Polarity-Bearing Topics for Cross-Domain Sentiment Classification</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-54" href="#">acl2011-54</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>54 acl-2011-Automatically Extracting Polarity-Bearing Topics for Cross-Domain Sentiment Classification</h1>
<br/><p>Source: <a title="acl-2011-54-pdf" href="http://aclweb.org/anthology//P/P11/P11-1013.pdf">pdf</a></p><p>Author: Yulan He ; Chenghua Lin ; Harith Alani</p><p>Abstract: Joint sentiment-topic (JST) model was previously proposed to detect sentiment and topic simultaneously from text. The only supervision required by JST model learning is domain-independent polarity word priors. In this paper, we modify the JST model by incorporating word polarity priors through modifying the topic-word Dirichlet priors. We study the polarity-bearing topics extracted by JST and show that by augmenting the original feature space with polarity-bearing topics, the in-domain supervised classifiers learned from augmented feature representation achieve the state-of-the-art performance of 95% on the movie review data and an average of 90% on the multi-domain sentiment dataset. Furthermore, using feature augmentation and selection according to the information gain criteria for cross-domain sentiment classification, our proposed approach performs either better or comparably compared to previous approaches. Nevertheless, our approach is much simpler and does not require difficult parameter tuning.</p><p>Reference: <a title="acl-2011-54-reference" href="../acl2011_reference/acl-2011-Automatically_Extracting_Polarity-Bearing_Topics_for_Cross-Domain_Sentiment_Classification_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 uk  Abstract Joint sentiment-topic (JST) model was previously proposed to detect sentiment and topic simultaneously from text. [sent-11, score-0.525]
</p><p>2 Furthermore, using feature augmentation and selection according to the information gain criteria for cross-domain sentiment classification, our  proposed approach performs either better or comparably compared to previous approaches. [sent-15, score-0.58]
</p><p>3 1 Introduction Given a piece of text, sentiment classification aims to determine whether the semantic orientation of the text is positive, negative or neutral. [sent-17, score-0.432]
</p><p>4 However, in many practical cases, we may have plentiful labeled examples in the source domain, but very few or no labeled examples in the 123 target domain with a different distribution. [sent-25, score-0.277]
</p><p>5 For example, we may have many labeled books reviews, but we are interested in detecting the polarity of electronics reviews. [sent-26, score-0.177]
</p><p>6 Reviews for different produces might have widely different vocabularies, thus classifiers trained on one domain often fail to produce satisfactory results when shifting to another domain. [sent-27, score-0.169]
</p><p>7 This has motivated much research on sen-  timent transfer learning which transfers knowledge from a source task or domain to a different but related task or domain (? [sent-28, score-0.36]
</p><p>8 With prior polarity words extracted from both the MPQA subjectivity lexicon1 and the appraisal lexicon2, the JST model achieves a sentiment classification accuracy of 74% on the movie review data3 and 71% on the multi-domain sentiment dataset4. [sent-38, score-1.125]
</p><p>9 Moreover, it is also able to extract coherent and informative topics grouped under different sentiment. [sent-39, score-0.178]
</p><p>10 The fact that the JST model does not required any labeled documents for training makes it desirable for domain adaptation in sentiment classification. [sent-40, score-0.704]
</p><p>11 Many existing approaches solve the sentiment transfer problem by associating words 1http : / /www . [sent-41, score-0.405]
</p><p>12 Ac s2s0o1ci1a Atiosnso fcoirat Cioonm foprut Caotimonpaulta Lti nognuails Lti cnsg,u piasgteics 123–131, from different domains which indicate the same sentiment (? [sent-57, score-0.434]
</p><p>13 Indeed, the polarity-bearing topics extracted by JST essentially capture sentiment associations among words from different domains which effectively overcome the data distribution difference between source and target domains. [sent-61, score-0.701]
</p><p>14 The previously proposed JST model uses the sentiment prior information in the Gibbs sampling inference step that a sentiment label will only be sampled if the current word token has no prior sentiment as defined in a sentiment lexicon. [sent-62, score-1.73]
</p><p>15 This in fact implies a different generative process where many of the word prior sentiment labels are observed. [sent-63, score-0.464]
</p><p>16 This essentially creates an informed prior distribution for the sentiment labels and would allow the model to actually be latent and would be  consistent with the generative story. [sent-66, score-0.52]
</p><p>17 We proceed with a review of related work on sentiment domain adaptation. [sent-72, score-0.553]
</p><p>18 We then briefly describe the JST model and present another approach to incorporate word prior polarity information into JST learning. [sent-73, score-0.165]
</p><p>19 We subsequently show that words from different domains can indeed be grouped under the same polarity-bearing topic through an illustration of example topic words extracted by JST be-  fore proposing a domain adaptation approach based on JST. [sent-74, score-0.559]
</p><p>20 We verify our proposed approach by conducting experiments on both the movie review data 124 and the multi-domain sentiment dataset. [sent-75, score-0.508]
</p><p>21 2  Related Work  There has been significant amount of work on algorithms for domain adaptation in NLP. [sent-77, score-0.258]
</p><p>22 Earlier work treats the source domain data as “prior knowledge” and uses maximum a posterior (MAP) estimation to learn a model for the target domain data under this prior distribution (? [sent-78, score-0.522]
</p><p>23 ) also uses the source domain data to estimate prior distribution but in the context of a maximum entropy (ME) model. [sent-81, score-0.285]
</p><p>24 ) for domain adaptation where a mixture model is defined to learn differences between domains. [sent-83, score-0.28]
</p><p>25 Other approaches rely on unlabeled data in the target domain to overcome feature distribution differences between domains. [sent-84, score-0.275]
</p><p>26 ) proposed  structural correspondence learning (SCL) for domain adaptation in sentiment classification. [sent-88, score-0.657]
</p><p>27 Given labeled data from a source domain and unlabeled data from target domain, SCL selects a set of pivot features to link the source and target domains where pivots are selected based on their common frequency in both domains and also their mutual information with the source labels. [sent-89, score-0.531]
</p><p>28 ) proposed a kernel-mapping function which maps both source and target domains data to a high-dimensional feature space so that data points from the same domain are twice as similar as those from different domains. [sent-92, score-0.368]
</p><p>29 ) proposed translated learning which uses a language model to link the class labels to the features in the source spaces, which in turn is translated to the features in the target spaces. [sent-95, score-0.159]
</p><p>30 ) proposed the spectral feature alignment (SFA) algorithm where some domain-  independent words are used as a bridge to construct a bipartite graph to model the co-occurrence relationship between domain-specific words and domain-independent words. [sent-101, score-0.15]
</p><p>31 The sentiment score of each unlabeled documents is recursively calculated until convergence from its neighbors the actual labels of source domain documents and pseudo-labels of target document documents. [sent-105, score-0.745]
</p><p>32 This approach was later extended by simultaneously considering relations between documents and words from both source and target domains (? [sent-106, score-0.176]
</p><p>33 ) addressed the issue when the predictive distribution of class label given input data of the domains differs and proposed Predictive Distribution Matching SVM learn a robust classifier in the target domain by leveraging the labeled data from only the relevant regions of multiple sources. [sent-110, score-0.421]
</p><p>34 For each sentiment label l under document d, cFhooro esaec a d siesnttriimbuetinotn l θd,l ∼ Dir(α). [sent-128, score-0.47]
</p><p>35 For each word wi in document d choose a sentiment label li ∼ Mult(πd), choose a topic zi ∼ Mult(θd,li ), choose a word wi from ϕlzii , a Multinomial distribution over words conditioned on topic zi and sentiment label li. [sent-129, score-1.177]
</p><p>36 –  –  –  Gibbs sampling was used to estimate the posterior distribution by sequentially sampling each variable  of interest,  zt  and lt here, from the distribution over 125  ? [sent-130, score-0.17]
</p><p>37 01 iofth Se(rww)is =e l  ,(2)  ×  where the function S(w) returns the prior sentiment label of w in a sentiment lexicon, i. [sent-160, score-0.849]
</p><p>38 The matrix λ can be considered as a transformation matrix which modifies the Dirichlet priors β of size S T V , so that the word prior polarity can sbiez captured. [sent-163, score-0.171]
</p><p>39 Thus, the word “excellent” can only be drawn from the positive topic word distributions generated from a Dirichlet distribution with parameter βlpos. [sent-167, score-0.18]
</p><p>40 In this section, we study the polarity-bearing topics extracted by JST. [sent-169, score-0.146]
</p><p>41 We combined reviews from the source and target domains and discarded document labels in both domains. [sent-170, score-0.281]
</p><p>42 Words in each cell are grouped under one topic and the upper half of the table shows topic words under the positive sentiment label while the lower half shows topic words under the negative sentiment label. [sent-175, score-1.126]
</p><p>43 We can see that JST appears to better capture sentiment association distribution in the source and target domains. [sent-176, score-0.494]
</p><p>44 set, words from the DVD domain describe a rock concert DVD while words from the Electronics domain are likely relevant to stereo amplifiers and receivers, 126 and yet they are grouped under the same topic by the JST model. [sent-178, score-0.424]
</p><p>45 ×  set, “stainless” rarely appears in the Book domain and “interest” does not occur often in the Kitchen domain and they are grouped under the same topic. [sent-181, score-0.32]
</p><p>46 These observations motivate us to explore polaritybearing topics extracted by JST for cross-domain sentiment classification since grouping words from different domains but bearing similar sentiment has the effect of overcoming the data distribution difference of two domains. [sent-182, score-1.108]
</p><p>47 5  Domain Adaptation using JST  Given input data x and a class label y, labeled patterns of one domain can be drawn from the joint distribution P(x, y) = P(y|x)P(x). [sent-183, score-0.258]
</p><p>48 The task of domain adaptation is to predict the label yit corresponding to xit in the target domain. [sent-188, score-0.341]
</p><p>49 We assume that we are given two sets of training data, Ds and Dt, the source domain and target dodmaatian, Ddataa sets, respectively. [sent-189, score-0.231]
</p><p>50 In the multiclass classification problem, the source domain data consist of labeled instances, Ds = {(xsn; yns) ∈ X Y : 1o ≤ n ≤ Ns}, wcehs,ere D X =is {th(ex input space a×nd Y Y  =  i1s a fi nnit ≤e set o}f, ,c wlahsse elab Xels i. [sent-190, score-0.266]
</p><p>51 pTehresource and target domain data are first merged with document labels discarded. [sent-198, score-0.276]
</p><p>52 A JST model is then learned from the merged corpus to generate polaritybearing topics for each document. [sent-199, score-0.23]
</p><p>53 The original documents in the source domain are augmented with those polarity-bearing topics as shown in Step 4 of Algorithm ? [sent-200, score-0.393]
</p><p>54 , where lizi denotes a combination of sentiment label li and topic zi for word wi. [sent-202, score-0.541]
</p><p>55 Finally, feature selection is performed according to the information gain criteria and a classifier is then trained from the source domain using the new document representations. [sent-203, score-0.361]
</p><p>56 The target domain documents are also encoded in a similar way with polarity-bearing topics added into their feature representations. [sent-204, score-0.415]
</p><p>57 Input: The source domain data Ds= {(xsn;yns) ∈ X × uYt: : 1h e≤ s n c≤e dNoms}a,i nth dea target =do {m(xain dat)a, ∈ ∈D Xt =× {Yxtn : ∈1 X≤ : n1 ≤≤ n ≤} ,N tthe, eN tatr ? [sent-206, score-0.231]
</p><p>58 r t hNe target domain Dt 1u: Merge D sesn tainmde nDtt c wlasisthif ideorc fuorm tehnet laarbgeelts d odimscaairnde Dd,  2: 3: 4:  5: 6: 7: 8:  xtn,  DM e=rg {e(x Dsn, a1n ≤d n ≤ Ns; 1≤ n ≤ Nt} TDra =in a JxST,1 1m ≤od nel ≤ on D fTorra iena ach J SdoTc mumodenelt xsn D= (w1, w2 , . [sent-208, score-0.321]
</p><p>59 , wm) ∈ Ds do Augment document with polarity-bearing topics generated from JST, (w1 w2, wm, l1z1, l2z2, lmzm) Add {xsn0 ; yns} into a document pool B endA dfodr Perform feature selection using IG on B PReertufornrm a fcelaastusriefie ser, tercatiinoend u on Bg  xsn0 =  Return  , . [sent-211, score-0.382]
</p><p>60 that the JST model directly models P(l|d), the probability of sentiment lraecbetlly given document, ahned p rhoebncaeb ldiotycu omfe sennt polarity can be classified accordingly. [sent-219, score-0.471]
</p><p>61 Since JST model learning does not require the availability of document labels, it is possible to augment the source domain data by adding most confident pseudo-labeled documents from the target domain by the JST model as shown in Algorithm ? [sent-220, score-0.508]
</p><p>62 6 Experiments We evaluate our proposed approach on the two datasets, the movie review (MR) data and the multidomain sentiment (MDS) dataset. [sent-223, score-0.508]
</p><p>63 The movie review data consist of 1000 positive and 1000 neg-  ative movie reviews drawn from the IMDB movie archive while the multi-domain sentiment dataset contains four different types of product reviews extracted from Amazon. [sent-224, score-0.745]
</p><p>64 Input: The target domain data, Dt= {xtn∈ X : u1t ≤ n ≤ Nrget,t tN dot ? [sent-227, score-0.191]
</p><p>65 The MPQA subjectivity lexicon is used as a sentiment lexicon in our experiments. [sent-231, score-0.394]
</p><p>66 1 Experimental Setup While the original JST model can produce reasonable results with a simple symmetric Dirichlet prior, here we use asymmetric prior α over the topic proportions which is learned directly from data using a fixed-point iteration method (? [sent-233, score-0.193]
</p><p>67 2 Supervised Sentiment Classification We performed 5-fold cross validation for the performance evaluation of supervised sentiment classification. [sent-242, score-0.396]
</p><p>68 For example, when bTe ris o fse fte attou 5, ctlhuesrtee are 53 topic groups munpldee,r weahechn of the positive, negative, or neutral sentiment labels and hence there are altogether 15 feature clusters. [sent-265, score-0.571]
</p><p>69 The generated topics for each document from the JST model were simply added into its bag-of-words (BOW) feature representation prior to model training. [sent-266, score-0.389]
</p><p>70 shows the classification results on the five different domains by varying the number of topics from 1 to 200. [sent-269, score-0.287]
</p><p>71 It can be observed that the best classification accuracy is obtained when the number of topics is set to 1 (or 3 feature clusters). [sent-270, score-0.255]
</p><p>72 Nevertheless, when the number of topics is set to 15, using JST feature augmentation still outperforms ME without feature augmentation (the baseline model) in all of the domains. [sent-272, score-0.424]
</p><p>73 It is worth pointing out that the JST model with single topic becomes the standard LDA model with only three sentiment topics. [sent-273, score-0.521]
</p><p>74 Nevertheless, we have proposed an effective way to incorporate domain-independent word polarity prior information into model learning. [sent-274, score-0.191]
</p><p>75 ) explored different methods to automatically generate annotator rationales to improve sentiment classification accuracy. [sent-318, score-0.463]
</p><p>76 ) adopted a two-stage process by first classifying sentences as personal views and impersonal views and then using an ensemble method to perform sentiment classification. [sent-328, score-0.373]
</p><p>77 3 Domain Adaptation We conducted domain adaptation experiments on the MDS dataset comprising of four different domains, Book (B), DVD (D), Electronics (E), and Kitchen appliances (K). [sent-334, score-0.258]
</p><p>78 A classifier trained on the training set of one domain is tested on the test set of a different domain. [sent-336, score-0.168]
</p><p>79 LDA results were generated from an ME classifier trained on document vectors augmented with topics generated from the LDA model. [sent-342, score-0.308]
</p><p>80 JST results were obtained in a similar way except that we used the polaritybearing topics generated from the JST model. [sent-344, score-0.229]
</p><p>81 We also tested with adding pseudo-labeled examples from the JST model into the source domain for ME classifier training (following Algorithm ? [sent-345, score-0.23]
</p><p>82 The document sentiment classification probability threshold τ was set to 0. [sent-350, score-0.493]
</p><p>83 where the result for each domain and for each method is averaged over all three possible adaptation tasks by varying the source domain. [sent-356, score-0.319]
</p><p>84 The adaptation loss is calculated with respect to the in-domain gold standard classification result. [sent-357, score-0.2]
</p><p>85 We plot the classification accuracy versus different topic numbers in Figure ? [sent-404, score-0.163]
</p><p>86 It can be observed that for the  relatively larger Book and DVD data sets, the accuracies peaked at topic number 10, whereas for the relatively smaller Electronics and Kitchen data sets, the best performance was obtained at topic number 50. [sent-407, score-0.208]
</p><p>87 Increasing topic numbers results in the decrease of classification accuracy. [sent-408, score-0.163]
</p><p>88 Manually examining the extracted polarity topics from JST reveals that when the topic number is small, each topic cluster contains well-mixed words from different domains. [sent-409, score-0.43]
</p><p>89 However, when the topic number is large, words under each topic cluster tend to be dominated by a single domain. [sent-410, score-0.208]
</p><p>90 our proposed approach with two other domain adaptation algorithms for sentiment classification, SCL and SFA. [sent-413, score-0.657]
</p><p>91 Each set of bars represent a cross-domain sentiment classification task. [sent-414, score-0.432]
</p><p>92 The thick horizontal lines are in-domain sentiment classification accuracies. [sent-415, score-0.432]
</p><p>93 Furthermore, using feature augmentation and selection according to the information gain criteria for cross-domain sentiment classification, our proposed approach outperforms SCL and gives similar results as SFA. [sent-460, score-0.58]
</p><p>94 First, polarity-bearing topics generated by the JST model were simply added into the original feature space of documents, it is worth investigating attaching different weight to each topic 130 bbaasseelliinnee  SSCCLL? [sent-463, score-0.374]
</p><p>95 maybe in proportional to the posterior probability of sentiment label and topic given a word estimated by the JST model. [sent-493, score-0.537]
</p><p>96 ) on both pseudo-labeled examples and source domain training examples in order to improve the adaptation performance. [sent-497, score-0.298]
</p><p>97 Customizing sentiment  classifiers to new domains: a case study. [sent-510, score-0.398]
</p><p>98 Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification. [sent-528, score-0.487]
</p><p>99 Employing personal/impersonal views in supervised and semi-supervised sentiment classification. [sent-589, score-0.396]
</p><p>100 A sentimental education: sentiment analysis using subjectivity summariza-  tion based on minimum cuts. [sent-626, score-0.394]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('jst', 0.743), ('sentiment', 0.373), ('topics', 0.146), ('domain', 0.144), ('dvd', 0.131), ('adaptation', 0.114), ('xtn', 0.109), ('topic', 0.104), ('lda', 0.095), ('augmentation', 0.089), ('dd', 0.078), ('electronics', 0.078), ('polarity', 0.076), ('kitchen', 0.076), ('scl', 0.076), ('movie', 0.073), ('prior', 0.067), ('book', 0.066), ('polaritybearing', 0.062), ('bb', 0.062), ('kk', 0.062), ('document', 0.061), ('domains', 0.061), ('classification', 0.059), ('spectral', 0.052), ('feature', 0.05), ('reviews', 0.048), ('exeter', 0.047), ('xsn', 0.047), ('yns', 0.047), ('target', 0.047), ('dirichlet', 0.046), ('dai', 0.045), ('mds', 0.041), ('ee', 0.04), ('source', 0.04), ('zt', 0.038), ('label', 0.036), ('review', 0.036), ('augmented', 0.035), ('sfa', 0.034), ('yessenalina', 0.034), ('denoted', 0.034), ('distribution', 0.034), ('dt', 0.033), ('grouped', 0.032), ('transfer', 0.032), ('bbaasseelliinnee', 0.031), ('ftorra', 0.031), ('hne', 0.031), ('iena', 0.031), ('iigg', 0.031), ('jjsstt', 0.031), ('mmii', 0.031), ('mumodenelt', 0.031), ('rationales', 0.031), ('sdotc', 0.031), ('seah', 0.031), ('ssccll', 0.031), ('ssffaa', 0.031), ('nevertheless', 0.03), ('ds', 0.03), ('zi', 0.028), ('documents', 0.028), ('ns', 0.028), ('priors', 0.028), ('pivots', 0.028), ('loss', 0.027), ('ln', 0.027), ('mr', 0.027), ('proposed', 0.026), ('predictive', 0.026), ('appraisal', 0.025), ('cla', 0.025), ('classifiers', 0.025), ('posterior', 0.024), ('labels', 0.024), ('classifier', 0.024), ('pool', 0.023), ('supervised', 0.023), ('labeled', 0.023), ('augmenting', 0.023), ('mult', 0.023), ('model', 0.022), ('criteria', 0.022), ('adapted', 0.022), ('daum', 0.022), ('simpler', 0.021), ('subjectivity', 0.021), ('drawn', 0.021), ('varying', 0.021), ('ach', 0.021), ('mpqa', 0.021), ('generated', 0.021), ('gibbs', 0.02), ('sampling', 0.02), ('bow', 0.02), ('chelba', 0.02), ('altogether', 0.02), ('selection', 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999923 <a title="54-tfidf-1" href="./acl-2011-Automatically_Extracting_Polarity-Bearing_Topics_for_Cross-Domain_Sentiment_Classification.html">54 acl-2011-Automatically Extracting Polarity-Bearing Topics for Cross-Domain Sentiment Classification</a></p>
<p>Author: Yulan He ; Chenghua Lin ; Harith Alani</p><p>Abstract: Joint sentiment-topic (JST) model was previously proposed to detect sentiment and topic simultaneously from text. The only supervision required by JST model learning is domain-independent polarity word priors. In this paper, we modify the JST model by incorporating word polarity priors through modifying the topic-word Dirichlet priors. We study the polarity-bearing topics extracted by JST and show that by augmenting the original feature space with polarity-bearing topics, the in-domain supervised classifiers learned from augmented feature representation achieve the state-of-the-art performance of 95% on the movie review data and an average of 90% on the multi-domain sentiment dataset. Furthermore, using feature augmentation and selection according to the information gain criteria for cross-domain sentiment classification, our proposed approach performs either better or comparably compared to previous approaches. Nevertheless, our approach is much simpler and does not require difficult parameter tuning.</p><p>2 0.35915381 <a title="54-tfidf-2" href="./acl-2011-Using_Multiple_Sources_to_Construct_a_Sentiment_Sensitive_Thesaurus_for_Cross-Domain_Sentiment_Classification.html">332 acl-2011-Using Multiple Sources to Construct a Sentiment Sensitive Thesaurus for Cross-Domain Sentiment Classification</a></p>
<p>Author: Danushka Bollegala ; David Weir ; John Carroll</p><p>Abstract: We describe a sentiment classification method that is applicable when we do not have any labeled data for a target domain but have some labeled data for multiple other domains, designated as the source domains. We automat- ically create a sentiment sensitive thesaurus using both labeled and unlabeled data from multiple source domains to find the association between words that express similar sentiments in different domains. The created thesaurus is then used to expand feature vectors to train a binary classifier. Unlike previous cross-domain sentiment classification methods, our method can efficiently learn from multiple source domains. Our method significantly outperforms numerous baselines and returns results that are better than or comparable to previous cross-domain sentiment classification methods on a benchmark dataset containing Amazon user reviews for different types of products.</p><p>3 0.32509303 <a title="54-tfidf-3" href="./acl-2011-Learning_Word_Vectors_for_Sentiment_Analysis.html">204 acl-2011-Learning Word Vectors for Sentiment Analysis</a></p>
<p>Author: Andrew L. Maas ; Raymond E. Daly ; Peter T. Pham ; Dan Huang ; Andrew Y. Ng ; Christopher Potts</p><p>Abstract: Unsupervised vector-based approaches to semantics can model rich lexical meanings, but they largely fail to capture sentiment information that is central to many word meanings and important for a wide range of NLP tasks. We present a model that uses a mix of unsupervised and supervised techniques to learn word vectors capturing semanticterm–documentinformation as well as rich sentiment content. The proposed model can leverage both continuous and multi-dimensional sentiment information as well as non-sentiment annotations. We instantiate the model to utilize the document-level sentiment polarity annotations present in many online documents (e.g. star ratings). We evaluate the model using small, widely used sentiment and subjectivity corpora and find it out-performs several previously introduced methods for sentiment classification. We also introduce a large dataset , of movie reviews to serve as a more robust benchmark for work in this area.</p><p>4 0.22971819 <a title="54-tfidf-4" href="./acl-2011-Semi-supervised_latent_variable_models_for_sentence-level_sentiment_analysis.html">279 acl-2011-Semi-supervised latent variable models for sentence-level sentiment analysis</a></p>
<p>Author: Oscar Tackstrom ; Ryan McDonald</p><p>Abstract: We derive two variants of a semi-supervised model for fine-grained sentiment analysis. Both models leverage abundant natural supervision in the form of review ratings, as well as a small amount of manually crafted sentence labels, to learn sentence-level sentiment classifiers. The proposed model is a fusion of a fully supervised structured conditional model and its partially supervised counterpart. This allows for highly efficient estimation and inference algorithms with rich feature definitions. We describe the two variants as well as their component models and verify experimentally that both variants give significantly improved results for sentence-level sentiment analysis compared to all baselines. 1 Sentence-level sentiment analysis In this paper, we demonstrate how combining coarse-grained and fine-grained supervision benefits sentence-level sentiment analysis an important task in the field of opinion classification and retrieval (Pang and Lee, 2008). Typical supervised learning approaches to sentence-level sentiment analysis rely on sentence-level supervision. While such fine-grained supervision rarely exist naturally, and thus requires labor intensive manual annotation effort (Wiebe et al., 2005), coarse-grained supervision is naturally abundant in the form of online review ratings. This coarse-grained supervision is, of course, less informative compared to fine-grained supervision, however, by combining a small amount of sentence-level supervision with a large amount of document-level supervision, we are able to substantially improve on the sentence-level classification task. Our work combines two strands of research: models for sentiment analysis that take document structure into account; – 569 Ryan McDonald Google, Inc., New York ryanmcd@ google com . and models that use latent variables to learn unobserved phenomena from that which can be observed. Exploiting document structure for sentiment analysis has attracted research attention since the early work of Pang and Lee (2004), who performed minimal cuts in a sentence graph to select subjective sentences. McDonald et al. (2007) later showed that jointly learning fine-grained (sentence) and coarsegrained (document) sentiment improves predictions at both levels. More recently, Yessenalina et al. (2010) described how sentence-level latent variables can be used to improve document-level prediction and Nakagawa et al. (2010) used latent variables over syntactic dependency trees to improve sentence-level prediction, using only labeled sentences for training. In a similar vein, Sauper et al. (2010) integrated generative content structure models with discriminative models for multi-aspect sentiment summarization and ranking. These approaches all rely on the availability of fine-grained annotations, but Ta¨ckstro¨m and McDonald (201 1) showed that latent variables can be used to learn fine-grained sentiment using only coarse-grained supervision. While this model was shown to beat a set of natural baselines with quite a wide margin, it has its shortcomings. Most notably, due to the loose constraints provided by the coarse supervision, it tends to only predict the two dominant fine-grained sentiment categories well for each document sentiment category, so that almost all sentences in positive documents are deemed positive or neutral, and vice versa for negative documents. As a way of overcoming these shortcomings, we propose to fuse a coarsely supervised model with a fully supervised model. Below, we describe two ways of achieving such a combined model in the framework of structured conditional latent variable models. Contrary to (generative) topic models (Mei et al., 2007; Titov and Proceedings ofP thoer t4l9atnhd A, Onrnuegaoln M,e Jeuntineg 19 o-f2 t4h,e 2 A0s1s1o.c?i ac t2io0n11 fo Ar Cssoocmiaptuiotanti foonra Clo Lminpguutiast i ocns:aslh Loirntpgaupisetrics , pages 569–574, Figure 1: a) Factor graph of the fully observed graphical model. b) Factor graph of the corresponding latent variable model. During training, shaded nodes are observed, while non-shaded nodes are unobserved. The input sentences si are always observed. Note that there are no factors connecting the document node, yd, with the input nodes, s, so that the sentence-level variables, ys, in effect form a bottleneck between the document sentiment and the input sentences. McDonald, 2008; Lin and He, 2009), structured conditional models can handle rich and overlapping features and allow for exact inference and simple gradient based estimation. The former models are largely orthogonal to the one we propose in this work and combining their merits might be fruitful. As shown by Sauper et al. (2010), it is possible to fuse generative document structure models and task specific structured conditional models. While we do model document structure in terms of sentiment transitions, we do not model topical structure. An interesting avenue for future work would be to extend the model of Sauper et al. (2010) to take coarse-grained taskspecific supervision into account, while modeling fine-grained task-specific aspects with latent variables. Note also that the proposed approach is orthogonal to semi-supervised and unsupervised induction of context independent (prior polarity) lexicons (Turney, 2002; Kim and Hovy, 2004; Esuli and Sebastiani, 2009; Rao and Ravichandran, 2009; Velikovich et al., 2010). The output of such models could readily be incorporated as features in the proposed model. 1.1 Preliminaries Let d be a document consisting of n sentences, s = (si)in=1, with a document–sentence-sequence pair denoted d = (d, s). Let yd = (yd, ys) denote random variables1 the document level sentiment, yd, and the sequence of sentence level sentiment, = (ysi)in=1 . – ys 1We are abusing notation throughout by using the same symbols to refer to random variables and their particular assignments. 570 In what follows, we assume that we have access to two training sets: a small set of fully labeled instances, DF = {(dj, and a large set of ydj)}jm=f1, coarsely labeled instances DC = {(dj, yjd)}jm=fm+fm+c1. Furthermore, we assume that yd and all yis take values in {POS, NEG, NEU}. We focus on structured conditional models in the exponential family, with the standard parametrization pθ(yd,ys|s) = expnhφ(yd,ys,s),θi − Aθ(s)o</p><p>5 0.22181515 <a title="54-tfidf-5" href="./acl-2011-Target-dependent_Twitter_Sentiment_Classification.html">292 acl-2011-Target-dependent Twitter Sentiment Classification</a></p>
<p>Author: Long Jiang ; Mo Yu ; Ming Zhou ; Xiaohua Liu ; Tiejun Zhao</p><p>Abstract: Sentiment analysis on Twitter data has attracted much attention recently. In this paper, we focus on target-dependent Twitter sentiment classification; namely, given a query, we classify the sentiments of the tweets as positive, negative or neutral according to whether they contain positive, negative or neutral sentiments about that query. Here the query serves as the target of the sentiments. The state-ofthe-art approaches for solving this problem always adopt the target-independent strategy, which may assign irrelevant sentiments to the given target. Moreover, the state-of-the-art approaches only take the tweet to be classified into consideration when classifying the sentiment; they ignore its context (i.e., related tweets). However, because tweets are usually short and more ambiguous, sometimes it is not enough to consider only the current tweet for sentiment classification. In this paper, we propose to improve target-dependent Twitter sentiment classification by 1) incorporating target-dependent features; and 2) taking related tweets into consideration. According to the experimental results, our approach greatly improves the performance of target-dependent sentiment classification. 1</p><p>6 0.22010523 <a title="54-tfidf-6" href="./acl-2011-Sentiment_Analysis_of_Citations_using_Sentence_Structure-Based_Features.html">281 acl-2011-Sentiment Analysis of Citations using Sentence Structure-Based Features</a></p>
<p>7 0.21631838 <a title="54-tfidf-7" href="./acl-2011-Joint_Bilingual_Sentiment_Classification_with_Unlabeled_Parallel_Corpora.html">183 acl-2011-Joint Bilingual Sentiment Classification with Unlabeled Parallel Corpora</a></p>
<p>8 0.19188358 <a title="54-tfidf-8" href="./acl-2011-PsychoSentiWordNet.html">253 acl-2011-PsychoSentiWordNet</a></p>
<p>9 0.18771864 <a title="54-tfidf-9" href="./acl-2011-Dr_Sentiment_Knows_Everything%21.html">105 acl-2011-Dr Sentiment Knows Everything!</a></p>
<p>10 0.18126659 <a title="54-tfidf-10" href="./acl-2011-Domain_Adaptation_by_Constraining_Inter-Domain_Variability_of_Latent_Feature_Representation.html">103 acl-2011-Domain Adaptation by Constraining Inter-Domain Variability of Latent Feature Representation</a></p>
<p>11 0.16829285 <a title="54-tfidf-11" href="./acl-2011-Is_Machine_Translation_Ripe_for_Cross-Lingual_Sentiment_Classification%3F.html">179 acl-2011-Is Machine Translation Ripe for Cross-Lingual Sentiment Classification?</a></p>
<p>12 0.16353247 <a title="54-tfidf-12" href="./acl-2011-MemeTube%3A_A_Sentiment-based_Audiovisual_System_for_Analyzing_and_Displaying_Microblog_Messages.html">218 acl-2011-MemeTube: A Sentiment-based Audiovisual System for Analyzing and Displaying Microblog Messages</a></p>
<p>13 0.1626841 <a title="54-tfidf-13" href="./acl-2011-Aspect_Ranking%3A_Identifying_Important_Product_Aspects_from_Online_Consumer_Reviews.html">45 acl-2011-Aspect Ranking: Identifying Important Product Aspects from Online Consumer Reviews</a></p>
<p>14 0.16027078 <a title="54-tfidf-14" href="./acl-2011-C-Feel-It%3A_A_Sentiment_Analyzer_for_Micro-blogs.html">64 acl-2011-C-Feel-It: A Sentiment Analyzer for Micro-blogs</a></p>
<p>15 0.12798584 <a title="54-tfidf-15" href="./acl-2011-Automatic_Labelling_of_Topic_Models.html">52 acl-2011-Automatic Labelling of Topic Models</a></p>
<p>16 0.12317549 <a title="54-tfidf-16" href="./acl-2011-Identifying_Word_Translations_from_Comparable_Corpora_Using_Latent_Topic_Models.html">161 acl-2011-Identifying Word Translations from Comparable Corpora Using Latent Topic Models</a></p>
<p>17 0.12259737 <a title="54-tfidf-17" href="./acl-2011-Entity_Set_Expansion_using_Topic_information.html">117 acl-2011-Entity Set Expansion using Topic information</a></p>
<p>18 0.1187626 <a title="54-tfidf-18" href="./acl-2011-Content_Models_with_Attitude.html">82 acl-2011-Content Models with Attitude</a></p>
<p>19 0.11426165 <a title="54-tfidf-19" href="./acl-2011-A_Latent_Topic_Extracting_Method_based_on_Events_in_a_Document_and_its_Application.html">18 acl-2011-A Latent Topic Extracting Method based on Events in a Document and its Application</a></p>
<p>20 0.1110779 <a title="54-tfidf-20" href="./acl-2011-Interactive_Topic_Modeling.html">178 acl-2011-Interactive Topic Modeling</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.209), (1, 0.307), (2, 0.257), (3, -0.03), (4, 0.079), (5, -0.054), (6, -0.073), (7, 0.112), (8, 0.005), (9, 0.026), (10, 0.114), (11, -0.025), (12, 0.051), (13, 0.036), (14, 0.177), (15, 0.101), (16, -0.036), (17, -0.015), (18, -0.006), (19, 0.02), (20, -0.017), (21, -0.047), (22, -0.02), (23, 0.009), (24, -0.004), (25, 0.039), (26, -0.077), (27, 0.013), (28, 0.041), (29, 0.014), (30, -0.086), (31, 0.048), (32, 0.01), (33, -0.05), (34, -0.088), (35, 0.003), (36, -0.087), (37, 0.01), (38, -0.048), (39, 0.009), (40, 0.017), (41, -0.038), (42, -0.026), (43, 0.043), (44, -0.024), (45, 0.047), (46, -0.006), (47, 0.018), (48, -0.052), (49, -0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96144652 <a title="54-lsi-1" href="./acl-2011-Automatically_Extracting_Polarity-Bearing_Topics_for_Cross-Domain_Sentiment_Classification.html">54 acl-2011-Automatically Extracting Polarity-Bearing Topics for Cross-Domain Sentiment Classification</a></p>
<p>Author: Yulan He ; Chenghua Lin ; Harith Alani</p><p>Abstract: Joint sentiment-topic (JST) model was previously proposed to detect sentiment and topic simultaneously from text. The only supervision required by JST model learning is domain-independent polarity word priors. In this paper, we modify the JST model by incorporating word polarity priors through modifying the topic-word Dirichlet priors. We study the polarity-bearing topics extracted by JST and show that by augmenting the original feature space with polarity-bearing topics, the in-domain supervised classifiers learned from augmented feature representation achieve the state-of-the-art performance of 95% on the movie review data and an average of 90% on the multi-domain sentiment dataset. Furthermore, using feature augmentation and selection according to the information gain criteria for cross-domain sentiment classification, our proposed approach performs either better or comparably compared to previous approaches. Nevertheless, our approach is much simpler and does not require difficult parameter tuning.</p><p>2 0.88770688 <a title="54-lsi-2" href="./acl-2011-Using_Multiple_Sources_to_Construct_a_Sentiment_Sensitive_Thesaurus_for_Cross-Domain_Sentiment_Classification.html">332 acl-2011-Using Multiple Sources to Construct a Sentiment Sensitive Thesaurus for Cross-Domain Sentiment Classification</a></p>
<p>Author: Danushka Bollegala ; David Weir ; John Carroll</p><p>Abstract: We describe a sentiment classification method that is applicable when we do not have any labeled data for a target domain but have some labeled data for multiple other domains, designated as the source domains. We automat- ically create a sentiment sensitive thesaurus using both labeled and unlabeled data from multiple source domains to find the association between words that express similar sentiments in different domains. The created thesaurus is then used to expand feature vectors to train a binary classifier. Unlike previous cross-domain sentiment classification methods, our method can efficiently learn from multiple source domains. Our method significantly outperforms numerous baselines and returns results that are better than or comparable to previous cross-domain sentiment classification methods on a benchmark dataset containing Amazon user reviews for different types of products.</p><p>3 0.8773163 <a title="54-lsi-3" href="./acl-2011-Learning_Word_Vectors_for_Sentiment_Analysis.html">204 acl-2011-Learning Word Vectors for Sentiment Analysis</a></p>
<p>Author: Andrew L. Maas ; Raymond E. Daly ; Peter T. Pham ; Dan Huang ; Andrew Y. Ng ; Christopher Potts</p><p>Abstract: Unsupervised vector-based approaches to semantics can model rich lexical meanings, but they largely fail to capture sentiment information that is central to many word meanings and important for a wide range of NLP tasks. We present a model that uses a mix of unsupervised and supervised techniques to learn word vectors capturing semanticterm–documentinformation as well as rich sentiment content. The proposed model can leverage both continuous and multi-dimensional sentiment information as well as non-sentiment annotations. We instantiate the model to utilize the document-level sentiment polarity annotations present in many online documents (e.g. star ratings). We evaluate the model using small, widely used sentiment and subjectivity corpora and find it out-performs several previously introduced methods for sentiment classification. We also introduce a large dataset , of movie reviews to serve as a more robust benchmark for work in this area.</p><p>4 0.83428937 <a title="54-lsi-4" href="./acl-2011-Semi-supervised_latent_variable_models_for_sentence-level_sentiment_analysis.html">279 acl-2011-Semi-supervised latent variable models for sentence-level sentiment analysis</a></p>
<p>Author: Oscar Tackstrom ; Ryan McDonald</p><p>Abstract: We derive two variants of a semi-supervised model for fine-grained sentiment analysis. Both models leverage abundant natural supervision in the form of review ratings, as well as a small amount of manually crafted sentence labels, to learn sentence-level sentiment classifiers. The proposed model is a fusion of a fully supervised structured conditional model and its partially supervised counterpart. This allows for highly efficient estimation and inference algorithms with rich feature definitions. We describe the two variants as well as their component models and verify experimentally that both variants give significantly improved results for sentence-level sentiment analysis compared to all baselines. 1 Sentence-level sentiment analysis In this paper, we demonstrate how combining coarse-grained and fine-grained supervision benefits sentence-level sentiment analysis an important task in the field of opinion classification and retrieval (Pang and Lee, 2008). Typical supervised learning approaches to sentence-level sentiment analysis rely on sentence-level supervision. While such fine-grained supervision rarely exist naturally, and thus requires labor intensive manual annotation effort (Wiebe et al., 2005), coarse-grained supervision is naturally abundant in the form of online review ratings. This coarse-grained supervision is, of course, less informative compared to fine-grained supervision, however, by combining a small amount of sentence-level supervision with a large amount of document-level supervision, we are able to substantially improve on the sentence-level classification task. Our work combines two strands of research: models for sentiment analysis that take document structure into account; – 569 Ryan McDonald Google, Inc., New York ryanmcd@ google com . and models that use latent variables to learn unobserved phenomena from that which can be observed. Exploiting document structure for sentiment analysis has attracted research attention since the early work of Pang and Lee (2004), who performed minimal cuts in a sentence graph to select subjective sentences. McDonald et al. (2007) later showed that jointly learning fine-grained (sentence) and coarsegrained (document) sentiment improves predictions at both levels. More recently, Yessenalina et al. (2010) described how sentence-level latent variables can be used to improve document-level prediction and Nakagawa et al. (2010) used latent variables over syntactic dependency trees to improve sentence-level prediction, using only labeled sentences for training. In a similar vein, Sauper et al. (2010) integrated generative content structure models with discriminative models for multi-aspect sentiment summarization and ranking. These approaches all rely on the availability of fine-grained annotations, but Ta¨ckstro¨m and McDonald (201 1) showed that latent variables can be used to learn fine-grained sentiment using only coarse-grained supervision. While this model was shown to beat a set of natural baselines with quite a wide margin, it has its shortcomings. Most notably, due to the loose constraints provided by the coarse supervision, it tends to only predict the two dominant fine-grained sentiment categories well for each document sentiment category, so that almost all sentences in positive documents are deemed positive or neutral, and vice versa for negative documents. As a way of overcoming these shortcomings, we propose to fuse a coarsely supervised model with a fully supervised model. Below, we describe two ways of achieving such a combined model in the framework of structured conditional latent variable models. Contrary to (generative) topic models (Mei et al., 2007; Titov and Proceedings ofP thoer t4l9atnhd A, Onrnuegaoln M,e Jeuntineg 19 o-f2 t4h,e 2 A0s1s1o.c?i ac t2io0n11 fo Ar Cssoocmiaptuiotanti foonra Clo Lminpguutiast i ocns:aslh Loirntpgaupisetrics , pages 569–574, Figure 1: a) Factor graph of the fully observed graphical model. b) Factor graph of the corresponding latent variable model. During training, shaded nodes are observed, while non-shaded nodes are unobserved. The input sentences si are always observed. Note that there are no factors connecting the document node, yd, with the input nodes, s, so that the sentence-level variables, ys, in effect form a bottleneck between the document sentiment and the input sentences. McDonald, 2008; Lin and He, 2009), structured conditional models can handle rich and overlapping features and allow for exact inference and simple gradient based estimation. The former models are largely orthogonal to the one we propose in this work and combining their merits might be fruitful. As shown by Sauper et al. (2010), it is possible to fuse generative document structure models and task specific structured conditional models. While we do model document structure in terms of sentiment transitions, we do not model topical structure. An interesting avenue for future work would be to extend the model of Sauper et al. (2010) to take coarse-grained taskspecific supervision into account, while modeling fine-grained task-specific aspects with latent variables. Note also that the proposed approach is orthogonal to semi-supervised and unsupervised induction of context independent (prior polarity) lexicons (Turney, 2002; Kim and Hovy, 2004; Esuli and Sebastiani, 2009; Rao and Ravichandran, 2009; Velikovich et al., 2010). The output of such models could readily be incorporated as features in the proposed model. 1.1 Preliminaries Let d be a document consisting of n sentences, s = (si)in=1, with a document–sentence-sequence pair denoted d = (d, s). Let yd = (yd, ys) denote random variables1 the document level sentiment, yd, and the sequence of sentence level sentiment, = (ysi)in=1 . – ys 1We are abusing notation throughout by using the same symbols to refer to random variables and their particular assignments. 570 In what follows, we assume that we have access to two training sets: a small set of fully labeled instances, DF = {(dj, and a large set of ydj)}jm=f1, coarsely labeled instances DC = {(dj, yjd)}jm=fm+fm+c1. Furthermore, we assume that yd and all yis take values in {POS, NEG, NEU}. We focus on structured conditional models in the exponential family, with the standard parametrization pθ(yd,ys|s) = expnhφ(yd,ys,s),θi − Aθ(s)o</p><p>5 0.69097698 <a title="54-lsi-5" href="./acl-2011-Aspect_Ranking%3A_Identifying_Important_Product_Aspects_from_Online_Consumer_Reviews.html">45 acl-2011-Aspect Ranking: Identifying Important Product Aspects from Online Consumer Reviews</a></p>
<p>Author: Jianxing Yu ; Zheng-Jun Zha ; Meng Wang ; Tat-Seng Chua</p><p>Abstract: In this paper, we dedicate to the topic of aspect ranking, which aims to automatically identify important product aspects from online consumer reviews. The important aspects are identified according to two observations: (a) the important aspects of a product are usually commented by a large number of consumers; and (b) consumers’ opinions on the important aspects greatly influence their overall opinions on the product. In particular, given consumer reviews of a product, we first identify the product aspects by a shallow dependency parser and determine consumers’ opinions on these aspects via a sentiment classifier. We then develop an aspect ranking algorithm to identify the important aspects by simultaneously considering the aspect frequency and the influence of consumers’ opinions given to each aspect on their overall opinions. The experimental results on 11 popular products in four domains demonstrate the effectiveness of our approach. We further apply the aspect ranking results to the application ofdocumentlevel sentiment classification, and improve the performance significantly.</p><p>6 0.68475556 <a title="54-lsi-6" href="./acl-2011-Domain_Adaptation_by_Constraining_Inter-Domain_Variability_of_Latent_Feature_Representation.html">103 acl-2011-Domain Adaptation by Constraining Inter-Domain Variability of Latent Feature Representation</a></p>
<p>7 0.67579454 <a title="54-lsi-7" href="./acl-2011-MemeTube%3A_A_Sentiment-based_Audiovisual_System_for_Analyzing_and_Displaying_Microblog_Messages.html">218 acl-2011-MemeTube: A Sentiment-based Audiovisual System for Analyzing and Displaying Microblog Messages</a></p>
<p>8 0.66410303 <a title="54-lsi-8" href="./acl-2011-Joint_Bilingual_Sentiment_Classification_with_Unlabeled_Parallel_Corpora.html">183 acl-2011-Joint Bilingual Sentiment Classification with Unlabeled Parallel Corpora</a></p>
<p>9 0.66005385 <a title="54-lsi-9" href="./acl-2011-Is_Machine_Translation_Ripe_for_Cross-Lingual_Sentiment_Classification%3F.html">179 acl-2011-Is Machine Translation Ripe for Cross-Lingual Sentiment Classification?</a></p>
<p>10 0.62806332 <a title="54-lsi-10" href="./acl-2011-Target-dependent_Twitter_Sentiment_Classification.html">292 acl-2011-Target-dependent Twitter Sentiment Classification</a></p>
<p>11 0.61543912 <a title="54-lsi-11" href="./acl-2011-Sentiment_Analysis_of_Citations_using_Sentence_Structure-Based_Features.html">281 acl-2011-Sentiment Analysis of Citations using Sentence Structure-Based Features</a></p>
<p>12 0.58200163 <a title="54-lsi-12" href="./acl-2011-Content_Models_with_Attitude.html">82 acl-2011-Content Models with Attitude</a></p>
<p>13 0.5768019 <a title="54-lsi-13" href="./acl-2011-PsychoSentiWordNet.html">253 acl-2011-PsychoSentiWordNet</a></p>
<p>14 0.56731313 <a title="54-lsi-14" href="./acl-2011-Dr_Sentiment_Knows_Everything%21.html">105 acl-2011-Dr Sentiment Knows Everything!</a></p>
<p>15 0.5528754 <a title="54-lsi-15" href="./acl-2011-C-Feel-It%3A_A_Sentiment_Analyzer_for_Micro-blogs.html">64 acl-2011-C-Feel-It: A Sentiment Analyzer for Micro-blogs</a></p>
<p>16 0.53386474 <a title="54-lsi-16" href="./acl-2011-Effective_Measures_of_Domain_Similarity_for_Parsing.html">109 acl-2011-Effective Measures of Domain Similarity for Parsing</a></p>
<p>17 0.50716215 <a title="54-lsi-17" href="./acl-2011-Subjectivity_and_Sentiment_Analysis_of_Modern_Standard_Arabic.html">289 acl-2011-Subjectivity and Sentiment Analysis of Modern Standard Arabic</a></p>
<p>18 0.46572086 <a title="54-lsi-18" href="./acl-2011-Structural_Topic_Model_for_Latent_Topical_Structure_Analysis.html">287 acl-2011-Structural Topic Model for Latent Topical Structure Analysis</a></p>
<p>19 0.43616864 <a title="54-lsi-19" href="./acl-2011-Automatically_Predicting_Peer-Review_Helpfulness.html">55 acl-2011-Automatically Predicting Peer-Review Helpfulness</a></p>
<p>20 0.43204144 <a title="54-lsi-20" href="./acl-2011-Entity_Set_Expansion_using_Topic_information.html">117 acl-2011-Entity Set Expansion using Topic information</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.013), (17, 0.052), (26, 0.015), (36, 0.202), (37, 0.203), (39, 0.065), (41, 0.048), (53, 0.011), (55, 0.02), (59, 0.035), (72, 0.028), (88, 0.044), (91, 0.033), (96, 0.132)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.84567106 <a title="54-lda-1" href="./acl-2011-Automatically_Extracting_Polarity-Bearing_Topics_for_Cross-Domain_Sentiment_Classification.html">54 acl-2011-Automatically Extracting Polarity-Bearing Topics for Cross-Domain Sentiment Classification</a></p>
<p>Author: Yulan He ; Chenghua Lin ; Harith Alani</p><p>Abstract: Joint sentiment-topic (JST) model was previously proposed to detect sentiment and topic simultaneously from text. The only supervision required by JST model learning is domain-independent polarity word priors. In this paper, we modify the JST model by incorporating word polarity priors through modifying the topic-word Dirichlet priors. We study the polarity-bearing topics extracted by JST and show that by augmenting the original feature space with polarity-bearing topics, the in-domain supervised classifiers learned from augmented feature representation achieve the state-of-the-art performance of 95% on the movie review data and an average of 90% on the multi-domain sentiment dataset. Furthermore, using feature augmentation and selection according to the information gain criteria for cross-domain sentiment classification, our proposed approach performs either better or comparably compared to previous approaches. Nevertheless, our approach is much simpler and does not require difficult parameter tuning.</p><p>2 0.8435117 <a title="54-lda-2" href="./acl-2011-A_Graph_Approach_to_Spelling_Correction_in_Domain-Centric_Search.html">13 acl-2011-A Graph Approach to Spelling Correction in Domain-Centric Search</a></p>
<p>Author: Zhuowei Bao ; Benny Kimelfeld ; Yunyao Li</p><p>Abstract: Spelling correction for keyword-search queries is challenging in restricted domains such as personal email (or desktop) search, due to the scarcity of query logs, and due to the specialized nature of the domain. For that task, this paper presents an algorithm that is based on statistics from the corpus data (rather than the query log). This algorithm, which employs a simple graph-based approach, can incorporate different types of data sources with different levels of reliability (e.g., email subject vs. email body), and can handle complex spelling errors like splitting and merging of words. An experimental study shows the superiority of the algorithm over existing alternatives in the email domain.</p><p>3 0.79023755 <a title="54-lda-3" href="./acl-2011-Using_Multiple_Sources_to_Construct_a_Sentiment_Sensitive_Thesaurus_for_Cross-Domain_Sentiment_Classification.html">332 acl-2011-Using Multiple Sources to Construct a Sentiment Sensitive Thesaurus for Cross-Domain Sentiment Classification</a></p>
<p>Author: Danushka Bollegala ; David Weir ; John Carroll</p><p>Abstract: We describe a sentiment classification method that is applicable when we do not have any labeled data for a target domain but have some labeled data for multiple other domains, designated as the source domains. We automat- ically create a sentiment sensitive thesaurus using both labeled and unlabeled data from multiple source domains to find the association between words that express similar sentiments in different domains. The created thesaurus is then used to expand feature vectors to train a binary classifier. Unlike previous cross-domain sentiment classification methods, our method can efficiently learn from multiple source domains. Our method significantly outperforms numerous baselines and returns results that are better than or comparable to previous cross-domain sentiment classification methods on a benchmark dataset containing Amazon user reviews for different types of products.</p><p>4 0.78902447 <a title="54-lda-4" href="./acl-2011-IMASS%3A_An_Intelligent_Microblog_Analysis_and_Summarization_System.html">156 acl-2011-IMASS: An Intelligent Microblog Analysis and Summarization System</a></p>
<p>Author: Jui-Yu Weng ; Cheng-Lun Yang ; Bo-Nian Chen ; Yen-Kai Wang ; Shou-De Lin</p><p>Abstract: This paper presents a system to summarize a Microblog post and its responses with the goal to provide readers a more constructive and concise set of information for efficient digestion. We introduce a novel two-phase summarization scheme. In the first phase, the post plus its responses are classified into four categories based on the intention, interrogation, sharing, discussion and chat. For each type of post, in the second phase, we exploit different strategies, including opinion analysis, response pair identification, and response relevancy detection, to summarize and highlight critical information to display. This system provides an alternative thinking about machinesummarization: by utilizing AI approaches, computers are capable of constructing deeper and more user-friendly abstraction. 1</p><p>5 0.77812892 <a title="54-lda-5" href="./acl-2011-Event_Extraction_as_Dependency_Parsing.html">122 acl-2011-Event Extraction as Dependency Parsing</a></p>
<p>Author: David McClosky ; Mihai Surdeanu ; Christopher Manning</p><p>Abstract: Nested event structures are a common occurrence in both open domain and domain specific extraction tasks, e.g., a “crime” event can cause a “investigation” event, which can lead to an “arrest” event. However, most current approaches address event extraction with highly local models that extract each event and argument independently. We propose a simple approach for the extraction of such structures by taking the tree of event-argument relations and using it directly as the representation in a reranking dependency parser. This provides a simple framework that captures global properties of both nested and flat event structures. We explore a rich feature space that models both the events to be parsed and context from the original supporting text. Our approach obtains competitive results in the extraction of biomedical events from the BioNLP’09 shared task with a F1 score of 53.5% in development and 48.6% in testing.</p><p>6 0.77530694 <a title="54-lda-6" href="./acl-2011-Which_Noun_Phrases_Denote_Which_Concepts%3F.html">334 acl-2011-Which Noun Phrases Denote Which Concepts?</a></p>
<p>7 0.77472824 <a title="54-lda-7" href="./acl-2011-Domain_Adaptation_by_Constraining_Inter-Domain_Variability_of_Latent_Feature_Representation.html">103 acl-2011-Domain Adaptation by Constraining Inter-Domain Variability of Latent Feature Representation</a></p>
<p>8 0.77259803 <a title="54-lda-8" href="./acl-2011-Prefix_Probability_for_Probabilistic_Synchronous_Context-Free_Grammars.html">250 acl-2011-Prefix Probability for Probabilistic Synchronous Context-Free Grammars</a></p>
<p>9 0.77078104 <a title="54-lda-9" href="./acl-2011-Exploiting_Web-Derived_Selectional_Preference_to_Improve_Statistical_Dependency_Parsing.html">127 acl-2011-Exploiting Web-Derived Selectional Preference to Improve Statistical Dependency Parsing</a></p>
<p>10 0.76843935 <a title="54-lda-10" href="./acl-2011-Learning_Word_Vectors_for_Sentiment_Analysis.html">204 acl-2011-Learning Word Vectors for Sentiment Analysis</a></p>
<p>11 0.76769006 <a title="54-lda-11" href="./acl-2011-Neutralizing_Linguistically_Problematic_Annotations_in_Unsupervised_Dependency_Parsing_Evaluation.html">230 acl-2011-Neutralizing Linguistically Problematic Annotations in Unsupervised Dependency Parsing Evaluation</a></p>
<p>12 0.76315236 <a title="54-lda-12" href="./acl-2011-Data_point_selection_for_cross-language_adaptation_of_dependency_parsers.html">92 acl-2011-Data point selection for cross-language adaptation of dependency parsers</a></p>
<p>13 0.75604647 <a title="54-lda-13" href="./acl-2011-Discriminative_Feature-Tied_Mixture_Modeling_for_Statistical_Machine_Translation.html">100 acl-2011-Discriminative Feature-Tied Mixture Modeling for Statistical Machine Translation</a></p>
<p>14 0.75550914 <a title="54-lda-14" href="./acl-2011-Joint_Training_of_Dependency_Parsing_Filters_through_Latent_Support_Vector_Machines.html">186 acl-2011-Joint Training of Dependency Parsing Filters through Latent Support Vector Machines</a></p>
<p>15 0.75378084 <a title="54-lda-15" href="./acl-2011-Joint_Bilingual_Sentiment_Classification_with_Unlabeled_Parallel_Corpora.html">183 acl-2011-Joint Bilingual Sentiment Classification with Unlabeled Parallel Corpora</a></p>
<p>16 0.75316083 <a title="54-lda-16" href="./acl-2011-Transition-based_Dependency_Parsing_with_Rich_Non-local_Features.html">309 acl-2011-Transition-based Dependency Parsing with Rich Non-local Features</a></p>
<p>17 0.75160807 <a title="54-lda-17" href="./acl-2011-Coreference_Resolution_with_World_Knowledge.html">85 acl-2011-Coreference Resolution with World Knowledge</a></p>
<p>18 0.74966705 <a title="54-lda-18" href="./acl-2011-Query_Weighting_for_Ranking_Model_Adaptation.html">256 acl-2011-Query Weighting for Ranking Model Adaptation</a></p>
<p>19 0.74844205 <a title="54-lda-19" href="./acl-2011-Is_Machine_Translation_Ripe_for_Cross-Lingual_Sentiment_Classification%3F.html">179 acl-2011-Is Machine Translation Ripe for Cross-Lingual Sentiment Classification?</a></p>
<p>20 0.7482456 <a title="54-lda-20" href="./acl-2011-Effects_of_Noun_Phrase_Bracketing_in_Dependency_Parsing_and_Machine_Translation.html">111 acl-2011-Effects of Noun Phrase Bracketing in Dependency Parsing and Machine Translation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
