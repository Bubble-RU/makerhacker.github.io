<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>18 acl-2011-A Latent Topic Extracting Method based on Events in a Document and its Application</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-18" href="#">acl2011-18</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>18 acl-2011-A Latent Topic Extracting Method based on Events in a Document and its Application</h1>
<br/><p>Source: <a title="acl-2011-18-pdf" href="http://aclweb.org/anthology//P/P11/P11-3006.pdf">pdf</a></p><p>Author: Risa Kitajima ; Ichiro Kobayashi</p><p>Abstract: Recently, several latent topic analysis methods such as LSI, pLSI, and LDA have been widely used for text analysis. However, those methods basically assign topics to words, but do not account for the events in a document. With this background, in this paper, we propose a latent topic extracting method which assigns topics to events. We also show that our proposed method is useful to generate a document summary based on a latent topic.</p><p>Reference: <a title="acl-2011-18-reference" href="../acl2011_reference/acl-2011-A_Latent_Topic_Extracting_Method_based_on_Events_in_a_Document_and_its_Application_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 jp s Abstract  Recently, several latent topic analysis methods such as LSI, pLSI, and LDA have been widely used for text analysis. [sent-5, score-0.538]
</p><p>2 However, those methods basically assign topics to words, but do not account for the events in a document. [sent-6, score-0.441]
</p><p>3 With this background, in this paper, we propose a latent topic extracting method which assigns topics to events. [sent-7, score-0.84]
</p><p>4 We also show that our proposed method is useful to generate a document summary based on a latent topic. [sent-8, score-0.565]
</p><p>5 1 Introduction Recently, several latent topic analysis methods such as Latent Semantic Indexing (LSI) (Deerwester et al. [sent-9, score-0.503]
</p><p>6 However, those methods basically assign topics to words, but do not account for the events in a document. [sent-12, score-0.441]
</p><p>7 Here, we define a unit of informing the content of document at the level of sentence as an “Event” 1, and propose a model that treats a document as a set of Events. [sent-13, score-0.406]
</p><p>8 We use LDA as a latent topic analysis method, and assign topics to Events in a document. [sent-14, score-0.732]
</p><p>9 To examine our proposed method’s performance on extracting latent topics from a document, we compare the accuracy of our method to that of the conventional methods through a common document retrieval task. [sent-15, score-0.978]
</p><p>10 Furthermore, as an application of our method, we apply it to a query-biased document summarization (Tombros and Sanderson, 1For the definition of an Event,  see  Section 3. [sent-16, score-0.392]
</p><p>11 jp s 1998; Okumura and Mochizuki, 2000; Berger and Mittal, 2000) to verify that the method is useful for various applications. [sent-20, score-0.083]
</p><p>12 (2010) proposed a flexible latent topics inference in which topics are assigned to phrases in a document. [sent-22, score-0.745]
</p><p>13 (2005) showed that the accuracy of document classification will be improved by introducing a feature dealing with the dependency relationships among words. [sent-24, score-0.244]
</p><p>14 In case of assigning topics to words, it is likely that two documents, which have the same word frequency in themselves, tend to be estimated as they have the same topic probablistic distribution without considering the dependency relation among words. [sent-25, score-0.682]
</p><p>15 However, there are many cases where the relationship among words is regarded as more important rather than the frequency of words as the feature identifying the topics of a document. [sent-26, score-0.273]
</p><p>16 For example, in case of classifying opinions to objects in a document, we have to identify what sort of opinion is assigned to the target objects, therefore, we have to focus on the relationship among words in a sentence, not only on the frequent words appeared in a document. [sent-27, score-0.079]
</p><p>17 For this reason, we propose a method to as-  sign topics to Events instead of words. [sent-28, score-0.277]
</p><p>18 As for studies on document summarization, there are various methods, such as the method based on word frequency (Luhn, 1958; Nenkova and Vanderwende, 2005), and the method based on a graph (Radev, 2004; Wan and Yang, 2006). [sent-29, score-0.274]
</p><p>19 Moreover, several methods using a latent topic model have been proposed (Bing et al. [sent-30, score-0.549]
</p><p>20 In those studies, the methods estimate a topic distribution on each sentence in the same way as the latent semantic analysis methods normally do that on each document, and generate a summary based on the distribution. [sent-35, score-0.706]
</p><p>21 We also show that our proposed method is useful for the document summarization based on extracting latent topics from sentences. [sent-36, score-0.981]
</p><p>22 A latent topic distribution is estimated based on this matrix. [sent-38, score-0.631]
</p><p>23 To extract these pairs, we analyze the dependency structure of sentences in a document by a Japanese dependency structure analyzer, CaboCha 2. [sent-42, score-0.267]
</p><p>24 2 Making an Event-by-Document Matrix In making a word-by-document matrix, highfrequent words appeared in any documents, and extremely infrequent words are usually not included in the matrix. [sent-45, score-0.058]
</p><p>25 We think the reason for this is because an Event, a pair of words, can be more meaningful than 2http://chasen. [sent-47, score-0.105]
</p><p>26 This means that the same process of making a word-by-document matrix cannot be applied to making an Event-by-document matrix because the nature of an Event as a feature expressing a document is different from that of a word. [sent-55, score-0.35]
</p><p>27 In concrete, if the events, which once appear in documents, would be removed from the candidates to  be a part of a document vector, there might be a case where the constructed document vector does not reflect the content of the original documents. [sent-56, score-0.406]
</p><p>28 Considering this, in order to make the constructed document vector reflect the content of the original documents, we do not remove the Event only itself extracted from a sentence, even though it appears only once in a document. [sent-57, score-0.228]
</p><p>29 3 Estimating a Topic Distribution After making an Event-by-document matrix, a latent topic distribution of each Event is estimated by means of Latent Dirichlet Allocation. [sent-59, score-0.658]
</p><p>30 Latent Dirichlet Allocation is a generative probabilistic model that allows multiple topics to occur in a document, and gets the topic distribution based on the idea that each topic emerges in a document based on a certain probability. [sent-60, score-1.062]
</p><p>31 Each topic is expressed as a multinomial distribution of words. [sent-61, score-0.38]
</p><p>32 In this study, since a topic is assigned to an Event, each topic is expressed as a multinomial distribution of Events. [sent-62, score-0.642]
</p><p>33 As a method to estimate a topic distribution, while a variational Bayes method (Blei et al. [sent-63, score-0.451]
</p><p>34 , 2006) have  been proposed, in this study we use Gibbs sampling method (Grififths and Steyvers, 2004). [sent-65, score-0.048]
</p><p>35 Furthermore, we define a sum of topic distributions of the events in a query as the topic distribution of the query. [sent-66, score-0.894]
</p><p>36 4  Performance Evaluation Experiment  Through a common document retrieval task, we compare our method with the conventional method and evaluate both of them. [sent-67, score-0.378]
</p><p>37 In concrete, we regard the documents which have a similar topic distribution to a query’s topic distribution as the result of retrieval, and then examine whether or not the estimated topic distribution can represent the latent semantics of each document based on the accuracy of retrieval results. [sent-68, score-1.775]
</p><p>38 Henceforth, we call the conventional word-based LDA “wordLDA” and our proposed event-based LDA “eventLDA”. [sent-69, score-0.091]
</p><p>39 1 Measures for Topic Distribution As measures for identifying the similarity of topic distribution, we adopt Kullback-Leibler Divergence (Kullback and Leibler, 1951), Symmetric Kullback-Leibler Divergence (Kullback and Leibler, 195 1), Jensen-Shannon Divergence (Lin, 2002), and  cosine similarity. [sent-71, score-0.512]
</p><p>40 As for wordLDA, Henning (2009) has reported that Jensen-Shannon Divergence shows the best performance among the above measures in terms of estimating the similarity between two sentences. [sent-72, score-0.193]
</p><p>41 We also compare the performance of the above measures when using eventLDA. [sent-73, score-0.067]
</p><p>42 2 Experimental Settings As for the documents used in the experiment, we use a set of data including users’ reviews and their evaluations for hotels and their facilities, provided by Rakuten Travel3. [sent-75, score-0.183]
</p><p>43 Each review has five-grade evaluations of a hotel’s facilities such as room, location, and so on. [sent-76, score-0.066]
</p><p>44 Since the data hold the relationships between objects and their evaluations, therefore, it is said that they are appropriate for the performance evaluation of our method because the relationship is usually expressed in a pair of words, i. [sent-77, score-0.127]
</p><p>45 The query we used in the experiment was “a room is good”. [sent-80, score-0.182]
</p><p>46 The total number of documents is 2000, consisting of 1000 documents randomly selected from the users’ reviews whose evaluation for “a room” is 1(bad) and 1000 documents randomly selected from the reviews whose evaluation is 5 (good). [sent-81, score-0.349]
</p><p>47 The latter  1000 documents are regarded as the objective documents in retrieval. [sent-82, score-0.186]
</p><p>48 Because of this experiment design, it is clear that the random choice for retrieving “good” vs. [sent-83, score-0.046]
</p><p>49 As for the evaluation measure, we adopt 11-point interpolated average precision. [sent-85, score-0.088]
</p><p>50 jp/ 32 ducted from the viewpoints of the proper number of topics and the most useful measure to estimate similarity. [sent-91, score-0.389]
</p><p>51 At first, we use Jensen-Shannon Divergence as the measure to estimate the similarity of topic distribution, changing the number of topics k in the following, k = 5, k = 10, k = 20, k = 50, k = 100, and k = 200. [sent-92, score-0.684]
</p><p>52 Next, the number of topics is fixed based on the result of the first process, and then it is decided which measure is the most useful by applying each measure to estimate the similarity of topic distributions. [sent-93, score-0.769]
</p><p>53 The number of trials is 20, and all trials are averaged. [sent-95, score-0.196]
</p><p>54 The same experiment is conducted for wordLDA to compare both results. [sent-96, score-0.046]
</p><p>55 3 Result Table 1 shows the retrieval result examined by 11point interpolated average precision, changing the number oftopics k. [sent-98, score-0.169]
</p><p>56 High accuracy is shown at k = 5 in eventLDA, and k = 50 in wordLDA, respectively. [sent-99, score-0.037]
</p><p>57 Overall, we see that eventLDA keeps higher accuracy than wordLDA. [sent-100, score-0.069]
</p><p>58 Table 2 shows the retrieval result examined by 11-point interpolated average precision under various measures. [sent-104, score-0.169]
</p><p>59 The number of topics k is k = 50 in wordLDA and k = 5 in eventLDA respectively, based on the above result. [sent-105, score-0.229]
</p><p>60 Under any measures, we see that eventLDA keeps higher accuracy than wordLDA. [sent-106, score-0.069]
</p><p>61 4 Discussions The result of the experiment shows that eventLDA provides a better performance than wordLDA, therefore, we see our method can properly treat the latent topics of a document. [sent-111, score-0.6]
</p><p>62 As the reason for this, we think that a topic distribution on a feature is narrowed down to some extent by using an Event as the feature instead of a word, and then as a result, the possibility of generating error topics decreased. [sent-113, score-0.687]
</p><p>63 On the other hand, a proper measure for our method is identified as cosine similarity, although cosine similarity is not a measure to estimate probabilistic distribution. [sent-114, score-0.485]
</p><p>64 It is unexpected that the measures proper to estimate probabilistic distribution got  the result of lower performance than cosine similarity. [sent-115, score-0.397]
</p><p>65 From this, there are some space where we need to examine the characteristics of topic distribution as a probabilistic distribution. [sent-116, score-0.428]
</p><p>66 5 Application to Summarization Here, we show multi-document summarization as an application of our proposed method. [sent-117, score-0.26]
</p><p>67 We make a query-biased summary, and show the effectiveness of our method by comparing the accuracy of a generated summary by our method with that of summaries by the representative summarization methods often used as benchmark methods to compare. [sent-118, score-0.448]
</p><p>68 1 Extracting Sentences by MMR-MD In extracting important sentences, considering only similarity to a given query, we may generate a redundant summary. [sent-120, score-0.144]
</p><p>69 To avoid this problem, a measure, MMR-MD (Maximal Marginal Relevance MultiDocument), was proposed (Goldstein et al. [sent-121, score-0.046]
</p><p>70 This measure is the one which prevents extracting similar sentences by providing penalty score that corresponds to similarity between a newly extracted sentence and the previously extracted sentences. [sent-123, score-0.224]
</p><p>71 [λSim1 (Ci ,Q) −(1−λ)maxCj∈SSim2(Ci,Cj)] (1) We aim to choose sentences whose content is similar to content based on a latent topic, while reducing the redundancy of choosing similar sentences to the previously chosen sentences. [sent-126, score-0.403]
</p><p>72 As the measures to estimate topic distribution similarity, we use the four measures explained in Section 4. [sent-128, score-0.547]
</p><p>73 The data consists of 30 topic sets of documents in which each set has about 10 Japanese newspaper articles, and the total number of the sentences in the data is 3587. [sent-134, score-0.429]
</p><p>74 In order to make evaluation for the result provided by our method easier, we compile a set of questions, provided by the data sets for evaluating the result of summarization, as a query, and then use it as a query for query-biased summarization. [sent-135, score-0.216]
</p><p>75 As an evaluation method, we adopt precision and coverage used at TSC3 (Hirao et al. [sent-136, score-0.047]
</p><p>76 Precision is an evaluation measure which indicates the ratio of the number of correct sentences to that of the sentences generated by the system. [sent-138, score-0.111]
</p><p>77 Coverage is an evaluation measure which indicates the degree of how the system output is close to the summary generated by a human, taking account of the redundancy. [sent-139, score-0.101]
</p><p>78 Moreover, to examine the characteristics of the proposed method, we compare both methods in  terms of the number of topics and the proper measure to estimate similarity. [sent-140, score-0.47]
</p><p>79 5 sets of documents selected at random from 30 sets of documents are used in the trials, and all the trials are totally averaged. [sent-142, score-0.284]
</p><p>80 As a target for comparison with the proposed method, we also conduct an experiment using wordLDA. [sent-143, score-0.092]
</p><p>81 3 Result As a result, there is no difference among the four measures the same result is obtained by the four measures. [sent-149, score-0.103]
</p><p>82 The number of topics providing the highest accuracy is k = 5 for wordLDA, and k = 10 for eventLDA, respectively. [sent-151, score-0.266]
</p><p>83 Furthermore, Table 4 shows comparison between the proposed method and representative summarization methods which do not deal with latent topics. [sent-157, score-0.571]
</p><p>84 As representative summarization methods to compare our method, we took up the Lead method (Brandow et al. [sent-158, score-0.284]
</p><p>85 , 1995) which is effective for document sumarization of newspapers, and the important sentence extraction-based summarization method using TF-IDF. [sent-159, score-0.405]
</p><p>86 We see that the proposed method is useful for estimating a topic on a sentence. [sent-165, score-0.398]
</p><p>87 As the reason for that the accuracy does not depend on any kinds of similarity measures, we think that an estimated topic distribution is biased to a particu-  lar topic, therefore, there was not any influence due to the kinds of similarity measures. [sent-166, score-0.737]
</p><p>88 Moreover, the proper number of topics of eventLDA is bigger than that of wordLDA. [sent-167, score-0.28]
</p><p>89 In comparison with the representative methods, the proposed method takes close accuracy to their accuracy, therefore, we see that the performance of our method is at the same level as those representative methods which directly deal with words in documents. [sent-169, score-0.293]
</p><p>90 In particular, as for coverage, our method shows high accuracy. [sent-170, score-0.048]
</p><p>91 We think the reason for this is because a comprehensive summary was made by latent topics. [sent-171, score-0.398]
</p><p>92 6  Conclusion  In this paper, we have defined a pair of words with  dependency relationship as “Event” and proposed a latent topic extracting method in which the content of a document is comprehended by assigning latent topics onto Events. [sent-172, score-1.462]
</p><p>93 We have examined the ability of our proposed method in Section 4, and as its application, we have shown a document summarization using the proposed method in Section 5. [sent-173, score-0.578]
</p><p>94 We have shown that eventLDA has higher ability than wordLDA in terms of estimating a topic distribution on even a sentence or a document; furthermore, even in case of assigning a topic on an Event, we see that latent topics can be properly estimated. [sent-174, score-1.161]
</p><p>95 Since an Event can hold a relationship between a pair of words, it can be said that our proposed method, i. [sent-175, score-0.09]
</p><p>96 , eventLDA, can comprehend the content of a document more deeper and proper than the conventional method, i. [sent-177, score-0.324]
</p><p>97 Therefore, eventLDA can be effectively applied to various document data sets rather than wordLDA can be. [sent-180, score-0.178]
</p><p>98 , an Event is also useful to estimate latent topics in a document. [sent-183, score-0.53]
</p><p>99 As future works, we will conduct experiments with various types of data and query, and further investigate the characteristic of our proposed method. [sent-184, score-0.046]
</p><p>100 Corpus and evaluation measures for multiple document summarization with multiple sources. [sent-286, score-0.424]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('eventlda', 0.456), ('wordlda', 0.364), ('topic', 0.262), ('latent', 0.241), ('topics', 0.229), ('event', 0.21), ('events', 0.183), ('summarization', 0.179), ('document', 0.178), ('okumura', 0.101), ('trials', 0.098), ('query', 0.096), ('documents', 0.093), ('lsi', 0.091), ('distribution', 0.091), ('similarity', 0.084), ('manabu', 0.081), ('kullback', 0.08), ('rakuten', 0.08), ('divergence', 0.079), ('dirichlet', 0.078), ('lda', 0.077), ('measures', 0.067), ('arora', 0.061), ('bhandari', 0.061), ('brandow', 0.061), ('grififths', 0.061), ('ochanomizu', 0.061), ('plsi', 0.061), ('tombros', 0.061), ('extracting', 0.06), ('estimate', 0.06), ('retrieval', 0.059), ('matrix', 0.059), ('think', 0.059), ('representative', 0.057), ('leibler', 0.054), ('vibhu', 0.054), ('summary', 0.052), ('cosine', 0.052), ('proper', 0.051), ('content', 0.05), ('measure', 0.049), ('hirao', 0.049), ('henning', 0.049), ('method', 0.048), ('adopt', 0.047), ('proposed', 0.046), ('experiment', 0.046), ('reason', 0.046), ('conventional', 0.045), ('relationship', 0.044), ('allocation', 0.044), ('deerwester', 0.044), ('newspaper', 0.043), ('blei', 0.043), ('estimating', 0.042), ('mittal', 0.042), ('lucy', 0.042), ('interpolated', 0.041), ('probabilistic', 0.04), ('room', 0.04), ('japanese', 0.038), ('vanderwende', 0.038), ('facilities', 0.038), ('estimated', 0.037), ('goldstein', 0.037), ('accuracy', 0.037), ('biased', 0.037), ('result', 0.036), ('objects', 0.035), ('reviews', 0.035), ('berger', 0.035), ('jp', 0.035), ('wan', 0.035), ('application', 0.035), ('examine', 0.035), ('assigning', 0.034), ('examined', 0.033), ('variational', 0.033), ('thomas', 0.032), ('keeps', 0.032), ('nenkova', 0.032), ('infrequent', 0.031), ('sentences', 0.031), ('indexing', 0.031), ('concrete', 0.03), ('dependency', 0.029), ('suzuki', 0.029), ('articles', 0.029), ('basically', 0.029), ('matsumoto', 0.029), ('evaluations', 0.028), ('summaries', 0.027), ('making', 0.027), ('multinomial', 0.027), ('bing', 0.027), ('anastasios', 0.027), ('hiroki', 0.027), ('hotels', 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="18-tfidf-1" href="./acl-2011-A_Latent_Topic_Extracting_Method_based_on_Events_in_a_Document_and_its_Application.html">18 acl-2011-A Latent Topic Extracting Method based on Events in a Document and its Application</a></p>
<p>Author: Risa Kitajima ; Ichiro Kobayashi</p><p>Abstract: Recently, several latent topic analysis methods such as LSI, pLSI, and LDA have been widely used for text analysis. However, those methods basically assign topics to words, but do not account for the events in a document. With this background, in this paper, we propose a latent topic extracting method which assigns topics to events. We also show that our proposed method is useful to generate a document summary based on a latent topic.</p><p>2 0.25045097 <a title="18-tfidf-2" href="./acl-2011-Identifying_Word_Translations_from_Comparable_Corpora_Using_Latent_Topic_Models.html">161 acl-2011-Identifying Word Translations from Comparable Corpora Using Latent Topic Models</a></p>
<p>Author: Ivan Vulic ; Wim De Smet ; Marie-Francine Moens</p><p>Abstract: A topic model outputs a set of multinomial distributions over words for each topic. In this paper, we investigate the value of bilingual topic models, i.e., a bilingual Latent Dirichlet Allocation model for finding translations of terms in comparable corpora without using any linguistic resources. Experiments on a document-aligned English-Italian Wikipedia corpus confirm that the developed methods which only use knowledge from word-topic distributions outperform methods based on similarity measures in the original word-document space. The best results, obtained by combining knowledge from wordtopic distributions with similarity measures in the original space, are also reported.</p><p>3 0.23722632 <a title="18-tfidf-3" href="./acl-2011-Automatic_Labelling_of_Topic_Models.html">52 acl-2011-Automatic Labelling of Topic Models</a></p>
<p>Author: Jey Han Lau ; Karl Grieser ; David Newman ; Timothy Baldwin</p><p>Abstract: We propose a method for automatically labelling topics learned via LDA topic models. We generate our label candidate set from the top-ranking topic terms, titles of Wikipedia articles containing the top-ranking topic terms, and sub-phrases extracted from the Wikipedia article titles. We rank the label candidates using a combination of association measures and lexical features, optionally fed into a supervised ranking model. Our method is shown to perform strongly over four independent sets of topics, significantly better than a benchmark method.</p><p>4 0.23066998 <a title="18-tfidf-4" href="./acl-2011-Entity_Set_Expansion_using_Topic_information.html">117 acl-2011-Entity Set Expansion using Topic information</a></p>
<p>Author: Kugatsu Sadamitsu ; Kuniko Saito ; Kenji Imamura ; Genichiro Kikui</p><p>Abstract: This paper proposes three modules based on latent topics of documents for alleviating “semantic drift” in bootstrapping entity set expansion. These new modules are added to a discriminative bootstrapping algorithm to realize topic feature generation, negative example selection and entity candidate pruning. In this study, we model latent topics with LDA (Latent Dirichlet Allocation) in an unsupervised way. Experiments show that the accuracy of the extracted entities is improved by 6.7 to 28.2% depending on the domain.</p><p>5 0.22003561 <a title="18-tfidf-5" href="./acl-2011-Discovery_of_Topically_Coherent_Sentences_for_Extractive_Summarization.html">98 acl-2011-Discovery of Topically Coherent Sentences for Extractive Summarization</a></p>
<p>Author: Asli Celikyilmaz ; Dilek Hakkani-Tur</p><p>Abstract: Extractive methods for multi-document summarization are mainly governed by information overlap, coherence, and content constraints. We present an unsupervised probabilistic approach to model the hidden abstract concepts across documents as well as the correlation between these concepts, to generate topically coherent and non-redundant summaries. Based on human evaluations our models generate summaries with higher linguistic quality in terms of coherence, readability, and redundancy compared to benchmark systems. Although our system is unsupervised and optimized for topical coherence, we achieve a 44.1 ROUGE on the DUC-07 test set, roughly in the range of state-of-the-art supervised models.</p><p>6 0.21137078 <a title="18-tfidf-6" href="./acl-2011-Using_Cross-Entity_Inference_to_Improve_Event_Extraction.html">328 acl-2011-Using Cross-Entity Inference to Improve Event Extraction</a></p>
<p>7 0.20100036 <a title="18-tfidf-7" href="./acl-2011-Interactive_Topic_Modeling.html">178 acl-2011-Interactive Topic Modeling</a></p>
<p>8 0.19820049 <a title="18-tfidf-8" href="./acl-2011-Peeling_Back_the_Layers%3A_Detecting_Event_Role_Fillers_in_Secondary_Contexts.html">244 acl-2011-Peeling Back the Layers: Detecting Event Role Fillers in Secondary Contexts</a></p>
<p>9 0.19432771 <a title="18-tfidf-9" href="./acl-2011-Can_Document_Selection_Help_Semi-supervised_Learning%3F_A_Case_Study_On_Event_Extraction.html">65 acl-2011-Can Document Selection Help Semi-supervised Learning? A Case Study On Event Extraction</a></p>
<p>10 0.1913576 <a title="18-tfidf-10" href="./acl-2011-Event_Extraction_as_Dependency_Parsing.html">122 acl-2011-Event Extraction as Dependency Parsing</a></p>
<p>11 0.18975671 <a title="18-tfidf-11" href="./acl-2011-Structural_Topic_Model_for_Latent_Topical_Structure_Analysis.html">287 acl-2011-Structural Topic Model for Latent Topical Structure Analysis</a></p>
<p>12 0.1749087 <a title="18-tfidf-12" href="./acl-2011-Probabilistic_Document_Modeling_for_Syntax_Removal_in_Text_Summarization.html">251 acl-2011-Probabilistic Document Modeling for Syntax Removal in Text Summarization</a></p>
<p>13 0.17332762 <a title="18-tfidf-13" href="./acl-2011-A_Hierarchical_Model_of_Web_Summaries.html">14 acl-2011-A Hierarchical Model of Web Summaries</a></p>
<p>14 0.16748151 <a title="18-tfidf-14" href="./acl-2011-A_Pilot_Study_of_Opinion_Summarization_in_Conversations.html">21 acl-2011-A Pilot Study of Opinion Summarization in Conversations</a></p>
<p>15 0.14850752 <a title="18-tfidf-15" href="./acl-2011-Learning_Word_Vectors_for_Sentiment_Analysis.html">204 acl-2011-Learning Word Vectors for Sentiment Analysis</a></p>
<p>16 0.14018549 <a title="18-tfidf-16" href="./acl-2011-Comparative_News_Summarization_Using_Linear_Programming.html">76 acl-2011-Comparative News Summarization Using Linear Programming</a></p>
<p>17 0.13219963 <a title="18-tfidf-17" href="./acl-2011-Effective_Measures_of_Domain_Similarity_for_Parsing.html">109 acl-2011-Effective Measures of Domain Similarity for Parsing</a></p>
<p>18 0.13194706 <a title="18-tfidf-18" href="./acl-2011-Improving_Question_Recommendation_by_Exploiting_Information_Need.html">169 acl-2011-Improving Question Recommendation by Exploiting Information Need</a></p>
<p>19 0.12689795 <a title="18-tfidf-19" href="./acl-2011-Query_Snowball%3A_A_Co-occurrence-based_Approach_to_Multi-document_Summarization_for_Question_Answering.html">255 acl-2011-Query Snowball: A Co-occurrence-based Approach to Multi-document Summarization for Question Answering</a></p>
<p>20 0.12415897 <a title="18-tfidf-20" href="./acl-2011-Using_Bilingual_Information_for_Cross-Language_Document_Summarization.html">326 acl-2011-Using Bilingual Information for Cross-Language Document Summarization</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.24), (1, 0.199), (2, -0.156), (3, 0.193), (4, 0.074), (5, -0.061), (6, -0.226), (7, 0.268), (8, 0.212), (9, 0.047), (10, -0.111), (11, 0.061), (12, 0.061), (13, 0.003), (14, 0.13), (15, 0.024), (16, 0.06), (17, 0.026), (18, -0.048), (19, 0.042), (20, -0.055), (21, 0.029), (22, -0.023), (23, 0.025), (24, -0.023), (25, 0.017), (26, -0.002), (27, -0.027), (28, -0.032), (29, -0.011), (30, -0.008), (31, -0.017), (32, 0.017), (33, 0.006), (34, -0.03), (35, -0.004), (36, -0.026), (37, -0.011), (38, 0.039), (39, 0.021), (40, -0.011), (41, -0.022), (42, 0.01), (43, -0.008), (44, -0.036), (45, 0.049), (46, 0.04), (47, -0.054), (48, 0.039), (49, -0.073)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97174627 <a title="18-lsi-1" href="./acl-2011-A_Latent_Topic_Extracting_Method_based_on_Events_in_a_Document_and_its_Application.html">18 acl-2011-A Latent Topic Extracting Method based on Events in a Document and its Application</a></p>
<p>Author: Risa Kitajima ; Ichiro Kobayashi</p><p>Abstract: Recently, several latent topic analysis methods such as LSI, pLSI, and LDA have been widely used for text analysis. However, those methods basically assign topics to words, but do not account for the events in a document. With this background, in this paper, we propose a latent topic extracting method which assigns topics to events. We also show that our proposed method is useful to generate a document summary based on a latent topic.</p><p>2 0.81157696 <a title="18-lsi-2" href="./acl-2011-Discovery_of_Topically_Coherent_Sentences_for_Extractive_Summarization.html">98 acl-2011-Discovery of Topically Coherent Sentences for Extractive Summarization</a></p>
<p>Author: Asli Celikyilmaz ; Dilek Hakkani-Tur</p><p>Abstract: Extractive methods for multi-document summarization are mainly governed by information overlap, coherence, and content constraints. We present an unsupervised probabilistic approach to model the hidden abstract concepts across documents as well as the correlation between these concepts, to generate topically coherent and non-redundant summaries. Based on human evaluations our models generate summaries with higher linguistic quality in terms of coherence, readability, and redundancy compared to benchmark systems. Although our system is unsupervised and optimized for topical coherence, we achieve a 44.1 ROUGE on the DUC-07 test set, roughly in the range of state-of-the-art supervised models.</p><p>3 0.79356426 <a title="18-lsi-3" href="./acl-2011-Structural_Topic_Model_for_Latent_Topical_Structure_Analysis.html">287 acl-2011-Structural Topic Model for Latent Topical Structure Analysis</a></p>
<p>Author: Hongning Wang ; Duo Zhang ; ChengXiang Zhai</p><p>Abstract: Topic models have been successfully applied to many document analysis tasks to discover topics embedded in text. However, existing topic models generally cannot capture the latent topical structures in documents. Since languages are intrinsically cohesive and coherent, modeling and discovering latent topical transition structures within documents would be beneficial for many text analysis tasks. In this work, we propose a new topic model, Structural Topic Model, which simultaneously discovers topics and reveals the latent topical structures in text through explicitly modeling topical transitions with a latent first-order Markov chain. Experiment results show that the proposed Structural Topic Model can effectively discover topical structures in text, and the identified structures significantly improve the performance of tasks such as sentence annotation and sentence ordering. ,</p><p>4 0.73878938 <a title="18-lsi-4" href="./acl-2011-Interactive_Topic_Modeling.html">178 acl-2011-Interactive Topic Modeling</a></p>
<p>Author: Yuening Hu ; Jordan Boyd-Graber ; Brianna Satinoff</p><p>Abstract: Topic models have been used extensively as a tool for corpus exploration, and a cottage industry has developed to tweak topic models to better encode human intuitions or to better model data. However, creating such extensions requires expertise in machine learning unavailable to potential end-users of topic modeling software. In this work, we develop a framework for allowing users to iteratively refine the topics discovered by models such as latent Dirichlet allocation (LDA) by adding constraints that enforce that sets of words must appear together in the same topic. We incorporate these constraints interactively by selectively removing elements in the state of a Markov Chain used for inference; we investigate a variety of methods for incorporating this information and demonstrate that these interactively added constraints improve topic usefulness for simulated and actual user sessions.</p><p>5 0.7387445 <a title="18-lsi-5" href="./acl-2011-Probabilistic_Document_Modeling_for_Syntax_Removal_in_Text_Summarization.html">251 acl-2011-Probabilistic Document Modeling for Syntax Removal in Text Summarization</a></p>
<p>Author: William M. Darling ; Fei Song</p><p>Abstract: Statistical approaches to automatic text summarization based on term frequency continue to perform on par with more complex summarization methods. To compute useful frequency statistics, however, the semantically important words must be separated from the low-content function words. The standard approach of using an a priori stopword list tends to result in both undercoverage, where syntactical words are seen as semantically relevant, and overcoverage, where words related to content are ignored. We present a generative probabilistic modeling approach to building content distributions for use with statistical multi-document summarization where the syntax words are learned directly from the data with a Hidden Markov Model and are thereby deemphasized in the term frequency statistics. This approach is compared to both a stopword-list and POS-tagging approach and our method demonstrates improved coverage on the DUC 2006 and TAC 2010 datasets using the ROUGE metric.</p><p>6 0.73622495 <a title="18-lsi-6" href="./acl-2011-A_Hierarchical_Model_of_Web_Summaries.html">14 acl-2011-A Hierarchical Model of Web Summaries</a></p>
<p>7 0.72691137 <a title="18-lsi-7" href="./acl-2011-Automatic_Labelling_of_Topic_Models.html">52 acl-2011-Automatic Labelling of Topic Models</a></p>
<p>8 0.70918411 <a title="18-lsi-8" href="./acl-2011-Identifying_Word_Translations_from_Comparable_Corpora_Using_Latent_Topic_Models.html">161 acl-2011-Identifying Word Translations from Comparable Corpora Using Latent Topic Models</a></p>
<p>9 0.70514917 <a title="18-lsi-9" href="./acl-2011-Topical_Keyphrase_Extraction_from_Twitter.html">305 acl-2011-Topical Keyphrase Extraction from Twitter</a></p>
<p>10 0.68609285 <a title="18-lsi-10" href="./acl-2011-Entity_Set_Expansion_using_Topic_information.html">117 acl-2011-Entity Set Expansion using Topic information</a></p>
<p>11 0.5561409 <a title="18-lsi-11" href="./acl-2011-A_Pilot_Study_of_Opinion_Summarization_in_Conversations.html">21 acl-2011-A Pilot Study of Opinion Summarization in Conversations</a></p>
<p>12 0.54929256 <a title="18-lsi-12" href="./acl-2011-Peeling_Back_the_Layers%3A_Detecting_Event_Role_Fillers_in_Secondary_Contexts.html">244 acl-2011-Peeling Back the Layers: Detecting Event Role Fillers in Secondary Contexts</a></p>
<p>13 0.5263117 <a title="18-lsi-13" href="./acl-2011-Comparative_News_Summarization_Using_Linear_Programming.html">76 acl-2011-Comparative News Summarization Using Linear Programming</a></p>
<p>14 0.52366263 <a title="18-lsi-14" href="./acl-2011-A_Mobile_Touchable_Application_for_Online_Topic_Graph_Extraction_and_Exploration_of_Web_Content.html">19 acl-2011-A Mobile Touchable Application for Online Topic Graph Extraction and Exploration of Web Content</a></p>
<p>15 0.521254 <a title="18-lsi-15" href="./acl-2011-Query_Snowball%3A_A_Co-occurrence-based_Approach_to_Multi-document_Summarization_for_Question_Answering.html">255 acl-2011-Query Snowball: A Co-occurrence-based Approach to Multi-document Summarization for Question Answering</a></p>
<p>16 0.50903976 <a title="18-lsi-16" href="./acl-2011-Automatic_Assessment_of_Coverage_Quality_in_Intelligence_Reports.html">47 acl-2011-Automatic Assessment of Coverage Quality in Intelligence Reports</a></p>
<p>17 0.49907714 <a title="18-lsi-17" href="./acl-2011-Template-Based_Information_Extraction_without_the_Templates.html">293 acl-2011-Template-Based Information Extraction without the Templates</a></p>
<p>18 0.49421105 <a title="18-lsi-18" href="./acl-2011-Can_Document_Selection_Help_Semi-supervised_Learning%3F_A_Case_Study_On_Event_Extraction.html">65 acl-2011-Can Document Selection Help Semi-supervised Learning? A Case Study On Event Extraction</a></p>
<p>19 0.49194273 <a title="18-lsi-19" href="./acl-2011-Towards_a_Framework_for_Abstractive_Summarization_of_Multimodal_Documents.html">308 acl-2011-Towards a Framework for Abstractive Summarization of Multimodal Documents</a></p>
<p>20 0.48897582 <a title="18-lsi-20" href="./acl-2011-Effective_Measures_of_Domain_Similarity_for_Parsing.html">109 acl-2011-Effective Measures of Domain Similarity for Parsing</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.017), (17, 0.056), (26, 0.031), (33, 0.181), (37, 0.133), (39, 0.065), (41, 0.074), (49, 0.012), (55, 0.028), (59, 0.041), (72, 0.029), (91, 0.028), (96, 0.2)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.87165242 <a title="18-lda-1" href="./acl-2011-A_Latent_Topic_Extracting_Method_based_on_Events_in_a_Document_and_its_Application.html">18 acl-2011-A Latent Topic Extracting Method based on Events in a Document and its Application</a></p>
<p>Author: Risa Kitajima ; Ichiro Kobayashi</p><p>Abstract: Recently, several latent topic analysis methods such as LSI, pLSI, and LDA have been widely used for text analysis. However, those methods basically assign topics to words, but do not account for the events in a document. With this background, in this paper, we propose a latent topic extracting method which assigns topics to events. We also show that our proposed method is useful to generate a document summary based on a latent topic.</p><p>2 0.82230633 <a title="18-lda-2" href="./acl-2011-Learning_Hierarchical_Translation_Structure_with_Linguistic_Annotations.html">202 acl-2011-Learning Hierarchical Translation Structure with Linguistic Annotations</a></p>
<p>Author: Markos Mylonakis ; Khalil Sima'an</p><p>Abstract: While it is generally accepted that many translation phenomena are correlated with linguistic structures, employing linguistic syntax for translation has proven a highly non-trivial task. The key assumption behind many approaches is that translation is guided by the source and/or target language parse, employing rules extracted from the parse tree or performing tree transformations. These approaches enforce strict constraints and might overlook important translation phenomena that cross linguistic constituents. We propose a novel flexible modelling approach to introduce linguistic information of varying granularity from the source side. Our method induces joint probability synchronous grammars and estimates their parameters, by select- ing and weighing together linguistically motivated rules according to an objective function directly targeting generalisation over future data. We obtain statistically significant improvements across 4 different language pairs with English as source, mounting up to +1.92 BLEU for Chinese as target.</p><p>3 0.82108539 <a title="18-lda-3" href="./acl-2011-A_Statistical_Tree_Annotator_and_Its_Applications.html">28 acl-2011-A Statistical Tree Annotator and Its Applications</a></p>
<p>Author: Xiaoqiang Luo ; Bing Zhao</p><p>Abstract: In many natural language applications, there is a need to enrich syntactical parse trees. We present a statistical tree annotator augmenting nodes with additional information. The annotator is generic and can be applied to a variety of applications. We report 3 such applications in this paper: predicting function tags; predicting null elements; and predicting whether a tree constituent is projectable in machine translation. Our function tag prediction system outperforms significantly published results.</p><p>4 0.81928992 <a title="18-lda-4" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>Author: Joel Lang ; Mirella Lapata</p><p>Abstract: In this paper we describe an unsupervised method for semantic role induction which holds promise for relieving the data acquisition bottleneck associated with supervised role labelers. We present an algorithm that iteratively splits and merges clusters representing semantic roles, thereby leading from an initial clustering to a final clustering of better quality. The method is simple, surprisingly effective, and allows to integrate linguistic knowledge transparently. By combining role induction with a rule-based component for argument identification we obtain an unsupervised end-to-end semantic role labeling system. Evaluation on the CoNLL 2008 benchmark dataset demonstrates that our method outperforms competitive unsupervised approaches by a wide margin.</p><p>5 0.81767392 <a title="18-lda-5" href="./acl-2011-Exploring_Entity_Relations_for_Named_Entity_Disambiguation.html">128 acl-2011-Exploring Entity Relations for Named Entity Disambiguation</a></p>
<p>Author: Danuta Ploch</p><p>Abstract: Named entity disambiguation is the task of linking an entity mention in a text to the correct real-world referent predefined in a knowledge base, and is a crucial subtask in many areas like information retrieval or topic detection and tracking. Named entity disambiguation is challenging because entity mentions can be ambiguous and an entity can be referenced by different surface forms. We present an approach that exploits Wikipedia relations between entities co-occurring with the ambiguous form to derive a range of novel features for classifying candidate referents. We find that our features improve disambiguation results significantly over a strong popularity baseline, and are especially suitable for recognizing entities not contained in the knowledge base. Our system achieves state-of-the-art results on the TAC-KBP 2009 dataset.</p><p>6 0.8173151 <a title="18-lda-6" href="./acl-2011-Piggyback%3A_Using_Search_Engines_for_Robust_Cross-Domain_Named_Entity_Recognition.html">246 acl-2011-Piggyback: Using Search Engines for Robust Cross-Domain Named Entity Recognition</a></p>
<p>7 0.81726408 <a title="18-lda-7" href="./acl-2011-An_Algorithm_for_Unsupervised_Transliteration_Mining_with_an_Application_to_Word_Alignment.html">34 acl-2011-An Algorithm for Unsupervised Transliteration Mining with an Application to Word Alignment</a></p>
<p>8 0.81637704 <a title="18-lda-8" href="./acl-2011-Fine-Grained_Class_Label_Markup_of_Search_Queries.html">137 acl-2011-Fine-Grained Class Label Markup of Search Queries</a></p>
<p>9 0.81573951 <a title="18-lda-9" href="./acl-2011-Question_Detection_in_Spoken_Conversations_Using_Textual_Conversations.html">257 acl-2011-Question Detection in Spoken Conversations Using Textual Conversations</a></p>
<p>10 0.81571758 <a title="18-lda-10" href="./acl-2011-Domain_Adaptation_for_Machine_Translation_by_Mining_Unseen_Words.html">104 acl-2011-Domain Adaptation for Machine Translation by Mining Unseen Words</a></p>
<p>11 0.81545806 <a title="18-lda-11" href="./acl-2011-A_Bayesian_Model_for_Unsupervised_Semantic_Parsing.html">3 acl-2011-A Bayesian Model for Unsupervised Semantic Parsing</a></p>
<p>12 0.81507266 <a title="18-lda-12" href="./acl-2011-Semi-supervised_Relation_Extraction_with_Large-scale_Word_Clustering.html">277 acl-2011-Semi-supervised Relation Extraction with Large-scale Word Clustering</a></p>
<p>13 0.81500888 <a title="18-lda-13" href="./acl-2011-Parsing_the_Internal_Structure_of_Words%3A_A_New_Paradigm_for_Chinese_Word_Segmentation.html">241 acl-2011-Parsing the Internal Structure of Words: A New Paradigm for Chinese Word Segmentation</a></p>
<p>14 0.81494546 <a title="18-lda-14" href="./acl-2011-Effects_of_Noun_Phrase_Bracketing_in_Dependency_Parsing_and_Machine_Translation.html">111 acl-2011-Effects of Noun Phrase Bracketing in Dependency Parsing and Machine Translation</a></p>
<p>15 0.81481254 <a title="18-lda-15" href="./acl-2011-Unsupervised_Bilingual_Morpheme_Segmentation_and_Alignment_with_Context-rich_Hidden_Semi-Markov_Models.html">318 acl-2011-Unsupervised Bilingual Morpheme Segmentation and Alignment with Context-rich Hidden Semi-Markov Models</a></p>
<p>16 0.81474853 <a title="18-lda-16" href="./acl-2011-Beam-Width_Prediction_for_Efficient_Context-Free_Parsing.html">58 acl-2011-Beam-Width Prediction for Efficient Context-Free Parsing</a></p>
<p>17 0.81428468 <a title="18-lda-17" href="./acl-2011-A_Pronoun_Anaphora_Resolution_System_based_on_Factorial_Hidden_Markov_Models.html">23 acl-2011-A Pronoun Anaphora Resolution System based on Factorial Hidden Markov Models</a></p>
<p>18 0.81415427 <a title="18-lda-18" href="./acl-2011-Exploiting_Syntactico-Semantic_Structures_for_Relation_Extraction.html">126 acl-2011-Exploiting Syntactico-Semantic Structures for Relation Extraction</a></p>
<p>19 0.81368542 <a title="18-lda-19" href="./acl-2011-An_exponential_translation_model_for_target_language_morphology.html">44 acl-2011-An exponential translation model for target language morphology</a></p>
<p>20 0.81270599 <a title="18-lda-20" href="./acl-2011-Using_Bilingual_Parallel_Corpora_for_Cross-Lingual_Textual_Entailment.html">327 acl-2011-Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
