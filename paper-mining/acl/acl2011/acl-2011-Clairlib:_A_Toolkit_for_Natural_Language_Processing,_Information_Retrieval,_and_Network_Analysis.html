<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>67 acl-2011-Clairlib: A Toolkit for Natural Language Processing, Information Retrieval, and Network Analysis</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-67" href="#">acl2011-67</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>67 acl-2011-Clairlib: A Toolkit for Natural Language Processing, Information Retrieval, and Network Analysis</h1>
<br/><p>Source: <a title="acl-2011-67-pdf" href="http://aclweb.org/anthology//P/P11/P11-4021.pdf">pdf</a></p><p>Author: Amjad Abu-Jbara ; Dragomir Radev</p><p>Abstract: In this paper we present Clairlib, an opensource toolkit for Natural Language Processing, Information Retrieval, and Network Analysis. Clairlib provides an integrated framework intended to simplify a number of generic tasks within and across those three areas. It has a command-line interface, a graphical interface, and a documented API. Clairlib is compatible with all the common platforms and operating systems. In addition to its own functionality, it provides interfaces to external software and corpora. Clairlib comes with a comprehensive documentation and a rich set of tutorials and visual demos.</p><p>Reference: <a title="acl-2011-67-reference" href="../acl2011_reference/acl-2011-Clairlib%3A_A_Toolkit_for_Natural_Language_Processing%2C_Information_Retrieval%2C_and_Network_Analysis_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 amjbara@umi ch edu Abstract In this paper we present Clairlib, an opensource toolkit for Natural Language Processing, Information Retrieval, and Network Analysis. [sent-2, score-0.021]
</p><p>2 Clairlib provides an integrated framework intended to simplify a number of generic tasks within and across those three areas. [sent-3, score-0.077]
</p><p>3 It has a command-line interface, a graphical interface, and a documented API. [sent-4, score-0.072]
</p><p>4 Clairlib is compatible with all the common platforms and operating systems. [sent-5, score-0.051]
</p><p>5 In addition to its own functionality, it provides interfaces to external software and corpora. [sent-6, score-0.058]
</p><p>6 Clairlib comes with a comprehensive documentation and a rich set of tutorials and visual demos. [sent-7, score-0.137]
</p><p>7 1 Introduction  The development of software packages and code libraries that implement algorithms and perform tasks in scientific areas is of great advantage for both researchers and educators. [sent-8, score-0.154]
</p><p>8 The availability of these tools saves the researchers a lot of the time and the effort needed to implement the new approaches they propose and conduct experiments to verify their hypotheses. [sent-9, score-0.107]
</p><p>9 Educators also find these tools useful in class demonstrations and for setting up practical programming assignments and projects for their students. [sent-10, score-0.155]
</p><p>10 A large number of systems have been developed over the years to solve problems and perform tasks in Natural Language Processing, Information Retrieval, or Network Analysis. [sent-11, score-0.028]
</p><p>11 Many of these systems perform specific tasks such as parsing, Graph Partitioning, co-reference resolution, web crawling etc. [sent-12, score-0.06]
</p><p>12 Some other systems are frameworks for performing generic tasks in one area of focus such as 121 Dragomir Radev EECS Department and School of Information  University of Michigan Ann Arbor, MI, USA radev@umi ch . [sent-13, score-0.028]
</p><p>13 This paper presents Clairlib, an open-source toolkit that contains a suit of modules for generic tasks in Natural Language Processing (NLP), Information Retrieval (IR), and Network Analysis (NA). [sent-16, score-0.155]
</p><p>14 While many systems have been developed to address tasks or subtasks in one of these areas as we have just mentioned, Clairlib provides one integrated environment that addresses tasks in the three areas. [sent-17, score-0.145]
</p><p>15 Clairlib is designed to meet the needs of researchers and educators with varying purposes and backgrounds. [sent-19, score-0.053]
</p><p>16 For this purpose, Clairlib provides three different interfaces to its functionality: a  graphical interface, a command-line interface, and an application programming interface (API). [sent-20, score-0.248]
</p><p>17 It has been heavily developed since then until it witnessed a qualitative leap by adding the Graphical Interface and many new features to the latest version that we are presenting here. [sent-23, score-0.032]
</p><p>18 1c 12 S0y1s1te Amss Doecmiaotinosntr faotiron Cos,m papguetast 1io2n1aì°½&euro;&ldquo;l1 L2in6g,uistics all the common platforms and operating systems. [sent-31, score-0.033]
</p><p>19 Clairlib has been used in several research projects to implement systems and conduct experiments. [sent-33, score-0.083]
</p><p>20 2  System Overview  Clairlib consists of three main components: the core library, the command-line interface, and the graphical user interface. [sent-40, score-0.096]
</p><p>21 The three components were designed and connected together in a manner that aims to achieve simplicity, integration, and ease of use. [sent-41, score-0.023]
</p><p>22 1 Modules The core of Clairlib is a collection of more than 100 modules organized in a shallow hierarchy, each of which performs a specific task or implements a certain algorithm. [sent-44, score-0.131]
</p><p>23 A set of core modules define the data structures and perform the basic processing tasks. [sent-45, score-0.131]
</p><p>24 For example, Clair::Document defines a data structure for holding textual data in various formats, and performs the basic text processing tasks such as tok-  enization, stemming, tag stripping, etc. [sent-46, score-0.028]
</p><p>25 Another set of modules perform more specific tasks in the three areas of focus (NLP, IR, and NA). [sent-47, score-0.152]
</p><p>26 For example, Clair::Bio::GIN::Interaction is devoted to protein-protein interaction extraction from biomedical text. [sent-48, score-0.104]
</p><p>27 A third set contains modules that interface Clairlib to external tools. [sent-49, score-0.229]
</p><p>28 For example, Clair::Utils::Parse provides an interface to Charniak parser (Charniak, 2000), Stanford parser (Klein and Manning, 2003), and Chunklink2. [sent-50, score-0.154]
</p><p>29 The API is oriented to developers to help them write applications and build systems on top of Clairlib modules; and to researchers to help them write applications and setup custom experiments for their research. [sent-52, score-0.096]
</p><p>30 2 Command-line Interface The command-line interface provides an easy access to many of the tasks that Clairlib modules implement. [sent-57, score-0.288]
</p><p>31 Each command is documented and demonstrated in  one or more tutorials. [sent-59, score-0.052]
</p><p>32 The function of each command can be customized by passing arguments with the command. [sent-60, score-0.029]
</p><p>33 net -method GirvanNewman  -n  4  uses the GrivanNewman algorithm to divide a given graph into 4 partitions. [sent-63, score-0.019]
</p><p>34 3 Graphical User Interface The graphical user interface (GUI) is an important feature that has been recently added to Clairlib and constituted a quantum leap in its development. [sent-65, score-0.226]
</p><p>35 The main purpose of the GUI is to make the rich set of Clairlib functionalities easier to access by a larger number of users from various levels and backgrounds especially students and users with limited or no programming experience. [sent-66, score-0.243]
</p><p>36 It is also intended to help students do their assignments, projects, and research experiments in an interactive environment. [sent-67, score-0.06]
</p><p>37 We believe that visual tools facilitate understanding and make learning a more enjoyable experience for many students. [sent-68, score-0.086]
</p><p>38 Therefore, while it is suitable for small and medium  scale projects, it is not guaranteed to work efficiently for large projects that involve large datasets and require heavy processing. [sent-70, score-0.034]
</p><p>39 The command-line interface is a better choice for large projects. [sent-71, score-0.123]
</p><p>40 , and 5) perform several operations on a network such as random walk, label propagation, partitioning, etc. [sent-74, score-0.178]
</p><p>41 This component uses the open source library, JUNG3 to visualize networks. [sent-75, score-0.058]
</p><p>42 net/  Figure 1: A screenshot for the network visualization component of Clairlib  a screenshot for the Network Visualizer. [sent-78, score-0.339]
</p><p>43 The Text Processing component allows users to process textual data published on the internet or imported from a file stored on the disk. [sent-79, score-0.093]
</p><p>44 Most of the text processing capabilities implemented in Clairlib core library are available through this component. [sent-81, score-0.045]
</p><p>45 Figure 2 shows a screenshot of the text processing component. [sent-82, score-0.043]
</p><p>46 The Corpus Processing component allows users to build a corpus of textual data out of a collection of files in plain, HTML, or PDF format; or by crawling a website. [sent-83, score-0.117]
</p><p>47 Several tasks could be performed on a corpus such as indexing, querying, summarization,  information extraction, hyperlink network construction, etc. [sent-84, score-0.206]
</p><p>48 Although these components can be run independently, they are very integrated and designed to easily interact with each other. [sent-85, score-0.041]
</p><p>49 For example, a user can crawl a website using the Corpus component, then switch to the Text Processing component to extract the text from the web documents and stem all the words, then switch back to the Corpus component to build a document similarity graph. [sent-86, score-0.156]
</p><p>50 The graph can then be taken to the Network component to be visualized and analyzed. [sent-87, score-0.056]
</p><p>51 The documentation contains the installation information for different platforms, a description of all Clairlib components and modules, and a lot of usage examples. [sent-90, score-0.072]
</p><p>52 In addition to this documentation, Clairlib provides three other resources: API Reference  The API Reference provides a complete description of each module in the library. [sent-91, score-0.113]
</p><p>53 This reference is useful for developers who want to use Clairlib modules in their own applications and systems. [sent-93, score-0.127]
</p><p>54 Tutorials Tutorials teach users how to use Clairlib by examples. [sent-95, score-0.056]
</p><p>55 Each tutorial addresses a specific task and provides a set of instructions to complete the task using Clairlib command-line tools or its API. [sent-96, score-0.068]
</p><p>56 Visual Demos Visual demos target the users of the graphical interface. [sent-97, score-0.127]
</p><p>57 The demos visually show how to start the GUI and how to use its components to perform several tasks. [sent-98, score-0.071]
</p><p>58 Figure 2: A screenshot for the text processing component of Clairlib  3  Functionality  Clairlib provides modules and tools for a broad spectrum of tasks. [sent-99, score-0.254]
</p><p>59 Some functionalities, however, are imported from other open-source packages or external software. [sent-101, score-0.054]
</p><p>60 This section lists the main functionalities categorized by their areas. [sent-102, score-0.105]
</p><p>61 2 Information Retrieval IR functionalities include Web Crawling, Indexing, TF-IDF, PageRank, Phrase Based Retrieval, Fuzzy OR Queries, Latent Semantic Indexing, Web Search, Automatic Link Extraction, and Protein-Protein Interaction Extraction. [sent-106, score-0.105]
</p><p>62 3 Network Analysis Network Analysis functionalities include Network Statistics, Random Network Generation, Network Visualization, Network Partitioning, Community 124 Finding, Random Walks, Flow Networks, Signed Networks, and Semi-supervised Graph-based Classification. [sent-108, score-0.105]
</p><p>63 Some of these functionalities are implemented using several approaches. [sent-110, score-0.105]
</p><p>64 For example, Clairlib have implementations for 5 graph partitioning algorithms. [sent-111, score-0.06]
</p><p>65 4  Uses of Clairlib  The diverse set of domains that Clairlib covers and the different types of interfaces it provides make it suitable for use in many contexts. [sent-113, score-0.058]
</p><p>66 Education Clairlib contains visual tools that instructors can use to do class demonstrations to help their students understand the basic concepts and the algorithms they face during their study. [sent-115, score-0.221]
</p><p>67 For example, the random walk simulator can be used to teach the students how random walk works by showing a sample network and then walk randomly step-by-step through it and show the students how the probabilities change after each step. [sent-116, score-0.435]
</p><p>68 It can also be used to create assignments of varying levels of difficulty and different scopes. [sent-117, score-0.043]
</p><p>69 Instructors may ask their students to do experiments with a dataset using Clairlib, write applications that use the API, extend an existing module, or contribute new modules to Clairlib. [sent-118, score-0.184]
</p><p>70 One example could be to ask the students to a build a simple information retrieval  system that indexes a collection of documents and executes search queries on it. [sent-119, score-0.117]
</p><p>71 Clairlib has been used to create assignments and projects in NLP and IR classes at the University of Michigan and Columbia University. [sent-120, score-0.077]
</p><p>72 The experience was positive for both the instructors and the students. [sent-121, score-0.052]
</p><p>73 The instructors were able to design assignments that cover several aspects of the course and can be done in a reasonable amount of time. [sent-122, score-0.095]
</p><p>74 The students used the API to accomplish their assignments and projects. [sent-123, score-0.103]
</p><p>75 This helped them focus on the important concepts rather than diving into fine programming details. [sent-124, score-0.018]
</p><p>76 This makes it a good resource for researchers to build systems and conduct experiments. [sent-127, score-0.064]
</p><p>77 Example: Protein-Protein Interaction Extraction This is an example of a project that builds an information extraction system and uses Clairlib as its main processing component (Ozgur and Radev, 2009). [sent-134, score-0.037]
</p><p>78 Figure 3 shows an example protein interaction network extracted from the abstracts of a collection of biomedical articles from PubMed. [sent-137, score-0.33]
</p><p>79 This network is then analyzed to compute node centralities and the basic network statistics. [sent-138, score-0.388]
</p><p>80 Example: Scientific Paper Summarization Using Citation Networks This is an example of a research work that used Clairlib to implement an approach and conduct experiments to support the research hypothesis. [sent-139, score-0.049]
</p><p>81 Qazvinian and Radev (2009) used Clairlib to implement their method for citation-based summarization. [sent-140, score-0.024]
</p><p>82 Example: Text Classification This is an example of a teaching assignment that  was used in an introductory course on information retrieval at the University of Michigan. [sent-142, score-0.039]
</p><p>83 5  Conclusions  Clairlib is a broad-coverage toolkit for Natural Language Processing, Information Retrieval, and Network Analysis. [sent-144, score-0.021]
</p><p>84 It provides a simple, integrated, interactive, and extensible framework for education and research uses. [sent-145, score-0.031]
</p><p>85 It provides an API, a command-  Figure 3: Clairlib used to construct and analyze a protein network extracted from biomedical articles  line interface, and graphical user interface for the convenience of users with varying purposes and backgrounds. [sent-146, score-0.545]
</p><p>86 It has been tested for various types of tasks in various environments. [sent-148, score-0.028]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('clairlib', 0.886), ('network', 0.178), ('interface', 0.123), ('modules', 0.106), ('functionalities', 0.105), ('radev', 0.083), ('gui', 0.078), ('protein', 0.07), ('api', 0.069), ('clair', 0.064), ('students', 0.06), ('dragomir', 0.054), ('instructors', 0.052), ('module', 0.051), ('graphical', 0.049), ('documentation', 0.049), ('visual', 0.049), ('demos', 0.048), ('screenshot', 0.043), ('assignments', 0.043), ('ozgur', 0.043), ('biomedical', 0.042), ('partitioning', 0.041), ('hassan', 0.04), ('interaction', 0.04), ('retrieval', 0.039), ('networks', 0.039), ('tutorials', 0.039), ('summarization', 0.038), ('visualization', 0.038), ('tools', 0.037), ('component', 0.037), ('walk', 0.037), ('scientific', 0.035), ('projects', 0.034), ('qazvinian', 0.033), ('platforms', 0.033), ('batagelj', 0.032), ('centralities', 0.032), ('educators', 0.032), ('leap', 0.032), ('mrvar', 0.032), ('pajek', 0.032), ('crawling', 0.032), ('provides', 0.031), ('users', 0.03), ('command', 0.029), ('tasks', 0.028), ('arzucan', 0.028), ('packages', 0.028), ('stripping', 0.028), ('interfaces', 0.027), ('functionality', 0.027), ('michigan', 0.026), ('fader', 0.026), ('cunningham', 0.026), ('diameter', 0.026), ('imported', 0.026), ('teach', 0.026), ('core', 0.025), ('ahmed', 0.025), ('perl', 0.025), ('amjad', 0.025), ('conduct', 0.025), ('implement', 0.024), ('indexing', 0.024), ('ir', 0.024), ('demonstrations', 0.023), ('nltk', 0.023), ('documented', 0.023), ('components', 0.023), ('user', 0.022), ('gate', 0.022), ('devoted', 0.022), ('environment', 0.022), ('eecs', 0.021), ('pdf', 0.021), ('switch', 0.021), ('umi', 0.021), ('html', 0.021), ('researchers', 0.021), ('toolkit', 0.021), ('lexrank', 0.021), ('formats', 0.021), ('visualize', 0.021), ('developers', 0.021), ('library', 0.02), ('graph', 0.019), ('anthony', 0.019), ('xml', 0.019), ('compatible', 0.018), ('bird', 0.018), ('guess', 0.018), ('political', 0.018), ('integrated', 0.018), ('areas', 0.018), ('build', 0.018), ('write', 0.018), ('programming', 0.018), ('citation', 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="67-tfidf-1" href="./acl-2011-Clairlib%3A_A_Toolkit_for_Natural_Language_Processing%2C_Information_Retrieval%2C_and_Network_Analysis.html">67 acl-2011-Clairlib: A Toolkit for Natural Language Processing, Information Retrieval, and Network Analysis</a></p>
<p>Author: Amjad Abu-Jbara ; Dragomir Radev</p><p>Abstract: In this paper we present Clairlib, an opensource toolkit for Natural Language Processing, Information Retrieval, and Network Analysis. Clairlib provides an integrated framework intended to simplify a number of generic tasks within and across those three areas. It has a command-line interface, a graphical interface, and a documented API. Clairlib is compatible with all the common platforms and operating systems. In addition to its own functionality, it provides interfaces to external software and corpora. Clairlib comes with a comprehensive documentation and a rich set of tutorials and visual demos.</p><p>2 0.075185679 <a title="67-tfidf-2" href="./acl-2011-Identifying_the_Semantic_Orientation_of_Foreign_Words.html">162 acl-2011-Identifying the Semantic Orientation of Foreign Words</a></p>
<p>Author: Ahmed Hassan ; Amjad AbuJbara ; Rahul Jha ; Dragomir Radev</p><p>Abstract: We present a method for identifying the positive or negative semantic orientation of foreign words. Identifying the semantic orientation of words has numerous applications in the areas of text classification, analysis of product review, analysis of responses to surveys, and mining online discussions. Identifying the semantic orientation of English words has been extensively studied in literature. Most of this work assumes the existence of resources (e.g. Wordnet, seeds, etc) that do not exist in foreign languages. In this work, we describe a method based on constructing a multilingual network connecting English and foreign words. We use this network to identify the semantic orientation of foreign words based on connection between words in the same language as well as multilingual connections. The method is experimentally tested using a manually labeled set of positive and negative words and has shown very promising results.</p><p>3 0.073836043 <a title="67-tfidf-3" href="./acl-2011-Insights_from_Network_Structure_for_Text_Mining.html">174 acl-2011-Insights from Network Structure for Text Mining</a></p>
<p>Author: Zornitsa Kozareva ; Eduard Hovy</p><p>Abstract: Text mining and data harvesting algorithms have become popular in the computational linguistics community. They employ patterns that specify the kind of information to be harvested, and usually bootstrap either the pattern learning or the term harvesting process (or both) in a recursive cycle, using data learned in one step to generate more seeds for the next. They therefore treat the source text corpus as a network, in which words are the nodes and relations linking them are the edges. The results of computational network analysis, especially from the world wide web, are thus applicable. Surprisingly, these results have not yet been broadly introduced into the computational linguistics community. In this paper we show how various results apply to text mining, how they explain some previously observed phenomena, and how they can be helpful for computational linguistics applications.</p><p>4 0.073104478 <a title="67-tfidf-4" href="./acl-2011-Coherent_Citation-Based_Summarization_of_Scientific_Papers.html">71 acl-2011-Coherent Citation-Based Summarization of Scientific Papers</a></p>
<p>Author: Amjad Abu-Jbara ; Dragomir Radev</p><p>Abstract: In citation-based summarization, text written by several researchers is leveraged to identify the important aspects of a target paper. Previous work on this problem focused almost exclusively on its extraction aspect (i.e. selecting a representative set of citation sentences that highlight the contribution of the target paper). Meanwhile, the fluency of the produced summaries has been mostly ignored. For example, diversity, readability, cohesion, and ordering of the sentences included in the summary have not been thoroughly considered. This resulted in noisy and confusing summaries. In this work, we present an approach for producing readable and cohesive citation-based summaries. Our experiments show that the pro- posed approach outperforms several baselines in terms of both extraction quality and fluency.</p><p>5 0.05854968 <a title="67-tfidf-5" href="./acl-2011-SciSumm%3A_A_Multi-Document_Summarization_System_for_Scientific_Articles.html">270 acl-2011-SciSumm: A Multi-Document Summarization System for Scientific Articles</a></p>
<p>Author: Nitin Agarwal ; Ravi Shankar Reddy ; Kiran GVR ; Carolyn Penstein Rose</p><p>Abstract: In this demo, we present SciSumm, an interactive multi-document summarization system for scientific articles. The document collection to be summarized is a list of papers cited together within the same source article, otherwise known as a co-citation. At the heart of the approach is a topic based clustering of fragments extracted from each article based on queries generated from the context surrounding the co-cited list of papers. This analysis enables the generation of an overview of common themes from the co-cited papers that relate to the context in which the co-citation was found. SciSumm is currently built over the 2008 ACL Anthology, however the gen- eralizable nature of the summarization techniques and the extensible architecture makes it possible to use the system with other corpora where a citation network is available. Evaluation results on the same corpus demonstrate that our system performs better than an existing widely used multi-document summarization system (MEAD).</p><p>6 0.055911761 <a title="67-tfidf-6" href="./acl-2011-An_Interface_for_Rapid_Natural_Language_Processing_Development_in_UIMA.html">42 acl-2011-An Interface for Rapid Natural Language Processing Development in UIMA</a></p>
<p>7 0.054999288 <a title="67-tfidf-7" href="./acl-2011-Social_Network_Extraction_from_Texts%3A_A_Thesis_Proposal.html">286 acl-2011-Social Network Extraction from Texts: A Thesis Proposal</a></p>
<p>8 0.041559275 <a title="67-tfidf-8" href="./acl-2011-Machine_Translation_System_Combination_by_Confusion_Forest.html">217 acl-2011-Machine Translation System Combination by Confusion Forest</a></p>
<p>9 0.038562614 <a title="67-tfidf-9" href="./acl-2011-Towards_a_Framework_for_Abstractive_Summarization_of_Multimodal_Documents.html">308 acl-2011-Towards a Framework for Abstractive Summarization of Multimodal Documents</a></p>
<p>10 0.038414657 <a title="67-tfidf-10" href="./acl-2011-Learning_From_Collective_Human_Behavior_to_Introduce_Diversity_in_Lexical_Choice.html">201 acl-2011-Learning From Collective Human Behavior to Introduce Diversity in Lexical Choice</a></p>
<p>11 0.036976077 <a title="67-tfidf-11" href="./acl-2011-A_Speech-based_Just-in-Time_Retrieval_System_using_Semantic_Search.html">26 acl-2011-A Speech-based Just-in-Time Retrieval System using Semantic Search</a></p>
<p>12 0.036260698 <a title="67-tfidf-12" href="./acl-2011-Interactive_Group_Suggesting_for_Twitter.html">177 acl-2011-Interactive Group Suggesting for Twitter</a></p>
<p>13 0.035431664 <a title="67-tfidf-13" href="./acl-2011-Collective_Classification_of_Congressional_Floor-Debate_Transcripts.html">73 acl-2011-Collective Classification of Congressional Floor-Debate Transcripts</a></p>
<p>14 0.033150729 <a title="67-tfidf-14" href="./acl-2011-Sentiment_Analysis_of_Citations_using_Sentence_Structure-Based_Features.html">281 acl-2011-Sentiment Analysis of Citations using Sentence Structure-Based Features</a></p>
<p>15 0.032313619 <a title="67-tfidf-15" href="./acl-2011-MACAON_An_NLP_Tool_Suite_for_Processing_Word_Lattices.html">215 acl-2011-MACAON An NLP Tool Suite for Processing Word Lattices</a></p>
<p>16 0.032027688 <a title="67-tfidf-16" href="./acl-2011-Engkoo%3A_Mining_the_Web_for_Language_Learning.html">115 acl-2011-Engkoo: Mining the Web for Language Learning</a></p>
<p>17 0.030402383 <a title="67-tfidf-17" href="./acl-2011-Automatic_Assessment_of_Coverage_Quality_in_Intelligence_Reports.html">47 acl-2011-Automatic Assessment of Coverage Quality in Intelligence Reports</a></p>
<p>18 0.030234413 <a title="67-tfidf-18" href="./acl-2011-Blast%3A_A_Tool_for_Error_Analysis_of_Machine_Translation_Output.html">62 acl-2011-Blast: A Tool for Error Analysis of Machine Translation Output</a></p>
<p>19 0.028698036 <a title="67-tfidf-19" href="./acl-2011-Event_Extraction_as_Dependency_Parsing.html">122 acl-2011-Event Extraction as Dependency Parsing</a></p>
<p>20 0.027876189 <a title="67-tfidf-20" href="./acl-2011-A_Latent_Topic_Extracting_Method_based_on_Events_in_a_Document_and_its_Application.html">18 acl-2011-A Latent Topic Extracting Method based on Events in a Document and its Application</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.077), (1, 0.035), (2, -0.025), (3, 0.019), (4, -0.026), (5, -0.005), (6, -0.022), (7, 0.005), (8, 0.013), (9, -0.028), (10, -0.041), (11, -0.014), (12, -0.021), (13, -0.01), (14, -0.067), (15, -0.048), (16, 0.028), (17, -0.018), (18, 0.008), (19, -0.022), (20, 0.01), (21, 0.034), (22, 0.039), (23, 0.023), (24, 0.03), (25, -0.049), (26, -0.013), (27, 0.094), (28, -0.074), (29, -0.029), (30, -0.038), (31, 0.022), (32, -0.003), (33, -0.039), (34, 0.043), (35, -0.049), (36, 0.001), (37, -0.028), (38, -0.037), (39, 0.059), (40, 0.047), (41, -0.003), (42, -0.007), (43, -0.018), (44, 0.058), (45, -0.063), (46, -0.054), (47, -0.029), (48, -0.021), (49, -0.014)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.90697592 <a title="67-lsi-1" href="./acl-2011-Clairlib%3A_A_Toolkit_for_Natural_Language_Processing%2C_Information_Retrieval%2C_and_Network_Analysis.html">67 acl-2011-Clairlib: A Toolkit for Natural Language Processing, Information Retrieval, and Network Analysis</a></p>
<p>Author: Amjad Abu-Jbara ; Dragomir Radev</p><p>Abstract: In this paper we present Clairlib, an opensource toolkit for Natural Language Processing, Information Retrieval, and Network Analysis. Clairlib provides an integrated framework intended to simplify a number of generic tasks within and across those three areas. It has a command-line interface, a graphical interface, and a documented API. Clairlib is compatible with all the common platforms and operating systems. In addition to its own functionality, it provides interfaces to external software and corpora. Clairlib comes with a comprehensive documentation and a rich set of tutorials and visual demos.</p><p>2 0.57720554 <a title="67-lsi-2" href="./acl-2011-Wikulu%3A_An_Extensible_Architecture_for_Integrating_Natural_Language_Processing_Techniques_with_Wikis.html">338 acl-2011-Wikulu: An Extensible Architecture for Integrating Natural Language Processing Techniques with Wikis</a></p>
<p>Author: Daniel Bar ; Nicolai Erbs ; Torsten Zesch ; Iryna Gurevych</p><p>Abstract: We present Wikulu1, a system focusing on supporting wiki users with their everyday tasks by means of an intelligent interface. Wikulu is implemented as an extensible architecture which transparently integrates natural language processing (NLP) techniques with wikis. It is designed to be deployed with any wiki platform, and the current prototype integrates a wide range of NLP algorithms such as keyphrase extraction, link discovery, text segmentation, summarization, or text similarity. Additionally, we show how Wikulu can be applied for visually analyzing the results of NLP algorithms, educational purposes, and enabling semantic wikis.</p><p>3 0.56769621 <a title="67-lsi-3" href="./acl-2011-Collective_Classification_of_Congressional_Floor-Debate_Transcripts.html">73 acl-2011-Collective Classification of Congressional Floor-Debate Transcripts</a></p>
<p>Author: Clinton Burfoot ; Steven Bird ; Timothy Baldwin</p><p>Abstract: This paper explores approaches to sentiment classification of U.S. Congressional floordebate transcripts. Collective classification techniques are used to take advantage of the informal citation structure present in the debates. We use a range of methods based on local and global formulations and introduce novel approaches for incorporating the outputs of machine learners into collective classification algorithms. Our experimental evaluation shows that the mean-field algorithm obtains the best results for the task, significantly outperforming the benchmark technique.</p><p>4 0.54942882 <a title="67-lsi-4" href="./acl-2011-Coherent_Citation-Based_Summarization_of_Scientific_Papers.html">71 acl-2011-Coherent Citation-Based Summarization of Scientific Papers</a></p>
<p>Author: Amjad Abu-Jbara ; Dragomir Radev</p><p>Abstract: In citation-based summarization, text written by several researchers is leveraged to identify the important aspects of a target paper. Previous work on this problem focused almost exclusively on its extraction aspect (i.e. selecting a representative set of citation sentences that highlight the contribution of the target paper). Meanwhile, the fluency of the produced summaries has been mostly ignored. For example, diversity, readability, cohesion, and ordering of the sentences included in the summary have not been thoroughly considered. This resulted in noisy and confusing summaries. In this work, we present an approach for producing readable and cohesive citation-based summaries. Our experiments show that the pro- posed approach outperforms several baselines in terms of both extraction quality and fluency.</p><p>5 0.54758579 <a title="67-lsi-5" href="./acl-2011-Insights_from_Network_Structure_for_Text_Mining.html">174 acl-2011-Insights from Network Structure for Text Mining</a></p>
<p>Author: Zornitsa Kozareva ; Eduard Hovy</p><p>Abstract: Text mining and data harvesting algorithms have become popular in the computational linguistics community. They employ patterns that specify the kind of information to be harvested, and usually bootstrap either the pattern learning or the term harvesting process (or both) in a recursive cycle, using data learned in one step to generate more seeds for the next. They therefore treat the source text corpus as a network, in which words are the nodes and relations linking them are the edges. The results of computational network analysis, especially from the world wide web, are thus applicable. Surprisingly, these results have not yet been broadly introduced into the computational linguistics community. In this paper we show how various results apply to text mining, how they explain some previously observed phenomena, and how they can be helpful for computational linguistics applications.</p><p>6 0.51469755 <a title="67-lsi-6" href="./acl-2011-Learning_From_Collective_Human_Behavior_to_Introduce_Diversity_in_Lexical_Choice.html">201 acl-2011-Learning From Collective Human Behavior to Introduce Diversity in Lexical Choice</a></p>
<p>7 0.5049572 <a title="67-lsi-7" href="./acl-2011-SciSumm%3A_A_Multi-Document_Summarization_System_for_Scientific_Articles.html">270 acl-2011-SciSumm: A Multi-Document Summarization System for Scientific Articles</a></p>
<p>8 0.49890015 <a title="67-lsi-8" href="./acl-2011-A_Speech-based_Just-in-Time_Retrieval_System_using_Semantic_Search.html">26 acl-2011-A Speech-based Just-in-Time Retrieval System using Semantic Search</a></p>
<p>9 0.48891351 <a title="67-lsi-9" href="./acl-2011-A_Mobile_Touchable_Application_for_Online_Topic_Graph_Extraction_and_Exploration_of_Web_Content.html">19 acl-2011-A Mobile Touchable Application for Online Topic Graph Extraction and Exploration of Web Content</a></p>
<p>10 0.44819036 <a title="67-lsi-10" href="./acl-2011-Social_Network_Extraction_from_Texts%3A_A_Thesis_Proposal.html">286 acl-2011-Social Network Extraction from Texts: A Thesis Proposal</a></p>
<p>11 0.43432868 <a title="67-lsi-11" href="./acl-2011-Age_Prediction_in_Blogs%3A_A_Study_of_Style%2C_Content%2C_and_Online_Behavior_in_Pre-_and_Post-Social_Media_Generations.html">31 acl-2011-Age Prediction in Blogs: A Study of Style, Content, and Online Behavior in Pre- and Post-Social Media Generations</a></p>
<p>12 0.42743704 <a title="67-lsi-12" href="./acl-2011-Towards_Style_Transformation_from_Written-Style_to_Audio-Style.html">306 acl-2011-Towards Style Transformation from Written-Style to Audio-Style</a></p>
<p>13 0.42733717 <a title="67-lsi-13" href="./acl-2011-Predicting_Clicks_in_a_Vocabulary_Learning_System.html">248 acl-2011-Predicting Clicks in a Vocabulary Learning System</a></p>
<p>14 0.41515481 <a title="67-lsi-14" href="./acl-2011-Identifying_the_Semantic_Orientation_of_Foreign_Words.html">162 acl-2011-Identifying the Semantic Orientation of Foreign Words</a></p>
<p>15 0.4136416 <a title="67-lsi-15" href="./acl-2011-The_ACL_Anthology_Searchbench.html">298 acl-2011-The ACL Anthology Searchbench</a></p>
<p>16 0.41074094 <a title="67-lsi-16" href="./acl-2011-An_Interface_for_Rapid_Natural_Language_Processing_Development_in_UIMA.html">42 acl-2011-An Interface for Rapid Natural Language Processing Development in UIMA</a></p>
<p>17 0.40729368 <a title="67-lsi-17" href="./acl-2011-Even_the_Abstract_have_Color%3A_Consensus_in_Word-Colour_Associations.html">120 acl-2011-Even the Abstract have Color: Consensus in Word-Colour Associations</a></p>
<p>18 0.39651209 <a title="67-lsi-18" href="./acl-2011-An_ERP-based_Brain-Computer_Interface_for_text_entry_using_Rapid_Serial_Visual_Presentation_and_Language_Modeling.html">35 acl-2011-An ERP-based Brain-Computer Interface for text entry using Rapid Serial Visual Presentation and Language Modeling</a></p>
<p>19 0.39624009 <a title="67-lsi-19" href="./acl-2011-Towards_a_Framework_for_Abstractive_Summarization_of_Multimodal_Documents.html">308 acl-2011-Towards a Framework for Abstractive Summarization of Multimodal Documents</a></p>
<p>20 0.39355993 <a title="67-lsi-20" href="./acl-2011-Lost_in_Translation%3A_Authorship_Attribution_using_Frame_Semantics.html">214 acl-2011-Lost in Translation: Authorship Attribution using Frame Semantics</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(1, 0.017), (5, 0.042), (6, 0.237), (11, 0.011), (13, 0.019), (17, 0.028), (18, 0.016), (26, 0.062), (31, 0.016), (37, 0.062), (39, 0.043), (41, 0.057), (55, 0.012), (59, 0.031), (72, 0.025), (91, 0.038), (96, 0.17), (97, 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.85115552 <a title="67-lda-1" href="./acl-2011-NULEX%3A_An_Open-License_Broad_Coverage_Lexicon.html">229 acl-2011-NULEX: An Open-License Broad Coverage Lexicon</a></p>
<p>Author: Clifton McFate ; Kenneth Forbus</p><p>Abstract: Broad coverage lexicons for the English language have traditionally been handmade. This approach, while accurate, requires too much human labor. Furthermore, resources contain gaps in coverage, contain specific types of information, or are incompatible with other resources. We believe that the state of open-license technology is such that a comprehensive syntactic lexicon can be automatically compiled. This paper describes the creation of such a lexicon, NU-LEX, an open-license feature-based lexicon for general purpose parsing that combines WordNet, VerbNet, and Wiktionary and contains over 100,000 words. NU-LEX was integrated into a bottom up chart parser. We ran the parser through three sets of sentences, 50 sentences total, from the Simple English Wikipedia and compared its performance to the same parser using Comlex. Both parsers performed almost equally with NU-LEX finding all lex-items for 50% of the sentences and Comlex succeeding for 52%. Furthermore, NULEXâs shortcomings primarily fell into two categories, suggesting future research directions. 1</p><p>same-paper 2 0.78741252 <a title="67-lda-2" href="./acl-2011-Clairlib%3A_A_Toolkit_for_Natural_Language_Processing%2C_Information_Retrieval%2C_and_Network_Analysis.html">67 acl-2011-Clairlib: A Toolkit for Natural Language Processing, Information Retrieval, and Network Analysis</a></p>
<p>Author: Amjad Abu-Jbara ; Dragomir Radev</p><p>Abstract: In this paper we present Clairlib, an opensource toolkit for Natural Language Processing, Information Retrieval, and Network Analysis. Clairlib provides an integrated framework intended to simplify a number of generic tasks within and across those three areas. It has a command-line interface, a graphical interface, and a documented API. Clairlib is compatible with all the common platforms and operating systems. In addition to its own functionality, it provides interfaces to external software and corpora. Clairlib comes with a comprehensive documentation and a rich set of tutorials and visual demos.</p><p>3 0.78234124 <a title="67-lda-3" href="./acl-2011-Dealing_with_Spurious_Ambiguity_in_Learning_ITG-based_Word_Alignment.html">93 acl-2011-Dealing with Spurious Ambiguity in Learning ITG-based Word Alignment</a></p>
<p>Author: Shujian Huang ; Stephan Vogel ; Jiajun Chen</p><p>Abstract: Word alignment has an exponentially large search space, which often makes exact inference infeasible. Recent studies have shown that inversion transduction grammars are reasonable constraints for word alignment, and that the constrained space could be efficiently searched using synchronous parsing algorithms. However, spurious ambiguity may occur in synchronous parsing and cause problems in both search efficiency and accuracy. In this paper, we conduct a detailed study of the causes of spurious ambiguity and how it effects parsing and discriminative learning. We also propose a variant of the grammar which eliminates those ambiguities. Our grammar shows advantages over previous grammars in both synthetic and real-world experiments.</p><p>4 0.65825534 <a title="67-lda-4" href="./acl-2011-Fine-Grained_Class_Label_Markup_of_Search_Queries.html">137 acl-2011-Fine-Grained Class Label Markup of Search Queries</a></p>
<p>Author: Joseph Reisinger ; Marius Pasca</p><p>Abstract: We develop a novel approach to the semantic analysis of short text segments and demonstrate its utility on a large corpus of Web search queries. Extracting meaning from short text segments is difficult as there is little semantic redundancy between terms; hence methods based on shallow semantic analysis may fail to accurately estimate meaning. Furthermore search queries lack explicit syntax often used to determine intent in question answering. In this paper we propose a hybrid model of semantic analysis combining explicit class-label extraction with a latent class PCFG. This class-label correlation (CLC) model admits a robust parallel approximation, allowing it to scale to large amounts of query data. We demonstrate its performance in terms of (1) its predicted label accuracy on polysemous queries and (2) its ability to accurately chunk queries into base constituents.</p><p>5 0.65358496 <a title="67-lda-5" href="./acl-2011-Exact_Decoding_of_Syntactic_Translation_Models_through_Lagrangian_Relaxation.html">123 acl-2011-Exact Decoding of Syntactic Translation Models through Lagrangian Relaxation</a></p>
<p>Author: Alexander M. Rush ; Michael Collins</p><p>Abstract: We describe an exact decoding algorithm for syntax-based statistical translation. The approach uses Lagrangian relaxation to decompose the decoding problem into tractable subproblems, thereby avoiding exhaustive dynamic programming. The method recovers exact solutions, with certificates of optimality, on over 97% of test examples; it has comparable speed to state-of-the-art decoders.</p><p>6 0.6469903 <a title="67-lda-6" href="./acl-2011-A_Fast_and_Accurate_Method_for_Approximate_String_Search.html">11 acl-2011-A Fast and Accurate Method for Approximate String Search</a></p>
<p>7 0.64585179 <a title="67-lda-7" href="./acl-2011-ParaSense_or_How_to_Use_Parallel_Corpora_for_Word_Sense_Disambiguation.html">240 acl-2011-ParaSense or How to Use Parallel Corpora for Word Sense Disambiguation</a></p>
<p>8 0.64517748 <a title="67-lda-8" href="./acl-2011-Using_Bilingual_Parallel_Corpora_for_Cross-Lingual_Textual_Entailment.html">327 acl-2011-Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment</a></p>
<p>9 0.64460492 <a title="67-lda-9" href="./acl-2011-Interactive_Group_Suggesting_for_Twitter.html">177 acl-2011-Interactive Group Suggesting for Twitter</a></p>
<p>10 0.64198428 <a title="67-lda-10" href="./acl-2011-Language-independent_compound_splitting_with_morphological_operations.html">193 acl-2011-Language-independent compound splitting with morphological operations</a></p>
<p>11 0.6418162 <a title="67-lda-11" href="./acl-2011-Domain_Adaptation_for_Machine_Translation_by_Mining_Unseen_Words.html">104 acl-2011-Domain Adaptation for Machine Translation by Mining Unseen Words</a></p>
<p>12 0.64158392 <a title="67-lda-12" href="./acl-2011-Joint_Annotation_of_Search_Queries.html">182 acl-2011-Joint Annotation of Search Queries</a></p>
<p>13 0.64099073 <a title="67-lda-13" href="./acl-2011-Crowdsourcing_Translation%3A_Professional_Quality_from_Non-Professionals.html">90 acl-2011-Crowdsourcing Translation: Professional Quality from Non-Professionals</a></p>
<p>14 0.64084697 <a title="67-lda-14" href="./acl-2011-Learning_to_Win_by_Reading_Manuals_in_a_Monte-Carlo_Framework.html">207 acl-2011-Learning to Win by Reading Manuals in a Monte-Carlo Framework</a></p>
<p>15 0.63924193 <a title="67-lda-15" href="./acl-2011-Entity_Set_Expansion_using_Topic_information.html">117 acl-2011-Entity Set Expansion using Topic information</a></p>
<p>16 0.63912296 <a title="67-lda-16" href="./acl-2011-Towards_a_Framework_for_Abstractive_Summarization_of_Multimodal_Documents.html">308 acl-2011-Towards a Framework for Abstractive Summarization of Multimodal Documents</a></p>
<p>17 0.63893443 <a title="67-lda-17" href="./acl-2011-Extracting_Social_Power_Relationships_from_Natural_Language.html">133 acl-2011-Extracting Social Power Relationships from Natural Language</a></p>
<p>18 0.63829565 <a title="67-lda-18" href="./acl-2011-Sentiment_Analysis_of_Citations_using_Sentence_Structure-Based_Features.html">281 acl-2011-Sentiment Analysis of Citations using Sentence Structure-Based Features</a></p>
<p>19 0.63828039 <a title="67-lda-19" href="./acl-2011-Social_Network_Extraction_from_Texts%3A_A_Thesis_Proposal.html">286 acl-2011-Social Network Extraction from Texts: A Thesis Proposal</a></p>
<p>20 0.63819396 <a title="67-lda-20" href="./acl-2011-Computing_and_Evaluating_Syntactic_Complexity_Features_for_Automated_Scoring_of_Spontaneous_Non-Native_Speech.html">77 acl-2011-Computing and Evaluating Syntactic Complexity Features for Automated Scoring of Spontaneous Non-Native Speech</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
