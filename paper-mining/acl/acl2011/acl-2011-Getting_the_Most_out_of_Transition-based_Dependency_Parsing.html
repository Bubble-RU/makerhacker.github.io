<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>143 acl-2011-Getting the Most out of Transition-based Dependency Parsing</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-143" href="#">acl2011-143</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>143 acl-2011-Getting the Most out of Transition-based Dependency Parsing</h1>
<br/><p>Source: <a title="acl-2011-143-pdf" href="http://aclweb.org/anthology//P/P11/P11-2121.pdf">pdf</a></p><p>Author: Jinho D. Choi ; Martha Palmer</p><p>Abstract: This paper suggests two ways of improving transition-based, non-projective dependency parsing. First, we add a transition to an existing non-projective parsing algorithm, so it can perform either projective or non-projective parsing as needed. Second, we present a bootstrapping technique that narrows down discrepancies between gold-standard and automatic parses used as features. The new addition to the algorithm shows a clear advantage in parsing speed. The bootstrapping technique gives a significant improvement to parsing accuracy, showing near state-of-theart performance with respect to other parsing approaches evaluated on the same data set.</p><p>Reference: <a title="acl-2011-143-reference" href="../acl2011_reference/acl-2011-Getting_the_Most_out_of_Transition-based_Dependency_Parsing_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Choi Department of Computer Science University of Colorado at Boulder cho i d@ co l j orado  . [sent-2, score-0.037]
</p><p>2 edu  Abstract This paper suggests two ways of improving transition-based, non-projective dependency parsing. [sent-3, score-0.169]
</p><p>3 First, we add a transition to an existing non-projective parsing algorithm, so it can perform either projective or non-projective parsing as needed. [sent-4, score-1.331]
</p><p>4 Second, we present a bootstrapping technique that narrows down discrepancies between gold-standard and automatic parses used as features. [sent-5, score-0.292]
</p><p>5 The new addition to the algorithm shows a clear advantage in parsing speed. [sent-6, score-0.415]
</p><p>6 The bootstrapping technique gives a significant improvement to parsing accuracy, showing near state-of-theart performance with respect to other parsing approaches evaluated on the same data set. [sent-7, score-1.019]
</p><p>7 1 Introduction  Dependency parsing has recently gained considerable interest because it is simple and fast, yet provides useful information for many NLP tasks (Shen et al. [sent-8, score-0.36]
</p><p>8 There are two main dependency parsing approaches (Nivre and McDonald, 2008). [sent-11, score-0.563]
</p><p>9 One is a transition-based approach that greedily searches for local optima (highest scoring transitions) and uses parse history as features to predict the next transition (Nivre, 2003). [sent-12, score-0.318]
</p><p>10 The other is a graph-based approach that searches for a global optimum (highest scoring tree) from a complete graph in which vertices represent word tokens and edges (directed and weighted) represent dependency relations (McDonald et al. [sent-13, score-0.256]
</p><p>11 Lately, the usefulness of the transition-based approach has drawn more attention because it generally performs noticeably faster than the graph-based 687 Martha Palmer Department of Linguistics University of Colorado at Boulder mpalmer@ colorado edu  . [sent-15, score-0.148]
</p><p>12 The transition-based ap-  proach has a worst-case parsing complexity of O(n) for projective, and O(n2) for non-projective parsing (Nivre, 2008). [sent-18, score-0.805]
</p><p>13 The complexity is lower for projective parsing because it can deterministically drop certain tokens from the search space whereas that is not advisable for non-projective parsing. [sent-19, score-0.894]
</p><p>14 Despite this fact, it is possible to perform non-projective parsing in linear time in practice (Nivre, 2009). [sent-20, score-0.485]
</p><p>15 This is because the amount of non-projective dependencies is much smaller than the amount of projective dependencies, so a parser can perform projective parsing for most cases and perform non-projective parsing only when it is needed. [sent-21, score-1.62]
</p><p>16 One other advantage of the transition-based approach is that it can use parse history as features to make the next prediction. [sent-22, score-0.035]
</p><p>17 This parse information helps to improve parsing accuracy without hurting parsing complexity (Nivre, 2006). [sent-23, score-0.842]
</p><p>18 Most current transition-based approaches use gold-standard parses as features during training; however, this is not necessarily what parsers encounter during decoding. [sent-24, score-0.134]
</p><p>19 Thus, it is desirable to minimize the gap between gold-standard and automatic parses for the best results. [sent-25, score-0.06]
</p><p>20 This paper improves the engineering of different  aspects of transition-based, non-projective dependency parsing. [sent-26, score-0.169]
</p><p>21 To reduce the search space, we add a transition to an existing non-projective parsing algorithm. [sent-27, score-0.564]
</p><p>22 To narrow down the discrepancies between gold-standard and automatic parses, we present a bootstrapping technique. [sent-28, score-0.15]
</p><p>23 The new addition to the algorithm shows a clear advantage in parsing speed. [sent-29, score-0.415]
</p><p>24 The bootstrapping technique gives a significant improvement to parsing accuracy. [sent-30, score-0.478]
</p><p>25 transition  For each row, the first line shows a transition and the second line shows  preconditions of the transition. [sent-39, score-0.448]
</p><p>26 2  Reducing search space  Our algorithm is based on Choi-Nicolov’s approach to Nivre’s list-based algorithm (Nivre, 2008). [sent-40, score-0.11]
</p><p>27 The main difference between these two approaches is in their implementation of the SHIFT transition. [sent-41, score-0.08]
</p><p>28 ChoiNicolov’s approach divides the SHIFT transition into two, deterministic and non-deterministic SHIFT’s,  and trains the non-deterministic SHIFT with a classifier so it can be predicted during decoding. [sent-42, score-0.276]
</p><p>29 Choi and Nicolov (2009) showed that this implementation reduces the parsing complexity from O(n2) to linear time in practice (a worst-case complexity is O(n2)). [sent-43, score-0.662]
</p><p>30 We suggest another transition-based parsing approach that reduces the search space even more. [sent-44, score-0.36]
</p><p>31 The idea is to merge transitions in Choi-Nicolov’s non-projective algorithm with transitions in Nivre’s projective algorithm (Nivre, 2003). [sent-45, score-0.78]
</p><p>32 Nivre’s projective algorithm has a worst-case complexity of O(n), which is faster than any non-projective parsing algorithm. [sent-46, score-0.918]
</p><p>33 Since the number of non-projective dependencies is much smaller than the number of projective dependencies (Nivre and Nilsson, 2005), it is not efficient to perform non-projective parsing for all cases. [sent-47, score-0.939]
</p><p>34 Ideally, it is better to perform projective parsing for most cases and perform non-projective parsing only when it is needed. [sent-48, score-1.166]
</p><p>35 In this algorithm, we add another transition to Choi-Nicolov’s approach, LEFT-POP, similar to the LEFT-ARC transition in Nivre’s projective algorithm. [sent-49, score-0.776]
</p><p>36 By adding this transition, an oracle can now choose either projective or non-projective parsing depending on parsing states. [sent-50, score-1.088]
</p><p>37 1  1We also tried adding the RIGHT-ARC transition from Nivre’s projective algorithm, which did not improve parsing performance for our experiments. [sent-51, score-0.932]
</p><p>38 688 Note that Nivre (2009) has a similar idea of performing projective and non-projective parsing selectively. [sent-52, score-0.728]
</p><p>39 That algorithm uses a SWAP transition to reorder tokens related to non-projective dependencies, and runs in linear time in practice (a worst-case complexity is still O(n2)). [sent-53, score-0.503]
</p><p>40 Our algorithm is distinguished in that it does not require such reordering. [sent-54, score-0.055]
</p><p>41 All parsing states are represented as tuples (λ1, λ2, β, E), where λ1, λ2, and β are lists of word tokens. [sent-56, score-0.36]
</p><p>42 L is a dependency label and i, j, k represent indices of their corresponding word tokens. [sent-58, score-0.169]
</p><p>43 , the algorithm terminates when all tokens in β are consumed. [sent-68, score-0.096]
</p><p>44 All transitions are performed by comparing the last to-  ken in λ1, wi, and the first token in β, wj. [sent-70, score-0.214]
</p><p>45 Both LEFT-POPL and LEFT-ARCL are performed when wj is the head of wi with a dependency relation L. [sent-71, score-0.254]
</p><p>46 The difference is that LEFT-POP removes wi from λ1 after the transition, assuming that the token is no longer needed in later parsing states, whereas LEFTARC keeps the token so it can be the head of some token wj < . [sent-72, score-0.634]
</p><p>47 The improvment is even more significant in a language like Czech for which parsers generally perform more poorly. [sent-74, score-0.079]
</p><p>48 (42271)94∗)O  Table 3: Accuracy comparisons between different parsing approaches (LAS/UAS: labeled/unlabeled attachment score). [sent-83, score-0.394]
</p><p>49 (2009) introduced the best transitionbased system using synchronous syntactic-semantic parsing (‘Merlo’), and Bohnet (2009) introduced the best graph-based system using a maximum spanning tree algorithm (‘Bohnet’). [sent-88, score-0.54]
</p><p>50 3 Speed comparisons Figure 1 shows average parsing speeds for each sentence group in both English and Czech evaluation sets (Table 4). [sent-91, score-0.518]
</p><p>51 ‘Nivre’ is Nivre’s swap algorithm (Nivre, 2009), of which we use the implementation from MaltParser (maltpar ser . [sent-92, score-0.16]
</p><p>52 The other approaches are implemented in our open source project, called ClearParser (code . [sent-94, score-0.034]
</p><p>53 The loading times for machine learning models are excluded because they are independent from  the parsing algorithms. [sent-101, score-0.4]
</p><p>54 Our approach shows linear growth all along, even for the sentence groups where some approaches start showing curves. [sent-106, score-0.204]
</p><p>55 pisndamis)(gersPn1 280624 01230456N0ivOrueCN7+0 Sentence length  Figure 1: Average parsing speeds with respect to sentence groups in Table 4. [sent-107, score-0.558]
</p><p>56 3Later, ‘Merlo’ and ‘Bohnet” introduced more advanced systems, showing some improvements over their previous approaches (Titov et al. [sent-108, score-0.148]
</p><p>57 We also measured average parsing speeds for ‘Our’, which showed a very similar growth to ‘Our+’ . [sent-112, score-0.564]
</p><p>58 20 ms; it performed slightly faster than ‘Our+’ because it skipped more nodes by performing more non-deterministic SHIFT’s, which may or may not have been correct decisions for the corresponding parsing states. [sent-114, score-0.443]
</p><p>59 It is worth mentioning that the curve shown by ‘Nivre’ might be caused by implementation details regarding feature extraction, which we included as part of parsing. [sent-115, score-0.046]
</p><p>60 To abstract away from these implementation details and focus purely on the algorithms, we would need to compare the actual number of transitions performed by each parser, which will be explored in future work. [sent-116, score-0.197]
</p><p>61 6  Conclusion and future work  We present two ways of improving transition-based,  non-projective dependency parsing. [sent-117, score-0.169]
</p><p>62 The additional transition gives improvements to both parsing speed and accuracy, showing a linear time parsing speed with respect to sentence length. [sent-118, score-1.232]
</p><p>63 The bootstrapping technique gives a significant improvement to parsing accuracy, showing near state-of-the-art performance with respect to other parsing approaches. [sent-119, score-0.985]
</p><p>64 In the future, we will test the robustness of these approaches in more languages. [sent-120, score-0.034]
</p><p>65 Top accuracy and fast dependency parsing is not a contradiction. [sent-130, score-0.529]
</p><p>66 Parsing to stanford dependencies: Trade-offs between speed and accuracy. [sent-139, score-0.072]
</p><p>67 K-best, locally pruned, transition-based dependency parsing using robust risk minimization. [sent-144, score-0.529]
</p><p>68 What’s great and what’s not: Learning to classify the scope of negation for improved sentiment analysis. [sent-150, score-0.044]
</p><p>69 A latent variable model of synchronous syntactic-semantic parsing for multiple languages. [sent-158, score-0.413]
</p><p>70 The conll-2009 shared task: Syntactic and semantic dependencies in multiple languages. [sent-162, score-0.148]
</p><p>71 A dual coordinate descent method for large-scale linear svm. [sent-168, score-0.054]
</p><p>72 A new string-to-dependency machine translation algorithm with a target dependency language model. [sent-204, score-0.224]
</p><p>73 Online graph planarisation for synchronous parsing of semantic and syntactic dependencies. [sent-208, score-0.453]
</p><p>74 A tale of two parsers: investigating and combining graphbased and transition-based dependency parsing using beam-search. [sent-212, score-0.564]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('nivre', 0.432), ('projective', 0.368), ('parsing', 0.36), ('transition', 0.204), ('dependency', 0.169), ('speeds', 0.158), ('transitions', 0.151), ('bohnet', 0.149), ('joakim', 0.146), ('shift', 0.141), ('merlo', 0.139), ('conll', 0.11), ('dependencies', 0.086), ('complexity', 0.085), ('gesmundo', 0.081), ('bernd', 0.081), ('jinho', 0.081), ('choi', 0.077), ('bootstrapping', 0.076), ('discrepancies', 0.074), ('speed', 0.072), ('paola', 0.07), ('councill', 0.07), ('showing', 0.07), ('jan', 0.067), ('subcontract', 0.063), ('token', 0.063), ('shared', 0.062), ('mcdonald', 0.062), ('colorado', 0.061), ('parses', 0.06), ('swap', 0.059), ('cer', 0.059), ('henderson', 0.057), ('haji', 0.055), ('algorithm', 0.055), ('linear', 0.054), ('synchronous', 0.053), ('titov', 0.053), ('ivan', 0.051), ('maltparser', 0.051), ('faster', 0.05), ('searches', 0.046), ('growth', 0.046), ('implementation', 0.046), ('wj', 0.045), ('ryan', 0.045), ('advanced', 0.044), ('negation', 0.044), ('technique', 0.042), ('tokens', 0.041), ('respect', 0.04), ('tiehre', 0.04), ('narrows', 0.04), ('advisable', 0.04), ('clinic', 0.04), ('gabriele', 0.04), ('isaac', 0.04), ('loading', 0.04), ('nek', 0.04), ('onc', 0.04), ('planarisation', 0.04), ('preconditions', 0.04), ('sathiya', 0.04), ('strategic', 0.04), ('parsers', 0.04), ('wi', 0.04), ('boulder', 0.04), ('spanning', 0.04), ('deterministic', 0.04), ('perform', 0.039), ('nicolov', 0.037), ('orado', 0.037), ('hurting', 0.037), ('noticeably', 0.037), ('massimiliano', 0.037), ('hospital', 0.037), ('keerthi', 0.037), ('lately', 0.037), ('leonid', 0.037), ('near', 0.037), ('history', 0.035), ('langford', 0.035), ('mayo', 0.035), ('daisuke', 0.035), ('pavel', 0.035), ('tale', 0.035), ('approaches', 0.034), ('skipped', 0.033), ('optima', 0.033), ('speculation', 0.033), ('ciaramita', 0.033), ('thirdorder', 0.033), ('practice', 0.032), ('reorder', 0.032), ('higherorder', 0.032), ('nicolas', 0.032), ('harvard', 0.032), ('transitionbased', 0.032), ('divides', 0.032)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="143-tfidf-1" href="./acl-2011-Getting_the_Most_out_of_Transition-based_Dependency_Parsing.html">143 acl-2011-Getting the Most out of Transition-based Dependency Parsing</a></p>
<p>Author: Jinho D. Choi ; Martha Palmer</p><p>Abstract: This paper suggests two ways of improving transition-based, non-projective dependency parsing. First, we add a transition to an existing non-projective parsing algorithm, so it can perform either projective or non-projective parsing as needed. Second, we present a bootstrapping technique that narrows down discrepancies between gold-standard and automatic parses used as features. The new addition to the algorithm shows a clear advantage in parsing speed. The bootstrapping technique gives a significant improvement to parsing accuracy, showing near state-of-theart performance with respect to other parsing approaches evaluated on the same data set.</p><p>2 0.29905745 <a title="143-tfidf-2" href="./acl-2011-Transition-based_Dependency_Parsing_with_Rich_Non-local_Features.html">309 acl-2011-Transition-based Dependency Parsing with Rich Non-local Features</a></p>
<p>Author: Yue Zhang ; Joakim Nivre</p><p>Abstract: Transition-based dependency parsers generally use heuristic decoding algorithms but can accommodate arbitrarily rich feature representations. In this paper, we show that we can improve the accuracy of such parsers by considering even richer feature sets than those employed in previous systems. In the standard Penn Treebank setup, our novel features improve attachment score form 91.4% to 92.9%, giving the best results so far for transitionbased parsing and rivaling the best results overall. For the Chinese Treebank, they give a signficant improvement of the state of the art. An open source release of our parser is freely available.</p><p>3 0.22067755 <a title="143-tfidf-3" href="./acl-2011-Improving_Dependency_Parsing_with_Semantic_Classes.html">167 acl-2011-Improving Dependency Parsing with Semantic Classes</a></p>
<p>Author: Eneko Agirre ; Kepa Bengoetxea ; Koldo Gojenola ; Joakim Nivre</p><p>Abstract: This paper presents the introduction of WordNet semantic classes in a dependency parser, obtaining improvements on the full Penn Treebank for the first time. We tried different combinations of some basic semantic classes and word sense disambiguation algorithms. Our experiments show that selecting the adequate combination of semantic features on development data is key for success. Given the basic nature of the semantic classes and word sense disambiguation algorithms used, we think there is ample room for future improvements. 1</p><p>4 0.21680763 <a title="143-tfidf-4" href="./acl-2011-An_Ensemble_Model_that_Combines_Syntactic_and_Semantic_Clustering_for_Discriminative_Dependency_Parsing.html">39 acl-2011-An Ensemble Model that Combines Syntactic and Semantic Clustering for Discriminative Dependency Parsing</a></p>
<p>Author: Gholamreza Haffari ; Marzieh Razavi ; Anoop Sarkar</p><p>Abstract: We combine multiple word representations based on semantic clusters extracted from the (Brown et al., 1992) algorithm and syntactic clusters obtained from the Berkeley parser (Petrov et al., 2006) in order to improve discriminative dependency parsing in the MSTParser framework (McDonald et al., 2005). We also provide an ensemble method for combining diverse cluster-based models. The two contributions together significantly improves unlabeled dependency accuracy from 90.82% to 92. 13%.</p><p>5 0.18159135 <a title="143-tfidf-5" href="./acl-2011-Exploiting_Web-Derived_Selectional_Preference_to_Improve_Statistical_Dependency_Parsing.html">127 acl-2011-Exploiting Web-Derived Selectional Preference to Improve Statistical Dependency Parsing</a></p>
<p>Author: Guangyou Zhou ; Jun Zhao ; Kang Liu ; Li Cai</p><p>Abstract: In this paper, we present a novel approach which incorporates the web-derived selectional preferences to improve statistical dependency parsing. Conventional selectional preference learning methods have usually focused on word-to-class relations, e.g., a verb selects as its subject a given nominal class. This paper extends previous work to wordto-word selectional preferences by using webscale data. Experiments show that web-scale data improves statistical dependency parsing, particularly for long dependency relationships. There is no data like more data, performance improves log-linearly with the number of parameters (unique N-grams). More importantly, when operating on new domains, we show that using web-derived selectional preferences is essential for achieving robust performance.</p><p>6 0.18156883 <a title="143-tfidf-6" href="./acl-2011-Effects_of_Noun_Phrase_Bracketing_in_Dependency_Parsing_and_Machine_Translation.html">111 acl-2011-Effects of Noun Phrase Bracketing in Dependency Parsing and Machine Translation</a></p>
<p>7 0.17697759 <a title="143-tfidf-7" href="./acl-2011-Dynamic_Programming_Algorithms_for_Transition-Based_Dependency_Parsers.html">107 acl-2011-Dynamic Programming Algorithms for Transition-Based Dependency Parsers</a></p>
<p>8 0.16268417 <a title="143-tfidf-8" href="./acl-2011-Shift-Reduce_CCG_Parsing.html">282 acl-2011-Shift-Reduce CCG Parsing</a></p>
<p>9 0.16081156 <a title="143-tfidf-9" href="./acl-2011-Optimistic_Backtracking_-_A_Backtracking_Overlay_for_Deterministic_Incremental_Parsing.html">236 acl-2011-Optimistic Backtracking - A Backtracking Overlay for Deterministic Incremental Parsing</a></p>
<p>10 0.14700057 <a title="143-tfidf-10" href="./acl-2011-Automatic_Detection_and_Correction_of_Errors_in_Dependency_Treebanks.html">48 acl-2011-Automatic Detection and Correction of Errors in Dependency Treebanks</a></p>
<p>11 0.14438005 <a title="143-tfidf-11" href="./acl-2011-Temporal_Restricted_Boltzmann_Machines_for_Dependency_Parsing.html">295 acl-2011-Temporal Restricted Boltzmann Machines for Dependency Parsing</a></p>
<p>12 0.11955946 <a title="143-tfidf-12" href="./acl-2011-Improving_Arabic_Dependency_Parsing_with_Form-based_and_Functional_Morphological_Features.html">164 acl-2011-Improving Arabic Dependency Parsing with Form-based and Functional Morphological Features</a></p>
<p>13 0.11821541 <a title="143-tfidf-13" href="./acl-2011-Partial_Parsing_from_Bitext_Projections.html">243 acl-2011-Partial Parsing from Bitext Projections</a></p>
<p>14 0.11206255 <a title="143-tfidf-14" href="./acl-2011-Beam-Width_Prediction_for_Efficient_Context-Free_Parsing.html">58 acl-2011-Beam-Width Prediction for Efficient Context-Free Parsing</a></p>
<p>15 0.10525759 <a title="143-tfidf-15" href="./acl-2011-Event_Extraction_as_Dependency_Parsing.html">122 acl-2011-Event Extraction as Dependency Parsing</a></p>
<p>16 0.10442805 <a title="143-tfidf-16" href="./acl-2011-Joint_Hebrew_Segmentation_and_Parsing_using_a_PCFGLA_Lattice_Parser.html">184 acl-2011-Joint Hebrew Segmentation and Parsing using a PCFGLA Lattice Parser</a></p>
<p>17 0.10332365 <a title="143-tfidf-17" href="./acl-2011-Web-Scale_Features_for_Full-Scale_Parsing.html">333 acl-2011-Web-Scale Features for Full-Scale Parsing</a></p>
<p>18 0.10179253 <a title="143-tfidf-18" href="./acl-2011-Incremental_Syntactic_Language_Models_for_Phrase-based_Translation.html">171 acl-2011-Incremental Syntactic Language Models for Phrase-based Translation</a></p>
<p>19 0.098771051 <a title="143-tfidf-19" href="./acl-2011-Joint_Training_of_Dependency_Parsing_Filters_through_Latent_Support_Vector_Machines.html">186 acl-2011-Joint Training of Dependency Parsing Filters through Latent Support Vector Machines</a></p>
<p>20 0.098127507 <a title="143-tfidf-20" href="./acl-2011-Neutralizing_Linguistically_Problematic_Annotations_in_Unsupervised_Dependency_Parsing_Evaluation.html">230 acl-2011-Neutralizing Linguistically Problematic Annotations in Unsupervised Dependency Parsing Evaluation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.207), (1, -0.047), (2, -0.075), (3, -0.337), (4, -0.024), (5, -0.06), (6, 0.037), (7, 0.119), (8, 0.09), (9, -0.015), (10, 0.069), (11, 0.06), (12, 0.06), (13, -0.175), (14, -0.044), (15, 0.015), (16, 0.054), (17, -0.016), (18, -0.003), (19, -0.098), (20, -0.085), (21, -0.009), (22, 0.022), (23, -0.002), (24, 0.072), (25, -0.117), (26, 0.027), (27, -0.027), (28, -0.093), (29, 0.005), (30, -0.018), (31, -0.013), (32, 0.016), (33, 0.064), (34, -0.009), (35, 0.011), (36, -0.001), (37, 0.147), (38, 0.1), (39, 0.089), (40, -0.017), (41, -0.076), (42, 0.029), (43, 0.009), (44, -0.065), (45, -0.003), (46, -0.008), (47, -0.014), (48, 0.004), (49, 0.048)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97701555 <a title="143-lsi-1" href="./acl-2011-Getting_the_Most_out_of_Transition-based_Dependency_Parsing.html">143 acl-2011-Getting the Most out of Transition-based Dependency Parsing</a></p>
<p>Author: Jinho D. Choi ; Martha Palmer</p><p>Abstract: This paper suggests two ways of improving transition-based, non-projective dependency parsing. First, we add a transition to an existing non-projective parsing algorithm, so it can perform either projective or non-projective parsing as needed. Second, we present a bootstrapping technique that narrows down discrepancies between gold-standard and automatic parses used as features. The new addition to the algorithm shows a clear advantage in parsing speed. The bootstrapping technique gives a significant improvement to parsing accuracy, showing near state-of-theart performance with respect to other parsing approaches evaluated on the same data set.</p><p>2 0.88979435 <a title="143-lsi-2" href="./acl-2011-Dynamic_Programming_Algorithms_for_Transition-Based_Dependency_Parsers.html">107 acl-2011-Dynamic Programming Algorithms for Transition-Based Dependency Parsers</a></p>
<p>Author: Marco Kuhlmann ; Carlos Gomez-Rodriguez ; Giorgio Satta</p><p>Abstract: We develop a general dynamic programming technique for the tabulation of transition-based dependency parsers, and apply it to obtain novel, polynomial-time algorithms for parsing with the arc-standard and arc-eager models. We also show how to reverse our technique to obtain new transition-based dependency parsers from existing tabular methods. Additionally, we provide a detailed discussion of the conditions under which the feature models commonly used in transition-based parsing can be integrated into our algorithms.</p><p>3 0.88549185 <a title="143-lsi-3" href="./acl-2011-Transition-based_Dependency_Parsing_with_Rich_Non-local_Features.html">309 acl-2011-Transition-based Dependency Parsing with Rich Non-local Features</a></p>
<p>Author: Yue Zhang ; Joakim Nivre</p><p>Abstract: Transition-based dependency parsers generally use heuristic decoding algorithms but can accommodate arbitrarily rich feature representations. In this paper, we show that we can improve the accuracy of such parsers by considering even richer feature sets than those employed in previous systems. In the standard Penn Treebank setup, our novel features improve attachment score form 91.4% to 92.9%, giving the best results so far for transitionbased parsing and rivaling the best results overall. For the Chinese Treebank, they give a signficant improvement of the state of the art. An open source release of our parser is freely available.</p><p>4 0.81687415 <a title="143-lsi-4" href="./acl-2011-An_Ensemble_Model_that_Combines_Syntactic_and_Semantic_Clustering_for_Discriminative_Dependency_Parsing.html">39 acl-2011-An Ensemble Model that Combines Syntactic and Semantic Clustering for Discriminative Dependency Parsing</a></p>
<p>Author: Gholamreza Haffari ; Marzieh Razavi ; Anoop Sarkar</p><p>Abstract: We combine multiple word representations based on semantic clusters extracted from the (Brown et al., 1992) algorithm and syntactic clusters obtained from the Berkeley parser (Petrov et al., 2006) in order to improve discriminative dependency parsing in the MSTParser framework (McDonald et al., 2005). We also provide an ensemble method for combining diverse cluster-based models. The two contributions together significantly improves unlabeled dependency accuracy from 90.82% to 92. 13%.</p><p>5 0.80498898 <a title="143-lsi-5" href="./acl-2011-Exploiting_Web-Derived_Selectional_Preference_to_Improve_Statistical_Dependency_Parsing.html">127 acl-2011-Exploiting Web-Derived Selectional Preference to Improve Statistical Dependency Parsing</a></p>
<p>Author: Guangyou Zhou ; Jun Zhao ; Kang Liu ; Li Cai</p><p>Abstract: In this paper, we present a novel approach which incorporates the web-derived selectional preferences to improve statistical dependency parsing. Conventional selectional preference learning methods have usually focused on word-to-class relations, e.g., a verb selects as its subject a given nominal class. This paper extends previous work to wordto-word selectional preferences by using webscale data. Experiments show that web-scale data improves statistical dependency parsing, particularly for long dependency relationships. There is no data like more data, performance improves log-linearly with the number of parameters (unique N-grams). More importantly, when operating on new domains, we show that using web-derived selectional preferences is essential for achieving robust performance.</p><p>6 0.80181605 <a title="143-lsi-6" href="./acl-2011-Optimistic_Backtracking_-_A_Backtracking_Overlay_for_Deterministic_Incremental_Parsing.html">236 acl-2011-Optimistic Backtracking - A Backtracking Overlay for Deterministic Incremental Parsing</a></p>
<p>7 0.78874922 <a title="143-lsi-7" href="./acl-2011-Partial_Parsing_from_Bitext_Projections.html">243 acl-2011-Partial Parsing from Bitext Projections</a></p>
<p>8 0.7498908 <a title="143-lsi-8" href="./acl-2011-Temporal_Restricted_Boltzmann_Machines_for_Dependency_Parsing.html">295 acl-2011-Temporal Restricted Boltzmann Machines for Dependency Parsing</a></p>
<p>9 0.74756259 <a title="143-lsi-9" href="./acl-2011-Neutralizing_Linguistically_Problematic_Annotations_in_Unsupervised_Dependency_Parsing_Evaluation.html">230 acl-2011-Neutralizing Linguistically Problematic Annotations in Unsupervised Dependency Parsing Evaluation</a></p>
<p>10 0.7147606 <a title="143-lsi-10" href="./acl-2011-Improving_Dependency_Parsing_with_Semantic_Classes.html">167 acl-2011-Improving Dependency Parsing with Semantic Classes</a></p>
<p>11 0.71167135 <a title="143-lsi-11" href="./acl-2011-Shift-Reduce_CCG_Parsing.html">282 acl-2011-Shift-Reduce CCG Parsing</a></p>
<p>12 0.71016634 <a title="143-lsi-12" href="./acl-2011-Effects_of_Noun_Phrase_Bracketing_in_Dependency_Parsing_and_Machine_Translation.html">111 acl-2011-Effects of Noun Phrase Bracketing in Dependency Parsing and Machine Translation</a></p>
<p>13 0.68663442 <a title="143-lsi-13" href="./acl-2011-Automatic_Detection_and_Correction_of_Errors_in_Dependency_Treebanks.html">48 acl-2011-Automatic Detection and Correction of Errors in Dependency Treebanks</a></p>
<p>14 0.67910457 <a title="143-lsi-14" href="./acl-2011-Joint_Training_of_Dependency_Parsing_Filters_through_Latent_Support_Vector_Machines.html">186 acl-2011-Joint Training of Dependency Parsing Filters through Latent Support Vector Machines</a></p>
<p>15 0.61916423 <a title="143-lsi-15" href="./acl-2011-Web-Scale_Features_for_Full-Scale_Parsing.html">333 acl-2011-Web-Scale Features for Full-Scale Parsing</a></p>
<p>16 0.55753058 <a title="143-lsi-16" href="./acl-2011-Better_Automatic_Treebank_Conversion_Using_A_Feature-Based_Approach.html">59 acl-2011-Better Automatic Treebank Conversion Using A Feature-Based Approach</a></p>
<p>17 0.55290771 <a title="143-lsi-17" href="./acl-2011-Joint_Hebrew_Segmentation_and_Parsing_using_a_PCFGLA_Lattice_Parser.html">184 acl-2011-Joint Hebrew Segmentation and Parsing using a PCFGLA Lattice Parser</a></p>
<p>18 0.54786748 <a title="143-lsi-18" href="./acl-2011-Optimal_Head-Driven_Parsing_Complexity_for_Linear_Context-Free_Rewriting_Systems.html">234 acl-2011-Optimal Head-Driven Parsing Complexity for Linear Context-Free Rewriting Systems</a></p>
<p>19 0.52696079 <a title="143-lsi-19" href="./acl-2011-Reversible_Stochastic_Attribute-Value_Grammars.html">267 acl-2011-Reversible Stochastic Attribute-Value Grammars</a></p>
<p>20 0.50795776 <a title="143-lsi-20" href="./acl-2011-Data_point_selection_for_cross-language_adaptation_of_dependency_parsers.html">92 acl-2011-Data point selection for cross-language adaptation of dependency parsers</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.012), (17, 0.013), (26, 0.013), (37, 0.1), (39, 0.035), (41, 0.525), (59, 0.028), (72, 0.024), (91, 0.032), (96, 0.113), (97, 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.95748538 <a title="143-lda-1" href="./acl-2011-Contrasting_Multi-Lingual_Prosodic_Cues_to_Predict_Verbal_Feedback_for_Rapport.html">83 acl-2011-Contrasting Multi-Lingual Prosodic Cues to Predict Verbal Feedback for Rapport</a></p>
<p>Author: Siwei Wang ; Gina-Anne Levow</p><p>Abstract: Verbal feedback is an important information source in establishing interactional rapport. However, predicting verbal feedback across languages is challenging due to languagespecific differences, inter-speaker variation, and the relative sparseness and optionality of verbal feedback. In this paper, we employ an approach combining classifier weighting and SMOTE algorithm oversampling to improve verbal feedback prediction in Arabic, English, and Spanish dyadic conversations. This approach improves the prediction of verbal feedback, up to 6-fold, while maintaining a high overall accuracy. Analyzing highly weighted features highlights widespread use of pitch, with more varied use of intensity and duration.</p><p>2 0.95006746 <a title="143-lda-2" href="./acl-2011-Using_Cross-Entity_Inference_to_Improve_Event_Extraction.html">328 acl-2011-Using Cross-Entity Inference to Improve Event Extraction</a></p>
<p>Author: Yu Hong ; Jianfeng Zhang ; Bin Ma ; Jianmin Yao ; Guodong Zhou ; Qiaoming Zhu</p><p>Abstract: Event extraction is the task of detecting certain specified types of events that are mentioned in the source language data. The state-of-the-art research on the task is transductive inference (e.g. cross-event inference). In this paper, we propose a new method of event extraction by well using cross-entity inference. In contrast to previous inference methods, we regard entitytype consistency as key feature to predict event mentions. We adopt this inference method to improve the traditional sentence-level event extraction system. Experiments show that we can get 8.6% gain in trigger (event) identification, and more than 11.8% gain for argument (role) classification in ACE event extraction. 1</p><p>3 0.93317431 <a title="143-lda-3" href="./acl-2011-Metagrammar_engineering%3A_Towards_systematic_exploration_of_implemented_grammars.html">219 acl-2011-Metagrammar engineering: Towards systematic exploration of implemented grammars</a></p>
<p>Author: Antske Fokkens</p><p>Abstract: When designing grammars of natural language, typically, more than one formal analysis can account for a given phenomenon. Moreover, because analyses interact, the choices made by the engineer influence the possibilities available in further grammar development. The order in which phenomena are treated may therefore have a major impact on the resulting grammar. This paper proposes to tackle this problem by using metagrammar development as a methodology for grammar engineering. Iargue that metagrammar engineering as an approach facilitates the systematic exploration of grammars through comparison of competing analyses. The idea is illustrated through a comparative study of auxiliary structures in HPSG-based grammars for German and Dutch. Auxiliaries form a central phenomenon of German and Dutch and are likely to influence many components of the grammar. This study shows that a special auxiliary+verb construction significantly improves efficiency compared to the standard argument-composition analysis for both parsing and generation.</p><p>4 0.92998016 <a title="143-lda-4" href="./acl-2011-K-means_Clustering_with_Feature_Hashing.html">189 acl-2011-K-means Clustering with Feature Hashing</a></p>
<p>Author: Hajime Senuma</p><p>Abstract: One of the major problems of K-means is that one must use dense vectors for its centroids, and therefore it is infeasible to store such huge vectors in memory when the feature space is high-dimensional. We address this issue by using feature hashing (Weinberger et al., 2009), a dimension-reduction technique, which can reduce the size of dense vectors while retaining sparsity of sparse vectors. Our analysis gives theoretical motivation and justification for applying feature hashing to Kmeans, by showing how much will the objective of K-means be (additively) distorted. Furthermore, to empirically verify our method, we experimented on a document clustering task.</p><p>same-paper 5 0.92849958 <a title="143-lda-5" href="./acl-2011-Getting_the_Most_out_of_Transition-based_Dependency_Parsing.html">143 acl-2011-Getting the Most out of Transition-based Dependency Parsing</a></p>
<p>Author: Jinho D. Choi ; Martha Palmer</p><p>Abstract: This paper suggests two ways of improving transition-based, non-projective dependency parsing. First, we add a transition to an existing non-projective parsing algorithm, so it can perform either projective or non-projective parsing as needed. Second, we present a bootstrapping technique that narrows down discrepancies between gold-standard and automatic parses used as features. The new addition to the algorithm shows a clear advantage in parsing speed. The bootstrapping technique gives a significant improvement to parsing accuracy, showing near state-of-theart performance with respect to other parsing approaches evaluated on the same data set.</p><p>6 0.92379373 <a title="143-lda-6" href="./acl-2011-From_Bilingual_Dictionaries_to_Interlingual_Document_Representations.html">139 acl-2011-From Bilingual Dictionaries to Interlingual Document Representations</a></p>
<p>7 0.91813999 <a title="143-lda-7" href="./acl-2011-Nonparametric_Bayesian_Machine_Transliteration_with_Synchronous_Adaptor_Grammars.html">232 acl-2011-Nonparametric Bayesian Machine Transliteration with Synchronous Adaptor Grammars</a></p>
<p>8 0.90677804 <a title="143-lda-8" href="./acl-2011-Bayesian_Inference_for_Zodiac_and_Other_Homophonic_Ciphers.html">56 acl-2011-Bayesian Inference for Zodiac and Other Homophonic Ciphers</a></p>
<p>9 0.84545285 <a title="143-lda-9" href="./acl-2011-Joint_Identification_and_Segmentation_of_Domain-Specific_Dialogue_Acts_for_Conversational_Dialogue_Systems.html">185 acl-2011-Joint Identification and Segmentation of Domain-Specific Dialogue Acts for Conversational Dialogue Systems</a></p>
<p>10 0.65504265 <a title="143-lda-10" href="./acl-2011-Can_Document_Selection_Help_Semi-supervised_Learning%3F_A_Case_Study_On_Event_Extraction.html">65 acl-2011-Can Document Selection Help Semi-supervised Learning? A Case Study On Event Extraction</a></p>
<p>11 0.64825726 <a title="143-lda-11" href="./acl-2011-Deciphering_Foreign_Language.html">94 acl-2011-Deciphering Foreign Language</a></p>
<p>12 0.63673979 <a title="143-lda-12" href="./acl-2011-Modeling_Wisdom_of_Crowds_Using_Latent_Mixture_of_Discriminative_Experts.html">223 acl-2011-Modeling Wisdom of Crowds Using Latent Mixture of Discriminative Experts</a></p>
<p>13 0.63649374 <a title="143-lda-13" href="./acl-2011-Large-Scale_Cross-Document_Coreference_Using_Distributed_Inference_and_Hierarchical_Models.html">196 acl-2011-Large-Scale Cross-Document Coreference Using Distributed Inference and Hierarchical Models</a></p>
<p>14 0.61778408 <a title="143-lda-14" href="./acl-2011-An_Affect-Enriched_Dialogue_Act_Classification_Model_for_Task-Oriented_Dialogue.html">33 acl-2011-An Affect-Enriched Dialogue Act Classification Model for Task-Oriented Dialogue</a></p>
<p>15 0.60793424 <a title="143-lda-15" href="./acl-2011-A_Generative_Entity-Mention_Model_for_Linking_Entities_with_Knowledge_Base.html">12 acl-2011-A Generative Entity-Mention Model for Linking Entities with Knowledge Base</a></p>
<p>16 0.59991693 <a title="143-lda-16" href="./acl-2011-Faster_and_Smaller_N-Gram_Language_Models.html">135 acl-2011-Faster and Smaller N-Gram Language Models</a></p>
<p>17 0.59819174 <a title="143-lda-17" href="./acl-2011-Peeling_Back_the_Layers%3A_Detecting_Event_Role_Fillers_in_Secondary_Contexts.html">244 acl-2011-Peeling Back the Layers: Detecting Event Role Fillers in Secondary Contexts</a></p>
<p>18 0.59408224 <a title="143-lda-18" href="./acl-2011-An_Error_Analysis_of_Relation_Extraction_in_Social_Media_Documents.html">40 acl-2011-An Error Analysis of Relation Extraction in Social Media Documents</a></p>
<p>19 0.58790493 <a title="143-lda-19" href="./acl-2011-Beam-Width_Prediction_for_Efficient_Context-Free_Parsing.html">58 acl-2011-Beam-Width Prediction for Efficient Context-Free Parsing</a></p>
<p>20 0.58731622 <a title="143-lda-20" href="./acl-2011-Unary_Constraints_for_Efficient_Context-Free_Parsing.html">316 acl-2011-Unary Constraints for Efficient Context-Free Parsing</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
