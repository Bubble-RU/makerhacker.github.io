<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>222 acl-2011-Model-Portability Experiments for Textual Temporal Analysis</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-222" href="#">acl2011-222</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>222 acl-2011-Model-Portability Experiments for Textual Temporal Analysis</h1>
<br/><p>Source: <a title="acl-2011-222-pdf" href="http://aclweb.org/anthology//P/P11/P11-2047.pdf">pdf</a></p><p>Author: Oleksandr Kolomiyets ; Steven Bethard ; Marie-Francine Moens</p><p>Abstract: We explore a semi-supervised approach for improving the portability of time expression recognition to non-newswire domains: we generate additional training examples by substituting temporal expression words with potential synonyms. We explore using synonyms both from WordNet and from the Latent Words Language Model (LWLM), which predicts synonyms in context using an unsupervised approach. We evaluate a state-of-the-art time expression recognition system trained both with and without the additional training examples using data from TempEval 2010, Reuters and Wikipedia. We find that the LWLM provides substantial improvements on the Reuters corpus, and smaller improvements on the Wikipedia corpus. We find that WordNet alone never improves performance, though intersecting the examples from the LWLM and WordNet provides more stable results for Wikipedia. 1</p><p>Reference: <a title="acl-2011-222-reference" href="../acl2011_reference/acl-2011-Model-Portability_Experiments_for_Textual_Temporal_Analysis_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Model-Portability Experiments for Textual Temporal Analysis Oleksandr Kolomiyets, Steven Bethard and Marie-Francine Moens Department of Computer Science Katholieke Universiteit Leuven Celestijnenlaan 200A, Heverlee, 3001 , Belgium  { ole ks andr . [sent-1, score-0.016]
</p><p>2 ko l omi yet s  ,  s teven  Abstract We explore a semi-supervised approach for improving the portability of time expression recognition to non-newswire domains: we generate additional training examples by substituting temporal expression words with potential synonyms. [sent-2, score-0.461]
</p><p>3 We explore using synonyms both from WordNet and from the Latent Words Language Model (LWLM), which predicts synonyms in context using an unsupervised approach. [sent-3, score-0.494]
</p><p>4 We evaluate a state-of-the-art time expression recognition system trained both with and without the additional training examples using data from TempEval 2010, Reuters and Wikipedia. [sent-4, score-0.21]
</p><p>5 We find that WordNet alone never improves performance, though intersecting the examples from the LWLM and WordNet provides more stable results for Wikipedia. [sent-6, score-0.055]
</p><p>6 html) and the TempEval 2010 time expression task (Verhagen et al. [sent-14, score-0.107]
</p><p>7 Thus we know little about how well time expression recognition systems generalize to other sorts of text. [sent-23, score-0.144]
</p><p>8 We therefore take a state-of-the-art time recognizer and evaluate it both on TempEval 2010 and on two new test sets drawn from Reuters and Wikipedia. [sent-24, score-0.035]
</p><p>9 At the same time, we are interested in helping the model recognize more types of time expressions than are available explicitly in the newswire training data. [sent-25, score-0.131]
</p><p>10 We therefore introduce a semisupervised approach for expanding the training data, where we take words from temporal expressions in the data, substitute these words with likely synonyms, and add the generated examples to the training set. [sent-26, score-0.274]
</p><p>11 We select synonyms both via Word-  i2oacTnf0hg1lesufrodti,ahmsnceotdgi q-nmeSuhtiap sfkrotMenmsa. [sent-27, score-0.247]
</p><p>12 Msltuh)fe(rDosm acntoih-dseulWpLhtairkvsenpdtxMWiamonedtrs-, named entity task (Grishman and Sundheim, 1996), the Automatic Content Extraction time 271  Proceedings ofP thoer t4l9atnhd A, Onrnuegaoln M,e Jeuntineg 19 o-f2 t4h,e 2 A0s1s1o. [sent-30, score-0.035]
</p><p>13 , 2009), which investigated a semi-supervised approach to time expression rec-  ognition. [sent-35, score-0.107]
</p><p>14 They begin by selecting 100 time expressions as seeds, selecting only expressions that are almost always annotated as times in the training half of the Automatic Content Extraction corpus. [sent-36, score-0.196]
</p><p>15 Then they begin an iterative process where they search an unlabeled corpus for patterns given their seeds (with patterns consisting of surrounding tokens, parts-of-speech, syntactic chunks etc. [sent-37, score-0.101]
</p><p>16 ) and then search for new seeds given their patterns. [sent-38, score-0.04]
</p><p>17 The patterns resulting from this iterative process achieve F1 scores of up to 0. [sent-39, score-0.029]
</p><p>18 Time expressions are identified as phrasal chunks with spans derived from the parse as described in (Kolomiyets and Moens, 2010). [sent-44, score-0.105]
</p><p>19 Xxxxx 9 9 for the expression April 30 The condensed word-shape representation for the head word and the entire phrase, e. [sent-48, score-0.103]
</p><p>20 X ( x ) ( 9 ) for the expression April 30 The concatenated string of the syntactic types of the children of the phrase in the parse tree The depth in the parse tree  3. [sent-50, score-0.072]
</p><p>21 2 Lexical Resources for Bootstrapping Sparsity of annotated corpora is the biggest challenge for any supervised machine learning tech-  nique and especially for porting the trained models onto other domains. [sent-51, score-0.079]
</p><p>22 To overcome this problem we hypothesize that knowledge of semantically similar words, like temporal triggers, could be found by associating words that do not occur in the training set to similar words that do occur in the training set. [sent-52, score-0.149]
</p><p>23 The first option is to use the Latent Words Language Model (LWLM) (Deschacht and Moens, 2009) – a language model that learns from an unlabeled corpus how to provide a weighted set of synonyms for words in context. [sent-54, score-0.264]
</p><p>24 The LWLM model is trained on the Reuters news article corpus of 80 million words. [sent-55, score-0.017]
</p><p>25 WordNet (Miller, 1995) is another resource for synonyms widely used in research and applications of natural language processing. [sent-56, score-0.247]
</p><p>26 Synonyms from WordNet seem to be very useful for bootstrapping as they provide replacement words to a specific word in a particular sense. [sent-57, score-0.128]
</p><p>27 For each synset in WordNet there is a collection of other “sister” synsets, called coordinate terms, which are topologically located under the same hypernym. [sent-58, score-0.072]
</p><p>28 3 Bootstrapping Strategies Having a list of synonyms for each token in the sentence, we can replace one of the original tokens by its synonym while still mostly preserving the sentence semantics. [sent-60, score-0.308]
</p><p>29 We choose to replace just the headword, under the assumption that since temporal trigger words usually occur at the headword position, adding alternative synonyms for the headword should allow our model to learn temporal triggers that did not appear in the training data. [sent-61, score-0.611]
</p><p>30 Bootstrapped models were asked to generate between one and ten additional training examples per instance. [sent-68, score-0.112]
</p><p>31 The maximum P, R, F1 and the number of synonyms at which this maximum was achieved are given in the P, R, F1 and # Syn rows. [sent-69, score-0.247]
</p><p>32 We designed the following bootstrapping strategies for generating new temporal expressions: • LWLM: the phrasal head is replaced by one of the LWLM synonyms. [sent-72, score-0.355]
</p><p>33 • WordNet Sense: Synonyms and coordinate  1st  terms for the most common sense of the phrasal head are selected and used for generating new examples of time expressions. [sent-73, score-0.19]
</p><p>34 • WordNet Pseudo-Lesk: The synset for the phrasal head is selected as having the largest intersection between the synset’s words and the LWLM synonyms. [sent-74, score-0.117]
</p><p>35 Then, synonyms and coordinate terms are used for generating new examples of time expressions. [sent-75, score-0.361]
</p><p>36 • LWLM+WordNet: The intersection of the LWLM synonyms and the WordNet synset found by pseudo-Lesk are used. [sent-76, score-0.306]
</p><p>37 In this way for every annotated time expression we generate n new examples (n∈[1 ,10]) and use them for training bootstrapped classification models. [sent-77, score-0.225]
</p><p>38 4  Experimental Setup  The tested model is trained on the official TempEval 2010 training data with 53450 tokens and 2117 annotated TIMEX3 tokens. [sent-78, score-0.112]
</p><p>39 For testing the portability of the model to other domains we annotated two small target domain document collections with TIMEX3 tags. [sent-79, score-0.108]
</p><p>40 , 2004), containing 2960 total tokens and 240 annotated TIMEX3 tokens (interannotator agreement 0. [sent-81, score-0.103]
</p><p>41 org/wiki/Obama), containing 7029 total tokens and 5 12 annotated TIMEX3 tokens (inter-annotator agreement 0. [sent-85, score-0.103]
</p><p>42 The basic TempEval model is evaluated on the source domain (TempEval 2010 evaluation set 9599 tokens in total and 269 TIMEX3 annotated tokens) and target domain data (Reuters and Wikipedia) using the TempEval 2010 evaluation metrics. [sent-87, score-0.159]
</p><p>43 Since porting the model onto other domains usually causes a performance drop, our experiments are focused on improving the results by employing different bootstrapping strategies1. [sent-88, score-0.239]
</p><p>44 5  Results  The recognition performance of the model is reported in Table 1 (column “Basic TempEval Model”) for the source and the target domains. [sent-89, score-0.07]
</p><p>45 The basic TempEval model itself achieves F1-score of 0. [sent-90, score-0.057]
</p><p>46 834 on the official TempEval 2010 evaluation corpus and has a potential rank 8 among 15 participated systems. [sent-91, score-0.015]
</p><p>47 1 The annotated datasets are available at http://www. [sent-95, score-0.021]
</p><p>48 php  Figure 1: F1 score of the LWLM bootstrapping strategy, generating from zero to ten additional training examples per instance. [sent-99, score-0.244]
</p><p>49 However, this model does not port well to the Reuters corpus (0. [sent-100, score-0.017]
</p><p>50 For the Wikipedia-based corpus, the basic TempEval model actually performs a little better than on the  source domain (0. [sent-104, score-0.077]
</p><p>51 Table 1 shows the maximum F1 score achieved by each of these strategies, along with the number of generated synonyms (between one and ten) at which this maximum was achieved. [sent-109, score-0.247]
</p><p>52 None of the bootstrapped models outperformed the basic TempEval model on the TempEval 2010 evaluation data, and the WordNet 1st Sense strategy and the WordNet Pseudo-Lesk strategy never outperformed the basic TempEval model on any corpus. [sent-110, score-0.325]
</p><p>53 However, for the Reuters and Wikipedia corpora, the LWLM and LWLM+WordNet bootstrapping strategies outperformed the basic TempEval model. [sent-111, score-0.225]
</p><p>54 The LWLM strategy gives a large boost to model performance on the Reuters corpus from 0. [sent-112, score-0.156]
</p><p>55 This puts performance on Reuters near performance on the TempEval domain from which the model was trained (0. [sent-116, score-0.069]
</p><p>56 On the Wikipedia corpus, the LWLM bootstrapping strategy results in a moderate boost, from 0. [sent-119, score-0.232]
</p><p>57 Figure 1 shows that using more synonyms with this strategy drops perform274  Figure 2: F1 score of the LWLM+WordNet bootstrapping strategy, generating from zero to ten additional training examples per instance. [sent-123, score-0.578]
</p><p>58 ance on the Wikipedia corpus back down to the level of the basic TempEval model. [sent-124, score-0.056]
</p><p>59 The LWLM+WordNet strategy gives a moderate boost on the Reuters corpus from 0. [sent-125, score-0.158]
</p><p>60 Figure 2 shows that using six or more synonyms drops this performance back to just above the basic TempEval model. [sent-129, score-0.321]
</p><p>61 On the Wikipedia corpus, the LWLM+WordNet strategy results in a moderate boost, from 0. [sent-130, score-0.104]
</p><p>62 Using additional synonyms results in a small decline in performance, though even with ten synonyms, the performance is better than the basic TempEval model. [sent-134, score-0.351]
</p><p>63 In general, the LWLM strategy gives the best performance, while the LWLM+WordNet strategy is less sensitive to the exact number of synonyms used when expanding the training data. [sent-135, score-0.42]
</p><p>64 6  TempEval Error Analysis  We were curious why synonym-based bootstrapping did not improve performance on the source-domain TempEval 2010 data. [sent-136, score-0.16]
</p><p>65 An error analysis suggested that some time expressions might have been left unannotated by the human annotators. [sent-137, score-0.133]
</p><p>66 887 F1-score with the TempEval  annotators, primarily due to unannotated time expressions such as 23-year, a few days and thirdquarter. [sent-141, score-0.114]
</p><p>67 Figure 3 : F 1 score of the LWLM bootstrapping strategy, comparing performance on the original TempEval data to the re-annotated version. [sent-142, score-0.144]
</p><p>68 Using this re-annotated TempEval 2010 data2, we re-evaluated the proposed bootstrapping techniques. [sent-143, score-0.128]
</p><p>69 Figure 3 and Figure 4 compare performance on the original TempEval data to performance on the re-annotated version. [sent-144, score-0.032]
</p><p>70 We now see the same trends for the TempEval data as were observed for  the Reuters and Wikipedia corpora: using a small number of synonyms from the LWLM to generate new training examples leads to performance gains. [sent-145, score-0.327]
</p><p>71 The LWLM bootstrapping model using the first synonym achieves 0. [sent-146, score-0.165]
</p><p>72 7  Discussion and Conclusions  We have presented model-portability experiments on time expression recognition with a number of bootstrapping strategies. [sent-150, score-0.272]
</p><p>73 These bootstrapping strategies generate additional training examples by substituting temporal expression words with potential synonyms from two sources: WordNet and the Latent Word Language Model (LWLM). [sent-151, score-0.699]
</p><p>74 Bootstrapping with LWLM synonyms provides a large boost for Reuters data and TempEval data and a decent boost for Wikipedia data when the top few synonyms are used. [sent-152, score-0.602]
</p><p>75 Additional synonyms do not help, probably because they are too newswirespecific: both the contexts from the TempEval training data and the synonyms from the Reuterstrained LWLM come from newswire text, so the 2 Available at  http://www. [sent-153, score-0.527]
</p><p>76 php 275  Figure 4: F1 score of the LWLM+WordNet bootstrapping strategy, comparing performance on the original TempEval data to the re-annotated version. [sent-157, score-0.144]
</p><p>77 Intersecting the synonyms generated by the LWLM and by WordNet moderates the LWLM, making the bootstrapping strategy less sensitive to the exact number of synonyms used. [sent-159, score-0.691]
</p><p>78 However,  while the intersected model performs as well as the LWLM model on Wikipedia, the gains over the non-bootstrapped model on Reuters and TempEval data are smaller. [sent-160, score-0.051]
</p><p>79 Overall, our results show that when porting time expression recognition models to other domains, a performance drop can be avoided by synonymbased bootstrapping. [sent-161, score-0.202]
</p><p>80 Future work will focus on using synonym-based expansion in the contexts (not just the time expressions headwords), and on incorporating contextual information and syntactic transformations. [sent-162, score-0.096]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tempeval', 0.642), ('lwlm', 0.568), ('synonyms', 0.247), ('reuters', 0.216), ('bootstrapping', 0.128), ('wordnet', 0.121), ('temporal', 0.113), ('poveda', 0.092), ('jordi', 0.074), ('expression', 0.072), ('wikipedia', 0.072), ('strategy', 0.069), ('expressions', 0.061), ('kolomiyets', 0.055), ('boost', 0.054), ('synset', 0.043), ('surdeanu', 0.042), ('porting', 0.042), ('tokens', 0.041), ('seeds', 0.04), ('basic', 0.04), ('headword', 0.04), ('moens', 0.038), ('strategies', 0.037), ('recognition', 0.037), ('deschacht', 0.037), ('llorens', 0.037), ('oleksandr', 0.037), ('tgen', 0.037), ('moderate', 0.035), ('time', 0.035), ('bootstrapped', 0.033), ('negri', 0.032), ('verhagen', 0.032), ('examples', 0.031), ('head', 0.031), ('mihai', 0.031), ('ten', 0.031), ('portability', 0.03), ('coordinate', 0.029), ('normalization', 0.028), ('hacioglu', 0.028), ('phrasal', 0.027), ('mani', 0.025), ('uppsala', 0.025), ('reduction', 0.024), ('intersecting', 0.024), ('triggers', 0.023), ('lewis', 0.022), ('ahn', 0.022), ('annotated', 0.021), ('substituting', 0.021), ('april', 0.021), ('domain', 0.02), ('domains', 0.02), ('outperformed', 0.02), ('str', 0.02), ('synonym', 0.02), ('grishman', 0.02), ('error', 0.019), ('generating', 0.019), ('sense', 0.018), ('drops', 0.018), ('training', 0.018), ('unannotated', 0.018), ('expanding', 0.017), ('chunks', 0.017), ('additional', 0.017), ('model', 0.017), ('latent', 0.017), ('intersection', 0.016), ('semisupervised', 0.016), ('yiming', 0.016), ('hector', 0.016), ('amass', 0.016), ('celestijnenlaan', 0.016), ('ole', 0.016), ('ance', 0.016), ('curious', 0.016), ('matteo', 0.016), ('sundheim', 0.016), ('tern', 0.016), ('onto', 0.016), ('performance', 0.016), ('george', 0.015), ('patterns', 0.015), ('probably', 0.015), ('headwords', 0.015), ('atem', 0.015), ('turmo', 0.015), ('kadri', 0.015), ('flemish', 0.015), ('leuven', 0.015), ('bethard', 0.015), ('luca', 0.015), ('roser', 0.015), ('generate', 0.015), ('official', 0.015), ('extraction', 0.015), ('iterative', 0.014)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="222-tfidf-1" href="./acl-2011-Model-Portability_Experiments_for_Textual_Temporal_Analysis.html">222 acl-2011-Model-Portability Experiments for Textual Temporal Analysis</a></p>
<p>Author: Oleksandr Kolomiyets ; Steven Bethard ; Marie-Francine Moens</p><p>Abstract: We explore a semi-supervised approach for improving the portability of time expression recognition to non-newswire domains: we generate additional training examples by substituting temporal expression words with potential synonyms. We explore using synonyms both from WordNet and from the Latent Words Language Model (LWLM), which predicts synonyms in context using an unsupervised approach. We evaluate a state-of-the-art time expression recognition system trained both with and without the additional training examples using data from TempEval 2010, Reuters and Wikipedia. We find that the LWLM provides substantial improvements on the Reuters corpus, and smaller improvements on the Wikipedia corpus. We find that WordNet alone never improves performance, though intersecting the examples from the LWLM and WordNet provides more stable results for Wikipedia. 1</p><p>2 0.080304563 <a title="222-tfidf-2" href="./acl-2011-Temporal_Evaluation.html">294 acl-2011-Temporal Evaluation</a></p>
<p>Author: Naushad UzZaman ; James Allen</p><p>Abstract: In this paper we propose a new method for evaluating systems that extract temporal information from text. It uses temporal closure1 to reward relations that are equivalent but distinct. Our metric measures the overall performance of systems with a single score, making comparison between different systems straightforward. Our approach is easy to implement, intuitive, accurate, scalable and computationally inexpensive. 1</p><p>3 0.067568608 <a title="222-tfidf-3" href="./acl-2011-Identification_of_Domain-Specific_Senses_in_a_Machine-Readable_Dictionary.html">158 acl-2011-Identification of Domain-Specific Senses in a Machine-Readable Dictionary</a></p>
<p>Author: Fumiyo Fukumoto ; Yoshimi Suzuki</p><p>Abstract: This paper focuses on domain-specific senses and presents a method for assigning category/domain label to each sense of words in a dictionary. The method first identifies each sense of a word in the dictionary to its corresponding category. We used a text classification technique to select appropriate senses for each domain. Then, senses were scored by computing the rank scores. We used Markov Random Walk (MRW) model. The method was tested on English and Japanese resources, WordNet 3.0 and EDR Japanese dictionary. For evaluation of the method, we compared English results with the Subject Field Codes (SFC) resources. We also compared each English and Japanese results to the first sense heuristics in the WSD task. These results suggest that identification of domain-specific senses (IDSS) may actually be of benefit.</p><p>4 0.065661952 <a title="222-tfidf-4" href="./acl-2011-Together_We_Can%3A_Bilingual_Bootstrapping_for_WSD.html">304 acl-2011-Together We Can: Bilingual Bootstrapping for WSD</a></p>
<p>Author: Mitesh M. Khapra ; Salil Joshi ; Arindam Chatterjee ; Pushpak Bhattacharyya</p><p>Abstract: Recent work on bilingual Word Sense Disambiguation (WSD) has shown that a resource deprived language (L1) can benefit from the annotation work done in a resource rich language (L2) via parameter projection. However, this method assumes the presence of sufficient annotated data in one resource rich language which may not always be possible. Instead, we focus on the situation where there are two resource deprived languages, both having a very small amount of seed annotated data and a large amount of untagged data. We then use bilingual bootstrapping, wherein, a model trained using the seed annotated data of L1 is used to annotate the untagged data of L2 and vice versa using parameter projection. The untagged instances of L1 and L2 which get annotated with high confidence are then added to the seed data of the respective languages and the above process is repeated. Our experiments show that such a bilingual bootstrapping algorithm when evaluated on two different domains with small seed sizes using Hindi (L1) and Marathi (L2) as the language pair performs better than monolingual bootstrapping and significantly reduces annotation cost.</p><p>5 0.058140475 <a title="222-tfidf-5" href="./acl-2011-Identifying_the_Semantic_Orientation_of_Foreign_Words.html">162 acl-2011-Identifying the Semantic Orientation of Foreign Words</a></p>
<p>Author: Ahmed Hassan ; Amjad AbuJbara ; Rahul Jha ; Dragomir Radev</p><p>Abstract: We present a method for identifying the positive or negative semantic orientation of foreign words. Identifying the semantic orientation of words has numerous applications in the areas of text classification, analysis of product review, analysis of responses to surveys, and mining online discussions. Identifying the semantic orientation of English words has been extensively studied in literature. Most of this work assumes the existence of resources (e.g. Wordnet, seeds, etc) that do not exist in foreign languages. In this work, we describe a method based on constructing a multilingual network connecting English and foreign words. We use this network to identify the semantic orientation of foreign words based on connection between words in the same language as well as multilingual connections. The method is experimentally tested using a manually labeled set of positive and negative words and has shown very promising results.</p><p>6 0.053510055 <a title="222-tfidf-6" href="./acl-2011-Improving_Dependency_Parsing_with_Semantic_Classes.html">167 acl-2011-Improving Dependency Parsing with Semantic Classes</a></p>
<p>7 0.05331865 <a title="222-tfidf-7" href="./acl-2011-Unsupervised_Decomposition_of_a_Document_into_Authorial_Components.html">319 acl-2011-Unsupervised Decomposition of a Document into Authorial Components</a></p>
<p>8 0.047857907 <a title="222-tfidf-8" href="./acl-2011-Can_Document_Selection_Help_Semi-supervised_Learning%3F_A_Case_Study_On_Event_Extraction.html">65 acl-2011-Can Document Selection Help Semi-supervised Learning? A Case Study On Event Extraction</a></p>
<p>9 0.045076076 <a title="222-tfidf-9" href="./acl-2011-HITS-based_Seed_Selection_and_Stop_List_Construction_for_Bootstrapping.html">148 acl-2011-HITS-based Seed Selection and Stop List Construction for Bootstrapping</a></p>
<p>10 0.041429382 <a title="222-tfidf-10" href="./acl-2011-Exploring_Entity_Relations_for_Named_Entity_Disambiguation.html">128 acl-2011-Exploring Entity Relations for Named Entity Disambiguation</a></p>
<p>11 0.038473275 <a title="222-tfidf-11" href="./acl-2011-Entity_Set_Expansion_using_Topic_information.html">117 acl-2011-Entity Set Expansion using Topic information</a></p>
<p>12 0.038009256 <a title="222-tfidf-12" href="./acl-2011-Relation_Guided_Bootstrapping_of_Semantic_Lexicons.html">262 acl-2011-Relation Guided Bootstrapping of Semantic Lexicons</a></p>
<p>13 0.036973488 <a title="222-tfidf-13" href="./acl-2011-Local_and_Global_Algorithms_for_Disambiguation_to_Wikipedia.html">213 acl-2011-Local and Global Algorithms for Disambiguation to Wikipedia</a></p>
<p>14 0.036242649 <a title="222-tfidf-14" href="./acl-2011-End-to-End_Relation_Extraction_Using_Distant_Supervision_from_External_Semantic_Repositories.html">114 acl-2011-End-to-End Relation Extraction Using Distant Supervision from External Semantic Repositories</a></p>
<p>15 0.035728294 <a title="222-tfidf-15" href="./acl-2011-Wikipedia_Revision_Toolkit%3A_Efficiently_Accessing_Wikipedias_Edit_History.html">337 acl-2011-Wikipedia Revision Toolkit: Efficiently Accessing Wikipedias Edit History</a></p>
<p>16 0.035065018 <a title="222-tfidf-16" href="./acl-2011-Putting_it_Simply%3A_a_Context-Aware_Approach_to_Lexical_Simplification.html">254 acl-2011-Putting it Simply: a Context-Aware Approach to Lexical Simplification</a></p>
<p>17 0.035019625 <a title="222-tfidf-17" href="./acl-2011-NULEX%3A_An_Open-License_Broad_Coverage_Lexicon.html">229 acl-2011-NULEX: An Open-License Broad Coverage Lexicon</a></p>
<p>18 0.032614604 <a title="222-tfidf-18" href="./acl-2011-Using_Bilingual_Parallel_Corpora_for_Cross-Lingual_Textual_Entailment.html">327 acl-2011-Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment</a></p>
<p>19 0.032089733 <a title="222-tfidf-19" href="./acl-2011-French_TimeBank%3A_An_ISO-TimeML_Annotated_Reference_Corpus.html">138 acl-2011-French TimeBank: An ISO-TimeML Annotated Reference Corpus</a></p>
<p>20 0.029940452 <a title="222-tfidf-20" href="./acl-2011-Extracting_Opinion_Expressions_and_Their_Polarities_-_Exploration_of_Pipelines_and_Joint_Models.html">131 acl-2011-Extracting Opinion Expressions and Their Polarities - Exploration of Pipelines and Joint Models</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.084), (1, 0.022), (2, -0.042), (3, 0.005), (4, 0.011), (5, -0.007), (6, 0.032), (7, 0.001), (8, -0.028), (9, -0.019), (10, -0.002), (11, -0.017), (12, 0.049), (13, -0.018), (14, 0.004), (15, -0.03), (16, 0.094), (17, -0.01), (18, 0.002), (19, -0.002), (20, 0.023), (21, 0.002), (22, -0.002), (23, 0.005), (24, 0.038), (25, -0.021), (26, 0.029), (27, 0.051), (28, 0.016), (29, 0.038), (30, 0.062), (31, 0.014), (32, 0.044), (33, -0.058), (34, 0.017), (35, 0.01), (36, -0.041), (37, 0.022), (38, 0.034), (39, -0.033), (40, 0.034), (41, 0.012), (42, -0.031), (43, 0.008), (44, -0.012), (45, -0.0), (46, -0.017), (47, -0.009), (48, 0.021), (49, -0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.84802765 <a title="222-lsi-1" href="./acl-2011-Model-Portability_Experiments_for_Textual_Temporal_Analysis.html">222 acl-2011-Model-Portability Experiments for Textual Temporal Analysis</a></p>
<p>Author: Oleksandr Kolomiyets ; Steven Bethard ; Marie-Francine Moens</p><p>Abstract: We explore a semi-supervised approach for improving the portability of time expression recognition to non-newswire domains: we generate additional training examples by substituting temporal expression words with potential synonyms. We explore using synonyms both from WordNet and from the Latent Words Language Model (LWLM), which predicts synonyms in context using an unsupervised approach. We evaluate a state-of-the-art time expression recognition system trained both with and without the additional training examples using data from TempEval 2010, Reuters and Wikipedia. We find that the LWLM provides substantial improvements on the Reuters corpus, and smaller improvements on the Wikipedia corpus. We find that WordNet alone never improves performance, though intersecting the examples from the LWLM and WordNet provides more stable results for Wikipedia. 1</p><p>2 0.62063384 <a title="222-lsi-2" href="./acl-2011-Together_We_Can%3A_Bilingual_Bootstrapping_for_WSD.html">304 acl-2011-Together We Can: Bilingual Bootstrapping for WSD</a></p>
<p>Author: Mitesh M. Khapra ; Salil Joshi ; Arindam Chatterjee ; Pushpak Bhattacharyya</p><p>Abstract: Recent work on bilingual Word Sense Disambiguation (WSD) has shown that a resource deprived language (L1) can benefit from the annotation work done in a resource rich language (L2) via parameter projection. However, this method assumes the presence of sufficient annotated data in one resource rich language which may not always be possible. Instead, we focus on the situation where there are two resource deprived languages, both having a very small amount of seed annotated data and a large amount of untagged data. We then use bilingual bootstrapping, wherein, a model trained using the seed annotated data of L1 is used to annotate the untagged data of L2 and vice versa using parameter projection. The untagged instances of L1 and L2 which get annotated with high confidence are then added to the seed data of the respective languages and the above process is repeated. Our experiments show that such a bilingual bootstrapping algorithm when evaluated on two different domains with small seed sizes using Hindi (L1) and Marathi (L2) as the language pair performs better than monolingual bootstrapping and significantly reduces annotation cost.</p><p>3 0.59048516 <a title="222-lsi-3" href="./acl-2011-NULEX%3A_An_Open-License_Broad_Coverage_Lexicon.html">229 acl-2011-NULEX: An Open-License Broad Coverage Lexicon</a></p>
<p>Author: Clifton McFate ; Kenneth Forbus</p><p>Abstract: Broad coverage lexicons for the English language have traditionally been handmade. This approach, while accurate, requires too much human labor. Furthermore, resources contain gaps in coverage, contain specific types of information, or are incompatible with other resources. We believe that the state of open-license technology is such that a comprehensive syntactic lexicon can be automatically compiled. This paper describes the creation of such a lexicon, NU-LEX, an open-license feature-based lexicon for general purpose parsing that combines WordNet, VerbNet, and Wiktionary and contains over 100,000 words. NU-LEX was integrated into a bottom up chart parser. We ran the parser through three sets of sentences, 50 sentences total, from the Simple English Wikipedia and compared its performance to the same parser using Comlex. Both parsers performed almost equally with NU-LEX finding all lex-items for 50% of the sentences and Comlex succeeding for 52%. Furthermore, NULEX’s shortcomings primarily fell into two categories, suggesting future research directions. 1</p><p>4 0.56754094 <a title="222-lsi-4" href="./acl-2011-Identifying_the_Semantic_Orientation_of_Foreign_Words.html">162 acl-2011-Identifying the Semantic Orientation of Foreign Words</a></p>
<p>Author: Ahmed Hassan ; Amjad AbuJbara ; Rahul Jha ; Dragomir Radev</p><p>Abstract: We present a method for identifying the positive or negative semantic orientation of foreign words. Identifying the semantic orientation of words has numerous applications in the areas of text classification, analysis of product review, analysis of responses to surveys, and mining online discussions. Identifying the semantic orientation of English words has been extensively studied in literature. Most of this work assumes the existence of resources (e.g. Wordnet, seeds, etc) that do not exist in foreign languages. In this work, we describe a method based on constructing a multilingual network connecting English and foreign words. We use this network to identify the semantic orientation of foreign words based on connection between words in the same language as well as multilingual connections. The method is experimentally tested using a manually labeled set of positive and negative words and has shown very promising results.</p><p>5 0.53933138 <a title="222-lsi-5" href="./acl-2011-Local_and_Global_Algorithms_for_Disambiguation_to_Wikipedia.html">213 acl-2011-Local and Global Algorithms for Disambiguation to Wikipedia</a></p>
<p>Author: Lev Ratinov ; Dan Roth ; Doug Downey ; Mike Anderson</p><p>Abstract: Disambiguating concepts and entities in a context sensitive way is a fundamental problem in natural language processing. The comprehensiveness of Wikipedia has made the online encyclopedia an increasingly popular target for disambiguation. Disambiguation to Wikipedia is similar to a traditional Word Sense Disambiguation task, but distinct in that the Wikipedia link structure provides additional information about which disambiguations are compatible. In this work we analyze approaches that utilize this information to arrive at coherent sets of disambiguations for a given document (which we call “global” approaches), and compare them to more traditional (local) approaches. We show that previous approaches for global disambiguation can be improved, but even then the local disambiguation provides a baseline which is very hard to beat.</p><p>6 0.52293217 <a title="222-lsi-6" href="./acl-2011-HITS-based_Seed_Selection_and_Stop_List_Construction_for_Bootstrapping.html">148 acl-2011-HITS-based Seed Selection and Stop List Construction for Bootstrapping</a></p>
<p>7 0.52053744 <a title="222-lsi-7" href="./acl-2011-Wikipedia_Revision_Toolkit%3A_Efficiently_Accessing_Wikipedias_Edit_History.html">337 acl-2011-Wikipedia Revision Toolkit: Efficiently Accessing Wikipedias Edit History</a></p>
<p>8 0.49388713 <a title="222-lsi-8" href="./acl-2011-Exploring_Entity_Relations_for_Named_Entity_Disambiguation.html">128 acl-2011-Exploring Entity Relations for Named Entity Disambiguation</a></p>
<p>9 0.49205226 <a title="222-lsi-9" href="./acl-2011-Insights_from_Network_Structure_for_Text_Mining.html">174 acl-2011-Insights from Network Structure for Text Mining</a></p>
<p>10 0.47349834 <a title="222-lsi-10" href="./acl-2011-Identification_of_Domain-Specific_Senses_in_a_Machine-Readable_Dictionary.html">158 acl-2011-Identification of Domain-Specific Senses in a Machine-Readable Dictionary</a></p>
<p>11 0.46029598 <a title="222-lsi-11" href="./acl-2011-Wikulu%3A_An_Extensible_Architecture_for_Integrating_Natural_Language_Processing_Techniques_with_Wikis.html">338 acl-2011-Wikulu: An Extensible Architecture for Integrating Natural Language Processing Techniques with Wikis</a></p>
<p>12 0.45694989 <a title="222-lsi-12" href="./acl-2011-Which_Noun_Phrases_Denote_Which_Concepts%3F.html">334 acl-2011-Which Noun Phrases Denote Which Concepts?</a></p>
<p>13 0.45223439 <a title="222-lsi-13" href="./acl-2011-MACAON_An_NLP_Tool_Suite_for_Processing_Word_Lattices.html">215 acl-2011-MACAON An NLP Tool Suite for Processing Word Lattices</a></p>
<p>14 0.45094416 <a title="222-lsi-14" href="./acl-2011-Towards_Tracking_Semantic_Change_by_Visual_Analytics.html">307 acl-2011-Towards Tracking Semantic Change by Visual Analytics</a></p>
<p>15 0.44975975 <a title="222-lsi-15" href="./acl-2011-French_TimeBank%3A_An_ISO-TimeML_Annotated_Reference_Corpus.html">138 acl-2011-French TimeBank: An ISO-TimeML Annotated Reference Corpus</a></p>
<p>16 0.44951472 <a title="222-lsi-16" href="./acl-2011-Evaluating_the_Impact_of_Coder_Errors_on_Active_Learning.html">119 acl-2011-Evaluating the Impact of Coder Errors on Active Learning</a></p>
<p>17 0.44797724 <a title="222-lsi-17" href="./acl-2011-End-to-End_Relation_Extraction_Using_Distant_Supervision_from_External_Semantic_Repositories.html">114 acl-2011-End-to-End Relation Extraction Using Distant Supervision from External Semantic Repositories</a></p>
<p>18 0.44184488 <a title="222-lsi-18" href="./acl-2011-Types_of_Common-Sense_Knowledge_Needed_for_Recognizing_Textual_Entailment.html">315 acl-2011-Types of Common-Sense Knowledge Needed for Recognizing Textual Entailment</a></p>
<p>19 0.43861943 <a title="222-lsi-19" href="./acl-2011-Language_of_Vandalism%3A_Improving_Wikipedia_Vandalism_Detection_via_Stylometric_Analysis.html">195 acl-2011-Language of Vandalism: Improving Wikipedia Vandalism Detection via Stylometric Analysis</a></p>
<p>20 0.42280433 <a title="222-lsi-20" href="./acl-2011-Temporal_Evaluation.html">294 acl-2011-Temporal Evaluation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.026), (17, 0.042), (26, 0.029), (37, 0.119), (39, 0.04), (41, 0.049), (55, 0.015), (59, 0.064), (72, 0.035), (90, 0.267), (91, 0.057), (96, 0.096), (97, 0.037), (98, 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.71942568 <a title="222-lda-1" href="./acl-2011-Model-Portability_Experiments_for_Textual_Temporal_Analysis.html">222 acl-2011-Model-Portability Experiments for Textual Temporal Analysis</a></p>
<p>Author: Oleksandr Kolomiyets ; Steven Bethard ; Marie-Francine Moens</p><p>Abstract: We explore a semi-supervised approach for improving the portability of time expression recognition to non-newswire domains: we generate additional training examples by substituting temporal expression words with potential synonyms. We explore using synonyms both from WordNet and from the Latent Words Language Model (LWLM), which predicts synonyms in context using an unsupervised approach. We evaluate a state-of-the-art time expression recognition system trained both with and without the additional training examples using data from TempEval 2010, Reuters and Wikipedia. We find that the LWLM provides substantial improvements on the Reuters corpus, and smaller improvements on the Wikipedia corpus. We find that WordNet alone never improves performance, though intersecting the examples from the LWLM and WordNet provides more stable results for Wikipedia. 1</p><p>2 0.69827467 <a title="222-lda-2" href="./acl-2011-Local_Histograms_of_Character_N-grams_for_Authorship_Attribution.html">212 acl-2011-Local Histograms of Character N-grams for Authorship Attribution</a></p>
<p>Author: Hugo Jair Escalante ; Thamar Solorio ; Manuel Montes-y-Gomez</p><p>Abstract: This paper proposes the use of local histograms (LH) over character n-grams for authorship attribution (AA). LHs are enriched histogram representations that preserve sequential information in documents; they have been successfully used for text categorization and document visualization using word histograms. In this work we explore the suitability of LHs over n-grams at the character-level for AA. We show that LHs are particularly helpful for AA, because they provide useful information for uncovering, to some extent, the writing style of authors. We report experimental results in AA data sets that confirm that LHs over character n-grams are more helpful for AA than the usual global histograms, yielding results far superior to state of the art approaches. We found that LHs are even more advantageous in challenging conditions, such as having imbalanced and small training sets. Our results motivate further research on the use of LHs for modeling the writing style of authors for related tasks, such as authorship verification and plagiarism detection.</p><p>3 0.65251213 <a title="222-lda-3" href="./acl-2011-Ranking_Class_Labels_Using_Query_Sessions.html">258 acl-2011-Ranking Class Labels Using Query Sessions</a></p>
<p>Author: Marius Pasca</p><p>Abstract: The role of search queries, as available within query sessions or in isolation from one another, in examined in the context of ranking the class labels (e.g., brazilian cities, business centers, hilly sites) extracted from Web documents for various instances (e.g., rio de janeiro). The co-occurrence of a class label and an instance, in the same query or within the same query session, is used to reinforce the estimated relevance of the class label for the instance. Experiments over evaluation sets of instances associated with Web search queries illustrate the higher quality of the query-based, re-ranked class labels, relative to ranking baselines using documentbased counts.</p><p>4 0.6503278 <a title="222-lda-4" href="./acl-2011-C-Feel-It%3A_A_Sentiment_Analyzer_for_Micro-blogs.html">64 acl-2011-C-Feel-It: A Sentiment Analyzer for Micro-blogs</a></p>
<p>Author: Aditya Joshi ; Balamurali AR ; Pushpak Bhattacharyya ; Rajat Mohanty</p><p>Abstract: Social networking and micro-blogging sites are stores of opinion-bearing content created by human users. We describe C-Feel-It, a system which can tap opinion content in posts (called tweets) from the micro-blogging website, Twitter. This web-based system categorizes tweets pertaining to a search string as positive, negative or objective and gives an aggregate sentiment score that represents a sentiment snapshot for a search string. We present a qualitative evaluation of this system based on a human-annotated tweet corpus.</p><p>5 0.61826718 <a title="222-lda-5" href="./acl-2011-Model-Based_Aligner_Combination_Using_Dual_Decomposition.html">221 acl-2011-Model-Based Aligner Combination Using Dual Decomposition</a></p>
<p>Author: John DeNero ; Klaus Macherey</p><p>Abstract: Unsupervised word alignment is most often modeled as a Markov process that generates a sentence f conditioned on its translation e. A similar model generating e from f will make different alignment predictions. Statistical machine translation systems combine the predictions of two directional models, typically using heuristic combination procedures like grow-diag-final. This paper presents a graphical model that embeds two directional aligners into a single model. Inference can be performed via dual decomposition, which reuses the efficient inference algorithms of the directional models. Our bidirectional model enforces a one-to-one phrase constraint while accounting for the uncertainty in the underlying directional models. The resulting alignments improve upon baseline combination heuristics in word-level and phrase-level evaluations.</p><p>6 0.55785805 <a title="222-lda-6" href="./acl-2011-Improving_Arabic_Dependency_Parsing_with_Form-based_and_Functional_Morphological_Features.html">164 acl-2011-Improving Arabic Dependency Parsing with Form-based and Functional Morphological Features</a></p>
<p>7 0.55465782 <a title="222-lda-7" href="./acl-2011-Exploiting_Syntactico-Semantic_Structures_for_Relation_Extraction.html">126 acl-2011-Exploiting Syntactico-Semantic Structures for Relation Extraction</a></p>
<p>8 0.54947448 <a title="222-lda-8" href="./acl-2011-Coreference_Resolution_with_World_Knowledge.html">85 acl-2011-Coreference Resolution with World Knowledge</a></p>
<p>9 0.54739368 <a title="222-lda-9" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<p>10 0.54724872 <a title="222-lda-10" href="./acl-2011-Subjectivity_and_Sentiment_Analysis_of_Modern_Standard_Arabic.html">289 acl-2011-Subjectivity and Sentiment Analysis of Modern Standard Arabic</a></p>
<p>11 0.54655749 <a title="222-lda-11" href="./acl-2011-Joint_Training_of_Dependency_Parsing_Filters_through_Latent_Support_Vector_Machines.html">186 acl-2011-Joint Training of Dependency Parsing Filters through Latent Support Vector Machines</a></p>
<p>12 0.54602444 <a title="222-lda-12" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>13 0.54507267 <a title="222-lda-13" href="./acl-2011-Improving_Dependency_Parsing_with_Semantic_Classes.html">167 acl-2011-Improving Dependency Parsing with Semantic Classes</a></p>
<p>14 0.54506987 <a title="222-lda-14" href="./acl-2011-Target-dependent_Twitter_Sentiment_Classification.html">292 acl-2011-Target-dependent Twitter Sentiment Classification</a></p>
<p>15 0.54470915 <a title="222-lda-15" href="./acl-2011-Effects_of_Noun_Phrase_Bracketing_in_Dependency_Parsing_and_Machine_Translation.html">111 acl-2011-Effects of Noun Phrase Bracketing in Dependency Parsing and Machine Translation</a></p>
<p>16 0.54310155 <a title="222-lda-16" href="./acl-2011-A_Discriminative_Model_for_Joint_Morphological_Disambiguation_and_Dependency_Parsing.html">10 acl-2011-A Discriminative Model for Joint Morphological Disambiguation and Dependency Parsing</a></p>
<p>17 0.54284 <a title="222-lda-17" href="./acl-2011-Semi-supervised_Relation_Extraction_with_Large-scale_Word_Clustering.html">277 acl-2011-Semi-supervised Relation Extraction with Large-scale Word Clustering</a></p>
<p>18 0.54230171 <a title="222-lda-18" href="./acl-2011-Domain_Adaptation_by_Constraining_Inter-Domain_Variability_of_Latent_Feature_Representation.html">103 acl-2011-Domain Adaptation by Constraining Inter-Domain Variability of Latent Feature Representation</a></p>
<p>19 0.5413897 <a title="222-lda-19" href="./acl-2011-In-domain_Relation_Discovery_with_Meta-constraints_via_Posterior_Regularization.html">170 acl-2011-In-domain Relation Discovery with Meta-constraints via Posterior Regularization</a></p>
<p>20 0.54109448 <a title="222-lda-20" href="./acl-2011-Transition-based_Dependency_Parsing_with_Rich_Non-local_Features.html">309 acl-2011-Transition-based Dependency Parsing with Rich Non-local Features</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
