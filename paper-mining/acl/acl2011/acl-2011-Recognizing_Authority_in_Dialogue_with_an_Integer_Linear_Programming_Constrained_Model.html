<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>260 acl-2011-Recognizing Authority in Dialogue with an Integer Linear Programming Constrained Model</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-260" href="#">acl2011-260</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>260 acl-2011-Recognizing Authority in Dialogue with an Integer Linear Programming Constrained Model</h1>
<br/><p>Source: <a title="acl-2011-260-pdf" href="http://aclweb.org/anthology//P/P11/P11-1102.pdf">pdf</a></p><p>Author: Elijah Mayfield ; Carolyn Penstein Rose</p><p>Abstract: We present a novel computational formulation of speaker authority in discourse. This notion, which focuses on how speakers position themselves relative to each other in discourse, is first developed into a reliable coding scheme (0.71 agreement between human annotators). We also provide a computational model for automatically annotating text using this coding scheme, using supervised learning enhanced by constraints implemented with Integer Linear Programming. We show that this constrained model’s analyses of speaker authority correlates very strongly with expert human judgments (r2 coefficient of 0.947).</p><p>Reference: <a title="acl-2011-260-reference" href="../acl2011_reference/acl-2011-Recognizing_Authority_in_Dialogue_with_an_Integer_Linear_Programming_Constrained_Model_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract We present a novel computational formulation of speaker authority in discourse. [sent-2, score-0.58]
</p><p>2 This notion, which focuses on how speakers position themselves relative to each other in discourse, is first developed into a reliable coding scheme (0. [sent-3, score-0.28]
</p><p>3 We also provide a computational model for automatically annotating text using this coding scheme, using supervised learning enhanced by constraints implemented with Integer Linear Programming. [sent-5, score-0.23]
</p><p>4 We show that this constrained model’s analyses of speaker authority correlates very strongly with expert human judgments (r2 coefficient of 0. [sent-6, score-0.547]
</p><p>5 1 Introduction  In this work, we seek to formalize the ways speakers position themselves in discourse. [sent-8, score-0.173]
</p><p>6 We do this in a way that maintains a notion of discourse structure, and which can be aggregated to evaluate a speaker’s overall stance in a dialogue. [sent-9, score-0.213]
</p><p>7 We define the body of work in positioning to include any attempt to formalize the processes by which speakers attempt to influence or give evidence of their relations to each other. [sent-10, score-0.367]
</p><p>8 Constructs such as Initiative and Control (Whittaker and Stenton, 1988), which attempt to operationalize the authority over a discourse’s structure, fall under the umbrella of positioning. [sent-11, score-0.258]
</p><p>9 Work in dialogue act tagging is also relevant, as it seeks to describe the ac1018 Carolyn Penstein Ros e´ Language Technologies Institute Carnegie Mellon University Pittsburgh, PA 15213 cpro se @ cs cmu edu  . [sent-14, score-0.255]
</p><p>10 tions and moves with which speakers display these types of positioning (Stolcke et al. [sent-16, score-0.464]
</p><p>11 To complement these bodies of work, we choose to focus on the question of how speakers position themselves as authoritative in a discourse. [sent-18, score-0.232]
</p><p>12 While all of the tasks mentioned above focus on specific problems in the larger rhetorical question of speaker positioning, none explicitly address this framing of authority. [sent-20, score-0.293]
</p><p>13 Of the contentful dialogue moves made by a speaker, in what fraction of those moves is the speaker positioned as the primary authority on that topic? [sent-23, score-1.144]
</p><p>14 We present a reproducible formulation of this sociolinguistics research in section 3, along with our preliminary findings on reliability between human coders, where we observe inter-rater agreement of 0. [sent-25, score-0.211]
</p><p>15 Applying this coding scheme to data, we see strong correlations with important motivational constructs such as Self-Efficacy (Bandura, 1997) as well as learning gains. [sent-27, score-0.197]
</p><p>16 One dimension is a set of codes describing the authoritative status of a contribution1 . [sent-31, score-0.215]
</p><p>17 These constraints are formulated as boolean statements describing what a correct label sequence looks like, and are imposed on our model using an Integer Linear Programming formulation (Roth and Yih, 2004). [sent-34, score-0.23]
</p><p>18 , 1991) and shows a high correlation with human  judgements of authoritativeness (r2 = 0. [sent-36, score-0.323]
</p><p>19 2  Background  The Negotiation framework, as formulated by the SFL community, places a special emphasis on how speakers function in a discourse as sources or recipients of information or action. [sent-39, score-0.289]
</p><p>20 Much work has examined the emergence of discourse structure from the choices speakers make at the linguistic and intentional level (Grosz and Sidner, 1986). [sent-42, score-0.324]
</p><p>21 For instance, when a speaker asks a question, it is expected to be followed with an answer. [sent-43, score-0.244]
</p><p>22 In discourse analysis, this notion is described through dialogue games (Carlson, 1983), while conversation analysis frames the structure in terms of adjacency pairs (Schegloff, 2007). [sent-44, score-0.526]
</p><p>23 These expectations can be viewed under the umbrella of conditional relevance (Levinson, 2000), and the ex-  changes can be labelled discourse segments. [sent-45, score-0.214]
</p><p>24 In prior work, the way that people influence discourse structure is described through the two tightlyrelated concepts of initiative and control. [sent-46, score-0.364]
</p><p>25 A speaker who begins a discourse segment is said to have initiative, while control accounts for which speaker is being addressed in a dialogue (Whittaker and Stenton, 1988). [sent-47, score-1.045]
</p><p>26 As initiative passes back and forth between discourse participants, control over the con1We  single contribution. [sent-48, score-0.387]
</p><p>27 1019 versation similarly transfers from one speaker to another (Walker and Whittaker, 1990). [sent-49, score-0.244]
</p><p>28 Research in initiative and control has been applied in the form of mixed-initiative dialogue systems (Smith, 1992). [sent-51, score-0.431]
</p><p>29 However, that body of work focuses on influenctreat  each line in our corpus  as a  ing discourse structure through positioning. [sent-53, score-0.203]
</p><p>30 The question that we are asking instead focuses on how speakers view their authority as a source of information about the topic of the discourse. [sent-54, score-0.483]
</p><p>31 A speaker might already know the answer to a question they asked - for instance, when a teacher is verifying a student’s knowledge. [sent-58, score-0.326]
</p><p>32 However, in most cases asking a question represents a lack of authority, treating the other speakers as a source for that knowledge. [sent-59, score-0.225]
</p><p>33 While there have been preliminary attempts to separate out these specific types of positioning in initiative, such as Chu-Carroll and Brown (1998), it has not been studied extensively in a computational setting. [sent-60, score-0.194]
</p><p>34 Another similar thread of research is to identify a speaker’s certainty, that is, the confidence of a speaker and how that self-evaluation affects their language (Pon-Barry and Shieber, 2010). [sent-61, score-0.244]
</p><p>35 Substantial work has gone into automatically identifying levels of speaker certainty, for example in Liscombe  et al. [sent-62, score-0.244]
</p><p>36 The major difference between our work and this body of literature is that work on certainty has rarely focused on how state translates into interaction between speakers (with some exceptions, such as the application of certainty to tutoring dialogues (Forbes-Riley and Litman, 2009)). [sent-65, score-0.392]
</p><p>37 Instead, the focus is on the person’s self-evaluation, independent of the influence on the speaker’s positioning within a discourse. [sent-66, score-0.194]
</p><p>38 Dialogue act tagging seeks to describe the moves people make to express themselves in a discourse. [sent-67, score-0.192]
</p><p>39 We know that there are interesting correlations between these acts and other factors, such as learning gains (Litman and Forbes-Riley, 2006) and the relevance of a contribution for summarization (Wrede and Shriberg, 2003). [sent-70, score-0.207]
</p><p>40 However, adapting dialogue act tags to the question of how speakers position themselves is not straightforward. [sent-71, score-0.425]
</p><p>41 Many dialogue acts can be used in authoritative or nonauthoritative ways, based on context, and can posi-  tion a speaker as either giver or receiver of information. [sent-73, score-0.595]
</p><p>42 Thus these more general tagsets are not specific enough to the role of authority in discourse. [sent-74, score-0.31]
</p><p>43 It attempts to describe how speakers use their role as a source of knowledge or action to position themselves relative to others in a discourse. [sent-81, score-0.165]
</p><p>44 Applications of the framework include distinguishing between focus on teacher knowledge and student reasoning (Veel, 1999) and distribution of authority in juvenile trials (Martin et al. [sent-82, score-0.335]
</p><p>45 The  framework can also be applied to problems similar to those studied through the lens of initiative, such as the distinction between authority over discourse structure and authority over content (Martin, 2000). [sent-84, score-0.719]
</p><p>46 Within examples, discourse segment boundaries are shown by horizontal lines. [sent-86, score-0.287]
</p><p>47 1 Our Formulation of Negotiation The codes that we can apply to a contribution using the Negotiation framework are comprised offour main codes, K1, K2, A1, and A2, and two additional codes, ch and o. [sent-93, score-0.285]
</p><p>48 This is a reduction over the many task-specific or highly contextual codes used in the  original work. [sent-94, score-0.216]
</p><p>49 If the former, then it is a K move (knowledge); if the latter, then an A move (action). [sent-98, score-0.344]
</p><p>50 Research in the SFL community has focused on intra-segment structure, and empirical evidence from this research has shown that exchanges between speakers follow a very specific pattern: o* X2? [sent-106, score-0.191]
</p><p>51 o* X1+ o* That is to say, each segment contains a primary  move (a K1 or an A1) and an optional preceding secondary move, with other non-contentful moves interspersed throughout. [sent-107, score-0.54]
</p><p>52 A single statement of fact would be a K1 move comprising an entire segment, while a single question/answer pair would be a K2 move followed by a K1. [sent-108, score-0.344]
</p><p>53 We iteratively developed a coding manual which describes, in a reproducible way, how to apply the codes listed above. [sent-110, score-0.361]
</p><p>54 2 Preliminary Evaluation This coding scheme was evaluated for reliability on two corpora using Cohen’s kappa (Cohen, 1960). [sent-114, score-0.279]
</p><p>55 The first conversation was between three students in a collaborative learning task; inter-rater reliability kappa for Negotiation labels was 0. [sent-118, score-0.292]
</p><p>56 In our work, we label conversations using the coding scheme above. [sent-123, score-0.251]
</p><p>57 To determine how well these codes correlate with other interesting factors, we choose to assign a quantitative measure of authoritativeness to each speaker. [sent-124, score-0.476]
</p><p>58 y S with label l ∈ L  We then define the Authoritativeness ratio Auth(S) for a speaker S in a dialogue consisting of contributions c1. [sent-130, score-0.561]
</p><p>59 We sum these together to reach a single numeric value for each speaker’s projection of authority in the dialogue. [sent-135, score-0.258]
</p><p>60 Our analysis showed that aggressive behavior correlated with authoritativeness ratio (p < . [sent-140, score-0.422]
</p><p>61 We can also describe patterns that appear in discourse segments, as detailed in section 3. [sent-161, score-0.168]
</p><p>62 In our coding manual, these instructions are given as rules for how segments should be coded by humans. [sent-163, score-0.231]
</p><p>63 However, in the dialogue below, it is equally inarguable that the same move is an A1: 1022  fgAA12ygeoa ahlmost to the edge of the lake  Without this context, these moves would be indistinguishable to a model. [sent-170, score-0.576]
</p><p>64 We also observed that markers for segmentation of a segment vary between contentful initiations and non-contentful ones. [sent-172, score-0.335]
</p><p>65 However, after that backchannel move, a short floor-grabbing move is often made to start the next segment. [sent-178, score-0.172]
</p><p>66 This is markedly different from contentful segment initiations:  Afglthcroe2fscIytodhemunose d’octlindhr’catevlshcatolvnyedskatolwsniktewocn soeitmrabcteilrmcoulwpentsh,wic  often initiate new segments. [sent-180, score-0.257]
</p><p>67 We then add a feature for the predicted label of the previous contribution - after each contribution is classified, the next contribution adds a feature for the automatic label. [sent-187, score-0.32]
</p><p>68 We build two segmentation models, one trained on contributions of less than four tokens, and another trained on contributions of four or more tokens, to distinguish between characteristics of contentful and non-contentful contributions. [sent-189, score-0.173]
</p><p>69 The second represents  whether a change in speaker has occurred between the current and previous contribution. [sent-192, score-0.244]
</p><p>70 This formulation has an advantage over other sequence labelling formulations, such as Viterbi decoding, in its ability to enforce structure through constraints. [sent-195, score-0.174]
</p><p>71 We then enhance this classifier by adding constraints, which allow expert knowledge of discourse structure to be enforced in classification. [sent-196, score-0.246]
</p><p>72 We can use these constraints to eliminate label options which would violate the rules for a segment outlined in our coding manual. [sent-197, score-0.393]
</p><p>73 Each classification decision is made at the contribution level, jointly optimizing the Negotiation label and segmentation label for a single contribution, then treating those labels as given for the next contribution classification. [sent-198, score-0.359]
</p><p>74 all SVM, and use the resulting regression for each label as a score, giving us six values l~i for our Negotiation label and two values si for our segmentation label. [sent-200, score-0.175]
</p><p>75 1 that our discourse segments follow strict rules related to ordering and repetition of contributions. [sent-203, score-0.202]
</p><p>76 Below, we list the constraints that we used in our model to enforce that pattern, along with a brief explanation of the intuition behind each. [sent-204, score-0.169]
</p><p>77 ∀∀jci <∈ i s,,c(jli∈= t ⇒ K2) (lj ⇒6= K1) ∀∀cji <∈ i s,,c(jli∈= t ⇒ A2) (l ⇒j6= A1)  (1) (2)  The first constraints enforce the rule that a primary move cannot occur before a secondary move in the same segment. [sent-205, score-0.613]
</p><p>78 For instance, a question must  initiate a new segment if it follows a statement. [sent-206, score-0.22]
</p><p>79 ∀∀jci <∈ i s,,c(jli∈∈ s { ⇒A1 (,ljA ∈2/} {)K ⇒1,K2}) ∀∀cji <∈ i s,,c(jli∈∈ s { ⇒K1 (l,jK ∈/2} {)A ⇒1,A2})  (3) (4)  These constraints specify that A moves and K moves cannot cooccur in a segment. [sent-207, score-0.406]
</p><p>80 ∀∀cji <∈ i s,,c(jli∈= s A ⇒1) (l ⇒j6= ( Ali−1)1)= A1) ∨ ∀∀cji <∈ i s,,c(jli∈= s K ⇒1) (lj ⇒6= ( Kli−1)1)= K1) ∨  (5) (6)  This pair states that two primary moves cannot occur in the same segment unless they are contiguous, in rapid succession. [sent-209, score-0.314]
</p><p>81 Computationally, an advantage of these constraints is that they do not extend past the current segment in history. [sent-211, score-0.227]
</p><p>82 s Neao-  segmentation model is used and no ILP constraints are enforced. [sent-217, score-0.195]
</p><p>83 2, wsi othu no segmentation model and no ILP constraints enforced. [sent-221, score-0.195]
</p><p>84 This represents  how much variance in authoritativeness is accounted for in the predicted ratios. [sent-229, score-0.323]
</p><p>85 This final metric is the most important for measuring reproducibility of human analyses of speaker authority in conversation. [sent-230, score-0.502]
</p><p>86 1 Results All classification results are given in Table 2 and charts showing correlation between predicted and actual speaker Authoritativeness ratios are shown in Figure 1. [sent-244, score-0.298]
</p><p>87 465); however, its accuracy is still very low and its ability to predict Authoritativeness ratio of a speaker is not particularly high (r2 of 0. [sent-246, score-0.305]
</p><p>88 However, the gains found in the contextual model are somewhat orthogonal to the gains from using ILP constraints, as applying those constraints to the contextual model results in further performance gains (and a high r2 coefficient of 0. [sent-251, score-0.393]
</p><p>89 Our Authoritativeness ratio does not take into account moves labelled o or ch. [sent-259, score-0.256]
</p><p>90 What we find is that the most advanced model still makes many mistakes at determining whether a move should be labelled as o or a core move. [sent-260, score-0.258]
</p><p>91 This error rate is, however, fairly consistent across the four core move codes. [sent-261, score-0.212]
</p><p>92 When a move is determined (correctly) to not be an o move, the system is highly accurate in distinguishing between the four core labels. [sent-262, score-0.212]
</p><p>93 The one systematic confusion that continues to appear most frequently in our results is the inabil-  ity to distinguish between a segment containing an A2 move followed by an A1 move, and a segment containing a K1 move followed by an o move. [sent-263, score-0.582]
</p><p>94 6  Conclusions  In this work we have presented one formulation of authority in dialogue. [sent-268, score-0.336]
</p><p>95 This formulation allows us to describe positioning in discourse in a way that  1025 is complementary to prior work in mixed-initiative dialogue systems and analysis of speaker certainty. [sent-269, score-0.896]
</p><p>96 Our model includes a simple understanding of discourse structure while also encoding information about the types of moves used, and the certainty of a speaker as a source of information. [sent-270, score-0.71]
</p><p>97 This formulation is reproducible by human coders, with an inter-rater reliability of 0. [sent-271, score-0.211]
</p><p>98 More importantly, this model replicates human analyses of authoritativeness very well, with an r2 coefficient of 0. [sent-276, score-0.368]
</p><p>99 Our segmentation accuracy is also fairly low, and further examination of segmentation accuracy using a more sophisticated evaluation metric, such as WindowDiff (Pevzner and Hearst, 2002), would be helpful. [sent-280, score-0.174]
</p><p>100 We are now interested in how we can apply this to the larger questions of positioning we began this paper by asking, especially in describing speaker positioning at various instants throughout a single discourse. [sent-282, score-0.632]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('authoritativeness', 0.323), ('authority', 0.258), ('negotiation', 0.246), ('speaker', 0.244), ('dialogue', 0.212), ('positioning', 0.194), ('jli', 0.172), ('move', 0.172), ('discourse', 0.168), ('initiative', 0.161), ('codes', 0.153), ('moves', 0.149), ('ilp', 0.13), ('coding', 0.122), ('speakers', 0.121), ('segment', 0.119), ('cji', 0.114), ('certainty', 0.114), ('constraints', 0.108), ('contribution', 0.092), ('segmentation', 0.087), ('contentful', 0.086), ('maptask', 0.086), ('reproducible', 0.086), ('sfl', 0.086), ('formulation', 0.078), ('ros', 0.076), ('kappa', 0.073), ('collaborative', 0.071), ('exchanges', 0.07), ('litman', 0.069), ('conversation', 0.066), ('mayfield', 0.066), ('elijah', 0.065), ('wrede', 0.065), ('contextual', 0.063), ('authoritative', 0.062), ('ratio', 0.061), ('enforce', 0.061), ('instruction', 0.06), ('control', 0.058), ('whittaker', 0.057), ('liscombe', 0.057), ('penstein', 0.057), ('asking', 0.055), ('ratios', 0.054), ('secondary', 0.054), ('initiate', 0.052), ('formalize', 0.052), ('tagsets', 0.052), ('integer', 0.052), ('exchange', 0.049), ('question', 0.049), ('coders', 0.049), ('carolyn', 0.049), ('conversations', 0.048), ('martin', 0.047), ('reliability', 0.047), ('primary', 0.046), ('labelled', 0.046), ('notion', 0.045), ('coefficient', 0.045), ('student', 0.044), ('action', 0.044), ('label', 0.044), ('act', 0.043), ('ahlmost', 0.043), ('auth', 0.043), ('bandura', 0.043), ('britta', 0.043), ('fgk', 0.043), ('howley', 0.043), ('initiations', 0.043), ('jci', 0.043), ('peltason', 0.043), ('pevzner', 0.043), ('stenton', 0.043), ('enforced', 0.043), ('tutoring', 0.043), ('coded', 0.042), ('diane', 0.042), ('ch', 0.04), ('elizabeth', 0.04), ('core', 0.04), ('cohen', 0.039), ('acts', 0.039), ('gains', 0.038), ('aggressive', 0.038), ('correlations', 0.038), ('anderson', 0.038), ('giver', 0.038), ('selfridge', 0.038), ('scheme', 0.037), ('students', 0.035), ('structure', 0.035), ('systemic', 0.035), ('lj', 0.035), ('segments', 0.034), ('instructions', 0.033), ('teacher', 0.033)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999893 <a title="260-tfidf-1" href="./acl-2011-Recognizing_Authority_in_Dialogue_with_an_Integer_Linear_Programming_Constrained_Model.html">260 acl-2011-Recognizing Authority in Dialogue with an Integer Linear Programming Constrained Model</a></p>
<p>Author: Elijah Mayfield ; Carolyn Penstein Rose</p><p>Abstract: We present a novel computational formulation of speaker authority in discourse. This notion, which focuses on how speakers position themselves relative to each other in discourse, is first developed into a reliable coding scheme (0.71 agreement between human annotators). We also provide a computational model for automatically annotating text using this coding scheme, using supervised learning enhanced by constraints implemented with Integer Linear Programming. We show that this constrained model’s analyses of speaker authority correlates very strongly with expert human judgments (r2 coefficient of 0.947).</p><p>2 0.20918524 <a title="260-tfidf-2" href="./acl-2011-Joint_Identification_and_Segmentation_of_Domain-Specific_Dialogue_Acts_for_Conversational_Dialogue_Systems.html">185 acl-2011-Joint Identification and Segmentation of Domain-Specific Dialogue Acts for Conversational Dialogue Systems</a></p>
<p>Author: Fabrizio Morbini ; Kenji Sagae</p><p>Abstract: Individual utterances often serve multiple communicative purposes in dialogue. We present a data-driven approach for identification of multiple dialogue acts in single utterances in the context of dialogue systems with limited training data. Our approach results in significantly increased understanding of user intent, compared to two strong baselines.</p><p>3 0.19965234 <a title="260-tfidf-3" href="./acl-2011-An_Affect-Enriched_Dialogue_Act_Classification_Model_for_Task-Oriented_Dialogue.html">33 acl-2011-An Affect-Enriched Dialogue Act Classification Model for Task-Oriented Dialogue</a></p>
<p>Author: Kristy Boyer ; Joseph Grafsgaard ; Eun Young Ha ; Robert Phillips ; James Lester</p><p>Abstract: Dialogue act classification is a central challenge for dialogue systems. Although the importance of emotion in human dialogue is widely recognized, most dialogue act classification models make limited or no use of affective channels in dialogue act classification. This paper presents a novel affect-enriched dialogue act classifier for task-oriented dialogue that models facial expressions of users, in particular, facial expressions related to confusion. The findings indicate that the affectenriched classifiers perform significantly better for distinguishing user requests for feedback and grounding dialogue acts within textual dialogue. The results point to ways in which dialogue systems can effectively leverage affective channels to improve dialogue act classification. 1</p><p>4 0.17895639 <a title="260-tfidf-4" href="./acl-2011-Data-oriented_Monologue-to-Dialogue_Generation.html">91 acl-2011-Data-oriented Monologue-to-Dialogue Generation</a></p>
<p>Author: Paul Piwek ; Svetlana Stoyanchev</p><p>Abstract: This short paper introduces an implemented and evaluated monolingual Text-to-Text generation system. The system takes monologue and transforms it to two-participant dialogue. After briefly motivating the task of monologue-to-dialogue generation, we describe the system and present an evaluation in terms of fluency and accuracy.</p><p>5 0.14589064 <a title="260-tfidf-5" href="./acl-2011-Lexically-Triggered_Hidden_Markov_Models_for_Clinical_Document_Coding.html">209 acl-2011-Lexically-Triggered Hidden Markov Models for Clinical Document Coding</a></p>
<p>Author: Svetlana Kiritchenko ; Colin Cherry</p><p>Abstract: The automatic coding of clinical documents is an important task for today’s healthcare providers. Though it can be viewed as multi-label document classification, the coding problem has the interesting property that most code assignments can be supported by a single phrase found in the input document. We propose a Lexically-Triggered Hidden Markov Model (LT-HMM) that leverages these phrases to improve coding accuracy. The LT-HMM works in two stages: first, a lexical match is performed against a term dictionary to collect a set of candidate codes for a document. Next, a discriminative HMM selects the best subset of codes to assign to the document by tagging candidates as present or absent. By confirming codes proposed by a dictionary, the LT-HMM can share features across codes, enabling strong performance even on rare codes. In fact, we are able to recover codes that do not occur in the training set at all. Our approach achieves the best ever performance on the 2007 Medical NLP Challenge test set, with an F-measure of 89.84.</p><p>6 0.14390448 <a title="260-tfidf-6" href="./acl-2011-A_Pilot_Study_of_Opinion_Summarization_in_Conversations.html">21 acl-2011-A Pilot Study of Opinion Summarization in Conversations</a></p>
<p>7 0.13593712 <a title="260-tfidf-7" href="./acl-2011-Automatically_Evaluating_Text_Coherence_Using_Discourse_Relations.html">53 acl-2011-Automatically Evaluating Text Coherence Using Discourse Relations</a></p>
<p>8 0.12813532 <a title="260-tfidf-8" href="./acl-2011-Turn-Taking_Cues_in_a_Human_Tutoring_Corpus.html">312 acl-2011-Turn-Taking Cues in a Human Tutoring Corpus</a></p>
<p>9 0.12566228 <a title="260-tfidf-9" href="./acl-2011-Entrainment_in_Speech_Preceding_Backchannels..html">118 acl-2011-Entrainment in Speech Preceding Backchannels.</a></p>
<p>10 0.12047806 <a title="260-tfidf-10" href="./acl-2011-Semantic_Information_and_Derivation_Rules_for_Robust_Dialogue_Act_Detection_in_a_Spoken_Dialogue_System.html">272 acl-2011-Semantic Information and Derivation Rules for Robust Dialogue Act Detection in a Spoken Dialogue System</a></p>
<p>11 0.11600158 <a title="260-tfidf-11" href="./acl-2011-Multimodal_Menu-based_Dialogue_with_Speech_Cursor_in_DICO_II%2B.html">227 acl-2011-Multimodal Menu-based Dialogue with Speech Cursor in DICO II+</a></p>
<p>12 0.10132807 <a title="260-tfidf-12" href="./acl-2011-Detection_of_Agreement_and_Disagreement_in_Broadcast_Conversations.html">95 acl-2011-Detection of Agreement and Disagreement in Broadcast Conversations</a></p>
<p>13 0.081470765 <a title="260-tfidf-13" href="./acl-2011-Question_Detection_in_Spoken_Conversations_Using_Textual_Conversations.html">257 acl-2011-Question Detection in Spoken Conversations Using Textual Conversations</a></p>
<p>14 0.075626403 <a title="260-tfidf-14" href="./acl-2011-Computing_and_Evaluating_Syntactic_Complexity_Features_for_Automated_Scoring_of_Spontaneous_Non-Native_Speech.html">77 acl-2011-Computing and Evaluating Syntactic Complexity Features for Automated Scoring of Spontaneous Non-Native Speech</a></p>
<p>15 0.070096649 <a title="260-tfidf-15" href="./acl-2011-Disentangling_Chat_with_Local_Coherence_Models.html">101 acl-2011-Disentangling Chat with Local Coherence Models</a></p>
<p>16 0.067738801 <a title="260-tfidf-16" href="./acl-2011-In-domain_Relation_Discovery_with_Meta-constraints_via_Posterior_Regularization.html">170 acl-2011-In-domain Relation Discovery with Meta-constraints via Posterior Regularization</a></p>
<p>17 0.067676142 <a title="260-tfidf-17" href="./acl-2011-Global_Learning_of_Typed_Entailment_Rules.html">144 acl-2011-Global Learning of Typed Entailment Rules</a></p>
<p>18 0.067370839 <a title="260-tfidf-18" href="./acl-2011-A_Bayesian_Model_for_Unsupervised_Semantic_Parsing.html">3 acl-2011-A Bayesian Model for Unsupervised Semantic Parsing</a></p>
<p>19 0.067312427 <a title="260-tfidf-19" href="./acl-2011-Hierarchical_Reinforcement_Learning_and_Hidden_Markov_Models_for_Task-Oriented_Natural_Language_Generation.html">149 acl-2011-Hierarchical Reinforcement Learning and Hidden Markov Models for Task-Oriented Natural Language Generation</a></p>
<p>20 0.066774733 <a title="260-tfidf-20" href="./acl-2011-Multi-Modal_Annotation_of_Quest_Games_in_Second_Life.html">226 acl-2011-Multi-Modal Annotation of Quest Games in Second Life</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.171), (1, 0.053), (2, -0.062), (3, 0.034), (4, -0.254), (5, 0.24), (6, -0.043), (7, 0.005), (8, -0.024), (9, 0.027), (10, 0.056), (11, 0.008), (12, 0.027), (13, 0.005), (14, 0.011), (15, -0.009), (16, -0.037), (17, -0.022), (18, -0.021), (19, 0.039), (20, 0.031), (21, 0.029), (22, -0.028), (23, 0.019), (24, -0.022), (25, 0.03), (26, -0.041), (27, 0.025), (28, -0.004), (29, 0.087), (30, 0.033), (31, 0.029), (32, 0.017), (33, 0.054), (34, -0.055), (35, 0.0), (36, -0.005), (37, 0.031), (38, -0.004), (39, -0.034), (40, 0.024), (41, 0.054), (42, 0.026), (43, -0.068), (44, -0.002), (45, -0.007), (46, 0.032), (47, -0.051), (48, -0.071), (49, 0.05)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93604672 <a title="260-lsi-1" href="./acl-2011-Recognizing_Authority_in_Dialogue_with_an_Integer_Linear_Programming_Constrained_Model.html">260 acl-2011-Recognizing Authority in Dialogue with an Integer Linear Programming Constrained Model</a></p>
<p>Author: Elijah Mayfield ; Carolyn Penstein Rose</p><p>Abstract: We present a novel computational formulation of speaker authority in discourse. This notion, which focuses on how speakers position themselves relative to each other in discourse, is first developed into a reliable coding scheme (0.71 agreement between human annotators). We also provide a computational model for automatically annotating text using this coding scheme, using supervised learning enhanced by constraints implemented with Integer Linear Programming. We show that this constrained model’s analyses of speaker authority correlates very strongly with expert human judgments (r2 coefficient of 0.947).</p><p>2 0.82345015 <a title="260-lsi-2" href="./acl-2011-An_Affect-Enriched_Dialogue_Act_Classification_Model_for_Task-Oriented_Dialogue.html">33 acl-2011-An Affect-Enriched Dialogue Act Classification Model for Task-Oriented Dialogue</a></p>
<p>Author: Kristy Boyer ; Joseph Grafsgaard ; Eun Young Ha ; Robert Phillips ; James Lester</p><p>Abstract: Dialogue act classification is a central challenge for dialogue systems. Although the importance of emotion in human dialogue is widely recognized, most dialogue act classification models make limited or no use of affective channels in dialogue act classification. This paper presents a novel affect-enriched dialogue act classifier for task-oriented dialogue that models facial expressions of users, in particular, facial expressions related to confusion. The findings indicate that the affectenriched classifiers perform significantly better for distinguishing user requests for feedback and grounding dialogue acts within textual dialogue. The results point to ways in which dialogue systems can effectively leverage affective channels to improve dialogue act classification. 1</p><p>3 0.81123745 <a title="260-lsi-3" href="./acl-2011-Data-oriented_Monologue-to-Dialogue_Generation.html">91 acl-2011-Data-oriented Monologue-to-Dialogue Generation</a></p>
<p>Author: Paul Piwek ; Svetlana Stoyanchev</p><p>Abstract: This short paper introduces an implemented and evaluated monolingual Text-to-Text generation system. The system takes monologue and transforms it to two-participant dialogue. After briefly motivating the task of monologue-to-dialogue generation, we describe the system and present an evaluation in terms of fluency and accuracy.</p><p>4 0.79740721 <a title="260-lsi-4" href="./acl-2011-Joint_Identification_and_Segmentation_of_Domain-Specific_Dialogue_Acts_for_Conversational_Dialogue_Systems.html">185 acl-2011-Joint Identification and Segmentation of Domain-Specific Dialogue Acts for Conversational Dialogue Systems</a></p>
<p>Author: Fabrizio Morbini ; Kenji Sagae</p><p>Abstract: Individual utterances often serve multiple communicative purposes in dialogue. We present a data-driven approach for identification of multiple dialogue acts in single utterances in the context of dialogue systems with limited training data. Our approach results in significantly increased understanding of user intent, compared to two strong baselines.</p><p>5 0.73982191 <a title="260-lsi-5" href="./acl-2011-Entrainment_in_Speech_Preceding_Backchannels..html">118 acl-2011-Entrainment in Speech Preceding Backchannels.</a></p>
<p>Author: Rivka Levitan ; Agustin Gravano ; Julia Hirschberg</p><p>Abstract: In conversation, when speech is followed by a backchannel, evidence of continued engagement by one’s dialogue partner, that speech displays a combination of cues that appear to signal to one’s interlocutor that a backchannel is appropriate. We term these cues backchannel-preceding cues (BPC)s, and examine the Columbia Games Corpus for evidence of entrainment on such cues. Entrainment, the phenomenon of dialogue partners becoming more similar to each other, is widely believed to be crucial to conversation quality and success. Our results show that speaking partners entrain on BPCs; that is, they tend to use similar sets of BPCs; this similarity increases over the course of a dialogue; and this similarity is associated with measures of dialogue coordination and task success. 1</p><p>6 0.7280044 <a title="260-lsi-6" href="./acl-2011-Multimodal_Menu-based_Dialogue_with_Speech_Cursor_in_DICO_II%2B.html">227 acl-2011-Multimodal Menu-based Dialogue with Speech Cursor in DICO II+</a></p>
<p>7 0.72456014 <a title="260-lsi-7" href="./acl-2011-Turn-Taking_Cues_in_a_Human_Tutoring_Corpus.html">312 acl-2011-Turn-Taking Cues in a Human Tutoring Corpus</a></p>
<p>8 0.69192553 <a title="260-lsi-8" href="./acl-2011-Semantic_Information_and_Derivation_Rules_for_Robust_Dialogue_Act_Detection_in_a_Spoken_Dialogue_System.html">272 acl-2011-Semantic Information and Derivation Rules for Robust Dialogue Act Detection in a Spoken Dialogue System</a></p>
<p>9 0.56327403 <a title="260-lsi-9" href="./acl-2011-Multi-Modal_Annotation_of_Quest_Games_in_Second_Life.html">226 acl-2011-Multi-Modal Annotation of Quest Games in Second Life</a></p>
<p>10 0.55336553 <a title="260-lsi-10" href="./acl-2011-Prototyping_virtual_instructors_from_human-human_corpora.html">252 acl-2011-Prototyping virtual instructors from human-human corpora</a></p>
<p>11 0.51102227 <a title="260-lsi-11" href="./acl-2011-Question_Detection_in_Spoken_Conversations_Using_Textual_Conversations.html">257 acl-2011-Question Detection in Spoken Conversations Using Textual Conversations</a></p>
<p>12 0.49526352 <a title="260-lsi-12" href="./acl-2011-Detection_of_Agreement_and_Disagreement_in_Broadcast_Conversations.html">95 acl-2011-Detection of Agreement and Disagreement in Broadcast Conversations</a></p>
<p>13 0.49148735 <a title="260-lsi-13" href="./acl-2011-A_Pilot_Study_of_Opinion_Summarization_in_Conversations.html">21 acl-2011-A Pilot Study of Opinion Summarization in Conversations</a></p>
<p>14 0.48626646 <a title="260-lsi-14" href="./acl-2011-MACAON_An_NLP_Tool_Suite_for_Processing_Word_Lattices.html">215 acl-2011-MACAON An NLP Tool Suite for Processing Word Lattices</a></p>
<p>15 0.48389453 <a title="260-lsi-15" href="./acl-2011-Combining_Indicators_of_Allophony.html">74 acl-2011-Combining Indicators of Allophony</a></p>
<p>16 0.46716863 <a title="260-lsi-16" href="./acl-2011-IMASS%3A_An_Intelligent_Microblog_Analysis_and_Summarization_System.html">156 acl-2011-IMASS: An Intelligent Microblog Analysis and Summarization System</a></p>
<p>17 0.45131963 <a title="260-lsi-17" href="./acl-2011-Automatically_Evaluating_Text_Coherence_Using_Discourse_Relations.html">53 acl-2011-Automatically Evaluating Text Coherence Using Discourse Relations</a></p>
<p>18 0.43969181 <a title="260-lsi-18" href="./acl-2011-Modeling_Wisdom_of_Crowds_Using_Latent_Mixture_of_Discriminative_Experts.html">223 acl-2011-Modeling Wisdom of Crowds Using Latent Mixture of Discriminative Experts</a></p>
<p>19 0.41070315 <a title="260-lsi-19" href="./acl-2011-Disentangling_Chat_with_Local_Coherence_Models.html">101 acl-2011-Disentangling Chat with Local Coherence Models</a></p>
<p>20 0.4071213 <a title="260-lsi-20" href="./acl-2011-The_impact_of_language_models_and_loss_functions_on_repair_disfluency_detection.html">301 acl-2011-The impact of language models and loss functions on repair disfluency detection</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.43), (17, 0.051), (26, 0.019), (31, 0.01), (37, 0.048), (39, 0.046), (41, 0.05), (55, 0.025), (59, 0.03), (72, 0.038), (91, 0.036), (96, 0.12), (98, 0.03)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.93599868 <a title="260-lda-1" href="./acl-2011-Subjective_Natural_Language_Problems%3A_Motivations%2C_Applications%2C_Characterizations%2C_and_Implications.html">288 acl-2011-Subjective Natural Language Problems: Motivations, Applications, Characterizations, and Implications</a></p>
<p>Author: Cecilia Ovesdotter Alm</p><p>Abstract: This opinion paper discusses subjective natural language problems in terms of their motivations, applications, characterizations, and implications. It argues that such problems deserve increased attention because of their potential to challenge the status of theoretical understanding, problem-solving methods, and evaluation techniques in computational linguistics. The author supports a more holistic approach to such problems; a view that extends beyond opinion mining or sentiment analysis.</p><p>2 0.89649332 <a title="260-lda-2" href="./acl-2011-The_ACL_Anthology_Searchbench.html">298 acl-2011-The ACL Anthology Searchbench</a></p>
<p>Author: Ulrich Schafer ; Bernd Kiefer ; Christian Spurk ; Jorg Steffen ; Rui Wang</p><p>Abstract: We describe a novel application for structured search in scientific digital libraries. The ACL Anthology Searchbench is meant to become a publicly available research tool to query the content of the ACL Anthology. The application provides search in both its bibliographic metadata and semantically analyzed full textual content. By combining these two features, very efficient and focused queries are possible. At the same time, the application serves as a showcase for the recent progress in natural language processing (NLP) research and language technology. The system currently indexes the textual content of 7,500 anthology papers from 2002–2009 with predicateargument-like semantic structures. It also provides useful search filters based on bibliographic metadata. It will be extended to provide the full anthology content and en- . hanced functionality based on further NLP techniques. 1 Introduction and Motivation Scientists in all disciplines nowadays are faced with a flood of new publications every day. In addition, more and more publications from the past become digitally available and thus even increase the amount. Finding relevant information and avoiding duplication of work have become urgent issues to be addressed by the scientific community. The organization and preservation of scientific knowledge in scientific publications, vulgo text documents, thwarts these efforts. From a viewpoint of 7 dfki .de / lt a computer scientist, scientific papers are just ‘unstructured information’ . At least in our own scientific community, Computational Linguistics, it is generally assumed that NLP could help to support search in such document collections. The ACL Anthology1 is a comprehensive elec- tronic collection of scientific papers in our own field (Bird et al., 2008). It is updated regularly with new publications, but also older papers have been scanned and are made available electronically. We have implemented the ACL Anthology Searchbench2 for two reasons: Our first aim is to provide a more targeted search facility in this collection than standard web search on the anthology website. In this sense, the Searchbench is meant to become a service to our own community. Our second motivation is to use the developed system as a showcase for the progress that has been made over the last years in precision-oriented deep linguistic parsing in terms of both efficiency and coverage, specifically in the context of the DELPHIN community3. Our system also uses further NLP techniques such as unsupervised term extraction, named entity recognition and part-of-speech (PoS) tagging. By automatically precomputing normalized semantic representations (predicate-argument structure) of each sentence in the anthology, the search space is structured and allows to find equivalent or related predicates even if they are expressed differ- 1http : / /www . aclweb .org/ anthology 2http : //aclasb . dfki . de 3http : / /www . de lph-in . net – DELPH-IN stands for DEep Linguistic Processing with HPSG INitiative. Portland,P Orroecge ondi,n UgSsA o,f 2 th1e J AunCeL 2-H0L1 T. 2 ?0c 1210 1S1ys Atesmso Dcieamtio n s ftorart Cio nms,p puatgaetiso 7n–al1 L3i,nguistics ently, e.g. in passive constructions, using synonyms, etc. By storing the semantic sentence structure along with the original text in a structured full-text search engine, it can be guaranteed that recall cannot fall behind the baseline of a fulltext search. In addition, the Searchbench also provides detailed bibliographic metadata for filtering as well as autosuggest texts for input fields computed from the corpus two further key features one can expect from such systems today, nevertheless very important for efficient search in digital libraries. We describe the offline preprocessing and deep parsing approach in Section 2. Section 3 concentrates on the generation of the semantic search index. In Section 4, we describe the search interface. We conclude in Section 5 and present an outlook to future extensions. – 2 Parsing the ACL Anthology The basis of the search index for the ACL Anthology are its original PDF documents, currently 8,200 from the years 2002 through 2009. To overcome quality problems in text extraction from PDF, we use a commercial PDF extractor based on OCR techniques. This approach guarantees uniform and highquality textual representations even from older papers in the anthology (before 2000) which mostly were scanned from printed paper versions. The general idea of the semantics-oriented access to scholarly paper content is to parse each sentence they contain with the open-source HPSG (Pollard and Sag, 1994) grammar for English (ERG; Flickinger (2002)) and then distill and index semantically structured representations for search. To make the deep parser robust, it is embedded in a NLP workflow. The coverage (percentage of full deeply parsed sentences) on the anthology corpus could be increased from 65 % to now more than 85 % through careful combination of several robustness techniques; for example: (1) chart pruning, directed search during parsing to increase per- formance, and also coverage for longer sentences (Cramer and Zhang, 2010); (2) chart mapping, a novel method for integrating preprocessing information in exactly the way the deep grammar expects it (Adolphs et al., 2008); (3) new version of the ERG with better handling of open word classes; (4) 8 more fine-grained named entity recognition, including recognition of citation patterns; (5) new, better suited parse ranking model (WeScience; Flickinger et al. (2010)). Because of limited space, we will focus on (1) and (2) below. A more detailed description and further results are available in (Sch a¨fer and Kiefer, 2011). Except for a small part of the named entity recognition components (citations, some terminology) and the parse ranking model, there are no further adaptations to genre or domain of the text corpus. This implies that the NLP workflow could be easily and modularly adapted to other (scientific or nonscientific) domains—mainly thanks to the generic and comprehensive language modelling in the ERG. The NLP preprocessing component workflow is implemented using the Heart of Gold NLP middleware architecture (Sch a¨fer, 2006). It starts with sentence boundary detection (SBR) and regular expression-based tokenization using its built-in component JTok, followed by the trigram-based PoS tagger TnT (Brants, 2000) trained on the Penn Treebank (Marcus et al., 1993) and the named entity recognizer SProUT (Dro z˙d z˙y n´ski et al., 2004). 2.1 Precise Preprocessing Integration with Chart Mapping Tagger output is combined with information from the named entity recognizer, e.g. delivering hypothetical information on citation expressions. The combined result is delivered as input to the deep parser PET (Callmeier, 2000) running the ERG. Here, citations, for example, can be treated as either persons, locations or appositions. Concerning punctuation, the ERG can make use of information on opening and closing quotation marks. Such information is often not explicit in the input text, e.g. when, as in our setup, gained through OCR which does not distinguish between ‘ and ’ or “ and However, a tokenizer can often guess (recon- ”. struct) leftness and rightness correctly. This information, passed to the deep parser via chart mapping, helps it to disambiguate. 2.2 Increased Processing Speed and Coverage through Chart Pruning In addition to a well-established discriminative maximum entropy model for post-analysis parse selection, we use an additional generative model as described in Cramer and Zhang (2010) to restrict the search space during parsing. This restriction increases efficiency, but also coverage, because the parse time was restricted to at most 60 CPU seconds on a standard PC, and more sentences could now be parsed within these bounds. A 4 GB limit for main memory consumption was far beyond what was ever needed. We saw a small but negligible decrease in parsing accuracy, 5.4 % best parses were not found due to the pruning of important chart edges. Ninomiya et al. (2006) did a very thorough comparison ofdifferent performance optimization strategies, and among those also a local pruning strategy similar to the one used here. There is an important difference between the systems, in that theirs works on a reduced context-free backbone first and reconstructs the results with the full grammar, while PET uses the HPSG grammar directly, with subsumption packing and partial unpacking to achieve a similar effect as the packed chart of a context-free parser. sentence length −→ Figure 1: Distribution of sentence length and mean parse times for mild pruning In total, we parsed 1,537,801 sentences, of which 57,832 (3.8 %) could not be parsed because of lexicon errors. Most of them were caused by OCR ar- tifacts resulting in unexpected punctuation character combinations. These can be identified and will be deleted in the future. Figure 1 displays the average parse time of processing with a mild chart pruning setting, together with the mean quadratic error. In addition, it contains the distribution of input sentences over sentence length. Obviously, the vast majority of sen9 tences has a length of at most 60 words4. The parse times only grow mildly due to the many optimization techniques in the original system, and also the new chart pruning method. The sentence length distribution has been integrated into Figure 1 to show that the predominant part of our real-world corpus can be processed using this information-rich method with very low parse times (overall average parse time < 2 s per sentence). The large amount of short inputs is at first surprising, even more so that most of these inputs can not be parsed. Most of these inputs are non-sentences such as headings, enumerations, footnotes, table cell content. There are several alternatives to deal with such input, one to identify and handle them in a preprocessing step, another to use a special root condition in the deep analysis component that is able to combine phrases with well-defined properties for inputs where no spanning result could be found. We employed the second method, which has the advantage that it handles a larger range of phenomena in a homogeneous way. Figure 2 shows the change in percentage of unparsed and timed out inputs for the mild pruning method with and without the root condition combining fragments. sentence length −→ Figure 2: Unparsed and timed out sentences with and without fragment combination Figure 2 shows that this changes the curve for unparsed sentences towards more expected characteristics and removes the uncommonly high percentage of short sentences for which no parse can be computed. Together with the parses for fragmented 4It has to be pointed out that extremely long sentences also may be non-sentences resulting from PDF extraction errors, missing punctuation etc. No manual correction took place. Figure 3: Multiple semantic tuples may be generated for a sentence input, we get a recall (sentences with at least one parse) over the whole corpus of 85.9 % (1,321,336 sentences), without a significant change for any of the other measures, and with potential for further improvement. 3 Semantic Tuple Extraction with DMRS In contrast to shallow parsers, the ERG not only handles detailed syntactic analyses of phrases, com- pounds, coordination, negation and other linguistic phenomena that are important for extracting semantic relations, but also generates a formal semantic representation of the meaning of the input sentence in the Minimal Recursion Semantics (MRS) representation format (Copestake et al., 2005). It consists of elementary predications for each word and larger constituents, connected via argument positions and variables, from which predicate-argument structure can be extracted. MRS representations resulting from deep parsing are still relatively close to linguistic structures and contain more detailed information than a user would like to query and search for. Therefore, an additional extraction and abstraction step is performed before storing semantic structures in the search index. Firstly, MRS is converted to DMRS (Copestake, 2009), a dependency-style version of MRS that eases extraction of predicate-argument structure using the implementation in LKB (Copestake, 2002). The representation format we devised for the search index we call semantic tuples, in fact quintuples</p><p>same-paper 3 0.85420716 <a title="260-lda-3" href="./acl-2011-Recognizing_Authority_in_Dialogue_with_an_Integer_Linear_Programming_Constrained_Model.html">260 acl-2011-Recognizing Authority in Dialogue with an Integer Linear Programming Constrained Model</a></p>
<p>Author: Elijah Mayfield ; Carolyn Penstein Rose</p><p>Abstract: We present a novel computational formulation of speaker authority in discourse. This notion, which focuses on how speakers position themselves relative to each other in discourse, is first developed into a reliable coding scheme (0.71 agreement between human annotators). We also provide a computational model for automatically annotating text using this coding scheme, using supervised learning enhanced by constraints implemented with Integer Linear Programming. We show that this constrained model’s analyses of speaker authority correlates very strongly with expert human judgments (r2 coefficient of 0.947).</p><p>4 0.84175193 <a title="260-lda-4" href="./acl-2011-Language_of_Vandalism%3A_Improving_Wikipedia_Vandalism_Detection_via_Stylometric_Analysis.html">195 acl-2011-Language of Vandalism: Improving Wikipedia Vandalism Detection via Stylometric Analysis</a></p>
<p>Author: Manoj Harpalani ; Michael Hart ; Sandesh Signh ; Rob Johnson ; Yejin Choi</p><p>Abstract: Community-based knowledge forums, such as Wikipedia, are susceptible to vandalism, i.e., ill-intentioned contributions that are detrimental to the quality of collective intelligence. Most previous work to date relies on shallow lexico-syntactic patterns and metadata to automatically detect vandalism in Wikipedia. In this paper, we explore more linguistically motivated approaches to vandalism detection. In particular, we hypothesize that textual vandalism constitutes a unique genre where a group of people share a similar linguistic behavior. Experimental results suggest that (1) statistical models give evidence to unique language styles in vandalism, and that (2) deep syntactic patterns based on probabilistic context free grammars (PCFG) discriminate vandalism more effectively than shallow lexicosyntactic patterns based on n-grams. ,</p><p>5 0.73190188 <a title="260-lda-5" href="./acl-2011-Better_Hypothesis_Testing_for_Statistical_Machine_Translation%3A_Controlling_for_Optimizer_Instability.html">60 acl-2011-Better Hypothesis Testing for Statistical Machine Translation: Controlling for Optimizer Instability</a></p>
<p>Author: Jonathan H. Clark ; Chris Dyer ; Alon Lavie ; Noah A. Smith</p><p>Abstract: In statistical machine translation, a researcher seeks to determine whether some innovation (e.g., a new feature, model, or inference algorithm) improves translation quality in comparison to a baseline system. To answer this question, he runs an experiment to evaluate the behavior of the two systems on held-out data. In this paper, we consider how to make such experiments more statistically reliable. We provide a systematic analysis of the effects of optimizer instability—an extraneous variable that is seldom controlled for—on experimental outcomes, and make recommendations for reporting results more accurately.</p><p>6 0.49434197 <a title="260-lda-6" href="./acl-2011-An_Affect-Enriched_Dialogue_Act_Classification_Model_for_Task-Oriented_Dialogue.html">33 acl-2011-An Affect-Enriched Dialogue Act Classification Model for Task-Oriented Dialogue</a></p>
<p>7 0.4771744 <a title="260-lda-7" href="./acl-2011-Towards_Tracking_Semantic_Change_by_Visual_Analytics.html">307 acl-2011-Towards Tracking Semantic Change by Visual Analytics</a></p>
<p>8 0.47346365 <a title="260-lda-8" href="./acl-2011-The_Surprising_Variance_in_Shortest-Derivation_Parsing.html">300 acl-2011-The Surprising Variance in Shortest-Derivation Parsing</a></p>
<p>9 0.47315586 <a title="260-lda-9" href="./acl-2011-A_Corpus_of_Scope-disambiguated_English_Text.html">8 acl-2011-A Corpus of Scope-disambiguated English Text</a></p>
<p>10 0.47305581 <a title="260-lda-10" href="./acl-2011-Lexically-Triggered_Hidden_Markov_Models_for_Clinical_Document_Coding.html">209 acl-2011-Lexically-Triggered Hidden Markov Models for Clinical Document Coding</a></p>
<p>11 0.47118539 <a title="260-lda-11" href="./acl-2011-Good_Seed_Makes_a_Good_Crop%3A_Accelerating_Active_Learning_Using_Language_Modeling.html">145 acl-2011-Good Seed Makes a Good Crop: Accelerating Active Learning Using Language Modeling</a></p>
<p>12 0.46929783 <a title="260-lda-12" href="./acl-2011-Extracting_Social_Power_Relationships_from_Natural_Language.html">133 acl-2011-Extracting Social Power Relationships from Natural Language</a></p>
<p>13 0.46728563 <a title="260-lda-13" href="./acl-2011-Integrating_surprisal_and_uncertain-input_models_in_online_sentence_comprehension%3A_formal_techniques_and_empirical_results.html">176 acl-2011-Integrating surprisal and uncertain-input models in online sentence comprehension: formal techniques and empirical results</a></p>
<p>14 0.46463001 <a title="260-lda-14" href="./acl-2011-Evaluating_the_Impact_of_Coder_Errors_on_Active_Learning.html">119 acl-2011-Evaluating the Impact of Coder Errors on Active Learning</a></p>
<p>15 0.46312502 <a title="260-lda-15" href="./acl-2011-MACAON_An_NLP_Tool_Suite_for_Processing_Word_Lattices.html">215 acl-2011-MACAON An NLP Tool Suite for Processing Word Lattices</a></p>
<p>16 0.46186545 <a title="260-lda-16" href="./acl-2011-Unary_Constraints_for_Efficient_Context-Free_Parsing.html">316 acl-2011-Unary Constraints for Efficient Context-Free Parsing</a></p>
<p>17 0.45954582 <a title="260-lda-17" href="./acl-2011-Multi-Modal_Annotation_of_Quest_Games_in_Second_Life.html">226 acl-2011-Multi-Modal Annotation of Quest Games in Second Life</a></p>
<p>18 0.45852733 <a title="260-lda-18" href="./acl-2011-Age_Prediction_in_Blogs%3A_A_Study_of_Style%2C_Content%2C_and_Online_Behavior_in_Pre-_and_Post-Social_Media_Generations.html">31 acl-2011-Age Prediction in Blogs: A Study of Style, Content, and Online Behavior in Pre- and Post-Social Media Generations</a></p>
<p>19 0.45603883 <a title="260-lda-19" href="./acl-2011-Beam-Width_Prediction_for_Efficient_Context-Free_Parsing.html">58 acl-2011-Beam-Width Prediction for Efficient Context-Free Parsing</a></p>
<p>20 0.45556632 <a title="260-lda-20" href="./acl-2011-An_Empirical_Investigation_of_Discounting_in_Cross-Domain_Language_Models.html">38 acl-2011-An Empirical Investigation of Discounting in Cross-Domain Language Models</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
