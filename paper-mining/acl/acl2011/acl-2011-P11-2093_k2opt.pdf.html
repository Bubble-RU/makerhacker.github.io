<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>238 acl-2011-P11-2093 k2opt.pdf</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-238" href="#">acl2011-238</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>238 acl-2011-P11-2093 k2opt.pdf</h1>
<br/><p>Source: <a title="acl-2011-238-pdf" href="http://aclweb.org/anthology//P/P11/P11-2093.pdf">pdf</a></p><p>Author: empty-author</p><p>Abstract: We present a pointwise approach to Japanese morphological analysis (MA) that ignores structure information during learning and tagging. Despite the lack of structure, it is able to outperform the current state-of-the-art structured approach for Japanese MA, and achieves accuracy similar to that of structured predictors using the same feature set. We also find that the method is both robust to outof-domain data, and can be easily adapted through the use of a combination of partial annotation and active learning.</p><p>Reference: <a title="acl-2011-238-reference" href="../acl2011_reference/acl-2011-P11-2093_k2opt.pdf_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Despite the lack of structure, it is able to outperform the current state-of-the-art structured approach for Japanese MA, and achieves accuracy similar to that of structured predictors using the same feature set. [sent-2, score-0.232]
</p><p>2 We also find that the method is both robust to outof-domain data, and can be easily adapted through the use of a combination of partial annotation and active learning. [sent-3, score-0.495]
</p><p>3 1 Introduction Japanese morphological analysis (MA) takes an unsegmented string of Japanese text as input, and outputs a string of morphemes annotated with parts of speech (POSs). [sent-4, score-0.474]
</p><p>4 As MA is the first step in Japanese NLP, its accuracy directly affects the accuracy of  NLP systems as a whole. [sent-5, score-0.098]
</p><p>5 In addition, with the proliferation oftext in various domains, there is increasing need for methods that are both robust and adaptable to out-of-domain data (Escudero et al. [sent-6, score-0.217]
</p><p>6 Previous approaches have used structured predictors such as hidden Markov models (HMMs) or conditional random fields (CRFs), which consider the interactions between neighboring words and parts of speech (Nagata, 1994; Asahara and Matsumoto, 2000; Kudo et al. [sent-8, score-0.342]
</p><p>7 (2008) have shown that gains provided by structured prediction can be largely recovered by using a richer feature set. [sent-11, score-0.187]
</p><p>8 (2008) focus on the speed benefits of pointwise prediction, we demonstrate that it also allows for more robust and adaptable MA. [sent-14, score-0.477]
</p><p>9 We find experimental evidence that pointwise MA can exceed the accuracy of a state-of-the-art structured approach (Kudo et al. [sent-15, score-0.418]
</p><p>10 , 2004) on in-domain data, and is significantly more robust to out-of-domain data. [sent-16, score-0.054]
</p><p>11 We also show that pointwise MA can be adapted  to new domains with minimal effort through the combination of active learning and partial annotation (Tsuboi et al. [sent-17, score-0.701]
</p><p>12 , 2008), where only informative parts of a particular sentence are annotated. [sent-18, score-0.044]
</p><p>13 In a realistic domain adaptation scenario, we find that a combination of pointwise prediction, partial annotation, and active learning allows for easy adaptation. [sent-19, score-0.85]
</p><p>14 2  Japanese Morphological Analysis  Japanese MA takes an unsegmented string of characters x1I as input, segments it into morphemes w1J, and annotates each morpheme with a part of speech t1J. [sent-20, score-0.243]
</p><p>15 This can be formulated as a two-step process of first segmenting words, then estimating POSs (Ng and Low, 2004), or as a single joint process of finding a morpheme/POS string from unsegmented text (Kudo et al. [sent-21, score-0.297]
</p><p>16 In this section we describe an existing joint sequence-based method for Japanese MA, as well as our proposed two-step pointwise method. [sent-24, score-0.338]
</p><p>17 1 Joint Sequence-Based MA Japanese MA has traditionally used sequence based models, finding a maximal POS sequence for en-  Figure 1: Joint MA (a) performs maximization over the entire sequence, while two-step MA (b) maximizes the 4 boundary and 4 POS tags independently. [sent-26, score-0.307]
</p><p>18 Type  Feature Strings  Unigramtj, tjwj, c(wj), tjc(wj) Bigramtj−1tj, tj−1tjwj−1, tj−1tjwj, tj−1tjwj−1wj j−1j−1j−1  Table 1: Features for the joint model using tags t and  words w. [sent-27, score-0.13]
</p><p>19 c(·) is a mapping function onto character types (wkoarndjis, wka. [sent-28, score-0.054]
</p><p>20 CRFs are trained over segmentation lattices, which allows for the handling of variable length sequences that occur due to multiple segmentations. [sent-34, score-0.093]
</p><p>21 The model is able to take into account arbitrary features, as well as the context between neighboring tags. [sent-35, score-0.054]
</p><p>22 It should be noted that these are wordbased features, and information about transitions between POS tags is included. [sent-39, score-0.108]
</p><p>23 When creating training data, the use of word-based features indicates that word boundaries must be annotated, while the use of POS transition information further indicates that all of these words must be annotated with POSs. [sent-40, score-0.261]
</p><p>24 1More fine-grained POS tags have provided small boosts in accuracy in previous research (Kudo et al. [sent-41, score-0.101]
</p><p>25 , 2004), but these in-  crease the annotation burden, which is contrary to our goal. [sent-42, score-0.093]
</p><p>26 Typec(xl), c(xr) n-gram  c(xl−1xl), c(xlxr), c(xrxr+1) c(xl−2xl−1xl), c(xl−1xlxr) c(xlxrxr+1), c(xrxr+1xr+2)  WS Onlyls, rs, is POS Onlywj, c(wj), djk Table 2: Features for the two-step model. [sent-44, score-0.106]
</p><p>27 xl and xr indicate the characters to the left and right of the word boundary or word wj in question. [sent-45, score-0.686]
</p><p>28 ls, rs, and is represent the left, right, and inside dictionary features, while djk indicates that tag k exists in the dictionary for word j. [sent-46, score-0.51]
</p><p>29 2  2-Step Pointwise MA  In our research, we take a two-step approach, first segmenting character sequence into the word sequence with the highest probability, then tagging each word with parts of speech This approach is shown in Figure 1 (b). [sent-48, score-0.325]
</p><p>30 We follow Sassano (2002) in formulating word segmentation as a binary classification problem, estimating boundary tags Tag bi = 1 indicates that a word boundary exists between characters xi and xi+1, while bi = 0 indicates that a word boundary does not exist. [sent-50, score-0.912]
</p><p>31 POS estimation can also be formulated as a multi-class classification problem, where we choose one tag tj for each word wj. [sent-51, score-0.205]
</p><p>32 These two classification problems can be solved by tools in the standard machine learning toolbox such as logistic regression (LR), support vector machines (SVMs), or conditional random fields (CRFs). [sent-52, score-0.121]
</p><p>33 We use information about the surrounding characters (character and character-type n-grams), as well as the presence or absence of words in the dictionary as features (Table 2). [sent-53, score-0.171]
</p><p>34 Specifically dictionary features for word segmentation ls and rs are active if a string of length s included in the dictionary is present directly to the left or right of the present word boundary, and is is active if the present word boundary is included in a dictionary word of length s. [sent-54, score-1.391]
</p><p>35 Dictionary feature djk for POS estimation indicates whether the current word wj occurs as a dictionary entry with tag tk. [sent-55, score-0.456]
</p><p>36 Previous work using this two-stage approach has used sequence-based prediction methods, such as maximum entropy Markov models (MEMMs) or CRFs (Ng and Low, 2004; Peng et al. [sent-57, score-0.091]
</p><p>37 (2008) note, and we confirm, sequence-based predictors are often not necessary when an appropriately rich feature set is used. [sent-60, score-0.063]
</p><p>38 (2008) and all other previous methods is that we rely only on features that are directly calculable from the surface string, without using estimated information such as word boundaries or neighboring POS tags2. [sent-62, score-0.157]
</p><p>39 This allows for training from sentences that are partially annotated as described in the following section. [sent-63, score-0.098]
</p><p>40 3  Domain Adaptation for Morphological Analysis  NLP is now being used in domains such as medical text and legal documents, and it is necessary that MA be easily adaptable to these areas. [sent-64, score-0.163]
</p><p>41 In a domain adaptation situation, we have at our disposal both annotated general domain data, and unannotated tar-  get domain data. [sent-65, score-0.593]
</p><p>42 We would like to annotate the target domain data efficiently to achieve a maximal gain in accuracy for a minimal amount of work. [sent-66, score-0.243]
</p><p>43 Active learning has been used as a way to pick data that is useful to annotate in this scenario for several applications (Chan and Ng, 2007; Rai et al. [sent-67, score-0.039]
</p><p>44 When adapting sequence-based prediction methods, most active learning approaches have focused on picking full sentences that are valuable to annotate (Ringger et al. [sent-69, score-0.367]
</p><p>45 However, even within sentences, there are generally a few points of interest surrounded by large segments that are well covered by already annotated data. [sent-71, score-0.062]
</p><p>46 Partial annotation provides a solution to this problem (Tsuboi et al. [sent-72, score-0.093]
</p><p>47 In partial annotation, data that will not contribute to the improvement of the classifier is left untagged. [sent-74, score-0.153]
</p><p>48 For example, if there is a single difficult word in a long sentence, only the word boundaries and POS of the difficult word will be tagged. [sent-75, score-0.173]
</p><p>49 “Dif2Dictionary features are active if the string exists, regardless of whether it is treated as a single word in w1J, and thus can be  calculated without the word segmentation result. [sent-76, score-0.462]
</p><p>50 53kk  Table 3: General and target domain corpus sizes in words. [sent-79, score-0.115]
</p><p>51 ficult” words can be selected using active learning approaches, choosing words with the lowest classifier accuracy to annotate. [sent-80, score-0.286]
</p><p>52 In addition, corpora that are tagged with word boundaries but not POS tags are often available; this is another type of partial annotation. [sent-81, score-0.266]
</p><p>53 When using sequence-based prediction, learning on partially annotated data is not straightforward, as the data that must be used to train context-based transition probabilities may be left unannotated. [sent-82, score-0.14]
</p><p>54 In contrast, in the pointwise prediction framework, training using this data is both simple and efficient; unannotated points are simply ignored. [sent-83, score-0.41]
</p><p>55 A method for learning CRFs from partially annotated data has been presented by Tsuboi et al. [sent-84, score-0.098]
</p><p>56 However, when using partial annotation, CRFs’ already slow  training time becomes slower still, as they must be trained over every sequence that has at least one annotated point. [sent-86, score-0.214]
</p><p>57 Training time is important in an active learning situation, as an annotator must wait while the model is being re-trained. [sent-87, score-0.237]
</p><p>58 4  Experiments  In order to test the effectiveness of pointwise MA, we did an experiment measuring accuracy both on in-domain data, and in a domain-adaptation situation. [sent-88, score-0.309]
</p><p>59 We used the Balanced Corpus of Contemporary Written Japanese (BCCWJ) (Maekawa, 2008), specifying the whitepaper, news, and books sections as our general domain corpus, and the web text section as our target domain corpus (Table 3). [sent-89, score-0.23]
</p><p>60 As a representative of joint sequence-based MA described in 2. [sent-90, score-0.078]
</p><p>61 For the pointwise two-step method, we trained logistic regression models with the LIBLINEAR toolkit (Fan et al. [sent-93, score-0.26]
</p><p>62 In addition, we trained a CRF-based  model with the CRFSuite toolkit (Okazaki, 2007) using the same features and set-up (for both word  TaG T bErleaN in+4:TAWRord/TG PAOeEsR NStF-9m476Je. [sent-96, score-0.035]
</p><p>63 d2801-23wL% hRen trained and tested on general (GEN) or target (TAR) domain corpora. [sent-99, score-0.115]
</p><p>64 segmentation and POS tagging) to examine the contribution of context information (2-CRF). [sent-100, score-0.093]
</p><p>65 To create the dictionary, we added all of the words in the corpus, but left out a small portion of singletons to prevent overfitting on the training data3. [sent-101, score-0.103]
</p><p>66 (2004) and use Word/POS tag pair Fmeasure, so that both word boundaries and POS tags must be correct for a word to be considered correct. [sent-103, score-0.24]
</p><p>67 1 Analysis Results In our first experiment we compared the accuracy of the three methods on both the in-domain and out-  of-domain test sets (Table 4). [sent-105, score-0.049]
</p><p>68 The reason for accuracy gains over JOINT lies largely in the fact that while JOINT is more reliant on the dictionary, and thus tends to mis-segment unknown words, the two-step methods are significantly more robust. [sent-107, score-0.12]
</p><p>69 The small difference between 2-LR and 2-CRF indicates that given a significantly rich feature set, contextbased features provide little advantage, although the advantage is larger on out-of-domain data. [sent-108, score-0.048]
</p><p>70 2 Domain Adaptation Our second experiment focused on the domain adaptability of each method. [sent-113, score-0.115]
</p><p>71 Using the target domain training corpus as a pool of unannotated data, we performed active learning-based domain adaptation using two techniques. [sent-114, score-0.653]
</p><p>72 •  Sentence-based annotation (SENT), where senSteenncteesn we-ibtha tehde a nlonwoetastit ntot (al POS and word  3For  JOINT we  removed singletons randomly until coverage  was 99. [sent-115, score-0.224]
</p><p>73 Figure 2: Domain adaptation results for three approaches and two annotation methods. [sent-117, score-0.22]
</p><p>74 •  Word-based partial annotation (PART), where tWheo wd-obrads or pwaorrtida boundary wnit (h the smallest probability margin between the first and second candidates was chosen. [sent-119, score-0.337]
</p><p>75 This can only be used with the pointwise 2-LR approach4 . [sent-120, score-0.26]
</p><p>76 For both methods, 100 words (or for SENT until the end of the sentence in which the 100th word is reached) are annotated, then the classifier is retrained and new probability scores are generated. [sent-121, score-0.035]
</p><p>77 From the results in Figure 2, it can be seen that the combination of PART and 2-LR allows for significantly faster adaptation than other approaches, achieving accuracy gains in 15 iterations that are achieved in 100 iterations with SENT, and surpassing 2-CRF after 15 iterations. [sent-123, score-0.212]
</p><p>78 Finally, it can be seen that JOINT improves at a pace similar to PART, likely due to the fact that its pre-adaptation accuracy is lower than the other methods. [sent-124, score-0.049]
</p><p>79 It can be seen from Table 4 that even after adaptation with the full corpus, it will still lag behind the two-step methods. [sent-125, score-0.127]
</p><p>80 5  Conclusion  This paper proposed a pointwise approach to Japanese morphological analysis. [sent-126, score-0.377]
</p><p>81 It showed that despite the lack of structure, it was able to achieve re4In order to prevent wasteful annotation, each unique word  was only annotated once per iteration. [sent-127, score-0.097]
</p><p>82 We also demonstrated that it is both robust and adaptable to out-of-domain text through the use of partial annotation and active learning. [sent-129, score-0.658]
</p><p>83 Domain adaptation with active learning for word sense disambiguation. [sent-137, score-0.399]
</p><p>84 An empirical study of the domain dependence of supervised word sense disambiguation systems. [sent-141, score-0.15]
</p><p>85 An error-driven word-character hybrid model for joint Chinese word segmentation and POS tagging. [sent-149, score-0.206]
</p><p>86 A stochastic Japanese morphological analyzer using a forward-DP backward-A∗ Nbest search algorithm. [sent-171, score-0.117]
</p><p>87 Chinese and Japanese word segmentation using word-level and character-level information. [sent-175, score-0.128]
</p><p>88 CRFsuite: a fast implementation of conditional random fields (CRFs). [sent-188, score-0.121]
</p><p>89 Chinese segmentation and new word detection using conditional random fields. [sent-194, score-0.179]
</p><p>90 Using smaller constituents rather than sentences in active learning for Japanese dependency parsing. [sent-207, score-0.237]
</p><p>91 An empirical study of active learning with support vector machines for Japanese word segmentation. [sent-211, score-0.272]
</p><p>92 An analysis of active learning strategies for sequence labeling tasks. [sent-215, score-0.278]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('japanese', 0.285), ('pointwise', 0.26), ('active', 0.237), ('kudo', 0.231), ('xl', 0.207), ('ma', 0.188), ('crfs', 0.17), ('adaptable', 0.163), ('tsuboi', 0.161), ('boundary', 0.133), ('adaptation', 0.127), ('neubig', 0.121), ('xrxr', 0.121), ('morphological', 0.117), ('dictionary', 0.117), ('pos', 0.115), ('domain', 0.115), ('partial', 0.111), ('shinsuke', 0.106), ('djk', 0.106), ('sassano', 0.106), ('wj', 0.1), ('mori', 0.098), ('annotation', 0.093), ('segmentation', 0.093), ('prediction', 0.091), ('tj', 0.084), ('unsegmented', 0.084), ('crfsuite', 0.08), ('escudero', 0.08), ('xlxr', 0.08), ('xlxrxr', 0.08), ('xr', 0.08), ('joint', 0.078), ('rai', 0.071), ('mecab', 0.071), ('fields', 0.07), ('boundaries', 0.068), ('yuji', 0.066), ('asahara', 0.065), ('kruengkrai', 0.065), ('ringger', 0.065), ('predictors', 0.063), ('liang', 0.062), ('annotated', 0.062), ('string', 0.062), ('singletons', 0.061), ('poss', 0.061), ('structured', 0.06), ('unannotated', 0.059), ('graham', 0.058), ('settles', 0.058), ('wordbased', 0.056), ('sent', 0.055), ('character', 0.054), ('characters', 0.054), ('neighboring', 0.054), ('rs', 0.054), ('robust', 0.054), ('nagata', 0.054), ('contemporary', 0.054), ('tags', 0.052), ('conditional', 0.051), ('kyoto', 0.05), ('taku', 0.05), ('liblinear', 0.05), ('tag', 0.05), ('exceed', 0.049), ('accuracy', 0.049), ('ng', 0.048), ('indicates', 0.048), ('chan', 0.045), ('parts', 0.044), ('morphemes', 0.043), ('peng', 0.043), ('ls', 0.042), ('hwee', 0.042), ('left', 0.042), ('sequence', 0.041), ('hal', 0.041), ('tou', 0.041), ('maximal', 0.04), ('fan', 0.04), ('annotate', 0.039), ('bi', 0.038), ('tagging', 0.038), ('chinese', 0.038), ('daum', 0.037), ('exists', 0.037), ('segmenting', 0.037), ('partially', 0.036), ('gains', 0.036), ('formulated', 0.036), ('word', 0.035), ('naoaki', 0.035), ('hiroki', 0.035), ('ntot', 0.035), ('honmachi', 0.035), ('avishek', 0.035), ('reliant', 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999899 <a title="238-tfidf-1" href="./acl-2011-P11-2093_k2opt.pdf.html">238 acl-2011-P11-2093 k2opt.pdf</a></p>
<p>Author: empty-author</p><p>Abstract: We present a pointwise approach to Japanese morphological analysis (MA) that ignores structure information during learning and tagging. Despite the lack of structure, it is able to outperform the current state-of-the-art structured approach for Japanese MA, and achieves accuracy similar to that of structured predictors using the same feature set. We also find that the method is both robust to outof-domain data, and can be easily adapted through the use of a combination of partial annotation and active learning.</p><p>2 0.15478019 <a title="238-tfidf-2" href="./acl-2011-A_Stacked_Sub-Word_Model_for_Joint_Chinese_Word_Segmentation_and_Part-of-Speech_Tagging.html">27 acl-2011-A Stacked Sub-Word Model for Joint Chinese Word Segmentation and Part-of-Speech Tagging</a></p>
<p>Author: Weiwei Sun</p><p>Abstract: The large combined search space of joint word segmentation and Part-of-Speech (POS) tagging makes efficient decoding very hard. As a result, effective high order features representing rich contexts are inconvenient to use. In this work, we propose a novel stacked subword model for this task, concerning both efficiency and effectiveness. Our solution is a two step process. First, one word-based segmenter, one character-based segmenter and one local character classifier are trained to produce coarse segmentation and POS information. Second, the outputs of the three predictors are merged into sub-word sequences, which are further bracketed and labeled with POS tags by a fine-grained sub-word tagger. The coarse-to-fine search scheme is effi- cient, while in the sub-word tagging step rich contextual features can be approximately derived. Evaluation on the Penn Chinese Treebank shows that our model yields improvements over the best system reported in the literature.</p><p>3 0.12439615 <a title="238-tfidf-3" href="./acl-2011-Unsupervised_Bilingual_Morpheme_Segmentation_and_Alignment_with_Context-rich_Hidden_Semi-Markov_Models.html">318 acl-2011-Unsupervised Bilingual Morpheme Segmentation and Alignment with Context-rich Hidden Semi-Markov Models</a></p>
<p>Author: Jason Naradowsky ; Kristina Toutanova</p><p>Abstract: This paper describes an unsupervised dynamic graphical model for morphological segmentation and bilingual morpheme alignment for statistical machine translation. The model extends Hidden Semi-Markov chain models by using factored output nodes and special structures for its conditional probability distributions. It relies on morpho-syntactic and lexical source-side information (part-of-speech, morphological segmentation) while learning a morpheme segmentation over the target language. Our model outperforms a competitive word alignment system in alignment quality. Used in a monolingual morphological segmentation setting it substantially improves accuracy over previous state-of-the-art models on three Arabic and Hebrew datasets.</p><p>4 0.11979862 <a title="238-tfidf-4" href="./acl-2011-Evaluating_the_Impact_of_Coder_Errors_on_Active_Learning.html">119 acl-2011-Evaluating the Impact of Coder Errors on Active Learning</a></p>
<p>Author: Ines Rehbein ; Josef Ruppenhofer</p><p>Abstract: Active Learning (AL) has been proposed as a technique to reduce the amount of annotated data needed in the context of supervised classification. While various simulation studies for a number of NLP tasks have shown that AL works well on goldstandard data, there is some doubt whether the approach can be successful when applied to noisy, real-world data sets. This paper presents a thorough evaluation of the impact of annotation noise on AL and shows that systematic noise resulting from biased coder decisions can seriously harm the AL process. We present a method to filter out inconsistent annotations during AL and show that this makes AL far more robust when ap- plied to noisy data.</p><p>5 0.10629823 <a title="238-tfidf-5" href="./acl-2011-Domain_Adaptation_for_Machine_Translation_by_Mining_Unseen_Words.html">104 acl-2011-Domain Adaptation for Machine Translation by Mining Unseen Words</a></p>
<p>Author: Hal Daume III ; Jagadeesh Jagarlamudi</p><p>Abstract: We show that unseen words account for a large part of the translation error when moving to new domains. Using an extension of a recent approach to mining translations from comparable corpora (Haghighi et al., 2008), we are able to find translations for otherwise OOV terms. We show several approaches to integrating such translations into a phrasebased translation system, yielding consistent improvements in translations quality (between 0.5 and 1.5 Bleu points) on four domains and two language pairs.</p><p>6 0.10602933 <a title="238-tfidf-6" href="./acl-2011-A_Discriminative_Model_for_Joint_Morphological_Disambiguation_and_Dependency_Parsing.html">10 acl-2011-A Discriminative Model for Joint Morphological Disambiguation and Dependency Parsing</a></p>
<p>7 0.10394059 <a title="238-tfidf-7" href="./acl-2011-Parsing_the_Internal_Structure_of_Words%3A_A_New_Paradigm_for_Chinese_Word_Segmentation.html">241 acl-2011-Parsing the Internal Structure of Words: A New Paradigm for Chinese Word Segmentation</a></p>
<p>8 0.098541625 <a title="238-tfidf-8" href="./acl-2011-Is_Machine_Translation_Ripe_for_Cross-Lingual_Sentiment_Classification%3F.html">179 acl-2011-Is Machine Translation Ripe for Cross-Lingual Sentiment Classification?</a></p>
<p>9 0.09195365 <a title="238-tfidf-9" href="./acl-2011-A_Comprehensive_Dictionary_of_Multiword_Expressions.html">6 acl-2011-A Comprehensive Dictionary of Multiword Expressions</a></p>
<p>10 0.088323772 <a title="238-tfidf-10" href="./acl-2011-Combining_Morpheme-based_Machine_Translation_with_Post-processing_Morpheme_Prediction.html">75 acl-2011-Combining Morpheme-based Machine Translation with Post-processing Morpheme Prediction</a></p>
<p>11 0.08616703 <a title="238-tfidf-11" href="./acl-2011-A_Cross-Lingual_ILP_Solution_to_Zero_Anaphora_Resolution.html">9 acl-2011-A Cross-Lingual ILP Solution to Zero Anaphora Resolution</a></p>
<p>12 0.086066984 <a title="238-tfidf-12" href="./acl-2011-Joint_Annotation_of_Search_Queries.html">182 acl-2011-Joint Annotation of Search Queries</a></p>
<p>13 0.0858813 <a title="238-tfidf-13" href="./acl-2011-Creating_a_manually_error-tagged_and_shallow-parsed_learner_corpus.html">88 acl-2011-Creating a manually error-tagged and shallow-parsed learner corpus</a></p>
<p>14 0.084140606 <a title="238-tfidf-14" href="./acl-2011-Effective_Use_of_Function_Words_for_Rule_Generalization_in_Forest-Based_Translation.html">110 acl-2011-Effective Use of Function Words for Rule Generalization in Forest-Based Translation</a></p>
<p>15 0.083788849 <a title="238-tfidf-15" href="./acl-2011-Query_Snowball%3A_A_Co-occurrence-based_Approach_to_Multi-document_Summarization_for_Question_Answering.html">255 acl-2011-Query Snowball: A Co-occurrence-based Approach to Multi-document Summarization for Question Answering</a></p>
<p>16 0.082303554 <a title="238-tfidf-16" href="./acl-2011-Domain_Adaptation_by_Constraining_Inter-Domain_Variability_of_Latent_Feature_Representation.html">103 acl-2011-Domain Adaptation by Constraining Inter-Domain Variability of Latent Feature Representation</a></p>
<p>17 0.082059018 <a title="238-tfidf-17" href="./acl-2011-Improved_Modeling_of_Out-Of-Vocabulary_Words_Using_Morphological_Classes.html">163 acl-2011-Improved Modeling of Out-Of-Vocabulary Words Using Morphological Classes</a></p>
<p>18 0.080471881 <a title="238-tfidf-18" href="./acl-2011-Effective_Measures_of_Domain_Similarity_for_Parsing.html">109 acl-2011-Effective Measures of Domain Similarity for Parsing</a></p>
<p>19 0.077634864 <a title="238-tfidf-19" href="./acl-2011-Identification_of_Domain-Specific_Senses_in_a_Machine-Readable_Dictionary.html">158 acl-2011-Identification of Domain-Specific Senses in a Machine-Readable Dictionary</a></p>
<p>20 0.074899562 <a title="238-tfidf-20" href="./acl-2011-Using_Multiple_Sources_to_Construct_a_Sentiment_Sensitive_Thesaurus_for_Cross-Domain_Sentiment_Classification.html">332 acl-2011-Using Multiple Sources to Construct a Sentiment Sensitive Thesaurus for Cross-Domain Sentiment Classification</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.199), (1, -0.01), (2, -0.003), (3, -0.039), (4, -0.048), (5, -0.033), (6, 0.086), (7, -0.003), (8, 0.039), (9, 0.128), (10, -0.005), (11, 0.022), (12, -0.05), (13, 0.071), (14, 0.073), (15, -0.017), (16, -0.01), (17, -0.002), (18, 0.158), (19, 0.1), (20, 0.013), (21, -0.105), (22, -0.025), (23, 0.022), (24, -0.034), (25, 0.06), (26, -0.056), (27, 0.017), (28, 0.004), (29, -0.003), (30, 0.111), (31, 0.045), (32, 0.051), (33, -0.05), (34, -0.029), (35, 0.055), (36, -0.14), (37, -0.016), (38, -0.069), (39, -0.022), (40, 0.073), (41, -0.026), (42, -0.12), (43, -0.001), (44, -0.043), (45, -0.1), (46, 0.056), (47, -0.04), (48, -0.07), (49, -0.166)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93879521 <a title="238-lsi-1" href="./acl-2011-P11-2093_k2opt.pdf.html">238 acl-2011-P11-2093 k2opt.pdf</a></p>
<p>Author: empty-author</p><p>Abstract: We present a pointwise approach to Japanese morphological analysis (MA) that ignores structure information during learning and tagging. Despite the lack of structure, it is able to outperform the current state-of-the-art structured approach for Japanese MA, and achieves accuracy similar to that of structured predictors using the same feature set. We also find that the method is both robust to outof-domain data, and can be easily adapted through the use of a combination of partial annotation and active learning.</p><p>2 0.6737954 <a title="238-lsi-2" href="./acl-2011-A_Stacked_Sub-Word_Model_for_Joint_Chinese_Word_Segmentation_and_Part-of-Speech_Tagging.html">27 acl-2011-A Stacked Sub-Word Model for Joint Chinese Word Segmentation and Part-of-Speech Tagging</a></p>
<p>Author: Weiwei Sun</p><p>Abstract: The large combined search space of joint word segmentation and Part-of-Speech (POS) tagging makes efficient decoding very hard. As a result, effective high order features representing rich contexts are inconvenient to use. In this work, we propose a novel stacked subword model for this task, concerning both efficiency and effectiveness. Our solution is a two step process. First, one word-based segmenter, one character-based segmenter and one local character classifier are trained to produce coarse segmentation and POS information. Second, the outputs of the three predictors are merged into sub-word sequences, which are further bracketed and labeled with POS tags by a fine-grained sub-word tagger. The coarse-to-fine search scheme is effi- cient, while in the sub-word tagging step rich contextual features can be approximately derived. Evaluation on the Penn Chinese Treebank shows that our model yields improvements over the best system reported in the literature.</p><p>3 0.53442252 <a title="238-lsi-3" href="./acl-2011-Is_Machine_Translation_Ripe_for_Cross-Lingual_Sentiment_Classification%3F.html">179 acl-2011-Is Machine Translation Ripe for Cross-Lingual Sentiment Classification?</a></p>
<p>Author: Kevin Duh ; Akinori Fujino ; Masaaki Nagata</p><p>Abstract: Recent advances in Machine Translation (MT) have brought forth a new paradigm for building NLP applications in low-resource scenarios. To build a sentiment classifier for a language with no labeled resources, one can translate labeled data from another language, then train a classifier on the translated text. This can be viewed as a domain adaptation problem, where labeled translations and test data have some mismatch. Various prior work have achieved positive results using this approach. In this opinion piece, we take a step back and make some general statements about crosslingual adaptation problems. First, we claim that domain mismatch is not caused by MT errors, and accuracy degradation will occur even in the case of perfect MT. Second, we argue that the cross-lingual adaptation problem is qualitatively different from other (monolingual) adaptation problems in NLP; thus new adaptation algorithms ought to be considered. This paper will describe a series of carefullydesigned experiments that led us to these conclusions. 1 Summary Question 1: If MT gave perfect translations (semantically), do we still have a domain adaptation challenge in cross-lingual sentiment classification? Answer: Yes. The reason is that while many lations of a word may be valid, the MT system have a systematic bias. For example, the word some” might be prevalent in English reviews, transmight “awebut in 429 translated reviews, the word “excellent” is generated instead. From the perspective of MT, this translation is correct and preserves sentiment polarity. But from the perspective of a classifier, there is a domain mismatch due to differences in word distributions. Question 2: Can we apply standard adaptation algorithms developed for other (monolingual) adaptation problems to cross-lingual adaptation? Answer: No. It appears that the interaction between target unlabeled data and source data can be rather unexpected in the case of cross-lingual adaptation. We do not know the reason, but our experiments show that the accuracy of adaptation algorithms in cross-lingual scenarios have much higher variance than monolingual scenarios. The goal of this opinion piece is to argue the need to better understand the characteristics of domain adaptation in cross-lingual problems. We invite the reader to disagree with our conclusion (that the true barrier to good performance is not insufficient MT quality, but inappropriate domain adaptation methods). Here we present a series of experiments that led us to this conclusion. First we describe the experiment design (§2) and baselines (§3), before answering Question §12 (§4) dan bda Question 32) (§5). 2 Experiment Design The cross-lingual setup is this: we have labeled data from source domain S and wish to build a sentiment classifier for target domain T. Domain mismatch can arise from language differences (e.g. English vs. translated text) or market differences (e.g. DVD vs. Book reviews). Our experiments will involve fixing Proceedings ofP thoer t4l9atnhd A, Onrnuegaoln M,e Jeuntineg 19 o-f2 t4h,e 2 A0s1s1o.c?i ac t2io0n11 fo Ar Cssoocmiaptuiotanti foonra Clo Lminpguutiast i ocns:aslh Loirntpgaupisetrics , pages 429–433, T to a common testset and varying S. This allows us to experiment with different settings for adaptation. We use the Amazon review dataset of Prettenhofer (2010)1 , due to its wide range of languages (English [EN], Japanese [JP], French [FR], German [DE]) and markets (music, DVD, books). Unlike Prettenhofer (2010), we reverse the direction of cross-lingual adaptation and consider English as target. English is not a low-resource language, but this setting allows for more comparisons. Each source dataset has 2000 reviews, equally balanced between positive and negative. The target has 2000 test samples, large unlabeled data (25k, 30k, 50k samples respectively for Music, DVD, and Books), and an additional 2000 labeled data reserved for oracle experiments. Texts in JP, FR, and DE are translated word-by-word into English with Google Translate.2 We perform three sets of experiments, shown in Table 1. Table 2 lists all the results; we will interpret them in the following sections. Target (T) Source (S) 312BDMToVuasbDkil-ecE1N:ExpDMB eorVuimsDkice-JEnPtN,s eBD,MtuoVBDpuoVsk:-iFDck-iERxFN,T DB,vVoMaDruky-sSiDc.E-, 3 How much performance degradation occurs in cross-lingual adaptation? First, we need to quantify the accuracy degradation under different source data, without consideration of domain adaptation methods. So we train a SVM classifier on labeled source data3, and directly apply it on test data. The oracle setting, which has no domain-mismatch (e.g. train on Music-EN, test on Music-EN), achieves an average test accuracy of (81.6 + 80.9 + 80.0)/3 = 80.8%4. Aver1http://www.webis.de/research/corpora/webis-cls-10 2This is done by querying foreign words to build a bilingual dictionary. The words are converted to tfidf unigram features. 3For all methods we try here, 5% of the 2000 labeled source samples are held-out for parameter tuning. 4See column EN of Table 2, Supervised SVM results. 430 age cross-lingual accuracies are: 69.4% (JP), 75.6% (FR), 77.0% (DE), so degradations compared to oracle are: -11% (JP), -5% (FR), -4% (DE).5 Crossmarket degradations are around -6%6. Observation 1: Degradations due to market and language mismatch are comparable in several cases (e.g. MUSIC-DE and DVD-EN perform similarly for target MUSIC-EN). Observation 2: The ranking of source language by decreasing accuracy is DE > FR > JP. Does this mean JP-EN is a more difficult language pair for MT? The next section will show that this is not necessarily the case. Certainly, the domain mismatch for JP is larger than DE, but this could be due to phenomenon other than MT errors. 4 Where exactly is the domain mismatch? 4.1 Theory of Domain Adaptation We analyze domain adaptation by the concepts of labeling and instance mismatch (Jiang and Zhai, 2007). Let pt(x, y) = pt (y|x)pt (x) be the target distribution of samples x (e.g. unigram feature vec- tor) and labels y (positive / negative). Let ps (x, y) = ps (y|x)ps (x) be the corresponding source distributio(ny. Wx)pe assume that one (or both) of the following distributions differ between source and target: • Instance mismatch: ps (x) pt (x). • Labeling mismatch: ps (y|x) pt(y|x). Instance mismatch implies that the input feature vectors have different distribution (e.g. one dataset uses the word “excellent” often, while the other uses the word “awesome”). This degrades performance because classifiers trained on “excellent” might not know how to classify texts with the word “awesome.” The solution is to tie together these features (Blitzer et al., 2006) or re-weight the input distribution (Sugiyama et al., 2008). Under some assumptions (i.e. covariate shift), oracle accuracy can be achieved theoretically (Shimodaira, 2000). Labeling mismatch implies the same input has different labels in different domains. For example, the JP word meaning “excellent” may be mistranslated as “bad” in English. Then, positive JP = = 5See “Adapt by Language” columns of Table 2. Note JP+FR+DE condition has 6000 labeled samples, so is not directly comparable to other adaptation scenarios (2000 samples). Nevertheless, mixing languages seem to give good results. 6See “Adapt by Market” columns of Table 2. TargetClassifierOEraNcleJPAFdaRpt bDyE LanJgPu+agFeR+DEMUASdIaCpt D byV MDar BkeOtOK MUSIC-ENSAudpaeprtvedise TdS SVVMM8719..666783..50 7745..62 7 776..937880..36--7768..847745..16 DVD-ENSAudpaeprtveidse TdS SVVMM8801..907701..14 7765..54 7 767..347789..477754..28--7746..57 BOOK-ENSAudpaeprtveidse TdS SVVMM8801..026793..68 7775..64 7 767..747799..957735..417767..24-Table 2: Test accuracies (%) for English Music/DVD/Book reviews. Each column is an adaptation scenario using different source data. The source data may vary by language or by market. For example, the first row shows that for the target of Music-EN, the accuracy of a SVM trained on translated JP reviews (in the same market) is 68.5, while the accuracy of a SVM trained on DVD reviews (in the same language) is 76.8. “Oracle” indicates training on the same market and same language domain as the target. “JP+FR+DE” indicates the concatenation of JP, FR, DE as source data. Boldface shows the winner of Supervised vs. Adapted. reviews ps (y will be associated = +1|x = bad) co(nydit =io +na1l − |x = 1 will be high, whereas the true xdis =tr bibaudti)o wn bad) instead. labeling mismatch, with the word “bad”: lslh boeu hldi hha,v we high pt(y = There are several cases for depending on sheovwe tahle c polarity changes (Table 3). The solution is to filter out these noisy samples (Jiang and Zhai, 2007) or optimize loosely-linked objectives through shared parameters or Bayesian priors (Finkel and Manning, 2009). Which mismatch is responsible for accuracy degradations in cross-lingual adaptation? • Instance mismatch: Systematic Iantessta nwcoerd m diissmtraibtcuhti:on Ssy MT bias gener- sdtiefmferaetinct MfroTm b naturally- occurring English. (Translation may be valid.) Label mismatch: MT error mis-translates a word iLnatob something w: MithT Td eifrfreorren mti polarity. Conclusion from §4.2 and §4.3: Instance mismaCtcohn occurs often; M §4T. error appears Imnisntainmcael. • Mis-translated polarity Effect Taeb0+±.lge→ .3(:±“ 0−tgLhoae b”nd →l m− i“sg→m otbah+dce”h):mIfpoLAinse ca-ptsoriuaesncvieatl /ndioeansgbvcaewrptlimovaeshipntdvaei(+), negative (−), or neutral (0) words have different effects. Wnege athtiivnek ( −th)e, foirrs nt tuwtroa cases hoardves graceful degradation, but the third case may be catastrophic. 431 4.2 Analysis of Instance Mismatch To measure instance mismatch, we compute statistics between ps (x) and pt(x), or approximations thereof: First, we calculate a (normalized) average feature from all samples of source S, which represents the unigram distribution of MT output. Simi- larly, the average feature vector for target T approximates the unigram distribution of English reviews pt(x). Then we measure: • KL Divergence between Avg(S) and Avg(T), wKhLer De Avg() nisc eth bee average Avvegct(oSr.) • Set Coverage of Avg(T) on Avg(S): how many Sweotrd C (type) ien o Tf appears oatn le Aavsgt once ionw wS .m Both measures correlate strongly with final accuracy, as seen in Figure 1. The correlation coefficients are r = −0.78 for KL Divergence and r = 0.71 for Coverage, 0 b.7o8th statistically significant (p < 0.05). This implies that instance mismatch is an important reason for the degradations seen in Section 3.7 4.3 Analysis of Labeling Mismatch We measure labeling mismatch by looking at differences in the weight vectors of oracle SVM and adapted SVM. Intuitively, if a feature has positive weight in the oracle SVM, but negative weight in the adapted SVM, then it is likely a MT mis-translation 7The observant reader may notice that cross-market points exhibit higher coverage but equal accuracy (74-78%) to some cross-lingual points. This suggests that MT output may be more constrained in vocabulary than naturally-occurring English. 0.35 0.3 gnvLrDeiceKe0 0 0. 120.25 510 erts TeCovega0 0 0. .98657 68 70 72 7A4ccuracy76 78 80 82 0.4 68 70 72 7A4ccuracy76 78 80 82 Figure 1: KL Divergence and Coverage vs. accuracy. (o) are cross-lingual and (x) are cross-market data points. is causing the polarity flip. Algorithm 1 (with K=2000) shows how we compute polarity flip rate.8 We found that the polarity flip rate does not correlate well with accuracy at all (r = 0.04). Conclusion: Labeling mismatch is not a factor in performance degradation. Nevertheless, we note there is a surprising large number of flips (24% on average). A manual check of the flipped words in BOOK-JP revealed few MT mistakes. Only 3.7% of 450 random EN-JP word pairs checked can be judged as blatantly incorrect (without sentence context). The majority of flipped words do not have a clear sentiment orientation (e.g. “amazon”, “human”, “moreover”). 5 Are standard adaptation algorithms applicable to cross-lingual problems? One of the breakthroughs in cross-lingual text classification is the realization that it can be cast as domain adaptation. This makes available a host of preexisting adaptation algorithms for improving over supervised results. However, we argue that it may be 8The feature normalization in Step 1 is important that the weight magnitudes are comparable. to ensure 432 Algorithm 1 Measuring labeling mismatch Input: Weight vectors for source wsand target wt Input: Target data average sample vector avg(T) Output: Polarity flip rate f 1: Normalize: ws = avg(T) * ws ; wt = avg(T) * wt 2: Set S+ = { K most positive features in ws} 3: Set S− == {{ KK mmoosstt negative ffeeaattuurreess inn wws}} 4: Set T+ == {{ KK m moosstt npoesgiatitivvee f efeaatuturreess i inn w wt}} 5: Set T− == {{ KK mmoosstt negative ffeeaattuurreess inn wwt}} 6: for each= f{e a Ktur me io ∈t T+ adtiov 7: rif e ia c∈h S fe−a ttuhreen i if ∈ = T f + 1 8: enidf fio ∈r 9: for each feature j ∈ T− do 10: rif e j ∈h Sfe+a uthreen j f ∈ = T f + 1 11: enidf fjo r∈ 12: f = 2Kf better to “adapt” the standard adaptation algorithm to the cross-lingual setting. We arrived at this conclusion by trying the adapted counterpart of SVMs off-the-shelf. Recently, (Bergamo and Torresani, 2010) showed that Transductive SVMs (TSVM), originally developed for semi-supervised learning, are also strong adaptation methods. The idea is to train on source data like a SVM, but encourage the classification boundary to divide through low density regions in the unlabeled target data. Table 2 shows that TSVM outperforms SVM in all but one case for cross-market adaptation, but gives mixed results for cross-lingual adaptation. This is a puzzling result considering that both use the same unlabeled data. Why does TSVM exhibit such a large variance on cross-lingual problems, but not on cross-market problems? Is unlabeled target data interacting with source data in some unexpected way? Certainly there are several successful studies (Wan, 2009; Wei and Pal, 2010; Banea et al., 2008), but we think it is important to consider the possibility that cross-lingual adaptation has some fundamental differences. We conjecture that adapting from artificially-generated text (e.g. MT output) is a different story than adapting from naturallyoccurring text (e.g. cross-market). In short, MT is ripe for cross-lingual adaptation; what is not ripe is probably our understanding of the special characteristics of the adaptation problem. References Carmen Banea, Rada Mihalcea, Janyce Wiebe, and Samer Hassan. 2008. Multilingual subjectivity analysis using machine translation. In Proc. of Conference on Empirical Methods in Natural Language Processing (EMNLP). Alessandro Bergamo and Lorenzo Torresani. 2010. Exploiting weakly-labeled web images to improve object classification: a domain adaptation approach. In Advances in Neural Information Processing Systems (NIPS). John Blitzer, Ryan McDonald, and Fernando Pereira. 2006. Domain adaptation with structural correspondence learning. In Proc. of Conference on Empirical Methods in Natural Language Processing (EMNLP). Jenny Rose Finkel and Chris Manning. 2009. Hierarchical Bayesian domain adaptation. In Proc. of NAACL Human Language Technologies (HLT). Jing Jiang and ChengXiang Zhai. 2007. Instance weighting for domain adaptation in NLP. In Proc. of the Association for Computational Linguistics (ACL). Peter Prettenhofer and Benno Stein. 2010. Crosslanguage text classification using structural correspondence learning. In Proc. of the Association for Computational Linguistics (ACL). Hidetoshi Shimodaira. 2000. Improving predictive inference under covariate shift by weighting the loglikelihood function. Journal of Statistical Planning and Inferenc, 90. Masashi Sugiyama, Taiji Suzuki, Shinichi Nakajima, Hisashi Kashima, Paul von B ¨unau, and Motoaki Kawanabe. 2008. Direct importance estimation for covariate shift adaptation. Annals of the Institute of Statistical Mathematics, 60(4). Xiaojun Wan. 2009. Co-training for cross-lingual sentiment classification. In Proc. of the Association for Computational Linguistics (ACL). Bin Wei and Chris Pal. 2010. Cross lingual adaptation: an experiment on sentiment classification. In Proceedings of the ACL 2010 Conference Short Papers. 433</p><p>4 0.52497143 <a title="238-lsi-4" href="./acl-2011-Evaluating_the_Impact_of_Coder_Errors_on_Active_Learning.html">119 acl-2011-Evaluating the Impact of Coder Errors on Active Learning</a></p>
<p>Author: Ines Rehbein ; Josef Ruppenhofer</p><p>Abstract: Active Learning (AL) has been proposed as a technique to reduce the amount of annotated data needed in the context of supervised classification. While various simulation studies for a number of NLP tasks have shown that AL works well on goldstandard data, there is some doubt whether the approach can be successful when applied to noisy, real-world data sets. This paper presents a thorough evaluation of the impact of annotation noise on AL and shows that systematic noise resulting from biased coder decisions can seriously harm the AL process. We present a method to filter out inconsistent annotations during AL and show that this makes AL far more robust when ap- plied to noisy data.</p><p>5 0.52358466 <a title="238-lsi-5" href="./acl-2011-Fully_Unsupervised_Word_Segmentation_with_BVE_and_MDL.html">140 acl-2011-Fully Unsupervised Word Segmentation with BVE and MDL</a></p>
<p>Author: Daniel Hewlett ; Paul Cohen</p><p>Abstract: Several results in the word segmentation literature suggest that description length provides a useful estimate of segmentation quality in fully unsupervised settings. However, since the space of potential segmentations grows exponentially with the length of the corpus, no tractable algorithm follows directly from the Minimum Description Length (MDL) principle. Therefore, it is necessary to generate a set of candidate segmentations and select between them according to the MDL principle. We evaluate several algorithms for generating these candidate segmentations on a range of natural language corpora, and show that the Bootstrapped Voting Experts algorithm consistently outperforms other methods when paired with MDL.</p><p>6 0.5207116 <a title="238-lsi-6" href="./acl-2011-Exploiting_Morphology_in_Turkish_Named_Entity_Recognition_System.html">124 acl-2011-Exploiting Morphology in Turkish Named Entity Recognition System</a></p>
<p>7 0.51898128 <a title="238-lsi-7" href="./acl-2011-Domain_Adaptation_by_Constraining_Inter-Domain_Variability_of_Latent_Feature_Representation.html">103 acl-2011-Domain Adaptation by Constraining Inter-Domain Variability of Latent Feature Representation</a></p>
<p>8 0.50824642 <a title="238-lsi-8" href="./acl-2011-That%27s_What_She_Said%3A_Double_Entendre_Identification.html">297 acl-2011-That's What She Said: Double Entendre Identification</a></p>
<p>9 0.5034368 <a title="238-lsi-9" href="./acl-2011-Effective_Measures_of_Domain_Similarity_for_Parsing.html">109 acl-2011-Effective Measures of Domain Similarity for Parsing</a></p>
<p>10 0.50138623 <a title="238-lsi-10" href="./acl-2011-Data_point_selection_for_cross-language_adaptation_of_dependency_parsers.html">92 acl-2011-Data point selection for cross-language adaptation of dependency parsers</a></p>
<p>11 0.48445541 <a title="238-lsi-11" href="./acl-2011-Learning_Sub-Word_Units_for_Open_Vocabulary_Speech_Recognition.html">203 acl-2011-Learning Sub-Word Units for Open Vocabulary Speech Recognition</a></p>
<p>12 0.48440921 <a title="238-lsi-12" href="./acl-2011-Does_Size_Matter_-_How_Much_Data_is_Required_to_Train_a_REG_Algorithm%3F.html">102 acl-2011-Does Size Matter - How Much Data is Required to Train a REG Algorithm?</a></p>
<p>13 0.48126507 <a title="238-lsi-13" href="./acl-2011-Unsupervised_Bilingual_Morpheme_Segmentation_and_Alignment_with_Context-rich_Hidden_Semi-Markov_Models.html">318 acl-2011-Unsupervised Bilingual Morpheme Segmentation and Alignment with Context-rich Hidden Semi-Markov Models</a></p>
<p>14 0.47212061 <a title="238-lsi-14" href="./acl-2011-Parsing_the_Internal_Structure_of_Words%3A_A_New_Paradigm_for_Chinese_Word_Segmentation.html">241 acl-2011-Parsing the Internal Structure of Words: A New Paradigm for Chinese Word Segmentation</a></p>
<p>15 0.46871075 <a title="238-lsi-15" href="./acl-2011-Chinese_sentence_segmentation_as_comma_classification.html">66 acl-2011-Chinese sentence segmentation as comma classification</a></p>
<p>16 0.46751952 <a title="238-lsi-16" href="./acl-2011-A_Discriminative_Model_for_Joint_Morphological_Disambiguation_and_Dependency_Parsing.html">10 acl-2011-A Discriminative Model for Joint Morphological Disambiguation and Dependency Parsing</a></p>
<p>17 0.45277193 <a title="238-lsi-17" href="./acl-2011-Improved_Modeling_of_Out-Of-Vocabulary_Words_Using_Morphological_Classes.html">163 acl-2011-Improved Modeling of Out-Of-Vocabulary Words Using Morphological Classes</a></p>
<p>18 0.45142505 <a title="238-lsi-18" href="./acl-2011-MACAON_An_NLP_Tool_Suite_for_Processing_Word_Lattices.html">215 acl-2011-MACAON An NLP Tool Suite for Processing Word Lattices</a></p>
<p>19 0.44493893 <a title="238-lsi-19" href="./acl-2011-Unsupervised_Part-of-Speech_Tagging_with_Bilingual_Graph-Based_Projections.html">323 acl-2011-Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</a></p>
<p>20 0.4426142 <a title="238-lsi-20" href="./acl-2011-Better_Automatic_Treebank_Conversion_Using_A_Feature-Based_Approach.html">59 acl-2011-Better Automatic Treebank Conversion Using A Feature-Based Approach</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.011), (17, 0.04), (26, 0.015), (37, 0.115), (39, 0.113), (41, 0.067), (46, 0.262), (53, 0.012), (55, 0.038), (59, 0.049), (72, 0.033), (91, 0.04), (96, 0.147)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.8561213 <a title="238-lda-1" href="./acl-2011-That%27s_What_She_Said%3A_Double_Entendre_Identification.html">297 acl-2011-That's What She Said: Double Entendre Identification</a></p>
<p>Author: Chloe Kiddon ; Yuriy Brun</p><p>Abstract: Humor identification is a hard natural language understanding problem. We identify a subproblem — the “that’s what she said” problem with two distinguishing characteristics: (1) use of nouns that are euphemisms for sexually explicit nouns and (2) structure common in the erotic domain. We address this problem in a classification approach that includes features that model those two characteristics. Experiments on web data demonstrate that our approach improves precision by 12% over baseline techniques that use only word-based features. —</p><p>2 0.82065994 <a title="238-lda-2" href="./acl-2011-Lexically-Triggered_Hidden_Markov_Models_for_Clinical_Document_Coding.html">209 acl-2011-Lexically-Triggered Hidden Markov Models for Clinical Document Coding</a></p>
<p>Author: Svetlana Kiritchenko ; Colin Cherry</p><p>Abstract: The automatic coding of clinical documents is an important task for today’s healthcare providers. Though it can be viewed as multi-label document classification, the coding problem has the interesting property that most code assignments can be supported by a single phrase found in the input document. We propose a Lexically-Triggered Hidden Markov Model (LT-HMM) that leverages these phrases to improve coding accuracy. The LT-HMM works in two stages: first, a lexical match is performed against a term dictionary to collect a set of candidate codes for a document. Next, a discriminative HMM selects the best subset of codes to assign to the document by tagging candidates as present or absent. By confirming codes proposed by a dictionary, the LT-HMM can share features across codes, enabling strong performance even on rare codes. In fact, we are able to recover codes that do not occur in the training set at all. Our approach achieves the best ever performance on the 2007 Medical NLP Challenge test set, with an F-measure of 89.84.</p><p>same-paper 3 0.78474009 <a title="238-lda-3" href="./acl-2011-P11-2093_k2opt.pdf.html">238 acl-2011-P11-2093 k2opt.pdf</a></p>
<p>Author: empty-author</p><p>Abstract: We present a pointwise approach to Japanese morphological analysis (MA) that ignores structure information during learning and tagging. Despite the lack of structure, it is able to outperform the current state-of-the-art structured approach for Japanese MA, and achieves accuracy similar to that of structured predictors using the same feature set. We also find that the method is both robust to outof-domain data, and can be easily adapted through the use of a combination of partial annotation and active learning.</p><p>4 0.65478188 <a title="238-lda-4" href="./acl-2011-Discovering_Sociolinguistic_Associations_with_Structured_Sparsity.html">97 acl-2011-Discovering Sociolinguistic Associations with Structured Sparsity</a></p>
<p>Author: Jacob Eisenstein ; Noah A. Smith ; Eric P. Xing</p><p>Abstract: We present a method to discover robust and interpretable sociolinguistic associations from raw geotagged text data. Using aggregate demographic statistics about the authors’ geographic communities, we solve a multi-output regression problem between demographics and lexical frequencies. By imposing a composite ‘1,∞ regularizer, we obtain structured sparsity, driving entire rows of coefficients to zero. We perform two regression studies. First, we use term frequencies to predict demographic attributes; our method identifies a compact set of words that are strongly associated with author demographics. Next, we conjoin demographic attributes into features, which we use to predict term frequencies. The composite regularizer identifies a small number of features, which correspond to communities of authors united by shared demographic and linguistic properties.</p><p>5 0.65322077 <a title="238-lda-5" href="./acl-2011-A_Stacked_Sub-Word_Model_for_Joint_Chinese_Word_Segmentation_and_Part-of-Speech_Tagging.html">27 acl-2011-A Stacked Sub-Word Model for Joint Chinese Word Segmentation and Part-of-Speech Tagging</a></p>
<p>Author: Weiwei Sun</p><p>Abstract: The large combined search space of joint word segmentation and Part-of-Speech (POS) tagging makes efficient decoding very hard. As a result, effective high order features representing rich contexts are inconvenient to use. In this work, we propose a novel stacked subword model for this task, concerning both efficiency and effectiveness. Our solution is a two step process. First, one word-based segmenter, one character-based segmenter and one local character classifier are trained to produce coarse segmentation and POS information. Second, the outputs of the three predictors are merged into sub-word sequences, which are further bracketed and labeled with POS tags by a fine-grained sub-word tagger. The coarse-to-fine search scheme is effi- cient, while in the sub-word tagging step rich contextual features can be approximately derived. Evaluation on the Penn Chinese Treebank shows that our model yields improvements over the best system reported in the literature.</p><p>6 0.65185571 <a title="238-lda-6" href="./acl-2011-Scaling_up_Automatic_Cross-Lingual_Semantic_Role_Annotation.html">269 acl-2011-Scaling up Automatic Cross-Lingual Semantic Role Annotation</a></p>
<p>7 0.65083349 <a title="238-lda-7" href="./acl-2011-Learning_Hierarchical_Translation_Structure_with_Linguistic_Annotations.html">202 acl-2011-Learning Hierarchical Translation Structure with Linguistic Annotations</a></p>
<p>8 0.65075409 <a title="238-lda-8" href="./acl-2011-A_Word-Class_Approach_to_Labeling_PSCFG_Rules_for_Machine_Translation.html">29 acl-2011-A Word-Class Approach to Labeling PSCFG Rules for Machine Translation</a></p>
<p>9 0.65036833 <a title="238-lda-9" href="./acl-2011-Joint_Annotation_of_Search_Queries.html">182 acl-2011-Joint Annotation of Search Queries</a></p>
<p>10 0.64986885 <a title="238-lda-10" href="./acl-2011-Beam-Width_Prediction_for_Efficient_Context-Free_Parsing.html">58 acl-2011-Beam-Width Prediction for Efficient Context-Free Parsing</a></p>
<p>11 0.64931458 <a title="238-lda-11" href="./acl-2011-Parsing_the_Internal_Structure_of_Words%3A_A_New_Paradigm_for_Chinese_Word_Segmentation.html">241 acl-2011-Parsing the Internal Structure of Words: A New Paradigm for Chinese Word Segmentation</a></p>
<p>12 0.64637125 <a title="238-lda-12" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>13 0.64554149 <a title="238-lda-13" href="./acl-2011-Exploring_Entity_Relations_for_Named_Entity_Disambiguation.html">128 acl-2011-Exploring Entity Relations for Named Entity Disambiguation</a></p>
<p>14 0.6445272 <a title="238-lda-14" href="./acl-2011-A_Comparison_of_Loopy_Belief_Propagation_and_Dual_Decomposition_for_Integrated_CCG_Supertagging_and_Parsing.html">5 acl-2011-A Comparison of Loopy Belief Propagation and Dual Decomposition for Integrated CCG Supertagging and Parsing</a></p>
<p>15 0.64336681 <a title="238-lda-15" href="./acl-2011-Exploiting_Syntactico-Semantic_Structures_for_Relation_Extraction.html">126 acl-2011-Exploiting Syntactico-Semantic Structures for Relation Extraction</a></p>
<p>16 0.64287174 <a title="238-lda-16" href="./acl-2011-The_Surprising_Variance_in_Shortest-Derivation_Parsing.html">300 acl-2011-The Surprising Variance in Shortest-Derivation Parsing</a></p>
<p>17 0.64207792 <a title="238-lda-17" href="./acl-2011-A_Statistical_Tree_Annotator_and_Its_Applications.html">28 acl-2011-A Statistical Tree Annotator and Its Applications</a></p>
<p>18 0.64204466 <a title="238-lda-18" href="./acl-2011-Unary_Constraints_for_Efficient_Context-Free_Parsing.html">316 acl-2011-Unary Constraints for Efficient Context-Free Parsing</a></p>
<p>19 0.6414417 <a title="238-lda-19" href="./acl-2011-Fine-Grained_Class_Label_Markup_of_Search_Queries.html">137 acl-2011-Fine-Grained Class Label Markup of Search Queries</a></p>
<p>20 0.64103705 <a title="238-lda-20" href="./acl-2011-Language-Independent_Parsing_with_Empty_Elements.html">192 acl-2011-Language-Independent Parsing with Empty Elements</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
