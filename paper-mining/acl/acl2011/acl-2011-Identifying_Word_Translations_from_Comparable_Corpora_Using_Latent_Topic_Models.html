<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>161 acl-2011-Identifying Word Translations from Comparable Corpora Using Latent Topic Models</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-161" href="#">acl2011-161</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>161 acl-2011-Identifying Word Translations from Comparable Corpora Using Latent Topic Models</h1>
<br/><p>Source: <a title="acl-2011-161-pdf" href="http://aclweb.org/anthology//P/P11/P11-2084.pdf">pdf</a></p><p>Author: Ivan Vulic ; Wim De Smet ; Marie-Francine Moens</p><p>Abstract: A topic model outputs a set of multinomial distributions over words for each topic. In this paper, we investigate the value of bilingual topic models, i.e., a bilingual Latent Dirichlet Allocation model for finding translations of terms in comparable corpora without using any linguistic resources. Experiments on a document-aligned English-Italian Wikipedia corpus confirm that the developed methods which only use knowledge from word-topic distributions outperform methods based on similarity measures in the original word-document space. The best results, obtained by combining knowledge from wordtopic distributions with similarity measures in the original space, are also reported.</p><p>Reference: <a title="acl-2011-161-reference" href="../acl2011_reference/acl-2011-Identifying_Word_Translations_from_Comparable_Corpora_Using_Latent_Topic_Models_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 be c  Abstract A topic model outputs a set of multinomial distributions over words for each topic. [sent-8, score-0.501]
</p><p>2 In this paper, we investigate the value of bilingual topic models, i. [sent-9, score-0.448]
</p><p>3 , a bilingual Latent Dirichlet Allocation model for finding translations of terms in comparable corpora without using any linguistic resources. [sent-11, score-0.311]
</p><p>4 Experiments on a document-aligned English-Italian Wikipedia corpus confirm that the developed methods which only use knowledge from word-topic distributions outperform methods based on similarity measures in the original word-document space. [sent-12, score-0.271]
</p><p>5 The best results, obtained by combining knowledge from wordtopic distributions with similarity measures in the original space, are also reported. [sent-13, score-0.353]
</p><p>6 , 2003) are based upon the idea that latent variables exist which determine how words in documents might be generated. [sent-15, score-0.146]
</p><p>7 Fitting a generative model means finding the best set of those latent variables in order to explain the observed data. [sent-16, score-0.147]
</p><p>8 Within that setting, documents are observed as mixtures of latent topics, where topics are probability distributions over words. [sent-17, score-0.527]
</p><p>9 Our goal is to model and test the capability of probabilistic topic models to identify potential translations from document-aligned text collections. [sent-18, score-0.543]
</p><p>10 A representative example of such a comparable text collection is Wikipedia, where one may observe articles discussing the same topic, but strongly varying 479 in style, length and even vocabulary, while still sharing a certain amount of main concepts (or topics). [sent-19, score-0.077]
</p><p>11 We try to establish a connection between such latent topics and an idea known as the distributional hypothesis (Harris, 1954) - words with a similar meaning are often used in similar contexts. [sent-20, score-0.404]
</p><p>12 Besides  the  obvious  context  of direct  co-  occurrence, we believe that topic models are an additional source of knowledge which might be used to improve results in the quest for translation candidates extracted without the availability of a translation dictionary and linguistic knowledge. [sent-21, score-0.662]
</p><p>13 We designed several methods, all derived from the core idea of using word distributions over topics as an extra source of contextual knowledge. [sent-22, score-0.614]
</p><p>14 Two words are potential translation candidates if they are often present in the same cross-lingual topics and not observed in other cross-lingual topics. [sent-23, score-0.451]
</p><p>15 In other words, a word w2 from a target language is a potential translation candidate for a word w1 from a source language, if the distribution of w2 over the target language topics is similar to the distribution of w1 over the source language topics. [sent-24, score-0.897]
</p><p>16 Section 2 describes related work, focusing on previous attempts to use topic models to recognize potential translations. [sent-26, score-0.414]
</p><p>17 i ac t2io0n11 fo Ar Cssoocmiaptuiotanti foonra Clo Lminpguutiast i ocns:aslh Loirntpgaupisetrics , pages 479–484, 2  Related Work  The idea to acquire translation candidates based on comparable and unrelated corpora comes from (Rapp, 1995). [sent-32, score-0.274]
</p><p>18 These methods need an initial lexicon of translations, cognates or similar words which are then used to acquire additional translations of the context words. [sent-35, score-0.236]
</p><p>19 In contrast, our method does not bootstrap on language pairs that share morphology, cognates or similar words. [sent-36, score-0.109]
</p><p>20 Some attempts of obtaining translations using cross-lingual topic models have been made in the last few years, but they are model-dependent and do not provide a general environment to adapt and apply other topic models for the task of finding translation correspondences. [sent-37, score-0.888]
</p><p>21 , 2009) have designed a probabilistic topic model that fits Wikipedia data, but they did not use their models to obtain po-  tential translations. [sent-39, score-0.343]
</p><p>22 , 2009) retrieve a list of potential translations simply by selecting a small number N of the most probable words in both languages and then add the Cartesian product of these sets for every topic to a set of candidate translations. [sent-41, score-0.625]
</p><p>23 This approach is straightforward, but it does not catch the structure of the latent topic space completely. [sent-42, score-0.454]
</p><p>24 3  Methodology  In this section we present the topic model we used in our experiments and outline the formal framework within which three different approaches for acquiring potential word translations were built. [sent-45, score-0.583]
</p><p>25 1 Bilingual LDA The topic model we use is a bilingual extension of a standard LDA model, called bilingual LDA 480 (BiLDA), which has been presented in (Ni et al. [sent-47, score-0.553]
</p><p>26 As the name suggests, it is an extension of the basic LDA model, taking into account bilinguality and designed for parallel document pairs. [sent-50, score-0.044]
</p><p>27 We test its performance on a collection of comparable texts which are document-aligned and therefore share their topics. [sent-51, score-0.124]
</p><p>28 BiLDA takes advantage of the document alignment by using a single variable that contains the topic distribution θ, that is languageindependent by assumption and shared by the paired bilingual comparable documents. [sent-52, score-0.608]
</p><p>29 Topics for each document are sampled from θ, from which the words are sampled in conjugation with the vocabulary distribution φ (for language S) and ψ (for language T). [sent-53, score-0.192]
</p><p>30 1 summarizes the generative story, while figure 1 shows the plate model. [sent-55, score-0.036]
</p><p>31 1: GENERATIVE STORY FOR BILDA()  for each document pair dj  do fodr ea? [sent-57, score-0.044]
</p><p>32 chs a m w op rlde zpw SojT is∼t ioMn iu ∈lt(d θφψj)TS,z ji) Figure 1: The standard bilingual LDA model  Having one common θ for both of the related documents implies parallelism between the texts. [sent-58, score-0.105]
</p><p>33 This observation does not completely hold for comparable corpora with topically aligned texts. [sent-59, score-0.171]
</p><p>34 To train the model we use Gibbs sampling, similar to the sampling method for monolingual LDA, with parameters α and β set to 50/K and 0. [sent-60, score-0.081]
</p><p>35 After the training we end up with a set of φ and word-topic probability distributions that are used for the calculations of the word associations. [sent-62, score-0.198]
</p><p>36 The formula for a set of ψ word-topic probability distributions for the target side of a corpus is computed in an analogical manner. [sent-64, score-0.305]
</p><p>37 2 Main Framework Once we derive a shared set of topics along with language-specific distributions of words over topics, it is possible to use them for the computation of the similarity between words in different languages. [sent-66, score-0.529]
</p><p>38 1 KL Method The similarity between a source word w1 and a target word w2 is measured by the extent to which they share the same topics, i. [sent-69, score-0.386]
</p><p>39 , by the extent that their conditional topic distributions are similar. [sent-71, score-0.501]
</p><p>40 One way of expressing similarity is the Kullback-Leibler (KL) divergence, already used in a monolingual setting in (Steyvers and Griffiths, 2007). [sent-72, score-0.154]
</p><p>41 The similarity between two words is based on the similarity between χ(1) and χ(2), the similarity of conditional topic distributions for words w1 and w2, where χ(1) = P(Z|w1)1 and χ(2) = P(Z|w2). [sent-73, score-0.84]
</p><p>42 If we apply Bayes’ rule, we  get P(Z|w) =  P(wP|Z()wP)(Z),  1P(Z|w1 ) refers P(zj |w1)  to a set  where P(Z) and P(w)  of all conditional topic distributions  481 are prior distributions for topics and words respectively. [sent-75, score-0.917]
</p><p>43 P(Z) is a uniform distribution for the BiLDA model, whereas this assumption clearly does not hold for topic models with a non-uniform topic prior. [sent-76, score-0.725]
</p><p>44 If the assumption eofn uniformity =for P P(Z) holds, we can write:  P(zj|wi) ∝PN(wori|mzφj)=Noφrj,miφ for an English word  wi,  (2)  and:  P(zj|wi) ∝PN(worim|zψj)=Noψrj,miψ  (3)  for a French word wPi, where Normφ denotes the normalization factor P(wi|zj), i. [sent-78, score-0.18]
</p><p>45 , the sum of all probabilities φ (oPr probabilities ψ for Normψ)  PjK=1  for the currently obserPved word wi. [sent-80, score-0.04]
</p><p>46 We can then calculate the KL divergence as follows:  KL(χ(1),χ(2) ∝jX=K1Noφrj,m1φlogψφjj, 21//NNoorrmmψφ (4) 3. [sent-81, score-0.036]
</p><p>47 2 Cue Method An alternative, more straightforward approach (called the Cue method) tries to express similarity between two words emphasizing the associative relation between two words in a more natural way. [sent-83, score-0.113]
</p><p>48 , the probability that a target word w2 will|w w be generated as a response to a cue source word w1. [sent-86, score-0.357]
</p><p>49 For the BiLDA model we can write: XK  P(w2|w1) =  XP(w2|zj)P(zj|w1) Xj=1 XK  =jX=1ψj,2Noφjr,m1φ φ  (5)  This conditioning automatically compromises be-  tween word frequency and semantic relatedness (Griffiths et al. [sent-87, score-0.087]
</p><p>50 , 2007), since higher frequency words tend to have higher probabilities across all topics, but the distribution over topics P(zj |w1) ensures that semantically related topics domina|twe the sum. [sent-88, score-0.602]
</p><p>51 3  TI Method  The last approach borrows an idea from information retrieval and constructs word vectors over a shared latent topic space. [sent-91, score-0.595]
</p><p>52 Values within vectors are the TF-ITF (term frequency - inverse topic frequency) scores which are calculated in a completely analogical manner as the TF-IDF scores for the original word-document space (Manning and Sch u¨tze,  nk(w,Si)  1999). [sent-92, score-0.744]
</p><p>53 If we are given a source word wi, denotes the number of times the word wi is associated with a source topic zk. [sent-93, score-0.842]
</p><p>54 Term frequency (TF) of the source word wi for the source topic zk is given as:  TFi,k=wjX∈nW(kSw,Sni)k(w,Sj)  (6)  Inverse topical frequency (ITF) measures the gen-  eral importance of the source word wi across all source topics. [sent-94, score-1.517]
</p><p>55 The inverse topical frequency for the source word wi is calculated as2:  ITFi= log1 + |k :K n(kw,Si)> 0|  (7)  The final TF-ITF score for the source word wi and the topic zk is given by TF−ITFi,k = TFi,k ·ITFi. [sent-96, score-1.382]
</p><p>56 We calculateis thgeiv TenFb-IyTTFF scores Ffor target wor·IdTs associated with target topics in an analogical manner. [sent-97, score-0.501]
</p><p>57 Source and target words share the same Kdimensional topical space, where K-dimensional vectors consisting of the TF-ITF scores are built for all words. [sent-98, score-0.301]
</p><p>58 The standard cosine similarity metric is then used to find the most similar word vectors from the target vocabulary for a source word vector. [sent-99, score-0.52]
</p><p>59 482  cos(w1,w2) =qPkK=1P(SkKk1=)21·Sqk1·P Tk2kK=1(Tk2)2 (8) 4  Results and Discussion  As our training corpus, we use the English-Italian Wikipedia corpus of 18, 898 document pairs, where each aligned pair discusses the same subject. [sent-102, score-0.081]
</p><p>60 Our Italian vocabulary consists of 7, 160 nouns, while our English vocabulary contains 9, 166 nouns. [sent-104, score-0.146]
</p><p>61 As our baseline system, we use the cosine similarity between Italian word vectors and English word vectors with TF-IDF scores in the original word-  document space (Cos), with aligned documents. [sent-107, score-0.449]
</p><p>62 Table 1 shows the Precision@ 1 scores (the percentage of words where the first word from the list of translations is the correct one) for all three approaches (KL, Cue and TI), for different number of topics K. [sent-108, score-0.465]
</p><p>63 Although KL is designed specifically to measure the similarity of two distributions, its results are significantly below those ofthe Cue and TI, whose performances are comparable. [sent-109, score-0.113]
</p><p>64 Whereas the latter two methods yield the highest results around the 2, 000 topics mark, the performance of KL increases linearly with the number of topics. [sent-110, score-0.297]
</p><p>65 We have also detected that we are able to boost overall scores if we combine two methods. [sent-112, score-0.038]
</p><p>66 We have opted for the two best methods (TI+Cue), where overall score is calculated by Score = λ ·ScoreCue+ oSvceorraellT sIc. [sent-113, score-0.038]
</p><p>67 o3 eW ies caallscou provide tShceo rreesu =ltsλ ·Sobctaoirneed by linearly combining (with equal weights) the cosine similarity between TF-ITFvectors with that between TF-IDF vector (TI+Cos). [sent-114, score-0.194]
</p><p>68 For  a source word w, rankw denotes the rank of its correct translation within the retrieved list of potential translations. [sent-116, score-0.336]
</p><p>69 503 1)  MRR =|V1 |Xran1kw  (9)  where V denotes the set of words used for evaluation. [sent-118, score-0.064]
</p><p>70 We kept only the top 20 candidates from the  ranked list. [sent-119, score-0.049]
</p><p>71 Table 2 shows the MRR scores for the same set of experiments. [sent-120, score-0.038]
</p><p>72 5890) Topic models have the ability to build clusters of words which might not always co-occur together in the same textual units and therefore add extra information of potential relatedness. [sent-122, score-0.106]
</p><p>73 Although we have presented results for a document-aligned corpus, the framework is completely generic and applicable to other topically related corpora. [sent-123, score-0.094]
</p><p>74 Again, the KL method has the weakest perfor-  mance among the three methods based on the wordtopic distributions, while the other two methods seem very useful when combined together or when combined with the similarity measure used in the original word-document space. [sent-124, score-0.195]
</p><p>75 , the Italian word raggio is correctly translated as ray, but Google Translate returns radius as the first translation candidate). [sent-127, score-0.113]
</p><p>76 All proposed methods retrieve lists of semantically related words, where synonymy is not the only semantic relation observed. [sent-128, score-0.082]
</p><p>77 Such lists provide comprehensible and useful contextual information in the target language for the source word, even when the correct translation candidate is missing, as might be seen in table 3. [sent-129, score-0.264]
</p><p>78 (1) romanzo(2) paesaggio(3) cavallo  (novel)(landscape)(horse)  the correct translation is not found (column 1), lies hidden lower in the list (2), and is retrieved as the first candidate (3); K=2000; TI+Cue. [sent-130, score-0.118]
</p><p>79 5 Conclusion We have presented a generic, language-independent framework for mining translations of words from latent topic models. [sent-131, score-0.583]
</p><p>80 We have proven that topical knowledge is useful and improves the quality of word translations. [sent-132, score-0.132]
</p><p>81 The quality of translations depends only on the quality of a topic model and its ability to find latent relations between words. [sent-133, score-0.583]
</p><p>82 Our next steps involve experiments with other topic models and other corpora, and combining this unsuper-  vised approach with other tools for lexicon extraction and synonymy detection from unrelated and comparable corpora. [sent-134, score-0.55]
</p><p>83 Crosslanguage linking of news stories on the web using interlingual topic modelling. [sent-152, score-0.343]
</p><p>84 A geometric view on bilingual lexicon extraction from comparable corpora. [sent-161, score-0.227]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('topic', 0.343), ('topics', 0.258), ('zj', 0.249), ('bilda', 0.245), ('zk', 0.198), ('wi', 0.179), ('kl', 0.162), ('distributions', 0.158), ('mrr', 0.148), ('lda', 0.144), ('smet', 0.144), ('cue', 0.131), ('translations', 0.129), ('cos', 0.124), ('similarity', 0.113), ('latent', 0.111), ('bilingual', 0.105), ('ws', 0.103), ('leuven', 0.099), ('topical', 0.092), ('ti', 0.09), ('analogical', 0.089), ('mimno', 0.089), ('source', 0.088), ('cueti', 0.082), ('kdimensional', 0.082), ('kklcuetiti', 0.082), ('ula', 0.082), ('wordtopic', 0.082), ('wikipedia', 0.08), ('comparable', 0.077), ('translation', 0.073), ('vocabulary', 0.073), ('potential', 0.071), ('italian', 0.07), ('steyvers', 0.067), ('wim', 0.066), ('gaussier', 0.066), ('vectors', 0.066), ('denotes', 0.064), ('cognates', 0.062), ('topically', 0.059), ('belgium', 0.059), ('target', 0.058), ('griffiths', 0.058), ('moens', 0.057), ('diab', 0.054), ('norm', 0.054), ('inverse', 0.05), ('ni', 0.05), ('nk', 0.049), ('candidates', 0.049), ('jx', 0.048), ('share', 0.047), ('wp', 0.047), ('frequency', 0.047), ('ivan', 0.046), ('lexicon', 0.045), ('dirichlet', 0.045), ('candidate', 0.045), ('synonymy', 0.045), ('document', 0.044), ('xk', 0.043), ('cosine', 0.042), ('monolingual', 0.041), ('pn', 0.04), ('unrelated', 0.04), ('word', 0.04), ('sampling', 0.04), ('allocation', 0.04), ('linearly', 0.039), ('tf', 0.039), ('distribution', 0.039), ('ew', 0.038), ('blei', 0.038), ('scores', 0.038), ('calculated', 0.038), ('discusses', 0.037), ('retrieve', 0.037), ('priors', 0.037), ('generative', 0.036), ('matveeva', 0.036), ('landscape', 0.036), ('irina', 0.036), ('ffor', 0.036), ('conjugation', 0.036), ('polylingual', 0.036), ('amass', 0.036), ('calc', 0.036), ('celestijnenlaan', 0.036), ('fodr', 0.036), ('oftimes', 0.036), ('quest', 0.036), ('uniformity', 0.036), ('xiaochuan', 0.036), ('divergence', 0.036), ('sch', 0.035), ('idea', 0.035), ('completely', 0.035), ('extra', 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="161-tfidf-1" href="./acl-2011-Identifying_Word_Translations_from_Comparable_Corpora_Using_Latent_Topic_Models.html">161 acl-2011-Identifying Word Translations from Comparable Corpora Using Latent Topic Models</a></p>
<p>Author: Ivan Vulic ; Wim De Smet ; Marie-Francine Moens</p><p>Abstract: A topic model outputs a set of multinomial distributions over words for each topic. In this paper, we investigate the value of bilingual topic models, i.e., a bilingual Latent Dirichlet Allocation model for finding translations of terms in comparable corpora without using any linguistic resources. Experiments on a document-aligned English-Italian Wikipedia corpus confirm that the developed methods which only use knowledge from word-topic distributions outperform methods based on similarity measures in the original word-document space. The best results, obtained by combining knowledge from wordtopic distributions with similarity measures in the original space, are also reported.</p><p>2 0.30599836 <a title="161-tfidf-2" href="./acl-2011-Automatic_Labelling_of_Topic_Models.html">52 acl-2011-Automatic Labelling of Topic Models</a></p>
<p>Author: Jey Han Lau ; Karl Grieser ; David Newman ; Timothy Baldwin</p><p>Abstract: We propose a method for automatically labelling topics learned via LDA topic models. We generate our label candidate set from the top-ranking topic terms, titles of Wikipedia articles containing the top-ranking topic terms, and sub-phrases extracted from the Wikipedia article titles. We rank the label candidates using a combination of association measures and lexical features, optionally fed into a supervised ranking model. Our method is shown to perform strongly over four independent sets of topics, significantly better than a benchmark method.</p><p>3 0.26239508 <a title="161-tfidf-3" href="./acl-2011-Entity_Set_Expansion_using_Topic_information.html">117 acl-2011-Entity Set Expansion using Topic information</a></p>
<p>Author: Kugatsu Sadamitsu ; Kuniko Saito ; Kenji Imamura ; Genichiro Kikui</p><p>Abstract: This paper proposes three modules based on latent topics of documents for alleviating “semantic drift” in bootstrapping entity set expansion. These new modules are added to a discriminative bootstrapping algorithm to realize topic feature generation, negative example selection and entity candidate pruning. In this study, we model latent topics with LDA (Latent Dirichlet Allocation) in an unsupervised way. Experiments show that the accuracy of the extracted entities is improved by 6.7 to 28.2% depending on the domain.</p><p>4 0.25045097 <a title="161-tfidf-4" href="./acl-2011-A_Latent_Topic_Extracting_Method_based_on_Events_in_a_Document_and_its_Application.html">18 acl-2011-A Latent Topic Extracting Method based on Events in a Document and its Application</a></p>
<p>Author: Risa Kitajima ; Ichiro Kobayashi</p><p>Abstract: Recently, several latent topic analysis methods such as LSI, pLSI, and LDA have been widely used for text analysis. However, those methods basically assign topics to words, but do not account for the events in a document. With this background, in this paper, we propose a latent topic extracting method which assigns topics to events. We also show that our proposed method is useful to generate a document summary based on a latent topic.</p><p>5 0.24163929 <a title="161-tfidf-5" href="./acl-2011-Interactive_Topic_Modeling.html">178 acl-2011-Interactive Topic Modeling</a></p>
<p>Author: Yuening Hu ; Jordan Boyd-Graber ; Brianna Satinoff</p><p>Abstract: Topic models have been used extensively as a tool for corpus exploration, and a cottage industry has developed to tweak topic models to better encode human intuitions or to better model data. However, creating such extensions requires expertise in machine learning unavailable to potential end-users of topic modeling software. In this work, we develop a framework for allowing users to iteratively refine the topics discovered by models such as latent Dirichlet allocation (LDA) by adding constraints that enforce that sets of words must appear together in the same topic. We incorporate these constraints interactively by selectively removing elements in the state of a Markov Chain used for inference; we investigate a variety of methods for incorporating this information and demonstrate that these interactively added constraints improve topic usefulness for simulated and actual user sessions.</p><p>6 0.21508725 <a title="161-tfidf-6" href="./acl-2011-Structural_Topic_Model_for_Latent_Topical_Structure_Analysis.html">287 acl-2011-Structural Topic Model for Latent Topical Structure Analysis</a></p>
<p>7 0.21363746 <a title="161-tfidf-7" href="./acl-2011-Discovery_of_Topically_Coherent_Sentences_for_Extractive_Summarization.html">98 acl-2011-Discovery of Topically Coherent Sentences for Extractive Summarization</a></p>
<p>8 0.19972101 <a title="161-tfidf-8" href="./acl-2011-A_Hierarchical_Model_of_Web_Summaries.html">14 acl-2011-A Hierarchical Model of Web Summaries</a></p>
<p>9 0.19595315 <a title="161-tfidf-9" href="./acl-2011-Rare_Word_Translation_Extraction_from_Aligned_Comparable_Documents.html">259 acl-2011-Rare Word Translation Extraction from Aligned Comparable Documents</a></p>
<p>10 0.15793854 <a title="161-tfidf-10" href="./acl-2011-Improving_Question_Recommendation_by_Exploiting_Information_Need.html">169 acl-2011-Improving Question Recommendation by Exploiting Information Need</a></p>
<p>11 0.15239531 <a title="161-tfidf-11" href="./acl-2011-Clustering_Comparable_Corpora_For_Bilingual_Lexicon_Extraction.html">70 acl-2011-Clustering Comparable Corpora For Bilingual Lexicon Extraction</a></p>
<p>12 0.14882605 <a title="161-tfidf-12" href="./acl-2011-Learning_Word_Vectors_for_Sentiment_Analysis.html">204 acl-2011-Learning Word Vectors for Sentiment Analysis</a></p>
<p>13 0.14397131 <a title="161-tfidf-13" href="./acl-2011-Effective_Measures_of_Domain_Similarity_for_Parsing.html">109 acl-2011-Effective Measures of Domain Similarity for Parsing</a></p>
<p>14 0.1387914 <a title="161-tfidf-14" href="./acl-2011-Probabilistic_Document_Modeling_for_Syntax_Removal_in_Text_Summarization.html">251 acl-2011-Probabilistic Document Modeling for Syntax Removal in Text Summarization</a></p>
<p>15 0.12317549 <a title="161-tfidf-15" href="./acl-2011-Automatically_Extracting_Polarity-Bearing_Topics_for_Cross-Domain_Sentiment_Classification.html">54 acl-2011-Automatically Extracting Polarity-Bearing Topics for Cross-Domain Sentiment Classification</a></p>
<p>16 0.12025507 <a title="161-tfidf-16" href="./acl-2011-Topical_Keyphrase_Extraction_from_Twitter.html">305 acl-2011-Topical Keyphrase Extraction from Twitter</a></p>
<p>17 0.1164491 <a title="161-tfidf-17" href="./acl-2011-A_Mobile_Touchable_Application_for_Online_Topic_Graph_Extraction_and_Exploration_of_Web_Content.html">19 acl-2011-A Mobile Touchable Application for Online Topic Graph Extraction and Exploration of Web Content</a></p>
<p>18 0.10923114 <a title="161-tfidf-18" href="./acl-2011-Crowdsourcing_Translation%3A_Professional_Quality_from_Non-Professionals.html">90 acl-2011-Crowdsourcing Translation: Professional Quality from Non-Professionals</a></p>
<p>19 0.10470343 <a title="161-tfidf-19" href="./acl-2011-Domain_Adaptation_by_Constraining_Inter-Domain_Variability_of_Latent_Feature_Representation.html">103 acl-2011-Domain Adaptation by Constraining Inter-Domain Variability of Latent Feature Representation</a></p>
<p>20 0.10347502 <a title="161-tfidf-20" href="./acl-2011-Domain_Adaptation_for_Machine_Translation_by_Mining_Unseen_Words.html">104 acl-2011-Domain Adaptation for Machine Translation by Mining Unseen Words</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.273), (1, 0.082), (2, -0.016), (3, 0.228), (4, 0.003), (5, -0.138), (6, -0.094), (7, 0.287), (8, -0.013), (9, 0.076), (10, -0.089), (11, 0.015), (12, 0.178), (13, -0.069), (14, 0.285), (15, 0.029), (16, 0.005), (17, -0.081), (18, -0.031), (19, -0.058), (20, 0.014), (21, 0.043), (22, -0.024), (23, -0.019), (24, -0.011), (25, 0.022), (26, -0.058), (27, 0.067), (28, -0.062), (29, -0.044), (30, 0.035), (31, -0.06), (32, 0.016), (33, 0.013), (34, -0.033), (35, 0.028), (36, 0.035), (37, 0.006), (38, 0.027), (39, -0.043), (40, -0.028), (41, 0.066), (42, 0.067), (43, -0.008), (44, -0.015), (45, 0.018), (46, -0.005), (47, -0.029), (48, 0.042), (49, -0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97300977 <a title="161-lsi-1" href="./acl-2011-Identifying_Word_Translations_from_Comparable_Corpora_Using_Latent_Topic_Models.html">161 acl-2011-Identifying Word Translations from Comparable Corpora Using Latent Topic Models</a></p>
<p>Author: Ivan Vulic ; Wim De Smet ; Marie-Francine Moens</p><p>Abstract: A topic model outputs a set of multinomial distributions over words for each topic. In this paper, we investigate the value of bilingual topic models, i.e., a bilingual Latent Dirichlet Allocation model for finding translations of terms in comparable corpora without using any linguistic resources. Experiments on a document-aligned English-Italian Wikipedia corpus confirm that the developed methods which only use knowledge from word-topic distributions outperform methods based on similarity measures in the original word-document space. The best results, obtained by combining knowledge from wordtopic distributions with similarity measures in the original space, are also reported.</p><p>2 0.88820976 <a title="161-lsi-2" href="./acl-2011-Automatic_Labelling_of_Topic_Models.html">52 acl-2011-Automatic Labelling of Topic Models</a></p>
<p>Author: Jey Han Lau ; Karl Grieser ; David Newman ; Timothy Baldwin</p><p>Abstract: We propose a method for automatically labelling topics learned via LDA topic models. We generate our label candidate set from the top-ranking topic terms, titles of Wikipedia articles containing the top-ranking topic terms, and sub-phrases extracted from the Wikipedia article titles. We rank the label candidates using a combination of association measures and lexical features, optionally fed into a supervised ranking model. Our method is shown to perform strongly over four independent sets of topics, significantly better than a benchmark method.</p><p>3 0.87844318 <a title="161-lsi-3" href="./acl-2011-Interactive_Topic_Modeling.html">178 acl-2011-Interactive Topic Modeling</a></p>
<p>Author: Yuening Hu ; Jordan Boyd-Graber ; Brianna Satinoff</p><p>Abstract: Topic models have been used extensively as a tool for corpus exploration, and a cottage industry has developed to tweak topic models to better encode human intuitions or to better model data. However, creating such extensions requires expertise in machine learning unavailable to potential end-users of topic modeling software. In this work, we develop a framework for allowing users to iteratively refine the topics discovered by models such as latent Dirichlet allocation (LDA) by adding constraints that enforce that sets of words must appear together in the same topic. We incorporate these constraints interactively by selectively removing elements in the state of a Markov Chain used for inference; we investigate a variety of methods for incorporating this information and demonstrate that these interactively added constraints improve topic usefulness for simulated and actual user sessions.</p><p>4 0.86645091 <a title="161-lsi-4" href="./acl-2011-Structural_Topic_Model_for_Latent_Topical_Structure_Analysis.html">287 acl-2011-Structural Topic Model for Latent Topical Structure Analysis</a></p>
<p>Author: Hongning Wang ; Duo Zhang ; ChengXiang Zhai</p><p>Abstract: Topic models have been successfully applied to many document analysis tasks to discover topics embedded in text. However, existing topic models generally cannot capture the latent topical structures in documents. Since languages are intrinsically cohesive and coherent, modeling and discovering latent topical transition structures within documents would be beneficial for many text analysis tasks. In this work, we propose a new topic model, Structural Topic Model, which simultaneously discovers topics and reveals the latent topical structures in text through explicitly modeling topical transitions with a latent first-order Markov chain. Experiment results show that the proposed Structural Topic Model can effectively discover topical structures in text, and the identified structures significantly improve the performance of tasks such as sentence annotation and sentence ordering. ,</p><p>5 0.82785732 <a title="161-lsi-5" href="./acl-2011-A_Hierarchical_Model_of_Web_Summaries.html">14 acl-2011-A Hierarchical Model of Web Summaries</a></p>
<p>Author: Yves Petinot ; Kathleen McKeown ; Kapil Thadani</p><p>Abstract: We investigate the relevance of hierarchical topic models to represent the content of Web gists. We focus our attention on DMOZ, a popular Web directory, and propose two algorithms to infer such a model from its manually-curated hierarchy of categories. Our first approach, based on information-theoretic grounds, uses an algorithm similar to recursive feature selection. Our second approach is fully Bayesian and derived from the more general model, hierarchical LDA. We evaluate the performance of both models against a flat 1-gram baseline and show improvements in terms of perplexity over held-out data.</p><p>6 0.81568468 <a title="161-lsi-6" href="./acl-2011-Entity_Set_Expansion_using_Topic_information.html">117 acl-2011-Entity Set Expansion using Topic information</a></p>
<p>7 0.78649586 <a title="161-lsi-7" href="./acl-2011-A_Latent_Topic_Extracting_Method_based_on_Events_in_a_Document_and_its_Application.html">18 acl-2011-A Latent Topic Extracting Method based on Events in a Document and its Application</a></p>
<p>8 0.73991668 <a title="161-lsi-8" href="./acl-2011-Topical_Keyphrase_Extraction_from_Twitter.html">305 acl-2011-Topical Keyphrase Extraction from Twitter</a></p>
<p>9 0.7392171 <a title="161-lsi-9" href="./acl-2011-Discovery_of_Topically_Coherent_Sentences_for_Extractive_Summarization.html">98 acl-2011-Discovery of Topically Coherent Sentences for Extractive Summarization</a></p>
<p>10 0.67751503 <a title="161-lsi-10" href="./acl-2011-Probabilistic_Document_Modeling_for_Syntax_Removal_in_Text_Summarization.html">251 acl-2011-Probabilistic Document Modeling for Syntax Removal in Text Summarization</a></p>
<p>11 0.61100328 <a title="161-lsi-11" href="./acl-2011-A_Mobile_Touchable_Application_for_Online_Topic_Graph_Extraction_and_Exploration_of_Web_Content.html">19 acl-2011-A Mobile Touchable Application for Online Topic Graph Extraction and Exploration of Web Content</a></p>
<p>12 0.58574957 <a title="161-lsi-12" href="./acl-2011-Effective_Measures_of_Domain_Similarity_for_Parsing.html">109 acl-2011-Effective Measures of Domain Similarity for Parsing</a></p>
<p>13 0.56933939 <a title="161-lsi-13" href="./acl-2011-From_Bilingual_Dictionaries_to_Interlingual_Document_Representations.html">139 acl-2011-From Bilingual Dictionaries to Interlingual Document Representations</a></p>
<p>14 0.56035054 <a title="161-lsi-14" href="./acl-2011-Rare_Word_Translation_Extraction_from_Aligned_Comparable_Documents.html">259 acl-2011-Rare Word Translation Extraction from Aligned Comparable Documents</a></p>
<p>15 0.53760105 <a title="161-lsi-15" href="./acl-2011-Clustering_Comparable_Corpora_For_Bilingual_Lexicon_Extraction.html">70 acl-2011-Clustering Comparable Corpora For Bilingual Lexicon Extraction</a></p>
<p>16 0.51575994 <a title="161-lsi-16" href="./acl-2011-Simple_supervised_document_geolocation_with_geodesic_grids.html">285 acl-2011-Simple supervised document geolocation with geodesic grids</a></p>
<p>17 0.51111352 <a title="161-lsi-17" href="./acl-2011-Automatically_Extracting_Polarity-Bearing_Topics_for_Cross-Domain_Sentiment_Classification.html">54 acl-2011-Automatically Extracting Polarity-Bearing Topics for Cross-Domain Sentiment Classification</a></p>
<p>18 0.4686482 <a title="161-lsi-18" href="./acl-2011-A_Large_Scale_Distributed_Syntactic%2C_Semantic_and_Lexical_Language_Model_for_Machine_Translation.html">17 acl-2011-A Large Scale Distributed Syntactic, Semantic and Lexical Language Model for Machine Translation</a></p>
<p>19 0.45344856 <a title="161-lsi-19" href="./acl-2011-Contrasting_Opposing_Views_of_News_Articles_on_Contentious_Issues.html">84 acl-2011-Contrasting Opposing Views of News Articles on Contentious Issues</a></p>
<p>20 0.43664682 <a title="161-lsi-20" href="./acl-2011-Improving_Question_Recommendation_by_Exploiting_Information_Need.html">169 acl-2011-Improving Question Recommendation by Exploiting Information Need</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.024), (17, 0.084), (26, 0.044), (37, 0.113), (39, 0.071), (41, 0.051), (53, 0.01), (55, 0.027), (59, 0.038), (72, 0.031), (91, 0.035), (96, 0.152), (98, 0.258)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.92119515 <a title="161-lda-1" href="./acl-2011-A_Probabilistic_Modeling_Framework_for_Lexical_Entailment.html">22 acl-2011-A Probabilistic Modeling Framework for Lexical Entailment</a></p>
<p>Author: Eyal Shnarch ; Jacob Goldberger ; Ido Dagan</p><p>Abstract: Recognizing entailment at the lexical level is an important and commonly-addressed component in textual inference. Yet, this task has been mostly approached by simplified heuristic methods. This paper proposes an initial probabilistic modeling framework for lexical entailment, with suitable EM-based parameter estimation. Our model considers prominent entailment factors, including differences in lexical-resources reliability and the impacts of transitivity and multiple evidence. Evaluations show that the proposed model outperforms most prior systems while pointing at required future improvements. 1 Introduction and Background Textual Entailment was proposed as a generic paradigm for applied semantic inference (Dagan et al., 2006). This task requires deciding whether a tex- tual statement (termed the hypothesis-H) can be inferred (entailed) from another text (termed the textT). Since it was first introduced, the six rounds of the Recognizing Textual Entailment (RTE) challenges1 , currently organized under NIST, have become a standard benchmark for entailment systems. These systems tackle their complex task at various levels of inference, including logical representation (Tatu and Moldovan, 2007; MacCartney and Manning, 2007), semantic analysis (Burchardt et al., 2007) and syntactic parsing (Bar-Haim et al., 2008; Wang et al., 2009). Inference at these levels usually 1http://www.nist.gov/tac/2010/RTE/index.html 558 requires substantial processing and resources (e.g. parsing) aiming at high performance. Nevertheless, simple entailment methods, performing at the lexical level, provide strong baselines which most systems did not outperform (Mirkin et al., 2009; Majumdar and Bhattacharyya, 2010). Within complex systems, lexical entailment modeling is an important component. Finally, there are cases in which a full system cannot be used (e.g. lacking a parser for a targeted language) and one must resort to the simpler lexical approach. While lexical entailment methods are widely used, most of them apply ad hoc heuristics which do not rely on a principled underlying framework. Typically, such methods quantify the degree of lexical coverage of the hypothesis terms by the text’s terms. Coverage is determined either by a direct match of identical terms in T and H or by utilizing lexical semantic resources, such as WordNet (Fellbaum, 1998), that capture lexical entailment relations (denoted here as entailment rules). Common heuristics for quantifying the degree of coverage are setting a threshold on the percentage coverage of H’s terms (Majumdar and Bhattacharyya, 2010), counting absolute number of uncovered terms (Clark and Harrison, 2010), or applying an Information Retrievalstyle vector space similarity score (MacKinlay and Baldwin, 2009). Other works (Corley and Mihalcea, 2005; Zanzotto and Moschitti, 2006) have applied a heuristic formula to estimate the similarity between text fragments based on a similarity function between their terms. These heuristics do not capture several important aspects of entailment, such as varying reliability of Proceedings ofP thoer t4l9atnhd A, Onrnuegaoln M,e Jeuntineg 19 o-f2 t4h,e 2 A0s1s1o.c?i ac t2io0n11 fo Ar Cssoocmiaptuiotanti foonra Clo Lminpguutiast i ocns:aslh Loirntpgaupisetrics , pages 558–563, entailment resources and the impact of rule chaining and multiple evidence on entailment likelihood. An additional observation from these and other systems is that their performance improves only moderately when utilizing lexical resources2. We believe that the textual entailment field would benefit from more principled models for various entailment phenomena. Inspired by the earlier steps in the evolution of Statistical Machine Translation methods (such as the initial IBM models (Brown et al., 1993)), we formulate a concrete generative probabilistic modeling framework that captures the basic aspects of lexical entailment. Parameter estimation is addressed by an EM-based approach, which enables estimating the hidden lexical-level entailment parameters from entailment annotations which are available only at the sentence-level. While heuristic methods are limited in their ability to wisely integrate indications for entailment, probabilistic methods have the advantage of being extendable and enabling the utilization of wellfounded probabilistic methods such as the EM algorithm. We compared the performance of several model variations to previously published results on RTE data sets, as well as to our own implementation of typical lexical baselines. Results show that both the probabilistic model and our percentagecoverage baseline perform favorably relative to prior art. These results support the viability of the probabilistic framework while pointing at certain modeling aspects that need to be improved. 2 Probabilistic Model Under the lexical entailment scope, our modeling goal is obtaining a probabilistic score for the likelihood that all H’s terms are entailed by T. To that end, we model prominent aspects of lexical entailment, which were mostly neglected by previous lexical methods: (1) distinguishing different reliability levels of lexical resources; (2) allowing transitive chains of rule applications and considering their length when estimating their validity; and (3) considering multiple entailments when entailing a term. 2See ablation tests reports in http://aclweb.org/aclwiki/ index.php?title=RTE Knowledge Resources#Ablation Tests 559 Figure 1: The generative process of entailing terms of a hypothesis from a text. Edges represent entailment rules. There are 3 evidences for the entailment of hi :a rule from Resource1 , another one from Resource3 both suggesting that tj entails it, and a chain from t1through an intermediate term t0. 2.1 Model Description For T to entail H it is usually a necessary, but not sufficient, that every term h ∈ H would be entsauiflefidci by ,at t hleatast e one t teerrmm mt h ∈ ∈T (Glickman eet al., 2006). Figure s1t odneescr tiebrmes tth ∈e process komf entailing hypothesis terms. The trivial case is when identical terms, possibly at the stem or lemma level, appear in T and H (a direct match as tn and hm in Figure 1). Alternatively, we can establish entailment based on knowledge of entailing lexical-semantic relations, such as synonyms, hypernyms and morphological derivations, available in lexical resources (e.g the rule inference → reasoning from WordNet). (We.eg d theneo rutel by R(r) cthee → resource nwgh ficroh provided teht)e. rule r. Since entailment is a transitive relation, rules may compose transitive chains that connect a term t ∈ T ctoo a pteosrme rha ∈ Hive through hinatte cromnendeicatte a tteerrmms. t ∈Fo Tr instance, fr hom ∈ t hHe r thurleosu infer → inference armnds inference → reasoning we can dre →duc inef tehreen rcuele a infer → reasoning (were inference dise dthuec ein thteerm rueldeia intef trer →m as t0 in Figure 1). Multiple chains may connect t to h (as for tj and hi in Figure 1) or connect several terms in T to h (as t1 and tj are indicating the entailment of hi in Figure 1), thus providing multiple evidence for h’s entailment. It is reasonable to expect that if a term t indeed entails a term h, it is likely to find evidences for this relation in several resources. Taking a probabilistic perspective, we assume a parameter θR for each resource R, denoting its reliability, i.e. the prior probability that applying a rule from R corresponds to a valid entailment instance. Direct matches are considered as a special “resource”, called MATCH, for which θMATCH is expected to be close to 1. We now present our probabilistic model. For a text term t ∈ T to entail a hypothesis term h by a tcehxatin te c, mde tn ∈ote Td by etn →tcai h, thhyep application mof h every r ∈ c must be valid. N −→ote h ,t thhaet a pruplleic r i onn a cfh eaviner c rco ∈nne cc mtsu tswt ob ete vramlisd (its oleteft t-hhaatnd a- rsuildee ran ind aits c righthand-side, denoted lhs → rhs). The lhs of the first rhualned i-ns c eis, td ∈ oTte adn ldh sth →e r rhhss )o.f T Tthhee l lahsts r oufle t hine ifitr sist rhu ∈ iHn. c W ise t d ∈en Tote a nthde t event so fo a vhael ilda rtu rluel applicathio ∈n by l Whse →dren orhtes. t Sei envceen a-priori a d ru rluel r aips pvliacliadwith probability θR(r) , ancnde assuming independence of all r ∈ c, we obtain Eq. 1 to specify the probability rof ∈ ∈th ce, weveen otb tt i→cn Ehq. Next, pleetc C(h) ede pnroobtethe set of chains which− → suggest txhte, leentt Cail(mhe)n dt eonfo hte. The probability that T does not entail h at all (by any chain), specified in Eq. 2, is the probability that all these chains are not valid. Finally, the probability that T entails all of H, assuming independence of H’s terms, is the probability that every h ∈ H is entailed, as given ien p Eq. a3b. Nityot tihceat t ehvaet yth here ∈ c oHul ids be a term h which is not covered by any available rule chain. Under this formulation, we assume that each such h is covered by a single rule coming from a special “resource” called UNCOVERED (expecting θUNCOVERED to be relatively small). p(t −→c h) = Yp(lhs →r rhs) = Yr∈c p(T 9 h) = Y YθR(r)(1) Yr∈c [1 − p(t− →c h)] (2) c∈YC(h) p(T → H) = Y p(T → h) (3) hY∈H As can be seen, our model indeed distinguishes varying resource reliability, decreases entailment probability as rule chains grow and increases it when entailment of a term is supported by multiple chains. The above treatment of uncovered terms in H, as captured in Eq. 3, assumes that their entailment probability is independent of the rest of the hypothesis. However, when the number of covered hypothesis terms increases the probability that the remaining terms are actually entailed by T increases too 560 (even though we do not have supporting knowledge for their entailment). Thus, an alternative model is to group all uncovered terms together and estimate the overall probability of their joint entailment as a function of the lexical coverage of the hypothesis. We denote Hc as the subset of H’s terms which are covered by some rule chain and Huc as the remaining uncovered part. Eq. 3a then provides a refined entailment model for H, in which the second term specifies the probability that Huc is entailed given that Hc is validly entailed and the corresponding lengths: p(T→H) = [Yp(T→h)]·p(T→Huc hY∈Hc 2.2 | |Hc|,|H|) (3a) Parameter Estimation The difficulty in estimating the θR values is that these are term-level parameters while the RTEtraining entailment annotation is given for the sentence-level. Therefore, we use EM-based estimation for the hidden parameters (Dempster et al., 1977). In the E step we use the current θR values to compute all whcr (T, H) values for each training pair. whcr (T, H) stands for the posterior probability that application of the rule r in the chain c for h ∈ H tish valid, given nth oaft heieth reurl eT r e innta thiles c Hha or not ra hcc ∈ord Hing to the training annotation (see Eq. 4). Remember that a rule r provides an entailment relation between its left-hand-side (lhs) and its right-hand-side (rhs). Therefore Eq. 4 uses the notation lhs →r rhs to designate the application of the rule r (similar htos Eq. 1). wEhc:r(T,H)=   p (lTh9→sH−→ |rlhsrp−→ rh(Tsr→9|hTsH )9→p(lhHs−→ r) =hs)if(4T)9→H After applying Bayes’ rule we get a fraction with Eq. 3 in its denominator and θR(r) as the second term of the numerator. The first numerator term is defined as in Eq. 3 except that for the corresponding rule application we substitute θR(r) by 1(per the conditioning event). The probabilistic model defined by Eq. 1-3 is a loop-free directed acyclic graphical model (aka a Bayesian network). Hence the E-step probabilities can be efficiently calculated using the belief propagation algorithm (Pearl, 1988). The M step uses Eq. 5 to update the parameter set. For each resource R we average the whcr (T, H) val- ues for all its rule applications in the training, whose total number is denoted nR. M : θR=n1RTX,HhX∈Hc∈XC(h)r∈c|RX(r)=wRhcr(T,H) (5) For Eq. 3a we need to estimate also p(T→Huc | |Hc| ,|H|). 3Tah iws eis n ndeoende t directly avteia a amlsaoxi pm(Tu→m Hlikeli-| |hHoo|d, eHst|i)m.a Tthioins over tehe d training set, by calculating the proportion of entailing examples within the set of all examples of a given hypothesis length (|H|) aonfd a a given lneusm ofbe ar goifv ecnov heyrepdo hteersmiss (|Hc|). HA|)s |Hc| we tvaekne tnhuem nbuemrb oefr ocofv videerendtic taelr mtesrm (|sH in| )T. a Ands |HH (exact match) suinmcbee irn o afl imdeonstti caall cases itner Tms a nind H which have an exact match in T are indeed entailed. We also tried initializing the EM algorithm with these direct estimations but did not obtain performance improvements. 3 Evaluations and Results The 5th Recognizing Textual Entailment challenge (RTE-5) introduced a new search task (Bentivogli et al., 2009) which became the main task in RTE6 (Bentivogli et al., 2010). In this task participants should find all sentences that entail a given hypothesis in a given document cluster. This task’s data sets reflect a natural distribution of entailments in a corpus and demonstrate a more realistic scenario than the previous RTE challenges. In our system, sentences are tokenized and stripped of stop words and terms are lemmatized and tagged for part-of-speech. As lexical resources we use WordNet (WN) (Fellbaum, 1998), taking as entailment rules synonyms, derivations, hyponyms and meronyms of the first senses of T and H terms, and the CatVar (Categorial Variation) database (Habash and Dorr, 2003). We allow rule chains of length up to 4 in WordNet (WN4). We compare our model to two types of baselines: (1) RTE published results: the average of the best runs of all systems, the best and second best performing lexical systems and the best full system of each challenge; (2) our implementation of lexical 561 coverage model, tuning the percentage-of-coverage threshold for entailment on the training set. This model uses the same configuration as ourprobabilistic model. We also implemented an Information Re- trieval style baseline3 (both with and without lexical expansions), but given its poorer performance we omit its results here. Table 1 presents the results. We can see that both our implemented models (probabilistic and coverage) outperform all RTE lexical baselines on both data sets, apart from (Majumdar and Bhattacharyya, 2010) which incorporates additional lexical resources, a named entity recognizer and a co-reference system. On RTE-5, the probabilistic model is comparable in performance to the best full system, while the coverage model achieves considerably better results. We notice that our implemented models successfully utilize resources to increase performance, as opposed to typical smaller or less consistent improvements in prior works (see Section 1). ModelRTE-5F1%RTE-6 ERT2b avne sgdst.b floeu fsxl taic slyealxs tisyceysmastlemesyms tem4 3504 . 36.4531 4 34873. 0 .68254 evrcagon+ o CW raeN tsVo4a+urCcaetVr43479685. 25384 4534. 5817 Tabspticrlaoe1:+ Envo CW arlueN tasV4oi+urnCcaetsVularonRTE-5and4 R521 T. 80 E-6.RT4 s25 y. s9635t1ems (1)(MacKinlay and Baldwin, 2009), (2)(Clark and Harrison, 2010), (3)(Mirkin et al., 2009)(2 submitted runs), (4)(Majumdar and Bhattacharyya, 2010) and (5)(Jia et al., 2010). are: While the probabilistic and coverage models are comparable on RTE-6 (with non-significant advantage for the former), on RTE-5 the latter performs 3Utilizing Lucene search engine (http://lucene.apache.org) better, suggesting that the probabilistic model needs to be further improved. In particular, WN4 performs better than the single-step WN only on RTE-5, suggesting the need to improve the modeling of chain- ing. The fluctuations over the data sets and impacts of resources suggest the need for further investigation over additional data sets and resources. As for the coverage model, under our configuration it poses a bigger challenge for RTE systems than perviously reported baselines. It is thus proposed as an easy to implement baseline for future entailment research. 4 Conclusions and Future Work This paper presented, for the first time, a principled and relatively rich probabilistic model for lexical entailment, amenable for estimation of hidden lexicallevel parameters from standard sentence-level annotations. The positive results of the probabilistic model compared to prior art and its ability to exploit lexical resources indicate its future potential. Yet, further investigation is needed. For example, analyzing current model’s limitations, we observed that the multiplicative nature of eqs. 1and 3 (reflecting independence assumptions) is too restrictive, resembling a logical AND. Accordingly we plan to explore relaxing this strict conjunctive behavior through models such as noisy-AND (Pearl, 1988). We also intend to explore the contribution of our model, and particularly its estimated parameter values, within a complex system that integrates multiple levels of inference. Acknowledgments This work was partially supported by the NEGEV Consortium of the Israeli Ministry of Industry, Trade and Labor (www.negev-initiative.org), the PASCAL-2 Network of Excellence of the European Community FP7-ICT-2007-1-216886, the FIRBIsrael research project N. RBIN045PXH and by the Israel Science Foundation grant 1112/08. References Roy Bar-Haim, Jonathan Berant, Ido Dagan, Iddo Greental, Shachar Mirkin, Eyal Shnarch, and Idan Szpektor. 2008. Efficient semantic deduction and approximate matching over compact parse forests. In Proceedings of Text Analysis Conference (TAC). 562 Luisa Bentivogli, Ido Dagan, Hoa Trang Dang, Danilo Giampiccolo, and Bernardo Magnini. 2009. The fifth PASCAL recognizing textual entailment challenge. In Proceedings of Text Analysis Conference (TAC). Luisa Bentivogli, Peter Clark, Ido Dagan, Hoa Trang Dang, and Danilo Giampiccolo. 2010. The sixth PASCAL recognizing textual entailment challenge. In Proceedings of Text Analysis Conference (TAC). Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: parameter estimation. Computational Linguistics, 19(2):263–3 11, June. Aljoscha Burchardt, Nils Reiter, Stefan Thater, and Anette Frank. 2007. A semantic approach to textual entailment: System evaluation and task analysis. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing. Peter Clark and Phil Harrison. 2010. BLUE-Lite: a knowledge-based lexical entailment system for RTE6. In Proceedings of Text Analysis Conference (TAC). Courtney Corley and Rada Mihalcea. 2005. Measuring the semantic similarity of texts. In Proceedings of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment. Ido Dagan, Oren Glickman, and Bernardo Magnini. 2006. The PASCAL recognising textual entailment challenge. In Lecture Notes in Computer Science, volume 3944, pages 177–190. A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977. Maximum likelihood from incomplete data via the EM algorithm. Journal of the royal statistical society, se- ries [B], 39(1): 1–38. Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database (Language, Speech, and Communication). The MIT Press. Oren Glickman, Eyal Shnarch, and Ido Dagan. 2006. Lexical reference: a semantic matching subtask. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 172–179. Association for Computational Linguistics. Nizar Habash and Bonnie Dorr. 2003. A categorial variation database for english. In Proceedings of the North American Association for Computational Linguistics. Houping Jia, Xiaojiang Huang, Tengfei Ma, Xiaojun Wan, and Jianguo Xiao. 2010. PKUTM participation at TAC 2010 RTE and summarization track. In Proceedings of Text Analysis Conference (TAC). Bill MacCartney and Christopher D. Manning. 2007. Natural logic for textual inference. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing. Andrew MacKinlay and Timothy Baldwin. 2009. A baseline approach to the RTE5 search pilot. In Proceedings of Text Analysis Conference (TAC). Debarghya Majumdar and Pushpak Bhattacharyya. 2010. Lexical based text entailment system for main task of RTE6. In Proceedings of Text Analysis Conference (TAC). Mirkin, Roy Bar-Haim, Jonathan Berant, Ido Eyal Shnarch, Asher Stern, and Idan Szpektor. 2009. Addressing discourse and document structure in the RTE search task. In Proceedings of Text Analysis Conference (TAC). Judea Pearl. 1988. Probabilistic reasoning in intelligent systems: networks ofplausible inference. Morgan Kaufmann. Marta Tatu and Dan Moldovan. 2007. COGEX at RTE 3. In Proceedings of the ACL-PASCAL Workshop on Shachar Dagan, Textual Entailment and Paraphrasing. Rui Wang, Yi Zhang, and Guenter Neumann. 2009. A joint syntactic-semantic representation for recognizing textual relatedness. In Proceedings of Text Analysis Conference (TAC). Fabio Massimo Zanzotto and Alessandro Moschitti. 2006. Automatic learning of textual entailments with cross-pair similarities. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics. 563</p><p>2 0.86124521 <a title="161-lda-2" href="./acl-2011-Turn-Taking_Cues_in_a_Human_Tutoring_Corpus.html">312 acl-2011-Turn-Taking Cues in a Human Tutoring Corpus</a></p>
<p>Author: Heather Friedberg</p><p>Abstract: Most spoken dialogue systems are still lacking in their ability to accurately model the complex process that is human turntaking. This research analyzes a humanhuman tutoring corpus in order to identify prosodic turn-taking cues, with the hopes that they can be used by intelligent tutoring systems to predict student turn boundaries. Results show that while there was variation between subjects, three features were significant turn-yielding cues overall. In addition, a positive relationship between the number of cues present and the probability of a turn yield was demonstrated. 1</p><p>3 0.84855801 <a title="161-lda-3" href="./acl-2011-Shift-Reduce_CCG_Parsing.html">282 acl-2011-Shift-Reduce CCG Parsing</a></p>
<p>Author: Yue Zhang ; Stephen Clark</p><p>Abstract: CCGs are directly compatible with binarybranching bottom-up parsing algorithms, in particular CKY and shift-reduce algorithms. While the chart-based approach has been the dominant approach for CCG, the shift-reduce method has been little explored. In this paper, we develop a shift-reduce CCG parser using a discriminative model and beam search, and compare its strengths and weaknesses with the chart-based C&C; parser. We study different errors made by the two parsers, and show that the shift-reduce parser gives competitive accuracies compared to C&C.; Considering our use of a small beam, and given the high ambiguity levels in an automatically-extracted grammar and the amount of information in the CCG lexical categories which form the shift actions, this is a surprising result.</p><p>same-paper 4 0.78510201 <a title="161-lda-4" href="./acl-2011-Identifying_Word_Translations_from_Comparable_Corpora_Using_Latent_Topic_Models.html">161 acl-2011-Identifying Word Translations from Comparable Corpora Using Latent Topic Models</a></p>
<p>Author: Ivan Vulic ; Wim De Smet ; Marie-Francine Moens</p><p>Abstract: A topic model outputs a set of multinomial distributions over words for each topic. In this paper, we investigate the value of bilingual topic models, i.e., a bilingual Latent Dirichlet Allocation model for finding translations of terms in comparable corpora without using any linguistic resources. Experiments on a document-aligned English-Italian Wikipedia corpus confirm that the developed methods which only use knowledge from word-topic distributions outperform methods based on similarity measures in the original word-document space. The best results, obtained by combining knowledge from wordtopic distributions with similarity measures in the original space, are also reported.</p><p>5 0.77485979 <a title="161-lda-5" href="./acl-2011-Learning_to_Grade_Short_Answer_Questions_using_Semantic_Similarity_Measures_and_Dependency_Graph_Alignments.html">205 acl-2011-Learning to Grade Short Answer Questions using Semantic Similarity Measures and Dependency Graph Alignments</a></p>
<p>Author: Michael Mohler ; Razvan Bunescu ; Rada Mihalcea</p><p>Abstract: In this work we address the task of computerassisted assessment of short student answers. We combine several graph alignment features with lexical semantic similarity measures using machine learning techniques and show that the student answers can be more accurately graded than if the semantic measures were used in isolation. We also present a first attempt to align the dependency graphs of the student and the instructor answers in order to make use of a structural component in the automatic grading of student answers.</p><p>6 0.73091793 <a title="161-lda-6" href="./acl-2011-A_Comparison_of_Loopy_Belief_Propagation_and_Dual_Decomposition_for_Integrated_CCG_Supertagging_and_Parsing.html">5 acl-2011-A Comparison of Loopy Belief Propagation and Dual Decomposition for Integrated CCG Supertagging and Parsing</a></p>
<p>7 0.71300834 <a title="161-lda-7" href="./acl-2011-Using_Bilingual_Parallel_Corpora_for_Cross-Lingual_Textual_Entailment.html">327 acl-2011-Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment</a></p>
<p>8 0.71291959 <a title="161-lda-8" href="./acl-2011-Efficient_CCG_Parsing%3A_A%2A_versus_Adaptive_Supertagging.html">112 acl-2011-Efficient CCG Parsing: A* versus Adaptive Supertagging</a></p>
<p>9 0.67878729 <a title="161-lda-9" href="./acl-2011-Learning_to_Win_by_Reading_Manuals_in_a_Monte-Carlo_Framework.html">207 acl-2011-Learning to Win by Reading Manuals in a Monte-Carlo Framework</a></p>
<p>10 0.67365748 <a title="161-lda-10" href="./acl-2011-An_Affect-Enriched_Dialogue_Act_Classification_Model_for_Task-Oriented_Dialogue.html">33 acl-2011-An Affect-Enriched Dialogue Act Classification Model for Task-Oriented Dialogue</a></p>
<p>11 0.66975832 <a title="161-lda-11" href="./acl-2011-Exploring_Entity_Relations_for_Named_Entity_Disambiguation.html">128 acl-2011-Exploring Entity Relations for Named Entity Disambiguation</a></p>
<p>12 0.65832305 <a title="161-lda-12" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<p>13 0.65817529 <a title="161-lda-13" href="./acl-2011-Transition-based_Dependency_Parsing_with_Rich_Non-local_Features.html">309 acl-2011-Transition-based Dependency Parsing with Rich Non-local Features</a></p>
<p>14 0.65617353 <a title="161-lda-14" href="./acl-2011-Optimistic_Backtracking_-_A_Backtracking_Overlay_for_Deterministic_Incremental_Parsing.html">236 acl-2011-Optimistic Backtracking - A Backtracking Overlay for Deterministic Incremental Parsing</a></p>
<p>15 0.65448803 <a title="161-lda-15" href="./acl-2011-Optimal_and_Syntactically-Informed_Decoding_for_Monolingual_Phrase-Based_Alignment.html">235 acl-2011-Optimal and Syntactically-Informed Decoding for Monolingual Phrase-Based Alignment</a></p>
<p>16 0.65393066 <a title="161-lda-16" href="./acl-2011-Exploiting_Syntactico-Semantic_Structures_for_Relation_Extraction.html">126 acl-2011-Exploiting Syntactico-Semantic Structures for Relation Extraction</a></p>
<p>17 0.65229332 <a title="161-lda-17" href="./acl-2011-Learning_Hierarchical_Translation_Structure_with_Linguistic_Annotations.html">202 acl-2011-Learning Hierarchical Translation Structure with Linguistic Annotations</a></p>
<p>18 0.65174758 <a title="161-lda-18" href="./acl-2011-Fine-Grained_Class_Label_Markup_of_Search_Queries.html">137 acl-2011-Fine-Grained Class Label Markup of Search Queries</a></p>
<p>19 0.65146971 <a title="161-lda-19" href="./acl-2011-Parsing_the_Internal_Structure_of_Words%3A_A_New_Paradigm_for_Chinese_Word_Segmentation.html">241 acl-2011-Parsing the Internal Structure of Words: A New Paradigm for Chinese Word Segmentation</a></p>
<p>20 0.65060711 <a title="161-lda-20" href="./acl-2011-Semi-supervised_Relation_Extraction_with_Large-scale_Word_Clustering.html">277 acl-2011-Semi-supervised Relation Extraction with Large-scale Word Clustering</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
