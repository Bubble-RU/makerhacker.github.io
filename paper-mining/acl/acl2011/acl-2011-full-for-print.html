<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>342 acl-2011-full-for-print</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-342" href="#">acl2011-342</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>342 acl-2011-full-for-print</h1>
<br/><p>Source: <a title="acl-2011-342-pdf" href="http://aclweb.org/anthology//P/P11/P11-5005.pdf">pdf</a></p><p>Author: Kuzman Ganchev</p><p>Abstract: unkown-abstract</p><p>Reference: <a title="acl-2011-342-reference" href="../acl2011_reference/acl-2011-full-for-print_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Rich Prior Knowledge in Learning for Natural Language Processing Bibliography For a more up-to-date bibliography as well as additional information about these methods, point your browser to: http ://sideinfo . [sent-1, score-0.194]
</p><p>2 com/  1 Constraint-Driven Learning Constraint driven learning (CoDL) was first introduced in Chang et al. [sent-3, score-0.038]
</p><p>3 A further paper on the topic is in submission [Chang et al. [sent-6, score-0.038]
</p><p>4 2  Generalized Expectation  Generalized Expectation (GE) constraints were first introduced by Mann and McCallum [2007] 1 and were used to incorporate prior knowledge about the label distribution into semi-supervised classification. [sent-8, score-0.117]
</p><p>5 GE constraints have also been used to leverage “labeled features” in document classification [Druck et al. [sent-9, score-0.072]
</p><p>6 , 2009b, Bellare and McCallum, 2009] , and to incorporate linguistic prior knowledge into dependency grammar induction [Druck et al. [sent-11, score-0.254]
</p><p>7 [2008] , and has been applied to dependency grammar induction [Ganchev et al. [sent-16, score-0.209]
</p><p>8 , 2010] , part of speech induction [Gra c¸a et al. [sent-19, score-0.086]
</p><p>9 , 2009b] , and cross-lingual semantic  alignment [Platt et al. [sent-24, score-0.035]
</p><p>10 The framework was independently discovered by Bellare et al. [sent-26, score-0.121]
</p><p>11 [2009] as an approximation to GE constraints, under the name Alternating Projections, and used under that name also by Singh et al. [sent-27, score-0.033]
</p><p>12 The framework was also independently discovered by Liang et al. [sent-29, score-0.121]
</p><p>13 [2009] as an approximation to 1In Mann and McCallum [2007] the method  was  called Expectation Regularization. [sent-30, score-0.033]
</p><p>14 a Bayesian model motivated by modeling prior information as measurements, and applied to information extraction. [sent-31, score-0.045]
</p><p>15 [2009] introduce a distribution matching framework very closely related to GE constraints, with the idea that the model should predict the same feature expectations on labeled and undlabeled data for a set of features, formalized as a kernel. [sent-33, score-0.121]
</p><p>16 [2010] introduce a framework for semi-supervised learning based on constraints, and trained with an iterative update algorithm very similar to CoDL, but introducing only confident constraints as the algorithm progresses. [sent-35, score-0.149]
</p><p>17 Gupta and Sarawagi [2011] introduce a framework for agreement that is closely related to the PR-based work in Ganchev et al. [sent-36, score-0.084]
</p><p>18 Generalized expectation criteria for bootstrapping extractors using record-text alignment. [sent-46, score-0.302]
</p><p>19 Semi-supervised learning of dependency parsers using generalized expectation criteria. [sent-86, score-0.436]
</p><p>20 Generalized expectation criteria for semisupervised learning of conditional random fields. [sent-176, score-0.307]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ganchev', 0.422), ('druck', 0.378), ('expectation', 0.23), ('mann', 0.207), ('gra', 0.191), ('gillenwater', 0.184), ('url', 0.172), ('graa', 0.165), ('joo', 0.165), ('bellare', 0.16), ('graca', 0.134), ('kuzman', 0.13), ('posterior', 0.121), ('mccallum', 0.117), ('chang', 0.116), ('generalized', 0.115), ('bibliography', 0.11), ('codl', 0.11), ('platt', 0.106), ('ge', 0.105), ('ratinov', 0.097), ('quadrianto', 0.09), ('induction', 0.086), ('jennifer', 0.082), ('uai', 0.08), ('gupta', 0.08), ('ben', 0.079), ('singh', 0.076), ('wsdm', 0.074), ('measurements', 0.074), ('naseem', 0.074), ('constraints', 0.072), ('icml', 0.07), ('grammar', 0.07), ('alternating', 0.069), ('projections', 0.065), ('october', 0.065), ('carlson', 0.065), ('gregory', 0.062), ('constrained', 0.056), ('sparsity', 0.056), ('andrew', 0.055), ('dependency', 0.053), ('nips', 0.051), ('roweis', 0.049), ('novi', 0.049), ('translingual', 0.049), ('constraintdriven', 0.049), ('postcat', 0.049), ('ma', 0.048), ('pereira', 0.048), ('discovered', 0.048), ('http', 0.047), ('prior', 0.045), ('sarawagi', 0.045), ('sunita', 0.045), ('csail', 0.045), ('petterson', 0.045), ('aclweb', 0.045), ('closely', 0.045), ('cambridge', 0.043), ('regularization', 0.043), ('pr', 0.043), ('rizzolo', 0.042), ('dustin', 0.042), ('hillard', 0.042), ('february', 0.042), ('fernando', 0.041), ('kedar', 0.04), ('joao', 0.04), ('schuurmans', 0.04), ('burr', 0.04), ('settles', 0.04), ('estevam', 0.04), ('framework', 0.039), ('criteria', 0.039), ('learning', 0.038), ('submission', 0.038), ('williams', 0.038), ('bitext', 0.038), ('aaai', 0.037), ('formalized', 0.037), ('browser', 0.037), ('culotta', 0.037), ('betteridge', 0.037), ('hruschka', 0.037), ('harr', 0.037), ('tahira', 0.037), ('neural', 0.036), ('bengio', 0.035), ('guiding', 0.035), ('alignment', 0.035), ('cm', 0.034), ('lev', 0.034), ('independently', 0.034), ('liang', 0.034), ('rahul', 0.033), ('sameer', 0.033), ('extractors', 0.033), ('approximation', 0.033)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="342-tfidf-1" href="./acl-2011-full-for-print.html">342 acl-2011-full-for-print</a></p>
<p>Author: Kuzman Ganchev</p><p>Abstract: unkown-abstract</p><p>2 0.14117664 <a title="342-tfidf-2" href="./acl-2011-Domain_Adaptation_by_Constraining_Inter-Domain_Variability_of_Latent_Feature_Representation.html">103 acl-2011-Domain Adaptation by Constraining Inter-Domain Variability of Latent Feature Representation</a></p>
<p>Author: Ivan Titov</p><p>Abstract: We consider a semi-supervised setting for domain adaptation where only unlabeled data is available for the target domain. One way to tackle this problem is to train a generative model with latent variables on the mixture of data from the source and target domains. Such a model would cluster features in both domains and ensure that at least some of the latent variables are predictive of the label on the source domain. The danger is that these predictive clusters will consist of features specific to the source domain only and, consequently, a classifier relying on such clusters would perform badly on the target domain. We introduce a constraint enforcing that marginal distributions of each cluster (i.e., each latent variable) do not vary significantly across domains. We show that this constraint is effec- tive on the sentiment classification task (Pang et al., 2002), resulting in scores similar to the ones obtained by the structural correspondence methods (Blitzer et al., 2007) without the need to engineer auxiliary tasks.</p><p>3 0.12790252 <a title="342-tfidf-3" href="./acl-2011-Data_point_selection_for_cross-language_adaptation_of_dependency_parsers.html">92 acl-2011-Data point selection for cross-language adaptation of dependency parsers</a></p>
<p>Author: Anders Sgaard</p><p>Abstract: We consider a very simple, yet effective, approach to cross language adaptation of dependency parsers. We first remove lexical items from the treebanks and map part-of-speech tags into a common tagset. We then train a language model on tag sequences in otherwise unlabeled target data and rank labeled source data by perplexity per word of tag sequences from less similar to most similar to the target. We then train our target language parser on the most similar data points in the source labeled data. The strategy achieves much better results than a non-adapted baseline and stateof-the-art unsupervised dependency parsing, and results are comparable to more complex projection-based cross language adaptation algorithms.</p><p>4 0.11266032 <a title="342-tfidf-4" href="./acl-2011-In-domain_Relation_Discovery_with_Meta-constraints_via_Posterior_Regularization.html">170 acl-2011-In-domain Relation Discovery with Meta-constraints via Posterior Regularization</a></p>
<p>Author: Harr Chen ; Edward Benson ; Tahira Naseem ; Regina Barzilay</p><p>Abstract: We present a novel approach to discovering relations and their instantiations from a collection of documents in a single domain. Our approach learns relation types by exploiting meta-constraints that characterize the general qualities of a good relation in any domain. These constraints state that instances of a single relation should exhibit regularities at multiple levels of linguistic structure, including lexicography, syntax, and document-level context. We capture these regularities via the structure of our probabilistic model as well as a set of declaratively-specified constraints enforced during posterior inference. Across two domains our approach successfully recovers hidden relation structure, comparable to or outperforming previous state-of-the-art approaches. Furthermore, we find that a small , set of constraints is applicable across the domains, and that using domain-specific constraints can further improve performance. 1</p><p>5 0.087486617 <a title="342-tfidf-5" href="./acl-2011-Partial_Parsing_from_Bitext_Projections.html">243 acl-2011-Partial Parsing from Bitext Projections</a></p>
<p>Author: Prashanth Mannem ; Aswarth Dara</p><p>Abstract: Recent work has shown how a parallel corpus can be leveraged to build syntactic parser for a target language by projecting automatic source parse onto the target sentence using word alignments. The projected target dependency parses are not always fully connected to be useful for training traditional dependency parsers. In this paper, we present a greedy non-directional parsing algorithm which doesn’t need a fully connected parse and can learn from partial parses by utilizing available structural and syntactic information in them. Our parser achieved statistically significant improvements over a baseline system that trains on only fully connected parses for Bulgarian, Spanish and Hindi. It also gave a significant improvement over previously reported results for Bulgarian and set a benchmark for Hindi.</p><p>6 0.076442845 <a title="342-tfidf-6" href="./acl-2011-A_Hierarchical_Pitman-Yor_Process_HMM_for_Unsupervised_Part_of_Speech_Induction.html">15 acl-2011-A Hierarchical Pitman-Yor Process HMM for Unsupervised Part of Speech Induction</a></p>
<p>7 0.067425348 <a title="342-tfidf-7" href="./acl-2011-Neutralizing_Linguistically_Problematic_Annotations_in_Unsupervised_Dependency_Parsing_Evaluation.html">230 acl-2011-Neutralizing Linguistically Problematic Annotations in Unsupervised Dependency Parsing Evaluation</a></p>
<p>8 0.063878253 <a title="342-tfidf-8" href="./acl-2011-Model-Based_Aligner_Combination_Using_Dual_Decomposition.html">221 acl-2011-Model-Based Aligner Combination Using Dual Decomposition</a></p>
<p>9 0.06262701 <a title="342-tfidf-9" href="./acl-2011-Unsupervised_Part-of-Speech_Tagging_with_Bilingual_Graph-Based_Projections.html">323 acl-2011-Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</a></p>
<p>10 0.06097322 <a title="342-tfidf-10" href="./acl-2011-Entity_Set_Expansion_using_Topic_information.html">117 acl-2011-Entity Set Expansion using Topic information</a></p>
<p>11 0.056386251 <a title="342-tfidf-11" href="./acl-2011-Large-Scale_Cross-Document_Coreference_Using_Distributed_Inference_and_Hierarchical_Models.html">196 acl-2011-Large-Scale Cross-Document Coreference Using Distributed Inference and Hierarchical Models</a></p>
<p>12 0.055077799 <a title="342-tfidf-12" href="./acl-2011-Reordering_Modeling_using_Weighted_Alignment_Matrices.html">265 acl-2011-Reordering Modeling using Weighted Alignment Matrices</a></p>
<p>13 0.050997108 <a title="342-tfidf-13" href="./acl-2011-Piggyback%3A_Using_Search_Engines_for_Robust_Cross-Domain_Named_Entity_Recognition.html">246 acl-2011-Piggyback: Using Search Engines for Robust Cross-Domain Named Entity Recognition</a></p>
<p>14 0.049552642 <a title="342-tfidf-14" href="./acl-2011-K-means_Clustering_with_Feature_Hashing.html">189 acl-2011-K-means Clustering with Feature Hashing</a></p>
<p>15 0.049214032 <a title="342-tfidf-15" href="./acl-2011-From_Bilingual_Dictionaries_to_Interlingual_Document_Representations.html">139 acl-2011-From Bilingual Dictionaries to Interlingual Document Representations</a></p>
<p>16 0.04500578 <a title="342-tfidf-16" href="./acl-2011-Interactive_Topic_Modeling.html">178 acl-2011-Interactive Topic Modeling</a></p>
<p>17 0.043836817 <a title="342-tfidf-17" href="./acl-2011-Knowledge-Based_Weak_Supervision_for_Information_Extraction_of_Overlapping_Relations.html">190 acl-2011-Knowledge-Based Weak Supervision for Information Extraction of Overlapping Relations</a></p>
<p>18 0.043641865 <a title="342-tfidf-18" href="./acl-2011-Bayesian_Word_Alignment_for_Statistical_Machine_Translation.html">57 acl-2011-Bayesian Word Alignment for Statistical Machine Translation</a></p>
<p>19 0.041348148 <a title="342-tfidf-19" href="./acl-2011-Confidence_Driven_Unsupervised_Semantic_Parsing.html">79 acl-2011-Confidence Driven Unsupervised Semantic Parsing</a></p>
<p>20 0.040280156 <a title="342-tfidf-20" href="./acl-2011-Unsupervised_Word_Alignment_with_Arbitrary_Features.html">325 acl-2011-Unsupervised Word Alignment with Arbitrary Features</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.109), (1, -0.0), (2, -0.029), (3, -0.023), (4, 0.015), (5, -0.032), (6, 0.011), (7, 0.055), (8, -0.033), (9, 0.048), (10, 0.086), (11, 0.04), (12, 0.053), (13, 0.026), (14, 0.009), (15, 0.04), (16, -0.019), (17, -0.041), (18, -0.044), (19, -0.041), (20, -0.045), (21, -0.046), (22, -0.005), (23, 0.019), (24, -0.01), (25, 0.019), (26, -0.031), (27, -0.002), (28, 0.065), (29, -0.006), (30, 0.014), (31, 0.111), (32, 0.056), (33, 0.041), (34, 0.033), (35, -0.012), (36, 0.016), (37, 0.072), (38, -0.056), (39, -0.028), (40, 0.018), (41, -0.027), (42, 0.003), (43, -0.047), (44, -0.076), (45, -0.119), (46, -0.056), (47, 0.053), (48, 0.013), (49, -0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92027688 <a title="342-lsi-1" href="./acl-2011-full-for-print.html">342 acl-2011-full-for-print</a></p>
<p>Author: Kuzman Ganchev</p><p>Abstract: unkown-abstract</p><p>2 0.63139158 <a title="342-lsi-2" href="./acl-2011-Domain_Adaptation_by_Constraining_Inter-Domain_Variability_of_Latent_Feature_Representation.html">103 acl-2011-Domain Adaptation by Constraining Inter-Domain Variability of Latent Feature Representation</a></p>
<p>Author: Ivan Titov</p><p>Abstract: We consider a semi-supervised setting for domain adaptation where only unlabeled data is available for the target domain. One way to tackle this problem is to train a generative model with latent variables on the mixture of data from the source and target domains. Such a model would cluster features in both domains and ensure that at least some of the latent variables are predictive of the label on the source domain. The danger is that these predictive clusters will consist of features specific to the source domain only and, consequently, a classifier relying on such clusters would perform badly on the target domain. We introduce a constraint enforcing that marginal distributions of each cluster (i.e., each latent variable) do not vary significantly across domains. We show that this constraint is effec- tive on the sentiment classification task (Pang et al., 2002), resulting in scores similar to the ones obtained by the structural correspondence methods (Blitzer et al., 2007) without the need to engineer auxiliary tasks.</p><p>3 0.56863618 <a title="342-lsi-3" href="./acl-2011-Data_point_selection_for_cross-language_adaptation_of_dependency_parsers.html">92 acl-2011-Data point selection for cross-language adaptation of dependency parsers</a></p>
<p>Author: Anders Sgaard</p><p>Abstract: We consider a very simple, yet effective, approach to cross language adaptation of dependency parsers. We first remove lexical items from the treebanks and map part-of-speech tags into a common tagset. We then train a language model on tag sequences in otherwise unlabeled target data and rank labeled source data by perplexity per word of tag sequences from less similar to most similar to the target. We then train our target language parser on the most similar data points in the source labeled data. The strategy achieves much better results than a non-adapted baseline and stateof-the-art unsupervised dependency parsing, and results are comparable to more complex projection-based cross language adaptation algorithms.</p><p>4 0.5329836 <a title="342-lsi-4" href="./acl-2011-Knowledge-Based_Weak_Supervision_for_Information_Extraction_of_Overlapping_Relations.html">190 acl-2011-Knowledge-Based Weak Supervision for Information Extraction of Overlapping Relations</a></p>
<p>Author: Raphael Hoffmann ; Congle Zhang ; Xiao Ling ; Luke Zettlemoyer ; Daniel S. Weld</p><p>Abstract: Information extraction (IE) holds the promise of generating a large-scale knowledge base from the Web’s natural language text. Knowledge-based weak supervision, using structured data to heuristically label a training corpus, works towards this goal by enabling the automated learning of a potentially unbounded number of relation extractors. Recently, researchers have developed multiinstance learning algorithms to combat the noisy training data that can come from heuristic labeling, but their models assume relations are disjoint — for example they cannot extract the pair Founded ( Jobs Apple ) and CEO-o f ( Jobs Apple ) . , , This paper presents a novel approach for multi-instance learning with overlapping relations that combines a sentence-level extrac- , tion model with a simple, corpus-level component for aggregating the individual facts. We apply our model to learn extractors for NY Times text using weak supervision from Freebase. Experiments show that the approach runs quickly and yields surprising gains in accuracy, at both the aggregate and sentence level.</p><p>5 0.52799809 <a title="342-lsi-5" href="./acl-2011-Unsupervised_Part-of-Speech_Tagging_with_Bilingual_Graph-Based_Projections.html">323 acl-2011-Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</a></p>
<p>Author: Dipanjan Das ; Slav Petrov</p><p>Abstract: We describe a novel approach for inducing unsupervised part-of-speech taggers for languages that have no labeled training data, but have translated text in a resource-rich language. Our method does not assume any knowledge about the target language (in particular no tagging dictionary is assumed), making it applicable to a wide array of resource-poor languages. We use graph-based label propagation for cross-lingual knowledge transfer and use the projected labels as features in an unsupervised model (BergKirkpatrick et al., 2010). Across eight European languages, our approach results in an average absolute improvement of 10.4% over a state-of-the-art baseline, and 16.7% over vanilla hidden Markov models induced with the Expectation Maximization algorithm.</p><p>6 0.50790012 <a title="342-lsi-6" href="./acl-2011-Partial_Parsing_from_Bitext_Projections.html">243 acl-2011-Partial Parsing from Bitext Projections</a></p>
<p>7 0.49923879 <a title="342-lsi-7" href="./acl-2011-Temporal_Restricted_Boltzmann_Machines_for_Dependency_Parsing.html">295 acl-2011-Temporal Restricted Boltzmann Machines for Dependency Parsing</a></p>
<p>8 0.46606344 <a title="342-lsi-8" href="./acl-2011-In-domain_Relation_Discovery_with_Meta-constraints_via_Posterior_Regularization.html">170 acl-2011-In-domain Relation Discovery with Meta-constraints via Posterior Regularization</a></p>
<p>9 0.46171117 <a title="342-lsi-9" href="./acl-2011-Tier-based_Strictly_Local_Constraints_for_Phonology.html">303 acl-2011-Tier-based Strictly Local Constraints for Phonology</a></p>
<p>10 0.46094102 <a title="342-lsi-10" href="./acl-2011-Hierarchical_Text_Classification_with_Latent_Concepts.html">150 acl-2011-Hierarchical Text Classification with Latent Concepts</a></p>
<p>11 0.44373918 <a title="342-lsi-11" href="./acl-2011-Semi-supervised_condensed_nearest_neighbor_for_part-of-speech_tagging.html">278 acl-2011-Semi-supervised condensed nearest neighbor for part-of-speech tagging</a></p>
<p>12 0.44230512 <a title="342-lsi-12" href="./acl-2011-Model-Based_Aligner_Combination_Using_Dual_Decomposition.html">221 acl-2011-Model-Based Aligner Combination Using Dual Decomposition</a></p>
<p>13 0.4354299 <a title="342-lsi-13" href="./acl-2011-Event_Discovery_in_Social_Media_Feeds.html">121 acl-2011-Event Discovery in Social Media Feeds</a></p>
<p>14 0.43400434 <a title="342-lsi-14" href="./acl-2011-Why_Initialization_Matters_for_IBM_Model_1%3A_Multiple_Optima_and_Non-Strict_Convexity.html">335 acl-2011-Why Initialization Matters for IBM Model 1: Multiple Optima and Non-Strict Convexity</a></p>
<p>15 0.41702771 <a title="342-lsi-15" href="./acl-2011-Is_Machine_Translation_Ripe_for_Cross-Lingual_Sentiment_Classification%3F.html">179 acl-2011-Is Machine Translation Ripe for Cross-Lingual Sentiment Classification?</a></p>
<p>16 0.4092907 <a title="342-lsi-16" href="./acl-2011-A_Hierarchical_Pitman-Yor_Process_HMM_for_Unsupervised_Part_of_Speech_Induction.html">15 acl-2011-A Hierarchical Pitman-Yor Process HMM for Unsupervised Part of Speech Induction</a></p>
<p>17 0.40530184 <a title="342-lsi-17" href="./acl-2011-P11-5002_k2opt.pdf.html">239 acl-2011-P11-5002 k2opt.pdf</a></p>
<p>18 0.40310854 <a title="342-lsi-18" href="./acl-2011-Optimal_Head-Driven_Parsing_Complexity_for_Linear_Context-Free_Rewriting_Systems.html">234 acl-2011-Optimal Head-Driven Parsing Complexity for Linear Context-Free Rewriting Systems</a></p>
<p>19 0.4009726 <a title="342-lsi-19" href="./acl-2011-Neutralizing_Linguistically_Problematic_Annotations_in_Unsupervised_Dependency_Parsing_Evaluation.html">230 acl-2011-Neutralizing Linguistically Problematic Annotations in Unsupervised Dependency Parsing Evaluation</a></p>
<p>20 0.4009212 <a title="342-lsi-20" href="./acl-2011-Exact_Decoding_of_Syntactic_Translation_Models_through_Lagrangian_Relaxation.html">123 acl-2011-Exact Decoding of Syntactic Translation Models through Lagrangian Relaxation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(17, 0.023), (26, 0.01), (31, 0.023), (37, 0.09), (39, 0.038), (41, 0.094), (53, 0.014), (55, 0.035), (59, 0.029), (72, 0.031), (77, 0.392), (91, 0.036), (96, 0.092)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.75323004 <a title="342-lda-1" href="./acl-2011-full-for-print.html">342 acl-2011-full-for-print</a></p>
<p>Author: Kuzman Ganchev</p><p>Abstract: unkown-abstract</p><p>2 0.64639616 <a title="342-lda-2" href="./acl-2011-Modeling_Wisdom_of_Crowds_Using_Latent_Mixture_of_Discriminative_Experts.html">223 acl-2011-Modeling Wisdom of Crowds Using Latent Mixture of Discriminative Experts</a></p>
<p>Author: Derya Ozkan ; Louis-Philippe Morency</p><p>Abstract: In many computational linguistic scenarios, training labels are subjectives making it necessary to acquire the opinions of multiple annotators/experts, which is referred to as ”wisdom of crowds”. In this paper, we propose a new approach for modeling wisdom of crowds based on the Latent Mixture of Discriminative Experts (LMDE) model that can automatically learn the prototypical patterns and hidden dynamic among different experts. Experiments show improvement over state-of-the-art approaches on the task of listener backchannel prediction in dyadic conversations.</p><p>3 0.41357511 <a title="342-lda-3" href="./acl-2011-Data_point_selection_for_cross-language_adaptation_of_dependency_parsers.html">92 acl-2011-Data point selection for cross-language adaptation of dependency parsers</a></p>
<p>Author: Anders Sgaard</p><p>Abstract: We consider a very simple, yet effective, approach to cross language adaptation of dependency parsers. We first remove lexical items from the treebanks and map part-of-speech tags into a common tagset. We then train a language model on tag sequences in otherwise unlabeled target data and rank labeled source data by perplexity per word of tag sequences from less similar to most similar to the target. We then train our target language parser on the most similar data points in the source labeled data. The strategy achieves much better results than a non-adapted baseline and stateof-the-art unsupervised dependency parsing, and results are comparable to more complex projection-based cross language adaptation algorithms.</p><p>4 0.40152603 <a title="342-lda-4" href="./acl-2011-Knowledge-Based_Weak_Supervision_for_Information_Extraction_of_Overlapping_Relations.html">190 acl-2011-Knowledge-Based Weak Supervision for Information Extraction of Overlapping Relations</a></p>
<p>Author: Raphael Hoffmann ; Congle Zhang ; Xiao Ling ; Luke Zettlemoyer ; Daniel S. Weld</p><p>Abstract: Information extraction (IE) holds the promise of generating a large-scale knowledge base from the Web’s natural language text. Knowledge-based weak supervision, using structured data to heuristically label a training corpus, works towards this goal by enabling the automated learning of a potentially unbounded number of relation extractors. Recently, researchers have developed multiinstance learning algorithms to combat the noisy training data that can come from heuristic labeling, but their models assume relations are disjoint — for example they cannot extract the pair Founded ( Jobs Apple ) and CEO-o f ( Jobs Apple ) . , , This paper presents a novel approach for multi-instance learning with overlapping relations that combines a sentence-level extrac- , tion model with a simple, corpus-level component for aggregating the individual facts. We apply our model to learn extractors for NY Times text using weak supervision from Freebase. Experiments show that the approach runs quickly and yields surprising gains in accuracy, at both the aggregate and sentence level.</p><p>5 0.39022803 <a title="342-lda-5" href="./acl-2011-Can_Document_Selection_Help_Semi-supervised_Learning%3F_A_Case_Study_On_Event_Extraction.html">65 acl-2011-Can Document Selection Help Semi-supervised Learning? A Case Study On Event Extraction</a></p>
<p>Author: Shasha Liao ; Ralph Grishman</p><p>Abstract: Annotating training data for event extraction is tedious and labor-intensive. Most current event extraction tasks rely on hundreds of annotated documents, but this is often not enough. In this paper, we present a novel self-training strategy, which uses Information Retrieval (IR) to collect a cluster of related documents as the resource for bootstrapping. Also, based on the particular characteristics of this corpus, global inference is applied to provide more confident and informative data selection. We compare this approach to self-training on a normal newswire corpus and show that IR can provide a better corpus for bootstrapping and that global inference can further improve instance selection. We obtain gains of 1.7% in trigger labeling and 2.3% in role labeling through IR and an additional 1.1% in trigger labeling and 1.3% in role labeling by applying global inference. 1</p><p>6 0.3893913 <a title="342-lda-6" href="./acl-2011-Exploiting_Syntactico-Semantic_Structures_for_Relation_Extraction.html">126 acl-2011-Exploiting Syntactico-Semantic Structures for Relation Extraction</a></p>
<p>7 0.38673103 <a title="342-lda-7" href="./acl-2011-Joint_Identification_and_Segmentation_of_Domain-Specific_Dialogue_Acts_for_Conversational_Dialogue_Systems.html">185 acl-2011-Joint Identification and Segmentation of Domain-Specific Dialogue Acts for Conversational Dialogue Systems</a></p>
<p>8 0.38450533 <a title="342-lda-8" href="./acl-2011-Large-Scale_Cross-Document_Coreference_Using_Distributed_Inference_and_Hierarchical_Models.html">196 acl-2011-Large-Scale Cross-Document Coreference Using Distributed Inference and Hierarchical Models</a></p>
<p>9 0.38431662 <a title="342-lda-9" href="./acl-2011-Beam-Width_Prediction_for_Efficient_Context-Free_Parsing.html">58 acl-2011-Beam-Width Prediction for Efficient Context-Free Parsing</a></p>
<p>10 0.38430661 <a title="342-lda-10" href="./acl-2011-Exploring_Entity_Relations_for_Named_Entity_Disambiguation.html">128 acl-2011-Exploring Entity Relations for Named Entity Disambiguation</a></p>
<p>11 0.38206828 <a title="342-lda-11" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>12 0.37887153 <a title="342-lda-12" href="./acl-2011-Evaluating_the_Impact_of_Coder_Errors_on_Active_Learning.html">119 acl-2011-Evaluating the Impact of Coder Errors on Active Learning</a></p>
<p>13 0.37818465 <a title="342-lda-13" href="./acl-2011-Unary_Constraints_for_Efficient_Context-Free_Parsing.html">316 acl-2011-Unary Constraints for Efficient Context-Free Parsing</a></p>
<p>14 0.37767661 <a title="342-lda-14" href="./acl-2011-Insertion%2C_Deletion%2C_or_Substitution%3F_Normalizing_Text_Messages_without_Pre-categorization_nor_Supervision.html">172 acl-2011-Insertion, Deletion, or Substitution? Normalizing Text Messages without Pre-categorization nor Supervision</a></p>
<p>15 0.37686956 <a title="342-lda-15" href="./acl-2011-Lexically-Triggered_Hidden_Markov_Models_for_Clinical_Document_Coding.html">209 acl-2011-Lexically-Triggered Hidden Markov Models for Clinical Document Coding</a></p>
<p>16 0.37623852 <a title="342-lda-16" href="./acl-2011-Piggyback%3A_Using_Search_Engines_for_Robust_Cross-Domain_Named_Entity_Recognition.html">246 acl-2011-Piggyback: Using Search Engines for Robust Cross-Domain Named Entity Recognition</a></p>
<p>17 0.37619391 <a title="342-lda-17" href="./acl-2011-Effects_of_Noun_Phrase_Bracketing_in_Dependency_Parsing_and_Machine_Translation.html">111 acl-2011-Effects of Noun Phrase Bracketing in Dependency Parsing and Machine Translation</a></p>
<p>18 0.37573701 <a title="342-lda-18" href="./acl-2011-An_Error_Analysis_of_Relation_Extraction_in_Social_Media_Documents.html">40 acl-2011-An Error Analysis of Relation Extraction in Social Media Documents</a></p>
<p>19 0.37549174 <a title="342-lda-19" href="./acl-2011-Temporal_Restricted_Boltzmann_Machines_for_Dependency_Parsing.html">295 acl-2011-Temporal Restricted Boltzmann Machines for Dependency Parsing</a></p>
<p>20 0.37534988 <a title="342-lda-20" href="./acl-2011-Collective_Classification_of_Congressional_Floor-Debate_Transcripts.html">73 acl-2011-Collective Classification of Congressional Floor-Debate Transcripts</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
