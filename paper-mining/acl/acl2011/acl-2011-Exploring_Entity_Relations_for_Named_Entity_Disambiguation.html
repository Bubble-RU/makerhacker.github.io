<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>128 acl-2011-Exploring Entity Relations for Named Entity Disambiguation</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-128" href="#">acl2011-128</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>128 acl-2011-Exploring Entity Relations for Named Entity Disambiguation</h1>
<br/><p>Source: <a title="acl-2011-128-pdf" href="http://aclweb.org/anthology//P/P11/P11-3004.pdf">pdf</a></p><p>Author: Danuta Ploch</p><p>Abstract: Named entity disambiguation is the task of linking an entity mention in a text to the correct real-world referent predefined in a knowledge base, and is a crucial subtask in many areas like information retrieval or topic detection and tracking. Named entity disambiguation is challenging because entity mentions can be ambiguous and an entity can be referenced by different surface forms. We present an approach that exploits Wikipedia relations between entities co-occurring with the ambiguous form to derive a range of novel features for classifying candidate referents. We find that our features improve disambiguation results significantly over a strong popularity baseline, and are especially suitable for recognizing entities not contained in the knowledge base. Our system achieves state-of-the-art results on the TAC-KBP 2009 dataset.</p><p>Reference: <a title="acl-2011-128-reference" href="../acl2011_reference/acl-2011-Exploring_Entity_Relations_for_Named_Entity_Disambiguation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 de  Abstract Named entity disambiguation is the task of linking an entity mention in a text to the correct real-world referent predefined in a knowledge base, and is a crucial subtask in many areas like information retrieval or topic detection and tracking. [sent-3, score-0.798]
</p><p>2 Named entity disambiguation is challenging because entity mentions can be ambiguous and an entity can be referenced by different surface forms. [sent-4, score-1.34]
</p><p>3 We present an approach that exploits Wikipedia relations between entities co-occurring with the ambiguous form to derive a range of novel features for classifying candidate referents. [sent-5, score-0.492]
</p><p>4 We find that our features improve disambiguation results significantly over a strong popularity baseline, and are especially suitable for recognizing entities not contained in the knowledge base. [sent-6, score-0.498]
</p><p>5 1 Introduction  Identifying the correct real-world referents ofnamed entities (NE) mentioned in text (such as people, organizations, and geographic locations) plays an important role in various natural language processing and information retrieval tasks. [sent-8, score-0.142]
</p><p>6 The goal of Named Entity Disambiguation (NED) is to label a surface form denoting an NE in text with one of multiple predefined NEs from a knowledge base (KB), or to detect that the surface form refers to an out-ofKB entity, which is known as NIL detection. [sent-9, score-0.824]
</p><p>7 NED has become a popular research field recently, as the growth of large-scale publicly available encyclopedic knowledge resources such as Wikipedia has 18 stimulated research on linking NEs in text to their entries in these KBs (Bunescu and Pasca, 2006; McNamee and Dang, 2009). [sent-10, score-0.159]
</p><p>8 The disambiguation of named entities raises several challenges: Surface forms in text can be ambiguous, and the same entity can be referred to by different surface forms. [sent-11, score-1.056]
</p><p>9 For example, the surface form “George Bush” may denote either of two former U. [sent-12, score-0.367]
</p><p>10 Thus, a many-to-many mapping between surface forms and entities has to be resolved. [sent-16, score-0.547]
</p><p>11 In addition, entity mentions may not have a matching entity in the KB, which is often the case for nonpopular entities. [sent-17, score-0.452]
</p><p>12 Typical approaches to NED combine the use of document context knowledge with entity information stored in the KB in order to disambiguate entities. [sent-18, score-0.399]
</p><p>13 Many systems represent document context and KB information as word or concept vectors, and rank entities using vector space similarity metrics (Cucerzan, 2007). [sent-19, score-0.357]
</p><p>14 Other authors employ supervised machine learning algorithms to classify or rank candidate entities (Bunescu and Pasca, 2006; Zhang et al. [sent-20, score-0.311]
</p><p>15 Common features include popularity metrics based on Wikipedia’s graph structure or on name mention frequency (Dredze et al. [sent-22, score-0.241]
</p><p>16 , 2010; Han and Zhao, 2009), similarity metrics exploring Wikipedia’s concept relations (Han and Zhao, 2009), and string similarity features. [sent-23, score-0.184]
</p><p>17 While previous research has largely focused on disambiguating each entity mention in a document  Portland, OPR,ro UcSeeAdi 1n9g-s2 o4f J uthnee A 2C01L-1H. [sent-26, score-0.376]
</p><p>18 c T2 2001111 A Sstsuodceinatti Soens fsoiorn C,o pmagpeusta 18ti–o2n3a,l Linguistics separately (McNamee and Dang, 2009), we explore an approach that is driven by the observation that entities normally co-occur in texts. [sent-28, score-0.142]
</p><p>19 Documents often discuss several different entities related to each other, e. [sent-29, score-0.142]
</p><p>20 a news article may report on a meeting of political leaders from different countries. [sent-31, score-0.08]
</p><p>21 Our Contributions In this paper, we evaluate a range of novel disambiguation features that exploit the relations between NEs identified in a document and in the KB. [sent-33, score-0.404]
</p><p>22 Our goal is to explore the usefulness of Wikipedia’s link structure as source of relations between entities. [sent-34, score-0.094]
</p><p>23 We propose a method for candidate selection that is based on an inverted index of surface forms and entities (Section 3. [sent-35, score-0.805]
</p><p>24 Instead of a bag-of-words approach we use co-occurring NEs in text for describing an ambiguous surface form. [sent-37, score-0.408]
</p><p>25 We introduce several different disambiguation features that exploit the relations between entities derived from the graph structure of Wikipedia (Section  3. [sent-38, score-0.493]
</p><p>26 Finally, we combine our disambiguation features and achieve state-of-the-art results with a Support Vector Machine (SVM) classifier (Section 4). [sent-40, score-0.289]
</p><p>27 2  Problem statement  The task of NED is to assign a surface form s found in a document d to a target NE t ∈ E(s), where E(s) ⊂ uEm eisn a sdet t oof a c taanrdgiedta NteE EN tEs ∈ ∈fr Eom(s an entity KE(Bs )th ⊂at Eis idse fain seedt by aEn = {e1, e2 , . [sent-41, score-0.703]
</p><p>28 , en}, or ttoy recognize sth daetf itnheed dfo buynd E su =rfa {cee form s ref}er,s o to a missing target entity t ∈/ E(s). [sent-44, score-0.298]
</p><p>29 Since the same surface form s may refer to more than one NE e, the correct target entity t has to be determined from a set of candidates E(s) Name variants Often, name variants (e. [sent-47, score-0.827]
</p><p>30 abbreviations, acronyms or synonyms) are used in texts to refer to the same NE, which has to be considered for the determination of candidates E(s) for a given surface form s. [sent-49, score-0.481]
</p><p>31 Another challenge of 19  Figure 1: Ambiguity of Wikipedia surface forms. [sent-51, score-0.322]
</p><p>32 The distribution follows a power law, as many surface forms have only a single meaning (i. [sent-52, score-0.405]
</p><p>33 refer to a single Wikipedia concept), and some surface forms are highly ambiguous, referring to very many different concepts. [sent-54, score-0.464]
</p><p>34 NED is therefore to recognize missing NEs where t ∈/ E(s), given a surface form s (NIL detection). [sent-55, score-0.367]
</p><p>35 In this section we describe the construction and structure of the KB and the candidate selection scheme, followed by an overview of disambiguation features and the candidate classification algorithm. [sent-57, score-0.556]
</p><p>36 1 Knowledge base construction Our approach disambiguates named entities against a KB constructed from Wikipedia. [sent-59, score-0.275]
</p><p>37 To this end, we process Wikipedia to extract several types of information for each Wikipedia article describing a concept (i. [sent-60, score-0.14]
</p><p>38 any article not being a redirect page, a disambiguation page, or any other kind of meta page). [sent-62, score-0.403]
</p><p>39 We collect a set of name variants (surface forms) for each concept from article titles, redirect pages, disambiguation pages and the anchor texts of internal Wikipedia links, following Cucerzan (2007). [sent-63, score-0.553]
</p><p>40 For each concept, we also collect its set of incoming and  outgoing links to other Wikipedia pages. [sent-64, score-0.161]
</p><p>41 We store this information in an inverted index, which allows for very efficient access and search during candidate selection and feature computation. [sent-66, score-0.264]
</p><p>42 The distribution of surface forms follows a power law, where the majority of surface forms is unambiguous, but some surface forms are very ambiguous (Figure 1). [sent-67, score-1.301]
</p><p>43 This suggests that for a given set of distinct surface forms found in a document, many of these will unambiguously refer to a single Wikipedia entity. [sent-68, score-0.436]
</p><p>44 These entities can then be used to disambiguate surface forms referring to multiple entities. [sent-69, score-0.629]
</p><p>45 2  Candidate selection  Given a surface form identified in a document, the task of the candidate selection component is to retrieve a set of candidate entities from the KB. [sent-71, score-0.863]
</p><p>46 To this end, we execute a search on index fields storing article titles, redirect titles, and name variants. [sent-72, score-0.306]
</p><p>47 We implement a weighted search to give high weights to exact title matches, a lesser emphasis on redirect matches, and finally a low weight for all other name variants. [sent-73, score-0.207]
</p><p>48 In addition, we implement a fuzzy  search on the title and redirect fields to select KB entries with approximate string similarity to the surface form. [sent-74, score-0.544]
</p><p>49 3 Disambiguation features In this section, we describe the features that we use in our disambiguation approach. [sent-76, score-0.28]
</p><p>50 Entity Context (EC) The EC disambiguation feature is calculated as the cosine similarity between the document context d of a surface form s and the Wikipedia article c of each candidate c ∈ E(s). [sent-77, score-0.964]
</p><p>51 If a surface form is ambiguous, we choose the most popular NE with the popularity metric described below. [sent-81, score-0.445]
</p><p>52 Analogously, we represent each c as a vector of the incoming and outgoing URIs found on its Wikipedia page. [sent-82, score-0.132]
</p><p>53 Link Context (LC) The link context feature is an extension of the EC feature. [sent-83, score-0.103]
</p><p>54 Since our observations have shown that the entity context can be very small and consequently the overlap between d and  c may be very low, we extend d by all incoming (LC-in) or by all incoming and outgoing (LC-all) Wikipedia URIs of the NEs from the entity context. [sent-84, score-0.654]
</p><p>55 We assume that Wikipedia pages that refer to other 20 Wikipedia pages contain information on the referenced pages or at least are thematically related to these pages. [sent-85, score-0.081]
</p><p>56 Candidate Rank (CR) The features described so far disambiguate every surface form s ∈ S from a fdaorc dumisaemntb dig separately, w shuerfraecaes our mC asnd ∈id Sate fr oRman ka feature aims to disambiguate all surface forms S found in a document d at once. [sent-87, score-1.081]
</p><p>57 We represent d as a graph D = (E(S) , L(E(S))) where the nodes E(S) = ∪s∈SE(s) are all candidates of all surface Efor(Sms) =in ∪the document and L(E(S)) is the set of links between the candidates, as found in Wikipedia. [sent-88, score-0.547]
</p><p>58 Then, we compute the PageRank score (Brin and Page, 1998) of all c ∈ E(S) and choose for each s athgee, c 1a9n9d8id)a otef awllith c t h∈e highest PageRank score cinh the document graph D. [sent-89, score-0.167]
</p><p>59 Standard Features In addition to the previously described features we also implement a set of commonly accepted features. [sent-90, score-0.066]
</p><p>60 These include a feature based on the cosine similarity between word vector representations of the document and the Wikipedia article of each candidate (BOW) (Bunescu, 2007). [sent-91, score-0.393]
</p><p>61 Another standard feature we use is the popularity of a surface form (SFP). [sent-94, score-0.498]
</p><p>62 We calculate how often a surface form s references a candidate c ∈ E(s) in relation to the totrealf enruemncbeesr a ao cfa mndenidtiaotens c o∈f s (ins Wikipedia (Han ea tnodZhao, 2009). [sent-95, score-0.504]
</p><p>63 Since we use an index for selecting candidates (Section 3. [sent-96, score-0.13]
</p><p>64 2), we also exploit the candidate selection score (CS) returned for each candidate as a disambiguation feature. [sent-97, score-0.553]
</p><p>65 4 Candidate classifier and NIL detection We cast NED as a supervised classification task and use two binary SVM classifiers (Vapnik, 1995). [sent-99, score-0.075]
</p><p>66 The first classifier decides for each candidate c ∈ E(s) if fiti corresponds teoc tidhee target entity. [sent-100, score-0.184]
</p><p>67 For training the classifier we label as a positive example at most  x(c)  x(c)  one from the set of candidates for a surface form s, and all others as negative. [sent-102, score-0.497]
</p><p>68 In addition, we train a separate classifier to detect NIL queries, i. [sent-103, score-0.047]
</p><p>69 The best feature set contains all features except for LC-all and CR. [sent-113, score-0.091]
</p><p>70 Our system outperforms previously reported results on NIL queries, and compares favorably on all queries. [sent-114, score-0.041]
</p><p>71 if the similarity values of all candidates c ∈ E(s) are very liolawri. [sent-115, score-0.123]
</p><p>72 W vael uceaslc oufla atell scaevnedriadla tdeisffe cr ∈ent E fe(as-) tures, such as the maximum, mean and minimum, the difference between maximum and mean, and the difference between maximum and minimum, of all  atomic features, using the feature vectors of all candidates in E(s). [sent-116, score-0.277]
</p><p>73 Both classifier use a radial basis function kernel, with parameter settings of C = 32 and γ = 8. [sent-117, score-0.047]
</p><p>74 A set of 3904 surface form-document pairs (queries) is constructed from these sources, encompassing 560 unique entities. [sent-121, score-0.322]
</p><p>75 The majority of queries (57%) are NIL queries, of the KB queries, 69% are for organizations and 15% each for persons and geopolitical entities. [sent-122, score-0.225]
</p><p>76 For each query the surface form appearing in the given document has to be disambiguated against the KB. [sent-123, score-0.45]
</p><p>77 We randomly split the 3904 queries to perform 10-fold cross-validation, and stratify the resulting folds to ensure a similar distribution of KB and NIL  queries in our training data. [sent-124, score-0.351]
</p><p>78 After normalizing feature values to be in [0, 1], we train a candidate and a NIL classifier on 90% of the queries in each iteration, and test using the remaining 10%. [sent-125, score-0.399]
</p><p>79 Results reported in this paper are then averaged across the 21 All queries  KB  NIL  1,0 0,9  car oi-aegvMdacuy0 0 , 408137625Baselin featursBetfauresD dze tal. [sent-126, score-0.162]
</p><p>80 Figure 2: The micro-averaged accuracy for all types of queries on TAC-KBP 2009 data in comparison to other systems. [sent-128, score-0.193]
</p><p>81 Table 1compares the micro-averaged accuracy of  our approach on KB and NIL queries for different feature sets, and lists the results of two other stateof-the-art systems (Dredze et al. [sent-130, score-0.246]
</p><p>82 As a baseline we use a feature set consisting of the BOW and SFP features. [sent-135, score-0.053]
</p><p>83 The best feature set in our experiments comprises all features except for the LC-all and CR features. [sent-136, score-0.091]
</p><p>84 Using the best feature set improves the disambiguation accuracy by 6. [sent-139, score-0.288]
</p><p>85 2% over the baseline feature set, which is significant at p = 0. [sent-140, score-0.053]
</p><p>86 For KB queries our system’s accuracy is higher than that of Dredze et al. [sent-142, score-0.193]
</p><p>87 We can  see that the novel entity features contribute to a higher overall accuracy. [sent-146, score-0.264]
</p><p>88 Including the candidate selection score (CS) improves accuracy by 3. [sent-147, score-0.208]
</p><p>89 The Wikipedia link-based features provide additional gains, however differences are quite 0,85  BOW  BOW + EC  BOW + EC + LC-in  BOW + EC + LC-all  Figure 3: Differences in micro-averaged accuracy for various feature combinations on TAC-KBP 2009 data. [sent-149, score-0.122]
</p><p>90 Adding Wikipedia link-based features significantly improves performance over the baseline feature set. [sent-150, score-0.091]
</p><p>91 The Candidate Rank (CR) feature slightly decreases the overall accuracy. [sent-156, score-0.053]
</p><p>92 A manual inspection of the CR feature shows that often candidates cannot be distinguished by the classifier because they are assigned the same PageRank scores. [sent-157, score-0.183]
</p><p>93 We assume this results from our use of uniform priors for the edges and vertices of the document graphs. [sent-158, score-0.083]
</p><p>94 5  Conclusion and Future Work  We presented a supervised approach for named entity disambiguation that explores novel features based on Wikipedia’s link structure. [sent-159, score-0.597]
</p><p>95 These features use NEs co-occurring with an ambiguous surface form in a document and their Wikipedia relations to score the candidates. [sent-160, score-0.618]
</p><p>96 We find that our features improve disambiguation results by 6. [sent-162, score-0.242]
</p><p>97 2% over the popularity baseline, and are especially helpful for recognizing entities not contained in the KB. [sent-163, score-0.22]
</p><p>98 In addition to Wikipedia, we also intend to exploit more dynamical information sources. [sent-167, score-0.062]
</p><p>99 Named entity dis-  ambiguation by leveraging wikipedia semantic knowledge. [sent-203, score-0.551]
</p><p>100 Overview of the tac 2009 knowledge base population track. [sent-208, score-0.176]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('wikipedia', 0.325), ('surface', 0.322), ('kb', 0.311), ('nes', 0.261), ('nil', 0.249), ('entity', 0.226), ('disambiguation', 0.204), ('ned', 0.19), ('mcnamee', 0.166), ('queries', 0.162), ('entities', 0.142), ('candidate', 0.137), ('bow', 0.12), ('redirect', 0.119), ('cr', 0.107), ('ne', 0.093), ('ambiguous', 0.086), ('candidates', 0.083), ('dredze', 0.083), ('forms', 0.083), ('document', 0.083), ('ec', 0.082), ('article', 0.08), ('named', 0.079), ('popularity', 0.078), ('dang', 0.075), ('incoming', 0.07), ('bunescu', 0.07), ('han', 0.07), ('kbs', 0.062), ('uris', 0.062), ('outgoing', 0.062), ('name', 0.06), ('concept', 0.06), ('sfp', 0.055), ('disambiguate', 0.054), ('base', 0.054), ('tac', 0.054), ('pagerank', 0.054), ('feature', 0.053), ('referenced', 0.05), ('titles', 0.05), ('link', 0.05), ('index', 0.047), ('classifier', 0.047), ('zheng', 0.046), ('form', 0.045), ('encyclopedic', 0.045), ('pasca', 0.045), ('relations', 0.044), ('linking', 0.043), ('analogously', 0.043), ('bush', 0.043), ('cucerzan', 0.041), ('favorably', 0.041), ('trang', 0.041), ('brin', 0.041), ('hoa', 0.04), ('similarity', 0.04), ('selection', 0.04), ('razvan', 0.039), ('features', 0.038), ('cos', 0.038), ('page', 0.037), ('knowledge', 0.036), ('organizations', 0.036), ('exploit', 0.035), ('entries', 0.035), ('mention', 0.035), ('inverted', 0.034), ('vectors', 0.034), ('organizing', 0.033), ('law', 0.033), ('disambiguating', 0.032), ('population', 0.032), ('rank', 0.032), ('accuracy', 0.031), ('refer', 0.031), ('paul', 0.031), ('variants', 0.03), ('berlin', 0.03), ('finkel', 0.03), ('graph', 0.03), ('multilingual', 0.03), ('links', 0.029), ('implement', 0.028), ('referring', 0.028), ('detection', 0.028), ('xianpei', 0.027), ('geopolitical', 0.027), ('stratify', 0.027), ('rfa', 0.027), ('dynamical', 0.027), ('eom', 0.027), ('asnd', 0.027), ('cinh', 0.027), ('hypertextual', 0.027), ('itnheed', 0.027), ('otef', 0.027), ('sdet', 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="128-tfidf-1" href="./acl-2011-Exploring_Entity_Relations_for_Named_Entity_Disambiguation.html">128 acl-2011-Exploring Entity Relations for Named Entity Disambiguation</a></p>
<p>Author: Danuta Ploch</p><p>Abstract: Named entity disambiguation is the task of linking an entity mention in a text to the correct real-world referent predefined in a knowledge base, and is a crucial subtask in many areas like information retrieval or topic detection and tracking. Named entity disambiguation is challenging because entity mentions can be ambiguous and an entity can be referenced by different surface forms. We present an approach that exploits Wikipedia relations between entities co-occurring with the ambiguous form to derive a range of novel features for classifying candidate referents. We find that our features improve disambiguation results significantly over a strong popularity baseline, and are especially suitable for recognizing entities not contained in the knowledge base. Our system achieves state-of-the-art results on the TAC-KBP 2009 dataset.</p><p>2 0.34833068 <a title="128-tfidf-2" href="./acl-2011-A_Generative_Entity-Mention_Model_for_Linking_Entities_with_Knowledge_Base.html">12 acl-2011-A Generative Entity-Mention Model for Linking Entities with Knowledge Base</a></p>
<p>Author: Xianpei Han ; Le Sun</p><p>Abstract: Linking entities with knowledge base (entity linking) is a key issue in bridging the textual data with the structural knowledge base. Due to the name variation problem and the name ambiguity problem, the entity linking decisions are critically depending on the heterogenous knowledge of entities. In this paper, we propose a generative probabilistic model, called entitymention model, which can leverage heterogenous entity knowledge (including popularity knowledge, name knowledge and context knowledge) for the entity linking task. In our model, each name mention to be linked is modeled as a sample generated through a three-step generative story, and the entity knowledge is encoded in the distribution of entities in document P(e), the distribution of possible names of a specific entity P(s|e), and the distribution of possible contexts of a specific entity P(c|e). To find the referent entity of a name mention, our method combines the evidences from all the three distributions P(e), P(s|e) and P(c|e). Experimental results show that our method can significantly outperform the traditional methods. 1</p><p>3 0.29705706 <a title="128-tfidf-3" href="./acl-2011-Knowledge_Base_Population%3A_Successful_Approaches_and_Challenges.html">191 acl-2011-Knowledge Base Population: Successful Approaches and Challenges</a></p>
<p>Author: Heng Ji ; Ralph Grishman</p><p>Abstract: In this paper we give an overview of the Knowledge Base Population (KBP) track at the 2010 Text Analysis Conference. The main goal of KBP is to promote research in discovering facts about entities and augmenting a knowledge base (KB) with these facts. This is done through two tasks, Entity Linking linking names in context to entities in the KB and Slot Filling – adding information about an entity to the KB. A large source collection of newswire and web documents is provided from which systems are to discover information. Attributes (“slots”) derived from Wikipedia infoboxes are used to create the reference KB. In this paper we provide an overview of the techniques which can serve as a basis for a good KBP system, lay out the – – remaining challenges by comparison with traditional Information Extraction (IE) and Question Answering (QA) tasks, and provide some suggestions to address these challenges. 1</p><p>4 0.19763778 <a title="128-tfidf-4" href="./acl-2011-Local_and_Global_Algorithms_for_Disambiguation_to_Wikipedia.html">213 acl-2011-Local and Global Algorithms for Disambiguation to Wikipedia</a></p>
<p>Author: Lev Ratinov ; Dan Roth ; Doug Downey ; Mike Anderson</p><p>Abstract: Disambiguating concepts and entities in a context sensitive way is a fundamental problem in natural language processing. The comprehensiveness of Wikipedia has made the online encyclopedia an increasingly popular target for disambiguation. Disambiguation to Wikipedia is similar to a traditional Word Sense Disambiguation task, but distinct in that the Wikipedia link structure provides additional information about which disambiguations are compatible. In this work we analyze approaches that utilize this information to arrive at coherent sets of disambiguations for a given document (which we call “global” approaches), and compare them to more traditional (local) approaches. We show that previous approaches for global disambiguation can be improved, but even then the local disambiguation provides a baseline which is very hard to beat.</p><p>5 0.17805812 <a title="128-tfidf-5" href="./acl-2011-End-to-End_Relation_Extraction_Using_Distant_Supervision_from_External_Semantic_Repositories.html">114 acl-2011-End-to-End Relation Extraction Using Distant Supervision from External Semantic Repositories</a></p>
<p>Author: Truc Vien T. Nguyen ; Alessandro Moschitti</p><p>Abstract: In this paper, we extend distant supervision (DS) based on Wikipedia for Relation Extraction (RE) by considering (i) relations defined in external repositories, e.g. YAGO, and (ii) any subset of Wikipedia documents. We show that training data constituted by sentences containing pairs of named entities in target relations is enough to produce reliable supervision. Our experiments with state-of-the-art relation extraction models, trained on the above data, show a meaningful F1 of 74.29% on a manually annotated test set: this highly improves the state-of-art in RE using DS. Additionally, our end-to-end experiments demonstrated that our extractors can be applied to any general text document.</p><p>6 0.16198599 <a title="128-tfidf-6" href="./acl-2011-Piggyback%3A_Using_Search_Engines_for_Robust_Cross-Domain_Named_Entity_Recognition.html">246 acl-2011-Piggyback: Using Search Engines for Robust Cross-Domain Named Entity Recognition</a></p>
<p>7 0.16195562 <a title="128-tfidf-7" href="./acl-2011-Large-Scale_Cross-Document_Coreference_Using_Distributed_Inference_and_Hierarchical_Models.html">196 acl-2011-Large-Scale Cross-Document Coreference Using Distributed Inference and Hierarchical Models</a></p>
<p>8 0.15884267 <a title="128-tfidf-8" href="./acl-2011-Wikipedia_Revision_Toolkit%3A_Efficiently_Accessing_Wikipedias_Edit_History.html">337 acl-2011-Wikipedia Revision Toolkit: Efficiently Accessing Wikipedias Edit History</a></p>
<p>9 0.13851191 <a title="128-tfidf-9" href="./acl-2011-Simple_supervised_document_geolocation_with_geodesic_grids.html">285 acl-2011-Simple supervised document geolocation with geodesic grids</a></p>
<p>10 0.13602002 <a title="128-tfidf-10" href="./acl-2011-Automatic_Labelling_of_Topic_Models.html">52 acl-2011-Automatic Labelling of Topic Models</a></p>
<p>11 0.12760501 <a title="128-tfidf-11" href="./acl-2011-Neutralizing_Linguistically_Problematic_Annotations_in_Unsupervised_Dependency_Parsing_Evaluation.html">230 acl-2011-Neutralizing Linguistically Problematic Annotations in Unsupervised Dependency Parsing Evaluation</a></p>
<p>12 0.12401186 <a title="128-tfidf-12" href="./acl-2011-Extending_the_Entity_Grid_with_Entity-Specific_Features.html">129 acl-2011-Extending the Entity Grid with Entity-Specific Features</a></p>
<p>13 0.11962568 <a title="128-tfidf-13" href="./acl-2011-Entity_Set_Expansion_using_Topic_information.html">117 acl-2011-Entity Set Expansion using Topic information</a></p>
<p>14 0.11830762 <a title="128-tfidf-14" href="./acl-2011-Jigs_and_Lures%3A_Associating_Web_Queries_with_Structured_Entities.html">181 acl-2011-Jigs and Lures: Associating Web Queries with Structured Entities</a></p>
<p>15 0.10496747 <a title="128-tfidf-15" href="./acl-2011-Semi-supervised_Relation_Extraction_with_Large-scale_Word_Clustering.html">277 acl-2011-Semi-supervised Relation Extraction with Large-scale Word Clustering</a></p>
<p>16 0.09929657 <a title="128-tfidf-16" href="./acl-2011-Search_in_the_Lost_Sense_of_%22Query%22%3A_Question_Formulation_in_Web_Search_Queries_and_its_Temporal_Changes.html">271 acl-2011-Search in the Lost Sense of "Query": Question Formulation in Web Search Queries and its Temporal Changes</a></p>
<p>17 0.098968647 <a title="128-tfidf-17" href="./acl-2011-Simple_English_Wikipedia%3A_A_New_Text_Simplification_Task.html">283 acl-2011-Simple English Wikipedia: A New Text Simplification Task</a></p>
<p>18 0.090137616 <a title="128-tfidf-18" href="./acl-2011-Hierarchical_Reinforcement_Learning_and_Hidden_Markov_Models_for_Task-Oriented_Natural_Language_Generation.html">149 acl-2011-Hierarchical Reinforcement Learning and Hidden Markov Models for Task-Oriented Natural Language Generation</a></p>
<p>19 0.088940226 <a title="128-tfidf-19" href="./acl-2011-Ranking_Class_Labels_Using_Query_Sessions.html">258 acl-2011-Ranking Class Labels Using Query Sessions</a></p>
<p>20 0.086533651 <a title="128-tfidf-20" href="./acl-2011-Language_of_Vandalism%3A_Improving_Wikipedia_Vandalism_Detection_via_Stylometric_Analysis.html">195 acl-2011-Language of Vandalism: Improving Wikipedia Vandalism Detection via Stylometric Analysis</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.21), (1, 0.099), (2, -0.195), (3, 0.092), (4, 0.042), (5, -0.088), (6, 0.008), (7, -0.166), (8, -0.22), (9, 0.001), (10, 0.049), (11, 0.021), (12, -0.094), (13, -0.155), (14, 0.137), (15, 0.087), (16, 0.26), (17, -0.009), (18, 0.006), (19, -0.069), (20, 0.065), (21, -0.098), (22, 0.009), (23, -0.112), (24, 0.131), (25, -0.017), (26, -0.024), (27, -0.033), (28, 0.01), (29, 0.105), (30, -0.044), (31, 0.085), (32, 0.019), (33, 0.026), (34, 0.168), (35, 0.153), (36, -0.03), (37, -0.042), (38, 0.015), (39, -0.005), (40, -0.011), (41, 0.078), (42, -0.089), (43, 0.091), (44, -0.07), (45, 0.058), (46, -0.106), (47, 0.043), (48, 0.036), (49, 0.07)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97319084 <a title="128-lsi-1" href="./acl-2011-Exploring_Entity_Relations_for_Named_Entity_Disambiguation.html">128 acl-2011-Exploring Entity Relations for Named Entity Disambiguation</a></p>
<p>Author: Danuta Ploch</p><p>Abstract: Named entity disambiguation is the task of linking an entity mention in a text to the correct real-world referent predefined in a knowledge base, and is a crucial subtask in many areas like information retrieval or topic detection and tracking. Named entity disambiguation is challenging because entity mentions can be ambiguous and an entity can be referenced by different surface forms. We present an approach that exploits Wikipedia relations between entities co-occurring with the ambiguous form to derive a range of novel features for classifying candidate referents. We find that our features improve disambiguation results significantly over a strong popularity baseline, and are especially suitable for recognizing entities not contained in the knowledge base. Our system achieves state-of-the-art results on the TAC-KBP 2009 dataset.</p><p>2 0.88373154 <a title="128-lsi-2" href="./acl-2011-Local_and_Global_Algorithms_for_Disambiguation_to_Wikipedia.html">213 acl-2011-Local and Global Algorithms for Disambiguation to Wikipedia</a></p>
<p>Author: Lev Ratinov ; Dan Roth ; Doug Downey ; Mike Anderson</p><p>Abstract: Disambiguating concepts and entities in a context sensitive way is a fundamental problem in natural language processing. The comprehensiveness of Wikipedia has made the online encyclopedia an increasingly popular target for disambiguation. Disambiguation to Wikipedia is similar to a traditional Word Sense Disambiguation task, but distinct in that the Wikipedia link structure provides additional information about which disambiguations are compatible. In this work we analyze approaches that utilize this information to arrive at coherent sets of disambiguations for a given document (which we call “global” approaches), and compare them to more traditional (local) approaches. We show that previous approaches for global disambiguation can be improved, but even then the local disambiguation provides a baseline which is very hard to beat.</p><p>3 0.85815799 <a title="128-lsi-3" href="./acl-2011-A_Generative_Entity-Mention_Model_for_Linking_Entities_with_Knowledge_Base.html">12 acl-2011-A Generative Entity-Mention Model for Linking Entities with Knowledge Base</a></p>
<p>Author: Xianpei Han ; Le Sun</p><p>Abstract: Linking entities with knowledge base (entity linking) is a key issue in bridging the textual data with the structural knowledge base. Due to the name variation problem and the name ambiguity problem, the entity linking decisions are critically depending on the heterogenous knowledge of entities. In this paper, we propose a generative probabilistic model, called entitymention model, which can leverage heterogenous entity knowledge (including popularity knowledge, name knowledge and context knowledge) for the entity linking task. In our model, each name mention to be linked is modeled as a sample generated through a three-step generative story, and the entity knowledge is encoded in the distribution of entities in document P(e), the distribution of possible names of a specific entity P(s|e), and the distribution of possible contexts of a specific entity P(c|e). To find the referent entity of a name mention, our method combines the evidences from all the three distributions P(e), P(s|e) and P(c|e). Experimental results show that our method can significantly outperform the traditional methods. 1</p><p>4 0.82388031 <a title="128-lsi-4" href="./acl-2011-Knowledge_Base_Population%3A_Successful_Approaches_and_Challenges.html">191 acl-2011-Knowledge Base Population: Successful Approaches and Challenges</a></p>
<p>Author: Heng Ji ; Ralph Grishman</p><p>Abstract: In this paper we give an overview of the Knowledge Base Population (KBP) track at the 2010 Text Analysis Conference. The main goal of KBP is to promote research in discovering facts about entities and augmenting a knowledge base (KB) with these facts. This is done through two tasks, Entity Linking linking names in context to entities in the KB and Slot Filling – adding information about an entity to the KB. A large source collection of newswire and web documents is provided from which systems are to discover information. Attributes (“slots”) derived from Wikipedia infoboxes are used to create the reference KB. In this paper we provide an overview of the techniques which can serve as a basis for a good KBP system, lay out the – – remaining challenges by comparison with traditional Information Extraction (IE) and Question Answering (QA) tasks, and provide some suggestions to address these challenges. 1</p><p>5 0.72077495 <a title="128-lsi-5" href="./acl-2011-Wikipedia_Revision_Toolkit%3A_Efficiently_Accessing_Wikipedias_Edit_History.html">337 acl-2011-Wikipedia Revision Toolkit: Efficiently Accessing Wikipedias Edit History</a></p>
<p>Author: Oliver Ferschke ; Torsten Zesch ; Iryna Gurevych</p><p>Abstract: We present an open-source toolkit which allows (i) to reconstruct past states of Wikipedia, and (ii) to efficiently access the edit history of Wikipedia articles. Reconstructing past states of Wikipedia is a prerequisite for reproducing previous experimental work based on Wikipedia. Beyond that, the edit history of Wikipedia articles has been shown to be a valuable knowledge source for NLP, but access is severely impeded by the lack of efficient tools for managing the huge amount of provided data. By using a dedicated storage format, our toolkit massively decreases the data volume to less than 2% of the original size, and at the same time provides an easy-to-use interface to access the revision data. The language-independent design allows to process any language represented in Wikipedia. We expect this work to consolidate NLP research using Wikipedia in general, and to foster research making use of the knowledge encoded in Wikipedia’s edit history.</p><p>6 0.57275051 <a title="128-lsi-6" href="./acl-2011-Language_of_Vandalism%3A_Improving_Wikipedia_Vandalism_Detection_via_Stylometric_Analysis.html">195 acl-2011-Language of Vandalism: Improving Wikipedia Vandalism Detection via Stylometric Analysis</a></p>
<p>7 0.56095839 <a title="128-lsi-7" href="./acl-2011-Large-Scale_Cross-Document_Coreference_Using_Distributed_Inference_and_Hierarchical_Models.html">196 acl-2011-Large-Scale Cross-Document Coreference Using Distributed Inference and Hierarchical Models</a></p>
<p>8 0.54964519 <a title="128-lsi-8" href="./acl-2011-Simple_supervised_document_geolocation_with_geodesic_grids.html">285 acl-2011-Simple supervised document geolocation with geodesic grids</a></p>
<p>9 0.52239466 <a title="128-lsi-9" href="./acl-2011-End-to-End_Relation_Extraction_Using_Distant_Supervision_from_External_Semantic_Repositories.html">114 acl-2011-End-to-End Relation Extraction Using Distant Supervision from External Semantic Repositories</a></p>
<p>10 0.50298429 <a title="128-lsi-10" href="./acl-2011-Piggyback%3A_Using_Search_Engines_for_Robust_Cross-Domain_Named_Entity_Recognition.html">246 acl-2011-Piggyback: Using Search Engines for Robust Cross-Domain Named Entity Recognition</a></p>
<p>11 0.47276118 <a title="128-lsi-11" href="./acl-2011-Model-Portability_Experiments_for_Textual_Temporal_Analysis.html">222 acl-2011-Model-Portability Experiments for Textual Temporal Analysis</a></p>
<p>12 0.46702775 <a title="128-lsi-12" href="./acl-2011-Unsupervised_Discovery_of_Domain-Specific_Knowledge_from_Text.html">320 acl-2011-Unsupervised Discovery of Domain-Specific Knowledge from Text</a></p>
<p>13 0.46001315 <a title="128-lsi-13" href="./acl-2011-Extending_the_Entity_Grid_with_Entity-Specific_Features.html">129 acl-2011-Extending the Entity Grid with Entity-Specific Features</a></p>
<p>14 0.45722497 <a title="128-lsi-14" href="./acl-2011-A_Speech-based_Just-in-Time_Retrieval_System_using_Semantic_Search.html">26 acl-2011-A Speech-based Just-in-Time Retrieval System using Semantic Search</a></p>
<p>15 0.41151547 <a title="128-lsi-15" href="./acl-2011-Jigs_and_Lures%3A_Associating_Web_Queries_with_Structured_Entities.html">181 acl-2011-Jigs and Lures: Associating Web Queries with Structured Entities</a></p>
<p>16 0.393929 <a title="128-lsi-16" href="./acl-2011-Exploiting_Syntactico-Semantic_Structures_for_Relation_Extraction.html">126 acl-2011-Exploiting Syntactico-Semantic Structures for Relation Extraction</a></p>
<p>17 0.38958725 <a title="128-lsi-17" href="./acl-2011-Recognizing_Named_Entities_in_Tweets.html">261 acl-2011-Recognizing Named Entities in Tweets</a></p>
<p>18 0.37951979 <a title="128-lsi-18" href="./acl-2011-Wikulu%3A_An_Extensible_Architecture_for_Integrating_Natural_Language_Processing_Techniques_with_Wikis.html">338 acl-2011-Wikulu: An Extensible Architecture for Integrating Natural Language Processing Techniques with Wikis</a></p>
<p>19 0.37072766 <a title="128-lsi-19" href="./acl-2011-Local_Histograms_of_Character_N-grams_for_Authorship_Attribution.html">212 acl-2011-Local Histograms of Character N-grams for Authorship Attribution</a></p>
<p>20 0.36919054 <a title="128-lsi-20" href="./acl-2011-The_ACL_Anthology_Searchbench.html">298 acl-2011-The ACL Anthology Searchbench</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.024), (8, 0.165), (9, 0.017), (17, 0.028), (26, 0.033), (31, 0.011), (37, 0.111), (39, 0.078), (41, 0.07), (53, 0.033), (55, 0.045), (59, 0.058), (61, 0.012), (72, 0.026), (91, 0.038), (96, 0.134), (97, 0.011), (98, 0.032)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.88467658 <a title="128-lda-1" href="./acl-2011-Terminal-Aware_Synchronous_Binarization.html">296 acl-2011-Terminal-Aware Synchronous Binarization</a></p>
<p>Author: Licheng Fang ; Tagyoung Chung ; Daniel Gildea</p><p>Abstract: We present an SCFG binarization algorithm that combines the strengths of early terminal matching on the source language side and early language model integration on the target language side. We also examine how different strategies of target-side terminal attachment during binarization can significantly affect translation quality.</p><p>same-paper 2 0.85480899 <a title="128-lda-2" href="./acl-2011-Exploring_Entity_Relations_for_Named_Entity_Disambiguation.html">128 acl-2011-Exploring Entity Relations for Named Entity Disambiguation</a></p>
<p>Author: Danuta Ploch</p><p>Abstract: Named entity disambiguation is the task of linking an entity mention in a text to the correct real-world referent predefined in a knowledge base, and is a crucial subtask in many areas like information retrieval or topic detection and tracking. Named entity disambiguation is challenging because entity mentions can be ambiguous and an entity can be referenced by different surface forms. We present an approach that exploits Wikipedia relations between entities co-occurring with the ambiguous form to derive a range of novel features for classifying candidate referents. We find that our features improve disambiguation results significantly over a strong popularity baseline, and are especially suitable for recognizing entities not contained in the knowledge base. Our system achieves state-of-the-art results on the TAC-KBP 2009 dataset.</p><p>3 0.80942571 <a title="128-lda-3" href="./acl-2011-A_Bayesian_Model_for_Unsupervised_Semantic_Parsing.html">3 acl-2011-A Bayesian Model for Unsupervised Semantic Parsing</a></p>
<p>Author: Ivan Titov ; Alexandre Klementiev</p><p>Abstract: We propose a non-parametric Bayesian model for unsupervised semantic parsing. Following Poon and Domingos (2009), we consider a semantic parsing setting where the goal is to (1) decompose the syntactic dependency tree of a sentence into fragments, (2) assign each of these fragments to a cluster of semantically equivalent syntactic structures, and (3) predict predicate-argument relations between the fragments. We use hierarchical PitmanYor processes to model statistical dependencies between meaning representations of predicates and those of their arguments, as well as the clusters of their syntactic realizations. We develop a modification of the MetropolisHastings split-merge sampler, resulting in an efficient inference algorithm for the model. The method is experimentally evaluated by us- ing the induced semantic representation for the question answering task in the biomedical domain.</p><p>4 0.76196575 <a title="128-lda-4" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>Author: Joel Lang ; Mirella Lapata</p><p>Abstract: In this paper we describe an unsupervised method for semantic role induction which holds promise for relieving the data acquisition bottleneck associated with supervised role labelers. We present an algorithm that iteratively splits and merges clusters representing semantic roles, thereby leading from an initial clustering to a final clustering of better quality. The method is simple, surprisingly effective, and allows to integrate linguistic knowledge transparently. By combining role induction with a rule-based component for argument identification we obtain an unsupervised end-to-end semantic role labeling system. Evaluation on the CoNLL 2008 benchmark dataset demonstrates that our method outperforms competitive unsupervised approaches by a wide margin.</p><p>5 0.76094878 <a title="128-lda-5" href="./acl-2011-Scaling_up_Automatic_Cross-Lingual_Semantic_Role_Annotation.html">269 acl-2011-Scaling up Automatic Cross-Lingual Semantic Role Annotation</a></p>
<p>Author: Lonneke van der Plas ; Paola Merlo ; James Henderson</p><p>Abstract: Broad-coverage semantic annotations for training statistical learners are only available for a handful of languages. Previous approaches to cross-lingual transfer of semantic annotations have addressed this problem with encouraging results on a small scale. In this paper, we scale up previous efforts by using an automatic approach to semantic annotation that does not rely on a semantic ontology for the target language. Moreover, we improve the quality of the transferred semantic annotations by using a joint syntacticsemantic parser that learns the correlations between syntax and semantics of the target language and smooths out the errors from automatic transfer. We reach a labelled F-measure for predicates and arguments of only 4% and 9% points, respectively, lower than the upper bound from manual annotations.</p><p>6 0.7584359 <a title="128-lda-6" href="./acl-2011-Shift-Reduce_CCG_Parsing.html">282 acl-2011-Shift-Reduce CCG Parsing</a></p>
<p>7 0.75757122 <a title="128-lda-7" href="./acl-2011-A_Comparison_of_Loopy_Belief_Propagation_and_Dual_Decomposition_for_Integrated_CCG_Supertagging_and_Parsing.html">5 acl-2011-A Comparison of Loopy Belief Propagation and Dual Decomposition for Integrated CCG Supertagging and Parsing</a></p>
<p>8 0.75752771 <a title="128-lda-8" href="./acl-2011-Beam-Width_Prediction_for_Efficient_Context-Free_Parsing.html">58 acl-2011-Beam-Width Prediction for Efficient Context-Free Parsing</a></p>
<p>9 0.75473964 <a title="128-lda-9" href="./acl-2011-Improving_Arabic_Dependency_Parsing_with_Form-based_and_Functional_Morphological_Features.html">164 acl-2011-Improving Arabic Dependency Parsing with Form-based and Functional Morphological Features</a></p>
<p>10 0.75320011 <a title="128-lda-10" href="./acl-2011-Exploiting_Syntactico-Semantic_Structures_for_Relation_Extraction.html">126 acl-2011-Exploiting Syntactico-Semantic Structures for Relation Extraction</a></p>
<p>11 0.75252342 <a title="128-lda-11" href="./acl-2011-Learning_Hierarchical_Translation_Structure_with_Linguistic_Annotations.html">202 acl-2011-Learning Hierarchical Translation Structure with Linguistic Annotations</a></p>
<p>12 0.75251317 <a title="128-lda-12" href="./acl-2011-Piggyback%3A_Using_Search_Engines_for_Robust_Cross-Domain_Named_Entity_Recognition.html">246 acl-2011-Piggyback: Using Search Engines for Robust Cross-Domain Named Entity Recognition</a></p>
<p>13 0.75213134 <a title="128-lda-13" href="./acl-2011-Using_Bilingual_Parallel_Corpora_for_Cross-Lingual_Textual_Entailment.html">327 acl-2011-Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment</a></p>
<p>14 0.75063741 <a title="128-lda-14" href="./acl-2011-The_Surprising_Variance_in_Shortest-Derivation_Parsing.html">300 acl-2011-The Surprising Variance in Shortest-Derivation Parsing</a></p>
<p>15 0.75050908 <a title="128-lda-15" href="./acl-2011-Unsupervised_Part-of-Speech_Tagging_with_Bilingual_Graph-Based_Projections.html">323 acl-2011-Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</a></p>
<p>16 0.75031096 <a title="128-lda-16" href="./acl-2011-Subjectivity_and_Sentiment_Analysis_of_Modern_Standard_Arabic.html">289 acl-2011-Subjectivity and Sentiment Analysis of Modern Standard Arabic</a></p>
<p>17 0.75030625 <a title="128-lda-17" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<p>18 0.75020576 <a title="128-lda-18" href="./acl-2011-Fine-Grained_Class_Label_Markup_of_Search_Queries.html">137 acl-2011-Fine-Grained Class Label Markup of Search Queries</a></p>
<p>19 0.74969167 <a title="128-lda-19" href="./acl-2011-Evaluating_the_Impact_of_Coder_Errors_on_Active_Learning.html">119 acl-2011-Evaluating the Impact of Coder Errors on Active Learning</a></p>
<p>20 0.74823701 <a title="128-lda-20" href="./acl-2011-Joint_Annotation_of_Search_Queries.html">182 acl-2011-Joint Annotation of Search Queries</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
