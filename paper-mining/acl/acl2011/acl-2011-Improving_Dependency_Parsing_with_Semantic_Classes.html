<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>167 acl-2011-Improving Dependency Parsing with Semantic Classes</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-167" href="#">acl2011-167</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>167 acl-2011-Improving Dependency Parsing with Semantic Classes</h1>
<br/><p>Source: <a title="acl-2011-167-pdf" href="http://aclweb.org/anthology//P/P11/P11-2123.pdf">pdf</a></p><p>Author: Eneko Agirre ; Kepa Bengoetxea ; Koldo Gojenola ; Joakim Nivre</p><p>Abstract: This paper presents the introduction of WordNet semantic classes in a dependency parser, obtaining improvements on the full Penn Treebank for the first time. We tried different combinations of some basic semantic classes and word sense disambiguation algorithms. Our experiments show that selecting the adequate combination of semantic features on development data is key for success. Given the basic nature of the semantic classes and word sense disambiguation algorithms used, we think there is ample room for future improvements. 1</p><p>Reference: <a title="acl-2011-167-reference" href="../acl2011_reference/acl-2011-Improving_Dependency_Parsing_with_Semantic_Classes_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 +  Abstract This paper presents the introduction of WordNet semantic classes in a dependency parser, obtaining improvements on the full Penn Treebank for the first time. [sent-8, score-0.737]
</p><p>2 We tried different combinations of some basic semantic classes and word sense disambiguation algorithms. [sent-9, score-0.725]
</p><p>3 Our experiments show that selecting the adequate combination of semantic features on development data is key for success. [sent-10, score-0.366]
</p><p>4 Given the basic nature of the semantic classes and word sense disambiguation algorithms used, we think there is ample room for future improvements. [sent-11, score-0.704]
</p><p>5 In principle, dependency parsing offers good prospects for experimenting with word-to-word-semantic relationships. [sent-14, score-0.354]
</p><p>6 We present a set of experiments using semantic classes in dependency parsing of the Penn Treebank (PTB). [sent-15, score-0.706]
</p><p>7 (2008), who used different types of semantic information, obtaining significant improvements in two constituency parsers, showing how semantic information helps in constituency parsing. [sent-17, score-0.743]
</p><p>8 We will evaluate the parser on both the full PTB (Marcus et al. [sent-19, score-0.201]
</p><p>9 1993) and on a sense699  annotated subset of the Brown Corpus portion of PTB, in order to investigate the upper bound performance of the models given gold-standard sense information, as in Agirre et al. [sent-20, score-0.293]
</p><p>10 (2008) trained two state-of-the-art sta-  tistical parsers (Charniak, 2000; Bikel, 2004) on semantically-enriched input, where content words had been substituted with their semantic classes. [sent-23, score-0.325]
</p><p>11 This was done trying to overcome the limitations of lexicalized approaches to parsing (Magerman, 1995; Collins, 1996; Charniak, 1997; Collins, 2003), where related words, like scissors and knife cannot be generalized. [sent-24, score-0.275]
</p><p>12 This simple method allowed incorporating lexical semantic information into the parser. [sent-25, score-0.323]
</p><p>13 They tested the parsers in both a full parsing and a PP attachment context. [sent-26, score-0.472]
</p><p>14 The experiments showed that semantic classes gave significant improvement relative to the baseline, demonstrating that a simplistic approach to incorporating lexical semantics into a parser significantly improves its performance. [sent-27, score-0.548]
</p><p>15 This work presented the first results over both WordNet and the Penn Treebank to show that semantic processing helps parsing. [sent-28, score-0.273]
</p><p>16 Collins (2000) tested a combined parsing/word sense disambiguation model based in WordNet which did not obtain improvements in parsing. [sent-29, score-0.379]
</p><p>17 (2008) presented a semisupervised method for training dependency parsers, using word clusters derived from a large unannotated corpus as features. [sent-31, score-0.255]
</p><p>18 They demonstrate the effectiveness of the approach in a series of dependency  parsing experiments on PTB and the Prague Dependency Treebank, showing that the cluster-based features yield substantial gains in performance across a wide range of conditions. [sent-32, score-0.449]
</p><p>19 i ac t2io0n11 fo Ar Cssoocmiaptuiotanti foonra Clo Lminpguutiast i ocns:aslh Loirntpgaupisetrics , pages 699–703, Ciaramita and Attardi (2007) show that adding semantic features extracted by a named entity tagger (such as PERSON or MONEY) improves the accuracy of a dependency parser, yielding a 5. [sent-37, score-0.47]
</p><p>20 Candito and Seddah (2010) performed experiments in statistical parsing of French, where terminal forms were replaced by more general symbols, particularly clusters of words obtained through unsupervised clustering. [sent-39, score-0.214]
</p><p>21 The results showed that word clusters had a positive effect. [sent-40, score-0.057]
</p><p>22 Regarding dependency parsing of the English PTB, currently Koo and Collins (2010) and Zhang and Nivre (201 1) hold the best results, with 93. [sent-41, score-0.315]
</p><p>23 Apart from these, there have been other attempts to make use of semantic information in different frameworks and languages, as in (Hektoen 1997; Xiong et al. [sent-45, score-0.273]
</p><p>24 3  Experimental Framework  In this section we will briefly describe the datadriven parser used for the experiments (subsection 3 . [sent-48, score-0.107]
</p><p>25 Finally, we will describe the types of semantic representation used in the experiments. [sent-51, score-0.326]
</p><p>26 2006) is a trainable dependency parser that has been successfully applied to typologically different languages and treebanks. [sent-54, score-0.265]
</p><p>27 The parser obtains deterministically a dependency tree in linear-time in a single pass over the input using two main data structures: a stack of partially analyzed items and the remaining input sequence. [sent-57, score-0.265]
</p><p>28 To determine the best action at each step, the parser uses history-based feature models and SVM classifiers. [sent-58, score-0.107]
</p><p>29 One of the main reasons for using MaltParser for our experiments is that it easily allows the introduction of semantic informa-  tion, adding new features, and incorporating them in the training model. [sent-59, score-0.323]
</p><p>30 2  Dataset  We used two different datasets: the full PTB and the Semcor/PTB intersection (Agirre et al. [sent-61, score-0.153]
</p><p>31 700 The full PTB allows for comparison with the stateof-the-art, and we followed the usual train-test split. [sent-63, score-0.094]
</p><p>32 The Semcor/PTB intersection contains both gold-standard sense and parse tree annotations, and allows to set an upper bound of the relative impact of a given semantic representation on parsing. [sent-64, score-0.678]
</p><p>33 We will evaluate the parser via Labeled Attachment Score (LAS). [sent-68, score-0.107]
</p><p>34 We will use Bikel’s randomized parsing evaluation comparator to test the statistical significance of the results using word sense information, relative to the respective baseline parser using only standard features. [sent-69, score-0.501]
</p><p>35 We used PennConverter (Johansson and  Nugues, 2007) to convert constituent trees in the Penn Treebank annotation style into dependency trees. [sent-70, score-0.158]
</p><p>36 Although in general the results from parsing Pennconverter’s output are lower than with other conversions, Johansson and Nugues (2007) claim that this conversion is better suited for semantic processing, with a richer structure and a more finegrained set of dependency labels. [sent-71, score-0.634]
</p><p>37 3  Semantic representation and disambiguation methods  We will experiment with the range of semantic representations used in Agirre et al. [sent-75, score-0.402]
</p><p>38 Words in WordNet (Fellbaum, 1998) are organized into sets of synonyms, called synsets (SS). [sent-78, score-0.103]
</p><p>39 Each synset in turn belongs to a unique semantic file (SF). [sent-79, score-0.417]
</p><p>40 There are a total of 45 SFs (1 for adverbs, 3 for adjectives, 15 for verbs, and 26 for nouns), based on syntactic and semantic categories. [sent-80, score-0.273]
</p><p>41 For example, noun semantic files (SF_N) differentiate nouns denoting acts or actions, and nouns denoting animals, among others. [sent-81, score-0.562]
</p><p>42 We experiment with both full syn-  sets and SFs as instances of fine-grained and coarse-grained semantic representation, respectively. [sent-82, score-0.367]
</p><p>43 As an example of the difference in these two representations, knife in its tool sense is in the EDGE TOOL USED AS A CUTTING INSTRUMENT singleton synset, and also in the ARTIFACT SF along with thousands of other words including cutter. [sent-83, score-0.316]
</p><p>44 Note that these are the two extremes of semantic granularity in WordNet. [sent-84, score-0.273]
</p><p>45 As a hybrid representation, we also tested the effect of merging words with their corresponding SF (e. [sent-85, score-0.054]
</p><p>46 This is a form of semantic specialization rather than generalization, and allows the parser to discriminate between the different senses of each word, but not generalize across words. [sent-88, score-0.478]
</p><p>47 For each of these three semantic representations, we experimented with using each of: (1) all open-class POSs (nouns, verbs, adjectives and adverbs), (2) nouns only, and (3) verbs only. [sent-89, score-0.395]
</p><p>48 There are thus a total of 9 combinations of representation type and target POS: SS (synset), SS_N (noun synsets), SS_V (verb synsets), SF (semantic file), SF_N (noun semantic files), SF_V (verb semantic files), WSF (wordform+SF), WSF_N (wordform+SF for nouns) and WSF_V (for verbs). [sent-90, score-0.659]
</p><p>49 For a given semantic representation, we need some form of WSD to determine the semantics of  each token occurrence of a target word. [sent-91, score-0.273]
</p><p>50 For the full Penn Treebank experiments, we only had access to the first sense, taken from Wordnet 1. [sent-94, score-0.094]
</p><p>51 4  Results  In the following two subsections, we will first present the results in the SemCor/PTB intersection, with the option of using gold, 1st sense and automatic sense information (subsection 4. [sent-96, score-0.396]
</p><p>52 2) will show the results on the full PTB, using 1st sense information. [sent-98, score-0.292]
</p><p>53 All results are shown as labelled attachment score (LAS). [sent-99, score-0.115]
</p><p>54 1 Semcor/PTB (GOLD/1ST/ASR) We conducted a series of experiments testing: • Each individual semantic feature, which gives 9 possibilities, also testing different  learning configurations for each one. [sent-101, score-0.367]
</p><p>55 •  Combinations of semantic features, for instance, SF+SS_N+WSF would combine the 701 System  LAS  Semcor-Penn intersection. [sent-102, score-0.273]
</p><p>56 Although there were hundreds of combinations, we took the best combination of semantic features on the development set for the final test. [sent-107, score-0.366]
</p><p>57 For that reason, the table only presents 10 results for each disambiguation method, 9 for the individual features and one for the best combination. [sent-108, score-0.211]
</p><p>58 Table 1 presents the results obtained for each of the disambiguation methods (gold standard sense information, 1st sense, and automatic sense ranking) and individual semantic feature. [sent-109, score-0.841]
</p><p>59 In all cases except two, the use of semantic classes is benefiSystem  LAS  set for the full PTB. [sent-110, score-0.485]
</p><p>60 Regarding individual features, the SF feature using GOLD senses gives the best im-  provement. [sent-115, score-0.112]
</p><p>61 Regarding the best combination as selected in the training data, each WSD method yields a different combination, with best results for 1ST. [sent-118, score-0.054]
</p><p>62 The improvement is statistically significant for both 1ST and GOLD. [sent-119, score-0.056]
</p><p>63 The best results are obtained when using the first sense heuristic, but the difference is not statistically significant. [sent-121, score-0.254]
</p><p>64 This shows that perfect WSD is not needed to obtain improvements, but it also shows that we reached the upperbound of our generalization and learning method. [sent-122, score-0.039]
</p><p>65 2  Penn Treebank and 1st sense  We only had 1st sense information available for the full PTB. [sent-124, score-0.49]
</p><p>66 We tested MaltParser on the best configuration obtained for the reduced Semcor/PTB on the full treebank, taking sections 2-21 for training and section 23 for the final test. [sent-125, score-0.148]
</p><p>67 Table 2 presents the results, showing that several of the individual features and the best combination give  significant improvements. [sent-126, score-0.243]
</p><p>68 To our knowledge, this is the first time that WordNet semantic classes help to obtain improvements on the full Penn Treebank. [sent-127, score-0.536]
</p><p>69 702 It is interesting to mention that, although not shown on the tables, using lemmatization to assign semantic classes to wordforms gave a slight increase for all the tests (0. [sent-128, score-0.456]
</p><p>70 This can be seen as an argument in favour of performing morphological analysis, an aspect that is many times neglected when processing morphologically poor languages as English. [sent-131, score-0.039]
</p><p>71 5  Conclusions  We tested the inclusion of several types of semantic information, in the form of WordNet semantic classes in a dependency parser, showing that: • Semantic information gives an improvement  on a transition-based deterministic dependency parsing. [sent-134, score-1.088]
</p><p>72 • Feature combinations give an improvement over using a single feature. [sent-135, score-0.06]
</p><p>73 (2008) used a simple method of substituting wordforms with semantic information, which only allowed using a single semantic feature. [sent-137, score-0.611]
</p><p>74 MaltParser allows the combination of several semantic features together with other features such as wordform, lemma or part of speech. [sent-138, score-0.405]
</p><p>75 Although tables 1 and 2 only show the best combination for each type of semantic information, this can be appreciated on GOLD and 1ST in Table 1. [sent-139, score-0.366]
</p><p>76 Due to space reasons, we only have showed the best combination, but we can say that in general combining features gives significant increases over using a single semantic feature. [sent-140, score-0.312]
</p><p>77 • The present work presents a statistically significant improvement for the full treebank using WordNet-based semantic information for the first time. [sent-141, score-0.582]
</p><p>78 (2008), which showed improvements on a subset of the PTB. [sent-143, score-0.051]
</p><p>79 Given the basic nature of the semantic classes  and WSD algorithms, we think there is room for future improvements, incorporating new kinds of semantic information, such as WordNet base concepts, Wikipedia concepts, or similarity measures. [sent-144, score-0.753]
</p><p>80 Improving parsing and PP attachment performance with sense information. [sent-147, score-0.47]
</p><p>81 Statistical parsing with a context-free grammar and word statistics. [sent-167, score-0.157]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('semantic', 0.273), ('agirre', 0.257), ('sf', 0.223), ('ptb', 0.206), ('sense', 0.198), ('wordnet', 0.168), ('dependency', 0.158), ('parsing', 0.157), ('maltparser', 0.15), ('wordform', 0.145), ('wsd', 0.144), ('nivre', 0.134), ('koo', 0.12), ('knife', 0.118), ('pennconverter', 0.118), ('classes', 0.118), ('penn', 0.118), ('treebank', 0.116), ('attachment', 0.115), ('parser', 0.107), ('synsets', 0.103), ('las', 0.1), ('subsection', 0.1), ('full', 0.094), ('johansson', 0.092), ('bengoetxea', 0.09), ('koldo', 0.09), ('sfs', 0.09), ('wsf', 0.09), ('joakim', 0.082), ('asr', 0.081), ('synset', 0.079), ('nugues', 0.079), ('kepa', 0.079), ('disambiguation', 0.076), ('nouns', 0.074), ('collins', 0.071), ('fujita', 0.068), ('bikel', 0.068), ('file', 0.065), ('wordforms', 0.065), ('ciaramita', 0.065), ('candito', 0.062), ('fellbaum', 0.061), ('gold', 0.06), ('combinations', 0.06), ('intersection', 0.059), ('senses', 0.059), ('eneko', 0.058), ('mccarthy', 0.058), ('clusters', 0.057), ('statistically', 0.056), ('files', 0.055), ('showing', 0.054), ('combination', 0.054), ('tested', 0.054), ('representation', 0.053), ('individual', 0.053), ('christiane', 0.053), ('artifact', 0.053), ('parsers', 0.052), ('ratnaparkhi', 0.051), ('improvements', 0.051), ('carreras', 0.05), ('incorporating', 0.05), ('regarding', 0.049), ('xavier', 0.049), ('xiong', 0.049), ('bound', 0.048), ('verbs', 0.048), ('upper', 0.047), ('terry', 0.047), ('conversion', 0.046), ('constituency', 0.046), ('adverbs', 0.045), ('michael', 0.043), ('presents', 0.043), ('denoting', 0.043), ('suzuki', 0.043), ('series', 0.041), ('semisupervised', 0.04), ('neglected', 0.039), ('appreciated', 0.039), ('magerman', 0.039), ('upperbound', 0.039), ('wordnetbased', 0.039), ('nodalida', 0.039), ('tartu', 0.039), ('conversions', 0.039), ('semcor', 0.039), ('bler', 0.039), ('comparator', 0.039), ('ehu', 0.039), ('ingfi', 0.039), ('oakim', 0.039), ('prospects', 0.039), ('seddah', 0.039), ('specialization', 0.039), ('features', 0.039), ('room', 0.039)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999946 <a title="167-tfidf-1" href="./acl-2011-Improving_Dependency_Parsing_with_Semantic_Classes.html">167 acl-2011-Improving Dependency Parsing with Semantic Classes</a></p>
<p>Author: Eneko Agirre ; Kepa Bengoetxea ; Koldo Gojenola ; Joakim Nivre</p><p>Abstract: This paper presents the introduction of WordNet semantic classes in a dependency parser, obtaining improvements on the full Penn Treebank for the first time. We tried different combinations of some basic semantic classes and word sense disambiguation algorithms. Our experiments show that selecting the adequate combination of semantic features on development data is key for success. Given the basic nature of the semantic classes and word sense disambiguation algorithms used, we think there is ample room for future improvements. 1</p><p>2 0.26870847 <a title="167-tfidf-2" href="./acl-2011-Transition-based_Dependency_Parsing_with_Rich_Non-local_Features.html">309 acl-2011-Transition-based Dependency Parsing with Rich Non-local Features</a></p>
<p>Author: Yue Zhang ; Joakim Nivre</p><p>Abstract: Transition-based dependency parsers generally use heuristic decoding algorithms but can accommodate arbitrarily rich feature representations. In this paper, we show that we can improve the accuracy of such parsers by considering even richer feature sets than those employed in previous systems. In the standard Penn Treebank setup, our novel features improve attachment score form 91.4% to 92.9%, giving the best results so far for transitionbased parsing and rivaling the best results overall. For the Chinese Treebank, they give a signficant improvement of the state of the art. An open source release of our parser is freely available.</p><p>3 0.22067755 <a title="167-tfidf-3" href="./acl-2011-Getting_the_Most_out_of_Transition-based_Dependency_Parsing.html">143 acl-2011-Getting the Most out of Transition-based Dependency Parsing</a></p>
<p>Author: Jinho D. Choi ; Martha Palmer</p><p>Abstract: This paper suggests two ways of improving transition-based, non-projective dependency parsing. First, we add a transition to an existing non-projective parsing algorithm, so it can perform either projective or non-projective parsing as needed. Second, we present a bootstrapping technique that narrows down discrepancies between gold-standard and automatic parses used as features. The new addition to the algorithm shows a clear advantage in parsing speed. The bootstrapping technique gives a significant improvement to parsing accuracy, showing near state-of-theart performance with respect to other parsing approaches evaluated on the same data set.</p><p>4 0.21446702 <a title="167-tfidf-4" href="./acl-2011-An_Ensemble_Model_that_Combines_Syntactic_and_Semantic_Clustering_for_Discriminative_Dependency_Parsing.html">39 acl-2011-An Ensemble Model that Combines Syntactic and Semantic Clustering for Discriminative Dependency Parsing</a></p>
<p>Author: Gholamreza Haffari ; Marzieh Razavi ; Anoop Sarkar</p><p>Abstract: We combine multiple word representations based on semantic clusters extracted from the (Brown et al., 1992) algorithm and syntactic clusters obtained from the Berkeley parser (Petrov et al., 2006) in order to improve discriminative dependency parsing in the MSTParser framework (McDonald et al., 2005). We also provide an ensemble method for combining diverse cluster-based models. The two contributions together significantly improves unlabeled dependency accuracy from 90.82% to 92. 13%.</p><p>5 0.21030551 <a title="167-tfidf-5" href="./acl-2011-Latent_Semantic_Word_Sense_Induction_and_Disambiguation.html">198 acl-2011-Latent Semantic Word Sense Induction and Disambiguation</a></p>
<p>Author: Tim Van de Cruys ; Marianna Apidianaki</p><p>Abstract: In this paper, we present a unified model for the automatic induction of word senses from text, and the subsequent disambiguation of particular word instances using the automatically extracted sense inventory. The induction step and the disambiguation step are based on the same principle: words and contexts are mapped to a limited number of topical dimensions in a latent semantic word space. The intuition is that a particular sense is associated with a particular topic, so that different senses can be discriminated through their association with particular topical dimensions; in a similar vein, a particular instance of a word can be disambiguated by determining its most important topical dimensions. The model is evaluated on the SEMEVAL-20 10 word sense induction and disambiguation task, on which it reaches stateof-the-art results.</p><p>6 0.19808505 <a title="167-tfidf-6" href="./acl-2011-Effects_of_Noun_Phrase_Bracketing_in_Dependency_Parsing_and_Machine_Translation.html">111 acl-2011-Effects of Noun Phrase Bracketing in Dependency Parsing and Machine Translation</a></p>
<p>7 0.17858665 <a title="167-tfidf-7" href="./acl-2011-ParaSense_or_How_to_Use_Parallel_Corpora_for_Word_Sense_Disambiguation.html">240 acl-2011-ParaSense or How to Use Parallel Corpora for Word Sense Disambiguation</a></p>
<p>8 0.17412752 <a title="167-tfidf-8" href="./acl-2011-Exploiting_Web-Derived_Selectional_Preference_to_Improve_Statistical_Dependency_Parsing.html">127 acl-2011-Exploiting Web-Derived Selectional Preference to Improve Statistical Dependency Parsing</a></p>
<p>9 0.17270699 <a title="167-tfidf-9" href="./acl-2011-Identification_of_Domain-Specific_Senses_in_a_Machine-Readable_Dictionary.html">158 acl-2011-Identification of Domain-Specific Senses in a Machine-Readable Dictionary</a></p>
<p>10 0.15779623 <a title="167-tfidf-10" href="./acl-2011-Web-Scale_Features_for_Full-Scale_Parsing.html">333 acl-2011-Web-Scale Features for Full-Scale Parsing</a></p>
<p>11 0.14962822 <a title="167-tfidf-11" href="./acl-2011-Scaling_up_Automatic_Cross-Lingual_Semantic_Role_Annotation.html">269 acl-2011-Scaling up Automatic Cross-Lingual Semantic Role Annotation</a></p>
<p>12 0.14623202 <a title="167-tfidf-12" href="./acl-2011-Shift-Reduce_CCG_Parsing.html">282 acl-2011-Shift-Reduce CCG Parsing</a></p>
<p>13 0.14585529 <a title="167-tfidf-13" href="./acl-2011-A_Bayesian_Model_for_Unsupervised_Semantic_Parsing.html">3 acl-2011-A Bayesian Model for Unsupervised Semantic Parsing</a></p>
<p>14 0.14385183 <a title="167-tfidf-14" href="./acl-2011-Automatic_Detection_and_Correction_of_Errors_in_Dependency_Treebanks.html">48 acl-2011-Automatic Detection and Correction of Errors in Dependency Treebanks</a></p>
<p>15 0.13065855 <a title="167-tfidf-15" href="./acl-2011-Neutralizing_Linguistically_Problematic_Annotations_in_Unsupervised_Dependency_Parsing_Evaluation.html">230 acl-2011-Neutralizing Linguistically Problematic Annotations in Unsupervised Dependency Parsing Evaluation</a></p>
<p>16 0.13045168 <a title="167-tfidf-16" href="./acl-2011-Improving_Arabic_Dependency_Parsing_with_Form-based_and_Functional_Morphological_Features.html">164 acl-2011-Improving Arabic Dependency Parsing with Form-based and Functional Morphological Features</a></p>
<p>17 0.12277687 <a title="167-tfidf-17" href="./acl-2011-Models_and_Training_for_Unsupervised_Preposition_Sense_Disambiguation.html">224 acl-2011-Models and Training for Unsupervised Preposition Sense Disambiguation</a></p>
<p>18 0.11812057 <a title="167-tfidf-18" href="./acl-2011-Towards_Tracking_Semantic_Change_by_Visual_Analytics.html">307 acl-2011-Towards Tracking Semantic Change by Visual Analytics</a></p>
<p>19 0.11709217 <a title="167-tfidf-19" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>20 0.11471716 <a title="167-tfidf-20" href="./acl-2011-Together_We_Can%3A_Bilingual_Bootstrapping_for_WSD.html">304 acl-2011-Together We Can: Bilingual Bootstrapping for WSD</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.259), (1, -0.02), (2, -0.131), (3, -0.291), (4, -0.039), (5, -0.056), (6, 0.165), (7, 0.104), (8, 0.052), (9, -0.059), (10, 0.052), (11, -0.111), (12, 0.143), (13, -0.135), (14, -0.034), (15, -0.129), (16, 0.14), (17, 0.073), (18, -0.043), (19, 0.039), (20, -0.048), (21, -0.003), (22, -0.051), (23, 0.034), (24, 0.079), (25, -0.09), (26, 0.041), (27, -0.085), (28, -0.073), (29, 0.028), (30, -0.025), (31, -0.004), (32, 0.01), (33, 0.018), (34, 0.049), (35, 0.014), (36, 0.019), (37, -0.012), (38, 0.043), (39, 0.054), (40, -0.014), (41, 0.027), (42, -0.029), (43, 0.052), (44, 0.018), (45, 0.038), (46, 0.016), (47, 0.02), (48, 0.039), (49, -0.005)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97168469 <a title="167-lsi-1" href="./acl-2011-Improving_Dependency_Parsing_with_Semantic_Classes.html">167 acl-2011-Improving Dependency Parsing with Semantic Classes</a></p>
<p>Author: Eneko Agirre ; Kepa Bengoetxea ; Koldo Gojenola ; Joakim Nivre</p><p>Abstract: This paper presents the introduction of WordNet semantic classes in a dependency parser, obtaining improvements on the full Penn Treebank for the first time. We tried different combinations of some basic semantic classes and word sense disambiguation algorithms. Our experiments show that selecting the adequate combination of semantic features on development data is key for success. Given the basic nature of the semantic classes and word sense disambiguation algorithms used, we think there is ample room for future improvements. 1</p><p>2 0.77441514 <a title="167-lsi-2" href="./acl-2011-An_Ensemble_Model_that_Combines_Syntactic_and_Semantic_Clustering_for_Discriminative_Dependency_Parsing.html">39 acl-2011-An Ensemble Model that Combines Syntactic and Semantic Clustering for Discriminative Dependency Parsing</a></p>
<p>Author: Gholamreza Haffari ; Marzieh Razavi ; Anoop Sarkar</p><p>Abstract: We combine multiple word representations based on semantic clusters extracted from the (Brown et al., 1992) algorithm and syntactic clusters obtained from the Berkeley parser (Petrov et al., 2006) in order to improve discriminative dependency parsing in the MSTParser framework (McDonald et al., 2005). We also provide an ensemble method for combining diverse cluster-based models. The two contributions together significantly improves unlabeled dependency accuracy from 90.82% to 92. 13%.</p><p>3 0.76120204 <a title="167-lsi-3" href="./acl-2011-Getting_the_Most_out_of_Transition-based_Dependency_Parsing.html">143 acl-2011-Getting the Most out of Transition-based Dependency Parsing</a></p>
<p>Author: Jinho D. Choi ; Martha Palmer</p><p>Abstract: This paper suggests two ways of improving transition-based, non-projective dependency parsing. First, we add a transition to an existing non-projective parsing algorithm, so it can perform either projective or non-projective parsing as needed. Second, we present a bootstrapping technique that narrows down discrepancies between gold-standard and automatic parses used as features. The new addition to the algorithm shows a clear advantage in parsing speed. The bootstrapping technique gives a significant improvement to parsing accuracy, showing near state-of-theart performance with respect to other parsing approaches evaluated on the same data set.</p><p>4 0.76117647 <a title="167-lsi-4" href="./acl-2011-Transition-based_Dependency_Parsing_with_Rich_Non-local_Features.html">309 acl-2011-Transition-based Dependency Parsing with Rich Non-local Features</a></p>
<p>Author: Yue Zhang ; Joakim Nivre</p><p>Abstract: Transition-based dependency parsers generally use heuristic decoding algorithms but can accommodate arbitrarily rich feature representations. In this paper, we show that we can improve the accuracy of such parsers by considering even richer feature sets than those employed in previous systems. In the standard Penn Treebank setup, our novel features improve attachment score form 91.4% to 92.9%, giving the best results so far for transitionbased parsing and rivaling the best results overall. For the Chinese Treebank, they give a signficant improvement of the state of the art. An open source release of our parser is freely available.</p><p>5 0.75997329 <a title="167-lsi-5" href="./acl-2011-Neutralizing_Linguistically_Problematic_Annotations_in_Unsupervised_Dependency_Parsing_Evaluation.html">230 acl-2011-Neutralizing Linguistically Problematic Annotations in Unsupervised Dependency Parsing Evaluation</a></p>
<p>Author: Roy Schwartz ; Omri Abend ; Roi Reichart ; Ari Rappoport</p><p>Abstract: Dependency parsing is a central NLP task. In this paper we show that the common evaluation for unsupervised dependency parsing is highly sensitive to problematic annotations. We show that for three leading unsupervised parsers (Klein and Manning, 2004; Cohen and Smith, 2009; Spitkovsky et al., 2010a), a small set of parameters can be found whose modification yields a significant improvement in standard evaluation measures. These parameters correspond to local cases where no linguistic consensus exists as to the proper gold annotation. Therefore, the standard evaluation does not provide a true indication of algorithm quality. We present a new measure, Neutral Edge Direction (NED), and show that it greatly reduces this undesired phenomenon.</p><p>6 0.75883466 <a title="167-lsi-6" href="./acl-2011-Exploiting_Web-Derived_Selectional_Preference_to_Improve_Statistical_Dependency_Parsing.html">127 acl-2011-Exploiting Web-Derived Selectional Preference to Improve Statistical Dependency Parsing</a></p>
<p>7 0.74538064 <a title="167-lsi-7" href="./acl-2011-Effects_of_Noun_Phrase_Bracketing_in_Dependency_Parsing_and_Machine_Translation.html">111 acl-2011-Effects of Noun Phrase Bracketing in Dependency Parsing and Machine Translation</a></p>
<p>8 0.71954876 <a title="167-lsi-8" href="./acl-2011-Latent_Semantic_Word_Sense_Induction_and_Disambiguation.html">198 acl-2011-Latent Semantic Word Sense Induction and Disambiguation</a></p>
<p>9 0.66872746 <a title="167-lsi-9" href="./acl-2011-Automatic_Detection_and_Correction_of_Errors_in_Dependency_Treebanks.html">48 acl-2011-Automatic Detection and Correction of Errors in Dependency Treebanks</a></p>
<p>10 0.65990621 <a title="167-lsi-10" href="./acl-2011-Web-Scale_Features_for_Full-Scale_Parsing.html">333 acl-2011-Web-Scale Features for Full-Scale Parsing</a></p>
<p>11 0.61677712 <a title="167-lsi-11" href="./acl-2011-Partial_Parsing_from_Bitext_Projections.html">243 acl-2011-Partial Parsing from Bitext Projections</a></p>
<p>12 0.61327463 <a title="167-lsi-12" href="./acl-2011-Optimistic_Backtracking_-_A_Backtracking_Overlay_for_Deterministic_Incremental_Parsing.html">236 acl-2011-Optimistic Backtracking - A Backtracking Overlay for Deterministic Incremental Parsing</a></p>
<p>13 0.61055332 <a title="167-lsi-13" href="./acl-2011-Towards_Tracking_Semantic_Change_by_Visual_Analytics.html">307 acl-2011-Towards Tracking Semantic Change by Visual Analytics</a></p>
<p>14 0.60991096 <a title="167-lsi-14" href="./acl-2011-Dynamic_Programming_Algorithms_for_Transition-Based_Dependency_Parsers.html">107 acl-2011-Dynamic Programming Algorithms for Transition-Based Dependency Parsers</a></p>
<p>15 0.60794169 <a title="167-lsi-15" href="./acl-2011-Temporal_Restricted_Boltzmann_Machines_for_Dependency_Parsing.html">295 acl-2011-Temporal Restricted Boltzmann Machines for Dependency Parsing</a></p>
<p>16 0.5935083 <a title="167-lsi-16" href="./acl-2011-NULEX%3A_An_Open-License_Broad_Coverage_Lexicon.html">229 acl-2011-NULEX: An Open-License Broad Coverage Lexicon</a></p>
<p>17 0.58931583 <a title="167-lsi-17" href="./acl-2011-Which_Noun_Phrases_Denote_Which_Concepts%3F.html">334 acl-2011-Which Noun Phrases Denote Which Concepts?</a></p>
<p>18 0.58574086 <a title="167-lsi-18" href="./acl-2011-Shift-Reduce_CCG_Parsing.html">282 acl-2011-Shift-Reduce CCG Parsing</a></p>
<p>19 0.57033247 <a title="167-lsi-19" href="./acl-2011-Better_Automatic_Treebank_Conversion_Using_A_Feature-Based_Approach.html">59 acl-2011-Better Automatic Treebank Conversion Using A Feature-Based Approach</a></p>
<p>20 0.56116557 <a title="167-lsi-20" href="./acl-2011-Identification_of_Domain-Specific_Senses_in_a_Machine-Readable_Dictionary.html">158 acl-2011-Identification of Domain-Specific Senses in a Machine-Readable Dictionary</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.018), (17, 0.039), (37, 0.135), (39, 0.064), (41, 0.071), (55, 0.024), (59, 0.074), (72, 0.022), (91, 0.031), (96, 0.1), (97, 0.359)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.87449682 <a title="167-lda-1" href="./acl-2011-Types_of_Common-Sense_Knowledge_Needed_for_Recognizing_Textual_Entailment.html">315 acl-2011-Types of Common-Sense Knowledge Needed for Recognizing Textual Entailment</a></p>
<p>Author: Peter LoBue ; Alexander Yates</p><p>Abstract: Understanding language requires both linguistic knowledge and knowledge about how the world works, also known as common-sense knowledge. We attempt to characterize the kinds of common-sense knowledge most often involved in recognizing textual entailments. We identify 20 categories of common-sense knowledge that are prevalent in textual entailment, many of which have received scarce attention from researchers building collections of knowledge.</p><p>same-paper 2 0.76657665 <a title="167-lda-2" href="./acl-2011-Improving_Dependency_Parsing_with_Semantic_Classes.html">167 acl-2011-Improving Dependency Parsing with Semantic Classes</a></p>
<p>Author: Eneko Agirre ; Kepa Bengoetxea ; Koldo Gojenola ; Joakim Nivre</p><p>Abstract: This paper presents the introduction of WordNet semantic classes in a dependency parser, obtaining improvements on the full Penn Treebank for the first time. We tried different combinations of some basic semantic classes and word sense disambiguation algorithms. Our experiments show that selecting the adequate combination of semantic features on development data is key for success. Given the basic nature of the semantic classes and word sense disambiguation algorithms used, we think there is ample room for future improvements. 1</p><p>3 0.74318099 <a title="167-lda-3" href="./acl-2011-A_Discriminative_Model_for_Joint_Morphological_Disambiguation_and_Dependency_Parsing.html">10 acl-2011-A Discriminative Model for Joint Morphological Disambiguation and Dependency Parsing</a></p>
<p>Author: John Lee ; Jason Naradowsky ; David A. Smith</p><p>Abstract: Most previous studies of morphological disambiguation and dependency parsing have been pursued independently. Morphological taggers operate on n-grams and do not take into account syntactic relations; parsers use the “pipeline” approach, assuming that morphological information has been separately obtained. However, in morphologically-rich languages, there is often considerable interaction between morphology and syntax, such that neither can be disambiguated without the other. In this paper, we propose a discriminative model that jointly infers morphological properties and syntactic structures. In evaluations on various highly-inflected languages, this joint model outperforms both a baseline tagger in morphological disambiguation, and a pipeline parser in head selection.</p><p>4 0.69078553 <a title="167-lda-4" href="./acl-2011-Why_Press_Backspace%3F_Understanding_User_Input_Behaviors_in_Chinese_Pinyin_Input_Method.html">336 acl-2011-Why Press Backspace? Understanding User Input Behaviors in Chinese Pinyin Input Method</a></p>
<p>Author: Yabin Zheng ; Lixing Xie ; Zhiyuan Liu ; Maosong Sun ; Yang Zhang ; Liyun Ru</p><p>Abstract: Chinese Pinyin input method is very important for Chinese language information processing. Users may make errors when they are typing in Chinese words. In this paper, we are concerned with the reasons that cause the errors. Inspired by the observation that pressing backspace is one of the most common user behaviors to modify the errors, we collect 54, 309, 334 error-correction pairs from a realworld data set that contains 2, 277, 786 users via backspace operations. In addition, we present a comparative analysis of the data to achieve a better understanding of users’ input behaviors. Comparisons with English typos suggest that some language-specific properties result in a part of Chinese input errors. 1</p><p>5 0.63712871 <a title="167-lda-5" href="./acl-2011-A_Hierarchical_Model_of_Web_Summaries.html">14 acl-2011-A Hierarchical Model of Web Summaries</a></p>
<p>Author: Yves Petinot ; Kathleen McKeown ; Kapil Thadani</p><p>Abstract: We investigate the relevance of hierarchical topic models to represent the content of Web gists. We focus our attention on DMOZ, a popular Web directory, and propose two algorithms to infer such a model from its manually-curated hierarchy of categories. Our first approach, based on information-theoretic grounds, uses an algorithm similar to recursive feature selection. Our second approach is fully Bayesian and derived from the more general model, hierarchical LDA. We evaluate the performance of both models against a flat 1-gram baseline and show improvements in terms of perplexity over held-out data.</p><p>6 0.57704419 <a title="167-lda-6" href="./acl-2011-Identification_of_Domain-Specific_Senses_in_a_Machine-Readable_Dictionary.html">158 acl-2011-Identification of Domain-Specific Senses in a Machine-Readable Dictionary</a></p>
<p>7 0.57246584 <a title="167-lda-7" href="./acl-2011-Improving_Arabic_Dependency_Parsing_with_Form-based_and_Functional_Morphological_Features.html">164 acl-2011-Improving Arabic Dependency Parsing with Form-based and Functional Morphological Features</a></p>
<p>8 0.54356164 <a title="167-lda-8" href="./acl-2011-NULEX%3A_An_Open-License_Broad_Coverage_Lexicon.html">229 acl-2011-NULEX: An Open-License Broad Coverage Lexicon</a></p>
<p>9 0.53424668 <a title="167-lda-9" href="./acl-2011-Transition-based_Dependency_Parsing_with_Rich_Non-local_Features.html">309 acl-2011-Transition-based Dependency Parsing with Rich Non-local Features</a></p>
<p>10 0.524903 <a title="167-lda-10" href="./acl-2011-Effects_of_Noun_Phrase_Bracketing_in_Dependency_Parsing_and_Machine_Translation.html">111 acl-2011-Effects of Noun Phrase Bracketing in Dependency Parsing and Machine Translation</a></p>
<p>11 0.52077675 <a title="167-lda-11" href="./acl-2011-Together_We_Can%3A_Bilingual_Bootstrapping_for_WSD.html">304 acl-2011-Together We Can: Bilingual Bootstrapping for WSD</a></p>
<p>12 0.51721728 <a title="167-lda-12" href="./acl-2011-Model-Portability_Experiments_for_Textual_Temporal_Analysis.html">222 acl-2011-Model-Portability Experiments for Textual Temporal Analysis</a></p>
<p>13 0.50743318 <a title="167-lda-13" href="./acl-2011-A_Corpus_for_Modeling_Morpho-Syntactic_Agreement_in_Arabic%3A_Gender%2C_Number_and_Rationality.html">7 acl-2011-A Corpus for Modeling Morpho-Syntactic Agreement in Arabic: Gender, Number and Rationality</a></p>
<p>14 0.50265592 <a title="167-lda-14" href="./acl-2011-Coreference_Resolution_with_World_Knowledge.html">85 acl-2011-Coreference Resolution with World Knowledge</a></p>
<p>15 0.49869946 <a title="167-lda-15" href="./acl-2011-A_Graph_Approach_to_Spelling_Correction_in_Domain-Centric_Search.html">13 acl-2011-A Graph Approach to Spelling Correction in Domain-Centric Search</a></p>
<p>16 0.4981724 <a title="167-lda-16" href="./acl-2011-Part-of-Speech_Tagging_for_Twitter%3A_Annotation%2C_Features%2C_and_Experiments.html">242 acl-2011-Part-of-Speech Tagging for Twitter: Annotation, Features, and Experiments</a></p>
<p>17 0.49801621 <a title="167-lda-17" href="./acl-2011-Subjectivity_and_Sentiment_Analysis_of_Modern_Standard_Arabic.html">289 acl-2011-Subjectivity and Sentiment Analysis of Modern Standard Arabic</a></p>
<p>18 0.49047488 <a title="167-lda-18" href="./acl-2011-Latent_Semantic_Word_Sense_Induction_and_Disambiguation.html">198 acl-2011-Latent Semantic Word Sense Induction and Disambiguation</a></p>
<p>19 0.48771203 <a title="167-lda-19" href="./acl-2011-That%27s_What_She_Said%3A_Double_Entendre_Identification.html">297 acl-2011-That's What She Said: Double Entendre Identification</a></p>
<p>20 0.4862538 <a title="167-lda-20" href="./acl-2011-Unsupervised_Discovery_of_Domain-Specific_Knowledge_from_Text.html">320 acl-2011-Unsupervised Discovery of Domain-Specific Knowledge from Text</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
