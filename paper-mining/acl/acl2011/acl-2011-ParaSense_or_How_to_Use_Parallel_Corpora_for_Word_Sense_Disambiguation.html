<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>240 acl-2011-ParaSense or How to Use Parallel Corpora for Word Sense Disambiguation</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-240" href="#">acl2011-240</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>240 acl-2011-ParaSense or How to Use Parallel Corpora for Word Sense Disambiguation</h1>
<br/><p>Source: <a title="acl-2011-240-pdf" href="http://aclweb.org/anthology//P/P11/P11-2055.pdf">pdf</a></p><p>Author: Els Lefever ; Veronique Hoste ; Martine De Cock</p><p>Abstract: This paper describes a set of exploratory experiments for a multilingual classificationbased approach to Word Sense Disambiguation. Instead of using a predefined monolingual sense-inventory such as WordNet, we use a language-independent framework where the word senses are derived automatically from word alignments on a parallel corpus. We built five classifiers with English as an input language and translations in the five supported languages (viz. French, Dutch, Italian, Spanish and German) as classification output. The feature vectors incorporate both the more traditional local context features, as well as binary bag-of-words features that are extracted from the aligned translations. Our results show that the ParaSense multilingual WSD system shows very competitive results compared to the best systems that were evaluated on the SemEval-2010 Cross-Lingual Word Sense Disambiguation task for all five target languages.</p><p>Reference: <a title="acl-2011-240-reference" href="../acl2011_reference/acl-2011-ParaSense_or_How_to_Use_Parallel_Corpora_for_Word_Sense_Disambiguation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 of Linguistics, Ghent University Blandijnberg 2, 9000 Gent, Belgium  Abstract This paper describes a set of exploratory experiments for a multilingual classificationbased approach to Word Sense Disambiguation. [sent-3, score-0.186]
</p><p>2 Instead of using a predefined monolingual sense-inventory such as WordNet, we use a language-independent framework where the word senses are derived automatically from word alignments on a parallel corpus. [sent-4, score-0.416]
</p><p>3 We built five classifiers with English as an input language and translations in the five supported languages (viz. [sent-5, score-0.364]
</p><p>4 The feature vectors incorporate both the more traditional local context features, as well as binary bag-of-words features that are extracted from the aligned translations. [sent-7, score-0.373]
</p><p>5 Our results show that the ParaSense multilingual WSD system shows very competitive results compared to the best systems that were evaluated  on the SemEval-2010 Cross-Lingual Word Sense Disambiguation task for all five target languages. [sent-8, score-0.24]
</p><p>6 1 Introduction Word Sense Disambiguation (WSD) is the NLP task that consists in selecting the correct sense of a polysemous word in a given context. [sent-9, score-0.317]
</p><p>7 Most stateof-the-art WSD systems are supervised classifiers that are trained on manually sense-tagged corpora, which are very time-consuming and expensive to build (Agirre and Edmonds, 2006) . [sent-10, score-0.055]
</p><p>8 In order to overcome this acquisition bottleneck (sense-tagged corpora are scarce for languages other than English), we decided to take a multilingual approach to WSD, that builds up the sense inventory on the basis of the Europarl parallel corpus (Koehn, 2005). [sent-11, score-0.823]
</p><p>9 Using 317 translations from a parallel corpus implicitly deals with the granularity problem as finer sense distinctions are only relevant as far as they are lexicalized in the target translations. [sent-12, score-0.49]
</p><p>10 It also facilitates the integration of WSD in multilingual applications such as multilingual Information Retrieval (IR) or Ma-  chine Translation (MT). [sent-13, score-0.41]
</p><p>11 Both papers describe the integration of a dedicated WSD module in a Chinese-English statistical machine translation framework and report statistically significant improvements in terms of standard MT evaluation metrics. [sent-16, score-0.183]
</p><p>12 Several studies have already shown the validity of using parallel corpora for sense discrimination (e. [sent-17, score-0.481]
</p><p>13 , 2003; Diab and Resnik, 2002; Chan and Ng, 2005; Dagan and Itai, 1994)) and for WSD systems that use a combination of existing WordNets with multilingual evidence (Tufi s¸ et al. [sent-23, score-0.229]
</p><p>14 The research described in this paper is novel as it presents a truly multilingual classification-based approach to WSD that directly incorporates evidence from four other languages. [sent-25, score-0.229]
</p><p>15 The task is a lexical sample task for twenty English ambiguous nouns that consists in assigning a correct translation in the five supported target languages (viz. [sent-31, score-0.387]
</p><p>16 French, Italian, Spanish, German and Dutch) for an ambiguous focus word in a given context. [sent-32, score-0.178]
</p><p>17 In order to detect the relevant translations for each of the twenty ambiguous focus words, we ran GIZA++ (Och and Ney, 2003) with its default settings for all focus words. [sent-33, score-0.374]
</p><p>18 This word alignment output was then considered to be the label for  the training instances for the corresponding classifier (e. [sent-34, score-0.231]
</p><p>19 the Dutch translation is the label that is used to train the Dutch classifier). [sent-36, score-0.114]
</p><p>20 By considering this word alignment output as oracle information, we redefined the CLWSD task as a classification task. [sent-37, score-0.151]
</p><p>21 We performed heuristic experiments to define the parameter settings for the classifier, leading to the selection of the Jeffrey Divergence distance metric, Gain Ratio feature weighting and k = 7 as number of nearest neighbours. [sent-40, score-0.097]
</p><p>22 In future work, we plan to use an optimized word-expert approach in which a genetic algorithm performs joint feature selection and parameter optimization per ambiguous word (Daelemans et al. [sent-41, score-0.324]
</p><p>23 For our feature vector creation, we combined a set of English local context features and a set of binary bag-of-words features that were extracted from the  aligned translations. [sent-43, score-0.428]
</p><p>24 The first training set incorporates the automatically generated word alignments as labels. [sent-46, score-0.113]
</p><p>25 We applied an automatic post-processing step on these word alignments in order to remove leading and trailing determiners and 318 prepositions. [sent-47, score-0.113]
</p><p>26 In future work, we will investigate other word alignment strategies and measure the impact on the classification scores. [sent-48, score-0.121]
</p><p>27 The second training set uses manually verified word alignments as labels for the training instances. [sent-49, score-0.152]
</p><p>28 All English sentences were preprocessed by means of a memory-based shallow parser (MBSP) (Daelemans and van den Bosch, 2005) that performs tokenization, Part-of-Speech tagging and text chunking. [sent-51, score-0.198]
</p><p>29 for the Dutch classifier, we extract bag-of-words features from the Italian, Spanish, French and German aligned translations). [sent-54, score-0.17]
</p><p>30 In order to extract useful content words, we first ran Part-of-Speech tagging and lemmatisation by means ofthe Treetagger (Schmid, 1994) tool. [sent-55, score-0.033]
</p><p>31 Per ambiguous focus word, a list of content words (nouns, adjectives, verbs and adverbs) was extracted that occurred in the aligned translations of the English sentences containing the focus word. [sent-56, score-0.422]
</p><p>32 One binary feature per selected content word was then created per ambiguous word: ‘0’ in case the word does not occur in the aligned translation of this instance,  and ‘ 1’ in case the word does occur in the aligned translation of the training instance. [sent-57, score-0.801]
</p><p>33 2 Test Feature Vector Construction For the creation of the feature vectors for the test instances, we follow a similar strategy as the one we used for the creation of the training instances. [sent-59, score-0.161]
</p><p>34 The first part of the feature vector contains the English local context features that were also extracted for the training instances. [sent-60, score-0.223]
</p><p>35 For the construction of the bag-of-words features however, we need to adopt a different approach as we do not have aligned translations for the English test instances at our disposal. [sent-61, score-0.406]
</p><p>36 We decided to deploy a novel strategy that uses the Google Translate API1 to automatically generate a translation for all English test instances in the five supported languages. [sent-62, score-0.275]
</p><p>37 Online machine translations tools have already been used before to create artificial parallel corpora that were used for NLP tasks such as for instance Named Entity Recognition (Shah et al. [sent-63, score-0.329]
</p><p>38 In a next step the automatically generated translation was preprocessed in the same way as the training translations (Part-of-Speech-tagged and lemmatized). [sent-65, score-0.311]
</p><p>39 The resulting lemmas were then used to con-  struct the same set of binary bag-of-words features that were stored for the training instances of the ambiguous focus word. [sent-66, score-0.264]
</p><p>40 3  Evaluation  To evaluate our five classifiers, we used the sense inventory and test set of the SemEval “Cross-Lingual Word Sense Disambiguation” task. [sent-67, score-0.334]
</p><p>41 The sense inventory was built up on the basis of the Europarl corpus: all retrieved translations of a polysemous word were manually grouped into clusters, which constitute different senses of that given word. [sent-68, score-0.581]
</p><p>42 The test instances were selected from the JRC-ACQUIS Multilingual Parallel Corpus2 and BNC3. [sent-69, score-0.045]
</p><p>43 To label the test data, native speakers provided their top three translations from the predefined clusters ofEuroparl translations, in order to assign frequency weights to the set of gold standard translations. [sent-70, score-0.145]
</p><p>44 A more detailed description of the construction of the data set can be found in Lefever and Hoste (2010a). [sent-71, score-0.046]
</p><p>45 As evaluation metrics, we used both the SemEval BEST precision metric from the CLWSD task as well as a straightforward accuracy measure. [sent-72, score-0.032]
</p><p>46 The SemEval metric takes into account the frequency  weights of the gold standard translations: translations that were picked by different annotators get a higher weight. [sent-73, score-0.177]
</p><p>47 uk/ 319 can propose as many guesses as the system believes are correct, but the resulting score is divided by the number of guesses. [sent-82, score-0.075]
</p><p>48 In this way, systems that output a lot of guesses are not favoured. [sent-83, score-0.075]
</p><p>49 Let H be the set of annotators, T the set oftest items and hi the set of responses for an item i ∈ T for annotator thh ∈ eHt. [sent-86, score-0.065]
</p><p>50 o fL rete sAp o bnes tehse f soert a onf iitteemms i f ∈ro mT fTo rw ahnenreot tahteo system provides at lteheas ste one answer raonmd ai : i ∈ A the set of guesses from the system for item: ii. [sent-87, score-0.075]
</p><p>51 ∈Fo Ar e thaech s i, we gcuaelcsuselsate fr othme mthuelt siyssette muni foonr (Hi) for all hi for all h ∈ H and for each unique type (res) in Hi rth aallt hhas ∈ an a asnsodc fioatred ea frequency (freqres). [sent-88, score-0.065]
</p><p>52 Pres∈ai freqres  Prec =Pai:i∈A|A|||Haii||  (1)  The second metric we use is a straightforward accuracy measure, that divides the number of correct answers by the total amount of test instances. [sent-89, score-0.101]
</p><p>53 As a baseline, we selected the most frequent lemmatized translation that resulted from the automated word alignment (GIZA++). [sent-90, score-0.275]
</p><p>54 We also compare our results with the two winning SemEval-2 systems for the Cross-Lingual Word Sense Disambiguation task, UvT-WSD (that only participated for Dutch and Spanish) and T3-COLEUR. [sent-91, score-0.05]
</p><p>55 The UvT-WSD system (van Gompel, 2010), that also uses a k-nearest neighbor classifier and a variety of local and global context features, obtained the best scores for Spanish and Dutch in the SemEval CLWSD competition. [sent-92, score-0.168]
</p><p>56 Although we also use a memory-based learner, our method is different from this system in the way the feature vectors are constructed. [sent-93, score-0.065]
</p><p>57 Next to the incorporation of similar local context features, we also include evidence from multiple languages in our feature vector. [sent-94, score-0.267]
</p><p>58 This system adopts a different approach: during the training phase a monolingual WSD system processes the English input sentence and a word alignment module is used to extract the aligned translation. [sent-96, score-0.337]
</p><p>59 The English senses together with their aligned translations (and probability scores) are then stored in a word sense translation table, in which look-ups are performed during the testing phase. [sent-97, score-0.706]
</p><p>60 This system also differs from the Uvt-WSD and ParaSense systems in the sense that the word senses are derived from WordNet, whereas the other systems do not use any external resources. [sent-98, score-0.332]
</p><p>61 The results for all five classifiers are listed in two tables. [sent-99, score-0.109]
</p><p>62 For both setups we trained three flavors of the ParaSense system (1: local context + translation features, 2: translation features and 3: local context features). [sent-102, score-0.66]
</p><p>63 The classification results show that for both setups all three flavors of the ParaSense system easily beat the baseline. [sent-103, score-0.171]
</p><p>64 Moreover, the ParaSense system clearly outperforms the winning SemEval systems, except for Spanish where the scores are similar. [sent-104, score-0.05]
</p><p>65 the two SemEval systems as well as the three flavors of the ParaSense system, were trained on the same Europarl data, the scores illustrate the potential advantages of using a multilingual approach. [sent-106, score-0.29]
</p><p>66 For Dutch, the classifier that merely uses translation features even outperforms the classifier that uses the local context features. [sent-108, score-0.402]
</p><p>67 In previous research (Lefever and Hoste, 2011), we showed that the classifier using evidence  from all different languages was constantly better than the ones using less or no multilingual evidence. [sent-109, score-0.35]
</p><p>68 In addition, the scores also degraded relatively to the number of translation features that was used. [sent-110, score-0.169]
</p><p>69 As we used a different set of translation features for the latter pilot experiments (we only used the translations of the ambiguous words instead of the full bag-ofwords features we used for the current setup), we 320 need to confirm this trend with more experiments using the current feature sets. [sent-111, score-0.53]
</p><p>70 Another important observation is that the classification scores degrade when using the automatically generated word alignments, but only to a minor extent. [sent-112, score-0.049]
</p><p>71 Further experiments with different word alignment settings and symmetrisation methods should allow us to further improve the results with the automatically generated word alignments. [sent-114, score-0.17]
</p><p>72 Using the nonvalidated labels makes the system very flexible and language-independent, as all steps in the feature vector creation can be run automatically. [sent-115, score-0.113]
</p><p>73 4  Conclusion  We presented preliminary results for a multilingual classification-based approach to Word Sense Disambiguation. [sent-116, score-0.186]
</p><p>74 In addition to the commonly used monolingual local context features, we also incorporate bag-of-word features that are built from the aligned translations. [sent-117, score-0.343]
</p><p>75 Although there is still a lot of room for improvement on the feature base, our results show that the ParaSense system clearly outperforms state-of-the-art systems for all languages, except for Spanish where the results are very similar. [sent-118, score-0.065]
</p><p>76 As all steps are run automatically, this multilingual approach could be an answer for the acquisition bottleneck, as long as there are parallel corpora available for the targeted languages. [sent-119, score-0.37]
</p><p>77 Although large multilingual corpora are still rather scarce, we strongly believe there will be more parallel corpora available in the near future (large companies and organizations disposing of large quantities of parallel text, internet corpora such as the ever growing Wikipedia corpus, etc. [sent-120, score-0.615]
</p><p>78 Another line of research could be the exploitation of comparable corpora to acquire additional training data. [sent-122, score-0.061]
</p><p>79 In future work, we want to run additional experiments with different classifiers (SVM) and apply  a genetic algorithm to perform joint feature selection, parameter optimization and instance selection. [sent-123, score-0.202]
</p><p>80 We also plan to expand our feature set by including global context features (content words from the English sentence) and to examine the relationship between the performance and the number (and nature) of languages that is added to the feature vector. [sent-124, score-0.277]
</p><p>81 In addition, we will apply semantic analysis tools (such  as LSA) on our multilingual bag-of-words sets in order to detect latent semantic topics in the multilingual feature base. [sent-125, score-0.437]
</p><p>82 Finally, we want to evaluate to which extent the integration of our WSD output  helps practical applications such as Machine Translation or Information Retrieval. [sent-126, score-0.038]
</p><p>83 Combined optimization of feature selection and algorithm parameters in machine learning of language. [sent-178, score-0.135]
</p><p>84 Word sense disambiguation using a second language monolingual corpus. [sent-184, score-0.43]
</p><p>85 Exploiting parallel texts for word sense disambiguation: An empirical study. [sent-265, score-0.394]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('wsd', 0.356), ('parasense', 0.311), ('semeval', 0.245), ('sense', 0.222), ('lefever', 0.207), ('hoste', 0.196), ('multilingual', 0.186), ('dutch', 0.167), ('daelemans', 0.151), ('translations', 0.145), ('clwsd', 0.138), ('disambiguation', 0.138), ('parallel', 0.123), ('aligned', 0.115), ('translation', 0.114), ('spanish', 0.107), ('flavors', 0.104), ('gent', 0.104), ('ghent', 0.104), ('tufi', 0.104), ('italian', 0.099), ('ambiguous', 0.096), ('europarl', 0.084), ('chan', 0.077), ('guesses', 0.075), ('belgium', 0.075), ('alignment', 0.072), ('monolingual', 0.07), ('freqres', 0.069), ('diab', 0.069), ('local', 0.067), ('setups', 0.067), ('twenty', 0.067), ('classifier', 0.065), ('hi', 0.065), ('feature', 0.065), ('alignments', 0.064), ('corpora', 0.061), ('senses', 0.061), ('eurowordnet', 0.061), ('vossen', 0.061), ('french', 0.06), ('inventory', 0.058), ('den', 0.057), ('van', 0.056), ('carpuat', 0.056), ('shah', 0.056), ('languages', 0.056), ('classifiers', 0.055), ('features', 0.055), ('five', 0.054), ('edmonds', 0.053), ('preprocessed', 0.052), ('winning', 0.05), ('word', 0.049), ('creation', 0.048), ('construction', 0.046), ('polysemous', 0.046), ('instances', 0.045), ('mccarthy', 0.044), ('genetic', 0.044), ('evidence', 0.043), ('german', 0.043), ('wordnet', 0.043), ('bottleneck', 0.043), ('ide', 0.043), ('scarce', 0.042), ('guo', 0.042), ('ng', 0.042), ('valletta', 0.041), ('agirre', 0.04), ('dagan', 0.04), ('lemmatized', 0.04), ('english', 0.039), ('verified', 0.039), ('discrimination', 0.039), ('integration', 0.038), ('optimization', 0.038), ('mt', 0.037), ('context', 0.036), ('validity', 0.036), ('uppsala', 0.035), ('binary', 0.035), ('chunk', 0.034), ('tagging', 0.033), ('focus', 0.033), ('lemma', 0.032), ('metric', 0.032), ('decided', 0.032), ('selection', 0.032), ('module', 0.031), ('gale', 0.031), ('martine', 0.03), ('redefined', 0.03), ('norwell', 0.03), ('eronique', 0.03), ('deploy', 0.03), ('pai', 0.03), ('gompel', 0.03), ('tof', 0.03)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999893 <a title="240-tfidf-1" href="./acl-2011-ParaSense_or_How_to_Use_Parallel_Corpora_for_Word_Sense_Disambiguation.html">240 acl-2011-ParaSense or How to Use Parallel Corpora for Word Sense Disambiguation</a></p>
<p>Author: Els Lefever ; Veronique Hoste ; Martine De Cock</p><p>Abstract: This paper describes a set of exploratory experiments for a multilingual classificationbased approach to Word Sense Disambiguation. Instead of using a predefined monolingual sense-inventory such as WordNet, we use a language-independent framework where the word senses are derived automatically from word alignments on a parallel corpus. We built five classifiers with English as an input language and translations in the five supported languages (viz. French, Dutch, Italian, Spanish and German) as classification output. The feature vectors incorporate both the more traditional local context features, as well as binary bag-of-words features that are extracted from the aligned translations. Our results show that the ParaSense multilingual WSD system shows very competitive results compared to the best systems that were evaluated on the SemEval-2010 Cross-Lingual Word Sense Disambiguation task for all five target languages.</p><p>2 0.22120477 <a title="240-tfidf-2" href="./acl-2011-Latent_Semantic_Word_Sense_Induction_and_Disambiguation.html">198 acl-2011-Latent Semantic Word Sense Induction and Disambiguation</a></p>
<p>Author: Tim Van de Cruys ; Marianna Apidianaki</p><p>Abstract: In this paper, we present a unified model for the automatic induction of word senses from text, and the subsequent disambiguation of particular word instances using the automatically extracted sense inventory. The induction step and the disambiguation step are based on the same principle: words and contexts are mapped to a limited number of topical dimensions in a latent semantic word space. The intuition is that a particular sense is associated with a particular topic, so that different senses can be discriminated through their association with particular topical dimensions; in a similar vein, a particular instance of a word can be disambiguated by determining its most important topical dimensions. The model is evaluated on the SEMEVAL-20 10 word sense induction and disambiguation task, on which it reaches stateof-the-art results.</p><p>3 0.18120423 <a title="240-tfidf-3" href="./acl-2011-Rare_Word_Translation_Extraction_from_Aligned_Comparable_Documents.html">259 acl-2011-Rare Word Translation Extraction from Aligned Comparable Documents</a></p>
<p>Author: Emmanuel Prochasson ; Pascale Fung</p><p>Abstract: We present a first known result of high precision rare word bilingual extraction from comparable corpora, using aligned comparable documents and supervised classification. We incorporate two features, a context-vector similarity and a co-occurrence model between words in aligned documents in a machine learning approach. We test our hypothesis on different pairs of languages and corpora. We obtain very high F-Measure between 80% and 98% for recognizing and extracting correct translations for rare terms (from 1to 5 occurrences). Moreover, we show that our system can be trained on a pair of languages and test on a different pair of languages, obtaining a F-Measure of 77% for the classification of Chinese-English translations using a training corpus of Spanish-French. Our method is therefore even potentially applicable to low resources languages without training data.</p><p>4 0.17858665 <a title="240-tfidf-4" href="./acl-2011-Improving_Dependency_Parsing_with_Semantic_Classes.html">167 acl-2011-Improving Dependency Parsing with Semantic Classes</a></p>
<p>Author: Eneko Agirre ; Kepa Bengoetxea ; Koldo Gojenola ; Joakim Nivre</p><p>Abstract: This paper presents the introduction of WordNet semantic classes in a dependency parser, obtaining improvements on the full Penn Treebank for the first time. We tried different combinations of some basic semantic classes and word sense disambiguation algorithms. Our experiments show that selecting the adequate combination of semantic features on development data is key for success. Given the basic nature of the semantic classes and word sense disambiguation algorithms used, we think there is ample room for future improvements. 1</p><p>5 0.17164683 <a title="240-tfidf-5" href="./acl-2011-Identification_of_Domain-Specific_Senses_in_a_Machine-Readable_Dictionary.html">158 acl-2011-Identification of Domain-Specific Senses in a Machine-Readable Dictionary</a></p>
<p>Author: Fumiyo Fukumoto ; Yoshimi Suzuki</p><p>Abstract: This paper focuses on domain-specific senses and presents a method for assigning category/domain label to each sense of words in a dictionary. The method first identifies each sense of a word in the dictionary to its corresponding category. We used a text classification technique to select appropriate senses for each domain. Then, senses were scored by computing the rank scores. We used Markov Random Walk (MRW) model. The method was tested on English and Japanese resources, WordNet 3.0 and EDR Japanese dictionary. For evaluation of the method, we compared English results with the Subject Field Codes (SFC) resources. We also compared each English and Japanese results to the first sense heuristics in the WSD task. These results suggest that identification of domain-specific senses (IDSS) may actually be of benefit.</p><p>6 0.14197204 <a title="240-tfidf-6" href="./acl-2011-Models_and_Training_for_Unsupervised_Preposition_Sense_Disambiguation.html">224 acl-2011-Models and Training for Unsupervised Preposition Sense Disambiguation</a></p>
<p>7 0.13453983 <a title="240-tfidf-7" href="./acl-2011-Crowdsourcing_Translation%3A_Professional_Quality_from_Non-Professionals.html">90 acl-2011-Crowdsourcing Translation: Professional Quality from Non-Professionals</a></p>
<p>8 0.13243501 <a title="240-tfidf-8" href="./acl-2011-Together_We_Can%3A_Bilingual_Bootstrapping_for_WSD.html">304 acl-2011-Together We Can: Bilingual Bootstrapping for WSD</a></p>
<p>9 0.12788375 <a title="240-tfidf-9" href="./acl-2011-Joint_Bilingual_Sentiment_Classification_with_Unlabeled_Parallel_Corpora.html">183 acl-2011-Joint Bilingual Sentiment Classification with Unlabeled Parallel Corpora</a></p>
<p>10 0.1269328 <a title="240-tfidf-10" href="./acl-2011-How_Much_Can_We_Gain_from_Supervised_Word_Alignment%3F.html">152 acl-2011-How Much Can We Gain from Supervised Word Alignment?</a></p>
<p>11 0.11962758 <a title="240-tfidf-11" href="./acl-2011-Towards_Tracking_Semantic_Change_by_Visual_Analytics.html">307 acl-2011-Towards Tracking Semantic Change by Visual Analytics</a></p>
<p>12 0.1158171 <a title="240-tfidf-12" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<p>13 0.11306188 <a title="240-tfidf-13" href="./acl-2011-Domain_Adaptation_for_Machine_Translation_by_Mining_Unseen_Words.html">104 acl-2011-Domain Adaptation for Machine Translation by Mining Unseen Words</a></p>
<p>14 0.10765511 <a title="240-tfidf-14" href="./acl-2011-Using_Bilingual_Parallel_Corpora_for_Cross-Lingual_Textual_Entailment.html">327 acl-2011-Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment</a></p>
<p>15 0.1046005 <a title="240-tfidf-15" href="./acl-2011-An_exponential_translation_model_for_target_language_morphology.html">44 acl-2011-An exponential translation model for target language morphology</a></p>
<p>16 0.10141724 <a title="240-tfidf-16" href="./acl-2011-Evaluating_the_Impact_of_Coder_Errors_on_Active_Learning.html">119 acl-2011-Evaluating the Impact of Coder Errors on Active Learning</a></p>
<p>17 0.10036992 <a title="240-tfidf-17" href="./acl-2011-I_Thou_Thee%2C_Thou_Traitor%3A_Predicting_Formal_vs._Informal_Address_in_English_Literature.html">157 acl-2011-I Thou Thee, Thou Traitor: Predicting Formal vs. Informal Address in English Literature</a></p>
<p>18 0.096213982 <a title="240-tfidf-18" href="./acl-2011-Identifying_Word_Translations_from_Comparable_Corpora_Using_Latent_Topic_Models.html">161 acl-2011-Identifying Word Translations from Comparable Corpora Using Latent Topic Models</a></p>
<p>19 0.092676617 <a title="240-tfidf-19" href="./acl-2011-Disambiguating_temporal-contrastive_connectives_for_machine_translation.html">96 acl-2011-Disambiguating temporal-contrastive connectives for machine translation</a></p>
<p>20 0.092014968 <a title="240-tfidf-20" href="./acl-2011-AM-FM%3A_A_Semantic_Framework_for_Translation_Quality_Assessment.html">2 acl-2011-AM-FM: A Semantic Framework for Translation Quality Assessment</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.249), (1, -0.061), (2, 0.023), (3, 0.084), (4, 0.024), (5, 0.0), (6, 0.188), (7, 0.022), (8, -0.019), (9, -0.018), (10, 0.042), (11, -0.189), (12, 0.153), (13, -0.027), (14, 0.008), (15, -0.11), (16, 0.184), (17, 0.118), (18, 0.02), (19, 0.009), (20, 0.033), (21, -0.075), (22, 0.003), (23, 0.102), (24, -0.031), (25, 0.076), (26, -0.038), (27, 0.015), (28, 0.002), (29, -0.046), (30, 0.021), (31, 0.025), (32, -0.062), (33, -0.008), (34, -0.011), (35, 0.06), (36, 0.043), (37, -0.017), (38, -0.018), (39, -0.027), (40, -0.041), (41, 0.041), (42, 0.045), (43, 0.029), (44, 0.006), (45, 0.009), (46, -0.016), (47, -0.062), (48, 0.045), (49, 0.046)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93546402 <a title="240-lsi-1" href="./acl-2011-ParaSense_or_How_to_Use_Parallel_Corpora_for_Word_Sense_Disambiguation.html">240 acl-2011-ParaSense or How to Use Parallel Corpora for Word Sense Disambiguation</a></p>
<p>Author: Els Lefever ; Veronique Hoste ; Martine De Cock</p><p>Abstract: This paper describes a set of exploratory experiments for a multilingual classificationbased approach to Word Sense Disambiguation. Instead of using a predefined monolingual sense-inventory such as WordNet, we use a language-independent framework where the word senses are derived automatically from word alignments on a parallel corpus. We built five classifiers with English as an input language and translations in the five supported languages (viz. French, Dutch, Italian, Spanish and German) as classification output. The feature vectors incorporate both the more traditional local context features, as well as binary bag-of-words features that are extracted from the aligned translations. Our results show that the ParaSense multilingual WSD system shows very competitive results compared to the best systems that were evaluated on the SemEval-2010 Cross-Lingual Word Sense Disambiguation task for all five target languages.</p><p>2 0.7780869 <a title="240-lsi-2" href="./acl-2011-Identification_of_Domain-Specific_Senses_in_a_Machine-Readable_Dictionary.html">158 acl-2011-Identification of Domain-Specific Senses in a Machine-Readable Dictionary</a></p>
<p>Author: Fumiyo Fukumoto ; Yoshimi Suzuki</p><p>Abstract: This paper focuses on domain-specific senses and presents a method for assigning category/domain label to each sense of words in a dictionary. The method first identifies each sense of a word in the dictionary to its corresponding category. We used a text classification technique to select appropriate senses for each domain. Then, senses were scored by computing the rank scores. We used Markov Random Walk (MRW) model. The method was tested on English and Japanese resources, WordNet 3.0 and EDR Japanese dictionary. For evaluation of the method, we compared English results with the Subject Field Codes (SFC) resources. We also compared each English and Japanese results to the first sense heuristics in the WSD task. These results suggest that identification of domain-specific senses (IDSS) may actually be of benefit.</p><p>3 0.74522346 <a title="240-lsi-3" href="./acl-2011-Towards_Tracking_Semantic_Change_by_Visual_Analytics.html">307 acl-2011-Towards Tracking Semantic Change by Visual Analytics</a></p>
<p>Author: Christian Rohrdantz ; Annette Hautli ; Thomas Mayer ; Miriam Butt ; Daniel A. Keim ; Frans Plank</p><p>Abstract: This paper presents a new approach to detecting and tracking changes in word meaning by visually modeling and representing diachronic development in word contexts. Previous studies have shown that computational models are capable of clustering and disambiguating senses, a more recent trend investigates whether changes in word meaning can be tracked by automatic methods. The aim of our study is to offer a new instrument for investigating the diachronic development of word senses in a way that allows for a better understanding of the nature of semantic change in general. For this purpose we combine techniques from the field of Visual Analytics with unsupervised methods from Natural Language Processing, allowing for an interactive visual exploration of semantic change.</p><p>4 0.73813593 <a title="240-lsi-4" href="./acl-2011-Latent_Semantic_Word_Sense_Induction_and_Disambiguation.html">198 acl-2011-Latent Semantic Word Sense Induction and Disambiguation</a></p>
<p>Author: Tim Van de Cruys ; Marianna Apidianaki</p><p>Abstract: In this paper, we present a unified model for the automatic induction of word senses from text, and the subsequent disambiguation of particular word instances using the automatically extracted sense inventory. The induction step and the disambiguation step are based on the same principle: words and contexts are mapped to a limited number of topical dimensions in a latent semantic word space. The intuition is that a particular sense is associated with a particular topic, so that different senses can be discriminated through their association with particular topical dimensions; in a similar vein, a particular instance of a word can be disambiguated by determining its most important topical dimensions. The model is evaluated on the SEMEVAL-20 10 word sense induction and disambiguation task, on which it reaches stateof-the-art results.</p><p>5 0.72309154 <a title="240-lsi-5" href="./acl-2011-Together_We_Can%3A_Bilingual_Bootstrapping_for_WSD.html">304 acl-2011-Together We Can: Bilingual Bootstrapping for WSD</a></p>
<p>Author: Mitesh M. Khapra ; Salil Joshi ; Arindam Chatterjee ; Pushpak Bhattacharyya</p><p>Abstract: Recent work on bilingual Word Sense Disambiguation (WSD) has shown that a resource deprived language (L1) can benefit from the annotation work done in a resource rich language (L2) via parameter projection. However, this method assumes the presence of sufficient annotated data in one resource rich language which may not always be possible. Instead, we focus on the situation where there are two resource deprived languages, both having a very small amount of seed annotated data and a large amount of untagged data. We then use bilingual bootstrapping, wherein, a model trained using the seed annotated data of L1 is used to annotate the untagged data of L2 and vice versa using parameter projection. The untagged instances of L1 and L2 which get annotated with high confidence are then added to the seed data of the respective languages and the above process is repeated. Our experiments show that such a bilingual bootstrapping algorithm when evaluated on two different domains with small seed sizes using Hindi (L1) and Marathi (L2) as the language pair performs better than monolingual bootstrapping and significantly reduces annotation cost.</p><p>6 0.69335961 <a title="240-lsi-6" href="./acl-2011-Disambiguating_temporal-contrastive_connectives_for_machine_translation.html">96 acl-2011-Disambiguating temporal-contrastive connectives for machine translation</a></p>
<p>7 0.67903847 <a title="240-lsi-7" href="./acl-2011-Rare_Word_Translation_Extraction_from_Aligned_Comparable_Documents.html">259 acl-2011-Rare Word Translation Extraction from Aligned Comparable Documents</a></p>
<p>8 0.6189689 <a title="240-lsi-8" href="./acl-2011-Clustering_Comparable_Corpora_For_Bilingual_Lexicon_Extraction.html">70 acl-2011-Clustering Comparable Corpora For Bilingual Lexicon Extraction</a></p>
<p>9 0.61267114 <a title="240-lsi-9" href="./acl-2011-Models_and_Training_for_Unsupervised_Preposition_Sense_Disambiguation.html">224 acl-2011-Models and Training for Unsupervised Preposition Sense Disambiguation</a></p>
<p>10 0.60622662 <a title="240-lsi-10" href="./acl-2011-Which_Noun_Phrases_Denote_Which_Concepts%3F.html">334 acl-2011-Which Noun Phrases Denote Which Concepts?</a></p>
<p>11 0.58871907 <a title="240-lsi-11" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<p>12 0.57799929 <a title="240-lsi-12" href="./acl-2011-Domain_Adaptation_for_Machine_Translation_by_Mining_Unseen_Words.html">104 acl-2011-Domain Adaptation for Machine Translation by Mining Unseen Words</a></p>
<p>13 0.57318276 <a title="240-lsi-13" href="./acl-2011-From_Bilingual_Dictionaries_to_Interlingual_Document_Representations.html">139 acl-2011-From Bilingual Dictionaries to Interlingual Document Representations</a></p>
<p>14 0.57156354 <a title="240-lsi-14" href="./acl-2011-Translationese_and_Its_Dialects.html">311 acl-2011-Translationese and Its Dialects</a></p>
<p>15 0.5711906 <a title="240-lsi-15" href="./acl-2011-Model-Portability_Experiments_for_Textual_Temporal_Analysis.html">222 acl-2011-Model-Portability Experiments for Textual Temporal Analysis</a></p>
<p>16 0.56029081 <a title="240-lsi-16" href="./acl-2011-I_Thou_Thee%2C_Thou_Traitor%3A_Predicting_Formal_vs._Informal_Address_in_English_Literature.html">157 acl-2011-I Thou Thee, Thou Traitor: Predicting Formal vs. Informal Address in English Literature</a></p>
<p>17 0.54854256 <a title="240-lsi-17" href="./acl-2011-Crowdsourcing_Translation%3A_Professional_Quality_from_Non-Professionals.html">90 acl-2011-Crowdsourcing Translation: Professional Quality from Non-Professionals</a></p>
<p>18 0.5423978 <a title="240-lsi-18" href="./acl-2011-Engkoo%3A_Mining_the_Web_for_Language_Learning.html">115 acl-2011-Engkoo: Mining the Web for Language Learning</a></p>
<p>19 0.52763236 <a title="240-lsi-19" href="./acl-2011-Hindi_to_Punjabi_Machine_Translation_System.html">151 acl-2011-Hindi to Punjabi Machine Translation System</a></p>
<p>20 0.52092355 <a title="240-lsi-20" href="./acl-2011-Two_Easy_Improvements_to_Lexical_Weighting.html">313 acl-2011-Two Easy Improvements to Lexical Weighting</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.029), (17, 0.038), (26, 0.058), (37, 0.082), (39, 0.044), (41, 0.074), (53, 0.016), (55, 0.024), (59, 0.087), (70, 0.19), (72, 0.043), (91, 0.046), (96, 0.144), (97, 0.036), (98, 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.81497943 <a title="240-lda-1" href="./acl-2011-Jigs_and_Lures%3A_Associating_Web_Queries_with_Structured_Entities.html">181 acl-2011-Jigs and Lures: Associating Web Queries with Structured Entities</a></p>
<p>Author: Patrick Pantel ; Ariel Fuxman</p><p>Abstract: We propose methods for estimating the probability that an entity from an entity database is associated with a web search query. Association is modeled using a query entity click graph, blending general query click logs with vertical query click logs. Smoothing techniques are proposed to address the inherent data sparsity in such graphs, including interpolation using a query synonymy model. A large-scale empirical analysis of the smoothing techniques, over a 2-year click graph collected from a commercial search engine, shows significant reductions in modeling error. The association models are then applied to the task of recommending products to web queries, by annotating queries with products from a large catalog and then mining query- product associations through web search session analysis. Experimental analysis shows that our smoothing techniques improve coverage while keeping precision stable, and overall, that our top-performing model affects 9% of general web queries with 94% precision.</p><p>same-paper 2 0.78372717 <a title="240-lda-2" href="./acl-2011-ParaSense_or_How_to_Use_Parallel_Corpora_for_Word_Sense_Disambiguation.html">240 acl-2011-ParaSense or How to Use Parallel Corpora for Word Sense Disambiguation</a></p>
<p>Author: Els Lefever ; Veronique Hoste ; Martine De Cock</p><p>Abstract: This paper describes a set of exploratory experiments for a multilingual classificationbased approach to Word Sense Disambiguation. Instead of using a predefined monolingual sense-inventory such as WordNet, we use a language-independent framework where the word senses are derived automatically from word alignments on a parallel corpus. We built five classifiers with English as an input language and translations in the five supported languages (viz. French, Dutch, Italian, Spanish and German) as classification output. The feature vectors incorporate both the more traditional local context features, as well as binary bag-of-words features that are extracted from the aligned translations. Our results show that the ParaSense multilingual WSD system shows very competitive results compared to the best systems that were evaluated on the SemEval-2010 Cross-Lingual Word Sense Disambiguation task for all five target languages.</p><p>3 0.73005104 <a title="240-lda-3" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>Author: Joel Lang ; Mirella Lapata</p><p>Abstract: In this paper we describe an unsupervised method for semantic role induction which holds promise for relieving the data acquisition bottleneck associated with supervised role labelers. We present an algorithm that iteratively splits and merges clusters representing semantic roles, thereby leading from an initial clustering to a final clustering of better quality. The method is simple, surprisingly effective, and allows to integrate linguistic knowledge transparently. By combining role induction with a rule-based component for argument identification we obtain an unsupervised end-to-end semantic role labeling system. Evaluation on the CoNLL 2008 benchmark dataset demonstrates that our method outperforms competitive unsupervised approaches by a wide margin.</p><p>4 0.72186863 <a title="240-lda-4" href="./acl-2011-In-domain_Relation_Discovery_with_Meta-constraints_via_Posterior_Regularization.html">170 acl-2011-In-domain Relation Discovery with Meta-constraints via Posterior Regularization</a></p>
<p>Author: Harr Chen ; Edward Benson ; Tahira Naseem ; Regina Barzilay</p><p>Abstract: We present a novel approach to discovering relations and their instantiations from a collection of documents in a single domain. Our approach learns relation types by exploiting meta-constraints that characterize the general qualities of a good relation in any domain. These constraints state that instances of a single relation should exhibit regularities at multiple levels of linguistic structure, including lexicography, syntax, and document-level context. We capture these regularities via the structure of our probabilistic model as well as a set of declaratively-specified constraints enforced during posterior inference. Across two domains our approach successfully recovers hidden relation structure, comparable to or outperforming previous state-of-the-art approaches. Furthermore, we find that a small , set of constraints is applicable across the domains, and that using domain-specific constraints can further improve performance. 1</p><p>5 0.72135931 <a title="240-lda-5" href="./acl-2011-Scaling_up_Automatic_Cross-Lingual_Semantic_Role_Annotation.html">269 acl-2011-Scaling up Automatic Cross-Lingual Semantic Role Annotation</a></p>
<p>Author: Lonneke van der Plas ; Paola Merlo ; James Henderson</p><p>Abstract: Broad-coverage semantic annotations for training statistical learners are only available for a handful of languages. Previous approaches to cross-lingual transfer of semantic annotations have addressed this problem with encouraging results on a small scale. In this paper, we scale up previous efforts by using an automatic approach to semantic annotation that does not rely on a semantic ontology for the target language. Moreover, we improve the quality of the transferred semantic annotations by using a joint syntacticsemantic parser that learns the correlations between syntax and semantics of the target language and smooths out the errors from automatic transfer. We reach a labelled F-measure for predicates and arguments of only 4% and 9% points, respectively, lower than the upper bound from manual annotations.</p><p>6 0.72048259 <a title="240-lda-6" href="./acl-2011-Fine-Grained_Class_Label_Markup_of_Search_Queries.html">137 acl-2011-Fine-Grained Class Label Markup of Search Queries</a></p>
<p>7 0.71930611 <a title="240-lda-7" href="./acl-2011-Using_Bilingual_Parallel_Corpora_for_Cross-Lingual_Textual_Entailment.html">327 acl-2011-Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment</a></p>
<p>8 0.71896273 <a title="240-lda-8" href="./acl-2011-Improving_Arabic_Dependency_Parsing_with_Form-based_and_Functional_Morphological_Features.html">164 acl-2011-Improving Arabic Dependency Parsing with Form-based and Functional Morphological Features</a></p>
<p>9 0.71535206 <a title="240-lda-9" href="./acl-2011-A_Bayesian_Model_for_Unsupervised_Semantic_Parsing.html">3 acl-2011-A Bayesian Model for Unsupervised Semantic Parsing</a></p>
<p>10 0.71534157 <a title="240-lda-10" href="./acl-2011-Knowledge-Based_Weak_Supervision_for_Information_Extraction_of_Overlapping_Relations.html">190 acl-2011-Knowledge-Based Weak Supervision for Information Extraction of Overlapping Relations</a></p>
<p>11 0.71489537 <a title="240-lda-11" href="./acl-2011-Exact_Decoding_of_Syntactic_Translation_Models_through_Lagrangian_Relaxation.html">123 acl-2011-Exact Decoding of Syntactic Translation Models through Lagrangian Relaxation</a></p>
<p>12 0.7147907 <a title="240-lda-12" href="./acl-2011-Coreference_for_Learning_to_Extract_Relations%3A_Yes_Virginia%2C_Coreference_Matters.html">86 acl-2011-Coreference for Learning to Extract Relations: Yes Virginia, Coreference Matters</a></p>
<p>13 0.7133739 <a title="240-lda-13" href="./acl-2011-Together_We_Can%3A_Bilingual_Bootstrapping_for_WSD.html">304 acl-2011-Together We Can: Bilingual Bootstrapping for WSD</a></p>
<p>14 0.71264255 <a title="240-lda-14" href="./acl-2011-Peeling_Back_the_Layers%3A_Detecting_Event_Role_Fillers_in_Secondary_Contexts.html">244 acl-2011-Peeling Back the Layers: Detecting Event Role Fillers in Secondary Contexts</a></p>
<p>15 0.71183586 <a title="240-lda-15" href="./acl-2011-Can_Document_Selection_Help_Semi-supervised_Learning%3F_A_Case_Study_On_Event_Extraction.html">65 acl-2011-Can Document Selection Help Semi-supervised Learning? A Case Study On Event Extraction</a></p>
<p>16 0.71124113 <a title="240-lda-16" href="./acl-2011-An_Error_Analysis_of_Relation_Extraction_in_Social_Media_Documents.html">40 acl-2011-An Error Analysis of Relation Extraction in Social Media Documents</a></p>
<p>17 0.71086371 <a title="240-lda-17" href="./acl-2011-Interactive_Topic_Modeling.html">178 acl-2011-Interactive Topic Modeling</a></p>
<p>18 0.71081609 <a title="240-lda-18" href="./acl-2011-A_Statistical_Tree_Annotator_and_Its_Applications.html">28 acl-2011-A Statistical Tree Annotator and Its Applications</a></p>
<p>19 0.70994103 <a title="240-lda-19" href="./acl-2011-An_Efficient_Indexer_for_Large_N-Gram_Corpora.html">36 acl-2011-An Efficient Indexer for Large N-Gram Corpora</a></p>
<p>20 0.70977545 <a title="240-lda-20" href="./acl-2011-Exploiting_Syntactico-Semantic_Structures_for_Relation_Extraction.html">126 acl-2011-Exploiting Syntactico-Semantic Structures for Relation Extraction</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
