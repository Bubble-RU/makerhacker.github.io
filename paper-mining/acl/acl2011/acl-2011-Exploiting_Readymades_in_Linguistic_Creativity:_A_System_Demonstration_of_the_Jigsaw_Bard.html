<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>125 acl-2011-Exploiting Readymades in Linguistic Creativity: A System Demonstration of the Jigsaw Bard</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-125" href="#">acl2011-125</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>125 acl-2011-Exploiting Readymades in Linguistic Creativity: A System Demonstration of the Jigsaw Bard</h1>
<br/><p>Source: <a title="acl-2011-125-pdf" href="http://aclweb.org/anthology//P/P11/P11-4003.pdf">pdf</a></p><p>Author: Tony Veale ; Yanfen Hao</p><p>Abstract: Large lexical resources, such as corpora and databases of Web ngrams, are a rich source of pre-fabricated phrases that can be reused in many different contexts. However, one must be careful in how these resources are used, and noted writers such as George Orwell have argued that the use of canned phrases encourages sloppy thinking and results in poor communication. Nonetheless, while Orwell prized home-made phrases over the readymade variety, there is a vibrant movement in modern art which shifts artistic creation from the production of novel artifacts to the clever reuse of readymades or objets trouvés. We describe here a system that makes creative reuse of the linguistic readymades in the Google ngrams. Our system, the Jigsaw Bard, thus owes more to Marcel Duchamp than to George Orwell. We demonstrate how textual readymades can be identified and harvested on a large scale, and used to drive a modest form of linguistic creativity. 1</p><p>Reference: <a title="acl-2011-125-reference" href="../acl2011_reference/acl-2011-Exploiting_Readymades_in_Linguistic_Creativity%3A_A_System_Demonstration_of_the_Jigsaw_Bard_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 ie Demonstration System can be viewed at: Abstract Large lexical resources, such as corpora and databases of Web ngrams, are a rich source of pre-fabricated phrases that can be reused in many different contexts. [sent-4, score-0.132]
</p><p>2 However, one must be careful in how these resources are used, and noted writers such as George Orwell have argued that the use of canned phrases encourages sloppy thinking and results in poor communication. [sent-5, score-0.083]
</p><p>3 Nonetheless, while Orwell prized home-made phrases over the readymade variety, there  is a vibrant movement in modern art which shifts artistic creation from the production of novel artifacts to the clever reuse of readymades or objets trouvés. [sent-6, score-0.948]
</p><p>4 We describe here a system that makes creative reuse of the linguistic readymades in the Google ngrams. [sent-7, score-0.538]
</p><p>5 We demonstrate how textual readymades can be identified and harvested on a large scale, and used to drive a modest form of linguistic creativity. [sent-9, score-0.439]
</p><p>6 Lazy language can thus promote lazy thinking, and vice versa. [sent-16, score-0.075]
</p><p>7 While a good writer bends words to his meaning, Orwell worries that a lazy writer bends his meaning to convenient words. [sent-18, score-0.315]
</p><p>8 Orwell is especially scornful about readymade phrases which, when over-used, “are tacked together like the sections of a prefabricated henhouse. [sent-19, score-0.411]
</p><p>9 ” A writer who operates by “mechanically repeating the familiar phrases” and “gumming together long strips of words which have already been set in order by someone else” has, he argues, “gone some distance toward turning himself into a machine. [sent-20, score-0.128]
</p><p>10 ” Given his derogatory mechanistic view of the use of readymade phrases, Orwell would not be surprised to learn that computers are highly proficient in the large-scale use of familiar phrases, whether acquired from large text corpora or from the Google ngrams (see Brants and Franz, 2006). [sent-21, score-0.465]
</p><p>11 And if one cannot use familiar  a perceived argues  decline  in the English language. [sent-24, score-0.045]
</p><p>12 that language and thought form  a  He  tight  readymade  phrases, how can one make playful  and creative – allusions  to the writings of others, or  14 Proceedings of the ACL-HLT 2011 System Demonstrations, pages 14–19, Portland, Oregon, USA, 21 June 201 1. [sent-25, score-0.394]
</p><p>13 Orwell’s use of the term readymade is entirely negative, yet the term is altogether more respectable in the world of modern art, thanks to its use by artists such as Marcel Duchamp. [sent-28, score-0.344]
</p><p>14 For many artists, a readymade object is not a substitute, but a starting point, for creativity. [sent-29, score-0.329]
</p><p>15 Perhaps the most famous (and notorious) readymade in the world of art is Marcel Duchamp’s Fountain, a humble urinal that becomes an elegantly curved piece of sculpture when viewed with the right mindset. [sent-32, score-0.334]
</p><p>16 Duchamp referred to his objets trouvés as “assisted readymades” because they allow an artist to remake the act of  creation as one of pure insight and inspired recognition rather than one of manual craftsmanship (see Taylor, 2009). [sent-33, score-0.112]
</p><p>17 In computational terms, the Duchampian notion of a readymade allows creativity to be modeled not as a construction problem but as a decision problem. [sent-34, score-0.416]
</p><p>18 However, a Duchampian agent must instead be exposed to the multitude of potentially inspiring real-world stimuli that a human artist encounters everyday. [sent-36, score-0.107]
</p><p>19 Readymades represent a serendipitous form of creativity that is poorly served by exploratory models of creativity, such as that of Boden (1994), and better served by the investment models such as the buy-low-sell-high theory of Sternberg and Lubart (1995). [sent-37, score-0.199]
</p><p>20 In this view, creators and artists find unexpected or untapped value in unfashionable objects or ideas that already exist, and quickly move their gaze elsewhere once the public at large come to recognize this value. [sent-38, score-0.082]
</p><p>21 Duchampian creators invest in everyday objects, just as Duchamp found artistic merit in urinals, bottles and combs. [sent-39, score-0.161]
</p><p>22 From a linguistic perspective, these everyday objects are commonplace words and phrases which, when wrenched from their conventional contexts of use,  are free to take on enhanced meanings and provide additional returns to the investor. [sent-40, score-0.164]
</p><p>23 The realm in 15 which a maker of linguistic readymades operates is not the real world, and not an abstract conceptual space, but the realm of texts: large corpora become rich hunting grounds for investors in linguistic objets trouvés. [sent-41, score-0.53]
</p><p>24 We show how a rich vocabulary of cultural stereotypes can be acquired from the Web, and how this vocabulary facilitates the implementation of a decision procedure for recognizing potential readymades in large corpora – in this case, the Google database of Web ngrams (Brants and Franz, 2006). [sent-43, score-0.84]
</p><p>25 The cognitive / linguistic intuitions that underpin the Bard’s concept of textual readymades are put to the empirical test in section 5. [sent-45, score-0.482]
</p><p>26 2  Linguistic Readymades  Readymades are the result of artistic appropriation, in which an object with cultural resonance an image, a phrase, a quote, a name, a thing – is reused in a new context with a new meaning. [sent-47, score-0.351]
</p><p>27 As a fertile source of cultural reference points, language is an equally fertile medium for appropriation. [sent-48, score-0.249]
</p><p>28 Thus, in the constant swirl of language and culture, movie quotes suggest song lyrics, which in turn suggest movie titles, which suggest book titles, or restaurant names, or the names of racehorses, and so on, and on. [sent-49, score-0.07]
</p><p>29 The 1996 movie The Usual Suspects takes its name from a memorable scene in 1942’s Casablanca, as does the Woody Allen play and movie Play it Again Sam. [sent-50, score-0.119]
</p><p>30 Linguistic readymades, then, are well-formed text fragments that are often highly quotable because they carry some figurative content which can be reused in different contexts. [sent-55, score-0.17]
</p><p>31 A quote like “round up the usual suspects” or “I am Spartacus” requires a great deal of cultural knowledge to appreciate. [sent-56, score-0.175]
</p><p>32 Since literal semantics only provides a small part of their meaning, a computer’s ability to recognize linguistic readymades is only as good as the cultural knowledge at its disposal. [sent-57, score-0.65]
</p><p>33 Each is likely a literal description of a real object or event – even “robot fish”, which describes an autonomous marine vehicle whose movements mimic real fish. [sent-59, score-0.07]
</p><p>34 But each exhibits figurative potential as well, providing a memorable description of physical or emotional coldness. [sent-60, score-0.17]
</p><p>35 Whether or not each was ever used in a figurative sense before is not the point: once this potential is recognized, each phrase becomes a reusable linguistic readymade for the construction of a vivid figurative comparison, as in “as cold as a robot fish”. [sent-61, score-0.862]
</p><p>36 3  A Vocabulary of Cultural Stereotypes  How does a computer acquire the knowledge that fish, snow, January, bullets and corpses are cultural signifiers of coldness? [sent-64, score-0.212]
</p><p>37 Much the same way that humans acquire this knowledge: by attending to  the way these signifiers are used by others, espe16 cially when they are used in cultural clichés like proverbial similes (e. [sent-65, score-0.49]
</p><p>38 In fact, folk similes are an important vector in the transmission of cultural knowledge: they point to, and exploit, the shared cultural touchstones that speakers and listeners alike can use to construct and intuit meanings. [sent-68, score-0.616]
</p><p>39 Taylor (1954) catalogued thousands of proverbial comparisons and similes from California, identifying just as many building blocks in the construction of new phrases and figurative meanings. [sent-69, score-0.524]
</p><p>40 Only the most common similes can be found in dictionaries, as shown by Norrick (1986), while Moon (2008) demonstrates that large-scale corpus analysis is needed to identify folk similes with a breadth approaching that of Taylor’s study. [sent-70, score-0.495]
</p><p>41 Veale and Hao use the Google API to find many instances of the pattern “as ADJ as a|an *” on the web, where ADJ is an adjectival property and * is the Google wildcard. [sent-72, score-0.157]
</p><p>42 WordNet (Fellbaum, 1998) is used to provide a set of over 2,000 different values  for ADJ, and the text snippets returned by Google are parsed to extract the basic simile bindings. [sent-73, score-0.082]
</p><p>43 Once the bindings are annotated to remove noise, as well as frequent uses of irony, this Web harvest produces over 12,000 cultural bindings between a noun (such as fish, or robot) and its most stereotypical properties (such as cold, wet, stiff, logical, heartless, etc. [sent-74, score-0.365]
</p><p>44 This is a set of building blocks on a larger scale than even that of Taylor, allowing us to build on Veale and Hao (2007) to identify readymades in their hundreds of thousands in the Google ngrams. [sent-78, score-0.435]
</p><p>45 However, to identify readymades as resonant variations on cultural stereotypes, we need a certain fluidity in our treatment of adjectival properties. [sent-79, score-0.668]
</p><p>46 The phrase “wet haddock” is a readymade for coldness because “wet” accentuates the “cold” that we associate with “haddock” (via the web simile “as cold as a haddock”). [sent-80, score-0.596]
</p><p>47 In the words of Hofstadter (1995), we need to build a SlipNet of properties whose structure captures the propensity of properties to mutually and coherently reinforce each other, so that phrases which subtly accentuate an unstated property can be recognized. [sent-81, score-0.511]
</p><p>48 We hypothesize that the construction “as ADJ1 and ADJ2 as” shows ADJ1 and ADJ2 to be mutually reinforcing properties, since they can be seen to work together as a single complex property in a single comparison. [sent-83, score-0.139]
</p><p>49 Thus, using the full complement of adjectival properties used by Veale and Hao (2007), we harvest all instances of the patterns “as ADJ and * as” and “as * and ADJ as” from Google, noting the combinations that are found and their frequencies. [sent-84, score-0.191]
</p><p>50 In all, over 180,000 links are harvested, connecting over 2,500 adjectival properties to one other. [sent-86, score-0.148]
</p><p>51 4  Harvesting Readymades from Corpora  In the course of an average day, a creative writer is exposed to a constant barrage of linguistic stimuli, any small portion of which can strike a chord as a potential readymade. [sent-88, score-0.302]
</p><p>52 In this casual inspiration phase, the observant writer recognizes that a certain combination of words may produce, in another context, a meaning that is more than the sum of its  parts. [sent-89, score-0.083]
</p><p>53 Ironically, Orwell (1946) suggests that lazy writers “shirk” their responsibility to be “scrupulous” in their use of language by “simply throwing [their] mind open and letting the ready-made phrases come crowding in”. [sent-91, score-0.23]
</p><p>54 For Orwell, words just get in the way, and should be kept at arm’s length until the writer has first allowed a clear meaning to crystallize. [sent-92, score-0.083]
</p><p>55 This is dubious advice, as one expects a creative writer to keep an open mind when considering all the possibilities that present themselves. [sent-93, score-0.217]
</p><p>56 Given a rich vocabulary of cultural stereotypes and their properties, computers are capable of indexing and recalling a considerably larger  17 body of resonant combinations than the average human. [sent-95, score-0.393]
</p><p>57 The necessary barrage of linguistic stimuli can be provided by the Google 1T database of Web ngrams (Brants and Franz, 2006). [sent-96, score-0.215]
</p><p>58 Trawling these ngrams, a modestly creative computer can recognize well-formed combinations of cultural elements that might serve as a vivid vehicle of description in a future comparison. [sent-97, score-0.34]
</p><p>59 For every phrase P in the ngrams, where P combines stereotype nouns and/or adjectival modifiers, the computer simply poses the following question: is there an unstated property A such that the simile “as A as P” is a meaningful and memorable comparison? [sent-98, score-0.488]
</p><p>60 The property A can be simple, as in “as dark as a chocolate espresso”, or complex, as in “as dark and sophisticated as a chocolate martini”. [sent-99, score-0.29]
</p><p>61 In either case, the phrase P is tucked away, and indexed under the property A until such time as the computer needs to produce a vivid evocation of A. [sent-100, score-0.192]
</p><p>62 The following patterns are used to identify potential readymades in the Web ngrams: (1) NounS1 NounS2 where both nouns denote stereotypes that  share an unstated property AdjA. [sent-101, score-0.732]
</p><p>63 (2) NounS1 NounS2 where both nouns denote stereotypes with salient properties AdjA1 and AdjA2 respectively, such that AdjA1 and AdjA2 are mutually reinforcing. [sent-104, score-0.355]
</p><p>64 Example: “as dark and sophisticated as a chocolate martini”. [sent-106, score-0.1]
</p><p>65 (3) AdjA NounS where NounS denotes a cultural stereotype, and the adjective AdjA denotes a property that mutually reinforces an unstated but salient property AdjSA of the stereotype. [sent-107, score-0.522]
</p><p>66 More complex structures for P are also possible, as in the phrases “a lake of tears” (a melancholy way to accentuate the property “wet”) and “a statue in a library” (for “silent” and “quiet”). [sent-110, score-0.229]
</p><p>67 In this current description, we focus on 2-gram phrases only. [sent-111, score-0.083]
</p><p>68 Screenshot of The Jigsaw Bard, retrieving linguistic readymades for the input property “cold”. [sent-113, score-0.529]
</p><p>69 com/jigsaw Using these patterns, our application – the Jigsaw Bard (see Figure 1) – pre-builds a vast collection of figurative similes well in advance of the time it is asked to use or suggest any of them. [sent-116, score-0.35]
</p><p>70 Each phrase it proposes has the ring of linguistic authenticity; because this authenticity is rooted in another, more literal context, the Bard also exhibits its own Duchamp-like (if Duchamp-lite) creativity. [sent-119, score-0.119]
</p><p>71 5  Empirical Evaluation  The vastness of the web, captured in the largescale sample that is the Google ngrams, means the Jigsaw Bard finds considerable grist for its mill in the phrases that match (1)… (3). [sent-121, score-0.083]
</p><p>72 Thus, the most restrictive pattern, pattern (1), harvests approx. [sent-122, score-0.06]
</p><p>73 20,000 phrases from the Google 2-grams, for almost a thousand simple properties (indexing an average of 29 phrases under each property, such as “swan song” for “beautiful”). [sent-123, score-0.247]
</p><p>74 Pattern (2) – which allows a blend of stereotypes to be indexed under a complex property – harvests approx. [sent-124, score-0.333]
</p><p>75 70,000 complex properties (indexing an average of 12 phrases …  18  under each, such as “hospital bed” for “comfortable and safe”). [sent-126, score-0.164]
</p><p>76 Pattern (3) – which pairs a stereotype noun with an adjective that draws out a salient property of the stereotype – is similarly productive: it harvests approx. [sent-127, score-0.393]
</p><p>77 150,000 readymade 2-grams for over 2,000 simple properties (indexing an average of 125 phrases per property, as in “youthful knight” for “heroic” and “zealous convert” for “devout”). [sent-128, score-0.459]
</p><p>78 The Jigsaw Bard is best understood as a creative thesaurus: for any given property (or blend of properties) selected by the user, the Bard presents a range of apt similes constructed from linguistic readymades. [sent-129, score-0.464]
</p><p>79 Quality-wise, users must make their own determinations as to which similes are most suited to their descriptive purposes, yet it is important that suggestions provided by the Bard are sensible and well-motivated. [sent-131, score-0.229]
</p><p>80 Both intuitions can be tested using Whissell’s (1989) dictionary of affect, a psycholinguistic resource used for sentiment analysis that assigns a pleasantness score of between 1. [sent-133, score-0.24]
</p><p>81 We should thus be able to predict the pleasantness of a stereotype noun (like fish) using a weighted average of the pleasantness of its salient properties (like cold, slippery). [sent-136, score-0.62]
</p><p>82 We should also be able to predict the pleasantness of an adjective using a weighted average of the pleasantness of its adjacent adjectives in the SlipNet. [sent-137, score-0.394]
</p><p>83 (In each case, weights are provided by relevant web frequencies. [sent-138, score-0.054]
</p><p>84 05) to compare the predictions made in each case to the actual pleasantness scores provided by Whissell’s dictionary, and thereby assess the quality of the knowledge used to make the predictions. [sent-140, score-0.197]
</p><p>85 In the first case, predictions of the pleasantness of stereotype nouns based on the pleasantness of their salient properties (i. [sent-141, score-0.651]
</p><p>86 , predicting the pleasantness of Y from the Xs in “as X as Y”) have a positive correlation of 0. [sent-143, score-0.197]
</p><p>87 5 with Whissell; conversely, ironic properties yield a negative correlation of –0. [sent-144, score-0.081]
</p><p>88 In  the second, predictions of the pleasantness of adjectives based on their relations in the SlipNet (i. [sent-146, score-0.197]
</p><p>89 , predicting the pleasantness of X from the Ys in “as X and Y as”) have a positive correlation of 0. [sent-148, score-0.197]
</p><p>90 Though pleasantness is just one dimension of lexical affect, it is one that requires a broad knowledge of a word, its usage and its denotations to accurately estimate. [sent-150, score-0.197]
</p><p>91 In this respect, the Bard is well served by a large stock of stereotypes and a coherent network of informative properties. [sent-151, score-0.186]
</p><p>92 6  Conclusions  Fishlov (1992) has argued that poetic similes represent a conscious deviation from the norms of non-poetic comparison. [sent-152, score-0.272]
</p><p>93 His analysis shows that poetic similes are longer and more elaborate, and are more likely to be figurative and to flirt with incongruity. [sent-153, score-0.393]
</p><p>94 Creative similes do not necessarily use words that are longer, or rarer, or fancier, but use many of the same cultural building blocks as non-creative similes. [sent-154, score-0.446]
</p><p>95 Armed with a rich vocabulary of building blocks, the Jigsaw Bard harvests a great many readymade phrases from the Google ngrams – from the evocative “chocolate martini” to the seemingly incongruous “robot fish” – that can be used to evoke an wide range of properties. [sent-155, score-0.53]
</p><p>96 However, any creativity we may attribute to it comes not from the phrases themselves – they are readymades, after all – but from the recognition of the subtle and often complex properties they evoke. [sent-157, score-0.285]
</p><p>97 The Bard exploits a sweet-spot in our understanding of linguistic creativity, and so, as presented here, is merely a starting point for our continued exploitation of linguistic readymades, rather than an end in itself. [sent-158, score-0.092]
</p><p>98 By harvesting more complex syntactic structures, and using more sophisticated techniques for analyzing the figurative potential of these phrases, the Bard and its ilk may gradually approach the levels of poeticity discussed by Fishlov. [sent-159, score-0.165]
</p><p>99 7  Hardware Requirements  The Jigsaw Bard is designed to be a lightweight application that compiles its comprehensive data19 base of readymades in advance. [sent-161, score-0.393]
</p><p>100 Defying the crowd: Cultivating creativity in a culture of conformity. [sent-199, score-0.121]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('readymades', 0.393), ('bard', 0.302), ('readymade', 0.295), ('similes', 0.229), ('pleasantness', 0.197), ('orwell', 0.197), ('cultural', 0.175), ('duchamp', 0.149), ('jigsaw', 0.147), ('stereotypes', 0.147), ('fish', 0.136), ('cold', 0.128), ('creativity', 0.121), ('figurative', 0.121), ('veale', 0.115), ('creative', 0.099), ('stereotype', 0.098), ('artistic', 0.093), ('slipnet', 0.093), ('ngrams', 0.092), ('wet', 0.091), ('property', 0.09), ('robot', 0.085), ('writer', 0.083), ('phrases', 0.083), ('haddock', 0.082), ('simile', 0.082), ('properties', 0.081), ('lazy', 0.075), ('unstated', 0.071), ('google', 0.068), ('adjectival', 0.067), ('artist', 0.067), ('marcel', 0.066), ('trouv', 0.066), ('vivid', 0.066), ('hao', 0.063), ('harvests', 0.06), ('chocolate', 0.06), ('accentuate', 0.056), ('adja', 0.056), ('duchampian', 0.056), ('martini', 0.056), ('dublin', 0.054), ('web', 0.054), ('adj', 0.052), ('boden', 0.049), ('memorable', 0.049), ('proverbial', 0.049), ('whissell', 0.049), ('reused', 0.049), ('artists', 0.049), ('mutually', 0.049), ('salient', 0.047), ('linguistic', 0.046), ('objets', 0.045), ('familiar', 0.045), ('harvesting', 0.044), ('intuitions', 0.043), ('harvest', 0.043), ('poetic', 0.043), ('tony', 0.043), ('blocks', 0.042), ('stimuli', 0.04), ('dark', 0.04), ('metaphors', 0.04), ('art', 0.039), ('served', 0.039), ('indexing', 0.038), ('authenticity', 0.037), ('banal', 0.037), ('barrage', 0.037), ('bends', 0.037), ('coldness', 0.037), ('crowding', 0.037), ('fertile', 0.037), ('folk', 0.037), ('fountain', 0.037), ('generativity', 0.037), ('lubart', 0.037), ('pleasant', 0.037), ('signifiers', 0.037), ('strike', 0.037), ('yanfen', 0.037), ('literal', 0.036), ('indexed', 0.036), ('brants', 0.036), ('mind', 0.035), ('movie', 0.035), ('everyday', 0.035), ('object', 0.034), ('taylor', 0.033), ('acquired', 0.033), ('creators', 0.033), ('prefabricated', 0.033), ('belfield', 0.033), ('bindings', 0.033), ('resonant', 0.033), ('george', 0.031), ('nouns', 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999946 <a title="125-tfidf-1" href="./acl-2011-Exploiting_Readymades_in_Linguistic_Creativity%3A_A_System_Demonstration_of_the_Jigsaw_Bard.html">125 acl-2011-Exploiting Readymades in Linguistic Creativity: A System Demonstration of the Jigsaw Bard</a></p>
<p>Author: Tony Veale ; Yanfen Hao</p><p>Abstract: Large lexical resources, such as corpora and databases of Web ngrams, are a rich source of pre-fabricated phrases that can be reused in many different contexts. However, one must be careful in how these resources are used, and noted writers such as George Orwell have argued that the use of canned phrases encourages sloppy thinking and results in poor communication. Nonetheless, while Orwell prized home-made phrases over the readymade variety, there is a vibrant movement in modern art which shifts artistic creation from the production of novel artifacts to the clever reuse of readymades or objets trouvés. We describe here a system that makes creative reuse of the linguistic readymades in the Google ngrams. Our system, the Jigsaw Bard, thus owes more to Marcel Duchamp than to George Orwell. We demonstrate how textual readymades can be identified and harvested on a large scale, and used to drive a modest form of linguistic creativity. 1</p><p>2 0.36664516 <a title="125-tfidf-2" href="./acl-2011-Creative_Language_Retrieval%3A_A_Robust_Hybrid_of_Information_Retrieval_and_Linguistic_Creativity.html">89 acl-2011-Creative Language Retrieval: A Robust Hybrid of Information Retrieval and Linguistic Creativity</a></p>
<p>Author: Tony Veale</p><p>Abstract: Information retrieval (IR) and figurative language processing (FLP) could scarcely be more different in their treatment of language and meaning. IR views language as an open-ended set of mostly stable signs with which texts can be indexed and retrieved, focusing more on a text’s potential relevance than its potential meaning. In contrast, FLP views language as a system of unstable signs that can be used to talk about the world in creative new ways. There is another key difference: IR is practical, scalable and robust, and in daily use by millions of casual users. FLP is neither scalable nor robust, and not yet practical enough to migrate beyond the lab. This paper thus presents a mutually beneficial hybrid of IR and FLP, one that enriches IR with new operators to enable the non-literal retrieval of creative expressions, and which also transplants FLP into a robust, scalable framework in which practical applications of linguistic creativity can be implemented. 1</p><p>3 0.061801646 <a title="125-tfidf-3" href="./acl-2011-Content_Models_with_Attitude.html">82 acl-2011-Content Models with Attitude</a></p>
<p>Author: Christina Sauper ; Aria Haghighi ; Regina Barzilay</p><p>Abstract: We present a probabilistic topic model for jointly identifying properties and attributes of social media review snippets. Our model simultaneously learns a set of properties of a product and captures aggregate user sentiments towards these properties. This approach directly enables discovery of highly rated or inconsistent properties of a product. Our model admits an efficient variational meanfield inference algorithm which can be parallelized and run on large snippet collections. We evaluate our model on a large corpus of snippets from Yelp reviews to assess property and attribute prediction. We demonstrate that it outperforms applicable baselines by a considerable margin.</p><p>4 0.043228976 <a title="125-tfidf-4" href="./acl-2011-Insights_from_Network_Structure_for_Text_Mining.html">174 acl-2011-Insights from Network Structure for Text Mining</a></p>
<p>Author: Zornitsa Kozareva ; Eduard Hovy</p><p>Abstract: Text mining and data harvesting algorithms have become popular in the computational linguistics community. They employ patterns that specify the kind of information to be harvested, and usually bootstrap either the pattern learning or the term harvesting process (or both) in a recursive cycle, using data learned in one step to generate more seeds for the next. They therefore treat the source text corpus as a network, in which words are the nodes and relations linking them are the edges. The results of computational network analysis, especially from the world wide web, are thus applicable. Surprisingly, these results have not yet been broadly introduced into the computational linguistics community. In this paper we show how various results apply to text mining, how they explain some previously observed phenomena, and how they can be helpful for computational linguistics applications.</p><p>5 0.039844662 <a title="125-tfidf-5" href="./acl-2011-Phrase-Based_Translation_Model_for_Question_Retrieval_in_Community_Question_Answer_Archives.html">245 acl-2011-Phrase-Based Translation Model for Question Retrieval in Community Question Answer Archives</a></p>
<p>Author: Guangyou Zhou ; Li Cai ; Jun Zhao ; Kang Liu</p><p>Abstract: Community-based question answer (Q&A;) has become an important issue due to the popularity of Q&A; archives on the web. This paper is concerned with the problem of question retrieval. Question retrieval in Q&A; archives aims to find historical questions that are semantically equivalent or relevant to the queried questions. In this paper, we propose a novel phrase-based translation model for question retrieval. Compared to the traditional word-based translation models, the phrasebased translation model is more effective because it captures contextual information in modeling the translation ofphrases as a whole, rather than translating single words in isolation. Experiments conducted on real Q&A; data demonstrate that our proposed phrasebased translation model significantly outperforms the state-of-the-art word-based translation model.</p><p>6 0.037747063 <a title="125-tfidf-6" href="./acl-2011-Subjective_Natural_Language_Problems%3A_Motivations%2C_Applications%2C_Characterizations%2C_and_Implications.html">288 acl-2011-Subjective Natural Language Problems: Motivations, Applications, Characterizations, and Implications</a></p>
<p>7 0.034006532 <a title="125-tfidf-7" href="./acl-2011-An_Empirical_Evaluation_of_Data-Driven_Paraphrase_Generation_Techniques.html">37 acl-2011-An Empirical Evaluation of Data-Driven Paraphrase Generation Techniques</a></p>
<p>8 0.033171345 <a title="125-tfidf-8" href="./acl-2011-An_Unsupervised_Model_for_Joint_Phrase_Alignment_and_Extraction.html">43 acl-2011-An Unsupervised Model for Joint Phrase Alignment and Extraction</a></p>
<p>9 0.032124907 <a title="125-tfidf-9" href="./acl-2011-An_exponential_translation_model_for_target_language_morphology.html">44 acl-2011-An exponential translation model for target language morphology</a></p>
<p>10 0.031872172 <a title="125-tfidf-10" href="./acl-2011-EdIt%3A_A_Broad-Coverage_Grammar_Checker_Using_Pattern_Grammar.html">108 acl-2011-EdIt: A Broad-Coverage Grammar Checker Using Pattern Grammar</a></p>
<p>11 0.031565849 <a title="125-tfidf-11" href="./acl-2011-A_Mobile_Touchable_Application_for_Online_Topic_Graph_Extraction_and_Exploration_of_Web_Content.html">19 acl-2011-A Mobile Touchable Application for Online Topic Graph Extraction and Exploration of Web Content</a></p>
<p>12 0.029983031 <a title="125-tfidf-12" href="./acl-2011-Reordering_Constraint_Based_on_Document-Level_Context.html">263 acl-2011-Reordering Constraint Based on Document-Level Context</a></p>
<p>13 0.029658673 <a title="125-tfidf-13" href="./acl-2011-Exploiting_Web-Derived_Selectional_Preference_to_Improve_Statistical_Dependency_Parsing.html">127 acl-2011-Exploiting Web-Derived Selectional Preference to Improve Statistical Dependency Parsing</a></p>
<p>14 0.028725836 <a title="125-tfidf-14" href="./acl-2011-Towards_a_Framework_for_Abstractive_Summarization_of_Multimodal_Documents.html">308 acl-2011-Towards a Framework for Abstractive Summarization of Multimodal Documents</a></p>
<p>15 0.028385185 <a title="125-tfidf-15" href="./acl-2011-Types_of_Common-Sense_Knowledge_Needed_for_Recognizing_Textual_Entailment.html">315 acl-2011-Types of Common-Sense Knowledge Needed for Recognizing Textual Entailment</a></p>
<p>16 0.027352938 <a title="125-tfidf-16" href="./acl-2011-A_New_Dataset_and_Method_for_Automatically_Grading_ESOL_Texts.html">20 acl-2011-A New Dataset and Method for Automatically Grading ESOL Texts</a></p>
<p>17 0.027183108 <a title="125-tfidf-17" href="./acl-2011-An_Efficient_Indexer_for_Large_N-Gram_Corpora.html">36 acl-2011-An Efficient Indexer for Large N-Gram Corpora</a></p>
<p>18 0.027049793 <a title="125-tfidf-18" href="./acl-2011-Algorithm_Selection_and_Model_Adaptation_for_ESL_Correction_Tasks.html">32 acl-2011-Algorithm Selection and Model Adaptation for ESL Correction Tasks</a></p>
<p>19 0.027023328 <a title="125-tfidf-19" href="./acl-2011-Web-Scale_Features_for_Full-Scale_Parsing.html">333 acl-2011-Web-Scale Features for Full-Scale Parsing</a></p>
<p>20 0.026583176 <a title="125-tfidf-20" href="./acl-2011-Learning_Word_Vectors_for_Sentiment_Analysis.html">204 acl-2011-Learning Word Vectors for Sentiment Analysis</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.09), (1, 0.033), (2, -0.013), (3, 0.012), (4, -0.026), (5, -0.025), (6, 0.01), (7, -0.04), (8, 0.02), (9, -0.041), (10, -0.018), (11, -0.017), (12, -0.006), (13, 0.03), (14, -0.007), (15, -0.017), (16, -0.011), (17, 0.025), (18, -0.072), (19, -0.011), (20, 0.046), (21, 0.041), (22, -0.004), (23, -0.005), (24, -0.009), (25, 0.011), (26, 0.04), (27, 0.017), (28, 0.013), (29, -0.021), (30, 0.099), (31, -0.01), (32, 0.031), (33, -0.006), (34, -0.014), (35, 0.017), (36, -0.066), (37, -0.111), (38, 0.023), (39, 0.213), (40, 0.008), (41, -0.124), (42, 0.049), (43, 0.01), (44, 0.071), (45, -0.022), (46, -0.036), (47, 0.029), (48, 0.123), (49, 0.165)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93982244 <a title="125-lsi-1" href="./acl-2011-Exploiting_Readymades_in_Linguistic_Creativity%3A_A_System_Demonstration_of_the_Jigsaw_Bard.html">125 acl-2011-Exploiting Readymades in Linguistic Creativity: A System Demonstration of the Jigsaw Bard</a></p>
<p>Author: Tony Veale ; Yanfen Hao</p><p>Abstract: Large lexical resources, such as corpora and databases of Web ngrams, are a rich source of pre-fabricated phrases that can be reused in many different contexts. However, one must be careful in how these resources are used, and noted writers such as George Orwell have argued that the use of canned phrases encourages sloppy thinking and results in poor communication. Nonetheless, while Orwell prized home-made phrases over the readymade variety, there is a vibrant movement in modern art which shifts artistic creation from the production of novel artifacts to the clever reuse of readymades or objets trouvés. We describe here a system that makes creative reuse of the linguistic readymades in the Google ngrams. Our system, the Jigsaw Bard, thus owes more to Marcel Duchamp than to George Orwell. We demonstrate how textual readymades can be identified and harvested on a large scale, and used to drive a modest form of linguistic creativity. 1</p><p>2 0.75273246 <a title="125-lsi-2" href="./acl-2011-Creative_Language_Retrieval%3A_A_Robust_Hybrid_of_Information_Retrieval_and_Linguistic_Creativity.html">89 acl-2011-Creative Language Retrieval: A Robust Hybrid of Information Retrieval and Linguistic Creativity</a></p>
<p>Author: Tony Veale</p><p>Abstract: Information retrieval (IR) and figurative language processing (FLP) could scarcely be more different in their treatment of language and meaning. IR views language as an open-ended set of mostly stable signs with which texts can be indexed and retrieved, focusing more on a text’s potential relevance than its potential meaning. In contrast, FLP views language as a system of unstable signs that can be used to talk about the world in creative new ways. There is another key difference: IR is practical, scalable and robust, and in daily use by millions of casual users. FLP is neither scalable nor robust, and not yet practical enough to migrate beyond the lab. This paper thus presents a mutually beneficial hybrid of IR and FLP, one that enriches IR with new operators to enable the non-literal retrieval of creative expressions, and which also transplants FLP into a robust, scalable framework in which practical applications of linguistic creativity can be implemented. 1</p><p>3 0.45067677 <a title="125-lsi-3" href="./acl-2011-ConsentCanvas%3A_Automatic_Texturing_for_Improved_Readability_in_End-User_License_Agreements.html">80 acl-2011-ConsentCanvas: Automatic Texturing for Improved Readability in End-User License Agreements</a></p>
<p>Author: Oliver Schneider ; Alex Garnett</p><p>Abstract: We present ConsentCanvas, a system which structures and “texturizes” End-User License Agreement (EULA) documents to be more readable. The system aims to help users better understand the terms under which they are providing their informed consent. ConsentCanvas receives unstructured text documents as input and uses unsupervised natural language processing methods to embellish the source document using a linked stylesheet. Unlike similar usable security projects which employ summarization techniques, our system preserves the contents of the source document, minimizing the cognitive and legal burden for both the end user and the licensor. Our system does not require a corpus for training. 1</p><p>4 0.42571312 <a title="125-lsi-4" href="./acl-2011-Automatically_Predicting_Peer-Review_Helpfulness.html">55 acl-2011-Automatically Predicting Peer-Review Helpfulness</a></p>
<p>Author: Wenting Xiong ; Diane Litman</p><p>Abstract: Identifying peer-review helpfulness is an important task for improving the quality of feedback that students receive from their peers. As a first step towards enhancing existing peerreview systems with new functionality based on helpfulness detection, we examine whether standard product review analysis techniques also apply to our new context of peer reviews. In addition, we investigate the utility of incorporating additional specialized features tailored to peer review. Our preliminary results show that the structural features, review unigrams and meta-data combined are useful in modeling the helpfulness of both peer reviews and product reviews, while peer-review specific auxiliary features can further improve helpfulness prediction.</p><p>5 0.41581234 <a title="125-lsi-5" href="./acl-2011-Predicting_Relative_Prominence_in_Noun-Noun_Compounds.html">249 acl-2011-Predicting Relative Prominence in Noun-Noun Compounds</a></p>
<p>Author: Taniya Mishra ; Srinivas Bangalore</p><p>Abstract: There are several theories regarding what influences prominence assignment in English noun-noun compounds. We have developed corpus-driven models for automatically predicting prominence assignment in noun-noun compounds using feature sets based on two such theories: the informativeness theory and the semantic composition theory. The evaluation of the prediction models indicate that though both of these theories are relevant, they account for different types of variability in prominence assignment.</p><p>6 0.409365 <a title="125-lsi-6" href="./acl-2011-Predicting_Clicks_in_a_Vocabulary_Learning_System.html">248 acl-2011-Predicting Clicks in a Vocabulary Learning System</a></p>
<p>7 0.4028208 <a title="125-lsi-7" href="./acl-2011-Tier-based_Strictly_Local_Constraints_for_Phonology.html">303 acl-2011-Tier-based Strictly Local Constraints for Phonology</a></p>
<p>8 0.39995775 <a title="125-lsi-8" href="./acl-2011-SystemT%3A_A_Declarative_Information_Extraction_System.html">291 acl-2011-SystemT: A Declarative Information Extraction System</a></p>
<p>9 0.38416588 <a title="125-lsi-9" href="./acl-2011-Content_Models_with_Attitude.html">82 acl-2011-Content Models with Attitude</a></p>
<p>10 0.3768495 <a title="125-lsi-10" href="./acl-2011-A_Speech-based_Just-in-Time_Retrieval_System_using_Semantic_Search.html">26 acl-2011-A Speech-based Just-in-Time Retrieval System using Semantic Search</a></p>
<p>11 0.37415248 <a title="125-lsi-11" href="./acl-2011-Integrating_surprisal_and_uncertain-input_models_in_online_sentence_comprehension%3A_formal_techniques_and_empirical_results.html">176 acl-2011-Integrating surprisal and uncertain-input models in online sentence comprehension: formal techniques and empirical results</a></p>
<p>12 0.36931905 <a title="125-lsi-12" href="./acl-2011-Word_Maturity%3A_Computational_Modeling_of_Word_Knowledge.html">341 acl-2011-Word Maturity: Computational Modeling of Word Knowledge</a></p>
<p>13 0.34957108 <a title="125-lsi-13" href="./acl-2011-Subjective_Natural_Language_Problems%3A_Motivations%2C_Applications%2C_Characterizations%2C_and_Implications.html">288 acl-2011-Subjective Natural Language Problems: Motivations, Applications, Characterizations, and Implications</a></p>
<p>14 0.34178925 <a title="125-lsi-14" href="./acl-2011-Discovering_Sociolinguistic_Associations_with_Structured_Sparsity.html">97 acl-2011-Discovering Sociolinguistic Associations with Structured Sparsity</a></p>
<p>15 0.33363694 <a title="125-lsi-15" href="./acl-2011-Lexically-Triggered_Hidden_Markov_Models_for_Clinical_Document_Coding.html">209 acl-2011-Lexically-Triggered Hidden Markov Models for Clinical Document Coding</a></p>
<p>16 0.33213502 <a title="125-lsi-16" href="./acl-2011-An_Interface_for_Rapid_Natural_Language_Processing_Development_in_UIMA.html">42 acl-2011-An Interface for Rapid Natural Language Processing Development in UIMA</a></p>
<p>17 0.33039701 <a title="125-lsi-17" href="./acl-2011-A_New_Dataset_and_Method_for_Automatically_Grading_ESOL_Texts.html">20 acl-2011-A New Dataset and Method for Automatically Grading ESOL Texts</a></p>
<p>18 0.32079616 <a title="125-lsi-18" href="./acl-2011-Metagrammar_engineering%3A_Towards_systematic_exploration_of_implemented_grammars.html">219 acl-2011-Metagrammar engineering: Towards systematic exploration of implemented grammars</a></p>
<p>19 0.31316745 <a title="125-lsi-19" href="./acl-2011-Underspecifying_and_Predicting_Voice_for_Surface_Realisation_Ranking.html">317 acl-2011-Underspecifying and Predicting Voice for Surface Realisation Ranking</a></p>
<p>20 0.30999821 <a title="125-lsi-20" href="./acl-2011-Does_Size_Matter_-_How_Much_Data_is_Required_to_Train_a_REG_Algorithm%3F.html">102 acl-2011-Does Size Matter - How Much Data is Required to Train a REG Algorithm?</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(1, 0.013), (5, 0.031), (17, 0.031), (19, 0.417), (26, 0.029), (31, 0.019), (37, 0.043), (39, 0.03), (41, 0.034), (50, 0.046), (55, 0.03), (59, 0.03), (72, 0.029), (91, 0.042), (96, 0.087), (97, 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.81092 <a title="125-lda-1" href="./acl-2011-Exploiting_Readymades_in_Linguistic_Creativity%3A_A_System_Demonstration_of_the_Jigsaw_Bard.html">125 acl-2011-Exploiting Readymades in Linguistic Creativity: A System Demonstration of the Jigsaw Bard</a></p>
<p>Author: Tony Veale ; Yanfen Hao</p><p>Abstract: Large lexical resources, such as corpora and databases of Web ngrams, are a rich source of pre-fabricated phrases that can be reused in many different contexts. However, one must be careful in how these resources are used, and noted writers such as George Orwell have argued that the use of canned phrases encourages sloppy thinking and results in poor communication. Nonetheless, while Orwell prized home-made phrases over the readymade variety, there is a vibrant movement in modern art which shifts artistic creation from the production of novel artifacts to the clever reuse of readymades or objets trouvés. We describe here a system that makes creative reuse of the linguistic readymades in the Google ngrams. Our system, the Jigsaw Bard, thus owes more to Marcel Duchamp than to George Orwell. We demonstrate how textual readymades can be identified and harvested on a large scale, and used to drive a modest form of linguistic creativity. 1</p><p>2 0.49923307 <a title="125-lda-2" href="./acl-2011-Learning_Condensed_Feature_Representations_from_Large_Unsupervised_Data_Sets_for_Supervised_Learning.html">199 acl-2011-Learning Condensed Feature Representations from Large Unsupervised Data Sets for Supervised Learning</a></p>
<p>Author: Jun Suzuki ; Hideki Isozaki ; Masaaki Nagata</p><p>Abstract: This paper proposes a novel approach for effectively utilizing unsupervised data in addition to supervised data for supervised learning. We use unsupervised data to generate informative ‘condensed feature representations’ from the original feature set used in supervised NLP systems. The main contribution of our method is that it can offer dense and low-dimensional feature spaces for NLP tasks while maintaining the state-ofthe-art performance provided by the recently developed high-performance semi-supervised learning technique. Our method matches the results of current state-of-the-art systems with very few features, i.e., F-score 90.72 with 344 features for CoNLL-2003 NER data, and UAS 93.55 with 12.5K features for dependency parsing data derived from PTB-III. ,</p><p>3 0.46376106 <a title="125-lda-3" href="./acl-2011-Improving_Arabic_Dependency_Parsing_with_Form-based_and_Functional_Morphological_Features.html">164 acl-2011-Improving Arabic Dependency Parsing with Form-based and Functional Morphological Features</a></p>
<p>Author: Yuval Marton ; Nizar Habash ; Owen Rambow</p><p>Abstract: We explore the contribution of morphological features both lexical and inflectional to dependency parsing of Arabic, a morphologically rich language. Using controlled experiments, we find that definiteness, person, number, gender, and the undiacritzed lemma are most helpful for parsing on automatically tagged input. We further contrast the contribution of form-based and functional features, and show that functional gender and number (e.g., “broken plurals”) and the related rationality feature improve over form-based features. It is the first time functional morphological features are used for Arabic NLP. – –</p><p>4 0.44878283 <a title="125-lda-4" href="./acl-2011-Creative_Language_Retrieval%3A_A_Robust_Hybrid_of_Information_Retrieval_and_Linguistic_Creativity.html">89 acl-2011-Creative Language Retrieval: A Robust Hybrid of Information Retrieval and Linguistic Creativity</a></p>
<p>Author: Tony Veale</p><p>Abstract: Information retrieval (IR) and figurative language processing (FLP) could scarcely be more different in their treatment of language and meaning. IR views language as an open-ended set of mostly stable signs with which texts can be indexed and retrieved, focusing more on a text’s potential relevance than its potential meaning. In contrast, FLP views language as a system of unstable signs that can be used to talk about the world in creative new ways. There is another key difference: IR is practical, scalable and robust, and in daily use by millions of casual users. FLP is neither scalable nor robust, and not yet practical enough to migrate beyond the lab. This paper thus presents a mutually beneficial hybrid of IR and FLP, one that enriches IR with new operators to enable the non-literal retrieval of creative expressions, and which also transplants FLP into a robust, scalable framework in which practical applications of linguistic creativity can be implemented. 1</p><p>5 0.42099616 <a title="125-lda-5" href="./acl-2011-Good_Seed_Makes_a_Good_Crop%3A_Accelerating_Active_Learning_Using_Language_Modeling.html">145 acl-2011-Good Seed Makes a Good Crop: Accelerating Active Learning Using Language Modeling</a></p>
<p>Author: Dmitriy Dligach ; Martha Palmer</p><p>Abstract: Active Learning (AL) is typically initialized with a small seed of examples selected randomly. However, when the distribution of classes in the data is skewed, some classes may be missed, resulting in a slow learning progress. Our contribution is twofold: (1) we show that an unsupervised language modeling based technique is effective in selecting rare class examples, and (2) we use this technique for seeding AL and demonstrate that it leads to a higher learning rate. The evaluation is conducted in the context of word sense disambiguation.</p><p>6 0.30334181 <a title="125-lda-6" href="./acl-2011-Simple_Unsupervised_Grammar_Induction_from_Raw_Text_with_Cascaded_Finite_State_Models.html">284 acl-2011-Simple Unsupervised Grammar Induction from Raw Text with Cascaded Finite State Models</a></p>
<p>7 0.30207071 <a title="125-lda-7" href="./acl-2011-Jointly_Learning_to_Extract_and_Compress.html">187 acl-2011-Jointly Learning to Extract and Compress</a></p>
<p>8 0.29223624 <a title="125-lda-8" href="./acl-2011-EdIt%3A_A_Broad-Coverage_Grammar_Checker_Using_Pattern_Grammar.html">108 acl-2011-EdIt: A Broad-Coverage Grammar Checker Using Pattern Grammar</a></p>
<p>9 0.29083216 <a title="125-lda-9" href="./acl-2011-Evaluating_the_Impact_of_Coder_Errors_on_Active_Learning.html">119 acl-2011-Evaluating the Impact of Coder Errors on Active Learning</a></p>
<p>10 0.28982446 <a title="125-lda-10" href="./acl-2011-Fine-Grained_Class_Label_Markup_of_Search_Queries.html">137 acl-2011-Fine-Grained Class Label Markup of Search Queries</a></p>
<p>11 0.28852862 <a title="125-lda-11" href="./acl-2011-Coreference_for_Learning_to_Extract_Relations%3A_Yes_Virginia%2C_Coreference_Matters.html">86 acl-2011-Coreference for Learning to Extract Relations: Yes Virginia, Coreference Matters</a></p>
<p>12 0.28743291 <a title="125-lda-12" href="./acl-2011-Algorithm_Selection_and_Model_Adaptation_for_ESL_Correction_Tasks.html">32 acl-2011-Algorithm Selection and Model Adaptation for ESL Correction Tasks</a></p>
<p>13 0.28694791 <a title="125-lda-13" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>14 0.28681758 <a title="125-lda-14" href="./acl-2011-An_Efficient_Indexer_for_Large_N-Gram_Corpora.html">36 acl-2011-An Efficient Indexer for Large N-Gram Corpora</a></p>
<p>15 0.28650665 <a title="125-lda-15" href="./acl-2011-Extracting_Social_Power_Relationships_from_Natural_Language.html">133 acl-2011-Extracting Social Power Relationships from Natural Language</a></p>
<p>16 0.28619859 <a title="125-lda-16" href="./acl-2011-Interactive_Topic_Modeling.html">178 acl-2011-Interactive Topic Modeling</a></p>
<p>17 0.28617716 <a title="125-lda-17" href="./acl-2011-Knowledge-Based_Weak_Supervision_for_Information_Extraction_of_Overlapping_Relations.html">190 acl-2011-Knowledge-Based Weak Supervision for Information Extraction of Overlapping Relations</a></p>
<p>18 0.28533763 <a title="125-lda-18" href="./acl-2011-A_Comprehensive_Dictionary_of_Multiword_Expressions.html">6 acl-2011-A Comprehensive Dictionary of Multiword Expressions</a></p>
<p>19 0.285328 <a title="125-lda-19" href="./acl-2011-An_Empirical_Investigation_of_Discounting_in_Cross-Domain_Language_Models.html">38 acl-2011-An Empirical Investigation of Discounting in Cross-Domain Language Models</a></p>
<p>20 0.28518134 <a title="125-lda-20" href="./acl-2011-Using_Bilingual_Parallel_Corpora_for_Cross-Lingual_Textual_Entailment.html">327 acl-2011-Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
