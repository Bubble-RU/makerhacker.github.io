<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>183 acl-2011-Joint Bilingual Sentiment Classification with Unlabeled Parallel Corpora</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-183" href="#">acl2011-183</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>183 acl-2011-Joint Bilingual Sentiment Classification with Unlabeled Parallel Corpora</h1>
<br/><p>Source: <a title="acl-2011-183-pdf" href="http://aclweb.org/anthology//P/P11/P11-1033.pdf">pdf</a></p><p>Author: Bin Lu ; Chenhao Tan ; Claire Cardie ; Benjamin K. Tsou</p><p>Abstract: Most previous work on multilingual sentiment analysis has focused on methods to adapt sentiment resources from resource-rich languages to resource-poor languages. We present a novel approach for joint bilingual sentiment classification at the sentence level that augments available labeled data in each language with unlabeled parallel data. We rely on the intuition that the sentiment labels for parallel sentences should be similar and present a model that jointly learns improved monolingual sentiment classifiers for each language. Experiments on multiple data sets show that the proposed approach (1) outperforms the monolingual baselines, significantly improving the accuracy for both languages by 3.44%-8. 12%; (2) outperforms two standard approaches for leveraging unlabeled data; and (3) produces (albeit smaller) performance gains when employing pseudo-parallel data from machine translation engines. 1</p><p>Reference: <a title="acl-2011-183-reference" href="../acl2011_reference/acl-2011-Joint_Bilingual_Sentiment_Classification_with_Unlabeled_Parallel_Corpora_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Abstract Most previous work on multilingual sentiment analysis has focused on methods to adapt sentiment resources from resource-rich languages to resource-poor languages. [sent-6, score-0.944]
</p><p>2 We present a novel approach for joint bilingual sentiment classification at the sentence level that augments available labeled data in each language with unlabeled parallel data. [sent-7, score-1.605]
</p><p>3 We rely on the intuition that the sentiment labels for parallel sentences should be similar and present a model that jointly learns improved monolingual sentiment classifiers for each language. [sent-8, score-1.45]
</p><p>4 Experiments on multiple data sets show that the proposed approach (1) outperforms the monolingual baselines, significantly improving the accuracy for both languages by 3. [sent-9, score-0.385]
</p><p>5 12%; (2) outperforms two standard approaches for leveraging unlabeled data; and (3) produces (albeit smaller) performance gains when employing pseudo-parallel data from machine translation engines. [sent-11, score-0.585]
</p><p>6 1  Introduction  The field of sentiment analysis has quickly attracted the attention of researchers and practitioners alike (e. [sent-12, score-0.38]
</p><p>7 Indeed, sentiment analysis systems, which mine opinions from textual sources (e. [sent-18, score-0.38]
</p><p>8 Not surprisingly, most methods for sentiment classification are supervised learning techniques, which require training data annotated with the appropriate sentiment labels (e. [sent-22, score-0.919]
</p><p>9 Previous work in multilingual sentiment analysis  has therefore focused on methods to adapt sentiment resources (e. [sent-27, score-0.877]
</p><p>10 lexicons) from resourcerich languages (typically English) to other languages, with the goal of transferring sentiment or subjectivity analysis capabilities from English to other languages (e. [sent-29, score-0.588]
</p><p>11 In addition, there is still much room for improvement in existing monolingual (including English) sentiment classifiers, especially at the sentence level (Pang and Lee, 2008). [sent-40, score-0.574]
</p><p>12 This paper tackles the task of bilingual sentiment analysis. [sent-41, score-0.485]
</p><p>13 In contrast to previous work, we (1) assume that some amount of sentimentlabeled data is available for the language pair under study, and (2) investigate methods to simultaneously improve sentiment classification for both languages. [sent-42, score-0.641]
</p><p>14 Given the labeled data in each language, we propose an approach that exploits an unlabeled parallel corpus with the following Proce dinPgosrt olafn thde, 4 O9rtehg Aon ,n Ju anle M 1e9e-2tin4g, 2 o0f1 t1h. [sent-43, score-0.966]
</p><p>15 Ac s2s0o1ci1a Atiosnso fcoirat Cio nm foprut Caotimonpaulta Lti nognuails Lti cnsg,u piasgteics 320–3 0,  intuition: two sentences or documents that are parallel (i. [sent-45, score-0.278]
</p><p>16 translations of one another) should exhibit the same sentiment — their sentiment labels (e. [sent-47, score-0.796]
</p><p>17 Although our approach should be applicable at the document-level and for additional sentiment tasks, we focus on sentence-level polarity classification in this work. [sent-51, score-0.526]
</p><p>18 maximum entropy and SVM classifiers) as well as two alternative methods for leveraging unlabeled data (transductive SVMs (Joachims, 1999b) and cotraining (Blum and Mitchell, 1998)). [sent-54, score-0.519]
</p><p>19 We furthermore find that  improvements, albeit smaller, are obtained when the parallel data is replaced with a pseudo-parallel (i. [sent-58, score-0.324]
</p><p>20 To our knowledge, this is the first multilingual sentiment analysis study to focus on methods for simultaneously improving sentiment classification for a pair of languages based on unlabeled data rather than resource adaptation from one language to another. [sent-61, score-1.64]
</p><p>21 There is a growing body of work on multilingual sentiment analysis. [sent-67, score-0.497]
</p><p>22 Most approaches focus on resource adaptation from one language (usually English) to other languages with few sentiment resources. [sent-68, score-0.484]
</p><p>23 (2007), for example, generate subjectivity analysis resources in a new language from English sentiment resources by leveraging a bilingual dictionary or a parallel corpus. [sent-70, score-0.795]
</p><p>24 Prettenhofer and Stein (2010) investigate crosslingual sentiment classification from the perspective of domain adaptation based on structural correspondence learning (Blitzer et al. [sent-73, score-0.488]
</p><p>25 Chinese features comprising the two independent ―views‖ to exploit unlabeled Chinese data and a labeled English corpus and thereby improves Chinese sentiment classification. [sent-76, score-1.11]
</p><p>26 Another notable approach is the work of BoydGraber and Resnik (2010), which presents a generative model --- supervised multilingual latent Dirichlet allocation --- that jointly models topics that are consistent across languages, and employs them to better predict sentiment ratings. [sent-77, score-0.555]
</p><p>27 Unlike the methods described above, we focus on simultaneously improving the performance of sentiment classification in a pair of languages by  developing a model that relies on sentimentlabeled data in each language as well as unlabeled parallel text for the language pair. [sent-78, score-1.411]
</p><p>28 Another line of related work is semi-supervised learning, which combines labeled and unlabeled data to improve the performance of the task of interest (Zhu and Goldberg, 2009). [sent-80, score-0.73]
</p><p>29 Maximum likelihood parameter estimation (training) for such a model, with a set of labeled examples , amounts to solving the following optimization problem:  (2) 3. [sent-114, score-0.283]
</p><p>30 where denotes the polarity of the -th instance (positive or negative); and are respectively the numbers of labeled instances in and ; and are parallel instances in and respectively (i. [sent-122, score-0.588]
</p><p>31 Given the input data and our task is to jointly learn two monolingual sentiment classifiers — one for and one for . [sent-126, score-0.758]
</p><p>32 In this study, we focus on sentence-level sentiment classification, i. [sent-128, score-0.38]
</p><p>33 2  The Joint Model  Given the problem definition above, we now present a novel model to exploit the correspondence of parallel sentences in unlabeled bilingual text. [sent-132, score-0.85]
</p><p>34 (4) where is the unobserved class label for the -th instance in the unlabeled data. [sent-134, score-0.509]
</p><p>35 This probability directly models the sentiment label agreement between However, there could be considerable noise in real-world parallel data, i. [sent-135, score-0.616]
</p><p>36 the sentence pairs may be noisily parallel (or even comparable) instead of fully parallel (Munteanu and Marcu, 2005). [sent-137, score-0.472]
</p><p>37 In such noisy cases, the labels (positive or negative) could be different for the two monolingual sentences in a sentence pair. [sent-138, score-0.272]
</p><p>38 The intuition here is that if the translation probability of two sentences is high, the probability that they have the same sentiment label should be high as well. [sent-142, score-0.488]
</p><p>39 Therefore, by considering the noise in parallel data, we get:  (5) where is the translation probability of the -th sentence pair in ;2 is the opposite of the first term models the probability that and have the same label; and the second term models the probability that they have different labels. [sent-143, score-0.397]
</p><p>40 By further considering the weight to ascribe to the unlabeled data vs. [sent-144, score-0.587]
</p><p>41 When is 0, the algorithm ignores the unlabeled data and degenerates to two MaxEnt models trained on only the labeled data. [sent-146, score-0.776]
</p><p>42 3 The EM Algorithm on MaxEnt To solve the optimization problem for the model, we need to jointly estimate the optimal parameters for the two monolingual classifiers by finding: (7) This can be done with an EM algorithm, whose steps are summarized in Algorithm 1. [sent-148, score-0.326]
</p><p>43 Then, in the E-step, the  classifiers, based on current values of and , compute for each labeled example and assign probabilistically-weighted class labels to each unlabeled example. [sent-153, score-0.714]
</p><p>44 Next, in the M-step, the parameters, and , are updated using both the original labeled data (and ) and the newly labeled data . [sent-154, score-0.526]
</p><p>45 joint log likelihood; Convergence: If the increase of the joint log likelihood is sufficiently small, break; end for Output as and as  s,  In the M-step, we can optimize the regularized joint log likelihood using any gradient-based optimization technique (Malouf, 2002). [sent-160, score-0.61]
</p><p>46 , 1989) and run EM until the change in regularized joint log likelihood is less than 1e-5 or we reach 100  iterations. [sent-163, score-0.268]
</p><p>47 Google machine translation 4 ) to translate unlabeled indomain data from to or vice versa. [sent-171, score-0.585]
</p><p>48 In each setting, the English labeled data constitutes and the Chinese labeled data,  . [sent-195, score-0.474]
</p><p>49 For the unlabeled parallel text, we use the ISI Chinese-English parallel corpus (Munteanu and Marcu, 2005), which was extracted automatically from news articles published by Xinhua News Agency in the Chinese Gigaword (2nd Edition) and English Gigaword (2nd Edition) collections. [sent-197, score-0.939]
</p><p>50 To do this, we train a single classifier from the combined Chinese and English labeled data for each data setting above by concatenating the original English and Chinese feature sets. [sent-199, score-0.385]
</p><p>51 We then classify each unlabeled sentence pair by combining the two sentences in each pair into one. [sent-200, score-0.575]
</p><p>52 We choose the most confidently predicted 10,000 positive and 10,000 negative pairs to constitute the unlabeled parallel corpus for each data setting. [sent-201, score-0.881]
</p><p>53 MaxEnt: This method learns a MaxEnt classifier for each language given the monolingual labeled data; the unlabeled data is not used. [sent-210, score-0.974]
</p><p>54 SVM: This method learns an SVM classifier for each language given the monolingual labeled data; the unlabeled data is not used. [sent-211, score-0.974]
</p><p>55 Monolingual TSVM (TSVM-M): This method learns two transductive SVM (TSVM) classifiers given the monolingual labeled data and the monolingual unlabeled data for each language. [sent-213, score-1.382]
</p><p>56 Bilingual TSVM (TSVM-B): This method learns one TSVM classifier given the labeled training data in two languages together with the unlabeled sentences by combining the two sentences in each unlabeled pair into one. [sent-214, score-1.431]
</p><p>57 We expect this method to perform better than TSVMM since the combined (bilingual) unlabeled sentences could be more helpful than the unlabeled monolingual sentences. [sent-215, score-1.17]
</p><p>58 Co-Training with SVMs (Co-SVM): This method applies SVM-based co-training given both the labeled training data and the unlabeled parallel  data following Wan (2009). [sent-216, score-1.018]
</p><p>59 First, two monolingual SVM classifiers are built based on only the corresponding labeled data, and then they are bootstrapped by adding the most confident predicted examples from the unlabeled data into the training set. [sent-217, score-0.998]
</p><p>60 In each iteration, we select the most confidently predicted 50 positive and 50 negative sentences from each of the two classifiers, and take the union of the resulting 200 sentence pairs as the newly labeled training data. [sent-219, score-0.379]
</p><p>61 ) 5  Results and Analysis  In our experiments, the methods are tested in the two data settings with the corresponding unlabeled parallel corpus as mentioned in Section We use  4. [sent-221, score-0.802]
</p><p>62 Preliminary experiments showed that Equation 5 does not significantly improve the performance in our case, which is reasonable since we choose only sentence pairs with the highest translation probabilities to be our unlabeled data (see Section 4. [sent-223, score-0.622]
</p><p>63 (2002) showed that binary features perform better than frequency features for sentiment classification. [sent-227, score-0.38]
</p><p>64 The weights for unlabeled data and regularization, and , are set to 1 unless otherwise stated. [sent-228, score-0.519]
</p><p>65 By making use of the unlabeled parallel data, our proposed approach improves the accuracy, compared to MaxEnt, by 8. [sent-233, score-0.742]
</p><p>66 Among the baselines, the best is Co-SVM; TSVMs do not always improve performance using  8  the unlabeled data compared to the standalone SVM; and TSVM-B outperforms TSVM-M except for Chinese in the second setting. [sent-242, score-0.519]
</p><p>67 Without unlabeled parallel data, the performance on the Chinese data is better than on the English data, which is consistent with results reported in NTCIR-6 (Seki et al. [sent-244, score-0.755]
</p><p>68 Overall, the unlabeled parallel data improves classification accuracy for both languages when using our proposed joint model and Co-SVM. [sent-246, score-1.048]
</p><p>69 Weight of Unlabeled Data  classification alone is more difficult than Chinese for our datasets, we obtain greater performance gains for English by exploiting unlabeled parallel data as well as the Chinese labeled data. [sent-255, score-1.068]
</p><p>70 2  Varying the Weight Unlabeled Data  and Amount  of  Figure 1 shows the accuracy curve of the proposed  ,  approach for the two data settings when varying the weight for the unlabeled data, from 0 to 1. [sent-257, score-0.737]
</p><p>71 When is set to 0, the joint model degenerates to two MaxEnt models trained with only the labeled data. [sent-258, score-0.34]
</p><p>72 Although MPQA is more difficult in general compared to the NTCIR data, we still see steady improvements in performance with unlabeled parallel data. [sent-262, score-0.703]
</p><p>73 Overall, the proposed approach performs quite well for a wide range of parameter values of Figure 2 shows the accuracy curve of the proposed approach for the two data settings when varying the amount of unlabeled data from 0 to 20,000 instances. [sent-263, score-0.793]
</p><p>74 2  Amount of Unlabeled Data  more and more unlabeled data. [sent-269, score-0.467]
</p><p>75 However, even with only 2,000 unlabeled sentence pairs, the proposed approach still produces large performance gains. [sent-270, score-0.506]
</p><p>76 4, we generate pseudoparallel data by translating the monolingual sentences in each setting using Google’s machine translation system. [sent-273, score-0.493]
</p><p>77 Figures 3 and 4 show the  performance of our model using the pseudoparallel data versus the real parallel data, in the two settings, respectively. [sent-274, score-0.357]
</p><p>78 The EN->CH pseudoparallel data consists of the English unlabeled data and its automatic Chinese translation, and vice versa. [sent-275, score-0.64]
</p><p>79 The difference between using parallel versus pseudo-parallel data is around 2-4% in Figures 3 and 4, which is reasonable since the quality of the pseudo-parallel data is not as good as that of the parallel data. [sent-277, score-0.613]
</p><p>80 4 Adding Pseudo-Parallel Labeled Data In this section, we investigate how adding automatically translated labeled data might influence the performance as mentioned in Section 3. [sent-293, score-0.345]
</p><p>81 We use only the translated labeled data to train classifiers, and then directly classify the test data. [sent-295, score-0.345]
</p><p>82 In addition, the class distributions of the English labeled data and the Chinese are quite different (30% vs. [sent-302, score-0.296]
</p><p>83 Figures 5 and 6 show the accuracies when varying the weight of the translated labeled data vs. [sent-304, score-0.444]
</p><p>84 the labeled data, with and without the unlabeled parallel data. [sent-305, score-0.914]
</p><p>85 Accuracy with Pseudo-Parallel Labeled Data in Setting 2 see that the translated data can be helpful given the labeled data and even the unlabeled data, as long as is small; while in Figure 6, the translated data decreases the performance in most cases for setting 2. [sent-312, score-1.068]
</p><p>86 5  Discussion  To further understand what contributions our proposed approach makes to the performance gain, we look inside the parameters in the MaxEnt models learned before and after adding the parallel unlabeled data. [sent-315, score-0.742]
</p><p>87 Table 3 shows the features in the model learned from the labeled data that have the largest weight change after adding the parallel data;  Positve cmuop Woerta dnticoenB0 . [sent-316, score-0.567]
</p><p>88 de547i1D30g8hat and Table 4 shows the newly learned features from the unlabeled data with the largest weights. [sent-326, score-0.519]
</p><p>89 The new features also seem reasonable given the knowledge that the labeled and unlabeled data includes negative news about for specific topics (e. [sent-330, score-0.815]
</p><p>90 We also examine the process of joint training by checking the performance on test data and the agreement of the two monolingual models on the unlabeled parallel data in both settings. [sent-333, score-1.084]
</p><p>91 ) Since the two sentences discuss human rights from very different perspectives, it is reasonable that the two monolingual models will classify them with different polarities (i. [sent-347, score-0.334]
</p><p>92 6  Conclusion  In this paper, we study bilingual sentiment classification and propose a joint model to simultaneously learn better monolingual sentiment classifiers for each language by exploiting an unlabeled parallel corpus together with the labeled data available for each language. [sent-350, score-2.32]
</p><p>93 Our experiments show that the proposed approach can significantly improve sentiment classification for both languages. [sent-351, score-0.49]
</p><p>94 SVMs), and to extend the proposed model to handle word-level parallel information, e. [sent-355, score-0.275]
</p><p>95 Another issue is to investigate how to improve multilingual sentiment analysis by exploiting comparable corpora. [sent-358, score-0.528]
</p><p>96 Holistic sentiment analysis across languages: Multilingual supervised Latent Dirichlet Allocation. [sent-391, score-0.38]
</p><p>97 Learning with compositional semantics as structural inference for subsentential sentiment analysis. [sent-407, score-0.38]
</p><p>98 Dependency tree-based sentiment classification using CRFs with hidden variables. [sent-456, score-0.451]
</p><p>99 Text classification from labeled and unlabeled documents using EM. [sent-461, score-0.749]
</p><p>100 Opinion mining and sentiment analysis, Foundations and Trends in Information Retrieval, Now Publishers. [sent-470, score-0.38]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('unlabeled', 0.467), ('sentiment', 0.38), ('parallel', 0.236), ('labeled', 0.211), ('chinese', 0.202), ('monolingual', 0.194), ('maxent', 0.152), ('multilingual', 0.117), ('ntcir', 0.112), ('mpqa', 0.108), ('banea', 0.106), ('bilingual', 0.105), ('transductive', 0.088), ('burkett', 0.088), ('seki', 0.084), ('joint', 0.083), ('translated', 0.082), ('tsvm', 0.081), ('polarity', 0.075), ('classifiers', 0.074), ('subjectivity', 0.074), ('likelihood', 0.072), ('classification', 0.071), ('setting', 0.07), ('chenhao', 0.069), ('pseudoparallel', 0.069), ('sentimentlabeled', 0.069), ('english', 0.068), ('weight', 0.068), ('languages', 0.067), ('opinion', 0.066), ('wan', 0.066), ('translation', 0.066), ('rights', 0.061), ('prettenhofer', 0.061), ('amini', 0.061), ('regularized', 0.061), ('jointly', 0.058), ('pang', 0.058), ('blum', 0.058), ('svms', 0.055), ('svm', 0.054), ('mihalcea', 0.053), ('data', 0.052), ('log', 0.052), ('equation', 0.051), ('learns', 0.05), ('kong', 0.049), ('claire', 0.048), ('munteanu', 0.048), ('appendix', 0.048), ('negative', 0.048), ('settings', 0.047), ('em', 0.047), ('degenerates', 0.046), ('sindhwani', 0.046), ('tsvms', 0.046), ('xiaojun', 0.046), ('carmen', 0.046), ('positive', 0.046), ('janyce', 0.045), ('blitzer', 0.045), ('hong', 0.043), ('joachims', 0.042), ('unobserved', 0.042), ('sentences', 0.042), ('tseng', 0.041), ('yohei', 0.041), ('proposed', 0.039), ('choi', 0.039), ('wiebe', 0.039), ('schulz', 0.037), ('reasonable', 0.037), ('rada', 0.037), ('thumbs', 0.037), ('giza', 0.037), ('adaptation', 0.037), ('albeit', 0.036), ('simultaneously', 0.036), ('labels', 0.036), ('nigam', 0.035), ('cornell', 0.033), ('steadily', 0.033), ('noriko', 0.033), ('nakagawa', 0.033), ('stein', 0.033), ('respectively', 0.033), ('gradient', 0.033), ('quite', 0.033), ('pair', 0.033), ('accuracy', 0.033), ('breck', 0.032), ('confidently', 0.032), ('evans', 0.032), ('iterations', 0.031), ('term', 0.031), ('varying', 0.031), ('exploiting', 0.031), ('isi', 0.031), ('yejin', 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="183-tfidf-1" href="./acl-2011-Joint_Bilingual_Sentiment_Classification_with_Unlabeled_Parallel_Corpora.html">183 acl-2011-Joint Bilingual Sentiment Classification with Unlabeled Parallel Corpora</a></p>
<p>Author: Bin Lu ; Chenhao Tan ; Claire Cardie ; Benjamin K. Tsou</p><p>Abstract: Most previous work on multilingual sentiment analysis has focused on methods to adapt sentiment resources from resource-rich languages to resource-poor languages. We present a novel approach for joint bilingual sentiment classification at the sentence level that augments available labeled data in each language with unlabeled parallel data. We rely on the intuition that the sentiment labels for parallel sentences should be similar and present a model that jointly learns improved monolingual sentiment classifiers for each language. Experiments on multiple data sets show that the proposed approach (1) outperforms the monolingual baselines, significantly improving the accuracy for both languages by 3.44%-8. 12%; (2) outperforms two standard approaches for leveraging unlabeled data; and (3) produces (albeit smaller) performance gains when employing pseudo-parallel data from machine translation engines. 1</p><p>2 0.37545317 <a title="183-tfidf-2" href="./acl-2011-Using_Multiple_Sources_to_Construct_a_Sentiment_Sensitive_Thesaurus_for_Cross-Domain_Sentiment_Classification.html">332 acl-2011-Using Multiple Sources to Construct a Sentiment Sensitive Thesaurus for Cross-Domain Sentiment Classification</a></p>
<p>Author: Danushka Bollegala ; David Weir ; John Carroll</p><p>Abstract: We describe a sentiment classification method that is applicable when we do not have any labeled data for a target domain but have some labeled data for multiple other domains, designated as the source domains. We automat- ically create a sentiment sensitive thesaurus using both labeled and unlabeled data from multiple source domains to find the association between words that express similar sentiments in different domains. The created thesaurus is then used to expand feature vectors to train a binary classifier. Unlike previous cross-domain sentiment classification methods, our method can efficiently learn from multiple source domains. Our method significantly outperforms numerous baselines and returns results that are better than or comparable to previous cross-domain sentiment classification methods on a benchmark dataset containing Amazon user reviews for different types of products.</p><p>3 0.341573 <a title="183-tfidf-3" href="./acl-2011-Learning_Word_Vectors_for_Sentiment_Analysis.html">204 acl-2011-Learning Word Vectors for Sentiment Analysis</a></p>
<p>Author: Andrew L. Maas ; Raymond E. Daly ; Peter T. Pham ; Dan Huang ; Andrew Y. Ng ; Christopher Potts</p><p>Abstract: Unsupervised vector-based approaches to semantics can model rich lexical meanings, but they largely fail to capture sentiment information that is central to many word meanings and important for a wide range of NLP tasks. We present a model that uses a mix of unsupervised and supervised techniques to learn word vectors capturing semanticterm–documentinformation as well as rich sentiment content. The proposed model can leverage both continuous and multi-dimensional sentiment information as well as non-sentiment annotations. We instantiate the model to utilize the document-level sentiment polarity annotations present in many online documents (e.g. star ratings). We evaluate the model using small, widely used sentiment and subjectivity corpora and find it out-performs several previously introduced methods for sentiment classification. We also introduce a large dataset , of movie reviews to serve as a more robust benchmark for work in this area.</p><p>4 0.2455537 <a title="183-tfidf-4" href="./acl-2011-Semi-supervised_latent_variable_models_for_sentence-level_sentiment_analysis.html">279 acl-2011-Semi-supervised latent variable models for sentence-level sentiment analysis</a></p>
<p>Author: Oscar Tackstrom ; Ryan McDonald</p><p>Abstract: We derive two variants of a semi-supervised model for fine-grained sentiment analysis. Both models leverage abundant natural supervision in the form of review ratings, as well as a small amount of manually crafted sentence labels, to learn sentence-level sentiment classifiers. The proposed model is a fusion of a fully supervised structured conditional model and its partially supervised counterpart. This allows for highly efficient estimation and inference algorithms with rich feature definitions. We describe the two variants as well as their component models and verify experimentally that both variants give significantly improved results for sentence-level sentiment analysis compared to all baselines. 1 Sentence-level sentiment analysis In this paper, we demonstrate how combining coarse-grained and fine-grained supervision benefits sentence-level sentiment analysis an important task in the field of opinion classification and retrieval (Pang and Lee, 2008). Typical supervised learning approaches to sentence-level sentiment analysis rely on sentence-level supervision. While such fine-grained supervision rarely exist naturally, and thus requires labor intensive manual annotation effort (Wiebe et al., 2005), coarse-grained supervision is naturally abundant in the form of online review ratings. This coarse-grained supervision is, of course, less informative compared to fine-grained supervision, however, by combining a small amount of sentence-level supervision with a large amount of document-level supervision, we are able to substantially improve on the sentence-level classification task. Our work combines two strands of research: models for sentiment analysis that take document structure into account; – 569 Ryan McDonald Google, Inc., New York ryanmcd@ google com . and models that use latent variables to learn unobserved phenomena from that which can be observed. Exploiting document structure for sentiment analysis has attracted research attention since the early work of Pang and Lee (2004), who performed minimal cuts in a sentence graph to select subjective sentences. McDonald et al. (2007) later showed that jointly learning fine-grained (sentence) and coarsegrained (document) sentiment improves predictions at both levels. More recently, Yessenalina et al. (2010) described how sentence-level latent variables can be used to improve document-level prediction and Nakagawa et al. (2010) used latent variables over syntactic dependency trees to improve sentence-level prediction, using only labeled sentences for training. In a similar vein, Sauper et al. (2010) integrated generative content structure models with discriminative models for multi-aspect sentiment summarization and ranking. These approaches all rely on the availability of fine-grained annotations, but Ta¨ckstro¨m and McDonald (201 1) showed that latent variables can be used to learn fine-grained sentiment using only coarse-grained supervision. While this model was shown to beat a set of natural baselines with quite a wide margin, it has its shortcomings. Most notably, due to the loose constraints provided by the coarse supervision, it tends to only predict the two dominant fine-grained sentiment categories well for each document sentiment category, so that almost all sentences in positive documents are deemed positive or neutral, and vice versa for negative documents. As a way of overcoming these shortcomings, we propose to fuse a coarsely supervised model with a fully supervised model. Below, we describe two ways of achieving such a combined model in the framework of structured conditional latent variable models. Contrary to (generative) topic models (Mei et al., 2007; Titov and Proceedings ofP thoer t4l9atnhd A, Onrnuegaoln M,e Jeuntineg 19 o-f2 t4h,e 2 A0s1s1o.c?i ac t2io0n11 fo Ar Cssoocmiaptuiotanti foonra Clo Lminpguutiast i ocns:aslh Loirntpgaupisetrics , pages 569–574, Figure 1: a) Factor graph of the fully observed graphical model. b) Factor graph of the corresponding latent variable model. During training, shaded nodes are observed, while non-shaded nodes are unobserved. The input sentences si are always observed. Note that there are no factors connecting the document node, yd, with the input nodes, s, so that the sentence-level variables, ys, in effect form a bottleneck between the document sentiment and the input sentences. McDonald, 2008; Lin and He, 2009), structured conditional models can handle rich and overlapping features and allow for exact inference and simple gradient based estimation. The former models are largely orthogonal to the one we propose in this work and combining their merits might be fruitful. As shown by Sauper et al. (2010), it is possible to fuse generative document structure models and task specific structured conditional models. While we do model document structure in terms of sentiment transitions, we do not model topical structure. An interesting avenue for future work would be to extend the model of Sauper et al. (2010) to take coarse-grained taskspecific supervision into account, while modeling fine-grained task-specific aspects with latent variables. Note also that the proposed approach is orthogonal to semi-supervised and unsupervised induction of context independent (prior polarity) lexicons (Turney, 2002; Kim and Hovy, 2004; Esuli and Sebastiani, 2009; Rao and Ravichandran, 2009; Velikovich et al., 2010). The output of such models could readily be incorporated as features in the proposed model. 1.1 Preliminaries Let d be a document consisting of n sentences, s = (si)in=1, with a document–sentence-sequence pair denoted d = (d, s). Let yd = (yd, ys) denote random variables1 the document level sentiment, yd, and the sequence of sentence level sentiment, = (ysi)in=1 . – ys 1We are abusing notation throughout by using the same symbols to refer to random variables and their particular assignments. 570 In what follows, we assume that we have access to two training sets: a small set of fully labeled instances, DF = {(dj, and a large set of ydj)}jm=f1, coarsely labeled instances DC = {(dj, yjd)}jm=fm+fm+c1. Furthermore, we assume that yd and all yis take values in {POS, NEG, NEU}. We focus on structured conditional models in the exponential family, with the standard parametrization pθ(yd,ys|s) = expnhφ(yd,ys,s),θi − Aθ(s)o</p><p>5 0.24420771 <a title="183-tfidf-5" href="./acl-2011-Sentiment_Analysis_of_Citations_using_Sentence_Structure-Based_Features.html">281 acl-2011-Sentiment Analysis of Citations using Sentence Structure-Based Features</a></p>
<p>Author: Awais Athar</p><p>Abstract: Sentiment analysis of citations in scientific papers and articles is a new and interesting problem due to the many linguistic differences between scientific texts and other genres. In this paper, we focus on the problem of automatic identification of positive and negative sentiment polarity in citations to scientific papers. Using a newly constructed annotated citation sentiment corpus, we explore the effectiveness of existing and novel features, including n-grams, specialised science-specific lexical features, dependency relations, sentence splitting and negation features. Our results show that 3-grams and dependencies perform best in this task; they outperform the sentence splitting, science lexicon and negation based features.</p><p>6 0.24390543 <a title="183-tfidf-6" href="./acl-2011-Target-dependent_Twitter_Sentiment_Classification.html">292 acl-2011-Target-dependent Twitter Sentiment Classification</a></p>
<p>7 0.21631838 <a title="183-tfidf-7" href="./acl-2011-Automatically_Extracting_Polarity-Bearing_Topics_for_Cross-Domain_Sentiment_Classification.html">54 acl-2011-Automatically Extracting Polarity-Bearing Topics for Cross-Domain Sentiment Classification</a></p>
<p>8 0.21123023 <a title="183-tfidf-8" href="./acl-2011-PsychoSentiWordNet.html">253 acl-2011-PsychoSentiWordNet</a></p>
<p>9 0.20699483 <a title="183-tfidf-9" href="./acl-2011-Dr_Sentiment_Knows_Everything%21.html">105 acl-2011-Dr Sentiment Knows Everything!</a></p>
<p>10 0.19429396 <a title="183-tfidf-10" href="./acl-2011-Is_Machine_Translation_Ripe_for_Cross-Lingual_Sentiment_Classification%3F.html">179 acl-2011-Is Machine Translation Ripe for Cross-Lingual Sentiment Classification?</a></p>
<p>11 0.18015084 <a title="183-tfidf-11" href="./acl-2011-Aspect_Ranking%3A_Identifying_Important_Product_Aspects_from_Online_Consumer_Reviews.html">45 acl-2011-Aspect Ranking: Identifying Important Product Aspects from Online Consumer Reviews</a></p>
<p>12 0.17931995 <a title="183-tfidf-12" href="./acl-2011-Domain_Adaptation_by_Constraining_Inter-Domain_Variability_of_Latent_Feature_Representation.html">103 acl-2011-Domain Adaptation by Constraining Inter-Domain Variability of Latent Feature Representation</a></p>
<p>13 0.17929822 <a title="183-tfidf-13" href="./acl-2011-C-Feel-It%3A_A_Sentiment_Analyzer_for_Micro-blogs.html">64 acl-2011-C-Feel-It: A Sentiment Analyzer for Micro-blogs</a></p>
<p>14 0.17668331 <a title="183-tfidf-14" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<p>15 0.17436388 <a title="183-tfidf-15" href="./acl-2011-MemeTube%3A_A_Sentiment-based_Audiovisual_System_for_Analyzing_and_Displaying_Microblog_Messages.html">218 acl-2011-MemeTube: A Sentiment-based Audiovisual System for Analyzing and Displaying Microblog Messages</a></p>
<p>16 0.15329935 <a title="183-tfidf-16" href="./acl-2011-Identifying_Noun_Product_Features_that_Imply_Opinions.html">159 acl-2011-Identifying Noun Product Features that Imply Opinions</a></p>
<p>17 0.14259544 <a title="183-tfidf-17" href="./acl-2011-Extracting_Opinion_Expressions_and_Their_Polarities_-_Exploration_of_Pipelines_and_Joint_Models.html">131 acl-2011-Extracting Opinion Expressions and Their Polarities - Exploration of Pipelines and Joint Models</a></p>
<p>18 0.13959786 <a title="183-tfidf-18" href="./acl-2011-Subjectivity_and_Sentiment_Analysis_of_Modern_Standard_Arabic.html">289 acl-2011-Subjectivity and Sentiment Analysis of Modern Standard Arabic</a></p>
<p>19 0.13478602 <a title="183-tfidf-19" href="./acl-2011-Using_Bilingual_Information_for_Cross-Language_Document_Summarization.html">326 acl-2011-Using Bilingual Information for Cross-Language Document Summarization</a></p>
<p>20 0.12904008 <a title="183-tfidf-20" href="./acl-2011-Rare_Word_Translation_Extraction_from_Aligned_Comparable_Documents.html">259 acl-2011-Rare Word Translation Extraction from Aligned Comparable Documents</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.321), (1, 0.235), (2, 0.324), (3, -0.048), (4, 0.107), (5, 0.007), (6, 0.074), (7, 0.033), (8, 0.054), (9, -0.043), (10, 0.146), (11, -0.045), (12, -0.013), (13, -0.018), (14, 0.099), (15, 0.069), (16, 0.002), (17, 0.012), (18, 0.163), (19, 0.016), (20, -0.025), (21, -0.072), (22, -0.0), (23, 0.099), (24, 0.009), (25, 0.052), (26, -0.068), (27, 0.026), (28, 0.142), (29, -0.014), (30, 0.076), (31, 0.026), (32, -0.024), (33, -0.09), (34, -0.002), (35, -0.03), (36, 0.053), (37, 0.014), (38, 0.002), (39, 0.02), (40, -0.002), (41, 0.03), (42, 0.041), (43, 0.032), (44, -0.011), (45, -0.02), (46, -0.071), (47, -0.005), (48, -0.021), (49, 0.073)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96702641 <a title="183-lsi-1" href="./acl-2011-Joint_Bilingual_Sentiment_Classification_with_Unlabeled_Parallel_Corpora.html">183 acl-2011-Joint Bilingual Sentiment Classification with Unlabeled Parallel Corpora</a></p>
<p>Author: Bin Lu ; Chenhao Tan ; Claire Cardie ; Benjamin K. Tsou</p><p>Abstract: Most previous work on multilingual sentiment analysis has focused on methods to adapt sentiment resources from resource-rich languages to resource-poor languages. We present a novel approach for joint bilingual sentiment classification at the sentence level that augments available labeled data in each language with unlabeled parallel data. We rely on the intuition that the sentiment labels for parallel sentences should be similar and present a model that jointly learns improved monolingual sentiment classifiers for each language. Experiments on multiple data sets show that the proposed approach (1) outperforms the monolingual baselines, significantly improving the accuracy for both languages by 3.44%-8. 12%; (2) outperforms two standard approaches for leveraging unlabeled data; and (3) produces (albeit smaller) performance gains when employing pseudo-parallel data from machine translation engines. 1</p><p>2 0.85006076 <a title="183-lsi-2" href="./acl-2011-Using_Multiple_Sources_to_Construct_a_Sentiment_Sensitive_Thesaurus_for_Cross-Domain_Sentiment_Classification.html">332 acl-2011-Using Multiple Sources to Construct a Sentiment Sensitive Thesaurus for Cross-Domain Sentiment Classification</a></p>
<p>Author: Danushka Bollegala ; David Weir ; John Carroll</p><p>Abstract: We describe a sentiment classification method that is applicable when we do not have any labeled data for a target domain but have some labeled data for multiple other domains, designated as the source domains. We automat- ically create a sentiment sensitive thesaurus using both labeled and unlabeled data from multiple source domains to find the association between words that express similar sentiments in different domains. The created thesaurus is then used to expand feature vectors to train a binary classifier. Unlike previous cross-domain sentiment classification methods, our method can efficiently learn from multiple source domains. Our method significantly outperforms numerous baselines and returns results that are better than or comparable to previous cross-domain sentiment classification methods on a benchmark dataset containing Amazon user reviews for different types of products.</p><p>3 0.77736193 <a title="183-lsi-3" href="./acl-2011-Learning_Word_Vectors_for_Sentiment_Analysis.html">204 acl-2011-Learning Word Vectors for Sentiment Analysis</a></p>
<p>Author: Andrew L. Maas ; Raymond E. Daly ; Peter T. Pham ; Dan Huang ; Andrew Y. Ng ; Christopher Potts</p><p>Abstract: Unsupervised vector-based approaches to semantics can model rich lexical meanings, but they largely fail to capture sentiment information that is central to many word meanings and important for a wide range of NLP tasks. We present a model that uses a mix of unsupervised and supervised techniques to learn word vectors capturing semanticterm–documentinformation as well as rich sentiment content. The proposed model can leverage both continuous and multi-dimensional sentiment information as well as non-sentiment annotations. We instantiate the model to utilize the document-level sentiment polarity annotations present in many online documents (e.g. star ratings). We evaluate the model using small, widely used sentiment and subjectivity corpora and find it out-performs several previously introduced methods for sentiment classification. We also introduce a large dataset , of movie reviews to serve as a more robust benchmark for work in this area.</p><p>4 0.76639915 <a title="183-lsi-4" href="./acl-2011-Semi-supervised_latent_variable_models_for_sentence-level_sentiment_analysis.html">279 acl-2011-Semi-supervised latent variable models for sentence-level sentiment analysis</a></p>
<p>Author: Oscar Tackstrom ; Ryan McDonald</p><p>Abstract: We derive two variants of a semi-supervised model for fine-grained sentiment analysis. Both models leverage abundant natural supervision in the form of review ratings, as well as a small amount of manually crafted sentence labels, to learn sentence-level sentiment classifiers. The proposed model is a fusion of a fully supervised structured conditional model and its partially supervised counterpart. This allows for highly efficient estimation and inference algorithms with rich feature definitions. We describe the two variants as well as their component models and verify experimentally that both variants give significantly improved results for sentence-level sentiment analysis compared to all baselines. 1 Sentence-level sentiment analysis In this paper, we demonstrate how combining coarse-grained and fine-grained supervision benefits sentence-level sentiment analysis an important task in the field of opinion classification and retrieval (Pang and Lee, 2008). Typical supervised learning approaches to sentence-level sentiment analysis rely on sentence-level supervision. While such fine-grained supervision rarely exist naturally, and thus requires labor intensive manual annotation effort (Wiebe et al., 2005), coarse-grained supervision is naturally abundant in the form of online review ratings. This coarse-grained supervision is, of course, less informative compared to fine-grained supervision, however, by combining a small amount of sentence-level supervision with a large amount of document-level supervision, we are able to substantially improve on the sentence-level classification task. Our work combines two strands of research: models for sentiment analysis that take document structure into account; – 569 Ryan McDonald Google, Inc., New York ryanmcd@ google com . and models that use latent variables to learn unobserved phenomena from that which can be observed. Exploiting document structure for sentiment analysis has attracted research attention since the early work of Pang and Lee (2004), who performed minimal cuts in a sentence graph to select subjective sentences. McDonald et al. (2007) later showed that jointly learning fine-grained (sentence) and coarsegrained (document) sentiment improves predictions at both levels. More recently, Yessenalina et al. (2010) described how sentence-level latent variables can be used to improve document-level prediction and Nakagawa et al. (2010) used latent variables over syntactic dependency trees to improve sentence-level prediction, using only labeled sentences for training. In a similar vein, Sauper et al. (2010) integrated generative content structure models with discriminative models for multi-aspect sentiment summarization and ranking. These approaches all rely on the availability of fine-grained annotations, but Ta¨ckstro¨m and McDonald (201 1) showed that latent variables can be used to learn fine-grained sentiment using only coarse-grained supervision. While this model was shown to beat a set of natural baselines with quite a wide margin, it has its shortcomings. Most notably, due to the loose constraints provided by the coarse supervision, it tends to only predict the two dominant fine-grained sentiment categories well for each document sentiment category, so that almost all sentences in positive documents are deemed positive or neutral, and vice versa for negative documents. As a way of overcoming these shortcomings, we propose to fuse a coarsely supervised model with a fully supervised model. Below, we describe two ways of achieving such a combined model in the framework of structured conditional latent variable models. Contrary to (generative) topic models (Mei et al., 2007; Titov and Proceedings ofP thoer t4l9atnhd A, Onrnuegaoln M,e Jeuntineg 19 o-f2 t4h,e 2 A0s1s1o.c?i ac t2io0n11 fo Ar Cssoocmiaptuiotanti foonra Clo Lminpguutiast i ocns:aslh Loirntpgaupisetrics , pages 569–574, Figure 1: a) Factor graph of the fully observed graphical model. b) Factor graph of the corresponding latent variable model. During training, shaded nodes are observed, while non-shaded nodes are unobserved. The input sentences si are always observed. Note that there are no factors connecting the document node, yd, with the input nodes, s, so that the sentence-level variables, ys, in effect form a bottleneck between the document sentiment and the input sentences. McDonald, 2008; Lin and He, 2009), structured conditional models can handle rich and overlapping features and allow for exact inference and simple gradient based estimation. The former models are largely orthogonal to the one we propose in this work and combining their merits might be fruitful. As shown by Sauper et al. (2010), it is possible to fuse generative document structure models and task specific structured conditional models. While we do model document structure in terms of sentiment transitions, we do not model topical structure. An interesting avenue for future work would be to extend the model of Sauper et al. (2010) to take coarse-grained taskspecific supervision into account, while modeling fine-grained task-specific aspects with latent variables. Note also that the proposed approach is orthogonal to semi-supervised and unsupervised induction of context independent (prior polarity) lexicons (Turney, 2002; Kim and Hovy, 2004; Esuli and Sebastiani, 2009; Rao and Ravichandran, 2009; Velikovich et al., 2010). The output of such models could readily be incorporated as features in the proposed model. 1.1 Preliminaries Let d be a document consisting of n sentences, s = (si)in=1, with a document–sentence-sequence pair denoted d = (d, s). Let yd = (yd, ys) denote random variables1 the document level sentiment, yd, and the sequence of sentence level sentiment, = (ysi)in=1 . – ys 1We are abusing notation throughout by using the same symbols to refer to random variables and their particular assignments. 570 In what follows, we assume that we have access to two training sets: a small set of fully labeled instances, DF = {(dj, and a large set of ydj)}jm=f1, coarsely labeled instances DC = {(dj, yjd)}jm=fm+fm+c1. Furthermore, we assume that yd and all yis take values in {POS, NEG, NEU}. We focus on structured conditional models in the exponential family, with the standard parametrization pθ(yd,ys|s) = expnhφ(yd,ys,s),θi − Aθ(s)o</p><p>5 0.76140994 <a title="183-lsi-5" href="./acl-2011-Automatically_Extracting_Polarity-Bearing_Topics_for_Cross-Domain_Sentiment_Classification.html">54 acl-2011-Automatically Extracting Polarity-Bearing Topics for Cross-Domain Sentiment Classification</a></p>
<p>Author: Yulan He ; Chenghua Lin ; Harith Alani</p><p>Abstract: Joint sentiment-topic (JST) model was previously proposed to detect sentiment and topic simultaneously from text. The only supervision required by JST model learning is domain-independent polarity word priors. In this paper, we modify the JST model by incorporating word polarity priors through modifying the topic-word Dirichlet priors. We study the polarity-bearing topics extracted by JST and show that by augmenting the original feature space with polarity-bearing topics, the in-domain supervised classifiers learned from augmented feature representation achieve the state-of-the-art performance of 95% on the movie review data and an average of 90% on the multi-domain sentiment dataset. Furthermore, using feature augmentation and selection according to the information gain criteria for cross-domain sentiment classification, our proposed approach performs either better or comparably compared to previous approaches. Nevertheless, our approach is much simpler and does not require difficult parameter tuning.</p><p>6 0.69237471 <a title="183-lsi-6" href="./acl-2011-Aspect_Ranking%3A_Identifying_Important_Product_Aspects_from_Online_Consumer_Reviews.html">45 acl-2011-Aspect Ranking: Identifying Important Product Aspects from Online Consumer Reviews</a></p>
<p>7 0.69189376 <a title="183-lsi-7" href="./acl-2011-Is_Machine_Translation_Ripe_for_Cross-Lingual_Sentiment_Classification%3F.html">179 acl-2011-Is Machine Translation Ripe for Cross-Lingual Sentiment Classification?</a></p>
<p>8 0.65942365 <a title="183-lsi-8" href="./acl-2011-Target-dependent_Twitter_Sentiment_Classification.html">292 acl-2011-Target-dependent Twitter Sentiment Classification</a></p>
<p>9 0.64839184 <a title="183-lsi-9" href="./acl-2011-Sentiment_Analysis_of_Citations_using_Sentence_Structure-Based_Features.html">281 acl-2011-Sentiment Analysis of Citations using Sentence Structure-Based Features</a></p>
<p>10 0.62384254 <a title="183-lsi-10" href="./acl-2011-MemeTube%3A_A_Sentiment-based_Audiovisual_System_for_Analyzing_and_Displaying_Microblog_Messages.html">218 acl-2011-MemeTube: A Sentiment-based Audiovisual System for Analyzing and Displaying Microblog Messages</a></p>
<p>11 0.60101795 <a title="183-lsi-11" href="./acl-2011-Subjectivity_and_Sentiment_Analysis_of_Modern_Standard_Arabic.html">289 acl-2011-Subjectivity and Sentiment Analysis of Modern Standard Arabic</a></p>
<p>12 0.59295732 <a title="183-lsi-12" href="./acl-2011-Domain_Adaptation_by_Constraining_Inter-Domain_Variability_of_Latent_Feature_Representation.html">103 acl-2011-Domain Adaptation by Constraining Inter-Domain Variability of Latent Feature Representation</a></p>
<p>13 0.58331764 <a title="183-lsi-13" href="./acl-2011-C-Feel-It%3A_A_Sentiment_Analyzer_for_Micro-blogs.html">64 acl-2011-C-Feel-It: A Sentiment Analyzer for Micro-blogs</a></p>
<p>14 0.571917 <a title="183-lsi-14" href="./acl-2011-PsychoSentiWordNet.html">253 acl-2011-PsychoSentiWordNet</a></p>
<p>15 0.56045622 <a title="183-lsi-15" href="./acl-2011-Dr_Sentiment_Knows_Everything%21.html">105 acl-2011-Dr Sentiment Knows Everything!</a></p>
<p>16 0.55615127 <a title="183-lsi-16" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<p>17 0.53035396 <a title="183-lsi-17" href="./acl-2011-Semi-supervised_condensed_nearest_neighbor_for_part-of-speech_tagging.html">278 acl-2011-Semi-supervised condensed nearest neighbor for part-of-speech tagging</a></p>
<p>18 0.52830148 <a title="183-lsi-18" href="./acl-2011-Content_Models_with_Attitude.html">82 acl-2011-Content Models with Attitude</a></p>
<p>19 0.5201776 <a title="183-lsi-19" href="./acl-2011-Liars_and_Saviors_in_a_Sentiment_Annotated_Corpus_of_Comments_to_Political_Debates.html">211 acl-2011-Liars and Saviors in a Sentiment Annotated Corpus of Comments to Political Debates</a></p>
<p>20 0.50502825 <a title="183-lsi-20" href="./acl-2011-Domain_Adaptation_for_Machine_Translation_by_Mining_Unseen_Words.html">104 acl-2011-Domain Adaptation for Machine Translation by Mining Unseen Words</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.027), (11, 0.101), (17, 0.032), (26, 0.046), (37, 0.218), (39, 0.049), (41, 0.058), (53, 0.035), (55, 0.04), (59, 0.049), (69, 0.015), (72, 0.033), (88, 0.016), (91, 0.032), (96, 0.175), (97, 0.01), (98, 0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94412416 <a title="183-lda-1" href="./acl-2011-Joint_Bilingual_Sentiment_Classification_with_Unlabeled_Parallel_Corpora.html">183 acl-2011-Joint Bilingual Sentiment Classification with Unlabeled Parallel Corpora</a></p>
<p>Author: Bin Lu ; Chenhao Tan ; Claire Cardie ; Benjamin K. Tsou</p><p>Abstract: Most previous work on multilingual sentiment analysis has focused on methods to adapt sentiment resources from resource-rich languages to resource-poor languages. We present a novel approach for joint bilingual sentiment classification at the sentence level that augments available labeled data in each language with unlabeled parallel data. We rely on the intuition that the sentiment labels for parallel sentences should be similar and present a model that jointly learns improved monolingual sentiment classifiers for each language. Experiments on multiple data sets show that the proposed approach (1) outperforms the monolingual baselines, significantly improving the accuracy for both languages by 3.44%-8. 12%; (2) outperforms two standard approaches for leveraging unlabeled data; and (3) produces (albeit smaller) performance gains when employing pseudo-parallel data from machine translation engines. 1</p><p>2 0.92969346 <a title="183-lda-2" href="./acl-2011-Automatic_Detection_and_Correction_of_Errors_in_Dependency_Treebanks.html">48 acl-2011-Automatic Detection and Correction of Errors in Dependency Treebanks</a></p>
<p>Author: Alexander Volokh ; Gunter Neumann</p><p>Abstract: Annotated corpora are essential for almost all NLP applications. Whereas they are expected to be of a very high quality because of their importance for the followup developments, they still contain a considerable number of errors. With this work we want to draw attention to this fact. Additionally, we try to estimate the amount of errors and propose a method for their automatic correction. Whereas our approach is able to find only a portion of the errors that we suppose are contained in almost any annotated corpus due to the nature of the process of its creation, it has a very high precision, and thus is in any case beneficial for the quality of the corpus it is applied to. At last, we compare it to a different method for error detection in treebanks and find out that the errors that we are able to detect are mostly different and that our approaches are complementary. 1</p><p>3 0.9222942 <a title="183-lda-3" href="./acl-2011-Using_Multiple_Sources_to_Construct_a_Sentiment_Sensitive_Thesaurus_for_Cross-Domain_Sentiment_Classification.html">332 acl-2011-Using Multiple Sources to Construct a Sentiment Sensitive Thesaurus for Cross-Domain Sentiment Classification</a></p>
<p>Author: Danushka Bollegala ; David Weir ; John Carroll</p><p>Abstract: We describe a sentiment classification method that is applicable when we do not have any labeled data for a target domain but have some labeled data for multiple other domains, designated as the source domains. We automat- ically create a sentiment sensitive thesaurus using both labeled and unlabeled data from multiple source domains to find the association between words that express similar sentiments in different domains. The created thesaurus is then used to expand feature vectors to train a binary classifier. Unlike previous cross-domain sentiment classification methods, our method can efficiently learn from multiple source domains. Our method significantly outperforms numerous baselines and returns results that are better than or comparable to previous cross-domain sentiment classification methods on a benchmark dataset containing Amazon user reviews for different types of products.</p><p>4 0.92082703 <a title="183-lda-4" href="./acl-2011-Event_Extraction_as_Dependency_Parsing.html">122 acl-2011-Event Extraction as Dependency Parsing</a></p>
<p>Author: David McClosky ; Mihai Surdeanu ; Christopher Manning</p><p>Abstract: Nested event structures are a common occurrence in both open domain and domain specific extraction tasks, e.g., a “crime” event can cause a “investigation” event, which can lead to an “arrest” event. However, most current approaches address event extraction with highly local models that extract each event and argument independently. We propose a simple approach for the extraction of such structures by taking the tree of event-argument relations and using it directly as the representation in a reranking dependency parser. This provides a simple framework that captures global properties of both nested and flat event structures. We explore a rich feature space that models both the events to be parsed and context from the original supporting text. Our approach obtains competitive results in the extraction of biomedical events from the BioNLP’09 shared task with a F1 score of 53.5% in development and 48.6% in testing.</p><p>5 0.91974974 <a title="183-lda-5" href="./acl-2011-Finding_Deceptive_Opinion_Spam_by_Any_Stretch_of_the_Imagination.html">136 acl-2011-Finding Deceptive Opinion Spam by Any Stretch of the Imagination</a></p>
<p>Author: Myle Ott ; Yejin Choi ; Claire Cardie ; Jeffrey T. Hancock</p><p>Abstract: Consumers increasingly rate, review and research products online (Jansen, 2010; Litvin et al., 2008). Consequently, websites containing consumer reviews are becoming targets of opinion spam. While recent work has focused primarily on manually identifiable instances of opinion spam, in this work we study deceptive opinion spam—fictitious opinions that have been deliberately written to sound authentic. Integrating work from psychology and computational linguistics, we develop and compare three approaches to detecting deceptive opinion spam, and ultimately develop a classifier that is nearly 90% accurate on our gold-standard opinion spam dataset. Based on feature analysis of our learned models, we additionally make several theoretical contributions, including revealing a relationship between deceptive opinions and imaginative writing.</p><p>6 0.91793007 <a title="183-lda-6" href="./acl-2011-Which_Noun_Phrases_Denote_Which_Concepts%3F.html">334 acl-2011-Which Noun Phrases Denote Which Concepts?</a></p>
<p>7 0.91669387 <a title="183-lda-7" href="./acl-2011-Target-dependent_Twitter_Sentiment_Classification.html">292 acl-2011-Target-dependent Twitter Sentiment Classification</a></p>
<p>8 0.91558588 <a title="183-lda-8" href="./acl-2011-Learning_Word_Vectors_for_Sentiment_Analysis.html">204 acl-2011-Learning Word Vectors for Sentiment Analysis</a></p>
<p>9 0.91444743 <a title="183-lda-9" href="./acl-2011-Data_point_selection_for_cross-language_adaptation_of_dependency_parsers.html">92 acl-2011-Data point selection for cross-language adaptation of dependency parsers</a></p>
<p>10 0.91286552 <a title="183-lda-10" href="./acl-2011-Exploiting_Web-Derived_Selectional_Preference_to_Improve_Statistical_Dependency_Parsing.html">127 acl-2011-Exploiting Web-Derived Selectional Preference to Improve Statistical Dependency Parsing</a></p>
<p>11 0.9128288 <a title="183-lda-11" href="./acl-2011-Query_Weighting_for_Ranking_Model_Adaptation.html">256 acl-2011-Query Weighting for Ranking Model Adaptation</a></p>
<p>12 0.91126966 <a title="183-lda-12" href="./acl-2011-Automatically_Extracting_Polarity-Bearing_Topics_for_Cross-Domain_Sentiment_Classification.html">54 acl-2011-Automatically Extracting Polarity-Bearing Topics for Cross-Domain Sentiment Classification</a></p>
<p>13 0.90782428 <a title="183-lda-13" href="./acl-2011-Domain_Adaptation_by_Constraining_Inter-Domain_Variability_of_Latent_Feature_Representation.html">103 acl-2011-Domain Adaptation by Constraining Inter-Domain Variability of Latent Feature Representation</a></p>
<p>14 0.90612221 <a title="183-lda-14" href="./acl-2011-Coreference_Resolution_with_World_Knowledge.html">85 acl-2011-Coreference Resolution with World Knowledge</a></p>
<p>15 0.90525454 <a title="183-lda-15" href="./acl-2011-Neutralizing_Linguistically_Problematic_Annotations_in_Unsupervised_Dependency_Parsing_Evaluation.html">230 acl-2011-Neutralizing Linguistically Problematic Annotations in Unsupervised Dependency Parsing Evaluation</a></p>
<p>16 0.90109158 <a title="183-lda-16" href="./acl-2011-Transition-based_Dependency_Parsing_with_Rich_Non-local_Features.html">309 acl-2011-Transition-based Dependency Parsing with Rich Non-local Features</a></p>
<p>17 0.90078115 <a title="183-lda-17" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<p>18 0.89868641 <a title="183-lda-18" href="./acl-2011-Discriminative_Feature-Tied_Mixture_Modeling_for_Statistical_Machine_Translation.html">100 acl-2011-Discriminative Feature-Tied Mixture Modeling for Statistical Machine Translation</a></p>
<p>19 0.89788675 <a title="183-lda-19" href="./acl-2011-An_Ensemble_Model_that_Combines_Syntactic_and_Semantic_Clustering_for_Discriminative_Dependency_Parsing.html">39 acl-2011-An Ensemble Model that Combines Syntactic and Semantic Clustering for Discriminative Dependency Parsing</a></p>
<p>20 0.89736986 <a title="183-lda-20" href="./acl-2011-Subjectivity_and_Sentiment_Analysis_of_Modern_Standard_Arabic.html">289 acl-2011-Subjectivity and Sentiment Analysis of Modern Standard Arabic</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
