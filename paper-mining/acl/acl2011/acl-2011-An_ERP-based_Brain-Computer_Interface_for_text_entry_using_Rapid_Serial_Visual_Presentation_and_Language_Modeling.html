<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>35 acl-2011-An ERP-based Brain-Computer Interface for text entry using Rapid Serial Visual Presentation and Language Modeling</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-35" href="#">acl2011-35</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>35 acl-2011-An ERP-based Brain-Computer Interface for text entry using Rapid Serial Visual Presentation and Language Modeling</h1>
<br/><p>Source: <a title="acl-2011-35-pdf" href="http://aclweb.org/anthology//P/P11/P11-4007.pdf">pdf</a></p><p>Author: Kenneth Hild ; Umut Orhan ; Deniz Erdogmus ; Brian Roark ; Barry Oken ; Shalini Purwar ; Hooman Nezamfar ; Melanie Fried-Oken</p><p>Abstract: Event related potentials (ERP) corresponding to stimuli in electroencephalography (EEG) can be used to detect the intent of a person for brain computer interfaces (BCI). This paradigm is widely used to build letter-byletter text input systems using BCI. Nevertheless using a BCI-typewriter depending only on EEG responses will not be sufficiently accurate for single-trial operation in general, and existing systems utilize many-trial schemes to achieve accuracy at the cost of speed. Hence incorporation of a language model based prior or additional evidence is vital to improve accuracy and speed. In this demonstration we will present a BCI system for typing that integrates a stochastic language model with ERP classification to achieve speedups, via the rapid serial visual presentation (RSVP) paradigm.</p><p>Reference: <a title="acl-2011-35-reference" href="../acl2011_reference/acl-2011-An_ERP-based_Brain-Computer_Interface_for_text_entry_using_Rapid_Serial_Visual_Presentation_and_Language_Modeling_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Fried-Oken◦  ◦Oregon Health and Science University {hi ldk roarkb oken friedm} @ ohsu . [sent-10, score-0.049]
</p><p>2 edu  ,  ,  ,  Abstract Event related potentials (ERP) corresponding to stimuli in electroencephalography (EEG) can be used to detect the intent of a person for brain computer interfaces (BCI). [sent-11, score-0.421]
</p><p>3 This paradigm is widely used to build letter-byletter text input systems using BCI. [sent-12, score-0.079]
</p><p>4 Hence incorporation of a language model based prior or additional evidence is vital to improve accuracy and speed. [sent-14, score-0.042]
</p><p>5 In this demonstration we will present a BCI system for typing that integrates a stochastic language model with ERP classification to achieve speedups, via the rapid serial visual presentation (RSVP) paradigm. [sent-15, score-0.397]
</p><p>6 1 Introduction  There exist a considerable number ofpeople with severe motor and speech disabilities. [sent-16, score-0.065]
</p><p>7 Brain computer interfaces (BCI) are a potential technology to create a novel communication environment for this population, especially persons with completely paralyzed voluntary muscles (Wolpaw, 2007; Pfurtscheller et al. [sent-17, score-0.163]
</p><p>8 One possible application of BCI is typing systems; specifically, those BCI systems that use electroencephalography (EEG) have been increasingly studied in the recent decades to enable the selection of letters for expressive language generation (Wolpaw, 2007; Pfurtscheller et al. [sent-19, score-0.2]
</p><p>9 However, the use of noninvasive techniques for letter-by-letter systems lacks efficiency due to low signal to noise ratio and variability of background brain activity. [sent-21, score-0.184]
</p><p>10 Therefore current BCI-spellers suffer from low symbol rates and researchers have turned to various hierarchical symbol trees to achieve system speedups (Serby et al. [sent-22, score-0.354]
</p><p>11 Incorporation of a language model, which predicts the next letter using the previous letters, into the 38  †Cognitive Systems Lab, Northeastern University {orhan ,e rdogmus ,purwar ,ne z amfar} @ e ce . [sent-26, score-0.067]
</p><p>12 As opposed to the matrix layout of the popular P300-Speller (Wolpaw, 2007), shown in Figure 1, or the hexagonal two-level hierarchy of the Berlin BCI (Treder and Blankertz, 2010), we utilize another well-established paradigm: rapid serial visual presentation (RSVP), shown in Figure 2. [sent-29, score-0.365]
</p><p>13 This paradigm relies on presenting one stimulus at a time at the focal point of the screen. [sent-30, score-0.276]
</p><p>14 The sequence of stimuli are presented at relatively high speeds, each subsequent stimulus replacing the previous one, while the subject tries to perform mental target matching between the intended symbol and the presented stimuli. [sent-31, score-0.668]
</p><p>15 EEG responses corresponding to the visual stimuli are classified using regularized discriminant analysis (RDA) applied to stimuluslocked temporal features from multiple channels. [sent-32, score-0.508]
</p><p>16 The RSVP interface is of particular utility for the most impaired users, including those suffering from locked-in syndrome (LIS). [sent-33, score-0.225]
</p><p>17 Locked-in syndrome can result from traumatic brain injury, such as a brainstem , or from neurodegenerative diseases such as amyotrophic lateral sclerosis (ALS or Lou  stroke1  Gehrig’s disease). [sent-34, score-0.195]
</p><p>18 While vision is retained, the motor control impairments extend to eye movements. [sent-36, score-0.098]
</p><p>19 an individual is a particular muscle twitch or single eye blink, if that. [sent-43, score-0.077]
</p><p>20 Such users have lost the voluntary motor control sufficient for such an interface. [sent-44, score-0.114]
</p><p>21 Relying on extensive visual scanning or complex gestural feedback from the user renders a typing interface difficult or impossible to use for the most impaired users. [sent-45, score-0.515]
</p><p>22 Simpler interactions via brain-computer interfaces (BCI) hold much promise for effective text communication for these most impaired users. [sent-46, score-0.223]
</p><p>23 Yet these simple interfaces have yet to take full advantage of language models to ease or speed typing. [sent-47, score-0.083]
</p><p>24 In this demonstration, we will present a languagemodel enabled interface that is appropriate for the most impaired users. [sent-48, score-0.176]
</p><p>25 In addition, the RSVP paradigm provides some useful interface flexibility relative to the grid-based paradigm. [sent-49, score-0.146]
</p><p>26 First, it allows for auditory rather than  visual scanning, for use by the visually impaired or when visual access is inconvenient, such as in face-to-face communication. [sent-50, score-0.449]
</p><p>27 Auditory scanning is less straightforward when using a grid. [sent-51, score-0.072]
</p><p>28 2  RSVP based BCI and ERP Classification  RSVP is an experimental psychophysics technique in which visual stimulus sequences are displayed on a screen over time on a fixed focal area and in rapid succession. [sent-56, score-0.623]
</p><p>29 tec, Austria) opts for a spatially distributed presentation of possible symbols, highlighting them in different orders and combinations to elicit P300 responses. [sent-58, score-0.111]
</p><p>30 Berlin BCI’s recent variation utilizes a 2-layer tree structure where the subject chooses among six units (symbols or sets of these) where the options are laid out on the screen while the subject focuses on a central focal area that uses an RSVP-like paradigm to  elicit P300 responses. [sent-59, score-0.487]
</p><p>31 In contrast, our approach is to distribute the stimuli temporally and present one symbol at a time using RSVP and seek a binary response to find the desired letter, as shown in Figure 2. [sent-61, score-0.368]
</p><p>32 The latter method has the advantage of not requiring the user to look at different areas of the screen, which can be an important factor for those with LIS. [sent-62, score-0.052]
</p><p>33 Our RSVP paradigm utilizes stimulus sequences consisting of the 26 letters in the English alphabet plus symbols for space and backspace, presented in a randomly ordered sequence. [sent-63, score-0.535]
</p><p>34 This natural novelty response of the brain, occurring when the user detects a rare, sought-after target, allows us to make binary decisions about the user’s intent. [sent-65, score-0.119]
</p><p>35 The intent detection problem becomes a signal classification problem when the EEG signals are windowed in a stimulus-time-locked manner start-  ing at stimulus onset and extending for a sufficient duration in this case 500ms. [sent-66, score-0.273]
</p><p>36 Consider Figure 3, which shows the trial-averaged temporal signals from various EEG channels corresponding to target and non-target (distractor) symbols. [sent-67, score-0.101]
</p><p>37 This graph shows a clear effect between 300 and 500 ms for the target symbols that is not present for the distractor symbols (the latter of which clearly shows a component having a periodicity of 400 ms, which is expected in this case since a new image was presented every 400 ms). [sent-68, score-0.477]
</p><p>38 Figure 4, on the other hand, shows the magnitude of the trial and distractor responses at channel Cz on a single-trial basis, rather than averaged over all trials. [sent-69, score-0.263]
</p><p>39 The signals acquired from each EEG channel are incorporated and classified to determine the class label: ERP or non-ERP. [sent-70, score-0.16]
</p><p>40 Fourth, the data vectors obtained for each channel and a given stimulus are concatenated to create the data matrix corresponding to the specified stimulus. [sent-75, score-0.236]
</p><p>41 Fifth, Regularized Discriminant Anal–  ysis (RDA) (Friedman, 1989), which estimates conditional probability densities for each class using  Figure 3: Trial-averaged EEG data corresponding to the target response (top) and distractor response (bottom) for a 1 second window. [sent-76, score-0.34]
</p><p>42 Kernel Density Estimation (KDE), is used to determine a purely EEG-based classification discriminant score for each stimulus. [sent-77, score-0.107]
</p><p>43 Sixth, the conditional probability of each letter given the typed history is obtained from the language model. [sent-78, score-0.124]
</p><p>44 RDA is a modified quadratic discriminant analysis (QDA) model. [sent-80, score-0.107]
</p><p>45 Assuming each class has a multivariate normal distribution and assuming classification is made according to the comparison of posterior distributions of the classes, the optimal Bayes classifier resides within the QDA model family. [sent-81, score-0.081]
</p><p>46 QDA depends on the inverse of the class covariance matrices, which are to be estimated from training data. [sent-82, score-0.179]
</p><p>47 RDA applies regularization and shrinkage procedures to the class covariance matrix 40  Figure 4: Single-trial EEG data at channel Cz corresponding to the target response (top) and distractor response (bottom) for a 1second window. [sent-84, score-0.706]
</p><p>48 The shrinkage procedure makes the class covariances closer to the overall data covariance, and therefore to each other, thus making the quadratic boundary more similar to a linear boundary. [sent-86, score-0.174]
</p><p>49 Regularization is administered as  Σˆc(λ,γ) = (1 − γ)Σˆc(λ) +dγtr[Σˆc(λ)]I,  (2)  where γ is the regularization parameter, tr[·] is the wtrahceer efu γnc isti othne, raengdu lda i sz tthioen ndi pmareanmsieotner ,o tfr [t·h]e i sd tahtea  vector. [sent-88, score-0.039]
</p><p>50 After carrying out the regularization and shrinkage on the estimated covariance matrices, the Bayesian classification rule (Duda et al. [sent-89, score-0.292]
</p><p>51 The set of visual stimuli (letters plus two extra symbols, in our case) can be shown multiple times to achieve a higher classification accuracy for the EEG-based classifier. [sent-93, score-0.294]
</p><p>52 The information obtained from showing the visual stimuli multiple times can easily be combined by assuming the trials are statistically independent, as is commonly assumed in EEG-based spellers2. [sent-94, score-0.326]
</p><p>53 Figure 5 presents a diagram of the timing of the presentation of stimuli. [sent-95, score-0.162]
</p><p>54 We define a sequence to be a randomly-ordered set of all the letters (and the space and backspace symbols). [sent-96, score-0.24]
</p><p>55 The letters are randomly ordered for each sequence because the magnitude of the ERP, hence the quality of the EEG-based classification, is commonly thought to depend on how surprised the user is to find the intended letter. [sent-97, score-0.196]
</p><p>56 Our system also has a user-defined parameter by which we are able to limit the maximum number of sequences shown to the user be-  fore our system makes a decision on the (single) intended letter. [sent-98, score-0.208]
</p><p>57 We use the term epoch to denote all the sequences that are used by our system to make a decision on a single, intended let2The typical number of repetitions of visual stimuli is on the order of 8 or 16, although g. [sent-100, score-0.574]
</p><p>58 tec claims one subject is able to achieve reliable operation with 2 trials (verbal communication). [sent-101, score-0.146]
</p><p>59 As can be seen in the timing diagram shown in Figure 5, epoch k contains between 1 and Mk sequences. [sent-103, score-0.215]
</p><p>60 This figure shows the onset of each sequence, each fixation image (which is shown at the beginning of each sequence), and each letter using narrow pulses. [sent-104, score-0.132]
</p><p>61 After each sequence is shown, the cumulative (overall) score for all letters is computed. [sent-105, score-0.155]
</p><p>62 The cumulative scores are non-negative and sum to one (summing over the 28 symbols). [sent-106, score-0.068]
</p><p>63 If the number of sequences shown is less than the user-defined limit and if the maximum cumulative score is less than 0. [sent-107, score-0.167]
</p><p>64 Likewise, if either the maximum number of sequences has already been shown or if the maximum cumulative score equals or exceeds 0. [sent-109, score-0.197]
</p><p>65 9, then the associated symbol (for all symbols ex-  cept the backspace) is added to the end of the list of previously-detected symbols, the user is able to take a break of indefinite length, and then the system continues with the next epoch. [sent-110, score-0.348]
</p><p>66 If the symbol having the maximum cumulative score is the backspace symbol, then the last item in the list of previouslydetected symbols is removed and, like before, the user can take a break and then the system continues with the next epoch. [sent-111, score-0.569]
</p><p>67 , speech recognition or machine translation, as well as for the kind of typing application being investigated here (Roark et al. [sent-114, score-0.064]
</p><p>68 The next letters to be typed become highly predictable in certain contexts, particularly word-internally. [sent-117, score-0.144]
</p><p>69 BCI-spellers, including the RSVP Keyboard paradigm presented here, can be extremely low-speed, letter-by-letter writing systems, and thus  can greatly benefit from the incorporation of probabilistic letter predictions from an accurate language model. [sent-119, score-0.188]
</p><p>70 Most importantly for  Figure 6: Block diagram of system architecture. [sent-124, score-0.058]
</p><p>71 4 System Architecture Figure 6 shows a block diagram of our system. [sent-126, score-0.058]
</p><p>72 The output of the amplifier is fed to the laptop via a USB connection with a delay that is both highly variable and unknown a priori. [sent-140, score-0.21]
</p><p>73 Consequently, we are unable to rely on the laptop system clock in order to synchronize the EEG data and the onset of the visual stimuli. [sent-141, score-0.303]
</p><p>74 Instead, synchronization between the EEG data and the visual stimuli is provided by sending a parallel port trigger, via an express cardto-parallel port adaptor, to one of the digital inputs of the amplifier, which is then digitized along with the EEG data. [sent-142, score-0.454]
</p><p>75 The parallel port trigger is sent immediately after the laptop monitor sends the vertical retrace signal. [sent-146, score-0.208]
</p><p>76 wakka=HomePage 42 dard deviation of the delay needed to trigger the parallel port has been measured to be on the order of tens of microseconds, which should be sufficiently small for our purposes. [sent-150, score-0.17]
</p><p>77 5  Results  Here we report data collected from 2 subjects, one of whom is a LIS subject with very limited experience using our BCI system, and the other a healthy subject with extensive experience using our BCI system. [sent-151, score-0.369]
</p><p>78 The symbol duration was set to 400 ms, the duty cycle was set to 50%, and the maximum number of sequences per trial was set to 6. [sent-152, score-0.287]
</p><p>79 Before testing, the classifier of our system was trained on data obtained as each subject viewed 50 symbols with 3 sequences per epoch (the classifier was trained once for the LIS subject and once for the healthy subject). [sent-153, score-0.73]
</p><p>80 The healthy subject was specifically instructed to neither move nor blink their eyes, to the extent possible, while the symbols are being flashed on the screen in front of them. [sent-154, score-0.512]
</p><p>81 The only requirement given to them concerning the chosen text was that they must not, at any point in the experiment, change what they are planning to type and they must correct all mistakes using the backspace symbol. [sent-157, score-0.153]
</p><p>82 A total of 10 symbols were correctly typed by this subject, who had chosen to spell, “THE STEELERS ARE GOING TO . [sent-159, score-0.195]
</p><p>83 Notice that the number of sequences shown exceeds the maximum value of 6 for 3 of the symbols. [sent-163, score-0.129]
</p><p>84 This occurs when the specified letter is mistyped one or more times. [sent-164, score-0.111]
</p><p>85 For example, for each mistyped nonbackspace symbol, a backspace is required to delete  of  Figure 7: Number sequences to reach the confidence threshold for the non-expert, LIS subject. [sent-165, score-0.296]
</p><p>86 Number of sequences to reach the confidence thresh-  Figure 8: old for the expert, healthy subject. [sent-166, score-0.24]
</p><p>87 Likewise, if a backspace symbol is detected although it was not the symbol that the subject wished to type, then the correct symbol must be retyped. [sent-168, score-0.741]
</p><p>88 As shown in the figure, the mean number of sequences for each correctly-typed symbol is 14. [sent-169, score-0.257]
</p><p>89 4 and the mean number of sequences per symbol is 5. [sent-170, score-0.257]
</p><p>90 Figure 8 shows the result for the expert, healthy subject. [sent-172, score-0.141]
</p><p>91 A total of 20 symbols were correctly typed by this subject, who had chosen to spell, “THE LAKERS ARE IN FIRST PLACE”. [sent-173, score-0.195]
</p><p>92 The mean number of sequences for each correctlytyped symbol for this subject is 1. [sent-174, score-0.371]
</p><p>93 4 and the mean number of sequences per symbol is also 1. [sent-175, score-0.257]
</p><p>94 Notice that in 15 out of 20 epochs the classifier was able to detect the intended symbol on the first epoch, which corresponds to a single-trial presentation of the symbols, and no mistakes were made for any of the 20 symbols. [sent-177, score-0.286]
</p><p>95 There are two obvious explanations as to why the healthy subject performed better than the LIS subject. [sent-178, score-0.255]
</p><p>96 First, it is possible that the healthy subject was using a non-neural signal, perhaps an electromyographic (EMG) signal stemming from an unintended  43 muscle movement occurring synchronously with the target onset. [sent-179, score-0.4]
</p><p>97 Second, it is also possible that the LIS subject needs more training in order to learn how to control the system. [sent-180, score-0.114]
</p><p>98 We believe the second explanation is correct and are currently taking steps to make sure the LIS subject has additional time to train on our system in hopes of resolving this question quickly. [sent-181, score-0.114]
</p><p>99 Talking off the top of your head: toward a mental prosthesis utilizing event-related brain potentials. [sent-205, score-0.178]
</p><p>100 (C) overt attention and visual speller design in an ERP-based braincomputer interface. [sent-248, score-0.238]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('eeg', 0.396), ('rsvp', 0.272), ('bci', 0.262), ('erp', 0.173), ('lis', 0.161), ('symbol', 0.158), ('backspace', 0.153), ('visual', 0.151), ('brain', 0.146), ('stimuli', 0.143), ('healthy', 0.141), ('symbols', 0.138), ('stimulus', 0.132), ('rda', 0.131), ('distractor', 0.124), ('epoch', 0.124), ('shrinkage', 0.124), ('wolpaw', 0.124), ('subject', 0.114), ('impaired', 0.109), ('discriminant', 0.107), ('sequences', 0.099), ('pfurtscheller', 0.099), ('treder', 0.099), ('covariance', 0.099), ('letters', 0.087), ('laptop', 0.087), ('interfaces', 0.083), ('port', 0.08), ('paradigm', 0.079), ('screen', 0.075), ('amplifier', 0.074), ('blankertz', 0.074), ('hz', 0.074), ('qda', 0.074), ('channel', 0.072), ('scanning', 0.072), ('presentation', 0.071), ('cumulative', 0.068), ('response', 0.067), ('interface', 0.067), ('letter', 0.067), ('roark', 0.066), ('focal', 0.065), ('motor', 0.065), ('onset', 0.065), ('typing', 0.064), ('diagram', 0.058), ('typed', 0.057), ('rapid', 0.057), ('intended', 0.057), ('serial', 0.054), ('user', 0.052), ('class', 0.05), ('bauby', 0.049), ('braincomputer', 0.049), ('delay', 0.049), ('duda', 0.049), ('electroencephalography', 0.049), ('graz', 0.049), ('oken', 0.049), ('orhan', 0.049), ('rehabilitation', 0.049), ('serby', 0.049), ('syndrome', 0.049), ('voluntary', 0.049), ('ms', 0.045), ('cz', 0.044), ('austria', 0.044), ('muscle', 0.044), ('blink', 0.044), ('diving', 0.044), ('mistyped', 0.044), ('psychophysics', 0.044), ('incorporation', 0.042), ('trigger', 0.041), ('elicit', 0.04), ('farwell', 0.04), ('regularized', 0.039), ('regularization', 0.039), ('signal', 0.038), ('signals', 0.038), ('speller', 0.038), ('auditory', 0.038), ('speedups', 0.038), ('responses', 0.037), ('spell', 0.036), ('eye', 0.033), ('timing', 0.033), ('target', 0.032), ('matrix', 0.032), ('trials', 0.032), ('mental', 0.032), ('communication', 0.031), ('multivariate', 0.031), ('movement', 0.031), ('temporal', 0.031), ('estimated', 0.03), ('exceeds', 0.03), ('trial', 0.03)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="35-tfidf-1" href="./acl-2011-An_ERP-based_Brain-Computer_Interface_for_text_entry_using_Rapid_Serial_Visual_Presentation_and_Language_Modeling.html">35 acl-2011-An ERP-based Brain-Computer Interface for text entry using Rapid Serial Visual Presentation and Language Modeling</a></p>
<p>Author: Kenneth Hild ; Umut Orhan ; Deniz Erdogmus ; Brian Roark ; Barry Oken ; Shalini Purwar ; Hooman Nezamfar ; Melanie Fried-Oken</p><p>Abstract: Event related potentials (ERP) corresponding to stimuli in electroencephalography (EEG) can be used to detect the intent of a person for brain computer interfaces (BCI). This paradigm is widely used to build letter-byletter text input systems using BCI. Nevertheless using a BCI-typewriter depending only on EEG responses will not be sufficiently accurate for single-trial operation in general, and existing systems utilize many-trial schemes to achieve accuracy at the cost of speed. Hence incorporation of a language model based prior or additional evidence is vital to improve accuracy and speed. In this demonstration we will present a BCI system for typing that integrates a stochastic language model with ERP classification to achieve speedups, via the rapid serial visual presentation (RSVP) paradigm.</p><p>2 0.095518231 <a title="35-tfidf-2" href="./acl-2011-Why_Press_Backspace%3F_Understanding_User_Input_Behaviors_in_Chinese_Pinyin_Input_Method.html">336 acl-2011-Why Press Backspace? Understanding User Input Behaviors in Chinese Pinyin Input Method</a></p>
<p>Author: Yabin Zheng ; Lixing Xie ; Zhiyuan Liu ; Maosong Sun ; Yang Zhang ; Liyun Ru</p><p>Abstract: Chinese Pinyin input method is very important for Chinese language information processing. Users may make errors when they are typing in Chinese words. In this paper, we are concerned with the reasons that cause the errors. Inspired by the observation that pressing backspace is one of the most common user behaviors to modify the errors, we collect 54, 309, 334 error-correction pairs from a realworld data set that contains 2, 277, 786 users via backspace operations. In addition, we present a comparative analysis of the data to achieve a better understanding of users’ input behaviors. Comparisons with English typos suggest that some language-specific properties result in a part of Chinese input errors. 1</p><p>3 0.056445889 <a title="35-tfidf-3" href="./acl-2011-Insertion%2C_Deletion%2C_or_Substitution%3F_Normalizing_Text_Messages_without_Pre-categorization_nor_Supervision.html">172 acl-2011-Insertion, Deletion, or Substitution? Normalizing Text Messages without Pre-categorization nor Supervision</a></p>
<p>Author: Fei Liu ; Fuliang Weng ; Bingqing Wang ; Yang Liu</p><p>Abstract: Most text message normalization approaches are based on supervised learning and rely on human labeled training data. In addition, the nonstandard words are often categorized into different types and specific models are designed to tackle each type. In this paper, we propose a unified letter transformation approach that requires neither pre-categorization nor human supervision. Our approach models the generation process from the dictionary words to nonstandard tokens under a sequence labeling framework, where each letter in the dictionary word can be retained, removed, or substituted by other letters/digits. To avoid the expensive and time consuming hand labeling process, we automatically collected a large set of noisy training pairs using a novel webbased approach and performed character-level . alignment for model training. Experiments on both Twitter and SMS messages show that our system significantly outperformed the stateof-the-art deletion-based abbreviation system and the jazzy spell checker (absolute accuracy gain of 21.69% and 18. 16% over jazzy spell checker on the two test sets respectively).</p><p>4 0.05574413 <a title="35-tfidf-4" href="./acl-2011-IMASS%3A_An_Intelligent_Microblog_Analysis_and_Summarization_System.html">156 acl-2011-IMASS: An Intelligent Microblog Analysis and Summarization System</a></p>
<p>Author: Jui-Yu Weng ; Cheng-Lun Yang ; Bo-Nian Chen ; Yen-Kai Wang ; Shou-De Lin</p><p>Abstract: This paper presents a system to summarize a Microblog post and its responses with the goal to provide readers a more constructive and concise set of information for efficient digestion. We introduce a novel two-phase summarization scheme. In the first phase, the post plus its responses are classified into four categories based on the intention, interrogation, sharing, discussion and chat. For each type of post, in the second phase, we exploit different strategies, including opinion analysis, response pair identification, and response relevancy detection, to summarize and highlight critical information to display. This system provides an alternative thinking about machinesummarization: by utilizing AI approaches, computers are capable of constructing deeper and more user-friendly abstraction. 1</p><p>5 0.050755307 <a title="35-tfidf-5" href="./acl-2011-Confidence_Driven_Unsupervised_Semantic_Parsing.html">79 acl-2011-Confidence Driven Unsupervised Semantic Parsing</a></p>
<p>Author: Dan Goldwasser ; Roi Reichart ; James Clarke ; Dan Roth</p><p>Abstract: Current approaches for semantic parsing take a supervised approach requiring a considerable amount of training data which is expensive and difficult to obtain. This supervision bottleneck is one of the major difficulties in scaling up semantic parsing. We argue that a semantic parser can be trained effectively without annotated data, and introduce an unsupervised learning algorithm. The algorithm takes a self training approach driven by confidence estimation. Evaluated over Geoquery, a standard dataset for this task, our system achieved 66% accuracy, compared to 80% of its fully supervised counterpart, demonstrating the promise of unsupervised approaches for this task.</p><p>6 0.050519511 <a title="35-tfidf-6" href="./acl-2011-Typed_Graph_Models_for_Learning_Latent_Attributes_from_Names.html">314 acl-2011-Typed Graph Models for Learning Latent Attributes from Names</a></p>
<p>7 0.041762885 <a title="35-tfidf-7" href="./acl-2011-An_Efficient_Indexer_for_Large_N-Gram_Corpora.html">36 acl-2011-An Efficient Indexer for Large N-Gram Corpora</a></p>
<p>8 0.041688178 <a title="35-tfidf-8" href="./acl-2011-An_exponential_translation_model_for_target_language_morphology.html">44 acl-2011-An exponential translation model for target language morphology</a></p>
<p>9 0.040905885 <a title="35-tfidf-9" href="./acl-2011-Enhancing_Language_Models_in_Statistical_Machine_Translation_with_Backward_N-grams_and_Mutual_Information_Triggers.html">116 acl-2011-Enhancing Language Models in Statistical Machine Translation with Backward N-grams and Mutual Information Triggers</a></p>
<p>10 0.039043516 <a title="35-tfidf-10" href="./acl-2011-Collecting_Highly_Parallel_Data_for_Paraphrase_Evaluation.html">72 acl-2011-Collecting Highly Parallel Data for Paraphrase Evaluation</a></p>
<p>11 0.035959892 <a title="35-tfidf-11" href="./acl-2011-A_Scalable_Probabilistic_Classifier_for_Language_Modeling.html">24 acl-2011-A Scalable Probabilistic Classifier for Language Modeling</a></p>
<p>12 0.035426065 <a title="35-tfidf-12" href="./acl-2011-Lexically-Triggered_Hidden_Markov_Models_for_Clinical_Document_Coding.html">209 acl-2011-Lexically-Triggered Hidden Markov Models for Clinical Document Coding</a></p>
<p>13 0.034635514 <a title="35-tfidf-13" href="./acl-2011-Confidence-Weighted_Learning_of_Factored_Discriminative_Language_Models.html">78 acl-2011-Confidence-Weighted Learning of Factored Discriminative Language Models</a></p>
<p>14 0.034617119 <a title="35-tfidf-14" href="./acl-2011-MemeTube%3A_A_Sentiment-based_Audiovisual_System_for_Analyzing_and_Displaying_Microblog_Messages.html">218 acl-2011-MemeTube: A Sentiment-based Audiovisual System for Analyzing and Displaying Microblog Messages</a></p>
<p>15 0.033832472 <a title="35-tfidf-15" href="./acl-2011-Collective_Classification_of_Congressional_Floor-Debate_Transcripts.html">73 acl-2011-Collective Classification of Congressional Floor-Debate Transcripts</a></p>
<p>16 0.033730224 <a title="35-tfidf-16" href="./acl-2011-A_Word-Class_Approach_to_Labeling_PSCFG_Rules_for_Machine_Translation.html">29 acl-2011-A Word-Class Approach to Labeling PSCFG Rules for Machine Translation</a></p>
<p>17 0.032949038 <a title="35-tfidf-17" href="./acl-2011-Good_Seed_Makes_a_Good_Crop%3A_Accelerating_Active_Learning_Using_Language_Modeling.html">145 acl-2011-Good Seed Makes a Good Crop: Accelerating Active Learning Using Language Modeling</a></p>
<p>18 0.032831807 <a title="35-tfidf-18" href="./acl-2011-A_Speech-based_Just-in-Time_Retrieval_System_using_Semantic_Search.html">26 acl-2011-A Speech-based Just-in-Time Retrieval System using Semantic Search</a></p>
<p>19 0.032797072 <a title="35-tfidf-19" href="./acl-2011-Interactive_Group_Suggesting_for_Twitter.html">177 acl-2011-Interactive Group Suggesting for Twitter</a></p>
<p>20 0.032543901 <a title="35-tfidf-20" href="./acl-2011-Can_Document_Selection_Help_Semi-supervised_Learning%3F_A_Case_Study_On_Event_Extraction.html">65 acl-2011-Can Document Selection Help Semi-supervised Learning? A Case Study On Event Extraction</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.111), (1, 0.012), (2, -0.017), (3, 0.008), (4, -0.036), (5, 0.016), (6, -0.004), (7, -0.033), (8, 0.001), (9, 0.017), (10, -0.032), (11, 0.004), (12, 0.014), (13, 0.039), (14, -0.02), (15, 0.02), (16, -0.021), (17, 0.001), (18, 0.024), (19, -0.016), (20, 0.07), (21, 0.03), (22, 0.015), (23, -0.0), (24, -0.003), (25, -0.055), (26, 0.009), (27, -0.002), (28, -0.055), (29, -0.061), (30, -0.012), (31, 0.073), (32, 0.008), (33, 0.001), (34, -0.006), (35, -0.05), (36, -0.008), (37, 0.059), (38, 0.057), (39, 0.064), (40, 0.017), (41, 0.004), (42, 0.004), (43, 0.037), (44, -0.032), (45, -0.027), (46, -0.012), (47, 0.014), (48, -0.042), (49, 0.06)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.88918328 <a title="35-lsi-1" href="./acl-2011-An_ERP-based_Brain-Computer_Interface_for_text_entry_using_Rapid_Serial_Visual_Presentation_and_Language_Modeling.html">35 acl-2011-An ERP-based Brain-Computer Interface for text entry using Rapid Serial Visual Presentation and Language Modeling</a></p>
<p>Author: Kenneth Hild ; Umut Orhan ; Deniz Erdogmus ; Brian Roark ; Barry Oken ; Shalini Purwar ; Hooman Nezamfar ; Melanie Fried-Oken</p><p>Abstract: Event related potentials (ERP) corresponding to stimuli in electroencephalography (EEG) can be used to detect the intent of a person for brain computer interfaces (BCI). This paradigm is widely used to build letter-byletter text input systems using BCI. Nevertheless using a BCI-typewriter depending only on EEG responses will not be sufficiently accurate for single-trial operation in general, and existing systems utilize many-trial schemes to achieve accuracy at the cost of speed. Hence incorporation of a language model based prior or additional evidence is vital to improve accuracy and speed. In this demonstration we will present a BCI system for typing that integrates a stochastic language model with ERP classification to achieve speedups, via the rapid serial visual presentation (RSVP) paradigm.</p><p>2 0.60597813 <a title="35-lsi-2" href="./acl-2011-Prototyping_virtual_instructors_from_human-human_corpora.html">252 acl-2011-Prototyping virtual instructors from human-human corpora</a></p>
<p>Author: Luciana Benotti ; Alexandre Denis</p><p>Abstract: Virtual instructors can be used in several applications, ranging from trainers in simulated worlds to non player characters for virtual games. In this paper we present a novel algorithm for rapidly prototyping virtual instructors from human-human corpora without manual annotation. Automatically prototyping full-fledged dialogue systems from corpora is far from being a reality nowadays. Our algorithm is restricted in that only the virtual instructor can perform speech acts while the user responses are limited to physical actions in the virtual world. We evaluate a virtual instructor, generated using this algorithm, with human users. We compare our results both with human instructors and rule-based virtual instructors hand-coded for the same task.</p><p>3 0.58139986 <a title="35-lsi-3" href="./acl-2011-Local_Histograms_of_Character_N-grams_for_Authorship_Attribution.html">212 acl-2011-Local Histograms of Character N-grams for Authorship Attribution</a></p>
<p>Author: Hugo Jair Escalante ; Thamar Solorio ; Manuel Montes-y-Gomez</p><p>Abstract: This paper proposes the use of local histograms (LH) over character n-grams for authorship attribution (AA). LHs are enriched histogram representations that preserve sequential information in documents; they have been successfully used for text categorization and document visualization using word histograms. In this work we explore the suitability of LHs over n-grams at the character-level for AA. We show that LHs are particularly helpful for AA, because they provide useful information for uncovering, to some extent, the writing style of authors. We report experimental results in AA data sets that confirm that LHs over character n-grams are more helpful for AA than the usual global histograms, yielding results far superior to state of the art approaches. We found that LHs are even more advantageous in challenging conditions, such as having imbalanced and small training sets. Our results motivate further research on the use of LHs for modeling the writing style of authors for related tasks, such as authorship verification and plagiarism detection.</p><p>4 0.5688774 <a title="35-lsi-4" href="./acl-2011-Towards_Style_Transformation_from_Written-Style_to_Audio-Style.html">306 acl-2011-Towards Style Transformation from Written-Style to Audio-Style</a></p>
<p>Author: Amjad Abu-Jbara ; Barbara Rosario ; Kent Lyons</p><p>Abstract: In this paper, we address the problem of optimizing the style of textual content to make it more suitable to being listened to by a user as opposed to being read. We study the differences between the written style and the audio style by consulting the linguistics andjour- nalism literatures. Guided by this study, we suggest a number of linguistic features to distinguish between the two styles. We show the correctness of our features and the impact of style transformation on the user experience through statistical analysis, a style classification task, and a user study.</p><p>5 0.56468368 <a title="35-lsi-5" href="./acl-2011-Unsupervised_Discovery_of_Rhyme_Schemes.html">321 acl-2011-Unsupervised Discovery of Rhyme Schemes</a></p>
<p>Author: Sravana Reddy ; Kevin Knight</p><p>Abstract: This paper describes an unsupervised, language-independent model for finding rhyme schemes in poetry, using no prior knowledge about rhyme or pronunciation.</p><p>6 0.52533907 <a title="35-lsi-6" href="./acl-2011-ConsentCanvas%3A_Automatic_Texturing_for_Improved_Readability_in_End-User_License_Agreements.html">80 acl-2011-ConsentCanvas: Automatic Texturing for Improved Readability in End-User License Agreements</a></p>
<p>7 0.52197862 <a title="35-lsi-7" href="./acl-2011-A_Speech-based_Just-in-Time_Retrieval_System_using_Semantic_Search.html">26 acl-2011-A Speech-based Just-in-Time Retrieval System using Semantic Search</a></p>
<p>8 0.52127397 <a title="35-lsi-8" href="./acl-2011-Improving_On-line_Handwritten_Recognition_using_Translation_Models_in_Multimodal_Interactive_Machine_Translation.html">168 acl-2011-Improving On-line Handwritten Recognition using Translation Models in Multimodal Interactive Machine Translation</a></p>
<p>9 0.51269609 <a title="35-lsi-9" href="./acl-2011-Modeling_Wisdom_of_Crowds_Using_Latent_Mixture_of_Discriminative_Experts.html">223 acl-2011-Modeling Wisdom of Crowds Using Latent Mixture of Discriminative Experts</a></p>
<p>10 0.51186925 <a title="35-lsi-10" href="./acl-2011-SystemT%3A_A_Declarative_Information_Extraction_System.html">291 acl-2011-SystemT: A Declarative Information Extraction System</a></p>
<p>11 0.5109781 <a title="35-lsi-11" href="./acl-2011-Predicting_Clicks_in_a_Vocabulary_Learning_System.html">248 acl-2011-Predicting Clicks in a Vocabulary Learning System</a></p>
<p>12 0.51042438 <a title="35-lsi-12" href="./acl-2011-Integrating_surprisal_and_uncertain-input_models_in_online_sentence_comprehension%3A_formal_techniques_and_empirical_results.html">176 acl-2011-Integrating surprisal and uncertain-input models in online sentence comprehension: formal techniques and empirical results</a></p>
<p>13 0.50559306 <a title="35-lsi-13" href="./acl-2011-Hierarchical_Reinforcement_Learning_and_Hidden_Markov_Models_for_Task-Oriented_Natural_Language_Generation.html">149 acl-2011-Hierarchical Reinforcement Learning and Hidden Markov Models for Task-Oriented Natural Language Generation</a></p>
<p>14 0.50483572 <a title="35-lsi-14" href="./acl-2011-Subjective_Natural_Language_Problems%3A_Motivations%2C_Applications%2C_Characterizations%2C_and_Implications.html">288 acl-2011-Subjective Natural Language Problems: Motivations, Applications, Characterizations, and Implications</a></p>
<p>15 0.50168604 <a title="35-lsi-15" href="./acl-2011-Age_Prediction_in_Blogs%3A_A_Study_of_Style%2C_Content%2C_and_Online_Behavior_in_Pre-_and_Post-Social_Media_Generations.html">31 acl-2011-Age Prediction in Blogs: A Study of Style, Content, and Online Behavior in Pre- and Post-Social Media Generations</a></p>
<p>16 0.49899173 <a title="35-lsi-16" href="./acl-2011-Clairlib%3A_A_Toolkit_for_Natural_Language_Processing%2C_Information_Retrieval%2C_and_Network_Analysis.html">67 acl-2011-Clairlib: A Toolkit for Natural Language Processing, Information Retrieval, and Network Analysis</a></p>
<p>17 0.49693003 <a title="35-lsi-17" href="./acl-2011-Word_Maturity%3A_Computational_Modeling_of_Word_Knowledge.html">341 acl-2011-Word Maturity: Computational Modeling of Word Knowledge</a></p>
<p>18 0.49419203 <a title="35-lsi-18" href="./acl-2011-A_Fast_and_Accurate_Method_for_Approximate_String_Search.html">11 acl-2011-A Fast and Accurate Method for Approximate String Search</a></p>
<p>19 0.49357516 <a title="35-lsi-19" href="./acl-2011-Insertion%2C_Deletion%2C_or_Substitution%3F_Normalizing_Text_Messages_without_Pre-categorization_nor_Supervision.html">172 acl-2011-Insertion, Deletion, or Substitution? Normalizing Text Messages without Pre-categorization nor Supervision</a></p>
<p>20 0.4924683 <a title="35-lsi-20" href="./acl-2011-Combining_Indicators_of_Allophony.html">74 acl-2011-Combining Indicators of Allophony</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(1, 0.407), (5, 0.04), (17, 0.049), (26, 0.028), (37, 0.049), (39, 0.031), (41, 0.062), (55, 0.036), (59, 0.036), (72, 0.041), (91, 0.028), (96, 0.1), (97, 0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.7533983 <a title="35-lda-1" href="./acl-2011-An_ERP-based_Brain-Computer_Interface_for_text_entry_using_Rapid_Serial_Visual_Presentation_and_Language_Modeling.html">35 acl-2011-An ERP-based Brain-Computer Interface for text entry using Rapid Serial Visual Presentation and Language Modeling</a></p>
<p>Author: Kenneth Hild ; Umut Orhan ; Deniz Erdogmus ; Brian Roark ; Barry Oken ; Shalini Purwar ; Hooman Nezamfar ; Melanie Fried-Oken</p><p>Abstract: Event related potentials (ERP) corresponding to stimuli in electroencephalography (EEG) can be used to detect the intent of a person for brain computer interfaces (BCI). This paradigm is widely used to build letter-byletter text input systems using BCI. Nevertheless using a BCI-typewriter depending only on EEG responses will not be sufficiently accurate for single-trial operation in general, and existing systems utilize many-trial schemes to achieve accuracy at the cost of speed. Hence incorporation of a language model based prior or additional evidence is vital to improve accuracy and speed. In this demonstration we will present a BCI system for typing that integrates a stochastic language model with ERP classification to achieve speedups, via the rapid serial visual presentation (RSVP) paradigm.</p><p>2 0.66474694 <a title="35-lda-2" href="./acl-2011-A_Comprehensive_Dictionary_of_Multiword_Expressions.html">6 acl-2011-A Comprehensive Dictionary of Multiword Expressions</a></p>
<p>Author: Kosho Shudo ; Akira Kurahone ; Toshifumi Tanabe</p><p>Abstract: It has been widely recognized that one of the most difficult and intriguing problems in natural language processing (NLP) is how to cope with idiosyncratic multiword expressions. This paper presents an overview of the comprehensive dictionary (JDMWE) of Japanese multiword expressions. The JDMWE is characterized by a large notational, syntactic, and semantic diversity of contained expressions as well as a detailed description of their syntactic functions, structures, and flexibilities. The dictionary contains about 104,000 expressions, potentially 750,000 expressions. This paper shows that the JDMWE’s validity can be supported by comparing the dictionary with a large-scale Japanese N-gram frequency dataset, namely the LDC2009T08, generated by Google Inc. (Kudo et al. 2009). 1</p><p>3 0.53691113 <a title="35-lda-3" href="./acl-2011-Learning_Sub-Word_Units_for_Open_Vocabulary_Speech_Recognition.html">203 acl-2011-Learning Sub-Word Units for Open Vocabulary Speech Recognition</a></p>
<p>Author: Carolina Parada ; Mark Dredze ; Abhinav Sethy ; Ariya Rastrow</p><p>Abstract: Large vocabulary speech recognition systems fail to recognize words beyond their vocabulary, many of which are information rich terms, like named entities or foreign words. Hybrid word/sub-word systems solve this problem by adding sub-word units to large vocabulary word based systems; new words can then be represented by combinations of subword units. Previous work heuristically created the sub-word lexicon from phonetic representations of text using simple statistics to select common phone sequences. We propose a probabilistic model to learn the subword lexicon optimized for a given task. We consider the task of out of vocabulary (OOV) word detection, which relies on output from a hybrid model. A hybrid model with our learned sub-word lexicon reduces error by 6.3% and 7.6% (absolute) at a 5% false alarm rate on an English Broadcast News and MIT Lectures task respectively.</p><p>4 0.50560188 <a title="35-lda-4" href="./acl-2011-Identification_of_Domain-Specific_Senses_in_a_Machine-Readable_Dictionary.html">158 acl-2011-Identification of Domain-Specific Senses in a Machine-Readable Dictionary</a></p>
<p>Author: Fumiyo Fukumoto ; Yoshimi Suzuki</p><p>Abstract: This paper focuses on domain-specific senses and presents a method for assigning category/domain label to each sense of words in a dictionary. The method first identifies each sense of a word in the dictionary to its corresponding category. We used a text classification technique to select appropriate senses for each domain. Then, senses were scored by computing the rank scores. We used Markov Random Walk (MRW) model. The method was tested on English and Japanese resources, WordNet 3.0 and EDR Japanese dictionary. For evaluation of the method, we compared English results with the Subject Field Codes (SFC) resources. We also compared each English and Japanese results to the first sense heuristics in the WSD task. These results suggest that identification of domain-specific senses (IDSS) may actually be of benefit.</p><p>5 0.49173167 <a title="35-lda-5" href="./acl-2011-Sentiment_Analysis_of_Citations_using_Sentence_Structure-Based_Features.html">281 acl-2011-Sentiment Analysis of Citations using Sentence Structure-Based Features</a></p>
<p>Author: Awais Athar</p><p>Abstract: Sentiment analysis of citations in scientific papers and articles is a new and interesting problem due to the many linguistic differences between scientific texts and other genres. In this paper, we focus on the problem of automatic identification of positive and negative sentiment polarity in citations to scientific papers. Using a newly constructed annotated citation sentiment corpus, we explore the effectiveness of existing and novel features, including n-grams, specialised science-specific lexical features, dependency relations, sentence splitting and negation features. Our results show that 3-grams and dependencies perform best in this task; they outperform the sentence splitting, science lexicon and negation based features.</p><p>6 0.48623195 <a title="35-lda-6" href="./acl-2011-AM-FM%3A_A_Semantic_Framework_for_Translation_Quality_Assessment.html">2 acl-2011-AM-FM: A Semantic Framework for Translation Quality Assessment</a></p>
<p>7 0.35863173 <a title="35-lda-7" href="./acl-2011-Discrete_vs._Continuous_Rating_Scales_for_Language_Evaluation_in_NLP.html">99 acl-2011-Discrete vs. Continuous Rating Scales for Language Evaluation in NLP</a></p>
<p>8 0.35000241 <a title="35-lda-8" href="./acl-2011-Large-Scale_Cross-Document_Coreference_Using_Distributed_Inference_and_Hierarchical_Models.html">196 acl-2011-Large-Scale Cross-Document Coreference Using Distributed Inference and Hierarchical Models</a></p>
<p>9 0.34959328 <a title="35-lda-9" href="./acl-2011-An_Efficient_Indexer_for_Large_N-Gram_Corpora.html">36 acl-2011-An Efficient Indexer for Large N-Gram Corpora</a></p>
<p>10 0.34947574 <a title="35-lda-10" href="./acl-2011-Can_Document_Selection_Help_Semi-supervised_Learning%3F_A_Case_Study_On_Event_Extraction.html">65 acl-2011-Can Document Selection Help Semi-supervised Learning? A Case Study On Event Extraction</a></p>
<p>11 0.34941655 <a title="35-lda-11" href="./acl-2011-Evaluating_the_Impact_of_Coder_Errors_on_Active_Learning.html">119 acl-2011-Evaluating the Impact of Coder Errors on Active Learning</a></p>
<p>12 0.34921098 <a title="35-lda-12" href="./acl-2011-Good_Seed_Makes_a_Good_Crop%3A_Accelerating_Active_Learning_Using_Language_Modeling.html">145 acl-2011-Good Seed Makes a Good Crop: Accelerating Active Learning Using Language Modeling</a></p>
<p>13 0.34904185 <a title="35-lda-13" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>14 0.3479538 <a title="35-lda-14" href="./acl-2011-Knowledge-Based_Weak_Supervision_for_Information_Extraction_of_Overlapping_Relations.html">190 acl-2011-Knowledge-Based Weak Supervision for Information Extraction of Overlapping Relations</a></p>
<p>15 0.3475312 <a title="35-lda-15" href="./acl-2011-Fine-Grained_Class_Label_Markup_of_Search_Queries.html">137 acl-2011-Fine-Grained Class Label Markup of Search Queries</a></p>
<p>16 0.34728992 <a title="35-lda-16" href="./acl-2011-Faster_and_Smaller_N-Gram_Language_Models.html">135 acl-2011-Faster and Smaller N-Gram Language Models</a></p>
<p>17 0.34724385 <a title="35-lda-17" href="./acl-2011-Translationese_and_Its_Dialects.html">311 acl-2011-Translationese and Its Dialects</a></p>
<p>18 0.34722486 <a title="35-lda-18" href="./acl-2011-An_Error_Analysis_of_Relation_Extraction_in_Social_Media_Documents.html">40 acl-2011-An Error Analysis of Relation Extraction in Social Media Documents</a></p>
<p>19 0.34710333 <a title="35-lda-19" href="./acl-2011-Using_Bilingual_Parallel_Corpora_for_Cross-Lingual_Textual_Entailment.html">327 acl-2011-Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment</a></p>
<p>20 0.34694558 <a title="35-lda-20" href="./acl-2011-Lexically-Triggered_Hidden_Markov_Models_for_Clinical_Document_Coding.html">209 acl-2011-Lexically-Triggered Hidden Markov Models for Clinical Document Coding</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
