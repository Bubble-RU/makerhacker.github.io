<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-324" href="#">acl2011-324</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</h1>
<br/><p>Source: <a title="acl-2011-324-pdf" href="http://aclweb.org/anthology//P/P11/P11-1112.pdf">pdf</a></p><p>Author: Joel Lang ; Mirella Lapata</p><p>Abstract: In this paper we describe an unsupervised method for semantic role induction which holds promise for relieving the data acquisition bottleneck associated with supervised role labelers. We present an algorithm that iteratively splits and merges clusters representing semantic roles, thereby leading from an initial clustering to a final clustering of better quality. The method is simple, surprisingly effective, and allows to integrate linguistic knowledge transparently. By combining role induction with a rule-based component for argument identification we obtain an unsupervised end-to-end semantic role labeling system. Evaluation on the CoNLL 2008 benchmark dataset demonstrates that our method outperforms competitive unsupervised approaches by a wide margin.</p><p>Reference: <a title="acl-2011-324-reference" href="../acl2011_reference/acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 J Lang- 3 @ sms ed ac Abstract In this paper we describe an unsupervised method for semantic role induction which holds promise for relieving the data acquisition bottleneck associated with supervised role labelers. [sent-5, score-0.834]
</p><p>2 We present an algorithm that iteratively splits and merges clusters representing semantic roles, thereby leading from an initial clustering to a final clustering of better quality. [sent-6, score-0.827]
</p><p>3 By combining role induction with a rule-based component for argument identification we obtain an unsupervised end-to-end semantic role labeling system. [sent-8, score-1.212]
</p><p>4 The term is most commonly used to describe the automatic identification and labeling of the semantic roles conveyed by sentential constituents (Gildea and Jurafsky, 2002). [sent-11, score-0.51]
</p><p>5 The semantic roles in the examples are labeled in the style of PropBank (Palmer et al. [sent-28, score-0.341]
</p><p>6 , 2005), a broad-coverage human-annotated corpus of semantic roles and their syntactic realizations. [sent-29, score-0.392]
</p><p>7 Under the PropBank annotation framework (which we will assume throughout this paper) each predicate is associated with a set of core roles (named A0, A1, A2, and so on) whose interpretations are specific to that predicate1 and a set of adjunct roles (e. [sent-30, score-0.489]
</p><p>8 Indeed, the analysis produced by existing semantic role labelers has been shown to benefit a wide spectrum of applications ranging from information extraction (Surdeanu et al. [sent-34, score-0.364]
</p><p>9 Since both argument identification and labeling can be readily modeled as classification tasks, most state-of-the-art systems to date conceptualize se-  1More precisely, A0 and A1 have a common interpretation across predicates as proto-agent and proto-patient in the sense of Dowty (1991). [sent-37, score-0.491]
</p><p>10 c s 2o0ci1a1ti Aonss foocria Ctioomnp fourta Ctioomnaplu Ltaintigouniaslti Lcisn,g puaigsetsic 1s117–1126, mantic role labeling as a supervised learning problem. [sent-40, score-0.34]
</p><p>11 Current approaches have high performance a system will recall around 81% of the arguments correctly and 95% of those will be assigned a correct semantic role (see M `arquez et al. [sent-41, score-0.635]
</p><p>12 Unfortunately, the reliance on role-annotated data which is expensive and time-consuming to produce for every language and domain, presents a major bottleneck to the widespread application of semantic role labeling. [sent-45, score-0.405]
</p><p>13 In this paper we present a simple approach to unsupervised semantic role labeling. [sent-51, score-0.424]
</p><p>14 It first identifies the semantic arguments of a predicate and then assigns semantic roles to them. [sent-53, score-0.818]
</p><p>15 Argument identification is carried out through a small set of linguistically-motivated rules, whereas role induction is treated as a clustering problem. [sent-55, score-0.515]
</p><p>16 In this setting, the goal is to assign argument instances to clusters such that each cluster contains arguments corresponding to a specific semantic role and each role corresponds to exactly one cluster. [sent-56, score-1.815]
</p><p>17 We formulate a clustering algorithm that executes a series of split and merge operations in order to transduce an initial clustering into a final clustering of better quality. [sent-57, score-0.53]
</p><p>18 Split operations leverage syntactic cues so as to create “pure” clusters that contain arguments of the same role whereas merge operations bring together  argument instances of a particular role located in different clusters. [sent-58, score-1.71]
</p><p>19 Swier and Stevenson (2004) induce role labels with a bootstrapping scheme where the set of labeled instances is iteratively expanded using a classifier trained on previously labeled instances. [sent-66, score-0.447]
</p><p>20 Their method is unsupervised in that it starts with a dataset containing no role annotations at all. [sent-67, score-0.386]
</p><p>21 , 2000) in order to identify the arguments of predicates and make initial role assignments. [sent-69, score-0.533]
</p><p>22 VerbNet is a broad coverage lexicon organized into verb classes each of which is explicitly associated with argument realization and semantic role specifications. [sent-70, score-0.708]
</p><p>23 (2009) propose an algorithm that identifies the arguments of predicates by relying only on part of speech annotations, without, however, assigning semantic roles. [sent-72, score-0.435]
</p><p>24 In contrast, Lang and Lapata (2010) focus solely on the role induction problem which they formulate as the process of detecting alternations and finding a canonical syntactic form for them. [sent-73, score-0.379]
</p><p>25 Latent variables represent the semantic roles of arguments and role induction corresponds to inferring the state of these latent variables. [sent-77, score-0.94]
</p><p>26 We formulate the induction of semantic roles as a clustering problem and propose a split-merge algorithm which iteratively manipulates clusters representing semantic roles. [sent-79, score-1.062]
</p><p>27 For example, arguments occurring in similar syntactic positions are likely to bear the same semantic role and should therefore be grouped together. [sent-81, score-0.756]
</p><p>28 Analogously, arguments that are lexically similar are likely to represent the same semantic role. [sent-82, score-0.404]
</p><p>29 Like Lang and Lapata (2010) and Grenager and Manning (2006) our method operates over syntactically parsed sentences, without, however, making use of any information pertaining to semantic roles (e. [sent-84, score-0.384]
</p><p>30 3  Learning Setting  We follow the general architecture of supervised semantic role labeling systems. [sent-88, score-0.473]
</p><p>31 Given a sentence and a designated verb, the SRL task consists of identifying the arguments of the verbal predicate (argument identification) and labeling them with semantic roles (role induction). [sent-89, score-0.753]
</p><p>32 In our case neither argument identification nor role induction relies on role-annotated data or other semantic resources although we assume that the input sentences are syntactically analyzed. [sent-90, score-0.896]
</p><p>33 However, we opted for a —  dependency-based representation, as it simplifies argument identification considerably and is consistent 1119 with the CoNLL 2008 benchmark dataset used for evaluation in our experiments. [sent-92, score-0.454]
</p><p>34 Given a dependency parse of a sentence, our system identifies argument instances and assigns them to clusters. [sent-93, score-0.461]
</p><p>35 Thereafter, argument instances can be labeled with an identifier corresponding to the cluster they have been assigned to, similar to PropBank core labels (e. [sent-94, score-0.665]
</p><p>36 4  Argument Identification  In the supervised setting, a classifier is employed in order to decide for each node in the parse tree whether it represents a semantic argument or not. [sent-97, score-0.465]
</p><p>37 Nodes classified as arguments are then assigned a semantic role. [sent-98, score-0.404]
</p><p>38 In the unsupervised setting, we slightly reformulate argument identification as the task of discarding as many non-semantic arguments as possible. [sent-99, score-0.723]
</p><p>39 This means that the argument identification component does not make a final positive decision for any of the argument candidates; instead, this de-  cision is deferred to role induction. [sent-100, score-0.914]
</p><p>40 We will exemplify how the argument identification component works for the predicate expect in the sentence “The company said it expects its sales to remain steady” whose parse tree is shown in Figure 1. [sent-104, score-0.496]
</p><p>41 Initially, all words save the predicate itself are treated as argument candidates. [sent-105, score-0.364]
</p><p>42 5  Split-Merge Role Induction  We treat role induction as a clustering problem with the goal of assigning argument instances (i. [sent-113, score-0.839]
</p><p>43 , specific arguments occurring in an input sentence) to clusters such that these represent semantic roles. [sent-115, score-0.752]
</p><p>44 In accordance with PropBank, we induce a separate set of clusters for each verb and each cluster thus represents a verb-specific role. [sent-116, score-0.577]
</p><p>45 Our algorithm works by iteratively splitting and merging clusters of argument instances in order to arrive at increasingly accurate representations of semantic roles. [sent-117, score-0.961]
</p><p>46 Although splits and merges could be arbitrarily interleaved, our algorithm executes a single split operation (split phase), followed by a series of merges (merge phase). [sent-118, score-0.398]
</p><p>47 The split phase partitions the seed cluster containing all argument instances of a particular verb into more fine-grained (sub-)clusters. [sent-119, score-0.835]
</p><p>48 This initial split results in a clustering with high purity but low collocation, i. [sent-120, score-0.473]
</p><p>49 The degree of dislocation is reduced in the consecutive merge phase, in which clusters that are likely to represent the same role are merged. [sent-126, score-0.732]
</p><p>50 The goal then is to partition this  cluster in such a way that the split-off clusters have high purity, i. [sent-129, score-0.524]
</p><p>51 A cluster is allocated for each key and all argument instances with a matching key are assigned to that cluster. [sent-133, score-0.634]
</p><p>52 Since each cluster encodes fine-grained syntactic distinctions, we assume that arguments occurring in the same position are likely to bear the same semantic role. [sent-134, score-0.734]
</p><p>53 The assumption is largely supported by our empirical results (see Section 7); the clusters emerging from the initial split phase have a purity of approximately 90%. [sent-135, score-0.8]
</p><p>54 2 Merge Phase The split phase creates clusters with high purity, however, argument instances of a particular role are often scattered amongst many clusters resulting in a cluster assignment with low collocation. [sent-140, score-1.643]
</p><p>55 The goal of the merge phase is to improve collocation by executing a series of merge steps. [sent-141, score-0.594]
</p><p>56 Each pair is scored by a function that reflects how likely the two clusters are to contain arguments of the same role and the best scoring pair is chosen for merging. [sent-143, score-0.901]
</p><p>57 In the following, we will specify which pairs of clusters are considered (candidate search), how they are scored, and when the merge phase terminates. [sent-144, score-0.599]
</p><p>58 Moreover, it would be desirable to exclude pairings involving small clusters (i. [sent-155, score-0.351]
</p><p>59 Rather than considering all cluster pairings, we therefore select a specific cluster at each step and score merges between this cluster and certain other clusters. [sent-158, score-0.783]
</p><p>60 In addition, we prioritize merges between large clusters and avoid merges between small clusters. [sent-160, score-0.627]
</p><p>61 Then, merges between the selected cluster and all larger clusters are considered. [sent-163, score-0.68]
</p><p>62 The highest-scoring merge is executed, unless all merges are ruled out, i. [sent-164, score-0.378]
</p><p>63 Operation merge(Li, Lj) merges cluster Li into cluster Lj and removes Li from the list L. [sent-171, score-0.574]
</p><p>64 2 Scoring Function Our scoring function quantifies whether two clusters  are likely to contain arguments of the same role and was designed to reflect the following criteria: 1. [sent-174, score-0.933]
</p><p>65 whether the arguments found in the two clusters are lexically similar; 2. [sent-175, score-0.586]
</p><p>66 whether clause-level constraints are satisfied, specifically the constraint that all arguments of a particular clause have different semantic roles, i. [sent-176, score-0.404]
</p><p>67 whether the arguments present in the two clusters have similar parts of speech. [sent-179, score-0.586]
</p><p>68 In contrast, lexical similarity implies that the clusters are likely to represent the same semantic role. [sent-184, score-0.489]
</p><p>69 Unavoidably, lexical similarity will be more reliable for arguments with overt lexical content as opposed to pronouns, however this should not impact the scoring of sufficiently large clusters. [sent-188, score-0.358]
</p><p>70 Each of the criteria mentioned above is quantified through a separate score and combined into an overall similarity function, which scores two clusters c and c0 as follows:  score(c, 0)= 0l ex(c, 0)ioftpcheo nrsw(sc(i s,ec . [sent-189, score-0.392]
</p><p>71 When the part-of-speech similarity (pos) is below a certain threshold β or when clause-level constraints (cons) are satisfied to a lesser extent than threshold γ, the score takes value zero and the merge is ruled out. [sent-191, score-0.413]
</p><p>72 Lexical Similarity We measure lexical similarity between two clusters through cosine similarity. [sent-194, score-0.356]
</p><p>73 Specifically, each cluster is represented as a vector whose components correspond to the occurrence frequencies of the argument head words in the cluster. [sent-195, score-0.5]
</p><p>74 Therefore, clusters should not merge if the resulting cluster contains (many) arguments of the same clause. [sent-197, score-0.981]
</p><p>75 The idea is to start with a very restrictive setting (high values) in which the negative evidence rules out merges more strictly, and then to gradually relax the requirement for a merge by lowering the threshold values. [sent-204, score-0.381]
</p><p>76 1923  Table 2: Clustering results with our split-merge algorithm, the unsupervised model proposed in Lang and Lapata (2010) and a baseline that assigns arguments to clusters based on their syntactic function. [sent-229, score-0.697]
</p><p>77 Although the dataset provides annotations for verbal and nominal predicate-argument constructions, we only considered the former, following previous work on semantic role labeling (M` arquez et al. [sent-235, score-0.579]
</p><p>78 Evaluation Metrics For each verb, we determine the extent to which argument instances in a cluster share the same gold standard role (purity) and the extent to which a particular gold standard role is assigned to a single cluster (collocation). [sent-237, score-1.535]
</p><p>79 More formally, for each group of verb-specific clusters we measure the purity of the clusters as the percentage of instances belonging to the majority gold class in their respective cluster. [sent-238, score-1.212]
</p><p>80 Let N denote the total number of instances, Gj the set of instances  belonging to the j-th gold class and Ci the set of instances belonging to the i-th cluster. [sent-239, score-0.411]
</p><p>81 Finally, we use the harmonic mean of purity and collocation as a single measure of clustering quality:  F1=2×CCO+O×PUPU  (7)  Comparison Models We compared our splitmerge algorithm against two competitive approaches. [sent-243, score-0.591]
</p><p>82 The first one assigns argument instances to clusters according to their syntactic function (e. [sent-244, score-0.829]
</p><p>83 This baseline has been previously used as point of comparison by other unsupervised semantic role labeling systems (Grenager and Manning, 2006; Lang and Lapata, 2010) and shown difficult to outperform. [sent-247, score-0.492]
</p><p>84 We re-  port cluster purity (PU), collocation (CO) and their harmonic mean (F1) for the baseline (Syntactic Function), Lang and Lapata’s (2010) model and our split-merge algorithm (Split-Merge) on four 2This is the number of gold standard roles. [sent-255, score-0.749]
</p><p>85 These result from the combination of automatic parses with automatically identified arguments (auto/auto), gold parses with automatic arguments (gold/auto), automatic parses with gold arguments (auto/gold) and gold parses with gold arguments (gold/gold). [sent-258, score-1.576]
</p><p>86 On the auto/auto dataset the splitmerge algorithm results in 9% higher purity than the baseline and increases F1 by 2. [sent-263, score-0.443]
</p><p>87 Performance also increases if gold standard arguments are  used instead of automatically identified arguments. [sent-272, score-0.35]
</p><p>88 We also assessed the argument identification com1124  RoleSPyUntactCicO FunctFio1nPUSplitC-MOergeF1  roles with our split-merge algorithm and the syntactic function baseline. [sent-274, score-0.689]
</p><p>89 1% (percentage of semantic arguments out of those identified) and recall of 87. [sent-277, score-0.404]
</p><p>90 9% (percentage of identified arguments out of all gold arguments). [sent-278, score-0.35]
</p><p>91 However, note that these figures are not strictly comparable to those reported for supervised systems, due to the fact that our argument identification component only discards nonargument candidates. [sent-279, score-0.433]
</p><p>92 Furthermore, the purity scores given here represent the average purity of those clusters for which the specified role is the majority role. [sent-289, score-1.22]
</p><p>93 If we were to annotate the clusters induced by our system, low collocation would result in higher annotation effort while low purity would result in poorer data quality. [sent-292, score-0.814]
</p><p>94 Our system improves purity substantially over the baselines, without affecting collocation in a way that would massively increase the annotation effort. [sent-293, score-0.491]
</p><p>95 This  means we would assign labels to 74% of instances in the dataset (excluding those discarded during argument identification) and attain a role classification with 79. [sent-297, score-0.801]
</p><p>96 5 However, instead of labeling all 165, 662 instances contained in these clusters individually we would only have to assign labels to 2, 869 clusters. [sent-299, score-0.548]
</p><p>97 8  Conclusions  In this paper we presented a novel approach to unsupervised role induction which we formulated as a clustering problem. [sent-301, score-0.474]
</p><p>98 We proposed a split-merge algorithm that iteratively manipulates clusters representing semantic roles whilst trading off cluster purity with collocation. [sent-302, score-1.292]
</p><p>99 The split phase creates “pure” clusters that contain arguments of the same role whereas the merge phase attempts to increase collocation by merging clusters which are likely to represent the same role. [sent-303, score-1.725]
</p><p>100 Coupled with a rule-based component for automatically identifying argument candidates our split-merge algorithm forms an end-to-end system that is capable of inducing role labels without any supervision. [sent-307, score-0.553]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('purity', 0.337), ('clusters', 0.315), ('argument', 0.291), ('arguments', 0.271), ('role', 0.231), ('cluster', 0.209), ('roles', 0.208), ('merge', 0.186), ('merges', 0.156), ('instances', 0.134), ('semantic', 0.133), ('lang', 0.128), ('collocation', 0.124), ('lapata', 0.109), ('identification', 0.101), ('phase', 0.098), ('induction', 0.097), ('surdeanu', 0.089), ('oprd', 0.089), ('clustering', 0.086), ('propbank', 0.083), ('gold', 0.079), ('predicate', 0.073), ('obj', 0.071), ('labeling', 0.068), ('termination', 0.066), ('dataset', 0.062), ('unsupervised', 0.06), ('broke', 0.059), ('adv', 0.054), ('verbs', 0.054), ('conll', 0.053), ('verb', 0.053), ('rule', 0.052), ('arquez', 0.052), ('discarded', 0.052), ('syntactic', 0.051), ('iteratively', 0.051), ('grenager', 0.051), ('gj', 0.051), ('split', 0.05), ('lex', 0.048), ('scoring', 0.046), ('rock', 0.046), ('analogously', 0.046), ('melli', 0.044), ('splitmerge', 0.044), ('cons', 0.044), ('sbj', 0.044), ('parses', 0.044), ('syntactically', 0.043), ('bottleneck', 0.041), ('supervised', 0.041), ('object', 0.041), ('similarity', 0.041), ('lowered', 0.039), ('predicative', 0.039), ('coord', 0.039), ('prd', 0.039), ('manipulates', 0.039), ('mnr', 0.039), ('tmp', 0.039), ('threshold', 0.039), ('effort', 0.038), ('function', 0.038), ('merging', 0.037), ('bear', 0.037), ('satisfied', 0.036), ('extent', 0.036), ('swier', 0.036), ('urstenau', 0.036), ('quantified', 0.036), ('pairings', 0.036), ('nmod', 0.036), ('ruled', 0.036), ('executes', 0.036), ('steady', 0.036), ('kipper', 0.036), ('gordon', 0.036), ('lj', 0.036), ('dependency', 0.036), ('im', 0.035), ('thresholds', 0.034), ('abend', 0.034), ('pu', 0.034), ('prt', 0.034), ('annotating', 0.034), ('annotations', 0.033), ('occurring', 0.033), ('quantifies', 0.032), ('pradhan', 0.032), ('belonging', 0.032), ('predicates', 0.031), ('ext', 0.031), ('sales', 0.031), ('verbnet', 0.031), ('labels', 0.031), ('window', 0.03), ('srl', 0.03), ('affecting', 0.03)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="324-tfidf-1" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>Author: Joel Lang ; Mirella Lapata</p><p>Abstract: In this paper we describe an unsupervised method for semantic role induction which holds promise for relieving the data acquisition bottleneck associated with supervised role labelers. We present an algorithm that iteratively splits and merges clusters representing semantic roles, thereby leading from an initial clustering to a final clustering of better quality. The method is simple, surprisingly effective, and allows to integrate linguistic knowledge transparently. By combining role induction with a rule-based component for argument identification we obtain an unsupervised end-to-end semantic role labeling system. Evaluation on the CoNLL 2008 benchmark dataset demonstrates that our method outperforms competitive unsupervised approaches by a wide margin.</p><p>2 0.30308983 <a title="324-tfidf-2" href="./acl-2011-A_Bayesian_Model_for_Unsupervised_Semantic_Parsing.html">3 acl-2011-A Bayesian Model for Unsupervised Semantic Parsing</a></p>
<p>Author: Ivan Titov ; Alexandre Klementiev</p><p>Abstract: We propose a non-parametric Bayesian model for unsupervised semantic parsing. Following Poon and Domingos (2009), we consider a semantic parsing setting where the goal is to (1) decompose the syntactic dependency tree of a sentence into fragments, (2) assign each of these fragments to a cluster of semantically equivalent syntactic structures, and (3) predict predicate-argument relations between the fragments. We use hierarchical PitmanYor processes to model statistical dependencies between meaning representations of predicates and those of their arguments, as well as the clusters of their syntactic realizations. We develop a modification of the MetropolisHastings split-merge sampler, resulting in an efficient inference algorithm for the model. The method is experimentally evaluated by us- ing the induced semantic representation for the question answering task in the biomedical domain.</p><p>3 0.22975311 <a title="324-tfidf-3" href="./acl-2011-Scaling_up_Automatic_Cross-Lingual_Semantic_Role_Annotation.html">269 acl-2011-Scaling up Automatic Cross-Lingual Semantic Role Annotation</a></p>
<p>Author: Lonneke van der Plas ; Paola Merlo ; James Henderson</p><p>Abstract: Broad-coverage semantic annotations for training statistical learners are only available for a handful of languages. Previous approaches to cross-lingual transfer of semantic annotations have addressed this problem with encouraging results on a small scale. In this paper, we scale up previous efforts by using an automatic approach to semantic annotation that does not rely on a semantic ontology for the target language. Moreover, we improve the quality of the transferred semantic annotations by using a joint syntacticsemantic parser that learns the correlations between syntax and semantics of the target language and smooths out the errors from automatic transfer. We reach a labelled F-measure for predicates and arguments of only 4% and 9% points, respectively, lower than the upper bound from manual annotations.</p><p>4 0.19261345 <a title="324-tfidf-4" href="./acl-2011-Template-Based_Information_Extraction_without_the_Templates.html">293 acl-2011-Template-Based Information Extraction without the Templates</a></p>
<p>Author: Nathanael Chambers ; Dan Jurafsky</p><p>Abstract: Standard algorithms for template-based information extraction (IE) require predefined template schemas, and often labeled data, to learn to extract their slot fillers (e.g., an embassy is the Target of a Bombing template). This paper describes an approach to template-based IE that removes this requirement and performs extraction without knowing the template structure in advance. Our algorithm instead learns the template structure automatically from raw text, inducing template schemas as sets of linked events (e.g., bombings include detonate, set off, and destroy events) associated with semantic roles. We also solve the standard IE task, using the induced syntactic patterns to extract role fillers from specific documents. We evaluate on the MUC-4 terrorism dataset and show that we induce template structure very similar to handcreated gold structure, and we extract role fillers with an F1 score of .40, approaching the performance of algorithms that require full knowledge of the templates.</p><p>5 0.18486603 <a title="324-tfidf-5" href="./acl-2011-Semi-supervised_Relation_Extraction_with_Large-scale_Word_Clustering.html">277 acl-2011-Semi-supervised Relation Extraction with Large-scale Word Clustering</a></p>
<p>Author: Ang Sun ; Ralph Grishman ; Satoshi Sekine</p><p>Abstract: We present a simple semi-supervised relation extraction system with large-scale word clustering. We focus on systematically exploring the effectiveness of different cluster-based features. We also propose several statistical methods for selecting clusters at an appropriate level of granularity. When training on different sizes of data, our semi-supervised approach consistently outperformed a state-of-the-art supervised baseline system. 1</p><p>6 0.17778578 <a title="324-tfidf-6" href="./acl-2011-MEANT%3A_An_inexpensive%2C_high-accuracy%2C_semi-automatic_metric_for_evaluating_translation_utility_based_on_semantic_roles.html">216 acl-2011-MEANT: An inexpensive, high-accuracy, semi-automatic metric for evaluating translation utility based on semantic roles</a></p>
<p>7 0.17410961 <a title="324-tfidf-7" href="./acl-2011-Can_Document_Selection_Help_Semi-supervised_Learning%3F_A_Case_Study_On_Event_Extraction.html">65 acl-2011-Can Document Selection Help Semi-supervised Learning? A Case Study On Event Extraction</a></p>
<p>8 0.17399131 <a title="324-tfidf-8" href="./acl-2011-Latent_Semantic_Word_Sense_Induction_and_Disambiguation.html">198 acl-2011-Latent Semantic Word Sense Induction and Disambiguation</a></p>
<p>9 0.16848202 <a title="324-tfidf-9" href="./acl-2011-In-domain_Relation_Discovery_with_Meta-constraints_via_Posterior_Regularization.html">170 acl-2011-In-domain Relation Discovery with Meta-constraints via Posterior Regularization</a></p>
<p>10 0.16203365 <a title="324-tfidf-10" href="./acl-2011-An_Ensemble_Model_that_Combines_Syntactic_and_Semantic_Clustering_for_Discriminative_Dependency_Parsing.html">39 acl-2011-An Ensemble Model that Combines Syntactic and Semantic Clustering for Discriminative Dependency Parsing</a></p>
<p>11 0.15072574 <a title="324-tfidf-11" href="./acl-2011-Classifying_arguments_by_scheme.html">68 acl-2011-Classifying arguments by scheme</a></p>
<p>12 0.13706918 <a title="324-tfidf-12" href="./acl-2011-Fine-Grained_Class_Label_Markup_of_Search_Queries.html">137 acl-2011-Fine-Grained Class Label Markup of Search Queries</a></p>
<p>13 0.12971078 <a title="324-tfidf-13" href="./acl-2011-A_Word-Class_Approach_to_Labeling_PSCFG_Rules_for_Machine_Translation.html">29 acl-2011-A Word-Class Approach to Labeling PSCFG Rules for Machine Translation</a></p>
<p>14 0.11709217 <a title="324-tfidf-14" href="./acl-2011-Improving_Dependency_Parsing_with_Semantic_Classes.html">167 acl-2011-Improving Dependency Parsing with Semantic Classes</a></p>
<p>15 0.11516154 <a title="324-tfidf-15" href="./acl-2011-Content_Models_with_Attitude.html">82 acl-2011-Content Models with Attitude</a></p>
<p>16 0.10345119 <a title="324-tfidf-16" href="./acl-2011-Automatically_Evaluating_Text_Coherence_Using_Discourse_Relations.html">53 acl-2011-Automatically Evaluating Text Coherence Using Discourse Relations</a></p>
<p>17 0.10189538 <a title="324-tfidf-17" href="./acl-2011-Semi-Supervised_Frame-Semantic_Parsing_for_Unknown_Predicates.html">274 acl-2011-Semi-Supervised Frame-Semantic Parsing for Unknown Predicates</a></p>
<p>18 0.10059611 <a title="324-tfidf-18" href="./acl-2011-Coreference_for_Learning_to_Extract_Relations%3A_Yes_Virginia%2C_Coreference_Matters.html">86 acl-2011-Coreference for Learning to Extract Relations: Yes Virginia, Coreference Matters</a></p>
<p>19 0.096535012 <a title="324-tfidf-19" href="./acl-2011-Semantic_Representation_of_Negation_Using_Focus_Detection.html">273 acl-2011-Semantic Representation of Negation Using Focus Detection</a></p>
<p>20 0.089149103 <a title="324-tfidf-20" href="./acl-2011-Corpus_Expansion_for_Statistical_Machine_Translation_with_Semantic_Role_Label_Substitution_Rules.html">87 acl-2011-Corpus Expansion for Statistical Machine Translation with Semantic Role Label Substitution Rules</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.256), (1, 0.049), (2, -0.183), (3, -0.075), (4, 0.097), (5, 0.04), (6, 0.041), (7, 0.033), (8, 0.017), (9, -0.071), (10, 0.072), (11, -0.154), (12, 0.062), (13, 0.074), (14, -0.122), (15, -0.16), (16, -0.194), (17, -0.08), (18, -0.008), (19, 0.007), (20, -0.099), (21, 0.08), (22, -0.132), (23, -0.146), (24, 0.074), (25, -0.02), (26, -0.044), (27, -0.135), (28, -0.02), (29, -0.072), (30, -0.041), (31, -0.069), (32, -0.032), (33, -0.034), (34, -0.037), (35, -0.03), (36, 0.073), (37, -0.016), (38, -0.113), (39, -0.072), (40, 0.002), (41, 0.052), (42, -0.085), (43, 0.133), (44, 0.092), (45, 0.071), (46, 0.009), (47, -0.024), (48, -0.105), (49, 0.126)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9807831 <a title="324-lsi-1" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>Author: Joel Lang ; Mirella Lapata</p><p>Abstract: In this paper we describe an unsupervised method for semantic role induction which holds promise for relieving the data acquisition bottleneck associated with supervised role labelers. We present an algorithm that iteratively splits and merges clusters representing semantic roles, thereby leading from an initial clustering to a final clustering of better quality. The method is simple, surprisingly effective, and allows to integrate linguistic knowledge transparently. By combining role induction with a rule-based component for argument identification we obtain an unsupervised end-to-end semantic role labeling system. Evaluation on the CoNLL 2008 benchmark dataset demonstrates that our method outperforms competitive unsupervised approaches by a wide margin.</p><p>2 0.89692289 <a title="324-lsi-2" href="./acl-2011-Classifying_arguments_by_scheme.html">68 acl-2011-Classifying arguments by scheme</a></p>
<p>Author: Vanessa Wei Feng ; Graeme Hirst</p><p>Abstract: Argumentation schemes are structures or templates for various kinds of arguments. Given the text of an argument with premises and conclusion identified, we classify it as an instance ofone offive common schemes, using features specific to each scheme. We achieve accuracies of 63–91% in one-against-others classification and 80–94% in pairwise classification (baseline = 50% in both cases).</p><p>3 0.84513861 <a title="324-lsi-3" href="./acl-2011-A_Bayesian_Model_for_Unsupervised_Semantic_Parsing.html">3 acl-2011-A Bayesian Model for Unsupervised Semantic Parsing</a></p>
<p>Author: Ivan Titov ; Alexandre Klementiev</p><p>Abstract: We propose a non-parametric Bayesian model for unsupervised semantic parsing. Following Poon and Domingos (2009), we consider a semantic parsing setting where the goal is to (1) decompose the syntactic dependency tree of a sentence into fragments, (2) assign each of these fragments to a cluster of semantically equivalent syntactic structures, and (3) predict predicate-argument relations between the fragments. We use hierarchical PitmanYor processes to model statistical dependencies between meaning representations of predicates and those of their arguments, as well as the clusters of their syntactic realizations. We develop a modification of the MetropolisHastings split-merge sampler, resulting in an efficient inference algorithm for the model. The method is experimentally evaluated by us- ing the induced semantic representation for the question answering task in the biomedical domain.</p><p>4 0.75753158 <a title="324-lsi-4" href="./acl-2011-Scaling_up_Automatic_Cross-Lingual_Semantic_Role_Annotation.html">269 acl-2011-Scaling up Automatic Cross-Lingual Semantic Role Annotation</a></p>
<p>Author: Lonneke van der Plas ; Paola Merlo ; James Henderson</p><p>Abstract: Broad-coverage semantic annotations for training statistical learners are only available for a handful of languages. Previous approaches to cross-lingual transfer of semantic annotations have addressed this problem with encouraging results on a small scale. In this paper, we scale up previous efforts by using an automatic approach to semantic annotation that does not rely on a semantic ontology for the target language. Moreover, we improve the quality of the transferred semantic annotations by using a joint syntacticsemantic parser that learns the correlations between syntax and semantics of the target language and smooths out the errors from automatic transfer. We reach a labelled F-measure for predicates and arguments of only 4% and 9% points, respectively, lower than the upper bound from manual annotations.</p><p>5 0.68849021 <a title="324-lsi-5" href="./acl-2011-Semi-Supervised_Frame-Semantic_Parsing_for_Unknown_Predicates.html">274 acl-2011-Semi-Supervised Frame-Semantic Parsing for Unknown Predicates</a></p>
<p>Author: Dipanjan Das ; Noah A. Smith</p><p>Abstract: We describe a new approach to disambiguating semantic frames evoked by lexical predicates previously unseen in a lexicon or annotated data. Our approach makes use of large amounts of unlabeled data in a graph-based semi-supervised learning framework. We construct a large graph where vertices correspond to potential predicates and use label propagation to learn possible semantic frames for new ones. The label-propagated graph is used within a frame-semantic parser and, for unknown predicates, results in over 15% absolute improvement in frame identification accuracy and over 13% absolute improvement in full frame-semantic parsing F1 score on a blind test set, over a state-of-the-art supervised baseline.</p><p>6 0.65754926 <a title="324-lsi-6" href="./acl-2011-Template-Based_Information_Extraction_without_the_Templates.html">293 acl-2011-Template-Based Information Extraction without the Templates</a></p>
<p>7 0.62202632 <a title="324-lsi-7" href="./acl-2011-Unsupervised_Learning_of_Semantic_Relation_Composition.html">322 acl-2011-Unsupervised Learning of Semantic Relation Composition</a></p>
<p>8 0.54297769 <a title="324-lsi-8" href="./acl-2011-Unsupervised_Decomposition_of_a_Document_into_Authorial_Components.html">319 acl-2011-Unsupervised Decomposition of a Document into Authorial Components</a></p>
<p>9 0.51155519 <a title="324-lsi-9" href="./acl-2011-Improving_Dependency_Parsing_with_Semantic_Classes.html">167 acl-2011-Improving Dependency Parsing with Semantic Classes</a></p>
<p>10 0.50743407 <a title="324-lsi-10" href="./acl-2011-Insights_from_Network_Structure_for_Text_Mining.html">174 acl-2011-Insights from Network Structure for Text Mining</a></p>
<p>11 0.50137424 <a title="324-lsi-11" href="./acl-2011-Confidence_Driven_Unsupervised_Semantic_Parsing.html">79 acl-2011-Confidence Driven Unsupervised Semantic Parsing</a></p>
<p>12 0.49925977 <a title="324-lsi-12" href="./acl-2011-Learning_Dependency-Based_Compositional_Semantics.html">200 acl-2011-Learning Dependency-Based Compositional Semantics</a></p>
<p>13 0.49449828 <a title="324-lsi-13" href="./acl-2011-In-domain_Relation_Discovery_with_Meta-constraints_via_Posterior_Regularization.html">170 acl-2011-In-domain Relation Discovery with Meta-constraints via Posterior Regularization</a></p>
<p>14 0.49427152 <a title="324-lsi-14" href="./acl-2011-Contrasting_Opposing_Views_of_News_Articles_on_Contentious_Issues.html">84 acl-2011-Contrasting Opposing Views of News Articles on Contentious Issues</a></p>
<p>15 0.49228692 <a title="324-lsi-15" href="./acl-2011-MEANT%3A_An_inexpensive%2C_high-accuracy%2C_semi-automatic_metric_for_evaluating_translation_utility_based_on_semantic_roles.html">216 acl-2011-MEANT: An inexpensive, high-accuracy, semi-automatic metric for evaluating translation utility based on semantic roles</a></p>
<p>16 0.48167047 <a title="324-lsi-16" href="./acl-2011-Content_Models_with_Attitude.html">82 acl-2011-Content Models with Attitude</a></p>
<p>17 0.48133588 <a title="324-lsi-17" href="./acl-2011-Semi-supervised_Relation_Extraction_with_Large-scale_Word_Clustering.html">277 acl-2011-Semi-supervised Relation Extraction with Large-scale Word Clustering</a></p>
<p>18 0.47272563 <a title="324-lsi-18" href="./acl-2011-Nonlinear_Evidence_Fusion_and_Propagation_for_Hyponymy_Relation_Mining.html">231 acl-2011-Nonlinear Evidence Fusion and Propagation for Hyponymy Relation Mining</a></p>
<p>19 0.46424469 <a title="324-lsi-19" href="./acl-2011-Latent_Semantic_Word_Sense_Induction_and_Disambiguation.html">198 acl-2011-Latent Semantic Word Sense Induction and Disambiguation</a></p>
<p>20 0.46405476 <a title="324-lsi-20" href="./acl-2011-Unsupervised_Discovery_of_Domain-Specific_Knowledge_from_Text.html">320 acl-2011-Unsupervised Discovery of Domain-Specific Knowledge from Text</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(1, 0.021), (5, 0.028), (17, 0.063), (26, 0.029), (31, 0.013), (37, 0.126), (39, 0.064), (41, 0.09), (53, 0.017), (55, 0.038), (59, 0.094), (72, 0.032), (80, 0.093), (91, 0.046), (96, 0.139), (97, 0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.95580226 <a title="324-lda-1" href="./acl-2011-A_Corpus_for_Modeling_Morpho-Syntactic_Agreement_in_Arabic%3A_Gender%2C_Number_and_Rationality.html">7 acl-2011-A Corpus for Modeling Morpho-Syntactic Agreement in Arabic: Gender, Number and Rationality</a></p>
<p>Author: Sarah Alkuhlani ; Nizar Habash</p><p>Abstract: We present an enriched version of the Penn Arabic Treebank (Maamouri et al., 2004), where latent features necessary for modeling morpho-syntactic agreement in Arabic are manually annotated. We describe our process for efficient annotation, and present the first quantitative analysis of Arabic morphosyntactic phenomena.</p><p>same-paper 2 0.92648399 <a title="324-lda-2" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>Author: Joel Lang ; Mirella Lapata</p><p>Abstract: In this paper we describe an unsupervised method for semantic role induction which holds promise for relieving the data acquisition bottleneck associated with supervised role labelers. We present an algorithm that iteratively splits and merges clusters representing semantic roles, thereby leading from an initial clustering to a final clustering of better quality. The method is simple, surprisingly effective, and allows to integrate linguistic knowledge transparently. By combining role induction with a rule-based component for argument identification we obtain an unsupervised end-to-end semantic role labeling system. Evaluation on the CoNLL 2008 benchmark dataset demonstrates that our method outperforms competitive unsupervised approaches by a wide margin.</p><p>3 0.92405605 <a title="324-lda-3" href="./acl-2011-Improving_Arabic_Dependency_Parsing_with_Form-based_and_Functional_Morphological_Features.html">164 acl-2011-Improving Arabic Dependency Parsing with Form-based and Functional Morphological Features</a></p>
<p>Author: Yuval Marton ; Nizar Habash ; Owen Rambow</p><p>Abstract: We explore the contribution of morphological features both lexical and inflectional to dependency parsing of Arabic, a morphologically rich language. Using controlled experiments, we find that definiteness, person, number, gender, and the undiacritzed lemma are most helpful for parsing on automatically tagged input. We further contrast the contribution of form-based and functional features, and show that functional gender and number (e.g., “broken plurals”) and the related rationality feature improve over form-based features. It is the first time functional morphological features are used for Arabic NLP. – –</p><p>4 0.90331161 <a title="324-lda-4" href="./acl-2011-An_exponential_translation_model_for_target_language_morphology.html">44 acl-2011-An exponential translation model for target language morphology</a></p>
<p>Author: Michael Subotin</p><p>Abstract: This paper presents an exponential model for translation into highly inflected languages which can be scaled to very large datasets. As in other recent proposals, it predicts targetside phrases and can be conditioned on sourceside context. However, crucially for the task of modeling morphological generalizations, it estimates feature parameters from the entire training set rather than as a collection of separate classifiers. We apply it to English-Czech translation, using a variety of features capturing potential predictors for case, number, and gender, and one of the largest publicly available parallel data sets. We also describe generation and modeling of inflected forms unobserved in training data and decoding procedures for a model with non-local target-side feature dependencies.</p><p>5 0.8948245 <a title="324-lda-5" href="./acl-2011-Exploiting_Syntactico-Semantic_Structures_for_Relation_Extraction.html">126 acl-2011-Exploiting Syntactico-Semantic Structures for Relation Extraction</a></p>
<p>Author: Yee Seng Chan ; Dan Roth</p><p>Abstract: In this paper, we observe that there exists a second dimension to the relation extraction (RE) problem that is orthogonal to the relation type dimension. We show that most of these second dimensional structures are relatively constrained and not difficult to identify. We propose a novel algorithmic approach to RE that starts by first identifying these structures and then, within these, identifying the semantic type of the relation. In the real RE problem where relation arguments need to be identified, exploiting these structures also allows reducing pipelined propagated errors. We show that this RE framework provides significant improvement in RE performance.</p><p>6 0.8844797 <a title="324-lda-6" href="./acl-2011-In-domain_Relation_Discovery_with_Meta-constraints_via_Posterior_Regularization.html">170 acl-2011-In-domain Relation Discovery with Meta-constraints via Posterior Regularization</a></p>
<p>7 0.88336325 <a title="324-lda-7" href="./acl-2011-Can_Document_Selection_Help_Semi-supervised_Learning%3F_A_Case_Study_On_Event_Extraction.html">65 acl-2011-Can Document Selection Help Semi-supervised Learning? A Case Study On Event Extraction</a></p>
<p>8 0.87967777 <a title="324-lda-8" href="./acl-2011-Subjectivity_and_Sentiment_Analysis_of_Modern_Standard_Arabic.html">289 acl-2011-Subjectivity and Sentiment Analysis of Modern Standard Arabic</a></p>
<p>9 0.87805974 <a title="324-lda-9" href="./acl-2011-Scaling_up_Automatic_Cross-Lingual_Semantic_Role_Annotation.html">269 acl-2011-Scaling up Automatic Cross-Lingual Semantic Role Annotation</a></p>
<p>10 0.87619781 <a title="324-lda-10" href="./acl-2011-A_Bayesian_Model_for_Unsupervised_Semantic_Parsing.html">3 acl-2011-A Bayesian Model for Unsupervised Semantic Parsing</a></p>
<p>11 0.87408519 <a title="324-lda-11" href="./acl-2011-Exploring_Entity_Relations_for_Named_Entity_Disambiguation.html">128 acl-2011-Exploring Entity Relations for Named Entity Disambiguation</a></p>
<p>12 0.87348533 <a title="324-lda-12" href="./acl-2011-Semi-supervised_Relation_Extraction_with_Large-scale_Word_Clustering.html">277 acl-2011-Semi-supervised Relation Extraction with Large-scale Word Clustering</a></p>
<p>13 0.87293923 <a title="324-lda-13" href="./acl-2011-Knowledge-Based_Weak_Supervision_for_Information_Extraction_of_Overlapping_Relations.html">190 acl-2011-Knowledge-Based Weak Supervision for Information Extraction of Overlapping Relations</a></p>
<p>14 0.87159395 <a title="324-lda-14" href="./acl-2011-Beam-Width_Prediction_for_Efficient_Context-Free_Parsing.html">58 acl-2011-Beam-Width Prediction for Efficient Context-Free Parsing</a></p>
<p>15 0.86744452 <a title="324-lda-15" href="./acl-2011-Translationese_and_Its_Dialects.html">311 acl-2011-Translationese and Its Dialects</a></p>
<p>16 0.86635423 <a title="324-lda-16" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<p>17 0.86212689 <a title="324-lda-17" href="./acl-2011-Peeling_Back_the_Layers%3A_Detecting_Event_Role_Fillers_in_Secondary_Contexts.html">244 acl-2011-Peeling Back the Layers: Detecting Event Role Fillers in Secondary Contexts</a></p>
<p>18 0.86190844 <a title="324-lda-18" href="./acl-2011-Semi-Supervised_Frame-Semantic_Parsing_for_Unknown_Predicates.html">274 acl-2011-Semi-Supervised Frame-Semantic Parsing for Unknown Predicates</a></p>
<p>19 0.86165702 <a title="324-lda-19" href="./acl-2011-Lexically-Triggered_Hidden_Markov_Models_for_Clinical_Document_Coding.html">209 acl-2011-Lexically-Triggered Hidden Markov Models for Clinical Document Coding</a></p>
<p>20 0.86102897 <a title="324-lda-20" href="./acl-2011-Using_Bilingual_Parallel_Corpora_for_Cross-Lingual_Textual_Entailment.html">327 acl-2011-Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
