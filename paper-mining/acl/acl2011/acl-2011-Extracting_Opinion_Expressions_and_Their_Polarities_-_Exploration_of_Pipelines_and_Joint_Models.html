<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>131 acl-2011-Extracting Opinion Expressions and Their Polarities - Exploration of Pipelines and Joint Models</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-131" href="#">acl2011-131</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>131 acl-2011-Extracting Opinion Expressions and Their Polarities - Exploration of Pipelines and Joint Models</h1>
<br/><p>Source: <a title="acl-2011-131-pdf" href="http://aclweb.org/anthology//P/P11/P11-2018.pdf">pdf</a></p><p>Author: Richard Johansson ; Alessandro Moschitti</p><p>Abstract: We investigate systems that identify opinion expressions and assigns polarities to the extracted expressions. In particular, we demonstrate the benefit of integrating opinion extraction and polarity classification into a joint model using features reflecting the global polarity structure. The model is trained using large-margin structured prediction methods. The system is evaluated on the MPQA opinion corpus, where we compare it to the only previously published end-to-end system for opinion expression extraction and polarity classification. The results show an improvement of between 10 and 15 absolute points in F-measure.</p><p>Reference: <a title="acl-2011-131-reference" href="../acl2011_reference/acl-2011-Extracting_Opinion_Expressions_and_Their_Polarities_-_Exploration_of_Pipelines_and_Joint_Models_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 it  ,  Abstract We investigate systems that identify opinion expressions and assigns polarities to the extracted expressions. [sent-3, score-0.656]
</p><p>2 In particular, we demonstrate the benefit of integrating opinion extraction and polarity classification into a joint model using features reflecting the global polarity structure. [sent-4, score-1.279]
</p><p>3 The system is evaluated on the MPQA opinion corpus, where we compare it to the only previously published end-to-end system for opinion expression extraction and polarity classification. [sent-6, score-1.248]
</p><p>4 1 Introduction Automatic systems for the analysis of opinions expressed in text on the web have been studied extensively. [sent-8, score-0.128]
</p><p>5 However, in recent years there has been a shift towards a more detailed task: not only finding the text expressing the opinion, but also analysing it: who holds the opinion and to what is addressed; it is positive or negative (polarity); what its intensity is. [sent-10, score-0.388]
</p><p>6 This more complex formulation leads us deep into NLP territory; the methods employed here have been inspired by information extraction and semantic role labeling, combinatorial optimization and structured machine learning. [sent-11, score-0.125]
</p><p>7 A crucial step in the automatic analysis of opinion is to mark up the opinion expressions: the pieces of 101 text allowing us to infer that someone has a particular feeling about some topic. [sent-12, score-0.648]
</p><p>8 Then, opinions can be assigned a polarity describing whether the feeling is positive, neutral or negative. [sent-13, score-0.632]
</p><p>9 For the task of classifiying the polarity of a given expression, there has been fairly extensive work on suitable classification features (Wilson et al. [sent-17, score-0.442]
</p><p>10 While the tasks of expression detection and polarity classification have mostly been studied in isolation, Choi and Cardie (2010) developed a sequence labeler that simultaneously extracted opinion expressions and assigned polarities. [sent-19, score-1.231]
</p><p>11 This is so far the only published result on joint opinion segmentation and polarity classification. [sent-20, score-0.816]
</p><p>12 However, their experiment lacked the obvious baseline: a standard pipeline consisting of an expression identifier followed by a polarity classifier. [sent-21, score-0.631]
</p><p>13 In addition, while theirs is the first end-to-end system for expression extraction with polarities, it is still a sequence labeler, which, by construction, is restricted to use simple local features. [sent-22, score-0.238]
</p><p>14 In contrast, in (Johansson and Moschitti, 2010b), we showed that global structure matters: opinions interact to a large extent, and we can learn about their interactions on the opinion level by means of their interactions on the syntactic and semantic levels. [sent-23, score-0.51]
</p><p>15 It is intuitive that  this should also be valid when polarities enter the Proceedings ofP thoer t4l9atnhd A, Onrnuegaoln M,e Jeuntineg 19 o-f2 t4h,e 2 A0s1s1o. [sent-24, score-0.201]
</p><p>16 Evaluative adjectives referring to the same evaluee may cluster together in the same clause or be dominated by a verb of categorization; opinions with opposite polarities may be conjoined through a contrastive discourse connective such as but. [sent-27, score-0.333]
</p><p>17 In this paper, we first implement two strong baselines consisting of pipelines of opinion expression segmentation and polarity labeling and compare them to the joint opinion extractor and polarity classifier by Choi and Cardie (2010). [sent-28, score-1.897]
</p><p>18 Secondly, we extend the global structure approach and add features reflecting the polarity structure of the sentence. [sent-29, score-0.543]
</p><p>19 The central building block in the MPQA annotation is the opinion expression. [sent-34, score-0.308]
</p><p>20 Opinion expressions belong to two  categories: Direct subjective expressions (DSEs) are explicit mentions of opinion whereas expressive subjective elements (ESEs) signal the attitude of the speaker by the choice of words. [sent-35, score-0.628]
</p><p>21 Opinions have two features: polarity and intensity, and most expressions are also associated with a holder, also called source. [sent-36, score-0.589]
</p><p>22 The polarity takes the values POSITIVE, NEUTRAL, NEGATIVE, and BOTH; for compatibility with Choi and Cardie (2010), we mapped BOTH to NEUTRAL. [sent-38, score-0.492]
</p><p>23 3  The Baselines  In order to test our hypothesis against strong baselines, we developed two pipeline systems. [sent-39, score-0.053]
</p><p>24 The first part of each pipeline extracts opinion expressions, and this is followed by a multiclass classifier assigning a polarity to a given opinion expression, similar to that described by Wilson et al. [sent-40, score-1.129]
</p><p>25 The first of the two baselines extracts opinion expressions using a sequence labeler similar to that by Breck et al. [sent-42, score-0.64]
</p><p>26 Sequence labeling techniques such as HMMs and CRFs are widely used for segmentation problems such as  named entity recognition and noun chunk extraction. [sent-45, score-0.064]
</p><p>27 We trained a first-order labeler with the discrimi102 native training method by Collins (2002) and used common features: words, POS, lemmas in a sliding window. [sent-46, score-0.098]
</p><p>28 For the second baseline, we added our opinion expression reranker (Johansson and Moschitti, 2010b) on top of the expression sequence labeler. [sent-49, score-0.865]
</p><p>29 Given an expression, we use a classifier to assign a polarity value: positive, neutral, or negative. [sent-50, score-0.486]
</p><p>30 The problem of polarity classification has been studied in detail by Wilson et al. [sent-52, score-0.468]
</p><p>31 Our classifier is simpler and is based on fairly shallow features: words, POS, subjectivity clues, and bigrams inside and around the expression. [sent-54, score-0.085]
</p><p>32 4  The Joint Model  We formulate the opinion extraction task as a structured prediction problem ˆy = arg maxy w · Φ(x, y). [sent-55, score-0.414]
</p><p>33 This is a high-level formulation we still need an inference procedure for the arg max and a learner to estimate w on a training set. [sent-58, score-0.069]
</p><p>34 1 Approximate Inference Since there is a combinatorial number of ways to segment a sentence and label the segments with polarities, the tractability of the arg max operation will obviously depend on whether we can factorize the problem for a particular Φ. [sent-60, score-0.094]
</p><p>35 Choi and Cardie (2010) used a Markov factorization and could thus apply standard sequence labeling with a Viterbi arg max. [sent-61, score-0.122]
</p><p>36 However, in (Johansson and Moschitti, 2010b), we showed that a large improvement can be achieved if relations between possible expressions are considered; these relations can be syntactic or semantic in nature, for instance. [sent-62, score-0.278]
</p><p>37 This representation breaks the Markov assumption and the arg max becomes intractable. [sent-63, score-0.069]
</p><p>38 We instead used a reranking approximation: a Viterbibased sequence tagger following Breck et al. [sent-64, score-0.077]
</p><p>39 (2007) generated a manageable hypothesis set of complete  segmentations, from which the reranking classifier picked one hypothesis as its final output. [sent-65, score-0.125]
</p><p>40 Since the set is small, no particular structure assumption (such as Markovization) needs to be made, so the reranker can in principle use features of arbitrary complexity. [sent-66, score-0.21]
</p><p>41 We now adapt that approach to the problem of joint opinion expression segmentation and polarity classification. [sent-67, score-0.978]
</p><p>42 In that case, we not only need hypotheses generated by a sequence labeler, but also the polarity labelings output by a polarity classifier. [sent-68, score-0.932]
</p><p>43 The hypothesis generation thus proceeds as follows: • For a given sentence, let the base sequence laFboelrer a generate up ntcoe ks sequences osefq quunelnabceel leadopinion expressions; • for every sequence, apply the base polarity fcolarss eivfeierry yto s generate up ptop kp polarity labelings. [sent-69, score-1.065]
</p><p>44 Thus, the hypothesis set size is at most ks · kp. [sent-70, score-0.088]
</p><p>45 We used a ks of 64 and a kp of 4 in all experiments. [sent-71, score-0.107]
</p><p>46 To illustrate this process we give a hypothetical example, assuming ks = kp = 2 and the sentence The appeasement emboldened the terrorists. [sent-72, score-0.594]
</p><p>47 2 Features of the Joint Model The features used by thejoint opinion segmenter and polarity classifier are based on pairs of opinions: basic features extracted from each expression such as polarities and words, and relational features describing their interaction. [sent-74, score-1.215]
</p><p>48 To extract relations we used the parser by Johansson and Nugues (2008) to annotate sentences with dependencies and shallow semantics in the PropBank (Palmer et al. [sent-75, score-0.095]
</p><p>49 Figure 1 shows the sentence the appeasement emboldened the terrorists, where appeasement and terrorists are opinions with negative polarity, with dependency syntax (above the text) and a predicate– argument structure (below). [sent-78, score-1.118]
</p><p>50 The model used the following novel features that take the polarities of the expressions into account. [sent-83, score-0.348]
</p><p>51 The examples are given with respect to the two expressions (appeasement and terrorists) in Figure 1. [sent-84, score-0.147]
</p><p>52 Sum of the scores from the polarity classifier for every opinion. [sent-86, score-0.486]
</p><p>53 For every pair of opinions in the sentence, we add the pair of polarities: NEGATIVE+NEGATIVE. [sent-88, score-0.192]
</p><p>54 For a pair of opinions, we use the polarities and a  representation of the path through the syntax tree between the expressions, following standard practice from dependency-based SRL (Johansson and Nugues, 2008): NEGATIVE+SBJ↑OBJ↓+NEGATIVE. [sent-90, score-0.286]
</p><p>55 that one expression is above the other in the syntax tree. [sent-94, score-0.192]
</p><p>56 In the example, no such feature is extracted since neither of the expressions dominates the other. [sent-95, score-0.147]
</p><p>57 The polarity pair concatenated with the words of the closest nodes of the two expressions: NEGATIVE+NEGATIVE+appeasement+terrorists. [sent-97, score-0.475]
</p><p>58 From the opinion sequence labeler, we get the expression type as in MPQA (DSE or ESE): ESENEGATIVE:+SBJ↑OBJ↓+ESE-NEGATIVE. [sent-99, score-0.518]
</p><p>59 When two opinions are directly connected through a link in the semantic structure, we add the role label as a feature. [sent-101, score-0.164]
</p><p>60 We  follow the path between the expressions and add a feature for every word we pass: NEGATIVE:+emboldened+NEGATIVE. [sent-103, score-0.193]
</p><p>61 We also used the features we developed in (Johansson and Moschitti, 2010b) to represent relations between expressions without taking polarity into account. [sent-104, score-0.617]
</p><p>62 3 Training the Model To train the model find w we applied max-margin estimation for structured outputs, a generalization of the well-known support vector machine from binary classification to prediction of structured objects. [sent-106, score-0.068]
</p><p>63 The quadratic program is usually not solved directly  since the number of constraints precludes a direct solution. [sent-109, score-0.059]
</p><p>64 The loss ∆ was defined as 1 minus a weighted combination of polarity-labeled and unlabeled intersection F-measure as described in Section 5. [sent-113, score-0.051]
</p><p>65 SVMstruct  5  Experiments  Opinion expression boundaries are hard to define rigorously (Wiebe et al. [sent-114, score-0.162]
</p><p>66 The MPQA annotators used the overlap metric: an expression is counted as correct if it overlaps with one in the gold standard. [sent-116, score-0.215]
</p><p>67 This has also been used to evaluate opinion extractors (Choi et al. [sent-117, score-0.308]
</p><p>68 However, this metric has a number of problems: 1) it is possible to ”fool” the metric by creating expressions that cover the whole sentence; 2) it does not give higher credit to output that is ”almost 104 perfect” rather than ”almost incorrect”. [sent-120, score-0.147]
</p><p>69 Therefore,  in (Johansson and Moschitti, 2010b), we measured the intersection between the system output and the gold standard: every compared segment is assigned a score between 0 and 1, as opposed to strict or overlap scoring that only assigns 0 or 1. [sent-121, score-0.104]
</p><p>70 1 Evaluation of Segmentation with Polarity We first compared the two baselines to the new integrated segmentation/polarity system. [sent-124, score-0.039]
</p><p>71 Table 1 shows the performance according to the intersection metric. [sent-125, score-0.051]
</p><p>72 Our first baseline consists of an expression segmenter and a polarity classifier (ES+PC), while in the second baseline we also add the expression reranker (ER) as we did in (Johansson and Moschitti, 2010b). [sent-126, score-1.05]
</p><p>73 The new reranker described in this paper is referred to as the expression/polarity reranker (EPR). [sent-127, score-0.37]
</p><p>74 In addition, we see the benefit of the new reranker with polarity interaction features. [sent-141, score-0.627]
</p><p>75 The system using this reranker (ES+PC+EPR) outperforms the expression reranker (ES+ER+PC). [sent-142, score-0.532]
</p><p>76 1 Table 2 shows our figures (for the two baselines and the new reranker)  along with theirs, referred to as C & C (2010). [sent-148, score-0.039]
</p><p>77 The table shows the scores for every polarity value. [sent-149, score-0.442]
</p><p>78 For compatibility with their evaluation, we used the overlap metric and carried out the evaluation using a 10-fold cross-validation procedure on a 400document subset of the MPQA corpus. [sent-150, score-0.125]
</p><p>79 The C & C system shows a large precision bias despite being optimized with respect to the recall-promoting overlap metric. [sent-188, score-0.053]
</p><p>80 The precision is lower than for C & C overall, but this is offset by recall boosts for all polarities that are much larger than the precision drops. [sent-190, score-0.229]
</p><p>81 The polarity-based reranker (ES+PC+EPR) soundly outperforms all other systems. [sent-191, score-0.185]
</p><p>82 6  Conclusion  We have studied the implementation of end-to-end systems for opinion expression extraction and polarity labeling. [sent-192, score-0.966]
</p><p>83 We first showed that it was easy to 1In addition to polarity, their system also assigned opinion intensity which we do not consider here. [sent-193, score-0.353]
</p><p>84 105 improve over previous results simply by combining  an opinion extractor and a polarity classifier; the improvements were between 7. [sent-194, score-0.777]
</p><p>85 However, our most interesting result is that a joint model of expression extraction and polarity labeling significantly improves over the sequential approach. [sent-196, score-0.694]
</p><p>86 This model uses features describing the interaction of opinions through linguistic structures. [sent-197, score-0.129]
</p><p>87 The final system improved over the baseline by 4 points in intersection F-measure and 7 points in recall. [sent-200, score-0.051]
</p><p>88 The improvements over Choi and Cardie (2010) ranged between 10 and 15 in overlap F-measure and between 17 and 24 in recall. [sent-201, score-0.053]
</p><p>89 This is not only of practical value but also confirms our linguistic intuitions that surface phenomena such as syntax and semantic roles are used in encoding the rhetorical organization of the sentence, and that we can thus extract useful information from those structures. [sent-202, score-0.068]
</p><p>90 However, automatic discourse structure analysis is still in its infancy while syntactic and shallow semantic parsing are relatively mature. [sent-205, score-0.171]
</p><p>91 Interesting future work should be devoted to address the use of structural kernels for the proposed reranker. [sent-206, score-0.072]
</p><p>92 This would allow to better exploit syntactic and shallow semantic structures, e. [sent-207, score-0.116]
</p><p>93 as in (Moschitti, 2008), also applying lexical similarity and syntactic kernels (Bloehdorn et al. [sent-209, score-0.109]
</p><p>94 Combined syntactic and semantic kernels for text classification. [sent-214, score-0.147]
</p><p>95 Semantic kernels for text classification based on topological measures of feature similarity. [sent-222, score-0.072]
</p><p>96 Learning with compositional semantics as structural inference for subsentential sentiment analysis. [sent-230, score-0.048]
</p><p>97 Hierarchical sequential learning for extracting opinions and their attributes. [sent-234, score-0.102]
</p><p>98 Joint extraction of entities and relations for opinion recog-  nition. [sent-238, score-0.364]
</p><p>99 Kernel methods, syntax and semantics for relational text categorization. [sent-266, score-0.056]
</p><p>100 Supervised and unsupervised methods in employing discourse relations for improving opinion polarity classification. [sent-279, score-0.808]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('polarity', 0.442), ('opinion', 0.308), ('appeasement', 0.255), ('emboldened', 0.232), ('moschitti', 0.232), ('polarities', 0.201), ('johansson', 0.191), ('reranker', 0.185), ('terrorists', 0.184), ('choi', 0.169), ('expression', 0.162), ('expressions', 0.147), ('pc', 0.146), ('epr', 0.143), ('bloehdorn', 0.139), ('mpqa', 0.124), ('es', 0.121), ('alessandro', 0.109), ('opinions', 0.102), ('labeler', 0.098), ('breck', 0.096), ('cardie', 0.091), ('wilson', 0.073), ('kernels', 0.072), ('ks', 0.062), ('yejin', 0.062), ('yij', 0.061), ('claire', 0.061), ('wiebe', 0.058), ('overlap', 0.053), ('intersection', 0.051), ('compatibility', 0.05), ('sequence', 0.048), ('holder', 0.046), ('sbj', 0.046), ('janyce', 0.045), ('er', 0.045), ('intensity', 0.045), ('kp', 0.045), ('arg', 0.044), ('classifier', 0.044), ('propbank', 0.043), ('shallow', 0.041), ('tsochantaridis', 0.041), ('theresa', 0.04), ('baselines', 0.039), ('semantic', 0.038), ('yii', 0.038), ('hxi', 0.038), ('syntactic', 0.037), ('precludes', 0.035), ('negative', 0.035), ('structured', 0.034), ('segmentation', 0.034), ('nombank', 0.034), ('somasundaran', 0.034), ('yi', 0.033), ('pair', 0.033), ('feeling', 0.032), ('joint', 0.032), ('joachims', 0.032), ('segmenter', 0.031), ('discourse', 0.03), ('labeling', 0.03), ('syntax', 0.03), ('obj', 0.03), ('united', 0.03), ('stephan', 0.029), ('neutral', 0.029), ('fmeasure', 0.029), ('pipelines', 0.029), ('reranking', 0.029), ('boosts', 0.028), ('meyers', 0.028), ('relations', 0.028), ('extraction', 0.028), ('pipeline', 0.027), ('reflecting', 0.027), ('extractor', 0.027), ('nugues', 0.027), ('describing', 0.027), ('trento', 0.027), ('semantics', 0.026), ('studied', 0.026), ('expressive', 0.026), ('hypothesis', 0.026), ('tackled', 0.025), ('combinatorial', 0.025), ('taskar', 0.025), ('max', 0.025), ('structure', 0.025), ('quadratic', 0.024), ('add', 0.024), ('paul', 0.023), ('markov', 0.023), ('palmer', 0.023), ('path', 0.022), ('sentiment', 0.022), ('carried', 0.022), ('xi', 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="131-tfidf-1" href="./acl-2011-Extracting_Opinion_Expressions_and_Their_Polarities_-_Exploration_of_Pipelines_and_Joint_Models.html">131 acl-2011-Extracting Opinion Expressions and Their Polarities - Exploration of Pipelines and Joint Models</a></p>
<p>Author: Richard Johansson ; Alessandro Moschitti</p><p>Abstract: We investigate systems that identify opinion expressions and assigns polarities to the extracted expressions. In particular, we demonstrate the benefit of integrating opinion extraction and polarity classification into a joint model using features reflecting the global polarity structure. The model is trained using large-margin structured prediction methods. The system is evaluated on the MPQA opinion corpus, where we compare it to the only previously published end-to-end system for opinion expression extraction and polarity classification. The results show an improvement of between 10 and 15 absolute points in F-measure.</p><p>2 0.3254011 <a title="131-tfidf-2" href="./acl-2011-Identifying_Noun_Product_Features_that_Imply_Opinions.html">159 acl-2011-Identifying Noun Product Features that Imply Opinions</a></p>
<p>Author: Lei Zhang ; Bing Liu</p><p>Abstract: Identifying domain-dependent opinion words is a key problem in opinion mining and has been studied by several researchers. However, existing work has been focused on adjectives and to some extent verbs. Limited work has been done on nouns and noun phrases. In our work, we used the feature-based opinion mining model, and we found that in some domains nouns and noun phrases that indicate product features may also imply opinions. In many such cases, these nouns are not subjective but objective. Their involved sentences are also objective sentences and imply positive or negative opinions. Identifying such nouns and noun phrases and their polarities is very challenging but critical for effective opinion mining in these domains. To the best of our knowledge, this problem has not been studied in the literature. This paper proposes a method to deal with the problem. Experimental results based on real-life datasets show promising results. 1</p><p>3 0.19481841 <a title="131-tfidf-3" href="./acl-2011-Liars_and_Saviors_in_a_Sentiment_Annotated_Corpus_of_Comments_to_Political_Debates.html">211 acl-2011-Liars and Saviors in a Sentiment Annotated Corpus of Comments to Political Debates</a></p>
<p>Author: Paula Carvalho ; Luis Sarmento ; Jorge Teixeira ; Mario J. Silva</p><p>Abstract: We investigate the expression of opinions about human entities in user-generated content (UGC). A set of 2,800 online news comments (8,000 sentences) was manually annotated, following a rich annotation scheme designed for this purpose. We conclude that the challenge in performing opinion mining in such type of content is correctly identifying the positive opinions, because (i) they are much less frequent than negative opinions and (ii) they are particularly exposed to verbal irony. We also show that the recognition of human targets poses additional challenges on mining opinions from UGC, since they are frequently mentioned by pronouns, definite descriptions and nicknames. 1</p><p>4 0.14563411 <a title="131-tfidf-4" href="./acl-2011-Sentiment_Analysis_of_Citations_using_Sentence_Structure-Based_Features.html">281 acl-2011-Sentiment Analysis of Citations using Sentence Structure-Based Features</a></p>
<p>Author: Awais Athar</p><p>Abstract: Sentiment analysis of citations in scientific papers and articles is a new and interesting problem due to the many linguistic differences between scientific texts and other genres. In this paper, we focus on the problem of automatic identification of positive and negative sentiment polarity in citations to scientific papers. Using a newly constructed annotated citation sentiment corpus, we explore the effectiveness of existing and novel features, including n-grams, specialised science-specific lexical features, dependency relations, sentence splitting and negation features. Our results show that 3-grams and dependencies perform best in this task; they outperform the sentence splitting, science lexicon and negation based features.</p><p>5 0.14259544 <a title="131-tfidf-5" href="./acl-2011-Joint_Bilingual_Sentiment_Classification_with_Unlabeled_Parallel_Corpora.html">183 acl-2011-Joint Bilingual Sentiment Classification with Unlabeled Parallel Corpora</a></p>
<p>Author: Bin Lu ; Chenhao Tan ; Claire Cardie ; Benjamin K. Tsou</p><p>Abstract: Most previous work on multilingual sentiment analysis has focused on methods to adapt sentiment resources from resource-rich languages to resource-poor languages. We present a novel approach for joint bilingual sentiment classification at the sentence level that augments available labeled data in each language with unlabeled parallel data. We rely on the intuition that the sentiment labels for parallel sentences should be similar and present a model that jointly learns improved monolingual sentiment classifiers for each language. Experiments on multiple data sets show that the proposed approach (1) outperforms the monolingual baselines, significantly improving the accuracy for both languages by 3.44%-8. 12%; (2) outperforms two standard approaches for leveraging unlabeled data; and (3) produces (albeit smaller) performance gains when employing pseudo-parallel data from machine translation engines. 1</p><p>6 0.1342935 <a title="131-tfidf-6" href="./acl-2011-A_Pilot_Study_of_Opinion_Summarization_in_Conversations.html">21 acl-2011-A Pilot Study of Opinion Summarization in Conversations</a></p>
<p>7 0.11550627 <a title="131-tfidf-7" href="./acl-2011-PsychoSentiWordNet.html">253 acl-2011-PsychoSentiWordNet</a></p>
<p>8 0.10337043 <a title="131-tfidf-8" href="./acl-2011-Aspect_Ranking%3A_Identifying_Important_Product_Aspects_from_Online_Consumer_Reviews.html">45 acl-2011-Aspect Ranking: Identifying Important Product Aspects from Online Consumer Reviews</a></p>
<p>9 0.10290558 <a title="131-tfidf-9" href="./acl-2011-Subjectivity_and_Sentiment_Analysis_of_Modern_Standard_Arabic.html">289 acl-2011-Subjectivity and Sentiment Analysis of Modern Standard Arabic</a></p>
<p>10 0.097604826 <a title="131-tfidf-10" href="./acl-2011-Dr_Sentiment_Knows_Everything%21.html">105 acl-2011-Dr Sentiment Knows Everything!</a></p>
<p>11 0.093483038 <a title="131-tfidf-11" href="./acl-2011-Identifying_the_Semantic_Orientation_of_Foreign_Words.html">162 acl-2011-Identifying the Semantic Orientation of Foreign Words</a></p>
<p>12 0.084839389 <a title="131-tfidf-12" href="./acl-2011-Target-dependent_Twitter_Sentiment_Classification.html">292 acl-2011-Target-dependent Twitter Sentiment Classification</a></p>
<p>13 0.083710991 <a title="131-tfidf-13" href="./acl-2011-End-to-End_Relation_Extraction_Using_Distant_Supervision_from_External_Semantic_Repositories.html">114 acl-2011-End-to-End Relation Extraction Using Distant Supervision from External Semantic Repositories</a></p>
<p>14 0.083253898 <a title="131-tfidf-14" href="./acl-2011-Learning_Word_Vectors_for_Sentiment_Analysis.html">204 acl-2011-Learning Word Vectors for Sentiment Analysis</a></p>
<p>15 0.081338152 <a title="131-tfidf-15" href="./acl-2011-Extracting_Social_Power_Relationships_from_Natural_Language.html">133 acl-2011-Extracting Social Power Relationships from Natural Language</a></p>
<p>16 0.079649568 <a title="131-tfidf-16" href="./acl-2011-Event_Extraction_as_Dependency_Parsing.html">122 acl-2011-Event Extraction as Dependency Parsing</a></p>
<p>17 0.073465474 <a title="131-tfidf-17" href="./acl-2011-Is_Machine_Translation_Ripe_for_Cross-Lingual_Sentiment_Classification%3F.html">179 acl-2011-Is Machine Translation Ripe for Cross-Lingual Sentiment Classification?</a></p>
<p>18 0.072477095 <a title="131-tfidf-18" href="./acl-2011-Social_Network_Extraction_from_Texts%3A_A_Thesis_Proposal.html">286 acl-2011-Social Network Extraction from Texts: A Thesis Proposal</a></p>
<p>19 0.07001058 <a title="131-tfidf-19" href="./acl-2011-Finding_Deceptive_Opinion_Spam_by_Any_Stretch_of_the_Imagination.html">136 acl-2011-Finding Deceptive Opinion Spam by Any Stretch of the Imagination</a></p>
<p>20 0.0681144 <a title="131-tfidf-20" href="./acl-2011-The_impact_of_language_models_and_loss_functions_on_repair_disfluency_detection.html">301 acl-2011-The impact of language models and loss functions on repair disfluency detection</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.158), (1, 0.147), (2, 0.089), (3, -0.065), (4, 0.044), (5, 0.075), (6, 0.03), (7, 0.006), (8, -0.007), (9, -0.047), (10, 0.064), (11, -0.029), (12, -0.107), (13, 0.02), (14, -0.029), (15, -0.022), (16, 0.021), (17, -0.049), (18, 0.014), (19, -0.063), (20, 0.011), (21, 0.111), (22, -0.028), (23, 0.01), (24, 0.048), (25, -0.017), (26, 0.18), (27, -0.015), (28, -0.036), (29, 0.164), (30, 0.304), (31, 0.019), (32, -0.097), (33, 0.082), (34, 0.061), (35, 0.019), (36, -0.006), (37, 0.084), (38, 0.012), (39, -0.185), (40, -0.087), (41, 0.091), (42, 0.004), (43, -0.018), (44, -0.04), (45, 0.003), (46, -0.012), (47, 0.001), (48, 0.036), (49, -0.049)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95799387 <a title="131-lsi-1" href="./acl-2011-Extracting_Opinion_Expressions_and_Their_Polarities_-_Exploration_of_Pipelines_and_Joint_Models.html">131 acl-2011-Extracting Opinion Expressions and Their Polarities - Exploration of Pipelines and Joint Models</a></p>
<p>Author: Richard Johansson ; Alessandro Moschitti</p><p>Abstract: We investigate systems that identify opinion expressions and assigns polarities to the extracted expressions. In particular, we demonstrate the benefit of integrating opinion extraction and polarity classification into a joint model using features reflecting the global polarity structure. The model is trained using large-margin structured prediction methods. The system is evaluated on the MPQA opinion corpus, where we compare it to the only previously published end-to-end system for opinion expression extraction and polarity classification. The results show an improvement of between 10 and 15 absolute points in F-measure.</p><p>2 0.90030885 <a title="131-lsi-2" href="./acl-2011-Liars_and_Saviors_in_a_Sentiment_Annotated_Corpus_of_Comments_to_Political_Debates.html">211 acl-2011-Liars and Saviors in a Sentiment Annotated Corpus of Comments to Political Debates</a></p>
<p>Author: Paula Carvalho ; Luis Sarmento ; Jorge Teixeira ; Mario J. Silva</p><p>Abstract: We investigate the expression of opinions about human entities in user-generated content (UGC). A set of 2,800 online news comments (8,000 sentences) was manually annotated, following a rich annotation scheme designed for this purpose. We conclude that the challenge in performing opinion mining in such type of content is correctly identifying the positive opinions, because (i) they are much less frequent than negative opinions and (ii) they are particularly exposed to verbal irony. We also show that the recognition of human targets poses additional challenges on mining opinions from UGC, since they are frequently mentioned by pronouns, definite descriptions and nicknames. 1</p><p>3 0.89567643 <a title="131-lsi-3" href="./acl-2011-Identifying_Noun_Product_Features_that_Imply_Opinions.html">159 acl-2011-Identifying Noun Product Features that Imply Opinions</a></p>
<p>Author: Lei Zhang ; Bing Liu</p><p>Abstract: Identifying domain-dependent opinion words is a key problem in opinion mining and has been studied by several researchers. However, existing work has been focused on adjectives and to some extent verbs. Limited work has been done on nouns and noun phrases. In our work, we used the feature-based opinion mining model, and we found that in some domains nouns and noun phrases that indicate product features may also imply opinions. In many such cases, these nouns are not subjective but objective. Their involved sentences are also objective sentences and imply positive or negative opinions. Identifying such nouns and noun phrases and their polarities is very challenging but critical for effective opinion mining in these domains. To the best of our knowledge, this problem has not been studied in the literature. This paper proposes a method to deal with the problem. Experimental results based on real-life datasets show promising results. 1</p><p>4 0.79151493 <a title="131-lsi-4" href="./acl-2011-Finding_Deceptive_Opinion_Spam_by_Any_Stretch_of_the_Imagination.html">136 acl-2011-Finding Deceptive Opinion Spam by Any Stretch of the Imagination</a></p>
<p>Author: Myle Ott ; Yejin Choi ; Claire Cardie ; Jeffrey T. Hancock</p><p>Abstract: Consumers increasingly rate, review and research products online (Jansen, 2010; Litvin et al., 2008). Consequently, websites containing consumer reviews are becoming targets of opinion spam. While recent work has focused primarily on manually identifiable instances of opinion spam, in this work we study deceptive opinion spam—fictitious opinions that have been deliberately written to sound authentic. Integrating work from psychology and computational linguistics, we develop and compare three approaches to detecting deceptive opinion spam, and ultimately develop a classifier that is nearly 90% accurate on our gold-standard opinion spam dataset. Based on feature analysis of our learned models, we additionally make several theoretical contributions, including revealing a relationship between deceptive opinions and imaginative writing.</p><p>5 0.58653915 <a title="131-lsi-5" href="./acl-2011-Aspect_Ranking%3A_Identifying_Important_Product_Aspects_from_Online_Consumer_Reviews.html">45 acl-2011-Aspect Ranking: Identifying Important Product Aspects from Online Consumer Reviews</a></p>
<p>Author: Jianxing Yu ; Zheng-Jun Zha ; Meng Wang ; Tat-Seng Chua</p><p>Abstract: In this paper, we dedicate to the topic of aspect ranking, which aims to automatically identify important product aspects from online consumer reviews. The important aspects are identified according to two observations: (a) the important aspects of a product are usually commented by a large number of consumers; and (b) consumers’ opinions on the important aspects greatly influence their overall opinions on the product. In particular, given consumer reviews of a product, we first identify the product aspects by a shallow dependency parser and determine consumers’ opinions on these aspects via a sentiment classifier. We then develop an aspect ranking algorithm to identify the important aspects by simultaneously considering the aspect frequency and the influence of consumers’ opinions given to each aspect on their overall opinions. The experimental results on 11 popular products in four domains demonstrate the effectiveness of our approach. We further apply the aspect ranking results to the application ofdocumentlevel sentiment classification, and improve the performance significantly.</p><p>6 0.49954417 <a title="131-lsi-6" href="./acl-2011-Identifying_the_Semantic_Orientation_of_Foreign_Words.html">162 acl-2011-Identifying the Semantic Orientation of Foreign Words</a></p>
<p>7 0.47953337 <a title="131-lsi-7" href="./acl-2011-Contrasting_Opposing_Views_of_News_Articles_on_Contentious_Issues.html">84 acl-2011-Contrasting Opposing Views of News Articles on Contentious Issues</a></p>
<p>8 0.47829556 <a title="131-lsi-8" href="./acl-2011-A_Pilot_Study_of_Opinion_Summarization_in_Conversations.html">21 acl-2011-A Pilot Study of Opinion Summarization in Conversations</a></p>
<p>9 0.46675265 <a title="131-lsi-9" href="./acl-2011-Subjective_Natural_Language_Problems%3A_Motivations%2C_Applications%2C_Characterizations%2C_and_Implications.html">288 acl-2011-Subjective Natural Language Problems: Motivations, Applications, Characterizations, and Implications</a></p>
<p>10 0.43478328 <a title="131-lsi-10" href="./acl-2011-That%27s_What_She_Said%3A_Double_Entendre_Identification.html">297 acl-2011-That's What She Said: Double Entendre Identification</a></p>
<p>11 0.42697084 <a title="131-lsi-11" href="./acl-2011-Language_Use%3A_What_can_it_tell_us%3F.html">194 acl-2011-Language Use: What can it tell us?</a></p>
<p>12 0.39371261 <a title="131-lsi-12" href="./acl-2011-Subjectivity_and_Sentiment_Analysis_of_Modern_Standard_Arabic.html">289 acl-2011-Subjectivity and Sentiment Analysis of Modern Standard Arabic</a></p>
<p>13 0.37767494 <a title="131-lsi-13" href="./acl-2011-Sentiment_Analysis_of_Citations_using_Sentence_Structure-Based_Features.html">281 acl-2011-Sentiment Analysis of Citations using Sentence Structure-Based Features</a></p>
<p>14 0.34383023 <a title="131-lsi-14" href="./acl-2011-Model-Portability_Experiments_for_Textual_Temporal_Analysis.html">222 acl-2011-Model-Portability Experiments for Textual Temporal Analysis</a></p>
<p>15 0.34101811 <a title="131-lsi-15" href="./acl-2011-Extracting_Comparative_Entities_and_Predicates_from_Texts_Using_Comparative_Type_Classification.html">130 acl-2011-Extracting Comparative Entities and Predicates from Texts Using Comparative Type Classification</a></p>
<p>16 0.33731779 <a title="131-lsi-16" href="./acl-2011-Semantic_Representation_of_Negation_Using_Focus_Detection.html">273 acl-2011-Semantic Representation of Negation Using Focus Detection</a></p>
<p>17 0.30971849 <a title="131-lsi-17" href="./acl-2011-Automatically_Predicting_Peer-Review_Helpfulness.html">55 acl-2011-Automatically Predicting Peer-Review Helpfulness</a></p>
<p>18 0.30963904 <a title="131-lsi-18" href="./acl-2011-The_impact_of_language_models_and_loss_functions_on_repair_disfluency_detection.html">301 acl-2011-The impact of language models and loss functions on repair disfluency detection</a></p>
<p>19 0.30651915 <a title="131-lsi-19" href="./acl-2011-Semi-Supervised_Frame-Semantic_Parsing_for_Unknown_Predicates.html">274 acl-2011-Semi-Supervised Frame-Semantic Parsing for Unknown Predicates</a></p>
<p>20 0.30607739 <a title="131-lsi-20" href="./acl-2011-French_TimeBank%3A_An_ISO-TimeML_Annotated_Reference_Corpus.html">138 acl-2011-French TimeBank: An ISO-TimeML Annotated Reference Corpus</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.04), (9, 0.016), (11, 0.011), (17, 0.037), (26, 0.015), (31, 0.019), (37, 0.122), (39, 0.044), (41, 0.057), (53, 0.047), (55, 0.024), (59, 0.072), (69, 0.216), (72, 0.036), (91, 0.025), (96, 0.123), (97, 0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.7804814 <a title="131-lda-1" href="./acl-2011-Extracting_Opinion_Expressions_and_Their_Polarities_-_Exploration_of_Pipelines_and_Joint_Models.html">131 acl-2011-Extracting Opinion Expressions and Their Polarities - Exploration of Pipelines and Joint Models</a></p>
<p>Author: Richard Johansson ; Alessandro Moschitti</p><p>Abstract: We investigate systems that identify opinion expressions and assigns polarities to the extracted expressions. In particular, we demonstrate the benefit of integrating opinion extraction and polarity classification into a joint model using features reflecting the global polarity structure. The model is trained using large-margin structured prediction methods. The system is evaluated on the MPQA opinion corpus, where we compare it to the only previously published end-to-end system for opinion expression extraction and polarity classification. The results show an improvement of between 10 and 15 absolute points in F-measure.</p><p>2 0.6668303 <a title="131-lda-2" href="./acl-2011-Improving_Arabic_Dependency_Parsing_with_Form-based_and_Functional_Morphological_Features.html">164 acl-2011-Improving Arabic Dependency Parsing with Form-based and Functional Morphological Features</a></p>
<p>Author: Yuval Marton ; Nizar Habash ; Owen Rambow</p><p>Abstract: We explore the contribution of morphological features both lexical and inflectional to dependency parsing of Arabic, a morphologically rich language. Using controlled experiments, we find that definiteness, person, number, gender, and the undiacritzed lemma are most helpful for parsing on automatically tagged input. We further contrast the contribution of form-based and functional features, and show that functional gender and number (e.g., “broken plurals”) and the related rationality feature improve over form-based features. It is the first time functional morphological features are used for Arabic NLP. – –</p><p>3 0.66384238 <a title="131-lda-3" href="./acl-2011-Subjectivity_and_Sentiment_Analysis_of_Modern_Standard_Arabic.html">289 acl-2011-Subjectivity and Sentiment Analysis of Modern Standard Arabic</a></p>
<p>Author: Muhammad Abdul-Mageed ; Mona Diab ; Mohammed Korayem</p><p>Abstract: Although Subjectivity and Sentiment Analysis (SSA) has been witnessing a flurry of novel research, there are few attempts to build SSA systems for Morphologically-Rich Languages (MRL). In the current study, we report efforts to partially fill this gap. We present a newly developed manually annotated corpus ofModern Standard Arabic (MSA) together with a new polarity lexicon.The corpus is a collection of newswire documents annotated on the sentence level. We also describe an automatic SSA tagging system that exploits the annotated data. We investigate the impact of different levels ofpreprocessing settings on the SSA classification task. We show that by explicitly accounting for the rich morphology the system is able to achieve significantly higher levels of performance.</p><p>4 0.66321397 <a title="131-lda-4" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>Author: Joel Lang ; Mirella Lapata</p><p>Abstract: In this paper we describe an unsupervised method for semantic role induction which holds promise for relieving the data acquisition bottleneck associated with supervised role labelers. We present an algorithm that iteratively splits and merges clusters representing semantic roles, thereby leading from an initial clustering to a final clustering of better quality. The method is simple, surprisingly effective, and allows to integrate linguistic knowledge transparently. By combining role induction with a rule-based component for argument identification we obtain an unsupervised end-to-end semantic role labeling system. Evaluation on the CoNLL 2008 benchmark dataset demonstrates that our method outperforms competitive unsupervised approaches by a wide margin.</p><p>5 0.66286981 <a title="131-lda-5" href="./acl-2011-Target-dependent_Twitter_Sentiment_Classification.html">292 acl-2011-Target-dependent Twitter Sentiment Classification</a></p>
<p>Author: Long Jiang ; Mo Yu ; Ming Zhou ; Xiaohua Liu ; Tiejun Zhao</p><p>Abstract: Sentiment analysis on Twitter data has attracted much attention recently. In this paper, we focus on target-dependent Twitter sentiment classification; namely, given a query, we classify the sentiments of the tweets as positive, negative or neutral according to whether they contain positive, negative or neutral sentiments about that query. Here the query serves as the target of the sentiments. The state-ofthe-art approaches for solving this problem always adopt the target-independent strategy, which may assign irrelevant sentiments to the given target. Moreover, the state-of-the-art approaches only take the tweet to be classified into consideration when classifying the sentiment; they ignore its context (i.e., related tweets). However, because tweets are usually short and more ambiguous, sometimes it is not enough to consider only the current tweet for sentiment classification. In this paper, we propose to improve target-dependent Twitter sentiment classification by 1) incorporating target-dependent features; and 2) taking related tweets into consideration. According to the experimental results, our approach greatly improves the performance of target-dependent sentiment classification. 1</p><p>6 0.66252965 <a title="131-lda-6" href="./acl-2011-Exploring_Entity_Relations_for_Named_Entity_Disambiguation.html">128 acl-2011-Exploring Entity Relations for Named Entity Disambiguation</a></p>
<p>7 0.66016483 <a title="131-lda-7" href="./acl-2011-Semi-supervised_Relation_Extraction_with_Large-scale_Word_Clustering.html">277 acl-2011-Semi-supervised Relation Extraction with Large-scale Word Clustering</a></p>
<p>8 0.6592679 <a title="131-lda-8" href="./acl-2011-Exploiting_Syntactico-Semantic_Structures_for_Relation_Extraction.html">126 acl-2011-Exploiting Syntactico-Semantic Structures for Relation Extraction</a></p>
<p>9 0.65700519 <a title="131-lda-9" href="./acl-2011-Joint_Bilingual_Sentiment_Classification_with_Unlabeled_Parallel_Corpora.html">183 acl-2011-Joint Bilingual Sentiment Classification with Unlabeled Parallel Corpora</a></p>
<p>10 0.65666431 <a title="131-lda-10" href="./acl-2011-Semi-Supervised_Frame-Semantic_Parsing_for_Unknown_Predicates.html">274 acl-2011-Semi-Supervised Frame-Semantic Parsing for Unknown Predicates</a></p>
<p>11 0.65665621 <a title="131-lda-11" href="./acl-2011-In-domain_Relation_Discovery_with_Meta-constraints_via_Posterior_Regularization.html">170 acl-2011-In-domain Relation Discovery with Meta-constraints via Posterior Regularization</a></p>
<p>12 0.65603083 <a title="131-lda-12" href="./acl-2011-Coreference_Resolution_with_World_Knowledge.html">85 acl-2011-Coreference Resolution with World Knowledge</a></p>
<p>13 0.65584791 <a title="131-lda-13" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<p>14 0.6545189 <a title="131-lda-14" href="./acl-2011-Chinese_sentence_segmentation_as_comma_classification.html">66 acl-2011-Chinese sentence segmentation as comma classification</a></p>
<p>15 0.65204716 <a title="131-lda-15" href="./acl-2011-A_Bayesian_Model_for_Unsupervised_Semantic_Parsing.html">3 acl-2011-A Bayesian Model for Unsupervised Semantic Parsing</a></p>
<p>16 0.65202743 <a title="131-lda-16" href="./acl-2011-Unsupervised_Part-of-Speech_Tagging_with_Bilingual_Graph-Based_Projections.html">323 acl-2011-Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</a></p>
<p>17 0.65198553 <a title="131-lda-17" href="./acl-2011-Knowledge-Based_Weak_Supervision_for_Information_Extraction_of_Overlapping_Relations.html">190 acl-2011-Knowledge-Based Weak Supervision for Information Extraction of Overlapping Relations</a></p>
<p>18 0.65139562 <a title="131-lda-18" href="./acl-2011-Translationese_and_Its_Dialects.html">311 acl-2011-Translationese and Its Dialects</a></p>
<p>19 0.65046549 <a title="131-lda-19" href="./acl-2011-Effects_of_Noun_Phrase_Bracketing_in_Dependency_Parsing_and_Machine_Translation.html">111 acl-2011-Effects of Noun Phrase Bracketing in Dependency Parsing and Machine Translation</a></p>
<p>20 0.65031737 <a title="131-lda-20" href="./acl-2011-Collective_Classification_of_Congressional_Floor-Debate_Transcripts.html">73 acl-2011-Collective Classification of Congressional Floor-Debate Transcripts</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
