<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>255 acl-2011-Query Snowball: A Co-occurrence-based Approach to Multi-document Summarization for Question Answering</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-255" href="#">acl2011-255</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>255 acl-2011-Query Snowball: A Co-occurrence-based Approach to Multi-document Summarization for Question Answering</h1>
<br/><p>Source: <a title="acl-2011-255-pdf" href="http://aclweb.org/anthology//P/P11/P11-2039.pdf">pdf</a></p><p>Author: Hajime Morita ; Tetsuya Sakai ; Manabu Okumura</p><p>Abstract: We propose a new method for query-oriented extractive multi-document summarization. To enrich the information need representation of a given query, we build a co-occurrence graph to obtain words that augment the original query terms. We then formulate the summarization problem as a Maximum Coverage Problem with Knapsack Constraints based on word pairs rather than single words. Our experiments with the NTCIR ACLIA question answering test collections show that our method achieves a pyramid F3-score of up to 0.3 13, a 36% improvement over a baseline using Maximal Marginal Relevance. 1</p><p>Reference: <a title="acl-2011-255-reference" href="../acl2011_reference/acl-2011-Query_Snowball%3A_A_Co-occurrence-based_Approach_to_Multi-document_Summarization_for_Question_Answering_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 org, r  oku @pi Abstract We propose a new method for query-oriented extractive multi-document summarization. [sent-7, score-0.055]
</p><p>2 To enrich the information need representation of a given query, we build a co-occurrence graph to obtain words that augment the original query terms. [sent-8, score-0.287]
</p><p>3 We then formulate the summarization problem as a Maximum Coverage Problem with Knapsack Constraints based on word pairs rather than single words. [sent-9, score-0.226]
</p><p>4 Our experiments with the NTCIR ACLIA question answering test collections show that our method achieves a pyramid F3-score of up to 0. [sent-10, score-0.239]
</p><p>5 1  Introduction  Automatic text summarization aims at reducing the amount of text the user has to read while preserving important contents, and has many applications in this age of digital information overload (Mani, 2001). [sent-12, score-0.196]
</p><p>6 In particular, query-oriented multi-document summarization is useful for helping the user satisfy his information need efficiently by gathering important pieces of information from multiple documents. [sent-13, score-0.236]
</p><p>7 In this study, we focus on extractive summarization (Liu and Liu, 2009), in particular, on sentence selection from a given set of source documents that contain relevant sentences. [sent-14, score-0.308]
</p><p>8 One well-known challenge in selecting sentences relevant to the information need is the vocabulary mismatch between the query (i. [sent-15, score-0.198]
</p><p>9 Hence, to enrich the information need representation, we build a co-occurrence 223 . [sent-18, score-0.054]
</p><p>10 jp graph to obtain words that augment the original query terms. [sent-21, score-0.233]
</p><p>11 Another challenge in sentence selection for query-oriented multi-document summarization is  how to avoid redundancy so that diverse pieces of information (i. [sent-23, score-0.282]
</p><p>12 For penalizing redundancy across sentences, using single words as the basic unit may not always be appropriate, because different nuggets for a given information need often have many words in common. [sent-26, score-0.206]
</p><p>13 Figure 1 shows an example of this word overlap problem from the NTCIR-8 ACLIA2 Japanese question answering test collection. [sent-27, score-0.126]
</p><p>14 Here, two gold-standard nuggets for the question “Sen to Chihiro no Kamikakushi (Spirited Away) is a fulllength animated movie from Japan. [sent-28, score-0.336]
</p><p>15 Each nugget represents a particular award that the movie received, and the two Japanese nugget strings have as many as three words in common: “批評 (review/critic)”, “ア ニ メ (animation)” and (award). [sent-31, score-0.382]
</p><p>16 ” Thus, if we use single words as the basis for penalising redundancy in sentence selection, it would be difficult to cover both of these nuggets in the summary because of the word overlaps. [sent-32, score-0.262]
</p><p>17 We therefore use word pairs as the basic unit for computing sentence scores, and then formulate the summarization problem as a Maximum Cover Problem with Knapsack Constraints (MCKP) (Filatova  “賞  and Hatzivassiloglou, 2004; Takamura and Okumura, 2009a). [sent-33, score-0.226]
</p><p>18 This problem is an optimization problem that maximizes the total score of words covered by a summary under a summary length limit. [sent-34, score-0.158]
</p><p>19 i ac t2io0n11 fo Ar Cssoocmiaptuiotanti foonra Clo Lminpguutiastti ocns:aslh Loirntpgaupisetricss, pages 223–229, •  •  •  Question SQeune to oCnhihiro no Kamikakushi (Spirited Away) is a full-length animated movie from Japan. [sent-37, score-0.115]
</p><p>20 2  Related Work  Much work has been done for generic multidocument summarization (Takamura and Okumura, 2009a; Takamura and Okumura, 2009b; Celikyilmaz and Hakkani-Tur, 2010; Lin et al. [sent-43, score-0.249]
</p><p>21 Carbonell and Goldstein (1998) proposed the Maximal Marginal Relevance (MMR) criteria for non-redundant sentence selection, which consist of document similarity and redundancy penalty. [sent-45, score-0.081]
</p><p>22 (2007) formulated the document summarization problem as an MCKP, and proposed a supervised method. [sent-48, score-0.264]
</p><p>23 Filatova and Hatzivassiloglou (2004) also formulated summarization as an MCKP, and they used two types of concepts in documents: single words and events (named entity pairs with a verb or a noun). [sent-50, score-0.229]
</p><p>24 MMR-based methods are also popular for queryoriented summarization (Jagarlamudi et al. [sent-52, score-0.196]
</p><p>25 Moreover, graph-based methods for summarization and sentence retrieval are popular (Otterbacher et al. [sent-57, score-0.196]
</p><p>26 Unlike existing graph-based methods, our method explicitly computes indirect relationships between the query and words in the documents to enrich the information need representation. [sent-59, score-0.339]
</p><p>27 (2005) is similar to our proposed method in that it uses word co-occurrence and dependencies within sentences in order to measure relevance of words to the query. [sent-62, score-0.133]
</p><p>28 1 introduces the Query Snowball (QSB) method which computes the query relevance score for each word. [sent-65, score-0.407]
</p><p>29 2 describes how we formulate the summarization problem based on word pairs. [sent-67, score-0.226]
</p><p>30 1 Query Snowball method (QSB) The basic idea behind QSB is to close the gap between the query (i. [sent-69, score-0.198]
</p><p>31 To this end, QSB computes a query relevance score for each word in the source documents as described below. [sent-72, score-0.464]
</p><p>32 Here, Q is the set of query terms (each represented by q), R1 is the set of words (r1) that co-occur with a query term in the same sentence, and R2 is the set of words (r2) that co-occur with a word from R1, excluding those that are already in R1. [sent-74, score-0.396]
</p><p>33 The imaginary root node at the center represents the information need,  and we assume that the need is propagated through this graph, where edges represent within-sentence co-occurrences. [sent-75, score-0.053]
</p><p>34 Thus, to compute sentence scores, we use not only the query terms but also the words in R1 and R2. [sent-76, score-0.198]
</p><p>35 Our first clue for computing a word score is the query-independent importance of the word. [sent-77, score-0.046]
</p><p>36 We represent this base word score by sb(w) = log(N/ctf (w)) or sb(w) = log(N/n(w)), where ctf (w) is the total number of occurrences of w within the corpus and n(w) is the document frequency of w, and N is the total number of documents in the corpus. [sent-78, score-0.174]
</p><p>37 We will refer to these two versions as itf and idf, respectively. [sent-79, score-0.037]
</p><p>38 Our second clue  is the weight propagated from the center of the cooccurence graph shown in Figure 1. [sent-80, score-0.053]
</p><p>39 As Figure 2 suggests, the query relevance score for r1 ∈ R1 is computed based not only on its base wfoorr rd1 score 1 b iust caolmsop on tdhe b relationship y b oetnw itesen b rs1e and q ∈ Q. [sent-82, score-0.459]
</p><p>40 Then, the query relevance score for r1can be computed as:  sr(r1) =q∑∈Qsb(r1)(ssubm(qQ)) (distanfrceeq((qq,,rr11)) + 1. [sent-85, score-0.377]
</p><p>41 It can be observed that the query releva∑nceq∈ score sr(r1) reflects the base word scores of ∑both q and r1, as well as the cooccurrence frequency freq(q, r1). [sent-87, score-0.322]
</p><p>42 Moreover, sr(r1)  depends on distance(q, r1), the minimum dependency distance between q and r1, which reflects the strength of relationship between q and r1. [sent-88, score-0.183]
</p><p>43 225 Similarly, the query relevance score for r2 ∈ R2 is computed b thasee qdu on yth reel bevaasen cweo srcdo score o rf2 2r 2∈ a Rnd2 the relationship between r2 and r1 ∈ R1:  sr(r2) =∑sb(r2)(ssurm(rR11)) (distanfrceeq((rr11,,rr22)) + 1. [sent-93, score-0.423]
</p><p>44 2 Score Max∑imization Using Word Pairs Having determined the query relevance score, the next step is to define the summary score. [sent-96, score-0.387]
</p><p>45 This is because word pairs are more informative for discriminating across different pieces of information than single common words. [sent-98, score-0.04]
</p><p>46 (Recall the example mentioned in Section 1) Thus, the word pair score is simply defined as: sp(w1 , w2) =  sr (w1)sr (w2) and the summary score is computed as: fQSBP(S) sp(w1,w2) (3) {w1 ,w2 |w1=w2 an∑d ∑w1 ,w2 ∈u and u∈S}  = ∑  where u is a textual unit, which in our case is a sentence. [sent-99, score-0.244]
</p><p>47 02-20 5 Table 1: ACLIA dataset statistics We evaluate our method using Japanese QA test collections from NTCIR-7 ACLIA1 and NTCIR8 ACLIA2 (Mitamura et al. [sent-112, score-0.06]
</p><p>48 The collections contain complex questions and their answer nuggets with weights. [sent-115, score-0.264]
</p><p>49 As our aim is to answer complex questions by means of multidocument summarization, we removed factoid questions from the ACLIA2 test data. [sent-119, score-0.141]
</p><p>50 Although the ACLIA test collections were originally designed for Japanese QA evaluation, we treat them as query-oriented summarization test collections. [sent-120, score-0.256]
</p><p>51 We use all the candidate documents from which nuggets were extracted as input to the multidocument summarizers. [sent-121, score-0.27]
</p><p>52 That is, in our problem setting, the relevant documents are already given, although the given document sets also occasionally contain documents that were eventually never used for nugget extraction (Mitamura et al. [sent-122, score-0.301]
</p><p>53 We preprocessed the Japanese documents basi-  cally by automatically detecting sentence boundaries based on Japanese punctuation marks, but we also used regular-expression-based heuristics to detect glossary of terms in articles. [sent-125, score-0.057]
</p><p>54 As the descriptions of these glossaries are usually very useful for answering BIOGRAPHY and DEFINITION questions, we treated each term description (generally multiple sentences) as a single sentence. [sent-126, score-0.065]
</p><p>55 , 2004) for morphological analysis, and calculated base word scores sb(w) using Mainichi articles from 1991 to 2005. [sent-128, score-0.036]
</p><p>56 We also used Mecab to convert each word to its base form and to filter using POS tags to extract content words. [sent-129, score-0.036]
</p><p>57 As for dependency parsing for distance computation, we used Cabocha (Kudo and Matsumoto, 2000). [sent-130, score-0.106]
</p><p>58 Following the NTCIR-9 one click access task setting1 , we aimed at generating summaries of Japanese 500 characters or less. [sent-132, score-0.033]
</p><p>59 To evaluate the summaries, we followed the practices at the TAC summarization tasks (Dang, 2008) and NTCIR ACLIA tasks, and computed pyramid-based preci-  sion with an allowance parameter of C, recall, Fβ (where β is 1 or 3) scores. [sent-133, score-0.196]
</p><p>60 The value of C was determined based on the average nugget length for each question type of the ACLIA2 collection (Mitamura et al. [sent-134, score-0.213]
</p><p>61 Precision and recall are computed based on the nuggets that the summary covered as well as their weights. [sent-136, score-0.216]
</p><p>62 The first author of this paper manually evaluated whether each nugget matches a summary. [sent-137, score-0.152]
</p><p>63 For example, at the TAC 2008 opinion summarization track, a top performer in terms of pyramid F score used an MMR-based method. [sent-140, score-0.355]
</p><p>64 aspx Thus, the first term of this function reflects how the sentences reflect the entire documents; the second term reflects the relevance of the sentences to the query; and finally the function penalizes redundant sentences. [sent-145, score-0.217]
</p><p>65 3 Variants of the Proposed Method To clarify the contributions of each components, the minimum dependency distance, QSB and the word  pair, we also evaluated the following simplified versions of QSBP. [sent-151, score-0.078]
</p><p>66 (We use the itf version by default, and will refer to the idf version as QSBP(idf). [sent-152, score-0.14]
</p><p>67 ) To examine the contribution of using minimum dependency distance, We remove distance(w, w0) from Eq. [sent-153, score-0.078]
</p><p>68 To examine the contribution of using word pairs for score maximization (see Section 3. [sent-157, score-0.046]
</p><p>69 (5) {w |w∈ui∑ ∑and ui ∈S} To examine the contribution of the QSB relevance scoring (see Section 3. [sent-160, score-0.207]
</p><p>70 (6) {w1 ,w2 |w1=w2 and∑ ∑w1 ,w2 ∈ui and ui ∈S} We will refer to this as WP. [sent-163, score-0.074]
</p><p>71 Note that this relies only on base word scores and is query-independent. [sent-164, score-0.036]
</p><p>72 Thus, the minimum dependency distance, Query Snowball and the use of word 227 pairs all contribute significantly to the performance of QSBP. [sent-183, score-0.078]
</p><p>73 Note that we are using the ACLIA data as summarization test collections and that the official QA results of ACLIA should not be compared with ours. [sent-184, score-0.256]
</p><p>74 Table 3 shows the F3 scores for each question type. [sent-188, score-0.061]
</p><p>75 It can be observed that QSBP is the top performer for BIO, DEF and REL questions on average, while QSBP(idf) is the top performer for EVENT and WHY questions on average. [sent-189, score-0.208]
</p><p>76 It is possible that different word scoring methods work well for different question types. [sent-190, score-0.061]
</p><p>77 161  Table 3: F3-scores for each question type (ACLIA2 test) 5  Conclusions and Future work  We proposed the Query Snowball (QSB) method for query-oriented multi-document summarization. [sent-309, score-0.061]
</p><p>78 To enrich the information need representation of a given query, QSB obtains words that augment the original query terms from a co-occurrence graph. [sent-310, score-0.287]
</p><p>79 We then formulated the summarization problem as an MCKP based on word pairs rather than single words. [sent-311, score-0.229]
</p><p>80 Our method, QSBP, achieves a pyramid F3-score of up to 0. [sent-312, score-0.053]
</p><p>81 Also, we plan to extend our approach to abstractive summarization. [sent-315, score-0.036]
</p><p>82 The use of mmr, diversity-based reranking for reordering documents and producing summaries. [sent-323, score-0.057]
</p><p>83 Overview of the tac 2008 opin-  ion question answering and summarization tasks. [sent-333, score-0.378]
</p><p>84 Japanese dependency structure analysis based on support vector machines. [sent-355, score-0.043]
</p><p>85 Putting the user in the loop: interactive maximal marginal relevance for query-focused summarization. [sent-381, score-0.226]
</p><p>86 From extractive to abstractive meeting summaries: can it be done by sentence compression? [sent-386, score-0.091]
</p><p>87 Text summarization model based on maximum coverage problem and its variant. [sent-423, score-0.196]
</p><p>88 Text summarization model based on the budgeted median problem. [sent-428, score-0.261]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('qsbp', 0.541), ('qsb', 0.282), ('aclia', 0.221), ('mitamura', 0.221), ('query', 0.198), ('summarization', 0.196), ('nuggets', 0.16), ('nugget', 0.152), ('relevance', 0.133), ('japanese', 0.123), ('nodist', 0.123), ('idf', 0.103), ('mckp', 0.098), ('snowball', 0.098), ('sr', 0.096), ('mmr', 0.095), ('takamura', 0.095), ('sb', 0.092), ('ntcir', 0.085), ('animated', 0.08), ('ui', 0.074), ('umax', 0.074), ('okumura', 0.066), ('manabu', 0.066), ('budgeted', 0.065), ('answering', 0.065), ('distance', 0.063), ('question', 0.061), ('collections', 0.06), ('submodular', 0.06), ('performer', 0.06), ('lin', 0.059), ('documents', 0.057), ('kudo', 0.056), ('tac', 0.056), ('summary', 0.056), ('extractive', 0.055), ('sim', 0.055), ('enrich', 0.054), ('filatova', 0.053), ('propagated', 0.053), ('pyramid', 0.053), ('multidocument', 0.053), ('tetsuya', 0.051), ('distanfrceeq', 0.049), ('fqsbp', 0.049), ('itech', 0.049), ('kamikakushi', 0.049), ('ruihua', 0.049), ('shima', 0.049), ('spirited', 0.049), ('tatsunori', 0.049), ('varadarajan', 0.049), ('jagarlamudi', 0.049), ('maximal', 0.049), ('bilmes', 0.047), ('redundancy', 0.046), ('score', 0.046), ('qa', 0.045), ('questions', 0.044), ('marginal', 0.044), ('tokyo', 0.043), ('award', 0.043), ('dependency', 0.043), ('khuller', 0.043), ('knapsack', 0.043), ('sakai', 0.043), ('otterbacher', 0.043), ('mecab', 0.043), ('teruko', 0.043), ('lund', 0.043), ('wp', 0.042), ('reflects', 0.042), ('pieces', 0.04), ('mori', 0.04), ('itf', 0.037), ('gg', 0.037), ('base', 0.036), ('abstractive', 0.036), ('noriko', 0.036), ('minimum', 0.035), ('document', 0.035), ('movie', 0.035), ('augment', 0.035), ('hiroya', 0.034), ('hasegawa', 0.034), ('freq', 0.034), ('summaries', 0.033), ('celikyilmaz', 0.033), ('hui', 0.033), ('film', 0.033), ('formulated', 0.033), ('yih', 0.032), ('trec', 0.032), ('taku', 0.031), ('formulate', 0.03), ('computes', 0.03), ('jeff', 0.03), ('carbonell', 0.029), ('hideki', 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="255-tfidf-1" href="./acl-2011-Query_Snowball%3A_A_Co-occurrence-based_Approach_to_Multi-document_Summarization_for_Question_Answering.html">255 acl-2011-Query Snowball: A Co-occurrence-based Approach to Multi-document Summarization for Question Answering</a></p>
<p>Author: Hajime Morita ; Tetsuya Sakai ; Manabu Okumura</p><p>Abstract: We propose a new method for query-oriented extractive multi-document summarization. To enrich the information need representation of a given query, we build a co-occurrence graph to obtain words that augment the original query terms. We then formulate the summarization problem as a Maximum Coverage Problem with Knapsack Constraints based on word pairs rather than single words. Our experiments with the NTCIR ACLIA question answering test collections show that our method achieves a pyramid F3-score of up to 0.3 13, a 36% improvement over a baseline using Maximal Marginal Relevance. 1</p><p>2 0.1744159 <a title="255-tfidf-2" href="./acl-2011-A_Class_of_Submodular_Functions_for_Document_Summarization.html">4 acl-2011-A Class of Submodular Functions for Document Summarization</a></p>
<p>Author: Hui Lin ; Jeff Bilmes</p><p>Abstract: We design a class of submodular functions meant for document summarization tasks. These functions each combine two terms, one which encourages the summary to be representative of the corpus, and the other which positively rewards diversity. Critically, our functions are monotone nondecreasing and submodular, which means that an efficient scalable greedy optimization scheme has a constant factor guarantee of optimality. When evaluated on DUC 2004-2007 corpora, we obtain better than existing state-of-art results in both generic and query-focused document summarization. Lastly, we show that several well-established methods for document summarization correspond, in fact, to submodular function optimization, adding further evidence that submodular functions are a natural fit for document summarization.</p><p>3 0.1664646 <a title="255-tfidf-3" href="./acl-2011-A_Pilot_Study_of_Opinion_Summarization_in_Conversations.html">21 acl-2011-A Pilot Study of Opinion Summarization in Conversations</a></p>
<p>Author: Dong Wang ; Yang Liu</p><p>Abstract: This paper presents a pilot study of opinion summarization on conversations. We create a corpus containing extractive and abstractive summaries of speaker’s opinion towards a given topic using 88 telephone conversations. We adopt two methods to perform extractive summarization. The first one is a sentence-ranking method that linearly combines scores measured from different aspects including topic relevance, subjectivity, and sentence importance. The second one is a graph-based method, which incorporates topic and sentiment information, as well as additional information about sentence-to-sentence relations extracted based on dialogue structure. Our evaluation results show that both methods significantly outperform the baseline approach that extracts the longest utterances. In particular, we find that incorporating dialogue structure in the graph-based method contributes to the improved system performance.</p><p>4 0.14755856 <a title="255-tfidf-4" href="./acl-2011-Learning_From_Collective_Human_Behavior_to_Introduce_Diversity_in_Lexical_Choice.html">201 acl-2011-Learning From Collective Human Behavior to Introduce Diversity in Lexical Choice</a></p>
<p>Author: Vahed Qazvinian ; Dragomir R. Radev</p><p>Abstract: We analyze collective discourse, a collective human behavior in content generation, and show that it exhibits diversity, a property of general collective systems. Using extensive analysis, we propose a novel paradigm for designing summary generation systems that reflect the diversity of perspectives seen in reallife collective summarization. We analyze 50 sets of summaries written by human about the same story or artifact and investigate the diversity of perspectives across these summaries. We show how different summaries use various phrasal information units (i.e., nuggets) to express the same atomic semantic units, called factoids. Finally, we present a ranker that employs distributional similarities to build a net- work of words, and captures the diversity of perspectives by detecting communities in this network. Our experiments show how our system outperforms a wide range of other document ranking systems that leverage diversity.</p><p>5 0.13615853 <a title="255-tfidf-5" href="./acl-2011-Query_Weighting_for_Ranking_Model_Adaptation.html">256 acl-2011-Query Weighting for Ranking Model Adaptation</a></p>
<p>Author: Peng Cai ; Wei Gao ; Aoying Zhou ; Kam-Fai Wong</p><p>Abstract: We propose to directly measure the importance of queries in the source domain to the target domain where no rank labels of documents are available, which is referred to as query weighting. Query weighting is a key step in ranking model adaptation. As the learning object of ranking algorithms is divided by query instances, we argue that it’s more reasonable to conduct importance weighting at query level than document level. We present two query weighting schemes. The first compresses the query into a query feature vector, which aggregates all document instances in the same query, and then conducts query weighting based on the query feature vector. This method can efficiently estimate query importance by compressing query data, but the potential risk is information loss resulted from the compression. The second measures the similarity between the source query and each target query, and then combines these fine-grained similarity values for its importance estimation. Adaptation experiments on LETOR3.0 data set demonstrate that query weighting significantly outperforms document instance weighting methods.</p><p>6 0.12689795 <a title="255-tfidf-6" href="./acl-2011-A_Latent_Topic_Extracting_Method_based_on_Events_in_a_Document_and_its_Application.html">18 acl-2011-A Latent Topic Extracting Method based on Events in a Document and its Application</a></p>
<p>7 0.12680632 <a title="255-tfidf-7" href="./acl-2011-Joint_Annotation_of_Search_Queries.html">182 acl-2011-Joint Annotation of Search Queries</a></p>
<p>8 0.12287838 <a title="255-tfidf-8" href="./acl-2011-SciSumm%3A_A_Multi-Document_Summarization_System_for_Scientific_Articles.html">270 acl-2011-SciSumm: A Multi-Document Summarization System for Scientific Articles</a></p>
<p>9 0.10859647 <a title="255-tfidf-9" href="./acl-2011-Fine-Grained_Class_Label_Markup_of_Search_Queries.html">137 acl-2011-Fine-Grained Class Label Markup of Search Queries</a></p>
<p>10 0.10585297 <a title="255-tfidf-10" href="./acl-2011-Improving_Question_Recommendation_by_Exploiting_Information_Need.html">169 acl-2011-Improving Question Recommendation by Exploiting Information Need</a></p>
<p>11 0.10260098 <a title="255-tfidf-11" href="./acl-2011-Jointly_Learning_to_Extract_and_Compress.html">187 acl-2011-Jointly Learning to Extract and Compress</a></p>
<p>12 0.10071792 <a title="255-tfidf-12" href="./acl-2011-Search_in_the_Lost_Sense_of_%22Query%22%3A_Question_Formulation_in_Web_Search_Queries_and_its_Temporal_Changes.html">271 acl-2011-Search in the Lost Sense of "Query": Question Formulation in Web Search Queries and its Temporal Changes</a></p>
<p>13 0.099154197 <a title="255-tfidf-13" href="./acl-2011-Using_Bilingual_Information_for_Cross-Language_Document_Summarization.html">326 acl-2011-Using Bilingual Information for Cross-Language Document Summarization</a></p>
<p>14 0.096468359 <a title="255-tfidf-14" href="./acl-2011-Comparative_News_Summarization_Using_Linear_Programming.html">76 acl-2011-Comparative News Summarization Using Linear Programming</a></p>
<p>15 0.094567642 <a title="255-tfidf-15" href="./acl-2011-Discovery_of_Topically_Coherent_Sentences_for_Extractive_Summarization.html">98 acl-2011-Discovery of Topically Coherent Sentences for Extractive Summarization</a></p>
<p>16 0.091820903 <a title="255-tfidf-16" href="./acl-2011-Automatic_Assessment_of_Coverage_Quality_in_Intelligence_Reports.html">47 acl-2011-Automatic Assessment of Coverage Quality in Intelligence Reports</a></p>
<p>17 0.089511171 <a title="255-tfidf-17" href="./acl-2011-Jigs_and_Lures%3A_Associating_Web_Queries_with_Structured_Entities.html">181 acl-2011-Jigs and Lures: Associating Web Queries with Structured Entities</a></p>
<p>18 0.089208618 <a title="255-tfidf-18" href="./acl-2011-Probabilistic_Document_Modeling_for_Syntax_Removal_in_Text_Summarization.html">251 acl-2011-Probabilistic Document Modeling for Syntax Removal in Text Summarization</a></p>
<p>19 0.08433231 <a title="255-tfidf-19" href="./acl-2011-Ranking_Class_Labels_Using_Query_Sessions.html">258 acl-2011-Ranking Class Labels Using Query Sessions</a></p>
<p>20 0.083788849 <a title="255-tfidf-20" href="./acl-2011-P11-2093_k2opt.pdf.html">238 acl-2011-P11-2093 k2opt.pdf</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.16), (1, 0.08), (2, -0.073), (3, 0.107), (4, -0.104), (5, -0.124), (6, -0.109), (7, 0.032), (8, 0.101), (9, -0.039), (10, 0.017), (11, 0.016), (12, -0.127), (13, -0.022), (14, -0.135), (15, -0.06), (16, 0.072), (17, 0.066), (18, 0.038), (19, 0.05), (20, -0.082), (21, -0.063), (22, 0.054), (23, 0.049), (24, -0.023), (25, -0.033), (26, 0.03), (27, -0.092), (28, 0.038), (29, 0.013), (30, 0.024), (31, -0.062), (32, 0.062), (33, -0.091), (34, -0.01), (35, 0.04), (36, -0.083), (37, -0.027), (38, 0.062), (39, -0.018), (40, -0.071), (41, -0.037), (42, -0.003), (43, -0.007), (44, 0.053), (45, -0.014), (46, -0.001), (47, -0.053), (48, -0.085), (49, -0.063)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92583817 <a title="255-lsi-1" href="./acl-2011-Query_Snowball%3A_A_Co-occurrence-based_Approach_to_Multi-document_Summarization_for_Question_Answering.html">255 acl-2011-Query Snowball: A Co-occurrence-based Approach to Multi-document Summarization for Question Answering</a></p>
<p>Author: Hajime Morita ; Tetsuya Sakai ; Manabu Okumura</p><p>Abstract: We propose a new method for query-oriented extractive multi-document summarization. To enrich the information need representation of a given query, we build a co-occurrence graph to obtain words that augment the original query terms. We then formulate the summarization problem as a Maximum Coverage Problem with Knapsack Constraints based on word pairs rather than single words. Our experiments with the NTCIR ACLIA question answering test collections show that our method achieves a pyramid F3-score of up to 0.3 13, a 36% improvement over a baseline using Maximal Marginal Relevance. 1</p><p>2 0.79048365 <a title="255-lsi-2" href="./acl-2011-A_Class_of_Submodular_Functions_for_Document_Summarization.html">4 acl-2011-A Class of Submodular Functions for Document Summarization</a></p>
<p>Author: Hui Lin ; Jeff Bilmes</p><p>Abstract: We design a class of submodular functions meant for document summarization tasks. These functions each combine two terms, one which encourages the summary to be representative of the corpus, and the other which positively rewards diversity. Critically, our functions are monotone nondecreasing and submodular, which means that an efficient scalable greedy optimization scheme has a constant factor guarantee of optimality. When evaluated on DUC 2004-2007 corpora, we obtain better than existing state-of-art results in both generic and query-focused document summarization. Lastly, we show that several well-established methods for document summarization correspond, in fact, to submodular function optimization, adding further evidence that submodular functions are a natural fit for document summarization.</p><p>3 0.69455248 <a title="255-lsi-3" href="./acl-2011-SciSumm%3A_A_Multi-Document_Summarization_System_for_Scientific_Articles.html">270 acl-2011-SciSumm: A Multi-Document Summarization System for Scientific Articles</a></p>
<p>Author: Nitin Agarwal ; Ravi Shankar Reddy ; Kiran GVR ; Carolyn Penstein Rose</p><p>Abstract: In this demo, we present SciSumm, an interactive multi-document summarization system for scientific articles. The document collection to be summarized is a list of papers cited together within the same source article, otherwise known as a co-citation. At the heart of the approach is a topic based clustering of fragments extracted from each article based on queries generated from the context surrounding the co-cited list of papers. This analysis enables the generation of an overview of common themes from the co-cited papers that relate to the context in which the co-citation was found. SciSumm is currently built over the 2008 ACL Anthology, however the gen- eralizable nature of the summarization techniques and the extensible architecture makes it possible to use the system with other corpora where a citation network is available. Evaluation results on the same corpus demonstrate that our system performs better than an existing widely used multi-document summarization system (MEAD).</p><p>4 0.60671419 <a title="255-lsi-4" href="./acl-2011-Learning_From_Collective_Human_Behavior_to_Introduce_Diversity_in_Lexical_Choice.html">201 acl-2011-Learning From Collective Human Behavior to Introduce Diversity in Lexical Choice</a></p>
<p>Author: Vahed Qazvinian ; Dragomir R. Radev</p><p>Abstract: We analyze collective discourse, a collective human behavior in content generation, and show that it exhibits diversity, a property of general collective systems. Using extensive analysis, we propose a novel paradigm for designing summary generation systems that reflect the diversity of perspectives seen in reallife collective summarization. We analyze 50 sets of summaries written by human about the same story or artifact and investigate the diversity of perspectives across these summaries. We show how different summaries use various phrasal information units (i.e., nuggets) to express the same atomic semantic units, called factoids. Finally, we present a ranker that employs distributional similarities to build a net- work of words, and captures the diversity of perspectives by detecting communities in this network. Our experiments show how our system outperforms a wide range of other document ranking systems that leverage diversity.</p><p>5 0.60570908 <a title="255-lsi-5" href="./acl-2011-Jointly_Learning_to_Extract_and_Compress.html">187 acl-2011-Jointly Learning to Extract and Compress</a></p>
<p>Author: Taylor Berg-Kirkpatrick ; Dan Gillick ; Dan Klein</p><p>Abstract: We learn a joint model of sentence extraction and compression for multi-document summarization. Our model scores candidate summaries according to a combined linear model whose features factor over (1) the n-gram types in the summary and (2) the compressions used. We train the model using a marginbased objective whose loss captures end summary quality. Because of the exponentially large set of candidate summaries, we use a cutting-plane algorithm to incrementally detect and add active constraints efficiently. Inference in our model can be cast as an ILP and thereby solved in reasonable time; we also present a fast approximation scheme which achieves similar performance. Our jointly extracted and compressed summaries outperform both unlearned baselines and our learned extraction-only system on both ROUGE and Pyramid, without a drop in judged linguistic quality. We achieve the highest published ROUGE results to date on the TAC 2008 data set.</p><p>6 0.60507303 <a title="255-lsi-6" href="./acl-2011-A_Pilot_Study_of_Opinion_Summarization_in_Conversations.html">21 acl-2011-A Pilot Study of Opinion Summarization in Conversations</a></p>
<p>7 0.58857226 <a title="255-lsi-7" href="./acl-2011-Towards_a_Framework_for_Abstractive_Summarization_of_Multimodal_Documents.html">308 acl-2011-Towards a Framework for Abstractive Summarization of Multimodal Documents</a></p>
<p>8 0.56589067 <a title="255-lsi-8" href="./acl-2011-Comparative_News_Summarization_Using_Linear_Programming.html">76 acl-2011-Comparative News Summarization Using Linear Programming</a></p>
<p>9 0.54369736 <a title="255-lsi-9" href="./acl-2011-Automatic_Assessment_of_Coverage_Quality_in_Intelligence_Reports.html">47 acl-2011-Automatic Assessment of Coverage Quality in Intelligence Reports</a></p>
<p>10 0.53545696 <a title="255-lsi-10" href="./acl-2011-Using_Bilingual_Information_for_Cross-Language_Document_Summarization.html">326 acl-2011-Using Bilingual Information for Cross-Language Document Summarization</a></p>
<p>11 0.52945668 <a title="255-lsi-11" href="./acl-2011-Query_Weighting_for_Ranking_Model_Adaptation.html">256 acl-2011-Query Weighting for Ranking Model Adaptation</a></p>
<p>12 0.51900887 <a title="255-lsi-12" href="./acl-2011-Probabilistic_Document_Modeling_for_Syntax_Removal_in_Text_Summarization.html">251 acl-2011-Probabilistic Document Modeling for Syntax Removal in Text Summarization</a></p>
<p>13 0.49417624 <a title="255-lsi-13" href="./acl-2011-Search_in_the_Lost_Sense_of_%22Query%22%3A_Question_Formulation_in_Web_Search_Queries_and_its_Temporal_Changes.html">271 acl-2011-Search in the Lost Sense of "Query": Question Formulation in Web Search Queries and its Temporal Changes</a></p>
<p>14 0.49120769 <a title="255-lsi-14" href="./acl-2011-Improving_Question_Recommendation_by_Exploiting_Information_Need.html">169 acl-2011-Improving Question Recommendation by Exploiting Information Need</a></p>
<p>15 0.47562063 <a title="255-lsi-15" href="./acl-2011-IMASS%3A_An_Intelligent_Microblog_Analysis_and_Summarization_System.html">156 acl-2011-IMASS: An Intelligent Microblog Analysis and Summarization System</a></p>
<p>16 0.46767202 <a title="255-lsi-16" href="./acl-2011-Discovery_of_Topically_Coherent_Sentences_for_Extractive_Summarization.html">98 acl-2011-Discovery of Topically Coherent Sentences for Extractive Summarization</a></p>
<p>17 0.46139562 <a title="255-lsi-17" href="./acl-2011-Joint_Annotation_of_Search_Queries.html">182 acl-2011-Joint Annotation of Search Queries</a></p>
<p>18 0.4422999 <a title="255-lsi-18" href="./acl-2011-A_Latent_Topic_Extracting_Method_based_on_Events_in_a_Document_and_its_Application.html">18 acl-2011-A Latent Topic Extracting Method based on Events in a Document and its Application</a></p>
<p>19 0.43536219 <a title="255-lsi-19" href="./acl-2011-A_Simple_Measure_to_Assess_Non-response.html">25 acl-2011-A Simple Measure to Assess Non-response</a></p>
<p>20 0.42474249 <a title="255-lsi-20" href="./acl-2011-Creative_Language_Retrieval%3A_A_Robust_Hybrid_of_Information_Retrieval_and_Linguistic_Creativity.html">89 acl-2011-Creative Language Retrieval: A Robust Hybrid of Information Retrieval and Linguistic Creativity</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.013), (17, 0.041), (26, 0.036), (37, 0.072), (39, 0.036), (41, 0.067), (46, 0.016), (50, 0.015), (53, 0.014), (55, 0.034), (59, 0.023), (72, 0.022), (76, 0.315), (91, 0.028), (96, 0.177), (98, 0.015)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.77312762 <a title="255-lda-1" href="./acl-2011-Optimistic_Backtracking_-_A_Backtracking_Overlay_for_Deterministic_Incremental_Parsing.html">236 acl-2011-Optimistic Backtracking - A Backtracking Overlay for Deterministic Incremental Parsing</a></p>
<p>Author: Gisle Ytrestl</p><p>Abstract: This paper describes a backtracking strategy for an incremental deterministic transitionbased parser for HPSG. The method could theoretically be implemented on any other transition-based parser with some adjustments. In this paper, the algorithm is evaluated on CuteForce, an efficient deterministic shiftreduce HPSG parser. The backtracking strategy may serve to improve existing parsers, or to assess if a deterministic parser would benefit from backtracking as a strategy to improve parsing.</p><p>same-paper 2 0.73504132 <a title="255-lda-2" href="./acl-2011-Query_Snowball%3A_A_Co-occurrence-based_Approach_to_Multi-document_Summarization_for_Question_Answering.html">255 acl-2011-Query Snowball: A Co-occurrence-based Approach to Multi-document Summarization for Question Answering</a></p>
<p>Author: Hajime Morita ; Tetsuya Sakai ; Manabu Okumura</p><p>Abstract: We propose a new method for query-oriented extractive multi-document summarization. To enrich the information need representation of a given query, we build a co-occurrence graph to obtain words that augment the original query terms. We then formulate the summarization problem as a Maximum Coverage Problem with Knapsack Constraints based on word pairs rather than single words. Our experiments with the NTCIR ACLIA question answering test collections show that our method achieves a pyramid F3-score of up to 0.3 13, a 36% improvement over a baseline using Maximal Marginal Relevance. 1</p><p>3 0.66391098 <a title="255-lda-3" href="./acl-2011-Integrating_history-length_interpolation_and_classes_in_language_modeling.html">175 acl-2011-Integrating history-length interpolation and classes in language modeling</a></p>
<p>Author: Hinrich Schutze</p><p>Abstract: Building on earlier work that integrates different factors in language modeling, we view (i) backing off to a shorter history and (ii) class-based generalization as two complementary mechanisms of using a larger equivalence class for prediction when the default equivalence class is too small for reliable estimation. This view entails that the classes in a language model should be learned from rare events only and should be preferably applied to rare events. We construct such a model and show that both training on rare events and preferable application to rare events improve perplexity when compared to a simple direct interpolation of class-based with standard language models.</p><p>4 0.65468758 <a title="255-lda-4" href="./acl-2011-Improving_Question_Recommendation_by_Exploiting_Information_Need.html">169 acl-2011-Improving Question Recommendation by Exploiting Information Need</a></p>
<p>Author: Shuguang Li ; Suresh Manandhar</p><p>Abstract: In this paper we address the problem of question recommendation from large archives of community question answering data by exploiting the users’ information needs. Our experimental results indicate that questions based on the same or similar information need can provide excellent question recommendation. We show that translation model can be effectively utilized to predict the information need given only the user’s query question. Experiments show that the proposed information need prediction approach can improve the performance of question recommendation.</p><p>5 0.56367588 <a title="255-lda-5" href="./acl-2011-Using_Bilingual_Parallel_Corpora_for_Cross-Lingual_Textual_Entailment.html">327 acl-2011-Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment</a></p>
<p>Author: Yashar Mehdad ; Matteo Negri ; Marcello Federico</p><p>Abstract: This paper explores the use of bilingual parallel corpora as a source of lexical knowledge for cross-lingual textual entailment. We claim that, in spite of the inherent difficulties of the task, phrase tables extracted from parallel data allow to capture both lexical relations between single words, and contextual information useful for inference. We experiment with a phrasal matching method in order to: i) build a system portable across languages, and ii) evaluate the contribution of lexical knowledge in isolation, without interaction with other inference mechanisms. Results achieved on an English-Spanish corpus obtained from the RTE3 dataset support our claim, with an overall accuracy above average scores reported by RTE participants on monolingual data. Finally, we show that using parallel corpora to extract paraphrase tables reveals their potential also in the monolingual setting, improving the results achieved with other sources of lexical knowledge.</p><p>6 0.56317896 <a title="255-lda-6" href="./acl-2011-Fine-Grained_Class_Label_Markup_of_Search_Queries.html">137 acl-2011-Fine-Grained Class Label Markup of Search Queries</a></p>
<p>7 0.56190991 <a title="255-lda-7" href="./acl-2011-Jointly_Learning_to_Extract_and_Compress.html">187 acl-2011-Jointly Learning to Extract and Compress</a></p>
<p>8 0.56182647 <a title="255-lda-8" href="./acl-2011-A_Hierarchical_Pitman-Yor_Process_HMM_for_Unsupervised_Part_of_Speech_Induction.html">15 acl-2011-A Hierarchical Pitman-Yor Process HMM for Unsupervised Part of Speech Induction</a></p>
<p>9 0.56020254 <a title="255-lda-9" href="./acl-2011-Deciphering_Foreign_Language.html">94 acl-2011-Deciphering Foreign Language</a></p>
<p>10 0.56002724 <a title="255-lda-10" href="./acl-2011-Unsupervised_Bilingual_Morpheme_Segmentation_and_Alignment_with_Context-rich_Hidden_Semi-Markov_Models.html">318 acl-2011-Unsupervised Bilingual Morpheme Segmentation and Alignment with Context-rich Hidden Semi-Markov Models</a></p>
<p>11 0.55976641 <a title="255-lda-11" href="./acl-2011-A_Fast_and_Accurate_Method_for_Approximate_String_Search.html">11 acl-2011-A Fast and Accurate Method for Approximate String Search</a></p>
<p>12 0.55852401 <a title="255-lda-12" href="./acl-2011-Language-independent_compound_splitting_with_morphological_operations.html">193 acl-2011-Language-independent compound splitting with morphological operations</a></p>
<p>13 0.55821073 <a title="255-lda-13" href="./acl-2011-Incremental_Syntactic_Language_Models_for_Phrase-based_Translation.html">171 acl-2011-Incremental Syntactic Language Models for Phrase-based Translation</a></p>
<p>14 0.55803168 <a title="255-lda-14" href="./acl-2011-Domain_Adaptation_for_Machine_Translation_by_Mining_Unseen_Words.html">104 acl-2011-Domain Adaptation for Machine Translation by Mining Unseen Words</a></p>
<p>15 0.55766904 <a title="255-lda-15" href="./acl-2011-Learning_to_Win_by_Reading_Manuals_in_a_Monte-Carlo_Framework.html">207 acl-2011-Learning to Win by Reading Manuals in a Monte-Carlo Framework</a></p>
<p>16 0.5574649 <a title="255-lda-16" href="./acl-2011-Identifying_Word_Translations_from_Comparable_Corpora_Using_Latent_Topic_Models.html">161 acl-2011-Identifying Word Translations from Comparable Corpora Using Latent Topic Models</a></p>
<p>17 0.55724835 <a title="255-lda-17" href="./acl-2011-Large-Scale_Cross-Document_Coreference_Using_Distributed_Inference_and_Hierarchical_Models.html">196 acl-2011-Large-Scale Cross-Document Coreference Using Distributed Inference and Hierarchical Models</a></p>
<p>18 0.55689621 <a title="255-lda-18" href="./acl-2011-A_Latent_Topic_Extracting_Method_based_on_Events_in_a_Document_and_its_Application.html">18 acl-2011-A Latent Topic Extracting Method based on Events in a Document and its Application</a></p>
<p>19 0.55682492 <a title="255-lda-19" href="./acl-2011-An_Empirical_Evaluation_of_Data-Driven_Paraphrase_Generation_Techniques.html">37 acl-2011-An Empirical Evaluation of Data-Driven Paraphrase Generation Techniques</a></p>
<p>20 0.55671597 <a title="255-lda-20" href="./acl-2011-Entity_Set_Expansion_using_Topic_information.html">117 acl-2011-Entity Set Expansion using Topic information</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
