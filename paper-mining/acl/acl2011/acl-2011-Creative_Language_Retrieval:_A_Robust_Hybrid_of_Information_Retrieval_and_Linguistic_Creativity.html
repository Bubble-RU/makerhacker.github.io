<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>89 acl-2011-Creative Language Retrieval: A Robust Hybrid of Information Retrieval and Linguistic Creativity</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-89" href="#">acl2011-89</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>89 acl-2011-Creative Language Retrieval: A Robust Hybrid of Information Retrieval and Linguistic Creativity</h1>
<br/><p>Source: <a title="acl-2011-89-pdf" href="http://aclweb.org/anthology//P/P11/P11-1029.pdf">pdf</a></p><p>Author: Tony Veale</p><p>Abstract: Information retrieval (IR) and figurative language processing (FLP) could scarcely be more different in their treatment of language and meaning. IR views language as an open-ended set of mostly stable signs with which texts can be indexed and retrieved, focusing more on a text’s potential relevance than its potential meaning. In contrast, FLP views language as a system of unstable signs that can be used to talk about the world in creative new ways. There is another key difference: IR is practical, scalable and robust, and in daily use by millions of casual users. FLP is neither scalable nor robust, and not yet practical enough to migrate beyond the lab. This paper thus presents a mutually beneficial hybrid of IR and FLP, one that enriches IR with new operators to enable the non-literal retrieval of creative expressions, and which also transplants FLP into a robust, scalable framework in which practical applications of linguistic creativity can be implemented. 1</p><p>Reference: <a title="acl-2011-89-reference" href="../acl2011_reference/acl-2011-Creative_Language_Retrieval%3A_A_Robust_Hybrid_of_Information_Retrieval_and_Linguistic_Creativity_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In contrast, FLP views language as a system of unstable signs that can be used to talk about the world in creative new ways. [sent-6, score-0.443]
</p><p>2 Figurative devices like metaphor can communicate far richer meanings than are evident from a superficial – and perhaps literally nonsensical – reading. [sent-11, score-0.17]
</p><p>3 Though thematically related, each approach to FLP is broadly distinct, giving computational form to different cognitive demands of creative language: thus, some focus on interdomain mappings (e. [sent-19, score-0.502]
</p><p>4 Moreover, such systems tend to be developed in isolation, and are rarely designed to cohere as part of a larger framework of creative reasoning (e. [sent-25, score-0.443]
</p><p>5 IR does not distinguish between creative and conventional uses of language, or between literal and non-literal meanings. [sent-34, score-0.516]
</p><p>6 IR is also remarkably modular: its components are designed to work together interchangeably, from stemmers and indexers to heuristics for query expansion and document ranking. [sent-35, score-0.213]
</p><p>7 This works well in the main, but it means that IR falls flat when the goal of retrieval is not to identify relevant documents but to retrieve new and creative ways of expressing a given idea. [sent-38, score-0.561]
</p><p>8 To retrieve creative language, and to be potentially surprised or inspired by the results, one needs to facilitate a non-literal relationship between queries and the texts that they match. [sent-39, score-0.55]
</p><p>9 If the most robust elements of FLP are used to provide new non-literal query operators for IR, then IR can be used to retrieve potentially new and creative ways of speaking about a topic from a large text collec-  tion. [sent-41, score-0.769]
</p><p>10 In the next section we consider the related work on which the current realization of these ideas is founded, before presenting a specific trio of new semantic query operators in section 3. [sent-43, score-0.275]
</p><p>11 We describe three simple but practical applications of this creative IR paradigm in section 4. [sent-44, score-0.475]
</p><p>12 2  Related Work and Ideas  IR works on the premise that a user can turn an information need into an effective query by anticipating the language that is used to talk about a given topic in a target collection. [sent-47, score-0.16]
</p><p>13 If the collection uses creative language in speaking about a topic, then a query must also contain the seeds of this creative language. [sent-48, score-1.046]
</p><p>14 Veale (2004) introduces the idea of creative information retrieval to explore how an IR system can itself provide a degree of creative anticipation, acting as a mediator between the lit-  279 eral specification of a meaning and the retrieval of creative articulations of this meaning. [sent-49, score-1.455]
</p><p>15 A creative IR system may even anticipate out-ofdictionary words, like chocoholic and sexoholic. [sent-55, score-0.443]
</p><p>16 Conventional IR systems use a range of query expansion techniques to automatically bolster a user’s query with additional keywords or weights, to permit the retrieval of relevant texts it might not otherwise match (e. [sent-56, score-0.436]
</p><p>17 Techniques vary, from the use of stemmers and morphological analysis to the use of thesauri (such as WordNet; see Fellbaum, 1998; Voorhees, 1998) to pad a query with synonyms, to the use of statistical analysis to identify more appropriate context-sensitive associations and near-synonyms (e. [sent-59, score-0.16]
</p><p>18 Crucially,  expansion improves recall at the expense of overall precision, making automatic techniques even more dangerous when the goal is to retrieve results that are creative and relevant. [sent-63, score-0.551]
</p><p>19 Mason (2004) shows how statistical analysis can automatically detect and extract conventional metaphors from corpora, though creative metaphors still remain a tantalizing challenge. [sent-72, score-0.651]
</p><p>20 Veale and Hao (2007) exploit the simile frame “as X as Y” to harvest a great many common similes and their underlying stereotypes from the web (e. [sent-74, score-0.49]
</p><p>21 “as hot as an oven”), while Veale and Hao (2010) show that the pattern “about as X as Y” retrieves an equally large collection of creative (if mostly ironic) comparisons. [sent-76, score-0.492]
</p><p>22 We now build on these results to develop a set of new semantic operators, that use corpus-derived knowledge to support finely controlled non-literal matching and automatic query expansion. [sent-78, score-0.16]
</p><p>23 While conventional IR queries articulate a need for information, creative IR queries articulate a need for expressions to convey the same meaning in a fresh or unusual way. [sent-80, score-0.581]
</p><p>24 A query and a matching phrase can be figuratively construed to have the same meaning if there is a non-literal mapping between the elements of the query and the elements of the phrase. [sent-81, score-0.424]
</p><p>25 In creative IR, this non-literal mapping is facilitated by the query’s explicit use of  semantic wildcards (e. [sent-82, score-0.592]
</p><p>26 The wildcard * is a boon for power-users of the Google search engine, precisely because it allows users to focus on the retrieval of matching phrases rather than relevant documents. [sent-85, score-0.209]
</p><p>27 On a larger scale, Veale and Hao (2007) used the * wildcard to harvest web similes, but reported that harvesting cultural data with wildcards is not a straightforward process. [sent-87, score-0.375]
</p><p>28 By focusing on the phrase level rather than the document level, and by returning phrase sets rather than document sets, creative IR maximizes diversity by finding as many bindings for its wildcards as a text collection will support. [sent-92, score-0.671]
</p><p>29 But we need more flexible and precise wildcards than *. [sent-93, score-0.149]
</p><p>30 X Semantic query expansion replaces a query term X with a set {X, X1, X2, , Xn} where each Xi is related to X by a prescribed lexico-semantic relationship, such as synonymy, hyponymy or meronymy. [sent-97, score-0.373]
</p><p>31 Intuitively, each query term suggests other terms from its semantic neighborhood, yet there are practical limits to this intuition. [sent-101, score-0.192]
</p><p>32 Millions of matches for this pattern can be found in the Google 3-grams (Brants and Franz, 2006), allowing us to build a map of comparable terms by linking the root-forms of X and Y with a similarity score obtained via a WordNet-based measure (e. [sent-112, score-0.166]
</p><p>33 artist matches not just artist, composer and poet, but studio, portfolio and gallery, and many other terms that are semantically dissimilar but prag…  …  …  matically linked to artist. [sent-118, score-0.22]
</p><p>34 X is ranked by similarity to X, query matches can also be ranked by similarity. [sent-120, score-0.326]
</p><p>35 X matches any element of {X, Xi, X2, , Xn} , where each Xi pragmatically reinforces X, and X pragmatically reinforces each Xi. [sent-122, score-0.369]
</p><p>36 Moreover, to maximize recall, we use the Google API (rather than Google ngrams) to harvest suitable bindings for X and Xi from the web. [sent-124, score-0.159]
</p><p>37 Similes exploit familiar stereotypes to describe a less familiar concept, so one can learn a great deal about a culture and its language from the similes that have the most currency (Taylor, 1954). [sent-128, score-0.344]
</p><p>38 The wildcard @X builds on the results of Veale and Hao (2007) to allow creative IR queries to retrieve matches on the basis of cultural expectations. [sent-129, score-0.862]
</p><p>39 This foundation provides a large set of adjectival features (over  2000) for a larger set of nouns (over 4000) denoting stereotypes for which these features are salient. [sent-130, score-0.219]
</p><p>40 If N is a noun, then @N matches any element of the set {A1, A2, An}, where each Ai is an adjective denoting a stereotypical property of N. [sent-131, score-0.329]
</p><p>41 For example, @diamond matches any element of {transparent, immutable, beautiful, tough, expensive, valuable, shiny, bright, lasting, desirable, strong, hard} . [sent-132, score-0.223]
</p><p>42 If A is an adjective, then @ A matches any element of the set {N1, N2, Nn}, where each Ni is a noun denoting a stereotype for which A is a culturally established property. [sent-133, score-0.369]
</p><p>43 For example, @tall matches any element of {giraffe, skyscraper, tree, redwood, tower, sunflower, lighthouse, beanstalk, rocket, supermodel} . [sent-134, score-0.223]
</p><p>44 Stereotypes crystallize in a language as clichés, so one can argue that stereotypes and clichés are little or no use to a creative IR system. [sent-135, score-0.575]
</p><p>45 Yet, as demonstrated in Fishlov (1992), creative language …,  …,  …  …  …,  …,  is replete with stereotypes, not in their guises, but in novel and often incongruous nations. [sent-136, score-0.443]
</p><p>46 The creative value of a stereotype how it is used, as we’ll show later in section  281 clichéd combilies in 4. [sent-137, score-0.589]
</p><p>47 The semantic wildcard ^C matches C and any element of {C1, C2, Cn}, where each Ci is a member of the category named by C. [sent-142, score-0.447]
</p><p>48 ^ C can denote a fixed category in a resource like WordNet or even Wikipedia; thus, ^fruit matches any member of {apple, orange, pear, lemon} and ^animal any member of {dog, cat, mouse, deer, fox}. [sent-143, score-0.278]
</p><p>49 Ad-hoc categories arise in creative IR when the results of a query – or more specifically, the bindings for a query wildcard – are funneled into a new user-defined category. [sent-144, score-1.045]
</p><p>50 For instance, the query “^fruit juice” matches any phrase in a text collection that denotes a named fruit juice, from “lemon …,  …,  …,  juice” to “pawpaw juice”. [sent-145, score-0.392]
</p><p>51 A user can now funnel the bindings for ^fruit in this query into an ad-hoc category juicefruit, to gather together those fruits that are used for their juice. [sent-146, score-0.283]
</p><p>52 Ad-hoc categories allow users of IR to remake a category system in their own image, and create a new vocabulary of categories to serve their own goals and interests, as when “^food pizza” is used to suggest disparate members for the ad-hoc category pizzatopping. [sent-148, score-0.246]
</p><p>53 4 Compound Operators Each wildcard maps a query term onto a set of expansion terms. [sent-152, score-0.359]
</p><p>54 artist, yielding more diversity, more noise, and more creative potential. [sent-171, score-0.443]
</p><p>55 @@ Stereotype-of-a-stereotype: if @X matches any element of {X1, X2, , Xn} then @@X matches any of @X1 ∪ @X2 ∪ ∪ @Xn. [sent-172, score-0.389]
</p><p>56 For instance, @@diamond matches any stereotype that shares a salient property with diamond, and @@sharp matches any salient property of any noun for which sharp is a stereotypical property. [sent-173, score-0.72]
</p><p>57 @ Neighborhood-of-a-stereotype: if @X matches any element of {X1, X2, , Xn} then ? [sent-175, score-0.223]
</p><p>58 @cunning matches any term in the pragmatic neighborhood of a stereotype for cunning, while ? [sent-181, score-0.431]
</p><p>59 @knife matches any property that mutually reinforces any stereotypical property of knife @? [sent-182, score-0.365]
</p><p>60 corpse matches any salient property of any stereotype in the neighborhood of corpse, while @? [sent-187, score-0.54]
</p><p>61 fast matches any stereotype noun with a salient property that is …  …  …  …  …  …  …  …  …  …  …,  …  similar to, and reinforced by, fast. [sent-188, score-0.41]
</p><p>62 ^ Neighborhood-of-a-category: if ^ C matches any of {C, C1, C2, Cn} then ? [sent-190, score-0.166]
</p><p>63 @^ Stereotypes-in-a-category: if ^C matches any of {C, C1, C2, , Cn} then @^C matches any of @C ∪ @C1 ∪ ∪ @Cn. [sent-199, score-0.332]
</p><p>64 …  …  …,  …  …  …,  …  …  …  …  …  …  282 ^ @ Members-of-a-stereotype-category: if @ X matches any element of {X1, X2, , Xn} then ^@X matches any of ^X1 ∪ ^X2 ∪ ∪ ^Xn. [sent-200, score-0.389]
</p><p>65 So ^@strong matches any member of a category (such as warrior) that is stereotypically strong. [sent-201, score-0.244]
</p><p>66 Each creative query is a jumping off point in a space of lexicalized ideas that is implied by a large corpus, with each successive match leading the user deeper into the space. [sent-207, score-0.659]
</p><p>67 By turning matches into queries, a user can perform a creative exploration of the space of phrases and ideas (see Boden, 1994) while purposefully sidestepping the noise of the Google ngrams. [sent-208, score-0.665]
</p><p>68 Suppose a user selects “Catholic king”: the new query “Catholic ? [sent-212, score-0.16]
</p><p>69 In this way, creative IR allows a user to explore the text-supported ramifications of a metaphor like Popes are Kings (e. [sent-216, score-0.581]
</p><p>70 The more wildcards a query contains, the more degrees of freedom it offers to the explorer. [sent-220, score-0.309]
</p><p>71 laboratory” uncovers a plethora of analogies for the relationship between scientists and their labs: matches in the Google 3-grams include “technician ’s workshop”, “artist’ ’s studio”, “chef’s kitchen” and “gardener’ ’s greenhouse”. [sent-223, score-0.166]
</p><p>72 A meaningful metaphor can be constructed for X by framing X with any stereotype to which it is pragmatically comparable, that is, any stereotype in ? [sent-229, score-0.47]
</p><p>73 If ^ PS denotes the ad-hoc set of additional properties that may be inferred for X when a stereotype S is used to convey property P, then ^PS = ? [sent-242, score-0.206]
</p><p>74 The query “^PS X” now finds corpus-attested elements of ^PS that can meaningfully be used to modify X. [sent-244, score-0.212]
</p><p>75 These IR formulations are used by Aristotle, an online metaphor generator, to generate targeted metaphors that highlight a property P in a topic X. [sent-245, score-0.285]
</p><p>76 We respect judges but dislike critics;  we respect heroes but dislike killers; we respect sharpshooters but dislike snipers; and respect rebels but dislike insurgents. [sent-257, score-0.24]
</p><p>77 We then grow these categories to include additional reinforcing elements from their pragmatic neighborhoods, ? [sent-260, score-0.151]
</p><p>78 3 Poetic Similes with The Jigsaw Bard The well-formed phrases of a large corpus can be viewed as the linguistic equivalent of objets trouvés in art: readymade or “found” objects that might take on fresh meanings in a creative context. [sent-283, score-0.475]
</p><p>79 The phrase “robot fish”, for instance, denotes a moreor-less literal object in the context of autonomous robotic submersibles, but can also be used to convey a figurative meaning as part of a creative com-  parison (e. [sent-284, score-0.567]
</p><p>80 Building on Fishlov’s argument, creative IR can be used to turn the readymade phrases of the Google ngrams into vehicles for creative comparison. [sent-288, score-0.953]
</p><p>81 For a topic X and a property P, simple similes of the form “X is as P as S” are easily generated, where S ∈ @P ? [sent-289, score-0.272]
</p><p>82 P @P” will retrieve corpus-attested elaborations of stereotypes in @P to suggest similes of the form “X is as P as P 11 S”, where P 11 ∈ ? [sent-294, score-0.399]
</p><p>83 These similes exhibit elements of what Fishlov dubs poetic similes (PS). [sent-296, score-0.567]
</p><p>84 Complex queries can retrieve more creative combinations, so “@P @P” (e. [sent-298, score-0.55]
</p><p>85 ∩  Blended properties also make for nuanced similes of the form “as P and ? [sent-306, score-0.245]
</p><p>86 While one can be “as rich as a fat king”, something can be “as rich and enticing as a chocolate truffle”, “a chocolate brownie”, “a chocolate fruitcake”, and even “a chocolate king”. [sent-309, score-0.244]
</p><p>87 The Jigsaw Bard is a web application that harnesses the readymades of the Google ngrams to formulate novel similes from existing phrases. [sent-310, score-0.279]
</p><p>88 Nonetheless, ad-hoc categories in creative IR are often populated with the bindings produced by uses of @ and 284 ? [sent-319, score-0.579]
</p><p>89 Almuhareb and Poesio choose 2 14 English nouns from 13 of WordNet’s upper-level semantic categories, and proceed to harvest property values for these concepts from the web using the Hearst-like pattern “a|an|the * C is|was”. [sent-330, score-0.194]
</p><p>90 They also harvest 8934 attribute nouns, such as temperature and color, using the query “the * of the C is|was” . [sent-332, score-0.24]
</p><p>91 However, when @X is used to harvest a further set of attribute nouns for  X, via web queries of the form “the P * of X” (where P ∈ @X), then @ X augmented with this additional set of attributes (like hands for surgeon) produces a larger space of 7, 183 features. [sent-344, score-0.186]
</p><p>92 In any case, the role of adjectives in the applications of section 4 is largely an affective one: if X is a noun, then one must have confidence that the adjectives in @X are consonant with our understanding of X, and if P is a property, that the adjectives in ? [sent-366, score-0.305]
</p><p>93 Well enough to estimate the pleasantness of X from the adjectives in @ X, perhaps? [sent-371, score-0.192]
</p><p>94 We thus estimate the affect of all stereotype nouns for which Whissell also records a score. [sent-374, score-0.2]
</p><p>95 In contrast, estimates based on the pleasantness of adjectives found in corresponding WordNet glosses  show a positive correlation of just 0. [sent-378, score-0.192]
</p><p>96 P to suggest adjectives that evoke an unstated property in a metaphor or simile, or to suggest coherent blends of properties. [sent-385, score-0.328]
</p><p>97 When we estimate the pleasantness of each adjective P in Whissell’s dictionary via the weighted mean of the pleasantness of adjectives in ? [sent-386, score-0.298]
</p><p>98 One can imagine wildcards for matching potential puns, portmanteau words and other novel forms, as well as wildcards for figurative processes like metonymy, synecdoche, hyperbolae and even irony. [sent-401, score-0.383]
</p><p>99 Ultimately, it is hoped that creative IR can serve as a textual bridge between high-level creativity and the low-level creative potentials that are implicit in a large corpus. [sent-402, score-0.951]
</p><p>100 Met* : a method for discriminating metonymy and metaphor by computer. [sent-457, score-0.183]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('creative', 0.443), ('ir', 0.226), ('similes', 0.212), ('flp', 0.21), ('catholic', 0.195), ('almuhareb', 0.18), ('veale', 0.172), ('matches', 0.166), ('query', 0.16), ('wildcards', 0.149), ('wildcard', 0.146), ('stereotype', 0.146), ('metaphor', 0.138), ('stereotypes', 0.132), ('pleasantness', 0.106), ('metaphors', 0.087), ('adjectives', 0.086), ('figurative', 0.085), ('harvest', 0.08), ('poesio', 0.08), ('bindings', 0.079), ('fishlov', 0.079), ('xn', 0.078), ('neighborhood', 0.077), ('aristotle', 0.075), ('fass', 0.075), ('google', 0.071), ('ngrams', 0.067), ('fruit', 0.066), ('simile', 0.066), ('whissell', 0.066), ('creativity', 0.065), ('retrieval', 0.063), ('xi', 0.062), ('fish', 0.061), ('bard', 0.061), ('chocolate', 0.061), ('hanks', 0.061), ('dislike', 0.06), ('epithets', 0.06), ('negphrase', 0.06), ('posphrase', 0.06), ('savant', 0.06), ('property', 0.06), ('cognitive', 0.059), ('operators', 0.059), ('categories', 0.057), ('cold', 0.057), ('element', 0.057), ('wordnet', 0.057), ('ideas', 0.056), ('retrieve', 0.055), ('artist', 0.054), ('nouns', 0.054), ('corpse', 0.053), ('gentner', 0.053), ('jigsaw', 0.053), ('juice', 0.053), ('expansion', 0.053), ('queries', 0.052), ('elements', 0.052), ('hao', 0.051), ('retrieves', 0.049), ('affective', 0.047), ('stereotypical', 0.046), ('poetic', 0.046), ('robot', 0.046), ('barnden', 0.045), ('barsalou', 0.045), ('diamond', 0.045), ('dubs', 0.045), ('juicefruit', 0.045), ('maccormac', 0.045), ('metonymy', 0.045), ('pastpart', 0.045), ('posword', 0.045), ('category', 0.044), ('king', 0.044), ('evoke', 0.044), ('disparate', 0.044), ('pragmatic', 0.042), ('idiom', 0.042), ('boden', 0.04), ('pragmatically', 0.04), ('inf', 0.039), ('voorhees', 0.039), ('literal', 0.039), ('salient', 0.038), ('clich', 0.034), ('neighborhoods', 0.034), ('ps', 0.034), ('ap', 0.034), ('member', 0.034), ('conventional', 0.034), ('adjectival', 0.033), ('concisely', 0.033), ('reinforces', 0.033), ('nuanced', 0.033), ('practical', 0.032), ('meanings', 0.032)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999934 <a title="89-tfidf-1" href="./acl-2011-Creative_Language_Retrieval%3A_A_Robust_Hybrid_of_Information_Retrieval_and_Linguistic_Creativity.html">89 acl-2011-Creative Language Retrieval: A Robust Hybrid of Information Retrieval and Linguistic Creativity</a></p>
<p>Author: Tony Veale</p><p>Abstract: Information retrieval (IR) and figurative language processing (FLP) could scarcely be more different in their treatment of language and meaning. IR views language as an open-ended set of mostly stable signs with which texts can be indexed and retrieved, focusing more on a text’s potential relevance than its potential meaning. In contrast, FLP views language as a system of unstable signs that can be used to talk about the world in creative new ways. There is another key difference: IR is practical, scalable and robust, and in daily use by millions of casual users. FLP is neither scalable nor robust, and not yet practical enough to migrate beyond the lab. This paper thus presents a mutually beneficial hybrid of IR and FLP, one that enriches IR with new operators to enable the non-literal retrieval of creative expressions, and which also transplants FLP into a robust, scalable framework in which practical applications of linguistic creativity can be implemented. 1</p><p>2 0.36664516 <a title="89-tfidf-2" href="./acl-2011-Exploiting_Readymades_in_Linguistic_Creativity%3A_A_System_Demonstration_of_the_Jigsaw_Bard.html">125 acl-2011-Exploiting Readymades in Linguistic Creativity: A System Demonstration of the Jigsaw Bard</a></p>
<p>Author: Tony Veale ; Yanfen Hao</p><p>Abstract: Large lexical resources, such as corpora and databases of Web ngrams, are a rich source of pre-fabricated phrases that can be reused in many different contexts. However, one must be careful in how these resources are used, and noted writers such as George Orwell have argued that the use of canned phrases encourages sloppy thinking and results in poor communication. Nonetheless, while Orwell prized home-made phrases over the readymade variety, there is a vibrant movement in modern art which shifts artistic creation from the production of novel artifacts to the clever reuse of readymades or objets trouvés. We describe here a system that makes creative reuse of the linguistic readymades in the Google ngrams. Our system, the Jigsaw Bard, thus owes more to Marcel Duchamp than to George Orwell. We demonstrate how textual readymades can be identified and harvested on a large scale, and used to drive a modest form of linguistic creativity. 1</p><p>3 0.13165516 <a title="89-tfidf-3" href="./acl-2011-Joint_Annotation_of_Search_Queries.html">182 acl-2011-Joint Annotation of Search Queries</a></p>
<p>Author: Michael Bendersky ; W. Bruce Croft ; David A. Smith</p><p>Abstract: W. Bruce Croft Dept. of Computer Science University of Massachusetts Amherst, MA cro ft @ c s .uma s s .edu David A. Smith Dept. of Computer Science University of Massachusetts Amherst, MA dasmith@ c s .umas s .edu articles or web pages). As previous research shows, these differences severely limit the applicability of Marking up search queries with linguistic annotations such as part-of-speech tags, capitalization, and segmentation, is an impor- tant part of query processing and understanding in information retrieval systems. Due to their brevity and idiosyncratic structure, search queries pose a challenge to existing NLP tools. To address this challenge, we propose a probabilistic approach for performing joint query annotation. First, we derive a robust set of unsupervised independent annotations, using queries and pseudo-relevance feedback. Then, we stack additional classifiers on the independent annotations, and exploit the dependencies between them to further improve the accuracy, even with a very limited amount of available training data. We evaluate our method using a range of queries extracted from a web search log. Experimental results verify the effectiveness of our approach for both short keyword queries, and verbose natural language queries.</p><p>4 0.11657692 <a title="89-tfidf-4" href="./acl-2011-Query_Weighting_for_Ranking_Model_Adaptation.html">256 acl-2011-Query Weighting for Ranking Model Adaptation</a></p>
<p>Author: Peng Cai ; Wei Gao ; Aoying Zhou ; Kam-Fai Wong</p><p>Abstract: We propose to directly measure the importance of queries in the source domain to the target domain where no rank labels of documents are available, which is referred to as query weighting. Query weighting is a key step in ranking model adaptation. As the learning object of ranking algorithms is divided by query instances, we argue that it’s more reasonable to conduct importance weighting at query level than document level. We present two query weighting schemes. The first compresses the query into a query feature vector, which aggregates all document instances in the same query, and then conducts query weighting based on the query feature vector. This method can efficiently estimate query importance by compressing query data, but the potential risk is information loss resulted from the compression. The second measures the similarity between the source query and each target query, and then combines these fine-grained similarity values for its importance estimation. Adaptation experiments on LETOR3.0 data set demonstrate that query weighting significantly outperforms document instance weighting methods.</p><p>5 0.11139664 <a title="89-tfidf-5" href="./acl-2011-Fine-Grained_Class_Label_Markup_of_Search_Queries.html">137 acl-2011-Fine-Grained Class Label Markup of Search Queries</a></p>
<p>Author: Joseph Reisinger ; Marius Pasca</p><p>Abstract: We develop a novel approach to the semantic analysis of short text segments and demonstrate its utility on a large corpus of Web search queries. Extracting meaning from short text segments is difficult as there is little semantic redundancy between terms; hence methods based on shallow semantic analysis may fail to accurately estimate meaning. Furthermore search queries lack explicit syntax often used to determine intent in question answering. In this paper we propose a hybrid model of semantic analysis combining explicit class-label extraction with a latent class PCFG. This class-label correlation (CLC) model admits a robust parallel approximation, allowing it to scale to large amounts of query data. We demonstrate its performance in terms of (1) its predicted label accuracy on polysemous queries and (2) its ability to accurately chunk queries into base constituents.</p><p>6 0.10472496 <a title="89-tfidf-6" href="./acl-2011-Search_in_the_Lost_Sense_of_%22Query%22%3A_Question_Formulation_in_Web_Search_Queries_and_its_Temporal_Changes.html">271 acl-2011-Search in the Lost Sense of "Query": Question Formulation in Web Search Queries and its Temporal Changes</a></p>
<p>7 0.10056322 <a title="89-tfidf-7" href="./acl-2011-Ranking_Class_Labels_Using_Query_Sessions.html">258 acl-2011-Ranking Class Labels Using Query Sessions</a></p>
<p>8 0.084616475 <a title="89-tfidf-8" href="./acl-2011-Jigs_and_Lures%3A_Associating_Web_Queries_with_Structured_Entities.html">181 acl-2011-Jigs and Lures: Associating Web Queries with Structured Entities</a></p>
<p>9 0.061549153 <a title="89-tfidf-9" href="./acl-2011-Web-Scale_Features_for_Full-Scale_Parsing.html">333 acl-2011-Web-Scale Features for Full-Scale Parsing</a></p>
<p>10 0.056791645 <a title="89-tfidf-10" href="./acl-2011-A_Mobile_Touchable_Application_for_Online_Topic_Graph_Extraction_and_Exploration_of_Web_Content.html">19 acl-2011-A Mobile Touchable Application for Online Topic Graph Extraction and Exploration of Web Content</a></p>
<p>11 0.054285593 <a title="89-tfidf-11" href="./acl-2011-Knowledge_Base_Population%3A_Successful_Approaches_and_Challenges.html">191 acl-2011-Knowledge Base Population: Successful Approaches and Challenges</a></p>
<p>12 0.054166358 <a title="89-tfidf-12" href="./acl-2011-Improving_Question_Recommendation_by_Exploiting_Information_Need.html">169 acl-2011-Improving Question Recommendation by Exploiting Information Need</a></p>
<p>13 0.053010583 <a title="89-tfidf-13" href="./acl-2011-Types_of_Common-Sense_Knowledge_Needed_for_Recognizing_Textual_Entailment.html">315 acl-2011-Types of Common-Sense Knowledge Needed for Recognizing Textual Entailment</a></p>
<p>14 0.050822653 <a title="89-tfidf-14" href="./acl-2011-Content_Models_with_Attitude.html">82 acl-2011-Content Models with Attitude</a></p>
<p>15 0.049410135 <a title="89-tfidf-15" href="./acl-2011-Query_Snowball%3A_A_Co-occurrence-based_Approach_to_Multi-document_Summarization_for_Question_Answering.html">255 acl-2011-Query Snowball: A Co-occurrence-based Approach to Multi-document Summarization for Question Answering</a></p>
<p>16 0.049287818 <a title="89-tfidf-16" href="./acl-2011-Piggyback%3A_Using_Search_Engines_for_Robust_Cross-Domain_Named_Entity_Recognition.html">246 acl-2011-Piggyback: Using Search Engines for Robust Cross-Domain Named Entity Recognition</a></p>
<p>17 0.049024533 <a title="89-tfidf-17" href="./acl-2011-Using_Multiple_Sources_to_Construct_a_Sentiment_Sensitive_Thesaurus_for_Cross-Domain_Sentiment_Classification.html">332 acl-2011-Using Multiple Sources to Construct a Sentiment Sensitive Thesaurus for Cross-Domain Sentiment Classification</a></p>
<p>18 0.048388697 <a title="89-tfidf-18" href="./acl-2011-A_Graph_Approach_to_Spelling_Correction_in_Domain-Centric_Search.html">13 acl-2011-A Graph Approach to Spelling Correction in Domain-Centric Search</a></p>
<p>19 0.048001803 <a title="89-tfidf-19" href="./acl-2011-A_Latent_Topic_Extracting_Method_based_on_Events_in_a_Document_and_its_Application.html">18 acl-2011-A Latent Topic Extracting Method based on Events in a Document and its Application</a></p>
<p>20 0.046571232 <a title="89-tfidf-20" href="./acl-2011-Insights_from_Network_Structure_for_Text_Mining.html">174 acl-2011-Insights from Network Structure for Text Mining</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.14), (1, 0.071), (2, -0.056), (3, 0.046), (4, -0.068), (5, -0.124), (6, -0.027), (7, -0.1), (8, 0.074), (9, -0.056), (10, 0.043), (11, -0.024), (12, -0.013), (13, 0.028), (14, 0.008), (15, -0.049), (16, -0.02), (17, 0.015), (18, -0.071), (19, -0.016), (20, 0.044), (21, 0.053), (22, -0.018), (23, -0.002), (24, -0.018), (25, 0.032), (26, 0.025), (27, 0.02), (28, 0.014), (29, -0.042), (30, 0.077), (31, -0.036), (32, 0.015), (33, -0.04), (34, -0.066), (35, 0.023), (36, -0.049), (37, -0.094), (38, 0.066), (39, 0.214), (40, 0.009), (41, -0.124), (42, 0.039), (43, -0.008), (44, 0.058), (45, -0.003), (46, -0.036), (47, 0.024), (48, 0.075), (49, 0.124)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94318497 <a title="89-lsi-1" href="./acl-2011-Creative_Language_Retrieval%3A_A_Robust_Hybrid_of_Information_Retrieval_and_Linguistic_Creativity.html">89 acl-2011-Creative Language Retrieval: A Robust Hybrid of Information Retrieval and Linguistic Creativity</a></p>
<p>Author: Tony Veale</p><p>Abstract: Information retrieval (IR) and figurative language processing (FLP) could scarcely be more different in their treatment of language and meaning. IR views language as an open-ended set of mostly stable signs with which texts can be indexed and retrieved, focusing more on a text’s potential relevance than its potential meaning. In contrast, FLP views language as a system of unstable signs that can be used to talk about the world in creative new ways. There is another key difference: IR is practical, scalable and robust, and in daily use by millions of casual users. FLP is neither scalable nor robust, and not yet practical enough to migrate beyond the lab. This paper thus presents a mutually beneficial hybrid of IR and FLP, one that enriches IR with new operators to enable the non-literal retrieval of creative expressions, and which also transplants FLP into a robust, scalable framework in which practical applications of linguistic creativity can be implemented. 1</p><p>2 0.87138331 <a title="89-lsi-2" href="./acl-2011-Exploiting_Readymades_in_Linguistic_Creativity%3A_A_System_Demonstration_of_the_Jigsaw_Bard.html">125 acl-2011-Exploiting Readymades in Linguistic Creativity: A System Demonstration of the Jigsaw Bard</a></p>
<p>Author: Tony Veale ; Yanfen Hao</p><p>Abstract: Large lexical resources, such as corpora and databases of Web ngrams, are a rich source of pre-fabricated phrases that can be reused in many different contexts. However, one must be careful in how these resources are used, and noted writers such as George Orwell have argued that the use of canned phrases encourages sloppy thinking and results in poor communication. Nonetheless, while Orwell prized home-made phrases over the readymade variety, there is a vibrant movement in modern art which shifts artistic creation from the production of novel artifacts to the clever reuse of readymades or objets trouvés. We describe here a system that makes creative reuse of the linguistic readymades in the Google ngrams. Our system, the Jigsaw Bard, thus owes more to Marcel Duchamp than to George Orwell. We demonstrate how textual readymades can be identified and harvested on a large scale, and used to drive a modest form of linguistic creativity. 1</p><p>3 0.54452085 <a title="89-lsi-3" href="./acl-2011-Search_in_the_Lost_Sense_of_%22Query%22%3A_Question_Formulation_in_Web_Search_Queries_and_its_Temporal_Changes.html">271 acl-2011-Search in the Lost Sense of "Query": Question Formulation in Web Search Queries and its Temporal Changes</a></p>
<p>Author: Bo Pang ; Ravi Kumar</p><p>Abstract: Web search is an information-seeking activity. Often times, this amounts to a user seeking answers to a question. However, queries, which encode user’s information need, are typically not expressed as full-length natural language sentences in particular, as questions. Rather, they consist of one or more text fragments. As humans become more searchengine-savvy, do natural-language questions still have a role to play in web search? Through a systematic, large-scale study, we find to our surprise that as time goes by, web users are more likely to use questions to express their search intent. —</p><p>4 0.50933278 <a title="89-lsi-4" href="./acl-2011-Ranking_Class_Labels_Using_Query_Sessions.html">258 acl-2011-Ranking Class Labels Using Query Sessions</a></p>
<p>Author: Marius Pasca</p><p>Abstract: The role of search queries, as available within query sessions or in isolation from one another, in examined in the context of ranking the class labels (e.g., brazilian cities, business centers, hilly sites) extracted from Web documents for various instances (e.g., rio de janeiro). The co-occurrence of a class label and an instance, in the same query or within the same query session, is used to reinforce the estimated relevance of the class label for the instance. Experiments over evaluation sets of instances associated with Web search queries illustrate the higher quality of the query-based, re-ranked class labels, relative to ranking baselines using documentbased counts.</p><p>5 0.50726336 <a title="89-lsi-5" href="./acl-2011-Jigs_and_Lures%3A_Associating_Web_Queries_with_Structured_Entities.html">181 acl-2011-Jigs and Lures: Associating Web Queries with Structured Entities</a></p>
<p>Author: Patrick Pantel ; Ariel Fuxman</p><p>Abstract: We propose methods for estimating the probability that an entity from an entity database is associated with a web search query. Association is modeled using a query entity click graph, blending general query click logs with vertical query click logs. Smoothing techniques are proposed to address the inherent data sparsity in such graphs, including interpolation using a query synonymy model. A large-scale empirical analysis of the smoothing techniques, over a 2-year click graph collected from a commercial search engine, shows significant reductions in modeling error. The association models are then applied to the task of recommending products to web queries, by annotating queries with products from a large catalog and then mining query- product associations through web search session analysis. Experimental analysis shows that our smoothing techniques improve coverage while keeping precision stable, and overall, that our top-performing model affects 9% of general web queries with 94% precision.</p><p>6 0.50486064 <a title="89-lsi-6" href="./acl-2011-Fine-Grained_Class_Label_Markup_of_Search_Queries.html">137 acl-2011-Fine-Grained Class Label Markup of Search Queries</a></p>
<p>7 0.50259399 <a title="89-lsi-7" href="./acl-2011-Predicting_Clicks_in_a_Vocabulary_Learning_System.html">248 acl-2011-Predicting Clicks in a Vocabulary Learning System</a></p>
<p>8 0.50214952 <a title="89-lsi-8" href="./acl-2011-ConsentCanvas%3A_Automatic_Texturing_for_Improved_Readability_in_End-User_License_Agreements.html">80 acl-2011-ConsentCanvas: Automatic Texturing for Improved Readability in End-User License Agreements</a></p>
<p>9 0.48382199 <a title="89-lsi-9" href="./acl-2011-A_Speech-based_Just-in-Time_Retrieval_System_using_Semantic_Search.html">26 acl-2011-A Speech-based Just-in-Time Retrieval System using Semantic Search</a></p>
<p>10 0.48202333 <a title="89-lsi-10" href="./acl-2011-A_Graph_Approach_to_Spelling_Correction_in_Domain-Centric_Search.html">13 acl-2011-A Graph Approach to Spelling Correction in Domain-Centric Search</a></p>
<p>11 0.46188471 <a title="89-lsi-11" href="./acl-2011-An_Efficient_Indexer_for_Large_N-Gram_Corpora.html">36 acl-2011-An Efficient Indexer for Large N-Gram Corpora</a></p>
<p>12 0.45179853 <a title="89-lsi-12" href="./acl-2011-A_Mobile_Touchable_Application_for_Online_Topic_Graph_Extraction_and_Exploration_of_Web_Content.html">19 acl-2011-A Mobile Touchable Application for Online Topic Graph Extraction and Exploration of Web Content</a></p>
<p>13 0.44589713 <a title="89-lsi-13" href="./acl-2011-Query_Weighting_for_Ranking_Model_Adaptation.html">256 acl-2011-Query Weighting for Ranking Model Adaptation</a></p>
<p>14 0.4333033 <a title="89-lsi-14" href="./acl-2011-SystemT%3A_A_Declarative_Information_Extraction_System.html">291 acl-2011-SystemT: A Declarative Information Extraction System</a></p>
<p>15 0.42747769 <a title="89-lsi-15" href="./acl-2011-Joint_Annotation_of_Search_Queries.html">182 acl-2011-Joint Annotation of Search Queries</a></p>
<p>16 0.423787 <a title="89-lsi-16" href="./acl-2011-Predicting_Relative_Prominence_in_Noun-Noun_Compounds.html">249 acl-2011-Predicting Relative Prominence in Noun-Noun Compounds</a></p>
<p>17 0.40630868 <a title="89-lsi-17" href="./acl-2011-Automatically_Predicting_Peer-Review_Helpfulness.html">55 acl-2011-Automatically Predicting Peer-Review Helpfulness</a></p>
<p>18 0.39738202 <a title="89-lsi-18" href="./acl-2011-Content_Models_with_Attitude.html">82 acl-2011-Content Models with Attitude</a></p>
<p>19 0.3940444 <a title="89-lsi-19" href="./acl-2011-An_Interface_for_Rapid_Natural_Language_Processing_Development_in_UIMA.html">42 acl-2011-An Interface for Rapid Natural Language Processing Development in UIMA</a></p>
<p>20 0.38983133 <a title="89-lsi-20" href="./acl-2011-Piggyback%3A_Using_Search_Engines_for_Robust_Cross-Domain_Named_Entity_Recognition.html">246 acl-2011-Piggyback: Using Search Engines for Robust Cross-Domain Named Entity Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.03), (17, 0.045), (19, 0.094), (26, 0.042), (31, 0.011), (37, 0.061), (39, 0.025), (41, 0.031), (50, 0.319), (55, 0.038), (59, 0.035), (72, 0.029), (91, 0.037), (96, 0.086), (97, 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.76979053 <a title="89-lda-1" href="./acl-2011-Creative_Language_Retrieval%3A_A_Robust_Hybrid_of_Information_Retrieval_and_Linguistic_Creativity.html">89 acl-2011-Creative Language Retrieval: A Robust Hybrid of Information Retrieval and Linguistic Creativity</a></p>
<p>Author: Tony Veale</p><p>Abstract: Information retrieval (IR) and figurative language processing (FLP) could scarcely be more different in their treatment of language and meaning. IR views language as an open-ended set of mostly stable signs with which texts can be indexed and retrieved, focusing more on a text’s potential relevance than its potential meaning. In contrast, FLP views language as a system of unstable signs that can be used to talk about the world in creative new ways. There is another key difference: IR is practical, scalable and robust, and in daily use by millions of casual users. FLP is neither scalable nor robust, and not yet practical enough to migrate beyond the lab. This paper thus presents a mutually beneficial hybrid of IR and FLP, one that enriches IR with new operators to enable the non-literal retrieval of creative expressions, and which also transplants FLP into a robust, scalable framework in which practical applications of linguistic creativity can be implemented. 1</p><p>2 0.56528807 <a title="89-lda-2" href="./acl-2011-Simple_Unsupervised_Grammar_Induction_from_Raw_Text_with_Cascaded_Finite_State_Models.html">284 acl-2011-Simple Unsupervised Grammar Induction from Raw Text with Cascaded Finite State Models</a></p>
<p>Author: Elias Ponvert ; Jason Baldridge ; Katrin Erk</p><p>Abstract: We consider a new subproblem of unsupervised parsing from raw text, unsupervised partial parsing—the unsupervised version of text chunking. We show that addressing this task directly, using probabilistic finite-state methods, produces better results than relying on the local predictions of a current best unsupervised parser, Seginer’s (2007) CCL. These finite-state models are combined in a cascade to produce more general (full-sentence) constituent structures; doing so outperforms CCL by a wide margin in unlabeled PARSEVAL scores for English, German and Chinese. Finally, we address the use of phrasal punctuation as a heuristic indicator of phrasal boundaries, both in our system and in CCL.</p><p>3 0.53324884 <a title="89-lda-3" href="./acl-2011-Exploiting_Readymades_in_Linguistic_Creativity%3A_A_System_Demonstration_of_the_Jigsaw_Bard.html">125 acl-2011-Exploiting Readymades in Linguistic Creativity: A System Demonstration of the Jigsaw Bard</a></p>
<p>Author: Tony Veale ; Yanfen Hao</p><p>Abstract: Large lexical resources, such as corpora and databases of Web ngrams, are a rich source of pre-fabricated phrases that can be reused in many different contexts. However, one must be careful in how these resources are used, and noted writers such as George Orwell have argued that the use of canned phrases encourages sloppy thinking and results in poor communication. Nonetheless, while Orwell prized home-made phrases over the readymade variety, there is a vibrant movement in modern art which shifts artistic creation from the production of novel artifacts to the clever reuse of readymades or objets trouvés. We describe here a system that makes creative reuse of the linguistic readymades in the Google ngrams. Our system, the Jigsaw Bard, thus owes more to Marcel Duchamp than to George Orwell. We demonstrate how textual readymades can be identified and harvested on a large scale, and used to drive a modest form of linguistic creativity. 1</p><p>4 0.52211225 <a title="89-lda-4" href="./acl-2011-Jointly_Learning_to_Extract_and_Compress.html">187 acl-2011-Jointly Learning to Extract and Compress</a></p>
<p>Author: Taylor Berg-Kirkpatrick ; Dan Gillick ; Dan Klein</p><p>Abstract: We learn a joint model of sentence extraction and compression for multi-document summarization. Our model scores candidate summaries according to a combined linear model whose features factor over (1) the n-gram types in the summary and (2) the compressions used. We train the model using a marginbased objective whose loss captures end summary quality. Because of the exponentially large set of candidate summaries, we use a cutting-plane algorithm to incrementally detect and add active constraints efficiently. Inference in our model can be cast as an ILP and thereby solved in reasonable time; we also present a fast approximation scheme which achieves similar performance. Our jointly extracted and compressed summaries outperform both unlearned baselines and our learned extraction-only system on both ROUGE and Pyramid, without a drop in judged linguistic quality. We achieve the highest published ROUGE results to date on the TAC 2008 data set.</p><p>5 0.45077401 <a title="89-lda-5" href="./acl-2011-A_Class_of_Submodular_Functions_for_Document_Summarization.html">4 acl-2011-A Class of Submodular Functions for Document Summarization</a></p>
<p>Author: Hui Lin ; Jeff Bilmes</p><p>Abstract: We design a class of submodular functions meant for document summarization tasks. These functions each combine two terms, one which encourages the summary to be representative of the corpus, and the other which positively rewards diversity. Critically, our functions are monotone nondecreasing and submodular, which means that an efficient scalable greedy optimization scheme has a constant factor guarantee of optimality. When evaluated on DUC 2004-2007 corpora, we obtain better than existing state-of-art results in both generic and query-focused document summarization. Lastly, we show that several well-established methods for document summarization correspond, in fact, to submodular function optimization, adding further evidence that submodular functions are a natural fit for document summarization.</p><p>6 0.42434552 <a title="89-lda-6" href="./acl-2011-Improving_Arabic_Dependency_Parsing_with_Form-based_and_Functional_Morphological_Features.html">164 acl-2011-Improving Arabic Dependency Parsing with Form-based and Functional Morphological Features</a></p>
<p>7 0.4117893 <a title="89-lda-7" href="./acl-2011-Learning_Condensed_Feature_Representations_from_Large_Unsupervised_Data_Sets_for_Supervised_Learning.html">199 acl-2011-Learning Condensed Feature Representations from Large Unsupervised Data Sets for Supervised Learning</a></p>
<p>8 0.41110277 <a title="89-lda-8" href="./acl-2011-Good_Seed_Makes_a_Good_Crop%3A_Accelerating_Active_Learning_Using_Language_Modeling.html">145 acl-2011-Good Seed Makes a Good Crop: Accelerating Active Learning Using Language Modeling</a></p>
<p>9 0.38145903 <a title="89-lda-9" href="./acl-2011-Translationese_and_Its_Dialects.html">311 acl-2011-Translationese and Its Dialects</a></p>
<p>10 0.37950301 <a title="89-lda-10" href="./acl-2011-Algorithm_Selection_and_Model_Adaptation_for_ESL_Correction_Tasks.html">32 acl-2011-Algorithm Selection and Model Adaptation for ESL Correction Tasks</a></p>
<p>11 0.37928677 <a title="89-lda-11" href="./acl-2011-An_Efficient_Indexer_for_Large_N-Gram_Corpora.html">36 acl-2011-An Efficient Indexer for Large N-Gram Corpora</a></p>
<p>12 0.37846059 <a title="89-lda-12" href="./acl-2011-Exact_Decoding_of_Syntactic_Translation_Models_through_Lagrangian_Relaxation.html">123 acl-2011-Exact Decoding of Syntactic Translation Models through Lagrangian Relaxation</a></p>
<p>13 0.37792838 <a title="89-lda-13" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<p>14 0.3777476 <a title="89-lda-14" href="./acl-2011-Evaluating_the_Impact_of_Coder_Errors_on_Active_Learning.html">119 acl-2011-Evaluating the Impact of Coder Errors on Active Learning</a></p>
<p>15 0.37685856 <a title="89-lda-15" href="./acl-2011-Extracting_Social_Power_Relationships_from_Natural_Language.html">133 acl-2011-Extracting Social Power Relationships from Natural Language</a></p>
<p>16 0.37645668 <a title="89-lda-16" href="./acl-2011-In-domain_Relation_Discovery_with_Meta-constraints_via_Posterior_Regularization.html">170 acl-2011-In-domain Relation Discovery with Meta-constraints via Posterior Regularization</a></p>
<p>17 0.37625083 <a title="89-lda-17" href="./acl-2011-An_exponential_translation_model_for_target_language_morphology.html">44 acl-2011-An exponential translation model for target language morphology</a></p>
<p>18 0.3759703 <a title="89-lda-18" href="./acl-2011-Using_Bilingual_Parallel_Corpora_for_Cross-Lingual_Textual_Entailment.html">327 acl-2011-Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment</a></p>
<p>19 0.37592691 <a title="89-lda-19" href="./acl-2011-Fine-Grained_Class_Label_Markup_of_Search_Queries.html">137 acl-2011-Fine-Grained Class Label Markup of Search Queries</a></p>
<p>20 0.37590632 <a title="89-lda-20" href="./acl-2011-Piggyback%3A_Using_Search_Engines_for_Robust_Cross-Domain_Named_Entity_Recognition.html">246 acl-2011-Piggyback: Using Search Engines for Robust Cross-Domain Named Entity Recognition</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
