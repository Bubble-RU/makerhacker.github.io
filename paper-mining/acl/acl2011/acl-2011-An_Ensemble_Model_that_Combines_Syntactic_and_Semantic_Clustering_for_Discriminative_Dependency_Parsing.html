<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>39 acl-2011-An Ensemble Model that Combines Syntactic and Semantic Clustering for Discriminative Dependency Parsing</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-39" href="#">acl2011-39</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>39 acl-2011-An Ensemble Model that Combines Syntactic and Semantic Clustering for Discriminative Dependency Parsing</h1>
<br/><p>Source: <a title="acl-2011-39-pdf" href="http://aclweb.org/anthology//P/P11/P11-2125.pdf">pdf</a></p><p>Author: Gholamreza Haffari ; Marzieh Razavi ; Anoop Sarkar</p><p>Abstract: We combine multiple word representations based on semantic clusters extracted from the (Brown et al., 1992) algorithm and syntactic clusters obtained from the Berkeley parser (Petrov et al., 2006) in order to improve discriminative dependency parsing in the MSTParser framework (McDonald et al., 2005). We also provide an ensemble method for combining diverse cluster-based models. The two contributions together significantly improves unlabeled dependency accuracy from 90.82% to 92. 13%.</p><p>Reference: <a title="acl-2011-39-reference" href="../acl2011_reference/acl-2011-An_Ensemble_Model_that_Combines_Syntactic_and_Semantic_Clustering_for_Discriminative_Dependency_Parsing_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu Abstract We combine multiple word representations based on semantic clusters extracted from the (Brown et al. [sent-2, score-0.349]
</p><p>2 , 1992) algorithm and syntactic clusters obtained from the Berkeley parser (Petrov et al. [sent-3, score-0.3]
</p><p>3 , 2006) in order to improve discriminative dependency parsing in the MSTParser framework (McDonald et al. [sent-4, score-0.533]
</p><p>4 We also provide an ensemble method for combining diverse cluster-based models. [sent-6, score-0.539]
</p><p>5 The two contributions together significantly improves unlabeled dependency accuracy from 90. [sent-7, score-0.363]
</p><p>6 1 Introduction A simple  method  for using  unlabeled  data in  discriminative dependency parsing was provided in (Koo et al. [sent-10, score-0.588]
</p><p>7 , 2008) which involved clustering the labeled and unlabeled data and then each word in the dependency treebank was assigned a cluster identifier. [sent-11, score-0.682]
</p><p>8 These identifiers were used to augment the feature representation of the edge-factored or secondorder features, and this extended feature set was used to discriminatively train a dependency parser. [sent-12, score-0.426]
</p><p>9 The use of clusters leads to the question of how to integrate various types of clusters (possibly from different clustering algorithms) in discriminative dependency parsing. [sent-13, score-0.854]
</p><p>10 , 1992) clustering algorithm are typically viewed as “semantic”, e. [sent-15, score-0.138]
</p><p>11 one cluster might contain plan, letter, request, memo, . [sent-17, score-0.161]
</p><p>12 Another clustering view that is more “syntactic” in nature comes from the use of statesplitting in PCFGs. [sent-24, score-0.174]
</p><p>13 For instance, we could extract a syntactic cluster loss, time, profit, earnings, performance, rating, . [sent-25, score-0.217]
</p><p>14 : all head words of noun phrases corresponding to cluster of direct objects of 710 Marzieh Razavi and Anoop Sarkar School of Computing Science  Simon Fraser University Vancouver, Canada {mra z avi anoop} @ c s . [sent-28, score-0.276]
</p><p>15 In this paper, we obtain syntactic clusters from the Berkeley parser (Petrov et al. [sent-31, score-0.3]
</p><p>16 This paper makes two contributions: 1) We combine together multiple word representations based on semantic and syntactic clusters in order to improve discriminative dependency parsing in the MSTParser framework (McDonald et al. [sent-33, score-0.938]
</p><p>17 , 2005), and 2) We provide an ensemble method for combining diverse clustering algorithms that is the discriminative parsing analog to the generative product of experts model for parsing described in (Petrov, 2010). [sent-34, score-1.262]
</p><p>18 These two contributions combined significantly improves unlabeled dependency accuracy: 90. [sent-35, score-0.363]
</p><p>19 2 Dependency Parsing A dependency tree represents the syntactic structure of a sentence with a directed graph (Figure 1), where nodes correspond to the words, and arcs indicate  head-modifier pairs (Mel’ ˇcuk, 1987). [sent-39, score-0.464]
</p><p>20 Graph-based dependency parsing searches for the highest-scoring tree according to apart-factored scoring function. [sent-40, score-0.506]
</p><p>21 In the first-order parsing models, the parts are individual head-modifier arcs in the dependency tree (McDonald et al. [sent-41, score-0.635]
</p><p>22 In the higher-order models, the parts consist of arcs together with some context, e. [sent-43, score-0.081]
</p><p>23 the parent or the sister arcs (McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010). [sent-45, score-0.143]
</p><p>24 The above arg max search for non-projective dependency parsing is accomProceedings ofP thoer t4l9atnhd A, Onrnuegaoln M,e Jeuntineg 19 o-f2 t4h,e 2 A0s1s1o. [sent-47, score-0.454]
</p><p>25 NmT1ah0PSre1k-92fti5sr  row under the words are the split POS tags (Syn-Low), the second row are the split bracketing tags (Syn-High), and the third row is the first 4 bits (to save space in this figure) of the (Brown et al. [sent-50, score-0.442]
</p><p>26 plished using minimum spanning tree algorithms (West, 2001) or approximate inference algorithms (Smith and Eisner, 2008; Koo et al. [sent-52, score-0.16]
</p><p>27 The model parameters are trained using a discriminative learning algorithm, e. [sent-55, score-0.079]
</p><p>28 averaged perceptron (Collins, 2002) or MIRA (Crammer and Singer, 2003). [sent-57, score-0.033]
</p><p>29 In this paper, we work with both first-order and second-order models, we train the models using MIRA, and we use the (Eisner, 1996) algorithm for inference. [sent-58, score-0.057]
</p><p>30 The baseline features capture information about the lexical items and their part of speech (POS) tags (as defined in (McDonald et al. [sent-59, score-0.091]
</p><p>31 , 2008), we use word cluster identifiers as the source of an additional set of features. [sent-62, score-0.279]
</p><p>32 The clusters inject long distance syntactic or semantic information into the model (in contrast with the use of POS tags in the baseline) and help alleviate the sparse data problem for complex features that include n-grams. [sent-65, score-0.399]
</p><p>33 3 The Ensemble Model  A word can have different syntactic or semantic cluster representations, each of which may lead to a different parsing model. [sent-66, score-0.43]
</p><p>34 We use ensemble learning (Dietterich, 2002) in order to combine a collection of diverse and accurate models into a more powerful model. [sent-67, score-0.672]
</p><p>35 In this paper, we construct the base models based on different syntactic/semantic clusters used in the features in each model. [sent-68, score-0.298]
</p><p>36 Our ensemble parsing model is a linear combination of the base models:  PARSE(s) = argt ∈mTa (xs)XkαkXwk· fk(s,r)  (2)  where αk is the weight of the kth base model, and each base model has its own feature mapping fk (. [sent-69, score-0.991]
</p><p>37 Each expert pars711 ing model in the ensemble contains all of the baseline and the cluster-based feature templates; therefore, the experts have in common (at least) the baseline features. [sent-71, score-0.663]
</p><p>38 The only difference between individual parsing models is the assigned cluster labels, and hence some of the cluster-based features. [sent-72, score-0.445]
</p><p>39 In a future work, we plan to take the union of all of the feature sets and train a joint discriminative parsing model. [sent-73, score-0.258]
</p><p>40 The ensemble approach seems more scal-  able though, since we can incrementally add a large number of clustering algorithms into the ensemble. [sent-74, score-0.721]
</p><p>41 4  Syntactic and Semantic Clustering  In our ensemble model we use three different clustering methods to obtain three types of word representations that can help alleviate sparse data in a dependency parser. [sent-75, score-1.006]
</p><p>42 Our two other clusterings are extracted from the split non-terminals obtained from the PCFG-based Berkeley parser (Petrov et al. [sent-79, score-0.213]
</p><p>43 Split non-terminals from the Berkeley parser output are converted into cluster identifiers in two different ways: 1) the split POS tags for each word are used as an alternate word representation. [sent-81, score-0.488]
</p><p>44 We call this representation Syn-Low, and 2) head percolation rules are used to label each non-terminal in the parse such that each non-terminal has a unique daughter labeled as head. [sent-82, score-0.191]
</p><p>45 Each word is assigned a cluster identifier which is defined as the parent split non-terminal of that word if it is not marked as head,  else if the parent is marked as head we recursively check its parent until we reach the unique split nonterminal that is not marked as head. [sent-83, score-0.612]
</p><p>46 We only use cluster identifiers from the Berkeley parser, rather than dependencies, or any other information. [sent-86, score-0.279]
</p><p>47 First order features  Sec Baseline BrownSyn-LowSyn-High Ensemble  Sec Baseline BrownSyn-LowSyn-High Ensemble  first/second row is the unlabeled-accuracy/unlabeled-completecorrect. [sent-87, score-0.05]
</p><p>48 (b) F-score for each dependency ( NNS-2 5 market s ) ) ) ) ) ) length. [sent-90, score-0.275]
</p><p>49 For the Berkeley parser output shown above, the resulting word representations and dependency tree is shown in Fig. [sent-91, score-0.448]
</p><p>50 If we group all the head-words in the training data that project up to split non-terminal NP-24 then we get a cluster: loss, time, profit, earnings, performance, rating, . [sent-93, score-0.093]
</p><p>51 which are head words  of the noun phrases that appear as direct object of verbs like improve. [sent-96, score-0.079]
</p><p>52 5 Experimental Results The experiments were done on the English Penn Treebank, using standard head-percolation rules (Yamada and Matsumoto, 2003) to convert the phrase structure into dependency trees. [sent-97, score-0.275]
</p><p>53 We split the Treebank into a training set (Sections 2-21), a devel712 opment set (Section 22), and test sets (Sections 0, 1, 23, and 24). [sent-98, score-0.126]
</p><p>54 POS tags for the development and test data were assigned by MXPOST (Ratnaparkhi, 1996), where the tagger was trained on the entire training corpus. [sent-102, score-0.053]
</p><p>55 To generate part of speech tags for the training data, we used 20way jackknifing, i. [sent-103, score-0.053]
</p><p>56 Syntactic State-Splitting The sentence-specific word clusters are derived from the parse trees using Berkeley parser1, which generates phrase-structure  parse trees with split syntactic categories. [sent-107, score-0.6]
</p><p>57 To generate parse trees for development and test data, the parser is trained on the entire training data to learn a PCFG with latent annotations using split-merge operations for 5 iterations. [sent-108, score-0.198]
</p><p>58 To generate parse trees for the training data, we used 20-way jackknifing as with the tagger. [sent-109, score-0.207]
</p><p>59 Word Clusterings from Brown Algorithm The word clusters were derived using Percy Liang’s implementation of the (Brown et al. [sent-110, score-0.181]
</p><p>60 2 cTohnista produces a ohridesra orfch Wicaall clustering over xtth. [sent-113, score-0.138]
</p><p>61 In our experiments we use the clusters obtained in (Koo et al. [sent-115, score-0.181]
</p><p>62 In this table, the baseline (first column) does not use any cluster-based features, the next three models use cluster-based features using different clustering algorithms, and the last column is our ensemble model which is the lin-  ear combination of the three cluster-based models. [sent-118, score-0.759]
</p><p>63 As Table 1 shows, the ensemble model has outperformed the baseline and individual models in almost all cases. [sent-119, score-0.636]
</p><p>64 Among the individual models, the model with Brown semantic clusters clearly outperforms the baseline, but the two models with syntactic clusters perform almost the same as the baseline. [sent-120, score-0.557]
</p><p>65 The ensemble model outperforms all of the individual models and does so very consistently across both first-order and second-order dependency models. [sent-121, score-0.873]
</p><p>66 Error Analysis To better understand the contribution of each model to the ensemble, we take a closer look at the parsing errors for each model and the ensemble. [sent-122, score-0.179]
</p><p>67 For most POS categories, the  Brown cluster model is the best individual model, but for Adjectives it is Syn-High, and for Pronouns it is Syn-Low that is the best. [sent-136, score-0.209]
</p><p>68 But the ensemble always does the best in every grammatical category. [sent-137, score-0.493]
</p><p>69 2(b) shows the F-score of the different models for various dependency lengths, where the length of a dependency from word wi to word wj is equal to |i − j |. [sent-139, score-0.607]
</p><p>70 We see that different models are experts on |diif −fe jre|n. [sent-140, score-0.115]
</p><p>71 t W lengths (Syn-Low on 8, Syn-High on 9), while the ensemble model can always combine their expertise and do better at each length. [sent-141, score-0.675]
</p><p>72 6 Comparison to Related Work Several ensemble models have been proposed for dependency parsing (Sagae and Lavie, 2006; Hall et al. [sent-142, score-1.004]
</p><p>73 Essentially, all of these approaches combine different dependency parsing systems, i. [sent-144, score-0.53]
</p><p>74 Although graph-based models are globally trained and can use exact inference algorithms, their features are defined over a limited history of parsing decisions. [sent-147, score-0.236]
</p><p>75 Since transitionbased parsing models have the opposite characteristics, the idea is to combine these two types of  models to exploit their complementary strengths. [sent-148, score-0.426]
</p><p>76 The base parsing models are either independently trained (Sagae and Lavie, 2006; Hall et al. [sent-149, score-0.296]
</p><p>77 Firstly, we combine various graph-based models, constructed using different syntactic/semantic clusters. [sent-154, score-0.076]
</p><p>78 Secondly, we do exact inference on the shared hypothesis space of the base models. [sent-155, score-0.06]
</p><p>79 This is in contrast to previous work which combine the best parse trees suggested by the individual base-models to generate a final parse tree, i. [sent-156, score-0.335]
</p><p>80 7 Conclusion We presented an ensemble of different dependency parsing models, each model corresponding to a different syntactic/semantic word clustering annotation. [sent-159, score-1.085]
</p><p>81 The ensemble obtains consistent improvements in unlabeled dependency parsing, e. [sent-160, score-0.823]
</p><p>82 Our error analysis has revealed that each syn-  tactic/semantic parsing model is an expert in capturing different dependency lengths, and the ensemble model can always combine their expertise and do better at each dependency length. [sent-166, score-1.393]
</p><p>83 We can incrementally add a large number models using different clustering algorithms, and our preliminary results show increased improvement in accuracy when more models are added into the ensemble. [sent-167, score-0.288]
</p><p>84 We would like to thank Terry Koo for his help with the cluster-based features for dependency parsing and Ryan McDonald for the MSTParser source code which we modified and used for the experiments in this paper. [sent-169, score-0.454]
</p><p>85 Reverse revision and linear tree combination for dependency parsing. [sent-174, score-0.327]
</p><p>86 Experiments with a higher-order pro-  jective dependency parser. [sent-196, score-0.275]
</p><p>87 Discriminative training methods for hidden markov models: theory and experiments with perceptron algorithms. [sent-211, score-0.033]
</p><p>88 Three new probabilistic models for dependency parsing: an exploration. [sent-232, score-0.332]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ensemble', 0.493), ('koo', 0.306), ('dependency', 0.275), ('clusters', 0.181), ('parsing', 0.179), ('mcdonald', 0.179), ('cluster', 0.161), ('clustering', 0.138), ('attardi', 0.124), ('dell', 0.118), ('identifiers', 0.118), ('brown', 0.113), ('orletta', 0.108), ('berkeley', 0.106), ('surdeanu', 0.094), ('split', 0.093), ('nivre', 0.088), ('petrov', 0.085), ('argt', 0.082), ('monash', 0.082), ('arcs', 0.081), ('head', 0.079), ('discriminative', 0.079), ('mstparser', 0.076), ('parse', 0.076), ('combine', 0.076), ('mta', 0.072), ('earnings', 0.072), ('jackknifing', 0.072), ('hall', 0.071), ('sagae', 0.07), ('yamada', 0.063), ('parser', 0.063), ('bllip', 0.062), ('profit', 0.062), ('parent', 0.062), ('base', 0.06), ('trees', 0.059), ('expertise', 0.059), ('experts', 0.058), ('representations', 0.058), ('models', 0.057), ('clusterings', 0.057), ('fk', 0.057), ('sec', 0.057), ('mel', 0.057), ('transitionbased', 0.057), ('syntactic', 0.056), ('crammer', 0.056), ('unlabeled', 0.055), ('pos', 0.055), ('anoop', 0.054), ('algorithms', 0.054), ('treebank', 0.053), ('tags', 0.053), ('tree', 0.052), ('eisner', 0.051), ('row', 0.05), ('individual', 0.048), ('mira', 0.048), ('penn', 0.048), ('lengths', 0.047), ('carreras', 0.046), ('diverse', 0.046), ('np', 0.045), ('xs', 0.044), ('nilsson', 0.042), ('rating', 0.042), ('alleviate', 0.042), ('collins', 0.039), ('lavie', 0.038), ('matsumoto', 0.038), ('canada', 0.038), ('baseline', 0.038), ('expert', 0.036), ('percolation', 0.036), ('analog', 0.036), ('avi', 0.036), ('cuk', 0.036), ('gholamreza', 0.036), ('haffari', 0.036), ('jre', 0.036), ('megyesi', 0.036), ('mra', 0.036), ('nbd', 0.036), ('rgpin', 0.036), ('statesplitting', 0.036), ('incrementally', 0.036), ('semantic', 0.034), ('contributions', 0.033), ('blaheta', 0.033), ('inject', 0.033), ('blended', 0.033), ('dency', 0.033), ('dietterich', 0.033), ('ear', 0.033), ('efe', 0.033), ('opment', 0.033), ('secondorder', 0.033), ('perceptron', 0.033)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="39-tfidf-1" href="./acl-2011-An_Ensemble_Model_that_Combines_Syntactic_and_Semantic_Clustering_for_Discriminative_Dependency_Parsing.html">39 acl-2011-An Ensemble Model that Combines Syntactic and Semantic Clustering for Discriminative Dependency Parsing</a></p>
<p>Author: Gholamreza Haffari ; Marzieh Razavi ; Anoop Sarkar</p><p>Abstract: We combine multiple word representations based on semantic clusters extracted from the (Brown et al., 1992) algorithm and syntactic clusters obtained from the Berkeley parser (Petrov et al., 2006) in order to improve discriminative dependency parsing in the MSTParser framework (McDonald et al., 2005). We also provide an ensemble method for combining diverse cluster-based models. The two contributions together significantly improves unlabeled dependency accuracy from 90.82% to 92. 13%.</p><p>2 0.28950498 <a title="39-tfidf-2" href="./acl-2011-Transition-based_Dependency_Parsing_with_Rich_Non-local_Features.html">309 acl-2011-Transition-based Dependency Parsing with Rich Non-local Features</a></p>
<p>Author: Yue Zhang ; Joakim Nivre</p><p>Abstract: Transition-based dependency parsers generally use heuristic decoding algorithms but can accommodate arbitrarily rich feature representations. In this paper, we show that we can improve the accuracy of such parsers by considering even richer feature sets than those employed in previous systems. In the standard Penn Treebank setup, our novel features improve attachment score form 91.4% to 92.9%, giving the best results so far for transitionbased parsing and rivaling the best results overall. For the Chinese Treebank, they give a signficant improvement of the state of the art. An open source release of our parser is freely available.</p><p>3 0.23020588 <a title="39-tfidf-3" href="./acl-2011-Exploiting_Web-Derived_Selectional_Preference_to_Improve_Statistical_Dependency_Parsing.html">127 acl-2011-Exploiting Web-Derived Selectional Preference to Improve Statistical Dependency Parsing</a></p>
<p>Author: Guangyou Zhou ; Jun Zhao ; Kang Liu ; Li Cai</p><p>Abstract: In this paper, we present a novel approach which incorporates the web-derived selectional preferences to improve statistical dependency parsing. Conventional selectional preference learning methods have usually focused on word-to-class relations, e.g., a verb selects as its subject a given nominal class. This paper extends previous work to wordto-word selectional preferences by using webscale data. Experiments show that web-scale data improves statistical dependency parsing, particularly for long dependency relationships. There is no data like more data, performance improves log-linearly with the number of parameters (unique N-grams). More importantly, when operating on new domains, we show that using web-derived selectional preferences is essential for achieving robust performance.</p><p>4 0.21680763 <a title="39-tfidf-4" href="./acl-2011-Getting_the_Most_out_of_Transition-based_Dependency_Parsing.html">143 acl-2011-Getting the Most out of Transition-based Dependency Parsing</a></p>
<p>Author: Jinho D. Choi ; Martha Palmer</p><p>Abstract: This paper suggests two ways of improving transition-based, non-projective dependency parsing. First, we add a transition to an existing non-projective parsing algorithm, so it can perform either projective or non-projective parsing as needed. Second, we present a bootstrapping technique that narrows down discrepancies between gold-standard and automatic parses used as features. The new addition to the algorithm shows a clear advantage in parsing speed. The bootstrapping technique gives a significant improvement to parsing accuracy, showing near state-of-theart performance with respect to other parsing approaches evaluated on the same data set.</p><p>5 0.21446702 <a title="39-tfidf-5" href="./acl-2011-Improving_Dependency_Parsing_with_Semantic_Classes.html">167 acl-2011-Improving Dependency Parsing with Semantic Classes</a></p>
<p>Author: Eneko Agirre ; Kepa Bengoetxea ; Koldo Gojenola ; Joakim Nivre</p><p>Abstract: This paper presents the introduction of WordNet semantic classes in a dependency parser, obtaining improvements on the full Penn Treebank for the first time. We tried different combinations of some basic semantic classes and word sense disambiguation algorithms. Our experiments show that selecting the adequate combination of semantic features on development data is key for success. Given the basic nature of the semantic classes and word sense disambiguation algorithms used, we think there is ample room for future improvements. 1</p><p>6 0.19600762 <a title="39-tfidf-6" href="./acl-2011-Web-Scale_Features_for_Full-Scale_Parsing.html">333 acl-2011-Web-Scale Features for Full-Scale Parsing</a></p>
<p>7 0.16644499 <a title="39-tfidf-7" href="./acl-2011-Effects_of_Noun_Phrase_Bracketing_in_Dependency_Parsing_and_Machine_Translation.html">111 acl-2011-Effects of Noun Phrase Bracketing in Dependency Parsing and Machine Translation</a></p>
<p>8 0.16203365 <a title="39-tfidf-8" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>9 0.14331788 <a title="39-tfidf-9" href="./acl-2011-Shift-Reduce_CCG_Parsing.html">282 acl-2011-Shift-Reduce CCG Parsing</a></p>
<p>10 0.13835688 <a title="39-tfidf-10" href="./acl-2011-Automatic_Detection_and_Correction_of_Errors_in_Dependency_Treebanks.html">48 acl-2011-Automatic Detection and Correction of Errors in Dependency Treebanks</a></p>
<p>11 0.1310987 <a title="39-tfidf-11" href="./acl-2011-Semi-supervised_Relation_Extraction_with_Large-scale_Word_Clustering.html">277 acl-2011-Semi-supervised Relation Extraction with Large-scale Word Clustering</a></p>
<p>12 0.12853858 <a title="39-tfidf-12" href="./acl-2011-Joint_Training_of_Dependency_Parsing_Filters_through_Latent_Support_Vector_Machines.html">186 acl-2011-Joint Training of Dependency Parsing Filters through Latent Support Vector Machines</a></p>
<p>13 0.12141785 <a title="39-tfidf-13" href="./acl-2011-A_Bayesian_Model_for_Unsupervised_Semantic_Parsing.html">3 acl-2011-A Bayesian Model for Unsupervised Semantic Parsing</a></p>
<p>14 0.11080535 <a title="39-tfidf-14" href="./acl-2011-A_Discriminative_Model_for_Joint_Morphological_Disambiguation_and_Dependency_Parsing.html">10 acl-2011-A Discriminative Model for Joint Morphological Disambiguation and Dependency Parsing</a></p>
<p>15 0.11029235 <a title="39-tfidf-15" href="./acl-2011-A_Word-Class_Approach_to_Labeling_PSCFG_Rules_for_Machine_Translation.html">29 acl-2011-A Word-Class Approach to Labeling PSCFG Rules for Machine Translation</a></p>
<p>16 0.10452716 <a title="39-tfidf-16" href="./acl-2011-Neutralizing_Linguistically_Problematic_Annotations_in_Unsupervised_Dependency_Parsing_Evaluation.html">230 acl-2011-Neutralizing Linguistically Problematic Annotations in Unsupervised Dependency Parsing Evaluation</a></p>
<p>17 0.10432235 <a title="39-tfidf-17" href="./acl-2011-Latent_Semantic_Word_Sense_Induction_and_Disambiguation.html">198 acl-2011-Latent Semantic Word Sense Induction and Disambiguation</a></p>
<p>18 0.10391963 <a title="39-tfidf-18" href="./acl-2011-Joint_Hebrew_Segmentation_and_Parsing_using_a_PCFGLA_Lattice_Parser.html">184 acl-2011-Joint Hebrew Segmentation and Parsing using a PCFGLA Lattice Parser</a></p>
<p>19 0.10386331 <a title="39-tfidf-19" href="./acl-2011-Beam-Width_Prediction_for_Efficient_Context-Free_Parsing.html">58 acl-2011-Beam-Width Prediction for Efficient Context-Free Parsing</a></p>
<p>20 0.10313942 <a title="39-tfidf-20" href="./acl-2011-Partial_Parsing_from_Bitext_Projections.html">243 acl-2011-Partial Parsing from Bitext Projections</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.242), (1, -0.047), (2, -0.109), (3, -0.331), (4, -0.01), (5, -0.066), (6, 0.035), (7, 0.112), (8, 0.087), (9, 0.0), (10, 0.087), (11, 0.019), (12, 0.043), (13, -0.113), (14, -0.022), (15, 0.018), (16, -0.049), (17, 0.019), (18, -0.004), (19, -0.03), (20, -0.112), (21, -0.077), (22, 0.009), (23, -0.013), (24, 0.09), (25, -0.131), (26, 0.05), (27, -0.075), (28, -0.053), (29, -0.039), (30, -0.049), (31, -0.063), (32, -0.024), (33, 0.009), (34, 0.04), (35, -0.015), (36, 0.024), (37, -0.022), (38, 0.003), (39, 0.089), (40, 0.045), (41, 0.007), (42, -0.009), (43, 0.054), (44, 0.035), (45, 0.025), (46, 0.13), (47, -0.022), (48, -0.002), (49, 0.01)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97715831 <a title="39-lsi-1" href="./acl-2011-An_Ensemble_Model_that_Combines_Syntactic_and_Semantic_Clustering_for_Discriminative_Dependency_Parsing.html">39 acl-2011-An Ensemble Model that Combines Syntactic and Semantic Clustering for Discriminative Dependency Parsing</a></p>
<p>Author: Gholamreza Haffari ; Marzieh Razavi ; Anoop Sarkar</p><p>Abstract: We combine multiple word representations based on semantic clusters extracted from the (Brown et al., 1992) algorithm and syntactic clusters obtained from the Berkeley parser (Petrov et al., 2006) in order to improve discriminative dependency parsing in the MSTParser framework (McDonald et al., 2005). We also provide an ensemble method for combining diverse cluster-based models. The two contributions together significantly improves unlabeled dependency accuracy from 90.82% to 92. 13%.</p><p>2 0.88055515 <a title="39-lsi-2" href="./acl-2011-Transition-based_Dependency_Parsing_with_Rich_Non-local_Features.html">309 acl-2011-Transition-based Dependency Parsing with Rich Non-local Features</a></p>
<p>Author: Yue Zhang ; Joakim Nivre</p><p>Abstract: Transition-based dependency parsers generally use heuristic decoding algorithms but can accommodate arbitrarily rich feature representations. In this paper, we show that we can improve the accuracy of such parsers by considering even richer feature sets than those employed in previous systems. In the standard Penn Treebank setup, our novel features improve attachment score form 91.4% to 92.9%, giving the best results so far for transitionbased parsing and rivaling the best results overall. For the Chinese Treebank, they give a signficant improvement of the state of the art. An open source release of our parser is freely available.</p><p>3 0.87915593 <a title="39-lsi-3" href="./acl-2011-Exploiting_Web-Derived_Selectional_Preference_to_Improve_Statistical_Dependency_Parsing.html">127 acl-2011-Exploiting Web-Derived Selectional Preference to Improve Statistical Dependency Parsing</a></p>
<p>Author: Guangyou Zhou ; Jun Zhao ; Kang Liu ; Li Cai</p><p>Abstract: In this paper, we present a novel approach which incorporates the web-derived selectional preferences to improve statistical dependency parsing. Conventional selectional preference learning methods have usually focused on word-to-class relations, e.g., a verb selects as its subject a given nominal class. This paper extends previous work to wordto-word selectional preferences by using webscale data. Experiments show that web-scale data improves statistical dependency parsing, particularly for long dependency relationships. There is no data like more data, performance improves log-linearly with the number of parameters (unique N-grams). More importantly, when operating on new domains, we show that using web-derived selectional preferences is essential for achieving robust performance.</p><p>4 0.84638202 <a title="39-lsi-4" href="./acl-2011-Getting_the_Most_out_of_Transition-based_Dependency_Parsing.html">143 acl-2011-Getting the Most out of Transition-based Dependency Parsing</a></p>
<p>Author: Jinho D. Choi ; Martha Palmer</p><p>Abstract: This paper suggests two ways of improving transition-based, non-projective dependency parsing. First, we add a transition to an existing non-projective parsing algorithm, so it can perform either projective or non-projective parsing as needed. Second, we present a bootstrapping technique that narrows down discrepancies between gold-standard and automatic parses used as features. The new addition to the algorithm shows a clear advantage in parsing speed. The bootstrapping technique gives a significant improvement to parsing accuracy, showing near state-of-theart performance with respect to other parsing approaches evaluated on the same data set.</p><p>5 0.78114212 <a title="39-lsi-5" href="./acl-2011-Neutralizing_Linguistically_Problematic_Annotations_in_Unsupervised_Dependency_Parsing_Evaluation.html">230 acl-2011-Neutralizing Linguistically Problematic Annotations in Unsupervised Dependency Parsing Evaluation</a></p>
<p>Author: Roy Schwartz ; Omri Abend ; Roi Reichart ; Ari Rappoport</p><p>Abstract: Dependency parsing is a central NLP task. In this paper we show that the common evaluation for unsupervised dependency parsing is highly sensitive to problematic annotations. We show that for three leading unsupervised parsers (Klein and Manning, 2004; Cohen and Smith, 2009; Spitkovsky et al., 2010a), a small set of parameters can be found whose modification yields a significant improvement in standard evaluation measures. These parameters correspond to local cases where no linguistic consensus exists as to the proper gold annotation. Therefore, the standard evaluation does not provide a true indication of algorithm quality. We present a new measure, Neutral Edge Direction (NED), and show that it greatly reduces this undesired phenomenon.</p><p>6 0.7781139 <a title="39-lsi-6" href="./acl-2011-Improving_Dependency_Parsing_with_Semantic_Classes.html">167 acl-2011-Improving Dependency Parsing with Semantic Classes</a></p>
<p>7 0.77509499 <a title="39-lsi-7" href="./acl-2011-Web-Scale_Features_for_Full-Scale_Parsing.html">333 acl-2011-Web-Scale Features for Full-Scale Parsing</a></p>
<p>8 0.72935325 <a title="39-lsi-8" href="./acl-2011-Effects_of_Noun_Phrase_Bracketing_in_Dependency_Parsing_and_Machine_Translation.html">111 acl-2011-Effects of Noun Phrase Bracketing in Dependency Parsing and Machine Translation</a></p>
<p>9 0.70698971 <a title="39-lsi-9" href="./acl-2011-Automatic_Detection_and_Correction_of_Errors_in_Dependency_Treebanks.html">48 acl-2011-Automatic Detection and Correction of Errors in Dependency Treebanks</a></p>
<p>10 0.70542067 <a title="39-lsi-10" href="./acl-2011-Optimistic_Backtracking_-_A_Backtracking_Overlay_for_Deterministic_Incremental_Parsing.html">236 acl-2011-Optimistic Backtracking - A Backtracking Overlay for Deterministic Incremental Parsing</a></p>
<p>11 0.70534074 <a title="39-lsi-11" href="./acl-2011-Temporal_Restricted_Boltzmann_Machines_for_Dependency_Parsing.html">295 acl-2011-Temporal Restricted Boltzmann Machines for Dependency Parsing</a></p>
<p>12 0.70169371 <a title="39-lsi-12" href="./acl-2011-Partial_Parsing_from_Bitext_Projections.html">243 acl-2011-Partial Parsing from Bitext Projections</a></p>
<p>13 0.69735324 <a title="39-lsi-13" href="./acl-2011-Dynamic_Programming_Algorithms_for_Transition-Based_Dependency_Parsers.html">107 acl-2011-Dynamic Programming Algorithms for Transition-Based Dependency Parsers</a></p>
<p>14 0.67957175 <a title="39-lsi-14" href="./acl-2011-Better_Automatic_Treebank_Conversion_Using_A_Feature-Based_Approach.html">59 acl-2011-Better Automatic Treebank Conversion Using A Feature-Based Approach</a></p>
<p>15 0.63303638 <a title="39-lsi-15" href="./acl-2011-Joint_Training_of_Dependency_Parsing_Filters_through_Latent_Support_Vector_Machines.html">186 acl-2011-Joint Training of Dependency Parsing Filters through Latent Support Vector Machines</a></p>
<p>16 0.63098741 <a title="39-lsi-16" href="./acl-2011-Shift-Reduce_CCG_Parsing.html">282 acl-2011-Shift-Reduce CCG Parsing</a></p>
<p>17 0.62738407 <a title="39-lsi-17" href="./acl-2011-Learning_Condensed_Feature_Representations_from_Large_Unsupervised_Data_Sets_for_Supervised_Learning.html">199 acl-2011-Learning Condensed Feature Representations from Large Unsupervised Data Sets for Supervised Learning</a></p>
<p>18 0.60212308 <a title="39-lsi-18" href="./acl-2011-Reversible_Stochastic_Attribute-Value_Grammars.html">267 acl-2011-Reversible Stochastic Attribute-Value Grammars</a></p>
<p>19 0.55762702 <a title="39-lsi-19" href="./acl-2011-A_Discriminative_Model_for_Joint_Morphological_Disambiguation_and_Dependency_Parsing.html">10 acl-2011-A Discriminative Model for Joint Morphological Disambiguation and Dependency Parsing</a></p>
<p>20 0.54923433 <a title="39-lsi-20" href="./acl-2011-Joint_Hebrew_Segmentation_and_Parsing_using_a_PCFGLA_Lattice_Parser.html">184 acl-2011-Joint Hebrew Segmentation and Parsing using a PCFGLA Lattice Parser</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.015), (17, 0.044), (24, 0.213), (26, 0.02), (28, 0.016), (31, 0.012), (37, 0.2), (39, 0.085), (41, 0.05), (55, 0.032), (59, 0.025), (72, 0.025), (91, 0.039), (96, 0.154)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.85157305 <a title="39-lda-1" href="./acl-2011-An_Ensemble_Model_that_Combines_Syntactic_and_Semantic_Clustering_for_Discriminative_Dependency_Parsing.html">39 acl-2011-An Ensemble Model that Combines Syntactic and Semantic Clustering for Discriminative Dependency Parsing</a></p>
<p>Author: Gholamreza Haffari ; Marzieh Razavi ; Anoop Sarkar</p><p>Abstract: We combine multiple word representations based on semantic clusters extracted from the (Brown et al., 1992) algorithm and syntactic clusters obtained from the Berkeley parser (Petrov et al., 2006) in order to improve discriminative dependency parsing in the MSTParser framework (McDonald et al., 2005). We also provide an ensemble method for combining diverse cluster-based models. The two contributions together significantly improves unlabeled dependency accuracy from 90.82% to 92. 13%.</p><p>2 0.7751779 <a title="39-lda-2" href="./acl-2011-Transition-based_Dependency_Parsing_with_Rich_Non-local_Features.html">309 acl-2011-Transition-based Dependency Parsing with Rich Non-local Features</a></p>
<p>Author: Yue Zhang ; Joakim Nivre</p><p>Abstract: Transition-based dependency parsers generally use heuristic decoding algorithms but can accommodate arbitrarily rich feature representations. In this paper, we show that we can improve the accuracy of such parsers by considering even richer feature sets than those employed in previous systems. In the standard Penn Treebank setup, our novel features improve attachment score form 91.4% to 92.9%, giving the best results so far for transitionbased parsing and rivaling the best results overall. For the Chinese Treebank, they give a signficant improvement of the state of the art. An open source release of our parser is freely available.</p><p>3 0.77505636 <a title="39-lda-3" href="./acl-2011-Data_point_selection_for_cross-language_adaptation_of_dependency_parsers.html">92 acl-2011-Data point selection for cross-language adaptation of dependency parsers</a></p>
<p>Author: Anders Sgaard</p><p>Abstract: We consider a very simple, yet effective, approach to cross language adaptation of dependency parsers. We first remove lexical items from the treebanks and map part-of-speech tags into a common tagset. We then train a language model on tag sequences in otherwise unlabeled target data and rank labeled source data by perplexity per word of tag sequences from less similar to most similar to the target. We then train our target language parser on the most similar data points in the source labeled data. The strategy achieves much better results than a non-adapted baseline and stateof-the-art unsupervised dependency parsing, and results are comparable to more complex projection-based cross language adaptation algorithms.</p><p>4 0.77481335 <a title="39-lda-4" href="./acl-2011-Event_Extraction_as_Dependency_Parsing.html">122 acl-2011-Event Extraction as Dependency Parsing</a></p>
<p>Author: David McClosky ; Mihai Surdeanu ; Christopher Manning</p><p>Abstract: Nested event structures are a common occurrence in both open domain and domain specific extraction tasks, e.g., a “crime” event can cause a “investigation” event, which can lead to an “arrest” event. However, most current approaches address event extraction with highly local models that extract each event and argument independently. We propose a simple approach for the extraction of such structures by taking the tree of event-argument relations and using it directly as the representation in a reranking dependency parser. This provides a simple framework that captures global properties of both nested and flat event structures. We explore a rich feature space that models both the events to be parsed and context from the original supporting text. Our approach obtains competitive results in the extraction of biomedical events from the BioNLP’09 shared task with a F1 score of 53.5% in development and 48.6% in testing.</p><p>5 0.77457488 <a title="39-lda-5" href="./acl-2011-Using_Multiple_Sources_to_Construct_a_Sentiment_Sensitive_Thesaurus_for_Cross-Domain_Sentiment_Classification.html">332 acl-2011-Using Multiple Sources to Construct a Sentiment Sensitive Thesaurus for Cross-Domain Sentiment Classification</a></p>
<p>Author: Danushka Bollegala ; David Weir ; John Carroll</p><p>Abstract: We describe a sentiment classification method that is applicable when we do not have any labeled data for a target domain but have some labeled data for multiple other domains, designated as the source domains. We automat- ically create a sentiment sensitive thesaurus using both labeled and unlabeled data from multiple source domains to find the association between words that express similar sentiments in different domains. The created thesaurus is then used to expand feature vectors to train a binary classifier. Unlike previous cross-domain sentiment classification methods, our method can efficiently learn from multiple source domains. Our method significantly outperforms numerous baselines and returns results that are better than or comparable to previous cross-domain sentiment classification methods on a benchmark dataset containing Amazon user reviews for different types of products.</p><p>6 0.77125406 <a title="39-lda-6" href="./acl-2011-Automatically_Extracting_Polarity-Bearing_Topics_for_Cross-Domain_Sentiment_Classification.html">54 acl-2011-Automatically Extracting Polarity-Bearing Topics for Cross-Domain Sentiment Classification</a></p>
<p>7 0.77018356 <a title="39-lda-7" href="./acl-2011-Putting_it_Simply%3A_a_Context-Aware_Approach_to_Lexical_Simplification.html">254 acl-2011-Putting it Simply: a Context-Aware Approach to Lexical Simplification</a></p>
<p>8 0.76741481 <a title="39-lda-8" href="./acl-2011-Which_Noun_Phrases_Denote_Which_Concepts%3F.html">334 acl-2011-Which Noun Phrases Denote Which Concepts?</a></p>
<p>9 0.76609075 <a title="39-lda-9" href="./acl-2011-Exploiting_Web-Derived_Selectional_Preference_to_Improve_Statistical_Dependency_Parsing.html">127 acl-2011-Exploiting Web-Derived Selectional Preference to Improve Statistical Dependency Parsing</a></p>
<p>10 0.76520169 <a title="39-lda-10" href="./acl-2011-Learning_Word_Vectors_for_Sentiment_Analysis.html">204 acl-2011-Learning Word Vectors for Sentiment Analysis</a></p>
<p>11 0.76511788 <a title="39-lda-11" href="./acl-2011-Joint_Training_of_Dependency_Parsing_Filters_through_Latent_Support_Vector_Machines.html">186 acl-2011-Joint Training of Dependency Parsing Filters through Latent Support Vector Machines</a></p>
<p>12 0.76494813 <a title="39-lda-12" href="./acl-2011-Joint_Bilingual_Sentiment_Classification_with_Unlabeled_Parallel_Corpora.html">183 acl-2011-Joint Bilingual Sentiment Classification with Unlabeled Parallel Corpora</a></p>
<p>13 0.76144212 <a title="39-lda-13" href="./acl-2011-Neutralizing_Linguistically_Problematic_Annotations_in_Unsupervised_Dependency_Parsing_Evaluation.html">230 acl-2011-Neutralizing Linguistically Problematic Annotations in Unsupervised Dependency Parsing Evaluation</a></p>
<p>14 0.7601217 <a title="39-lda-14" href="./acl-2011-Prefix_Probability_for_Probabilistic_Synchronous_Context-Free_Grammars.html">250 acl-2011-Prefix Probability for Probabilistic Synchronous Context-Free Grammars</a></p>
<p>15 0.7595613 <a title="39-lda-15" href="./acl-2011-Effects_of_Noun_Phrase_Bracketing_in_Dependency_Parsing_and_Machine_Translation.html">111 acl-2011-Effects of Noun Phrase Bracketing in Dependency Parsing and Machine Translation</a></p>
<p>16 0.75951242 <a title="39-lda-16" href="./acl-2011-Query_Weighting_for_Ranking_Model_Adaptation.html">256 acl-2011-Query Weighting for Ranking Model Adaptation</a></p>
<p>17 0.75948036 <a title="39-lda-17" href="./acl-2011-Coreference_Resolution_with_World_Knowledge.html">85 acl-2011-Coreference Resolution with World Knowledge</a></p>
<p>18 0.75851393 <a title="39-lda-18" href="./acl-2011-Domain_Adaptation_by_Constraining_Inter-Domain_Variability_of_Latent_Feature_Representation.html">103 acl-2011-Domain Adaptation by Constraining Inter-Domain Variability of Latent Feature Representation</a></p>
<p>19 0.75647128 <a title="39-lda-19" href="./acl-2011-Target-dependent_Twitter_Sentiment_Classification.html">292 acl-2011-Target-dependent Twitter Sentiment Classification</a></p>
<p>20 0.75125629 <a title="39-lda-20" href="./acl-2011-Discriminative_Feature-Tied_Mixture_Modeling_for_Statistical_Machine_Translation.html">100 acl-2011-Discriminative Feature-Tied Mixture Modeling for Statistical Machine Translation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
