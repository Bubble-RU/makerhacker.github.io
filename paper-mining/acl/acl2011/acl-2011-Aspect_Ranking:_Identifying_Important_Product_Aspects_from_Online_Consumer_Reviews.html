<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>45 acl-2011-Aspect Ranking: Identifying Important Product Aspects from Online Consumer Reviews</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-45" href="#">acl2011-45</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>45 acl-2011-Aspect Ranking: Identifying Important Product Aspects from Online Consumer Reviews</h1>
<br/><p>Source: <a title="acl-2011-45-pdf" href="http://aclweb.org/anthology//P/P11/P11-1150.pdf">pdf</a></p><p>Author: Jianxing Yu ; Zheng-Jun Zha ; Meng Wang ; Tat-Seng Chua</p><p>Abstract: In this paper, we dedicate to the topic of aspect ranking, which aims to automatically identify important product aspects from online consumer reviews. The important aspects are identified according to two observations: (a) the important aspects of a product are usually commented by a large number of consumers; and (b) consumers’ opinions on the important aspects greatly influence their overall opinions on the product. In particular, given consumer reviews of a product, we first identify the product aspects by a shallow dependency parser and determine consumers’ opinions on these aspects via a sentiment classifier. We then develop an aspect ranking algorithm to identify the important aspects by simultaneously considering the aspect frequency and the influence of consumers’ opinions given to each aspect on their overall opinions. The experimental results on 11 popular products in four domains demonstrate the effectiveness of our approach. We further apply the aspect ranking results to the application ofdocumentlevel sentiment classification, and improve the performance significantly.</p><p>Reference: <a title="acl-2011-45-reference" href="../acl2011_reference/acl-2011-Aspect_Ranking%3A_Identifying_Important_Product_Aspects_from_Online_Consumer_Reviews_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The important aspects are identified according to two observations: (a) the important aspects of a product are usually commented by a large number of consumers; and (b) consumers’ opinions on the important aspects greatly influence their overall opinions on the product. [sent-2, score-2.061]
</p><p>2 In particular, given consumer reviews of a product, we first identify the product aspects by a shallow dependency parser and determine consumers’ opinions on these aspects via a sentiment classifier. [sent-3, score-2.037]
</p><p>3 We then develop an aspect ranking algorithm to identify the important aspects by simultaneously considering the aspect frequency and the influence of consumers’ opinions given to each aspect on their overall opinions. [sent-4, score-2.27]
</p><p>4 We further apply the aspect ranking results to the application ofdocumentlevel sentiment classification, and improve the performance significantly. [sent-6, score-0.86]
</p><p>5 Most retail Web sites encourage consumers to write reviews to express their opinions on various aspects of the products. [sent-9, score-1.222]
</p><p>6 Figure 1: Sample reviews on iPhone 3GS product huge collections of consumer reviews on the Web. [sent-13, score-1.007]
</p><p>7 These reviews have become an important resource for both consumers and firms. [sent-14, score-0.648]
</p><p>8 Consumers commonly seek quality information from online consumer reviews prior to purchasing a product, while many firms use online consumer reviews as an important resource in their product development, marketing, and consumer relationship management. [sent-15, score-1.711]
</p><p>9 As illustrated in Figure 1, most online reviews express consumers’ overall opinion ratings on the product, and their opinions on multiple aspects of the product. [sent-16, score-1.185]
</p><p>10 While a product may have hundreds of aspects, we argue that some aspects are more important than the others and have greater influence on consumers’ purchase decisions as well as firms’ product development strategies. [sent-17, score-0.847]
</p><p>11 ” Generally, identifying the important product aspects will benefit both consumers and firms. [sent-19, score-0.861]
</p><p>12 c s 2o0ci1a1ti Aonss foocria Ctioomnp fourta Ctioomnaplu Ltaintigouniaslti Lcisn,g puaigsetsic 1s496–1505, these aspects and thus enhance the product reputation effectively. [sent-22, score-0.518]
</p><p>13 However, it is impractical for people to identify the important aspects from the numerous reviews manually. [sent-23, score-0.804]
</p><p>14 Thus, it becomes a compelling need to automatically identify the important aspects from consumer reviews. [sent-24, score-0.762]
</p><p>15 A straightforward solution for important aspect identification is to select the aspects that are frequently commented in consumer reviews as the important ones. [sent-25, score-1.61]
</p><p>16 However, consumers’ opinions on the frequent aspects may not influence their overall opinions on the product, and thus not influence consumers’ purchase decisions. [sent-26, score-1.036]
</p><p>17 Motivated by the above observations, in this paper, we propose an effective approach to automatically identify the important product aspects from consumer reviews. [sent-30, score-0.896]
</p><p>18 Our assumption is that the important aspects of a product should be the aspects that are frequently commented by consumers, and consumers’ opinions on the important aspects greatly influence their overall opinions on the product. [sent-31, score-2.004]
</p><p>19 Given the online consumer reviews of a specific product, we first identify the aspects in the reviews using a shallow dependency parser (Wu et al. [sent-32, score-1.376]
</p><p>20 , 2009), and determine consumers’ opinions on these aspects via a sentiment classifier. [sent-33, score-0.893]
</p><p>21 We then design an aspect ranking algorithm to identify the important aspects by simultaneously taking into account the aspect frequency and the influence of consumers’ opinions given to each aspect on their overall opinions. [sent-34, score-2.27]
</p><p>22 Specifically, we assume that consumer’s overall opinion rating on a product is generated based on a weighted sum of his/her specific opinions on multiple aspects of the product, where the weights essentially measure the degree of importance of the aspects. [sent-35, score-1.122]
</p><p>23 A probabilistic regression algorithm is then developed to derive these importance weights by leveraging the aspect frequency and the consistency  between the overall opinions and the weighted sum of opinions on various aspects. [sent-36, score-1.035]
</p><p>24 The consumer reviews on these products are crawled from the prevalent forum Web sites (e. [sent-38, score-0.675]
</p><p>25 Furthermore, we apply the aspect ranking results to the application of document-level sentiment classification by carrying out the term-weighting based on the aspect importance. [sent-45, score-1.329]
</p><p>26 The main contributions of this paper include, 1) We dedicate to the topic of aspect ranking, which aims to automatically identify important aspects of a product from consumer reviews. [sent-47, score-1.395]
</p><p>27 2) We develop an aspect ranking algorithm to identify the important aspects by simultaneously considering the aspect frequency and the influence of consumers’ opinions given to each aspect on their overall opinions. [sent-48, score-2.27]
</p><p>28 3) We apply aspect ranking results to the application of document-level sentiment classification, and improve the performance significantly. [sent-49, score-0.86]
</p><p>29 There is another work named aspect ranking (Snyder et al. [sent-50, score-0.551]
</p><p>30 This work mainly focuses on predicting opinionated ratings on aspects rather than identifying important aspects. [sent-53, score-0.525]
</p><p>31 2  Aspect Ranking Framework  In this section, we first present some notations and then elaborate the key components of our approach, including the aspect identification, sentiment classification, and aspect ranking algorithm. [sent-58, score-1.306]
</p><p>32 Ef oanchli n reev cioenwr ∈ R is associated with an overall opinion rating Or, and covers several aspects with consumer commOents on these aspects. [sent-61, score-0.949]
</p><p>33 Suppose there are m aspects A = {a1, · · · , am} involved in the review corpus R, w=h {eare ak i·s ,thae }k- ithnv aspect. [sent-62, score-0.586]
</p><p>34 nW teh deef rienveie ork as ptuhes opinion on aspect ak in review r. [sent-63, score-0.846]
</p><p>35 We assume that the overall opinion rating Or is generated based on a weighted sum oonf tr aheti opinions on specific aspects ork (Wang et al. [sent-64, score-0.966]
</p><p>36 The weights are denoted as {ωrk}km=1, each of which essentially measures the degree of importance of the aspect ak in review r. [sent-66, score-0.71]
</p><p>37 To identify the aspects in free text reviews, we first parse each review using the Stanford parser 1, and extract the noun phrases (NP) from the parsing tree as aspect candidates. [sent-73, score-1.032]
</p><p>38 While these candidates may contain much noise, we leverage the Pros and Cons reviews to assist identify aspects from the candidates. [sent-74, score-0.774]
</p><p>39 Specifically, we first expand each aspect term with its synonym terms obtained from the synonym terms Web site 2, and then cluster the terms to obtain unique aspects based on 1http://nlp. [sent-78, score-0.992]
</p><p>40 3 Aspect Sentiment Classification Since the Pros and Cons reviews explicitly express positive and negative opinions on the aspects, respectively, our task is to determine the opinions in free text reviews. [sent-84, score-0.727]
</p><p>41 To this end, we here utilize Pros and Cons reviews to train a SVM sentiment classifier. [sent-85, score-0.633]
</p><p>42 Specifically, we collect sentiment terms in the Pros and Cons reviews as features and represent each review into feature vector using Boolean weighting. [sent-86, score-0.775]
</p><p>43 Note that we select sentiment terms as those appear in the sentiment lexicon provided by MPQA project (Wilson et al. [sent-87, score-0.657]
</p><p>44 Given a free text review, since it may cover various opinions on multiple aspects, we first locate the opinionated expression modifying each aspect, and determine the opinion on the aspect using the learned SVM classifier. [sent-90, score-0.843]
</p><p>45 In particular, since the opinionated expression on each aspect tends to contain sentiment terms and appear closely to the aspect (Hu  µ  and Liu, 2004), we select the expressions which contain sentiment terms and are at the distance of less than 5 from the aspect NP in the parsing tree. [sent-91, score-2.009]
</p><p>46 4 Aspect Ranking Generally, consumer’s opinion on each specific aspect in the review influences his/her overall opinion on the product. [sent-93, score-0.932]
</p><p>47 Thus, we assume that the consumer gives the overall opinion rating Or based on tshuem weight∑ed sum voefr hail s/ ohpeirn opinion ork on each aspect ak: ∑km=1 ωrkork, which can be rewritten as ωrTor, w∑here ωr and or are the weight and opinion vectors. [sent-94, score-1.367]
</p><p>48 In particular, we aim to find an optimal Ψˆ to maximize the probability of observing the overall opinion ratings in the reviews corpus. [sent-105, score-0.559]
</p><p>49 As a result, we obtain the optimal importance weights ωr which measure the importance of aspects in review r ∈ R. [sent-118, score-0.651]
</p><p>50 e Waceh t aspect ak by integrating its importance score in all the reviews as,  ϖk=|R1|∑r∈Rωrk,  k = 1,··· ,m  (14)  It is worth noting that the aspect frequency is considered again in this integration process. [sent-120, score-1.329]
</p><p>51 3  Evaluations  In this section, we evaluate the effectiveness of our approach on aspect identification, sentiment classification, and aspect ranking. [sent-122, score-1.159]
</p><p>52 This data set contains consumer reviews on 11popular products in 4 domains. [sent-125, score-0.633]
</p><p>53 The aspects of the reviews, as well as the opinions on the aspects were manually annotated as the gold standard for evaluations. [sent-132, score-0.968]
</p><p>54 To examine the performance on aspect identification and sentiment classification, we employed F1-measure, which was the combination of precision and recall, as the evaluation metric. [sent-134, score-0.786]
</p><p>55 This evaluation metric will favor the ranking which ranks the most important aspects at the top. [sent-137, score-0.588]
</p><p>56 We then sampled some reviews covering these aspects, and provided the reviews to each annotator to read. [sent-141, score-0.61]
</p><p>57 Each review contains the overall opinion rating, the highlighted aspects, and opinion terms. [sent-142, score-0.488]
</p><p>58 Such results imply that our approach can accurately identify the aspects from consumer reviews by leveraging the Pros and Cons reviews. [sent-156, score-1.033]
</p><p>59 Thus, we can deduce from such results that the Pros and Cons reviews are useful for sentiment classification. [sent-172, score-0.639]
</p><p>60 4 Evaluations on Aspect Ranking In this section, we compared our aspect ranking algorithm against the following three methods. [sent-179, score-0.551]
</p><p>61 The method ranks the aspects based on aspect frequency. [sent-181, score-0.83]
</p><p>62 This method measures the correlation between the opinions on specific aspects and the overall opinion. [sent-183, score-0.653]
</p><p>63 It counts the  number of the cases when such two kinds of opinions are consistent, and ranks the aspects based on the number of the consistent cases. [sent-184, score-0.605]
</p><p>64 We can deduce from the results that our aspect ranking algorithm can effectively identify the important aspects from consumer reviews by leveraging the aspect frequency and the influence of consumers’ opinions given to each aspect on their overall opinions. [sent-200, score-2.862]
</p><p>65 Table 5 shows the aspect ranking results of these four methods. [sent-201, score-0.551]
</p><p>66 Due to the space limitation, we here only show top 10 aspects of the product iphone 3GS. [sent-202, score-0.602]
</p><p>67 All of these aspects are in the top 10 of our ranking results. [sent-208, score-0.51]
</p><p>68 Therefore, we can conclude that our approach is able to automatically identify the important aspects from numerous consumer reviews. [sent-209, score-0.762]
</p><p>69 4  Applications  The identification of important aspects can support a wide range of applications. [sent-210, score-0.493]
</p><p>70 provide product comparison on the important aspects to users, so that users can make wise purchase decisions conveniently. [sent-214, score-0.668]
</p><p>71 In the following, we apply the aspect ranking results to assist document-level review sentiment classification. [sent-215, score-1.009]
</p><p>72 Generally, a review document contains consumer’s positive/negative opinions on various aspects of the product. [sent-216, score-0.706]
</p><p>73 In addition, when we learn a document-level sentiment classifier, the features generated from unimportant aspects lack of discriminability and thus may deteriorate the performance of the classifier (Fang et al. [sent-218, score-0.693]
</p><p>74 While the important aspects and the sentiment terms on these aspects can greatly influence the overall opinions of the review, they are highly likely to be discriminative features for sentiment classification. [sent-220, score-1.819]
</p><p>75 These observations motivate us to utilize aspect ranking results to assist classifying the sentiment of review documents. [sent-221, score-1.028]
</p><p>76 Specifically, we randomly sampled 100 reviews of each product as the testing data and used the remaining reviews as the training data. [sent-222, score-0.744]
</p><p>77 We first utilized our approach to identify the importance aspects from the training data. [sent-223, score-0.526]
</p><p>78 We then explored the aspect terms and sentiment terms as features, based on which each review is represented as a feature vector. [sent-224, score-0.934]
</p><p>79 Here, we give more emphasis on the important aspects and the sentiment terms that modify these aspects. [sent-225, score-0.789]
</p><p>80 In particular, we set the term-weighting as 1+ φ · ϖk, wpahretirceu ϖk iws eth see importance score ogf athse 1 aspect ak, 1502  is set to 100. [sent-226, score-0.487]
</p><p>81 Based on the weighted features, we then trained a SVM classifier using the training reviews to determine the overall opinions on the testing reviews. [sent-227, score-0.555]
</p><p>82 Thus, we can speculate that the identification of important aspects is beneficial to improving the performance of documentlevel sentiment classification. [sent-238, score-0.802]
</p><p>83 φ  5  Related Work  Existing researches mainly focused on determining opinions on the reviews, or identifying aspects from these reviews. [sent-239, score-0.616]
</p><p>84 They viewed each aspect equally without distinguishing the important ones. [sent-240, score-0.482]
</p><p>85 Since the consumer reviews usually expressed opinions on multiple aspects, some works had drilled down to the aspect-level sentiment analysis, which aimed to identify the aspects from the reviews and to determine the opinions on the specific aspects instead of the overall opinion. [sent-258, score-2.507]
</p><p>86 For the topic of aspect identification, Hu and Liu (2004) presented the association mining method to extract the frequent terms as the aspects. [sent-259, score-0.525]
</p><p>87 (2009) utilized the dependency parser to extract the noun phrases and verb phrases from the reviews as the aspect candidates. [sent-268, score-0.773]
</p><p>88 (2007) considered the situation when the consumers’ opinions on one aspect could influence their opinions on others. [sent-271, score-0.889]
</p><p>89 And they proposed a Good Grief algorithm to leveraging such meta-relations to improve the prediction accuracy of aspect opinion ratings. [sent-273, score-0.606]
</p><p>90 (2010) proposed the topic of latent aspect rating which aimed to infer the opinion rating on the aspect. [sent-275, score-0.835]
</p><p>91 They then proposed a generative Latent Rating Regression model (LRR) to infer aspect opinion ratings based on the review content and the associated overall rating. [sent-277, score-0.801]
</p><p>92 They aimed to summarize all the reviews and integrate major opinions on various aspects for a given product. [sent-279, score-0.919]
</p><p>93 They utilized topics to describe aspects and incorporated a regression model fed by the ground-truth opinion ratings. [sent-282, score-0.586]
</p><p>94 They then aggregated opinions on each specific aspects and selected representative text segment to generate a summary. [sent-285, score-0.603]
</p><p>95 In addition, some works proposed the topic of product ranking which aimed to identify the best products for each specific aspect (Zhang et al. [sent-286, score-0.891]
</p><p>96 Different from previous researches, we dedicate our work to identifying the important aspects from the consumer reviews of a specific product. [sent-289, score-1.068]
</p><p>97 6  Conclusions and Future Works  In this paper, we have proposed to identify the important aspects of a product from online consumer reviews. [sent-290, score-0.938]
</p><p>98 Our assumption is that the important aspects of a product should be the aspects that are frequently commented by consumers and consumers’ opinions on the important aspects greatly influence their overall opinions on the product. [sent-291, score-2.29]
</p><p>99 Based on this assumption, we have developed an aspect ranking algorithm to identify the important aspects by simultaneously considering the aspect frequency and the influence of consumers’ opinions given to each aspect on their overall opinions. [sent-292, score-2.27]
</p><p>100 We have further applied the aspect ranking results to the application of document-level sentiment classification, and have significantly improved the classification performance. [sent-295, score-0.904]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('aspect', 0.425), ('aspects', 0.384), ('sentiment', 0.309), ('reviews', 0.305), ('consumers', 0.286), ('consumer', 0.263), ('opinions', 0.2), ('opinion', 0.158), ('pros', 0.148), ('product', 0.134), ('ranking', 0.126), ('review', 0.122), ('cons', 0.121), ('ndcg', 0.099), ('rating', 0.094), ('iphone', 0.084), ('ak', 0.08), ('pang', 0.076), ('purchase', 0.074), ('commented', 0.067), ('products', 0.065), ('influence', 0.064), ('importance', 0.062), ('ork', 0.061), ('identify', 0.058), ('important', 0.057), ('identification', 0.052), ('overall', 0.05), ('ratings', 0.046), ('rtor', 0.046), ('classification', 0.044), ('online', 0.042), ('dedicate', 0.04), ('terms', 0.039), ('opinionated', 0.038), ('firms', 0.037), ('hu', 0.037), ('svm', 0.036), ('weighting', 0.035), ('customer', 0.034), ('topic', 0.034), ('customers', 0.033), ('synonym', 0.033), ('frequency', 0.032), ('www', 0.032), ('researches', 0.032), ('boolean', 0.031), ('forrester', 0.03), ('manevitz', 0.03), ('ohana', 0.03), ('unicom', 0.03), ('stars', 0.03), ('kl', 0.03), ('aimed', 0.03), ('acl', 0.03), ('wu', 0.028), ('snyder', 0.028), ('liu', 0.028), ('mining', 0.027), ('summarization', 0.027), ('assist', 0.027), ('frequencybased', 0.027), ('jarvelin', 0.027), ('mullen', 0.027), ('paltoglou', 0.027), ('el', 0.026), ('deduce', 0.025), ('evaluative', 0.025), ('grief', 0.025), ('retail', 0.025), ('zha', 0.025), ('goldberg', 0.024), ('popescu', 0.024), ('thumbs', 0.024), ('simultaneously', 0.024), ('km', 0.023), ('marketing', 0.023), ('leveraging', 0.023), ('greatly', 0.023), ('sites', 0.022), ('regression', 0.022), ('carenini', 0.022), ('utilized', 0.022), ('free', 0.022), ('ranks', 0.021), ('noun', 0.021), ('notations', 0.021), ('weights', 0.021), ('wilson', 0.02), ('covariance', 0.02), ('wang', 0.02), ('matrix', 0.02), ('crawled', 0.02), ('rk', 0.02), ('unsupervised', 0.02), ('utilize', 0.019), ('fang', 0.019), ('wise', 0.019), ('specific', 0.019), ('evaluations', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000015 <a title="45-tfidf-1" href="./acl-2011-Aspect_Ranking%3A_Identifying_Important_Product_Aspects_from_Online_Consumer_Reviews.html">45 acl-2011-Aspect Ranking: Identifying Important Product Aspects from Online Consumer Reviews</a></p>
<p>Author: Jianxing Yu ; Zheng-Jun Zha ; Meng Wang ; Tat-Seng Chua</p><p>Abstract: In this paper, we dedicate to the topic of aspect ranking, which aims to automatically identify important product aspects from online consumer reviews. The important aspects are identified according to two observations: (a) the important aspects of a product are usually commented by a large number of consumers; and (b) consumers’ opinions on the important aspects greatly influence their overall opinions on the product. In particular, given consumer reviews of a product, we first identify the product aspects by a shallow dependency parser and determine consumers’ opinions on these aspects via a sentiment classifier. We then develop an aspect ranking algorithm to identify the important aspects by simultaneously considering the aspect frequency and the influence of consumers’ opinions given to each aspect on their overall opinions. The experimental results on 11 popular products in four domains demonstrate the effectiveness of our approach. We further apply the aspect ranking results to the application ofdocumentlevel sentiment classification, and improve the performance significantly.</p><p>2 0.32550234 <a title="45-tfidf-2" href="./acl-2011-Using_Multiple_Sources_to_Construct_a_Sentiment_Sensitive_Thesaurus_for_Cross-Domain_Sentiment_Classification.html">332 acl-2011-Using Multiple Sources to Construct a Sentiment Sensitive Thesaurus for Cross-Domain Sentiment Classification</a></p>
<p>Author: Danushka Bollegala ; David Weir ; John Carroll</p><p>Abstract: We describe a sentiment classification method that is applicable when we do not have any labeled data for a target domain but have some labeled data for multiple other domains, designated as the source domains. We automat- ically create a sentiment sensitive thesaurus using both labeled and unlabeled data from multiple source domains to find the association between words that express similar sentiments in different domains. The created thesaurus is then used to expand feature vectors to train a binary classifier. Unlike previous cross-domain sentiment classification methods, our method can efficiently learn from multiple source domains. Our method significantly outperforms numerous baselines and returns results that are better than or comparable to previous cross-domain sentiment classification methods on a benchmark dataset containing Amazon user reviews for different types of products.</p><p>3 0.32259732 <a title="45-tfidf-3" href="./acl-2011-Learning_Word_Vectors_for_Sentiment_Analysis.html">204 acl-2011-Learning Word Vectors for Sentiment Analysis</a></p>
<p>Author: Andrew L. Maas ; Raymond E. Daly ; Peter T. Pham ; Dan Huang ; Andrew Y. Ng ; Christopher Potts</p><p>Abstract: Unsupervised vector-based approaches to semantics can model rich lexical meanings, but they largely fail to capture sentiment information that is central to many word meanings and important for a wide range of NLP tasks. We present a model that uses a mix of unsupervised and supervised techniques to learn word vectors capturing semanticterm–documentinformation as well as rich sentiment content. The proposed model can leverage both continuous and multi-dimensional sentiment information as well as non-sentiment annotations. We instantiate the model to utilize the document-level sentiment polarity annotations present in many online documents (e.g. star ratings). We evaluate the model using small, widely used sentiment and subjectivity corpora and find it out-performs several previously introduced methods for sentiment classification. We also introduce a large dataset , of movie reviews to serve as a more robust benchmark for work in this area.</p><p>4 0.26261705 <a title="45-tfidf-4" href="./acl-2011-Identifying_Noun_Product_Features_that_Imply_Opinions.html">159 acl-2011-Identifying Noun Product Features that Imply Opinions</a></p>
<p>Author: Lei Zhang ; Bing Liu</p><p>Abstract: Identifying domain-dependent opinion words is a key problem in opinion mining and has been studied by several researchers. However, existing work has been focused on adjectives and to some extent verbs. Limited work has been done on nouns and noun phrases. In our work, we used the feature-based opinion mining model, and we found that in some domains nouns and noun phrases that indicate product features may also imply opinions. In many such cases, these nouns are not subjective but objective. Their involved sentences are also objective sentences and imply positive or negative opinions. Identifying such nouns and noun phrases and their polarities is very challenging but critical for effective opinion mining in these domains. To the best of our knowledge, this problem has not been studied in the literature. This paper proposes a method to deal with the problem. Experimental results based on real-life datasets show promising results. 1</p><p>5 0.21109134 <a title="45-tfidf-5" href="./acl-2011-Target-dependent_Twitter_Sentiment_Classification.html">292 acl-2011-Target-dependent Twitter Sentiment Classification</a></p>
<p>Author: Long Jiang ; Mo Yu ; Ming Zhou ; Xiaohua Liu ; Tiejun Zhao</p><p>Abstract: Sentiment analysis on Twitter data has attracted much attention recently. In this paper, we focus on target-dependent Twitter sentiment classification; namely, given a query, we classify the sentiments of the tweets as positive, negative or neutral according to whether they contain positive, negative or neutral sentiments about that query. Here the query serves as the target of the sentiments. The state-ofthe-art approaches for solving this problem always adopt the target-independent strategy, which may assign irrelevant sentiments to the given target. Moreover, the state-of-the-art approaches only take the tweet to be classified into consideration when classifying the sentiment; they ignore its context (i.e., related tweets). However, because tweets are usually short and more ambiguous, sometimes it is not enough to consider only the current tweet for sentiment classification. In this paper, we propose to improve target-dependent Twitter sentiment classification by 1) incorporating target-dependent features; and 2) taking related tweets into consideration. According to the experimental results, our approach greatly improves the performance of target-dependent sentiment classification. 1</p><p>6 0.20503928 <a title="45-tfidf-6" href="./acl-2011-Sentiment_Analysis_of_Citations_using_Sentence_Structure-Based_Features.html">281 acl-2011-Sentiment Analysis of Citations using Sentence Structure-Based Features</a></p>
<p>7 0.20014974 <a title="45-tfidf-7" href="./acl-2011-Content_Models_with_Attitude.html">82 acl-2011-Content Models with Attitude</a></p>
<p>8 0.19465701 <a title="45-tfidf-8" href="./acl-2011-Semi-supervised_latent_variable_models_for_sentence-level_sentiment_analysis.html">279 acl-2011-Semi-supervised latent variable models for sentence-level sentiment analysis</a></p>
<p>9 0.18156151 <a title="45-tfidf-9" href="./acl-2011-PsychoSentiWordNet.html">253 acl-2011-PsychoSentiWordNet</a></p>
<p>10 0.18015084 <a title="45-tfidf-10" href="./acl-2011-Joint_Bilingual_Sentiment_Classification_with_Unlabeled_Parallel_Corpora.html">183 acl-2011-Joint Bilingual Sentiment Classification with Unlabeled Parallel Corpora</a></p>
<p>11 0.17938274 <a title="45-tfidf-11" href="./acl-2011-Dr_Sentiment_Knows_Everything%21.html">105 acl-2011-Dr Sentiment Knows Everything!</a></p>
<p>12 0.17487477 <a title="45-tfidf-12" href="./acl-2011-Liars_and_Saviors_in_a_Sentiment_Annotated_Corpus_of_Comments_to_Political_Debates.html">211 acl-2011-Liars and Saviors in a Sentiment Annotated Corpus of Comments to Political Debates</a></p>
<p>13 0.1626841 <a title="45-tfidf-13" href="./acl-2011-Automatically_Extracting_Polarity-Bearing_Topics_for_Cross-Domain_Sentiment_Classification.html">54 acl-2011-Automatically Extracting Polarity-Bearing Topics for Cross-Domain Sentiment Classification</a></p>
<p>14 0.14361593 <a title="45-tfidf-14" href="./acl-2011-C-Feel-It%3A_A_Sentiment_Analyzer_for_Micro-blogs.html">64 acl-2011-C-Feel-It: A Sentiment Analyzer for Micro-blogs</a></p>
<p>15 0.14256701 <a title="45-tfidf-15" href="./acl-2011-MemeTube%3A_A_Sentiment-based_Audiovisual_System_for_Analyzing_and_Displaying_Microblog_Messages.html">218 acl-2011-MemeTube: A Sentiment-based Audiovisual System for Analyzing and Displaying Microblog Messages</a></p>
<p>16 0.14130831 <a title="45-tfidf-16" href="./acl-2011-A_Pilot_Study_of_Opinion_Summarization_in_Conversations.html">21 acl-2011-A Pilot Study of Opinion Summarization in Conversations</a></p>
<p>17 0.1375186 <a title="45-tfidf-17" href="./acl-2011-Automatically_Predicting_Peer-Review_Helpfulness.html">55 acl-2011-Automatically Predicting Peer-Review Helpfulness</a></p>
<p>18 0.11139359 <a title="45-tfidf-18" href="./acl-2011-Comparative_News_Summarization_Using_Linear_Programming.html">76 acl-2011-Comparative News Summarization Using Linear Programming</a></p>
<p>19 0.10337043 <a title="45-tfidf-19" href="./acl-2011-Extracting_Opinion_Expressions_and_Their_Polarities_-_Exploration_of_Pipelines_and_Joint_Models.html">131 acl-2011-Extracting Opinion Expressions and Their Polarities - Exploration of Pipelines and Joint Models</a></p>
<p>20 0.099332243 <a title="45-tfidf-20" href="./acl-2011-Finding_Deceptive_Opinion_Spam_by_Any_Stretch_of_the_Imagination.html">136 acl-2011-Finding Deceptive Opinion Spam by Any Stretch of the Imagination</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.19), (1, 0.313), (2, 0.259), (3, -0.06), (4, 0.056), (5, -0.012), (6, -0.056), (7, 0.051), (8, 0.018), (9, -0.07), (10, 0.078), (11, -0.047), (12, -0.086), (13, -0.009), (14, 0.02), (15, 0.046), (16, 0.002), (17, -0.02), (18, 0.002), (19, 0.018), (20, -0.01), (21, 0.034), (22, 0.003), (23, -0.016), (24, 0.006), (25, 0.006), (26, 0.089), (27, -0.067), (28, 0.003), (29, 0.082), (30, 0.115), (31, 0.04), (32, -0.134), (33, 0.018), (34, -0.012), (35, -0.016), (36, -0.052), (37, 0.042), (38, -0.013), (39, 0.022), (40, 0.007), (41, -0.034), (42, -0.037), (43, 0.072), (44, 0.047), (45, 0.046), (46, 0.016), (47, 0.069), (48, 0.058), (49, 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98687887 <a title="45-lsi-1" href="./acl-2011-Aspect_Ranking%3A_Identifying_Important_Product_Aspects_from_Online_Consumer_Reviews.html">45 acl-2011-Aspect Ranking: Identifying Important Product Aspects from Online Consumer Reviews</a></p>
<p>Author: Jianxing Yu ; Zheng-Jun Zha ; Meng Wang ; Tat-Seng Chua</p><p>Abstract: In this paper, we dedicate to the topic of aspect ranking, which aims to automatically identify important product aspects from online consumer reviews. The important aspects are identified according to two observations: (a) the important aspects of a product are usually commented by a large number of consumers; and (b) consumers’ opinions on the important aspects greatly influence their overall opinions on the product. In particular, given consumer reviews of a product, we first identify the product aspects by a shallow dependency parser and determine consumers’ opinions on these aspects via a sentiment classifier. We then develop an aspect ranking algorithm to identify the important aspects by simultaneously considering the aspect frequency and the influence of consumers’ opinions given to each aspect on their overall opinions. The experimental results on 11 popular products in four domains demonstrate the effectiveness of our approach. We further apply the aspect ranking results to the application ofdocumentlevel sentiment classification, and improve the performance significantly.</p><p>2 0.76636028 <a title="45-lsi-2" href="./acl-2011-Liars_and_Saviors_in_a_Sentiment_Annotated_Corpus_of_Comments_to_Political_Debates.html">211 acl-2011-Liars and Saviors in a Sentiment Annotated Corpus of Comments to Political Debates</a></p>
<p>Author: Paula Carvalho ; Luis Sarmento ; Jorge Teixeira ; Mario J. Silva</p><p>Abstract: We investigate the expression of opinions about human entities in user-generated content (UGC). A set of 2,800 online news comments (8,000 sentences) was manually annotated, following a rich annotation scheme designed for this purpose. We conclude that the challenge in performing opinion mining in such type of content is correctly identifying the positive opinions, because (i) they are much less frequent than negative opinions and (ii) they are particularly exposed to verbal irony. We also show that the recognition of human targets poses additional challenges on mining opinions from UGC, since they are frequently mentioned by pronouns, definite descriptions and nicknames. 1</p><p>3 0.75400609 <a title="45-lsi-3" href="./acl-2011-Using_Multiple_Sources_to_Construct_a_Sentiment_Sensitive_Thesaurus_for_Cross-Domain_Sentiment_Classification.html">332 acl-2011-Using Multiple Sources to Construct a Sentiment Sensitive Thesaurus for Cross-Domain Sentiment Classification</a></p>
<p>Author: Danushka Bollegala ; David Weir ; John Carroll</p><p>Abstract: We describe a sentiment classification method that is applicable when we do not have any labeled data for a target domain but have some labeled data for multiple other domains, designated as the source domains. We automat- ically create a sentiment sensitive thesaurus using both labeled and unlabeled data from multiple source domains to find the association between words that express similar sentiments in different domains. The created thesaurus is then used to expand feature vectors to train a binary classifier. Unlike previous cross-domain sentiment classification methods, our method can efficiently learn from multiple source domains. Our method significantly outperforms numerous baselines and returns results that are better than or comparable to previous cross-domain sentiment classification methods on a benchmark dataset containing Amazon user reviews for different types of products.</p><p>4 0.75156188 <a title="45-lsi-4" href="./acl-2011-Learning_Word_Vectors_for_Sentiment_Analysis.html">204 acl-2011-Learning Word Vectors for Sentiment Analysis</a></p>
<p>Author: Andrew L. Maas ; Raymond E. Daly ; Peter T. Pham ; Dan Huang ; Andrew Y. Ng ; Christopher Potts</p><p>Abstract: Unsupervised vector-based approaches to semantics can model rich lexical meanings, but they largely fail to capture sentiment information that is central to many word meanings and important for a wide range of NLP tasks. We present a model that uses a mix of unsupervised and supervised techniques to learn word vectors capturing semanticterm–documentinformation as well as rich sentiment content. The proposed model can leverage both continuous and multi-dimensional sentiment information as well as non-sentiment annotations. We instantiate the model to utilize the document-level sentiment polarity annotations present in many online documents (e.g. star ratings). We evaluate the model using small, widely used sentiment and subjectivity corpora and find it out-performs several previously introduced methods for sentiment classification. We also introduce a large dataset , of movie reviews to serve as a more robust benchmark for work in this area.</p><p>5 0.74720502 <a title="45-lsi-5" href="./acl-2011-Identifying_Noun_Product_Features_that_Imply_Opinions.html">159 acl-2011-Identifying Noun Product Features that Imply Opinions</a></p>
<p>Author: Lei Zhang ; Bing Liu</p><p>Abstract: Identifying domain-dependent opinion words is a key problem in opinion mining and has been studied by several researchers. However, existing work has been focused on adjectives and to some extent verbs. Limited work has been done on nouns and noun phrases. In our work, we used the feature-based opinion mining model, and we found that in some domains nouns and noun phrases that indicate product features may also imply opinions. In many such cases, these nouns are not subjective but objective. Their involved sentences are also objective sentences and imply positive or negative opinions. Identifying such nouns and noun phrases and their polarities is very challenging but critical for effective opinion mining in these domains. To the best of our knowledge, this problem has not been studied in the literature. This paper proposes a method to deal with the problem. Experimental results based on real-life datasets show promising results. 1</p><p>6 0.74145365 <a title="45-lsi-6" href="./acl-2011-Content_Models_with_Attitude.html">82 acl-2011-Content Models with Attitude</a></p>
<p>7 0.72872788 <a title="45-lsi-7" href="./acl-2011-Semi-supervised_latent_variable_models_for_sentence-level_sentiment_analysis.html">279 acl-2011-Semi-supervised latent variable models for sentence-level sentiment analysis</a></p>
<p>8 0.66719812 <a title="45-lsi-8" href="./acl-2011-Sentiment_Analysis_of_Citations_using_Sentence_Structure-Based_Features.html">281 acl-2011-Sentiment Analysis of Citations using Sentence Structure-Based Features</a></p>
<p>9 0.66538417 <a title="45-lsi-9" href="./acl-2011-Automatically_Extracting_Polarity-Bearing_Topics_for_Cross-Domain_Sentiment_Classification.html">54 acl-2011-Automatically Extracting Polarity-Bearing Topics for Cross-Domain Sentiment Classification</a></p>
<p>10 0.65747529 <a title="45-lsi-10" href="./acl-2011-MemeTube%3A_A_Sentiment-based_Audiovisual_System_for_Analyzing_and_Displaying_Microblog_Messages.html">218 acl-2011-MemeTube: A Sentiment-based Audiovisual System for Analyzing and Displaying Microblog Messages</a></p>
<p>11 0.65263081 <a title="45-lsi-11" href="./acl-2011-Finding_Deceptive_Opinion_Spam_by_Any_Stretch_of_the_Imagination.html">136 acl-2011-Finding Deceptive Opinion Spam by Any Stretch of the Imagination</a></p>
<p>12 0.64027059 <a title="45-lsi-12" href="./acl-2011-Target-dependent_Twitter_Sentiment_Classification.html">292 acl-2011-Target-dependent Twitter Sentiment Classification</a></p>
<p>13 0.63436007 <a title="45-lsi-13" href="./acl-2011-Automatically_Predicting_Peer-Review_Helpfulness.html">55 acl-2011-Automatically Predicting Peer-Review Helpfulness</a></p>
<p>14 0.61468154 <a title="45-lsi-14" href="./acl-2011-Extracting_Opinion_Expressions_and_Their_Polarities_-_Exploration_of_Pipelines_and_Joint_Models.html">131 acl-2011-Extracting Opinion Expressions and Their Polarities - Exploration of Pipelines and Joint Models</a></p>
<p>15 0.5751192 <a title="45-lsi-15" href="./acl-2011-C-Feel-It%3A_A_Sentiment_Analyzer_for_Micro-blogs.html">64 acl-2011-C-Feel-It: A Sentiment Analyzer for Micro-blogs</a></p>
<p>16 0.56878871 <a title="45-lsi-16" href="./acl-2011-PsychoSentiWordNet.html">253 acl-2011-PsychoSentiWordNet</a></p>
<p>17 0.56655014 <a title="45-lsi-17" href="./acl-2011-Joint_Bilingual_Sentiment_Classification_with_Unlabeled_Parallel_Corpora.html">183 acl-2011-Joint Bilingual Sentiment Classification with Unlabeled Parallel Corpora</a></p>
<p>18 0.54408723 <a title="45-lsi-18" href="./acl-2011-Dr_Sentiment_Knows_Everything%21.html">105 acl-2011-Dr Sentiment Knows Everything!</a></p>
<p>19 0.54374105 <a title="45-lsi-19" href="./acl-2011-Subjectivity_and_Sentiment_Analysis_of_Modern_Standard_Arabic.html">289 acl-2011-Subjectivity and Sentiment Analysis of Modern Standard Arabic</a></p>
<p>20 0.48429197 <a title="45-lsi-20" href="./acl-2011-A_Pilot_Study_of_Opinion_Summarization_in_Conversations.html">21 acl-2011-A Pilot Study of Opinion Summarization in Conversations</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.016), (17, 0.044), (26, 0.034), (31, 0.015), (37, 0.147), (39, 0.07), (41, 0.045), (53, 0.044), (55, 0.018), (59, 0.027), (62, 0.228), (72, 0.02), (91, 0.019), (96, 0.175)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.92080534 <a title="45-lda-1" href="./acl-2011-Combining_Indicators_of_Allophony.html">74 acl-2011-Combining Indicators of Allophony</a></p>
<p>Author: Luc Boruta</p><p>Abstract: Allophonic rules are responsible for the great variety in phoneme realizations. Infants can not reliably infer abstract word representations without knowledge of their native allophonic grammar. We explore the hypothesis that some properties of infants’ input, referred to as indicators, are correlated with allophony. First, we provide an extensive evaluation of individual indicators that rely on distributional or lexical information. Then, we present a first evaluation of the combination of indicators of different types, considering both logical and numerical combinations schemes. Though distributional and lexical indicators are not redundant, straightforward combinations do not outperform individual indicators.</p><p>2 0.87815034 <a title="45-lda-2" href="./acl-2011-Wikulu%3A_An_Extensible_Architecture_for_Integrating_Natural_Language_Processing_Techniques_with_Wikis.html">338 acl-2011-Wikulu: An Extensible Architecture for Integrating Natural Language Processing Techniques with Wikis</a></p>
<p>Author: Daniel Bar ; Nicolai Erbs ; Torsten Zesch ; Iryna Gurevych</p><p>Abstract: We present Wikulu1, a system focusing on supporting wiki users with their everyday tasks by means of an intelligent interface. Wikulu is implemented as an extensible architecture which transparently integrates natural language processing (NLP) techniques with wikis. It is designed to be deployed with any wiki platform, and the current prototype integrates a wide range of NLP algorithms such as keyphrase extraction, link discovery, text segmentation, summarization, or text similarity. Additionally, we show how Wikulu can be applied for visually analyzing the results of NLP algorithms, educational purposes, and enabling semantic wikis.</p><p>same-paper 3 0.84332299 <a title="45-lda-3" href="./acl-2011-Aspect_Ranking%3A_Identifying_Important_Product_Aspects_from_Online_Consumer_Reviews.html">45 acl-2011-Aspect Ranking: Identifying Important Product Aspects from Online Consumer Reviews</a></p>
<p>Author: Jianxing Yu ; Zheng-Jun Zha ; Meng Wang ; Tat-Seng Chua</p><p>Abstract: In this paper, we dedicate to the topic of aspect ranking, which aims to automatically identify important product aspects from online consumer reviews. The important aspects are identified according to two observations: (a) the important aspects of a product are usually commented by a large number of consumers; and (b) consumers’ opinions on the important aspects greatly influence their overall opinions on the product. In particular, given consumer reviews of a product, we first identify the product aspects by a shallow dependency parser and determine consumers’ opinions on these aspects via a sentiment classifier. We then develop an aspect ranking algorithm to identify the important aspects by simultaneously considering the aspect frequency and the influence of consumers’ opinions given to each aspect on their overall opinions. The experimental results on 11 popular products in four domains demonstrate the effectiveness of our approach. We further apply the aspect ranking results to the application ofdocumentlevel sentiment classification, and improve the performance significantly.</p><p>4 0.83746272 <a title="45-lda-4" href="./acl-2011-Machine_Translation_System_Combination_by_Confusion_Forest.html">217 acl-2011-Machine Translation System Combination by Confusion Forest</a></p>
<p>Author: Taro Watanabe ; Eiichiro Sumita</p><p>Abstract: The state-of-the-art system combination method for machine translation (MT) is based on confusion networks constructed by aligning hypotheses with regard to word similarities. We introduce a novel system combination framework in which hypotheses are encoded as a confusion forest, a packed forest representing alternative trees. The forest is generated using syntactic consensus among parsed hypotheses: First, MT outputs are parsed. Second, a context free grammar is learned by extracting a set of rules that constitute the parse trees. Third, a packed forest is generated starting from the root symbol of the extracted grammar through non-terminal rewriting. The new hypothesis is produced by searching the best derivation in the forest. Experimental results on the WMT10 system combination shared task yield comparable performance to the conventional confusion network based method with smaller space.</p><p>5 0.833296 <a title="45-lda-5" href="./acl-2011-Unsupervised_Word_Alignment_with_Arbitrary_Features.html">325 acl-2011-Unsupervised Word Alignment with Arbitrary Features</a></p>
<p>Author: Chris Dyer ; Jonathan H. Clark ; Alon Lavie ; Noah A. Smith</p><p>Abstract: We introduce a discriminatively trained, globally normalized, log-linear variant of the lexical translation models proposed by Brown et al. (1993). In our model, arbitrary, nonindependent features may be freely incorporated, thereby overcoming the inherent limitation of generative models, which require that features be sensitive to the conditional independencies of the generative process. However, unlike previous work on discriminative modeling of word alignment (which also permits the use of arbitrary features), the parameters in our models are learned from unannotated parallel sentences, rather than from supervised word alignments. Using a variety of intrinsic and extrinsic measures, including translation performance, we show our model yields better alignments than generative baselines in a number of language pairs.</p><p>6 0.72557449 <a title="45-lda-6" href="./acl-2011-Joint_Bilingual_Sentiment_Classification_with_Unlabeled_Parallel_Corpora.html">183 acl-2011-Joint Bilingual Sentiment Classification with Unlabeled Parallel Corpora</a></p>
<p>7 0.72212291 <a title="45-lda-7" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<p>8 0.72037446 <a title="45-lda-8" href="./acl-2011-Target-dependent_Twitter_Sentiment_Classification.html">292 acl-2011-Target-dependent Twitter Sentiment Classification</a></p>
<p>9 0.71952558 <a title="45-lda-9" href="./acl-2011-Transition-based_Dependency_Parsing_with_Rich_Non-local_Features.html">309 acl-2011-Transition-based Dependency Parsing with Rich Non-local Features</a></p>
<p>10 0.71950924 <a title="45-lda-10" href="./acl-2011-Exploring_Entity_Relations_for_Named_Entity_Disambiguation.html">128 acl-2011-Exploring Entity Relations for Named Entity Disambiguation</a></p>
<p>11 0.71746588 <a title="45-lda-11" href="./acl-2011-Automatically_Extracting_Polarity-Bearing_Topics_for_Cross-Domain_Sentiment_Classification.html">54 acl-2011-Automatically Extracting Polarity-Bearing Topics for Cross-Domain Sentiment Classification</a></p>
<p>12 0.71726942 <a title="45-lda-12" href="./acl-2011-Chinese_sentence_segmentation_as_comma_classification.html">66 acl-2011-Chinese sentence segmentation as comma classification</a></p>
<p>13 0.71659714 <a title="45-lda-13" href="./acl-2011-Data_point_selection_for_cross-language_adaptation_of_dependency_parsers.html">92 acl-2011-Data point selection for cross-language adaptation of dependency parsers</a></p>
<p>14 0.71630478 <a title="45-lda-14" href="./acl-2011-Effects_of_Noun_Phrase_Bracketing_in_Dependency_Parsing_and_Machine_Translation.html">111 acl-2011-Effects of Noun Phrase Bracketing in Dependency Parsing and Machine Translation</a></p>
<p>15 0.71581131 <a title="45-lda-15" href="./acl-2011-An_Ensemble_Model_that_Combines_Syntactic_and_Semantic_Clustering_for_Discriminative_Dependency_Parsing.html">39 acl-2011-An Ensemble Model that Combines Syntactic and Semantic Clustering for Discriminative Dependency Parsing</a></p>
<p>16 0.71576059 <a title="45-lda-16" href="./acl-2011-Learning_Hierarchical_Translation_Structure_with_Linguistic_Annotations.html">202 acl-2011-Learning Hierarchical Translation Structure with Linguistic Annotations</a></p>
<p>17 0.71455085 <a title="45-lda-17" href="./acl-2011-Unsupervised_Part-of-Speech_Tagging_with_Bilingual_Graph-Based_Projections.html">323 acl-2011-Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</a></p>
<p>18 0.71324241 <a title="45-lda-18" href="./acl-2011-An_Algorithm_for_Unsupervised_Transliteration_Mining_with_an_Application_to_Word_Alignment.html">34 acl-2011-An Algorithm for Unsupervised Transliteration Mining with an Application to Word Alignment</a></p>
<p>19 0.71128654 <a title="45-lda-19" href="./acl-2011-Using_Multiple_Sources_to_Construct_a_Sentiment_Sensitive_Thesaurus_for_Cross-Domain_Sentiment_Classification.html">332 acl-2011-Using Multiple Sources to Construct a Sentiment Sensitive Thesaurus for Cross-Domain Sentiment Classification</a></p>
<p>20 0.71107447 <a title="45-lda-20" href="./acl-2011-An_exponential_translation_model_for_target_language_morphology.html">44 acl-2011-An exponential translation model for target language morphology</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
