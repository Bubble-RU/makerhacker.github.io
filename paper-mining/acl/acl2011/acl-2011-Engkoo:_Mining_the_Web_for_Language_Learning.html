<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>115 acl-2011-Engkoo: Mining the Web for Language Learning</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-115" href="#">acl2011-115</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>115 acl-2011-Engkoo: Mining the Web for Language Learning</h1>
<br/><p>Source: <a title="acl-2011-115-pdf" href="http://aclweb.org/anthology//P/P11/P11-4008.pdf">pdf</a></p><p>Author: Matthew R. Scott ; Xiaohua Liu ; Ming Zhou ; Microsoft Engkoo Team</p><p>Abstract: This paper presents Engkoo 1, a system for exploring and learning language. It is built primarily by mining translation knowledge from billions of web pages - using the Internet to catch language in motion. Currently Engkoo is built for Chinese users who are learning English; however the technology itself is language independent and can be extended in the future. At a system level, Engkoo is an application platform that supports a multitude of NLP technologies such as cross language retrieval, alignment, sentence classification, and statistical machine translation. The data set that supports this system is primarily built from mining a massive set of bilingual terms and sentences from across the web. Specifically, web pages that contain both Chinese and English are discovered and analyzed for parallelism, extracted and formulated into clear term definitions and sample sentences. This approach allows us to build perhaps the world’s largest lexicon linking both Chinese and English together - at the same time covering the most up-to-date terms as captured by the net.</p><p>Reference: <a title="acl-2011-115-reference" href="../acl2011_reference/acl-2011-Engkoo%3A_Mining_the_Web_for_Language_Learning_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 It is built primarily by mining translation knowledge from billions of web pages - using the Internet to catch language in motion. [sent-5, score-0.455]
</p><p>2 Currently Engkoo is built for Chinese users who are learning English; however the technology itself is language independent and can be extended in the future. [sent-6, score-0.148]
</p><p>3 The data set that supports this system is primarily built from mining a massive set of bilingual terms and sentences from across the web. [sent-8, score-0.464]
</p><p>4 Specifically, web pages that contain both Chinese and English are discovered and analyzed for parallelism, extracted and formulated into clear term definitions and sample sentences. [sent-9, score-0.312]
</p><p>5 Firstly, they often depend on static contents compiled by experts, and therefore cannot cover fresh words or new usages of existing words. [sent-13, score-0.155]
</p><p>6 44 functions are often limited, making it hard for users to effectively find information they are interested in. [sent-17, score-0.115]
</p><p>7 Lastly, existing tools tend to focus exclusively on dictionary, machine translation or language learning, losing out on synergy that can reduce inefficiencies in the user experience. [sent-18, score-0.164]
</p><p>8 Different from existing tools, it discovers fresh and authentic translation knowledge from billions of web pages - using the Internet to catch language in motion, and offering novel search functions that allow users efficient access to massive knowledge resources. [sent-20, score-0.72]
</p><p>9 Additionally, the system unifies the scenarios of dictionary, machine translation, and language learning into a seamless and more productive user experience. [sent-21, score-0.157]
</p><p>10 Engkoo derives its data from a process that continuously culls bilingual term/sentence pairs from the web, filters noise and conducts a series of NLP processes including POS tagging, dependency parsing and classification. [sent-22, score-0.406]
</p><p>11 Next, the mined bilingual pairs, together with the extracted linguistic knowledge, are indexed. [sent-24, score-0.406]
</p><p>12 Finally, it exposes a set of web services through which users can: 1) look up the definition of a word/phrase; 2) retrieve example sentences using keywords, POS tags or collocations; and 3) get the translation of a word/phrase/sentence. [sent-25, score-0.646]
</p><p>13 While Engkoo is currently built for Chinese users who are learning English, the technology itself is language independent and can be extended to sup-  port other language pairs in the future. [sent-26, score-0.223]
</p><p>14 We have deployed Engkoo online to Chinese internet users and gathered log data that suggests its PortlandP, Ororce geodnin,g UsS oAf, t 2h1e J AuCnLe-2H 0L1T1. [sent-27, score-0.166]
</p><p>15 0% are active users (make at least 1 query); active users make 8 queries per day on average. [sent-32, score-0.23]
</p><p>16 The service receives more than one million page views per day. [sent-33, score-0.113]
</p><p>17 Online dictionary lookup services can be divided into two categories. [sent-39, score-0.27]
</p><p>18 , Oxford dictionaries 2 and Longman contemporary English dictionary 3. [sent-42, score-0.173]
</p><p>19 Examples of these kinds of services include iCiba 4 and Lingoes 5. [sent-43, score-0.094]
</p><p>20 The second depends mainly on mined bilingual term/sentence pairs, e. [sent-44, score-0.406]
</p><p>21 , fuzzy POS-based search, classifier filtering), and an integrated language learning experience (e. [sent-49, score-0.109]
</p><p>22 , translation with interactive word alignment, and photorealistic lip-synced video tutors). [sent-51, score-0.135]
</p><p>23 (2006) uses document object model (DOM) tree mapping to extract bilingual sentence pairs from aligned bilingual web pages. [sent-54, score-0.741]
</p><p>24 (2009b) exploits collective patterns to extract bilingual term/sentence pairs from one web page. [sent-56, score-0.489]
</p><p>25 (2010) proposes training a SVM-based classifier with multiple linguistic features to evaluate the quality of mined corpora. [sent-58, score-0.186]
</p><p>26 Following this line of work, Engkoo implements its mining pipeline with a focus on robustness and speed, and is designed to work on a very large volume of web pages. [sent-62, score-0.274]
</p><p>27 The first layer consists of the crawler and the raw web page storage. [sent-77, score-0.44]
</p><p>28 The crawler periodically downloads two kinds of web pages, which are put into the storage. [sent-78, score-0.315]
</p><p>29 The first kind of web pages are parallel web pages (describe the same contents but with different languages, often from bilingual sites, e. [sent-79, score-0.692]
</p><p>30 , government sites), and the second are those containing bilingual contents. [sent-81, score-0.252]
</p><p>31 A list of seed URLs are maintained and updated after each round of the mining process. [sent-82, score-0.082]
</p><p>32 The second layer consists of the extractor, the filter, the classifiers and the readability evaluator, which are applied sequentially. [sent-83, score-0.18]
</p><p>33 The extractor scans the raw web page storage and identifies bilingual web page pairs using URL patterns. [sent-84, score-0.885]
</p><p>34 For example,  two web pages are parallel if their URLs are in the form of “· · · /zh/· · · ” and “· · · /en/· · · ”, respectively. [sent-85, score-0.219]
</p><p>35 (2006) the extractor then extracts bilingual term/sentence pairs from parallel web pages. [sent-87, score-0.636]
</p><p>36 Meanwhile, it identifies web pages with bilingual contents, and mines bilingual term/sentence pairs from them using the method proposed by Jiang et al. [sent-88, score-0.741]
</p><p>37 The readability evaluator assigns a score to each term/sentence pair according to Formula 1 7. [sent-96, score-0.087]
</p><p>38 Firstly, a list of top sites from which a good number of high  quality pairs are obtained, is figured out; these are used as seeds by the crawler. [sent-101, score-0.185]
</p><p>39 Secondly, bilingual term/sentence pairs extracted from traditional dictionaries are fed into this layer as well, but with the quality checking process ignored. [sent-102, score-0.521]
</p><p>40 The third layer consists of a series of NLP components, which conduct POS tagging, dependency parsing, and word alignment, respectively. [sent-103, score-0.08]
</p><p>41 It also includes components that learn translation information and collocations from the parsed term/sentence pairs. [sent-104, score-0.228]
</p><p>42 Based on the learned statistical information, two phrase-based statistical machine translation (SMT) systems are trained, which can then translate sentences from one language to the other and vice versa. [sent-105, score-0.14]
</p><p>43 Finally, the mined bilingual term/sentence pairs, together with their parsed information, are stored and indexed with a multi-level indexing engine, a core component of this layer. [sent-106, score-0.406]
</p><p>44 The indexer is called multi-level since it uses not only keywords but also POS tags and dependency triples (e. [sent-107, score-0.163]
</p><p>45 The fourth layer consists of a set of services that expose the mined term/sentence pairs and the linguistic knowledge based on the built index. [sent-113, score-0.477]
</p><p>46 On top of these services, we construct a web application, supporting a wide range offunctions, such as searching bilingual terms/sentences, translation and so on. [sent-114, score-0.514]
</p><p>47 The crawler scans the Internet to get parallel and bilingual web pages. [sent-118, score-0.678]
</p><p>48 It employs a set of heuristic rules related to URLs and contents to filter unwanted pages. [sent-119, score-0.115]
</p><p>49 That is, it uses these URLs as seeds, and then conducts a deep-first crawling with a maximum allowable depth of 5. [sent-121, score-0.088]
</p><p>50 In this way, the crawler tries  to avoid repeatedly downloading the same web page. [sent-124, score-0.315]
</p><p>51 A bilingual term/sentence extractor is implemented following Shi et al. [sent-128, score-0.342]
</p><p>52 It works in two modes, mining from parallel web pages and from bilingual web pages. [sent-131, score-0.715]
</p><p>53 Parallel web pages are identified recursively in the following way. [sent-132, score-0.162]
</p><p>54 Given a pair of parallel web pages, the URLs in two pages are extracted respectively, and are further aligned according to their positions in DOM trees, so that more parallel pages can be obtained. [sent-133, score-0.276]
</p><p>55 (2007) is implemented as well to mine the definition of a given term using search engines. [sent-135, score-0.132]
</p><p>56 By now, we have obtained about 1,050 million bilingual term pairs and 100 million bilingual sentence pairs. [sent-136, score-0.698]
</p><p>57 The filter takes three steps to drop low quality pairs. [sent-138, score-0.088]
</p><p>58 In Engkoo, the language model is a 5-gram language model trained on news articles using SRILM (Stolcke, 2002), while the translation model is based on a manually compiled translation table. [sent-146, score-0.23]
</p><p>59 We have got about 20 million bilingual term pairs and 15 million bilingual sentence pairs after filtering noise. [sent-147, score-0.773]
</p><p>60 For each classifier, about 10,000 sentence pairs are manually annotated for training/development/testing. [sent-150, score-0.075]
</p><p>61 Our SMT systems are phrase-based, trained on the web mined bilingual sentence pairs using the GIZA++ (Och and Ney, 2000) alignment  s′  p(s)p(s′  p(s′  package, with a collaborative decoder similar to Li et al. [sent-154, score-0.74]
</p><p>62 At the heart of the indexer is the inverted lists, each of which contains an entry pointing to an ordered list of the related term/sentence pairs. [sent-160, score-0.081]
</p><p>63 The traditional dictionary interface is extended with a blending of web-mined and ranked term definitions, sample sentences, synonyms, collocations, and phonetically similar terms. [sent-165, score-0.313]
</p><p>64 The result page user experience includes an intuitive comparable tabs interface described in Jiang et al. [sent-166, score-0.289]
</p><p>65 (2009a) that effectively exposes differences be-  47 tween similar terms. [sent-167, score-0.092]
</p><p>66 The search experience is augmented with a fuzzy auto completion experience, which besides traditional prefix matching is also robust against errors and allows for alternative inputs. [sent-168, score-0.204]
</p><p>67 All of these contain inline micro translations to help users narrow in on their intended search. [sent-169, score-0.115]
</p><p>68 Errors are resolved by a blend of edit-distance and phonetic search algorithms tuned for Chinese user behavior patterns identified by user study. [sent-170, score-0.176]
</p><p>69 The definitions for the term derived from traditional dictionary sources are included in the main definition area and refer to the noise of a small bird. [sent-173, score-0.296]
</p><p>70 Augmenting the definition area are “Web translations,” which include the contemporary use of the word standing for micro-blogging. [sent-174, score-0.084]
</p><p>71 Web-mined bilingual sample sentences are also presented and ranked by popularity metrics; this demonstrates the modern usage of the term. [sent-175, score-0.365]
</p><p>72 Engkoo exposes a novel search and interactive exploration interface for the ever-growing web-mined bilingual sample sentences in its database. [sent-177, score-0.595]
</p><p>73 Emphasis is placed on sample sentences in Engkoo because of their crucial role in language learning. [sent-178, score-0.113]
</p><p>74 One can search for sentences as they would in traditional search engines or concordancers. [sent-180, score-0.183]
</p><p>75 Further, sentences can be filtered based on classifiers such as oral, written, and technical styles, source, and language difficulty. [sent-182, score-0.097]
</p><p>76 Additionally sample sentences for terms can be filtered by their inflection and the semantics of a particular definition. [sent-183, score-0.113]
</p><p>77 Interactivity can be found in the word alignment between the languages as one moves his or her mouse over the words, which can also be clicked on for deeper exploration. [sent-184, score-0.064]
</p><p>78 Sample sentences between two similar words can be displayed side-by-side in a tabbed  (a) A screenshot of the definition and sample sentence areas of a Engkoo result page. [sent-186, score-0.278]
</p><p>79 (b) A screenshot of samples sentences for the POS-wildcard query “v. [sent-187, score-0.136]
</p><p>80 (c) A screenshot of machine translation integrated into the dictionary experience, where the top pane shows results of machine translation while the bottom pane displays example sentences mined from the web. [sent-189, score-0.66]
</p><p>81 48  user interface to easily expose the subtleties between usages. [sent-191, score-0.16]
</p><p>82 In the example seen in Figure 2(b), a user has searched for the collocation verb+TV, represented by the query “v. [sent-192, score-0.133]
</p><p>83 ” In the results, we find fresh and authentic sample sentences mined from the web, the first of which contains “watch TV,” the most common collocation, as the top result. [sent-194, score-0.38]
</p><p>84 Additionally, the corresponding keyword in Chinese is automatically highlighted using statistical alignment techniques. [sent-195, score-0.064]
</p><p>85 For many users, the difference between a machine translation (MT) system and a translation dictionary are not entirely clear. [sent-197, score-0.297]
</p><p>86 For shorter MT queries, sample sentences might also be returned as one can see in Figure 2(c) which expands the search and also raises confidence in a translation as one can observe it used on the web. [sent-199, score-0.261]
</p><p>87 Like the sample sentences, word alignment is also exposed on the machine translation. [sent-200, score-0.137]
</p><p>88 As the alignment naturally serves as a word breaker, users can click the selection for  a lookup which would open a new tab with the definition. [sent-201, score-0.258]
</p><p>89 This is especially useful in cases where a user might want to find alternatives to a particular part of a translation. [sent-202, score-0.094]
</p><p>90 Note that the seemingly single line dictionary search box is also adapted to MT behavior, allowing users to paste in multi-line text as it can detect and unfold itself to a larger text area as needed. [sent-203, score-0.26]
</p><p>91 4  Conclusions and Future work  We have presented Engkoo, a novel online translation system which uniquely unifies the scenarios of dictionary, machine translation, and language learning. [sent-204, score-0.193]
</p><p>92 The features of the offering are based on an ever-expanding data set derived from state-of-the-art web mining and NLP techniques. [sent-205, score-0.291]
</p><p>93 Direct user feedback and implicit log data suggest that the service is effective for both translation utility and language learning, with advantages over existing services. [sent-207, score-0.193]
</p><p>94 In future work, we are examining extracting language  49 knowledge from the real-time web for translation in news scenarios. [sent-208, score-0.262]
</p><p>95 Additionally, we are actively mining other language pairs to build a multi-language learning system. [sent-209, score-0.157]
</p><p>96 Combinable tabs: An interactive method of information comparison using a combinable tabbed document interface. [sent-218, score-0.157]
</p><p>97 Mining bilingual data  from the web with adaptively learnt patterns. [sent-222, score-0.414]
</p><p>98 Collaborative decoding: Partial hypothesis re-ranking using translation consensus between decoders. [sent-230, score-0.1]
</p><p>99 Evaluating the quality of web-mined bilingual sentences using multiple linguistic features. [sent-234, score-0.324]
</p><p>100 A dom tree alignment model for mining parallel data from the web. [sent-246, score-0.269]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('engkoo', 0.641), ('bilingual', 0.252), ('web', 0.162), ('mined', 0.154), ('crawler', 0.153), ('ming', 0.123), ('urls', 0.12), ('users', 0.115), ('xiaohua', 0.111), ('jiang', 0.109), ('translation', 0.1), ('dictionary', 0.097), ('services', 0.094), ('tv', 0.092), ('exposes', 0.092), ('extractor', 0.09), ('collocations', 0.084), ('mining', 0.082), ('indexer', 0.081), ('layer', 0.08), ('lookup', 0.079), ('pairs', 0.075), ('sample', 0.073), ('experience', 0.071), ('liu', 0.069), ('dom', 0.066), ('fresh', 0.066), ('chinese', 0.065), ('user', 0.064), ('alignment', 0.064), ('combinable', 0.061), ('tabbed', 0.061), ('screenshot', 0.061), ('contents', 0.059), ('parallel', 0.057), ('massive', 0.057), ('classifiers', 0.057), ('zhou', 0.057), ('filter', 0.056), ('smt', 0.055), ('interface', 0.055), ('tabs', 0.054), ('pane', 0.054), ('scans', 0.054), ('cheng', 0.053), ('shi', 0.053), ('internet', 0.051), ('wild', 0.05), ('unifies', 0.05), ('search', 0.048), ('traditional', 0.047), ('authentic', 0.047), ('conducts', 0.047), ('niu', 0.047), ('offering', 0.047), ('firstly', 0.045), ('page', 0.045), ('sites', 0.045), ('evaluator', 0.044), ('dongdong', 0.044), ('secondly', 0.044), ('components', 0.044), ('keywords', 0.043), ('readability', 0.043), ('scenarios', 0.043), ('definition', 0.043), ('watch', 0.042), ('term', 0.041), ('expose', 0.041), ('billions', 0.041), ('crawling', 0.041), ('contemporary', 0.041), ('sentences', 0.04), ('triples', 0.039), ('li', 0.039), ('million', 0.039), ('fuzzy', 0.038), ('mu', 0.038), ('url', 0.038), ('catch', 0.037), ('definitions', 0.036), ('interactive', 0.035), ('query', 0.035), ('pos', 0.035), ('dictionaries', 0.035), ('additionally', 0.035), ('collocation', 0.034), ('sun', 0.034), ('collaborative', 0.033), ('seeds', 0.033), ('built', 0.033), ('meanwhile', 0.033), ('quality', 0.032), ('mt', 0.032), ('noise', 0.032), ('implements', 0.03), ('alternatives', 0.03), ('compiled', 0.03), ('experts', 0.029), ('service', 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="115-tfidf-1" href="./acl-2011-Engkoo%3A_Mining_the_Web_for_Language_Learning.html">115 acl-2011-Engkoo: Mining the Web for Language Learning</a></p>
<p>Author: Matthew R. Scott ; Xiaohua Liu ; Ming Zhou ; Microsoft Engkoo Team</p><p>Abstract: This paper presents Engkoo 1, a system for exploring and learning language. It is built primarily by mining translation knowledge from billions of web pages - using the Internet to catch language in motion. Currently Engkoo is built for Chinese users who are learning English; however the technology itself is language independent and can be extended in the future. At a system level, Engkoo is an application platform that supports a multitude of NLP technologies such as cross language retrieval, alignment, sentence classification, and statistical machine translation. The data set that supports this system is primarily built from mining a massive set of bilingual terms and sentences from across the web. Specifically, web pages that contain both Chinese and English are discovered and analyzed for parallelism, extracted and formulated into clear term definitions and sample sentences. This approach allows us to build perhaps the world’s largest lexicon linking both Chinese and English together - at the same time covering the most up-to-date terms as captured by the net.</p><p>2 0.12492705 <a title="115-tfidf-2" href="./acl-2011-Clustering_Comparable_Corpora_For_Bilingual_Lexicon_Extraction.html">70 acl-2011-Clustering Comparable Corpora For Bilingual Lexicon Extraction</a></p>
<p>Author: Bo Li ; Eric Gaussier ; Akiko Aizawa</p><p>Abstract: We study in this paper the problem of enhancing the comparability of bilingual corpora in order to improve the quality of bilingual lexicons extracted from comparable corpora. We introduce a clustering-based approach for enhancing corpus comparability which exploits the homogeneity feature of the corpus, and finally preserves most of the vocabulary of the original corpus. Our experiments illustrate the well-foundedness of this method and show that the bilingual lexicons obtained from the homogeneous corpus are of better quality than the lexicons obtained with previous approaches.</p><p>3 0.12303927 <a title="115-tfidf-3" href="./acl-2011-Search_in_the_Lost_Sense_of_%22Query%22%3A_Question_Formulation_in_Web_Search_Queries_and_its_Temporal_Changes.html">271 acl-2011-Search in the Lost Sense of "Query": Question Formulation in Web Search Queries and its Temporal Changes</a></p>
<p>Author: Bo Pang ; Ravi Kumar</p><p>Abstract: Web search is an information-seeking activity. Often times, this amounts to a user seeking answers to a question. However, queries, which encode user’s information need, are typically not expressed as full-length natural language sentences in particular, as questions. Rather, they consist of one or more text fragments. As humans become more searchengine-savvy, do natural-language questions still have a role to play in web search? Through a systematic, large-scale study, we find to our surprise that as time goes by, web users are more likely to use questions to express their search intent. —</p><p>4 0.10703111 <a title="115-tfidf-4" href="./acl-2011-Domain_Adaptation_for_Machine_Translation_by_Mining_Unseen_Words.html">104 acl-2011-Domain Adaptation for Machine Translation by Mining Unseen Words</a></p>
<p>Author: Hal Daume III ; Jagadeesh Jagarlamudi</p><p>Abstract: We show that unseen words account for a large part of the translation error when moving to new domains. Using an extension of a recent approach to mining translations from comparable corpora (Haghighi et al., 2008), we are able to find translations for otherwise OOV terms. We show several approaches to integrating such translations into a phrasebased translation system, yielding consistent improvements in translations quality (between 0.5 and 1.5 Bleu points) on four domains and two language pairs.</p><p>5 0.10444549 <a title="115-tfidf-5" href="./acl-2011-From_Bilingual_Dictionaries_to_Interlingual_Document_Representations.html">139 acl-2011-From Bilingual Dictionaries to Interlingual Document Representations</a></p>
<p>Author: Jagadeesh Jagarlamudi ; Hal Daume III ; Raghavendra Udupa</p><p>Abstract: Mapping documents into an interlingual representation can help bridge the language barrier of a cross-lingual corpus. Previous approaches use aligned documents as training data to learn an interlingual representation, making them sensitive to the domain of the training data. In this paper, we learn an interlingual representation in an unsupervised manner using only a bilingual dictionary. We first use the bilingual dictionary to find candidate document alignments and then use them to find an interlingual representation. Since the candidate alignments are noisy, we de- velop a robust learning algorithm to learn the interlingual representation. We show that bilingual dictionaries generalize to different domains better: our approach gives better performance than either a word by word translation method or Canonical Correlation Analysis (CCA) trained on a different domain.</p><p>6 0.10090181 <a title="115-tfidf-6" href="./acl-2011-Rare_Word_Translation_Extraction_from_Aligned_Comparable_Documents.html">259 acl-2011-Rare Word Translation Extraction from Aligned Comparable Documents</a></p>
<p>7 0.099159598 <a title="115-tfidf-7" href="./acl-2011-Joint_Bilingual_Sentiment_Classification_with_Unlabeled_Parallel_Corpora.html">183 acl-2011-Joint Bilingual Sentiment Classification with Unlabeled Parallel Corpora</a></p>
<p>8 0.096801281 <a title="115-tfidf-8" href="./acl-2011-How_Much_Can_We_Gain_from_Supervised_Word_Alignment%3F.html">152 acl-2011-How Much Can We Gain from Supervised Word Alignment?</a></p>
<p>9 0.096084394 <a title="115-tfidf-9" href="./acl-2011-Interactive_Group_Suggesting_for_Twitter.html">177 acl-2011-Interactive Group Suggesting for Twitter</a></p>
<p>10 0.0928936 <a title="115-tfidf-10" href="./acl-2011-Why_Press_Backspace%3F_Understanding_User_Input_Behaviors_in_Chinese_Pinyin_Input_Method.html">336 acl-2011-Why Press Backspace? Understanding User Input Behaviors in Chinese Pinyin Input Method</a></p>
<p>11 0.089004762 <a title="115-tfidf-11" href="./acl-2011-Consistent_Translation_using_Discriminative_Learning_-_A_Translation_Memory-inspired_Approach.html">81 acl-2011-Consistent Translation using Discriminative Learning - A Translation Memory-inspired Approach</a></p>
<p>12 0.085703962 <a title="115-tfidf-12" href="./acl-2011-Reordering_with_Source_Language_Collocations.html">266 acl-2011-Reordering with Source Language Collocations</a></p>
<p>13 0.085189618 <a title="115-tfidf-13" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<p>14 0.0816705 <a title="115-tfidf-14" href="./acl-2011-A_Mobile_Touchable_Application_for_Online_Topic_Graph_Extraction_and_Exploration_of_Web_Content.html">19 acl-2011-A Mobile Touchable Application for Online Topic Graph Extraction and Exploration of Web Content</a></p>
<p>15 0.080264904 <a title="115-tfidf-15" href="./acl-2011-Using_Bilingual_Parallel_Corpora_for_Cross-Lingual_Textual_Entailment.html">327 acl-2011-Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment</a></p>
<p>16 0.075872943 <a title="115-tfidf-16" href="./acl-2011-Automatic_Evaluation_of_Chinese_Translation_Output%3A_Word-Level_or_Character-Level%3F.html">49 acl-2011-Automatic Evaluation of Chinese Translation Output: Word-Level or Character-Level?</a></p>
<p>17 0.074181624 <a title="115-tfidf-17" href="./acl-2011-Jigs_and_Lures%3A_Associating_Web_Queries_with_Structured_Entities.html">181 acl-2011-Jigs and Lures: Associating Web Queries with Structured Entities</a></p>
<p>18 0.073535524 <a title="115-tfidf-18" href="./acl-2011-Goodness%3A_A_Method_for_Measuring_Machine_Translation_Confidence.html">146 acl-2011-Goodness: A Method for Measuring Machine Translation Confidence</a></p>
<p>19 0.073300235 <a title="115-tfidf-19" href="./acl-2011-Phrase-Based_Translation_Model_for_Question_Retrieval_in_Community_Question_Answer_Archives.html">245 acl-2011-Phrase-Based Translation Model for Question Retrieval in Community Question Answer Archives</a></p>
<p>20 0.072630696 <a title="115-tfidf-20" href="./acl-2011-Hypothesis_Mixture_Decoding_for_Statistical_Machine_Translation.html">155 acl-2011-Hypothesis Mixture Decoding for Statistical Machine Translation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.208), (1, -0.043), (2, 0.039), (3, 0.111), (4, -0.032), (5, -0.051), (6, 0.03), (7, -0.101), (8, 0.044), (9, -0.024), (10, -0.017), (11, 0.017), (12, 0.043), (13, -0.076), (14, -0.021), (15, 0.007), (16, 0.069), (17, -0.011), (18, 0.085), (19, -0.029), (20, -0.007), (21, 0.002), (22, 0.021), (23, 0.051), (24, -0.017), (25, -0.027), (26, -0.03), (27, 0.127), (28, 0.013), (29, -0.136), (30, 0.091), (31, 0.023), (32, 0.009), (33, -0.073), (34, -0.022), (35, -0.068), (36, 0.017), (37, -0.011), (38, 0.026), (39, 0.028), (40, -0.033), (41, 0.048), (42, 0.038), (43, 0.071), (44, 0.037), (45, -0.041), (46, -0.028), (47, 0.005), (48, 0.051), (49, 0.063)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94674969 <a title="115-lsi-1" href="./acl-2011-Engkoo%3A_Mining_the_Web_for_Language_Learning.html">115 acl-2011-Engkoo: Mining the Web for Language Learning</a></p>
<p>Author: Matthew R. Scott ; Xiaohua Liu ; Ming Zhou ; Microsoft Engkoo Team</p><p>Abstract: This paper presents Engkoo 1, a system for exploring and learning language. It is built primarily by mining translation knowledge from billions of web pages - using the Internet to catch language in motion. Currently Engkoo is built for Chinese users who are learning English; however the technology itself is language independent and can be extended in the future. At a system level, Engkoo is an application platform that supports a multitude of NLP technologies such as cross language retrieval, alignment, sentence classification, and statistical machine translation. The data set that supports this system is primarily built from mining a massive set of bilingual terms and sentences from across the web. Specifically, web pages that contain both Chinese and English are discovered and analyzed for parallelism, extracted and formulated into clear term definitions and sample sentences. This approach allows us to build perhaps the world’s largest lexicon linking both Chinese and English together - at the same time covering the most up-to-date terms as captured by the net.</p><p>2 0.71005917 <a title="115-lsi-2" href="./acl-2011-Clustering_Comparable_Corpora_For_Bilingual_Lexicon_Extraction.html">70 acl-2011-Clustering Comparable Corpora For Bilingual Lexicon Extraction</a></p>
<p>Author: Bo Li ; Eric Gaussier ; Akiko Aizawa</p><p>Abstract: We study in this paper the problem of enhancing the comparability of bilingual corpora in order to improve the quality of bilingual lexicons extracted from comparable corpora. We introduce a clustering-based approach for enhancing corpus comparability which exploits the homogeneity feature of the corpus, and finally preserves most of the vocabulary of the original corpus. Our experiments illustrate the well-foundedness of this method and show that the bilingual lexicons obtained from the homogeneous corpus are of better quality than the lexicons obtained with previous approaches.</p><p>3 0.69631505 <a title="115-lsi-3" href="./acl-2011-From_Bilingual_Dictionaries_to_Interlingual_Document_Representations.html">139 acl-2011-From Bilingual Dictionaries to Interlingual Document Representations</a></p>
<p>Author: Jagadeesh Jagarlamudi ; Hal Daume III ; Raghavendra Udupa</p><p>Abstract: Mapping documents into an interlingual representation can help bridge the language barrier of a cross-lingual corpus. Previous approaches use aligned documents as training data to learn an interlingual representation, making them sensitive to the domain of the training data. In this paper, we learn an interlingual representation in an unsupervised manner using only a bilingual dictionary. We first use the bilingual dictionary to find candidate document alignments and then use them to find an interlingual representation. Since the candidate alignments are noisy, we de- velop a robust learning algorithm to learn the interlingual representation. We show that bilingual dictionaries generalize to different domains better: our approach gives better performance than either a word by word translation method or Canonical Correlation Analysis (CCA) trained on a different domain.</p><p>4 0.66789436 <a title="115-lsi-4" href="./acl-2011-Rare_Word_Translation_Extraction_from_Aligned_Comparable_Documents.html">259 acl-2011-Rare Word Translation Extraction from Aligned Comparable Documents</a></p>
<p>Author: Emmanuel Prochasson ; Pascale Fung</p><p>Abstract: We present a first known result of high precision rare word bilingual extraction from comparable corpora, using aligned comparable documents and supervised classification. We incorporate two features, a context-vector similarity and a co-occurrence model between words in aligned documents in a machine learning approach. We test our hypothesis on different pairs of languages and corpora. We obtain very high F-Measure between 80% and 98% for recognizing and extracting correct translations for rare terms (from 1to 5 occurrences). Moreover, we show that our system can be trained on a pair of languages and test on a different pair of languages, obtaining a F-Measure of 77% for the classification of Chinese-English translations using a training corpus of Spanish-French. Our method is therefore even potentially applicable to low resources languages without training data.</p><p>5 0.63265198 <a title="115-lsi-5" href="./acl-2011-Why_Press_Backspace%3F_Understanding_User_Input_Behaviors_in_Chinese_Pinyin_Input_Method.html">336 acl-2011-Why Press Backspace? Understanding User Input Behaviors in Chinese Pinyin Input Method</a></p>
<p>Author: Yabin Zheng ; Lixing Xie ; Zhiyuan Liu ; Maosong Sun ; Yang Zhang ; Liyun Ru</p><p>Abstract: Chinese Pinyin input method is very important for Chinese language information processing. Users may make errors when they are typing in Chinese words. In this paper, we are concerned with the reasons that cause the errors. Inspired by the observation that pressing backspace is one of the most common user behaviors to modify the errors, we collect 54, 309, 334 error-correction pairs from a realworld data set that contains 2, 277, 786 users via backspace operations. In addition, we present a comparative analysis of the data to achieve a better understanding of users’ input behaviors. Comparisons with English typos suggest that some language-specific properties result in a part of Chinese input errors. 1</p><p>6 0.62301683 <a title="115-lsi-6" href="./acl-2011-Wikulu%3A_An_Extensible_Architecture_for_Integrating_Natural_Language_Processing_Techniques_with_Wikis.html">338 acl-2011-Wikulu: An Extensible Architecture for Integrating Natural Language Processing Techniques with Wikis</a></p>
<p>7 0.61987722 <a title="115-lsi-7" href="./acl-2011-ConsentCanvas%3A_Automatic_Texturing_for_Improved_Readability_in_End-User_License_Agreements.html">80 acl-2011-ConsentCanvas: Automatic Texturing for Improved Readability in End-User License Agreements</a></p>
<p>8 0.59261405 <a title="115-lsi-8" href="./acl-2011-Hindi_to_Punjabi_Machine_Translation_System.html">151 acl-2011-Hindi to Punjabi Machine Translation System</a></p>
<p>9 0.57593131 <a title="115-lsi-9" href="./acl-2011-A_Speech-based_Just-in-Time_Retrieval_System_using_Semantic_Search.html">26 acl-2011-A Speech-based Just-in-Time Retrieval System using Semantic Search</a></p>
<p>10 0.57314634 <a title="115-lsi-10" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<p>11 0.54757065 <a title="115-lsi-11" href="./acl-2011-Predicting_Clicks_in_a_Vocabulary_Learning_System.html">248 acl-2011-Predicting Clicks in a Vocabulary Learning System</a></p>
<p>12 0.54462028 <a title="115-lsi-12" href="./acl-2011-ParaSense_or_How_to_Use_Parallel_Corpora_for_Word_Sense_Disambiguation.html">240 acl-2011-ParaSense or How to Use Parallel Corpora for Word Sense Disambiguation</a></p>
<p>13 0.5396508 <a title="115-lsi-13" href="./acl-2011-Together_We_Can%3A_Bilingual_Bootstrapping_for_WSD.html">304 acl-2011-Together We Can: Bilingual Bootstrapping for WSD</a></p>
<p>14 0.52345085 <a title="115-lsi-14" href="./acl-2011-I_Thou_Thee%2C_Thou_Traitor%3A_Predicting_Formal_vs._Informal_Address_in_English_Literature.html">157 acl-2011-I Thou Thee, Thou Traitor: Predicting Formal vs. Informal Address in English Literature</a></p>
<p>15 0.52323598 <a title="115-lsi-15" href="./acl-2011-Clairlib%3A_A_Toolkit_for_Natural_Language_Processing%2C_Information_Retrieval%2C_and_Network_Analysis.html">67 acl-2011-Clairlib: A Toolkit for Natural Language Processing, Information Retrieval, and Network Analysis</a></p>
<p>16 0.52275652 <a title="115-lsi-16" href="./acl-2011-Domain_Adaptation_for_Machine_Translation_by_Mining_Unseen_Words.html">104 acl-2011-Domain Adaptation for Machine Translation by Mining Unseen Words</a></p>
<p>17 0.51963001 <a title="115-lsi-17" href="./acl-2011-A_Graph_Approach_to_Spelling_Correction_in_Domain-Centric_Search.html">13 acl-2011-A Graph Approach to Spelling Correction in Domain-Centric Search</a></p>
<p>18 0.51242214 <a title="115-lsi-18" href="./acl-2011-Interactive_Group_Suggesting_for_Twitter.html">177 acl-2011-Interactive Group Suggesting for Twitter</a></p>
<p>19 0.51091808 <a title="115-lsi-19" href="./acl-2011-A_Fast_and_Accurate_Method_for_Approximate_String_Search.html">11 acl-2011-A Fast and Accurate Method for Approximate String Search</a></p>
<p>20 0.50585592 <a title="115-lsi-20" href="./acl-2011-Translationese_and_Its_Dialects.html">311 acl-2011-Translationese and Its Dialects</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.032), (17, 0.035), (26, 0.436), (37, 0.054), (39, 0.047), (41, 0.051), (55, 0.026), (59, 0.022), (72, 0.038), (91, 0.041), (96, 0.129)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.91194016 <a title="115-lda-1" href="./acl-2011-Dr_Sentiment_Knows_Everything%21.html">105 acl-2011-Dr Sentiment Knows Everything!</a></p>
<p>Author: Amitava Das ; Sivaji Bandyopadhyay</p><p>Abstract: Sentiment analysis is one of the hot demanding research areas since last few decades. Although a formidable amount of research have been done, the existing reported solutions or available systems are still far from perfect or do not meet the satisfaction level of end users’ . The main issue is the various conceptual rules that govern sentiment and there are even more clues (possibly unlimited) that can convey these concepts from realization to verbalization of a human being. Human psychology directly relates to the unrevealed clues and governs the sentiment realization of us. Human psychology relates many things like social psychology, culture, pragmatics and many more endless intelligent aspects of civilization. Proper incorporation of human psychology into computational sentiment knowledge representation may solve the problem. In the present paper we propose a template based online interactive gaming technology, called Dr Sentiment to automatically create the PsychoSentiWordNet involving internet population. The PsychoSentiWordNet is an extension of SentiWordNet that presently holds human psychological knowledge on a few aspects along with sentiment knowledge.</p><p>same-paper 2 0.87238717 <a title="115-lda-2" href="./acl-2011-Engkoo%3A_Mining_the_Web_for_Language_Learning.html">115 acl-2011-Engkoo: Mining the Web for Language Learning</a></p>
<p>Author: Matthew R. Scott ; Xiaohua Liu ; Ming Zhou ; Microsoft Engkoo Team</p><p>Abstract: This paper presents Engkoo 1, a system for exploring and learning language. It is built primarily by mining translation knowledge from billions of web pages - using the Internet to catch language in motion. Currently Engkoo is built for Chinese users who are learning English; however the technology itself is language independent and can be extended in the future. At a system level, Engkoo is an application platform that supports a multitude of NLP technologies such as cross language retrieval, alignment, sentence classification, and statistical machine translation. The data set that supports this system is primarily built from mining a massive set of bilingual terms and sentences from across the web. Specifically, web pages that contain both Chinese and English are discovered and analyzed for parallelism, extracted and formulated into clear term definitions and sample sentences. This approach allows us to build perhaps the world’s largest lexicon linking both Chinese and English together - at the same time covering the most up-to-date terms as captured by the net.</p><p>3 0.82041413 <a title="115-lda-3" href="./acl-2011-PsychoSentiWordNet.html">253 acl-2011-PsychoSentiWordNet</a></p>
<p>Author: Amitava Das</p><p>Abstract: Sentiment analysis is one of the hot demanding research areas since last few decades. Although a formidable amount of research has been done but still the existing reported solutions or available systems are far from perfect or to meet the satisfaction level of end user's. The main issue may be there are many conceptual rules that govern sentiment, and there are even more clues (possibly unlimited) that can convey these concepts from realization to verbalization of a human being. Human psychology directly relates to the unrevealed clues; govern the sentiment realization of us. Human psychology relates many things like social psychology, culture, pragmatics and many more endless intelligent aspects of civilization. Proper incorporation of human psychology into computational sentiment knowledge representation may solve the problem. PsychoSentiWordNet is an extension over SentiWordNet that holds human psychological knowledge and sentiment knowledge simultaneously. 1</p><p>4 0.81745821 <a title="115-lda-4" href="./acl-2011-Rare_Word_Translation_Extraction_from_Aligned_Comparable_Documents.html">259 acl-2011-Rare Word Translation Extraction from Aligned Comparable Documents</a></p>
<p>Author: Emmanuel Prochasson ; Pascale Fung</p><p>Abstract: We present a first known result of high precision rare word bilingual extraction from comparable corpora, using aligned comparable documents and supervised classification. We incorporate two features, a context-vector similarity and a co-occurrence model between words in aligned documents in a machine learning approach. We test our hypothesis on different pairs of languages and corpora. We obtain very high F-Measure between 80% and 98% for recognizing and extracting correct translations for rare terms (from 1to 5 occurrences). Moreover, we show that our system can be trained on a pair of languages and test on a different pair of languages, obtaining a F-Measure of 77% for the classification of Chinese-English translations using a training corpus of Spanish-French. Our method is therefore even potentially applicable to low resources languages without training data.</p><p>5 0.74520886 <a title="115-lda-5" href="./acl-2011-Web-Scale_Features_for_Full-Scale_Parsing.html">333 acl-2011-Web-Scale Features for Full-Scale Parsing</a></p>
<p>Author: Mohit Bansal ; Dan Klein</p><p>Abstract: Counts from large corpora (like the web) can be powerful syntactic cues. Past work has used web counts to help resolve isolated ambiguities, such as binary noun-verb PP attachments and noun compound bracketings. In this work, we first present a method for generating web count features that address the full range of syntactic attachments. These features encode both surface evidence of lexical affinities as well as paraphrase-based cues to syntactic structure. We then integrate our features into full-scale dependency and constituent parsers. We show relative error reductions of7.0% over the second-order dependency parser of McDonald and Pereira (2006), 9.2% over the constituent parser of Petrov et al. (2006), and 3.4% over a non-local constituent reranker.</p><p>6 0.67032105 <a title="115-lda-6" href="./acl-2011-Exact_Decoding_of_Syntactic_Translation_Models_through_Lagrangian_Relaxation.html">123 acl-2011-Exact Decoding of Syntactic Translation Models through Lagrangian Relaxation</a></p>
<p>7 0.65367907 <a title="115-lda-7" href="./acl-2011-Clustering_Comparable_Corpora_For_Bilingual_Lexicon_Extraction.html">70 acl-2011-Clustering Comparable Corpora For Bilingual Lexicon Extraction</a></p>
<p>8 0.59060138 <a title="115-lda-8" href="./acl-2011-Ranking_Class_Labels_Using_Query_Sessions.html">258 acl-2011-Ranking Class Labels Using Query Sessions</a></p>
<p>9 0.5858773 <a title="115-lda-9" href="./acl-2011-Search_in_the_Lost_Sense_of_%22Query%22%3A_Question_Formulation_in_Web_Search_Queries_and_its_Temporal_Changes.html">271 acl-2011-Search in the Lost Sense of "Query": Question Formulation in Web Search Queries and its Temporal Changes</a></p>
<p>10 0.54218221 <a title="115-lda-10" href="./acl-2011-Jigs_and_Lures%3A_Associating_Web_Queries_with_Structured_Entities.html">181 acl-2011-Jigs and Lures: Associating Web Queries with Structured Entities</a></p>
<p>11 0.53957796 <a title="115-lda-11" href="./acl-2011-Joint_Annotation_of_Search_Queries.html">182 acl-2011-Joint Annotation of Search Queries</a></p>
<p>12 0.52657741 <a title="115-lda-12" href="./acl-2011-Fine-Grained_Class_Label_Markup_of_Search_Queries.html">137 acl-2011-Fine-Grained Class Label Markup of Search Queries</a></p>
<p>13 0.51160258 <a title="115-lda-13" href="./acl-2011-Using_Large_Monolingual_and_Bilingual_Corpora_to_Improve_Coordination_Disambiguation.html">331 acl-2011-Using Large Monolingual and Bilingual Corpora to Improve Coordination Disambiguation</a></p>
<p>14 0.50666249 <a title="115-lda-14" href="./acl-2011-An_Efficient_Indexer_for_Large_N-Gram_Corpora.html">36 acl-2011-An Efficient Indexer for Large N-Gram Corpora</a></p>
<p>15 0.50011194 <a title="115-lda-15" href="./acl-2011-Query_Weighting_for_Ranking_Model_Adaptation.html">256 acl-2011-Query Weighting for Ranking Model Adaptation</a></p>
<p>16 0.49628919 <a title="115-lda-16" href="./acl-2011-Wikulu%3A_An_Extensible_Architecture_for_Integrating_Natural_Language_Processing_Techniques_with_Wikis.html">338 acl-2011-Wikulu: An Extensible Architecture for Integrating Natural Language Processing Techniques with Wikis</a></p>
<p>17 0.49594107 <a title="115-lda-17" href="./acl-2011-Crowdsourcing_Translation%3A_Professional_Quality_from_Non-Professionals.html">90 acl-2011-Crowdsourcing Translation: Professional Quality from Non-Professionals</a></p>
<p>18 0.48904702 <a title="115-lda-18" href="./acl-2011-Language-independent_compound_splitting_with_morphological_operations.html">193 acl-2011-Language-independent compound splitting with morphological operations</a></p>
<p>19 0.48740754 <a title="115-lda-19" href="./acl-2011-MACAON_An_NLP_Tool_Suite_for_Processing_Word_Lattices.html">215 acl-2011-MACAON An NLP Tool Suite for Processing Word Lattices</a></p>
<p>20 0.48613706 <a title="115-lda-20" href="./acl-2011-Wikipedia_Revision_Toolkit%3A_Efficiently_Accessing_Wikipedias_Edit_History.html">337 acl-2011-Wikipedia Revision Toolkit: Efficiently Accessing Wikipedias Edit History</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
