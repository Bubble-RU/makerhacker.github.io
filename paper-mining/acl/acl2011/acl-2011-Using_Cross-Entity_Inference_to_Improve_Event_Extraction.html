<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>328 acl-2011-Using Cross-Entity Inference to Improve Event Extraction</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-328" href="#">acl2011-328</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>328 acl-2011-Using Cross-Entity Inference to Improve Event Extraction</h1>
<br/><p>Source: <a title="acl-2011-328-pdf" href="http://aclweb.org/anthology//P/P11/P11-1113.pdf">pdf</a></p><p>Author: Yu Hong ; Jianfeng Zhang ; Bin Ma ; Jianmin Yao ; Guodong Zhou ; Qiaoming Zhu</p><p>Abstract: Event extraction is the task of detecting certain specified types of events that are mentioned in the source language data. The state-of-the-art research on the task is transductive inference (e.g. cross-event inference). In this paper, we propose a new method of event extraction by well using cross-entity inference. In contrast to previous inference methods, we regard entitytype consistency as key feature to predict event mentions. We adopt this inference method to improve the traditional sentence-level event extraction system. Experiments show that we can get 8.6% gain in trigger (event) identification, and more than 11.8% gain for argument (role) classification in ACE event extraction. 1</p><p>Reference: <a title="acl-2011-328-reference" href="../acl2011_reference/acl-2011-Using_Cross-Entity_Inference_to_Improve_Event_Extraction_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 cn  Abstract Event extraction is the task of detecting certain specified types of events that are mentioned in the source language data. [sent-3, score-0.312]
</p><p>2 The state-of-the-art research on the task is transductive inference (e. [sent-4, score-0.26]
</p><p>3 In this paper, we propose a new method of event extraction by well using cross-entity inference. [sent-7, score-0.854]
</p><p>4 In contrast to previous inference methods, we regard entitytype consistency as key feature to predict event mentions. [sent-8, score-1.094]
</p><p>5 We adopt this inference method to improve the traditional sentence-level event extraction system. [sent-9, score-0.985]
</p><p>6 6% gain in trigger (event) identification, and more than 11. [sent-11, score-0.172]
</p><p>7 8% gain for argument (role) classification in ACE event extraction. [sent-12, score-0.849]
</p><p>8 1  Introduction  The event extraction task in ACE (Automatic Content Extraction) evaluation involves three challenging issues: distinguishing events of different types, finding the participants of an event and determin-  ing the roles of the participants. [sent-13, score-1.871]
</p><p>9 The recent researches on the task show the availability of transductive inference, such as that of the following methods: cross-document, crosssentence and cross-event inferences. [sent-14, score-0.149]
</p><p>10 Transductive inference is a process to use the known instances to predict the attributes of unknown instances. [sent-15, score-0.226]
</p><p>11 As an example, given a target event, the cross-event inference can predict its type by well using the related events co-occurred with it within the same document. [sent-16, score-0.44]
</p><p>12 it is hard to tell whether it is a Transport event in ACE, which means that he left the place; or an End-Position event, which means that he retired from the company. [sent-18, score-0.841]
</p><p>13 But cross-event inference can use a related event “Then he went shopping” within 1127 the same document to identify it as a Transport event correctly. [sent-19, score-1.677]
</p><p>14 As the above example might suggest, the availability of transductive inference for event extraction relies heavily on the known evidences of an event occurrence in specific condition. [sent-20, score-1.985]
</p><p>15 However, the evidence supporting the inference is normally  unclear or absent. [sent-21, score-0.224]
</p><p>16 For instance, the relation among events is the key clue for cross-event inference to predict a target event type, as shown in the inference process of the sentence (1). [sent-22, score-1.299]
</p><p>17 But event relation extraction itself is a hard task in Information Extraction. [sent-23, score-0.895]
</p><p>18 So cross-event inference often suffers from some false evidence (viz. [sent-24, score-0.209]
</p><p>19 , misleading by unrelated events) or lack of valid evidence (viz. [sent-25, score-0.049]
</p><p>20 In this paper, we propose a new method of transductive inference, named cross-entity inference, for event extraction by well using the relations among entities. [sent-27, score-0.983]
</p><p>21 This method is firstly motivated by the inherent ability of entity types in revealing event types. [sent-28, score-0.997]
</p><p>22 it is easy to identify the sentence (2) as a Transport event in ACE, which means that he left the place, because nobody would retire (End-Position type) from a bathroom. [sent-31, score-0.818]
</p><p>23 And compared to the entities in sentence (1) and (2), the entity “Microsoft” in (3) would give us more confidence to tag the “left” event as an End-Position type, because people are used to giving the full name of the place where they retired. [sent-32, score-1.16]
</p><p>24 The cross-entity inference is also motivated by the phenomenon that the entities of the same type often attend similar events. [sent-33, score-0.41]
</p><p>25 That gives us a way to predict event type based on entity-type consistency. [sent-34, score-0.909]
</p><p>26 it is hard to identify it as an Elect event in ACE, which means Obama wins the Presidential Election, ProceedingPso orftla thned 4,9 Otrhe Agonnn,u Jauln Mee 1e9t-i2ng4, o 2f0 t1h1e. [sent-36, score-0.813]
</p><p>27 c s 2o0ci1a1ti Aonss foocria Ctioomnp fourta Ctioomnaplu Ltaintigouniaslti Lcisn,g puaigsetsic 1s127–1136, or an Attack event, which means Obama roughs somebody up. [sent-38, score-0.02]
</p><p>28 But if we have the priori knowledge that the sentence “Bush beats McCain” is an Elect event, and “Obama” was a presidential contender just like “Bush” (strict type consistency), we have ample evidence to predict that the sentence (4) is also an Elect event. [sent-39, score-0.319]
</p><p>29 Indeed above cross-entity inference for eventtype identification is not the only use of entity-type consistency. [sent-40, score-0.159]
</p><p>30 As we shall describe below, we can make use of it at all issues of event extraction: ? [sent-41, score-0.773]
</p><p>31 For event type: the entities of the same type are most likely to attend similar events. [sent-42, score-1.052]
</p><p>32 And the events often use consistent or synonymous trigger. [sent-43, score-0.173]
</p><p>33 For event argument (participant): the entities of the same type normally co-occur with simi-  lar participants in the events of the same type. [sent-45, score-1.335]
</p><p>34 For argument role: the arguments of the same type, for the most part, play the same roles in similar events. [sent-47, score-0.172]
</p><p>35 With the help of above characteristics of entity, we can perform a step-by-step inference in this order: ? [sent-48, score-0.131]
</p><p>36 Step 1: predicting event type and labeling trigger given the entities of the same type. [sent-49, score-1.181]
</p><p>37 Step 2: identifying arguments in certain event given priori entity type, event type and trigger that obtained by step 1. [sent-51, score-2.161]
</p><p>38 Step 3: determining argument roles in certain event given entity type, event type, trigger and arguments that obtained by step 1 and step 2. [sent-53, score-2.15]
</p><p>39 On the basis, we give a blind cross-entity inference method for event extraction in this paper. [sent-54, score-0.985]
</p><p>40 In the method, we first regard entities as queries to retrieve their related documents from large-scale language resources, and use the global evidences of the documents to generate entity-type descriptions. [sent-55, score-0.221]
</p><p>41 Second we determine the type consistency of entities by measuring the similarity of the type descriptions. [sent-56, score-0.442]
</p><p>42 Finally, given the priori attributes of events in the training data, with the help of the entities of the same type, we perform the step-by-step cross-entity inference on the attributes of test  events (candidate sentences). [sent-57, score-0.775]
</p><p>43 In contrast to other transductive inference methods on event extraction, the cross-entity inference makes every effort to strengthen effects of entities in predicting event occurrences. [sent-58, score-2.081]
</p><p>44 Thus the inferential process can benefit from following aspects: 1) less false evidence, viz. [sent-59, score-0.049]
</p><p>45 less false entity-type consistency (the key clue of cross-entity inference), 1128 because the consistency can be more precisely determined with the help of fully entity-type description that obtained based on the related information from Web; 2) more valid evidence, viz. [sent-60, score-0.285]
</p><p>46 more entities of the same type (the key references for the inference), because any entity never lack its congeners. [sent-61, score-0.43]
</p><p>47 2  Task Description  The event extraction task we addressing is that of the Automatic Content Extraction (ACE) evaluations, where an event is defined as a specific occurrence involving participants. [sent-62, score-1.66]
</p><p>48 And event extraction task requires that certain specified types of events that are mentioned in the source language data be detected. [sent-63, score-1.085]
</p><p>49 Entity: an object or a set of objects in one of the semantic categories of interest, referred to in the document by one or more (co-referential) entity mentions. [sent-65, score-0.194]
</p><p>50 Entity mention: a reference to an entity (typically, a noun phrase). [sent-67, score-0.215]
</p><p>51 Event trigger: the main word that most clearly expresses an event occurrence (An ACE event trigger is generally a verb or a noun). [sent-69, score-1.751]
</p><p>52 Event arguments: the entity mentions that are involved in an event (viz. [sent-71, score-1.043]
</p><p>53 Argument roles: the relation of arguments to the event where they participate. [sent-74, score-0.85]
</p><p>54 Event mention: a phrase or sentence within which an event is described, including trigger and arguments. [sent-76, score-0.945]
</p><p>55 The 2005 ACE evaluation had 8 types of events, with 33 subtypes; for the purpose of this paper, we will treat these simply as 33 separate event types and do not consider the hierarchical structure among them. [sent-77, score-0.833]
</p><p>56 Besides, the ACE evaluation plan defines the following standards to determine the correctness of an event extraction: ? [sent-78, score-0.773]
</p><p>57 A trigger is correctly labeled if its event type and offset (viz. [sent-79, score-1.057]
</p><p>58 , the position of the trigger word in  text) match a reference trigger. [sent-80, score-0.193]
</p><p>59 An argument is correctly identified if its event type and offsets match any of the reference argument mentions, in other word, correctly recognizing participants in an event. [sent-82, score-1.111]
</p><p>60 An argument is correctly classified if its role matches any of the reference argument mentions. [sent-84, score-0.234]
</p><p>61 Consider the sentence: (5) It has refused in the last five years to revoke the license of a single doctor for committing medical errors. [sent-85, score-0.137]
</p><p>62 Thereinto, the name identification is another hard task in ACE evaluation and not the focus in this paper. [sent-87, score-0.07]
</p><p>63 So we  skip the phase and instead directly use the entity labels provided by ACE. [sent-88, score-0.194]
</p><p>64 3  Related Work  Almost all the current ACE event extraction systems focus on processing one sentence at a time (Grishman et al. [sent-89, score-0.854]
</p><p>65 However, there have been several studies using high-level information from a wider scope: Maslennikov and Chua (2007) use discourse trees and local syntactic dependencies in a patternbased framework to incorporate wider context to refine the performance of relation extraction. [sent-92, score-0.116]
</p><p>66 They claimed that discourse information could filter noisy dependency paths as well as increasing the reliability of dependency path extraction. [sent-93, score-0.044]
</p><p>67 (2005) used Gibbs sampling, a simple Monte Carlo method used to perform approximate inference in factored probabilistic models. [sent-95, score-0.131]
</p><p>68 By using simulated annealing in place of Viterbi decoding in sequence models such as HMMs, CMMs, and CRFs, it is possible to incorporate non-local structure while preserving tractable inference. [sent-96, score-0.029]
</p><p>69 They used this technique to augment an information extraction system with long-distance dependency models, enforcing label consistency and extraction template consistency constraints. [sent-97, score-0.39]
</p><p>70 02”  in  1129 rowsky, 1995); they extended the scope from a single document to a cluster of topic-related documents and employed a rule-based approach to propagate consistent trigger classification and event arguments across sentences and documents. [sent-101, score-1.003]
</p><p>71 Combining global evidence from related documents with local decisions, they obtained an appreciable improvement in both event and event argument identification. [sent-102, score-1.712]
</p><p>72 This unified probabilistic model allows the two components to jointly make decisions based upon both the local evidence sur-  rounding each phrase and the “peripheral vision”. [sent-104, score-0.07]
</p><p>73 Liao and Grishman (2010) propose document level cross-event inference to improve event extraction. [sent-106, score-0.904]
</p><p>74 In contrast to Gupta’s work, Liao do not limit themselves to time information for events, but rather use related events and event-type consistency to make predictions or resolve ambiguities regarding a given event. [sent-107, score-0.287]
</p><p>75 4  Motivation  In event extraction, current transductive inference methods focus on the issue that many events are missing or spuriously tagged because the local information is not sufficient to make a confident decision. [sent-108, score-1.248]
</p><p>76 The solution is to mine credible evidences of event occurrences from global information and regard that as priori knowledge to predict unknown event attributes, such as that of cross-document and cross-event inference methods. [sent-109, score-1.87]
</p><p>77 However, by analyzing the sentence-level baseline event extraction, we found that the entities within a sentence, as the most important local in-  formation, actually contain sufficient clues for event detection. [sent-110, score-1.711]
</p><p>78 It is only based on the premise that we know the backgrounds of the entities beforehand. [sent-111, score-0.174]
</p><p>79 For instance, if we knew the entity “vesuvius” is an active volcano, we could easily identify the word “erupt”, which co-occurred with the entity, as the trigger of a “volcanic eruption” event but not that of a “spotty rash”. [sent-112, score-1.159]
</p><p>80 In spite of that, it is actually difficult to use an entity to directly infer an event occurrence because we normally don’t know the inevitable connection between the background of the entity and the event attributes. [sent-113, score-2.089]
</p><p>81 But we can well use the entities of the same background to perform the inference. [sent-114, score-0.171]
</p><p>82 In detail, if we first know entity(a) has the same background with entity(b), and we also know that entity(a), as a certain role, participates in a specific event, then we can predict that entity(b) might participtes in a similar event as the same role. [sent-115, score-0.932]
</p><p>83 (6) Bush should torture the al Qaeda chief operations officer. [sent-117, score-0.039]
</p><p>84 The sentences are two event mentions which have the same attributes:  (65)AETvr agerbinulgmtegy e2npr:tesCro. [sent-118, score-0.849]
</p><p>85 tAoewntacure k Rx oalme= pAlTeta rcgke tr  From the sentences, we can find that the entities “Saddam” and “Qaeda chief” have the same background (viz. [sent-120, score-0.171]
</p><p>86 , terrorist leader), and they are both the arguments of Attack events as the role of Target. [sent-121, score-0.293]
</p><p>87 So if we previously know any of the event mentions, we can infer another one with the help of the entities of the same background. [sent-122, score-0.947]
</p><p>88 In a word, the cross-entity inference, we proposed for event extraction, bases on the hypothesis: Entities of the consistent type normally participate in similar events as the same role. [sent-123, score-1.082]
</p><p>89 As we will introduce below, some statistical data from ACE training corpus can support the hypothesis, which show the consistency of event type and role in event mentions where entities of the same type occur. [sent-124, score-2.105]
</p><p>90 1  Entity Consistency and Distribution  Within the ACE corpus, there is a strong entity  consistency: if one entity mention appears in a type 2 They are extracted from the files “CNN_CF_20030305. [sent-126, score-0.525]
</p><p>91 of event, other entity mentions of the same type will appear in similar events, and even use the same word to trigger the events. [sent-131, score-0.534]
</p><p>92 To see this we calculated the conditional probability (in the ACE corpus) of a certain entity type appearing in the 33 ACE event subtypes. [sent-132, score-1.146]
</p><p>93 Conditional probability of an entity type appearing as the 34 ACE role types (Here only the probabilities of Population-Center, Exploding and Air entities as examples) As there are 33 event subtypes and 43 entity types, there are potentially 33*43=1419 entityevent combinations. [sent-135, score-1.541]
</p><p>94 For example, the Population-Center entities only occur in 4 types of event mentions with the conditional probability more than 0. [sent-137, score-1.054]
</p><p>95 From Table 3, we can find that only Attack and Transport events co-occur frequently with Population-Center entities (see Figure 1 and Table 3). [sent-139, score-0.317]
</p><p>96 05 Actually we find that most entity types appear in more restricted event mentions than Population-  Center entity. [sent-145, score-1.073]
</p><p>97 For example, Air entity only cooccurs with 5 event types (Attack, Transport, Die, Transfer-Ownership and Injure), and Exploding 1130  entity co-occurs with 4 event types (see Figure 1). [sent-146, score-2.015]
</p><p>98 Especially, they only co-occur with one or two event types with the conditional probability more than 0. [sent-147, score-0.834]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('event', 0.773), ('ace', 0.265), ('entity', 0.194), ('events', 0.173), ('trigger', 0.172), ('entities', 0.144), ('inference', 0.131), ('transductive', 0.129), ('consistency', 0.114), ('transport', 0.106), ('type', 0.092), ('extraction', 0.081), ('mentions', 0.076), ('argument', 0.076), ('elect', 0.072), ('exploding', 0.072), ('attack', 0.062), ('arguments', 0.058), ('priori', 0.052), ('attributes', 0.051), ('obama', 0.051), ('bush', 0.05), ('evidence', 0.049), ('evidences', 0.045), ('subtypes', 0.045), ('mention', 0.045), ('normally', 0.044), ('predict', 0.044), ('presidential', 0.043), ('revoke', 0.043), ('qaeda', 0.043), ('doctor', 0.043), ('attend', 0.043), ('role', 0.041), ('beats', 0.039), ('chief', 0.039), ('grishman', 0.039), ('air', 0.039), ('roles', 0.038), ('liao', 0.037), ('fillers', 0.035), ('gupta', 0.035), ('participants', 0.033), ('occurrence', 0.033), ('regard', 0.032), ('license', 0.031), ('conditional', 0.031), ('know', 0.03), ('types', 0.03), ('false', 0.029), ('place', 0.029), ('certain', 0.028), ('discussing', 0.028), ('clue', 0.028), ('appearing', 0.028), ('identification', 0.028), ('background', 0.027), ('wider', 0.026), ('left', 0.025), ('discourse', 0.024), ('hard', 0.022), ('local', 0.021), ('inef', 0.021), ('cooccurs', 0.021), ('revoked', 0.021), ('spuriously', 0.021), ('volcano', 0.021), ('vesuvius', 0.021), ('tar', 0.021), ('terrorist', 0.021), ('inevitable', 0.021), ('retired', 0.021), ('jianmin', 0.021), ('reference', 0.021), ('ji', 0.021), ('correctly', 0.02), ('name', 0.02), ('availability', 0.02), ('committing', 0.02), ('somebody', 0.02), ('ces', 0.02), ('appreciable', 0.02), ('claimed', 0.02), ('rem', 0.02), ('lro', 0.02), ('nobody', 0.02), ('credible', 0.02), ('knew', 0.02), ('esa', 0.02), ('inferential', 0.02), ('election', 0.02), ('maslennikov', 0.02), ('injure', 0.02), ('step', 0.019), ('relation', 0.019), ('ues', 0.018), ('wins', 0.018), ('iat', 0.018), ('peripheral', 0.018), ('chua', 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999997 <a title="328-tfidf-1" href="./acl-2011-Using_Cross-Entity_Inference_to_Improve_Event_Extraction.html">328 acl-2011-Using Cross-Entity Inference to Improve Event Extraction</a></p>
<p>Author: Yu Hong ; Jianfeng Zhang ; Bin Ma ; Jianmin Yao ; Guodong Zhou ; Qiaoming Zhu</p><p>Abstract: Event extraction is the task of detecting certain specified types of events that are mentioned in the source language data. The state-of-the-art research on the task is transductive inference (e.g. cross-event inference). In this paper, we propose a new method of event extraction by well using cross-entity inference. In contrast to previous inference methods, we regard entitytype consistency as key feature to predict event mentions. We adopt this inference method to improve the traditional sentence-level event extraction system. Experiments show that we can get 8.6% gain in trigger (event) identification, and more than 11.8% gain for argument (role) classification in ACE event extraction. 1</p><p>2 0.6940468 <a title="328-tfidf-2" href="./acl-2011-Can_Document_Selection_Help_Semi-supervised_Learning%3F_A_Case_Study_On_Event_Extraction.html">65 acl-2011-Can Document Selection Help Semi-supervised Learning? A Case Study On Event Extraction</a></p>
<p>Author: Shasha Liao ; Ralph Grishman</p><p>Abstract: Annotating training data for event extraction is tedious and labor-intensive. Most current event extraction tasks rely on hundreds of annotated documents, but this is often not enough. In this paper, we present a novel self-training strategy, which uses Information Retrieval (IR) to collect a cluster of related documents as the resource for bootstrapping. Also, based on the particular characteristics of this corpus, global inference is applied to provide more confident and informative data selection. We compare this approach to self-training on a normal newswire corpus and show that IR can provide a better corpus for bootstrapping and that global inference can further improve instance selection. We obtain gains of 1.7% in trigger labeling and 2.3% in role labeling through IR and an additional 1.1% in trigger labeling and 1.3% in role labeling by applying global inference. 1</p><p>3 0.63061428 <a title="328-tfidf-3" href="./acl-2011-Peeling_Back_the_Layers%3A_Detecting_Event_Role_Fillers_in_Secondary_Contexts.html">244 acl-2011-Peeling Back the Layers: Detecting Event Role Fillers in Secondary Contexts</a></p>
<p>Author: Ruihong Huang ; Ellen Riloff</p><p>Abstract: The goal of our research is to improve event extraction by learning to identify secondary role filler contexts in the absence of event keywords. We propose a multilayered event extraction architecture that progressively “zooms in” on relevant information. Our extraction model includes a document genre classifier to recognize event narratives, two types of sentence classifiers, and noun phrase classifiers to extract role fillers. These modules are organized as a pipeline to gradually zero in on event-related information. We present results on the MUC-4 event extraction data set and show that this model performs better than previous systems.</p><p>4 0.55286574 <a title="328-tfidf-4" href="./acl-2011-Event_Extraction_as_Dependency_Parsing.html">122 acl-2011-Event Extraction as Dependency Parsing</a></p>
<p>Author: David McClosky ; Mihai Surdeanu ; Christopher Manning</p><p>Abstract: Nested event structures are a common occurrence in both open domain and domain specific extraction tasks, e.g., a “crime” event can cause a “investigation” event, which can lead to an “arrest” event. However, most current approaches address event extraction with highly local models that extract each event and argument independently. We propose a simple approach for the extraction of such structures by taking the tree of event-argument relations and using it directly as the representation in a reranking dependency parser. This provides a simple framework that captures global properties of both nested and flat event structures. We explore a rich feature space that models both the events to be parsed and context from the original supporting text. Our approach obtains competitive results in the extraction of biomedical events from the BioNLP’09 shared task with a F1 score of 53.5% in development and 48.6% in testing.</p><p>5 0.23000513 <a title="328-tfidf-5" href="./acl-2011-Template-Based_Information_Extraction_without_the_Templates.html">293 acl-2011-Template-Based Information Extraction without the Templates</a></p>
<p>Author: Nathanael Chambers ; Dan Jurafsky</p><p>Abstract: Standard algorithms for template-based information extraction (IE) require predefined template schemas, and often labeled data, to learn to extract their slot fillers (e.g., an embassy is the Target of a Bombing template). This paper describes an approach to template-based IE that removes this requirement and performs extraction without knowing the template structure in advance. Our algorithm instead learns the template structure automatically from raw text, inducing template schemas as sets of linked events (e.g., bombings include detonate, set off, and destroy events) associated with semantic roles. We also solve the standard IE task, using the induced syntactic patterns to extract role fillers from specific documents. We evaluate on the MUC-4 terrorism dataset and show that we induce template structure very similar to handcreated gold structure, and we extract role fillers with an F1 score of .40, approaching the performance of algorithms that require full knowledge of the templates.</p><p>6 0.21137078 <a title="328-tfidf-6" href="./acl-2011-A_Latent_Topic_Extracting_Method_based_on_Events_in_a_Document_and_its_Application.html">18 acl-2011-A Latent Topic Extracting Method based on Events in a Document and its Application</a></p>
<p>7 0.16397458 <a title="328-tfidf-7" href="./acl-2011-A_Generative_Entity-Mention_Model_for_Linking_Entities_with_Knowledge_Base.html">12 acl-2011-A Generative Entity-Mention Model for Linking Entities with Knowledge Base</a></p>
<p>8 0.14455567 <a title="328-tfidf-8" href="./acl-2011-Event_Discovery_in_Social_Media_Feeds.html">121 acl-2011-Event Discovery in Social Media Feeds</a></p>
<p>9 0.14372991 <a title="328-tfidf-9" href="./acl-2011-Multi-Modal_Annotation_of_Quest_Games_in_Second_Life.html">226 acl-2011-Multi-Modal Annotation of Quest Games in Second Life</a></p>
<p>10 0.13812201 <a title="328-tfidf-10" href="./acl-2011-Joint_Training_of_Dependency_Parsing_Filters_through_Latent_Support_Vector_Machines.html">186 acl-2011-Joint Training of Dependency Parsing Filters through Latent Support Vector Machines</a></p>
<p>11 0.13598168 <a title="328-tfidf-11" href="./acl-2011-Large-Scale_Cross-Document_Coreference_Using_Distributed_Inference_and_Hierarchical_Models.html">196 acl-2011-Large-Scale Cross-Document Coreference Using Distributed Inference and Hierarchical Models</a></p>
<p>12 0.13567518 <a title="328-tfidf-12" href="./acl-2011-Social_Network_Extraction_from_Texts%3A_A_Thesis_Proposal.html">286 acl-2011-Social Network Extraction from Texts: A Thesis Proposal</a></p>
<p>13 0.12610576 <a title="328-tfidf-13" href="./acl-2011-Semi-supervised_Relation_Extraction_with_Large-scale_Word_Clustering.html">277 acl-2011-Semi-supervised Relation Extraction with Large-scale Word Clustering</a></p>
<p>14 0.11542336 <a title="328-tfidf-14" href="./acl-2011-Enhancing_Language_Models_in_Statistical_Machine_Translation_with_Backward_N-grams_and_Mutual_Information_Triggers.html">116 acl-2011-Enhancing Language Models in Statistical Machine Translation with Backward N-grams and Mutual Information Triggers</a></p>
<p>15 0.11428124 <a title="328-tfidf-15" href="./acl-2011-Knowledge_Base_Population%3A_Successful_Approaches_and_Challenges.html">191 acl-2011-Knowledge Base Population: Successful Approaches and Challenges</a></p>
<p>16 0.10449297 <a title="328-tfidf-16" href="./acl-2011-Extending_the_Entity_Grid_with_Entity-Specific_Features.html">129 acl-2011-Extending the Entity Grid with Entity-Specific Features</a></p>
<p>17 0.10435433 <a title="328-tfidf-17" href="./acl-2011-A_Pronoun_Anaphora_Resolution_System_based_on_Factorial_Hidden_Markov_Models.html">23 acl-2011-A Pronoun Anaphora Resolution System based on Factorial Hidden Markov Models</a></p>
<p>18 0.099380232 <a title="328-tfidf-18" href="./acl-2011-Coreference_for_Learning_to_Extract_Relations%3A_Yes_Virginia%2C_Coreference_Matters.html">86 acl-2011-Coreference for Learning to Extract Relations: Yes Virginia, Coreference Matters</a></p>
<p>19 0.088754259 <a title="328-tfidf-19" href="./acl-2011-Exploiting_Syntactico-Semantic_Structures_for_Relation_Extraction.html">126 acl-2011-Exploiting Syntactico-Semantic Structures for Relation Extraction</a></p>
<p>20 0.083746552 <a title="328-tfidf-20" href="./acl-2011-Exploring_Entity_Relations_for_Named_Entity_Disambiguation.html">128 acl-2011-Exploring Entity Relations for Named Entity Disambiguation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.172), (1, 0.122), (2, -0.377), (3, 0.039), (4, 0.485), (5, 0.343), (6, -0.167), (7, -0.127), (8, 0.358), (9, 0.056), (10, -0.048), (11, 0.066), (12, -0.031), (13, 0.052), (14, 0.047), (15, 0.068), (16, 0.106), (17, 0.075), (18, -0.022), (19, 0.028), (20, 0.026), (21, -0.032), (22, 0.023), (23, 0.024), (24, -0.021), (25, 0.049), (26, -0.015), (27, 0.007), (28, 0.001), (29, 0.035), (30, 0.013), (31, 0.056), (32, -0.018), (33, 0.0), (34, 0.002), (35, -0.001), (36, -0.0), (37, -0.02), (38, 0.001), (39, -0.011), (40, -0.008), (41, -0.019), (42, -0.006), (43, 0.007), (44, 0.01), (45, -0.002), (46, 0.002), (47, 0.021), (48, 0.017), (49, -0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99232012 <a title="328-lsi-1" href="./acl-2011-Using_Cross-Entity_Inference_to_Improve_Event_Extraction.html">328 acl-2011-Using Cross-Entity Inference to Improve Event Extraction</a></p>
<p>Author: Yu Hong ; Jianfeng Zhang ; Bin Ma ; Jianmin Yao ; Guodong Zhou ; Qiaoming Zhu</p><p>Abstract: Event extraction is the task of detecting certain specified types of events that are mentioned in the source language data. The state-of-the-art research on the task is transductive inference (e.g. cross-event inference). In this paper, we propose a new method of event extraction by well using cross-entity inference. In contrast to previous inference methods, we regard entitytype consistency as key feature to predict event mentions. We adopt this inference method to improve the traditional sentence-level event extraction system. Experiments show that we can get 8.6% gain in trigger (event) identification, and more than 11.8% gain for argument (role) classification in ACE event extraction. 1</p><p>2 0.95392823 <a title="328-lsi-2" href="./acl-2011-Peeling_Back_the_Layers%3A_Detecting_Event_Role_Fillers_in_Secondary_Contexts.html">244 acl-2011-Peeling Back the Layers: Detecting Event Role Fillers in Secondary Contexts</a></p>
<p>Author: Ruihong Huang ; Ellen Riloff</p><p>Abstract: The goal of our research is to improve event extraction by learning to identify secondary role filler contexts in the absence of event keywords. We propose a multilayered event extraction architecture that progressively “zooms in” on relevant information. Our extraction model includes a document genre classifier to recognize event narratives, two types of sentence classifiers, and noun phrase classifiers to extract role fillers. These modules are organized as a pipeline to gradually zero in on event-related information. We present results on the MUC-4 event extraction data set and show that this model performs better than previous systems.</p><p>3 0.93517458 <a title="328-lsi-3" href="./acl-2011-Can_Document_Selection_Help_Semi-supervised_Learning%3F_A_Case_Study_On_Event_Extraction.html">65 acl-2011-Can Document Selection Help Semi-supervised Learning? A Case Study On Event Extraction</a></p>
<p>Author: Shasha Liao ; Ralph Grishman</p><p>Abstract: Annotating training data for event extraction is tedious and labor-intensive. Most current event extraction tasks rely on hundreds of annotated documents, but this is often not enough. In this paper, we present a novel self-training strategy, which uses Information Retrieval (IR) to collect a cluster of related documents as the resource for bootstrapping. Also, based on the particular characteristics of this corpus, global inference is applied to provide more confident and informative data selection. We compare this approach to self-training on a normal newswire corpus and show that IR can provide a better corpus for bootstrapping and that global inference can further improve instance selection. We obtain gains of 1.7% in trigger labeling and 2.3% in role labeling through IR and an additional 1.1% in trigger labeling and 1.3% in role labeling by applying global inference. 1</p><p>4 0.86670554 <a title="328-lsi-4" href="./acl-2011-Event_Extraction_as_Dependency_Parsing.html">122 acl-2011-Event Extraction as Dependency Parsing</a></p>
<p>Author: David McClosky ; Mihai Surdeanu ; Christopher Manning</p><p>Abstract: Nested event structures are a common occurrence in both open domain and domain specific extraction tasks, e.g., a “crime” event can cause a “investigation” event, which can lead to an “arrest” event. However, most current approaches address event extraction with highly local models that extract each event and argument independently. We propose a simple approach for the extraction of such structures by taking the tree of event-argument relations and using it directly as the representation in a reranking dependency parser. This provides a simple framework that captures global properties of both nested and flat event structures. We explore a rich feature space that models both the events to be parsed and context from the original supporting text. Our approach obtains competitive results in the extraction of biomedical events from the BioNLP’09 shared task with a F1 score of 53.5% in development and 48.6% in testing.</p><p>5 0.62896603 <a title="328-lsi-5" href="./acl-2011-Template-Based_Information_Extraction_without_the_Templates.html">293 acl-2011-Template-Based Information Extraction without the Templates</a></p>
<p>Author: Nathanael Chambers ; Dan Jurafsky</p><p>Abstract: Standard algorithms for template-based information extraction (IE) require predefined template schemas, and often labeled data, to learn to extract their slot fillers (e.g., an embassy is the Target of a Bombing template). This paper describes an approach to template-based IE that removes this requirement and performs extraction without knowing the template structure in advance. Our algorithm instead learns the template structure automatically from raw text, inducing template schemas as sets of linked events (e.g., bombings include detonate, set off, and destroy events) associated with semantic roles. We also solve the standard IE task, using the induced syntactic patterns to extract role fillers from specific documents. We evaluate on the MUC-4 terrorism dataset and show that we induce template structure very similar to handcreated gold structure, and we extract role fillers with an F1 score of .40, approaching the performance of algorithms that require full knowledge of the templates.</p><p>6 0.52479911 <a title="328-lsi-6" href="./acl-2011-Event_Discovery_in_Social_Media_Feeds.html">121 acl-2011-Event Discovery in Social Media Feeds</a></p>
<p>7 0.51966059 <a title="328-lsi-7" href="./acl-2011-Multi-Modal_Annotation_of_Quest_Games_in_Second_Life.html">226 acl-2011-Multi-Modal Annotation of Quest Games in Second Life</a></p>
<p>8 0.43123999 <a title="328-lsi-8" href="./acl-2011-Joint_Training_of_Dependency_Parsing_Filters_through_Latent_Support_Vector_Machines.html">186 acl-2011-Joint Training of Dependency Parsing Filters through Latent Support Vector Machines</a></p>
<p>9 0.36447716 <a title="328-lsi-9" href="./acl-2011-Social_Network_Extraction_from_Texts%3A_A_Thesis_Proposal.html">286 acl-2011-Social Network Extraction from Texts: A Thesis Proposal</a></p>
<p>10 0.36073059 <a title="328-lsi-10" href="./acl-2011-A_Latent_Topic_Extracting_Method_based_on_Events_in_a_Document_and_its_Application.html">18 acl-2011-A Latent Topic Extracting Method based on Events in a Document and its Application</a></p>
<p>11 0.30760399 <a title="328-lsi-11" href="./acl-2011-Knowledge_Base_Population%3A_Successful_Approaches_and_Challenges.html">191 acl-2011-Knowledge Base Population: Successful Approaches and Challenges</a></p>
<p>12 0.29076228 <a title="328-lsi-12" href="./acl-2011-A_Generative_Entity-Mention_Model_for_Linking_Entities_with_Knowledge_Base.html">12 acl-2011-A Generative Entity-Mention Model for Linking Entities with Knowledge Base</a></p>
<p>13 0.27555636 <a title="328-lsi-13" href="./acl-2011-Exploiting_Syntactico-Semantic_Structures_for_Relation_Extraction.html">126 acl-2011-Exploiting Syntactico-Semantic Structures for Relation Extraction</a></p>
<p>14 0.2700409 <a title="328-lsi-14" href="./acl-2011-An_Error_Analysis_of_Relation_Extraction_in_Social_Media_Documents.html">40 acl-2011-An Error Analysis of Relation Extraction in Social Media Documents</a></p>
<p>15 0.25787127 <a title="328-lsi-15" href="./acl-2011-Large-Scale_Cross-Document_Coreference_Using_Distributed_Inference_and_Hierarchical_Models.html">196 acl-2011-Large-Scale Cross-Document Coreference Using Distributed Inference and Hierarchical Models</a></p>
<p>16 0.25316671 <a title="328-lsi-16" href="./acl-2011-SystemT%3A_A_Declarative_Information_Extraction_System.html">291 acl-2011-SystemT: A Declarative Information Extraction System</a></p>
<p>17 0.25283572 <a title="328-lsi-17" href="./acl-2011-Lexically-Triggered_Hidden_Markov_Models_for_Clinical_Document_Coding.html">209 acl-2011-Lexically-Triggered Hidden Markov Models for Clinical Document Coding</a></p>
<p>18 0.22927371 <a title="328-lsi-18" href="./acl-2011-Extending_the_Entity_Grid_with_Entity-Specific_Features.html">129 acl-2011-Extending the Entity Grid with Entity-Specific Features</a></p>
<p>19 0.22004864 <a title="328-lsi-19" href="./acl-2011-Enhancing_Language_Models_in_Statistical_Machine_Translation_with_Backward_N-grams_and_Mutual_Information_Triggers.html">116 acl-2011-Enhancing Language Models in Statistical Machine Translation with Backward N-grams and Mutual Information Triggers</a></p>
<p>20 0.21845636 <a title="328-lsi-20" href="./acl-2011-Knowledge-Based_Weak_Supervision_for_Information_Extraction_of_Overlapping_Relations.html">190 acl-2011-Knowledge-Based Weak Supervision for Information Extraction of Overlapping Relations</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.019), (17, 0.054), (26, 0.026), (31, 0.012), (37, 0.067), (39, 0.033), (41, 0.482), (55, 0.015), (59, 0.065), (72, 0.017), (91, 0.025), (96, 0.069), (97, 0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94351465 <a title="328-lda-1" href="./acl-2011-Using_Cross-Entity_Inference_to_Improve_Event_Extraction.html">328 acl-2011-Using Cross-Entity Inference to Improve Event Extraction</a></p>
<p>Author: Yu Hong ; Jianfeng Zhang ; Bin Ma ; Jianmin Yao ; Guodong Zhou ; Qiaoming Zhu</p><p>Abstract: Event extraction is the task of detecting certain specified types of events that are mentioned in the source language data. The state-of-the-art research on the task is transductive inference (e.g. cross-event inference). In this paper, we propose a new method of event extraction by well using cross-entity inference. In contrast to previous inference methods, we regard entitytype consistency as key feature to predict event mentions. We adopt this inference method to improve the traditional sentence-level event extraction system. Experiments show that we can get 8.6% gain in trigger (event) identification, and more than 11.8% gain for argument (role) classification in ACE event extraction. 1</p><p>2 0.94053042 <a title="328-lda-2" href="./acl-2011-Contrasting_Multi-Lingual_Prosodic_Cues_to_Predict_Verbal_Feedback_for_Rapport.html">83 acl-2011-Contrasting Multi-Lingual Prosodic Cues to Predict Verbal Feedback for Rapport</a></p>
<p>Author: Siwei Wang ; Gina-Anne Levow</p><p>Abstract: Verbal feedback is an important information source in establishing interactional rapport. However, predicting verbal feedback across languages is challenging due to languagespecific differences, inter-speaker variation, and the relative sparseness and optionality of verbal feedback. In this paper, we employ an approach combining classifier weighting and SMOTE algorithm oversampling to improve verbal feedback prediction in Arabic, English, and Spanish dyadic conversations. This approach improves the prediction of verbal feedback, up to 6-fold, while maintaining a high overall accuracy. Analyzing highly weighted features highlights widespread use of pitch, with more varied use of intensity and duration.</p><p>3 0.91706944 <a title="328-lda-3" href="./acl-2011-Metagrammar_engineering%3A_Towards_systematic_exploration_of_implemented_grammars.html">219 acl-2011-Metagrammar engineering: Towards systematic exploration of implemented grammars</a></p>
<p>Author: Antske Fokkens</p><p>Abstract: When designing grammars of natural language, typically, more than one formal analysis can account for a given phenomenon. Moreover, because analyses interact, the choices made by the engineer influence the possibilities available in further grammar development. The order in which phenomena are treated may therefore have a major impact on the resulting grammar. This paper proposes to tackle this problem by using metagrammar development as a methodology for grammar engineering. Iargue that metagrammar engineering as an approach facilitates the systematic exploration of grammars through comparison of competing analyses. The idea is illustrated through a comparative study of auxiliary structures in HPSG-based grammars for German and Dutch. Auxiliaries form a central phenomenon of German and Dutch and are likely to influence many components of the grammar. This study shows that a special auxiliary+verb construction significantly improves efficiency compared to the standard argument-composition analysis for both parsing and generation.</p><p>4 0.90553391 <a title="328-lda-4" href="./acl-2011-K-means_Clustering_with_Feature_Hashing.html">189 acl-2011-K-means Clustering with Feature Hashing</a></p>
<p>Author: Hajime Senuma</p><p>Abstract: One of the major problems of K-means is that one must use dense vectors for its centroids, and therefore it is infeasible to store such huge vectors in memory when the feature space is high-dimensional. We address this issue by using feature hashing (Weinberger et al., 2009), a dimension-reduction technique, which can reduce the size of dense vectors while retaining sparsity of sparse vectors. Our analysis gives theoretical motivation and justification for applying feature hashing to Kmeans, by showing how much will the objective of K-means be (additively) distorted. Furthermore, to empirically verify our method, we experimented on a document clustering task.</p><p>5 0.89479101 <a title="328-lda-5" href="./acl-2011-From_Bilingual_Dictionaries_to_Interlingual_Document_Representations.html">139 acl-2011-From Bilingual Dictionaries to Interlingual Document Representations</a></p>
<p>Author: Jagadeesh Jagarlamudi ; Hal Daume III ; Raghavendra Udupa</p><p>Abstract: Mapping documents into an interlingual representation can help bridge the language barrier of a cross-lingual corpus. Previous approaches use aligned documents as training data to learn an interlingual representation, making them sensitive to the domain of the training data. In this paper, we learn an interlingual representation in an unsupervised manner using only a bilingual dictionary. We first use the bilingual dictionary to find candidate document alignments and then use them to find an interlingual representation. Since the candidate alignments are noisy, we de- velop a robust learning algorithm to learn the interlingual representation. We show that bilingual dictionaries generalize to different domains better: our approach gives better performance than either a word by word translation method or Canonical Correlation Analysis (CCA) trained on a different domain.</p><p>6 0.89380932 <a title="328-lda-6" href="./acl-2011-Getting_the_Most_out_of_Transition-based_Dependency_Parsing.html">143 acl-2011-Getting the Most out of Transition-based Dependency Parsing</a></p>
<p>7 0.89054221 <a title="328-lda-7" href="./acl-2011-Nonparametric_Bayesian_Machine_Transliteration_with_Synchronous_Adaptor_Grammars.html">232 acl-2011-Nonparametric Bayesian Machine Transliteration with Synchronous Adaptor Grammars</a></p>
<p>8 0.88492578 <a title="328-lda-8" href="./acl-2011-Bayesian_Inference_for_Zodiac_and_Other_Homophonic_Ciphers.html">56 acl-2011-Bayesian Inference for Zodiac and Other Homophonic Ciphers</a></p>
<p>9 0.80970484 <a title="328-lda-9" href="./acl-2011-Joint_Identification_and_Segmentation_of_Domain-Specific_Dialogue_Acts_for_Conversational_Dialogue_Systems.html">185 acl-2011-Joint Identification and Segmentation of Domain-Specific Dialogue Acts for Conversational Dialogue Systems</a></p>
<p>10 0.62659311 <a title="328-lda-10" href="./acl-2011-Can_Document_Selection_Help_Semi-supervised_Learning%3F_A_Case_Study_On_Event_Extraction.html">65 acl-2011-Can Document Selection Help Semi-supervised Learning? A Case Study On Event Extraction</a></p>
<p>11 0.60682029 <a title="328-lda-11" href="./acl-2011-Deciphering_Foreign_Language.html">94 acl-2011-Deciphering Foreign Language</a></p>
<p>12 0.59908801 <a title="328-lda-12" href="./acl-2011-Large-Scale_Cross-Document_Coreference_Using_Distributed_Inference_and_Hierarchical_Models.html">196 acl-2011-Large-Scale Cross-Document Coreference Using Distributed Inference and Hierarchical Models</a></p>
<p>13 0.59685695 <a title="328-lda-13" href="./acl-2011-Modeling_Wisdom_of_Crowds_Using_Latent_Mixture_of_Discriminative_Experts.html">223 acl-2011-Modeling Wisdom of Crowds Using Latent Mixture of Discriminative Experts</a></p>
<p>14 0.5814842 <a title="328-lda-14" href="./acl-2011-An_Affect-Enriched_Dialogue_Act_Classification_Model_for_Task-Oriented_Dialogue.html">33 acl-2011-An Affect-Enriched Dialogue Act Classification Model for Task-Oriented Dialogue</a></p>
<p>15 0.57125598 <a title="328-lda-15" href="./acl-2011-Faster_and_Smaller_N-Gram_Language_Models.html">135 acl-2011-Faster and Smaller N-Gram Language Models</a></p>
<p>16 0.56919485 <a title="328-lda-16" href="./acl-2011-Peeling_Back_the_Layers%3A_Detecting_Event_Role_Fillers_in_Secondary_Contexts.html">244 acl-2011-Peeling Back the Layers: Detecting Event Role Fillers in Secondary Contexts</a></p>
<p>17 0.56121933 <a title="328-lda-17" href="./acl-2011-An_Error_Analysis_of_Relation_Extraction_in_Social_Media_Documents.html">40 acl-2011-An Error Analysis of Relation Extraction in Social Media Documents</a></p>
<p>18 0.55915272 <a title="328-lda-18" href="./acl-2011-A_Generative_Entity-Mention_Model_for_Linking_Entities_with_Knowledge_Base.html">12 acl-2011-A Generative Entity-Mention Model for Linking Entities with Knowledge Base</a></p>
<p>19 0.55667263 <a title="328-lda-19" href="./acl-2011-Unary_Constraints_for_Efficient_Context-Free_Parsing.html">316 acl-2011-Unary Constraints for Efficient Context-Free Parsing</a></p>
<p>20 0.55054802 <a title="328-lda-20" href="./acl-2011-Exploiting_Syntactico-Semantic_Structures_for_Relation_Extraction.html">126 acl-2011-Exploiting Syntactico-Semantic Structures for Relation Extraction</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
