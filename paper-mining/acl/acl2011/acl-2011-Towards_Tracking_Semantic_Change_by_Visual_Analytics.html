<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>307 acl-2011-Towards Tracking Semantic Change by Visual Analytics</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-307" href="#">acl2011-307</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>307 acl-2011-Towards Tracking Semantic Change by Visual Analytics</h1>
<br/><p>Source: <a title="acl-2011-307-pdf" href="http://aclweb.org/anthology//P/P11/P11-2053.pdf">pdf</a></p><p>Author: Christian Rohrdantz ; Annette Hautli ; Thomas Mayer ; Miriam Butt ; Daniel A. Keim ; Frans Plank</p><p>Abstract: This paper presents a new approach to detecting and tracking changes in word meaning by visually modeling and representing diachronic development in word contexts. Previous studies have shown that computational models are capable of clustering and disambiguating senses, a more recent trend investigates whether changes in word meaning can be tracked by automatic methods. The aim of our study is to offer a new instrument for investigating the diachronic development of word senses in a way that allows for a better understanding of the nature of semantic change in general. For this purpose we combine techniques from the field of Visual Analytics with unsupervised methods from Natural Language Processing, allowing for an interactive visual exploration of semantic change.</p><p>Reference: <a title="acl-2011-307-reference" href="../acl2011_reference/acl-2011-Towards_Tracking_Semantic_Change_by_Visual_Analytics_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Keim1 Frans Plank2 Department of Computer Science1 Department of Linguistics2 University of Konstanz  Abstract This paper presents a new approach to detecting and tracking changes in word meaning by visually modeling and representing diachronic development in word contexts. [sent-2, score-0.475]
</p><p>2 Previous studies have shown that computational models are capable of clustering and disambiguating senses, a more recent trend investigates whether changes in word meaning can be tracked by automatic methods. [sent-3, score-0.344]
</p><p>3 The aim of our study is to offer a new instrument for investigating the diachronic development of word senses in a way that allows for a better understanding of the nature of semantic change in general. [sent-4, score-1.002]
</p><p>4 For this purpose we combine techniques from the field of Visual Analytics with unsupervised methods from Natural Language Processing, allowing for an interactive visual exploration of semantic change. [sent-5, score-0.188]
</p><p>5 1 Introduction  The problem of determining and inferring the sense of a word on the basis of its context has been the subject of quite a bit of research. [sent-6, score-0.26]
</p><p>6 Earlier investigations have mainly focused on the disambiguation of word senses from information contained in the context, e. [sent-7, score-0.617]
</p><p>7 Sch u¨tze (1998) or on the induction of word senses (Yarowsky, 1995). [sent-9, score-0.527]
</p><p>8 Only recently, the field has added a diachronic dimension to its investigations and has moved towards the computational detection of sense development over time (Sagi et al. [sent-10, score-0.607]
</p><p>9 , 2009; Cook and Stevenson, 2010), thereby complementing theoretical investigations in historical linguistics with information gained from large corpora. [sent-11, score-0.142]
</p><p>10 These approaches have concentrated on measuring 305 general changes in the meaning of a word (e. [sent-12, score-0.22]
</p><p>11 , narrowing or pejoration), whereas in this paper we deal with cases where words acquire a new sense by extending their contexts to other domains. [sent-14, score-0.423]
</p><p>12 For the scope of this investigation we restrict ourselves to cases of semantic change in English even though the methodology is generally language independent. [sent-15, score-0.19]
</p><p>13 Our choice is on the one hand motivated by the extensive knowledge available on se-  mantic change in English. [sent-16, score-0.106]
</p><p>14 1 Given the variety and the amount of text available, we are able to track changes from 1987 until 2007 in 1. [sent-19, score-0.119]
</p><p>15 In order to be able to explore our approach in a fruitful manner, we decided to concentrate on words which have acquired a new dimension of use due to the introduction of computing and the internet, e. [sent-21, score-0.108]
</p><p>16 In particular, the Netscape Navigator was introduced in 1994 and our data show that this does indeed correlate with a change in use of these words. [sent-24, score-0.106]
</p><p>17 This combination provides a novel instrument which allows for tracking the diachronic development of word meaning by visualizing the contexts in which the words occur. [sent-27, score-0.589]
</p><p>18 Our overall aim is not to replace linguistic analysis in  1http : / /http : / /www . [sent-28, score-0.048]
</p><p>19 i ac t2io0n11 fo Ar Cssoocmiaptuiotanti foonra Clo Lminpguutiast i ocns:aslh Loirntpgaupisetrics , pages 305–310, this field with an automatic method, but to guide research by generating new hypotheses about the development of semantic change. [sent-33, score-0.096]
</p><p>20 2  Related work  The computational modeling ofword senses is based on the assumption that the meaning of a word can be inferred from the words in its immediate context (“context words”). [sent-34, score-0.608]
</p><p>21 The goal of WSD is to classify occurrences of polysemous words according to manually predefined senses. [sent-36, score-0.032]
</p><p>22 The aim of WSI is to learn word senses from text corpora without having a predefined number of  senses. [sent-39, score-0.544]
</p><p>23 This goal is more difficult to achieve, as it is not clear beforehand how many senses should be extracted and how a sense could be described in an abstract way. [sent-40, score-0.647]
</p><p>24 , 2003) can be successfully applied to perform word sense induction from small word contexts. [sent-42, score-0.281]
</p><p>25 The original idea of LSA and LDA is to learn “topics” from documents, whereas in our scenario word contexts rather than documents are used, i. [sent-43, score-0.214]
</p><p>26 , a small number of words before and after the word under investigation (bag of words). [sent-45, score-0.033]
</p><p>27 (2009) have demonstrated that broadening and narrowing of word senses can be tracked over time by applying LSA to small word contexts in diachronic corpora. [sent-47, score-1.159]
</p><p>28 In general, the aim of our paper is to go beyond the approach of Sagi et al. [sent-49, score-0.048]
</p><p>29 Ideally, a starting point of change is found and the development over time can be tracked, paired with a quantitative comparison of prevailing senses. [sent-51, score-0.205]
</p><p>30 We therefore suggest  to visualize word contexts in order to gain a better understanding of diachronic developments and also generate hypotheses for further investigations. [sent-52, score-0.468]
</p><p>31 306 3 An interactive visualization approach to semantic change In order to test our approach, we opted for a large corpus with a high temporal resolution. [sent-53, score-0.422]
</p><p>32 8 million newspaper articles from 1987 to 2007 has a rather small time depth of 20 years but provides a time stamp for the exact publication date. [sent-55, score-0.26]
</p><p>33 Therefore, changes can be tracked on a daily basis. [sent-56, score-0.242]
</p><p>34 The data processing involved context extraction, vector space creation, and sense modeling. [sent-57, score-0.227]
</p><p>35 As Sch u¨tze (1998) showed, looking at a context window of 25 words before and after a key word provides enough information in order to disambiguate word senses. [sent-58, score-0.109]
</p><p>36 Each extracted context is complemented with the time stamp from the corpus. [sent-59, score-0.234]
</p><p>37 To reduce the dimensionality, all context words were lemmatized and stop words were filtered out. [sent-60, score-0.043]
</p><p>38 For the set of all contexts of a key word, a global LDA model was trained using the MALLET toolkit2  (McCallum, 2002). [sent-61, score-0.181]
</p><p>39 Each context is assigned to its most probable topic/sense, complemented by a specific point on the time scale according to its time stamp from the corpus. [sent-62, score-0.288]
</p><p>40 Contexts for which the highest probability was less than 40% were omitted because they could not be assigned to a certain sense unambiguously. [sent-63, score-0.184]
</p><p>41 The distribution of senses over time was then visualized. [sent-64, score-0.517]
</p><p>42 1 Visualization Different visualizations provide multidimensional views on the data and yield a better understanding of the developments. [sent-66, score-0.203]
</p><p>43 While plotting every word occurrence individually offers the opportunity to detect and inspect outliers, aggregated views on the data are able to provide insights on overall developments. [sent-67, score-0.074]
</p><p>44 Figure 1provides a view where the percentages of word contexts belonging to different senses are plotted over time. [sent-68, score-0.721]
</p><p>45 For the verbs to browse and to surf seven senses are learned with LDA. [sent-69, score-0.992]
</p><p>46 Each sense corresponds to one row and is described by the top five terms identified by LDA. [sent-70, score-0.184]
</p><p>47 The higher the gray area at a certain x-axis point, the more of the contexts of the corresponding year belong to the specific sense. [sent-71, score-0.293]
</p><p>48 Each shade of gray represents 10% of the overall  data, i. [sent-72, score-0.08]
</p><p>49 , three shades of gray mean that between 2http : //mallet . [sent-74, score-0.109]
</p><p>50 Figure 2 shows the development of contexts over time, with each context plotted individually. [sent-79, score-0.313]
</p><p>51 3 Each axis represents one sense of to browse, in each subfigure different combinations of senses are plotted. [sent-81, score-0.705]
</p><p>52 f) belong to both senses with at least 40% probability. [sent-86, score-0.463]
</p><p>53 Senses that share many ambiguous contexts are usually similar. [sent-87, score-0.228]
</p><p>54 By mousing over a colored dot, its context is shown, allowing for an in depth analysis. [sent-88, score-0.14]
</p><p>55 2 Case studies In order to be able to judge the effectiveness of our new approach, we chose key words that are likely  candidates for a change in use in the time from 1987 to 2007. [sent-90, score-0.201]
</p><p>56 That is, we concentrated on terms relating to the relatively recent introduction of the internet. [sent-91, score-0.04]
</p><p>57 The advantage of these terms is that the cause of change can be located precisely in time. [sent-92, score-0.106]
</p><p>58 Figure 1 shows the temporal sense development of the verbs to browse and to surf, together with the descriptive terms for each sense. [sent-93, score-0.625]
</p><p>59 307 browse and sense k for to surf pattern quite similarly. [sent-95, score-0.713]
</p><p>60 Inspecting their contexts reveals that both senses appear with the invention of web browsers, peaking shortly after the introduction of Netscape Navigator (1994). [sent-96, score-0.644]
</p><p>61 For to browse, another broader sense (sense f) concerning browsing in both the internet and digital media collections shows a continuous increase over time, dominating in 2007. [sent-97, score-0.606]
</p><p>62 The first occurrences assigned to sense f in 1987 are “browse data bases”, “word-by-word browsing” in databases and “browsing files in the center’s library”, referring to physical files, namely photographs. [sent-98, score-0.291]
</p><p>63 We speculate that the sense of browsing physical media might haven given rise to the sense  which refers to browsing electronic media, which in turn becomes the dominating sense with the advent of the web. [sent-99, score-1.228]
</p><p>64 Figure 2 shows pairwise comparisons of word senses with respect to the contexts they share, i. [sent-100, score-0.71]
</p><p>65 , contexts that cannot unambiguously be assigned to one or the other. [sent-102, score-0.181]
</p><p>66 Each context is represented by one dot colored according to its time stamp. [sent-103, score-0.211]
</p><p>67 It can be seen that senses d (animals that browse) and e (browsing the web) share no contexts at all. [sent-104, score-0.691]
</p><p>68 Senses d (animals that browse) and f (browsing files) share only few contexts. [sent-105, score-0.047]
</p><p>69 In turn, senses e and f share a fair number of contexts, which is to be expected, as they are closely related. [sent-106, score-0.51]
</p><p>70 Single contexts, each represented by a colored dot, can be inspected via a  Figure 2: Pairwise comparisons of different senses for the verb “to browse”. [sent-107, score-0.559]
</p><p>71 In each subfigure different combinations  of LDA dimensions  are mapped on the axes. [sent-108, score-0.133]
</p><p>72 For each dimension the top 5 positively associated terms were extracted, together with their value in the corresponding dimension. [sent-110, score-0.067]
</p><p>73 This allows for an in-depth look at specific data points and a better understanding how the data points relate to a sense. [sent-112, score-0.039]
</p><p>74 LDA  In comparison, Table 1 shows the LSA dimensions learned from the contexts of the verb to browse. [sent-115, score-0.256]
</p><p>75 The top five associated terms for each dimension have  been extracted as descriptor. [sent-116, score-0.067]
</p><p>76 The dimensions are heavily dominated by senses strongly represented in the corpus (e. [sent-117, score-0.538]
</p><p>77 , animals that browse) only occur in very low-ranked dimensions and are mixed with other senses (see the bold term deer in dimension 15). [sent-122, score-0.709]
</p><p>78 308 4  Evaluation  We compared the findings provided by our visualization with word sense information coming from various resources, namely the 2007 Collins dictionary (COLL), the English WordNet4 (WN) (Fellbaum, 1998) and the Longman Dictionary (LONG) from 1987. [sent-123, score-0.422]
</p><p>79 However, we are well aware that dictionaries are by no means good gold standards as lexicographers themselves vary greatly when assigning word senses. [sent-125, score-0.033]
</p><p>80 In the case of to browse, COLL and WordNet  suggest the senses “shopping around; not necessarily buying”, “feed as in a meadow or pasture” and “browse a computer directory, surfthe internet or the world wide web. [sent-127, score-0.504]
</p><p>81 ” These senses are also identified in our visualizations, which even additionally differentiate between the senses of “browsing the web” and “browsing a computer directory. [sent-128, score-0.926]
</p><p>82 ” A WordNet sense that cannot be detected in the data is the meaning “to eat lightly and try different dishes. [sent-129, score-0.295]
</p><p>83 ” Table 2 shows the results of comparing dictionary word senses (DIC) with the results from our visualization (VIS). [sent-130, score-0.67]
</p><p>84 What can be seen is that our method is able to track semantic change diachronically and 4http : / /wordnetweb . [sent-131, score-0.198]
</p><p>85 In the case of “messenger”, the visualizations suggest another sense related to  “instant messaging” that arises with the advent of the AOL instant messenger in 1997. [sent-135, score-0.504]
</p><p>86 This leads us to the conclusion that our method is appropriate from a historical linguistic point of view. [sent-136, score-0.058]
</p><p>87 5  Discussion and conclusions  When dealing with a complex phenomenon such as semantic change, one has to be aware of the limitations of an automatic approach in order to be able to draw the right conclusions from its results. [sent-137, score-0.123]
</p><p>88 The first results of the case studies presented in this paper show that LDA is useful for distinguishing different word senses on the basis of word contexts and performs better than LSA for this task. [sent-138, score-0.71]
</p><p>89 This makes it possible to compensate for one of the major disadvantages  of generative and vector space models, namely their functioning as “black boxes” whose results cannot be tracked easily. [sent-140, score-0.164]
</p><p>90 The biggest problem in dealing with a corpusbased method of detecting meaning change is the availability of suitable corpora. [sent-141, score-0.206]
</p><p>91 First, computing semantic information on the basis of contexts requires a large amount of data in order to be able to infer reliable results. [sent-142, score-0.305]
</p><p>92 Second, the words in the context from which the meanings will be distinguished should be 309 both semantically and orthographically stable over time so that comparisons between different stages in the development of the language can be made. [sent-143, score-0.209]
</p><p>93 On the one hand words do change their meaning, after all this is what the present study is all about. [sent-145, score-0.106]
</p><p>94 However, we assume that the meanings in a certain context window are stable enough to infer reliable results provided it is possible that the forms of the same words in different periods can be linked. [sent-146, score-0.109]
</p><p>95 This of course limits the applicability of the approach to smaller time ranges due to changes in the phonetic form of words. [sent-147, score-0.165]
</p><p>96 Moreover, in particular for older pe-  riods of the language, different variants for the same word, either due to sound changes or different (or rather no) spelling conventions, abound. [sent-148, score-0.078]
</p><p>97 For now, we circumvent this problem by testing our tool on corpora where the drawbacks of historical texts are less severe but at the same time interesting developments can be detected to prove our approach correct. [sent-149, score-0.196]
</p><p>98 For future research, we want to test our methodology on a broader range of terms, texts and languages and develop novel interactive visualizations to aid investigations in two ways. [sent-150, score-0.364]
</p><p>99 As a first aim, the user should be allowed to check the validity and quality of the visualizations by experimenting with parameter settings and inspecting their outcome. [sent-151, score-0.208]
</p><p>100 Second, the user is supposed to gain a better understanding of semantic change by interactively exploring a corpus. [sent-152, score-0.196]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('senses', 0.463), ('browse', 0.356), ('browsing', 0.237), ('sense', 0.184), ('contexts', 0.181), ('visualization', 0.174), ('diachronic', 0.173), ('surf', 0.173), ('tracked', 0.164), ('visualizations', 0.164), ('sagi', 0.131), ('lsa', 0.123), ('lda', 0.116), ('change', 0.106), ('analytics', 0.095), ('stamp', 0.087), ('visual', 0.086), ('investigations', 0.084), ('gray', 0.08), ('changes', 0.078), ('animals', 0.075), ('dimensions', 0.075), ('cook', 0.071), ('meaning', 0.069), ('dimension', 0.067), ('coll', 0.066), ('keim', 0.066), ('navigator', 0.066), ('netscape', 0.066), ('colored', 0.063), ('historical', 0.058), ('narrowing', 0.058), ('subfigure', 0.058), ('konstanz', 0.058), ('ocf', 0.058), ('advent', 0.058), ('time', 0.054), ('messenger', 0.053), ('mallet', 0.053), ('wsi', 0.053), ('semantic', 0.051), ('interactive', 0.051), ('dot', 0.051), ('complemented', 0.05), ('aim', 0.048), ('deerwester', 0.047), ('brody', 0.047), ('share', 0.047), ('thomas', 0.046), ('instant', 0.045), ('development', 0.045), ('tracking', 0.044), ('inspecting', 0.044), ('plotted', 0.044), ('instrument', 0.044), ('context', 0.043), ('dominating', 0.042), ('developments', 0.042), ('wsd', 0.042), ('sch', 0.042), ('detected', 0.042), ('internet', 0.041), ('wo', 0.041), ('able', 0.041), ('files', 0.04), ('temporal', 0.04), ('concentrated', 0.04), ('understanding', 0.039), ('media', 0.038), ('disambiguation', 0.037), ('physical', 0.035), ('meanings', 0.034), ('tze', 0.034), ('depth', 0.034), ('methodology', 0.033), ('word', 0.033), ('comparisons', 0.033), ('phonetic', 0.033), ('occurrences', 0.032), ('year', 0.032), ('broader', 0.032), ('concerning', 0.032), ('reliable', 0.032), ('coming', 0.031), ('dealing', 0.031), ('newspaper', 0.031), ('blei', 0.031), ('induction', 0.031), ('wordnet', 0.031), ('latent', 0.03), ('darker', 0.029), ('shades', 0.029), ('explorative', 0.029), ('delve', 0.029), ('kachites', 0.029), ('roll', 0.029), ('deer', 0.029), ('ellis', 0.029), ('kristin', 0.029), ('haven', 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000008 <a title="307-tfidf-1" href="./acl-2011-Towards_Tracking_Semantic_Change_by_Visual_Analytics.html">307 acl-2011-Towards Tracking Semantic Change by Visual Analytics</a></p>
<p>Author: Christian Rohrdantz ; Annette Hautli ; Thomas Mayer ; Miriam Butt ; Daniel A. Keim ; Frans Plank</p><p>Abstract: This paper presents a new approach to detecting and tracking changes in word meaning by visually modeling and representing diachronic development in word contexts. Previous studies have shown that computational models are capable of clustering and disambiguating senses, a more recent trend investigates whether changes in word meaning can be tracked by automatic methods. The aim of our study is to offer a new instrument for investigating the diachronic development of word senses in a way that allows for a better understanding of the nature of semantic change in general. For this purpose we combine techniques from the field of Visual Analytics with unsupervised methods from Natural Language Processing, allowing for an interactive visual exploration of semantic change.</p><p>2 0.32382366 <a title="307-tfidf-2" href="./acl-2011-Identification_of_Domain-Specific_Senses_in_a_Machine-Readable_Dictionary.html">158 acl-2011-Identification of Domain-Specific Senses in a Machine-Readable Dictionary</a></p>
<p>Author: Fumiyo Fukumoto ; Yoshimi Suzuki</p><p>Abstract: This paper focuses on domain-specific senses and presents a method for assigning category/domain label to each sense of words in a dictionary. The method first identifies each sense of a word in the dictionary to its corresponding category. We used a text classification technique to select appropriate senses for each domain. Then, senses were scored by computing the rank scores. We used Markov Random Walk (MRW) model. The method was tested on English and Japanese resources, WordNet 3.0 and EDR Japanese dictionary. For evaluation of the method, we compared English results with the Subject Field Codes (SFC) resources. We also compared each English and Japanese results to the first sense heuristics in the WSD task. These results suggest that identification of domain-specific senses (IDSS) may actually be of benefit.</p><p>3 0.31237796 <a title="307-tfidf-3" href="./acl-2011-Latent_Semantic_Word_Sense_Induction_and_Disambiguation.html">198 acl-2011-Latent Semantic Word Sense Induction and Disambiguation</a></p>
<p>Author: Tim Van de Cruys ; Marianna Apidianaki</p><p>Abstract: In this paper, we present a unified model for the automatic induction of word senses from text, and the subsequent disambiguation of particular word instances using the automatically extracted sense inventory. The induction step and the disambiguation step are based on the same principle: words and contexts are mapped to a limited number of topical dimensions in a latent semantic word space. The intuition is that a particular sense is associated with a particular topic, so that different senses can be discriminated through their association with particular topical dimensions; in a similar vein, a particular instance of a word can be disambiguated by determining its most important topical dimensions. The model is evaluated on the SEMEVAL-20 10 word sense induction and disambiguation task, on which it reaches stateof-the-art results.</p><p>4 0.16728194 <a title="307-tfidf-4" href="./acl-2011-Models_and_Training_for_Unsupervised_Preposition_Sense_Disambiguation.html">224 acl-2011-Models and Training for Unsupervised Preposition Sense Disambiguation</a></p>
<p>Author: Dirk Hovy ; Ashish Vaswani ; Stephen Tratz ; David Chiang ; Eduard Hovy</p><p>Abstract: We present a preliminary study on unsupervised preposition sense disambiguation (PSD), comparing different models and training techniques (EM, MAP-EM with L0 norm, Bayesian inference using Gibbs sampling). To our knowledge, this is the first attempt at unsupervised preposition sense disambiguation. Our best accuracy reaches 56%, a significant improvement (at p <.001) of 16% over the most-frequent-sense baseline.</p><p>5 0.15692212 <a title="307-tfidf-5" href="./acl-2011-Which_Noun_Phrases_Denote_Which_Concepts%3F.html">334 acl-2011-Which Noun Phrases Denote Which Concepts?</a></p>
<p>Author: Jayant Krishnamurthy ; Tom Mitchell</p><p>Abstract: Resolving polysemy and synonymy is required for high-quality information extraction. We present ConceptResolver, a component for the Never-Ending Language Learner (NELL) (Carlson et al., 2010) that handles both phenomena by identifying the latent concepts that noun phrases refer to. ConceptResolver performs both word sense induction and synonym resolution on relations extracted from text using an ontology and a small amount of labeled data. Domain knowledge (the ontology) guides concept creation by defining a set of possible semantic types for concepts. Word sense induction is performed by inferring a set of semantic types for each noun phrase. Synonym detection exploits redundant informa- tion to train several domain-specific synonym classifiers in a semi-supervised fashion. When ConceptResolver is run on NELL’s knowledge base, 87% of the word senses it creates correspond to real-world concepts, and 85% of noun phrases that it suggests refer to the same concept are indeed synonyms.</p><p>6 0.14906538 <a title="307-tfidf-6" href="./acl-2011-Disambiguating_temporal-contrastive_connectives_for_machine_translation.html">96 acl-2011-Disambiguating temporal-contrastive connectives for machine translation</a></p>
<p>7 0.11962758 <a title="307-tfidf-7" href="./acl-2011-ParaSense_or_How_to_Use_Parallel_Corpora_for_Word_Sense_Disambiguation.html">240 acl-2011-ParaSense or How to Use Parallel Corpora for Word Sense Disambiguation</a></p>
<p>8 0.11812057 <a title="307-tfidf-8" href="./acl-2011-Improving_Dependency_Parsing_with_Semantic_Classes.html">167 acl-2011-Improving Dependency Parsing with Semantic Classes</a></p>
<p>9 0.07529705 <a title="307-tfidf-9" href="./acl-2011-Learning_Word_Vectors_for_Sentiment_Analysis.html">204 acl-2011-Learning Word Vectors for Sentiment Analysis</a></p>
<p>10 0.062746562 <a title="307-tfidf-10" href="./acl-2011-HITS-based_Seed_Selection_and_Stop_List_Construction_for_Bootstrapping.html">148 acl-2011-HITS-based Seed Selection and Stop List Construction for Bootstrapping</a></p>
<p>11 0.061531745 <a title="307-tfidf-11" href="./acl-2011-Word_Maturity%3A_Computational_Modeling_of_Word_Knowledge.html">341 acl-2011-Word Maturity: Computational Modeling of Word Knowledge</a></p>
<p>12 0.061123863 <a title="307-tfidf-12" href="./acl-2011-Together_We_Can%3A_Bilingual_Bootstrapping_for_WSD.html">304 acl-2011-Together We Can: Bilingual Bootstrapping for WSD</a></p>
<p>13 0.059287004 <a title="307-tfidf-13" href="./acl-2011-Good_Seed_Makes_a_Good_Crop%3A_Accelerating_Active_Learning_Using_Language_Modeling.html">145 acl-2011-Good Seed Makes a Good Crop: Accelerating Active Learning Using Language Modeling</a></p>
<p>14 0.057643067 <a title="307-tfidf-14" href="./acl-2011-Evaluating_the_Impact_of_Coder_Errors_on_Active_Learning.html">119 acl-2011-Evaluating the Impact of Coder Errors on Active Learning</a></p>
<p>15 0.055003393 <a title="307-tfidf-15" href="./acl-2011-Interactive_Topic_Modeling.html">178 acl-2011-Interactive Topic Modeling</a></p>
<p>16 0.053352017 <a title="307-tfidf-16" href="./acl-2011-Identifying_Word_Translations_from_Comparable_Corpora_Using_Latent_Topic_Models.html">161 acl-2011-Identifying Word Translations from Comparable Corpora Using Latent Topic Models</a></p>
<p>17 0.052816954 <a title="307-tfidf-17" href="./acl-2011-Subjective_Natural_Language_Problems%3A_Motivations%2C_Applications%2C_Characterizations%2C_and_Implications.html">288 acl-2011-Subjective Natural Language Problems: Motivations, Applications, Characterizations, and Implications</a></p>
<p>18 0.048341349 <a title="307-tfidf-18" href="./acl-2011-A_Latent_Topic_Extracting_Method_based_on_Events_in_a_Document_and_its_Application.html">18 acl-2011-A Latent Topic Extracting Method based on Events in a Document and its Application</a></p>
<p>19 0.047742881 <a title="307-tfidf-19" href="./acl-2011-Age_Prediction_in_Blogs%3A_A_Study_of_Style%2C_Content%2C_and_Online_Behavior_in_Pre-_and_Post-Social_Media_Generations.html">31 acl-2011-Age Prediction in Blogs: A Study of Style, Content, and Online Behavior in Pre- and Post-Social Media Generations</a></p>
<p>20 0.047457978 <a title="307-tfidf-20" href="./acl-2011-A_Hierarchical_Model_of_Web_Summaries.html">14 acl-2011-A Hierarchical Model of Web Summaries</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.146), (1, 0.05), (2, -0.059), (3, 0.007), (4, -0.01), (5, -0.031), (6, 0.121), (7, 0.056), (8, -0.045), (9, -0.027), (10, -0.013), (11, -0.225), (12, 0.233), (13, 0.051), (14, -0.019), (15, -0.152), (16, 0.21), (17, 0.19), (18, -0.068), (19, 0.198), (20, 0.077), (21, -0.046), (22, -0.015), (23, 0.028), (24, -0.034), (25, 0.019), (26, 0.062), (27, -0.022), (28, -0.099), (29, 0.018), (30, -0.097), (31, 0.085), (32, -0.025), (33, 0.082), (34, -0.073), (35, -0.053), (36, -0.067), (37, 0.001), (38, 0.022), (39, -0.01), (40, 0.006), (41, -0.004), (42, 0.063), (43, 0.059), (44, 0.045), (45, -0.021), (46, -0.058), (47, -0.001), (48, 0.019), (49, -0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96731746 <a title="307-lsi-1" href="./acl-2011-Towards_Tracking_Semantic_Change_by_Visual_Analytics.html">307 acl-2011-Towards Tracking Semantic Change by Visual Analytics</a></p>
<p>Author: Christian Rohrdantz ; Annette Hautli ; Thomas Mayer ; Miriam Butt ; Daniel A. Keim ; Frans Plank</p><p>Abstract: This paper presents a new approach to detecting and tracking changes in word meaning by visually modeling and representing diachronic development in word contexts. Previous studies have shown that computational models are capable of clustering and disambiguating senses, a more recent trend investigates whether changes in word meaning can be tracked by automatic methods. The aim of our study is to offer a new instrument for investigating the diachronic development of word senses in a way that allows for a better understanding of the nature of semantic change in general. For this purpose we combine techniques from the field of Visual Analytics with unsupervised methods from Natural Language Processing, allowing for an interactive visual exploration of semantic change.</p><p>2 0.92424881 <a title="307-lsi-2" href="./acl-2011-Identification_of_Domain-Specific_Senses_in_a_Machine-Readable_Dictionary.html">158 acl-2011-Identification of Domain-Specific Senses in a Machine-Readable Dictionary</a></p>
<p>Author: Fumiyo Fukumoto ; Yoshimi Suzuki</p><p>Abstract: This paper focuses on domain-specific senses and presents a method for assigning category/domain label to each sense of words in a dictionary. The method first identifies each sense of a word in the dictionary to its corresponding category. We used a text classification technique to select appropriate senses for each domain. Then, senses were scored by computing the rank scores. We used Markov Random Walk (MRW) model. The method was tested on English and Japanese resources, WordNet 3.0 and EDR Japanese dictionary. For evaluation of the method, we compared English results with the Subject Field Codes (SFC) resources. We also compared each English and Japanese results to the first sense heuristics in the WSD task. These results suggest that identification of domain-specific senses (IDSS) may actually be of benefit.</p><p>3 0.84143347 <a title="307-lsi-3" href="./acl-2011-Latent_Semantic_Word_Sense_Induction_and_Disambiguation.html">198 acl-2011-Latent Semantic Word Sense Induction and Disambiguation</a></p>
<p>Author: Tim Van de Cruys ; Marianna Apidianaki</p><p>Abstract: In this paper, we present a unified model for the automatic induction of word senses from text, and the subsequent disambiguation of particular word instances using the automatically extracted sense inventory. The induction step and the disambiguation step are based on the same principle: words and contexts are mapped to a limited number of topical dimensions in a latent semantic word space. The intuition is that a particular sense is associated with a particular topic, so that different senses can be discriminated through their association with particular topical dimensions; in a similar vein, a particular instance of a word can be disambiguated by determining its most important topical dimensions. The model is evaluated on the SEMEVAL-20 10 word sense induction and disambiguation task, on which it reaches stateof-the-art results.</p><p>4 0.77330112 <a title="307-lsi-4" href="./acl-2011-Which_Noun_Phrases_Denote_Which_Concepts%3F.html">334 acl-2011-Which Noun Phrases Denote Which Concepts?</a></p>
<p>Author: Jayant Krishnamurthy ; Tom Mitchell</p><p>Abstract: Resolving polysemy and synonymy is required for high-quality information extraction. We present ConceptResolver, a component for the Never-Ending Language Learner (NELL) (Carlson et al., 2010) that handles both phenomena by identifying the latent concepts that noun phrases refer to. ConceptResolver performs both word sense induction and synonym resolution on relations extracted from text using an ontology and a small amount of labeled data. Domain knowledge (the ontology) guides concept creation by defining a set of possible semantic types for concepts. Word sense induction is performed by inferring a set of semantic types for each noun phrase. Synonym detection exploits redundant informa- tion to train several domain-specific synonym classifiers in a semi-supervised fashion. When ConceptResolver is run on NELL’s knowledge base, 87% of the word senses it creates correspond to real-world concepts, and 85% of noun phrases that it suggests refer to the same concept are indeed synonyms.</p><p>5 0.67836189 <a title="307-lsi-5" href="./acl-2011-Models_and_Training_for_Unsupervised_Preposition_Sense_Disambiguation.html">224 acl-2011-Models and Training for Unsupervised Preposition Sense Disambiguation</a></p>
<p>Author: Dirk Hovy ; Ashish Vaswani ; Stephen Tratz ; David Chiang ; Eduard Hovy</p><p>Abstract: We present a preliminary study on unsupervised preposition sense disambiguation (PSD), comparing different models and training techniques (EM, MAP-EM with L0 norm, Bayesian inference using Gibbs sampling). To our knowledge, this is the first attempt at unsupervised preposition sense disambiguation. Our best accuracy reaches 56%, a significant improvement (at p <.001) of 16% over the most-frequent-sense baseline.</p><p>6 0.64723742 <a title="307-lsi-6" href="./acl-2011-Disambiguating_temporal-contrastive_connectives_for_machine_translation.html">96 acl-2011-Disambiguating temporal-contrastive connectives for machine translation</a></p>
<p>7 0.55715597 <a title="307-lsi-7" href="./acl-2011-ParaSense_or_How_to_Use_Parallel_Corpora_for_Word_Sense_Disambiguation.html">240 acl-2011-ParaSense or How to Use Parallel Corpora for Word Sense Disambiguation</a></p>
<p>8 0.46415111 <a title="307-lsi-8" href="./acl-2011-Improving_Dependency_Parsing_with_Semantic_Classes.html">167 acl-2011-Improving Dependency Parsing with Semantic Classes</a></p>
<p>9 0.4516972 <a title="307-lsi-9" href="./acl-2011-Word_Maturity%3A_Computational_Modeling_of_Word_Knowledge.html">341 acl-2011-Word Maturity: Computational Modeling of Word Knowledge</a></p>
<p>10 0.44784546 <a title="307-lsi-10" href="./acl-2011-Even_the_Abstract_have_Color%3A_Consensus_in_Word-Colour_Associations.html">120 acl-2011-Even the Abstract have Color: Consensus in Word-Colour Associations</a></p>
<p>11 0.40663049 <a title="307-lsi-11" href="./acl-2011-Model-Portability_Experiments_for_Textual_Temporal_Analysis.html">222 acl-2011-Model-Portability Experiments for Textual Temporal Analysis</a></p>
<p>12 0.38912517 <a title="307-lsi-12" href="./acl-2011-Unsupervised_Decomposition_of_a_Document_into_Authorial_Components.html">319 acl-2011-Unsupervised Decomposition of a Document into Authorial Components</a></p>
<p>13 0.38850665 <a title="307-lsi-13" href="./acl-2011-Subjective_Natural_Language_Problems%3A_Motivations%2C_Applications%2C_Characterizations%2C_and_Implications.html">288 acl-2011-Subjective Natural Language Problems: Motivations, Applications, Characterizations, and Implications</a></p>
<p>14 0.38328555 <a title="307-lsi-14" href="./acl-2011-Together_We_Can%3A_Bilingual_Bootstrapping_for_WSD.html">304 acl-2011-Together We Can: Bilingual Bootstrapping for WSD</a></p>
<p>15 0.35831687 <a title="307-lsi-15" href="./acl-2011-Predicting_Clicks_in_a_Vocabulary_Learning_System.html">248 acl-2011-Predicting Clicks in a Vocabulary Learning System</a></p>
<p>16 0.32978216 <a title="307-lsi-16" href="./acl-2011-HITS-based_Seed_Selection_and_Stop_List_Construction_for_Bootstrapping.html">148 acl-2011-HITS-based Seed Selection and Stop List Construction for Bootstrapping</a></p>
<p>17 0.29875964 <a title="307-lsi-17" href="./acl-2011-NULEX%3A_An_Open-License_Broad_Coverage_Lexicon.html">229 acl-2011-NULEX: An Open-License Broad Coverage Lexicon</a></p>
<p>18 0.29373077 <a title="307-lsi-18" href="./acl-2011-Local_and_Global_Algorithms_for_Disambiguation_to_Wikipedia.html">213 acl-2011-Local and Global Algorithms for Disambiguation to Wikipedia</a></p>
<p>19 0.29220453 <a title="307-lsi-19" href="./acl-2011-Wikulu%3A_An_Extensible_Architecture_for_Integrating_Natural_Language_Processing_Techniques_with_Wikis.html">338 acl-2011-Wikulu: An Extensible Architecture for Integrating Natural Language Processing Techniques with Wikis</a></p>
<p>20 0.27771801 <a title="307-lsi-20" href="./acl-2011-Good_Seed_Makes_a_Good_Crop%3A_Accelerating_Active_Learning_Using_Language_Modeling.html">145 acl-2011-Good Seed Makes a Good Crop: Accelerating Active Learning Using Language Modeling</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.013), (5, 0.054), (17, 0.043), (26, 0.03), (37, 0.1), (39, 0.052), (41, 0.063), (53, 0.015), (55, 0.027), (59, 0.063), (71, 0.268), (72, 0.035), (91, 0.024), (96, 0.12), (97, 0.017), (98, 0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.81891567 <a title="307-lda-1" href="./acl-2011-Semantic_Representation_of_Negation_Using_Focus_Detection.html">273 acl-2011-Semantic Representation of Negation Using Focus Detection</a></p>
<p>Author: Eduardo Blanco ; Dan Moldovan</p><p>Abstract: Negation is present in all human languages and it is used to reverse the polarity of part of statements that are otherwise affirmative by default. A negated statement often carries positive implicit meaning, but to pinpoint the positive part from the negative part is rather difficult. This paper aims at thoroughly representing the semantics of negation by revealing implicit positive meaning. The proposed representation relies on focus of negation detection. For this, new annotation over PropBank and a learning algorithm are proposed.</p><p>same-paper 2 0.77453017 <a title="307-lda-2" href="./acl-2011-Towards_Tracking_Semantic_Change_by_Visual_Analytics.html">307 acl-2011-Towards Tracking Semantic Change by Visual Analytics</a></p>
<p>Author: Christian Rohrdantz ; Annette Hautli ; Thomas Mayer ; Miriam Butt ; Daniel A. Keim ; Frans Plank</p><p>Abstract: This paper presents a new approach to detecting and tracking changes in word meaning by visually modeling and representing diachronic development in word contexts. Previous studies have shown that computational models are capable of clustering and disambiguating senses, a more recent trend investigates whether changes in word meaning can be tracked by automatic methods. The aim of our study is to offer a new instrument for investigating the diachronic development of word senses in a way that allows for a better understanding of the nature of semantic change in general. For this purpose we combine techniques from the field of Visual Analytics with unsupervised methods from Natural Language Processing, allowing for an interactive visual exploration of semantic change.</p><p>3 0.6956706 <a title="307-lda-3" href="./acl-2011-Exploiting_Syntactico-Semantic_Structures_for_Relation_Extraction.html">126 acl-2011-Exploiting Syntactico-Semantic Structures for Relation Extraction</a></p>
<p>Author: Yee Seng Chan ; Dan Roth</p><p>Abstract: In this paper, we observe that there exists a second dimension to the relation extraction (RE) problem that is orthogonal to the relation type dimension. We show that most of these second dimensional structures are relatively constrained and not difficult to identify. We propose a novel algorithmic approach to RE that starts by first identifying these structures and then, within these, identifying the semantic type of the relation. In the real RE problem where relation arguments need to be identified, exploiting these structures also allows reducing pipelined propagated errors. We show that this RE framework provides significant improvement in RE performance.</p><p>4 0.68119615 <a title="307-lda-4" href="./acl-2011-Clause_Restructuring_For_SMT_Not_Absolutely_Helpful.html">69 acl-2011-Clause Restructuring For SMT Not Absolutely Helpful</a></p>
<p>Author: Susan Howlett ; Mark Dras</p><p>Abstract: There are a number of systems that use a syntax-based reordering step prior to phrasebased statistical MT. An early work proposing this idea showed improved translation performance, but subsequent work has had mixed results. Speculations as to cause have suggested the parser, the data, or other factors. We systematically investigate possible factors to give an initial answer to the question: Under what conditions does this use of syntax help PSMT?</p><p>5 0.58091414 <a title="307-lda-5" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>Author: Joel Lang ; Mirella Lapata</p><p>Abstract: In this paper we describe an unsupervised method for semantic role induction which holds promise for relieving the data acquisition bottleneck associated with supervised role labelers. We present an algorithm that iteratively splits and merges clusters representing semantic roles, thereby leading from an initial clustering to a final clustering of better quality. The method is simple, surprisingly effective, and allows to integrate linguistic knowledge transparently. By combining role induction with a rule-based component for argument identification we obtain an unsupervised end-to-end semantic role labeling system. Evaluation on the CoNLL 2008 benchmark dataset demonstrates that our method outperforms competitive unsupervised approaches by a wide margin.</p><p>6 0.57624173 <a title="307-lda-6" href="./acl-2011-Improving_Arabic_Dependency_Parsing_with_Form-based_and_Functional_Morphological_Features.html">164 acl-2011-Improving Arabic Dependency Parsing with Form-based and Functional Morphological Features</a></p>
<p>7 0.57407975 <a title="307-lda-7" href="./acl-2011-Scaling_up_Automatic_Cross-Lingual_Semantic_Role_Annotation.html">269 acl-2011-Scaling up Automatic Cross-Lingual Semantic Role Annotation</a></p>
<p>8 0.57263499 <a title="307-lda-8" href="./acl-2011-Beam-Width_Prediction_for_Efficient_Context-Free_Parsing.html">58 acl-2011-Beam-Width Prediction for Efficient Context-Free Parsing</a></p>
<p>9 0.57206869 <a title="307-lda-9" href="./acl-2011-In-domain_Relation_Discovery_with_Meta-constraints_via_Posterior_Regularization.html">170 acl-2011-In-domain Relation Discovery with Meta-constraints via Posterior Regularization</a></p>
<p>10 0.57142073 <a title="307-lda-10" href="./acl-2011-Using_Bilingual_Parallel_Corpora_for_Cross-Lingual_Textual_Entailment.html">327 acl-2011-Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment</a></p>
<p>11 0.57125098 <a title="307-lda-11" href="./acl-2011-Translationese_and_Its_Dialects.html">311 acl-2011-Translationese and Its Dialects</a></p>
<p>12 0.57115638 <a title="307-lda-12" href="./acl-2011-A_Comparison_of_Loopy_Belief_Propagation_and_Dual_Decomposition_for_Integrated_CCG_Supertagging_and_Parsing.html">5 acl-2011-A Comparison of Loopy Belief Propagation and Dual Decomposition for Integrated CCG Supertagging and Parsing</a></p>
<p>13 0.57113922 <a title="307-lda-13" href="./acl-2011-Can_Document_Selection_Help_Semi-supervised_Learning%3F_A_Case_Study_On_Event_Extraction.html">65 acl-2011-Can Document Selection Help Semi-supervised Learning? A Case Study On Event Extraction</a></p>
<p>14 0.57102883 <a title="307-lda-14" href="./acl-2011-Exploring_Entity_Relations_for_Named_Entity_Disambiguation.html">128 acl-2011-Exploring Entity Relations for Named Entity Disambiguation</a></p>
<p>15 0.57017195 <a title="307-lda-15" href="./acl-2011-A_Bayesian_Model_for_Unsupervised_Semantic_Parsing.html">3 acl-2011-A Bayesian Model for Unsupervised Semantic Parsing</a></p>
<p>16 0.56948864 <a title="307-lda-16" href="./acl-2011-Piggyback%3A_Using_Search_Engines_for_Robust_Cross-Domain_Named_Entity_Recognition.html">246 acl-2011-Piggyback: Using Search Engines for Robust Cross-Domain Named Entity Recognition</a></p>
<p>17 0.56833327 <a title="307-lda-17" href="./acl-2011-Learning_Hierarchical_Translation_Structure_with_Linguistic_Annotations.html">202 acl-2011-Learning Hierarchical Translation Structure with Linguistic Annotations</a></p>
<p>18 0.56826419 <a title="307-lda-18" href="./acl-2011-Lexically-Triggered_Hidden_Markov_Models_for_Clinical_Document_Coding.html">209 acl-2011-Lexically-Triggered Hidden Markov Models for Clinical Document Coding</a></p>
<p>19 0.56809676 <a title="307-lda-19" href="./acl-2011-Extracting_Social_Power_Relationships_from_Natural_Language.html">133 acl-2011-Extracting Social Power Relationships from Natural Language</a></p>
<p>20 0.56808281 <a title="307-lda-20" href="./acl-2011-Subjectivity_and_Sentiment_Analysis_of_Modern_Standard_Arabic.html">289 acl-2011-Subjectivity and Sentiment Analysis of Modern Standard Arabic</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
