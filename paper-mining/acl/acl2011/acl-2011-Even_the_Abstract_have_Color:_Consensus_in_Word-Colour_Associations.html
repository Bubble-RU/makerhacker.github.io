<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>120 acl-2011-Even the Abstract have Color: Consensus in Word-Colour Associations</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-120" href="#">acl2011-120</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>120 acl-2011-Even the Abstract have Color: Consensus in Word-Colour Associations</h1>
<br/><p>Source: <a title="acl-2011-120-pdf" href="http://aclweb.org/anthology//P/P11/P11-2064.pdf">pdf</a></p><p>Author: Saif Mohammad</p><p>Abstract: Colour is a key component in the successful dissemination of information. Since many real-world concepts are associated with colour, for example danger with red, linguistic information is often complemented with the use of appropriate colours in information visualization and product marketing. Yet, there is no comprehensive resource that captures concept–colour associations. We present a method to create a large word–colour association lexicon by crowdsourcing. A wordchoice question was used to obtain sense-level annotations and to ensure data quality. We focus especially on abstract concepts and emotions to show that even they tend to have strong colour associations. Thus, using the right colours can not only improve semantic coherence, but also inspire the desired emotional response.</p><p>Reference: <a title="acl-2011-120-reference" href="../acl2011_reference/acl-2011-Even_the_Abstract_have_Color%3A_Consensus_in_Word-Colour_Associations_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Since many real-world concepts are associated with colour, for example danger with red, linguistic information is often complemented with the use of appropriate colours in information visualization and product marketing. [sent-7, score-0.37]
</p><p>2 We present a method to create a large word–colour association lexicon by crowdsourcing. [sent-9, score-0.068]
</p><p>3 We focus especially on abstract concepts and emotions to show that even they tend to have strong colour associations. [sent-11, score-1.066]
</p><p>4 Thus, using the right colours can not only improve semantic coherence, but also inspire the desired emotional response. [sent-12, score-0.291]
</p><p>5 Consider, for example, the use of red in stop signs. [sent-17, score-0.077]
</p><p>6 Drivers are able to recognize the sign faster, and it evokes a subliminal emotion pertaining to possible danger, which is entirely appropriate in the context. [sent-18, score-0.077]
</p><p>7 The use of red to show areas of high crime rate in a visualization is another example of good use of colour to draw emo-  tional response. [sent-19, score-1.008]
</p><p>8 On the other hand, improper use of colour can be more detrimental to understanding than using no colour (Marcus, 1982; Meier, 1988). [sent-20, score-1.786]
</p><p>9 A word has strong association with a colour when the colour is a salient feature of the concept the word refers to, or because the word is related to a such a concept. [sent-21, score-1.86]
</p><p>10 Many concept–colour associations, such as swan with white and vegetables with green, involve physical entities. [sent-22, score-0.107]
</p><p>11 However, even abstract notions and emotions may have colour associations (honesty–white, danger–red, joy–yellow, anger–red). [sent-23, score-1.097]
</p><p>12 Further, many associations are culturespecific (Gage, 1969; Chen, 2005). [sent-24, score-0.1]
</p><p>13 For example, prosperity is associated with red in much of Asia. [sent-25, score-0.139]
</p><p>14 In this paper, we describe how we created a large word–colour lexicon by crowdsourcing with effective quality control measures (Section 3), as well as  experiments and analyses to show that: • More than 30% of the terms have a strong cMolooruer tahsasnoc 3ia0ti%on o (Sections 4). [sent-27, score-0.135]
</p><p>15 i ac t2io0n11 fo Ar Cssoocmiaptuiotanti foonra Clo Lminpguutiast i ocns:aslh Loirntpgaupisetrics , pages 368–373, •  •  •  About 33% of thesaurus categories have strong cAobloouurt 3as3s%oc oifat itohnessa (Section 5). [sent-30, score-0.123]
</p><p>16 Abstract terms have colour associations almost as osftrteanct as physical e cnotliotiuers adsos (Section 6). [sent-31, score-1.057]
</p><p>17 There is a strong association between different eTmheorteio inss a aa sntrdo cnoglo ausrsso (Section 7). [sent-32, score-0.057]
</p><p>18 Thus, using the right colours can not only improve semantic coherence, but also inspire the desired emotional response. [sent-33, score-0.291]
</p><p>19 Experiments with colour categories have been used both to show that language has an effect on thought (Brown and Lenneberg, 1954; Ratner, 1989) and that it does not  (Bornstein, 1985). [sent-35, score-0.948]
</p><p>20 (201 1), and others show that people of different ages and genders have different colour preferences. [sent-41, score-0.907]
</p><p>21 ) In this work, we are interested in identifying words that have a strong association with a colour due to their meaning; associations that are not affected by age and gender preferences. [sent-43, score-1.068]
</p><p>22 There is substantial work on inferring the emotions evoked by colour (Luscher, 1969; Kaya, 2004). [sent-44, score-1.025]
</p><p>23 Strapparava and Ozbal (2010) compute corpusbased semantic similarity between emotions and colours. [sent-45, score-0.121]
</p><p>24 We combine a word–colour and a word– emotion lexicon to determine the association between emotion words and colours. [sent-46, score-0.239]
</p><p>25 Berlin and Kay (1969), and later Kay and Maffi (1999), showed that often colour terms appeared in languages in certain groups. [sent-47, score-0.929]
</p><p>26 If a language has only two colour terms, then they are white and black. [sent-48, score-0.972]
</p><p>27 If a language has three colour terms, then they tend to be  white, black, and red. [sent-49, score-0.893]
</p><p>28 Such groupings are seen for up to eleven colours, and based on these groupings, colours can be ranked as follows: 1http://www. [sent-50, score-0.216]
</p><p>29 3 To make our task feasible, we chose to use the eleven basic colour words of Berlin and Kay (1969). [sent-67, score-0.909]
</p><p>30 The MRC Psycholinguistic Database (Coltheart, 1981) has, among other information, the imageability ratings for 9240 words. [sent-68, score-0.136]
</p><p>31 4 The imageability rating is a score given by human judges that reflects how easy it is to visualize the concept. [sent-69, score-0.141]
</p><p>32 We use the ratings in our experiments to determine whether there is a correlation between imageability and strength of colour association. [sent-71, score-1.094]
</p><p>33 3  Crowdsourcing  We used the Macquarie Thesaurus (Bernard, 1986) as the source for terms to be annotated by people on Mechanical Turk. [sent-72, score-0.05]
</p><p>34 These categories can be thought of as coarse senses (Yarowsky, 1992; Mohammad and Hirst, 2006). [sent-74, score-0.072]
</p><p>35 Since we were additionally interested in determining colour signatures for emotions (Section 7), we chose to annotate all of the 10,170 word– sense pairs that Mohammad and Turney (2010) used to create their word–emotion lexicon. [sent-76, score-0.997]
</p><p>36 • black • green • purple • white •• bblluaeck •• grey •• pink •• yellow •• bblrouewn •• orange •• rpeidn Q1 is a word choice question generated automatically by taking a near-synonym from the thesaurus and random distractors. [sent-81, score-0.37]
</p><p>37 The near-synonym also guides the annotator to the desired sense ofthe word. [sent-83, score-0.056]
</p><p>38 3  Table 1: Percentage of terms marked as being associated with each colour. [sent-115, score-0.098]
</p><p>39 The colour options in Q2 were presented in random order. [sent-117, score-0.893]
</p><p>40 We do not provide a “not associated with any colour” option to encourage colour selection even if the association is weak. [sent-118, score-0.98]
</p><p>41 We requested annotations from five different people for each term. [sent-120, score-0.054]
</p><p>42 Since, for these instances, the annotator did not know the meaning of the target word, we discarded the corresponding colour association response. [sent-124, score-0.959]
</p><p>43 The information from multiple annotators was combined by taking the majority vote, resulting in a lexicon with 8,813 entries. [sent-128, score-0.096]
</p><p>44 Each entry contains a unique word–synonym pair, majority voted colour(s), and a confidence score—number of votes for the colour / number of total votes. [sent-129, score-0.942]
</p><p>45 (For the analyses in Sections 5, 6, and 7, ties were broken by picking one colour at random. [sent-130, score-0.893]
</p><p>46 ) A separate version of the lexicon that includes entries for all of the valid annotations by each of the annotators is also available. [sent-131, score-0.089]
</p><p>47 6 The first row in Table 1 shows the percentage of times different colours were associated with the target term. [sent-132, score-0.262]
</p><p>48 Even though the colour options were presented in random order, the order of the most frequently associated colours is identical to the Berlin and Kay order (Section 2:(1)). [sent-134, score-1.138]
</p><p>49 e0 Table 3: Percentage of terms in different majority classes. [sent-145, score-0.066]
</p><p>50 ××  were associated with at least two different colours. [sent-146, score-0.062]
</p><p>51 Table 4 shows how often the majority class in colour associations is 1, 2, 3, 4, and 5, respectively. [sent-148, score-1.023]
</p><p>52 A large number of terms have a majority class size ≥ 2 (84. [sent-155, score-0.066]
</p><p>53 u sO hnaev can argue that terms with a majority class size ≥ 3 (32%) ghaueve t strong mcsol wouitrh ha sas mocaijaotiroitnys. [sent-158, score-0.098]
</p><p>54 nL aow “ agreement for certain instances is an indicator that these words have weak, if any, colour association. [sent-160, score-0.911]
</p><p>55 Words are associated with colours to different degrees. [sent-165, score-0.245]
</p><p>56 eS aosmsoe wiaotredds may c boel ausrssotc oia tdeidff ewreitnht more than one colour by comparable degrees, and there might be higher disagreement. [sent-166, score-0.893]
</p><p>57 5  Category–Colour Association  Different words within a thesaurus category may not be strongly associated with any colour, or they may be associated with many different colours. [sent-170, score-0.232]
</p><p>58 We now determine whether there exist categories where the semantic coherence carries over to a strong common association with one colour. [sent-171, score-0.142]
</p><p>59 Only cate371 gories that had at least four words that also appear in the word–colour lexicon were considered; 535 of the 812 categories from Macquarie Thesaurus met this condition. [sent-173, score-0.08]
</p><p>60 If a category has exactly four words that appear in the colour lexicon, and if all four words are associated with different colours, then the category has the lowest possible strength of colour  association—0. [sent-174, score-1.956]
</p><p>61 5 or above, that is, half or more of the words in these categories are associated with one colour. [sent-186, score-0.099]
</p><p>62 6  Imageability  It is natural for physical entities of a certain colour to be associated with that colour. [sent-188, score-0.983]
</p><p>63 However, abstract concepts such as danger and excitability are also associated with colours—red and orange, respectively. [sent-189, score-0.149]
</p><p>64 Figure 1 displays an experiment to determine whether there is a correlation between imageability and association with colour. [sent-190, score-0.174]
</p><p>65 We define imageability of a thesaurus category to be the average of the imageability ratings of words in it. [sent-191, score-0.344]
</p><p>66 We calculated imageability for the 535 categories described in the previous section using only the words that appear in the colour lexicon. [sent-192, score-1.046]
</p><p>67 Figure 1 shows the scatter plot of these categories on the im-  ageability and strength of colour association  axes. [sent-193, score-1.01]
</p><p>68 8 Table 4: Colour signature of emotive terms: percentage of terms associated with each colour. [sent-282, score-0.146]
</p><p>69 The two most associated colours are shown in bold. [sent-285, score-0.245]
</p><p>70 7 Table 5: Colour signature of positive and negative terms: percentage terms associated with each colour. [sent-308, score-0.146]
</p><p>71 The two most associated colours are shown in bold. [sent-311, score-0.245]
</p><p>72 higher imageability correlated with greater tendency to have a colour association, then we would see most of the points along the diagonal moving up from left to right. [sent-312, score-1.009]
</p><p>73 Instead, we observe that the strongly associated categories are spread all across the imageability axis, implying that there is only weak, if any, correlation. [sent-313, score-0.231]
</p><p>74 Imageability and colour association have a Pearson’s product moment correlation of 0. [sent-314, score-0.934]
</p><p>75 7 The Colour of Emotion Words Emotions such  joy, sadness, and anger are abstract concepts dealing with one’s psychological state. [sent-317, score-0.09]
</p><p>76 As pointed out in Section 2, there is prior work on emotions evoked by colours. [sent-318, score-0.132]
</p><p>77 In contrast, here as  we investigate the colours associated with emotion words. [sent-319, score-0.322]
</p><p>78 We combine the word–emotion association lexicon compiled by Mohammad and Turney (2010; 2011) and our word–colour lexicon to determine the colour signature of emotions—the rows in Table 4. [sent-320, score-1.052]
</p><p>79 Notably, we see that all of the emotions have strong associations with certain colours. [sent-321, score-0.236]
</p><p>80 Among the positive emotions: anticipation is most frequently associated with white and green; joy with white, green, and yellow; and trust with white, blue, and green. [sent-324, score-0.213]
</p><p>81 Table 4 shows the colour signature for terms marked positive and negative (these include terms that may not be associated with the eight basic emotions). [sent-325, score-1.058]
</p><p>82 Observe that the neg372 ative terms are strongly associated with black and red, whereas the positive terms are strongly associated with white and green. [sent-326, score-0.335]
</p><p>83 Thus, colour can add to the potency of emotional concepts, yielding even more effective visualizations. [sent-327, score-0.929]
</p><p>84 8  Conclusions and Future Work  We created a large word–colour association lexicon by crowdsourcing. [sent-328, score-0.068]
</p><p>85 A word-choice question was used to guide the annotator to the desired sense of the target word, and to ensure data quality. [sent-329, score-0.056]
</p><p>86 We observed that abstract concepts, emotions in particular, have strong colour associations. [sent-330, score-1.029]
</p><p>87 Thus, using the right colours in tasks such as information visualization, product marketing, and web development, can not only improve semantic coherence, but also inspire the desired psychological response. [sent-331, score-0.255]
</p><p>88 Interestingly, we found that frequencies of colour choice in associations follow the same order in which colour terms occur in language (Berlin and Kay, 1969). [sent-332, score-1.922]
</p><p>89 Future work includes developing automatic corpusbased methods to determine the strength of word– colour association, and the extent to which strong word–colour associations manifest themselves as more-than-random chance co-occurrence in text. [sent-333, score-1.106]
</p><p>90 Thanks to the more than 2000 people  who answered the colour survey with diligence and care. [sent-336, score-0.907]
</p><p>91 On the development of color naming in young children: Data and theory. [sent-351, score-0.126]
</p><p>92 Comparative studies on cultural meaning difference of colors between china and western societies. [sent-368, score-0.05]
</p><p>93 Review and analysis of color coding research for visual displays. [sent-380, score-0.126]
</p><p>94 Color appearance and the emergence and evolution of basic color lexicons. [sent-392, score-0.126]
</p><p>95 Relationship between color and emotion: a study ofcollege students. [sent-396, score-0.126]
</p><p>96 Ace: a color expert system for user interface design. [sent-409, score-0.126]
</p><p>97 Emotions evoked by common words and phrases: Using mechanical turk to create an emotion lexicon. [sent-418, score-0.141]
</p><p>98 The use of color in computer interfaces: Preliminary research. [sent-435, score-0.126]
</p><p>99 A sociohistorical critique of naturalistic theories of color perception. [sent-438, score-0.126]
</p><p>100 Color: Cross cultural marketing perspectves as to what governs our response to it. [sent-442, score-0.045]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('colour', 0.893), ('colours', 0.183), ('color', 0.126), ('imageability', 0.116), ('emotions', 0.104), ('associations', 0.1), ('white', 0.079), ('emotion', 0.077), ('red', 0.077), ('mohammad', 0.069), ('associated', 0.062), ('yellow', 0.057), ('thesaurus', 0.054), ('anger', 0.053), ('macquarie', 0.053), ('danger', 0.05), ('kay', 0.049), ('saif', 0.046), ('lexicon', 0.043), ('green', 0.041), ('inspire', 0.039), ('pink', 0.039), ('whiteblackredgreenyellowbluebrownpinkpurpleorangegrey', 0.039), ('category', 0.038), ('visualization', 0.038), ('concepts', 0.037), ('categories', 0.037), ('terms', 0.036), ('emotional', 0.036), ('joy', 0.033), ('desired', 0.033), ('strength', 0.032), ('berlin', 0.032), ('strong', 0.032), ('signature', 0.031), ('coherence', 0.031), ('majority', 0.03), ('sadness', 0.03), ('marketing', 0.03), ('black', 0.028), ('evoked', 0.028), ('physical', 0.028), ('compatriot', 0.026), ('glimmer', 0.026), ('luscher', 0.026), ('meier', 0.026), ('mrc', 0.026), ('pribadi', 0.026), ('purple', 0.026), ('orange', 0.026), ('visualize', 0.025), ('association', 0.025), ('crowdsourcing', 0.024), ('annotators', 0.023), ('anticipation', 0.023), ('disgust', 0.023), ('scatter', 0.023), ('stimulate', 0.023), ('annotations', 0.023), ('annotator', 0.023), ('sleep', 0.021), ('roget', 0.021), ('ozbal', 0.021), ('frustrated', 0.021), ('sable', 0.021), ('turney', 0.02), ('grey', 0.02), ('bernard', 0.02), ('ratings', 0.02), ('voted', 0.019), ('fear', 0.019), ('turk', 0.019), ('meaning', 0.018), ('thought', 0.018), ('age', 0.018), ('card', 0.018), ('agreement', 0.018), ('psycholinguistic', 0.017), ('mechanical', 0.017), ('senses', 0.017), ('determine', 0.017), ('colors', 0.017), ('corpusbased', 0.017), ('requested', 0.017), ('groupings', 0.017), ('strapparava', 0.017), ('concept', 0.017), ('percentage', 0.017), ('child', 0.016), ('eleven', 0.016), ('trust', 0.016), ('strongly', 0.016), ('correlation', 0.016), ('cultural', 0.015), ('ou', 0.015), ('chance', 0.015), ('brown', 0.014), ('vote', 0.014), ('council', 0.014), ('people', 0.014)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="120-tfidf-1" href="./acl-2011-Even_the_Abstract_have_Color%3A_Consensus_in_Word-Colour_Associations.html">120 acl-2011-Even the Abstract have Color: Consensus in Word-Colour Associations</a></p>
<p>Author: Saif Mohammad</p><p>Abstract: Colour is a key component in the successful dissemination of information. Since many real-world concepts are associated with colour, for example danger with red, linguistic information is often complemented with the use of appropriate colours in information visualization and product marketing. Yet, there is no comprehensive resource that captures concept–colour associations. We present a method to create a large word–colour association lexicon by crowdsourcing. A wordchoice question was used to obtain sense-level annotations and to ensure data quality. We focus especially on abstract concepts and emotions to show that even they tend to have strong colour associations. Thus, using the right colours can not only improve semantic coherence, but also inspire the desired emotional response.</p><p>2 0.040636338 <a title="120-tfidf-2" href="./acl-2011-Goodness%3A_A_Method_for_Measuring_Machine_Translation_Confidence.html">146 acl-2011-Goodness: A Method for Measuring Machine Translation Confidence</a></p>
<p>Author: Nguyen Bach ; Fei Huang ; Yaser Al-Onaizan</p><p>Abstract: State-of-the-art statistical machine translation (MT) systems have made significant progress towards producing user-acceptable translation output. However, there is still no efficient way for MT systems to inform users which words are likely translated correctly and how confident it is about the whole sentence. We propose a novel framework to predict wordlevel and sentence-level MT errors with a large number of novel features. Experimental results show that the MT error prediction accuracy is increased from 69.1 to 72.2 in F-score. The Pearson correlation between the proposed confidence measure and the human-targeted translation edit rate (HTER) is 0.6. Improve- ments between 0.4 and 0.9 TER reduction are obtained with the n-best list reranking task using the proposed confidence measure. Also, we present a visualization prototype of MT errors at the word and sentence levels with the objective to improve post-editor productivity.</p><p>3 0.033834718 <a title="120-tfidf-3" href="./acl-2011-Towards_Tracking_Semantic_Change_by_Visual_Analytics.html">307 acl-2011-Towards Tracking Semantic Change by Visual Analytics</a></p>
<p>Author: Christian Rohrdantz ; Annette Hautli ; Thomas Mayer ; Miriam Butt ; Daniel A. Keim ; Frans Plank</p><p>Abstract: This paper presents a new approach to detecting and tracking changes in word meaning by visually modeling and representing diachronic development in word contexts. Previous studies have shown that computational models are capable of clustering and disambiguating senses, a more recent trend investigates whether changes in word meaning can be tracked by automatic methods. The aim of our study is to offer a new instrument for investigating the diachronic development of word senses in a way that allows for a better understanding of the nature of semantic change in general. For this purpose we combine techniques from the field of Visual Analytics with unsupervised methods from Natural Language Processing, allowing for an interactive visual exploration of semantic change.</p><p>4 0.031396747 <a title="120-tfidf-4" href="./acl-2011-Types_of_Common-Sense_Knowledge_Needed_for_Recognizing_Textual_Entailment.html">315 acl-2011-Types of Common-Sense Knowledge Needed for Recognizing Textual Entailment</a></p>
<p>Author: Peter LoBue ; Alexander Yates</p><p>Abstract: Understanding language requires both linguistic knowledge and knowledge about how the world works, also known as common-sense knowledge. We attempt to characterize the kinds of common-sense knowledge most often involved in recognizing textual entailments. We identify 20 categories of common-sense knowledge that are prevalent in textual entailment, many of which have received scarce attention from researchers building collections of knowledge.</p><p>5 0.030563373 <a title="120-tfidf-5" href="./acl-2011-Predicting_Clicks_in_a_Vocabulary_Learning_System.html">248 acl-2011-Predicting Clicks in a Vocabulary Learning System</a></p>
<p>Author: Aaron Michelony</p><p>Abstract: We consider the problem of predicting which words a student will click in a vocabulary learning system. Often a language learner will find value in the ability to look up the meaning of an unknown word while reading an electronic document by clicking the word. Highlighting words likely to be unknown to a readeris attractive due to drawing his orher attention to it and indicating that information is available. However, this option is usually done manually in vocabulary systems and online encyclopedias such as Wikipedia. Furthurmore, it is never on a per-user basis. This paper presents an automated way of highlighting words likely to be unknown to the specific user. We present related work in search engine ranking, a description of the study used to collect click data, the experiment we performed using the random forest machine learning algorithm and finish with a discussion of future work.</p><p>6 0.026860338 <a title="120-tfidf-6" href="./acl-2011-PsychoSentiWordNet.html">253 acl-2011-PsychoSentiWordNet</a></p>
<p>7 0.026437495 <a title="120-tfidf-7" href="./acl-2011-Subjective_Natural_Language_Problems%3A_Motivations%2C_Applications%2C_Characterizations%2C_and_Implications.html">288 acl-2011-Subjective Natural Language Problems: Motivations, Applications, Characterizations, and Implications</a></p>
<p>8 0.025329173 <a title="120-tfidf-8" href="./acl-2011-Which_Noun_Phrases_Denote_Which_Concepts%3F.html">334 acl-2011-Which Noun Phrases Denote Which Concepts?</a></p>
<p>9 0.024829842 <a title="120-tfidf-9" href="./acl-2011-MemeTube%3A_A_Sentiment-based_Audiovisual_System_for_Analyzing_and_Displaying_Microblog_Messages.html">218 acl-2011-MemeTube: A Sentiment-based Audiovisual System for Analyzing and Displaying Microblog Messages</a></p>
<p>10 0.024472736 <a title="120-tfidf-10" href="./acl-2011-Using_Multiple_Sources_to_Construct_a_Sentiment_Sensitive_Thesaurus_for_Cross-Domain_Sentiment_Classification.html">332 acl-2011-Using Multiple Sources to Construct a Sentiment Sensitive Thesaurus for Cross-Domain Sentiment Classification</a></p>
<p>11 0.023239426 <a title="120-tfidf-11" href="./acl-2011-Relation_Guided_Bootstrapping_of_Semantic_Lexicons.html">262 acl-2011-Relation Guided Bootstrapping of Semantic Lexicons</a></p>
<p>12 0.023057122 <a title="120-tfidf-12" href="./acl-2011-Rare_Word_Translation_Extraction_from_Aligned_Comparable_Documents.html">259 acl-2011-Rare Word Translation Extraction from Aligned Comparable Documents</a></p>
<p>13 0.022502409 <a title="120-tfidf-13" href="./acl-2011-Automatic_Labelling_of_Topic_Models.html">52 acl-2011-Automatic Labelling of Topic Models</a></p>
<p>14 0.022229899 <a title="120-tfidf-14" href="./acl-2011-Jigs_and_Lures%3A_Associating_Web_Queries_with_Structured_Entities.html">181 acl-2011-Jigs and Lures: Associating Web Queries with Structured Entities</a></p>
<p>15 0.020815728 <a title="120-tfidf-15" href="./acl-2011-They_Can_Help%3A_Using_Crowdsourcing_to_Improve_the_Evaluation_of_Grammatical_Error_Detection_Systems.html">302 acl-2011-They Can Help: Using Crowdsourcing to Improve the Evaluation of Grammatical Error Detection Systems</a></p>
<p>16 0.02049806 <a title="120-tfidf-16" href="./acl-2011-An_Affect-Enriched_Dialogue_Act_Classification_Model_for_Task-Oriented_Dialogue.html">33 acl-2011-An Affect-Enriched Dialogue Act Classification Model for Task-Oriented Dialogue</a></p>
<p>17 0.020387761 <a title="120-tfidf-17" href="./acl-2011-Latent_Semantic_Word_Sense_Induction_and_Disambiguation.html">198 acl-2011-Latent Semantic Word Sense Induction and Disambiguation</a></p>
<p>18 0.020143842 <a title="120-tfidf-18" href="./acl-2011-Automatic_Assessment_of_Coverage_Quality_in_Intelligence_Reports.html">47 acl-2011-Automatic Assessment of Coverage Quality in Intelligence Reports</a></p>
<p>19 0.019773018 <a title="120-tfidf-19" href="./acl-2011-Insights_from_Network_Structure_for_Text_Mining.html">174 acl-2011-Insights from Network Structure for Text Mining</a></p>
<p>20 0.019635569 <a title="120-tfidf-20" href="./acl-2011-Identification_of_Domain-Specific_Senses_in_a_Machine-Readable_Dictionary.html">158 acl-2011-Identification of Domain-Specific Senses in a Machine-Readable Dictionary</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.056), (1, 0.025), (2, -0.005), (3, 0.008), (4, -0.014), (5, 0.011), (6, 0.016), (7, -0.007), (8, -0.003), (9, -0.025), (10, -0.015), (11, -0.027), (12, 0.011), (13, 0.002), (14, -0.029), (15, -0.018), (16, -0.007), (17, 0.014), (18, -0.016), (19, -0.006), (20, 0.054), (21, 0.035), (22, -0.03), (23, -0.009), (24, -0.038), (25, -0.015), (26, 0.012), (27, 0.018), (28, -0.022), (29, -0.005), (30, -0.035), (31, -0.026), (32, -0.017), (33, 0.023), (34, -0.019), (35, 0.021), (36, -0.003), (37, -0.011), (38, 0.023), (39, 0.014), (40, 0.017), (41, -0.008), (42, -0.028), (43, -0.043), (44, 0.008), (45, -0.047), (46, -0.027), (47, 0.028), (48, -0.017), (49, -0.033)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.86336708 <a title="120-lsi-1" href="./acl-2011-Even_the_Abstract_have_Color%3A_Consensus_in_Word-Colour_Associations.html">120 acl-2011-Even the Abstract have Color: Consensus in Word-Colour Associations</a></p>
<p>Author: Saif Mohammad</p><p>Abstract: Colour is a key component in the successful dissemination of information. Since many real-world concepts are associated with colour, for example danger with red, linguistic information is often complemented with the use of appropriate colours in information visualization and product marketing. Yet, there is no comprehensive resource that captures concept–colour associations. We present a method to create a large word–colour association lexicon by crowdsourcing. A wordchoice question was used to obtain sense-level annotations and to ensure data quality. We focus especially on abstract concepts and emotions to show that even they tend to have strong colour associations. Thus, using the right colours can not only improve semantic coherence, but also inspire the desired emotional response.</p><p>2 0.63812608 <a title="120-lsi-2" href="./acl-2011-Discrete_vs._Continuous_Rating_Scales_for_Language_Evaluation_in_NLP.html">99 acl-2011-Discrete vs. Continuous Rating Scales for Language Evaluation in NLP</a></p>
<p>Author: Anja Belz ; Eric Kow</p><p>Abstract: Studies assessing rating scales are very common in psychology and related fields, but are rare in NLP. In this paper we assess discrete and continuous scales used for measuring quality assessments of computergenerated language. We conducted six separate experiments designed to investigate the validity, reliability, stability, interchangeability and sensitivity of discrete vs. continuous scales. We show that continuous scales are viable for use in language evaluation, and offer distinct advantages over discrete scales. 1 Background and Introduction Rating scales have been used for measuring human perception of various stimuli for a long time, at least since the early 20th century (Freyd, 1923). First used in psychology and psychophysics, they are now also common in a variety of other disciplines, including NLP. Discrete scales are the only type of scale commonly used for qualitative assessments of computer-generated language in NLP (e.g. in the DUC/TAC evaluation competitions). Continuous scales are commonly used in psychology and related fields, but are virtually unknown in NLP. While studies assessing the quality of individual scales and comparing different types of rating scales are common in psychology and related fields, such studies hardly exist in NLP, and so at present little is known about whether discrete scales are a suitable rating tool for NLP evaluation tasks, or whether continuous scales might provide a better alternative. A range of studies from sociology, psychophysiology, biometrics and other fields have compared 230 Kow} @bright on .ac .uk discrete and continuous scales. Results tend to differ for different types of data. E.g., results from pain measurement show a continuous scale to outperform a discrete scale (ten Klooster et al., 2006). Other results (Svensson, 2000) from measuring students’ ease of following lectures show a discrete scale to outperform a continuous scale. When measuring dyspnea, Lansing et al. (2003) found a hybrid scale to perform on a par with a discrete scale. Another consideration is the types of data produced by discrete and continuous scales. Parametric methods of statistical analysis, which are far more sensitive than non-parametric ones, are commonly applied to both discrete and continuous data. However, parametric methods make very strong assumptions about data, including that it is numerical and normally distributed (Siegel, 1957). If these assumptions are violated, then the significance of results is overestimated. Clearly, the numerical assumption does not hold for the categorial data produced by discrete scales, and it is unlikely to be normally distributed. Many researchers are happier to apply parametric methods to data from continuous scales, and some simply take it as read that such data is normally distributed (Lansing et al., 2003). Our aim in the present study was to systematically assess and compare discrete and continuous scales when used for the qualitative assessment of computer-generated language. We start with an overview of assessment scale types (Section 2). We describe the experiments we conducted (Sec- tion 4), the data we used in them (Section 3), and the properties we examined in our inter-scale comparisons (Section 5), before presenting our results Proceedings ofP thoer t4l9atnhd A, Onrnuegaoln M,e Jeuntineg 19 o-f2 t4h,e 2 A0s1s1o.c?i ac t2io0n11 fo Ar Cssoocmiaptuiotanti foonra Clo Lminpguutiastti ocns:aslh Loirntpgaupisetricss, pages 230–235, Q1: Grammaticality The summary should have no datelines, system-internal formatting, capitalization errors or obviously ungrammatical sentences (e.g., fragments, missing components) that make the text difficult to read. 1. Very Poor 2. Poor 3. Barely Acceptable 4. Good 5. Very Good Figure 1: Evaluation of Readability in DUC’06, comprising 5 evaluation criteria, including Grammaticality. Evaluation task for each summary text: evaluator selects one of the options (1–5) to represent quality of the summary in terms of the criterion. (Section 6), and some conclusions (Section 7). 2 Rating Scales With Verbal Descriptor Scales (VDSs), participants give responses on ordered lists of verbally described and/or numerically labelled response cate- gories, typically varying in number from 2 to 11 (Svensson, 2000). An example of a VDS used in NLP is shown in Figure 1. VDSs are used very widely in contexts where computationally generated language is evaluated, including in dialogue, summarisation, MT and data-to-text generation. Visual analogue scales (VASs) are far less common outside psychology and related areas than VDSs. Responses are given by selecting a point on a typically horizontal line (although vertical lines have also been used (Scott and Huskisson, 2003)), on which the two end points represent the extreme values of the variable to be measured. Such lines can be mono-polar or bi-polar, and the end points are labelled with an image (smiling/frowning face), or a brief verbal descriptor, to indicate which end of the line corresponds to which extreme of the variable. The labels are commonly chosen to represent a point beyond any response actually likely to be chosen by raters. There is only one examples of a VAS in NLP system evaluation that we are aware of (Gatt et al., 2009). Hybrid scales, known as a graphic rating scales, combine the features of VDSs and VASs, and are also used in psychology. Here, the verbal descriptors are aligned along the line of a VAS and the endpoints are typically unmarked (Svensson, 2000). We are aware of one example in NLP (Williams and Reiter, 2008); 231 Q1: Grammaticality The summary should have no datelines, system-internal formatting, capitalization errors or obviously ungrammatical sentences (e.g., fragments, missing components) that make the text difficult to read. extbreamdely excellent Figure 2: Evaluation of Grammaticality with alternative VAS scale (cf. Figure 1). Evaluation task for each summary text: evaluator selects a place on the line to represent quality of the summary in terms of the criterion. we did not investigate this scale in our study. We used the following two specific scale designs in our experiments: VDS-7: 7 response categories, numbered (7 = best) and verbally described (e.g. 7 = “perfectly fluent” for Fluency, and 7 = “perfectly clear” for Clarity). Response categories were presented in a vertical list, with the best category at the bottom. Each category had a tick-box placed next to it; the rater’s task was to tick the box by their chosen rating. VAS: a horizontal, bi-polar line, with no ticks on it, mapping to 0–100. In the image description tests, statements identified the left end as negative, the right end as positive; in the weather forecast tests, the positive end had a smiling face and the label “statement couldn’t be clearer/read better”; the negative end had a frowning face and the label “statement couldn’t be more unclear/read worse”. The raters’ task was to move a pointer (initially in the middle of the line) to the place corresponding to their rating. 3 Data Weather forecast texts: In one half of our evaluation experiments we used human-written and automatically generated weather forecasts for the same weather data. The data in our evaluations was for 22 different forecast dates and included outputs from 10 generator systems and one set of human forecasts. This data has also been used for comparative system evaluation in previous research (Langner, 2010; Angeli et al., 2010; Belz and Kow, 2009). The following are examples of weather forecast texts from the data: 1: S SE 2 8 -3 2 INCREAS ING 3 6-4 0 BY MID AF TERNOON 2 : S ’ LY 2 6-3 2 BACKING S SE 3 0 -3 5 BY AFTERNOON INCREAS ING 3 5 -4 0 GUSTS 5 0 BY MID EVENING Image descriptions: In the other half of our evaluations, we used human-written and automatically generated image descriptions for the same images. The data in our evaluations was for 112 different image sets and included outputs from 6 generator systems and 2 sets of human-authored descriptions. This data was originally created in the TUNA Project (van Deemter et al., 2006). The following is an example of an item from the corpus, consisting of a set of images and a description for the entity in the red frame: the smal l blue fan 4 Experimental Set-up 4.1 Evaluation criteria Fluency/Readability: Both the weather forecast and image description evaluation experiments used a quality criterion intended to capture ‘how well a piece of text reads’ , called Fluency in the latter, Readability in the former. Adequacy/Clarity: In the image description experiments, the second quality criterion was Adequacy, explained as “how clear the description is”, and “how easy it would be to identify the image from the description”. This criterion was called Clarity in the weather forecast experiments, explained as “how easy is it to understand what is being described”. 4.2 Raters In the image experiments we used 8 raters (native speakers) in each experiment, from cohorts of 3rdyear undergraduate and postgraduate students doing a degree in a linguistics-related subject. They were paid and spent about 1hour doing the experiment. In the weather forecast experiments, we used 22 raters in each experiment, from among academic staff at our own university. They were not paid and spent about 15 minutes doing the experiment. 232 4.3 Summary overview of experiments Weather VDS-7 (A): VDS-7 scale; weather forecast data; criteria: Readability and Clarity; 22 raters (university staff) each assessing 22 forecasts. Weather VDS-7 (B): exact repeat of Weather VDS-7 (A), including same raters. Weather VAS: VAS scale; 22 raters (university staff), no overlap with raters in Weather VDS-7 experiments; other details same as in Weather VDS-7. Image VDS-7: VDS-7 scale; image description data; 8 raters (linguistics students) each rating 112 descriptions; criteria: Fluency and Adequacy. Image VAS (A): VAS scale; 8 raters (linguistics students), no overlap with raters in Image VAS-7; other details same as in Image VDS-7 experiment. Image VAS (B): exact repeat of Image VAS (A), including same raters. 4.4 Design features common to all experiments In all our experiments we used a Repeated Latin Squares design to ensure that each rater sees the same number of outputs from each system and for each text type (forecast date/image set). Following detailed instructions, raters first did a small number of practice examples, followed by the texts to be rated, in an order randomised for each rater. Evaluations were carried out via a web interface. They were allowed to interrupt the experiment, and in the case of the 1hour long image description evaluation they were encouraged to take breaks. 5 Comparison and Assessment of Scales Validity is to the extent to which an assessment method measures what it is intended to measure (Svensson, 2000). Validity is often impossible to assess objectively, as is the case of all our criteria except Adequacy, the validity of which we can directly test by looking at correlations with the accuracy with which participants in a separate experiment identify the intended images given their descriptions. A standard method for assessing Reliability is Kendall’s W, a coefficient of concordance, measuring the degree to which different raters agree in their ratings. We report W for all 6 experiments. Stability refers to the extent to which the results of an experiment run on one occasion agree with the results of the same experiment (with the same raters) run on a different occasion. In the present study, we assess stability in an intra-rater, test-retest design, assessing the agreement between the same participant’s responses in the first and second runs of the test with Pearson’s product-moment correlation coefficient. We report these measures between ratings given in Image VAS (A) vs. those given in Image VAS (B), and between ratings given in Weather VDS-7 (A) vs. those given in Weather VDS-7 (B). We assess Interchangeability, that is, the extent to which our VDS and VAS scales agree, by computing Pearson’s and Spearman’s coefficients between results. We report these measures for all pairs of weather forecast/image description evaluations. We assess the Sensitivity of our scales by determining the number of significant differences between different systems and human authors detected by each scale. We also look at the relative effect of the different experimental factors by computing the F-Ratio for System (the main factor under investigation, so its relative effect should be high), Rater and Text Type (their effect should be low). F-ratios were de- termined by a one-way ANOVA with the evaluation criterion in question as the dependent variable and System, Rater or Text Type as grouping factors. 6 Results 6.1 Interchangeability and Reliability for system/human authored image descriptions Interchangeability: Pearson’s r between the means per system/human in the three image description evaluation experiments were as follows (Spearman’s ρ shown in brackets): Forb.eqAdFlouthV AD S d-(e7Aq)uac.y945a78n*d(V.F9A2l5uS8e*(—An *c)y,.98o36r.748*e1l9a*(tV.i98(Ao.2578nS019s(*5B b) e- tween Image VDS-7 and Image VAS (A) (the main VAS experiment) are extremely high, meaning that they could substitute for each other here. Reliability: Inter-rater agreement in terms of Kendall’s W in each of the experiments: 233 K ’ s W FAldue qnucayc .6V549D80S* -7* VA.46S7 16(*A * )VA.7S529 (5*B *) W was higher in the VAS data in the case of Fluency, whereas for Adequacy, W was the same for the VDS data and VAS (B), and higher in the VDS data than in the VAS (A) data. 6.2 Interchangeability and Reliability for system/human authored weather forecasts Interchangeability: The correlation coefficients (Pearson’s r with Spearman’s ρ in brackets) between the means per system/human in the image description experiments were as follows: ForRCea.ld bVoDt hS -A7 (d BAeq)ua.c9y851a*nVdD(.8F9S7-lu09*(eBn—*)cy,.9 o43r2957*1e la(*t.8i(o736n025Vs9*6A bS)e- tween Weather VDS-7 (A) (the main VDS-7 experiment) and Weather VAS (A) are again very high, although rank-correlation is somewhat lower. Reliability: Inter-rater agreement Kendall’s W was as follows: in terms of W RClea rdi.tyVDS.5-4739 7(*A * )VDS.4- 7583 (*B * ).4 8 V50*A *S This time the highest agreement for both Clarity and Readability was in the VDS-7 data. 6.3 Stability tests for image and weather data Pearson’s r between ratings given by the same raters first in Image VAS (A) and then in Image VAS (B) was .666 for Adequacy, .593 for Fluency. Between ratings given by the same raters first in Weather VDS-7 (A) and then in Weather VDS-7 (B), Pearson’s r was .656 for Clarity, .704 for Readability. (All significant at p < .01.) Note that these are computed on individual scores (rather than means as in the correlation figures given in previous sections). 6.4 F-ratios and post-hoc analysis for image data The table below shows F-ratios determined by a oneway ANOVA with the evaluation criterion in question (Adequacy/Fluency) as the dependent variable and System/Rater/Text Type as the grouping factor. Note that for System a high F-ratio is desirable, but a low F-ratio is desirable for other factors. tem, the main factor under investigation, VDS-7 found 8 for Adequacy and 14 for Fluency; VAS (A) found 7 for Adequacy and 15 for Fluency. 6.5 F-ratios and post-hoc analysis for weather data The table below shows F-ratios analogous to the previous section (for Clarity/Readability). tem, VDS-7 (A) found 24 for Clarity, 23 for Readability; VAS found 25 for Adequacy, 26 for Fluency. 6.6 Scale validity test for image data Our final table of results shows Pearson’s correlation coefficients (calculated on means per system) between the Adequacy data from the three image description evaluation experiments on the one hand, and the data from an extrinsic experiment in which we measured the accuracy with which participants identified the intended image described by a description: ThecorIlm at iog ne V bAeDSt w-(A7eB)An dA eqd uqe ac uy a cy.I89nD720d 6AI*Dc .Acuray was strong and highly significant in all three image description evaluation experiments, but strongest in VAS (B), and weakest in VAS (A). For comparison, 234 Pearson’s between Fluency and ID Accuracy ranged between .3 and .5, whereas Pearson’s between Adequacy and ID Speed (also measured in the same image identfication experiment) ranged between -.35 and -.29. 7 Discussion and Conclusions Our interchangeability results (Sections 6. 1and 6.2) indicate that the VAS and VDS-7 scales we have tested can substitute for each other in our present evaluation tasks in terms of the mean system scores they produce. Where we were able to measure validity (Section 6.6), both scales were shown to be similarly valid, predicting image identification accuracy figures from a separate experiment equally well. Stability (Section 6.3) was marginally better for VDS-7 data, and Reliability (Sections 6.1 and 6.2) was better for VAS data in the image descrip- tion evaluations, but (mostly) better for VDS-7 data in the weather forecast evaluations. Finally, the VAS experiments found greater numbers of statistically significant differences between systems in 3 out of 4 cases (Section 6.5). Our own raters strongly prefer working with VAS scales over VDSs. This has also long been clear from the psychology literature (Svensson, 2000)), where raters are typically found to prefer VAS scales over VDSs which can be a “constant source of vexation to the conscientious rater when he finds his judgments falling between the defined points” (Champney, 1941). Moreover, if a rater’s judgment falls between two points on a VDS then they must make the false choice between the two points just above and just below their actual judgment. In this case we know that the point they end up selecting is not an accurate measure of their judgment but rather just one of two equally accurate ones (one of which goes unrecorded). Our results establish (for our evaluation tasks) that VAS scales, so far unproven for use in NLP, are at least as good as VDSs, currently virtually the only scale in use in NLP. Combined with the fact that raters strongly prefer VASs and that they are regarded as more amenable to parametric means of statistical analysis, this indicates that VAS scales should be used more widely for NLP evaluation tasks. References Gabor Angeli, Percy Liang, and Dan Klein. 2010. A simple domain-independent probabilistic approach to generation. In Proceedings of the 15th Conference on Empirical Methods in Natural Language Processing (EMNLP’10). Anja Belz and Eric Kow. 2009. System building cost vs. output quality in data-to-text generation. In Proceedings of the 12th European Workshop on Natural Language Generation, pages 16–24. H. Champney. 1941. The measurement of parent behavior. Child Development, 12(2): 13 1. M. Freyd. 1923. The graphic rating scale. Biometrical Journal, 42:83–102. A. Gatt, A. Belz, and E. Kow. 2009. The TUNA Challenge 2009: Overview and evaluation results. In Proceedings of the 12th European Workshop on Natural Language Generation (ENLG’09), pages 198–206. Brian Langner. 2010. Data-driven Natural Language Generation: Making Machines Talk Like Humans Using Natural Corpora. Ph.D. thesis, Language Technologies Institute, School of Computer Science, Carnegie Mellon University. Robert W. Lansing, Shakeeb H. Moosavi, and Robert B. Banzett. 2003. Measurement of dyspnea: word labeled visual analog scale vs. verbal ordinal scale. Respiratory Physiology & Neurobiology, 134(2):77 –83. J. Scott and E. C. Huskisson. 2003. Vertical or horizontal visual analogue scales. Annals of the rheumatic diseases, (38):560. Sidney Siegel. 1957. Non-parametric statistics. The American Statistician, 11(3): 13–19. Elisabeth Svensson. 2000. Comparison of the quality of assessments using continuous and discrete ordinal rating scales. Biometrical Journal, 42(4):417–434. P. M. ten Klooster, A. P. Klaar, E. Taal, R. E. Gheith, J. J. Rasker, A. K. El-Garf, and M. A. van de Laar. 2006. The validity and reliability of the graphic rating scale and verbal rating scale for measuing pain across cultures: A study in egyptian and dutch women with rheumatoid arthritis. The Clinical Journal of Pain, 22(9):827–30. Kees van Deemter, Ielka van der Sluis, and Albert Gatt. 2006. Building a semantically transparent corpus for the generation of referring expressions. In Proceedings of the 4th International Conference on Natural Language Generation, pages 130–132, Sydney, Australia, July. S. Williams and E. Reiter. 2008. Generating basic skills reports for low-skilled readers. Natural Language Engineering, 14(4):495–525. 235</p><p>3 0.58732307 <a title="120-lsi-3" href="./acl-2011-Subjective_Natural_Language_Problems%3A_Motivations%2C_Applications%2C_Characterizations%2C_and_Implications.html">288 acl-2011-Subjective Natural Language Problems: Motivations, Applications, Characterizations, and Implications</a></p>
<p>Author: Cecilia Ovesdotter Alm</p><p>Abstract: This opinion paper discusses subjective natural language problems in terms of their motivations, applications, characterizations, and implications. It argues that such problems deserve increased attention because of their potential to challenge the status of theoretical understanding, problem-solving methods, and evaluation techniques in computational linguistics. The author supports a more holistic approach to such problems; a view that extends beyond opinion mining or sentiment analysis.</p><p>4 0.55575383 <a title="120-lsi-4" href="./acl-2011-Learning_to_Win_by_Reading_Manuals_in_a_Monte-Carlo_Framework.html">207 acl-2011-Learning to Win by Reading Manuals in a Monte-Carlo Framework</a></p>
<p>Author: S.R.K Branavan ; David Silver ; Regina Barzilay</p><p>Abstract: This paper presents a novel approach for leveraging automatically extracted textual knowledge to improve the performance of control applications such as games. Our ultimate goal is to enrich a stochastic player with highlevel guidance expressed in text. Our model jointly learns to identify text that is relevant to a given game state in addition to learning game strategies guided by the selected text. Our method operates in the Monte-Carlo search framework, and learns both text analysis and game strategies based only on environment feedback. We apply our approach to the complex strategy game Civilization II using the official game manual as the text guide. Our results show that a linguistically-informed game-playing agent significantly outperforms its language-unaware counterpart, yielding a 27% absolute improvement and winning over 78% of games when playing against the built- . in AI of Civilization II. 1</p><p>5 0.50813419 <a title="120-lsi-5" href="./acl-2011-Language_Use%3A_What_can_it_tell_us%3F.html">194 acl-2011-Language Use: What can it tell us?</a></p>
<p>Author: Marjorie Freedman ; Alex Baron ; Vasin Punyakanok ; Ralph Weischedel</p><p>Abstract: For 20 years, information extraction has focused on facts expressed in text. In contrast, this paper is a snapshot of research in progress on inferring properties and relationships among participants in dialogs, even though these properties/relationships need not be expressed as facts. For instance, can a machine detect that someone is attempting to persuade another to action or to change beliefs or is asserting their credibility? We report results on both English and Arabic discussion forums. 1</p><p>6 0.50338733 <a title="120-lsi-6" href="./acl-2011-Hierarchical_Text_Classification_with_Latent_Concepts.html">150 acl-2011-Hierarchical Text Classification with Latent Concepts</a></p>
<p>7 0.50211358 <a title="120-lsi-7" href="./acl-2011-Word_Maturity%3A_Computational_Modeling_of_Word_Knowledge.html">341 acl-2011-Word Maturity: Computational Modeling of Word Knowledge</a></p>
<p>8 0.50146139 <a title="120-lsi-8" href="./acl-2011-Extracting_Comparative_Entities_and_Predicates_from_Texts_Using_Comparative_Type_Classification.html">130 acl-2011-Extracting Comparative Entities and Predicates from Texts Using Comparative Type Classification</a></p>
<p>9 0.49866596 <a title="120-lsi-9" href="./acl-2011-A_New_Dataset_and_Method_for_Automatically_Grading_ESOL_Texts.html">20 acl-2011-A New Dataset and Method for Automatically Grading ESOL Texts</a></p>
<p>10 0.49780157 <a title="120-lsi-10" href="./acl-2011-A_Simple_Measure_to_Assess_Non-response.html">25 acl-2011-A Simple Measure to Assess Non-response</a></p>
<p>11 0.49763983 <a title="120-lsi-11" href="./acl-2011-Combining_Indicators_of_Allophony.html">74 acl-2011-Combining Indicators of Allophony</a></p>
<p>12 0.49760506 <a title="120-lsi-12" href="./acl-2011-Age_Prediction_in_Blogs%3A_A_Study_of_Style%2C_Content%2C_and_Online_Behavior_in_Pre-_and_Post-Social_Media_Generations.html">31 acl-2011-Age Prediction in Blogs: A Study of Style, Content, and Online Behavior in Pre- and Post-Social Media Generations</a></p>
<p>13 0.48756644 <a title="120-lsi-13" href="./acl-2011-NULEX%3A_An_Open-License_Broad_Coverage_Lexicon.html">229 acl-2011-NULEX: An Open-License Broad Coverage Lexicon</a></p>
<p>14 0.48521203 <a title="120-lsi-14" href="./acl-2011-Unsupervised_Discovery_of_Domain-Specific_Knowledge_from_Text.html">320 acl-2011-Unsupervised Discovery of Domain-Specific Knowledge from Text</a></p>
<p>15 0.48038241 <a title="120-lsi-15" href="./acl-2011-Prototyping_virtual_instructors_from_human-human_corpora.html">252 acl-2011-Prototyping virtual instructors from human-human corpora</a></p>
<p>16 0.47410336 <a title="120-lsi-16" href="./acl-2011-Towards_Style_Transformation_from_Written-Style_to_Audio-Style.html">306 acl-2011-Towards Style Transformation from Written-Style to Audio-Style</a></p>
<p>17 0.46975043 <a title="120-lsi-17" href="./acl-2011-Does_Size_Matter_-_How_Much_Data_is_Required_to_Train_a_REG_Algorithm%3F.html">102 acl-2011-Does Size Matter - How Much Data is Required to Train a REG Algorithm?</a></p>
<p>18 0.46924752 <a title="120-lsi-18" href="./acl-2011-Predicting_Clicks_in_a_Vocabulary_Learning_System.html">248 acl-2011-Predicting Clicks in a Vocabulary Learning System</a></p>
<p>19 0.44111139 <a title="120-lsi-19" href="./acl-2011-Lost_in_Translation%3A_Authorship_Attribution_using_Frame_Semantics.html">214 acl-2011-Lost in Translation: Authorship Attribution using Frame Semantics</a></p>
<p>20 0.44011801 <a title="120-lsi-20" href="./acl-2011-Discovering_Sociolinguistic_Associations_with_Structured_Sparsity.html">97 acl-2011-Discovering Sociolinguistic Associations with Structured Sparsity</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.052), (17, 0.03), (26, 0.043), (31, 0.015), (37, 0.06), (39, 0.059), (41, 0.036), (55, 0.031), (59, 0.034), (60, 0.326), (72, 0.035), (91, 0.041), (96, 0.099), (97, 0.015)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.70465827 <a title="120-lda-1" href="./acl-2011-Even_the_Abstract_have_Color%3A_Consensus_in_Word-Colour_Associations.html">120 acl-2011-Even the Abstract have Color: Consensus in Word-Colour Associations</a></p>
<p>Author: Saif Mohammad</p><p>Abstract: Colour is a key component in the successful dissemination of information. Since many real-world concepts are associated with colour, for example danger with red, linguistic information is often complemented with the use of appropriate colours in information visualization and product marketing. Yet, there is no comprehensive resource that captures concept–colour associations. We present a method to create a large word–colour association lexicon by crowdsourcing. A wordchoice question was used to obtain sense-level annotations and to ensure data quality. We focus especially on abstract concepts and emotions to show that even they tend to have strong colour associations. Thus, using the right colours can not only improve semantic coherence, but also inspire the desired emotional response.</p><p>2 0.52385628 <a title="120-lda-2" href="./acl-2011-Using_Bilingual_Information_for_Cross-Language_Document_Summarization.html">326 acl-2011-Using Bilingual Information for Cross-Language Document Summarization</a></p>
<p>Author: Xiaojun Wan</p><p>Abstract: Cross-language document summarization is defined as the task of producing a summary in a target language (e.g. Chinese) for a set of documents in a source language (e.g. English). Existing methods for addressing this task make use of either the information from the original documents in the source language or the information from the translated documents in the target language. In this study, we propose to use the bilingual information from both the source and translated documents for this task. Two summarization methods (SimFusion and CoRank) are proposed to leverage the bilingual information in the graph-based ranking framework for cross-language summary extraction. Experimental results on the DUC2001 dataset with manually translated reference Chinese summaries show the effectiveness of the proposed methods. 1</p><p>3 0.46317539 <a title="120-lda-3" href="./acl-2011-Target-dependent_Twitter_Sentiment_Classification.html">292 acl-2011-Target-dependent Twitter Sentiment Classification</a></p>
<p>Author: Long Jiang ; Mo Yu ; Ming Zhou ; Xiaohua Liu ; Tiejun Zhao</p><p>Abstract: Sentiment analysis on Twitter data has attracted much attention recently. In this paper, we focus on target-dependent Twitter sentiment classification; namely, given a query, we classify the sentiments of the tweets as positive, negative or neutral according to whether they contain positive, negative or neutral sentiments about that query. Here the query serves as the target of the sentiments. The state-ofthe-art approaches for solving this problem always adopt the target-independent strategy, which may assign irrelevant sentiments to the given target. Moreover, the state-of-the-art approaches only take the tweet to be classified into consideration when classifying the sentiment; they ignore its context (i.e., related tweets). However, because tweets are usually short and more ambiguous, sometimes it is not enough to consider only the current tweet for sentiment classification. In this paper, we propose to improve target-dependent Twitter sentiment classification by 1) incorporating target-dependent features; and 2) taking related tweets into consideration. According to the experimental results, our approach greatly improves the performance of target-dependent sentiment classification. 1</p><p>4 0.43718168 <a title="120-lda-4" href="./acl-2011-Bayesian_Word_Alignment_for_Statistical_Machine_Translation.html">57 acl-2011-Bayesian Word Alignment for Statistical Machine Translation</a></p>
<p>Author: Coskun Mermer ; Murat Saraclar</p><p>Abstract: In this work, we compare the translation performance of word alignments obtained via Bayesian inference to those obtained via expectation-maximization (EM). We propose a Gibbs sampler for fully Bayesian inference in IBM Model 1, integrating over all possible parameter values in finding the alignment distribution. We show that Bayesian inference outperforms EM in all of the tested language pairs, domains and data set sizes, by up to 2.99 BLEU points. We also show that the proposed method effectively addresses the well-known rare word problem in EM-estimated models; and at the same time induces a much smaller dictionary of bilingual word-pairs. .t r</p><p>5 0.42500699 <a title="120-lda-5" href="./acl-2011-Fine-Grained_Class_Label_Markup_of_Search_Queries.html">137 acl-2011-Fine-Grained Class Label Markup of Search Queries</a></p>
<p>Author: Joseph Reisinger ; Marius Pasca</p><p>Abstract: We develop a novel approach to the semantic analysis of short text segments and demonstrate its utility on a large corpus of Web search queries. Extracting meaning from short text segments is difficult as there is little semantic redundancy between terms; hence methods based on shallow semantic analysis may fail to accurately estimate meaning. Furthermore search queries lack explicit syntax often used to determine intent in question answering. In this paper we propose a hybrid model of semantic analysis combining explicit class-label extraction with a latent class PCFG. This class-label correlation (CLC) model admits a robust parallel approximation, allowing it to scale to large amounts of query data. We demonstrate its performance in terms of (1) its predicted label accuracy on polysemous queries and (2) its ability to accurately chunk queries into base constituents.</p><p>6 0.42489946 <a title="120-lda-6" href="./acl-2011-Evaluating_the_Impact_of_Coder_Errors_on_Active_Learning.html">119 acl-2011-Evaluating the Impact of Coder Errors on Active Learning</a></p>
<p>7 0.42292815 <a title="120-lda-7" href="./acl-2011-Joint_Annotation_of_Search_Queries.html">182 acl-2011-Joint Annotation of Search Queries</a></p>
<p>8 0.42261195 <a title="120-lda-8" href="./acl-2011-The_Surprising_Variance_in_Shortest-Derivation_Parsing.html">300 acl-2011-The Surprising Variance in Shortest-Derivation Parsing</a></p>
<p>9 0.42087966 <a title="120-lda-9" href="./acl-2011-Good_Seed_Makes_a_Good_Crop%3A_Accelerating_Active_Learning_Using_Language_Modeling.html">145 acl-2011-Good Seed Makes a Good Crop: Accelerating Active Learning Using Language Modeling</a></p>
<p>10 0.42047468 <a title="120-lda-10" href="./acl-2011-Lexically-Triggered_Hidden_Markov_Models_for_Clinical_Document_Coding.html">209 acl-2011-Lexically-Triggered Hidden Markov Models for Clinical Document Coding</a></p>
<p>11 0.42001778 <a title="120-lda-11" href="./acl-2011-Scaling_up_Automatic_Cross-Lingual_Semantic_Role_Annotation.html">269 acl-2011-Scaling up Automatic Cross-Lingual Semantic Role Annotation</a></p>
<p>12 0.41897529 <a title="120-lda-12" href="./acl-2011-Extracting_Social_Power_Relationships_from_Natural_Language.html">133 acl-2011-Extracting Social Power Relationships from Natural Language</a></p>
<p>13 0.41816014 <a title="120-lda-13" href="./acl-2011-An_Empirical_Investigation_of_Discounting_in_Cross-Domain_Language_Models.html">38 acl-2011-An Empirical Investigation of Discounting in Cross-Domain Language Models</a></p>
<p>14 0.41780174 <a title="120-lda-14" href="./acl-2011-Interactive_Topic_Modeling.html">178 acl-2011-Interactive Topic Modeling</a></p>
<p>15 0.41701698 <a title="120-lda-15" href="./acl-2011-Beam-Width_Prediction_for_Efficient_Context-Free_Parsing.html">58 acl-2011-Beam-Width Prediction for Efficient Context-Free Parsing</a></p>
<p>16 0.41664529 <a title="120-lda-16" href="./acl-2011-Piggyback%3A_Using_Search_Engines_for_Robust_Cross-Domain_Named_Entity_Recognition.html">246 acl-2011-Piggyback: Using Search Engines for Robust Cross-Domain Named Entity Recognition</a></p>
<p>17 0.41534323 <a title="120-lda-17" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>18 0.41521987 <a title="120-lda-18" href="./acl-2011-Ranking_Class_Labels_Using_Query_Sessions.html">258 acl-2011-Ranking Class Labels Using Query Sessions</a></p>
<p>19 0.41495895 <a title="120-lda-19" href="./acl-2011-Parsing_the_Internal_Structure_of_Words%3A_A_New_Paradigm_for_Chinese_Word_Segmentation.html">241 acl-2011-Parsing the Internal Structure of Words: A New Paradigm for Chinese Word Segmentation</a></p>
<p>20 0.41463065 <a title="120-lda-20" href="./acl-2011-Exact_Decoding_of_Syntactic_Translation_Models_through_Lagrangian_Relaxation.html">123 acl-2011-Exact Decoding of Syntactic Translation Models through Lagrangian Relaxation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
