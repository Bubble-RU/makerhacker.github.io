<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>96 acl-2011-Disambiguating temporal-contrastive connectives for machine translation</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-96" href="#">acl2011-96</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>96 acl-2011-Disambiguating temporal-contrastive connectives for machine translation</h1>
<br/><p>Source: <a title="acl-2011-96-pdf" href="http://aclweb.org/anthology//P/P11/P11-3009.pdf">pdf</a></p><p>Author: Thomas Meyer</p><p>Abstract: Temporal–contrastive discourse connectives (although, while, since, etc.) signal various types ofrelations between clauses such as temporal, contrast, concession and cause. They are often ambiguous and therefore difficult to translate from one language to another. We discuss several new and translation-oriented experiments for the disambiguation of a specific subset of discourse connectives in order to correct some of the translation errors made by current statistical machine translation systems.</p><p>Reference: <a title="acl-2011-96-reference" href="../acl2011_reference/acl-2011-Disambiguating_temporal-contrastive_connectives_for_machine_translation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 ch  Abstract Temporal–contrastive discourse connectives (although, while, since, etc. [sent-3, score-0.853]
</p><p>2 ) signal various types ofrelations between clauses such as temporal, contrast, concession and cause. [sent-4, score-0.197]
</p><p>3 They are often ambiguous and therefore difficult to translate from one language to another. [sent-5, score-0.045]
</p><p>4 We discuss several new and translation-oriented experiments for the disambiguation of a specific subset of discourse connectives in order to correct some of the translation errors made by current statistical machine translation systems. [sent-6, score-1.113]
</p><p>5 1 Introduction The probabilistic phrase-based models used in statistical machine translation (SMT) have been improved by integrating linguistic information during training stages. [sent-7, score-0.083]
</p><p>6 On the other hand, integrating discourse information, such as discourse relations holding between two spans oftext or between sentences, has not yet been applied to SMT. [sent-10, score-0.562]
</p><p>7 This paper describes several disambiguation and translation experiments for a specific subset of discourse connectives. [sent-11, score-0.427]
</p><p>8 Based on examinations in multilingual corpora, we identified the connectives although, but, however, meanwhile, since, though, when and while as being particularly problematic for machine translation. [sent-12, score-0.597]
</p><p>9 These discourse connectives 46 signal various types of relations between clauses, such as temporal, contrast, concession, expansion, cause and condition, which are, as we also show, hard to annotate even by humans. [sent-13, score-0.876]
</p><p>10 Disambiguating these senses and tagging them in large corpora is hypothesized to help in improving SMT systems to avoid translation errors. [sent-14, score-0.316]
</p><p>11 Resources and the state of the art for discourse connective disambiguation and parsing are described in Section 3. [sent-17, score-0.788]
</p><p>12 Section 4 summarizes our experiments for disambiguating the senses of temporal–contrastive connectives. [sent-18, score-0.301]
</p><p>13 The impact of connective disambiguation on SMT is briefly presented in Section 5. [sent-19, score-0.532]
</p><p>14 2  Translating Connectives  Discourse connectives can signal multiple senses (Miltsakaki et al. [sent-21, score-0.871]
</p><p>15 For instance, the connective since can have a temporal and causal meaning. [sent-23, score-0.585]
</p><p>16 The disambiguation of these senses is crucial to the correct translation of texts from one language to another. [sent-24, score-0.446]
</p><p>17 Translation can be difficult because there may be no direct lexical correspondence for the explicit source language connective in the target language, as shown by the reference translation of the first example in Table 1, taken from the Europarl corpus (Koehn, 2005). [sent-25, score-0.571]
</p><p>18 More often, the incorrect rendering of the sense of a connective can lead to wrong translations, as in the second, third and fourth example in Table 1, which were translated by the Moses SMT decoder (Koehn Portland, OPR,ro UcSeeAdi 1n9g-s2 o4f J uthnee A 2C01L-1H. [sent-26, score-0.567]
</p><p>19 The discourse connectives, their translations, and their senses are indicated in bold. [sent-29, score-0.507]
</p><p>20 The first example is a reference translation from EN into FR, while the second, third and fourth example are wrong translations generated by MT (EN–FR and EN–DE), hence marked with an asterisk. [sent-30, score-0.208]
</p><p>21 The reference translation for the second example uses the French connective car with a correct causal sense, instead of the wrong depuis que generated by SMT, which expresses a temporal relation. [sent-33, score-0.788]
</p><p>22 In the third example, the SMT system failed to translate the English connective while to French. [sent-34, score-0.474]
</p><p>23 The French translation is therefore not coherent, the contrastive discourse information cannot be established without an explicit connective. [sent-35, score-0.486]
</p><p>24 In its German translation, it would be correct to use the connective auch wenn (for contrast) instead of obwohl (for concession). [sent-38, score-0.45]
</p><p>25 These examples illustrate the difficulties in trans-  lating discourse connectives, even when they are lexically explicit. [sent-39, score-0.279]
</p><p>26 When examining the frequency and sense distribution of these connectives and their translations in  the Europarl corpus, the results confirm that at least such a fine-grained disambiguation as the one between contrast and concession is necessary for a correct translation. [sent-43, score-1.035]
</p><p>27 Table 2 shows cases where the different senses of the connectives while and although lead to different translations. [sent-44, score-0.848]
</p><p>28 Disambiguation of the senses here can help finding the correct lexical correspondence of the connective. [sent-45, score-0.275]
</p><p>29 To confirm that the automatic translation of discourse connectives is not straightforward, we annotated 80 sentences from the Europarl corpus containing the connective while with the corresponding sense (T, CO or CT) and another 60 sentences containing the French connective alors que (T or CT). [sent-46, score-1.97]
</p><p>30 We then translated these sentences with the already mentioned EN–FR and FR–EN Moses SMT system and compared the output manually to the reference translations from the corpus. [sent-47, score-0.073]
</p><p>31 The overall system performance was 61% of correct translations for sentences with while and 55% of correct translations with alors que. [sent-48, score-0.189]
</p><p>32 As mistakes we either counted missing target connective words (only when the output sentence became incoherent) or wrong connective words because of failure in correct sense rendering. [sent-49, score-0.975]
</p><p>33 Also, the manual sense annotation task is not trivial. [sent-50, score-0.118]
</p><p>34 In a manual annotation experiment, the senses of the connective while (T, CO and CT) were indicated in 30 sentences by 4 annotators. [sent-51, score-0.724]
</p><p>35 The overall agreement on the senses was not higher than a kappa value of 0. [sent-52, score-0.28]
</p><p>36 3  Data and Related Work  One of the few available discourse annotated corpora in English is the Penn Discourse Treebank (PDTB) (Prasad et al. [sent-54, score-0.256]
</p><p>37 For this resource, one hundred types of explicit connectives were manually annotated, as well as implicit relations not signaled by a connective. [sent-56, score-0.683]
</p><p>38 For French, the ANNODIS project for annotation of discourse (Pery-Woodley et al. [sent-57, score-0.285]
</p><p>39 For German, a lexicon of discourse connectives exists since the 1990s, namely DiMLex for lexicon of discourse markers (Stede and Umbach, 1998). [sent-61, score-1.184]
</p><p>40 An equivalent, more recent database for French is LexConn for lexicon of  connectives (Roze et al. [sent-62, score-0.624]
</p><p>41 For the first classification experiments in Section 4, we concentrated on English and the explicit connectives in the PDTB data. [sent-65, score-0.655]
</p><p>42 The sense hierarchy used in the PDTB consists of three levels, reaching from four top level senses (Temporal, Contingency, Comparison and Expansion) via 16 subsenses on the second level to 23 further subsenses on the third level. [sent-66, score-0.579]
</p><p>43 As the annotators were allowed to assign one or two senses for each connective there are 129 possible simple or complex senses for more than 18,000 explicit connectives. [sent-67, score-0.986]
</p><p>44 The PDTB further sees connectives as discourse-level predicates that have two propositional arguments. [sent-68, score-0.597]
</p><p>45 Argument 2 is the one containing the explicit connective. [sent-69, score-0.058]
</p><p>46 [argument 2]), which is very helpful to examine the context of a connective (see Section 4. [sent-76, score-0.426]
</p><p>47 –  The release of the PDTB had quite an impact on disambiguation experiments. [sent-78, score-0.106]
</p><p>48 The state of the art for recognizing explicit connectives in English is therefore already high, at a level of 94% for disambiguating the four main senses on the first level of the PDTB sense hierarchy (Pitler and Nenkova, 2009). [sent-79, score-1.119]
</p><p>49 However, when using all 100 types of connectives 48 and the whole PDTB training set, it is not so difficult to achieve such a high score, because of the large amount of instances and the rather broad distinction of the four main classes only. [sent-80, score-0.597]
</p><p>50 As we show in the next section, when building separate classifiers for specific connectives with senses from the more detailed second hierarchy level of the PDTB, it is more difficult to reach high accuracies. [sent-81, score-0.915]
</p><p>51 (2010) built the first end-to-end PDTB discourse parser, which is able to parse unrestricted text with an F1 score of 38. [sent-83, score-0.277]
</p><p>52 18% on PDTB test data and for senses on the second hierarchy level. [sent-84, score-0.293]
</p><p>53 5 decision tree and NaiveBayes algorithms often used in recent research on discourse connective classification. [sent-88, score-0.682]
</p><p>54 Our first experiment was aimed at sense disambiguation down to the third level of the PDTB hierarchy. [sent-89, score-0.225]
</p><p>55 The training set here consisted of all 100 types of explicit connectives annotated in the PDTB training set (15,366 instances). [sent-90, score-0.655]
</p><p>56 The only two features were the (capitalized) connective word tokens from the PDTB and their Part of Speech (POS) tags. [sent-92, score-0.426]
</p><p>57 For all 129 possible sense combinations, including complex senses, results reach 66. [sent-93, score-0.071]
</p><p>58 86% for correctly classified connectives (with the 4 main senses), when using the connective token as the only feature. [sent-98, score-1.023]
</p><p>59 condition (COND), contrast (CT), concession (CO) and expansion (E). [sent-104, score-0.183]
</p><p>60 All subsenses from the third PDTB hierarchy level were merged under second level ones (C, COND, CT, CO). [sent-105, score-0.174]
</p><p>61 Exceptions were the top level senses T and E, which, so far, need no further disambiguation for translation. [sent-106, score-0.382]
</p><p>62 In addition, we extracted separate training sets for each of the 8 temporal–contrastive connectives in question and one training set for all them. [sent-107, score-0.597]
</p><p>63 The number of occurrences and senses in the sets for the single con-  nectives is listed in Table 3. [sent-108, score-0.251]
</p><p>64 The total number of instances in the training set for all 8 connectives is 5,299 occurrences, with a sense distribution of 56. [sent-109, score-0.668]
</p><p>65 1 Features The following basic surface features were considered when disambiguating the senses signaled by connectives. [sent-117, score-0.329]
</p><p>66 Future automated disambiguation will be applied to unrestricted text, identifying the discourse arguments and syntactical elements in automatically parsed and POS–tagged sentences. [sent-119, score-0.422]
</p><p>67 the (capitalized) connective word form its POS tag first word of argument 1 last word of argument 1 first word of argument 2 last word of argument 2 POS tag of the first word of argument 2  8. [sent-127, score-0.766]
</p><p>68 punctuation pattern 49 The cased word forms (feature 1) were left as is, therefore also indicating whether the connective is located at the beginning of a sentence or not. [sent-130, score-0.426]
</p><p>69 (2010) and duVerle and Prendinger (2009), the context of a connective is very important. [sent-136, score-0.426]
</p><p>70 The arguments may include other (reinforcing or opposite) connectives, numbers and antonyms (to express contrastive relations). [sent-137, score-0.107]
</p><p>71 We extracted the words at the beginning and at the end of argument 1 (features 3, 4) and argument 2 (features 5, 6) which are, as observed, other connectives, gerunds, adverbs or determiners (further generalized by features 7 and 8). [sent-138, score-0.136]
</p><p>72 The paths to syntactical ancestors (feature 9) in which the connective word form appears are quite numerous and were therefore truncated to a maximum of four ancestors (e. [sent-139, score-0.519]
</p><p>73 where C is the explicit connective and A a placeholder for all the other words. [sent-145, score-0.484]
</p><p>74 Punctuation is important for locating connectives as many of them are subordinating and coordinating conjunctions, separated by commas (Haddow, 2005, p. [sent-146, score-0.597]
</p><p>75 2  Results  In the disambiguation experiments described here, results were generated separately for every temporal–contrastive connective (supposing one may try to improve the translation of only certain connectives), in addition to one result for the whole subset. [sent-149, score-0.597]
</p><p>76 They were measured using accuracy (percentage of correctly classified instances) and the kappa value. [sent-151, score-0.047]
</p><p>77 the prediction for the most frequent sense annotated for the corresponding connective. [sent-154, score-0.071]
</p><p>78 The last result for all 8 temporal–contrastive connectives reports a six-way classification of senses very close to one another: the accuracy and kappa values are well above random agreement and prediction of the majority class. [sent-157, score-0.895]
</p><p>79 Note that experiments for specific subsets of connectives have very rarely been tried in research. [sent-158, score-0.597]
</p><p>80 The results for the single connectives are comparable with ours in the case of since and while, where similar senses were used. [sent-164, score-0.848]
</p><p>81 5  SMT Experiments  We have started to explore how to constrain an SMT system to use labeled connectives resulting from the experiments above. [sent-166, score-0.597]
</p><p>82 There are at least two methods to integrate labeled discourse connectives in the SMT process. [sent-167, score-0.853]
</p><p>83 , 2007)  in order to encourage it to translate a specific sense of a connective with an acceptable equivalent. [sent-169, score-0.54]
</p><p>84 A second, more natural method for an SMT system would be to apply the discourse information obtained from the disambiguation module, adding the sense tags to the discourse connectives in a large parallel corpus. [sent-170, score-1.286]
</p><p>85 Information about the possible senses of the connective while, labeled as temporal(1), contrast(2) or concession(3)) was directly introduced to the English source language phrases when there was an appro2Paired t-tests were performed at 95% confidence level. [sent-173, score-0.677]
</p><p>86 50 priate translation of the connective in the French equivalent phrase. [sent-175, score-0.491]
</p><p>87 The following example gives an idea of the changes in the phrase table of the above-mentioned EN–FR  Moses SMT system: < original: and the commission , while preserving | || et la commission tout en de´ faenndda tnhte |c c| |o 1m m3. [sent-177, score-0.217]
</p><p>88 7|1 e8t |a a| |c o| |m m| 1m i1s aenndda nwhti l|e|| many || | ee-0t 6bi 1en 5 que d0e7 neo-0m6b 2r. [sent-180, score-0.064]
</p><p>89 7an18y | | | |t t| |b i1e 1n > modified: and the commission , while-1 preserving | || et la commission tout en da´ nefden thdean cto |m m| |m m1i s1s i1o 1n 2, w. [sent-185, score-0.217]
</p><p>90 71h8il |- |1 1| p| |r |e s1e r1v and while-3 many ||| et bien que de nombreuses || | 1 10. [sent-186, score-0.084]
</p><p>91 labeled connectives  are correctly  tends to confirm the hypothesis  translated. [sent-192, score-0.623]
</p><p>92 This  of this paper, that  information regarding discourse connectives  indeed  can lead to better translations. [sent-193, score-0.853]
</p><p>93 6 Conclusion and Future Work The paper described  new translation-oriented  proaches to the disambiguation plicit discourse connectives temporal–contrastive  ap-  of a subset of ex-  with highly ambiguous  senses. [sent-194, score-1.018]
</p><p>94 Although lexically ex-  plicit, their translation by current SMT systems is  often wrong. [sent-195, score-0.088]
</p><p>95 In addition, the paper showed a first method to force an existing and trained SMT system to translate discourse connectives correctly. [sent-198, score-0.878]
</p><p>96 This led to noticeable improvements on the translations of the tested sentences. [sent-199, score-0.051]
</p><p>97 We will continue to train SMT systems on automatically labeled discourse connectives in large corpora. [sent-200, score-0.853]
</p><p>98 Rhetorical structure theory: towards a functional theory oftext organization. [sent-250, score-0.032]
</p><p>99 ANNODIS: une approche out-  ille de l’annotation de structures discursives. [sent-258, score-0.057]
</p><p>100 DiMLex: a lexicon of discourse markers for text generation and understanding. [sent-276, score-0.304]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('connectives', 0.597), ('connective', 0.426), ('pdtb', 0.311), ('discourse', 0.256), ('senses', 0.251), ('concession', 0.137), ('temporal', 0.129), ('smt', 0.12), ('contrastive', 0.107), ('disambiguation', 0.106), ('sense', 0.071), ('ct', 0.068), ('argument', 0.068), ('europarl', 0.067), ('translation', 0.065), ('que', 0.064), ('miltsakaki', 0.06), ('cond', 0.059), ('lexconn', 0.059), ('subsenses', 0.059), ('explicit', 0.058), ('en', 0.057), ('commission', 0.052), ('idiap', 0.052), ('translations', 0.051), ('prasad', 0.051), ('disambiguating', 0.05), ('french', 0.048), ('fr', 0.047), ('hierarchy', 0.042), ('alors', 0.039), ('annodis', 0.039), ('dimlex', 0.039), ('nagard', 0.039), ('plicit', 0.039), ('roze', 0.039), ('syntactical', 0.039), ('moses', 0.039), ('pitler', 0.037), ('co', 0.036), ('dinesh', 0.035), ('rashmi', 0.035), ('duverle', 0.035), ('stede', 0.035), ('tout', 0.035), ('nov', 0.032), ('oftext', 0.032), ('koehn', 0.031), ('exemplifies', 0.03), ('eleni', 0.03), ('nikhil', 0.03), ('philippe', 0.03), ('causal', 0.03), ('annotation', 0.029), ('kappa', 0.029), ('signaled', 0.028), ('wrong', 0.028), ('ancestors', 0.027), ('lexicon', 0.027), ('confirm', 0.026), ('translate', 0.025), ('level', 0.025), ('capitalized', 0.024), ('reaching', 0.024), ('correct', 0.024), ('third', 0.023), ('switzerland', 0.023), ('expansion', 0.023), ('contrast', 0.023), ('signal', 0.023), ('rhetorical', 0.023), ('lexically', 0.023), ('weka', 0.023), ('reference', 0.022), ('preserving', 0.021), ('unrestricted', 0.021), ('aravind', 0.021), ('mann', 0.021), ('joshi', 0.021), ('nenkova', 0.021), ('markers', 0.021), ('de', 0.02), ('ambiguous', 0.02), ('clauses', 0.02), ('fourth', 0.019), ('pos', 0.019), ('acceptable', 0.018), ('accuracy', 0.018), ('philipp', 0.018), ('manual', 0.018), ('integrating', 0.018), ('school', 0.017), ('asher', 0.017), ('martigny', 0.017), ('ofrelations', 0.017), ('livio', 0.017), ('robaldo', 0.017), ('ziheng', 0.017), ('matr', 0.017), ('approche', 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="96-tfidf-1" href="./acl-2011-Disambiguating_temporal-contrastive_connectives_for_machine_translation.html">96 acl-2011-Disambiguating temporal-contrastive connectives for machine translation</a></p>
<p>Author: Thomas Meyer</p><p>Abstract: Temporal–contrastive discourse connectives (although, while, since, etc.) signal various types ofrelations between clauses such as temporal, contrast, concession and cause. They are often ambiguous and therefore difficult to translate from one language to another. We discuss several new and translation-oriented experiments for the disambiguation of a specific subset of discourse connectives in order to correct some of the translation errors made by current statistical machine translation systems.</p><p>2 0.26907539 <a title="96-tfidf-2" href="./acl-2011-Automatically_Evaluating_Text_Coherence_Using_Discourse_Relations.html">53 acl-2011-Automatically Evaluating Text Coherence Using Discourse Relations</a></p>
<p>Author: Ziheng Lin ; Hwee Tou Ng ; Min-Yen Kan</p><p>Abstract: We present a novel model to represent and assess the discourse coherence of text. Our model assumes that coherent text implicitly favors certain types of discourse relation transitions. We implement this model and apply it towards the text ordering ranking task, which aims to discern an original text from a permuted ordering of its sentences. The experimental results demonstrate that our model is able to significantly outperform the state-ofthe-art coherence model by Barzilay and Lapata (2005), reducing the error rate of the previous approach by an average of 29% over three data sets against human upperbounds. We further show that our model is synergistic with the previous approach, demonstrating an error reduction of 73% when the features from both models are combined for the task.</p><p>3 0.1668023 <a title="96-tfidf-3" href="./acl-2011-Identification_of_Domain-Specific_Senses_in_a_Machine-Readable_Dictionary.html">158 acl-2011-Identification of Domain-Specific Senses in a Machine-Readable Dictionary</a></p>
<p>Author: Fumiyo Fukumoto ; Yoshimi Suzuki</p><p>Abstract: This paper focuses on domain-specific senses and presents a method for assigning category/domain label to each sense of words in a dictionary. The method first identifies each sense of a word in the dictionary to its corresponding category. We used a text classification technique to select appropriate senses for each domain. Then, senses were scored by computing the rank scores. We used Markov Random Walk (MRW) model. The method was tested on English and Japanese resources, WordNet 3.0 and EDR Japanese dictionary. For evaluation of the method, we compared English results with the Subject Field Codes (SFC) resources. We also compared each English and Japanese results to the first sense heuristics in the WSD task. These results suggest that identification of domain-specific senses (IDSS) may actually be of benefit.</p><p>4 0.14906538 <a title="96-tfidf-4" href="./acl-2011-Towards_Tracking_Semantic_Change_by_Visual_Analytics.html">307 acl-2011-Towards Tracking Semantic Change by Visual Analytics</a></p>
<p>Author: Christian Rohrdantz ; Annette Hautli ; Thomas Mayer ; Miriam Butt ; Daniel A. Keim ; Frans Plank</p><p>Abstract: This paper presents a new approach to detecting and tracking changes in word meaning by visually modeling and representing diachronic development in word contexts. Previous studies have shown that computational models are capable of clustering and disambiguating senses, a more recent trend investigates whether changes in word meaning can be tracked by automatic methods. The aim of our study is to offer a new instrument for investigating the diachronic development of word senses in a way that allows for a better understanding of the nature of semantic change in general. For this purpose we combine techniques from the field of Visual Analytics with unsupervised methods from Natural Language Processing, allowing for an interactive visual exploration of semantic change.</p><p>5 0.14595191 <a title="96-tfidf-5" href="./acl-2011-Latent_Semantic_Word_Sense_Induction_and_Disambiguation.html">198 acl-2011-Latent Semantic Word Sense Induction and Disambiguation</a></p>
<p>Author: Tim Van de Cruys ; Marianna Apidianaki</p><p>Abstract: In this paper, we present a unified model for the automatic induction of word senses from text, and the subsequent disambiguation of particular word instances using the automatically extracted sense inventory. The induction step and the disambiguation step are based on the same principle: words and contexts are mapped to a limited number of topical dimensions in a latent semantic word space. The intuition is that a particular sense is associated with a particular topic, so that different senses can be discriminated through their association with particular topical dimensions; in a similar vein, a particular instance of a word can be disambiguated by determining its most important topical dimensions. The model is evaluated on the SEMEVAL-20 10 word sense induction and disambiguation task, on which it reaches stateof-the-art results.</p><p>6 0.10298906 <a title="96-tfidf-6" href="./acl-2011-Models_and_Training_for_Unsupervised_Preposition_Sense_Disambiguation.html">224 acl-2011-Models and Training for Unsupervised Preposition Sense Disambiguation</a></p>
<p>7 0.092676617 <a title="96-tfidf-7" href="./acl-2011-ParaSense_or_How_to_Use_Parallel_Corpora_for_Word_Sense_Disambiguation.html">240 acl-2011-ParaSense or How to Use Parallel Corpora for Word Sense Disambiguation</a></p>
<p>8 0.085948862 <a title="96-tfidf-8" href="./acl-2011-Temporal_Evaluation.html">294 acl-2011-Temporal Evaluation</a></p>
<p>9 0.085584357 <a title="96-tfidf-9" href="./acl-2011-Which_Noun_Phrases_Denote_Which_Concepts%3F.html">334 acl-2011-Which Noun Phrases Denote Which Concepts?</a></p>
<p>10 0.068994857 <a title="96-tfidf-10" href="./acl-2011-Pre-_and_Postprocessing_for_Statistical_Machine_Translation_into_Germanic_Languages.html">247 acl-2011-Pre- and Postprocessing for Statistical Machine Translation into Germanic Languages</a></p>
<p>11 0.064085446 <a title="96-tfidf-11" href="./acl-2011-On-line_Language_Model_Biasing_for_Statistical_Machine_Translation.html">233 acl-2011-On-line Language Model Biasing for Statistical Machine Translation</a></p>
<p>12 0.061362065 <a title="96-tfidf-12" href="./acl-2011-Rare_Word_Translation_Extraction_from_Aligned_Comparable_Documents.html">259 acl-2011-Rare Word Translation Extraction from Aligned Comparable Documents</a></p>
<p>13 0.060274344 <a title="96-tfidf-13" href="./acl-2011-Improving_Dependency_Parsing_with_Semantic_Classes.html">167 acl-2011-Improving Dependency Parsing with Semantic Classes</a></p>
<p>14 0.057982497 <a title="96-tfidf-14" href="./acl-2011-Scaling_up_Automatic_Cross-Lingual_Semantic_Role_Annotation.html">269 acl-2011-Scaling up Automatic Cross-Lingual Semantic Role Annotation</a></p>
<p>15 0.057900071 <a title="96-tfidf-15" href="./acl-2011-Crowdsourcing_Translation%3A_Professional_Quality_from_Non-Professionals.html">90 acl-2011-Crowdsourcing Translation: Professional Quality from Non-Professionals</a></p>
<p>16 0.057144567 <a title="96-tfidf-16" href="./acl-2011-Domain_Adaptation_for_Machine_Translation_by_Mining_Unseen_Words.html">104 acl-2011-Domain Adaptation for Machine Translation by Mining Unseen Words</a></p>
<p>17 0.056836586 <a title="96-tfidf-17" href="./acl-2011-Consistent_Translation_using_Discriminative_Learning_-_A_Translation_Memory-inspired_Approach.html">81 acl-2011-Consistent Translation using Discriminative Learning - A Translation Memory-inspired Approach</a></p>
<p>18 0.05605603 <a title="96-tfidf-18" href="./acl-2011-Recognizing_Authority_in_Dialogue_with_an_Integer_Linear_Programming_Constrained_Model.html">260 acl-2011-Recognizing Authority in Dialogue with an Integer Linear Programming Constrained Model</a></p>
<p>19 0.053080756 <a title="96-tfidf-19" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>20 0.052309044 <a title="96-tfidf-20" href="./acl-2011-French_TimeBank%3A_An_ISO-TimeML_Annotated_Reference_Corpus.html">138 acl-2011-French TimeBank: An ISO-TimeML Annotated Reference Corpus</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.139), (1, -0.029), (2, -0.021), (3, 0.023), (4, 0.0), (5, 0.03), (6, 0.097), (7, 0.028), (8, -0.021), (9, -0.008), (10, 0.003), (11, -0.195), (12, 0.089), (13, -0.057), (14, -0.038), (15, -0.073), (16, 0.077), (17, 0.168), (18, -0.044), (19, 0.129), (20, 0.042), (21, 0.019), (22, -0.035), (23, 0.005), (24, 0.006), (25, 0.054), (26, -0.019), (27, -0.016), (28, -0.004), (29, 0.047), (30, -0.065), (31, 0.094), (32, 0.025), (33, 0.033), (34, -0.052), (35, -0.067), (36, -0.165), (37, 0.076), (38, -0.07), (39, -0.127), (40, -0.109), (41, 0.029), (42, 0.051), (43, -0.108), (44, -0.057), (45, 0.035), (46, -0.016), (47, -0.048), (48, -0.064), (49, 0.063)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93749148 <a title="96-lsi-1" href="./acl-2011-Disambiguating_temporal-contrastive_connectives_for_machine_translation.html">96 acl-2011-Disambiguating temporal-contrastive connectives for machine translation</a></p>
<p>Author: Thomas Meyer</p><p>Abstract: Temporal–contrastive discourse connectives (although, while, since, etc.) signal various types ofrelations between clauses such as temporal, contrast, concession and cause. They are often ambiguous and therefore difficult to translate from one language to another. We discuss several new and translation-oriented experiments for the disambiguation of a specific subset of discourse connectives in order to correct some of the translation errors made by current statistical machine translation systems.</p><p>2 0.68816924 <a title="96-lsi-2" href="./acl-2011-Identification_of_Domain-Specific_Senses_in_a_Machine-Readable_Dictionary.html">158 acl-2011-Identification of Domain-Specific Senses in a Machine-Readable Dictionary</a></p>
<p>Author: Fumiyo Fukumoto ; Yoshimi Suzuki</p><p>Abstract: This paper focuses on domain-specific senses and presents a method for assigning category/domain label to each sense of words in a dictionary. The method first identifies each sense of a word in the dictionary to its corresponding category. We used a text classification technique to select appropriate senses for each domain. Then, senses were scored by computing the rank scores. We used Markov Random Walk (MRW) model. The method was tested on English and Japanese resources, WordNet 3.0 and EDR Japanese dictionary. For evaluation of the method, we compared English results with the Subject Field Codes (SFC) resources. We also compared each English and Japanese results to the first sense heuristics in the WSD task. These results suggest that identification of domain-specific senses (IDSS) may actually be of benefit.</p><p>3 0.66110778 <a title="96-lsi-3" href="./acl-2011-Towards_Tracking_Semantic_Change_by_Visual_Analytics.html">307 acl-2011-Towards Tracking Semantic Change by Visual Analytics</a></p>
<p>Author: Christian Rohrdantz ; Annette Hautli ; Thomas Mayer ; Miriam Butt ; Daniel A. Keim ; Frans Plank</p><p>Abstract: This paper presents a new approach to detecting and tracking changes in word meaning by visually modeling and representing diachronic development in word contexts. Previous studies have shown that computational models are capable of clustering and disambiguating senses, a more recent trend investigates whether changes in word meaning can be tracked by automatic methods. The aim of our study is to offer a new instrument for investigating the diachronic development of word senses in a way that allows for a better understanding of the nature of semantic change in general. For this purpose we combine techniques from the field of Visual Analytics with unsupervised methods from Natural Language Processing, allowing for an interactive visual exploration of semantic change.</p><p>4 0.62282526 <a title="96-lsi-4" href="./acl-2011-Automatically_Evaluating_Text_Coherence_Using_Discourse_Relations.html">53 acl-2011-Automatically Evaluating Text Coherence Using Discourse Relations</a></p>
<p>Author: Ziheng Lin ; Hwee Tou Ng ; Min-Yen Kan</p><p>Abstract: We present a novel model to represent and assess the discourse coherence of text. Our model assumes that coherent text implicitly favors certain types of discourse relation transitions. We implement this model and apply it towards the text ordering ranking task, which aims to discern an original text from a permuted ordering of its sentences. The experimental results demonstrate that our model is able to significantly outperform the state-ofthe-art coherence model by Barzilay and Lapata (2005), reducing the error rate of the previous approach by an average of 29% over three data sets against human upperbounds. We further show that our model is synergistic with the previous approach, demonstrating an error reduction of 73% when the features from both models are combined for the task.</p><p>5 0.59439069 <a title="96-lsi-5" href="./acl-2011-Latent_Semantic_Word_Sense_Induction_and_Disambiguation.html">198 acl-2011-Latent Semantic Word Sense Induction and Disambiguation</a></p>
<p>Author: Tim Van de Cruys ; Marianna Apidianaki</p><p>Abstract: In this paper, we present a unified model for the automatic induction of word senses from text, and the subsequent disambiguation of particular word instances using the automatically extracted sense inventory. The induction step and the disambiguation step are based on the same principle: words and contexts are mapped to a limited number of topical dimensions in a latent semantic word space. The intuition is that a particular sense is associated with a particular topic, so that different senses can be discriminated through their association with particular topical dimensions; in a similar vein, a particular instance of a word can be disambiguated by determining its most important topical dimensions. The model is evaluated on the SEMEVAL-20 10 word sense induction and disambiguation task, on which it reaches stateof-the-art results.</p><p>6 0.54014796 <a title="96-lsi-6" href="./acl-2011-Models_and_Training_for_Unsupervised_Preposition_Sense_Disambiguation.html">224 acl-2011-Models and Training for Unsupervised Preposition Sense Disambiguation</a></p>
<p>7 0.53949767 <a title="96-lsi-7" href="./acl-2011-Which_Noun_Phrases_Denote_Which_Concepts%3F.html">334 acl-2011-Which Noun Phrases Denote Which Concepts?</a></p>
<p>8 0.53794551 <a title="96-lsi-8" href="./acl-2011-Temporal_Evaluation.html">294 acl-2011-Temporal Evaluation</a></p>
<p>9 0.53149271 <a title="96-lsi-9" href="./acl-2011-French_TimeBank%3A_An_ISO-TimeML_Annotated_Reference_Corpus.html">138 acl-2011-French TimeBank: An ISO-TimeML Annotated Reference Corpus</a></p>
<p>10 0.50578451 <a title="96-lsi-10" href="./acl-2011-ParaSense_or_How_to_Use_Parallel_Corpora_for_Word_Sense_Disambiguation.html">240 acl-2011-ParaSense or How to Use Parallel Corpora for Word Sense Disambiguation</a></p>
<p>11 0.40834633 <a title="96-lsi-11" href="./acl-2011-Translationese_and_Its_Dialects.html">311 acl-2011-Translationese and Its Dialects</a></p>
<p>12 0.39102468 <a title="96-lsi-12" href="./acl-2011-I_Thou_Thee%2C_Thou_Traitor%3A_Predicting_Formal_vs._Informal_Address_in_English_Literature.html">157 acl-2011-I Thou Thee, Thou Traitor: Predicting Formal vs. Informal Address in English Literature</a></p>
<p>13 0.36689404 <a title="96-lsi-13" href="./acl-2011-Unsupervised_Learning_of_Semantic_Relation_Composition.html">322 acl-2011-Unsupervised Learning of Semantic Relation Composition</a></p>
<p>14 0.34031898 <a title="96-lsi-14" href="./acl-2011-Disentangling_Chat_with_Local_Coherence_Models.html">101 acl-2011-Disentangling Chat with Local Coherence Models</a></p>
<p>15 0.33892885 <a title="96-lsi-15" href="./acl-2011-Domain_Adaptation_for_Machine_Translation_by_Mining_Unseen_Words.html">104 acl-2011-Domain Adaptation for Machine Translation by Mining Unseen Words</a></p>
<p>16 0.33488941 <a title="96-lsi-16" href="./acl-2011-Model-Portability_Experiments_for_Textual_Temporal_Analysis.html">222 acl-2011-Model-Portability Experiments for Textual Temporal Analysis</a></p>
<p>17 0.33121705 <a title="96-lsi-17" href="./acl-2011-Subjective_Natural_Language_Problems%3A_Motivations%2C_Applications%2C_Characterizations%2C_and_Implications.html">288 acl-2011-Subjective Natural Language Problems: Motivations, Applications, Characterizations, and Implications</a></p>
<p>18 0.3275528 <a title="96-lsi-18" href="./acl-2011-Improving_Dependency_Parsing_with_Semantic_Classes.html">167 acl-2011-Improving Dependency Parsing with Semantic Classes</a></p>
<p>19 0.3262583 <a title="96-lsi-19" href="./acl-2011-Sentence_Ordering_Driven_by_Local_and_Global_Coherence_for_Summary_Generation.html">280 acl-2011-Sentence Ordering Driven by Local and Global Coherence for Summary Generation</a></p>
<p>20 0.31837496 <a title="96-lsi-20" href="./acl-2011-Recognizing_Authority_in_Dialogue_with_an_Integer_Linear_Programming_Constrained_Model.html">260 acl-2011-Recognizing Authority in Dialogue with an Integer Linear Programming Constrained Model</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.04), (17, 0.041), (26, 0.041), (27, 0.277), (37, 0.09), (39, 0.035), (41, 0.046), (53, 0.02), (55, 0.022), (59, 0.063), (72, 0.032), (91, 0.023), (96, 0.151), (97, 0.019), (98, 0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.87619072 <a title="96-lda-1" href="./acl-2011-Wikipedia_Revision_Toolkit%3A_Efficiently_Accessing_Wikipedias_Edit_History.html">337 acl-2011-Wikipedia Revision Toolkit: Efficiently Accessing Wikipedias Edit History</a></p>
<p>Author: Oliver Ferschke ; Torsten Zesch ; Iryna Gurevych</p><p>Abstract: We present an open-source toolkit which allows (i) to reconstruct past states of Wikipedia, and (ii) to efficiently access the edit history of Wikipedia articles. Reconstructing past states of Wikipedia is a prerequisite for reproducing previous experimental work based on Wikipedia. Beyond that, the edit history of Wikipedia articles has been shown to be a valuable knowledge source for NLP, but access is severely impeded by the lack of efficient tools for managing the huge amount of provided data. By using a dedicated storage format, our toolkit massively decreases the data volume to less than 2% of the original size, and at the same time provides an easy-to-use interface to access the revision data. The language-independent design allows to process any language represented in Wikipedia. We expect this work to consolidate NLP research using Wikipedia in general, and to foster research making use of the knowledge encoded in Wikipedia’s edit history.</p><p>same-paper 2 0.76576161 <a title="96-lda-2" href="./acl-2011-Disambiguating_temporal-contrastive_connectives_for_machine_translation.html">96 acl-2011-Disambiguating temporal-contrastive connectives for machine translation</a></p>
<p>Author: Thomas Meyer</p><p>Abstract: Temporal–contrastive discourse connectives (although, while, since, etc.) signal various types ofrelations between clauses such as temporal, contrast, concession and cause. They are often ambiguous and therefore difficult to translate from one language to another. We discuss several new and translation-oriented experiments for the disambiguation of a specific subset of discourse connectives in order to correct some of the translation errors made by current statistical machine translation systems.</p><p>3 0.70480126 <a title="96-lda-3" href="./acl-2011-Disentangling_Chat_with_Local_Coherence_Models.html">101 acl-2011-Disentangling Chat with Local Coherence Models</a></p>
<p>Author: Micha Elsner ; Eugene Charniak</p><p>Abstract: We evaluate several popular models of local discourse coherence for domain and task generality by applying them to chat disentanglement. Using experiments on synthetic multiparty conversations, we show that most models transfer well from text to dialogue. Coherence models improve results overall when good parses and topic models are available, and on a constrained task for real chat data.</p><p>4 0.64653075 <a title="96-lda-4" href="./acl-2011-Domain_Adaptation_for_Machine_Translation_by_Mining_Unseen_Words.html">104 acl-2011-Domain Adaptation for Machine Translation by Mining Unseen Words</a></p>
<p>Author: Hal Daume III ; Jagadeesh Jagarlamudi</p><p>Abstract: We show that unseen words account for a large part of the translation error when moving to new domains. Using an extension of a recent approach to mining translations from comparable corpora (Haghighi et al., 2008), we are able to find translations for otherwise OOV terms. We show several approaches to integrating such translations into a phrasebased translation system, yielding consistent improvements in translations quality (between 0.5 and 1.5 Bleu points) on four domains and two language pairs.</p><p>5 0.59265578 <a title="96-lda-5" href="./acl-2011-Using_Bilingual_Parallel_Corpora_for_Cross-Lingual_Textual_Entailment.html">327 acl-2011-Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment</a></p>
<p>Author: Yashar Mehdad ; Matteo Negri ; Marcello Federico</p><p>Abstract: This paper explores the use of bilingual parallel corpora as a source of lexical knowledge for cross-lingual textual entailment. We claim that, in spite of the inherent difficulties of the task, phrase tables extracted from parallel data allow to capture both lexical relations between single words, and contextual information useful for inference. We experiment with a phrasal matching method in order to: i) build a system portable across languages, and ii) evaluate the contribution of lexical knowledge in isolation, without interaction with other inference mechanisms. Results achieved on an English-Spanish corpus obtained from the RTE3 dataset support our claim, with an overall accuracy above average scores reported by RTE participants on monolingual data. Finally, we show that using parallel corpora to extract paraphrase tables reveals their potential also in the monolingual setting, improving the results achieved with other sources of lexical knowledge.</p><p>6 0.58988893 <a title="96-lda-6" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>7 0.5887807 <a title="96-lda-7" href="./acl-2011-In-domain_Relation_Discovery_with_Meta-constraints_via_Posterior_Regularization.html">170 acl-2011-In-domain Relation Discovery with Meta-constraints via Posterior Regularization</a></p>
<p>8 0.58687216 <a title="96-lda-8" href="./acl-2011-A_Bayesian_Model_for_Unsupervised_Semantic_Parsing.html">3 acl-2011-A Bayesian Model for Unsupervised Semantic Parsing</a></p>
<p>9 0.58609027 <a title="96-lda-9" href="./acl-2011-Fine-Grained_Class_Label_Markup_of_Search_Queries.html">137 acl-2011-Fine-Grained Class Label Markup of Search Queries</a></p>
<p>10 0.58563542 <a title="96-lda-10" href="./acl-2011-Knowledge-Based_Weak_Supervision_for_Information_Extraction_of_Overlapping_Relations.html">190 acl-2011-Knowledge-Based Weak Supervision for Information Extraction of Overlapping Relations</a></p>
<p>11 0.58506989 <a title="96-lda-11" href="./acl-2011-ParaSense_or_How_to_Use_Parallel_Corpora_for_Word_Sense_Disambiguation.html">240 acl-2011-ParaSense or How to Use Parallel Corpora for Word Sense Disambiguation</a></p>
<p>12 0.58493042 <a title="96-lda-12" href="./acl-2011-Extracting_Social_Power_Relationships_from_Natural_Language.html">133 acl-2011-Extracting Social Power Relationships from Natural Language</a></p>
<p>13 0.58482951 <a title="96-lda-13" href="./acl-2011-Latent_Semantic_Word_Sense_Induction_and_Disambiguation.html">198 acl-2011-Latent Semantic Word Sense Induction and Disambiguation</a></p>
<p>14 0.58429545 <a title="96-lda-14" href="./acl-2011-Extracting_Opinion_Expressions_and_Their_Polarities_-_Exploration_of_Pipelines_and_Joint_Models.html">131 acl-2011-Extracting Opinion Expressions and Their Polarities - Exploration of Pipelines and Joint Models</a></p>
<p>15 0.58331287 <a title="96-lda-15" href="./acl-2011-Optimal_and_Syntactically-Informed_Decoding_for_Monolingual_Phrase-Based_Alignment.html">235 acl-2011-Optimal and Syntactically-Informed Decoding for Monolingual Phrase-Based Alignment</a></p>
<p>16 0.58318675 <a title="96-lda-16" href="./acl-2011-Semi-Supervised_Frame-Semantic_Parsing_for_Unknown_Predicates.html">274 acl-2011-Semi-Supervised Frame-Semantic Parsing for Unknown Predicates</a></p>
<p>17 0.58280277 <a title="96-lda-17" href="./acl-2011-Translationese_and_Its_Dialects.html">311 acl-2011-Translationese and Its Dialects</a></p>
<p>18 0.58138055 <a title="96-lda-18" href="./acl-2011-An_exponential_translation_model_for_target_language_morphology.html">44 acl-2011-An exponential translation model for target language morphology</a></p>
<p>19 0.58133483 <a title="96-lda-19" href="./acl-2011-Piggyback%3A_Using_Search_Engines_for_Robust_Cross-Domain_Named_Entity_Recognition.html">246 acl-2011-Piggyback: Using Search Engines for Robust Cross-Domain Named Entity Recognition</a></p>
<p>20 0.58088005 <a title="96-lda-20" href="./acl-2011-Scaling_up_Automatic_Cross-Lingual_Semantic_Role_Annotation.html">269 acl-2011-Scaling up Automatic Cross-Lingual Semantic Role Annotation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
