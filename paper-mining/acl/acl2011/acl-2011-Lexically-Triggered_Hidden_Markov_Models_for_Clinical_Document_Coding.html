<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>209 acl-2011-Lexically-Triggered Hidden Markov Models for Clinical Document Coding</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-209" href="#">acl2011-209</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>209 acl-2011-Lexically-Triggered Hidden Markov Models for Clinical Document Coding</h1>
<br/><p>Source: <a title="acl-2011-209-pdf" href="http://aclweb.org/anthology//P/P11/P11-1075.pdf">pdf</a></p><p>Author: Svetlana Kiritchenko ; Colin Cherry</p><p>Abstract: The automatic coding of clinical documents is an important task for today’s healthcare providers. Though it can be viewed as multi-label document classification, the coding problem has the interesting property that most code assignments can be supported by a single phrase found in the input document. We propose a Lexically-Triggered Hidden Markov Model (LT-HMM) that leverages these phrases to improve coding accuracy. The LT-HMM works in two stages: first, a lexical match is performed against a term dictionary to collect a set of candidate codes for a document. Next, a discriminative HMM selects the best subset of codes to assign to the document by tagging candidates as present or absent. By confirming codes proposed by a dictionary, the LT-HMM can share features across codes, enabling strong performance even on rare codes. In fact, we are able to recover codes that do not occur in the training set at all. Our approach achieves the best ever performance on the 2007 Medical NLP Challenge test set, with an F-measure of 89.84.</p><p>Reference: <a title="acl-2011-209-reference" href="../acl2011_reference/acl-2011-Lexically-Triggered_Hidden_Markov_Models_for_Clinical_Document_Coding_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 ca  Abstract The automatic coding of clinical documents is an important task for today’s healthcare providers. [sent-5, score-0.613]
</p><p>2 Though it can be viewed as multi-label document classification, the coding problem has the interesting property that most code assignments can be supported by a single phrase found in the input document. [sent-6, score-0.903]
</p><p>3 We propose a Lexically-Triggered Hidden Markov Model (LT-HMM) that leverages these phrases to improve coding accuracy. [sent-7, score-0.275]
</p><p>4 The LT-HMM works in two stages: first, a lexical match is performed against a term dictionary to collect a set of candidate codes for a document. [sent-8, score-0.896]
</p><p>5 Next, a discriminative HMM selects the best subset of codes to assign to the document by tagging candidates as present or absent. [sent-9, score-0.824]
</p><p>6 By confirming codes proposed by a dictionary, the LT-HMM can share features across codes, enabling strong performance even on rare codes. [sent-10, score-0.64]
</p><p>7 In fact, we are able to recover  codes that do not occur in the training set at all. [sent-11, score-0.622]
</p><p>8 Converting clinical narratives into a structured form would support essential activities such as administrative reporting, quality control, biosurveillance and biomedical research (Meystre et al. [sent-17, score-0.257]
</p><p>9 One way of representing a document is to code the patient’s conditions and the performed procedures into a nomenclature of clinical codes. [sent-19, score-0.857]
</p><p>10 The International Classification of Diseases,  9th and 10th revisions, Clinical Modification (ICD9-CM, ICD-10-CM) are the official administrative coding schemes for healthcare organizations in several countries, including the US and Canada. [sent-20, score-0.435]
</p><p>11 Typically, coding is performed by trained coding professionals, but this process can be both costly and errorprone. [sent-21, score-0.55]
</p><p>12 Automated methods can speed-up the coding process, improve the accuracy and consistency of internal documentation, and even result in higher reimbursement for the healthcare organization (Benson, 2006). [sent-22, score-0.366]
</p><p>13 Traditionally, statistical document coding is viewed as multi-class multi-label document classification, where each clinical free-text document is labelled with one or several codes from a pre-defined, possibly very large set of codes (Patrick et al. [sent-23, score-2.156]
</p><p>14 One classification model is learned for each code, and then all models are applied in turn to a new document to determine which codes should be assigned to the document. [sent-26, score-0.791]
</p><p>15 This paper presents a novel approach to document  coding that simultaneously models code-specific as well as general patterns in the data. [sent-28, score-0.43]
</p><p>16 Ac s2s0o1ci1a Atiosnso fcoirat Cioonm foprut Caotimonpaulta Lti nognuails Lti cnsg,u piasgteics 742–751, us to predict any code label, even codes for which no training data is available. [sent-31, score-1.09]
</p><p>17 Our approach, the lexically-triggered HMM (LT-HMM), is based on the fact that a code assignment is often indicated by short lexical triggers in the text. [sent-32, score-0.585]
</p><p>18 First, the LT-HMM identifies candidate codes by matching terms from a medical terminology dictionary. [sent-34, score-0.91]
</p><p>19 In this architecture, low-frequency codes can still be matched and confirmed using general characteristics of their trigger’s local context, leading to better prediction performance on these codes. [sent-36, score-0.597]
</p><p>20 2  Document Coding and Lexical Triggers  Document coding is a special case of multi-class multi-label text classification. [sent-37, score-0.275]
</p><p>21 Given a fixed set of possible codes, the ultimate goal is to assign a set of  codes to documents, based on their content. [sent-38, score-0.621]
</p><p>22 Furthermore, we observe that for each code assigned to a document, there is generally at least one corresponding trigger term in the text that accounts for the code’s assignment. [sent-39, score-0.823]
</p><p>23 For example, if an ICD-9-CM coding professional were to see “allergic bronchitis” somewhere in a clinical narrative, he or she would immediately consider adding code 493. [sent-40, score-0.947]
</p><p>24 The presence of these trigger terms separates document coding from text classification tasks, such as topic or genre classification, where evidence for a particular label is built up throughout a document. [sent-42, score-0.884]
</p><p>25 However, this does not make document coding a term recognition task, concerned only with the detection of triggers. [sent-43, score-0.528]
</p><p>26 Codes are assigned to a document as a whole, and code assignment decisions within a document may interact. [sent-44, score-0.815]
</p><p>27 Formally, we define the document coding task as follows: given a set of documents X and a set of available codes C, assign to each document xi a subset of codes Ci ⊂ C. [sent-46, score-1.828]
</p><p>28 In particular, we will assume that an (incomplete) dictionary D(c) exists for each code c ∈ C, which lists specific code terms asso743 ciated with c. [sent-49, score-1.023]
</p><p>29 Each code can have several corresponding terms while each term indicates the presence of exactly one code. [sent-52, score-0.586]
</p><p>30 A candidate code c is proposed each time a term from D(c) is found in a document. [sent-53, score-0.663]
</p><p>31 1 From triggers to codes The presence of a term from D(c) does not automatically imply the assignment of code c to a document. [sent-55, score-1.281]
</p><p>32 Even with extremely precise dictionaries, there are three main reasons why a candidate code may not appear in a document’s code subset. [sent-56, score-1.072]
</p><p>33 The context of the trigger term might indicate the irrelevancy of the code. [sent-58, score-0.437]
</p><p>34 In the clinical domain, such irrelevancy can be specified by a negative or speculative statement (e. [sent-59, score-0.327]
</p><p>35 There can be several closely related candidate codes; yet only one, the best fitted code should be assigned to the document. [sent-66, score-0.621]
</p><p>36 00) may both appear in the same clinical report, but only the most specific code, 789. [sent-69, score-0.242]
</p><p>37 For example, the ICD-9-CM coding rules state that no symptom codes should be given to a document if a definite diagnosis is present. [sent-73, score-1.123]
</p><p>38 On the other hand, if the diagnosis is uncertain, then codes for the symptoms should be assigned. [sent-75, score-0.656]
</p><p>39 This suggests a paradigm where suggested by a detected trigger in terms of both its local context presence of other candidate codes  a candidate code, term, is assessed (item 1) and the for the document  (items 2 and 3). [sent-76, score-1.551]
</p><p>40 1Note that dictionary-based trigger detection could be replaced by tagging approaches similar to those used in namedentity-recognition or information extraction. [sent-77, score-0.335]
</p><p>41 2 ICD-9-CM Coding As a specific application we have chosen the task of assigning ICD-9-CM codes to free-form clinical narratives. [sent-79, score-0.819]
</p><p>42 The reports were annotated with ICD-9-CM codes by three coding companies, and the majority codes were selected as a gold standard. [sent-83, score-1.469]
</p><p>43 In particular, the ICD-9-CM coding guidelines come with an index file that contains hundreds of thousands of terms  mapped to corresponding codes. [sent-87, score-0.368]
</p><p>44 As mentioned above, the ICD-9-CM coding rules create strong code dependencies: codes are assigned to a document as a set and not individually. [sent-93, score-1.516]
</p><p>45 Furthermore, the code distribution throughout the CMC training documents has a very heavy tail; that is, there are a few heavily-used codes and a large number of codes that are used only occasionally. [sent-94, score-1.716]
</p><p>46 3  Related work  Automated clinical coding has received much attention in the medical informatics literature. [sent-96, score-0.603]
</p><p>47 reviewed 113 studies on automated coding published in the last 40 years (Stanfill et al. [sent-98, score-0.293]
</p><p>48 The authors conclude that there exists a variety of tools 744 covering different purposes, healthcare specialties, and clinical document types; however, these tools are not generalizable and neither are their evaluation results. [sent-100, score-0.468]
</p><p>49 This approach is feasible for the small code set used in the challenge, but it is questionable in real-life settings where thousands of codes need to be considered. [sent-114, score-1.047]
</p><p>50 Strong competition systems had good answers for dealing with negative and speculative contexts, taking advantage of the competition’s limited set of possible code combinations, and handling of low-frequency codes. [sent-123, score-0.542]
</p><p>51 We combine a symbolic component that matches lexical strings of a document against a medical dictionary to determine possible codes (Lussier  et al. [sent-125, score-1.018]
</p><p>52 , 2000; Kevers and Medori, 2010) and a statistical component that finalizes the assignment of codes to the document. [sent-126, score-0.654]
</p><p>53 (2007), in that we train a single model for all codes with codespecific and generic features. [sent-128, score-0.635]
</p><p>54 (2007) did not employ our lexical trigger step or our sequence-modeling formulation. [sent-130, score-0.293]
</p><p>55 In fact, they considered all possible code subsets, which can be infeasible in real-life settings. [sent-131, score-0.45]
</p><p>56 Lexically match text to the dictionary to get a set of candidate codes; 2. [sent-133, score-0.238]
</p><p>57 Using features derived from the candidates and the document, select the best code subset. [sent-134, score-0.517]
</p><p>58 In the first stage, dictionary terms are detected in the document using exact string matching. [sent-135, score-0.362]
</p><p>59 All codes corresponding to matches become candidate codes,  and no other codes can be proposed for this document. [sent-136, score-1.346]
</p><p>60 In the second stage, a single classifier is trained to select the best code subset from the matched candidates. [sent-137, score-0.472]
</p><p>61 The LT-HMM allows features learned from a document coded with ci to transfer at test time to predict code cj, provided their respective triggers appear in similar contexts. [sent-140, score-0.846]
</p><p>62 Training one common classifier improves our chances to reliably predict codes that have few training instances, and even codes that do not appear at all in the training data. [sent-141, score-1.304]
</p><p>63 1 Trigger Detection We have manually assembled a dictionary of terms for each of the 45 codes used in the CMC challenge. [sent-143, score-0.72]
</p><p>64 2 The dictionaries were built by collecting relevant medical terminology from UMLS, the ICD-9CM coding guidelines, and the CMC training data. [sent-144, score-0.454]
</p><p>65 If a trigger term is missing from the dictionary and, as the result, the code is not selected as a candidate code, it will not be recovered in the following stage, resulting in a false negative. [sent-156, score-1.042]
</p><p>66 2 Sequence Construction After trigger detection, we view the input document as a sequence of candidate codes, each correspond-  ing to a detected trigger (see Figure 1). [sent-162, score-1.044]
</p><p>67 By tagging these candidates in sequence, we can label each candidate code as present or absent and use previous tagging decisions to model code interactions. [sent-163, score-1.189]
</p><p>68 The final code subset is constructed by collecting all candidate codes tagged as present. [sent-164, score-1.199]
</p><p>69 Our training data consists of [document, code set] pairs, augmented with the trigger terms detected through dictionary matching. [sent-165, score-0.975]
</p><p>70 We transform this into a sequence to be tagged using the following steps: Ordering: The candidate code sequence is presented in reverse chronological order, according to when their corresponding trigger terms appear in the document. [sent-166, score-1.04]
</p><p>71 That is, the last candidate to be detected by the dictionary will be the first code to appear in our candidate sequence. [sent-167, score-0.944]
</p><p>72 Reverse order was chosen because clinical documents often close with a final (and informative) diagnosis. [sent-168, score-0.247]
</p><p>73 Merging: Each detected trigger corresponds to exactly one code; however, several triggers may be detected for the same code throughout a document. [sent-169, score-1.032]
</p><p>74 If a code has several triggers, we keep only the last occurrence. [sent-170, score-0.45]
</p><p>75 Labelling: Each candidate code is assigned a binary label (present or absent) based on whether it appears in the gold-standard code set. [sent-172, score-1.111]
</p><p>76 The top binary layer is the correct output tag sequence, which confirms or rejects the presence of candidate codes. [sent-174, score-0.295]
</p><p>77 The bottom layer shows the candidate code sequence derived from the text, with corresponding trigger phrases and some prominent features. [sent-175, score-0.96]
</p><p>78 process can not introduce gold-standard codes that were not proposed by the dictionary. [sent-176, score-0.597]
</p><p>79 To the left, we have an input text with underlined trigger phrases, as detected by our dictionary. [sent-178, score-0.4]
</p><p>80 This implies an input sequence (bottom right), which consists of detected codes and their corresponding trigger phrases. [sent-179, score-1.041]
</p><p>81 The gold-standard code set for the document is used to infer a gold-standard label sequence for these codes (top right). [sent-180, score-1.266]
</p><p>82 A discriminative HMM has two major categories of features: emission features, which characterize a candidate’s tag in terms of the input document x, and transition features, which characterize a tag in terms of the tags that have come before it. [sent-189, score-0.454]
</p><p>83 Transition Features The transition features are modeled as simple indicators over n-grams of present codes, for values of n up to 10, the largest number of codes proposed by 746 our dictionary in the training set. [sent-192, score-0.789]
</p><p>84 3 This allows the  system to learn sequences of codes that are (and are not) likely to occur in the gold-standard data. [sent-193, score-0.618]
</p><p>85 We found it useful to pad our n-grams with “beginning of document” tokens for sequences when fewer than n codes have been labelled as present, but found it harmful to include an end-of-document tag once labelling is complete. [sent-194, score-0.678]
</p><p>86 Emission Features The vast majority of our training signal comes from emission features, which carefully model both the trigger term’s local context and the document as a whole. [sent-196, score-0.558]
</p><p>87 For each candidate code, three types of features are generated: document features, ConText features, and code-semantics features (Table 1). [sent-197, score-0.393]
</p><p>88 These n-gram features have the candidate code appended to them, making them similar to features traditionally used in multiclass document categorization. [sent-199, score-0.863]
</p><p>89 ConText is publicly available software that determines the presence of negated, hypothetical, historical, and family-related context for a given phrase in a clinical text (Harkema et al. [sent-201, score-0.303]
</p><p>90 Regardless of its simplicity, the algorithm has shown very good performance on a variety of clinical document types. [sent-212, score-0.377]
</p><p>91 We run ConText for each trigger term located in the text and produce two types of features: features related to the candidate code in question and features related to other candidate codes of the document. [sent-213, score-1.791]
</p><p>92 Code Semantics: We include features that indicate if the code itself corresponds to a disease or a symptom. [sent-217, score-0.493]
</p><p>93 Like the ConText features, code features come in two types: those regarding the candidate code in question and those regarding other candidate codes from the same document. [sent-219, score-1.874]
</p><p>94 Generic features are concerned with classifying any candidate as present or absent based on characteristics of its trigger or semantics. [sent-221, score-0.552]
</p><p>95 Code-specific features append the candidate code to the feature. [sent-222, score-0.645]
</p><p>96 For example, the feature context=po s represents that the current candidate has a trigger term in a positive context, while context=pos : 4 8 6 adds the information that the code in question is 4 8 6. [sent-223, score-0.974]
</p><p>97 Note that n-grams features are only code-specific, as they are not connected to any specific trigger term. [sent-224, score-0.336]
</p><p>98 To an extent, code-specific features allow us  to replicate the traditional classification approach, which focuses on one code at a time. [sent-225, score-0.513]
</p><p>99 Using these features, the classifier is free to build complex submodels for a particular code, provided that this code has enough training examples. [sent-226, score-0.497]
</p><p>100 In this way, even in the extreme case of having zero training examples for a particular code, the model can still potentially assign the code to new documents, provided it is detected by our dictionary. [sent-228, score-0.583]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('codes', 0.597), ('code', 0.45), ('trigger', 0.293), ('coding', 0.275), ('clinical', 0.222), ('document', 0.155), ('candidate', 0.152), ('medical', 0.106), ('cmc', 0.099), ('triggers', 0.099), ('healthcare', 0.091), ('dictionary', 0.086), ('detected', 0.084), ('term', 0.061), ('diagnosis', 0.059), ('symbolic', 0.053), ('umls', 0.052), ('absent', 0.045), ('documentation', 0.045), ('challenge', 0.044), ('sequence', 0.044), ('context', 0.043), ('features', 0.043), ('emission', 0.042), ('allergic', 0.04), ('bronchitis', 0.04), ('irrelevancy', 0.04), ('pneumonia', 0.04), ('stanfill', 0.04), ('suominen', 0.04), ('presence', 0.038), ('coded', 0.038), ('hmm', 0.038), ('generic', 0.038), ('terms', 0.037), ('tag', 0.037), ('wt', 0.036), ('assignment', 0.036), ('speculative', 0.035), ('administrative', 0.035), ('organizations', 0.034), ('professionals', 0.032), ('obstacle', 0.03), ('dictionaries', 0.03), ('procedures', 0.03), ('negative', 0.03), ('come', 0.03), ('pain', 0.027), ('rejects', 0.027), ('competition', 0.027), ('crammer', 0.027), ('patient', 0.026), ('hypothetical', 0.026), ('guidelines', 0.026), ('negated', 0.025), ('training', 0.025), ('documents', 0.025), ('teams', 0.025), ('assign', 0.024), ('goldstein', 0.024), ('separates', 0.024), ('candidates', 0.024), ('tagging', 0.024), ('margin', 0.024), ('input', 0.023), ('labelling', 0.023), ('ci', 0.023), ('classifier', 0.022), ('throughout', 0.022), ('narrative', 0.022), ('sequences', 0.021), ('component', 0.021), ('layer', 0.021), ('transition', 0.02), ('classification', 0.02), ('label', 0.02), ('appear', 0.02), ('versions', 0.02), ('binary', 0.02), ('rules', 0.02), ('traditionally', 0.02), ('assigned', 0.019), ('gradient', 0.019), ('concerned', 0.019), ('stage', 0.018), ('automated', 0.018), ('positive', 0.018), ('characterize', 0.018), ('predict', 0.018), ('detection', 0.018), ('terminology', 0.018), ('indicators', 0.018), ('alterations', 0.017), ('odfe', 0.017), ('radiology', 0.017), ('symptom', 0.017), ('afford', 0.017), ('stimulate', 0.017), ('kiritchenko', 0.017), ('meystre', 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="209-tfidf-1" href="./acl-2011-Lexically-Triggered_Hidden_Markov_Models_for_Clinical_Document_Coding.html">209 acl-2011-Lexically-Triggered Hidden Markov Models for Clinical Document Coding</a></p>
<p>Author: Svetlana Kiritchenko ; Colin Cherry</p><p>Abstract: The automatic coding of clinical documents is an important task for today’s healthcare providers. Though it can be viewed as multi-label document classification, the coding problem has the interesting property that most code assignments can be supported by a single phrase found in the input document. We propose a Lexically-Triggered Hidden Markov Model (LT-HMM) that leverages these phrases to improve coding accuracy. The LT-HMM works in two stages: first, a lexical match is performed against a term dictionary to collect a set of candidate codes for a document. Next, a discriminative HMM selects the best subset of codes to assign to the document by tagging candidates as present or absent. By confirming codes proposed by a dictionary, the LT-HMM can share features across codes, enabling strong performance even on rare codes. In fact, we are able to recover codes that do not occur in the training set at all. Our approach achieves the best ever performance on the 2007 Medical NLP Challenge test set, with an F-measure of 89.84.</p><p>2 0.20419651 <a title="209-tfidf-2" href="./acl-2011-Enhancing_Language_Models_in_Statistical_Machine_Translation_with_Backward_N-grams_and_Mutual_Information_Triggers.html">116 acl-2011-Enhancing Language Models in Statistical Machine Translation with Backward N-grams and Mutual Information Triggers</a></p>
<p>Author: Deyi Xiong ; Min Zhang ; Haizhou Li</p><p>Abstract: In this paper, with a belief that a language model that embraces a larger context provides better prediction ability, we present two extensions to standard n-gram language models in statistical machine translation: a backward language model that augments the conventional forward language model, and a mutual information trigger model which captures long-distance dependencies that go beyond the scope of standard n-gram language models. We integrate the two proposed models into phrase-based statistical machine translation and conduct experiments on large-scale training data to investigate their effectiveness. Our experimental results show that both models are able to significantly improve transla- , tion quality and collectively achieve up to 1 BLEU point over a competitive baseline.</p><p>3 0.14954014 <a title="209-tfidf-3" href="./acl-2011-Improving_Classification_of_Medical_Assertions_in_Clinical_Notes.html">165 acl-2011-Improving Classification of Medical Assertions in Clinical Notes</a></p>
<p>Author: Youngjun Kim ; Ellen Riloff ; Stephane Meystre</p><p>Abstract: We present an NLP system that classifies the assertion type of medical problems in clinical notes used for the Fourth i2b2/VA Challenge. Our classifier uses a variety of linguistic features, including lexical, syntactic, lexicosyntactic, and contextual features. To overcome an extremely unbalanced distribution of assertion types in the data set, we focused our efforts on adding features specifically to improve the performance of minority classes. As a result, our system reached 94. 17% micro-averaged and 79.76% macro-averaged F1-measures, and showed substantial recall gains on the minority classes. 1</p><p>4 0.14589064 <a title="209-tfidf-4" href="./acl-2011-Recognizing_Authority_in_Dialogue_with_an_Integer_Linear_Programming_Constrained_Model.html">260 acl-2011-Recognizing Authority in Dialogue with an Integer Linear Programming Constrained Model</a></p>
<p>Author: Elijah Mayfield ; Carolyn Penstein Rose</p><p>Abstract: We present a novel computational formulation of speaker authority in discourse. This notion, which focuses on how speakers position themselves relative to each other in discourse, is first developed into a reliable coding scheme (0.71 agreement between human annotators). We also provide a computational model for automatically annotating text using this coding scheme, using supervised learning enhanced by constraints implemented with Integer Linear Programming. We show that this constrained model’s analyses of speaker authority correlates very strongly with expert human judgments (r2 coefficient of 0.947).</p><p>5 0.14313932 <a title="209-tfidf-5" href="./acl-2011-Can_Document_Selection_Help_Semi-supervised_Learning%3F_A_Case_Study_On_Event_Extraction.html">65 acl-2011-Can Document Selection Help Semi-supervised Learning? A Case Study On Event Extraction</a></p>
<p>Author: Shasha Liao ; Ralph Grishman</p><p>Abstract: Annotating training data for event extraction is tedious and labor-intensive. Most current event extraction tasks rely on hundreds of annotated documents, but this is often not enough. In this paper, we present a novel self-training strategy, which uses Information Retrieval (IR) to collect a cluster of related documents as the resource for bootstrapping. Also, based on the particular characteristics of this corpus, global inference is applied to provide more confident and informative data selection. We compare this approach to self-training on a normal newswire corpus and show that IR can provide a better corpus for bootstrapping and that global inference can further improve instance selection. We obtain gains of 1.7% in trigger labeling and 2.3% in role labeling through IR and an additional 1.1% in trigger labeling and 1.3% in role labeling by applying global inference. 1</p><p>6 0.074800156 <a title="209-tfidf-6" href="./acl-2011-Automatic_Labelling_of_Topic_Models.html">52 acl-2011-Automatic Labelling of Topic Models</a></p>
<p>7 0.07251855 <a title="209-tfidf-7" href="./acl-2011-Faster_and_Smaller_N-Gram_Language_Models.html">135 acl-2011-Faster and Smaller N-Gram Language Models</a></p>
<p>8 0.071703561 <a title="209-tfidf-8" href="./acl-2011-Using_Cross-Entity_Inference_to_Improve_Event_Extraction.html">328 acl-2011-Using Cross-Entity Inference to Improve Event Extraction</a></p>
<p>9 0.069556572 <a title="209-tfidf-9" href="./acl-2011-From_Bilingual_Dictionaries_to_Interlingual_Document_Representations.html">139 acl-2011-From Bilingual Dictionaries to Interlingual Document Representations</a></p>
<p>10 0.053891875 <a title="209-tfidf-10" href="./acl-2011-Entity_Set_Expansion_using_Topic_information.html">117 acl-2011-Entity Set Expansion using Topic information</a></p>
<p>11 0.053092066 <a title="209-tfidf-11" href="./acl-2011-Exploring_Entity_Relations_for_Named_Entity_Disambiguation.html">128 acl-2011-Exploring Entity Relations for Named Entity Disambiguation</a></p>
<p>12 0.051075257 <a title="209-tfidf-12" href="./acl-2011-Domain_Adaptation_for_Machine_Translation_by_Mining_Unseen_Words.html">104 acl-2011-Domain Adaptation for Machine Translation by Mining Unseen Words</a></p>
<p>13 0.050810002 <a title="209-tfidf-13" href="./acl-2011-Automatic_Extraction_of_Lexico-Syntactic_Patterns_for_Detection_of_Negation_and_Speculation_Scopes.html">50 acl-2011-Automatic Extraction of Lexico-Syntactic Patterns for Detection of Negation and Speculation Scopes</a></p>
<p>14 0.049245819 <a title="209-tfidf-14" href="./acl-2011-A_Fast_and_Accurate_Method_for_Approximate_String_Search.html">11 acl-2011-A Fast and Accurate Method for Approximate String Search</a></p>
<p>15 0.048877824 <a title="209-tfidf-15" href="./acl-2011-Hierarchical_Text_Classification_with_Latent_Concepts.html">150 acl-2011-Hierarchical Text Classification with Latent Concepts</a></p>
<p>16 0.04843723 <a title="209-tfidf-16" href="./acl-2011-Identification_of_Domain-Specific_Senses_in_a_Machine-Readable_Dictionary.html">158 acl-2011-Identification of Domain-Specific Senses in a Machine-Readable Dictionary</a></p>
<p>17 0.048048254 <a title="209-tfidf-17" href="./acl-2011-Template-Based_Information_Extraction_without_the_Templates.html">293 acl-2011-Template-Based Information Extraction without the Templates</a></p>
<p>18 0.047912288 <a title="209-tfidf-18" href="./acl-2011-Probabilistic_Document_Modeling_for_Syntax_Removal_in_Text_Summarization.html">251 acl-2011-Probabilistic Document Modeling for Syntax Removal in Text Summarization</a></p>
<p>19 0.047911048 <a title="209-tfidf-19" href="./acl-2011-Fully_Unsupervised_Word_Segmentation_with_BVE_and_MDL.html">140 acl-2011-Fully Unsupervised Word Segmentation with BVE and MDL</a></p>
<p>20 0.04775463 <a title="209-tfidf-20" href="./acl-2011-Extracting_Paraphrases_from_Definition_Sentences_on_the_Web.html">132 acl-2011-Extracting Paraphrases from Definition Sentences on the Web</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.134), (1, 0.039), (2, -0.063), (3, 0.029), (4, 0.017), (5, 0.032), (6, -0.025), (7, 0.012), (8, 0.049), (9, 0.024), (10, -0.046), (11, 0.012), (12, 0.025), (13, 0.032), (14, 0.03), (15, 0.018), (16, 0.005), (17, -0.001), (18, 0.019), (19, -0.041), (20, 0.073), (21, -0.075), (22, 0.056), (23, -0.036), (24, -0.043), (25, 0.038), (26, 0.022), (27, 0.052), (28, -0.072), (29, 0.021), (30, 0.073), (31, 0.022), (32, 0.128), (33, 0.043), (34, -0.14), (35, 0.05), (36, 0.013), (37, -0.06), (38, 0.12), (39, 0.002), (40, 0.035), (41, 0.062), (42, 0.012), (43, -0.005), (44, 0.026), (45, -0.079), (46, -0.013), (47, -0.002), (48, -0.098), (49, 0.196)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94504887 <a title="209-lsi-1" href="./acl-2011-Lexically-Triggered_Hidden_Markov_Models_for_Clinical_Document_Coding.html">209 acl-2011-Lexically-Triggered Hidden Markov Models for Clinical Document Coding</a></p>
<p>Author: Svetlana Kiritchenko ; Colin Cherry</p><p>Abstract: The automatic coding of clinical documents is an important task for today’s healthcare providers. Though it can be viewed as multi-label document classification, the coding problem has the interesting property that most code assignments can be supported by a single phrase found in the input document. We propose a Lexically-Triggered Hidden Markov Model (LT-HMM) that leverages these phrases to improve coding accuracy. The LT-HMM works in two stages: first, a lexical match is performed against a term dictionary to collect a set of candidate codes for a document. Next, a discriminative HMM selects the best subset of codes to assign to the document by tagging candidates as present or absent. By confirming codes proposed by a dictionary, the LT-HMM can share features across codes, enabling strong performance even on rare codes. In fact, we are able to recover codes that do not occur in the training set at all. Our approach achieves the best ever performance on the 2007 Medical NLP Challenge test set, with an F-measure of 89.84.</p><p>2 0.6998021 <a title="209-lsi-2" href="./acl-2011-Improving_Classification_of_Medical_Assertions_in_Clinical_Notes.html">165 acl-2011-Improving Classification of Medical Assertions in Clinical Notes</a></p>
<p>Author: Youngjun Kim ; Ellen Riloff ; Stephane Meystre</p><p>Abstract: We present an NLP system that classifies the assertion type of medical problems in clinical notes used for the Fourth i2b2/VA Challenge. Our classifier uses a variety of linguistic features, including lexical, syntactic, lexicosyntactic, and contextual features. To overcome an extremely unbalanced distribution of assertion types in the data set, we focused our efforts on adding features specifically to improve the performance of minority classes. As a result, our system reached 94. 17% micro-averaged and 79.76% macro-averaged F1-measures, and showed substantial recall gains on the minority classes. 1</p><p>3 0.6129033 <a title="209-lsi-3" href="./acl-2011-Enhancing_Language_Models_in_Statistical_Machine_Translation_with_Backward_N-grams_and_Mutual_Information_Triggers.html">116 acl-2011-Enhancing Language Models in Statistical Machine Translation with Backward N-grams and Mutual Information Triggers</a></p>
<p>Author: Deyi Xiong ; Min Zhang ; Haizhou Li</p><p>Abstract: In this paper, with a belief that a language model that embraces a larger context provides better prediction ability, we present two extensions to standard n-gram language models in statistical machine translation: a backward language model that augments the conventional forward language model, and a mutual information trigger model which captures long-distance dependencies that go beyond the scope of standard n-gram language models. We integrate the two proposed models into phrase-based statistical machine translation and conduct experiments on large-scale training data to investigate their effectiveness. Our experimental results show that both models are able to significantly improve transla- , tion quality and collectively achieve up to 1 BLEU point over a competitive baseline.</p><p>4 0.5215987 <a title="209-lsi-4" href="./acl-2011-ConsentCanvas%3A_Automatic_Texturing_for_Improved_Readability_in_End-User_License_Agreements.html">80 acl-2011-ConsentCanvas: Automatic Texturing for Improved Readability in End-User License Agreements</a></p>
<p>Author: Oliver Schneider ; Alex Garnett</p><p>Abstract: We present ConsentCanvas, a system which structures and “texturizes” End-User License Agreement (EULA) documents to be more readable. The system aims to help users better understand the terms under which they are providing their informed consent. ConsentCanvas receives unstructured text documents as input and uses unsupervised natural language processing methods to embellish the source document using a linked stylesheet. Unlike similar usable security projects which employ summarization techniques, our system preserves the contents of the source document, minimizing the cognitive and legal burden for both the end user and the licensor. Our system does not require a corpus for training. 1</p><p>5 0.4682588 <a title="209-lsi-5" href="./acl-2011-An_Interface_for_Rapid_Natural_Language_Processing_Development_in_UIMA.html">42 acl-2011-An Interface for Rapid Natural Language Processing Development in UIMA</a></p>
<p>Author: Balaji Soundrarajan ; Thomas Ginter ; Scott DuVall</p><p>Abstract: This demonstration presents the Annotation Librarian, an application programming interface that supports rapid development of natural language processing (NLP) projects built in Apache Unstructured Information Management Architecture (UIMA). The flexibility of UIMA to support all types of unstructured data – images, audio, and text – increases the complexity of some of the most common NLP development tasks. The Annotation Librarian interface handles these common functions and allows the creation and management of annotations by mirroring Java methods used to manipulate Strings. The familiar syntax and NLP-centric design allows developers to adopt and rapidly develop NLP algorithms in UIMA. The general functionality of the interface is described in relation to the use cases that necessitated its creation. 1</p><p>6 0.45718977 <a title="209-lsi-6" href="./acl-2011-Automatic_Extraction_of_Lexico-Syntactic_Patterns_for_Detection_of_Negation_and_Speculation_Scopes.html">50 acl-2011-Automatic Extraction of Lexico-Syntactic Patterns for Detection of Negation and Speculation Scopes</a></p>
<p>7 0.45430779 <a title="209-lsi-7" href="./acl-2011-Combining_Indicators_of_Allophony.html">74 acl-2011-Combining Indicators of Allophony</a></p>
<p>8 0.44526812 <a title="209-lsi-8" href="./acl-2011-An_ERP-based_Brain-Computer_Interface_for_text_entry_using_Rapid_Serial_Visual_Presentation_and_Language_Modeling.html">35 acl-2011-An ERP-based Brain-Computer Interface for text entry using Rapid Serial Visual Presentation and Language Modeling</a></p>
<p>9 0.41836411 <a title="209-lsi-9" href="./acl-2011-The_impact_of_language_models_and_loss_functions_on_repair_disfluency_detection.html">301 acl-2011-The impact of language models and loss functions on repair disfluency detection</a></p>
<p>10 0.41823792 <a title="209-lsi-10" href="./acl-2011-Faster_and_Smaller_N-Gram_Language_Models.html">135 acl-2011-Faster and Smaller N-Gram Language Models</a></p>
<p>11 0.41292563 <a title="209-lsi-11" href="./acl-2011-A_Scalable_Probabilistic_Classifier_for_Language_Modeling.html">24 acl-2011-A Scalable Probabilistic Classifier for Language Modeling</a></p>
<p>12 0.41227716 <a title="209-lsi-12" href="./acl-2011-Learning_Condensed_Feature_Representations_from_Large_Unsupervised_Data_Sets_for_Supervised_Learning.html">199 acl-2011-Learning Condensed Feature Representations from Large Unsupervised Data Sets for Supervised Learning</a></p>
<p>13 0.40853518 <a title="209-lsi-13" href="./acl-2011-Semi-supervised_condensed_nearest_neighbor_for_part-of-speech_tagging.html">278 acl-2011-Semi-supervised condensed nearest neighbor for part-of-speech tagging</a></p>
<p>14 0.4042722 <a title="209-lsi-14" href="./acl-2011-Can_Document_Selection_Help_Semi-supervised_Learning%3F_A_Case_Study_On_Event_Extraction.html">65 acl-2011-Can Document Selection Help Semi-supervised Learning? A Case Study On Event Extraction</a></p>
<p>15 0.4033381 <a title="209-lsi-15" href="./acl-2011-Semantic_Representation_of_Negation_Using_Focus_Detection.html">273 acl-2011-Semantic Representation of Negation Using Focus Detection</a></p>
<p>16 0.4022561 <a title="209-lsi-16" href="./acl-2011-A_Fast_and_Accurate_Method_for_Approximate_String_Search.html">11 acl-2011-A Fast and Accurate Method for Approximate String Search</a></p>
<p>17 0.3997803 <a title="209-lsi-17" href="./acl-2011-A_Corpus_of_Scope-disambiguated_English_Text.html">8 acl-2011-A Corpus of Scope-disambiguated English Text</a></p>
<p>18 0.38674396 <a title="209-lsi-18" href="./acl-2011-Recognizing_Authority_in_Dialogue_with_an_Integer_Linear_Programming_Constrained_Model.html">260 acl-2011-Recognizing Authority in Dialogue with an Integer Linear Programming Constrained Model</a></p>
<p>19 0.38592121 <a title="209-lsi-19" href="./acl-2011-From_Bilingual_Dictionaries_to_Interlingual_Document_Representations.html">139 acl-2011-From Bilingual Dictionaries to Interlingual Document Representations</a></p>
<p>20 0.38427705 <a title="209-lsi-20" href="./acl-2011-Exploiting_Readymades_in_Linguistic_Creativity%3A_A_System_Demonstration_of_the_Jigsaw_Bard.html">125 acl-2011-Exploiting Readymades in Linguistic Creativity: A System Demonstration of the Jigsaw Bard</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.058), (17, 0.056), (26, 0.034), (31, 0.013), (37, 0.066), (39, 0.071), (41, 0.097), (46, 0.234), (55, 0.042), (59, 0.03), (61, 0.013), (72, 0.037), (91, 0.039), (96, 0.102), (97, 0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.82014781 <a title="209-lda-1" href="./acl-2011-That%27s_What_She_Said%3A_Double_Entendre_Identification.html">297 acl-2011-That's What She Said: Double Entendre Identification</a></p>
<p>Author: Chloe Kiddon ; Yuriy Brun</p><p>Abstract: Humor identification is a hard natural language understanding problem. We identify a subproblem — the “that’s what she said” problem with two distinguishing characteristics: (1) use of nouns that are euphemisms for sexually explicit nouns and (2) structure common in the erotic domain. We address this problem in a classification approach that includes features that model those two characteristics. Experiments on web data demonstrate that our approach improves precision by 12% over baseline techniques that use only word-based features. —</p><p>same-paper 2 0.78697312 <a title="209-lda-2" href="./acl-2011-Lexically-Triggered_Hidden_Markov_Models_for_Clinical_Document_Coding.html">209 acl-2011-Lexically-Triggered Hidden Markov Models for Clinical Document Coding</a></p>
<p>Author: Svetlana Kiritchenko ; Colin Cherry</p><p>Abstract: The automatic coding of clinical documents is an important task for today’s healthcare providers. Though it can be viewed as multi-label document classification, the coding problem has the interesting property that most code assignments can be supported by a single phrase found in the input document. We propose a Lexically-Triggered Hidden Markov Model (LT-HMM) that leverages these phrases to improve coding accuracy. The LT-HMM works in two stages: first, a lexical match is performed against a term dictionary to collect a set of candidate codes for a document. Next, a discriminative HMM selects the best subset of codes to assign to the document by tagging candidates as present or absent. By confirming codes proposed by a dictionary, the LT-HMM can share features across codes, enabling strong performance even on rare codes. In fact, we are able to recover codes that do not occur in the training set at all. Our approach achieves the best ever performance on the 2007 Medical NLP Challenge test set, with an F-measure of 89.84.</p><p>3 0.7044763 <a title="209-lda-3" href="./acl-2011-P11-2093_k2opt.pdf.html">238 acl-2011-P11-2093 k2opt.pdf</a></p>
<p>Author: empty-author</p><p>Abstract: We present a pointwise approach to Japanese morphological analysis (MA) that ignores structure information during learning and tagging. Despite the lack of structure, it is able to outperform the current state-of-the-art structured approach for Japanese MA, and achieves accuracy similar to that of structured predictors using the same feature set. We also find that the method is both robust to outof-domain data, and can be easily adapted through the use of a combination of partial annotation and active learning.</p><p>4 0.59940439 <a title="209-lda-4" href="./acl-2011-Unary_Constraints_for_Efficient_Context-Free_Parsing.html">316 acl-2011-Unary Constraints for Efficient Context-Free Parsing</a></p>
<p>Author: Nathan Bodenstab ; Kristy Hollingshead ; Brian Roark</p><p>Abstract: We present a novel pruning method for context-free parsing that increases efficiency by disallowing phrase-level unary productions in CKY chart cells spanning a single word. Our work is orthogonal to recent work on “closing” chart cells, which has focused on multi-word constituents, leaving span-1 chart cells unpruned. We show that a simple discriminative classifier can learn with high accuracy which span-1 chart cells to close to phrase-level unary productions. Eliminating these unary productions from the search can have a large impact on downstream processing, depending on implementation details of the search. We apply our method to four parsing architectures and demonstrate how it is complementary to the cell-closing paradigm, as well as other pruning methods such as coarse-to-fine, agenda, and beam-search pruning.</p><p>5 0.59849274 <a title="209-lda-5" href="./acl-2011-Beam-Width_Prediction_for_Efficient_Context-Free_Parsing.html">58 acl-2011-Beam-Width Prediction for Efficient Context-Free Parsing</a></p>
<p>Author: Nathan Bodenstab ; Aaron Dunlop ; Keith Hall ; Brian Roark</p><p>Abstract: Efficient decoding for syntactic parsing has become a necessary research area as statistical grammars grow in accuracy and size and as more NLP applications leverage syntactic analyses. We review prior methods for pruning and then present a new framework that unifies their strengths into a single approach. Using a log linear model, we learn the optimal beam-search pruning parameters for each CYK chart cell, effectively predicting the most promising areas of the model space to explore. We demonstrate that our method is faster than coarse-to-fine pruning, exemplified in both the Charniak and Berkeley parsers, by empirically comparing our parser to the Berkeley parser using the same grammar and under identical operating conditions.</p><p>6 0.59386265 <a title="209-lda-6" href="./acl-2011-Evaluating_the_Impact_of_Coder_Errors_on_Active_Learning.html">119 acl-2011-Evaluating the Impact of Coder Errors on Active Learning</a></p>
<p>7 0.59197074 <a title="209-lda-7" href="./acl-2011-Can_Document_Selection_Help_Semi-supervised_Learning%3F_A_Case_Study_On_Event_Extraction.html">65 acl-2011-Can Document Selection Help Semi-supervised Learning? A Case Study On Event Extraction</a></p>
<p>8 0.59033298 <a title="209-lda-8" href="./acl-2011-Large-Scale_Cross-Document_Coreference_Using_Distributed_Inference_and_Hierarchical_Models.html">196 acl-2011-Large-Scale Cross-Document Coreference Using Distributed Inference and Hierarchical Models</a></p>
<p>9 0.58871919 <a title="209-lda-9" href="./acl-2011-Exploiting_Syntactico-Semantic_Structures_for_Relation_Extraction.html">126 acl-2011-Exploiting Syntactico-Semantic Structures for Relation Extraction</a></p>
<p>10 0.5858708 <a title="209-lda-10" href="./acl-2011-Good_Seed_Makes_a_Good_Crop%3A_Accelerating_Active_Learning_Using_Language_Modeling.html">145 acl-2011-Good Seed Makes a Good Crop: Accelerating Active Learning Using Language Modeling</a></p>
<p>11 0.58537215 <a title="209-lda-11" href="./acl-2011-Learning_Hierarchical_Translation_Structure_with_Linguistic_Annotations.html">202 acl-2011-Learning Hierarchical Translation Structure with Linguistic Annotations</a></p>
<p>12 0.58527631 <a title="209-lda-12" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>13 0.58466941 <a title="209-lda-13" href="./acl-2011-Scaling_up_Automatic_Cross-Lingual_Semantic_Role_Annotation.html">269 acl-2011-Scaling up Automatic Cross-Lingual Semantic Role Annotation</a></p>
<p>14 0.58404076 <a title="209-lda-14" href="./acl-2011-Fine-Grained_Class_Label_Markup_of_Search_Queries.html">137 acl-2011-Fine-Grained Class Label Markup of Search Queries</a></p>
<p>15 0.58276457 <a title="209-lda-15" href="./acl-2011-Faster_and_Smaller_N-Gram_Language_Models.html">135 acl-2011-Faster and Smaller N-Gram Language Models</a></p>
<p>16 0.5819177 <a title="209-lda-16" href="./acl-2011-Joint_Identification_and_Segmentation_of_Domain-Specific_Dialogue_Acts_for_Conversational_Dialogue_Systems.html">185 acl-2011-Joint Identification and Segmentation of Domain-Specific Dialogue Acts for Conversational Dialogue Systems</a></p>
<p>17 0.58186299 <a title="209-lda-17" href="./acl-2011-The_Surprising_Variance_in_Shortest-Derivation_Parsing.html">300 acl-2011-The Surprising Variance in Shortest-Derivation Parsing</a></p>
<p>18 0.58142948 <a title="209-lda-18" href="./acl-2011-Piggyback%3A_Using_Search_Engines_for_Robust_Cross-Domain_Named_Entity_Recognition.html">246 acl-2011-Piggyback: Using Search Engines for Robust Cross-Domain Named Entity Recognition</a></p>
<p>19 0.58137441 <a title="209-lda-19" href="./acl-2011-Integrating_surprisal_and_uncertain-input_models_in_online_sentence_comprehension%3A_formal_techniques_and_empirical_results.html">176 acl-2011-Integrating surprisal and uncertain-input models in online sentence comprehension: formal techniques and empirical results</a></p>
<p>20 0.58049572 <a title="209-lda-20" href="./acl-2011-Optimistic_Backtracking_-_A_Backtracking_Overlay_for_Deterministic_Incremental_Parsing.html">236 acl-2011-Optimistic Backtracking - A Backtracking Overlay for Deterministic Incremental Parsing</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
