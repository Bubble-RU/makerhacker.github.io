<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>196 acl-2011-Large-Scale Cross-Document Coreference Using Distributed Inference and Hierarchical Models</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-196" href="#">acl2011-196</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>196 acl-2011-Large-Scale Cross-Document Coreference Using Distributed Inference and Hierarchical Models</h1>
<br/><p>Source: <a title="acl-2011-196-pdf" href="http://aclweb.org/anthology//P/P11/P11-1080.pdf">pdf</a></p><p>Author: Sameer Singh ; Amarnag Subramanya ; Fernando Pereira ; Andrew McCallum</p><p>Abstract: Cross-document coreference, the task of grouping all the mentions of each entity in a document collection, arises in information extraction and automated knowledge base construction. For large collections, it is clearly impractical to consider all possible groupings of mentions into distinct entities. To solve the problem we propose two ideas: (a) a distributed inference technique that uses parallelism to enable large scale processing, and (b) a hierarchical model of coreference that represents uncertainty over multiple granularities of entities to facilitate more effective approximate inference. To evaluate these ideas, we constructed a labeled corpus of 1.5 million disambiguated mentions in Web pages by selecting link anchors referring to Wikipedia entities. We show that the combination of the hierarchical model with distributed inference quickly obtains high accuracy (with error reduction of 38%) on this large dataset, demonstrating the scalability of our approach.</p><p>Reference: <a title="acl-2011-196-reference" href="../acl2011_reference/acl-2011-Large-Scale_Cross-Document_Coreference_Using_Distributed_Inference_and_Hierarchical_Models_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 com, Abstract Cross-document coreference, the task of grouping all the mentions of each entity in a document collection, arises in information extraction and automated knowledge base construction. [sent-4, score-0.62]
</p><p>2 For large collections, it is clearly impractical to consider all possible groupings of mentions into distinct entities. [sent-5, score-0.48]
</p><p>3 5 million disambiguated mentions in Web pages by selecting link anchors referring to Wikipedia entities. [sent-8, score-0.535]
</p><p>4 We show that the combination of the hierarchical model with distributed inference  quickly obtains high accuracy (with error reduction of 38%) on this large dataset, demonstrating the scalability of our approach. [sent-9, score-0.432]
</p><p>5 1 Introduction Given a collection of mentions of entities extracted from a body of text, coreference or entity resolution consists of clustering the mentions such that two mentions belong to the same cluster if and only if they refer to the same entity. [sent-10, score-2.368]
</p><p>6 While significant progress has been made in within-document coreference (Ng, 2005; Culotta et al. [sent-13, score-0.381]
</p><p>7 edu  2009; Haghighi and Klein, 2010), the larger problem of cross-document coreference has not received as much attention. [sent-17, score-0.381]
</p><p>8 Unlike inference in other language processing tasks that scales linearly in the size of the corpus,  the hypothesis space for coreference grows superexponentially with the number of mentions. [sent-18, score-0.517]
</p><p>9 We believe that cross-document coreference resolution is most useful when applied to a very large set of documents, such as all the news articles published during the last 20 years. [sent-20, score-0.437]
</p><p>10 In this paper we propose a model and inference algorithms that can scale the cross-document coreference problem to corpora of that size. [sent-22, score-0.562]
</p><p>11 Much of the previous work in cross-document coreference (Bagga and Baldwin, 1998; Ravin and Kazi, 1999; Gooi and Allan, 2004; Pedersen et al. [sent-23, score-0.381]
</p><p>12 , 2010) groups mentions into entities with some form of greedy clustering using a pairwise mention similarity or distance function based on mention text, context, and document-level statistics. [sent-25, score-1.268]
</p><p>13 Other previous work attempts to address some of the above concerns by mapping coreference to in-  ference on an undirected graphical model (Culotta et al. [sent-28, score-0.447]
</p><p>14 These models contain pairwise factors between all pairs of mentions capturing similarity between them. [sent-33, score-0.702]
</p><p>15 Actor  Figure 1: Cross-Document Coreference Problem: Example mentions of “Kevin Times articles, with the true entities shown on the right. [sent-70, score-0.721]
</p><p>16 However as the number of mentions grows to Web scale, as in our problem of crossdocument coreference, even these inference techniques become infeasible, motivating the need for  a scalable, parallelizable solution. [sent-77, score-0.734]
</p><p>17 Entities are distributed across the machines such that the parallel MCMC chains on the different machines use only local proposal distributions. [sent-79, score-0.535]
</p><p>18 After a fixed number of samples on each machine, we redistribute the entities among machines to enable proposals across entities that were previously on different machines. [sent-80, score-0.854]
</p><p>19 As the number of mentions becomes large, highquality samples for MCMC become scarce. [sent-82, score-0.524]
</p><p>20 We add sub-entity variables that represent clusters of similar mentions that are likely to be coreferent; these are used to propose composite jumps that move multiple mentions together. [sent-84, score-1.094]
</p><p>21 We also introduce super-entity variables that represent clusters of similar entities; these are used to dis794 tribute entities among the machines such that similar  entities are assigned to the same machine. [sent-85, score-0.625]
</p><p>22 These additional levels of hierarchy dramatically increase the probability of beneficial proposals even with a large number of entities and mentions. [sent-86, score-0.462]
</p><p>23 2  Cross-document Coreference  The problem of coreference is to identify the sets of mention strings that refer to the same underlying entity. [sent-94, score-0.548]
</p><p>24 In within-document corefer-  ence, the mentions occur in a single document. [sent-96, score-0.48]
</p><p>25 The number of mentions (and entities) in each document is usually in the hundreds. [sent-97, score-0.48]
</p><p>26 The difficulty of the task arises from a large hypothesis space (exponential in the number of mentions) and challenge in resolving nominal and pronominal mentions to the correct named mentions. [sent-98, score-0.48]
</p><p>27 In most cases, named mentions are not ambiguous within a document. [sent-99, score-0.48]
</p><p>28 In crossdocument coreference, the number of mentions and entities is in the millions, making the combinatorics even more daunting. [sent-100, score-0.839]
</p><p>29 Furthermore, naming ambiguity is much more common as the same string can refer to multiple entities in different documents, and distinct strings may refer to the same entity in different documents. [sent-101, score-0.412]
</p><p>30 The model that we use for coreference represents mentions (M) and entities (E) as random variables. [sent-112, score-1.102]
</p><p>31 Each mention can take an entity as its value, and each entity takes a set of mentions as its value. [sent-113, score-0.896]
</p><p>32 More precisely, the probability of a configuration E = e is defined by  p(e) ∝ expPe∈e n+PPmm,n∈ e,en,n∈/ 6=emψ r(am(m,n,)no) where factor ψa representsP affinity between mentions that are coreferent according to e, and factor ψr represents repulsion between mentions that are  not coreferent. [sent-115, score-1.249]
</p><p>33 Figure 2 shows the model instantiated with five mentions over a twoentity hypothesis. [sent-117, score-0.522]
</p><p>34 For the factor potentials, we use cosine similarity of mention context pairs (φmn) such that 795  Figure 2: Pairwise Coreference Model: Factor graph for a 2-entity configuration of 5 mentions. [sent-118, score-0.335]
</p><p>35 As we will note in the next section, we do not need to calculate features between all pairs of mentions (as would be prohibitively expensive for large datasets); instead we only compute the features as and when required. [sent-123, score-0.48]
</p><p>36 The proposal function moves a randomly chosen mention l from its current entity es to a randomly chosen entity et. [sent-139, score-0.657]
</p><p>37 However, we only focus on inference in this work, and the only parameter that we set manually is the bias b, which indirectly influences the number of entities in Unless specified otherwise, in this work the initial configuration for MCMC is the singleton configuration, i. [sent-146, score-0.513]
</p><p>38 ine the factors that lie within the changed entities to evaluate a proposal, and (c) inference may be stopped at any point to obtain the current best configuration. [sent-150, score-0.499]
</p><p>39 However, the super exponential nature of the hypothesis space in cross-doc coreference renders this algorithm computationally unsuitable for 796 large scale coreference tasks. [sent-151, score-0.807]
</p><p>40 In particular, fruitful proposals (that increase the model score) are extremely rare, resulting in a large number of proposals that are not accepted. [sent-152, score-0.408]
</p><p>41 We describe methods to speed up inference by 1) evaluating multiple proposal simultaneously (Section 3), and 2) by augmenting our model with hierarchical variables that enable better proposal distributions (Section 4). [sent-153, score-0.623]
</p><p>42 3  Distributed MAP Inference  The key observation that enables distribution is that the acceptance probability computation of a proposal only examines a few factors that are not common to the previous and next configurations (Eq. [sent-154, score-0.341]
</p><p>43 Consider a pair of proposals, one that moves men-  tion l from entity es to entity et, and the other that moves mention l0 from entity e0s to entity et0. [sent-156, score-0.84]
</p><p>44 The set of factors to compute acceptance of the first proposal are factors between l and mentions in es and et, while the set of factors required to compute acceptance of the second proposal lie between l0 and mentions in e0s and et0. [sent-157, score-1.802]
</p><p>45 Different orders of evaluating such proposals are equivalent, and in fact, these proposals can be proposed and evaluated concurrently. [sent-159, score-0.36]
</p><p>46 This mutual-exclusivity is not restricted only to pairs of proposals; a set of proposals are mutually-exclusive if no two proposals require the same factor for evaluation. [sent-160, score-0.411]
</p><p>47 We divide the mentions and entities among multiple machines, and propose moves of mentions between entities assigned to the same machine. [sent-162, score-1.495]
</p><p>48 Since acceptance of a mention’s move requires examining factors that lie  between other mentions in its entity, we ensure that all mentions of an entity are assigned the same machine. [sent-164, score-1.355]
</p><p>49 To enable exploration of the complete configuration space, rounds of sampling are interleaved by redistribution stages, in which the entities are redistributed among the machines (see Figure 3). [sent-166, score-0.645]
</p><p>50 We use MapReduce (Dean and Ghe-  DistributorI n f e r e n c e Figure 3: Distributed MCMC-based Inference: Distributor divides the entities among the machines, and the machines run inference. [sent-167, score-0.338]
</p><p>51 This approach to distribution is equivalent to inference with all mentions and entities on a single  machine with a restricted proposer, but is faster since it exploits independencies to propose multiple jumps simultaneously. [sent-170, score-0.91]
</p><p>52 Partitioning the entities and proposing localjumps are restrictions to the single-machine proposal distribution; redistribution stages ensure the equivalent Markov chains are still irreducible. [sent-172, score-0.569]
</p><p>53 But as the number of mentions and entities increases, these fruitful samples become extremely rare due to the blowup in the possible space of configurations, resulting in rejection of a large number of proposals. [sent-177, score-0.813]
</p><p>54 However, due to random redistribution and a  naive proposal function within each machine, a large fraction of proposals are still wasted. [sent-179, score-0.446]
</p><p>55 1 Sub-Entities Consider the task of proposing moves of mentions (within a machine). [sent-182, score-0.533]
</p><p>56 Given the large number of mentions and entities, the probability that a ran797  domly picked mention that is moved to a random entity results in a better configuration is extremely small. [sent-183, score-0.858]
</p><p>57 If such a move is accepted, this gives us evidence that the mention did not belong to the previous entity, and we should also move similar mentions from the previous entity simultaneously to the same entity. [sent-184, score-0.826]
</p><p>58 Since the proposer moves only a single mention at a time, a large number of samples may be required to discover these fruitful moves. [sent-185, score-0.32]
</p><p>59 To enable block proposals that move similar mentions simultaneously, we introduce latent sub-entity variables that represent groups of similar mentions within an entity, where the similarity is defined by the model. [sent-186, score-1.318]
</p><p>60 For inference, we have stages of sampling sub-entities (moving individual mentions) in-  terleaved with stages of entity sampling (moving all mentions within a sub-entity). [sent-187, score-0.762]
</p><p>61 2 Super-Entities Another issue faced during distributed inference is that random redistribution is often wasteful. [sent-190, score-0.414]
</p><p>62 For example, if dissimilar entities are assigned to a machine, none of the proposals may be accepted. [sent-191, score-0.421]
</p><p>63 For a large number of entities and machines, the probability that similar entities will be assigned to the same machine is extremely small, leading to a larger number of wasted proposals. [sent-192, score-0.482]
</p><p>64 As for sub-entities above, inference switches between regular sampling of entities and sampling of super-entities (by moving entities). [sent-195, score-0.453]
</p><p>65 Dotted lines represent repulsion factors and solid lines represent affinity factors (the color denotes the type of variable that the factor touches). [sent-202, score-0.322]
</p><p>66 Second, we run the automated Person-X evaluation to obtain thousands of mentions that we use to demonstrate accuracy and scalability improvements. [sent-214, score-0.524]
</p><p>67 1 John Smith Corpus To compare with related work, we run an evaluation on the “John Smith” corpus (Bagga and Bald-  798 win, 1998), containing 197 mentions of the name “John Smith” from New York Times articles (labeled to obtain 35 true entities). [sent-217, score-0.512]
</p><p>68 2  Person-X Evaluation  There is a severe lack of labeled corpora for crossdocument coreference due to the effort required to evaluate the coreference decisions. [sent-228, score-0.88]
</p><p>69 Every mention string is replaced with an “X” for the coreference system. [sent-230, score-0.517]
</p><p>70 We use this evaluation methodology on 25k personname mentions from the New York Times corpus (Sandhaus, 2008) each with one of 50 unique strings. [sent-231, score-0.48]
</p><p>71 Size of an entity is the number of mentions of that entity. [sent-238, score-0.62]
</p><p>72 Figure 5 shows accuracy compared to relative wallclock running time for distributed inference on the flat, pairwise model. [sent-239, score-0.381]
</p><p>73 Distributed inference on our hierarchical model is evaluated in Figure 6 against inference on the pairwise model from Figure 5. [sent-241, score-0.445]
</p><p>74 Moreover, distributed in-  ference on the combined hierarchical model is both faster and more accurate than the individual hierarchical models. [sent-243, score-0.342]
</p><p>75 Since this set of mentions and labels can be noisy, we use the following filtering steps. [sent-252, score-0.48]
</p><p>76 All entities with less than 6 links to them are also discarded. [sent-256, score-0.288]
</p><p>77 We randomly sampled 5% of the entities to create a development set, treating the remaining entities as the test set. [sent-258, score-0.482]
</p><p>78 org/Hi l lary_Cl  inton  ψa/r (m, n) =  ± (φmn  − b + wSTREQ(m, n))  where STREQ is 1if mentions m and n are string identical (0 otherwise), and w is the weight to this feature. [sent-264, score-0.48]
</p><p>79 Due to the large size of the corpus, existing crossdocument coreference approaches could not be applied to this dataset. [sent-267, score-0.499]
</p><p>80 However, since a majority of related work consists of using clustering after defining a similarity function (Section 6), we provide a baseline evaluation of clustering with SubSquare (Bshouty and Long, 2010), a scalable, distributed clustering method. [sent-268, score-0.538]
</p><p>81 Subsquare takes as input a weighted graph with mentions as nodes and similarity between mentions used as edge weights. [sent-269, score-1.006]
</p><p>82 This algorithm is an efficient form of approximate spectral clustering (Bshouty and Long, 2010), and since it is given the same distances between mentions as our models, we expect it to get similar accuracy. [sent-271, score-0.641]
</p><p>83 We also gen-  erate another baseline clustering by assigning mentions with identical strings to the same entity. [sent-272, score-0.621]
</p><p>84 6  Related Work  Although the cross-document coreference problem is challenging and lacks large labeled datasets, its ubiquitous role as a key component of many knowledge discovery tasks has inspired several efforts. [sent-291, score-0.381]
</p><p>85 One of the first approaches to cross-document coreference (Bagga and Baldwin, 1998) uses an idf-based cosine-distance scoring function for pairs of contexts, similar to the one we use. [sent-293, score-0.381]
</p><p>86 Ravin and Kazi (1999) extend this work to be somewhat scalable by comparing pairs of contexts only if the mentions are deemed “ambiguous” using a heuristic. [sent-294, score-0.512]
</p><p>87 Since many related methods use clustering, there are a number of distributed clustering algorithms that may help scale these approaches. [sent-305, score-0.317]
</p><p>88 (2010) have proposed an online deterministic method that uses a stream of input mentions and assigns them greedily to entities. [sent-313, score-0.48]
</p><p>89 Although it can resolve mentions from non-trivial sized datasets, the method is restricted to a single machine, which  is not scalable to the very large number of mentions that are encountered in practice. [sent-314, score-0.992]
</p><p>90 Our representation of the problem as an undirected graphical model, and performing distributed inference on it, provides a combination of advantages not available in any of these approaches. [sent-315, score-0.364]
</p><p>91 First, most of the methods will not scale to the hundreds of millions of mentions that are present in real-world applications. [sent-316, score-0.525]
</p><p>92 801 7  Conclusions  Motivated by the problem of solving the coreference problem on billions of mentions from all of the newswire documents from the past few decades, we make the following contributions. [sent-324, score-0.861]
</p><p>93 First, we introduce distributed version of MCMC-based inference technique that can utilize parallelism to enable scalability. [sent-325, score-0.385]
</p><p>94 Second, we augment the model with hierarchical variables that facilitate fruitful proposal distributions. [sent-326, score-0.334]
</p><p>95 We also plan to examine inference on complex coreference models (such as with entity-wide factors). [sent-331, score-0.517]
</p><p>96 Our work enables crossdocument coreference on very large corpora, and we would like to explore the downstream applications that can benefit from it. [sent-334, score-0.499]
</p><p>97 Simple coreference resolution with rich syntactic and semantic features. [sent-413, score-0.437]
</p><p>98 Cross-document coreference resolution: A key technology for learning by reading. [sent-446, score-0.381]
</p><p>99 Machine learning for coreference resolution: From local classification to global ranking. [sent-464, score-0.381]
</p><p>100 An integrated, conditional model of information extraction and coreference with application to citation matching. [sent-514, score-0.381]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('mentions', 0.48), ('coreference', 0.381), ('entities', 0.241), ('proposals', 0.18), ('distributed', 0.162), ('proposal', 0.15), ('entity', 0.14), ('mention', 0.136), ('inference', 0.136), ('mcmc', 0.132), ('crossdocument', 0.118), ('redistribution', 0.116), ('subsquare', 0.116), ('wick', 0.116), ('clustering', 0.11), ('wikipedia', 0.107), ('configuration', 0.102), ('acceptance', 0.098), ('machines', 0.097), ('factors', 0.093), ('hierarchical', 0.09), ('pairwise', 0.083), ('bagga', 0.078), ('bshouty', 0.077), ('gooi', 0.077), ('culotta', 0.077), ('mccallum', 0.073), ('smith', 0.069), ('haghighi', 0.058), ('ravin', 0.058), ('resolution', 0.056), ('link', 0.055), ('moves', 0.053), ('jumps', 0.053), ('enable', 0.051), ('spectral', 0.051), ('factor', 0.051), ('repulsion', 0.051), ('fruitful', 0.048), ('links', 0.047), ('allan', 0.047), ('similarity', 0.046), ('variables', 0.046), ('scale', 0.045), ('pedersen', 0.044), ('scalability', 0.044), ('wellner', 0.044), ('aron', 0.044), ('andrew', 0.044), ('samples', 0.044), ('mn', 0.043), ('rao', 0.043), ('instantiated', 0.042), ('hierarchy', 0.041), ('mann', 0.041), ('map', 0.041), ('singh', 0.04), ('page', 0.04), ('bengston', 0.039), ('blume', 0.039), ('changhe', 0.039), ('datta', 0.039), ('firefighter', 0.039), ('kazi', 0.039), ('khashayar', 0.039), ('proposer', 0.039), ('rohanimanesh', 0.039), ('samplerank', 0.039), ('es', 0.038), ('sampling', 0.038), ('parallelism', 0.036), ('greedy', 0.036), ('nips', 0.036), ('move', 0.035), ('sameer', 0.035), ('uncertainty', 0.035), ('singleton', 0.034), ('affinity', 0.034), ('anchor', 0.034), ('sdm', 0.034), ('undirected', 0.033), ('baldwin', 0.033), ('graphical', 0.033), ('stages', 0.033), ('datasets', 0.032), ('name', 0.032), ('scalable', 0.032), ('freedman', 0.031), ('nx', 0.031), ('amarnag', 0.031), ('subramanya', 0.031), ('strings', 0.031), ('mcnamee', 0.029), ('purandare', 0.029), ('mapreduce', 0.029), ('niu', 0.029), ('mayfield', 0.029), ('webpages', 0.029), ('lie', 0.029), ('chains', 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="196-tfidf-1" href="./acl-2011-Large-Scale_Cross-Document_Coreference_Using_Distributed_Inference_and_Hierarchical_Models.html">196 acl-2011-Large-Scale Cross-Document Coreference Using Distributed Inference and Hierarchical Models</a></p>
<p>Author: Sameer Singh ; Amarnag Subramanya ; Fernando Pereira ; Andrew McCallum</p><p>Abstract: Cross-document coreference, the task of grouping all the mentions of each entity in a document collection, arises in information extraction and automated knowledge base construction. For large collections, it is clearly impractical to consider all possible groupings of mentions into distinct entities. To solve the problem we propose two ideas: (a) a distributed inference technique that uses parallelism to enable large scale processing, and (b) a hierarchical model of coreference that represents uncertainty over multiple granularities of entities to facilitate more effective approximate inference. To evaluate these ideas, we constructed a labeled corpus of 1.5 million disambiguated mentions in Web pages by selecting link anchors referring to Wikipedia entities. We show that the combination of the hierarchical model with distributed inference quickly obtains high accuracy (with error reduction of 38%) on this large dataset, demonstrating the scalability of our approach.</p><p>2 0.30995381 <a title="196-tfidf-2" href="./acl-2011-A_Pronoun_Anaphora_Resolution_System_based_on_Factorial_Hidden_Markov_Models.html">23 acl-2011-A Pronoun Anaphora Resolution System based on Factorial Hidden Markov Models</a></p>
<p>Author: Dingcheng Li ; Tim Miller ; William Schuler</p><p>Abstract: and Wellner, This paper presents a supervised pronoun anaphora resolution system based on factorial hidden Markov models (FHMMs). The basic idea is that the hidden states of FHMMs are an explicit short-term memory with an antecedent buffer containing recently described referents. Thus an observed pronoun can find its antecedent from the hidden buffer, or in terms of a generative model, the entries in the hidden buffer generate the corresponding pronouns. A system implementing this model is evaluated on the ACE corpus with promising performance.</p><p>3 0.25416225 <a title="196-tfidf-3" href="./acl-2011-Extending_the_Entity_Grid_with_Entity-Specific_Features.html">129 acl-2011-Extending the Entity Grid with Entity-Specific Features</a></p>
<p>Author: Micha Elsner ; Eugene Charniak</p><p>Abstract: We extend the popular entity grid representation for local coherence modeling. The grid abstracts away information about the entities it models; we add discourse prominence, named entity type and coreference features to distinguish between important and unimportant entities. We improve the best result for WSJ document discrimination by 6%.</p><p>4 0.24334417 <a title="196-tfidf-4" href="./acl-2011-A_Generative_Entity-Mention_Model_for_Linking_Entities_with_Knowledge_Base.html">12 acl-2011-A Generative Entity-Mention Model for Linking Entities with Knowledge Base</a></p>
<p>Author: Xianpei Han ; Le Sun</p><p>Abstract: Linking entities with knowledge base (entity linking) is a key issue in bridging the textual data with the structural knowledge base. Due to the name variation problem and the name ambiguity problem, the entity linking decisions are critically depending on the heterogenous knowledge of entities. In this paper, we propose a generative probabilistic model, called entitymention model, which can leverage heterogenous entity knowledge (including popularity knowledge, name knowledge and context knowledge) for the entity linking task. In our model, each name mention to be linked is modeled as a sample generated through a three-step generative story, and the entity knowledge is encoded in the distribution of entities in document P(e), the distribution of possible names of a specific entity P(s|e), and the distribution of possible contexts of a specific entity P(c|e). To find the referent entity of a name mention, our method combines the evidences from all the three distributions P(e), P(s|e) and P(c|e). Experimental results show that our method can significantly outperform the traditional methods. 1</p><p>5 0.23417728 <a title="196-tfidf-5" href="./acl-2011-Coreference_for_Learning_to_Extract_Relations%3A_Yes_Virginia%2C_Coreference_Matters.html">86 acl-2011-Coreference for Learning to Extract Relations: Yes Virginia, Coreference Matters</a></p>
<p>Author: Ryan Gabbard ; Marjorie Freedman ; Ralph Weischedel</p><p>Abstract: As an alternative to requiring substantial supervised relation training data, many have explored bootstrapping relation extraction from a few seed examples. Most techniques assume that the examples are based on easily spotted anchors, e.g., names or dates. Sentences in a corpus which contain the anchors are then used to induce alternative ways of expressing the relation. We explore whether coreference can improve the learning process. That is, if the algorithm considered examples such as his sister, would accuracy be improved? With coreference, we see on average a 2-fold increase in F-Score. Despite using potentially errorful machine coreference, we see significant increase in recall on all relations. Precision increases in four cases and decreases in six.</p><p>6 0.18138067 <a title="196-tfidf-6" href="./acl-2011-Bootstrapping_coreference_resolution_using_word_associations.html">63 acl-2011-Bootstrapping coreference resolution using word associations</a></p>
<p>7 0.17861792 <a title="196-tfidf-7" href="./acl-2011-A_Cross-Lingual_ILP_Solution_to_Zero_Anaphora_Resolution.html">9 acl-2011-A Cross-Lingual ILP Solution to Zero Anaphora Resolution</a></p>
<p>8 0.16366872 <a title="196-tfidf-8" href="./acl-2011-Exploiting_Syntactico-Semantic_Structures_for_Relation_Extraction.html">126 acl-2011-Exploiting Syntactico-Semantic Structures for Relation Extraction</a></p>
<p>9 0.16195562 <a title="196-tfidf-9" href="./acl-2011-Exploring_Entity_Relations_for_Named_Entity_Disambiguation.html">128 acl-2011-Exploring Entity Relations for Named Entity Disambiguation</a></p>
<p>10 0.14356142 <a title="196-tfidf-10" href="./acl-2011-Knowledge_Base_Population%3A_Successful_Approaches_and_Challenges.html">191 acl-2011-Knowledge Base Population: Successful Approaches and Challenges</a></p>
<p>11 0.140444 <a title="196-tfidf-11" href="./acl-2011-Coreference_Resolution_with_World_Knowledge.html">85 acl-2011-Coreference Resolution with World Knowledge</a></p>
<p>12 0.13598168 <a title="196-tfidf-12" href="./acl-2011-Using_Cross-Entity_Inference_to_Improve_Event_Extraction.html">328 acl-2011-Using Cross-Entity Inference to Improve Event Extraction</a></p>
<p>13 0.13471517 <a title="196-tfidf-13" href="./acl-2011-Knowledge-Based_Weak_Supervision_for_Information_Extraction_of_Overlapping_Relations.html">190 acl-2011-Knowledge-Based Weak Supervision for Information Extraction of Overlapping Relations</a></p>
<p>14 0.13168772 <a title="196-tfidf-14" href="./acl-2011-Semi-supervised_Relation_Extraction_with_Large-scale_Word_Clustering.html">277 acl-2011-Semi-supervised Relation Extraction with Large-scale Word Clustering</a></p>
<p>15 0.12552406 <a title="196-tfidf-15" href="./acl-2011-End-to-End_Relation_Extraction_Using_Distant_Supervision_from_External_Semantic_Repositories.html">114 acl-2011-End-to-End Relation Extraction Using Distant Supervision from External Semantic Repositories</a></p>
<p>16 0.1253338 <a title="196-tfidf-16" href="./acl-2011-Local_and_Global_Algorithms_for_Disambiguation_to_Wikipedia.html">213 acl-2011-Local and Global Algorithms for Disambiguation to Wikipedia</a></p>
<p>17 0.10446454 <a title="196-tfidf-17" href="./acl-2011-Entity_Set_Expansion_using_Topic_information.html">117 acl-2011-Entity Set Expansion using Topic information</a></p>
<p>18 0.10070223 <a title="196-tfidf-18" href="./acl-2011-Can_Document_Selection_Help_Semi-supervised_Learning%3F_A_Case_Study_On_Event_Extraction.html">65 acl-2011-Can Document Selection Help Semi-supervised Learning? A Case Study On Event Extraction</a></p>
<p>19 0.097092353 <a title="196-tfidf-19" href="./acl-2011-A_Bayesian_Model_for_Unsupervised_Semantic_Parsing.html">3 acl-2011-A Bayesian Model for Unsupervised Semantic Parsing</a></p>
<p>20 0.086001009 <a title="196-tfidf-20" href="./acl-2011-An_Error_Analysis_of_Relation_Extraction_in_Social_Media_Documents.html">40 acl-2011-An Error Analysis of Relation Extraction in Social Media Documents</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.221), (1, 0.072), (2, -0.22), (3, 0.04), (4, 0.157), (5, 0.042), (6, 0.01), (7, -0.096), (8, -0.337), (9, 0.083), (10, 0.116), (11, 0.024), (12, -0.116), (13, -0.1), (14, 0.047), (15, 0.087), (16, -0.006), (17, 0.036), (18, 0.037), (19, 0.05), (20, -0.023), (21, -0.037), (22, 0.117), (23, 0.064), (24, -0.016), (25, -0.009), (26, -0.02), (27, -0.099), (28, -0.085), (29, -0.059), (30, 0.049), (31, -0.057), (32, -0.091), (33, 0.029), (34, -0.023), (35, 0.018), (36, 0.045), (37, 0.011), (38, 0.019), (39, 0.065), (40, 0.054), (41, 0.009), (42, -0.005), (43, 0.043), (44, -0.02), (45, -0.011), (46, -0.028), (47, 0.001), (48, 0.049), (49, -0.079)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95694834 <a title="196-lsi-1" href="./acl-2011-Large-Scale_Cross-Document_Coreference_Using_Distributed_Inference_and_Hierarchical_Models.html">196 acl-2011-Large-Scale Cross-Document Coreference Using Distributed Inference and Hierarchical Models</a></p>
<p>Author: Sameer Singh ; Amarnag Subramanya ; Fernando Pereira ; Andrew McCallum</p><p>Abstract: Cross-document coreference, the task of grouping all the mentions of each entity in a document collection, arises in information extraction and automated knowledge base construction. For large collections, it is clearly impractical to consider all possible groupings of mentions into distinct entities. To solve the problem we propose two ideas: (a) a distributed inference technique that uses parallelism to enable large scale processing, and (b) a hierarchical model of coreference that represents uncertainty over multiple granularities of entities to facilitate more effective approximate inference. To evaluate these ideas, we constructed a labeled corpus of 1.5 million disambiguated mentions in Web pages by selecting link anchors referring to Wikipedia entities. We show that the combination of the hierarchical model with distributed inference quickly obtains high accuracy (with error reduction of 38%) on this large dataset, demonstrating the scalability of our approach.</p><p>2 0.84728128 <a title="196-lsi-2" href="./acl-2011-A_Pronoun_Anaphora_Resolution_System_based_on_Factorial_Hidden_Markov_Models.html">23 acl-2011-A Pronoun Anaphora Resolution System based on Factorial Hidden Markov Models</a></p>
<p>Author: Dingcheng Li ; Tim Miller ; William Schuler</p><p>Abstract: and Wellner, This paper presents a supervised pronoun anaphora resolution system based on factorial hidden Markov models (FHMMs). The basic idea is that the hidden states of FHMMs are an explicit short-term memory with an antecedent buffer containing recently described referents. Thus an observed pronoun can find its antecedent from the hidden buffer, or in terms of a generative model, the entries in the hidden buffer generate the corresponding pronouns. A system implementing this model is evaluated on the ACE corpus with promising performance.</p><p>3 0.74993986 <a title="196-lsi-3" href="./acl-2011-A_Cross-Lingual_ILP_Solution_to_Zero_Anaphora_Resolution.html">9 acl-2011-A Cross-Lingual ILP Solution to Zero Anaphora Resolution</a></p>
<p>Author: Ryu Iida ; Massimo Poesio</p><p>Abstract: We present an ILP-based model of zero anaphora detection and resolution that builds on the joint determination of anaphoricity and coreference model proposed by Denis and Baldridge (2007), but revises it and extends it into a three-way ILP problem also incorporating subject detection. We show that this new model outperforms several baselines and competing models, as well as a direct translation of the Denis / Baldridge model, for both Italian and Japanese zero anaphora. We incorporate our model in complete anaphoric resolvers for both Italian and Japanese, showing that our approach leads to improved performance also when not used in isolation, provided that separate classifiers are used for zeros and for ex- plicitly realized anaphors.</p><p>4 0.74598318 <a title="196-lsi-4" href="./acl-2011-Bootstrapping_coreference_resolution_using_word_associations.html">63 acl-2011-Bootstrapping coreference resolution using word associations</a></p>
<p>Author: Hamidreza Kobdani ; Hinrich Schuetze ; Michael Schiehlen ; Hans Kamp</p><p>Abstract: In this paper, we present an unsupervised framework that bootstraps a complete coreference resolution (CoRe) system from word associations mined from a large unlabeled corpus. We show that word associations are useful for CoRe – e.g., the strong association between Obama and President is an indicator of likely coreference. Association information has so far not been used in CoRe because it is sparse and difficult to learn from small labeled corpora. Since unlabeled text is readily available, our unsupervised approach addresses the sparseness problem. In a self-training framework, we train a decision tree on a corpus that is automatically labeled using word associations. We show that this unsupervised system has better CoRe performance than other learning approaches that do not use manually labeled data. .</p><p>5 0.73705608 <a title="196-lsi-5" href="./acl-2011-Coreference_Resolution_with_World_Knowledge.html">85 acl-2011-Coreference Resolution with World Knowledge</a></p>
<p>Author: Altaf Rahman ; Vincent Ng</p><p>Abstract: While world knowledge has been shown to improve learning-based coreference resolvers, the improvements were typically obtained by incorporating world knowledge into a fairly weak baseline resolver. Hence, it is not clear whether these benefits can carry over to a stronger baseline. Moreover, since there has been no attempt to apply different sources of world knowledge in combination to coreference resolution, it is not clear whether they offer complementary benefits to a resolver. We systematically compare commonly-used and under-investigated sources of world knowledge for coreference resolution by applying them to two learning-based coreference models and evaluating them on documents annotated with two different annotation schemes.</p><p>6 0.72526211 <a title="196-lsi-6" href="./acl-2011-A_Generative_Entity-Mention_Model_for_Linking_Entities_with_Knowledge_Base.html">12 acl-2011-A Generative Entity-Mention Model for Linking Entities with Knowledge Base</a></p>
<p>7 0.70623356 <a title="196-lsi-7" href="./acl-2011-Extending_the_Entity_Grid_with_Entity-Specific_Features.html">129 acl-2011-Extending the Entity Grid with Entity-Specific Features</a></p>
<p>8 0.64773029 <a title="196-lsi-8" href="./acl-2011-Knowledge_Base_Population%3A_Successful_Approaches_and_Challenges.html">191 acl-2011-Knowledge Base Population: Successful Approaches and Challenges</a></p>
<p>9 0.62432718 <a title="196-lsi-9" href="./acl-2011-Exploiting_Syntactico-Semantic_Structures_for_Relation_Extraction.html">126 acl-2011-Exploiting Syntactico-Semantic Structures for Relation Extraction</a></p>
<p>10 0.55333412 <a title="196-lsi-10" href="./acl-2011-Exploring_Entity_Relations_for_Named_Entity_Disambiguation.html">128 acl-2011-Exploring Entity Relations for Named Entity Disambiguation</a></p>
<p>11 0.55124521 <a title="196-lsi-11" href="./acl-2011-Coreference_for_Learning_to_Extract_Relations%3A_Yes_Virginia%2C_Coreference_Matters.html">86 acl-2011-Coreference for Learning to Extract Relations: Yes Virginia, Coreference Matters</a></p>
<p>12 0.52297604 <a title="196-lsi-12" href="./acl-2011-Knowledge-Based_Weak_Supervision_for_Information_Extraction_of_Overlapping_Relations.html">190 acl-2011-Knowledge-Based Weak Supervision for Information Extraction of Overlapping Relations</a></p>
<p>13 0.51111674 <a title="196-lsi-13" href="./acl-2011-Semi-supervised_Relation_Extraction_with_Large-scale_Word_Clustering.html">277 acl-2011-Semi-supervised Relation Extraction with Large-scale Word Clustering</a></p>
<p>14 0.47458732 <a title="196-lsi-14" href="./acl-2011-End-to-End_Relation_Extraction_Using_Distant_Supervision_from_External_Semantic_Repositories.html">114 acl-2011-End-to-End Relation Extraction Using Distant Supervision from External Semantic Repositories</a></p>
<p>15 0.47367683 <a title="196-lsi-15" href="./acl-2011-Local_and_Global_Algorithms_for_Disambiguation_to_Wikipedia.html">213 acl-2011-Local and Global Algorithms for Disambiguation to Wikipedia</a></p>
<p>16 0.46963271 <a title="196-lsi-16" href="./acl-2011-An_Error_Analysis_of_Relation_Extraction_in_Social_Media_Documents.html">40 acl-2011-An Error Analysis of Relation Extraction in Social Media Documents</a></p>
<p>17 0.44617853 <a title="196-lsi-17" href="./acl-2011-Disentangling_Chat_with_Local_Coherence_Models.html">101 acl-2011-Disentangling Chat with Local Coherence Models</a></p>
<p>18 0.42435613 <a title="196-lsi-18" href="./acl-2011-Unsupervised_Discovery_of_Domain-Specific_Knowledge_from_Text.html">320 acl-2011-Unsupervised Discovery of Domain-Specific Knowledge from Text</a></p>
<p>19 0.37324426 <a title="196-lsi-19" href="./acl-2011-Recognizing_Named_Entities_in_Tweets.html">261 acl-2011-Recognizing Named Entities in Tweets</a></p>
<p>20 0.36962157 <a title="196-lsi-20" href="./acl-2011-Which_Noun_Phrases_Denote_Which_Concepts%3F.html">334 acl-2011-Which Noun Phrases Denote Which Concepts?</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.033), (17, 0.064), (26, 0.029), (37, 0.111), (39, 0.052), (41, 0.123), (51, 0.179), (53, 0.011), (55, 0.034), (59, 0.042), (72, 0.047), (91, 0.042), (96, 0.128), (97, 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.84029132 <a title="196-lda-1" href="./acl-2011-Large-Scale_Cross-Document_Coreference_Using_Distributed_Inference_and_Hierarchical_Models.html">196 acl-2011-Large-Scale Cross-Document Coreference Using Distributed Inference and Hierarchical Models</a></p>
<p>Author: Sameer Singh ; Amarnag Subramanya ; Fernando Pereira ; Andrew McCallum</p><p>Abstract: Cross-document coreference, the task of grouping all the mentions of each entity in a document collection, arises in information extraction and automated knowledge base construction. For large collections, it is clearly impractical to consider all possible groupings of mentions into distinct entities. To solve the problem we propose two ideas: (a) a distributed inference technique that uses parallelism to enable large scale processing, and (b) a hierarchical model of coreference that represents uncertainty over multiple granularities of entities to facilitate more effective approximate inference. To evaluate these ideas, we constructed a labeled corpus of 1.5 million disambiguated mentions in Web pages by selecting link anchors referring to Wikipedia entities. We show that the combination of the hierarchical model with distributed inference quickly obtains high accuracy (with error reduction of 38%) on this large dataset, demonstrating the scalability of our approach.</p><p>2 0.83867204 <a title="196-lda-2" href="./acl-2011-Semi-Supervised_SimHash_for_Efficient_Document_Similarity_Search.html">276 acl-2011-Semi-Supervised SimHash for Efficient Document Similarity Search</a></p>
<p>Author: Qixia Jiang ; Maosong Sun</p><p>Abstract: Searching documents that are similar to a query document is an important component in modern information retrieval. Some existing hashing methods can be used for efficient document similarity search. However, unsupervised hashing methods cannot incorporate prior knowledge for better hashing. Although some supervised hashing methods can derive effective hash functions from prior knowledge, they are either computationally expensive or poorly discriminative. This paper proposes a novel (semi-)supervised hashing method named Semi-Supervised SimHash (S3H) for high-dimensional data similarity search. The basic idea of S3H is to learn the optimal feature weights from prior knowledge to relocate the data such that similar data have similar hash codes. We evaluate our method with several state-of-the-art methods on two large datasets. All the results show that our method gets the best performance. 1</p><p>3 0.83050215 <a title="196-lda-3" href="./acl-2011-Automatically_Predicting_Peer-Review_Helpfulness.html">55 acl-2011-Automatically Predicting Peer-Review Helpfulness</a></p>
<p>Author: Wenting Xiong ; Diane Litman</p><p>Abstract: Identifying peer-review helpfulness is an important task for improving the quality of feedback that students receive from their peers. As a first step towards enhancing existing peerreview systems with new functionality based on helpfulness detection, we examine whether standard product review analysis techniques also apply to our new context of peer reviews. In addition, we investigate the utility of incorporating additional specialized features tailored to peer review. Our preliminary results show that the structural features, review unigrams and meta-data combined are useful in modeling the helpfulness of both peer reviews and product reviews, while peer-review specific auxiliary features can further improve helpfulness prediction.</p><p>4 0.78384411 <a title="196-lda-4" href="./acl-2011-Gappy_Phrasal_Alignment_By_Agreement.html">141 acl-2011-Gappy Phrasal Alignment By Agreement</a></p>
<p>Author: Mohit Bansal ; Chris Quirk ; Robert Moore</p><p>Abstract: We propose a principled and efficient phraseto-phrase alignment model, useful in machine translation as well as other related natural language processing problems. In a hidden semiMarkov model, word-to-phrase and phraseto-word translations are modeled directly by the system. Agreement between two directional models encourages the selection of parsimonious phrasal alignments, avoiding the overfitting commonly encountered in unsupervised training with multi-word units. Expanding the state space to include “gappy phrases” (such as French ne ? pas) makes the alignment space more symmetric; thus, it allows agreement between discontinuous alignments. The resulting system shows substantial improvements in both alignment quality and translation quality over word-based Hidden Markov Models, while maintaining asymptotically equivalent runtime.</p><p>5 0.7721343 <a title="196-lda-5" href="./acl-2011-Can_Document_Selection_Help_Semi-supervised_Learning%3F_A_Case_Study_On_Event_Extraction.html">65 acl-2011-Can Document Selection Help Semi-supervised Learning? A Case Study On Event Extraction</a></p>
<p>Author: Shasha Liao ; Ralph Grishman</p><p>Abstract: Annotating training data for event extraction is tedious and labor-intensive. Most current event extraction tasks rely on hundreds of annotated documents, but this is often not enough. In this paper, we present a novel self-training strategy, which uses Information Retrieval (IR) to collect a cluster of related documents as the resource for bootstrapping. Also, based on the particular characteristics of this corpus, global inference is applied to provide more confident and informative data selection. We compare this approach to self-training on a normal newswire corpus and show that IR can provide a better corpus for bootstrapping and that global inference can further improve instance selection. We obtain gains of 1.7% in trigger labeling and 2.3% in role labeling through IR and an additional 1.1% in trigger labeling and 1.3% in role labeling by applying global inference. 1</p><p>6 0.76638556 <a title="196-lda-6" href="./acl-2011-Exploiting_Syntactico-Semantic_Structures_for_Relation_Extraction.html">126 acl-2011-Exploiting Syntactico-Semantic Structures for Relation Extraction</a></p>
<p>7 0.75435793 <a title="196-lda-7" href="./acl-2011-Beam-Width_Prediction_for_Efficient_Context-Free_Parsing.html">58 acl-2011-Beam-Width Prediction for Efficient Context-Free Parsing</a></p>
<p>8 0.75127226 <a title="196-lda-8" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>9 0.74943936 <a title="196-lda-9" href="./acl-2011-Joint_Identification_and_Segmentation_of_Domain-Specific_Dialogue_Acts_for_Conversational_Dialogue_Systems.html">185 acl-2011-Joint Identification and Segmentation of Domain-Specific Dialogue Acts for Conversational Dialogue Systems</a></p>
<p>10 0.74887413 <a title="196-lda-10" href="./acl-2011-Lexically-Triggered_Hidden_Markov_Models_for_Clinical_Document_Coding.html">209 acl-2011-Lexically-Triggered Hidden Markov Models for Clinical Document Coding</a></p>
<p>11 0.74677157 <a title="196-lda-11" href="./acl-2011-Translationese_and_Its_Dialects.html">311 acl-2011-Translationese and Its Dialects</a></p>
<p>12 0.74538404 <a title="196-lda-12" href="./acl-2011-An_Error_Analysis_of_Relation_Extraction_in_Social_Media_Documents.html">40 acl-2011-An Error Analysis of Relation Extraction in Social Media Documents</a></p>
<p>13 0.74311972 <a title="196-lda-13" href="./acl-2011-Evaluating_the_Impact_of_Coder_Errors_on_Active_Learning.html">119 acl-2011-Evaluating the Impact of Coder Errors on Active Learning</a></p>
<p>14 0.7427485 <a title="196-lda-14" href="./acl-2011-Unary_Constraints_for_Efficient_Context-Free_Parsing.html">316 acl-2011-Unary Constraints for Efficient Context-Free Parsing</a></p>
<p>15 0.74223572 <a title="196-lda-15" href="./acl-2011-Effects_of_Noun_Phrase_Bracketing_in_Dependency_Parsing_and_Machine_Translation.html">111 acl-2011-Effects of Noun Phrase Bracketing in Dependency Parsing and Machine Translation</a></p>
<p>16 0.74141026 <a title="196-lda-16" href="./acl-2011-Piggyback%3A_Using_Search_Engines_for_Robust_Cross-Domain_Named_Entity_Recognition.html">246 acl-2011-Piggyback: Using Search Engines for Robust Cross-Domain Named Entity Recognition</a></p>
<p>17 0.74063241 <a title="196-lda-17" href="./acl-2011-Insertion%2C_Deletion%2C_or_Substitution%3F_Normalizing_Text_Messages_without_Pre-categorization_nor_Supervision.html">172 acl-2011-Insertion, Deletion, or Substitution? Normalizing Text Messages without Pre-categorization nor Supervision</a></p>
<p>18 0.74050212 <a title="196-lda-18" href="./acl-2011-An_Efficient_Indexer_for_Large_N-Gram_Corpora.html">36 acl-2011-An Efficient Indexer for Large N-Gram Corpora</a></p>
<p>19 0.73877597 <a title="196-lda-19" href="./acl-2011-Peeling_Back_the_Layers%3A_Detecting_Event_Role_Fillers_in_Secondary_Contexts.html">244 acl-2011-Peeling Back the Layers: Detecting Event Role Fillers in Secondary Contexts</a></p>
<p>20 0.73750108 <a title="196-lda-20" href="./acl-2011-Collective_Classification_of_Congressional_Floor-Debate_Transcripts.html">73 acl-2011-Collective Classification of Congressional Floor-Debate Transcripts</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
