<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>68 acl-2011-Classifying arguments by scheme</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-68" href="#">acl2011-68</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>68 acl-2011-Classifying arguments by scheme</h1>
<br/><p>Source: <a title="acl-2011-68-pdf" href="http://aclweb.org/anthology//P/P11/P11-1099.pdf">pdf</a></p><p>Author: Vanessa Wei Feng ; Graeme Hirst</p><p>Abstract: Argumentation schemes are structures or templates for various kinds of arguments. Given the text of an argument with premises and conclusion identified, we classify it as an instance ofone offive common schemes, using features specific to each scheme. We achieve accuracies of 63–91% in one-against-others classification and 80–94% in pairwise classification (baseline = 50% in both cases).</p><p>Reference: <a title="acl-2011-68-reference" href="../acl2011_reference/acl-2011-Classifying_arguments_by_scheme_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract Argumentation schemes are structures or templates for various kinds of arguments. [sent-3, score-0.195]
</p><p>2 Given the text of an argument with premises and conclusion identified, we classify it as an instance ofone offive common schemes, using features specific to each scheme. [sent-4, score-0.515]
</p><p>3 We achieve accuracies of 63–91% in one-against-others classification and 80–94% in pairwise classification (baseline = 50% in both cases). [sent-5, score-0.092]
</p><p>4 1 Introduction We investigate a new task in the computational analysis of arguments: the classification of arguments by the argumentation schemes that they use. [sent-6, score-1.01]
</p><p>5 An argumentation scheme, informally, is a framework or  structure for a (possibly defeasible) argument; we will give a more-formal definition and examples in Section 3. [sent-7, score-0.612]
</p><p>6 Our work is motivated by the need to determine the unstated (or implicitly stated) premises that arguments written in natural language normally draw on. [sent-8, score-0.381]
</p><p>7 For instance, the argument in Example 1 consists of one explicit premise (the first sentence) and a conclusion (the second sentence): Example 1 [Premise:] The survival of the entire world is at stake. [sent-10, score-0.723]
</p><p>8 [Conclusion:] The treaties and covenants aiming for a world free of nuclear arsenals and other conventional and biological weapons of mass destruction should be adhered to scrupulously by all nations. [sent-11, score-0.301]
</p><p>9 987 Graeme Hirst Department of Computer Science University of Toronto Toronto, ON, M5S 3G4, Canada gh@cs toronto edu  . [sent-12, score-0.183]
</p><p>10 Another premise is left implicit “Adhering to those treaties and covenants is a means of realizing survival of the entire world”. [sent-14, score-0.519]
</p><p>11 Our ultimate goal is to reconstruct the enthymemes in an argument, because determining these unstated assumptions is an integral part of understanding, supporting, or attacking an entire argument. [sent-16, score-0.33]
</p><p>12 Hence reconstructing enthymemes is an important problem in argument understanding. [sent-17, score-0.433]
</p><p>13 We believe that first identifying the particular argumentation scheme that an argument is using will help to bridge the gap between stated and unstated propositions in the argument, because each argumentation scheme is a relatively fixed “template” for arguing. [sent-18, score-1.918]
</p><p>14 That is, given an argument, we first classify its argumentation scheme; then we fit the stated propositions into the corresponding template; and from this we infer the enthymemes. [sent-19, score-0.806]
</p><p>15 —  In this paper, we present an argument scheme classification system as a stage following argument detection and proposition classification. [sent-20, score-0.864]
</p><p>16 First in Section 2 and Section 3, we introduce the background  to our work, including related work in this field, the two core concepts of argumentation schemes and scheme-sets, and the Araucaria dataset. [sent-21, score-0.775]
</p><p>17 In Section 4 and Section 5 we present our classification system, including the overall framework, data preprocessing, feature selection, and the experimental setups. [sent-22, score-0.046]
</p><p>18 Cohen (1987) presented a computational model of argumentative discourse. [sent-27, score-0.085]
</p><p>19 Dick (1987; 1991a; 1991b) developed a representation for retrieval of judicial decisions by the structure of their legal argument a necessity for finding legal precedents independent of their domain. [sent-28, score-0.488]
</p><p>20 However, at that time no corpus of arguments was available, so Dick’s system was purely —  theoretical. [sent-29, score-0.189]
</p><p>21 Recently, the Araucaria project at University of Dundee has developed a software tool for manual argument analysis, with a point-and-click interface for users to reconstruct and diagram an argument (Reed and Rowe, 2004; Rowe and Reed, 2008). [sent-30, score-0.681]
</p><p>22 The project also maintains an online repository, called AraucariaDB, of marked-up naturally occurring arguments collected by annotators worldwide, which can be used as an experimental corpus for automatic argumentation analysis (for details see Section 3. [sent-31, score-0.878]
</p><p>23 Recent work on argument interpretation includes that of George, Zukerman, and Nieman (2007), who interpret constructed-example arguments (not naturally occurring text) as Bayesian networks. [sent-33, score-0.543]
</p><p>24 Other contemporary research has looked at the automatic detection of arguments in text and the classification of premises and conclusions. [sent-34, score-0.395]
</p><p>25 In their early work, they focused on automatic detection of arguments in legal texts. [sent-36, score-0.28]
</p><p>26 In their follow-up work, they trained a support vector machine to further classify each argumentative clause into a premise or a conclusion, with an F1 measure of 68. [sent-39, score-0.385]
</p><p>27 In addition, their context-free grammar for argumentation structure parsing obtained around 60% accuracy. [sent-42, score-0.612]
</p><p>28 Assuming the eventual success of their, or others’, research program on detecting and classifying the components of an argument, we seek to 988 determine how the pieces fit together as an instance of an argumentation scheme. [sent-44, score-0.708]
</p><p>29 1 Definition and examples Argumentation schemes are structures or templates for forms of arguments. [sent-46, score-0.195]
</p><p>30 The arguments need not be deductive or inductive; on the contrary, most argumentation schemes are for presumptive or defeasible arguments (Walton and Reed, 2002). [sent-47, score-1.246]
</p><p>31 For example,  argument from cause to effect is a commonly used scheme in everyday arguments. [sent-48, score-0.433]
</p><p>32 A list of such argumentation schemes is called a scheme-set. [sent-49, score-0.802]
</p><p>33 It has been shown that argumentation schemes are useful in evaluating common arguments as fallacious or not (van Eemeren and Grootendorst, 1992). [sent-50, score-0.964]
</p><p>34 In order to judge the weakness of an argument, a set of critical questions are asked according to the particular scheme that the argument is using, and the argument is regarded as valid if it matches all the requirements imposed by the scheme. [sent-51, score-0.736]
</p><p>35 Walton’s set of 65 argumentation schemes (Walton et al. [sent-52, score-0.775]
</p><p>36 , 2008) is one ofthe best-developed schemesets in argumentation theory. [sent-53, score-0.612]
</p><p>37 The five schemes defined in Table 1 are the most commonly used ones, and they are the focus of the scheme classification system that we will describe in this paper. [sent-54, score-0.295]
</p><p>38 2  Araucaria dataset  One of the challenges for automatic argumentation analysis is that suitable annotated corpora are still very rare, in spite of work by many researchers. [sent-56, score-0.634]
</p><p>39 In the work described here, we use the Araucaria database1 , an online repository of arguments, as our  experimental dataset. [sent-57, score-0.045]
</p><p>40 Araucaria includes approximately 660 manually annotated arguments from various sources, such as newspapers and court cases, and keeps growing. [sent-58, score-0.256]
</p><p>41 Although Araucaria has several limitations, such as rather small size and low agreement among it is nonetheless one of the best argumentative corpora available to date. [sent-59, score-0.085]
</p><p>42 php# araucaria argumentation corpus 2The developers of Araucaria did not report on interannotator agreement, probably because some arguments are annotated by only one commentator. [sent-65, score-1.25]
</p><p>43 Argument from example Premise: In this particular case, the individual a has property F and also property G. [sent-66, score-0.158]
</p><p>44 Conclusion: Therefore, generally, if x has property F, then it also has property G. [sent-67, score-0.158]
</p><p>45 Argument from cause to effect Majorpremise: Generally, if A occurs, then B will (might) occur. [sent-68, score-0.021]
</p><p>46 Minor premise: In this case, A occurs (might occur). [sent-69, score-0.02]
</p><p>47 Minor premise: Carrying out action A is a means to realize G. [sent-72, score-0.047]
</p><p>48 Conclusion: Therefore, I ought (practically speaking) to carry out this action A. [sent-73, score-0.054]
</p><p>49 Argument from consequences Premise: If A is (is not) brought about, good (bad) consequences will (will not) plausibly occur. [sent-74, score-0.217]
</p><p>50 Conclusion: Therefore, A should (should not) be brought about. [sent-75, score-0.043]
</p><p>51 Argument from verbal classification Individual premise: a has a particular property F. [sent-76, score-0.125]
</p><p>52 Classification premise: For all x, if x has property F, then x can be classified as having property G. [sent-77, score-0.158]
</p><p>53 Table 1: The five most frequent schemes and their definitions in Walton’s scheme-set. [sent-79, score-0.163]
</p><p>54 Arguments in Araucaria are annotated in a XMLbased format called “AML” (Argument Markup  Language). [sent-80, score-0.049]
</p><p>55 A typical argument (see Example 2) consists of several AU nodes. [sent-81, score-0.304]
</p><p>56 Each AU node is a complete argument unit, composed of a conclusion proposition followed by optional premise proposition(s) in a linked or convergent structure. [sent-82, score-0.757]
</p><p>57 Each of these propositions can be further defined as a hierarchical collection of smaller AUs. [sent-83, score-0.085]
</p><p>58 , “Argument from Consequences”) of which the current proposition is a member; enthymemes that have been made explicit 989 are annotated as “missing = yes”. [sent-86, score-0.226]
</p><p>59 Example 2 Example of argument markup from Araucaria  If the  we  free  stop  viewing  the of  free creation of art . [sent-87, score-0.532]
</p><p>60 art  ,  we will stop      The prohibition of free viewing of art is not acceptable . [sent-88, score-0.183]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('argumentation', 0.612), ('araucaria', 0.382), ('argument', 0.304), ('premise', 0.268), ('arguments', 0.189), ('toronto', 0.183), ('schemes', 0.163), ('walton', 0.122), ('premises', 0.113), ('enthymemes', 0.104), ('proposition', 0.1), ('reed', 0.092), ('scheme', 0.086), ('argumentative', 0.085), ('propositions', 0.085), ('unstated', 0.079), ('property', 0.079), ('consequences', 0.075), ('covenants', 0.069), ('defeasible', 0.069), ('mochales', 0.069), ('survival', 0.069), ('treaties', 0.069), ('legal', 0.067), ('dick', 0.061), ('rowe', 0.061), ('stated', 0.054), ('reconstruct', 0.053), ('classification', 0.046), ('repository', 0.045), ('viewing', 0.045), ('au', 0.043), ('brought', 0.043), ('markup', 0.041), ('free', 0.04), ('art', 0.036), ('conclusion', 0.035), ('canada', 0.033), ('templates', 0.032), ('classify', 0.032), ('convergent', 0.031), ('adhering', 0.031), ('dundee', 0.031), ('gh', 0.031), ('ofone', 0.031), ('precedents', 0.031), ('vanessa', 0.031), ('minor', 0.03), ('action', 0.028), ('attacking', 0.028), ('eventual', 0.028), ('nuclear', 0.028), ('template', 0.028), ('called', 0.027), ('ought', 0.026), ('worldwide', 0.026), ('world', 0.026), ('classifying', 0.026), ('stop', 0.026), ('occurring', 0.026), ('reconstructing', 0.025), ('court', 0.025), ('graeme', 0.025), ('plausibly', 0.024), ('weapons', 0.024), ('ultimate', 0.024), ('deductive', 0.024), ('moens', 0.024), ('detection', 0.024), ('naturally', 0.024), ('fit', 0.023), ('realizing', 0.023), ('interannotator', 0.023), ('biological', 0.023), ('contemporary', 0.023), ('annotated', 0.022), ('weakness', 0.022), ('aiming', 0.022), ('developers', 0.022), ('everyday', 0.022), ('hirst', 0.022), ('entire', 0.021), ('integral', 0.021), ('cause', 0.021), ('imposed', 0.02), ('newspapers', 0.02), ('diagram', 0.02), ('downstream', 0.02), ('occurs', 0.02), ('yes', 0.02), ('informally', 0.02), ('realize', 0.019), ('member', 0.019), ('practically', 0.019), ('feng', 0.019), ('inductive', 0.019), ('optional', 0.019), ('pieces', 0.019), ('necessity', 0.019), ('carrying', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999997 <a title="68-tfidf-1" href="./acl-2011-Classifying_arguments_by_scheme.html">68 acl-2011-Classifying arguments by scheme</a></p>
<p>Author: Vanessa Wei Feng ; Graeme Hirst</p><p>Abstract: Argumentation schemes are structures or templates for various kinds of arguments. Given the text of an argument with premises and conclusion identified, we classify it as an instance ofone offive common schemes, using features specific to each scheme. We achieve accuracies of 63–91% in one-against-others classification and 80–94% in pairwise classification (baseline = 50% in both cases).</p><p>2 0.15072574 <a title="68-tfidf-2" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>Author: Joel Lang ; Mirella Lapata</p><p>Abstract: In this paper we describe an unsupervised method for semantic role induction which holds promise for relieving the data acquisition bottleneck associated with supervised role labelers. We present an algorithm that iteratively splits and merges clusters representing semantic roles, thereby leading from an initial clustering to a final clustering of better quality. The method is simple, surprisingly effective, and allows to integrate linguistic knowledge transparently. By combining role induction with a rule-based component for argument identification we obtain an unsupervised end-to-end semantic role labeling system. Evaluation on the CoNLL 2008 benchmark dataset demonstrates that our method outperforms competitive unsupervised approaches by a wide margin.</p><p>3 0.10411684 <a title="68-tfidf-3" href="./acl-2011-Unsupervised_Discovery_of_Domain-Specific_Knowledge_from_Text.html">320 acl-2011-Unsupervised Discovery of Domain-Specific Knowledge from Text</a></p>
<p>Author: Dirk Hovy ; Chunliang Zhang ; Eduard Hovy ; Anselmo Penas</p><p>Abstract: Learning by Reading (LbR) aims at enabling machines to acquire knowledge from and reason about textual input. This requires knowledge about the domain structure (such as entities, classes, and actions) in order to do inference. We present a method to infer this implicit knowledge from unlabeled text. Unlike previous approaches, we use automatically extracted classes with a probability distribution over entities to allow for context-sensitive labeling. From a corpus of 1.4m sentences, we learn about 250k simple propositions about American football in the form of predicateargument structures like “quarterbacks throw passes to receivers”. Using several statistical measures, we show that our model is able to generalize and explain the data statistically significantly better than various baseline approaches. Human subjects judged up to 96.6% of the resulting propositions to be sensible. The classes and probabilistic model can be used in textual enrichment to improve the performance of LbR end-to-end systems.</p><p>4 0.10326268 <a title="68-tfidf-4" href="./acl-2011-A_Bayesian_Model_for_Unsupervised_Semantic_Parsing.html">3 acl-2011-A Bayesian Model for Unsupervised Semantic Parsing</a></p>
<p>Author: Ivan Titov ; Alexandre Klementiev</p><p>Abstract: We propose a non-parametric Bayesian model for unsupervised semantic parsing. Following Poon and Domingos (2009), we consider a semantic parsing setting where the goal is to (1) decompose the syntactic dependency tree of a sentence into fragments, (2) assign each of these fragments to a cluster of semantically equivalent syntactic structures, and (3) predict predicate-argument relations between the fragments. We use hierarchical PitmanYor processes to model statistical dependencies between meaning representations of predicates and those of their arguments, as well as the clusters of their syntactic realizations. We develop a modification of the MetropolisHastings split-merge sampler, resulting in an efficient inference algorithm for the model. The method is experimentally evaluated by us- ing the induced semantic representation for the question answering task in the biomedical domain.</p><p>5 0.078220487 <a title="68-tfidf-5" href="./acl-2011-Can_Document_Selection_Help_Semi-supervised_Learning%3F_A_Case_Study_On_Event_Extraction.html">65 acl-2011-Can Document Selection Help Semi-supervised Learning? A Case Study On Event Extraction</a></p>
<p>Author: Shasha Liao ; Ralph Grishman</p><p>Abstract: Annotating training data for event extraction is tedious and labor-intensive. Most current event extraction tasks rely on hundreds of annotated documents, but this is often not enough. In this paper, we present a novel self-training strategy, which uses Information Retrieval (IR) to collect a cluster of related documents as the resource for bootstrapping. Also, based on the particular characteristics of this corpus, global inference is applied to provide more confident and informative data selection. We compare this approach to self-training on a normal newswire corpus and show that IR can provide a better corpus for bootstrapping and that global inference can further improve instance selection. We obtain gains of 1.7% in trigger labeling and 2.3% in role labeling through IR and an additional 1.1% in trigger labeling and 1.3% in role labeling by applying global inference. 1</p><p>6 0.077919245 <a title="68-tfidf-6" href="./acl-2011-In-domain_Relation_Discovery_with_Meta-constraints_via_Posterior_Regularization.html">170 acl-2011-In-domain Relation Discovery with Meta-constraints via Posterior Regularization</a></p>
<p>7 0.060765766 <a title="68-tfidf-7" href="./acl-2011-Scaling_up_Automatic_Cross-Lingual_Semantic_Role_Annotation.html">269 acl-2011-Scaling up Automatic Cross-Lingual Semantic Role Annotation</a></p>
<p>8 0.050665859 <a title="68-tfidf-8" href="./acl-2011-Types_of_Common-Sense_Knowledge_Needed_for_Recognizing_Textual_Entailment.html">315 acl-2011-Types of Common-Sense Knowledge Needed for Recognizing Textual Entailment</a></p>
<p>9 0.045600068 <a title="68-tfidf-9" href="./acl-2011-Template-Based_Information_Extraction_without_the_Templates.html">293 acl-2011-Template-Based Information Extraction without the Templates</a></p>
<p>10 0.045591999 <a title="68-tfidf-10" href="./acl-2011-Web-Scale_Features_for_Full-Scale_Parsing.html">333 acl-2011-Web-Scale Features for Full-Scale Parsing</a></p>
<p>11 0.044727597 <a title="68-tfidf-11" href="./acl-2011-Unsupervised_Learning_of_Semantic_Relation_Composition.html">322 acl-2011-Unsupervised Learning of Semantic Relation Composition</a></p>
<p>12 0.043308668 <a title="68-tfidf-12" href="./acl-2011-Using_Cross-Entity_Inference_to_Improve_Event_Extraction.html">328 acl-2011-Using Cross-Entity Inference to Improve Event Extraction</a></p>
<p>13 0.042522468 <a title="68-tfidf-13" href="./acl-2011-Coreference_for_Learning_to_Extract_Relations%3A_Yes_Virginia%2C_Coreference_Matters.html">86 acl-2011-Coreference for Learning to Extract Relations: Yes Virginia, Coreference Matters</a></p>
<p>14 0.042348649 <a title="68-tfidf-14" href="./acl-2011-Event_Extraction_as_Dependency_Parsing.html">122 acl-2011-Event Extraction as Dependency Parsing</a></p>
<p>15 0.036918186 <a title="68-tfidf-15" href="./acl-2011-MEANT%3A_An_inexpensive%2C_high-accuracy%2C_semi-automatic_metric_for_evaluating_translation_utility_based_on_semantic_roles.html">216 acl-2011-MEANT: An inexpensive, high-accuracy, semi-automatic metric for evaluating translation utility based on semantic roles</a></p>
<p>16 0.034511823 <a title="68-tfidf-16" href="./acl-2011-Global_Learning_of_Typed_Entailment_Rules.html">144 acl-2011-Global Learning of Typed Entailment Rules</a></p>
<p>17 0.034469467 <a title="68-tfidf-17" href="./acl-2011-Contrasting_Opposing_Views_of_News_Articles_on_Contentious_Issues.html">84 acl-2011-Contrasting Opposing Views of News Articles on Contentious Issues</a></p>
<p>18 0.031852625 <a title="68-tfidf-18" href="./acl-2011-Underspecifying_and_Predicting_Voice_for_Surface_Realisation_Ranking.html">317 acl-2011-Underspecifying and Predicting Voice for Surface Realisation Ranking</a></p>
<p>19 0.030357134 <a title="68-tfidf-19" href="./acl-2011-Models_and_Training_for_Unsupervised_Preposition_Sense_Disambiguation.html">224 acl-2011-Models and Training for Unsupervised Preposition Sense Disambiguation</a></p>
<p>20 0.029879911 <a title="68-tfidf-20" href="./acl-2011-Content_Models_with_Attitude.html">82 acl-2011-Content Models with Attitude</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.079), (1, 0.028), (2, -0.062), (3, -0.015), (4, 0.036), (5, 0.047), (6, 0.01), (7, -0.0), (8, 0.004), (9, -0.02), (10, 0.016), (11, -0.053), (12, 0.025), (13, 0.043), (14, -0.047), (15, -0.035), (16, -0.068), (17, -0.056), (18, -0.041), (19, -0.015), (20, -0.001), (21, 0.063), (22, -0.071), (23, -0.068), (24, 0.022), (25, -0.023), (26, -0.058), (27, -0.064), (28, -0.044), (29, -0.017), (30, -0.01), (31, -0.02), (32, -0.02), (33, -0.018), (34, -0.007), (35, 0.037), (36, 0.026), (37, -0.037), (38, -0.048), (39, -0.044), (40, 0.001), (41, 0.048), (42, -0.084), (43, 0.1), (44, -0.015), (45, 0.034), (46, -0.02), (47, -0.019), (48, -0.044), (49, 0.115)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95477873 <a title="68-lsi-1" href="./acl-2011-Classifying_arguments_by_scheme.html">68 acl-2011-Classifying arguments by scheme</a></p>
<p>Author: Vanessa Wei Feng ; Graeme Hirst</p><p>Abstract: Argumentation schemes are structures or templates for various kinds of arguments. Given the text of an argument with premises and conclusion identified, we classify it as an instance ofone offive common schemes, using features specific to each scheme. We achieve accuracies of 63–91% in one-against-others classification and 80–94% in pairwise classification (baseline = 50% in both cases).</p><p>2 0.80999917 <a title="68-lsi-2" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>Author: Joel Lang ; Mirella Lapata</p><p>Abstract: In this paper we describe an unsupervised method for semantic role induction which holds promise for relieving the data acquisition bottleneck associated with supervised role labelers. We present an algorithm that iteratively splits and merges clusters representing semantic roles, thereby leading from an initial clustering to a final clustering of better quality. The method is simple, surprisingly effective, and allows to integrate linguistic knowledge transparently. By combining role induction with a rule-based component for argument identification we obtain an unsupervised end-to-end semantic role labeling system. Evaluation on the CoNLL 2008 benchmark dataset demonstrates that our method outperforms competitive unsupervised approaches by a wide margin.</p><p>3 0.71288395 <a title="68-lsi-3" href="./acl-2011-A_Bayesian_Model_for_Unsupervised_Semantic_Parsing.html">3 acl-2011-A Bayesian Model for Unsupervised Semantic Parsing</a></p>
<p>Author: Ivan Titov ; Alexandre Klementiev</p><p>Abstract: We propose a non-parametric Bayesian model for unsupervised semantic parsing. Following Poon and Domingos (2009), we consider a semantic parsing setting where the goal is to (1) decompose the syntactic dependency tree of a sentence into fragments, (2) assign each of these fragments to a cluster of semantically equivalent syntactic structures, and (3) predict predicate-argument relations between the fragments. We use hierarchical PitmanYor processes to model statistical dependencies between meaning representations of predicates and those of their arguments, as well as the clusters of their syntactic realizations. We develop a modification of the MetropolisHastings split-merge sampler, resulting in an efficient inference algorithm for the model. The method is experimentally evaluated by us- ing the induced semantic representation for the question answering task in the biomedical domain.</p><p>4 0.67988247 <a title="68-lsi-4" href="./acl-2011-Scaling_up_Automatic_Cross-Lingual_Semantic_Role_Annotation.html">269 acl-2011-Scaling up Automatic Cross-Lingual Semantic Role Annotation</a></p>
<p>Author: Lonneke van der Plas ; Paola Merlo ; James Henderson</p><p>Abstract: Broad-coverage semantic annotations for training statistical learners are only available for a handful of languages. Previous approaches to cross-lingual transfer of semantic annotations have addressed this problem with encouraging results on a small scale. In this paper, we scale up previous efforts by using an automatic approach to semantic annotation that does not rely on a semantic ontology for the target language. Moreover, we improve the quality of the transferred semantic annotations by using a joint syntacticsemantic parser that learns the correlations between syntax and semantics of the target language and smooths out the errors from automatic transfer. We reach a labelled F-measure for predicates and arguments of only 4% and 9% points, respectively, lower than the upper bound from manual annotations.</p><p>5 0.59465808 <a title="68-lsi-5" href="./acl-2011-Semi-Supervised_Frame-Semantic_Parsing_for_Unknown_Predicates.html">274 acl-2011-Semi-Supervised Frame-Semantic Parsing for Unknown Predicates</a></p>
<p>Author: Dipanjan Das ; Noah A. Smith</p><p>Abstract: We describe a new approach to disambiguating semantic frames evoked by lexical predicates previously unseen in a lexicon or annotated data. Our approach makes use of large amounts of unlabeled data in a graph-based semi-supervised learning framework. We construct a large graph where vertices correspond to potential predicates and use label propagation to learn possible semantic frames for new ones. The label-propagated graph is used within a frame-semantic parser and, for unknown predicates, results in over 15% absolute improvement in frame identification accuracy and over 13% absolute improvement in full frame-semantic parsing F1 score on a blind test set, over a state-of-the-art supervised baseline.</p><p>6 0.5334006 <a title="68-lsi-6" href="./acl-2011-Underspecifying_and_Predicting_Voice_for_Surface_Realisation_Ranking.html">317 acl-2011-Underspecifying and Predicting Voice for Surface Realisation Ranking</a></p>
<p>7 0.47464782 <a title="68-lsi-7" href="./acl-2011-Template-Based_Information_Extraction_without_the_Templates.html">293 acl-2011-Template-Based Information Extraction without the Templates</a></p>
<p>8 0.46027654 <a title="68-lsi-8" href="./acl-2011-Unsupervised_Learning_of_Semantic_Relation_Composition.html">322 acl-2011-Unsupervised Learning of Semantic Relation Composition</a></p>
<p>9 0.44206196 <a title="68-lsi-9" href="./acl-2011-MEANT%3A_An_inexpensive%2C_high-accuracy%2C_semi-automatic_metric_for_evaluating_translation_utility_based_on_semantic_roles.html">216 acl-2011-MEANT: An inexpensive, high-accuracy, semi-automatic metric for evaluating translation utility based on semantic roles</a></p>
<p>10 0.43953758 <a title="68-lsi-10" href="./acl-2011-Unsupervised_Discovery_of_Domain-Specific_Knowledge_from_Text.html">320 acl-2011-Unsupervised Discovery of Domain-Specific Knowledge from Text</a></p>
<p>11 0.41984755 <a title="68-lsi-11" href="./acl-2011-Contrasting_Opposing_Views_of_News_Articles_on_Contentious_Issues.html">84 acl-2011-Contrasting Opposing Views of News Articles on Contentious Issues</a></p>
<p>12 0.41853082 <a title="68-lsi-12" href="./acl-2011-Hierarchical_Reinforcement_Learning_and_Hidden_Markov_Models_for_Task-Oriented_Natural_Language_Generation.html">149 acl-2011-Hierarchical Reinforcement Learning and Hidden Markov Models for Task-Oriented Natural Language Generation</a></p>
<p>13 0.39025658 <a title="68-lsi-13" href="./acl-2011-Confidence_Driven_Unsupervised_Semantic_Parsing.html">79 acl-2011-Confidence Driven Unsupervised Semantic Parsing</a></p>
<p>14 0.38889471 <a title="68-lsi-14" href="./acl-2011-Semantic_Representation_of_Negation_Using_Focus_Detection.html">273 acl-2011-Semantic Representation of Negation Using Focus Detection</a></p>
<p>15 0.3797085 <a title="68-lsi-15" href="./acl-2011-Learning_Dependency-Based_Compositional_Semantics.html">200 acl-2011-Learning Dependency-Based Compositional Semantics</a></p>
<p>16 0.35907954 <a title="68-lsi-16" href="./acl-2011-Insights_from_Network_Structure_for_Text_Mining.html">174 acl-2011-Insights from Network Structure for Text Mining</a></p>
<p>17 0.35195518 <a title="68-lsi-17" href="./acl-2011-Unsupervised_Discovery_of_Rhyme_Schemes.html">321 acl-2011-Unsupervised Discovery of Rhyme Schemes</a></p>
<p>18 0.34626886 <a title="68-lsi-18" href="./acl-2011-Lost_in_Translation%3A_Authorship_Attribution_using_Frame_Semantics.html">214 acl-2011-Lost in Translation: Authorship Attribution using Frame Semantics</a></p>
<p>19 0.34082782 <a title="68-lsi-19" href="./acl-2011-An_Interface_for_Rapid_Natural_Language_Processing_Development_in_UIMA.html">42 acl-2011-An Interface for Rapid Natural Language Processing Development in UIMA</a></p>
<p>20 0.33813894 <a title="68-lsi-20" href="./acl-2011-Improving_Dependency_Parsing_with_Semantic_Classes.html">167 acl-2011-Improving Dependency Parsing with Semantic Classes</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.028), (17, 0.051), (26, 0.017), (31, 0.01), (37, 0.077), (39, 0.036), (41, 0.059), (48, 0.349), (55, 0.011), (59, 0.048), (72, 0.048), (91, 0.044), (96, 0.098), (98, 0.01)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.73510653 <a title="68-lda-1" href="./acl-2011-Classifying_arguments_by_scheme.html">68 acl-2011-Classifying arguments by scheme</a></p>
<p>Author: Vanessa Wei Feng ; Graeme Hirst</p><p>Abstract: Argumentation schemes are structures or templates for various kinds of arguments. Given the text of an argument with premises and conclusion identified, we classify it as an instance ofone offive common schemes, using features specific to each scheme. We achieve accuracies of 63–91% in one-against-others classification and 80–94% in pairwise classification (baseline = 50% in both cases).</p><p>2 0.49766406 <a title="68-lda-2" href="./acl-2011-Knowledge-Based_Weak_Supervision_for_Information_Extraction_of_Overlapping_Relations.html">190 acl-2011-Knowledge-Based Weak Supervision for Information Extraction of Overlapping Relations</a></p>
<p>Author: Raphael Hoffmann ; Congle Zhang ; Xiao Ling ; Luke Zettlemoyer ; Daniel S. Weld</p><p>Abstract: Information extraction (IE) holds the promise of generating a large-scale knowledge base from the Web’s natural language text. Knowledge-based weak supervision, using structured data to heuristically label a training corpus, works towards this goal by enabling the automated learning of a potentially unbounded number of relation extractors. Recently, researchers have developed multiinstance learning algorithms to combat the noisy training data that can come from heuristic labeling, but their models assume relations are disjoint — for example they cannot extract the pair Founded ( Jobs Apple ) and CEO-o f ( Jobs Apple ) . , , This paper presents a novel approach for multi-instance learning with overlapping relations that combines a sentence-level extrac- , tion model with a simple, corpus-level component for aggregating the individual facts. We apply our model to learn extractors for NY Times text using weak supervision from Freebase. Experiments show that the approach runs quickly and yields surprising gains in accuracy, at both the aggregate and sentence level.</p><p>3 0.42883742 <a title="68-lda-3" href="./acl-2011-Exploiting_Syntactico-Semantic_Structures_for_Relation_Extraction.html">126 acl-2011-Exploiting Syntactico-Semantic Structures for Relation Extraction</a></p>
<p>Author: Yee Seng Chan ; Dan Roth</p><p>Abstract: In this paper, we observe that there exists a second dimension to the relation extraction (RE) problem that is orthogonal to the relation type dimension. We show that most of these second dimensional structures are relatively constrained and not difficult to identify. We propose a novel algorithmic approach to RE that starts by first identifying these structures and then, within these, identifying the semantic type of the relation. In the real RE problem where relation arguments need to be identified, exploiting these structures also allows reducing pipelined propagated errors. We show that this RE framework provides significant improvement in RE performance.</p><p>4 0.42583382 <a title="68-lda-4" href="./acl-2011-Can_Document_Selection_Help_Semi-supervised_Learning%3F_A_Case_Study_On_Event_Extraction.html">65 acl-2011-Can Document Selection Help Semi-supervised Learning? A Case Study On Event Extraction</a></p>
<p>Author: Shasha Liao ; Ralph Grishman</p><p>Abstract: Annotating training data for event extraction is tedious and labor-intensive. Most current event extraction tasks rely on hundreds of annotated documents, but this is often not enough. In this paper, we present a novel self-training strategy, which uses Information Retrieval (IR) to collect a cluster of related documents as the resource for bootstrapping. Also, based on the particular characteristics of this corpus, global inference is applied to provide more confident and informative data selection. We compare this approach to self-training on a normal newswire corpus and show that IR can provide a better corpus for bootstrapping and that global inference can further improve instance selection. We obtain gains of 1.7% in trigger labeling and 2.3% in role labeling through IR and an additional 1.1% in trigger labeling and 1.3% in role labeling by applying global inference. 1</p><p>5 0.42427799 <a title="68-lda-5" href="./acl-2011-Unsupervised_Semantic_Role_Induction_via_Split-Merge_Clustering.html">324 acl-2011-Unsupervised Semantic Role Induction via Split-Merge Clustering</a></p>
<p>Author: Joel Lang ; Mirella Lapata</p><p>Abstract: In this paper we describe an unsupervised method for semantic role induction which holds promise for relieving the data acquisition bottleneck associated with supervised role labelers. We present an algorithm that iteratively splits and merges clusters representing semantic roles, thereby leading from an initial clustering to a final clustering of better quality. The method is simple, surprisingly effective, and allows to integrate linguistic knowledge transparently. By combining role induction with a rule-based component for argument identification we obtain an unsupervised end-to-end semantic role labeling system. Evaluation on the CoNLL 2008 benchmark dataset demonstrates that our method outperforms competitive unsupervised approaches by a wide margin.</p><p>6 0.4227823 <a title="68-lda-6" href="./acl-2011-Algorithm_Selection_and_Model_Adaptation_for_ESL_Correction_Tasks.html">32 acl-2011-Algorithm Selection and Model Adaptation for ESL Correction Tasks</a></p>
<p>7 0.42130795 <a title="68-lda-7" href="./acl-2011-Coreference_for_Learning_to_Extract_Relations%3A_Yes_Virginia%2C_Coreference_Matters.html">86 acl-2011-Coreference for Learning to Extract Relations: Yes Virginia, Coreference Matters</a></p>
<p>8 0.41832337 <a title="68-lda-8" href="./acl-2011-An_Error_Analysis_of_Relation_Extraction_in_Social_Media_Documents.html">40 acl-2011-An Error Analysis of Relation Extraction in Social Media Documents</a></p>
<p>9 0.41772583 <a title="68-lda-9" href="./acl-2011-EdIt%3A_A_Broad-Coverage_Grammar_Checker_Using_Pattern_Grammar.html">108 acl-2011-EdIt: A Broad-Coverage Grammar Checker Using Pattern Grammar</a></p>
<p>10 0.41764367 <a title="68-lda-10" href="./acl-2011-Evaluating_the_Impact_of_Coder_Errors_on_Active_Learning.html">119 acl-2011-Evaluating the Impact of Coder Errors on Active Learning</a></p>
<p>11 0.41721612 <a title="68-lda-11" href="./acl-2011-Piggyback%3A_Using_Search_Engines_for_Robust_Cross-Domain_Named_Entity_Recognition.html">246 acl-2011-Piggyback: Using Search Engines for Robust Cross-Domain Named Entity Recognition</a></p>
<p>12 0.41707146 <a title="68-lda-12" href="./acl-2011-In-domain_Relation_Discovery_with_Meta-constraints_via_Posterior_Regularization.html">170 acl-2011-In-domain Relation Discovery with Meta-constraints via Posterior Regularization</a></p>
<p>13 0.41666561 <a title="68-lda-13" href="./acl-2011-Translationese_and_Its_Dialects.html">311 acl-2011-Translationese and Its Dialects</a></p>
<p>14 0.41626352 <a title="68-lda-14" href="./acl-2011-Lexically-Triggered_Hidden_Markov_Models_for_Clinical_Document_Coding.html">209 acl-2011-Lexically-Triggered Hidden Markov Models for Clinical Document Coding</a></p>
<p>15 0.41582942 <a title="68-lda-15" href="./acl-2011-Beam-Width_Prediction_for_Efficient_Context-Free_Parsing.html">58 acl-2011-Beam-Width Prediction for Efficient Context-Free Parsing</a></p>
<p>16 0.41446593 <a title="68-lda-16" href="./acl-2011-Large-Scale_Cross-Document_Coreference_Using_Distributed_Inference_and_Hierarchical_Models.html">196 acl-2011-Large-Scale Cross-Document Coreference Using Distributed Inference and Hierarchical Models</a></p>
<p>17 0.41434532 <a title="68-lda-17" href="./acl-2011-A_Bayesian_Model_for_Unsupervised_Semantic_Parsing.html">3 acl-2011-A Bayesian Model for Unsupervised Semantic Parsing</a></p>
<p>18 0.41433048 <a title="68-lda-18" href="./acl-2011-Semi-supervised_Relation_Extraction_with_Large-scale_Word_Clustering.html">277 acl-2011-Semi-supervised Relation Extraction with Large-scale Word Clustering</a></p>
<p>19 0.41402501 <a title="68-lda-19" href="./acl-2011-Using_Bilingual_Parallel_Corpora_for_Cross-Lingual_Textual_Entailment.html">327 acl-2011-Using Bilingual Parallel Corpora for Cross-Lingual Textual Entailment</a></p>
<p>20 0.41383967 <a title="68-lda-20" href="./acl-2011-A_Comparison_of_Loopy_Belief_Propagation_and_Dual_Decomposition_for_Integrated_CCG_Supertagging_and_Parsing.html">5 acl-2011-A Comparison of Loopy Belief Propagation and Dual Decomposition for Integrated CCG Supertagging and Parsing</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
