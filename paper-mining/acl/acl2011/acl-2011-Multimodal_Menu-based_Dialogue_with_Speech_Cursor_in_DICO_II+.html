<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>227 acl-2011-Multimodal Menu-based Dialogue with Speech Cursor in DICO II+</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-227" href="#">acl2011-227</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>227 acl-2011-Multimodal Menu-based Dialogue with Speech Cursor in DICO II+</h1>
<br/><p>Source: <a title="acl-2011-227-pdf" href="http://aclweb.org/anthology//P/P11/P11-4016.pdf">pdf</a></p><p>Author: Staffan Larsson ; Alexander Berman ; Jessica Villing</p><p>Abstract: Alexander Berman Jessica Villing Talkamatic AB University of Gothenburg Sweden Sweden alex@ t alkamat i . se c jessi ca@ l ing .gu . s e 2 In-vehicle dialogue systems This paper describes Dico II+, an in-vehicle dialogue system demonstrating a novel combination of flexible multimodal menu-based dialogueand a “speech cursor” which enables menu navigation as well as browsing long list using haptic input and spoken output.</p><p>Reference: <a title="acl-2011-227-reference" href="../acl2011_reference/acl-2011-Multimodal_Menu-based_Dialogue_with_Speech_Cursor_in_DICO_II%2B_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 s e 2 In-vehicle dialogue systems This paper describes Dico II+, an in-vehicle dialogue system demonstrating a novel combination of flexible multimodal menu-based dialogueand a “speech cursor” which enables menu navigation as well as browsing long list using haptic input and spoken output. [sent-6, score-1.57]
</p><p>2 1 Introduction Dico is a multimodal in-car dialogue system application, originally developed in the DICO (with capital letters) project by Volvo Technology AB and the University of Gothenburg. [sent-7, score-0.537]
</p><p>3 Dico is built on top of the GoDiS dialogue system platform (Larsson, 2002), which in turn is implemented using TrindiKit (Traum and Larsson, 2003). [sent-8, score-0.441]
</p><p>4 The main goal of the original Dico application (Olsson and Villing, 2005), (Villing and Larsson, 2006) was to develop an interface that is less distracting for the driver, and thus both safer and easier to use than existing interfaces. [sent-9, score-0.037]
</p><p>5 Since then, the Dico demonstrator has been further developed. [sent-11, score-0.062]
</p><p>6 In this paper, we describe the Dico II+ demonstrator which introduces a novel combination of flexible Multimodal Menu-Based Dialogue and a Speech Cursor which together enable flexible multimodal interaction without the need for looking at the screen. [sent-12, score-0.532]
</p><p>7 In the following, we will first argue for the usefulness of in-vehicle dialogue systems. [sent-13, score-0.418]
</p><p>8 We will  then briefly present the GoDiS platform which Dico II+ is based on, as well as some aspects of flexible dialogue enabled by the GoDiS dialogue manager. [sent-14, score-0.95]
</p><p>9 92 Voice interaction is a very natural means of communication for humans, and enabling spoken interaction with technologies may thus make it easier and less cognitively demanding for people to interact with machines. [sent-15, score-0.405]
</p><p>10 However, this requires that the spoken interaction is similar to ordinary spoken human-human dialogue. [sent-16, score-0.269]
</p><p>11 A problem with available in-vehicle voice control technologies is that they are not flexible enough in terms of the interaction strategies and modalities offered to the user. [sent-17, score-0.36]
</p><p>12 3  GoDiS features in Dico  GoDiS (Larsson, 2002) is an experimental dialogue system implementing a theory of IssueBased Dialogue Management based on Ginzburg’s concept of Questions Under Discussion (QUD). [sent-18, score-0.418]
</p><p>13 GoDiS is implemented using the TrindiKit, a toolkit for implementing dialogue move engines and dia-  logue systems based on the Information State approach (Traum and Larsson, 2003). [sent-19, score-0.418]
</p><p>14 GoDiS has been adapted to several different dialogue types, domains, and languages, including menu-based multimodal dialogue when acting as an interface to an mp3 player (Hjelm et al. [sent-20, score-0.992]
</p><p>15 The GoDiS dialogue manager allows the user to interact more flexibly and naturally with menubased interfaces to devices. [sent-22, score-0.643]
</p><p>16 General dialogue management issues such as accommodation, task switching and grounding are handled by the applicationindependent dialogue manager. [sent-23, score-0.891]
</p><p>17 Re-using these technologies in new applications enables rapid prototyping of advanced dialogue applications. [sent-24, score-0.464]
</p><p>18 1 Accommodation The applications in Dico II+ are based on existing menu interfaces, using a method for converting menus into dialogue plans (see below). [sent-28, score-0.584]
</p><p>19 While it is possible for the novice user to let the system take initiative and guide the user through the menus stepby-step, expert users might prefer to use accommodation strategies enabling the user to skip through  the menus and getting right to the point. [sent-29, score-0.688]
</p><p>20 2  Multiple simultaneous tasks and task switching GoDiS enables arbitrarily nested subdialogues. [sent-45, score-0.072]
</p><p>21 It is possible to start one dialogue to perform a task, and then start a subdialogue before the first task is completed. [sent-46, score-0.418]
</p><p>22 This gives the user freedom to switch task at any time: Ex. [sent-48, score-0.158]
</p><p>23 Changing Lisa’s home number to oh three one two three four five six seven. [sent-62, score-0.118]
</p><p>24 As an example, the single user utterance “Lisa” may result in positive feedback on the semantic level but negative on the pragmatic, resulting in a system utterance consisting of two feedback moves and a clarification question: “Lisa. [sent-65, score-0.297]
</p><p>25 Do you want to make a call, change an entry in the phonebook, or delete an entry from the phonebook? [sent-67, score-0.045]
</p><p>26 ” 4  Multimodal menu-based dialogue  Dico II+ implemented a concept of Multimodal Menu-based Dialogue (MMD). [sent-68, score-0.418]
</p><p>27 A common argument for using spoken interaction in a car context is that the driver should be able to use a system without looking at a screen. [sent-71, score-0.318]
</p><p>28 However,  there are many situations where current technology requires the user to look at a screen at some point in the interaction. [sent-72, score-0.259]
</p><p>29 The idea behind MMD is that the user should be able to switch between and combine modalities freely across and within utterances. [sent-73, score-0.234]
</p><p>30 This makes it possible to use the system using speech only, using traditional GUI interaction only, or using a combination of the two. [sent-74, score-0.188]
</p><p>31 MMD enables integrated multimodality for user input, meaning that a single contribution can use several input modalities, e. [sent-75, score-0.232]
</p><p>32 “Call this contact [click]” where the [click] symbolises haptic input (e. [sent-77, score-0.191]
</p><p>33 a mouse click) which in this case selects a specific contact. [sent-79, score-0.026]
</p><p>34 , output is generally rendered both as speech and as GUI output. [sent-82, score-0.043]
</p><p>35 To use speech only, the user can merely ignore the graphical output and not use the haptic input device. [sent-83, score-0.361]
</p><p>36 To enable interaction using GUI only, speech input and output can be turned on or off using a button which toggles between “speech on” and “speech off” mode. [sent-84, score-0.188]
</p><p>37 The GUI used in Dico II+ is a generic graphical interface for the GoDiS system, developed by Talkamatic AB with graphical adaptations for Dico. [sent-85, score-0.079]
</p><p>38 It represents GoDiS dialogue moves graphically as menus using a refined version of the conversion schema presented in (Larsson et al. [sent-86, score-0.538]
</p><p>39 For example, alternative questions are represented as multiple choice menus, and wh-questions are represented as scrollable lists. [sent-88, score-0.036]
</p><p>40 Conversely, haptic user input from the GUI is interpreted as dialogue moves. [sent-89, score-0.715]
</p><p>41 Selecting an action in a multiple-choice menu corresponds to making a request move, and selecting an item in a scrollable list corresponds to an answer move. [sent-90, score-0.154]
</p><p>42 In combination with the flexible dialogue capabilities of the GoDiS dialogue manager, and the concept ofMMD, we believe that a Speech Cursor provides a powerful and userfriendly way of interacting with menu-based interfaces in cognitively demanding environments such  as the in-vehicle environment. [sent-92, score-1.048]
</p><p>43 1 The problem A common argument for using spoken interaction in a car context is that the driver should be able to use a system without looking at a screen. [sent-94, score-0.318]
</p><p>44 However, there are many situations where current technology requires the user to look at a screen at some point in the interaction. [sent-95, score-0.259]
</p><p>45 This was true also for Dico II in the case of browsing lists; for example, to find out which contacts were listed in the phonebook, the user would at some point have to look at the screen. [sent-96, score-0.247]
</p><p>46 Imagine that the user wants to select a song from 94 a song database, and that the user has made restrictions filtering out 30 songs from the database. [sent-97, score-0.547]
</p><p>47 The dialogue system asks the user which of the songs she wants to hear displaying them in a list on the screen. [sent-98, score-0.771]
</p><p>48 The user must now either look at the screen and use a scroll-wheel or similar to select a song, or look at the screen to see which songs are available, and then speak the proper song title. [sent-99, score-0.572]
</p><p>49 This means that part of the point of using spoken interaction in the car is lost. [sent-100, score-0.239]
</p><p>50 The example discusses car use, but is  applicable any time when the user cannot or does not want to look at a screen, for instance when using a cellphone walking in a city, or when using a web application on a portable device. [sent-101, score-0.26]
</p><p>51 While this strategy in principle solves the problem, it is rather time-consuming compared to browsing the list using a screen and a haptic input device (such as a scroll-wheel); this may decrease the perceived usability of the voice interface in comparison with traditional GUI-based interaction. [sent-103, score-0.508]
</p><p>52 Some existing voice interaction systems use a technology to establish understanding which consists of displaying the top N best recognition hypotheses to the user, each one associated with a number, together with a verbal request to the user to say the number corresponding to the desired result. [sent-104, score-0.38]
</p><p>53 This situation, however, requires the user to look at  a screen, and is arguably quite unnatural. [sent-105, score-0.172]
</p><p>54 2 The solution: Speech Cursor Dico II+ requires a haptic menu navigation device, such as a mouse (trackball, touch pad, TrackPointTM) with buttons, pointers and drivers, keyboard with arrow keys, or jog dial/shuttle wheel. [sent-107, score-0.291]
</p><p>55 A typical in-vehicle menu navigation device consists of three or four buttons (UP, DOWN, OK and possible BACK). [sent-108, score-0.193]
</p><p>56 Every time a new item gets focus, the system reads out a voice icon - a spoken representation of the item. [sent-109, score-0.182]
</p><p>57 Every time a new element gets focus, all any ongoing voice output is interrupted by the voice icon for the element in focus. [sent-111, score-0.187]
</p><p>58 6  Combining flexible dialogue and Speech Cursor  Combining flexible dialogue processing with the Speech Cursor concept1 enables interaction where the user may freely choose between using domain-  level spoken utterances (requests, confirmations, questions, answers etc. [sent-112, score-1.419]
</p><p>59 This is an improvement over existing technology in that it offers a greater variety of interaction styles which can be freely chosen and combined by the user, as well as offering flexible dialogue interaction. [sent-114, score-0.661]
</p><p>60 Specifically, it provides flexible spoken dialogue interaction in combination with user-friendly browsing of long lists without the need for looking at the screen. [sent-115, score-0.826]
</p><p>61 4: U: “I want to listen to Madonna”(This utterance uses accommodation to allow the user to supply unrequested information) S: “There are 3 songs by Madonna. [sent-117, score-0.391]
</p><p>62 ” (Showing list of all songs by Madonna: ’Like a Prayer’, ’La Isla Bonita ’, ’Music ’, . [sent-119, score-0.124]
</p><p>63 5: U: “I want to add an ABBA song” S: “What album? [sent-125, score-0.045]
</p><p>64 DJ GoDiS: Multimodal menu-based dialogue in an asychronous isu system. [sent-138, score-0.418]
</p><p>65 In Claire Gardent and Bertrand Gaiffe, editors, Proceedings of the ninth workshop on the semantics and pragmatics of dialogue. [sent-139, score-0.034]
</p><p>66 Fernandez, editors, Proceedings of the 10th workshop on the semantics and pragmatics of dialogue. [sent-171, score-0.034]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('dico', 0.496), ('dialogue', 0.418), ('godis', 0.351), ('larsson', 0.227), ('cursor', 0.164), ('haptic', 0.145), ('staffan', 0.145), ('user', 0.13), ('interaction', 0.123), ('multimodal', 0.119), ('mmd', 0.103), ('prayer', 0.103), ('songs', 0.103), ('talkamatic', 0.103), ('villing', 0.103), ('home', 0.096), ('flexible', 0.091), ('menus', 0.091), ('screen', 0.087), ('lisa', 0.085), ('gui', 0.084), ('phonebook', 0.083), ('song', 0.081), ('voice', 0.078), ('browsing', 0.075), ('menu', 0.075), ('spoken', 0.073), ('accommodation', 0.073), ('ii', 0.071), ('jessica', 0.063), ('bonita', 0.062), ('demonstrator', 0.062), ('hjelm', 0.062), ('isla', 0.062), ('manager', 0.06), ('album', 0.055), ('driver', 0.055), ('ok', 0.053), ('hear', 0.05), ('traum', 0.047), ('modalities', 0.047), ('enables', 0.046), ('want', 0.045), ('navigation', 0.045), ('ab', 0.044), ('speech', 0.043), ('car', 0.043), ('device', 0.043), ('look', 0.042), ('arrival', 0.041), ('mamma', 0.041), ('mia', 0.041), ('olsson', 0.041), ('trindikit', 0.041), ('volvo', 0.041), ('utterance', 0.04), ('money', 0.04), ('click', 0.037), ('interface', 0.037), ('music', 0.036), ('cognitively', 0.036), ('understands', 0.036), ('madonna', 0.036), ('scrollable', 0.036), ('gothenburg', 0.036), ('interfaces', 0.035), ('pragmatics', 0.034), ('multimodality', 0.034), ('icon', 0.031), ('highlighted', 0.03), ('buttons', 0.03), ('feedback', 0.029), ('freely', 0.029), ('moves', 0.029), ('grounding', 0.029), ('switch', 0.028), ('demanding', 0.028), ('calling', 0.028), ('displaying', 0.027), ('mouse', 0.026), ('switching', 0.026), ('sweden', 0.025), ('editors', 0.025), ('anna', 0.024), ('contact', 0.024), ('looking', 0.024), ('pragmatic', 0.023), ('phone', 0.023), ('platform', 0.023), ('la', 0.023), ('call', 0.023), ('enabling', 0.022), ('wants', 0.022), ('request', 0.022), ('combination', 0.022), ('oh', 0.022), ('input', 0.022), ('list', 0.021), ('strategies', 0.021), ('graphical', 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="227-tfidf-1" href="./acl-2011-Multimodal_Menu-based_Dialogue_with_Speech_Cursor_in_DICO_II%2B.html">227 acl-2011-Multimodal Menu-based Dialogue with Speech Cursor in DICO II+</a></p>
<p>Author: Staffan Larsson ; Alexander Berman ; Jessica Villing</p><p>Abstract: Alexander Berman Jessica Villing Talkamatic AB University of Gothenburg Sweden Sweden alex@ t alkamat i . se c jessi ca@ l ing .gu . s e 2 In-vehicle dialogue systems This paper describes Dico II+, an in-vehicle dialogue system demonstrating a novel combination of flexible multimodal menu-based dialogueand a “speech cursor” which enables menu navigation as well as browsing long list using haptic input and spoken output.</p><p>2 0.3342804 <a title="227-tfidf-2" href="./acl-2011-Joint_Identification_and_Segmentation_of_Domain-Specific_Dialogue_Acts_for_Conversational_Dialogue_Systems.html">185 acl-2011-Joint Identification and Segmentation of Domain-Specific Dialogue Acts for Conversational Dialogue Systems</a></p>
<p>Author: Fabrizio Morbini ; Kenji Sagae</p><p>Abstract: Individual utterances often serve multiple communicative purposes in dialogue. We present a data-driven approach for identification of multiple dialogue acts in single utterances in the context of dialogue systems with limited training data. Our approach results in significantly increased understanding of user intent, compared to two strong baselines.</p><p>3 0.26142836 <a title="227-tfidf-3" href="./acl-2011-Data-oriented_Monologue-to-Dialogue_Generation.html">91 acl-2011-Data-oriented Monologue-to-Dialogue Generation</a></p>
<p>Author: Paul Piwek ; Svetlana Stoyanchev</p><p>Abstract: This short paper introduces an implemented and evaluated monolingual Text-to-Text generation system. The system takes monologue and transforms it to two-participant dialogue. After briefly motivating the task of monologue-to-dialogue generation, we describe the system and present an evaluation in terms of fluency and accuracy.</p><p>4 0.26045957 <a title="227-tfidf-4" href="./acl-2011-An_Affect-Enriched_Dialogue_Act_Classification_Model_for_Task-Oriented_Dialogue.html">33 acl-2011-An Affect-Enriched Dialogue Act Classification Model for Task-Oriented Dialogue</a></p>
<p>Author: Kristy Boyer ; Joseph Grafsgaard ; Eun Young Ha ; Robert Phillips ; James Lester</p><p>Abstract: Dialogue act classification is a central challenge for dialogue systems. Although the importance of emotion in human dialogue is widely recognized, most dialogue act classification models make limited or no use of affective channels in dialogue act classification. This paper presents a novel affect-enriched dialogue act classifier for task-oriented dialogue that models facial expressions of users, in particular, facial expressions related to confusion. The findings indicate that the affectenriched classifiers perform significantly better for distinguishing user requests for feedback and grounding dialogue acts within textual dialogue. The results point to ways in which dialogue systems can effectively leverage affective channels to improve dialogue act classification. 1</p><p>5 0.20721497 <a title="227-tfidf-5" href="./acl-2011-Semantic_Information_and_Derivation_Rules_for_Robust_Dialogue_Act_Detection_in_a_Spoken_Dialogue_System.html">272 acl-2011-Semantic Information and Derivation Rules for Robust Dialogue Act Detection in a Spoken Dialogue System</a></p>
<p>Author: Wei-Bin Liang ; Chung-Hsien Wu ; Chia-Ping Chen</p><p>Abstract: In this study, a novel approach to robust dialogue act detection for error-prone speech recognition in a spoken dialogue system is proposed. First, partial sentence trees are proposed to represent a speech recognition output sentence. Semantic information and the derivation rules of the partial sentence trees are extracted and used to model the relationship between the dialogue acts and the derivation rules. The constructed model is then used to generate a semantic score for dialogue act detection given an input speech utterance. The proposed approach is implemented and evaluated in a Mandarin spoken dialogue system for tour-guiding service. Combined with scores derived from the ASR recognition probability and the dialogue history, the proposed approach achieves 84.3% detection accuracy, an absolute improvement of 34.7% over the baseline of the semantic slot-based method with 49.6% detection accuracy.</p><p>6 0.11600158 <a title="227-tfidf-6" href="./acl-2011-Recognizing_Authority_in_Dialogue_with_an_Integer_Linear_Programming_Constrained_Model.html">260 acl-2011-Recognizing Authority in Dialogue with an Integer Linear Programming Constrained Model</a></p>
<p>7 0.10713279 <a title="227-tfidf-7" href="./acl-2011-Turn-Taking_Cues_in_a_Human_Tutoring_Corpus.html">312 acl-2011-Turn-Taking Cues in a Human Tutoring Corpus</a></p>
<p>8 0.086329103 <a title="227-tfidf-8" href="./acl-2011-A_Pilot_Study_of_Opinion_Summarization_in_Conversations.html">21 acl-2011-A Pilot Study of Opinion Summarization in Conversations</a></p>
<p>9 0.083838798 <a title="227-tfidf-9" href="./acl-2011-Entrainment_in_Speech_Preceding_Backchannels..html">118 acl-2011-Entrainment in Speech Preceding Backchannels.</a></p>
<p>10 0.073837593 <a title="227-tfidf-10" href="./acl-2011-Multi-Modal_Annotation_of_Quest_Games_in_Second_Life.html">226 acl-2011-Multi-Modal Annotation of Quest Games in Second Life</a></p>
<p>11 0.072931096 <a title="227-tfidf-11" href="./acl-2011-Hierarchical_Reinforcement_Learning_and_Hidden_Markov_Models_for_Task-Oriented_Natural_Language_Generation.html">149 acl-2011-Hierarchical Reinforcement Learning and Hidden Markov Models for Task-Oriented Natural Language Generation</a></p>
<p>12 0.068729594 <a title="227-tfidf-12" href="./acl-2011-Prototyping_virtual_instructors_from_human-human_corpora.html">252 acl-2011-Prototyping virtual instructors from human-human corpora</a></p>
<p>13 0.057554942 <a title="227-tfidf-13" href="./acl-2011-Question_Detection_in_Spoken_Conversations_Using_Textual_Conversations.html">257 acl-2011-Question Detection in Spoken Conversations Using Textual Conversations</a></p>
<p>14 0.048886869 <a title="227-tfidf-14" href="./acl-2011-Improving_On-line_Handwritten_Recognition_using_Translation_Models_in_Multimodal_Interactive_Machine_Translation.html">168 acl-2011-Improving On-line Handwritten Recognition using Translation Models in Multimodal Interactive Machine Translation</a></p>
<p>15 0.047370553 <a title="227-tfidf-15" href="./acl-2011-Towards_a_Framework_for_Abstractive_Summarization_of_Multimodal_Documents.html">308 acl-2011-Towards a Framework for Abstractive Summarization of Multimodal Documents</a></p>
<p>16 0.046287894 <a title="227-tfidf-16" href="./acl-2011-A_Speech-based_Just-in-Time_Retrieval_System_using_Semantic_Search.html">26 acl-2011-A Speech-based Just-in-Time Retrieval System using Semantic Search</a></p>
<p>17 0.044911273 <a title="227-tfidf-17" href="./acl-2011-A_Mobile_Touchable_Application_for_Online_Topic_Graph_Extraction_and_Exploration_of_Web_Content.html">19 acl-2011-A Mobile Touchable Application for Online Topic Graph Extraction and Exploration of Web Content</a></p>
<p>18 0.044123095 <a title="227-tfidf-18" href="./acl-2011-Interactive_Group_Suggesting_for_Twitter.html">177 acl-2011-Interactive Group Suggesting for Twitter</a></p>
<p>19 0.04189986 <a title="227-tfidf-19" href="./acl-2011-Towards_Style_Transformation_from_Written-Style_to_Audio-Style.html">306 acl-2011-Towards Style Transformation from Written-Style to Audio-Style</a></p>
<p>20 0.039908964 <a title="227-tfidf-20" href="./acl-2011-IMASS%3A_An_Intelligent_Microblog_Analysis_and_Summarization_System.html">156 acl-2011-IMASS: An Intelligent Microblog Analysis and Summarization System</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.077), (1, 0.05), (2, -0.029), (3, 0.029), (4, -0.309), (5, 0.299), (6, -0.079), (7, -0.049), (8, 0.004), (9, 0.005), (10, 0.11), (11, 0.023), (12, 0.099), (13, -0.057), (14, 0.053), (15, -0.013), (16, 0.047), (17, -0.006), (18, -0.017), (19, 0.044), (20, -0.058), (21, 0.031), (22, 0.094), (23, -0.133), (24, -0.005), (25, -0.062), (26, -0.078), (27, 0.013), (28, 0.034), (29, -0.028), (30, 0.034), (31, 0.026), (32, -0.073), (33, -0.045), (34, 0.001), (35, -0.056), (36, -0.033), (37, -0.008), (38, 0.023), (39, 0.041), (40, 0.02), (41, -0.006), (42, 0.039), (43, -0.002), (44, 0.027), (45, 0.004), (46, 0.009), (47, 0.014), (48, 0.003), (49, -0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98090672 <a title="227-lsi-1" href="./acl-2011-Multimodal_Menu-based_Dialogue_with_Speech_Cursor_in_DICO_II%2B.html">227 acl-2011-Multimodal Menu-based Dialogue with Speech Cursor in DICO II+</a></p>
<p>Author: Staffan Larsson ; Alexander Berman ; Jessica Villing</p><p>Abstract: Alexander Berman Jessica Villing Talkamatic AB University of Gothenburg Sweden Sweden alex@ t alkamat i . se c jessi ca@ l ing .gu . s e 2 In-vehicle dialogue systems This paper describes Dico II+, an in-vehicle dialogue system demonstrating a novel combination of flexible multimodal menu-based dialogueand a “speech cursor” which enables menu navigation as well as browsing long list using haptic input and spoken output.</p><p>2 0.9360649 <a title="227-lsi-2" href="./acl-2011-Joint_Identification_and_Segmentation_of_Domain-Specific_Dialogue_Acts_for_Conversational_Dialogue_Systems.html">185 acl-2011-Joint Identification and Segmentation of Domain-Specific Dialogue Acts for Conversational Dialogue Systems</a></p>
<p>Author: Fabrizio Morbini ; Kenji Sagae</p><p>Abstract: Individual utterances often serve multiple communicative purposes in dialogue. We present a data-driven approach for identification of multiple dialogue acts in single utterances in the context of dialogue systems with limited training data. Our approach results in significantly increased understanding of user intent, compared to two strong baselines.</p><p>3 0.92672187 <a title="227-lsi-3" href="./acl-2011-Data-oriented_Monologue-to-Dialogue_Generation.html">91 acl-2011-Data-oriented Monologue-to-Dialogue Generation</a></p>
<p>Author: Paul Piwek ; Svetlana Stoyanchev</p><p>Abstract: This short paper introduces an implemented and evaluated monolingual Text-to-Text generation system. The system takes monologue and transforms it to two-participant dialogue. After briefly motivating the task of monologue-to-dialogue generation, we describe the system and present an evaluation in terms of fluency and accuracy.</p><p>4 0.92357457 <a title="227-lsi-4" href="./acl-2011-An_Affect-Enriched_Dialogue_Act_Classification_Model_for_Task-Oriented_Dialogue.html">33 acl-2011-An Affect-Enriched Dialogue Act Classification Model for Task-Oriented Dialogue</a></p>
<p>Author: Kristy Boyer ; Joseph Grafsgaard ; Eun Young Ha ; Robert Phillips ; James Lester</p><p>Abstract: Dialogue act classification is a central challenge for dialogue systems. Although the importance of emotion in human dialogue is widely recognized, most dialogue act classification models make limited or no use of affective channels in dialogue act classification. This paper presents a novel affect-enriched dialogue act classifier for task-oriented dialogue that models facial expressions of users, in particular, facial expressions related to confusion. The findings indicate that the affectenriched classifiers perform significantly better for distinguishing user requests for feedback and grounding dialogue acts within textual dialogue. The results point to ways in which dialogue systems can effectively leverage affective channels to improve dialogue act classification. 1</p><p>5 0.78835386 <a title="227-lsi-5" href="./acl-2011-Semantic_Information_and_Derivation_Rules_for_Robust_Dialogue_Act_Detection_in_a_Spoken_Dialogue_System.html">272 acl-2011-Semantic Information and Derivation Rules for Robust Dialogue Act Detection in a Spoken Dialogue System</a></p>
<p>Author: Wei-Bin Liang ; Chung-Hsien Wu ; Chia-Ping Chen</p><p>Abstract: In this study, a novel approach to robust dialogue act detection for error-prone speech recognition in a spoken dialogue system is proposed. First, partial sentence trees are proposed to represent a speech recognition output sentence. Semantic information and the derivation rules of the partial sentence trees are extracted and used to model the relationship between the dialogue acts and the derivation rules. The constructed model is then used to generate a semantic score for dialogue act detection given an input speech utterance. The proposed approach is implemented and evaluated in a Mandarin spoken dialogue system for tour-guiding service. Combined with scores derived from the ASR recognition probability and the dialogue history, the proposed approach achieves 84.3% detection accuracy, an absolute improvement of 34.7% over the baseline of the semantic slot-based method with 49.6% detection accuracy.</p><p>6 0.56189245 <a title="227-lsi-6" href="./acl-2011-Turn-Taking_Cues_in_a_Human_Tutoring_Corpus.html">312 acl-2011-Turn-Taking Cues in a Human Tutoring Corpus</a></p>
<p>7 0.55096769 <a title="227-lsi-7" href="./acl-2011-Recognizing_Authority_in_Dialogue_with_an_Integer_Linear_Programming_Constrained_Model.html">260 acl-2011-Recognizing Authority in Dialogue with an Integer Linear Programming Constrained Model</a></p>
<p>8 0.51004016 <a title="227-lsi-8" href="./acl-2011-Entrainment_in_Speech_Preceding_Backchannels..html">118 acl-2011-Entrainment in Speech Preceding Backchannels.</a></p>
<p>9 0.48349041 <a title="227-lsi-9" href="./acl-2011-Prototyping_virtual_instructors_from_human-human_corpora.html">252 acl-2011-Prototyping virtual instructors from human-human corpora</a></p>
<p>10 0.46268931 <a title="227-lsi-10" href="./acl-2011-Multi-Modal_Annotation_of_Quest_Games_in_Second_Life.html">226 acl-2011-Multi-Modal Annotation of Quest Games in Second Life</a></p>
<p>11 0.36404186 <a title="227-lsi-11" href="./acl-2011-Hierarchical_Reinforcement_Learning_and_Hidden_Markov_Models_for_Task-Oriented_Natural_Language_Generation.html">149 acl-2011-Hierarchical Reinforcement Learning and Hidden Markov Models for Task-Oriented Natural Language Generation</a></p>
<p>12 0.25297964 <a title="227-lsi-12" href="./acl-2011-A_Pilot_Study_of_Opinion_Summarization_in_Conversations.html">21 acl-2011-A Pilot Study of Opinion Summarization in Conversations</a></p>
<p>13 0.23777802 <a title="227-lsi-13" href="./acl-2011-IMASS%3A_An_Intelligent_Microblog_Analysis_and_Summarization_System.html">156 acl-2011-IMASS: An Intelligent Microblog Analysis and Summarization System</a></p>
<p>14 0.23006168 <a title="227-lsi-14" href="./acl-2011-A_Speech-based_Just-in-Time_Retrieval_System_using_Semantic_Search.html">26 acl-2011-A Speech-based Just-in-Time Retrieval System using Semantic Search</a></p>
<p>15 0.22107005 <a title="227-lsi-15" href="./acl-2011-An_ERP-based_Brain-Computer_Interface_for_text_entry_using_Rapid_Serial_Visual_Presentation_and_Language_Modeling.html">35 acl-2011-An ERP-based Brain-Computer Interface for text entry using Rapid Serial Visual Presentation and Language Modeling</a></p>
<p>16 0.21002023 <a title="227-lsi-16" href="./acl-2011-Wikulu%3A_An_Extensible_Architecture_for_Integrating_Natural_Language_Processing_Techniques_with_Wikis.html">338 acl-2011-Wikulu: An Extensible Architecture for Integrating Natural Language Processing Techniques with Wikis</a></p>
<p>17 0.20855114 <a title="227-lsi-17" href="./acl-2011-Question_Detection_in_Spoken_Conversations_Using_Textual_Conversations.html">257 acl-2011-Question Detection in Spoken Conversations Using Textual Conversations</a></p>
<p>18 0.20619355 <a title="227-lsi-18" href="./acl-2011-Interactive_Group_Suggesting_for_Twitter.html">177 acl-2011-Interactive Group Suggesting for Twitter</a></p>
<p>19 0.19943158 <a title="227-lsi-19" href="./acl-2011-MACAON_An_NLP_Tool_Suite_for_Processing_Word_Lattices.html">215 acl-2011-MACAON An NLP Tool Suite for Processing Word Lattices</a></p>
<p>20 0.18743233 <a title="227-lsi-20" href="./acl-2011-Improving_On-line_Handwritten_Recognition_using_Translation_Models_in_Multimodal_Interactive_Machine_Translation.html">168 acl-2011-Improving On-line Handwritten Recognition using Translation Models in Multimodal Interactive Machine Translation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.034), (17, 0.046), (26, 0.046), (30, 0.383), (37, 0.027), (39, 0.021), (41, 0.069), (55, 0.036), (59, 0.032), (72, 0.026), (91, 0.029), (96, 0.146), (97, 0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.74776584 <a title="227-lda-1" href="./acl-2011-Multimodal_Menu-based_Dialogue_with_Speech_Cursor_in_DICO_II%2B.html">227 acl-2011-Multimodal Menu-based Dialogue with Speech Cursor in DICO II+</a></p>
<p>Author: Staffan Larsson ; Alexander Berman ; Jessica Villing</p><p>Abstract: Alexander Berman Jessica Villing Talkamatic AB University of Gothenburg Sweden Sweden alex@ t alkamat i . se c jessi ca@ l ing .gu . s e 2 In-vehicle dialogue systems This paper describes Dico II+, an in-vehicle dialogue system demonstrating a novel combination of flexible multimodal menu-based dialogueand a “speech cursor” which enables menu navigation as well as browsing long list using haptic input and spoken output.</p><p>2 0.59777045 <a title="227-lda-2" href="./acl-2011-Extending_the_Entity_Grid_with_Entity-Specific_Features.html">129 acl-2011-Extending the Entity Grid with Entity-Specific Features</a></p>
<p>Author: Micha Elsner ; Eugene Charniak</p><p>Abstract: We extend the popular entity grid representation for local coherence modeling. The grid abstracts away information about the entities it models; we add discourse prominence, named entity type and coreference features to distinguish between important and unimportant entities. We improve the best result for WSJ document discrimination by 6%.</p><p>3 0.45619416 <a title="227-lda-3" href="./acl-2011-Disentangling_Chat_with_Local_Coherence_Models.html">101 acl-2011-Disentangling Chat with Local Coherence Models</a></p>
<p>Author: Micha Elsner ; Eugene Charniak</p><p>Abstract: We evaluate several popular models of local discourse coherence for domain and task generality by applying them to chat disentanglement. Using experiments on synthetic multiparty conversations, we show that most models transfer well from text to dialogue. Coherence models improve results overall when good parses and topic models are available, and on a constrained task for real chat data.</p><p>4 0.42635101 <a title="227-lda-4" href="./acl-2011-An_Empirical_Evaluation_of_Data-Driven_Paraphrase_Generation_Techniques.html">37 acl-2011-An Empirical Evaluation of Data-Driven Paraphrase Generation Techniques</a></p>
<p>Author: Donald Metzler ; Eduard Hovy ; Chunliang Zhang</p><p>Abstract: Paraphrase generation is an important task that has received a great deal of interest recently. Proposed data-driven solutions to the problem have ranged from simple approaches that make minimal use of NLP tools to more complex approaches that rely on numerous language-dependent resources. Despite all of the attention, there have been very few direct empirical evaluations comparing the merits of the different approaches. This paper empirically examines the tradeoffs between simple and sophisticated paraphrase harvesting approaches to help shed light on their strengths and weaknesses. Our evaluation reveals that very simple approaches fare surprisingly well and have a number of distinct advantages, including strong precision, good coverage, and low redundancy.</p><p>5 0.42534715 <a title="227-lda-5" href="./acl-2011-Exact_Decoding_of_Syntactic_Translation_Models_through_Lagrangian_Relaxation.html">123 acl-2011-Exact Decoding of Syntactic Translation Models through Lagrangian Relaxation</a></p>
<p>Author: Alexander M. Rush ; Michael Collins</p><p>Abstract: We describe an exact decoding algorithm for syntax-based statistical translation. The approach uses Lagrangian relaxation to decompose the decoding problem into tractable subproblems, thereby avoiding exhaustive dynamic programming. The method recovers exact solutions, with certificates of optimality, on over 97% of test examples; it has comparable speed to state-of-the-art decoders.</p><p>6 0.42280307 <a title="227-lda-6" href="./acl-2011-Fine-Grained_Class_Label_Markup_of_Search_Queries.html">137 acl-2011-Fine-Grained Class Label Markup of Search Queries</a></p>
<p>7 0.42261523 <a title="227-lda-7" href="./acl-2011-A_Fast_and_Accurate_Method_for_Approximate_String_Search.html">11 acl-2011-A Fast and Accurate Method for Approximate String Search</a></p>
<p>8 0.42250174 <a title="227-lda-8" href="./acl-2011-Deciphering_Foreign_Language.html">94 acl-2011-Deciphering Foreign Language</a></p>
<p>9 0.42244524 <a title="227-lda-9" href="./acl-2011-Interactive_Group_Suggesting_for_Twitter.html">177 acl-2011-Interactive Group Suggesting for Twitter</a></p>
<p>10 0.42214209 <a title="227-lda-10" href="./acl-2011-A_Speech-based_Just-in-Time_Retrieval_System_using_Semantic_Search.html">26 acl-2011-A Speech-based Just-in-Time Retrieval System using Semantic Search</a></p>
<p>11 0.42128497 <a title="227-lda-11" href="./acl-2011-Clustering_Comparable_Corpora_For_Bilingual_Lexicon_Extraction.html">70 acl-2011-Clustering Comparable Corpora For Bilingual Lexicon Extraction</a></p>
<p>12 0.42076311 <a title="227-lda-12" href="./acl-2011-Clairlib%3A_A_Toolkit_for_Natural_Language_Processing%2C_Information_Retrieval%2C_and_Network_Analysis.html">67 acl-2011-Clairlib: A Toolkit for Natural Language Processing, Information Retrieval, and Network Analysis</a></p>
<p>13 0.42007506 <a title="227-lda-13" href="./acl-2011-A_Hierarchical_Pitman-Yor_Process_HMM_for_Unsupervised_Part_of_Speech_Induction.html">15 acl-2011-A Hierarchical Pitman-Yor Process HMM for Unsupervised Part of Speech Induction</a></p>
<p>14 0.41971117 <a title="227-lda-14" href="./acl-2011-Good_Seed_Makes_a_Good_Crop%3A_Accelerating_Active_Learning_Using_Language_Modeling.html">145 acl-2011-Good Seed Makes a Good Crop: Accelerating Active Learning Using Language Modeling</a></p>
<p>15 0.41941631 <a title="227-lda-15" href="./acl-2011-Faster_and_Smaller_N-Gram_Language_Models.html">135 acl-2011-Faster and Smaller N-Gram Language Models</a></p>
<p>16 0.41853288 <a title="227-lda-16" href="./acl-2011-An_Efficient_Indexer_for_Large_N-Gram_Corpora.html">36 acl-2011-An Efficient Indexer for Large N-Gram Corpora</a></p>
<p>17 0.41837934 <a title="227-lda-17" href="./acl-2011-Sentence_Ordering_Driven_by_Local_and_Global_Coherence_for_Summary_Generation.html">280 acl-2011-Sentence Ordering Driven by Local and Global Coherence for Summary Generation</a></p>
<p>18 0.41824523 <a title="227-lda-18" href="./acl-2011-Large-Scale_Cross-Document_Coreference_Using_Distributed_Inference_and_Hierarchical_Models.html">196 acl-2011-Large-Scale Cross-Document Coreference Using Distributed Inference and Hierarchical Models</a></p>
<p>19 0.41822094 <a title="227-lda-19" href="./acl-2011-Collecting_Highly_Parallel_Data_for_Paraphrase_Evaluation.html">72 acl-2011-Collecting Highly Parallel Data for Paraphrase Evaluation</a></p>
<p>20 0.41746157 <a title="227-lda-20" href="./acl-2011-Incremental_Syntactic_Language_Models_for_Phrase-based_Translation.html">171 acl-2011-Incremental Syntactic Language Models for Phrase-based Translation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
