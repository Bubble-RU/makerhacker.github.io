<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>204 acl-2012-Translation Model Size Reduction for Hierarchical Phrase-based Statistical Machine Translation</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-204" href="../acl2012/acl-2012-Translation_Model_Size_Reduction_for_Hierarchical_Phrase-based_Statistical_Machine_Translation.html">acl2012-204</a> <a title="acl-2012-204-reference" href="#">acl2012-204-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>204 acl-2012-Translation Model Size Reduction for Hierarchical Phrase-based Statistical Machine Translation</h1>
<br/><p>Source: <a title="acl-2012-204-pdf" href="http://aclweb.org/anthology//P/P12/P12-2057.pdf">pdf</a></p><p>Author: Seung-Wook Lee ; Dongdong Zhang ; Mu Li ; Ming Zhou ; Hae-Chang Rim</p><p>Abstract: In this paper, we propose a novel method of reducing the size of translation model for hierarchical phrase-based machine translation systems. Previous approaches try to prune infrequent entries or unreliable entries based on statistics, but cause a problem of reducing the translation coverage. On the contrary, the proposed method try to prune only ineffective entries based on the estimation of the information redundancy encoded in phrase pairs and hierarchical rules, and thus preserve the search space of SMT decoders as much as possible. Experimental results on Chinese-toEnglish machine translation tasks show that our method is able to reduce almost the half size of the translation model with very tiny degradation of translation performance.</p><br/>
<h2>reference text</h2><br/>
<br/><br/><br/></body>
</html>
