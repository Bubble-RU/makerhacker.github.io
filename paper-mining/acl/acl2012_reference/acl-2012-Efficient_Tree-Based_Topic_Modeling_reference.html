<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>79 acl-2012-Efficient Tree-Based Topic Modeling</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-79" href="../acl2012/acl-2012-Efficient_Tree-Based_Topic_Modeling.html">acl2012-79</a> <a title="acl-2012-79-reference" href="#">acl2012-79-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>79 acl-2012-Efficient Tree-Based Topic Modeling</h1>
<br/><p>Source: <a title="acl-2012-79-pdf" href="http://aclweb.org/anthology//P/P12/P12-2054.pdf">pdf</a></p><p>Author: Yuening Hu ; Jordan Boyd-Graber</p><p>Abstract: Topic modeling with a tree-based prior has been used for a variety of applications because it can encode correlations between words that traditional topic modeling cannot. However, its expressive power comes at the cost of more complicated inference. We extend the SPARSELDA (Yao et al., 2009) inference scheme for latent Dirichlet allocation (LDA) to tree-based topic models. This sampling scheme computes the exact conditional distribution for Gibbs sampling much more quickly than enumerating all possible latent variable assignments. We further improve performance by iteratively refining the sampling distribution only when needed. Experiments show that the proposed techniques dramatically improve the computation time.</p><br/>
<h2>reference text</h2><p>Steven Abney and Marc Light. 1999. Hiding a semantic hierarchy in a Markov model. In Proceedings of the Workshop on Unsupervised Learning in Natural Language Processing. David Andrzejewski, Xiaojin Zhu, and Mark Craven. 2009. Incorporating domain knowledge into topic modeling via Dirichlet forest priors. In Proceedings of International Conference of Machine Learning. David M. Blei, Andrew Ng, and Michael Jordan. 2003. Latent Dirichlet allocation. Journal of Machine Learning Research, 3:993–1022. Jordan Boyd-Graber, David M. Blei, and Xiaojin Zhu. 2007. A topic model for word sense disambiguation. In Proceedings of Emperical Methods in Natural Language Processing. Gregor Heinrich. 2004. Parameter estimation for text analysis. Technical report. http://www.arbylon.net/publications/text-est.pdf. Yuening Hu, Jordan Boyd-Graber, and Brianna Satinoff. 2011. Interactive topic modeling. In Association for Computational Linguistics. Jagadeesh Jagarlamudi and Hal Daume´ III. 2010. Extracting multilingual topics from unaligned corpora. In Proceedings of the European Conference on Information Retrieval (ECIR). George A. Miller. 1990. Nouns in WordNet: A lexical inheritance system. International Journal of Lexicography, 3(4):245–264. Alexander J. Smola and Shravan Narayanamurthy. 2010. An architecture for parallel topic models. International Conference on Very Large Databases, 3. Limin Yao, David Mimno, and Andrew McCallum. 2009. Efficient methods for topic model inference on streaming document collections. In Knowledge Discovery and Data Mining. 279</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
