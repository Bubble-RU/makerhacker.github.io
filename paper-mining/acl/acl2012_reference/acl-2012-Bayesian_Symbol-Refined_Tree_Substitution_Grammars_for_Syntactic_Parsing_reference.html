<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>38 acl-2012-Bayesian Symbol-Refined Tree Substitution Grammars for Syntactic Parsing</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-38" href="../acl2012/acl-2012-Bayesian_Symbol-Refined_Tree_Substitution_Grammars_for_Syntactic_Parsing.html">acl2012-38</a> <a title="acl-2012-38-reference" href="#">acl2012-38-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>38 acl-2012-Bayesian Symbol-Refined Tree Substitution Grammars for Syntactic Parsing</h1>
<br/><p>Source: <a title="acl-2012-38-pdf" href="http://aclweb.org/anthology//P/P12/P12-1046.pdf">pdf</a></p><p>Author: Hiroyuki Shindo ; Yusuke Miyao ; Akinori Fujino ; Masaaki Nagata</p><p>Abstract: We propose Symbol-Refined Tree Substitution Grammars (SR-TSGs) for syntactic parsing. An SR-TSG is an extension of the conventional TSG model where each nonterminal symbol can be refined (subcategorized) to fit the training data. We aim to provide a unified model where TSG rules and symbol refinement are learned from training data in a fully automatic and consistent fashion. We present a novel probabilistic SR-TSG model based on the hierarchical Pitman-Yor Process to encode backoff smoothing from a fine-grained SR-TSG to simpler CFG rules, and develop an efficient training method based on Markov Chain Monte Carlo (MCMC) sampling. Our SR-TSG parser achieves an F1 score of 92.4% in the Wall Street Journal (WSJ) English Penn Treebank parsing task, which is a 7.7 point improvement over a conventional Bayesian TSG parser, and better than state-of-the-art discriminative reranking parsers.</p><br/>
<h2>reference text</h2><p>Mohit Bansal and Dan Klein. 2010. Simple, Accurate Parsing with an All-Fragments Grammar. In In Proc. of ACL, pages 1098–1 107. Phil Blunsom and Trevor Cohn. 2010. Unsupervised Induction of Tree Substitution Grammars for Dependency Parsing. In Proc. of EMNLP, pages 1204–1213. Eugene Charniak and Mark Johnson. 2005. Coarseto-Fine n-Best Parsing and MaxEnt Discriminative Reranking. In Proc. of ACL, 1:173–180. Shay B Cohen, David M Blei, and Noah A Smith. 2010. Variational Inference for Adaptor Grammars. In In Proc. of HLT-NAACL, pages 564–572. Trevor Cohn and Mirella Lapata. 2009. Sentence Compression as Tree Transduction. Journal of Artificial Intelligence Research, 34:637–674. Trevor Cohn, Phil Blunsom, and Sharon Goldwater. 2010. Inducing Tree-Substitution Grammars. Journal of Machine Learning Research, 11:3053–3096. Michael Collins. 2003. Head-Driven Statistical Models for Natural Language Parsing. Computational Linguistics, 29:589–637. Steve DeNeefe and Kevin Knight. 2009. Synchronous  Tree Adjoining Machine Translation. In Proc. of EMNLP, page 727. Thomas S Ferguson. 1973. A Bayesian Analysis of Some Nonparametric Problems. Annals of Statistics, 1:209–230. Victoria Fossum and Kevin Knight. 2009. Combining Constituent Parsers. In Proc. of HLT-NAACL, pages 253–256. Michel Galley, Mark Hopkins, Kevin Knight, Daniel Marcu, Los Angeles, and Marina Del Rey. 2004. What’s in a Translation Rule? Information Sciences, pages 273–280. Liang Huang. 2008. Forest Reranking : Discriminative Parsing with Non-Local Features. In Proc. of ACL, 19104:0. Mark Johnson and Sharon Goldwater. 2009. Improving nonparameteric Bayesian inference: experiments on unsupervised word segmentation with adaptor grammars. In In Proc. of HLT-NAACL, pages 3 17–325. Mark Johnson, Thomas L Griffiths, and Sharon Goldwater. 2007a. Adaptor Grammars : A Framework for Specifying Compositional Nonparametric Bayesian Models. Advances in Neural Information Processing Systems 19, 19:641–648. Mark Johnson, Thomas L Griffiths, and Sharon Goldwater. 2007b. Bayesian Inference for PCFGs via Markov chain Monte Carlo. In In Proc. of HLT-NAACL, pages 139–146.  448 Mark Johnson. 1998. PCFG Models of Linguistic Tree Representations. Computational Linguistics, 24:613– 632. Dan Klein and Christopher D Manning. 2003. Accurate Unlexicalized Parsing. In Proc. of ACL, 1:423–430. K Lari and S J Young. 1991. Applications of Stochastic Context-Free Grammars Using the Inside–Outside Algorithm. Computer Speech and Language, 5:237– 257. Mitchell P Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a Large Annotated Corpus of English: The Penn Treebank. Computational Linguistics, 19:3 13–330. Takuya Matsuzaki, Yusuke Miyao, and Jun’ichi Tsujii. 2005. Probabilistic CFG with latent annotations. In Proc. of ACL, pages 75–82. Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. 2006. Learning Accurate, Compact, and Interpretable Tree Annotation. In Proc. of ACL, pages 433–440. Slav Petrov. 2010. Products of Random Latent Variable Grammars. In Proc. of HLT-NAACL, pages 19–27. Jim Pitman and Marc Yor. 1997. The two-parameter Poisson-Dirichlet distribution derived from a stable subordinator. The Annals of Probability, 25:855–900.  Matt Post and Daniel Gildea. 2009. Bayesian Learning of a Tree Substitution Grammar. In In Proc. of ACLIJCNLP, pages 45–48. Yee Whye Teh. 2006a. A Bayesian Interpretation of Interpolated Kneser-Ney. NUS School of Computing Technical Report TRA2/06. YW Teh. 2006b. A Hierarchical Bayesian Language Model based on Pitman-Yor Processes. In Proc. of ACL, 44:985–992. J Tenenbaum, TJ O’Donnell, and ND Goodman. 2009. Fragment Grammars: Exploring Computation and Reuse in Language. MIT Computer Science and Artificial Intelligence Laboratory Technical Report Series. Mengqiu Wang, Noah A Smith, and Teruko Mitamura. 2007. What is the Jeopardy Model ? A QuasiSynchronous Grammar for QA. In Proc. of EMNLPCoNLL, pages 22–32. Elif Yamangil and Stuart M Shieber. 2010. Bayesian Synchronous Tree-Substitution Grammar Induction and Its Application to Sentence Compression. In In Proc. of ACL, pages 937–947. Hui Zhang, Min Zhang, Chew Lim Tan, and Haizhou Li. 2009. K-Best Combination of Syntactic Parsers. In Proc. of EMNLP, pages 1552–1560. Willem Zuidema. 2007. Parsimonious Data-Oriented Parsing. In Proc. of EMNLP-CoNLL, pages 551–560.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
