<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>169 acl-2012-Reducing Wrong Labels in Distant Supervision for Relation Extraction</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-169" href="../acl2012/acl-2012-Reducing_Wrong_Labels_in_Distant_Supervision_for_Relation_Extraction.html">acl2012-169</a> <a title="acl-2012-169-reference" href="#">acl2012-169-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>169 acl-2012-Reducing Wrong Labels in Distant Supervision for Relation Extraction</h1>
<br/><p>Source: <a title="acl-2012-169-pdf" href="http://aclweb.org/anthology//P/P12/P12-1076.pdf">pdf</a></p><p>Author: Shingo Takamatsu ; Issei Sato ; Hiroshi Nakagawa</p><p>Abstract: In relation extraction, distant supervision seeks to extract relations between entities from text by using a knowledge base, such as Freebase, as a source of supervision. When a sentence and a knowledge base refer to the same entity pair, this approach heuristically labels the sentence with the corresponding relation in the knowledge base. However, this heuristic can fail with the result that some sentences are labeled wrongly. This noisy labeled data causes poor extraction performance. In this paper, we propose a method to reduce the number of wrong labels. We present a novel generative model that directly models the heuristic labeling process of distant supervision. The model predicts whether assigned labels are correct or wrong via its hidden variables. Our experimental results show that this model detected wrong labels with higher performance than baseline methods. In the ex- periment, we also found that our wrong label reduction boosted the performance of relation extraction.</p><br/>
<h2>reference text</h2><br/>
<br/><br/><br/></body>
</html>
