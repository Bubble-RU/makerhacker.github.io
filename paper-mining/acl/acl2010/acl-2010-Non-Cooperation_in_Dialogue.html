<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>178 acl-2010-Non-Cooperation in Dialogue</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-178" href="#">acl2010-178</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>178 acl-2010-Non-Cooperation in Dialogue</h1>
<br/><p>Source: <a title="acl-2010-178-pdf" href="http://aclweb.org/anthology//P/P10/P10-3001.pdf">pdf</a></p><p>Author: Brian Pluss</p><p>Abstract: This paper presents ongoing research on computational models for non-cooperative dialogue. We start by analysing different levels of cooperation in conversation. Then, inspired by findings from an empirical study, we propose a technique for measuring non-cooperation in political interviews. Finally, we describe a research programme towards obtaining a suitable model and discuss previous accounts for conflictive dialogue, identifying the differences with our work.</p><p>Reference: <a title="acl-2010-178-reference" href="../acl2010_reference/acl-2010-Non-Cooperation_in_Dialogue_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 We start by analysing different levels of cooperation in conversation. [sent-5, score-0.265]
</p><p>2 Then, inspired by findings from an empirical study, we propose a technique for measuring non-cooperation in political interviews. [sent-6, score-0.172]
</p><p>3 Finally, we describe a research programme towards obtaining a suitable model and discuss previous accounts for conflictive dialogue, identifying the differences with our work. [sent-7, score-0.076]
</p><p>4 1 Introduction Most approaches to modeling conversation are based on a strong notion of cooperation between the dialogue participants (DPs). [sent-8, score-0.834]
</p><p>5 These assumptions are theoretically grounded, as most work in linguistics has considered situations in which DPs share a common goal and cooperate to achieve it by means of conversation (Grice, 1975; Clark and Schaefer, 1989). [sent-10, score-0.242]
</p><p>6 They are also practically sound: dialogue models are usually implemented in the form of dialogue systems, built for the purpose of providing a service to their users (e. [sent-11, score-0.598]
</p><p>7 In everyday conversation, however, a great many situations escape the arguments above. [sent-15, score-0.09]
</p><p>8 Con1  sider the following (1) PAXMAN  example1 :  [1]: (interrupting) Did you threaten to overrule him? [sent-16, score-0.537]
</p><p>9 HOWARD [2]: I, I, was not entitled to instruct Derek Lewis, and Idid not instruct him. [sent-17, score-0.205]
</p><p>10 PAXMAN [5]: (overlappling) Did you threaten to overrule him? [sent-24, score-0.537]
</p><p>11 PAXMAN [9]: (overlappling) Did you threaten to overrule him, Mr. [sent-33, score-0.537]
</p><p>12 and Iacted scrupulously in accordance with that advice, Idid not overrule Derek Lewis. [sent-38, score-0.34]
</p><p>13 PAXMAN [11]: (overlapping) Did you threaten to overrule him? [sent-41, score-0.537]
</p><p>14 HOWARD[14]: (pauses) I have accounted for my decision to dismiss Derek Lewis. [sent-48, score-0.038]
</p><p>15 PAXMAN [15]: (overlapping) Did you threaten to overrule him? [sent-51, score-0.537]
</p><p>16 PAXMAN [17]: Inote that you’re not answering the  question of whether you threatened to overrule him. [sent-56, score-0.397]
</p><p>17 exchange  is clearly conflictive,  Still, the  to the point that  their behaviour compromises the flow of the conversation. [sent-58, score-0.174]
</p><p>18 The case was given considerable attention in the media, as a result of accusations by Lewis that Howard had instructed him, thus exceeding the powers of his office. [sent-60, score-0.033]
</p><p>19 1c 02 S01tu0d Aenssto Rceiasetiaornch fo Wro Crokmshpoupt,a ptiaogneasl 1 L–in6g,uistics “the participants -IRs [=interviewers] and IEs [=interviewees]- exclude themselves from a wide variety of actions that they are normally free to do in the give and take of ordinary conversa-  tion. [sent-63, score-0.092]
</p><p>20 8) Now, consider the fragment  below2:  (2) PAXMAN [1]: Can you clear up whether or not you did threaten to overrule Derek Lewis when you were Home Secretary? [sent-67, score-0.537]
</p><p>21 (Newsnight, BBC, 2004)  On this occasion, Howard provides an answer almost immediately and the flow of the conversation contrasts noticeably with that in (1). [sent-82, score-0.178]
</p><p>22 The investigation reported in this article aims at shedding light on the nature of non-cooperation in dialogue, by capturing the intuitions that allow us to differentiate between both conversations in terms of participant behaviour. [sent-83, score-0.036]
</p><p>23 Dialogue games supporters could say that there is a game that describes the interaction in the first example. [sent-84, score-0.042]
</p><p>24 While this might be true, such an approach would force us, in the limit, to define one game for each possible conversation that would not fit a certain standard. [sent-85, score-0.149]
</p><p>25 They claim that a rigorous model of conversational interaction is useful, but accept that most of the huge variety of everyday conversation escapes it. [sent-87, score-0.338]
</p><p>26 Dialogue games are based on strict rules that capture typical dialogue situations while leaving out considerable detail. [sent-88, score-0.401]
</p><p>27 As example (1) shows, DPs behaviour can 2This exchange took place seven years after (1), when public awareness of the 1995 affair had dissipated. [sent-89, score-0.145]
</p><p>28 2 divert from the typical case in unexpected ways, falling outside the characterisation3. [sent-90, score-0.033]
</p><p>29 Nevertheless, the rules and patterns captured by game models are useful, as they describe the expected behaviour of the DPs under a certain conversational scenario. [sent-91, score-0.244]
</p><p>30 In our research, we aim at reconciling two worlds, using the insights from dialogue games to provide a description of expected behaviour in the form of social obligations, but looking at naturally occurring cases that deviate from the norm. [sent-92, score-0.544]
</p><p>31 This, in turn, calls for a technique to measure non-cooperation in dialogue and in this paper we provide one that is theoretically sound and supported by empirical evidence. [sent-93, score-0.299]
</p><p>32 The following section discusses levels of cooperation in dialogue; Section 3 presents an empirical study and a practical measure of noncooperation in political interviews; in Section 4 we discuss related work, our working hypothesis and a methodology; and Section 5 has the conclusions. [sent-94, score-0.513]
</p><p>33 2  Linguistic and Non-Linguistic Cooperation  Cooperation in dialogue can happen at different levels. [sent-95, score-0.299]
</p><p>34 In most cases, conversation supports a social activity that constrains the behaviour acceptable or expected from the participants. [sent-96, score-0.352]
</p><p>35 In addition, conversational behaviour determines how cooperatively participants engage in a social activity. [sent-97, score-0.425]
</p><p>36 However, cooperation at the conversational level does not necessarily translate to the social level. [sent-98, score-0.484]
</p><p>37 Consider, for instance, a witness under interrogation in a U. [sent-99, score-0.088]
</p><p>38 Such behaviour will be accepted in the conversational setting as established by law, although it is not cooperative in relation with the goals of the trial. [sent-102, score-0.404]
</p><p>39 Non-cooperation at the conversational level, on the other hand, usually results in lack of cooperation at the social level. [sent-103, score-0.484]
</p><p>40 Take as an example, the same witness remaining silent, rather than answering or appealing to the Fifth Amendment. [sent-104, score-0.05]
</p><p>41 To illustrate further, consider a fictional alter-  native to (1), where Howard replies by saying “I will not answer that question, as it is not relevant to whether Iexceeded the powers of my office”. [sent-105, score-0.033]
</p><p>42 3Consider, for instance, Giznburg’s QUD model (Ginzburg, 1996) when applied to dialogue (1), in which Howard repeatedly fails to either accept or reject Paxman’s question. [sent-106, score-0.328]
</p><p>43 ) be compelled in any criminal case to be a witness against himself”. [sent-110, score-0.05]
</p><p>44 This is not cooperative for the interview, but it is so at the linguistic level. [sent-111, score-0.071]
</p><p>45 The distinction between linguistic and nonlinguistic (also called task-related, high-level or social) cooperation has been addressed before. [sent-115, score-0.265]
</p><p>46 Attardo (1997) revisits Gricean pragmatics, relating non-linguistic cooperation to participants’ behaviour towards realising task-related goals, and linguistic cooperation to assumptions on their respective behaviour in order to encode and decode intended meaning. [sent-116, score-0.758]
</p><p>47 From a computational perspective, Bunt (1994) relies on a similar distinction for defining dialogue acts. [sent-117, score-0.299]
</p><p>48 Walton and Krabbe (1995) proposed a typology of dialogue based on the initial situation triggering the exchange and participants’ shared aims and individual goals. [sent-120, score-0.363]
</p><p>49 Based on their work, Reed and Long (1997) distinguish cases where participants follow a common set of dialogue rules and stay within a mutually acknowledged framework from a stronger notion in which their individual goals are in the same direction. [sent-121, score-0.549]
</p><p>50 Borrowing from the latter, in the rest ofthe paper, we will speak ofcollaboration when DPs share the same task-level goals, and use cooperation when participants follow the conversational obligations imposed by the social activity (i. [sent-122, score-0.727]
</p><p>51 We will not deal with collaboration here, though, as our focus is on non-cooperation. [sent-125, score-0.033]
</p><p>52 3  An Empirical Study  In this section, we describe an empirical pilot study aimed at identifying a set of features that distinguish cooperative from non-cooperative conversational behaviour and at establishing a suitable domain in which to focus our work. [sent-126, score-0.315]
</p><p>53 1 The Corpus We collected the transcripts of 10 adversarial dialogues: 4 political interviews, 2 entertainment interviews, 1 parliamentary inquiry, 1 courtroom confrontation, 1 courtroom interrogation and 1 3 dispute. [sent-128, score-0.381]
</p><p>54 The corpus includes 2 collaborative political interviews for result comparison and is nearly 14,500 words long5. [sent-129, score-0.394]
</p><p>55 In a first analysis, we identified those surface features that characterised each conversation as conflictive: e. [sent-130, score-0.149]
</p><p>56 As for the domain, the wealth ofinteresting conversational situations that arise in political interviews make a suitable context for this research. [sent-137, score-0.55]
</p><p>57 2 Degrees of Non-Cooperation Based on the analysis described above, we propose a technique for measuring non-cooperation in political interviews using a set of non-cooperative features (NCFs). [sent-144, score-0.36]
</p><p>58 The number of occurrences of  these features will determine the degree of noncooperation (DNC) of an exchange. [sent-145, score-0.076]
</p><p>59 We grouped NCFs following three aspects of conversation: turn-taking, grounding and speech acts (see Table 1for a complete list). [sent-146, score-0.089]
</p><p>60 Interlocutors in a political interview are expected to respect transition-relevance places, openings and closings according to social conventions. [sent-149, score-0.318]
</p><p>61 Table 1: NCFs for political interviews contributions standing (e. [sent-157, score-0.36]
</p><p>62 acknowledged  by providing evidence of undercontinued attention, relevant next In political interviews a question is by rejecting it or by providing a di-  rect answer. [sent-159, score-0.43]
</p><p>63 Likewise, answers are acknowledged by rejecting their relevance, by asking a next relevant question or by moving on to a new topical issue. [sent-160, score-0.099]
</p><p>64 Going back to Heritage’s comment, in a political interview participants can fail to restrict their speech acts to the force and content expected for their role. [sent-163, score-0.359]
</p><p>65 Non-cooperative features related to speech acts include the interviewer expressing a personal opinion or criticising subjectively the interviewee’s positions and the interviewee asking questions (except for clarification requests) or making irrelevant comments. [sent-164, score-0.155]
</p><p>66 We define the degree of non-cooperation (DNC) of a dialogue as the proportion of utterances with one of more occurrences of these non-cooperative features6. [sent-165, score-0.331]
</p><p>67 Furthermore, the DNC could be thus computed for the whole conversation and also for each participant, by counting only occurrences of features and utterances from each DP. [sent-166, score-0.181]
</p><p>68 , an interviewee attempting a change of topic has a stronger impact on the DNC than, say, one interrupting. [sent-170, score-0.057]
</p><p>69 4 of (1) annotated with non-cooperative features (O: overlap;  GF: grounding  failure;  UC: unsolicited  comment; I: interruption; TC: topic change): (3) P [11] : Uir. [sent-171, score-0.089]
</p><p>70 4  (overlapping) Did you threaten to O overrule him? [sent-181, score-0.537]
</p><p>71 GF (pauses) I have accounted for my decision to dismiss Derek Lewis. [sent-188, score-0.038]
</p><p>72 Inote that you’re not answering the question whether you threatened to overrule him. [sent-196, score-0.397]
</p><p>73 7 Igave him the benefit of my opin- UC ion in strong language, but Idid not instruct him because Iwas not, er, entitled to instruct him. [sent-226, score-0.205]
</p><p>74 8 I was entitled to express my opinion UC and that is what I did. [sent-228, score-0.083]
</p><p>75 9 With respect, that is not answering the question of whether you threatened to overrule him. [sent-230, score-0.397]
</p><p>76 9 It’s dealing with the relevant point TC which was what I was entitled to do and what I was not entitled to do, Uie. [sent-232, score-0.166]
</p><p>77 Table 2 summarises utterances  non-cooperative  features,  and the degree of non-cooperation for  each participant and for the whole fragment. [sent-234, score-0.068]
</p><p>78 436m98ent Table 2: Computing the DNC for dialogue (3) The DNC was computed for all the political interviews in the corpus. [sent-238, score-0.659]
</p><p>79 Table 3 shows the val-  Table 3: DNC of political interviews in the corpus ues obtained. [sent-239, score-0.36]
</p><p>80 Adversarial interviews have a large number of NCFs, thus a high value for the DNC. [sent-240, score-0.188]
</p><p>81 On the other hand, collaborative exchanges have low occurrence of NCFs (or none at all)7. [sent-241, score-0.034]
</p><p>82 4  Discussion  There have been previous approaches to modeling dialogue on the basis that participants are not always fully cooperative. [sent-242, score-0.391]
</p><p>83 Jameson (1989) presents an extensive study for modeling bias, individual goals, projected image and belief ascription in conversation. [sent-243, score-0.069]
</p><p>84 User-model approaches are flexi-  ble to account for intricate situations but, as noted by Taylor et al. [sent-244, score-0.06]
</p><p>85 Taylor (1994) addressed non-cooperative dialogue behaviour by implementing CYNIC, a dialogue system able to generate and recognise deception; a notion of noncooperation weaker than the one we address. [sent-246, score-0.845]
</p><p>86 More recently, Traum (2008) brought attention to the need for computational accounts of dialogue situations in which a broader notion of cooperation is not assumed: e. [sent-247, score-0.653]
</p><p>87 We are currently performing two studies: one to determine inter-annotator agreement of the coding scheme for NCFs, and another to test how NCFs correlate to human judgements of non-cooperative conversational behaviour. [sent-250, score-0.13]
</p><p>88 5 Traum’s work on conflictive dialogue is mainly aimed at creating virtual humans with abilities to engage in adversarial dialogue. [sent-251, score-0.47]
</p><p>89 (2008) present a model of conversation strategies for negotiation, that includes variables representing trust, politeness and emotions, and a set of  agents8. [sent-253, score-0.149]
</p><p>90 Despite being adversarial in nature, the conversational scenarios are modeled by means of rules, that are followed by the interlocutors, according to the values of some of the variables. [sent-255, score-0.225]
</p><p>91 Hence, the dialogues are adversarial, but cooperative under our characterisation of linguistic non-cooperation, and it is not clear how effectively the model accounts for cases in which participants fail to follow the rules of a scenario. [sent-256, score-0.202]
</p><p>92 1 Working Hypothesis Finding a suitable model of non-cooperative dialogue involves bridging the gap between the theoretical aspects mentioned so far and the evidence in the empirical data of the previous section. [sent-258, score-0.299]
</p><p>93 Thus, a participant with high priorities for in-  dividual goals might compromise the workings of a conversation by choosing contributions that go against the norms of the social activity. [sent-260, score-0.439]
</p><p>94 On the other hand, participants with higher priorities associated with obligations will favour contributions consistent with the rules of the social activity. [sent-261, score-0.408]
</p><p>95 9The use of simulation in dialogue modeling was pioneered by Power (1979). [sent-268, score-0.299]
</p><p>96 , Wizard-of-Oz, dialogue systems), by making it easier to introduce modifications, do re-runs, and generate a large number of cases with different parameter settings. [sent-271, score-0.299]
</p><p>97 moment of writing, we are investigating the line  of research on obligation-driven dialogue modeling, initiated by Traum and Allen (1994) and developed further by Poesio and Traum (1998) and Kreutel and Matheson (2003). [sent-272, score-0.299]
</p><p>98 For the simulation, DPs will be autonomous conversational agents with a cognitive state consisting of goals, a notion of their expected behaviour in a political interview, priorities, and some knowledge of the world. [sent-273, score-0.445]
</p><p>99 5  Conclusions  In this paper we presented an attempt to shed light on non-cooperation in dialogue by proposing a practical measure of the degree of linguistic noncooperation in political interviews and a methodology towards a suitable computational model. [sent-276, score-0.735]
</p><p>100 Incremental information state updates in an obligation-driven dialogue model. [sent-355, score-0.299]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('overrule', 0.34), ('dialogue', 0.299), ('paxman', 0.284), ('howard', 0.27), ('cooperation', 0.265), ('threaten', 0.197), ('interviews', 0.188), ('political', 0.172), ('ncfs', 0.17), ('derek', 0.151), ('dnc', 0.151), ('dps', 0.151), ('obligations', 0.151), ('conversation', 0.149), ('traum', 0.135), ('conversational', 0.13), ('behaviour', 0.114), ('adversarial', 0.095), ('participants', 0.092), ('social', 0.089), ('goals', 0.089), ('allen', 0.086), ('entitled', 0.083), ('priorities', 0.076), ('conflictive', 0.076), ('noncooperation', 0.076), ('walton', 0.076), ('cooperative', 0.071), ('overlapping', 0.069), ('instruct', 0.061), ('situations', 0.06), ('uc', 0.059), ('interview', 0.057), ('idid', 0.057), ('interviewee', 0.057), ('krabbe', 0.057), ('marriott', 0.057), ('threatened', 0.057), ('intentions', 0.054), ('grounding', 0.051), ('gf', 0.051), ('matheson', 0.05), ('interrupting', 0.05), ('witness', 0.05), ('lewis', 0.043), ('heritage', 0.043), ('games', 0.042), ('pragmatics', 0.042), ('acknowledged', 0.04), ('dialogues', 0.039), ('acts', 0.038), ('ascription', 0.038), ('blaylock', 0.038), ('courtroom', 0.038), ('deception', 0.038), ('dismiss', 0.038), ('inote', 0.038), ('interrogation', 0.038), ('kreutel', 0.038), ('newsnight', 0.038), ('overlappling', 0.038), ('schaefer', 0.038), ('secretary', 0.038), ('unsolicited', 0.038), ('participant', 0.036), ('house', 0.034), ('collaborative', 0.034), ('plans', 0.033), ('collaboration', 0.033), ('trains', 0.033), ('perlocutionary', 0.033), ('cooperate', 0.033), ('triggering', 0.033), ('powers', 0.033), ('prison', 0.033), ('divert', 0.033), ('interlocutors', 0.033), ('interviewees', 0.033), ('utterances', 0.032), ('exchange', 0.031), ('taylor', 0.031), ('poesio', 0.031), ('questions', 0.031), ('belief', 0.031), ('maintenance', 0.03), ('everyday', 0.03), ('jeremy', 0.03), ('bbc', 0.03), ('reed', 0.03), ('sacks', 0.03), ('rejecting', 0.03), ('accept', 0.029), ('notion', 0.029), ('flow', 0.029), ('asking', 0.029), ('irs', 0.028), ('grosz', 0.028), ('iwill', 0.028), ('recognise', 0.028), ('approaching', 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="178-tfidf-1" href="./acl-2010-Non-Cooperation_in_Dialogue.html">178 acl-2010-Non-Cooperation in Dialogue</a></p>
<p>Author: Brian Pluss</p><p>Abstract: This paper presents ongoing research on computational models for non-cooperative dialogue. We start by analysing different levels of cooperation in conversation. Then, inspired by findings from an empirical study, we propose a technique for measuring non-cooperation in political interviews. Finally, we describe a research programme towards obtaining a suitable model and discuss previous accounts for conflictive dialogue, identifying the differences with our work.</p><p>2 0.16036603 <a title="178-tfidf-2" href="./acl-2010-Towards_Relational_POMDPs_for_Adaptive_Dialogue_Management.html">239 acl-2010-Towards Relational POMDPs for Adaptive Dialogue Management</a></p>
<p>Author: Pierre Lison</p><p>Abstract: Open-ended spoken interactions are typically characterised by both structural complexity and high levels of uncertainty, making dialogue management in such settings a particularly challenging problem. Traditional approaches have focused on providing theoretical accounts for either the uncertainty or the complexity of spoken dialogue, but rarely considered the two issues simultaneously. This paper describes ongoing work on a new approach to dialogue management which attempts to fill this gap. We represent the interaction as a Partially Observable Markov Decision Process (POMDP) over a rich state space incorporating both dialogue, user, and environment models. The tractability of the resulting POMDP can be preserved using a mechanism for dynamically constraining the action space based on prior knowledge over locally relevant dialogue structures. These constraints are encoded in a small set of general rules expressed as a Markov Logic network. The first-order expressivity of Markov Logic enables us to leverage the rich relational structure of the problem and efficiently abstract over large regions ofthe state and action spaces.</p><p>3 0.13451955 <a title="178-tfidf-3" href="./acl-2010-Learning_to_Adapt_to_Unknown_Users%3A_Referring_Expression_Generation_in_Spoken_Dialogue_Systems.html">167 acl-2010-Learning to Adapt to Unknown Users: Referring Expression Generation in Spoken Dialogue Systems</a></p>
<p>Author: Srinivasan Janarthanam ; Oliver Lemon</p><p>Abstract: We present a data-driven approach to learn user-adaptive referring expression generation (REG) policies for spoken dialogue systems. Referring expressions can be difficult to understand in technical domains where users may not know the technical ‘jargon’ names of the domain entities. In such cases, dialogue systems must be able to model the user’s (lexical) domain knowledge and use appropriate referring expressions. We present a reinforcement learning (RL) framework in which the sys- tem learns REG policies which can adapt to unknown users online. Furthermore, unlike supervised learning methods which require a large corpus of expert adaptive behaviour to train on, we show that effective adaptive policies can be learned from a small dialogue corpus of non-adaptive human-machine interaction, by using a RL framework and a statistical user simulation. We show that in comparison to adaptive hand-coded baseline policies, the learned policy performs significantly better, with an 18.6% average increase in adaptation accuracy. The best learned policy also takes less dialogue time (average 1.07 min less) than the best hand-coded policy. This is because the learned policies can adapt online to changing evidence about the user’s domain expertise.</p><p>4 0.12812804 <a title="178-tfidf-4" href="./acl-2010-Modeling_Norms_of_Turn-Taking_in_Multi-Party_Conversation.html">173 acl-2010-Modeling Norms of Turn-Taking in Multi-Party Conversation</a></p>
<p>Author: Kornel Laskowski</p><p>Abstract: Substantial research effort has been invested in recent decades into the computational study and automatic processing of multi-party conversation. While most aspects of conversational speech have benefited from a wide availability of analytic, computationally tractable techniques, only qualitative assessments are available for characterizing multi-party turn-taking. The current paper attempts to address this deficiency by first proposing a framework for computing turn-taking model perplexity, and then by evaluating several multi-participant modeling approaches. Experiments show that direct multi-participant models do not generalize to held out data, and likely never will, for practical reasons. In contrast, the Extended-Degree-of-Overlap model represents a suitable candidate for future work in this area, and is shown to successfully predict the distribution of speech in time and across participants in previously unseen conversations.</p><p>5 0.12533194 <a title="178-tfidf-5" href="./acl-2010-Demonstration_of_a_Prototype_for_a_Conversational_Companion_for_Reminiscing_about_Images.html">82 acl-2010-Demonstration of a Prototype for a Conversational Companion for Reminiscing about Images</a></p>
<p>Author: Yorick Wilks ; Roberta Catizone ; Alexiei Dingli ; Weiwei Cheng</p><p>Abstract: This paper describes an initial prototype demonstrator of a Companion, designed as a platform for novel approaches to the following: 1) The use of Information Extraction (IE) techniques to extract the content of incoming dialogue utterances after an Automatic Speech Recognition (ASR) phase, 2) The conversion of the input to Resource Descriptor Format (RDF) to allow the generation of new facts from existing ones, under the control of a Dialogue Manger (DM), that also has access to stored knowledge and to open knowledge accessed in real time from the web, all in RDF form, 3) A DM implemented as a stack and network virtual machine that models mixed initiative in dialogue control, and 4) A tuned dialogue act detector based on corpus evidence. The prototype platform was evaluated, and we describe this briefly; it is also designed to support more extensive forms of emotion detection carried by both speech and lexical content, as well as extended forms of machine learning.</p><p>6 0.11420868 <a title="178-tfidf-6" href="./acl-2010-Extracting_Social_Networks_from_Literary_Fiction.html">112 acl-2010-Extracting Social Networks from Literary Fiction</a></p>
<p>7 0.10700461 <a title="178-tfidf-7" href="./acl-2010-Beetle_II%3A_A_System_for_Tutoring_and_Computational_Linguistics_Experimentation.html">47 acl-2010-Beetle II: A System for Tutoring and Computational Linguistics Experimentation</a></p>
<p>8 0.10538461 <a title="178-tfidf-8" href="./acl-2010-Importance-Driven_Turn-Bidding_for_Spoken_Dialogue_Systems.html">142 acl-2010-Importance-Driven Turn-Bidding for Spoken Dialogue Systems</a></p>
<p>9 0.094250277 <a title="178-tfidf-9" href="./acl-2010-Optimising_Information_Presentation_for_Spoken_Dialogue_Systems.html">187 acl-2010-Optimising Information Presentation for Spoken Dialogue Systems</a></p>
<p>10 0.093610518 <a title="178-tfidf-10" href="./acl-2010-The_Impact_of_Interpretation_Problems_on_Tutorial_Dialogue.html">227 acl-2010-The Impact of Interpretation Problems on Tutorial Dialogue</a></p>
<p>11 0.093260892 <a title="178-tfidf-11" href="./acl-2010-Classification_of_Feedback_Expressions_in_Multimodal_Data.html">58 acl-2010-Classification of Feedback Expressions in Multimodal Data</a></p>
<p>12 0.08841636 <a title="178-tfidf-12" href="./acl-2010-Now%2C_Where_Was_I%3F_Resumption_Strategies_for_an_In-Vehicle_Dialogue_System.html">179 acl-2010-Now, Where Was I? Resumption Strategies for an In-Vehicle Dialogue System</a></p>
<p>13 0.085445657 <a title="178-tfidf-13" href="./acl-2010-Phrase-Based_Statistical_Language_Generation_Using_Graphical_Models_and_Active_Learning.html">194 acl-2010-Phrase-Based Statistical Language Generation Using Graphical Models and Active Learning</a></p>
<p>14 0.066530928 <a title="178-tfidf-14" href="./acl-2010-A_Game-Theoretic_Model_of_Metaphorical_Bargaining.html">6 acl-2010-A Game-Theoretic Model of Metaphorical Bargaining</a></p>
<p>15 0.065268688 <a title="178-tfidf-15" href="./acl-2010-Decision_Detection_Using_Hierarchical_Graphical_Models.html">81 acl-2010-Decision Detection Using Hierarchical Graphical Models</a></p>
<p>16 0.058571011 <a title="178-tfidf-16" href="./acl-2010-Talking_NPCs_in_a_Virtual_Game_World.html">224 acl-2010-Talking NPCs in a Virtual Game World</a></p>
<p>17 0.055820011 <a title="178-tfidf-17" href="./acl-2010-%22Was_It_Good%3F_It_Was_Provocative.%22_Learning_the_Meaning_of_Scalar_Adjectives.html">2 acl-2010-"Was It Good? It Was Provocative." Learning the Meaning of Scalar Adjectives</a></p>
<p>18 0.050992027 <a title="178-tfidf-18" href="./acl-2010-Incorporating_Extra-Linguistic_Information_into_Reference_Resolution_in_Collaborative_Task_Dialogue.html">149 acl-2010-Incorporating Extra-Linguistic Information into Reference Resolution in Collaborative Task Dialogue</a></p>
<p>19 0.049105011 <a title="178-tfidf-19" href="./acl-2010-Vocabulary_Choice_as_an_Indicator_of_Perspective.html">256 acl-2010-Vocabulary Choice as an Indicator of Perspective</a></p>
<p>20 0.042435881 <a title="178-tfidf-20" href="./acl-2010-Recommendation_in_Internet_Forums_and_Blogs.html">204 acl-2010-Recommendation in Internet Forums and Blogs</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.098), (1, 0.079), (2, -0.075), (3, -0.163), (4, -0.05), (5, -0.172), (6, -0.142), (7, 0.073), (8, -0.048), (9, -0.008), (10, 0.049), (11, -0.053), (12, 0.021), (13, 0.021), (14, 0.021), (15, -0.058), (16, 0.001), (17, 0.019), (18, 0.016), (19, -0.005), (20, -0.046), (21, -0.004), (22, 0.044), (23, -0.022), (24, -0.037), (25, 0.023), (26, -0.011), (27, -0.057), (28, 0.049), (29, -0.081), (30, -0.071), (31, 0.207), (32, 0.035), (33, 0.127), (34, -0.047), (35, -0.056), (36, -0.051), (37, -0.086), (38, -0.028), (39, 0.082), (40, 0.008), (41, -0.022), (42, -0.089), (43, 0.045), (44, 0.131), (45, -0.024), (46, -0.127), (47, -0.081), (48, 0.101), (49, -0.046)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96835953 <a title="178-lsi-1" href="./acl-2010-Non-Cooperation_in_Dialogue.html">178 acl-2010-Non-Cooperation in Dialogue</a></p>
<p>Author: Brian Pluss</p><p>Abstract: This paper presents ongoing research on computational models for non-cooperative dialogue. We start by analysing different levels of cooperation in conversation. Then, inspired by findings from an empirical study, we propose a technique for measuring non-cooperation in political interviews. Finally, we describe a research programme towards obtaining a suitable model and discuss previous accounts for conflictive dialogue, identifying the differences with our work.</p><p>2 0.73587269 <a title="178-lsi-2" href="./acl-2010-Now%2C_Where_Was_I%3F_Resumption_Strategies_for_an_In-Vehicle_Dialogue_System.html">179 acl-2010-Now, Where Was I? Resumption Strategies for an In-Vehicle Dialogue System</a></p>
<p>Author: Jessica Villing</p><p>Abstract: In-vehicle dialogue systems often contain more than one application, e.g. a navigation and a telephone application. This means that the user might, for example, interrupt the interaction with the telephone application to ask for directions from the navigation application, and then resume the dialogue with the telephone application. In this paper we present an analysis of interruption and resumption behaviour in human-human in-vehicle dialogues and also propose some implications for resumption strategies in an in-vehicle dialogue system.</p><p>3 0.72854078 <a title="178-lsi-3" href="./acl-2010-Towards_Relational_POMDPs_for_Adaptive_Dialogue_Management.html">239 acl-2010-Towards Relational POMDPs for Adaptive Dialogue Management</a></p>
<p>Author: Pierre Lison</p><p>Abstract: Open-ended spoken interactions are typically characterised by both structural complexity and high levels of uncertainty, making dialogue management in such settings a particularly challenging problem. Traditional approaches have focused on providing theoretical accounts for either the uncertainty or the complexity of spoken dialogue, but rarely considered the two issues simultaneously. This paper describes ongoing work on a new approach to dialogue management which attempts to fill this gap. We represent the interaction as a Partially Observable Markov Decision Process (POMDP) over a rich state space incorporating both dialogue, user, and environment models. The tractability of the resulting POMDP can be preserved using a mechanism for dynamically constraining the action space based on prior knowledge over locally relevant dialogue structures. These constraints are encoded in a small set of general rules expressed as a Markov Logic network. The first-order expressivity of Markov Logic enables us to leverage the rich relational structure of the problem and efficiently abstract over large regions ofthe state and action spaces.</p><p>4 0.67012411 <a title="178-lsi-4" href="./acl-2010-Demonstration_of_a_Prototype_for_a_Conversational_Companion_for_Reminiscing_about_Images.html">82 acl-2010-Demonstration of a Prototype for a Conversational Companion for Reminiscing about Images</a></p>
<p>Author: Yorick Wilks ; Roberta Catizone ; Alexiei Dingli ; Weiwei Cheng</p><p>Abstract: This paper describes an initial prototype demonstrator of a Companion, designed as a platform for novel approaches to the following: 1) The use of Information Extraction (IE) techniques to extract the content of incoming dialogue utterances after an Automatic Speech Recognition (ASR) phase, 2) The conversion of the input to Resource Descriptor Format (RDF) to allow the generation of new facts from existing ones, under the control of a Dialogue Manger (DM), that also has access to stored knowledge and to open knowledge accessed in real time from the web, all in RDF form, 3) A DM implemented as a stack and network virtual machine that models mixed initiative in dialogue control, and 4) A tuned dialogue act detector based on corpus evidence. The prototype platform was evaluated, and we describe this briefly; it is also designed to support more extensive forms of emotion detection carried by both speech and lexical content, as well as extended forms of machine learning.</p><p>5 0.63796824 <a title="178-lsi-5" href="./acl-2010-Decision_Detection_Using_Hierarchical_Graphical_Models.html">81 acl-2010-Decision Detection Using Hierarchical Graphical Models</a></p>
<p>Author: Trung H. Bui ; Stanley Peters</p><p>Abstract: We investigate hierarchical graphical models (HGMs) for automatically detecting decisions in multi-party discussions. Several types of dialogue act (DA) are distinguished on the basis of their roles in formulating decisions. HGMs enable us to model dependencies between observed features of discussions, decision DAs, and subdialogues that result in a decision. For the task of detecting decision regions, an HGM classifier was found to outperform non-hierarchical graphical models and support vector machines, raising the F1-score to 0.80 from 0.55.</p><p>6 0.61922824 <a title="178-lsi-6" href="./acl-2010-Classification_of_Feedback_Expressions_in_Multimodal_Data.html">58 acl-2010-Classification of Feedback Expressions in Multimodal Data</a></p>
<p>7 0.61727595 <a title="178-lsi-7" href="./acl-2010-Extracting_Social_Networks_from_Literary_Fiction.html">112 acl-2010-Extracting Social Networks from Literary Fiction</a></p>
<p>8 0.59448397 <a title="178-lsi-8" href="./acl-2010-Importance-Driven_Turn-Bidding_for_Spoken_Dialogue_Systems.html">142 acl-2010-Importance-Driven Turn-Bidding for Spoken Dialogue Systems</a></p>
<p>9 0.59168684 <a title="178-lsi-9" href="./acl-2010-Modeling_Norms_of_Turn-Taking_in_Multi-Party_Conversation.html">173 acl-2010-Modeling Norms of Turn-Taking in Multi-Party Conversation</a></p>
<p>10 0.53359425 <a title="178-lsi-10" href="./acl-2010-Phrase-Based_Statistical_Language_Generation_Using_Graphical_Models_and_Active_Learning.html">194 acl-2010-Phrase-Based Statistical Language Generation Using Graphical Models and Active Learning</a></p>
<p>11 0.44808871 <a title="178-lsi-11" href="./acl-2010-Talking_NPCs_in_a_Virtual_Game_World.html">224 acl-2010-Talking NPCs in a Virtual Game World</a></p>
<p>12 0.44745722 <a title="178-lsi-12" href="./acl-2010-Learning_to_Adapt_to_Unknown_Users%3A_Referring_Expression_Generation_in_Spoken_Dialogue_Systems.html">167 acl-2010-Learning to Adapt to Unknown Users: Referring Expression Generation in Spoken Dialogue Systems</a></p>
<p>13 0.43798417 <a title="178-lsi-13" href="./acl-2010-Optimising_Information_Presentation_for_Spoken_Dialogue_Systems.html">187 acl-2010-Optimising Information Presentation for Spoken Dialogue Systems</a></p>
<p>14 0.40003511 <a title="178-lsi-14" href="./acl-2010-Recommendation_in_Internet_Forums_and_Blogs.html">204 acl-2010-Recommendation in Internet Forums and Blogs</a></p>
<p>15 0.33459079 <a title="178-lsi-15" href="./acl-2010-Beetle_II%3A_A_System_for_Tutoring_and_Computational_Linguistics_Experimentation.html">47 acl-2010-Beetle II: A System for Tutoring and Computational Linguistics Experimentation</a></p>
<p>16 0.29751039 <a title="178-lsi-16" href="./acl-2010-The_Impact_of_Interpretation_Problems_on_Tutorial_Dialogue.html">227 acl-2010-The Impact of Interpretation Problems on Tutorial Dialogue</a></p>
<p>17 0.29690641 <a title="178-lsi-17" href="./acl-2010-Mood_Patterns_and_Affective_Lexicon_Access_in_Weblogs.html">176 acl-2010-Mood Patterns and Affective Lexicon Access in Weblogs</a></p>
<p>18 0.28997222 <a title="178-lsi-18" href="./acl-2010-Combining_Data_and_Mathematical_Models_of_Language_Change.html">61 acl-2010-Combining Data and Mathematical Models of Language Change</a></p>
<p>19 0.28672886 <a title="178-lsi-19" href="./acl-2010-Correcting_Errors_in_Speech_Recognition_with_Articulatory_Dynamics.html">74 acl-2010-Correcting Errors in Speech Recognition with Articulatory Dynamics</a></p>
<p>20 0.28407276 <a title="178-lsi-20" href="./acl-2010-Using_Speech_to_Reply_to_SMS_Messages_While_Driving%3A_An_In-Car_Simulator_User_Study.html">254 acl-2010-Using Speech to Reply to SMS Messages While Driving: An In-Car Simulator User Study</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.016), (25, 0.043), (39, 0.011), (42, 0.542), (45, 0.011), (59, 0.04), (72, 0.017), (73, 0.024), (78, 0.02), (83, 0.085), (84, 0.021), (98, 0.067)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91345495 <a title="178-lda-1" href="./acl-2010-Non-Cooperation_in_Dialogue.html">178 acl-2010-Non-Cooperation in Dialogue</a></p>
<p>Author: Brian Pluss</p><p>Abstract: This paper presents ongoing research on computational models for non-cooperative dialogue. We start by analysing different levels of cooperation in conversation. Then, inspired by findings from an empirical study, we propose a technique for measuring non-cooperation in political interviews. Finally, we describe a research programme towards obtaining a suitable model and discuss previous accounts for conflictive dialogue, identifying the differences with our work.</p><p>2 0.83886975 <a title="178-lda-2" href="./acl-2010-Incorporating_Extra-Linguistic_Information_into_Reference_Resolution_in_Collaborative_Task_Dialogue.html">149 acl-2010-Incorporating Extra-Linguistic Information into Reference Resolution in Collaborative Task Dialogue</a></p>
<p>Author: Ryu Iida ; Syumpei Kobayashi ; Takenobu Tokunaga</p><p>Abstract: This paper proposes an approach to reference resolution in situated dialogues by exploiting extra-linguistic information. Recently, investigations of referential behaviours involved in situations in the real world have received increasing attention by researchers (Di Eugenio et al., 2000; Byron, 2005; van Deemter, 2007; Spanger et al., 2009). In order to create an accurate reference resolution model, we need to handle extra-linguistic information as well as textual information examined by existing approaches (Soon et al., 2001 ; Ng and Cardie, 2002, etc.). In this paper, we incorporate extra-linguistic information into an existing corpus-based reference resolution model, and investigate its effects on refer- ence resolution problems within a corpus of Japanese dialogues. The results demonstrate that our proposed model achieves an accuracy of 79.0% for this task.</p><p>3 0.74786949 <a title="178-lda-3" href="./acl-2010-Generating_Focused_Topic-Specific_Sentiment_Lexicons.html">123 acl-2010-Generating Focused Topic-Specific Sentiment Lexicons</a></p>
<p>Author: Valentin Jijkoun ; Maarten de Rijke ; Wouter Weerkamp</p><p>Abstract: We present a method for automatically generating focused and accurate topicspecific subjectivity lexicons from a general purpose polarity lexicon that allow users to pin-point subjective on-topic information in a set of relevant documents. We motivate the need for such lexicons in the field of media analysis, describe a bootstrapping method for generating a topic-specific lexicon from a general purpose polarity lexicon, and evaluate the quality of the generated lexicons both manually and using a TREC Blog track test set for opinionated blog post retrieval. Although the generated lexicons can be an order of magnitude more selective than the general purpose lexicon, they maintain, or even improve, the performance of an opin- ion retrieval system.</p><p>4 0.64372623 <a title="178-lda-4" href="./acl-2010-Inducing_Domain-Specific_Semantic_Class_Taggers_from_%28Almost%29_Nothing.html">150 acl-2010-Inducing Domain-Specific Semantic Class Taggers from (Almost) Nothing</a></p>
<p>Author: Ruihong Huang ; Ellen Riloff</p><p>Abstract: This research explores the idea of inducing domain-specific semantic class taggers using only a domain-specific text collection and seed words. The learning process begins by inducing a classifier that only has access to contextual features, forcing it to generalize beyond the seeds. The contextual classifier then labels new instances, to expand and diversify the training set. Next, a cross-category bootstrapping process simultaneously trains a suite of classifiers for multiple semantic classes. The positive instances for one class are used as negative instances for the others in an iterative bootstrapping cycle. We also explore a one-semantic-class-per-discourse heuristic, and use the classifiers to dynam- ically create semantic features. We evaluate our approach by inducing six semantic taggers from a collection of veterinary medicine message board posts.</p><p>5 0.54607904 <a title="178-lda-5" href="./acl-2010-Sparsity_in_Dependency_Grammar_Induction.html">214 acl-2010-Sparsity in Dependency Grammar Induction</a></p>
<p>Author: Jennifer Gillenwater ; Kuzman Ganchev ; Joao Graca ; Fernando Pereira ; Ben Taskar</p><p>Abstract: A strong inductive bias is essential in unsupervised grammar induction. We explore a particular sparsity bias in dependency grammars that encourages a small number of unique dependency types. Specifically, we investigate sparsity-inducing penalties on the posterior distributions of parent-child POS tag pairs in the posterior regularization (PR) framework of Graça et al. (2007). In ex- periments with 12 languages, we achieve substantial gains over the standard expectation maximization (EM) baseline, with average improvement in attachment accuracy of 6.3%. Further, our method outperforms models based on a standard Bayesian sparsity-inducing prior by an average of 4.9%. On English in particular, we show that our approach improves on several other state-of-the-art techniques.</p><p>6 0.53766263 <a title="178-lda-6" href="./acl-2010-The_Prevalence_of_Descriptive_Referring_Expressions_in_News_and_Narrative.html">231 acl-2010-The Prevalence of Descriptive Referring Expressions in News and Narrative</a></p>
<p>7 0.5219807 <a title="178-lda-7" href="./acl-2010-A_Unified_Graph_Model_for_Sentence-Based_Opinion_Retrieval.html">22 acl-2010-A Unified Graph Model for Sentence-Based Opinion Retrieval</a></p>
<p>8 0.51075953 <a title="178-lda-8" href="./acl-2010-Using_Anaphora_Resolution_to_Improve_Opinion_Target_Identification_in_Movie_Reviews.html">251 acl-2010-Using Anaphora Resolution to Improve Opinion Target Identification in Movie Reviews</a></p>
<p>9 0.50378519 <a title="178-lda-9" href="./acl-2010-Sentence_and_Expression_Level_Annotation_of_Opinions_in_User-Generated_Discourse.html">208 acl-2010-Sentence and Expression Level Annotation of Opinions in User-Generated Discourse</a></p>
<p>10 0.47983184 <a title="178-lda-10" href="./acl-2010-Hierarchical_Sequential_Learning_for_Extracting_Opinions_and_Their_Attributes.html">134 acl-2010-Hierarchical Sequential Learning for Extracting Opinions and Their Attributes</a></p>
<p>11 0.4425149 <a title="178-lda-11" href="./acl-2010-Learning_to_Adapt_to_Unknown_Users%3A_Referring_Expression_Generation_in_Spoken_Dialogue_Systems.html">167 acl-2010-Learning to Adapt to Unknown Users: Referring Expression Generation in Spoken Dialogue Systems</a></p>
<p>12 0.38519555 <a title="178-lda-12" href="./acl-2010-Classification_of_Feedback_Expressions_in_Multimodal_Data.html">58 acl-2010-Classification of Feedback Expressions in Multimodal Data</a></p>
<p>13 0.37840939 <a title="178-lda-13" href="./acl-2010-Automatically_Generating_Annotator_Rationales_to_Improve_Sentiment_Classification.html">42 acl-2010-Automatically Generating Annotator Rationales to Improve Sentiment Classification</a></p>
<p>14 0.37274292 <a title="178-lda-14" href="./acl-2010-Mood_Patterns_and_Affective_Lexicon_Access_in_Weblogs.html">176 acl-2010-Mood Patterns and Affective Lexicon Access in Weblogs</a></p>
<p>15 0.36714837 <a title="178-lda-15" href="./acl-2010-Preferences_versus_Adaptation_during_Referring_Expression_Generation.html">199 acl-2010-Preferences versus Adaptation during Referring Expression Generation</a></p>
<p>16 0.36259216 <a title="178-lda-16" href="./acl-2010-Importance-Driven_Turn-Bidding_for_Spoken_Dialogue_Systems.html">142 acl-2010-Importance-Driven Turn-Bidding for Spoken Dialogue Systems</a></p>
<p>17 0.36143225 <a title="178-lda-17" href="./acl-2010-Supervised_Noun_Phrase_Coreference_Research%3A_The_First_Fifteen_Years.html">219 acl-2010-Supervised Noun Phrase Coreference Research: The First Fifteen Years</a></p>
<p>18 0.35900638 <a title="178-lda-18" href="./acl-2010-Extracting_Social_Networks_from_Literary_Fiction.html">112 acl-2010-Extracting Social Networks from Literary Fiction</a></p>
<p>19 0.35210088 <a title="178-lda-19" href="./acl-2010-Now%2C_Where_Was_I%3F_Resumption_Strategies_for_an_In-Vehicle_Dialogue_System.html">179 acl-2010-Now, Where Was I? Resumption Strategies for an In-Vehicle Dialogue System</a></p>
<p>20 0.35176161 <a title="178-lda-20" href="./acl-2010-Assessing_the_Role_of_Discourse_References_in_Entailment_Inference.html">33 acl-2010-Assessing the Role of Discourse References in Entailment Inference</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
