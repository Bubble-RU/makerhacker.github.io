<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>228 acl-2010-The Importance of Rule Restrictions in CCG</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-228" href="#">acl2010-228</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>228 acl-2010-The Importance of Rule Restrictions in CCG</h1>
<br/><p>Source: <a title="acl-2010-228-pdf" href="http://aclweb.org/anthology//P/P10/P10-1055.pdf">pdf</a></p><p>Author: Marco Kuhlmann ; Alexander Koller ; Giorgio Satta</p><p>Abstract: Combinatory Categorial Grammar (CCG) is generally construed as a fully lexicalized formalism, where all grammars use one and the same universal set of rules, and crosslinguistic variation is isolated in the lexicon. In this paper, we show that the weak generative capacity of this ‘pure’ form of CCG is strictly smaller than that of CCG with grammar-specific rules, and of other mildly context-sensitive grammar formalisms, including Tree Adjoining Grammar (TAG). Our result also carries over to a multi-modal extension of CCG.</p><p>Reference: <a title="acl-2010-228-reference" href="../acl2010_reference/acl-2010-The_Importance_of_Rule_Restrictions_in_CCG_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In this paper, we show that the weak generative capacity of this ‘pure’ form of CCG is strictly smaller than that of CCG with grammar-specific rules, and of other mildly context-sensitive grammar formalisms, including Tree Adjoining Grammar (TAG). [sent-4, score-0.524]
</p><p>2 Our result also carries over to a multi-modal extension of CCG. [sent-5, score-0.085]
</p><p>3 1 Introduction Combinatory Categorial Grammar (CCG) (Steedman, 2001 ; Steedman and Baldridge, 2010) is an  expressive grammar formalism with formal roots in combinatory logic (Curry et al. [sent-6, score-0.493]
</p><p>4 , 1958) and links to the type-logical tradition of categorial grammar (Moortgat, 1997). [sent-7, score-0.237]
</p><p>5 It has been successfully used for a wide range of practical tasks, such as data-driven parsing (Hockenmaier and Steedman, 2002; Clark and Curran, 2007), wide-coverage semantic construction (Bos et al. [sent-8, score-0.027]
</p><p>6 , 2004), and the modelling of syntactic priming (Reitter et al. [sent-9, score-0.035]
</p><p>7 It is well-known that CCG can generate languages that are not context-free (which is necessary to capture natural languages), but can still be parsed in polynomial time. [sent-11, score-0.071]
</p><p>8 Specifically, VijayShanker and Weir (1994) identified a version of CCG that is weakly equivalent to Tree Adjoining Grammar (TAG) (Joshi and Schabes, 1997) and other mildly context-sensitive grammar formalisms, and can generate non-context-free languages such as anbncn . [sent-12, score-0.369]
</p><p>9 The generative capacity of CCG is commonly attributed to its flexible composition rules, which allow it to model more complex word orders that context-free grammar can. [sent-13, score-0.486]
</p><p>10 The discussion of the (weak and strong) gener-  ative capacity of CCG and TAG has recently been revived (Hockenmaier and Young, 2008; Koller and Kuhlmann, 2009). [sent-14, score-0.246]
</p><p>11 In particular, Koller and Kuhlmann (2009) have shown that CCGs that are pure (i. [sent-15, score-0.314]
</p><p>12 , they can only use generalized composition rules, and there is no way to restrict the instances of these rules that may be used) and first-order (i. [sent-17, score-0.243]
</p><p>13 , all argument categories are atomic) can not generate anbncn . [sent-19, score-0.265]
</p><p>14 This shows that the generative capacity of at least first-order CCG crucially relies on its ability to restrict rule instantiations, and is at odds with the general conception of CCG as a fully lexicalized formalism, in which all grammars use one and the same set of universal rules. [sent-20, score-0.629]
</p><p>15 A question then is whether the result carries over to pure CCG with higher-order categories. [sent-21, score-0.37]
</p><p>16 Our technical result is that every lan-  guage L that can be generated by a pure CCG has a context-free sublanguage L0 ? [sent-23, score-0.314]
</p><p>17 L such that every string in L is a permutation of? [sent-24, score-0.129]
</p><p>18 This means that anbncn , for instance, cannot be generated by pure CCG, as it does not have any (non-trivial) permutation-equivalent sublanguages. [sent-26, score-0.47]
</p><p>19 Conversely, we show that there are still languages that can be generated by pure CCG but not by context-free grammar. [sent-27, score-0.385]
</p><p>20 We then show that our permutation language lemma also holds for pure multi-modal CCG as defined by Baldridge and Kruijff (2003), in which the use of rules can be controlled through the lexicon entries by assigning types to slashes. [sent-28, score-0.491]
</p><p>21 Since this extension was intended to do away with the need for grammar-specific rule restrictions, it comes as quite a surprise that pure multi-modal 534  Proce dinUgsp osfa tlhae, 4S8wthed Aen n,u 1a1l-1 M6e Jeutilnyg 2 o0f1 t0h. [sent-29, score-0.422]
</p><p>22 c As2s0o1c0ia Atisosnoc foiart Cionom fopru Ctaotmiopnuatla Lti on gaulis Lti cnsg,u piasgtiecs 534–543, CCG in the style of Baldridge and Kruijff (2003) is still less expressive than the CCG formalism used by Vijay-Shanker and Weir (1994). [sent-31, score-0.238]
</p><p>23 This means that word order in CCG cannot be fully lexicalized with  the current formal tools; some ordering constraints must be specified via language-specific combination rules and not in lexicon entries. [sent-32, score-0.201]
</p><p>24 On the other hand, as pure multi-modal CCG has been successfully applied to model the syntax of a variety of natural languages, another way to read our results is as contributions to a discussion about the exact expressiveness needed to model natural language. [sent-33, score-0.407]
</p><p>25 The remainder of this paper is structured as follows. [sent-34, score-0.043]
</p><p>26 In Section 2, we introduce the formalism of pure CCG that we consider in this paper, and illustrate the relevance of rule restrictions. [sent-35, score-0.559]
</p><p>27 We then study the generative capacity of pure CCG in Section 3; this section also presents our main result. [sent-36, score-0.564]
</p><p>28 In Section 4, we show that this result still holds for multi-modal CCG. [sent-37, score-0.064]
</p><p>29 Section 5 concludes the paper with a discussion of the relevance of our findings. [sent-38, score-0.089]
</p><p>30 2  Combinatory Categorial Grammar  We start by providing formal definitions for categories, syntactic rules, and grammars, and then discuss the relevance of rule restrictions for CCG. [sent-39, score-0.215]
</p><p>31 1 Categories Given a finite set A of atomic categories, the set of categories over A is the smallest set C such that A ? [sent-41, score-0.189]
</p><p>32 AA category represents a Cfunction that see2ks C a string with category y to the right (indicated by the forward slash) and returns a new string with category x; a category instead seeks its argument to otrhye xle; fat (indicated by nthstee abda csekewkasr idts slash). [sent-45, score-0.782]
</p><p>33 nInt the remainder of this paper, we use lowercase sansserif letters such as x; y; z as variables for categories, and the vertical bar j as a variable for slashes. [sent-46, score-0.141]
</p><p>34 In order to save some parentheses, we understand slashes as left-associative operators, and write a category such as . [sent-47, score-0.161]
</p><p>35 x=y/nz as The list of arguments of a category c is defined recursively as follows: If c is atomic, then it has no arguments. [sent-48, score-0.186]
</p><p>36 If c D xjy for some categories x and y, then the arguments ojf c are the slashed category jy, plus the arguments of x. [sent-49, score-0.327]
</p><p>37 We number the arguments of a category from outermost to innermost. [sent-50, score-0.231]
</p><p>38 The arity of a category is the number of its arguments. [sent-51, score-0.166]
</p><p>39 The target of a category c is the atomic category  x=y  xny  x=ynz. [sent-52, score-0.569]
</p><p>40 x=y y ) x forward application > y xny ) x backward application < x=y y=z ) x=z forward harmonic composition >B ynz xny ) xnz backward harmonic composition  B? [sent-54, score-1.094]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ccg', 0.663), ('pure', 0.314), ('xny', 0.208), ('capacity', 0.178), ('anbncn', 0.156), ('composition', 0.139), ('formalism', 0.137), ('category', 0.127), ('kuhlmann', 0.117), ('combinatory', 0.115), ('atomic', 0.107), ('categorial', 0.105), ('grammar', 0.097), ('weir', 0.094), ('baldridge', 0.092), ('padua', 0.091), ('slash', 0.091), ('kruijff', 0.091), ('categories', 0.082), ('koller', 0.082), ('steedman', 0.08), ('backward', 0.08), ('mildly', 0.074), ('permutation', 0.074), ('expressive', 0.072), ('generative', 0.072), ('rules', 0.068), ('restrictions', 0.065), ('forward', 0.064), ('weak', 0.062), ('hockenmaier', 0.061), ('adjoining', 0.061), ('relevance', 0.06), ('uppsala', 0.059), ('arguments', 0.059), ('lexicalized', 0.057), ('harmonic', 0.056), ('carries', 0.056), ('string', 0.055), ('formalisms', 0.051), ('universal', 0.05), ('rule', 0.048), ('philology', 0.045), ('ccgs', 0.045), ('moortgat', 0.045), ('outermost', 0.045), ('nint', 0.045), ('stripping', 0.045), ('grammars', 0.043), ('remainder', 0.043), ('languages', 0.042), ('formal', 0.042), ('fat', 0.042), ('jy', 0.042), ('curry', 0.042), ('conception', 0.042), ('odds', 0.042), ('strictly', 0.041), ('ative', 0.039), ('vijayshanker', 0.039), ('arity', 0.039), ('xle', 0.039), ('tag', 0.038), ('crossed', 0.037), ('expressiveness', 0.037), ('restrict', 0.036), ('construed', 0.035), ('crosslinguistic', 0.035), ('tradition', 0.035), ('priming', 0.035), ('holds', 0.035), ('indicated', 0.035), ('fully', 0.034), ('save', 0.034), ('italy', 0.034), ('bar', 0.034), ('lowercase', 0.033), ('giorgio', 0.033), ('schabes', 0.033), ('vertical', 0.031), ('surprise', 0.031), ('seeks', 0.031), ('satta', 0.031), ('sweden', 0.031), ('isolated', 0.03), ('roots', 0.03), ('discussion', 0.029), ('operators', 0.029), ('bos', 0.029), ('instantiations', 0.029), ('excellence', 0.029), ('joshi', 0.029), ('still', 0.029), ('extension', 0.029), ('vice', 0.028), ('parentheses', 0.028), ('argument', 0.027), ('successfully', 0.027), ('crucially', 0.027), ('saarbr', 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="228-tfidf-1" href="./acl-2010-The_Importance_of_Rule_Restrictions_in_CCG.html">228 acl-2010-The Importance of Rule Restrictions in CCG</a></p>
<p>Author: Marco Kuhlmann ; Alexander Koller ; Giorgio Satta</p><p>Abstract: Combinatory Categorial Grammar (CCG) is generally construed as a fully lexicalized formalism, where all grammars use one and the same universal set of rules, and crosslinguistic variation is isolated in the lexicon. In this paper, we show that the weak generative capacity of this ‘pure’ form of CCG is strictly smaller than that of CCG with grammar-specific rules, and of other mildly context-sensitive grammar formalisms, including Tree Adjoining Grammar (TAG). Our result also carries over to a multi-modal extension of CCG.</p><p>2 0.46147788 <a title="228-tfidf-2" href="./acl-2010-Accurate_Context-Free_Parsing_with_Combinatory_Categorial_Grammar.html">23 acl-2010-Accurate Context-Free Parsing with Combinatory Categorial Grammar</a></p>
<p>Author: Timothy A. D. Fowler ; Gerald Penn</p><p>Abstract: The definition of combinatory categorial grammar (CCG) in the literature varies quite a bit from author to author. However, the differences between the definitions are important in terms of the language classes of each CCG. We prove that a wide range of CCGs are strongly context-free, including the CCG of CCGbank and of the parser of Clark and Curran (2007). In light of these new results, we train the PCFG parser of Petrov and Klein (2007) on CCGbank and achieve state of the art results in supertagging accuracy, PARSEVAL measures and dependency accuracy.</p><p>3 0.23250388 <a title="228-tfidf-3" href="./acl-2010-Wide-Coverage_NLP_with_Linguistically_Expressive_Grammars.html">260 acl-2010-Wide-Coverage NLP with Linguistically Expressive Grammars</a></p>
<p>Author: Julia Hockenmaier ; Yusuke Miyao ; Josef van Genabith</p><p>Abstract: unkown-abstract</p><p>4 0.2077097 <a title="228-tfidf-4" href="./acl-2010-Rebanking_CCGbank_for_Improved_NP_Interpretation.html">203 acl-2010-Rebanking CCGbank for Improved NP Interpretation</a></p>
<p>Author: Matthew Honnibal ; James R. Curran ; Johan Bos</p><p>Abstract: Once released, treebanks tend to remain unchanged despite any shortcomings in their depth of linguistic analysis or coverage of specific phenomena. Instead, separate resources are created to address such problems. In this paper we show how to improve the quality of a treebank, by integrating resources and implementing improved analyses for specific constructions. We demonstrate this rebanking process by creating an updated version of CCGbank that includes the predicate-argument structure of both verbs and nouns, baseNP brackets, verb-particle constructions, and restrictive and non-restrictive nominal modifiers; and evaluate the impact of these changes on a statistical parser.</p><p>5 0.19560002 <a title="228-tfidf-5" href="./acl-2010-Minimized_Models_and_Grammar-Informed_Initialization_for_Supertagging_with_Highly_Ambiguous_Lexicons.html">172 acl-2010-Minimized Models and Grammar-Informed Initialization for Supertagging with Highly Ambiguous Lexicons</a></p>
<p>Author: Sujith Ravi ; Jason Baldridge ; Kevin Knight</p><p>Abstract: We combine two complementary ideas for learning supertaggers from highly ambiguous lexicons: grammar-informed tag transitions and models minimized via integer programming. Each strategy on its own greatly improves performance over basic expectation-maximization training with a bitag Hidden Markov Model, which we show on the CCGbank and CCG-TUT corpora. The strategies provide further error reductions when combined. We describe a new two-stage integer programming strategy that efficiently deals with the high degree of ambiguity on these datasets while obtaining the full effect of model minimization.</p><p>6 0.14494537 <a title="228-tfidf-6" href="./acl-2010-Faster_Parsing_by_Supertagger_Adaptation.html">114 acl-2010-Faster Parsing by Supertagger Adaptation</a></p>
<p>7 0.085516214 <a title="228-tfidf-7" href="./acl-2010-Fixed_Length_Word_Suffix_for_Factored_Statistical_Machine_Translation.html">119 acl-2010-Fixed Length Word Suffix for Factored Statistical Machine Translation</a></p>
<p>8 0.070404865 <a title="228-tfidf-8" href="./acl-2010-A_Probabilistic_Generative_Model_for_an_Intermediate_Constituency-Dependency_Representation.html">12 acl-2010-A Probabilistic Generative Model for an Intermediate Constituency-Dependency Representation</a></p>
<p>9 0.060509022 <a title="228-tfidf-9" href="./acl-2010-Compositional_Matrix-Space_Models_of_Language.html">66 acl-2010-Compositional Matrix-Space Models of Language</a></p>
<p>10 0.059546523 <a title="228-tfidf-10" href="./acl-2010-Learning_to_Translate_with_Source_and_Target_Syntax.html">169 acl-2010-Learning to Translate with Source and Target Syntax</a></p>
<p>11 0.05760666 <a title="228-tfidf-11" href="./acl-2010-String_Extension_Learning.html">217 acl-2010-String Extension Learning</a></p>
<p>12 0.053999308 <a title="228-tfidf-12" href="./acl-2010-Efficient_Inference_through_Cascades_of_Weighted_Tree_Transducers.html">95 acl-2010-Efficient Inference through Cascades of Weighted Tree Transducers</a></p>
<p>13 0.053451963 <a title="228-tfidf-13" href="./acl-2010-Fully_Unsupervised_Core-Adjunct_Argument_Classification.html">120 acl-2010-Fully Unsupervised Core-Adjunct Argument Classification</a></p>
<p>14 0.053115539 <a title="228-tfidf-14" href="./acl-2010-Fine-Grained_Tree-to-String_Translation_Rule_Extraction.html">118 acl-2010-Fine-Grained Tree-to-String Translation Rule Extraction</a></p>
<p>15 0.051275611 <a title="228-tfidf-15" href="./acl-2010-Bayesian_Synchronous_Tree-Substitution_Grammar_Induction_and_Its_Application_to_Sentence_Compression.html">46 acl-2010-Bayesian Synchronous Tree-Substitution Grammar Induction and Its Application to Sentence Compression</a></p>
<p>16 0.048731428 <a title="228-tfidf-16" href="./acl-2010-Grammar_Prototyping_and_Testing_with_the_LinGO_Grammar_Matrix_Customization_System.html">128 acl-2010-Grammar Prototyping and Testing with the LinGO Grammar Matrix Customization System</a></p>
<p>17 0.047124237 <a title="228-tfidf-17" href="./acl-2010-Hard_Constraints_for_Grammatical_Function_Labelling.html">130 acl-2010-Hard Constraints for Grammatical Function Labelling</a></p>
<p>18 0.045210499 <a title="228-tfidf-18" href="./acl-2010-Learning_Common_Grammar_from_Multilingual_Corpus.html">162 acl-2010-Learning Common Grammar from Multilingual Corpus</a></p>
<p>19 0.044622663 <a title="228-tfidf-19" href="./acl-2010-Detecting_Errors_in_Automatically-Parsed_Dependency_Relations.html">84 acl-2010-Detecting Errors in Automatically-Parsed Dependency Relations</a></p>
<p>20 0.042477138 <a title="228-tfidf-20" href="./acl-2010-Computing_Weakest_Readings.html">67 acl-2010-Computing Weakest Readings</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.118), (1, -0.013), (2, 0.108), (3, -0.027), (4, -0.124), (5, -0.137), (6, 0.224), (7, 0.065), (8, 0.216), (9, -0.062), (10, 0.316), (11, 0.119), (12, -0.276), (13, 0.113), (14, -0.044), (15, 0.034), (16, 0.026), (17, -0.072), (18, -0.117), (19, -0.055), (20, 0.103), (21, -0.141), (22, -0.103), (23, 0.02), (24, -0.001), (25, -0.029), (26, -0.064), (27, -0.038), (28, 0.04), (29, 0.023), (30, -0.025), (31, 0.101), (32, 0.025), (33, 0.017), (34, -0.076), (35, 0.098), (36, 0.054), (37, 0.021), (38, 0.046), (39, 0.009), (40, -0.01), (41, -0.013), (42, -0.025), (43, 0.035), (44, 0.054), (45, 0.067), (46, 0.078), (47, -0.082), (48, -0.039), (49, -0.063)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98117369 <a title="228-lsi-1" href="./acl-2010-The_Importance_of_Rule_Restrictions_in_CCG.html">228 acl-2010-The Importance of Rule Restrictions in CCG</a></p>
<p>Author: Marco Kuhlmann ; Alexander Koller ; Giorgio Satta</p><p>Abstract: Combinatory Categorial Grammar (CCG) is generally construed as a fully lexicalized formalism, where all grammars use one and the same universal set of rules, and crosslinguistic variation is isolated in the lexicon. In this paper, we show that the weak generative capacity of this ‘pure’ form of CCG is strictly smaller than that of CCG with grammar-specific rules, and of other mildly context-sensitive grammar formalisms, including Tree Adjoining Grammar (TAG). Our result also carries over to a multi-modal extension of CCG.</p><p>2 0.90204936 <a title="228-lsi-2" href="./acl-2010-Accurate_Context-Free_Parsing_with_Combinatory_Categorial_Grammar.html">23 acl-2010-Accurate Context-Free Parsing with Combinatory Categorial Grammar</a></p>
<p>Author: Timothy A. D. Fowler ; Gerald Penn</p><p>Abstract: The definition of combinatory categorial grammar (CCG) in the literature varies quite a bit from author to author. However, the differences between the definitions are important in terms of the language classes of each CCG. We prove that a wide range of CCGs are strongly context-free, including the CCG of CCGbank and of the parser of Clark and Curran (2007). In light of these new results, we train the PCFG parser of Petrov and Klein (2007) on CCGbank and achieve state of the art results in supertagging accuracy, PARSEVAL measures and dependency accuracy.</p><p>3 0.65293139 <a title="228-lsi-3" href="./acl-2010-Wide-Coverage_NLP_with_Linguistically_Expressive_Grammars.html">260 acl-2010-Wide-Coverage NLP with Linguistically Expressive Grammars</a></p>
<p>Author: Julia Hockenmaier ; Yusuke Miyao ; Josef van Genabith</p><p>Abstract: unkown-abstract</p><p>4 0.6430319 <a title="228-lsi-4" href="./acl-2010-Rebanking_CCGbank_for_Improved_NP_Interpretation.html">203 acl-2010-Rebanking CCGbank for Improved NP Interpretation</a></p>
<p>Author: Matthew Honnibal ; James R. Curran ; Johan Bos</p><p>Abstract: Once released, treebanks tend to remain unchanged despite any shortcomings in their depth of linguistic analysis or coverage of specific phenomena. Instead, separate resources are created to address such problems. In this paper we show how to improve the quality of a treebank, by integrating resources and implementing improved analyses for specific constructions. We demonstrate this rebanking process by creating an updated version of CCGbank that includes the predicate-argument structure of both verbs and nouns, baseNP brackets, verb-particle constructions, and restrictive and non-restrictive nominal modifiers; and evaluate the impact of these changes on a statistical parser.</p><p>5 0.55747223 <a title="228-lsi-5" href="./acl-2010-Minimized_Models_and_Grammar-Informed_Initialization_for_Supertagging_with_Highly_Ambiguous_Lexicons.html">172 acl-2010-Minimized Models and Grammar-Informed Initialization for Supertagging with Highly Ambiguous Lexicons</a></p>
<p>Author: Sujith Ravi ; Jason Baldridge ; Kevin Knight</p><p>Abstract: We combine two complementary ideas for learning supertaggers from highly ambiguous lexicons: grammar-informed tag transitions and models minimized via integer programming. Each strategy on its own greatly improves performance over basic expectation-maximization training with a bitag Hidden Markov Model, which we show on the CCGbank and CCG-TUT corpora. The strategies provide further error reductions when combined. We describe a new two-stage integer programming strategy that efficiently deals with the high degree of ambiguity on these datasets while obtaining the full effect of model minimization.</p><p>6 0.52190453 <a title="228-lsi-6" href="./acl-2010-Faster_Parsing_by_Supertagger_Adaptation.html">114 acl-2010-Faster Parsing by Supertagger Adaptation</a></p>
<p>7 0.39216644 <a title="228-lsi-7" href="./acl-2010-On_the_Computational_Complexity_of_Dominance_Links_in_Grammatical_Formalisms.html">182 acl-2010-On the Computational Complexity of Dominance Links in Grammatical Formalisms</a></p>
<p>8 0.3322987 <a title="228-lsi-8" href="./acl-2010-A_Probabilistic_Generative_Model_for_an_Intermediate_Constituency-Dependency_Representation.html">12 acl-2010-A Probabilistic Generative Model for an Intermediate Constituency-Dependency Representation</a></p>
<p>9 0.29009673 <a title="228-lsi-9" href="./acl-2010-SystemT%3A_An_Algebraic_Approach_to_Declarative_Information_Extraction.html">222 acl-2010-SystemT: An Algebraic Approach to Declarative Information Extraction</a></p>
<p>10 0.2838659 <a title="228-lsi-10" href="./acl-2010-Computing_Weakest_Readings.html">67 acl-2010-Computing Weakest Readings</a></p>
<p>11 0.27158639 <a title="228-lsi-11" href="./acl-2010-Grammar_Prototyping_and_Testing_with_the_LinGO_Grammar_Matrix_Customization_System.html">128 acl-2010-Grammar Prototyping and Testing with the LinGO Grammar Matrix Customization System</a></p>
<p>12 0.24845114 <a title="228-lsi-12" href="./acl-2010-Efficient_Inference_through_Cascades_of_Weighted_Tree_Transducers.html">95 acl-2010-Efficient Inference through Cascades of Weighted Tree Transducers</a></p>
<p>13 0.22362694 <a title="228-lsi-13" href="./acl-2010-Optimal_Rank_Reduction_for_Linear_Context-Free_Rewriting_Systems_with_Fan-Out_Two.html">186 acl-2010-Optimal Rank Reduction for Linear Context-Free Rewriting Systems with Fan-Out Two</a></p>
<p>14 0.2120655 <a title="228-lsi-14" href="./acl-2010-String_Extension_Learning.html">217 acl-2010-String Extension Learning</a></p>
<p>15 0.20872447 <a title="228-lsi-15" href="./acl-2010-Compositional_Matrix-Space_Models_of_Language.html">66 acl-2010-Compositional Matrix-Space Models of Language</a></p>
<p>16 0.20206298 <a title="228-lsi-16" href="./acl-2010-The_Use_of_Formal_Language_Models_in_the_Typology_of_the_Morphology_of_Amerindian_Languages.html">234 acl-2010-The Use of Formal Language Models in the Typology of the Morphology of Amerindian Languages</a></p>
<p>17 0.19724207 <a title="228-lsi-17" href="./acl-2010-Learning_Common_Grammar_from_Multilingual_Corpus.html">162 acl-2010-Learning Common Grammar from Multilingual Corpus</a></p>
<p>18 0.19602039 <a title="228-lsi-18" href="./acl-2010-Detecting_Errors_in_Automatically-Parsed_Dependency_Relations.html">84 acl-2010-Detecting Errors in Automatically-Parsed Dependency Relations</a></p>
<p>19 0.19476433 <a title="228-lsi-19" href="./acl-2010-A_Taxonomy%2C_Dataset%2C_and_Classifier_for_Automatic_Noun_Compound_Interpretation.html">19 acl-2010-A Taxonomy, Dataset, and Classifier for Automatic Noun Compound Interpretation</a></p>
<p>20 0.18335347 <a title="228-lsi-20" href="./acl-2010-Learning_to_Translate_with_Source_and_Target_Syntax.html">169 acl-2010-Learning to Translate with Source and Target Syntax</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(25, 0.046), (33, 0.016), (39, 0.012), (59, 0.044), (73, 0.015), (78, 0.653), (83, 0.032), (84, 0.017), (98, 0.062)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9533276 <a title="228-lda-1" href="./acl-2010-The_Importance_of_Rule_Restrictions_in_CCG.html">228 acl-2010-The Importance of Rule Restrictions in CCG</a></p>
<p>Author: Marco Kuhlmann ; Alexander Koller ; Giorgio Satta</p><p>Abstract: Combinatory Categorial Grammar (CCG) is generally construed as a fully lexicalized formalism, where all grammars use one and the same universal set of rules, and crosslinguistic variation is isolated in the lexicon. In this paper, we show that the weak generative capacity of this ‘pure’ form of CCG is strictly smaller than that of CCG with grammar-specific rules, and of other mildly context-sensitive grammar formalisms, including Tree Adjoining Grammar (TAG). Our result also carries over to a multi-modal extension of CCG.</p><p>2 0.82683718 <a title="228-lda-2" href="./acl-2010-Edit_Tree_Distance_Alignments_for_Semantic_Role_Labelling.html">94 acl-2010-Edit Tree Distance Alignments for Semantic Role Labelling</a></p>
<p>Author: Hector-Hugo Franco-Penya</p><p>Abstract: ―Tree SRL system‖ is a Semantic Role Labelling supervised system based on a tree-distance algorithm and a simple k-NN implementation. The novelty of the system lies in comparing the sentences as tree structures with multiple relations instead of extracting vectors of features for each relation and classifying them. The system was tested with the English CoNLL-2009 shared task data set where 79% accuracy was obtained. 1</p><p>3 0.72190857 <a title="228-lda-3" href="./acl-2010-The_Influence_of_Discourse_on_Syntax%3A_A_Psycholinguistic_Model_of_Sentence_Processing.html">229 acl-2010-The Influence of Discourse on Syntax: A Psycholinguistic Model of Sentence Processing</a></p>
<p>Author: Amit Dubey</p><p>Abstract: Probabilistic models of sentence comprehension are increasingly relevant to questions concerning human language processing. However, such models are often limited to syntactic factors. This paper introduces a novel sentence processing model that consists of a parser augmented with a probabilistic logic-based model of coreference resolution, which allows us to simulate how context interacts with syntax in a reading task. Our simulations show that a Weakly Interactive cognitive architecture can explain data which had been provided as evidence for the Strongly Interactive hypothesis.</p><p>4 0.64732838 <a title="228-lda-4" href="./acl-2010-A_Latent_Dirichlet_Allocation_Method_for_Selectional_Preferences.html">10 acl-2010-A Latent Dirichlet Allocation Method for Selectional Preferences</a></p>
<p>Author: Alan Ritter ; Mausam Mausam ; Oren Etzioni</p><p>Abstract: The computation of selectional preferences, the admissible argument values for a relation, is a well-known NLP task with broad applicability. We present LDA-SP, which utilizes LinkLDA (Erosheva et al., 2004) to model selectional preferences. By simultaneously inferring latent topics and topic distributions over relations, LDA-SP combines the benefits of previous approaches: like traditional classbased approaches, it produces humaninterpretable classes describing each relation’s preferences, but it is competitive with non-class-based methods in predictive power. We compare LDA-SP to several state-ofthe-art methods achieving an 85% increase in recall at 0.9 precision over mutual information (Erk, 2007). We also evaluate LDA-SP’s effectiveness at filtering improper applications of inference rules, where we show substantial improvement over Pantel et al. ’s system (Pantel et al., 2007).</p><p>5 0.56090075 <a title="228-lda-5" href="./acl-2010-Contextualizing_Semantic_Representations_Using_Syntactically_Enriched_Vector_Models.html">70 acl-2010-Contextualizing Semantic Representations Using Syntactically Enriched Vector Models</a></p>
<p>Author: Stefan Thater ; Hagen Furstenau ; Manfred Pinkal</p><p>Abstract: We present a syntactically enriched vector model that supports the computation of contextualized semantic representations in a quasi compositional fashion. It employs a systematic combination of first- and second-order context vectors. We apply our model to two different tasks and show that (i) it substantially outperforms previous work on a paraphrase ranking task, and (ii) achieves promising results on a wordsense similarity task; to our knowledge, it is the first time that an unsupervised method has been applied to this task.</p><p>6 0.46894598 <a title="228-lda-6" href="./acl-2010-A_Structured_Model_for_Joint_Learning_of_Argument_Roles_and_Predicate_Senses.html">17 acl-2010-A Structured Model for Joint Learning of Argument Roles and Predicate Senses</a></p>
<p>7 0.46101993 <a title="228-lda-7" href="./acl-2010-A_Tree_Transducer_Model_for_Synchronous_Tree-Adjoining_Grammars.html">21 acl-2010-A Tree Transducer Model for Synchronous Tree-Adjoining Grammars</a></p>
<p>8 0.45592389 <a title="228-lda-8" href="./acl-2010-Latent_Variable_Models_of_Selectional_Preference.html">158 acl-2010-Latent Variable Models of Selectional Preference</a></p>
<p>9 0.45097834 <a title="228-lda-9" href="./acl-2010-Accurate_Context-Free_Parsing_with_Combinatory_Categorial_Grammar.html">23 acl-2010-Accurate Context-Free Parsing with Combinatory Categorial Grammar</a></p>
<p>10 0.44563195 <a title="228-lda-10" href="./acl-2010-Beyond_NomBank%3A_A_Study_of_Implicit_Arguments_for_Nominal_Predicates.html">49 acl-2010-Beyond NomBank: A Study of Implicit Arguments for Nominal Predicates</a></p>
<p>11 0.40255138 <a title="228-lda-11" href="./acl-2010-Computing_Weakest_Readings.html">67 acl-2010-Computing Weakest Readings</a></p>
<p>12 0.39949989 <a title="228-lda-12" href="./acl-2010-Filtering_Syntactic_Constraints_for_Statistical_Machine_Translation.html">115 acl-2010-Filtering Syntactic Constraints for Statistical Machine Translation</a></p>
<p>13 0.39139292 <a title="228-lda-13" href="./acl-2010-Fully_Unsupervised_Core-Adjunct_Argument_Classification.html">120 acl-2010-Fully Unsupervised Core-Adjunct Argument Classification</a></p>
<p>14 0.38735244 <a title="228-lda-14" href="./acl-2010-Hard_Constraints_for_Grammatical_Function_Labelling.html">130 acl-2010-Hard Constraints for Grammatical Function Labelling</a></p>
<p>15 0.37378332 <a title="228-lda-15" href="./acl-2010-Exemplar-Based_Models_for_Word_Meaning_in_Context.html">107 acl-2010-Exemplar-Based Models for Word Meaning in Context</a></p>
<p>16 0.37280768 <a title="228-lda-16" href="./acl-2010-Joint_Syntactic_and_Semantic_Parsing_of_Chinese.html">153 acl-2010-Joint Syntactic and Semantic Parsing of Chinese</a></p>
<p>17 0.36746764 <a title="228-lda-17" href="./acl-2010-Learning_Arguments_and_Supertypes_of_Semantic_Relations_Using_Recursive_Patterns.html">160 acl-2010-Learning Arguments and Supertypes of Semantic Relations Using Recursive Patterns</a></p>
<p>18 0.36713493 <a title="228-lda-18" href="./acl-2010-Predicate_Argument_Structure_Analysis_Using_Transformation_Based_Learning.html">198 acl-2010-Predicate Argument Structure Analysis Using Transformation Based Learning</a></p>
<p>19 0.36516353 <a title="228-lda-19" href="./acl-2010-Efficient_Inference_through_Cascades_of_Weighted_Tree_Transducers.html">95 acl-2010-Efficient Inference through Cascades of Weighted Tree Transducers</a></p>
<p>20 0.36503598 <a title="228-lda-20" href="./acl-2010-Convolution_Kernel_over_Packed_Parse_Forest.html">71 acl-2010-Convolution Kernel over Packed Parse Forest</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
