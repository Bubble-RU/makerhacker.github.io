<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>179 acl-2010-Now, Where Was I? Resumption Strategies for an In-Vehicle Dialogue System</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-179" href="#">acl2010-179</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>179 acl-2010-Now, Where Was I? Resumption Strategies for an In-Vehicle Dialogue System</h1>
<br/><p>Source: <a title="acl-2010-179-pdf" href="http://aclweb.org/anthology//P/P10/P10-1082.pdf">pdf</a></p><p>Author: Jessica Villing</p><p>Abstract: In-vehicle dialogue systems often contain more than one application, e.g. a navigation and a telephone application. This means that the user might, for example, interrupt the interaction with the telephone application to ask for directions from the navigation application, and then resume the dialogue with the telephone application. In this paper we present an analysis of interruption and resumption behaviour in human-human in-vehicle dialogues and also propose some implications for resumption strategies in an in-vehicle dialogue system.</p><p>Reference: <a title="acl-2010-179-reference" href="../acl2010_reference/acl-2010-Now%2C_Where_Was_I%3F_Resumption_Strategies_for_an_In-Vehicle_Dialogue_System_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 This means that the user might, for example, interrupt the interaction with the telephone application to ask for directions from the navigation application, and then resume the dialogue with the telephone application. [sent-7, score-0.594]
</p><p>2 In this paper we present an analysis of interruption and resumption behaviour in human-human in-vehicle dialogues and also propose some implications for resumption strategies in an in-vehicle dialogue system. [sent-8, score-0.69]
</p><p>3 , 2005) revealed that secondary task distraction is the largest cause of driver inattention, and that the handling of wireless devices is the most common secondary task. [sent-13, score-0.557]
</p><p>4 Therefore the dialogue system should consider the cognitive load of the driver and adjust the dialogue accordingly. [sent-15, score-0.931]
</p><p>5 One way of doing this is to continously measure the cognitive workload level ofthe driver and, ifthe workload is high,  determine type of workload and act accordingly. [sent-16, score-1.966]
</p><p>6 caused by the driving task), the user might need information that is crucial for the driving task (e. [sent-22, score-0.286]
</p><p>7 get navigation instructions), or to pause the dialogue in order to enable the user to concentrate on the driving task (Villing, 2009). [sent-24, score-0.504]
</p><p>8 Both the driver and the system should be able to initiate interruptions. [sent-25, score-0.526]
</p><p>9 Instead, the dialogue system should be able to either pause until the workload is low or change topic and/or domain, and then resume where the interruption took place. [sent-30, score-0.98]
</p><p>10 However, resumption of an interrupted topic needs to be done in a way that minimizes the risk that  the cognitive workload increases again. [sent-31, score-0.832]
</p><p>11 Although a lot of research has been done regarding dialogue system output, very little work has been done regarding resumption of an interrupted topic. [sent-32, score-0.399]
</p><p>12 In this paper we will analyse human-human in-vehicle dialogue to find out how resumptions are done in human-human dialogue and propose some implications for resumption strategies in a dialogue system. [sent-33, score-0.648]
</p><p>13 3  Data collection  A data collection has been carried out within the DICO project (see, for example, (Larsson and Villing, 2007)) to study how an additional distraction or increase in the cognitive load would affect a driver’s dialogue behaviour. [sent-41, score-0.284]
</p><p>14 The goal was to elicit a natural dialogue (as opposed to giving the driver  a constructed task such as for example a math task) and make the participants engage in the conversation. [sent-42, score-0.736]
</p><p>15 The interview questions and the driving instructions were given to the passenger, hence the driver knew neither what questions to discuss nor the route in advance. [sent-44, score-0.917]
</p><p>16 Therefore, the driver had to signal, implicitly or explicitly, when she wanted driving instructions and when she wanted a new question to discuss. [sent-45, score-0.718]
</p><p>17 The passenger too had to have a strategy for when to change topic. [sent-46, score-0.346]
</p><p>18 The reasons for this setup was to elicit a natural and fairly intense dialogue and to force the participants to frequently change topic and/or domain (e. [sent-47, score-0.319]
</p><p>19 The participants changed roles after 30 minutes, which meant that each participant acted both as driver and as passenger. [sent-50, score-0.57]
</p><p>20 The cognitive load of the driver was measured in two ways. [sent-51, score-0.627]
</p><p>21 The driver performed a Tactile Detection Task (TDT) (van Winsum et al. [sent-52, score-0.526]
</p><p>22 The driver is told to push a button each time the summer is activated. [sent-55, score-0.526]
</p><p>23 Although the TDT task in itself might cause an increased workload level, the task is performed during the whole session and thereby it is possible to distinguish high workload caused by something else but the TDT task. [sent-57, score-0.944]
</p><p>24 IDIS determines workload based on the driver’s behaviour (for example, steering wheel movements or applying the brake). [sent-60, score-0.504]
</p><p>25 What differs between the two measurements is that the TDT measures the actual workload of each driver, while IDIS makes its assumptions based on knowledge of what manouvres are usually cognitively demanding. [sent-61, score-0.49]
</p><p>26 All in all 3590 driver utterances and 4382 passenger utterances are transcribed. [sent-63, score-1.026]
</p><p>27 , the participants start discussing an interview question, a navigation instruction, make a remark about the traffic or anything else that has not been discussed before. [sent-67, score-0.478]
</p><p>28 interrupt-topic: unfinished topic → whatever An utterance is considered to interrupt if it belongs to another topic than the previous utterance and the previous topic has not been ended with an end-topic. [sent-71, score-0.523]
</p><p>29 resume-topic: whatever → unfinished topic A topic is considered to be resumed if it has been discussed earlier but was not –  •  –  •  –  been finished by an end-topic but instead interrupted with an interrupt-topic. [sent-72, score-0.348]
</p><p>30 • high: high workload according to IDIS –  •  low: low workload according to IDIS  The annotation schema has not been tested for inter-coder reliability. [sent-78, score-0.962]
</p><p>31 4  Results  The codings from the DICO data collection has been analysed with respect to interruption and resumption of topics (interrupt-topic and resumetopic, respectively). [sent-80, score-0.325]
</p><p>32 The reason is probably that both the driver and the passenger were strongly engaged in the interview and navigation tasks. [sent-83, score-1.277]
</p><p>33 The fact that the driver did not know the route elicited frequent switches to the navigation domain done by both the driver and the passenger, as can be seen in Figure 1. [sent-84, score-1.245]
</p><p>34 Therefore, we have only analysed interruption and resumption from and to the interview and navigation domains. [sent-85, score-0.713]
</p><p>35 ")/-("*,/01"2*3+," Figure 1: Distribution of utterances coded as interrupt-topic for each domain, when interrupting from an interview topic. [sent-90, score-0.404]
</p><p>36 1 Redundancy The easiest way of resuming an interrupted topic in a dialogue system is to repeat the last phrase that was uttered before the interruption. [sent-92, score-0.59]
</p><p>37 We wanted to see if the resuming utterances in humanhuman dialogue are redundant and if redundancy has anything to do with the length of the interruption. [sent-94, score-0.543]
</p><p>38 As a redundant utterance we counted all utterances that repeated one or more words from the last utterance before the interruption. [sent-96, score-0.31]
</p><p>39 As can be seen, there are twice as many nonredundant as redundant utterances after a short interruption (≤4 turns), while there are almost solely rpetdiounnd (≤an4t utterances aifleter t a long interruption (≥ 10 turns). [sent-110, score-0.501]
</p><p>40 2 Category Figure 3 shows the distribution, sorted per category, of driver utterances when resuming to an interview and a navigation topic. [sent-114, score-1.222]
</p><p>41 Figure 4 shows the corresponding figures for passenger utterances. [sent-115, score-0.363]
</p><p>42 /#0-1#0)2/#34 :5863#78369 Figure 3: Driver resuming to the interview and navigation domains. [sent-118, score-0.619]
</p><p>43 The driver’s behaviour is similar both when resuming to an interview and a navigation topic. [sent-119, score-0.659]
</p><p>44 Declarative phrases are most common, followed by incomplete, interrogative (for interview topics) and noun phrases. [sent-120, score-0.279]
</p><p>45 /#,0/#1)2/#43 :5863#78369 Figure 4: Passenger resuming to the interview and navigation domains. [sent-123, score-0.619]
</p><p>46 When looking at the passenger utterances we see a lot of variation between the domains. [sent-124, score-0.423]
</p><p>47 When resuming to an interview topic the passenger uses mostly declarative phrases, followed by noun phrases and interrogative phrases. [sent-125, score-1.018]
</p><p>48 When resuming to a navigation topic imperative phrases are most common, followed by declarative phrases. [sent-126, score-0.546]
</p><p>49 Only the passenger use imperative phrases, probably since the passenger is managing both the interview questions and the navigation instructions and therefore is the one that is forcing both the inter-  view and the navigation task through. [sent-127, score-1.327]
</p><p>50 3 Workload level The in-vehicle environment is forcing the driver to carry out tasks during high cognitive workload. [sent-129, score-0.59]
</p><p>51 To minimize the risk of increasing the workload further, an in-vehicle dialogue system should be able to decide when to interrupt and when to resume a topic depending on the driver’s workload level. [sent-130, score-1.316]
</p><p>52 The figures in this section shows workload level and type of workload during interruption and resumption to and from topics in the interview domain. [sent-131, score-1.482]
</p><p>53 When designing the interview and navigation tasks that were to be carried out during the data collection, we focused on designing them so that the participants were encouraged to discuss as much as possible with each other. [sent-132, score-0.462]
</p><p>54 Therefore, the navigation instructions sometimes were hard to understand, which forced the participants to discuss the instructions and together try to interpret them. [sent-133, score-0.289]
</p><p>55 Therefore we have not analysed the workload level while interrupting and resuming topics in the navigation domain since the result might be 801  misleading. [sent-134, score-0.983]
</p><p>56 Type of workload is determined by analysing the TDT and IDIS signals described in 3. [sent-135, score-0.464]
</p><p>57 The data has been normalized for variation in workload time. [sent-137, score-0.464]
</p><p>58 The diagrams shows the distribution of interruption and resumption utterances  made by the driver and the passenger, respectively. [sent-138, score-0.909]
</p><p>59 Figure 5: Workload while the driver is interrupting an interview topic. [sent-139, score-0.833]
</p><p>60 Figure 6: Workload while the passenger is interrupting an interview topic. [sent-140, score-0.653]
</p><p>61 Figures 5 and 6 show driver workload level while the driver and the passenger (respectively) are interrupting from the interview domain. [sent-141, score-2.169]
</p><p>62 The driver most often interrupts during a possible driving-induced or low workload, the same goes for the passenger but in opposite order. [sent-142, score-0.957]
</p><p>63 It is least common for the driver to interrupt during dialogue- or driving-induced workload, while the passenger rarely interrupts during dialogueinduced and never during driving-induced workload. [sent-143, score-1.006]
</p><p>64 Figure 7: Workload while driver is resuming to the interview domain. [sent-144, score-0.988]
</p><p>65 Figure 8: Workload while passenger is resuming  to the interview domain. [sent-145, score-0.808]
</p><p>66 Figures 7 and 8 show workload level while the driver and the passenger (respectively) are resuming to the interview domain. [sent-146, score-1.798]
</p><p>67 The driver most often resumes while the workload is low or possibly driving-induced, while the passenger is mostly resuming during low workload and never during driving-induced workload. [sent-147, score-2.138]
</p><p>68 5  Discussion  For both driver and passenger, the most common way to resume an interview topic is to use a declarative utterance, which is illustrated in Figure 3. [sent-148, score-0.982]
</p><p>69 They compared grade of 802  redundancy based on where in the dialogue the interruption occur, what we have looked at in the DICO corpus is how many turns the interrupting  discussion contains. [sent-150, score-0.448]
</p><p>70 Example (1) shows how the driver interrupts a discussion about what book he is currently reading to get navigation instructions: (1) Driver: What I read now i So fie ’ s s world . [sent-154, score-0.75]
</p><p>71 [ DEC ]  ,  If the number of turns is higher than ten (on average, 11,5) the resuming speaker makes a redundant utterance, repeating one or more words from the last utterance before the interruption. [sent-161, score-0.434]
</p><p>72 The passenger often uses a bare noun phrase to resume, the noun phrase can repeat a part of the interview question. [sent-174, score-0.656]
</p><p>73 For example, after a discussion about wonders of the world, which was interrupted by a discussion about which way to go next, the passenger resumed by uttering the single word “wonders” which was immediatly understood by the driver as a resumption to the interview topic. [sent-175, score-1.398]
</p><p>74 [ NP ]  When resuming to the navigation domain, the driver mostly uses a declarative phrase, typically to clarify an instruction. [sent-188, score-1.003]
</p><p>75 ” which the passenger answers by clarifying which way to go. [sent-192, score-0.346]
</p><p>76 The passenger instead uses mostly imperative phrases as a reminder of the last instruction, such as “keep straight on ”. [sent-193, score-0.408]
</p><p>77 When the speakers interrupts an interview topic they mostly switch to the navigation domain, see Figure 1. [sent-194, score-0.561]
</p><p>78 That means that the most common reason for the speaker to interrupt is to ask for or give information that is crucial for the driving task (as opposed for the other and traffic domains, which are mostly used to signal that the speaker’s cognitive load level is high (Villing et al. [sent-195, score-0.4]
</p><p>79 As can be seen in Figures 5 and 6, the driver mostly interrupts the interview domain during a possible driving-induced workload while the passenger mostly interrupts during low workload. [sent-197, score-1.821]
</p><p>80 ”), while the passenger gives additional information that the driver has not asked for explicitly but the passenger judges that the driver might need ( “just go straight ahead in the next crossing ”, “here is where we should turn towards Järntorget”). [sent-202, score-1.791]
</p><p>81 Figure 7 shows that the driver mostly resumes to the interview domain during low or possible driving-induced workload. [sent-204, score-0.882]
</p><p>82 Since the IDIS system makes its assumption on driving behaviour, based on what the average driver finds cognitively demanding, it might sometimes be so that the system  overgenerates and indicates high workload even though the driver at hand does not find the driving task cognitively demanding. [sent-205, score-1.816]
</p><p>83 This might be an explanation to these results, since the driver often resumes to an interview topic although he or she is, for example, driving through a roundabout or pushing the brakes. [sent-206, score-0.984]
</p><p>84 It is also rather common that the driver is resuming to an interview question during dialogue-induced workload, perhaps because she has started thinking about an answer to a question and therefore the TDT indicates high workload and the IDIS does not. [sent-207, score-1.468]
</p><p>85 The passenger mostly resumes to the interview domain during low workload, which indicates that the passenger analyses both the traffic situation and the state of mind of the driver before he or she wants to draw the drivers attention from the driving task. [sent-208, score-1.736]
</p><p>86 6  Implications for in-vehicle dialogue systems  In this paper we point at some of the dialogue strategies that are used in human-human dialogue  during high cognitive load when resuming to an interrupted topic. [sent-209, score-0.919]
</p><p>87 To make the dialogue natural and easy to understand the dialogue manager should consider which domain it will resume to and the number of turns between the interruption and resumption before deciding what phrase to use as output. [sent-211, score-0.806]
</p><p>88 For example, the results indicate that it might be more suitable to use a declarative phrase when resuming to a domain where the system is asking the user for information, for example when adding songs to a play list at the mp3-player (cf. [sent-212, score-0.397]
</p><p>89 If the number of turns exceeds 4 it is probably smoother to let the system just repeat one or more keywords from the interrupted utterance to make the user understand what topic should be discussed, instead of repeating the whole utterance or even start the task from  the beginning. [sent-215, score-0.492]
</p><p>90 This will make the system feel less tedious which should have a positive effect on the cognitive workload level. [sent-216, score-0.529]
</p><p>91 When resuming to a domain where the system has information to give to the user it is suitable to make a short, informative utterance (e. [sent-218, score-0.416]
</p><p>92 For example, if the user is using a navigation system and he or she is experiencing driving-induced workload when approach-  ing e. [sent-222, score-0.675]
</p><p>93 When resuming to the interview domain the driver (i. [sent-227, score-1.024]
</p><p>94 Therefore the dialogue system should be able to store not only what has been agreed upon regarding the interrupted task, but also the last few utterances to make it possible to interpret the user utterance as a resumption. [sent-230, score-0.471]
</p><p>95 804  It is common that the driver utterances are incomplete, perhaps due to the fact that the driver’s primary task is the driving and therefore his or her mind is not always set on the dialogue task. [sent-231, score-0.871]
</p><p>96 7  Future work  Next we intend to implement strategies for interruption and resumption in the DICO dialogue system. [sent-234, score-0.48]
</p><p>97 Cognitive workload will be measured as well as driving ability (for example, by using a Lane Change Task (Mattes, 2003)). [sent-236, score-0.58]
</p><p>98 Towards the next generation intelligent driver information system (idis): The volvo cars interaction manager concept. [sent-240, score-0.526]
</p><p>99 The lane-change-task as a tool for driver distraction evaluation. [sent-252, score-0.557]
</p><p>100 The effect of speech versus tactile driver support messages on workload, driver behaviour and user acceptance. [sent-260, score-1.165]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('driver', 0.526), ('workload', 0.464), ('passenger', 0.346), ('interview', 0.231), ('resuming', 0.231), ('navigation', 0.157), ('resumption', 0.154), ('dialogue', 0.152), ('interruption', 0.152), ('idis', 0.144), ('driving', 0.116), ('resume', 0.096), ('utterance', 0.095), ('tdt', 0.093), ('interrupted', 0.093), ('utterances', 0.077), ('villing', 0.077), ('interrupting', 0.076), ('topic', 0.073), ('interrupt', 0.067), ('interrupts', 0.067), ('dico', 0.059), ('declarative', 0.056), ('user', 0.054), ('load', 0.053), ('cognitive', 0.048), ('interrogative', 0.048), ('traffic', 0.046), ('participants', 0.044), ('instructions', 0.044), ('turns', 0.044), ('redundant', 0.043), ('jessica', 0.042), ('behaviour', 0.04), ('resumes', 0.038), ('demanding', 0.038), ('domain', 0.036), ('card', 0.035), ('telephone', 0.034), ('mostly', 0.033), ('finished', 0.033), ('whatever', 0.033), ('ahead', 0.031), ('distraction', 0.031), ('larsson', 0.031), ('imperative', 0.029), ('lindstr', 0.029), ('resumed', 0.029), ('cognitively', 0.026), ('staffan', 0.025), ('pause', 0.025), ('urn', 0.025), ('redundancy', 0.024), ('strategies', 0.022), ('dec', 0.022), ('speaker', 0.021), ('repeat', 0.021), ('incomplete', 0.02), ('phrase', 0.02), ('coded', 0.02), ('apl', 0.019), ('brostr', 0.019), ('cecilia', 0.019), ('chno', 0.019), ('ekelund', 0.019), ('logy', 0.019), ('neale', 0.019), ('orget', 0.019), ('raight', 0.019), ('seward', 0.019), ('tactile', 0.019), ('winsum', 0.019), ('wonders', 0.019), ('anders', 0.019), ('answered', 0.019), ('analysed', 0.019), ('low', 0.018), ('instruction', 0.018), ('bare', 0.018), ('indicating', 0.018), ('probably', 0.017), ('figures', 0.017), ('tedious', 0.017), ('enemy', 0.017), ('interruptions', 0.017), ('occured', 0.017), ('sequencing', 0.017), ('crossing', 0.016), ('high', 0.016), ('wanted', 0.016), ('implications', 0.016), ('pressed', 0.015), ('safety', 0.015), ('nina', 0.015), ('designing', 0.015), ('st', 0.015), ('elicit', 0.014), ('unfinished', 0.014), ('gr', 0.014), ('partners', 0.014)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="179-tfidf-1" href="./acl-2010-Now%2C_Where_Was_I%3F_Resumption_Strategies_for_an_In-Vehicle_Dialogue_System.html">179 acl-2010-Now, Where Was I? Resumption Strategies for an In-Vehicle Dialogue System</a></p>
<p>Author: Jessica Villing</p><p>Abstract: In-vehicle dialogue systems often contain more than one application, e.g. a navigation and a telephone application. This means that the user might, for example, interrupt the interaction with the telephone application to ask for directions from the navigation application, and then resume the dialogue with the telephone application. In this paper we present an analysis of interruption and resumption behaviour in human-human in-vehicle dialogues and also propose some implications for resumption strategies in an in-vehicle dialogue system.</p><p>2 0.091437452 <a title="179-tfidf-2" href="./acl-2010-Learning_to_Adapt_to_Unknown_Users%3A_Referring_Expression_Generation_in_Spoken_Dialogue_Systems.html">167 acl-2010-Learning to Adapt to Unknown Users: Referring Expression Generation in Spoken Dialogue Systems</a></p>
<p>Author: Srinivasan Janarthanam ; Oliver Lemon</p><p>Abstract: We present a data-driven approach to learn user-adaptive referring expression generation (REG) policies for spoken dialogue systems. Referring expressions can be difficult to understand in technical domains where users may not know the technical ‘jargon’ names of the domain entities. In such cases, dialogue systems must be able to model the user’s (lexical) domain knowledge and use appropriate referring expressions. We present a reinforcement learning (RL) framework in which the sys- tem learns REG policies which can adapt to unknown users online. Furthermore, unlike supervised learning methods which require a large corpus of expert adaptive behaviour to train on, we show that effective adaptive policies can be learned from a small dialogue corpus of non-adaptive human-machine interaction, by using a RL framework and a statistical user simulation. We show that in comparison to adaptive hand-coded baseline policies, the learned policy performs significantly better, with an 18.6% average increase in adaptation accuracy. The best learned policy also takes less dialogue time (average 1.07 min less) than the best hand-coded policy. This is because the learned policies can adapt online to changing evidence about the user’s domain expertise.</p><p>3 0.08841636 <a title="179-tfidf-3" href="./acl-2010-Non-Cooperation_in_Dialogue.html">178 acl-2010-Non-Cooperation in Dialogue</a></p>
<p>Author: Brian Pluss</p><p>Abstract: This paper presents ongoing research on computational models for non-cooperative dialogue. We start by analysing different levels of cooperation in conversation. Then, inspired by findings from an empirical study, we propose a technique for measuring non-cooperation in political interviews. Finally, we describe a research programme towards obtaining a suitable model and discuss previous accounts for conflictive dialogue, identifying the differences with our work.</p><p>4 0.082045034 <a title="179-tfidf-4" href="./acl-2010-Importance-Driven_Turn-Bidding_for_Spoken_Dialogue_Systems.html">142 acl-2010-Importance-Driven Turn-Bidding for Spoken Dialogue Systems</a></p>
<p>Author: Ethan Selfridge ; Peter Heeman</p><p>Abstract: Current turn-taking approaches for spoken dialogue systems rely on the speaker releasing the turn before the other can take it. This reliance results in restricted interactions that can lead to inefficient dialogues. In this paper we present a model we refer to as Importance-Driven Turn-Bidding that treats turn-taking as a negotiative process. Each conversant bids for the turn based on the importance of the intended utterance, and Reinforcement Learning is used to indirectly learn this parameter. We find that Importance-Driven Turn-Bidding performs better than two current turntaking approaches in an artificial collaborative slot-filling domain. The negotiative nature of this model creates efficient dia- logues, and supports the improvement of mixed-initiative interaction.</p><p>5 0.079081953 <a title="179-tfidf-5" href="./acl-2010-Towards_Relational_POMDPs_for_Adaptive_Dialogue_Management.html">239 acl-2010-Towards Relational POMDPs for Adaptive Dialogue Management</a></p>
<p>Author: Pierre Lison</p><p>Abstract: Open-ended spoken interactions are typically characterised by both structural complexity and high levels of uncertainty, making dialogue management in such settings a particularly challenging problem. Traditional approaches have focused on providing theoretical accounts for either the uncertainty or the complexity of spoken dialogue, but rarely considered the two issues simultaneously. This paper describes ongoing work on a new approach to dialogue management which attempts to fill this gap. We represent the interaction as a Partially Observable Markov Decision Process (POMDP) over a rich state space incorporating both dialogue, user, and environment models. The tractability of the resulting POMDP can be preserved using a mechanism for dynamically constraining the action space based on prior knowledge over locally relevant dialogue structures. These constraints are encoded in a small set of general rules expressed as a Markov Logic network. The first-order expressivity of Markov Logic enables us to leverage the rich relational structure of the problem and efficiently abstract over large regions ofthe state and action spaces.</p><p>6 0.075964399 <a title="179-tfidf-6" href="./acl-2010-Using_Speech_to_Reply_to_SMS_Messages_While_Driving%3A_An_In-Car_Simulator_User_Study.html">254 acl-2010-Using Speech to Reply to SMS Messages While Driving: An In-Car Simulator User Study</a></p>
<p>7 0.068616785 <a title="179-tfidf-7" href="./acl-2010-Phrase-Based_Statistical_Language_Generation_Using_Graphical_Models_and_Active_Learning.html">194 acl-2010-Phrase-Based Statistical Language Generation Using Graphical Models and Active Learning</a></p>
<p>8 0.067984663 <a title="179-tfidf-8" href="./acl-2010-Optimising_Information_Presentation_for_Spoken_Dialogue_Systems.html">187 acl-2010-Optimising Information Presentation for Spoken Dialogue Systems</a></p>
<p>9 0.065775216 <a title="179-tfidf-9" href="./acl-2010-Demonstration_of_a_Prototype_for_a_Conversational_Companion_for_Reminiscing_about_Images.html">82 acl-2010-Demonstration of a Prototype for a Conversational Companion for Reminiscing about Images</a></p>
<p>10 0.058671545 <a title="179-tfidf-10" href="./acl-2010-The_Impact_of_Interpretation_Problems_on_Tutorial_Dialogue.html">227 acl-2010-The Impact of Interpretation Problems on Tutorial Dialogue</a></p>
<p>11 0.057829283 <a title="179-tfidf-11" href="./acl-2010-Beetle_II%3A_A_System_for_Tutoring_and_Computational_Linguistics_Experimentation.html">47 acl-2010-Beetle II: A System for Tutoring and Computational Linguistics Experimentation</a></p>
<p>12 0.049941007 <a title="179-tfidf-12" href="./acl-2010-Automated_Planning_for_Situated_Natural_Language_Generation.html">35 acl-2010-Automated Planning for Situated Natural Language Generation</a></p>
<p>13 0.048906609 <a title="179-tfidf-13" href="./acl-2010-Classification_of_Feedback_Expressions_in_Multimodal_Data.html">58 acl-2010-Classification of Feedback Expressions in Multimodal Data</a></p>
<p>14 0.048423003 <a title="179-tfidf-14" href="./acl-2010-Decision_Detection_Using_Hierarchical_Graphical_Models.html">81 acl-2010-Decision Detection Using Hierarchical Graphical Models</a></p>
<p>15 0.039838847 <a title="179-tfidf-15" href="./acl-2010-Reading_between_the_Lines%3A_Learning_to_Map_High-Level_Instructions_to_Commands.html">202 acl-2010-Reading between the Lines: Learning to Map High-Level Instructions to Commands</a></p>
<p>16 0.035557803 <a title="179-tfidf-16" href="./acl-2010-A_Cognitive_Cost_Model_of_Annotations_Based_on_Eye-Tracking_Data.html">4 acl-2010-A Cognitive Cost Model of Annotations Based on Eye-Tracking Data</a></p>
<p>17 0.033724602 <a title="179-tfidf-17" href="./acl-2010-Learning_to_Follow_Navigational_Directions.html">168 acl-2010-Learning to Follow Navigational Directions</a></p>
<p>18 0.032261606 <a title="179-tfidf-18" href="./acl-2010-Cross-Lingual_Latent_Topic_Extraction.html">79 acl-2010-Cross-Lingual Latent Topic Extraction</a></p>
<p>19 0.031639986 <a title="179-tfidf-19" href="./acl-2010-Recommendation_in_Internet_Forums_and_Blogs.html">204 acl-2010-Recommendation in Internet Forums and Blogs</a></p>
<p>20 0.030947026 <a title="179-tfidf-20" href="./acl-2010-Speech-Driven_Access_to_the_Deep_Web_on_Mobile_Devices.html">215 acl-2010-Speech-Driven Access to the Deep Web on Mobile Devices</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.06), (1, 0.047), (2, -0.049), (3, -0.107), (4, -0.015), (5, -0.115), (6, -0.096), (7, 0.047), (8, -0.015), (9, -0.012), (10, 0.027), (11, -0.037), (12, 0.022), (13, 0.019), (14, 0.031), (15, -0.057), (16, 0.013), (17, -0.016), (18, -0.021), (19, -0.043), (20, -0.026), (21, -0.006), (22, 0.033), (23, 0.028), (24, -0.001), (25, 0.009), (26, 0.011), (27, 0.005), (28, -0.008), (29, -0.089), (30, 0.001), (31, 0.065), (32, -0.021), (33, 0.019), (34, -0.029), (35, -0.016), (36, -0.009), (37, -0.048), (38, -0.043), (39, 0.086), (40, 0.033), (41, -0.023), (42, -0.017), (43, 0.021), (44, 0.028), (45, -0.088), (46, 0.082), (47, -0.043), (48, 0.08), (49, -0.08)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95216435 <a title="179-lsi-1" href="./acl-2010-Now%2C_Where_Was_I%3F_Resumption_Strategies_for_an_In-Vehicle_Dialogue_System.html">179 acl-2010-Now, Where Was I? Resumption Strategies for an In-Vehicle Dialogue System</a></p>
<p>Author: Jessica Villing</p><p>Abstract: In-vehicle dialogue systems often contain more than one application, e.g. a navigation and a telephone application. This means that the user might, for example, interrupt the interaction with the telephone application to ask for directions from the navigation application, and then resume the dialogue with the telephone application. In this paper we present an analysis of interruption and resumption behaviour in human-human in-vehicle dialogues and also propose some implications for resumption strategies in an in-vehicle dialogue system.</p><p>2 0.73598564 <a title="179-lsi-2" href="./acl-2010-Towards_Relational_POMDPs_for_Adaptive_Dialogue_Management.html">239 acl-2010-Towards Relational POMDPs for Adaptive Dialogue Management</a></p>
<p>Author: Pierre Lison</p><p>Abstract: Open-ended spoken interactions are typically characterised by both structural complexity and high levels of uncertainty, making dialogue management in such settings a particularly challenging problem. Traditional approaches have focused on providing theoretical accounts for either the uncertainty or the complexity of spoken dialogue, but rarely considered the two issues simultaneously. This paper describes ongoing work on a new approach to dialogue management which attempts to fill this gap. We represent the interaction as a Partially Observable Markov Decision Process (POMDP) over a rich state space incorporating both dialogue, user, and environment models. The tractability of the resulting POMDP can be preserved using a mechanism for dynamically constraining the action space based on prior knowledge over locally relevant dialogue structures. These constraints are encoded in a small set of general rules expressed as a Markov Logic network. The first-order expressivity of Markov Logic enables us to leverage the rich relational structure of the problem and efficiently abstract over large regions ofthe state and action spaces.</p><p>3 0.73261255 <a title="179-lsi-3" href="./acl-2010-Non-Cooperation_in_Dialogue.html">178 acl-2010-Non-Cooperation in Dialogue</a></p>
<p>Author: Brian Pluss</p><p>Abstract: This paper presents ongoing research on computational models for non-cooperative dialogue. We start by analysing different levels of cooperation in conversation. Then, inspired by findings from an empirical study, we propose a technique for measuring non-cooperation in political interviews. Finally, we describe a research programme towards obtaining a suitable model and discuss previous accounts for conflictive dialogue, identifying the differences with our work.</p><p>4 0.64742506 <a title="179-lsi-4" href="./acl-2010-Importance-Driven_Turn-Bidding_for_Spoken_Dialogue_Systems.html">142 acl-2010-Importance-Driven Turn-Bidding for Spoken Dialogue Systems</a></p>
<p>Author: Ethan Selfridge ; Peter Heeman</p><p>Abstract: Current turn-taking approaches for spoken dialogue systems rely on the speaker releasing the turn before the other can take it. This reliance results in restricted interactions that can lead to inefficient dialogues. In this paper we present a model we refer to as Importance-Driven Turn-Bidding that treats turn-taking as a negotiative process. Each conversant bids for the turn based on the importance of the intended utterance, and Reinforcement Learning is used to indirectly learn this parameter. We find that Importance-Driven Turn-Bidding performs better than two current turntaking approaches in an artificial collaborative slot-filling domain. The negotiative nature of this model creates efficient dia- logues, and supports the improvement of mixed-initiative interaction.</p><p>5 0.61214042 <a title="179-lsi-5" href="./acl-2010-Demonstration_of_a_Prototype_for_a_Conversational_Companion_for_Reminiscing_about_Images.html">82 acl-2010-Demonstration of a Prototype for a Conversational Companion for Reminiscing about Images</a></p>
<p>Author: Yorick Wilks ; Roberta Catizone ; Alexiei Dingli ; Weiwei Cheng</p><p>Abstract: This paper describes an initial prototype demonstrator of a Companion, designed as a platform for novel approaches to the following: 1) The use of Information Extraction (IE) techniques to extract the content of incoming dialogue utterances after an Automatic Speech Recognition (ASR) phase, 2) The conversion of the input to Resource Descriptor Format (RDF) to allow the generation of new facts from existing ones, under the control of a Dialogue Manger (DM), that also has access to stored knowledge and to open knowledge accessed in real time from the web, all in RDF form, 3) A DM implemented as a stack and network virtual machine that models mixed initiative in dialogue control, and 4) A tuned dialogue act detector based on corpus evidence. The prototype platform was evaluated, and we describe this briefly; it is also designed to support more extensive forms of emotion detection carried by both speech and lexical content, as well as extended forms of machine learning.</p><p>6 0.57065028 <a title="179-lsi-6" href="./acl-2010-Phrase-Based_Statistical_Language_Generation_Using_Graphical_Models_and_Active_Learning.html">194 acl-2010-Phrase-Based Statistical Language Generation Using Graphical Models and Active Learning</a></p>
<p>7 0.55569506 <a title="179-lsi-7" href="./acl-2010-Optimising_Information_Presentation_for_Spoken_Dialogue_Systems.html">187 acl-2010-Optimising Information Presentation for Spoken Dialogue Systems</a></p>
<p>8 0.54132277 <a title="179-lsi-8" href="./acl-2010-Decision_Detection_Using_Hierarchical_Graphical_Models.html">81 acl-2010-Decision Detection Using Hierarchical Graphical Models</a></p>
<p>9 0.5149827 <a title="179-lsi-9" href="./acl-2010-Classification_of_Feedback_Expressions_in_Multimodal_Data.html">58 acl-2010-Classification of Feedback Expressions in Multimodal Data</a></p>
<p>10 0.5066787 <a title="179-lsi-10" href="./acl-2010-Learning_to_Adapt_to_Unknown_Users%3A_Referring_Expression_Generation_in_Spoken_Dialogue_Systems.html">167 acl-2010-Learning to Adapt to Unknown Users: Referring Expression Generation in Spoken Dialogue Systems</a></p>
<p>11 0.4661524 <a title="179-lsi-11" href="./acl-2010-Using_Speech_to_Reply_to_SMS_Messages_While_Driving%3A_An_In-Car_Simulator_User_Study.html">254 acl-2010-Using Speech to Reply to SMS Messages While Driving: An In-Car Simulator User Study</a></p>
<p>12 0.43060768 <a title="179-lsi-12" href="./acl-2010-Extracting_Social_Networks_from_Literary_Fiction.html">112 acl-2010-Extracting Social Networks from Literary Fiction</a></p>
<p>13 0.41846481 <a title="179-lsi-13" href="./acl-2010-Recommendation_in_Internet_Forums_and_Blogs.html">204 acl-2010-Recommendation in Internet Forums and Blogs</a></p>
<p>14 0.34972492 <a title="179-lsi-14" href="./acl-2010-Beetle_II%3A_A_System_for_Tutoring_and_Computational_Linguistics_Experimentation.html">47 acl-2010-Beetle II: A System for Tutoring and Computational Linguistics Experimentation</a></p>
<p>15 0.34394321 <a title="179-lsi-15" href="./acl-2010-Modeling_Norms_of_Turn-Taking_in_Multi-Party_Conversation.html">173 acl-2010-Modeling Norms of Turn-Taking in Multi-Party Conversation</a></p>
<p>16 0.31157121 <a title="179-lsi-16" href="./acl-2010-The_Impact_of_Interpretation_Problems_on_Tutorial_Dialogue.html">227 acl-2010-The Impact of Interpretation Problems on Tutorial Dialogue</a></p>
<p>17 0.29303941 <a title="179-lsi-17" href="./acl-2010-%22Was_It_Good%3F_It_Was_Provocative.%22_Learning_the_Meaning_of_Scalar_Adjectives.html">2 acl-2010-"Was It Good? It Was Provocative." Learning the Meaning of Scalar Adjectives</a></p>
<p>18 0.2894544 <a title="179-lsi-18" href="./acl-2010-Reading_between_the_Lines%3A_Learning_to_Map_High-Level_Instructions_to_Commands.html">202 acl-2010-Reading between the Lines: Learning to Map High-Level Instructions to Commands</a></p>
<p>19 0.26984274 <a title="179-lsi-19" href="./acl-2010-Automated_Planning_for_Situated_Natural_Language_Generation.html">35 acl-2010-Automated Planning for Situated Natural Language Generation</a></p>
<p>20 0.26328626 <a title="179-lsi-20" href="./acl-2010-A_Cognitive_Cost_Model_of_Annotations_Based_on_Eye-Tracking_Data.html">4 acl-2010-A Cognitive Cost Model of Annotations Based on Eye-Tracking Data</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(6, 0.437), (14, 0.011), (25, 0.041), (39, 0.01), (42, 0.056), (59, 0.061), (73, 0.027), (78, 0.014), (80, 0.012), (83, 0.072), (84, 0.021), (98, 0.082)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.78421783 <a title="179-lda-1" href="./acl-2010-Now%2C_Where_Was_I%3F_Resumption_Strategies_for_an_In-Vehicle_Dialogue_System.html">179 acl-2010-Now, Where Was I? Resumption Strategies for an In-Vehicle Dialogue System</a></p>
<p>Author: Jessica Villing</p><p>Abstract: In-vehicle dialogue systems often contain more than one application, e.g. a navigation and a telephone application. This means that the user might, for example, interrupt the interaction with the telephone application to ask for directions from the navigation application, and then resume the dialogue with the telephone application. In this paper we present an analysis of interruption and resumption behaviour in human-human in-vehicle dialogues and also propose some implications for resumption strategies in an in-vehicle dialogue system.</p><p>2 0.5926227 <a title="179-lda-2" href="./acl-2010-Don%27t_%27Have_a_Clue%27%3F_Unsupervised_Co-Learning_of_Downward-Entailing_Operators..html">92 acl-2010-Don't 'Have a Clue'? Unsupervised Co-Learning of Downward-Entailing Operators.</a></p>
<p>Author: Cristian Danescu-Niculescu-Mizil ; Lillian Lee</p><p>Abstract: Researchers in textual entailment have begun to consider inferences involving downward-entailing operators, an interesting and important class of lexical items that change the way inferences are made. Recent work proposed a method for learning English downward-entailing operators that requires access to a high-quality collection of negative polarity items (NPIs). However, English is one of the very few languages for which such a list exists. We propose the first approach that can be applied to the many languages for which there is no pre-existing high-precision database of NPIs. As a case study, we apply our method to Romanian and show that our method yields good results. Also, we perform a cross-linguistic analysis that suggests interesting connections to some findings in linguistic typology.</p><p>3 0.31406417 <a title="179-lda-3" href="./acl-2010-Sparsity_in_Dependency_Grammar_Induction.html">214 acl-2010-Sparsity in Dependency Grammar Induction</a></p>
<p>Author: Jennifer Gillenwater ; Kuzman Ganchev ; Joao Graca ; Fernando Pereira ; Ben Taskar</p><p>Abstract: A strong inductive bias is essential in unsupervised grammar induction. We explore a particular sparsity bias in dependency grammars that encourages a small number of unique dependency types. Specifically, we investigate sparsity-inducing penalties on the posterior distributions of parent-child POS tag pairs in the posterior regularization (PR) framework of Graça et al. (2007). In ex- periments with 12 languages, we achieve substantial gains over the standard expectation maximization (EM) baseline, with average improvement in attachment accuracy of 6.3%. Further, our method outperforms models based on a standard Bayesian sparsity-inducing prior by an average of 4.9%. On English in particular, we show that our approach improves on several other state-of-the-art techniques.</p><p>4 0.31362927 <a title="179-lda-4" href="./acl-2010-Using_Anaphora_Resolution_to_Improve_Opinion_Target_Identification_in_Movie_Reviews.html">251 acl-2010-Using Anaphora Resolution to Improve Opinion Target Identification in Movie Reviews</a></p>
<p>Author: Niklas Jakob ; Iryna Gurevych</p><p>Abstract: unkown-abstract</p><p>5 0.31245703 <a title="179-lda-5" href="./acl-2010-Inducing_Domain-Specific_Semantic_Class_Taggers_from_%28Almost%29_Nothing.html">150 acl-2010-Inducing Domain-Specific Semantic Class Taggers from (Almost) Nothing</a></p>
<p>Author: Ruihong Huang ; Ellen Riloff</p><p>Abstract: This research explores the idea of inducing domain-specific semantic class taggers using only a domain-specific text collection and seed words. The learning process begins by inducing a classifier that only has access to contextual features, forcing it to generalize beyond the seeds. The contextual classifier then labels new instances, to expand and diversify the training set. Next, a cross-category bootstrapping process simultaneously trains a suite of classifiers for multiple semantic classes. The positive instances for one class are used as negative instances for the others in an iterative bootstrapping cycle. We also explore a one-semantic-class-per-discourse heuristic, and use the classifiers to dynam- ically create semantic features. We evaluate our approach by inducing six semantic taggers from a collection of veterinary medicine message board posts.</p><p>6 0.30719775 <a title="179-lda-6" href="./acl-2010-Sentence_and_Expression_Level_Annotation_of_Opinions_in_User-Generated_Discourse.html">208 acl-2010-Sentence and Expression Level Annotation of Opinions in User-Generated Discourse</a></p>
<p>7 0.30350715 <a title="179-lda-7" href="./acl-2010-Generating_Focused_Topic-Specific_Sentiment_Lexicons.html">123 acl-2010-Generating Focused Topic-Specific Sentiment Lexicons</a></p>
<p>8 0.30287176 <a title="179-lda-8" href="./acl-2010-A_Unified_Graph_Model_for_Sentence-Based_Opinion_Retrieval.html">22 acl-2010-A Unified Graph Model for Sentence-Based Opinion Retrieval</a></p>
<p>9 0.3025794 <a title="179-lda-9" href="./acl-2010-Hierarchical_Sequential_Learning_for_Extracting_Opinions_and_Their_Attributes.html">134 acl-2010-Hierarchical Sequential Learning for Extracting Opinions and Their Attributes</a></p>
<p>10 0.30072162 <a title="179-lda-10" href="./acl-2010-Automatically_Generating_Annotator_Rationales_to_Improve_Sentiment_Classification.html">42 acl-2010-Automatically Generating Annotator Rationales to Improve Sentiment Classification</a></p>
<p>11 0.29961765 <a title="179-lda-11" href="./acl-2010-The_Prevalence_of_Descriptive_Referring_Expressions_in_News_and_Narrative.html">231 acl-2010-The Prevalence of Descriptive Referring Expressions in News and Narrative</a></p>
<p>12 0.29925853 <a title="179-lda-12" href="./acl-2010-Entity-Based_Local_Coherence_Modelling_Using_Topological_Fields.html">101 acl-2010-Entity-Based Local Coherence Modelling Using Topological Fields</a></p>
<p>13 0.29878396 <a title="179-lda-13" href="./acl-2010-Supervised_Noun_Phrase_Coreference_Research%3A_The_First_Fifteen_Years.html">219 acl-2010-Supervised Noun Phrase Coreference Research: The First Fifteen Years</a></p>
<p>14 0.29821166 <a title="179-lda-14" href="./acl-2010-Understanding_the_Semantic_Structure_of_Noun_Phrase_Queries.html">245 acl-2010-Understanding the Semantic Structure of Noun Phrase Queries</a></p>
<p>15 0.297203 <a title="179-lda-15" href="./acl-2010-Bootstrapping_Semantic_Analyzers_from_Non-Contradictory_Texts.html">55 acl-2010-Bootstrapping Semantic Analyzers from Non-Contradictory Texts</a></p>
<p>16 0.29713461 <a title="179-lda-16" href="./acl-2010-Minimized_Models_and_Grammar-Informed_Initialization_for_Supertagging_with_Highly_Ambiguous_Lexicons.html">172 acl-2010-Minimized Models and Grammar-Informed Initialization for Supertagging with Highly Ambiguous Lexicons</a></p>
<p>17 0.29704911 <a title="179-lda-17" href="./acl-2010-Creating_Robust_Supervised_Classifiers_via_Web-Scale_N-Gram_Data.html">76 acl-2010-Creating Robust Supervised Classifiers via Web-Scale N-Gram Data</a></p>
<p>18 0.29649958 <a title="179-lda-18" href="./acl-2010-Open-Domain_Semantic_Role_Labeling_by_Modeling_Word_Spans.html">184 acl-2010-Open-Domain Semantic Role Labeling by Modeling Word Spans</a></p>
<p>19 0.29649091 <a title="179-lda-19" href="./acl-2010-Experiments_in_Graph-Based_Semi-Supervised_Learning_Methods_for_Class-Instance_Acquisition.html">109 acl-2010-Experiments in Graph-Based Semi-Supervised Learning Methods for Class-Instance Acquisition</a></p>
<p>20 0.29639319 <a title="179-lda-20" href="./acl-2010-Automatic_Generation_of_Story_Highlights.html">39 acl-2010-Automatic Generation of Story Highlights</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
