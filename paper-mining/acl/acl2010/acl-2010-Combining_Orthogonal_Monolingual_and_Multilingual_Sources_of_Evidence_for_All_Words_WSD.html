<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>62 acl-2010-Combining Orthogonal Monolingual and Multilingual Sources of Evidence for All Words WSD</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-62" href="#">acl2010-62</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>62 acl-2010-Combining Orthogonal Monolingual and Multilingual Sources of Evidence for All Words WSD</h1>
<br/><p>Source: <a title="acl-2010-62-pdf" href="http://aclweb.org/anthology//P/P10/P10-1156.pdf">pdf</a></p><p>Author: Weiwei Guo ; Mona Diab</p><p>Abstract: Word Sense Disambiguation remains one ofthe most complex problems facing computational linguists to date. In this paper we present a system that combines evidence from a monolingual WSD system together with that from a multilingual WSD system to yield state of the art performance on standard All-Words data sets. The monolingual system is based on a modification ofthe graph based state ofthe art algorithm In-Degree. The multilingual system is an improvement over an AllWords unsupervised approach, SALAAM. SALAAM exploits multilingual evidence as a means of disambiguation. In this paper, we present modifications to both of the original approaches and then their combination. We finally report the highest results obtained to date on the SENSEVAL 2 standard data set using an unsupervised method, we achieve an overall F measure of 64.58 using a voting scheme.</p><p>Reference: <a title="acl-2010-62-reference" href="../acl2010_reference/acl-2010-Combining_Orthogonal_Monolingual_and_Multilingual_Sources_of_Evidence_for_All_Words_WSD_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In this paper we present a system that combines evidence from a monolingual WSD system together with that from a multilingual WSD system to yield state of the art performance on standard All-Words data sets. [sent-4, score-0.342]
</p><p>2 The monolingual system is based on a modification ofthe graph based state ofthe art algorithm In-Degree. [sent-5, score-0.23]
</p><p>3 The multilingual  system is an improvement over an AllWords unsupervised approach, SALAAM. [sent-6, score-0.17]
</p><p>4 SALAAM exploits multilingual evidence as a means of disambiguation. [sent-7, score-0.15]
</p><p>5 We finally report the highest results obtained to date on the SENSEVAL 2 standard data set using an unsupervised method, we achieve an overall F measure of 64. [sent-9, score-0.116]
</p><p>6 The two WSD systems are a monolingual system Re lCont and a multilingual system TransCont . [sent-22, score-0.23]
</p><p>7 Tran sCont is an enhancement over an existing approach that leverages multilingual evidence through projection, SALAAM, described in detail in (Diab and Resnik, 2002). [sent-24, score-0.111]
</p><p>8 We show that by combining both sources of evidence, our approach yields the highest performance for an unsupervised system to date on standard All-Words data sets. [sent-26, score-0.196]
</p><p>9 For example a sentence such as ‘I walked by the bank and saw many beautiful plants there. [sent-37, score-0.166]
</p><p>10 ’ will have the verbs ‘walked, saw’, the nouns ‘bank, plants’ , the adjectives ‘many, beautiful’, and the adverb ‘there’, be disambiguated from a standard lexical resource. [sent-38, score-0.114]
</p><p>11 edu relies on WN similarity measures in conjunction with evidence obtained through exploiting multilingual evidence. [sent-48, score-0.322]
</p><p>12 3 4  Our Approach  Our current investigation exploits two basic unsupervised approaches that perform at state-of-the-  art for the AW WSD task in an unsupervised setting. [sent-50, score-0.199]
</p><p>13 Crucially the two systems rely on different sources of evidence allowing them to complement each other to a large extent leading to better performance than for each system independently. [sent-51, score-0.099]
</p><p>14 Given a target content word and co-occurring contextual clues, the monolingual system RelCont attempts to assign the approporiate meaning definition to the target word. [sent-52, score-0.249]
</p><p>15 In the basic SM07 work, the authors combine different semantic similarity measures with different graph based algorithms as an extension to work in (Mihalcea, 2005). [sent-60, score-0.219]
</p><p>16 sTuwcoh senses oftwo different words may be connected by an edge e, depending on their distance. [sent-70, score-0.104]
</p><p>17 That two senses are connected suggests they should have influence on each other, accordingly a maximum 3We acknowledge the existence of many research papers that tackled the AW WSD problem using unsupervised approaches, yet for lack of space we will not be able to review most of them. [sent-71, score-0.208]
</p><p>18 The highest yield-  ing algorithm in their work is the In-Degree algorithm combining different WN similarity measures depending on POS. [sent-74, score-0.274]
</p><p>19 , 1997) similarity measure within nouns, the Leacock & Chodorow (LCH) (Leacock and Chodorow, 1998) similarity measure within verbs, and the Lesk (Lesk, 1986) similarity measure within adjectives, within adverbs, and among different POS tag pairings. [sent-76, score-0.583]
</p><p>20 They report a state-ofthe-art unsupervised system that yields an overall performance across all AW POS sets of 57. [sent-79, score-0.165]
</p><p>21 The In-Degree algorithm presents the problem as a weighted graph –  –  with senses as nodes and the similarity between senses as weights on edges. [sent-84, score-0.42]
</p><p>22 After all the In-Degree values for each sense are computed, the sense with maximum value is chosen as the final sense for that word. [sent-87, score-0.486]
</p><p>23 In this paper, we use the In-Degree algorithm while applying some modifications to the basic similarity measures exploited and the WN lexical resource tapped into. [sent-88, score-0.251]
</p><p>24 Our modifications are described as follows: JCN for Verb-Verb Similarity In our implementation of the In-Degree algorithm, we use the JCN similarity measure for both Noun-Noun similarity calculation similar to SM07. [sent-90, score-0.353]
</p><p>25 , 2005), henceforth (PEA05), we expand the basic Lesk similarity measure to take into account the glosses for all the relations for the synsets on the contextual words and compare them with the glosses of the target word senses, therefore going beyond the is-a relation. [sent-93, score-0.462]
</p><p>26 We exploit the observation that WN senses are too fine-grained, accordingly the neighbors would be slightly varied while sharing significant semantic meaning content. [sent-94, score-0.213]
</p><p>27 In PEA05, the authors retrieve all the relevant neighbors to form a bag of words for both the target sense and the surrounding senses of the context words, they specifically focus on the Lesk similarity measure. [sent-97, score-0.472]
</p><p>28 In our current work, we employ the neighbors in a disambiguation strategy using different similarity measures one pair at a  time. [sent-98, score-0.312]
</p><p>29 Our algorithm takes as input a target sense and a sense pertaining to a word in the surrounding context, and returns a sense similarity score. [sent-99, score-0.691]
</p><p>30 5 For the monolingual system, we employ the same normalization values used in SM07 for the different similarity measures. [sent-102, score-0.227]
</p><p>31 Namely for the Lesk and Expand-Lesk, we use the same cut-offvalue of 240, accordingly, if the Lesk or Expand-Lesk similarity value returns 0 <= 240 it is converted to a real number in the interval [0,1], any similarity over 240 is by default mapped to 1. [sent-103, score-0.286]
</p><p>32 We also experimented with different thresholds for the Lesk and Expand-Lesk similarity measure using the SENSEVAL 3 data as a tuning set. [sent-105, score-0.202]
</p><p>33 5We experimented with expanding both the contextual sense and the target sense and we found that the unreliability of some of the relations is detrimental to the algorithm’s performance. [sent-114, score-0.391]
</p><p>34 Therefore, we expand the number of glosses available in WN by using the SemCor data set, thereby adding more examples to compare. [sent-118, score-0.082]
</p><p>35 The SemCor corpus is a corpus that is manually sense tagged (Miller, In this expansion, depending on the version of WN, we use the sense-index file in the WN Database to convert the SemCor data to the appropriate version sense annotations. [sent-119, score-0.324]
</p><p>36 6  We augment the sense entries for the different POS WN databases with example usages from SemCor. [sent-121, score-0.199]
</p><p>37 The SALAAM algorithm exploits the word correspondence cross linguistically to tag word senses on words in running text. [sent-132, score-0.244]
</p><p>38 The first assumption is that senses ofpolysemous words in one language could be lexicalized differently in other languages. [sent-134, score-0.104]
</p><p>39 Then perform disambiguation on the typeset clusters using WN. [sent-142, score-0.217]
</p><p>40 Once senses are identified for each word in the cluster, the senses are propagated back to the origi-  nal word instances in the corpus. [sent-143, score-0.208]
</p><p>41 In the SALAAM algorithm, the disambiguation step is carried out as follows: within each of these target sets consider all possible sense tags for each word and choose sense tags informed by semantic similarity with all the other words in the whole group. [sent-144, score-0.597]
</p><p>42 The algorithm is a greedy algorithm that aims at maximizing the similarity of the chosen sense across all the words in the set. [sent-145, score-0.367]
</p><p>43 The SALAAM disambiguation algorithm used the noun groupings (NounGroupings) algorithm described in DR02. [sent-146, score-0.161]
</p><p>44 The authors report only results on the nouns only since NounGroupings heavily exploits the hierarchy structure of the WN noun taxonomy, which does not exist for adjectives and adverbs, and is very shallow for verbs. [sent-148, score-0.143]
</p><p>45 Essentially SALAAM relies on variability in translation as it is important to have multiple words in a typeset to allow for disambiguation. [sent-149, score-0.179]
</p><p>46 We still rely on parallel corpora, we extract typesets based on the intersection of word alignments in both alignment directions using more advanced GIZA++ machinery. [sent-155, score-0.126]
</p><p>47 Moreover, we modified the underlying disambiguation method on the typesets. [sent-157, score-0.099]
</p><p>48 Our disambiguation method relies on calculating the sense pair similarity exhaustively across all the 1545  word types in a typeset and choosing the combination that yields the highest similarity. [sent-159, score-0.594]
</p><p>49 We experimented with all the WN similarity measures in the WN similarity package. [sent-160, score-0.324]
</p><p>50 We found that the best results are yielded using the Lesk2/Lesk3 similarity measure for N, A and R POS tagsets, while the Lin and JCN measures yield the best performance for the verbs. [sent-162, score-0.267]
</p><p>51 In contrast to the DR02 approach, we modify the internal WSD process to use the In-Degree algorithm on the typeset, so each sense obtains a confidence, and the sense(s) with the highest confidences are returned. [sent-163, score-0.193]
</p><p>52 3 Combining Re lCont and TransCont Our objective is to combine the different sources ofevidence for the purposes ofproducing an effective overall global WSD system that is able to disambiguate all content words in running text. [sent-165, score-0.093]
</p><p>53 1 MERGE In this combination scheme, the words in the typeset that result from the TransCont approach are added to the context of the target word in the RelCont approach. [sent-169, score-0.149]
</p><p>54 Heeding this difference, we proceed to calculate similarity for words in the typesets using different similarity measures. [sent-171, score-0.382]
</p><p>55 In the case of noun-noun similarity, in the original Re lCont experiments we use JCN, however with the words present in the TransCont typesets we use one of the Lesk variants, Lesk2 or Lesk3. [sent-172, score-0.096]
</p><p>56 Yet for the words yielded in the TransCont typesets a  method that exploits the underlying rich relations in the noun hierarchy captures the semantic similarity more aptly. [sent-174, score-0.365]
</p><p>57 In the case of verbs we still maintain the JCN similarity as it most effective 9http://wn-similarity. [sent-175, score-0.182]
</p><p>58 net/ given the shallowness of the verb hierarchy and the inherent nature of the verbal synsets which are differentiated along syntactic rather than semantic dimensions. [sent-177, score-0.091]
</p><p>59 We employ the Lesk algorithm still with A-A and R-R similarity and when comparing across different POS tag pairings. [sent-178, score-0.244]
</p><p>60 2 VOTE In this combination scheme, the output of the global disambiguation system is simply an intersection of the two outputs from the two underlying systems Re lCont and TransCont. [sent-181, score-0.134]
</p><p>61 Specifically, we sum up the confidence ranging from 0 to 1 of the two system In-Degree algorithm outputs to obtain a final confidence for each sense, choosing the sense(s) that yields the highest confidences. [sent-182, score-0.108]
</p><p>62 We include the most frequent sense baseline (MFBL), though  we note that we consider the most frequent sense or first sense baseline to be a supervised baseline since it depends crucially on SemCor in ranking the senses within 3. [sent-198, score-0.59]
</p><p>63 11From an application standpoint, we do not find the first sense baseline to be of interest since it introduces a strong level of uniformity removing semantic variability which is not desirable. [sent-201, score-0.193]
</p><p>64 Even if the first sense achieves higher results in data sets, it is an artifact of the size of the data and the very limited number of documents under investigation. [sent-202, score-0.162]
</p><p>65 Our overall results on all the data sets clearly outperform the baseline as well as state-of-theart performance using an unsupervised system (SM07) in overall f-measure across all the data sets. [sent-216, score-0.152]
</p><p>66 12% ) is probably due to the fact that we do not consider the items tagged as ”U” and also we resolve some of the POS tag mismatches between the gold set  and the test data. [sent-220, score-0.101]
</p><p>67 We note that for the SV2AW data set our coverage is not 100% due to some POS tag mismatches that could not have been resolved automatically. [sent-221, score-0.101]
</p><p>68 In observing the performance of the overall RelCont, we note that using JCN for verbs clearly outperforms using the LCH similarity measure. [sent-223, score-0.211]
</p><p>69 Observing the results yielded per POS in Table 1, ExpandL seems to have the biggest impact on the Nouns only. [sent-226, score-0.088]
</p><p>70 In fact the performance on the nouns deteriorated from the base condition JCN-V from 68. [sent-229, score-0.113]
</p><p>71 This maybe due to inconsistencies in the annotations of nouns in SemCor or the very fine granularity of the nouns in  WN. [sent-232, score-0.086]
</p><p>72 Combining SemCor and ExpandL seems to have a positive impact on the verbs and adverbs, but not on the nouns and adjectives. [sent-236, score-0.082]
</p><p>73 For example, we see that SemCor augmentation helps all POS tag sets over using ExpandL alone or even when combined with SemCor. [sent-238, score-0.119]
</p><p>74 87 compared to the best unsupervised system IRST-DDD-U which yielded an F-measure of 58. [sent-245, score-0.152]
</p><p>75 Therefore our parallel corpus is the French English translation condition mentioned in DR02 work as FrGl. [sent-252, score-0.1]
</p><p>76 We have 4 experimental conditions: FRGL using Lesk2 for all POS tags in the typeset disambiguation (Lesk2); FRGL using Lesk3 for all POS tags (Lesk3); using Lesk3 for N, A and R but LIN similarity measure for verbs (Lesk3 Lin); using Lesk3 for N, A and R but JCN for verbs (Lesk3 JCN). [sent-253, score-0.466]
</p><p>77 Essentially our new implementation of the multilingual system significantly outperforms the original DR02 implementation for all experimental conditions. [sent-256, score-0.111]
</p><p>78 1547  Table 1: RelCont  F-measure results per POS tag per condition for SV2AW using WN 1. [sent-257, score-0.2]
</p><p>79 Table 2: RelCont  F-measure results per POS tag per condition for SV3AW using WN 1. [sent-260, score-0.2]
</p><p>80 All the combined experimental conditions have the same percentage coverage. [sent-266, score-0.095]
</p><p>81 In Table 5 we note that the combined conditions outperform the two base systems independently, using TransCont is always helpful for any ofthe 3 monolingual systems, no matter we use VOTE or MERGE. [sent-270, score-0.179]
</p><p>82 In Table 6 the combined result is not always better than the corresponding monolingual system. [sent-272, score-0.133]
</p><p>83 There may be 2 main reasons for the loss: (1) SV3 is the tuning set in SM07, and we inherit the thresholds for similarity metrics from that study. [sent-276, score-0.174]
</p><p>84 6  Discussion  We looked closely at the data in the combined conditions attempting to get a feel for the data and understand what was captured and what was not. [sent-282, score-0.095]
</p><p>85 Some ofthe good examples that are captured in the combined system that are not tagged in RelCont is the case of ringer in Like most of the other 6,000 churches in Britain with sets of bells , St. [sent-283, score-0.16]
</p><p>86 The RelCont answer is ringer sense number 4:  (horseshoes) the successful throw of a horseshoe 1548  Table 3: TransCont  Table  4:  F-measure results per POS tag per condition for SV2AW using WN 1. [sent-286, score-0.4]
</p><p>87 23M6597easur  TransCont  F-measure results per POS tag per condition for SV3AW using WN  1. [sent-294, score-0.2]
</p><p>88 When the merged system is employed we see the correct sense being chosen as sense number 1 in the MERGE condition: defined in WN as a person who rings church bells (as for summoning the congregation) resulting from a corresponding translation into French as sonneur. [sent-298, score-0.397]
</p><p>89 ”, the sense of English here is clearly in reference to the people of England,  however, our WSD system preferred the language sense of the word. [sent-303, score-0.359]
</p><p>90 If it had access to syntactic/semantic roles we assume it could capture that this sense of the word entails volition for example. [sent-305, score-0.162]
</p><p>91 7  Conclusions and Future Directions  In this paper we present a framework that combines orthogonal sources of evidence to create a state-of-the-art system for the task of WSD disambiguation for AW. [sent-309, score-0.235]
</p><p>92 Our approach yields an overall global F measure of 64. [sent-310, score-0.099]
</p><p>93 58 for the standard SV2AW data set combining monolingual and mul-  tilingual evidence. [sent-311, score-0.115]
</p><p>94 An unsupervised method for word sense tagging using parallel corpora. [sent-327, score-0.251]
</p><p>95 In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics, 1549  Table 5: F-measure % for all Combined experimental conditions  on  SV2AW  Table 6: F-measure % for all Combined experimental conditions  on  SV3AW  pages 255–262, Philadelphia, Pennsylvania, USA, July. [sent-328, score-0.092]
</p><p>96 Semantic similarity based on corpus statistics and lexical taxonomy. [sent-349, score-0.143]
</p><p>97 Combining local context and wordnet sense similarity for word sense identification. [sent-355, score-0.499]
</p><p>98 Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone. [sent-361, score-0.261]
</p><p>99 Unsupervised large-vocabulary word sense disambiguation with graph-based algorithms for sequence data labeling. [sent-365, score-0.261]
</p><p>100 Unsupervised graph-based word sense disambiguation using measures of word semantic similarity. [sent-406, score-0.299]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('transcont', 0.422), ('semcor', 0.277), ('wsd', 0.261), ('relcont', 0.249), ('salaam', 0.249), ('jcn', 0.246), ('wn', 0.203), ('lesk', 0.2), ('lcont', 0.173), ('sense', 0.162), ('expandl', 0.153), ('similarity', 0.143), ('typeset', 0.118), ('senses', 0.104), ('aw', 0.101), ('disambiguation', 0.099), ('typesets', 0.096), ('senseval', 0.096), ('diab', 0.086), ('pos', 0.085), ('monolingual', 0.084), ('multilingual', 0.076), ('tag', 0.07), ('condition', 0.07), ('navigli', 0.062), ('synsets', 0.062), ('lch', 0.062), ('unsupervised', 0.059), ('yielded', 0.058), ('guo', 0.058), ('mfbl', 0.058), ('noungroupings', 0.058), ('glosses', 0.052), ('re', 0.05), ('combined', 0.049), ('adverbs', 0.047), ('sinha', 0.046), ('walked', 0.046), ('conditions', 0.046), ('accordingly', 0.045), ('merge', 0.044), ('nouns', 0.043), ('art', 0.042), ('yields', 0.042), ('mona', 0.041), ('verbs', 0.039), ('exploits', 0.039), ('modifications', 0.039), ('bells', 0.038), ('frgl', 0.038), ('ringer', 0.038), ('graph', 0.038), ('measures', 0.038), ('expansion', 0.038), ('translated', 0.038), ('orthogonal', 0.037), ('augment', 0.037), ('mihalcea', 0.037), ('contextual', 0.036), ('leacock', 0.036), ('system', 0.035), ('vote', 0.035), ('columbia', 0.035), ('evidence', 0.035), ('bank', 0.034), ('perceive', 0.034), ('french', 0.032), ('meaning', 0.032), ('neighbors', 0.032), ('wordnet', 0.032), ('adjectives', 0.032), ('combining', 0.031), ('algorithm', 0.031), ('semeval', 0.031), ('variability', 0.031), ('thresholds', 0.031), ('target', 0.031), ('mismatches', 0.031), ('relies', 0.03), ('rada', 0.03), ('per', 0.03), ('parallel', 0.03), ('saw', 0.03), ('expand', 0.03), ('namely', 0.029), ('overall', 0.029), ('tran', 0.029), ('carpuat', 0.029), ('plants', 0.029), ('weiwei', 0.029), ('sources', 0.029), ('hierarchy', 0.029), ('palmer', 0.028), ('henceforth', 0.028), ('measure', 0.028), ('sight', 0.027), ('incident', 0.027), ('beautiful', 0.027), ('chodorow', 0.027), ('resnik', 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="62-tfidf-1" href="./acl-2010-Combining_Orthogonal_Monolingual_and_Multilingual_Sources_of_Evidence_for_All_Words_WSD.html">62 acl-2010-Combining Orthogonal Monolingual and Multilingual Sources of Evidence for All Words WSD</a></p>
<p>Author: Weiwei Guo ; Mona Diab</p><p>Abstract: Word Sense Disambiguation remains one ofthe most complex problems facing computational linguists to date. In this paper we present a system that combines evidence from a monolingual WSD system together with that from a multilingual WSD system to yield state of the art performance on standard All-Words data sets. The monolingual system is based on a modification ofthe graph based state ofthe art algorithm In-Degree. The multilingual system is an improvement over an AllWords unsupervised approach, SALAAM. SALAAM exploits multilingual evidence as a means of disambiguation. In this paper, we present modifications to both of the original approaches and then their combination. We finally report the highest results obtained to date on the SENSEVAL 2 standard data set using an unsupervised method, we achieve an overall F measure of 64.58 using a voting scheme.</p><p>2 0.26209378 <a title="62-tfidf-2" href="./acl-2010-It_Makes_Sense%3A_A_Wide-Coverage_Word_Sense_Disambiguation_System_for_Free_Text.html">152 acl-2010-It Makes Sense: A Wide-Coverage Word Sense Disambiguation System for Free Text</a></p>
<p>Author: Zhi Zhong ; Hwee Tou Ng</p><p>Abstract: Word sense disambiguation (WSD) systems based on supervised learning achieved the best performance in SensEval and SemEval workshops. However, there are few publicly available open source WSD systems. This limits the use of WSD in other applications, especially for researchers whose research interests are not in WSD. In this paper, we present IMS, a supervised English all-words WSD system. The flexible framework of IMS allows users to integrate different preprocessing tools, additional features, and different classifiers. By default, we use linear support vector machines as the classifier with multiple knowledge-based features. In our implementation, IMS achieves state-of-the-art results on several SensEval and SemEval tasks.</p><p>3 0.20038156 <a title="62-tfidf-3" href="./acl-2010-Topic_Models_for_Word_Sense_Disambiguation_and_Token-Based_Idiom_Detection.html">237 acl-2010-Topic Models for Word Sense Disambiguation and Token-Based Idiom Detection</a></p>
<p>Author: Linlin Li ; Benjamin Roth ; Caroline Sporleder</p><p>Abstract: This paper presents a probabilistic model for sense disambiguation which chooses the best sense based on the conditional probability of sense paraphrases given a context. We use a topic model to decompose this conditional probability into two conditional probabilities with latent variables. We propose three different instantiations of the model for solving sense disambiguation problems with different degrees of resource availability. The proposed models are tested on three different tasks: coarse-grained word sense disambiguation, fine-grained word sense disambiguation, and detection of literal vs. nonliteral usages of potentially idiomatic expressions. In all three cases, we outper- form state-of-the-art systems either quantitatively or statistically significantly.</p><p>4 0.19308923 <a title="62-tfidf-4" href="./acl-2010-Knowledge-Rich_Word_Sense_Disambiguation_Rivaling_Supervised_Systems.html">156 acl-2010-Knowledge-Rich Word Sense Disambiguation Rivaling Supervised Systems</a></p>
<p>Author: Simone Paolo Ponzetto ; Roberto Navigli</p><p>Abstract: One of the main obstacles to highperformance Word Sense Disambiguation (WSD) is the knowledge acquisition bottleneck. In this paper, we present a methodology to automatically extend WordNet with large amounts of semantic relations from an encyclopedic resource, namely Wikipedia. We show that, when provided with a vast amount of high-quality semantic relations, simple knowledge-lean disambiguation algorithms compete with state-of-the-art supervised WSD systems in a coarse-grained all-words setting and outperform them on gold-standard domain-specific datasets.</p><p>5 0.19240278 <a title="62-tfidf-5" href="./acl-2010-All_Words_Domain_Adapted_WSD%3A_Finding_a_Middle_Ground_between_Supervision_and_Unsupervision.html">26 acl-2010-All Words Domain Adapted WSD: Finding a Middle Ground between Supervision and Unsupervision</a></p>
<p>Author: Mitesh Khapra ; Anup Kulkarni ; Saurabh Sohoney ; Pushpak Bhattacharyya</p><p>Abstract: In spite of decades of research on word sense disambiguation (WSD), all-words general purpose WSD has remained a distant goal. Many supervised WSD systems have been built, but the effort of creating the training corpus - annotated sense marked corpora - has always been a matter of concern. Therefore, attempts have been made to develop unsupervised and knowledge based techniques for WSD which do not need sense marked corpora. However such approaches have not proved effective, since they typically do not better Wordnet first sense baseline accuracy. Our research reported here proposes to stick to the supervised approach, but with far less demand on annotation. We show that if we have ANY sense marked corpora, be it from mixed domain or a specific domain, a small amount of annotation in ANY other domain can deliver the goods almost as if exhaustive sense marking were available in that domain. We have tested our approach across Tourism and Health domain corpora, using also the well known mixed domain SemCor corpus. Accuracy figures close to self domain training lend credence to the viability of our approach. Our contribution thus lies in finding a convenient middle ground between pure supervised and pure unsupervised WSD. Finally, our approach is not restricted to any specific set of target words, a departure from a commonly observed practice in domain specific WSD.</p><p>6 0.1631002 <a title="62-tfidf-6" href="./acl-2010-WSD_as_a_Distributed_Constraint_Optimization_Problem.html">257 acl-2010-WSD as a Distributed Constraint Optimization Problem</a></p>
<p>7 0.14556867 <a title="62-tfidf-7" href="./acl-2010-Wikipedia_as_Sense_Inventory_to_Improve_Diversity_in_Web_Search_Results.html">261 acl-2010-Wikipedia as Sense Inventory to Improve Diversity in Web Search Results</a></p>
<p>8 0.14366333 <a title="62-tfidf-8" href="./acl-2010-Bilingual_Sense_Similarity_for_Statistical_Machine_Translation.html">51 acl-2010-Bilingual Sense Similarity for Statistical Machine Translation</a></p>
<p>9 0.13830219 <a title="62-tfidf-9" href="./acl-2010-BabelNet%3A_Building_a_Very_Large_Multilingual_Semantic_Network.html">44 acl-2010-BabelNet: Building a Very Large Multilingual Semantic Network</a></p>
<p>10 0.094904363 <a title="62-tfidf-10" href="./acl-2010-An_Active_Learning_Approach_to_Finding_Related_Terms.html">27 acl-2010-An Active Learning Approach to Finding Related Terms</a></p>
<p>11 0.093497798 <a title="62-tfidf-11" href="./acl-2010-Contextualizing_Semantic_Representations_Using_Syntactically_Enriched_Vector_Models.html">70 acl-2010-Contextualizing Semantic Representations Using Syntactically Enriched Vector Models</a></p>
<p>12 0.082375064 <a title="62-tfidf-12" href="./acl-2010-Structural_Semantic_Relatedness%3A_A_Knowledge-Based_Method_to_Named_Entity_Disambiguation.html">218 acl-2010-Structural Semantic Relatedness: A Knowledge-Based Method to Named Entity Disambiguation</a></p>
<p>13 0.075408839 <a title="62-tfidf-13" href="./acl-2010-A_Framework_for_Figurative_Language_Detection_Based_on_Sense_Differentiation.html">5 acl-2010-A Framework for Figurative Language Detection Based on Sense Differentiation</a></p>
<p>14 0.069411837 <a title="62-tfidf-14" href="./acl-2010-Arabic_Named_Entity_Recognition%3A_Using_Features_Extracted_from_Noisy_Data.html">32 acl-2010-Arabic Named Entity Recognition: Using Features Extracted from Noisy Data</a></p>
<p>15 0.067586124 <a title="62-tfidf-15" href="./acl-2010-Improved_Unsupervised_POS_Induction_through_Prototype_Discovery.html">144 acl-2010-Improved Unsupervised POS Induction through Prototype Discovery</a></p>
<p>16 0.058537796 <a title="62-tfidf-16" href="./acl-2010-Phylogenetic_Grammar_Induction.html">195 acl-2010-Phylogenetic Grammar Induction</a></p>
<p>17 0.058110151 <a title="62-tfidf-17" href="./acl-2010-Extraction_and_Approximation_of_Numerical_Attributes_from_the_Web.html">113 acl-2010-Extraction and Approximation of Numerical Attributes from the Web</a></p>
<p>18 0.054216597 <a title="62-tfidf-18" href="./acl-2010-A_Structured_Model_for_Joint_Learning_of_Argument_Roles_and_Predicate_Senses.html">17 acl-2010-A Structured Model for Joint Learning of Argument Roles and Predicate Senses</a></p>
<p>19 0.052289702 <a title="62-tfidf-19" href="./acl-2010-The_S-Space_Package%3A_An_Open_Source_Package_for_Word_Space_Models.html">232 acl-2010-The S-Space Package: An Open Source Package for Word Space Models</a></p>
<p>20 0.052276522 <a title="62-tfidf-20" href="./acl-2010-Simultaneous_Tokenization_and_Part-Of-Speech_Tagging_for_Arabic_without_a_Morphological_Analyzer.html">213 acl-2010-Simultaneous Tokenization and Part-Of-Speech Tagging for Arabic without a Morphological Analyzer</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.197), (1, 0.058), (2, -0.046), (3, 0.02), (4, 0.288), (5, 0.03), (6, 0.132), (7, 0.099), (8, -0.027), (9, 0.11), (10, 0.064), (11, -0.091), (12, 0.062), (13, 0.072), (14, -0.112), (15, -0.133), (16, -0.026), (17, -0.15), (18, 0.054), (19, -0.008), (20, 0.02), (21, 0.009), (22, 0.051), (23, 0.07), (24, 0.079), (25, 0.114), (26, -0.004), (27, 0.092), (28, 0.078), (29, 0.099), (30, -0.017), (31, 0.013), (32, -0.003), (33, -0.038), (34, -0.01), (35, 0.009), (36, -0.018), (37, 0.12), (38, -0.027), (39, 0.014), (40, -0.014), (41, 0.082), (42, 0.077), (43, 0.096), (44, 0.09), (45, -0.063), (46, 0.014), (47, 0.014), (48, -0.056), (49, -0.044)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94114983 <a title="62-lsi-1" href="./acl-2010-Combining_Orthogonal_Monolingual_and_Multilingual_Sources_of_Evidence_for_All_Words_WSD.html">62 acl-2010-Combining Orthogonal Monolingual and Multilingual Sources of Evidence for All Words WSD</a></p>
<p>Author: Weiwei Guo ; Mona Diab</p><p>Abstract: Word Sense Disambiguation remains one ofthe most complex problems facing computational linguists to date. In this paper we present a system that combines evidence from a monolingual WSD system together with that from a multilingual WSD system to yield state of the art performance on standard All-Words data sets. The monolingual system is based on a modification ofthe graph based state ofthe art algorithm In-Degree. The multilingual system is an improvement over an AllWords unsupervised approach, SALAAM. SALAAM exploits multilingual evidence as a means of disambiguation. In this paper, we present modifications to both of the original approaches and then their combination. We finally report the highest results obtained to date on the SENSEVAL 2 standard data set using an unsupervised method, we achieve an overall F measure of 64.58 using a voting scheme.</p><p>2 0.90254587 <a title="62-lsi-2" href="./acl-2010-It_Makes_Sense%3A_A_Wide-Coverage_Word_Sense_Disambiguation_System_for_Free_Text.html">152 acl-2010-It Makes Sense: A Wide-Coverage Word Sense Disambiguation System for Free Text</a></p>
<p>Author: Zhi Zhong ; Hwee Tou Ng</p><p>Abstract: Word sense disambiguation (WSD) systems based on supervised learning achieved the best performance in SensEval and SemEval workshops. However, there are few publicly available open source WSD systems. This limits the use of WSD in other applications, especially for researchers whose research interests are not in WSD. In this paper, we present IMS, a supervised English all-words WSD system. The flexible framework of IMS allows users to integrate different preprocessing tools, additional features, and different classifiers. By default, we use linear support vector machines as the classifier with multiple knowledge-based features. In our implementation, IMS achieves state-of-the-art results on several SensEval and SemEval tasks.</p><p>3 0.86725956 <a title="62-lsi-3" href="./acl-2010-WSD_as_a_Distributed_Constraint_Optimization_Problem.html">257 acl-2010-WSD as a Distributed Constraint Optimization Problem</a></p>
<p>Author: Siva Reddy ; Abhilash Inumella</p><p>Abstract: This work models Word Sense Disambiguation (WSD) problem as a Distributed Constraint Optimization Problem (DCOP). To model WSD as a DCOP, we view information from various knowledge sources as constraints. DCOP algorithms have the remarkable property to jointly maximize over a wide range of utility functions associated with these constraints. We show how utility functions can be designed for various knowledge sources. For the purpose of evaluation, we modelled all words WSD as a simple DCOP problem. The results are competi- tive with state-of-art knowledge based systems.</p><p>4 0.83239055 <a title="62-lsi-4" href="./acl-2010-All_Words_Domain_Adapted_WSD%3A_Finding_a_Middle_Ground_between_Supervision_and_Unsupervision.html">26 acl-2010-All Words Domain Adapted WSD: Finding a Middle Ground between Supervision and Unsupervision</a></p>
<p>Author: Mitesh Khapra ; Anup Kulkarni ; Saurabh Sohoney ; Pushpak Bhattacharyya</p><p>Abstract: In spite of decades of research on word sense disambiguation (WSD), all-words general purpose WSD has remained a distant goal. Many supervised WSD systems have been built, but the effort of creating the training corpus - annotated sense marked corpora - has always been a matter of concern. Therefore, attempts have been made to develop unsupervised and knowledge based techniques for WSD which do not need sense marked corpora. However such approaches have not proved effective, since they typically do not better Wordnet first sense baseline accuracy. Our research reported here proposes to stick to the supervised approach, but with far less demand on annotation. We show that if we have ANY sense marked corpora, be it from mixed domain or a specific domain, a small amount of annotation in ANY other domain can deliver the goods almost as if exhaustive sense marking were available in that domain. We have tested our approach across Tourism and Health domain corpora, using also the well known mixed domain SemCor corpus. Accuracy figures close to self domain training lend credence to the viability of our approach. Our contribution thus lies in finding a convenient middle ground between pure supervised and pure unsupervised WSD. Finally, our approach is not restricted to any specific set of target words, a departure from a commonly observed practice in domain specific WSD.</p><p>5 0.69732451 <a title="62-lsi-5" href="./acl-2010-Topic_Models_for_Word_Sense_Disambiguation_and_Token-Based_Idiom_Detection.html">237 acl-2010-Topic Models for Word Sense Disambiguation and Token-Based Idiom Detection</a></p>
<p>Author: Linlin Li ; Benjamin Roth ; Caroline Sporleder</p><p>Abstract: This paper presents a probabilistic model for sense disambiguation which chooses the best sense based on the conditional probability of sense paraphrases given a context. We use a topic model to decompose this conditional probability into two conditional probabilities with latent variables. We propose three different instantiations of the model for solving sense disambiguation problems with different degrees of resource availability. The proposed models are tested on three different tasks: coarse-grained word sense disambiguation, fine-grained word sense disambiguation, and detection of literal vs. nonliteral usages of potentially idiomatic expressions. In all three cases, we outper- form state-of-the-art systems either quantitatively or statistically significantly.</p><p>6 0.67616928 <a title="62-lsi-6" href="./acl-2010-Knowledge-Rich_Word_Sense_Disambiguation_Rivaling_Supervised_Systems.html">156 acl-2010-Knowledge-Rich Word Sense Disambiguation Rivaling Supervised Systems</a></p>
<p>7 0.56613934 <a title="62-lsi-7" href="./acl-2010-BabelNet%3A_Building_a_Very_Large_Multilingual_Semantic_Network.html">44 acl-2010-BabelNet: Building a Very Large Multilingual Semantic Network</a></p>
<p>8 0.54901314 <a title="62-lsi-8" href="./acl-2010-A_Framework_for_Figurative_Language_Detection_Based_on_Sense_Differentiation.html">5 acl-2010-A Framework for Figurative Language Detection Based on Sense Differentiation</a></p>
<p>9 0.54015714 <a title="62-lsi-9" href="./acl-2010-Wikipedia_as_Sense_Inventory_to_Improve_Diversity_in_Web_Search_Results.html">261 acl-2010-Wikipedia as Sense Inventory to Improve Diversity in Web Search Results</a></p>
<p>10 0.49724844 <a title="62-lsi-10" href="./acl-2010-Bilingual_Sense_Similarity_for_Statistical_Machine_Translation.html">51 acl-2010-Bilingual Sense Similarity for Statistical Machine Translation</a></p>
<p>11 0.42493305 <a title="62-lsi-11" href="./acl-2010-An_Active_Learning_Approach_to_Finding_Related_Terms.html">27 acl-2010-An Active Learning Approach to Finding Related Terms</a></p>
<p>12 0.40278897 <a title="62-lsi-12" href="./acl-2010-A_Bayesian_Method_for_Robust_Estimation_of_Distributional_Similarities.html">3 acl-2010-A Bayesian Method for Robust Estimation of Distributional Similarities</a></p>
<p>13 0.39990482 <a title="62-lsi-13" href="./acl-2010-The_S-Space_Package%3A_An_Open_Source_Package_for_Word_Space_Models.html">232 acl-2010-The S-Space Package: An Open Source Package for Word Space Models</a></p>
<p>14 0.38586167 <a title="62-lsi-14" href="./acl-2010-The_Manually_Annotated_Sub-Corpus%3A_A_Community_Resource_for_and_by_the_People.html">230 acl-2010-The Manually Annotated Sub-Corpus: A Community Resource for and by the People</a></p>
<p>15 0.36360145 <a title="62-lsi-15" href="./acl-2010-Word_Representations%3A_A_Simple_and_General_Method_for_Semi-Supervised_Learning.html">263 acl-2010-Word Representations: A Simple and General Method for Semi-Supervised Learning</a></p>
<p>16 0.35636103 <a title="62-lsi-16" href="./acl-2010-Arabic_Named_Entity_Recognition%3A_Using_Features_Extracted_from_Noisy_Data.html">32 acl-2010-Arabic Named Entity Recognition: Using Features Extracted from Noisy Data</a></p>
<p>17 0.35515147 <a title="62-lsi-17" href="./acl-2010-Don%27t_%27Have_a_Clue%27%3F_Unsupervised_Co-Learning_of_Downward-Entailing_Operators..html">92 acl-2010-Don't 'Have a Clue'? Unsupervised Co-Learning of Downward-Entailing Operators.</a></p>
<p>18 0.35230559 <a title="62-lsi-18" href="./acl-2010-Identifying_Text_Polarity_Using_Random_Walks.html">141 acl-2010-Identifying Text Polarity Using Random Walks</a></p>
<p>19 0.35151735 <a title="62-lsi-19" href="./acl-2010-Pseudo-Word_for_Phrase-Based_Machine_Translation.html">201 acl-2010-Pseudo-Word for Phrase-Based Machine Translation</a></p>
<p>20 0.35021952 <a title="62-lsi-20" href="./acl-2010-SVD_and_Clustering_for_Unsupervised_POS_Tagging.html">205 acl-2010-SVD and Clustering for Unsupervised POS Tagging</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.329), (25, 0.084), (39, 0.012), (42, 0.016), (44, 0.015), (53, 0.025), (59, 0.099), (73, 0.049), (78, 0.028), (80, 0.014), (83, 0.088), (84, 0.028), (98, 0.122)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.97675067 <a title="62-lda-1" href="./acl-2010-Towards_Relational_POMDPs_for_Adaptive_Dialogue_Management.html">239 acl-2010-Towards Relational POMDPs for Adaptive Dialogue Management</a></p>
<p>Author: Pierre Lison</p><p>Abstract: Open-ended spoken interactions are typically characterised by both structural complexity and high levels of uncertainty, making dialogue management in such settings a particularly challenging problem. Traditional approaches have focused on providing theoretical accounts for either the uncertainty or the complexity of spoken dialogue, but rarely considered the two issues simultaneously. This paper describes ongoing work on a new approach to dialogue management which attempts to fill this gap. We represent the interaction as a Partially Observable Markov Decision Process (POMDP) over a rich state space incorporating both dialogue, user, and environment models. The tractability of the resulting POMDP can be preserved using a mechanism for dynamically constraining the action space based on prior knowledge over locally relevant dialogue structures. These constraints are encoded in a small set of general rules expressed as a Markov Logic network. The first-order expressivity of Markov Logic enables us to leverage the rich relational structure of the problem and efficiently abstract over large regions ofthe state and action spaces.</p><p>2 0.85655773 <a title="62-lda-2" href="./acl-2010-A_Tree_Transducer_Model_for_Synchronous_Tree-Adjoining_Grammars.html">21 acl-2010-A Tree Transducer Model for Synchronous Tree-Adjoining Grammars</a></p>
<p>Author: Andreas Maletti</p><p>Abstract: A characterization of the expressive power of synchronous tree-adjoining grammars (STAGs) in terms of tree transducers (or equivalently, synchronous tree substitution grammars) is developed. Essentially, a STAG corresponds to an extended tree transducer that uses explicit substitution in both the input and output. This characterization allows the easy integration of STAG into toolkits for extended tree transducers. Moreover, the applicability of the characterization to several representational and algorithmic problems is demonstrated.</p><p>3 0.84398931 <a title="62-lda-3" href="./acl-2010-Efficient_Third-Order_Dependency_Parsers.html">99 acl-2010-Efficient Third-Order Dependency Parsers</a></p>
<p>Author: Terry Koo ; Michael Collins</p><p>Abstract: We present algorithms for higher-order dependency parsing that are “third-order” in the sense that they can evaluate substructures containing three dependencies, and “efficient” in the sense that they require only O(n4) time. Importantly, our new parsers can utilize both sibling-style and grandchild-style interactions. We evaluate our parsers on the Penn Treebank and Prague Dependency Treebank, achieving unlabeled attachment scores of 93.04% and 87.38%, respectively.</p><p>same-paper 4 0.78145516 <a title="62-lda-4" href="./acl-2010-Combining_Orthogonal_Monolingual_and_Multilingual_Sources_of_Evidence_for_All_Words_WSD.html">62 acl-2010-Combining Orthogonal Monolingual and Multilingual Sources of Evidence for All Words WSD</a></p>
<p>Author: Weiwei Guo ; Mona Diab</p><p>Abstract: Word Sense Disambiguation remains one ofthe most complex problems facing computational linguists to date. In this paper we present a system that combines evidence from a monolingual WSD system together with that from a multilingual WSD system to yield state of the art performance on standard All-Words data sets. The monolingual system is based on a modification ofthe graph based state ofthe art algorithm In-Degree. The multilingual system is an improvement over an AllWords unsupervised approach, SALAAM. SALAAM exploits multilingual evidence as a means of disambiguation. In this paper, we present modifications to both of the original approaches and then their combination. We finally report the highest results obtained to date on the SENSEVAL 2 standard data set using an unsupervised method, we achieve an overall F measure of 64.58 using a voting scheme.</p><p>5 0.63822418 <a title="62-lda-5" href="./acl-2010-Reading_between_the_Lines%3A_Learning_to_Map_High-Level_Instructions_to_Commands.html">202 acl-2010-Reading between the Lines: Learning to Map High-Level Instructions to Commands</a></p>
<p>Author: S.R.K. Branavan ; Luke Zettlemoyer ; Regina Barzilay</p><p>Abstract: In this paper, we address the task of mapping high-level instructions to sequences of commands in an external environment. Processing these instructions is challenging—they posit goals to be achieved without specifying the steps required to complete them. We describe a method that fills in missing information using an automatically derived environment model that encodes states, transitions, and commands that cause these transitions to happen. We present an efficient approximate approach for learning this environment model as part of a policygradient reinforcement learning algorithm for text interpretation. This design enables learning for mapping high-level instructions, which previous statistical methods cannot handle.1</p><p>6 0.63710964 <a title="62-lda-6" href="./acl-2010-Sparsity_in_Dependency_Grammar_Induction.html">214 acl-2010-Sparsity in Dependency Grammar Induction</a></p>
<p>7 0.63441318 <a title="62-lda-7" href="./acl-2010-Dynamic_Programming_for_Linear-Time_Incremental_Parsing.html">93 acl-2010-Dynamic Programming for Linear-Time Incremental Parsing</a></p>
<p>8 0.61331111 <a title="62-lda-8" href="./acl-2010-Automated_Planning_for_Situated_Natural_Language_Generation.html">35 acl-2010-Automated Planning for Situated Natural Language Generation</a></p>
<p>9 0.58626181 <a title="62-lda-9" href="./acl-2010-Learning_Common_Grammar_from_Multilingual_Corpus.html">162 acl-2010-Learning Common Grammar from Multilingual Corpus</a></p>
<p>10 0.58470029 <a title="62-lda-10" href="./acl-2010-Simple%2C_Accurate_Parsing_with_an_All-Fragments_Grammar.html">211 acl-2010-Simple, Accurate Parsing with an All-Fragments Grammar</a></p>
<p>11 0.58391553 <a title="62-lda-11" href="./acl-2010-Bootstrapping_Semantic_Analyzers_from_Non-Contradictory_Texts.html">55 acl-2010-Bootstrapping Semantic Analyzers from Non-Contradictory Texts</a></p>
<p>12 0.58318985 <a title="62-lda-12" href="./acl-2010-Learning_to_Follow_Navigational_Directions.html">168 acl-2010-Learning to Follow Navigational Directions</a></p>
<p>13 0.58200616 <a title="62-lda-13" href="./acl-2010-Structural_Semantic_Relatedness%3A_A_Knowledge-Based_Method_to_Named_Entity_Disambiguation.html">218 acl-2010-Structural Semantic Relatedness: A Knowledge-Based Method to Named Entity Disambiguation</a></p>
<p>14 0.57977688 <a title="62-lda-14" href="./acl-2010-Convolution_Kernel_over_Packed_Parse_Forest.html">71 acl-2010-Convolution Kernel over Packed Parse Forest</a></p>
<p>15 0.5788421 <a title="62-lda-15" href="./acl-2010-Unsupervised_Event_Coreference_Resolution_with_Rich_Linguistic_Features.html">247 acl-2010-Unsupervised Event Coreference Resolution with Rich Linguistic Features</a></p>
<p>16 0.57521093 <a title="62-lda-16" href="./acl-2010-Efficient_Path_Counting_Transducers_for_Minimum_Bayes-Risk_Decoding_of_Statistical_Machine_Translation_Lattices.html">97 acl-2010-Efficient Path Counting Transducers for Minimum Bayes-Risk Decoding of Statistical Machine Translation Lattices</a></p>
<p>17 0.5690375 <a title="62-lda-17" href="./acl-2010-Complexity_Metrics_in_an_Incremental_Right-Corner_Parser.html">65 acl-2010-Complexity Metrics in an Incremental Right-Corner Parser</a></p>
<p>18 0.56865352 <a title="62-lda-18" href="./acl-2010-Importance-Driven_Turn-Bidding_for_Spoken_Dialogue_Systems.html">142 acl-2010-Importance-Driven Turn-Bidding for Spoken Dialogue Systems</a></p>
<p>19 0.56661582 <a title="62-lda-19" href="./acl-2010-Optimising_Information_Presentation_for_Spoken_Dialogue_Systems.html">187 acl-2010-Optimising Information Presentation for Spoken Dialogue Systems</a></p>
<p>20 0.56622207 <a title="62-lda-20" href="./acl-2010-Understanding_the_Semantic_Structure_of_Noun_Phrase_Queries.html">245 acl-2010-Understanding the Semantic Structure of Noun Phrase Queries</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
