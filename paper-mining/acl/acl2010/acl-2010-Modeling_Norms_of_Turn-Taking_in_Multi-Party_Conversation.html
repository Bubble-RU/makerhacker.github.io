<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>173 acl-2010-Modeling Norms of Turn-Taking in Multi-Party Conversation</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-173" href="#">acl2010-173</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>173 acl-2010-Modeling Norms of Turn-Taking in Multi-Party Conversation</h1>
<br/><p>Source: <a title="acl-2010-173-pdf" href="http://aclweb.org/anthology//P/P10/P10-1102.pdf">pdf</a></p><p>Author: Kornel Laskowski</p><p>Abstract: Substantial research effort has been invested in recent decades into the computational study and automatic processing of multi-party conversation. While most aspects of conversational speech have benefited from a wide availability of analytic, computationally tractable techniques, only qualitative assessments are available for characterizing multi-party turn-taking. The current paper attempts to address this deficiency by first proposing a framework for computing turn-taking model perplexity, and then by evaluating several multi-participant modeling approaches. Experiments show that direct multi-participant models do not generalize to held out data, and likely never will, for practical reasons. In contrast, the Extended-Degree-of-Overlap model represents a suitable candidate for future work in this area, and is shown to successfully predict the distribution of speech in time and across participants in previously unseen conversations.</p><p>Reference: <a title="acl-2010-173-reference" href="../acl2010_reference/acl-2010-Modeling_Norms_of_Turn-Taking_in_Multi-Party_Conversation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Modeling Norms of Turn-Taking in Multi-Party Conversation Kornel Laskowski Carnegie Mellon University Pittsburgh PA, USA kornel @ cs . [sent-1, score-0.08]
</p><p>2 edu  Abstract Substantial research effort has been invested in recent decades into the computational study and automatic processing of multi-party conversation. [sent-3, score-0.109]
</p><p>3 While most aspects of conversational speech have benefited from a wide availability of analytic, computationally tractable techniques, only qualitative assessments are available for characterizing multi-party turn-taking. [sent-4, score-0.162]
</p><p>4 The current paper attempts to address this deficiency by first proposing a framework for computing turn-taking model perplexity, and then by evaluating several multi-participant modeling approaches. [sent-5, score-0.101]
</p><p>5 Experiments show that direct multi-participant models do not generalize to held out data, and likely never will, for practical reasons. [sent-6, score-0.079]
</p><p>6 In contrast, the  Extended-Degree-of-Overlap model represents a suitable candidate for future work in this area, and is shown to successfully predict the distribution of speech in time and across participants in previously unseen conversations. [sent-7, score-0.377]
</p><p>7 1 Introduction Substantial research effort has been invested in recent decades into the computational study and automatic processing of multi-party conversation. [sent-8, score-0.109]
</p><p>8 Consequently, even in multi-party settings, automatic systems generally continue to treat participants independently, fusing information across participants relatively late in processing. [sent-10, score-0.56]
</p><p>9 This state of affairs has resulted in the near-  exclusion from computational consideration and from semantic analysis of a phenomenon which occurs at the lowest level of speech exchange, namely the relative timing of the deployment of speech in arbitrary multi-party groups. [sent-11, score-0.245]
</p><p>10 This phenomenon, the implicit taking of turns at talk (Sacks et al. [sent-12, score-0.054]
</p><p>11 , 1974), is important because unless participants adhere to its general rules, a conversation would simply not take place. [sent-13, score-0.65]
</p><p>12 It is therefore somewhat surprising that while most other aspects of speech enjoy a large base of computational methodologies for their study, there are few quantitative techniques for assessing the flow of turn-taking in general multi-party conversation. [sent-14, score-0.114]
</p><p>13 The current work attempts to address this problem by proposing a simple framework, which, at least conceptually, borrows quite heavily from the standard language modeling paradigm. [sent-15, score-0.136]
</p><p>14 First, it defines the perplexity ofa vector-valued Markov process whose multi-participant states are a concatenation of the binary states of individual speakers. [sent-16, score-0.317]
</p><p>15 Second, it presents some obvious evidence regarding the unsuitability of models defined directly  over this space, under various assumptions of independence, for the inference of conversationindependent norms of turn-taking. [sent-17, score-0.052]
</p><p>16 Finally, it demonstrates that the extended-degree-of-overlap model of (Laskowski and Schultz, 2007), which models participants in an alternate space, achieves by far the best likelihood estimates for previously unseen conversations. [sent-18, score-0.259]
</p><p>17 This appears to be because the model can learn across conversations, regardless of the number of their participants. [sent-19, score-0.042]
</p><p>18 The corpus consists of 75 meetings, held by various research groups at ICSI, which would have occurred even if they had not been recorded. [sent-26, score-0.035]
</p><p>19 Each meeting was attended by 3 to 9 participants, providing a wide variety of possible interaction types. [sent-28, score-0.112]
</p><p>20 1 Definitions Turn-taking is a generally observed phenomenon in conversation (Sacks et al. [sent-30, score-0.406]
</p><p>21 In spite of this, linguists tend to disagree about what precisely constitutes a turn (Sacks et al. [sent-33, score-0.05]
</p><p>22 ,  1974; Edelsky, 1981 ; Goodwin, 1981 ; Traum and Heeman, 1997), or even a turn boundary. [sent-34, score-0.05]
</p><p>23 To avoid being tied to any particular sociolinguistic theory, the current work equates “turn” with any contiguous interval of speech uttered by the same participant. [sent-36, score-0.139]
</p><p>24 Such intervals are commonly referred to as talk spurts (Norwine and Murphy, 1938). [sent-37, score-0.238]
</p><p>25 , 2001), in which spurts are “defined as speech regions uninterrupted by pauses longer than 500 ms” (italics in the original). [sent-39, score-0.156]
</p><p>26 Here, a threshold of 300 ms is used instead, as recently proposed in NIST’s Rich Transcription Meeting Recognition evaluations (NIST, 2002). [sent-40, score-0.061]
</p><p>27 The resulting definition of talk spurt, it is important to  note, is in quite common use but frequently under different names. [sent-41, score-0.054]
</p><p>28 An oft-cited example is the inter-pausal unit of (Koiso et al. [sent-42, score-0.051]
</p><p>29 A consequence of this choice is that any model of turn-taking behavior inferred will effectively be a model of the distribution of speech, in time and across participants. [sent-44, score-0.091]
</p><p>30 Finally, an important aspect of this work is that it analyzes turn-taking behavior as independent of the words spoken (and of the ways in which those words are spoken). [sent-46, score-0.049]
</p><p>31 As a result, strictly speaking, what is modeled is not the distribution of speech in time and across participants but of binary speech activity in time and across participants. [sent-47, score-0.533]
</p><p>32 Despite this seemingly dramatic simplification, it will be seen that important aspects ofturn-taking are sufficiently rare to be problematic for modeling. [sent-48, score-0.038]
</p><p>33 Modeling them jointly alongside lexical information, in multi-party scenarios, is likely to remain in-  ×  tractable for the foreseeable future. [sent-49, score-0.083]
</p><p>34 At any instant t, each of K participants to a conversation is in a state drawn from Ψ ≡ {S0, S1} ≡ {? [sent-52, score-0.797]
</p><p>35 ra iwndni cfraotems speech (or, more precisely, “intra-talk-spurt instants”) ahn (do S0 ≡ ? [sent-55, score-0.076]
</p><p>36 The joint state of all participants at time t is described using the K-length column vector ∈  ΨK  . [sent-57, score-0.302]
</p><p>37 view of this work, can be represented as the matrix Q ≡ [q1, q2, . [sent-67, score-0.037]
</p><p>38 Q is known as the (discrete) vocal interaction (Dabbs and Ruback, 1987) record. [sent-71, score-0.116]
</p><p>39 T is the total number of frames in the conversation, sampled at  Ts = 100 ms intervals. [sent-72, score-0.061]
</p><p>40 This is approximately the duration of the shortest lexical productions in the ICSI Meeting Corpus. [sent-73, score-0.125]
</p><p>41 1The inter-pausal unit differs from the pause unit of (Seligman et al. [sent-74, score-0.102]
</p><p>42 , 1997) in that the latter is an intra-turn unit, requiring prior turn segmentation 1000  3. [sent-75, score-0.05]
</p><p>43 ]∗, in which no participant is speaking (∗ indicates matrix transpose, to avoid confusion with conversation duration T) is first prepended to Q. [sent-84, score-0.556]
</p><p>44 P0 = P ( q0 ) therefore represents the unconditional probability of all participants being silent just prior to the start of any conversation2. [sent-85, score-0.259]
</p><p>45 YYT  P0  ·  YP (qt |  qt−1,  Θ) ,  (3)  tY= Y1  where in the second line the history is truncated to yield a standard first-order Markov form. [sent-87, score-0.036]
</p><p>46 Each of the T factors in Equation 3 is independent of the instant t, P ( qt | qt−1 , Θ ) = P ( qt = Sj | qt−1 = Si , Θ ) ≡ aij ,  (4) (5)  as per the notation in (Rabiner, 1989). [sent-88, score-1.045]
</p><p>47 In particular, each factor is a function only of the state Si in which the conversation was at time t − 1 and the wstahtiec Sj ien cwohnvicehr sthatei ocnon wvaesrs aattio timn ies ta t− −ti 1me a t, a thnde not of the instants t − 1 or t. [sent-89, score-0.558]
</p><p>48 It may be expressed as tth oef sthceala inrs aij wsh ti −ch 1 foo rrm t. [sent-90, score-0.133]
</p><p>49 s tth me aityh row apnreds jth column entry of the matrix {aij} ≡ Θ. [sent-91, score-0.074]
</p><p>50 4  Perplexity  In language modeling practice, one finds the likelihood P ( w | Θ ), of a word sequence w of length kwk udn Pde (rw a |mΘod)e,l o Θ, to o bred an qiuncenocnev ewnie onft le measure fuonrd comparison. [sent-93, score-0.047]
</p><p>51 Here, a similar metric is proposed, to be used for the same purposes, for the record Q. [sent-97, score-0.055]
</p><p>52 As can be seen in Equation 8, the negative log-likelihood is normalized by the number K of participants and the number T of frames in Q; the latter renders the measure useful for making duration-independent comparisons. [sent-99, score-0.259]
</p><p>53 The normalization by K does not per se suggest that turntaking in conversations with different K is necessarily similar; it merely provides similar bounds on the magnitudes of these metrics. [sent-100, score-0.1]
</p><p>54 4  Direct Estimation of Θ  Direct application of bigram modeling techniques, defined over the states {S}, is treated as a baseline. [sent-101, score-0.109]
</p><p>55 1 The Case of K = 2 Participants In contrast to multi-party conversation, dialogue has been extensively modeled in the ways described in this paper. [sent-103, score-0.059]
</p><p>56 Beginning with (Brady, 1969), Markov modeling techniques over the joint speech activity of two interlocutors have been  explored by both the sociolinguist and the psycholinguist community (Jaffe and Feldstein, 1970; Dabbs and Ruback, 1987). [sent-104, score-0.231]
</p><p>57 The same models have also appeared in dialogue systems (Raux, 2008). [sent-105, score-0.059]
</p><p>58 Most recently, they have been augmented with duration models in a study of the Switchboard corpus (Grothendieck et al. [sent-106, score-0.125]
</p><p>59 This is partly due to the exponential growth in the number of states as K increases, and partly due to difficulties in interpretation. [sent-110, score-0.134]
</p><p>60 the number of participants) without losing track of speakers when two or more participants speak simultaneously (known as overlap). [sent-112, score-0.259]
</p><p>61 1  Conditionally Dependent Participants  In a particular conversation with K participants, the state space of an ergodic process contains 2K states, and the number of free parameters in a model Θ which treats participant behavior as conditionally d? [sent-115, score-0.626]
</p><p>62 e 2K states are likely to not occur within a convers? [sent-122, score-0.062]
</p><p>63 ation of duration T, leading to misestimation of the desired probabilities. [sent-123, score-0.205]
</p><p>64 To demonstrate this, three perplexity trajectories for a snippet of meeting Bmr0 2 4 are shown in Figure 1, in the interval beginning 5 minutes into the meeting and ending 20 minutes later. [sent-124, score-0.669]
</p><p>65 (The meeting is actually just over 50 minutes long but only a snippet is shown to better appreciate small time-scale variation. [sent-125, score-0.241]
</p><p>66 ) The depicted perplexities are not unweighted averages over the whole meeting of duration T as in Equation 8, but over a 60second Hamming window centered on each t. [sent-126, score-0.224]
</p><p>67 The first trajectory, the dashed black line, is obtained when the entire meeting is used to estimate ΘCD, and is then scored by that same model (an “oracle” condition). [sent-127, score-0.098]
</p><p>68 Significant perplexity varia-  tion is observed throughout the depicted snippet. [sent-128, score-0.232]
</p><p>69 The second trajectory, the continuous black line, is that obtained when the meeting is split into two equal-duration halves, one consisting of all instants prior to the midpoint and the other of all instants following it. [sent-129, score-0.489]
</p><p>70 These halves are hereafter referred to as A and B, respectively (the interval in Figure 1 falls entirely within the A half). [sent-130, score-0.247]
</p><p>71 Finally, the third trajectory, the continuous gray line, is obtained when the two halves A and B of the meeting are scored using the mismatched models ΘCBD and ΘCAD, respectively (this condition is henceforth referred to as the B+A condition). [sent-133, score-0.439]
</p><p>72 It can be seen that even when probabilities  are estimated from the same participants, in exactly the same conversation, a direct conditionally dependent model exposed to over 25 minutes of a conversation cannot predict the turn-taking patterns observed later. [sent-134, score-0.632]
</p><p>73 2 Conditionally Independent Participants A potential reason for the gross misestimation of ΘCD under mismatched conditions is the size of the state space {S}. [sent-137, score-0.203]
</p><p>74 ed Tuhcee dnu by assuming mtheatte participants behave independently at instant t, but are conditioned on their joint behavior at t 1. [sent-139, score-0.447]
</p><p>75 The lciokneldiihtiooonde dof o Q huenidre jro tinhet resulting conditionally independent model ΘCI has the form −  P(Q )  =. [sent-140, score-0.14]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('qt', 0.405), ('conversation', 0.356), ('participants', 0.259), ('perplexity', 0.193), ('instants', 0.159), ('conditionally', 0.14), ('instant', 0.139), ('halves', 0.128), ('duration', 0.125), ('dabbs', 0.119), ('kci', 0.119), ('laskowski', 0.119), ('nll', 0.119), ('ruback', 0.119), ('aij', 0.096), ('ppl', 0.096), ('icsi', 0.096), ('sacks', 0.096), ('minutes', 0.092), ('trajectory', 0.09), ('cad', 0.08), ('cbd', 0.08), ('feldstein', 0.08), ('jaffe', 0.08), ('kornel', 0.08), ('misestimation', 0.08), ('mismatched', 0.08), ('norwine', 0.08), ('spurts', 0.08), ('cd', 0.078), ('speech', 0.076), ('goodwin', 0.07), ('interlocutors', 0.07), ('yt', 0.066), ('vocal', 0.064), ('invested', 0.064), ('schultz', 0.064), ('interval', 0.063), ('states', 0.062), ('ms', 0.061), ('shriberg', 0.06), ('meeting', 0.06), ('dialogue', 0.059), ('merely', 0.056), ('referred', 0.056), ('beginning', 0.055), ('record', 0.055), ('oracle', 0.055), ('talk', 0.054), ('proposing', 0.054), ('snippet', 0.054), ('interaction', 0.052), ('yk', 0.052), ('norms', 0.052), ('murphy', 0.052), ('rabiner', 0.052), ('unit', 0.051), ('turn', 0.05), ('markov', 0.05), ('phenomenon', 0.05), ('behavior', 0.049), ('tractable', 0.048), ('ty', 0.048), ('intervals', 0.048), ('modeling', 0.047), ('decades', 0.045), ('yp', 0.045), ('conversations', 0.044), ('sj', 0.044), ('direct', 0.044), ('state', 0.043), ('across', 0.042), ('si', 0.042), ('condition', 0.039), ('depicted', 0.039), ('aspects', 0.038), ('black', 0.038), ('activity', 0.038), ('henceforth', 0.038), ('seconds', 0.038), ('continuous', 0.038), ('participant', 0.038), ('matrix', 0.037), ('tth', 0.037), ('partly', 0.036), ('line', 0.036), ('held', 0.035), ('borrows', 0.035), ('akc', 0.035), ('pde', 0.035), ('operationalize', 0.035), ('midpoint', 0.035), ('yeah', 0.035), ('multiparty', 0.035), ('appreciate', 0.035), ('alongside', 0.035), ('floor', 0.035), ('raux', 0.035), ('adhere', 0.035), ('brady', 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="173-tfidf-1" href="./acl-2010-Modeling_Norms_of_Turn-Taking_in_Multi-Party_Conversation.html">173 acl-2010-Modeling Norms of Turn-Taking in Multi-Party Conversation</a></p>
<p>Author: Kornel Laskowski</p><p>Abstract: Substantial research effort has been invested in recent decades into the computational study and automatic processing of multi-party conversation. While most aspects of conversational speech have benefited from a wide availability of analytic, computationally tractable techniques, only qualitative assessments are available for characterizing multi-party turn-taking. The current paper attempts to address this deficiency by first proposing a framework for computing turn-taking model perplexity, and then by evaluating several multi-participant modeling approaches. Experiments show that direct multi-participant models do not generalize to held out data, and likely never will, for practical reasons. In contrast, the Extended-Degree-of-Overlap model represents a suitable candidate for future work in this area, and is shown to successfully predict the distribution of speech in time and across participants in previously unseen conversations.</p><p>2 0.13669191 <a title="173-tfidf-2" href="./acl-2010-Intelligent_Selection_of_Language_Model_Training_Data.html">151 acl-2010-Intelligent Selection of Language Model Training Data</a></p>
<p>Author: Robert C. Moore ; William Lewis</p><p>Abstract: We address the problem of selecting nondomain-specific language model training data to build auxiliary language models for use in tasks such as machine translation. Our approach is based on comparing the cross-entropy, according to domainspecific and non-domain-specifc language models, for each sentence of the text source used to produce the latter language model. We show that this produces better language models, trained on less data, than both random data selection and two other previously proposed methods.</p><p>3 0.12812804 <a title="173-tfidf-3" href="./acl-2010-Non-Cooperation_in_Dialogue.html">178 acl-2010-Non-Cooperation in Dialogue</a></p>
<p>Author: Brian Pluss</p><p>Abstract: This paper presents ongoing research on computational models for non-cooperative dialogue. We start by analysing different levels of cooperation in conversation. Then, inspired by findings from an empirical study, we propose a technique for measuring non-cooperation in political interviews. Finally, we describe a research programme towards obtaining a suitable model and discuss previous accounts for conflictive dialogue, identifying the differences with our work.</p><p>4 0.10535154 <a title="173-tfidf-4" href="./acl-2010-Complexity_Metrics_in_an_Incremental_Right-Corner_Parser.html">65 acl-2010-Complexity Metrics in an Incremental Right-Corner Parser</a></p>
<p>Author: Stephen Wu ; Asaf Bachrach ; Carlos Cardenas ; William Schuler</p><p>Abstract: Hierarchical HMM (HHMM) parsers make promising cognitive models: while they use a bounded model of working memory and pursue incremental hypotheses in parallel, they still achieve parsing accuracies competitive with chart-based techniques. This paper aims to validate that a right-corner HHMM parser is also able to produce complexity metrics, which quantify a reader’s incremental difficulty in understanding a sentence. Besides defining standard metrics in the HHMM framework, a new metric, embedding difference, is also proposed, which tests the hypothesis that HHMM store elements represents syntactic working memory. Results show that HHMM surprisal outperforms all other evaluated metrics in predicting reading times, and that embedding difference makes a significant, independent contribution.</p><p>5 0.090285845 <a title="173-tfidf-5" href="./acl-2010-A_Cognitive_Cost_Model_of_Annotations_Based_on_Eye-Tracking_Data.html">4 acl-2010-A Cognitive Cost Model of Annotations Based on Eye-Tracking Data</a></p>
<p>Author: Katrin Tomanek ; Udo Hahn ; Steffen Lohmann ; Jurgen Ziegler</p><p>Abstract: We report on an experiment to track complex decision points in linguistic metadata annotation where the decision behavior of annotators is observed with an eyetracking device. As experimental conditions we investigate different forms of textual context and linguistic complexity classes relative to syntax and semantics. Our data renders evidence that annotation performance depends on the semantic and syntactic complexity of the decision points and, more interestingly, indicates that fullscale context is mostly negligible with – the exception of semantic high-complexity cases. We then induce from this observational data a cognitively grounded cost model of linguistic meta-data annotations and compare it with existing non-cognitive models. Our data reveals that the cognitively founded model explains annotation costs (expressed in annotation time) more adequately than non-cognitive ones.</p><p>6 0.077606566 <a title="173-tfidf-6" href="./acl-2010-Extracting_Social_Networks_from_Literary_Fiction.html">112 acl-2010-Extracting Social Networks from Literary Fiction</a></p>
<p>7 0.077071801 <a title="173-tfidf-7" href="./acl-2010-Demonstration_of_a_Prototype_for_a_Conversational_Companion_for_Reminiscing_about_Images.html">82 acl-2010-Demonstration of a Prototype for a Conversational Companion for Reminiscing about Images</a></p>
<p>8 0.067831673 <a title="173-tfidf-8" href="./acl-2010-Domain_Adaptation_of_Maximum_Entropy_Language_Models.html">91 acl-2010-Domain Adaptation of Maximum Entropy Language Models</a></p>
<p>9 0.063704796 <a title="173-tfidf-9" href="./acl-2010-Towards_Relational_POMDPs_for_Adaptive_Dialogue_Management.html">239 acl-2010-Towards Relational POMDPs for Adaptive Dialogue Management</a></p>
<p>10 0.062363084 <a title="173-tfidf-10" href="./acl-2010-Talking_NPCs_in_a_Virtual_Game_World.html">224 acl-2010-Talking NPCs in a Virtual Game World</a></p>
<p>11 0.060529873 <a title="173-tfidf-11" href="./acl-2010-Syntactic_and_Semantic_Factors_in_Processing_Difficulty%3A_An_Integrated_Measure.html">220 acl-2010-Syntactic and Semantic Factors in Processing Difficulty: An Integrated Measure</a></p>
<p>12 0.058187194 <a title="173-tfidf-12" href="./acl-2010-Correcting_Errors_in_Speech_Recognition_with_Articulatory_Dynamics.html">74 acl-2010-Correcting Errors in Speech Recognition with Articulatory Dynamics</a></p>
<p>13 0.056354295 <a title="173-tfidf-13" href="./acl-2010-Importance-Driven_Turn-Bidding_for_Spoken_Dialogue_Systems.html">142 acl-2010-Importance-Driven Turn-Bidding for Spoken Dialogue Systems</a></p>
<p>14 0.053330898 <a title="173-tfidf-14" href="./acl-2010-Learning_to_Adapt_to_Unknown_Users%3A_Referring_Expression_Generation_in_Spoken_Dialogue_Systems.html">167 acl-2010-Learning to Adapt to Unknown Users: Referring Expression Generation in Spoken Dialogue Systems</a></p>
<p>15 0.052745614 <a title="173-tfidf-15" href="./acl-2010-Bootstrapping_Semantic_Analyzers_from_Non-Contradictory_Texts.html">55 acl-2010-Bootstrapping Semantic Analyzers from Non-Contradictory Texts</a></p>
<p>16 0.04982806 <a title="173-tfidf-16" href="./acl-2010-A_Risk_Minimization_Framework_for_Extractive_Speech_Summarization.html">14 acl-2010-A Risk Minimization Framework for Extractive Speech Summarization</a></p>
<p>17 0.049096134 <a title="173-tfidf-17" href="./acl-2010-Preferences_versus_Adaptation_during_Referring_Expression_Generation.html">199 acl-2010-Preferences versus Adaptation during Referring Expression Generation</a></p>
<p>18 0.047726519 <a title="173-tfidf-18" href="./acl-2010-Sparsity_in_Dependency_Grammar_Induction.html">214 acl-2010-Sparsity in Dependency Grammar Induction</a></p>
<p>19 0.046427093 <a title="173-tfidf-19" href="./acl-2010-Towards_Open-Domain_Semantic_Role_Labeling.html">238 acl-2010-Towards Open-Domain Semantic Role Labeling</a></p>
<p>20 0.044677213 <a title="173-tfidf-20" href="./acl-2010-Incorporating_Extra-Linguistic_Information_into_Reference_Resolution_in_Collaborative_Task_Dialogue.html">149 acl-2010-Incorporating Extra-Linguistic Information into Reference Resolution in Collaborative Task Dialogue</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.127), (1, 0.041), (2, -0.029), (3, -0.095), (4, -0.01), (5, -0.096), (6, -0.066), (7, -0.007), (8, 0.039), (9, -0.001), (10, -0.044), (11, 0.017), (12, 0.085), (13, 0.01), (14, -0.06), (15, -0.027), (16, 0.024), (17, 0.081), (18, -0.019), (19, 0.059), (20, -0.013), (21, -0.017), (22, 0.023), (23, -0.037), (24, -0.025), (25, 0.075), (26, 0.074), (27, -0.105), (28, 0.108), (29, -0.086), (30, -0.059), (31, 0.187), (32, 0.093), (33, 0.089), (34, -0.065), (35, 0.025), (36, -0.026), (37, -0.012), (38, -0.1), (39, 0.023), (40, -0.04), (41, -0.076), (42, -0.026), (43, 0.067), (44, -0.018), (45, 0.085), (46, -0.122), (47, 0.008), (48, 0.053), (49, 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94606984 <a title="173-lsi-1" href="./acl-2010-Modeling_Norms_of_Turn-Taking_in_Multi-Party_Conversation.html">173 acl-2010-Modeling Norms of Turn-Taking in Multi-Party Conversation</a></p>
<p>Author: Kornel Laskowski</p><p>Abstract: Substantial research effort has been invested in recent decades into the computational study and automatic processing of multi-party conversation. While most aspects of conversational speech have benefited from a wide availability of analytic, computationally tractable techniques, only qualitative assessments are available for characterizing multi-party turn-taking. The current paper attempts to address this deficiency by first proposing a framework for computing turn-taking model perplexity, and then by evaluating several multi-participant modeling approaches. Experiments show that direct multi-participant models do not generalize to held out data, and likely never will, for practical reasons. In contrast, the Extended-Degree-of-Overlap model represents a suitable candidate for future work in this area, and is shown to successfully predict the distribution of speech in time and across participants in previously unseen conversations.</p><p>2 0.71846402 <a title="173-lsi-2" href="./acl-2010-Correcting_Errors_in_Speech_Recognition_with_Articulatory_Dynamics.html">74 acl-2010-Correcting Errors in Speech Recognition with Articulatory Dynamics</a></p>
<p>Author: Frank Rudzicz</p><p>Abstract: We introduce a novel mechanism for incorporating articulatory dynamics into speech recognition with the theory of task dynamics. This system reranks sentencelevel hypotheses by the likelihoods of their hypothetical articulatory realizations which are derived from relationships learned with aligned acoustic/articulatory data. Experiments compare this with two baseline systems, namely an acoustic hidden Markov model and a dynamic Bayes network augmented with discretized representations of the vocal tract. Our system based on task dynamics reduces worderror rates significantly by 10.2% relative to the best baseline models.</p><p>3 0.6747911 <a title="173-lsi-3" href="./acl-2010-Non-Cooperation_in_Dialogue.html">178 acl-2010-Non-Cooperation in Dialogue</a></p>
<p>Author: Brian Pluss</p><p>Abstract: This paper presents ongoing research on computational models for non-cooperative dialogue. We start by analysing different levels of cooperation in conversation. Then, inspired by findings from an empirical study, we propose a technique for measuring non-cooperation in political interviews. Finally, we describe a research programme towards obtaining a suitable model and discuss previous accounts for conflictive dialogue, identifying the differences with our work.</p><p>4 0.65293825 <a title="173-lsi-4" href="./acl-2010-Extracting_Social_Networks_from_Literary_Fiction.html">112 acl-2010-Extracting Social Networks from Literary Fiction</a></p>
<p>Author: David Elson ; Nicholas Dames ; Kathleen McKeown</p><p>Abstract: We present a method for extracting social networks from literature, namely, nineteenth-century British novels and serials. We derive the networks from dialogue interactions, and thus our method depends on the ability to determine when two characters are in conversation. Our approach involves character name chunking, quoted speech attribution and conversation detection given the set of quotes. We extract features from the social networks and examine their correlation with one another, as well as with metadata such as the novel’s setting. Our results provide evidence that the majority of novels in this time period do not fit two characterizations provided by literacy scholars. Instead, our results suggest an alternative explanation for differences in social networks.</p><p>5 0.5647487 <a title="173-lsi-5" href="./acl-2010-How_Spoken_Language_Corpora_Can_Refine_Current_Speech_Motor_Training_Methodologies.html">137 acl-2010-How Spoken Language Corpora Can Refine Current Speech Motor Training Methodologies</a></p>
<p>Author: Daniil Umanski ; Federico Sangati</p><p>Abstract: The growing availability of spoken language corpora presents new opportunities for enriching the methodologies of speech and language therapy. In this paper, we present a novel approach for constructing speech motor exercises, based on linguistic knowledge extracted from spoken language corpora. In our study with the Dutch Spoken Corpus, syllabic inventories were obtained by means of automatic syllabification of the spoken language data. Our experimental syllabification method exhibited a reliable performance, and allowed for the acquisition of syllabic tokens from the corpus. Consequently, the syl- labic tokens were integrated in a tool for clinicians, a result which holds the potential of contributing to the current state of speech motor training methodologies.</p><p>6 0.55050856 <a title="173-lsi-6" href="./acl-2010-Combining_Data_and_Mathematical_Models_of_Language_Change.html">61 acl-2010-Combining Data and Mathematical Models of Language Change</a></p>
<p>7 0.5358516 <a title="173-lsi-7" href="./acl-2010-Decision_Detection_Using_Hierarchical_Graphical_Models.html">81 acl-2010-Decision Detection Using Hierarchical Graphical Models</a></p>
<p>8 0.52391529 <a title="173-lsi-8" href="./acl-2010-Domain_Adaptation_of_Maximum_Entropy_Language_Models.html">91 acl-2010-Domain Adaptation of Maximum Entropy Language Models</a></p>
<p>9 0.50655055 <a title="173-lsi-9" href="./acl-2010-Towards_Relational_POMDPs_for_Adaptive_Dialogue_Management.html">239 acl-2010-Towards Relational POMDPs for Adaptive Dialogue Management</a></p>
<p>10 0.50259036 <a title="173-lsi-10" href="./acl-2010-Classification_of_Feedback_Expressions_in_Multimodal_Data.html">58 acl-2010-Classification of Feedback Expressions in Multimodal Data</a></p>
<p>11 0.49700245 <a title="173-lsi-11" href="./acl-2010-Intelligent_Selection_of_Language_Model_Training_Data.html">151 acl-2010-Intelligent Selection of Language Model Training Data</a></p>
<p>12 0.44195929 <a title="173-lsi-12" href="./acl-2010-Phrase-Based_Statistical_Language_Generation_Using_Graphical_Models_and_Active_Learning.html">194 acl-2010-Phrase-Based Statistical Language Generation Using Graphical Models and Active Learning</a></p>
<p>13 0.40201968 <a title="173-lsi-13" href="./acl-2010-A_Rational_Model_of_Eye_Movement_Control_in_Reading.html">13 acl-2010-A Rational Model of Eye Movement Control in Reading</a></p>
<p>14 0.40067178 <a title="173-lsi-14" href="./acl-2010-Talking_NPCs_in_a_Virtual_Game_World.html">224 acl-2010-Talking NPCs in a Virtual Game World</a></p>
<p>15 0.39663047 <a title="173-lsi-15" href="./acl-2010-A_Generalized-Zero-Preserving_Method_for_Compact_Encoding_of_Concept_Lattices.html">7 acl-2010-A Generalized-Zero-Preserving Method for Compact Encoding of Concept Lattices</a></p>
<p>16 0.39282197 <a title="173-lsi-16" href="./acl-2010-Demonstration_of_a_Prototype_for_a_Conversational_Companion_for_Reminiscing_about_Images.html">82 acl-2010-Demonstration of a Prototype for a Conversational Companion for Reminiscing about Images</a></p>
<p>17 0.38777259 <a title="173-lsi-17" href="./acl-2010-Personalising_Speech-To-Speech_Translation_in_the_EMIME_Project.html">193 acl-2010-Personalising Speech-To-Speech Translation in the EMIME Project</a></p>
<p>18 0.37964633 <a title="173-lsi-18" href="./acl-2010-Complexity_Metrics_in_an_Incremental_Right-Corner_Parser.html">65 acl-2010-Complexity Metrics in an Incremental Right-Corner Parser</a></p>
<p>19 0.37334874 <a title="173-lsi-19" href="./acl-2010-Hierarchical_Joint_Learning%3A_Improving_Joint_Parsing_and_Named_Entity_Recognition_with_Non-Jointly_Labeled_Data.html">132 acl-2010-Hierarchical Joint Learning: Improving Joint Parsing and Named Entity Recognition with Non-Jointly Labeled Data</a></p>
<p>20 0.3698858 <a title="173-lsi-20" href="./acl-2010-Importance-Driven_Turn-Bidding_for_Spoken_Dialogue_Systems.html">142 acl-2010-Importance-Driven Turn-Bidding for Spoken Dialogue Systems</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.037), (25, 0.045), (42, 0.035), (44, 0.011), (45, 0.345), (59, 0.076), (72, 0.013), (73, 0.037), (76, 0.011), (78, 0.024), (80, 0.021), (83, 0.114), (84, 0.046), (98, 0.099)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.8246997 <a title="173-lda-1" href="./acl-2010-Hunting_for_the_Black_Swan%3A_Risk_Mining_from_Text.html">138 acl-2010-Hunting for the Black Swan: Risk Mining from Text</a></p>
<p>Author: Jochen Leidner ; Frank Schilder</p><p>Abstract: In the business world, analyzing and dealing with risk permeates all decisions and actions. However, to date, risk identification, the first step in the risk management cycle, has always been a manual activity with little to no intelligent software tool support. In addition, although companies are required to list risks to their business in their annual SEC filings in the USA, these descriptions are often very highlevel and vague. In this paper, we introduce Risk Mining, which is the task of identifying a set of risks pertaining to a business area or entity. We argue that by combining Web mining and Information Extraction (IE) techniques, risks can be detected automatically before they materialize, thus providing valuable business intelligence. We describe a system that induces a risk taxonomy with concrete risks (e.g., interest rate changes) at its leaves and more abstract risks (e.g., financial risks) closer to its root node. The taxonomy is induced via a bootstrapping algorithms starting with a few seeds. The risk taxonomy is used by the system as input to a risk monitor that matches risk mentions in financial documents to the abstract risk types, thus bridging a lexical gap. Our system is able to automatically generate company specific “risk maps”, which we demonstrate for a corpus of earnings report conference calls.</p><p>same-paper 2 0.77465445 <a title="173-lda-2" href="./acl-2010-Modeling_Norms_of_Turn-Taking_in_Multi-Party_Conversation.html">173 acl-2010-Modeling Norms of Turn-Taking in Multi-Party Conversation</a></p>
<p>Author: Kornel Laskowski</p><p>Abstract: Substantial research effort has been invested in recent decades into the computational study and automatic processing of multi-party conversation. While most aspects of conversational speech have benefited from a wide availability of analytic, computationally tractable techniques, only qualitative assessments are available for characterizing multi-party turn-taking. The current paper attempts to address this deficiency by first proposing a framework for computing turn-taking model perplexity, and then by evaluating several multi-participant modeling approaches. Experiments show that direct multi-participant models do not generalize to held out data, and likely never will, for practical reasons. In contrast, the Extended-Degree-of-Overlap model represents a suitable candidate for future work in this area, and is shown to successfully predict the distribution of speech in time and across participants in previously unseen conversations.</p><p>3 0.66292012 <a title="173-lda-3" href="./acl-2010-Enhanced_Word_Decomposition_by_Calibrating_the_Decision_Threshold_of_Probabilistic_Models_and_Using_a_Model_Ensemble.html">100 acl-2010-Enhanced Word Decomposition by Calibrating the Decision Threshold of Probabilistic Models and Using a Model Ensemble</a></p>
<p>Author: Sebastian Spiegler ; Peter A. Flach</p><p>Abstract: This paper demonstrates that the use of ensemble methods and carefully calibrating the decision threshold can significantly improve the performance of machine learning methods for morphological word decomposition. We employ two algorithms which come from a family of generative probabilistic models. The models consider segment boundaries as hidden variables and include probabilities for letter transitions within segments. The advantage of this model family is that it can learn from small datasets and easily gen- eralises to larger datasets. The first algorithm PROMODES, which participated in the Morpho Challenge 2009 (an international competition for unsupervised morphological analysis) employs a lower order model whereas the second algorithm PROMODES-H is a novel development of the first using a higher order model. We present the mathematical description for both algorithms, conduct experiments on the morphologically rich language Zulu and compare characteristics of both algorithms based on the experimental results.</p><p>4 0.46641776 <a title="173-lda-4" href="./acl-2010-%22Ask_Not_What_Textual_Entailment_Can_Do_for_You...%22.html">1 acl-2010-"Ask Not What Textual Entailment Can Do for You..."</a></p>
<p>Author: Mark Sammons ; V.G.Vinod Vydiswaran ; Dan Roth</p><p>Abstract: We challenge the NLP community to participate in a large-scale, distributed effort to design and build resources for developing and evaluating solutions to new and existing NLP tasks in the context of Recognizing Textual Entailment. We argue that the single global label with which RTE examples are annotated is insufficient to effectively evaluate RTE system performance; to promote research on smaller, related NLP tasks, we believe more detailed annotation and evaluation are needed, and that this effort will benefit not just RTE researchers, but the NLP community as a whole. We use insights from successful RTE systems to propose a model for identifying and annotating textual infer- ence phenomena in textual entailment examples, and we present the results of a pilot annotation study that show this model is feasible and the results immediately useful.</p><p>5 0.46607554 <a title="173-lda-5" href="./acl-2010-The_S-Space_Package%3A_An_Open_Source_Package_for_Word_Space_Models.html">232 acl-2010-The S-Space Package: An Open Source Package for Word Space Models</a></p>
<p>Author: David Jurgens ; Keith Stevens</p><p>Abstract: We present the S-Space Package, an open source framework for developing and evaluating word space algorithms. The package implements well-known word space algorithms, such as LSA, and provides a comprehensive set of matrix utilities and data structures for extending new or existing models. The package also includes word space benchmarks for evaluation. Both algorithms and libraries are designed for high concurrency and scalability. We demonstrate the efficiency of the reference implementations and also provide their results on six benchmarks.</p><p>6 0.46424258 <a title="173-lda-6" href="./acl-2010-Entity-Based_Local_Coherence_Modelling_Using_Topological_Fields.html">101 acl-2010-Entity-Based Local Coherence Modelling Using Topological Fields</a></p>
<p>7 0.46336323 <a title="173-lda-7" href="./acl-2010-Phylogenetic_Grammar_Induction.html">195 acl-2010-Phylogenetic Grammar Induction</a></p>
<p>8 0.46320316 <a title="173-lda-8" href="./acl-2010-A_Study_of_Information_Retrieval_Weighting_Schemes_for_Sentiment_Analysis.html">18 acl-2010-A Study of Information Retrieval Weighting Schemes for Sentiment Analysis</a></p>
<p>9 0.46176243 <a title="173-lda-9" href="./acl-2010-Using_Anaphora_Resolution_to_Improve_Opinion_Target_Identification_in_Movie_Reviews.html">251 acl-2010-Using Anaphora Resolution to Improve Opinion Target Identification in Movie Reviews</a></p>
<p>10 0.46152633 <a title="173-lda-10" href="./acl-2010-Joint_Syntactic_and_Semantic_Parsing_of_Chinese.html">153 acl-2010-Joint Syntactic and Semantic Parsing of Chinese</a></p>
<p>11 0.46052536 <a title="173-lda-11" href="./acl-2010-Supervised_Noun_Phrase_Coreference_Research%3A_The_First_Fifteen_Years.html">219 acl-2010-Supervised Noun Phrase Coreference Research: The First Fifteen Years</a></p>
<p>12 0.46006823 <a title="173-lda-12" href="./acl-2010-A_Rational_Model_of_Eye_Movement_Control_in_Reading.html">13 acl-2010-A Rational Model of Eye Movement Control in Reading</a></p>
<p>13 0.459979 <a title="173-lda-13" href="./acl-2010-Complexity_Metrics_in_an_Incremental_Right-Corner_Parser.html">65 acl-2010-Complexity Metrics in an Incremental Right-Corner Parser</a></p>
<p>14 0.45968223 <a title="173-lda-14" href="./acl-2010-Open-Domain_Semantic_Role_Labeling_by_Modeling_Word_Spans.html">184 acl-2010-Open-Domain Semantic Role Labeling by Modeling Word Spans</a></p>
<p>15 0.45921147 <a title="173-lda-15" href="./acl-2010-Extracting_Social_Networks_from_Literary_Fiction.html">112 acl-2010-Extracting Social Networks from Literary Fiction</a></p>
<p>16 0.45898071 <a title="173-lda-16" href="./acl-2010-Sentence_and_Expression_Level_Annotation_of_Opinions_in_User-Generated_Discourse.html">208 acl-2010-Sentence and Expression Level Annotation of Opinions in User-Generated Discourse</a></p>
<p>17 0.45853674 <a title="173-lda-17" href="./acl-2010-Bootstrapping_Semantic_Analyzers_from_Non-Contradictory_Texts.html">55 acl-2010-Bootstrapping Semantic Analyzers from Non-Contradictory Texts</a></p>
<p>18 0.45843232 <a title="173-lda-18" href="./acl-2010-Unsupervised_Event_Coreference_Resolution_with_Rich_Linguistic_Features.html">247 acl-2010-Unsupervised Event Coreference Resolution with Rich Linguistic Features</a></p>
<p>19 0.45720968 <a title="173-lda-19" href="./acl-2010-Coreference_Resolution_with_Reconcile.html">73 acl-2010-Coreference Resolution with Reconcile</a></p>
<p>20 0.45714486 <a title="173-lda-20" href="./acl-2010-Sparsity_in_Dependency_Grammar_Induction.html">214 acl-2010-Sparsity in Dependency Grammar Induction</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
