<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>137 acl-2010-How Spoken Language Corpora Can Refine Current Speech Motor Training Methodologies</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-137" href="#">acl2010-137</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>137 acl-2010-How Spoken Language Corpora Can Refine Current Speech Motor Training Methodologies</h1>
<br/><p>Source: <a title="acl-2010-137-pdf" href="http://aclweb.org/anthology//P/P10/P10-3007.pdf">pdf</a></p><p>Author: Daniil Umanski ; Federico Sangati</p><p>Abstract: The growing availability of spoken language corpora presents new opportunities for enriching the methodologies of speech and language therapy. In this paper, we present a novel approach for constructing speech motor exercises, based on linguistic knowledge extracted from spoken language corpora. In our study with the Dutch Spoken Corpus, syllabic inventories were obtained by means of automatic syllabification of the spoken language data. Our experimental syllabification method exhibited a reliable performance, and allowed for the acquisition of syllabic tokens from the corpus. Consequently, the syl- labic tokens were integrated in a tool for clinicians, a result which holds the potential of contributing to the current state of speech motor training methodologies.</p><p>Reference: <a title="acl-2010-137-reference" href="../acl2010_reference/acl-2010-How_Spoken_Language_Corpora_Can_Refine_Current_Speech_Motor_Training_Methodologies_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 How spoken language corpora can refine current speech motor training methodologies Daniil Umanski, Niels O. [sent-1, score-1.045]
</p><p>2 Abstract The growing availability of spoken language corpora presents new opportunities for enriching the methodologies of speech and language therapy. [sent-8, score-0.424]
</p><p>3 In this paper, we present a novel approach for constructing speech motor exercises, based on linguistic knowledge extracted from spoken language corpora. [sent-9, score-0.981]
</p><p>4 In our study with the Dutch Spoken Corpus, syllabic inventories were obtained by means of automatic syllabification of the spoken language data. [sent-10, score-0.553]
</p><p>5 Our experimental syllabification method exhibited a reliable performance, and allowed for the acquisition of syllabic tokens from the corpus. [sent-11, score-0.391]
</p><p>6 Consequently, the syl-  labic tokens were integrated in a tool for clinicians, a result which holds the potential of contributing to the current state of speech motor training methodologies. [sent-12, score-0.858]
</p><p>7 1 Introduction Spoken language corpora are often accessed by linguists, who need to manipulate specifically defined speech stimuli in their experiments. [sent-13, score-0.287]
</p><p>8 However, this valuable resource of linguistic information has not yet been systematically applied for the benefit of speech therapy methodologies. [sent-14, score-0.239]
</p><p>9 This is not surprising, considering the fact that spoken language corpora have only appeared relatively recently, and are still not easily accessible outside the NLP community. [sent-15, score-0.178]
</p><p>10 Existing applications for selecting linguistic stimuli, although undoubtedly useful, are not based on spoken language data, and are generally not designed for utilization by speech therapists per se (Aichert et al. [sent-16, score-0.418]
</p><p>11 In coor-  dination with speech pathologists, the domain of Language and Computation University of Amsterdam, the Netherlands . [sent-19, score-0.205]
</p><p>12 nl speech motor training was identified as an appropriate area of application. [sent-22, score-0.826]
</p><p>13 The traditional speech motor programs are based on a rather static inventory of speech items, and clinicians do not have access to a modular way of selecting speech targets for training. [sent-23, score-1.416]
</p><p>14 Therefore, in this project, we deal with developing an interactive interface to assist speech therapists with constructing individualized speech motor practice programs for their patients. [sent-24, score-1.177]
</p><p>15 The principal innovation of the proposed system in regard to existing stimuli selection applications is twofold: first, the syllabic inventories are derived from spoken word forms, and second, the selection interface is integrated within a broader platform for conducting speech motor practice. [sent-25, score-1.297]
</p><p>16 1 Speech Motor Disorders  Speech motor disorders (SMD) arise from neurological impairments in the motor systems involved in speech production. [sent-27, score-1.567]
</p><p>17 SMD include acquired and developmental forms of dysarthria and apraxia of speech. [sent-28, score-0.209]
</p><p>18 Dysarthria refers to the group of disorders associated with weakness, slowness and inability to coordinate the muscles used to produce speech (Duffy, 2005). [sent-29, score-0.325]
</p><p>19 Apraxia of speech (AOS) is referred to the impaired planning and programming of speech (Ziegler , 2008). [sent-30, score-0.41]
</p><p>20 Fluency disorders, namely stuttering and cluttering, although not always classified as SMD, have been extensively studied from the speech motor skill perspective (Van Lieshout et al. [sent-31, score-0.894]
</p><p>21 2 Speech Motor Training The goal of speech therapy with SMD patients is establishing and maintaining correct speech motor routines by means of practice. [sent-34, score-1.11]
</p><p>22 The process of learning and maintaining productive speech motor skills is referred to as speech motor training. [sent-35, score-1.675]
</p><p>23 0c S20tu1d0e Ants Roecsiea tirconh f Woror Cksomhop u,t pa tgioensa 3l7 L–in4g2u,istics  An insightful design of speech motor training exercises is crucial in order to achieve an optimal learning process, in terms of efficiency, retention, and transfer levels (Namasivayam, 2008). [sent-38, score-0.916]
</p><p>24 (2008) make the attempt to relate findings from research on non-speech motor learning principles to the case of speech motor training. [sent-40, score-1.474]
</p><p>25 They outline a number of critical factors in the design of speech motor exercises. [sent-41, score-0.826]
</p><p>26 These factors include the training program structure, selection of speech items, and the nature of the provided feedback. [sent-42, score-0.233]
</p><p>27 It is now generally agreed that speech motor exercises should involve simplified speech tasks. [sent-43, score-1.121]
</p><p>28 The use of non-sense syllable combinations is a generally accepted method for minimizing the effects of higher-order linguistic processing levels, with the idea of tapping as directly as possible to the motor component of speech production (Smits-Bandstra et al. [sent-44, score-1.313]
</p><p>29 3  Selection of speech items  The main considerations in selecting speech items for a specific patient are functional relevance and motor complexity. [sent-47, score-1.219]
</p><p>30 Functional relevance refers to the specific motor, articulatory or phonetic deficits, and consequently to the treatment goals of the patient. [sent-48, score-0.171]
</p><p>31 Relative motor complexity of speech segments is much less defined in linguistic terms than, for example, syntactic complexity (Kleinow et al. [sent-50, score-0.826]
</p><p>32 Although the partwhole relationship, which works well for syntactic constructions, can be applied to syllabic structures as well (e. [sent-52, score-0.124]
</p><p>33 However, in an original recent work, Ziegler presented a non-linear probabilistic model of the phonetic code, which involves units from a sub-segmental level up to the level of metrical feet (Ziegler , 2009). [sent-55, score-0.076]
</p><p>34 The model is verified on the basis of accuracy data from a large sample of apraxic speakers, and thus provides a quantitive  index of a speech segment’s motor complexity. [sent-56, score-0.856]
</p><p>35 Taken together, it is evident that the task of selecting sets of speech items for an individualized, optimal learning process is far from obvious, and much can be done to assist the clinicians with going through this step. [sent-57, score-0.436]
</p><p>36 3  The role of the syllable  The syllable is the primary speech unit used in studies on speech motor control (Namasivayam, 2008). [sent-58, score-1.925]
</p><p>37 It is also the basic unit used for constructing speech items in current methodologies of speech motor training (Kent, 2000). [sent-59, score-1.139]
</p><p>38 Since the choice of syllabic tokens is assumed to affect speech motor learning, it would be beneficial to have access to the syllabic inventory of the spoken language. [sent-60, score-1.297]
</p><p>39 Besides the inventory of spoken syllables, we are interested in the distribution of syllables across the language. [sent-61, score-0.372]
</p><p>40 1 Syllable frequency effects The observation that syllables exhibit an exponen-  tial distribution in English, Dutch and German has led researchers to infer the existence of a ’mental syllabary’ component in the speech production model (Schiller et al. [sent-63, score-0.481]
</p><p>41 Since this hypothesis assumes that production of high frequency syllables relies on highly automated motor gestures, it bears direct consequences on the utility of speech motor exercises. [sent-65, score-1.745]
</p><p>42 In other words, manipulating syllable sets in terms of their relative frequency is expected to have an effect on the learning process of new motor gestures. [sent-66, score-1.101]
</p><p>43 report that syllable frequency and syllable structure play a decisive role with respect to articulatory accuracy in the spontaneous speech production of patients with AOS (Staiger et al. [sent-69, score-1.329]
</p><p>44 Similarly, (Laganaro, 2008) confirms a significant effect of syllable frequency on production accuracy in experiments with speakers with AOS and speakers with conduction aphasia. [sent-71, score-0.607]
</p><p>45 2  Implications on motor learning  In that view, practicing with high-frequency syllables could promote a faster transfer of skills to everyday language, as the most ’required’ motor gestures are being strengthened. [sent-73, score-1.508]
</p><p>46 On the other hand, practicing with low-frequency syllables could potentially promote plasticity (or ’stretching’ ) of the speech motor system, as the learner is required to assemble motor plans from scratch, similar to the process of learning to pronounce words in a foreign language. [sent-74, score-1.682]
</p><p>47 38  4  A study with the Spoken Dutch Corpus  The Corpus Gesproken Nederlands (CGN) is a large corpus of spoken Dutch1 . [sent-76, score-0.155]
</p><p>48 The CGN contains manually verified phonetic transcriptions of 53,583 spoken forms, sampled from a wide variety of communication situations. [sent-77, score-0.261]
</p><p>49 A spoken form reports the phoneme sequence as it was actually uttered by the speaker as opposed to the canonical  form, which represents how the same word would be uttered in principle. [sent-78, score-0.331]
</p><p>50 1 Motivation for accessing spoken forms In contrast to written language corpora, such as CELEX (Baayenet al. [sent-80, score-0.21]
</p><p>51 , 1996), in which speakers read prepared written material, spontaneous speech corpora offer an access to an informal, unscripted speech on a variety of topics, including speakers from a range of regional dialects, age and educational backgrounds. [sent-82, score-0.582]
</p><p>52 Speakers most often deviate from the canonical pronunciation, producing segment reductions, deletions, insertions and assimilations in spontaneous speech (Mitterer, 2008). [sent-84, score-0.408]
</p><p>53 The work of Greenberg provides an in-depth account on the pronunciation variation in spoken English. [sent-85, score-0.202]
</p><p>54 A detailed phonetic transcription of the Switchboard corpus revealed that the spectral properties of many phonetic elements deviate significantly from their canonical form (Greenberg, 1999). [sent-86, score-0.287]
</p><p>55 In the light of the apparent discrepancy between the canonical forms and the actual spoken language, it becomes apparent that deriving syllabic inventories from spoken word forms will approximate the reality of spontaneous speech production better than relying on canonical representations. [sent-87, score-1.08]
</p><p>56 Consequently, it can be argued that clinical applications will benefit from incorporating speech items which optimally converge with the ’live’ realization of speech. [sent-88, score-0.313]
</p><p>57 2 Syllabification of spoken forms The syllabification information available in the CGN applies only to the canonical forms of words, and no syllabification of spoken word forms exists. [sent-90, score-1.029]
</p><p>58 The methods of automatic syllabification have been applied and tested exclusively on canonical word forms (Bartlett, 2007). [sent-91, score-0.374]
</p><p>59 In order to obtain the syllabic inventory of spoken language per se, 1(see http://lands. [sent-92, score-0.315]
</p><p>60 nl/cgn/) a preliminary study on automatic syllabification of spoken word forms has been carried out. [sent-95, score-0.445]
</p><p>61 Two methods for dealing with the syllabification task  were proposed, the first based on an n-gram model defined over sequences of phonemes, and the second based on statistics over syllable units. [sent-96, score-0.671]
</p><p>62 Both algorithms accept as input a list of possible segmentations of a given phonetic sequence, and return the one which maximizes the score of the specific function they implement. [sent-97, score-0.12]
</p><p>63 The authors describe the syllabification task as a tagging problem, in which each phonetic symbol of a word is tagged as either a syllable boundary (‘B’) or as a non-syllable boundary (‘N’). [sent-102, score-0.747]
</p><p>64 the tag sequence which is more probable for the given phoneme sequence pn1, as shown in equation (1). [sent-104, score-0.071]
</p><p>65 Broadly speaking, given a set of possible segmentations of a given phoneme sequence, the algorithm, selects the one which maximizes the pres-  ence and frequency of its segments. [sent-107, score-0.117]
</p><p>66 759r0d93s Table 1: Summary of syllabification results on canonical word forms. [sent-112, score-0.319]
</p><p>67 4  Results  The first step involved the evaluation of the two algorithms on syllabification of canonical word forms. [sent-114, score-0.319]
</p><p>68 The evaluation is presented in terms of percentage of correct syllable boundaries2, and percentage of correctly syllabified words. [sent-119, score-0.47]
</p><p>69 5  Data extraction  The process of evaluating syllabification of spoken word forms is compromised by the fact that there exists no gold annotation for the pronunciation data in the corpus. [sent-124, score-0.492]
</p><p>70 Motivated by the high agreement score, we have applied the phoneme-based method on the spoken word forms in the CGN, and compiled a syllabic inventory. [sent-133, score-0.334]
</p><p>71 In total, 832,236 syllable tokens were encountered in the corpus, of them 11,054 unique syllables were extracted and listed. [sent-134, score-0.649]
</p><p>72 According to our statistics, 4% of unique syllable tokens account for 80% of all extracted tokens, and 10% of unique syllables account for 90% respectively. [sent-137, score-0.649]
</p><p>73 For each extracted syllable, we have recorded its structure, frequency rank, and the articulatory characteristics of its consonants. [sent-138, score-0.083]
</p><p>74 Next, we describe the speech  items selection tool for clinicians. [sent-139, score-0.3]
</p><p>75 Figure 1: Syllable frequency distribution over the spoken forms in the Dutch Spoken Corpus. [sent-140, score-0.254]
</p><p>76 The y-axis plots the total number of syllable tokens extracted for each frequency bin. [sent-142, score-0.512]
</p><p>77 For each exercise, a number of syllable sets are selected, according to the specific needs of the patient. [sent-145, score-0.436]
</p><p>78 The main function of the interface, thus, deals with selection of customized syllable sets, and is described next. [sent-146, score-0.464]
</p><p>79 The rest of the interface deals with the different ways in which the syllable sets can be grouped into exercises, and how exercises are scheduled between treatment sessions. [sent-147, score-0.653]
</p><p>80 1 User-defined syllable sets The process starts with selecting the number of syllables in the current set, a number between one and four. [sent-149, score-0.641]
</p><p>81 Each box allows for a separate configuration of one syllable  group. [sent-151, score-0.462]
</p><p>82 As can be seen in Figure 2, a syllable box contains a number of menus, and a text grid at the bottom of the box. [sent-152, score-0.436]
</p><p>83 Figure 2: A snapshot of the part of the interface allowing configuration of syllable sets Here follows the list of the parameters which the user can manipulate, and their possible values:  •  • •  Syllable Type4 Syllable Frequency5  Syllable  4CV, CVC, CCV, CCVC, etc. [sent-153, score-0.524]
</p><p>84 •  Manner of articulation7  •  high,  Voiced - Unvoiced consonant 6  •  -  Place of articulation8  Once the user selects a syllable type, he/she can further specify each consonant within that syllable type in terms of voiced/unvoiced segment choice and manner and place of articulation. [sent-155, score-0.974]
</p><p>85 For the sake of simplicity, syllable frequency ranks have been divided in three rank groups. [sent-156, score-0.48]
</p><p>86 As the user selects the parameters which define the desired syllable type, the text grid is continuously filled with the list of syllables satisfying these cri-  teria, and a counter shows the number of syllables currently in the grid. [sent-158, score-0.798]
</p><p>87 Once the configuration process is accomplished, the syllables which ’survived’ the selection will constitute the speech items of the current exercise, and the user proceeds to select how the syllable sets should be grouped, scheduled and so on. [sent-159, score-0.977]
</p><p>88 Therefore, a usability study should provide guidelines for an optimal design of the interface, so that its utility for clinicians is maximized. [sent-164, score-0.164]
</p><p>89 Furthermore, we plan to integrate the proposed  interface within an computer-based interactive platform for speech therapy. [sent-165, score-0.267]
</p><p>90 A seamless integration of a speech items selection module within biofeedback games for performing exercises with these items seems straight forward, as the selected items can be directly embedded (e. [sent-166, score-0.524]
</p><p>91 , as text symbols or more abstract shapes) in the graphical environment where the exercises take place. [sent-168, score-0.09]
</p><p>92 Syllable frequency and syllable structure in apraxia of speech. [sent-176, score-0.6]
</p><p>93 Research on speech motor control and its disorders, a review and prospectives. [sent-206, score-0.848]
</p><p>94 Inuences of length and  syntactic complexity on the speech motor stability of the uent speech of adults who stutter. [sent-212, score-1.057]
</p><p>95 Is there a syllable frequency effect in aphasia or in apraxia of speech or both? [sent-216, score-0.805]
</p><p>96 Investigating speech motor practice and learning in people who stutter Journal of Fluency Disorders 33 (2008) 3251 Schiller, N. [sent-243, score-0.826]
</p><p>97 Speech and non-speech sequence skill learning in adults who stutter. [sent-266, score-0.081]
</p><p>98 Syllable frequency and syllable structure in the spontaneous speech production of patients with apraxia of speech. [sent-271, score-0.974]
</p><p>99 Recent developments in studies ofspeech motor control in stuttering. [sent-294, score-0.643]
</p><p>100 Modelling the architecture of phonetic plans: Evidence from apraxia of speech. [sent-312, score-0.196]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('motor', 0.621), ('syllable', 0.436), ('syllabification', 0.235), ('speech', 0.205), ('syllables', 0.181), ('spoken', 0.155), ('syllabic', 0.124), ('ziegler', 0.12), ('disorders', 0.12), ('apraxia', 0.12), ('clinicians', 0.12), ('exercises', 0.09), ('cgn', 0.086), ('canonical', 0.084), ('phonetic', 0.076), ('spontaneous', 0.073), ('smd', 0.069), ('dutch', 0.068), ('items', 0.067), ('interface', 0.062), ('lieshout', 0.06), ('schiller', 0.06), ('forms', 0.055), ('aichert', 0.052), ('greenberg', 0.052), ('namasivayam', 0.052), ('staiger', 0.052), ('production', 0.051), ('pronunciation', 0.047), ('aos', 0.045), ('patients', 0.045), ('frequency', 0.044), ('segmentations', 0.044), ('netherlands', 0.043), ('clinical', 0.041), ('kent', 0.041), ('consonant', 0.041), ('methodologies', 0.041), ('elsevier', 0.039), ('inventories', 0.039), ('articulatory', 0.039), ('bartlett', 0.039), ('speakers', 0.038), ('inventory', 0.036), ('stimuli', 0.035), ('aphasiology', 0.034), ('baayenet', 0.034), ('dysarthria', 0.034), ('kleinow', 0.034), ('laganaro', 0.034), ('leiden', 0.034), ('maas', 0.034), ('mitterer', 0.034), ('practicing', 0.034), ('scheduled', 0.034), ('skill', 0.034), ('stuttering', 0.034), ('syllabified', 0.034), ('therapists', 0.034), ('therapy', 0.034), ('fluency', 0.034), ('tokens', 0.032), ('treatment', 0.031), ('patient', 0.03), ('verified', 0.03), ('timit', 0.03), ('zue', 0.03), ('individualized', 0.03), ('syllabary', 0.03), ('phoneme', 0.029), ('selection', 0.028), ('gestures', 0.028), ('principles', 0.027), ('configuration', 0.026), ('adults', 0.026), ('deviate', 0.026), ('november', 0.026), ('celex', 0.026), ('revealed', 0.025), ('consequently', 0.025), ('manipulate', 0.024), ('duffy', 0.024), ('selecting', 0.024), ('skills', 0.023), ('riley', 0.023), ('baayen', 0.023), ('peters', 0.023), ('corpora', 0.023), ('exercise', 0.022), ('utility', 0.022), ('control', 0.022), ('usability', 0.022), ('schmid', 0.022), ('sequence', 0.021), ('uttered', 0.021), ('brain', 0.021), ('van', 0.021), ('segment', 0.02), ('plans', 0.02), ('assist', 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000014 <a title="137-tfidf-1" href="./acl-2010-How_Spoken_Language_Corpora_Can_Refine_Current_Speech_Motor_Training_Methodologies.html">137 acl-2010-How Spoken Language Corpora Can Refine Current Speech Motor Training Methodologies</a></p>
<p>Author: Daniil Umanski ; Federico Sangati</p><p>Abstract: The growing availability of spoken language corpora presents new opportunities for enriching the methodologies of speech and language therapy. In this paper, we present a novel approach for constructing speech motor exercises, based on linguistic knowledge extracted from spoken language corpora. In our study with the Dutch Spoken Corpus, syllabic inventories were obtained by means of automatic syllabification of the spoken language data. Our experimental syllabification method exhibited a reliable performance, and allowed for the acquisition of syllabic tokens from the corpus. Consequently, the syl- labic tokens were integrated in a tool for clinicians, a result which holds the potential of contributing to the current state of speech motor training methodologies.</p><p>2 0.11539722 <a title="137-tfidf-2" href="./acl-2010-Correcting_Errors_in_Speech_Recognition_with_Articulatory_Dynamics.html">74 acl-2010-Correcting Errors in Speech Recognition with Articulatory Dynamics</a></p>
<p>Author: Frank Rudzicz</p><p>Abstract: We introduce a novel mechanism for incorporating articulatory dynamics into speech recognition with the theory of task dynamics. This system reranks sentencelevel hypotheses by the likelihoods of their hypothetical articulatory realizations which are derived from relationships learned with aligned acoustic/articulatory data. Experiments compare this with two baseline systems, namely an acoustic hidden Markov model and a dynamic Bayes network augmented with discretized representations of the vocal tract. Our system based on task dynamics reduces worderror rates significantly by 10.2% relative to the best baseline models.</p><p>3 0.064802103 <a title="137-tfidf-3" href="./acl-2010-A_Risk_Minimization_Framework_for_Extractive_Speech_Summarization.html">14 acl-2010-A Risk Minimization Framework for Extractive Speech Summarization</a></p>
<p>Author: Shih-Hsiang Lin ; Berlin Chen</p><p>Abstract: In this paper, we formulate extractive summarization as a risk minimization problem and propose a unified probabilistic framework that naturally combines supervised and unsupervised summarization models to inherit their individual merits as well as to overcome their inherent limitations. In addition, the introduction of various loss functions also provides the summarization framework with a flexible but systematic way to render the redundancy and coherence relationships among sentences and between sentences and the whole document, respectively. Experiments on speech summarization show that the methods deduced from our framework are very competitive with existing summarization approaches. 1</p><p>4 0.056100816 <a title="137-tfidf-4" href="./acl-2010-Letter-Phoneme_Alignment%3A_An_Exploration.html">170 acl-2010-Letter-Phoneme Alignment: An Exploration</a></p>
<p>Author: Sittichai Jiampojamarn ; Grzegorz Kondrak</p><p>Abstract: Letter-phoneme alignment is usually generated by a straightforward application of the EM algorithm. We explore several alternative alignment methods that employ phonetics, integer programming, and sets of constraints, and propose a novel approach of refining the EM alignment by aggregation of best alignments. We perform both intrinsic and extrinsic evaluation of the assortment of methods. We show that our proposed EM-Aggregation algorithm leads to the improvement of the state of the art in letter-to-phoneme conversion on several different data sets.</p><p>5 0.050546419 <a title="137-tfidf-5" href="./acl-2010-A_Rational_Model_of_Eye_Movement_Control_in_Reading.html">13 acl-2010-A Rational Model of Eye Movement Control in Reading</a></p>
<p>Author: Klinton Bicknell ; Roger Levy</p><p>Abstract: A number of results in the study of realtime sentence comprehension have been explained by computational models as resulting from the rational use of probabilistic linguistic information. Many times, these hypotheses have been tested in reading by linking predictions about relative word difficulty to word-aggregated eye tracking measures such as go-past time. In this paper, we extend these results by asking to what extent reading is well-modeled as rational behavior at a finer level of analysis, predicting not aggregate measures, but the duration and location of each fixation. We present a new rational model of eye movement control in reading, the central assumption of which is that eye move- ment decisions are made to obtain noisy visual information as the reader performs Bayesian inference on the identities of the words in the sentence. As a case study, we present two simulations demonstrating that the model gives a rational explanation for between-word regressions.</p><p>6 0.042341359 <a title="137-tfidf-6" href="./acl-2010-Personalising_Speech-To-Speech_Translation_in_the_EMIME_Project.html">193 acl-2010-Personalising Speech-To-Speech Translation in the EMIME Project</a></p>
<p>7 0.0414465 <a title="137-tfidf-7" href="./acl-2010-Domain_Adaptation_of_Maximum_Entropy_Language_Models.html">91 acl-2010-Domain Adaptation of Maximum Entropy Language Models</a></p>
<p>8 0.039248381 <a title="137-tfidf-8" href="./acl-2010-The_Human_Language_Project%3A_Building_a_Universal_Corpus_of_the_World%27s_Languages.html">226 acl-2010-The Human Language Project: Building a Universal Corpus of the World's Languages</a></p>
<p>9 0.038863491 <a title="137-tfidf-9" href="./acl-2010-Conditional_Random_Fields_for_Word_Hyphenation.html">68 acl-2010-Conditional Random Fields for Word Hyphenation</a></p>
<p>10 0.037967693 <a title="137-tfidf-10" href="./acl-2010-Classification_of_Feedback_Expressions_in_Multimodal_Data.html">58 acl-2010-Classification of Feedback Expressions in Multimodal Data</a></p>
<p>11 0.037814438 <a title="137-tfidf-11" href="./acl-2010-Combining_Data_and_Mathematical_Models_of_Language_Change.html">61 acl-2010-Combining Data and Mathematical Models of Language Change</a></p>
<p>12 0.03672073 <a title="137-tfidf-12" href="./acl-2010-Optimising_Information_Presentation_for_Spoken_Dialogue_Systems.html">187 acl-2010-Optimising Information Presentation for Spoken Dialogue Systems</a></p>
<p>13 0.034710579 <a title="137-tfidf-13" href="./acl-2010-Modeling_Norms_of_Turn-Taking_in_Multi-Party_Conversation.html">173 acl-2010-Modeling Norms of Turn-Taking in Multi-Party Conversation</a></p>
<p>14 0.034506008 <a title="137-tfidf-14" href="./acl-2010-Fixed_Length_Word_Suffix_for_Factored_Statistical_Machine_Translation.html">119 acl-2010-Fixed Length Word Suffix for Factored Statistical Machine Translation</a></p>
<p>15 0.033038959 <a title="137-tfidf-15" href="./acl-2010-Speech-Driven_Access_to_the_Deep_Web_on_Mobile_Devices.html">215 acl-2010-Speech-Driven Access to the Deep Web on Mobile Devices</a></p>
<p>16 0.031070571 <a title="137-tfidf-16" href="./acl-2010-Towards_Relational_POMDPs_for_Adaptive_Dialogue_Management.html">239 acl-2010-Towards Relational POMDPs for Adaptive Dialogue Management</a></p>
<p>17 0.030163128 <a title="137-tfidf-17" href="./acl-2010-Top-Down_K-Best_A%2A_Parsing.html">236 acl-2010-Top-Down K-Best A* Parsing</a></p>
<p>18 0.029070437 <a title="137-tfidf-18" href="./acl-2010-Cognitively_Plausible_Models_of_Human_Language_Processing.html">59 acl-2010-Cognitively Plausible Models of Human Language Processing</a></p>
<p>19 0.027768265 <a title="137-tfidf-19" href="./acl-2010-A_Cognitive_Cost_Model_of_Annotations_Based_on_Eye-Tracking_Data.html">4 acl-2010-A Cognitive Cost Model of Annotations Based on Eye-Tracking Data</a></p>
<p>20 0.026761174 <a title="137-tfidf-20" href="./acl-2010-Syntactic_and_Semantic_Factors_in_Processing_Difficulty%3A_An_Integrated_Measure.html">220 acl-2010-Syntactic and Semantic Factors in Processing Difficulty: An Integrated Measure</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.082), (1, 0.019), (2, -0.021), (3, -0.055), (4, -0.001), (5, -0.06), (6, -0.039), (7, -0.0), (8, 0.043), (9, -0.011), (10, -0.02), (11, 0.017), (12, 0.018), (13, -0.022), (14, -0.029), (15, 0.003), (16, -0.012), (17, 0.026), (18, 0.012), (19, 0.043), (20, -0.014), (21, -0.003), (22, -0.008), (23, -0.017), (24, 0.028), (25, 0.072), (26, -0.009), (27, 0.022), (28, 0.038), (29, 0.003), (30, -0.096), (31, 0.132), (32, 0.08), (33, -0.085), (34, 0.027), (35, -0.031), (36, -0.041), (37, 0.096), (38, -0.044), (39, 0.071), (40, 0.003), (41, -0.072), (42, 0.11), (43, -0.004), (44, -0.097), (45, 0.058), (46, 0.052), (47, -0.007), (48, 0.042), (49, 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95261747 <a title="137-lsi-1" href="./acl-2010-How_Spoken_Language_Corpora_Can_Refine_Current_Speech_Motor_Training_Methodologies.html">137 acl-2010-How Spoken Language Corpora Can Refine Current Speech Motor Training Methodologies</a></p>
<p>Author: Daniil Umanski ; Federico Sangati</p><p>Abstract: The growing availability of spoken language corpora presents new opportunities for enriching the methodologies of speech and language therapy. In this paper, we present a novel approach for constructing speech motor exercises, based on linguistic knowledge extracted from spoken language corpora. In our study with the Dutch Spoken Corpus, syllabic inventories were obtained by means of automatic syllabification of the spoken language data. Our experimental syllabification method exhibited a reliable performance, and allowed for the acquisition of syllabic tokens from the corpus. Consequently, the syl- labic tokens were integrated in a tool for clinicians, a result which holds the potential of contributing to the current state of speech motor training methodologies.</p><p>2 0.75265205 <a title="137-lsi-2" href="./acl-2010-Correcting_Errors_in_Speech_Recognition_with_Articulatory_Dynamics.html">74 acl-2010-Correcting Errors in Speech Recognition with Articulatory Dynamics</a></p>
<p>Author: Frank Rudzicz</p><p>Abstract: We introduce a novel mechanism for incorporating articulatory dynamics into speech recognition with the theory of task dynamics. This system reranks sentencelevel hypotheses by the likelihoods of their hypothetical articulatory realizations which are derived from relationships learned with aligned acoustic/articulatory data. Experiments compare this with two baseline systems, namely an acoustic hidden Markov model and a dynamic Bayes network augmented with discretized representations of the vocal tract. Our system based on task dynamics reduces worderror rates significantly by 10.2% relative to the best baseline models.</p><p>3 0.71964711 <a title="137-lsi-3" href="./acl-2010-Personalising_Speech-To-Speech_Translation_in_the_EMIME_Project.html">193 acl-2010-Personalising Speech-To-Speech Translation in the EMIME Project</a></p>
<p>Author: Mikko Kurimo ; William Byrne ; John Dines ; Philip N. Garner ; Matthew Gibson ; Yong Guan ; Teemu Hirsimaki ; Reima Karhila ; Simon King ; Hui Liang ; Keiichiro Oura ; Lakshmi Saheer ; Matt Shannon ; Sayaki Shiota ; Jilei Tian</p><p>Abstract: In the EMIME project we have studied unsupervised cross-lingual speaker adaptation. We have employed an HMM statistical framework for both speech recognition and synthesis which provides transformation mechanisms to adapt the synthesized voice in TTS (text-to-speech) using the recognized voice in ASR (automatic speech recognition). An important application for this research is personalised speech-to-speech translation that will use the voice of the speaker in the input language to utter the translated sentences in the output language. In mobile environments this enhances the users’ interaction across language barriers by making the output speech sound more like the original speaker’s way of speaking, even if she or he could not speak the output language.</p><p>4 0.63630354 <a title="137-lsi-4" href="./acl-2010-Domain_Adaptation_of_Maximum_Entropy_Language_Models.html">91 acl-2010-Domain Adaptation of Maximum Entropy Language Models</a></p>
<p>Author: Tanel Alumae ; Mikko Kurimo</p><p>Abstract: We investigate a recently proposed Bayesian adaptation method for building style-adapted maximum entropy language models for speech recognition, given a large corpus of written language data and a small corpus of speech transcripts. Experiments show that the method consistently outperforms linear interpolation which is typically used in such cases.</p><p>5 0.61433673 <a title="137-lsi-5" href="./acl-2010-Combining_Data_and_Mathematical_Models_of_Language_Change.html">61 acl-2010-Combining Data and Mathematical Models of Language Change</a></p>
<p>Author: Morgan Sonderegger ; Partha Niyogi</p><p>Abstract: English noun/verb (N/V) pairs (contract, cement) have undergone complex patterns of change between 3 stress patterns for several centuries. We describe a longitudinal dataset of N/V pair pronunciations, leading to a set of properties to be accounted for by any computational model. We analyze the dynamics of 5 dynamical systems models of linguistic populations, each derived from a model of learning by individuals. We compare each model’s dynamics to a set of properties observed in the N/V data, and reason about how assumptions about individual learning affect population-level dynamics.</p><p>6 0.54798716 <a title="137-lsi-6" href="./acl-2010-Modeling_Norms_of_Turn-Taking_in_Multi-Party_Conversation.html">173 acl-2010-Modeling Norms of Turn-Taking in Multi-Party Conversation</a></p>
<p>7 0.53446817 <a title="137-lsi-7" href="./acl-2010-Using_Speech_to_Reply_to_SMS_Messages_While_Driving%3A_An_In-Car_Simulator_User_Study.html">254 acl-2010-Using Speech to Reply to SMS Messages While Driving: An In-Car Simulator User Study</a></p>
<p>8 0.46502277 <a title="137-lsi-8" href="./acl-2010-Hunting_for_the_Black_Swan%3A_Risk_Mining_from_Text.html">138 acl-2010-Hunting for the Black Swan: Risk Mining from Text</a></p>
<p>9 0.4514114 <a title="137-lsi-9" href="./acl-2010-Intelligent_Selection_of_Language_Model_Training_Data.html">151 acl-2010-Intelligent Selection of Language Model Training Data</a></p>
<p>10 0.39279717 <a title="137-lsi-10" href="./acl-2010-Learning_Word-Class_Lattices_for_Definition_and_Hypernym_Extraction.html">166 acl-2010-Learning Word-Class Lattices for Definition and Hypernym Extraction</a></p>
<p>11 0.38477534 <a title="137-lsi-11" href="./acl-2010-Enhanced_Word_Decomposition_by_Calibrating_the_Decision_Threshold_of_Probabilistic_Models_and_Using_a_Model_Ensemble.html">100 acl-2010-Enhanced Word Decomposition by Calibrating the Decision Threshold of Probabilistic Models and Using a Model Ensemble</a></p>
<p>12 0.38051552 <a title="137-lsi-12" href="./acl-2010-The_Human_Language_Project%3A_Building_a_Universal_Corpus_of_the_World%27s_Languages.html">226 acl-2010-The Human Language Project: Building a Universal Corpus of the World's Languages</a></p>
<p>13 0.36057821 <a title="137-lsi-13" href="./acl-2010-A_Rational_Model_of_Eye_Movement_Control_in_Reading.html">13 acl-2010-A Rational Model of Eye Movement Control in Reading</a></p>
<p>14 0.35642013 <a title="137-lsi-14" href="./acl-2010-Automatic_Sanskrit_Segmentizer_Using_Finite_State_Transducers.html">40 acl-2010-Automatic Sanskrit Segmentizer Using Finite State Transducers</a></p>
<p>15 0.35490495 <a title="137-lsi-15" href="./acl-2010-Finding_Cognate_Groups_Using_Phylogenies.html">116 acl-2010-Finding Cognate Groups Using Phylogenies</a></p>
<p>16 0.34927708 <a title="137-lsi-16" href="./acl-2010-Classification_of_Feedback_Expressions_in_Multimodal_Data.html">58 acl-2010-Classification of Feedback Expressions in Multimodal Data</a></p>
<p>17 0.34748888 <a title="137-lsi-17" href="./acl-2010-Decision_Detection_Using_Hierarchical_Graphical_Models.html">81 acl-2010-Decision Detection Using Hierarchical Graphical Models</a></p>
<p>18 0.3386803 <a title="137-lsi-18" href="./acl-2010-Don%27t_%27Have_a_Clue%27%3F_Unsupervised_Co-Learning_of_Downward-Entailing_Operators..html">92 acl-2010-Don't 'Have a Clue'? Unsupervised Co-Learning of Downward-Entailing Operators.</a></p>
<p>19 0.33316505 <a title="137-lsi-19" href="./acl-2010-All_Words_Domain_Adapted_WSD%3A_Finding_a_Middle_Ground_between_Supervision_and_Unsupervision.html">26 acl-2010-All Words Domain Adapted WSD: Finding a Middle Ground between Supervision and Unsupervision</a></p>
<p>20 0.33252239 <a title="137-lsi-20" href="./acl-2010-Fixed_Length_Word_Suffix_for_Factored_Statistical_Machine_Translation.html">119 acl-2010-Fixed Length Word Suffix for Factored Statistical Machine Translation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.01), (4, 0.015), (14, 0.029), (20, 0.022), (25, 0.037), (39, 0.015), (42, 0.028), (44, 0.016), (51, 0.39), (59, 0.064), (73, 0.05), (78, 0.024), (83, 0.075), (84, 0.036), (98, 0.07)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.75161552 <a title="137-lda-1" href="./acl-2010-How_Spoken_Language_Corpora_Can_Refine_Current_Speech_Motor_Training_Methodologies.html">137 acl-2010-How Spoken Language Corpora Can Refine Current Speech Motor Training Methodologies</a></p>
<p>Author: Daniil Umanski ; Federico Sangati</p><p>Abstract: The growing availability of spoken language corpora presents new opportunities for enriching the methodologies of speech and language therapy. In this paper, we present a novel approach for constructing speech motor exercises, based on linguistic knowledge extracted from spoken language corpora. In our study with the Dutch Spoken Corpus, syllabic inventories were obtained by means of automatic syllabification of the spoken language data. Our experimental syllabification method exhibited a reliable performance, and allowed for the acquisition of syllabic tokens from the corpus. Consequently, the syl- labic tokens were integrated in a tool for clinicians, a result which holds the potential of contributing to the current state of speech motor training methodologies.</p><p>2 0.52802467 <a title="137-lda-2" href="./acl-2010-A_Bayesian_Method_for_Robust_Estimation_of_Distributional_Similarities.html">3 acl-2010-A Bayesian Method for Robust Estimation of Distributional Similarities</a></p>
<p>Author: Jun'ichi Kazama ; Stijn De Saeger ; Kow Kuroda ; Masaki Murata ; Kentaro Torisawa</p><p>Abstract: Existing word similarity measures are not robust to data sparseness since they rely only on the point estimation of words’ context profiles obtained from a limited amount of data. This paper proposes a Bayesian method for robust distributional word similarities. The method uses a distribution of context profiles obtained by Bayesian estimation and takes the expectation of a base similarity measure under that distribution. When the context profiles are multinomial distributions, the priors are Dirichlet, and the base measure is . the Bhattacharyya coefficient, we can derive an analytical form that allows efficient calculation. For the task of word similarity estimation using a large amount of Web data in Japanese, we show that the proposed measure gives better accuracies than other well-known similarity measures.</p><p>3 0.42661086 <a title="137-lda-3" href="./acl-2010-Improving_Arabic-to-English_Statistical_Machine_Translation_by_Reordering_Post-Verbal_Subjects_for_Alignment.html">145 acl-2010-Improving Arabic-to-English Statistical Machine Translation by Reordering Post-Verbal Subjects for Alignment</a></p>
<p>Author: Marine Carpuat ; Yuval Marton ; Nizar Habash</p><p>Abstract: We study the challenges raised by Arabic verb and subject detection and reordering in Statistical Machine Translation (SMT). We show that post-verbal subject (VS) constructions are hard to translate because they have highly ambiguous reordering patterns when translated to English. In addition, implementing reordering is difficult because the boundaries of VS constructions are hard to detect accurately, even with a state-of-the-art Arabic dependency parser. We therefore propose to reorder VS constructions into SV order for SMT word alignment only. This strategy significantly improves BLEU and TER scores, even on a strong large-scale baseline and despite noisy parses.</p><p>4 0.35703564 <a title="137-lda-4" href="./acl-2010-Knowledge-Rich_Word_Sense_Disambiguation_Rivaling_Supervised_Systems.html">156 acl-2010-Knowledge-Rich Word Sense Disambiguation Rivaling Supervised Systems</a></p>
<p>Author: Simone Paolo Ponzetto ; Roberto Navigli</p><p>Abstract: One of the main obstacles to highperformance Word Sense Disambiguation (WSD) is the knowledge acquisition bottleneck. In this paper, we present a methodology to automatically extend WordNet with large amounts of semantic relations from an encyclopedic resource, namely Wikipedia. We show that, when provided with a vast amount of high-quality semantic relations, simple knowledge-lean disambiguation algorithms compete with state-of-the-art supervised WSD systems in a coarse-grained all-words setting and outperform them on gold-standard domain-specific datasets.</p><p>5 0.33495408 <a title="137-lda-5" href="./acl-2010-Latent_Variable_Models_of_Selectional_Preference.html">158 acl-2010-Latent Variable Models of Selectional Preference</a></p>
<p>Author: Diarmuid O Seaghdha</p><p>Abstract: This paper describes the application of so-called topic models to selectional preference induction. Three models related to Latent Dirichlet Allocation, a proven method for modelling document-word cooccurrences, are presented and evaluated on datasets of human plausibility judgements. Compared to previously proposed techniques, these models perform very competitively, especially for infrequent predicate-argument combinations where they exceed the quality of Web-scale predictions while using relatively little data.</p><p>6 0.33320874 <a title="137-lda-6" href="./acl-2010-Complexity_Metrics_in_an_Incremental_Right-Corner_Parser.html">65 acl-2010-Complexity Metrics in an Incremental Right-Corner Parser</a></p>
<p>7 0.33119571 <a title="137-lda-7" href="./acl-2010-A_Study_of_Information_Retrieval_Weighting_Schemes_for_Sentiment_Analysis.html">18 acl-2010-A Study of Information Retrieval Weighting Schemes for Sentiment Analysis</a></p>
<p>8 0.33012116 <a title="137-lda-8" href="./acl-2010-Entity-Based_Local_Coherence_Modelling_Using_Topological_Fields.html">101 acl-2010-Entity-Based Local Coherence Modelling Using Topological Fields</a></p>
<p>9 0.33010867 <a title="137-lda-9" href="./acl-2010-Bootstrapping_Semantic_Analyzers_from_Non-Contradictory_Texts.html">55 acl-2010-Bootstrapping Semantic Analyzers from Non-Contradictory Texts</a></p>
<p>10 0.32999957 <a title="137-lda-10" href="./acl-2010-Sparsity_in_Dependency_Grammar_Induction.html">214 acl-2010-Sparsity in Dependency Grammar Induction</a></p>
<p>11 0.32987791 <a title="137-lda-11" href="./acl-2010-Using_Anaphora_Resolution_to_Improve_Opinion_Target_Identification_in_Movie_Reviews.html">251 acl-2010-Using Anaphora Resolution to Improve Opinion Target Identification in Movie Reviews</a></p>
<p>12 0.32987249 <a title="137-lda-12" href="./acl-2010-The_Manually_Annotated_Sub-Corpus%3A_A_Community_Resource_for_and_by_the_People.html">230 acl-2010-The Manually Annotated Sub-Corpus: A Community Resource for and by the People</a></p>
<p>13 0.32817972 <a title="137-lda-13" href="./acl-2010-Open-Domain_Semantic_Role_Labeling_by_Modeling_Word_Spans.html">184 acl-2010-Open-Domain Semantic Role Labeling by Modeling Word Spans</a></p>
<p>14 0.32797551 <a title="137-lda-14" href="./acl-2010-Phylogenetic_Grammar_Induction.html">195 acl-2010-Phylogenetic Grammar Induction</a></p>
<p>15 0.32786053 <a title="137-lda-15" href="./acl-2010-Fully_Unsupervised_Core-Adjunct_Argument_Classification.html">120 acl-2010-Fully Unsupervised Core-Adjunct Argument Classification</a></p>
<p>16 0.32741591 <a title="137-lda-16" href="./acl-2010-Detecting_Experiences_from_Weblogs.html">85 acl-2010-Detecting Experiences from Weblogs</a></p>
<p>17 0.32708472 <a title="137-lda-17" href="./acl-2010-Automatic_Generation_of_Story_Highlights.html">39 acl-2010-Automatic Generation of Story Highlights</a></p>
<p>18 0.32704073 <a title="137-lda-18" href="./acl-2010-Unsupervised_Event_Coreference_Resolution_with_Rich_Linguistic_Features.html">247 acl-2010-Unsupervised Event Coreference Resolution with Rich Linguistic Features</a></p>
<p>19 0.32700348 <a title="137-lda-19" href="./acl-2010-Cognitively_Plausible_Models_of_Human_Language_Processing.html">59 acl-2010-Cognitively Plausible Models of Human Language Processing</a></p>
<p>20 0.32695141 <a title="137-lda-20" href="./acl-2010-Experiments_in_Graph-Based_Semi-Supervised_Learning_Methods_for_Class-Instance_Acquisition.html">109 acl-2010-Experiments in Graph-Based Semi-Supervised Learning Methods for Class-Instance Acquisition</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
