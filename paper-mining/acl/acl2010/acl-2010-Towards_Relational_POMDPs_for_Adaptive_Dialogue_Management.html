<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>239 acl-2010-Towards Relational POMDPs for Adaptive Dialogue Management</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-239" href="#">acl2010-239</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>239 acl-2010-Towards Relational POMDPs for Adaptive Dialogue Management</h1>
<br/><p>Source: <a title="acl-2010-239-pdf" href="http://aclweb.org/anthology//P/P10/P10-3002.pdf">pdf</a></p><p>Author: Pierre Lison</p><p>Abstract: Open-ended spoken interactions are typically characterised by both structural complexity and high levels of uncertainty, making dialogue management in such settings a particularly challenging problem. Traditional approaches have focused on providing theoretical accounts for either the uncertainty or the complexity of spoken dialogue, but rarely considered the two issues simultaneously. This paper describes ongoing work on a new approach to dialogue management which attempts to fill this gap. We represent the interaction as a Partially Observable Markov Decision Process (POMDP) over a rich state space incorporating both dialogue, user, and environment models. The tractability of the resulting POMDP can be preserved using a mechanism for dynamically constraining the action space based on prior knowledge over locally relevant dialogue structures. These constraints are encoded in a small set of general rules expressed as a Markov Logic network. The first-order expressivity of Markov Logic enables us to leverage the rich relational structure of the problem and efficiently abstract over large regions ofthe state and action spaces.</p><p>Reference: <a title="acl-2010-239-reference" href="../acl2010_reference/acl-2010-Towards_Relational_POMDPs_for_Adaptive_Dialogue_Management_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Traditional approaches have focused on providing theoretical accounts for either the uncertainty or the complexity of spoken dialogue, but rarely considered the two issues simultaneously. [sent-2, score-0.244]
</p><p>2 This paper describes ongoing work on a new approach to dialogue management which attempts to fill this gap. [sent-3, score-0.669]
</p><p>3 We represent the interaction as a Partially Observable Markov Decision Process (POMDP) over a rich state space incorporating both dialogue, user, and environment models. [sent-4, score-0.405]
</p><p>4 The tractability of the resulting POMDP can be preserved  using a mechanism for dynamically constraining the action space based on prior knowledge over locally relevant dialogue structures. [sent-5, score-1.085]
</p><p>5 The first-order expressivity of Markov Logic enables us to leverage the rich relational structure of the problem and efficiently abstract over large regions ofthe state and action spaces. [sent-7, score-0.614]
</p><p>6 1 Introduction The development of spoken dialogue systems for rich, open-ended interactions raises a number of challenges, one of which is dialogue management. [sent-8, score-1.09]
</p><p>7 The role of dialogue management is to determine which communicative actions to take (i. [sent-9, score-0.778]
</p><p>8 what to say) given a goal and particular observations about the interaction and the current situation. [sent-11, score-0.049]
</p><p>9 First, spoken dialogue systems must usually deal  7  with high levels of noise and uncertainty. [sent-13, score-0.584]
</p><p>10 These uncertainties may arise from speech recognition errors, limited grammar coverage, or from various linguistic and pragmatic ambiguities. [sent-14, score-0.208]
</p><p>11 Second, open-ended dialogue is characteristically complex, and exhibits rich relational structures. [sent-15, score-0.677]
</p><p>12 Natural interactions should be adaptive to a variety of factors dependent on the interaction history, the general context, and the user preferences. [sent-16, score-0.26]
</p><p>13 As a consequence, the state space necessary to model the dynamics of the environment tends to be large and sparsely populated. [sent-17, score-0.399]
</p><p>14 These two problems have typically been addressed separately in the literature. [sent-18, score-0.041]
</p><p>15 On the one hand, the issue of uncertainty in speech understanding is usually dealt using a range of probabilistic models combined with decision-theoretic planning. [sent-19, score-0.101]
</p><p>16 Among these, Partially Observable Markov Decision Process (POMDP) models have recently emerged as a unifying mathematical framework for dialogue management (Williams and Young, 2007; Lemon and Pietquin, 2007). [sent-20, score-0.737]
</p><p>17 POMDPs provide an explicit account for a wide range of uncertainties related to partial observability (noisy, incomplete spoken inputs) and stochastic action effects (the world may evolve in unpredictable ways after executing an action). [sent-21, score-0.81]
</p><p>18 On the other hand, structural complexity is typically addressed with logic-based approaches. [sent-22, score-0.096]
</p><p>19 Some investigated topics in this paradigm are pragmatic interpretation (Thomason et al. [sent-23, score-0.099]
</p><p>20 , 2006), dialogue structure (Asher and Lascarides, 2003), or collaborative planning (Kruijff et al. [sent-24, score-0.547]
</p><p>21 These approaches are able to model sophisticated dialogue behaviours, but at the expense of robustness and adaptivity. [sent-26, score-0.496]
</p><p>22 They generally assume complete observability and provide only a very limited account (if any) of uncertainties. [sent-27, score-0.187]
</p><p>23 We are currently developing an hybrid approach which simultaneously tackles the uncertainty and complexity of dialogue management, based on a UppsaPlar,o Scewe d ineng,s 1 o3f Jtuhley A 2C0L10 2. [sent-28, score-0.658]
</p><p>24 In this paper, we more  specifically describe a new mechanism for dynamically constraining the space of possible actions available at a given time. [sent-32, score-0.433]
</p><p>25 Our aim is to use such mechanism to significantly reduce the search space and therefore make the planning problem globally more tractable. [sent-33, score-0.241]
</p><p>26 We first structure the state space using Markov Logic Networks, a first-order probabilistic language. [sent-35, score-0.182]
</p><p>27 Prior pragmatic knowledge about dialogue structure is then exploited to derive the set of dialogue actions which are locally admissible or relevant, and prune all irrelevant ones. [sent-36, score-1.247]
</p><p>28 The first-order expressivity of Markov Logic Networks allows us to easily specify the constraints via a small set of general rules which abstract over large regions of the state and action spaces. [sent-37, score-0.452]
</p><p>29 Our long-term goal is to develop an unified framework for adaptive dialogue management in rich, open-ended interactional settings. [sent-38, score-0.696]
</p><p>30 Section 2 lays down the formal foundations of our work, by describing dialogue management as a POMDP problem. [sent-40, score-0.695]
</p><p>31 We then describe in Section 3 our approach to POMDP planning with control knowl-  edge using Markov Logic rules. [sent-41, score-0.126]
</p><p>32 1 Partially Observable Markov Decision Processes (POMDPs) POMDPs are a mathematical model for sequential decision-making in partially observable environments. [sent-44, score-0.282]
</p><p>33 It provides a powerful framework for control problems which combine partial observability, uncertain action effects, incomplete knowledge of the environment dynamics and multiple, potentially conflicting objectives. [sent-45, score-0.493]
</p><p>34 Via reinforcement learning, it is possible to automatically learn near-optimal action policies given a POMDP model combined with real or simulated user data (Schatzmann et al. [sent-46, score-0.274]
</p><p>35 1 Formal definition A POMDP is a tuple hS, A, Z, T, Ω, Ri, where: •  S is the state space, which is the model of tShe i sw thoerld s fartoem s ptahec agent’s viewpoint. [sent-50, score-0.106]
</p><p>36 eIlt oisf  defined as a set of mutually exclusive states. [sent-51, score-0.12]
</p><p>37 8 r(at, st)  r(at+1, st+1)  Figure 1: Bayesian decision network corresponding to the POMDP model. [sent-52, score-0.054]
</p><p>38 Actions are represented as rectangles to stress that they are system actions rather than observed variables. [sent-54, score-0.213]
</p><p>39 Arcs into circular nodes express influence, whereas arcs into squared nodes are informational. [sent-55, score-0.168]
</p><p>40 For readability, only one state is shown at each time step, but it should be noted that the policy π is function of the full belief state rather than a single (unobservable) state. [sent-56, score-0.212]
</p><p>41 •  •  •  •  •  ×  A is the action space: the set of possible acAtion iss hate et ahec disposal eof: tthhee agent. [sent-57, score-0.378]
</p><p>42 Z is the observation space: the set of obserZvat i son thse w obhiscehr can o bne captured by tth oef agent. [sent-58, score-0.044]
</p><p>43 They correspond to features of the environment which can be directly perceived by the agent’s sensors. [sent-59, score-0.128]
</p><p>44 T is the transition function, defined as T : ST Athe aSn → [0, 1], cwtiohner,e T(s, a, s0) = P(s0|s, a) iSs t h→e probability roef reaching state s0 fro|ms, sat)a ties s ief pacrotiboanb a tisy performed. [sent-60, score-0.161]
</p><p>45 Ω is the observation function, defined as ΩΩ : sZ t A ob rSv → [0, 1], wcitithon Ω(z, a, s0) = P(z|a, s0), i . [sent-61, score-0.041]
</p><p>46 Sthe → probability ho fΩ observing z Paft(ezr| performing a and being now in state s0. [sent-63, score-0.106]
</p><p>47 R is the reward function, defined as R : SR A th → R(s, a) cetniocond,e dse tfhinee utility Rfor : tShe × agent t o< perform tehnec oadcetison th a wtilhitiyle oinr state s. [sent-64, score-0.272]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('dialogue', 0.46), ('pomdp', 0.423), ('pomdps', 0.219), ('action', 0.195), ('observability', 0.187), ('observable', 0.157), ('management', 0.149), ('markov', 0.126), ('actions', 0.122), ('logic', 0.112), ('uncertainties', 0.109), ('state', 0.106), ('uncertainty', 0.101), ('pragmatic', 0.099), ('environment', 0.091), ('constraining', 0.089), ('spoken', 0.088), ('adaptive', 0.087), ('planning', 0.087), ('expressivity', 0.085), ('rich', 0.083), ('interactions', 0.082), ('relational', 0.079), ('iss', 0.078), ('tshe', 0.078), ('mechanism', 0.078), ('dynamics', 0.076), ('space', 0.076), ('partially', 0.075), ('agent', 0.074), ('locally', 0.069), ('arcs', 0.069), ('dynamically', 0.068), ('regions', 0.066), ('ongoing', 0.06), ('complexity', 0.055), ('squared', 0.055), ('ief', 0.055), ('disposal', 0.055), ('wro', 0.055), ('characteristically', 0.055), ('managers', 0.055), ('tehnec', 0.055), ('kruijff', 0.055), ('decision', 0.054), ('incomplete', 0.053), ('sparsely', 0.05), ('sz', 0.05), ('lays', 0.05), ('hate', 0.05), ('evolve', 0.05), ('thomason', 0.05), ('rectangles', 0.05), ('tractability', 0.05), ('mathematical', 0.05), ('interaction', 0.049), ('networks', 0.047), ('communicative', 0.047), ('sthe', 0.047), ('executing', 0.047), ('dfki', 0.047), ('behaviours', 0.047), ('eof', 0.047), ('asher', 0.044), ('lascarides', 0.044), ('sat', 0.044), ('bne', 0.044), ('williams', 0.044), ('characterised', 0.044), ('athe', 0.044), ('circular', 0.044), ('unpredictable', 0.044), ('schatzmann', 0.044), ('emerged', 0.042), ('tackles', 0.042), ('oisf', 0.042), ('exclusive', 0.042), ('user', 0.042), ('addressed', 0.041), ('stress', 0.041), ('ob', 0.041), ('pierre', 0.041), ('st', 0.041), ('control', 0.039), ('uncertain', 0.039), ('fro', 0.039), ('lemon', 0.038), ('effects', 0.037), ('perceived', 0.037), ('admissible', 0.037), ('reinforcement', 0.037), ('dse', 0.037), ('levels', 0.036), ('foundations', 0.036), ('scewe', 0.036), ('mutually', 0.036), ('asn', 0.036), ('unifying', 0.036), ('expense', 0.036), ('ucken', 0.036)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="239-tfidf-1" href="./acl-2010-Towards_Relational_POMDPs_for_Adaptive_Dialogue_Management.html">239 acl-2010-Towards Relational POMDPs for Adaptive Dialogue Management</a></p>
<p>Author: Pierre Lison</p><p>Abstract: Open-ended spoken interactions are typically characterised by both structural complexity and high levels of uncertainty, making dialogue management in such settings a particularly challenging problem. Traditional approaches have focused on providing theoretical accounts for either the uncertainty or the complexity of spoken dialogue, but rarely considered the two issues simultaneously. This paper describes ongoing work on a new approach to dialogue management which attempts to fill this gap. We represent the interaction as a Partially Observable Markov Decision Process (POMDP) over a rich state space incorporating both dialogue, user, and environment models. The tractability of the resulting POMDP can be preserved using a mechanism for dynamically constraining the action space based on prior knowledge over locally relevant dialogue structures. These constraints are encoded in a small set of general rules expressed as a Markov Logic network. The first-order expressivity of Markov Logic enables us to leverage the rich relational structure of the problem and efficiently abstract over large regions ofthe state and action spaces.</p><p>2 0.24387792 <a title="239-tfidf-2" href="./acl-2010-Learning_to_Adapt_to_Unknown_Users%3A_Referring_Expression_Generation_in_Spoken_Dialogue_Systems.html">167 acl-2010-Learning to Adapt to Unknown Users: Referring Expression Generation in Spoken Dialogue Systems</a></p>
<p>Author: Srinivasan Janarthanam ; Oliver Lemon</p><p>Abstract: We present a data-driven approach to learn user-adaptive referring expression generation (REG) policies for spoken dialogue systems. Referring expressions can be difficult to understand in technical domains where users may not know the technical ‘jargon’ names of the domain entities. In such cases, dialogue systems must be able to model the user’s (lexical) domain knowledge and use appropriate referring expressions. We present a reinforcement learning (RL) framework in which the sys- tem learns REG policies which can adapt to unknown users online. Furthermore, unlike supervised learning methods which require a large corpus of expert adaptive behaviour to train on, we show that effective adaptive policies can be learned from a small dialogue corpus of non-adaptive human-machine interaction, by using a RL framework and a statistical user simulation. We show that in comparison to adaptive hand-coded baseline policies, the learned policy performs significantly better, with an 18.6% average increase in adaptation accuracy. The best learned policy also takes less dialogue time (average 1.07 min less) than the best hand-coded policy. This is because the learned policies can adapt online to changing evidence about the user’s domain expertise.</p><p>3 0.2079792 <a title="239-tfidf-3" href="./acl-2010-Optimising_Information_Presentation_for_Spoken_Dialogue_Systems.html">187 acl-2010-Optimising Information Presentation for Spoken Dialogue Systems</a></p>
<p>Author: Verena Rieser ; Oliver Lemon ; Xingkun Liu</p><p>Abstract: We present a novel approach to Information Presentation (IP) in Spoken Dialogue Systems (SDS) using a data-driven statistical optimisation framework for content planning and attribute selection. First we collect data in a Wizard-of-Oz (WoZ) experiment and use it to build a supervised model of human behaviour. This forms a baseline for measuring the performance of optimised policies, developed from this data using Reinforcement Learning (RL) methods. We show that the optimised policies significantly outperform the baselines in a variety of generation scenarios: while the supervised model is able to attain up to 87.6% of the possible reward on this task, the RL policies are significantly better in 5 out of 6 scenarios, gaining up to 91.5% of the total possible reward. The RL policies perform especially well in more complex scenarios. We are also the first to show that adding predictive “lower level” features (e.g. from the NLG realiser) is important for optimising IP strategies according to user preferences. This provides new insights into the nature of the IP problem for SDS.</p><p>4 0.16364905 <a title="239-tfidf-4" href="./acl-2010-Importance-Driven_Turn-Bidding_for_Spoken_Dialogue_Systems.html">142 acl-2010-Importance-Driven Turn-Bidding for Spoken Dialogue Systems</a></p>
<p>Author: Ethan Selfridge ; Peter Heeman</p><p>Abstract: Current turn-taking approaches for spoken dialogue systems rely on the speaker releasing the turn before the other can take it. This reliance results in restricted interactions that can lead to inefficient dialogues. In this paper we present a model we refer to as Importance-Driven Turn-Bidding that treats turn-taking as a negotiative process. Each conversant bids for the turn based on the importance of the intended utterance, and Reinforcement Learning is used to indirectly learn this parameter. We find that Importance-Driven Turn-Bidding performs better than two current turntaking approaches in an artificial collaborative slot-filling domain. The negotiative nature of this model creates efficient dia- logues, and supports the improvement of mixed-initiative interaction.</p><p>5 0.16036603 <a title="239-tfidf-5" href="./acl-2010-Non-Cooperation_in_Dialogue.html">178 acl-2010-Non-Cooperation in Dialogue</a></p>
<p>Author: Brian Pluss</p><p>Abstract: This paper presents ongoing research on computational models for non-cooperative dialogue. We start by analysing different levels of cooperation in conversation. Then, inspired by findings from an empirical study, we propose a technique for measuring non-cooperation in political interviews. Finally, we describe a research programme towards obtaining a suitable model and discuss previous accounts for conflictive dialogue, identifying the differences with our work.</p><p>6 0.15817258 <a title="239-tfidf-6" href="./acl-2010-Reading_between_the_Lines%3A_Learning_to_Map_High-Level_Instructions_to_Commands.html">202 acl-2010-Reading between the Lines: Learning to Map High-Level Instructions to Commands</a></p>
<p>7 0.14885083 <a title="239-tfidf-7" href="./acl-2010-Beetle_II%3A_A_System_for_Tutoring_and_Computational_Linguistics_Experimentation.html">47 acl-2010-Beetle II: A System for Tutoring and Computational Linguistics Experimentation</a></p>
<p>8 0.13834062 <a title="239-tfidf-8" href="./acl-2010-Phrase-Based_Statistical_Language_Generation_Using_Graphical_Models_and_Active_Learning.html">194 acl-2010-Phrase-Based Statistical Language Generation Using Graphical Models and Active Learning</a></p>
<p>9 0.13481817 <a title="239-tfidf-9" href="./acl-2010-Demonstration_of_a_Prototype_for_a_Conversational_Companion_for_Reminiscing_about_Images.html">82 acl-2010-Demonstration of a Prototype for a Conversational Companion for Reminiscing about Images</a></p>
<p>10 0.12221096 <a title="239-tfidf-10" href="./acl-2010-The_Impact_of_Interpretation_Problems_on_Tutorial_Dialogue.html">227 acl-2010-The Impact of Interpretation Problems on Tutorial Dialogue</a></p>
<p>11 0.11093095 <a title="239-tfidf-11" href="./acl-2010-Classification_of_Feedback_Expressions_in_Multimodal_Data.html">58 acl-2010-Classification of Feedback Expressions in Multimodal Data</a></p>
<p>12 0.1051247 <a title="239-tfidf-12" href="./acl-2010-Decision_Detection_Using_Hierarchical_Graphical_Models.html">81 acl-2010-Decision Detection Using Hierarchical Graphical Models</a></p>
<p>13 0.091343157 <a title="239-tfidf-13" href="./acl-2010-Learning_to_Follow_Navigational_Directions.html">168 acl-2010-Learning to Follow Navigational Directions</a></p>
<p>14 0.083806962 <a title="239-tfidf-14" href="./acl-2010-Extracting_Social_Networks_from_Literary_Fiction.html">112 acl-2010-Extracting Social Networks from Literary Fiction</a></p>
<p>15 0.079081953 <a title="239-tfidf-15" href="./acl-2010-Now%2C_Where_Was_I%3F_Resumption_Strategies_for_an_In-Vehicle_Dialogue_System.html">179 acl-2010-Now, Where Was I? Resumption Strategies for an In-Vehicle Dialogue System</a></p>
<p>16 0.077953912 <a title="239-tfidf-16" href="./acl-2010-Automated_Planning_for_Situated_Natural_Language_Generation.html">35 acl-2010-Automated Planning for Situated Natural Language Generation</a></p>
<p>17 0.070049956 <a title="239-tfidf-17" href="./acl-2010-Incorporating_Extra-Linguistic_Information_into_Reference_Resolution_in_Collaborative_Task_Dialogue.html">149 acl-2010-Incorporating Extra-Linguistic Information into Reference Resolution in Collaborative Task Dialogue</a></p>
<p>18 0.063704796 <a title="239-tfidf-18" href="./acl-2010-Modeling_Norms_of_Turn-Taking_in_Multi-Party_Conversation.html">173 acl-2010-Modeling Norms of Turn-Taking in Multi-Party Conversation</a></p>
<p>19 0.063550234 <a title="239-tfidf-19" href="./acl-2010-Combining_Data_and_Mathematical_Models_of_Language_Change.html">61 acl-2010-Combining Data and Mathematical Models of Language Change</a></p>
<p>20 0.056011442 <a title="239-tfidf-20" href="./acl-2010-Bootstrapping_Semantic_Analyzers_from_Non-Contradictory_Texts.html">55 acl-2010-Bootstrapping Semantic Analyzers from Non-Contradictory Texts</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.128), (1, 0.088), (2, -0.069), (3, -0.235), (4, -0.058), (5, -0.271), (6, -0.201), (7, 0.083), (8, -0.037), (9, 0.015), (10, 0.034), (11, -0.093), (12, 0.032), (13, 0.015), (14, 0.019), (15, -0.133), (16, 0.074), (17, 0.058), (18, -0.076), (19, -0.054), (20, -0.025), (21, 0.004), (22, -0.055), (23, 0.045), (24, 0.015), (25, 0.016), (26, -0.038), (27, -0.03), (28, 0.015), (29, -0.073), (30, 0.049), (31, 0.023), (32, 0.041), (33, 0.063), (34, -0.009), (35, 0.005), (36, -0.067), (37, -0.04), (38, -0.023), (39, 0.077), (40, 0.019), (41, -0.095), (42, -0.057), (43, 0.019), (44, 0.12), (45, 0.013), (46, -0.013), (47, -0.016), (48, 0.039), (49, -0.049)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98411423 <a title="239-lsi-1" href="./acl-2010-Towards_Relational_POMDPs_for_Adaptive_Dialogue_Management.html">239 acl-2010-Towards Relational POMDPs for Adaptive Dialogue Management</a></p>
<p>Author: Pierre Lison</p><p>Abstract: Open-ended spoken interactions are typically characterised by both structural complexity and high levels of uncertainty, making dialogue management in such settings a particularly challenging problem. Traditional approaches have focused on providing theoretical accounts for either the uncertainty or the complexity of spoken dialogue, but rarely considered the two issues simultaneously. This paper describes ongoing work on a new approach to dialogue management which attempts to fill this gap. We represent the interaction as a Partially Observable Markov Decision Process (POMDP) over a rich state space incorporating both dialogue, user, and environment models. The tractability of the resulting POMDP can be preserved using a mechanism for dynamically constraining the action space based on prior knowledge over locally relevant dialogue structures. These constraints are encoded in a small set of general rules expressed as a Markov Logic network. The first-order expressivity of Markov Logic enables us to leverage the rich relational structure of the problem and efficiently abstract over large regions ofthe state and action spaces.</p><p>2 0.81974149 <a title="239-lsi-2" href="./acl-2010-Importance-Driven_Turn-Bidding_for_Spoken_Dialogue_Systems.html">142 acl-2010-Importance-Driven Turn-Bidding for Spoken Dialogue Systems</a></p>
<p>Author: Ethan Selfridge ; Peter Heeman</p><p>Abstract: Current turn-taking approaches for spoken dialogue systems rely on the speaker releasing the turn before the other can take it. This reliance results in restricted interactions that can lead to inefficient dialogues. In this paper we present a model we refer to as Importance-Driven Turn-Bidding that treats turn-taking as a negotiative process. Each conversant bids for the turn based on the importance of the intended utterance, and Reinforcement Learning is used to indirectly learn this parameter. We find that Importance-Driven Turn-Bidding performs better than two current turntaking approaches in an artificial collaborative slot-filling domain. The negotiative nature of this model creates efficient dia- logues, and supports the improvement of mixed-initiative interaction.</p><p>3 0.79472786 <a title="239-lsi-3" href="./acl-2010-Now%2C_Where_Was_I%3F_Resumption_Strategies_for_an_In-Vehicle_Dialogue_System.html">179 acl-2010-Now, Where Was I? Resumption Strategies for an In-Vehicle Dialogue System</a></p>
<p>Author: Jessica Villing</p><p>Abstract: In-vehicle dialogue systems often contain more than one application, e.g. a navigation and a telephone application. This means that the user might, for example, interrupt the interaction with the telephone application to ask for directions from the navigation application, and then resume the dialogue with the telephone application. In this paper we present an analysis of interruption and resumption behaviour in human-human in-vehicle dialogues and also propose some implications for resumption strategies in an in-vehicle dialogue system.</p><p>4 0.79281104 <a title="239-lsi-4" href="./acl-2010-Non-Cooperation_in_Dialogue.html">178 acl-2010-Non-Cooperation in Dialogue</a></p>
<p>Author: Brian Pluss</p><p>Abstract: This paper presents ongoing research on computational models for non-cooperative dialogue. We start by analysing different levels of cooperation in conversation. Then, inspired by findings from an empirical study, we propose a technique for measuring non-cooperation in political interviews. Finally, we describe a research programme towards obtaining a suitable model and discuss previous accounts for conflictive dialogue, identifying the differences with our work.</p><p>5 0.72858614 <a title="239-lsi-5" href="./acl-2010-Optimising_Information_Presentation_for_Spoken_Dialogue_Systems.html">187 acl-2010-Optimising Information Presentation for Spoken Dialogue Systems</a></p>
<p>Author: Verena Rieser ; Oliver Lemon ; Xingkun Liu</p><p>Abstract: We present a novel approach to Information Presentation (IP) in Spoken Dialogue Systems (SDS) using a data-driven statistical optimisation framework for content planning and attribute selection. First we collect data in a Wizard-of-Oz (WoZ) experiment and use it to build a supervised model of human behaviour. This forms a baseline for measuring the performance of optimised policies, developed from this data using Reinforcement Learning (RL) methods. We show that the optimised policies significantly outperform the baselines in a variety of generation scenarios: while the supervised model is able to attain up to 87.6% of the possible reward on this task, the RL policies are significantly better in 5 out of 6 scenarios, gaining up to 91.5% of the total possible reward. The RL policies perform especially well in more complex scenarios. We are also the first to show that adding predictive “lower level” features (e.g. from the NLG realiser) is important for optimising IP strategies according to user preferences. This provides new insights into the nature of the IP problem for SDS.</p><p>6 0.71012211 <a title="239-lsi-6" href="./acl-2010-Learning_to_Adapt_to_Unknown_Users%3A_Referring_Expression_Generation_in_Spoken_Dialogue_Systems.html">167 acl-2010-Learning to Adapt to Unknown Users: Referring Expression Generation in Spoken Dialogue Systems</a></p>
<p>7 0.6871137 <a title="239-lsi-7" href="./acl-2010-Demonstration_of_a_Prototype_for_a_Conversational_Companion_for_Reminiscing_about_Images.html">82 acl-2010-Demonstration of a Prototype for a Conversational Companion for Reminiscing about Images</a></p>
<p>8 0.68038827 <a title="239-lsi-8" href="./acl-2010-Phrase-Based_Statistical_Language_Generation_Using_Graphical_Models_and_Active_Learning.html">194 acl-2010-Phrase-Based Statistical Language Generation Using Graphical Models and Active Learning</a></p>
<p>9 0.62133253 <a title="239-lsi-9" href="./acl-2010-Decision_Detection_Using_Hierarchical_Graphical_Models.html">81 acl-2010-Decision Detection Using Hierarchical Graphical Models</a></p>
<p>10 0.54124969 <a title="239-lsi-10" href="./acl-2010-Classification_of_Feedback_Expressions_in_Multimodal_Data.html">58 acl-2010-Classification of Feedback Expressions in Multimodal Data</a></p>
<p>11 0.50687683 <a title="239-lsi-11" href="./acl-2010-Reading_between_the_Lines%3A_Learning_to_Map_High-Level_Instructions_to_Commands.html">202 acl-2010-Reading between the Lines: Learning to Map High-Level Instructions to Commands</a></p>
<p>12 0.48150524 <a title="239-lsi-12" href="./acl-2010-Modeling_Norms_of_Turn-Taking_in_Multi-Party_Conversation.html">173 acl-2010-Modeling Norms of Turn-Taking in Multi-Party Conversation</a></p>
<p>13 0.46897069 <a title="239-lsi-13" href="./acl-2010-Talking_NPCs_in_a_Virtual_Game_World.html">224 acl-2010-Talking NPCs in a Virtual Game World</a></p>
<p>14 0.46343228 <a title="239-lsi-14" href="./acl-2010-Automated_Planning_for_Situated_Natural_Language_Generation.html">35 acl-2010-Automated Planning for Situated Natural Language Generation</a></p>
<p>15 0.45921829 <a title="239-lsi-15" href="./acl-2010-Learning_to_Follow_Navigational_Directions.html">168 acl-2010-Learning to Follow Navigational Directions</a></p>
<p>16 0.45809445 <a title="239-lsi-16" href="./acl-2010-Beetle_II%3A_A_System_for_Tutoring_and_Computational_Linguistics_Experimentation.html">47 acl-2010-Beetle II: A System for Tutoring and Computational Linguistics Experimentation</a></p>
<p>17 0.4031114 <a title="239-lsi-17" href="./acl-2010-Extracting_Social_Networks_from_Literary_Fiction.html">112 acl-2010-Extracting Social Networks from Literary Fiction</a></p>
<p>18 0.39983451 <a title="239-lsi-18" href="./acl-2010-The_Impact_of_Interpretation_Problems_on_Tutorial_Dialogue.html">227 acl-2010-The Impact of Interpretation Problems on Tutorial Dialogue</a></p>
<p>19 0.3300904 <a title="239-lsi-19" href="./acl-2010-Combining_Data_and_Mathematical_Models_of_Language_Change.html">61 acl-2010-Combining Data and Mathematical Models of Language Change</a></p>
<p>20 0.28126147 <a title="239-lsi-20" href="./acl-2010-Correcting_Errors_in_Speech_Recognition_with_Articulatory_Dynamics.html">74 acl-2010-Correcting Errors in Speech Recognition with Articulatory Dynamics</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.569), (25, 0.051), (42, 0.022), (59, 0.042), (73, 0.018), (74, 0.016), (78, 0.043), (83, 0.055), (84, 0.013), (98, 0.084)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91108572 <a title="239-lda-1" href="./acl-2010-Towards_Relational_POMDPs_for_Adaptive_Dialogue_Management.html">239 acl-2010-Towards Relational POMDPs for Adaptive Dialogue Management</a></p>
<p>Author: Pierre Lison</p><p>Abstract: Open-ended spoken interactions are typically characterised by both structural complexity and high levels of uncertainty, making dialogue management in such settings a particularly challenging problem. Traditional approaches have focused on providing theoretical accounts for either the uncertainty or the complexity of spoken dialogue, but rarely considered the two issues simultaneously. This paper describes ongoing work on a new approach to dialogue management which attempts to fill this gap. We represent the interaction as a Partially Observable Markov Decision Process (POMDP) over a rich state space incorporating both dialogue, user, and environment models. The tractability of the resulting POMDP can be preserved using a mechanism for dynamically constraining the action space based on prior knowledge over locally relevant dialogue structures. These constraints are encoded in a small set of general rules expressed as a Markov Logic network. The first-order expressivity of Markov Logic enables us to leverage the rich relational structure of the problem and efficiently abstract over large regions ofthe state and action spaces.</p><p>2 0.6864211 <a title="239-lda-2" href="./acl-2010-A_Tree_Transducer_Model_for_Synchronous_Tree-Adjoining_Grammars.html">21 acl-2010-A Tree Transducer Model for Synchronous Tree-Adjoining Grammars</a></p>
<p>Author: Andreas Maletti</p><p>Abstract: A characterization of the expressive power of synchronous tree-adjoining grammars (STAGs) in terms of tree transducers (or equivalently, synchronous tree substitution grammars) is developed. Essentially, a STAG corresponds to an extended tree transducer that uses explicit substitution in both the input and output. This characterization allows the easy integration of STAG into toolkits for extended tree transducers. Moreover, the applicability of the characterization to several representational and algorithmic problems is demonstrated.</p><p>3 0.65026236 <a title="239-lda-3" href="./acl-2010-Efficient_Third-Order_Dependency_Parsers.html">99 acl-2010-Efficient Third-Order Dependency Parsers</a></p>
<p>Author: Terry Koo ; Michael Collins</p><p>Abstract: We present algorithms for higher-order dependency parsing that are “third-order” in the sense that they can evaluate substructures containing three dependencies, and “efficient” in the sense that they require only O(n4) time. Importantly, our new parsers can utilize both sibling-style and grandchild-style interactions. We evaluate our parsers on the Penn Treebank and Prague Dependency Treebank, achieving unlabeled attachment scores of 93.04% and 87.38%, respectively.</p><p>4 0.53821421 <a title="239-lda-4" href="./acl-2010-Combining_Orthogonal_Monolingual_and_Multilingual_Sources_of_Evidence_for_All_Words_WSD.html">62 acl-2010-Combining Orthogonal Monolingual and Multilingual Sources of Evidence for All Words WSD</a></p>
<p>Author: Weiwei Guo ; Mona Diab</p><p>Abstract: Word Sense Disambiguation remains one ofthe most complex problems facing computational linguists to date. In this paper we present a system that combines evidence from a monolingual WSD system together with that from a multilingual WSD system to yield state of the art performance on standard All-Words data sets. The monolingual system is based on a modification ofthe graph based state ofthe art algorithm In-Degree. The multilingual system is an improvement over an AllWords unsupervised approach, SALAAM. SALAAM exploits multilingual evidence as a means of disambiguation. In this paper, we present modifications to both of the original approaches and then their combination. We finally report the highest results obtained to date on the SENSEVAL 2 standard data set using an unsupervised method, we achieve an overall F measure of 64.58 using a voting scheme.</p><p>5 0.37489212 <a title="239-lda-5" href="./acl-2010-Sparsity_in_Dependency_Grammar_Induction.html">214 acl-2010-Sparsity in Dependency Grammar Induction</a></p>
<p>Author: Jennifer Gillenwater ; Kuzman Ganchev ; Joao Graca ; Fernando Pereira ; Ben Taskar</p><p>Abstract: A strong inductive bias is essential in unsupervised grammar induction. We explore a particular sparsity bias in dependency grammars that encourages a small number of unique dependency types. Specifically, we investigate sparsity-inducing penalties on the posterior distributions of parent-child POS tag pairs in the posterior regularization (PR) framework of Graça et al. (2007). In ex- periments with 12 languages, we achieve substantial gains over the standard expectation maximization (EM) baseline, with average improvement in attachment accuracy of 6.3%. Further, our method outperforms models based on a standard Bayesian sparsity-inducing prior by an average of 4.9%. On English in particular, we show that our approach improves on several other state-of-the-art techniques.</p><p>6 0.366337 <a title="239-lda-6" href="./acl-2010-Reading_between_the_Lines%3A_Learning_to_Map_High-Level_Instructions_to_Commands.html">202 acl-2010-Reading between the Lines: Learning to Map High-Level Instructions to Commands</a></p>
<p>7 0.36512098 <a title="239-lda-7" href="./acl-2010-Dynamic_Programming_for_Linear-Time_Incremental_Parsing.html">93 acl-2010-Dynamic Programming for Linear-Time Incremental Parsing</a></p>
<p>8 0.3564221 <a title="239-lda-8" href="./acl-2010-Automated_Planning_for_Situated_Natural_Language_Generation.html">35 acl-2010-Automated Planning for Situated Natural Language Generation</a></p>
<p>9 0.32225108 <a title="239-lda-9" href="./acl-2010-Learning_to_Follow_Navigational_Directions.html">168 acl-2010-Learning to Follow Navigational Directions</a></p>
<p>10 0.30771223 <a title="239-lda-10" href="./acl-2010-Efficient_Inference_through_Cascades_of_Weighted_Tree_Transducers.html">95 acl-2010-Efficient Inference through Cascades of Weighted Tree Transducers</a></p>
<p>11 0.30184966 <a title="239-lda-11" href="./acl-2010-Optimising_Information_Presentation_for_Spoken_Dialogue_Systems.html">187 acl-2010-Optimising Information Presentation for Spoken Dialogue Systems</a></p>
<p>12 0.29923078 <a title="239-lda-12" href="./acl-2010-P10-5005_k2opt.pdf.html">190 acl-2010-P10-5005 k2opt.pdf</a></p>
<p>13 0.29741576 <a title="239-lda-13" href="./acl-2010-Importance-Driven_Turn-Bidding_for_Spoken_Dialogue_Systems.html">142 acl-2010-Importance-Driven Turn-Bidding for Spoken Dialogue Systems</a></p>
<p>14 0.29401845 <a title="239-lda-14" href="./acl-2010-Learning_to_Adapt_to_Unknown_Users%3A_Referring_Expression_Generation_in_Spoken_Dialogue_Systems.html">167 acl-2010-Learning to Adapt to Unknown Users: Referring Expression Generation in Spoken Dialogue Systems</a></p>
<p>15 0.29325479 <a title="239-lda-15" href="./acl-2010-Computing_Weakest_Readings.html">67 acl-2010-Computing Weakest Readings</a></p>
<p>16 0.29172397 <a title="239-lda-16" href="./acl-2010-Modeling_Norms_of_Turn-Taking_in_Multi-Party_Conversation.html">173 acl-2010-Modeling Norms of Turn-Taking in Multi-Party Conversation</a></p>
<p>17 0.28962803 <a title="239-lda-17" href="./acl-2010-Learning_Common_Grammar_from_Multilingual_Corpus.html">162 acl-2010-Learning Common Grammar from Multilingual Corpus</a></p>
<p>18 0.28759253 <a title="239-lda-18" href="./acl-2010-Decision_Detection_Using_Hierarchical_Graphical_Models.html">81 acl-2010-Decision Detection Using Hierarchical Graphical Models</a></p>
<p>19 0.28722298 <a title="239-lda-19" href="./acl-2010-Convolution_Kernel_over_Packed_Parse_Forest.html">71 acl-2010-Convolution Kernel over Packed Parse Forest</a></p>
<p>20 0.28715193 <a title="239-lda-20" href="./acl-2010-Simple%2C_Accurate_Parsing_with_an_All-Fragments_Grammar.html">211 acl-2010-Simple, Accurate Parsing with an All-Fragments Grammar</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
