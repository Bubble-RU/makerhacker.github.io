<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>138 acl-2010-Hunting for the Black Swan: Risk Mining from Text</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-138" href="#">acl2010-138</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>138 acl-2010-Hunting for the Black Swan: Risk Mining from Text</h1>
<br/><p>Source: <a title="acl-2010-138-pdf" href="http://aclweb.org/anthology//P/P10/P10-4010.pdf">pdf</a></p><p>Author: Jochen Leidner ; Frank Schilder</p><p>Abstract: In the business world, analyzing and dealing with risk permeates all decisions and actions. However, to date, risk identification, the first step in the risk management cycle, has always been a manual activity with little to no intelligent software tool support. In addition, although companies are required to list risks to their business in their annual SEC filings in the USA, these descriptions are often very highlevel and vague. In this paper, we introduce Risk Mining, which is the task of identifying a set of risks pertaining to a business area or entity. We argue that by combining Web mining and Information Extraction (IE) techniques, risks can be detected automatically before they materialize, thus providing valuable business intelligence. We describe a system that induces a risk taxonomy with concrete risks (e.g., interest rate changes) at its leaves and more abstract risks (e.g., financial risks) closer to its root node. The taxonomy is induced via a bootstrapping algorithms starting with a few seeds. The risk taxonomy is used by the system as input to a risk monitor that matches risk mentions in financial documents to the abstract risk types, thus bridging a lexical gap. Our system is able to automatically generate company specific “risk maps”, which we demonstrate for a corpus of earnings report conference calls.</p><p>Reference: <a title="acl-2010-138-reference" href="../acl2010_reference/acl-2010-Hunting_for_the_Black_Swan%3A_Risk_Mining_from_Text_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 com  Abstract In the business world, analyzing and dealing with risk permeates all decisions and actions. [sent-5, score-0.694]
</p><p>2 However, to date, risk identification, the first step in the risk management cycle, has always been a manual activity with little to no intelligent software tool support. [sent-6, score-1.294]
</p><p>3 In addition, although companies are required to list risks to their business in their annual SEC filings in the USA, these descriptions are often very highlevel and vague. [sent-7, score-0.728]
</p><p>4 In this paper, we introduce Risk Mining, which is the task of identifying a set of risks pertaining to a business area or entity. [sent-8, score-0.617]
</p><p>5 We argue that by combining Web mining and Information Extraction (IE) techniques, risks can be detected automatically before they materialize, thus providing valuable business intelligence. [sent-9, score-0.658]
</p><p>6 We describe a system that induces a risk taxonomy with concrete risks (e. [sent-10, score-1.347]
</p><p>7 , interest rate changes) at its leaves and more abstract risks (e. [sent-12, score-0.57]
</p><p>8 The taxonomy is induced via a bootstrapping algorithms starting with a few seeds. [sent-15, score-0.105]
</p><p>9 The risk taxonomy is used by the system as input to a risk monitor that matches risk mentions in  financial documents to the abstract risk types, thus bridging a lexical gap. [sent-16, score-2.887]
</p><p>10 Our system is able to automatically generate company specific “risk maps”, which we demonstrate for a corpus of earnings report conference calls. [sent-17, score-0.161]
</p><p>11 In business, companies are exposed to market risks such as new competitors, disruptive technologies, change in customer attitudes, or a changes in government legislation that can dramatically affect their profitability or threaten their business model or mode of operation. [sent-19, score-0.708]
</p><p>12 Therefore, any tool to assist in the elicitation of otherwise unforeseen risk factors carries tremendous potential value. [sent-20, score-0.663]
</p><p>13 Nassim Nicholas Taleb calls these “black swans” (Taleb, 2007). [sent-22, score-0.032]
</p><p>14 Companies in the US are required to disclose a list of potential risks in their annual Form 10-K SEC fillings in order to warn (potential) investors, and risks are frequently the topic of conference phone calls about a company’s earnings. [sent-23, score-1.172]
</p><p>15 These risks are often reported in general terms, in particular, because it is quite difficult to pinpoint the unknown unknown, i. [sent-24, score-0.603]
</p><p>16 what kind of risk is concretely going to materialize. [sent-26, score-0.647]
</p><p>17 On the other hand, there is a stream of valuable evidence available on the Web, such as news messages, blog entries, and analysts’ reports talking about companies’ performance and products. [sent-27, score-0.084]
</p><p>18 Financial analysts and risk officers in large companies have not enjoyed any text analytics support so far, and risk lists devised using questionnaires or interviews are unlikely to be exhaustive due to small sample size, a gap which we aim to address in this paper. [sent-28, score-1.38]
</p><p>19 To this end, we propose to use a combination of Web Mining (WM) and Information Eextraction (IE) to assist humans interested in risk (with respect to an organization) and to bridge the gap between the general language and concrete risks. [sent-29, score-0.688]
</p><p>20 We describe our system, which is divided in two main parts: (a) an offline Risk Miner that facilitates the risk identification step ofthe risk management process, and an online (b) Risk Monitor that supports the risk monitoring step (cf. [sent-30, score-1.996]
</p><p>21 In addition, a Risk Mapper can aggregate and visualize the evidence in the form of a risk map. [sent-32, score-0.647]
</p><p>22 Our risk mining algorithm combines Riloff hyponym patterns with recursive Web pattern bootstrapping and a graph representation. [sent-33, score-0.78]
</p><p>23 We do not know of any other implemented endto-end system for computer-assisted risk identification/visualization using text mining technology. [sent-34, score-0.688]
</p><p>24 IE systems have been applied to the  financial domain on Message Understanding Contest (MUC) like tasks, ranging from named entity tagging to slot filling in templates (Costantino, 1992). [sent-38, score-0.133]
</p><p>25 , 2008), which was designed to extract hyponymy, but they did so at the expense of recall, using longer dual anchored patterns and a pattern linkage graph. [sent-45, score-0.126]
</p><p>26 Also, they create a set of pairs, whereas our approach creates a taxonomy tree as output. [sent-52, score-0.105]
</p><p>27 Most importantly though, our approach is not driven by frequency, and was instead designed to work especially with rare occurrences in mind to permit “black swan”-type risk discovery. [sent-53, score-0.647]
</p><p>28 , 2009) study the correlation between share price volatility, a proxy for risk, and a set of trigger words occurring in 60,000 SEC 10-K filings from 1995-2006. [sent-56, score-0.072]
</p><p>29 Since the disclosure of a company’s risks is mandatory by law, SEC reports provide a rich source. [sent-57, score-0.605]
</p><p>30 Their trigger words are selected a priori by humans; in contrast, risk mining as exercised in this paper aims to find risk-indicative words and phrases automatically. [sent-58, score-0.721]
</p><p>31 Kogan and colleagues attempt to find a regression model using very simple unigram features  based on whole documents that predicts volatility, whereas our goal is to automatically extract patterns to be used as alerts. [sent-59, score-0.056]
</p><p>32 , 2004) found that sub-string matching of 14 pre-defined string literals outperforms an SVM classifier using bag-of-words features in the task of speculative language detection in medical abstracts. [sent-63, score-0.042]
</p><p>33 They use a bi-partite graph-based approach, where one kind of node (content node) represents things people wish for (“world peace”) and the other kind of node (template nodes) represent templates that extract them (e. [sent-66, score-0.069]
</p><p>34 3  Data  We apply the mined risk extraction patterns to a corpus of financial documents. [sent-70, score-0.803]
</p><p>35 In particular, we are dealing with 170k earning calls transcripts, a text type that contains monologue (company executives reporting about their company’s performance and general situation) as well as dialogue (in the form of questions and answers at the end of each conference call). [sent-72, score-0.073]
</p><p>36 Participants typically include select business analysts from investment banks, and the calls are published afterwards for the shareholders’ benefits. [sent-73, score-0.112]
</p><p>37 We randomly took a sample of N=6,185 transcripts to use them in our risk alerting experiments. [sent-75, score-0.704]
</p><p>38 For demonstration purposes, we add a (c) Risk Mapper, a visualization component. [sent-79, score-0.026]
</p><p>39 We describe how a variety ofrisks can be identified given a normally very high-level description of risks, as one can find in earnings reports, other finan-  cial news, or the risk section of 10-K SEC filings. [sent-80, score-0.73]
</p><p>40 Also, the three Lewisburg area warehouses will be consolidated as we assess the logistical needs of the casegood group’s existing warehouse operations at an appropriate time in the future to minimize any disruption of service to our customers. [sent-83, score-0.041]
</p><p>41 This will result in the loss of 425 jobs or approximately 15% of the casegood group’s current employee base. [sent-84, score-0.041]
</p><p>42 Idon’t know the net equipment sales number last quarter and this quarter. [sent-86, score-0.072]
</p><p>43 But it sounded like from your comments that if you exclude these fees, that equipment sales were probably flattish. [sent-87, score-0.054]
</p><p>44 CEO: We’re not breaking out the origination fee from the equipment fee, but Ithink in total, Iwould say flattish to slightly up. [sent-89, score-0.063]
</p><p>45 Figure 1: Example sentences from the earnings conference call dataset. [sent-90, score-0.083]
</p><p>46 ;  and eventually more concrete, candidates, and relate them to risk types via a transitive chain of binary IS-A relations. [sent-93, score-0.647]
</p><p>47 Contrary to the related work, we use a base NP chunker and download the full pages returned by the search engine rather than search snippets in order to be able to extract risk phrases rather than just terms, which reduces contextual ambiguity and thus increases overall precision. [sent-94, score-0.691]
</p><p>48 The taxonomy learning method described in  the following subsection determines a risk taxonomy and new risks patterns. [sent-95, score-1.427]
</p><p>49 architecture The second part of the system, the Risk Monitor, takes the risks from the risk taxonomy and uses them for monitoring financial text streams such as news, SEC filings, or (in our use case) earnings reports. [sent-96, score-1.55]
</p><p>50 Using this, an analyst is then able to identify concrete risks in news messages and link them to the high-level risk descriptions. [sent-97, score-1.288]
</p><p>51 He or she may want to identify operational risks such as fraud for a particular company, for instance. [sent-98, score-0.634]
</p><p>52 The risk taxonomy can also derive further risks in this category (e. [sent-99, score-1.322]
</p><p>53 Iceland) can be directly linked to the risk as stated in earnings reports or security filings. [sent-106, score-0.765]
</p><p>54 2 Taxonomy induction method Using frequency to compute confidence in a pattern does not work for risk mining, however, because mention of particular risks might be rare. [sent-110, score-1.269]
</p><p>55 Instead of frequency based indicators (n-grams, frequency weights), we rely on two types of structural confidence validation, namely (a) previously identified risks and (b) previously acquired structural patterns. [sent-111, score-0.57]
</p><p>56 Note, however, that we can still use PageRank, a popularity-based graph algorithm, because multiple patterns might be connected to a risk term or phrase, even in the absence of frequency counts for each (i. [sent-112, score-0.734]
</p><p>57 The first step is used to extract a list of risks based on high precision patterns. [sent-117, score-0.586]
</p><p>58 However, it has been shown that the use of such patterns (e. [sent-118, score-0.04]
</p><p>59 Ideally, we want  to retrieve specific risks by re-applying the the extract risk descriptions: 2http : / /www . [sent-121, score-1.233]
</p><p>60 (a) Take a seed, instantiate " < SEED > such as * " pattern with seed, extract candidates: Input: risks Method: apply pattern " < SEED > such as < INSTANCE > ", where < SEED > = risks  Outpnuetn:ts l)ist of instances (e. [sent-124, score-1.26]
</p><p>61 , faulty compo(b) For each candidate from the list of instances, we find a set of additional candidate hyponyms. [sent-126, score-0.108]
</p><p>62 Input: faulty components Method: apply pattern " < SEED > such as < INSTANCE > ", where < SEED > = faulty components Output: list of instances (e. [sent-127, score-0.188]
</p><p>63 Since the Risk Candidate extraction step will also find many false positives, we need to factor in information that validates that the extracted risk is indeed a risk. [sent-131, score-0.647]
</p><p>64 We do this by constructing a possible pattern containing this new risk. [sent-132, score-0.052]
</p><p>65 (a) Append " * risks " to the output of 1(b) in order to make sure that the candidate occurs in a risk context. [sent-133, score-1.237]
</p><p>66 Input: brake(s) Pattern: "brake ( s ) * risk ( s ) " Output: a list of patterns (e. [sent-134, score-0.687]
</p><p>67 We have now reached the point where we constructed a graph with risks and patterns. [sent-139, score-0.57]
</p><p>68 Risks are connected via IS-A links; risks and patterns are connected via PATTERN links. [sent-140, score-0.67]
</p><p>69 Note that there are links from risks to patterns and from patterns to risks; some risks back-pointed by a pattern may actually not be a risk (e. [sent-141, score-1.919]
</p><p>70 However, this node is also not connected to a more abstract risk node and will therefore have a low PageRank score. [sent-144, score-0.713]
</p><p>71 Risks that are connected to patterns that have a high authority (i. [sent-145, score-0.07]
</p><p>72 The risk black Swan, for example, has only one pattern it occurs in, but this pattern can be filled by many other risks (e. [sent-148, score-1.36]
</p><p>73 Hence, the PageRank score of the black swan is high similar to well known risks, such as fraud. [sent-151, score-0.107]
</p><p>74 3 Risk alerting method We compile the risk taxonomy into a trie automaton, and create a second trie for company names from the meta-data of our corpus. [sent-153, score-0.953]
</p><p>75 The Risk Monitor reads the two tries and uses the first to detect mentions of risks in the earning reports and the second one to tag company names, both using case-insensitive matching for better recall. [sent-154, score-0.741]
</p><p>76 Optionally, we can use Porter stemming during trie construction and matching to trade precision for even higher recall, but in the experiments reported here this is not used. [sent-155, score-0.041]
</p><p>77 count for this hcompany; risk typei tuple, which we use foorr t graphic rendering purposes. [sent-157, score-0.647]
</p><p>78 The second option also permits the user to explore the detected risk mentions per company and by risk type. [sent-160, score-1.389]
</p><p>79 5  Results  From the Web mining process, we obtain a set of pairs (Figure 4), from which the taxonomy is constructed. [sent-161, score-0.146]
</p><p>80 In one run with only 12 seeds (just the risk type names with variants), we obtained a taxonomy with 280 validated leave nodes that are connected transitively to the risks root node. [sent-162, score-1.392]
</p><p>81 Our resulting system produces visualizations we call “risk maps”, because they graphically present the extracted risk types in aggregated form. [sent-163, score-0.647]
</p><p>82 A set of risk types can be selected for presentation as well as a set of companies of interest. [sent-164, score-0.7]
</p><p>83 A risk map display is then generated using either R (Figure 5) or an interactive Web page, depending on the user’s preference. [sent-165, score-0.647]
</p><p>84 We inspected the output of the risk miner and observed the follow-  Figure 5: An Example Risk Map. [sent-167, score-0.715]
</p><p>85 ing classes of issues: (a) chunker errors: if phrasal boundaries are placed at the wrong position, the taxonomy will include wrong relations. [sent-168, score-0.133]
</p><p>86 that I -A indi re ct ris k s) beS fore we introduced a stop word filter that discards candidate tuples that contain no content words. [sent-171, score-0.261]
</p><p>87 Another prominent example is “short term” instead of the correct “short term risk”; (b) semantic drift3 : due to polysemy, words and phrases  can denote risk and non-risk meanings, depending on context. [sent-172, score-0.664]
</p><p>88 is cash flow primarily an operational risk or a financial risk? [sent-179, score-0.8]
</p><p>89 We also found that some classes contain more noise than others, for example operational risk was less precise than financial risk, probably due to the lesser specificity of the former risk type. [sent-187, score-1.447]
</p><p>90 In this paper, we introduced the task ofrisk mining, which produces patterns that are useful in another task, risk alerting. [sent-189, score-0.687]
</p><p>91 Both tasks provide com-  putational assistance to risk-related decision making in the financial sector. [sent-190, score-0.116]
</p><p>92 We described a specialpurpose algorithm for inducing a risk taxonomy offline, which can then be used online to analyze earning reports in order to signal risks. [sent-191, score-0.828]
</p><p>93 how to match up terms and phrases in financial news prose with the more abstract language typically used in talking about risk in general. [sent-194, score-0.812]
</p><p>94 We have described an implemented demonstrator system comprising an offline risk taxonomy miner, an online risk alerter and a visualization component that creates visual risk maps by company and risk type, which we have applied to a corpus of earnings call transcripts. [sent-195, score-2.924]
</p><p>95 Extracted negative and also positive risks can be used in many applications, ranging from e-mail alerts to determinating credit ratings. [sent-197, score-0.62]
</p><p>96 Our preliminary work on risk maps can be  put on a more theoretical footing (Hunter, 2000). [sent-198, score-0.665]
</p><p>97 After studying further how output of risk alerting  correlates4  with non-textual signals like share  price, risk detection signals could inform human or trading decisions. [sent-199, score-1.365]
</p><p>98 4Our hypothesis is that risk patterns can outperform bag of words (Kogan et al. [sent-203, score-0.687]
</p><p>99 May all your wishes come true: A study of wishes and how to recognize them. [sent-227, score-0.088]
</p><p>100 Semantic class learning from the web with hyponym pattern linkage graphs. [sent-247, score-0.114]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('risk', 0.647), ('risks', 0.57), ('ris', 0.241), ('ks', 0.144), ('financial', 0.116), ('taxonomy', 0.105), ('earnings', 0.083), ('company', 0.078), ('faulty', 0.068), ('miner', 0.068), ('swan', 0.068), ('monitor', 0.061), ('kogan', 0.054), ('companies', 0.053), ('pattern', 0.052), ('sec', 0.048), ('business', 0.047), ('web', 0.044), ('wishes', 0.044), ('pagerank', 0.042), ('cal', 0.042), ('mining', 0.041), ('alerting', 0.041), ('casegood', 0.041), ('earning', 0.041), ('filings', 0.041), ('financi', 0.041), ('trie', 0.041), ('volatility', 0.041), ('patterns', 0.04), ('black', 0.039), ('market', 0.038), ('operational', 0.037), ('legal', 0.037), ('ional', 0.036), ('mapper', 0.036), ('brake', 0.036), ('equipment', 0.036), ('operat', 0.036), ('reports', 0.035), ('seed', 0.034), ('unknown', 0.033), ('analysts', 0.033), ('calls', 0.032), ('connected', 0.03), ('monitoring', 0.029), ('al', 0.028), ('chunker', 0.028), ('thomson', 0.028), ('alerts', 0.027), ('bryan', 0.027), ('envi', 0.027), ('fee', 0.027), ('fraud', 0.027), ('lewisburg', 0.027), ('nassim', 0.027), ('ronment', 0.027), ('starmine', 0.027), ('streetevents', 0.027), ('taleb', 0.027), ('reuters', 0.026), ('visualization', 0.026), ('offline', 0.026), ('talking', 0.025), ('concrete', 0.025), ('news', 0.024), ('saeger', 0.024), ('transitively', 0.024), ('speculative', 0.024), ('credit', 0.023), ('analyst', 0.022), ('candidate', 0.02), ('pennsylvania', 0.02), ('sales', 0.018), ('kozareva', 0.018), ('craig', 0.018), ('rat', 0.018), ('quarter', 0.018), ('light', 0.018), ('node', 0.018), ('maps', 0.018), ('linkage', 0.018), ('priori', 0.018), ('medical', 0.018), ('mentions', 0.017), ('templates', 0.017), ('dis', 0.017), ('descriptions', 0.017), ('term', 0.017), ('price', 0.016), ('house', 0.016), ('nicholas', 0.016), ('transcripts', 0.016), ('ceo', 0.016), ('extract', 0.016), ('assist', 0.016), ('validated', 0.016), ('ie', 0.016), ('signals', 0.015), ('trigger', 0.015)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999869 <a title="138-tfidf-1" href="./acl-2010-Hunting_for_the_Black_Swan%3A_Risk_Mining_from_Text.html">138 acl-2010-Hunting for the Black Swan: Risk Mining from Text</a></p>
<p>Author: Jochen Leidner ; Frank Schilder</p><p>Abstract: In the business world, analyzing and dealing with risk permeates all decisions and actions. However, to date, risk identification, the first step in the risk management cycle, has always been a manual activity with little to no intelligent software tool support. In addition, although companies are required to list risks to their business in their annual SEC filings in the USA, these descriptions are often very highlevel and vague. In this paper, we introduce Risk Mining, which is the task of identifying a set of risks pertaining to a business area or entity. We argue that by combining Web mining and Information Extraction (IE) techniques, risks can be detected automatically before they materialize, thus providing valuable business intelligence. We describe a system that induces a risk taxonomy with concrete risks (e.g., interest rate changes) at its leaves and more abstract risks (e.g., financial risks) closer to its root node. The taxonomy is induced via a bootstrapping algorithms starting with a few seeds. The risk taxonomy is used by the system as input to a risk monitor that matches risk mentions in financial documents to the abstract risk types, thus bridging a lexical gap. Our system is able to automatically generate company specific “risk maps”, which we demonstrate for a corpus of earnings report conference calls.</p><p>2 0.098190956 <a title="138-tfidf-2" href="./acl-2010-A_Risk_Minimization_Framework_for_Extractive_Speech_Summarization.html">14 acl-2010-A Risk Minimization Framework for Extractive Speech Summarization</a></p>
<p>Author: Shih-Hsiang Lin ; Berlin Chen</p><p>Abstract: In this paper, we formulate extractive summarization as a risk minimization problem and propose a unified probabilistic framework that naturally combines supervised and unsupervised summarization models to inherit their individual merits as well as to overcome their inherent limitations. In addition, the introduction of various loss functions also provides the summarization framework with a flexible but systematic way to render the redundancy and coherence relationships among sentences and between sentences and the whole document, respectively. Experiments on speech summarization show that the methods deduced from our framework are very competitive with existing summarization approaches. 1</p><p>3 0.079812184 <a title="138-tfidf-3" href="./acl-2010-Automatically_Generating_Term_Frequency_Induced_Taxonomies.html">43 acl-2010-Automatically Generating Term Frequency Induced Taxonomies</a></p>
<p>Author: Karin Murthy ; Tanveer A Faruquie ; L Venkata Subramaniam ; Hima Prasad K ; Mukesh Mohania</p><p>Abstract: We propose a novel method to automatically acquire a term-frequency-based taxonomy from a corpus using an unsupervised method. A term-frequency-based taxonomy is useful for application domains where the frequency with which terms occur on their own and in combination with other terms imposes a natural term hierarchy. We highlight an application for our approach and demonstrate its effectiveness and robustness in extracting knowledge from real-world data.</p><p>4 0.046845179 <a title="138-tfidf-4" href="./acl-2010-On_Learning_Subtypes_of_the_Part-Whole_Relation%3A_Do_Not_Mix_Your_Seeds.html">181 acl-2010-On Learning Subtypes of the Part-Whole Relation: Do Not Mix Your Seeds</a></p>
<p>Author: Ashwin Ittoo ; Gosse Bouma</p><p>Abstract: An important relation in information extraction is the part-whole relation. Ontological studies mention several types of this relation. In this paper, we show that the traditional practice of initializing minimally-supervised algorithms with a single set that mixes seeds of different types fails to capture the wide variety of part-whole patterns and tuples. The results obtained with mixed seeds ultimately converge to one of the part-whole relation types. We also demonstrate that all the different types of part-whole relations can still be discovered, regardless of the type characterized by the initializing seeds. We performed our experiments with a state-ofthe-art information extraction algorithm. 1</p><p>5 0.04653284 <a title="138-tfidf-5" href="./acl-2010-Learning_Arguments_and_Supertypes_of_Semantic_Relations_Using_Recursive_Patterns.html">160 acl-2010-Learning Arguments and Supertypes of Semantic Relations Using Recursive Patterns</a></p>
<p>Author: Zornitsa Kozareva ; Eduard Hovy</p><p>Abstract: A challenging problem in open information extraction and text mining is the learning of the selectional restrictions of semantic relations. We propose a minimally supervised bootstrapping algorithm that uses a single seed and a recursive lexico-syntactic pattern to learn the arguments and the supertypes of a diverse set of semantic relations from the Web. We evaluate the performance of our algorithm on multiple semantic relations expressed using “verb”, “noun”, and “verb prep” lexico-syntactic patterns. Humanbased evaluation shows that the accuracy of the harvested information is about 90%. We also compare our results with existing knowledge base to outline the similarities and differences of the granularity and diversity of the harvested knowledge.</p><p>6 0.045405842 <a title="138-tfidf-6" href="./acl-2010-Generating_Templates_of_Entity_Summaries_with_an_Entity-Aspect_Model_and_Pattern_Mining.html">125 acl-2010-Generating Templates of Entity Summaries with an Entity-Aspect Model and Pattern Mining</a></p>
<p>7 0.036514491 <a title="138-tfidf-7" href="./acl-2010-A_Taxonomy%2C_Dataset%2C_and_Classifier_for_Automatic_Noun_Compound_Interpretation.html">19 acl-2010-A Taxonomy, Dataset, and Classifier for Automatic Noun Compound Interpretation</a></p>
<p>8 0.035141215 <a title="138-tfidf-8" href="./acl-2010-Inducing_Domain-Specific_Semantic_Class_Taggers_from_%28Almost%29_Nothing.html">150 acl-2010-Inducing Domain-Specific Semantic Class Taggers from (Almost) Nothing</a></p>
<p>9 0.033040635 <a title="138-tfidf-9" href="./acl-2010-An_Active_Learning_Approach_to_Finding_Related_Terms.html">27 acl-2010-An Active Learning Approach to Finding Related Terms</a></p>
<p>10 0.031900849 <a title="138-tfidf-10" href="./acl-2010-Growing_Related_Words_from_Seed_via_User_Behaviors%3A_A_Re-Ranking_Based_Approach.html">129 acl-2010-Growing Related Words from Seed via User Behaviors: A Re-Ranking Based Approach</a></p>
<p>11 0.030877281 <a title="138-tfidf-11" href="./acl-2010-Towards_Open-Domain_Semantic_Role_Labeling.html">238 acl-2010-Towards Open-Domain Semantic Role Labeling</a></p>
<p>12 0.030821433 <a title="138-tfidf-12" href="./acl-2010-Weakly_Supervised_Learning_of_Presupposition_Relations_between_Verbs.html">258 acl-2010-Weakly Supervised Learning of Presupposition Relations between Verbs</a></p>
<p>13 0.030396629 <a title="138-tfidf-13" href="./acl-2010-Extraction_and_Approximation_of_Numerical_Attributes_from_the_Web.html">113 acl-2010-Extraction and Approximation of Numerical Attributes from the Web</a></p>
<p>14 0.030147037 <a title="138-tfidf-14" href="./acl-2010-Generating_Image_Descriptions_Using_Dependency_Relational_Patterns.html">124 acl-2010-Generating Image Descriptions Using Dependency Relational Patterns</a></p>
<p>15 0.028894598 <a title="138-tfidf-15" href="./acl-2010-Learning_Word-Class_Lattices_for_Definition_and_Hypernym_Extraction.html">166 acl-2010-Learning Word-Class Lattices for Definition and Hypernym Extraction</a></p>
<p>16 0.028040607 <a title="138-tfidf-16" href="./acl-2010-Hard_Constraints_for_Grammatical_Function_Labelling.html">130 acl-2010-Hard Constraints for Grammatical Function Labelling</a></p>
<p>17 0.027844653 <a title="138-tfidf-17" href="./acl-2010-Global_Learning_of_Focused_Entailment_Graphs.html">127 acl-2010-Global Learning of Focused Entailment Graphs</a></p>
<p>18 0.027028278 <a title="138-tfidf-18" href="./acl-2010-A_Latent_Dirichlet_Allocation_Method_for_Selectional_Preferences.html">10 acl-2010-A Latent Dirichlet Allocation Method for Selectional Preferences</a></p>
<p>19 0.027000004 <a title="138-tfidf-19" href="./acl-2010-Detecting_Experiences_from_Weblogs.html">85 acl-2010-Detecting Experiences from Weblogs</a></p>
<p>20 0.026545055 <a title="138-tfidf-20" href="./acl-2010-Recommendation_in_Internet_Forums_and_Blogs.html">204 acl-2010-Recommendation in Internet Forums and Blogs</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.086), (1, 0.039), (2, -0.026), (3, -0.019), (4, 0.011), (5, -0.016), (6, 0.004), (7, -0.025), (8, -0.015), (9, -0.027), (10, -0.014), (11, 0.015), (12, -0.033), (13, -0.054), (14, 0.043), (15, 0.047), (16, 0.026), (17, 0.032), (18, -0.02), (19, 0.011), (20, -0.003), (21, 0.019), (22, 0.003), (23, -0.007), (24, -0.042), (25, -0.027), (26, -0.078), (27, 0.069), (28, 0.023), (29, 0.036), (30, -0.026), (31, 0.06), (32, 0.042), (33, 0.0), (34, 0.03), (35, -0.062), (36, -0.048), (37, 0.068), (38, 0.022), (39, 0.082), (40, -0.041), (41, -0.035), (42, 0.088), (43, 0.07), (44, 0.058), (45, 0.047), (46, -0.051), (47, -0.039), (48, 0.064), (49, 0.06)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94794494 <a title="138-lsi-1" href="./acl-2010-Hunting_for_the_Black_Swan%3A_Risk_Mining_from_Text.html">138 acl-2010-Hunting for the Black Swan: Risk Mining from Text</a></p>
<p>Author: Jochen Leidner ; Frank Schilder</p><p>Abstract: In the business world, analyzing and dealing with risk permeates all decisions and actions. However, to date, risk identification, the first step in the risk management cycle, has always been a manual activity with little to no intelligent software tool support. In addition, although companies are required to list risks to their business in their annual SEC filings in the USA, these descriptions are often very highlevel and vague. In this paper, we introduce Risk Mining, which is the task of identifying a set of risks pertaining to a business area or entity. We argue that by combining Web mining and Information Extraction (IE) techniques, risks can be detected automatically before they materialize, thus providing valuable business intelligence. We describe a system that induces a risk taxonomy with concrete risks (e.g., interest rate changes) at its leaves and more abstract risks (e.g., financial risks) closer to its root node. The taxonomy is induced via a bootstrapping algorithms starting with a few seeds. The risk taxonomy is used by the system as input to a risk monitor that matches risk mentions in financial documents to the abstract risk types, thus bridging a lexical gap. Our system is able to automatically generate company specific “risk maps”, which we demonstrate for a corpus of earnings report conference calls.</p><p>2 0.74374658 <a title="138-lsi-2" href="./acl-2010-Automatically_Generating_Term_Frequency_Induced_Taxonomies.html">43 acl-2010-Automatically Generating Term Frequency Induced Taxonomies</a></p>
<p>Author: Karin Murthy ; Tanveer A Faruquie ; L Venkata Subramaniam ; Hima Prasad K ; Mukesh Mohania</p><p>Abstract: We propose a novel method to automatically acquire a term-frequency-based taxonomy from a corpus using an unsupervised method. A term-frequency-based taxonomy is useful for application domains where the frequency with which terms occur on their own and in combination with other terms imposes a natural term hierarchy. We highlight an application for our approach and demonstrate its effectiveness and robustness in extracting knowledge from real-world data.</p><p>3 0.69328409 <a title="138-lsi-3" href="./acl-2010-On_Learning_Subtypes_of_the_Part-Whole_Relation%3A_Do_Not_Mix_Your_Seeds.html">181 acl-2010-On Learning Subtypes of the Part-Whole Relation: Do Not Mix Your Seeds</a></p>
<p>Author: Ashwin Ittoo ; Gosse Bouma</p><p>Abstract: An important relation in information extraction is the part-whole relation. Ontological studies mention several types of this relation. In this paper, we show that the traditional practice of initializing minimally-supervised algorithms with a single set that mixes seeds of different types fails to capture the wide variety of part-whole patterns and tuples. The results obtained with mixed seeds ultimately converge to one of the part-whole relation types. We also demonstrate that all the different types of part-whole relations can still be discovered, regardless of the type characterized by the initializing seeds. We performed our experiments with a state-ofthe-art information extraction algorithm. 1</p><p>4 0.60056466 <a title="138-lsi-4" href="./acl-2010-Complexity_Assumptions_in_Ontology_Verbalisation.html">64 acl-2010-Complexity Assumptions in Ontology Verbalisation</a></p>
<p>Author: Richard Power</p><p>Abstract: We describe the strategy currently pursued for verbalising OWL ontologies by sentences in Controlled Natural Language (i.e., combining generic rules for realising logical patterns with ontology-specific lexicons for realising atomic terms for individuals, classes, and properties) and argue that its success depends on assumptions about the complexity of terms and axioms in the ontology. We then show, through analysis of a corpus of ontologies, that although these assumptions could in principle be violated, they are overwhelmingly respected in practice by ontology developers.</p><p>5 0.59085 <a title="138-lsi-5" href="./acl-2010-Learning_Arguments_and_Supertypes_of_Semantic_Relations_Using_Recursive_Patterns.html">160 acl-2010-Learning Arguments and Supertypes of Semantic Relations Using Recursive Patterns</a></p>
<p>Author: Zornitsa Kozareva ; Eduard Hovy</p><p>Abstract: A challenging problem in open information extraction and text mining is the learning of the selectional restrictions of semantic relations. We propose a minimally supervised bootstrapping algorithm that uses a single seed and a recursive lexico-syntactic pattern to learn the arguments and the supertypes of a diverse set of semantic relations from the Web. We evaluate the performance of our algorithm on multiple semantic relations expressed using “verb”, “noun”, and “verb prep” lexico-syntactic patterns. Humanbased evaluation shows that the accuracy of the harvested information is about 90%. We also compare our results with existing knowledge base to outline the similarities and differences of the granularity and diversity of the harvested knowledge.</p><p>6 0.55440623 <a title="138-lsi-6" href="./acl-2010-Learning_Word-Class_Lattices_for_Definition_and_Hypernym_Extraction.html">166 acl-2010-Learning Word-Class Lattices for Definition and Hypernym Extraction</a></p>
<p>7 0.49444959 <a title="138-lsi-7" href="./acl-2010-Combining_Data_and_Mathematical_Models_of_Language_Change.html">61 acl-2010-Combining Data and Mathematical Models of Language Change</a></p>
<p>8 0.47123507 <a title="138-lsi-8" href="./acl-2010-Don%27t_%27Have_a_Clue%27%3F_Unsupervised_Co-Learning_of_Downward-Entailing_Operators..html">92 acl-2010-Don't 'Have a Clue'? Unsupervised Co-Learning of Downward-Entailing Operators.</a></p>
<p>9 0.47076914 <a title="138-lsi-9" href="./acl-2010-How_Spoken_Language_Corpora_Can_Refine_Current_Speech_Motor_Training_Methodologies.html">137 acl-2010-How Spoken Language Corpora Can Refine Current Speech Motor Training Methodologies</a></p>
<p>10 0.44465005 <a title="138-lsi-10" href="./acl-2010-SystemT%3A_An_Algebraic_Approach_to_Declarative_Information_Extraction.html">222 acl-2010-SystemT: An Algebraic Approach to Declarative Information Extraction</a></p>
<p>11 0.43720651 <a title="138-lsi-11" href="./acl-2010-Talking_NPCs_in_a_Virtual_Game_World.html">224 acl-2010-Talking NPCs in a Virtual Game World</a></p>
<p>12 0.43409604 <a title="138-lsi-12" href="./acl-2010-A_Taxonomy%2C_Dataset%2C_and_Classifier_for_Automatic_Noun_Compound_Interpretation.html">19 acl-2010-A Taxonomy, Dataset, and Classifier for Automatic Noun Compound Interpretation</a></p>
<p>13 0.39431906 <a title="138-lsi-13" href="./acl-2010-Comparable_Entity_Mining_from_Comparative_Questions.html">63 acl-2010-Comparable Entity Mining from Comparative Questions</a></p>
<p>14 0.38747525 <a title="138-lsi-14" href="./acl-2010-Generating_Templates_of_Entity_Summaries_with_an_Entity-Aspect_Model_and_Pattern_Mining.html">125 acl-2010-Generating Templates of Entity Summaries with an Entity-Aspect Model and Pattern Mining</a></p>
<p>15 0.37301937 <a title="138-lsi-15" href="./acl-2010-Inducing_Domain-Specific_Semantic_Class_Taggers_from_%28Almost%29_Nothing.html">150 acl-2010-Inducing Domain-Specific Semantic Class Taggers from (Almost) Nothing</a></p>
<p>16 0.36701146 <a title="138-lsi-16" href="./acl-2010-Weakly_Supervised_Learning_of_Presupposition_Relations_between_Verbs.html">258 acl-2010-Weakly Supervised Learning of Presupposition Relations between Verbs</a></p>
<p>17 0.36521816 <a title="138-lsi-17" href="./acl-2010-Mood_Patterns_and_Affective_Lexicon_Access_in_Weblogs.html">176 acl-2010-Mood Patterns and Affective Lexicon Access in Weblogs</a></p>
<p>18 0.36450502 <a title="138-lsi-18" href="./acl-2010-Experiments_in_Graph-Based_Semi-Supervised_Learning_Methods_for_Class-Instance_Acquisition.html">109 acl-2010-Experiments in Graph-Based Semi-Supervised Learning Methods for Class-Instance Acquisition</a></p>
<p>19 0.36439157 <a title="138-lsi-19" href="./acl-2010-Tools_for_Multilingual_Grammar-Based_Translation_on_the_Web.html">235 acl-2010-Tools for Multilingual Grammar-Based Translation on the Web</a></p>
<p>20 0.36288923 <a title="138-lsi-20" href="./acl-2010-Demonstration_of_a_Prototype_for_a_Conversational_Companion_for_Reminiscing_about_Images.html">82 acl-2010-Demonstration of a Prototype for a Conversational Companion for Reminiscing about Images</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.012), (25, 0.054), (28, 0.014), (33, 0.01), (39, 0.012), (42, 0.041), (44, 0.016), (45, 0.331), (59, 0.063), (72, 0.021), (73, 0.055), (76, 0.02), (78, 0.034), (80, 0.023), (83, 0.071), (84, 0.036), (97, 0.01), (98, 0.074)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.79369277 <a title="138-lda-1" href="./acl-2010-Hunting_for_the_Black_Swan%3A_Risk_Mining_from_Text.html">138 acl-2010-Hunting for the Black Swan: Risk Mining from Text</a></p>
<p>Author: Jochen Leidner ; Frank Schilder</p><p>Abstract: In the business world, analyzing and dealing with risk permeates all decisions and actions. However, to date, risk identification, the first step in the risk management cycle, has always been a manual activity with little to no intelligent software tool support. In addition, although companies are required to list risks to their business in their annual SEC filings in the USA, these descriptions are often very highlevel and vague. In this paper, we introduce Risk Mining, which is the task of identifying a set of risks pertaining to a business area or entity. We argue that by combining Web mining and Information Extraction (IE) techniques, risks can be detected automatically before they materialize, thus providing valuable business intelligence. We describe a system that induces a risk taxonomy with concrete risks (e.g., interest rate changes) at its leaves and more abstract risks (e.g., financial risks) closer to its root node. The taxonomy is induced via a bootstrapping algorithms starting with a few seeds. The risk taxonomy is used by the system as input to a risk monitor that matches risk mentions in financial documents to the abstract risk types, thus bridging a lexical gap. Our system is able to automatically generate company specific “risk maps”, which we demonstrate for a corpus of earnings report conference calls.</p><p>2 0.70991492 <a title="138-lda-2" href="./acl-2010-Modeling_Norms_of_Turn-Taking_in_Multi-Party_Conversation.html">173 acl-2010-Modeling Norms of Turn-Taking in Multi-Party Conversation</a></p>
<p>Author: Kornel Laskowski</p><p>Abstract: Substantial research effort has been invested in recent decades into the computational study and automatic processing of multi-party conversation. While most aspects of conversational speech have benefited from a wide availability of analytic, computationally tractable techniques, only qualitative assessments are available for characterizing multi-party turn-taking. The current paper attempts to address this deficiency by first proposing a framework for computing turn-taking model perplexity, and then by evaluating several multi-participant modeling approaches. Experiments show that direct multi-participant models do not generalize to held out data, and likely never will, for practical reasons. In contrast, the Extended-Degree-of-Overlap model represents a suitable candidate for future work in this area, and is shown to successfully predict the distribution of speech in time and across participants in previously unseen conversations.</p><p>3 0.61529553 <a title="138-lda-3" href="./acl-2010-Enhanced_Word_Decomposition_by_Calibrating_the_Decision_Threshold_of_Probabilistic_Models_and_Using_a_Model_Ensemble.html">100 acl-2010-Enhanced Word Decomposition by Calibrating the Decision Threshold of Probabilistic Models and Using a Model Ensemble</a></p>
<p>Author: Sebastian Spiegler ; Peter A. Flach</p><p>Abstract: This paper demonstrates that the use of ensemble methods and carefully calibrating the decision threshold can significantly improve the performance of machine learning methods for morphological word decomposition. We employ two algorithms which come from a family of generative probabilistic models. The models consider segment boundaries as hidden variables and include probabilities for letter transitions within segments. The advantage of this model family is that it can learn from small datasets and easily gen- eralises to larger datasets. The first algorithm PROMODES, which participated in the Morpho Challenge 2009 (an international competition for unsupervised morphological analysis) employs a lower order model whereas the second algorithm PROMODES-H is a novel development of the first using a higher order model. We present the mathematical description for both algorithms, conduct experiments on the morphologically rich language Zulu and compare characteristics of both algorithms based on the experimental results.</p><p>4 0.411246 <a title="138-lda-4" href="./acl-2010-Using_Anaphora_Resolution_to_Improve_Opinion_Target_Identification_in_Movie_Reviews.html">251 acl-2010-Using Anaphora Resolution to Improve Opinion Target Identification in Movie Reviews</a></p>
<p>Author: Niklas Jakob ; Iryna Gurevych</p><p>Abstract: unkown-abstract</p><p>5 0.40407413 <a title="138-lda-5" href="./acl-2010-The_S-Space_Package%3A_An_Open_Source_Package_for_Word_Space_Models.html">232 acl-2010-The S-Space Package: An Open Source Package for Word Space Models</a></p>
<p>Author: David Jurgens ; Keith Stevens</p><p>Abstract: We present the S-Space Package, an open source framework for developing and evaluating word space algorithms. The package implements well-known word space algorithms, such as LSA, and provides a comprehensive set of matrix utilities and data structures for extending new or existing models. The package also includes word space benchmarks for evaluation. Both algorithms and libraries are designed for high concurrency and scalability. We demonstrate the efficiency of the reference implementations and also provide their results on six benchmarks.</p><p>6 0.40384141 <a title="138-lda-6" href="./acl-2010-Simple%2C_Accurate_Parsing_with_an_All-Fragments_Grammar.html">211 acl-2010-Simple, Accurate Parsing with an All-Fragments Grammar</a></p>
<p>7 0.40128657 <a title="138-lda-7" href="./acl-2010-Latent_Variable_Models_of_Selectional_Preference.html">158 acl-2010-Latent Variable Models of Selectional Preference</a></p>
<p>8 0.40108982 <a title="138-lda-8" href="./acl-2010-Generating_Entailment_Rules_from_FrameNet.html">121 acl-2010-Generating Entailment Rules from FrameNet</a></p>
<p>9 0.40035805 <a title="138-lda-9" href="./acl-2010-Experiments_in_Graph-Based_Semi-Supervised_Learning_Methods_for_Class-Instance_Acquisition.html">109 acl-2010-Experiments in Graph-Based Semi-Supervised Learning Methods for Class-Instance Acquisition</a></p>
<p>10 0.40019453 <a title="138-lda-10" href="./acl-2010-Fully_Unsupervised_Core-Adjunct_Argument_Classification.html">120 acl-2010-Fully Unsupervised Core-Adjunct Argument Classification</a></p>
<p>11 0.4001779 <a title="138-lda-11" href="./acl-2010-Sentence_and_Expression_Level_Annotation_of_Opinions_in_User-Generated_Discourse.html">208 acl-2010-Sentence and Expression Level Annotation of Opinions in User-Generated Discourse</a></p>
<p>12 0.39955211 <a title="138-lda-12" href="./acl-2010-Hierarchical_Sequential_Learning_for_Extracting_Opinions_and_Their_Attributes.html">134 acl-2010-Hierarchical Sequential Learning for Extracting Opinions and Their Attributes</a></p>
<p>13 0.39920264 <a title="138-lda-13" href="./acl-2010-Entity-Based_Local_Coherence_Modelling_Using_Topological_Fields.html">101 acl-2010-Entity-Based Local Coherence Modelling Using Topological Fields</a></p>
<p>14 0.39720243 <a title="138-lda-14" href="./acl-2010-Unsupervised_Ontology_Induction_from_Text.html">248 acl-2010-Unsupervised Ontology Induction from Text</a></p>
<p>15 0.39703417 <a title="138-lda-15" href="./acl-2010-Grammar_Prototyping_and_Testing_with_the_LinGO_Grammar_Matrix_Customization_System.html">128 acl-2010-Grammar Prototyping and Testing with the LinGO Grammar Matrix Customization System</a></p>
<p>16 0.39672369 <a title="138-lda-16" href="./acl-2010-Assessing_the_Role_of_Discourse_References_in_Entailment_Inference.html">33 acl-2010-Assessing the Role of Discourse References in Entailment Inference</a></p>
<p>17 0.39618286 <a title="138-lda-17" href="./acl-2010-Convolution_Kernel_over_Packed_Parse_Forest.html">71 acl-2010-Convolution Kernel over Packed Parse Forest</a></p>
<p>18 0.39589286 <a title="138-lda-18" href="./acl-2010-Extraction_and_Approximation_of_Numerical_Attributes_from_the_Web.html">113 acl-2010-Extraction and Approximation of Numerical Attributes from the Web</a></p>
<p>19 0.39554626 <a title="138-lda-19" href="./acl-2010-Sparsity_in_Dependency_Grammar_Induction.html">214 acl-2010-Sparsity in Dependency Grammar Induction</a></p>
<p>20 0.39453027 <a title="138-lda-20" href="./acl-2010-Learning_Arguments_and_Supertypes_of_Semantic_Relations_Using_Recursive_Patterns.html">160 acl-2010-Learning Arguments and Supertypes of Semantic Relations Using Recursive Patterns</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
