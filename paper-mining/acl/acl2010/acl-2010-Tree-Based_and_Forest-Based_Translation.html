<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>243 acl-2010-Tree-Based and Forest-Based Translation</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-243" href="#">acl2010-243</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>243 acl-2010-Tree-Based and Forest-Based Translation</h1>
<br/><p>Source: <a title="acl-2010-243-pdf" href="http://aclweb.org/anthology//P/P10/P10-5002.pdf">pdf</a></p><p>Author: Yang Liu ; Liang Huang</p><p>Abstract: unkown-abstract</p><p>Reference: <a title="acl-2010-243-reference" href="../acl2010_reference/acl-2010-Tree-Based_and_Forest-Based_Translation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 cn ct 1 Introduction The past several years have witnessed rapid advances in syntax-based machine translation, which exploits natural language syntax to guide translation. [sent-3, score-0.329]
</p><p>2 Depending on the type of input, most ofthese efforts can be divided into two broad categories: (a) string-based systems whose input is a string, which is simultaneously parsed and translated by a synchronous grammar (Wu, 1997; Chiang, 2005; Galley et al. [sent-4, score-0.377]
</p><p>3 , 2006), and (b) tree-based systems whose input is already a parse tree to be directly converted into a target tree or string (Lin, 2004; Ding and Palmer, 2005; Quirk et al. [sent-5, score-0.421]
</p><p>4 Compared with their string-based counterparts, tree-based systems offer many attractive features:  they are much faster in decoding (linear time vs. [sent-9, score-0.656]
</p><p>5 cubic time), do not require sophisticated binarization (Zhang et al. [sent-10, score-0.207]
</p><p>6 , 2006), and can use separate grammars for parsing and translation (e. [sent-11, score-0.383]
</p><p>7 a context-free grammar for the former and a tree substitution grammar for the latter). [sent-13, score-0.344]
</p><p>8 However, despite these advantages, most treebased systems suffer from a major drawback: they only use 1-best parse trees to direct translation, which potentially introduces translation mistakes due to parsing errors (Quirk and Corston-Oliver, 2006). [sent-14, score-0.996]
</p><p>9 This situation becomes worse for resourcepoor source languages without enough Treebank data to train a high-accuracy parser. [sent-15, score-0.049]
</p><p>10 This problem can be alleviated elegantly by using packed forests (Huang, 2008), which encodes exponentially many parse trees in a polynomial space. [sent-16, score-1.059]
</p><p>11 , 2008; Mi and Huang, 2008) thus take a packed forest instead of a parse tree as an input. [sent-18, score-0.698]
</p><p>12 In addition, packed forests could also be used for translation rule extraction, which helps alleviate the propagation of parsing errors into rule set. [sent-19, score-1.305]
</p><p>13 Forest-based translation can be regarded as a compromise between the  string-based and tree-based methods, while com2 Liang Huang Information Sciences Institute University of Southern California lhuang@ i i s . [sent-20, score-0.435]
</p><p>14 edu bining the advantages of both: decoding is still fast, yet does not commit to a single parse. [sent-21, score-0.647]
</p><p>15 Surprisingly, translating a forest of millions of trees is even faster than translating 30 individual trees, and offers significantly better translation quality. [sent-22, score-1.078]
</p><p>16 2  Content Overview  This tutorial surveys tree-based and forest-based translation methods. [sent-24, score-0.465]
</p><p>17 For each approach, we will discuss the two fundamental tasks: decoding, which performs the actual translation, and rule extraction, which learns translation rules from realworld data automatically. [sent-25, score-0.603]
</p><p>18 Finally, we will in-  troduce some more recent developments to treebased and forest-based translation, such as tree sequence based models, tree-to-tree models, joint parsing and translation, and faster decoding algorithms. [sent-26, score-1.125]
</p><p>19 We will conclude our talk by pointing out some directions for future work. [sent-27, score-0.165]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('decoding', 0.355), ('packed', 0.316), ('translation', 0.301), ('treebased', 0.202), ('faster', 0.191), ('forest', 0.182), ('huang', 0.173), ('forests', 0.153), ('quirk', 0.133), ('rule', 0.116), ('elegantly', 0.11), ('lhuang', 0.11), ('yliu', 0.11), ('alleviated', 0.11), ('troduce', 0.11), ('bining', 0.11), ('tree', 0.106), ('tutorial', 0.105), ('advantages', 0.103), ('overview', 0.102), ('trees', 0.102), ('mi', 0.098), ('translating', 0.097), ('realworld', 0.095), ('parse', 0.094), ('asscolcia', 0.09), ('cgeom', 0.09), ('jtuulytor', 0.09), ('witnessed', 0.085), ('binarization', 0.085), ('parsing', 0.082), ('pra', 0.082), ('sciences', 0.08), ('developments', 0.079), ('motivations', 0.079), ('commit', 0.079), ('compromise', 0.076), ('cubic', 0.076), ('ofthese', 0.076), ('liu', 0.075), ('sweden', 0.074), ('mistakes', 0.072), ('southern', 0.072), ('drawback', 0.072), ('uppsala', 0.072), ('grammar', 0.071), ('pointing', 0.07), ('extraction', 0.069), ('propagation', 0.066), ('string', 0.066), ('attractive', 0.065), ('af', 0.065), ('academy', 0.065), ('exponentially', 0.065), ('alleviate', 0.063), ('rapid', 0.062), ('ding', 0.062), ('counterparts', 0.062), ('galley', 0.059), ('sc', 0.059), ('surveys', 0.059), ('regarded', 0.058), ('talk', 0.057), ('polynomial', 0.057), ('millions', 0.056), ('institute', 0.056), ('synchronous', 0.055), ('substitution', 0.055), ('offers', 0.052), ('encodes', 0.052), ('exploits', 0.052), ('suffer', 0.052), ('surprisingly', 0.051), ('chiang', 0.051), ('situation', 0.049), ('converted', 0.049), ('pruning', 0.049), ('errors', 0.049), ('efforts', 0.048), ('learns', 0.047), ('palmer', 0.046), ('sophisticated', 0.046), ('ct', 0.046), ('extensions', 0.046), ('offer', 0.045), ('california', 0.044), ('fundamental', 0.044), ('helps', 0.043), ('guide', 0.043), ('simultaneously', 0.043), ('liang', 0.043), ('broad', 0.042), ('introduces', 0.042), ('translated', 0.042), ('past', 0.041), ('former', 0.041), ('fo', 0.04), ('yang', 0.039), ('popular', 0.039), ('conclude', 0.038)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="243-tfidf-1" href="./acl-2010-Tree-Based_and_Forest-Based_Translation.html">243 acl-2010-Tree-Based and Forest-Based Translation</a></p>
<p>Author: Yang Liu ; Liang Huang</p><p>Abstract: unkown-abstract</p><p>2 0.28440502 <a title="243-tfidf-2" href="./acl-2010-Constituency_to_Dependency_Translation_with_Forests.html">69 acl-2010-Constituency to Dependency Translation with Forests</a></p>
<p>Author: Haitao Mi ; Qun Liu</p><p>Abstract: Tree-to-string systems (and their forestbased extensions) have gained steady popularity thanks to their simplicity and efficiency, but there is a major limitation: they are unable to guarantee the grammaticality of the output, which is explicitly modeled in string-to-tree systems via targetside syntax. We thus propose to combine the advantages of both, and present a novel constituency-to-dependency translation model, which uses constituency forests on the source side to direct the translation, and dependency trees on the target side (as a language model) to ensure grammaticality. Medium-scale experiments show an absolute and statistically significant improvement of +0.7 BLEU points over a state-of-the-art forest-based tree-to-string system even with fewer rules. This is also the first time that a treeto-tree model can surpass tree-to-string counterparts.</p><p>3 0.26038891 <a title="243-tfidf-3" href="./acl-2010-Fine-Grained_Tree-to-String_Translation_Rule_Extraction.html">118 acl-2010-Fine-Grained Tree-to-String Translation Rule Extraction</a></p>
<p>Author: Xianchao Wu ; Takuya Matsuzaki ; Jun'ichi Tsujii</p><p>Abstract: Tree-to-string translation rules are widely used in linguistically syntax-based statistical machine translation systems. In this paper, we propose to use deep syntactic information for obtaining fine-grained translation rules. A head-driven phrase structure grammar (HPSG) parser is used to obtain the deep syntactic information, which includes a fine-grained description of the syntactic property and a semantic representation of a sentence. We extract fine-grained rules from aligned HPSG tree/forest-string pairs and use them in our tree-to-string and string-to-tree systems. Extensive experiments on largescale bidirectional Japanese-English trans- lations testified the effectiveness of our approach.</p><p>4 0.21988545 <a title="243-tfidf-4" href="./acl-2010-Convolution_Kernel_over_Packed_Parse_Forest.html">71 acl-2010-Convolution Kernel over Packed Parse Forest</a></p>
<p>Author: Min Zhang ; Hui Zhang ; Haizhou Li</p><p>Abstract: This paper proposes a convolution forest kernel to effectively explore rich structured features embedded in a packed parse forest. As opposed to the convolution tree kernel, the proposed forest kernel does not have to commit to a single best parse tree, is thus able to explore very large object spaces and much more structured features embedded in a forest. This makes the proposed kernel more robust against parsing errors and data sparseness issues than the convolution tree kernel. The paper presents the formal definition of convolution forest kernel and also illustrates the computing algorithm to fast compute the proposed convolution forest kernel. Experimental results on two NLP applications, relation extraction and semantic role labeling, show that the proposed forest kernel significantly outperforms the baseline of the convolution tree kernel. 1</p><p>5 0.21571934 <a title="243-tfidf-5" href="./acl-2010-Learning_to_Translate_with_Source_and_Target_Syntax.html">169 acl-2010-Learning to Translate with Source and Target Syntax</a></p>
<p>Author: David Chiang</p><p>Abstract: Statistical translation models that try to capture the recursive structure of language have been widely adopted over the last few years. These models make use of varying amounts of information from linguistic theory: some use none at all, some use information about the grammar of the target language, some use information about the grammar of the source language. But progress has been slower on translation models that are able to learn the relationship between the grammars of both the source and target language. We discuss the reasons why this has been a challenge, review existing attempts to meet this challenge, and show how some old and new ideas can be combined into a sim- ple approach that uses both source and target syntax for significant improvements in translation accuracy.</p><p>6 0.20147851 <a title="243-tfidf-6" href="./acl-2010-cdec%3A_A_Decoder%2C_Alignment%2C_and_Learning_Framework_for_Finite-State_and_Context-Free_Translation_Models.html">265 acl-2010-cdec: A Decoder, Alignment, and Learning Framework for Finite-State and Context-Free Translation Models</a></p>
<p>7 0.15364327 <a title="243-tfidf-7" href="./acl-2010-Boosting-Based_System_Combination_for_Machine_Translation.html">54 acl-2010-Boosting-Based System Combination for Machine Translation</a></p>
<p>8 0.12914643 <a title="243-tfidf-8" href="./acl-2010-Better_Filtration_and_Augmentation_for_Hierarchical_Phrase-Based_Translation_Rules.html">48 acl-2010-Better Filtration and Augmentation for Hierarchical Phrase-Based Translation Rules</a></p>
<p>9 0.12820192 <a title="243-tfidf-9" href="./acl-2010-Semantic_Parsing%3A_The_Task%2C_the_State_of_the_Art_and_the_Future.html">206 acl-2010-Semantic Parsing: The Task, the State of the Art and the Future</a></p>
<p>10 0.12192748 <a title="243-tfidf-10" href="./acl-2010-A_Joint_Rule_Selection_Model_for_Hierarchical_Phrase-Based_Translation.html">9 acl-2010-A Joint Rule Selection Model for Hierarchical Phrase-Based Translation</a></p>
<p>11 0.12014322 <a title="243-tfidf-11" href="./acl-2010-Filtering_Syntactic_Constraints_for_Statistical_Machine_Translation.html">115 acl-2010-Filtering Syntactic Constraints for Statistical Machine Translation</a></p>
<p>12 0.11369187 <a title="243-tfidf-12" href="./acl-2010-Jointly_Optimizing_a_Two-Step_Conditional_Random_Field_Model_for_Machine_Transliteration_and_Its_Fast_Decoding_Algorithm.html">154 acl-2010-Jointly Optimizing a Two-Step Conditional Random Field Model for Machine Transliteration and Its Fast Decoding Algorithm</a></p>
<p>13 0.10848286 <a title="243-tfidf-13" href="./acl-2010-Dynamic_Programming_for_Linear-Time_Incremental_Parsing.html">93 acl-2010-Dynamic Programming for Linear-Time Incremental Parsing</a></p>
<p>14 0.10623505 <a title="243-tfidf-14" href="./acl-2010-Hierarchical_Search_for_Word_Alignment.html">133 acl-2010-Hierarchical Search for Word Alignment</a></p>
<p>15 0.10163417 <a title="243-tfidf-15" href="./acl-2010-Annotation.html">31 acl-2010-Annotation</a></p>
<p>16 0.10162408 <a title="243-tfidf-16" href="./acl-2010-Wide-Coverage_NLP_with_Linguistically_Expressive_Grammars.html">260 acl-2010-Wide-Coverage NLP with Linguistically Expressive Grammars</a></p>
<p>17 0.098400764 <a title="243-tfidf-17" href="./acl-2010-Training_Phrase_Translation_Models_with_Leaving-One-Out.html">240 acl-2010-Training Phrase Translation Models with Leaving-One-Out</a></p>
<p>18 0.097624779 <a title="243-tfidf-18" href="./acl-2010-Cross-Language_Document_Summarization_Based_on_Machine_Translation_Quality_Prediction.html">77 acl-2010-Cross-Language Document Summarization Based on Machine Translation Quality Prediction</a></p>
<p>19 0.096080638 <a title="243-tfidf-19" href="./acl-2010-Bilingual_Sense_Similarity_for_Statistical_Machine_Translation.html">51 acl-2010-Bilingual Sense Similarity for Statistical Machine Translation</a></p>
<p>20 0.091739014 <a title="243-tfidf-20" href="./acl-2010-Correcting_Errors_in_a_Treebank_Based_on_Synchronous_Tree_Substitution_Grammar.html">75 acl-2010-Correcting Errors in a Treebank Based on Synchronous Tree Substitution Grammar</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.208), (1, -0.243), (2, 0.05), (3, 0.008), (4, -0.128), (5, -0.074), (6, 0.126), (7, 0.022), (8, -0.258), (9, -0.009), (10, 0.124), (11, -0.058), (12, 0.143), (13, -0.02), (14, -0.016), (15, 0.125), (16, -0.067), (17, -0.009), (18, -0.039), (19, 0.009), (20, 0.091), (21, -0.04), (22, -0.192), (23, -0.088), (24, -0.156), (25, 0.014), (26, 0.02), (27, 0.043), (28, 0.051), (29, -0.071), (30, -0.07), (31, -0.116), (32, -0.074), (33, -0.045), (34, -0.077), (35, -0.17), (36, -0.033), (37, 0.082), (38, 0.085), (39, 0.047), (40, -0.026), (41, 0.009), (42, -0.009), (43, -0.075), (44, 0.008), (45, 0.005), (46, -0.058), (47, 0.017), (48, 0.001), (49, 0.015)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96689606 <a title="243-lsi-1" href="./acl-2010-Tree-Based_and_Forest-Based_Translation.html">243 acl-2010-Tree-Based and Forest-Based Translation</a></p>
<p>Author: Yang Liu ; Liang Huang</p><p>Abstract: unkown-abstract</p><p>2 0.81202203 <a title="243-lsi-2" href="./acl-2010-Fine-Grained_Tree-to-String_Translation_Rule_Extraction.html">118 acl-2010-Fine-Grained Tree-to-String Translation Rule Extraction</a></p>
<p>Author: Xianchao Wu ; Takuya Matsuzaki ; Jun'ichi Tsujii</p><p>Abstract: Tree-to-string translation rules are widely used in linguistically syntax-based statistical machine translation systems. In this paper, we propose to use deep syntactic information for obtaining fine-grained translation rules. A head-driven phrase structure grammar (HPSG) parser is used to obtain the deep syntactic information, which includes a fine-grained description of the syntactic property and a semantic representation of a sentence. We extract fine-grained rules from aligned HPSG tree/forest-string pairs and use them in our tree-to-string and string-to-tree systems. Extensive experiments on largescale bidirectional Japanese-English trans- lations testified the effectiveness of our approach.</p><p>3 0.73510814 <a title="243-lsi-3" href="./acl-2010-Constituency_to_Dependency_Translation_with_Forests.html">69 acl-2010-Constituency to Dependency Translation with Forests</a></p>
<p>Author: Haitao Mi ; Qun Liu</p><p>Abstract: Tree-to-string systems (and their forestbased extensions) have gained steady popularity thanks to their simplicity and efficiency, but there is a major limitation: they are unable to guarantee the grammaticality of the output, which is explicitly modeled in string-to-tree systems via targetside syntax. We thus propose to combine the advantages of both, and present a novel constituency-to-dependency translation model, which uses constituency forests on the source side to direct the translation, and dependency trees on the target side (as a language model) to ensure grammaticality. Medium-scale experiments show an absolute and statistically significant improvement of +0.7 BLEU points over a state-of-the-art forest-based tree-to-string system even with fewer rules. This is also the first time that a treeto-tree model can surpass tree-to-string counterparts.</p><p>4 0.70792365 <a title="243-lsi-4" href="./acl-2010-cdec%3A_A_Decoder%2C_Alignment%2C_and_Learning_Framework_for_Finite-State_and_Context-Free_Translation_Models.html">265 acl-2010-cdec: A Decoder, Alignment, and Learning Framework for Finite-State and Context-Free Translation Models</a></p>
<p>Author: Chris Dyer ; Adam Lopez ; Juri Ganitkevitch ; Jonathan Weese ; Ferhan Ture ; Phil Blunsom ; Hendra Setiawan ; Vladimir Eidelman ; Philip Resnik</p><p>Abstract: Adam Lopez University of Edinburgh alopez@inf.ed.ac.uk Juri Ganitkevitch Johns Hopkins University juri@cs.jhu.edu Ferhan Ture University of Maryland fture@cs.umd.edu Phil Blunsom Oxford University pblunsom@comlab.ox.ac.uk Vladimir Eidelman University of Maryland vlad@umiacs.umd.edu Philip Resnik University of Maryland resnik@umiacs.umd.edu classes in a unified way.1 Although open source decoders for both phraseWe present cdec, an open source framework for decoding, aligning with, and training a number of statistical machine translation models, including word-based models, phrase-based models, and models based on synchronous context-free grammars. Using a single unified internal representation for translation forests, the decoder strictly separates model-specific translation logic from general rescoring, pruning, and inference algorithms. From this unified representation, the decoder can extract not only the 1- or k-best translations, but also alignments to a reference, or the quantities necessary to drive discriminative training using gradient-based or gradient-free optimization techniques. Its efficient C++ implementation means that memory use and runtime performance are significantly better than comparable decoders.</p><p>5 0.5485068 <a title="243-lsi-5" href="./acl-2010-Learning_to_Translate_with_Source_and_Target_Syntax.html">169 acl-2010-Learning to Translate with Source and Target Syntax</a></p>
<p>Author: David Chiang</p><p>Abstract: Statistical translation models that try to capture the recursive structure of language have been widely adopted over the last few years. These models make use of varying amounts of information from linguistic theory: some use none at all, some use information about the grammar of the target language, some use information about the grammar of the source language. But progress has been slower on translation models that are able to learn the relationship between the grammars of both the source and target language. We discuss the reasons why this has been a challenge, review existing attempts to meet this challenge, and show how some old and new ideas can be combined into a sim- ple approach that uses both source and target syntax for significant improvements in translation accuracy.</p><p>6 0.52836406 <a title="243-lsi-6" href="./acl-2010-Convolution_Kernel_over_Packed_Parse_Forest.html">71 acl-2010-Convolution Kernel over Packed Parse Forest</a></p>
<p>7 0.49998057 <a title="243-lsi-7" href="./acl-2010-A_Joint_Rule_Selection_Model_for_Hierarchical_Phrase-Based_Translation.html">9 acl-2010-A Joint Rule Selection Model for Hierarchical Phrase-Based Translation</a></p>
<p>8 0.48384684 <a title="243-lsi-8" href="./acl-2010-Filtering_Syntactic_Constraints_for_Statistical_Machine_Translation.html">115 acl-2010-Filtering Syntactic Constraints for Statistical Machine Translation</a></p>
<p>9 0.47726303 <a title="243-lsi-9" href="./acl-2010-Boosting-Based_System_Combination_for_Machine_Translation.html">54 acl-2010-Boosting-Based System Combination for Machine Translation</a></p>
<p>10 0.47050813 <a title="243-lsi-10" href="./acl-2010-Better_Filtration_and_Augmentation_for_Hierarchical_Phrase-Based_Translation_Rules.html">48 acl-2010-Better Filtration and Augmentation for Hierarchical Phrase-Based Translation Rules</a></p>
<p>11 0.4411158 <a title="243-lsi-11" href="./acl-2010-Simple%2C_Accurate_Parsing_with_an_All-Fragments_Grammar.html">211 acl-2010-Simple, Accurate Parsing with an All-Fragments Grammar</a></p>
<p>12 0.40784261 <a title="243-lsi-12" href="./acl-2010-Tools_for_Multilingual_Grammar-Based_Translation_on_the_Web.html">235 acl-2010-Tools for Multilingual Grammar-Based Translation on the Web</a></p>
<p>13 0.40729949 <a title="243-lsi-13" href="./acl-2010-Wide-Coverage_NLP_with_Linguistically_Expressive_Grammars.html">260 acl-2010-Wide-Coverage NLP with Linguistically Expressive Grammars</a></p>
<p>14 0.40513653 <a title="243-lsi-14" href="./acl-2010-Jointly_Optimizing_a_Two-Step_Conditional_Random_Field_Model_for_Machine_Transliteration_and_Its_Fast_Decoding_Algorithm.html">154 acl-2010-Jointly Optimizing a Two-Step Conditional Random Field Model for Machine Transliteration and Its Fast Decoding Algorithm</a></p>
<p>15 0.39651409 <a title="243-lsi-15" href="./acl-2010-Computing_Weakest_Readings.html">67 acl-2010-Computing Weakest Readings</a></p>
<p>16 0.39245802 <a title="243-lsi-16" href="./acl-2010-Efficient_Staggered_Decoding_for_Sequence_Labeling.html">98 acl-2010-Efficient Staggered Decoding for Sequence Labeling</a></p>
<p>17 0.39155838 <a title="243-lsi-17" href="./acl-2010-Unsupervised_Search_for_the_Optimal_Segmentation_for_Statistical_Machine_Translation.html">249 acl-2010-Unsupervised Search for the Optimal Segmentation for Statistical Machine Translation</a></p>
<p>18 0.38501504 <a title="243-lsi-18" href="./acl-2010-Efficient_Path_Counting_Transducers_for_Minimum_Bayes-Risk_Decoding_of_Statistical_Machine_Translation_Lattices.html">97 acl-2010-Efficient Path Counting Transducers for Minimum Bayes-Risk Decoding of Statistical Machine Translation Lattices</a></p>
<p>19 0.3610667 <a title="243-lsi-19" href="./acl-2010-A_Tree_Transducer_Model_for_Synchronous_Tree-Adjoining_Grammars.html">21 acl-2010-A Tree Transducer Model for Synchronous Tree-Adjoining Grammars</a></p>
<p>20 0.35021076 <a title="243-lsi-20" href="./acl-2010-Bayesian_Synchronous_Tree-Substitution_Grammar_Induction_and_Its_Application_to_Sentence_Compression.html">46 acl-2010-Bayesian Synchronous Tree-Substitution Grammar Induction and Its Application to Sentence Compression</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(25, 0.13), (42, 0.011), (44, 0.473), (59, 0.111), (73, 0.023), (78, 0.029), (83, 0.065), (98, 0.067)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.8827495 <a title="243-lda-1" href="./acl-2010-Tree-Based_and_Forest-Based_Translation.html">243 acl-2010-Tree-Based and Forest-Based Translation</a></p>
<p>Author: Yang Liu ; Liang Huang</p><p>Abstract: unkown-abstract</p><p>2 0.74701309 <a title="243-lda-2" href="./acl-2010-Learning_Script_Knowledge_with_Web_Experiments.html">165 acl-2010-Learning Script Knowledge with Web Experiments</a></p>
<p>Author: Michaela Regneri ; Alexander Koller ; Manfred Pinkal</p><p>Abstract: We describe a novel approach to unsupervised learning of the events that make up a script, along with constraints on their temporal ordering. We collect naturallanguage descriptions of script-specific event sequences from volunteers over the Internet. Then we compute a graph representation of the script’s temporal structure using a multiple sequence alignment algorithm. The evaluation of our system shows that we outperform two informed baselines.</p><p>3 0.70705408 <a title="243-lda-3" href="./acl-2010-Sentiment_Translation_through_Lexicon_Induction.html">210 acl-2010-Sentiment Translation through Lexicon Induction</a></p>
<p>Author: Christian Scheible</p><p>Abstract: The translation of sentiment information is a task from which sentiment analysis systems can benefit. We present a novel, graph-based approach using SimRank, a well-established vertex similarity algorithm to transfer sentiment information between a source language and a target language graph. We evaluate this method in comparison with SO-PMI.</p><p>4 0.46110272 <a title="243-lda-4" href="./acl-2010-Discourse_Structure%3A_Theory%2C_Practice_and_Use.html">86 acl-2010-Discourse Structure: Theory, Practice and Use</a></p>
<p>Author: Bonnie Webber ; Markus Egg ; Valia Kordoni</p><p>Abstract: unkown-abstract</p><p>5 0.42735898 <a title="243-lda-5" href="./acl-2010-Semantic_Parsing%3A_The_Task%2C_the_State_of_the_Art_and_the_Future.html">206 acl-2010-Semantic Parsing: The Task, the State of the Art and the Future</a></p>
<p>Author: Rohit J. Kate ; Yuk Wah Wong</p><p>Abstract: unkown-abstract</p><p>6 0.40800485 <a title="243-lda-6" href="./acl-2010-Automatic_Evaluation_Method_for_Machine_Translation_Using_Noun-Phrase_Chunking.html">37 acl-2010-Automatic Evaluation Method for Machine Translation Using Noun-Phrase Chunking</a></p>
<p>7 0.39712381 <a title="243-lda-7" href="./acl-2010-Unsupervised_Event_Coreference_Resolution_with_Rich_Linguistic_Features.html">247 acl-2010-Unsupervised Event Coreference Resolution with Rich Linguistic Features</a></p>
<p>8 0.39644843 <a title="243-lda-8" href="./acl-2010-Annotation.html">31 acl-2010-Annotation</a></p>
<p>9 0.39328057 <a title="243-lda-9" href="./acl-2010-Constituency_to_Dependency_Translation_with_Forests.html">69 acl-2010-Constituency to Dependency Translation with Forests</a></p>
<p>10 0.38748339 <a title="243-lda-10" href="./acl-2010-Wide-Coverage_NLP_with_Linguistically_Expressive_Grammars.html">260 acl-2010-Wide-Coverage NLP with Linguistically Expressive Grammars</a></p>
<p>11 0.38272268 <a title="243-lda-11" href="./acl-2010-Convolution_Kernel_over_Packed_Parse_Forest.html">71 acl-2010-Convolution Kernel over Packed Parse Forest</a></p>
<p>12 0.38058174 <a title="243-lda-12" href="./acl-2010-Topic_Models_for_Word_Sense_Disambiguation_and_Token-Based_Idiom_Detection.html">237 acl-2010-Topic Models for Word Sense Disambiguation and Token-Based Idiom Detection</a></p>
<p>13 0.37915736 <a title="243-lda-13" href="./acl-2010-Temporal_Information_Processing_of_a_New_Language%3A_Fast_Porting_with_Minimal_Resources.html">225 acl-2010-Temporal Information Processing of a New Language: Fast Porting with Minimal Resources</a></p>
<p>14 0.37405825 <a title="243-lda-14" href="./acl-2010-Structural_Semantic_Relatedness%3A_A_Knowledge-Based_Method_to_Named_Entity_Disambiguation.html">218 acl-2010-Structural Semantic Relatedness: A Knowledge-Based Method to Named Entity Disambiguation</a></p>
<p>15 0.37352899 <a title="243-lda-15" href="./acl-2010-Event-Based_Hyperspace_Analogue_to_Language_for_Query_Expansion.html">106 acl-2010-Event-Based Hyperspace Analogue to Language for Query Expansion</a></p>
<p>16 0.3727026 <a title="243-lda-16" href="./acl-2010-Grammar_Prototyping_and_Testing_with_the_LinGO_Grammar_Matrix_Customization_System.html">128 acl-2010-Grammar Prototyping and Testing with the LinGO Grammar Matrix Customization System</a></p>
<p>17 0.37260208 <a title="243-lda-17" href="./acl-2010-Fully_Unsupervised_Core-Adjunct_Argument_Classification.html">120 acl-2010-Fully Unsupervised Core-Adjunct Argument Classification</a></p>
<p>18 0.3722398 <a title="243-lda-18" href="./acl-2010-BabelNet%3A_Building_a_Very_Large_Multilingual_Semantic_Network.html">44 acl-2010-BabelNet: Building a Very Large Multilingual Semantic Network</a></p>
<p>19 0.3692334 <a title="243-lda-19" href="./acl-2010-Talking_NPCs_in_a_Virtual_Game_World.html">224 acl-2010-Talking NPCs in a Virtual Game World</a></p>
<p>20 0.36919156 <a title="243-lda-20" href="./acl-2010-Accurate_Context-Free_Parsing_with_Combinatory_Categorial_Grammar.html">23 acl-2010-Accurate Context-Free Parsing with Combinatory Categorial Grammar</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
