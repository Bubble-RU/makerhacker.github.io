<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>121 acl-2010-Generating Entailment Rules from FrameNet</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-121" href="#">acl2010-121</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>121 acl-2010-Generating Entailment Rules from FrameNet</h1>
<br/><p>Source: <a title="acl-2010-121-pdf" href="http://aclweb.org/anthology//P/P10/P10-2045.pdf">pdf</a></p><p>Author: Roni Ben Aharon ; Idan Szpektor ; Ido Dagan</p><p>Abstract: Idan Szpektor Ido Dagan Yahoo! Research Department of Computer Science Haifa, Israel Bar-Ilan University idan @ yahoo- inc .com Ramat Gan, Israel dagan @ c s .biu . ac . i l FrameNet is a manually constructed database based on Frame Semantics. It models the semantic Many NLP tasks need accurate knowledge for semantic inference. To this end, mostly WordNet is utilized. Yet WordNet is limited, especially for inference be- tween predicates. To help filling this gap, we present an algorithm that generates inference rules between predicates from FrameNet. Our experiment shows that the novel resource is effective and complements WordNet in terms of rule coverage.</p><p>Reference: <a title="acl-2010-121-reference" href="../acl2010_reference/acl-2010-Generating_Entailment_Rules_from_FrameNet_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Research Department of Computer Science Haifa, Israel Bar-Ilan University idan @ yahoo- inc . [sent-5, score-0.069]
</p><p>2 Yet WordNet is limited, especially for inference be-  tween predicates. [sent-12, score-0.032]
</p><p>3 To help filling this gap, we present an algorithm that generates inference rules between predicates from FrameNet. [sent-13, score-0.208]
</p><p>4 Our experiment shows that the novel resource is effective and complements WordNet in terms of rule coverage. [sent-14, score-0.098]
</p><p>5 1 Introduction Many text understanding applications, such as Question Answering (QA) and Information Extraction (IE), need to infer a target textual meaning from other texts. [sent-15, score-0.044]
</p><p>6 We address one prominent type of inference knowledge known as entailment rules, focusing specifically on rules between predicates, such as ‘cure X ⇒ X recover’ . [sent-22, score-0.567]
</p><p>7 W‘ceu ea iXm at highly accurate rule acquisition, for which utilizing manually constructed sources seem appropriate. [sent-23, score-0.046]
</p><p>8 Yet it is incomplete for generating entailment rules between predicates (Section 2. [sent-25, score-0.633]
</p><p>9 , 1998) could be effectively used for generating entailment rules between predicates. [sent-29, score-0.576]
</p><p>10 argument structure of predicates in terms of prototypical situations called frames. [sent-31, score-0.185]
</p><p>11 Prior work utilized FrameNet’s argument mapping capabilities but took entailment relations from other resources, namely WordNet. [sent-32, score-0.662]
</p><p>12 We propose a novel method for generating entailment rules from FrameNet by detecting the entailment relations implied in FrameNet. [sent-33, score-1.092]
</p><p>13 We utilize FrameNet’s annotated sentences and relations between frames to extract both the entailment relations and their argument mappings. [sent-34, score-0.767]
</p><p>14 Our analysis shows that the rules generated by our algorithm have a reasonable “per-rule” accuracy of about 70%2. [sent-35, score-0.142]
</p><p>15 We tested the generated ruleset on an entailment testbed derived from an IE benchmark and compared it both to WordNet and to state-of-the-art rule generation from FrameNet. [sent-36, score-0.54]
</p><p>16 1 Entailment Rules and their Acquisition To generate entailment rules, two issues should be addressed: a) identifying the lexical entailment relations between predicates, e. [sent-41, score-0.97]
</p><p>17 ‘cure ⇒ recover’ ; b) mapping argument positions, e. [sent-43, score-0.118]
</p><p>18 To this end, most systems mainly utilize WordNet (Fellbaum, 1998), being  the most prominent lexical resource with broad coverage of predicates. [sent-48, score-0.094]
</p><p>19 c C2o0n1f0er Aenscseoc Sihatoirotn P faopre Crso,m papguetsat 2io4n1a–l2 L4i6n,guistics  relations capture types of entailment relations, including synonymy, hypernymy, morphologicallyderived, entailment and cause. [sent-55, score-0.932]
</p><p>20 First, many entailment relations, notably for the WordNet entailment and cause relation types, are missing, e. [sent-57, score-0.888]
</p><p>21 Furthermore, WordNet does not in‘celluedcet argument mapping between related predicates. [sent-60, score-0.118]
</p><p>22 Thus, only substitutable WordNet relations (synonymy and hypernymy), for which argument positions are preserved, could be used to generate entailment rules. [sent-61, score-0.671]
</p><p>23 , 1998) is a knowledgebase of frames, describing prototypical situations. [sent-69, score-0.041]
</p><p>24 For each frame, several semantic roles are specified, called frame elements (FEs), denoting the participants in the situation described. [sent-73, score-0.109]
</p><p>25 For example, some core FEs of the Commerce pay frame are Buyer and Goods, while a non-core FE is Place. [sent-75, score-0.142]
</p><p>26 A frame includes a list of predicates that can evoke the described situation, called lexical units (LUs). [sent-79, score-0.204]
</p><p>27 For example, the frame Commerce pay lists the LUs pay. [sent-81, score-0.142]
</p><p>28 Each annotation refers to one LU in a specific frame and the FEs of the frame that occur in the sentence. [sent-85, score-0.218]
</p><p>29 An example sentence is “IBuyer have to  pay the billsMoney”. [sent-86, score-0.033]
</p><p>30 Each sentence is accompanied by a valence pattern, which provides, among other info, grammatical functions of the core FEs with respect to the LU. [sent-87, score-0.065]
</p><p>31 The valence pattern of the above sentence is [(Buyer Subj), (Money Obj)]. [sent-88, score-0.034]
</p><p>32 3 Using FrameNet for Semantic Inference To the best of our knowledge, the only work that utilized FrameNet for entailment rule generation is LexPar (Coyne and Rambow, 2009). [sent-90, score-0.49]
</p><p>33 LexPar first identifies lexical entailment relations by going over all LU pairs which are either in the same frame or whose frames are related by one of FrameNet’s inter-frame relations. [sent-91, score-0.727]
</p><p>34 Each candidate pair is considered entailing if the two LUs are either synonyms or in a direct hypernymy relation in WordNet (providing the vast majority of LexPar’s relations), or if their related frames are connected via the Perspective relation in FrameNet. [sent-92, score-0.259]
</p><p>35 Then, argument mappings between each entailing LU pair are extracted based on the core FEs that are shared between the two LUs. [sent-93, score-0.191]
</p><p>36 The syntactic positions of the shared FEs are taken from the valence patterns of the LUs. [sent-94, score-0.034]
</p><p>37 A LexPar rule exam-  ple is presented in Figure 3 (top part). [sent-95, score-0.046]
</p><p>38 Since most of LexPar’s entailment relations are based on WordNet’s relations, LexPar’s rules could be viewed as an intersection of WordNet and FrameNet lexical relations, accompanied with argument mappings taken from FrameNet. [sent-96, score-0.822]
</p><p>39 3  Rule Extraction from FrameNet  The above prior work identified lexical entailment relations mainly from WordNet, which limits the use of FrameNet in two ways. [sent-97, score-0.582]
</p><p>40 First, some relations that appear in FrameNet are missed because they do not appear in WordNet. [sent-98, score-0.1]
</p><p>41 Second, unlike FrameNet, WordNet does not include argument mappings for its relations. [sent-99, score-0.118]
</p><p>42 Thus, prior work for rule generation considered only substitutable relations from WordNet (synonyms and hypernyms), not utilizing FrameNet’s capability to map arguments of non-substitutable relations. [sent-100, score-0.214]
</p><p>43 Our goal in this paper is to generate entailment rules solely from the information within FrameNet. [sent-101, score-0.535]
</p><p>44 From each sentence of a given LU, we extract one template for each annotated FE in the sentence. [sent-106, score-0.062]
</p><p>45 Each template includes the LU, one argument corresponding to the target FE and their syntactic relation in the sentence parse-tree. [sent-107, score-0.179]
</p><p>46 We focus on extracting unary templates, as they can describe any ar242  Figure 1: Template extraction for a sentence containing the LU ‘arrest’. [sent-108, score-0.075]
</p><p>47 gument mapping by decomposing templates with several arguments into unary ones (Szpektor and Dagan, 2008). [sent-109, score-0.254]
</p><p>48 Each extracted path is converted into a template by replacing the FE node with an argument variable. [sent-114, score-0.149]
</p><p>49 Some templates originated from different annotated sentences share the same LU and syntactic structure, but differ in their FEs. [sent-117, score-0.148]
</p><p>50 Usually, one of these templates is incorrect, due to erroneous parse  ←ob−j arrest’ is acorrecttemplate, in to ‘Charges r←oesb−jt’ arrest’). [sent-118, score-0.148]
</p><p>51 ‘Suspect  contrast only the most frequently −an naortreastetd’) template so kute eopf the identical templates, assuming it is the correct one. [sent-121, score-0.062]
</p><p>52 2 Identifying Lexical Entailment Relations FrameNet groups LUs in frames and describes re-  lations between frames. [sent-123, score-0.064]
</p><p>53 We next describe how we automatically extract several types of lexical entailment relations between LUs using two approaches. [sent-125, score-0.554]
</p><p>54 In the first approach, LUs in the same frame that are morphological derivations of each other, e. [sent-126, score-0.109]
</p><p>55 The second approach is based on our observation that some LUs express the prototypical situation that their frame describes, which we denote dominant LUs. [sent-132, score-0.22]
</p><p>56 For example, the LU ‘recover’ is dominant for the Recovery frame. [sent-133, score-0.07]
</p><p>57 We mark LUs as dominant if they are morphologically derived from the frame’s name. [sent-134, score-0.07]
</p><p>58 Our assumption is that since dominant LUs express the frame’s generic meaning, their meaning is likely to be entailed by the other LUs in this frame. [sent-135, score-0.07]
</p><p>59 Consequently, we generate such lexical rules between any dominant LU and any other LU  in a given frame, e. [sent-136, score-0.227]
</p><p>60 In addition, we assume that eifc two frames are related by some type of entailment relation, their dominant LUs are also related by the same relation. [sent-141, score-0.55]
</p><p>61 Accordingly, we extract entailment relations between dominant LUs of frames that are connected via the Inheritance, Cause and Perspective relations, where Inheritance and Cause generate directional entailment relations (e. [sent-142, score-1.166]
</p><p>62 ‘choose ⇒ ddeirceicdtei’o naanld ‘nctuarielm ⇒ recover’, respectively) sweh i⇒le Perspective generates e bciodivreerc’t,io rneaspl paraphrase relations (e. [sent-144, score-0.13]
</p><p>63 Finally, we generate the transitive closure of the set of lexical relations identified by the above methods. [sent-147, score-0.167]
</p><p>64 3 Generating Entailment Rules The final step in the FRED algorithm generates lexical syntactic entailment rules from the extracted templates and lexical entailment relations. [sent-151, score-1.175]
</p><p>65 For each identified lexical relation ‘left ⇒ right’  betFwoere ena two LUs, tehde l sexeti coafl lF reElas tthioant are ts⇒h ar reigd by both LUs is collected. [sent-152, score-0.068]
</p><p>66 pair, l Tlfefet and r  to each of the LUs, denoted by Finally, for each template  Trfigeht,  ∈  ∈  r’  the rule ‘l ⇒ is generated. [sent-161, score-0.108]
</p><p>67 n tnhe a dvdairtiioouns, templates including the same FE and the same LU. [sent-163, score-0.148]
</p><p>68 To improve rule quality, we filter out rules that map FEs of adjunct-like semantic types, such as Time and Location, since different templates of such FEs may have different semantic meanings  be←fo−re  a←ft−er  (e. [sent-165, score-0.313]
</p><p>69 Thus, it is hard← ←to− identify et’h ‘osTei template pairs teh’a)t. [sent-168, score-0.062]
</p><p>70 We manually evaluated a random sample of 250 rules from the resulting rule-set, out of which we judged 69% as correct. [sent-170, score-0.119]
</p><p>71 1 Experimental Setup We would like to evaluate the overall utility of our resource for NLP applications, assessing the correctness of the actual rule applications performed in practice, as well as to compare its performance to related resources. [sent-172, score-0.074]
</p><p>72 To this end, we follow the experimental setup presented in (Szpektor and Dagan, 2009), which utilized the ACE 2005 event dataset3 as a testbed for entailment rule-sets. [sent-173, score-0.507]
</p><p>73 The task is to extract argument mentions for 26 events, such as Sue and Attack, from the ACE annotated corpus, using a given tested entailment rule-set. [sent-175, score-0.534]
</p><p>74 Each event is represented by a set of unary seed templates, one for each event argument. [sent-176, score-0.188]
</p><p>75 Some seed templates for Attack are ‘At-  tackers←u−bjattack’  and  ‘attack−o→bjTarget’. [sent-177, score-0.183]
</p><p>76 ACE corpus by matching either the seed templates or templates entailing them found in the tested rule-set. [sent-179, score-0.435]
</p><p>77 We manually added for each event its relevant WordNet synset-ids and FrameNet frame-ids, so only rules fitting the event target meaning will be extracted from the tested rule-sets. [sent-180, score-0.228]
</p><p>78 2 Tested Configurations We evaluated several rule-set configurations: No-Rules The system matches only the seed templates directly, without any additional rules. [sent-182, score-0.183]
</p><p>79 0, using only the synonymy and hypernymy relations (see Section 2. [sent-184, score-0.193]
</p><p>80 Transitive chaining of relations is allowed (Moldovan and Novischi, 2002). [sent-186, score-0.1]
</p><p>81 We generated unary rules from each LexPar rule based on a manually constructed mapping from FrameNet grammatical functions to Minipar dependency relations. [sent-188, score-0.294]
</p><p>82 As expected, using No-Rules achieves the highest precision and the lowest recall compared to all other configurations. [sent-196, score-0.049]
</p><p>83 This shows that the subset of WordNet rules captured by LexPar (Section 2. [sent-202, score-0.119]
</p><p>84 When using all WordNet’s substitutable relations, a substantial relative increase in recall is achieved (32%). [sent-204, score-0.117]
</p><p>85 Most errors are due to correct WordNet rules whose LHS is ambiguous. [sent-206, score-0.119]
</p><p>86 Since we do not apply a WSD module, these rules are also incorrectly applied to other senses ofthe LHS. [sent-207, score-0.119]
</p><p>87 Our main result is that using FRED’s rule-set, recall increases significantly, a relative increase of 27% compared to No-Rules, while precision hardly decreases. [sent-209, score-0.073]
</p><p>88 Hence, overall F1 is the highest compared to all other configurations (a relative increase of 17% compared to No-Rules). [sent-210, score-0.058]
</p><p>89 FRED preforms significantly better than LexPar  in both recall, precision and F1 (a relative increase of 25%, 28% and 41% respectively). [sent-213, score-0.048]
</p><p>90 For example, LexPar hardly utilizes FrameNet’s argument mapping capabilities since most of its rules are based on a sub-set of WordNet’s substitutable relations. [sent-214, score-0.305]
</p><p>91 This mostly results from the fact that FrameNet mainly contains common senses of predicates while WordNet includes many rare word senses; which, as said above, harms precision when WSD is not applied. [sent-216, score-0.109]
</p><p>92 5% of incorrect extractions are due to erronous rules in FRED, while the majority of errors are due to sense mismatch or syntactic matching errors of the seed templates ot entailing templates in texts. [sent-218, score-0.523]
</p><p>93 Yet, its rules are mostly complementary to those from WordNet. [sent-220, score-0.147]
</p><p>94 This added value is demonstrated by the 19% recall increase for the union of FRED and WordNet rule-sets compared to WordNet alone. [sent-221, score-0.049]
</p><p>95 FRED provides mainly argument map-  pings for non-substitutable WordNet relations, e. [sent-222, score-0.115]
</p><p>96 v X’, but also lexical rel‘aattitoancsk tnh oatn are missing f. [sent-226, score-0.038]
</p><p>97 Overall, our experiment shows that the rulebase generated by FRED seems an appropriate complementary resource to the widely used WordNet-based rules in semantic inference and expansion over predicates. [sent-232, score-0.23]
</p><p>98 5  Conclusions  We presented FRED, a novel algorithm for generating entailment rules solely from the information contained in FrameNet. [sent-234, score-0.576]
</p><p>99 Our experiment showed that FRED’s rules perform substantially better than LexPar, the only prior rule-set derived from FrameNet. [sent-235, score-0.119]
</p><p>100 In addition, FRED’s rule-set largely complements the rules generated from WordNet because it contains argument mappings between non-substitutable predicates, which are missing  from WordNet, as well as lexical relations that are not included in WordNet. [sent-236, score-0.422]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('entailment', 0.416), ('lus', 0.34), ('lexpar', 0.33), ('framenet', 0.29), ('fred', 0.207), ('wordnet', 0.198), ('recovery', 0.177), ('cure', 0.17), ('lu', 0.16), ('fes', 0.153), ('templates', 0.148), ('arrest', 0.14), ('patient', 0.137), ('fe', 0.123), ('rules', 0.119), ('affliction', 0.116), ('frame', 0.109), ('relations', 0.1), ('argument', 0.087), ('dagan', 0.084), ('apprehend', 0.078), ('ob', 0.076), ('unary', 0.075), ('szpektor', 0.073), ('entailing', 0.073), ('dominant', 0.07), ('idan', 0.069), ('substitutable', 0.068), ('frames', 0.064), ('hypernymy', 0.062), ('template', 0.062), ('ido', 0.061), ('recover', 0.06), ('predicates', 0.057), ('ace', 0.055), ('ub', 0.047), ('rule', 0.046), ('israel', 0.044), ('giampiccolo', 0.044), ('inheritance', 0.044), ('textual', 0.044), ('pascal', 0.043), ('authorities', 0.041), ('prototypical', 0.041), ('generating', 0.041), ('event', 0.039), ('aharon', 0.039), ('coyne', 0.039), ('gan', 0.039), ('offense', 0.039), ('ramat', 0.039), ('roni', 0.039), ('tlfefet', 0.039), ('lexical', 0.038), ('suspect', 0.037), ('ge', 0.037), ('attack', 0.035), ('seed', 0.035), ('bernardo', 0.034), ('obj', 0.034), ('cf', 0.034), ('valence', 0.034), ('configurations', 0.034), ('buyer', 0.034), ('pay', 0.033), ('inference', 0.032), ('accompanied', 0.031), ('synonymy', 0.031), ('mapping', 0.031), ('mappings', 0.031), ('tested', 0.031), ('paraphrase', 0.03), ('relation', 0.03), ('wsd', 0.029), ('transitive', 0.029), ('commerce', 0.029), ('minipar', 0.029), ('macro', 0.029), ('baker', 0.028), ('mainly', 0.028), ('resource', 0.028), ('habash', 0.028), ('ur', 0.028), ('utilized', 0.028), ('complementary', 0.028), ('danilo', 0.026), ('recognising', 0.026), ('subj', 0.026), ('cause', 0.026), ('recall', 0.025), ('moldovan', 0.025), ('ben', 0.025), ('arrive', 0.024), ('testbed', 0.024), ('complements', 0.024), ('wilcoxon', 0.024), ('precision', 0.024), ('increase', 0.024), ('generated', 0.023), ('magnini', 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="121-tfidf-1" href="./acl-2010-Generating_Entailment_Rules_from_FrameNet.html">121 acl-2010-Generating Entailment Rules from FrameNet</a></p>
<p>Author: Roni Ben Aharon ; Idan Szpektor ; Ido Dagan</p><p>Abstract: Idan Szpektor Ido Dagan Yahoo! Research Department of Computer Science Haifa, Israel Bar-Ilan University idan @ yahoo- inc .com Ramat Gan, Israel dagan @ c s .biu . ac . i l FrameNet is a manually constructed database based on Frame Semantics. It models the semantic Many NLP tasks need accurate knowledge for semantic inference. To this end, mostly WordNet is utilized. Yet WordNet is limited, especially for inference be- tween predicates. To help filling this gap, we present an algorithm that generates inference rules between predicates from FrameNet. Our experiment shows that the novel resource is effective and complements WordNet in terms of rule coverage.</p><p>2 0.32662746 <a title="121-tfidf-2" href="./acl-2010-Global_Learning_of_Focused_Entailment_Graphs.html">127 acl-2010-Global Learning of Focused Entailment Graphs</a></p>
<p>Author: Jonathan Berant ; Ido Dagan ; Jacob Goldberger</p><p>Abstract: We propose a global algorithm for learning entailment relations between predicates. We define a graph structure over predicates that represents entailment relations as directed edges, and use a global transitivity constraint on the graph to learn the optimal set of edges, by formulating the optimization problem as an Integer Linear Program. We motivate this graph with an application that provides a hierarchical summary for a set of propositions that focus on a target concept, and show that our global algorithm improves performance by more than 10% over baseline algorithms.</p><p>3 0.25341657 <a title="121-tfidf-3" href="./acl-2010-Assessing_the_Role_of_Discourse_References_in_Entailment_Inference.html">33 acl-2010-Assessing the Role of Discourse References in Entailment Inference</a></p>
<p>Author: Shachar Mirkin ; Ido Dagan ; Sebastian Pado</p><p>Abstract: Discourse references, notably coreference and bridging, play an important role in many text understanding applications, but their impact on textual entailment is yet to be systematically understood. On the basis of an in-depth analysis of entailment instances, we argue that discourse references have the potential of substantially improving textual entailment recognition, and identify a number of research directions towards this goal.</p><p>4 0.20367898 <a title="121-tfidf-4" href="./acl-2010-An_Open-Source_Package_for_Recognizing_Textual_Entailment.html">30 acl-2010-An Open-Source Package for Recognizing Textual Entailment</a></p>
<p>Author: Milen Kouylekov ; Matteo Negri</p><p>Abstract: This paper presents a general-purpose open source package for recognizing Textual Entailment. The system implements a collection of algorithms, providing a configurable framework to quickly set up a working environment to experiment with the RTE task. Fast prototyping of new solutions is also allowed by the possibility to extend its modular architecture. We present the tool as a useful resource to approach the Textual Entailment problem, as an instrument for didactic purposes, and as an opportunity to create a collaborative environment to promote research in the field.</p><p>5 0.18455857 <a title="121-tfidf-5" href="./acl-2010-%22Ask_Not_What_Textual_Entailment_Can_Do_for_You...%22.html">1 acl-2010-"Ask Not What Textual Entailment Can Do for You..."</a></p>
<p>Author: Mark Sammons ; V.G.Vinod Vydiswaran ; Dan Roth</p><p>Abstract: We challenge the NLP community to participate in a large-scale, distributed effort to design and build resources for developing and evaluating solutions to new and existing NLP tasks in the context of Recognizing Textual Entailment. We argue that the single global label with which RTE examples are annotated is insufficient to effectively evaluate RTE system performance; to promote research on smaller, related NLP tasks, we believe more detailed annotation and evaluation are needed, and that this effort will benefit not just RTE researchers, but the NLP community as a whole. We use insights from successful RTE systems to propose a model for identifying and annotating textual infer- ence phenomena in textual entailment examples, and we present the results of a pilot annotation study that show this model is feasible and the results immediately useful.</p><p>6 0.13095137 <a title="121-tfidf-6" href="./acl-2010-Towards_Open-Domain_Semantic_Role_Labeling.html">238 acl-2010-Towards Open-Domain Semantic Role Labeling</a></p>
<p>7 0.12070128 <a title="121-tfidf-7" href="./acl-2010-Weakly_Supervised_Learning_of_Presupposition_Relations_between_Verbs.html">258 acl-2010-Weakly Supervised Learning of Presupposition Relations between Verbs</a></p>
<p>8 0.11375637 <a title="121-tfidf-8" href="./acl-2010-Knowledge-Rich_Word_Sense_Disambiguation_Rivaling_Supervised_Systems.html">156 acl-2010-Knowledge-Rich Word Sense Disambiguation Rivaling Supervised Systems</a></p>
<p>9 0.089032032 <a title="121-tfidf-9" href="./acl-2010-Unsupervised_Event_Coreference_Resolution_with_Rich_Linguistic_Features.html">247 acl-2010-Unsupervised Event Coreference Resolution with Rich Linguistic Features</a></p>
<p>10 0.088470638 <a title="121-tfidf-10" href="./acl-2010-Predicate_Argument_Structure_Analysis_Using_Transformation_Based_Learning.html">198 acl-2010-Predicate Argument Structure Analysis Using Transformation Based Learning</a></p>
<p>11 0.088465139 <a title="121-tfidf-11" href="./acl-2010-Expanding_Verb_Coverage_in_Cyc_with_VerbNet.html">108 acl-2010-Expanding Verb Coverage in Cyc with VerbNet</a></p>
<p>12 0.081902049 <a title="121-tfidf-12" href="./acl-2010-BabelNet%3A_Building_a_Very_Large_Multilingual_Semantic_Network.html">44 acl-2010-BabelNet: Building a Very Large Multilingual Semantic Network</a></p>
<p>13 0.07008332 <a title="121-tfidf-13" href="./acl-2010-Learning_Arguments_and_Supertypes_of_Semantic_Relations_Using_Recursive_Patterns.html">160 acl-2010-Learning Arguments and Supertypes of Semantic Relations Using Recursive Patterns</a></p>
<p>14 0.069108762 <a title="121-tfidf-14" href="./acl-2010-A_Latent_Dirichlet_Allocation_Method_for_Selectional_Preferences.html">10 acl-2010-A Latent Dirichlet Allocation Method for Selectional Preferences</a></p>
<p>15 0.067404792 <a title="121-tfidf-15" href="./acl-2010-Edit_Tree_Distance_Alignments_for_Semantic_Role_Labelling.html">94 acl-2010-Edit Tree Distance Alignments for Semantic Role Labelling</a></p>
<p>16 0.066978179 <a title="121-tfidf-16" href="./acl-2010-The_Manually_Annotated_Sub-Corpus%3A_A_Community_Resource_for_and_by_the_People.html">230 acl-2010-The Manually Annotated Sub-Corpus: A Community Resource for and by the People</a></p>
<p>17 0.066877596 <a title="121-tfidf-17" href="./acl-2010-Fully_Unsupervised_Core-Adjunct_Argument_Classification.html">120 acl-2010-Fully Unsupervised Core-Adjunct Argument Classification</a></p>
<p>18 0.064448521 <a title="121-tfidf-18" href="./acl-2010-Detecting_Experiences_from_Weblogs.html">85 acl-2010-Detecting Experiences from Weblogs</a></p>
<p>19 0.062156782 <a title="121-tfidf-19" href="./acl-2010-Beyond_NomBank%3A_A_Study_of_Implicit_Arguments_for_Nominal_Predicates.html">49 acl-2010-Beyond NomBank: A Study of Implicit Arguments for Nominal Predicates</a></p>
<p>20 0.058008522 <a title="121-tfidf-20" href="./acl-2010-Computing_Weakest_Readings.html">67 acl-2010-Computing Weakest Readings</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.161), (1, 0.117), (2, 0.075), (3, -0.056), (4, 0.08), (5, 0.117), (6, 0.068), (7, 0.118), (8, -0.249), (9, -0.235), (10, -0.05), (11, 0.226), (12, -0.115), (13, 0.036), (14, -0.029), (15, -0.196), (16, -0.055), (17, 0.002), (18, -0.038), (19, -0.027), (20, -0.037), (21, 0.042), (22, -0.019), (23, 0.009), (24, -0.009), (25, -0.019), (26, -0.007), (27, -0.032), (28, 0.012), (29, -0.091), (30, 0.063), (31, 0.023), (32, 0.07), (33, -0.015), (34, 0.101), (35, -0.034), (36, -0.02), (37, 0.075), (38, 0.041), (39, -0.042), (40, 0.0), (41, 0.052), (42, -0.054), (43, -0.078), (44, 0.055), (45, 0.034), (46, -0.1), (47, 0.035), (48, -0.011), (49, -0.007)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96513778 <a title="121-lsi-1" href="./acl-2010-Generating_Entailment_Rules_from_FrameNet.html">121 acl-2010-Generating Entailment Rules from FrameNet</a></p>
<p>Author: Roni Ben Aharon ; Idan Szpektor ; Ido Dagan</p><p>Abstract: Idan Szpektor Ido Dagan Yahoo! Research Department of Computer Science Haifa, Israel Bar-Ilan University idan @ yahoo- inc .com Ramat Gan, Israel dagan @ c s .biu . ac . i l FrameNet is a manually constructed database based on Frame Semantics. It models the semantic Many NLP tasks need accurate knowledge for semantic inference. To this end, mostly WordNet is utilized. Yet WordNet is limited, especially for inference be- tween predicates. To help filling this gap, we present an algorithm that generates inference rules between predicates from FrameNet. Our experiment shows that the novel resource is effective and complements WordNet in terms of rule coverage.</p><p>2 0.79817754 <a title="121-lsi-2" href="./acl-2010-Global_Learning_of_Focused_Entailment_Graphs.html">127 acl-2010-Global Learning of Focused Entailment Graphs</a></p>
<p>Author: Jonathan Berant ; Ido Dagan ; Jacob Goldberger</p><p>Abstract: We propose a global algorithm for learning entailment relations between predicates. We define a graph structure over predicates that represents entailment relations as directed edges, and use a global transitivity constraint on the graph to learn the optimal set of edges, by formulating the optimization problem as an Integer Linear Program. We motivate this graph with an application that provides a hierarchical summary for a set of propositions that focus on a target concept, and show that our global algorithm improves performance by more than 10% over baseline algorithms.</p><p>3 0.74184614 <a title="121-lsi-3" href="./acl-2010-%22Ask_Not_What_Textual_Entailment_Can_Do_for_You...%22.html">1 acl-2010-"Ask Not What Textual Entailment Can Do for You..."</a></p>
<p>Author: Mark Sammons ; V.G.Vinod Vydiswaran ; Dan Roth</p><p>Abstract: We challenge the NLP community to participate in a large-scale, distributed effort to design and build resources for developing and evaluating solutions to new and existing NLP tasks in the context of Recognizing Textual Entailment. We argue that the single global label with which RTE examples are annotated is insufficient to effectively evaluate RTE system performance; to promote research on smaller, related NLP tasks, we believe more detailed annotation and evaluation are needed, and that this effort will benefit not just RTE researchers, but the NLP community as a whole. We use insights from successful RTE systems to propose a model for identifying and annotating textual infer- ence phenomena in textual entailment examples, and we present the results of a pilot annotation study that show this model is feasible and the results immediately useful.</p><p>4 0.7294507 <a title="121-lsi-4" href="./acl-2010-An_Open-Source_Package_for_Recognizing_Textual_Entailment.html">30 acl-2010-An Open-Source Package for Recognizing Textual Entailment</a></p>
<p>Author: Milen Kouylekov ; Matteo Negri</p><p>Abstract: This paper presents a general-purpose open source package for recognizing Textual Entailment. The system implements a collection of algorithms, providing a configurable framework to quickly set up a working environment to experiment with the RTE task. Fast prototyping of new solutions is also allowed by the possibility to extend its modular architecture. We present the tool as a useful resource to approach the Textual Entailment problem, as an instrument for didactic purposes, and as an opportunity to create a collaborative environment to promote research in the field.</p><p>5 0.57945114 <a title="121-lsi-5" href="./acl-2010-Assessing_the_Role_of_Discourse_References_in_Entailment_Inference.html">33 acl-2010-Assessing the Role of Discourse References in Entailment Inference</a></p>
<p>Author: Shachar Mirkin ; Ido Dagan ; Sebastian Pado</p><p>Abstract: Discourse references, notably coreference and bridging, play an important role in many text understanding applications, but their impact on textual entailment is yet to be systematically understood. On the basis of an in-depth analysis of entailment instances, we argue that discourse references have the potential of substantially improving textual entailment recognition, and identify a number of research directions towards this goal.</p><p>6 0.48283643 <a title="121-lsi-6" href="./acl-2010-Weakly_Supervised_Learning_of_Presupposition_Relations_between_Verbs.html">258 acl-2010-Weakly Supervised Learning of Presupposition Relations between Verbs</a></p>
<p>7 0.48102105 <a title="121-lsi-7" href="./acl-2010-Expanding_Verb_Coverage_in_Cyc_with_VerbNet.html">108 acl-2010-Expanding Verb Coverage in Cyc with VerbNet</a></p>
<p>8 0.46644256 <a title="121-lsi-8" href="./acl-2010-GernEdiT_-_The_GermaNet_Editing_Tool.html">126 acl-2010-GernEdiT - The GermaNet Editing Tool</a></p>
<p>9 0.35104561 <a title="121-lsi-9" href="./acl-2010-Detecting_Experiences_from_Weblogs.html">85 acl-2010-Detecting Experiences from Weblogs</a></p>
<p>10 0.3464978 <a title="121-lsi-10" href="./acl-2010-Computing_Weakest_Readings.html">67 acl-2010-Computing Weakest Readings</a></p>
<p>11 0.31902257 <a title="121-lsi-11" href="./acl-2010-Learning_Arguments_and_Supertypes_of_Semantic_Relations_Using_Recursive_Patterns.html">160 acl-2010-Learning Arguments and Supertypes of Semantic Relations Using Recursive Patterns</a></p>
<p>12 0.31040108 <a title="121-lsi-12" href="./acl-2010-Towards_Open-Domain_Semantic_Role_Labeling.html">238 acl-2010-Towards Open-Domain Semantic Role Labeling</a></p>
<p>13 0.31008756 <a title="121-lsi-13" href="./acl-2010-Automatic_Selectional_Preference_Acquisition_for_Latin_Verbs.html">41 acl-2010-Automatic Selectional Preference Acquisition for Latin Verbs</a></p>
<p>14 0.30313313 <a title="121-lsi-14" href="./acl-2010-Knowledge-Rich_Word_Sense_Disambiguation_Rivaling_Supervised_Systems.html">156 acl-2010-Knowledge-Rich Word Sense Disambiguation Rivaling Supervised Systems</a></p>
<p>15 0.29369736 <a title="121-lsi-15" href="./acl-2010-Don%27t_%27Have_a_Clue%27%3F_Unsupervised_Co-Learning_of_Downward-Entailing_Operators..html">92 acl-2010-Don't 'Have a Clue'? Unsupervised Co-Learning of Downward-Entailing Operators.</a></p>
<p>16 0.28966415 <a title="121-lsi-16" href="./acl-2010-BabelNet%3A_Building_a_Very_Large_Multilingual_Semantic_Network.html">44 acl-2010-BabelNet: Building a Very Large Multilingual Semantic Network</a></p>
<p>17 0.28549311 <a title="121-lsi-17" href="./acl-2010-Learning_Script_Knowledge_with_Web_Experiments.html">165 acl-2010-Learning Script Knowledge with Web Experiments</a></p>
<p>18 0.28256622 <a title="121-lsi-18" href="./acl-2010-Unsupervised_Ontology_Induction_from_Text.html">248 acl-2010-Unsupervised Ontology Induction from Text</a></p>
<p>19 0.27293789 <a title="121-lsi-19" href="./acl-2010-Plot_Induction_and_Evolutionary_Search_for_Story_Generation.html">196 acl-2010-Plot Induction and Evolutionary Search for Story Generation</a></p>
<p>20 0.27251136 <a title="121-lsi-20" href="./acl-2010-Predicate_Argument_Structure_Analysis_Using_Transformation_Based_Learning.html">198 acl-2010-Predicate Argument Structure Analysis Using Transformation Based Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.01), (25, 0.087), (39, 0.013), (42, 0.026), (44, 0.013), (59, 0.088), (61, 0.25), (72, 0.031), (73, 0.098), (78, 0.043), (80, 0.079), (83, 0.054), (84, 0.032), (98, 0.079)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.79876393 <a title="121-lda-1" href="./acl-2010-Generating_Entailment_Rules_from_FrameNet.html">121 acl-2010-Generating Entailment Rules from FrameNet</a></p>
<p>Author: Roni Ben Aharon ; Idan Szpektor ; Ido Dagan</p><p>Abstract: Idan Szpektor Ido Dagan Yahoo! Research Department of Computer Science Haifa, Israel Bar-Ilan University idan @ yahoo- inc .com Ramat Gan, Israel dagan @ c s .biu . ac . i l FrameNet is a manually constructed database based on Frame Semantics. It models the semantic Many NLP tasks need accurate knowledge for semantic inference. To this end, mostly WordNet is utilized. Yet WordNet is limited, especially for inference be- tween predicates. To help filling this gap, we present an algorithm that generates inference rules between predicates from FrameNet. Our experiment shows that the novel resource is effective and complements WordNet in terms of rule coverage.</p><p>2 0.64096856 <a title="121-lda-2" href="./acl-2010-Generating_Image_Descriptions_Using_Dependency_Relational_Patterns.html">124 acl-2010-Generating Image Descriptions Using Dependency Relational Patterns</a></p>
<p>Author: Ahmet Aker ; Robert Gaizauskas</p><p>Abstract: This paper presents a novel approach to automatic captioning of geo-tagged images by summarizing multiple webdocuments that contain information related to an image’s location. The summarizer is biased by dependency pattern models towards sentences which contain features typically provided for different scene types such as those of churches, bridges, etc. Our results show that summaries biased by dependency pattern models lead to significantly higher ROUGE scores than both n-gram language models reported in previous work and also Wikipedia baseline summaries. Summaries generated using dependency patterns also lead to more readable summaries than those generated without dependency patterns.</p><p>3 0.58591431 <a title="121-lda-3" href="./acl-2010-A_Taxonomy%2C_Dataset%2C_and_Classifier_for_Automatic_Noun_Compound_Interpretation.html">19 acl-2010-A Taxonomy, Dataset, and Classifier for Automatic Noun Compound Interpretation</a></p>
<p>Author: Stephen Tratz ; Eduard Hovy</p><p>Abstract: The automatic interpretation of noun-noun compounds is an important subproblem within many natural language processing applications and is an area of increasing interest. The problem is difficult, with disagreement regarding the number and nature of the relations, low inter-annotator agreement, and limited annotated data. In this paper, we present a novel taxonomy of relations that integrates previous relations, the largest publicly-available annotated dataset, and a supervised classification method for automatic noun compound interpretation.</p><p>4 0.57855642 <a title="121-lda-4" href="./acl-2010-Improving_Chinese_Semantic_Role_Labeling_with_Rich_Syntactic_Features.html">146 acl-2010-Improving Chinese Semantic Role Labeling with Rich Syntactic Features</a></p>
<p>Author: Weiwei Sun</p><p>Abstract: Developing features has been shown crucial to advancing the state-of-the-art in Semantic Role Labeling (SRL). To improve Chinese SRL, we propose a set of additional features, some of which are designed to better capture structural information. Our system achieves 93.49 Fmeasure, a significant improvement over the best reported performance 92.0. We are further concerned with the effect of parsing in Chinese SRL. We empirically analyze the two-fold effect, grouping words into constituents and providing syntactic information. We also give some preliminary linguistic explanations.</p><p>5 0.5768795 <a title="121-lda-5" href="./acl-2010-Fine-Grained_Tree-to-String_Translation_Rule_Extraction.html">118 acl-2010-Fine-Grained Tree-to-String Translation Rule Extraction</a></p>
<p>Author: Xianchao Wu ; Takuya Matsuzaki ; Jun'ichi Tsujii</p><p>Abstract: Tree-to-string translation rules are widely used in linguistically syntax-based statistical machine translation systems. In this paper, we propose to use deep syntactic information for obtaining fine-grained translation rules. A head-driven phrase structure grammar (HPSG) parser is used to obtain the deep syntactic information, which includes a fine-grained description of the syntactic property and a semantic representation of a sentence. We extract fine-grained rules from aligned HPSG tree/forest-string pairs and use them in our tree-to-string and string-to-tree systems. Extensive experiments on largescale bidirectional Japanese-English trans- lations testified the effectiveness of our approach.</p><p>6 0.56311917 <a title="121-lda-6" href="./acl-2010-Adapting_Self-Training_for_Semantic_Role_Labeling.html">25 acl-2010-Adapting Self-Training for Semantic Role Labeling</a></p>
<p>7 0.56292039 <a title="121-lda-7" href="./acl-2010-Towards_Open-Domain_Semantic_Role_Labeling.html">238 acl-2010-Towards Open-Domain Semantic Role Labeling</a></p>
<p>8 0.55749482 <a title="121-lda-8" href="./acl-2010-Assessing_the_Role_of_Discourse_References_in_Entailment_Inference.html">33 acl-2010-Assessing the Role of Discourse References in Entailment Inference</a></p>
<p>9 0.54062402 <a title="121-lda-9" href="./acl-2010-WebLicht%3A_Web-Based_LRT_Services_for_German.html">259 acl-2010-WebLicht: Web-Based LRT Services for German</a></p>
<p>10 0.53521323 <a title="121-lda-10" href="./acl-2010-Extraction_and_Approximation_of_Numerical_Attributes_from_the_Web.html">113 acl-2010-Extraction and Approximation of Numerical Attributes from the Web</a></p>
<p>11 0.52912831 <a title="121-lda-11" href="./acl-2010-Unsupervised_Ontology_Induction_from_Text.html">248 acl-2010-Unsupervised Ontology Induction from Text</a></p>
<p>12 0.52811205 <a title="121-lda-12" href="./acl-2010-Grammar_Prototyping_and_Testing_with_the_LinGO_Grammar_Matrix_Customization_System.html">128 acl-2010-Grammar Prototyping and Testing with the LinGO Grammar Matrix Customization System</a></p>
<p>13 0.52805328 <a title="121-lda-13" href="./acl-2010-Using_Anaphora_Resolution_to_Improve_Opinion_Target_Identification_in_Movie_Reviews.html">251 acl-2010-Using Anaphora Resolution to Improve Opinion Target Identification in Movie Reviews</a></p>
<p>14 0.52744281 <a title="121-lda-14" href="./acl-2010-Latent_Variable_Models_of_Selectional_Preference.html">158 acl-2010-Latent Variable Models of Selectional Preference</a></p>
<p>15 0.52733076 <a title="121-lda-15" href="./acl-2010-Conditional_Random_Fields_for_Word_Hyphenation.html">68 acl-2010-Conditional Random Fields for Word Hyphenation</a></p>
<p>16 0.52654922 <a title="121-lda-16" href="./acl-2010-BabelNet%3A_Building_a_Very_Large_Multilingual_Semantic_Network.html">44 acl-2010-BabelNet: Building a Very Large Multilingual Semantic Network</a></p>
<p>17 0.52586323 <a title="121-lda-17" href="./acl-2010-Accurate_Context-Free_Parsing_with_Combinatory_Categorial_Grammar.html">23 acl-2010-Accurate Context-Free Parsing with Combinatory Categorial Grammar</a></p>
<p>18 0.52546579 <a title="121-lda-18" href="./acl-2010-Models_of_Metaphor_in_NLP.html">175 acl-2010-Models of Metaphor in NLP</a></p>
<p>19 0.52538794 <a title="121-lda-19" href="./acl-2010-Learning_Arguments_and_Supertypes_of_Semantic_Relations_Using_Recursive_Patterns.html">160 acl-2010-Learning Arguments and Supertypes of Semantic Relations Using Recursive Patterns</a></p>
<p>20 0.52393925 <a title="121-lda-20" href="./acl-2010-Learning_to_Translate_with_Source_and_Target_Syntax.html">169 acl-2010-Learning to Translate with Source and Target Syntax</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
