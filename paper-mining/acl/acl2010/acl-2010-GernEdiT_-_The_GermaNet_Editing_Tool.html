<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>126 acl-2010-GernEdiT - The GermaNet Editing Tool</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-126" href="#">acl2010-126</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>126 acl-2010-GernEdiT - The GermaNet Editing Tool</h1>
<br/><p>Source: <a title="acl-2010-126-pdf" href="http://aclweb.org/anthology//P/P10/P10-4004.pdf">pdf</a></p><p>Author: Verena Henrich ; Erhard Hinrichs</p><p>Abstract: GernEdiT (short for: GermaNet Editing Tool) offers a graphical interface for the lexicographers and developers of GermaNet to access and modify the underlying GermaNet resource. GermaNet is a lexical-semantic wordnet that is modeled after the Princeton WordNet for English. The traditional lexicographic development of GermaNet was error prone and time-consuming, mainly due to a complex underlying data format and no opportunity of automatic consistency checks. GernEdiT replaces the earlier development by a more userfriendly tool, which facilitates automatic checking of internal consistency and correctness of the linguistic resource. This paper pre- sents all these core functionalities of GernEdiT along with details about its usage and usability. 1</p><p>Reference: <a title="acl-2010-126-reference" href="../acl2010_reference/acl-2010-GernEdiT_-_The_GermaNet_Editing_Tool_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Abstract GernEdiT (short for: GermaNet Editing Tool) offers a graphical interface for the lexicographers and developers of GermaNet to access and modify the underlying GermaNet resource. [sent-4, score-0.283]
</p><p>2 GermaNet is a lexical-semantic wordnet that is modeled after the Princeton WordNet for English. [sent-5, score-0.033]
</p><p>3 The traditional lexicographic development of GermaNet was error prone and time-consuming, mainly due to a complex underlying data format and no opportunity of automatic consistency checks. [sent-6, score-0.208]
</p><p>4 GernEdiT replaces the earlier development by a more userfriendly tool, which facilitates automatic checking of internal consistency and correctness of the linguistic resource. [sent-7, score-0.172]
</p><p>5 This paper pre-  sents all these core functionalities of GernEdiT along with details about its usage and usability. [sent-8, score-0.089]
</p><p>6 GernEdiT replaces the traditional GermaNet development based on lexicographer files (Fellbaum, 1998) by a more user-friendly visual tool that supports versioning and collaborative annotation by several lexicographers working in parallel. [sent-10, score-0.492]
</p><p>7 Furthermore, GernEdiT facilitates internal consistency of the GermaNet data such as appropriate linking of lexical units with synsets, connectedness of the synset graph, and automatic  Erhard Hinrichs University of Tübingen Tübingen, Germany. [sent-11, score-0.683]
</p><p>8 All these functionalities along with the main aspects of GernEdiT’s usage and usability are presented in this paper. [sent-15, score-0.111]
</p><p>9 2  The Structure of GermaNet  GermaNet is a lexical-semantic wordnet that is modeled after the Princeton WordNet for English (Fellbaum, 1998). [sent-16, score-0.033]
</p><p>10 It covers the three word categories of adjectives, nouns, and verbs and partitions the lexical space into a set of concepts that are interlinked by semantic relations. [sent-17, score-0.103]
</p><p>11 A synset is a set of words (called lexical units) where all the words are taken to have (almost) the same meaning. [sent-19, score-0.375]
</p><p>12 Thus a synset is a set-representation of the  semantic relation of synonymy, which means that it consists of a list of lexical units. [sent-20, score-0.375]
</p><p>13 There are two types of semantic relations in GermaNet: conceptual and lexical relations. [sent-21, score-0.231]
</p><p>14 They include relations such as hyperonymy, part-whole relations, entailment, or causation. [sent-25, score-0.058]
</p><p>15 GermaNet is hierarchically structured in terms of the hyperonymy relation. [sent-26, score-0.034]
</p><p>16 Antonymy, a pair of opposites, is an example of a lexical relation. [sent-28, score-0.084]
</p><p>17 The editor represents an interface to a relational database, where all GermaNet data is stored from now on. [sent-30, score-0.114]
</p><p>18 1  Motivation  The traditional lexicographic development of GermaNet was error prone and time-consuming, mainly due to a complex underlying data format and no opportunity of automatic consistency checks. [sent-36, score-0.208]
</p><p>19 This is exactly why GernEdiT was developed: It supports lexicographers who need to access, modify, and extend GermaNet data by  providing these functions through simple buttonclicks, searches, and form editing. [sent-37, score-0.277]
</p><p>20 These functionalities allow lexicographers, among other things, to find the appropriate place in the hierarchy for the insertion of new synsets and lexical units. [sent-39, score-0.442]
</p><p>21 Last but not least, GernEdiT facilitates internal consistency and correctness of the linguistic resource and supports versioning and collaborative annotation of GermaNet by several lexicographers working in parallel. [sent-40, score-0.506]
</p><p>22 2  The Main User Interface  Figure 1 illustrates the main user panel of GernEdiT. [sent-42, score-0.137]
</p><p>23 It shows a Search panel above, two panels for Synsets and Lexical Units in the middle, and four tabs below: a Conceptual Relations Editor, a Graph with Hyperonyms and Hyponyms, a Lexi20  Figure 2: Filtered list of lexical units. [sent-43, score-0.274]
</p><p>24 In Figure 1, a search for synsets consisting of lexical units with the word Nuss (German noun for: nut) has been executed. [sent-45, score-0.361]
</p><p>25 Accordingly, the Synsets panel displays the three resulting synsets that match the search item. [sent-46, score-0.299]
</p><p>26 Word Category specifies whether a synset is an adjective (adj), a noun (nomen), or a verb (verben), whereas Word Class classifies the synsets into semantic fields. [sent-48, score-0.475]
</p><p>27 The word class of the selected synset in Figure 1 is Nahrung (German noun for: food). [sent-49, score-0.291]
</p><p>28 , for the selected synset the paraphrase is: der essbare Kern einer Nuss (German phrase for: the edible kernel of a nut). [sent-52, score-0.291]
</p><p>29 The column All Orth Forms simply lists all orthographical variants of all its lexical units. [sent-53, score-0.125]
</p><p>30 Which lexical units are listed in the Lexical Units panel depends on the selected synset in the Synsets panel. [sent-54, score-0.583]
</p><p>31 Orth Form (short for: orthographic form) represents the correct spelling of a word according to the rules of the spelling reform Neue Deutsche Rechtschreibung (Rat für deutsche Rechtschreibung, 2006), a recently adopted spelling reform. [sent-56, score-0.329]
</p><p>32 In our example, the main orthographic form is Nuss. [sent-57, score-0.073]
</p><p>33 Orth Var may contain an alternative spelling that is admissible according to the Neue Deutsche Rechtschreibung. [sent-58, score-0.063]
</p><p>34 Old Orth Form represents the main orthographic form prior to the Neue Deutsche Rechtschreibung. [sent-59, score-0.073]
</p><p>35 This means that Nuß was the correct spelling instead of Nuss before the German spelling reform. [sent-60, score-0.126]
</p><p>36 The Boolean values Named Entity, Artificial, and Style Marking express further properties of a lexical unit, whether the lexical unit is a named entity, an artificial concept node, or a stylistic variant. [sent-63, score-0.26]
</p><p>37 For both the lexical units and the synsets, there are two buttons Use as From and Use as To, which help to add new relations (see the explanation of Figure 3 in section 3. [sent-64, score-0.314]
</p><p>38 3  Search Functionalities  It is possible to search for words or synset database IDs via the search panel (see Figure 1 at the top). [sent-67, score-0.438]
</p><p>39 The check box Ignore Case offers the possibility of searching without distinguishing between upper and lower case. [sent-68, score-0.057]
</p><p>40 Apart from the main form Delfin, there is an orthographic variant Delphin. [sent-70, score-0.073]
</p><p>41 Via the file menu, lists of all synsets or lexical units with their properties can be accessed. [sent-73, score-0.361]
</p><p>42 , filtering the lexical units or synsets by parts of their orthographical forms. [sent-76, score-0.402]
</p><p>43 Only verbs that have a frame that contains NN are chosen (see Frame contains check box and corresponding text field). [sent-78, score-0.117]
</p><p>44 Furthermore, the resulting filtered list is sorted in descending order by their examples (see the little triangle in the Examples header of the result table). [sent-79, score-0.04]
</p><p>45 The number in the brackets behind the word category in the tab title indicates the count of the filtered  lexical units (in this example 193 verbs pass the filter). [sent-80, score-0.308]
</p><p>46 4 Visualization of the Graph Hierarchy There is the possibility to display a graph with all hyperonyms and hyponyms of a selected synset. [sent-82, score-0.181]
</p><p>47 This is shown in the bottom half of Figure 1 in the tab Graph with Hyperonyms and Hyponyms. [sent-83, score-0.092]
</p><p>48 The graph in Figure 1 visualizes a part of the hierarchical structure of GermaNet centered around the synset containing Nuss and displays the hyperonyms and hyponyms of this synset up to a certain parameterized depth (in this case depth 2 has been chosen). [sent-84, score-0.819]
</p><p>49 The Hyperonym Depth chooser allows unfolding the graph to the top up to the preselected depth. [sent-85, score-0.053]
</p><p>50 As it is not possible to visualize the whole GermaNet contents at once, the graph can be seen as a window to GermaNet. [sent-86, score-0.073]
</p><p>51 A click on any synset node within the graph, navigates to that synset. [sent-87, score-0.324]
</p><p>52 This functionality supports lexicographers especially in finding the appropriate place in the hierarchy for the insertion of new synsets. [sent-88, score-0.383]
</p><p>53 5  Modifications of Existing Items  If the lexicographers’ task is to modify existing synsets or lexical units, this is done by selecting a synset or lexical unit displayed in the Synsets and the Lexical Units panels shown in Figure 1. [sent-90, score-0.796]
</p><p>54 For example by clicking in the cell Orth Form the spelling of a lexical unit can be corrected in case of an earlier typo was made. [sent-92, score-0.297]
</p><p>55 If lexicographers want to edit examples, frames, conceptual, or lexical relations this is done by choosing the appropriate tab indicated at the bottom of Figure 1. [sent-93, score-0.494]
</p><p>56 By clicking one of these tabs, the corresponding panel appears below these tabs. [sent-94, score-0.173]
</p><p>57 In Figure 1 the panel for Graph with Hyperonyms and Hyponyms is displayed. [sent-95, score-0.115]
</p><p>58 It is possible to edit the examples and frames associated with a lexical unit via the Examples and Frames tab. [sent-96, score-0.259]
</p><p>59 Frames specify the syntactic valence of a lexical unit. [sent-97, score-0.084]
</p><p>60 Each frame can have an associated example that indicates a possible usage of the lexical unit for that particular frame. [sent-98, score-0.197]
</p><p>61 The tab Examples and Frames is thus particularly geared towards the editing of verb entries. [sent-99, score-0.236]
</p><p>62 By clicking on the tab all examples and frames  of a lexical unit are listed and can then be modified by choosing the appropriate editing buttons. [sent-100, score-0.581]
</p><p>63 For more information about these editing functions see Henrich and Hinrichs (2010). [sent-101, score-0.144]
</p><p>64 6 Editing of Relations If lexicographers want to add new conceptual or lexical relations to a synset or a lexical unit this is done by clicking on the Conceptual Relations Editor or the Lexical Relations Editor shown in Figure 1. [sent-103, score-1.007]
</p><p>65 Figure 3 shows the panel that appears if the Conceptual Relations Editor has been chosen for the synset containing Nuss. [sent-104, score-0.426]
</p><p>66 To create a new relation, the lexicographer needs to use the buttons Use as From and Use as To shown in Figure 1. [sent-105, score-0.128]
</p><p>67 This will insert the ID of the selected synsets from the Synsets panel in the corresponding  From or To field in Figure 3. [sent-106, score-0.362]
</p><p>68 The button Delete ConRel allows deletion of a conceptual relation, if all consistency checks are passed. [sent-107, score-0.267]
</p><p>69 The Lexical Relations Editor tab supports editing all lexical relations. [sent-108, score-0.365]
</p><p>70 It is not displayed separately for reasons of space, but it is analogue to the Conceptual Relations Editor tab for editing conceptual relations. [sent-109, score-0.325]
</p><p>71 When clicking on the button Create Synset, the Lexical Unit Editor (shown in Figure 4, right) pops up. [sent-113, score-0.104]
</p><p>72 This workflow forces the parallel creation of a lexical unit while creating a synset. [sent-114, score-0.176]
</p><p>73 8  Consistency Checks  GernEdiT facilitates internal consistency of the workflow-oriented design of the editor. [sent-116, score-0.149]
</p><p>74 It is not possible to create a synset without creating a lexical unit in parallel (as described in section 3. [sent-117, score-0.467]
</p><p>75 Furthermore, it is not possible to insert a new synset without specifying the place in the GermaNet hierarchy where the new synset should be added. [sent-119, score-0.68]
</p><p>76 This is achieved by the button Add New Hyponym (see Figure 1) which forces the user to identify the appropriate hyperonym for the new synset to be added. [sent-120, score-0.399]
</p><p>77 Furthermore, it is not possible to insert a lexical unit without specifying the corresponding synset. [sent-121, score-0.217]
</p><p>78 On deletion of a synset, all corresponding data such as conceptual relations, lexical units with their lexical relations, frames, and examples, are deleted automatically. [sent-122, score-0.377]
</p><p>79 Consistency checks also take effect for the table cell editing in the Synsets and Lexical Units panels of the main user interface (see Figure 1), e. [sent-123, score-0.264]
</p><p>80 , the main orthographic form of a lexical unit may never be empty. [sent-125, score-0.249]
</p><p>81 All buttons in GernEdiT are enabled only if the corresponding functionalities meet the consistency requirements, e. [sent-126, score-0.228]
</p><p>82 , if a synset consists only of one lexical unit, it is not possible to de-  lete that lexical unit and thus the button Delete LexUnit is disabled. [sent-128, score-0.597]
</p><p>83 Also, if the deletion of a synset or a relation would violate the complete connectedness of the GermaNet graph, it is not possible to delete that synset. [sent-129, score-0.402]
</p><p>84 9  Further Functionalities  There are further functionalities available through the file menu. [sent-131, score-0.089]
</p><p>85 Besides retrieving the upto-date statistics of GermaNet, an editing history makes it possible to list all modifications on the GermaNet data, with the information about who made the change and how the modified item looked before. [sent-132, score-0.144]
</p><p>86 For example, it is possible to export all GermaNet  data. [sent-134, score-0.045]
</p><p>87 This  is  achieved  by  GermaNet contents into XML files, which are  the  used as an exchange  format of GermaNet, or to  23  export a list of all verbs with their corresponding frames and examples. [sent-135, score-0.172]
</p><p>88 4  Tool Evaluation  In order to assess the usefulness of GernEdiT, we conducted in depth interviews with the Germa-  Net lexicographers and with the senior researcher who oversees all lexicographic development. [sent-136, score-0.349]
</p><p>89 At the time of the interview all of these researchers had worked with the tool for about eight months. [sent-137, score-0.067]
</p><p>90 The initial learning curve for getting familiar with GernEdiT is considerably lower compared to the learning curve required for the traditional development based on lexicographer files. [sent-139, score-0.091]
</p><p>91 The menu-driven and graphics-based navigation through the GermaNet graph is much easier compared to finding the correct entry point in the purely text-based format of lexicographer files. [sent-141, score-0.169]
</p><p>92 Lexicographers no longer need to learn the complex specification syntax of the lexicographer files. [sent-143, score-0.068]
</p><p>93 GernEdiT facilitates automatic checking of internal consistency and correctness of the GermaNet data such as appropriate linking of lexical units with synsets, connectedness of the synset graph, and automatic closure among relations and their inverse counterparts. [sent-146, score-0.785]
</p><p>94 Especially for the senior researcher who is responsible for coordinating the GermaNet lexicographers, it is now much easier to trace back changes and to verify who was responsible for them. [sent-152, score-0.056]
</p><p>95 The collaborative annotation by several lexicographers working in parallel is now easily possible and does not cause any management overhead as before. [sent-154, score-0.255]
</p><p>96 In sum, the lexicographers of GermaNet gave very positive feedback about the use of GernEdiT and also made smaller suggestions for improving its user-friendliness further. [sent-155, score-0.253]
</p><p>97 The extremely positive feedback of the GermaNet lexicographers underscores the practical benefits gained by using the GernEdiT tool in practice. [sent-158, score-0.35]
</p><p>98 In future work, we plan to adapt the tool so that it can be used with wordnets for other languages as well. [sent-160, score-0.067]
</p><p>99 This would mean that the wordnet data for a given language would have to be stored in a relational database and that the tool itself can handle the language specific data structures of the wordnet in question. [sent-161, score-0.165]
</p><p>100 Acknowledgements We would like to thank all GermaNet lexicographers for their willingness to experiment with GernEdiT and to be interviewed about their experiences with the tool. [sent-162, score-0.232]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('germanet', 0.587), ('gernedit', 0.459), ('synset', 0.291), ('lexicographers', 0.232), ('synsets', 0.184), ('editing', 0.144), ('panel', 0.115), ('orth', 0.104), ('units', 0.093), ('tab', 0.092), ('unit', 0.092), ('deutsche', 0.089), ('functionalities', 0.089), ('conceptual', 0.089), ('hyperonyms', 0.085), ('lexical', 0.084), ('editor', 0.083), ('consistency', 0.079), ('lexicographer', 0.068), ('henrich', 0.068), ('neue', 0.068), ('nuss', 0.068), ('rechtschreibung', 0.068), ('tool', 0.067), ('spelling', 0.063), ('frames', 0.063), ('buttons', 0.06), ('relations', 0.058), ('clicking', 0.058), ('graph', 0.053), ('orthographic', 0.051), ('lexunit', 0.051), ('bingen', 0.048), ('button', 0.046), ('delete', 0.046), ('supports', 0.045), ('export', 0.045), ('verena', 0.045), ('facilitates', 0.044), ('hyponyms', 0.043), ('insert', 0.041), ('orthographical', 0.041), ('erhard', 0.041), ('panels', 0.041), ('var', 0.038), ('connectedness', 0.038), ('hinrichs', 0.038), ('box', 0.034), ('delfin', 0.034), ('hyperonym', 0.034), ('hyperonymy', 0.034), ('tabs', 0.034), ('tuebingen', 0.034), ('versioning', 0.034), ('lexicographic', 0.033), ('click', 0.033), ('wordnet', 0.033), ('id', 0.033), ('database', 0.032), ('hierarchy', 0.032), ('interface', 0.031), ('kunze', 0.03), ('underscores', 0.03), ('researcher', 0.03), ('german', 0.029), ('appropriate', 0.028), ('depth', 0.028), ('prone', 0.027), ('deletion', 0.027), ('internal', 0.026), ('checks', 0.026), ('senior', 0.026), ('place', 0.025), ('format', 0.025), ('nut', 0.024), ('collaborative', 0.023), ('correctness', 0.023), ('rat', 0.023), ('navigation', 0.023), ('check', 0.023), ('traditional', 0.023), ('main', 0.022), ('visualization', 0.022), ('field', 0.022), ('old', 0.022), ('opportunity', 0.021), ('princeton', 0.021), ('functionality', 0.021), ('closure', 0.021), ('uni', 0.021), ('frame', 0.021), ('feedback', 0.021), ('filtered', 0.02), ('contents', 0.02), ('fellbaum', 0.02), ('chosen', 0.02), ('modify', 0.02), ('examples', 0.02), ('verbs', 0.019), ('add', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="126-tfidf-1" href="./acl-2010-GernEdiT_-_The_GermaNet_Editing_Tool.html">126 acl-2010-GernEdiT - The GermaNet Editing Tool</a></p>
<p>Author: Verena Henrich ; Erhard Hinrichs</p><p>Abstract: GernEdiT (short for: GermaNet Editing Tool) offers a graphical interface for the lexicographers and developers of GermaNet to access and modify the underlying GermaNet resource. GermaNet is a lexical-semantic wordnet that is modeled after the Princeton WordNet for English. The traditional lexicographic development of GermaNet was error prone and time-consuming, mainly due to a complex underlying data format and no opportunity of automatic consistency checks. GernEdiT replaces the earlier development by a more userfriendly tool, which facilitates automatic checking of internal consistency and correctness of the linguistic resource. This paper pre- sents all these core functionalities of GernEdiT along with details about its usage and usability. 1</p><p>2 0.16196766 <a title="126-tfidf-2" href="./acl-2010-BabelNet%3A_Building_a_Very_Large_Multilingual_Semantic_Network.html">44 acl-2010-BabelNet: Building a Very Large Multilingual Semantic Network</a></p>
<p>Author: Roberto Navigli ; Simone Paolo Ponzetto</p><p>Abstract: In this paper we present BabelNet a very large, wide-coverage multilingual semantic network. The resource is automatically constructed by means of a methodology that integrates lexicographic and encyclopedic knowledge from WordNet and Wikipedia. In addition Machine Translation is also applied to enrich the resource with lexical information for all languages. We conduct experiments on new and existing gold-standard datasets to show the high quality and coverage of the resource. –</p><p>3 0.063113786 <a title="126-tfidf-3" href="./acl-2010-Knowledge-Rich_Word_Sense_Disambiguation_Rivaling_Supervised_Systems.html">156 acl-2010-Knowledge-Rich Word Sense Disambiguation Rivaling Supervised Systems</a></p>
<p>Author: Simone Paolo Ponzetto ; Roberto Navigli</p><p>Abstract: One of the main obstacles to highperformance Word Sense Disambiguation (WSD) is the knowledge acquisition bottleneck. In this paper, we present a methodology to automatically extend WordNet with large amounts of semantic relations from an encyclopedic resource, namely Wikipedia. We show that, when provided with a vast amount of high-quality semantic relations, simple knowledge-lean disambiguation algorithms compete with state-of-the-art supervised WSD systems in a coarse-grained all-words setting and outperform them on gold-standard domain-specific datasets.</p><p>4 0.049999364 <a title="126-tfidf-4" href="./acl-2010-Automatic_Selectional_Preference_Acquisition_for_Latin_Verbs.html">41 acl-2010-Automatic Selectional Preference Acquisition for Latin Verbs</a></p>
<p>Author: Barbara McGillivray</p><p>Abstract: We present a system that automatically induces Selectional Preferences (SPs) for Latin verbs from two treebanks by using Latin WordNet. Our method overcomes some of the problems connected with data sparseness and the small size of the input corpora. We also suggest a way to evaluate the acquired SPs on unseen events extracted from other Latin corpora.</p><p>5 0.048471153 <a title="126-tfidf-5" href="./acl-2010-Topic_Models_for_Word_Sense_Disambiguation_and_Token-Based_Idiom_Detection.html">237 acl-2010-Topic Models for Word Sense Disambiguation and Token-Based Idiom Detection</a></p>
<p>Author: Linlin Li ; Benjamin Roth ; Caroline Sporleder</p><p>Abstract: This paper presents a probabilistic model for sense disambiguation which chooses the best sense based on the conditional probability of sense paraphrases given a context. We use a topic model to decompose this conditional probability into two conditional probabilities with latent variables. We propose three different instantiations of the model for solving sense disambiguation problems with different degrees of resource availability. The proposed models are tested on three different tasks: coarse-grained word sense disambiguation, fine-grained word sense disambiguation, and detection of literal vs. nonliteral usages of potentially idiomatic expressions. In all three cases, we outper- form state-of-the-art systems either quantitatively or statistically significantly.</p><p>6 0.047577903 <a title="126-tfidf-6" href="./acl-2010-Expanding_Verb_Coverage_in_Cyc_with_VerbNet.html">108 acl-2010-Expanding Verb Coverage in Cyc with VerbNet</a></p>
<p>7 0.045515355 <a title="126-tfidf-7" href="./acl-2010-Learning_Phrase-Based_Spelling_Error_Models_from_Clickthrough_Data.html">164 acl-2010-Learning Phrase-Based Spelling Error Models from Clickthrough Data</a></p>
<p>8 0.043386247 <a title="126-tfidf-8" href="./acl-2010-WebLicht%3A_Web-Based_LRT_Services_for_German.html">259 acl-2010-WebLicht: Web-Based LRT Services for German</a></p>
<p>9 0.035079442 <a title="126-tfidf-9" href="./acl-2010-Contextualizing_Semantic_Representations_Using_Syntactically_Enriched_Vector_Models.html">70 acl-2010-Contextualizing Semantic Representations Using Syntactically Enriched Vector Models</a></p>
<p>10 0.033465691 <a title="126-tfidf-10" href="./acl-2010-An_Active_Learning_Approach_to_Finding_Related_Terms.html">27 acl-2010-An Active Learning Approach to Finding Related Terms</a></p>
<p>11 0.033116519 <a title="126-tfidf-11" href="./acl-2010-Global_Learning_of_Focused_Entailment_Graphs.html">127 acl-2010-Global Learning of Focused Entailment Graphs</a></p>
<p>12 0.032760911 <a title="126-tfidf-12" href="./acl-2010-Generating_Entailment_Rules_from_FrameNet.html">121 acl-2010-Generating Entailment Rules from FrameNet</a></p>
<p>13 0.030212557 <a title="126-tfidf-13" href="./acl-2010-Edit_Tree_Distance_Alignments_for_Semantic_Role_Labelling.html">94 acl-2010-Edit Tree Distance Alignments for Semantic Role Labelling</a></p>
<p>14 0.029920736 <a title="126-tfidf-14" href="./acl-2010-Weakly_Supervised_Learning_of_Presupposition_Relations_between_Verbs.html">258 acl-2010-Weakly Supervised Learning of Presupposition Relations between Verbs</a></p>
<p>15 0.02989888 <a title="126-tfidf-15" href="./acl-2010-Combining_Orthogonal_Monolingual_and_Multilingual_Sources_of_Evidence_for_All_Words_WSD.html">62 acl-2010-Combining Orthogonal Monolingual and Multilingual Sources of Evidence for All Words WSD</a></p>
<p>16 0.028891437 <a title="126-tfidf-16" href="./acl-2010-An_Open-Source_Package_for_Recognizing_Textual_Entailment.html">30 acl-2010-An Open-Source Package for Recognizing Textual Entailment</a></p>
<p>17 0.026504621 <a title="126-tfidf-17" href="./acl-2010-All_Words_Domain_Adapted_WSD%3A_Finding_a_Middle_Ground_between_Supervision_and_Unsupervision.html">26 acl-2010-All Words Domain Adapted WSD: Finding a Middle Ground between Supervision and Unsupervision</a></p>
<p>18 0.025877912 <a title="126-tfidf-18" href="./acl-2010-Detecting_Experiences_from_Weblogs.html">85 acl-2010-Detecting Experiences from Weblogs</a></p>
<p>19 0.025789643 <a title="126-tfidf-19" href="./acl-2010-Creating_Robust_Supervised_Classifiers_via_Web-Scale_N-Gram_Data.html">76 acl-2010-Creating Robust Supervised Classifiers via Web-Scale N-Gram Data</a></p>
<p>20 0.025347203 <a title="126-tfidf-20" href="./acl-2010-Automated_Planning_for_Situated_Natural_Language_Generation.html">35 acl-2010-Automated Planning for Situated Natural Language Generation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.077), (1, 0.041), (2, -0.017), (3, -0.022), (4, 0.084), (5, -0.001), (6, 0.041), (7, 0.052), (8, -0.044), (9, -0.001), (10, 0.007), (11, -0.006), (12, -0.027), (13, 0.014), (14, -0.013), (15, 0.001), (16, 0.025), (17, 0.067), (18, 0.029), (19, 0.048), (20, -0.034), (21, -0.007), (22, 0.029), (23, -0.024), (24, 0.058), (25, -0.012), (26, -0.015), (27, 0.039), (28, -0.015), (29, -0.058), (30, 0.011), (31, 0.011), (32, 0.072), (33, -0.06), (34, 0.046), (35, -0.101), (36, -0.026), (37, 0.012), (38, -0.014), (39, -0.0), (40, 0.033), (41, -0.022), (42, -0.03), (43, 0.008), (44, -0.048), (45, 0.012), (46, -0.083), (47, 0.031), (48, -0.099), (49, 0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92906487 <a title="126-lsi-1" href="./acl-2010-GernEdiT_-_The_GermaNet_Editing_Tool.html">126 acl-2010-GernEdiT - The GermaNet Editing Tool</a></p>
<p>Author: Verena Henrich ; Erhard Hinrichs</p><p>Abstract: GernEdiT (short for: GermaNet Editing Tool) offers a graphical interface for the lexicographers and developers of GermaNet to access and modify the underlying GermaNet resource. GermaNet is a lexical-semantic wordnet that is modeled after the Princeton WordNet for English. The traditional lexicographic development of GermaNet was error prone and time-consuming, mainly due to a complex underlying data format and no opportunity of automatic consistency checks. GernEdiT replaces the earlier development by a more userfriendly tool, which facilitates automatic checking of internal consistency and correctness of the linguistic resource. This paper pre- sents all these core functionalities of GernEdiT along with details about its usage and usability. 1</p><p>2 0.64075828 <a title="126-lsi-2" href="./acl-2010-Expanding_Verb_Coverage_in_Cyc_with_VerbNet.html">108 acl-2010-Expanding Verb Coverage in Cyc with VerbNet</a></p>
<p>Author: Clifton McFate</p><p>Abstract: A robust dictionary of semantic frames is an essential element of natural language understanding systems that use ontologies. However, creating lexical resources that accurately capture semantic representations en masse is a persistent problem. Where the sheer amount of content makes hand creation inefficient, computerized approaches often suffer from over generality and difficulty with sense disambiguation. This paper describes a semi-automatic method to create verb semantic frames in the Cyc ontology by converting the information contained in VerbNet into a Cyc usable format. This method captures the differences in meaning between types of verbs, and uses existing connections between WordNet, VerbNet, and Cyc to specify distinctions between individual verbs when available. This method provides 27,909 frames to OpenCyc which currently has none and can be used to extend ResearchCyc as well. We show that these frames lead to a 20% increase in sample sentences parsed over the Research Cyc verb lexicon. 1</p><p>3 0.61496687 <a title="126-lsi-3" href="./acl-2010-Automatic_Selectional_Preference_Acquisition_for_Latin_Verbs.html">41 acl-2010-Automatic Selectional Preference Acquisition for Latin Verbs</a></p>
<p>Author: Barbara McGillivray</p><p>Abstract: We present a system that automatically induces Selectional Preferences (SPs) for Latin verbs from two treebanks by using Latin WordNet. Our method overcomes some of the problems connected with data sparseness and the small size of the input corpora. We also suggest a way to evaluate the acquired SPs on unseen events extracted from other Latin corpora.</p><p>4 0.60320598 <a title="126-lsi-4" href="./acl-2010-BabelNet%3A_Building_a_Very_Large_Multilingual_Semantic_Network.html">44 acl-2010-BabelNet: Building a Very Large Multilingual Semantic Network</a></p>
<p>Author: Roberto Navigli ; Simone Paolo Ponzetto</p><p>Abstract: In this paper we present BabelNet a very large, wide-coverage multilingual semantic network. The resource is automatically constructed by means of a methodology that integrates lexicographic and encyclopedic knowledge from WordNet and Wikipedia. In addition Machine Translation is also applied to enrich the resource with lexical information for all languages. We conduct experiments on new and existing gold-standard datasets to show the high quality and coverage of the resource. –</p><p>5 0.53766143 <a title="126-lsi-5" href="./acl-2010-Knowledge-Rich_Word_Sense_Disambiguation_Rivaling_Supervised_Systems.html">156 acl-2010-Knowledge-Rich Word Sense Disambiguation Rivaling Supervised Systems</a></p>
<p>Author: Simone Paolo Ponzetto ; Roberto Navigli</p><p>Abstract: One of the main obstacles to highperformance Word Sense Disambiguation (WSD) is the knowledge acquisition bottleneck. In this paper, we present a methodology to automatically extend WordNet with large amounts of semantic relations from an encyclopedic resource, namely Wikipedia. We show that, when provided with a vast amount of high-quality semantic relations, simple knowledge-lean disambiguation algorithms compete with state-of-the-art supervised WSD systems in a coarse-grained all-words setting and outperform them on gold-standard domain-specific datasets.</p><p>6 0.50231087 <a title="126-lsi-6" href="./acl-2010-Detecting_Experiences_from_Weblogs.html">85 acl-2010-Detecting Experiences from Weblogs</a></p>
<p>7 0.45302129 <a title="126-lsi-7" href="./acl-2010-The_Manually_Annotated_Sub-Corpus%3A_A_Community_Resource_for_and_by_the_People.html">230 acl-2010-The Manually Annotated Sub-Corpus: A Community Resource for and by the People</a></p>
<p>8 0.44417313 <a title="126-lsi-8" href="./acl-2010-Weakly_Supervised_Learning_of_Presupposition_Relations_between_Verbs.html">258 acl-2010-Weakly Supervised Learning of Presupposition Relations between Verbs</a></p>
<p>9 0.43365988 <a title="126-lsi-9" href="./acl-2010-Generating_Entailment_Rules_from_FrameNet.html">121 acl-2010-Generating Entailment Rules from FrameNet</a></p>
<p>10 0.4183563 <a title="126-lsi-10" href="./acl-2010-Learning_Word-Class_Lattices_for_Definition_and_Hypernym_Extraction.html">166 acl-2010-Learning Word-Class Lattices for Definition and Hypernym Extraction</a></p>
<p>11 0.40831324 <a title="126-lsi-11" href="./acl-2010-Wikipedia_as_Sense_Inventory_to_Improve_Diversity_in_Web_Search_Results.html">261 acl-2010-Wikipedia as Sense Inventory to Improve Diversity in Web Search Results</a></p>
<p>12 0.39965698 <a title="126-lsi-12" href="./acl-2010-The_Human_Language_Project%3A_Building_a_Universal_Corpus_of_the_World%27s_Languages.html">226 acl-2010-The Human Language Project: Building a Universal Corpus of the World's Languages</a></p>
<p>13 0.37868336 <a title="126-lsi-13" href="./acl-2010-Structural_Semantic_Relatedness%3A_A_Knowledge-Based_Method_to_Named_Entity_Disambiguation.html">218 acl-2010-Structural Semantic Relatedness: A Knowledge-Based Method to Named Entity Disambiguation</a></p>
<p>14 0.32946166 <a title="126-lsi-14" href="./acl-2010-WebLicht%3A_Web-Based_LRT_Services_for_German.html">259 acl-2010-WebLicht: Web-Based LRT Services for German</a></p>
<p>15 0.31114545 <a title="126-lsi-15" href="./acl-2010-Identifying_Generic_Noun_Phrases.html">139 acl-2010-Identifying Generic Noun Phrases</a></p>
<p>16 0.30722666 <a title="126-lsi-16" href="./acl-2010-Improving_the_Use_of_Pseudo-Words_for_Evaluating_Selectional_Preferences.html">148 acl-2010-Improving the Use of Pseudo-Words for Evaluating Selectional Preferences</a></p>
<p>17 0.30392957 <a title="126-lsi-17" href="./acl-2010-Plot_Induction_and_Evolutionary_Search_for_Story_Generation.html">196 acl-2010-Plot Induction and Evolutionary Search for Story Generation</a></p>
<p>18 0.30225512 <a title="126-lsi-18" href="./acl-2010-Learning_Arguments_and_Supertypes_of_Semantic_Relations_Using_Recursive_Patterns.html">160 acl-2010-Learning Arguments and Supertypes of Semantic Relations Using Recursive Patterns</a></p>
<p>19 0.30215389 <a title="126-lsi-19" href="./acl-2010-Profiting_from_Mark-Up%3A_Hyper-Text_Annotations_for_Guided_Parsing.html">200 acl-2010-Profiting from Mark-Up: Hyper-Text Annotations for Guided Parsing</a></p>
<p>20 0.29988536 <a title="126-lsi-20" href="./acl-2010-Learning_Script_Knowledge_with_Web_Experiments.html">165 acl-2010-Learning Script Knowledge with Web Experiments</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.013), (14, 0.011), (25, 0.036), (42, 0.021), (59, 0.059), (73, 0.037), (78, 0.024), (83, 0.038), (84, 0.557), (98, 0.075)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91749948 <a title="126-lda-1" href="./acl-2010-GernEdiT_-_The_GermaNet_Editing_Tool.html">126 acl-2010-GernEdiT - The GermaNet Editing Tool</a></p>
<p>Author: Verena Henrich ; Erhard Hinrichs</p><p>Abstract: GernEdiT (short for: GermaNet Editing Tool) offers a graphical interface for the lexicographers and developers of GermaNet to access and modify the underlying GermaNet resource. GermaNet is a lexical-semantic wordnet that is modeled after the Princeton WordNet for English. The traditional lexicographic development of GermaNet was error prone and time-consuming, mainly due to a complex underlying data format and no opportunity of automatic consistency checks. GernEdiT replaces the earlier development by a more userfriendly tool, which facilitates automatic checking of internal consistency and correctness of the linguistic resource. This paper pre- sents all these core functionalities of GernEdiT along with details about its usage and usability. 1</p><p>2 0.89202225 <a title="126-lda-2" href="./acl-2010-Estimating_Strictly_Piecewise_Distributions.html">103 acl-2010-Estimating Strictly Piecewise Distributions</a></p>
<p>Author: Jeffrey Heinz ; James Rogers</p><p>Abstract: Strictly Piecewise (SP) languages are a subclass of regular languages which encode certain kinds of long-distance dependencies that are found in natural languages. Like the classes in the Chomsky and Subregular hierarchies, there are many independently converging characterizations of the SP class (Rogers et al., to appear). Here we define SP distributions and show that they can be efficiently estimated from positive data.</p><p>3 0.73186404 <a title="126-lda-3" href="./acl-2010-Syntactic_and_Semantic_Factors_in_Processing_Difficulty%3A_An_Integrated_Measure.html">220 acl-2010-Syntactic and Semantic Factors in Processing Difficulty: An Integrated Measure</a></p>
<p>Author: Jeff Mitchell ; Mirella Lapata ; Vera Demberg ; Frank Keller</p><p>Abstract: The analysis of reading times can provide insights into the processes that underlie language comprehension, with longer reading times indicating greater cognitive load. There is evidence that the language processor is highly predictive, such that prior context allows upcoming linguistic material to be anticipated. Previous work has investigated the contributions of semantic and syntactic contexts in isolation, essentially treating them as independent factors. In this paper we analyze reading times in terms of a single predictive measure which integrates a model of semantic composition with an incremental parser and a language model.</p><p>4 0.71043509 <a title="126-lda-4" href="./acl-2010-Starting_from_Scratch_in_Semantic_Role_Labeling.html">216 acl-2010-Starting from Scratch in Semantic Role Labeling</a></p>
<p>Author: Michael Connor ; Yael Gertner ; Cynthia Fisher ; Dan Roth</p><p>Abstract: A fundamental step in sentence comprehension involves assigning semantic roles to sentence constituents. To accomplish this, the listener must parse the sentence, find constituents that are candidate arguments, and assign semantic roles to those constituents. Each step depends on prior lexical and syntactic knowledge. Where do children learning their first languages begin in solving this problem? In this paper we focus on the parsing and argumentidentification steps that precede Semantic Role Labeling (SRL) training. We combine a simplified SRL with an unsupervised HMM part of speech tagger, and experiment with psycholinguisticallymotivated ways to label clusters resulting from the HMM so that they can be used to parse input for the SRL system. The results show that proposed shallow representations of sentence structure are robust to reductions in parsing accuracy, and that the contribution of alternative representations of sentence structure to successful semantic role labeling varies with the integrity of the parsing and argumentidentification stages.</p><p>5 0.60783088 <a title="126-lda-5" href="./acl-2010-A_Study_of_Information_Retrieval_Weighting_Schemes_for_Sentiment_Analysis.html">18 acl-2010-A Study of Information Retrieval Weighting Schemes for Sentiment Analysis</a></p>
<p>Author: Georgios Paltoglou ; Mike Thelwall</p><p>Abstract: Most sentiment analysis approaches use as baseline a support vector machines (SVM) classifier with binary unigram weights. In this paper, we explore whether more sophisticated feature weighting schemes from Information Retrieval can enhance classification accuracy. We show that variants of the classic tf.idf scheme adapted to sentiment analysis provide significant increases in accuracy, especially when using a sublinear function for term frequency weights and document frequency smoothing. The techniques are tested on a wide selection of data sets and produce the best accuracy to our knowledge.</p><p>6 0.55181956 <a title="126-lda-6" href="./acl-2010-How_Many_Words_Is_a_Picture_Worth%3F_Automatic_Caption_Generation_for_News_Images.html">136 acl-2010-How Many Words Is a Picture Worth? Automatic Caption Generation for News Images</a></p>
<p>7 0.48968685 <a title="126-lda-7" href="./acl-2010-Complexity_Metrics_in_an_Incremental_Right-Corner_Parser.html">65 acl-2010-Complexity Metrics in an Incremental Right-Corner Parser</a></p>
<p>8 0.47744137 <a title="126-lda-8" href="./acl-2010-Cognitively_Plausible_Models_of_Human_Language_Processing.html">59 acl-2010-Cognitively Plausible Models of Human Language Processing</a></p>
<p>9 0.44477174 <a title="126-lda-9" href="./acl-2010-String_Extension_Learning.html">217 acl-2010-String Extension Learning</a></p>
<p>10 0.40444165 <a title="126-lda-10" href="./acl-2010-A_Rational_Model_of_Eye_Movement_Control_in_Reading.html">13 acl-2010-A Rational Model of Eye Movement Control in Reading</a></p>
<p>11 0.38092339 <a title="126-lda-11" href="./acl-2010-Compositional_Matrix-Space_Models_of_Language.html">66 acl-2010-Compositional Matrix-Space Models of Language</a></p>
<p>12 0.35370588 <a title="126-lda-12" href="./acl-2010-Models_of_Metaphor_in_NLP.html">175 acl-2010-Models of Metaphor in NLP</a></p>
<p>13 0.35349429 <a title="126-lda-13" href="./acl-2010-Computing_Weakest_Readings.html">67 acl-2010-Computing Weakest Readings</a></p>
<p>14 0.35294688 <a title="126-lda-14" href="./acl-2010-Expanding_Verb_Coverage_in_Cyc_with_VerbNet.html">108 acl-2010-Expanding Verb Coverage in Cyc with VerbNet</a></p>
<p>15 0.34713298 <a title="126-lda-15" href="./acl-2010-Multilingual_Pseudo-Relevance_Feedback%3A_Performance_Study_of_Assisting_Languages.html">177 acl-2010-Multilingual Pseudo-Relevance Feedback: Performance Study of Assisting Languages</a></p>
<p>16 0.34630531 <a title="126-lda-16" href="./acl-2010-Automatic_Selectional_Preference_Acquisition_for_Latin_Verbs.html">41 acl-2010-Automatic Selectional Preference Acquisition for Latin Verbs</a></p>
<p>17 0.34030265 <a title="126-lda-17" href="./acl-2010-Learning_Common_Grammar_from_Multilingual_Corpus.html">162 acl-2010-Learning Common Grammar from Multilingual Corpus</a></p>
<p>18 0.3394717 <a title="126-lda-18" href="./acl-2010-PCFGs%2C_Topic_Models%2C_Adaptor_Grammars_and_Learning_Topical_Collocations_and_the_Structure_of_Proper_Names.html">191 acl-2010-PCFGs, Topic Models, Adaptor Grammars and Learning Topical Collocations and the Structure of Proper Names</a></p>
<p>19 0.33940202 <a title="126-lda-19" href="./acl-2010-Tools_for_Multilingual_Grammar-Based_Translation_on_the_Web.html">235 acl-2010-Tools for Multilingual Grammar-Based Translation on the Web</a></p>
<p>20 0.33385572 <a title="126-lda-20" href="./acl-2010-Phylogenetic_Grammar_Induction.html">195 acl-2010-Phylogenetic Grammar Induction</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
