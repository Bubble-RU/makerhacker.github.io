<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>264 acl-2010-Wrapping up a Summary: From Representation to Generation</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-264" href="#">acl2010-264</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>264 acl-2010-Wrapping up a Summary: From Representation to Generation</h1>
<br/><p>Source: <a title="acl-2010-264-pdf" href="http://aclweb.org/anthology//P/P10/P10-2070.pdf">pdf</a></p><p>Author: Josef Steinberger ; Marco Turchi ; Mijail Kabadjov ; Ralf Steinberger ; Nello Cristianini</p><p>Abstract: The main focus of this work is to investigate robust ways for generating summaries from summary representations without recurring to simple sentence extraction and aiming at more human-like summaries. This is motivated by empirical evidence from TAC 2009 data showing that human summaries contain on average more and shorter sentences than the system summaries. We report encouraging preliminary results comparable to those attained by participating systems at TAC 2009.</p><p>Reference: <a title="acl-2010-264-reference" href="../acl2010_reference/acl-2010-Wrapping_up_a_Summary%3A_From_Representation_to_Generation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 eu Abstract The main focus of this work is to investigate robust ways for generating summaries from summary representations without recurring to simple sentence extraction and aiming at more human-like summaries. [sent-8, score-0.728]
</p><p>2 This is motivated by empirical evidence from TAC 2009 data showing that human summaries contain on average more and shorter sentences than the system summaries. [sent-9, score-0.441]
</p><p>3 We report encouraging preliminary results comparable to those attained by participating systems at TAC 2009. [sent-10, score-0.052]
</p><p>4 The advantages of looking at the summarization problem in terms of distinct processing phases are numerous. [sent-12, score-0.237]
</p><p>5 It not only serves as a common ground for comparing different systems and understanding better the underlying logic and assumptions, but it also provides a neat framework for developing systems based on clean and extendable designs. [sent-13, score-0.042]
</p><p>6 (2007) showed that solely by enhancing the first source interpretation phase, one is already able to pro–  –  duce better summaries. [sent-16, score-0.118]
</p><p>7 There has been limited work on the last summary generation phase due to the fact that it is unarguably a very challenging problem. [sent-17, score-0.347]
</p><p>8 net l amount of approaches assume simple sentence selection, a type of extractive summarization, where often the summary representation and the end summary are, indeed, conflated. [sent-19, score-0.513]
</p><p>9 The main focus of this work is, thus, to investigate robust ways for generating summaries from summary representations without recurring to simple sentence extraction and aiming at more human-like summaries. [sent-20, score-0.728]
</p><p>10 This decision is also motivated by empirical evidence from TAC 2009 data (see table 1) showing that human summaries contain on average more and shorter sentences than the system summaries. [sent-21, score-0.441]
</p><p>11 The intuition behind this is that, by containing more sentences, a summary is  able to capture more of the important content from the source. [sent-22, score-0.192]
</p><p>12 Our initial experimental results show that our approach is feasible, since it produces summaries, which when evaluated against the TAC 2009 data1 yield ROUGE scores (Lin and Hovy, 2003) comparable to the participating systems in the Summarization task at TAC 2009. [sent-23, score-0.103]
</p><p>13 2  Related Work  There is a large body of literature on summarization (Hovy, 2005; Erkan and Radev, 2004; Kupiec et al. [sent-26, score-0.201]
</p><p>14 The most closely related work to the  approach presented hereby is work on summarization attempting to go beyond simple sentence ex1http : / /www . [sent-28, score-0.297]
</p><p>15 c C2o0n1f0er Aenscseoc Sihatoirotn P faopre Crso,m papguetsat 3io8n2a–l3 L8i6n,guistics traction and to a lesser degree work on sentence compression. [sent-32, score-0.096]
</p><p>16 Although our approach is related to sentence compression (Knight and Marcu, 2002; Clarke and Lapata, 2008), it is subtly different. [sent-34, score-0.159]
</p><p>17 Firstly, we reduce the number of terms to be used in the summary at a global level, not at a local per-sentence level. [sent-35, score-0.228]
</p><p>18 Secondly, we directly exploit the resulting structures from the SVD making the last generation step fully aware ofprevious processing stages, as opposed to tackling the problem of sentence compression in isolation. [sent-36, score-0.215]
</p><p>19 A similar approach to our sentence reconstruction method has been developed by Quirk et al. [sent-37, score-0.448]
</p><p>20 In their work, training and test sets contain sentence pairs that  are composed of two different proper English sentences and a paraphrase of a source sentence is generated by finding the optimal path through a paraphrases lattice. [sent-39, score-0.342]
</p><p>21 3  Three-fold Summarization: Interpretation, Transformation and Generation  We chose the LSA paradigm for summarization, since it provides a clear and direct instantiation of Sp¨ arck-Jones’ three-stage framework. [sent-41, score-0.043]
</p><p>22 In LSA-based summarization the interpretation phase takes the form of building a term-bysentence matrix A = [A1, A2, . [sent-42, score-0.45]
</p><p>23 , anj]T represents the weighted term-frequency vector of sentence j  in a given set of documents. [sent-48, score-0.096]
</p><p>24 We adopt the same weighting scheme as the one described in (Steinberger et al. [sent-49, score-0.033]
</p><p>25 , 2007), as well as their more general definition of term entailing not only unigrams and bigrams, but also named entities. [sent-50, score-0.116]
</p><p>26 The transformation phase is done by applying singular value decomposition (SVD) to the initial term-by-sentence matrix defined as A = UΣVT. [sent-51, score-0.362]
</p><p>27 The generation phase is where our main contribution comes in. [sent-52, score-0.155]
</p><p>28 At this point we depart from standard LSA-based approaches and aim at producing a succinct summary representation comprised only of salient terms Term Summary Representation (TSR). [sent-53, score-0.341]
</p><p>29 Then this TSR is passed on to another module which attempts to produce complete sentences. [sent-54, score-0.041]
</p><p>30 The module for sentence reconstruction is described in detail in section 4, in what follows we explain the method for producing a TSR. [sent-55, score-0.566]
</p><p>31 1 Term Summary Representation To explain how a term summary representation (TSR) is produced, we first need to define two concepts: salience score of a given term and salience  threshold. [sent-57, score-0.753]
</p><p>32 Salience score for each term in matrix A is given by the magnitude of the corresponding vector in the matrix resulting from the dot product of the matrix of left singular vectors with the diagonal matrix of singular values. [sent-58, score-0.649]
</p><p>33 More formally, let T = U · Σ and then for each term i, the salience score Uis given by |. [sent-59, score-0.247]
</p><p>34 f S Sthalei top k ththr term, w ish eeqn uaall terms are sorted in descending order on the basis of their salience scores and a cutoff is defined as a percentage (e. [sent-61, score-0.396]
</p><p>35 In other words, if the total number of terms is n, then 100 ∗ k/n must be equal utom mtbhee percentage c nu,to thfef specified. [sent-64, score-0.108]
</p><p>36 The generation of a TSR is performed in two steps. [sent-65, score-0.056]
</p><p>37 First, an initial pool of sentences is selected by using the same technique as in (Steinberger and Je˘ zek, 2009) which exploits the dot product of the diagonal matrix of singular values with the right singular vectors: Σ · VT. [sent-66, score-0.496]
</p><p>38 2 This initial pool of sentseinncgeusla irs vthecet output ·oVf standard LSA approaches. [sent-67, score-0.126]
</p><p>39 Second, the terms from the source matrix A are identified in the initial pool of sentences and those terms whose salience score is above the salience  h|Te~ni  threshold are copied across to the TSR. [sent-68, score-0.747]
</p><p>40 Thus, the TSR is formed by the most (globally) salient terms from each one of the sentences. [sent-69, score-0.036]
</p><p>41 For example: • Extracted Sentence: “Irish Prime Minister Bertie Ahern admitted on Tuesday that he had held a series of private one-on-one meetings on the Northern Ireland peace process with Sinn Fein leader Gerry Adams, but denied they had been secret in any way. [sent-70, score-0.153]
</p><p>42 ” • TSR Sentence at 10%: “Irish Prime Minister Bertie Ahern Tuesday had held one-on-one meetings Northern Ireland peace process Sinn Fein leader Gerry Adams”3 2Due to space constraints, full details on that step are omitted here, see (Steinberger and Je˘ zek, 2009). [sent-71, score-0.153]
</p><p>43 3The TSR sentence is stemmed just before feeding it to the reconstruction module discussed in the next section. [sent-72, score-0.602]
</p><p>44 4  Noisy-channel model for sentence reconstruction  This section describes a probabilistic approach to the reconstruction problem. [sent-96, score-0.8]
</p><p>45 We adopt the noisychannel framework that has been widely used in a number of other NLP applications. [sent-97, score-0.094]
</p><p>46 Our interpretation of the noisy channel consists of looking at a stemmed string without stopwords and imagining that it was originally a long string and that someone removed or stemmed some text from it. [sent-98, score-0.405]
</p><p>47 In our framework, reconstruction consists of identifying the original long string. [sent-99, score-0.352]
</p><p>48 To model our interpretation of the noisy channel, we make use of one of the most popular classes of SMT systems: the Phrase Based Model (PBM) (Zens et al. [sent-100, score-0.064]
</p><p>49 It is an extension of the noisychannel model and was introduced by Brown et al. [sent-103, score-0.061]
</p><p>50 In PBM, a source sentence f is segmented into a sequence of I phrases fI = [f1, f2, . [sent-105, score-0.15]
</p><p>51 fI] and the same is done for the target sentence e, where the notion of  phrase is not related to any grammatical assumption; a phrase is an n-gram. [sent-108, score-0.178]
</p><p>52 The best translation ebest of f is obtained by: YI  ebest= arg meaxp(e|f) = arg maexiY=1φ(fi|ei)λφ  d(ai− bi−1)λdiY|=e1|pLM(ei|e1. [sent-109, score-0.188]
</p><p>53 ei−1)λLM where φ(fi |ei) is the probability of translating a phrase ei einto a phrase fi. [sent-111, score-0.17]
</p><p>54 In the reordering model, ai denotes the start position of the source phrase that was translated into the ith target phrase, and bi−1 denotes the end position of the source phrase translated into the (i− 1th) target phrase. [sent-113, score-0.224]
</p><p>55 In our reconstruction problem, the difference between the source and target sentences is not in terms of languages, but in terms of forms. [sent-121, score-0.521]
</p><p>56 In fact, our source sentence f is a stemmed sentence without stopwords, while the target sentence e is a complete English sentence. [sent-122, score-0.455]
</p><p>57 “Translate” means to reconstruct the most probable sentence e given f inserting new words and reproducing the inflected surface forms of the source words. [sent-123, score-0.15]
</p><p>58 1 Training of the model In Statistical Machine Translation, a PBM system is trained using parallel sentences, where each sentence in a language is paired with another sentence in a different language and one is the translation of the other. [sent-125, score-0.239]
</p><p>59 In the reconstruction problem, we use a set, S1 of 2,487,414 English sentences extracted from the news. [sent-126, score-0.395]
</p><p>60 This set is duplicated, S2, and for each sentence in S2, stopwords are removed and the re-  maining words are stemmed using Porter’s stemmer (Porter, 1980). [sent-127, score-0.277]
</p><p>61 Verbs are not included in this list, because they are relevant for the reconstruction task. [sent-129, score-0.352]
</p><p>62 , 2007), a complete phrase-based translation toolkit for academic purposes. [sent-132, score-0.047]
</p><p>63 It provides all the state-of-theart components needed to create a phrase-based machine translation system. [sent-133, score-0.047]
</p><p>64 •  5 Experimental Results For our experiments we made use of the TAC 2009 data which conveniently contains humanproduced summaries against which we could evaluate the output of our system (NIST, 2009). [sent-135, score-0.343]
</p><p>65 To begin our inquiry we carried out a phase of exploratory data analysis, in which we measured the average number of sentences per summary, words per sentence and words per summary in human vs. [sent-136, score-0.43]
</p><p>66 Additionally, we also measured these statistics of summaries produced by our system at five different percentage cutoffs: 100%, 15%, 10%, 5% and 1%. [sent-138, score-0.415]
</p><p>67 The most notable thing is that human summaries contain on average more and shorter sentences than the system summaries (see 2nd and 3rd column from left to right). [sent-140, score-0.854]
</p><p>68 Secondly, we note that as the percentage cutoff decreases (from 4th column rightwards) the characteristics of the summaries produced by our system are increasingly more similar to those of the human summaries. [sent-141, score-0.59]
</p><p>69 In other words, within the 100-  word window imposed by the TAC guidelines, our system is able to fit more (and hence shorter) sentences as we decrease the percentage cutoff. [sent-142, score-0.153]
</p><p>70 The last five columns of table 2 (from left to right) correspond to summaries produced by our system at various percentage cutoffs. [sent-147, score-0.415]
</p><p>71 The 2nd column, LSAextract, corresponds to the performance of our system at producing summaries by sentence extraction only. [sent-148, score-0.482]
</p><p>72 5 In the light of the above, the decrease in performance from column LSAextract to column ‘At 100%’ can be regarded as reconstruction error. [sent-149, score-0.53]
</p><p>73 6 Then, as we decrease the percentage cutoff (from  4th column rightwards) we are increasingly covering more of the content comprised by the human summaries (as far as the ROUGE metrics are able to gauge this, of course). [sent-150, score-0.665]
</p><p>74 In other words, the improvement of content coverage makes up for the reconstruction error, and at 5% cutoff we already obtain ROUGE scores comparable to LSAextract. [sent-151, score-0.457]
</p><p>75 This suggests that if we improve the quality of our sentence reconstruction we would potentially end up with a better performing system than a typical LSA system based on sentence selection. [sent-152, score-0.544]
</p><p>76 Finally, we admittedly note that by applying a percentage cutoff on the initial term set and further performing the sentence reconstruction we gain in content coverage, to a certain extent, on the expense of sentence readability. [sent-154, score-0.836]
</p><p>77 6  Conclusion  In this paper we proposed a novel approach to summary generation from summary representation based on the LSA summarization framework and on a machine-translation-inspired technique  for sentence reconstruction. [sent-155, score-0.77]
</p><p>78 Our preliminary results show that our approach is feasible, since it produces summaries which resemble better human summaries in terms ofthe average number of sentences per summary and yield ROUGE scores comparable to the participating systems in the Summarization task at TAC 2009. [sent-156, score-1.009]
</p><p>79 In future work we plan on working towards improving the quality of our sentence reconstruction step in order to produce better and more readable sentences. [sent-158, score-0.483]
</p><p>80 5These are, effectively, what we called initial pool of sentences in section 3, before the TSR generation. [sent-159, score-0.169]
</p><p>81 6The only difference between the two types of summaries is the reconstruction step, since we are including 100% of the terms. [sent-160, score-0.695]
</p><p>82 Global inference for sentence compression: An integer linear programming approach. [sent-180, score-0.096]
</p><p>83 Generic text summarization using relevance measure and latent semantic analysis. [sent-192, score-0.201]
</p><p>84 Summarization beyond sentence extraction: A probabilistic approach  to sentence compression. [sent-204, score-0.192]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('reconstruction', 0.352), ('summaries', 0.343), ('tsr', 0.273), ('tac', 0.217), ('steinberger', 0.208), ('summarization', 0.201), ('summary', 0.192), ('salience', 0.183), ('rouge', 0.122), ('stemmed', 0.113), ('cutoff', 0.105), ('pbm', 0.104), ('phase', 0.099), ('je', 0.098), ('sentence', 0.096), ('lsa', 0.093), ('ei', 0.088), ('matrix', 0.086), ('singular', 0.083), ('pool', 0.075), ('percentage', 0.072), ('column', 0.07), ('ahern', 0.069), ('bertie', 0.069), ('ebest', 0.069), ('fein', 0.069), ('lsaextract', 0.069), ('rightwards', 0.069), ('sinn', 0.069), ('zek', 0.069), ('stopwords', 0.068), ('term', 0.064), ('interpretation', 0.064), ('compression', 0.063), ('minister', 0.061), ('adams', 0.061), ('leader', 0.061), ('irish', 0.061), ('bristol', 0.061), ('noisychannel', 0.061), ('mail', 0.061), ('tuesday', 0.061), ('koehn', 0.058), ('generation', 0.056), ('gong', 0.056), ('plm', 0.056), ('northern', 0.056), ('boguraev', 0.056), ('shorter', 0.055), ('source', 0.054), ('bi', 0.053), ('paraphrase', 0.053), ('participating', 0.052), ('unigrams', 0.052), ('recurring', 0.052), ('initial', 0.051), ('sp', 0.05), ('gerry', 0.049), ('kupiec', 0.049), ('mani', 0.049), ('kabadjov', 0.049), ('ireland', 0.049), ('meetings', 0.047), ('channel', 0.047), ('translation', 0.047), ('fi', 0.046), ('erkan', 0.045), ('aiming', 0.045), ('clarke', 0.045), ('peace', 0.045), ('zens', 0.045), ('producing', 0.043), ('och', 0.043), ('ste', 0.043), ('svd', 0.043), ('porter', 0.043), ('instantiation', 0.043), ('transformation', 0.043), ('sentences', 0.043), ('oxford', 0.042), ('clean', 0.042), ('royal', 0.042), ('phrase', 0.041), ('module', 0.041), ('diagonal', 0.039), ('hovy', 0.039), ('decrease', 0.038), ('comprised', 0.037), ('emphasis', 0.037), ('dot', 0.036), ('quirk', 0.036), ('terms', 0.036), ('arg', 0.036), ('prime', 0.035), ('readable', 0.035), ('bigrams', 0.034), ('explain', 0.034), ('ai', 0.034), ('adopt', 0.033), ('representation', 0.033)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="264-tfidf-1" href="./acl-2010-Wrapping_up_a_Summary%3A_From_Representation_to_Generation.html">264 acl-2010-Wrapping up a Summary: From Representation to Generation</a></p>
<p>Author: Josef Steinberger ; Marco Turchi ; Mijail Kabadjov ; Ralf Steinberger ; Nello Cristianini</p><p>Abstract: The main focus of this work is to investigate robust ways for generating summaries from summary representations without recurring to simple sentence extraction and aiming at more human-like summaries. This is motivated by empirical evidence from TAC 2009 data showing that human summaries contain on average more and shorter sentences than the system summaries. We report encouraging preliminary results comparable to those attained by participating systems at TAC 2009.</p><p>2 0.26963827 <a title="264-tfidf-2" href="./acl-2010-Cross-Language_Document_Summarization_Based_on_Machine_Translation_Quality_Prediction.html">77 acl-2010-Cross-Language Document Summarization Based on Machine Translation Quality Prediction</a></p>
<p>Author: Xiaojun Wan ; Huiying Li ; Jianguo Xiao</p><p>Abstract: Cross-language document summarization is a task of producing a summary in one language for a document set in a different language. Existing methods simply use machine translation for document translation or summary translation. However, current machine translation services are far from satisfactory, which results in that the quality of the cross-language summary is usually very poor, both in readability and content. In this paper, we propose to consider the translation quality of each sentence in the English-to-Chinese cross-language summarization process. First, the translation quality of each English sentence in the document set is predicted with the SVM regression method, and then the quality score of each sentence is incorporated into the summarization process. Finally, the English sentences with high translation quality and high informativeness are selected and translated to form the Chinese summary. Experimental results demonstrate the effectiveness and usefulness of the proposed approach. 1</p><p>3 0.24952902 <a title="264-tfidf-3" href="./acl-2010-Automatic_Evaluation_of_Linguistic_Quality_in_Multi-Document_Summarization.html">38 acl-2010-Automatic Evaluation of Linguistic Quality in Multi-Document Summarization</a></p>
<p>Author: Emily Pitler ; Annie Louis ; Ani Nenkova</p><p>Abstract: To date, few attempts have been made to develop and validate methods for automatic evaluation of linguistic quality in text summarization. We present the first systematic assessment of several diverse classes of metrics designed to capture various aspects of well-written text. We train and test linguistic quality models on consecutive years of NIST evaluation data in order to show the generality of results. For grammaticality, the best results come from a set of syntactic features. Focus, coherence and referential clarity are best evaluated by a class of features measuring local coherence on the basis of cosine similarity between sentences, coreference informa- tion, and summarization specific features. Our best results are 90% accuracy for pairwise comparisons of competing systems over a test set of several inputs and 70% for ranking summaries of a specific input.</p><p>4 0.22970699 <a title="264-tfidf-4" href="./acl-2010-A_Risk_Minimization_Framework_for_Extractive_Speech_Summarization.html">14 acl-2010-A Risk Minimization Framework for Extractive Speech Summarization</a></p>
<p>Author: Shih-Hsiang Lin ; Berlin Chen</p><p>Abstract: In this paper, we formulate extractive summarization as a risk minimization problem and propose a unified probabilistic framework that naturally combines supervised and unsupervised summarization models to inherit their individual merits as well as to overcome their inherent limitations. In addition, the introduction of various loss functions also provides the summarization framework with a flexible but systematic way to render the redundancy and coherence relationships among sentences and between sentences and the whole document, respectively. Experiments on speech summarization show that the methods deduced from our framework are very competitive with existing summarization approaches. 1</p><p>5 0.19459786 <a title="264-tfidf-5" href="./acl-2010-A_New_Approach_to_Improving_Multilingual_Summarization_Using_a_Genetic_Algorithm.html">11 acl-2010-A New Approach to Improving Multilingual Summarization Using a Genetic Algorithm</a></p>
<p>Author: Marina Litvak ; Mark Last ; Menahem Friedman</p><p>Abstract: Automated summarization methods can be defined as “language-independent,” if they are not based on any languagespecific knowledge. Such methods can be used for multilingual summarization defined by Mani (2001) as “processing several languages, with summary in the same language as input.” In this paper, we introduce MUSE, a languageindependent approach for extractive summarization based on the linear optimization of several sentence ranking measures using a genetic algorithm. We tested our methodology on two languages—English and Hebrew—and evaluated its performance with ROUGE-1 Recall vs. state- of-the-art extractive summarization approaches. Our results show that MUSE performs better than the best known multilingual approach (TextRank1) in both languages. Moreover, our experimental results on a bilingual (English and Hebrew) document collection suggest that MUSE does not need to be retrained on each language and the same model can be used across at least two different languages.</p><p>6 0.18788332 <a title="264-tfidf-6" href="./acl-2010-Generating_Image_Descriptions_Using_Dependency_Relational_Patterns.html">124 acl-2010-Generating Image Descriptions Using Dependency Relational Patterns</a></p>
<p>7 0.17218986 <a title="264-tfidf-7" href="./acl-2010-A_Hybrid_Hierarchical_Model_for_Multi-Document_Summarization.html">8 acl-2010-A Hybrid Hierarchical Model for Multi-Document Summarization</a></p>
<p>8 0.16806854 <a title="264-tfidf-8" href="./acl-2010-Automatic_Generation_of_Story_Highlights.html">39 acl-2010-Automatic Generation of Story Highlights</a></p>
<p>9 0.15261948 <a title="264-tfidf-9" href="./acl-2010-Optimizing_Informativeness_and_Readability_for_Sentiment_Summarization.html">188 acl-2010-Optimizing Informativeness and Readability for Sentiment Summarization</a></p>
<p>10 0.11207879 <a title="264-tfidf-10" href="./acl-2010-Generating_Templates_of_Entity_Summaries_with_an_Entity-Aspect_Model_and_Pattern_Mining.html">125 acl-2010-Generating Templates of Entity Summaries with an Entity-Aspect Model and Pattern Mining</a></p>
<p>11 0.10981645 <a title="264-tfidf-11" href="./acl-2010-Metadata-Aware_Measures_for_Answer_Summarization_in_Community_Question_Answering.html">171 acl-2010-Metadata-Aware Measures for Answer Summarization in Community Question Answering</a></p>
<p>12 0.094240569 <a title="264-tfidf-12" href="./acl-2010-Generating_Fine-Grained_Reviews_of_Songs_from_Album_Reviews.html">122 acl-2010-Generating Fine-Grained Reviews of Songs from Album Reviews</a></p>
<p>13 0.081476577 <a title="264-tfidf-13" href="./acl-2010-Training_Phrase_Translation_Models_with_Leaving-One-Out.html">240 acl-2010-Training Phrase Translation Models with Leaving-One-Out</a></p>
<p>14 0.070113733 <a title="264-tfidf-14" href="./acl-2010-Paraphrase_Lattice_for_Statistical_Machine_Translation.html">192 acl-2010-Paraphrase Lattice for Statistical Machine Translation</a></p>
<p>15 0.068891414 <a title="264-tfidf-15" href="./acl-2010-Fixed_Length_Word_Suffix_for_Factored_Statistical_Machine_Translation.html">119 acl-2010-Fixed Length Word Suffix for Factored Statistical Machine Translation</a></p>
<p>16 0.067839943 <a title="264-tfidf-16" href="./acl-2010-Bilingual_Sense_Similarity_for_Statistical_Machine_Translation.html">51 acl-2010-Bilingual Sense Similarity for Statistical Machine Translation</a></p>
<p>17 0.057643473 <a title="264-tfidf-17" href="./acl-2010-Syntactic_and_Semantic_Factors_in_Processing_Difficulty%3A_An_Integrated_Measure.html">220 acl-2010-Syntactic and Semantic Factors in Processing Difficulty: An Integrated Measure</a></p>
<p>18 0.055028513 <a title="264-tfidf-18" href="./acl-2010-Unsupervised_Search_for_the_Optimal_Segmentation_for_Statistical_Machine_Translation.html">249 acl-2010-Unsupervised Search for the Optimal Segmentation for Statistical Machine Translation</a></p>
<p>19 0.054424915 <a title="264-tfidf-19" href="./acl-2010-Compositional_Matrix-Space_Models_of_Language.html">66 acl-2010-Compositional Matrix-Space Models of Language</a></p>
<p>20 0.053813465 <a title="264-tfidf-20" href="./acl-2010-Identifying_Non-Explicit_Citing_Sentences_for_Citation-Based_Summarization..html">140 acl-2010-Identifying Non-Explicit Citing Sentences for Citation-Based Summarization.</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.204), (1, -0.004), (2, -0.152), (3, -0.017), (4, -0.005), (5, 0.001), (6, 0.001), (7, -0.43), (8, -0.063), (9, -0.034), (10, 0.064), (11, -0.009), (12, -0.103), (13, 0.05), (14, -0.043), (15, -0.068), (16, -0.027), (17, 0.028), (18, 0.022), (19, 0.042), (20, 0.092), (21, 0.09), (22, -0.023), (23, 0.014), (24, 0.043), (25, 0.016), (26, -0.058), (27, -0.02), (28, 0.047), (29, 0.0), (30, -0.018), (31, -0.044), (32, -0.034), (33, -0.047), (34, 0.065), (35, -0.002), (36, -0.085), (37, -0.017), (38, 0.044), (39, 0.034), (40, 0.001), (41, -0.031), (42, 0.016), (43, -0.018), (44, 0.02), (45, 0.011), (46, -0.003), (47, 0.015), (48, -0.019), (49, -0.042)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9585166 <a title="264-lsi-1" href="./acl-2010-Wrapping_up_a_Summary%3A_From_Representation_to_Generation.html">264 acl-2010-Wrapping up a Summary: From Representation to Generation</a></p>
<p>Author: Josef Steinberger ; Marco Turchi ; Mijail Kabadjov ; Ralf Steinberger ; Nello Cristianini</p><p>Abstract: The main focus of this work is to investigate robust ways for generating summaries from summary representations without recurring to simple sentence extraction and aiming at more human-like summaries. This is motivated by empirical evidence from TAC 2009 data showing that human summaries contain on average more and shorter sentences than the system summaries. We report encouraging preliminary results comparable to those attained by participating systems at TAC 2009.</p><p>2 0.8777892 <a title="264-lsi-2" href="./acl-2010-A_Risk_Minimization_Framework_for_Extractive_Speech_Summarization.html">14 acl-2010-A Risk Minimization Framework for Extractive Speech Summarization</a></p>
<p>Author: Shih-Hsiang Lin ; Berlin Chen</p><p>Abstract: In this paper, we formulate extractive summarization as a risk minimization problem and propose a unified probabilistic framework that naturally combines supervised and unsupervised summarization models to inherit their individual merits as well as to overcome their inherent limitations. In addition, the introduction of various loss functions also provides the summarization framework with a flexible but systematic way to render the redundancy and coherence relationships among sentences and between sentences and the whole document, respectively. Experiments on speech summarization show that the methods deduced from our framework are very competitive with existing summarization approaches. 1</p><p>3 0.8373127 <a title="264-lsi-3" href="./acl-2010-A_New_Approach_to_Improving_Multilingual_Summarization_Using_a_Genetic_Algorithm.html">11 acl-2010-A New Approach to Improving Multilingual Summarization Using a Genetic Algorithm</a></p>
<p>Author: Marina Litvak ; Mark Last ; Menahem Friedman</p><p>Abstract: Automated summarization methods can be defined as “language-independent,” if they are not based on any languagespecific knowledge. Such methods can be used for multilingual summarization defined by Mani (2001) as “processing several languages, with summary in the same language as input.” In this paper, we introduce MUSE, a languageindependent approach for extractive summarization based on the linear optimization of several sentence ranking measures using a genetic algorithm. We tested our methodology on two languages—English and Hebrew—and evaluated its performance with ROUGE-1 Recall vs. state- of-the-art extractive summarization approaches. Our results show that MUSE performs better than the best known multilingual approach (TextRank1) in both languages. Moreover, our experimental results on a bilingual (English and Hebrew) document collection suggest that MUSE does not need to be retrained on each language and the same model can be used across at least two different languages.</p><p>4 0.81601435 <a title="264-lsi-4" href="./acl-2010-Cross-Language_Document_Summarization_Based_on_Machine_Translation_Quality_Prediction.html">77 acl-2010-Cross-Language Document Summarization Based on Machine Translation Quality Prediction</a></p>
<p>Author: Xiaojun Wan ; Huiying Li ; Jianguo Xiao</p><p>Abstract: Cross-language document summarization is a task of producing a summary in one language for a document set in a different language. Existing methods simply use machine translation for document translation or summary translation. However, current machine translation services are far from satisfactory, which results in that the quality of the cross-language summary is usually very poor, both in readability and content. In this paper, we propose to consider the translation quality of each sentence in the English-to-Chinese cross-language summarization process. First, the translation quality of each English sentence in the document set is predicted with the SVM regression method, and then the quality score of each sentence is incorporated into the summarization process. Finally, the English sentences with high translation quality and high informativeness are selected and translated to form the Chinese summary. Experimental results demonstrate the effectiveness and usefulness of the proposed approach. 1</p><p>5 0.79207206 <a title="264-lsi-5" href="./acl-2010-Automatic_Evaluation_of_Linguistic_Quality_in_Multi-Document_Summarization.html">38 acl-2010-Automatic Evaluation of Linguistic Quality in Multi-Document Summarization</a></p>
<p>Author: Emily Pitler ; Annie Louis ; Ani Nenkova</p><p>Abstract: To date, few attempts have been made to develop and validate methods for automatic evaluation of linguistic quality in text summarization. We present the first systematic assessment of several diverse classes of metrics designed to capture various aspects of well-written text. We train and test linguistic quality models on consecutive years of NIST evaluation data in order to show the generality of results. For grammaticality, the best results come from a set of syntactic features. Focus, coherence and referential clarity are best evaluated by a class of features measuring local coherence on the basis of cosine similarity between sentences, coreference informa- tion, and summarization specific features. Our best results are 90% accuracy for pairwise comparisons of competing systems over a test set of several inputs and 70% for ranking summaries of a specific input.</p><p>6 0.73049772 <a title="264-lsi-6" href="./acl-2010-Automatic_Generation_of_Story_Highlights.html">39 acl-2010-Automatic Generation of Story Highlights</a></p>
<p>7 0.72588009 <a title="264-lsi-7" href="./acl-2010-A_Hybrid_Hierarchical_Model_for_Multi-Document_Summarization.html">8 acl-2010-A Hybrid Hierarchical Model for Multi-Document Summarization</a></p>
<p>8 0.67161155 <a title="264-lsi-8" href="./acl-2010-Generating_Image_Descriptions_Using_Dependency_Relational_Patterns.html">124 acl-2010-Generating Image Descriptions Using Dependency Relational Patterns</a></p>
<p>9 0.64384872 <a title="264-lsi-9" href="./acl-2010-Optimizing_Informativeness_and_Readability_for_Sentiment_Summarization.html">188 acl-2010-Optimizing Informativeness and Readability for Sentiment Summarization</a></p>
<p>10 0.59065354 <a title="264-lsi-10" href="./acl-2010-Identifying_Non-Explicit_Citing_Sentences_for_Citation-Based_Summarization..html">140 acl-2010-Identifying Non-Explicit Citing Sentences for Citation-Based Summarization.</a></p>
<p>11 0.58705002 <a title="264-lsi-11" href="./acl-2010-Generating_Templates_of_Entity_Summaries_with_an_Entity-Aspect_Model_and_Pattern_Mining.html">125 acl-2010-Generating Templates of Entity Summaries with an Entity-Aspect Model and Pattern Mining</a></p>
<p>12 0.52780205 <a title="264-lsi-12" href="./acl-2010-Generating_Fine-Grained_Reviews_of_Songs_from_Album_Reviews.html">122 acl-2010-Generating Fine-Grained Reviews of Songs from Album Reviews</a></p>
<p>13 0.47288477 <a title="264-lsi-13" href="./acl-2010-Metadata-Aware_Measures_for_Answer_Summarization_in_Community_Question_Answering.html">171 acl-2010-Metadata-Aware Measures for Answer Summarization in Community Question Answering</a></p>
<p>14 0.46511188 <a title="264-lsi-14" href="./acl-2010-How_Many_Words_Is_a_Picture_Worth%3F_Automatic_Caption_Generation_for_News_Images.html">136 acl-2010-How Many Words Is a Picture Worth? Automatic Caption Generation for News Images</a></p>
<p>15 0.43008193 <a title="264-lsi-15" href="./acl-2010-Plot_Induction_and_Evolutionary_Search_for_Story_Generation.html">196 acl-2010-Plot Induction and Evolutionary Search for Story Generation</a></p>
<p>16 0.38555577 <a title="264-lsi-16" href="./acl-2010-Learning_Word-Class_Lattices_for_Definition_and_Hypernym_Extraction.html">166 acl-2010-Learning Word-Class Lattices for Definition and Hypernym Extraction</a></p>
<p>17 0.36105829 <a title="264-lsi-17" href="./acl-2010-Entity-Based_Local_Coherence_Modelling_Using_Topological_Fields.html">101 acl-2010-Entity-Based Local Coherence Modelling Using Topological Fields</a></p>
<p>18 0.35852128 <a title="264-lsi-18" href="./acl-2010-Fixed_Length_Word_Suffix_for_Factored_Statistical_Machine_Translation.html">119 acl-2010-Fixed Length Word Suffix for Factored Statistical Machine Translation</a></p>
<p>19 0.31627846 <a title="264-lsi-19" href="./acl-2010-A_Generalized-Zero-Preserving_Method_for_Compact_Encoding_of_Concept_Lattices.html">7 acl-2010-A Generalized-Zero-Preserving Method for Compact Encoding of Concept Lattices</a></p>
<p>20 0.31597403 <a title="264-lsi-20" href="./acl-2010-Last_but_Definitely_Not_Least%3A_On_the_Role_of_the_Last_Sentence_in_Automatic_Polarity-Classification.html">157 acl-2010-Last but Definitely Not Least: On the Role of the Last Sentence in Automatic Polarity-Classification</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.31), (4, 0.015), (16, 0.016), (25, 0.04), (33, 0.022), (39, 0.019), (42, 0.019), (44, 0.012), (59, 0.109), (73, 0.036), (78, 0.027), (80, 0.019), (83, 0.099), (84, 0.033), (98, 0.155)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.79914176 <a title="264-lda-1" href="./acl-2010-Decision_Detection_Using_Hierarchical_Graphical_Models.html">81 acl-2010-Decision Detection Using Hierarchical Graphical Models</a></p>
<p>Author: Trung H. Bui ; Stanley Peters</p><p>Abstract: We investigate hierarchical graphical models (HGMs) for automatically detecting decisions in multi-party discussions. Several types of dialogue act (DA) are distinguished on the basis of their roles in formulating decisions. HGMs enable us to model dependencies between observed features of discussions, decision DAs, and subdialogues that result in a decision. For the task of detecting decision regions, an HGM classifier was found to outperform non-hierarchical graphical models and support vector machines, raising the F1-score to 0.80 from 0.55.</p><p>same-paper 2 0.79240316 <a title="264-lda-2" href="./acl-2010-Wrapping_up_a_Summary%3A_From_Representation_to_Generation.html">264 acl-2010-Wrapping up a Summary: From Representation to Generation</a></p>
<p>Author: Josef Steinberger ; Marco Turchi ; Mijail Kabadjov ; Ralf Steinberger ; Nello Cristianini</p><p>Abstract: The main focus of this work is to investigate robust ways for generating summaries from summary representations without recurring to simple sentence extraction and aiming at more human-like summaries. This is motivated by empirical evidence from TAC 2009 data showing that human summaries contain on average more and shorter sentences than the system summaries. We report encouraging preliminary results comparable to those attained by participating systems at TAC 2009.</p><p>3 0.65225416 <a title="264-lda-3" href="./acl-2010-Hierarchical_Search_for_Word_Alignment.html">133 acl-2010-Hierarchical Search for Word Alignment</a></p>
<p>Author: Jason Riesa ; Daniel Marcu</p><p>Abstract: We present a simple yet powerful hierarchical search algorithm for automatic word alignment. Our algorithm induces a forest of alignments from which we can efficiently extract a ranked k-best list. We score a given alignment within the forest with a flexible, linear discriminative model incorporating hundreds of features, and trained on a relatively small amount of annotated data. We report results on Arabic-English word alignment and translation tasks. Our model outperforms a GIZA++ Model-4 baseline by 6.3 points in F-measure, yielding a 1.1 BLEU score increase over a state-of-the-art syntax-based machine translation system.</p><p>4 0.58019495 <a title="264-lda-4" href="./acl-2010-Open-Domain_Semantic_Role_Labeling_by_Modeling_Word_Spans.html">184 acl-2010-Open-Domain Semantic Role Labeling by Modeling Word Spans</a></p>
<p>Author: Fei Huang ; Alexander Yates</p><p>Abstract: Most supervised language processing systems show a significant drop-off in performance when they are tested on text that comes from a domain significantly different from the domain of the training data. Semantic role labeling techniques are typically trained on newswire text, and in tests their performance on fiction is as much as 19% worse than their performance on newswire text. We investigate techniques for building open-domain semantic role labeling systems that approach the ideal of a train-once, use-anywhere system. We leverage recently-developed techniques for learning representations of text using latent-variable language models, and extend these techniques to ones that provide the kinds of features that are useful for semantic role labeling. In experiments, our novel system reduces error by 16% relative to the previous state of the art on out-of-domain text.</p><p>5 0.57708168 <a title="264-lda-5" href="./acl-2010-Bilingual_Sense_Similarity_for_Statistical_Machine_Translation.html">51 acl-2010-Bilingual Sense Similarity for Statistical Machine Translation</a></p>
<p>Author: Boxing Chen ; George Foster ; Roland Kuhn</p><p>Abstract: This paper proposes new algorithms to compute the sense similarity between two units (words, phrases, rules, etc.) from parallel corpora. The sense similarity scores are computed by using the vector space model. We then apply the algorithms to statistical machine translation by computing the sense similarity between the source and target side of translation rule pairs. Similarity scores are used as additional features of the translation model to improve translation performance. Significant improvements are obtained over a state-of-the-art hierarchical phrase-based machine translation system. 1</p><p>6 0.57434165 <a title="264-lda-6" href="./acl-2010-Bootstrapping_Semantic_Analyzers_from_Non-Contradictory_Texts.html">55 acl-2010-Bootstrapping Semantic Analyzers from Non-Contradictory Texts</a></p>
<p>7 0.573645 <a title="264-lda-7" href="./acl-2010-Improved_Unsupervised_POS_Induction_through_Prototype_Discovery.html">144 acl-2010-Improved Unsupervised POS Induction through Prototype Discovery</a></p>
<p>8 0.57364166 <a title="264-lda-8" href="./acl-2010-Improving_Arabic-to-English_Statistical_Machine_Translation_by_Reordering_Post-Verbal_Subjects_for_Alignment.html">145 acl-2010-Improving Arabic-to-English Statistical Machine Translation by Reordering Post-Verbal Subjects for Alignment</a></p>
<p>9 0.57363105 <a title="264-lda-9" href="./acl-2010-Discriminative_Modeling_of_Extraction_Sets_for_Machine_Translation.html">87 acl-2010-Discriminative Modeling of Extraction Sets for Machine Translation</a></p>
<p>10 0.5734067 <a title="264-lda-10" href="./acl-2010-Boosting-Based_System_Combination_for_Machine_Translation.html">54 acl-2010-Boosting-Based System Combination for Machine Translation</a></p>
<p>11 0.5724597 <a title="264-lda-11" href="./acl-2010-Bridging_SMT_and_TM_with_Translation_Recommendation.html">56 acl-2010-Bridging SMT and TM with Translation Recommendation</a></p>
<p>12 0.57176787 <a title="264-lda-12" href="./acl-2010-Creating_Robust_Supervised_Classifiers_via_Web-Scale_N-Gram_Data.html">76 acl-2010-Creating Robust Supervised Classifiers via Web-Scale N-Gram Data</a></p>
<p>13 0.57147032 <a title="264-lda-13" href="./acl-2010-Improving_the_Use_of_Pseudo-Words_for_Evaluating_Selectional_Preferences.html">148 acl-2010-Improving the Use of Pseudo-Words for Evaluating Selectional Preferences</a></p>
<p>14 0.57123011 <a title="264-lda-14" href="./acl-2010-Automatic_Generation_of_Story_Highlights.html">39 acl-2010-Automatic Generation of Story Highlights</a></p>
<p>15 0.57110304 <a title="264-lda-15" href="./acl-2010-Cross-Lingual_Latent_Topic_Extraction.html">79 acl-2010-Cross-Lingual Latent Topic Extraction</a></p>
<p>16 0.57095313 <a title="264-lda-16" href="./acl-2010-Experiments_in_Graph-Based_Semi-Supervised_Learning_Methods_for_Class-Instance_Acquisition.html">109 acl-2010-Experiments in Graph-Based Semi-Supervised Learning Methods for Class-Instance Acquisition</a></p>
<p>17 0.57091969 <a title="264-lda-17" href="./acl-2010-Discriminative_Pruning_for_Discriminative_ITG_Alignment.html">88 acl-2010-Discriminative Pruning for Discriminative ITG Alignment</a></p>
<p>18 0.57062936 <a title="264-lda-18" href="./acl-2010-Structural_Semantic_Relatedness%3A_A_Knowledge-Based_Method_to_Named_Entity_Disambiguation.html">218 acl-2010-Structural Semantic Relatedness: A Knowledge-Based Method to Named Entity Disambiguation</a></p>
<p>19 0.5699423 <a title="264-lda-19" href="./acl-2010-TrustRank%3A_Inducing_Trust_in_Automatic_Translations_via_Ranking.html">244 acl-2010-TrustRank: Inducing Trust in Automatic Translations via Ranking</a></p>
<p>20 0.56980956 <a title="264-lda-20" href="./acl-2010-Error_Detection_for_Statistical_Machine_Translation_Using_Linguistic_Features.html">102 acl-2010-Error Detection for Statistical Machine Translation Using Linguistic Features</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
