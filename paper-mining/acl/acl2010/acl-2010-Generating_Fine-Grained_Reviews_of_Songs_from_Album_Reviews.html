<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>122 acl-2010-Generating Fine-Grained Reviews of Songs from Album Reviews</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-122" href="#">acl2010-122</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>122 acl-2010-Generating Fine-Grained Reviews of Songs from Album Reviews</h1>
<br/><p>Source: <a title="acl-2010-122-pdf" href="http://aclweb.org/anthology//P/P10/P10-1140.pdf">pdf</a></p><p>Author: Swati Tata ; Barbara Di Eugenio</p><p>Abstract: Music Recommendation Systems often recommend individual songs, as opposed to entire albums. The challenge is to generate reviews for each song, since only full album reviews are available on-line. We developed a summarizer that combines information extraction and generation techniques to produce summaries of reviews of individual songs. We present an intrinsic evaluation of the extraction components, and of the informativeness of the summaries; and a user study of the impact of the song review summaries on users’ decision making processes. Users were able to make quicker and more informed decisions when presented with the summary as compared to the full album review.</p><p>Reference: <a title="acl-2010-122-reference" href="../acl2010_reference/acl-2010-Generating_Fine-Grained_Reviews_of_Songs_from_Album_Reviews_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The challenge is to generate reviews for each song, since only full album reviews are available on-line. [sent-3, score-1.164]
</p><p>2 We developed a summarizer that combines information extraction and generation techniques to produce summaries of reviews of individual songs. [sent-4, score-0.515]
</p><p>3 We present an intrinsic evaluation of the extraction components, and of the informativeness of the summaries; and a user study of the impact of the song review summaries on users’ decision making processes. [sent-5, score-0.881]
</p><p>4 Users were able to make quicker and more informed decisions when presented with the summary as compared to the full album review. [sent-6, score-0.634]
</p><p>5 1 Introduction In recent years, the personal music collection of many individuals has significantly grown due to the availability of portable devices like MP3 players and of internet services. [sent-7, score-0.263]
</p><p>6 Music listeners are now looking for techniques to help them manage their music collections and explore songs they may not even know they have (Clema, 2006). [sent-8, score-0.481]
</p><p>7 Currently, most of those electronic devices follow a Universal Plug and Play (UPNP) protocol (UPN, 2008), and can be used in a simple network, on which the songs listened to can be monitored. [sent-9, score-0.276]
</p><p>8 Most Product RSs include reviews from customers who bought or tried the product. [sent-16, score-0.349]
</p><p>9 As the number of reviews available for each individual product in-  creases, RSs may overwhelm the user if they make all those reviews available. [sent-17, score-0.746]
</p><p>10 Additionally, in some reviews only few sentences actually describe the recommended product, hence, the interest in opinion mining and in summarizing those reviews. [sent-18, score-0.505]
</p><p>11 Summarizing reviews becomes more complex: available data consists of album reviews, not individual song reviews (www . [sent-25, score-1.719]
</p><p>12 Comments about a given song are fragmented all over an album review. [sent-30, score-1.079]
</p><p>13 We devote Section 4 to our summarizer, that extracts comments on individual tracks from album reviews  and produces a summary of those comments for each individual track recommended to the user. [sent-35, score-1.074]
</p><p>14 We found that users make quicker and more informed decisions when presented with the song review summaries as opposed to the full album review. [sent-37, score-1.372]
</p><p>15 Hence, summarizing customer reviews has mostly been studied as a combination of machine learning and NLP techniques (Hu and Liu, 2004; Gamon et al. [sent-43, score-0.42]
</p><p>16 For example, (Hu and Liu, 2004) use associative mining techniques to identify features that frequently occur in reviews  taken from www . [sent-45, score-0.475]
</p><p>17 Most work on product reviews focuses on identifying sentences and polarity of opinion terms, not on generating a coherent summary from the extracted features, which is the main goal of our research. [sent-51, score-0.567]
</p><p>18 , 2006), whose focus was on extracting domain specific ontologies in order to structure summarization of customer reviews. [sent-54, score-0.141]
</p><p>19 Summarizing reviews on objects different from products, such as restaurants (Nguyen et al. [sent-55, score-0.346]
</p><p>20 We are aware of only one piece of work that focuses on music reviews (Downie and Hu, 2006). [sent-58, score-0.541]
</p><p>21 This study is mainly concerned with identifying descriptive patterns in positive or negative reviews but not on summarizing the reviews. [sent-59, score-0.395]
</p><p>22 1 Summarizing song reviews is different As mentioned earlier, using album reviews for  song summarization poses new challenges: a) Comments on features of a song are embedded and fragmented within the album reviews, as shown in Figure 1. [sent-61, score-3.401]
</p><p>23 b) Each song needs to be identified each time it is referred to in the review. [sent-63, score-0.59]
</p><p>24 Additionally, song titles need not be noun phrases and hence NP extraction algorithms miss many occurrences, as was shown by preliminary experiments we ran. [sent-67, score-0.642]
</p><p>25 ), unlike in product reviews where manufacturer/designer are rarely mentioned. [sent-69, score-0.349]
</p><p>26 Moving from window to window and from top to bottom: a) The top leftmost window shows different devices on which the user listens to songs. [sent-73, score-0.206]
</p><p>27 We use the SimpleKMeans Clustering (Mitchell, 1997) to identify and rank the top twenty-five songs which belong to the same cluster and are closest to the given song. [sent-78, score-0.257]
</p><p>28 Closeness between two songs in a cluster is measured as the number of attributes (album, artist etc)  of the songs that match. [sent-79, score-0.513]
</p><p>29 d) When the user clicks on More Info for one of the recommended songs, the pop-up, bottom window is displayed, which contains the summary of the reviews for the specific song. [sent-80, score-0.556]
</p><p>30 Our framework can be applied to any domain where reviews of individual components need to be summarized from reviews of collections, such as reviews of different hotels and restaurants in a city. [sent-85, score-1.035]
</p><p>31 It consists of 1350 album reviews across 27 albums (50 reviews per album). [sent-91, score-1.198]
</p><p>32 This corpus was annotated for song titles and song features. [sent-95, score-1.135]
</p><p>33 Feature annotation consists of marking a phrase as a feature and matching it with the song  which the feature is attributed. [sent-96, score-0.634]
</p><p>34 Note that we have no a priori inventory of features; what counts to  Figure 3: Summarization Pipeline  g  p  as features of songs emerged from the annotation, since annotators were asked to annotate for noun phrases which contain “any song related term or terms spoken in the context of a song”. [sent-97, score-0.795]
</p><p>35 Ten randomly chosen reviews were doubly annotated for song titles and features. [sent-101, score-0.926]
</p><p>36 We identify a string of words as the title of a song to be extracted from an album review if it (1) includes some or all the words in the title of a track of that album, and (2) this string occurs in the right context. [sent-109, score-1.25]
</p><p>37 Constraint (2) is necessary because the string of words corresponding to the title may appear in the lyrics of  the song or anywhere else in the review. [sent-110, score-0.617]
</p><p>38 , 2007), our approach to song title extraction is based on n-grams. [sent-116, score-0.618]
</p><p>39 Given the reviews for an album and the list of songs in that album, first, we build a lexicon of all the words in the song titles. [sent-118, score-1.608]
</p><p>40 We also segment the reviews into sentences via sentence boundary detection. [sent-119, score-0.38]
</p><p>41 All the n-grams remaining at this point are potential song titles. [sent-126, score-0.528]
</p><p>42 This intersection always resulted in one single song ID, since song titles in each album differ by at least one content word. [sent-128, score-1.661]
</p><p>43 Recall that the algorithm is run on reviews for each album separately. [sent-129, score-0.845]
</p><p>44 2  Feature Extraction  Once the song titles are identified in the album review, sentences with song titles are used as anchors to (1) identify segments of texts that talk about a specific song, and then (2) extract the feature(s) that the pertinent text segment discusses. [sent-131, score-1.892]
</p><p>45 An album review is first divided into segments using the text tiling algorithm. [sent-138, score-0.686]
</p><p>46 The segments that contain potential features of a song are identified using the following heuristics: Step 1: Include segi if it contains a song title. [sent-143, score-1.246]
</p><p>47 1379  These segments are more likely to contain features of songs as they are composed of the sentences surrounding the song title. [sent-144, score-0.863]
</p><p>48 Since we have no a priori inventory of features (the feature annotation will be used for evaluation, not for development), we use WordNet (Fellbaum, 1998) to identify feature terms: i. [sent-146, score-0.16]
</p><p>49 Feature terms exclude the words “music”, “song”, the artist/band/album name as they are likely to occur across album reviews. [sent-149, score-0.526]
</p><p>50 All feature terms in the final set of segments selected by the heuristics are taken to be features of the song described by that segment. [sent-150, score-0.652]
</p><p>51 Removing parts of sentences that describe another feature, will have no effect on the summary as a whole as the portions that are removed will be present in the group of sentences that describe the other feature. [sent-157, score-0.161]
</p><p>52 To identify portions of the sentence relevant to the single feature f, we use the Stanford Typed Dependency Parser (Klein and Manning, 2002; de Marnee and Manning, 2008). [sent-161, score-0.139]
</p><p>53 By the end of this step, for each feature f of a certain song si, we have generated a set of f-sentences. [sent-182, score-0.581]
</p><p>54 McCartney laid down the guitar lead for this track. [sent-189, score-0.141]
</p><p>55 Identical lead guitar provide the rhythmic basis for this song. [sent-191, score-0.141]
</p><p>56 The first sentence talks about the guitar solo, the second and the third about the lead guitar. [sent-192, score-0.205]
</p><p>57 We 1380  Figure 6: Grouping sentences by sub-features  identify subgroups via common n-grams between f-sentences, and make sure that only n-grams that are related to feature f are identified at this stage, as detailed in Figure 6. [sent-194, score-0.194]
</p><p>58 Step 2 in Figure 6 will group b and c together since guitar lead properly contains the feature term guitar. [sent-196, score-0.194]
</p><p>59 In Step 3, sentence a is sentence fx-si such that its LCN with all other sentences (b and c) contains only the feature term; hence, sentence a is left on its own. [sent-197, score-0.178]
</p><p>60 As concerns polarity grouping, different reviews may express different opinions regarding a particular feature. [sent-199, score-0.394]
</p><p>61 5 Selection and Ordering Finally, the generation of a coherent summary involves selection of the sentences to be included, and ordering them in a coherent fashion. [sent-213, score-0.188]
</p><p>62 Our assumption is that among the original sentences, a sentence that talks about one feature only is likely to express a stronger opinion about that feature than a sentence in which other features are present. [sent-222, score-0.263]
</p><p>63 We order the sentences by exploiting a music ontology (Giasson and Raimond, 2007). [sent-223, score-0.251]
</p><p>64 The ordering of the domains is such that first we present the general features of the song (e. [sent-229, score-0.56]
</p><p>65 5  Evaluation  In this section we report three evaluations, two intrinsic and one extrinsic: evaluation of the song title and feature extraction steps; evaluation of the informativeness of summaries; and a user study to judge how summaries affect decision making. [sent-239, score-0.925]
</p><p>66 1 Song Title and Feature Extraction  The song title extraction and feature extraction algorithms (Sections 4. [sent-241, score-0.706]
</p><p>67 2) were manually evaluated on 100 reviews randomly taken from the corpus (2 or 3 from each album). [sent-243, score-0.319]
</p><p>68 The 100 reviews contained 1304 occurrences of song titles and 898 occurrences of song features, as previously annotated. [sent-245, score-1.514]
</p><p>69 1294 occurrences of song titles were correctly identified; additionally, 123 spurious occurrences were also identified. [sent-246, score-0.667]
</p><p>70 Of the 898 occurrences of song features, 853 were correctly identified by our feature extraction algorithm, with an additional 41 spurious occurrences. [sent-251, score-0.708]
</p><p>71 Note that a feature (NP) is considered as correctly identified, if its head noun is annotated in a review for the song with correct ID. [sent-255, score-0.645]
</p><p>72 We compared their algorithm to ours on 10 randomly chosen reviews from our corpus, for a total of about 500 sentences. [sent-257, score-0.319]
</p><p>73 5% recall) is much lower than ours, and than their original results on product reviews (72% precision, and 80% recall). [sent-260, score-0.349]
</p><p>74 2  Informativeness of the summaries  To evaluate the information captured in the summary, we randomly selected 5 or 6 songs from 10 albums, and generated the corresponding 52 summaries, oneper song–this corresponds to atest set of about 500 album reviews (each album has about 50 reviews). [sent-262, score-1.74]
</p><p>75 We approximate those goldstandard reference summaries with 2 or 3 critic reviews per album taken from www . [sent-265, score-1.146]
</p><p>76 c First, we manually annotated both critic reviews and the automatically generated summaries for song titles and song features. [sent-272, score-1.675]
</p><p>77 2% of the features identified in the critic reviews are also identified in the summaries (recall that a feature is considered as identified, if the head-noun of the NP is identified by both the critic review and the summary, and attributed to the same song). [sent-276, score-0.962]
</p><p>78 It is not surprising that additional features may appear in the summaries: even if only one of the 50 album reviews talks about that feature, it is included in the summary. [sent-278, score-0.909]
</p><p>79 In a second evaluation, we used our Feature Extraction algorithm to extract features from the critic reviews, for each song whose summary needs to be evaluated. [sent-280, score-0.718]
</p><p>80 This is an indirect evaluation of that algorithm, in that it shows it is not affected by somewhat different data, since the critic  reviews are more formally written. [sent-281, score-0.406]
</p><p>81 375, or 95% of the features identified in the critic reviews are also identified in the summaries. [sent-282, score-0.562]
</p><p>82 For each of the recommended songs, the baseline version provides only whole album reviews, the experimental version provides the automatically generated song feature summary, as shown in Figure 2. [sent-290, score-1.159]
</p><p>83 The interface for the baseline version is similar, but the summary in the bottom window is replaced by the corresponding album review. [sent-291, score-0.635]
</p><p>84 The presented re-  view is the one among the 50 reviews for that album whose length is closest to the average length of album reviews in the corpus (478 words). [sent-292, score-1.69]
</p><p>85 Each user was presented with 5 songs in succession, with 3 recommendations each (only the top 3 recommendations were presented among the available 25, see Section 3). [sent-293, score-0.364]
</p><p>86 The first song was a test song for users to get acquainted with the system. [sent-296, score-1.139]
</p><p>87 18 users interacted with the baseline version and 21 users with the experimental version (five additional subjects were run but their log data was not properly saved). [sent-299, score-0.188]
</p><p>88 Our main measure is time on task, the total time taken to select the recommendations from song 2 to song 5 this excludes the time spent listening to the songs. [sent-301, score-1.095]
</p><p>89 This is a positive result, because decreasing time to selection is important, given that music collections can include millions of songs. [sent-305, score-0.268]
</p><p>90 However, time-on-task basically represents the time it takes users to peruse the review or summary, and the number of words in the summaries is significantly lower than the number of words in the reviews (p < 0. [sent-306, score-0.6]
</p><p>91 Users in the baseline condition picked the first recommendation as often as the other two rec–  ommendations combined; users in the experimental condition picked the second and third recommendations more often than the first, and the difference between the two conditions is significant (χ2 = 8. [sent-311, score-0.178]
</p><p>92 If we examine behavior song by song, this holds true especially for song 3 (χ2 = 12. [sent-314, score-1.056]
</p><p>93 We speculate that users in the experimental condition 1383  are more discriminatory in their choices, because important features of the recommended songs are evident in the summaries, but are buried in the album reviews. [sent-319, score-0.928]
</p><p>94 For example, for Song 3, only one of the 20 sentences in the album review is about the first recommended song, and is not very positive. [sent-320, score-0.671]
</p><p>95 Whereas these numbers in isolation are not too telling, they are at least suggestive that users did not find these summaries badly written. [sent-336, score-0.217]
</p><p>96 6  Discussion and Conclusions  Most summarization research on customer reviews focuses on obtaining features of the products, but not much work has been done on presenting them as a coherent summary. [sent-338, score-0.512]
</p><p>97 In this paper, we described a system that uses information extraction and summarization techniques in order to generate summaries of individual songs from multiple album reviews. [sent-339, score-1.027]
</p><p>98 Users made quicker decisions and their choice of recommendations was more varied when presented with song review summaries than with album reviews. [sent-343, score-1.328]
</p><p>99 Our framework can be applied to any domain where reviews of individual components need to be summarized from reviews of collections, such as travel reviews that cover many cities in a country, or different restaurants  in a city. [sent-344, score-1.035]
</p><p>100 Summarization of multiple user reviews in the restaurant domain. [sent-432, score-0.37]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('song', 0.528), ('album', 0.526), ('reviews', 0.319), ('songs', 0.235), ('music', 0.222), ('summaries', 0.134), ('guitar', 0.118), ('critic', 0.087), ('users', 0.083), ('www', 0.08), ('titles', 0.079), ('summary', 0.071), ('summarization', 0.07), ('review', 0.064), ('identified', 0.062), ('segi', 0.057), ('tiling', 0.057), ('recommendation', 0.056), ('title', 0.055), ('summarizing', 0.054), ('feature', 0.053), ('recommended', 0.052), ('user', 0.051), ('customer', 0.047), ('polarity', 0.045), ('coherent', 0.044), ('artist', 0.043), ('songrecommend', 0.043), ('subgroup', 0.043), ('tata', 0.043), ('upnp', 0.043), ('yag', 0.043), ('devices', 0.041), ('segments', 0.039), ('recommendations', 0.039), ('window', 0.038), ('quicker', 0.037), ('soubbotin', 0.037), ('informativeness', 0.037), ('com', 0.036), ('extraction', 0.035), ('ama', 0.034), ('rss', 0.034), ('albums', 0.034), ('lyrics', 0.034), ('silver', 0.034), ('features', 0.032), ('sentence', 0.032), ('hu', 0.032), ('intrinsic', 0.032), ('talks', 0.032), ('portions', 0.032), ('rs', 0.031), ('occurrences', 0.03), ('customers', 0.03), ('opinions', 0.03), ('product', 0.03), ('maxwell', 0.029), ('sentences', 0.029), ('opinion', 0.029), ('grouping', 0.029), ('bang', 0.028), ('downie', 0.028), ('giasson', 0.028), ('hammer', 0.028), ('harnly', 0.028), ('lcn', 0.028), ('marnee', 0.028), ('mccartney', 0.028), ('minnen', 0.028), ('octopus', 0.028), ('schedl', 0.028), ('subfeatures', 0.028), ('subgroups', 0.028), ('typed', 0.028), ('ai', 0.028), ('df', 0.027), ('individual', 0.027), ('restaurants', 0.027), ('grammaticality', 0.026), ('prototype', 0.026), ('comments', 0.026), ('clicks', 0.025), ('fragmented', 0.025), ('higashinaka', 0.025), ('mcroy', 0.025), ('regenerated', 0.025), ('swati', 0.025), ('recall', 0.025), ('collections', 0.024), ('domain', 0.024), ('extrinsic', 0.024), ('carenini', 0.023), ('lead', 0.023), ('template', 0.023), ('subjects', 0.022), ('positive', 0.022), ('step', 0.022), ('identify', 0.022), ('mining', 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="122-tfidf-1" href="./acl-2010-Generating_Fine-Grained_Reviews_of_Songs_from_Album_Reviews.html">122 acl-2010-Generating Fine-Grained Reviews of Songs from Album Reviews</a></p>
<p>Author: Swati Tata ; Barbara Di Eugenio</p><p>Abstract: Music Recommendation Systems often recommend individual songs, as opposed to entire albums. The challenge is to generate reviews for each song, since only full album reviews are available on-line. We developed a summarizer that combines information extraction and generation techniques to produce summaries of reviews of individual songs. We present an intrinsic evaluation of the extraction components, and of the informativeness of the summaries; and a user study of the impact of the song review summaries on users’ decision making processes. Users were able to make quicker and more informed decisions when presented with the summary as compared to the full album review.</p><p>2 0.14699164 <a title="122-tfidf-2" href="./acl-2010-Last_but_Definitely_Not_Least%3A_On_the_Role_of_the_Last_Sentence_in_Automatic_Polarity-Classification.html">157 acl-2010-Last but Definitely Not Least: On the Role of the Last Sentence in Automatic Polarity-Classification</a></p>
<p>Author: Israela Becker ; Vered Aharonson</p><p>Abstract: Two psycholinguistic and psychophysical experiments show that in order to efficiently extract polarity of written texts such as customerreviews on the Internet, one should concentrate computational efforts on messages in the final position of the text.</p><p>3 0.12570563 <a title="122-tfidf-3" href="./acl-2010-Optimizing_Informativeness_and_Readability_for_Sentiment_Summarization.html">188 acl-2010-Optimizing Informativeness and Readability for Sentiment Summarization</a></p>
<p>Author: Hitoshi Nishikawa ; Takaaki Hasegawa ; Yoshihiro Matsuo ; Genichiro Kikui</p><p>Abstract: We propose a novel algorithm for sentiment summarization that takes account of informativeness and readability, simultaneously. Our algorithm generates a summary by selecting and ordering sentences taken from multiple review texts according to two scores that represent the informativeness and readability of the sentence order. The informativeness score is defined by the number of sentiment expressions and the readability score is learned from the target corpus. We evaluate our method by summarizing reviews on restaurants. Our method outperforms an existing algorithm as indicated by its ROUGE score and human readability experiments.</p><p>4 0.11627862 <a title="122-tfidf-4" href="./acl-2010-Automatic_Evaluation_of_Linguistic_Quality_in_Multi-Document_Summarization.html">38 acl-2010-Automatic Evaluation of Linguistic Quality in Multi-Document Summarization</a></p>
<p>Author: Emily Pitler ; Annie Louis ; Ani Nenkova</p><p>Abstract: To date, few attempts have been made to develop and validate methods for automatic evaluation of linguistic quality in text summarization. We present the first systematic assessment of several diverse classes of metrics designed to capture various aspects of well-written text. We train and test linguistic quality models on consecutive years of NIST evaluation data in order to show the generality of results. For grammaticality, the best results come from a set of syntactic features. Focus, coherence and referential clarity are best evaluated by a class of features measuring local coherence on the basis of cosine similarity between sentences, coreference informa- tion, and summarization specific features. Our best results are 90% accuracy for pairwise comparisons of competing systems over a test set of several inputs and 70% for ranking summaries of a specific input.</p><p>5 0.11047599 <a title="122-tfidf-5" href="./acl-2010-Sentiment_Learning_on_Product_Reviews_via_Sentiment_Ontology_Tree.html">209 acl-2010-Sentiment Learning on Product Reviews via Sentiment Ontology Tree</a></p>
<p>Author: Wei Wei ; Jon Atle Gulla</p><p>Abstract: Existing works on sentiment analysis on product reviews suffer from the following limitations: (1) The knowledge of hierarchical relationships of products attributes is not fully utilized. (2) Reviews or sentences mentioning several attributes associated with complicated sentiments are not dealt with very well. In this paper, we propose a novel HL-SOT approach to labeling a product’s attributes and their associated sentiments in product reviews by a Hierarchical Learning (HL) process with a defined Sentiment Ontology Tree (SOT). The empirical analysis against a humanlabeled data set demonstrates promising and reasonable performance of the proposed HL-SOT approach. While this paper is mainly on sentiment analysis on reviews of one product, our proposed HLSOT approach is easily generalized to labeling a mix of reviews of more than one products.</p><p>6 0.10742395 <a title="122-tfidf-6" href="./acl-2010-Cross-Language_Document_Summarization_Based_on_Machine_Translation_Quality_Prediction.html">77 acl-2010-Cross-Language Document Summarization Based on Machine Translation Quality Prediction</a></p>
<p>7 0.094240569 <a title="122-tfidf-7" href="./acl-2010-Wrapping_up_a_Summary%3A_From_Representation_to_Generation.html">264 acl-2010-Wrapping up a Summary: From Representation to Generation</a></p>
<p>8 0.088330999 <a title="122-tfidf-8" href="./acl-2010-Using_Anaphora_Resolution_to_Improve_Opinion_Target_Identification_in_Movie_Reviews.html">251 acl-2010-Using Anaphora Resolution to Improve Opinion Target Identification in Movie Reviews</a></p>
<p>9 0.084779963 <a title="122-tfidf-9" href="./acl-2010-Sentence_and_Expression_Level_Annotation_of_Opinions_in_User-Generated_Discourse.html">208 acl-2010-Sentence and Expression Level Annotation of Opinions in User-Generated Discourse</a></p>
<p>10 0.083200842 <a title="122-tfidf-10" href="./acl-2010-A_Risk_Minimization_Framework_for_Extractive_Speech_Summarization.html">14 acl-2010-A Risk Minimization Framework for Extractive Speech Summarization</a></p>
<p>11 0.081546031 <a title="122-tfidf-11" href="./acl-2010-Generating_Image_Descriptions_Using_Dependency_Relational_Patterns.html">124 acl-2010-Generating Image Descriptions Using Dependency Relational Patterns</a></p>
<p>12 0.080063105 <a title="122-tfidf-12" href="./acl-2010-Event-Based_Hyperspace_Analogue_to_Language_for_Query_Expansion.html">106 acl-2010-Event-Based Hyperspace Analogue to Language for Query Expansion</a></p>
<p>13 0.076941907 <a title="122-tfidf-13" href="./acl-2010-Cross_Lingual_Adaptation%3A_An_Experiment_on_Sentiment_Classifications.html">80 acl-2010-Cross Lingual Adaptation: An Experiment on Sentiment Classifications</a></p>
<p>14 0.072533481 <a title="122-tfidf-14" href="./acl-2010-Cross-Language_Text_Classification_Using_Structural_Correspondence_Learning.html">78 acl-2010-Cross-Language Text Classification Using Structural Correspondence Learning</a></p>
<p>15 0.071218044 <a title="122-tfidf-15" href="./acl-2010-A_Hybrid_Hierarchical_Model_for_Multi-Document_Summarization.html">8 acl-2010-A Hybrid Hierarchical Model for Multi-Document Summarization</a></p>
<p>16 0.070846252 <a title="122-tfidf-16" href="./acl-2010-Generating_Templates_of_Entity_Summaries_with_an_Entity-Aspect_Model_and_Pattern_Mining.html">125 acl-2010-Generating Templates of Entity Summaries with an Entity-Aspect Model and Pattern Mining</a></p>
<p>17 0.064378291 <a title="122-tfidf-17" href="./acl-2010-A_Study_of_Information_Retrieval_Weighting_Schemes_for_Sentiment_Analysis.html">18 acl-2010-A Study of Information Retrieval Weighting Schemes for Sentiment Analysis</a></p>
<p>18 0.063413963 <a title="122-tfidf-18" href="./acl-2010-Recommendation_in_Internet_Forums_and_Blogs.html">204 acl-2010-Recommendation in Internet Forums and Blogs</a></p>
<p>19 0.062609412 <a title="122-tfidf-19" href="./acl-2010-A_New_Approach_to_Improving_Multilingual_Summarization_Using_a_Genetic_Algorithm.html">11 acl-2010-A New Approach to Improving Multilingual Summarization Using a Genetic Algorithm</a></p>
<p>20 0.062225588 <a title="122-tfidf-20" href="./acl-2010-Automatic_Generation_of_Story_Highlights.html">39 acl-2010-Automatic Generation of Story Highlights</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.143), (1, 0.088), (2, -0.145), (3, 0.05), (4, -0.061), (5, -0.003), (6, -0.021), (7, -0.122), (8, -0.038), (9, 0.007), (10, 0.023), (11, -0.02), (12, -0.06), (13, -0.001), (14, -0.032), (15, 0.001), (16, 0.053), (17, -0.031), (18, 0.043), (19, 0.04), (20, -0.008), (21, -0.016), (22, 0.02), (23, 0.001), (24, 0.029), (25, 0.074), (26, 0.048), (27, 0.027), (28, -0.022), (29, 0.015), (30, 0.022), (31, 0.053), (32, -0.032), (33, 0.008), (34, 0.049), (35, 0.006), (36, 0.001), (37, 0.016), (38, 0.085), (39, 0.004), (40, -0.001), (41, 0.103), (42, -0.07), (43, -0.113), (44, -0.037), (45, -0.176), (46, 0.11), (47, -0.115), (48, 0.112), (49, 0.049)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.935817 <a title="122-lsi-1" href="./acl-2010-Generating_Fine-Grained_Reviews_of_Songs_from_Album_Reviews.html">122 acl-2010-Generating Fine-Grained Reviews of Songs from Album Reviews</a></p>
<p>Author: Swati Tata ; Barbara Di Eugenio</p><p>Abstract: Music Recommendation Systems often recommend individual songs, as opposed to entire albums. The challenge is to generate reviews for each song, since only full album reviews are available on-line. We developed a summarizer that combines information extraction and generation techniques to produce summaries of reviews of individual songs. We present an intrinsic evaluation of the extraction components, and of the informativeness of the summaries; and a user study of the impact of the song review summaries on users’ decision making processes. Users were able to make quicker and more informed decisions when presented with the summary as compared to the full album review.</p><p>2 0.76406318 <a title="122-lsi-2" href="./acl-2010-Last_but_Definitely_Not_Least%3A_On_the_Role_of_the_Last_Sentence_in_Automatic_Polarity-Classification.html">157 acl-2010-Last but Definitely Not Least: On the Role of the Last Sentence in Automatic Polarity-Classification</a></p>
<p>Author: Israela Becker ; Vered Aharonson</p><p>Abstract: Two psycholinguistic and psychophysical experiments show that in order to efficiently extract polarity of written texts such as customerreviews on the Internet, one should concentrate computational efforts on messages in the final position of the text.</p><p>3 0.60468423 <a title="122-lsi-3" href="./acl-2010-Comparable_Entity_Mining_from_Comparative_Questions.html">63 acl-2010-Comparable Entity Mining from Comparative Questions</a></p>
<p>Author: Shasha Li ; Chin-Yew Lin ; Young-In Song ; Zhoujun Li</p><p>Abstract: Comparing one thing with another is a typical part of human decision making process. However, it is not always easy to know what to compare and what are the alternatives. To address this difficulty, we present a novel way to automatically mine comparable entities from comparative questions that users posted online. To ensure high precision and high recall, we develop a weakly-supervised bootstrapping method for comparative question identification and comparable entity extraction by leveraging a large online question archive. The experimental results show our method achieves F1measure of 82.5% in comparative question identification and 83.3% in comparable entity extraction. Both significantly outperform an existing state-of-the-art method. 1</p><p>4 0.52139074 <a title="122-lsi-4" href="./acl-2010-Automatic_Evaluation_of_Linguistic_Quality_in_Multi-Document_Summarization.html">38 acl-2010-Automatic Evaluation of Linguistic Quality in Multi-Document Summarization</a></p>
<p>Author: Emily Pitler ; Annie Louis ; Ani Nenkova</p><p>Abstract: To date, few attempts have been made to develop and validate methods for automatic evaluation of linguistic quality in text summarization. We present the first systematic assessment of several diverse classes of metrics designed to capture various aspects of well-written text. We train and test linguistic quality models on consecutive years of NIST evaluation data in order to show the generality of results. For grammaticality, the best results come from a set of syntactic features. Focus, coherence and referential clarity are best evaluated by a class of features measuring local coherence on the basis of cosine similarity between sentences, coreference informa- tion, and summarization specific features. Our best results are 90% accuracy for pairwise comparisons of competing systems over a test set of several inputs and 70% for ranking summaries of a specific input.</p><p>5 0.50852507 <a title="122-lsi-5" href="./acl-2010-Generating_Templates_of_Entity_Summaries_with_an_Entity-Aspect_Model_and_Pattern_Mining.html">125 acl-2010-Generating Templates of Entity Summaries with an Entity-Aspect Model and Pattern Mining</a></p>
<p>Author: Peng Li ; Jing Jiang ; Yinglin Wang</p><p>Abstract: In this paper, we propose a novel approach to automatic generation of summary templates from given collections of summary articles. This kind of summary templates can be useful in various applications. We first develop an entity-aspect LDA model to simultaneously cluster both sentences and words into aspects. We then apply frequent subtree pattern mining on the dependency parse trees of the clustered and labeled sentences to discover sentence patterns that well represent the aspects. Key features of our method include automatic grouping of semantically related sentence patterns and automatic identification of template slots that need to be filled in. We apply our method on five Wikipedia entity categories and compare our method with two baseline methods. Both quantitative evaluation based on human judgment and qualitative comparison demonstrate the effectiveness and advantages of our method.</p><p>6 0.50319743 <a title="122-lsi-6" href="./acl-2010-Using_Speech_to_Reply_to_SMS_Messages_While_Driving%3A_An_In-Car_Simulator_User_Study.html">254 acl-2010-Using Speech to Reply to SMS Messages While Driving: An In-Car Simulator User Study</a></p>
<p>7 0.50259519 <a title="122-lsi-7" href="./acl-2010-Generating_Image_Descriptions_Using_Dependency_Relational_Patterns.html">124 acl-2010-Generating Image Descriptions Using Dependency Relational Patterns</a></p>
<p>8 0.49271819 <a title="122-lsi-8" href="./acl-2010-Cross_Lingual_Adaptation%3A_An_Experiment_on_Sentiment_Classifications.html">80 acl-2010-Cross Lingual Adaptation: An Experiment on Sentiment Classifications</a></p>
<p>9 0.48508304 <a title="122-lsi-9" href="./acl-2010-Optimizing_Informativeness_and_Readability_for_Sentiment_Summarization.html">188 acl-2010-Optimizing Informativeness and Readability for Sentiment Summarization</a></p>
<p>10 0.47875625 <a title="122-lsi-10" href="./acl-2010-%22Was_It_Good%3F_It_Was_Provocative.%22_Learning_the_Meaning_of_Scalar_Adjectives.html">2 acl-2010-"Was It Good? It Was Provocative." Learning the Meaning of Scalar Adjectives</a></p>
<p>11 0.47780815 <a title="122-lsi-11" href="./acl-2010-Automatic_Generation_of_Story_Highlights.html">39 acl-2010-Automatic Generation of Story Highlights</a></p>
<p>12 0.47646037 <a title="122-lsi-12" href="./acl-2010-Cross-Language_Text_Classification_Using_Structural_Correspondence_Learning.html">78 acl-2010-Cross-Language Text Classification Using Structural Correspondence Learning</a></p>
<p>13 0.46714902 <a title="122-lsi-13" href="./acl-2010-Entity-Based_Local_Coherence_Modelling_Using_Topological_Fields.html">101 acl-2010-Entity-Based Local Coherence Modelling Using Topological Fields</a></p>
<p>14 0.43901724 <a title="122-lsi-14" href="./acl-2010-How_Many_Words_Is_a_Picture_Worth%3F_Automatic_Caption_Generation_for_News_Images.html">136 acl-2010-How Many Words Is a Picture Worth? Automatic Caption Generation for News Images</a></p>
<p>15 0.43889827 <a title="122-lsi-15" href="./acl-2010-Wrapping_up_a_Summary%3A_From_Representation_to_Generation.html">264 acl-2010-Wrapping up a Summary: From Representation to Generation</a></p>
<p>16 0.43356448 <a title="122-lsi-16" href="./acl-2010-A_Hybrid_Hierarchical_Model_for_Multi-Document_Summarization.html">8 acl-2010-A Hybrid Hierarchical Model for Multi-Document Summarization</a></p>
<p>17 0.40913501 <a title="122-lsi-17" href="./acl-2010-Recommendation_in_Internet_Forums_and_Blogs.html">204 acl-2010-Recommendation in Internet Forums and Blogs</a></p>
<p>18 0.40247968 <a title="122-lsi-18" href="./acl-2010-Sentiment_Learning_on_Product_Reviews_via_Sentiment_Ontology_Tree.html">209 acl-2010-Sentiment Learning on Product Reviews via Sentiment Ontology Tree</a></p>
<p>19 0.39849174 <a title="122-lsi-19" href="./acl-2010-Cross-Language_Document_Summarization_Based_on_Machine_Translation_Quality_Prediction.html">77 acl-2010-Cross-Language Document Summarization Based on Machine Translation Quality Prediction</a></p>
<p>20 0.37361073 <a title="122-lsi-20" href="./acl-2010-A_Study_of_Information_Retrieval_Weighting_Schemes_for_Sentiment_Analysis.html">18 acl-2010-A Study of Information Retrieval Weighting Schemes for Sentiment Analysis</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.011), (23, 0.283), (25, 0.055), (39, 0.011), (40, 0.014), (42, 0.032), (59, 0.074), (72, 0.056), (73, 0.054), (76, 0.013), (78, 0.022), (80, 0.011), (83, 0.113), (84, 0.038), (98, 0.1)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.78619099 <a title="122-lda-1" href="./acl-2010-Comparable_Entity_Mining_from_Comparative_Questions.html">63 acl-2010-Comparable Entity Mining from Comparative Questions</a></p>
<p>Author: Shasha Li ; Chin-Yew Lin ; Young-In Song ; Zhoujun Li</p><p>Abstract: Comparing one thing with another is a typical part of human decision making process. However, it is not always easy to know what to compare and what are the alternatives. To address this difficulty, we present a novel way to automatically mine comparable entities from comparative questions that users posted online. To ensure high precision and high recall, we develop a weakly-supervised bootstrapping method for comparative question identification and comparable entity extraction by leveraging a large online question archive. The experimental results show our method achieves F1measure of 82.5% in comparative question identification and 83.3% in comparable entity extraction. Both significantly outperform an existing state-of-the-art method. 1</p><p>same-paper 2 0.76769817 <a title="122-lda-2" href="./acl-2010-Generating_Fine-Grained_Reviews_of_Songs_from_Album_Reviews.html">122 acl-2010-Generating Fine-Grained Reviews of Songs from Album Reviews</a></p>
<p>Author: Swati Tata ; Barbara Di Eugenio</p><p>Abstract: Music Recommendation Systems often recommend individual songs, as opposed to entire albums. The challenge is to generate reviews for each song, since only full album reviews are available on-line. We developed a summarizer that combines information extraction and generation techniques to produce summaries of reviews of individual songs. We present an intrinsic evaluation of the extraction components, and of the informativeness of the summaries; and a user study of the impact of the song review summaries on users’ decision making processes. Users were able to make quicker and more informed decisions when presented with the summary as compared to the full album review.</p><p>3 0.73291731 <a title="122-lda-3" href="./acl-2010-Exemplar-Based_Models_for_Word_Meaning_in_Context.html">107 acl-2010-Exemplar-Based Models for Word Meaning in Context</a></p>
<p>Author: Katrin Erk ; Sebastian Pado</p><p>Abstract: This paper describes ongoing work on distributional models for word meaning in context. We abandon the usual one-vectorper-word paradigm in favor of an exemplar model that activates only relevant occurrences. On a paraphrasing task, we find that a simple exemplar model outperforms more complex state-of-the-art models.</p><p>4 0.54813457 <a title="122-lda-4" href="./acl-2010-Sentiment_Learning_on_Product_Reviews_via_Sentiment_Ontology_Tree.html">209 acl-2010-Sentiment Learning on Product Reviews via Sentiment Ontology Tree</a></p>
<p>Author: Wei Wei ; Jon Atle Gulla</p><p>Abstract: Existing works on sentiment analysis on product reviews suffer from the following limitations: (1) The knowledge of hierarchical relationships of products attributes is not fully utilized. (2) Reviews or sentences mentioning several attributes associated with complicated sentiments are not dealt with very well. In this paper, we propose a novel HL-SOT approach to labeling a product’s attributes and their associated sentiments in product reviews by a Hierarchical Learning (HL) process with a defined Sentiment Ontology Tree (SOT). The empirical analysis against a humanlabeled data set demonstrates promising and reasonable performance of the proposed HL-SOT approach. While this paper is mainly on sentiment analysis on reviews of one product, our proposed HLSOT approach is easily generalized to labeling a mix of reviews of more than one products.</p><p>5 0.54781264 <a title="122-lda-5" href="./acl-2010-Open-Domain_Semantic_Role_Labeling_by_Modeling_Word_Spans.html">184 acl-2010-Open-Domain Semantic Role Labeling by Modeling Word Spans</a></p>
<p>Author: Fei Huang ; Alexander Yates</p><p>Abstract: Most supervised language processing systems show a significant drop-off in performance when they are tested on text that comes from a domain significantly different from the domain of the training data. Semantic role labeling techniques are typically trained on newswire text, and in tests their performance on fiction is as much as 19% worse than their performance on newswire text. We investigate techniques for building open-domain semantic role labeling systems that approach the ideal of a train-once, use-anywhere system. We leverage recently-developed techniques for learning representations of text using latent-variable language models, and extend these techniques to ones that provide the kinds of features that are useful for semantic role labeling. In experiments, our novel system reduces error by 16% relative to the previous state of the art on out-of-domain text.</p><p>6 0.5447548 <a title="122-lda-6" href="./acl-2010-Using_Anaphora_Resolution_to_Improve_Opinion_Target_Identification_in_Movie_Reviews.html">251 acl-2010-Using Anaphora Resolution to Improve Opinion Target Identification in Movie Reviews</a></p>
<p>7 0.54232168 <a title="122-lda-7" href="./acl-2010-Metadata-Aware_Measures_for_Answer_Summarization_in_Community_Question_Answering.html">171 acl-2010-Metadata-Aware Measures for Answer Summarization in Community Question Answering</a></p>
<p>8 0.54107779 <a title="122-lda-8" href="./acl-2010-Global_Learning_of_Focused_Entailment_Graphs.html">127 acl-2010-Global Learning of Focused Entailment Graphs</a></p>
<p>9 0.5405004 <a title="122-lda-9" href="./acl-2010-Sentence_and_Expression_Level_Annotation_of_Opinions_in_User-Generated_Discourse.html">208 acl-2010-Sentence and Expression Level Annotation of Opinions in User-Generated Discourse</a></p>
<p>10 0.53942806 <a title="122-lda-10" href="./acl-2010-Modeling_Semantic_Relevance_for_Question-Answer_Pairs_in_Web_Social_Communities.html">174 acl-2010-Modeling Semantic Relevance for Question-Answer Pairs in Web Social Communities</a></p>
<p>11 0.53912562 <a title="122-lda-11" href="./acl-2010-Hierarchical_Sequential_Learning_for_Extracting_Opinions_and_Their_Attributes.html">134 acl-2010-Hierarchical Sequential Learning for Extracting Opinions and Their Attributes</a></p>
<p>12 0.53909308 <a title="122-lda-12" href="./acl-2010-Entity-Based_Local_Coherence_Modelling_Using_Topological_Fields.html">101 acl-2010-Entity-Based Local Coherence Modelling Using Topological Fields</a></p>
<p>13 0.53833306 <a title="122-lda-13" href="./acl-2010-Extraction_and_Approximation_of_Numerical_Attributes_from_the_Web.html">113 acl-2010-Extraction and Approximation of Numerical Attributes from the Web</a></p>
<p>14 0.5364992 <a title="122-lda-14" href="./acl-2010-Experiments_in_Graph-Based_Semi-Supervised_Learning_Methods_for_Class-Instance_Acquisition.html">109 acl-2010-Experiments in Graph-Based Semi-Supervised Learning Methods for Class-Instance Acquisition</a></p>
<p>15 0.53576541 <a title="122-lda-15" href="./acl-2010-%22Ask_Not_What_Textual_Entailment_Can_Do_for_You...%22.html">1 acl-2010-"Ask Not What Textual Entailment Can Do for You..."</a></p>
<p>16 0.53221422 <a title="122-lda-16" href="./acl-2010-A_Study_of_Information_Retrieval_Weighting_Schemes_for_Sentiment_Analysis.html">18 acl-2010-A Study of Information Retrieval Weighting Schemes for Sentiment Analysis</a></p>
<p>17 0.53190494 <a title="122-lda-17" href="./acl-2010-Automatic_Generation_of_Story_Highlights.html">39 acl-2010-Automatic Generation of Story Highlights</a></p>
<p>18 0.53184587 <a title="122-lda-18" href="./acl-2010-Understanding_the_Semantic_Structure_of_Noun_Phrase_Queries.html">245 acl-2010-Understanding the Semantic Structure of Noun Phrase Queries</a></p>
<p>19 0.53096843 <a title="122-lda-19" href="./acl-2010-Joint_Syntactic_and_Semantic_Parsing_of_Chinese.html">153 acl-2010-Joint Syntactic and Semantic Parsing of Chinese</a></p>
<p>20 0.5296101 <a title="122-lda-20" href="./acl-2010-The_Manually_Annotated_Sub-Corpus%3A_A_Community_Resource_for_and_by_the_People.html">230 acl-2010-The Manually Annotated Sub-Corpus: A Community Resource for and by the People</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
