<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>47 acl-2010-Beetle II: A System for Tutoring and Computational Linguistics Experimentation</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-47" href="#">acl2010-47</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>47 acl-2010-Beetle II: A System for Tutoring and Computational Linguistics Experimentation</h1>
<br/><p>Source: <a title="acl-2010-47-pdf" href="http://aclweb.org/anthology//P/P10/P10-4003.pdf">pdf</a></p><p>Author: Myroslava O. Dzikovska ; Johanna D. Moore ; Natalie Steinhauser ; Gwendolyn Campbell ; Elaine Farrow ; Charles B. Callaway</p><p>Abstract: We present BEETLE II, a tutorial dialogue system designed to accept unrestricted language input and support experimentation with different tutorial planning and dialogue strategies. Our first system evaluation used two different tutorial policies and demonstrated that the system can be successfully used to study the impact of different approaches to tutoring. In the future, the system can also be used to experiment with a variety ofnatural language interpretation and generation techniques.</p><p>Reference: <a title="acl-2010-47-reference" href="../acl2010_reference/acl-2010-Beetle_II%3A_A_System_for_Tutoring_and_Computational_Linguistics_Experimentation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 BEETLE II: a system for tutoring and computational linguistics experimentation Myroslava O. [sent-1, score-0.321]
</p><p>2 Abstract We present BEETLE II, a tutorial dialogue system designed to accept unrestricted language input and support experimentation with different tutorial planning and dialogue strategies. [sent-13, score-1.065]
</p><p>3 Our first system evaluation used two different tutorial policies and demonstrated that the system can be successfully used to study the impact of different approaches to tutoring. [sent-14, score-0.395]
</p><p>4 In the future, the system can also be used to experiment with a variety ofnatural language interpretation and generation techniques. [sent-15, score-0.141]
</p><p>5 1 Introduction Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations (Jordan et al. [sent-16, score-0.798]
</p><p>6 , 2007), because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring (Chi et al. [sent-21, score-0.601]
</p><p>7 However, most existing systems use pre-authored tutor responses for addressing student errors. [sent-25, score-0.495]
</p><p>8 The advantage of this approach is that tutors can devise remediation dialogues that are highly tailored to specific misconceptions many students share, providing step-by-step scaffolding and potentially suggesting additional problems. [sent-26, score-0.316]
</p><p>9 The disadvantage is a lack of adaptivity and generality: students often get the same remediation for the same error regardless of their past performance or dialogue context, as it is infeasible to  Charles B. [sent-27, score-0.483]
</p><p>10 author a different remediation dialogue for every possible dialogue state. [sent-29, score-0.628]
</p><p>11 It also becomes more difficult to experiment with different tutorial policies within the system due to the inherent completixites in applying tutoring strategies consistently across a large number of individual hand-authored remediations. [sent-30, score-0.637]
</p><p>12 The BEETLE II system architecture is designed to overcome these limitations (Callaway et al. [sent-31, score-0.117]
</p><p>13 It uses a deep parser and generator, together with a domain reasoner and a diagnoser, to produce detailed analyses of student utterances and generate feedback automatically. [sent-33, score-0.393]
</p><p>14 This allows the system to consistently apply the same tutorial policy across a range of questions. [sent-34, score-0.381]
</p><p>15 To some extent, this comes at the expense of being able to address individual student misconceptions. [sent-35, score-0.347]
</p><p>16 A distinguishing feature of the system is that it is based on an introductory electricity and electronics course developed by experienced instructional designers. [sent-37, score-0.137]
</p><p>17 The course was first created for use in a human-human tutoring study, without taking into account possible limitations of computer tutoring. [sent-38, score-0.254]
</p><p>18 The exercises were then transferred into a computer system with only minor adjustments (e. [sent-39, score-0.103]
</p><p>19 This resulted in a realistic tutoring setup, which presents interesting challenges to language processing components, involving a wide variety of language phenomena. [sent-42, score-0.254]
</p><p>20 We demonstrate a version of the system that has undergone a successful user evaluation in 13  UppsalaP,r Sowce ed enin,g 1s3 o Jfu tlhye 2 A0C1L0. [sent-43, score-0.067]
</p><p>21 The evaluation results indicate that additional improvements to remediation strategies, and  especially to strategies dealing with interpretation problems, are necessary for effective tutoring. [sent-46, score-0.277]
</p><p>22 The rest of this paper discusses the BEETLE II system architecture (Section 2), system evaluation (Section 3), and the range of computational linguistics problems that can be investigated using BEETLE II (Section 4). [sent-48, score-0.184]
</p><p>23 2  System Architecture  The BEETLE II system delivers basic electricity and electronics tutoring to students with no prior knowledge of the subject. [sent-49, score-0.486]
</p><p>24 The student interface includes an area to display reading material, a circuit simulator, and a dialogue history window. [sent-51, score-0.626]
</p><p>25 Students read pre-authored curriculum slides and carry out exercises which involve experimenting with the circuit simulator and explaining the observed behavior. [sent-53, score-0.151]
</p><p>26 The system also asks some high-level questions, such as “What is voltage? [sent-54, score-0.067]
</p><p>27 The system uses a standard interpretation pipeline, with domain-independent parsing and generation components supported by domain specific reasoners for decision making. [sent-57, score-0.141]
</p><p>28 The architecture is discussed in detail in the rest of this section. [sent-58, score-0.05]
</p><p>29 1 Interpretation Components We use the TRIPS dialogue parser (Allen et al. [sent-60, score-0.24]
</p><p>30 For example, it can determine that in the answer to the question “Which bulbs will be on and which bulbs will be off in this diagram? [sent-68, score-0.244]
</p><p>31 ”, “off” can be taken to mean “all bulbs in the diagram will be off. [sent-69, score-0.123]
</p><p>32 ” The resulting output is then passed on to the domain reasoning and diagnosis components. [sent-70, score-0.058]
</p><p>33 2 Domain Reasoning and Diagnosis The system uses a knowledge base implemented in the KM representation language (Clark and Porter, 1999; Dzikovska et al. [sent-72, score-0.067]
</p><p>34 At present, the knowledge base represents 14 object types and supports the curriculum containing over 200 questions and 40 different circuits. [sent-74, score-0.089]
</p><p>35 Student explanations are checked on two levels, verifying factual and explanation correctness. [sent-75, score-0.079]
</p><p>36 ”, if the student says “it is in a closed path”, the system checks two things: a) is the bulb indeed in a closed path? [sent-77, score-0.825]
</p><p>37 and b) is being in a closed path a reasonable explanation for the bulb being lit? [sent-78, score-0.392]
</p><p>38 Different remediation strategies need to be used depending  on whether the student made a factual error (i. [sent-79, score-0.594]
</p><p>39 , they misread the diagram and the bulb is not in a closed path) or produced an incorrect explanation (i. [sent-81, score-0.417]
</p><p>40 , the bulb is indeed in a closed path, but they failed to mention that a battery needs to be in the same closed path for the bulb to light). [sent-83, score-0.705]
</p><p>41 The knowledge base is used to check the factual correctness of the answers first, and then a diagnoser checks the explanation correctness. [sent-84, score-0.198]
</p><p>42 (2008b), outputs a diagnosis which consists of lists of correct, contradictory and non-mentioned objects and relations from the student’s answer. [sent-86, score-0.058]
</p><p>43 At present, the system uses a heuristic matching algorithm to classify relations into the appropriate category, though in the future we may consider a classifier similar to Nielsen et al. [sent-87, score-0.067]
</p><p>44 3 Tutorial Planner The tutorial planner implements a set of generic tutoring strategies, as well as a policy to choose an appropriate strategy at each point of the interaction. [sent-90, score-0.68]
</p><p>45 The currently implemented strategies are: acknowledging the correct part of the answer; suggesting a slide to read with background material; prompting for missing parts of the answer; hinting (low- and high- specificity); and giving away the answer. [sent-92, score-0.055]
</p><p>46 Two or more strategies can be used together if necessary. [sent-93, score-0.055]
</p><p>47 For a low specificity hint it selects 14  Figure 1: Screenshot of the BEETLE II system  GUI Figure 2: System architecture diagram 15  an as-yet unmentioned object and hints at it, for example, “Here’s a hint: Your answer should mention a battery. [sent-95, score-0.526]
</p><p>48 ” For high-specificity, it attempts to hint at a two-place relation, for example, “Here’s a hint: the battery is connected to something. [sent-96, score-0.206]
</p><p>49 ” The tutorial policy makes a high-level decision as to which strategy to use (for example, “acknowledge the correct part and give a high specificity hint”) based on the answer analysis and dialogue context. [sent-97, score-0.744]
</p><p>50 At present, the system takes into consideration the number of incorrect answers received in response to the current question and the number of uninterpretable answers. [sent-98, score-0.155]
</p><p>51 1  In addition to a remediation policy, the tutorial planner implements an error recovery policy (Dzikovska et al. [sent-99, score-0.572]
</p><p>52 Since the system accepts unrestricted input, interpretation errors are unavoidable. [sent-101, score-0.181]
</p><p>53 Our recovery policy is modeled on the TargetedHelp (Hockey et al. [sent-102, score-0.134]
</p><p>54 If the system cannot find an interpretation for an utterance, it attempts to produce a message that describes the problem but without giving away the answer, for example, “I’m sorry, I’m having a problem understanding. [sent-104, score-0.173]
</p><p>55 ” The help message is accompanied with a hint at the appropriate level, also depending on the number of previous incorrect and non-interpretable answers. [sent-106, score-0.213]
</p><p>56 4  Generation  The strategy decision made by the tutorial planner, together with relevant semantic content from the student’s answer (e. [sent-108, score-0.36]
</p><p>57 , part of the answer to confirm), is passed to content planning and generation. [sent-110, score-0.172]
</p><p>58 The system uses a domain-specific content planner to produce input to the surface realizer  based on the strategy decision, and a FUF/SURGE (Elhadad and Robin, 1992) generation system to produce the appropriate text. [sent-111, score-0.246]
</p><p>59 5 Dialogue Management Interaction between components is coordinated by the dialogue manager which uses the informationstate approach (Larsson and Traum, 2000). [sent-114, score-0.24]
</p><p>60 The dialogue state is represented by a cumulative answer analysis which tracks, over multiple turns, the correct, incorrect, and not-yet-mentioned parts 1Other factors such as student confidence could be considered as well (Callaway et al. [sent-115, score-0.703]
</p><p>61 Once the complete answer has been accumulated, the system accepts it and moves on. [sent-118, score-0.183]
</p><p>62 Tutor hints can contribute parts of the answer to the cumulative state as well, allowing the system to jointly construct the solution with the student. [sent-119, score-0.228]
</p><p>63 Each participant took a pre-test, worked through a lesson with the system, took a post-test, and completed a user satisfaction survey. [sent-122, score-0.088]
</p><p>64 We implemented two different tutoring policies in the system for this evaluation. [sent-124, score-0.371]
</p><p>65 The baseline policy used an “accept and bottom out” strategy for all student answers, regardless of their content. [sent-125, score-0.483]
</p><p>66 The students were always given the correct answer, but the system made no attempt at remediation, and never indicated whether the student was understood (or correct). [sent-126, score-0.509]
</p><p>67 In comparison, the full adaptive policy attempted to select an appropriate strategy based on student answer analysis and dialogue context, as described above. [sent-127, score-0.873]
</p><p>68 On average, each student session contained 232 student language turns in the fully adaptive condition (SD = 25. [sent-129, score-0.728]
</p><p>69 Out of 81 students, 76 successfully completed the evaluation (data from 5 participants had to be discarded due to system crashes). [sent-133, score-0.112]
</p><p>70 32), and students gave higher satisfaction scores to the baseline condition (baseline: M = 3. [sent-139, score-0.138]
</p><p>71 However, the evaluation demonstrated that the system can be successfully deployed in experiments with naive users and therefore can be used to study the impact of different natural language processing algorithms on learning gain and user satisfaction. [sent-146, score-0.067]
</p><p>72 An example dialogue with the system, taken from the evaluation corpus, is shown in Figure 3. [sent-147, score-0.24]
</p><p>73 16  Tutor: Student: Tutor: Student: Tutor:  Student: Tutor:  Why was bulb A on when switch Y was open and switch Z was closed? [sent-148, score-0.263]
</p><p>74 there was a closed path not effected by the switch I’m sorry, I’m having a problem understanding. [sent-152, score-0.235]
</p><p>75 it has a closed path with the battery You’re on the right track. [sent-156, score-0.246]
</p><p>76 Bulb A is still contained in a closed path with the battery. [sent-158, score-0.188]
</p><p>77 Figure 3: Example interaction with the system from our corpus It shows three key system properties: after the student’s first turn, the system rephrases its understanding of the correct part of the student answer and prompts the student to supply the missing information. [sent-159, score-1.059]
</p><p>78 In the second turn, the student utter-  ance could not be interpreted and the system responds with a targeted help message and a hint about the object that needs to be mentioned. [sent-160, score-0.594]
</p><p>79 Finally, in the last turn the system combines the information from the tutor’s hint and the student’s answers and restates the complete answer since the current answer was completed over multiple turns. [sent-161, score-0.547]
</p><p>80 4  Conclusions and Future Work  The BEETLE II system we present was built to serve as a platform for research in computational linguistics and tutoring, and can be used for taskbased evaluation of algorithms developed for other domains. [sent-162, score-0.067]
</p><p>81 We are currently developing an annotation scheme for the data we collected to identify student paraphrases of correct answers. [sent-163, score-0.347]
</p><p>82 The annotated data will be used to evaluate the accuracy of existing paraphrasing and textual entailment approaches and to investigate how to combine such algorithms with the current deep linguistic analysis to improve system robustness. [sent-164, score-0.113]
</p><p>83 , situations where the sys-  tem arrived at an incorrect interpretation of a student utterance and took action on it. [sent-167, score-0.49]
</p><p>84 In dialogue management and generation, the key issue we are planning to investigate is that of linguistic alignment. [sent-169, score-0.296]
</p><p>85 The analysis of the data we have collected indicates that student satisfaction may be affected if the system rephrases student answers using different words (for example, using better terminology) but doesn’t explicitly explain the reason why different terminology is needed (Dzikovska et al. [sent-170, score-0.907]
</p><p>86 Results from other systems show that measures of semantic coherence between a student and a system were positively associated with higher learning gain (Ward and Litman, 2006). [sent-172, score-0.414]
</p><p>87 Using a deep generator to automatically generate system feedback gives us a level of control over the output and will allow us to devise experiments to study those issues in more detail. [sent-173, score-0.144]
</p><p>88 From the point of view of tutoring research, we are planning to use the system to answer  questions about the effectiveness of different approaches to tutoring, and the differences between human-human and human-computer tutoring. [sent-174, score-0.54]
</p><p>89 Previous comparisons of human-human and humancomputer dialogue were limited to systems that asked short-answer questions (Litman et al. [sent-175, score-0.287]
</p><p>90 Having a system that allows more unrestricted language input will provide a more balanced comparison. [sent-177, score-0.107]
</p><p>91 We are also planning experiments that will allow us to evaluate the effectiveness of individual strategies implemented in the system by comparing system versions using different tutoring policies. [sent-178, score-0.499]
</p><p>92 Towards tutorial dialog to support self-explanation: Adding natural language understanding to a cognitive tutor. [sent-187, score-0.211]
</p><p>93 Towards modelling and using common ground in tutorial dialogue. [sent-195, score-0.211]
</p><p>94 Linking semantic and knowledge representations in a multi-domain dialogue system. [sent-234, score-0.24]
</p><p>95 Targeted help for spoken dialogue systems: intelligent feedback improves naive users’ performance. [sent-281, score-0.274]
</p><p>96 Information state and dialogue management in the TRINDI Dialogue Move Engine Toolkit. [sent-289, score-0.24]
</p><p>97 Contentlearning correlations in spoken tutoring dialogs at  word, turn and discourse levels. [sent-308, score-0.288]
</p><p>98 Interactivity versus expectation: Eliciting learning oriented behavior with tutorial dialogue systems. [sent-315, score-0.451]
</p><p>99 Developing pedagogically effective tutorial dialogue tactics: Experiments and a testbed. [sent-329, score-0.451]
</p><p>100 Cohesion and learning in a tutorial spoken dialog system. [sent-333, score-0.245]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('student', 0.347), ('dzikovska', 0.296), ('tutoring', 0.254), ('dialogue', 0.24), ('beetle', 0.212), ('tutorial', 0.211), ('myroslava', 0.191), ('bulb', 0.169), ('callaway', 0.148), ('remediation', 0.148), ('tutor', 0.148), ('hint', 0.148), ('elaine', 0.127), ('steinhauser', 0.127), ('closed', 0.121), ('answer', 0.116), ('farrow', 0.106), ('gwendolyn', 0.106), ('policy', 0.103), ('litman', 0.098), ('students', 0.095), ('johanna', 0.088), ('diane', 0.086), ('flairs', 0.086), ('natalie', 0.085), ('vanlehn', 0.085), ('planner', 0.079), ('interpretation', 0.074), ('sd', 0.073), ('path', 0.067), ('system', 0.067), ('ii', 0.067), ('bulbs', 0.064), ('diagnoser', 0.064), ('kurt', 0.064), ('diagram', 0.059), ('florida', 0.059), ('nielsen', 0.058), ('battery', 0.058), ('diagnosis', 0.058), ('grove', 0.058), ('education', 0.057), ('planning', 0.056), ('strategies', 0.055), ('answers', 0.055), ('ros', 0.054), ('coconut', 0.054), ('moore', 0.054), ('architecture', 0.05), ('policies', 0.05), ('lit', 0.048), ('rephrases', 0.048), ('slate', 0.048), ('charles', 0.048), ('allen', 0.047), ('switch', 0.047), ('questions', 0.047), ('deep', 0.046), ('hints', 0.045), ('completed', 0.045), ('factual', 0.044), ('satisfaction', 0.043), ('aied', 0.042), ('aleven', 0.042), ('butler', 0.042), ('curriculum', 0.042), ('interpreter', 0.042), ('tutors', 0.042), ('specificity', 0.041), ('unrestricted', 0.04), ('electricity', 0.039), ('graesser', 0.039), ('circuit', 0.039), ('larsson', 0.039), ('pamela', 0.039), ('sorry', 0.039), ('simulation', 0.037), ('hockey', 0.036), ('exercises', 0.036), ('haifa', 0.036), ('km', 0.036), ('purandare', 0.036), ('screenshot', 0.036), ('utterance', 0.036), ('explanation', 0.035), ('campbell', 0.034), ('simulator', 0.034), ('spoken', 0.034), ('uk', 0.034), ('jordan', 0.034), ('adaptive', 0.034), ('strategy', 0.033), ('incorrect', 0.033), ('orlando', 0.033), ('edinburgh', 0.032), ('message', 0.032), ('devise', 0.031), ('electronics', 0.031), ('stock', 0.031), ('recovery', 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="47-tfidf-1" href="./acl-2010-Beetle_II%3A_A_System_for_Tutoring_and_Computational_Linguistics_Experimentation.html">47 acl-2010-Beetle II: A System for Tutoring and Computational Linguistics Experimentation</a></p>
<p>Author: Myroslava O. Dzikovska ; Johanna D. Moore ; Natalie Steinhauser ; Gwendolyn Campbell ; Elaine Farrow ; Charles B. Callaway</p><p>Abstract: We present BEETLE II, a tutorial dialogue system designed to accept unrestricted language input and support experimentation with different tutorial planning and dialogue strategies. Our first system evaluation used two different tutorial policies and demonstrated that the system can be successfully used to study the impact of different approaches to tutoring. In the future, the system can also be used to experiment with a variety ofnatural language interpretation and generation techniques.</p><p>2 0.73044652 <a title="47-tfidf-2" href="./acl-2010-The_Impact_of_Interpretation_Problems_on_Tutorial_Dialogue.html">227 acl-2010-The Impact of Interpretation Problems on Tutorial Dialogue</a></p>
<p>Author: Myroslava O. Dzikovska ; Johanna D. Moore ; Natalie Steinhauser ; Gwendolyn Campbell</p><p>Abstract: Supporting natural language input may improve learning in intelligent tutoring systems. However, interpretation errors are unavoidable and require an effective recovery policy. We describe an evaluation of an error recovery policy in the BEETLE II tutorial dialogue system and discuss how different types of interpretation problems affect learning gain and user satisfaction. In particular, the problems arising from student use of non-standard terminology appear to have negative consequences. We argue that existing strategies for dealing with terminology problems are insufficient and that improving such strategies is important in future ITS research.</p><p>3 0.15873036 <a title="47-tfidf-3" href="./acl-2010-Learning_to_Adapt_to_Unknown_Users%3A_Referring_Expression_Generation_in_Spoken_Dialogue_Systems.html">167 acl-2010-Learning to Adapt to Unknown Users: Referring Expression Generation in Spoken Dialogue Systems</a></p>
<p>Author: Srinivasan Janarthanam ; Oliver Lemon</p><p>Abstract: We present a data-driven approach to learn user-adaptive referring expression generation (REG) policies for spoken dialogue systems. Referring expressions can be difficult to understand in technical domains where users may not know the technical ‘jargon’ names of the domain entities. In such cases, dialogue systems must be able to model the user’s (lexical) domain knowledge and use appropriate referring expressions. We present a reinforcement learning (RL) framework in which the sys- tem learns REG policies which can adapt to unknown users online. Furthermore, unlike supervised learning methods which require a large corpus of expert adaptive behaviour to train on, we show that effective adaptive policies can be learned from a small dialogue corpus of non-adaptive human-machine interaction, by using a RL framework and a statistical user simulation. We show that in comparison to adaptive hand-coded baseline policies, the learned policy performs significantly better, with an 18.6% average increase in adaptation accuracy. The best learned policy also takes less dialogue time (average 1.07 min less) than the best hand-coded policy. This is because the learned policies can adapt online to changing evidence about the user’s domain expertise.</p><p>4 0.14885083 <a title="47-tfidf-4" href="./acl-2010-Towards_Relational_POMDPs_for_Adaptive_Dialogue_Management.html">239 acl-2010-Towards Relational POMDPs for Adaptive Dialogue Management</a></p>
<p>Author: Pierre Lison</p><p>Abstract: Open-ended spoken interactions are typically characterised by both structural complexity and high levels of uncertainty, making dialogue management in such settings a particularly challenging problem. Traditional approaches have focused on providing theoretical accounts for either the uncertainty or the complexity of spoken dialogue, but rarely considered the two issues simultaneously. This paper describes ongoing work on a new approach to dialogue management which attempts to fill this gap. We represent the interaction as a Partially Observable Markov Decision Process (POMDP) over a rich state space incorporating both dialogue, user, and environment models. The tractability of the resulting POMDP can be preserved using a mechanism for dynamically constraining the action space based on prior knowledge over locally relevant dialogue structures. These constraints are encoded in a small set of general rules expressed as a Markov Logic network. The first-order expressivity of Markov Logic enables us to leverage the rich relational structure of the problem and efficiently abstract over large regions ofthe state and action spaces.</p><p>5 0.12445407 <a title="47-tfidf-5" href="./acl-2010-Optimising_Information_Presentation_for_Spoken_Dialogue_Systems.html">187 acl-2010-Optimising Information Presentation for Spoken Dialogue Systems</a></p>
<p>Author: Verena Rieser ; Oliver Lemon ; Xingkun Liu</p><p>Abstract: We present a novel approach to Information Presentation (IP) in Spoken Dialogue Systems (SDS) using a data-driven statistical optimisation framework for content planning and attribute selection. First we collect data in a Wizard-of-Oz (WoZ) experiment and use it to build a supervised model of human behaviour. This forms a baseline for measuring the performance of optimised policies, developed from this data using Reinforcement Learning (RL) methods. We show that the optimised policies significantly outperform the baselines in a variety of generation scenarios: while the supervised model is able to attain up to 87.6% of the possible reward on this task, the RL policies are significantly better in 5 out of 6 scenarios, gaining up to 91.5% of the total possible reward. The RL policies perform especially well in more complex scenarios. We are also the first to show that adding predictive “lower level” features (e.g. from the NLG realiser) is important for optimising IP strategies according to user preferences. This provides new insights into the nature of the IP problem for SDS.</p><p>6 0.10700461 <a title="47-tfidf-6" href="./acl-2010-Non-Cooperation_in_Dialogue.html">178 acl-2010-Non-Cooperation in Dialogue</a></p>
<p>7 0.10015237 <a title="47-tfidf-7" href="./acl-2010-Importance-Driven_Turn-Bidding_for_Spoken_Dialogue_Systems.html">142 acl-2010-Importance-Driven Turn-Bidding for Spoken Dialogue Systems</a></p>
<p>8 0.093880199 <a title="47-tfidf-8" href="./acl-2010-Demonstration_of_a_Prototype_for_a_Conversational_Companion_for_Reminiscing_about_Images.html">82 acl-2010-Demonstration of a Prototype for a Conversational Companion for Reminiscing about Images</a></p>
<p>9 0.080522195 <a title="47-tfidf-9" href="./acl-2010-Phrase-Based_Statistical_Language_Generation_Using_Graphical_Models_and_Active_Learning.html">194 acl-2010-Phrase-Based Statistical Language Generation Using Graphical Models and Active Learning</a></p>
<p>10 0.076516427 <a title="47-tfidf-10" href="./acl-2010-Metadata-Aware_Measures_for_Answer_Summarization_in_Community_Question_Answering.html">171 acl-2010-Metadata-Aware Measures for Answer Summarization in Community Question Answering</a></p>
<p>11 0.074665122 <a title="47-tfidf-11" href="./acl-2010-Semantic_Parsing%3A_The_Task%2C_the_State_of_the_Art_and_the_Future.html">206 acl-2010-Semantic Parsing: The Task, the State of the Art and the Future</a></p>
<p>12 0.073300265 <a title="47-tfidf-12" href="./acl-2010-Classification_of_Feedback_Expressions_in_Multimodal_Data.html">58 acl-2010-Classification of Feedback Expressions in Multimodal Data</a></p>
<p>13 0.069582678 <a title="47-tfidf-13" href="./acl-2010-P10-5005_k2opt.pdf.html">190 acl-2010-P10-5005 k2opt.pdf</a></p>
<p>14 0.067242637 <a title="47-tfidf-14" href="./acl-2010-%22Was_It_Good%3F_It_Was_Provocative.%22_Learning_the_Meaning_of_Scalar_Adjectives.html">2 acl-2010-"Was It Good? It Was Provocative." Learning the Meaning of Scalar Adjectives</a></p>
<p>15 0.066209517 <a title="47-tfidf-15" href="./acl-2010-Discourse_Structure%3A_Theory%2C_Practice_and_Use.html">86 acl-2010-Discourse Structure: Theory, Practice and Use</a></p>
<p>16 0.062568523 <a title="47-tfidf-16" href="./acl-2010-Modeling_Semantic_Relevance_for_Question-Answer_Pairs_in_Web_Social_Communities.html">174 acl-2010-Modeling Semantic Relevance for Question-Answer Pairs in Web Social Communities</a></p>
<p>17 0.060809299 <a title="47-tfidf-17" href="./acl-2010-Annotation.html">31 acl-2010-Annotation</a></p>
<p>18 0.058214881 <a title="47-tfidf-18" href="./acl-2010-Speech-Driven_Access_to_the_Deep_Web_on_Mobile_Devices.html">215 acl-2010-Speech-Driven Access to the Deep Web on Mobile Devices</a></p>
<p>19 0.057829283 <a title="47-tfidf-19" href="./acl-2010-Now%2C_Where_Was_I%3F_Resumption_Strategies_for_an_In-Vehicle_Dialogue_System.html">179 acl-2010-Now, Where Was I? Resumption Strategies for an In-Vehicle Dialogue System</a></p>
<p>20 0.056395825 <a title="47-tfidf-20" href="./acl-2010-Decision_Detection_Using_Hierarchical_Graphical_Models.html">81 acl-2010-Decision Detection Using Hierarchical Graphical Models</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.133), (1, 0.105), (2, -0.074), (3, -0.266), (4, -0.053), (5, -0.277), (6, -0.224), (7, 0.086), (8, -0.119), (9, 0.008), (10, 0.13), (11, -0.07), (12, -0.047), (13, 0.034), (14, -0.002), (15, 0.034), (16, -0.225), (17, -0.228), (18, 0.09), (19, -0.264), (20, -0.114), (21, 0.353), (22, -0.13), (23, -0.183), (24, 0.024), (25, -0.113), (26, -0.085), (27, -0.078), (28, 0.03), (29, 0.041), (30, 0.06), (31, -0.01), (32, 0.076), (33, -0.12), (34, 0.119), (35, 0.061), (36, 0.106), (37, -0.078), (38, 0.016), (39, -0.075), (40, 0.063), (41, 0.141), (42, 0.086), (43, -0.09), (44, 0.007), (45, 0.056), (46, 0.017), (47, 0.017), (48, 0.028), (49, 0.036)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97012144 <a title="47-lsi-1" href="./acl-2010-Beetle_II%3A_A_System_for_Tutoring_and_Computational_Linguistics_Experimentation.html">47 acl-2010-Beetle II: A System for Tutoring and Computational Linguistics Experimentation</a></p>
<p>Author: Myroslava O. Dzikovska ; Johanna D. Moore ; Natalie Steinhauser ; Gwendolyn Campbell ; Elaine Farrow ; Charles B. Callaway</p><p>Abstract: We present BEETLE II, a tutorial dialogue system designed to accept unrestricted language input and support experimentation with different tutorial planning and dialogue strategies. Our first system evaluation used two different tutorial policies and demonstrated that the system can be successfully used to study the impact of different approaches to tutoring. In the future, the system can also be used to experiment with a variety ofnatural language interpretation and generation techniques.</p><p>2 0.96558064 <a title="47-lsi-2" href="./acl-2010-The_Impact_of_Interpretation_Problems_on_Tutorial_Dialogue.html">227 acl-2010-The Impact of Interpretation Problems on Tutorial Dialogue</a></p>
<p>Author: Myroslava O. Dzikovska ; Johanna D. Moore ; Natalie Steinhauser ; Gwendolyn Campbell</p><p>Abstract: Supporting natural language input may improve learning in intelligent tutoring systems. However, interpretation errors are unavoidable and require an effective recovery policy. We describe an evaluation of an error recovery policy in the BEETLE II tutorial dialogue system and discuss how different types of interpretation problems affect learning gain and user satisfaction. In particular, the problems arising from student use of non-standard terminology appear to have negative consequences. We argue that existing strategies for dealing with terminology problems are insufficient and that improving such strategies is important in future ITS research.</p><p>3 0.37301034 <a title="47-lsi-3" href="./acl-2010-Towards_Relational_POMDPs_for_Adaptive_Dialogue_Management.html">239 acl-2010-Towards Relational POMDPs for Adaptive Dialogue Management</a></p>
<p>Author: Pierre Lison</p><p>Abstract: Open-ended spoken interactions are typically characterised by both structural complexity and high levels of uncertainty, making dialogue management in such settings a particularly challenging problem. Traditional approaches have focused on providing theoretical accounts for either the uncertainty or the complexity of spoken dialogue, but rarely considered the two issues simultaneously. This paper describes ongoing work on a new approach to dialogue management which attempts to fill this gap. We represent the interaction as a Partially Observable Markov Decision Process (POMDP) over a rich state space incorporating both dialogue, user, and environment models. The tractability of the resulting POMDP can be preserved using a mechanism for dynamically constraining the action space based on prior knowledge over locally relevant dialogue structures. These constraints are encoded in a small set of general rules expressed as a Markov Logic network. The first-order expressivity of Markov Logic enables us to leverage the rich relational structure of the problem and efficiently abstract over large regions ofthe state and action spaces.</p><p>4 0.35315523 <a title="47-lsi-4" href="./acl-2010-Now%2C_Where_Was_I%3F_Resumption_Strategies_for_an_In-Vehicle_Dialogue_System.html">179 acl-2010-Now, Where Was I? Resumption Strategies for an In-Vehicle Dialogue System</a></p>
<p>Author: Jessica Villing</p><p>Abstract: In-vehicle dialogue systems often contain more than one application, e.g. a navigation and a telephone application. This means that the user might, for example, interrupt the interaction with the telephone application to ask for directions from the navigation application, and then resume the dialogue with the telephone application. In this paper we present an analysis of interruption and resumption behaviour in human-human in-vehicle dialogues and also propose some implications for resumption strategies in an in-vehicle dialogue system.</p><p>5 0.33348402 <a title="47-lsi-5" href="./acl-2010-Non-Cooperation_in_Dialogue.html">178 acl-2010-Non-Cooperation in Dialogue</a></p>
<p>Author: Brian Pluss</p><p>Abstract: This paper presents ongoing research on computational models for non-cooperative dialogue. We start by analysing different levels of cooperation in conversation. Then, inspired by findings from an empirical study, we propose a technique for measuring non-cooperation in political interviews. Finally, we describe a research programme towards obtaining a suitable model and discuss previous accounts for conflictive dialogue, identifying the differences with our work.</p><p>6 0.31978959 <a title="47-lsi-6" href="./acl-2010-Learning_to_Adapt_to_Unknown_Users%3A_Referring_Expression_Generation_in_Spoken_Dialogue_Systems.html">167 acl-2010-Learning to Adapt to Unknown Users: Referring Expression Generation in Spoken Dialogue Systems</a></p>
<p>7 0.3107262 <a title="47-lsi-7" href="./acl-2010-Importance-Driven_Turn-Bidding_for_Spoken_Dialogue_Systems.html">142 acl-2010-Importance-Driven Turn-Bidding for Spoken Dialogue Systems</a></p>
<p>8 0.29954565 <a title="47-lsi-8" href="./acl-2010-P10-5005_k2opt.pdf.html">190 acl-2010-P10-5005 k2opt.pdf</a></p>
<p>9 0.29432678 <a title="47-lsi-9" href="./acl-2010-%22Was_It_Good%3F_It_Was_Provocative.%22_Learning_the_Meaning_of_Scalar_Adjectives.html">2 acl-2010-"Was It Good? It Was Provocative." Learning the Meaning of Scalar Adjectives</a></p>
<p>10 0.29170665 <a title="47-lsi-10" href="./acl-2010-Optimising_Information_Presentation_for_Spoken_Dialogue_Systems.html">187 acl-2010-Optimising Information Presentation for Spoken Dialogue Systems</a></p>
<p>11 0.29009762 <a title="47-lsi-11" href="./acl-2010-Demonstration_of_a_Prototype_for_a_Conversational_Companion_for_Reminiscing_about_Images.html">82 acl-2010-Demonstration of a Prototype for a Conversational Companion for Reminiscing about Images</a></p>
<p>12 0.24571331 <a title="47-lsi-12" href="./acl-2010-Classification_of_Feedback_Expressions_in_Multimodal_Data.html">58 acl-2010-Classification of Feedback Expressions in Multimodal Data</a></p>
<p>13 0.23317541 <a title="47-lsi-13" href="./acl-2010-Phrase-Based_Statistical_Language_Generation_Using_Graphical_Models_and_Active_Learning.html">194 acl-2010-Phrase-Based Statistical Language Generation Using Graphical Models and Active Learning</a></p>
<p>14 0.22614133 <a title="47-lsi-14" href="./acl-2010-Decision_Detection_Using_Hierarchical_Graphical_Models.html">81 acl-2010-Decision Detection Using Hierarchical Graphical Models</a></p>
<p>15 0.22314434 <a title="47-lsi-15" href="./acl-2010-Metadata-Aware_Measures_for_Answer_Summarization_in_Community_Question_Answering.html">171 acl-2010-Metadata-Aware Measures for Answer Summarization in Community Question Answering</a></p>
<p>16 0.1899306 <a title="47-lsi-16" href="./acl-2010-Plot_Induction_and_Evolutionary_Search_for_Story_Generation.html">196 acl-2010-Plot Induction and Evolutionary Search for Story Generation</a></p>
<p>17 0.18872108 <a title="47-lsi-17" href="./acl-2010-Modeling_Semantic_Relevance_for_Question-Answer_Pairs_in_Web_Social_Communities.html">174 acl-2010-Modeling Semantic Relevance for Question-Answer Pairs in Web Social Communities</a></p>
<p>18 0.1788639 <a title="47-lsi-18" href="./acl-2010-Using_Speech_to_Reply_to_SMS_Messages_While_Driving%3A_An_In-Car_Simulator_User_Study.html">254 acl-2010-Using Speech to Reply to SMS Messages While Driving: An In-Car Simulator User Study</a></p>
<p>19 0.17615566 <a title="47-lsi-19" href="./acl-2010-Unsupervised_Ontology_Induction_from_Text.html">248 acl-2010-Unsupervised Ontology Induction from Text</a></p>
<p>20 0.17320867 <a title="47-lsi-20" href="./acl-2010-A_Rational_Model_of_Eye_Movement_Control_in_Reading.html">13 acl-2010-A Rational Model of Eye Movement Control in Reading</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.02), (25, 0.062), (32, 0.404), (42, 0.045), (58, 0.057), (59, 0.06), (73, 0.044), (76, 0.011), (78, 0.023), (83, 0.071), (84, 0.027), (98, 0.088)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.78529662 <a title="47-lda-1" href="./acl-2010-Beetle_II%3A_A_System_for_Tutoring_and_Computational_Linguistics_Experimentation.html">47 acl-2010-Beetle II: A System for Tutoring and Computational Linguistics Experimentation</a></p>
<p>Author: Myroslava O. Dzikovska ; Johanna D. Moore ; Natalie Steinhauser ; Gwendolyn Campbell ; Elaine Farrow ; Charles B. Callaway</p><p>Abstract: We present BEETLE II, a tutorial dialogue system designed to accept unrestricted language input and support experimentation with different tutorial planning and dialogue strategies. Our first system evaluation used two different tutorial policies and demonstrated that the system can be successfully used to study the impact of different approaches to tutoring. In the future, the system can also be used to experiment with a variety ofnatural language interpretation and generation techniques.</p><p>2 0.63436419 <a title="47-lda-2" href="./acl-2010-The_Impact_of_Interpretation_Problems_on_Tutorial_Dialogue.html">227 acl-2010-The Impact of Interpretation Problems on Tutorial Dialogue</a></p>
<p>Author: Myroslava O. Dzikovska ; Johanna D. Moore ; Natalie Steinhauser ; Gwendolyn Campbell</p><p>Abstract: Supporting natural language input may improve learning in intelligent tutoring systems. However, interpretation errors are unavoidable and require an effective recovery policy. We describe an evaluation of an error recovery policy in the BEETLE II tutorial dialogue system and discuss how different types of interpretation problems affect learning gain and user satisfaction. In particular, the problems arising from student use of non-standard terminology appear to have negative consequences. We argue that existing strategies for dealing with terminology problems are insufficient and that improving such strategies is important in future ITS research.</p><p>3 0.62101728 <a title="47-lda-3" href="./acl-2010-Grammar_Prototyping_and_Testing_with_the_LinGO_Grammar_Matrix_Customization_System.html">128 acl-2010-Grammar Prototyping and Testing with the LinGO Grammar Matrix Customization System</a></p>
<p>Author: Emily M. Bender ; Scott Drellishak ; Antske Fokkens ; Michael Wayne Goodman ; Daniel P. Mills ; Laurie Poulson ; Safiyyah Saleem</p><p>Abstract: This demonstration presents the LinGO Grammar Matrix grammar customization system: a repository of distilled linguistic knowledge and a web-based service which elicits a typological description of a language from the user and yields a customized grammar fragment ready for sustained development into a broad-coverage grammar. We describe the implementation of this repository with an emphasis on how the information is made available to users, including in-browser testing capabilities.</p><p>4 0.36095008 <a title="47-lda-4" href="./acl-2010-Temporal_Information_Processing_of_a_New_Language%3A_Fast_Porting_with_Minimal_Resources.html">225 acl-2010-Temporal Information Processing of a New Language: Fast Porting with Minimal Resources</a></p>
<p>Author: Francisco Costa ; Antonio Branco</p><p>Abstract: We describe the semi-automatic adaptation of a TimeML annotated corpus from English to Portuguese, a language for which TimeML annotated data was not available yet. In order to validate this adaptation, we use the obtained data to replicate some results in the literature that used the original English data. The fact that comparable results are obtained indicates that our approach can be used successfully to rapidly create semantically annotated resources for new languages.</p><p>5 0.35381991 <a title="47-lda-5" href="./acl-2010-Using_Anaphora_Resolution_to_Improve_Opinion_Target_Identification_in_Movie_Reviews.html">251 acl-2010-Using Anaphora Resolution to Improve Opinion Target Identification in Movie Reviews</a></p>
<p>Author: Niklas Jakob ; Iryna Gurevych</p><p>Abstract: unkown-abstract</p><p>6 0.35171494 <a title="47-lda-6" href="./acl-2010-Sparsity_in_Dependency_Grammar_Induction.html">214 acl-2010-Sparsity in Dependency Grammar Induction</a></p>
<p>7 0.34849289 <a title="47-lda-7" href="./acl-2010-Simple%2C_Accurate_Parsing_with_an_All-Fragments_Grammar.html">211 acl-2010-Simple, Accurate Parsing with an All-Fragments Grammar</a></p>
<p>8 0.34547895 <a title="47-lda-8" href="./acl-2010-Convolution_Kernel_over_Packed_Parse_Forest.html">71 acl-2010-Convolution Kernel over Packed Parse Forest</a></p>
<p>9 0.34536722 <a title="47-lda-9" href="./acl-2010-Entity-Based_Local_Coherence_Modelling_Using_Topological_Fields.html">101 acl-2010-Entity-Based Local Coherence Modelling Using Topological Fields</a></p>
<p>10 0.34323359 <a title="47-lda-10" href="./acl-2010-Experiments_in_Graph-Based_Semi-Supervised_Learning_Methods_for_Class-Instance_Acquisition.html">109 acl-2010-Experiments in Graph-Based Semi-Supervised Learning Methods for Class-Instance Acquisition</a></p>
<p>11 0.34274128 <a title="47-lda-11" href="./acl-2010-Understanding_the_Semantic_Structure_of_Noun_Phrase_Queries.html">245 acl-2010-Understanding the Semantic Structure of Noun Phrase Queries</a></p>
<p>12 0.34240609 <a title="47-lda-12" href="./acl-2010-Wikipedia_as_Sense_Inventory_to_Improve_Diversity_in_Web_Search_Results.html">261 acl-2010-Wikipedia as Sense Inventory to Improve Diversity in Web Search Results</a></p>
<p>13 0.34233189 <a title="47-lda-13" href="./acl-2010-Structural_Semantic_Relatedness%3A_A_Knowledge-Based_Method_to_Named_Entity_Disambiguation.html">218 acl-2010-Structural Semantic Relatedness: A Knowledge-Based Method to Named Entity Disambiguation</a></p>
<p>14 0.34222606 <a title="47-lda-14" href="./acl-2010-Hierarchical_Sequential_Learning_for_Extracting_Opinions_and_Their_Attributes.html">134 acl-2010-Hierarchical Sequential Learning for Extracting Opinions and Their Attributes</a></p>
<p>15 0.34157833 <a title="47-lda-15" href="./acl-2010-Learning_to_Translate_with_Source_and_Target_Syntax.html">169 acl-2010-Learning to Translate with Source and Target Syntax</a></p>
<p>16 0.34139782 <a title="47-lda-16" href="./acl-2010-Sentence_and_Expression_Level_Annotation_of_Opinions_in_User-Generated_Discourse.html">208 acl-2010-Sentence and Expression Level Annotation of Opinions in User-Generated Discourse</a></p>
<p>17 0.34137574 <a title="47-lda-17" href="./acl-2010-Minimized_Models_and_Grammar-Informed_Initialization_for_Supertagging_with_Highly_Ambiguous_Lexicons.html">172 acl-2010-Minimized Models and Grammar-Informed Initialization for Supertagging with Highly Ambiguous Lexicons</a></p>
<p>18 0.34126264 <a title="47-lda-18" href="./acl-2010-Inducing_Domain-Specific_Semantic_Class_Taggers_from_%28Almost%29_Nothing.html">150 acl-2010-Inducing Domain-Specific Semantic Class Taggers from (Almost) Nothing</a></p>
<p>19 0.34113568 <a title="47-lda-19" href="./acl-2010-Joint_Syntactic_and_Semantic_Parsing_of_Chinese.html">153 acl-2010-Joint Syntactic and Semantic Parsing of Chinese</a></p>
<p>20 0.340455 <a title="47-lda-20" href="./acl-2010-Bootstrapping_Semantic_Analyzers_from_Non-Contradictory_Texts.html">55 acl-2010-Bootstrapping Semantic Analyzers from Non-Contradictory Texts</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
