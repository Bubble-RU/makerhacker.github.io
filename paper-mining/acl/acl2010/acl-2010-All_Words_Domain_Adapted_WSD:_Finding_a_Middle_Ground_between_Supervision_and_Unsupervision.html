<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>26 acl-2010-All Words Domain Adapted WSD: Finding a Middle Ground between Supervision and Unsupervision</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-26" href="#">acl2010-26</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>26 acl-2010-All Words Domain Adapted WSD: Finding a Middle Ground between Supervision and Unsupervision</h1>
<br/><p>Source: <a title="acl-2010-26-pdf" href="http://aclweb.org/anthology//P/P10/P10-1155.pdf">pdf</a></p><p>Author: Mitesh Khapra ; Anup Kulkarni ; Saurabh Sohoney ; Pushpak Bhattacharyya</p><p>Abstract: In spite of decades of research on word sense disambiguation (WSD), all-words general purpose WSD has remained a distant goal. Many supervised WSD systems have been built, but the effort of creating the training corpus - annotated sense marked corpora - has always been a matter of concern. Therefore, attempts have been made to develop unsupervised and knowledge based techniques for WSD which do not need sense marked corpora. However such approaches have not proved effective, since they typically do not better Wordnet first sense baseline accuracy. Our research reported here proposes to stick to the supervised approach, but with far less demand on annotation. We show that if we have ANY sense marked corpora, be it from mixed domain or a specific domain, a small amount of annotation in ANY other domain can deliver the goods almost as if exhaustive sense marking were available in that domain. We have tested our approach across Tourism and Health domain corpora, using also the well known mixed domain SemCor corpus. Accuracy figures close to self domain training lend credence to the viability of our approach. Our contribution thus lies in finding a convenient middle ground between pure supervised and pure unsupervised WSD. Finally, our approach is not restricted to any specific set of target words, a departure from a commonly observed practice in domain specific WSD.</p><p>Reference: <a title="acl-2010-26-reference" href="../acl2010_reference/acl-2010-All_Words_Domain_Adapted_WSD%3A_Finding_a_Middle_Ground_between_Supervision_and_Unsupervision_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Many supervised WSD systems have been built, but the effort of creating the training corpus - annotated sense marked corpora - has always been a matter of concern. [sent-7, score-0.347]
</p><p>2 Therefore, attempts have been made to develop unsupervised and knowledge based techniques for WSD which do not need sense marked corpora. [sent-8, score-0.294]
</p><p>3 We show that if  we have ANY sense marked corpora, be it from mixed domain or a specific domain, a small amount of annotation in ANY other domain can deliver the goods almost as if exhaustive sense marking were available in that domain. [sent-11, score-0.964]
</p><p>4 We have tested our approach across Tourism and Health domain corpora, using also the well known mixed domain SemCor corpus. [sent-12, score-0.504]
</p><p>5 Finally, our approach is not restricted to any specific set of target words, a departure from a commonly observed practice in domain specific WSD. [sent-15, score-0.44]
</p><p>6 1 Introduction Amongst annotation tasks, sense marking surely takes the cake, demanding as it does high level  oflanguage competence, topic comprehension and domain sensitivity. [sent-16, score-0.4]
</p><p>7 Unsupervised and knowledge based approaches have been tried with the hope of creating WSD systems with no need for sense marked corpora (Koeling et al. [sent-21, score-0.27]
</p><p>8 Our work here is motivated by the desire to develop annotation-lean all-words domain adapted techniques for supervised WSD. [sent-26, score-0.33]
</p><p>9 It is a common observation that domain specific WSD exhibits high level of accuracy even for the all-words scenario (Khapra et al. [sent-27, score-0.276]
</p><p>10 Also domain adaptation - in which training happens in one domain and testing in another - often is able to attain good levels of performance, albeit on a specific set of target words (Chan and Ng, 2007; Agirre and de Lacalle, 2009). [sent-29, score-0.838]
</p><p>11 To the best of our knowledge there does not exist a system that solves the com-  bined problem of all words domain adapted WSD. [sent-30, score-0.293]
</p><p>12 For any target domain, create a small amount of sense annotated corpus. [sent-32, score-0.313]
</p><p>13 Mix it with an existing sense annotated corpus from a mixed domain or specific domain to train the WSD engine. [sent-34, score-0.748]
</p><p>14 In section 2 we discuss previous work in the area of domain adaptation for WSD. [sent-39, score-0.406]
</p><p>15 Section 4 discusses the injection strategy for domain adaptation. [sent-43, score-0.589]
</p><p>16 Each of these datasets contains a handful of target words (41-191 words) which are sense marked in the corpus. [sent-55, score-0.375]
</p><p>17 The former showed that adding just 30% of the target data to the source data achieved the same performance as that obtained by taking the entire source and target data. [sent-57, score-0.417]
</p><p>18 Agirre and de Lacalle (2009) reported a 22% error reduction when source and target data were combined for training a classifier, as compared to the case when only the target data was used for training the classifier. [sent-58, score-0.296]
</p><p>19 However, both these works focused on target word specific WSD and do not address all-words domain specific WSD. [sent-59, score-0.44]
</p><p>20 (2007) showed that their predominant sense acquisition method gives good results on the corpus of Koeling et al. [sent-61, score-0.39]
</p><p>21 In particular, they showed that the performance of their method is comparable to the most frequent sense obtained from a tagged corpus, thereby making a strong case for unsupervised methods for domain-specific WSD. [sent-63, score-0.31]
</p><p>22 (2009b) for unsupervised and knowledge based approaches respectively have cast a doubt on the viability of supervised approaches which rely on sense tagged corpora. [sent-68, score-0.457]
</p><p>23 (2009b) showed that a graph based algorithm which uses only the relations between concepts in a Lexical Knowledge Base (LKB) can outperform supervised approaches when tested on specific domains (for a set of chosen target words). [sent-74, score-0.364]
</p><p>24 , the most frequent sense) of each target word using pair-wise Wordnet based similarity measures by pairing the target word with its top-k neighbors in the thesaurus. [sent-92, score-0.292]
</p><p>25 Each target word is then disambiguated by assigning it its predominant sense the motivation being that the predominant sense is a powerful, hard-to-beat baseline. [sent-93, score-0.876]
</p><p>26 Each target word in the test set is then disambiguated by simply assigning it its predominant sense obtained using the above method. [sent-104, score-0.547]
</p><p>27 (2010) proposed a supervised algorithm for domain-specific WSD and showed that it beats the most frequent corpus sense and performs on par with other state of the art algorithms like PageRank. [sent-107, score-0.298]
</p><p>28 Source setting: We train the algorithm on a mixed-domain corpus (SemCor) or a domainspecific corpus (say, Tourism) and test it on a different domain (say, Health). [sent-125, score-0.311]
</p><p>29 , the best performance that can be achieved if sense marked data from the target domain were available. [sent-131, score-0.595]
</p><p>30 We augment the training data which could be from one domain or mixed domain with a small amount of data from the target domain. [sent-134, score-0.647]
</p><p>31 degree of Wordnet polysemy  Category  for polysemous words HealthTourismSemCor  Noun5. [sent-138, score-0.322]
</p><p>32 43  Table 3: Average degree of Wordnet polysemy of polysemous words per category in the 3 domains them to the training data. [sent-153, score-0.454]
</p><p>33 5  DataSet Preparation  Due to the lack of any publicly available all-words domain specific sense marked corpora we set upon the task of collecting data from two domains, viz. [sent-157, score-0.495]
</p><p>34 The data for Tourism domain was downloaded from Indian Tourism websites whereas the data for Health domain was obtained from two doctors. [sent-159, score-0.493]
</p><p>35 A total of 1,34,095 words from the Tourism domain and 42,046 words from the Health domain were manually sense marked. [sent-163, score-0.706]
</p><p>36 Some files were sense marked by both the lexicographers and the Inter Tagger Agreement (ITA) calculated from these files was 83% which is comparable to the 78% ITA reported on the SemCor corpus considering the domainspecific nature of the corpus. [sent-164, score-0.297]
</p><p>37 25 Table 2: Average number of instances per polysemous word per category in the 3 domains Avg. [sent-186, score-0.344]
</p><p>38 degree of Corpus polysemy for polysemous words Category HealthTourismSemCor Noun1. [sent-187, score-0.322]
</p><p>39 56 Table 4: Average degree of Corpus polysemy of polysemous words per category in the 3 domains Note that we do not use the monosemous words while calculating precision and recall of our algorithms. [sent-202, score-0.537]
</p><p>40 We note that the number of instances per word in the Tourism domain is comparable to that in the SemCor corpus whereas the number of instances per word in the Health corpus is smaller due to the  overall smaller size of the Health corpus. [sent-204, score-0.472]
</p><p>41 Tables 3 and 4 summarize the average degree of Wordnet polysemy and corpus polysemy of the polysemous words in the corpus. [sent-205, score-0.451]
</p><p>42 Wordnet polysemy is the number of senses of a word as listed in the Wordnet, whereas corpus polysemy is the number of senses of a word actually appearing in the corpus. [sent-206, score-0.298]
</p><p>43 As expected, the average degree of corpus polysemy (Table 4) is much less than the average degree of Wordnet polysemy (Table 3). [sent-207, score-0.302]
</p><p>44 Further, the average degree of corpus polysemy (Table 4) in the two domains is less than that in the mixed-domain SemCor corpus, which is expected due to the domain specific nature of the corpora. [sent-208, score-0.491]
</p><p>45 Finally, Table 5 summarizes the number of unique polysemous words per category in each domain. [sent-209, score-0.267]
</p><p>46 of unique polysemous words Category HealthTourismSemCor Noun218842295871  Verb Adjective Adverb  984 1024 217  1591 1635 308  2565 2640 463  All4413776311539  Table 5: Number of unique polysemous words  per category  in each domain. [sent-211, score-0.452]
</p><p>47 1535  The data is currently being enhanced by manually sense marking more words from each domain and will be soon freely available4 for research purposes. [sent-212, score-0.438]
</p><p>48 We did a 2-fold cross validation for supervised adaptation and report the average performance over the two folds. [sent-214, score-0.304]
</p><p>49 2 Unsupervised approach The predominant sense for each word in the two domains was calculated using the method described in section 4. [sent-232, score-0.412]
</p><p>50 Each target word in the test set is then disambiguated by simply assigning it its predominant sense obtained using the above method. [sent-238, score-0.547]
</p><p>51 3 Supervised adaptation We report results in the source setting, target setting and adaptation setting as described earlier using the following four combinations for source and target data: 1. [sent-252, score-0.758]
</p><p>52 In each case, the target domain data was divided into two folds. [sent-260, score-0.348]
</p><p>53 One fold was set aside for testing and the other for injecting data in the adaptation setting. [sent-261, score-0.27]
</p><p>54 We increased the size of the injected target examples from 1000 to 14000 words in increments of 1000. [sent-262, score-0.288]
</p><p>55 da Ttah (in words) iren-jected from the target domain and the y-axis rep-  resents the F-score. [sent-266, score-0.348]
</p><p>56 only random : This curve plots the performance obtained using x randomly selected sense tagged words from the target domain and zero sense tagged words from the source domain (x was varied from 1000 to 14000 words in increments of 1000). [sent-268, score-1.285]
</p><p>57 1536  Injection Size v/s F-score  Injection Size (words)  Figure 1: Supervised adaptation from SemCor to Tourism using injections  Injection Size v/s F-score  Injection Size (words)  Figure 3: Supervised adaptation from Tourism to Health using injections b. [sent-269, score-0.792]
</p><p>58 random+source : This curve plots the performance obtained by mixing x randomly selected sense tagged words from the target domain with the entire training data from the source domain (again x was varied from 1000 to 14000 words in increments of 1000). [sent-270, score-1.05]
</p><p>59 source baseline (srcb) : This represents the Fscore obtained by training on the source data  alone without mixing any examples from the target domain. [sent-272, score-0.309]
</p><p>60 wordnet first sense (wfs) : This represents the F-score obtained by selecting the first sense from Wordnet, a typically reported baseline. [sent-274, score-0.485]
</p><p>61 target skyline (tsky) : This represents the average 2-fold F-score obtained by training on one entire fold of the target data itself (Health: 15320 polysemous words; Tourism: 47242 polysemous words) and testing on the other fold. [sent-276, score-0.645]
</p><p>62 1 Knowledge Based and Unsupervised approaches It is apparent from Tables 6 and 7 that knowledge based and unsupervised approaches do not perform well when compared to the Wordnet first sense (which is freely available and hence can be used for disambiguation). [sent-280, score-0.297]
</p><p>63 , the case when training data from a source domain is applied as it is to a target domain - without using any injections). [sent-283, score-0.638]
</p><p>64 The F-score obtained by training on SemCor (mixed-domain corpus) and testing on the two target domains without using any injections (srcb) F-score of 61. [sent-287, score-0.421]
</p><p>65 , 2000; Agirre and Martinez, 2004) which suggest that instead of adapting from a generic/mixed domain to a specific domain, it is better to completely ignore the generic examples and use hand-tagged data from the target domain itself. [sent-292, score-0.653]
</p><p>66 So, while the behavior of a few target words would change drastically when the –  –  domain changes, a majority of the words will exhibit the same behavior (i. [sent-294, score-0.424]
</p><p>67 However, it is still better than the performance of unsupervised and knowledge based approaches which tilts the scale in favor of supervised approaches even when only mixed domain sense marked corpora is available. [sent-298, score-0.748]
</p><p>68 Adding injections from the target domain improves the performance. [sent-300, score-0.568]
</p><p>69 As the amount of injection increases the performance approaches the skyline, and in the case of SC→H and T→H tith even crosses dth ien skyline performance showing that combining the source and target data can give better performance than using the target data alone. [sent-301, score-0.811]
</p><p>70 This is consistent with the domain adaptation results reported by Agirre and de Lacalle (2009) on a specific set of target words. [sent-302, score-0.57]
</p><p>71 The performance of random+source is always  better than only random indicating that the data from the source domain does help to improve performance. [sent-304, score-0.354]
</p><p>72 Adapting from one specific domain (Tourism or Health) to another specific domain (Health or Tourism) gives the same performance as that obtained by adapting from a mixed-domain (SemCor) to a specific domain (Tourism, Health). [sent-307, score-0.918]
</p><p>73 This is an interesting observation as it suggests that as long as data from one domain is available it is easy to build a WSD engine that works for other domains by injecting a small amount of data from these domains. [sent-308, score-0.399]
</p><p>74 3  Quantifying the trade-off between performance and corpus size To correctly quantify the benefit of adding injections from the target domain, we calculated the amount of target data (peak size) that is needed to reach the skyline F-score (peak F) in the absence of any data from the source domain. [sent-314, score-0.735]
</p><p>75 We then plotted a graph (Figure 5) to capture the relation between the size of injections (expressed as a percentage of the peak size) and the F-score (expressed as a percentage of the peak F). [sent-318, score-0.458]
</p><p>76 Size v/s Performance  % peak_size  Figure 5: Trade-off between performance and corpus size We observe that by mixing only 20-40% of the peak size with the source domain we can obtain up to 95% of the performance obtained by using the 1538  entire target data (peak size). [sent-319, score-0.754]
</p><p>77 In absolute terms, the size of the injections is only 7000-9000 polysemous words which is a very small price to pay considering the performance benefits. [sent-320, score-0.489]
</p><p>78 In any scenario involving a shift from domain D1 to domain D2, we will always encounter words belonging to the following 4 categories: a. [sent-325, score-0.498]
</p><p>79 WD1 : This class includes words which are encountered only in the source domain D1 and do not appear in the target domain D2. [sent-326, score-0.676]
</p><p>80 Since we are interested in adapting to the target domain and since these words do not appear in the target domain, it is quite obvious that they are not important for the problem of domain adaptation. [sent-327, score-0.788]
</p><p>81 WD2 : This class includes words which are en-  countered only in the target domain D2 and do not appear in the source domain D1. [sent-329, score-0.676]
</p><p>82 Again, it is quite obvious that these words are important for the problem of domain adaptation. [sent-330, score-0.293]
</p><p>83 WD1D2conformists : This class includes words which are encountered in both the domains and exhibit the same predominant sense in both the domains. [sent-333, score-0.45]
</p><p>84 Correct identification of these words is important so that we can use the predominant sense learned from D1 for disambiguating instances of these words appearing in D2. [sent-334, score-0.473]
</p><p>85 WD1D2non−conformists : This class includes words which are encountered in both the domains but their predominant sense in the target domain D2 does not conform to the predominant sense learned from the source domain D1. [sent-336, score-1.45]
</p><p>86 Correct identification of these words is important so that we can ignore the predominant senses learned from D1 while disambiguating  instances of these words appearing in D2. [sent-337, score-0.337]
</p><p>87 The fact that nearly 50-60% of the words fall in the “conformist” category once again makes a strong case for reusing sense tagged data from one domain to another domain. [sent-339, score-0.519]
</p><p>88 The above characterization suggests that an ideal domain adaptation strategy should focus on injecting WD2 and WD1D2non−conformists as these would yield maximum benefits if injected into the training data. [sent-350, score-0.641]
</p><p>89 However, just to prove that a random injection strategy does as good as an ideal strategy  we assume the presence of an oracle which identifies the WD1D2non−conformists. [sent-352, score-0.556]
</p><p>90 This is due to the “one sense per domain” phenomenon seeing only a few instances of a word is sufficient to identify the predominant sense ofthe word. [sent-355, score-0.597]
</p><p>91 Further, to ensure a better overall performance, the instances of the most frequent words are injected first followed by less frequent words till we exhaust the total size of the injections (1000, 2000 and so on). [sent-356, score-0.425]
</p><p>92 9  Conclusion and Future Work  Based on our study of WSD in 4 domain adaptation scenarios, we make the following conclusions: 1. [sent-362, score-0.406]
</p><p>93 Supervised adaptation by mixing small amount  of data (7000-9000 words) from the target domain with the source domain gives nearly the same performance (F-score of around 70% in all the 4 adaptation scenarios) as that obtained by training on the entire target domain data. [sent-363, score-1.462]
</p><p>94 Unsupervised and knowledge based approaches which use distributional similarity and Wordnet based similarity measures do not compare well with the Wordnet first sense baseline performance and do not come anywhere close to the performance of supervised adaptation. [sent-365, score-0.437]
</p><p>95 Supervised adaptation from a mixed domain to a specific domain gives the same performance as that from one specific domain (Tourism) to another specific domain (Health). [sent-367, score-1.306]
</p><p>96 This is an interesting finding with the following implication: as long as one has sense marked corpus - be it from a mixed or specific domain - simply injecting ANY small amount of data from the target domain suffices to beget good accuracy. [sent-370, score-1.034]
</p><p>97 Knowledge-based wsd on specific domains: Performing better than generic supervised wsd. [sent-388, score-0.312]
</p><p>98 Domain adaptation with active learning for word sense  disambiguation. [sent-397, score-0.346]
</p><p>99 An empirical study of the domain dependence of supervised word sense disambiguation systems. [sent-402, score-0.53]
</p><p>100 Domain-specific word sense disambiguation combining corpus based and wordnet based parameters. [sent-422, score-0.34]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tourism', 0.486), ('health', 0.306), ('injection', 0.298), ('domain', 0.23), ('injections', 0.22), ('predominant', 0.192), ('semcor', 0.177), ('adaptation', 0.176), ('sense', 0.17), ('agirre', 0.166), ('wsd', 0.166), ('polysemous', 0.147), ('target', 0.118), ('wordnet', 0.112), ('wfs', 0.11), ('polysemy', 0.101), ('supervised', 0.1), ('lacalle', 0.096), ('mccarthy', 0.095), ('injecting', 0.094), ('koeling', 0.088), ('skyline', 0.082), ('peak', 0.079), ('conformists', 0.078), ('khapra', 0.078), ('healthtourismsemcor', 0.063), ('strategy', 0.061), ('source', 0.06), ('oracle', 0.058), ('size', 0.056), ('category', 0.052), ('unsupervised', 0.05), ('domains', 0.05), ('marked', 0.049), ('untagged', 0.047), ('specific', 0.046), ('adverb', 0.045), ('monosemous', 0.045), ('mixed', 0.044), ('ideal', 0.042), ('oier', 0.041), ('eneko', 0.039), ('morristown', 0.038), ('words', 0.038), ('mixing', 0.038), ('increments', 0.038), ('injected', 0.038), ('jcn', 0.038), ('lesk', 0.038), ('sc', 0.037), ('random', 0.036), ('degree', 0.036), ('personalized', 0.035), ('chan', 0.035), ('instances', 0.035), ('senses', 0.034), ('disambiguated', 0.034), ('rob', 0.033), ('nj', 0.033), ('obtained', 0.033), ('anup', 0.031), ('domainalgorithmp', 0.031), ('ita', 0.031), ('mitesh', 0.031), ('srcb', 0.031), ('unsupervision', 0.031), ('usseemdc', 0.031), ('viability', 0.031), ('weeber', 0.031), ('adjective', 0.031), ('lopez', 0.031), ('similarity', 0.03), ('disambiguation', 0.03), ('per', 0.03), ('pagerank', 0.03), ('tagged', 0.029), ('adapting', 0.029), ('diana', 0.029), ('corpus', 0.028), ('ng', 0.028), ('performance', 0.028), ('si', 0.028), ('escudero', 0.027), ('inject', 0.027), ('reversing', 0.027), ('sj', 0.026), ('neighbors', 0.026), ('approaches', 0.026), ('setting', 0.025), ('domainspecific', 0.025), ('synsets', 0.025), ('lexicographers', 0.025), ('mta', 0.025), ('patwardhan', 0.025), ('ppr', 0.025), ('pushpak', 0.025), ('knowledge', 0.025), ('amount', 0.025), ('obvious', 0.025), ('graph', 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="26-tfidf-1" href="./acl-2010-All_Words_Domain_Adapted_WSD%3A_Finding_a_Middle_Ground_between_Supervision_and_Unsupervision.html">26 acl-2010-All Words Domain Adapted WSD: Finding a Middle Ground between Supervision and Unsupervision</a></p>
<p>Author: Mitesh Khapra ; Anup Kulkarni ; Saurabh Sohoney ; Pushpak Bhattacharyya</p><p>Abstract: In spite of decades of research on word sense disambiguation (WSD), all-words general purpose WSD has remained a distant goal. Many supervised WSD systems have been built, but the effort of creating the training corpus - annotated sense marked corpora - has always been a matter of concern. Therefore, attempts have been made to develop unsupervised and knowledge based techniques for WSD which do not need sense marked corpora. However such approaches have not proved effective, since they typically do not better Wordnet first sense baseline accuracy. Our research reported here proposes to stick to the supervised approach, but with far less demand on annotation. We show that if we have ANY sense marked corpora, be it from mixed domain or a specific domain, a small amount of annotation in ANY other domain can deliver the goods almost as if exhaustive sense marking were available in that domain. We have tested our approach across Tourism and Health domain corpora, using also the well known mixed domain SemCor corpus. Accuracy figures close to self domain training lend credence to the viability of our approach. Our contribution thus lies in finding a convenient middle ground between pure supervised and pure unsupervised WSD. Finally, our approach is not restricted to any specific set of target words, a departure from a commonly observed practice in domain specific WSD.</p><p>2 0.20792159 <a title="26-tfidf-2" href="./acl-2010-Knowledge-Rich_Word_Sense_Disambiguation_Rivaling_Supervised_Systems.html">156 acl-2010-Knowledge-Rich Word Sense Disambiguation Rivaling Supervised Systems</a></p>
<p>Author: Simone Paolo Ponzetto ; Roberto Navigli</p><p>Abstract: One of the main obstacles to highperformance Word Sense Disambiguation (WSD) is the knowledge acquisition bottleneck. In this paper, we present a methodology to automatically extend WordNet with large amounts of semantic relations from an encyclopedic resource, namely Wikipedia. We show that, when provided with a vast amount of high-quality semantic relations, simple knowledge-lean disambiguation algorithms compete with state-of-the-art supervised WSD systems in a coarse-grained all-words setting and outperform them on gold-standard domain-specific datasets.</p><p>3 0.19240278 <a title="26-tfidf-3" href="./acl-2010-Combining_Orthogonal_Monolingual_and_Multilingual_Sources_of_Evidence_for_All_Words_WSD.html">62 acl-2010-Combining Orthogonal Monolingual and Multilingual Sources of Evidence for All Words WSD</a></p>
<p>Author: Weiwei Guo ; Mona Diab</p><p>Abstract: Word Sense Disambiguation remains one ofthe most complex problems facing computational linguists to date. In this paper we present a system that combines evidence from a monolingual WSD system together with that from a multilingual WSD system to yield state of the art performance on standard All-Words data sets. The monolingual system is based on a modification ofthe graph based state ofthe art algorithm In-Degree. The multilingual system is an improvement over an AllWords unsupervised approach, SALAAM. SALAAM exploits multilingual evidence as a means of disambiguation. In this paper, we present modifications to both of the original approaches and then their combination. We finally report the highest results obtained to date on the SENSEVAL 2 standard data set using an unsupervised method, we achieve an overall F measure of 64.58 using a voting scheme.</p><p>4 0.17712082 <a title="26-tfidf-4" href="./acl-2010-It_Makes_Sense%3A_A_Wide-Coverage_Word_Sense_Disambiguation_System_for_Free_Text.html">152 acl-2010-It Makes Sense: A Wide-Coverage Word Sense Disambiguation System for Free Text</a></p>
<p>Author: Zhi Zhong ; Hwee Tou Ng</p><p>Abstract: Word sense disambiguation (WSD) systems based on supervised learning achieved the best performance in SensEval and SemEval workshops. However, there are few publicly available open source WSD systems. This limits the use of WSD in other applications, especially for researchers whose research interests are not in WSD. In this paper, we present IMS, a supervised English all-words WSD system. The flexible framework of IMS allows users to integrate different preprocessing tools, additional features, and different classifiers. By default, we use linear support vector machines as the classifier with multiple knowledge-based features. In our implementation, IMS achieves state-of-the-art results on several SensEval and SemEval tasks.</p><p>5 0.17047745 <a title="26-tfidf-5" href="./acl-2010-Topic_Models_for_Word_Sense_Disambiguation_and_Token-Based_Idiom_Detection.html">237 acl-2010-Topic Models for Word Sense Disambiguation and Token-Based Idiom Detection</a></p>
<p>Author: Linlin Li ; Benjamin Roth ; Caroline Sporleder</p><p>Abstract: This paper presents a probabilistic model for sense disambiguation which chooses the best sense based on the conditional probability of sense paraphrases given a context. We use a topic model to decompose this conditional probability into two conditional probabilities with latent variables. We propose three different instantiations of the model for solving sense disambiguation problems with different degrees of resource availability. The proposed models are tested on three different tasks: coarse-grained word sense disambiguation, fine-grained word sense disambiguation, and detection of literal vs. nonliteral usages of potentially idiomatic expressions. In all three cases, we outper- form state-of-the-art systems either quantitatively or statistically significantly.</p><p>6 0.13950738 <a title="26-tfidf-6" href="./acl-2010-WSD_as_a_Distributed_Constraint_Optimization_Problem.html">257 acl-2010-WSD as a Distributed Constraint Optimization Problem</a></p>
<p>7 0.10691186 <a title="26-tfidf-7" href="./acl-2010-BabelNet%3A_Building_a_Very_Large_Multilingual_Semantic_Network.html">44 acl-2010-BabelNet: Building a Very Large Multilingual Semantic Network</a></p>
<p>8 0.096338667 <a title="26-tfidf-8" href="./acl-2010-Wikipedia_as_Sense_Inventory_to_Improve_Diversity_in_Web_Search_Results.html">261 acl-2010-Wikipedia as Sense Inventory to Improve Diversity in Web Search Results</a></p>
<p>9 0.090633199 <a title="26-tfidf-9" href="./acl-2010-Bilingual_Sense_Similarity_for_Statistical_Machine_Translation.html">51 acl-2010-Bilingual Sense Similarity for Statistical Machine Translation</a></p>
<p>10 0.077715904 <a title="26-tfidf-10" href="./acl-2010-Contextualizing_Semantic_Representations_Using_Syntactically_Enriched_Vector_Models.html">70 acl-2010-Contextualizing Semantic Representations Using Syntactically Enriched Vector Models</a></p>
<p>11 0.070941128 <a title="26-tfidf-11" href="./acl-2010-Domain_Adaptation_of_Maximum_Entropy_Language_Models.html">91 acl-2010-Domain Adaptation of Maximum Entropy Language Models</a></p>
<p>12 0.065097637 <a title="26-tfidf-12" href="./acl-2010-Personalising_Speech-To-Speech_Translation_in_the_EMIME_Project.html">193 acl-2010-Personalising Speech-To-Speech Translation in the EMIME Project</a></p>
<p>13 0.059240885 <a title="26-tfidf-13" href="./acl-2010-A_Framework_for_Figurative_Language_Detection_Based_on_Sense_Differentiation.html">5 acl-2010-A Framework for Figurative Language Detection Based on Sense Differentiation</a></p>
<p>14 0.058817919 <a title="26-tfidf-14" href="./acl-2010-Inducing_Domain-Specific_Semantic_Class_Taggers_from_%28Almost%29_Nothing.html">150 acl-2010-Inducing Domain-Specific Semantic Class Taggers from (Almost) Nothing</a></p>
<p>15 0.058547534 <a title="26-tfidf-15" href="./acl-2010-Cross-Language_Text_Classification_Using_Structural_Correspondence_Learning.html">78 acl-2010-Cross-Language Text Classification Using Structural Correspondence Learning</a></p>
<p>16 0.057811577 <a title="26-tfidf-16" href="./acl-2010-Open-Domain_Semantic_Role_Labeling_by_Modeling_Word_Spans.html">184 acl-2010-Open-Domain Semantic Role Labeling by Modeling Word Spans</a></p>
<p>17 0.057512086 <a title="26-tfidf-17" href="./acl-2010-Cross_Lingual_Adaptation%3A_An_Experiment_on_Sentiment_Classifications.html">80 acl-2010-Cross Lingual Adaptation: An Experiment on Sentiment Classifications</a></p>
<p>18 0.056168854 <a title="26-tfidf-18" href="./acl-2010-Creating_Robust_Supervised_Classifiers_via_Web-Scale_N-Gram_Data.html">76 acl-2010-Creating Robust Supervised Classifiers via Web-Scale N-Gram Data</a></p>
<p>19 0.055196721 <a title="26-tfidf-19" href="./acl-2010-An_Active_Learning_Approach_to_Finding_Related_Terms.html">27 acl-2010-An Active Learning Approach to Finding Related Terms</a></p>
<p>20 0.050223362 <a title="26-tfidf-20" href="./acl-2010-Improved_Unsupervised_POS_Induction_through_Prototype_Discovery.html">144 acl-2010-Improved Unsupervised POS Induction through Prototype Discovery</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.156), (1, 0.079), (2, -0.054), (3, -0.001), (4, 0.233), (5, 0.006), (6, 0.103), (7, 0.095), (8, -0.041), (9, 0.089), (10, 0.096), (11, -0.066), (12, 0.048), (13, 0.051), (14, -0.072), (15, -0.123), (16, 0.017), (17, -0.111), (18, 0.023), (19, 0.012), (20, 0.07), (21, 0.009), (22, 0.033), (23, 0.006), (24, 0.036), (25, 0.077), (26, 0.06), (27, 0.032), (28, 0.035), (29, 0.07), (30, -0.056), (31, 0.08), (32, 0.032), (33, -0.009), (34, 0.032), (35, 0.038), (36, -0.102), (37, 0.177), (38, -0.002), (39, 0.049), (40, -0.047), (41, 0.013), (42, 0.128), (43, -0.043), (44, 0.023), (45, -0.126), (46, 0.063), (47, 0.002), (48, 0.0), (49, 0.062)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95066464 <a title="26-lsi-1" href="./acl-2010-All_Words_Domain_Adapted_WSD%3A_Finding_a_Middle_Ground_between_Supervision_and_Unsupervision.html">26 acl-2010-All Words Domain Adapted WSD: Finding a Middle Ground between Supervision and Unsupervision</a></p>
<p>Author: Mitesh Khapra ; Anup Kulkarni ; Saurabh Sohoney ; Pushpak Bhattacharyya</p><p>Abstract: In spite of decades of research on word sense disambiguation (WSD), all-words general purpose WSD has remained a distant goal. Many supervised WSD systems have been built, but the effort of creating the training corpus - annotated sense marked corpora - has always been a matter of concern. Therefore, attempts have been made to develop unsupervised and knowledge based techniques for WSD which do not need sense marked corpora. However such approaches have not proved effective, since they typically do not better Wordnet first sense baseline accuracy. Our research reported here proposes to stick to the supervised approach, but with far less demand on annotation. We show that if we have ANY sense marked corpora, be it from mixed domain or a specific domain, a small amount of annotation in ANY other domain can deliver the goods almost as if exhaustive sense marking were available in that domain. We have tested our approach across Tourism and Health domain corpora, using also the well known mixed domain SemCor corpus. Accuracy figures close to self domain training lend credence to the viability of our approach. Our contribution thus lies in finding a convenient middle ground between pure supervised and pure unsupervised WSD. Finally, our approach is not restricted to any specific set of target words, a departure from a commonly observed practice in domain specific WSD.</p><p>2 0.83480656 <a title="26-lsi-2" href="./acl-2010-It_Makes_Sense%3A_A_Wide-Coverage_Word_Sense_Disambiguation_System_for_Free_Text.html">152 acl-2010-It Makes Sense: A Wide-Coverage Word Sense Disambiguation System for Free Text</a></p>
<p>Author: Zhi Zhong ; Hwee Tou Ng</p><p>Abstract: Word sense disambiguation (WSD) systems based on supervised learning achieved the best performance in SensEval and SemEval workshops. However, there are few publicly available open source WSD systems. This limits the use of WSD in other applications, especially for researchers whose research interests are not in WSD. In this paper, we present IMS, a supervised English all-words WSD system. The flexible framework of IMS allows users to integrate different preprocessing tools, additional features, and different classifiers. By default, we use linear support vector machines as the classifier with multiple knowledge-based features. In our implementation, IMS achieves state-of-the-art results on several SensEval and SemEval tasks.</p><p>3 0.81025791 <a title="26-lsi-3" href="./acl-2010-WSD_as_a_Distributed_Constraint_Optimization_Problem.html">257 acl-2010-WSD as a Distributed Constraint Optimization Problem</a></p>
<p>Author: Siva Reddy ; Abhilash Inumella</p><p>Abstract: This work models Word Sense Disambiguation (WSD) problem as a Distributed Constraint Optimization Problem (DCOP). To model WSD as a DCOP, we view information from various knowledge sources as constraints. DCOP algorithms have the remarkable property to jointly maximize over a wide range of utility functions associated with these constraints. We show how utility functions can be designed for various knowledge sources. For the purpose of evaluation, we modelled all words WSD as a simple DCOP problem. The results are competi- tive with state-of-art knowledge based systems.</p><p>4 0.78519541 <a title="26-lsi-4" href="./acl-2010-Combining_Orthogonal_Monolingual_and_Multilingual_Sources_of_Evidence_for_All_Words_WSD.html">62 acl-2010-Combining Orthogonal Monolingual and Multilingual Sources of Evidence for All Words WSD</a></p>
<p>Author: Weiwei Guo ; Mona Diab</p><p>Abstract: Word Sense Disambiguation remains one ofthe most complex problems facing computational linguists to date. In this paper we present a system that combines evidence from a monolingual WSD system together with that from a multilingual WSD system to yield state of the art performance on standard All-Words data sets. The monolingual system is based on a modification ofthe graph based state ofthe art algorithm In-Degree. The multilingual system is an improvement over an AllWords unsupervised approach, SALAAM. SALAAM exploits multilingual evidence as a means of disambiguation. In this paper, we present modifications to both of the original approaches and then their combination. We finally report the highest results obtained to date on the SENSEVAL 2 standard data set using an unsupervised method, we achieve an overall F measure of 64.58 using a voting scheme.</p><p>5 0.67646116 <a title="26-lsi-5" href="./acl-2010-Topic_Models_for_Word_Sense_Disambiguation_and_Token-Based_Idiom_Detection.html">237 acl-2010-Topic Models for Word Sense Disambiguation and Token-Based Idiom Detection</a></p>
<p>Author: Linlin Li ; Benjamin Roth ; Caroline Sporleder</p><p>Abstract: This paper presents a probabilistic model for sense disambiguation which chooses the best sense based on the conditional probability of sense paraphrases given a context. We use a topic model to decompose this conditional probability into two conditional probabilities with latent variables. We propose three different instantiations of the model for solving sense disambiguation problems with different degrees of resource availability. The proposed models are tested on three different tasks: coarse-grained word sense disambiguation, fine-grained word sense disambiguation, and detection of literal vs. nonliteral usages of potentially idiomatic expressions. In all three cases, we outper- form state-of-the-art systems either quantitatively or statistically significantly.</p><p>6 0.62784076 <a title="26-lsi-6" href="./acl-2010-Knowledge-Rich_Word_Sense_Disambiguation_Rivaling_Supervised_Systems.html">156 acl-2010-Knowledge-Rich Word Sense Disambiguation Rivaling Supervised Systems</a></p>
<p>7 0.49779803 <a title="26-lsi-7" href="./acl-2010-BabelNet%3A_Building_a_Very_Large_Multilingual_Semantic_Network.html">44 acl-2010-BabelNet: Building a Very Large Multilingual Semantic Network</a></p>
<p>8 0.48903608 <a title="26-lsi-8" href="./acl-2010-A_Framework_for_Figurative_Language_Detection_Based_on_Sense_Differentiation.html">5 acl-2010-A Framework for Figurative Language Detection Based on Sense Differentiation</a></p>
<p>9 0.46225235 <a title="26-lsi-9" href="./acl-2010-Wikipedia_as_Sense_Inventory_to_Improve_Diversity_in_Web_Search_Results.html">261 acl-2010-Wikipedia as Sense Inventory to Improve Diversity in Web Search Results</a></p>
<p>10 0.44385886 <a title="26-lsi-10" href="./acl-2010-Personalising_Speech-To-Speech_Translation_in_the_EMIME_Project.html">193 acl-2010-Personalising Speech-To-Speech Translation in the EMIME Project</a></p>
<p>11 0.39676887 <a title="26-lsi-11" href="./acl-2010-Domain_Adaptation_of_Maximum_Entropy_Language_Models.html">91 acl-2010-Domain Adaptation of Maximum Entropy Language Models</a></p>
<p>12 0.38688388 <a title="26-lsi-12" href="./acl-2010-Bilingual_Sense_Similarity_for_Statistical_Machine_Translation.html">51 acl-2010-Bilingual Sense Similarity for Statistical Machine Translation</a></p>
<p>13 0.37627161 <a title="26-lsi-13" href="./acl-2010-How_Spoken_Language_Corpora_Can_Refine_Current_Speech_Motor_Training_Methodologies.html">137 acl-2010-How Spoken Language Corpora Can Refine Current Speech Motor Training Methodologies</a></p>
<p>14 0.35082129 <a title="26-lsi-14" href="./acl-2010-Learning_Better_Data_Representation_Using_Inference-Driven_Metric_Learning.html">161 acl-2010-Learning Better Data Representation Using Inference-Driven Metric Learning</a></p>
<p>15 0.34315044 <a title="26-lsi-15" href="./acl-2010-Cross-Language_Text_Classification_Using_Structural_Correspondence_Learning.html">78 acl-2010-Cross-Language Text Classification Using Structural Correspondence Learning</a></p>
<p>16 0.33127016 <a title="26-lsi-16" href="./acl-2010-Identifying_Text_Polarity_Using_Random_Walks.html">141 acl-2010-Identifying Text Polarity Using Random Walks</a></p>
<p>17 0.33055001 <a title="26-lsi-17" href="./acl-2010-Cross_Lingual_Adaptation%3A_An_Experiment_on_Sentiment_Classifications.html">80 acl-2010-Cross Lingual Adaptation: An Experiment on Sentiment Classifications</a></p>
<p>18 0.3271504 <a title="26-lsi-18" href="./acl-2010-Temporal_Information_Processing_of_a_New_Language%3A_Fast_Porting_with_Minimal_Resources.html">225 acl-2010-Temporal Information Processing of a New Language: Fast Porting with Minimal Resources</a></p>
<p>19 0.32611349 <a title="26-lsi-19" href="./acl-2010-Inducing_Domain-Specific_Semantic_Class_Taggers_from_%28Almost%29_Nothing.html">150 acl-2010-Inducing Domain-Specific Semantic Class Taggers from (Almost) Nothing</a></p>
<p>20 0.3254534 <a title="26-lsi-20" href="./acl-2010-Generating_Fine-Grained_Reviews_of_Songs_from_Album_Reviews.html">122 acl-2010-Generating Fine-Grained Reviews of Songs from Album Reviews</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(7, 0.011), (14, 0.036), (25, 0.089), (39, 0.014), (42, 0.021), (44, 0.011), (53, 0.013), (59, 0.137), (67, 0.276), (73, 0.035), (76, 0.013), (78, 0.032), (80, 0.013), (83, 0.073), (84, 0.028), (98, 0.104)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.75491881 <a title="26-lda-1" href="./acl-2010-All_Words_Domain_Adapted_WSD%3A_Finding_a_Middle_Ground_between_Supervision_and_Unsupervision.html">26 acl-2010-All Words Domain Adapted WSD: Finding a Middle Ground between Supervision and Unsupervision</a></p>
<p>Author: Mitesh Khapra ; Anup Kulkarni ; Saurabh Sohoney ; Pushpak Bhattacharyya</p><p>Abstract: In spite of decades of research on word sense disambiguation (WSD), all-words general purpose WSD has remained a distant goal. Many supervised WSD systems have been built, but the effort of creating the training corpus - annotated sense marked corpora - has always been a matter of concern. Therefore, attempts have been made to develop unsupervised and knowledge based techniques for WSD which do not need sense marked corpora. However such approaches have not proved effective, since they typically do not better Wordnet first sense baseline accuracy. Our research reported here proposes to stick to the supervised approach, but with far less demand on annotation. We show that if we have ANY sense marked corpora, be it from mixed domain or a specific domain, a small amount of annotation in ANY other domain can deliver the goods almost as if exhaustive sense marking were available in that domain. We have tested our approach across Tourism and Health domain corpora, using also the well known mixed domain SemCor corpus. Accuracy figures close to self domain training lend credence to the viability of our approach. Our contribution thus lies in finding a convenient middle ground between pure supervised and pure unsupervised WSD. Finally, our approach is not restricted to any specific set of target words, a departure from a commonly observed practice in domain specific WSD.</p><p>2 0.59807557 <a title="26-lda-2" href="./acl-2010-Learning_to_Translate_with_Source_and_Target_Syntax.html">169 acl-2010-Learning to Translate with Source and Target Syntax</a></p>
<p>Author: David Chiang</p><p>Abstract: Statistical translation models that try to capture the recursive structure of language have been widely adopted over the last few years. These models make use of varying amounts of information from linguistic theory: some use none at all, some use information about the grammar of the target language, some use information about the grammar of the source language. But progress has been slower on translation models that are able to learn the relationship between the grammars of both the source and target language. We discuss the reasons why this has been a challenge, review existing attempts to meet this challenge, and show how some old and new ideas can be combined into a sim- ple approach that uses both source and target syntax for significant improvements in translation accuracy.</p><p>3 0.59734088 <a title="26-lda-3" href="./acl-2010-Knowledge-Rich_Word_Sense_Disambiguation_Rivaling_Supervised_Systems.html">156 acl-2010-Knowledge-Rich Word Sense Disambiguation Rivaling Supervised Systems</a></p>
<p>Author: Simone Paolo Ponzetto ; Roberto Navigli</p><p>Abstract: One of the main obstacles to highperformance Word Sense Disambiguation (WSD) is the knowledge acquisition bottleneck. In this paper, we present a methodology to automatically extend WordNet with large amounts of semantic relations from an encyclopedic resource, namely Wikipedia. We show that, when provided with a vast amount of high-quality semantic relations, simple knowledge-lean disambiguation algorithms compete with state-of-the-art supervised WSD systems in a coarse-grained all-words setting and outperform them on gold-standard domain-specific datasets.</p><p>4 0.59613919 <a title="26-lda-4" href="./acl-2010-Minimized_Models_and_Grammar-Informed_Initialization_for_Supertagging_with_Highly_Ambiguous_Lexicons.html">172 acl-2010-Minimized Models and Grammar-Informed Initialization for Supertagging with Highly Ambiguous Lexicons</a></p>
<p>Author: Sujith Ravi ; Jason Baldridge ; Kevin Knight</p><p>Abstract: We combine two complementary ideas for learning supertaggers from highly ambiguous lexicons: grammar-informed tag transitions and models minimized via integer programming. Each strategy on its own greatly improves performance over basic expectation-maximization training with a bitag Hidden Markov Model, which we show on the CCGbank and CCG-TUT corpora. The strategies provide further error reductions when combined. We describe a new two-stage integer programming strategy that efficiently deals with the high degree of ambiguity on these datasets while obtaining the full effect of model minimization.</p><p>5 0.59375119 <a title="26-lda-5" href="./acl-2010-Faster_Parsing_by_Supertagger_Adaptation.html">114 acl-2010-Faster Parsing by Supertagger Adaptation</a></p>
<p>Author: Jonathan K. Kummerfeld ; Jessika Roesner ; Tim Dawborn ; James Haggerty ; James R. Curran ; Stephen Clark</p><p>Abstract: We propose a novel self-training method for a parser which uses a lexicalised grammar and supertagger, focusing on increasing the speed of the parser rather than its accuracy. The idea is to train the supertagger on large amounts of parser output, so that the supertagger can learn to supply the supertags that the parser will eventually choose as part of the highestscoring derivation. Since the supertagger supplies fewer supertags overall, the parsing speed is increased. We demonstrate the effectiveness of the method using a CCG supertagger and parser, obtain- ing significant speed increases on newspaper text with no loss in accuracy. We also show that the method can be used to adapt the CCG parser to new domains, obtaining accuracy and speed improvements for Wikipedia and biomedical text.</p><p>6 0.59285015 <a title="26-lda-6" href="./acl-2010-Simple%2C_Accurate_Parsing_with_an_All-Fragments_Grammar.html">211 acl-2010-Simple, Accurate Parsing with an All-Fragments Grammar</a></p>
<p>7 0.58924031 <a title="26-lda-7" href="./acl-2010-Structural_Semantic_Relatedness%3A_A_Knowledge-Based_Method_to_Named_Entity_Disambiguation.html">218 acl-2010-Structural Semantic Relatedness: A Knowledge-Based Method to Named Entity Disambiguation</a></p>
<p>8 0.58891058 <a title="26-lda-8" href="./acl-2010-BabelNet%3A_Building_a_Very_Large_Multilingual_Semantic_Network.html">44 acl-2010-BabelNet: Building a Very Large Multilingual Semantic Network</a></p>
<p>9 0.58411175 <a title="26-lda-9" href="./acl-2010-A_Joint_Rule_Selection_Model_for_Hierarchical_Phrase-Based_Translation.html">9 acl-2010-A Joint Rule Selection Model for Hierarchical Phrase-Based Translation</a></p>
<p>10 0.58407402 <a title="26-lda-10" href="./acl-2010-Fully_Unsupervised_Core-Adjunct_Argument_Classification.html">120 acl-2010-Fully Unsupervised Core-Adjunct Argument Classification</a></p>
<p>11 0.58363128 <a title="26-lda-11" href="./acl-2010-Learning_Common_Grammar_from_Multilingual_Corpus.html">162 acl-2010-Learning Common Grammar from Multilingual Corpus</a></p>
<p>12 0.58332658 <a title="26-lda-12" href="./acl-2010-Creating_Robust_Supervised_Classifiers_via_Web-Scale_N-Gram_Data.html">76 acl-2010-Creating Robust Supervised Classifiers via Web-Scale N-Gram Data</a></p>
<p>13 0.58294207 <a title="26-lda-13" href="./acl-2010-Wikipedia_as_Sense_Inventory_to_Improve_Diversity_in_Web_Search_Results.html">261 acl-2010-Wikipedia as Sense Inventory to Improve Diversity in Web Search Results</a></p>
<p>14 0.58226955 <a title="26-lda-14" href="./acl-2010-Blocked_Inference_in_Bayesian_Tree_Substitution_Grammars.html">53 acl-2010-Blocked Inference in Bayesian Tree Substitution Grammars</a></p>
<p>15 0.58198082 <a title="26-lda-15" href="./acl-2010-Topic_Models_for_Word_Sense_Disambiguation_and_Token-Based_Idiom_Detection.html">237 acl-2010-Topic Models for Word Sense Disambiguation and Token-Based Idiom Detection</a></p>
<p>16 0.5809418 <a title="26-lda-16" href="./acl-2010-Using_Speech_to_Reply_to_SMS_Messages_While_Driving%3A_An_In-Car_Simulator_User_Study.html">254 acl-2010-Using Speech to Reply to SMS Messages While Driving: An In-Car Simulator User Study</a></p>
<p>17 0.58081508 <a title="26-lda-17" href="./acl-2010-It_Makes_Sense%3A_A_Wide-Coverage_Word_Sense_Disambiguation_System_for_Free_Text.html">152 acl-2010-It Makes Sense: A Wide-Coverage Word Sense Disambiguation System for Free Text</a></p>
<p>18 0.58079243 <a title="26-lda-18" href="./acl-2010-Bootstrapping_Semantic_Analyzers_from_Non-Contradictory_Texts.html">55 acl-2010-Bootstrapping Semantic Analyzers from Non-Contradictory Texts</a></p>
<p>19 0.58078796 <a title="26-lda-19" href="./acl-2010-Open-Domain_Semantic_Role_Labeling_by_Modeling_Word_Spans.html">184 acl-2010-Open-Domain Semantic Role Labeling by Modeling Word Spans</a></p>
<p>20 0.57964271 <a title="26-lda-20" href="./acl-2010-A_Semi-Supervised_Key_Phrase_Extraction_Approach%3A_Learning_from_Title_Phrases_through_a_Document_Semantic_Network.html">15 acl-2010-A Semi-Supervised Key Phrase Extraction Approach: Learning from Title Phrases through a Document Semantic Network</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
