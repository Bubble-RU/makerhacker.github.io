<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>157 acl-2010-Last but Definitely Not Least: On the Role of the Last Sentence in Automatic Polarity-Classification</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-157" href="#">acl2010-157</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>157 acl-2010-Last but Definitely Not Least: On the Role of the Last Sentence in Automatic Polarity-Classification</h1>
<br/><p>Source: <a title="acl-2010-157-pdf" href="http://aclweb.org/anthology//P/P10/P10-2061.pdf">pdf</a></p><p>Author: Israela Becker ; Vered Aharonson</p><p>Abstract: Two psycholinguistic and psychophysical experiments show that in order to efficiently extract polarity of written texts such as customerreviews on the Internet, one should concentrate computational efforts on messages in the final position of the text.</p><p>Reference: <a title="acl-2010-157-reference" href="../acl2010_reference/acl-2010-Last_but_Definitely_Not_Least%3A_On_the_Role_of_the_Last_Sentence_in_Automatic_Polarity-Classification_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 i s l –  Abstract Two psycholinguistic and psychophysical experiments show that in order to efficiently extract polarity of written texts such as customerreviews on the Internet, one should concentrate computational efforts on messages in the final position of the text. [sent-4, score-0.714]
</p><p>2 1 Introduction The ever-growing field of polarity-classification of written texts may benefit greatly from linguistic insights and tools that will allow to efficiently (and thus economically) extract the polarity of written texts, in particular, online customer reviews. [sent-5, score-0.643]
</p><p>3 Many researchers interpret “efficiently” as using better computational methods to resolve the polarity of written texts. [sent-6, score-0.306]
</p><p>4 We suggest that text  units should be handled with tools of discourse linguistics too in order to reveal where, within texts, their polarity is best manifested. [sent-7, score-0.367]
</p><p>5 Specifically, we propose to focus on the last sentence of the given text in order to efficiently extract the polarity of the whole text. [sent-8, score-0.616]
</p><p>6 This will reduce computational costs, as well as improve the quality of polarity detection and classification when large databases of text units are involved. [sent-9, score-0.325]
</p><p>7 Therefore, we first briefly review the well-established structure of text units while comparing notions of topicextraction vs. [sent-11, score-0.207]
</p><p>8 We then report the psycholinguistic experiments that we ran in order to support our prediction as to the role of the last sentence in polarity manifestation. [sent-13, score-0.614]
</p><p>9 2  Topic-extraction  One of the basic features required to perform automatic topic-extraction is sentence position. [sent-15, score-0.068]
</p><p>10 The importance of sentence position for computational purposes was first indicated by Baxendale in the late 1950s (Baxendale, 1958): Baxendale hypothesized that the first and the last sentence of a given text are the potential topiccontaining sentences. [sent-16, score-0.343]
</p><p>11 He tested this hypothesis on a corpus of 200 paragraphs extracted out of 6 technical articles. [sent-17, score-0.111]
</p><p>12 He found that in 85% of the documents, the first sentence was the topic sentence, whereas in only 7% of the documents, it was the last sentence. [sent-18, score-0.248]
</p><p>13 A large scale study supporting Baxendale’s hypothesis was conducted by Lin and Hovy (Lin and Hovy, 1997) who examined 13,000 documents of the Ziff-Davis newswire corpus of articles reviewing computer hardware and software. [sent-19, score-0.12]
</p><p>14 In this corpus, each document was accompanied by a set of topic keywords and a small abstract of six sentences. [sent-20, score-0.126]
</p><p>15 Lin and Hovy measured the yield of each sentence against the topic keywords and ranked the sentences by their average yield. [sent-21, score-0.244]
</p><p>16 They con-  cluded that in ~2/3 of the documents, the topic keywords are indeed mentioned in the title and first five sentences of the document. [sent-22, score-0.205]
</p><p>17 Baxendale’s theory gained further psycholinguistic support by the experimental results of Kieras (Kieras, 1978, Kieras, 1980) who showed that subjects re-constructed the content 331  UppsalaP,r Sowceeeddeinn,g 1s1 o-f16 th Jeu AlyC 2L0 21001. [sent-23, score-0.344]
</p><p>18 c C2o0n1f0er Aenscseoc Sihatoirotn P faopre Crso,m papguetsat 3io3n1a–l3 L3i5n,guistics  of paragraphs they were asked to read by relying on sentences in initial positions. [sent-25, score-0.24]
</p><p>19 These finding subsequently gained extensive theoretical and experimental support by Giora (Giora, 1983, Giora, 1985) who correlated the position of a sentence within a text with its degree of informativeness. [sent-26, score-0.194]
</p><p>20 Giora (Giora, 1985, Giora, 1988) defined a discourse topic (DT) as the least informative (most uninformative) yet dominant proposition of a text. [sent-27, score-0.177]
</p><p>21 As such, this proposition functions as a reference point for processing the rest of the propositions. [sent-29, score-0.057]
</p><p>22 The text position which best benefits such processing is text  initial; it facilitates processing of oncoming propositions (with respect to the DT) relative to when the DT is placed in text final position. [sent-30, score-0.145]
</p><p>23 Furthermore, Giora and Lee showed (Giora and Lee, 1996) that when the DT appears also at the end of a text it is somewhat informationally redundant. [sent-31, score-0.135]
</p><p>24 However, functionally, it plays a role in wrapping the text up and marking its boundary. [sent-32, score-0.035]
</p><p>25 Authors often make reference to the DT at the end of a text in order to summarize and deliberately recapitulate what has been written up to that point while also signaling the end of discourse topic segment. [sent-33, score-0.223]
</p><p>26 Topic-  When dealing with polarity-classification (as with topic-extraction), one should again identify the most uninformative yet dominant proposition of the text. [sent-35, score-0.152]
</p><p>27 Based on preliminary investigations, we suggest that the DT of any customer review is the customer’s evaluation, whether negative or positive, of a product that s/he has purchased or a service s/he has used, rather than the details of the specific product or service. [sent-37, score-0.518]
</p><p>28 The message that customer reviews try to get across is, therefore, of evaluative nature. [sent-38, score-0.486]
</p><p>29 To best communicate this affect, the DT should appear at the end of the review (instead of the beginning of the review) as a means of recapitulating the point of the message, thereby guaranteeing that it is fully understood by the readership. [sent-39, score-0.171]
</p><p>30 Indeed, the cognitive prominence of information in final position - the recency-effect - has been well established in numerous psychological experiments (see, for example, (Murdock, 1962)). [sent-40, score-0.09]
</p><p>31 Thus, the most frequent evaluation of the product (which is the most uninformative one) also should surface at the end of the text due to the ease of its retrieval, which is presumably what product review readers would re-  fer to as “the bottom line”. [sent-41, score-0.617]
</p><p>32 To the best of our knowledge, this psycholinguistic prediction has not been supported by psycholinguistic evidence to date. [sent-42, score-0.304]
</p><p>33 However, it has been somewhat supported by the computational results of Yang, Lin and Chen (Yang et al. [sent-43, score-0.031]
</p><p>34 , 2007b) who classified emotions of posts in blog corpora. [sent-45, score-0.069]
</p><p>35 Yang, Lin & Chen realized that bloggers tend to emphasize their feelings by using emoticons (such as: ☺," and #) and that these emoticons frequently appear in final sentences. [sent-46, score-0.116]
</p><p>36 Thus, they first focused on the last sentence of posts as representing the polarity of the entire posts. [sent-47, score-0.498]
</p><p>37 They showed that extracting polarity and consequently sentiments from last sentences outperforms all other computational strategies. [sent-49, score-0.517]
</p><p>38 4  Method  We aim to show that the last sentence of a customer review is a better predictor for the polarity of the whole review than any other sentence (assuming that the first sentence is devoted to pre-  senting the product or service). [sent-50, score-1.306]
</p><p>39 In the first experiment we examined the readers’ rating of the polarity of reviews in their entirety, while in the second experiment we examined the readers’ rating of the same reviews based on reading single sentences extracted from these reviews: the last sentence or the second one. [sent-52, score-2.12]
</p><p>40 The second sentence could have been replaced by any other sentence, but the first one, as our preliminary investigations clearly show that the first sentence is in many cases devoted to presenting the product or service discussed and does not contain any polarity content. [sent-53, score-0.604]
</p><p>41 For example: "I read Isaac’s storm, by Erik Larson, around 1998. [sent-54, score-0.049]
</p><p>42 All in all a most interesting and rewarding book, one that I would recommend highly. [sent-57, score-0.051]
</p><p>43 1  Materials  Sixteen customer-reviews were extracted from  Blitzer, Dredze, and Pereira’s sentiment database (Blitzer et al. [sent-60, score-0.065]
</p><p>44 This database contains product-reviews taken from Amazon 1 where each review is rated by its author on a 15 star scale. [sent-62, score-0.299]
</p><p>45 The database covers 4 product types (domains): Kitchen, Books, DVDs, and Electronics. [sent-63, score-0.11]
</p><p>46 Of the 16 extracted reviews, 8 were positive (4-5 star rating) and the other 8 negative (1-2 star rating). [sent-65, score-0.264]
</p><p>47 Given that in this experiment we examine the polarity of the last sentence relative to that of the whole review or to a few other sentences, we focused on the first reviews (as listed in the aforementioned database) of at least 5 sentences or longer, rather than on too-short reviews. [sent-66, score-1.097]
</p><p>48 By “too-short” we refer to reviews in which such comparison would be meaningless; for example, ones that range between 1-3 sentences will not allow to compare the last sentence with any of the others. [sent-67, score-0.55]
</p><p>49 2  Participants  Thirty-five subjects participated in the first experiment: 14 women and 21 men, ranging in age  from 22 to 73. [sent-69, score-0.227]
</p><p>50 Thirty-six subjects participated in the second experiment: 23 women and 13 men ranging in age from 20 to 59. [sent-70, score-0.292]
</p><p>51 3  Procedure  In the first experiment, subjects were asked to read 16 reviews; in the second experiment subjects were asked to read 32 single sentences extracted from the same 16 reviews: the last sentence and the second sentence of each review. [sent-73, score-0.941]
</p><p>52 The last and the second sentence of each review were not presented together but individually. [sent-74, score-0.37]
</p><p>53 In both experiments subjects were asked to guess the ratings of the texts which were given by the authors on a 1-5 star scale, by clicking on a radio-button: “In each of the following screens you will be asked to read a customer review (or a sentence extracted out of a customer review). [sent-75, score-1.278]
</p><p>54 At the end of each review (or sentence)  1 http://www. [sent-80, score-0.171]
</p><p>55 ” In the second experiment, in addition to the psychological experiment, the latencies following reading of the texts up until the clicking of the mouse, as well as the biometric measurements of the mouse’s trajectories, were recorded. [sent-83, score-0.299]
</p><p>56 In both experiments each subject was run in an individual session and had an unlimited time to reflect and decide on the polarity of each text. [sent-84, score-0.262]
</p><p>57 Five seconds after a decision was made (as to whether the reviewer was in favor of the product or not), the subject was presented with the next text. [sent-85, score-0.151]
</p><p>58 The texts were presented in random order so as to prevent possible interactions between them. [sent-86, score-0.069]
</p><p>59 In the initial design phase of the experiment  we discussed the idea of adding an “irrelevant” option in addition to the 5-star scale of polarity. [sent-87, score-0.114]
</p><p>60 This option was meant to be used for sentences that carry no evaluation at all. [sent-88, score-0.108]
</p><p>61 Such an addition would have necessitated locating the extrachoice radio button at a separated remote place from the 5-star scale radio buttons, since conceptually it cannot be located on a nearby position. [sent-89, score-0.252]
</p><p>62 Although the reviews were randomly selected, 32 sentences extracted out of 16 reviews might seem like a small sample. [sent-91, score-0.647]
</p><p>63 However, the upper time limit for reliable psycholinguistic experiments is 20-25 minute. [sent-92, score-0.152]
</p><p>64 Although tempted to extend the experiments in order to acquire more data, longer times result in subject impatience, which shows on lower scoring rates. [sent-93, score-0.027]
</p><p>65 Ex-  perimental times in both experiments ranged between 15-35 minutes. [sent-95, score-0.027]
</p><p>66 5 Results Results of the distribution of differences between the authors’ and the readers’ ratings of the texts are presented in Figure 1: The distribution of differences for whole reviews is (unsurprisingly) the narrowest (Figure 1a). [sent-96, score-0.54]
</p><p>67 The dis333  tribution of differences for last sentences (Figure 1b) is somewhat wider than (but still quite similar to) the distribution of differences for whole reviews. [sent-97, score-0.387]
</p><p>68 The distribution of differences for second sentences is the widest of the three (Figure 1c). [sent-98, score-0.135]
</p><p>69 Moreover, when correlating readers’ rating of whole reviews with readers’ rating of single sentences, the correlation coefficient for last sentences is significantly higher than for second sentences. [sent-100, score-1.422]
</p><p>70 As for the biometric measurements performed in the second experiment, since all subjects were computer-skilled, hesitation revealed through mouse-movements was assumed to be attributed to difficulty of decision-making rather than to problems in operating the mouse. [sent-101, score-0.314]
</p><p>71 As previously stated, we recorded mouse latency times following the reading of the texts up until clicking the mouse. [sent-102, score-0.555]
</p><p>72 Mouse latency times were not normalized for each subject due to the limited number of results. [sent-103, score-0.153]
</p><p>73 However, the average latency time is shorter for last sentences (19. [sent-104, score-0.373]
</p><p>74 Indeed, the difference between latency times is not significant, as a paired t-test could not reject the null hypothesis that those distributions have equal means, but might show some tendency. [sent-109, score-0.182]
</p><p>75 We also used the WizWhy software (Meidan,  2005) to perform combined analyses of readers’ rating and response times. [sent-110, score-0.39]
</p><p>76 The analyses showed that when the difference between authors’ and readers’ ratings was ≤ 1 and the response time much shorter than average (<14. [sent-111, score-0.161]
</p><p>77 1 sec), then 96% of the sentences were last sentences. [sent-112, score-0.213]
</p><p>78 Due to the small sample size, we cautiously infer that last sentences express polarity better than second sentences, bearing in mind that the second sentence in our experiment represents any other sentence in the text except for the first one. [sent-113, score-0.752]
</p><p>79 We also predicted that hesitation in making a decision would effect not only latency times but also mouse trajectories. [sent-114, score-0.446]
</p><p>80 Namely, hesitation will be accompanied by moving the mouse here and there, while decisiveness will show a firm movement. [sent-115, score-0.324]
</p><p>81 However, no such difference between the responses to last sentences or to second sentences appeared in our analysis; most subjects laid their hand still while reading the texts and while reflecting upon their answers. [sent-116, score-0.57]
</p><p>82    6  Conclusions and Future Work  In 2 psycholinguistic and psychophysical experiments, we showed that rating whole customer-reviews as compared to rating final sentences of these reviews showed an (expected) insignificant difference. [sent-118, score-1.516]
</p><p>83 In contrast, rating whole customer-reviews as compared to rating second sentences of these reviews, showed a considerable difference. [sent-119, score-0.964]
</p><p>84 Thus, instead of focusing on whole texts, computational linguists should focus on the last sentences for efficient and accurate automatic polarity-classification. [sent-120, score-0.3]
</p><p>85 We are currently running experiments that  Rating Difference (Authors' rating - Readers' rating) Figure 1. [sent-122, score-0.364]
</p><p>86 Histograms of the rating differences between the authors of reviews and their readers: for whole reviews (a), for last sentence only (b), and for second sentence only (c). [sent-123, score-1.375]
</p><p>87 334  Readers’ star rating of: Correlated with: Pearson Correlation Coefficient (P<0. [sent-124, score-0.482]
</p><p>88 0001) Whole reviews  Last sentences Second sentences Last sentences Second sentences  Authors’ star rating of whole  reviews  0. [sent-125, score-1.431]
</p><p>89 Pearson Correlation Coefficients  include hundreds of subjects in order to draw a profile of polarity evolvement throughout customer reviews. [sent-131, score-0.578]
</p><p>90 Specifically, we present our subjects with sentences in various locations in customer reviews asking them to rate them. [sent-132, score-0.666]
</p><p>91 As the expanded experiment is not psychophysical, we added an additional remote radio button named “irrelevant” where subjects can judge a given  text as lacking any evident polarity. [sent-133, score-0.371]
</p><p>92 Based on the rating results we will draw polarity profiles in order to see where, within customer reviews, polarity is best manifested and whether there are other “candidates” sentences that would serve as useful polarity indicators. [sent-134, score-1.464]
</p><p>93 The profiles will be used as a feature in our computational analysis. [sent-135, score-0.041]
</p><p>94 Henry - for their help with programming and running the psychophysical experiment. [sent-139, score-0.115]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('giora', 0.403), ('rating', 0.364), ('reviews', 0.269), ('polarity', 0.262), ('mouse', 0.217), ('readers', 0.2), ('customer', 0.192), ('psycholinguistic', 0.152), ('baxendale', 0.151), ('review', 0.144), ('kieras', 0.144), ('last', 0.132), ('latency', 0.126), ('subjects', 0.124), ('star', 0.118), ('psychophysical', 0.115), ('dt', 0.096), ('whole', 0.087), ('sentences', 0.081), ('reviewer', 0.078), ('hesitation', 0.076), ('product', 0.073), ('texts', 0.069), ('sentence', 0.068), ('correlation', 0.066), ('uninformative', 0.065), ('authors', 0.064), ('radio', 0.061), ('ratings', 0.059), ('clicking', 0.059), ('biometric', 0.058), ('changua', 0.058), ('emoticons', 0.058), ('meidan', 0.058), ('murdock', 0.058), ('remote', 0.058), ('reading', 0.057), ('proposition', 0.057), ('asked', 0.056), ('paragraphs', 0.054), ('experiment', 0.054), ('yang', 0.054), ('lin', 0.051), ('recommend', 0.051), ('prominence', 0.05), ('read', 0.049), ('topic', 0.048), ('keywords', 0.047), ('blitzer', 0.047), ('pearson', 0.047), ('written', 0.044), ('hovy', 0.044), ('definitely', 0.043), ('women', 0.043), ('discourse', 0.042), ('showed', 0.042), ('profiles', 0.041), ('emotion', 0.041), ('chen', 0.04), ('position', 0.04), ('button', 0.039), ('men', 0.039), ('dredze', 0.038), ('rachel', 0.038), ('database', 0.037), ('posts', 0.036), ('investigations', 0.036), ('service', 0.036), ('text', 0.035), ('devoted', 0.035), ('recommended', 0.035), ('shorter', 0.034), ('coefficient', 0.033), ('examined', 0.033), ('scale', 0.033), ('predictor', 0.033), ('blog', 0.033), ('efficiently', 0.032), ('somewhat', 0.031), ('accompanied', 0.031), ('participated', 0.03), ('measurements', 0.03), ('age', 0.03), ('dominant', 0.03), ('hypothesis', 0.029), ('indeed', 0.029), ('proceeding', 0.029), ('differences', 0.028), ('extracted', 0.028), ('units', 0.028), ('end', 0.027), ('option', 0.027), ('times', 0.027), ('response', 0.026), ('second', 0.026), ('irrelevant', 0.026), ('gained', 0.026), ('documents', 0.025), ('correlated', 0.025), ('message', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.000001 <a title="157-tfidf-1" href="./acl-2010-Last_but_Definitely_Not_Least%3A_On_the_Role_of_the_Last_Sentence_in_Automatic_Polarity-Classification.html">157 acl-2010-Last but Definitely Not Least: On the Role of the Last Sentence in Automatic Polarity-Classification</a></p>
<p>Author: Israela Becker ; Vered Aharonson</p><p>Abstract: Two psycholinguistic and psychophysical experiments show that in order to efficiently extract polarity of written texts such as customerreviews on the Internet, one should concentrate computational efforts on messages in the final position of the text.</p><p>2 0.14699164 <a title="157-tfidf-2" href="./acl-2010-Generating_Fine-Grained_Reviews_of_Songs_from_Album_Reviews.html">122 acl-2010-Generating Fine-Grained Reviews of Songs from Album Reviews</a></p>
<p>Author: Swati Tata ; Barbara Di Eugenio</p><p>Abstract: Music Recommendation Systems often recommend individual songs, as opposed to entire albums. The challenge is to generate reviews for each song, since only full album reviews are available on-line. We developed a summarizer that combines information extraction and generation techniques to produce summaries of reviews of individual songs. We present an intrinsic evaluation of the extraction components, and of the informativeness of the summaries; and a user study of the impact of the song review summaries on users’ decision making processes. Users were able to make quicker and more informed decisions when presented with the summary as compared to the full album review.</p><p>3 0.1346228 <a title="157-tfidf-3" href="./acl-2010-Sentiment_Learning_on_Product_Reviews_via_Sentiment_Ontology_Tree.html">209 acl-2010-Sentiment Learning on Product Reviews via Sentiment Ontology Tree</a></p>
<p>Author: Wei Wei ; Jon Atle Gulla</p><p>Abstract: Existing works on sentiment analysis on product reviews suffer from the following limitations: (1) The knowledge of hierarchical relationships of products attributes is not fully utilized. (2) Reviews or sentences mentioning several attributes associated with complicated sentiments are not dealt with very well. In this paper, we propose a novel HL-SOT approach to labeling a product’s attributes and their associated sentiments in product reviews by a Hierarchical Learning (HL) process with a defined Sentiment Ontology Tree (SOT). The empirical analysis against a humanlabeled data set demonstrates promising and reasonable performance of the proposed HL-SOT approach. While this paper is mainly on sentiment analysis on reviews of one product, our proposed HLSOT approach is easily generalized to labeling a mix of reviews of more than one products.</p><p>4 0.11884617 <a title="157-tfidf-4" href="./acl-2010-%22Was_It_Good%3F_It_Was_Provocative.%22_Learning_the_Meaning_of_Scalar_Adjectives.html">2 acl-2010-"Was It Good? It Was Provocative." Learning the Meaning of Scalar Adjectives</a></p>
<p>Author: Marie-Catherine de Marneffe ; Christopher D. Manning ; Christopher Potts</p><p>Abstract: Texts and dialogues often express information indirectly. For instance, speakers’ answers to yes/no questions do not always straightforwardly convey a ‘yes’ or ‘no’ answer. The intended reply is clear in some cases (Was it good? It was great!) but uncertain in others (Was it acceptable? It was unprecedented.). In this paper, we present methods for interpreting the answers to questions like these which involve scalar modifiers. We show how to ground scalar modifier meaning based on data collected from the Web. We learn scales between modifiers and infer the extent to which a given answer conveys ‘yes’ or ‘no’ . To evaluate the methods, we collected examples of question–answer pairs involving scalar modifiers from CNN transcripts and the Dialog Act corpus and use response distributions from Mechanical Turk workers to assess the degree to which each answer conveys ‘yes’ or ‘no’ . Our experimental results closely match the Turkers’ response data, demonstrating that meanings can be learned from Web data and that such meanings can drive pragmatic inference.</p><p>5 0.11554974 <a title="157-tfidf-5" href="./acl-2010-Cognitively_Plausible_Models_of_Human_Language_Processing.html">59 acl-2010-Cognitively Plausible Models of Human Language Processing</a></p>
<p>Author: Frank Keller</p><p>Abstract: We pose the development of cognitively plausible models of human language processing as a challenge for computational linguistics. Existing models can only deal with isolated phenomena (e.g., garden paths) on small, specifically selected data sets. The challenge is to build models that integrate multiple aspects of human language processing at the syntactic, semantic, and discourse level. Like human language processing, these models should be incremental, predictive, broad coverage, and robust to noise. This challenge can only be met if standardized data sets and evaluation measures are developed.</p><p>6 0.11338596 <a title="157-tfidf-6" href="./acl-2010-Sentence_and_Expression_Level_Annotation_of_Opinions_in_User-Generated_Discourse.html">208 acl-2010-Sentence and Expression Level Annotation of Opinions in User-Generated Discourse</a></p>
<p>7 0.10358789 <a title="157-tfidf-7" href="./acl-2010-Generating_Focused_Topic-Specific_Sentiment_Lexicons.html">123 acl-2010-Generating Focused Topic-Specific Sentiment Lexicons</a></p>
<p>8 0.103286 <a title="157-tfidf-8" href="./acl-2010-Identifying_Text_Polarity_Using_Random_Walks.html">141 acl-2010-Identifying Text Polarity Using Random Walks</a></p>
<p>9 0.10108707 <a title="157-tfidf-9" href="./acl-2010-Optimizing_Informativeness_and_Readability_for_Sentiment_Summarization.html">188 acl-2010-Optimizing Informativeness and Readability for Sentiment Summarization</a></p>
<p>10 0.092485487 <a title="157-tfidf-10" href="./acl-2010-Cross-Language_Text_Classification_Using_Structural_Correspondence_Learning.html">78 acl-2010-Cross-Language Text Classification Using Structural Correspondence Learning</a></p>
<p>11 0.085864209 <a title="157-tfidf-11" href="./acl-2010-Cross_Lingual_Adaptation%3A_An_Experiment_on_Sentiment_Classifications.html">80 acl-2010-Cross Lingual Adaptation: An Experiment on Sentiment Classifications</a></p>
<p>12 0.083519086 <a title="157-tfidf-12" href="./acl-2010-Hierarchical_Sequential_Learning_for_Extracting_Opinions_and_Their_Attributes.html">134 acl-2010-Hierarchical Sequential Learning for Extracting Opinions and Their Attributes</a></p>
<p>13 0.082013212 <a title="157-tfidf-13" href="./acl-2010-A_Study_of_Information_Retrieval_Weighting_Schemes_for_Sentiment_Analysis.html">18 acl-2010-A Study of Information Retrieval Weighting Schemes for Sentiment Analysis</a></p>
<p>14 0.073471792 <a title="157-tfidf-14" href="./acl-2010-Incorporating_Extra-Linguistic_Information_into_Reference_Resolution_in_Collaborative_Task_Dialogue.html">149 acl-2010-Incorporating Extra-Linguistic Information into Reference Resolution in Collaborative Task Dialogue</a></p>
<p>15 0.069769867 <a title="157-tfidf-15" href="./acl-2010-Syntactic_and_Semantic_Factors_in_Processing_Difficulty%3A_An_Integrated_Measure.html">220 acl-2010-Syntactic and Semantic Factors in Processing Difficulty: An Integrated Measure</a></p>
<p>16 0.066632383 <a title="157-tfidf-16" href="./acl-2010-Recommendation_in_Internet_Forums_and_Blogs.html">204 acl-2010-Recommendation in Internet Forums and Blogs</a></p>
<p>17 0.064355917 <a title="157-tfidf-17" href="./acl-2010-Cross-Language_Document_Summarization_Based_on_Machine_Translation_Quality_Prediction.html">77 acl-2010-Cross-Language Document Summarization Based on Machine Translation Quality Prediction</a></p>
<p>18 0.060763478 <a title="157-tfidf-18" href="./acl-2010-The_Influence_of_Discourse_on_Syntax%3A_A_Psycholinguistic_Model_of_Sentence_Processing.html">229 acl-2010-The Influence of Discourse on Syntax: A Psycholinguistic Model of Sentence Processing</a></p>
<p>19 0.060235903 <a title="157-tfidf-19" href="./acl-2010-Using_Anaphora_Resolution_to_Improve_Opinion_Target_Identification_in_Movie_Reviews.html">251 acl-2010-Using Anaphora Resolution to Improve Opinion Target Identification in Movie Reviews</a></p>
<p>20 0.055174407 <a title="157-tfidf-20" href="./acl-2010-Profiting_from_Mark-Up%3A_Hyper-Text_Annotations_for_Guided_Parsing.html">200 acl-2010-Profiting from Mark-Up: Hyper-Text Annotations for Guided Parsing</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.144), (1, 0.096), (2, -0.133), (3, 0.079), (4, -0.105), (5, -0.0), (6, -0.024), (7, -0.025), (8, -0.003), (9, 0.001), (10, 0.004), (11, 0.05), (12, 0.058), (13, 0.088), (14, -0.088), (15, 0.069), (16, 0.117), (17, -0.028), (18, 0.013), (19, 0.032), (20, -0.08), (21, 0.025), (22, 0.028), (23, -0.07), (24, -0.012), (25, 0.021), (26, 0.033), (27, -0.031), (28, -0.088), (29, 0.051), (30, -0.025), (31, 0.08), (32, -0.054), (33, 0.039), (34, 0.023), (35, -0.027), (36, 0.048), (37, 0.078), (38, 0.016), (39, 0.018), (40, -0.041), (41, 0.087), (42, -0.04), (43, -0.069), (44, -0.004), (45, -0.132), (46, 0.051), (47, -0.152), (48, 0.149), (49, -0.055)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95341063 <a title="157-lsi-1" href="./acl-2010-Last_but_Definitely_Not_Least%3A_On_the_Role_of_the_Last_Sentence_in_Automatic_Polarity-Classification.html">157 acl-2010-Last but Definitely Not Least: On the Role of the Last Sentence in Automatic Polarity-Classification</a></p>
<p>Author: Israela Becker ; Vered Aharonson</p><p>Abstract: Two psycholinguistic and psychophysical experiments show that in order to efficiently extract polarity of written texts such as customerreviews on the Internet, one should concentrate computational efforts on messages in the final position of the text.</p><p>2 0.69133681 <a title="157-lsi-2" href="./acl-2010-Generating_Fine-Grained_Reviews_of_Songs_from_Album_Reviews.html">122 acl-2010-Generating Fine-Grained Reviews of Songs from Album Reviews</a></p>
<p>Author: Swati Tata ; Barbara Di Eugenio</p><p>Abstract: Music Recommendation Systems often recommend individual songs, as opposed to entire albums. The challenge is to generate reviews for each song, since only full album reviews are available on-line. We developed a summarizer that combines information extraction and generation techniques to produce summaries of reviews of individual songs. We present an intrinsic evaluation of the extraction components, and of the informativeness of the summaries; and a user study of the impact of the song review summaries on users’ decision making processes. Users were able to make quicker and more informed decisions when presented with the summary as compared to the full album review.</p><p>3 0.56967354 <a title="157-lsi-3" href="./acl-2010-%22Was_It_Good%3F_It_Was_Provocative.%22_Learning_the_Meaning_of_Scalar_Adjectives.html">2 acl-2010-"Was It Good? It Was Provocative." Learning the Meaning of Scalar Adjectives</a></p>
<p>Author: Marie-Catherine de Marneffe ; Christopher D. Manning ; Christopher Potts</p><p>Abstract: Texts and dialogues often express information indirectly. For instance, speakers’ answers to yes/no questions do not always straightforwardly convey a ‘yes’ or ‘no’ answer. The intended reply is clear in some cases (Was it good? It was great!) but uncertain in others (Was it acceptable? It was unprecedented.). In this paper, we present methods for interpreting the answers to questions like these which involve scalar modifiers. We show how to ground scalar modifier meaning based on data collected from the Web. We learn scales between modifiers and infer the extent to which a given answer conveys ‘yes’ or ‘no’ . To evaluate the methods, we collected examples of question–answer pairs involving scalar modifiers from CNN transcripts and the Dialog Act corpus and use response distributions from Mechanical Turk workers to assess the degree to which each answer conveys ‘yes’ or ‘no’ . Our experimental results closely match the Turkers’ response data, demonstrating that meanings can be learned from Web data and that such meanings can drive pragmatic inference.</p><p>4 0.56525874 <a title="157-lsi-4" href="./acl-2010-Automatically_Generating_Annotator_Rationales_to_Improve_Sentiment_Classification.html">42 acl-2010-Automatically Generating Annotator Rationales to Improve Sentiment Classification</a></p>
<p>Author: Ainur Yessenalina ; Yejin Choi ; Claire Cardie</p><p>Abstract: One ofthe central challenges in sentimentbased text categorization is that not every portion of a document is equally informative for inferring the overall sentiment of the document. Previous research has shown that enriching the sentiment labels with human annotators’ “rationales” can produce substantial improvements in categorization performance (Zaidan et al., 2007). We explore methods to automatically generate annotator rationales for document-level sentiment classification. Rather unexpectedly, we find the automatically generated rationales just as helpful as human rationales.</p><p>5 0.54356158 <a title="157-lsi-5" href="./acl-2010-Sentiment_Learning_on_Product_Reviews_via_Sentiment_Ontology_Tree.html">209 acl-2010-Sentiment Learning on Product Reviews via Sentiment Ontology Tree</a></p>
<p>Author: Wei Wei ; Jon Atle Gulla</p><p>Abstract: Existing works on sentiment analysis on product reviews suffer from the following limitations: (1) The knowledge of hierarchical relationships of products attributes is not fully utilized. (2) Reviews or sentences mentioning several attributes associated with complicated sentiments are not dealt with very well. In this paper, we propose a novel HL-SOT approach to labeling a product’s attributes and their associated sentiments in product reviews by a Hierarchical Learning (HL) process with a defined Sentiment Ontology Tree (SOT). The empirical analysis against a humanlabeled data set demonstrates promising and reasonable performance of the proposed HL-SOT approach. While this paper is mainly on sentiment analysis on reviews of one product, our proposed HLSOT approach is easily generalized to labeling a mix of reviews of more than one products.</p><p>6 0.49188849 <a title="157-lsi-6" href="./acl-2010-Cross-Language_Text_Classification_Using_Structural_Correspondence_Learning.html">78 acl-2010-Cross-Language Text Classification Using Structural Correspondence Learning</a></p>
<p>7 0.47040126 <a title="157-lsi-7" href="./acl-2010-A_Study_of_Information_Retrieval_Weighting_Schemes_for_Sentiment_Analysis.html">18 acl-2010-A Study of Information Retrieval Weighting Schemes for Sentiment Analysis</a></p>
<p>8 0.46718243 <a title="157-lsi-8" href="./acl-2010-Optimizing_Informativeness_and_Readability_for_Sentiment_Summarization.html">188 acl-2010-Optimizing Informativeness and Readability for Sentiment Summarization</a></p>
<p>9 0.46049175 <a title="157-lsi-9" href="./acl-2010-Cross_Lingual_Adaptation%3A_An_Experiment_on_Sentiment_Classifications.html">80 acl-2010-Cross Lingual Adaptation: An Experiment on Sentiment Classifications</a></p>
<p>10 0.44106233 <a title="157-lsi-10" href="./acl-2010-Don%27t_%27Have_a_Clue%27%3F_Unsupervised_Co-Learning_of_Downward-Entailing_Operators..html">92 acl-2010-Don't 'Have a Clue'? Unsupervised Co-Learning of Downward-Entailing Operators.</a></p>
<p>11 0.42078117 <a title="157-lsi-11" href="./acl-2010-Mood_Patterns_and_Affective_Lexicon_Access_in_Weblogs.html">176 acl-2010-Mood Patterns and Affective Lexicon Access in Weblogs</a></p>
<p>12 0.41663903 <a title="157-lsi-12" href="./acl-2010-Generating_Focused_Topic-Specific_Sentiment_Lexicons.html">123 acl-2010-Generating Focused Topic-Specific Sentiment Lexicons</a></p>
<p>13 0.40405685 <a title="157-lsi-13" href="./acl-2010-The_Influence_of_Discourse_on_Syntax%3A_A_Psycholinguistic_Model_of_Sentence_Processing.html">229 acl-2010-The Influence of Discourse on Syntax: A Psycholinguistic Model of Sentence Processing</a></p>
<p>14 0.4001126 <a title="157-lsi-14" href="./acl-2010-A_Rational_Model_of_Eye_Movement_Control_in_Reading.html">13 acl-2010-A Rational Model of Eye Movement Control in Reading</a></p>
<p>15 0.39996964 <a title="157-lsi-15" href="./acl-2010-Cognitively_Plausible_Models_of_Human_Language_Processing.html">59 acl-2010-Cognitively Plausible Models of Human Language Processing</a></p>
<p>16 0.3891747 <a title="157-lsi-16" href="./acl-2010-Sentence_and_Expression_Level_Annotation_of_Opinions_in_User-Generated_Discourse.html">208 acl-2010-Sentence and Expression Level Annotation of Opinions in User-Generated Discourse</a></p>
<p>17 0.37976897 <a title="157-lsi-17" href="./acl-2010-Identifying_Text_Polarity_Using_Random_Walks.html">141 acl-2010-Identifying Text Polarity Using Random Walks</a></p>
<p>18 0.37712914 <a title="157-lsi-18" href="./acl-2010-Using_Speech_to_Reply_to_SMS_Messages_While_Driving%3A_An_In-Car_Simulator_User_Study.html">254 acl-2010-Using Speech to Reply to SMS Messages While Driving: An In-Car Simulator User Study</a></p>
<p>19 0.37453786 <a title="157-lsi-19" href="./acl-2010-Comparable_Entity_Mining_from_Comparative_Questions.html">63 acl-2010-Comparable Entity Mining from Comparative Questions</a></p>
<p>20 0.36195192 <a title="157-lsi-20" href="./acl-2010-Vocabulary_Choice_as_an_Indicator_of_Perspective.html">256 acl-2010-Vocabulary Choice as an Indicator of Perspective</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.011), (25, 0.033), (39, 0.019), (42, 0.038), (44, 0.012), (59, 0.055), (71, 0.379), (73, 0.064), (78, 0.041), (80, 0.018), (83, 0.108), (84, 0.052), (98, 0.084)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.78949612 <a title="157-lda-1" href="./acl-2010-Last_but_Definitely_Not_Least%3A_On_the_Role_of_the_Last_Sentence_in_Automatic_Polarity-Classification.html">157 acl-2010-Last but Definitely Not Least: On the Role of the Last Sentence in Automatic Polarity-Classification</a></p>
<p>Author: Israela Becker ; Vered Aharonson</p><p>Abstract: Two psycholinguistic and psychophysical experiments show that in order to efficiently extract polarity of written texts such as customerreviews on the Internet, one should concentrate computational efforts on messages in the final position of the text.</p><p>2 0.75082803 <a title="157-lda-2" href="./acl-2010-Learning_Better_Data_Representation_Using_Inference-Driven_Metric_Learning.html">161 acl-2010-Learning Better Data Representation Using Inference-Driven Metric Learning</a></p>
<p>Author: Paramveer S. Dhillon ; Partha Pratim Talukdar ; Koby Crammer</p><p>Abstract: We initiate a study comparing effectiveness of the transformed spaces learned by recently proposed supervised, and semisupervised metric learning algorithms to those generated by previously proposed unsupervised dimensionality reduction methods (e.g., PCA). Through a variety of experiments on different realworld datasets, we find IDML-IT, a semisupervised metric learning algorithm to be the most effective.</p><p>3 0.66981739 <a title="157-lda-3" href="./acl-2010-Domain_Adaptation_of_Maximum_Entropy_Language_Models.html">91 acl-2010-Domain Adaptation of Maximum Entropy Language Models</a></p>
<p>Author: Tanel Alumae ; Mikko Kurimo</p><p>Abstract: We investigate a recently proposed Bayesian adaptation method for building style-adapted maximum entropy language models for speech recognition, given a large corpus of written language data and a small corpus of speech transcripts. Experiments show that the method consistently outperforms linear interpolation which is typically used in such cases.</p><p>4 0.4476077 <a title="157-lda-4" href="./acl-2010-Hierarchical_Sequential_Learning_for_Extracting_Opinions_and_Their_Attributes.html">134 acl-2010-Hierarchical Sequential Learning for Extracting Opinions and Their Attributes</a></p>
<p>Author: Yejin Choi ; Claire Cardie</p><p>Abstract: Automatic opinion recognition involves a number of related tasks, such as identifying the boundaries of opinion expression, determining their polarity, and determining their intensity. Although much progress has been made in this area, existing research typically treats each of the above tasks in isolation. In this paper, we apply a hierarchical parameter sharing technique using Conditional Random Fields for fine-grained opinion analysis, jointly detecting the boundaries of opinion expressions as well as determining two of their key attributes polarity and intensity. Our experimental results show that our proposed approach improves the performance over a baseline that does not — exploit hierarchical structure among the classes. In addition, we find that the joint approach outperforms a baseline that is based on cascading two separate components.</p><p>5 0.43197161 <a title="157-lda-5" href="./acl-2010-Experiments_in_Graph-Based_Semi-Supervised_Learning_Methods_for_Class-Instance_Acquisition.html">109 acl-2010-Experiments in Graph-Based Semi-Supervised Learning Methods for Class-Instance Acquisition</a></p>
<p>Author: Partha Pratim Talukdar ; Fernando Pereira</p><p>Abstract: Graph-based semi-supervised learning (SSL) algorithms have been successfully used to extract class-instance pairs from large unstructured and structured text collections. However, a careful comparison of different graph-based SSL algorithms on that task has been lacking. We compare three graph-based SSL algorithms for class-instance acquisition on a variety of graphs constructed from different domains. We find that the recently proposed MAD algorithm is the most effective. We also show that class-instance extraction can be significantly improved by adding semantic information in the form of instance-attribute edges derived from an independently developed knowledge base. All of our code and data will be made publicly available to encourage reproducible research in this area.</p><p>6 0.42068341 <a title="157-lda-6" href="./acl-2010-Automatically_Generating_Annotator_Rationales_to_Improve_Sentiment_Classification.html">42 acl-2010-Automatically Generating Annotator Rationales to Improve Sentiment Classification</a></p>
<p>7 0.42016679 <a title="157-lda-7" href="./acl-2010-Cross-Language_Text_Classification_Using_Structural_Correspondence_Learning.html">78 acl-2010-Cross-Language Text Classification Using Structural Correspondence Learning</a></p>
<p>8 0.4188672 <a title="157-lda-8" href="./acl-2010-Cross_Lingual_Adaptation%3A_An_Experiment_on_Sentiment_Classifications.html">80 acl-2010-Cross Lingual Adaptation: An Experiment on Sentiment Classifications</a></p>
<p>9 0.41213951 <a title="157-lda-9" href="./acl-2010-Sparsity_in_Dependency_Grammar_Induction.html">214 acl-2010-Sparsity in Dependency Grammar Induction</a></p>
<p>10 0.41090578 <a title="157-lda-10" href="./acl-2010-Personalising_Speech-To-Speech_Translation_in_the_EMIME_Project.html">193 acl-2010-Personalising Speech-To-Speech Translation in the EMIME Project</a></p>
<p>11 0.41019386 <a title="157-lda-11" href="./acl-2010-A_Study_of_Information_Retrieval_Weighting_Schemes_for_Sentiment_Analysis.html">18 acl-2010-A Study of Information Retrieval Weighting Schemes for Sentiment Analysis</a></p>
<p>12 0.40715522 <a title="157-lda-12" href="./acl-2010-%22Ask_Not_What_Textual_Entailment_Can_Do_for_You...%22.html">1 acl-2010-"Ask Not What Textual Entailment Can Do for You..."</a></p>
<p>13 0.40286893 <a title="157-lda-13" href="./acl-2010-Simple%2C_Accurate_Parsing_with_an_All-Fragments_Grammar.html">211 acl-2010-Simple, Accurate Parsing with an All-Fragments Grammar</a></p>
<p>14 0.40208 <a title="157-lda-14" href="./acl-2010-Latent_Variable_Models_of_Selectional_Preference.html">158 acl-2010-Latent Variable Models of Selectional Preference</a></p>
<p>15 0.40190458 <a title="157-lda-15" href="./acl-2010-Using_Anaphora_Resolution_to_Improve_Opinion_Target_Identification_in_Movie_Reviews.html">251 acl-2010-Using Anaphora Resolution to Improve Opinion Target Identification in Movie Reviews</a></p>
<p>16 0.40038404 <a title="157-lda-16" href="./acl-2010-Entity-Based_Local_Coherence_Modelling_Using_Topological_Fields.html">101 acl-2010-Entity-Based Local Coherence Modelling Using Topological Fields</a></p>
<p>17 0.39950874 <a title="157-lda-17" href="./acl-2010-Sentence_and_Expression_Level_Annotation_of_Opinions_in_User-Generated_Discourse.html">208 acl-2010-Sentence and Expression Level Annotation of Opinions in User-Generated Discourse</a></p>
<p>18 0.39701012 <a title="157-lda-18" href="./acl-2010-Assessing_the_Role_of_Discourse_References_in_Entailment_Inference.html">33 acl-2010-Assessing the Role of Discourse References in Entailment Inference</a></p>
<p>19 0.39693278 <a title="157-lda-19" href="./acl-2010-A_Rational_Model_of_Eye_Movement_Control_in_Reading.html">13 acl-2010-A Rational Model of Eye Movement Control in Reading</a></p>
<p>20 0.39529389 <a title="157-lda-20" href="./acl-2010-Complexity_Metrics_in_an_Incremental_Right-Corner_Parser.html">65 acl-2010-Complexity Metrics in an Incremental Right-Corner Parser</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
