<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>251 acl-2010-Using Anaphora Resolution to Improve Opinion Target Identification in Movie Reviews</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-251" href="#">acl2010-251</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>251 acl-2010-Using Anaphora Resolution to Improve Opinion Target Identification in Movie Reviews</h1>
<br/><p>Source: <a title="acl-2010-251-pdf" href="http://aclweb.org/anthology//P/P10/P10-2049.pdf">pdf</a></p><p>Author: Niklas Jakob ; Iryna Gurevych</p><p>Abstract: unkown-abstract</p><p>Reference: <a title="acl-2010-251-reference" href="../acl2010_reference/acl-2010-Using_Anaphora_Resolution_to_Improve_Opinion_Target_Identification_in_Movie_Reviews_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 tuAbstract Current work on automatic opinion mining has ignored opinion targets expressed by anaphorical pronouns, thereby missing a significant number of opinion targets. [sent-3, score-2.229]
</p><p>2 In this paper we empirically evaluate whether using an off-the-shelf anaphora resolution algorithm can improve the performance of a baseline opinion mining system. [sent-4, score-0.927]
</p><p>3 We present an analysis based on two different anaphora resolution systems. [sent-5, score-0.207]
</p><p>4 Our experiments on a movie review corpus demonstrate, that an unsupervised anaphora resolution algorithm significantly improves the opinion target extraction. [sent-6, score-1.179]
</p><p>5 We furthermore suggest domain and task specific extensions to an off-the-shelf algorithm which  in turn yield significant improvements. [sent-7, score-0.133]
</p><p>6 1 Introduction Over the last years the task of opinion mining (OM) has been the topic of many publications. [sent-8, score-0.703]
</p><p>7 It has been approached with different goals in mind: Some research strived to perform subjectivity analysis at the document or sentence level, without focusing on what the individual opinions uttered in the document are about. [sent-9, score-0.115]
</p><p>8 Other approaches focused on extracting individual opinion words or phrases and what they are about. [sent-10, score-0.652]
</p><p>9 This aboutness has been referred to as the opinion target or opinion topic in the literature from the field. [sent-11, score-1.375]
</p><p>10 In this work our goal is to extract opinion target - opinion word pairs from sentences from movie reviews. [sent-12, score-1.556]
</p><p>11 In the task of OM, it can therefore also be necessary to analyze more than the content of one individual sentence when extracting opinion targets. [sent-14, score-0.652]
</p><p>12 de /people put, it’s unfathomable that this movie cracks the Top 250. [sent-16, score-0.225]
</p><p>13 If one wants to extract what the opinion in the second sentence is about, an algorithm which resolves the anaphoric reference to the opinion target is required. [sent-19, score-1.48]
</p><p>14 The extraction of such anaphoric opinion targets has been noted as an open issue multiple times in the OM context (Zhuang et al. [sent-20, score-1.007]
</p><p>15 It is not a marginal phenomenon, since Kessler and Nicolov (2009) report that in their data, 14% of the opinion targets are pronouns. [sent-22, score-0.925]
</p><p>16 However, the task of resolving anaphora to mine opinion targets has not been addressed and evaluated yet to the best of our knowledge. [sent-23, score-1.07]
</p><p>17 In this work, we investigate whether anaphora resolution (AR) can be successfully integrated into an OM algorithm and whether we can achieve an improvement regarding the OM in doing so. [sent-24, score-0.348]
</p><p>18 This paper is structured as follows: Section 2 discusses the related work on opinion target identification and OM on movie reviews. [sent-25, score-0.981]
</p><p>19 1 we discuss the related work on OM with a focus on approaches for opinion target identification. [sent-29, score-0.707]
</p><p>20 2 we elaborate on findings from related OM research which also worked with movie reviews as this is our target domain in the present paper. [sent-31, score-0.427]
</p><p>21 1 Opinion Target Identification The extraction of opinions and especially opinion targets has been performed with quite diverse 263  UppsalaP,r Sowce ed ein ,g 1s1 o-f16 th Jeu AlyC 2L0 210 1. [sent-33, score-1.033]
</p><p>22 The goal was to identify the opinion targets, here in form of products and their attributes, without a pre-built knowledge base which models the domain. [sent-37, score-0.624]
</p><p>23 A more linguistically motivated approach was taken by Kim and Hovy (2006) through identifying opinion holders and targets with semantic role labeling. [sent-41, score-0.955]
</p><p>24 (2006) present an algorithm for the extraction of opinion target - opinion word pairs. [sent-46, score-1.409]
</p><p>25 The opinion word and target candidates are identified in the annotated corpus and their extraction is then performed by applying possible paths connecting them in a dependency graph. [sent-47, score-0.929]
</p><p>26 The algorithm by Stoyanov and Cardie (2008) identifies coreferring targets in newspaper articles. [sent-50, score-0.341]
</p><p>27 A candidate selection or extraction step for the opinion targets is not required, since they rely on manually annotated targets and focus solely on the coreference resolution. [sent-51, score-1.349]
</p><p>28 However they do not resolve pronominal anaphora in order to achieve that. [sent-52, score-0.169]
</p><p>29 2  Opinion Mining on Movie Reviews  There is a huge body of work on OM in movie reviews which was sparked by the dataset from Pang and Lee (2005). [sent-54, score-0.382]
</p><p>30 These statements however do not reflect any opinions of the reviewers regarding the movie. [sent-57, score-0.171]
</p><p>31 (2006) also observe that movie reviews are different from e. [sent-59, score-0.344]
</p><p>32 This is reflected in their experiments, in which their system outperforms the system by Hu and Liu (2004) which attributes an opinion target to the opinion word which is closest regarding word distance in a sentence. [sent-63, score-1.432]
</p><p>33 The sentences in the movie reviews tend to be more complex, which can also be explained by their origin. [sent-64, score-0.344]
</p><p>34 The reviews were taken from the Internet Movie Database1 , on which the users are given a set of guidelines on how to write a review. [sent-65, score-0.119]
</p><p>35 Due to these insights, we are confident that the overall textual quality of the movie reviews is high enough for linguistically more advanced technologies such as parsing or AR to be successfully applied. [sent-66, score-0.344]
</p><p>36 1 Dataset Currently the only freely available dataset annotated with opinions including annotated anaphoric opinion targets is a corpus of movie reviews by Zhuang et al. [sent-68, score-1.495]
</p><p>37 Kessler and Nicolov (2009) describe a collection of product reviews in which anaphoric opinion targets are also annotated, but it is not available to the public (yet). [sent-70, score-1.088]
</p><p>38 5% of the opinion targets are referred to by pronouns. [sent-75, score-0.946]
</p><p>39 Table 2 outlines detailed statistics on which pronouns occur as opinion targets. [sent-76, score-0.721]
</p><p>40 In the first step, opinion target and opinion word candidates are extracted from the training data. [sent-84, score-1.406]
</p><p>41 Frequency counts of the annotated opinion targets and opin-  ion words are extracted from four training folds. [sent-85, score-0.984]
</p><p>42 The most frequently occurring opinion targets and opinion words are selected as candidates. [sent-86, score-1.571]
</p><p>43 For each opinion target - opinion word pair, the shortest path connecting them is extracted from the dependency graph. [sent-88, score-1.441]
</p><p>44 In order to be able to identify rarely occurring opinion targets which are not in the candidate list, they expand it by crawling the cast and crew names of the movies from the IMDB. [sent-90, score-1.039]
</p><p>45 This algorithm is based on statistical analysis ofthe antecedent candidates. [sent-96, score-0.169]
</p><p>46 Another promising algorithm for AR employs a rule based approach for antecedent identification. [sent-97, score-0.169]
</p><p>47 This approach seems like an adequate strategy for our OM task, since in the dataset used in our experiments only a small fraction of the total number of pronouns are actual opinion targets (see Table 1). [sent-99, score-1.028]
</p><p>48 We extended the CogNIAC implementation to also resolve “it” and “this ” as anaphora candidates, since off-the-shelf it only resolves personal pronouns. [sent-100, score-0.282]
</p><p>49 Both algorithms follow the common approach that noun phrases are  antecedent periments CogNIAC extensions  candidates for the anaphora. [sent-102, score-0.254]
</p><p>50 We therefore suggest three extensions to the algorithm which are on the one hand possible in the OM setting and on the other hand represent special features of the target discourse type: [1. [sent-106, score-0.195]
</p><p>51 We therefore filter out Person antecedent candidates which the Stanford NER detects for the impersonal and demonstrative pronouns and Location & Organization candidates for the personal pronouns. [sent-109, score-0.542]
</p><p>52 ] The second extension exploits the fact that reviews from the IMDB exhibit certain contextual  properties. [sent-112, score-0.141]
</p><p>53 In the reviews, the authors often refer to the movie or film as a whole by a pronoun. [sent-116, score-0.251]
</p><p>54 We exploit this by an additional rule which resolves an impersonal or demonstrative pronoun to “movie ” or “film” if there is no other (matching) antecedent candidate in the previous two sentences. [sent-117, score-0.507]
</p><p>55 ] The rules by which CogNIAC resolves anaphora were designed so that anaphora which have ambiguous antecedents are left unresolved. [sent-119, score-0.377]
</p><p>56 In such argument chains, we try to solve cases of antecedent ambiguity by analyzing the opinions: If there are ambiguous antecedent candidates for a  265  pronoun, we check whether there is an opinion uttered in the previous sentence. [sent-122, score-0.959]
</p><p>57 If this is the case and if the opinion target matches the pronoun regarding gender and number, we resolve the pronoun to the antecedent which was the previous opinion target. [sent-123, score-1.806]
</p><p>58 5  Experimental Work  To integrate AR in the OM algorithm, we add the antecedents of the pronouns annotated as opinion targets to the target candidate list. [sent-125, score-1.157]
</p><p>59 Then we extract the dependency paths connecting pronouns and opinion words and add them to the list of valid paths. [sent-126, score-0.783]
</p><p>60 When we run the algorithm, we extract anaphora which were resolved, if they occur with a valid dependency path to an opinion word. [sent-127, score-0.833]
</p><p>61 In such a case, the anaphor is substituted for its antecedent and thus extracted as part of an opinion  target - opinion word pair. [sent-128, score-1.482]
</p><p>62 One aspect regarding the extraction of opinion target - opinion word pairs remains open in Zhuang et al. [sent-133, score-1.47]
</p><p>63 However, almost 50% of the opinion target candidates are multiword expressions. [sent-135, score-0.83]
</p><p>64 (2006) do not explain how they extract multiword opinion targets with the dependency paths. [sent-137, score-1.031]
</p><p>65 In our experiments, we require a dependency path to be found to each word of a multiword target candidate for it to be extracted. [sent-138, score-0.242]
</p><p>66 (2006) do not state whether in their evaluation annotated multiword targets are treated as a single unit which needs to be extracted, or whether a partial matching is employed in such cases. [sent-140, score-0.441]
</p><p>67 We therefore employ a merging step, in which we combine adjacent opinion targets to a multiword expression. [sent-143, score-0.995]
</p><p>68 Table 4 gives a detailed overview of the AR for opinion target identification summed up over all folds. [sent-145, score-0.756]
</p><p>69 In Table 4, a true positive refers to an extracted pronoun which was annotated as an opinion target and is resolved to the correct antecedent. [sent-146, score-0.888]
</p><p>70 A false positive subsumes two error classes: A pronoun which was not annotated as an opinion target but extracted as such, or a pronoun which is resolved to an incorrect antecedent. [sent-147, score-1.01]
</p><p>71 We observe that the MARS algorithm yields an improvement regarding recall compared to the baseline system. [sent-153, score-0.161]
</p><p>72 However, it also extracts a high number of false positives for both the personal and impersonal / demonstrative pronouns. [sent-154, score-0.293]
</p><p>73 This is due to the fact that the MARS algorithm is designed for robustness and always resolves a pronoun to an antecedent. [sent-155, score-0.199]
</p><p>74 CogNIAC in its off-the-shelfconfiguration already yields significant improvements over the baseline regarding f-measure2. [sent-156, score-0.133]
</p><p>75 As shown in Table 4, the algorithm extracts impersonal and demonstrative pronouns with lower precision than personal pronouns. [sent-158, score-0.368]
</p><p>76 The best overall results regarding f-measure are reached if we combine all our extensions of the CogNIAC algorithm. [sent-165, score-0.173]
</p><p>77 The results of this configuration show that the positive effects of extensions [2] and [3] are complemen2Significance of improvements was tested using a paired two-tailed t-test and p ≤ 0. [sent-166, score-0.134]
</p><p>78 5 643259718∗  Table 4: Results of AR for Opinion Targets  tary regarding the extraction of impersonal and demonstrative pronouns. [sent-180, score-0.333]
</p><p>79 This configuration yields statistically significant improvements regarding fmeasure over the off-the-shelf CogNIAC configuration, while also having the overall highest recall. [sent-181, score-0.163]
</p><p>80 1 Error Analysis When extracting opinions from movie reviews, we observe the same challenge as Turney (2002): The users often characterize events in the storyline or roles the characters play. [sent-183, score-0.358]
</p><p>81 Hence these combinations are frequently but falsely extracted as opinion target - opinion word pairs, negatively affecting the precision. [sent-185, score-1.401]
</p><p>82 The algorithm cannot distinguish them from opinions expressing the stance of the author. [sent-186, score-0.11]
</p><p>83 This is due to the fact that the algorithm only learns a subset of the opinion words and opinion targets annotated in the training data. [sent-188, score-1.626]
</p><p>84 Currently, it cannot discover any new opinion words and targets. [sent-189, score-0.624]
</p><p>85 This could be addressed by integrating a component which identifies new opinion targets by calculating the relevance of a word in the corpus based on statistical measures. [sent-190, score-0.956]
</p><p>86 The AR introduces new sources of errors regarding the extraction of opinion targets: Errors in gender and number identification can lead to an incorrect selection of antecedent candidates. [sent-191, score-0.974]
</p><p>87 Even  if the gender and number identification is correct, the algorithm might select an incorrect antecedent if there is more than one possible candidate. [sent-192, score-0.251]
</p><p>88 A non-robust algorithm as CogNIAC might leave a pronoun which is an actual opinion target unresolved, due to the ambiguity of its antecedent candidates. [sent-193, score-0.97]
</p><p>89 t 6  Conclusions  We have shown that by extending an OM algorithm with AR for opinion target extraction significant improvements can be achieved. [sent-199, score-0.817]
</p><p>90 The rule based AR algorithm CogNIAC performs well regarding the extraction of opinion targets which are personal pronouns. [sent-200, score-1.152]
</p><p>91 The algorithm does not yield high precision when resolving impersonal and demonstrative pronouns. [sent-201, score-0.276]
</p><p>92 We present a set  of extensions which address this challenge and in combination yield significant improvements over the off-the-shelf configuration. [sent-202, score-0.125]
</p><p>93 A robust AR algorithm does not yield any improvements regarding f-measure in the OM task. [sent-203, score-0.194]
</p><p>94 This type of algorithm creates many false positives, which are not filtered out by the dependency paths employed in the algorithm by Zhuang et al. [sent-204, score-0.211]
</p><p>95 AR could also be employed in other OM algorithms which aim at identifying opinion targets by means of a statistical analysis. [sent-206, score-0.958]
</p><p>96 Vicedo and Ferr a´ndez (2000) successfully modified the relevance ranking of terms in their documents by replacing anaphora with their antecedents. [sent-207, score-0.22]
</p><p>97 The approach can be taken for OM algorithms which select the opinion target candidates with a relevance ranking (Hu and Liu, 2004; Yi et al. [sent-208, score-0.813]
</p><p>98 Extracting opinions, opinion holders, and topics expressed in online news media text. [sent-236, score-0.624]
</p><p>99 A general-purpose, off-the-shelf anaphora resolution module: Implementation and preliminary evaluation. [sent-253, score-0.207]
</p><p>100 Applying anaphora resolution to question answering and information retrieval systems. [sent-271, score-0.207]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('opinion', 0.624), ('targets', 0.301), ('cogniac', 0.298), ('om', 0.241), ('movie', 0.225), ('zhuang', 0.209), ('anaphora', 0.145), ('antecedent', 0.129), ('ar', 0.124), ('reviews', 0.119), ('impersonal', 0.104), ('regarding', 0.101), ('pronoun', 0.094), ('demonstrative', 0.09), ('target', 0.083), ('extensions', 0.072), ('opinions', 0.07), ('multiword', 0.07), ('darmstadt', 0.07), ('pronouns', 0.065), ('resolves', 0.065), ('mars', 0.064), ('resolution', 0.062), ('mining', 0.056), ('candidates', 0.053), ('sentiment', 0.05), ('identification', 0.049), ('personal', 0.048), ('nasukawa', 0.048), ('hu', 0.045), ('kessler', 0.045), ('anaphoric', 0.044), ('usa', 0.043), ('nicolov', 0.04), ('algorithm', 0.04), ('elsner', 0.039), ('id', 0.038), ('dataset', 0.038), ('extraction', 0.038), ('annotated', 0.037), ('dependency', 0.036), ('imdb', 0.035), ('crew', 0.035), ('ferr', 0.035), ('jeonghee', 0.035), ('storyline', 0.035), ('hochschulstra', 0.035), ('paths', 0.034), ('employed', 0.033), ('gender', 0.033), ('improvements', 0.032), ('vicedo', 0.032), ('outlines', 0.032), ('tetsuya', 0.032), ('relevance', 0.031), ('configuration', 0.03), ('holders', 0.03), ('technische', 0.03), ('finkel', 0.029), ('yi', 0.029), ('ner', 0.029), ('charniak', 0.028), ('characterizations', 0.028), ('resolved', 0.028), ('false', 0.028), ('path', 0.028), ('extracting', 0.028), ('crawling', 0.027), ('stoyanov', 0.027), ('movies', 0.027), ('affecting', 0.026), ('film', 0.026), ('candidate', 0.025), ('thumbs', 0.025), ('connecting', 0.024), ('resolve', 0.024), ('uttered', 0.024), ('fl', 0.024), ('liu', 0.024), ('topic', 0.023), ('hardly', 0.023), ('positives', 0.023), ('coreference', 0.023), ('pang', 0.023), ('ranking', 0.022), ('antecedents', 0.022), ('poesio', 0.022), ('customer', 0.022), ('frequently', 0.022), ('extension', 0.022), ('extracted', 0.022), ('documents', 0.022), ('turney', 0.021), ('precision', 0.021), ('yield', 0.021), ('referred', 0.021), ('universit', 0.021), ('subjectivity', 0.021), ('michigan', 0.021), ('recall', 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000008 <a title="251-tfidf-1" href="./acl-2010-Using_Anaphora_Resolution_to_Improve_Opinion_Target_Identification_in_Movie_Reviews.html">251 acl-2010-Using Anaphora Resolution to Improve Opinion Target Identification in Movie Reviews</a></p>
<p>Author: Niklas Jakob ; Iryna Gurevych</p><p>Abstract: unkown-abstract</p><p>2 0.55464411 <a title="251-tfidf-2" href="./acl-2010-A_Unified_Graph_Model_for_Sentence-Based_Opinion_Retrieval.html">22 acl-2010-A Unified Graph Model for Sentence-Based Opinion Retrieval</a></p>
<p>Author: Binyang Li ; Lanjun Zhou ; Shi Feng ; Kam-Fai Wong</p><p>Abstract: There is a growing research interest in opinion retrieval as on-line users’ opinions are becoming more and more popular in business, social networks, etc. Practically speaking, the goal of opinion retrieval is to retrieve documents, which entail opinions or comments, relevant to a target subject specified by the user’s query. A fundamental challenge in opinion retrieval is information representation. Existing research focuses on document-based approaches and documents are represented by bag-of-word. However, due to loss of contextual information, this representation fails to capture the associative information between an opinion and its corresponding target. It cannot distinguish different degrees of a sentiment word when associated with different targets. This in turn seriously affects opinion retrieval performance. In this paper, we propose a sentence-based approach based on a new information representa- , tion, namely topic-sentiment word pair, to capture intra-sentence contextual information between an opinion and its target. Additionally, we consider inter-sentence information to capture the relationships among the opinions on the same topic. Finally, the two types of information are combined in a unified graph-based model, which can effectively rank the documents. Compared with existing approaches, experimental results on the COAE08 dataset showed that our graph-based model achieved significant improvement. 1</p><p>3 0.39082959 <a title="251-tfidf-3" href="./acl-2010-Sentence_and_Expression_Level_Annotation_of_Opinions_in_User-Generated_Discourse.html">208 acl-2010-Sentence and Expression Level Annotation of Opinions in User-Generated Discourse</a></p>
<p>Author: Cigdem Toprak ; Niklas Jakob ; Iryna Gurevych</p><p>Abstract: In this paper, we introduce a corpus of consumer reviews from the rateitall and the eopinions websites annotated with opinion-related information. We present a two-level annotation scheme. In the first stage, the reviews are analyzed at the sentence level for (i) relevancy to a given topic, and (ii) expressing an evaluation about the topic. In the second stage, on-topic sentences containing evaluations about the topic are further investigated at the expression level for pinpointing the properties (semantic orientation, intensity), and the functional components of the evaluations (opinion terms, targets and holders). We discuss the annotation scheme, the inter-annotator agreement for different subtasks and our observations.</p><p>4 0.33465701 <a title="251-tfidf-4" href="./acl-2010-Hierarchical_Sequential_Learning_for_Extracting_Opinions_and_Their_Attributes.html">134 acl-2010-Hierarchical Sequential Learning for Extracting Opinions and Their Attributes</a></p>
<p>Author: Yejin Choi ; Claire Cardie</p><p>Abstract: Automatic opinion recognition involves a number of related tasks, such as identifying the boundaries of opinion expression, determining their polarity, and determining their intensity. Although much progress has been made in this area, existing research typically treats each of the above tasks in isolation. In this paper, we apply a hierarchical parameter sharing technique using Conditional Random Fields for fine-grained opinion analysis, jointly detecting the boundaries of opinion expressions as well as determining two of their key attributes polarity and intensity. Our experimental results show that our proposed approach improves the performance over a baseline that does not — exploit hierarchical structure among the classes. In addition, we find that the joint approach outperforms a baseline that is based on cascading two separate components.</p><p>5 0.3317543 <a title="251-tfidf-5" href="./acl-2010-Generating_Focused_Topic-Specific_Sentiment_Lexicons.html">123 acl-2010-Generating Focused Topic-Specific Sentiment Lexicons</a></p>
<p>Author: Valentin Jijkoun ; Maarten de Rijke ; Wouter Weerkamp</p><p>Abstract: We present a method for automatically generating focused and accurate topicspecific subjectivity lexicons from a general purpose polarity lexicon that allow users to pin-point subjective on-topic information in a set of relevant documents. We motivate the need for such lexicons in the field of media analysis, describe a bootstrapping method for generating a topic-specific lexicon from a general purpose polarity lexicon, and evaluate the quality of the generated lexicons both manually and using a TREC Blog track test set for opinionated blog post retrieval. Although the generated lexicons can be an order of magnitude more selective than the general purpose lexicon, they maintain, or even improve, the performance of an opin- ion retrieval system.</p><p>6 0.13168736 <a title="251-tfidf-6" href="./acl-2010-A_Hybrid_Hierarchical_Model_for_Multi-Document_Summarization.html">8 acl-2010-A Hybrid Hierarchical Model for Multi-Document Summarization</a></p>
<p>7 0.12920475 <a title="251-tfidf-7" href="./acl-2010-Sentiment_Learning_on_Product_Reviews_via_Sentiment_Ontology_Tree.html">209 acl-2010-Sentiment Learning on Product Reviews via Sentiment Ontology Tree</a></p>
<p>8 0.11692503 <a title="251-tfidf-8" href="./acl-2010-A_Study_of_Information_Retrieval_Weighting_Schemes_for_Sentiment_Analysis.html">18 acl-2010-A Study of Information Retrieval Weighting Schemes for Sentiment Analysis</a></p>
<p>9 0.11658666 <a title="251-tfidf-9" href="./acl-2010-Supervised_Noun_Phrase_Coreference_Research%3A_The_First_Fifteen_Years.html">219 acl-2010-Supervised Noun Phrase Coreference Research: The First Fifteen Years</a></p>
<p>10 0.090488575 <a title="251-tfidf-10" href="./acl-2010-Incorporating_Extra-Linguistic_Information_into_Reference_Resolution_in_Collaborative_Task_Dialogue.html">149 acl-2010-Incorporating Extra-Linguistic Information into Reference Resolution in Collaborative Task Dialogue</a></p>
<p>11 0.088330999 <a title="251-tfidf-11" href="./acl-2010-Generating_Fine-Grained_Reviews_of_Songs_from_Album_Reviews.html">122 acl-2010-Generating Fine-Grained Reviews of Songs from Album Reviews</a></p>
<p>12 0.07339523 <a title="251-tfidf-12" href="./acl-2010-Understanding_the_Semantic_Structure_of_Noun_Phrase_Queries.html">245 acl-2010-Understanding the Semantic Structure of Noun Phrase Queries</a></p>
<p>13 0.070799939 <a title="251-tfidf-13" href="./acl-2010-Vocabulary_Choice_as_an_Indicator_of_Perspective.html">256 acl-2010-Vocabulary Choice as an Indicator of Perspective</a></p>
<p>14 0.06946785 <a title="251-tfidf-14" href="./acl-2010-Identifying_Text_Polarity_Using_Random_Walks.html">141 acl-2010-Identifying Text Polarity Using Random Walks</a></p>
<p>15 0.067993291 <a title="251-tfidf-15" href="./acl-2010-Automatically_Generating_Annotator_Rationales_to_Improve_Sentiment_Classification.html">42 acl-2010-Automatically Generating Annotator Rationales to Improve Sentiment Classification</a></p>
<p>16 0.06627316 <a title="251-tfidf-16" href="./acl-2010-Evaluating_Multilanguage-Comparability_of_Subjectivity_Analysis_Systems.html">105 acl-2010-Evaluating Multilanguage-Comparability of Subjectivity Analysis Systems</a></p>
<p>17 0.066155665 <a title="251-tfidf-17" href="./acl-2010-The_Same-Head_Heuristic_for_Coreference.html">233 acl-2010-The Same-Head Heuristic for Coreference</a></p>
<p>18 0.06130312 <a title="251-tfidf-18" href="./acl-2010-Assessing_the_Role_of_Discourse_References_in_Entailment_Inference.html">33 acl-2010-Assessing the Role of Discourse References in Entailment Inference</a></p>
<p>19 0.060235903 <a title="251-tfidf-19" href="./acl-2010-Last_but_Definitely_Not_Least%3A_On_the_Role_of_the_Last_Sentence_in_Automatic_Polarity-Classification.html">157 acl-2010-Last but Definitely Not Least: On the Role of the Last Sentence in Automatic Polarity-Classification</a></p>
<p>20 0.055531874 <a title="251-tfidf-20" href="./acl-2010-Optimizing_Informativeness_and_Readability_for_Sentiment_Summarization.html">188 acl-2010-Optimizing Informativeness and Readability for Sentiment Summarization</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.171), (1, 0.165), (2, -0.279), (3, 0.293), (4, -0.316), (5, 0.153), (6, -0.047), (7, 0.2), (8, 0.044), (9, -0.01), (10, 0.078), (11, -0.079), (12, 0.047), (13, 0.106), (14, 0.061), (15, -0.073), (16, -0.281), (17, 0.122), (18, -0.04), (19, 0.045), (20, 0.019), (21, 0.039), (22, -0.01), (23, 0.117), (24, 0.041), (25, -0.034), (26, -0.052), (27, 0.034), (28, 0.104), (29, 0.07), (30, -0.039), (31, -0.03), (32, 0.118), (33, -0.03), (34, 0.011), (35, 0.051), (36, -0.058), (37, -0.047), (38, 0.06), (39, 0.03), (40, -0.031), (41, -0.035), (42, 0.017), (43, -0.047), (44, -0.06), (45, -0.033), (46, 0.002), (47, -0.055), (48, 0.04), (49, 0.053)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97746915 <a title="251-lsi-1" href="./acl-2010-Using_Anaphora_Resolution_to_Improve_Opinion_Target_Identification_in_Movie_Reviews.html">251 acl-2010-Using Anaphora Resolution to Improve Opinion Target Identification in Movie Reviews</a></p>
<p>Author: Niklas Jakob ; Iryna Gurevych</p><p>Abstract: unkown-abstract</p><p>2 0.91379821 <a title="251-lsi-2" href="./acl-2010-A_Unified_Graph_Model_for_Sentence-Based_Opinion_Retrieval.html">22 acl-2010-A Unified Graph Model for Sentence-Based Opinion Retrieval</a></p>
<p>Author: Binyang Li ; Lanjun Zhou ; Shi Feng ; Kam-Fai Wong</p><p>Abstract: There is a growing research interest in opinion retrieval as on-line users’ opinions are becoming more and more popular in business, social networks, etc. Practically speaking, the goal of opinion retrieval is to retrieve documents, which entail opinions or comments, relevant to a target subject specified by the user’s query. A fundamental challenge in opinion retrieval is information representation. Existing research focuses on document-based approaches and documents are represented by bag-of-word. However, due to loss of contextual information, this representation fails to capture the associative information between an opinion and its corresponding target. It cannot distinguish different degrees of a sentiment word when associated with different targets. This in turn seriously affects opinion retrieval performance. In this paper, we propose a sentence-based approach based on a new information representa- , tion, namely topic-sentiment word pair, to capture intra-sentence contextual information between an opinion and its target. Additionally, we consider inter-sentence information to capture the relationships among the opinions on the same topic. Finally, the two types of information are combined in a unified graph-based model, which can effectively rank the documents. Compared with existing approaches, experimental results on the COAE08 dataset showed that our graph-based model achieved significant improvement. 1</p><p>3 0.88171893 <a title="251-lsi-3" href="./acl-2010-Hierarchical_Sequential_Learning_for_Extracting_Opinions_and_Their_Attributes.html">134 acl-2010-Hierarchical Sequential Learning for Extracting Opinions and Their Attributes</a></p>
<p>Author: Yejin Choi ; Claire Cardie</p><p>Abstract: Automatic opinion recognition involves a number of related tasks, such as identifying the boundaries of opinion expression, determining their polarity, and determining their intensity. Although much progress has been made in this area, existing research typically treats each of the above tasks in isolation. In this paper, we apply a hierarchical parameter sharing technique using Conditional Random Fields for fine-grained opinion analysis, jointly detecting the boundaries of opinion expressions as well as determining two of their key attributes polarity and intensity. Our experimental results show that our proposed approach improves the performance over a baseline that does not — exploit hierarchical structure among the classes. In addition, we find that the joint approach outperforms a baseline that is based on cascading two separate components.</p><p>4 0.82856977 <a title="251-lsi-4" href="./acl-2010-Sentence_and_Expression_Level_Annotation_of_Opinions_in_User-Generated_Discourse.html">208 acl-2010-Sentence and Expression Level Annotation of Opinions in User-Generated Discourse</a></p>
<p>Author: Cigdem Toprak ; Niklas Jakob ; Iryna Gurevych</p><p>Abstract: In this paper, we introduce a corpus of consumer reviews from the rateitall and the eopinions websites annotated with opinion-related information. We present a two-level annotation scheme. In the first stage, the reviews are analyzed at the sentence level for (i) relevancy to a given topic, and (ii) expressing an evaluation about the topic. In the second stage, on-topic sentences containing evaluations about the topic are further investigated at the expression level for pinpointing the properties (semantic orientation, intensity), and the functional components of the evaluations (opinion terms, targets and holders). We discuss the annotation scheme, the inter-annotator agreement for different subtasks and our observations.</p><p>5 0.70365298 <a title="251-lsi-5" href="./acl-2010-Generating_Focused_Topic-Specific_Sentiment_Lexicons.html">123 acl-2010-Generating Focused Topic-Specific Sentiment Lexicons</a></p>
<p>Author: Valentin Jijkoun ; Maarten de Rijke ; Wouter Weerkamp</p><p>Abstract: We present a method for automatically generating focused and accurate topicspecific subjectivity lexicons from a general purpose polarity lexicon that allow users to pin-point subjective on-topic information in a set of relevant documents. We motivate the need for such lexicons in the field of media analysis, describe a bootstrapping method for generating a topic-specific lexicon from a general purpose polarity lexicon, and evaluate the quality of the generated lexicons both manually and using a TREC Blog track test set for opinionated blog post retrieval. Although the generated lexicons can be an order of magnitude more selective than the general purpose lexicon, they maintain, or even improve, the performance of an opin- ion retrieval system.</p><p>6 0.34780461 <a title="251-lsi-6" href="./acl-2010-A_Study_of_Information_Retrieval_Weighting_Schemes_for_Sentiment_Analysis.html">18 acl-2010-A Study of Information Retrieval Weighting Schemes for Sentiment Analysis</a></p>
<p>7 0.30445251 <a title="251-lsi-7" href="./acl-2010-Sentiment_Learning_on_Product_Reviews_via_Sentiment_Ontology_Tree.html">209 acl-2010-Sentiment Learning on Product Reviews via Sentiment Ontology Tree</a></p>
<p>8 0.30305451 <a title="251-lsi-8" href="./acl-2010-Vocabulary_Choice_as_an_Indicator_of_Perspective.html">256 acl-2010-Vocabulary Choice as an Indicator of Perspective</a></p>
<p>9 0.28108743 <a title="251-lsi-9" href="./acl-2010-Generating_Fine-Grained_Reviews_of_Songs_from_Album_Reviews.html">122 acl-2010-Generating Fine-Grained Reviews of Songs from Album Reviews</a></p>
<p>10 0.2770755 <a title="251-lsi-10" href="./acl-2010-Automatically_Generating_Annotator_Rationales_to_Improve_Sentiment_Classification.html">42 acl-2010-Automatically Generating Annotator Rationales to Improve Sentiment Classification</a></p>
<p>11 0.23936547 <a title="251-lsi-11" href="./acl-2010-Last_but_Definitely_Not_Least%3A_On_the_Role_of_the_Last_Sentence_in_Automatic_Polarity-Classification.html">157 acl-2010-Last but Definitely Not Least: On the Role of the Last Sentence in Automatic Polarity-Classification</a></p>
<p>12 0.22713919 <a title="251-lsi-12" href="./acl-2010-A_Hybrid_Hierarchical_Model_for_Multi-Document_Summarization.html">8 acl-2010-A Hybrid Hierarchical Model for Multi-Document Summarization</a></p>
<p>13 0.21958445 <a title="251-lsi-13" href="./acl-2010-Detecting_Experiences_from_Weblogs.html">85 acl-2010-Detecting Experiences from Weblogs</a></p>
<p>14 0.21948127 <a title="251-lsi-14" href="./acl-2010-Recommendation_in_Internet_Forums_and_Blogs.html">204 acl-2010-Recommendation in Internet Forums and Blogs</a></p>
<p>15 0.20865506 <a title="251-lsi-15" href="./acl-2010-Identifying_Text_Polarity_Using_Random_Walks.html">141 acl-2010-Identifying Text Polarity Using Random Walks</a></p>
<p>16 0.19841188 <a title="251-lsi-16" href="./acl-2010-Supervised_Noun_Phrase_Coreference_Research%3A_The_First_Fifteen_Years.html">219 acl-2010-Supervised Noun Phrase Coreference Research: The First Fifteen Years</a></p>
<p>17 0.19612338 <a title="251-lsi-17" href="./acl-2010-Identifying_Non-Explicit_Citing_Sentences_for_Citation-Based_Summarization..html">140 acl-2010-Identifying Non-Explicit Citing Sentences for Citation-Based Summarization.</a></p>
<p>18 0.1855557 <a title="251-lsi-18" href="./acl-2010-Evaluating_Multilanguage-Comparability_of_Subjectivity_Analysis_Systems.html">105 acl-2010-Evaluating Multilanguage-Comparability of Subjectivity Analysis Systems</a></p>
<p>19 0.18476582 <a title="251-lsi-19" href="./acl-2010-The_Same-Head_Heuristic_for_Coreference.html">233 acl-2010-The Same-Head Heuristic for Coreference</a></p>
<p>20 0.17394908 <a title="251-lsi-20" href="./acl-2010-Don%27t_%27Have_a_Clue%27%3F_Unsupervised_Co-Learning_of_Downward-Entailing_Operators..html">92 acl-2010-Don't 'Have a Clue'? Unsupervised Co-Learning of Downward-Entailing Operators.</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(25, 0.061), (42, 0.145), (44, 0.01), (59, 0.059), (60, 0.151), (72, 0.033), (73, 0.079), (76, 0.017), (78, 0.023), (80, 0.025), (83, 0.12), (84, 0.052), (88, 0.011), (98, 0.117)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.86865795 <a title="251-lda-1" href="./acl-2010-Using_Anaphora_Resolution_to_Improve_Opinion_Target_Identification_in_Movie_Reviews.html">251 acl-2010-Using Anaphora Resolution to Improve Opinion Target Identification in Movie Reviews</a></p>
<p>Author: Niklas Jakob ; Iryna Gurevych</p><p>Abstract: unkown-abstract</p><p>2 0.81524754 <a title="251-lda-2" href="./acl-2010-Generating_Focused_Topic-Specific_Sentiment_Lexicons.html">123 acl-2010-Generating Focused Topic-Specific Sentiment Lexicons</a></p>
<p>Author: Valentin Jijkoun ; Maarten de Rijke ; Wouter Weerkamp</p><p>Abstract: We present a method for automatically generating focused and accurate topicspecific subjectivity lexicons from a general purpose polarity lexicon that allow users to pin-point subjective on-topic information in a set of relevant documents. We motivate the need for such lexicons in the field of media analysis, describe a bootstrapping method for generating a topic-specific lexicon from a general purpose polarity lexicon, and evaluate the quality of the generated lexicons both manually and using a TREC Blog track test set for opinionated blog post retrieval. Although the generated lexicons can be an order of magnitude more selective than the general purpose lexicon, they maintain, or even improve, the performance of an opin- ion retrieval system.</p><p>3 0.81404483 <a title="251-lda-3" href="./acl-2010-Incorporating_Extra-Linguistic_Information_into_Reference_Resolution_in_Collaborative_Task_Dialogue.html">149 acl-2010-Incorporating Extra-Linguistic Information into Reference Resolution in Collaborative Task Dialogue</a></p>
<p>Author: Ryu Iida ; Syumpei Kobayashi ; Takenobu Tokunaga</p><p>Abstract: This paper proposes an approach to reference resolution in situated dialogues by exploiting extra-linguistic information. Recently, investigations of referential behaviours involved in situations in the real world have received increasing attention by researchers (Di Eugenio et al., 2000; Byron, 2005; van Deemter, 2007; Spanger et al., 2009). In order to create an accurate reference resolution model, we need to handle extra-linguistic information as well as textual information examined by existing approaches (Soon et al., 2001 ; Ng and Cardie, 2002, etc.). In this paper, we incorporate extra-linguistic information into an existing corpus-based reference resolution model, and investigate its effects on refer- ence resolution problems within a corpus of Japanese dialogues. The results demonstrate that our proposed model achieves an accuracy of 79.0% for this task.</p><p>4 0.79393423 <a title="251-lda-4" href="./acl-2010-Non-Cooperation_in_Dialogue.html">178 acl-2010-Non-Cooperation in Dialogue</a></p>
<p>Author: Brian Pluss</p><p>Abstract: This paper presents ongoing research on computational models for non-cooperative dialogue. We start by analysing different levels of cooperation in conversation. Then, inspired by findings from an empirical study, we propose a technique for measuring non-cooperation in political interviews. Finally, we describe a research programme towards obtaining a suitable model and discuss previous accounts for conflictive dialogue, identifying the differences with our work.</p><p>5 0.79251289 <a title="251-lda-5" href="./acl-2010-Sentence_and_Expression_Level_Annotation_of_Opinions_in_User-Generated_Discourse.html">208 acl-2010-Sentence and Expression Level Annotation of Opinions in User-Generated Discourse</a></p>
<p>Author: Cigdem Toprak ; Niklas Jakob ; Iryna Gurevych</p><p>Abstract: In this paper, we introduce a corpus of consumer reviews from the rateitall and the eopinions websites annotated with opinion-related information. We present a two-level annotation scheme. In the first stage, the reviews are analyzed at the sentence level for (i) relevancy to a given topic, and (ii) expressing an evaluation about the topic. In the second stage, on-topic sentences containing evaluations about the topic are further investigated at the expression level for pinpointing the properties (semantic orientation, intensity), and the functional components of the evaluations (opinion terms, targets and holders). We discuss the annotation scheme, the inter-annotator agreement for different subtasks and our observations.</p><p>6 0.78360105 <a title="251-lda-6" href="./acl-2010-Inducing_Domain-Specific_Semantic_Class_Taggers_from_%28Almost%29_Nothing.html">150 acl-2010-Inducing Domain-Specific Semantic Class Taggers from (Almost) Nothing</a></p>
<p>7 0.77601397 <a title="251-lda-7" href="./acl-2010-Hierarchical_Sequential_Learning_for_Extracting_Opinions_and_Their_Attributes.html">134 acl-2010-Hierarchical Sequential Learning for Extracting Opinions and Their Attributes</a></p>
<p>8 0.76888084 <a title="251-lda-8" href="./acl-2010-Sparsity_in_Dependency_Grammar_Induction.html">214 acl-2010-Sparsity in Dependency Grammar Induction</a></p>
<p>9 0.7642926 <a title="251-lda-9" href="./acl-2010-A_Unified_Graph_Model_for_Sentence-Based_Opinion_Retrieval.html">22 acl-2010-A Unified Graph Model for Sentence-Based Opinion Retrieval</a></p>
<p>10 0.75635415 <a title="251-lda-10" href="./acl-2010-The_Prevalence_of_Descriptive_Referring_Expressions_in_News_and_Narrative.html">231 acl-2010-The Prevalence of Descriptive Referring Expressions in News and Narrative</a></p>
<p>11 0.7231797 <a title="251-lda-11" href="./acl-2010-Extracting_Social_Networks_from_Literary_Fiction.html">112 acl-2010-Extracting Social Networks from Literary Fiction</a></p>
<p>12 0.71850657 <a title="251-lda-12" href="./acl-2010-Automatically_Generating_Annotator_Rationales_to_Improve_Sentiment_Classification.html">42 acl-2010-Automatically Generating Annotator Rationales to Improve Sentiment Classification</a></p>
<p>13 0.71827775 <a title="251-lda-13" href="./acl-2010-A_Study_of_Information_Retrieval_Weighting_Schemes_for_Sentiment_Analysis.html">18 acl-2010-A Study of Information Retrieval Weighting Schemes for Sentiment Analysis</a></p>
<p>14 0.71794015 <a title="251-lda-14" href="./acl-2010-Assessing_the_Role_of_Discourse_References_in_Entailment_Inference.html">33 acl-2010-Assessing the Role of Discourse References in Entailment Inference</a></p>
<p>15 0.71239483 <a title="251-lda-15" href="./acl-2010-%22Ask_Not_What_Textual_Entailment_Can_Do_for_You...%22.html">1 acl-2010-"Ask Not What Textual Entailment Can Do for You..."</a></p>
<p>16 0.70686215 <a title="251-lda-16" href="./acl-2010-Coreference_Resolution_with_Reconcile.html">73 acl-2010-Coreference Resolution with Reconcile</a></p>
<p>17 0.7060805 <a title="251-lda-17" href="./acl-2010-Learning_to_Adapt_to_Unknown_Users%3A_Referring_Expression_Generation_in_Spoken_Dialogue_Systems.html">167 acl-2010-Learning to Adapt to Unknown Users: Referring Expression Generation in Spoken Dialogue Systems</a></p>
<p>18 0.70379943 <a title="251-lda-18" href="./acl-2010-Generating_Fine-Grained_Reviews_of_Songs_from_Album_Reviews.html">122 acl-2010-Generating Fine-Grained Reviews of Songs from Album Reviews</a></p>
<p>19 0.7028057 <a title="251-lda-19" href="./acl-2010-Sentiment_Learning_on_Product_Reviews_via_Sentiment_Ontology_Tree.html">209 acl-2010-Sentiment Learning on Product Reviews via Sentiment Ontology Tree</a></p>
<p>20 0.70275605 <a title="251-lda-20" href="./acl-2010-Entity-Based_Local_Coherence_Modelling_Using_Topological_Fields.html">101 acl-2010-Entity-Based Local Coherence Modelling Using Topological Fields</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
