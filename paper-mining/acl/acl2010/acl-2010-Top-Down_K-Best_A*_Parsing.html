<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>236 acl-2010-Top-Down K-Best A* Parsing</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-236" href="#">acl2010-236</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>236 acl-2010-Top-Down K-Best A* Parsing</h1>
<br/><p>Source: <a title="acl-2010-236-pdf" href="http://aclweb.org/anthology//P/P10/P10-2037.pdf">pdf</a></p><p>Author: Adam Pauls ; Dan Klein ; Chris Quirk</p><p>Abstract: We propose a top-down algorithm for extracting k-best lists from a parser. Our algorithm, TKA∗ is a variant of the kbest A∗ (KA∗) algorithm of Pauls and Klein (2009). In contrast to KA∗, which performs an inside and outside pass before performing k-best extraction bottom up, TKA∗ performs only the inside pass before extracting k-best lists top down. TKA∗ maintains the same optimality and efficiency guarantees of KA∗, but is simpler to both specify and implement.</p><p>Reference: <a title="acl-2010-236-reference" href="../acl2010_reference/acl-2010-Top-Down_K-Best_A%2A_Parsing_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('item', 0.451), ('ka', 0.36), ('insid', 0.346), ('tka', 0.33), ('edg', 0.311), ('outsid', 0.259), ('deduc', 0.246), ('fronty', 0.13), ('der', 0.124), ('vp', 0.107), ('lazy', 0.106), ('agend', 0.092), ('wait', 0.086), ('klein', 0.083), ('rul', 0.082), ('pass', 0.075), ('viterb', 0.071), ('expand', 0.066), ('priorit', 0.064), ('paul', 0.063)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="236-tfidf-1" href="./acl-2010-Top-Down_K-Best_A%2A_Parsing.html">236 acl-2010-Top-Down K-Best A* Parsing</a></p>
<p>Author: Adam Pauls ; Dan Klein ; Chris Quirk</p><p>Abstract: We propose a top-down algorithm for extracting k-best lists from a parser. Our algorithm, TKA∗ is a variant of the kbest A∗ (KA∗) algorithm of Pauls and Klein (2009). In contrast to KA∗, which performs an inside and outside pass before performing k-best extraction bottom up, TKA∗ performs only the inside pass before extracting k-best lists top down. TKA∗ maintains the same optimality and efficiency guarantees of KA∗, but is simpler to both specify and implement.</p><p>2 0.48020992 <a title="236-tfidf-2" href="./acl-2010-Hierarchical_A%2A_Parsing_with_Bridge_Outside_Scores.html">131 acl-2010-Hierarchical A* Parsing with Bridge Outside Scores</a></p>
<p>Author: Adam Pauls ; Dan Klein</p><p>Abstract: Hierarchical A∗ (HA∗) uses of a hierarchy of coarse grammars to speed up parsing without sacrificing optimality. HA∗ prioritizes search in refined grammars using Viterbi outside costs computed in coarser grammars. We present Bridge Hierarchical A∗ (BHA∗), a modified Hierarchial A∗ algorithm which computes a novel outside cost called a bridge outside cost. These bridge costs mix finer outside scores with coarser inside scores, and thus constitute tighter heuristics than entirely coarse scores. We show that BHA∗ substantially outperforms HA∗ when the hierarchy contains only very coarse grammars, while achieving comparable performance on more refined hierarchies.</p><p>3 0.11538921 <a title="236-tfidf-3" href="./acl-2010-Dynamic_Programming_for_Linear-Time_Incremental_Parsing.html">93 acl-2010-Dynamic Programming for Linear-Time Incremental Parsing</a></p>
<p>Author: Liang Huang ; Kenji Sagae</p><p>Abstract: Incremental parsing techniques such as shift-reduce have gained popularity thanks to their efficiency, but there remains a major problem: the search is greedy and only explores a tiny fraction of the whole space (even with beam search) as opposed to dynamic programming. We show that, surprisingly, dynamic programming is in fact possible for many shift-reduce parsers, by merging “equivalent” stacks based on feature values. Empirically, our algorithm yields up to a five-fold speedup over a state-of-the-art shift-reduce depen- dency parser with no loss in accuracy. Better search also leads to better learning, and our final parser outperforms all previously reported dependency parsers for English and Chinese, yet is much faster.</p><p>4 0.098721258 <a title="236-tfidf-4" href="./acl-2010-Blocked_Inference_in_Bayesian_Tree_Substitution_Grammars.html">53 acl-2010-Blocked Inference in Bayesian Tree Substitution Grammars</a></p>
<p>Author: Trevor Cohn ; Phil Blunsom</p><p>Abstract: Learning a tree substitution grammar is very challenging due to derivational ambiguity. Our recent approach used a Bayesian non-parametric model to induce good derivations from treebanked input (Cohn et al., 2009), biasing towards small grammars composed of small generalisable productions. In this paper we present a novel training method for the model using a blocked Metropolis-Hastings sampler in place of the previous method’s local Gibbs sampler. The blocked sampler makes considerably larger moves than the local sampler and consequently con- verges in less time. A core component of the algorithm is a grammar transformation which represents an infinite tree substitution grammar in a finite context free grammar. This enables efficient blocked inference for training and also improves the parsing algorithm. Both algorithms are shown to improve parsing accuracy.</p><p>5 0.095635392 <a title="236-tfidf-5" href="./acl-2010-Constituency_to_Dependency_Translation_with_Forests.html">69 acl-2010-Constituency to Dependency Translation with Forests</a></p>
<p>Author: Haitao Mi ; Qun Liu</p><p>Abstract: Tree-to-string systems (and their forestbased extensions) have gained steady popularity thanks to their simplicity and efficiency, but there is a major limitation: they are unable to guarantee the grammaticality of the output, which is explicitly modeled in string-to-tree systems via targetside syntax. We thus propose to combine the advantages of both, and present a novel constituency-to-dependency translation model, which uses constituency forests on the source side to direct the translation, and dependency trees on the target side (as a language model) to ensure grammaticality. Medium-scale experiments show an absolute and statistically significant improvement of +0.7 BLEU points over a state-of-the-art forest-based tree-to-string system even with fewer rules. This is also the first time that a treeto-tree model can surpass tree-to-string counterparts.</p><p>6 0.091417402 <a title="236-tfidf-6" href="./acl-2010-Learning_to_Translate_with_Source_and_Target_Syntax.html">169 acl-2010-Learning to Translate with Source and Target Syntax</a></p>
<p>7 0.089444891 <a title="236-tfidf-7" href="./acl-2010-Optimizing_Question_Answering_Accuracy_by_Maximizing_Log-Likelihood.html">189 acl-2010-Optimizing Question Answering Accuracy by Maximizing Log-Likelihood</a></p>
<p>8 0.079246312 <a title="236-tfidf-8" href="./acl-2010-Bayesian_Synchronous_Tree-Substitution_Grammar_Induction_and_Its_Application_to_Sentence_Compression.html">46 acl-2010-Bayesian Synchronous Tree-Substitution Grammar Induction and Its Application to Sentence Compression</a></p>
<p>9 0.075070776 <a title="236-tfidf-9" href="./acl-2010-Simple%2C_Accurate_Parsing_with_an_All-Fragments_Grammar.html">211 acl-2010-Simple, Accurate Parsing with an All-Fragments Grammar</a></p>
<p>10 0.07490968 <a title="236-tfidf-10" href="./acl-2010-Global_Learning_of_Focused_Entailment_Graphs.html">127 acl-2010-Global Learning of Focused Entailment Graphs</a></p>
<p>11 0.074794523 <a title="236-tfidf-11" href="./acl-2010-cdec%3A_A_Decoder%2C_Alignment%2C_and_Learning_Framework_for_Finite-State_and_Context-Free_Translation_Models.html">265 acl-2010-cdec: A Decoder, Alignment, and Learning Framework for Finite-State and Context-Free Translation Models</a></p>
<p>12 0.071800545 <a title="236-tfidf-12" href="./acl-2010-Dependency_Parsing_and_Projection_Based_on_Word-Pair_Classification.html">83 acl-2010-Dependency Parsing and Projection Based on Word-Pair Classification</a></p>
<p>13 0.069143713 <a title="236-tfidf-13" href="./acl-2010-Viterbi_Training_for_PCFGs%3A_Hardness_Results_and_Competitiveness_of_Uniform_Initialization.html">255 acl-2010-Viterbi Training for PCFGs: Hardness Results and Competitiveness of Uniform Initialization</a></p>
<p>14 0.065461963 <a title="236-tfidf-14" href="./acl-2010-Predicate_Argument_Structure_Analysis_Using_Transformation_Based_Learning.html">198 acl-2010-Predicate Argument Structure Analysis Using Transformation Based Learning</a></p>
<p>15 0.065238863 <a title="236-tfidf-15" href="./acl-2010-Profiting_from_Mark-Up%3A_Hyper-Text_Annotations_for_Guided_Parsing.html">200 acl-2010-Profiting from Mark-Up: Hyper-Text Annotations for Guided Parsing</a></p>
<p>16 0.06273631 <a title="236-tfidf-16" href="./acl-2010-Filtering_Syntactic_Constraints_for_Statistical_Machine_Translation.html">115 acl-2010-Filtering Syntactic Constraints for Statistical Machine Translation</a></p>
<p>17 0.061145779 <a title="236-tfidf-17" href="./acl-2010-Fine-Grained_Tree-to-String_Translation_Rule_Extraction.html">118 acl-2010-Fine-Grained Tree-to-String Translation Rule Extraction</a></p>
<p>18 0.06066281 <a title="236-tfidf-18" href="./acl-2010-Comparable_Entity_Mining_from_Comparative_Questions.html">63 acl-2010-Comparable Entity Mining from Comparative Questions</a></p>
<p>19 0.059339046 <a title="236-tfidf-19" href="./acl-2010-Correcting_Errors_in_a_Treebank_Based_on_Synchronous_Tree_Substitution_Grammar.html">75 acl-2010-Correcting Errors in a Treebank Based on Synchronous Tree Substitution Grammar</a></p>
<p>20 0.057704449 <a title="236-tfidf-20" href="./acl-2010-Untangling_the_Cross-Lingual_Link_Structure_of_Wikipedia.html">250 acl-2010-Untangling the Cross-Lingual Link Structure of Wikipedia</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.143), (1, 0.036), (2, 0.04), (3, -0.0), (4, -0.053), (5, 0.115), (6, 0.11), (7, -0.044), (8, -0.028), (9, 0.148), (10, -0.007), (11, -0.016), (12, 0.04), (13, -0.043), (14, -0.077), (15, 0.001), (16, 0.02), (17, 0.033), (18, 0.038), (19, 0.013), (20, 0.026), (21, -0.095), (22, 0.036), (23, 0.104), (24, -0.299), (25, 0.083), (26, -0.223), (27, -0.178), (28, 0.172), (29, -0.397), (30, 0.286), (31, 0.098), (32, 0.104), (33, 0.093), (34, 0.046), (35, -0.084), (36, 0.116), (37, 0.104), (38, 0.007), (39, -0.006), (40, 0.091), (41, 0.181), (42, 0.018), (43, 0.03), (44, -0.048), (45, -0.05), (46, -0.056), (47, 0.012), (48, 0.054), (49, -0.074)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98187739 <a title="236-lsi-1" href="./acl-2010-Top-Down_K-Best_A%2A_Parsing.html">236 acl-2010-Top-Down K-Best A* Parsing</a></p>
<p>Author: Adam Pauls ; Dan Klein ; Chris Quirk</p><p>Abstract: We propose a top-down algorithm for extracting k-best lists from a parser. Our algorithm, TKA∗ is a variant of the kbest A∗ (KA∗) algorithm of Pauls and Klein (2009). In contrast to KA∗, which performs an inside and outside pass before performing k-best extraction bottom up, TKA∗ performs only the inside pass before extracting k-best lists top down. TKA∗ maintains the same optimality and efficiency guarantees of KA∗, but is simpler to both specify and implement.</p><p>2 0.96246195 <a title="236-lsi-2" href="./acl-2010-Hierarchical_A%2A_Parsing_with_Bridge_Outside_Scores.html">131 acl-2010-Hierarchical A* Parsing with Bridge Outside Scores</a></p>
<p>Author: Adam Pauls ; Dan Klein</p><p>Abstract: Hierarchical A∗ (HA∗) uses of a hierarchy of coarse grammars to speed up parsing without sacrificing optimality. HA∗ prioritizes search in refined grammars using Viterbi outside costs computed in coarser grammars. We present Bridge Hierarchical A∗ (BHA∗), a modified Hierarchial A∗ algorithm which computes a novel outside cost called a bridge outside cost. These bridge costs mix finer outside scores with coarser inside scores, and thus constitute tighter heuristics than entirely coarse scores. We show that BHA∗ substantially outperforms HA∗ when the hierarchy contains only very coarse grammars, while achieving comparable performance on more refined hierarchies.</p><p>3 0.36743408 <a title="236-lsi-3" href="./acl-2010-Optimal_Rank_Reduction_for_Linear_Context-Free_Rewriting_Systems_with_Fan-Out_Two.html">186 acl-2010-Optimal Rank Reduction for Linear Context-Free Rewriting Systems with Fan-Out Two</a></p>
<p>Author: Benoit Sagot ; Giorgio Satta</p><p>Abstract: Linear Context-Free Rewriting Systems (LCFRSs) are a grammar formalism capable of modeling discontinuous phrases. Many parsing applications use LCFRSs where the fan-out (a measure of the discontinuity of phrases) does not exceed 2. We present an efficient algorithm for optimal reduction of the length of production right-hand side in LCFRSs with fan-out at most 2. This results in asymptotical running time improvement for known parsing algorithms for this class.</p><p>4 0.3107633 <a title="236-lsi-4" href="./acl-2010-Don%27t_%27Have_a_Clue%27%3F_Unsupervised_Co-Learning_of_Downward-Entailing_Operators..html">92 acl-2010-Don't 'Have a Clue'? Unsupervised Co-Learning of Downward-Entailing Operators.</a></p>
<p>Author: Cristian Danescu-Niculescu-Mizil ; Lillian Lee</p><p>Abstract: Researchers in textual entailment have begun to consider inferences involving downward-entailing operators, an interesting and important class of lexical items that change the way inferences are made. Recent work proposed a method for learning English downward-entailing operators that requires access to a high-quality collection of negative polarity items (NPIs). However, English is one of the very few languages for which such a list exists. We propose the first approach that can be applied to the many languages for which there is no pre-existing high-precision database of NPIs. As a case study, we apply our method to Romanian and show that our method yields good results. Also, we perform a cross-linguistic analysis that suggests interesting connections to some findings in linguistic typology.</p><p>5 0.2913968 <a title="236-lsi-5" href="./acl-2010-Simple%2C_Accurate_Parsing_with_an_All-Fragments_Grammar.html">211 acl-2010-Simple, Accurate Parsing with an All-Fragments Grammar</a></p>
<p>Author: Mohit Bansal ; Dan Klein</p><p>Abstract: We present a simple but accurate parser which exploits both large tree fragments and symbol refinement. We parse with all fragments of the training set, in contrast to much recent work on tree selection in data-oriented parsing and treesubstitution grammar learning. We require only simple, deterministic grammar symbol refinement, in contrast to recent work on latent symbol refinement. Moreover, our parser requires no explicit lexicon machinery, instead parsing input sentences as character streams. Despite its simplicity, our parser achieves accuracies of over 88% F1 on the standard English WSJ task, which is competitive with substantially more complicated state-of-theart lexicalized and latent-variable parsers. Additional specific contributions center on making implicit all-fragments parsing efficient, including a coarse-to-fine inference scheme and a new graph encoding.</p><p>6 0.28595161 <a title="236-lsi-6" href="./acl-2010-Dynamic_Programming_for_Linear-Time_Incremental_Parsing.html">93 acl-2010-Dynamic Programming for Linear-Time Incremental Parsing</a></p>
<p>7 0.26306701 <a title="236-lsi-7" href="./acl-2010-Viterbi_Training_for_PCFGs%3A_Hardness_Results_and_Competitiveness_of_Uniform_Initialization.html">255 acl-2010-Viterbi Training for PCFGs: Hardness Results and Competitiveness of Uniform Initialization</a></p>
<p>8 0.24588057 <a title="236-lsi-8" href="./acl-2010-How_Spoken_Language_Corpora_Can_Refine_Current_Speech_Motor_Training_Methodologies.html">137 acl-2010-How Spoken Language Corpora Can Refine Current Speech Motor Training Methodologies</a></p>
<p>9 0.23306352 <a title="236-lsi-9" href="./acl-2010-Blocked_Inference_in_Bayesian_Tree_Substitution_Grammars.html">53 acl-2010-Blocked Inference in Bayesian Tree Substitution Grammars</a></p>
<p>10 0.21117954 <a title="236-lsi-10" href="./acl-2010-Extracting_Sequences_from_the_Web.html">111 acl-2010-Extracting Sequences from the Web</a></p>
<p>11 0.20123541 <a title="236-lsi-11" href="./acl-2010-Using_Speech_to_Reply_to_SMS_Messages_While_Driving%3A_An_In-Car_Simulator_User_Study.html">254 acl-2010-Using Speech to Reply to SMS Messages While Driving: An In-Car Simulator User Study</a></p>
<p>12 0.19132298 <a title="236-lsi-12" href="./acl-2010-Comparable_Entity_Mining_from_Comparative_Questions.html">63 acl-2010-Comparable Entity Mining from Comparative Questions</a></p>
<p>13 0.19040641 <a title="236-lsi-13" href="./acl-2010-Untangling_the_Cross-Lingual_Link_Structure_of_Wikipedia.html">250 acl-2010-Untangling the Cross-Lingual Link Structure of Wikipedia</a></p>
<p>14 0.18984883 <a title="236-lsi-14" href="./acl-2010-Constituency_to_Dependency_Translation_with_Forests.html">69 acl-2010-Constituency to Dependency Translation with Forests</a></p>
<p>15 0.18797778 <a title="236-lsi-15" href="./acl-2010-Learning_to_Translate_with_Source_and_Target_Syntax.html">169 acl-2010-Learning to Translate with Source and Target Syntax</a></p>
<p>16 0.18257247 <a title="236-lsi-16" href="./acl-2010-Global_Learning_of_Focused_Entailment_Graphs.html">127 acl-2010-Global Learning of Focused Entailment Graphs</a></p>
<p>17 0.17977741 <a title="236-lsi-17" href="./acl-2010-Fine-Grained_Tree-to-String_Translation_Rule_Extraction.html">118 acl-2010-Fine-Grained Tree-to-String Translation Rule Extraction</a></p>
<p>18 0.17606762 <a title="236-lsi-18" href="./acl-2010-Bayesian_Synchronous_Tree-Substitution_Grammar_Induction_and_Its_Application_to_Sentence_Compression.html">46 acl-2010-Bayesian Synchronous Tree-Substitution Grammar Induction and Its Application to Sentence Compression</a></p>
<p>19 0.17457192 <a title="236-lsi-19" href="./acl-2010-Combining_Data_and_Mathematical_Models_of_Language_Change.html">61 acl-2010-Combining Data and Mathematical Models of Language Change</a></p>
<p>20 0.17308924 <a title="236-lsi-20" href="./acl-2010-Computing_Weakest_Readings.html">67 acl-2010-Computing Weakest Readings</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(7, 0.052), (14, 0.021), (29, 0.046), (40, 0.02), (42, 0.011), (52, 0.012), (54, 0.043), (56, 0.036), (58, 0.349), (68, 0.031), (71, 0.063), (84, 0.145), (96, 0.052)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.79014421 <a title="236-lda-1" href="./acl-2010-Top-Down_K-Best_A%2A_Parsing.html">236 acl-2010-Top-Down K-Best A* Parsing</a></p>
<p>Author: Adam Pauls ; Dan Klein ; Chris Quirk</p><p>Abstract: We propose a top-down algorithm for extracting k-best lists from a parser. Our algorithm, TKA∗ is a variant of the kbest A∗ (KA∗) algorithm of Pauls and Klein (2009). In contrast to KA∗, which performs an inside and outside pass before performing k-best extraction bottom up, TKA∗ performs only the inside pass before extracting k-best lists top down. TKA∗ maintains the same optimality and efficiency guarantees of KA∗, but is simpler to both specify and implement.</p><p>2 0.71031684 <a title="236-lda-2" href="./acl-2010-Hierarchical_A%2A_Parsing_with_Bridge_Outside_Scores.html">131 acl-2010-Hierarchical A* Parsing with Bridge Outside Scores</a></p>
<p>Author: Adam Pauls ; Dan Klein</p><p>Abstract: Hierarchical A∗ (HA∗) uses of a hierarchy of coarse grammars to speed up parsing without sacrificing optimality. HA∗ prioritizes search in refined grammars using Viterbi outside costs computed in coarser grammars. We present Bridge Hierarchical A∗ (BHA∗), a modified Hierarchial A∗ algorithm which computes a novel outside cost called a bridge outside cost. These bridge costs mix finer outside scores with coarser inside scores, and thus constitute tighter heuristics than entirely coarse scores. We show that BHA∗ substantially outperforms HA∗ when the hierarchy contains only very coarse grammars, while achieving comparable performance on more refined hierarchies.</p><p>3 0.63505429 <a title="236-lda-3" href="./acl-2010-PCFGs%2C_Topic_Models%2C_Adaptor_Grammars_and_Learning_Topical_Collocations_and_the_Structure_of_Proper_Names.html">191 acl-2010-PCFGs, Topic Models, Adaptor Grammars and Learning Topical Collocations and the Structure of Proper Names</a></p>
<p>Author: Mark Johnson</p><p>Abstract: This paper establishes a connection between two apparently very different kinds of probabilistic models. Latent Dirichlet Allocation (LDA) models are used as “topic models” to produce a lowdimensional representation of documents, while Probabilistic Context-Free Grammars (PCFGs) define distributions over trees. The paper begins by showing that LDA topic models can be viewed as a special kind of PCFG, so Bayesian inference for PCFGs can be used to infer Topic Models as well. Adaptor Grammars (AGs) are a hierarchical, non-parameteric Bayesian extension of PCFGs. Exploiting the close relationship between LDA and PCFGs just described, we propose two novel probabilistic models that combine insights from LDA and AG models. The first replaces the unigram component of LDA topic models with multi-word sequences or collocations generated by an AG. The second extension builds on the first one to learn aspects of the internal structure of proper names.</p><p>4 0.61177117 <a title="236-lda-4" href="./acl-2010-On_Learning_Subtypes_of_the_Part-Whole_Relation%3A_Do_Not_Mix_Your_Seeds.html">181 acl-2010-On Learning Subtypes of the Part-Whole Relation: Do Not Mix Your Seeds</a></p>
<p>Author: Ashwin Ittoo ; Gosse Bouma</p><p>Abstract: An important relation in information extraction is the part-whole relation. Ontological studies mention several types of this relation. In this paper, we show that the traditional practice of initializing minimally-supervised algorithms with a single set that mixes seeds of different types fails to capture the wide variety of part-whole patterns and tuples. The results obtained with mixed seeds ultimately converge to one of the part-whole relation types. We also demonstrate that all the different types of part-whole relations can still be discovered, regardless of the type characterized by the initializing seeds. We performed our experiments with a state-ofthe-art information extraction algorithm. 1</p><p>5 0.46671236 <a title="236-lda-5" href="./acl-2010-Training_Phrase_Translation_Models_with_Leaving-One-Out.html">240 acl-2010-Training Phrase Translation Models with Leaving-One-Out</a></p>
<p>Author: Joern Wuebker ; Arne Mauser ; Hermann Ney</p><p>Abstract: Several attempts have been made to learn phrase translation probabilities for phrasebased statistical machine translation that go beyond pure counting of phrases in word-aligned training data. Most approaches report problems with overfitting. We describe a novel leavingone-out approach to prevent over-fitting that allows us to train phrase models that show improved translation performance on the WMT08 Europarl German-English task. In contrast to most previous work where phrase models were trained separately from other models used in translation, we include all components such as single word lexica and reordering mod- els in training. Using this consistent training of phrase models we are able to achieve improvements of up to 1.4 points in BLEU. As a side effect, the phrase table size is reduced by more than 80%.</p><p>6 0.46666038 <a title="236-lda-6" href="./acl-2010-Hierarchical_Search_for_Word_Alignment.html">133 acl-2010-Hierarchical Search for Word Alignment</a></p>
<p>7 0.46599755 <a title="236-lda-7" href="./acl-2010-Faster_Parsing_by_Supertagger_Adaptation.html">114 acl-2010-Faster Parsing by Supertagger Adaptation</a></p>
<p>8 0.46166372 <a title="236-lda-8" href="./acl-2010-Constituency_to_Dependency_Translation_with_Forests.html">69 acl-2010-Constituency to Dependency Translation with Forests</a></p>
<p>9 0.46139103 <a title="236-lda-9" href="./acl-2010-Accurate_Context-Free_Parsing_with_Combinatory_Categorial_Grammar.html">23 acl-2010-Accurate Context-Free Parsing with Combinatory Categorial Grammar</a></p>
<p>10 0.46128327 <a title="236-lda-10" href="./acl-2010-Blocked_Inference_in_Bayesian_Tree_Substitution_Grammars.html">53 acl-2010-Blocked Inference in Bayesian Tree Substitution Grammars</a></p>
<p>11 0.46082336 <a title="236-lda-11" href="./acl-2010-Rebanking_CCGbank_for_Improved_NP_Interpretation.html">203 acl-2010-Rebanking CCGbank for Improved NP Interpretation</a></p>
<p>12 0.45985809 <a title="236-lda-12" href="./acl-2010-Discriminative_Pruning_for_Discriminative_ITG_Alignment.html">88 acl-2010-Discriminative Pruning for Discriminative ITG Alignment</a></p>
<p>13 0.45925334 <a title="236-lda-13" href="./acl-2010-Discriminative_Modeling_of_Extraction_Sets_for_Machine_Translation.html">87 acl-2010-Discriminative Modeling of Extraction Sets for Machine Translation</a></p>
<p>14 0.45797965 <a title="236-lda-14" href="./acl-2010-Efficient_Third-Order_Dependency_Parsers.html">99 acl-2010-Efficient Third-Order Dependency Parsers</a></p>
<p>15 0.45797366 <a title="236-lda-15" href="./acl-2010-Hard_Constraints_for_Grammatical_Function_Labelling.html">130 acl-2010-Hard Constraints for Grammatical Function Labelling</a></p>
<p>16 0.45790088 <a title="236-lda-16" href="./acl-2010-Event-Based_Hyperspace_Analogue_to_Language_for_Query_Expansion.html">106 acl-2010-Event-Based Hyperspace Analogue to Language for Query Expansion</a></p>
<p>17 0.4578214 <a title="236-lda-17" href="./acl-2010-Using_Parse_Features_for_Preposition_Selection_and_Error_Detection.html">252 acl-2010-Using Parse Features for Preposition Selection and Error Detection</a></p>
<p>18 0.45716307 <a title="236-lda-18" href="./acl-2010-Supervised_Noun_Phrase_Coreference_Research%3A_The_First_Fifteen_Years.html">219 acl-2010-Supervised Noun Phrase Coreference Research: The First Fifteen Years</a></p>
<p>19 0.45634609 <a title="236-lda-19" href="./acl-2010-Joint_Syntactic_and_Semantic_Parsing_of_Chinese.html">153 acl-2010-Joint Syntactic and Semantic Parsing of Chinese</a></p>
<p>20 0.45624897 <a title="236-lda-20" href="./acl-2010-Filtering_Syntactic_Constraints_for_Statistical_Machine_Translation.html">115 acl-2010-Filtering Syntactic Constraints for Statistical Machine Translation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
