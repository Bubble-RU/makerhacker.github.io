<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>124 acl-2010-Generating Image Descriptions Using Dependency Relational Patterns</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-124" href="#">acl2010-124</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>124 acl-2010-Generating Image Descriptions Using Dependency Relational Patterns</h1>
<br/><p>Source: <a title="acl-2010-124-pdf" href="http://aclweb.org/anthology//P/P10/P10-1127.pdf">pdf</a></p><p>Author: Ahmet Aker ; Robert Gaizauskas</p><p>Abstract: This paper presents a novel approach to automatic captioning of geo-tagged images by summarizing multiple webdocuments that contain information related to an image’s location. The summarizer is biased by dependency pattern models towards sentences which contain features typically provided for different scene types such as those of churches, bridges, etc. Our results show that summaries biased by dependency pattern models lead to significantly higher ROUGE scores than both n-gram language models reported in previous work and also Wikipedia baseline summaries. Summaries generated using dependency patterns also lead to more readable summaries than those generated without dependency patterns.</p><p>Reference: <a title="acl-2010-124-reference" href="../acl2010_reference/acl-2010-Generating_Image_Descriptions_Using_Dependency_Relational_Patterns_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Generating image descriptions using dependency relational patterns  Ahmet Aker University of Sheffield a . [sent-1, score-0.847]
</p><p>2 The summarizer is biased by dependency pattern models towards sentences which contain features typically provided for different scene types such as those of churches, bridges, etc. [sent-6, score-0.471]
</p><p>3 Our results show that summaries biased by dependency pattern models lead to significantly higher ROUGE scores than both n-gram language models reported in previous work and also Wikipedia baseline summaries. [sent-7, score-0.578]
</p><p>4 Summaries generated using dependency patterns also lead to more  readable summaries than those generated without dependency patterns. [sent-8, score-0.691]
</p><p>5 This typically small amount of textual information associated with the image is of limited usefulness for image indexing, organization and search. [sent-11, score-0.74]
</p><p>6 Therefore methods which could automatically supplement the information available for image indexing and lead to improved image retrieval would be extremely useful. [sent-12, score-0.74]
</p><p>7 Following the general approach proposed by Aker and Gaizauskas (2009), in this paper we describe a method for automatic image captioning or caption enhancement starting with only a scene or subject type and a set of place names pertaining to an image for example hchurch, {St. [sent-13, score-0.906]
</p><p>8 However, our technique is suitable not only for image captioning but in any application context that requires summary descriptions of instances of object classes, where the instance is to be characterized in terms of the features typically mentioned in describing members of the class. [sent-26, score-0.91]
</p><p>9 They also experimented with representing such conceptual models using n-gram language models derived from corpora consisting of collections of descriptions of instances of specific object types (e. [sent-31, score-0.336]
</p><p>10 a corpus of descriptions of churches, a corpus of bridge descriptions, and so on) and reported results showing that incorporating such n-gram language models as a feature in a feature-based extractive summarizer improves the quality of automatically generated summaries. [sent-33, score-0.425]
</p><p>11 For example one common and important feature of object descriptions is the simple specification of the object type, e. [sent-35, score-0.523]
</p><p>12 Intuitively, what is important in both these cases is that there is a predication whose subject is the object instance of interest and the head of whose complement is the object type: London Bridge . [sent-49, score-0.346]
</p><p>13 This intuition suggests that rather than representing object type conceptual models via corpus-derived language models as do Aker and Gaizauskas (2009), we do so instead using corpus-derived dependency patterns. [sent-63, score-0.409]
</p><p>14 We explore this hypothesis by developing a method for deriving common dependency patterns from object type corpora (Section 2) and then incorporating these patterns into an extractive summarization system (Section 3). [sent-65, score-0.72]
</p><p>15 In Section 4 we evaluate the approach both by scoring against model summaries and via a readability assessment. [sent-66, score-0.303]
</p><p>16 Instead, since specific dependency patterns express specific types of inTable 2: Object types and the number of articles in each object type corpus. [sent-71, score-0.52]
</p><p>17 Object types which are bold are covered by the evaluation image set. [sent-72, score-0.37]
</p><p>18 1 Object type corpora We derive n-gram language and dependency pattern models using object type corpora made available to us by Aker and Gaizauskas. [sent-76, score-0.547]
</p><p>19 Aker and Gaizauskas (2009) define an object type corpus as a collection of texts about a specific static object type such as church, bridge, etc. [sent-77, score-0.472]
</p><p>20 To build such object type corpora the authors categorized Wikipedia articles places by object type. [sent-80, score-0.449]
</p><p>21 The object type of each article was identified automatically by running Is-A patterns over the first five sentences of the article. [sent-81, score-0.415]
</p><p>22 2 N-gram language models Aker and Gaizauskas (2009) experimented with uni-gram and bi-gram language models to capture the features commonly used when describing an object type and used these to bias the sentence selection of the summarizer towards the sentences that contain these features. [sent-85, score-0.478]
</p><p>23 3 Dependency patterns We use the same object type corpora to derive dependency patterns. [sent-93, score-0.52]
</p><p>24 The final two rows of the table show the output of the Stanford dependency parser and the relational patterns identified for this example. [sent-103, score-0.339]
</p><p>25 We continue this until we cover all direct relations with built resulting in two more patterns (OBJECTTYPE built DATE and OBJECTTYPE built W). [sent-131, score-0.334]
</p><p>26 Following these steps we extracted relational patterns for each object type corpus along with the frequency of occurrence of the pattern in the entire corpus. [sent-133, score-0.527]
</p><p>27 1 Pattern categorization  In addition to using dependency patterns as models for biasing sentence selection, we can also use them to control the kind of information to be included in the final summary (see Section 3. [sent-138, score-0.507]
</p><p>28 We may want to ensure that the summary contains a sentence describing the object type of the object, its location and some background information. [sent-140, score-0.466]
</p><p>29 To be able to do so, we categorize dependency patterns according to the type of information they express. [sent-142, score-0.382]
</p><p>30 We manually analyzed human written descriptions about instances of different object types and recorded for each sentence in the descriptions the kind of information it contained about the object. [sent-143, score-0.495]
</p><p>31 We analyzed descriptions of 3 10 different objects where each object had up to four different human written descriptions (Section 4. [sent-144, score-0.474]
</p><p>32 We also manually  assigned each dependency  pattern in each corpus-derived model to one of the above categories, provided it occurred five or more times in the object type corpora. [sent-149, score-0.484]
</p><p>33 The patterns extracted for our example sentence shown in Table 3, for instance, are all categorized by year category because all of them contain information about the foundation date of an object. [sent-150, score-0.286]
</p><p>34 3  Summarizer  We adopted the same overall approach to summarization used by Aker and Gaizauskas to generate the image descriptions. [sent-151, score-0.41]
</p><p>35 It is given two inputs: a toponym associated with an image and a set of documents to be summarized which have been retrieved from the web using the toponym as a query. [sent-153, score-0.486]
</p><p>36 The summarizer creates image descriptions in a three step process. [sent-154, score-0.63]
</p><p>37 In our experiments we extend this feature set by two dependency pattern related features: DpMSim and DepCat. [sent-174, score-0.287]
</p><p>38 To compute this score, we  first parse the sentence on the fly with the Stanford parser and obtain the dependency patterns for the sentence. [sent-177, score-0.33]
</p><p>39 We then associate each dependency pattern of the sentence with the occurrence frequency of that pattern in the dependency pattern model (DpM). [sent-178, score-0.642]
</p><p>40 It is a sum of all occurrence frequencies of the dependency patterns detected in a sentence S that are also contained in the DpM. [sent-180, score-0.33]
</p><p>41 DpMSim(S,DpM)  =XfDpM(p)  (1)  pX∈ XS  The second feature, DepCat, uses dependency patterns to categorize the sentences rather than ranking them. [sent-181, score-0.362]
</p><p>42 To do this, we obtain the relational patterns for the current sentence, check whether for each such pattern whether it is included in the DpM, and, if so, we add to the sentence the category the pattern was manually associated with. [sent-185, score-0.437]
</p><p>43 We used 32 of the 3 10 images from our image set (see Section 4. [sent-202, score-0.507]
</p><p>44 The image descriptions from this data set are used as model summaries. [sent-204, score-0.508]
</p><p>45 Our training data contains for each image a set of image descriptions taken from the VirtualTourist travel community web-site 4. [sent-205, score-0.878]
</p><p>46 From this web-site we took all existing image descriptions about a particular image or object. [sent-206, score-0.878]
</p><p>47 Note that some of these descriptions about a particular object were used to derive the model summaries for that object (see Section 4. [sent-207, score-0.743]
</p><p>48 Assuming that model summaries contain the most relevant sentences about an object we perform ROUGE comparisons between the sentences in all the image descriptions and the model summaries, i. [sent-209, score-1.026]
</p><p>49 we pair each sentence from all image descriptions about a particular place with every sentence from all the model 4www. [sent-211, score-0.6]
</p><p>50 In this way, we have for each sentence from all existing image de-  scriptions about an object a ROUGE score5 indicating its relevance. [sent-215, score-0.589]
</p><p>51 1 Data sets For evaluation we use the image collection de-  scribed in Aker and Gaizauskas (2010). [sent-225, score-0.37]
</p><p>52 The image collection contains 3 10 different images with manually assigned toponyms. [sent-226, score-0.507]
</p><p>53 The images cover 60 of the 107 object types identified from Wikipedia (see Table 2). [sent-227, score-0.31]
</p><p>54 For each image there are up to four short descriptions or model summaries. [sent-228, score-0.508]
</p><p>55 The model summaries were created manually based on image descriptions taken from VirtualTourist and contain a minimum of 190 and a maximum of 210 words. [sent-229, score-0.767]
</p><p>56 of this image collection was used to train the weights and the remaining (105 images) for evaluation. [sent-231, score-0.37]
</p><p>57 To generate automatic captions for the images we automatically retrieved the top 30 related web-documents for each image using the Yahoo! [sent-232, score-0.545]
</p><p>58 search engine and the toponym associated with the image as a query. [sent-233, score-0.428]
</p><p>59 Named after its designer, engineer Gustave Eiffel, the tower was built as the entrance arch for the 1889 World’s Fair. [sent-250, score-0.352]
</p><p>60 Although it was the world’s tallest structure when completed in 1889, the Eiffel Tower has since lost its standing both as  the tallest lattice tower and as the tallest structure in France. [sent-260, score-0.46]
</p><p>61 The tower has two restaurants: Altitude 95, on the first floor 311ft (95m) above sea level; and the Jules Verne, an expensive gastronomical restaurant on the second floor, with a private lift. [sent-261, score-0.302]
</p><p>62 2  ROUGE assessment  In the first assessment we compared the automatically generated summaries against model summaries written by humans using ROUGE (Lin, 2004). [sent-273, score-0.604]
</p><p>63 ROUGE 2 gives recall scores for bi-gram overlap between the automatically generated summaries and the reference ones. [sent-275, score-0.303]
</p><p>64 Firstly, we generated summaries for each image using the top-ranked non Wikipedia document retrieved in the Yahoo! [sent-278, score-0.655]
</p><p>65 From this document we create a baseline summary by selecting sentences from the beginning until the summary reaches a length of 200 words. [sent-280, score-0.321]
</p><p>66 Secondly, we separately ran the summarizer over the top ten documents for each single feature  and compared the automated summaries against the model ones. [sent-290, score-0.449]
</p><p>67 Table 5 shows that the dependency model feature (DpMSim) contributes most to the summary quality according to the ROUGE metrics. [sent-292, score-0.313]
</p><p>68 To see how the ROUGE scores change when features are combined with each other we performed different combinations of the features, ran the summarizer for each combination and compared the automated summaries against the model ones. [sent-297, score-0.454]
</p><p>69 1255  Table 6:  ROUGE scores of feature combinations which score moderately or significantly higher than dependency pattern model (DpMSim) feature and Wikipedia baseline. [sent-303, score-0.4]
</p><p>70 W1049i7k also included the dependency pattern categorization (DepCat) feature explained in Section 3. [sent-308, score-0.338]
</p><p>71 Table 6 shows the results of feature combinations which score moderately or significantly higher than the dependency pattern model (DpMSim) feature score shown in Table 5. [sent-310, score-0.386]
</p><p>72 The summaries categorized by dependency patterns (starterSimilarity+LMSim+DepCat) achieve significantly higher ROUGE scores than the Wikipedia baseline. [sent-312, score-0.627]
</p><p>73 It can be seen that this combination without the dependency patterns lead to lower ROUGE scores in ROUGE 2 and only moderate improvement in ROUGE SU4 if compared with Wikipedia baseline ROUGE scores. [sent-317, score-0.328]
</p><p>74 3 Readability assessment We also evaluated our summaries using a readability assessment as in DUC and TAC. [sent-319, score-0.389]
</p><p>75 DUC and TAC manually assess the quality of automatically generated summaries by asking human subjects to score each summary using five criteria grammaticality, redundancy, clarity, focus and structure criteria. [sent-320, score-0.415]
</p><p>76 For comparison we also evaluated summaries which were not structured by dependency patterns (starterSimilarity + LMSim) and also the Wikipedia baseline summaries. [sent-324, score-0.543]
</p><p>77 Each person was shown all 3 15 summaries (105 from each summary type) in a random way and was asked to assess them according to the DUC and TAC manual assessment scheme. [sent-326, score-0.428]
</p><p>78 We see from Table 7 that using dependency patterns to categorize the sentences and produce a structured summary helps to obtain better readable summaries. [sent-328, score-0.488]
</p><p>79 The scores of our automated summaries were better than the Wikipedia baseline summaries in the grammar feature. [sent-330, score-0.591]
</p><p>80 However, in other features the Wikipedia baseline summaries obtained better scores than our automated summaries. [sent-331, score-0.332]
</p><p>81 5  Related Work  Our approach has an advantage over related work in automatic image captioning in that it requires only GPS information associated with the image in order to generate captions. [sent-333, score-0.812]
</p><p>82 Other attempts towards automatic generation of image captions generate captions based on the immediate textual context of the image with or without consideration of image related features such as colour, shape or texture (Deschacht and Moens, 2007; Mori et al. [sent-334, score-1.186]
</p><p>83 However, Marsch & White (2003) argue that the content of an image and its immediate text have little semantic agreement and this can, according to Purves et al. [sent-341, score-0.37]
</p><p>84 Furthermore, these approaches assume that the image has been obtained from a document. [sent-343, score-0.37]
</p><p>85 However, dependency patterns have not been used extensively in summarization tasks. [sent-370, score-0.324]
</p><p>86 (2002) who used dependency patterns in combination with other features to generate extracts in a single document summarization task. [sent-372, score-0.35]
</p><p>87 The authors found that when learning weights in a simple feature weigthing scheme, the weight assigned to dependency patterns was lower than that assigned to other features. [sent-373, score-0.323]
</p><p>88 The small contribution of the dependency patterns may have been due to the small number of documents they used to derive their dependency patterns they gathered dependency patterns from only ten domain specific documents which are unlikely to be sufficient to capture repeated features in a domain. [sent-374, score-0.852]
</p><p>89 –  6  Discussion and Conclusion  We have proposed a method by which dependency patterns extracted from corpora of descriptions of  instances ofparticular object types can be used in a multi-document summarizer to automatically generate image descriptions. [sent-375, score-1.087]
</p><p>90 Our evaluations show that such an approach yields summaries which score more highly than an approach which uses a simpler representation of an object type model in the form of a n-gram language model. [sent-376, score-0.525]
</p><p>91 When used as the sole feature for sentence ranking, dependency pattern models (DpMSim) produced summaries with higher ROUGE scores than those obtained using the features reported in Aker and Gaizauskas (2009). [sent-377, score-0.636]
</p><p>92 Furthermore, we showed that using dependency patterns in combination with features reported in Aker and Gaizauskas to produce a structured summary led to significantly better results than Wikipedia baseline summaries as assessed by ROUGE. [sent-379, score-0.669]
</p><p>93 These results indicate that dependency patterns are worth investigating for object focused auto-  mated summarization tasks. [sent-381, score-0.497]
</p><p>94 Such investigations should in particular concentrate on how dependency patterns can be used to structure information within the summary, as our best results were achieved when dependency patterns were used for this purpose. [sent-382, score-0.568]
</p><p>95 One is to explore how dependency patterns could be used to produce generative summaries and/or perform sentence trimming. [sent-384, score-0.589]
</p><p>96 Another is to investigate how dependency patterns might be automatically clustered into groups expressing similar or related facts, rather than relying on manual categorization of dependency patterns into categories such as “type”, “year”, etc. [sent-385, score-0.652]
</p><p>97 Evaluation should be extended to investigate the utility of the automatically generated image descriptions for image retrieval. [sent-387, score-0.878]
</p><p>98 what is the flow of facts to describe a location) from existing image descriptions to produce better summaries. [sent-390, score-0.508]
</p><p>99 Automatic word assignment to images based on image division and vector quantization. [sent-519, score-0.507]
</p><p>100 Describing the where–improving image annotation and search through geography. [sent-547, score-0.37]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('image', 0.37), ('aker', 0.303), ('rouge', 0.296), ('summaries', 0.259), ('tower', 0.232), ('eiffel', 0.202), ('gaizauskas', 0.173), ('lmsim', 0.173), ('objecttype', 0.173), ('object', 0.173), ('depcat', 0.159), ('dpmsim', 0.159), ('dependency', 0.148), ('descriptions', 0.138), ('images', 0.137), ('patterns', 0.136), ('startersimilarity', 0.13), ('summary', 0.126), ('summarizer', 0.122), ('bridge', 0.102), ('pattern', 0.1), ('wikipedia', 0.099), ('tallest', 0.076), ('captioning', 0.072), ('built', 0.066), ('barnard', 0.063), ('type', 0.063), ('duc', 0.061), ('rhine', 0.058), ('toponym', 0.058), ('virtualtourist', 0.058), ('relational', 0.055), ('categorization', 0.051), ('duygulu', 0.051), ('multimedia', 0.046), ('abbey', 0.046), ('gps', 0.046), ('sentence', 0.046), ('scores', 0.044), ('readability', 0.044), ('assessment', 0.043), ('champ', 0.043), ('gustave', 0.043), ('monument', 0.043), ('sentences', 0.043), ('categorized', 0.04), ('summarization', 0.04), ('feature', 0.039), ('ascend', 0.038), ('captions', 0.038), ('dpm', 0.038), ('floor', 0.038), ('sudo', 0.038), ('stevenson', 0.038), ('categorize', 0.035), ('berg', 0.035), ('paris', 0.033), ('date', 0.033), ('categories', 0.033), ('restaurant', 0.032), ('scene', 0.031), ('describing', 0.031), ('year', 0.031), ('score', 0.03), ('reached', 0.03), ('indirect', 0.029), ('altitude', 0.029), ('arch', 0.029), ('ecole', 0.029), ('jules', 0.029), ('kurtic', 0.029), ('militaire', 0.029), ('mori', 0.029), ('nobata', 0.029), ('purves', 0.029), ('railway', 0.029), ('satoh', 0.029), ('shop', 0.029), ('slmd', 0.029), ('stairs', 0.029), ('verne', 0.029), ('world', 0.029), ('automated', 0.029), ('biased', 0.027), ('location', 0.027), ('visited', 0.026), ('visiting', 0.026), ('document', 0.026), ('located', 0.026), ('conceptual', 0.025), ('rivers', 0.025), ('westminster', 0.025), ('tour', 0.025), ('churches', 0.025), ('entrance', 0.025), ('freitas', 0.025), ('greenwood', 0.025), ('yangarber', 0.025), ('objects', 0.025), ('extractive', 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="124-tfidf-1" href="./acl-2010-Generating_Image_Descriptions_Using_Dependency_Relational_Patterns.html">124 acl-2010-Generating Image Descriptions Using Dependency Relational Patterns</a></p>
<p>Author: Ahmet Aker ; Robert Gaizauskas</p><p>Abstract: This paper presents a novel approach to automatic captioning of geo-tagged images by summarizing multiple webdocuments that contain information related to an image’s location. The summarizer is biased by dependency pattern models towards sentences which contain features typically provided for different scene types such as those of churches, bridges, etc. Our results show that summaries biased by dependency pattern models lead to significantly higher ROUGE scores than both n-gram language models reported in previous work and also Wikipedia baseline summaries. Summaries generated using dependency patterns also lead to more readable summaries than those generated without dependency patterns.</p><p>2 0.27514613 <a title="124-tfidf-2" href="./acl-2010-How_Many_Words_Is_a_Picture_Worth%3F_Automatic_Caption_Generation_for_News_Images.html">136 acl-2010-How Many Words Is a Picture Worth? Automatic Caption Generation for News Images</a></p>
<p>Author: Yansong Feng ; Mirella Lapata</p><p>Abstract: In this paper we tackle the problem of automatic caption generation for news images. Our approach leverages the vast resource of pictures available on the web and the fact that many of them are captioned. Inspired by recent work in summarization, we propose extractive and abstractive caption generation models. They both operate over the output of a probabilistic image annotation model that preprocesses the pictures and suggests keywords to describe their content. Experimental results show that an abstractive model defined over phrases is superior to extractive methods.</p><p>3 0.2050204 <a title="124-tfidf-3" href="./acl-2010-Automatic_Evaluation_of_Linguistic_Quality_in_Multi-Document_Summarization.html">38 acl-2010-Automatic Evaluation of Linguistic Quality in Multi-Document Summarization</a></p>
<p>Author: Emily Pitler ; Annie Louis ; Ani Nenkova</p><p>Abstract: To date, few attempts have been made to develop and validate methods for automatic evaluation of linguistic quality in text summarization. We present the first systematic assessment of several diverse classes of metrics designed to capture various aspects of well-written text. We train and test linguistic quality models on consecutive years of NIST evaluation data in order to show the generality of results. For grammaticality, the best results come from a set of syntactic features. Focus, coherence and referential clarity are best evaluated by a class of features measuring local coherence on the basis of cosine similarity between sentences, coreference informa- tion, and summarization specific features. Our best results are 90% accuracy for pairwise comparisons of competing systems over a test set of several inputs and 70% for ranking summaries of a specific input.</p><p>4 0.18788332 <a title="124-tfidf-4" href="./acl-2010-Wrapping_up_a_Summary%3A_From_Representation_to_Generation.html">264 acl-2010-Wrapping up a Summary: From Representation to Generation</a></p>
<p>Author: Josef Steinberger ; Marco Turchi ; Mijail Kabadjov ; Ralf Steinberger ; Nello Cristianini</p><p>Abstract: The main focus of this work is to investigate robust ways for generating summaries from summary representations without recurring to simple sentence extraction and aiming at more human-like summaries. This is motivated by empirical evidence from TAC 2009 data showing that human summaries contain on average more and shorter sentences than the system summaries. We report encouraging preliminary results comparable to those attained by participating systems at TAC 2009.</p><p>5 0.18276834 <a title="124-tfidf-5" href="./acl-2010-Optimizing_Informativeness_and_Readability_for_Sentiment_Summarization.html">188 acl-2010-Optimizing Informativeness and Readability for Sentiment Summarization</a></p>
<p>Author: Hitoshi Nishikawa ; Takaaki Hasegawa ; Yoshihiro Matsuo ; Genichiro Kikui</p><p>Abstract: We propose a novel algorithm for sentiment summarization that takes account of informativeness and readability, simultaneously. Our algorithm generates a summary by selecting and ordering sentences taken from multiple review texts according to two scores that represent the informativeness and readability of the sentence order. The informativeness score is defined by the number of sentiment expressions and the readability score is learned from the target corpus. We evaluate our method by summarizing reviews on restaurants. Our method outperforms an existing algorithm as indicated by its ROUGE score and human readability experiments.</p><p>6 0.16964795 <a title="124-tfidf-6" href="./acl-2010-Generating_Templates_of_Entity_Summaries_with_an_Entity-Aspect_Model_and_Pattern_Mining.html">125 acl-2010-Generating Templates of Entity Summaries with an Entity-Aspect Model and Pattern Mining</a></p>
<p>7 0.16084477 <a title="124-tfidf-7" href="./acl-2010-Cross-Language_Document_Summarization_Based_on_Machine_Translation_Quality_Prediction.html">77 acl-2010-Cross-Language Document Summarization Based on Machine Translation Quality Prediction</a></p>
<p>8 0.14517522 <a title="124-tfidf-8" href="./acl-2010-A_Hybrid_Hierarchical_Model_for_Multi-Document_Summarization.html">8 acl-2010-A Hybrid Hierarchical Model for Multi-Document Summarization</a></p>
<p>9 0.1375386 <a title="124-tfidf-9" href="./acl-2010-A_New_Approach_to_Improving_Multilingual_Summarization_Using_a_Genetic_Algorithm.html">11 acl-2010-A New Approach to Improving Multilingual Summarization Using a Genetic Algorithm</a></p>
<p>10 0.12681915 <a title="124-tfidf-10" href="./acl-2010-A_Risk_Minimization_Framework_for_Extractive_Speech_Summarization.html">14 acl-2010-A Risk Minimization Framework for Extractive Speech Summarization</a></p>
<p>11 0.095351569 <a title="124-tfidf-11" href="./acl-2010-Automatic_Generation_of_Story_Highlights.html">39 acl-2010-Automatic Generation of Story Highlights</a></p>
<p>12 0.090273321 <a title="124-tfidf-12" href="./acl-2010-Extraction_and_Approximation_of_Numerical_Attributes_from_the_Web.html">113 acl-2010-Extraction and Approximation of Numerical Attributes from the Web</a></p>
<p>13 0.089543365 <a title="124-tfidf-13" href="./acl-2010-Wikipedia_as_Sense_Inventory_to_Improve_Diversity_in_Web_Search_Results.html">261 acl-2010-Wikipedia as Sense Inventory to Improve Diversity in Web Search Results</a></p>
<p>14 0.081546031 <a title="124-tfidf-14" href="./acl-2010-Generating_Fine-Grained_Reviews_of_Songs_from_Album_Reviews.html">122 acl-2010-Generating Fine-Grained Reviews of Songs from Album Reviews</a></p>
<p>15 0.076071657 <a title="124-tfidf-15" href="./acl-2010-Metadata-Aware_Measures_for_Answer_Summarization_in_Community_Question_Answering.html">171 acl-2010-Metadata-Aware Measures for Answer Summarization in Community Question Answering</a></p>
<p>16 0.074917912 <a title="124-tfidf-16" href="./acl-2010-Learning_Word-Class_Lattices_for_Definition_and_Hypernym_Extraction.html">166 acl-2010-Learning Word-Class Lattices for Definition and Hypernym Extraction</a></p>
<p>17 0.069865644 <a title="124-tfidf-17" href="./acl-2010-Dependency_Parsing_and_Projection_Based_on_Word-Pair_Classification.html">83 acl-2010-Dependency Parsing and Projection Based on Word-Pair Classification</a></p>
<p>18 0.065497436 <a title="124-tfidf-18" href="./acl-2010-Importance_of_Linguistic_Constraints_in_Statistical_Dependency_Parsing.html">143 acl-2010-Importance of Linguistic Constraints in Statistical Dependency Parsing</a></p>
<p>19 0.06483268 <a title="124-tfidf-19" href="./acl-2010-Open_Information_Extraction_Using_Wikipedia.html">185 acl-2010-Open Information Extraction Using Wikipedia</a></p>
<p>20 0.063755862 <a title="124-tfidf-20" href="./acl-2010-Better_Filtration_and_Augmentation_for_Hierarchical_Phrase-Based_Translation_Rules.html">48 acl-2010-Better Filtration and Augmentation for Hierarchical Phrase-Based Translation Rules</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.182), (1, 0.074), (2, -0.121), (3, 0.007), (4, 0.016), (5, -0.024), (6, 0.079), (7, -0.338), (8, -0.078), (9, 0.028), (10, -0.032), (11, -0.074), (12, -0.174), (13, 0.088), (14, 0.068), (15, -0.032), (16, 0.022), (17, 0.13), (18, 0.021), (19, 0.061), (20, 0.028), (21, 0.054), (22, -0.009), (23, 0.005), (24, 0.035), (25, 0.028), (26, -0.052), (27, -0.039), (28, -0.026), (29, -0.066), (30, -0.02), (31, 0.042), (32, -0.004), (33, -0.04), (34, 0.007), (35, -0.071), (36, 0.058), (37, 0.01), (38, 0.17), (39, 0.036), (40, -0.058), (41, 0.198), (42, -0.015), (43, 0.105), (44, -0.127), (45, 0.036), (46, -0.008), (47, -0.178), (48, 0.01), (49, 0.007)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93727386 <a title="124-lsi-1" href="./acl-2010-Generating_Image_Descriptions_Using_Dependency_Relational_Patterns.html">124 acl-2010-Generating Image Descriptions Using Dependency Relational Patterns</a></p>
<p>Author: Ahmet Aker ; Robert Gaizauskas</p><p>Abstract: This paper presents a novel approach to automatic captioning of geo-tagged images by summarizing multiple webdocuments that contain information related to an image’s location. The summarizer is biased by dependency pattern models towards sentences which contain features typically provided for different scene types such as those of churches, bridges, etc. Our results show that summaries biased by dependency pattern models lead to significantly higher ROUGE scores than both n-gram language models reported in previous work and also Wikipedia baseline summaries. Summaries generated using dependency patterns also lead to more readable summaries than those generated without dependency patterns.</p><p>2 0.70071739 <a title="124-lsi-2" href="./acl-2010-How_Many_Words_Is_a_Picture_Worth%3F_Automatic_Caption_Generation_for_News_Images.html">136 acl-2010-How Many Words Is a Picture Worth? Automatic Caption Generation for News Images</a></p>
<p>Author: Yansong Feng ; Mirella Lapata</p><p>Abstract: In this paper we tackle the problem of automatic caption generation for news images. Our approach leverages the vast resource of pictures available on the web and the fact that many of them are captioned. Inspired by recent work in summarization, we propose extractive and abstractive caption generation models. They both operate over the output of a probabilistic image annotation model that preprocesses the pictures and suggests keywords to describe their content. Experimental results show that an abstractive model defined over phrases is superior to extractive methods.</p><p>3 0.68127435 <a title="124-lsi-3" href="./acl-2010-Generating_Templates_of_Entity_Summaries_with_an_Entity-Aspect_Model_and_Pattern_Mining.html">125 acl-2010-Generating Templates of Entity Summaries with an Entity-Aspect Model and Pattern Mining</a></p>
<p>Author: Peng Li ; Jing Jiang ; Yinglin Wang</p><p>Abstract: In this paper, we propose a novel approach to automatic generation of summary templates from given collections of summary articles. This kind of summary templates can be useful in various applications. We first develop an entity-aspect LDA model to simultaneously cluster both sentences and words into aspects. We then apply frequent subtree pattern mining on the dependency parse trees of the clustered and labeled sentences to discover sentence patterns that well represent the aspects. Key features of our method include automatic grouping of semantically related sentence patterns and automatic identification of template slots that need to be filled in. We apply our method on five Wikipedia entity categories and compare our method with two baseline methods. Both quantitative evaluation based on human judgment and qualitative comparison demonstrate the effectiveness and advantages of our method.</p><p>4 0.60354775 <a title="124-lsi-4" href="./acl-2010-Automatic_Evaluation_of_Linguistic_Quality_in_Multi-Document_Summarization.html">38 acl-2010-Automatic Evaluation of Linguistic Quality in Multi-Document Summarization</a></p>
<p>Author: Emily Pitler ; Annie Louis ; Ani Nenkova</p><p>Abstract: To date, few attempts have been made to develop and validate methods for automatic evaluation of linguistic quality in text summarization. We present the first systematic assessment of several diverse classes of metrics designed to capture various aspects of well-written text. We train and test linguistic quality models on consecutive years of NIST evaluation data in order to show the generality of results. For grammaticality, the best results come from a set of syntactic features. Focus, coherence and referential clarity are best evaluated by a class of features measuring local coherence on the basis of cosine similarity between sentences, coreference informa- tion, and summarization specific features. Our best results are 90% accuracy for pairwise comparisons of competing systems over a test set of several inputs and 70% for ranking summaries of a specific input.</p><p>5 0.60142595 <a title="124-lsi-5" href="./acl-2010-Wrapping_up_a_Summary%3A_From_Representation_to_Generation.html">264 acl-2010-Wrapping up a Summary: From Representation to Generation</a></p>
<p>Author: Josef Steinberger ; Marco Turchi ; Mijail Kabadjov ; Ralf Steinberger ; Nello Cristianini</p><p>Abstract: The main focus of this work is to investigate robust ways for generating summaries from summary representations without recurring to simple sentence extraction and aiming at more human-like summaries. This is motivated by empirical evidence from TAC 2009 data showing that human summaries contain on average more and shorter sentences than the system summaries. We report encouraging preliminary results comparable to those attained by participating systems at TAC 2009.</p><p>6 0.58320481 <a title="124-lsi-6" href="./acl-2010-A_Hybrid_Hierarchical_Model_for_Multi-Document_Summarization.html">8 acl-2010-A Hybrid Hierarchical Model for Multi-Document Summarization</a></p>
<p>7 0.5653879 <a title="124-lsi-7" href="./acl-2010-Optimizing_Informativeness_and_Readability_for_Sentiment_Summarization.html">188 acl-2010-Optimizing Informativeness and Readability for Sentiment Summarization</a></p>
<p>8 0.55765444 <a title="124-lsi-8" href="./acl-2010-Generating_Fine-Grained_Reviews_of_Songs_from_Album_Reviews.html">122 acl-2010-Generating Fine-Grained Reviews of Songs from Album Reviews</a></p>
<p>9 0.50391304 <a title="124-lsi-9" href="./acl-2010-A_Risk_Minimization_Framework_for_Extractive_Speech_Summarization.html">14 acl-2010-A Risk Minimization Framework for Extractive Speech Summarization</a></p>
<p>10 0.46447024 <a title="124-lsi-10" href="./acl-2010-Cross-Language_Document_Summarization_Based_on_Machine_Translation_Quality_Prediction.html">77 acl-2010-Cross-Language Document Summarization Based on Machine Translation Quality Prediction</a></p>
<p>11 0.45549601 <a title="124-lsi-11" href="./acl-2010-Learning_Word-Class_Lattices_for_Definition_and_Hypernym_Extraction.html">166 acl-2010-Learning Word-Class Lattices for Definition and Hypernym Extraction</a></p>
<p>12 0.45166329 <a title="124-lsi-12" href="./acl-2010-A_New_Approach_to_Improving_Multilingual_Summarization_Using_a_Genetic_Algorithm.html">11 acl-2010-A New Approach to Improving Multilingual Summarization Using a Genetic Algorithm</a></p>
<p>13 0.42989573 <a title="124-lsi-13" href="./acl-2010-Automatic_Generation_of_Story_Highlights.html">39 acl-2010-Automatic Generation of Story Highlights</a></p>
<p>14 0.39425302 <a title="124-lsi-14" href="./acl-2010-Last_but_Definitely_Not_Least%3A_On_the_Role_of_the_Last_Sentence_in_Automatic_Polarity-Classification.html">157 acl-2010-Last but Definitely Not Least: On the Role of the Last Sentence in Automatic Polarity-Classification</a></p>
<p>15 0.36117706 <a title="124-lsi-15" href="./acl-2010-Open_Information_Extraction_Using_Wikipedia.html">185 acl-2010-Open Information Extraction Using Wikipedia</a></p>
<p>16 0.35594609 <a title="124-lsi-16" href="./acl-2010-Identifying_Non-Explicit_Citing_Sentences_for_Citation-Based_Summarization..html">140 acl-2010-Identifying Non-Explicit Citing Sentences for Citation-Based Summarization.</a></p>
<p>17 0.34540406 <a title="124-lsi-17" href="./acl-2010-Complexity_Assumptions_in_Ontology_Verbalisation.html">64 acl-2010-Complexity Assumptions in Ontology Verbalisation</a></p>
<p>18 0.34232751 <a title="124-lsi-18" href="./acl-2010-Extraction_and_Approximation_of_Numerical_Attributes_from_the_Web.html">113 acl-2010-Extraction and Approximation of Numerical Attributes from the Web</a></p>
<p>19 0.33583945 <a title="124-lsi-19" href="./acl-2010-Hunting_for_the_Black_Swan%3A_Risk_Mining_from_Text.html">138 acl-2010-Hunting for the Black Swan: Risk Mining from Text</a></p>
<p>20 0.32766789 <a title="124-lsi-20" href="./acl-2010-Comparable_Entity_Mining_from_Comparative_Questions.html">63 acl-2010-Comparable Entity Mining from Comparative Questions</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(25, 0.053), (33, 0.012), (39, 0.01), (42, 0.024), (44, 0.021), (59, 0.093), (61, 0.278), (72, 0.014), (73, 0.031), (76, 0.02), (78, 0.016), (80, 0.011), (83, 0.114), (84, 0.044), (98, 0.153)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.77643692 <a title="124-lda-1" href="./acl-2010-Generating_Entailment_Rules_from_FrameNet.html">121 acl-2010-Generating Entailment Rules from FrameNet</a></p>
<p>Author: Roni Ben Aharon ; Idan Szpektor ; Ido Dagan</p><p>Abstract: Idan Szpektor Ido Dagan Yahoo! Research Department of Computer Science Haifa, Israel Bar-Ilan University idan @ yahoo- inc .com Ramat Gan, Israel dagan @ c s .biu . ac . i l FrameNet is a manually constructed database based on Frame Semantics. It models the semantic Many NLP tasks need accurate knowledge for semantic inference. To this end, mostly WordNet is utilized. Yet WordNet is limited, especially for inference be- tween predicates. To help filling this gap, we present an algorithm that generates inference rules between predicates from FrameNet. Our experiment shows that the novel resource is effective and complements WordNet in terms of rule coverage.</p><p>same-paper 2 0.77595186 <a title="124-lda-2" href="./acl-2010-Generating_Image_Descriptions_Using_Dependency_Relational_Patterns.html">124 acl-2010-Generating Image Descriptions Using Dependency Relational Patterns</a></p>
<p>Author: Ahmet Aker ; Robert Gaizauskas</p><p>Abstract: This paper presents a novel approach to automatic captioning of geo-tagged images by summarizing multiple webdocuments that contain information related to an image’s location. The summarizer is biased by dependency pattern models towards sentences which contain features typically provided for different scene types such as those of churches, bridges, etc. Our results show that summaries biased by dependency pattern models lead to significantly higher ROUGE scores than both n-gram language models reported in previous work and also Wikipedia baseline summaries. Summaries generated using dependency patterns also lead to more readable summaries than those generated without dependency patterns.</p><p>3 0.69506872 <a title="124-lda-3" href="./acl-2010-Improving_Chinese_Semantic_Role_Labeling_with_Rich_Syntactic_Features.html">146 acl-2010-Improving Chinese Semantic Role Labeling with Rich Syntactic Features</a></p>
<p>Author: Weiwei Sun</p><p>Abstract: Developing features has been shown crucial to advancing the state-of-the-art in Semantic Role Labeling (SRL). To improve Chinese SRL, we propose a set of additional features, some of which are designed to better capture structural information. Our system achieves 93.49 Fmeasure, a significant improvement over the best reported performance 92.0. We are further concerned with the effect of parsing in Chinese SRL. We empirically analyze the two-fold effect, grouping words into constituents and providing syntactic information. We also give some preliminary linguistic explanations.</p><p>4 0.61290443 <a title="124-lda-4" href="./acl-2010-Hierarchical_Search_for_Word_Alignment.html">133 acl-2010-Hierarchical Search for Word Alignment</a></p>
<p>Author: Jason Riesa ; Daniel Marcu</p><p>Abstract: We present a simple yet powerful hierarchical search algorithm for automatic word alignment. Our algorithm induces a forest of alignments from which we can efficiently extract a ranked k-best list. We score a given alignment within the forest with a flexible, linear discriminative model incorporating hundreds of features, and trained on a relatively small amount of annotated data. We report results on Arabic-English word alignment and translation tasks. Our model outperforms a GIZA++ Model-4 baseline by 6.3 points in F-measure, yielding a 1.1 BLEU score increase over a state-of-the-art syntax-based machine translation system.</p><p>5 0.61280537 <a title="124-lda-5" href="./acl-2010-Simple%2C_Accurate_Parsing_with_an_All-Fragments_Grammar.html">211 acl-2010-Simple, Accurate Parsing with an All-Fragments Grammar</a></p>
<p>Author: Mohit Bansal ; Dan Klein</p><p>Abstract: We present a simple but accurate parser which exploits both large tree fragments and symbol refinement. We parse with all fragments of the training set, in contrast to much recent work on tree selection in data-oriented parsing and treesubstitution grammar learning. We require only simple, deterministic grammar symbol refinement, in contrast to recent work on latent symbol refinement. Moreover, our parser requires no explicit lexicon machinery, instead parsing input sentences as character streams. Despite its simplicity, our parser achieves accuracies of over 88% F1 on the standard English WSJ task, which is competitive with substantially more complicated state-of-theart lexicalized and latent-variable parsers. Additional specific contributions center on making implicit all-fragments parsing efficient, including a coarse-to-fine inference scheme and a new graph encoding.</p><p>6 0.61234546 <a title="124-lda-6" href="./acl-2010-Bilingual_Sense_Similarity_for_Statistical_Machine_Translation.html">51 acl-2010-Bilingual Sense Similarity for Statistical Machine Translation</a></p>
<p>7 0.61153114 <a title="124-lda-7" href="./acl-2010-Automatic_Generation_of_Story_Highlights.html">39 acl-2010-Automatic Generation of Story Highlights</a></p>
<p>8 0.61092019 <a title="124-lda-8" href="./acl-2010-Experiments_in_Graph-Based_Semi-Supervised_Learning_Methods_for_Class-Instance_Acquisition.html">109 acl-2010-Experiments in Graph-Based Semi-Supervised Learning Methods for Class-Instance Acquisition</a></p>
<p>9 0.61040366 <a title="124-lda-9" href="./acl-2010-How_Many_Words_Is_a_Picture_Worth%3F_Automatic_Caption_Generation_for_News_Images.html">136 acl-2010-How Many Words Is a Picture Worth? Automatic Caption Generation for News Images</a></p>
<p>10 0.60994017 <a title="124-lda-10" href="./acl-2010-Open-Domain_Semantic_Role_Labeling_by_Modeling_Word_Spans.html">184 acl-2010-Open-Domain Semantic Role Labeling by Modeling Word Spans</a></p>
<p>11 0.60983366 <a title="124-lda-11" href="./acl-2010-Phylogenetic_Grammar_Induction.html">195 acl-2010-Phylogenetic Grammar Induction</a></p>
<p>12 0.60936165 <a title="124-lda-12" href="./acl-2010-Structural_Semantic_Relatedness%3A_A_Knowledge-Based_Method_to_Named_Entity_Disambiguation.html">218 acl-2010-Structural Semantic Relatedness: A Knowledge-Based Method to Named Entity Disambiguation</a></p>
<p>13 0.60935163 <a title="124-lda-13" href="./acl-2010-Bootstrapping_Semantic_Analyzers_from_Non-Contradictory_Texts.html">55 acl-2010-Bootstrapping Semantic Analyzers from Non-Contradictory Texts</a></p>
<p>14 0.60847592 <a title="124-lda-14" href="./acl-2010-Understanding_the_Semantic_Structure_of_Noun_Phrase_Queries.html">245 acl-2010-Understanding the Semantic Structure of Noun Phrase Queries</a></p>
<p>15 0.60799354 <a title="124-lda-15" href="./acl-2010-Joint_Syntactic_and_Semantic_Parsing_of_Chinese.html">153 acl-2010-Joint Syntactic and Semantic Parsing of Chinese</a></p>
<p>16 0.60744655 <a title="124-lda-16" href="./acl-2010-Error_Detection_for_Statistical_Machine_Translation_Using_Linguistic_Features.html">102 acl-2010-Error Detection for Statistical Machine Translation Using Linguistic Features</a></p>
<p>17 0.6074332 <a title="124-lda-17" href="./acl-2010-Wikipedia_as_Sense_Inventory_to_Improve_Diversity_in_Web_Search_Results.html">261 acl-2010-Wikipedia as Sense Inventory to Improve Diversity in Web Search Results</a></p>
<p>18 0.60723889 <a title="124-lda-18" href="./acl-2010-Dynamic_Programming_for_Linear-Time_Incremental_Parsing.html">93 acl-2010-Dynamic Programming for Linear-Time Incremental Parsing</a></p>
<p>19 0.6065619 <a title="124-lda-19" href="./acl-2010-Improving_Arabic-to-English_Statistical_Machine_Translation_by_Reordering_Post-Verbal_Subjects_for_Alignment.html">145 acl-2010-Improving Arabic-to-English Statistical Machine Translation by Reordering Post-Verbal Subjects for Alignment</a></p>
<p>20 0.60654438 <a title="124-lda-20" href="./acl-2010-Entity-Based_Local_Coherence_Modelling_Using_Topological_Fields.html">101 acl-2010-Entity-Based Local Coherence Modelling Using Topological Fields</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
