<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>77 acl-2010-Cross-Language Document Summarization Based on Machine Translation Quality Prediction</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-77" href="#">acl2010-77</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>77 acl-2010-Cross-Language Document Summarization Based on Machine Translation Quality Prediction</h1>
<br/><p>Source: <a title="acl-2010-77-pdf" href="http://aclweb.org/anthology//P/P10/P10-1094.pdf">pdf</a></p><p>Author: Xiaojun Wan ; Huiying Li ; Jianguo Xiao</p><p>Abstract: Cross-language document summarization is a task of producing a summary in one language for a document set in a different language. Existing methods simply use machine translation for document translation or summary translation. However, current machine translation services are far from satisfactory, which results in that the quality of the cross-language summary is usually very poor, both in readability and content. In this paper, we propose to consider the translation quality of each sentence in the English-to-Chinese cross-language summarization process. First, the translation quality of each English sentence in the document set is predicted with the SVM regression method, and then the quality score of each sentence is incorporated into the summarization process. Finally, the English sentences with high translation quality and high informativeness are selected and translated to form the Chinese summary. Experimental results demonstrate the effectiveness and usefulness of the proposed approach. 1</p><p>Reference: <a title="acl-2010-77-reference" href="../acl2010_reference/acl-2010-Cross-Language_Document_Summarization_Based_on_Machine_Translation_Quality_Prediction_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 cn cs  Abstract Cross-language document summarization is a task of producing a summary in one language for a document set in a different language. [sent-4, score-1.165]
</p><p>2 Existing methods simply use machine translation for document translation or summary translation. [sent-5, score-0.978]
</p><p>3 However, current machine translation services are far from satisfactory, which results in that the quality of the cross-language summary is usually very poor, both in readability and content. [sent-6, score-0.749]
</p><p>4 In this paper, we propose to consider the translation quality of each sentence in the English-to-Chinese cross-language summarization process. [sent-7, score-0.83]
</p><p>5 First, the translation quality of each English sentence in the document set is predicted with the SVM regression method, and then the quality score of each sentence is incorporated into the summarization process. [sent-8, score-1.617]
</p><p>6 Finally, the English sentences with high translation quality and high informativeness are selected and translated to form the  Chinese summary. [sent-9, score-0.73]
</p><p>7 1  Introduction  Given a document or document set in one source language, cross-language document summarization aims to produce a summary in a different target language. [sent-11, score-1.413]
</p><p>8 In this study, we focus on English-to-Chinese document summarization for the purpose of helping Chinese readers to quickly understand the major content of an English document or document set. [sent-12, score-1.083]
</p><p>9 Till now, most previous work focuses on monolingual document summarization, but cross-language document summarization has received little attention in the past years. [sent-14, score-0.835]
</p><p>10 A straightforward way for cross-language document summarization is to translate the summary from the source language to the target language by using machine translation services. [sent-15, score-1.176]
</p><p>11 However, though machine translation techniques have been  advanced a lot, the machine translation quality is far from satisfactory, and in many cases, the translated texts are hard to understand. [sent-16, score-0.734]
</p><p>12 Therefore, the translated summary is likely to be hard to understand by readers, i. [sent-17, score-0.502]
</p><p>13 For example, the translated Chinese sentence for an ordinary English sentence (“It is also Mr Baker who is making the most of presidential powers to dispense largesse. [sent-20, score-0.43]
</p><p>14 If such sentences are selected into the summary, the quality of the summary would be very poor. [sent-23, score-0.57]
</p><p>15 In order to address the above problem, we propose to consider the translation quality of the English sentences in the summarization process. [sent-24, score-0.779]
</p><p>16 An empirical evaluation is conducted to evaluate the performance of machine translation quality prediction, and a user study is performed to evaluate the cross-language summary quality. [sent-26, score-0.692]
</p><p>17 c As2s0o1c0ia Atisosnoc foiart Cionom fopru Ctaotmiopnuatla Lti on gaulis Lti cnsg,u piasgtiecs 917–926, results of machine translation quality prediction and cross-language summarization, respectively. [sent-32, score-0.465]
</p><p>18 1  Related Work Machine Translation Quality Prediction  Machine translation evaluation aims to assess the correctness and quality of the translation. [sent-35, score-0.362]
</p><p>19 Usu-  ally, the human reference translation is provided, and various methods and metrics have been developed for comparing the system-translated text and the human reference text. [sent-36, score-0.373]
</p><p>20 Quirk (2004) presents a supervised method for training a sentence level confidence measure on translation output using a human-annotated corpus. [sent-42, score-0.329]
</p><p>21 In this study, we further predict the translation quality of an English sentence before the machine translation process, i. [sent-52, score-0.691]
</p><p>22 2  Document Summarization  Document summarization methods can be generally categorized into extraction-based methods and abstraction-based methods. [sent-56, score-0.339]
</p><p>23 Extractionbased summarization methods usually assign each sentence a saliency score and then rank the sentences in a document or document set. [sent-58, score-1.143]
</p><p>24 For single document summarization, the sentence score is usually computed by empirical  combination of a number of statistical and linguistic feature values, such as term frequency, sentence position, cue words, stigma words, topic signature (Luhn 1969; Lin and Hovy, 2000). [sent-59, score-0.607]
</p><p>25 The summary sentences can also be selected by using machine learning methods (Kupiec et al. [sent-60, score-0.408]
</p><p>26 The influences of input difficulty on summarization performance have been investigated in (Nenkova and Louis, 2008). [sent-69, score-0.339]
</p><p>27 Graph-based methods have also been used to rank sentences in a document set. [sent-70, score-0.326]
</p><p>28 For example, Mihalcea and Tarau  (2005) extend the TextRank algorithm to compute sentence importance in a document set. [sent-71, score-0.377]
</p><p>29 Topic-focused or query biased multi-document summarization has also been investigated (Wan et al. [sent-73, score-0.339]
</p><p>30 Several pilot studies have been performed for the cross-language summarization task by simply using document translation or summary translation. [sent-77, score-1.117]
</p><p>31 (2004) propose to generate a Japanese summary without using a Japanese summarization system, by first translating Japanese documents into Korean documents, and then extracting summary sentences by using Korean summarizer, and finally mapping Korean summary sentences to Japanese summary sentences. [sent-81, score-1.865]
</p><p>32 Orasan  918  and Chiorean (2008) propose to produce summaries with the MMR method from Romanian news articles and then automatically translate the summaries into English. [sent-84, score-0.423]
</p><p>33 Cross language query based summarization has been investigated in (Pingali et al. [sent-85, score-0.339]
</p><p>34 Other related work includes multilingual summarization (Lin et al. [sent-87, score-0.387]
</p><p>35 Siddharthan and McKeown (2005) use the information redundancy in multilingual input to correct errors in machine translation and thus improve the quality of multilingual summaries. [sent-89, score-0.458]
</p><p>36 3  The Proposed Approach  Previous methods for cross-language summarization usually consist of two steps: one step for summarization and one step for translation. [sent-90, score-0.678]
</p><p>37 Different order of the two steps can lead to the following two basic English-to-Chinese summarization methods:  Late Translation (LateTrans): Firstly, an English summary is produced for the English document set by using existing summarization methods. [sent-91, score-1.256]
</p><p>38 Then, the English summary is automatically translated into the corresponding Chinese summary by using machine translation services. [sent-92, score-1.032]
</p><p>39 Early Translation (EarlyTrans): Firstly, the English documents are translated into Chinese documents by using machine translation services. [sent-93, score-0.472]
</p><p>40 Then, a Chinese summary is produced for the translated Chinese documents. [sent-94, score-0.502]
</p><p>41 2) The LateTrans method is deemed to be more effective than the EarlyTrans method, because the translation errors of the sentences have great influences on the summary sentence extraction in the EarlyTrans method. [sent-96, score-0.737]
</p><p>42 We also adopt the late translation strategy for our proposed approach. [sent-98, score-0.359]
</p><p>43 In the baseline method, a translated Chinese sentence is selected into the summary because the original English sentence is informative. [sent-99, score-0.76]
</p><p>44 However, an informative and fluent English sentence is likely to be translated into an uninformative and disfluent Chinese sentence, and therefore, this sentence cannot be selected into the summary. [sent-100, score-0.473]
</p><p>45 In order to address the above problem of existing methods, our proposed approach takes into account a novel factor of each sentence for crosslanguage summary extraction. [sent-101, score-0.532]
</p><p>46 Each English sentence is associated with a score indicating its translation quality. [sent-102, score-0.43]
</p><p>47 An English sentence with high translation quality score is more likely to be selected into the original English summary, and such English summary can be translated into a better Chinese summary. [sent-103, score-1.094]
</p><p>48 1  Machine Translation Quality Prediction Methodology  In this study, machine translation (MT) quality reflects both the translation accuracy and the fluency of the translated sentence. [sent-113, score-0.793]
</p><p>49 An English sentence with high MT quality score is likely to be translated into an accurate and fluent Chinese sentence, which can be easily read and understand by Chinese readers. [sent-114, score-0.611]
</p><p>50 The MT quality prediction is a task of mapping an English sentence to a numerical value corresponding to a quality level. [sent-115, score-0.556]
</p><p>51 1, several related work has used regression and classification methods for MT quality prediction without reference translations. [sent-118, score-0.403]
</p><p>52 In our approach, the MT quality of each sentence in the documents is also predicted without reference translations. [sent-119, score-0.478]
</p><p>53 In this study, we adopt the ε-support vector regression (ε-SVR) method (Vapnik 1995) for the sentence-level MT quality prediction task. [sent-121, score-0.39]
</p><p>54 At this step, each English sentence si can be associated with a MT quality score TransScore(si) predicted by the ε-SVR method. [sent-150, score-0.601]
</p><p>55 1  Evaluation Evaluation Setup  In the experiments, we first constructed the goldstandard dataset in the following way: DUC2001 provided 309 English news articles for document summarization tasks, and the articles were grouped into 30 document sets. [sent-155, score-0.949]
</p><p>56 We chose five document sets (d04, d05, d06, d08,  d11) with 54 news articles out of the DUC2001 document sets. [sent-157, score-0.496]
</p><p>57 All the sentences were automatically translated into Chinese sentences by using the Google Translate service. [sent-159, score-0.328]
</p><p>58 They read the original English sentence and the translated Chinese sentence, and then manually labeled the overall translation quality score for each sentence, separately. [sent-161, score-0.848]
</p><p>59 The translation quality is an overall measure for both the translation accuracy and the readability of the translated sentence. [sent-162, score-0.828]
</p><p>60 The final translation quality score was the average of the scores provided by the two annotators. [sent-166, score-0.568]
</p><p>61 The results guarantee that the use of MT quality scores in the summarization process is feasible. [sent-185, score-0.569]
</p><p>62 The sentences close to the centroid of the document set are usually more important than the sentences farther away. [sent-197, score-0.404]
</p><p>63 And the centroid weight C(si) of a sentence si is calculated as the cosine similarity between the sentence text and the concatenated text for the whole document set D. [sent-198, score-0.642]
</p><p>64 The leading several sentences of a document are usually important. [sent-201, score-0.326]
</p><p>65 So  we calculate for each sentence a weight to reflect its position priority as P(si)=1-(i-1)/n, where iis the sequence of the sentence si and n is the total number of sentences in the document. [sent-202, score-0.472]
</p><p>66 Because the first sentence of a document is very important, a sentence similar to the first sentence is also important. [sent-205, score-0.635]
</p><p>67 Thus we use the cosine similarity value between a sentence and the corresponding first sentence in the same document as the weight F(si) for sentence si. [sent-206, score-0.635]
</p><p>68 After the informativeness scores for all sentences are computed, the score of each sentence is normalized by dividing by the maximum score. [sent-209, score-0.533]
</p><p>69 After we obtain the MT quality score and the informativeness score of each sentence in the document set, we linearly combine the two ⋅  ⋅  ⋅  scores to get the overall score of each sentence. [sent-210, score-1.065]
</p><p>70 Finally, the sentences in the English summary are translated into the corresponding Chinese sentences by using Google Translate, and the Chinese summary is formed. [sent-212, score-0.988]
</p><p>71 1, DUC2001 provided 30 English document sets for generic multidocument summarization. [sent-219, score-0.325]
</p><p>72 The average document number per document set was 10. [sent-220, score-0.496]
</p><p>73 In our study, we aimed to produce Chinese summaries for the English document sets. [sent-223, score-0.43]
</p><p>74 The summary length was limited to five sentences, i. [sent-224, score-0.33]
</p><p>75 The DUC2001 dataset was divided into the following two datasets: Ideal Dataset: We have manually labeled the MT quality scores for the sentences in five document sets (d04-d1 1), and we directly used the manually labeled scores in the summarization process. [sent-227, score-1.04]
</p><p>76 Real Dataset: The MT quality scores for the sentences in the remaining 25 document sets were automatically predicted by using the learned SVM regression model. [sent-229, score-0.703]
</p><p>77 And we used the automatically predicted scores in the summarization process. [sent-230, score-0.48]
</p><p>78 If λ is set to 0, the summary is extracted without considering the MT quality factor. [sent-233, score-0.492]
</p><p>79 To date, various methods and metrics have been developed for English summary evaluation by comparing system summary with reference summary, such as the pyramid method (Nenkova et al. [sent-238, score-0.769]
</p><p>80 However, such methods or metrics cannot be directly used for evaluating Chinese summary without reference Chinese summary. [sent-240, score-0.439]
</p><p>81 We have developed a friendly tool for helping the subjects to evaluate each Chinese summary from the following three aspects: Content: This aspect indicates how much a summary reflects the major content of the document set. [sent-243, score-0.943]
</p><p>82 And the two summaries produced by the two systems for the same document set were presented in the same interface, and then the four subjects assigned scores to each summary after they read and compared the two summaries. [sent-255, score-0.91]
</p><p>83 2  Evaluation Results  Table 2 shows the evaluation results on the ideal dataset with 5 document sets. [sent-259, score-0.396]
</p><p>84 We can see that based on the manually labeled MT quality scores, the Chinese summaries produced by our proposed approach are significantly better than that produced by the baseline approach over all three aspects. [sent-260, score-0.381]
</p><p>85 Table 3 shows the evaluation results on the real dataset with 25 document sets. [sent-262, score-0.368]
</p><p>86 We can see that based on the automatically predicted MT  quality scores, the Chinese summaries produced by our proposed approach are significantly better than that produced by the baseline approach over the readability aspect and the overall aspect. [sent-263, score-0.548]
</p><p>87 Overall, the proposed approach is effective to produce good-quality Chinese summaries for English document sets. [sent-267, score-0.467]
</p><p>88 The Chinese sentences and the original English sentences in the summary are presented together. [sent-284, score-0.486]
</p><p>89 The normalized MT quality score for each sentence is also given at the end of the Chinese sentence. [sent-285, score-0.392]
</p><p>90 )  6  Discussion  In this study, we adopt the late translation strategy for cross-document summarization. [sent-334, score-0.322]
</p><p>91 As mentioned earlier, the late translation strategy has some advantages over the early translation strategy. [sent-335, score-0.471]
</p><p>92 However, in the early translation strategy, we can use the features derived from both the source English sentence and the target Chinese sentence to improve the MT quality prediction results. [sent-336, score-0.759]
</p><p>93 Overall, the framework of our proposed approach can be easily adapted for cross-document summarization with the early translation strategy. [sent-337, score-0.576]
</p><p>94 Though this study focuses on English-toChinese document summarization, crosslanguage summarization tasks for other languages can also be solved by using our proposed approach. [sent-339, score-0.66]
</p><p>95 7  Conclusion and Future Work  In this study we propose a novel approach to address the cross-language document summarization task. [sent-340, score-0.587]
</p><p>96 Our proposed approach predicts the MT quality score of each English sentence and then incorporates the score into the summarization process. [sent-341, score-0.869]
</p><p>97 In future work, we will manually translate English reference summaries into Chinese reference summaries, and then adopt the ROUGE metrics to perform automatic evaluation of the extracted Chinese summaries by comparing them with the Chinese reference summaries. [sent-343, score-0.711]
</p><p>98 Moreover, we will further improve the sentence’s MT quality by using sentence compression or sentence reduction techniques. [sent-344, score-0.42]
</p><p>99 Crosslingual summarization with thematic extraction, syntactic sentence simplification, and bilingual generation. [sent-386, score-0.468]
</p><p>100 The Pyramid method: incorporating human content  selection variation in summarization evaluation. [sent-514, score-0.339]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('summarization', 0.339), ('summary', 0.33), ('document', 0.248), ('chinese', 0.218), ('translation', 0.2), ('mt', 0.189), ('summaries', 0.182), ('translated', 0.172), ('quality', 0.162), ('earlytrans', 0.136), ('latetrans', 0.136), ('si', 0.136), ('sentence', 0.129), ('wan', 0.119), ('informativeness', 0.118), ('hurricane', 0.113), ('mse', 0.113), ('prediction', 0.103), ('score', 0.101), ('congress', 0.085), ('english', 0.085), ('sentences', 0.078), ('dataset', 0.077), ('nenkova', 0.077), ('regression', 0.074), ('predicted', 0.073), ('late', 0.071), ('ideal', 0.071), ('scores', 0.068), ('infoscore', 0.068), ('insurers', 0.068), ('transscore', 0.068), ('reference', 0.064), ('translate', 0.059), ('fluency', 0.059), ('yi', 0.057), ('readability', 0.057), ('florida', 0.055), ('perplexity', 0.055), ('dollars', 0.055), ('korean', 0.051), ('adopt', 0.051), ('parse', 0.05), ('lin', 0.05), ('documents', 0.05), ('multilingual', 0.048), ('libsvm', 0.048), ('google', 0.048), ('refers', 0.048), ('read', 0.047), ('industry', 0.046), ('government', 0.046), ('bahamas', 0.045), ('ballot', 0.045), ('chalendar', 0.045), ('citizen', 0.045), ('costliest', 0.045), ('devastated', 0.045), ('eusum', 0.045), ('inhabitants', 0.045), ('leuski', 0.045), ('louisiana', 0.045), ('officeholders', 0.045), ('outlying', 0.045), ('pingali', 0.045), ('statewide', 0.045), ('unwelcome', 0.045), ('uvbejr', 0.045), ('wtf', 0.045), ('metrics', 0.045), ('mihalcea', 0.044), ('informative', 0.043), ('real', 0.043), ('mr', 0.04), ('multidocument', 0.04), ('reinforcement', 0.04), ('tarau', 0.04), ('chae', 0.04), ('albrecht', 0.04), ('amini', 0.04), ('deaths', 0.04), ('disaster', 0.04), ('orasan', 0.04), ('peking', 0.04), ('spokesman', 0.04), ('dividing', 0.039), ('overall', 0.037), ('provided', 0.037), ('said', 0.037), ('proposed', 0.037), ('deviations', 0.036), ('textrank', 0.036), ('eastern', 0.036), ('pounds', 0.036), ('lengthy', 0.036), ('crosslanguage', 0.036), ('curry', 0.036), ('features', 0.036), ('subjects', 0.035), ('radev', 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="77-tfidf-1" href="./acl-2010-Cross-Language_Document_Summarization_Based_on_Machine_Translation_Quality_Prediction.html">77 acl-2010-Cross-Language Document Summarization Based on Machine Translation Quality Prediction</a></p>
<p>Author: Xiaojun Wan ; Huiying Li ; Jianguo Xiao</p><p>Abstract: Cross-language document summarization is a task of producing a summary in one language for a document set in a different language. Existing methods simply use machine translation for document translation or summary translation. However, current machine translation services are far from satisfactory, which results in that the quality of the cross-language summary is usually very poor, both in readability and content. In this paper, we propose to consider the translation quality of each sentence in the English-to-Chinese cross-language summarization process. First, the translation quality of each English sentence in the document set is predicted with the SVM regression method, and then the quality score of each sentence is incorporated into the summarization process. Finally, the English sentences with high translation quality and high informativeness are selected and translated to form the Chinese summary. Experimental results demonstrate the effectiveness and usefulness of the proposed approach. 1</p><p>2 0.36868665 <a title="77-tfidf-2" href="./acl-2010-A_Risk_Minimization_Framework_for_Extractive_Speech_Summarization.html">14 acl-2010-A Risk Minimization Framework for Extractive Speech Summarization</a></p>
<p>Author: Shih-Hsiang Lin ; Berlin Chen</p><p>Abstract: In this paper, we formulate extractive summarization as a risk minimization problem and propose a unified probabilistic framework that naturally combines supervised and unsupervised summarization models to inherit their individual merits as well as to overcome their inherent limitations. In addition, the introduction of various loss functions also provides the summarization framework with a flexible but systematic way to render the redundancy and coherence relationships among sentences and between sentences and the whole document, respectively. Experiments on speech summarization show that the methods deduced from our framework are very competitive with existing summarization approaches. 1</p><p>3 0.28834331 <a title="77-tfidf-3" href="./acl-2010-Automatic_Evaluation_of_Linguistic_Quality_in_Multi-Document_Summarization.html">38 acl-2010-Automatic Evaluation of Linguistic Quality in Multi-Document Summarization</a></p>
<p>Author: Emily Pitler ; Annie Louis ; Ani Nenkova</p><p>Abstract: To date, few attempts have been made to develop and validate methods for automatic evaluation of linguistic quality in text summarization. We present the first systematic assessment of several diverse classes of metrics designed to capture various aspects of well-written text. We train and test linguistic quality models on consecutive years of NIST evaluation data in order to show the generality of results. For grammaticality, the best results come from a set of syntactic features. Focus, coherence and referential clarity are best evaluated by a class of features measuring local coherence on the basis of cosine similarity between sentences, coreference informa- tion, and summarization specific features. Our best results are 90% accuracy for pairwise comparisons of competing systems over a test set of several inputs and 70% for ranking summaries of a specific input.</p><p>4 0.26963827 <a title="77-tfidf-4" href="./acl-2010-Wrapping_up_a_Summary%3A_From_Representation_to_Generation.html">264 acl-2010-Wrapping up a Summary: From Representation to Generation</a></p>
<p>Author: Josef Steinberger ; Marco Turchi ; Mijail Kabadjov ; Ralf Steinberger ; Nello Cristianini</p><p>Abstract: The main focus of this work is to investigate robust ways for generating summaries from summary representations without recurring to simple sentence extraction and aiming at more human-like summaries. This is motivated by empirical evidence from TAC 2009 data showing that human summaries contain on average more and shorter sentences than the system summaries. We report encouraging preliminary results comparable to those attained by participating systems at TAC 2009.</p><p>5 0.26350412 <a title="77-tfidf-5" href="./acl-2010-A_Hybrid_Hierarchical_Model_for_Multi-Document_Summarization.html">8 acl-2010-A Hybrid Hierarchical Model for Multi-Document Summarization</a></p>
<p>Author: Asli Celikyilmaz ; Dilek Hakkani-Tur</p><p>Abstract: Scoring sentences in documents given abstract summaries created by humans is important in extractive multi-document summarization. In this paper, we formulate extractive summarization as a two step learning problem building a generative model for pattern discovery and a regression model for inference. We calculate scores for sentences in document clusters based on their latent characteristics using a hierarchical topic model. Then, using these scores, we train a regression model based on the lexical and structural characteristics of the sentences, and use the model to score sentences of new documents to form a summary. Our system advances current state-of-the-art improving ROUGE scores by ∼7%. Generated summaries are less rbeydu ∼n7d%an.t a Gnedn more dc sohuemremnatr bieasse adre upon manual quality evaluations.</p><p>6 0.24472843 <a title="77-tfidf-6" href="./acl-2010-A_New_Approach_to_Improving_Multilingual_Summarization_Using_a_Genetic_Algorithm.html">11 acl-2010-A New Approach to Improving Multilingual Summarization Using a Genetic Algorithm</a></p>
<p>7 0.23566449 <a title="77-tfidf-7" href="./acl-2010-Optimizing_Informativeness_and_Readability_for_Sentiment_Summarization.html">188 acl-2010-Optimizing Informativeness and Readability for Sentiment Summarization</a></p>
<p>8 0.19268925 <a title="77-tfidf-8" href="./acl-2010-Generating_Templates_of_Entity_Summaries_with_an_Entity-Aspect_Model_and_Pattern_Mining.html">125 acl-2010-Generating Templates of Entity Summaries with an Entity-Aspect Model and Pattern Mining</a></p>
<p>9 0.18757199 <a title="77-tfidf-9" href="./acl-2010-Automatic_Generation_of_Story_Highlights.html">39 acl-2010-Automatic Generation of Story Highlights</a></p>
<p>10 0.18754761 <a title="77-tfidf-10" href="./acl-2010-TrustRank%3A_Inducing_Trust_in_Automatic_Translations_via_Ranking.html">244 acl-2010-TrustRank: Inducing Trust in Automatic Translations via Ranking</a></p>
<p>11 0.16705586 <a title="77-tfidf-11" href="./acl-2010-Metadata-Aware_Measures_for_Answer_Summarization_in_Community_Question_Answering.html">171 acl-2010-Metadata-Aware Measures for Answer Summarization in Community Question Answering</a></p>
<p>12 0.16084477 <a title="77-tfidf-12" href="./acl-2010-Generating_Image_Descriptions_Using_Dependency_Relational_Patterns.html">124 acl-2010-Generating Image Descriptions Using Dependency Relational Patterns</a></p>
<p>13 0.13373096 <a title="77-tfidf-13" href="./acl-2010-Bridging_SMT_and_TM_with_Translation_Recommendation.html">56 acl-2010-Bridging SMT and TM with Translation Recommendation</a></p>
<p>14 0.12852809 <a title="77-tfidf-14" href="./acl-2010-Automatic_Evaluation_Method_for_Machine_Translation_Using_Noun-Phrase_Chunking.html">37 acl-2010-Automatic Evaluation Method for Machine Translation Using Noun-Phrase Chunking</a></p>
<p>15 0.11251727 <a title="77-tfidf-15" href="./acl-2010-Cross_Lingual_Adaptation%3A_An_Experiment_on_Sentiment_Classifications.html">80 acl-2010-Cross Lingual Adaptation: An Experiment on Sentiment Classifications</a></p>
<p>16 0.11225992 <a title="77-tfidf-16" href="./acl-2010-Boosting-Based_System_Combination_for_Machine_Translation.html">54 acl-2010-Boosting-Based System Combination for Machine Translation</a></p>
<p>17 0.11121817 <a title="77-tfidf-17" href="./acl-2010-Evaluating_Multilanguage-Comparability_of_Subjectivity_Analysis_Systems.html">105 acl-2010-Evaluating Multilanguage-Comparability of Subjectivity Analysis Systems</a></p>
<p>18 0.10742395 <a title="77-tfidf-18" href="./acl-2010-Generating_Fine-Grained_Reviews_of_Songs_from_Album_Reviews.html">122 acl-2010-Generating Fine-Grained Reviews of Songs from Album Reviews</a></p>
<p>19 0.099689133 <a title="77-tfidf-19" href="./acl-2010-Learning_to_Translate_with_Source_and_Target_Syntax.html">169 acl-2010-Learning to Translate with Source and Target Syntax</a></p>
<p>20 0.099214785 <a title="77-tfidf-20" href="./acl-2010-Error_Detection_for_Statistical_Machine_Translation_Using_Linguistic_Features.html">102 acl-2010-Error Detection for Statistical Machine Translation Using Linguistic Features</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.3), (1, -0.022), (2, -0.212), (3, 0.05), (4, -0.011), (5, 0.003), (6, -0.046), (7, -0.53), (8, -0.131), (9, 0.012), (10, 0.13), (11, -0.027), (12, -0.08), (13, 0.03), (14, -0.082), (15, -0.065), (16, 0.018), (17, -0.025), (18, -0.029), (19, 0.015), (20, -0.012), (21, -0.007), (22, 0.009), (23, -0.005), (24, -0.028), (25, -0.017), (26, 0.022), (27, 0.069), (28, 0.003), (29, 0.089), (30, 0.001), (31, -0.046), (32, 0.076), (33, -0.025), (34, 0.003), (35, 0.01), (36, -0.058), (37, -0.011), (38, 0.012), (39, -0.089), (40, -0.031), (41, -0.091), (42, 0.025), (43, 0.055), (44, 0.088), (45, 0.018), (46, 0.021), (47, 0.056), (48, 0.011), (49, -0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97894305 <a title="77-lsi-1" href="./acl-2010-Cross-Language_Document_Summarization_Based_on_Machine_Translation_Quality_Prediction.html">77 acl-2010-Cross-Language Document Summarization Based on Machine Translation Quality Prediction</a></p>
<p>Author: Xiaojun Wan ; Huiying Li ; Jianguo Xiao</p><p>Abstract: Cross-language document summarization is a task of producing a summary in one language for a document set in a different language. Existing methods simply use machine translation for document translation or summary translation. However, current machine translation services are far from satisfactory, which results in that the quality of the cross-language summary is usually very poor, both in readability and content. In this paper, we propose to consider the translation quality of each sentence in the English-to-Chinese cross-language summarization process. First, the translation quality of each English sentence in the document set is predicted with the SVM regression method, and then the quality score of each sentence is incorporated into the summarization process. Finally, the English sentences with high translation quality and high informativeness are selected and translated to form the Chinese summary. Experimental results demonstrate the effectiveness and usefulness of the proposed approach. 1</p><p>2 0.88161618 <a title="77-lsi-2" href="./acl-2010-Wrapping_up_a_Summary%3A_From_Representation_to_Generation.html">264 acl-2010-Wrapping up a Summary: From Representation to Generation</a></p>
<p>Author: Josef Steinberger ; Marco Turchi ; Mijail Kabadjov ; Ralf Steinberger ; Nello Cristianini</p><p>Abstract: The main focus of this work is to investigate robust ways for generating summaries from summary representations without recurring to simple sentence extraction and aiming at more human-like summaries. This is motivated by empirical evidence from TAC 2009 data showing that human summaries contain on average more and shorter sentences than the system summaries. We report encouraging preliminary results comparable to those attained by participating systems at TAC 2009.</p><p>3 0.87786138 <a title="77-lsi-3" href="./acl-2010-A_Risk_Minimization_Framework_for_Extractive_Speech_Summarization.html">14 acl-2010-A Risk Minimization Framework for Extractive Speech Summarization</a></p>
<p>Author: Shih-Hsiang Lin ; Berlin Chen</p><p>Abstract: In this paper, we formulate extractive summarization as a risk minimization problem and propose a unified probabilistic framework that naturally combines supervised and unsupervised summarization models to inherit their individual merits as well as to overcome their inherent limitations. In addition, the introduction of various loss functions also provides the summarization framework with a flexible but systematic way to render the redundancy and coherence relationships among sentences and between sentences and the whole document, respectively. Experiments on speech summarization show that the methods deduced from our framework are very competitive with existing summarization approaches. 1</p><p>4 0.8594656 <a title="77-lsi-4" href="./acl-2010-A_New_Approach_to_Improving_Multilingual_Summarization_Using_a_Genetic_Algorithm.html">11 acl-2010-A New Approach to Improving Multilingual Summarization Using a Genetic Algorithm</a></p>
<p>Author: Marina Litvak ; Mark Last ; Menahem Friedman</p><p>Abstract: Automated summarization methods can be defined as “language-independent,” if they are not based on any languagespecific knowledge. Such methods can be used for multilingual summarization defined by Mani (2001) as “processing several languages, with summary in the same language as input.” In this paper, we introduce MUSE, a languageindependent approach for extractive summarization based on the linear optimization of several sentence ranking measures using a genetic algorithm. We tested our methodology on two languages—English and Hebrew—and evaluated its performance with ROUGE-1 Recall vs. state- of-the-art extractive summarization approaches. Our results show that MUSE performs better than the best known multilingual approach (TextRank1) in both languages. Moreover, our experimental results on a bilingual (English and Hebrew) document collection suggest that MUSE does not need to be retrained on each language and the same model can be used across at least two different languages.</p><p>5 0.77681345 <a title="77-lsi-5" href="./acl-2010-A_Hybrid_Hierarchical_Model_for_Multi-Document_Summarization.html">8 acl-2010-A Hybrid Hierarchical Model for Multi-Document Summarization</a></p>
<p>Author: Asli Celikyilmaz ; Dilek Hakkani-Tur</p><p>Abstract: Scoring sentences in documents given abstract summaries created by humans is important in extractive multi-document summarization. In this paper, we formulate extractive summarization as a two step learning problem building a generative model for pattern discovery and a regression model for inference. We calculate scores for sentences in document clusters based on their latent characteristics using a hierarchical topic model. Then, using these scores, we train a regression model based on the lexical and structural characteristics of the sentences, and use the model to score sentences of new documents to form a summary. Our system advances current state-of-the-art improving ROUGE scores by ∼7%. Generated summaries are less rbeydu ∼n7d%an.t a Gnedn more dc sohuemremnatr bieasse adre upon manual quality evaluations.</p><p>6 0.7767725 <a title="77-lsi-6" href="./acl-2010-Automatic_Evaluation_of_Linguistic_Quality_in_Multi-Document_Summarization.html">38 acl-2010-Automatic Evaluation of Linguistic Quality in Multi-Document Summarization</a></p>
<p>7 0.68124598 <a title="77-lsi-7" href="./acl-2010-Automatic_Generation_of_Story_Highlights.html">39 acl-2010-Automatic Generation of Story Highlights</a></p>
<p>8 0.65398085 <a title="77-lsi-8" href="./acl-2010-Optimizing_Informativeness_and_Readability_for_Sentiment_Summarization.html">188 acl-2010-Optimizing Informativeness and Readability for Sentiment Summarization</a></p>
<p>9 0.60735255 <a title="77-lsi-9" href="./acl-2010-Identifying_Non-Explicit_Citing_Sentences_for_Citation-Based_Summarization..html">140 acl-2010-Identifying Non-Explicit Citing Sentences for Citation-Based Summarization.</a></p>
<p>10 0.58792233 <a title="77-lsi-10" href="./acl-2010-Generating_Templates_of_Entity_Summaries_with_an_Entity-Aspect_Model_and_Pattern_Mining.html">125 acl-2010-Generating Templates of Entity Summaries with an Entity-Aspect Model and Pattern Mining</a></p>
<p>11 0.58478892 <a title="77-lsi-11" href="./acl-2010-TrustRank%3A_Inducing_Trust_in_Automatic_Translations_via_Ranking.html">244 acl-2010-TrustRank: Inducing Trust in Automatic Translations via Ranking</a></p>
<p>12 0.57887238 <a title="77-lsi-12" href="./acl-2010-Generating_Image_Descriptions_Using_Dependency_Relational_Patterns.html">124 acl-2010-Generating Image Descriptions Using Dependency Relational Patterns</a></p>
<p>13 0.54882145 <a title="77-lsi-13" href="./acl-2010-Evaluating_Machine_Translations_Using_mNCD.html">104 acl-2010-Evaluating Machine Translations Using mNCD</a></p>
<p>14 0.54443812 <a title="77-lsi-14" href="./acl-2010-Generating_Fine-Grained_Reviews_of_Songs_from_Album_Reviews.html">122 acl-2010-Generating Fine-Grained Reviews of Songs from Album Reviews</a></p>
<p>15 0.52072811 <a title="77-lsi-15" href="./acl-2010-Bridging_SMT_and_TM_with_Translation_Recommendation.html">56 acl-2010-Bridging SMT and TM with Translation Recommendation</a></p>
<p>16 0.50584078 <a title="77-lsi-16" href="./acl-2010-Tackling_Sparse_Data_Issue_in_Machine_Translation_Evaluation.html">223 acl-2010-Tackling Sparse Data Issue in Machine Translation Evaluation</a></p>
<p>17 0.50388545 <a title="77-lsi-17" href="./acl-2010-Balancing_User_Effort_and_Translation_Error_in_Interactive_Machine_Translation_via_Confidence_Measures.html">45 acl-2010-Balancing User Effort and Translation Error in Interactive Machine Translation via Confidence Measures</a></p>
<p>18 0.49798429 <a title="77-lsi-18" href="./acl-2010-Automatic_Evaluation_Method_for_Machine_Translation_Using_Noun-Phrase_Chunking.html">37 acl-2010-Automatic Evaluation Method for Machine Translation Using Noun-Phrase Chunking</a></p>
<p>19 0.49749619 <a title="77-lsi-19" href="./acl-2010-Metadata-Aware_Measures_for_Answer_Summarization_in_Community_Question_Answering.html">171 acl-2010-Metadata-Aware Measures for Answer Summarization in Community Question Answering</a></p>
<p>20 0.46458867 <a title="77-lsi-20" href="./acl-2010-Evaluating_Multilanguage-Comparability_of_Subjectivity_Analysis_Systems.html">105 acl-2010-Evaluating Multilanguage-Comparability of Subjectivity Analysis Systems</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(4, 0.012), (7, 0.021), (25, 0.029), (33, 0.01), (39, 0.019), (40, 0.22), (42, 0.016), (44, 0.015), (59, 0.079), (73, 0.065), (78, 0.038), (83, 0.139), (84, 0.027), (98, 0.222)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.89396548 <a title="77-lda-1" href="./acl-2010-Profiting_from_Mark-Up%3A_Hyper-Text_Annotations_for_Guided_Parsing.html">200 acl-2010-Profiting from Mark-Up: Hyper-Text Annotations for Guided Parsing</a></p>
<p>Author: Valentin I. Spitkovsky ; Daniel Jurafsky ; Hiyan Alshawi</p><p>Abstract: We show how web mark-up can be used to improve unsupervised dependency parsing. Starting from raw bracketings of four common HTML tags (anchors, bold, italics and underlines), we refine approximate partial phrase boundaries to yield accurate parsing constraints. Conversion procedures fall out of our linguistic analysis of a newly available million-word hyper-text corpus. We demonstrate that derived constraints aid grammar induction by training Klein and Manning’s Dependency Model with Valence (DMV) on this data set: parsing accuracy on Section 23 (all sentences) of the Wall Street Journal corpus jumps to 50.4%, beating previous state-of-the- art by more than 5%. Web-scale experiments show that the DMV, perhaps because it is unlexicalized, does not benefit from orders of magnitude more annotated but noisier data. Our model, trained on a single blog, generalizes to 53.3% accuracy out-of-domain, against the Brown corpus nearly 10% higher than the previous published best. The fact that web mark-up strongly correlates with syntactic structure may have broad applicability in NLP.</p><p>same-paper 2 0.85564792 <a title="77-lda-2" href="./acl-2010-Cross-Language_Document_Summarization_Based_on_Machine_Translation_Quality_Prediction.html">77 acl-2010-Cross-Language Document Summarization Based on Machine Translation Quality Prediction</a></p>
<p>Author: Xiaojun Wan ; Huiying Li ; Jianguo Xiao</p><p>Abstract: Cross-language document summarization is a task of producing a summary in one language for a document set in a different language. Existing methods simply use machine translation for document translation or summary translation. However, current machine translation services are far from satisfactory, which results in that the quality of the cross-language summary is usually very poor, both in readability and content. In this paper, we propose to consider the translation quality of each sentence in the English-to-Chinese cross-language summarization process. First, the translation quality of each English sentence in the document set is predicted with the SVM regression method, and then the quality score of each sentence is incorporated into the summarization process. Finally, the English sentences with high translation quality and high informativeness are selected and translated to form the Chinese summary. Experimental results demonstrate the effectiveness and usefulness of the proposed approach. 1</p><p>3 0.77239472 <a title="77-lda-3" href="./acl-2010-Error_Detection_for_Statistical_Machine_Translation_Using_Linguistic_Features.html">102 acl-2010-Error Detection for Statistical Machine Translation Using Linguistic Features</a></p>
<p>Author: Deyi Xiong ; Min Zhang ; Haizhou Li</p><p>Abstract: Automatic error detection is desired in the post-processing to improve machine translation quality. The previous work is largely based on confidence estimation using system-based features, such as word posterior probabilities calculated from Nbest lists or word lattices. We propose to incorporate two groups of linguistic features, which convey information from outside machine translation systems, into error detection: lexical and syntactic features. We use a maximum entropy classifier to predict translation errors by integrating word posterior probability feature and linguistic features. The experimental results show that 1) linguistic features alone outperform word posterior probability based confidence estimation in error detection; and 2) linguistic features can further provide complementary information when combined with word confidence scores, which collectively reduce the classification error rate by 18.52% and improve the F measure by 16.37%.</p><p>4 0.77132243 <a title="77-lda-4" href="./acl-2010-Optimizing_Informativeness_and_Readability_for_Sentiment_Summarization.html">188 acl-2010-Optimizing Informativeness and Readability for Sentiment Summarization</a></p>
<p>Author: Hitoshi Nishikawa ; Takaaki Hasegawa ; Yoshihiro Matsuo ; Genichiro Kikui</p><p>Abstract: We propose a novel algorithm for sentiment summarization that takes account of informativeness and readability, simultaneously. Our algorithm generates a summary by selecting and ordering sentences taken from multiple review texts according to two scores that represent the informativeness and readability of the sentence order. The informativeness score is defined by the number of sentiment expressions and the readability score is learned from the target corpus. We evaluate our method by summarizing reviews on restaurants. Our method outperforms an existing algorithm as indicated by its ROUGE score and human readability experiments.</p><p>5 0.76804984 <a title="77-lda-5" href="./acl-2010-Hierarchical_Search_for_Word_Alignment.html">133 acl-2010-Hierarchical Search for Word Alignment</a></p>
<p>Author: Jason Riesa ; Daniel Marcu</p><p>Abstract: We present a simple yet powerful hierarchical search algorithm for automatic word alignment. Our algorithm induces a forest of alignments from which we can efficiently extract a ranked k-best list. We score a given alignment within the forest with a flexible, linear discriminative model incorporating hundreds of features, and trained on a relatively small amount of annotated data. We report results on Arabic-English word alignment and translation tasks. Our model outperforms a GIZA++ Model-4 baseline by 6.3 points in F-measure, yielding a 1.1 BLEU score increase over a state-of-the-art syntax-based machine translation system.</p><p>6 0.7669571 <a title="77-lda-6" href="./acl-2010-Improving_Chinese_Semantic_Role_Labeling_with_Rich_Syntactic_Features.html">146 acl-2010-Improving Chinese Semantic Role Labeling with Rich Syntactic Features</a></p>
<p>7 0.76253951 <a title="77-lda-7" href="./acl-2010-Cross-Lingual_Latent_Topic_Extraction.html">79 acl-2010-Cross-Lingual Latent Topic Extraction</a></p>
<p>8 0.76234365 <a title="77-lda-8" href="./acl-2010-Identifying_Non-Explicit_Citing_Sentences_for_Citation-Based_Summarization..html">140 acl-2010-Identifying Non-Explicit Citing Sentences for Citation-Based Summarization.</a></p>
<p>9 0.75841093 <a title="77-lda-9" href="./acl-2010-Automatic_Collocation_Suggestion_in_Academic_Writing.html">36 acl-2010-Automatic Collocation Suggestion in Academic Writing</a></p>
<p>10 0.75778246 <a title="77-lda-10" href="./acl-2010-Improving_Statistical_Machine_Translation_with_Monolingual_Collocation.html">147 acl-2010-Improving Statistical Machine Translation with Monolingual Collocation</a></p>
<p>11 0.75707185 <a title="77-lda-11" href="./acl-2010-The_S-Space_Package%3A_An_Open_Source_Package_for_Word_Space_Models.html">232 acl-2010-The S-Space Package: An Open Source Package for Word Space Models</a></p>
<p>12 0.75667655 <a title="77-lda-12" href="./acl-2010-Diversify_and_Combine%3A_Improving_Word_Alignment_for_Machine_Translation_on_Low-Resource_Languages.html">90 acl-2010-Diversify and Combine: Improving Word Alignment for Machine Translation on Low-Resource Languages</a></p>
<p>13 0.75437999 <a title="77-lda-13" href="./acl-2010-Exploring_Syntactic_Structural_Features_for_Sub-Tree_Alignment_Using_Bilingual_Tree_Kernels.html">110 acl-2010-Exploring Syntactic Structural Features for Sub-Tree Alignment Using Bilingual Tree Kernels</a></p>
<p>14 0.75347751 <a title="77-lda-14" href="./acl-2010-Cross_Lingual_Adaptation%3A_An_Experiment_on_Sentiment_Classifications.html">80 acl-2010-Cross Lingual Adaptation: An Experiment on Sentiment Classifications</a></p>
<p>15 0.7530846 <a title="77-lda-15" href="./acl-2010-Bitext_Dependency_Parsing_with_Bilingual_Subtree_Constraints.html">52 acl-2010-Bitext Dependency Parsing with Bilingual Subtree Constraints</a></p>
<p>16 0.75234282 <a title="77-lda-16" href="./acl-2010-Bilingual_Sense_Similarity_for_Statistical_Machine_Translation.html">51 acl-2010-Bilingual Sense Similarity for Statistical Machine Translation</a></p>
<p>17 0.75230384 <a title="77-lda-17" href="./acl-2010-Bridging_SMT_and_TM_with_Translation_Recommendation.html">56 acl-2010-Bridging SMT and TM with Translation Recommendation</a></p>
<p>18 0.7521295 <a title="77-lda-18" href="./acl-2010-Semantics-Driven_Shallow_Parsing_for_Chinese_Semantic_Role_Labeling.html">207 acl-2010-Semantics-Driven Shallow Parsing for Chinese Semantic Role Labeling</a></p>
<p>19 0.75208074 <a title="77-lda-19" href="./acl-2010-Kernel_Based_Discourse_Relation_Recognition_with_Temporal_Ordering_Information.html">155 acl-2010-Kernel Based Discourse Relation Recognition with Temporal Ordering Information</a></p>
<p>20 0.75159872 <a title="77-lda-20" href="./acl-2010-Finding_Cognate_Groups_Using_Phylogenies.html">116 acl-2010-Finding Cognate Groups Using Phylogenies</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
