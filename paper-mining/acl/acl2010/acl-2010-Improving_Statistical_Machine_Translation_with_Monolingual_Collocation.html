<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>147 acl-2010-Improving Statistical Machine Translation with Monolingual Collocation</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-147" href="#">acl2010-147</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>147 acl-2010-Improving Statistical Machine Translation with Monolingual Collocation</h1>
<br/><p>Source: <a title="acl-2010-147-pdf" href="http://aclweb.org/anthology//P/P10/P10-1085.pdf">pdf</a></p><p>Author: Zhanyi Liu ; Haifeng Wang ; Hua Wu ; Sheng Li</p><p>Abstract: This paper proposes to use monolingual collocations to improve Statistical Machine Translation (SMT). We make use of the collocation probabilities, which are estimated from monolingual corpora, in two aspects, namely improving word alignment for various kinds of SMT systems and improving phrase table for phrase-based SMT. The experimental results show that our method improves the performance of both word alignment and translation quality significantly. As compared to baseline systems, we achieve absolute improvements of 2.40 BLEU score on a phrase-based SMT system and 1.76 BLEU score on a parsing-based SMT system. 1</p><p>Reference: <a title="acl-2010-147-reference" href="../acl2010_reference/acl-2010-Improving_Statistical_Machine_Translation_with_Monolingual_Collocation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 We make use of the collocation probabilities, which are estimated from monolingual corpora, in two aspects, namely improving word alignment for various kinds of SMT systems and improving phrase table for phrase-based SMT. [sent-8, score-1.365]
</p><p>2 The experimental results show that our method improves the performance of both word alignment and translation quality significantly. [sent-9, score-0.42]
</p><p>3 1  Introduction  Statistical bilingual word alignment (Brown et al. [sent-13, score-0.419]
</p><p>4 But as far as we know, few previous studies exploit the collocation relations of the words in a phrase. [sent-20, score-0.743]
</p><p>5 We first identify potentially collocated words and estimate collocation probabilities from monolingual corpora using a Monolingual Word Alignment (MWA) method (Liu et al. [sent-26, score-1.179]
</p><p>6 Then the collocation information is employed to improve Bilingual Word Alignment (BWA) for various kinds of SMT systems and to improve phrase table for phrase-based SMT. [sent-28, score-0.916]
</p><p>7 To improve BWA, we re-estimate the alignment probabilities by using the collocation probabilities of words in the same cept. [sent-29, score-1.338]
</p><p>8 An alignment between a source multi-word cept and a target word is a many-to-one multi-word alignment. [sent-32, score-0.421]
</p><p>9 To improve phrase table, we calculate phrase collocation probabilities based on word collocation probabilities. [sent-33, score-1.925]
</p><p>10 Then the phrase collocation probabilities are used as additional features in phrase-based SMT systems. [sent-34, score-0.997]
</p><p>11 The alignment improvement results in an improvement of 2. [sent-36, score-0.316]
</p><p>12 If we use phrase collocation probabilities as additional features, the phrase-based 825  ProceedinUgspp osfa tlhae, 4S8wthed Aennn,u 1a1l-1 M6e Jeutilnyg 2 o0f1 t0h. [sent-39, score-0.997]
</p><p>13 The paper is organized as follows: In section 2, we introduce the collocation model based on the MWA method. [sent-43, score-0.762]
</p><p>14 In section 3 and 4, we show how to improve the BWA method and the phrase table using collocation models respectively. [sent-44, score-0.897]
</p><p>15 A collocation is composed of two words occurring as either a consecutive word sequence or an interrupted word sequence in sentences, such as "by accident" or "take . [sent-48, score-0.932]
</p><p>16 This method adapts the bilingual word alignment algorithm to monolingual scenario to extract collocations only from monolingual corpora. [sent-54, score-0.799]
</p><p>17 1 Monolingual word alignment The monolingual corpus is first replicated to generate a parallel corpus, where each sentence pair consists of two identical sentences in the same language. [sent-58, score-0.496]
</p><p>18 Then the monolingual word alignment algorithm is employed to align the  potentially collocated words in the monolingual sentences. [sent-59, score-0.688]
</p><p>19 (2009), we employ the MWA Model 3 (corresponding to IBM Model 3) to calculate the probability of the monolingual word alignment sequence, as shown in Eq. [sent-61, score-0.553]
</p><p>20 pMWA Mode l3(S,A|S)ln(i  |wi)  li1 j1t(wj |waj)d(j|aj,l)  (1)  Where S  w1l is a monolingual sentence, i denotes the number of words that are aligned with wi . [sent-63, score-0.346]
</p><p>21 Since a word never collocates with itself, the alignment set is denoted as A  {(i,ai )| i [1 ,l] & ai  i} . [sent-64, score-0.308]
</p><p>22 Three kinds of probabilities are involved in this model: word collocation probability t(wj | waj ) , position collocation probability d(j | aj ,l) and fertility probability n(i | wi) . [sent-65, score-2.001]
</p><p>23 In the MWA method, the similar algorithm to bilingual word alignment is used to estimate the parameters of the models, except that a word cannot be aligned to itself. [sent-66, score-0.533]
</p><p>24 2 Collocation probability Given the monolingual word aligned corpus, we calculate the frequency of two words aligned in the corpus, denoted as freq(wi ,wj ) . [sent-71, score-0.431]
</p><p>25 Then the probability for each aligned word pair is estimated as follows:  p(wi|wj)wfrferqe(qw(wi,,wwj)j) p(wj|wi)wfrferqe(qw(wi, w,wj))  (2) (3)  In this paper, the words of collocation are symmetric and we do not determine which word is the head and which word is the modifier. [sent-73, score-1.013]
</p><p>26 Thus, the collocation probability of two words is defined as the average of both probabilities, as in Eq. [sent-74, score-0.796]
</p><p>27 r(wi,wj)p(wi|wj)2p(wj|wi)  (4)  If we have multiple monolingual corpora to estimate the collocation probabilities, we interpolate the probabilities as shown in Eq. [sent-76, score-1.061]
</p><p>28 k  3  (5) for  Improving Statistical Bilingual Word Alignment  We use the collocation information to improve both one-directional and bi-directional bilingual word alignments. [sent-79, score-0.927]
</p><p>29 The alignment probabilities are re-estimated by using the collocation probabili-  ties of words in the same cept. [sent-80, score-1.158]
</p><p>30 1  Improving one-directional bilingual word alignment According to the BWA method, given a bilingual sentence pair E  e1l and F  f1m , the optimal alignment sequence A between E and F can be obtained as in Eq. [sent-82, score-0.864]
</p><p>31 IBM Model 1 only employs the word translation model to calculate the probabilities of alignments. [sent-85, score-0.308]
</p><p>32 Although the fertility model is used to restrict the number of  source words in a cept and the position distortion model is used to describe the correlation of the positions of the source words, the quality of many-to-one alignments is lower than that of one-to-one alignments. [sent-90, score-0.507]
</p><p>33 Intuitively, the probability of the source words aligned to a target word is not only related to the fertility ability and their relative positions, but also related to lexical tokens of words, such as common phrase or idiom. [sent-91, score-0.35]
</p><p>34 In this paper, we use the collocation probability of the source words in a cept to measure their correlation strength. [sent-92, score-0.933]
</p><p>35 Given source words {fj | aj  i} aligned to ei , their collocation probability is calculated as in Eq. [sent-93, score-1.019]
</p><p>36 r({fj|aji})2ki11g ki *1r((fi[i]k 1,)f[i]g)  (7)  Here, f[i]k and f[i]g denote the kth word and gth word in {fj | aj  i} ; r(f[i]k ,f[i]g) denotes the collocation probability of f[i]k and f[i]g , as shown in Eq. [sent-95, score-0.999]
</p><p>37 Thus, the collocation probability of the alignment sequence of a sentence pair can be calcu-  lated according to Eq. [sent-97, score-1.13]
</p><p>38 r(F,A|E)il1r({fj  |aji})  (8)  Based on maximum entropy framework, we combine the collocation model and the BWA model to calculate the word alignment probability of a sentence pair, as shown in Eq. [sent-99, score-1.205]
</p><p>39 We use two features in this paper, namely alignment probabilities and collocation probabilities. [sent-102, score-1.158]
</p><p>40 We first train IBM Model 4 and collocation model on bilingual corpus and monolingual cor-  pus respectively. [sent-104, score-1.04]
</p><p>41 , 1999) to search for the optimal alignment sequence of a given sentence pair, where the score of an alignment sequence is calculated as in Eq. [sent-106, score-0.655]
</p><p>42 (8) only deals with many-toone alignments, but the alignment sequence of a sentence pair also includes one-to-one alignments. [sent-109, score-0.334]
</p><p>43 To calculate the collocation probability of the alignment sequence, we should also consider the collocation probabilities of such one-to-one alignments. [sent-110, score-1.997]
</p><p>44 To solve this problem, we use the collocation probability of the whole source sentence, r(F) , as the collocation probability of one-word cept. [sent-111, score-1.636]
</p><p>45 2  Improving bi-directional bilingual word alignments In word alignment models implemented in GIZA++, only one-to-one and many-to-one word alignment links can be found. [sent-113, score-0.962]
</p><p>46 Bi-directional alignments are generally obtained  from source-to-target alignments As2t and targetto-source alignments At2s , using some heuristic rules (Koehn et al. [sent-116, score-0.579]
</p><p>47 This method ignores the correlation of the words in the same alignment unit, so an alignment may include many unrelated words2, which influences the performances of SMT systems. [sent-118, score-0.647]
</p><p>48 may  include  up  to  827  In order to solve the above problem, we incorporate the collocation probabilities into the bidirectional word alignment process. [sent-123, score-1.222]
</p><p>49 (e1l',f1m',A)*  arAgAmsaxt{(ei,fj)pA(ei,fj)1r(ei)2r(fj)3}  (11)  Here, r(fj) and r(ei) denote the collocation probabilities of the words in the source language and target language respectively, which are calculated by using Eq. [sent-130, score-0.958]
</p><p>50  (p(e | f)  p(f | e))/2  p(ei,fj)eeiffj|ei|*|fj|  (12)  p(e | f) and p(f | e) are the source-to-target and target-to-source translation probabilities trained from the word aligned bilingual corpus. [sent-135, score-0.429]
</p><p>51 4  Improving Phrase Table  Phrase-based SMT system automatically extracts  bilingual phrase pairs from the word aligned bilingual corpus. [sent-136, score-0.423]
</p><p>52 In this paper, we use the collocation probability to measure the possibility of words composing a phrase. [sent-138, score-0.796]
</p><p>53 For each bilingual phrase pair automatically extracted from word aligned corpus, we calculate the collocation probabilities of source phrase and target phrase respectively, according to Eq. [sent-139, score-1.484]
</p><p>54 2n1 n r(wi,wj) r(w1n)i1jn*i1(n 1)  (13)  Here, w1n denotes a phrase with n words; r(wi ,wj ) denotes the collocation probability of a  AdBitloTnCcago ulrbampelo c1rano. [sent-141, score-0.979]
</p><p>55 For the phrase only including one word, we set a fixed collocation probability that is the average of the collocation probabilities of the sentences on a development set. [sent-146, score-1.775]
</p><p>56 These collocation probabilities are incorporated into the phrase-based SMT system as features. [sent-147, score-0.892]
</p><p>57 To train the collocation models, besides the monolingual parts of FBIS, we also employ some other larger Chinese and English monolingual corpora, namely, Chinese Gigaword (LDC2007T38), English Gigaword (LDC2007T07), UN corpus (LDC2004E12), Sinorama corpus (LDC2005T10), as shown in Table 1. [sent-150, score-1.059]
</p><p>58 Using these corpora, we got three kinds of collocation models: CM-1: the training data is the additional monolingual corpora; CM-2: the training data is either side of the bi-  lingual corpus; CM-3: the interpolation of CM-1 and CM-2. [sent-151, score-0.994]
</p><p>59 Then word alignments in the subset were manually labeled, referring to the guideline of the Chinese-to-English alignment (LDC2006E93), but we made some modifications for the guideline. [sent-153, score-0.501]
</p><p>60 There are several different evaluation metrics for word alignment (Ahrenberg et al. [sent-155, score-0.308]
</p><p>61 We use precision (P), recall (R) and alignment error ratio (AER), which are similar to those in Och and Ney (2000), except that we consider each alignment as a sure link. [sent-157, score-0.564]
</p><p>62 Example of the English-to-Chinese word alignments generated by the BWA method and the improved BWA method using CM-3. [sent-162, score-0.368]
</p><p>63 "" denotes the alignments of our method; "" denotes the alignments of the baseline method. [sent-163, score-0.519]
</p><p>64 By minimizing the AER on the development set, the interpolation  coefficients of the collocation probabilities on CM-1 and CM-2 were set to 0. [sent-168, score-0.934]
</p><p>65 2  Evaluation results  One-directional alignment results To train a Chinese-to-English SMT system, we need to perform both Chinese-to-English and English-to-Chinese word alignment. [sent-176, score-0.326]
</p><p>66 The evaluation results in Table 2 indicate that the performances of our methods on single word alignments are close to that of the baseline method. [sent-179, score-0.297]
</p><p>67 CM-3, the error rate of multi-word alignment results is further reduced. [sent-185, score-0.337]
</p><p>68 Figure 2 shows an example of word alignment results generated by the baseline method and the improved method using CM-3. [sent-186, score-0.478]
</p><p>69 In our collocation model, the collocation probability of "the people of the world" is much higher than that of "people world". [sent-188, score-1.56]
</p><p>70 For example, in the baseline alignment "has made . [sent-190, score-0.303]
</p><p>71 have 取得", "have" and "has" are unrelated to the target word, while our method only generated "made 取 得", this is because that the collocation probabilities of "has/have" and "made" are much lower  than that of the whole source sentence. [sent-193, score-1.022]
</p><p>72 Bi-directional alignment results We build a bi-directional alignment baseline in two steps: (1) GIZA++ is used to obtain the source-to-target and target-to-source alignments; (2) the bi-directional alignments are generated by using "grow-diag-final". [sent-194, score-0.782]
</p><p>73 We evaluate three methods: WA-1: one-directional alignment method proposed in section 3. [sent-196, score-0.302]
</p><p>74 1 and grow-diag-final; WA-2: GIZA++ and the bi-directional bilingual word alignments method proposed in section 3. [sent-197, score-0.382]
</p><p>75 We can see that WA-1 achieves lower alignment error rate as compared to the baseline method, since the performance of the improved onedirectional alignment method is better than that of GIZA++. [sent-201, score-0.717]
</p><p>76 This result indicates that improving  one-directional word alignment results in bidirectional word alignment improvement. [sent-202, score-0.665]
</p><p>77 This is because the proposed bi-directional alignment method can effectively recognize the correct alignments from the alignment union, by leveraging collocation probabilities of the words in the same cept. [sent-204, score-1.653]
</p><p>78 Our method using both methods proposed in section 3 produces the best alignment performance, achieving 11% absolute error rate reduction. [sent-205, score-0.459]
</p><p>79 2  Effect of improved word alignment on phrase-based SMT We investigate the effectiveness of the improved word alignments on the phrase-based SMT system. [sent-218, score-0.647]
</p><p>80 Example of the translations generated by the baseline system and the system where the phrase collocation probabilities are added  + TPIhamrblpesr5ocEv. [sent-224, score-1.036]
</p><p>81 Here, we investigate three different collocation models for translation quality improvement. [sent-228, score-0.841]
</p><p>82 From the results of Table 4, it can be seen that the systems using the improved bi-directional alignments achieve higher quality of translation than the baseline system. [sent-230, score-0.347]
</p><p>83 If the same alignment method is used, the systems using CM-3 got the highest BLEU scores. [sent-231, score-0.32]
</p><p>84 And if the same collocation model is used, the systems using WA-3 achieved the higher scores. [sent-232, score-0.762]
</p><p>85 3  Effect of phrase collocation probabilities  To investigate the effectiveness of the method proposed in section 4, we only use the collocation model CM-3 as described in section 5. [sent-235, score-1.799]
</p><p>86 When the phrase collocation probabilities are incorporated into the SMT system, the translation quality is improved, achieving an absolute improvement of 0. [sent-238, score-1.166]
</p><p>87 This result indicates that the collocation probabilities of phrases are useful in determining the boundary of phrase and predicting whether phrases should be translated together, which helps to improve the phrase-based SMT performance. [sent-240, score-1.01]
</p><p>88 Figure 3 shows an example: T1 is generated by the system where the phrase collocation probabilities are used and T2 is generated by the baseline system. [sent-241, score-1.056]
</p><p>89 In this example, since the collocation probability of " 出 问题" is much higher than that of " 问题 ", our method tends to split " 出 问题 " into "(出 问题) (。 )", rather than 。  。  "(出) (问题 )". [sent-242, score-0.832]
</p><p>90 For the phrase "才能 避免" in the source sentence, the collocation probability of the translation "in order to avoid" is higher than that of the translation "can we avoid". [sent-243, score-1.037]
</p><p>91 Although the phrase "我们 必须 采取 措 施" in the source sentence has the same translation "We must adopt effective measures", our method splits this phrase into two parts "我们 必 须" and "采取 措施", because two parts have higher collocation probabilities than the whole phrase. [sent-245, score-1.221]
</p><p>92 We also investigate the performance of the system employing both the word alignment improvement and phrase table improvement methods. [sent-246, score-0.467]
</p><p>93 The system using the improved word alignments achieves an absolute improvement of  1. [sent-263, score-0.349]
</p><p>94 We first used the MWA method to identify potentially collocated words and estimate collocation probabilities only from monolingual corpora, no additional resource or linguistic preprocessing is needed. [sent-266, score-1.177]
</p><p>95 Then the collocation information was employed to improve BWA for various kinds of SMT systems and to improve phrase table for phrasebased SMT. [sent-267, score-0.916]
</p><p>96 To improve BWA, we re-estimate the alignment probabilities by using the collocation probabilities of words in the same cept. [sent-268, score-1.338]
</p><p>97 To improve phrase table, we calculate phrase collocation probabilities based on word collocation probabilities. [sent-269, score-1.925]
</p><p>98 Then the phrase collocation probabilities are used as additional features in phrase-based SMT systems. [sent-270, score-0.997]
</p><p>99 The improved word alignment results in an improvement of 2. [sent-272, score-0.374]
</p><p>100 When we also used phrase collocation probabilities as additional features, the phrase-based SMT performance is finally improved by 2. [sent-275, score-1.038]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('collocation', 0.743), ('alignment', 0.266), ('smt', 0.208), ('bwa', 0.202), ('alignments', 0.193), ('monolingual', 0.149), ('probabilities', 0.149), ('mwa', 0.128), ('bilingual', 0.111), ('fj', 0.104), ('bleu', 0.091), ('phrase', 0.087), ('wi', 0.077), ('aligned', 0.072), ('wj', 0.072), ('cept', 0.069), ('collocated', 0.064), ('ibm', 0.061), ('translation', 0.055), ('probability', 0.053), ('aj', 0.052), ('fertility', 0.052), ('fbis', 0.051), ('koehn', 0.049), ('absolute', 0.048), ('ihi', 0.048), ('denotes', 0.048), ('och', 0.046), ('collocations', 0.046), ('giza', 0.045), ('aer', 0.044), ('source', 0.044), ('liu', 0.044), ('calculate', 0.043), ('word', 0.042), ('interpolation', 0.042), ('improved', 0.041), ('rate', 0.039), ('achieving', 0.038), ('joshua', 0.037), ('ahrenberg', 0.037), ('cepts', 0.037), ('rferqe', 0.037), ('waj', 0.037), ('baseline', 0.037), ('method', 0.036), ('sg', 0.033), ('ei', 0.033), ('qw', 0.032), ('error', 0.032), ('improve', 0.031), ('unrelated', 0.03), ('interrupted', 0.029), ('sequence', 0.029), ('chris', 0.027), ('improving', 0.027), ('ki', 0.026), ('alexandra', 0.026), ('philipp', 0.026), ('improvement', 0.025), ('performances', 0.025), ('kinds', 0.024), ('franz', 0.024), ('china', 0.024), ('correlation', 0.024), ('ijcnlp', 0.024), ('xiong', 0.024), ('gs', 0.023), ('meeting', 0.023), ('annual', 0.023), ('score', 0.023), ('calculated', 0.022), ('sheng', 0.022), ('marton', 0.022), ('bidirectional', 0.022), ('distortion', 0.022), ('hermann', 0.022), ('statistical', 0.022), ('investigate', 0.022), ('weights', 0.022), ('josef', 0.021), ('people', 0.021), ('quality', 0.021), ('wf', 0.02), ('generated', 0.02), ('corpora', 0.02), ('sentence', 0.02), ('ney', 0.019), ('cherry', 0.019), ('sr', 0.019), ('pair', 0.019), ('kth', 0.019), ('brown', 0.019), ('model', 0.019), ('potentially', 0.018), ('train', 0.018), ('got', 0.018), ('additional', 0.018), ('mckeown', 0.018), ('consecutive', 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="147-tfidf-1" href="./acl-2010-Improving_Statistical_Machine_Translation_with_Monolingual_Collocation.html">147 acl-2010-Improving Statistical Machine Translation with Monolingual Collocation</a></p>
<p>Author: Zhanyi Liu ; Haifeng Wang ; Hua Wu ; Sheng Li</p><p>Abstract: This paper proposes to use monolingual collocations to improve Statistical Machine Translation (SMT). We make use of the collocation probabilities, which are estimated from monolingual corpora, in two aspects, namely improving word alignment for various kinds of SMT systems and improving phrase table for phrase-based SMT. The experimental results show that our method improves the performance of both word alignment and translation quality significantly. As compared to baseline systems, we achieve absolute improvements of 2.40 BLEU score on a phrase-based SMT system and 1.76 BLEU score on a parsing-based SMT system. 1</p><p>2 0.51920515 <a title="147-tfidf-2" href="./acl-2010-Automatic_Collocation_Suggestion_in_Academic_Writing.html">36 acl-2010-Automatic Collocation Suggestion in Academic Writing</a></p>
<p>Author: Jian-Cheng Wu ; Yu-Chia Chang ; Teruko Mitamura ; Jason S. Chang</p><p>Abstract: In recent years, collocation has been widely acknowledged as an essential characteristic to distinguish native speakers from non-native speakers. Research on academic writing has also shown that collocations are not only common but serve a particularly important discourse function within the academic community. In our study, we propose a machine learning approach to implementing an online collocation writing assistant. We use a data-driven classifier to provide collocation suggestions to improve word choices, based on the result of classifica- tion. The system generates and ranks suggestions to assist learners’ collocation usages in their academic writing with satisfactory results. 1</p><p>3 0.2715292 <a title="147-tfidf-3" href="./acl-2010-Collocation_Extraction_beyond_the_Independence_Assumption.html">60 acl-2010-Collocation Extraction beyond the Independence Assumption</a></p>
<p>Author: Gerlof Bouma</p><p>Abstract: In this paper we start to explore two-part collocation extraction association measures that do not estimate expected probabilities on the basis of the independence assumption. We propose two new measures based upon the well-known measures of mutual information and pointwise mutual information. Expected probabilities are derived from automatically trained Aggregate Markov Models. On three collocation gold standards, we find the new association measures vary in their effectiveness.</p><p>4 0.25422844 <a title="147-tfidf-4" href="./acl-2010-Training_Phrase_Translation_Models_with_Leaving-One-Out.html">240 acl-2010-Training Phrase Translation Models with Leaving-One-Out</a></p>
<p>Author: Joern Wuebker ; Arne Mauser ; Hermann Ney</p><p>Abstract: Several attempts have been made to learn phrase translation probabilities for phrasebased statistical machine translation that go beyond pure counting of phrases in word-aligned training data. Most approaches report problems with overfitting. We describe a novel leavingone-out approach to prevent over-fitting that allows us to train phrase models that show improved translation performance on the WMT08 Europarl German-English task. In contrast to most previous work where phrase models were trained separately from other models used in translation, we include all components such as single word lexica and reordering mod- els in training. Using this consistent training of phrase models we are able to achieve improvements of up to 1.4 points in BLEU. As a side effect, the phrase table size is reduced by more than 80%.</p><p>5 0.24875855 <a title="147-tfidf-5" href="./acl-2010-Hierarchical_Search_for_Word_Alignment.html">133 acl-2010-Hierarchical Search for Word Alignment</a></p>
<p>Author: Jason Riesa ; Daniel Marcu</p><p>Abstract: We present a simple yet powerful hierarchical search algorithm for automatic word alignment. Our algorithm induces a forest of alignments from which we can efficiently extract a ranked k-best list. We score a given alignment within the forest with a flexible, linear discriminative model incorporating hundreds of features, and trained on a relatively small amount of annotated data. We report results on Arabic-English word alignment and translation tasks. Our model outperforms a GIZA++ Model-4 baseline by 6.3 points in F-measure, yielding a 1.1 BLEU score increase over a state-of-the-art syntax-based machine translation system.</p><p>6 0.23757531 <a title="147-tfidf-6" href="./acl-2010-Diversify_and_Combine%3A_Improving_Word_Alignment_for_Machine_Translation_on_Low-Resource_Languages.html">90 acl-2010-Diversify and Combine: Improving Word Alignment for Machine Translation on Low-Resource Languages</a></p>
<p>7 0.23645023 <a title="147-tfidf-7" href="./acl-2010-Active_Learning-Based_Elicitation_for_Semi-Supervised_Word_Alignment.html">24 acl-2010-Active Learning-Based Elicitation for Semi-Supervised Word Alignment</a></p>
<p>8 0.19153185 <a title="147-tfidf-8" href="./acl-2010-Discriminative_Modeling_of_Extraction_Sets_for_Machine_Translation.html">87 acl-2010-Discriminative Modeling of Extraction Sets for Machine Translation</a></p>
<p>9 0.17949231 <a title="147-tfidf-9" href="./acl-2010-Word_Alignment_with_Synonym_Regularization.html">262 acl-2010-Word Alignment with Synonym Regularization</a></p>
<p>10 0.17704648 <a title="147-tfidf-10" href="./acl-2010-Letter-Phoneme_Alignment%3A_An_Exploration.html">170 acl-2010-Letter-Phoneme Alignment: An Exploration</a></p>
<p>11 0.16472766 <a title="147-tfidf-11" href="./acl-2010-Boosting-Based_System_Combination_for_Machine_Translation.html">54 acl-2010-Boosting-Based System Combination for Machine Translation</a></p>
<p>12 0.15386452 <a title="147-tfidf-12" href="./acl-2010-Unsupervised_Search_for_the_Optimal_Segmentation_for_Statistical_Machine_Translation.html">249 acl-2010-Unsupervised Search for the Optimal Segmentation for Statistical Machine Translation</a></p>
<p>13 0.14869633 <a title="147-tfidf-13" href="./acl-2010-Exploring_Syntactic_Structural_Features_for_Sub-Tree_Alignment_Using_Bilingual_Tree_Kernels.html">110 acl-2010-Exploring Syntactic Structural Features for Sub-Tree Alignment Using Bilingual Tree Kernels</a></p>
<p>14 0.14758372 <a title="147-tfidf-14" href="./acl-2010-Pseudo-Word_for_Phrase-Based_Machine_Translation.html">201 acl-2010-Pseudo-Word for Phrase-Based Machine Translation</a></p>
<p>15 0.12766424 <a title="147-tfidf-15" href="./acl-2010-Better_Filtration_and_Augmentation_for_Hierarchical_Phrase-Based_Translation_Rules.html">48 acl-2010-Better Filtration and Augmentation for Hierarchical Phrase-Based Translation Rules</a></p>
<p>16 0.12557429 <a title="147-tfidf-16" href="./acl-2010-Error_Detection_for_Statistical_Machine_Translation_Using_Linguistic_Features.html">102 acl-2010-Error Detection for Statistical Machine Translation Using Linguistic Features</a></p>
<p>17 0.12228099 <a title="147-tfidf-17" href="./acl-2010-Discriminative_Pruning_for_Discriminative_ITG_Alignment.html">88 acl-2010-Discriminative Pruning for Discriminative ITG Alignment</a></p>
<p>18 0.12044434 <a title="147-tfidf-18" href="./acl-2010-Bilingual_Sense_Similarity_for_Statistical_Machine_Translation.html">51 acl-2010-Bilingual Sense Similarity for Statistical Machine Translation</a></p>
<p>19 0.11882523 <a title="147-tfidf-19" href="./acl-2010-Improving_Arabic-to-English_Statistical_Machine_Translation_by_Reordering_Post-Verbal_Subjects_for_Alignment.html">145 acl-2010-Improving Arabic-to-English Statistical Machine Translation by Reordering Post-Verbal Subjects for Alignment</a></p>
<p>20 0.11440309 <a title="147-tfidf-20" href="./acl-2010-Fully_Unsupervised_Core-Adjunct_Argument_Classification.html">120 acl-2010-Fully Unsupervised Core-Adjunct Argument Classification</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.23), (1, -0.336), (2, -0.078), (3, 0.022), (4, 0.147), (5, 0.105), (6, -0.226), (7, 0.041), (8, 0.116), (9, -0.048), (10, -0.006), (11, 0.055), (12, -0.085), (13, 0.143), (14, 0.233), (15, 0.029), (16, -0.04), (17, -0.24), (18, 0.134), (19, 0.37), (20, -0.158), (21, -0.013), (22, -0.26), (23, 0.098), (24, -0.009), (25, 0.06), (26, 0.032), (27, -0.063), (28, -0.012), (29, -0.101), (30, 0.037), (31, 0.041), (32, 0.009), (33, -0.014), (34, -0.03), (35, 0.037), (36, 0.01), (37, -0.043), (38, -0.013), (39, -0.028), (40, -0.002), (41, -0.019), (42, 0.025), (43, 0.011), (44, 0.024), (45, 0.013), (46, 0.004), (47, -0.007), (48, -0.031), (49, 0.014)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91578871 <a title="147-lsi-1" href="./acl-2010-Improving_Statistical_Machine_Translation_with_Monolingual_Collocation.html">147 acl-2010-Improving Statistical Machine Translation with Monolingual Collocation</a></p>
<p>Author: Zhanyi Liu ; Haifeng Wang ; Hua Wu ; Sheng Li</p><p>Abstract: This paper proposes to use monolingual collocations to improve Statistical Machine Translation (SMT). We make use of the collocation probabilities, which are estimated from monolingual corpora, in two aspects, namely improving word alignment for various kinds of SMT systems and improving phrase table for phrase-based SMT. The experimental results show that our method improves the performance of both word alignment and translation quality significantly. As compared to baseline systems, we achieve absolute improvements of 2.40 BLEU score on a phrase-based SMT system and 1.76 BLEU score on a parsing-based SMT system. 1</p><p>2 0.82079762 <a title="147-lsi-2" href="./acl-2010-Automatic_Collocation_Suggestion_in_Academic_Writing.html">36 acl-2010-Automatic Collocation Suggestion in Academic Writing</a></p>
<p>Author: Jian-Cheng Wu ; Yu-Chia Chang ; Teruko Mitamura ; Jason S. Chang</p><p>Abstract: In recent years, collocation has been widely acknowledged as an essential characteristic to distinguish native speakers from non-native speakers. Research on academic writing has also shown that collocations are not only common but serve a particularly important discourse function within the academic community. In our study, we propose a machine learning approach to implementing an online collocation writing assistant. We use a data-driven classifier to provide collocation suggestions to improve word choices, based on the result of classifica- tion. The system generates and ranks suggestions to assist learners’ collocation usages in their academic writing with satisfactory results. 1</p><p>3 0.7602123 <a title="147-lsi-3" href="./acl-2010-Collocation_Extraction_beyond_the_Independence_Assumption.html">60 acl-2010-Collocation Extraction beyond the Independence Assumption</a></p>
<p>Author: Gerlof Bouma</p><p>Abstract: In this paper we start to explore two-part collocation extraction association measures that do not estimate expected probabilities on the basis of the independence assumption. We propose two new measures based upon the well-known measures of mutual information and pointwise mutual information. Expected probabilities are derived from automatically trained Aggregate Markov Models. On three collocation gold standards, we find the new association measures vary in their effectiveness.</p><p>4 0.50901949 <a title="147-lsi-4" href="./acl-2010-Diversify_and_Combine%3A_Improving_Word_Alignment_for_Machine_Translation_on_Low-Resource_Languages.html">90 acl-2010-Diversify and Combine: Improving Word Alignment for Machine Translation on Low-Resource Languages</a></p>
<p>Author: Bing Xiang ; Yonggang Deng ; Bowen Zhou</p><p>Abstract: We present a novel method to improve word alignment quality and eventually the translation performance by producing and combining complementary word alignments for low-resource languages. Instead of focusing on the improvement of a single set of word alignments, we generate multiple sets of diversified alignments based on different motivations, such as linguistic knowledge, morphology and heuristics. We demonstrate this approach on an English-to-Pashto translation task by combining the alignments obtained from syntactic reordering, stemming, and partial words. The combined alignment outperforms the baseline alignment, with significantly higher F-scores and better transla- tion performance.</p><p>5 0.48328522 <a title="147-lsi-5" href="./acl-2010-Pseudo-Word_for_Phrase-Based_Machine_Translation.html">201 acl-2010-Pseudo-Word for Phrase-Based Machine Translation</a></p>
<p>Author: Xiangyu Duan ; Min Zhang ; Haizhou Li</p><p>Abstract: The pipeline of most Phrase-Based Statistical Machine Translation (PB-SMT) systems starts from automatically word aligned parallel corpus. But word appears to be too fine-grained in some cases such as non-compositional phrasal equivalences, where no clear word alignments exist. Using words as inputs to PBSMT pipeline has inborn deficiency. This paper proposes pseudo-word as a new start point for PB-SMT pipeline. Pseudo-word is a kind of basic multi-word expression that characterizes minimal sequence of consecutive words in sense of translation. By casting pseudo-word searching problem into a parsing framework, we search for pseudo-words in a monolingual way and a bilingual synchronous way. Experiments show that pseudo-word significantly outperforms word for PB-SMT model in both travel translation domain and news translation domain. 1</p><p>6 0.48041767 <a title="147-lsi-6" href="./acl-2010-Word_Alignment_with_Synonym_Regularization.html">262 acl-2010-Word Alignment with Synonym Regularization</a></p>
<p>7 0.46671686 <a title="147-lsi-7" href="./acl-2010-Training_Phrase_Translation_Models_with_Leaving-One-Out.html">240 acl-2010-Training Phrase Translation Models with Leaving-One-Out</a></p>
<p>8 0.45985663 <a title="147-lsi-8" href="./acl-2010-Discriminative_Modeling_of_Extraction_Sets_for_Machine_Translation.html">87 acl-2010-Discriminative Modeling of Extraction Sets for Machine Translation</a></p>
<p>9 0.45641127 <a title="147-lsi-9" href="./acl-2010-Active_Learning-Based_Elicitation_for_Semi-Supervised_Word_Alignment.html">24 acl-2010-Active Learning-Based Elicitation for Semi-Supervised Word Alignment</a></p>
<p>10 0.44912738 <a title="147-lsi-10" href="./acl-2010-Hierarchical_Search_for_Word_Alignment.html">133 acl-2010-Hierarchical Search for Word Alignment</a></p>
<p>11 0.42741874 <a title="147-lsi-11" href="./acl-2010-Letter-Phoneme_Alignment%3A_An_Exploration.html">170 acl-2010-Letter-Phoneme Alignment: An Exploration</a></p>
<p>12 0.41391644 <a title="147-lsi-12" href="./acl-2010-Discriminative_Pruning_for_Discriminative_ITG_Alignment.html">88 acl-2010-Discriminative Pruning for Discriminative ITG Alignment</a></p>
<p>13 0.36866286 <a title="147-lsi-13" href="./acl-2010-Exploring_Syntactic_Structural_Features_for_Sub-Tree_Alignment_Using_Bilingual_Tree_Kernels.html">110 acl-2010-Exploring Syntactic Structural Features for Sub-Tree Alignment Using Bilingual Tree Kernels</a></p>
<p>14 0.36092874 <a title="147-lsi-14" href="./acl-2010-Unsupervised_Search_for_the_Optimal_Segmentation_for_Statistical_Machine_Translation.html">249 acl-2010-Unsupervised Search for the Optimal Segmentation for Statistical Machine Translation</a></p>
<p>15 0.34193999 <a title="147-lsi-15" href="./acl-2010-Error_Detection_for_Statistical_Machine_Translation_Using_Linguistic_Features.html">102 acl-2010-Error Detection for Statistical Machine Translation Using Linguistic Features</a></p>
<p>16 0.33898038 <a title="147-lsi-16" href="./acl-2010-Boosting-Based_System_Combination_for_Machine_Translation.html">54 acl-2010-Boosting-Based System Combination for Machine Translation</a></p>
<p>17 0.30939767 <a title="147-lsi-17" href="./acl-2010-Hindi-to-Urdu_Machine_Translation_through_Transliteration.html">135 acl-2010-Hindi-to-Urdu Machine Translation through Transliteration</a></p>
<p>18 0.30578181 <a title="147-lsi-18" href="./acl-2010-cdec%3A_A_Decoder%2C_Alignment%2C_and_Learning_Framework_for_Finite-State_and_Context-Free_Translation_Models.html">265 acl-2010-cdec: A Decoder, Alignment, and Learning Framework for Finite-State and Context-Free Translation Models</a></p>
<p>19 0.29973581 <a title="147-lsi-19" href="./acl-2010-Better_Filtration_and_Augmentation_for_Hierarchical_Phrase-Based_Translation_Rules.html">48 acl-2010-Better Filtration and Augmentation for Hierarchical Phrase-Based Translation Rules</a></p>
<p>20 0.29489419 <a title="147-lsi-20" href="./acl-2010-Fixed_Length_Word_Suffix_for_Factored_Statistical_Machine_Translation.html">119 acl-2010-Fixed Length Word Suffix for Factored Statistical Machine Translation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(16, 0.042), (25, 0.036), (59, 0.15), (73, 0.033), (83, 0.344), (84, 0.015), (98, 0.232)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.97046363 <a title="147-lda-1" href="./acl-2010-Automatic_Evaluation_of_Linguistic_Quality_in_Multi-Document_Summarization.html">38 acl-2010-Automatic Evaluation of Linguistic Quality in Multi-Document Summarization</a></p>
<p>Author: Emily Pitler ; Annie Louis ; Ani Nenkova</p><p>Abstract: To date, few attempts have been made to develop and validate methods for automatic evaluation of linguistic quality in text summarization. We present the first systematic assessment of several diverse classes of metrics designed to capture various aspects of well-written text. We train and test linguistic quality models on consecutive years of NIST evaluation data in order to show the generality of results. For grammaticality, the best results come from a set of syntactic features. Focus, coherence and referential clarity are best evaluated by a class of features measuring local coherence on the basis of cosine similarity between sentences, coreference informa- tion, and summarization specific features. Our best results are 90% accuracy for pairwise comparisons of competing systems over a test set of several inputs and 70% for ranking summaries of a specific input.</p><p>2 0.97035122 <a title="147-lda-2" href="./acl-2010-Hierarchical_Joint_Learning%3A_Improving_Joint_Parsing_and_Named_Entity_Recognition_with_Non-Jointly_Labeled_Data.html">132 acl-2010-Hierarchical Joint Learning: Improving Joint Parsing and Named Entity Recognition with Non-Jointly Labeled Data</a></p>
<p>Author: Jenny Rose Finkel ; Christopher D. Manning</p><p>Abstract: One of the main obstacles to producing high quality joint models is the lack of jointly annotated data. Joint modeling of multiple natural language processing tasks outperforms single-task models learned from the same data, but still underperforms compared to single-task models learned on the more abundant quantities of available single-task annotated data. In this paper we present a novel model which makes use of additional single-task annotated data to improve the performance of a joint model. Our model utilizes a hierarchical prior to link the feature weights for shared features in several single-task models and the joint model. Experiments on joint parsing and named entity recog- nition, using the OntoNotes corpus, show that our hierarchical joint model can produce substantial gains over a joint model trained on only the jointly annotated data.</p><p>3 0.95605761 <a title="147-lda-3" href="./acl-2010-Coreference_Resolution_with_Reconcile.html">73 acl-2010-Coreference Resolution with Reconcile</a></p>
<p>Author: Veselin Stoyanov ; Claire Cardie ; Nathan Gilbert ; Ellen Riloff ; David Buttler ; David Hysom</p><p>Abstract: Despite the existence of several noun phrase coreference resolution data sets as well as several formal evaluations on the task, it remains frustratingly difficult to compare results across different coreference resolution systems. This is due to the high cost of implementing a complete end-to-end coreference resolution system, which often forces researchers to substitute available gold-standard information in lieu of implementing a module that would compute that information. Unfortunately, this leads to inconsistent and often unrealistic evaluation scenarios. With the aim to facilitate consistent and realistic experimental evaluations in coreference resolution, we present Reconcile, an infrastructure for the development of learning-based noun phrase (NP) coreference resolution systems. Reconcile is designed to facilitate the rapid creation of coreference resolution systems, easy implementation of new feature sets and approaches to coreference res- olution, and empirical evaluation of coreference resolvers across a variety of benchmark data sets and standard scoring metrics. We describe Reconcile and present experimental results showing that Reconcile can be used to create a coreference resolver that achieves performance comparable to state-ofthe-art systems on six benchmark data sets.</p><p>4 0.95372933 <a title="147-lda-4" href="./acl-2010-A_Cognitive_Cost_Model_of_Annotations_Based_on_Eye-Tracking_Data.html">4 acl-2010-A Cognitive Cost Model of Annotations Based on Eye-Tracking Data</a></p>
<p>Author: Katrin Tomanek ; Udo Hahn ; Steffen Lohmann ; Jurgen Ziegler</p><p>Abstract: We report on an experiment to track complex decision points in linguistic metadata annotation where the decision behavior of annotators is observed with an eyetracking device. As experimental conditions we investigate different forms of textual context and linguistic complexity classes relative to syntax and semantics. Our data renders evidence that annotation performance depends on the semantic and syntactic complexity of the decision points and, more interestingly, indicates that fullscale context is mostly negligible with – the exception of semantic high-complexity cases. We then induce from this observational data a cognitively grounded cost model of linguistic meta-data annotations and compare it with existing non-cognitive models. Our data reveals that the cognitively founded model explains annotation costs (expressed in annotation time) more adequately than non-cognitive ones.</p><p>5 0.95305133 <a title="147-lda-5" href="./acl-2010-Coreference_Resolution_across_Corpora%3A_Languages%2C_Coding_Schemes%2C_and_Preprocessing_Information.html">72 acl-2010-Coreference Resolution across Corpora: Languages, Coding Schemes, and Preprocessing Information</a></p>
<p>Author: Marta Recasens ; Eduard Hovy</p><p>Abstract: This paper explores the effect that different corpus configurations have on the performance of a coreference resolution system, as measured by MUC, B3, and CEAF. By varying separately three parameters (language, annotation scheme, and preprocessing information) and applying the same coreference resolution system, the strong bonds between system and corpus are demonstrated. The experiments reveal problems in coreference resolution evaluation relating to task definition, coding schemes, and features. They also ex- pose systematic biases in the coreference evaluation metrics. We show that system comparison is only possible when corpus parameters are in exact agreement.</p><p>same-paper 6 0.94959867 <a title="147-lda-6" href="./acl-2010-Improving_Statistical_Machine_Translation_with_Monolingual_Collocation.html">147 acl-2010-Improving Statistical Machine Translation with Monolingual Collocation</a></p>
<p>7 0.94937474 <a title="147-lda-7" href="./acl-2010-%22Ask_Not_What_Textual_Entailment_Can_Do_for_You...%22.html">1 acl-2010-"Ask Not What Textual Entailment Can Do for You..."</a></p>
<p>8 0.94307035 <a title="147-lda-8" href="./acl-2010-Vocabulary_Choice_as_an_Indicator_of_Perspective.html">256 acl-2010-Vocabulary Choice as an Indicator of Perspective</a></p>
<p>9 0.93087602 <a title="147-lda-9" href="./acl-2010-Arabic_Named_Entity_Recognition%3A_Using_Features_Extracted_from_Noisy_Data.html">32 acl-2010-Arabic Named Entity Recognition: Using Features Extracted from Noisy Data</a></p>
<p>10 0.92261565 <a title="147-lda-10" href="./acl-2010-Error_Detection_for_Statistical_Machine_Translation_Using_Linguistic_Features.html">102 acl-2010-Error Detection for Statistical Machine Translation Using Linguistic Features</a></p>
<p>11 0.91836768 <a title="147-lda-11" href="./acl-2010-Annotation.html">31 acl-2010-Annotation</a></p>
<p>12 0.91515249 <a title="147-lda-12" href="./acl-2010-Supervised_Noun_Phrase_Coreference_Research%3A_The_First_Fifteen_Years.html">219 acl-2010-Supervised Noun Phrase Coreference Research: The First Fifteen Years</a></p>
<p>13 0.91166091 <a title="147-lda-13" href="./acl-2010-Entity-Based_Local_Coherence_Modelling_Using_Topological_Fields.html">101 acl-2010-Entity-Based Local Coherence Modelling Using Topological Fields</a></p>
<p>14 0.91081792 <a title="147-lda-14" href="./acl-2010-Kernel_Based_Discourse_Relation_Recognition_with_Temporal_Ordering_Information.html">155 acl-2010-Kernel Based Discourse Relation Recognition with Temporal Ordering Information</a></p>
<p>15 0.91075993 <a title="147-lda-15" href="./acl-2010-Joint_Syntactic_and_Semantic_Parsing_of_Chinese.html">153 acl-2010-Joint Syntactic and Semantic Parsing of Chinese</a></p>
<p>16 0.90775192 <a title="147-lda-16" href="./acl-2010-Phylogenetic_Grammar_Induction.html">195 acl-2010-Phylogenetic Grammar Induction</a></p>
<p>17 0.90632701 <a title="147-lda-17" href="./acl-2010-The_Same-Head_Heuristic_for_Coreference.html">233 acl-2010-The Same-Head Heuristic for Coreference</a></p>
<p>18 0.90394485 <a title="147-lda-18" href="./acl-2010-Practical_Very_Large_Scale_CRFs.html">197 acl-2010-Practical Very Large Scale CRFs</a></p>
<p>19 0.90173119 <a title="147-lda-19" href="./acl-2010-Bridging_SMT_and_TM_with_Translation_Recommendation.html">56 acl-2010-Bridging SMT and TM with Translation Recommendation</a></p>
<p>20 0.89987344 <a title="147-lda-20" href="./acl-2010-TrustRank%3A_Inducing_Trust_in_Automatic_Translations_via_Ranking.html">244 acl-2010-TrustRank: Inducing Trust in Automatic Translations via Ranking</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
