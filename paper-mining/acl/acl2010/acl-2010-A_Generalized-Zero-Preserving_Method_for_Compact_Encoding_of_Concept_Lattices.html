<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>7 acl-2010-A Generalized-Zero-Preserving Method for Compact Encoding of Concept Lattices</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-7" href="#">acl2010-7</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>7 acl-2010-A Generalized-Zero-Preserving Method for Compact Encoding of Concept Lattices</h1>
<br/><p>Source: <a title="acl-2010-7-pdf" href="http://aclweb.org/anthology//P/P10/P10-1153.pdf">pdf</a></p><p>Author: Matthew Skala ; Victoria Krakovna ; Janos Kramar ; Gerald Penn</p><p>Abstract: Constructing an encoding of a concept lattice using short bit vectors allows for efficient computation of join operations on the lattice. Join is the central operation any unification-based parser must support. We extend the traditional bit vector encoding, which represents join failure using the zero vector, to count any vector with less than a fixed number of one bits as failure. This allows non-joinable elements to share bits, resulting in a smaller vector size. A constraint solver is used to construct the encoding, and a variety of techniques are employed to find near-optimal solutions and handle timeouts. An evaluation is provided comparing the extended representation of failure with traditional bit vector techniques.</p><p>Reference: <a title="acl-2010-7-reference" href="../acl2010_reference/acl-2010-A_Generalized-Zero-Preserving_Method_for_Compact_Encoding_of_Concept_Lattices_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 {vkrakovna ,  Abstract Constructing an encoding of a concept lattice using short bit vectors allows for efficient computation of join operations on the lattice. [sent-5, score-0.815]
</p><p>2 We extend the traditional bit vector encoding, which represents join failure using the zero vector, to count any vector with less than a fixed number of one bits as failure. [sent-7, score-1.128]
</p><p>3 A constraint solver is used to construct the encoding, and a variety of techniques are employed to find near-optimal solutions  and handle timeouts. [sent-9, score-0.229]
</p><p>4 An evaluation is provided comparing the extended representation of failure with traditional bit vector techniques. [sent-10, score-0.473]
</p><p>5 1 Introduction The use of bit vectors is almost as old as HPSG parsing itself. [sent-11, score-0.344]
</p><p>6 , 1989) as a method for computing the unification of two types without table lookup, bit vectors have been attractive because of three speed advantages: •  •  The classical bit vector encoding uses bitwise TAhNeD c tasos iccaalcl builatt vee type uncnoifdiicnagtio uns. [sent-13, score-1.047]
</p><p>7 That is exponential time in the  worst case; most bit vector methods avoid explicitly computing it. [sent-16, score-0.364]
</p><p>8 c s 2o0c1ia0ti Aosnso focria Ctio nm fpourta Ctoiomnpault Laitniognuaislt Licisn,g puaigsetisc 1s512–1521, the observation that counting the number of one  bits in an integer is implemented in the basic instruction sets of many CPUs. [sent-39, score-0.442]
</p><p>9 The question then arises whether smaller codes would be obtained by relaxing zero preservation so that any resulting vector with at most λ bits is interpreted as failure, with λ ≥ 1. [sent-40, score-0.534]
</p><p>10 Penn (2002) generalized join-preserving encodings of partial orders to the case where more than one code can be used to represent the same object, but the focus there was on codes arising from successful unifications; there was still only one representative for failure. [sent-41, score-0.321]
</p><p>11 We note at the outset that we are not using Bloom filters as such, but rather a derandomized encoding scheme that shares with Bloom filters the essential insight that λ can be greater than zero without adverse consequences for the required algebraic properties of the encoding. [sent-43, score-0.349]
</p><p>12 un Wde or join tof v u, v ∈ X, eif th one exists, eaansdt u up v fbooru nthde greatest flo uw,ver ∈ ∈ bo Xu,n idf or meet. [sent-48, score-0.222]
</p><p>13 Iofrd weer rneeleadtio an s aencodn g pfoarrt iiatsl join operation. [sent-51, score-0.222]
</p><p>14 W foer are especially interested in a class of partial orders called meet semilattices, in which every pair of elements has a unique meet. [sent-52, score-0.372]
</p><p>15 In a meet semilattice, the join of two elements is unique when it exists at all, and there is a unique globally least element ⊥ (“bottom”). [sent-53, score-0.598]
</p><p>16 A successor of an element u ∈ X is an element v u ∈ Xes ssourch o fth aant u v v atn ud ∈th Xere i iss a no w ∈ Xnt wvi 6=th w u, w v, uan vd u v w v v, i. [sent-54, score-0.322]
</p><p>17 A meet irreducible element is an element u ∈ X such that for any v, w ∈ X, itf i u = v eum w tth uen ∈ u = v or u = w. [sent-60, score-0.39]
</p><p>18 2 Bit-vector encoding Intuitively, taking thejoin oftwo types in a type hierarchy is like taking the intersection of two sets. [sent-66, score-0.384]
</p><p>19 Types often represent sets of possible values, and the type represented by the join really does represent the intersection of the sets that formed the input. [sent-67, score-0.401]
</p><p>20 So it seems natural to embed a partial order of types hX, vi into a partial order (in fact, a lattice) otyfp seests h hY, ? [sent-68, score-0.271]
</p><p>21 Tt ohfen s join g ti sZ simply set hinet seurpseecrtsieotn r e∩la. [sent-71, score-0.222]
</p><p>22 th Terh a join exists, can be naturally defined by g(f(u) , f(v)) = 0 if and only if f(u) ∩ f(v) = ∅. [sent-73, score-0.222]
</p><p>23 They set Z to be the set of all meet irreducible elements in X; and f(u) = {v ∈ Z|v w u}, that is, the imne Xet ;ir arenddu fci(bule) e=lem {ven ∈ts greater th u}an, or equal htoe u. [sent-77, score-0.296]
</p><p>24 If Z is chosen to be the maximal elements of X instead, then join preservation is lost but the embedding still preserves order, success, and failure. [sent-79, score-0.6]
</p><p>25 We construct shorter bit vectors by modifying the definition of g, so that the minimality results 1513  no longer apply. [sent-85, score-0.344]
</p><p>26 Consider a meet semilattice containing only the bottom element ⊥ and n maximal elements all incomparable mtoe enatc ⊥h oatnhder n. [sent-89, score-0.603]
</p><p>27 We would thus be spending n bits to represent a choice among n + 1alterna-  tives, which should fit into a logarithmic number of bits. [sent-91, score-0.339]
</p><p>28 With the traditional bit vector construction, each of the maximal elements consumes its own bit, even though those bits are highly correlated. [sent-93, score-0.893]
</p><p>29 There, it is desired to store a large array of bits subject to two considerations. [sent-95, score-0.431]
</p><p>30 The solution proposed by Bloom and widely used in the decades since is to map the entries in the large bit array pseudorandomly (by means of a hash function) into the entries of a small bit array. [sent-98, score-0.73]
</p><p>31 To store a one bit we find its hashed location and store it there. [sent-99, score-0.472]
</p><p>32 If we query a bit for which the answer should be zero but it happens to have the  same hashed location as another query with the answer one, then we return a one and that is one of our tolerated errors. [sent-100, score-0.58]
</p><p>33 To reduce the error rate we can elaborate the construction further: with some fixed k, we use k hash functions to map each bit in the large array to several locations in the small one. [sent-101, score-0.433]
</p><p>34 There will be many collisions ofindividual hashed locations, as shown; but the chances are good that when we query a bit we did not intend to store in the filter, at least one of its hashed locations will still be empty, and so the query will  1? [sent-105, score-0.69]
</p><p>35 In general, the hashed array can be much smaller than the original unhashed array (Bloom, 1970). [sent-108, score-0.231]
</p><p>36 Classical Bloom filtering applied to the sparse vectors of the embedding would create some percentage of incorrect join results, which would then have to be handled by other techniques. [sent-109, score-0.364]
</p><p>37 2 Modified failure detection In the traditional bit vector construction, types map to sets, join is computed by intersection of sets, and the empty set corresponds to failure (where no join exists). [sent-112, score-1.129]
</p><p>38 In the traditional construction, to preserve joins we must assign one bit to each of the meet-irreducible elements {d, e, f,g, h, i,j,k, l, m}, for a total of teelenm m beintst. [sent-117, score-0.581]
</p><p>39 As a more general example, consider the very simple meet semilattice consisting of just a least element ⊥ with n maximal elements incomparabelleem mtoe neta c⊥h owtihtehr. [sent-120, score-0.55]
</p><p>40 his in b bits by choosing the smallest b such that ? [sent-122, score-0.385]
</p><p>41 Both their technique and ours are at a disadvantage when applied to large trees; in particular, if the bottom of the partial order has successors which are not joinable with each other, then those will be assigned large sets with little overlap, and bits in the vectors will tend to be wasted. [sent-132, score-0.83]
</p><p>42 To find the join of two types in the same module, we find the intersection of their encodings and check whether it is of size greater than λ. [sent-140, score-0.451]
</p><p>43 For the remaining cases, where at least one of the types lacks a module, we observe that the module bottoms and non-module types form a tree, and the join can be computed in that tree. [sent-142, score-0.421]
</p><p>44 If x is a type in the module whose bottom is y, and z has no module, then x t z = y t z unless y t z = y imn wdhuliceh, case x tt z = x; so uitn only y re tma zin =s t oy compute joins xw tithi zn =the x ;tre seo. [sent-143, score-0.265]
</p><p>45 3  Set programming  Ideally, we would like to have an efficient algorithm for finding the best possible encoding of any given meet semilattice. [sent-146, score-0.515]
</p><p>46 The encoding can be represented as a collection of sets of integers (representing bit indices that contain ones), and an optimal encoding is the collection of sets whose over-  all union is smallest subject to the constraint that the collection forms an encoding at all. [sent-147, score-1.172]
</p><p>47 The reduction of partial order representation to set programming is clear: we create a set variable for every type, force the maximal types’ sets to contain at least 1elements, and then use subset to enforce that every type is a superset of all its successors (preserving order and success). [sent-159, score-0.685]
</p><p>48 Gtiv xen a constraint satisfaction problem like this one, we can ask two questions: is there a feasible solution, assigning values to the variables so all constraints are satisfied; and if so what is the optimal solution, producing the best value of the objective while remaining feasible? [sent-163, score-0.302]
</p><p>49 Ongoing research on set programming has produced a variety of software tools for solving these  problems. [sent-167, score-0.236]
</p><p>50 However, at first blush our instances are much too large for readily-available set programming tools. [sent-168, score-0.247]
</p><p>51 1 Simplifying the instances First of all, we only use minimum cardinality constraints |Si | ≥ ri for maximal types; and every ri ≥ tλs 1. [sent-173, score-0.329]
</p><p>52 | G≥iv ren a feasible bit assignment for a ma≥xim λa +l type wiviethn more stihbalen ri te alessmiegnnmts einn tit fso set Si, we can always remove elements until it has exactly ri elements, without violating the other constraints. [sent-174, score-0.576]
</p><p>53 Now, let a choke-vertex in the partial order hX, vi be an element u ∈ X such that for every v, w ∈ Xn e wlemheerent v uis ∈ a successor aotf w a envdu v v, we ∈ha Xve u v w. [sent-180, score-0.349]
</p><p>54 Choke-vertices are important because the optimal bit assignment for elements after a chokevertex u is almost independent of the bit assign-  ment elsewhere in the partial order. [sent-185, score-0.85]
</p><p>55 Removing the redundant constraints means there are no constraints between elements after u and elements before, or incomparable with, u. [sent-186, score-0.426]
</p><p>56 As a result, we can solve a smaller instance consisting of u and everything after it, to find the minimal number of bits ru for representing u. [sent-188, score-0.339]
</p><p>57 Then we solve the rest of the problem with a constraint |Su | = ru, excluding arollb partial iothrde ar ceolenmsteranintst ta |fSter| u, an rd then combine the two solutions with any arbitrary bijection between the set elements assigned to u in each solution. [sent-189, score-0.284]
</p><p>58 2 Splitting into components If we cut the partial order at every choke-vertex, we reduce the huge and impractical encoding problem to a collection of smaller ones. [sent-192, score-0.312]
</p><p>59 The cutting expresses the original partial order as a tree of components, each of which corresponds to a set programming instance. [sent-193, score-0.29]
</p><p>60 We can find an optimal encoding for the entire partial order by optimally encoding the components, starting with the leaves of that tree and working our way back to the root. [sent-195, score-0.598]
</p><p>61 The division into components creates a collection of set programming instances with a wide range of sizes and difficulty; we examine each instance and choose appropriate techniques for each one. [sent-196, score-0.247]
</p><p>62 These include when λ = 0 regardless of the structure of the component; when the component consists of a bottom and zero, one, or two nonjoinable successors; and when there is one element (a top) greater than all other elements in the component. [sent-199, score-0.272]
</p><p>63 Definition 2 A unary leaf (UL) is an element x in a partial order hX, vi such that x is maximal and x pisa trhtiea successor of exactly one oxt ihser m ealxeimmeanlt a. [sent-214, score-0.419]
</p><p>64 Furthermore, ULs occur frequently in the partial orders we consider in practice; and by increasing the number of sets in an instance, they have a disproportionate effect on the difficulty of solv-  ing the set programming problem. [sent-217, score-0.366]
</p><p>65 We therefore implement a special solution process for instances containing ULs: we remove them all, solve the resulting instance, and then add them back one at a time while attempting to increase the overall number of elements as little as possible. [sent-218, score-0.233]
</p><p>66 In practical experiments, the solver generally either produces an optimal or very nearly optimal solution within a time limit on the order of ten minutes; or fails to produce a feasible solution at all, even with a much longer limit. [sent-220, score-0.477]
</p><p>67 n consists of finding the smallest b such that is at least k; that is the number of bits for th? [sent-224, score-0.417]
</p><p>68 To add a UL x as the successor of an element y without increasing the total number of bits, we must find a choice of λ + 1of the bits already assigned to y, sharing at most λ bits with any of y’s other successors. [sent-232, score-0.891]
</p><p>69 Our algorithm counts the subsets already covered, and compares that with the number of choices of λ + 1 bits from the bits assigned to y. [sent-235, score-0.678]
</p><p>70 If enough choices remain, we use them; otherwise, we add bits until there are enough choices. [sent-236, score-0.339]
</p><p>71 4  Solving  For instances with a small number of sets and relatively large number of elements in the sets, we use an exponential variable solver. [sent-238, score-0.296]
</p><p>72 This encodes the set programming problem into integer programming. [sent-239, score-0.256]
</p><p>73 The constraints translate into simple inequalities on sums of the variables; and the system of constraints can be solved with standard integer programming techniques. [sent-247, score-0.388]
</p><p>74 After solving the integer programming problem we can then assign elements arbitrarily 1517  to the appropriate combinations of sets. [sent-248, score-0.425]
</p><p>75 The wide domains of the variables may be advantageous for some integer programming solvers as well. [sent-251, score-0.483]
</p><p>76 However, it creates an integer programming problem of size exponential in  the number of sets. [sent-252, score-0.293]
</p><p>77 For more general set programming instances, we feed the instance directly into a solver designed for such problems. [sent-254, score-0.359]
</p><p>78 We used the ECLiPSe logic programming system (Cisco Systems, 2008), which offers several set programming solvers as libraries, and settled on the ic sets library. [sent-255, score-0.645]
</p><p>79 This is a straightforward set programming solver based on containment bounds. [sent-256, score-0.359]
</p><p>80 We extended the solver by adding a lightweight not-subset constraint, and customized heuristics for variable and value selection designed to guide the solver to a feasible solution as soon as possible. [sent-257, score-0.487]
</p><p>81 We choose variables near the top of the instance first, and prefer to assign values that share exactly λ bits with existing assigned values. [sent-258, score-0.384]
</p><p>82 We also do limited symmetry breaking, in that whenever we assign a bit not shared with any current assignment, the choice of bit is arbitrary so we assume it must be the lowestindex bit. [sent-259, score-0.554]
</p><p>83 The present work is primarily on the benefits  of nonzero λ, and so a detailed study of general set programming techniques would be inappropriate; but we made informal tests of several other set-programming solvers. [sent-261, score-0.26]
</p><p>84 We had hoped that a solver using containment-lexicographic hybrid bounds as described by Sadler and Gervet (Sadler and Gervet, 2008) would offer good performance, and chose the ECLiPSe framework partly to gain access to its ic hybrid sets implementation of such bounds. [sent-262, score-0.284]
</p><p>85 We also evaluated the Cardinal solver included in ECLiPSe, which offers stronger propagation of cardinality information; it lacked other needed features and seemed  no more efficient than ic sets. [sent-265, score-0.27]
</p><p>86 Solvers with available source code were preferred for ease of customization, and free solvers were preferred for economy, but a license for ILOG CPLEX (IBM, 2008) was available and we tried using it with the natural encoding of sets as vectors of binary variables. [sent-267, score-0.5]
</p><p>87 An instance with n sets of up to b bits, dense with pairwise constraints like subset and maximum intersection, requires Θ(n2b) variables when encoded into integer programming in the natural way. [sent-270, score-0.405]
</p><p>88 As a result, the ECLiPSe solver can process much larger instances than CPLEX without exhausting memory. [sent-274, score-0.224]
</p><p>89 In particular, the apparent superiority of λ = 0 for the synsem_min module should not be taken  as indicating that no higher λ could be better: rather, that module includes a very difficult set programming instance on which the solver failed and fell back to GAK. [sent-287, score-0.549]
</p><p>90 For the even larger modules, nonzero λ proved helpful despite solver failures, because of the bits saved by UL removal. [sent-288, score-0.576]
</p><p>91 for the modules where the solver is failing anyway. [sent-291, score-0.257]
</p><p>92 One important lesson seems to be that further work on set programming solvers would be bene-  ficial: any future more capable set programming solver could be applied to the unsolved instances and would be expected to save more bits. [sent-292, score-0.788]
</p><p>93 Table 3 and Figure 3 show the performance of the join query with various encodings. [sent-293, score-0.273]
</p><p>94 As well as testing the non-modular ERG encoding for different values of λ, we tested the modularized encoding with λ = 0 for all modules (to show the effect of modularization alone) and with λ chosen per-module to give the shortest vectors. [sent-295, score-0.637]
</p><p>95 The same implementation sufficed for all these tests, by means of putting all types in one module for the non-modular bit vectors or no types in any module for the pure lookup table. [sent-297, score-0.688]
</p><p>96 The non-modular encoding with λ = 0 is the basic encoding of A ¨ıt-Kaci et al. [sent-302, score-0.426]
</p><p>97 ture, using a technique first published by Weg-  ner (1960), requires time increasing with the number of nonzero bits it counts; and a similar effect would appear on a word-by-word basis even if we used a constant-time per-word count. [sent-308, score-0.447]
</p><p>98 In our experiments, λ = 9 gave the fastest joins for the non-modular encoding of the ERG. [sent-310, score-0.343]
</p><p>99 5  Conclusion  We have described a generalization of conventional bit vector concept lattice encoding techniques to the case where all vectors with λ or fewer one bits represent failure; traditional encodings are the case λ = 0. [sent-315, score-1.145]
</p><p>100 A good encoding requires a kind of perfect hash, the design of which maps naturally to constraint programming over sets of integers. [sent-317, score-0.503]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('bits', 0.339), ('bit', 0.277), ('bloom', 0.228), ('join', 0.222), ('encoding', 0.213), ('programming', 0.191), ('solvers', 0.182), ('successors', 0.174), ('solver', 0.168), ('eclipse', 0.139), ('erg', 0.136), ('encodings', 0.13), ('elements', 0.124), ('gak', 0.121), ('hashed', 0.121), ('si', 0.116), ('failure', 0.113), ('meet', 0.111), ('element', 0.109), ('uls', 0.106), ('sj', 0.106), ('successor', 0.104), ('partial', 0.099), ('module', 0.095), ('cplex', 0.091), ('joins', 0.091), ('modules', 0.089), ('modularization', 0.087), ('ul', 0.084), ('lookup', 0.082), ('embedding', 0.075), ('optimal', 0.073), ('maximal', 0.07), ('nonzero', 0.069), ('semilattice', 0.069), ('hash', 0.068), ('vectors', 0.067), ('constraints', 0.066), ('integer', 0.065), ('intersection', 0.063), ('preserves', 0.062), ('constraint', 0.061), ('irreducible', 0.061), ('cardinality', 0.059), ('feasible', 0.057), ('hx', 0.057), ('preserve', 0.056), ('instances', 0.056), ('array', 0.055), ('codes', 0.054), ('solution', 0.053), ('sx', 0.052), ('unification', 0.052), ('sadler', 0.052), ('query', 0.051), ('sk', 0.051), ('vector', 0.05), ('preservation', 0.047), ('filters', 0.046), ('smallest', 0.046), ('incomparable', 0.046), ('variables', 0.045), ('solving', 0.045), ('zero', 0.044), ('ic', 0.043), ('variable', 0.041), ('type', 0.04), ('hpsg', 0.04), ('fastest', 0.039), ('ri', 0.039), ('technique', 0.039), ('bottom', 0.039), ('removal', 0.039), ('orders', 0.038), ('sets', 0.038), ('exponential', 0.037), ('vi', 0.037), ('store', 0.037), ('types', 0.036), ('return', 0.036), ('lattice', 0.036), ('bounds', 0.035), ('bitwise', 0.035), ('carlsson', 0.035), ('clp', 0.035), ('cnfsat', 0.035), ('gervet', 0.035), ('ilog', 0.035), ('joinable', 0.035), ('modularized', 0.035), ('mtoe', 0.035), ('precomputation', 0.035), ('semilattices', 0.035), ('timeout', 0.035), ('stores', 0.034), ('construction', 0.033), ('traditional', 0.033), ('gerald', 0.033), ('least', 0.032), ('hierarchy', 0.032)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="7-tfidf-1" href="./acl-2010-A_Generalized-Zero-Preserving_Method_for_Compact_Encoding_of_Concept_Lattices.html">7 acl-2010-A Generalized-Zero-Preserving Method for Compact Encoding of Concept Lattices</a></p>
<p>Author: Matthew Skala ; Victoria Krakovna ; Janos Kramar ; Gerald Penn</p><p>Abstract: Constructing an encoding of a concept lattice using short bit vectors allows for efficient computation of join operations on the lattice. Join is the central operation any unification-based parser must support. We extend the traditional bit vector encoding, which represents join failure using the zero vector, to count any vector with less than a fixed number of one bits as failure. This allows non-joinable elements to share bits, resulting in a smaller vector size. A constraint solver is used to construct the encoding, and a variety of techniques are employed to find near-optimal solutions and handle timeouts. An evaluation is provided comparing the extended representation of failure with traditional bit vector techniques.</p><p>2 0.081446446 <a title="7-tfidf-2" href="./acl-2010-An_Exact_A%2A_Method_for_Deciphering_Letter-Substitution_Ciphers.html">29 acl-2010-An Exact A* Method for Deciphering Letter-Substitution Ciphers</a></p>
<p>Author: Eric Corlett ; Gerald Penn</p><p>Abstract: Letter-substitution ciphers encode a document from a known or hypothesized language into an unknown writing system or an unknown encoding of a known writing system. It is a problem that can occur in a number of practical applications, such as in the problem of determining the encodings of electronic documents in which the language is known, but the encoding standard is not. It has also been used in relation to OCR applications. In this paper, we introduce an exact method for deciphering messages using a generalization of the Viterbi algorithm. We test this model on a set of ciphers developed from various web sites, and find that our algorithm has the potential to be a viable, practical method for efficiently solving decipherment prob- lems.</p><p>3 0.079760268 <a title="7-tfidf-3" href="./acl-2010-Online_Generation_of_Locality_Sensitive_Hash_Signatures.html">183 acl-2010-Online Generation of Locality Sensitive Hash Signatures</a></p>
<p>Author: Benjamin Van Durme ; Ashwin Lall</p><p>Abstract: Motivated by the recent interest in streaming algorithms for processing large text collections, we revisit the work of Ravichandran et al. (2005) on using the Locality Sensitive Hash (LSH) method of Charikar (2002) to enable fast, approximate comparisons of vector cosine similarity. For the common case of feature updates being additive over a data stream, we show that LSH signatures can be maintained online, without additional approximation error, and with lower memory requirements than when using the standard offline technique.</p><p>4 0.073815808 <a title="7-tfidf-4" href="./acl-2010-Dynamic_Programming_for_Linear-Time_Incremental_Parsing.html">93 acl-2010-Dynamic Programming for Linear-Time Incremental Parsing</a></p>
<p>Author: Liang Huang ; Kenji Sagae</p><p>Abstract: Incremental parsing techniques such as shift-reduce have gained popularity thanks to their efficiency, but there remains a major problem: the search is greedy and only explores a tiny fraction of the whole space (even with beam search) as opposed to dynamic programming. We show that, surprisingly, dynamic programming is in fact possible for many shift-reduce parsers, by merging “equivalent” stacks based on feature values. Empirically, our algorithm yields up to a five-fold speedup over a state-of-the-art shift-reduce depen- dency parser with no loss in accuracy. Better search also leads to better learning, and our final parser outperforms all previously reported dependency parsers for English and Chinese, yet is much faster.</p><p>5 0.062435683 <a title="7-tfidf-5" href="./acl-2010-A_Risk_Minimization_Framework_for_Extractive_Speech_Summarization.html">14 acl-2010-A Risk Minimization Framework for Extractive Speech Summarization</a></p>
<p>Author: Shih-Hsiang Lin ; Berlin Chen</p><p>Abstract: In this paper, we formulate extractive summarization as a risk minimization problem and propose a unified probabilistic framework that naturally combines supervised and unsupervised summarization models to inherit their individual merits as well as to overcome their inherent limitations. In addition, the introduction of various loss functions also provides the summarization framework with a flexible but systematic way to render the redundancy and coherence relationships among sentences and between sentences and the whole document, respectively. Experiments on speech summarization show that the methods deduced from our framework are very competitive with existing summarization approaches. 1</p><p>6 0.061123502 <a title="7-tfidf-6" href="./acl-2010-Metadata-Aware_Measures_for_Answer_Summarization_in_Community_Question_Answering.html">171 acl-2010-Metadata-Aware Measures for Answer Summarization in Community Question Answering</a></p>
<p>7 0.059261337 <a title="7-tfidf-7" href="./acl-2010-Hard_Constraints_for_Grammatical_Function_Labelling.html">130 acl-2010-Hard Constraints for Grammatical Function Labelling</a></p>
<p>8 0.057817794 <a title="7-tfidf-8" href="./acl-2010-Contextualizing_Semantic_Representations_Using_Syntactically_Enriched_Vector_Models.html">70 acl-2010-Contextualizing Semantic Representations Using Syntactically Enriched Vector Models</a></p>
<p>9 0.055900995 <a title="7-tfidf-9" href="./acl-2010-Learning_Word-Class_Lattices_for_Definition_and_Hypernym_Extraction.html">166 acl-2010-Learning Word-Class Lattices for Definition and Hypernym Extraction</a></p>
<p>10 0.051572863 <a title="7-tfidf-10" href="./acl-2010-Grammar_Prototyping_and_Testing_with_the_LinGO_Grammar_Matrix_Customization_System.html">128 acl-2010-Grammar Prototyping and Testing with the LinGO Grammar Matrix Customization System</a></p>
<p>11 0.048796892 <a title="7-tfidf-11" href="./acl-2010-Open-Domain_Semantic_Role_Labeling_by_Modeling_Word_Spans.html">184 acl-2010-Open-Domain Semantic Role Labeling by Modeling Word Spans</a></p>
<p>12 0.048491303 <a title="7-tfidf-12" href="./acl-2010-Compositional_Matrix-Space_Models_of_Language.html">66 acl-2010-Compositional Matrix-Space Models of Language</a></p>
<p>13 0.048323374 <a title="7-tfidf-13" href="./acl-2010-Viterbi_Training_for_PCFGs%3A_Hardness_Results_and_Competitiveness_of_Uniform_Initialization.html">255 acl-2010-Viterbi Training for PCFGs: Hardness Results and Competitiveness of Uniform Initialization</a></p>
<p>14 0.047808833 <a title="7-tfidf-14" href="./acl-2010-Hierarchical_Search_for_Word_Alignment.html">133 acl-2010-Hierarchical Search for Word Alignment</a></p>
<p>15 0.04565401 <a title="7-tfidf-15" href="./acl-2010-Minimized_Models_and_Grammar-Informed_Initialization_for_Supertagging_with_Highly_Ambiguous_Lexicons.html">172 acl-2010-Minimized Models and Grammar-Informed Initialization for Supertagging with Highly Ambiguous Lexicons</a></p>
<p>16 0.04538881 <a title="7-tfidf-16" href="./acl-2010-String_Extension_Learning.html">217 acl-2010-String Extension Learning</a></p>
<p>17 0.045175888 <a title="7-tfidf-17" href="./acl-2010-Complexity_Metrics_in_an_Incremental_Right-Corner_Parser.html">65 acl-2010-Complexity Metrics in an Incremental Right-Corner Parser</a></p>
<p>18 0.044665199 <a title="7-tfidf-18" href="./acl-2010-Simple%2C_Accurate_Parsing_with_an_All-Fragments_Grammar.html">211 acl-2010-Simple, Accurate Parsing with an All-Fragments Grammar</a></p>
<p>19 0.044535458 <a title="7-tfidf-19" href="./acl-2010-The_Human_Language_Project%3A_Building_a_Universal_Corpus_of_the_World%27s_Languages.html">226 acl-2010-The Human Language Project: Building a Universal Corpus of the World's Languages</a></p>
<p>20 0.043909695 <a title="7-tfidf-20" href="./acl-2010-Understanding_the_Semantic_Structure_of_Noun_Phrase_Queries.html">245 acl-2010-Understanding the Semantic Structure of Noun Phrase Queries</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.151), (1, 0.004), (2, -0.013), (3, -0.036), (4, -0.006), (5, -0.053), (6, 0.038), (7, -0.01), (8, 0.035), (9, -0.017), (10, -0.062), (11, 0.029), (12, -0.008), (13, -0.037), (14, -0.074), (15, 0.018), (16, -0.01), (17, 0.024), (18, -0.046), (19, 0.067), (20, 0.03), (21, 0.017), (22, 0.015), (23, -0.055), (24, 0.054), (25, 0.002), (26, -0.03), (27, -0.016), (28, 0.001), (29, 0.009), (30, -0.017), (31, -0.005), (32, -0.053), (33, -0.007), (34, -0.03), (35, 0.044), (36, -0.074), (37, -0.058), (38, -0.014), (39, -0.02), (40, -0.001), (41, -0.026), (42, 0.101), (43, 0.02), (44, 0.029), (45, 0.003), (46, -0.098), (47, 0.062), (48, 0.059), (49, 0.072)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9422307 <a title="7-lsi-1" href="./acl-2010-A_Generalized-Zero-Preserving_Method_for_Compact_Encoding_of_Concept_Lattices.html">7 acl-2010-A Generalized-Zero-Preserving Method for Compact Encoding of Concept Lattices</a></p>
<p>Author: Matthew Skala ; Victoria Krakovna ; Janos Kramar ; Gerald Penn</p><p>Abstract: Constructing an encoding of a concept lattice using short bit vectors allows for efficient computation of join operations on the lattice. Join is the central operation any unification-based parser must support. We extend the traditional bit vector encoding, which represents join failure using the zero vector, to count any vector with less than a fixed number of one bits as failure. This allows non-joinable elements to share bits, resulting in a smaller vector size. A constraint solver is used to construct the encoding, and a variety of techniques are employed to find near-optimal solutions and handle timeouts. An evaluation is provided comparing the extended representation of failure with traditional bit vector techniques.</p><p>2 0.59742165 <a title="7-lsi-2" href="./acl-2010-Efficient_Staggered_Decoding_for_Sequence_Labeling.html">98 acl-2010-Efficient Staggered Decoding for Sequence Labeling</a></p>
<p>Author: Nobuhiro Kaji ; Yasuhiro Fujiwara ; Naoki Yoshinaga ; Masaru Kitsuregawa</p><p>Abstract: The Viterbi algorithm is the conventional decoding algorithm most widely adopted for sequence labeling. Viterbi decoding is, however, prohibitively slow when the label set is large, because its time complexity is quadratic in the number of labels. This paper proposes an exact decoding algorithm that overcomes this problem. A novel property of our algorithm is that it efficiently reduces the labels to be decoded, while still allowing us to check the optimality of the solution. Experiments on three tasks (POS tagging, joint POS tagging and chunking, and supertagging) show that the new algorithm is several orders of magnitude faster than the basic Viterbi and a state-of-the-art algo- rithm, CARPEDIEM (Esposito and Radicioni, 2009).</p><p>3 0.58123034 <a title="7-lsi-3" href="./acl-2010-Online_Generation_of_Locality_Sensitive_Hash_Signatures.html">183 acl-2010-Online Generation of Locality Sensitive Hash Signatures</a></p>
<p>Author: Benjamin Van Durme ; Ashwin Lall</p><p>Abstract: Motivated by the recent interest in streaming algorithms for processing large text collections, we revisit the work of Ravichandran et al. (2005) on using the Locality Sensitive Hash (LSH) method of Charikar (2002) to enable fast, approximate comparisons of vector cosine similarity. For the common case of feature updates being additive over a data stream, we show that LSH signatures can be maintained online, without additional approximation error, and with lower memory requirements than when using the standard offline technique.</p><p>4 0.5754149 <a title="7-lsi-4" href="./acl-2010-Optimal_Rank_Reduction_for_Linear_Context-Free_Rewriting_Systems_with_Fan-Out_Two.html">186 acl-2010-Optimal Rank Reduction for Linear Context-Free Rewriting Systems with Fan-Out Two</a></p>
<p>Author: Benoit Sagot ; Giorgio Satta</p><p>Abstract: Linear Context-Free Rewriting Systems (LCFRSs) are a grammar formalism capable of modeling discontinuous phrases. Many parsing applications use LCFRSs where the fan-out (a measure of the discontinuity of phrases) does not exceed 2. We present an efficient algorithm for optimal reduction of the length of production right-hand side in LCFRSs with fan-out at most 2. This results in asymptotical running time improvement for known parsing algorithms for this class.</p><p>5 0.56289792 <a title="7-lsi-5" href="./acl-2010-An_Exact_A%2A_Method_for_Deciphering_Letter-Substitution_Ciphers.html">29 acl-2010-An Exact A* Method for Deciphering Letter-Substitution Ciphers</a></p>
<p>Author: Eric Corlett ; Gerald Penn</p><p>Abstract: Letter-substitution ciphers encode a document from a known or hypothesized language into an unknown writing system or an unknown encoding of a known writing system. It is a problem that can occur in a number of practical applications, such as in the problem of determining the encodings of electronic documents in which the language is known, but the encoding standard is not. It has also been used in relation to OCR applications. In this paper, we introduce an exact method for deciphering messages using a generalization of the Viterbi algorithm. We test this model on a set of ciphers developed from various web sites, and find that our algorithm has the potential to be a viable, practical method for efficiently solving decipherment prob- lems.</p><p>6 0.54417241 <a title="7-lsi-6" href="./acl-2010-Complexity_Assumptions_in_Ontology_Verbalisation.html">64 acl-2010-Complexity Assumptions in Ontology Verbalisation</a></p>
<p>7 0.51748788 <a title="7-lsi-7" href="./acl-2010-Viterbi_Training_for_PCFGs%3A_Hardness_Results_and_Competitiveness_of_Uniform_Initialization.html">255 acl-2010-Viterbi Training for PCFGs: Hardness Results and Competitiveness of Uniform Initialization</a></p>
<p>8 0.49111283 <a title="7-lsi-8" href="./acl-2010-Hard_Constraints_for_Grammatical_Function_Labelling.html">130 acl-2010-Hard Constraints for Grammatical Function Labelling</a></p>
<p>9 0.48867658 <a title="7-lsi-9" href="./acl-2010-Tools_for_Multilingual_Grammar-Based_Translation_on_the_Web.html">235 acl-2010-Tools for Multilingual Grammar-Based Translation on the Web</a></p>
<p>10 0.48255923 <a title="7-lsi-10" href="./acl-2010-Plot_Induction_and_Evolutionary_Search_for_Story_Generation.html">196 acl-2010-Plot Induction and Evolutionary Search for Story Generation</a></p>
<p>11 0.48033628 <a title="7-lsi-11" href="./acl-2010-Compositional_Matrix-Space_Models_of_Language.html">66 acl-2010-Compositional Matrix-Space Models of Language</a></p>
<p>12 0.47903812 <a title="7-lsi-12" href="./acl-2010-Talking_NPCs_in_a_Virtual_Game_World.html">224 acl-2010-Talking NPCs in a Virtual Game World</a></p>
<p>13 0.4759447 <a title="7-lsi-13" href="./acl-2010-Combining_Data_and_Mathematical_Models_of_Language_Change.html">61 acl-2010-Combining Data and Mathematical Models of Language Change</a></p>
<p>14 0.4661054 <a title="7-lsi-14" href="./acl-2010-On_the_Computational_Complexity_of_Dominance_Links_in_Grammatical_Formalisms.html">182 acl-2010-On the Computational Complexity of Dominance Links in Grammatical Formalisms</a></p>
<p>15 0.46295643 <a title="7-lsi-15" href="./acl-2010-Identifying_Generic_Noun_Phrases.html">139 acl-2010-Identifying Generic Noun Phrases</a></p>
<p>16 0.45822367 <a title="7-lsi-16" href="./acl-2010-Learning_Word-Class_Lattices_for_Definition_and_Hypernym_Extraction.html">166 acl-2010-Learning Word-Class Lattices for Definition and Hypernym Extraction</a></p>
<p>17 0.45024812 <a title="7-lsi-17" href="./acl-2010-Simple%2C_Accurate_Parsing_with_an_All-Fragments_Grammar.html">211 acl-2010-Simple, Accurate Parsing with an All-Fragments Grammar</a></p>
<p>18 0.44877112 <a title="7-lsi-18" href="./acl-2010-Grammar_Prototyping_and_Testing_with_the_LinGO_Grammar_Matrix_Customization_System.html">128 acl-2010-Grammar Prototyping and Testing with the LinGO Grammar Matrix Customization System</a></p>
<p>19 0.44331062 <a title="7-lsi-19" href="./acl-2010-Complexity_Metrics_in_an_Incremental_Right-Corner_Parser.html">65 acl-2010-Complexity Metrics in an Incremental Right-Corner Parser</a></p>
<p>20 0.43793994 <a title="7-lsi-20" href="./acl-2010-Automatically_Generating_Term_Frequency_Induced_Taxonomies.html">43 acl-2010-Automatically Generating Term Frequency Induced Taxonomies</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.016), (25, 0.044), (39, 0.421), (42, 0.012), (44, 0.014), (59, 0.095), (73, 0.035), (78, 0.031), (80, 0.014), (83, 0.062), (84, 0.034), (98, 0.108)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.85554898 <a title="7-lda-1" href="./acl-2010-A_Generalized-Zero-Preserving_Method_for_Compact_Encoding_of_Concept_Lattices.html">7 acl-2010-A Generalized-Zero-Preserving Method for Compact Encoding of Concept Lattices</a></p>
<p>Author: Matthew Skala ; Victoria Krakovna ; Janos Kramar ; Gerald Penn</p><p>Abstract: Constructing an encoding of a concept lattice using short bit vectors allows for efficient computation of join operations on the lattice. Join is the central operation any unification-based parser must support. We extend the traditional bit vector encoding, which represents join failure using the zero vector, to count any vector with less than a fixed number of one bits as failure. This allows non-joinable elements to share bits, resulting in a smaller vector size. A constraint solver is used to construct the encoding, and a variety of techniques are employed to find near-optimal solutions and handle timeouts. An evaluation is provided comparing the extended representation of failure with traditional bit vector techniques.</p><p>2 0.81142759 <a title="7-lda-2" href="./acl-2010-%22Was_It_Good%3F_It_Was_Provocative.%22_Learning_the_Meaning_of_Scalar_Adjectives.html">2 acl-2010-"Was It Good? It Was Provocative." Learning the Meaning of Scalar Adjectives</a></p>
<p>Author: Marie-Catherine de Marneffe ; Christopher D. Manning ; Christopher Potts</p><p>Abstract: Texts and dialogues often express information indirectly. For instance, speakers’ answers to yes/no questions do not always straightforwardly convey a ‘yes’ or ‘no’ answer. The intended reply is clear in some cases (Was it good? It was great!) but uncertain in others (Was it acceptable? It was unprecedented.). In this paper, we present methods for interpreting the answers to questions like these which involve scalar modifiers. We show how to ground scalar modifier meaning based on data collected from the Web. We learn scales between modifiers and infer the extent to which a given answer conveys ‘yes’ or ‘no’ . To evaluate the methods, we collected examples of question–answer pairs involving scalar modifiers from CNN transcripts and the Dialog Act corpus and use response distributions from Mechanical Turk workers to assess the degree to which each answer conveys ‘yes’ or ‘no’ . Our experimental results closely match the Turkers’ response data, demonstrating that meanings can be learned from Web data and that such meanings can drive pragmatic inference.</p><p>3 0.76068705 <a title="7-lda-3" href="./acl-2010-On_Jointly_Recognizing_and_Aligning_Bilingual_Named_Entities.html">180 acl-2010-On Jointly Recognizing and Aligning Bilingual Named Entities</a></p>
<p>Author: Yufeng Chen ; Chengqing Zong ; Keh-Yih Su</p><p>Abstract: We observe that (1) how a given named entity (NE) is translated (i.e., either semantically or phonetically) depends greatly on its associated entity type, and (2) entities within an aligned pair should share the same type. Also, (3) those initially detected NEs are anchors, whose information should be used to give certainty scores when selecting candidates. From this basis, an integrated model is thus proposed in this paper to jointly identify and align bilingual named entities between Chinese and English. It adopts a new mapping type ratio feature (which is the proportion of NE internal tokens that are semantically translated), enforces an entity type consistency constraint, and utilizes additional monolingual candidate certainty factors (based on those NE anchors). The experi- ments show that this novel approach has substantially raised the type-sensitive F-score of identified NE-pairs from 68.4% to 81.7% (42.1% F-score imperfection reduction) in our Chinese-English NE alignment task.</p><p>4 0.74465322 <a title="7-lda-4" href="./acl-2010-Bucking_the_Trend%3A_Large-Scale_Cost-Focused_Active_Learning_for_Statistical_Machine_Translation.html">57 acl-2010-Bucking the Trend: Large-Scale Cost-Focused Active Learning for Statistical Machine Translation</a></p>
<p>Author: Michael Bloodgood ; Chris Callison-Burch</p><p>Abstract: We explore how to improve machine translation systems by adding more translation data in situations where we already have substantial resources. The main challenge is how to buck the trend of diminishing returns that is commonly encountered. We present an active learning-style data solicitation algorithm to meet this challenge. We test it, gathering annotations via Amazon Mechanical Turk, and find that we get an order of magnitude increase in performance rates of improvement.</p><p>5 0.44632345 <a title="7-lda-5" href="./acl-2010-Complexity_Metrics_in_an_Incremental_Right-Corner_Parser.html">65 acl-2010-Complexity Metrics in an Incremental Right-Corner Parser</a></p>
<p>Author: Stephen Wu ; Asaf Bachrach ; Carlos Cardenas ; William Schuler</p><p>Abstract: Hierarchical HMM (HHMM) parsers make promising cognitive models: while they use a bounded model of working memory and pursue incremental hypotheses in parallel, they still achieve parsing accuracies competitive with chart-based techniques. This paper aims to validate that a right-corner HHMM parser is also able to produce complexity metrics, which quantify a reader’s incremental difficulty in understanding a sentence. Besides defining standard metrics in the HHMM framework, a new metric, embedding difference, is also proposed, which tests the hypothesis that HHMM store elements represents syntactic working memory. Results show that HHMM surprisal outperforms all other evaluated metrics in predicting reading times, and that embedding difference makes a significant, independent contribution.</p><p>6 0.44224918 <a title="7-lda-6" href="./acl-2010-An_Exact_A%2A_Method_for_Deciphering_Letter-Substitution_Ciphers.html">29 acl-2010-An Exact A* Method for Deciphering Letter-Substitution Ciphers</a></p>
<p>7 0.43653858 <a title="7-lda-7" href="./acl-2010-Hard_Constraints_for_Grammatical_Function_Labelling.html">130 acl-2010-Hard Constraints for Grammatical Function Labelling</a></p>
<p>8 0.41664803 <a title="7-lda-8" href="./acl-2010-Minimized_Models_and_Grammar-Informed_Initialization_for_Supertagging_with_Highly_Ambiguous_Lexicons.html">172 acl-2010-Minimized Models and Grammar-Informed Initialization for Supertagging with Highly Ambiguous Lexicons</a></p>
<p>9 0.41245791 <a title="7-lda-9" href="./acl-2010-Dynamic_Programming_for_Linear-Time_Incremental_Parsing.html">93 acl-2010-Dynamic Programming for Linear-Time Incremental Parsing</a></p>
<p>10 0.41149813 <a title="7-lda-10" href="./acl-2010-Automatic_Generation_of_Story_Highlights.html">39 acl-2010-Automatic Generation of Story Highlights</a></p>
<p>11 0.40906072 <a title="7-lda-11" href="./acl-2010-Profiting_from_Mark-Up%3A_Hyper-Text_Annotations_for_Guided_Parsing.html">200 acl-2010-Profiting from Mark-Up: Hyper-Text Annotations for Guided Parsing</a></p>
<p>12 0.4071717 <a title="7-lda-12" href="./acl-2010-Extraction_and_Approximation_of_Numerical_Attributes_from_the_Web.html">113 acl-2010-Extraction and Approximation of Numerical Attributes from the Web</a></p>
<p>13 0.40683669 <a title="7-lda-13" href="./acl-2010-Filtering_Syntactic_Constraints_for_Statistical_Machine_Translation.html">115 acl-2010-Filtering Syntactic Constraints for Statistical Machine Translation</a></p>
<p>14 0.40586001 <a title="7-lda-14" href="./acl-2010-Using_Speech_to_Reply_to_SMS_Messages_While_Driving%3A_An_In-Car_Simulator_User_Study.html">254 acl-2010-Using Speech to Reply to SMS Messages While Driving: An In-Car Simulator User Study</a></p>
<p>15 0.40489262 <a title="7-lda-15" href="./acl-2010-The_Human_Language_Project%3A_Building_a_Universal_Corpus_of_the_World%27s_Languages.html">226 acl-2010-The Human Language Project: Building a Universal Corpus of the World's Languages</a></p>
<p>16 0.4041068 <a title="7-lda-16" href="./acl-2010-Efficient_Inference_through_Cascades_of_Weighted_Tree_Transducers.html">95 acl-2010-Efficient Inference through Cascades of Weighted Tree Transducers</a></p>
<p>17 0.40386018 <a title="7-lda-17" href="./acl-2010-Phrase-Based_Statistical_Language_Generation_Using_Graphical_Models_and_Active_Learning.html">194 acl-2010-Phrase-Based Statistical Language Generation Using Graphical Models and Active Learning</a></p>
<p>18 0.40310818 <a title="7-lda-18" href="./acl-2010-Preferences_versus_Adaptation_during_Referring_Expression_Generation.html">199 acl-2010-Preferences versus Adaptation during Referring Expression Generation</a></p>
<p>19 0.40222496 <a title="7-lda-19" href="./acl-2010-Automated_Planning_for_Situated_Natural_Language_Generation.html">35 acl-2010-Automated Planning for Situated Natural Language Generation</a></p>
<p>20 0.40189803 <a title="7-lda-20" href="./acl-2010-Creating_Robust_Supervised_Classifiers_via_Web-Scale_N-Gram_Data.html">76 acl-2010-Creating Robust Supervised Classifiers via Web-Scale N-Gram Data</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
