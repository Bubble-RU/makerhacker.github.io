<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>132 acl-2010-Hierarchical Joint Learning: Improving Joint Parsing and Named Entity Recognition with Non-Jointly Labeled Data</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-132" href="#">acl2010-132</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>132 acl-2010-Hierarchical Joint Learning: Improving Joint Parsing and Named Entity Recognition with Non-Jointly Labeled Data</h1>
<br/><p>Source: <a title="acl-2010-132-pdf" href="http://aclweb.org/anthology//P/P10/P10-1074.pdf">pdf</a></p><p>Author: Jenny Rose Finkel ; Christopher D. Manning</p><p>Abstract: One of the main obstacles to producing high quality joint models is the lack of jointly annotated data. Joint modeling of multiple natural language processing tasks outperforms single-task models learned from the same data, but still underperforms compared to single-task models learned on the more abundant quantities of available single-task annotated data. In this paper we present a novel model which makes use of additional single-task annotated data to improve the performance of a joint model. Our model utilizes a hierarchical prior to link the feature weights for shared features in several single-task models and the joint model. Experiments on joint parsing and named entity recog- nition, using the OntoNotes corpus, show that our hierarchical joint model can produce substantial gains over a joint model trained on only the jointly annotated data.</p><p>Reference: <a title="acl-2010-132-reference" href="../acl2010_reference/acl-2010-Hierarchical_Joint_Learning%3A_Improving_Joint_Parsing_and_Named_Entity_Recognition_with_Non-Jointly_Labeled_Data_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract One of the main obstacles to producing high quality joint models is the lack of jointly annotated data. [sent-4, score-0.556]
</p><p>2 In this paper we present a novel model which makes use of additional single-task annotated data to improve the performance of a joint model. [sent-6, score-0.495]
</p><p>3 Our model utilizes a hierarchical prior to link the feature weights for shared features in several single-task models and the joint model. [sent-7, score-0.995]
</p><p>4 Experiments on joint parsing and named entity recog-  nition, using the OntoNotes corpus, show that our hierarchical joint model can produce substantial gains over a joint model trained on only the jointly annotated data. [sent-8, score-2.304]
</p><p>5 1 Introduction Joint learning of multiple types of linguistic structure results in models which produce more consistent outputs, and for which performance improves across all aspects of the joint structure. [sent-9, score-0.432]
</p><p>6 These high-level systems typically combine the outputs from many low-level systems, such as parsing, named entity recognition (NER) and coreference resolution. [sent-11, score-0.547]
</p><p>7 When trained separately, these single-task models can produce outputs which are inconsistent with one another, such as named entities which do not correspond to any nodes in the parse tree (see Figure 1 for an example). [sent-12, score-0.558]
</p><p>8 Because a named entity should correspond to a node in the parse tree, strong evidence about either aspect of the model should positively impact the other aspect. [sent-14, score-0.761]
</p><p>9 However, designing joint models which actually improve performance has proven challenging. [sent-15, score-0.473]
</p><p>10 , 2008) was on joint parsing and semantic role labeling, but the best systems (Johansson and Nugues, 2008) were the ones which completely decoupled the tasks. [sent-17, score-0.478]
</p><p>11 While negative results are rarely published, this was not the first failed attempt at joint parsing and semantic role labeling (Sutton and McCallum, 2005). [sent-18, score-0.478]
</p><p>12 There have been some recent successes with joint modeling. [sent-19, score-0.37]
</p><p>13 Zhang and Clark (2008) built a perceptron-based joint segmenter and part-of-speech (POS) tagger for Chinese, and Toutanova and Cherry (2009) learned a joint model of lemmatization and POS tagging which outperformed a pipelined model. [sent-20, score-0.858]
</p><p>14 Adler and Elhadad (2006) presented an HMMbased approach for unsupervised joint morphological segmentation and tagging of Hebrew, and  Goldberg and Tsarfaty (2008) developed a joint model of segmentation, tagging and parsing ofHebrew, based on lattice parsing. [sent-21, score-0.967]
</p><p>15 No discussion of joint modeling would be complete without mention of (Miller et al. [sent-22, score-0.409]
</p><p>16 , 2000), who trained a Collinsstyle generative parser (Collins, 1997) over a syntactic structure augmented with the template entity and template relations annotations for the MUC-7 shared task. [sent-23, score-0.34]
</p><p>17 One significant limitation for many joint models is the lack of jointly annotated data. [sent-24, score-0.556]
</p><p>18 We built a joint model of parsing and named entity recognition (Finkel and Manning, 2009b), which had small gains on parse performance and moderate gains on named entity performance, when compared with single-task models trained on the same data. [sent-25, score-1.915]
</p><p>19 , 2006), fell short of separate parsing and named 720  Proce dinUgsp osfa tlhae, 4S8wthed Aen n,u 1a1l-1 M6e Jeutilnyg 2 o0f1 t0h. [sent-27, score-0.361]
</p><p>20 entity models trained on larger corpora, annotated with only one type of information. [sent-30, score-0.381]
</p><p>21 This paper addresses the problem of how to learn high-quality joint models with smaller quantities of jointly-annotated data that has been augmented with larger amounts of single-task annotated data. [sent-31, score-0.539]
</p><p>22 We use a hierarchical prior to link a joint model trained on jointly-annotated data with other single-task models trained on single-task annotated data. [sent-33, score-0.956]
</p><p>23 The key to making this work is for the joint model to share some features with each of the single-task models. [sent-34, score-0.496]
</p><p>24 Then, the singly-annotated data can be used to influence the feature weights for the shared features in the joint model. [sent-35, score-0.536]
</p><p>25 This is an important contribution, because it provides all the benefits of joint modeling, but without the high cost of jointly annotating large corpora. [sent-36, score-0.451]
</p><p>26 We applied our hierarchical joint model to parsing and named entity recognition, and it reduced errors by over 20% on both tasks when compared to a joint model trained on only the jointly annotated data. [sent-37, score-1.88]
</p><p>27 Many schemes for multitask learning, including the one we use here, are instances of hierarchical models. [sent-39, score-0.272]
</p><p>28 (2005) applied a hierarchical prior to modeling exam scores of students. [sent-45, score-0.354]
</p><p>29 3 Hierarchical Joint Learning In this section we will discuss the main contribution of this paper, our hierarchical joint model which improves joint modeling performance through the use of single-task models which can be trained on singly-annotated data. [sent-51, score-1.18]
</p><p>30 Our experiments are on a joint parsing and named  entity task, but the technique is more general and only requires that the base models (the joint model and single-task models) share some features. [sent-52, score-1.555]
</p><p>31 This section covers the general technique, and we will cover the details of the parsing, named entity, and joint models that we use in Section 4. [sent-53, score-0.685]
</p><p>32 1 Intuitive Overview As discussed, we have a joint model which requires jointly-annotated data, and several singletask models which only require singly-annotated data. [sent-55, score-0.514]
</p><p>33 The key to our hierarchical model is that the joint model must have features in common with each of the single models, though it can also have features which are only present in the joint model. [sent-56, score-1.207]
</p><p>34 721  Figure 2: A graphical representation of our hierarchical joint model. [sent-57, score-0.585]
</p><p>35 There are separate base models for just parsing, just NER, and joint parsing and NER. [sent-58, score-0.616]
</p><p>36 The parameters for these models are linked via a hierarchical prior. [sent-59, score-0.355]
</p><p>37 However, parameters for the which are shared between the single-task and the joint model are able to influence  (feature features models one an-  other via a hierarchical prior. [sent-61, score-0.851]
</p><p>38 After training has been completed, we retain only the joint model’s parameters. [sent-63, score-0.37]
</p><p>39 Our resulting joint model is of higher quality than a comparable joint model trained on only thejointly-annotated data, due to all ofthe evidence provided by the additional single-task data. [sent-64, score-0.988]
</p><p>40 2  Formal Model  We have a set M of three base models: a pWarese h-oanvely am soedtel M, Man o fNE thRre-eon blya emo mdeold alsn:d a joint model. [sent-66, score-0.446]
</p><p>41 , parse features in the named entity model) will always be zero, so their weights have no impact on that  model’s likelihood function. [sent-72, score-0.744]
</p><p>42 Conversely, allowing the presence of those features in models for which they do not apply will not influence their weights in the other models because there will be no evidence about them in the data. [sent-73, score-0.268]
</p><p>43 These three models are linked by a hierarchical prior, and their feature weight vectors are all drawn from this prior. [sent-74, score-0.382]
</p><p>44 The parameters θ∗ for this prior have the same dimensionality as th∗e model-specific parameters θm and are drawn from another, top-level prior. [sent-75, score-0.297]
</p><p>45 1 The graphical representation of our hierarchical model is shown in Figure 2. [sent-77, score-0.297]
</p><p>46 The final∗ summation in the equation computes the prior likelihood of the top-level parameters θ∗ according to a Gaussian prior with variance σ∗ an∗d mean (typically zero). [sent-80, score-0.411]
</p><p>47 This formulation∗ encourages each base model to have feature weights similar to the top-level parameters (and hence one another). [sent-81, score-0.358]
</p><p>48 We need to compute partial derivatives in order to optimize the model parameters. [sent-88, score-0.481]
</p><p>49 The partial derivatives for the top level parameters θ∗ are:  ∂Lh∂ierθ(∗D,i;θ)= Xθ∗,iσ−2m θm,i! [sent-91, score-0.477]
</p><p>50 3  Optimization with Stochastic Gradient Descent  Inference in joint models tends to be slow, and often requires the use of stochastic optimization in order for the optimization to be tractable. [sent-96, score-0.622]
</p><p>51 L-BFGS and gradient descent, two frequently used numerical optimization algorithms, require computing the value and partial derivatives of the objective function using the entire training set. [sent-97, score-0.604]
</p><p>52 In most NLP models, such as lo-  gistic regression with a Gaussian prior, computing the stochastic objective function is fairly straightforward: you compute the model likelihood and partial derivatives for a randomly sampled subset of the training data. [sent-100, score-0.738]
</p><p>53 When computing the term for the prior, it must be rescaled by multiplying its value and derivatives by the proportion of the training data used. [sent-101, score-0.32]
</p><p>54 he W chrietnical fact to keep ibn mind is that the summed values and partial derivatives for any split of the data need to be equal to that of the full dataset. [sent-104, score-0.399]
</p><p>55 In practice, stochastic gradient descent only makes use of the partial derivatives and not the function value, so we will focus the remainder of the discussion on  how to rescale the partial derivatives. [sent-105, score-0.914]
</p><p>56 We now describe the more complicated case of stochastic optimization with a hierarchical objective function. [sent-106, score-0.427]
</p><p>57 For the sampled datum d, we then compute the function value and partial derivatives with respect to the correct base model for that datum. [sent-110, score-0.756]
</p><p>58 When we rescale the model-specific prior, we rescale based on the number of data in that model’s training set, not the total number of data in all the models combined. [sent-111, score-0.296]
</p><p>59 The stochSastic partial derivatives will equal zero for all model parameters θm such that m m(d), and for θm(d) it becomes:  |Db|  =  ∂Lh∂ieθr-smtoc(dh()D,i;θ)=  (5)  µ  ∂Lm(d∂)(θm{d(d});,iθm(d))−|Dm1(d)|? [sent-113, score-0.604]
</p><p>60 Now we will discuss the stochastic partial derivatives with respect to the top-level parameters θ∗, which requires modifying Equation 3. [sent-115, score-0.587]
</p><p>61 In the stochastic derivative we only perform this computation for the datum’s model m(d), and then we rescale that value based on the number ofdata in that datum’s model |Dm(d) |. [sent-117, score-0.455]
</p><p>62 The stochastic partial derivatives with respect to θ∗ become:  ∂Lhier-∂sθtoc∗h,(iD;θ)=  (6)  |Dm1(d)|? [sent-120, score-0.509]
</p><p>63 An equally correct formulation for the partial derivative of θ∗ is to simply rescale Equation 3 by the total nu∗mber of data in all models. [sent-125, score-0.299]
</p><p>64 4  Base Models  Our hierarchical joint model is composed of three separate models, one for just named entity recognition, one for just parsing, and one for joint parsing and named entity recognition. [sent-133, score-2.119]
</p><p>65 1 Semi-CRF for Named Entity Recognition For our named entity recognition model we use a  semi-CRF (Sarawagi and Cohen, 2004; Andrew, 2006). [sent-136, score-0.629]
</p><p>66 When doing named entity recognition, a semi-CRF will have one node for each entity, unlike a regular CRF which will have one node for each word. [sent-139, score-0.569]
</p><p>67 Note that the entity Hilary Clinton has one node in the semi-CRF representation, but two nodes in the linear-chain CRF. [sent-141, score-0.275]
</p><p>68 724 FRAG  INTJ UH  NP NP  NP PP  JJ  NN  LikeDaTgNro sIoNfDT-MaONQEPY-MiOCNEDY-bM-iNlOiPoN-nMEYO-iNEYN Sd-oMlaOrNsEY-ilastyear  Figure 4: An example of a sentence jointly annotated with parse and named entity information. [sent-156, score-0.72]
</p><p>69 Named entities correspond to nodes in the tree, and the parse label is augmented with the named entity informa-  tion. [sent-157, score-0.707]
</p><p>70 Because  we use a tree representation,  it is  easy to ensure that the features used in the NER model are identical to those in the joint parsing  and named entity model, because the joint model (which we will discuss in Section 4. [sent-158, score-1.588]
</p><p>71 3) is also based on a tree representation where each entity corresponds to a single node in the tree. [sent-159, score-0.32]
</p><p>72 The partition function is given by:  Zs  = X Xexp{θ · f(r,s)}  t′∈Xτ(s) rX∈t′ We also need to compute the partial derivatives which are used during optimization. [sent-169, score-0.474]
</p><p>73 The partial derivatives of θ are then given by  ∂∂Lθi=(tX,s)∈D ? [sent-171, score-0.399]
</p><p>74 (10) Just like with a linear-chain CRF, this equation will be zero when the feature expectations in the model equal the feature values in the training data. [sent-174, score-0.292]
</p><p>75 3  Joint Model of Parsing and Named Entity Recognition Our base joint model for parsing and named entity recognition is the same as (Finkel and Manning, 2009b), which is also based on the discriminative parser discussed in the previous section. [sent-179, score-1.183]
</p><p>76 The parse tree structure is augmented with named entity information; see Figure 4 for an example. [sent-180, score-0.705]
</p><p>77 The features in the joint model are designed in a manner that fits well with the hierarchical joint model: some are over just the parse structure, some are over just the named entities, and some are over the joint structure. [sent-181, score-1.813]
</p><p>78 The joint model shares the NER and parse features with the respective single-task models. [sent-182, score-0.605]
</p><p>79 Features over the joint structure only appear in the joint model, and their weights are only indirectly influenced by the singly-annotated data. [sent-183, score-0.798]
</p><p>80 In the joint model, the grammar is augmented with ad725  Training Range # Sent. [sent-185, score-0.434]
</p><p>81 ditional joint rules which are composed by adding named entity information to existing parse rules. [sent-189, score-0.966]
</p><p>82 Earlier we said that the NER-only model uses  identical named entity features as the joint model (and similarly for the parse-only model), but this is not quite true. [sent-192, score-1.065]
</p><p>83 For instance, the NER-only model may have word=Nigel as a feature, but because Nigel never occurs in the joint data, that feature is never manifested and no weight is learned for it. [sent-194, score-0.516]
</p><p>84 We deal with this similarly to how we dealt with the grammar: if a named entity feature occurs in either the joint data or the NER-only data, then both models will learn a weight for that feature. [sent-195, score-0.983]
</p><p>85 This modeling decision gives the joint model access to potentially useful features to which it would not have had access if it were not part of the hierarchical model. [sent-197, score-0.75]
</p><p>86 5 5 Experiments and Discussion We compared our hierarchical joint model to a regular (non-hierarchical) joint model, and to parseonly and NER-only models. [sent-198, score-1.037]
</p><p>87 , 2006), and made the same data modifications as (Finkel and Manning, 2009b) to ensure consistency between the parsing and named entity annotations. [sent-203, score-0.595]
</p><p>88 For each section of the data (ABC, MNB, NBC, PRI, VOA) we ran experiments training a linear-chain CRF on only the named entity information, a CRF-CFG parser on only the parse information, a joint parser and named entity recognizer, and our hierarchical model. [sent-205, score-1.668]
</p><p>89 For the hierarchical model, we used the CNN portion of the data (5093 sentences) for the extra named entity data (and ignored the parse trees) and the remaining portions combined for the extra parse data (and ignored the named entity an-  notations). [sent-206, score-1.483]
</p><p>90 As Table 2 shows, the hierarchical model did substantially better than the joint model overall, which is not surprising given the extra data to which it had access. [sent-213, score-0.787]
</p><p>91 One general trend, which is not surprising, is that the  hierarchical model helps the smaller datasets more than the large ones. [sent-218, score-0.297]
</p><p>92 Parse trees were evaluated using evalB, and  named entities were scored using micro-averaged F-measure (conlleval). [sent-313, score-0.3]
</p><p>93 –  –  6 Conclusion In this paper we presented a novel method for improving joint modeling using additional data which has not been labeled with the entire joint structure. [sent-316, score-0.779]
</p><p>94 We built single-task models for the non-jointly labeled data, designing those single-task models so that they have features  in common with the joint model, and then linked all of the different single-task and joint models via a hierarchical prior. [sent-318, score-1.226]
</p><p>95 We performed experiments on joint parsing and named entity recognition, and found that our hierarchical joint model substantially outperformed a joint model which was trained on only the jointly annotated data. [sent-319, score-2.25]
</p><p>96 Future directions for this work include automatically learning the variances, σm and σ∗ in the hierarchical model, so that the degree of in∗formation sharing between the models is optimized based on the training data available. [sent-320, score-0.277]
</p><p>97 We are also interested in ways to modify the objective function to place more emphasis on learning a good joint model, instead of equally weighting the learning of the joint and single-task models. [sent-321, score-0.841]
</p><p>98 A single generative model for joint morphological segmentation and syntactic parsing. [sent-408, score-0.489]
</p><p>99 The CoNLL-2008 shared task on joint parsing of syntactic and semantic  dependencies. [sent-431, score-0.478]
</p><p>100 A global model for joint lemmatization and part-of-speech prediction. [sent-439, score-0.488]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('joint', 0.37), ('derivatives', 0.281), ('named', 0.253), ('entity', 0.234), ('hierarchical', 0.215), ('finkel', 0.171), ('ner', 0.167), ('datum', 0.16), ('crf', 0.129), ('partial', 0.118), ('rescale', 0.117), ('stochastic', 0.11), ('parse', 0.109), ('parsing', 0.108), ('hilary', 0.107), ('prior', 0.1), ('zs', 0.094), ('ontonotes', 0.091), ('gelman', 0.086), ('model', 0.082), ('jointly', 0.081), ('dm', 0.081), ('haiti', 0.08), ('mnb', 0.08), ('nbc', 0.08), ('voa', 0.08), ('jenny', 0.078), ('parameters', 0.078), ('rose', 0.076), ('base', 0.076), ('clinton', 0.073), ('descent', 0.067), ('gradient', 0.064), ('variances', 0.064), ('derivative', 0.064), ('feature', 0.064), ('augmented', 0.064), ('gaussian', 0.063), ('models', 0.062), ('objective', 0.062), ('manning', 0.061), ('pri', 0.06), ('recognition', 0.06), ('weights', 0.058), ('cnn', 0.057), ('multitask', 0.057), ('gains', 0.054), ('elidan', 0.053), ('evgeniou', 0.053), ('frag', 0.053), ('intj', 0.053), ('segment', 0.053), ('summation', 0.05), ('db', 0.05), ('johansson', 0.05), ('np', 0.049), ('visited', 0.049), ('yi', 0.048), ('entities', 0.047), ('batch', 0.047), ('uh', 0.047), ('hmeo', 0.047), ('goldberg', 0.046), ('likelihood', 0.046), ('tree', 0.045), ('zero', 0.045), ('adjacent', 0.044), ('features', 0.044), ('annotated', 0.043), ('jj', 0.043), ('dh', 0.043), ('sarawagi', 0.043), ('trained', 0.042), ('evidence', 0.042), ('drawn', 0.041), ('designing', 0.041), ('segmentations', 0.041), ('saw', 0.041), ('node', 0.041), ('nn', 0.04), ('optimization', 0.04), ('abc', 0.04), ('modeling', 0.039), ('function', 0.039), ('term', 0.039), ('ando', 0.038), ('daphne', 0.038), ('adler', 0.038), ('lm', 0.038), ('extra', 0.038), ('segmentation', 0.037), ('equation', 0.037), ('conll', 0.037), ('nigel', 0.036), ('ys', 0.036), ('lemmatization', 0.036), ('lh', 0.036), ('christopher', 0.036), ('partition', 0.036), ('subtree', 0.036)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000008 <a title="132-tfidf-1" href="./acl-2010-Hierarchical_Joint_Learning%3A_Improving_Joint_Parsing_and_Named_Entity_Recognition_with_Non-Jointly_Labeled_Data.html">132 acl-2010-Hierarchical Joint Learning: Improving Joint Parsing and Named Entity Recognition with Non-Jointly Labeled Data</a></p>
<p>Author: Jenny Rose Finkel ; Christopher D. Manning</p><p>Abstract: One of the main obstacles to producing high quality joint models is the lack of jointly annotated data. Joint modeling of multiple natural language processing tasks outperforms single-task models learned from the same data, but still underperforms compared to single-task models learned on the more abundant quantities of available single-task annotated data. In this paper we present a novel model which makes use of additional single-task annotated data to improve the performance of a joint model. Our model utilizes a hierarchical prior to link the feature weights for shared features in several single-task models and the joint model. Experiments on joint parsing and named entity recog- nition, using the OntoNotes corpus, show that our hierarchical joint model can produce substantial gains over a joint model trained on only the jointly annotated data.</p><p>2 0.14121346 <a title="132-tfidf-2" href="./acl-2010-Domain_Adaptation_of_Maximum_Entropy_Language_Models.html">91 acl-2010-Domain Adaptation of Maximum Entropy Language Models</a></p>
<p>Author: Tanel Alumae ; Mikko Kurimo</p><p>Abstract: We investigate a recently proposed Bayesian adaptation method for building style-adapted maximum entropy language models for speech recognition, given a large corpus of written language data and a small corpus of speech transcripts. Experiments show that the method consistently outperforms linear interpolation which is typically used in such cases.</p><p>3 0.13292567 <a title="132-tfidf-3" href="./acl-2010-An_Entity-Level_Approach_to_Information_Extraction.html">28 acl-2010-An Entity-Level Approach to Information Extraction</a></p>
<p>Author: Aria Haghighi ; Dan Klein</p><p>Abstract: We present a generative model of template-filling in which coreference resolution and role assignment are jointly determined. Underlying template roles first generate abstract entities, which in turn generate concrete textual mentions. On the standard corporate acquisitions dataset, joint resolution in our entity-level model reduces error over a mention-level discriminative approach by up to 20%.</p><p>4 0.13104877 <a title="132-tfidf-4" href="./acl-2010-Joint_Syntactic_and_Semantic_Parsing_of_Chinese.html">153 acl-2010-Joint Syntactic and Semantic Parsing of Chinese</a></p>
<p>Author: Junhui Li ; Guodong Zhou ; Hwee Tou Ng</p><p>Abstract: This paper explores joint syntactic and semantic parsing of Chinese to further improve the performance of both syntactic and semantic parsing, in particular the performance of semantic parsing (in this paper, semantic role labeling). This is done from two levels. Firstly, an integrated parsing approach is proposed to integrate semantic parsing into the syntactic parsing process. Secondly, semantic information generated by semantic parsing is incorporated into the syntactic parsing model to better capture semantic information in syntactic parsing. Evaluation on Chinese TreeBank, Chinese PropBank, and Chinese NomBank shows that our integrated parsing approach outperforms the pipeline parsing approach on n-best parse trees, a natural extension of the widely used pipeline parsing approach on the top-best parse tree. Moreover, it shows that incorporating semantic role-related information into the syntactic parsing model significantly improves the performance of both syntactic parsing and semantic parsing. To our best knowledge, this is the first research on exploring syntactic parsing and semantic role labeling for both verbal and nominal predicates in an integrated way. 1</p><p>5 0.1309936 <a title="132-tfidf-5" href="./acl-2010-Arabic_Named_Entity_Recognition%3A_Using_Features_Extracted_from_Noisy_Data.html">32 acl-2010-Arabic Named Entity Recognition: Using Features Extracted from Noisy Data</a></p>
<p>Author: Yassine Benajiba ; Imed Zitouni ; Mona Diab ; Paolo Rosso</p><p>Abstract: Building an accurate Named Entity Recognition (NER) system for languages with complex morphology is a challenging task. In this paper, we present research that explores the feature space using both gold and bootstrapped noisy features to build an improved highly accurate Arabic NER system. We bootstrap noisy features by projection from an Arabic-English parallel corpus that is automatically tagged with a baseline NER system. The feature space covers lexical, morphological, and syntactic features. The proposed approach yields an improvement of up to 1.64 F-measure (absolute).</p><p>6 0.12637231 <a title="132-tfidf-6" href="./acl-2010-Jointly_Optimizing_a_Two-Step_Conditional_Random_Field_Model_for_Machine_Transliteration_and_Its_Fast_Decoding_Algorithm.html">154 acl-2010-Jointly Optimizing a Two-Step Conditional Random Field Model for Machine Transliteration and Its Fast Decoding Algorithm</a></p>
<p>7 0.10853906 <a title="132-tfidf-7" href="./acl-2010-Hierarchical_Search_for_Word_Alignment.html">133 acl-2010-Hierarchical Search for Word Alignment</a></p>
<p>8 0.10799546 <a title="132-tfidf-8" href="./acl-2010-Learning_Common_Grammar_from_Multilingual_Corpus.html">162 acl-2010-Learning Common Grammar from Multilingual Corpus</a></p>
<p>9 0.10598299 <a title="132-tfidf-9" href="./acl-2010-Coreference_Resolution_across_Corpora%3A_Languages%2C_Coding_Schemes%2C_and_Preprocessing_Information.html">72 acl-2010-Coreference Resolution across Corpora: Languages, Coding Schemes, and Preprocessing Information</a></p>
<p>10 0.10505691 <a title="132-tfidf-10" href="./acl-2010-Structural_Semantic_Relatedness%3A_A_Knowledge-Based_Method_to_Named_Entity_Disambiguation.html">218 acl-2010-Structural Semantic Relatedness: A Knowledge-Based Method to Named Entity Disambiguation</a></p>
<p>11 0.10430568 <a title="132-tfidf-11" href="./acl-2010-Phylogenetic_Grammar_Induction.html">195 acl-2010-Phylogenetic Grammar Induction</a></p>
<p>12 0.10312661 <a title="132-tfidf-12" href="./acl-2010-Practical_Very_Large_Scale_CRFs.html">197 acl-2010-Practical Very Large Scale CRFs</a></p>
<p>13 0.10195299 <a title="132-tfidf-13" href="./acl-2010-Generating_Templates_of_Entity_Summaries_with_an_Entity-Aspect_Model_and_Pattern_Mining.html">125 acl-2010-Generating Templates of Entity Summaries with an Entity-Aspect Model and Pattern Mining</a></p>
<p>14 0.10185795 <a title="132-tfidf-14" href="./acl-2010-Open-Domain_Semantic_Role_Labeling_by_Modeling_Word_Spans.html">184 acl-2010-Open-Domain Semantic Role Labeling by Modeling Word Spans</a></p>
<p>15 0.10124435 <a title="132-tfidf-15" href="./acl-2010-Distributional_Similarity_vs._PU_Learning_for_Entity_Set_Expansion.html">89 acl-2010-Distributional Similarity vs. PU Learning for Entity Set Expansion</a></p>
<p>16 0.09976349 <a title="132-tfidf-16" href="./acl-2010-Hierarchical_Sequential_Learning_for_Extracting_Opinions_and_Their_Attributes.html">134 acl-2010-Hierarchical Sequential Learning for Extracting Opinions and Their Attributes</a></p>
<p>17 0.096574023 <a title="132-tfidf-17" href="./acl-2010-Efficient_Optimization_of_an_MDL-Inspired_Objective_Function_for_Unsupervised_Part-Of-Speech_Tagging.html">96 acl-2010-Efficient Optimization of an MDL-Inspired Objective Function for Unsupervised Part-Of-Speech Tagging</a></p>
<p>18 0.095436245 <a title="132-tfidf-18" href="./acl-2010-Learning_to_Translate_with_Source_and_Target_Syntax.html">169 acl-2010-Learning to Translate with Source and Target Syntax</a></p>
<p>19 0.094575815 <a title="132-tfidf-19" href="./acl-2010-Word_Representations%3A_A_Simple_and_General_Method_for_Semi-Supervised_Learning.html">263 acl-2010-Word Representations: A Simple and General Method for Semi-Supervised Learning</a></p>
<p>20 0.086620741 <a title="132-tfidf-20" href="./acl-2010-A_Joint_Rule_Selection_Model_for_Hierarchical_Phrase-Based_Translation.html">9 acl-2010-A Joint Rule Selection Model for Hierarchical Phrase-Based Translation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.271), (1, -0.002), (2, 0.045), (3, -0.016), (4, -0.06), (5, 0.014), (6, 0.029), (7, -0.021), (8, 0.066), (9, 0.053), (10, -0.076), (11, -0.065), (12, 0.068), (13, -0.146), (14, -0.063), (15, -0.049), (16, -0.062), (17, 0.081), (18, 0.084), (19, -0.087), (20, -0.023), (21, 0.013), (22, -0.08), (23, 0.097), (24, -0.129), (25, -0.02), (26, 0.055), (27, -0.047), (28, 0.129), (29, -0.088), (30, -0.023), (31, 0.041), (32, -0.026), (33, -0.022), (34, -0.053), (35, 0.133), (36, -0.17), (37, 0.131), (38, -0.105), (39, -0.075), (40, -0.003), (41, 0.089), (42, -0.1), (43, 0.037), (44, -0.099), (45, 0.087), (46, 0.057), (47, 0.079), (48, -0.008), (49, 0.079)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97339928 <a title="132-lsi-1" href="./acl-2010-Hierarchical_Joint_Learning%3A_Improving_Joint_Parsing_and_Named_Entity_Recognition_with_Non-Jointly_Labeled_Data.html">132 acl-2010-Hierarchical Joint Learning: Improving Joint Parsing and Named Entity Recognition with Non-Jointly Labeled Data</a></p>
<p>Author: Jenny Rose Finkel ; Christopher D. Manning</p><p>Abstract: One of the main obstacles to producing high quality joint models is the lack of jointly annotated data. Joint modeling of multiple natural language processing tasks outperforms single-task models learned from the same data, but still underperforms compared to single-task models learned on the more abundant quantities of available single-task annotated data. In this paper we present a novel model which makes use of additional single-task annotated data to improve the performance of a joint model. Our model utilizes a hierarchical prior to link the feature weights for shared features in several single-task models and the joint model. Experiments on joint parsing and named entity recog- nition, using the OntoNotes corpus, show that our hierarchical joint model can produce substantial gains over a joint model trained on only the jointly annotated data.</p><p>2 0.66634625 <a title="132-lsi-2" href="./acl-2010-Domain_Adaptation_of_Maximum_Entropy_Language_Models.html">91 acl-2010-Domain Adaptation of Maximum Entropy Language Models</a></p>
<p>Author: Tanel Alumae ; Mikko Kurimo</p><p>Abstract: We investigate a recently proposed Bayesian adaptation method for building style-adapted maximum entropy language models for speech recognition, given a large corpus of written language data and a small corpus of speech transcripts. Experiments show that the method consistently outperforms linear interpolation which is typically used in such cases.</p><p>3 0.66597694 <a title="132-lsi-3" href="./acl-2010-An_Entity-Level_Approach_to_Information_Extraction.html">28 acl-2010-An Entity-Level Approach to Information Extraction</a></p>
<p>Author: Aria Haghighi ; Dan Klein</p><p>Abstract: We present a generative model of template-filling in which coreference resolution and role assignment are jointly determined. Underlying template roles first generate abstract entities, which in turn generate concrete textual mentions. On the standard corporate acquisitions dataset, joint resolution in our entity-level model reduces error over a mention-level discriminative approach by up to 20%.</p><p>4 0.62507182 <a title="132-lsi-4" href="./acl-2010-Arabic_Named_Entity_Recognition%3A_Using_Features_Extracted_from_Noisy_Data.html">32 acl-2010-Arabic Named Entity Recognition: Using Features Extracted from Noisy Data</a></p>
<p>Author: Yassine Benajiba ; Imed Zitouni ; Mona Diab ; Paolo Rosso</p><p>Abstract: Building an accurate Named Entity Recognition (NER) system for languages with complex morphology is a challenging task. In this paper, we present research that explores the feature space using both gold and bootstrapped noisy features to build an improved highly accurate Arabic NER system. We bootstrap noisy features by projection from an Arabic-English parallel corpus that is automatically tagged with a baseline NER system. The feature space covers lexical, morphological, and syntactic features. The proposed approach yields an improvement of up to 1.64 F-measure (absolute).</p><p>5 0.61751282 <a title="132-lsi-5" href="./acl-2010-Word_Representations%3A_A_Simple_and_General_Method_for_Semi-Supervised_Learning.html">263 acl-2010-Word Representations: A Simple and General Method for Semi-Supervised Learning</a></p>
<p>Author: Joseph Turian ; Lev-Arie Ratinov ; Yoshua Bengio</p><p>Abstract: If we take an existing supervised NLP system, a simple and general way to improve accuracy is to use unsupervised word representations as extra word features. We evaluate Brown clusters, Collobert and Weston (2008) embeddings, and HLBL (Mnih & Hinton, 2009) embeddings of words on both NER and chunking. We use near state-of-the-art supervised baselines, and find that each of the three word representations improves the accuracy of these baselines. We find further improvements by combining different word representations. You can download our word features, for off-the-shelf use in existing NLP systems, as well as our code, here: http ://metaoptimize com/proj ects/wordreprs/ .</p><p>6 0.58676058 <a title="132-lsi-6" href="./acl-2010-On_Jointly_Recognizing_and_Aligning_Bilingual_Named_Entities.html">180 acl-2010-On Jointly Recognizing and Aligning Bilingual Named Entities</a></p>
<p>7 0.56816781 <a title="132-lsi-7" href="./acl-2010-Jointly_Optimizing_a_Two-Step_Conditional_Random_Field_Model_for_Machine_Transliteration_and_Its_Fast_Decoding_Algorithm.html">154 acl-2010-Jointly Optimizing a Two-Step Conditional Random Field Model for Machine Transliteration and Its Fast Decoding Algorithm</a></p>
<p>8 0.52736038 <a title="132-lsi-8" href="./acl-2010-Authorship_Attribution_Using_Probabilistic_Context-Free_Grammars.html">34 acl-2010-Authorship Attribution Using Probabilistic Context-Free Grammars</a></p>
<p>9 0.5248037 <a title="132-lsi-9" href="./acl-2010-Intelligent_Selection_of_Language_Model_Training_Data.html">151 acl-2010-Intelligent Selection of Language Model Training Data</a></p>
<p>10 0.5202716 <a title="132-lsi-10" href="./acl-2010-Conditional_Random_Fields_for_Word_Hyphenation.html">68 acl-2010-Conditional Random Fields for Word Hyphenation</a></p>
<p>11 0.48339453 <a title="132-lsi-11" href="./acl-2010-Modeling_Norms_of_Turn-Taking_in_Multi-Party_Conversation.html">173 acl-2010-Modeling Norms of Turn-Taking in Multi-Party Conversation</a></p>
<p>12 0.47827187 <a title="132-lsi-12" href="./acl-2010-Phylogenetic_Grammar_Induction.html">195 acl-2010-Phylogenetic Grammar Induction</a></p>
<p>13 0.47536123 <a title="132-lsi-13" href="./acl-2010-Simple%2C_Accurate_Parsing_with_an_All-Fragments_Grammar.html">211 acl-2010-Simple, Accurate Parsing with an All-Fragments Grammar</a></p>
<p>14 0.47284648 <a title="132-lsi-14" href="./acl-2010-Learning_Common_Grammar_from_Multilingual_Corpus.html">162 acl-2010-Learning Common Grammar from Multilingual Corpus</a></p>
<p>15 0.47015747 <a title="132-lsi-15" href="./acl-2010-Using_Parse_Features_for_Preposition_Selection_and_Error_Detection.html">252 acl-2010-Using Parse Features for Preposition Selection and Error Detection</a></p>
<p>16 0.45563036 <a title="132-lsi-16" href="./acl-2010-Vocabulary_Choice_as_an_Indicator_of_Perspective.html">256 acl-2010-Vocabulary Choice as an Indicator of Perspective</a></p>
<p>17 0.45043275 <a title="132-lsi-17" href="./acl-2010-Distributional_Similarity_vs._PU_Learning_for_Entity_Set_Expansion.html">89 acl-2010-Distributional Similarity vs. PU Learning for Entity Set Expansion</a></p>
<p>18 0.44731322 <a title="132-lsi-18" href="./acl-2010-Towards_Open-Domain_Semantic_Role_Labeling.html">238 acl-2010-Towards Open-Domain Semantic Role Labeling</a></p>
<p>19 0.44462007 <a title="132-lsi-19" href="./acl-2010-Entity-Based_Local_Coherence_Modelling_Using_Topological_Fields.html">101 acl-2010-Entity-Based Local Coherence Modelling Using Topological Fields</a></p>
<p>20 0.44419754 <a title="132-lsi-20" href="./acl-2010-Practical_Very_Large_Scale_CRFs.html">197 acl-2010-Practical Very Large Scale CRFs</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.011), (25, 0.04), (44, 0.011), (59, 0.084), (71, 0.02), (73, 0.039), (78, 0.027), (83, 0.553), (84, 0.024), (98, 0.114)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.99336201 <a title="132-lda-1" href="./acl-2010-Vocabulary_Choice_as_an_Indicator_of_Perspective.html">256 acl-2010-Vocabulary Choice as an Indicator of Perspective</a></p>
<p>Author: Beata Beigman Klebanov ; Eyal Beigman ; Daniel Diermeier</p><p>Abstract: We establish the following characteristics of the task of perspective classification: (a) using term frequencies in a document does not improve classification achieved with absence/presence features; (b) for datasets allowing the relevant comparisons, a small number of top features is found to be as effective as the full feature set and indispensable for the best achieved performance, testifying to the existence of perspective-specific keywords. We relate our findings to research on word frequency distributions and to discourse analytic studies of perspective.</p><p>2 0.98736477 <a title="132-lda-2" href="./acl-2010-A_Cognitive_Cost_Model_of_Annotations_Based_on_Eye-Tracking_Data.html">4 acl-2010-A Cognitive Cost Model of Annotations Based on Eye-Tracking Data</a></p>
<p>Author: Katrin Tomanek ; Udo Hahn ; Steffen Lohmann ; Jurgen Ziegler</p><p>Abstract: We report on an experiment to track complex decision points in linguistic metadata annotation where the decision behavior of annotators is observed with an eyetracking device. As experimental conditions we investigate different forms of textual context and linguistic complexity classes relative to syntax and semantics. Our data renders evidence that annotation performance depends on the semantic and syntactic complexity of the decision points and, more interestingly, indicates that fullscale context is mostly negligible with – the exception of semantic high-complexity cases. We then induce from this observational data a cognitively grounded cost model of linguistic meta-data annotations and compare it with existing non-cognitive models. Our data reveals that the cognitively founded model explains annotation costs (expressed in annotation time) more adequately than non-cognitive ones.</p><p>3 0.98535323 <a title="132-lda-3" href="./acl-2010-Coreference_Resolution_across_Corpora%3A_Languages%2C_Coding_Schemes%2C_and_Preprocessing_Information.html">72 acl-2010-Coreference Resolution across Corpora: Languages, Coding Schemes, and Preprocessing Information</a></p>
<p>Author: Marta Recasens ; Eduard Hovy</p><p>Abstract: This paper explores the effect that different corpus configurations have on the performance of a coreference resolution system, as measured by MUC, B3, and CEAF. By varying separately three parameters (language, annotation scheme, and preprocessing information) and applying the same coreference resolution system, the strong bonds between system and corpus are demonstrated. The experiments reveal problems in coreference resolution evaluation relating to task definition, coding schemes, and features. They also ex- pose systematic biases in the coreference evaluation metrics. We show that system comparison is only possible when corpus parameters are in exact agreement.</p><p>4 0.97595537 <a title="132-lda-4" href="./acl-2010-Automatic_Evaluation_of_Linguistic_Quality_in_Multi-Document_Summarization.html">38 acl-2010-Automatic Evaluation of Linguistic Quality in Multi-Document Summarization</a></p>
<p>Author: Emily Pitler ; Annie Louis ; Ani Nenkova</p><p>Abstract: To date, few attempts have been made to develop and validate methods for automatic evaluation of linguistic quality in text summarization. We present the first systematic assessment of several diverse classes of metrics designed to capture various aspects of well-written text. We train and test linguistic quality models on consecutive years of NIST evaluation data in order to show the generality of results. For grammaticality, the best results come from a set of syntactic features. Focus, coherence and referential clarity are best evaluated by a class of features measuring local coherence on the basis of cosine similarity between sentences, coreference informa- tion, and summarization specific features. Our best results are 90% accuracy for pairwise comparisons of competing systems over a test set of several inputs and 70% for ranking summaries of a specific input.</p><p>same-paper 5 0.97465521 <a title="132-lda-5" href="./acl-2010-Hierarchical_Joint_Learning%3A_Improving_Joint_Parsing_and_Named_Entity_Recognition_with_Non-Jointly_Labeled_Data.html">132 acl-2010-Hierarchical Joint Learning: Improving Joint Parsing and Named Entity Recognition with Non-Jointly Labeled Data</a></p>
<p>Author: Jenny Rose Finkel ; Christopher D. Manning</p><p>Abstract: One of the main obstacles to producing high quality joint models is the lack of jointly annotated data. Joint modeling of multiple natural language processing tasks outperforms single-task models learned from the same data, but still underperforms compared to single-task models learned on the more abundant quantities of available single-task annotated data. In this paper we present a novel model which makes use of additional single-task annotated data to improve the performance of a joint model. Our model utilizes a hierarchical prior to link the feature weights for shared features in several single-task models and the joint model. Experiments on joint parsing and named entity recog- nition, using the OntoNotes corpus, show that our hierarchical joint model can produce substantial gains over a joint model trained on only the jointly annotated data.</p><p>6 0.88980693 <a title="132-lda-6" href="./acl-2010-Annotation.html">31 acl-2010-Annotation</a></p>
<p>7 0.87258726 <a title="132-lda-7" href="./acl-2010-%22Ask_Not_What_Textual_Entailment_Can_Do_for_You...%22.html">1 acl-2010-"Ask Not What Textual Entailment Can Do for You..."</a></p>
<p>8 0.86473686 <a title="132-lda-8" href="./acl-2010-Coreference_Resolution_with_Reconcile.html">73 acl-2010-Coreference Resolution with Reconcile</a></p>
<p>9 0.79610145 <a title="132-lda-9" href="./acl-2010-Decision_Detection_Using_Hierarchical_Graphical_Models.html">81 acl-2010-Decision Detection Using Hierarchical Graphical Models</a></p>
<p>10 0.78768921 <a title="132-lda-10" href="./acl-2010-Supervised_Noun_Phrase_Coreference_Research%3A_The_First_Fifteen_Years.html">219 acl-2010-Supervised Noun Phrase Coreference Research: The First Fifteen Years</a></p>
<p>11 0.78518701 <a title="132-lda-11" href="./acl-2010-Assessing_the_Role_of_Discourse_References_in_Entailment_Inference.html">33 acl-2010-Assessing the Role of Discourse References in Entailment Inference</a></p>
<p>12 0.77762669 <a title="132-lda-12" href="./acl-2010-Arabic_Named_Entity_Recognition%3A_Using_Features_Extracted_from_Noisy_Data.html">32 acl-2010-Arabic Named Entity Recognition: Using Features Extracted from Noisy Data</a></p>
<p>13 0.77688086 <a title="132-lda-13" href="./acl-2010-Extracting_Social_Networks_from_Literary_Fiction.html">112 acl-2010-Extracting Social Networks from Literary Fiction</a></p>
<p>14 0.7684052 <a title="132-lda-14" href="./acl-2010-Entity-Based_Local_Coherence_Modelling_Using_Topological_Fields.html">101 acl-2010-Entity-Based Local Coherence Modelling Using Topological Fields</a></p>
<p>15 0.76636511 <a title="132-lda-15" href="./acl-2010-Kernel_Based_Discourse_Relation_Recognition_with_Temporal_Ordering_Information.html">155 acl-2010-Kernel Based Discourse Relation Recognition with Temporal Ordering Information</a></p>
<p>16 0.76416075 <a title="132-lda-16" href="./acl-2010-The_Manually_Annotated_Sub-Corpus%3A_A_Community_Resource_for_and_by_the_People.html">230 acl-2010-The Manually Annotated Sub-Corpus: A Community Resource for and by the People</a></p>
<p>17 0.7586726 <a title="132-lda-17" href="./acl-2010-Hierarchical_Sequential_Learning_for_Extracting_Opinions_and_Their_Attributes.html">134 acl-2010-Hierarchical Sequential Learning for Extracting Opinions and Their Attributes</a></p>
<p>18 0.75423861 <a title="132-lda-18" href="./acl-2010-Joint_Syntactic_and_Semantic_Parsing_of_Chinese.html">153 acl-2010-Joint Syntactic and Semantic Parsing of Chinese</a></p>
<p>19 0.75233597 <a title="132-lda-19" href="./acl-2010-Practical_Very_Large_Scale_CRFs.html">197 acl-2010-Practical Very Large Scale CRFs</a></p>
<p>20 0.75033092 <a title="132-lda-20" href="./acl-2010-Generating_Fine-Grained_Reviews_of_Songs_from_Album_Reviews.html">122 acl-2010-Generating Fine-Grained Reviews of Songs from Album Reviews</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
