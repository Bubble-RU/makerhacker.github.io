<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>11 acl-2010-A New Approach to Improving Multilingual Summarization Using a Genetic Algorithm</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2010" href="../home/acl2010_home.html">acl2010</a> <a title="acl-2010-11" href="#">acl2010-11</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>11 acl-2010-A New Approach to Improving Multilingual Summarization Using a Genetic Algorithm</h1>
<br/><p>Source: <a title="acl-2010-11-pdf" href="http://aclweb.org/anthology//P/P10/P10-1095.pdf">pdf</a></p><p>Author: Marina Litvak ; Mark Last ; Menahem Friedman</p><p>Abstract: Automated summarization methods can be defined as “language-independent,” if they are not based on any languagespecific knowledge. Such methods can be used for multilingual summarization defined by Mani (2001) as “processing several languages, with summary in the same language as input.” In this paper, we introduce MUSE, a languageindependent approach for extractive summarization based on the linear optimization of several sentence ranking measures using a genetic algorithm. We tested our methodology on two languages—English and Hebrew—and evaluated its performance with ROUGE-1 Recall vs. state- of-the-art extractive summarization approaches. Our results show that MUSE performs better than the best known multilingual approach (TextRank1) in both languages. Moreover, our experimental results on a bilingual (English and Hebrew) document collection suggest that MUSE does not need to be retrained on each language and the same model can be used across at least two different languages.</p><p>Reference: <a title="acl-2010-11-reference" href="../acl2010_reference/acl-2010-A_New_Approach_to_Improving_Multilingual_Summarization_Using_a_Genetic_Algorithm_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 i l  Abstract Automated summarization methods can be defined as “language-independent,” if they are not based on any languagespecific knowledge. [sent-7, score-0.269]
</p><p>2 Such methods can be used for multilingual summarization defined by Mani (2001) as “processing several languages, with summary in the same language as input. [sent-8, score-0.43]
</p><p>3 ” In this paper, we introduce MUSE, a languageindependent approach for extractive summarization based on the linear optimization of several sentence ranking measures using a genetic algorithm. [sent-9, score-0.868]
</p><p>4 Our results show that MUSE performs better than the best known multilingual approach (TextRank1) in both languages. [sent-12, score-0.105]
</p><p>5 Moreover, our experimental results on a bilingual (English and Hebrew) document collection suggest that MUSE does not need to be retrained on each language and the same model can be used across at least two different languages. [sent-13, score-0.185]
</p><p>6 1 Introduction Document summaries should use a minimum number of words to express a document’s main ideas. [sent-14, score-0.132]
</p><p>7 As such, high quality summaries can significantly reduce the information overload many professionals in a variety of fields must contend 1We evaluated several summarizers—SUMMA, MEAD, Microsoft Word Autosummarize and TextRank—on the DUC 2002 corpus. [sent-15, score-0.132]
</p><p>8 Automated summarization methods can use different levels of linguistic analysis: morphological, syntactic, semantic and discourse/pragmatic (Mani, 2001). [sent-20, score-0.269]
</p><p>9 Although the summary quality is expected to improve when a summarization technique includes language specific knowledge, the inclusion of that knowledge impedes the use of the summarizer on multiple languages. [sent-21, score-0.364]
</p><p>10 The publication of information on the Internet in an ever-increasing variety of languages 2 dictates the importance of developing multilingual summarization approaches. [sent-23, score-0.405]
</p><p>11 In the absence of such techniques, the only alternative to language-independent summarization would be the labor-intensive translation of the entire document into a common language. [sent-25, score-0.372]
</p><p>12 Here we introduce MUSE (MUltilingual Sentence Extractor), a new approach to multilingual single-document extractive summarization where summarization is considered as an optimization or a search problem. [sent-26, score-0.904]
</p><p>13 We have evaluated our approach on two monolingual corpora of English and Hebrew documents  and, additionally, on one bilingual corpora comprising English and Hebrew documents. [sent-31, score-0.219]
</p><p>14 Our evaluation experiments sought to - Compare the GA-based approach for singledocument extractive summarization (MUSE) to the best known sentence scoring methods. [sent-32, score-0.649]
</p><p>15 The next section describes the related work in statistical extractive summarization. [sent-35, score-0.202]
</p><p>16 Section 3 introduces MUSE, the GA-based approach to multilingual single-document extractive summarization. [sent-36, score-0.307]
</p><p>17 Section 4 presents our experimental results on monolingual and bilingual corpora. [sent-37, score-0.082]
</p><p>18 2  Related Work  Extractive summarization is aimed at the selection of a subset of the most relevant fragments from a source text into the summary. [sent-39, score-0.3]
</p><p>19 Considered the first work on sentence scoring for automated text summarization, Luhn (1958) based the significance factor of a sentence on the frequency and the relative positions of significant words within a sentence. [sent-48, score-0.23]
</p><p>20 Edmundson (1969) tested different linear combinations of four sentence ranking scoring methods—cue, key, title and position—to identify that which performed best on a training corpus. [sent-49, score-0.302]
</p><p>21 , 2003) approaches, both of which use the vector space model for text representation and a set of predefined or user-specified weights for a combination of position, frequency, title, and centroid-based (MEAD) features. [sent-52, score-0.082]
</p><p>22 In none of these works, however, did the researchers attempt to find the optimal weights for the best linear combination. [sent-55, score-0.135]
</p><p>23 (2002) combined conventional sentence extraction and a trainable classifier based on support vector machines. [sent-61, score-0.087]
</p><p>24 Some authors reduced the summarization process to an optimization or a search problem. [sent-62, score-0.328]
</p><p>25 Hassel and Sjobergh (2006) used a standard hill-  climbing algorithm to build summaries that maximize the score for the total impact of the summary. [sent-63, score-0.132]
</p><p>26 A summary consists of first sentences from the document was used as a starting point for the search, and all neighbours (summaries that can be created by simply removing one sentence and adding another) were examined, looking for a better summary. [sent-64, score-0.211]
</p><p>27 (2006b) used genetic algorithms (GAs), which are known as prominent search and optimization methods (Goldberg, 1989), to find sets of sentences that maximize summary quality metrics, starting from a random selection of sentences as the initial population. [sent-67, score-0.304]
</p><p>28 To choose the best summary, multiple candidates should be generated and evaluated for each document (or document cluster). [sent-69, score-0.206]
</p><p>29 (2000) enhanced the  preference-based anaphora resolution algorithms by using a GA to find an optimal set of values for the outcomes of 14 indicators and apply the optimal combination of values from data on one text to a different text. [sent-72, score-0.12]
</p><p>30 com/  928  Today, graph-based text representations are becoming increasingly popular, due to their ability to enrich the document model with syntactic and semantic relations. [sent-76, score-0.103]
</p><p>31 (1997) were among the first to make an attempt at using graphbased ranking methods in single document extractive summarization, generating similarity links between document paragraphs and using degree scores in order to extract the important paragraphs from the text. [sent-78, score-0.488]
</p><p>32 Erkan and Radev (2004) and Mihalcea (2005) introduced algorithms for unsupervised extractive summarization that rely on the application of iterative graph-based ranking algo-  rithms, such as PageRank (Brin and Page, 1998) and HITS (Kleinberg, 1999). [sent-79, score-0.471]
</p><p>33 Their methods represent a document as a graph of sentences interconnected by similarity relations. [sent-80, score-0.103]
</p><p>34 3  MUSE – MUltilingual Sentence Extractor  In this paper we propose a learning approach to language-independent extractive summarization where the best set of weights for a linear combination of sentence scoring methods is found by a genetic algorithm trained on a collection of document summaries. [sent-83, score-1.082]
</p><p>35 The weighting vector thus obtained is used for sentence scoring in future summarizations. [sent-84, score-0.214]
</p><p>36 Since most sentence scoring methods  have a linear computational complexity, only the training phase of our approach is time-consuming. [sent-85, score-0.237]
</p><p>37 1 Sentence scoring methods Our work is aimed at identifying the best linear combination of the 31 sentence scoring methods listed in Table 1. [sent-87, score-0.438]
</p><p>38 Each method description includes a reference to the original work where the method was proposed for extractive summarization. [sent-88, score-0.202]
</p><p>39 Formulas incorporate the following notation: a sentence is denoted by S, a text document by D, the total number of words in S by N, the total number of sentences in D by n, the sequential number of S in D by i, and the in-document term frequency of the term t by tf(t). [sent-90, score-0.19]
</p><p>40 In the LUHN method, Wi and Ni are the number of keywords and the total number of words in the ith cluster, respectively, such that clusters are portions of a sentence bracketed by keywords, i. [sent-91, score-0.087]
</p><p>41 Methods that require  pre-defined threshold values are marked with a cross and listed in Table 2 together with the average threshold values obtained after method evaluation on English and Hebrew corpora. [sent-95, score-0.1]
</p><p>42 3 describes our application of a GA to the summarization task. [sent-101, score-0.269]
</p><p>43 Table 2: Selected thresholds for threshold-based scoring methods MethodThreshold LUHN0. [sent-102, score-0.126]
</p><p>44 2 Text representation models The vector-based scoring methods listed in Table 1 use tf or tf-idf term weights to evaluate sentence importance. [sent-116, score-0.265]
</p><p>45 (2005) showed that such graph representations can outperform the vector space model on several document categorization tasks. [sent-120, score-0.103]
</p><p>46 929 Table 1: Sentence scoring metrics  NameDescriptionSource  nodes represent unique terms (distinct words) and edges represent order-relationships between two  3. [sent-122, score-0.212]
</p><p>47 ThereisadirectededgefromAtoB ifanA  Optimization—learning the best linear combination  We found the best linear combination of the meth-  tsheprnmcIeDifmsoedmfthoesdrinaetor. [sent-124, score-0.206]
</p><p>48 Defined over the genetic representation, the fitness function measures the quality of the represented solution. [sent-131, score-0.292]
</p><p>49 We use ROUGE-1 Recall (Lin and Hovy, 2003) as a fitness function for measuring summarization quality, which is maximized during the optimization procedure. [sent-132, score-0.431]
</p><p>50 Initialization GA will explore only a small part of the search space, if the population is too small, whereas it slows down if there are too many solutions. [sent-134, score-0.093]
</p><p>51 Selection During each successive generation, a proportion of the existing population is selected to breed a new generation. [sent-142, score-0.093]
</p><p>52 We use a truncation selection method that rates the fitness of each solution and selects the best fifth (100 out of 500) of the individual solutions, i. [sent-143, score-0.138]
</p><p>53 Also, we use elitism—method that prevents losing the best found solution in the population by copying it to the next generation. [sent-147, score-0.128]
</p><p>54 These new solutions are generated from those selected through the following genetic operators: mating, crossover, and mutation. [sent-151, score-0.238]
</p><p>55 In mating, a pair of “parent” solutions is randomly selected, and a new solution is created us-  ing crossover and mutation, that are the most important part of a genetic algorithm. [sent-152, score-0.348]
</p><p>56 New parents are selected for each new child, and the process continues until a new population of solutions of appropriate size N is generated. [sent-154, score-0.142]
</p><p>57 However it is good to keep some part of population from one generation to the next. [sent-156, score-0.093]
</p><p>58 Our crossover operator includes a probability (80%) that a new and different offspring solution will be generated by calculating the weighted average of two “parent” vectors according to (Vignaux and Michalewicz, 1991). [sent-157, score-0.148]
</p><p>59 generational process uise repeated until a termination condition—a plateau of solution/combination fitness such that successive iterations no longer produce better results—has been reached. [sent-167, score-0.138]
</p><p>60 1 Overview The MUSE summarization approach was evaluated using a comparative experiment on two monolingual corpora of English and Hebrew texts and on a bilingual corpus of texts in both languages. [sent-171, score-0.389]
</p><p>61 The specific goals of the experiment are to: - Evaluate the optimal sentence scoring models induced from the corpora of summarized documents in two different languages. [sent-173, score-0.35]
</p><p>62 - Compare the performance of the GA-based multilingual summarization method proposed in this work to the state-of-the-art approaches. [sent-174, score-0.374]
</p><p>63 - Determine whether the same sentence scoring model can be efficiently used for extractive summarization across two different languages. [sent-176, score-0.649]
</p><p>64 2 Text preprocessing Crucial to extractive summarization, proper sentence segmentation contributes to the quality of summarization results. [sent-178, score-0.523]
</p><p>65 For English sentences, we used the sentence splitter provided with the MEAD summarizer (Radev et al. [sent-179, score-0.137]
</p><p>66 3 Experiment design The English text material we used in our experiments comprised the corpus of summarized documents available to the single document summarization task at the Document Understanding Conference, 2002 (DUC, 2002). [sent-183, score-0.468]
</p><p>67 For the Hebrew language, however, to the best of our knowledge, no summarization benchmarks exist. [sent-185, score-0.269]
</p><p>68 To generate a corpus of summarized Hebrew texts, therefore, we set up an experiment where human assessors were given 50 news articles of 250 to 830 words each from the Website of the Haaretz newspaper. [sent-186, score-0.148]
</p><p>69 8 All assessors were provided with the Tool Assisting Human Assessors (TAHA) software tool9 that enables sentences to be easily selected and stored for later inclusion in the doc-  ument extract. [sent-187, score-0.113]
</p><p>70 We filtered all the summaries produced by assessors that received average ROUGE score below 0. [sent-195, score-0.245]
</p><p>71 agreed with the rest of assessors in less than 50% of cases. [sent-198, score-0.113]
</p><p>72 Finally, our corpus of summarized Hebrew texts was compiled from the summaries of about 60% of the most consistent assessors, with an average of seven extracts per single document11 . [sent-199, score-0.167]
</p><p>73 The ROUGE scores of the selected assessors are distributed between 50 and 57 percents. [sent-200, score-0.113]
</p><p>74 4 Experimental Results We evaluated English and Hebrew summaries using ROUGE-1, 2, 3, 4, L, SU and W metrics, described in (2004). [sent-203, score-0.132]
</p><p>75 In agreement with Lin’s (2004) conclusion, our results for the different metrics were not statistically distinguishable. [sent-204, score-0.086]
</p><p>76 The results of training and testing comprise the average ROUGE values obtained for English, Hebrew, and bilingual corpora (Table 3). [sent-208, score-0.12]
</p><p>77 The same toolkit was used for summaries evaluation on Hebrew corpus. [sent-212, score-0.132]
</p><p>78 rizer, and (3) with the best single scoring method in each corpus. [sent-220, score-0.126]
</p><p>79 As a baseline, we compiled summaries created from the initial sentences (denoted by POS F). [sent-221, score-0.132]
</p><p>80 Table 4 shows the comparative results (ROUGE mean values) for English, Hebrew, and bilingual corpora, with the best summarizers on top. [sent-222, score-0.143]
</p><p>81 Pairwise comparisons between summarizers indicated that all methods (except POS F and ML TR in the English and bilingual corpora and D COV J and POS F in the Hebrew corpus) were significantly different at the 95% confidence level. [sent-223, score-0.181]
</p><p>82 MUSE performed significantly better than TextRank in all three corpora and better than the best single methods COV DEG in English and D COV J in Hebrew corpora respectively. [sent-224, score-0.076]
</p><p>83 Two sets of features—the full set of 31 sentence scoring metrics and the 10 best bilingual metrics determined in our previous work13 using  a clustering analysis of the methods results on both corpora—were tested on the bilingual corpus. [sent-225, score-0.514]
</p><p>84 The experimental results show that the optimized combination of the 10 best metrics is not significantly distinguishable from the best single metric in the multilingual corpus COV DEG. [sent-226, score-0.235]
</p><p>85 The difference between the combination of all 31 metrics and COV DEG is significant only with a onetailed p-value of 0. [sent-227, score-0.13]
</p><p>86 Our experiments showed that the removal of highly-correlated metrics (the metric with the lower ROUGE value out of each pair of highlycorrelated metrics) from the linear combination slightly improved summarization quality, but the improvement was not statistically significant. [sent-231, score-0.458]
</p><p>87 Table 5 shows the best vectors generated from training MUSE on all the documents in the En–  glish, Hebrew, and multilingual (one of 10 balanced) corpora and their ROUGE training scores and number of GA iterations. [sent-233, score-0.204]
</p><p>88 as ωφ(n) + (1 While the sum of the two weights (i1s obviously 1, the optimal value of ω, which minimizes the number of iterations needed for convergence, usually satisfies 1 < ω < 2  (i. [sent-238, score-0.111]
</p><p>89 3184  Assuming efficient implementation, most metrics have a linear computational complexity relative to the total number of words in a document - O(n). [sent-267, score-0.248]
</p><p>90 As a result, MUSE total computation  time, given a trained model, is also linear (at factor of the number of metrics in a combination). [sent-268, score-0.145]
</p><p>91 The training time is proportional to the number of GA iterations multiplied by the number of individuals in a population times the fitness evaluation (ROUGE) time. [sent-269, score-0.231]
</p><p>92 5  Conclusions and future work  In this paper we introduced MUSE, a new, GAbased approach to multilingual extractive summarization. [sent-271, score-0.307]
</p><p>93 The experimental results showed that MUSE significantly outperformed TextRank, the best known languageTable 5: Induced weights for the best linear combination of scoring metrics MetricENGHEBMULT COV DEG8. [sent-273, score-0.353]
</p><p>94 526 Iterations 10 6 7  independent approach, in both Hebrew and English using either monolingual or bilingual corpora. [sent-369, score-0.082]
</p><p>95 - Incorporate threshold values for threshold-based methods (Table 2) into the GA-based optimization procedure. [sent-372, score-0.09]
</p><p>96 - Improve performance of similarity-based metrics in the multilingual domain. [sent-373, score-0.191]
</p><p>97 - Extend the search for the best summary to the problem of multi-object optimization, combining several summary quality metrics. [sent-375, score-0.112]
</p><p>98 Generic text summarization using relevance measure and latent semantic analysis. [sent-448, score-0.269]
</p><p>99 Generating text summaries through the relative importance of topics. [sent-558, score-0.132]
</p><p>100 Beyond sumbasic: Taskfocused summarization with sentence simplification and lexical expansion. [sent-645, score-0.321]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('cov', 0.386), ('hebrew', 0.312), ('muse', 0.301), ('summarization', 0.269), ('extractive', 0.202), ('genetic', 0.189), ('luhn', 0.169), ('rouge', 0.151), ('deg', 0.137), ('ga', 0.135), ('summaries', 0.132), ('scoring', 0.126), ('textrank', 0.121), ('assessors', 0.113), ('edmundson', 0.107), ('multilingual', 0.105), ('fitness', 0.103), ('document', 0.103), ('population', 0.093), ('mead', 0.086), ('negev', 0.086), ('schenker', 0.086), ('metrics', 0.086), ('bilingual', 0.082), ('crossover', 0.075), ('radev', 0.066), ('title', 0.065), ('autosummarize', 0.064), ('bgu', 0.064), ('kallel', 0.064), ('litvak', 0.064), ('sheva', 0.064), ('documents', 0.061), ('summarizers', 0.061), ('optimization', 0.059), ('linear', 0.059), ('friedman', 0.056), ('mutation', 0.056), ('summary', 0.056), ('erkan', 0.056), ('pr', 0.055), ('ml', 0.054), ('sentence', 0.052), ('gas', 0.052), ('extractor', 0.05), ('satoshi', 0.049), ('tf', 0.049), ('solutions', 0.049), ('beer', 0.048), ('steinberger', 0.048), ('splitter', 0.046), ('combination', 0.044), ('beyer', 0.043), ('bunke', 0.043), ('gulli', 0.043), ('hassel', 0.043), ('ishikawa', 0.043), ('jezek', 0.043), ('mating', 0.043), ('metricenghebmult', 0.043), ('neto', 0.043), ('summa', 0.043), ('vignaux', 0.043), ('mihalcea', 0.041), ('paragraphs', 0.04), ('salton', 0.04), ('summarizer', 0.039), ('duc', 0.039), ('tr', 0.039), ('cross', 0.038), ('weights', 0.038), ('optimal', 0.038), ('microsoft', 0.038), ('asan', 0.038), ('filippova', 0.038), ('languageindependent', 0.038), ('ntcir', 0.038), ('offspring', 0.038), ('corpora', 0.038), ('israel', 0.037), ('english', 0.036), ('weighting', 0.036), ('solution', 0.035), ('denoted', 0.035), ('iterations', 0.035), ('trainable', 0.035), ('keywords', 0.035), ('summarized', 0.035), ('reproduction', 0.034), ('brin', 0.034), ('gong', 0.034), ('len', 0.034), ('saggion', 0.034), ('lecture', 0.034), ('grid', 0.033), ('teufel', 0.032), ('liu', 0.032), ('languages', 0.031), ('aimed', 0.031), ('threshold', 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="11-tfidf-1" href="./acl-2010-A_New_Approach_to_Improving_Multilingual_Summarization_Using_a_Genetic_Algorithm.html">11 acl-2010-A New Approach to Improving Multilingual Summarization Using a Genetic Algorithm</a></p>
<p>Author: Marina Litvak ; Mark Last ; Menahem Friedman</p><p>Abstract: Automated summarization methods can be defined as “language-independent,” if they are not based on any languagespecific knowledge. Such methods can be used for multilingual summarization defined by Mani (2001) as “processing several languages, with summary in the same language as input.” In this paper, we introduce MUSE, a languageindependent approach for extractive summarization based on the linear optimization of several sentence ranking measures using a genetic algorithm. We tested our methodology on two languages—English and Hebrew—and evaluated its performance with ROUGE-1 Recall vs. state- of-the-art extractive summarization approaches. Our results show that MUSE performs better than the best known multilingual approach (TextRank1) in both languages. Moreover, our experimental results on a bilingual (English and Hebrew) document collection suggest that MUSE does not need to be retrained on each language and the same model can be used across at least two different languages.</p><p>2 0.3090266 <a title="11-tfidf-2" href="./acl-2010-A_Risk_Minimization_Framework_for_Extractive_Speech_Summarization.html">14 acl-2010-A Risk Minimization Framework for Extractive Speech Summarization</a></p>
<p>Author: Shih-Hsiang Lin ; Berlin Chen</p><p>Abstract: In this paper, we formulate extractive summarization as a risk minimization problem and propose a unified probabilistic framework that naturally combines supervised and unsupervised summarization models to inherit their individual merits as well as to overcome their inherent limitations. In addition, the introduction of various loss functions also provides the summarization framework with a flexible but systematic way to render the redundancy and coherence relationships among sentences and between sentences and the whole document, respectively. Experiments on speech summarization show that the methods deduced from our framework are very competitive with existing summarization approaches. 1</p><p>3 0.24472843 <a title="11-tfidf-3" href="./acl-2010-Cross-Language_Document_Summarization_Based_on_Machine_Translation_Quality_Prediction.html">77 acl-2010-Cross-Language Document Summarization Based on Machine Translation Quality Prediction</a></p>
<p>Author: Xiaojun Wan ; Huiying Li ; Jianguo Xiao</p><p>Abstract: Cross-language document summarization is a task of producing a summary in one language for a document set in a different language. Existing methods simply use machine translation for document translation or summary translation. However, current machine translation services are far from satisfactory, which results in that the quality of the cross-language summary is usually very poor, both in readability and content. In this paper, we propose to consider the translation quality of each sentence in the English-to-Chinese cross-language summarization process. First, the translation quality of each English sentence in the document set is predicted with the SVM regression method, and then the quality score of each sentence is incorporated into the summarization process. Finally, the English sentences with high translation quality and high informativeness are selected and translated to form the Chinese summary. Experimental results demonstrate the effectiveness and usefulness of the proposed approach. 1</p><p>4 0.19459786 <a title="11-tfidf-4" href="./acl-2010-Wrapping_up_a_Summary%3A_From_Representation_to_Generation.html">264 acl-2010-Wrapping up a Summary: From Representation to Generation</a></p>
<p>Author: Josef Steinberger ; Marco Turchi ; Mijail Kabadjov ; Ralf Steinberger ; Nello Cristianini</p><p>Abstract: The main focus of this work is to investigate robust ways for generating summaries from summary representations without recurring to simple sentence extraction and aiming at more human-like summaries. This is motivated by empirical evidence from TAC 2009 data showing that human summaries contain on average more and shorter sentences than the system summaries. We report encouraging preliminary results comparable to those attained by participating systems at TAC 2009.</p><p>5 0.1654475 <a title="11-tfidf-5" href="./acl-2010-Automatic_Evaluation_of_Linguistic_Quality_in_Multi-Document_Summarization.html">38 acl-2010-Automatic Evaluation of Linguistic Quality in Multi-Document Summarization</a></p>
<p>Author: Emily Pitler ; Annie Louis ; Ani Nenkova</p><p>Abstract: To date, few attempts have been made to develop and validate methods for automatic evaluation of linguistic quality in text summarization. We present the first systematic assessment of several diverse classes of metrics designed to capture various aspects of well-written text. We train and test linguistic quality models on consecutive years of NIST evaluation data in order to show the generality of results. For grammaticality, the best results come from a set of syntactic features. Focus, coherence and referential clarity are best evaluated by a class of features measuring local coherence on the basis of cosine similarity between sentences, coreference informa- tion, and summarization specific features. Our best results are 90% accuracy for pairwise comparisons of competing systems over a test set of several inputs and 70% for ranking summaries of a specific input.</p><p>6 0.15638112 <a title="11-tfidf-6" href="./acl-2010-A_Hybrid_Hierarchical_Model_for_Multi-Document_Summarization.html">8 acl-2010-A Hybrid Hierarchical Model for Multi-Document Summarization</a></p>
<p>7 0.1375386 <a title="11-tfidf-7" href="./acl-2010-Generating_Image_Descriptions_Using_Dependency_Relational_Patterns.html">124 acl-2010-Generating Image Descriptions Using Dependency Relational Patterns</a></p>
<p>8 0.12867877 <a title="11-tfidf-8" href="./acl-2010-Optimizing_Informativeness_and_Readability_for_Sentiment_Summarization.html">188 acl-2010-Optimizing Informativeness and Readability for Sentiment Summarization</a></p>
<p>9 0.12283915 <a title="11-tfidf-9" href="./acl-2010-Automatic_Generation_of_Story_Highlights.html">39 acl-2010-Automatic Generation of Story Highlights</a></p>
<p>10 0.11861105 <a title="11-tfidf-10" href="./acl-2010-Metadata-Aware_Measures_for_Answer_Summarization_in_Community_Question_Answering.html">171 acl-2010-Metadata-Aware Measures for Answer Summarization in Community Question Answering</a></p>
<p>11 0.11314882 <a title="11-tfidf-11" href="./acl-2010-A_Statistical_Model_for_Lost_Language_Decipherment.html">16 acl-2010-A Statistical Model for Lost Language Decipherment</a></p>
<p>12 0.10424069 <a title="11-tfidf-12" href="./acl-2010-Bilingual_Lexicon_Generation_Using_Non-Aligned_Signatures.html">50 acl-2010-Bilingual Lexicon Generation Using Non-Aligned Signatures</a></p>
<p>13 0.095519803 <a title="11-tfidf-13" href="./acl-2010-Plot_Induction_and_Evolutionary_Search_for_Story_Generation.html">196 acl-2010-Plot Induction and Evolutionary Search for Story Generation</a></p>
<p>14 0.089649379 <a title="11-tfidf-14" href="./acl-2010-A_Study_of_Information_Retrieval_Weighting_Schemes_for_Sentiment_Analysis.html">18 acl-2010-A Study of Information Retrieval Weighting Schemes for Sentiment Analysis</a></p>
<p>15 0.085874841 <a title="11-tfidf-15" href="./acl-2010-A_Semi-Supervised_Key_Phrase_Extraction_Approach%3A_Learning_from_Title_Phrases_through_a_Document_Semantic_Network.html">15 acl-2010-A Semi-Supervised Key Phrase Extraction Approach: Learning from Title Phrases through a Document Semantic Network</a></p>
<p>16 0.079749525 <a title="11-tfidf-16" href="./acl-2010-Generating_Templates_of_Entity_Summaries_with_an_Entity-Aspect_Model_and_Pattern_Mining.html">125 acl-2010-Generating Templates of Entity Summaries with an Entity-Aspect Model and Pattern Mining</a></p>
<p>17 0.076450504 <a title="11-tfidf-17" href="./acl-2010-How_Many_Words_Is_a_Picture_Worth%3F_Automatic_Caption_Generation_for_News_Images.html">136 acl-2010-How Many Words Is a Picture Worth? Automatic Caption Generation for News Images</a></p>
<p>18 0.06282907 <a title="11-tfidf-18" href="./acl-2010-Unsupervised_Discourse_Segmentation_of_Documents_with_Inherently_Parallel_Structure.html">246 acl-2010-Unsupervised Discourse Segmentation of Documents with Inherently Parallel Structure</a></p>
<p>19 0.062609412 <a title="11-tfidf-19" href="./acl-2010-Generating_Fine-Grained_Reviews_of_Songs_from_Album_Reviews.html">122 acl-2010-Generating Fine-Grained Reviews of Songs from Album Reviews</a></p>
<p>20 0.061266974 <a title="11-tfidf-20" href="./acl-2010-Bilingual_Sense_Similarity_for_Statistical_Machine_Translation.html">51 acl-2010-Bilingual Sense Similarity for Statistical Machine Translation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.2), (1, 0.044), (2, -0.163), (3, 0.016), (4, 0.013), (5, -0.004), (6, 0.025), (7, -0.396), (8, -0.022), (9, -0.022), (10, 0.014), (11, -0.028), (12, -0.102), (13, 0.001), (14, -0.068), (15, -0.091), (16, -0.005), (17, -0.02), (18, 0.03), (19, 0.004), (20, 0.029), (21, 0.003), (22, -0.044), (23, -0.001), (24, 0.034), (25, -0.006), (26, -0.047), (27, -0.03), (28, 0.074), (29, 0.01), (30, -0.059), (31, -0.072), (32, 0.077), (33, -0.056), (34, -0.052), (35, -0.021), (36, 0.013), (37, -0.057), (38, -0.051), (39, 0.032), (40, 0.029), (41, -0.111), (42, 0.08), (43, -0.044), (44, 0.072), (45, 0.046), (46, -0.058), (47, 0.116), (48, -0.06), (49, -0.054)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94520545 <a title="11-lsi-1" href="./acl-2010-A_New_Approach_to_Improving_Multilingual_Summarization_Using_a_Genetic_Algorithm.html">11 acl-2010-A New Approach to Improving Multilingual Summarization Using a Genetic Algorithm</a></p>
<p>Author: Marina Litvak ; Mark Last ; Menahem Friedman</p><p>Abstract: Automated summarization methods can be defined as “language-independent,” if they are not based on any languagespecific knowledge. Such methods can be used for multilingual summarization defined by Mani (2001) as “processing several languages, with summary in the same language as input.” In this paper, we introduce MUSE, a languageindependent approach for extractive summarization based on the linear optimization of several sentence ranking measures using a genetic algorithm. We tested our methodology on two languages—English and Hebrew—and evaluated its performance with ROUGE-1 Recall vs. state- of-the-art extractive summarization approaches. Our results show that MUSE performs better than the best known multilingual approach (TextRank1) in both languages. Moreover, our experimental results on a bilingual (English and Hebrew) document collection suggest that MUSE does not need to be retrained on each language and the same model can be used across at least two different languages.</p><p>2 0.86261958 <a title="11-lsi-2" href="./acl-2010-A_Risk_Minimization_Framework_for_Extractive_Speech_Summarization.html">14 acl-2010-A Risk Minimization Framework for Extractive Speech Summarization</a></p>
<p>Author: Shih-Hsiang Lin ; Berlin Chen</p><p>Abstract: In this paper, we formulate extractive summarization as a risk minimization problem and propose a unified probabilistic framework that naturally combines supervised and unsupervised summarization models to inherit their individual merits as well as to overcome their inherent limitations. In addition, the introduction of various loss functions also provides the summarization framework with a flexible but systematic way to render the redundancy and coherence relationships among sentences and between sentences and the whole document, respectively. Experiments on speech summarization show that the methods deduced from our framework are very competitive with existing summarization approaches. 1</p><p>3 0.81414688 <a title="11-lsi-3" href="./acl-2010-Wrapping_up_a_Summary%3A_From_Representation_to_Generation.html">264 acl-2010-Wrapping up a Summary: From Representation to Generation</a></p>
<p>Author: Josef Steinberger ; Marco Turchi ; Mijail Kabadjov ; Ralf Steinberger ; Nello Cristianini</p><p>Abstract: The main focus of this work is to investigate robust ways for generating summaries from summary representations without recurring to simple sentence extraction and aiming at more human-like summaries. This is motivated by empirical evidence from TAC 2009 data showing that human summaries contain on average more and shorter sentences than the system summaries. We report encouraging preliminary results comparable to those attained by participating systems at TAC 2009.</p><p>4 0.77977484 <a title="11-lsi-4" href="./acl-2010-Cross-Language_Document_Summarization_Based_on_Machine_Translation_Quality_Prediction.html">77 acl-2010-Cross-Language Document Summarization Based on Machine Translation Quality Prediction</a></p>
<p>Author: Xiaojun Wan ; Huiying Li ; Jianguo Xiao</p><p>Abstract: Cross-language document summarization is a task of producing a summary in one language for a document set in a different language. Existing methods simply use machine translation for document translation or summary translation. However, current machine translation services are far from satisfactory, which results in that the quality of the cross-language summary is usually very poor, both in readability and content. In this paper, we propose to consider the translation quality of each sentence in the English-to-Chinese cross-language summarization process. First, the translation quality of each English sentence in the document set is predicted with the SVM regression method, and then the quality score of each sentence is incorporated into the summarization process. Finally, the English sentences with high translation quality and high informativeness are selected and translated to form the Chinese summary. Experimental results demonstrate the effectiveness and usefulness of the proposed approach. 1</p><p>5 0.69118953 <a title="11-lsi-5" href="./acl-2010-A_Hybrid_Hierarchical_Model_for_Multi-Document_Summarization.html">8 acl-2010-A Hybrid Hierarchical Model for Multi-Document Summarization</a></p>
<p>Author: Asli Celikyilmaz ; Dilek Hakkani-Tur</p><p>Abstract: Scoring sentences in documents given abstract summaries created by humans is important in extractive multi-document summarization. In this paper, we formulate extractive summarization as a two step learning problem building a generative model for pattern discovery and a regression model for inference. We calculate scores for sentences in document clusters based on their latent characteristics using a hierarchical topic model. Then, using these scores, we train a regression model based on the lexical and structural characteristics of the sentences, and use the model to score sentences of new documents to form a summary. Our system advances current state-of-the-art improving ROUGE scores by ∼7%. Generated summaries are less rbeydu ∼n7d%an.t a Gnedn more dc sohuemremnatr bieasse adre upon manual quality evaluations.</p><p>6 0.65746719 <a title="11-lsi-6" href="./acl-2010-Automatic_Evaluation_of_Linguistic_Quality_in_Multi-Document_Summarization.html">38 acl-2010-Automatic Evaluation of Linguistic Quality in Multi-Document Summarization</a></p>
<p>7 0.65549546 <a title="11-lsi-7" href="./acl-2010-Automatic_Generation_of_Story_Highlights.html">39 acl-2010-Automatic Generation of Story Highlights</a></p>
<p>8 0.59149981 <a title="11-lsi-8" href="./acl-2010-Identifying_Non-Explicit_Citing_Sentences_for_Citation-Based_Summarization..html">140 acl-2010-Identifying Non-Explicit Citing Sentences for Citation-Based Summarization.</a></p>
<p>9 0.57023495 <a title="11-lsi-9" href="./acl-2010-Optimizing_Informativeness_and_Readability_for_Sentiment_Summarization.html">188 acl-2010-Optimizing Informativeness and Readability for Sentiment Summarization</a></p>
<p>10 0.53115267 <a title="11-lsi-10" href="./acl-2010-Plot_Induction_and_Evolutionary_Search_for_Story_Generation.html">196 acl-2010-Plot Induction and Evolutionary Search for Story Generation</a></p>
<p>11 0.48170304 <a title="11-lsi-11" href="./acl-2010-Metadata-Aware_Measures_for_Answer_Summarization_in_Community_Question_Answering.html">171 acl-2010-Metadata-Aware Measures for Answer Summarization in Community Question Answering</a></p>
<p>12 0.47500005 <a title="11-lsi-12" href="./acl-2010-Generating_Image_Descriptions_Using_Dependency_Relational_Patterns.html">124 acl-2010-Generating Image Descriptions Using Dependency Relational Patterns</a></p>
<p>13 0.4585357 <a title="11-lsi-13" href="./acl-2010-Generating_Templates_of_Entity_Summaries_with_an_Entity-Aspect_Model_and_Pattern_Mining.html">125 acl-2010-Generating Templates of Entity Summaries with an Entity-Aspect Model and Pattern Mining</a></p>
<p>14 0.40173841 <a title="11-lsi-14" href="./acl-2010-How_Many_Words_Is_a_Picture_Worth%3F_Automatic_Caption_Generation_for_News_Images.html">136 acl-2010-How Many Words Is a Picture Worth? Automatic Caption Generation for News Images</a></p>
<p>15 0.39020231 <a title="11-lsi-15" href="./acl-2010-A_Statistical_Model_for_Lost_Language_Decipherment.html">16 acl-2010-A Statistical Model for Lost Language Decipherment</a></p>
<p>16 0.38414142 <a title="11-lsi-16" href="./acl-2010-Evaluating_Multilanguage-Comparability_of_Subjectivity_Analysis_Systems.html">105 acl-2010-Evaluating Multilanguage-Comparability of Subjectivity Analysis Systems</a></p>
<p>17 0.3578645 <a title="11-lsi-17" href="./acl-2010-A_Generalized-Zero-Preserving_Method_for_Compact_Encoding_of_Concept_Lattices.html">7 acl-2010-A Generalized-Zero-Preserving Method for Compact Encoding of Concept Lattices</a></p>
<p>18 0.35682252 <a title="11-lsi-18" href="./acl-2010-A_Study_of_Information_Retrieval_Weighting_Schemes_for_Sentiment_Analysis.html">18 acl-2010-A Study of Information Retrieval Weighting Schemes for Sentiment Analysis</a></p>
<p>19 0.35387132 <a title="11-lsi-19" href="./acl-2010-Bilingual_Lexicon_Generation_Using_Non-Aligned_Signatures.html">50 acl-2010-Bilingual Lexicon Generation Using Non-Aligned Signatures</a></p>
<p>20 0.35150337 <a title="11-lsi-20" href="./acl-2010-Learning_Word-Class_Lattices_for_Definition_and_Hypernym_Extraction.html">166 acl-2010-Learning Word-Class Lattices for Definition and Hypernym Extraction</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(4, 0.326), (14, 0.018), (25, 0.035), (33, 0.021), (42, 0.018), (59, 0.089), (72, 0.015), (73, 0.044), (76, 0.02), (78, 0.019), (83, 0.095), (84, 0.041), (98, 0.151)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.82062972 <a title="11-lda-1" href="./acl-2010-Optimal_Rank_Reduction_for_Linear_Context-Free_Rewriting_Systems_with_Fan-Out_Two.html">186 acl-2010-Optimal Rank Reduction for Linear Context-Free Rewriting Systems with Fan-Out Two</a></p>
<p>Author: Benoit Sagot ; Giorgio Satta</p><p>Abstract: Linear Context-Free Rewriting Systems (LCFRSs) are a grammar formalism capable of modeling discontinuous phrases. Many parsing applications use LCFRSs where the fan-out (a measure of the discontinuity of phrases) does not exceed 2. We present an efficient algorithm for optimal reduction of the length of production right-hand side in LCFRSs with fan-out at most 2. This results in asymptotical running time improvement for known parsing algorithms for this class.</p><p>2 0.81497777 <a title="11-lda-2" href="./acl-2010-Combining_Data_and_Mathematical_Models_of_Language_Change.html">61 acl-2010-Combining Data and Mathematical Models of Language Change</a></p>
<p>Author: Morgan Sonderegger ; Partha Niyogi</p><p>Abstract: English noun/verb (N/V) pairs (contract, cement) have undergone complex patterns of change between 3 stress patterns for several centuries. We describe a longitudinal dataset of N/V pair pronunciations, leading to a set of properties to be accounted for by any computational model. We analyze the dynamics of 5 dynamical systems models of linguistic populations, each derived from a model of learning by individuals. We compare each model’s dynamics to a set of properties observed in the N/V data, and reason about how assumptions about individual learning affect population-level dynamics.</p><p>same-paper 3 0.76163065 <a title="11-lda-3" href="./acl-2010-A_New_Approach_to_Improving_Multilingual_Summarization_Using_a_Genetic_Algorithm.html">11 acl-2010-A New Approach to Improving Multilingual Summarization Using a Genetic Algorithm</a></p>
<p>Author: Marina Litvak ; Mark Last ; Menahem Friedman</p><p>Abstract: Automated summarization methods can be defined as “language-independent,” if they are not based on any languagespecific knowledge. Such methods can be used for multilingual summarization defined by Mani (2001) as “processing several languages, with summary in the same language as input.” In this paper, we introduce MUSE, a languageindependent approach for extractive summarization based on the linear optimization of several sentence ranking measures using a genetic algorithm. We tested our methodology on two languages—English and Hebrew—and evaluated its performance with ROUGE-1 Recall vs. state- of-the-art extractive summarization approaches. Our results show that MUSE performs better than the best known multilingual approach (TextRank1) in both languages. Moreover, our experimental results on a bilingual (English and Hebrew) document collection suggest that MUSE does not need to be retrained on each language and the same model can be used across at least two different languages.</p><p>4 0.74972177 <a title="11-lda-4" href="./acl-2010-Bayesian_Synchronous_Tree-Substitution_Grammar_Induction_and_Its_Application_to_Sentence_Compression.html">46 acl-2010-Bayesian Synchronous Tree-Substitution Grammar Induction and Its Application to Sentence Compression</a></p>
<p>Author: Elif Yamangil ; Stuart M. Shieber</p><p>Abstract: We describe our experiments with training algorithms for tree-to-tree synchronous tree-substitution grammar (STSG) for monolingual translation tasks such as sentence compression and paraphrasing. These translation tasks are characterized by the relative ability to commit to parallel parse trees and availability of word alignments, yet the unavailability of large-scale data, calling for a Bayesian tree-to-tree formalism. We formalize nonparametric Bayesian STSG with epsilon alignment in full generality, and provide a Gibbs sampling algorithm for posterior inference tailored to the task of extractive sentence compression. We achieve improvements against a number of baselines, including expectation maximization and variational Bayes training, illustrating the merits of nonparametric inference over the space of grammars as opposed to sparse parametric inference with a fixed grammar.</p><p>5 0.55392355 <a title="11-lda-5" href="./acl-2010-Blocked_Inference_in_Bayesian_Tree_Substitution_Grammars.html">53 acl-2010-Blocked Inference in Bayesian Tree Substitution Grammars</a></p>
<p>Author: Trevor Cohn ; Phil Blunsom</p><p>Abstract: Learning a tree substitution grammar is very challenging due to derivational ambiguity. Our recent approach used a Bayesian non-parametric model to induce good derivations from treebanked input (Cohn et al., 2009), biasing towards small grammars composed of small generalisable productions. In this paper we present a novel training method for the model using a blocked Metropolis-Hastings sampler in place of the previous method’s local Gibbs sampler. The blocked sampler makes considerably larger moves than the local sampler and consequently con- verges in less time. A core component of the algorithm is a grammar transformation which represents an infinite tree substitution grammar in a finite context free grammar. This enables efficient blocked inference for training and also improves the parsing algorithm. Both algorithms are shown to improve parsing accuracy.</p><p>6 0.54869699 <a title="11-lda-6" href="./acl-2010-Learning_Common_Grammar_from_Multilingual_Corpus.html">162 acl-2010-Learning Common Grammar from Multilingual Corpus</a></p>
<p>7 0.53664809 <a title="11-lda-7" href="./acl-2010-Hierarchical_Search_for_Word_Alignment.html">133 acl-2010-Hierarchical Search for Word Alignment</a></p>
<p>8 0.53477502 <a title="11-lda-8" href="./acl-2010-How_Many_Words_Is_a_Picture_Worth%3F_Automatic_Caption_Generation_for_News_Images.html">136 acl-2010-How Many Words Is a Picture Worth? Automatic Caption Generation for News Images</a></p>
<p>9 0.53249955 <a title="11-lda-9" href="./acl-2010-Open-Domain_Semantic_Role_Labeling_by_Modeling_Word_Spans.html">184 acl-2010-Open-Domain Semantic Role Labeling by Modeling Word Spans</a></p>
<p>10 0.53214979 <a title="11-lda-10" href="./acl-2010-Error_Detection_for_Statistical_Machine_Translation_Using_Linguistic_Features.html">102 acl-2010-Error Detection for Statistical Machine Translation Using Linguistic Features</a></p>
<p>11 0.53162497 <a title="11-lda-11" href="./acl-2010-Cross-Lingual_Latent_Topic_Extraction.html">79 acl-2010-Cross-Lingual Latent Topic Extraction</a></p>
<p>12 0.53085726 <a title="11-lda-12" href="./acl-2010-Bilingual_Sense_Similarity_for_Statistical_Machine_Translation.html">51 acl-2010-Bilingual Sense Similarity for Statistical Machine Translation</a></p>
<p>13 0.53068596 <a title="11-lda-13" href="./acl-2010-Automatic_Generation_of_Story_Highlights.html">39 acl-2010-Automatic Generation of Story Highlights</a></p>
<p>14 0.5299623 <a title="11-lda-14" href="./acl-2010-A_Risk_Minimization_Framework_for_Extractive_Speech_Summarization.html">14 acl-2010-A Risk Minimization Framework for Extractive Speech Summarization</a></p>
<p>15 0.52927983 <a title="11-lda-15" href="./acl-2010-Dynamic_Programming_for_Linear-Time_Incremental_Parsing.html">93 acl-2010-Dynamic Programming for Linear-Time Incremental Parsing</a></p>
<p>16 0.52907431 <a title="11-lda-16" href="./acl-2010-Improved_Unsupervised_POS_Induction_through_Prototype_Discovery.html">144 acl-2010-Improved Unsupervised POS Induction through Prototype Discovery</a></p>
<p>17 0.529001 <a title="11-lda-17" href="./acl-2010-Structural_Semantic_Relatedness%3A_A_Knowledge-Based_Method_to_Named_Entity_Disambiguation.html">218 acl-2010-Structural Semantic Relatedness: A Knowledge-Based Method to Named Entity Disambiguation</a></p>
<p>18 0.52899313 <a title="11-lda-18" href="./acl-2010-Understanding_the_Semantic_Structure_of_Noun_Phrase_Queries.html">245 acl-2010-Understanding the Semantic Structure of Noun Phrase Queries</a></p>
<p>19 0.52866238 <a title="11-lda-19" href="./acl-2010-Phylogenetic_Grammar_Induction.html">195 acl-2010-Phylogenetic Grammar Induction</a></p>
<p>20 0.5285418 <a title="11-lda-20" href="./acl-2010-Bootstrapping_Semantic_Analyzers_from_Non-Contradictory_Texts.html">55 acl-2010-Bootstrapping Semantic Analyzers from Non-Contradictory Texts</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
