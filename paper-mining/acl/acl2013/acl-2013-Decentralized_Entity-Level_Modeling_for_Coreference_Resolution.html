<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>106 acl-2013-Decentralized Entity-Level Modeling for Coreference Resolution</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-106" href="#">acl2013-106</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>106 acl-2013-Decentralized Entity-Level Modeling for Coreference Resolution</h1>
<br/><p>Source: <a title="acl-2013-106-pdf" href="http://aclweb.org/anthology//P/P13/P13-1012.pdf">pdf</a></p><p>Author: Greg Durrett ; David Hall ; Dan Klein</p><p>Abstract: Efficiently incorporating entity-level information is a challenge for coreference resolution systems due to the difficulty of exact inference over partitions. We describe an end-to-end discriminative probabilistic model for coreference that, along with standard pairwise features, enforces structural agreement constraints between specified properties of coreferent mentions. This model can be represented as a factor graph for each document that admits efficient inference via belief propagation. We show that our method can use entity-level information to outperform a basic pairwise system.</p><p>Reference: <a title="acl-2013-106-reference" href="../acl2013_reference/acl-2013-Decentralized_Entity-Level_Modeling_for_Coreference_Resolution_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Decentralized Entity-Level Modeling for Coreference Resolution Greg Durrett, David Hall, and Dan Klein Computer Science Division University of California, Berkeley {gdurrett , dlwh , kle in} @ c s . [sent-1, score-0.069]
</p><p>2 edu  Abstract Efficiently incorporating entity-level information is a challenge for coreference resolution systems due to the difficulty of exact inference over partitions. [sent-3, score-0.54]
</p><p>3 We describe an end-to-end discriminative probabilistic model for coreference that, along with standard pairwise features, enforces structural agreement constraints between specified properties of coreferent mentions. [sent-4, score-0.883]
</p><p>4 This model can be represented as a factor graph for each document that admits efficient inference via belief propagation. [sent-5, score-0.491]
</p><p>5 We show that our method can use entity-level information to outperform a basic pairwise system. [sent-6, score-0.196]
</p><p>6 1 Introduction  The inclusion of entity-level features has been a driving force behind the development of many coreference resolution systems (Luo et al. [sent-7, score-0.523]
</p><p>7 However, such systems may be locked into bad coreference decisions and are difficult to directly optimize for standard evaluation metrics. [sent-12, score-0.453]
</p><p>8 In this work, we present a new structured model of entity-level information designed to allow efficient inference. [sent-13, score-0.064]
</p><p>9 We use a log-linear model that can be expressed as a factor graph. [sent-14, score-0.085]
</p><p>10 Pairwise features appear in the model as unary factors, adjacent to nodes representing a choice of antecedent (or none) for each mention. [sent-15, score-0.198]
</p><p>11 Additional nodes model entity-level properties on a per-mention basis, and  structural agreement factors softly drive properties of coreferent mentions to agree with one another. [sent-16, score-0.933]
</p><p>12 This is a key feature of our model: mentions manage their partial membership in various coreference chains, so that information about entity-level properties is decentralized and propagated across individual mentions, and we never need to explicitly instantiate entities. [sent-17, score-1.019]
</p><p>13 Exact inference in this factor graph is intractable, but efficient approximate inference can be carried out with belief propagation. [sent-18, score-0.492]
</p><p>14 Our model is the first discriminatively-trained model that both makes joint decisions over an entire document and models specific entity-level properties, rather than simply enforcing transitivity of pairwise decisions (Finkel and Manning, 2008; Song et al. [sent-19, score-0.54]
</p><p>15 We evaluate our system on the dataset from the CoNLL 2011 shared task using three different types of properties: synthetic oracle properties, entity phi features (number, gender, animacy, and NER type), and properties derived from unsupervised clusters targeting semantic type information. [sent-21, score-0.395]
</p><p>16 In all cases, our transitive model of en-  tity properties equals or outperforms our pairwise system and our reimplementation of a previous entity-level system (Rahman and Ng, 2009). [sent-22, score-0.602]
</p><p>17 Our final system is competitive with the winner of the CoNLL 2011 shared task (Lee et al. [sent-23, score-0.06]
</p><p>18 2  Example  We begin with an example motivating our use of entity-level features. [sent-25, score-0.05]
</p><p>19 Consider the following excerpt concerning two famous auction houses: When looking for [art items], [people] go to [Sotheby ’s and Christie ’s] because [they]A believe [they]B can get the best price for [them]. [sent-26, score-0.401]
</p><p>20 The first three mentions are all distinct entities, theyA and theyB refer to people, and them refers to art items. [sent-27, score-0.253]
</p><p>21 The three pronouns are tricky to resolve 114  ProceedingSsof oifa, th Beu 5l1gsarti Aan,An uuaglu Mste 4e-ti9n2g 0 o1f3 t. [sent-28, score-0.172]
</p><p>22 c A2s0s1o3ci Aatsiosonc fioartio Cno fmorpu Ctoamtiopnuatalt Lioinngauli Lsitnicgsu,i psatgicess 114–124,  automatically because they could at first glance resolve to any of the preceding mentions. [sent-30, score-0.165]
</p><p>23 We focus in particular on the resolution of theyA and them. [sent-31, score-0.113]
</p><p>24 In order to correctly resolve theyA to people rather than Sotheby’s and Christie ’s, we must take advantage of the fact that theyA appears as the subject of the verb believe, which is much more likely to be attributed to people than to auction houses. [sent-32, score-0.562]
</p><p>25 But how do we prevent it from choosing as its antecedent the next closest agreeing pronoun, theyA? [sent-34, score-0.26]
</p><p>26 One way is to exploit the correct coreference decision we have already made, theyA referring to people, since people are not as likely to have a price as art items are. [sent-35, score-0.629]
</p><p>27 This observation argues for enforcing agreement of entity-level semantic properties during inference, specifically properties relating to permitted semantic roles. [sent-36, score-0.739]
</p><p>28 Because even these six mentions have hundreds of potential partitions into coreference chains, we cannot search over partitions exhaustively, and therefore we must design our model to be able to use this information while still admitting an efficient inference scheme. [sent-37, score-0.793]
</p><p>29 2), then explain how to extend it to use transitive features (Sections 3. [sent-40, score-0.088]
</p><p>30 Throughout this section, let x be a variable containing the words in a document along with any relevant precomputed annotation (such as parse information, semantic roles, etc. [sent-43, score-0.158]
</p><p>31 ), and let n denote the number of mentions in a given document. [sent-44, score-0.169]
</p><p>32 1 BASIC Model Our BASIC model is depicted in Figure 1 in standard factor graph notation. [sent-46, score-0.176]
</p><p>33 Each mention i has an associated random variable ai taking values in the set {1, . [sent-47, score-0.04]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('theya', 0.51), ('coreference', 0.278), ('properties', 0.215), ('rahman', 0.179), ('auction', 0.17), ('sotheby', 0.17), ('mentions', 0.169), ('christie', 0.15), ('decentralized', 0.15), ('pairwise', 0.135), ('people', 0.125), ('antecedent', 0.115), ('resolution', 0.113), ('inference', 0.106), ('decisions', 0.106), ('coreferent', 0.104), ('resolve', 0.103), ('enforcing', 0.095), ('price', 0.088), ('partitions', 0.088), ('transitive', 0.088), ('factor', 0.085), ('art', 0.084), ('belief', 0.081), ('prevent', 0.076), ('phi', 0.075), ('precomputed', 0.075), ('gdurrett', 0.075), ('chains', 0.07), ('locked', 0.069), ('tricky', 0.069), ('durrett', 0.069), ('agreeing', 0.069), ('animacy', 0.069), ('houses', 0.069), ('kle', 0.069), ('efficient', 0.064), ('glance', 0.062), ('tity', 0.062), ('bu', 0.062), ('admits', 0.062), ('permitted', 0.062), ('exhaustively', 0.062), ('basic', 0.061), ('manage', 0.06), ('raghunathan', 0.06), ('reimplementation', 0.06), ('winner', 0.06), ('conll', 0.059), ('ley', 0.057), ('ng', 0.056), ('transitivity', 0.055), ('greg', 0.055), ('manner', 0.054), ('items', 0.054), ('argues', 0.054), ('pipelined', 0.054), ('binding', 0.054), ('driving', 0.054), ('attaching', 0.054), ('targeting', 0.054), ('excerpt', 0.052), ('enforces', 0.052), ('agreement', 0.051), ('klein', 0.051), ('synthetic', 0.051), ('greedily', 0.051), ('instantiate', 0.051), ('graph', 0.05), ('luo', 0.05), ('membership', 0.05), ('motivating', 0.05), ('structural', 0.048), ('intractable', 0.047), ('relating', 0.047), ('famous', 0.047), ('finkel', 0.046), ('division', 0.046), ('propagated', 0.046), ('drive', 0.046), ('operating', 0.046), ('factors', 0.046), ('unary', 0.044), ('believe', 0.044), ('exact', 0.043), ('document', 0.043), ('equals', 0.042), ('depicted', 0.041), ('song', 0.041), ('throughout', 0.04), ('lee', 0.04), ('variable', 0.04), ('force', 0.039), ('inclusion', 0.039), ('pronoun', 0.039), ('nodes', 0.039), ('attributed', 0.039), ('haghighi', 0.038), ('berkeley', 0.037), ('ner', 0.037)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="106-tfidf-1" href="./acl-2013-Decentralized_Entity-Level_Modeling_for_Coreference_Resolution.html">106 acl-2013-Decentralized Entity-Level Modeling for Coreference Resolution</a></p>
<p>Author: Greg Durrett ; David Hall ; Dan Klein</p><p>Abstract: Efficiently incorporating entity-level information is a challenge for coreference resolution systems due to the difficulty of exact inference over partitions. We describe an end-to-end discriminative probabilistic model for coreference that, along with standard pairwise features, enforces structural agreement constraints between specified properties of coreferent mentions. This model can be represented as a factor graph for each document that admits efficient inference via belief propagation. We show that our method can use entity-level information to outperform a basic pairwise system.</p><p>2 0.29845408 <a title="106-tfidf-2" href="./acl-2013-Multigraph_Clustering_for_Unsupervised_Coreference_Resolution.html">252 acl-2013-Multigraph Clustering for Unsupervised Coreference Resolution</a></p>
<p>Author: Sebastian Martschat</p><p>Abstract: We present an unsupervised model for coreference resolution that casts the problem as a clustering task in a directed labeled weighted multigraph. The model outperforms most systems participating in the English track of the CoNLL’ 12 shared task.</p><p>3 0.23483494 <a title="106-tfidf-3" href="./acl-2013-Domain-Specific_Coreference_Resolution_with_Lexicalized_Features.html">130 acl-2013-Domain-Specific Coreference Resolution with Lexicalized Features</a></p>
<p>Author: Nathan Gilbert ; Ellen Riloff</p><p>Abstract: Most coreference resolvers rely heavily on string matching, syntactic properties, and semantic attributes of words, but they lack the ability to make decisions based on individual words. In this paper, we explore the benefits of lexicalized features in the setting of domain-specific coreference resolution. We show that adding lexicalized features to off-the-shelf coreference resolvers yields significant performance gains on four domain-specific data sets and with two types of coreference resolution architectures.</p><p>4 0.18297504 <a title="106-tfidf-4" href="./acl-2013-Improving_pairwise_coreference_models_through_feature_space_hierarchy_learning.html">196 acl-2013-Improving pairwise coreference models through feature space hierarchy learning</a></p>
<p>Author: Emmanuel Lassalle ; Pascal Denis</p><p>Abstract: This paper proposes a new method for significantly improving the performance of pairwise coreference models. Given a set of indicators, our method learns how to best separate types of mention pairs into equivalence classes for which we construct distinct classification models. In effect, our approach finds an optimal feature space (derived from a base feature set and indicator set) for discriminating coreferential mention pairs. Although our approach explores a very large space of possible feature spaces, it remains tractable by exploiting the structure of the hierarchies built from the indicators. Our exper- iments on the CoNLL-2012 Shared Task English datasets (gold mentions) indicate that our method is robust relative to different clustering strategies and evaluation metrics, showing large and consistent improvements over a single pairwise model using the same base features. Our best system obtains a competitive 67.2 of average F1 over MUC, and CEAF which, despite its simplicity, places it above the mean score of other systems on these datasets. B3,</p><p>5 0.09828683 <a title="106-tfidf-5" href="./acl-2013-Variational_Inference_for_Structured_NLP_Models.html">382 acl-2013-Variational Inference for Structured NLP Models</a></p>
<p>Author: David Burkett ; Dan Klein</p><p>Abstract: unkown-abstract</p><p>6 0.089295514 <a title="106-tfidf-6" href="./acl-2013-A_Structured_Distributional_Semantic_Model_for_Event_Co-reference.html">22 acl-2013-A Structured Distributional Semantic Model for Event Co-reference</a></p>
<p>7 0.086029679 <a title="106-tfidf-7" href="./acl-2013-Argument_Inference_from_Relevant_Event_Mentions_in_Chinese_Argument_Extraction.html">56 acl-2013-Argument Inference from Relevant Event Mentions in Chinese Argument Extraction</a></p>
<p>8 0.081463642 <a title="106-tfidf-8" href="./acl-2013-PARMA%3A_A_Predicate_Argument_Aligner.html">267 acl-2013-PARMA: A Predicate Argument Aligner</a></p>
<p>9 0.074610598 <a title="106-tfidf-9" href="./acl-2013-HYENA-live%3A_Fine-Grained_Online_Entity_Type_Classification_from_Natural-language_Text.html">179 acl-2013-HYENA-live: Fine-Grained Online Entity Type Classification from Natural-language Text</a></p>
<p>10 0.074312665 <a title="106-tfidf-10" href="./acl-2013-Recognizing_Identical_Events_with_Graph_Kernels.html">296 acl-2013-Recognizing Identical Events with Graph Kernels</a></p>
<p>11 0.07265871 <a title="106-tfidf-11" href="./acl-2013-Entity_Linking_for_Tweets.html">139 acl-2013-Entity Linking for Tweets</a></p>
<p>12 0.067379221 <a title="106-tfidf-12" href="./acl-2013-Graph-based_Local_Coherence_Modeling.html">172 acl-2013-Graph-based Local Coherence Modeling</a></p>
<p>13 0.064435154 <a title="106-tfidf-13" href="./acl-2013-Joint_Apposition_Extraction_with_Syntactic_and_Semantic_Constraints.html">205 acl-2013-Joint Apposition Extraction with Syntactic and Semantic Constraints</a></p>
<p>14 0.057757959 <a title="106-tfidf-14" href="./acl-2013-PLIS%3A_a_Probabilistic_Lexical_Inference_System.html">269 acl-2013-PLIS: a Probabilistic Lexical Inference System</a></p>
<p>15 0.057014622 <a title="106-tfidf-15" href="./acl-2013-GuiTAR-based_Pronominal_Anaphora_Resolution_in_Bengali.html">177 acl-2013-GuiTAR-based Pronominal Anaphora Resolution in Bengali</a></p>
<p>16 0.05501771 <a title="106-tfidf-16" href="./acl-2013-ImpAr%3A_A_Deterministic_Algorithm_for_Implicit_Semantic_Role_Labelling.html">189 acl-2013-ImpAr: A Deterministic Algorithm for Implicit Semantic Role Labelling</a></p>
<p>17 0.053658944 <a title="106-tfidf-17" href="./acl-2013-A_Markov_Model_of_Machine_Translation_using_Non-parametric_Bayesian_Inference.html">10 acl-2013-A Markov Model of Machine Translation using Non-parametric Bayesian Inference</a></p>
<p>18 0.052964844 <a title="106-tfidf-18" href="./acl-2013-Discovering_User_Interactions_in_Ideological_Discussions.html">121 acl-2013-Discovering User Interactions in Ideological Discussions</a></p>
<p>19 0.052817456 <a title="106-tfidf-19" href="./acl-2013-Margin-based_Decomposed_Amortized_Inference.html">237 acl-2013-Margin-based Decomposed Amortized Inference</a></p>
<p>20 0.052790143 <a title="106-tfidf-20" href="./acl-2013-Joint_Word_Alignment_and_Bilingual_Named_Entity_Recognition_Using_Dual_Decomposition.html">210 acl-2013-Joint Word Alignment and Bilingual Named Entity Recognition Using Dual Decomposition</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.128), (1, 0.033), (2, -0.035), (3, -0.09), (4, 0.003), (5, 0.168), (6, 0.013), (7, 0.101), (8, -0.034), (9, 0.057), (10, 0.008), (11, -0.099), (12, -0.058), (13, -0.046), (14, -0.073), (15, 0.095), (16, -0.127), (17, 0.215), (18, -0.049), (19, 0.092), (20, -0.16), (21, 0.119), (22, -0.033), (23, -0.187), (24, -0.045), (25, 0.036), (26, -0.054), (27, 0.108), (28, 0.143), (29, -0.038), (30, 0.041), (31, 0.025), (32, 0.05), (33, 0.003), (34, 0.046), (35, 0.015), (36, 0.043), (37, -0.009), (38, -0.028), (39, -0.026), (40, -0.035), (41, -0.014), (42, -0.005), (43, -0.036), (44, -0.014), (45, 0.03), (46, -0.015), (47, 0.051), (48, 0.014), (49, -0.034)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96094829 <a title="106-lsi-1" href="./acl-2013-Decentralized_Entity-Level_Modeling_for_Coreference_Resolution.html">106 acl-2013-Decentralized Entity-Level Modeling for Coreference Resolution</a></p>
<p>Author: Greg Durrett ; David Hall ; Dan Klein</p><p>Abstract: Efficiently incorporating entity-level information is a challenge for coreference resolution systems due to the difficulty of exact inference over partitions. We describe an end-to-end discriminative probabilistic model for coreference that, along with standard pairwise features, enforces structural agreement constraints between specified properties of coreferent mentions. This model can be represented as a factor graph for each document that admits efficient inference via belief propagation. We show that our method can use entity-level information to outperform a basic pairwise system.</p><p>2 0.91388977 <a title="106-lsi-2" href="./acl-2013-Multigraph_Clustering_for_Unsupervised_Coreference_Resolution.html">252 acl-2013-Multigraph Clustering for Unsupervised Coreference Resolution</a></p>
<p>Author: Sebastian Martschat</p><p>Abstract: We present an unsupervised model for coreference resolution that casts the problem as a clustering task in a directed labeled weighted multigraph. The model outperforms most systems participating in the English track of the CoNLL’ 12 shared task.</p><p>3 0.88424665 <a title="106-lsi-3" href="./acl-2013-Domain-Specific_Coreference_Resolution_with_Lexicalized_Features.html">130 acl-2013-Domain-Specific Coreference Resolution with Lexicalized Features</a></p>
<p>Author: Nathan Gilbert ; Ellen Riloff</p><p>Abstract: Most coreference resolvers rely heavily on string matching, syntactic properties, and semantic attributes of words, but they lack the ability to make decisions based on individual words. In this paper, we explore the benefits of lexicalized features in the setting of domain-specific coreference resolution. We show that adding lexicalized features to off-the-shelf coreference resolvers yields significant performance gains on four domain-specific data sets and with two types of coreference resolution architectures.</p><p>4 0.78669554 <a title="106-lsi-4" href="./acl-2013-Improving_pairwise_coreference_models_through_feature_space_hierarchy_learning.html">196 acl-2013-Improving pairwise coreference models through feature space hierarchy learning</a></p>
<p>Author: Emmanuel Lassalle ; Pascal Denis</p><p>Abstract: This paper proposes a new method for significantly improving the performance of pairwise coreference models. Given a set of indicators, our method learns how to best separate types of mention pairs into equivalence classes for which we construct distinct classification models. In effect, our approach finds an optimal feature space (derived from a base feature set and indicator set) for discriminating coreferential mention pairs. Although our approach explores a very large space of possible feature spaces, it remains tractable by exploiting the structure of the hierarchies built from the indicators. Our exper- iments on the CoNLL-2012 Shared Task English datasets (gold mentions) indicate that our method is robust relative to different clustering strategies and evaluation metrics, showing large and consistent improvements over a single pairwise model using the same base features. Our best system obtains a competitive 67.2 of average F1 over MUC, and CEAF which, despite its simplicity, places it above the mean score of other systems on these datasets. B3,</p><p>5 0.7208243 <a title="106-lsi-5" href="./acl-2013-GuiTAR-based_Pronominal_Anaphora_Resolution_in_Bengali.html">177 acl-2013-GuiTAR-based Pronominal Anaphora Resolution in Bengali</a></p>
<p>Author: Apurbalal Senapati ; Utpal Garain</p><p>Abstract: This paper attempts to use an off-the-shelf anaphora resolution (AR) system for Bengali. The language specific preprocessing modules of GuiTAR (v3.0.3) are identified and suitably designed for Bengali. Anaphora resolution module is also modified or replaced in order to realize different configurations of GuiTAR. Performance of each configuration is evaluated and experiment shows that the off-the-shelf AR system can be effectively used for Indic languages. 1</p><p>6 0.60283571 <a title="106-lsi-6" href="./acl-2013-Joint_Apposition_Extraction_with_Syntactic_and_Semantic_Constraints.html">205 acl-2013-Joint Apposition Extraction with Syntactic and Semantic Constraints</a></p>
<p>7 0.46285126 <a title="106-lsi-7" href="./acl-2013-Variational_Inference_for_Structured_NLP_Models.html">382 acl-2013-Variational Inference for Structured NLP Models</a></p>
<p>8 0.45543024 <a title="106-lsi-8" href="./acl-2013-Graph-based_Local_Coherence_Modeling.html">172 acl-2013-Graph-based Local Coherence Modeling</a></p>
<p>9 0.43361115 <a title="106-lsi-9" href="./acl-2013-PARMA%3A_A_Predicate_Argument_Aligner.html">267 acl-2013-PARMA: A Predicate Argument Aligner</a></p>
<p>10 0.41600296 <a title="106-lsi-10" href="./acl-2013-A_Structured_Distributional_Semantic_Model_for_Event_Co-reference.html">22 acl-2013-A Structured Distributional Semantic Model for Event Co-reference</a></p>
<p>11 0.40670046 <a title="106-lsi-11" href="./acl-2013-Text-Driven_Toponym_Resolution_using_Indirect_Supervision.html">340 acl-2013-Text-Driven Toponym Resolution using Indirect Supervision</a></p>
<p>12 0.38726377 <a title="106-lsi-12" href="./acl-2013-Learning_to_Order_Natural_Language_Texts.html">225 acl-2013-Learning to Order Natural Language Texts</a></p>
<p>13 0.32769307 <a title="106-lsi-13" href="./acl-2013-Entity_Linking_for_Tweets.html">139 acl-2013-Entity Linking for Tweets</a></p>
<p>14 0.32724819 <a title="106-lsi-14" href="./acl-2013-Plurality%2C_Negation%2C_and_Quantification%3ATowards_Comprehensive_Quantifier_Scope_Disambiguation.html">280 acl-2013-Plurality, Negation, and Quantification:Towards Comprehensive Quantifier Scope Disambiguation</a></p>
<p>15 0.31884307 <a title="106-lsi-15" href="./acl-2013-Margin-based_Decomposed_Amortized_Inference.html">237 acl-2013-Margin-based Decomposed Amortized Inference</a></p>
<p>16 0.31679279 <a title="106-lsi-16" href="./acl-2013-Recognizing_Identical_Events_with_Graph_Kernels.html">296 acl-2013-Recognizing Identical Events with Graph Kernels</a></p>
<p>17 0.30469742 <a title="106-lsi-17" href="./acl-2013-PLIS%3A_a_Probabilistic_Lexical_Inference_System.html">269 acl-2013-PLIS: a Probabilistic Lexical Inference System</a></p>
<p>18 0.30422023 <a title="106-lsi-18" href="./acl-2013-Exploring_Word_Order_Universals%3A_a_Probabilistic_Graphical_Model_Approach.html">149 acl-2013-Exploring Word Order Universals: a Probabilistic Graphical Model Approach</a></p>
<p>19 0.2964212 <a title="106-lsi-19" href="./acl-2013-HYENA-live%3A_Fine-Grained_Online_Entity_Type_Classification_from_Natural-language_Text.html">179 acl-2013-HYENA-live: Fine-Grained Online Entity Type Classification from Natural-language Text</a></p>
<p>20 0.26864997 <a title="106-lsi-20" href="./acl-2013-ImpAr%3A_A_Deterministic_Algorithm_for_Implicit_Semantic_Role_Labelling.html">189 acl-2013-ImpAr: A Deterministic Algorithm for Implicit Semantic Role Labelling</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.049), (6, 0.017), (11, 0.042), (24, 0.033), (26, 0.016), (35, 0.068), (42, 0.032), (48, 0.024), (70, 0.019), (88, 0.583), (95, 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92843616 <a title="106-lda-1" href="./acl-2013-Decentralized_Entity-Level_Modeling_for_Coreference_Resolution.html">106 acl-2013-Decentralized Entity-Level Modeling for Coreference Resolution</a></p>
<p>Author: Greg Durrett ; David Hall ; Dan Klein</p><p>Abstract: Efficiently incorporating entity-level information is a challenge for coreference resolution systems due to the difficulty of exact inference over partitions. We describe an end-to-end discriminative probabilistic model for coreference that, along with standard pairwise features, enforces structural agreement constraints between specified properties of coreferent mentions. This model can be represented as a factor graph for each document that admits efficient inference via belief propagation. We show that our method can use entity-level information to outperform a basic pairwise system.</p><p>2 0.89049876 <a title="106-lda-2" href="./acl-2013-Evaluating_a_City_Exploration_Dialogue_System_with_Integrated_Question-Answering_and_Pedestrian_Navigation.html">141 acl-2013-Evaluating a City Exploration Dialogue System with Integrated Question-Answering and Pedestrian Navigation</a></p>
<p>Author: Srinivasan Janarthanam ; Oliver Lemon ; Phil Bartie ; Tiphaine Dalmas ; Anna Dickinson ; Xingkun Liu ; William Mackaness ; Bonnie Webber</p><p>Abstract: We present a city navigation and tourist information mobile dialogue app with integrated question-answering (QA) and geographic information system (GIS) modules that helps pedestrian users to navigate in and learn about urban environments. In contrast to existing mobile apps which treat these problems independently, our Android app addresses the problem of navigation and touristic questionanswering in an integrated fashion using a shared dialogue context. We evaluated our system in comparison with Samsung S-Voice (which interfaces to Google navigation and Google search) with 17 users and found that users judged our system to be significantly more interesting to interact with and learn from. They also rated our system above Google search (with the Samsung S-Voice interface) for tourist information tasks.</p><p>3 0.84453654 <a title="106-lda-3" href="./acl-2013-Sorani_Kurdish_versus_Kurmanji_Kurdish%3A_An_Empirical_Comparison.html">327 acl-2013-Sorani Kurdish versus Kurmanji Kurdish: An Empirical Comparison</a></p>
<p>Author: Kyumars Sheykh Esmaili ; Shahin Salavati</p><p>Abstract: Resource scarcity along with diversity– both in dialect and script–are the two primary challenges in Kurdish language processing. In this paper we aim at addressing these two problems by (i) building a text corpus for Sorani and Kurmanji, the two main dialects of Kurdish, and (ii) highlighting some of the orthographic, phonological, and morphological differences between these two dialects from statistical and rule-based perspectives.</p><p>4 0.79374999 <a title="106-lda-4" href="./acl-2013-Reconstructing_an_Indo-European_Family_Tree_from_Non-native_English_Texts.html">299 acl-2013-Reconstructing an Indo-European Family Tree from Non-native English Texts</a></p>
<p>Author: Ryo Nagata ; Edward Whittaker</p><p>Abstract: Mother tongue interference is the phenomenon where linguistic systems of a mother tongue are transferred to another language. Although there has been plenty of work on mother tongue interference, very little is known about how strongly it is transferred to another language and about what relation there is across mother tongues. To address these questions, this paper explores and visualizes mother tongue interference preserved in English texts written by Indo-European language speakers. This paper further explores linguistic features that explain why certain relations are preserved in English writing, and which contribute to related tasks such as native language identification.</p><p>5 0.74793899 <a title="106-lda-5" href="./acl-2013-Enhanced_and_Portable_Dependency_Projection_Algorithms_Using_Interlinear_Glossed_Text.html">136 acl-2013-Enhanced and Portable Dependency Projection Algorithms Using Interlinear Glossed Text</a></p>
<p>Author: Ryan Georgi ; Fei Xia ; William D. Lewis</p><p>Abstract: As most of the world’s languages are under-resourced, projection algorithms offer an enticing way to bootstrap the resources available for one resourcepoor language from a resource-rich language by means of parallel text and word alignment. These algorithms, however, make the strong assumption that the language pairs share common structures and that the parse trees will resemble one another. This assumption is useful but often leads to errors in projection. In this paper, we will address this weakness by using trees created from instances of Interlinear Glossed Text (IGT) to discover patterns of divergence between the lan- guages. We will show that this method improves the performance of projection algorithms significantly in some languages by accounting for divergence between languages using only the partial supervision of a few corrected trees.</p><p>6 0.729159 <a title="106-lda-6" href="./acl-2013-Aggregated_Word_Pair_Features_for_Implicit_Discourse_Relation_Disambiguation.html">41 acl-2013-Aggregated Word Pair Features for Implicit Discourse Relation Disambiguation</a></p>
<p>7 0.68738306 <a title="106-lda-7" href="./acl-2013-The_Haves_and_the_Have-Nots%3A_Leveraging_Unlabelled_Corpora_for_Sentiment_Analysis.html">345 acl-2013-The Haves and the Have-Nots: Leveraging Unlabelled Corpora for Sentiment Analysis</a></p>
<p>8 0.58003557 <a title="106-lda-8" href="./acl-2013-Density_Maximization_in_Context-Sense_Metric_Space_for_All-words_WSD.html">111 acl-2013-Density Maximization in Context-Sense Metric Space for All-words WSD</a></p>
<p>9 0.52785403 <a title="106-lda-9" href="./acl-2013-Multigraph_Clustering_for_Unsupervised_Coreference_Resolution.html">252 acl-2013-Multigraph Clustering for Unsupervised Coreference Resolution</a></p>
<p>10 0.48395774 <a title="106-lda-10" href="./acl-2013-Neighbors_Help%3A_Bilingual_Unsupervised_WSD_Using_Context.html">258 acl-2013-Neighbors Help: Bilingual Unsupervised WSD Using Context</a></p>
<p>11 0.44048882 <a title="106-lda-11" href="./acl-2013-DKPro_WSD%3A_A_Generalized_UIMA-based_Framework_for_Word_Sense_Disambiguation.html">105 acl-2013-DKPro WSD: A Generalized UIMA-based Framework for Word Sense Disambiguation</a></p>
<p>12 0.40709865 <a title="106-lda-12" href="./acl-2013-Variational_Inference_for_Structured_NLP_Models.html">382 acl-2013-Variational Inference for Structured NLP Models</a></p>
<p>13 0.40206444 <a title="106-lda-13" href="./acl-2013-Domain-Specific_Coreference_Resolution_with_Lexicalized_Features.html">130 acl-2013-Domain-Specific Coreference Resolution with Lexicalized Features</a></p>
<p>14 0.3966887 <a title="106-lda-14" href="./acl-2013-GuiTAR-based_Pronominal_Anaphora_Resolution_in_Bengali.html">177 acl-2013-GuiTAR-based Pronominal Anaphora Resolution in Bengali</a></p>
<p>15 0.3933897 <a title="106-lda-15" href="./acl-2013-Dual_Training_and_Dual_Prediction_for_Polarity_Classification.html">131 acl-2013-Dual Training and Dual Prediction for Polarity Classification</a></p>
<p>16 0.3823157 <a title="106-lda-16" href="./acl-2013-Multilingual_Affect_Polarity_and_Valence_Prediction_in_Metaphor-Rich_Texts.html">253 acl-2013-Multilingual Affect Polarity and Valence Prediction in Metaphor-Rich Texts</a></p>
<p>17 0.38211066 <a title="106-lda-17" href="./acl-2013-Bilingually-Guided_Monolingual_Dependency_Grammar_Induction.html">70 acl-2013-Bilingually-Guided Monolingual Dependency Grammar Induction</a></p>
<p>18 0.38105029 <a title="106-lda-18" href="./acl-2013-Question_Classification_Transfer.html">292 acl-2013-Question Classification Transfer</a></p>
<p>19 0.38044754 <a title="106-lda-19" href="./acl-2013-Improving_pairwise_coreference_models_through_feature_space_hierarchy_learning.html">196 acl-2013-Improving pairwise coreference models through feature space hierarchy learning</a></p>
<p>20 0.36388546 <a title="106-lda-20" href="./acl-2013-Cross-lingual_Projections_between_Languages_from_Different_Families.html">97 acl-2013-Cross-lingual Projections between Languages from Different Families</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
