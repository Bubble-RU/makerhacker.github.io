<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>95 acl-2013-Crawling microblogging services to gather language-classified URLs. Workflow and case study</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-95" href="#">acl2013-95</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>95 acl-2013-Crawling microblogging services to gather language-classified URLs. Workflow and case study</h1>
<br/><p>Source: <a title="acl-2013-95-pdf" href="http://aclweb.org/anthology//P/P13/P13-3002.pdf">pdf</a></p><p>Author: Adrien Barbaresi</p><p>Abstract: We present a way to extract links from messages published on microblogging platforms and we classify them according to the language and possible relevance of their target in order to build a text corpus. Three platforms are taken into consideration: FriendFeed, identi.ca and Reddit, as they account for a relative diversity of user profiles and more importantly user languages. In order to explore them, we introduce a traversal algorithm based on user pages. As we target lesser-known languages, we try to focus on non-English posts by filtering out English text. Using mature open-source software from the NLP research field, a spell checker (as- pell) and a language identification system (langid .py), our case study and our benchmarks give an insight into the linguistic structure of the considered services.</p><p>Reference: <a title="acl-2013-95-reference" href="../acl2013_reference/acl-2013-Crawling_microblogging_services_to_gather_language-classified_URLs._Workflow_and_case_study_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Crawling microblogging services to gather language-classified URLs Workflow and case study Adrien Barbaresi ICAR Lab ENS Lyon & University of Lyon 15 parvis Ren e´ Descartes, 69007 Lyon, France adrien . [sent-1, score-0.432]
</p><p>2 fr @  Abstract We present a way to extract links from messages published on microblogging platforms and we classify them according to the language and possible relevance of their target in order to build a text corpus. [sent-3, score-0.535]
</p><p>3 ca and Reddit, as they account for a relative diversity of user profiles and more importantly user languages. [sent-5, score-0.153]
</p><p>4 In order to explore them, we introduce a traversal algorithm based on user pages. [sent-6, score-0.136]
</p><p>5 Using mature open-source software from the NLP research field, a spell checker (as-  pell) and a language identification system (langid . [sent-8, score-0.314]
</p><p>6 by tuples) to gather links that are crawled in order to build a corpus (Baroni et al. [sent-14, score-0.145]
</p><p>7 Other technical difficulties include diverse and partly unknown search biases due, in part, to search engine optimization tricks as well as undocumented PageRank adjustments. [sent-21, score-0.094]
</p><p>8 ensure better randomness in a population of web documents as described by (Henzinger et al. [sent-25, score-0.116]
</p><p>9 2 User-based URL gathering Our hypothesis is that microblogging services are a good alternative to overcome the limitations of seed URL collections and the biases implied by search engine optimization techniques, PageRank and link classification. [sent-28, score-0.435]
</p><p>10 Its obvious limits are the amount of spam and advertise-  ment. [sent-30, score-0.077]
</p><p>11 Its obvious bias consists in the technologyprone users who are familiar with these platforms and account for numerous short messages which in turn over-represent their own interests and hobbies. [sent-31, score-0.383]
</p><p>12 However, user-related biases also have advantages, most notably the fact that documents that are most likely to be important are being shared, which has benefits when it comes to gather links in lesser-known languages, below the Englishspeaking spammer’s radar. [sent-32, score-0.295]
</p><p>13 We think that social networks and microblogging services may be of great  help when it comes to focus on them. [sent-38, score-0.482]
</p><p>14 In fact, the most engaged social networking nations do arguably not use English as a first communicating language1 . [sent-39, score-0.13]
</p><p>15 In addition, crawling these services gives an opportunity to perform a case study of existing tools and platforms. [sent-40, score-0.194]
</p><p>16 Finally, the method presented here could be used in other contexts : microtext collections, user lists and relations could prove useful for microtext corpus building, network visualization or social network sampling purposes (Gjoka et al. [sent-41, score-0.489]
</p><p>17 These services provide a good overview of the peculiarities of social networks. [sent-45, score-0.19]
</p><p>18 At least by the last two of them a crawl appears to be manageable in terms of both API accessibility and corpus size, which is not the case concerning Twitter for example. [sent-46, score-0.096]
</p><p>19 ca is a social microblogging service built on open source tools and open standards, which is the reason why we chose to crawl it at first. [sent-50, score-0.458]
</p><p>20 2  FriendFeed  To our knowledge, FriendFeed is the most active of the three microblogging services considered here. [sent-55, score-0.308]
</p><p>21 com/Press Events/Press Releases/ 2011/12/Social Networking Leads as Top Online Activity Globally But the size difference between the two platforms makes this hypothesis unlikely. [sent-63, score-0.076]
</p><p>22 All in all, the relative tolerance of this website makes it a good candidate to gather a lot of text in a short period of time. [sent-66, score-0.123]
</p><p>23 3  Reddit  Reddit is a social bookmarking and a microblogging platform, which ranks to the 7th place worldwide in the news category according to Alexa. [sent-68, score-0.298]
</p><p>24 The users account for the linguistic relevance of their channel, the moderation processes are mature, and since the channels (or subreddits) have to be hand-picked,  they ensure a certain stability. [sent-70, score-0.18]
</p><p>25 Sadly, it is currently not possible to go back in time further than the 500th oldest post due to API limitations, which severely restricts the number of links one may crawl. [sent-74, score-0.084]
</p><p>26 URL harvesting: social network traversal, obvious spam and non-text documents filtering, optional spell check of the short message to see if it could be English text, optional record of user IDs for later crawls. [sent-76, score-0.476]
</p><p>27 Operations on the URL queue: redirection  checks, sampling by domain name. [sent-78, score-0.143]
</p><p>28 Download of the web documents and analysis: HTML code stripping, document validity check, language identification. [sent-80, score-0.116]
</p><p>29 ca on the other hand is the spell check performed on the short messages in order to target non-English ones. [sent-86, score-0.334]
</p><p>30 Indeed, all new messages can be taken into consideration on the latter, making a selection unnecessary. [sent-87, score-0.197]
</p><p>31 Links pointing to media documents, which represent a high volume oflinks shared on microblogging services, are excluded from this study, as its final purpose is to be able to build a text corpus. [sent-88, score-0.208]
</p><p>32 As a page is downloaded or a query is executed, links are filtered on the fly using a series of heuristics described below, and finally the rest of the links is  stored. [sent-89, score-0.228]
</p><p>33 In this study, the goal is to concentrate on nonEnglish speaking messages in the hope of finding non-English links. [sent-93, score-0.167]
</p><p>34 The main ’timeline’ fosters a users discovery approach, which then becomes user-centered as the spider focuses on a list of users who are expected not to post messages in English and/or spam. [sent-94, score-0.327]
</p><p>35 The messages are filtered at each step to ensure relevant URLs are collected. [sent-95, score-0.195]
</p><p>36 This implies that a lot of subtrees are pruned, so that the chances of completing the traversal increase. [sent-96, score-0.075]
</p><p>37 In fact, experience shows that a relatively small fraction of users and URLs is selected. [sent-97, score-0.126]
</p><p>38 This approach is ’static’, as it does not rely on any long poll requests (which are for instance used to capture a fraction of Twitter’s messages as they are made public), it actively fetches the required pages. [sent-98, score-0.271]
</p><p>39 2 Check for redirection and sampling Further work on the URL queue before the language identification task ensures an even smaller fraction of URLs really goes through the resourceexpensive process of fetching and analyzing web documents. [sent-100, score-0.353]
</p><p>40 The first step of preprocessing consists in finding those URLs that lead to a redirect, which is done using a list comprising all the major URL shortening services and adding all intriguingly short URLs, i. [sent-101, score-0.128]
</p><p>41 To deal with shortened URLs, one can perform HTTP HEAD requests for each member of the list in order to determine and store the final URL. [sent-104, score-0.09]
</p><p>42 Due to the overlaps of domain names and the amount of spam and advertisement on social networks such an approach is very useful when it comes to analyze a large list of URLs. [sent-107, score-0.251]
</p><p>43 3 Language identification Microtext has characteristics that make it hard for ’classical’ NLP approaches like web page language identification based on URLs (Baykan et al. [sent-109, score-0.226]
</p><p>44 That is why mature NLP tools have to be used to filter the incoming messages. [sent-111, score-0.227]
</p><p>45 A similar work on language identification and FriendFeed is described in (Celli, 2009), who uses a dictionary-based approach: the software tries to guess the language of microtext by identifying very frequent words. [sent-112, score-0.29]
</p><p>46 However, the fast-paced evolution of the vocabulary used on social networks makes it hard to  rely only on lists of frequent terms, so that our approach seems more complete. [sent-113, score-0.169]
</p><p>47 A first dictionary-based filter First, a quick test is used in order to guess whether a microtext is English or not. [sent-114, score-0.28]
</p><p>48 Indeed, this operation cuts the amount of microtexts in half and enables to select the users or the friends which feature the desired response, thus directing the traversal in a more fruitful direction. [sent-115, score-0.27]
</p><p>49 This first filter uses a threshold to discriminate between short messages, expressed as a percentage of tokens which do not pass the spell check. [sent-123, score-0.273]
</p><p>50 The filter also relies on software biases, like Unicode errors, which make it nearly certain that the given input microtext is not English. [sent-124, score-0.307]
</p><p>51 py A language identification tool is used to classify the web documents and to benchmark the efficiency of the test mentioned above. [sent-127, score-0.178]
</p><p>52 Its use as a web service makes it a fast solution enabling distant or distributed work. [sent-130, score-0.098]
</p><p>53 However, this feature was discarded because it did not prove as efficient as  the approach used here when it comes to a substantial amounts of short messages. [sent-135, score-0.099]
</p><p>54 4  Results  The surface crawl dealing with the main timeline and one level of depth has been performed on the three platforms6. [sent-136, score-0.129]
</p><p>55 FriendFeed proved too large to start such a breadth-first crawler so that other strategies ought to be used (Gjoka et al. [sent-139, score-0.092]
</p><p>56 FriendFeed is the biggest link provider on a regular basis (about 10,000 or 15,000 messages per hour can easily be collected), whereas Reddit is the weakest, as the total figures show. [sent-141, score-0.167]
</p><p>57 Accordingly, English accounts for about 55 % of the websites7, with the second mostused content-language, German, only representing  6Several techniques are used to keep the number of requests as low as possible, most notably user profiling according to the tweeting frequency. [sent-143, score-0.119]
</p><p>58 So, there is a gap between English and the other languages, and there is also a discrepancy between the number of Internet users and the content languages. [sent-148, score-0.109]
</p><p>59 1 FriendFeed To test whether the first language filter was efficient, a testing sample of URLs and users was collected randomly. [sent-150, score-0.253]
</p><p>60 The first filter was emulated by selecting about 8% of messages (based on a random function) in the spam and mediafiltered posts of the public timeline. [sent-151, score-0.439]
</p><p>61 Indeed, the messages selected by the algorithm approximately amount to this fraction of the total. [sent-152, score-0.213]
</p><p>62 At the same time, the corresponding users were retrieved, exactly as described above, and then the user-based step was run, keeping one half of the user’s messages, which is also realistic according to real-  world data. [sent-153, score-0.08]
</p><p>63 The datasets compared here were both of an order of magnitude of at least 105 unique URLs before the redirection checks. [sent-154, score-0.095]
</p><p>64 62057  Table 1: 5 most frequent languages of URLs taken at random on FriendFeed According to the language identification system  (langid . [sent-159, score-0.158]
</p><p>65 py), the first language filter beats the random function by nearly 30 points (see Table 2). [sent-160, score-0.141]
</p><p>66 8The figures given describe the situation at the end, after the sampling by domain name and after the selection of documents based on a minimum length. [sent-165, score-0.094]
</p><p>67 The word URL is used as a shortcut for the web documents they link to. [sent-166, score-0.116]
</p><p>68 12  Table 2: 10 most frequent languages of spellcheck-filtered URLs gathered on FriendFeed 4. [sent-167, score-0.141]
</p><p>69 ca led to a total of 1,113,783 URLs checked for redirection, which were collected in about a week (the deep crawler reached 37,485 user IDs). [sent-170, score-0.148]
</p><p>70 9 %), since no language filter was used but only a spam filter. [sent-172, score-0.218]
</p><p>71 Table 3: 10 most frequent languages of URLs gathered on identi. [sent-173, score-0.141]
</p><p>72 3  Reddit  The figures presented here are the results of a single crawl of all available languages altogether, but regular crawls are needed to compensate for the 500 posts limit. [sent-175, score-0.271]
</p><p>73 1 % of the links found on channel pages (for a total of 4,769 URLs) and 55. [sent-177, score-0.128]
</p><p>74 9 % of the sum of the links  found on channel and on user pages (for a total of 20,173 URLs). [sent-178, score-0.189]
</p><p>75 The results in Table 5 show that the first filter was nearly sufficient to discriminate between the  Table 4: 10 most frequent languages of filtered URLs gathered on Reddit channels and on a combination of channels and user pages links. [sent-179, score-0.475]
</p><p>76 Indeed, the microtexts that were under the threshold led to a total of 204,170 URLs. [sent-180, score-0.071]
</p><p>77 28,605  URLs remained at the end of the toolchain and English accounted for 76. [sent-181, score-0.101]
</p><p>78 Yet, the lower filter achieved better results, which may be explained by the moderation system of the subreddits as well as by the greater regularity in the posts of this platform. [sent-185, score-0.338]
</p><p>79 5  Discussion  Three main technical challenges had to be addressed, which resulted in a separate workflow: the shortened URLs are numerous, yet they ought to be resolved in order to enable the use of heuristics based on the nature of the URLs or a proper sampling of the URLs themselves. [sent-186, score-0.117]
</p><p>80 The confrontation with the constantly increasing number of URLs to analyze and the necessarily limited re13  sources make a website sampling by domain name useful. [sent-187, score-0.082]
</p><p>81 Finally, the diversity of the web documents put the language recognition tools to a test, so that a few tweaks are necessary to correct the results. [sent-188, score-0.231]
</p><p>82 The relatively low number of results for Russian may be explained by weaknesses of langid . [sent-189, score-0.126]
</p><p>83 Indeed, a few tweaks are necessary to correct the biases of the software in its pre-trained version, in particular regarding texts falsely considered as being written in Chinese, although URL-based heuristics indi-  cate that the website is most probably hosted in Russia or in Japan. [sent-191, score-0.243]
</p><p>84 Ideally, a full-fledged comparison with other language identification software may be necessary to identify its areas of expertise. [sent-194, score-0.146]
</p><p>85 A common practice known as cloaking has not been addressed so far: a substantial fraction of web pages show a different content to crawler engines and to browsers. [sent-195, score-0.208]
</p><p>86 This Janus-faced behavior tends to alter the language characteristics of the web page in favor of English results. [sent-196, score-0.102]
</p><p>87 Regarding topics, a major user bias was not addressed either: among the most frequently shared links on identi. [sent-197, score-0.145]
</p><p>88 The social media analyzed here tend to be dominated by English-speaking users, either native speakers or second-language learners. [sent-199, score-0.09]
</p><p>89 The contrasted results on Reddit shed a different light on the exploration of user pages: in all likelihood, users mainly share links in English when they are not posting them on a language-relevant channel. [sent-202, score-0.225]
</p><p>90 The results on FriendFeed are better from this point of view, which may suggest that English is not used equally on all platforms by users who speak other languages than English. [sent-203, score-0.219]
</p><p>91 Nonetheless, the fact that the microblogging services studied here are mainly English-speaking seems to be a strong tendency. [sent-204, score-0.308]
</p><p>92 Last but not least, the adequateness of the web documents shared on social networks has yet to be thoroughly assessed. [sent-205, score-0.252]
</p><p>93 From the output of this toolchain to a full-fledged web corpus, other finegrained instruments (Sch a¨fer and Bildhauer, 2012) as well as further decisions processes (Sch a¨fer et al. [sent-206, score-0.141]
</p><p>94 6  Conclusion  We presented a methodology to gather multilingual URLs on three microblogging platforms. [sent-208, score-0.269]
</p><p>95 In order to do so, we perform traversals of the platforms and use already available tools to filter the URLs accordingly and identify their language. [sent-209, score-0.283]
</p><p>96 The main goal is achieved, as hundreds if not thousands of URLs for lesser-known languages such as Romanian or Indonesian can be gathered on social networks and microblogging services. [sent-214, score-0.452]
</p><p>97 When it comes to filter out English posts, a first step using an English spell checker gives better results than the baseline established using microtexts selected at random. [sent-215, score-0.396]
</p><p>98 However, the discrepancy between the languages one would expect to  find based on demographic indicators and the results of the study is remarkable. [sent-216, score-0.092]
</p><p>99 English websites stay numerous even when one tries to filter them out. [sent-217, score-0.201]
</p><p>100 Last, a random-walk crawl using these seeds and a state of the art text categorization may provide more information on what is really shared on microblogging platforms. [sent-219, score-0.304]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('friendfeed', 0.499), ('urls', 0.42), ('reddit', 0.285), ('microblogging', 0.208), ('messages', 0.167), ('filter', 0.141), ('langid', 0.126), ('microtext', 0.11), ('spell', 0.104), ('services', 0.1), ('url', 0.098), ('crawl', 0.096), ('redirection', 0.095), ('subreddits', 0.095), ('social', 0.09), ('links', 0.084), ('users', 0.08), ('spam', 0.077), ('platforms', 0.076), ('traversal', 0.075), ('gjoka', 0.071), ('henzinger', 0.071), ('microtexts', 0.071), ('toolchain', 0.071), ('web', 0.07), ('biases', 0.066), ('fer', 0.065), ('adrien', 0.063), ('languages', 0.063), ('identification', 0.062), ('lui', 0.062), ('user', 0.061), ('gather', 0.061), ('requests', 0.058), ('crawling', 0.058), ('crawls', 0.058), ('apis', 0.058), ('software', 0.056), ('lyon', 0.055), ('crawler', 0.055), ('posts', 0.054), ('channels', 0.052), ('mature', 0.05), ('sampling', 0.048), ('barbaresi', 0.048), ('baykan', 0.048), ('moderation', 0.048), ('monika', 0.048), ('tweaks', 0.048), ('fraction', 0.046), ('networks', 0.046), ('documents', 0.046), ('gathered', 0.045), ('roland', 0.044), ('friends', 0.044), ('channel', 0.044), ('sch', 0.042), ('checker', 0.042), ('truc', 0.042), ('twitter', 0.042), ('workflow', 0.04), ('networking', 0.04), ('felix', 0.039), ('hosted', 0.039), ('indonesian', 0.039), ('comes', 0.038), ('engines', 0.037), ('ought', 0.037), ('norwegian', 0.037), ('tools', 0.036), ('network', 0.035), ('check', 0.035), ('ens', 0.035), ('website', 0.034), ('api', 0.034), ('limitations', 0.033), ('discarded', 0.033), ('romanian', 0.033), ('timeline', 0.033), ('indeed', 0.033), ('frequent', 0.033), ('numerous', 0.032), ('page', 0.032), ('queue', 0.032), ('shortened', 0.032), ('collected', 0.032), ('diversity', 0.031), ('gupta', 0.031), ('consideration', 0.03), ('accordingly', 0.03), ('accounted', 0.03), ('discrepancy', 0.029), ('guess', 0.029), ('engine', 0.028), ('filtered', 0.028), ('html', 0.028), ('areas', 0.028), ('service', 0.028), ('short', 0.028), ('websites', 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999997 <a title="95-tfidf-1" href="./acl-2013-Crawling_microblogging_services_to_gather_language-classified_URLs._Workflow_and_case_study.html">95 acl-2013-Crawling microblogging services to gather language-classified URLs. Workflow and case study</a></p>
<p>Author: Adrien Barbaresi</p><p>Abstract: We present a way to extract links from messages published on microblogging platforms and we classify them according to the language and possible relevance of their target in order to build a text corpus. Three platforms are taken into consideration: FriendFeed, identi.ca and Reddit, as they account for a relative diversity of user profiles and more importantly user languages. In order to explore them, we introduce a traversal algorithm based on user pages. As we target lesser-known languages, we try to focus on non-English posts by filtering out English text. Using mature open-source software from the NLP research field, a spell checker (as- pell) and a language identification system (langid .py), our case study and our benchmarks give an insight into the linguistic structure of the considered services.</p><p>2 0.13985448 <a title="95-tfidf-2" href="./acl-2013-Dirt_Cheap_Web-Scale_Parallel_Text_from_the_Common_Crawl.html">120 acl-2013-Dirt Cheap Web-Scale Parallel Text from the Common Crawl</a></p>
<p>Author: Jason R. Smith ; Herve Saint-Amand ; Magdalena Plamada ; Philipp Koehn ; Chris Callison-Burch ; Adam Lopez</p><p>Abstract: Parallel text is the fuel that drives modern machine translation systems. The Web is a comprehensive source of preexisting parallel text, but crawling the entire web is impossible for all but the largest companies. We bring web-scale parallel text to the masses by mining the Common Crawl, a public Web crawl hosted on Amazon’s Elastic Cloud. Starting from nothing more than a set of common two-letter language codes, our open-source extension of the STRAND algorithm mined 32 terabytes of the crawl in just under a day, at a cost of about $500. Our large-scale experiment uncovers large amounts of parallel text in dozens of language pairs across a variety of domains and genres, some previously unavailable in curated datasets. Even with minimal cleaning and filtering, the resulting data boosts translation performance across the board for five different language pairs in the news domain, and on open domain test sets we see improvements of up to 5 BLEU. We make our code and data available for other researchers seeking to mine this rich new data resource.1</p><p>3 0.133063 <a title="95-tfidf-3" href="./acl-2013-Detecting_Event-Related_Links_and_Sentiments_from_Social_Media_Texts.html">115 acl-2013-Detecting Event-Related Links and Sentiments from Social Media Texts</a></p>
<p>Author: Alexandra Balahur ; Hristo Tanev</p><p>Abstract: Nowadays, the importance of Social Media is constantly growing, as people often use such platforms to share mainstream media news and comment on the events that they relate to. As such, people no loger remain mere spectators to the events that happen in the world, but become part of them, commenting on their developments and the entities involved, sharing their opinions and distributing related content. This paper describes a system that links the main events detected from clusters of newspaper articles to tweets related to them, detects complementary information sources from the links they contain and subsequently applies sentiment analysis to classify them into positive, negative and neutral. In this manner, readers can follow the main events happening in the world, both from the perspective of mainstream as well as social media and the public’s perception on them. This system will be part of the EMM media monitoring framework working live and it will be demonstrated using Google Earth.</p><p>4 0.084980719 <a title="95-tfidf-4" href="./acl-2013-Exploiting_Social_Media_for_Natural_Language_Processing%3A_Bridging_the_Gap_between_Language-centric_and_Real-world_Applications.html">146 acl-2013-Exploiting Social Media for Natural Language Processing: Bridging the Gap between Language-centric and Real-world Applications</a></p>
<p>Author: Simone Paolo Ponzetto ; Andrea Zielinski</p><p>Abstract: unkown-abstract</p><p>5 0.08358936 <a title="95-tfidf-5" href="./acl-2013-Microblogs_as_Parallel_Corpora.html">240 acl-2013-Microblogs as Parallel Corpora</a></p>
<p>Author: Wang Ling ; Guang Xiang ; Chris Dyer ; Alan Black ; Isabel Trancoso</p><p>Abstract: In the ever-expanding sea of microblog data, there is a surprising amount of naturally occurring parallel text: some users create post multilingual messages targeting international audiences while others “retweet” translations. We present an efficient method for detecting these messages and extracting parallel segments from them. We have been able to extract over 1M Chinese-English parallel segments from Sina Weibo (the Chinese counterpart of Twitter) using only their public APIs. As a supplement to existing parallel training data, our automatically extracted parallel data yields substantial translation quality improvements in translating microblog text and modest improvements in translating edited news commentary. The resources in described in this paper are available at http://www.cs.cmu.edu/∼lingwang/utopia.</p><p>6 0.073187307 <a title="95-tfidf-6" href="./acl-2013-A_Stacking-based_Approach_to_Twitter_User_Geolocation_Prediction.html">20 acl-2013-A Stacking-based Approach to Twitter User Geolocation Prediction</a></p>
<p>7 0.069753654 <a title="95-tfidf-7" href="./acl-2013-Resolving_Entity_Morphs_in_Censored_Data.html">301 acl-2013-Resolving Entity Morphs in Censored Data</a></p>
<p>8 0.067997321 <a title="95-tfidf-8" href="./acl-2013-Using_Conceptual_Class_Attributes_to_Characterize_Social_Media_Users.html">373 acl-2013-Using Conceptual Class Attributes to Characterize Social Media Users</a></p>
<p>9 0.066006973 <a title="95-tfidf-9" href="./acl-2013-Improving_Chinese_Word_Segmentation_on_Micro-blog_Using_Rich_Punctuations.html">193 acl-2013-Improving Chinese Word Segmentation on Micro-blog Using Rich Punctuations</a></p>
<p>10 0.061080061 <a title="95-tfidf-10" href="./acl-2013-A_user-centric_model_of_voting_intention_from_Social_Media.html">33 acl-2013-A user-centric model of voting intention from Social Media</a></p>
<p>11 0.057347715 <a title="95-tfidf-11" href="./acl-2013-AnnoMarket%3A_An_Open_Cloud_Platform_for_NLP.html">51 acl-2013-AnnoMarket: An Open Cloud Platform for NLP</a></p>
<p>12 0.055782463 <a title="95-tfidf-12" href="./acl-2013-Discovering_User_Interactions_in_Ideological_Discussions.html">121 acl-2013-Discovering User Interactions in Ideological Discussions</a></p>
<p>13 0.054459181 <a title="95-tfidf-13" href="./acl-2013-An_Empirical_Study_on_Uncertainty_Identification_in_Social_Media_Context.html">45 acl-2013-An Empirical Study on Uncertainty Identification in Social Media Context</a></p>
<p>14 0.053524695 <a title="95-tfidf-14" href="./acl-2013-ICARUS_-_An_Extensible_Graphical_Search_Tool_for_Dependency_Treebanks.html">183 acl-2013-ICARUS - An Extensible Graphical Search Tool for Dependency Treebanks</a></p>
<p>15 0.052327782 <a title="95-tfidf-15" href="./acl-2013-Linking_Tweets_to_News%3A_A_Framework_to_Enrich_Short_Text_Data_in_Social_Media.html">233 acl-2013-Linking Tweets to News: A Framework to Enrich Short Text Data in Social Media</a></p>
<p>16 0.052266546 <a title="95-tfidf-16" href="./acl-2013-Deceptive_Answer_Prediction_with_User_Preference_Graph.html">107 acl-2013-Deceptive Answer Prediction with User Preference Graph</a></p>
<p>17 0.05004558 <a title="95-tfidf-17" href="./acl-2013-Building_and_Evaluating_a_Distributional_Memory_for_Croatian.html">76 acl-2013-Building and Evaluating a Distributional Memory for Croatian</a></p>
<p>18 0.049592249 <a title="95-tfidf-18" href="./acl-2013-Task_Alternation_in_Parallel_Sentence_Retrieval_for_Twitter_Translation.html">338 acl-2013-Task Alternation in Parallel Sentence Retrieval for Twitter Translation</a></p>
<p>19 0.049254987 <a title="95-tfidf-19" href="./acl-2013-Adaptive_Parser-Centric_Text_Normalization.html">37 acl-2013-Adaptive Parser-Centric Text Normalization</a></p>
<p>20 0.047284473 <a title="95-tfidf-20" href="./acl-2013-Generating_Synthetic_Comparable_Questions_for_News_Articles.html">169 acl-2013-Generating Synthetic Comparable Questions for News Articles</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.134), (1, 0.073), (2, 0.015), (3, 0.008), (4, 0.067), (5, -0.017), (6, 0.064), (7, 0.009), (8, 0.1), (9, -0.093), (10, -0.089), (11, 0.029), (12, 0.021), (13, -0.004), (14, -0.031), (15, -0.049), (16, -0.01), (17, -0.0), (18, -0.011), (19, -0.049), (20, -0.033), (21, -0.007), (22, -0.011), (23, -0.013), (24, 0.032), (25, -0.002), (26, 0.003), (27, 0.015), (28, 0.025), (29, 0.002), (30, -0.037), (31, -0.04), (32, -0.053), (33, -0.021), (34, 0.091), (35, 0.04), (36, 0.015), (37, -0.024), (38, -0.007), (39, -0.028), (40, -0.01), (41, -0.015), (42, 0.007), (43, 0.056), (44, 0.013), (45, -0.035), (46, 0.051), (47, -0.101), (48, 0.05), (49, -0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92701399 <a title="95-lsi-1" href="./acl-2013-Crawling_microblogging_services_to_gather_language-classified_URLs._Workflow_and_case_study.html">95 acl-2013-Crawling microblogging services to gather language-classified URLs. Workflow and case study</a></p>
<p>Author: Adrien Barbaresi</p><p>Abstract: We present a way to extract links from messages published on microblogging platforms and we classify them according to the language and possible relevance of their target in order to build a text corpus. Three platforms are taken into consideration: FriendFeed, identi.ca and Reddit, as they account for a relative diversity of user profiles and more importantly user languages. In order to explore them, we introduce a traversal algorithm based on user pages. As we target lesser-known languages, we try to focus on non-English posts by filtering out English text. Using mature open-source software from the NLP research field, a spell checker (as- pell) and a language identification system (langid .py), our case study and our benchmarks give an insight into the linguistic structure of the considered services.</p><p>2 0.71652371 <a title="95-lsi-2" href="./acl-2013-A_Stacking-based_Approach_to_Twitter_User_Geolocation_Prediction.html">20 acl-2013-A Stacking-based Approach to Twitter User Geolocation Prediction</a></p>
<p>Author: Bo Han ; Paul Cook ; Timothy Baldwin</p><p>Abstract: We implement a city-level geolocation prediction system for Twitter users. The system infers a user’s location based on both tweet text and user-declared metadata using a stacking approach. We demonstrate that the stacking method substantially outperforms benchmark methods, achieving 49% accuracy on a benchmark dataset. We further evaluate our method on a recent crawl of Twitter data to investigate the impact of temporal factors on model generalisation. Our results suggest that user-declared location metadata is more sensitive to temporal change than the text of Twitter messages. We also describe two ways of accessing/demoing our system.</p><p>3 0.66590226 <a title="95-lsi-3" href="./acl-2013-A_computational_approach_to_politeness_with_application_to_social_factors.html">30 acl-2013-A computational approach to politeness with application to social factors</a></p>
<p>Author: Cristian Danescu-Niculescu-Mizil ; Moritz Sudhof ; Dan Jurafsky ; Jure Leskovec ; Christopher Potts</p><p>Abstract: We propose a computational framework for identifying linguistic aspects of politeness. Our starting point is a new corpus of requests annotated for politeness, which we use to evaluate aspects of politeness theory and to uncover new interactions between politeness markers and context. These findings guide our construction of a classifier with domain-independent lexical and syntactic features operationalizing key components of politeness theory, such as indirection, deference, impersonalization and modality. Our classifier achieves close to human performance and is effective across domains. We use our framework to study the relationship between po- liteness and social power, showing that polite Wikipedia editors are more likely to achieve high status through elections, but, once elevated, they become less polite. We see a similar negative correlation between politeness and power on Stack Exchange, where users at the top of the reputation scale are less polite than those at the bottom. Finally, we apply our classifier to a preliminary analysis of politeness variation by gender and community.</p><p>4 0.66536295 <a title="95-lsi-4" href="./acl-2013-An_Empirical_Study_on_Uncertainty_Identification_in_Social_Media_Context.html">45 acl-2013-An Empirical Study on Uncertainty Identification in Social Media Context</a></p>
<p>Author: Zhongyu Wei ; Junwen Chen ; Wei Gao ; Binyang Li ; Lanjun Zhou ; Yulan He ; Kam-Fai Wong</p><p>Abstract: Uncertainty text detection is important to many social-media-based applications since more and more users utilize social media platforms (e.g., Twitter, Facebook, etc.) as information source to produce or derive interpretations based on them. However, existing uncertainty cues are ineffective in social media context because of its specific characteristics. In this paper, we propose a variant of annotation scheme for uncertainty identification and construct the first uncertainty corpus based on tweets. We then conduct experiments on the generated tweets corpus to study the effectiveness of different types of features for uncertainty text identification.</p><p>5 0.63912851 <a title="95-lsi-5" href="./acl-2013-Exploiting_Social_Media_for_Natural_Language_Processing%3A_Bridging_the_Gap_between_Language-centric_and_Real-world_Applications.html">146 acl-2013-Exploiting Social Media for Natural Language Processing: Bridging the Gap between Language-centric and Real-world Applications</a></p>
<p>Author: Simone Paolo Ponzetto ; Andrea Zielinski</p><p>Abstract: unkown-abstract</p><p>6 0.62334806 <a title="95-lsi-6" href="./acl-2013-Resolving_Entity_Morphs_in_Censored_Data.html">301 acl-2013-Resolving Entity Morphs in Censored Data</a></p>
<p>7 0.62210584 <a title="95-lsi-7" href="./acl-2013-A_user-centric_model_of_voting_intention_from_Social_Media.html">33 acl-2013-A user-centric model of voting intention from Social Media</a></p>
<p>8 0.58522785 <a title="95-lsi-8" href="./acl-2013-PATHS%3A_A_System_for_Accessing_Cultural_Heritage_Collections.html">268 acl-2013-PATHS: A System for Accessing Cultural Heritage Collections</a></p>
<p>9 0.5839293 <a title="95-lsi-9" href="./acl-2013-Using_Conceptual_Class_Attributes_to_Characterize_Social_Media_Users.html">373 acl-2013-Using Conceptual Class Attributes to Characterize Social Media Users</a></p>
<p>10 0.58323509 <a title="95-lsi-10" href="./acl-2013-AnnoMarket%3A_An_Open_Cloud_Platform_for_NLP.html">51 acl-2013-AnnoMarket: An Open Cloud Platform for NLP</a></p>
<p>11 0.574117 <a title="95-lsi-11" href="./acl-2013-Detecting_Chronic_Critics_Based_on_Sentiment_Polarity_and_User%C3%A2%E2%80%A2%C5%BDs_Behavior_in_Social_Media.html">114 acl-2013-Detecting Chronic Critics Based on Sentiment Polarity and Userâ•Žs Behavior in Social Media</a></p>
<p>12 0.56461382 <a title="95-lsi-12" href="./acl-2013-Microblogs_as_Parallel_Corpora.html">240 acl-2013-Microblogs as Parallel Corpora</a></p>
<p>13 0.55936754 <a title="95-lsi-13" href="./acl-2013-ICARUS_-_An_Extensible_Graphical_Search_Tool_for_Dependency_Treebanks.html">183 acl-2013-ICARUS - An Extensible Graphical Search Tool for Dependency Treebanks</a></p>
<p>14 0.53248686 <a title="95-lsi-14" href="./acl-2013-Detecting_Event-Related_Links_and_Sentiments_from_Social_Media_Texts.html">115 acl-2013-Detecting Event-Related Links and Sentiments from Social Media Texts</a></p>
<p>15 0.52373958 <a title="95-lsi-15" href="./acl-2013-Sequential_Summarization%3A_A_New_Application_for_Timely_Updated_Twitter_Trending_Topics.html">319 acl-2013-Sequential Summarization: A New Application for Timely Updated Twitter Trending Topics</a></p>
<p>16 0.50987065 <a title="95-lsi-16" href="./acl-2013-Patient_Experience_in_Online_Support_Forums%3A_Modeling_Interpersonal_Interactions_and_Medication_Use.html">278 acl-2013-Patient Experience in Online Support Forums: Modeling Interpersonal Interactions and Medication Use</a></p>
<p>17 0.5093708 <a title="95-lsi-17" href="./acl-2013-Evaluating_a_City_Exploration_Dialogue_System_with_Integrated_Question-Answering_and_Pedestrian_Navigation.html">141 acl-2013-Evaluating a City Exploration Dialogue System with Integrated Question-Answering and Pedestrian Navigation</a></p>
<p>18 0.50283146 <a title="95-lsi-18" href="./acl-2013-Linking_Tweets_to_News%3A_A_Framework_to_Enrich_Short_Text_Data_in_Social_Media.html">233 acl-2013-Linking Tweets to News: A Framework to Enrich Short Text Data in Social Media</a></p>
<p>19 0.49088332 <a title="95-lsi-19" href="./acl-2013-Robust_Automated_Natural_Language_Processing_with_Multiword_Expressions_and_Collocations.html">302 acl-2013-Robust Automated Natural Language Processing with Multiword Expressions and Collocations</a></p>
<p>20 0.48940775 <a title="95-lsi-20" href="./acl-2013-Fluid_Construction_Grammar_for_Historical_and_Evolutionary_Linguistics.html">161 acl-2013-Fluid Construction Grammar for Historical and Evolutionary Linguistics</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.057), (6, 0.026), (11, 0.045), (15, 0.024), (24, 0.078), (25, 0.23), (26, 0.109), (28, 0.01), (35, 0.092), (42, 0.038), (48, 0.032), (70, 0.032), (88, 0.034), (90, 0.028), (95, 0.074)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.8208217 <a title="95-lda-1" href="./acl-2013-Crawling_microblogging_services_to_gather_language-classified_URLs._Workflow_and_case_study.html">95 acl-2013-Crawling microblogging services to gather language-classified URLs. Workflow and case study</a></p>
<p>Author: Adrien Barbaresi</p><p>Abstract: We present a way to extract links from messages published on microblogging platforms and we classify them according to the language and possible relevance of their target in order to build a text corpus. Three platforms are taken into consideration: FriendFeed, identi.ca and Reddit, as they account for a relative diversity of user profiles and more importantly user languages. In order to explore them, we introduce a traversal algorithm based on user pages. As we target lesser-known languages, we try to focus on non-English posts by filtering out English text. Using mature open-source software from the NLP research field, a spell checker (as- pell) and a language identification system (langid .py), our case study and our benchmarks give an insight into the linguistic structure of the considered services.</p><p>2 0.7913956 <a title="95-lda-2" href="./acl-2013-Explicit_and_Implicit_Syntactic_Features_for_Text_Classification.html">144 acl-2013-Explicit and Implicit Syntactic Features for Text Classification</a></p>
<p>Author: Matt Post ; Shane Bergsma</p><p>Abstract: Syntactic features are useful for many text classification tasks. Among these, tree kernels (Collins and Duffy, 2001) have been perhaps the most robust and effective syntactic tool, appealing for their empirical success, but also because they do not require an answer to the difficult question of which tree features to use for a given task. We compare tree kernels to different explicit sets of tree features on five diverse tasks, and find that explicit features often perform as well as tree kernels on accuracy and always in orders of magnitude less time, and with smaller models. Since explicit features are easy to generate and use (with publicly avail- able tools) , we suggest they should always be included as baseline comparisons in tree kernel method evaluations.</p><p>3 0.72323793 <a title="95-lda-3" href="./acl-2013-Why-Question_Answering_using_Intra-_and_Inter-Sentential_Causal_Relations.html">387 acl-2013-Why-Question Answering using Intra- and Inter-Sentential Causal Relations</a></p>
<p>Author: Jong-Hoon Oh ; Kentaro Torisawa ; Chikara Hashimoto ; Motoki Sano ; Stijn De Saeger ; Kiyonori Ohtake</p><p>Abstract: In this paper, we explore the utility of intra- and inter-sentential causal relations between terms or clauses as evidence for answering why-questions. To the best of our knowledge, this is the first work that uses both intra- and inter-sentential causal relations for why-QA. We also propose a method for assessing the appropriateness of causal relations as answers to a given question using the semantic orientation of excitation proposed by Hashimoto et al. (2012). By applying these ideas to Japanese why-QA, we improved precision by 4.4% against all the questions in our test set over the current state-of-theart system for Japanese why-QA. In addi- tion, unlike the state-of-the-art system, our system could achieve very high precision (83.2%) for 25% of all the questions in the test set by restricting its output to the confident answers only.</p><p>4 0.69719392 <a title="95-lda-4" href="./acl-2013-Can_Markov_Models_Over_Minimal_Translation_Units_Help_Phrase-Based_SMT%3F.html">77 acl-2013-Can Markov Models Over Minimal Translation Units Help Phrase-Based SMT?</a></p>
<p>Author: Nadir Durrani ; Alexander Fraser ; Helmut Schmid ; Hieu Hoang ; Philipp Koehn</p><p>Abstract: The phrase-based and N-gram-based SMT frameworks complement each other. While the former is better able to memorize, the latter provides a more principled model that captures dependencies across phrasal boundaries. Some work has been done to combine insights from these two frameworks. A recent successful attempt showed the advantage of using phrasebased search on top of an N-gram-based model. We probe this question in the reverse direction by investigating whether integrating N-gram-based translation and reordering models into a phrase-based decoder helps overcome the problematic phrasal independence assumption. A large scale evaluation over 8 language pairs shows that performance does significantly improve.</p><p>5 0.65440154 <a title="95-lda-5" href="./acl-2013-A_Bayesian_Model_for_Joint_Unsupervised_Induction_of_Sentiment%2C_Aspect_and_Discourse_Representations.html">2 acl-2013-A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations</a></p>
<p>Author: Angeliki Lazaridou ; Ivan Titov ; Caroline Sporleder</p><p>Abstract: We propose a joint model for unsupervised induction of sentiment, aspect and discourse information and show that by incorporating a notion of latent discourse relations in the model, we improve the prediction accuracy for aspect and sentiment polarity on the sub-sentential level. We deviate from the traditional view of discourse, as we induce types of discourse relations and associated discourse cues relevant to the considered opinion analysis task; consequently, the induced discourse relations play the role of opinion and aspect shifters. The quantitative analysis that we conducted indicated that the integration of a discourse model increased the prediction accuracy results with respect to the discourse-agnostic approach and the qualitative analysis suggests that the induced representations encode a meaningful discourse structure.</p><p>6 0.63982356 <a title="95-lda-6" href="./acl-2013-Sentiment_Relevance.html">318 acl-2013-Sentiment Relevance</a></p>
<p>7 0.63576853 <a title="95-lda-7" href="./acl-2013-Improving_Text_Simplification_Language_Modeling_Using_Unsimplified_Text_Data.html">194 acl-2013-Improving Text Simplification Language Modeling Using Unsimplified Text Data</a></p>
<p>8 0.63216454 <a title="95-lda-8" href="./acl-2013-Linking_Tweets_to_News%3A_A_Framework_to_Enrich_Short_Text_Data_in_Social_Media.html">233 acl-2013-Linking Tweets to News: A Framework to Enrich Short Text Data in Social Media</a></p>
<p>9 0.62946904 <a title="95-lda-9" href="./acl-2013-Mapping_Source_to_Target_Strings_without_Alignment_by_Analogical_Learning%3A_A_Case_Study_with_Transliteration.html">236 acl-2013-Mapping Source to Target Strings without Alignment by Analogical Learning: A Case Study with Transliteration</a></p>
<p>10 0.62920409 <a title="95-lda-10" href="./acl-2013-Exploiting_Topic_based_Twitter_Sentiment_for_Stock_Prediction.html">147 acl-2013-Exploiting Topic based Twitter Sentiment for Stock Prediction</a></p>
<p>11 0.62903309 <a title="95-lda-11" href="./acl-2013-Unsupervised_Consonant-Vowel_Prediction_over_Hundreds_of_Languages.html">369 acl-2013-Unsupervised Consonant-Vowel Prediction over Hundreds of Languages</a></p>
<p>12 0.62521279 <a title="95-lda-12" href="./acl-2013-Real-World_Semi-Supervised_Learning_of_POS-Taggers_for_Low-Resource_Languages.html">295 acl-2013-Real-World Semi-Supervised Learning of POS-Taggers for Low-Resource Languages</a></p>
<p>13 0.62488711 <a title="95-lda-13" href="./acl-2013-Identifying_Opinion_Subgroups_in_Arabic_Online_Discussions.html">187 acl-2013-Identifying Opinion Subgroups in Arabic Online Discussions</a></p>
<p>14 0.62418091 <a title="95-lda-14" href="./acl-2013-Detecting_Turnarounds_in_Sentiment_Analysis%3A_Thwarting.html">117 acl-2013-Detecting Turnarounds in Sentiment Analysis: Thwarting</a></p>
<p>15 0.62066233 <a title="95-lda-15" href="./acl-2013-Semantic_Frames_to_Predict_Stock_Price_Movement.html">310 acl-2013-Semantic Frames to Predict Stock Price Movement</a></p>
<p>16 0.61992496 <a title="95-lda-16" href="./acl-2013-Co-Regression_for_Cross-Language_Review_Rating_Prediction.html">81 acl-2013-Co-Regression for Cross-Language Review Rating Prediction</a></p>
<p>17 0.61952865 <a title="95-lda-17" href="./acl-2013-Using_Conceptual_Class_Attributes_to_Characterize_Social_Media_Users.html">373 acl-2013-Using Conceptual Class Attributes to Characterize Social Media Users</a></p>
<p>18 0.61833549 <a title="95-lda-18" href="./acl-2013-Dual_Training_and_Dual_Prediction_for_Polarity_Classification.html">131 acl-2013-Dual Training and Dual Prediction for Polarity Classification</a></p>
<p>19 0.61691028 <a title="95-lda-19" href="./acl-2013-Text_Classification_based_on_the_Latent_Topics_of_Important_Sentences_extracted_by_the_PageRank_Algorithm.html">341 acl-2013-Text Classification based on the Latent Topics of Important Sentences extracted by the PageRank Algorithm</a></p>
<p>20 0.61637187 <a title="95-lda-20" href="./acl-2013-SORT%3A_An_Interactive_Source-Rewriting_Tool_for_Improved_Translation.html">305 acl-2013-SORT: An Interactive Source-Rewriting Tool for Improved Translation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
