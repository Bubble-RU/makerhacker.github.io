<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>344 acl-2013-The Effects of Lexical Resource Quality on Preference Violation Detection</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-344" href="#">acl2013-344</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>344 acl-2013-The Effects of Lexical Resource Quality on Preference Violation Detection</h1>
<br/><p>Source: <a title="acl-2013-344-pdf" href="http://aclweb.org/anthology//P/P13/P13-2134.pdf">pdf</a></p><p>Author: Jesse Dunietz ; Lori Levin ; Jaime Carbonell</p><p>Abstract: Lexical resources such as WordNet and VerbNet are widely used in a multitude of NLP tasks, as are annotated corpora such as treebanks. Often, the resources are used as-is, without question or examination. This practice risks missing significant performance gains and even entire techniques. This paper addresses the importance of resource quality through the lens of a challenging NLP task: detecting selectional preference violations. We present DAVID, a simple, lexical resource-based preference violation detector. With asis lexical resources, DAVID achieves an F1-measure of just 28.27%. When the resource entries and parser outputs for a small sample are corrected, however, the F1-measure on that sample jumps from 40% to 61.54%, and performance on other examples rises, suggesting that the algorithm becomes practical given refined resources. More broadly, this paper shows that resource quality matters tremendously, sometimes even more than algorithmic improvements.</p><p>Reference: <a title="acl-2013-344-reference" href="../acl2013_reference/acl-2013-The_Effects_of_Lexical_Resource_Quality_on_Preference_Violation_Detection_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu Abstract Lexical resources such as WordNet and VerbNet are widely used in a multitude of NLP tasks, as are annotated corpora such as treebanks. [sent-3, score-0.056]
</p><p>2 This practice risks missing significant performance gains and even entire techniques. [sent-5, score-0.074]
</p><p>3 This paper addresses the importance of resource quality through the lens of a challenging NLP task: detecting selectional preference violations. [sent-6, score-0.362]
</p><p>4 We present DAVID, a simple, lexical resource-based  preference violation detector. [sent-7, score-0.243]
</p><p>5 When the resource entries and parser outputs for a small sample are corrected, however, the F1-measure on that sample jumps from 40% to 61. [sent-10, score-0.178]
</p><p>6 More broadly, this paper shows that resource quality matters tremendously, sometimes even more than algorithmic improvements. [sent-12, score-0.149]
</p><p>7 1 Introduction A variety of NLP tasks have been addressed using selectional preferences or restrictions, including word sense disambiguation (see Navigli (2009)), semantic parsing (e. [sent-13, score-0.25]
</p><p>8 , Shi and Mihalcea (2005)), and metaphor processing (see Shutova (2010)). [sent-15, score-0.102]
</p><p>9 These semantic problems are quite challenging; metaphor analysis, for instance, has long been recognized as requiring considerable seman-  tic knowledge (Wilks, 1978; Carbonell, 1980). [sent-16, score-0.102]
</p><p>10 edu  ,  presents an opportunity to revisit such challenges from the perspective of selectional preference violations. [sent-19, score-0.256]
</p><p>11 In this paper, we present DAVID (Detector of Arguments of Verbs with Incompatible Denotations), a resource-based system for detecting preference violations. [sent-22, score-0.1]
</p><p>12 Manning (201 1) showed that this may not hold for POS tagging that further improvements may require resource cleanup. [sent-27, score-0.106]
</p><p>13 In the same spirit, we argue that for some semantic tasks, exemplified by preference violation detection, resource quality may be at least as essential as algorithmic enhancements. [sent-28, score-0.392]
</p><p>14 –  2  The Preference Violation Detection Task  DAVID builds on the insight of Wilks (1978) that the strongest indicator of metaphoricity is the violation of selectional preferences. [sent-29, score-0.299]
</p><p>15 If laws is  the object of pruned, the verb is likely metaphorical. [sent-31, score-0.18]
</p><p>16 Flagging such semantic mismatches between verbs and arguments is the task of preference violation detection. [sent-32, score-0.375]
</p><p>17 c A2s0s1o3ci Aatsiosonc fioartio Cno fmorpu Ctoamtiopnuatalt Lioin gauli Lsitnicgsu,i psatgices 765–7 0, We base our definition of preferences on the Pragglejaz guidelines (Pragglejaz Group, 2007) for identifying the most basic sense of a word as the most concrete, embodied, or precise one. [sent-35, score-0.094]
</p><p>18 Similarly, we define selectional preferences as the semantic constraints imposed by a verb’s most basic sense. [sent-36, score-0.222]
</p><p>19 Dictionaries may list figurative senses of prune, but we take the basic sense to be cutting plant growth. [sent-37, score-0.085]
</p><p>20 Several types of verbs were excluded from the task because they have very lax preferences. [sent-38, score-0.061]
</p><p>21 For the sake of simplifying implementation, phrasal verbs were also ignored. [sent-42, score-0.061]
</p><p>22 , 2011), a semantic role labeling (SRL) system; VerbNet, a computational verb lexicon; SemLink (Loper et al. [sent-44, score-0.136]
</p><p>23 , 2007), which includes mappings between PropBank (Palmer et al. [sent-45, score-0.253]
</p><p>24 As one metaphor detection component of METAL’s several, DAVID is designed to favor precision over recall. [sent-47, score-0.129]
</p><p>25 Run SENNA to identify the semantic arguments of each verb in the sentence using the PropBank argument annotation scheme (Arg0, Arg1, etc. [sent-53, score-0.197]
</p><p>26 For each verb V , find all VerbNet entries for V . [sent-57, score-0.162]
</p><p>27 Using SemLink, map each PropBank argument name to the corresponding VerbNet thematic roles in these entries (Agent, Patient, etc. [sent-58, score-0.17]
</p><p>28 Retrieve from VerbNet the selectional restrictions of each thematic role. [sent-65, score-0.336]
</p><p>29 If the head of any argument cannot be interpreted to meet V ’s preferences, flag V as a violation. [sent-69, score-0.064]
</p><p>30 “The politician pruned laws regulating plastic bags, and created new fees for inspecting dairy farms. [sent-70, score-0.4]
</p><p>31 ” Verb Arg0 Arg1 pruned regulating created inspecting  The politician laws The politician --  laws . [sent-71, score-0.404]
</p><p>32 bags plastic bags new fees dairy farms  Table 1: SENNA’s SRL output for the example sentence above. [sent-74, score-0.2]
</p><p>33 Restriction  WordNet Synsets  animate  animate being . [sent-76, score-0.15]
</p><p>34 0 1  concrete  organization  Table 2: DAVID’s mappings between some common VerbNet restriction types and WordNet synsets. [sent-92, score-0.357]
</p><p>35 Each VerbNet restriction is interpreted as mandating or forbidding a set of WordNet hypernyms, defined by a custom mapping (see Table 2). [sent-93, score-0.091]
</p><p>36 For example, VerbNet requires both the Patient of a verb in carve-2 1. [sent-94, score-0.09]
</p><p>37 2 -2 and the Theme of a verb in wipe manner- 10 . [sent-95, score-0.09]
</p><p>38 By empirical inspection, concrete nouns are hyponyms of the WordNet synsets  phys i ob j ect . [sent-98, score-0.152]
</p><p>39 Each verb was marked for whether its arguments violated the selectional preferences of the most basic, literal meaning of the verb. [sent-108, score-0.383]
</p><p>40 The annotators resolved conflicts by dis766  Error source  Frequency  Bad/missing VN entries Bad/missing VN restrictions Bad/missing SL mappings Parsing/head-finding errors SRL errors  4. [sent-109, score-0.601]
</p><p>41 6%)  VN restriction system too weak Confounding WordNet senses Endemic errors: Resource errors: Tool errors: Total:  4 (12. [sent-117, score-0.12]
</p><p>42 For errors that were due to a combination of sources, 1/2 point was awarded to each source. [sent-126, score-0.066]
</p><p>43 With such low precision and F1, it seemed a lexical resource-based preference violation detector was out. [sent-130, score-0.276]
</p><p>44 When we analyzed the errors in 90 randomly selected sentences, however, we found that most were not due to systemic problems with the ap-  proach; rather, they stemmed from SRL and parsing errors and missing or incorrect resource entries (see Table 3). [sent-131, score-0.414]
</p><p>45 6  Refining The Data  To evaluate the effects of correcting DAVID’s inputs, we manually corrected the tool outputs and resource entries that affected the aforementioned 90 sentences. [sent-133, score-0.46]
</p><p>46 SRL output was corrected for every sentence, while SemLink and VerbNet entries were corrected only for each verb that produced an error. [sent-134, score-0.478]
</p><p>47 1 Corrections to Tool Output (Parser/SRL) Guided by the PropBank database and annotation guidelines, we corrected all errors in core role assignments from SENNA. [sent-136, score-0.27]
</p><p>48 These corrections included relabeling arguments, adding missed arguments, fixing argument spans, and deleting annotations for non-verbs. [sent-137, score-0.365]
</p><p>49 The only parser-related error we corrected was a mislabeled noun. [sent-138, score-0.158]
</p><p>50 2 Correcting Corrupted Data in VerbNet The VerbNet download is missing several subclasses that are referred to by SemLink or that have been updated on the VerbNet website. [sent-140, score-0.165]
</p><p>51 Some roles also have not been updated to the latest version, and some subclasses are listed with incorrect IDs. [sent-141, score-0.147]
</p><p>52 These problems, which caused SemLink mappings to fail, were corrected before reviewing errors from the corpus. [sent-142, score-0.477]
</p><p>53 Six subclasses needed to be fixed, all of which were easily detected by a simple script that did not depend on the 90-sentence subcorpus. [sent-143, score-0.091]
</p><p>54 We therefore expect that few further changes of this type would be needed for a more complete resource refinement effort. [sent-144, score-0.197]
</p><p>55 3 Corpus-Based Updates to SemLink Our modifications to SemLink’s mappings included adding missing verbs, adding missing roles to mappings, and correcting mappings to more appropriate classes or roles. [sent-146, score-0.869]
</p><p>56 We also added null mappings in cases where a PropBank argument had no corresponding role in VerbNet. [sent-147, score-0.397]
</p><p>57 This makes the  system’s strategy for ruling out mappings more reliable. [sent-148, score-0.253]
</p><p>58 No corrections were made purely based on the sample. [sent-149, score-0.142]
</p><p>59 Any time a verb’s mappings were edited, VerbNet was scoured for plausible mappings for every verb sense in PropBank, and any nonsensical mappings were deleted. [sent-150, score-0.922]
</p><p>60 For example, when the phrase go dormant caused an error, we inspected the mappings for go. [sent-151, score-0.253]
</p><p>61 Arguments of all but 2 of the 7 available mappings were edited, either to add missing arguments or to correct nonsensical ones. [sent-152, score-0.443]
</p><p>62 These changes actually had a net negative impact on test set performance because the bad mappings had masked parsing and selectional preference problems. [sent-153, score-0.599]
</p><p>63 Based on the 90-sentence subcorpus, we modified 20 of the existing verb entries in SemLink. [sent-154, score-0.162]
</p><p>64 These changes included correcting 8 role mappings, adding 13 missing role mappings to existing senses, deleting 2 incorrect senses, adding 11verb senses, correcting 2 senses, deleting 1 superfluous role mapping, and adding 46 null role mappings. [sent-155, score-1.048]
</p><p>65 (Note that although null mappings represented the  largest set of changes, they also had the least impact on system behavior. [sent-156, score-0.315]
</p><p>66 The modifications generally involved adding, correcting, or deleting selectional restrictions, often by introducing or rearranging subclasses. [sent-160, score-0.275]
</p><p>67 Other changes amounted to fixing clerical errors, such as incorrect role names or restrictions that had been ANDed instead of ORed. [sent-161, score-0.352]
</p><p>68 In some cases, the restrictions specified on a verb in a subclass did not apply to subcategorization frames inherited from a superclass, but in other cases the restrictions clearly applied to all frames. [sent-163, score-0.414]
</p><p>69 The conflict was resolved by duplicating subclassed verbs in the top-level class whenever different selectional restrictions were needed for the two sets of frames. [sent-164, score-0.361]
</p><p>70 Any non-obvious changes to selectional restrictions were verified by examining dozens of verb instances from SketchEngine’s (Kilgarriff et al. [sent-166, score-0.438]
</p><p>71 For example, the Agent of seek was restricted to +animate, but the corpus confirmed that organizations are commonly described non-metaphorically as seeking, so the restriction was updated to +animate | +organi z at i on. [sent-168, score-0.063]
</p><p>72 7  Results After Resource Refinement  After making corrections for each set of 10 sentences, we incrementally recomputed F1 and precision, both on the subcorpus corrected so far and on a test set of all 625 sentences that were never corrected. [sent-169, score-0.342]
</p><p>73 The most striking feature of these figures is how  much performance improves on corrected sentences: for the full 90 sentences, F1 rose from 30. [sent-172, score-0.158]
</p><p>74 Interestingly, resource corrections alone generally made a larger difference than tool corrections alone, suggesting that resources may be the dominant factor in resource-intensive tasks such as this one. [sent-177, score-0.552]
</p><p>75 Even more compellingly, the improvement from correcting both the tools and the resources was nearly double the sum of the improvements from each alone: tool and resource improvements interact synergistically. [sent-178, score-0.314]
</p><p>76 Due to a combination of SRL problems and the small number of sentences corrected, the scores on the test set improved little with resource correction; in fact, they even dipped slightly between the 30- and 60-sentence increments. [sent-180, score-0.106]
</p><p>77 Note also that all results on the test set are without corrected tool output; presumably, these sentences would also have improved synergistically with more accurate SRL. [sent-182, score-0.247]
</p><p>78 How long corrections would continue to improve performance is a question that we did not have the resources to answer, but our results suggest that there is plenty of room to go. [sent-183, score-0.225]
</p><p>79 Some errors, of course, are endemic to the approach and cannot be fixed either by improved resources or by better tools. [sent-184, score-0.107]
</p><p>80 Additionally, the selectional restrictions specified by VerbNet are fairly loose; a more refined set of categories might capture the range of verbs’ restrictions more accurately. [sent-186, score-0.444]
</p><p>81 8  Implications for Future Refinement Efforts  Although improving resources is infamously labor-intensive, we believe that similarly refining the remainder of VerbNet and SemLink would be  doable. [sent-187, score-0.083]
</p><p>82 In our study, it took about 25-35 personhours to examine about 150 verbs and to modify 20 VerbNet classes and 25 SemLink verb entries (excluding time for SENNA corrections, fixing corrupt VerbNet data, and analysis ofDAVID’s errors). [sent-188, score-0.307]
</p><p>83 Improving SemLink could be more complex, as its mappings are automatically generated from VerbNet annotations on top of the PropBank corpus. [sent-190, score-0.253]
</p><p>84 One possibility is to correct the generated mappings directly, as we did in our study, which we estimate would take about two person-months. [sent-191, score-0.253]
</p><p>85 768  With the addition of some metadata from the generation process, it would then be possible to follow the corrected mappings back to annotations from which they were generated and fix those annotations. [sent-192, score-0.445]
</p><p>86 One downside of this approach is that if the mappings were ever regenerated from the anno-  tated corpus, any mappings not encountered in the corpus would have to be added back afterwards. [sent-193, score-0.506]
</p><p>87 Null role mappings would be particularly thorny to implement. [sent-194, score-0.299]
</p><p>88 To add a null mapping, we must know that a role definitely does not belong, and is not just incidentally missing from an example. [sent-195, score-0.182]
</p><p>89 0 1, but Arg0 or Arg1 may be missing for other reasons (e. [sent-197, score-0.074]
</p><p>90 It may be best to simply omit null mappings, as is currently done. [sent-200, score-0.062]
</p><p>91 Alternatively, full parses from the Penn Treebank, on which PropBank is based, might allow distinguishing phenomena such as passives where arguments are predictably omitted. [sent-201, score-0.071]
</p><p>92 The maintainers of VerbNet and PropBank are aware of many of the issues we have raised, and we have been in contact with them about possible approaches to fixing them. [sent-202, score-0.084]
</p><p>93 They are particularly aware of the inconsistent semantics of selectional restrictions on VerbNet subclasses, and they hope to fix this issue within a larger attempt at retooling VerbNet’s selectional restrictions. [sent-203, score-0.516]
</p><p>94 We are also sharing our SemLink changes so that they can, if they choose, continue manual correction efforts or trace SemLink problems back to the annotated corpus. [sent-205, score-0.108]
</p><p>95 9  Conclusion  Our results argue for investing effort in developing and fixing resources, in addition to developing better NLP tools. [sent-206, score-0.126]
</p><p>96 Resource and tool improvements interact synergistically: better resources multiply the effect of algorithm enhancements. [sent-207, score-0.1]
</p><p>97 Gains from fixing resources may sometimes even exceed what the best possible algorithmic improvements can provide. [sent-208, score-0.183]
</p><p>98 We hope the NLP community will take up the challenge of investing in its resources to the extent that its tools demand. [sent-209, score-0.152]
</p><p>99 99%  Table 4: Performance on preference violation detection task. [sent-257, score-0.27]
</p><p>100 Columns 2 and 3 show how many sentences’ SRL/parsing and resource errors, respectively, had been fixed (“corr. [sent-259, score-0.106]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('verbnet', 0.551), ('semlink', 0.359), ('mappings', 0.253), ('propbank', 0.161), ('corrected', 0.158), ('selectional', 0.156), ('restrictions', 0.144), ('violation', 0.143), ('corrections', 0.142), ('senna', 0.113), ('resource', 0.106), ('metaphor', 0.102), ('preference', 0.1), ('subclasses', 0.091), ('verb', 0.09), ('laws', 0.09), ('fixing', 0.084), ('metal', 0.084), ('correcting', 0.08), ('srl', 0.079), ('vn', 0.079), ('pragglejaz', 0.077), ('animate', 0.075), ('missing', 0.074), ('deleting', 0.072), ('entries', 0.072), ('arguments', 0.071), ('preferences', 0.066), ('errors', 0.066), ('restriction', 0.063), ('null', 0.062), ('verbs', 0.061), ('wordnet', 0.061), ('patient', 0.057), ('senses', 0.057), ('resources', 0.056), ('politician', 0.052), ('dairy', 0.051), ('endemic', 0.051), ('matte', 0.051), ('phys', 0.051), ('regulating', 0.051), ('prune', 0.051), ('changes', 0.048), ('modifications', 0.047), ('role', 0.046), ('corrupted', 0.045), ('synergistically', 0.045), ('plastic', 0.045), ('subst', 0.045), ('nonsensical', 0.045), ('tool', 0.044), ('agent', 0.043), ('algorithmic', 0.043), ('refinement', 0.043), ('investing', 0.042), ('fees', 0.042), ('masked', 0.042), ('subcorpus', 0.042), ('concrete', 0.041), ('david', 0.04), ('pavel', 0.038), ('kilgarriff', 0.037), ('loper', 0.037), ('ance', 0.037), ('pruned', 0.036), ('subclass', 0.036), ('thematic', 0.036), ('argument', 0.036), ('suggesting', 0.035), ('violations', 0.035), ('iarpa', 0.035), ('fix', 0.034), ('pa', 0.034), ('inspecting', 0.033), ('wilks', 0.033), ('collobert', 0.033), ('detector', 0.033), ('correction', 0.033), ('carbonell', 0.032), ('ob', 0.032), ('jaime', 0.031), ('adding', 0.031), ('cal', 0.031), ('bags', 0.031), ('incorrect', 0.03), ('edited', 0.029), ('stroudsburg', 0.028), ('sense', 0.028), ('martins', 0.028), ('ect', 0.028), ('tools', 0.028), ('interpreted', 0.028), ('continue', 0.027), ('detection', 0.027), ('sl', 0.027), ('refining', 0.027), ('alone', 0.027), ('hope', 0.026), ('roles', 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999952 <a title="344-tfidf-1" href="./acl-2013-The_Effects_of_Lexical_Resource_Quality_on_Preference_Violation_Detection.html">344 acl-2013-The Effects of Lexical Resource Quality on Preference Violation Detection</a></p>
<p>Author: Jesse Dunietz ; Lori Levin ; Jaime Carbonell</p><p>Abstract: Lexical resources such as WordNet and VerbNet are widely used in a multitude of NLP tasks, as are annotated corpora such as treebanks. Often, the resources are used as-is, without question or examination. This practice risks missing significant performance gains and even entire techniques. This paper addresses the importance of resource quality through the lens of a challenging NLP task: detecting selectional preference violations. We present DAVID, a simple, lexical resource-based preference violation detector. With asis lexical resources, DAVID achieves an F1-measure of just 28.27%. When the resource entries and parser outputs for a small sample are corrected, however, the F1-measure on that sample jumps from 40% to 61.54%, and performance on other examples rises, suggesting that the algorithm becomes practical given refined resources. More broadly, this paper shows that resource quality matters tremendously, sometimes even more than algorithmic improvements.</p><p>2 0.13983652 <a title="344-tfidf-2" href="./acl-2013-Detecting_Metaphor_by_Contextual_Analogy.html">116 acl-2013-Detecting Metaphor by Contextual Analogy</a></p>
<p>Author: Eirini Florou</p><p>Abstract: As one of the most challenging issues in NLP, metaphor identification and its interpretation have seen many models and methods proposed. This paper presents a study on metaphor identification based on the semantic similarity between literal and non literal meanings of words that can appear at the same context.</p><p>3 0.10416804 <a title="344-tfidf-3" href="./acl-2013-Improved_Lexical_Acquisition_through_DPP-based_Verb_Clustering.html">192 acl-2013-Improved Lexical Acquisition through DPP-based Verb Clustering</a></p>
<p>Author: Roi Reichart ; Anna Korhonen</p><p>Abstract: Subcategorization frames (SCFs), selectional preferences (SPs) and verb classes capture related aspects of the predicateargument structure. We present the first unified framework for unsupervised learning of these three types of information. We show how to utilize Determinantal Point Processes (DPPs), elegant probabilistic models that are defined over the possible subsets of a given dataset and give higher probability mass to high quality and diverse subsets, for clustering. Our novel clustering algorithm constructs a joint SCF-DPP DPP kernel matrix and utilizes the efficient sampling algorithms of DPPs to cluster together verbs with similar SCFs and SPs. We evaluate the induced clusters in the context of the three tasks and show results that are superior to strong baselines for each 1.</p><p>4 0.091527425 <a title="344-tfidf-4" href="./acl-2013-SPred%3A_Large-scale_Harvesting_of_Semantic_Predicates.html">306 acl-2013-SPred: Large-scale Harvesting of Semantic Predicates</a></p>
<p>Author: Tiziano Flati ; Roberto Navigli</p><p>Abstract: We present SPred, a novel method for the creation of large repositories of semantic predicates. We start from existing collocations to form lexical predicates (e.g., break ∗) and learn the semantic classes that best f∗it) tahned ∗ argument. Taon idco this, we extract failtl thhee ∗ occurrences ion Wikipedia ewxthraiccht match the predicate and abstract its arguments to general semantic classes (e.g., break BODY PART, break AGREEMENT, etc.). Our experiments show that we are able to create a large collection of semantic predicates from the Oxford Advanced Learner’s Dictionary with high precision and recall, and perform well against the most similar approach.</p><p>5 0.09030401 <a title="344-tfidf-5" href="./acl-2013-A_Random_Walk_Approach_to_Selectional_Preferences_Based_on_Preference_Ranking_and_Propagation.html">17 acl-2013-A Random Walk Approach to Selectional Preferences Based on Preference Ranking and Propagation</a></p>
<p>Author: Zhenhua Tian ; Hengheng Xiang ; Ziqi Liu ; Qinghua Zheng</p><p>Abstract: This paper presents an unsupervised random walk approach to alleviate data sparsity for selectional preferences. Based on the measure of preferences between predicates and arguments, the model aggregates all the transitions from a given predicate to its nearby predicates, and propagates their argument preferences as the given predicate’s smoothed preferences. Experimental results show that this approach outperforms several state-of-the-art methods on the pseudo-disambiguation task, and it better correlates with human plausibility judgements.</p><p>6 0.086087406 <a title="344-tfidf-6" href="./acl-2013-Sentiment_Relevance.html">318 acl-2013-Sentiment Relevance</a></p>
<p>7 0.0841107 <a title="344-tfidf-7" href="./acl-2013-Understanding_Verbs_based_on_Overlapping_Verbs_Senses.html">366 acl-2013-Understanding Verbs based on Overlapping Verbs Senses</a></p>
<p>8 0.081983663 <a title="344-tfidf-8" href="./acl-2013-Cross-lingual_Transfer_of_Semantic_Role_Labeling_Models.html">98 acl-2013-Cross-lingual Transfer of Semantic Role Labeling Models</a></p>
<p>9 0.075835221 <a title="344-tfidf-9" href="./acl-2013-Multilingual_Affect_Polarity_and_Valence_Prediction_in_Metaphor-Rich_Texts.html">253 acl-2013-Multilingual Affect Polarity and Valence Prediction in Metaphor-Rich Texts</a></p>
<p>10 0.072245955 <a title="344-tfidf-10" href="./acl-2013-FrameNet_on_the_Way_to_Babel%3A_Creating_a_Bilingual_FrameNet_Using_Wiktionary_as_Interlingual_Connection.html">162 acl-2013-FrameNet on the Way to Babel: Creating a Bilingual FrameNet Using Wiktionary as Interlingual Connection</a></p>
<p>11 0.068591513 <a title="344-tfidf-11" href="./acl-2013-Semantic_Roles_for_String_to_Tree_Machine_Translation.html">314 acl-2013-Semantic Roles for String to Tree Machine Translation</a></p>
<p>12 0.06778796 <a title="344-tfidf-12" href="./acl-2013-A_Structured_Distributional_Semantic_Model_for_Event_Co-reference.html">22 acl-2013-A Structured Distributional Semantic Model for Event Co-reference</a></p>
<p>13 0.067784272 <a title="344-tfidf-13" href="./acl-2013-Align%2C_Disambiguate_and_Walk%3A_A_Unified_Approach_for_Measuring_Semantic_Similarity.html">43 acl-2013-Align, Disambiguate and Walk: A Unified Approach for Measuring Semantic Similarity</a></p>
<p>14 0.066711731 <a title="344-tfidf-14" href="./acl-2013-Linggle%3A_a_Web-scale_Linguistic_Search_Engine_for_Words_in_Context.html">231 acl-2013-Linggle: a Web-scale Linguistic Search Engine for Words in Context</a></p>
<p>15 0.063915662 <a title="344-tfidf-15" href="./acl-2013-ImpAr%3A_A_Deterministic_Algorithm_for_Implicit_Semantic_Role_Labelling.html">189 acl-2013-ImpAr: A Deterministic Algorithm for Implicit Semantic Role Labelling</a></p>
<p>16 0.060448091 <a title="344-tfidf-16" href="./acl-2013-An_Empirical_Examination_of_Challenges_in_Chinese_Parsing.html">44 acl-2013-An Empirical Examination of Challenges in Chinese Parsing</a></p>
<p>17 0.0588957 <a title="344-tfidf-17" href="./acl-2013-Automated_Collocation_Suggestion_for_Japanese_Second_Language_Learners.html">58 acl-2013-Automated Collocation Suggestion for Japanese Second Language Learners</a></p>
<p>18 0.058496784 <a title="344-tfidf-18" href="./acl-2013-Linking_and_Extending_an_Open_Multilingual_Wordnet.html">234 acl-2013-Linking and Extending an Open Multilingual Wordnet</a></p>
<p>19 0.053375419 <a title="344-tfidf-19" href="./acl-2013-Diathesis_alternation_approximation_for_verb_clustering.html">119 acl-2013-Diathesis alternation approximation for verb clustering</a></p>
<p>20 0.052498646 <a title="344-tfidf-20" href="./acl-2013-DKPro_WSD%3A_A_Generalized_UIMA-based_Framework_for_Word_Sense_Disambiguation.html">105 acl-2013-DKPro WSD: A Generalized UIMA-based Framework for Word Sense Disambiguation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.136), (1, 0.03), (2, -0.018), (3, -0.092), (4, -0.068), (5, -0.055), (6, -0.068), (7, 0.058), (8, 0.057), (9, 0.013), (10, -0.001), (11, 0.022), (12, -0.072), (13, -0.002), (14, 0.014), (15, -0.012), (16, 0.014), (17, 0.027), (18, 0.089), (19, -0.02), (20, 0.055), (21, 0.007), (22, -0.019), (23, -0.035), (24, 0.124), (25, -0.064), (26, -0.049), (27, -0.017), (28, 0.037), (29, 0.014), (30, -0.019), (31, -0.107), (32, -0.052), (33, 0.029), (34, -0.04), (35, 0.009), (36, 0.01), (37, -0.089), (38, 0.041), (39, 0.062), (40, -0.034), (41, -0.043), (42, 0.008), (43, 0.031), (44, 0.016), (45, -0.036), (46, 0.018), (47, 0.007), (48, 0.034), (49, -0.004)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93400812 <a title="344-lsi-1" href="./acl-2013-The_Effects_of_Lexical_Resource_Quality_on_Preference_Violation_Detection.html">344 acl-2013-The Effects of Lexical Resource Quality on Preference Violation Detection</a></p>
<p>Author: Jesse Dunietz ; Lori Levin ; Jaime Carbonell</p><p>Abstract: Lexical resources such as WordNet and VerbNet are widely used in a multitude of NLP tasks, as are annotated corpora such as treebanks. Often, the resources are used as-is, without question or examination. This practice risks missing significant performance gains and even entire techniques. This paper addresses the importance of resource quality through the lens of a challenging NLP task: detecting selectional preference violations. We present DAVID, a simple, lexical resource-based preference violation detector. With asis lexical resources, DAVID achieves an F1-measure of just 28.27%. When the resource entries and parser outputs for a small sample are corrected, however, the F1-measure on that sample jumps from 40% to 61.54%, and performance on other examples rises, suggesting that the algorithm becomes practical given refined resources. More broadly, this paper shows that resource quality matters tremendously, sometimes even more than algorithmic improvements.</p><p>2 0.72005773 <a title="344-lsi-2" href="./acl-2013-Understanding_Verbs_based_on_Overlapping_Verbs_Senses.html">366 acl-2013-Understanding Verbs based on Overlapping Verbs Senses</a></p>
<p>Author: Kavitha Rajan</p><p>Abstract: Natural language can be easily understood by everyone irrespective of their differences in age or region or qualification. The existence of a conceptual base that underlies all natural languages is an accepted claim as pointed out by Schank in his Conceptual Dependency (CD) theory. Inspired by the CD theory and theories in Indian grammatical tradition, we propose a new set of meaning primitives in this paper. We claim that this new set of primitives captures the meaning inherent in verbs and help in forming an inter-lingual and computable ontological classification of verbs. We have identified seven primitive overlapping verb senses which substantiate our claim. The percentage of coverage of these primitives is 100% for all verbs in Sanskrit and Hindi and 3750 verbs in English. 1</p><p>3 0.68413448 <a title="344-lsi-3" href="./acl-2013-Detecting_Metaphor_by_Contextual_Analogy.html">116 acl-2013-Detecting Metaphor by Contextual Analogy</a></p>
<p>Author: Eirini Florou</p><p>Abstract: As one of the most challenging issues in NLP, metaphor identification and its interpretation have seen many models and methods proposed. This paper presents a study on metaphor identification based on the semantic similarity between literal and non literal meanings of words that can appear at the same context.</p><p>4 0.66705257 <a title="344-lsi-4" href="./acl-2013-Diathesis_alternation_approximation_for_verb_clustering.html">119 acl-2013-Diathesis alternation approximation for verb clustering</a></p>
<p>Author: Lin Sun ; Diana McCarthy ; Anna Korhonen</p><p>Abstract: Although diathesis alternations have been used as features for manual verb classification, and there is recent work on incorporating such features in computational models of human language acquisition, work on large scale verb classification has yet to examine the potential for using diathesis alternations as input features to the clustering process. This paper proposes a method for approximating diathesis alternation behaviour in corpus data and shows, using a state-of-the-art verb clustering system, that features based on alternation approximation outperform those based on independent subcategorization frames. Our alternation-based approach is particularly adept at leveraging information from less frequent data.</p><p>5 0.65358746 <a title="344-lsi-5" href="./acl-2013-Improved_Lexical_Acquisition_through_DPP-based_Verb_Clustering.html">192 acl-2013-Improved Lexical Acquisition through DPP-based Verb Clustering</a></p>
<p>Author: Roi Reichart ; Anna Korhonen</p><p>Abstract: Subcategorization frames (SCFs), selectional preferences (SPs) and verb classes capture related aspects of the predicateargument structure. We present the first unified framework for unsupervised learning of these three types of information. We show how to utilize Determinantal Point Processes (DPPs), elegant probabilistic models that are defined over the possible subsets of a given dataset and give higher probability mass to high quality and diverse subsets, for clustering. Our novel clustering algorithm constructs a joint SCF-DPP DPP kernel matrix and utilizes the efficient sampling algorithms of DPPs to cluster together verbs with similar SCFs and SPs. We evaluate the induced clusters in the context of the three tasks and show results that are superior to strong baselines for each 1.</p><p>6 0.60692877 <a title="344-lsi-6" href="./acl-2013-Computational_considerations_of_comparisons_and_similes.html">88 acl-2013-Computational considerations of comparisons and similes</a></p>
<p>7 0.60419238 <a title="344-lsi-7" href="./acl-2013-Language_Acquisition_and_Probabilistic_Models%3A_keeping_it_simple.html">213 acl-2013-Language Acquisition and Probabilistic Models: keeping it simple</a></p>
<p>8 0.57602692 <a title="344-lsi-8" href="./acl-2013-Identifying_English_and_Hungarian_Light_Verb_Constructions%3A_A_Contrastive_Approach.html">186 acl-2013-Identifying English and Hungarian Light Verb Constructions: A Contrastive Approach</a></p>
<p>9 0.56840265 <a title="344-lsi-9" href="./acl-2013-Annotation_of_regular_polysemy_and_underspecification.html">53 acl-2013-Annotation of regular polysemy and underspecification</a></p>
<p>10 0.56826103 <a title="344-lsi-10" href="./acl-2013-A_Random_Walk_Approach_to_Selectional_Preferences_Based_on_Preference_Ranking_and_Propagation.html">17 acl-2013-A Random Walk Approach to Selectional Preferences Based on Preference Ranking and Propagation</a></p>
<p>11 0.56559777 <a title="344-lsi-11" href="./acl-2013-SPred%3A_Large-scale_Harvesting_of_Semantic_Predicates.html">306 acl-2013-SPred: Large-scale Harvesting of Semantic Predicates</a></p>
<p>12 0.55521655 <a title="344-lsi-12" href="./acl-2013-ImpAr%3A_A_Deterministic_Algorithm_for_Implicit_Semantic_Role_Labelling.html">189 acl-2013-ImpAr: A Deterministic Algorithm for Implicit Semantic Role Labelling</a></p>
<p>13 0.53652632 <a title="344-lsi-13" href="./acl-2013-FrameNet_on_the_Way_to_Babel%3A_Creating_a_Bilingual_FrameNet_Using_Wiktionary_as_Interlingual_Connection.html">162 acl-2013-FrameNet on the Way to Babel: Creating a Bilingual FrameNet Using Wiktionary as Interlingual Connection</a></p>
<p>14 0.5334298 <a title="344-lsi-14" href="./acl-2013-Multilingual_Affect_Polarity_and_Valence_Prediction_in_Metaphor-Rich_Texts.html">253 acl-2013-Multilingual Affect Polarity and Valence Prediction in Metaphor-Rich Texts</a></p>
<p>15 0.50031573 <a title="344-lsi-15" href="./acl-2013-Linking_and_Extending_an_Open_Multilingual_Wordnet.html">234 acl-2013-Linking and Extending an Open Multilingual Wordnet</a></p>
<p>16 0.48456118 <a title="344-lsi-16" href="./acl-2013-IndoNet%3A_A_Multilingual_Lexical_Knowledge_Network_for_Indian_Languages.html">198 acl-2013-IndoNet: A Multilingual Lexical Knowledge Network for Indian Languages</a></p>
<p>17 0.48031458 <a title="344-lsi-17" href="./acl-2013-Robust_Automated_Natural_Language_Processing_with_Multiword_Expressions_and_Collocations.html">302 acl-2013-Robust Automated Natural Language Processing with Multiword Expressions and Collocations</a></p>
<p>18 0.47637513 <a title="344-lsi-18" href="./acl-2013-Linggle%3A_a_Web-scale_Linguistic_Search_Engine_for_Words_in_Context.html">231 acl-2013-Linggle: a Web-scale Linguistic Search Engine for Words in Context</a></p>
<p>19 0.47028914 <a title="344-lsi-19" href="./acl-2013-Universal_Conceptual_Cognitive_Annotation_%28UCCA%29.html">367 acl-2013-Universal Conceptual Cognitive Annotation (UCCA)</a></p>
<p>20 0.45601541 <a title="344-lsi-20" href="./acl-2013-Neighbors_Help%3A_Bilingual_Unsupervised_WSD_Using_Context.html">258 acl-2013-Neighbors Help: Bilingual Unsupervised WSD Using Context</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.051), (6, 0.041), (11, 0.047), (14, 0.014), (15, 0.021), (24, 0.038), (26, 0.037), (30, 0.25), (35, 0.097), (42, 0.041), (48, 0.044), (67, 0.012), (70, 0.027), (71, 0.013), (88, 0.06), (90, 0.045), (95, 0.085)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.87874675 <a title="344-lda-1" href="./acl-2013-Annotation_of_regular_polysemy_and_underspecification.html">53 acl-2013-Annotation of regular polysemy and underspecification</a></p>
<p>Author: Hector Martinez Alonso ; Bolette Sandford Pedersen ; Nuria Bel</p><p>Abstract: We present the result of an annotation task on regular polysemy for a series of semantic classes or dot types in English, Danish and Spanish. This article describes the annotation process, the results in terms of inter-encoder agreement, and the sense distributions obtained with two methods: majority voting with a theory-compliant backoff strategy, and MACE, an unsupervised system to choose the most likely sense from all the annotations.</p><p>same-paper 2 0.8055284 <a title="344-lda-2" href="./acl-2013-The_Effects_of_Lexical_Resource_Quality_on_Preference_Violation_Detection.html">344 acl-2013-The Effects of Lexical Resource Quality on Preference Violation Detection</a></p>
<p>Author: Jesse Dunietz ; Lori Levin ; Jaime Carbonell</p><p>Abstract: Lexical resources such as WordNet and VerbNet are widely used in a multitude of NLP tasks, as are annotated corpora such as treebanks. Often, the resources are used as-is, without question or examination. This practice risks missing significant performance gains and even entire techniques. This paper addresses the importance of resource quality through the lens of a challenging NLP task: detecting selectional preference violations. We present DAVID, a simple, lexical resource-based preference violation detector. With asis lexical resources, DAVID achieves an F1-measure of just 28.27%. When the resource entries and parser outputs for a small sample are corrected, however, the F1-measure on that sample jumps from 40% to 61.54%, and performance on other examples rises, suggesting that the algorithm becomes practical given refined resources. More broadly, this paper shows that resource quality matters tremendously, sometimes even more than algorithmic improvements.</p><p>3 0.6986866 <a title="344-lda-3" href="./acl-2013-DKPro_WSD%3A_A_Generalized_UIMA-based_Framework_for_Word_Sense_Disambiguation.html">105 acl-2013-DKPro WSD: A Generalized UIMA-based Framework for Word Sense Disambiguation</a></p>
<p>Author: Tristan Miller ; Nicolai Erbs ; Hans-Peter Zorn ; Torsten Zesch ; Iryna Gurevych</p><p>Abstract: Implementations of word sense disambiguation (WSD) algorithms tend to be tied to a particular test corpus format and sense inventory. This makes it difficult to test their performance on new data sets, or to compare them against past algorithms implemented for different data sets. In this paper we present DKPro WSD, a freely licensed, general-purpose framework for WSD which is both modular and extensible. DKPro WSD abstracts the WSD process in such a way that test corpora, sense inventories, and algorithms can be freely swapped. Its UIMA-based architecture makes it easy to add support for new resources and algorithms. Related tasks such as word sense induction and entity linking are also supported.</p><p>4 0.67144507 <a title="344-lda-4" href="./acl-2013-Statistical_Machine_Translation_Improves_Question_Retrieval_in_Community_Question_Answering_via_Matrix_Factorization.html">329 acl-2013-Statistical Machine Translation Improves Question Retrieval in Community Question Answering via Matrix Factorization</a></p>
<p>Author: Guangyou Zhou ; Fang Liu ; Yang Liu ; Shizhu He ; Jun Zhao</p><p>Abstract: Community question answering (CQA) has become an increasingly popular research topic. In this paper, we focus on the problem of question retrieval. Question retrieval in CQA can automatically find the most relevant and recent questions that have been solved by other users. However, the word ambiguity and word mismatch problems bring about new challenges for question retrieval in CQA. State-of-the-art approaches address these issues by implicitly expanding the queried questions with additional words or phrases using monolingual translation models. While useful, the effectiveness of these models is highly dependent on the availability of quality parallel monolingual corpora (e.g., question-answer pairs) in the absence of which they are troubled by noise issue. In this work, we propose an alternative way to address the word ambiguity and word mismatch problems by taking advantage of potentially rich semantic information drawn from other languages. Our proposed method employs statistical machine translation to improve question retrieval and enriches the question representation with the translated words from other languages via matrix factorization. Experiments conducted on a real CQA data show that our proposed approach is promising.</p><p>5 0.58449167 <a title="344-lda-5" href="./acl-2013-Multigraph_Clustering_for_Unsupervised_Coreference_Resolution.html">252 acl-2013-Multigraph Clustering for Unsupervised Coreference Resolution</a></p>
<p>Author: Sebastian Martschat</p><p>Abstract: We present an unsupervised model for coreference resolution that casts the problem as a clustering task in a directed labeled weighted multigraph. The model outperforms most systems participating in the English track of the CoNLL’ 12 shared task.</p><p>6 0.57447815 <a title="344-lda-6" href="./acl-2013-Density_Maximization_in_Context-Sense_Metric_Space_for_All-words_WSD.html">111 acl-2013-Density Maximization in Context-Sense Metric Space for All-words WSD</a></p>
<p>7 0.57303184 <a title="344-lda-7" href="./acl-2013-Improving_pairwise_coreference_models_through_feature_space_hierarchy_learning.html">196 acl-2013-Improving pairwise coreference models through feature space hierarchy learning</a></p>
<p>8 0.572864 <a title="344-lda-8" href="./acl-2013-Graph-based_Local_Coherence_Modeling.html">172 acl-2013-Graph-based Local Coherence Modeling</a></p>
<p>9 0.57252866 <a title="344-lda-9" href="./acl-2013-Models_of_Translation_Competitions.html">250 acl-2013-Models of Translation Competitions</a></p>
<p>10 0.57232475 <a title="344-lda-10" href="./acl-2013-Word_Association_Profiles_and_their_Use_for_Automated_Scoring_of_Essays.html">389 acl-2013-Word Association Profiles and their Use for Automated Scoring of Essays</a></p>
<p>11 0.57183599 <a title="344-lda-11" href="./acl-2013-A_System_for_Summarizing_Scientific_Topics_Starting_from_Keywords.html">23 acl-2013-A System for Summarizing Scientific Topics Starting from Keywords</a></p>
<p>12 0.56748015 <a title="344-lda-12" href="./acl-2013-PARMA%3A_A_Predicate_Argument_Aligner.html">267 acl-2013-PARMA: A Predicate Argument Aligner</a></p>
<p>13 0.5673579 <a title="344-lda-13" href="./acl-2013-SenseSpotting%3A_Never_let_your_parallel_data_tie_you_to_an_old_domain.html">316 acl-2013-SenseSpotting: Never let your parallel data tie you to an old domain</a></p>
<p>14 0.56699383 <a title="344-lda-14" href="./acl-2013-Automatic_Term_Ambiguity_Detection.html">62 acl-2013-Automatic Term Ambiguity Detection</a></p>
<p>15 0.56659025 <a title="344-lda-15" href="./acl-2013-A_Sentence_Compression_Based_Framework_to_Query-Focused_Multi-Document_Summarization.html">18 acl-2013-A Sentence Compression Based Framework to Query-Focused Multi-Document Summarization</a></p>
<p>16 0.56658 <a title="344-lda-16" href="./acl-2013-Identifying_Bad_Semantic_Neighbors_for_Improving_Distributional_Thesauri.html">185 acl-2013-Identifying Bad Semantic Neighbors for Improving Distributional Thesauri</a></p>
<p>17 0.56558478 <a title="344-lda-17" href="./acl-2013-Align%2C_Disambiguate_and_Walk%3A_A_Unified_Approach_for_Measuring_Semantic_Similarity.html">43 acl-2013-Align, Disambiguate and Walk: A Unified Approach for Measuring Semantic Similarity</a></p>
<p>18 0.56540579 <a title="344-lda-18" href="./acl-2013-Collective_Annotation_of_Linguistic_Resources%3A_Basic_Principles_and_a_Formal_Model.html">83 acl-2013-Collective Annotation of Linguistic Resources: Basic Principles and a Formal Model</a></p>
<p>19 0.56488645 <a title="344-lda-19" href="./acl-2013-Text_Classification_based_on_the_Latent_Topics_of_Important_Sentences_extracted_by_the_PageRank_Algorithm.html">341 acl-2013-Text Classification based on the Latent Topics of Important Sentences extracted by the PageRank Algorithm</a></p>
<p>20 0.56477791 <a title="344-lda-20" href="./acl-2013-An_Infinite_Hierarchical_Bayesian_Model_of_Phrasal_Translation.html">46 acl-2013-An Infinite Hierarchical Bayesian Model of Phrasal Translation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
