<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>179 acl-2013-HYENA-live: Fine-Grained Online Entity Type Classification from Natural-language Text</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-179" href="#">acl2013-179</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>179 acl-2013-HYENA-live: Fine-Grained Online Entity Type Classification from Natural-language Text</h1>
<br/><p>Source: <a title="acl-2013-179-pdf" href="http://aclweb.org/anthology//P/P13/P13-4023.pdf">pdf</a></p><p>Author: Mohamed Amir Yosef ; Sandro Bauer ; Johannes Hoffart ; Marc Spaniol ; Gerhard Weikum</p><p>Abstract: Recent research has shown progress in achieving high-quality, very fine-grained type classification in hierarchical taxonomies. Within such a multi-level type hierarchy with several hundreds of types at different levels, many entities naturally belong to multiple types. In order to achieve high-precision in type classification, current approaches are either limited to certain domains or require time consuming multistage computations. As a consequence, existing systems are incapable of performing ad-hoc type classification on arbitrary input texts. In this demo, we present a novel Webbased tool that is able to perform domain independent entity type classification under real time conditions. Thanks to its efficient implementation and compacted feature representation, the system is able to process text inputs on-the-fly while still achieving equally high precision as leading state-ofthe-art implementations. Our system offers an online interface where natural-language text can be inserted, which returns semantic type labels for entity mentions. Further more, the user interface allows users to explore the assigned types by visualizing and navigating along the type-hierarchy.</p><p>Reference: <a title="acl-2013-179-reference" href="../acl2013_reference/acl-2013-HYENA-live%3A_Fine-Grained_Online_Entity_Type_Classification_from_Natural-language_Text_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 puik-  Abstract Recent research has shown progress in achieving high-quality, very fine-grained type classification in hierarchical taxonomies. [sent-7, score-0.339]
</p><p>2 Within such a multi-level type hierarchy with several hundreds of types at different levels, many entities naturally belong to multiple types. [sent-8, score-0.547]
</p><p>3 In order to achieve high-precision in type classification, current approaches are either limited to certain domains or require time consuming multistage computations. [sent-9, score-0.167]
</p><p>4 As a consequence, existing systems are incapable of performing ad-hoc type classification on arbitrary input texts. [sent-10, score-0.296]
</p><p>5 In this demo, we present a novel Webbased tool that is able to perform domain independent entity type classification under  real time conditions. [sent-11, score-0.517]
</p><p>6 Thanks to its efficient implementation and compacted feature representation, the system is able to process text inputs on-the-fly while still achieving equally high precision as leading state-ofthe-art implementations. [sent-12, score-0.15]
</p><p>7 Our system offers an online interface where natural-language text can be inserted, which returns semantic type labels for entity mentions. [sent-13, score-0.505]
</p><p>8 Further more, the user interface allows users to explore the assigned types by visualizing and navigating along the type-hierarchy. [sent-14, score-0.161]
</p><p>9 Each entity belongs to one or more semantic types associated with it. [sent-16, score-0.28]
</p><p>10 For instance, an entity such as Bob Dylan should be assigned the types S inger, Mus i cian, P oet, etc. [sent-17, score-0.28]
</p><p>11 , and also the corresponding supertype(s) (hypernyms) in a type hierarchy, in this case Person. [sent-18, score-0.167]
</p><p>12 Such fine-grained typing of  entities in texts can be a great asset for various NLP tasks including semantic role labeling, sense disambiguation and named entity disambiguation (NED). [sent-19, score-0.637]
</p><p>13 For instance, noun phrases such as “songwriter Dylan”, “Google founder Page”, or “rock legend Page” can be easily mapped to the entities Bob Dylan, Larry Page, and Jimmy Page if their respective types S inger, Bus ine s sPers on, and Guitari st are available (cf. [sent-20, score-0.2]
</p><p>14 Fundedwith  100,000$,  Google  was  founded by Brin  and Page  "  "PageplayedoEnMBthueEsri ntcfairneiasnptserg_eupneitoauprlein1952"  Figure 1: Fine-grained entity type classification Problem Statement Type classification is not only be based on hier-  archical sub-type relationships (e. [sent-22, score-0.646]
</p><p>15 sA Within a very fine-grained type hierarchy, many entities naturally belong to multiple types. [sent-25, score-0.308]
</p><p>16 Consequently, entities should not only be assigned the most (fine-grained) label associated to them, but with all labels relevant to them. [sent-27, score-0.141]
</p><p>17 So we face a hierarchical multi-label classification problem (Tsoumakas et al. [sent-28, score-0.172]
</p><p>18 Contribution This paper introduces HYENA-live, which allows an on-the-fly computation of semantic types for entity mentions, based on a multi-level type hierarchy. [sent-30, score-0.447]
</p><p>19 Our approach uses a suite of features for a given entity mention, such as neighboring words and bi133  Proce dingSsof oifa, th Beu 5l1gsarti Aan,An u aglu Mste 4e-ti9n2g 0 o1f3 t. [sent-31, score-0.264]
</p><p>20 In order to perform “live” entity type  classification based on ad-hoc text inputs, several performance optimizations have been undertaken to operate under real-time conditions. [sent-34, score-0.572]
</p><p>21 2  Entity Type Classification Systems  State-of-the-art tools for named entity recognition such as the Stanford NER Tagger (Finkel et al. [sent-35, score-0.298]
</p><p>22 , 2005) compute semantic tags only for a small set of coarse-grained types: Pers on, Locat i and on, Organi z at ion (plus tags for non-entity phrases of type time, money, percent, and date). [sent-36, score-0.247]
</p><p>23 However, we are not aware of any online tool that performs fine-grained typing of entity mentions. [sent-37, score-0.352]
</p><p>24 The most common workaround to perform entity classification is a two-stage process: in first applying an online tool for Named-Entity Disambiguation (NED), such as DBpedia Spotlight (Mendes et al. [sent-38, score-0.405]
</p><p>25 , 2011), in order to map the mentions onto canonical entities and subsequently query the knowledge base for their types. [sent-41, score-0.359]
</p><p>26 In fact, (Ling and Weld, 2012) followed this approach when comparing their entity classification system results against those obtained by  an adoption of the Illinois’ Named-Entity Linking system (NEL) (Ratinov et al. [sent-42, score-0.35]
</p><p>27 Specifically, entity typing via NED has three major drawbacks: 1. [sent-44, score-0.297]
</p><p>28 NED only works for those mentions that correspond to a canonical entity within a knowledge base. [sent-48, score-0.345]
</p><p>29 However, this fails for all out-ofknowledge-base entities like unregistered persons, start-up companies, etc. [sent-49, score-0.141]
</p><p>30 Yet, only very few knowledge bases have comprehensive class labeling of entities. [sent-52, score-0.136]
</p><p>31 (Fleischman and Hovy, 2002) is one ofthe earliest approaches to perform entity classification into subtypes of PERSON. [sent-57, score-0.423]
</p><p>32 While their approach is fundamentally suitable, their type system is very restricted. [sent-60, score-0.167]
</p><p>33 , 2010) considered 141 subtypes of WordNet class PERSON and developed a maximum entropy classifier exploiting the words surrounding the mentions together with their POS tags and other contextual features. [sent-63, score-0.335]
</p><p>34 Their type hierarchy is finegrained, but still limited to sub classes of PERSON. [sent-64, score-0.501]
</p><p>35 (Altaf ur Rahman and Ng, 2010) considered a two-level type hierarchy consisting of 29 top-level classes and a total of 92 sub-classes. [sent-66, score-0.545]
</p><p>36 They incorporated a hierarchical classifier using a rich feature set and made use of WordNet sense tagging. [sent-68, score-0.137]
</p><p>37 (Ling and Weld, 2012) developed FIGER, which classifies entity mentions onto a two-level taxonomy based on the Freebase knowledge base (Bollacker et al. [sent-70, score-0.56]
</p><p>38 This results in a two-level hierarchy with top-level topics and 112 types. [sent-72, score-0.18]
</p><p>39 They trained a CRF for the joint task of recognizing entity mentions and inferring type tags. [sent-73, score-0.512]
</p><p>40 Many classes are absent and plenty of instances come with only a single label (e. [sent-75, score-0.232]
</p><p>41 216 of the 562 entities were of type PERSON without subtypes). [sent-77, score-0.308]
</p><p>42 , 2012) is the most recent work in multi-label type classification. [sent-80, score-0.167]
</p><p>43 The HYENA system incorporates a large hierarchy of 505 classes 134  organized under 5 top level classes, with 100 descendant classes under each of them. [sent-81, score-0.567]
</p><p>44 The hierarchy reaches a depth of up to 9 levels in some parts. [sent-82, score-0.18]
</p><p>45 The system is based on an SVM classifier using a comprehensive set of features and provides results for all classes of a large data set. [sent-83, score-0.281]
</p><p>46 However, the main drawback of HYENA comes from its large hierarchy and the extensive set of features extracted from the fairly large training corpus it requires. [sent-85, score-0.223]
</p><p>47 As a result, on-the-fly type classification with HYENA is impossible in its current implementation. [sent-86, score-0.296]
</p><p>48 In Section 3 we explain in details HYENA’s type taxonomy and their feature portfolio. [sent-88, score-0.339]
</p><p>49 Later on, we explain the engineering undertaken in order to develop the on-the-fly type classification system HYENA-live (cf. [sent-89, score-0.351]
</p><p>50 1 Fine-grained Taxonomy The type system is an automatically gathered finegrained taxonomy of 505 classes. [sent-92, score-0.332]
</p><p>51 The classes are organized under 5 top level classes, with 100 descendant classes under each. [sent-93, score-0.387]
</p><p>52 , 2013) is selected to derive the taxonomy from because of its highly precise classification of entities into WordNet classes, which is a result of the accurate mapping YAGO has from Wikipedia Categories to WordNet synsets. [sent-95, score-0.391]
</p><p>53 We start with five top classes namely PERSON, LOCAT I ON, ORGANI ZAT I ON, EVENT and ART IFACT. [sent-96, score-0.154]
</p><p>54 Under each top class, the most 100 prominent descendant classes are picked. [sent-97, score-0.233]
</p><p>55 Prominence is estimated by the number of YAGO entities  tagged with this class. [sent-98, score-0.141]
</p><p>56 This results in a very-fine grained taxonomy of 505 types, represented as a directed acyclic graph with 9 levels in its deepest parts. [sent-99, score-0.211]
</p><p>57 While the classes are picked from the YAGO type system, the approach is generic and can be applied to derive type taxonomies from other knowledge bases such as Freebase or DBpedia (Auer et al. [sent-100, score-0.528]
</p><p>58 2 Feature Set For the sake of generality and applicability to arbitrary text, we opted for features that can be automatically extracted from the input text without any human interaction, or manual annotation. [sent-103, score-0.147]
</p><p>59 Mention String We derive four features from the entity mention string. [sent-105, score-0.525]
</p><p>60 The mention string itself, a noun phrase consisting of one or more consecutive words. [sent-106, score-0.261]
</p><p>61 The other three features are unigrams, bigrams, and trigrams that overlap with the mention string. [sent-107, score-0.346]
</p><p>62 Sentence Surrounding Mention We also exploit a bounded-size window around the mention to extract four features: all unigrams, bigrams, and trigrams. [sent-108, score-0.314]
</p><p>63 Two versions of those features are extracted, one to account for the occurrence of those tokens around the mention, and another to account for the position at which they occurred with respect to the mention (before or after). [sent-109, score-0.304]
</p><p>64 Our demo is using a conservative threshold for the size of the window which is three tokens on each side of the mention. [sent-111, score-0.126]
</p><p>65 This gives additional topical cues about the mention type (e. [sent-113, score-0.428]
</p><p>66 , if the paragraph is about a music concert, this is a cue for mapping people names to musician types). [sent-115, score-0.12]
</p><p>67 First, we use part-of-speech tags of the tokens in a size-bounded window around the mention in distance and absolute distance versions. [sent-119, score-0.354]
</p><p>68 Finally, we use the closest verb-preposition pair preceding the mention as another feature. [sent-121, score-0.261]
</p><p>69 1%) Table 1: Properties of the labeled data used for training HYENA-live  curring in the names of the entities of that type. [sent-130, score-0.141]
</p><p>70 We construct, for each type, a binary feature that indicates if the mention contains a word occurring in this type’s gazetteer. [sent-132, score-0.312]
</p><p>71 Note that this is a fully automated feature construction, and it does by no means determine the mention type(s) already, as most words occur in the gazetteers of many different types. [sent-133, score-0.312]
</p><p>72 1 Overview As described in Section 3, HYENA classifies mentions of named entities onto a hierarchy of 505 types using large set of features. [sent-136, score-0.623]
</p><p>73 By exploiting Wikipedia anchor links, mentions of named entities are automatically disambiguated to their correct entities. [sent-138, score-0.342]
</p><p>74 Each Wikipedia named entity has a corresponding YAGO  entity labeled with an accurate set of types, and hence we effortlessly obtain a huge training data set (cf. [sent-139, score-0.519]
</p><p>75 LIBLINEAR model files are normalized textual files: a header (data about the model and the total number of features), followed by listing the weights assigned to each feature (line number indicates the feature ID). [sent-158, score-0.266]
</p><p>76 Each model file has been post-processed to produce 2 files: •  •  A compacted model file containing only features of non-zero weights. [sent-159, score-0.238]
</p><p>77 Due to the observed sparsity in the model files, particularly at deeper levels, there is a significant decrease in disk space consumption for the compacted model files and hence in the memory requirements. [sent-163, score-0.239]
</p><p>78 In par-  ticular, modified versions of feature vectors need to be generated for each classifier; this is because 136  Figure 2: Modified system architecture designed for handling sparse models  a lot of features have been omitted from specific classifiers (those with zero weights). [sent-166, score-0.137]
</p><p>79 Figure 5 shows the user interface of HYENA-live in a Web browser: 1) On top, there is a panel where a user can input any text, e. [sent-171, score-0.142]
</p><p>80 We employ the Stanford NER Tagger to  identify noun phrases as candidates of entity mentions. [sent-174, score-0.221]
</p><p>81 Alternatively, users can flag entity mentions by double brackets (e. [sent-175, score-0.345]
</p><p>82 For the sake of simplicity, detected entity mentions by HYENA-live are highlighted in yellow. [sent-178, score-0.404]
</p><p>83 Each mention is clickable to study its type classification results. [sent-179, score-0.557]
</p><p>84 2) The output of type classification is shown inside a tabbed widget. [sent-180, score-0.296]
</p><p>85 Each tab corresponds to a detected mention by the system and tabs are sorted by the order of occurrence in the input text. [sent-181, score-0.347]
</p><p>86 To open a tab, the tab header or the corresponding mention in the input area needs to be clicked. [sent-182, score-0.429]
</p><p>87 3) The type classification of a mention is shown as a color-coded interactive tree. [sent-183, score-0.557]
</p><p>88 While the original type hierarchy is a directed acyclic graph, for the ease of navigation the classification output has been converted into a tree. [sent-184, score-0.522]
</p><p>89 There are three different types of nodes:  Green Nodes: referring to a class that has been accepted by the classifier. [sent-186, score-0.114]
</p><p>90 These nodes can be further expanded in order to check which sub-classes have been accepted or rejected by HYENA-live. [sent-187, score-0.136]
</p><p>91 • Red Nodes: corresponding to a class that was rejected by the classifier, and hence HYENA-live did not traverse deeper to test its sub-classes. [sent-188, score-0.131]
</p><p>92 • White Nodes: matching classes that have not been tested. [sent-189, score-0.154]
</p><p>93 ENT I TY) or their super class was rejected by the system. [sent-192, score-0.131]
</p><p>94 It is worth noting that HYENA-live automatically adjusts the layouting so that as much as possible of the hierarchy is shown to the user. [sent-193, score-0.18]
</p><p>95 Hence, we also provide  HYENA-live  as a JSON compliant entity classi-  fication Web-service. [sent-201, score-0.221]
</p><p>96 by a different classification technique or a different type taxonomy) with minimum modifications required on the user interface side. [sent-204, score-0.398]
</p><p>97 137  Figure 3: Interactively exploring the types of the “Battle of Waterloo” in the HYENA-live interface  References  Md. [sent-207, score-0.121]
</p><p>98 Inducing fine-grained semantic classes via hierarchical and collective classification. [sent-210, score-0.197]
</p><p>99 Assessing the challenge of fine-grained named entity recognition and classification. [sent-225, score-0.298]
</p><p>100 AIDA: An online tool for accurate disambiguation of named entities in text and tables. [sent-264, score-0.334]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('hyena', 0.265), ('mention', 0.261), ('entity', 0.221), ('hierarchy', 0.18), ('type', 0.167), ('ned', 0.166), ('classes', 0.154), ('hoffart', 0.152), ('entities', 0.141), ('yosef', 0.137), ('johannes', 0.131), ('yago', 0.131), ('classification', 0.129), ('mentions', 0.124), ('taxonomy', 0.121), ('dylan', 0.113), ('compacted', 0.099), ('gerhard', 0.098), ('dbpedia', 0.095), ('tab', 0.086), ('amir', 0.084), ('header', 0.082), ('files', 0.082), ('mohamed', 0.08), ('descendant', 0.079), ('spaniol', 0.079), ('instances', 0.078), ('person', 0.078), ('ling', 0.077), ('named', 0.077), ('rejected', 0.076), ('typing', 0.076), ('gazetteer', 0.076), ('ekbal', 0.075), ('inger', 0.075), ('sandro', 0.075), ('tsoumakas', 0.075), ('demo', 0.073), ('subtypes', 0.073), ('marc', 0.07), ('weld', 0.067), ('freebase', 0.067), ('unigrams', 0.067), ('mus', 0.066), ('ilaria', 0.066), ('fleischman', 0.066), ('musician', 0.066), ('organi', 0.066), ('spotlight', 0.066), ('interface', 0.062), ('altaf', 0.061), ('nel', 0.061), ('mendes', 0.061), ('locat', 0.061), ('disambiguation', 0.061), ('nodes', 0.06), ('sake', 0.059), ('types', 0.059), ('json', 0.058), ('aida', 0.058), ('disk', 0.058), ('class', 0.055), ('online', 0.055), ('undertaken', 0.055), ('bollacker', 0.055), ('paragraph', 0.054), ('window', 0.053), ('rahman', 0.052), ('consequence', 0.052), ('base', 0.052), ('page', 0.051), ('feature', 0.051), ('auer', 0.051), ('file', 0.048), ('wikipedia', 0.048), ('alice', 0.047), ('bob', 0.047), ('acyclic', 0.046), ('server', 0.045), ('opted', 0.045), ('wordnet', 0.044), ('grained', 0.044), ('finegrained', 0.044), ('ur', 0.044), ('hierarchical', 0.043), ('sparse', 0.043), ('features', 0.043), ('ratinov', 0.043), ('classifier', 0.043), ('bigrams', 0.042), ('onto', 0.042), ('liblinear', 0.042), ('trigrams', 0.042), ('finkel', 0.041), ('comprehensive', 0.041), ('user', 0.04), ('bases', 0.04), ('money', 0.04), ('suitable', 0.04), ('tags', 0.04)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="179-tfidf-1" href="./acl-2013-HYENA-live%3A_Fine-Grained_Online_Entity_Type_Classification_from_Natural-language_Text.html">179 acl-2013-HYENA-live: Fine-Grained Online Entity Type Classification from Natural-language Text</a></p>
<p>Author: Mohamed Amir Yosef ; Sandro Bauer ; Johannes Hoffart ; Marc Spaniol ; Gerhard Weikum</p><p>Abstract: Recent research has shown progress in achieving high-quality, very fine-grained type classification in hierarchical taxonomies. Within such a multi-level type hierarchy with several hundreds of types at different levels, many entities naturally belong to multiple types. In order to achieve high-precision in type classification, current approaches are either limited to certain domains or require time consuming multistage computations. As a consequence, existing systems are incapable of performing ad-hoc type classification on arbitrary input texts. In this demo, we present a novel Webbased tool that is able to perform domain independent entity type classification under real time conditions. Thanks to its efficient implementation and compacted feature representation, the system is able to process text inputs on-the-fly while still achieving equally high precision as leading state-ofthe-art implementations. Our system offers an online interface where natural-language text can be inserted, which returns semantic type labels for entity mentions. Further more, the user interface allows users to explore the assigned types by visualizing and navigating along the type-hierarchy.</p><p>2 0.3049742 <a title="179-tfidf-2" href="./acl-2013-Fine-grained_Semantic_Typing_of_Emerging_Entities.html">160 acl-2013-Fine-grained Semantic Typing of Emerging Entities</a></p>
<p>Author: Ndapandula Nakashole ; Tomasz Tylenda ; Gerhard Weikum</p><p>Abstract: Methods for information extraction (IE) and knowledge base (KB) construction have been intensively studied. However, a largely under-explored case is tapping into highly dynamic sources like news streams and social media, where new entities are continuously emerging. In this paper, we present a method for discovering and semantically typing newly emerging out-ofKB entities, thus improving the freshness and recall of ontology-based IE and improving the precision and semantic rigor of open IE. Our method is based on a probabilistic model that feeds weights into integer linear programs that leverage type signatures of relational phrases and type correlation or disjointness constraints. Our experimental evaluation, based on crowdsourced user studies, show our method performing significantly better than prior work.</p><p>3 0.24780695 <a title="179-tfidf-3" href="./acl-2013-Entity_Linking_for_Tweets.html">139 acl-2013-Entity Linking for Tweets</a></p>
<p>Author: Xiaohua Liu ; Yitong Li ; Haocheng Wu ; Ming Zhou ; Furu Wei ; Yi Lu</p><p>Abstract: We study the task of entity linking for tweets, which tries to associate each mention in a tweet with a knowledge base entry. Two main challenges of this task are the dearth of information in a single tweet and the rich entity mention variations. To address these challenges, we propose a collective inference method that simultaneously resolves a set of mentions. Particularly, our model integrates three kinds of similarities, i.e., mention-entry similarity, entry-entry similarity, and mention-mention similarity, to enrich the context for entity linking, and to address irregular mentions that are not covered by the entity-variation dictionary. We evaluate our method on a publicly available data set and demonstrate the effectiveness of our method.</p><p>4 0.23249333 <a title="179-tfidf-4" href="./acl-2013-Towards_Accurate_Distant_Supervision_for_Relational_Facts_Extraction.html">352 acl-2013-Towards Accurate Distant Supervision for Relational Facts Extraction</a></p>
<p>Author: Xingxing Zhang ; Jianwen Zhang ; Junyu Zeng ; Jun Yan ; Zheng Chen ; Zhifang Sui</p><p>Abstract: Distant supervision (DS) is an appealing learning method which learns from existing relational facts to extract more from a text corpus. However, the accuracy is still not satisfying. In this paper, we point out and analyze some critical factors in DS which have great impact on accuracy, including valid entity type detection, negative training examples construction and ensembles. We propose an approach to handle these factors. By experimenting on Wikipedia articles to extract the facts in Freebase (the top 92 relations), we show the impact of these three factors on the accuracy of DS and the remarkable improvement led by the proposed approach.</p><p>5 0.1590136 <a title="179-tfidf-5" href="./acl-2013-Improving_pairwise_coreference_models_through_feature_space_hierarchy_learning.html">196 acl-2013-Improving pairwise coreference models through feature space hierarchy learning</a></p>
<p>Author: Emmanuel Lassalle ; Pascal Denis</p><p>Abstract: This paper proposes a new method for significantly improving the performance of pairwise coreference models. Given a set of indicators, our method learns how to best separate types of mention pairs into equivalence classes for which we construct distinct classification models. In effect, our approach finds an optimal feature space (derived from a base feature set and indicator set) for discriminating coreferential mention pairs. Although our approach explores a very large space of possible feature spaces, it remains tractable by exploiting the structure of the hierarchies built from the indicators. Our exper- iments on the CoNLL-2012 Shared Task English datasets (gold mentions) indicate that our method is robust relative to different clustering strategies and evaluation metrics, showing large and consistent improvements over a single pairwise model using the same base features. Our best system obtains a competitive 67.2 of average F1 over MUC, and CEAF which, despite its simplicity, places it above the mean score of other systems on these datasets. B3,</p><p>6 0.13921921 <a title="179-tfidf-6" href="./acl-2013-Question_Classification_Transfer.html">292 acl-2013-Question Classification Transfer</a></p>
<p>7 0.13806038 <a title="179-tfidf-7" href="./acl-2013-SPred%3A_Large-scale_Harvesting_of_Semantic_Predicates.html">306 acl-2013-SPred: Large-scale Harvesting of Semantic Predicates</a></p>
<p>8 0.13758503 <a title="179-tfidf-8" href="./acl-2013-Learning_Entity_Representation_for_Entity_Disambiguation.html">219 acl-2013-Learning Entity Representation for Entity Disambiguation</a></p>
<p>9 0.13353555 <a title="179-tfidf-9" href="./acl-2013-Argument_Inference_from_Relevant_Event_Mentions_in_Chinese_Argument_Extraction.html">56 acl-2013-Argument Inference from Relevant Event Mentions in Chinese Argument Extraction</a></p>
<p>10 0.11425245 <a title="179-tfidf-10" href="./acl-2013-Generating_Synthetic_Comparable_Questions_for_News_Articles.html">169 acl-2013-Generating Synthetic Comparable Questions for News Articles</a></p>
<p>11 0.11224461 <a title="179-tfidf-11" href="./acl-2013-Named_Entity_Recognition_using_Cross-lingual_Resources%3A_Arabic_as_an_Example.html">256 acl-2013-Named Entity Recognition using Cross-lingual Resources: Arabic as an Example</a></p>
<p>12 0.09540575 <a title="179-tfidf-12" href="./acl-2013-Multigraph_Clustering_for_Unsupervised_Coreference_Resolution.html">252 acl-2013-Multigraph Clustering for Unsupervised Coreference Resolution</a></p>
<p>13 0.087732382 <a title="179-tfidf-13" href="./acl-2013-Enriching_Entity_Translation_Discovery_using_Selective_Temporality.html">138 acl-2013-Enriching Entity Translation Discovery using Selective Temporality</a></p>
<p>14 0.086693779 <a title="179-tfidf-14" href="./acl-2013-Filling_Knowledge_Base_Gaps_for_Distant_Supervision_of_Relation_Extraction.html">159 acl-2013-Filling Knowledge Base Gaps for Distant Supervision of Relation Extraction</a></p>
<p>15 0.083734542 <a title="179-tfidf-15" href="./acl-2013-PARMA%3A_A_Predicate_Argument_Aligner.html">267 acl-2013-PARMA: A Predicate Argument Aligner</a></p>
<p>16 0.08218091 <a title="179-tfidf-16" href="./acl-2013-Question_Answering_Using_Enhanced_Lexical_Semantic_Models.html">291 acl-2013-Question Answering Using Enhanced Lexical Semantic Models</a></p>
<p>17 0.08089406 <a title="179-tfidf-17" href="./acl-2013-Question_Analysis_for_Polish_Question_Answering.html">290 acl-2013-Question Analysis for Polish Question Answering</a></p>
<p>18 0.080650702 <a title="179-tfidf-18" href="./acl-2013-Bootstrapping_Entity_Translation_on_Weakly_Comparable_Corpora.html">71 acl-2013-Bootstrapping Entity Translation on Weakly Comparable Corpora</a></p>
<p>19 0.077866845 <a title="179-tfidf-19" href="./acl-2013-Automatic_Term_Ambiguity_Detection.html">62 acl-2013-Automatic Term Ambiguity Detection</a></p>
<p>20 0.074610598 <a title="179-tfidf-20" href="./acl-2013-Decentralized_Entity-Level_Modeling_for_Coreference_Resolution.html">106 acl-2013-Decentralized Entity-Level Modeling for Coreference Resolution</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.214), (1, 0.102), (2, -0.02), (3, -0.133), (4, 0.099), (5, 0.183), (6, -0.051), (7, 0.039), (8, 0.111), (9, 0.011), (10, -0.003), (11, -0.129), (12, -0.093), (13, -0.031), (14, -0.012), (15, 0.07), (16, -0.076), (17, 0.118), (18, -0.133), (19, 0.03), (20, -0.104), (21, 0.05), (22, -0.03), (23, 0.194), (24, 0.066), (25, -0.014), (26, 0.119), (27, -0.128), (28, -0.09), (29, 0.033), (30, 0.082), (31, -0.078), (32, 0.008), (33, 0.013), (34, -0.074), (35, 0.018), (36, -0.05), (37, -0.047), (38, -0.07), (39, -0.025), (40, 0.035), (41, -0.055), (42, -0.057), (43, 0.029), (44, -0.024), (45, 0.001), (46, -0.01), (47, -0.035), (48, 0.05), (49, 0.048)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97437179 <a title="179-lsi-1" href="./acl-2013-HYENA-live%3A_Fine-Grained_Online_Entity_Type_Classification_from_Natural-language_Text.html">179 acl-2013-HYENA-live: Fine-Grained Online Entity Type Classification from Natural-language Text</a></p>
<p>Author: Mohamed Amir Yosef ; Sandro Bauer ; Johannes Hoffart ; Marc Spaniol ; Gerhard Weikum</p><p>Abstract: Recent research has shown progress in achieving high-quality, very fine-grained type classification in hierarchical taxonomies. Within such a multi-level type hierarchy with several hundreds of types at different levels, many entities naturally belong to multiple types. In order to achieve high-precision in type classification, current approaches are either limited to certain domains or require time consuming multistage computations. As a consequence, existing systems are incapable of performing ad-hoc type classification on arbitrary input texts. In this demo, we present a novel Webbased tool that is able to perform domain independent entity type classification under real time conditions. Thanks to its efficient implementation and compacted feature representation, the system is able to process text inputs on-the-fly while still achieving equally high precision as leading state-ofthe-art implementations. Our system offers an online interface where natural-language text can be inserted, which returns semantic type labels for entity mentions. Further more, the user interface allows users to explore the assigned types by visualizing and navigating along the type-hierarchy.</p><p>2 0.87841022 <a title="179-lsi-2" href="./acl-2013-Towards_Accurate_Distant_Supervision_for_Relational_Facts_Extraction.html">352 acl-2013-Towards Accurate Distant Supervision for Relational Facts Extraction</a></p>
<p>Author: Xingxing Zhang ; Jianwen Zhang ; Junyu Zeng ; Jun Yan ; Zheng Chen ; Zhifang Sui</p><p>Abstract: Distant supervision (DS) is an appealing learning method which learns from existing relational facts to extract more from a text corpus. However, the accuracy is still not satisfying. In this paper, we point out and analyze some critical factors in DS which have great impact on accuracy, including valid entity type detection, negative training examples construction and ensembles. We propose an approach to handle these factors. By experimenting on Wikipedia articles to extract the facts in Freebase (the top 92 relations), we show the impact of these three factors on the accuracy of DS and the remarkable improvement led by the proposed approach.</p><p>3 0.87838817 <a title="179-lsi-3" href="./acl-2013-Fine-grained_Semantic_Typing_of_Emerging_Entities.html">160 acl-2013-Fine-grained Semantic Typing of Emerging Entities</a></p>
<p>Author: Ndapandula Nakashole ; Tomasz Tylenda ; Gerhard Weikum</p><p>Abstract: Methods for information extraction (IE) and knowledge base (KB) construction have been intensively studied. However, a largely under-explored case is tapping into highly dynamic sources like news streams and social media, where new entities are continuously emerging. In this paper, we present a method for discovering and semantically typing newly emerging out-ofKB entities, thus improving the freshness and recall of ontology-based IE and improving the precision and semantic rigor of open IE. Our method is based on a probabilistic model that feeds weights into integer linear programs that leverage type signatures of relational phrases and type correlation or disjointness constraints. Our experimental evaluation, based on crowdsourced user studies, show our method performing significantly better than prior work.</p><p>4 0.79469955 <a title="179-lsi-4" href="./acl-2013-Entity_Linking_for_Tweets.html">139 acl-2013-Entity Linking for Tweets</a></p>
<p>Author: Xiaohua Liu ; Yitong Li ; Haocheng Wu ; Ming Zhou ; Furu Wei ; Yi Lu</p><p>Abstract: We study the task of entity linking for tweets, which tries to associate each mention in a tweet with a knowledge base entry. Two main challenges of this task are the dearth of information in a single tweet and the rich entity mention variations. To address these challenges, we propose a collective inference method that simultaneously resolves a set of mentions. Particularly, our model integrates three kinds of similarities, i.e., mention-entry similarity, entry-entry similarity, and mention-mention similarity, to enrich the context for entity linking, and to address irregular mentions that are not covered by the entity-variation dictionary. We evaluate our method on a publicly available data set and demonstrate the effectiveness of our method.</p><p>5 0.702039 <a title="179-lsi-5" href="./acl-2013-Filling_Knowledge_Base_Gaps_for_Distant_Supervision_of_Relation_Extraction.html">159 acl-2013-Filling Knowledge Base Gaps for Distant Supervision of Relation Extraction</a></p>
<p>Author: Wei Xu ; Raphael Hoffmann ; Le Zhao ; Ralph Grishman</p><p>Abstract: Distant supervision has attracted recent interest for training information extraction systems because it does not require any human annotation but rather employs existing knowledge bases to heuristically label a training corpus. However, previous work has failed to address the problem of false negative training examples mislabeled due to the incompleteness of knowledge bases. To tackle this problem, we propose a simple yet novel framework that combines a passage retrieval model using coarse features into a state-of-the-art relation extractor using multi-instance learning with fine features. We adapt the information retrieval technique of pseudo- relevance feedback to expand knowledge bases, assuming entity pairs in top-ranked passages are more likely to express a relation. Our proposed technique significantly improves the quality of distantly supervised relation extraction, boosting recall from 47.7% to 61.2% with a consistently high level of precision of around 93% in the experiments.</p><p>6 0.66949308 <a title="179-lsi-6" href="./acl-2013-Learning_Entity_Representation_for_Entity_Disambiguation.html">219 acl-2013-Learning Entity Representation for Entity Disambiguation</a></p>
<p>7 0.61793989 <a title="179-lsi-7" href="./acl-2013-Generating_Synthetic_Comparable_Questions_for_News_Articles.html">169 acl-2013-Generating Synthetic Comparable Questions for News Articles</a></p>
<p>8 0.59738934 <a title="179-lsi-8" href="./acl-2013-Graph-based_Local_Coherence_Modeling.html">172 acl-2013-Graph-based Local Coherence Modeling</a></p>
<p>9 0.59679395 <a title="179-lsi-9" href="./acl-2013-Text-Driven_Toponym_Resolution_using_Indirect_Supervision.html">340 acl-2013-Text-Driven Toponym Resolution using Indirect Supervision</a></p>
<p>10 0.57307941 <a title="179-lsi-10" href="./acl-2013-Named_Entity_Recognition_using_Cross-lingual_Resources%3A_Arabic_as_an_Example.html">256 acl-2013-Named Entity Recognition using Cross-lingual Resources: Arabic as an Example</a></p>
<p>11 0.57009667 <a title="179-lsi-11" href="./acl-2013-HEADY%3A_News_headline_abstraction_through_event_pattern_clustering.html">178 acl-2013-HEADY: News headline abstraction through event pattern clustering</a></p>
<p>12 0.56780255 <a title="179-lsi-12" href="./acl-2013-Enriching_Entity_Translation_Discovery_using_Selective_Temporality.html">138 acl-2013-Enriching Entity Translation Discovery using Selective Temporality</a></p>
<p>13 0.5462842 <a title="179-lsi-13" href="./acl-2013-Improving_pairwise_coreference_models_through_feature_space_hierarchy_learning.html">196 acl-2013-Improving pairwise coreference models through feature space hierarchy learning</a></p>
<p>14 0.54517019 <a title="179-lsi-14" href="./acl-2013-Understanding_Tables_in_Context_Using_Standard_NLP_Toolkits.html">365 acl-2013-Understanding Tables in Context Using Standard NLP Toolkits</a></p>
<p>15 0.51491964 <a title="179-lsi-15" href="./acl-2013-Transfer_Learning_Based_Cross-lingual_Knowledge_Extraction_for_Wikipedia.html">356 acl-2013-Transfer Learning Based Cross-lingual Knowledge Extraction for Wikipedia</a></p>
<p>16 0.50512761 <a title="179-lsi-16" href="./acl-2013-Bootstrapping_Entity_Translation_on_Weakly_Comparable_Corpora.html">71 acl-2013-Bootstrapping Entity Translation on Weakly Comparable Corpora</a></p>
<p>17 0.48178297 <a title="179-lsi-17" href="./acl-2013-Large-scale_Semantic_Parsing_via_Schema_Matching_and_Lexicon_Extension.html">215 acl-2013-Large-scale Semantic Parsing via Schema Matching and Lexicon Extension</a></p>
<p>18 0.47435832 <a title="179-lsi-18" href="./acl-2013-Mining_Equivalent_Relations_from_Linked_Data.html">242 acl-2013-Mining Equivalent Relations from Linked Data</a></p>
<p>19 0.46246856 <a title="179-lsi-19" href="./acl-2013-The_Impact_of_Topic_Bias_on_Quality_Flaw_Prediction_in_Wikipedia.html">346 acl-2013-The Impact of Topic Bias on Quality Flaw Prediction in Wikipedia</a></p>
<p>20 0.45534903 <a title="179-lsi-20" href="./acl-2013-PATHS%3A_A_System_for_Accessing_Cultural_Heritage_Collections.html">268 acl-2013-PATHS: A System for Accessing Cultural Heritage Collections</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.052), (6, 0.028), (11, 0.036), (15, 0.016), (21, 0.01), (24, 0.049), (26, 0.073), (35, 0.094), (42, 0.044), (48, 0.055), (70, 0.039), (71, 0.307), (88, 0.048), (90, 0.016), (95, 0.071)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.89958215 <a title="179-lda-1" href="./acl-2013-GuiTAR-based_Pronominal_Anaphora_Resolution_in_Bengali.html">177 acl-2013-GuiTAR-based Pronominal Anaphora Resolution in Bengali</a></p>
<p>Author: Apurbalal Senapati ; Utpal Garain</p><p>Abstract: This paper attempts to use an off-the-shelf anaphora resolution (AR) system for Bengali. The language specific preprocessing modules of GuiTAR (v3.0.3) are identified and suitably designed for Bengali. Anaphora resolution module is also modified or replaced in order to realize different configurations of GuiTAR. Performance of each configuration is evaluated and experiment shows that the off-the-shelf AR system can be effectively used for Indic languages. 1</p><p>same-paper 2 0.81581676 <a title="179-lda-2" href="./acl-2013-HYENA-live%3A_Fine-Grained_Online_Entity_Type_Classification_from_Natural-language_Text.html">179 acl-2013-HYENA-live: Fine-Grained Online Entity Type Classification from Natural-language Text</a></p>
<p>Author: Mohamed Amir Yosef ; Sandro Bauer ; Johannes Hoffart ; Marc Spaniol ; Gerhard Weikum</p><p>Abstract: Recent research has shown progress in achieving high-quality, very fine-grained type classification in hierarchical taxonomies. Within such a multi-level type hierarchy with several hundreds of types at different levels, many entities naturally belong to multiple types. In order to achieve high-precision in type classification, current approaches are either limited to certain domains or require time consuming multistage computations. As a consequence, existing systems are incapable of performing ad-hoc type classification on arbitrary input texts. In this demo, we present a novel Webbased tool that is able to perform domain independent entity type classification under real time conditions. Thanks to its efficient implementation and compacted feature representation, the system is able to process text inputs on-the-fly while still achieving equally high precision as leading state-ofthe-art implementations. Our system offers an online interface where natural-language text can be inserted, which returns semantic type labels for entity mentions. Further more, the user interface allows users to explore the assigned types by visualizing and navigating along the type-hierarchy.</p><p>3 0.71304059 <a title="179-lda-3" href="./acl-2013-Word_Association_Profiles_and_their_Use_for_Automated_Scoring_of_Essays.html">389 acl-2013-Word Association Profiles and their Use for Automated Scoring of Essays</a></p>
<p>Author: Beata Beigman Klebanov ; Michael Flor</p><p>Abstract: We describe a new representation of the content vocabulary of a text we call word association profile that captures the proportions of highly associated, mildly associated, unassociated, and dis-associated pairs of words that co-exist in the given text. We illustrate the shape of the distirbution and observe variation with genre and target audience. We present a study of the relationship between quality of writing and word association profiles. For a set of essays written by college graduates on a number of general topics, we show that the higher scoring essays tend to have higher percentages of both highly associated and dis-associated pairs, and lower percentages of mildly associated pairs of words. Finally, we use word association profiles to improve a system for automated scoring of essays.</p><p>4 0.68432778 <a title="179-lda-4" href="./acl-2013-An_Empirical_Examination_of_Challenges_in_Chinese_Parsing.html">44 acl-2013-An Empirical Examination of Challenges in Chinese Parsing</a></p>
<p>Author: Jonathan K. Kummerfeld ; Daniel Tse ; James R. Curran ; Dan Klein</p><p>Abstract: Aspects of Chinese syntax result in a distinctive mix of parsing challenges. However, the contribution of individual sources of error to overall difficulty is not well understood. We conduct a comprehensive automatic analysis of error types made by Chinese parsers, covering a broad range of error types for large sets of sentences, enabling the first empirical ranking of Chinese error types by their performance impact. We also investigate which error types are resolved by using gold part-of-speech tags, showing that improving Chinese tagging only addresses certain error types, leaving substantial outstanding challenges.</p><p>5 0.66374004 <a title="179-lda-5" href="./acl-2013-Iterative_Transformation_of_Annotation_Guidelines_for_Constituency_Parsing.html">204 acl-2013-Iterative Transformation of Annotation Guidelines for Constituency Parsing</a></p>
<p>Author: Xiang Li ; Wenbin Jiang ; Yajuan Lu ; Qun Liu</p><p>Abstract: This paper presents an effective algorithm of annotation adaptation for constituency treebanks, which transforms a treebank from one annotation guideline to another with an iterative optimization procedure, thus to build a much larger treebank to train an enhanced parser without increasing model complexity. Experiments show that the transformed Tsinghua Chinese Treebank as additional training data brings significant improvement over the baseline trained on Penn Chinese Treebank only.</p><p>6 0.53069234 <a title="179-lda-6" href="./acl-2013-Joint_Apposition_Extraction_with_Syntactic_and_Semantic_Constraints.html">205 acl-2013-Joint Apposition Extraction with Syntactic and Semantic Constraints</a></p>
<p>7 0.52867597 <a title="179-lda-7" href="./acl-2013-FudanNLP%3A_A_Toolkit_for_Chinese_Natural_Language_Processing.html">164 acl-2013-FudanNLP: A Toolkit for Chinese Natural Language Processing</a></p>
<p>8 0.50881565 <a title="179-lda-8" href="./acl-2013-A_Bayesian_Model_for_Joint_Unsupervised_Induction_of_Sentiment%2C_Aspect_and_Discourse_Representations.html">2 acl-2013-A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations</a></p>
<p>9 0.50475657 <a title="179-lda-9" href="./acl-2013-Sentiment_Relevance.html">318 acl-2013-Sentiment Relevance</a></p>
<p>10 0.49976382 <a title="179-lda-10" href="./acl-2013-Identifying_Opinion_Subgroups_in_Arabic_Online_Discussions.html">187 acl-2013-Identifying Opinion Subgroups in Arabic Online Discussions</a></p>
<p>11 0.49884716 <a title="179-lda-11" href="./acl-2013-Topic_Modeling_Based_Classification_of_Clinical_Reports.html">351 acl-2013-Topic Modeling Based Classification of Clinical Reports</a></p>
<p>12 0.49663356 <a title="179-lda-12" href="./acl-2013-Graph-based_Local_Coherence_Modeling.html">172 acl-2013-Graph-based Local Coherence Modeling</a></p>
<p>13 0.49661213 <a title="179-lda-13" href="./acl-2013-Explicit_and_Implicit_Syntactic_Features_for_Text_Classification.html">144 acl-2013-Explicit and Implicit Syntactic Features for Text Classification</a></p>
<p>14 0.49638569 <a title="179-lda-14" href="./acl-2013-Improving_Text_Simplification_Language_Modeling_Using_Unsimplified_Text_Data.html">194 acl-2013-Improving Text Simplification Language Modeling Using Unsimplified Text Data</a></p>
<p>15 0.49589723 <a title="179-lda-15" href="./acl-2013-Linking_Tweets_to_News%3A_A_Framework_to_Enrich_Short_Text_Data_in_Social_Media.html">233 acl-2013-Linking Tweets to News: A Framework to Enrich Short Text Data in Social Media</a></p>
<p>16 0.4957335 <a title="179-lda-16" href="./acl-2013-SenseSpotting%3A_Never_let_your_parallel_data_tie_you_to_an_old_domain.html">316 acl-2013-SenseSpotting: Never let your parallel data tie you to an old domain</a></p>
<p>17 0.49544328 <a title="179-lda-17" href="./acl-2013-Part-of-Speech_Induction_in_Dependency_Trees_for_Statistical_Machine_Translation.html">276 acl-2013-Part-of-Speech Induction in Dependency Trees for Statistical Machine Translation</a></p>
<p>18 0.49531519 <a title="179-lda-18" href="./acl-2013-Detecting_Turnarounds_in_Sentiment_Analysis%3A_Thwarting.html">117 acl-2013-Detecting Turnarounds in Sentiment Analysis: Thwarting</a></p>
<p>19 0.49463302 <a title="179-lda-19" href="./acl-2013-A_System_for_Summarizing_Scientific_Topics_Starting_from_Keywords.html">23 acl-2013-A System for Summarizing Scientific Topics Starting from Keywords</a></p>
<p>20 0.49412638 <a title="179-lda-20" href="./acl-2013-Cross-lingual_Transfer_of_Semantic_Role_Labeling_Models.html">98 acl-2013-Cross-lingual Transfer of Semantic Role Labeling Models</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
