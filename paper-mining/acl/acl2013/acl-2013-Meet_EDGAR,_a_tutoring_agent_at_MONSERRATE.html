<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>239 acl-2013-Meet EDGAR, a tutoring agent at MONSERRATE</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-239" href="#">acl2013-239</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>239 acl-2013-Meet EDGAR, a tutoring agent at MONSERRATE</h1>
<br/><p>Source: <a title="acl-2013-239-pdf" href="http://aclweb.org/anthology//P/P13/P13-4011.pdf">pdf</a></p><p>Author: Pedro Fialho ; Luisa Coheur ; Sergio Curto ; Pedro Claudio ; Angela Costa ; Alberto Abad ; Hugo Meinedo ; Isabel Trancoso</p><p>Abstract: In this paper we describe a platform for embodied conversational agents with tutoring goals, which takes as input written and spoken questions and outputs answers in both forms. The platform is developed within a game environment, and currently allows speech recognition and synthesis in Portuguese, English and Spanish. In this paper we focus on its understanding component that supports in-domain interactions, and also small talk. Most indomain interactions are answered using different similarity metrics, which compare the perceived utterances with questions/sentences in the agent’s knowledge base; small-talk capabilities are mainly due to AIML, a language largely used by the chatbots’ community. In this paper we also introduce EDGAR, the butler of MONSERRATE, which was developed in the aforementioned platform, and that answers tourists’ questions about MONSERRATE.</p><p>Reference: <a title="acl-2013-239-reference" href="../acl2013_reference/acl-2013-Meet_EDGAR%2C_a_tutoring_agent_at_MONSERRATE_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Meet EDGAR, a tutoring agent at MONSERRATE Pedro Fialho, Lu´ ısa Coheur, S ´ergio Curto, Pedro Cl´ audio Aˆngela Costa, Alberto Abad, Hugo Meinedo and Isabel Trancoso Spoken Language Systems Lab (L2F), INESC-ID Rua Alves Redol 9 1000-029 Lisbon, Portugal name . [sent-1, score-0.195]
</p><p>2 pt 2  Abstract In this paper we describe a platform for embodied conversational agents with tutoring goals, which takes as input written and spoken questions and outputs answers in both forms. [sent-4, score-0.726]
</p><p>3 The platform is developed within a game environment, and currently allows speech recognition and synthesis in Portuguese, English and Spanish. [sent-5, score-0.367]
</p><p>4 Most indomain interactions are answered using different similarity metrics, which compare the perceived utterances with questions/sentences in the agent’s knowledge base; small-talk capabilities are mainly due to AIML, a language largely used by  the chatbots’ community. [sent-7, score-0.169]
</p><p>5 In this paper we also introduce EDGAR, the butler of MONSERRATE, which was developed in the aforementioned platform, and that answers tourists’ questions about MONSERRATE. [sent-8, score-0.239]
</p><p>6 1 Introduction Several initiatives have been taking place in the last years, targeting the concept of Edutainment, that is, education through entertainment. [sent-9, score-0.031]
</p><p>7 , 2011), and Sergeant Blackwell, installed in the Cooper-Hewitt National Design Museum in New York, is used by the U. [sent-11, score-0.03]
</p><p>8 , 2009) and EDGAR are also examples of virtual characters for the Portuguese language with the same edutainment goal: DuARTE Digital answers questions about Cust o´dia de Bel e´m, a famous work of the Portuguese jewelry; EDGAR is a virtual butler that answers questions about MONSERRATE (Figure 1). [sent-17, score-0.753]
</p><p>9 However, as expected, people tend also to make small talk when interacting with these agents. [sent-20, score-0.117]
</p><p>10 In this paper, we describe the platform behind EDGAR, which we developed aiming at the fast insertion of in-domain knowledge, and to deal with small talk. [sent-23, score-0.244]
</p><p>11 This platform is currently in the process of being industrially applied by a company known for its expertise in building and deploying kiosks. [sent-24, score-0.238]
</p><p>12 We will provide the hardware and software required to demonstrate EDGAR, both on a computer and on a tablet. [sent-25, score-0.035]
</p><p>13 This paper is organized as follows: in Section 2 we present EDGAR’s development platform 61  ProceedinSgosfi oa,f tB huel 5g1arsita, An Anuugauls Mt 4e-e9ti n2g01 o3f. [sent-26, score-0.208]
</p><p>14 2  The Embodied Conversational Agent platform  2. [sent-30, score-0.208]
</p><p>15 1 Architecture overview The architecture of the platform, generally designed for the development of Embodied Conversational Agents (ECAs) (such as EDGAR), is shown in Figure 2. [sent-31, score-0.04]
</p><p>16 In this platform, several modules intercommunicate by means of well defined  protocols, thus leveraging the capabilities of independent modules focused on specific tasks, such as speech recognition or 3D rendering/animation. [sent-32, score-0.216]
</p><p>17 This independence allows us to use subsets of this platform modules in scenarios with different requirements (for instance, we can record characters uttering a text). [sent-33, score-0.35]
</p><p>18 Design and deployment of the front end of EDGAR is performed in a game engine, which has enabled the use of computer graphics technologies and high quality assets, as seen in the video game industry. [sent-34, score-0.239]
</p><p>19 2 Multimodal components The game environment, where all the interaction with EDGAR takes place, is developed in the Unity1 platform, being composed of one highly 1http : / /unity3d . [sent-36, score-0.123]
</p><p>20 com/ detailed character, made and animated by Rocketbox studios2, a virtual keyboard and a push-whiletalking button. [sent-37, score-0.335]
</p><p>21 Language models were interpolated with all the domain questions defined in the Natural Language Understanding (NLU) framework (see below), while ASR includes features such as speech/nonspeech (SNS) detection and automatic gain control (AGC). [sent-41, score-0.084]
</p><p>22 Speech captured in a public space raises several ASR robustness issues, such as loudness variability of spoken utterances, which is particularly bound to happen in a museological environment (such as MONSERRATE) where silence is usually incited. [sent-42, score-0.208]
</p><p>23 Thus, we have added a bounded amplication to the captured signal, despite the AGC mechanism, ensuring that too silent sounds are not discarded by the SNS mechanism. [sent-43, score-0.029]
</p><p>24 Upon a spoken input, AUDIMUS translates it into a sentence, with a confidence value. [sent-44, score-0.05]
</p><p>25 An empty recognition result, or one with low confidence, triggers a control tag (“ REPEAT ”) to the NLU module, which results in a request for  the user to repeat what was said. [sent-45, score-0.04]
</p><p>26 The answer returned by the NLU module is synthesized in a language dependent Text To Speech (TTS) system, with DIXI (Paulo et al. [sent-46, score-0.166]
</p><p>27 com/ 62  synthesized audio is played while the corresponding phonemes are mapped into visemes, represented as skeletal animations, being synchronized according to phoneme durations, available in all the employed TTS engines. [sent-51, score-0.216]
</p><p>28 Emotions are declared in the knowledge sources of the agent. [sent-52, score-0.078]
</p><p>29 Figure 3: The EDGAR character in a joyful state. [sent-54, score-0.056]
</p><p>30 3 Interacting with EDGAR In a typical interaction, the user enters a question with a virtual keyboard or says it to the microphone while pressing a button (Figure 4), in the language chosen in the interface (as previously said, Portuguese, English or Spanish). [sent-56, score-0.287]
</p><p>31 Figure 4: A question written in the EDGAR inter-  face. [sent-57, score-0.028]
</p><p>32 Then, the ASR will transcribe it and the NLU module will process it. [sent-58, score-0.102]
</p><p>33 Afterwards, the answer, chosen by the NLU module, is heard through the speakers, due to the TTS, and sequentially written in a talk bubble, according to the produced speech. [sent-59, score-0.118]
</p><p>34 The answer is accompanied with visemes, represented by movements of the character’s mouth/lips, and by facial emotions as marked in the answers of the NLU knowledge base. [sent-60, score-0.185]
</p><p>35 A demo of EDGAR, only for English interactions, can be tested in https : / / edgar . [sent-61, score-0.711]
</p><p>36 1 In-domain knowledge sources The in-domain knowledge sources of the agent are XML files, hand-crafted by domain experts. [sent-67, score-0.184]
</p><p>37 This XML files have multilingual pairs constituted by different paraphrases of the same question and possible answers. [sent-68, score-0.074]
</p><p>38 The main reason to follow this approach (and contrary to other works  where grammars are used), is to ease the process of creating/enriching the knowledge sources of the agent being developed, which is typically done by non experts in linguistics or computer science. [sent-69, score-0.137]
</p><p>39 , 2006), where the agents knowledge sources are easy to create and maintain. [sent-71, score-0.148]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('edgar', 0.711), ('nlu', 0.225), ('platform', 0.208), ('monserrate', 0.169), ('virtual', 0.148), ('meinedo', 0.127), ('animated', 0.112), ('portuguese', 0.107), ('asr', 0.107), ('agents', 0.101), ('embodied', 0.093), ('agent', 0.09), ('tts', 0.089), ('game', 0.087), ('interactions', 0.086), ('agc', 0.085), ('audimus', 0.085), ('edutainment', 0.085), ('visemes', 0.085), ('butler', 0.075), ('keyboard', 0.075), ('answers', 0.073), ('museums', 0.069), ('duarte', 0.069), ('module', 0.067), ('modules', 0.066), ('sns', 0.065), ('synthesized', 0.065), ('interacting', 0.062), ('tutoring', 0.059), ('conversational', 0.059), ('character', 0.056), ('talk', 0.055), ('questions', 0.055), ('environment', 0.055), ('pedro', 0.052), ('spoken', 0.05), ('ine', 0.048), ('capabilities', 0.048), ('emotions', 0.047), ('sources', 0.047), ('audio', 0.046), ('multimodal', 0.046), ('xml', 0.045), ('characters', 0.041), ('repeat', 0.04), ('architecture', 0.04), ('digital', 0.038), ('skeletal', 0.037), ('constituted', 0.037), ('tales', 0.037), ('bubble', 0.037), ('synchronized', 0.037), ('animations', 0.037), ('leuski', 0.037), ('silence', 0.037), ('alves', 0.037), ('assets', 0.037), ('ergio', 0.037), ('loudness', 0.037), ('recruiting', 0.037), ('sergeant', 0.037), ('files', 0.037), ('developed', 0.036), ('speech', 0.036), ('utterances', 0.035), ('hardware', 0.035), ('paulo', 0.035), ('graphics', 0.035), ('heard', 0.035), ('heinz', 0.035), ('tourists', 0.035), ('mendes', 0.035), ('uttering', 0.035), ('pressing', 0.035), ('jewelry', 0.035), ('transcribe', 0.035), ('answer', 0.034), ('robinson', 0.033), ('durations', 0.033), ('trancoso', 0.033), ('zen', 0.033), ('costa', 0.033), ('establishing', 0.031), ('declared', 0.031), ('phonemes', 0.031), ('initiatives', 0.031), ('andersen', 0.031), ('isabel', 0.031), ('protocols', 0.031), ('facial', 0.031), ('deployment', 0.03), ('museum', 0.03), ('deploying', 0.03), ('installed', 0.03), ('captured', 0.029), ('surname', 0.029), ('interpolated', 0.029), ('button', 0.029), ('written', 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="239-tfidf-1" href="./acl-2013-Meet_EDGAR%2C_a_tutoring_agent_at_MONSERRATE.html">239 acl-2013-Meet EDGAR, a tutoring agent at MONSERRATE</a></p>
<p>Author: Pedro Fialho ; Luisa Coheur ; Sergio Curto ; Pedro Claudio ; Angela Costa ; Alberto Abad ; Hugo Meinedo ; Isabel Trancoso</p><p>Abstract: In this paper we describe a platform for embodied conversational agents with tutoring goals, which takes as input written and spoken questions and outputs answers in both forms. The platform is developed within a game environment, and currently allows speech recognition and synthesis in Portuguese, English and Spanish. In this paper we focus on its understanding component that supports in-domain interactions, and also small talk. Most indomain interactions are answered using different similarity metrics, which compare the perceived utterances with questions/sentences in the agent’s knowledge base; small-talk capabilities are mainly due to AIML, a language largely used by the chatbots’ community. In this paper we also introduce EDGAR, the butler of MONSERRATE, which was developed in the aforementioned platform, and that answers tourists’ questions about MONSERRATE.</p><p>2 0.077382654 <a title="239-tfidf-2" href="./acl-2013-AnnoMarket%3A_An_Open_Cloud_Platform_for_NLP.html">51 acl-2013-AnnoMarket: An Open Cloud Platform for NLP</a></p>
<p>Author: Valentin Tablan ; Kalina Bontcheva ; Ian Roberts ; Hamish Cunningham ; Marin Dimitrov</p><p>Abstract: This paper presents AnnoMarket, an open cloud-based platform which enables researchers to deploy, share, and use language processing components and resources, following the data-as-a-service and software-as-a-service paradigms. The focus is on multilingual text analysis resources and services, based on an opensource infrastructure and compliant with relevant NLP standards. We demonstrate how the AnnoMarket platform can be used to develop NLP applications with little or no programming, to index the results for enhanced browsing and search, and to evaluate performance. Utilising AnnoMarket is straightforward, since cloud infrastructural issues are dealt with by the platform, completely transparently to the user: load balancing, efficient data upload and storage, deployment on the virtual machines, security, and fault tolerance.</p><p>3 0.061797388 <a title="239-tfidf-3" href="./acl-2013-Utterance-Level_Multimodal_Sentiment_Analysis.html">379 acl-2013-Utterance-Level Multimodal Sentiment Analysis</a></p>
<p>Author: Veronica Perez-Rosas ; Rada Mihalcea ; Louis-Philippe Morency</p><p>Abstract: During real-life interactions, people are naturally gesturing and modulating their voice to emphasize specific points or to express their emotions. With the recent growth of social websites such as YouTube, Facebook, and Amazon, video reviews are emerging as a new source of multimodal and natural opinions that has been left almost untapped by automatic opinion analysis techniques. This paper presents a method for multimodal sentiment classification, which can identify the sentiment expressed in utterance-level visual datastreams. Using a new multimodal dataset consisting of sentiment annotated utterances extracted from video reviews, we show that multimodal sentiment analysis can be effectively performed, and that the joint use of visual, acoustic, and linguistic modalities can lead to error rate reductions of up to 10.5% as compared to the best performing individual modality.</p><p>4 0.055795006 <a title="239-tfidf-4" href="./acl-2013-Extending_an_interoperable_platform_to_facilitate_the_creation_of_multilingual_and_multimodal_NLP_applications.html">150 acl-2013-Extending an interoperable platform to facilitate the creation of multilingual and multimodal NLP applications</a></p>
<p>Author: Georgios Kontonatsios ; Paul Thompson ; Riza Theresa Batista-Navarro ; Claudiu Mihaila ; Ioannis Korkontzelos ; Sophia Ananiadou</p><p>Abstract: U-Compare is a UIMA-based workflow construction platform for building natural language processing (NLP) applications from heterogeneous language resources (LRs), without the need for programming skills. U-Compare has been adopted within the context of the METANET Network of Excellence, and over 40 LRs that process 15 European languages have been added to the U-Compare component library. In line with METANET’s aims of increasing communication between citizens of different European countries, U-Compare has been extended to facilitate the development of a wider range of applications, including both mul- tilingual and multimodal workflows. The enhancements exploit the UIMA Subject of Analysis (Sofa) mechanism, that allows different facets of the input data to be represented. We demonstrate how our customised extensions to U-Compare allow the construction and testing of NLP applications that transform the input data in different ways, e.g., machine translation, automatic summarisation and text-to-speech.</p><p>5 0.05451737 <a title="239-tfidf-5" href="./acl-2013-Is_word-to-phone_mapping_better_than_phone-phone_mapping_for_handling_English_words%3F.html">203 acl-2013-Is word-to-phone mapping better than phone-phone mapping for handling English words?</a></p>
<p>Author: Naresh Kumar Elluru ; Anandaswarup Vadapalli ; Raghavendra Elluru ; Hema Murthy ; Kishore Prahallad</p><p>Abstract: In this paper, we relook at the problem of pronunciation of English words using native phone set. Specifically, we investigate methods of pronouncing English words using Telugu phoneset in the con- text of Telugu Text-to-Speech. We compare phone-phone substitution and wordphone mapping for pronunciation of English words using Telugu phones. We are not considering other than native language phoneset in all our experiments. This differentiates our approach from other works in polyglot speech synthesis.</p><p>6 0.050872732 <a title="239-tfidf-6" href="./acl-2013-PAL%3A_A_Chatterbot_System_for_Answering_Domain-specific_Questions.html">266 acl-2013-PAL: A Chatterbot System for Answering Domain-specific Questions</a></p>
<p>7 0.047159422 <a title="239-tfidf-7" href="./acl-2013-Implicatures_and_Nested_Beliefs_in_Approximate_Decentralized-POMDPs.html">190 acl-2013-Implicatures and Nested Beliefs in Approximate Decentralized-POMDPs</a></p>
<p>8 0.043136027 <a title="239-tfidf-8" href="./acl-2013-Deceptive_Answer_Prediction_with_User_Preference_Graph.html">107 acl-2013-Deceptive Answer Prediction with User Preference Graph</a></p>
<p>9 0.04073678 <a title="239-tfidf-9" href="./acl-2013-Generating_Recommendation_Dialogs_by_Extracting_Information_from_User_Reviews.html">168 acl-2013-Generating Recommendation Dialogs by Extracting Information from User Reviews</a></p>
<p>10 0.040130872 <a title="239-tfidf-10" href="./acl-2013-Generating_Synthetic_Comparable_Questions_for_News_Articles.html">169 acl-2013-Generating Synthetic Comparable Questions for News Articles</a></p>
<p>11 0.037017092 <a title="239-tfidf-11" href="./acl-2013-Paraphrase-Driven_Learning_for_Open_Question_Answering.html">272 acl-2013-Paraphrase-Driven Learning for Open Question Answering</a></p>
<p>12 0.03687026 <a title="239-tfidf-12" href="./acl-2013-Question_Answering_Using_Enhanced_Lexical_Semantic_Models.html">291 acl-2013-Question Answering Using Enhanced Lexical Semantic Models</a></p>
<p>13 0.036584996 <a title="239-tfidf-13" href="./acl-2013-Automatic_Term_Ambiguity_Detection.html">62 acl-2013-Automatic Term Ambiguity Detection</a></p>
<p>14 0.035402611 <a title="239-tfidf-14" href="./acl-2013-Identification_of_Speakers_in_Novels.html">184 acl-2013-Identification of Speakers in Novels</a></p>
<p>15 0.035080738 <a title="239-tfidf-15" href="./acl-2013-Learning_Latent_Personas_of_Film_Characters.html">220 acl-2013-Learning Latent Personas of Film Characters</a></p>
<p>16 0.03380983 <a title="239-tfidf-16" href="./acl-2013-Incremental_Topic-Based_Translation_Model_Adaptation_for_Conversational_Spoken_Language_Translation.html">197 acl-2013-Incremental Topic-Based Translation Model Adaptation for Conversational Spoken Language Translation</a></p>
<p>17 0.033098582 <a title="239-tfidf-17" href="./acl-2013-Graph-based_Semi-Supervised_Model_for_Joint_Chinese_Word_Segmentation_and_Part-of-Speech_Tagging.html">173 acl-2013-Graph-based Semi-Supervised Model for Joint Chinese Word Segmentation and Part-of-Speech Tagging</a></p>
<p>18 0.03294757 <a title="239-tfidf-18" href="./acl-2013-Multimodal_DBN_for_Predicting_High-Quality_Answers_in_cQA_portals.html">254 acl-2013-Multimodal DBN for Predicting High-Quality Answers in cQA portals</a></p>
<p>19 0.032678224 <a title="239-tfidf-19" href="./acl-2013-Question_Classification_Transfer.html">292 acl-2013-Question Classification Transfer</a></p>
<p>20 0.032556627 <a title="239-tfidf-20" href="./acl-2013-Evaluating_a_City_Exploration_Dialogue_System_with_Integrated_Question-Answering_and_Pedestrian_Navigation.html">141 acl-2013-Evaluating a City Exploration Dialogue System with Integrated Question-Answering and Pedestrian Navigation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.071), (1, 0.029), (2, -0.01), (3, -0.023), (4, 0.029), (5, -0.009), (6, 0.027), (7, -0.07), (8, 0.051), (9, 0.036), (10, -0.041), (11, -0.023), (12, -0.018), (13, -0.009), (14, -0.01), (15, -0.053), (16, -0.02), (17, 0.034), (18, -0.004), (19, -0.041), (20, -0.068), (21, -0.083), (22, -0.001), (23, -0.007), (24, -0.025), (25, 0.002), (26, 0.061), (27, -0.004), (28, 0.059), (29, -0.026), (30, 0.037), (31, 0.003), (32, -0.052), (33, 0.023), (34, 0.025), (35, 0.047), (36, -0.024), (37, 0.001), (38, -0.005), (39, 0.051), (40, -0.014), (41, -0.006), (42, 0.033), (43, 0.003), (44, -0.059), (45, 0.057), (46, 0.021), (47, -0.001), (48, 0.013), (49, -0.039)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92651254 <a title="239-lsi-1" href="./acl-2013-Meet_EDGAR%2C_a_tutoring_agent_at_MONSERRATE.html">239 acl-2013-Meet EDGAR, a tutoring agent at MONSERRATE</a></p>
<p>Author: Pedro Fialho ; Luisa Coheur ; Sergio Curto ; Pedro Claudio ; Angela Costa ; Alberto Abad ; Hugo Meinedo ; Isabel Trancoso</p><p>Abstract: In this paper we describe a platform for embodied conversational agents with tutoring goals, which takes as input written and spoken questions and outputs answers in both forms. The platform is developed within a game environment, and currently allows speech recognition and synthesis in Portuguese, English and Spanish. In this paper we focus on its understanding component that supports in-domain interactions, and also small talk. Most indomain interactions are answered using different similarity metrics, which compare the perceived utterances with questions/sentences in the agent’s knowledge base; small-talk capabilities are mainly due to AIML, a language largely used by the chatbots’ community. In this paper we also introduce EDGAR, the butler of MONSERRATE, which was developed in the aforementioned platform, and that answers tourists’ questions about MONSERRATE.</p><p>2 0.66330481 <a title="239-lsi-2" href="./acl-2013-Evaluating_a_City_Exploration_Dialogue_System_with_Integrated_Question-Answering_and_Pedestrian_Navigation.html">141 acl-2013-Evaluating a City Exploration Dialogue System with Integrated Question-Answering and Pedestrian Navigation</a></p>
<p>Author: Srinivasan Janarthanam ; Oliver Lemon ; Phil Bartie ; Tiphaine Dalmas ; Anna Dickinson ; Xingkun Liu ; William Mackaness ; Bonnie Webber</p><p>Abstract: We present a city navigation and tourist information mobile dialogue app with integrated question-answering (QA) and geographic information system (GIS) modules that helps pedestrian users to navigate in and learn about urban environments. In contrast to existing mobile apps which treat these problems independently, our Android app addresses the problem of navigation and touristic questionanswering in an integrated fashion using a shared dialogue context. We evaluated our system in comparison with Samsung S-Voice (which interfaces to Google navigation and Google search) with 17 users and found that users judged our system to be significantly more interesting to interact with and learn from. They also rated our system above Google search (with the Samsung S-Voice interface) for tourist information tasks.</p><p>3 0.61267591 <a title="239-lsi-3" href="./acl-2013-Extending_an_interoperable_platform_to_facilitate_the_creation_of_multilingual_and_multimodal_NLP_applications.html">150 acl-2013-Extending an interoperable platform to facilitate the creation of multilingual and multimodal NLP applications</a></p>
<p>Author: Georgios Kontonatsios ; Paul Thompson ; Riza Theresa Batista-Navarro ; Claudiu Mihaila ; Ioannis Korkontzelos ; Sophia Ananiadou</p><p>Abstract: U-Compare is a UIMA-based workflow construction platform for building natural language processing (NLP) applications from heterogeneous language resources (LRs), without the need for programming skills. U-Compare has been adopted within the context of the METANET Network of Excellence, and over 40 LRs that process 15 European languages have been added to the U-Compare component library. In line with METANET’s aims of increasing communication between citizens of different European countries, U-Compare has been extended to facilitate the development of a wider range of applications, including both mul- tilingual and multimodal workflows. The enhancements exploit the UIMA Subject of Analysis (Sofa) mechanism, that allows different facets of the input data to be represented. We demonstrate how our customised extensions to U-Compare allow the construction and testing of NLP applications that transform the input data in different ways, e.g., machine translation, automatic summarisation and text-to-speech.</p><p>4 0.58827651 <a title="239-lsi-4" href="./acl-2013-Development_and_Analysis_of_NLP_Pipelines_in_Argo.html">118 acl-2013-Development and Analysis of NLP Pipelines in Argo</a></p>
<p>Author: Rafal Rak ; Andrew Rowley ; Jacob Carter ; Sophia Ananiadou</p><p>Abstract: Developing sophisticated NLP pipelines composed of multiple processing tools and components available through different providers may pose a challenge in terms of their interoperability. The Unstructured Information Management Architecture (UIMA) is an industry standard whose aim is to ensure such interoperability by defining common data structures and interfaces. The architecture has been gaining attention from industry and academia alike, resulting in a large volume ofUIMA-compliant processing components. In this paper, we demonstrate Argo, a Web-based workbench for the development and processing of NLP pipelines/workflows. The workbench is based upon UIMA, and thus has the potential of using many of the existing UIMA resources. We present features, and show examples, offacilitating the distributed development of components and the analysis of processing results. The latter includes annotation visualisers and editors, as well as serialisation to RDF format, which enables flexible querying in addition to data manipulation thanks to the semantic query language SPARQL. The distributed development feature allows users to seamlessly connect their tools to workflows running in Argo, and thus take advantage of both the available library of components (without the need of installing them locally) and the analytical tools.</p><p>5 0.56316465 <a title="239-lsi-5" href="./acl-2013-Implicatures_and_Nested_Beliefs_in_Approximate_Decentralized-POMDPs.html">190 acl-2013-Implicatures and Nested Beliefs in Approximate Decentralized-POMDPs</a></p>
<p>Author: Adam Vogel ; Christopher Potts ; Dan Jurafsky</p><p>Abstract: Conversational implicatures involve reasoning about multiply nested belief structures. This complexity poses significant challenges for computational models of conversation and cognition. We show that agents in the multi-agent DecentralizedPOMDP reach implicature-rich interpretations simply as a by-product of the way they reason about each other to maximize joint utility. Our simulations involve a reference game of the sort studied in psychology and linguistics as well as a dynamic, interactional scenario involving implemented artificial agents.</p><p>6 0.55427408 <a title="239-lsi-6" href="./acl-2013-AnnoMarket%3A_An_Open_Cloud_Platform_for_NLP.html">51 acl-2013-AnnoMarket: An Open Cloud Platform for NLP</a></p>
<p>7 0.54879487 <a title="239-lsi-7" href="./acl-2013-Identification_of_Speakers_in_Novels.html">184 acl-2013-Identification of Speakers in Novels</a></p>
<p>8 0.53178799 <a title="239-lsi-8" href="./acl-2013-Conditional_Random_Fields_for_Responsive_Surface_Realisation_using_Global_Features.html">90 acl-2013-Conditional Random Fields for Responsive Surface Realisation using Global Features</a></p>
<p>9 0.5029881 <a title="239-lsi-9" href="./acl-2013-PAL%3A_A_Chatterbot_System_for_Answering_Domain-specific_Questions.html">266 acl-2013-PAL: A Chatterbot System for Answering Domain-specific Questions</a></p>
<p>10 0.50180012 <a title="239-lsi-10" href="./acl-2013-Predicting_and_Eliciting_Addressee%27s_Emotion_in_Online_Dialogue.html">282 acl-2013-Predicting and Eliciting Addressee's Emotion in Online Dialogue</a></p>
<p>11 0.49179435 <a title="239-lsi-11" href="./acl-2013-Sign_Language_Lexical_Recognition_With_Propositional_Dynamic_Logic.html">321 acl-2013-Sign Language Lexical Recognition With Propositional Dynamic Logic</a></p>
<p>12 0.48934001 <a title="239-lsi-12" href="./acl-2013-Combining_Referring_Expression_Generation_and_Surface_Realization%3A_A_Corpus-Based_Investigation_of_Architectures.html">86 acl-2013-Combining Referring Expression Generation and Surface Realization: A Corpus-Based Investigation of Architectures</a></p>
<p>13 0.48003182 <a title="239-lsi-13" href="./acl-2013-Is_word-to-phone_mapping_better_than_phone-phone_mapping_for_handling_English_words%3F.html">203 acl-2013-Is word-to-phone mapping better than phone-phone mapping for handling English words?</a></p>
<p>14 0.46098974 <a title="239-lsi-14" href="./acl-2013-Tag2Blog%3A_Narrative_Generation_from_Satellite_Tag_Data.html">337 acl-2013-Tag2Blog: Narrative Generation from Satellite Tag Data</a></p>
<p>15 0.42938685 <a title="239-lsi-15" href="./acl-2013-Multimodal_DBN_for_Predicting_High-Quality_Answers_in_cQA_portals.html">254 acl-2013-Multimodal DBN for Predicting High-Quality Answers in cQA portals</a></p>
<p>16 0.41401526 <a title="239-lsi-16" href="./acl-2013-PATHS%3A_A_System_for_Accessing_Cultural_Heritage_Collections.html">268 acl-2013-PATHS: A System for Accessing Cultural Heritage Collections</a></p>
<p>17 0.40406668 <a title="239-lsi-17" href="./acl-2013-Crawling_microblogging_services_to_gather_language-classified_URLs._Workflow_and_case_study.html">95 acl-2013-Crawling microblogging services to gather language-classified URLs. Workflow and case study</a></p>
<p>18 0.39853576 <a title="239-lsi-18" href="./acl-2013-From_Natural_Language_Specifications_to_Program_Input_Parsers.html">163 acl-2013-From Natural Language Specifications to Program Input Parsers</a></p>
<p>19 0.38000792 <a title="239-lsi-19" href="./acl-2013-Fluid_Construction_Grammar_for_Historical_and_Evolutionary_Linguistics.html">161 acl-2013-Fluid Construction Grammar for Historical and Evolutionary Linguistics</a></p>
<p>20 0.37750447 <a title="239-lsi-20" href="./acl-2013-WebAnno%3A_A_Flexible%2C_Web-based_and_Visually_Supported_System_for_Distributed_Annotations.html">385 acl-2013-WebAnno: A Flexible, Web-based and Visually Supported System for Distributed Annotations</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.093), (6, 0.035), (11, 0.032), (15, 0.018), (24, 0.045), (26, 0.046), (27, 0.357), (28, 0.02), (35, 0.055), (42, 0.036), (48, 0.023), (70, 0.044), (88, 0.022), (90, 0.041), (95, 0.039)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.77234983 <a title="239-lda-1" href="./acl-2013-Meet_EDGAR%2C_a_tutoring_agent_at_MONSERRATE.html">239 acl-2013-Meet EDGAR, a tutoring agent at MONSERRATE</a></p>
<p>Author: Pedro Fialho ; Luisa Coheur ; Sergio Curto ; Pedro Claudio ; Angela Costa ; Alberto Abad ; Hugo Meinedo ; Isabel Trancoso</p><p>Abstract: In this paper we describe a platform for embodied conversational agents with tutoring goals, which takes as input written and spoken questions and outputs answers in both forms. The platform is developed within a game environment, and currently allows speech recognition and synthesis in Portuguese, English and Spanish. In this paper we focus on its understanding component that supports in-domain interactions, and also small talk. Most indomain interactions are answered using different similarity metrics, which compare the perceived utterances with questions/sentences in the agent’s knowledge base; small-talk capabilities are mainly due to AIML, a language largely used by the chatbots’ community. In this paper we also introduce EDGAR, the butler of MONSERRATE, which was developed in the aforementioned platform, and that answers tourists’ questions about MONSERRATE.</p><p>2 0.44059238 <a title="239-lda-2" href="./acl-2013-Using_Supervised_Bigram-based_ILP_for_Extractive_Summarization.html">377 acl-2013-Using Supervised Bigram-based ILP for Extractive Summarization</a></p>
<p>Author: Chen Li ; Xian Qian ; Yang Liu</p><p>Abstract: In this paper, we propose a bigram based supervised method for extractive document summarization in the integer linear programming (ILP) framework. For each bigram, a regression model is used to estimate its frequency in the reference summary. The regression model uses a variety ofindicative features and is trained discriminatively to minimize the distance between the estimated and the ground truth bigram frequency in the reference summary. During testing, the sentence selection problem is formulated as an ILP problem to maximize the bigram gains. We demonstrate that our system consistently outperforms the previous ILP method on different TAC data sets, and performs competitively compared to the best results in the TAC evaluations. We also conducted various analysis to show the impact of bigram selection, weight estimation, and ILP setup.</p><p>3 0.37697658 <a title="239-lda-3" href="./acl-2013-Unsupervised_Consonant-Vowel_Prediction_over_Hundreds_of_Languages.html">369 acl-2013-Unsupervised Consonant-Vowel Prediction over Hundreds of Languages</a></p>
<p>Author: Young-Bum Kim ; Benjamin Snyder</p><p>Abstract: In this paper, we present a solution to one aspect of the decipherment task: the prediction of consonants and vowels for an unknown language and alphabet. Adopting a classical Bayesian perspective, we performs posterior inference over hundreds of languages, leveraging knowledge of known languages and alphabets to uncover general linguistic patterns of typologically coherent language clusters. We achieve average accuracy in the unsupervised consonant/vowel prediction task of 99% across 503 languages. We further show that our methodology can be used to predict more fine-grained phonetic distinctions. On a three-way classification task between vowels, nasals, and nonnasal consonants, our model yields unsu- pervised accuracy of 89% across the same set of languages.</p><p>4 0.37613928 <a title="239-lda-4" href="./acl-2013-SEMILAR%3A_The_Semantic_Similarity_Toolkit.html">304 acl-2013-SEMILAR: The Semantic Similarity Toolkit</a></p>
<p>Author: Vasile Rus ; Mihai Lintean ; Rajendra Banjade ; Nobal Niraula ; Dan Stefanescu</p><p>Abstract: We present in this paper SEMILAR, the SEMantic simILARity toolkit. SEMILAR implements a number of algorithms for assessing the semantic similarity between two texts. It is available as a Java library and as a Java standalone ap-plication offering GUI-based access to the implemented semantic similarity methods. Furthermore, it offers facilities for manual se-mantic similarity annotation by experts through its component SEMILAT (a SEMantic simILarity Annotation Tool). 1</p><p>5 0.37572831 <a title="239-lda-5" href="./acl-2013-Collective_Annotation_of_Linguistic_Resources%3A_Basic_Principles_and_a_Formal_Model.html">83 acl-2013-Collective Annotation of Linguistic Resources: Basic Principles and a Formal Model</a></p>
<p>Author: Ulle Endriss ; Raquel Fernandez</p><p>Abstract: Crowdsourcing, which offers new ways of cheaply and quickly gathering large amounts of information contributed by volunteers online, has revolutionised the collection of labelled data. Yet, to create annotated linguistic resources from this data, we face the challenge of having to combine the judgements of a potentially large group of annotators. In this paper we investigate how to aggregate individual annotations into a single collective annotation, taking inspiration from the field of social choice theory. We formulate a general formal model for collective annotation and propose several aggregation methods that go beyond the commonly used majority rule. We test some of our methods on data from a crowdsourcing experiment on textual entailment annotation.</p><p>6 0.37229705 <a title="239-lda-6" href="./acl-2013-Creating_Similarity%3A_Lateral_Thinking_for_Vertical_Similarity_Judgments.html">96 acl-2013-Creating Similarity: Lateral Thinking for Vertical Similarity Judgments</a></p>
<p>7 0.3713277 <a title="239-lda-7" href="./acl-2013-Development_and_Analysis_of_NLP_Pipelines_in_Argo.html">118 acl-2013-Development and Analysis of NLP Pipelines in Argo</a></p>
<p>8 0.36892197 <a title="239-lda-8" href="./acl-2013-Align%2C_Disambiguate_and_Walk%3A_A_Unified_Approach_for_Measuring_Semantic_Similarity.html">43 acl-2013-Align, Disambiguate and Walk: A Unified Approach for Measuring Semantic Similarity</a></p>
<p>9 0.36867142 <a title="239-lda-9" href="./acl-2013-Automated_Pyramid_Scoring_of_Summaries_using_Distributional_Semantics.html">59 acl-2013-Automated Pyramid Scoring of Summaries using Distributional Semantics</a></p>
<p>10 0.36862057 <a title="239-lda-10" href="./acl-2013-Models_of_Translation_Competitions.html">250 acl-2013-Models of Translation Competitions</a></p>
<p>11 0.36855906 <a title="239-lda-11" href="./acl-2013-ICARUS_-_An_Extensible_Graphical_Search_Tool_for_Dependency_Treebanks.html">183 acl-2013-ICARUS - An Extensible Graphical Search Tool for Dependency Treebanks</a></p>
<p>12 0.36790159 <a title="239-lda-12" href="./acl-2013-Fast_and_Robust_Compressive_Summarization_with_Dual_Decomposition_and_Multi-Task_Learning.html">157 acl-2013-Fast and Robust Compressive Summarization with Dual Decomposition and Multi-Task Learning</a></p>
<p>13 0.36762637 <a title="239-lda-13" href="./acl-2013-Linking_Tweets_to_News%3A_A_Framework_to_Enrich_Short_Text_Data_in_Social_Media.html">233 acl-2013-Linking Tweets to News: A Framework to Enrich Short Text Data in Social Media</a></p>
<p>14 0.36725157 <a title="239-lda-14" href="./acl-2013-Recognizing_Partial_Textual_Entailment.html">297 acl-2013-Recognizing Partial Textual Entailment</a></p>
<p>15 0.36668947 <a title="239-lda-15" href="./acl-2013-Learning_Semantic_Textual_Similarity_with_Structural_Representations.html">222 acl-2013-Learning Semantic Textual Similarity with Structural Representations</a></p>
<p>16 0.36660057 <a title="239-lda-16" href="./acl-2013-Probabilistic_Sense_Sentiment_Similarity_through_Hidden_Emotions.html">284 acl-2013-Probabilistic Sense Sentiment Similarity through Hidden Emotions</a></p>
<p>17 0.36588308 <a title="239-lda-17" href="./acl-2013-Improved_Bayesian_Logistic_Supervised_Topic_Models_with_Data_Augmentation.html">191 acl-2013-Improved Bayesian Logistic Supervised Topic Models with Data Augmentation</a></p>
<p>18 0.36467609 <a title="239-lda-18" href="./acl-2013-Multimodal_DBN_for_Predicting_High-Quality_Answers_in_cQA_portals.html">254 acl-2013-Multimodal DBN for Predicting High-Quality Answers in cQA portals</a></p>
<p>19 0.36432934 <a title="239-lda-19" href="./acl-2013-WebAnno%3A_A_Flexible%2C_Web-based_and_Visually_Supported_System_for_Distributed_Annotations.html">385 acl-2013-WebAnno: A Flexible, Web-based and Visually Supported System for Distributed Annotations</a></p>
<p>20 0.36414444 <a title="239-lda-20" href="./acl-2013-An_Infinite_Hierarchical_Bayesian_Model_of_Phrasal_Translation.html">46 acl-2013-An Infinite Hierarchical Bayesian Model of Phrasal Translation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
