<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>187 acl-2013-Identifying Opinion Subgroups in Arabic Online Discussions</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-187" href="#">acl2013-187</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>187 acl-2013-Identifying Opinion Subgroups in Arabic Online Discussions</h1>
<br/><p>Source: <a title="acl-2013-187-pdf" href="http://aclweb.org/anthology//P/P13/P13-2144.pdf">pdf</a></p><p>Author: Amjad Abu-Jbara ; Ben King ; Mona Diab ; Dragomir Radev</p><p>Abstract: In this paper, we use Arabic natural language processing techniques to analyze Arabic debates. The goal is to identify how the participants in a discussion split into subgroups with contrasting opinions. The members of each subgroup share the same opinion with respect to the discussion topic and an opposing opinion to the members of other subgroups. We use opinion mining techniques to identify opinion expressions and determine their polarities and their targets. We opinion predictions to represent the discussion in one of two formal representations: signed attitude network or a space of attitude vectors. We identify opinion subgroups by partitioning the signed network representation or by clustering the vector space representation. We evaluate the system using a data set of labeled discussions and show that it achieves good results.</p><p>Reference: <a title="acl-2013-187-reference" href="../acl2013_reference/acl-2013-Identifying_Opinion_Subgroups_in_Arabic_Online_Discussions_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The goal is to identify how the participants in a discussion split into subgroups with contrasting opinions. [sent-4, score-0.501]
</p><p>2 The members of each subgroup share the  same opinion with respect to the discussion topic and an opposing opinion to the members of other subgroups. [sent-5, score-1.134]
</p><p>3 We use opinion mining techniques to identify opinion expressions and determine their polarities and their targets. [sent-6, score-0.944]
</p><p>4 We opinion predictions to represent the discussion in one of two formal representations: signed attitude network or a space of attitude vectors. [sent-7, score-1.064]
</p><p>5 We identify opinion subgroups by partitioning the signed network representation or by clustering the vector space representation. [sent-8, score-1.289]
</p><p>6 The re-  cent political and civic movements in the Arab World resulted in a revolutionary growth in the number of Arabic users on social networking sites. [sent-13, score-0.156]
</p><p>7 This growth in the presence of Arab users on social networks and all the interactions and discussions that happen among them led to a huge amount of opinion-rich Arabic text being available. [sent-17, score-0.171]
</p><p>8 When a controversial topic is discussed, it is normal for the discussants to adopt different viewpoints towards it. [sent-19, score-0.284]
</p><p>9 This usually causes rifts in discussion groups and leads to the split of the discussants into subgroups with contrasting opinions. [sent-20, score-0.609]
</p><p>10 Our goal in this paper is to use natural language processing techniques to detect opinion subgroups in Arabic discussions. [sent-21, score-0.67]
</p><p>11 Our approach starts by identifying opinionated (subjective) text and determining its polarity (positive, negative, or neutral). [sent-22, score-0.203]
</p><p>12 Next, we determine the target of each opinion expression. [sent-23, score-0.442]
</p><p>13 The target of opinion can be a named entity mentioned in the discussion or an aspect of the discussed topic. [sent-24, score-0.541]
</p><p>14 We use the identified opiniontarget relations to represent the discussion in one of two formal representations. [sent-25, score-0.148]
</p><p>15 In the first representation, each discussant is represented by a vector that encodes all his or her opinion information towards the discussion topic. [sent-26, score-0.791]
</p><p>16 In the second representation, each discussant is represented by a node in a signed graph. [sent-27, score-0.488]
</p><p>17 A positive edge connects two  discussants if they have similar opinion towards the topic, otherwise the sign of the edge is nega1http : / / semi oca st . [sent-28, score-0.691]
</p><p>18 To identify opinion subgroups, we cluster the vector space (the first representation) or partition the signed network (the second representation). [sent-32, score-0.849]
</p><p>19 The results show that the clustering the vector space representation achieves better results than partitioning the signed network representation. [sent-35, score-0.567]
</p><p>20 2  Previous Work  Our work is related to a large body of research on opinion mining and sentiment analysis. [sent-36, score-0.606]
</p><p>21 Pang & Lee (2008) and Liu & Zhang (2012) wrote two re-  cent comprehensive surveys about sentiment analysis and opinion mining techniques and applications. [sent-37, score-0.644]
</p><p>22 Previous work has proposed methods for identifying subjective text that expresses opinion and distinguishing it from objective text that presents factual information (Wiebe, 2000; Hatzivassiloglou and Wiebe, 2000a; Banea et al. [sent-38, score-0.535]
</p><p>23 Previous work addressed the problem of identifying the polarity of subjective text (Hatzivassiloglou and Wiebe, 2000b; Hassan et al. [sent-41, score-0.223]
</p><p>24 Many of the proposed methods for text polarity identification depend on the availability of polarity lexicons (i. [sent-44, score-0.196]
</p><p>25 Other research efforts focused on identifying the holders and the targets of opinion (Zhai et al. [sent-49, score-0.57]
</p><p>26 Opinion mining and sentiment analysis techniques have been used in various applications. [sent-52, score-0.196]
</p><p>27 One example of such applications is identifying perspectives (Grefenstette et al. [sent-53, score-0.111]
</p><p>28 (2003) proposed a method for extracting perspectives from political texts. [sent-59, score-0.102]
</p><p>29 They used their method to estimate the policy positions ofpolitical parties in Britain and Ireland, on both economic and social policy dimensions. [sent-60, score-0.152]
</p><p>30 Somasundaran and Wiebe (2009) present an unsupervised opinion analysis method for debateside classification. [sent-61, score-0.41]
</p><p>31 They mine the web to learn associations that are indicative of opinion stances in debates and combine this knowledge with discourse information. [sent-62, score-0.494]
</p><p>32 They use a number of linguistic and structural fea-  tures such as unigrams, bigrams, cue words, repeated punctuation, and opinion dependencies to build a stance classification model. [sent-65, score-0.46]
</p><p>33 In previous work, we proposed a method that uses participantto-participant and participant-to-topic attitudes to identify subgroups in ideological discussions using attitude vector space clustering (Abu-Jbara and Radev, 2012). [sent-66, score-0.702]
</p><p>34 In this paper, we extend this method by adding latent similarity features to the attitude vectors and applying it to Arabic discussions. [sent-67, score-0.162]
</p><p>35 In another previous work, our group proposed a supervised method for extracting signed social networks from text (Hassan et al. [sent-68, score-0.36]
</p><p>36 The signed networks constructed using this method were based only on participant-to-participant attitudes that are expressed explicitly in discussions. [sent-70, score-0.363]
</p><p>37 We used this method to extract signed networks from discussions and used a partitioning algorithm to detect opinion subgroups (Hassan et al. [sent-71, score-1.127]
</p><p>38 In this paper, we extend this method by using participant-to-topic attitudes to construct the signed network. [sent-73, score-0.308]
</p><p>39 Unfortunately, not much work has been done  on Arabic sentiment analysis and opinion mining. [sent-74, score-0.567]
</p><p>40 (2008) applies sentiment analysis techniques to identify and classify documentlevel opinions in text crawled from English and Arabic web forums. [sent-76, score-0.209]
</p><p>41 (201 1) proposed a method for identifying the polarity of nonEnglish words using multilingual semantic graphs. [sent-78, score-0.163]
</p><p>42 Abdul-Mageed and Diab (201 1) annotated a corpus of Modern Standard Arabic (MSA) news text for subjectivity at the sentence level. [sent-80, score-0.126]
</p><p>43 (2012a) developed SAMAR, a system for subjectivity and Sentiment Analysis for Arabic social media genres. [sent-83, score-0.188]
</p><p>44 3 Approach In this section, we present our approach to de-  tecting opinion subgroups in Arabic discussions. [sent-85, score-0.67]
</p><p>45 The input to the pipeline is a discussion thread in Arabic language crawled from a discussion forum. [sent-87, score-0.283]
</p><p>46 The output is the list of participants in the discussion and the subgroup membership of each discussant. [sent-88, score-0.26]
</p><p>47 1 Preprocessing The input to this component is a discussion thread in HTML format. [sent-91, score-0.145]
</p><p>48 We parse the HTML file to identify the posts, the discussants, and the thread structure. [sent-92, score-0.098]
</p><p>49 We transform the Arabic content of the posts and the discussant names that are written in Arabic to the Buckwalter encoding (Buckwalter, 2004). [sent-93, score-0.345]
</p><p>50 We identify the polarized words that appear in text by looking each word up in a lexicon  of Arabic polarized words. [sent-97, score-0.164]
</p><p>51 For example, a positive word that appears in a negated context should be treated as expressing negative opinion rather than positive. [sent-101, score-0.517]
</p><p>52 To identify the polarity of a word given the sentence it appears in, we use SAMAR (Abdul-Mageed et al. [sent-102, score-0.15]
</p><p>53 SAMAR labels a sentence that contains an opinion expression as positive, negative, or neutral taking into account the context of the opinion expression. [sent-104, score-0.82]
</p><p>54 The reported accuracy of SAMAR on different data sets ranges between 84% and 95% for subjectivity classification and 65% and 81% for polarity classification. [sent-105, score-0.224]
</p><p>55 3 Identifying Opinion Targets In this step, we determine the targets that the opinion is expressed towards. [sent-107, score-0.505]
</p><p>56 To avoid the noise that may result from including all noun phrases, we limit what we consider as an opinion target, to the ones that appear in at least two posts written by two different participants. [sent-109, score-0.51]
</p><p>57 Since, the sentence may contain multiple possible targets for every opinion expression, we associate each opinion expression with the target that is closest to it in the sentence. [sent-110, score-0.947]
</p><p>58 For each discussant, we keep track of the targets mentioned in his/her posts and the number of times each target was mentioned in a positive/negative context. [sent-111, score-0.194]
</p><p>59 4 Latent Textual Similarity If two participants share the same opinion, they tend to focus on similar aspects of the discussion topic and emphasize similar points that support their opinion. [sent-113, score-0.175]
</p><p>60 So, we represent all the text written in the discussion by each participant as a vector of 100 dimensions. [sent-117, score-0.208]
</p><p>61 The vector of each participant contains the topic distribution of the participant, as produced by the LDA model. [sent-118, score-0.116]
</p><p>62 5 Subgroup Detection At this point, we have for every discussant the targets towards which he/she expressed explicit opinion and a 100-dimensions vector representing the LDA distribution of the text written by him/her. [sent-120, score-0.82]
</p><p>63 We use this information to represent the discussion in two representations. [sent-121, score-0.099]
</p><p>64 In the first representation, each discussant is represented by a vector. [sent-122, score-0.245]
</p><p>65 (b) and (c) are two posts expressing contrasting viewpoints with respect to the topic. [sent-129, score-0.169]
</p><p>66 We also add to this vector the 100 topic entries from the LDA vector of that discussant. [sent-132, score-0.114]
</p><p>67 So, if the number of targets identified in step 3 of the pipeline is t then the number of entries in the discussant vector is 3 ∗ t 100. [sent-133, score-0.416]
</p><p>68 To identify opinion subgroups, we cluster the vector space. [sent-134, score-0.499]
</p><p>69 In this representation, each discussant is represented by a node in a graph. [sent-138, score-0.245]
</p><p>70 Two discussants are connected by an edge if they both mention at least one common target in their posts. [sent-139, score-0.228]
</p><p>71 If a discussant mentions a target multiple times in different contexts with different polarities, the ma-  +  ××  jority polarity is assumed as the opinion of this discussant with respect to this target. [sent-140, score-1.03]
</p><p>72 A positive sign is assigned to the edge connecting two discussants if the number of targets that they have similar opinion towards is greater than the targets that they have opposing opinion towards, otherwise a negative sign is assigned to the edge. [sent-141, score-1.431]
</p><p>73 To identify subgroups, we use a signed network partitioning algorithm to partition the network. [sent-142, score-0.507]
</p><p>74 , 2012b), we use the Dorian-Mrvar (1996) algorithm to partition the signed network. [sent-145, score-0.284]
</p><p>75 The optimization criterion aims to have dense positive links within groups and dense negative links between groups. [sent-146, score-0.179]
</p><p>76 4  Data  We use data from an Arabic discussion forum called Naqeshny. [sent-154, score-0.099]
</p><p>77 This means that the data set is self-labeled for subgroup membership. [sent-164, score-0.125]
</p><p>78 The average number of posts per discussion is 19. [sent-167, score-0.166]
</p><p>79 75 and the average number of participants per discussion is 13. [sent-168, score-0.135]
</p><p>80 In one variation, we use the signed network partitioning approach to detect subgroups. [sent-174, score-0.414]
</p><p>81 In the other variations, we use the vector space clustering approach. [sent-175, score-0.114]
</p><p>82 We also run two experiments to evaluate the contribution of both opiniontarget counts and latent similarity features on the clustering accuracy. [sent-177, score-0.165]
</p><p>83 The results show that the clustering approach achieves better results than the signed network partitioning approach. [sent-185, score-0.491]
</p><p>84 This can be explained by the fact that the vector representation is a richer representation and encodes all the discussants’ opinion information explicitly. [sent-186, score-0.525]
</p><p>85 6  Conclusion  In this paper, we presented a system for identifying opinion subgroups in Arabic online discussions. [sent-189, score-0.735]
</p><p>86 The system uses opinion and text sim-  TSCOiyeplsugxtneiSmdornN-gTielatwrFgEKoeyM-tkmOnalysP0 u. [sent-190, score-0.41]
</p><p>87 The first approach clusters a space of dis-  cussant opinion vectors. [sent-195, score-0.41]
</p><p>88 The second approach partitions a signed network representation of the discussion. [sent-196, score-0.348]
</p><p>89 Our experiments also showed that both opinion and similarity features are important. [sent-198, score-0.41]
</p><p>90 All statements of fact, opinion or conclusions contained herein are those of the authors and should not be construed as representing the of? [sent-200, score-0.41]
</p><p>91 Sentiment analysis in multiple languages: Feature selection for opinion classification in web forums. [sent-207, score-0.41]
</p><p>92 Subjectivity and sentiment annotation of modern standard arabic newswire. [sent-214, score-0.521]
</p><p>93 Awatif: A multi-genre corpus for modern standard arabic subjectivity and sentiment analysis. [sent-219, score-0.647]
</p><p>94 Samar: a system for subjectivity  and sentiment analysis of arabic social media. [sent-228, score-0.676]
</p><p>95 Samar: A system for subjectivity and sentiment analysis of arabic social media. [sent-233, score-0.676]
</p><p>96 A bootstrapping method for building subjectivity lexicons for languages with scarce resources. [sent-251, score-0.126]
</p><p>97 Genre independent subgroup detection in online discussion threads: A study of implicit attitude using textual latent semantics. [sent-269, score-0.386]
</p><p>98 Coupling niche browsers and affect analysis for an opinion mining application. [sent-294, score-0.449]
</p><p>99 Signed attitude networks: Predicting positive and negative links using linguistic analysis. [sent-323, score-0.266]
</p><p>100 Extracting policy positions from political texts using words as data. [sent-345, score-0.101]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('opinion', 0.41), ('arabic', 0.331), ('subgroups', 0.26), ('discussant', 0.245), ('signed', 0.243), ('discussants', 0.196), ('sentiment', 0.157), ('samar', 0.14), ('hassan', 0.13), ('subjectivity', 0.126), ('subgroup', 0.125), ('attitude', 0.123), ('janyce', 0.12), ('mona', 0.112), ('partitioning', 0.105), ('amjad', 0.1), ('discussion', 0.099), ('polarity', 0.098), ('targets', 0.095), ('arab', 0.094), ('muhammad', 0.086), ('dragomir', 0.085), ('wiebe', 0.079), ('clustering', 0.077), ('ahmed', 0.074), ('hatzivassiloglou', 0.07), ('posts', 0.067), ('network', 0.066), ('attitudes', 0.065), ('identifying', 0.065), ('social', 0.062), ('subjective', 0.06), ('diab', 0.059), ('korea', 0.058), ('umi', 0.056), ('polarized', 0.056), ('political', 0.056), ('negative', 0.056), ('networks', 0.055), ('discussions', 0.054), ('contrasting', 0.054), ('identify', 0.052), ('positive', 0.051), ('riloff', 0.05), ('opposing', 0.05), ('stance', 0.05), ('debates', 0.05), ('gradability', 0.049), ('hochbaum', 0.049), ('laver', 0.049), ('opiniontarget', 0.049), ('radev', 0.048), ('eecs', 0.048), ('viewpoints', 0.048), ('perspectives', 0.046), ('thread', 0.046), ('debate', 0.045), ('policy', 0.045), ('orientation', 0.045), ('lda', 0.044), ('jeju', 0.044), ('vasileios', 0.044), ('abbasi', 0.043), ('partition', 0.041), ('guo', 0.04), ('topic', 0.04), ('wassa', 0.04), ('opinionated', 0.04), ('representation', 0.039), ('pipeline', 0.039), ('latent', 0.039), ('mining', 0.039), ('participant', 0.039), ('fastest', 0.038), ('cent', 0.038), ('michigan', 0.037), ('vector', 0.037), ('zhai', 0.037), ('participants', 0.036), ('links', 0.036), ('dasigi', 0.036), ('banea', 0.036), ('buckwalter', 0.036), ('wilson', 0.035), ('sign', 0.034), ('bethard', 0.034), ('ideological', 0.034), ('stances', 0.034), ('anand', 0.034), ('bente', 0.034), ('maegaard', 0.034), ('grefenstette', 0.033), ('polarities', 0.033), ('choukri', 0.033), ('dempster', 0.033), ('written', 0.033), ('modern', 0.033), ('target', 0.032), ('msa', 0.032), ('takamura', 0.032)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="187-tfidf-1" href="./acl-2013-Identifying_Opinion_Subgroups_in_Arabic_Online_Discussions.html">187 acl-2013-Identifying Opinion Subgroups in Arabic Online Discussions</a></p>
<p>Author: Amjad Abu-Jbara ; Ben King ; Mona Diab ; Dragomir Radev</p><p>Abstract: In this paper, we use Arabic natural language processing techniques to analyze Arabic debates. The goal is to identify how the participants in a discussion split into subgroups with contrasting opinions. The members of each subgroup share the same opinion with respect to the discussion topic and an opposing opinion to the members of other subgroups. We use opinion mining techniques to identify opinion expressions and determine their polarities and their targets. We opinion predictions to represent the discussion in one of two formal representations: signed attitude network or a space of attitude vectors. We identify opinion subgroups by partitioning the signed network representation or by clustering the vector space representation. We evaluate the system using a data set of labeled discussions and show that it achieves good results.</p><p>2 0.40791661 <a title="187-tfidf-2" href="./acl-2013-Mining_Opinion_Words_and_Opinion_Targets_in_a_Two-Stage_Framework.html">244 acl-2013-Mining Opinion Words and Opinion Targets in a Two-Stage Framework</a></p>
<p>Author: Liheng Xu ; Kang Liu ; Siwei Lai ; Yubo Chen ; Jun Zhao</p><p>Abstract: This paper proposes a novel two-stage method for mining opinion words and opinion targets. In the first stage, we propose a Sentiment Graph Walking algorithm, which naturally incorporates syntactic patterns in a Sentiment Graph to extract opinion word/target candidates. Then random walking is employed to estimate confidence of candidates, which improves extraction accuracy by considering confidence of patterns. In the second stage, we adopt a self-learning strategy to refine the results from the first stage, especially for filtering out high-frequency noise terms and capturing the long-tail terms, which are not investigated by previous methods. The experimental results on three real world datasets demonstrate the effectiveness of our approach compared with stateof-the-art unsupervised methods.</p><p>3 0.40225732 <a title="187-tfidf-3" href="./acl-2013-Joint_Inference_for_Fine-grained_Opinion_Extraction.html">207 acl-2013-Joint Inference for Fine-grained Opinion Extraction</a></p>
<p>Author: Bishan Yang ; Claire Cardie</p><p>Abstract: This paper addresses the task of finegrained opinion extraction the identification of opinion-related entities: the opinion expressions, the opinion holders, and the targets of the opinions, and the relations between opinion expressions and their targets and holders. Most existing approaches tackle the extraction of opinion entities and opinion relations in a pipelined manner, where the interdependencies among different extraction stages are not captured. We propose a joint inference model that leverages knowledge from predictors that optimize subtasks – of opinion extraction, and seeks a globally optimal solution. Experimental results demonstrate that our joint inference approach significantly outperforms traditional pipeline methods and baselines that tackle subtasks in isolation for the problem of opinion extraction.</p><p>4 0.33543181 <a title="187-tfidf-4" href="./acl-2013-Syntactic_Patterns_versus_Word_Alignment%3A_Extracting_Opinion_Targets_from_Online_Reviews.html">336 acl-2013-Syntactic Patterns versus Word Alignment: Extracting Opinion Targets from Online Reviews</a></p>
<p>Author: Kang Liu ; Liheng Xu ; Jun Zhao</p><p>Abstract: Mining opinion targets is a fundamental and important task for opinion mining from online reviews. To this end, there are usually two kinds of methods: syntax based and alignment based methods. Syntax based methods usually exploited syntactic patterns to extract opinion targets, which were however prone to suffer from parsing errors when dealing with online informal texts. In contrast, alignment based methods used word alignment model to fulfill this task, which could avoid parsing errors without using parsing. However, there is no research focusing on which kind of method is more better when given a certain amount of reviews. To fill this gap, this paper empiri- cally studies how the performance of these two kinds of methods vary when changing the size, domain and language of the corpus. We further combine syntactic patterns with alignment model by using a partially supervised framework and investigate whether this combination is useful or not. In our experiments, we verify that our combination is effective on the corpus with small and medium size.</p><p>5 0.26254562 <a title="187-tfidf-5" href="./acl-2013-LABR%3A_A_Large_Scale_Arabic_Book_Reviews_Dataset.html">211 acl-2013-LABR: A Large Scale Arabic Book Reviews Dataset</a></p>
<p>Author: Mohamed Aly ; Amir Atiya</p><p>Abstract: We introduce LABR, the largest sentiment analysis dataset to-date for the Arabic language. It consists of over 63,000 book reviews, each rated on a scale of 1 to 5 stars. We investigate the properties of the the dataset, and present its statistics. We explore using the dataset for two tasks: sentiment polarity classification and rating classification. We provide standard splits of the dataset into training and testing, for both polarity and rating classification, in both balanced and unbalanced settings. We run baseline experiments on the dataset to establish a benchmark.</p><p>6 0.20376085 <a title="187-tfidf-6" href="./acl-2013-Exploring_Sentiment_in_Social_Media%3A_Bootstrapping_Subjectivity_Clues_from_Multilingual_Twitter_Streams.html">148 acl-2013-Exploring Sentiment in Social Media: Bootstrapping Subjectivity Clues from Multilingual Twitter Streams</a></p>
<p>7 0.18985662 <a title="187-tfidf-7" href="./acl-2013-An_annotated_corpus_of_quoted_opinions_in_news_articles.html">49 acl-2013-An annotated corpus of quoted opinions in news articles</a></p>
<p>8 0.1804245 <a title="187-tfidf-8" href="./acl-2013-Identifying_Sentiment_Words_Using_an_Optimization-based_Model_without_Seed_Words.html">188 acl-2013-Identifying Sentiment Words Using an Optimization-based Model without Seed Words</a></p>
<p>9 0.17137502 <a title="187-tfidf-9" href="./acl-2013-Sentiment_Relevance.html">318 acl-2013-Sentiment Relevance</a></p>
<p>10 0.16934589 <a title="187-tfidf-10" href="./acl-2013-Discovering_User_Interactions_in_Ideological_Discussions.html">121 acl-2013-Discovering User Interactions in Ideological Discussions</a></p>
<p>11 0.15745081 <a title="187-tfidf-11" href="./acl-2013-Named_Entity_Recognition_using_Cross-lingual_Resources%3A_Arabic_as_an_Example.html">256 acl-2013-Named Entity Recognition using Cross-lingual Resources: Arabic as an Example</a></p>
<p>12 0.15649478 <a title="187-tfidf-12" href="./acl-2013-A_Bayesian_Model_for_Joint_Unsupervised_Induction_of_Sentiment%2C_Aspect_and_Discourse_Representations.html">2 acl-2013-A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations</a></p>
<p>13 0.15063739 <a title="187-tfidf-13" href="./acl-2013-Bi-directional_Inter-dependencies_of_Subjective_Expressions_and_Targets_and_their_Value_for_a_Joint_Model.html">67 acl-2013-Bi-directional Inter-dependencies of Subjective Expressions and Targets and their Value for a Joint Model</a></p>
<p>14 0.13493295 <a title="187-tfidf-14" href="./acl-2013-Extra-Linguistic_Constraints_on_Stance_Recognition_in_Ideological_Debates.html">151 acl-2013-Extra-Linguistic Constraints on Stance Recognition in Ideological Debates</a></p>
<p>15 0.13440658 <a title="187-tfidf-15" href="./acl-2013-Exploiting_Topic_based_Twitter_Sentiment_for_Stock_Prediction.html">147 acl-2013-Exploiting Topic based Twitter Sentiment for Stock Prediction</a></p>
<p>16 0.1321876 <a title="187-tfidf-16" href="./acl-2013-Utterance-Level_Multimodal_Sentiment_Analysis.html">379 acl-2013-Utterance-Level Multimodal Sentiment Analysis</a></p>
<p>17 0.12650478 <a title="187-tfidf-17" href="./acl-2013-Detecting_Event-Related_Links_and_Sentiments_from_Social_Media_Texts.html">115 acl-2013-Detecting Event-Related Links and Sentiments from Social Media Texts</a></p>
<p>18 0.11989687 <a title="187-tfidf-18" href="./acl-2013-The_Haves_and_the_Have-Nots%3A_Leveraging_Unlabelled_Corpora_for_Sentiment_Analysis.html">345 acl-2013-The Haves and the Have-Nots: Leveraging Unlabelled Corpora for Sentiment Analysis</a></p>
<p>19 0.11986456 <a title="187-tfidf-19" href="./acl-2013-Language_Independent_Connectivity_Strength_Features_for_Phrase_Pivot_Statistical_Machine_Translation.html">214 acl-2013-Language Independent Connectivity Strength Features for Phrase Pivot Statistical Machine Translation</a></p>
<p>20 0.11791617 <a title="187-tfidf-20" href="./acl-2013-Detecting_Chronic_Critics_Based_on_Sentiment_Polarity_and_User%C3%A2%E2%80%A2%C5%BDs_Behavior_in_Social_Media.html">114 acl-2013-Detecting Chronic Critics Based on Sentiment Polarity and Userâ•Žs Behavior in Social Media</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.207), (1, 0.325), (2, -0.016), (3, 0.331), (4, -0.119), (5, 0.097), (6, -0.24), (7, -0.089), (8, -0.12), (9, -0.081), (10, -0.112), (11, 0.06), (12, 0.028), (13, 0.024), (14, -0.046), (15, 0.022), (16, -0.054), (17, -0.012), (18, -0.021), (19, 0.044), (20, 0.003), (21, 0.02), (22, 0.02), (23, 0.021), (24, -0.0), (25, -0.069), (26, -0.017), (27, -0.042), (28, 0.042), (29, -0.145), (30, -0.012), (31, -0.021), (32, 0.02), (33, -0.08), (34, 0.039), (35, -0.037), (36, 0.053), (37, 0.038), (38, 0.018), (39, 0.082), (40, 0.035), (41, 0.029), (42, 0.028), (43, -0.064), (44, 0.004), (45, 0.01), (46, 0.018), (47, -0.026), (48, -0.003), (49, -0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96014631 <a title="187-lsi-1" href="./acl-2013-Identifying_Opinion_Subgroups_in_Arabic_Online_Discussions.html">187 acl-2013-Identifying Opinion Subgroups in Arabic Online Discussions</a></p>
<p>Author: Amjad Abu-Jbara ; Ben King ; Mona Diab ; Dragomir Radev</p><p>Abstract: In this paper, we use Arabic natural language processing techniques to analyze Arabic debates. The goal is to identify how the participants in a discussion split into subgroups with contrasting opinions. The members of each subgroup share the same opinion with respect to the discussion topic and an opposing opinion to the members of other subgroups. We use opinion mining techniques to identify opinion expressions and determine their polarities and their targets. We opinion predictions to represent the discussion in one of two formal representations: signed attitude network or a space of attitude vectors. We identify opinion subgroups by partitioning the signed network representation or by clustering the vector space representation. We evaluate the system using a data set of labeled discussions and show that it achieves good results.</p><p>2 0.80536669 <a title="187-lsi-2" href="./acl-2013-Mining_Opinion_Words_and_Opinion_Targets_in_a_Two-Stage_Framework.html">244 acl-2013-Mining Opinion Words and Opinion Targets in a Two-Stage Framework</a></p>
<p>Author: Liheng Xu ; Kang Liu ; Siwei Lai ; Yubo Chen ; Jun Zhao</p><p>Abstract: This paper proposes a novel two-stage method for mining opinion words and opinion targets. In the first stage, we propose a Sentiment Graph Walking algorithm, which naturally incorporates syntactic patterns in a Sentiment Graph to extract opinion word/target candidates. Then random walking is employed to estimate confidence of candidates, which improves extraction accuracy by considering confidence of patterns. In the second stage, we adopt a self-learning strategy to refine the results from the first stage, especially for filtering out high-frequency noise terms and capturing the long-tail terms, which are not investigated by previous methods. The experimental results on three real world datasets demonstrate the effectiveness of our approach compared with stateof-the-art unsupervised methods.</p><p>3 0.77961838 <a title="187-lsi-3" href="./acl-2013-An_annotated_corpus_of_quoted_opinions_in_news_articles.html">49 acl-2013-An annotated corpus of quoted opinions in news articles</a></p>
<p>Author: Tim O'Keefe ; James R. Curran ; Peter Ashwell ; Irena Koprinska</p><p>Abstract: Quotes are used in news articles as evidence of a person’s opinion, and thus are a useful target for opinion mining. However, labelling each quote with a polarity score directed at a textually-anchored target can ignore the broader issue that the speaker is commenting on. We address this by instead labelling quotes as supporting or opposing a clear expression of a point of view on a topic, called a position statement. Using this we construct a corpus covering 7 topics with 2,228 quotes.</p><p>4 0.77039868 <a title="187-lsi-4" href="./acl-2013-Joint_Inference_for_Fine-grained_Opinion_Extraction.html">207 acl-2013-Joint Inference for Fine-grained Opinion Extraction</a></p>
<p>Author: Bishan Yang ; Claire Cardie</p><p>Abstract: This paper addresses the task of finegrained opinion extraction the identification of opinion-related entities: the opinion expressions, the opinion holders, and the targets of the opinions, and the relations between opinion expressions and their targets and holders. Most existing approaches tackle the extraction of opinion entities and opinion relations in a pipelined manner, where the interdependencies among different extraction stages are not captured. We propose a joint inference model that leverages knowledge from predictors that optimize subtasks – of opinion extraction, and seeks a globally optimal solution. Experimental results demonstrate that our joint inference approach significantly outperforms traditional pipeline methods and baselines that tackle subtasks in isolation for the problem of opinion extraction.</p><p>5 0.7500093 <a title="187-lsi-5" href="./acl-2013-Syntactic_Patterns_versus_Word_Alignment%3A_Extracting_Opinion_Targets_from_Online_Reviews.html">336 acl-2013-Syntactic Patterns versus Word Alignment: Extracting Opinion Targets from Online Reviews</a></p>
<p>Author: Kang Liu ; Liheng Xu ; Jun Zhao</p><p>Abstract: Mining opinion targets is a fundamental and important task for opinion mining from online reviews. To this end, there are usually two kinds of methods: syntax based and alignment based methods. Syntax based methods usually exploited syntactic patterns to extract opinion targets, which were however prone to suffer from parsing errors when dealing with online informal texts. In contrast, alignment based methods used word alignment model to fulfill this task, which could avoid parsing errors without using parsing. However, there is no research focusing on which kind of method is more better when given a certain amount of reviews. To fill this gap, this paper empiri- cally studies how the performance of these two kinds of methods vary when changing the size, domain and language of the corpus. We further combine syntactic patterns with alignment model by using a partially supervised framework and investigate whether this combination is useful or not. In our experiments, we verify that our combination is effective on the corpus with small and medium size.</p><p>6 0.65226686 <a title="187-lsi-6" href="./acl-2013-Bi-directional_Inter-dependencies_of_Subjective_Expressions_and_Targets_and_their_Value_for_a_Joint_Model.html">67 acl-2013-Bi-directional Inter-dependencies of Subjective Expressions and Targets and their Value for a Joint Model</a></p>
<p>7 0.61519742 <a title="187-lsi-7" href="./acl-2013-LABR%3A_A_Large_Scale_Arabic_Book_Reviews_Dataset.html">211 acl-2013-LABR: A Large Scale Arabic Book Reviews Dataset</a></p>
<p>8 0.60259467 <a title="187-lsi-8" href="./acl-2013-Detecting_Turnarounds_in_Sentiment_Analysis%3A_Thwarting.html">117 acl-2013-Detecting Turnarounds in Sentiment Analysis: Thwarting</a></p>
<p>9 0.56526512 <a title="187-lsi-9" href="./acl-2013-Detecting_Chronic_Critics_Based_on_Sentiment_Polarity_and_User%C3%A2%E2%80%A2%C5%BDs_Behavior_in_Social_Media.html">114 acl-2013-Detecting Chronic Critics Based on Sentiment Polarity and Userâ•Žs Behavior in Social Media</a></p>
<p>10 0.49407837 <a title="187-lsi-10" href="./acl-2013-Extra-Linguistic_Constraints_on_Stance_Recognition_in_Ideological_Debates.html">151 acl-2013-Extra-Linguistic Constraints on Stance Recognition in Ideological Debates</a></p>
<p>11 0.48696271 <a title="187-lsi-11" href="./acl-2013-Exploiting_Topic_based_Twitter_Sentiment_for_Stock_Prediction.html">147 acl-2013-Exploiting Topic based Twitter Sentiment for Stock Prediction</a></p>
<p>12 0.48079532 <a title="187-lsi-12" href="./acl-2013-Sentiment_Relevance.html">318 acl-2013-Sentiment Relevance</a></p>
<p>13 0.46733218 <a title="187-lsi-13" href="./acl-2013-Utterance-Level_Multimodal_Sentiment_Analysis.html">379 acl-2013-Utterance-Level Multimodal Sentiment Analysis</a></p>
<p>14 0.45519382 <a title="187-lsi-14" href="./acl-2013-Identifying_Sentiment_Words_Using_an_Optimization-based_Model_without_Seed_Words.html">188 acl-2013-Identifying Sentiment Words Using an Optimization-based Model without Seed Words</a></p>
<p>15 0.4494825 <a title="187-lsi-15" href="./acl-2013-Discovering_User_Interactions_in_Ideological_Discussions.html">121 acl-2013-Discovering User Interactions in Ideological Discussions</a></p>
<p>16 0.4474788 <a title="187-lsi-16" href="./acl-2013-Exploring_Sentiment_in_Social_Media%3A_Bootstrapping_Subjectivity_Clues_from_Multilingual_Twitter_Streams.html">148 acl-2013-Exploring Sentiment in Social Media: Bootstrapping Subjectivity Clues from Multilingual Twitter Streams</a></p>
<p>17 0.43592867 <a title="187-lsi-17" href="./acl-2013-Sentence_Level_Dialect_Identification_in_Arabic.html">317 acl-2013-Sentence Level Dialect Identification in Arabic</a></p>
<p>18 0.42277128 <a title="187-lsi-18" href="./acl-2013-Character-to-Character_Sentiment_Analysis_in_Shakespeare%27s_Plays.html">79 acl-2013-Character-to-Character Sentiment Analysis in Shakespeare's Plays</a></p>
<p>19 0.42243043 <a title="187-lsi-19" href="./acl-2013-Public_Dialogue%3A_Analysis_of_Tolerance_in_Online_Discussions.html">287 acl-2013-Public Dialogue: Analysis of Tolerance in Online Discussions</a></p>
<p>20 0.39580429 <a title="187-lsi-20" href="./acl-2013-Linguistic_Models_for_Analyzing_and_Detecting_Biased_Language.html">232 acl-2013-Linguistic Models for Analyzing and Detecting Biased Language</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.056), (4, 0.018), (6, 0.018), (11, 0.04), (13, 0.018), (15, 0.052), (24, 0.068), (26, 0.071), (31, 0.012), (35, 0.069), (42, 0.041), (48, 0.048), (63, 0.029), (70, 0.041), (86, 0.167), (88, 0.051), (90, 0.018), (95, 0.102)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.85016096 <a title="187-lda-1" href="./acl-2013-Identifying_Opinion_Subgroups_in_Arabic_Online_Discussions.html">187 acl-2013-Identifying Opinion Subgroups in Arabic Online Discussions</a></p>
<p>Author: Amjad Abu-Jbara ; Ben King ; Mona Diab ; Dragomir Radev</p><p>Abstract: In this paper, we use Arabic natural language processing techniques to analyze Arabic debates. The goal is to identify how the participants in a discussion split into subgroups with contrasting opinions. The members of each subgroup share the same opinion with respect to the discussion topic and an opposing opinion to the members of other subgroups. We use opinion mining techniques to identify opinion expressions and determine their polarities and their targets. We opinion predictions to represent the discussion in one of two formal representations: signed attitude network or a space of attitude vectors. We identify opinion subgroups by partitioning the signed network representation or by clustering the vector space representation. We evaluate the system using a data set of labeled discussions and show that it achieves good results.</p><p>2 0.80714476 <a title="187-lda-2" href="./acl-2013-Towards_Robust_Abstractive_Multi-Document_Summarization%3A_A_Caseframe_Analysis_of_Centrality_and_Domain.html">353 acl-2013-Towards Robust Abstractive Multi-Document Summarization: A Caseframe Analysis of Centrality and Domain</a></p>
<p>Author: Jackie Chi Kit Cheung ; Gerald Penn</p><p>Abstract: In automatic summarization, centrality is the notion that a summary should contain the core parts of the source text. Current systems use centrality, along with redundancy avoidance and some sentence compression, to produce mostly extractive summaries. In this paper, we investigate how summarization can advance past this paradigm towards robust abstraction by making greater use of the domain of the source text. We conduct a series of studies comparing human-written model summaries to system summaries at the semantic level of caseframes. We show that model summaries (1) are more abstractive and make use of more sentence aggregation, (2) do not contain as many topical caseframes as system summaries, and (3) cannot be reconstructed solely from the source text, but can be if texts from in-domain documents are added. These results suggest that substantial improvements are unlikely to result from better optimizing centrality-based criteria, but rather more domain knowledge is needed.</p><p>3 0.76927555 <a title="187-lda-3" href="./acl-2013-Co-regularizing_character-based_and_word-based_models_for_semi-supervised_Chinese_word_segmentation.html">82 acl-2013-Co-regularizing character-based and word-based models for semi-supervised Chinese word segmentation</a></p>
<p>Author: Xiaodong Zeng ; Derek F. Wong ; Lidia S. Chao ; Isabel Trancoso</p><p>Abstract: This paper presents a semi-supervised Chinese word segmentation (CWS) approach that co-regularizes character-based and word-based models. Similarly to multi-view learning, the “segmentation agreements” between the two different types of view are used to overcome the scarcity of the label information on unlabeled data. The proposed approach trains a character-based and word-based model on labeled data, respectively, as the initial models. Then, the two models are constantly updated using unlabeled examples, where the learning objective is maximizing their segmentation agreements. The agreements are regarded as a set of valuable constraints for regularizing the learning of both models on unlabeled data. The segmentation for an input sentence is decoded by using a joint scoring function combining the two induced models. The evaluation on the Chinese tree bank reveals that our model results in better gains over the state-of-the-art semi-supervised models reported in the literature.</p><p>4 0.73350048 <a title="187-lda-4" href="./acl-2013-Linking_Tweets_to_News%3A_A_Framework_to_Enrich_Short_Text_Data_in_Social_Media.html">233 acl-2013-Linking Tweets to News: A Framework to Enrich Short Text Data in Social Media</a></p>
<p>Author: Weiwei Guo ; Hao Li ; Heng Ji ; Mona Diab</p><p>Abstract: Many current Natural Language Processing [NLP] techniques work well assuming a large context of text as input data. However they become ineffective when applied to short texts such as Twitter feeds. To overcome the issue, we want to find a related newswire document to a given tweet to provide contextual support for NLP tasks. This requires robust modeling and understanding of the semantics of short texts. The contribution of the paper is two-fold: 1. we introduce the Linking-Tweets-toNews task as well as a dataset of linked tweet-news pairs, which can benefit many NLP applications; 2. in contrast to previ- ous research which focuses on lexical features within the short texts (text-to-word information), we propose a graph based latent variable model that models the inter short text correlations (text-to-text information). This is motivated by the observation that a tweet usually only covers one aspect of an event. We show that using tweet specific feature (hashtag) and news specific feature (named entities) as well as temporal constraints, we are able to extract text-to-text correlations, and thus completes the semantic picture of a short text. Our experiments show significant improvement of our new model over baselines with three evaluation metrics in the new task.</p><p>5 0.72806281 <a title="187-lda-5" href="./acl-2013-LABR%3A_A_Large_Scale_Arabic_Book_Reviews_Dataset.html">211 acl-2013-LABR: A Large Scale Arabic Book Reviews Dataset</a></p>
<p>Author: Mohamed Aly ; Amir Atiya</p><p>Abstract: We introduce LABR, the largest sentiment analysis dataset to-date for the Arabic language. It consists of over 63,000 book reviews, each rated on a scale of 1 to 5 stars. We investigate the properties of the the dataset, and present its statistics. We explore using the dataset for two tasks: sentiment polarity classification and rating classification. We provide standard splits of the dataset into training and testing, for both polarity and rating classification, in both balanced and unbalanced settings. We run baseline experiments on the dataset to establish a benchmark.</p><p>6 0.7237466 <a title="187-lda-6" href="./acl-2013-A_Bayesian_Model_for_Joint_Unsupervised_Induction_of_Sentiment%2C_Aspect_and_Discourse_Representations.html">2 acl-2013-A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations</a></p>
<p>7 0.72028506 <a title="187-lda-7" href="./acl-2013-Detecting_Turnarounds_in_Sentiment_Analysis%3A_Thwarting.html">117 acl-2013-Detecting Turnarounds in Sentiment Analysis: Thwarting</a></p>
<p>8 0.71662349 <a title="187-lda-8" href="./acl-2013-Sentiment_Relevance.html">318 acl-2013-Sentiment Relevance</a></p>
<p>9 0.71552896 <a title="187-lda-9" href="./acl-2013-An_Information_Theoretic_Approach_to_Bilingual_Word_Clustering.html">47 acl-2013-An Information Theoretic Approach to Bilingual Word Clustering</a></p>
<p>10 0.7155171 <a title="187-lda-10" href="./acl-2013-PARMA%3A_A_Predicate_Argument_Aligner.html">267 acl-2013-PARMA: A Predicate Argument Aligner</a></p>
<p>11 0.71417165 <a title="187-lda-11" href="./acl-2013-SenseSpotting%3A_Never_let_your_parallel_data_tie_you_to_an_old_domain.html">316 acl-2013-SenseSpotting: Never let your parallel data tie you to an old domain</a></p>
<p>12 0.71277916 <a title="187-lda-12" href="./acl-2013-Explicit_and_Implicit_Syntactic_Features_for_Text_Classification.html">144 acl-2013-Explicit and Implicit Syntactic Features for Text Classification</a></p>
<p>13 0.71176815 <a title="187-lda-13" href="./acl-2013-Using_Conceptual_Class_Attributes_to_Characterize_Social_Media_Users.html">373 acl-2013-Using Conceptual Class Attributes to Characterize Social Media Users</a></p>
<p>14 0.71051186 <a title="187-lda-14" href="./acl-2013-Cross-lingual_Projections_between_Languages_from_Different_Families.html">97 acl-2013-Cross-lingual Projections between Languages from Different Families</a></p>
<p>15 0.70930606 <a title="187-lda-15" href="./acl-2013-Evaluating_Text_Segmentation_using_Boundary_Edit_Distance.html">140 acl-2013-Evaluating Text Segmentation using Boundary Edit Distance</a></p>
<p>16 0.70804006 <a title="187-lda-16" href="./acl-2013-Offspring_from_Reproduction_Problems%3A_What_Replication_Failure_Teaches_Us.html">262 acl-2013-Offspring from Reproduction Problems: What Replication Failure Teaches Us</a></p>
<p>17 0.70671684 <a title="187-lda-17" href="./acl-2013-Crawling_microblogging_services_to_gather_language-classified_URLs._Workflow_and_case_study.html">95 acl-2013-Crawling microblogging services to gather language-classified URLs. Workflow and case study</a></p>
<p>18 0.7052204 <a title="187-lda-18" href="./acl-2013-Dual_Training_and_Dual_Prediction_for_Polarity_Classification.html">131 acl-2013-Dual Training and Dual Prediction for Polarity Classification</a></p>
<p>19 0.70490563 <a title="187-lda-19" href="./acl-2013-Re-embedding_words.html">294 acl-2013-Re-embedding words</a></p>
<p>20 0.70449322 <a title="187-lda-20" href="./acl-2013-Joint_Inference_for_Fine-grained_Opinion_Extraction.html">207 acl-2013-Joint Inference for Fine-grained Opinion Extraction</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
