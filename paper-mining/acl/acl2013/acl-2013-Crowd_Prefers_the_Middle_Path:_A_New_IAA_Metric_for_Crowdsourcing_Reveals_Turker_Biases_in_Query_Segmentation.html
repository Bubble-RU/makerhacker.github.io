<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>99 acl-2013-Crowd Prefers the Middle Path: A New IAA Metric for Crowdsourcing Reveals Turker Biases in Query Segmentation</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-99" href="#">acl2013-99</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>99 acl-2013-Crowd Prefers the Middle Path: A New IAA Metric for Crowdsourcing Reveals Turker Biases in Query Segmentation</h1>
<br/><p>Source: <a title="acl-2013-99-pdf" href="http://aclweb.org/anthology//P/P13/P13-1168.pdf">pdf</a></p><p>Author: Rohan Ramanath ; Monojit Choudhury ; Kalika Bali ; Rishiraj Saha Roy</p><p>Abstract: Query segmentation, like text chunking, is the first step towards query understanding. In this study, we explore the effectiveness of crowdsourcing for this task. Through carefully designed control experiments and Inter Annotator Agreement metrics for analysis of experimental data, we show that crowdsourcing may not be a suitable approach for query segmentation because the crowd seems to have a very strong bias towards dividing the query into roughly equal (often only two) parts. Similarly, in the case of hierarchical or nested segmentation, turkers have a strong preference towards balanced binary trees.</p><p>Reference: <a title="acl-2013-99-reference" href="../acl2013_reference/acl-2013-Crowd_Prefers_the_Middle_Path%3A_A_New_IAA_Metric_for_Crowdsourcing_Reveals_Turker_Biases_in_Query_Segmentation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Similarly, in the case of hierarchical or nested segmentation, turkers have a strong preference towards balanced binary trees. [sent-8, score-0.572]
</p><p>2 In the context of Web search queries, query segmentation is similarly the first step towards analysis and understanding of queries (Hagen et al. [sent-10, score-0.838]
</p><p>3 The task in both the cases is to divide the sentence or the query into contiguous segments or chunks of words such that the words from a segment are related to each other more strongly than words from different segments (Bendersky et al. [sent-12, score-0.529]
</p><p>4 A majority of work on query segmentation relies on manually segmented queries by human experts for training and evaluation of segmentation algorithms. [sent-27, score-1.228]
</p><p>5 For instance, Table 1 illustrates the variation in flat segmentation by 10 annotators. [sent-29, score-0.749]
</p><p>6 This confusion is mainly because the definition of a segment in a query is ambiguous and of an unspecified granularity. [sent-30, score-0.305]
</p><p>7 Although there is little work on the use of crowdsourcing for query segmentation (Hagen et al. [sent-32, score-0.721]
</p><p>8 Ac s2s0o1ci3a Atiosnso fcoirat Cio nm foprut Caotimonpaulta Lti nognuails Lti cnsg,u piasgteics 1713–172 , crowd could be a potential (and cheaper) source for reliable segmentation seems a reasonable assumption. [sent-36, score-0.435]
</p><p>9 In this paper we explore crowdsourcing as an option for query segmentation through experiments designed using Amazon Mechanical Turk (AMT)1 . [sent-39, score-0.721]
</p><p>10 Thus, it is necessary to compare query segmentation to the ¨u ber-structure of NL sentences as well as the unter-structure of random n-grams. [sent-44, score-0.637]
</p><p>11 To quantify the effect of granularity on segmentation, we also ask annotators to provide hierarchical or nested segmentations for real and random queries, as well as sentences. [sent-46, score-0.673]
</p><p>12 As a part of our analysis framework, we introduce a new IAA metric for comparison across flat and nested segmentations. [sent-54, score-0.829]
</p><p>13 In Sec 4, we introduce a new metric for IAA, that could be uniformly applied across flat and nested segmentations. [sent-62, score-0.829]
</p><p>14 2  Related Work  Query segmentation was introduced by Risvik et. [sent-67, score-0.363]
</p><p>15 Most of the research and evaluation considers query segmentation as a process analogous to identification of phrases within a query which when put within double-quotes (implying exact matching of the quoted phrase in the document) leads to better IR performance. [sent-73, score-0.853]
</p><p>16 Most automatic segmentation techniques (Bergsma and Wang, 2007; Tan and Peng, 2008; Zhang et al. [sent-78, score-0.363]
</p><p>17 However, in their approach the crowd is provided with a few (four) possible segmentations of a query to choose from (known through a personal communication with a authors). [sent-91, score-0.385]
</p><p>18 Thus, it presupposes an automatic process that can generate the correct segmentation of a query within top few options. [sent-92, score-0.608]
</p><p>19 An ideal segmentation should be based on the annotators’ own interpretation of the query. [sent-95, score-0.363]
</p><p>20 In the context of NL text, segmentation has been traditionally referred to as chunking and is a well-studied problem. [sent-99, score-0.426]
</p><p>21 One important implication of this is that annotators are expected to agree more on the higher level boundaries for nested segmentation than the lower ones. [sent-104, score-0.976]
</p><p>22 We note that hierarchical query segmentation was proposed for the first time by Huang et al. [sent-105, score-0.608]
</p><p>23 3  Experiments  The annotation experiments have been designed to systematically study the various aspects of query segmentation. [sent-109, score-0.304]
</p><p>24 In order to verify the effectiveness and reliability of crowdsourcing, we designed an AMT experiment for flat segmentation of Web search queries. [sent-110, score-0.776]
</p><p>25 Since we believe that the issue of granularity could be the prime reason for previously reported low IAA for segmentation, we also designed AMT-based nested segmentation experiments for the same set of queries, and obtained the corresponding gold annotations. [sent-113, score-0.843]
</p><p>26 Finally, to estimate the role of ambiguity inherent in the structure of Web search queries on IAA,  we conducted two more control experiments, both through crowdsourcing. [sent-114, score-0.299]
</p><p>27 First, flat and nested segmentation of well-formed English, i. [sent-115, score-1.15]
</p><p>28 , NL sentences of similar length distribution; and second, flat and nested segmentation of randomly generated queries. [sent-117, score-1.15]
</p><p>29 On the other hand high or comparable IAA for random queries would mean that annotations have strong biases. [sent-119, score-0.398]
</p><p>30 Furthermore, for generating the random queries, we  will use search query logs to learn n-gram models. [sent-123, score-0.274]
</p><p>31 (2012) released a dataset of 500 queries, 5 to 8 words long, for evaluation of various segmentation algorithms. [sent-125, score-0.363]
</p><p>32 This dataset has flat segmentations from three annotators obtained under controlled experimental settings, and can be considered as Gold annota1715  Figure 2: Length distribution of datasets. [sent-126, score-0.579]
</p><p>33 We procured the corresponding nested segmentation for these queries from two human experts, who are regular search engine users, between 20 and 30 years old, and familiar with various linguistic annotation tasks. [sent-129, score-1.098]
</p><p>34 We shall refer to the set of flat and nested gold annotations as QG500, whereas Q500 will be reserved for AMT experiments. [sent-132, score-0.98]
</p><p>35 Q700: Since 500 queries may not be enough for reliable conclusion and since the queries may not have been chosen specifically for the purpose of annotation experiments, we expanded the set with another 700 queries sampled from a slice of the query logs of Bing Australia4 containing 16. [sent-133, score-1.022]
</p><p>36 We picked, uniformly at random, queries that are 4 to 8 words long, have only English letters and numerals, and a high click entropy because “a query with a larger click entropy value is more likely to be an informational or ambiguous query” (Dou et al. [sent-135, score-0.475]
</p><p>37 QRand: Instead of generating search queries by throwing in words randomly, we thought it will be more interesting to explore annotation of  books5  4http : //www . [sent-141, score-0.289]
</p><p>38 Two separate AMT Human Intelligence Tasks (HITs) were designed for flat and nested query segmentation. [sent-160, score-1.032]
</p><p>39 The concept of flat and nested segmentation was introduced to the Turkers with the help of ex-  amples presented in two short videos6. [sent-163, score-1.15]
</p><p>40 Note that we intentionally kept definitions of flat and nested segmentation fuzzy because (a) it would require very long instruction manuals to cover all possible cases and (b) Turkers do not tend to read verbose and complex instructions. [sent-165, score-1.184]
</p><p>41 Therefore, before we can venture into analysis of the experimental data, we need to formalize the notion of IAA for flat and nested queries. [sent-176, score-0.787]
</p><p>42 For instance, we observed that a total of 128 turkers have provided the flat annotations for Q700, when we had only asked for 10 annotations per query. [sent-180, score-0.716]
</p><p>43 Second, most of the standard annotation metrics do not generalize for flat segmentation and trees. [sent-185, score-0.841]
</p><p>44 Therefore, it is far from obvious how to compare chunking or segmentation that covers the whole text or that might have overlapping units as in the case of nested segmentation. [sent-188, score-0.827]
</p><p>45 Furthermore, we would like to compare the reliability of flat and nested segmentation, and therefore, ideally we would like to have an IAA metric that can be meaningfully applied to both of these cases. [sent-189, score-0.856]
</p><p>46 To be consistent with prior work, we will stick to the notation used in Artstein and Poesio (2008) and redefine the  in the context of flat and nested segmentation. [sent-191, score-0.787]
</p><p>47 A flat or nested segmentation of q, represented by qj, j varying from 1 to total number of annotations c, is a particular instantiation of these boundary variables as described below. [sent-203, score-1.356]
</p><p>48 A flat segmentation, qj can be uniquely defined by a binary assignment of the boundary variables bj,i, where bj,i = 1iff wi and wi+1 belong to two different flat segments. [sent-205, score-0.928]
</p><p>49 A nested segmentation qj can also −  be uniquely defined by assigning non-negative integers to the boundary variables such that bj,i = 0 iff words wi and wi+1 form an atomic segment (i. [sent-209, score-0.98]
</p><p>50 This numbering scheme for nested segmentation can be understood through Fig. [sent-212, score-0.764]
</p><p>51 Every internal node of the binary tree corresponding to the nested segmentation is numbered according to its height. [sent-214, score-0.764]
</p><p>52 The number of unique nested segmentations of a query of length |q| is its corresponding Cataloafn a an quumerbyer o7f. [sent-218, score-0.742]
</p><p>53 Boundary variables for flat and nested segmentation are illustrated with an example of each kind in Tables 1 and 2 (last column). [sent-219, score-1.15]
</p><p>54 Moreover, it allows for different magnitudes of disagreement, which is a useful feature as we might want to differentially penalize disagreements at various levels of the tree for nested segmentation. [sent-224, score-0.446]
</p><p>55 565-566 of Artstein and Poesio (2008) for measuring these quantities for queries: –  s2within=2qc(c1 − 1)qX∈QmX=c1Xnc=1d(qm,qn) st2otal=2qc(q1c − 1)qX∈QmX=c1qX′∈QnX=c1d(qm,qn′)  (2)  (3) where, d(qm, qn′) is a distance metric for the agreement between annotations qm and qn′. [sent-227, score-0.315]
</p><p>56 We define two different distance metrics d1 and d2 that are applicable to flat and nested segmentation. [sent-228, score-0.82]
</p><p>57 We shall first define these metrics for comparing queries with equal length (i. [sent-229, score-0.344]
</p><p>58 d2 might be a desirable metric for nested segmentation, because research on sentence chunking shows that annotators agree more on clause or major phrase boundaries, even though they may not always agree on intra-clausal or intra-phrasal boundaries (Bali et al. [sent-232, score-0.717]
</p><p>59 Note that for flat segmentation, d1 and d2 are identical, and hence we will denote them as d. [sent-234, score-0.386]
</p><p>60 For flat segmentation, it boils down to the fact that all the annotations are equally likely, which is equivalent to the assumption that any boundary variable bi has 0. [sent-243, score-0.592]
</p><p>61 Analytical computation of the expected probability distributions of d1(qm, qn) and d2 (qm, qn) is harder for nested segmentation. [sent-246, score-0.437]
</p><p>62 Let us denote this expected cumulative probability distribution for flat segmentation  2|q|−1  as Pd(x; |q|) = the probability that for a pair of randomly )ch =ose thne fl parto segmentations oorf q, qm and qn, d(qm, qn) ≥ x. [sent-248, score-0.975]
</p><p>63 Likewise, let Pd1 (x; |q|) and Pd2 (x; |q| ) be) t ≥he respective probabilities t|hq|a)t for any two n|)e sbteed th segmentations qm ialnidti qn oaft q, the following holds: d1(qm, qn) ≥ x and d2(qm, qn) ≥ x. [sent-249, score-0.288]
</p><p>64 also note that a high value of S and low value of α indicate that though the annotators agree on the judgment of individual items, they also tend to agree on judgments of two different items, which in turn, could be due to strong annotator biases or due to lack of variability of the dataset. [sent-297, score-0.35]
</p><p>65 5  Results  Table 4 reports the values of α and S for flat and nested segmentation on the various datasets. [sent-300, score-1.15]
</p><p>66 For nested segmentation, the values were computed for two different distance metrics d1 and d2. [sent-301, score-0.434]
</p><p>67 As expected, the highest value of α for both flat and nested segmentation is observed for gold annotations. [sent-302, score-1.179]
</p><p>68 Higher α for nested segmentation QG500 than flat further validates our initial postulate that nested segmentation may reduce disagreement from granularity issues inherent in the definition of flat segmentation. [sent-305, score-2.389]
</p><p>69 Opposite trends are observed for Q700, Q500 and S300, where α for flat is the highest, followed by that for nested using d1, and then d2. [sent-306, score-0.787]
</p><p>70 Moreover, except for flat segmentation of sentences, α lies between 0. [sent-307, score-0.749]
</p><p>71 This clearly shows that segmentation, either flat or nested, cannot be reliably procured through  crowdsourcing. [sent-310, score-0.431]
</p><p>72 However, nearly equal IAA for sentences and queries implies that low agreement may not be an outcome of inherent ambiguity in the structure of queries. [sent-312, score-0.395]
</p><p>73 Slightly higher α for flat segmentation and a much higher α for nested segmentation of QRand reinforce the fact that low IAA is not due to a lack of structure in queries. [sent-313, score-1.513]
</p><p>74 It is interesting to note that α for nested segmentation of S300 and all segmentations of QRand are low or medium despite the fact that S is very high in all these cases. [sent-314, score-0.86]
</p><p>75 6  Biases in Annotation  The IAA statistics clearly show that there are certain strong biases in both flat and nested query segmentation, especially those obtained through crowdsourcing. [sent-321, score-1.183]
</p><p>76 Bias 1: During flat segmentation, annotators prefer dividing the query into two segments of roughly equal length. [sent-324, score-0.897]
</p><p>77 As discussed earlier, one of the major problems of flat segmentation is the fuzziness in granularity. [sent-325, score-0.786]
</p><p>78 In our experiments, we intentionally left the decision of whether to go for fine or coarse-grained segmentation to the annotator. [sent-326, score-0.363]
</p><p>79 However, it is surprising to observe that annotators typically divide the query into two segments (see Fig. [sent-327, score-0.454]
</p><p>80 This bias is observed across queries, sentences and random queries, where the percent-  age of annotations with 2 or 3 segments are greater than 83%, 91% and 96% respectively. [sent-329, score-0.338]
</p><p>81 5 and 1 (for perspective, consider a query 1719  Figure 3: Analysis of annotation biases: A1, A2 number of segments per flat segmentation vs. [sent-335, score-1.165]
</p><p>82 length; B 1, B2 standard deviation of segment length for flat segmentation; C1, C2 distribution of the tree –  –  –  heights in nested segmentation. [sent-336, score-0.893]
</p><p>83 It is likely that due to this bias, the S or observed agreement is moderately high for queries and very high for sentences, but then it also leads to high agreement across different queries and sentences (i. [sent-365, score-0.592]
</p><p>84 Bias 2: During nested segmentation, annotators prefer balanced binary trees. [sent-368, score-0.566]
</p><p>85 Quite analogous to bias 1, for nested segmentation we observe that annotators tend to prefer more balanced binary trees. [sent-369, score-1.013]
</p><p>86 3 plots C1 and C2 show the distribution ofthe tree heights for various cases and Table 5 reports the corresponding average height of the trees for queries and sentences of various lengths and the the expected value of the height if all trees were equally likely. [sent-371, score-0.443]
</p><p>87 Thus, the crowd seems to choose the middle path, avoiding extremes and hence may not be a –  reliable source of annotation for query segmentation. [sent-373, score-0.376]
</p><p>88 It can be argued that similar biases are also observed for gold annotations, and therefore, probably it is the inherent structure of the queries and sentences that lead to such biased distribution of segmentation patterns. [sent-374, score-0.786]
</p><p>89 However, note that α for QG500 is much higher than all other cases, which shows that the true agreement between gold annotators is immune to such biases or skewed distributions in the datasets. [sent-375, score-0.317]
</p><p>90 Furthermore, high values of α for QRand despite the very strong biases in annotation shows that there perhaps is very little choice that the annotators have while segmenting randomly generated queries. [sent-376, score-0.307]
</p><p>91 On the other hand, the textual coherence of the real queries and sentences provide many different choices for segmentation and the Turker typically gets carried away by these biases, leading to low α. [sent-377, score-0.593]
</p><p>92 Bias 3: Phrase structure drives segmentation only when reconcilable with Bias 1. [sent-378, score-0.363]
</p><p>93 Whenever the sentence or query has a verb phrase (VP) spanning roughly half of it, annotators seem to chunk be-  fore the VP as one would expect, quite as often as just after the verb, which is quite unexpected. [sent-379, score-0.342]
</p><p>94 gathers as many as eight flat annotations with a boundary between sarcasm and ruffled, and four with a boundary between ruffled and her. [sent-381, score-0.715]
</p><p>95 Bias 4: Prepositions influence segment boundaries differently for queries and sentences. [sent-409, score-0.334]
</p><p>96 We automatically labeled all the prepositions in the flat annotations and classified them according to the criterion of whether a boundary was placed immediately before or after it, or on both sides or neither side. [sent-410, score-0.592]
</p><p>97 Bias 3 and 4 present the complex interpretation of the structure of queries by the annotators which could be due to some emerging cognitive model of queries among the search engine users. [sent-419, score-0.557]
</p><p>98 7  Conclusion  We have studied various aspects of query segmentation through crowdsourcing by designing and conducting suitable experiments. [sent-421, score-0.721]
</p><p>99 One of the important contributions of this work is the formulation of a new IAA metric for comparing across flat and nested segmentations, especially for crowdsourcing based annotations. [sent-423, score-0.942]
</p><p>100 Since large scale data for query segmentation is very useful, it would be interesting to see if the problem can be rephrased to the Turkers in a way so as to obtain more reliable judgments. [sent-426, score-0.636]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('nested', 0.401), ('flat', 0.386), ('segmentation', 0.363), ('iaa', 0.292), ('query', 0.245), ('queries', 0.23), ('biases', 0.125), ('crowdsourcing', 0.113), ('annotations', 0.113), ('segments', 0.112), ('sec', 0.109), ('qrand', 0.104), ('turkers', 0.104), ('qn', 0.098), ('annotators', 0.097), ('segmentations', 0.096), ('qm', 0.094), ('boundary', 0.093), ('bias', 0.084), ('india', 0.08), ('turker', 0.079), ('hagen', 0.077), ('saha', 0.075), ('nl', 0.072), ('agreement', 0.066), ('chunking', 0.063), ('segment', 0.06), ('annotation', 0.059), ('abney', 0.057), ('course', 0.055), ('amt', 0.055), ('height', 0.052), ('aid', 0.051), ('shall', 0.051), ('granularity', 0.05), ('bali', 0.046), ('heights', 0.046), ('procured', 0.045), ('qmx', 0.045), ('disagreements', 0.045), ('artstein', 0.045), ('boundaries', 0.044), ('krippendorff', 0.044), ('crowd', 0.044), ('microsoft', 0.043), ('metric', 0.042), ('roy', 0.042), ('balanced', 0.041), ('inherent', 0.039), ('bangalore', 0.037), ('fuzziness', 0.037), ('monojit', 0.037), ('kharagpur', 0.037), ('sd', 0.036), ('expected', 0.036), ('agree', 0.035), ('wi', 0.034), ('instruction', 0.034), ('crowdsourced', 0.034), ('inter', 0.033), ('metrics', 0.033), ('annotator', 0.032), ('poesio', 0.031), ('choudhury', 0.03), ('versatile', 0.03), ('ambiguity', 0.03), ('aaiidd', 0.03), ('brenes', 0.03), ('erupted', 0.03), ('ffiirrsstt', 0.03), ('kalika', 0.03), ('kuansan', 0.03), ('lefti', 0.03), ('righti', 0.03), ('rishiraj', 0.03), ('risvik', 0.03), ('ruffled', 0.03), ('xiq', 0.03), ('youtu', 0.03), ('equal', 0.03), ('gold', 0.029), ('random', 0.029), ('qj', 0.029), ('appropriately', 0.028), ('chance', 0.028), ('reliable', 0.028), ('datasets', 0.027), ('implying', 0.027), ('hits', 0.027), ('prefer', 0.027), ('experts', 0.027), ('reliability', 0.027), ('plots', 0.027), ('bendersky', 0.026), ('carvalho', 0.026), ('misleadingly', 0.026), ('qx', 0.026), ('strong', 0.026), ('bergsma', 0.026), ('lab', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999774 <a title="99-tfidf-1" href="./acl-2013-Crowd_Prefers_the_Middle_Path%3A_A_New_IAA_Metric_for_Crowdsourcing_Reveals_Turker_Biases_in_Query_Segmentation.html">99 acl-2013-Crowd Prefers the Middle Path: A New IAA Metric for Crowdsourcing Reveals Turker Biases in Query Segmentation</a></p>
<p>Author: Rohan Ramanath ; Monojit Choudhury ; Kalika Bali ; Rishiraj Saha Roy</p><p>Abstract: Query segmentation, like text chunking, is the first step towards query understanding. In this study, we explore the effectiveness of crowdsourcing for this task. Through carefully designed control experiments and Inter Annotator Agreement metrics for analysis of experimental data, we show that crowdsourcing may not be a suitable approach for query segmentation because the crowd seems to have a very strong bias towards dividing the query into roughly equal (often only two) parts. Similarly, in the case of hierarchical or nested segmentation, turkers have a strong preference towards balanced binary trees.</p><p>2 0.23080739 <a title="99-tfidf-2" href="./acl-2013-Discriminative_Learning_with_Natural_Annotations%3A_Word_Segmentation_as_a_Case_Study.html">123 acl-2013-Discriminative Learning with Natural Annotations: Word Segmentation as a Case Study</a></p>
<p>Author: Wenbin Jiang ; Meng Sun ; Yajuan Lu ; Yating Yang ; Qun Liu</p><p>Abstract: Structural information in web text provides natural annotations for NLP problems such as word segmentation and parsing. In this paper we propose a discriminative learning algorithm to take advantage of the linguistic knowledge in large amounts of natural annotations on the Internet. It utilizes the Internet as an external corpus with massive (although slight and sparse) natural annotations, and enables a classifier to evolve on the large-scaled and real-time updated web text. With Chinese word segmentation as a case study, experiments show that the segmenter enhanced with the Chinese wikipedia achieves sig- nificant improvement on a series of testing sets from different domains, even with a single classifier and local features.</p><p>3 0.22587396 <a title="99-tfidf-3" href="./acl-2013-Evaluating_Text_Segmentation_using_Boundary_Edit_Distance.html">140 acl-2013-Evaluating Text Segmentation using Boundary Edit Distance</a></p>
<p>Author: Chris Fournier</p><p>Abstract: This work proposes a new segmentation evaluation metric, named boundary similarity (B), an inter-coder agreement coefficient adaptation, and a confusion-matrix for segmentation that are all based upon an adaptation of the boundary edit distance in Fournier and Inkpen (2012). Existing segmentation metrics such as Pk, WindowDiff, and Segmentation Similarity (S) are all able to award partial credit for near misses between boundaries, but are biased towards segmentations containing few or tightly clustered boundaries. Despite S’s improvements, its normalization also produces cosmetically high values that overestimate agreement & performance, leading this work to propose a solution.</p><p>4 0.21458024 <a title="99-tfidf-4" href="./acl-2013-Chinese_Parsing_Exploiting_Characters.html">80 acl-2013-Chinese Parsing Exploiting Characters</a></p>
<p>Author: Meishan Zhang ; Yue Zhang ; Wanxiang Che ; Ting Liu</p><p>Abstract: Characters play an important role in the Chinese language, yet computational processing of Chinese has been dominated by word-based approaches, with leaves in syntax trees being words. We investigate Chinese parsing from the character-level, extending the notion of phrase-structure trees by annotating internal structures of words. We demonstrate the importance of character-level information to Chinese processing by building a joint segmentation, part-of-speech (POS) tagging and phrase-structure parsing system that integrates character-structure features. Our joint system significantly outperforms a state-of-the-art word-based baseline on the standard CTB5 test, and gives the best published results for Chinese parsing.</p><p>5 0.18102035 <a title="99-tfidf-5" href="./acl-2013-Co-regularizing_character-based_and_word-based_models_for_semi-supervised_Chinese_word_segmentation.html">82 acl-2013-Co-regularizing character-based and word-based models for semi-supervised Chinese word segmentation</a></p>
<p>Author: Xiaodong Zeng ; Derek F. Wong ; Lidia S. Chao ; Isabel Trancoso</p><p>Abstract: This paper presents a semi-supervised Chinese word segmentation (CWS) approach that co-regularizes character-based and word-based models. Similarly to multi-view learning, the “segmentation agreements” between the two different types of view are used to overcome the scarcity of the label information on unlabeled data. The proposed approach trains a character-based and word-based model on labeled data, respectively, as the initial models. Then, the two models are constantly updated using unlabeled examples, where the learning objective is maximizing their segmentation agreements. The agreements are regarded as a set of valuable constraints for regularizing the learning of both models on unlabeled data. The segmentation for an input sentence is decoded by using a joint scoring function combining the two induced models. The evaluation on the Chinese tree bank reveals that our model results in better gains over the state-of-the-art semi-supervised models reported in the literature.</p><p>6 0.14054574 <a title="99-tfidf-6" href="./acl-2013-Improving_Chinese_Word_Segmentation_on_Micro-blog_Using_Rich_Punctuations.html">193 acl-2013-Improving Chinese Word Segmentation on Micro-blog Using Rich Punctuations</a></p>
<p>7 0.13242862 <a title="99-tfidf-7" href="./acl-2013-A_Lattice-based_Framework_for_Joint_Chinese_Word_Segmentation%2C_POS_Tagging_and_Parsing.html">7 acl-2013-A Lattice-based Framework for Joint Chinese Word Segmentation, POS Tagging and Parsing</a></p>
<p>8 0.12081292 <a title="99-tfidf-8" href="./acl-2013-Paraphrasing_Adaptation_for_Web_Search_Ranking.html">273 acl-2013-Paraphrasing Adaptation for Web Search Ranking</a></p>
<p>9 0.11530823 <a title="99-tfidf-9" href="./acl-2013-ICARUS_-_An_Extensible_Graphical_Search_Tool_for_Dependency_Treebanks.html">183 acl-2013-ICARUS - An Extensible Graphical Search Tool for Dependency Treebanks</a></p>
<p>10 0.11154652 <a title="99-tfidf-10" href="./acl-2013-Graph-based_Semi-Supervised_Model_for_Joint_Chinese_Word_Segmentation_and_Part-of-Speech_Tagging.html">173 acl-2013-Graph-based Semi-Supervised Model for Joint Chinese Word Segmentation and Part-of-Speech Tagging</a></p>
<p>11 0.1042091 <a title="99-tfidf-11" href="./acl-2013-TransDoop%3A_A_Map-Reduce_based_Crowdsourced_Translation_for_Complex_Domain.html">355 acl-2013-TransDoop: A Map-Reduce based Crowdsourced Translation for Complex Domain</a></p>
<p>12 0.10337123 <a title="99-tfidf-12" href="./acl-2013-Does_Korean_defeat_phonotactic_word_segmentation%3F.html">128 acl-2013-Does Korean defeat phonotactic word segmentation?</a></p>
<p>13 0.10285227 <a title="99-tfidf-13" href="./acl-2013-Collective_Annotation_of_Linguistic_Resources%3A_Basic_Principles_and_a_Formal_Model.html">83 acl-2013-Collective Annotation of Linguistic Resources: Basic Principles and a Formal Model</a></p>
<p>14 0.093430139 <a title="99-tfidf-14" href="./acl-2013-An_improved_MDL-based_compression_algorithm_for_unsupervised_word_segmentation.html">50 acl-2013-An improved MDL-based compression algorithm for unsupervised word segmentation</a></p>
<p>15 0.093090758 <a title="99-tfidf-15" href="./acl-2013-Question_Analysis_for_Polish_Question_Answering.html">290 acl-2013-Question Analysis for Polish Question Answering</a></p>
<p>16 0.091524266 <a title="99-tfidf-16" href="./acl-2013-Are_Semantically_Coherent_Topic_Models_Useful_for_Ad_Hoc_Information_Retrieval%3F.html">55 acl-2013-Are Semantically Coherent Topic Models Useful for Ad Hoc Information Retrieval?</a></p>
<p>17 0.086879723 <a title="99-tfidf-17" href="./acl-2013-Paraphrase-Driven_Learning_for_Open_Question_Answering.html">272 acl-2013-Paraphrase-Driven Learning for Open Question Answering</a></p>
<p>18 0.086774945 <a title="99-tfidf-18" href="./acl-2013-Reducing_Annotation_Effort_for_Quality_Estimation_via_Active_Learning.html">300 acl-2013-Reducing Annotation Effort for Quality Estimation via Active Learning</a></p>
<p>19 0.086726367 <a title="99-tfidf-19" href="./acl-2013-Linggle%3A_a_Web-scale_Linguistic_Search_Engine_for_Words_in_Context.html">231 acl-2013-Linggle: a Web-scale Linguistic Search Engine for Words in Context</a></p>
<p>20 0.07535658 <a title="99-tfidf-20" href="./acl-2013-Broadcast_News_Story_Segmentation_Using_Manifold_Learning_on_Latent_Topic_Distributions.html">73 acl-2013-Broadcast News Story Segmentation Using Manifold Learning on Latent Topic Distributions</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.179), (1, -0.028), (2, -0.123), (3, -0.018), (4, 0.211), (5, -0.079), (6, -0.024), (7, -0.081), (8, 0.014), (9, 0.126), (10, -0.069), (11, 0.139), (12, -0.009), (13, 0.022), (14, -0.108), (15, -0.048), (16, 0.092), (17, 0.015), (18, 0.021), (19, 0.015), (20, -0.057), (21, 0.044), (22, -0.105), (23, -0.003), (24, 0.011), (25, -0.099), (26, -0.107), (27, 0.146), (28, -0.026), (29, 0.119), (30, 0.006), (31, 0.042), (32, -0.114), (33, -0.06), (34, -0.034), (35, -0.135), (36, 0.146), (37, 0.024), (38, -0.03), (39, 0.072), (40, 0.132), (41, -0.083), (42, 0.047), (43, 0.062), (44, 0.054), (45, -0.075), (46, 0.022), (47, 0.036), (48, -0.119), (49, -0.047)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98085421 <a title="99-lsi-1" href="./acl-2013-Crowd_Prefers_the_Middle_Path%3A_A_New_IAA_Metric_for_Crowdsourcing_Reveals_Turker_Biases_in_Query_Segmentation.html">99 acl-2013-Crowd Prefers the Middle Path: A New IAA Metric for Crowdsourcing Reveals Turker Biases in Query Segmentation</a></p>
<p>Author: Rohan Ramanath ; Monojit Choudhury ; Kalika Bali ; Rishiraj Saha Roy</p><p>Abstract: Query segmentation, like text chunking, is the first step towards query understanding. In this study, we explore the effectiveness of crowdsourcing for this task. Through carefully designed control experiments and Inter Annotator Agreement metrics for analysis of experimental data, we show that crowdsourcing may not be a suitable approach for query segmentation because the crowd seems to have a very strong bias towards dividing the query into roughly equal (often only two) parts. Similarly, in the case of hierarchical or nested segmentation, turkers have a strong preference towards balanced binary trees.</p><p>2 0.83769852 <a title="99-lsi-2" href="./acl-2013-Evaluating_Text_Segmentation_using_Boundary_Edit_Distance.html">140 acl-2013-Evaluating Text Segmentation using Boundary Edit Distance</a></p>
<p>Author: Chris Fournier</p><p>Abstract: This work proposes a new segmentation evaluation metric, named boundary similarity (B), an inter-coder agreement coefficient adaptation, and a confusion-matrix for segmentation that are all based upon an adaptation of the boundary edit distance in Fournier and Inkpen (2012). Existing segmentation metrics such as Pk, WindowDiff, and Segmentation Similarity (S) are all able to award partial credit for near misses between boundaries, but are biased towards segmentations containing few or tightly clustered boundaries. Despite S’s improvements, its normalization also produces cosmetically high values that overestimate agreement & performance, leading this work to propose a solution.</p><p>3 0.63909495 <a title="99-lsi-3" href="./acl-2013-Discriminative_Learning_with_Natural_Annotations%3A_Word_Segmentation_as_a_Case_Study.html">123 acl-2013-Discriminative Learning with Natural Annotations: Word Segmentation as a Case Study</a></p>
<p>Author: Wenbin Jiang ; Meng Sun ; Yajuan Lu ; Yating Yang ; Qun Liu</p><p>Abstract: Structural information in web text provides natural annotations for NLP problems such as word segmentation and parsing. In this paper we propose a discriminative learning algorithm to take advantage of the linguistic knowledge in large amounts of natural annotations on the Internet. It utilizes the Internet as an external corpus with massive (although slight and sparse) natural annotations, and enables a classifier to evolve on the large-scaled and real-time updated web text. With Chinese word segmentation as a case study, experiments show that the segmenter enhanced with the Chinese wikipedia achieves sig- nificant improvement on a series of testing sets from different domains, even with a single classifier and local features.</p><p>4 0.61850643 <a title="99-lsi-4" href="./acl-2013-Does_Korean_defeat_phonotactic_word_segmentation%3F.html">128 acl-2013-Does Korean defeat phonotactic word segmentation?</a></p>
<p>Author: Robert Daland ; Kie Zuraw</p><p>Abstract: Computational models of infant word segmentation have not been tested on a wide range of languages. This paper applies a phonotactic segmentation model to Korean. In contrast to the undersegmentation pattern previously found in English and Russian, the model exhibited more oversegmentation errors and more errors overall. Despite the high error rate, analysis suggested that lexical acquisition might not be problematic, provided that infants attend only to frequently segmented items. 1</p><p>5 0.58413059 <a title="99-lsi-5" href="./acl-2013-Paraphrasing_Adaptation_for_Web_Search_Ranking.html">273 acl-2013-Paraphrasing Adaptation for Web Search Ranking</a></p>
<p>Author: Chenguang Wang ; Nan Duan ; Ming Zhou ; Ming Zhang</p><p>Abstract: Mismatch between queries and documents is a key issue for the web search task. In order to narrow down such mismatch, in this paper, we present an in-depth investigation on adapting a paraphrasing technique to web search from three aspects: a search-oriented paraphrasing model; an NDCG-based parameter optimization algorithm; an enhanced ranking model leveraging augmented features computed on paraphrases of original queries. Ex- periments performed on the large scale query-document data set show that, the search performance can be significantly improved, with +3.28% and +1.14% NDCG gains on dev and test sets respectively.</p><p>6 0.56789297 <a title="99-lsi-6" href="./acl-2013-An_improved_MDL-based_compression_algorithm_for_unsupervised_word_segmentation.html">50 acl-2013-An improved MDL-based compression algorithm for unsupervised word segmentation</a></p>
<p>7 0.56044555 <a title="99-lsi-7" href="./acl-2013-Co-regularizing_character-based_and_word-based_models_for_semi-supervised_Chinese_word_segmentation.html">82 acl-2013-Co-regularizing character-based and word-based models for semi-supervised Chinese word segmentation</a></p>
<p>8 0.52328354 <a title="99-lsi-8" href="./acl-2013-ICARUS_-_An_Extensible_Graphical_Search_Tool_for_Dependency_Treebanks.html">183 acl-2013-ICARUS - An Extensible Graphical Search Tool for Dependency Treebanks</a></p>
<p>9 0.50047612 <a title="99-lsi-9" href="./acl-2013-Improving_Chinese_Word_Segmentation_on_Micro-blog_Using_Rich_Punctuations.html">193 acl-2013-Improving Chinese Word Segmentation on Micro-blog Using Rich Punctuations</a></p>
<p>10 0.47672179 <a title="99-lsi-10" href="./acl-2013-Collective_Annotation_of_Linguistic_Resources%3A_Basic_Principles_and_a_Formal_Model.html">83 acl-2013-Collective Annotation of Linguistic Resources: Basic Principles and a Formal Model</a></p>
<p>11 0.44045603 <a title="99-lsi-11" href="./acl-2013-Chinese_Parsing_Exploiting_Characters.html">80 acl-2013-Chinese Parsing Exploiting Characters</a></p>
<p>12 0.44037497 <a title="99-lsi-12" href="./acl-2013-Feature-Based_Selection_of_Dependency_Paths_in_Ad_Hoc_Information_Retrieval.html">158 acl-2013-Feature-Based Selection of Dependency Paths in Ad Hoc Information Retrieval</a></p>
<p>13 0.4374162 <a title="99-lsi-13" href="./acl-2013-Crowdsourcing_Interaction_Logs_to_Understand_Text_Reuse_from_the_Web.html">100 acl-2013-Crowdsourcing Interaction Logs to Understand Text Reuse from the Web</a></p>
<p>14 0.42379421 <a title="99-lsi-14" href="./acl-2013-ParaQuery%3A_Making_Sense_of_Paraphrase_Collections.html">271 acl-2013-ParaQuery: Making Sense of Paraphrase Collections</a></p>
<p>15 0.4109562 <a title="99-lsi-15" href="./acl-2013-Reducing_Annotation_Effort_for_Quality_Estimation_via_Active_Learning.html">300 acl-2013-Reducing Annotation Effort for Quality Estimation via Active Learning</a></p>
<p>16 0.41085446 <a title="99-lsi-16" href="./acl-2013-A_Lattice-based_Framework_for_Joint_Chinese_Word_Segmentation%2C_POS_Tagging_and_Parsing.html">7 acl-2013-A Lattice-based Framework for Joint Chinese Word Segmentation, POS Tagging and Parsing</a></p>
<p>17 0.40155798 <a title="99-lsi-17" href="./acl-2013-Linggle%3A_a_Web-scale_Linguistic_Search_Engine_for_Words_in_Context.html">231 acl-2013-Linggle: a Web-scale Linguistic Search Engine for Words in Context</a></p>
<p>18 0.3944183 <a title="99-lsi-18" href="./acl-2013-Annotating_named_entities_in_clinical_text_by_combining_pre-annotation_and_active_learning.html">52 acl-2013-Annotating named entities in clinical text by combining pre-annotation and active learning</a></p>
<p>19 0.380849 <a title="99-lsi-19" href="./acl-2013-Graph-based_Semi-Supervised_Model_for_Joint_Chinese_Word_Segmentation_and_Part-of-Speech_Tagging.html">173 acl-2013-Graph-based Semi-Supervised Model for Joint Chinese Word Segmentation and Part-of-Speech Tagging</a></p>
<p>20 0.36799145 <a title="99-lsi-20" href="./acl-2013-WebAnno%3A_A_Flexible%2C_Web-based_and_Visually_Supported_System_for_Distributed_Annotations.html">385 acl-2013-WebAnno: A Flexible, Web-based and Visually Supported System for Distributed Annotations</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.043), (6, 0.035), (11, 0.069), (15, 0.032), (24, 0.085), (26, 0.037), (28, 0.012), (35, 0.094), (41, 0.162), (42, 0.055), (48, 0.041), (64, 0.026), (70, 0.037), (80, 0.017), (88, 0.028), (90, 0.041), (95, 0.078)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.89086223 <a title="99-lda-1" href="./acl-2013-Generating_Recommendation_Dialogs_by_Extracting_Information_from_User_Reviews.html">168 acl-2013-Generating Recommendation Dialogs by Extracting Information from User Reviews</a></p>
<p>Author: Kevin Reschke ; Adam Vogel ; Dan Jurafsky</p><p>Abstract: Recommendation dialog systems help users navigate e-commerce listings by asking questions about users’ preferences toward relevant domain attributes. We present a framework for generating and ranking fine-grained, highly relevant questions from user-generated reviews. We demonstrate ourapproachon anew dataset just released by Yelp, and release a new sentiment lexicon with 1329 adjectives for the restaurant domain.</p><p>same-paper 2 0.87822872 <a title="99-lda-2" href="./acl-2013-Crowd_Prefers_the_Middle_Path%3A_A_New_IAA_Metric_for_Crowdsourcing_Reveals_Turker_Biases_in_Query_Segmentation.html">99 acl-2013-Crowd Prefers the Middle Path: A New IAA Metric for Crowdsourcing Reveals Turker Biases in Query Segmentation</a></p>
<p>Author: Rohan Ramanath ; Monojit Choudhury ; Kalika Bali ; Rishiraj Saha Roy</p><p>Abstract: Query segmentation, like text chunking, is the first step towards query understanding. In this study, we explore the effectiveness of crowdsourcing for this task. Through carefully designed control experiments and Inter Annotator Agreement metrics for analysis of experimental data, we show that crowdsourcing may not be a suitable approach for query segmentation because the crowd seems to have a very strong bias towards dividing the query into roughly equal (often only two) parts. Similarly, in the case of hierarchical or nested segmentation, turkers have a strong preference towards balanced binary trees.</p><p>3 0.79128098 <a title="99-lda-3" href="./acl-2013-Models_of_Semantic_Representation_with_Visual_Attributes.html">249 acl-2013-Models of Semantic Representation with Visual Attributes</a></p>
<p>Author: Carina Silberer ; Vittorio Ferrari ; Mirella Lapata</p><p>Abstract: We consider the problem of grounding the meaning of words in the physical world and focus on the visual modality which we represent by visual attributes. We create a new large-scale taxonomy of visual attributes covering more than 500 concepts and their corresponding 688K images. We use this dataset to train attribute classifiers and integrate their predictions with text-based distributional models of word meaning. We show that these bimodal models give a better fit to human word association data compared to amodal models and word representations based on handcrafted norming data.</p><p>4 0.76355529 <a title="99-lda-4" href="./acl-2013-Text_Classification_based_on_the_Latent_Topics_of_Important_Sentences_extracted_by_the_PageRank_Algorithm.html">341 acl-2013-Text Classification based on the Latent Topics of Important Sentences extracted by the PageRank Algorithm</a></p>
<p>Author: Yukari Ogura ; Ichiro Kobayashi</p><p>Abstract: In this paper, we propose a method to raise the accuracy of text classification based on latent topics, reconsidering the techniques necessary for good classification for example, to decide important sentences in a document, the sentences with important words are usually regarded as important sentences. In this case, tf.idf is often used to decide important words. On the other hand, we apply the PageRank algorithm to rank important words in each document. Furthermore, before clustering documents, we refine the target documents by representing them as a collection of important sentences in each document. We then classify the documents based on latent information in the documents. As a clustering method, we employ the k-means algorithm and inves– tigate how our proposed method works for good clustering. We conduct experiments with Reuters-21578 corpus under various conditions of important sentence extraction, using latent and surface information for clustering, and have confirmed that our proposed method provides better result among various conditions for clustering.</p><p>5 0.74113572 <a title="99-lda-5" href="./acl-2013-Identifying_Bad_Semantic_Neighbors_for_Improving_Distributional_Thesauri.html">185 acl-2013-Identifying Bad Semantic Neighbors for Improving Distributional Thesauri</a></p>
<p>Author: Olivier Ferret</p><p>Abstract: Distributional thesauri are now widely used in a large number of Natural Language Processing tasks. However, they are far from containing only interesting semantic relations. As a consequence, improving such thesaurus is an important issue that is mainly tackled indirectly through the improvement of semantic similarity measures. In this article, we propose a more direct approach focusing on the identification of the neighbors of a thesaurus entry that are not semantically linked to this entry. This identification relies on a discriminative classifier trained from unsupervised selected examples for building a distributional model of the entry in texts. Its bad neighbors are found by applying this classifier to a representative set of occurrences of each of these neighbors. We evaluate the interest of this method for a large set of English nouns with various frequencies.</p><p>6 0.73726666 <a title="99-lda-6" href="./acl-2013-A_Bayesian_Model_for_Joint_Unsupervised_Induction_of_Sentiment%2C_Aspect_and_Discourse_Representations.html">2 acl-2013-A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations</a></p>
<p>7 0.73659599 <a title="99-lda-7" href="./acl-2013-Using_Supervised_Bigram-based_ILP_for_Extractive_Summarization.html">377 acl-2013-Using Supervised Bigram-based ILP for Extractive Summarization</a></p>
<p>8 0.73620903 <a title="99-lda-8" href="./acl-2013-Improving_Text_Simplification_Language_Modeling_Using_Unsimplified_Text_Data.html">194 acl-2013-Improving Text Simplification Language Modeling Using Unsimplified Text Data</a></p>
<p>9 0.73383898 <a title="99-lda-9" href="./acl-2013-Graph-based_Local_Coherence_Modeling.html">172 acl-2013-Graph-based Local Coherence Modeling</a></p>
<p>10 0.73144466 <a title="99-lda-10" href="./acl-2013-Leveraging_Domain-Independent_Information_in_Semantic_Parsing.html">228 acl-2013-Leveraging Domain-Independent Information in Semantic Parsing</a></p>
<p>11 0.73015803 <a title="99-lda-11" href="./acl-2013-Improving_pairwise_coreference_models_through_feature_space_hierarchy_learning.html">196 acl-2013-Improving pairwise coreference models through feature space hierarchy learning</a></p>
<p>12 0.72918069 <a title="99-lda-12" href="./acl-2013-Joint_Inference_for_Fine-grained_Opinion_Extraction.html">207 acl-2013-Joint Inference for Fine-grained Opinion Extraction</a></p>
<p>13 0.72801751 <a title="99-lda-13" href="./acl-2013-PARMA%3A_A_Predicate_Argument_Aligner.html">267 acl-2013-PARMA: A Predicate Argument Aligner</a></p>
<p>14 0.72801137 <a title="99-lda-14" href="./acl-2013-Large-scale_Semantic_Parsing_via_Schema_Matching_and_Lexicon_Extension.html">215 acl-2013-Large-scale Semantic Parsing via Schema Matching and Lexicon Extension</a></p>
<p>15 0.72786605 <a title="99-lda-15" href="./acl-2013-Paraphrase-Driven_Learning_for_Open_Question_Answering.html">272 acl-2013-Paraphrase-Driven Learning for Open Question Answering</a></p>
<p>16 0.72760797 <a title="99-lda-16" href="./acl-2013-Collective_Annotation_of_Linguistic_Resources%3A_Basic_Principles_and_a_Formal_Model.html">83 acl-2013-Collective Annotation of Linguistic Resources: Basic Principles and a Formal Model</a></p>
<p>17 0.72760797 <a title="99-lda-17" href="./acl-2013-Sentiment_Relevance.html">318 acl-2013-Sentiment Relevance</a></p>
<p>18 0.72689915 <a title="99-lda-18" href="./acl-2013-Combining_Intra-_and_Multi-sentential_Rhetorical_Parsing_for_Document-level_Discourse_Analysis.html">85 acl-2013-Combining Intra- and Multi-sentential Rhetorical Parsing for Document-level Discourse Analysis</a></p>
<p>19 0.72678035 <a title="99-lda-19" href="./acl-2013-Generating_Synthetic_Comparable_Questions_for_News_Articles.html">169 acl-2013-Generating Synthetic Comparable Questions for News Articles</a></p>
<p>20 0.72649479 <a title="99-lda-20" href="./acl-2013-A_Random_Walk_Approach_to_Selectional_Preferences_Based_on_Preference_Ranking_and_Propagation.html">17 acl-2013-A Random Walk Approach to Selectional Preferences Based on Preference Ranking and Propagation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
