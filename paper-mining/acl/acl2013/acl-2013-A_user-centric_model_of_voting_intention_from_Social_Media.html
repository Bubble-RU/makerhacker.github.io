<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>33 acl-2013-A user-centric model of voting intention from Social Media</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-33" href="#">acl2013-33</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>33 acl-2013-A user-centric model of voting intention from Social Media</h1>
<br/><p>Source: <a title="acl-2013-33-pdf" href="http://aclweb.org/anthology//P/P13/P13-1098.pdf">pdf</a></p><p>Author: Vasileios Lampos ; Daniel PreoÅ£iuc-Pietro ; Trevor Cohn</p><p>Abstract: Social Media contain a multitude of user opinions which can be used to predict realworld phenomena in many domains including politics, finance and health. Most existing methods treat these problems as linear regression, learning to relate word frequencies and other simple features to a known response variable (e.g., voting intention polls or financial indicators). These techniques require very careful filtering of the input texts, as most Social Media posts are irrelevant to the task. In this paper, we present a novel approach which performs high quality filtering automatically, through modelling not just words but also users, framed as a bilinear model with a sparse regulariser. We also consider the problem of modelling groups of related output variables, using a structured multi-task regularisation method. Our experiments on voting intention prediction demonstrate strong performance over large-scale input from Twitter on two distinct case studies, outperforming competitive baselines.</p><p>Reference: <a title="acl-2013-33-reference" href="../acl2013_reference/acl-2013-A_user-centric_model_of_voting_intention_from_Social_Media_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 A user-centric model of voting intention from Social Media Vasileios Lampos, Daniel Preo t¸iuc-Pietro and Trevor Cohn Computer Science Department University of Sheffield, UK  ,  ,  {v . [sent-1, score-0.452]
</p><p>2 Most existing methods treat these problems as linear regression, learning to relate word frequencies and other simple features to a known response variable (e. [sent-4, score-0.15]
</p><p>3 In this paper, we present a novel approach which performs high quality filtering automatically, through modelling not just words but also users, framed as a bilinear model with a sparse regulariser. [sent-8, score-0.449]
</p><p>4 We also consider the problem of modelling  groups of related output variables, using a structured multi-task regularisation method. [sent-9, score-0.218]
</p><p>5 Our experiments on voting intention prediction demonstrate strong performance over large-scale input from Twitter on two distinct case studies, outperforming competitive baselines. [sent-10, score-0.452]
</p><p>6 Our approach is able to explore  not only word frequencies, but also the space of users by introducing a bilinear formulation for this learning task. [sent-32, score-0.462]
</p><p>7 Regularised regression on both spaces allows for an automatic selection of the most important terms and users, performing at the same time an improved noise filtering. [sent-33, score-0.131]
</p><p>8 In addition, more advanced regularisation functions enable multi-task learning schemes that can exploit shared structure in the feature space. [sent-34, score-0.173]
</p><p>9 We evaluate our methods on the domain of politics using data from the microblogging service of Twitter to infer voting trends. [sent-38, score-0.247]
</p><p>10 c A2s 0o1c3ia Atisosnoc foiarti Conom fopru Ctaotmiopnuatla Lti on gaulis Lti ncsg,u pisagtiecs 9 3–10 3, posed framework is able to successfully predict voting intentions for the top-3 and top-4 parties in the United Kingdom (UK) and Austria respectively. [sent-41, score-0.448]
</p><p>11 They are used for performing regression aiming to infer voting intention polls in those countries. [sent-46, score-0.884]
</p><p>12 1 Tweets from users in the UK The first data set (we refer to it as Cuk) used in our experimental process consists of approx. [sent-50, score-0.124]
</p><p>13 In this way, we were able to extract hundreds of thousands of UK users, from which we sub-sampled 42K users to be distributed across the UK geographical regions proportionally to their population figures. [sent-56, score-0.124]
</p><p>14 2  Tweets for Austria  The second data set (Cau) is shorter in terms of the number of users involved (1. [sent-58, score-0.124]
</p><p>15 However, this time the selection of users has been made by Austrian political experts who decided which accounts to monitor by subjectively assessing the value of information they may provide towards political-oriented topics. [sent-60, score-0.307]
</p><p>16 Still, we assume that the different users will produce information ofvarying quality, and some should be eliminated entirely. [sent-61, score-0.124]
</p><p>17 (a) 240 voting intention polls for the 3 major parties in the UK (April 2010 to February 2012)  (b) 98 voting intention polls for the 4 major parties in Austria (January to December 2012) Figure 1: Voting intention polls for the UK and Austria. [sent-65, score-2.453]
</p><p>18 potential gains from user modelling compared to the UK case study. [sent-66, score-0.125]
</p><p>19 3 Ground Truth The ground truth for training and evaluating our regression models is formed by voting intention  polls from YouGov (UK) and a collection of Austrian pollsters2 as none performed high frequency polling for the Austrian case study. [sent-69, score-0.945]
</p><p>20 We focused on the three major parties in the UK, namely Conservatives (CON), Labour (LAB) and Liberal Democrats (LBD) and the four major parties in Austria, namely the Social Democratic Party (SPO¨), People’s Party (O¨VP), Freedom Party (FPO¨) and the Green Alternative Party (GRU¨). [sent-70, score-0.328]
</p><p>21 Matching with the time spans of the data sets described in the previous sections, we have acquired 240 unique polls for the UK and 65 polls for Austria. [sent-71, score-0.648]
</p><p>22 The latter have been expanded to 98 polls by replicating the poll of day ifor day –  –  2Wikipedia, http : / / de . [sent-72, score-0.436]
</p><p>23 In this section, we propose a set of methods that build on one another, which aim to filter the non desirable noise and extract the most informative features not only based on word frequencies, but also by incorporating users in this process. [sent-81, score-0.15]
</p><p>24 1 The bilinear model There exist a number of different possibilities for incorporating user information into a regression model. [sent-83, score-0.492]
</p><p>25 One solution is to group users into different types, such as journalist, politician, activist, etc. [sent-86, score-0.124]
</p><p>26 , but this presupposes a method  ×  for classification or clustering of users which is a non-trivial undertaking. [sent-87, score-0.124]
</p><p>27 Besides, these na¨ ıve approaches fail to account for the fact that most users use similar words to express their opinions, by separately parameterising the model for different users or user groups. [sent-88, score-0.328]
</p><p>28 We propose to account for individual users while restricting all users to share the same vocabulary. [sent-89, score-0.248]
</p><p>29 This is formulated as a bilinear predictive model, f(X) = uuTX w ww + β , (1) where X is an m p matrix of user-word frequencies a insd a uu amnd × ww are tthriex m ofod uesl parameters. [sent-90, score-1.152]
</p><p>30 Qijk holds the frequency of term j for user k during the day iin our sample. [sent-93, score-0.165]
</p><p>31 If a user k has posted ci·k tweets during day i, and cijk ≤ ci·k of them contain a term j, then the frequency ocf j for this day and user is defined as Qijk = ccijk. [sent-94, score-0.403]
</p><p>32 Aiming etor ilse adrenfi sparse Qsets of users and terms that are representative of the voting intention signal, we formulate our optimisation task as follows:  {w w w∗, uuu∗,β∗} = aw wr wg,m uu u,βinXi=n1? [sent-95, score-0.922]
</p><p>33 2 is the standard regularisation loss function, namely the sum squared error over the training instances. [sent-99, score-0.173]
</p><p>34 4 In the main formulation of our bilinear model, as the regularisation function ψ(·) we use the elas-  taisc hnee tr (Zou asnatdi Hastie, 2005), an e uxsete tnhseio enl osfthe well-studied ‘1-norm regulariser, known as the LASSO (Tibshirani, 1996). [sent-100, score-0.511]
</p><p>35 The ‘1-norm regularisation has found many applications in several scientific fields as it encourages sparse solutions which reduce the possibility of overfitting and enhance the interpretability of the inferred model (Hastie et al. [sent-101, score-0.237]
</p><p>36 Its regularisation function ψel(·) is defined by:  ψel( www ,λ,α) = λ? [sent-104, score-0.173]
</p><p>37 2 can be treated as a biconvex learning task (Al-Khayyal and Falk, 1983), by observing that for a fixed ww , learning uu is a convex problem and vice versa. [sent-108, score-0.536]
</p><p>38 In our case, the bilinear technique makes it possible to explore both word and user spaces, while maintaining a modest training complexity. [sent-115, score-0.418]
</p><p>39 Therefore, in our bilinear approach we divide learning in two phases, where we learn word and user weights respectively. [sent-116, score-0.457]
</p><p>40 (4)  zX= X1  V contains weighted sums of term frequencies  over anltla users feoirg hthteed dc osnusmidse roefd seretm mof f days. [sent-118, score-0.196]
</p><p>41 cTihees weights are held in uu and are representative of each user. [sent-119, score-0.231]
</p><p>42 The initial optimisation task is formulated as: {ww w ∗ , β∗} = argminkV ww w + β yyk22 −  wg w,mβ  + ψel (ww w , λ1, α1)  ,  (5)  where we aim to learn a sparse but consistent set of weights w∗ for the terms of our vocabulary. [sent-120, score-0.479]
</p><p>43 In the second phase, we are using ww ∗ to form the user-scores matrix D ∈ Rn×p:  =  Xm  Dik Xw∗zQizk,  (6)  zX= X1  which now contains weighted sums over all terms for the same set of days. [sent-121, score-0.254]
</p><p>44 The optimisation task becomes: {uu u ∗ , β∗} = argminkD uu u β  + −yy y k22  ug u,mβ  + ψel (uu u , λ2, α2)  . [sent-122, score-0.315]
</p><p>45 (7)  This process continues iteratively by inserting the weights of the second phase back to phase one,  and so on until convergence. [sent-123, score-0.137]
</p><p>46 2  Exploiting term-target or user-target relationships The previous model assumes that the response variable yy holds information about a single inference target. [sent-128, score-0.239]
</p><p>47 Here we consider tying together the user weights u uu, to enforce that the same set of users are relevant to all tasks, while learning different term weights. [sent-134, score-0.272]
</p><p>48 Suppose that our target variable yy ∈ Rτn refers now to τ political entities, yy = in this formation the top n element? [sent-136, score-0.461]
</p><p>49 tch to the first political entity, the next n elements to the second and so on. [sent-138, score-0.156]
</p><p>50 In the first phase of the bilinear model, we would have to solve the following optimisation task:  ? [sent-139, score-0.51]
</p><p>51 T;  Xτ  { ww w∗,β∗} = arwg,mβinXi=1kτVwwwii + βi− yik22 +Xψel(w ww i,λ1,α1) Xi= X1  ,  (8)  where V is given by Eq. [sent-143, score-0.508]
</p><p>52 4 and ww ∗ ∈ Rτm denwohteesre t hVe vse gctiover no fb weights wanhdic ww hw can b Re sliced into τ sub-vectors {ww w ∗1 , . [sent-144, score-0.547]
</p><p>53 In t}he e scehco onnde phase, sub-vectors ww i∗ are used to form the input matrices Di, i ∈ {1, . [sent-148, score-0.254]
</p><p>54 Since D0 ∈ Rτn×p, the user weight vector uu ∗ ∈ Rp and thus, we are learning a single weight per user and not one per political party as in the previous step. [sent-172, score-0.62]
</p><p>55 The method described above allows learning different term weights per response variable and then binds them under a shared set of user weights. [sent-173, score-0.255]
</p><p>56 , start by expanding the user space); both those models can also be optimised in an iterative process. [sent-176, score-0.138]
</p><p>57 aTl,l  996  from a shared set of users (and the opposite) may not be a good modelling practice for the domain of politics. [sent-181, score-0.169]
</p><p>58 Nevertheless, this observation served as a motivation for the method described in the next section, where we extract a consistent set of words  and users that are weighted differently among the considered political entities. [sent-182, score-0.28]
</p><p>59 3  Multi-task learning with the ‘1/‘2 regulariser All previous models even when combining all inference targets were not able to explore relationships across the different task domains; in our case, a task domain is defined by a specific political label or party. [sent-184, score-0.227]
</p><p>60 Ideally, we would like to make a sparse selection of words and users but with a regulariser that promotes inter-task sharing of structure, so that many features may have a positive influence towards one or more parties, but negative towards the remaining one(s). [sent-185, score-0.253]
</p><p>61 It is possible to achieve this multi-task learning property by introducing a different set of regularisation constraints in the optimisation function. [sent-186, score-0.296]
</p><p>62 We perform multi-task learning using an extension of group LASSO (Yuan and Lin, 2006), a method known as ‘‘‘111/‘‘‘222 regularisation (Argyriou et al. [sent-187, score-0.173]
</p><p>63 The ‘1/‘2 regulariser extends this notion for a τ-dimensional response variable. [sent-193, score-0.137]
</p><p>64 The global optimisation target is now formulated as: {W∗ U∗ ββ∗} ,  ,  =  arWg,Um,β ββ intX=τ1Xi=n1? [sent-194, score-0.184]
</p><p>65 wwτ] is the term weight matrix (each ww t refers to the t-th political entity or task), equivalently U = [uu u 1 . [sent-200, score-0.439]
</p><p>66 Consequently, we are performing filtering (many users and words will have zero weights) and, at the same time, assign weights of different magnitude and sign on the selected features, something that suits a political opinion mining application, where pro-A often means anti-B. [sent-208, score-0.396]
</p><p>67 Again, we are able iterate this bilinear process and in each step convexity is guaranteed. [sent-212, score-0.338]
</p><p>68 The evaluation process starts by using a fixed set of polls matching  to consecutive time points in the past for training and validating the parameters of each model. [sent-228, score-0.324]
</p><p>69 Testing is performed on the following δ (unseen) polls of the data set. [sent-229, score-0.324]
</p><p>70 Note that it may be tempting to adapt the regularisation parameters in each phase of the iterative training loop, however this would change the global objective (see Eqs. [sent-235, score-0.28]
</p><p>71 S627 E9387srep-  resenting the error of the inferred voting intention percentage for the 10-step validation process;  denotes the mean RMSE across the three political parties for each baseline or inference method. [sent-247, score-0.799]
</p><p>72 The first makes a constant prediction of the mean value of the response variable yy in the training set (Bµµ µ );the second predicts the last value of yy (Blast); and the third baseline (LEN) is a linear regression over the terms using elastic net regularisation. [sent-258, score-0.552]
</p><p>73 Recalling that each test set is made of 5 polls, Blast should be considered  as a hard baseline to beat7 given that voting intentions tend to have a smooth behaviour. [sent-259, score-0.249]
</p><p>74 Moreover, improving on LEN partly justifies the usefulness of a bilinear approach compared to a linear one. [sent-260, score-0.338]
</p><p>75 Performance results comparing inferred voting intention percentages and polls for Cuk and Cau are presented in Tables 1 and 2 respectively. [sent-261, score-0.776]
</p><p>76 However in the Austrian case study, LEN performs better that BEN, something that could be justified by the fact that the users in Cau were selected by domain experts, and consequently there was not much gain to be had by filtering them further. [sent-263, score-0.159]
</p><p>77 998  (a) Ground Truth (polls)  (b) BEN  (c) BGL Figure 3: UK case study Voting intention inference results (50 polls, 3 parties). [sent-267, score-0.249]
</p><p>78 Sub-figure 3a is a plot of ground truth as presented in voting intention polls (Fig. [sent-268, score-0.871]
</p><p>79 (a) Ground Truth (polls)  across  the four  (b) BEN  (c) BGL  Figure 4: Austrian case study Voting intention inference results (50 polls, 4 parties). [sent-276, score-0.249]
</p><p>80 Sub-figure 4a is a plot of ground truth as presented in voting intention polls (Fig. [sent-277, score-0.871]
</p><p>81 3b) cannot register any change with the exception of one test point in the leading party fight (CON versus LAB); BGL (Fig. [sent-281, score-0.141]
</p><p>82 Most importantly, a –  –  9Voting intention polls were plotted separately to allow a better presentation. [sent-287, score-0.573]
</p><p>83 Notice that weight magnitude may differ per case study and party as they are based on the range of the response variable  and the total number of selected features. [sent-289, score-0.219]
</p><p>84 This might be a result of overfitting the model to a single response variable which usually has a smooth behaviour. [sent-291, score-0.14]
</p><p>85 On the contrary, the multitask learning property of BGL reduces this type of overfitting providing more statistical evidence for  the terms and users and thus, yielding not only a better inference performance, but also a more accurate model. [sent-292, score-0.157]
</p><p>86 3 Qualitative Analysis In this section, we refer to features that have been selected and weighted as significant by our bilinear learning functions. [sent-294, score-0.338]
</p><p>87 Based on the weights for the word and the user spaces that we retrieve after the application of BGL in the last step of the evaluation process (see the previous section), we compute a score (weighted sum) for each tweet in our training data sets for both Cuk and Cau. [sent-295, score-0.149]
</p><p>88 In the displayed tweets for the UK study, the only possible outlier is the ‘Art Fanzine’ ; still, it seems to register a consistent behaviour (positive towards 1000  LAB, negative towards LBD) and, of course, hid-  den, indirect relationships may exist between political opinion and art. [sent-298, score-0.329]
</p><p>89 The Austrian case study revealed even more interesting tweets since training was conducted on data from a very active preelection period (we made an effort to translate those tweets in English language as well). [sent-299, score-0.204]
</p><p>90 5  Related Work  The topic of political opinion mining from Social Media has been the focus of various recent research works. [sent-301, score-0.198]
</p><p>91 , 2010; Bermingham and  Smeaton, 2011) or to model voting intention and other kinds of socio-political polls (O’Connor et al. [sent-303, score-0.776]
</p><p>92 majority of sentiment analysis tools are Englishspecific (or even American English) and, most importantly, political word lists (or ontologies) change in time, per country and per party; hence, generalisable methods should make an effort to limit reliance from such tools. [sent-319, score-0.196]
</p><p>93 , 2011) as we have developed a framework of “well-defined” algorithms that are “Social Web aware” (since the bilinear approach aims to improve noise filtering) and that have been tested on two evaluation scenarios with distinct characteristics. [sent-321, score-0.338]
</p><p>94 –  6  –  Conclusions and Future Work  We have presented a novel method for text regression that exploits both word and user spaces by  solving a bilinear optimisation task, and an extension that applies multi-task learning for multioutput inference. [sent-322, score-0.645]
</p><p>95 Future work may investigate further modelling improvements achieved by applying different regularisation functions as well as the adaptation of the presented models to classification problems. [sent-326, score-0.218]
</p><p>96 All authors would like to thank the political analysts (and especially Paul Ringler) from for their useful insights on politics in Austria. [sent-332, score-0.231]
</p><p>97 On using Twitter to monitor political sentiment and predict election results. [sent-346, score-0.267]
</p><p>98 On voting intentions inference from Twitter content: a case study on UK 2010 General Election. [sent-389, score-0.249]
</p><p>99 A global optimization algorithm for linear fractional and bilinear programs. [sent-433, score-0.367]
</p><p>100 Philipp  What 140 characters  about political sentiment. [sent-446, score-0.156]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('bilinear', 0.338), ('polls', 0.324), ('ww', 0.254), ('intention', 0.249), ('voting', 0.203), ('uu', 0.192), ('bgl', 0.173), ('regularisation', 0.173), ('parties', 0.164), ('lampos', 0.16), ('austrian', 0.157), ('political', 0.156), ('yy', 0.132), ('users', 0.124), ('cuk', 0.123), ('optimisation', 0.123), ('cau', 0.116), ('uk', 0.115), ('party', 0.112), ('twitter', 0.11), ('ben', 0.107), ('austria', 0.107), ('tweets', 0.102), ('social', 0.094), ('media', 0.083), ('user', 0.08), ('regression', 0.074), ('elastic', 0.073), ('regulariser', 0.071), ('lasso', 0.068), ('response', 0.066), ('vasileios', 0.064), ('tumasjan', 0.058), ('day', 0.056), ('nello', 0.055), ('rmse', 0.055), ('biconvex', 0.053), ('fpo', 0.053), ('metaxas', 0.053), ('trendminer', 0.053), ('truth', 0.053), ('weblogs', 0.05), ('phase', 0.049), ('len', 0.048), ('elections', 0.048), ('preo', 0.047), ('argyriou', 0.047), ('intentions', 0.046), ('modelling', 0.045), ('politics', 0.044), ('frequencies', 0.043), ('ground', 0.042), ('opinion', 0.042), ('variable', 0.041), ('sentiment', 0.04), ('predictive', 0.039), ('weights', 0.039), ('aaai', 0.038), ('connor', 0.037), ('hastie', 0.037), ('convex', 0.037), ('royal', 0.036), ('election', 0.036), ('bermingham', 0.036), ('blast', 0.036), ('gru', 0.036), ('inxi', 0.036), ('lbd', 0.036), ('nelder', 0.036), ('pirsiavash', 0.036), ('qijk', 0.036), ('quesada', 0.036), ('filtering', 0.035), ('predict', 0.035), ('net', 0.034), ('aiming', 0.034), ('el', 0.034), ('overfitting', 0.033), ('formulated', 0.032), ('analysts', 0.031), ('cristianini', 0.031), ('eni', 0.031), ('jansen', 0.031), ('zx', 0.031), ('rn', 0.031), ('sparse', 0.031), ('trevor', 0.031), ('series', 0.03), ('spaces', 0.03), ('iterative', 0.029), ('term', 0.029), ('optimised', 0.029), ('register', 0.029), ('zou', 0.029), ('global', 0.029), ('validation', 0.027), ('panagiotis', 0.027), ('selection', 0.027), ('filter', 0.026), ('qualitative', 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999958 <a title="33-tfidf-1" href="./acl-2013-A_user-centric_model_of_voting_intention_from_Social_Media.html">33 acl-2013-A user-centric model of voting intention from Social Media</a></p>
<p>Author: Vasileios Lampos ; Daniel PreoÅ£iuc-Pietro ; Trevor Cohn</p><p>Abstract: Social Media contain a multitude of user opinions which can be used to predict realworld phenomena in many domains including politics, finance and health. Most existing methods treat these problems as linear regression, learning to relate word frequencies and other simple features to a known response variable (e.g., voting intention polls or financial indicators). These techniques require very careful filtering of the input texts, as most Social Media posts are irrelevant to the task. In this paper, we present a novel approach which performs high quality filtering automatically, through modelling not just words but also users, framed as a bilinear model with a sparse regulariser. We also consider the problem of modelling groups of related output variables, using a structured multi-task regularisation method. Our experiments on voting intention prediction demonstrate strong performance over large-scale input from Twitter on two distinct case studies, outperforming competitive baselines.</p><p>2 0.1660793 <a title="33-tfidf-2" href="./acl-2013-Detecting_Event-Related_Links_and_Sentiments_from_Social_Media_Texts.html">115 acl-2013-Detecting Event-Related Links and Sentiments from Social Media Texts</a></p>
<p>Author: Alexandra Balahur ; Hristo Tanev</p><p>Abstract: Nowadays, the importance of Social Media is constantly growing, as people often use such platforms to share mainstream media news and comment on the events that they relate to. As such, people no loger remain mere spectators to the events that happen in the world, but become part of them, commenting on their developments and the entities involved, sharing their opinions and distributing related content. This paper describes a system that links the main events detected from clusters of newspaper articles to tweets related to them, detects complementary information sources from the links they contain and subsequently applies sentiment analysis to classify them into positive, negative and neutral. In this manner, readers can follow the main events happening in the world, both from the perspective of mainstream as well as social media and the public’s perception on them. This system will be part of the EMM media monitoring framework working live and it will be demonstrated using Google Earth.</p><p>3 0.16291639 <a title="33-tfidf-3" href="./acl-2013-Exploiting_Social_Media_for_Natural_Language_Processing%3A_Bridging_the_Gap_between_Language-centric_and_Real-world_Applications.html">146 acl-2013-Exploiting Social Media for Natural Language Processing: Bridging the Gap between Language-centric and Real-world Applications</a></p>
<p>Author: Simone Paolo Ponzetto ; Andrea Zielinski</p><p>Abstract: unkown-abstract</p><p>4 0.11156447 <a title="33-tfidf-4" href="./acl-2013-Exploiting_Topic_based_Twitter_Sentiment_for_Stock_Prediction.html">147 acl-2013-Exploiting Topic based Twitter Sentiment for Stock Prediction</a></p>
<p>Author: Jianfeng Si ; Arjun Mukherjee ; Bing Liu ; Qing Li ; Huayi Li ; Xiaotie Deng</p><p>Abstract: This paper proposes a technique to leverage topic based sentiments from Twitter to help predict the stock market. We first utilize a continuous Dirichlet Process Mixture model to learn the daily topic set. Then, for each topic we derive its sentiment according to its opinion words distribution to build a sentiment time series. We then regress the stock index and the Twitter sentiment time series to predict the market. Experiments on real-life S&P100; Index show that our approach is effective and performs better than existing state-of-the-art non-topic based methods. 1</p><p>5 0.11127314 <a title="33-tfidf-5" href="./acl-2013-Detecting_Chronic_Critics_Based_on_Sentiment_Polarity_and_User%C3%A2%E2%80%A2%C5%BDs_Behavior_in_Social_Media.html">114 acl-2013-Detecting Chronic Critics Based on Sentiment Polarity and Userâ•Žs Behavior in Social Media</a></p>
<p>Author: Sho Takase ; Akiko Murakami ; Miki Enoki ; Naoaki Okazaki ; Kentaro Inui</p><p>Abstract: There are some chronic critics who always complain about the entity in social media. We are working to automatically detect these chronic critics to prevent the spread of bad rumors about the reputation of the entity. In social media, most comments are informal, and, there are sarcastic and incomplete contexts. This means that it is difficult for current NLP technology such as opinion mining to recognize the complaints. As an alternative approach for social media, we can assume that users who share the same opinions will link to each other. Thus, we propose a method that combines opinion mining with graph analysis for the connections between users to identify the chronic critics. Our ex- perimental results show that the proposed method outperforms analysis based only on opinion mining techniques.</p><p>6 0.11034116 <a title="33-tfidf-6" href="./acl-2013-A_Stacking-based_Approach_to_Twitter_User_Geolocation_Prediction.html">20 acl-2013-A Stacking-based Approach to Twitter User Geolocation Prediction</a></p>
<p>7 0.096989959 <a title="33-tfidf-7" href="./acl-2013-Using_Conceptual_Class_Attributes_to_Characterize_Social_Media_Users.html">373 acl-2013-Using Conceptual Class Attributes to Characterize Social Media Users</a></p>
<p>8 0.091569409 <a title="33-tfidf-8" href="./acl-2013-Learning_to_Extract_International_Relations_from_Political_Context.html">224 acl-2013-Learning to Extract International Relations from Political Context</a></p>
<p>9 0.088759355 <a title="33-tfidf-9" href="./acl-2013-Microblogs_as_Parallel_Corpora.html">240 acl-2013-Microblogs as Parallel Corpora</a></p>
<p>10 0.088301621 <a title="33-tfidf-10" href="./acl-2013-An_Empirical_Study_on_Uncertainty_Identification_in_Social_Media_Context.html">45 acl-2013-An Empirical Study on Uncertainty Identification in Social Media Context</a></p>
<p>11 0.085965842 <a title="33-tfidf-11" href="./acl-2013-Linking_Tweets_to_News%3A_A_Framework_to_Enrich_Short_Text_Data_in_Social_Media.html">233 acl-2013-Linking Tweets to News: A Framework to Enrich Short Text Data in Social Media</a></p>
<p>12 0.08428251 <a title="33-tfidf-12" href="./acl-2013-Exploring_Sentiment_in_Social_Media%3A_Bootstrapping_Subjectivity_Clues_from_Multilingual_Twitter_Streams.html">148 acl-2013-Exploring Sentiment in Social Media: Bootstrapping Subjectivity Clues from Multilingual Twitter Streams</a></p>
<p>13 0.080804609 <a title="33-tfidf-13" href="./acl-2013-Sequential_Summarization%3A_A_New_Application_for_Timely_Updated_Twitter_Trending_Topics.html">319 acl-2013-Sequential Summarization: A New Application for Timely Updated Twitter Trending Topics</a></p>
<p>14 0.078624889 <a title="33-tfidf-14" href="./acl-2013-Discovering_User_Interactions_in_Ideological_Discussions.html">121 acl-2013-Discovering User Interactions in Ideological Discussions</a></p>
<p>15 0.075345613 <a title="33-tfidf-15" href="./acl-2013-Modelling_Annotator_Bias_with_Multi-task_Gaussian_Processes%3A_An_Application_to_Machine_Translation_Quality_Estimation.html">248 acl-2013-Modelling Annotator Bias with Multi-task Gaussian Processes: An Application to Machine Translation Quality Estimation</a></p>
<p>16 0.070289724 <a title="33-tfidf-16" href="./acl-2013-Identifying_Opinion_Subgroups_in_Arabic_Online_Discussions.html">187 acl-2013-Identifying Opinion Subgroups in Arabic Online Discussions</a></p>
<p>17 0.070080981 <a title="33-tfidf-17" href="./acl-2013-Resolving_Entity_Morphs_in_Censored_Data.html">301 acl-2013-Resolving Entity Morphs in Censored Data</a></p>
<p>18 0.067936927 <a title="33-tfidf-18" href="./acl-2013-Recognizing_Rare_Social_Phenomena_in_Conversation%3A_Empowerment_Detection_in_Support_Group_Chatrooms.html">298 acl-2013-Recognizing Rare Social Phenomena in Conversation: Empowerment Detection in Support Group Chatrooms</a></p>
<p>19 0.066977955 <a title="33-tfidf-19" href="./acl-2013-Public_Dialogue%3A_Analysis_of_Tolerance_in_Online_Discussions.html">287 acl-2013-Public Dialogue: Analysis of Tolerance in Online Discussions</a></p>
<p>20 0.061262473 <a title="33-tfidf-20" href="./acl-2013-Collective_Annotation_of_Linguistic_Resources%3A_Basic_Principles_and_a_Formal_Model.html">83 acl-2013-Collective Annotation of Linguistic Resources: Basic Principles and a Formal Model</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.16), (1, 0.14), (2, 0.012), (3, 0.068), (4, 0.057), (5, 0.031), (6, 0.089), (7, 0.024), (8, 0.106), (9, -0.068), (10, -0.112), (11, 0.041), (12, 0.035), (13, -0.058), (14, -0.017), (15, -0.05), (16, -0.01), (17, 0.019), (18, 0.091), (19, -0.067), (20, 0.072), (21, 0.035), (22, -0.004), (23, -0.042), (24, -0.024), (25, 0.007), (26, -0.006), (27, 0.001), (28, 0.019), (29, -0.007), (30, 0.043), (31, 0.023), (32, 0.033), (33, 0.054), (34, 0.003), (35, 0.074), (36, 0.023), (37, 0.027), (38, -0.034), (39, 0.005), (40, 0.015), (41, 0.017), (42, -0.037), (43, -0.013), (44, 0.072), (45, -0.039), (46, -0.007), (47, -0.003), (48, 0.042), (49, -0.009)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92339772 <a title="33-lsi-1" href="./acl-2013-A_user-centric_model_of_voting_intention_from_Social_Media.html">33 acl-2013-A user-centric model of voting intention from Social Media</a></p>
<p>Author: Vasileios Lampos ; Daniel PreoÅ£iuc-Pietro ; Trevor Cohn</p><p>Abstract: Social Media contain a multitude of user opinions which can be used to predict realworld phenomena in many domains including politics, finance and health. Most existing methods treat these problems as linear regression, learning to relate word frequencies and other simple features to a known response variable (e.g., voting intention polls or financial indicators). These techniques require very careful filtering of the input texts, as most Social Media posts are irrelevant to the task. In this paper, we present a novel approach which performs high quality filtering automatically, through modelling not just words but also users, framed as a bilinear model with a sparse regulariser. We also consider the problem of modelling groups of related output variables, using a structured multi-task regularisation method. Our experiments on voting intention prediction demonstrate strong performance over large-scale input from Twitter on two distinct case studies, outperforming competitive baselines.</p><p>2 0.83681095 <a title="33-lsi-2" href="./acl-2013-A_Stacking-based_Approach_to_Twitter_User_Geolocation_Prediction.html">20 acl-2013-A Stacking-based Approach to Twitter User Geolocation Prediction</a></p>
<p>Author: Bo Han ; Paul Cook ; Timothy Baldwin</p><p>Abstract: We implement a city-level geolocation prediction system for Twitter users. The system infers a user’s location based on both tweet text and user-declared metadata using a stacking approach. We demonstrate that the stacking method substantially outperforms benchmark methods, achieving 49% accuracy on a benchmark dataset. We further evaluate our method on a recent crawl of Twitter data to investigate the impact of temporal factors on model generalisation. Our results suggest that user-declared location metadata is more sensitive to temporal change than the text of Twitter messages. We also describe two ways of accessing/demoing our system.</p><p>3 0.82116121 <a title="33-lsi-3" href="./acl-2013-Exploiting_Social_Media_for_Natural_Language_Processing%3A_Bridging_the_Gap_between_Language-centric_and_Real-world_Applications.html">146 acl-2013-Exploiting Social Media for Natural Language Processing: Bridging the Gap between Language-centric and Real-world Applications</a></p>
<p>Author: Simone Paolo Ponzetto ; Andrea Zielinski</p><p>Abstract: unkown-abstract</p><p>4 0.81345272 <a title="33-lsi-4" href="./acl-2013-An_Empirical_Study_on_Uncertainty_Identification_in_Social_Media_Context.html">45 acl-2013-An Empirical Study on Uncertainty Identification in Social Media Context</a></p>
<p>Author: Zhongyu Wei ; Junwen Chen ; Wei Gao ; Binyang Li ; Lanjun Zhou ; Yulan He ; Kam-Fai Wong</p><p>Abstract: Uncertainty text detection is important to many social-media-based applications since more and more users utilize social media platforms (e.g., Twitter, Facebook, etc.) as information source to produce or derive interpretations based on them. However, existing uncertainty cues are ineffective in social media context because of its specific characteristics. In this paper, we propose a variant of annotation scheme for uncertainty identification and construct the first uncertainty corpus based on tweets. We then conduct experiments on the generated tweets corpus to study the effectiveness of different types of features for uncertainty text identification.</p><p>5 0.73155957 <a title="33-lsi-5" href="./acl-2013-Detecting_Chronic_Critics_Based_on_Sentiment_Polarity_and_User%C3%A2%E2%80%A2%C5%BDs_Behavior_in_Social_Media.html">114 acl-2013-Detecting Chronic Critics Based on Sentiment Polarity and Userâ•Žs Behavior in Social Media</a></p>
<p>Author: Sho Takase ; Akiko Murakami ; Miki Enoki ; Naoaki Okazaki ; Kentaro Inui</p><p>Abstract: There are some chronic critics who always complain about the entity in social media. We are working to automatically detect these chronic critics to prevent the spread of bad rumors about the reputation of the entity. In social media, most comments are informal, and, there are sarcastic and incomplete contexts. This means that it is difficult for current NLP technology such as opinion mining to recognize the complaints. As an alternative approach for social media, we can assume that users who share the same opinions will link to each other. Thus, we propose a method that combines opinion mining with graph analysis for the connections between users to identify the chronic critics. Our ex- perimental results show that the proposed method outperforms analysis based only on opinion mining techniques.</p><p>6 0.71642518 <a title="33-lsi-6" href="./acl-2013-Detecting_Event-Related_Links_and_Sentiments_from_Social_Media_Texts.html">115 acl-2013-Detecting Event-Related Links and Sentiments from Social Media Texts</a></p>
<p>7 0.6807074 <a title="33-lsi-7" href="./acl-2013-Using_Conceptual_Class_Attributes_to_Characterize_Social_Media_Users.html">373 acl-2013-Using Conceptual Class Attributes to Characterize Social Media Users</a></p>
<p>8 0.6409936 <a title="33-lsi-8" href="./acl-2013-Linking_Tweets_to_News%3A_A_Framework_to_Enrich_Short_Text_Data_in_Social_Media.html">233 acl-2013-Linking Tweets to News: A Framework to Enrich Short Text Data in Social Media</a></p>
<p>9 0.63209385 <a title="33-lsi-9" href="./acl-2013-Aid_is_Out_There%3A_Looking_for_Help_from_Tweets_during_a_Large_Scale_Disaster.html">42 acl-2013-Aid is Out There: Looking for Help from Tweets during a Large Scale Disaster</a></p>
<p>10 0.62973469 <a title="33-lsi-10" href="./acl-2013-Crawling_microblogging_services_to_gather_language-classified_URLs._Workflow_and_case_study.html">95 acl-2013-Crawling microblogging services to gather language-classified URLs. Workflow and case study</a></p>
<p>11 0.60171956 <a title="33-lsi-11" href="./acl-2013-A_computational_approach_to_politeness_with_application_to_social_factors.html">30 acl-2013-A computational approach to politeness with application to social factors</a></p>
<p>12 0.5940848 <a title="33-lsi-12" href="./acl-2013-Sequential_Summarization%3A_A_New_Application_for_Timely_Updated_Twitter_Trending_Topics.html">319 acl-2013-Sequential Summarization: A New Application for Timely Updated Twitter Trending Topics</a></p>
<p>13 0.57570165 <a title="33-lsi-13" href="./acl-2013-Resolving_Entity_Morphs_in_Censored_Data.html">301 acl-2013-Resolving Entity Morphs in Censored Data</a></p>
<p>14 0.56512231 <a title="33-lsi-14" href="./acl-2013-Recognizing_Rare_Social_Phenomena_in_Conversation%3A_Empowerment_Detection_in_Support_Group_Chatrooms.html">298 acl-2013-Recognizing Rare Social Phenomena in Conversation: Empowerment Detection in Support Group Chatrooms</a></p>
<p>15 0.55859107 <a title="33-lsi-15" href="./acl-2013-Exploiting_Topic_based_Twitter_Sentiment_for_Stock_Prediction.html">147 acl-2013-Exploiting Topic based Twitter Sentiment for Stock Prediction</a></p>
<p>16 0.54467112 <a title="33-lsi-16" href="./acl-2013-Public_Dialogue%3A_Analysis_of_Tolerance_in_Online_Discussions.html">287 acl-2013-Public Dialogue: Analysis of Tolerance in Online Discussions</a></p>
<p>17 0.52956879 <a title="33-lsi-17" href="./acl-2013-Microblogs_as_Parallel_Corpora.html">240 acl-2013-Microblogs as Parallel Corpora</a></p>
<p>18 0.51671392 <a title="33-lsi-18" href="./acl-2013-Patient_Experience_in_Online_Support_Forums%3A_Modeling_Interpersonal_Interactions_and_Medication_Use.html">278 acl-2013-Patient Experience in Online Support Forums: Modeling Interpersonal Interactions and Medication Use</a></p>
<p>19 0.4887827 <a title="33-lsi-19" href="./acl-2013-Bi-directional_Inter-dependencies_of_Subjective_Expressions_and_Targets_and_their_Value_for_a_Joint_Model.html">67 acl-2013-Bi-directional Inter-dependencies of Subjective Expressions and Targets and their Value for a Joint Model</a></p>
<p>20 0.47449496 <a title="33-lsi-20" href="./acl-2013-Exploring_Sentiment_in_Social_Media%3A_Bootstrapping_Subjectivity_Clues_from_Multilingual_Twitter_Streams.html">148 acl-2013-Exploring Sentiment in Social Media: Bootstrapping Subjectivity Clues from Multilingual Twitter Streams</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.046), (6, 0.044), (11, 0.059), (15, 0.032), (24, 0.047), (26, 0.083), (28, 0.012), (35, 0.059), (38, 0.016), (42, 0.043), (48, 0.045), (59, 0.267), (70, 0.027), (88, 0.032), (90, 0.033), (95, 0.068)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.79597503 <a title="33-lda-1" href="./acl-2013-A_user-centric_model_of_voting_intention_from_Social_Media.html">33 acl-2013-A user-centric model of voting intention from Social Media</a></p>
<p>Author: Vasileios Lampos ; Daniel PreoÅ£iuc-Pietro ; Trevor Cohn</p><p>Abstract: Social Media contain a multitude of user opinions which can be used to predict realworld phenomena in many domains including politics, finance and health. Most existing methods treat these problems as linear regression, learning to relate word frequencies and other simple features to a known response variable (e.g., voting intention polls or financial indicators). These techniques require very careful filtering of the input texts, as most Social Media posts are irrelevant to the task. In this paper, we present a novel approach which performs high quality filtering automatically, through modelling not just words but also users, framed as a bilinear model with a sparse regulariser. We also consider the problem of modelling groups of related output variables, using a structured multi-task regularisation method. Our experiments on voting intention prediction demonstrate strong performance over large-scale input from Twitter on two distinct case studies, outperforming competitive baselines.</p><p>2 0.73947018 <a title="33-lda-2" href="./acl-2013-WebAnno%3A_A_Flexible%2C_Web-based_and_Visually_Supported_System_for_Distributed_Annotations.html">385 acl-2013-WebAnno: A Flexible, Web-based and Visually Supported System for Distributed Annotations</a></p>
<p>Author: Seid Muhie Yimam ; Iryna Gurevych ; Richard Eckart de Castilho ; Chris Biemann</p><p>Abstract: We present WebAnno, a general purpose web-based annotation tool for a wide range of linguistic annotations. WebAnno offers annotation project management, freely configurable tagsets and the management of users in different roles. WebAnno uses modern web technology for visualizing and editing annotations in a web browser. It supports arbitrarily large documents, pluggable import/export filters, the curation of annotations across various users, and an interface to farming out annotations to a crowdsourcing platform. Currently WebAnno allows part-ofspeech, named entity, dependency parsing and co-reference chain annotations. The architecture design allows adding additional modes of visualization and editing, when new kinds of annotations are to be supported.</p><p>3 0.72457337 <a title="33-lda-3" href="./acl-2013-Joint_Apposition_Extraction_with_Syntactic_and_Semantic_Constraints.html">205 acl-2013-Joint Apposition Extraction with Syntactic and Semantic Constraints</a></p>
<p>Author: Will Radford ; James R. Curran</p><p>Abstract: Appositions are adjacent NPs used to add information to a discourse. We propose systems exploiting syntactic and semantic constraints to extract appositions from OntoNotes. Our joint log-linear model outperforms the state-of-the-art Favre and Hakkani-T u¨r (2009) model by ∼10% on HBarokakdacnais-tT News, a9n)d m aocdheielv beys ∼541.03%% oFnscore on multiple genres.</p><p>4 0.53403646 <a title="33-lda-4" href="./acl-2013-Sentiment_Relevance.html">318 acl-2013-Sentiment Relevance</a></p>
<p>Author: Christian Scheible ; Hinrich Schutze</p><p>Abstract: A number of different notions, including subjectivity, have been proposed for distinguishing parts of documents that convey sentiment from those that do not. We propose a new concept, sentiment relevance, to make this distinction and argue that it better reflects the requirements of sentiment analysis systems. We demonstrate experimentally that sentiment relevance and subjectivity are related, but different. Since no large amount of labeled training data for our new notion of sentiment relevance is available, we investigate two semi-supervised methods for creating sentiment relevance classifiers: a distant supervision approach that leverages structured information about the domain of the reviews; and transfer learning on feature representations based on lexical taxonomies that enables knowledge transfer. We show that both methods learn sentiment relevance classifiers that perform well.</p><p>5 0.53122133 <a title="33-lda-5" href="./acl-2013-Linking_Tweets_to_News%3A_A_Framework_to_Enrich_Short_Text_Data_in_Social_Media.html">233 acl-2013-Linking Tweets to News: A Framework to Enrich Short Text Data in Social Media</a></p>
<p>Author: Weiwei Guo ; Hao Li ; Heng Ji ; Mona Diab</p><p>Abstract: Many current Natural Language Processing [NLP] techniques work well assuming a large context of text as input data. However they become ineffective when applied to short texts such as Twitter feeds. To overcome the issue, we want to find a related newswire document to a given tweet to provide contextual support for NLP tasks. This requires robust modeling and understanding of the semantics of short texts. The contribution of the paper is two-fold: 1. we introduce the Linking-Tweets-toNews task as well as a dataset of linked tweet-news pairs, which can benefit many NLP applications; 2. in contrast to previ- ous research which focuses on lexical features within the short texts (text-to-word information), we propose a graph based latent variable model that models the inter short text correlations (text-to-text information). This is motivated by the observation that a tweet usually only covers one aspect of an event. We show that using tweet specific feature (hashtag) and news specific feature (named entities) as well as temporal constraints, we are able to extract text-to-text correlations, and thus completes the semantic picture of a short text. Our experiments show significant improvement of our new model over baselines with three evaluation metrics in the new task.</p><p>6 0.52669561 <a title="33-lda-6" href="./acl-2013-A_Bayesian_Model_for_Joint_Unsupervised_Induction_of_Sentiment%2C_Aspect_and_Discourse_Representations.html">2 acl-2013-A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations</a></p>
<p>7 0.52566183 <a title="33-lda-7" href="./acl-2013-Mapping_Source_to_Target_Strings_without_Alignment_by_Analogical_Learning%3A_A_Case_Study_with_Transliteration.html">236 acl-2013-Mapping Source to Target Strings without Alignment by Analogical Learning: A Case Study with Transliteration</a></p>
<p>8 0.52554864 <a title="33-lda-8" href="./acl-2013-Explicit_and_Implicit_Syntactic_Features_for_Text_Classification.html">144 acl-2013-Explicit and Implicit Syntactic Features for Text Classification</a></p>
<p>9 0.5215773 <a title="33-lda-9" href="./acl-2013-Bilingually-Guided_Monolingual_Dependency_Grammar_Induction.html">70 acl-2013-Bilingually-Guided Monolingual Dependency Grammar Induction</a></p>
<p>10 0.52127486 <a title="33-lda-10" href="./acl-2013-Dual_Training_and_Dual_Prediction_for_Polarity_Classification.html">131 acl-2013-Dual Training and Dual Prediction for Polarity Classification</a></p>
<p>11 0.52119553 <a title="33-lda-11" href="./acl-2013-Summarization_Through_Submodularity_and_Dispersion.html">333 acl-2013-Summarization Through Submodularity and Dispersion</a></p>
<p>12 0.52096367 <a title="33-lda-12" href="./acl-2013-Part-of-Speech_Induction_in_Dependency_Trees_for_Statistical_Machine_Translation.html">276 acl-2013-Part-of-Speech Induction in Dependency Trees for Statistical Machine Translation</a></p>
<p>13 0.52036935 <a title="33-lda-13" href="./acl-2013-A_Lattice-based_Framework_for_Joint_Chinese_Word_Segmentation%2C_POS_Tagging_and_Parsing.html">7 acl-2013-A Lattice-based Framework for Joint Chinese Word Segmentation, POS Tagging and Parsing</a></p>
<p>14 0.5196377 <a title="33-lda-14" href="./acl-2013-Real-World_Semi-Supervised_Learning_of_POS-Taggers_for_Low-Resource_Languages.html">295 acl-2013-Real-World Semi-Supervised Learning of POS-Taggers for Low-Resource Languages</a></p>
<p>15 0.51904261 <a title="33-lda-15" href="./acl-2013-Detecting_Turnarounds_in_Sentiment_Analysis%3A_Thwarting.html">117 acl-2013-Detecting Turnarounds in Sentiment Analysis: Thwarting</a></p>
<p>16 0.51734459 <a title="33-lda-16" href="./acl-2013-Improving_pairwise_coreference_models_through_feature_space_hierarchy_learning.html">196 acl-2013-Improving pairwise coreference models through feature space hierarchy learning</a></p>
<p>17 0.51731992 <a title="33-lda-17" href="./acl-2013-Online_Relative_Margin_Maximization_for_Statistical_Machine_Translation.html">264 acl-2013-Online Relative Margin Maximization for Statistical Machine Translation</a></p>
<p>18 0.51699376 <a title="33-lda-18" href="./acl-2013-Collective_Annotation_of_Linguistic_Resources%3A_Basic_Principles_and_a_Formal_Model.html">83 acl-2013-Collective Annotation of Linguistic Resources: Basic Principles and a Formal Model</a></p>
<p>19 0.5163272 <a title="33-lda-19" href="./acl-2013-Unsupervised_Consonant-Vowel_Prediction_over_Hundreds_of_Languages.html">369 acl-2013-Unsupervised Consonant-Vowel Prediction over Hundreds of Languages</a></p>
<p>20 0.51588088 <a title="33-lda-20" href="./acl-2013-Crawling_microblogging_services_to_gather_language-classified_URLs._Workflow_and_case_study.html">95 acl-2013-Crawling microblogging services to gather language-classified URLs. Workflow and case study</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
