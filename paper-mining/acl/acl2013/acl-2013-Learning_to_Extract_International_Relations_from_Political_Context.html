<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>224 acl-2013-Learning to Extract International Relations from Political Context</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-224" href="#">acl2013-224</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>224 acl-2013-Learning to Extract International Relations from Political Context</h1>
<br/><p>Source: <a title="acl-2013-224-pdf" href="http://aclweb.org/anthology//P/P13/P13-1108.pdf">pdf</a></p><p>Author: Brendan O'Connor ; Brandon M. Stewart ; Noah A. Smith</p><p>Abstract: We describe a new probabilistic model for extracting events between major political actors from news corpora. Our unsupervised model brings together familiar components in natural language processing (like parsers and topic models) with contextual political information— temporal and dyad dependence—to infer latent event classes. We quantitatively evaluate the model’s performance on political science benchmarks: recovering expert-assigned event class valences, and detecting real-world conflict. We also conduct a small case study based on our model’s inferences. A supplementary appendix, and replication software/data are available online, at: http://brenocon.com/irevents</p><p>Reference: <a title="acl-2013-224-reference" href="../acl2013_reference/acl-2013-Learning_to_Extract_International_Relations_from_Political_Context_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  bstewart @ fas  Abstract We describe a new probabilistic model for extracting events between major political actors from news corpora. [sent-5, score-0.605]
</p><p>2 Our unsupervised model brings together familiar components in natural language processing (like parsers and topic models) with contextual political information— temporal and dyad dependence—to infer latent event classes. [sent-6, score-0.816]
</p><p>3 We quantitatively evaluate the model’s performance on political science benchmarks: recovering expert-assigned event class valences, and detecting real-world conflict. [sent-7, score-0.524]
</p><p>4 Scaling this data effort to modern corpora presents an information extraction challenge: can a structured collection of accurate, politically relevant events between major political actors be extracted automatically and efficiently? [sent-12, score-0.651]
</p><p>5 And can they be grouped into meaningful event types with a low-dimensional structure useful for further analysis? [sent-13, score-0.212]
</p><p>6 We present an unsupervised approach to event extraction, in which political structure and linguistic evidence are combined. [sent-14, score-0.566]
</p><p>7 Our probabilistic model infers latent frames, each a distribution over textual expressions of a kind of event, as well as a representation ofthe relationship between each political actor pair at each point in time. [sent-20, score-0.425]
</p><p>8 We use syntactic preprocessing and a logistic normal topic model, including latent temporal smoothing on the political context prior. [sent-21, score-0.578]
</p><p>9 We apply the model in a series of comparisons to benchmark datasets in political science. [sent-22, score-0.312]
</p><p>10 First, we compare the automatically learned verb classes to a pre-existing ontology and hand-crafted verb patterns from TABARI,1 an open-source and widely used rule-based event extraction system for this domain. [sent-23, score-0.386]
</p><p>11 Second, we demonstrate correlation to a database of real-world international conflict events, the Militarized Interstate Dispute (MID) dataset (Jones et al. [sent-24, score-0.21]
</p><p>12 We outline the data used for event discovery (§2), describe our model (§3), inference (§4), eval-  u(§a2ti)o,n d (§5), aen odu cro mmomdeelnt (§ on , re inlafetreden wceo (rk§4 (§6). [sent-27, score-0.212]
</p><p>13 , a 7-day period) edder isveetd E f,ro tm i sth ae a tirmticelset’esp published d-adatey, a pnedwpredpath is a textual predicate expressed as a dependency path that typically includes a verb (we use the terms “predicate-path” and “verb-path” interchangeably). [sent-39, score-0.207]
</p><p>14 Verb paths are identified by looking at the shortest dependency path between two mentions in a sentence. [sent-50, score-0.21]
</p><p>15 Finally, only paths length 4 or less are allowed, the final dependency relation for the receiver may not be nsubj or agent, and the path may not contain any of the dependency relations conj, parataxis, det, or dep. [sent-65, score-0.29]
</p><p>16 5 For topic filtering, we apply a series of keyword filters to remove sports and finance news, and also apply a text classifier for diplomatic and military news, trained on several hundred manually labeled news articles (using ‘1-regularized logistic regression with unigram and bigram features). [sent-70, score-0.258]
</p><p>17 For experiments we remove tuples where the source and receiver entities are the same, and restrict to tuples with dyads that occur at least 500 times, and predicate paths that occur at least 10 times. [sent-72, score-0.562]
</p><p>18 This yields 365,623 event tuples from 235,830 documents, for 421 dyads and 10,457  unique  predicate  paths. [sent-73, score-0.502]
</p><p>19 Our model decomposes into two submodels: a Context submodel, which encodes how political context affects the probability distribution over event types, and a Language submodel, for how those events are manifested as textual predicate paths (Figure 1). [sent-80, score-0.885]
</p><p>20 We color global parameters for a frame blue, and local context parameters red, and use the term “frame” as a synonym for “event type. [sent-82, score-0.202]
</p><p>21 •  •  The context model generates a frame prior θs,r,t fTohre every cxotnmteoxdt (s, r, t). [sent-84, score-0.202]
</p><p>22 For each frame k, draw a multinomial distribFoutrio ean ohf dependency paths, φk ∼ Dir(b/V ) (where V is the number of dependency path types). [sent-86, score-0.341]
</p><p>23 For each (s, r, t), for every event tuple i in tFhoart context, • Sample its frame ∼ Mult(θs,r,t). [sent-87, score-0.414]
</p><p>24 We use structured logistic normal distributions to represent contextual effects. [sent-90, score-0.144]
</p><p>25 The simplest is the vanilla (V) context model, •  For each frame k, draw global parameters from  •  dFiofrfu esaec priors: prevalence αk aln pda variability σomk2. [sent-91, score-0.367]
</p><p>26 For each (s, r, t), • Draw ηk,s,r,t ∼ N(αk, σk2) for each frame k. [sent-92, score-0.202]
</p><p>27 • Apply a softmax transform,  θk,s,r,t=PkK0e=x1peηxkp,sη,rk,t0,s,r,t Thus the vector η∗,s,r,tP encodes the relative logodds of the different frames for events appearing in the context (s, r, t). [sent-93, score-0.307]
</p><p>28 This simple logistic normal prior is, in terms of topic models, analogous to the asymmetric Dirichlet prior version of LDA in Wallach et al. [sent-94, score-0.187]
</p><p>29 (2009), since the αk parameter can learn that some frames tend to be more likely than others. [sent-95, score-0.129]
</p><p>30 Smoothing Frames Across Time The vanilla model is capable of inducing frames through dependency path co-occurences, when multiple events occur in a given context. [sent-97, score-0.503]
</p><p>31 However, many dyad-time slices are very sparse; for  example, most dyads (all but 18) have events in fewer than half the time slices in the dataset. [sent-98, score-0.343]
</p><p>32 Therefore we propose a smoothed frames (SF) model, in which the 1096  frame distribution for a given dyad comes from a latent parameter β∗,s,r,t that smoothly varies over time. [sent-102, score-0.627]
</p><p>33 For each (s, r), draw the first timestep’s values as βk,s,r,1 ∼ N(0, 100), and for each context (s, r, t > 1),  • •  Draw βk,s,r,t ∼ N(βk,s,r,t−1, Draw ηk,s,r,t ∼  τ2)  N(αk + βk,s,r,t, σk2)  Other parameters (αk, σk2) are same as the vanilla model. [sent-103, score-0.165]
</p><p>34 Thus inferences about η will be smoothed according to event data at nearby timesteps. [sent-105, score-0.295]
</p><p>35 Dynamic linear models have been used elsewhere in machine learning and political science to allow latent topic frequencies (Blei and Lafferty, 2006; Quinn et al. [sent-107, score-0.395]
</p><p>36 The language model sampler sequentially up-  z(i)  dates every (and implicitly φ via collapsing) in the manner of Griffiths and Steyvers (2004): ∝ θs,r,t,z(nw,z + b/V )/(nz + b), where| θco,wunts, n are θfor all event tuples besides i. [sent-110, score-0.279]
</p><p>37 While Gibbs sampling for logistic normal priors is possible using auxiliary variable methods (Mimno et al. [sent-115, score-0.189]
</p><p>38 5  Experiments  We fit the two models on the dataset described in §2, varying the number of frames K, with 8 or more separate runs mfobre eera cofh setting. [sent-131, score-0.129]
</p><p>39 1 Lexical Scale Impurity In the international relations literature, much of the analysis of text-based events data makes use of a unidimensional conflict to cooperation scale. [sent-139, score-0.388]
</p><p>40 A popular event ontology in this domain, CAMEO,  consists of around 300 different event types, each 1097  given an expert-assigned scale in the range from −10 to +10 (Gerner et al. [sent-140, score-0.463]
</p><p>41 The TABARI pattern-based event extraction program comes with a list of almost 16,000 manually engineered verb patterns, each assigned to one CAMEO event type. [sent-142, score-0.534]
</p><p>42 “Express intent to de-escalate military engagement”), we elect to measure model quality as lexical scale purity: whether all the predicate paths within one automatically learned frame tend to have similar gold-standard scale scores. [sent-146, score-0.512]
</p><p>43 ) To calculate this, we construct a mapping between our corpus-derived  verb path vocabulary and the TABARI verb patterns, many of which contain one to several word stems that are intended to be matched in surface order. [sent-148, score-0.213]
</p><p>44 6 Therefore we convert each path to a word sequence and match against the TABARI lexicon—plus a few modifications for differences in infinitives and stemming—and find 528 dependency path matches. [sent-150, score-0.17]
</p><p>45 We assign each path w a gold-standard scale g(w) by resolving through its matching pattern’s CAMEO code. [sent-151, score-0.124]
</p><p>46 We formalize lexical scale impurity as the average absolute difference of scale values between two predicate paths under the same frame. [sent-152, score-0.352]
</p><p>47 Specifically, we want a token-level posterior expectation E( |g(wi)  −  g(wj) | |  zi  =  zj  , wi  = wj)  (1)  which is taken over pairs of path instances (i, j) where both paths wi, wj are in M, the set of verb paths that were matched between the lexicons. [sent-153, score-0.436]
</p><p>48 where n refers to the averaged Gibbs samples’ counts of event tuples having frame k and a particular verb path,8 and N is the number of token comparisons (i. [sent-157, score-0.545]
</p><p>49 g W(we a)ls −o compute a randomized null hypothesis to see how low impurity can be by chance: each of ∼1000 lsoiwmuil matpiounrsit randomly assigns eea:c he path fin ∼ M10 0to0 one of K frames (all its instances are exclusively assigned to that frame), and computes the impurity. [sent-161, score-0.305]
</p><p>50 On average the impurity is same at all K, but variance increases with K (since small clus−  ters might by chance get a highly similar paths in them), necessitating this null hypothesis analysis. [sent-162, score-0.216]
</p><p>51 2 Conflict Detection Political events data has shown considerable promise as a tool for crisis early warning systems (O’Brien, 2010; Brandt et al. [sent-165, score-0.178]
</p><p>52 While conflict forecasting is a potential application of our model, we conduct a simpler prediction task to validate whether the model is learning something useful: based on news text, tell whether or not an armed conflict is currently happening. [sent-167, score-0.465]
</p><p>53 We use the Dyadic MIDs, each of which ranks hostility levels between pairs of actors on a five point scale over a date interval; we define conflict to be the top two categories “Use of Force” (4) and “War” (5). [sent-172, score-0.401]
</p><p>54 We convert the data into a variable ys,r,t, the highest hostility  level reached by actor s directed towards receiver r in the dispute that overlaps with our 7-day interval t, and want to predict the binary indicator 1{ys,r,t ≥ 4}. [sent-173, score-0.348]
</p><p>55 Frames corresponding to material and verbal conflict were chosen for display. [sent-182, score-0.21]
</p><p>56 These cases highlight MID’s limitations—while it is well regarded in the political science literature, its coarse level of aggregation can fail to capture variation in conflict intensity. [sent-195, score-0.522]
</p><p>57 After excluding dyads with actors that the MID data does not intend to include—Kosovo, Tibet, Palestine, and international organizations—we have 267 directed dyads for evaluation, 117 of which have at least one dispute in the MID data. [sent-200, score-0.603]
</p><p>58 We also create a baseline ‘1-regularized logistic regression that uses normalized dependency path counts as the features (10,457 features). [sent-207, score-0.206]
</p><p>59 For both the baseline and vanilla model, contexts with no events are given a feature vector of all zeros. [sent-208, score-0.289]
</p><p>60 11 (We also explored an alternative evaluation setup, to hold out by dyad; however, the performance  variance is quite high between different random dyad splits. [sent-209, score-0.128]
</p><p>61 3 Results Results are shown in Figure The verb-path logistic regression performs strongly at AUC 0. [sent-211, score-0.121]
</p><p>62 5 2G3 45G102 5G01 mGodSVNemaulnoiathed Number of frames (K)  Number of frames (K)  Figure 3: Evaluation results. [sent-229, score-0.258]
</p><p>63 Note also, the vanilla model exhibits very little variability in prediction performance between model runs, in comparison to the smoothed model which is much more variable (presumably due to the higher number of parameters in the model); at small values of K, the smoothed model can perform poorly. [sent-248, score-0.277]
</p><p>64 We view the conflict detection task only as one of several validations, and thus turn to lexical evaluation of the induced frames. [sent-250, score-0.21]
</p><p>65 For lexical scale purity (bottom of Figure 3), the models perform  about the same, with the smoothed model a little bit worse at some values of K (though sometimes with better stability of the fits—opposite of range temporal dependencies. [sent-251, score-0.161]
</p><p>66 4 Case study Here we qualitatively examine the narrative story between the dyad with the highest frequency of events in our dataset, the Israeli-Palestinian relationship, finding qualitative agreement with other case studies of this conflict (Brandt et al. [sent-255, score-0.516]
</p><p>67 (The MID dataset does not include this conflict because the Palestinians are not considered a state actor. [sent-258, score-0.21]
</p><p>68 ) Using the Associated Press subset, we plot the highest incidence frames from one run of the K = 20 smoothed frame models, for the two directed dyads, and highlight some of the interesting relationships. [sent-259, score-0.453]
</p><p>69 The first period in the data where police actions (‘impose, seal, capture, seize, arrest’) exceed military actions (‘kill, fire, enter, attack, raid’) is with the signing of the “Interim Agreement on the West Bank and the Gaza Strip,” also known as the Oslo II agreement. [sent-262, score-0.131]
</p><p>70 In Figure 4(b) we show that our model produces a frame which captures the legal aftermath of particular events (‘accuse, criticize,’ but also ‘detain, release, extradite, charge’). [sent-264, score-0.38]
</p><p>71 Each of the major spikes in the data coincides with a particular event which either involves the investigation of a particular attack or series of attacks (as in A,B,E) or a discussion about prisoner swaps or mass arrests (as in events D, F, J). [sent-265, score-0.39]
</p><p>72 Our model also picks up positive diplomatic  events, as seen in Figure 4(c), a frame describing Israeli diplomatic actions towards Palestine (‘meet with, sign with, praise, say with, arrive in’). [sent-266, score-0.333]
</p><p>73 In Figure 4(d) we show the relevant frames de-  1100  Israeli Use of Force Tradeoff  Palestinian Use of Force  Figure 4: For Israel-Palestinian directed dyads, plots of E[θ] (proportion of weekly events in a frame) over time, annotated with historical events. [sent-270, score-0.399]
</p><p>74 At first, the drop in the use of force frame immediately following the start of the Second Intifada seems inconsistent with the historical record. [sent-275, score-0.306]
</p><p>75 However, there is a concucrrent rise in a different frame driven by the word ‘include’, which actually appears here due to an NLP error compounded with an artifact of the data source. [sent-276, score-0.202]
</p><p>76 We conclude the frame extractions for the Israeli-Palestinian case are consistent with the historical record over the period of study. [sent-288, score-0.255]
</p><p>77 1 Events Data in Political Science Projects using hand-collected events data represent some of the earliest efforts in the statistical study of international relations, dating back to the 1960s (Rummel, 1968; Azar and Sloan, 1975;  McClelland, 1970). [sent-290, score-0.178]
</p><p>78 Beginning in the mid-1980s, political scientists began experimenting with automated rule-based extraction systems (Schrodt and Gerner, 1994). [sent-291, score-0.358]
</p><p>79 The origi1101  nal TABARI system is still actively being devel-  oped, including just-released work on a new 200 million event dataset, GDELT (Schrodt and Leetaru, 2013). [sent-300, score-0.212]
</p><p>80 Schrodt (2006) estimates 4,000 trained person-hours were required to create dictionaries of political actors in the Middle East, and the phrase dictionary took dramatically longer; the comments in TABARI’s phrase dictionary indicate some of its 15,789 entries were created as early as 1991 . [sent-303, score-0.427]
</p><p>81 Ideally, any new events data solution would incorporate the extensive work already completed by political scientists in this area while minimizing the need for further dictionary development. [sent-304, score-0.49]
</p><p>82 In this work we use the actor dictionaries, and hope to incorporate the verb patterns in future work. [sent-305, score-0.137]
</p><p>83 , 1999; Gildea, 2002; Grenager and Manning, 2006; Lang and Lapata, 2010; O´ S ´eaghdha, 2010; Titov and Klementiev, 2012), and a version of frame learning called “unsupervised semantic parsing” (Titov and Klementiev, 2011; Poon and Domingos, 2009). [sent-316, score-0.202]
</p><p>84 Event extraction is also a large literature, including supervised systems targeting problems similar to MUC and political events (Piskorski and Atkinson, 2011; Piskorski  et al. [sent-318, score-0.536]
</p><p>85 (Gerrish also analyzed the international relations domain, using supervised bag-of-words regression to assess the expressed valence between a pair of actors in a news paragraph, using the predictions as observations in a latent temporal model, and compared to MID. [sent-329, score-0.235]
</p><p>86 7  Conclusion  Large-scale information extraction can dramatically enhance the study of political behavior. [sent-334, score-0.358]
</p><p>87 Automatic extraction of events from open source text for predictive forecasting. [sent-380, score-0.224]
</p><p>88 Real time, time series forecasting of inter-and intra-state political conflict. [sent-389, score-0.357]
</p><p>89 A Bayesian time series approach to the comparison of conflict dynamics. [sent-400, score-0.21]
</p><p>90 Regularization paths for generalized linear models via coordinate descent. [sent-489, score-0.125]
</p><p>91 An automated information extraction tool for international conflict data with performance as good as human coders: A rare events evaluation design. [sent-589, score-0.434]
</p><p>92 Domainindependent novel event discovery and semi-automatic 1103  event annotation. [sent-614, score-0.424]
</p><p>93 Some effects on theory from the international event analysis movement. [sent-627, score-0.212]
</p><p>94 Gibbs sampling for logistic normal topic models with graphbased priors. [sent-633, score-0.187]
</p><p>95 Bayesian inference for logistic models using Polya-Gamma latent variables. [sent-698, score-0.12]
</p><p>96 How to analyze political attention with minimal assumptions and costs. [sent-717, score-0.312]
</p><p>97 Automated coding of international event data using sparse parsing techniques. [sent-798, score-0.212]
</p><p>98 Validity assessment of a machine-coded event data set for the Middle East,  1982-1992. [sent-810, score-0.212]
</p><p>99 An event data analysis of third-party mediation in the middle east and balkans. [sent-817, score-0.289]
</p><p>100 Time series intervals and statistical inference: The effects of temporal aggregation on event data analysis. [sent-822, score-0.251]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('political', 0.312), ('schrodt', 0.274), ('event', 0.212), ('conflict', 0.21), ('frame', 0.202), ('mid', 0.183), ('events', 0.178), ('dyads', 0.165), ('tabari', 0.146), ('frames', 0.129), ('dyad', 0.128), ('gerner', 0.128), ('paths', 0.125), ('dispute', 0.119), ('actors', 0.115), ('vanilla', 0.111), ('impurity', 0.091), ('path', 0.085), ('smoothed', 0.083), ('pse', 0.081), ('logistic', 0.08), ('receiver', 0.08), ('gerrish', 0.075), ('brandt', 0.073), ('cameo', 0.073), ('seize', 0.073), ('actor', 0.073), ('auc', 0.07), ('tuples', 0.067), ('normal', 0.064), ('verb', 0.064), ('piskorski', 0.06), ('peace', 0.06), ('friedman', 0.06), ('predicate', 0.058), ('klementiev', 0.058), ('palestinian', 0.056), ('quinn', 0.056), ('boschee', 0.055), ('gdelt', 0.055), ('interstate', 0.055), ('militarized', 0.055), ('palestinians', 0.055), ('titov', 0.055), ('draw', 0.054), ('historical', 0.053), ('force', 0.051), ('weeks', 0.049), ('military', 0.049), ('gibbs', 0.049), ('rzhetsky', 0.048), ('blei', 0.047), ('extraction', 0.046), ('priors', 0.045), ('accuse', 0.045), ('iraq', 0.045), ('diplomatic', 0.045), ('forecasting', 0.045), ('smoothly', 0.045), ('topic', 0.043), ('unsupervised', 0.042), ('atkinson', 0.042), ('gigaword', 0.042), ('actions', 0.041), ('regression', 0.041), ('arxiv', 0.041), ('kill', 0.041), ('israeli', 0.04), ('east', 0.04), ('latent', 0.04), ('directed', 0.039), ('scale', 0.039), ('temporal', 0.039), ('west', 0.038), ('covariance', 0.038), ('posterior', 0.037), ('chambers', 0.037), ('allegation', 0.037), ('azar', 0.037), ('bremer', 0.037), ('carley', 0.037), ('cohesiveness', 0.037), ('desert', 0.037), ('detain', 0.037), ('diesner', 0.037), ('dyadic', 0.037), ('fastus', 0.037), ('freeman', 0.037), ('ghosn', 0.037), ('hobbs', 0.037), ('hoff', 0.037), ('hostility', 0.037), ('karim', 0.037), ('leetaru', 0.037), ('mediation', 0.037), ('psu', 0.037), ('raid', 0.037), ('rajaraman', 0.037), ('seal', 0.037), ('serif', 0.037)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.000002 <a title="224-tfidf-1" href="./acl-2013-Learning_to_Extract_International_Relations_from_Political_Context.html">224 acl-2013-Learning to Extract International Relations from Political Context</a></p>
<p>Author: Brendan O'Connor ; Brandon M. Stewart ; Noah A. Smith</p><p>Abstract: We describe a new probabilistic model for extracting events between major political actors from news corpora. Our unsupervised model brings together familiar components in natural language processing (like parsers and topic models) with contextual political information— temporal and dyad dependence—to infer latent event classes. We quantitatively evaluate the model’s performance on political science benchmarks: recovering expert-assigned event class valences, and detecting real-world conflict. We also conduct a small case study based on our model’s inferences. A supplementary appendix, and replication software/data are available online, at: http://brenocon.com/irevents</p><p>2 0.16324717 <a title="224-tfidf-2" href="./acl-2013-Argument_Inference_from_Relevant_Event_Mentions_in_Chinese_Argument_Extraction.html">56 acl-2013-Argument Inference from Relevant Event Mentions in Chinese Argument Extraction</a></p>
<p>Author: Peifeng Li ; Qiaoming Zhu ; Guodong Zhou</p><p>Abstract: As a paratactic language, sentence-level argument extraction in Chinese suffers much from the frequent occurrence of ellipsis with regard to inter-sentence arguments. To resolve such problem, this paper proposes a novel global argument inference model to explore specific relationships, such as Coreference, Sequence and Parallel, among relevant event mentions to recover those intersentence arguments in the sentence, discourse and document layers which represent the cohesion of an event or a topic. Evaluation on the ACE 2005 Chinese corpus justifies the effectiveness of our global argument inference model over a state-of-the-art baseline. 1</p><p>3 0.1539841 <a title="224-tfidf-3" href="./acl-2013-Recognizing_Identical_Events_with_Graph_Kernels.html">296 acl-2013-Recognizing Identical Events with Graph Kernels</a></p>
<p>Author: Goran Glavas ; Jan Snajder</p><p>Abstract: Identifying news stories that discuss the same real-world events is important for news tracking and retrieval. Most existing approaches rely on the traditional vector space model. We propose an approach for recognizing identical real-world events based on a structured, event-oriented document representation. We structure documents as graphs of event mentions and use graph kernels to measure the similarity between document pairs. Our experiments indicate that the proposed graph-based approach can outperform the traditional vector space model, and is especially suitable for distinguishing between topically similar, yet non-identical events.</p><p>4 0.14644355 <a title="224-tfidf-4" href="./acl-2013-Extracting_Events_with_Informal_Temporal_References_in_Personal_Histories_in_Online_Communities.html">153 acl-2013-Extracting Events with Informal Temporal References in Personal Histories in Online Communities</a></p>
<p>Author: Miaomiao Wen ; Zeyu Zheng ; Hyeju Jang ; Guang Xiang ; Carolyn Penstein Rose</p><p>Abstract: We present a system for extracting the dates of illness events (year and month of the event occurrence) from posting histories in the context of an online medical support community. A temporal tagger retrieves and normalizes dates mentioned informally in social media to actual month and year referents. Building on this, an event date extraction system learns to integrate the likelihood of candidate dates extracted from time-rich sentences with temporal constraints extracted from eventrelated sentences. Our integrated model achieves 89.7% of the maximum performance given the performance of the temporal expression retrieval step.</p><p>5 0.13566341 <a title="224-tfidf-5" href="./acl-2013-Outsourcing_FrameNet_to_the_Crowd.html">265 acl-2013-Outsourcing FrameNet to the Crowd</a></p>
<p>Author: Marco Fossati ; Claudio Giuliano ; Sara Tonelli</p><p>Abstract: We present the first attempt to perform full FrameNet annotation with crowdsourcing techniques. We compare two approaches: the first one is the standard annotation methodology of lexical units and frame elements in two steps, while the second is a novel approach aimed at acquiring frames in a bottom-up fashion, starting from frame element annotation. We show that our methodology, relying on a single annotation step and on simplified role definitions, outperforms the standard one both in terms of accuracy and time.</p><p>6 0.13330643 <a title="224-tfidf-6" href="./acl-2013-Semantic_Frames_to_Predict_Stock_Price_Movement.html">310 acl-2013-Semantic Frames to Predict Stock Price Movement</a></p>
<p>7 0.13317581 <a title="224-tfidf-7" href="./acl-2013-Joint_Event_Extraction_via_Structured_Prediction_with_Global_Features.html">206 acl-2013-Joint Event Extraction via Structured Prediction with Global Features</a></p>
<p>8 0.11140093 <a title="224-tfidf-8" href="./acl-2013-Probabilistic_Domain_Modelling_With_Contextualized_Distributional_Semantic_Vectors.html">283 acl-2013-Probabilistic Domain Modelling With Contextualized Distributional Semantic Vectors</a></p>
<p>9 0.10866798 <a title="224-tfidf-9" href="./acl-2013-A_Structured_Distributional_Semantic_Model_for_Event_Co-reference.html">22 acl-2013-A Structured Distributional Semantic Model for Event Co-reference</a></p>
<p>10 0.1080723 <a title="224-tfidf-10" href="./acl-2013-PARMA%3A_A_Predicate_Argument_Aligner.html">267 acl-2013-PARMA: A Predicate Argument Aligner</a></p>
<p>11 0.10012327 <a title="224-tfidf-11" href="./acl-2013-Discovering_User_Interactions_in_Ideological_Discussions.html">121 acl-2013-Discovering User Interactions in Ideological Discussions</a></p>
<p>12 0.098959662 <a title="224-tfidf-12" href="./acl-2013-Improved_Bayesian_Logistic_Supervised_Topic_Models_with_Data_Augmentation.html">191 acl-2013-Improved Bayesian Logistic Supervised Topic Models with Data Augmentation</a></p>
<p>13 0.091569409 <a title="224-tfidf-13" href="./acl-2013-A_user-centric_model_of_voting_intention_from_Social_Media.html">33 acl-2013-A user-centric model of voting intention from Social Media</a></p>
<p>14 0.087241635 <a title="224-tfidf-14" href="./acl-2013-Diathesis_alternation_approximation_for_verb_clustering.html">119 acl-2013-Diathesis alternation approximation for verb clustering</a></p>
<p>15 0.08272326 <a title="224-tfidf-15" href="./acl-2013-Learning_Latent_Personas_of_Film_Characters.html">220 acl-2013-Learning Latent Personas of Film Characters</a></p>
<p>16 0.081385046 <a title="224-tfidf-16" href="./acl-2013-HEADY%3A_News_headline_abstraction_through_event_pattern_clustering.html">178 acl-2013-HEADY: News headline abstraction through event pattern clustering</a></p>
<p>17 0.077810094 <a title="224-tfidf-17" href="./acl-2013-Exploiting_Social_Media_for_Natural_Language_Processing%3A_Bridging_the_Gap_between_Language-centric_and_Real-world_Applications.html">146 acl-2013-Exploiting Social Media for Natural Language Processing: Bridging the Gap between Language-centric and Real-world Applications</a></p>
<p>18 0.076099291 <a title="224-tfidf-18" href="./acl-2013-Cross-lingual_Transfer_of_Semantic_Role_Labeling_Models.html">98 acl-2013-Cross-lingual Transfer of Semantic Role Labeling Models</a></p>
<p>19 0.0744766 <a title="224-tfidf-19" href="./acl-2013-Temporal_Signals_Help_Label_Temporal_Relations.html">339 acl-2013-Temporal Signals Help Label Temporal Relations</a></p>
<p>20 0.074065715 <a title="224-tfidf-20" href="./acl-2013-SPred%3A_Large-scale_Harvesting_of_Semantic_Predicates.html">306 acl-2013-SPred: Large-scale Harvesting of Semantic Predicates</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.222), (1, 0.09), (2, -0.022), (3, -0.089), (4, 0.004), (5, 0.115), (6, 0.059), (7, 0.121), (8, -0.055), (9, -0.009), (10, -0.003), (11, -0.03), (12, 0.038), (13, 0.015), (14, -0.01), (15, -0.088), (16, -0.077), (17, 0.009), (18, 0.114), (19, -0.043), (20, 0.051), (21, -0.135), (22, 0.011), (23, -0.015), (24, 0.015), (25, -0.092), (26, -0.145), (27, -0.079), (28, -0.001), (29, 0.031), (30, 0.053), (31, 0.033), (32, -0.017), (33, -0.037), (34, 0.008), (35, -0.067), (36, -0.067), (37, -0.054), (38, -0.005), (39, 0.032), (40, 0.085), (41, -0.022), (42, -0.049), (43, -0.026), (44, -0.073), (45, 0.045), (46, -0.133), (47, -0.018), (48, -0.007), (49, 0.041)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92529589 <a title="224-lsi-1" href="./acl-2013-Learning_to_Extract_International_Relations_from_Political_Context.html">224 acl-2013-Learning to Extract International Relations from Political Context</a></p>
<p>Author: Brendan O'Connor ; Brandon M. Stewart ; Noah A. Smith</p><p>Abstract: We describe a new probabilistic model for extracting events between major political actors from news corpora. Our unsupervised model brings together familiar components in natural language processing (like parsers and topic models) with contextual political information— temporal and dyad dependence—to infer latent event classes. We quantitatively evaluate the model’s performance on political science benchmarks: recovering expert-assigned event class valences, and detecting real-world conflict. We also conduct a small case study based on our model’s inferences. A supplementary appendix, and replication software/data are available online, at: http://brenocon.com/irevents</p><p>2 0.65519947 <a title="224-lsi-2" href="./acl-2013-Extracting_Events_with_Informal_Temporal_References_in_Personal_Histories_in_Online_Communities.html">153 acl-2013-Extracting Events with Informal Temporal References in Personal Histories in Online Communities</a></p>
<p>Author: Miaomiao Wen ; Zeyu Zheng ; Hyeju Jang ; Guang Xiang ; Carolyn Penstein Rose</p><p>Abstract: We present a system for extracting the dates of illness events (year and month of the event occurrence) from posting histories in the context of an online medical support community. A temporal tagger retrieves and normalizes dates mentioned informally in social media to actual month and year referents. Building on this, an event date extraction system learns to integrate the likelihood of candidate dates extracted from time-rich sentences with temporal constraints extracted from eventrelated sentences. Our integrated model achieves 89.7% of the maximum performance given the performance of the temporal expression retrieval step.</p><p>3 0.65426701 <a title="224-lsi-3" href="./acl-2013-Recognizing_Identical_Events_with_Graph_Kernels.html">296 acl-2013-Recognizing Identical Events with Graph Kernels</a></p>
<p>Author: Goran Glavas ; Jan Snajder</p><p>Abstract: Identifying news stories that discuss the same real-world events is important for news tracking and retrieval. Most existing approaches rely on the traditional vector space model. We propose an approach for recognizing identical real-world events based on a structured, event-oriented document representation. We structure documents as graphs of event mentions and use graph kernels to measure the similarity between document pairs. Our experiments indicate that the proposed graph-based approach can outperform the traditional vector space model, and is especially suitable for distinguishing between topically similar, yet non-identical events.</p><p>4 0.64681655 <a title="224-lsi-4" href="./acl-2013-Semantic_Frames_to_Predict_Stock_Price_Movement.html">310 acl-2013-Semantic Frames to Predict Stock Price Movement</a></p>
<p>Author: Boyi Xie ; Rebecca J. Passonneau ; Leon Wu ; German G. Creamer</p><p>Abstract: Semantic frames are a rich linguistic resource. There has been much work on semantic frame parsers, but less that applies them to general NLP problems. We address a task to predict change in stock price from financial news. Semantic frames help to generalize from specific sentences to scenarios, and to detect the (positive or negative) roles of specific companies. We introduce a novel tree representation, and use it to train predictive models with tree kernels using support vector machines. Our experiments test multiple text representations on two binary classification tasks, change of price and polarity. Experiments show that features derived from semantic frame parsing have significantly better performance across years on the polarity task.</p><p>5 0.63336796 <a title="224-lsi-5" href="./acl-2013-Outsourcing_FrameNet_to_the_Crowd.html">265 acl-2013-Outsourcing FrameNet to the Crowd</a></p>
<p>Author: Marco Fossati ; Claudio Giuliano ; Sara Tonelli</p><p>Abstract: We present the first attempt to perform full FrameNet annotation with crowdsourcing techniques. We compare two approaches: the first one is the standard annotation methodology of lexical units and frame elements in two steps, while the second is a novel approach aimed at acquiring frames in a bottom-up fashion, starting from frame element annotation. We show that our methodology, relying on a single annotation step and on simplified role definitions, outperforms the standard one both in terms of accuracy and time.</p><p>6 0.57098001 <a title="224-lsi-6" href="./acl-2013-Argument_Inference_from_Relevant_Event_Mentions_in_Chinese_Argument_Extraction.html">56 acl-2013-Argument Inference from Relevant Event Mentions in Chinese Argument Extraction</a></p>
<p>7 0.56182498 <a title="224-lsi-7" href="./acl-2013-Grounded_Language_Learning_from_Video_Described_with_Sentences.html">175 acl-2013-Grounded Language Learning from Video Described with Sentences</a></p>
<p>8 0.55918992 <a title="224-lsi-8" href="./acl-2013-Diathesis_alternation_approximation_for_verb_clustering.html">119 acl-2013-Diathesis alternation approximation for verb clustering</a></p>
<p>9 0.55834407 <a title="224-lsi-9" href="./acl-2013-Joint_Event_Extraction_via_Structured_Prediction_with_Global_Features.html">206 acl-2013-Joint Event Extraction via Structured Prediction with Global Features</a></p>
<p>10 0.55794376 <a title="224-lsi-10" href="./acl-2013-HEADY%3A_News_headline_abstraction_through_event_pattern_clustering.html">178 acl-2013-HEADY: News headline abstraction through event pattern clustering</a></p>
<p>11 0.5405094 <a title="224-lsi-11" href="./acl-2013-A_Structured_Distributional_Semantic_Model_for_Event_Co-reference.html">22 acl-2013-A Structured Distributional Semantic Model for Event Co-reference</a></p>
<p>12 0.53971189 <a title="224-lsi-12" href="./acl-2013-Probabilistic_Domain_Modelling_With_Contextualized_Distributional_Semantic_Vectors.html">283 acl-2013-Probabilistic Domain Modelling With Contextualized Distributional Semantic Vectors</a></p>
<p>13 0.5387463 <a title="224-lsi-13" href="./acl-2013-Language_Acquisition_and_Probabilistic_Models%3A_keeping_it_simple.html">213 acl-2013-Language Acquisition and Probabilistic Models: keeping it simple</a></p>
<p>14 0.49848062 <a title="224-lsi-14" href="./acl-2013-Evolutionary_Hierarchical_Dirichlet_Process_for_Timeline_Summarization.html">142 acl-2013-Evolutionary Hierarchical Dirichlet Process for Timeline Summarization</a></p>
<p>15 0.49673876 <a title="224-lsi-15" href="./acl-2013-The_mathematics_of_language_learning.html">349 acl-2013-The mathematics of language learning</a></p>
<p>16 0.49649283 <a title="224-lsi-16" href="./acl-2013-Exploring_Word_Order_Universals%3A_a_Probabilistic_Graphical_Model_Approach.html">149 acl-2013-Exploring Word Order Universals: a Probabilistic Graphical Model Approach</a></p>
<p>17 0.49087915 <a title="224-lsi-17" href="./acl-2013-Improved_Lexical_Acquisition_through_DPP-based_Verb_Clustering.html">192 acl-2013-Improved Lexical Acquisition through DPP-based Verb Clustering</a></p>
<p>18 0.4758662 <a title="224-lsi-18" href="./acl-2013-Improved_Bayesian_Logistic_Supervised_Topic_Models_with_Data_Augmentation.html">191 acl-2013-Improved Bayesian Logistic Supervised Topic Models with Data Augmentation</a></p>
<p>19 0.46649018 <a title="224-lsi-19" href="./acl-2013-Learning_Latent_Personas_of_Film_Characters.html">220 acl-2013-Learning Latent Personas of Film Characters</a></p>
<p>20 0.46199626 <a title="224-lsi-20" href="./acl-2013-PARMA%3A_A_Predicate_Argument_Aligner.html">267 acl-2013-PARMA: A Predicate Argument Aligner</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.05), (6, 0.035), (11, 0.05), (15, 0.023), (24, 0.049), (26, 0.054), (35, 0.072), (36, 0.188), (42, 0.041), (48, 0.051), (56, 0.01), (64, 0.016), (70, 0.094), (80, 0.011), (88, 0.024), (90, 0.022), (95, 0.061)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.9168539 <a title="224-lda-1" href="./acl-2013-Variable_Bit_Quantisation_for_LSH.html">381 acl-2013-Variable Bit Quantisation for LSH</a></p>
<p>Author: Sean Moran ; Victor Lavrenko ; Miles Osborne</p><p>Abstract: We introduce a scheme for optimally allocating a variable number of bits per LSH hyperplane. Previous approaches assign a constant number of bits per hyperplane. This neglects the fact that a subset of hyperplanes may be more informative than others. Our method, dubbed Variable Bit Quantisation (VBQ), provides a datadriven non-uniform bit allocation across hyperplanes. Despite only using a fraction of the available hyperplanes, VBQ outperforms uniform quantisation by up to 168% for retrieval across standard text and image datasets.</p><p>same-paper 2 0.83527827 <a title="224-lda-2" href="./acl-2013-Learning_to_Extract_International_Relations_from_Political_Context.html">224 acl-2013-Learning to Extract International Relations from Political Context</a></p>
<p>Author: Brendan O'Connor ; Brandon M. Stewart ; Noah A. Smith</p><p>Abstract: We describe a new probabilistic model for extracting events between major political actors from news corpora. Our unsupervised model brings together familiar components in natural language processing (like parsers and topic models) with contextual political information— temporal and dyad dependence—to infer latent event classes. We quantitatively evaluate the model’s performance on political science benchmarks: recovering expert-assigned event class valences, and detecting real-world conflict. We also conduct a small case study based on our model’s inferences. A supplementary appendix, and replication software/data are available online, at: http://brenocon.com/irevents</p><p>3 0.75425351 <a title="224-lda-3" href="./acl-2013-ICARUS_-_An_Extensible_Graphical_Search_Tool_for_Dependency_Treebanks.html">183 acl-2013-ICARUS - An Extensible Graphical Search Tool for Dependency Treebanks</a></p>
<p>Author: Markus Gartner ; Gregor Thiele ; Wolfgang Seeker ; Anders Bjorkelund ; Jonas Kuhn</p><p>Abstract: We present ICARUS, a versatile graphical search tool to query dependency treebanks. Search results can be inspected both quantitatively and qualitatively by means of frequency lists, tables, or dependency graphs. ICARUS also ships with plugins that enable it to interface with tool chains running either locally or remotely.</p><p>4 0.66885078 <a title="224-lda-4" href="./acl-2013-Models_of_Semantic_Representation_with_Visual_Attributes.html">249 acl-2013-Models of Semantic Representation with Visual Attributes</a></p>
<p>Author: Carina Silberer ; Vittorio Ferrari ; Mirella Lapata</p><p>Abstract: We consider the problem of grounding the meaning of words in the physical world and focus on the visual modality which we represent by visual attributes. We create a new large-scale taxonomy of visual attributes covering more than 500 concepts and their corresponding 688K images. We use this dataset to train attribute classifiers and integrate their predictions with text-based distributional models of word meaning. We show that these bimodal models give a better fit to human word association data compared to amodal models and word representations based on handcrafted norming data.</p><p>5 0.66772383 <a title="224-lda-5" href="./acl-2013-Statistical_Machine_Translation_Improves_Question_Retrieval_in_Community_Question_Answering_via_Matrix_Factorization.html">329 acl-2013-Statistical Machine Translation Improves Question Retrieval in Community Question Answering via Matrix Factorization</a></p>
<p>Author: Guangyou Zhou ; Fang Liu ; Yang Liu ; Shizhu He ; Jun Zhao</p><p>Abstract: Community question answering (CQA) has become an increasingly popular research topic. In this paper, we focus on the problem of question retrieval. Question retrieval in CQA can automatically find the most relevant and recent questions that have been solved by other users. However, the word ambiguity and word mismatch problems bring about new challenges for question retrieval in CQA. State-of-the-art approaches address these issues by implicitly expanding the queried questions with additional words or phrases using monolingual translation models. While useful, the effectiveness of these models is highly dependent on the availability of quality parallel monolingual corpora (e.g., question-answer pairs) in the absence of which they are troubled by noise issue. In this work, we propose an alternative way to address the word ambiguity and word mismatch problems by taking advantage of potentially rich semantic information drawn from other languages. Our proposed method employs statistical machine translation to improve question retrieval and enriches the question representation with the translated words from other languages via matrix factorization. Experiments conducted on a real CQA data show that our proposed approach is promising.</p><p>6 0.65769935 <a title="224-lda-6" href="./acl-2013-Paraphrase-Driven_Learning_for_Open_Question_Answering.html">272 acl-2013-Paraphrase-Driven Learning for Open Question Answering</a></p>
<p>7 0.65745759 <a title="224-lda-7" href="./acl-2013-Transfer_Learning_Based_Cross-lingual_Knowledge_Extraction_for_Wikipedia.html">356 acl-2013-Transfer Learning Based Cross-lingual Knowledge Extraction for Wikipedia</a></p>
<p>8 0.65712255 <a title="224-lda-8" href="./acl-2013-Generating_Synthetic_Comparable_Questions_for_News_Articles.html">169 acl-2013-Generating Synthetic Comparable Questions for News Articles</a></p>
<p>9 0.65616506 <a title="224-lda-9" href="./acl-2013-Chinese_Parsing_Exploiting_Characters.html">80 acl-2013-Chinese Parsing Exploiting Characters</a></p>
<p>10 0.65517098 <a title="224-lda-10" href="./acl-2013-Parsing_with_Compositional_Vector_Grammars.html">275 acl-2013-Parsing with Compositional Vector Grammars</a></p>
<p>11 0.6544463 <a title="224-lda-11" href="./acl-2013-Sentiment_Relevance.html">318 acl-2013-Sentiment Relevance</a></p>
<p>12 0.65370601 <a title="224-lda-12" href="./acl-2013-Co-regularizing_character-based_and_word-based_models_for_semi-supervised_Chinese_word_segmentation.html">82 acl-2013-Co-regularizing character-based and word-based models for semi-supervised Chinese word segmentation</a></p>
<p>13 0.65245903 <a title="224-lda-13" href="./acl-2013-Embedding_Semantic_Similarity_in_Tree_Kernels_for_Domain_Adaptation_of_Relation_Extraction.html">134 acl-2013-Embedding Semantic Similarity in Tree Kernels for Domain Adaptation of Relation Extraction</a></p>
<p>14 0.64998198 <a title="224-lda-14" href="./acl-2013-Linking_Tweets_to_News%3A_A_Framework_to_Enrich_Short_Text_Data_in_Social_Media.html">233 acl-2013-Linking Tweets to News: A Framework to Enrich Short Text Data in Social Media</a></p>
<p>15 0.64972955 <a title="224-lda-15" href="./acl-2013-Extracting_Events_with_Informal_Temporal_References_in_Personal_Histories_in_Online_Communities.html">153 acl-2013-Extracting Events with Informal Temporal References in Personal Histories in Online Communities</a></p>
<p>16 0.64881468 <a title="224-lda-16" href="./acl-2013-Unsupervised_Consonant-Vowel_Prediction_over_Hundreds_of_Languages.html">369 acl-2013-Unsupervised Consonant-Vowel Prediction over Hundreds of Languages</a></p>
<p>17 0.64869845 <a title="224-lda-17" href="./acl-2013-Generalizing_Image_Captions_for_Image-Text_Parallel_Corpus.html">167 acl-2013-Generalizing Image Captions for Image-Text Parallel Corpus</a></p>
<p>18 0.64854717 <a title="224-lda-18" href="./acl-2013-Fast_and_Accurate_Shift-Reduce_Constituent_Parsing.html">155 acl-2013-Fast and Accurate Shift-Reduce Constituent Parsing</a></p>
<p>19 0.64819312 <a title="224-lda-19" href="./acl-2013-Language-Independent_Discriminative_Parsing_of_Temporal_Expressions.html">212 acl-2013-Language-Independent Discriminative Parsing of Temporal Expressions</a></p>
<p>20 0.64763904 <a title="224-lda-20" href="./acl-2013-Parsing_Graphs_with_Hyperedge_Replacement_Grammars.html">274 acl-2013-Parsing Graphs with Hyperedge Replacement Grammars</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
