<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>340 acl-2013-Text-Driven Toponym Resolution using Indirect Supervision</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-340" href="#">acl2013-340</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>340 acl-2013-Text-Driven Toponym Resolution using Indirect Supervision</h1>
<br/><p>Source: <a title="acl-2013-340-pdf" href="http://aclweb.org/anthology//P/P13/P13-1144.pdf">pdf</a></p><p>Author: Michael Speriosu ; Jason Baldridge</p><p>Abstract: Toponym resolvers identify the specific locations referred to by ambiguous placenames in text. Most resolvers are based on heuristics using spatial relationships between multiple toponyms in a document, or metadata such as population. This paper shows that text-driven disambiguation for toponyms is far more effective. We exploit document-level geotags to indirectly generate training instances for text classifiers for toponym resolution, and show that textual cues can be straightforwardly integrated with other commonly used ones. Results are given for both 19th century texts pertaining to the American Civil War and 20th century newswire articles.</p><p>Reference: <a title="acl-2013-340-reference" href="../acl2013_reference/acl-2013-Text-Driven_Toponym_Resolution_using_Indirect_Supervision_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract Toponym resolvers identify the specific locations referred to by ambiguous placenames in text. [sent-2, score-0.423]
</p><p>2 Most resolvers are based on heuristics using spatial relationships between multiple toponyms in a document, or metadata such as population. [sent-3, score-0.776]
</p><p>3 This paper shows that text-driven disambiguation for toponyms is far more effective. [sent-4, score-0.491]
</p><p>4 We exploit document-level geotags to indirectly generate training instances for text classifiers for toponym resolution, and show that textual cues can be straightforwardly integrated with other commonly used ones. [sent-5, score-0.71]
</p><p>5 1 Introduction It has been estimated that at least half of the world’s stored knowledge, both printed and digital, has geographic relevance, and that geographic information pervades many more aspects of humanity than previously thought (Petras, 2004; Skupin and Esperb´ e, 2011). [sent-7, score-0.31]
</p><p>6 Allowing for the querying and exploration of knowledge in a geographically informed way requires more powerful tools than a keyword-based search can provide, in part due to the ambiguity of toponyms (placenames). [sent-11, score-0.518]
</p><p>7 Toponym resolution is the task of disambiguating toponyms in natural language contexts to geographic locations (Leidner, 2008). [sent-12, score-0.916]
</p><p>8 Here we demonstrate the utility of incorporating distance measurements in toponym resolution systems. [sent-21, score-0.748]
</p><p>9 Most work on toponym resolution relies on heuristics and hand-built rules. [sent-22, score-0.729]
</p><p>10 ), resolving every instance of the same toponym type to the same location regardless of context (Ladra et al. [sent-24, score-0.801]
</p><p>11 Others use relationships between multiple toponyms in a context (local or whole document) and look for containment relationships, e. [sent-26, score-0.529]
</p><p>12 Still others first identify unambiguous toponyms and then disambiguate other toponyms based on geopolitical relationships with or distances to the unambiguous ones (Ding et al. [sent-35, score-1.067]
</p><p>13 Many favor resolutions of toponyms within a local context or document that cover a smaller geographic area over those that are more dispersed (Rauch et al. [sent-37, score-0.742]
</p><p>14 (2010) use relationships learned between people, organizations, and locations from Wikipedia to aid in toponym resolution when such named entities are present, but do not exploit any other textual context. [sent-43, score-0.958]
</p><p>15 Ac s2s0o1ci3a Atiosnso fcoirat Cio nm foprut Caotimonpaulta Lti nognuails Lti cnsg,u piasgteics 146 –1476, Most of these approaches suffer from a major weakness: they rely primarily on spatial relationships and metadata about locations (e. [sent-46, score-0.271]
</p><p>16 As such, they often require nearby toponyms (including unambiguous or containing toponyms) to resolve ambiguous ones. [sent-49, score-0.531]
</p><p>17 This reliance can result in poor coverage when the required information is missing in the context or when a document mentions locations that are neither nearby geographically nor in a geopolitical relationship. [sent-50, score-0.334]
</p><p>18 Spatially relevant words like downtown that are not explicit toponyms can be strong cues for resolution (Hollenstein and Purves, 2012). [sent-52, score-0.572]
</p><p>19 Furthermore, the connection between non-spatial words and locations has been successfully exploited in data-driven approaches to document geolocation (Eisenstein et al. [sent-53, score-0.281]
</p><p>20 In this paper, we learn resolvers that use all words in local or document context. [sent-59, score-0.281]
</p><p>21 For example, the word lobster appearing near the toponym Port-  land indicates the location is Portland in Maine rather than Oregon or Michigan. [sent-60, score-0.781]
</p><p>22 There are no massive collections of toponyms labeled with locations, so we train models indirectly using geotagged Wikipedia articles. [sent-62, score-0.509]
</p><p>23 Our primary focus is toponym resolution, so we evaluate on toponyms identified by human annotators. [sent-65, score-1.18]
</p><p>24 However, it is important to consider the utility of an end-to-end toponym identification and resolution system, so we also demonstrate that performance is still strong when toponyms are detected with a standard named entity recognizer. [sent-66, score-1.24]
</p><p>25 1 Gazetteer Toponym resolvers need a gazetteer to obtain candidate locations for each toponym. [sent-71, score-0.484]
</p><p>26 GEONAMES gives the locations of regional items like states, provinces, and countries as single points. [sent-78, score-0.217]
</p><p>27 To get around this, we represent regional locations as a set of points derived from the gazetteer. [sent-82, score-0.213]
</p><p>28 Since regional locations are named in the entries for locations they contain, all locations contained in the region are extracted (in some cases over 100,000 of them) and then k-means is run to find a smaller set of spatial centroids. [sent-83, score-0.655]
</p><p>29 The last two columns give the average number of candidate locations per toponym token and the number of candidate locations for the most ambiguous toponym. [sent-95, score-1.12]
</p><p>30 The distance between two locations is computed as the great circle distance between the closest pair of representative points, one from each location. [sent-97, score-0.229]
</p><p>31 2  Toponym Resolution Corpora  We need corpora with toponyms identified and resolved by human annotators for evaluation. [sent-99, score-0.532]
</p><p>32 Each toponym in the corpus was identified and resolved by hand. [sent-102, score-0.711]
</p><p>33 3  Toponym Resolvers  Given a set of toponyms provided via annotations or identified using NER, a resolver must select a candidate location for each toponym (or, in some cases, a resolver may abstain). [sent-118, score-1.515]
</p><p>34 Here, we describe baseline resolvers, a heuristic resolver based on the usual cues used in most toponym resolvers, and several text-driven resolvers. [sent-119, score-0.787]
</p><p>35 1 Baseline Resolvers RANDOM For each toponym, the RANDOM resolver randomly selects a location from those associated in the gazetteer with that toponym. [sent-122, score-0.26]
</p><p>36 POPULATION The POPULATION resolver selects the location with the greatest population for each toponym. [sent-123, score-0.264]
</p><p>37 It is generally quite effective, but when a toponym has several locations with large populations, it is often wrong. [sent-124, score-0.861]
</p><p>38 Also, it can only be used when such information is available, and it is 4States and countries are not annotated in CWAR, so we do not evaluate end-to-end using NER plus toponym resolution for it as there are many (falsely) false positives. [sent-125, score-0.773]
</p><p>39 In addition to capturing both minimality properties, it also identifies the relative prominence of the locations for each toponym in a given corpus. [sent-136, score-0.957]
</p><p>40 SPIDER resolves each toponym by finding the  location for each that minimizes the sum distance to all locations for all other toponyms in the same document. [sent-137, score-1.482]
</p><p>41 The adjusted distance between two locations is computed as the great circle distance divided by the product of the two locations’ weights. [sent-143, score-0.229]
</p><p>42 The weights are global, with one for each location in the gazetteer,  so the same weight vector is used for each token of a given toponym on a given iteration. [sent-145, score-0.781]
</p><p>43 When only one toponym is present in a document, we simply select the candidate with the greatest weight. [sent-154, score-0.724]
</p><p>44 When there is no such weight information, such as when the toponym does not co-  occur with other toponyms anywhere in the corpus, we select a candidate at random. [sent-155, score-1.195]
</p><p>45 SPIDER captures prominence, but we stress it is not our main innovation: its purpose is to be a benchmark for text-driven resolvers to beat. [sent-156, score-0.205]
</p><p>46 3  Text-Driven Resolvers  The text-driven resolvers presented in this section all use local context windows, document context, or both, to inform disambiguation. [sent-158, score-0.301]
</p><p>47 TRIPDL We use a document geolocator trained on GEOWIKI’s document location labels. [sent-159, score-0.236]
</p><p>48 Others—such as Smith and Crane (2001)—have estimated a document-level location to inform toponym resolution, but ours is the first we are aware of to use training data from a different domain to build a document geolocator that uses all words (not only toponyms) to estimate a document’s location. [sent-160, score-0.857]
</p><p>49 WISTR While TRIPDL uses an off-the-shelf document geolocator to capture the geographic gist of a document, WISTR (Wikipedia Indirectly Supervised Toponym Resolver) instead directly targets each toponym. [sent-165, score-0.231]
</p><p>50 To create the indirectly supervised training data for WISTR, the OpenNLP named entity recognizer detects toponyms in GEOWIKI, and candidate locations for each toponym are retrieved from GEONAMES. [sent-167, score-1.456]
</p><p>51 Each toponym with a location within 10km of the document location is considered a mention of that location. [sent-168, score-0.941]
</p><p>52 The toponym New York is mentioned several times in the article, and GEONAMES lists a New York at (40. [sent-172, score-0.67]
</p><p>53 Next, context windows w of twenty words to  each side of each toponym are extracted as features. [sent-177, score-0.69]
</p><p>54 We extract 1,489,428 such instances for toponyms relevant to our evaluation corpora. [sent-179, score-0.491]
</p><p>55 These instances are used to train logistic regression classifiers P(l|t, w) for location l and toponym t. [sent-180, score-0.781]
</p><p>56 Few such probabilistic toponym resolvers exist in the literature. [sent-183, score-0.875]
</p><p>57 Li (2007) builds a probability distribution over locations for each toponym, but still relies on nearby toponyms that could refer to regions that contain that toponym and requires hand construction of distributions. [sent-184, score-1.372]
</p><p>58 Overell and R u¨ger (2008) and Overell (2009) only use nearby toponyms as features. [sent-188, score-0.511]
</p><p>59 Our approach makes use of all words in local and document context and requires no explicitly labeled toponym tokens. [sent-192, score-0.766]
</p><p>60 TRAWL We bring TRIPDL, WISTR, and standard toponym resolution cues about administrative levels together with TRAWL (Toponym Resolution via Administrative levels and Wikipedia Locations). [sent-193, score-0.826]
</p><p>61 The general form of a probabilistic resolver that utilizes such information to select a location for a toponym t in document d may be defined as = arg maxl P(l, al |t, d). [sent-194, score-0.946]
</p><p>62 The above term is simplified as follows:  lˆ  lˆ  P(l, al|t, d)  =  P(al|t, d)P(l|al, t, d)  ≈  P(al|t)P(l|t, d)  where we approximate the administrative level prediction as independent of the document, and the location as independent of administrative level. [sent-197, score-0.261]
</p><p>63 λt, the weight of the local context distribution, is set according to the confidence that a prediction based on local context is correct: λt  =  f(ft()t+)C,  where f(t) is the fraction of training instances of toponym t of all instances extracted from GEOWIKI. [sent-199, score-0.764]
</p><p>64 Te |h|Ris b|o| oisst tsh states baenrd o cfo ruepntreriseesn stiatnicvee higher probability is assigned to locations with more points (and cities have just one point). [sent-204, score-0.232]
</p><p>65 6 WISTR fails to predict when encountering a toponym it has not seen in the training data, and TRIPDL fails when a toponym only has locations  in cells with no probability mass. [sent-210, score-1.549]
</p><p>66 The gazetteer used by a resolver may not contain, for a given toponym, a location whose latitude and longitude exactly match the gold label for the toponym (Leidner, 2008). [sent-221, score-0.956]
</p><p>67 We choose a metric that instead measures the distance between the correct and predicted location for each toponym and compute the mean and median of all such error distances. [sent-225, score-0.836]
</p><p>68 It is important to understand performance on plain text (without gold toponyms), which is the typical use case for applications using toponym resolvers. [sent-229, score-0.696]
</p><p>69 Both the accuracy metric and the errordistance metric encounter problems when the set of predicted toponyms is not the same as the set of gold toponyms (regardless of locations), e. [sent-230, score-1.027]
</p><p>70 In this case, we can use precision and recall, where a true positive is defined as the prediction of a correctly identified toponym’s location to be as close as possible to its gold label, given the gazetteer used. [sent-233, score-0.21]
</p><p>71 False positives occur when the NER incorrectly predicts a toponym, and false negatives occur when it fails to predict a toponym identified by the annotator. [sent-234, score-0.707]
</p><p>72 When a correctly identified toponym receives an incorrect location prediction, this counts as both a false negative and a false positive. [sent-235, score-0.836]
</p><p>73 We primarily present results from experiments with gold toponyms but in-  clude an accuracy measure for comparability with results from experiments run on plain text with a named entity recognizer. [sent-236, score-0.537]
</p><p>74 This accuracy metric simply computes the fraction of toponyms that were resolved as close as possible to their gold label given the gazetteer. [sent-237, score-0.539]
</p><p>75 5  Results  Table 2 gives the performance of the resolvers on the TR-CONLL and CWAR test sets when gold toponyms are used. [sent-238, score-0.722]
</p><p>76 The ORACLE row gives results when the candidate 1471  Figure 2: Visualization of how SPIDER clumps most predicted locations in the same region (above), on the CWAR-DEV corpus. [sent-240, score-0.244]
</p><p>77 On both datasets, SPIDER achieves errors and accuracies much better than RANDOM, validating the intuition that authors tend to discuss places near each other more often than not, while some locations are more prominent in a given corpus despite violating the minimality heuristic. [sent-244, score-0.29]
</p><p>78 The text-driven resolvers vastly outperform SPIDER, showing the effectiveness of textual cues for toponym resolution. [sent-245, score-0.897]
</p><p>79 The local context resolver WISTR is very effective: it has the highest accuracy for TR-CONLL, though two other text-based resolvers also beat the challenging POPULATION baseline’s accuracy. [sent-246, score-0.347]
</p><p>80 This makes toponym resolution easier overall (especially error distances) for minimality resolvers like SPIDER, which primarily seek tightly clustered sets of locations. [sent-250, score-1.022]
</p><p>81 This behavior is quite clear in visualizations of predicted locations such as Figure 2. [sent-251, score-0.21]
</p><p>82 (Also, we note that POPULATION is not a resolver per se since it only ever predicts one location for a given toponym, regardless of context. [sent-253, score-0.206]
</p><p>83 ) Table 3 gives results on TRC-TEST when NERidentified toponyms are used. [sent-254, score-0.491]
</p><p>84 When resolvers are run on NER-identified to-  ponyms, the text-driven resolvers that use local context again easily beat SPIDER. [sent-256, score-0.457]
</p><p>85 The named entity recognizer is likely better at detecting common toponyms than rare toponyms due to the na1472  on TRC-TEST with NER-identified toponyms. [sent-258, score-1.034]
</p><p>86 ture of its training data, and many more local context training instances were extracted from com-  mon toponyms than from rare ones in Wikipedia. [sent-259, score-0.538]
</p><p>87 We also measured the mean and median error distance for toponyms correctly identified by the named entity recognizer, and found that they tended to be 50-200km worse than for gold toponyms. [sent-261, score-0.592]
</p><p>88 This also makes sense given the named entity recognizer’s tendency to detect common toponyms: common toponyms tend to be more ambiguous than others. [sent-262, score-0.511]
</p><p>89 Washington, the toponym contributing the most total error, is a typical example of a toponym that is difficult to resolve, as there are two very prominent locations within the United States with the name. [sent-273, score-1.531]
</p><p>90 The presence of many east coast cues—both toponym and otherwise—make it unsurprising that the resolver would predict California, Pennsylvania despite the administrative level component’s heavier weight-  ing of the state. [sent-290, score-0.84]
</p><p>91 The average errors for the toponyms Australia and Russia are fairly small and stem from differences in how countries are represented across different gazetteers, not true incorrect predictions. [sent-291, score-0.517]
</p><p>92 Table 5 shows the toponyms with the greatest errors from CWAR-DEV with gold toponyms when resolved by WISTR+SPIDER. [sent-292, score-1.05]
</p><p>93 Mexico, however, frequently gets incorrectly selected as a city in Maryland near many other locations in the corpus when TRAWL’s administrative level component is not present. [sent-294, score-0.288]
</p><p>94 Many other of the toponyms contributing to the total error such as Jackson and Lexington are 1473  distances in kilometers from TRC-DEV with gold toponyms resolved by TRAWL. [sent-295, score-1.047]
</p><p>95 N is the number of instances, and the mean error for each toponym type is also given. [sent-296, score-0.687]
</p><p>96 They easily outperform standard minimality toponym resolvers, but can also be combined with them. [sent-300, score-0.741]
</p><p>97 This strategy works particularly well when predicting toponyms on a corpus with relatively restricted geographic extents. [sent-301, score-0.646]
</p><p>98 Performance remains good when resolving toponyms identified automatically, indicating that end-to-end systems based on our models may improve the experience of digital humanities scholars interested in finding and visualizing toponyms in large corpora. [sent-302, score-1.025]
</p><p>99 A  toponym resolution service following the OGC WPS standard. [sent-440, score-0.729]
</p><p>100 InfoXtract location normalization: a hybrid approach to geographic references in information extraction. [sent-452, score-0.266]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('toponym', 0.67), ('toponyms', 0.491), ('resolvers', 0.205), ('locations', 0.191), ('spider', 0.166), ('geographic', 0.155), ('wistr', 0.116), ('location', 0.111), ('trawl', 0.111), ('resolver', 0.095), ('leidner', 0.095), ('cwar', 0.08), ('administrative', 0.075), ('minimality', 0.071), ('tripdl', 0.071), ('paris', 0.062), ('spatial', 0.062), ('resolution', 0.059), ('gazetteer', 0.054), ('document', 0.049), ('wing', 0.048), ('civil', 0.045), ('geolocation', 0.041), ('geographical', 0.039), ('geonames', 0.039), ('population', 0.038), ('texas', 0.036), ('ner', 0.035), ('candidate', 0.034), ('recognizer', 0.032), ('grover', 0.032), ('pdl', 0.032), ('baldridge', 0.03), ('sigspatial', 0.029), ('places', 0.028), ('geopolitical', 0.027), ('local', 0.027), ('geographically', 0.027), ('geolocator', 0.027), ('geowiki', 0.027), ('loureiro', 0.027), ('overell', 0.027), ('placenames', 0.027), ('rauch', 0.027), ('gold', 0.026), ('countries', 0.026), ('prominence', 0.025), ('coordinates', 0.025), ('spatially', 0.025), ('digital', 0.024), ('roller', 0.024), ('teitler', 0.024), ('resolved', 0.022), ('cell', 0.022), ('war', 0.022), ('points', 0.022), ('cues', 0.022), ('france', 0.022), ('crane', 0.022), ('sankaranarayanan', 0.022), ('city', 0.022), ('al', 0.021), ('california', 0.021), ('austin', 0.021), ('named', 0.02), ('context', 0.02), ('eisenstein', 0.02), ('nearby', 0.02), ('unambiguous', 0.02), ('disambiguating', 0.02), ('greatest', 0.02), ('distance', 0.019), ('predicted', 0.019), ('identified', 0.019), ('united', 0.019), ('cities', 0.019), ('cells', 0.018), ('wikipedia', 0.018), ('relationships', 0.018), ('century', 0.018), ('false', 0.018), ('amitay', 0.018), ('arkansas', 0.018), ('buscaldi', 0.018), ('esperb', 0.018), ('fieldspring', 0.018), ('geolocated', 0.018), ('georeferencing', 0.018), ('hollenstein', 0.018), ('inning', 0.018), ('intagorn', 0.018), ('ladra', 0.018), ('maine', 0.018), ('purves', 0.018), ('scheidel', 0.018), ('skupin', 0.018), ('subdocuments', 0.018), ('indirectly', 0.018), ('error', 0.017), ('historical', 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="340-tfidf-1" href="./acl-2013-Text-Driven_Toponym_Resolution_using_Indirect_Supervision.html">340 acl-2013-Text-Driven Toponym Resolution using Indirect Supervision</a></p>
<p>Author: Michael Speriosu ; Jason Baldridge</p><p>Abstract: Toponym resolvers identify the specific locations referred to by ambiguous placenames in text. Most resolvers are based on heuristics using spatial relationships between multiple toponyms in a document, or metadata such as population. This paper shows that text-driven disambiguation for toponyms is far more effective. We exploit document-level geotags to indirectly generate training instances for text classifiers for toponym resolution, and show that textual cues can be straightforwardly integrated with other commonly used ones. Results are given for both 19th century texts pertaining to the American Civil War and 20th century newswire articles.</p><p>2 0.11261931 <a title="340-tfidf-2" href="./acl-2013-A_Stacking-based_Approach_to_Twitter_User_Geolocation_Prediction.html">20 acl-2013-A Stacking-based Approach to Twitter User Geolocation Prediction</a></p>
<p>Author: Bo Han ; Paul Cook ; Timothy Baldwin</p><p>Abstract: We implement a city-level geolocation prediction system for Twitter users. The system infers a user’s location based on both tweet text and user-declared metadata using a stacking approach. We demonstrate that the stacking method substantially outperforms benchmark methods, achieving 49% accuracy on a benchmark dataset. We further evaluate our method on a recent crawl of Twitter data to investigate the impact of temporal factors on model generalisation. Our results suggest that user-declared location metadata is more sensitive to temporal change than the text of Twitter messages. We also describe two ways of accessing/demoing our system.</p><p>3 0.047182806 <a title="340-tfidf-3" href="./acl-2013-Domain-Specific_Coreference_Resolution_with_Lexicalized_Features.html">130 acl-2013-Domain-Specific Coreference Resolution with Lexicalized Features</a></p>
<p>Author: Nathan Gilbert ; Ellen Riloff</p><p>Abstract: Most coreference resolvers rely heavily on string matching, syntactic properties, and semantic attributes of words, but they lack the ability to make decisions based on individual words. In this paper, we explore the benefits of lexicalized features in the setting of domain-specific coreference resolution. We show that adding lexicalized features to off-the-shelf coreference resolvers yields significant performance gains on four domain-specific data sets and with two types of coreference resolution architectures.</p><p>4 0.041478705 <a title="340-tfidf-4" href="./acl-2013-HYENA-live%3A_Fine-Grained_Online_Entity_Type_Classification_from_Natural-language_Text.html">179 acl-2013-HYENA-live: Fine-Grained Online Entity Type Classification from Natural-language Text</a></p>
<p>Author: Mohamed Amir Yosef ; Sandro Bauer ; Johannes Hoffart ; Marc Spaniol ; Gerhard Weikum</p><p>Abstract: Recent research has shown progress in achieving high-quality, very fine-grained type classification in hierarchical taxonomies. Within such a multi-level type hierarchy with several hundreds of types at different levels, many entities naturally belong to multiple types. In order to achieve high-precision in type classification, current approaches are either limited to certain domains or require time consuming multistage computations. As a consequence, existing systems are incapable of performing ad-hoc type classification on arbitrary input texts. In this demo, we present a novel Webbased tool that is able to perform domain independent entity type classification under real time conditions. Thanks to its efficient implementation and compacted feature representation, the system is able to process text inputs on-the-fly while still achieving equally high precision as leading state-ofthe-art implementations. Our system offers an online interface where natural-language text can be inserted, which returns semantic type labels for entity mentions. Further more, the user interface allows users to explore the assigned types by visualizing and navigating along the type-hierarchy.</p><p>5 0.039775304 <a title="340-tfidf-5" href="./acl-2013-Tag2Blog%3A_Narrative_Generation_from_Satellite_Tag_Data.html">337 acl-2013-Tag2Blog: Narrative Generation from Satellite Tag Data</a></p>
<p>Author: Kapila Ponnamperuma ; Advaith Siddharthan ; Cheng Zeng ; Chris Mellish ; Rene van der Wal</p><p>Abstract: The aim of the Tag2Blog system is to bring satellite tagged wild animals “to life” through narratives that place their movements in an ecological context. Our motivation is to use such automatically generated texts to enhance public engagement with a specific species reintroduction programme, although the protocols developed here can be applied to any animal or other movement study that involves signal data from tags. We are working with one of the largest nature conservation charities in Europe in this regard, focusing on a single species, the red kite. We describe a system that interprets a sequence of locational fixes obtained from a satellite tagged individual, and constructs a story around its use of the landscape.</p><p>6 0.039123777 <a title="340-tfidf-6" href="./acl-2013-Named_Entity_Recognition_using_Cross-lingual_Resources%3A_Arabic_as_an_Example.html">256 acl-2013-Named Entity Recognition using Cross-lingual Resources: Arabic as an Example</a></p>
<p>7 0.03496993 <a title="340-tfidf-7" href="./acl-2013-FudanNLP%3A_A_Toolkit_for_Chinese_Natural_Language_Processing.html">164 acl-2013-FudanNLP: A Toolkit for Chinese Natural Language Processing</a></p>
<p>8 0.03403737 <a title="340-tfidf-8" href="./acl-2013-Multigraph_Clustering_for_Unsupervised_Coreference_Resolution.html">252 acl-2013-Multigraph Clustering for Unsupervised Coreference Resolution</a></p>
<p>9 0.032125864 <a title="340-tfidf-9" href="./acl-2013-Learning_Entity_Representation_for_Entity_Disambiguation.html">219 acl-2013-Learning Entity Representation for Entity Disambiguation</a></p>
<p>10 0.030208224 <a title="340-tfidf-10" href="./acl-2013-Fine-grained_Semantic_Typing_of_Emerging_Entities.html">160 acl-2013-Fine-grained Semantic Typing of Emerging Entities</a></p>
<p>11 0.029352 <a title="340-tfidf-11" href="./acl-2013-Automatic_Term_Ambiguity_Detection.html">62 acl-2013-Automatic Term Ambiguity Detection</a></p>
<p>12 0.028809251 <a title="340-tfidf-12" href="./acl-2013-Building_Comparable_Corpora_Based_on_Bilingual_LDA_Model.html">74 acl-2013-Building Comparable Corpora Based on Bilingual LDA Model</a></p>
<p>13 0.028736027 <a title="340-tfidf-13" href="./acl-2013-Joint_Word_Alignment_and_Bilingual_Named_Entity_Recognition_Using_Dual_Decomposition.html">210 acl-2013-Joint Word Alignment and Bilingual Named Entity Recognition Using Dual Decomposition</a></p>
<p>14 0.028070984 <a title="340-tfidf-14" href="./acl-2013-A_corpus-based_evaluation_method_for_Distributional_Semantic_Models.html">31 acl-2013-A corpus-based evaluation method for Distributional Semantic Models</a></p>
<p>15 0.027866069 <a title="340-tfidf-15" href="./acl-2013-Improving_pairwise_coreference_models_through_feature_space_hierarchy_learning.html">196 acl-2013-Improving pairwise coreference models through feature space hierarchy learning</a></p>
<p>16 0.02756381 <a title="340-tfidf-16" href="./acl-2013-Graph-based_Local_Coherence_Modeling.html">172 acl-2013-Graph-based Local Coherence Modeling</a></p>
<p>17 0.02754326 <a title="340-tfidf-17" href="./acl-2013-Entity_Linking_for_Tweets.html">139 acl-2013-Entity Linking for Tweets</a></p>
<p>18 0.027113881 <a title="340-tfidf-18" href="./acl-2013-Dirt_Cheap_Web-Scale_Parallel_Text_from_the_Common_Crawl.html">120 acl-2013-Dirt Cheap Web-Scale Parallel Text from the Common Crawl</a></p>
<p>19 0.026717529 <a title="340-tfidf-19" href="./acl-2013-Learning_to_Extract_International_Relations_from_Political_Context.html">224 acl-2013-Learning to Extract International Relations from Political Context</a></p>
<p>20 0.025921999 <a title="340-tfidf-20" href="./acl-2013-Towards_Accurate_Distant_Supervision_for_Relational_Facts_Extraction.html">352 acl-2013-Towards Accurate Distant Supervision for Relational Facts Extraction</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.078), (1, 0.03), (2, -0.006), (3, -0.033), (4, 0.041), (5, 0.031), (6, 0.021), (7, 0.006), (8, 0.018), (9, -0.002), (10, -0.026), (11, -0.017), (12, -0.003), (13, -0.005), (14, -0.014), (15, -0.01), (16, -0.036), (17, 0.044), (18, -0.017), (19, -0.008), (20, -0.029), (21, 0.048), (22, 0.002), (23, 0.001), (24, 0.016), (25, 0.024), (26, -0.001), (27, -0.033), (28, 0.018), (29, 0.034), (30, 0.021), (31, -0.002), (32, 0.034), (33, 0.017), (34, 0.014), (35, -0.01), (36, 0.005), (37, 0.03), (38, 0.037), (39, -0.0), (40, 0.012), (41, 0.022), (42, -0.034), (43, 0.049), (44, 0.006), (45, 0.031), (46, 0.005), (47, 0.003), (48, -0.041), (49, -0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.84803361 <a title="340-lsi-1" href="./acl-2013-Text-Driven_Toponym_Resolution_using_Indirect_Supervision.html">340 acl-2013-Text-Driven Toponym Resolution using Indirect Supervision</a></p>
<p>Author: Michael Speriosu ; Jason Baldridge</p><p>Abstract: Toponym resolvers identify the specific locations referred to by ambiguous placenames in text. Most resolvers are based on heuristics using spatial relationships between multiple toponyms in a document, or metadata such as population. This paper shows that text-driven disambiguation for toponyms is far more effective. We exploit document-level geotags to indirectly generate training instances for text classifiers for toponym resolution, and show that textual cues can be straightforwardly integrated with other commonly used ones. Results are given for both 19th century texts pertaining to the American Civil War and 20th century newswire articles.</p><p>2 0.60262787 <a title="340-lsi-2" href="./acl-2013-Improving_pairwise_coreference_models_through_feature_space_hierarchy_learning.html">196 acl-2013-Improving pairwise coreference models through feature space hierarchy learning</a></p>
<p>Author: Emmanuel Lassalle ; Pascal Denis</p><p>Abstract: This paper proposes a new method for significantly improving the performance of pairwise coreference models. Given a set of indicators, our method learns how to best separate types of mention pairs into equivalence classes for which we construct distinct classification models. In effect, our approach finds an optimal feature space (derived from a base feature set and indicator set) for discriminating coreferential mention pairs. Although our approach explores a very large space of possible feature spaces, it remains tractable by exploiting the structure of the hierarchies built from the indicators. Our exper- iments on the CoNLL-2012 Shared Task English datasets (gold mentions) indicate that our method is robust relative to different clustering strategies and evaluation metrics, showing large and consistent improvements over a single pairwise model using the same base features. Our best system obtains a competitive 67.2 of average F1 over MUC, and CEAF which, despite its simplicity, places it above the mean score of other systems on these datasets. B3,</p><p>3 0.56420785 <a title="340-lsi-3" href="./acl-2013-Automatic_detection_of_deception_in_child-produced_speech_using_syntactic_complexity_features.html">63 acl-2013-Automatic detection of deception in child-produced speech using syntactic complexity features</a></p>
<p>Author: Maria Yancheva ; Frank Rudzicz</p><p>Abstract: It is important that the testimony of children be admissible in court, especially given allegations of abuse. Unfortunately, children can be misled by interrogators or might offer false information, with dire consequences. In this work, we evaluate various parameterizations of five classifiers (including support vector machines, neural networks, and random forests) in deciphering truth from lies given transcripts of interviews with 198 victims of abuse between the ages of 4 and 7. These evaluations are performed using a novel set of syntactic features, including measures of complexity. Our results show that sentence length, the mean number of clauses per utterance, and the StajnerMitkov measure of complexity are highly informative syntactic features, that classification accuracy varies greatly by the age of the speaker, and that accuracy up to 91.7% can be achieved by support vector machines given a sufficient amount of data.</p><p>4 0.54264343 <a title="340-lsi-4" href="./acl-2013-PATHS%3A_A_System_for_Accessing_Cultural_Heritage_Collections.html">268 acl-2013-PATHS: A System for Accessing Cultural Heritage Collections</a></p>
<p>Author: Eneko Agirre ; Nikolaos Aletras ; Paul Clough ; Samuel Fernando ; Paula Goodale ; Mark Hall ; Aitor Soroa ; Mark Stevenson</p><p>Abstract: This paper describes a system for navigating large collections of information about cultural heritage which is applied to Europeana, the European Library. Europeana contains over 20 million artefacts with meta-data in a wide range of European languages. The system currently provides access to Europeana content with meta-data in English and Spanish. The paper describes how Natural Language Processing is used to enrich and organise this meta-data to assist navigation through Europeana and shows how this information is used within the system.</p><p>5 0.54116499 <a title="340-lsi-5" href="./acl-2013-HYENA-live%3A_Fine-Grained_Online_Entity_Type_Classification_from_Natural-language_Text.html">179 acl-2013-HYENA-live: Fine-Grained Online Entity Type Classification from Natural-language Text</a></p>
<p>Author: Mohamed Amir Yosef ; Sandro Bauer ; Johannes Hoffart ; Marc Spaniol ; Gerhard Weikum</p><p>Abstract: Recent research has shown progress in achieving high-quality, very fine-grained type classification in hierarchical taxonomies. Within such a multi-level type hierarchy with several hundreds of types at different levels, many entities naturally belong to multiple types. In order to achieve high-precision in type classification, current approaches are either limited to certain domains or require time consuming multistage computations. As a consequence, existing systems are incapable of performing ad-hoc type classification on arbitrary input texts. In this demo, we present a novel Webbased tool that is able to perform domain independent entity type classification under real time conditions. Thanks to its efficient implementation and compacted feature representation, the system is able to process text inputs on-the-fly while still achieving equally high precision as leading state-ofthe-art implementations. Our system offers an online interface where natural-language text can be inserted, which returns semantic type labels for entity mentions. Further more, the user interface allows users to explore the assigned types by visualizing and navigating along the type-hierarchy.</p><p>6 0.53748369 <a title="340-lsi-6" href="./acl-2013-Using_Conceptual_Class_Attributes_to_Characterize_Social_Media_Users.html">373 acl-2013-Using Conceptual Class Attributes to Characterize Social Media Users</a></p>
<p>7 0.52732229 <a title="340-lsi-7" href="./acl-2013-A_Stacking-based_Approach_to_Twitter_User_Geolocation_Prediction.html">20 acl-2013-A Stacking-based Approach to Twitter User Geolocation Prediction</a></p>
<p>8 0.51961869 <a title="340-lsi-8" href="./acl-2013-Tag2Blog%3A_Narrative_Generation_from_Satellite_Tag_Data.html">337 acl-2013-Tag2Blog: Narrative Generation from Satellite Tag Data</a></p>
<p>9 0.51781791 <a title="340-lsi-9" href="./acl-2013-Domain-Specific_Coreference_Resolution_with_Lexicalized_Features.html">130 acl-2013-Domain-Specific Coreference Resolution with Lexicalized Features</a></p>
<p>10 0.51702702 <a title="340-lsi-10" href="./acl-2013-Identification_of_Speakers_in_Novels.html">184 acl-2013-Identification of Speakers in Novels</a></p>
<p>11 0.51639766 <a title="340-lsi-11" href="./acl-2013-Graph-based_Local_Coherence_Modeling.html">172 acl-2013-Graph-based Local Coherence Modeling</a></p>
<p>12 0.51258147 <a title="340-lsi-12" href="./acl-2013-GuiTAR-based_Pronominal_Anaphora_Resolution_in_Bengali.html">177 acl-2013-GuiTAR-based Pronominal Anaphora Resolution in Bengali</a></p>
<p>13 0.51254255 <a title="340-lsi-13" href="./acl-2013-Decentralized_Entity-Level_Modeling_for_Coreference_Resolution.html">106 acl-2013-Decentralized Entity-Level Modeling for Coreference Resolution</a></p>
<p>14 0.51248831 <a title="340-lsi-14" href="./acl-2013-Entity_Linking_for_Tweets.html">139 acl-2013-Entity Linking for Tweets</a></p>
<p>15 0.51172984 <a title="340-lsi-15" href="./acl-2013-Typesetting_for_Improved_Readability_using_Lexical_and_Syntactic_Information.html">364 acl-2013-Typesetting for Improved Readability using Lexical and Syntactic Information</a></p>
<p>16 0.5098353 <a title="340-lsi-16" href="./acl-2013-Linking_Tweets_to_News%3A_A_Framework_to_Enrich_Short_Text_Data_in_Social_Media.html">233 acl-2013-Linking Tweets to News: A Framework to Enrich Short Text Data in Social Media</a></p>
<p>17 0.49810982 <a title="340-lsi-17" href="./acl-2013-A_Novel_Classifier_Based_on_Quantum_Computation.html">14 acl-2013-A Novel Classifier Based on Quantum Computation</a></p>
<p>18 0.49328679 <a title="340-lsi-18" href="./acl-2013-The_Impact_of_Topic_Bias_on_Quality_Flaw_Prediction_in_Wikipedia.html">346 acl-2013-The Impact of Topic Bias on Quality Flaw Prediction in Wikipedia</a></p>
<p>19 0.49181548 <a title="340-lsi-19" href="./acl-2013-Multigraph_Clustering_for_Unsupervised_Coreference_Resolution.html">252 acl-2013-Multigraph Clustering for Unsupervised Coreference Resolution</a></p>
<p>20 0.48992655 <a title="340-lsi-20" href="./acl-2013-Learning_to_Order_Natural_Language_Texts.html">225 acl-2013-Learning to Order Natural Language Texts</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.038), (6, 0.037), (11, 0.038), (14, 0.014), (15, 0.013), (19, 0.316), (24, 0.053), (26, 0.033), (35, 0.058), (42, 0.033), (48, 0.028), (70, 0.037), (71, 0.014), (82, 0.034), (88, 0.054), (90, 0.026), (95, 0.07)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.75743806 <a title="340-lda-1" href="./acl-2013-Text-Driven_Toponym_Resolution_using_Indirect_Supervision.html">340 acl-2013-Text-Driven Toponym Resolution using Indirect Supervision</a></p>
<p>Author: Michael Speriosu ; Jason Baldridge</p><p>Abstract: Toponym resolvers identify the specific locations referred to by ambiguous placenames in text. Most resolvers are based on heuristics using spatial relationships between multiple toponyms in a document, or metadata such as population. This paper shows that text-driven disambiguation for toponyms is far more effective. We exploit document-level geotags to indirectly generate training instances for text classifiers for toponym resolution, and show that textual cues can be straightforwardly integrated with other commonly used ones. Results are given for both 19th century texts pertaining to the American Civil War and 20th century newswire articles.</p><p>2 0.6146794 <a title="340-lda-2" href="./acl-2013-Diverse_Keyword_Extraction_from_Conversations.html">126 acl-2013-Diverse Keyword Extraction from Conversations</a></p>
<p>Author: Maryam Habibi ; Andrei Popescu-Belis</p><p>Abstract: A new method for keyword extraction from conversations is introduced, which preserves the diversity of topics that are mentioned. Inspired from summarization, the method maximizes the coverage of topics that are recognized automatically in transcripts of conversation fragments. The method is evaluated on excerpts of the Fisher and AMI corpora, using a crowdsourcing platform to elicit comparative relevance judgments. The results demonstrate that the method outperforms two competitive baselines.</p><p>3 0.60646087 <a title="340-lda-3" href="./acl-2013-Sentence_Level_Dialect_Identification_in_Arabic.html">317 acl-2013-Sentence Level Dialect Identification in Arabic</a></p>
<p>Author: Heba Elfardy ; Mona Diab</p><p>Abstract: This paper introduces a supervised approach for performing sentence level dialect identification between Modern Standard Arabic and Egyptian Dialectal Arabic. We use token level labels to derive sentence-level features. These features are then used with other core and meta features to train a generative classifier that predicts the correct label for each sentence in the given input text. The system achieves an accuracy of 85.5% on an Arabic online-commentary dataset outperforming a previously proposed approach achieving 80.9% and reflecting a significant gain over a majority baseline of 5 1.9% and two strong baseline systems of 78.5% and 80.4%, respectively.</p><p>4 0.58380896 <a title="340-lda-4" href="./acl-2013-Learning_Semantic_Textual_Similarity_with_Structural_Representations.html">222 acl-2013-Learning Semantic Textual Similarity with Structural Representations</a></p>
<p>Author: Aliaksei Severyn ; Massimo Nicosia ; Alessandro Moschitti</p><p>Abstract: Measuring semantic textual similarity (STS) is at the cornerstone of many NLP applications. Different from the majority of approaches, where a large number of pairwise similarity features are used to represent a text pair, our model features the following: (i) it directly encodes input texts into relational syntactic structures; (ii) relies on tree kernels to handle feature engineering automatically; (iii) combines both structural and feature vector representations in a single scoring model, i.e., in Support Vector Regression (SVR); and (iv) delivers significant improvement over the best STS systems.</p><p>5 0.56114608 <a title="340-lda-5" href="./acl-2013-Automatic_Coupling_of_Answer_Extraction_and_Information_Retrieval.html">60 acl-2013-Automatic Coupling of Answer Extraction and Information Retrieval</a></p>
<p>Author: Xuchen Yao ; Benjamin Van Durme ; Peter Clark</p><p>Abstract: Information Retrieval (IR) and Answer Extraction are often designed as isolated or loosely connected components in Question Answering (QA), with repeated overengineering on IR, and not necessarily performance gain for QA. We propose to tightly integrate them by coupling automatically learned features for answer extraction to a shallow-structured IR model. Our method is very quick to implement, and significantly improves IR for QA (measured in Mean Average Precision and Mean Reciprocal Rank) by 10%-20% against an uncoupled retrieval baseline in both document and passage retrieval, which further leads to a downstream 20% improvement in QA F1.</p><p>6 0.51822388 <a title="340-lda-6" href="./acl-2013-A_Context_Free_TAG_Variant.html">4 acl-2013-A Context Free TAG Variant</a></p>
<p>7 0.44746926 <a title="340-lda-7" href="./acl-2013-Learning_a_Phrase-based_Translation_Model_from_Monolingual_Data_with_Application_to_Domain_Adaptation.html">223 acl-2013-Learning a Phrase-based Translation Model from Monolingual Data with Application to Domain Adaptation</a></p>
<p>8 0.42512625 <a title="340-lda-8" href="./acl-2013-A_Stacking-based_Approach_to_Twitter_User_Geolocation_Prediction.html">20 acl-2013-A Stacking-based Approach to Twitter User Geolocation Prediction</a></p>
<p>9 0.42227492 <a title="340-lda-9" href="./acl-2013-Fast_and_Adaptive_Online_Training_of_Feature-Rich_Translation_Models.html">156 acl-2013-Fast and Adaptive Online Training of Feature-Rich Translation Models</a></p>
<p>10 0.41576505 <a title="340-lda-10" href="./acl-2013-Utterance-Level_Multimodal_Sentiment_Analysis.html">379 acl-2013-Utterance-Level Multimodal Sentiment Analysis</a></p>
<p>11 0.4156844 <a title="340-lda-11" href="./acl-2013-Multigraph_Clustering_for_Unsupervised_Coreference_Resolution.html">252 acl-2013-Multigraph Clustering for Unsupervised Coreference Resolution</a></p>
<p>12 0.41126892 <a title="340-lda-12" href="./acl-2013-A_Random_Walk_Approach_to_Selectional_Preferences_Based_on_Preference_Ranking_and_Propagation.html">17 acl-2013-A Random Walk Approach to Selectional Preferences Based on Preference Ranking and Propagation</a></p>
<p>13 0.40827724 <a title="340-lda-13" href="./acl-2013-Density_Maximization_in_Context-Sense_Metric_Space_for_All-words_WSD.html">111 acl-2013-Density Maximization in Context-Sense Metric Space for All-words WSD</a></p>
<p>14 0.40811431 <a title="340-lda-14" href="./acl-2013-PARMA%3A_A_Predicate_Argument_Aligner.html">267 acl-2013-PARMA: A Predicate Argument Aligner</a></p>
<p>15 0.40673664 <a title="340-lda-15" href="./acl-2013-Improving_pairwise_coreference_models_through_feature_space_hierarchy_learning.html">196 acl-2013-Improving pairwise coreference models through feature space hierarchy learning</a></p>
<p>16 0.40351117 <a title="340-lda-16" href="./acl-2013-A_Bayesian_Model_for_Joint_Unsupervised_Induction_of_Sentiment%2C_Aspect_and_Discourse_Representations.html">2 acl-2013-A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations</a></p>
<p>17 0.40335786 <a title="340-lda-17" href="./acl-2013-Word_Association_Profiles_and_their_Use_for_Automated_Scoring_of_Essays.html">389 acl-2013-Word Association Profiles and their Use for Automated Scoring of Essays</a></p>
<p>18 0.40272033 <a title="340-lda-18" href="./acl-2013-Explicit_and_Implicit_Syntactic_Features_for_Text_Classification.html">144 acl-2013-Explicit and Implicit Syntactic Features for Text Classification</a></p>
<p>19 0.40254056 <a title="340-lda-19" href="./acl-2013-Identifying_Opinion_Subgroups_in_Arabic_Online_Discussions.html">187 acl-2013-Identifying Opinion Subgroups in Arabic Online Discussions</a></p>
<p>20 0.40244693 <a title="340-lda-20" href="./acl-2013-Graph-based_Local_Coherence_Modeling.html">172 acl-2013-Graph-based Local Coherence Modeling</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
