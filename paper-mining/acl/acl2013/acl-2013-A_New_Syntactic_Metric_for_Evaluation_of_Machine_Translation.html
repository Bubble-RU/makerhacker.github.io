<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>13 acl-2013-A New Syntactic Metric for Evaluation of Machine Translation</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-13" href="#">acl2013-13</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>13 acl-2013-A New Syntactic Metric for Evaluation of Machine Translation</h1>
<br/><p>Source: <a title="acl-2013-13-pdf" href="http://aclweb.org/anthology//P/P13/P13-3019.pdf">pdf</a></p><p>Author: Melania Duma ; Cristina Vertan ; Wolfgang Menzel</p><p>Abstract: Machine translation (MT) evaluation aims at measuring the quality of a candidate translation by comparing it with a reference translation. This comparison can be performed on multiple levels: lexical, syntactic or semantic. In this paper, we propose a new syntactic metric for MT evaluation based on the comparison of the dependency structures of the reference and the candidate translations. The dependency structures are obtained by means of a Weighted Constraints Dependency Grammar parser. Based on experiments performed on English to German translations, we show that the new metric correlates well with human judgments at the system level. 1</p><p>Reference: <a title="acl-2013-13-reference" href="../acl2013_reference/acl-2013-A_New_Syntactic_Metric_for_Evaluation_of_Machine_Translation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 de  Abstract Machine translation (MT) evaluation aims at measuring the quality of a candidate translation by comparing it with a reference translation. [sent-7, score-0.601]
</p><p>2 In this paper, we propose a new syntactic metric for MT evaluation based on the comparison of the dependency structures of the reference and the candidate translations. [sent-9, score-0.66]
</p><p>3 The dependency structures are obtained by means of a Weighted Constraints Dependency Grammar parser. [sent-10, score-0.202]
</p><p>4 Based on experiments performed on English to German translations, we show that the new metric correlates well with human judgments at the system level. [sent-11, score-0.274]
</p><p>5 1  Introduction  Research in automatic machine translation (MT) evaluation has the goal of developing a set of computer-based methods that measure accurately the correctness of the output generated by a MT system. [sent-12, score-0.227]
</p><p>6 However, this task is a difficult one  mainly because there is no unique reference output that can be used in the comparison with the candidate translation. [sent-13, score-0.229]
</p><p>7 Thus, it is difficult to decide if the deviation from an existing reference translation is a matter of style (the use of synonymous words, different syntax etc. [sent-15, score-0.299]
</p><p>8 Most of the automatic evaluation metrics developed so far are focused on the idea of lexical matching between the tokens of one or more reference translations and the tokens of a candidate translation. [sent-17, score-0.445]
</p><p>9 However, structural similarity between a reference translation and a candidate one cannot be captured by lexical features. [sent-18, score-0.448]
</p><p>10 Therefore, research in MT evaluation experiences a gradual shift of focus from lexical metrics to structural ones, whether they are syntactic or semantic or a combination of both. [sent-19, score-0.206]
</p><p>11 This paper introduces a new syntactic automatic MT evaluation method. [sent-20, score-0.096]
</p><p>12 At this stage of research the new metric is evaluating translations from any source language into German. [sent-21, score-0.237]
</p><p>13 The chosen tool for providing syntactic information for German is the Weighted Constraints Dependency Grammar (WCDG) parser (Menzel and Schröder, 1998), which is preferred over other parsers because of its robustness to ungrammatical input, as it is typical for MT output. [sent-23, score-0.274]
</p><p>14 In Section 2 the state of the art in MT evaluation is presented, while in Section 3 the new syntactic metric is described. [sent-25, score-0.272]
</p><p>15 Using an automatic method of evaluation a score is computed, based on the similarity between the output of the MT system and the reference. [sent-29, score-0.113]
</p><p>16 This similarity can be computed at different levels: lexical, syntactic or semantic. [sent-30, score-0.118]
</p><p>17 At the lexical level, the metrics  developed so far can be divided into two major categories: n-gram based and edit distance based. [sent-31, score-0.181]
</p><p>18 1 We will use the term reference for the reference translation and the term translation for the candidate translation. [sent-32, score-0.675]
</p><p>19 Lexical metrics that use the edit distance are constructed using the Levenshtein distance applied at the word level. [sent-38, score-0.181]
</p><p>20 , 2000) is the one which is used more frequently; it calculates the minimal number of insertion, substitutions and deletions needed to transform the candidate translation into a reference. [sent-40, score-0.224]
</p><p>21 Thus, they reward a low score to an otherwise fluent and syntactically correct candidate translation, if it does not share a certain number of words with the set of references. [sent-42, score-0.107]
</p><p>22 Another disadvantage is that many of them cannot be applied at the segment level, which is often needed in order to better assess the quality of MT output and to determine which improvements should be made to the MT system. [sent-45, score-0.128]
</p><p>23 Because of these disadvantages there is an increasing need for other approaches to MT evaluation that go beyond the lexical level of the phrases compared. [sent-46, score-0.115]
</p><p>24 In Liu and Gildea (2005), three syntactic evaluation metrics are presented. [sent-47, score-0.172]
</p><p>25 The first of these metrics, the Subtree Metric (SMT), is based on determining the number of subtrees that can be found in both the candidate translation and the reference phrase structure trees. [sent-48, score-0.475]
</p><p>26 The third metric proposed computes the number of matching n-grams between the headword chains of the reference and the candidate translation dependency trees obtained using the parser described in (Collins, 1999). [sent-50, score-0.948]
</p><p>27 The idea of syntactic similarity is further exploited in Owczarzak et al. [sent-51, score-0.089]
</p><p>28 The similarity between the translation and the reference is computed using the precision and the recall of the dependencies that illustrate the pair of sentences. [sent-53, score-0.366]
</p><p>29 Furthermore, paraphrases are used in order to improve the correlation with human judgments. [sent-54, score-0.182]
</p><p>30 Another set of syntactic metrics has been introduced in Gimenez (2008); some of them are based on analyzing different types of linguistic information (i. [sent-55, score-0.127]
</p><p>31 3  A new syntactic automatic metric  In this section we introduce the new syntactic metric which is based on constraint dependency parsing. [sent-58, score-0.687]
</p><p>32 In the first subsection, the WCDG parser  is presented, together with the advantages of using this parser over the other ones available, while the second subsection provides a detailed description of the new metric. [sent-59, score-0.31]
</p><p>33 1  Weighted Constraint Grammar Parser  Dependency  Our research was performed using a dependency parser. [sent-61, score-0.159]
</p><p>34 We decided on this type of parser because, as opposed to constituent parsers, it offers the possibility of better representing nonprojective structures. [sent-62, score-0.156]
</p><p>35 The goal of constraint dependency grammars (CDG) is to create dependency structures that represent a given phrase (Schröder et al. [sent-64, score-0.422]
</p><p>36 A relation between two words in a sentence is represented using an edge, which connects the  regent and the dependent. [sent-66, score-0.083]
</p><p>37 One property, for example, that is always enforced is that no word can have more than one regent on any level at a time. [sent-69, score-0.119]
</p><p>38 During the analysis, each of the constraints is applied to every edge or every pair of edges belonging to the constructed dependency parse tree. [sent-70, score-0.308]
</p><p>39 The main advantage of using constraint dependency grammars over dependency grammars based on generative rules is that they can deal better with free word order languages (Foth, 2004). [sent-71, score-0.485]
</p><p>40 Every constraint in WCDG is assigned a score which is a number between 0. [sent-73, score-0.104]
</p><p>41 0, 131  while the general score of a parse is calculated as the product of all the scores of all the instances of constraints that have not been satisfied. [sent-75, score-0.151]
</p><p>42 Rules that have a score of 0 are called hard rules,  meaning that they cannot be ignored, which is the case of the one regent only rule mentioned earlier. [sent-76, score-0.113]
</p><p>43 The advantage of using graded constraints, as opposed to crisp ones, stems from the fact that weights allow the parser to tolerate constraint violations, which, in turn, makes the parser robust against ungrammaticality. [sent-77, score-0.378]
</p><p>44 The parser was evaluated using different types of texts, and the results show that it has an accuracy between 80% and 90% in computing correct dependency attachments depending on the type of text (Foth et al. [sent-78, score-0.279]
</p><p>45 The benefit of using WCDG over other parsers is that it provides further information on a parse, like the general score of the parse and the constraints that are violated by the final result. [sent-80, score-0.25]
</p><p>46 Moreover, because of the fact that the candidate translations are sometimes not well-formed, parsing them represents a challenge. [sent-82, score-0.176]
</p><p>47 However, WCDG will always provide a final result, in the form of a dependency structure, even though it might have a low score due to the violated constraints. [sent-83, score-0.227]
</p><p>48 2 Description of the metric In order to define a new syntactic metric for MT evaluation, we have incorporated the WCDG parser in the process of evaluation. [sent-85, score-0.556]
</p><p>49 Because the output of the WCDG parser is a dependency tree, we have looked into techniques of measuring how similar two trees are. [sent-86, score-0.386]
</p><p>50 Our aim was to determine whether a tree similarity metric applied on the two dependency parse trees would prove to be an efficient way of capturing the similarity between the reference and the translation. [sent-87, score-0.746]
</p><p>51 Let us consider this example, in which the reference sentence is “Die schwarze Katze springt schnell auf den roten Stuhl. [sent-88, score-0.493]
</p><p>52 The black cat jumps quickly on the red chair) and the candidate translation is “Auf den roten Stuhl schnell springt die schwarze Katze ”(engl. [sent-90, score-0.664]
</p><p>53 Even though the word order of the two segments is quite different, and the translation has an incorrect syntax, they roughly have the same meaning. [sent-92, score-0.236]
</p><p>54 We present in Figure 1 the dependency parse trees obtained using WCDG for the sentences considered. [sent-93, score-0.342]
</p><p>55 We can observe that the  general structure of the translation is similar to that of the reference, the only difference being the reverse order between the left subtree and the right subtree. [sent-94, score-0.244]
</p><p>56 The tree similarity measure that we chose to use was the All Common Embedded Subtrees (ACET) (Lin et al. [sent-95, score-0.081]
</p><p>57 Given a tree T, an embedded subtree is obtained by removing one or more nodes, except for the root, from the tree T. [sent-97, score-0.297]
</p><p>58 Therefore, ACET is defined as the number of common embedded subtrees shared between two trees. [sent-99, score-0.203]
</p><p>59 (2008) show that ACET outperforms tree edit distance (Zhang and Shasha, 1989) in terms of efficiency. [sent-101, score-0.114]
</p><p>60 Example of dependency parse trees for reference and candidate translations In our experiments, we have applied the ACET algorithm, and computed the number of common embedded subtrees between the dependency parse trees of the hypothesis and the reference. [sent-103, score-1.12]
</p><p>61 Because of the additional information provided by the parsing, pre-processing of the output of the WCDG parser was necessary in order to transform the dependency tree into a general tree. [sent-104, score-0.355]
</p><p>62 In the following, we will refer to the new proposed metric using CESM (Common Embedded Subtree Metric). [sent-106, score-0.176]
</p><p>63 CESM was  computed using the precision, the recall and the F-measure of the common embedded subtrees of the reference and the translation:  132  where treeref and treehyp represent the preprocessed dependency trees of the reference and the hypothesis translations. [sent-107, score-0.769]
</p><p>64 4  Experimental setup and evaluation  In order to determine how accurate CESM is in capturing the similarity between references and translations, we evaluated it at the system level and at the segment level. [sent-108, score-0.215]
</p><p>65 The evaluation was conducted using data provided by the NAACL  2012 WMT workshop (Callison-Burch et al. [sent-109, score-0.092]
</p><p>66 As a result, 500 segments with a length between 50 and 80 characters were extracted from the German reference file. [sent-114, score-0.208]
</p><p>67 In the next step, we arbitrarily selected the outputs of 7 of the 15 systems that were submitted for evaluation in the English to German translation task: DFKI (Vilar, 2012), JHU (Ganitkevitch et al. [sent-115, score-0.192]
</p><p>68 After this initial step of filtering the data, the 7 systems were evaluated by calculating the CESM score for every pair of reference and translation segments corresponding to a system. [sent-118, score-0.385]
</p><p>69 The minimum value of ρ is -1, when there is no correlation between the two rankings, while the maximum value is 1, when the two rankings correlate perfectly (Callison-Burch et al. [sent-121, score-0.14]
</p><p>70 The ρ rank correlation coefficient was calculated as being ρ = 0. [sent-125, score-0.187]
</p><p>71 92, which shows there is a strong correlation between the results of CESM and the human judgments. [sent-126, score-0.108]
</p><p>72 In order to better assess the quality of CESM, the test set was also evaluated using NIST (Doddington,  2002), which managed to obtain the same rank correlation coefficient of ρ = 0. [sent-127, score-0.252]
</p><p>73 The first step in evaluating at the segment level was filtering the initial test set provided by the WMT12 workshop. [sent-129, score-0.099]
</p><p>74 For this purpose, 2500 reference and translation segments were selected with a length between 50 and 80 characters. [sent-130, score-0.355]
</p><p>75 The Kendall tau rank correlation coefficient was calculated in order to measure the correlation with human judgments, where Kendall tau (Callison-Burch et al. [sent-131, score-0.46]
</p><p>76 , 2012), we penalized ties given by CESM and ignored ties assigned by the human judgments. [sent-134, score-0.089]
</p><p>77 As a term of comparison, the highest correlation for segment level reported in Callinson-Burch et al. [sent-137, score-0.207]
</p><p>78 The rather low correlation result we obtained can be partially explained by the fact that only one judgment of a pair of reference and translation was taken into account. [sent-143, score-0.45]
</p><p>79 It will be 133  interesting to see how the averaging of the ranks of a translation influences the correlation coefficient. [sent-144, score-0.288]
</p><p>80 5  Conclusions and future work  In this paper, a new evaluation metric for MT was introduced, which is based on the comparison of dependency parse trees. [sent-145, score-0.446]
</p><p>81 The dependency trees were obtained using the WCDG German parser. [sent-146, score-0.276]
</p><p>82 The reason why we chose this parser was that, due to its architecture, it is able to handle ungrammatical and ambiguous input data. [sent-147, score-0.162]
</p><p>83 The experiments conducted so far show that using the data made available at the NAACL 2012 WMT workshop, CESM correlates well with the human judgments at the system level. [sent-148, score-0.098]
</p><p>84 One of the future experiments that we intend to perform is to assess metric quality on the entire evaluation set. [sent-149, score-0.284]
</p><p>85 Furthermore, the WMT12 workshop offers different ranking possibilities, like the ones presented in Bojar et al (201 1) and in Lopez (2012). [sent-151, score-0.078]
</p><p>86 It will be determined how much are the segment level evaluation results influenced by these ranking orders. [sent-152, score-0.144]
</p><p>87 One limitation of the proposed metric is that, at the moment it is restricted to translations from any source language to German as a target language. [sent-153, score-0.237]
</p><p>88 Because of this reason, we plan to extend the metric to other languages and see how well it performs in different settings. [sent-154, score-0.176]
</p><p>89 In further experiments we also intend to test CESM using statistical based dependency parsers, like the Malt Parser (Nivre et al. [sent-155, score-0.22]
</p><p>90 , 2006), in order to decide whether the choice of parser influences the performance of the metric. [sent-157, score-0.186]
</p><p>91 Another approach that we will explore for improving CESM is to compare dependency parse trees using the base form and the part-ofspeech of the tokens, instead of the exact lexical match. [sent-158, score-0.333]
</p><p>92 The accuracy of CESM can be further increased by the use of paraphrases, which can be obtained by using a German thesaurus or a lexical resource like GermaNet (Hamp and Feldweg, 1997). [sent-160, score-0.077]
</p><p>93 The results reported show that the use of this kind of paraphrases in order to produce new references has increased the BLEU score, therefore this is an approach that will be further investigated. [sent-162, score-0.074]
</p><p>94 A broadcoverage parser for German based on defeasible constraints. [sent-211, score-0.12]
</p><p>95 KONVENS 2004, Beiträge zur 7, Konferenz zur Verarbeitung natürlicher Sprache, Wien. [sent-212, score-0.096]
</p><p>96 Putting human assessments of machine translation systems in order. [sent-297, score-0.182]
</p><p>97 The karlsruhe institute of technology translation systems for the WMT 2012. [sent-320, score-0.147]
</p><p>98 Bleu: a method for automatic evaluation of machine translation. [sent-363, score-0.08]
</p><p>99 Class error rates for evaluation of machine translation output. [sent-370, score-0.227]
</p><p>100 Simple fast algorithms for the editing distance between trees and related problems. [sent-410, score-0.108]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('cesm', 0.44), ('wcdg', 0.346), ('hamburg', 0.222), ('schr', 0.22), ('menzel', 0.189), ('metric', 0.176), ('foth', 0.167), ('dependency', 0.159), ('reference', 0.152), ('translation', 0.147), ('acet', 0.139), ('mt', 0.134), ('parser', 0.12), ('german', 0.109), ('correlation', 0.108), ('embedded', 0.104), ('subtrees', 0.099), ('regent', 0.083), ('wmt', 0.081), ('candidate', 0.077), ('metrics', 0.076), ('trees', 0.074), ('constraint', 0.074), ('seventh', 0.073), ('owczarzak', 0.072), ('grammar', 0.069), ('judgments', 0.068), ('parse', 0.066), ('kendall', 0.066), ('tau', 0.066), ('der', 0.064), ('subtree', 0.064), ('graded', 0.064), ('duma', 0.063), ('fishel', 0.063), ('hamp', 0.063), ('katze', 0.063), ('niessen', 0.063), ('roten', 0.063), ('schnell', 0.063), ('schwarze', 0.063), ('springt', 0.063), ('terrorcat', 0.063), ('segment', 0.063), ('parsers', 0.061), ('translations', 0.061), ('dfki', 0.056), ('germanet', 0.056), ('popovic', 0.056), ('segments', 0.056), ('constraints', 0.055), ('syntactic', 0.051), ('auf', 0.051), ('jumps', 0.048), ('bler', 0.048), ('niehues', 0.048), ('zur', 0.048), ('coefficient', 0.048), ('bleu', 0.048), ('workshop', 0.047), ('evaluation', 0.045), ('chair', 0.044), ('tree', 0.043), ('obtained', 0.043), ('ungrammatical', 0.042), ('paraphrases', 0.041), ('ganitkevitch', 0.04), ('subsection', 0.039), ('parsing', 0.038), ('similarity', 0.038), ('den', 0.038), ('die', 0.038), ('violated', 0.038), ('edit', 0.037), ('constituent', 0.036), ('level', 0.036), ('machine', 0.035), ('monz', 0.035), ('lexical', 0.034), ('distance', 0.034), ('red', 0.033), ('influences', 0.033), ('weighted', 0.033), ('order', 0.033), ('measuring', 0.033), ('rankings', 0.032), ('assess', 0.032), ('rank', 0.031), ('intend', 0.031), ('ones', 0.031), ('daum', 0.031), ('cat', 0.031), ('ties', 0.03), ('score', 0.03), ('statistical', 0.03), ('grammars', 0.03), ('correlates', 0.03), ('ignored', 0.029), ('computed', 0.029), ('edge', 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999994 <a title="13-tfidf-1" href="./acl-2013-A_New_Syntactic_Metric_for_Evaluation_of_Machine_Translation.html">13 acl-2013-A New Syntactic Metric for Evaluation of Machine Translation</a></p>
<p>Author: Melania Duma ; Cristina Vertan ; Wolfgang Menzel</p><p>Abstract: Machine translation (MT) evaluation aims at measuring the quality of a candidate translation by comparing it with a reference translation. This comparison can be performed on multiple levels: lexical, syntactic or semantic. In this paper, we propose a new syntactic metric for MT evaluation based on the comparison of the dependency structures of the reference and the candidate translations. The dependency structures are obtained by means of a Weighted Constraints Dependency Grammar parser. Based on experiments performed on English to German translations, we show that the new metric correlates well with human judgments at the system level. 1</p><p>2 0.14332867 <a title="13-tfidf-2" href="./acl-2013-Improving_machine_translation_by_training_against_an_automatic_semantic_frame_based_evaluation_metric.html">195 acl-2013-Improving machine translation by training against an automatic semantic frame based evaluation metric</a></p>
<p>Author: Chi-kiu Lo ; Karteek Addanki ; Markus Saers ; Dekai Wu</p><p>Abstract: We present the first ever results showing that tuning a machine translation system against a semantic frame based objective function, MEANT, produces more robustly adequate translations than tuning against BLEU or TER as measured across commonly used metrics and human subjective evaluation. Moreover, for informal web forum data, human evaluators preferred MEANT-tuned systems over BLEU- or TER-tuned systems by a significantly wider margin than that for formal newswire—even though automatic semantic parsing might be expected to fare worse on informal language. We argue thatbypreserving the meaning ofthe trans- lations as captured by semantic frames right in the training process, an MT system is constrained to make more accurate choices of both lexical and reordering rules. As a result, MT systems tuned against semantic frame based MT evaluation metrics produce output that is more adequate. Tuning a machine translation system against a semantic frame based objective function is independent ofthe translation model paradigm, so, any translation model can benefit from the semantic knowledge incorporated to improve translation adequacy through our approach.</p><p>3 0.11635523 <a title="13-tfidf-3" href="./acl-2013-Name-aware_Machine_Translation.html">255 acl-2013-Name-aware Machine Translation</a></p>
<p>Author: Haibo Li ; Jing Zheng ; Heng Ji ; Qi Li ; Wen Wang</p><p>Abstract: We propose a Name-aware Machine Translation (MT) approach which can tightly integrate name processing into MT model, by jointly annotating parallel corpora, extracting name-aware translation grammar and rules, adding name phrase table and name translation driven decoding. Additionally, we also propose a new MT metric to appropriately evaluate the translation quality of informative words, by assigning different weights to different words according to their importance values in a document. Experiments on Chinese-English translation demonstrated the effectiveness of our approach on enhancing the quality of overall translation, name translation and word alignment over a high-quality MT baseline1 .</p><p>4 0.11331266 <a title="13-tfidf-4" href="./acl-2013-English-to-Russian_MT_evaluation_campaign.html">135 acl-2013-English-to-Russian MT evaluation campaign</a></p>
<p>Author: Pavel Braslavski ; Alexander Beloborodov ; Maxim Khalilov ; Serge Sharoff</p><p>Abstract: This paper presents the settings and the results of the ROMIP 2013 MT shared task for the English→Russian language directfioorn. t Teh Een quality Rofu generated utraagnsel datiiroencswas assessed using automatic metrics and human evaluation. We also discuss ways to reduce human evaluation efforts using pairwise sentence comparisons by human judges to simulate sort operations.</p><p>5 0.1070985 <a title="13-tfidf-5" href="./acl-2013-Joint_Inference_for_Heterogeneous_Dependency_Parsing.html">208 acl-2013-Joint Inference for Heterogeneous Dependency Parsing</a></p>
<p>Author: Guangyou Zhou ; Jun Zhao</p><p>Abstract: This paper is concerned with the problem of heterogeneous dependency parsing. In this paper, we present a novel joint inference scheme, which is able to leverage the consensus information between heterogeneous treebanks in the parsing phase. Different from stacked learning methods (Nivre and McDonald, 2008; Martins et al., 2008), which process the dependency parsing in a pipelined way (e.g., a second level uses the first level outputs), in our method, multiple dependency parsing models are coordinated to exchange consensus information. We conduct experiments on Chinese Dependency Treebank (CDT) and Penn Chinese Treebank (CTB), experimental results show that joint infer- ence can bring significant improvements to all state-of-the-art dependency parsers.</p><p>6 0.10640141 <a title="13-tfidf-6" href="./acl-2013-Dependency_Parser_Adaptation_with_Subtrees_from_Auto-Parsed_Target_Domain_Data.html">112 acl-2013-Dependency Parser Adaptation with Subtrees from Auto-Parsed Target Domain Data</a></p>
<p>7 0.10431558 <a title="13-tfidf-7" href="./acl-2013-A_Shift-Reduce_Parsing_Algorithm_for_Phrase-based_String-to-Dependency_Translation.html">19 acl-2013-A Shift-Reduce Parsing Algorithm for Phrase-based String-to-Dependency Translation</a></p>
<p>8 0.10328433 <a title="13-tfidf-8" href="./acl-2013-Fast_and_Accurate_Shift-Reduce_Constituent_Parsing.html">155 acl-2013-Fast and Accurate Shift-Reduce Constituent Parsing</a></p>
<p>9 0.10022461 <a title="13-tfidf-9" href="./acl-2013-Travatar%3A_A_Forest-to-String_Machine_Translation_Engine_based_on_Tree_Transducers.html">361 acl-2013-Travatar: A Forest-to-String Machine Translation Engine based on Tree Transducers</a></p>
<p>10 0.099588893 <a title="13-tfidf-10" href="./acl-2013-Universal_Dependency_Annotation_for_Multilingual_Parsing.html">368 acl-2013-Universal Dependency Annotation for Multilingual Parsing</a></p>
<p>11 0.097106718 <a title="13-tfidf-11" href="./acl-2013-The_Effect_of_Higher-Order_Dependency_Features_in_Discriminative_Phrase-Structure_Parsing.html">343 acl-2013-The Effect of Higher-Order Dependency Features in Discriminative Phrase-Structure Parsing</a></p>
<p>12 0.093697071 <a title="13-tfidf-12" href="./acl-2013-A_Markov_Model_of_Machine_Translation_using_Non-parametric_Bayesian_Inference.html">10 acl-2013-A Markov Model of Machine Translation using Non-parametric Bayesian Inference</a></p>
<p>13 0.09318357 <a title="13-tfidf-13" href="./acl-2013-Semantic_Parsing_as_Machine_Translation.html">312 acl-2013-Semantic Parsing as Machine Translation</a></p>
<p>14 0.090333052 <a title="13-tfidf-14" href="./acl-2013-Transition-based_Dependency_Parsing_with_Selectional_Branching.html">358 acl-2013-Transition-based Dependency Parsing with Selectional Branching</a></p>
<p>15 0.089894317 <a title="13-tfidf-15" href="./acl-2013-QuEst_-_A_translation_quality_estimation_framework.html">289 acl-2013-QuEst - A translation quality estimation framework</a></p>
<p>16 0.087692663 <a title="13-tfidf-16" href="./acl-2013-A_Transition-Based_Dependency_Parser_Using_a_Dynamic_Parsing_Strategy.html">26 acl-2013-A Transition-Based Dependency Parser Using a Dynamic Parsing Strategy</a></p>
<p>17 0.087537631 <a title="13-tfidf-17" href="./acl-2013-Semantic_Roles_for_String_to_Tree_Machine_Translation.html">314 acl-2013-Semantic Roles for String to Tree Machine Translation</a></p>
<p>18 0.08421541 <a title="13-tfidf-18" href="./acl-2013-Dirt_Cheap_Web-Scale_Parallel_Text_from_the_Common_Crawl.html">120 acl-2013-Dirt Cheap Web-Scale Parallel Text from the Common Crawl</a></p>
<p>19 0.083263986 <a title="13-tfidf-19" href="./acl-2013-Learning_a_Phrase-based_Translation_Model_from_Monolingual_Data_with_Application_to_Domain_Adaptation.html">223 acl-2013-Learning a Phrase-based Translation Model from Monolingual Data with Application to Domain Adaptation</a></p>
<p>20 0.08139959 <a title="13-tfidf-20" href="./acl-2013-A_Multi-Domain_Translation_Model_Framework_for_Statistical_Machine_Translation.html">11 acl-2013-A Multi-Domain Translation Model Framework for Statistical Machine Translation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.222), (1, -0.133), (2, 0.013), (3, 0.022), (4, -0.092), (5, 0.001), (6, 0.043), (7, -0.011), (8, 0.068), (9, -0.043), (10, -0.04), (11, 0.092), (12, -0.062), (13, 0.056), (14, 0.012), (15, 0.057), (16, -0.029), (17, -0.026), (18, -0.025), (19, 0.035), (20, 0.055), (21, -0.009), (22, -0.052), (23, -0.01), (24, -0.099), (25, 0.018), (26, -0.019), (27, 0.077), (28, -0.003), (29, 0.059), (30, -0.014), (31, -0.024), (32, 0.026), (33, -0.005), (34, 0.036), (35, -0.035), (36, -0.101), (37, 0.039), (38, 0.023), (39, -0.026), (40, -0.03), (41, 0.073), (42, -0.034), (43, -0.114), (44, -0.042), (45, -0.048), (46, -0.029), (47, -0.051), (48, -0.058), (49, -0.084)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95284146 <a title="13-lsi-1" href="./acl-2013-A_New_Syntactic_Metric_for_Evaluation_of_Machine_Translation.html">13 acl-2013-A New Syntactic Metric for Evaluation of Machine Translation</a></p>
<p>Author: Melania Duma ; Cristina Vertan ; Wolfgang Menzel</p><p>Abstract: Machine translation (MT) evaluation aims at measuring the quality of a candidate translation by comparing it with a reference translation. This comparison can be performed on multiple levels: lexical, syntactic or semantic. In this paper, we propose a new syntactic metric for MT evaluation based on the comparison of the dependency structures of the reference and the candidate translations. The dependency structures are obtained by means of a Weighted Constraints Dependency Grammar parser. Based on experiments performed on English to German translations, we show that the new metric correlates well with human judgments at the system level. 1</p><p>2 0.71800673 <a title="13-lsi-2" href="./acl-2013-English-to-Russian_MT_evaluation_campaign.html">135 acl-2013-English-to-Russian MT evaluation campaign</a></p>
<p>Author: Pavel Braslavski ; Alexander Beloborodov ; Maxim Khalilov ; Serge Sharoff</p><p>Abstract: This paper presents the settings and the results of the ROMIP 2013 MT shared task for the English→Russian language directfioorn. t Teh Een quality Rofu generated utraagnsel datiiroencswas assessed using automatic metrics and human evaluation. We also discuss ways to reduce human evaluation efforts using pairwise sentence comparisons by human judges to simulate sort operations.</p><p>3 0.70573616 <a title="13-lsi-3" href="./acl-2013-Improving_machine_translation_by_training_against_an_automatic_semantic_frame_based_evaluation_metric.html">195 acl-2013-Improving machine translation by training against an automatic semantic frame based evaluation metric</a></p>
<p>Author: Chi-kiu Lo ; Karteek Addanki ; Markus Saers ; Dekai Wu</p><p>Abstract: We present the first ever results showing that tuning a machine translation system against a semantic frame based objective function, MEANT, produces more robustly adequate translations than tuning against BLEU or TER as measured across commonly used metrics and human subjective evaluation. Moreover, for informal web forum data, human evaluators preferred MEANT-tuned systems over BLEU- or TER-tuned systems by a significantly wider margin than that for formal newswire—even though automatic semantic parsing might be expected to fare worse on informal language. We argue thatbypreserving the meaning ofthe trans- lations as captured by semantic frames right in the training process, an MT system is constrained to make more accurate choices of both lexical and reordering rules. As a result, MT systems tuned against semantic frame based MT evaluation metrics produce output that is more adequate. Tuning a machine translation system against a semantic frame based objective function is independent ofthe translation model paradigm, so, any translation model can benefit from the semantic knowledge incorporated to improve translation adequacy through our approach.</p><p>4 0.68840778 <a title="13-lsi-4" href="./acl-2013-Automatically_Predicting_Sentence_Translation_Difficulty.html">64 acl-2013-Automatically Predicting Sentence Translation Difficulty</a></p>
<p>Author: Abhijit Mishra ; Pushpak Bhattacharyya ; Michael Carl</p><p>Abstract: In this paper we introduce Translation Difficulty Index (TDI), a measure of difficulty in text translation. We first define and quantify translation difficulty in terms of TDI. We realize that any measure of TDI based on direct input by translators is fraught with subjectivity and adhocism. We, rather, rely on cognitive evidences from eye tracking. TDI is measured as the sum of fixation (gaze) and saccade (rapid eye movement) times of the eye. We then establish that TDI is correlated with three properties of the input sentence, viz. length (L), degree of polysemy (DP) and structural complexity (SC). We train a Support Vector Regression (SVR) system to predict TDIs for new sentences using these features as input. The prediction done by our framework is well correlated with the empirical gold standard data, which is a repository of < L, DP, SC > and TDI pairs for a set of sentences. The primary use of our work is a way of “binning” sentences (to be translated) in “easy”, “medium” and “hard” categories as per their predicted TDI. This can decide pricing of any translation task, especially useful in a scenario where parallel corpora for Machine Translation are built through translation crowdsourcing/outsourcing. This can also provide a way of monitoring progress of second language learners.</p><p>5 0.66232115 <a title="13-lsi-5" href="./acl-2013-Deepfix%3A_Statistical_Post-editing_of_Statistical_Machine_Translation_Using_Deep_Syntactic_Analysis.html">110 acl-2013-Deepfix: Statistical Post-editing of Statistical Machine Translation Using Deep Syntactic Analysis</a></p>
<p>Author: Rudolf Rosa ; David Marecek ; Ales Tamchyna</p><p>Abstract: Deepfix is a statistical post-editing system for improving the quality of statistical machine translation outputs. It attempts to correct errors in verb-noun valency using deep syntactic analysis and a simple probabilistic model of valency. On the English-to-Czech translation pair, we show that statistical post-editing of statistical machine translation leads to an improvement of the translation quality when helped by deep linguistic knowledge.</p><p>6 0.63928258 <a title="13-lsi-6" href="./acl-2013-Semantic_Parsing_as_Machine_Translation.html">312 acl-2013-Semantic Parsing as Machine Translation</a></p>
<p>7 0.61093718 <a title="13-lsi-7" href="./acl-2013-Translating_Italian_connectives_into_Italian_Sign_Language.html">360 acl-2013-Translating Italian connectives into Italian Sign Language</a></p>
<p>8 0.61062288 <a title="13-lsi-8" href="./acl-2013-A_Shift-Reduce_Parsing_Algorithm_for_Phrase-based_String-to-Dependency_Translation.html">19 acl-2013-A Shift-Reduce Parsing Algorithm for Phrase-based String-to-Dependency Translation</a></p>
<p>9 0.6094647 <a title="13-lsi-9" href="./acl-2013-Name-aware_Machine_Translation.html">255 acl-2013-Name-aware Machine Translation</a></p>
<p>10 0.60127282 <a title="13-lsi-10" href="./acl-2013-SORT%3A_An_Interactive_Source-Rewriting_Tool_for_Improved_Translation.html">305 acl-2013-SORT: An Interactive Source-Rewriting Tool for Improved Translation</a></p>
<p>11 0.59515959 <a title="13-lsi-11" href="./acl-2013-Smatch%3A_an_Evaluation_Metric_for_Semantic_Feature_Structures.html">324 acl-2013-Smatch: an Evaluation Metric for Semantic Feature Structures</a></p>
<p>12 0.59389067 <a title="13-lsi-12" href="./acl-2013-QuEst_-_A_translation_quality_estimation_framework.html">289 acl-2013-QuEst - A translation quality estimation framework</a></p>
<p>13 0.58462566 <a title="13-lsi-13" href="./acl-2013-Context-Dependent_Multilingual_Lexical_Lookup_for_Under-Resourced_Languages.html">92 acl-2013-Context-Dependent Multilingual Lexical Lookup for Under-Resourced Languages</a></p>
<p>14 0.58456385 <a title="13-lsi-14" href="./acl-2013-Travatar%3A_A_Forest-to-String_Machine_Translation_Engine_based_on_Tree_Transducers.html">361 acl-2013-Travatar: A Forest-to-String Machine Translation Engine based on Tree Transducers</a></p>
<p>15 0.58358735 <a title="13-lsi-15" href="./acl-2013-The_Effect_of_Higher-Order_Dependency_Features_in_Discriminative_Phrase-Structure_Parsing.html">343 acl-2013-The Effect of Higher-Order Dependency Features in Discriminative Phrase-Structure Parsing</a></p>
<p>16 0.58211708 <a title="13-lsi-16" href="./acl-2013-From_Natural_Language_Specifications_to_Program_Input_Parsers.html">163 acl-2013-From Natural Language Specifications to Program Input Parsers</a></p>
<p>17 0.57537878 <a title="13-lsi-17" href="./acl-2013-A_Novel_Translation_Framework_Based_on_Rhetorical_Structure_Theory.html">16 acl-2013-A Novel Translation Framework Based on Rhetorical Structure Theory</a></p>
<p>18 0.56543064 <a title="13-lsi-18" href="./acl-2013-On_the_Predictability_of_Human_Assessment%3A_when_Matrix_Completion_Meets_NLP_Evaluation.html">263 acl-2013-On the Predictability of Human Assessment: when Matrix Completion Meets NLP Evaluation</a></p>
<p>19 0.56433058 <a title="13-lsi-19" href="./acl-2013-Coordination_Structures_in_Dependency_Treebanks.html">94 acl-2013-Coordination Structures in Dependency Treebanks</a></p>
<p>20 0.55496567 <a title="13-lsi-20" href="./acl-2013-Joint_Inference_for_Heterogeneous_Dependency_Parsing.html">208 acl-2013-Joint Inference for Heterogeneous Dependency Parsing</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.061), (6, 0.046), (11, 0.046), (14, 0.33), (15, 0.023), (24, 0.03), (26, 0.03), (35, 0.066), (42, 0.056), (48, 0.034), (70, 0.029), (88, 0.015), (90, 0.04), (95, 0.128)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.79543018 <a title="13-lda-1" href="./acl-2013-Transfer_Learning_for_Constituency-Based_Grammars.html">357 acl-2013-Transfer Learning for Constituency-Based Grammars</a></p>
<p>Author: Yuan Zhang ; Regina Barzilay ; Amir Globerson</p><p>Abstract: In this paper, we consider the problem of cross-formalism transfer in parsing. We are interested in parsing constituencybased grammars such as HPSG and CCG using a small amount of data specific for the target formalism, and a large quantity of coarse CFG annotations from the Penn Treebank. While all of the target formalisms share a similar basic syntactic structure with Penn Treebank CFG, they also encode additional constraints and semantic features. To handle this apparent discrepancy, we design a probabilistic model that jointly generates CFG and target formalism parses. The model includes features of both parses, allowing trans- fer between the formalisms, while preserving parsing efficiency. We evaluate our approach on three constituency-based grammars CCG, HPSG, and LFG, augmented with the Penn Treebank-1. Our experiments show that across all three formalisms, the target parsers significantly benefit from the coarse annotations.1 —</p><p>same-paper 2 0.74294341 <a title="13-lda-2" href="./acl-2013-A_New_Syntactic_Metric_for_Evaluation_of_Machine_Translation.html">13 acl-2013-A New Syntactic Metric for Evaluation of Machine Translation</a></p>
<p>Author: Melania Duma ; Cristina Vertan ; Wolfgang Menzel</p><p>Abstract: Machine translation (MT) evaluation aims at measuring the quality of a candidate translation by comparing it with a reference translation. This comparison can be performed on multiple levels: lexical, syntactic or semantic. In this paper, we propose a new syntactic metric for MT evaluation based on the comparison of the dependency structures of the reference and the candidate translations. The dependency structures are obtained by means of a Weighted Constraints Dependency Grammar parser. Based on experiments performed on English to German translations, we show that the new metric correlates well with human judgments at the system level. 1</p><p>3 0.70617443 <a title="13-lda-3" href="./acl-2013-Semantic_Roles_for_String_to_Tree_Machine_Translation.html">314 acl-2013-Semantic Roles for String to Tree Machine Translation</a></p>
<p>Author: Marzieh Bazrafshan ; Daniel Gildea</p><p>Abstract: We experiment with adding semantic role information to a string-to-tree machine translation system based on the rule extraction procedure of Galley et al. (2004). We compare methods based on augmenting the set of nonterminals by adding semantic role labels, and altering the rule extraction process to produce a separate set of rules for each predicate that encompass its entire predicate-argument structure. Our results demonstrate that the second approach is effective in increasing the quality of translations.</p><p>4 0.69634008 <a title="13-lda-4" href="./acl-2013-A_corpus-based_evaluation_method_for_Distributional_Semantic_Models.html">31 acl-2013-A corpus-based evaluation method for Distributional Semantic Models</a></p>
<p>Author: Abdellah Fourtassi ; Emmanuel Dupoux</p><p>Abstract: Evaluation methods for Distributional Semantic Models typically rely on behaviorally derived gold standards. These methods are difficult to deploy in languages with scarce linguistic/behavioral resources. We introduce a corpus-based measure that evaluates the stability of the lexical semantic similarity space using a pseudo-synonym same-different detection task and no external resources. We show that it enables to predict two behaviorbased measures across a range of parameters in a Latent Semantic Analysis model.</p><p>5 0.65720493 <a title="13-lda-5" href="./acl-2013-Enlisting_the_Ghost%3A_Modeling_Empty_Categories_for_Machine_Translation.html">137 acl-2013-Enlisting the Ghost: Modeling Empty Categories for Machine Translation</a></p>
<p>Author: Bing Xiang ; Xiaoqiang Luo ; Bowen Zhou</p><p>Abstract: Empty categories (EC) are artificial elements in Penn Treebanks motivated by the government-binding (GB) theory to explain certain language phenomena such as pro-drop. ECs are ubiquitous in languages like Chinese, but they are tacitly ignored in most machine translation (MT) work because of their elusive nature. In this paper we present a comprehensive treatment of ECs by first recovering them with a structured MaxEnt model with a rich set of syntactic and lexical features, and then incorporating the predicted ECs into a Chinese-to-English machine translation task through multiple approaches, including the extraction of EC-specific sparse features. We show that the recovered empty categories not only improve the word alignment quality, but also lead to significant improvements in a large-scale state-of-the-art syntactic MT system.</p><p>6 0.52281946 <a title="13-lda-6" href="./acl-2013-Robust_multilingual_statistical_morphological_generation_models.html">303 acl-2013-Robust multilingual statistical morphological generation models</a></p>
<p>7 0.51877129 <a title="13-lda-7" href="./acl-2013-PARMA%3A_A_Predicate_Argument_Aligner.html">267 acl-2013-PARMA: A Predicate Argument Aligner</a></p>
<p>8 0.50611275 <a title="13-lda-8" href="./acl-2013-Joint_Apposition_Extraction_with_Syntactic_and_Semantic_Constraints.html">205 acl-2013-Joint Apposition Extraction with Syntactic and Semantic Constraints</a></p>
<p>9 0.5038777 <a title="13-lda-9" href="./acl-2013-Iterative_Transformation_of_Annotation_Guidelines_for_Constituency_Parsing.html">204 acl-2013-Iterative Transformation of Annotation Guidelines for Constituency Parsing</a></p>
<p>10 0.50301242 <a title="13-lda-10" href="./acl-2013-Explicit_and_Implicit_Syntactic_Features_for_Text_Classification.html">144 acl-2013-Explicit and Implicit Syntactic Features for Text Classification</a></p>
<p>11 0.50182223 <a title="13-lda-11" href="./acl-2013-The_Effects_of_Lexical_Resource_Quality_on_Preference_Violation_Detection.html">344 acl-2013-The Effects of Lexical Resource Quality on Preference Violation Detection</a></p>
<p>12 0.49689659 <a title="13-lda-12" href="./acl-2013-A_Context_Free_TAG_Variant.html">4 acl-2013-A Context Free TAG Variant</a></p>
<p>13 0.49620771 <a title="13-lda-13" href="./acl-2013-Fast_and_Accurate_Shift-Reduce_Constituent_Parsing.html">155 acl-2013-Fast and Accurate Shift-Reduce Constituent Parsing</a></p>
<p>14 0.49122828 <a title="13-lda-14" href="./acl-2013-A_Decade_of_Automatic_Content_Evaluation_of_News_Summaries%3A_Reassessing_the_State_of_the_Art.html">5 acl-2013-A Decade of Automatic Content Evaluation of News Summaries: Reassessing the State of the Art</a></p>
<p>15 0.49012697 <a title="13-lda-15" href="./acl-2013-Microblogs_as_Parallel_Corpora.html">240 acl-2013-Microblogs as Parallel Corpora</a></p>
<p>16 0.48817444 <a title="13-lda-16" href="./acl-2013-Travatar%3A_A_Forest-to-String_Machine_Translation_Engine_based_on_Tree_Transducers.html">361 acl-2013-Travatar: A Forest-to-String Machine Translation Engine based on Tree Transducers</a></p>
<p>17 0.48814881 <a title="13-lda-17" href="./acl-2013-Simple%2C_readable_sub-sentences.html">322 acl-2013-Simple, readable sub-sentences</a></p>
<p>18 0.48756173 <a title="13-lda-18" href="./acl-2013-What_causes_a_causal_relation%3F_Detecting_Causal_Triggers_in_Biomedical_Scientific_Discourse.html">386 acl-2013-What causes a causal relation? Detecting Causal Triggers in Biomedical Scientific Discourse</a></p>
<p>19 0.4867121 <a title="13-lda-19" href="./acl-2013-A_Tightly-coupled_Unsupervised_Clustering_and_Bilingual_Alignment_Model_for_Transliteration.html">25 acl-2013-A Tightly-coupled Unsupervised Clustering and Bilingual Alignment Model for Transliteration</a></p>
<p>20 0.4865889 <a title="13-lda-20" href="./acl-2013-Chinese_Parsing_Exploiting_Characters.html">80 acl-2013-Chinese Parsing Exploiting Characters</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
