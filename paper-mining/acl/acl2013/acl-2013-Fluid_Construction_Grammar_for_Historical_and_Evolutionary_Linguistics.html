<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>161 acl-2013-Fluid Construction Grammar for Historical and Evolutionary Linguistics</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-161" href="#">acl2013-161</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>161 acl-2013-Fluid Construction Grammar for Historical and Evolutionary Linguistics</h1>
<br/><p>Source: <a title="acl-2013-161-pdf" href="http://aclweb.org/anthology//P/P13/P13-4022.pdf">pdf</a></p><p>Author: Pieter Wellens ; Remi van Trijp ; Katrien Beuls ; Luc Steels</p><p>Abstract: Fluid Construction Grammar (FCG) is an open-source computational grammar formalism that is becoming increasingly popular for studying the history and evolution of language. This demonstration shows how FCG can be used to operationalise the cultural processes and cognitive mechanisms that underly language evolution and change.</p><p>Reference: <a title="acl-2013-161-reference" href="../acl2013_reference/acl-2013-Fluid_Construction_Grammar_for_Historical_and_Evolutionary_Linguistics_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Fluid Construction Grammar for Historical and Evolutionary Linguistics Pieter Wellens1, Remi 1VUB AI Lab Pleinlaan 2 1050 Brussels (Belgium) pieter | kat rien@  . [sent-1, score-0.121]
</p><p>2 ai vub  van  Trijp2, Katrien Beuls1, Luc Steels2,3  2Sony Computer Science Laboratory Paris 6 Rue Amyot 75005 Paris (France)  . [sent-2, score-0.092]
</p><p>3 remi @ c s l  Abstract Fluid Construction Grammar (FCG) is an open-source computational grammar formalism that is becoming increasingly popular for studying the history and evolution of language. [sent-5, score-0.357]
</p><p>4 This demonstration shows how FCG can be used to operationalise the cultural processes and cognitive mechanisms that underly language evolution and change. [sent-6, score-0.212]
</p><p>5 Ever increasing datasets, both in size and richness of anno-  tation, are becoming available (Yuri et al. [sent-8, score-0.019]
</p><p>6 , 2012; Davies, 2011), and linguists now have more powerful tools at their disposal for uncovering which changes have taken place. [sent-9, score-0.046]
</p><p>7 In this demonstration, we present Fluid Construction Grammar (Steels, 2011, FCG), an open-source grammar formalism that makes it possible to also address the question of how these changes happened by uncovering the cognitive mechanisms and cultural processes that drive language evolution. [sent-10, score-0.312]
</p><p>8 FCG combines the expressive power of feature structures and unification with the adaptivity and robustnes of machine learners. [sent-11, score-0.022]
</p><p>9 2  Design Philosophy  Fluid Construction Grammar is rooted in a cognitive-functional approach to language, which  is quite different from a generative grammar such s ony . [sent-16, score-0.103]
</p><p>10 A generative grammar is a model of language competence that licenses well-formed structures and rejects illformed utterances. [sent-21, score-0.103]
</p><p>11 Such grammars often decide on the well- or ill-formedness of utterances by using a strong type system that defines a set of features and possible values for those features. [sent-22, score-0.022]
</p><p>12 The burden of efficient and robust language processing with a generative grammar largely rests on the shoulders of the language processor. [sent-23, score-0.103]
</p><p>13 In parsing, such a grammar tries to uncover as much meaning as possible from a given utterance rather than deciding on its grammaticality. [sent-25, score-0.103]
</p><p>14 In the other direction, the grammar tries to produce intelligible utterances, which are well-formed as a side-effect if the grammar adequately captures the conventions of a particular language. [sent-26, score-0.226]
</p><p>15 A cognitive-functional grammar can best be implemented without a strong type system because the set of possible features and values for  them is assumed to be open-ended. [sent-27, score-0.103]
</p><p>16 Efficient and robust language processing also becomes a joint responsibility of the grammar and the linguistic processor. [sent-28, score-0.139]
</p><p>17 3 Reversible Language Processing As a construction grammar, FCG represents all linguistic knowledge as pairings of function and form (called constructions). [sent-29, score-0.137]
</p><p>18 This means that any linguistic item, be it a concrete lexical item (see Figure 1) or a schematic construction, shares the same fundamental representation in FCG. [sent-30, score-0.067]
</p><p>19 Each construction consists of two poles (a semantic/functional one and a syntactic/form one), each represented as a feature structure. [sent-31, score-0.136]
</p><p>20 By using a separate semantic and syntactic pole, FCG allows the same construction to be efficiently parsed and produced by the same processing engine by simply changing the direction of application. [sent-32, score-0.101]
</p><p>21 c A2s0s1o3ci Aatsiosonc fioartio Cno fmorpu Ctoamtiopnuatalt Lioin gauli Lsitnicgsu,i psatgices 127–132,  Figure 1: Lexical construction for the proper noun “Kim” as shown in the FCG web interface. [sent-35, score-0.101]
</p><p>22 All constructions are mappings between semantic (left) and syntactic feature structures (right). [sent-36, score-0.125]
</p><p>23 FCG processing uses two different kinds of unification called match and merge. [sent-37, score-0.022]
</p><p>24 going from meaning to form), the processor will consider a construction’s  semantic pole as a set of conditions that need to be satisfied, and the syntactic pole as additional information that can be contributed by the constructi1o2/n6/1. [sent-42, score-0.106]
</p><p>25 going from form to meaning), the roles of the poles are reversed. [sent-45, score-0.035]
</p><p>26 Since FCG pays a lot of attention to the interaction between linguistic knowledge and processing, it makes it possible to investigate the consequences of particular aspects of grammar with regard to representation, production, parsing, learning and propagation (in a population of language users). [sent-46, score-0.172]
</p><p>27 It is exactly this ability to monitor the impact of grammatical choices, that has sparked the interest of an increasingly wide audience of historical and evolutionary linguists. [sent-49, score-0.179]
</p><p>28 With FCG, different historical stages can be implemented (which addresses  questions about representation and processing) but FCG also comes bundled with a reflective learning framework (Beuls et al. [sent-50, score-0.15]
</p><p>29 , 2012) for learning the key constructions of each stage. [sent-51, score-0.125]
</p><p>30 That same architecture has proven to be adequately powerful to implement processes ofgrammaticalization so that  Figure 2: Schematic overview of the experimental methodology for historical and evolutionary linguists. [sent-52, score-0.203]
</p><p>31 The example here shows only two linguistic stages but there could be more. [sent-53, score-0.036]
</p><p>32 actual linguistic change over time can be modeled (van Trijp, 2010; Beuls and Steels, 2013; Wellens and Loetzsch, 2012). [sent-54, score-0.036]
</p><p>33 4  How to set up an evolutionary linguistics experiment in FCG? [sent-55, score-0.066]
</p><p>34 As the FCG processor can both produce and parse utterances it is possible to instantiate not one but a set or population of FCG processors (or FCG agents) that can communicatively interact with each other. [sent-56, score-0.077]
</p><p>35 Experiments in historical or evolutionary linguistics make use of this multiagent approach where all agents engage in situated pairwise interactions (language games) (Steels, 2012b). [sent-57, score-0.165]
</p><p>36 In this systems demo we will focus on a recent experiment in the emergence of grammatical agreement (Beuls and Steels, 2013). [sent-58, score-0.123]
</p><p>37 The language game consists of two agents in which one agent (the speaker) has to describe one or more (max three) objects in a scene to the other agent (the hearer). [sent-59, score-0.112]
</p><p>38 It follows that without any grammatical marking it would be difficult (often impossible) for the hearer to figure out which words describe the same object and thus to arrive at a successful interpretation. [sent-61, score-0.102]
</p><p>39 The hypothesis is that the introduction of agreement markers helps solve this ambiguity. [sent-62, score-0.058]
</p><p>40 Next to setting up a language game script the methodology consists of operationalizing the linguistic strategies required for a population to bootstrap and maintain a particular linguistic system (in this case nominal agreement). [sent-63, score-0.175]
</p><p>41 Examples of lin128  meta-layer processing  repair  diagnostic repair diagnostic dpiraognbolesmtic dpiraogbnolesmtic  ! [sent-64, score-0.204]
</p><p>42 " routine processing  Figure 3: Reflective meta-layer architecture operating as part of an FCG agent/processor. [sent-66, score-0.022]
</p><p>43 guistic systems already investigated include German case (van Trijp, 2012a; van Trijp, 2013), the grammatical expression of space (Spranger and Steels, 2012), the emergence of quantifiers (Pauw and Hilferty, 2012) and the expression of aspect in Russian (Gerasymova et al. [sent-67, score-0.155]
</p><p>44 An experiment generally investigates multiple linguistic systems of increasing complexity where each system can, but need not, map to a stage along an attested grammaticalization pathway. [sent-69, score-0.141]
</p><p>45 Most often a stage is introduced in order to gradually increase the complexity of the emergent dynamics. [sent-70, score-0.045]
</p><p>46 Implementing and linking together all the components involved in a single system is a highly non-trivial undertaking and our methodology prescribes the following four steps to undertake for each system (see also Figure 2). [sent-72, score-0.018]
</p><p>47 Reconstruction: A full operationalization of all the constructions (lexical and grammatical) involved in the chosen linguistic phenomena. [sent-73, score-0.161]
</p><p>48 When multiple agents are initialized with these constructions they should be able to communicate successfully with each other. [sent-74, score-0.187]
</p><p>49 This stage serves primarily to test and verify intuitions about the different linguistic systems. [sent-75, score-0.054]
</p><p>50 Individual Learning: Implementation of learning algorithms (or re-use of existing ones)  Figure 4: Meaningful marker strategy. [sent-76, score-0.018]
</p><p>51 so that one agent can learn the constructions based on the input of another agent. [sent-77, score-0.147]
</p><p>52 These learning operations are generally divided into diagnostics and repair strategies (see Figure 3). [sent-78, score-0.163]
</p><p>53 Diagnostics continually monitor FCG processing for errors or inefficiencies and generate problems if they are found. [sent-79, score-0.021]
</p><p>54 Repair strategies then act on these problems by altering the linguistic inventory (e. [sent-80, score-0.059]
</p><p>55 Population Alignment: There exists a large gap between the cognitive machinary needed for  learning an existing linguistic system (step 2) and bootstrapping, aligning and maintaining a complete linguistic system from scratch. [sent-83, score-0.099]
</p><p>56 Grammaticalization: Moving from one linguistic system to another is the final step of the experiment. [sent-85, score-0.036]
</p><p>57 The challenge is to find and implement the mechanisms that drive grammaticalization (Heine and Kuteva, 2007) in line with observed grammaticalization pathways. [sent-86, score-0.221]
</p><p>58 As an example we’ll give a short sketch of one possible game as played in the meaningful marker strategy as schematically shown in Figure 4. [sent-87, score-0.112]
</p><p>59 The sketch shows a context of four objects (O1 to O4), each described by three features. [sent-88, score-0.023]
</p><p>60 The speaker chooses topic O1 O2 which, given his vocabulary (shown top right), results in uttering “shuqfon sizhic zabu”. [sent-89, score-0.055]
</p><p>61 In order to explicitly communicate this linking the  +  speaker attaches the markers “-ti” and “-ta” so that their meaning is compatible with the objects they are linking as shown in the Figure. [sent-91, score-0.118]
</p><p>62 Diamond shaped nodes represent lexical constructions, egg shaped nodes represent grammatical constructions and rectangular nodes represent semantic categories. [sent-93, score-0.213]
</p><p>63 PREP] primes the category LOCATIVE RELATION which in turn primes both the [LOCATIVE RELATION] and [SPATIAL PHRASE] constructions. [sent-96, score-0.084]
</p><p>64 Both of these constructions also require a semantic category [REFERENT]. [sent-97, score-0.125]
</p><p>65 the hearer to arrive at a single non-ambiguous interpretation. [sent-98, score-0.068]
</p><p>66 For more details we refer the reader to (Beuls and Steels, 2013) and the web demo at http://ai. [sent-99, score-0.025]
</p><p>67 Reversible bidirectional processing, a single data representation for all linguistic knowledge, a reflective meta-layer architecture for  learning and a multi-agent component for managing multiple interacting FCG instances. [sent-104, score-0.119]
</p><p>68 FCG comes bundled with a library of heuristics and goal tests and with a bit of programming skills users can add new primitives easily. [sent-111, score-0.031]
</p><p>69 Customizable construction inventory: By default, FCG stores all constructions in one large set. [sent-112, score-0.226]
</p><p>70 One popular option is to organize constructions in smaller subsets (Beuls, 2011) like lexical, morphological, functional, etc. [sent-114, score-0.125]
</p><p>71 Another option is to use networks (Wellens, 2011) that can learn co-occurrence relations between constructions and “prime” constructions when they are likely to apply (see Figure 5). [sent-115, score-0.25]
</p><p>72 Interfaces to external repositories: FCG can connect to external repositories like Framenet (Baker et al. [sent-116, score-0.021]
</p><p>73 Robustness: FCG continues operation as far as it can get even if some constructions do not apply (Steels and van Trijp, 2011). [sent-119, score-0.199]
</p><p>74 Sup-  plied with appropriate diagnostics and repair strategies FCG can even recover from errors (van Trijp, 2012b). [sent-120, score-0.163]
</p><p>75 It is written in Common Lisp (CLOS) and compatible with most popular lisp implementations (SBCL, CCL, Lispworks, . [sent-124, score-0.035]
</p><p>76 FCG builds on many existing and proven technologies and adds new innovations to the mix resulting in a user friendly, yet powerful and extensible framework for in-depth investigations in natural language phenomena. [sent-134, score-0.019]
</p><p>77 Acknowledgments The FCG formalism is being developed at the Artificial Intelligence Laboratory of the Vrije Universiteit Brussel and the Sony Computer Science Laboratory in Paris. [sent-135, score-0.024]
</p><p>78 Remi van Trijp is funded by the Sony Computer Science Laboratory Paris. [sent-138, score-0.074]
</p><p>79 Agent-based models of strategies for the emergence and evolution of grammatical agreement. [sent-150, score-0.177]
</p><p>80 N-grams and word frequency data from the corpus of historical american english (coha). [sent-169, score-0.058]
</p><p>81 A language strategy for aspect: Encoding aktionsarten through morphology. [sent-172, score-0.025]
</p><p>82 van Rijn, editors, the 31th Annual Conference of the Cognitive Science Society, pages 3023–3027. [sent-193, score-0.074]
</p><p>83 Not as awful as it seems : Explaining german case through computational experiments in fluid construction grammar. [sent-239, score-0.407]
</p><p>84 Linguistic assessment crite-  ria for explaining language change: A case study on syncretism in German definite articles. [sent-248, score-0.021]
</p><p>85 Priming through constructional dependencies: a case study in fluid construction grammar. [sent-252, score-0.407]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('fcg', 0.606), ('steels', 0.415), ('fluid', 0.306), ('luc', 0.275), ('beuls', 0.138), ('trijp', 0.138), ('remi', 0.138), ('constructions', 0.125), ('pieter', 0.121), ('katrien', 0.104), ('wellens', 0.104), ('grammar', 0.103), ('construction', 0.101), ('grammaticalization', 0.087), ('benjamins', 0.082), ('van', 0.074), ('evolution', 0.073), ('repair', 0.071), ('diagnostics', 0.069), ('spranger', 0.069), ('editor', 0.068), ('cultural', 0.066), ('evolutionary', 0.066), ('reflective', 0.061), ('historical', 0.058), ('emergence', 0.047), ('hearer', 0.046), ('primes', 0.042), ('pole', 0.042), ('agents', 0.041), ('markers', 0.041), ('verlag', 0.038), ('linguistic', 0.036), ('bleys', 0.035), ('gerasymova', 0.035), ('joachim', 0.035), ('lisp', 0.035), ('loetzsch', 0.035), ('micelli', 0.035), ('pauw', 0.035), ('poles', 0.035), ('shuqfon', 0.035), ('sizhic', 0.035), ('sony', 0.035), ('universiteit', 0.035), ('vrije', 0.035), ('yuri', 0.035), ('zabu', 0.035), ('grammatical', 0.034), ('population', 0.033), ('john', 0.032), ('schematic', 0.031), ('locative', 0.031), ('heine', 0.031), ('bundled', 0.031), ('diagnostic', 0.031), ('mechanisms', 0.028), ('reversible', 0.028), ('pollard', 0.028), ('cognitive', 0.027), ('game', 0.027), ('springer', 0.027), ('uncovering', 0.027), ('emergent', 0.027), ('shaped', 0.027), ('demo', 0.025), ('strategy', 0.025), ('formalism', 0.024), ('customizable', 0.024), ('strategies', 0.023), ('design', 0.023), ('sketch', 0.023), ('agent', 0.022), ('laboratory', 0.022), ('arrive', 0.022), ('unification', 0.022), ('processor', 0.022), ('utterances', 0.022), ('architecture', 0.022), ('explaining', 0.021), ('monitor', 0.021), ('repositories', 0.021), ('communicate', 0.021), ('bootstrap', 0.02), ('speaker', 0.02), ('adequately', 0.02), ('powerful', 0.019), ('becoming', 0.019), ('baker', 0.019), ('patterns', 0.019), ('meaningful', 0.019), ('framenet', 0.019), ('paris', 0.019), ('drive', 0.019), ('linking', 0.018), ('marker', 0.018), ('processes', 0.018), ('stage', 0.018), ('ai', 0.018), ('agreement', 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999934 <a title="161-tfidf-1" href="./acl-2013-Fluid_Construction_Grammar_for_Historical_and_Evolutionary_Linguistics.html">161 acl-2013-Fluid Construction Grammar for Historical and Evolutionary Linguistics</a></p>
<p>Author: Pieter Wellens ; Remi van Trijp ; Katrien Beuls ; Luc Steels</p><p>Abstract: Fluid Construction Grammar (FCG) is an open-source computational grammar formalism that is becoming increasingly popular for studying the history and evolution of language. This demonstration shows how FCG can be used to operationalise the cultural processes and cognitive mechanisms that underly language evolution and change.</p><p>2 0.043174222 <a title="161-tfidf-2" href="./acl-2013-Semantic_Neighborhoods_as_Hypergraphs.html">311 acl-2013-Semantic Neighborhoods as Hypergraphs</a></p>
<p>Author: Chris Quirk ; Pallavi Choudhury</p><p>Abstract: Ambiguity preserving representations such as lattices are very useful in a number of NLP tasks, including paraphrase generation, paraphrase recognition, and machine translation evaluation. Lattices compactly represent lexical variation, but word order variation leads to a combinatorial explosion of states. We advocate hypergraphs as compact representations for sets of utterances describing the same event or object. We present a method to construct hypergraphs from sets of utterances, and evaluate this method on a simple recognition task. Given a set of utterances that describe a single object or event, we construct such a hypergraph, and demonstrate that it can recognize novel descriptions of the same event with high accuracy.</p><p>3 0.037094653 <a title="161-tfidf-3" href="./acl-2013-Identifying_English_and_Hungarian_Light_Verb_Constructions%3A_A_Contrastive_Approach.html">186 acl-2013-Identifying English and Hungarian Light Verb Constructions: A Contrastive Approach</a></p>
<p>Author: Veronika Vincze ; Istvan Nagy T. ; Richard Farkas</p><p>Abstract: Here, we introduce a machine learningbased approach that allows us to identify light verb constructions (LVCs) in Hungarian and English free texts. We also present the results of our experiments on the SzegedParalellFX English–Hungarian parallel corpus where LVCs were manually annotated in both languages. With our approach, we were able to contrast the performance of our method and define language-specific features for these typologically different languages. Our presented method proved to be sufficiently robust as it achieved approximately the same scores on the two typologically different languages.</p><p>4 0.03275653 <a title="161-tfidf-4" href="./acl-2013-Implicatures_and_Nested_Beliefs_in_Approximate_Decentralized-POMDPs.html">190 acl-2013-Implicatures and Nested Beliefs in Approximate Decentralized-POMDPs</a></p>
<p>Author: Adam Vogel ; Christopher Potts ; Dan Jurafsky</p><p>Abstract: Conversational implicatures involve reasoning about multiply nested belief structures. This complexity poses significant challenges for computational models of conversation and cognition. We show that agents in the multi-agent DecentralizedPOMDP reach implicature-rich interpretations simply as a by-product of the way they reason about each other to maximize joint utility. Our simulations involve a reference game of the sort studied in psychology and linguistics as well as a dynamic, interactional scenario involving implemented artificial agents.</p><p>5 0.032578494 <a title="161-tfidf-5" href="./acl-2013-ParGramBank%3A_The_ParGram_Parallel_Treebank.html">270 acl-2013-ParGramBank: The ParGram Parallel Treebank</a></p>
<p>Author: Sebastian Sulger ; Miriam Butt ; Tracy Holloway King ; Paul Meurer ; Tibor Laczko ; Gyorgy Rakosi ; Cheikh Bamba Dione ; Helge Dyvik ; Victoria Rosen ; Koenraad De Smedt ; Agnieszka Patejuk ; Ozlem Cetinoglu ; I Wayan Arka ; Meladel Mistica</p><p>Abstract: This paper discusses the construction of a parallel treebank currently involving ten languages from six language families. The treebank is based on deep LFG (LexicalFunctional Grammar) grammars that were developed within the framework of the ParGram (Parallel Grammar) effort. The grammars produce output that is maximally parallelized across languages and language families. This output forms the basis of a parallel treebank covering a diverse set of phenomena. The treebank is publicly available via the INESS treebanking environment, which also allows for the alignment of language pairs. We thus present a unique, multilayered parallel treebank that represents more and different types of languages than are avail- able in other treebanks, that represents me ladel .mi st ica@ gmai l com . deep linguistic knowledge and that allows for the alignment of sentences at several levels: dependency structures, constituency structures and POS information.</p><p>6 0.029930163 <a title="161-tfidf-6" href="./acl-2013-Transfer_Learning_for_Constituency-Based_Grammars.html">357 acl-2013-Transfer Learning for Constituency-Based Grammars</a></p>
<p>7 0.028765017 <a title="161-tfidf-7" href="./acl-2013-ICARUS_-_An_Extensible_Graphical_Search_Tool_for_Dependency_Treebanks.html">183 acl-2013-ICARUS - An Extensible Graphical Search Tool for Dependency Treebanks</a></p>
<p>8 0.027247682 <a title="161-tfidf-8" href="./acl-2013-Identification_of_Speakers_in_Novels.html">184 acl-2013-Identification of Speakers in Novels</a></p>
<p>9 0.026476856 <a title="161-tfidf-9" href="./acl-2013-Evolutionary_Hierarchical_Dirichlet_Process_for_Timeline_Summarization.html">142 acl-2013-Evolutionary Hierarchical Dirichlet Process for Timeline Summarization</a></p>
<p>10 0.024169294 <a title="161-tfidf-10" href="./acl-2013-Offspring_from_Reproduction_Problems%3A_What_Replication_Failure_Teaches_Us.html">262 acl-2013-Offspring from Reproduction Problems: What Replication Failure Teaches Us</a></p>
<p>11 0.024144733 <a title="161-tfidf-11" href="./acl-2013-Language-Independent_Discriminative_Parsing_of_Temporal_Expressions.html">212 acl-2013-Language-Independent Discriminative Parsing of Temporal Expressions</a></p>
<p>12 0.023991067 <a title="161-tfidf-12" href="./acl-2013-Automated_Collocation_Suggestion_for_Japanese_Second_Language_Learners.html">58 acl-2013-Automated Collocation Suggestion for Japanese Second Language Learners</a></p>
<p>13 0.023980739 <a title="161-tfidf-13" href="./acl-2013-Aggregated_Word_Pair_Features_for_Implicit_Discourse_Relation_Disambiguation.html">41 acl-2013-Aggregated Word Pair Features for Implicit Discourse Relation Disambiguation</a></p>
<p>14 0.023954632 <a title="161-tfidf-14" href="./acl-2013-Automatic_Interpretation_of_the_English_Possessive.html">61 acl-2013-Automatic Interpretation of the English Possessive</a></p>
<p>15 0.023655299 <a title="161-tfidf-15" href="./acl-2013-Universal_Dependency_Annotation_for_Multilingual_Parsing.html">368 acl-2013-Universal Dependency Annotation for Multilingual Parsing</a></p>
<p>16 0.023419214 <a title="161-tfidf-16" href="./acl-2013-Cross-lingual_Transfer_of_Semantic_Role_Labeling_Models.html">98 acl-2013-Cross-lingual Transfer of Semantic Role Labeling Models</a></p>
<p>17 0.023150703 <a title="161-tfidf-17" href="./acl-2013-The_Role_of_Syntax_in_Vector_Space_Models_of_Compositional_Semantics.html">347 acl-2013-The Role of Syntax in Vector Space Models of Compositional Semantics</a></p>
<p>18 0.022963291 <a title="161-tfidf-18" href="./acl-2013-The_effect_of_non-tightness_on_Bayesian_estimation_of_PCFGs.html">348 acl-2013-The effect of non-tightness on Bayesian estimation of PCFGs</a></p>
<p>19 0.022783142 <a title="161-tfidf-19" href="./acl-2013-Bilingually-Guided_Monolingual_Dependency_Grammar_Induction.html">70 acl-2013-Bilingually-Guided Monolingual Dependency Grammar Induction</a></p>
<p>20 0.022286499 <a title="161-tfidf-20" href="./acl-2013-Using_Conceptual_Class_Attributes_to_Characterize_Social_Media_Users.html">373 acl-2013-Using Conceptual Class Attributes to Characterize Social Media Users</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.067), (1, 0.008), (2, -0.013), (3, -0.024), (4, -0.039), (5, -0.004), (6, 0.027), (7, -0.005), (8, 0.021), (9, -0.009), (10, -0.028), (11, -0.004), (12, -0.022), (13, -0.01), (14, -0.023), (15, -0.018), (16, 0.014), (17, 0.006), (18, -0.003), (19, -0.002), (20, -0.026), (21, -0.032), (22, -0.0), (23, 0.001), (24, -0.011), (25, -0.009), (26, -0.025), (27, 0.027), (28, -0.027), (29, 0.016), (30, 0.009), (31, -0.013), (32, -0.0), (33, -0.044), (34, 0.051), (35, -0.025), (36, -0.023), (37, -0.01), (38, 0.016), (39, -0.009), (40, -0.003), (41, -0.038), (42, 0.03), (43, 0.001), (44, 0.007), (45, 0.019), (46, -0.021), (47, -0.048), (48, -0.043), (49, -0.008)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.85227454 <a title="161-lsi-1" href="./acl-2013-Fluid_Construction_Grammar_for_Historical_and_Evolutionary_Linguistics.html">161 acl-2013-Fluid Construction Grammar for Historical and Evolutionary Linguistics</a></p>
<p>Author: Pieter Wellens ; Remi van Trijp ; Katrien Beuls ; Luc Steels</p><p>Abstract: Fluid Construction Grammar (FCG) is an open-source computational grammar formalism that is becoming increasingly popular for studying the history and evolution of language. This demonstration shows how FCG can be used to operationalise the cultural processes and cognitive mechanisms that underly language evolution and change.</p><p>2 0.62105775 <a title="161-lsi-2" href="./acl-2013-Semantic_Neighborhoods_as_Hypergraphs.html">311 acl-2013-Semantic Neighborhoods as Hypergraphs</a></p>
<p>Author: Chris Quirk ; Pallavi Choudhury</p><p>Abstract: Ambiguity preserving representations such as lattices are very useful in a number of NLP tasks, including paraphrase generation, paraphrase recognition, and machine translation evaluation. Lattices compactly represent lexical variation, but word order variation leads to a combinatorial explosion of states. We advocate hypergraphs as compact representations for sets of utterances describing the same event or object. We present a method to construct hypergraphs from sets of utterances, and evaluate this method on a simple recognition task. Given a set of utterances that describe a single object or event, we construct such a hypergraph, and demonstrate that it can recognize novel descriptions of the same event with high accuracy.</p><p>3 0.61669397 <a title="161-lsi-3" href="./acl-2013-Language-Independent_Discriminative_Parsing_of_Temporal_Expressions.html">212 acl-2013-Language-Independent Discriminative Parsing of Temporal Expressions</a></p>
<p>Author: Gabor Angeli ; Jakob Uszkoreit</p><p>Abstract: Temporal resolution systems are traditionally tuned to a particular language, requiring significant human effort to translate them to new languages. We present a language independent semantic parser for learning the interpretation of temporal phrases given only a corpus of utterances and the times they reference. We make use of a latent parse that encodes a language-flexible representation of time, and extract rich features over both the parse and associated temporal semantics. The parameters of the model are learned using a weakly supervised bootstrapping approach, without the need for manually tuned parameters or any other language expertise. We achieve state-of-the-art accuracy on all languages in the TempEval2 temporal normalization task, reporting a 4% improvement in both English and Spanish accuracy, and to our knowledge the first results for four other languages.</p><p>4 0.56835741 <a title="161-lsi-4" href="./acl-2013-ICARUS_-_An_Extensible_Graphical_Search_Tool_for_Dependency_Treebanks.html">183 acl-2013-ICARUS - An Extensible Graphical Search Tool for Dependency Treebanks</a></p>
<p>Author: Markus Gartner ; Gregor Thiele ; Wolfgang Seeker ; Anders Bjorkelund ; Jonas Kuhn</p><p>Abstract: We present ICARUS, a versatile graphical search tool to query dependency treebanks. Search results can be inspected both quantitatively and qualitatively by means of frequency lists, tables, or dependency graphs. ICARUS also ships with plugins that enable it to interface with tool chains running either locally or remotely.</p><p>5 0.51567626 <a title="161-lsi-5" href="./acl-2013-Robust_Automated_Natural_Language_Processing_with_Multiword_Expressions_and_Collocations.html">302 acl-2013-Robust Automated Natural Language Processing with Multiword Expressions and Collocations</a></p>
<p>Author: Valia Kordoni ; Markus Egg</p><p>Abstract: unkown-abstract</p><p>6 0.51551455 <a title="161-lsi-6" href="./acl-2013-Typesetting_for_Improved_Readability_using_Lexical_and_Syntactic_Information.html">364 acl-2013-Typesetting for Improved Readability using Lexical and Syntactic Information</a></p>
<p>7 0.51071846 <a title="161-lsi-7" href="./acl-2013-Smatch%3A_an_Evaluation_Metric_for_Semantic_Feature_Structures.html">324 acl-2013-Smatch: an Evaluation Metric for Semantic Feature Structures</a></p>
<p>8 0.50550532 <a title="161-lsi-8" href="./acl-2013-Universal_Conceptual_Cognitive_Annotation_%28UCCA%29.html">367 acl-2013-Universal Conceptual Cognitive Annotation (UCCA)</a></p>
<p>9 0.49854279 <a title="161-lsi-9" href="./acl-2013-The_mathematics_of_language_learning.html">349 acl-2013-The mathematics of language learning</a></p>
<p>10 0.49453729 <a title="161-lsi-10" href="./acl-2013-Identifying_English_and_Hungarian_Light_Verb_Constructions%3A_A_Contrastive_Approach.html">186 acl-2013-Identifying English and Hungarian Light Verb Constructions: A Contrastive Approach</a></p>
<p>11 0.48275545 <a title="161-lsi-11" href="./acl-2013-Parsing_Graphs_with_Hyperedge_Replacement_Grammars.html">274 acl-2013-Parsing Graphs with Hyperedge Replacement Grammars</a></p>
<p>12 0.47291616 <a title="161-lsi-12" href="./acl-2013-ParGramBank%3A_The_ParGram_Parallel_Treebank.html">270 acl-2013-ParGramBank: The ParGram Parallel Treebank</a></p>
<p>13 0.46993646 <a title="161-lsi-13" href="./acl-2013-Propminer%3A_A_Workflow_for_Interactive_Information_Extraction_and_Exploration_using_Dependency_Trees.html">285 acl-2013-Propminer: A Workflow for Interactive Information Extraction and Exploration using Dependency Trees</a></p>
<p>14 0.46250233 <a title="161-lsi-14" href="./acl-2013-Patient_Experience_in_Online_Support_Forums%3A_Modeling_Interpersonal_Interactions_and_Medication_Use.html">278 acl-2013-Patient Experience in Online Support Forums: Modeling Interpersonal Interactions and Medication Use</a></p>
<p>15 0.4580138 <a title="161-lsi-15" href="./acl-2013-Grounded_Language_Learning_from_Video_Described_with_Sentences.html">175 acl-2013-Grounded Language Learning from Video Described with Sentences</a></p>
<p>16 0.45642561 <a title="161-lsi-16" href="./acl-2013-BRAINSUP%3A_Brainstorming_Support_for_Creative_Sentence_Generation.html">65 acl-2013-BRAINSUP: Brainstorming Support for Creative Sentence Generation</a></p>
<p>17 0.45544571 <a title="161-lsi-17" href="./acl-2013-Plurality%2C_Negation%2C_and_Quantification%3ATowards_Comprehensive_Quantifier_Scope_Disambiguation.html">280 acl-2013-Plurality, Negation, and Quantification:Towards Comprehensive Quantifier Scope Disambiguation</a></p>
<p>18 0.45485881 <a title="161-lsi-18" href="./acl-2013-Nonconvex_Global_Optimization_for_Latent-Variable_Models.html">260 acl-2013-Nonconvex Global Optimization for Latent-Variable Models</a></p>
<p>19 0.45305747 <a title="161-lsi-19" href="./acl-2013-Temporal_Signals_Help_Label_Temporal_Relations.html">339 acl-2013-Temporal Signals Help Label Temporal Relations</a></p>
<p>20 0.45205361 <a title="161-lsi-20" href="./acl-2013-Crawling_microblogging_services_to_gather_language-classified_URLs._Workflow_and_case_study.html">95 acl-2013-Crawling microblogging services to gather language-classified URLs. Workflow and case study</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.053), (6, 0.022), (11, 0.05), (14, 0.016), (15, 0.014), (24, 0.04), (26, 0.036), (31, 0.014), (35, 0.071), (42, 0.043), (48, 0.031), (52, 0.357), (64, 0.016), (70, 0.033), (88, 0.023), (90, 0.012), (95, 0.036)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.78024852 <a title="161-lda-1" href="./acl-2013-Fluid_Construction_Grammar_for_Historical_and_Evolutionary_Linguistics.html">161 acl-2013-Fluid Construction Grammar for Historical and Evolutionary Linguistics</a></p>
<p>Author: Pieter Wellens ; Remi van Trijp ; Katrien Beuls ; Luc Steels</p><p>Abstract: Fluid Construction Grammar (FCG) is an open-source computational grammar formalism that is becoming increasingly popular for studying the history and evolution of language. This demonstration shows how FCG can be used to operationalise the cultural processes and cognitive mechanisms that underly language evolution and change.</p><p>2 0.62947315 <a title="161-lda-2" href="./acl-2013-Temporal_Signals_Help_Label_Temporal_Relations.html">339 acl-2013-Temporal Signals Help Label Temporal Relations</a></p>
<p>Author: Leon Derczynski ; Robert Gaizauskas</p><p>Abstract: Automatically determining the temporal order of events and times in a text is difficult, though humans can readily perform this task. Sometimes events and times are related through use of an explicit co-ordination which gives information about the temporal relation: expressions like “before ” and “as soon as”. We investigate the r oˆle that these co-ordinating temporal signals have in determining the type of temporal relations in discourse. Using machine learning, we improve upon prior approaches to the problem, achieving over 80% accuracy at labelling the types of temporal relation between events and times that are related by temporal signals.</p><p>3 0.53734082 <a title="161-lda-3" href="./acl-2013-Derivational_Smoothing_for_Syntactic_Distributional_Semantics.html">113 acl-2013-Derivational Smoothing for Syntactic Distributional Semantics</a></p>
<p>Author: Sebastian Pado ; Jan Snajder ; Britta Zeller</p><p>Abstract: Syntax-based vector spaces are used widely in lexical semantics and are more versatile than word-based spaces (Baroni and Lenci, 2010). However, they are also sparse, with resulting reliability and coverage problems. We address this problem by derivational smoothing, which uses knowledge about derivationally related words (oldish → old) to improve semantic similarity est→imates. We develop a set of derivational smoothing methods and evaluate them on two lexical semantics tasks in German. Even for models built from very large corpora, simple derivational smoothing can improve coverage considerably.</p><p>4 0.52473253 <a title="161-lda-4" href="./acl-2013-Categorization_of_Turkish_News_Documents_with_Morphological_Analysis.html">78 acl-2013-Categorization of Turkish News Documents with Morphological Analysis</a></p>
<p>Author: Burak Kerim AkkuÅ� ; Ruket Cakici</p><p>Abstract: Morphologically rich languages such as Turkish may benefit from morphological analysis in natural language tasks. In this study, we examine the effects of morphological analysis on text categorization task in Turkish. We use stems and word categories that are extracted with morphological analysis as main features and compare them with fixed length stemmers in a bag of words approach with several learning algorithms. We aim to show the effects of using varying degrees of morphological information.</p><p>5 0.38408685 <a title="161-lda-5" href="./acl-2013-DErivBase%3A_Inducing_and_Evaluating_a_Derivational_Morphology_Resource_for_German.html">102 acl-2013-DErivBase: Inducing and Evaluating a Derivational Morphology Resource for German</a></p>
<p>Author: Britta Zeller ; Jan Snajder ; Sebastian Pado</p><p>Abstract: Derivational models are still an underresearched area in computational morphology. Even for German, a rather resourcerich language, there is a lack of largecoverage derivational knowledge. This paper describes a rule-based framework for inducing derivational families (i.e., clusters of lemmas in derivational relationships) and its application to create a highcoverage German resource, DERIVBASE, mapping over 280k lemmas into more than 17k non-singleton clusters. We focus on the rule component and a qualitative and quantitative evaluation. Our approach achieves up to 93% precision and 71% recall. We attribute the high precision to the fact that our rules are based on information from grammar books.</p><p>6 0.35750523 <a title="161-lda-6" href="./acl-2013-Universal_Conceptual_Cognitive_Annotation_%28UCCA%29.html">367 acl-2013-Universal Conceptual Cognitive Annotation (UCCA)</a></p>
<p>7 0.3547115 <a title="161-lda-7" href="./acl-2013-Collective_Annotation_of_Linguistic_Resources%3A_Basic_Principles_and_a_Formal_Model.html">83 acl-2013-Collective Annotation of Linguistic Resources: Basic Principles and a Formal Model</a></p>
<p>8 0.35383624 <a title="161-lda-8" href="./acl-2013-Filling_Knowledge_Base_Gaps_for_Distant_Supervision_of_Relation_Extraction.html">159 acl-2013-Filling Knowledge Base Gaps for Distant Supervision of Relation Extraction</a></p>
<p>9 0.35147613 <a title="161-lda-9" href="./acl-2013-Combining_Intra-_and_Multi-sentential_Rhetorical_Parsing_for_Document-level_Discourse_Analysis.html">85 acl-2013-Combining Intra- and Multi-sentential Rhetorical Parsing for Document-level Discourse Analysis</a></p>
<p>10 0.35101333 <a title="161-lda-10" href="./acl-2013-Sentiment_Relevance.html">318 acl-2013-Sentiment Relevance</a></p>
<p>11 0.34977245 <a title="161-lda-11" href="./acl-2013-Learning_to_Order_Natural_Language_Texts.html">225 acl-2013-Learning to Order Natural Language Texts</a></p>
<p>12 0.34960872 <a title="161-lda-12" href="./acl-2013-A_Bayesian_Model_for_Joint_Unsupervised_Induction_of_Sentiment%2C_Aspect_and_Discourse_Representations.html">2 acl-2013-A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations</a></p>
<p>13 0.3494831 <a title="161-lda-13" href="./acl-2013-Parsing_with_Compositional_Vector_Grammars.html">275 acl-2013-Parsing with Compositional Vector Grammars</a></p>
<p>14 0.34888428 <a title="161-lda-14" href="./acl-2013-Linggle%3A_a_Web-scale_Linguistic_Search_Engine_for_Words_in_Context.html">231 acl-2013-Linggle: a Web-scale Linguistic Search Engine for Words in Context</a></p>
<p>15 0.34886712 <a title="161-lda-15" href="./acl-2013-A_Random_Walk_Approach_to_Selectional_Preferences_Based_on_Preference_Ranking_and_Propagation.html">17 acl-2013-A Random Walk Approach to Selectional Preferences Based on Preference Ranking and Propagation</a></p>
<p>16 0.34864184 <a title="161-lda-16" href="./acl-2013-Learning_to_Extract_International_Relations_from_Political_Context.html">224 acl-2013-Learning to Extract International Relations from Political Context</a></p>
<p>17 0.34822369 <a title="161-lda-17" href="./acl-2013-Identifying_Bad_Semantic_Neighbors_for_Improving_Distributional_Thesauri.html">185 acl-2013-Identifying Bad Semantic Neighbors for Improving Distributional Thesauri</a></p>
<p>18 0.34811845 <a title="161-lda-18" href="./acl-2013-Paraphrase-Driven_Learning_for_Open_Question_Answering.html">272 acl-2013-Paraphrase-Driven Learning for Open Question Answering</a></p>
<p>19 0.34784412 <a title="161-lda-19" href="./acl-2013-Large-scale_Semantic_Parsing_via_Schema_Matching_and_Lexicon_Extension.html">215 acl-2013-Large-scale Semantic Parsing via Schema Matching and Lexicon Extension</a></p>
<p>20 0.3471134 <a title="161-lda-20" href="./acl-2013-An_Infinite_Hierarchical_Bayesian_Model_of_Phrasal_Translation.html">46 acl-2013-An Infinite Hierarchical Bayesian Model of Phrasal Translation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
