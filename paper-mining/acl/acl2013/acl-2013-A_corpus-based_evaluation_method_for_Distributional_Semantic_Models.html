<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>31 acl-2013-A corpus-based evaluation method for Distributional Semantic Models</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-31" href="#">acl2013-31</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>31 acl-2013-A corpus-based evaluation method for Distributional Semantic Models</h1>
<br/><p>Source: <a title="acl-2013-31-pdf" href="http://aclweb.org/anthology//P/P13/P13-3024.pdf">pdf</a></p><p>Author: Abdellah Fourtassi ; Emmanuel Dupoux</p><p>Abstract: Evaluation methods for Distributional Semantic Models typically rely on behaviorally derived gold standards. These methods are difficult to deploy in languages with scarce linguistic/behavioral resources. We introduce a corpus-based measure that evaluates the stability of the lexical semantic similarity space using a pseudo-synonym same-different detection task and no external resources. We show that it enables to predict two behaviorbased measures across a range of parameters in a Latent Semantic Analysis model.</p><p>Reference: <a title="acl-2013-31-reference" href="../acl2013_reference/acl-2013-A_corpus-based_evaluation_method_for_Distributional_Semantic_Models_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 We introduce a corpus-based measure that evaluates the stability of the lexical semantic similarity space using a pseudo-synonym same-different detection task and no external resources. [sent-7, score-0.401]
</p><p>2 We show that it enables to predict two behaviorbased measures across a range of parameters in a Latent Semantic Analysis model. [sent-8, score-0.143]
</p><p>3 Other commonly used methods evaluate DSMs by comparing their semantic representation to a behaviorally derived gold standard. [sent-18, score-0.325]
</p><p>4 Some standards  are derived from the TOEFL synonym test (Landauer and Dumais, 1997), or the Nelson word associations norms (Nelson et al. [sent-19, score-0.435]
</p><p>5 Others use results from semantic priming experiments (Hutchison et al. [sent-21, score-0.183]
</p><p>6 Baroni and Lenci (201 1) set up a more refined gold standard for English specifying different kinds of semantic relationship based on dictionary resources (like WordNet and ConceptNet). [sent-24, score-0.19]
</p><p>7 Here we introduce a method that aims at providing a rapid and quantitative evaluation for DSMs using an internal gold standard and requiring no external resources. [sent-30, score-0.102]
</p><p>8 We claim that this measure evaluates the intrinsic ability of the model to capture lexical semantic similarity. [sent-32, score-0.311]
</p><p>9 Each matrix cell indicates the occurrence frequency of a given word in a given context. [sent-38, score-0.095]
</p><p>10 Singular value  decomposition (a kind of matrix factorization) is used to extract a reduced representation by truncating the matrix to a certain size (which we call the semantic dimension of the model). [sent-39, score-0.164]
</p><p>11 The cosine of the angle between vectors of the resulting space is used to measure the semantic similarity between words. [sent-40, score-0.354]
</p><p>12 We selected the upper bound of 4 M words to be comparable with the typical corpus size used in theoretical studies on LSA (see for instance Landauer and Dumais (1997) and Griffiths et al. [sent-45, score-0.083]
</p><p>13 For each corpus, we kept only words that occurred at least 10 times and we excluded a stop list of high  frequency words with no conceptual content such as: the, of, to, and . [sent-47, score-0.06]
</p><p>14 For the simulations, we used the free software Gensim (Rˇeh ˚u ˇrek and Sojka, 2010) that provides an online Python implementation of LSA. [sent-51, score-0.06]
</p><p>15 Then, we computed our corpus-based measure with the same models. [sent-54, score-0.218]
</p><p>16 (2007), we used the free association norms collected by Nelson et al. [sent-57, score-0.182]
</p><p>17 (1998) as a gold standard to study the psychological relevance of the LSA semantic representation. [sent-58, score-0.273]
</p><p>18 The norms were constructed by asking more than 6000 participants to produce the first word that came to mind in response to a cue word. [sent-59, score-0.277]
</p><p>19 The participants were presented with 5,019 stimulus words and the responses (word associates) were ordered by the frequency with which they were named. [sent-60, score-0.095]
</p><p>20 The overlap between the words used in  the norms and the vocabulary of our smallest corpus was 1093 words. [sent-61, score-0.313]
</p><p>21 We used only this restricted overlap in our experiment. [sent-62, score-0.144]
</p><p>22 In order to evaluate the performance of LSA models in reproducing these human generated data, we used the same measure as in Griffiths et al. [sent-63, score-0.146]
</p><p>23 (2007): the median rank ofthe first associates of a word in the semantic space. [sent-64, score-0.936]
</p><p>24 This was done in three steps : 1) for each word cue Wc, we sorted the list of the remaining words Wi in the overlap set, based on their LSA cosine similarity with that cue: cos(LSA(Wc) , LSA(Wi)), with highest cosine ranked first. [sent-65, score-0.423]
</p><p>25 2) We found the ranks of the first three associates for that cue in that list. [sent-66, score-0.334]
</p><p>26 3) We applied 1) and 2) to all words in the overlap set and we computed the median rank for each of the first three associates. [sent-67, score-0.787]
</p><p>27 (2007) tested a set of semantic dimensions going from 100 to 700. [sent-69, score-0.292]
</p><p>28 We extended the range of dimensions by testing the following set : [2,5,10,20,30,40,50,100, 200, 300,400,500,600,700,800,1000]. [sent-70, score-0.158]
</p><p>29 We also manipulated the number of successive sentences to be  taken as defining the context of a given word (document size), which we varied from 1to 100. [sent-71, score-0.09]
</p><p>30 In Figure 1we show the results for the 4 M size corpus with 10 sentences long documents. [sent-72, score-0.083]
</p><p>31 Figure 1 : The median rank of the three associates as a function of the semantic dimensions (lower is better) For the smaller corpora we found similar results as we can see from Table 1 where the scores represent the median rank averaged over the set of dimensions ranging from 10 to 1000. [sent-73, score-1.75]
</p><p>32 (2007), the median rank measure predicts the order of the first three associates in the norms. [sent-75, score-0.974]
</p><p>33 In the rest of the article, we will need to characterize the semantic model by a single value. [sent-76, score-0.128]
</p><p>34 Instead of taking the median rank of only one of the 166  Sizeassociate 1associate 2associate 3 1 M78. [sent-77, score-0.571]
</p><p>35 57  Table 1 : The median rank of the first three associates for different sizes associates, we will consider a more reliable measure by averaging over the median ranks of the three associates across the overlap set. [sent-85, score-1.727]
</p><p>36 2 The Pseudo-synonym detection task The measure we introduce in this part is based  on a Same-Different Task (SDT). [sent-88, score-0.146]
</p><p>37 It is described schematically in Figure 2, and is computed as follows: for each corpus, we generate a PseudoSynonym-corpus (PS-corpus) where each word in the overlap set is randomly replaced by one of two lexical variants. [sent-89, score-0.291]
</p><p>38 In the derived corpus, therefore, the overlap lexicon is twice as big, because each word is duplicated and each variant appears roughly with half of the frequency of the original word. [sent-91, score-0.34]
</p><p>39 The Same-Different Task is set up as follows: a pair of words is selected at random in the derived corpus, and the task is to decide whether they are variants of one another or not, only based on their cosine distances. [sent-92, score-0.136]
</p><p>40 Using standard signal detection techniques, it is possible to use the distribution of cosine distances across the entire list of word pairs in the overlap set to compute a Receiver Operating Characteristic Curve (Fawcett, 2006), from which one derives the area under the curve. [sent-93, score-0.259]
</p><p>41 It can be interpreted as the probability that given two pairs  of words, of which only one is a pseudo-synonym pair, the pairs are correctly identified based on cosine distance only. [sent-95, score-0.08]
</p><p>42 It is worth mentioning that the idea of generating pseudo-synonyms could be seen as the opposite of the “pseudo-word” task used in evaluating word sense disambiguation models (see for instance Gale et al. [sent-98, score-0.082]
</p><p>43 We now have two measures evaluating the quality of a given semantic representation: The Median Rank (behavior-based) and the SDT-ρ (corpus-based). [sent-102, score-0.163]
</p><p>44 To answer this question, we compared the performance of both measures across different semantic models, document lengths and cor-  pus sizes. [sent-104, score-0.216]
</p><p>45 3  Results  In Figure 3 (left), we show the results of the behavior-based Median Rank measure, obtained from the three corpora across a number of semantic dimensions. [sent-105, score-0.128]
</p><p>46 It is important to highlight the fact that small differences between high dimensional models do not necessarily reflect a difference in the quality of the semantic representation. [sent-107, score-0.128]
</p><p>47 In this regard, Landauer and Dumais (1997) argued that very small changes in computed cosines can in some cases alter the LSA ordering of the words and hence affect the performance score. [sent-108, score-0.162]
</p><p>48 (2007) and with the findings in Landauer and Dumais (1997) where maximum performance for a different task (TOEFL synonym  test) was obtained over a broad region around 300 dimensions. [sent-111, score-0.129]
</p><p>49 Besides the effect ofdimensionality, Figure 3 (left) indicates that performance gets better as we increase the corpus size. [sent-112, score-0.114]
</p><p>50 We can see that SDT-ρ shows a parallel set of results and correctly predicts both the effect of dimensionality and the effect of corpus size. [sent-114, score-0.236]
</p><p>51 Indeed, the general trend is quite similar to the one described with the Median Rank in that the best performance is obtained for a few hundred dimensions and the three curves show a better score for large corpora. [sent-115, score-0.208]
</p><p>52 Figure 4 shows the effect of document length on the Median Rank and SDT-ρ. [sent-116, score-0.12]
</p><p>53 For both measures, we computed these scores and averaged them over the three corpora and the range of dimensions going from 100 to 1000. [sent-117, score-0.312]
</p><p>54 As we can see, SDT-ρ predicts the psychological optimal document length, 167  Figure 2 : Schematic description of the Same-Different Task used. [sent-118, score-0.191]
</p><p>55 It shows the overall correlation between SDT-ρ and the Median Rank. [sent-123, score-0.114]
</p><p>56 One point in the graph corresponds to a particular choice of semantic dimension, document length and corpus size. [sent-124, score-0.228]
</p><p>57 To measure the correlation, we use the Maximal Information Coefficient (MIC) recently introduced by Reshef et al. [sent-125, score-0.146]
</p><p>58 This measure captures a wide range of dependencies between two variables both functional and not. [sent-127, score-0.184]
</p><p>59 For our data this correlation measure yields a score of MIC = 0. [sent-129, score-0.26]
</p><p>60 In order to see how the SDT-ρ measure would correlate with another human-generated benchmark, we ran an additional experiment using the TOEFL synonym test (Landauer and Dumais, 1997) as gold standard. [sent-131, score-0.337]
</p><p>61 It contains a list of 80 questions consisting of a probe word and four answers (only one of which is defined as the correct synonym). [sent-132, score-0.136]
</p><p>62 We tested the effect of semantic dimensionality on a 6 M word sized Wikipedia corpus where documents contained respectively 2, 10 and 100 sentences for each series of runs. [sent-133, score-0.277]
</p><p>63 We kept only the questions for which the probes and the 4 answers all appeared in the corpus vocabulary. [sent-134, score-0.088]
</p><p>64 We computed the response of the model on a probe word by selecting the answer word with which it had the smallest cosine angle. [sent-136, score-0.282]
</p><p>65 The correlation with SDT-ρ is shown in Figure 5 (right). [sent-142, score-0.114]
</p><p>66 Here again, our corpus-based measure predicts the general trend of the behavior-based measure: higher values of SDT-ρ correspond to higher percentage of correct answers. [sent-143, score-0.248]
</p><p>67 In both experiments, we used the overlap set of the gold standard with the Wikicorpus to compute the SDT-ρ measure. [sent-146, score-0.206]
</p><p>68 However, as the main idea is to apply this evaluation method to corpora for which there is no available human-generated gold standards, we computed new correlations using a SDT-ρ measure computed, this time, over a set of randomly selected words. [sent-147, score-0.356]
</p><p>69 For this purpose we used the 4M corpus with 10 sentences long documents and we varied the semantic dimensions. [sent-148, score-0.23]
</p><p>70 We used the Median Rank computed with the Free as-  sociation norms as a behavior-based measure. [sent-149, score-0.194]
</p><p>71 We tested both the effect of frequency and size: we varied the set size from 100 to 1000 words which we randomly selected from three frequency ranges : higher than 400, between 40 and 400 and between 40 and 1. [sent-150, score-0.318]
</p><p>72 Based on the MIC correlation measure, mid168  Figure 3 : The Median rank (left) and SDT-ρ (right) as a function of a number of dimensions and corpus sizes. [sent-154, score-0.438]
</p><p>73 Figure 4 : The Median rank (left) and SDT-ρ (right) as a function of document length (number of sentences). [sent-156, score-0.21]
</p><p>74 Both measures are averaged over the three corpora and over the range of dimensions going from 100 to 1000. [sent-157, score-0.275]
</p><p>75 Figure 5 : Overall correlation between Median Rank and SDT-ρ (left) and between Correct answers in TOEFL synonym test and SDT-ρ (right) for all the runs. [sent-158, score-0.284]
</p><p>76 05 Table 2 : Correlation scores of the Median Rank with the SDT-ρ measure computed over randomly selected words from the corpus, the whole lexicon and the overlap with the free association norms. [sent-173, score-0.507]
</p><p>77 The correlations are as high as the one computed with the overlap even with a half size set (500 words). [sent-176, score-0.288]
</p><p>78 The overlap is itself mostly composed of midfrequency words, but we made sure that the ran-  dom test sets have no more than 10% of their words in the overlap. [sent-177, score-0.144]
</p><p>79 When faced with a new corpus and a task involving similarity between words, one could implement this rather straightforward method in order, for instance, to set the semantic model parameters. [sent-181, score-0.175]
</p><p>80 The method could also be used to compare the performance of different distributional semantic models, because it does not depend on a particular format for semantic representation. [sent-182, score-0.365]
</p><p>81 All that is required is the existence of a semantic similarity  measure between pairs of words. [sent-183, score-0.274]
</p><p>82 However, further work is needed to evaluate the robustness of this measure in models other than LSA. [sent-184, score-0.146]
</p><p>83 It is important to keep in mind that the correlation of our measure with the behavior-based methods only indicates that SDT-ρ can be trusted, to some extent, in evaluating these semantic tasks. [sent-185, score-0.424]
</p><p>84 It does not necessarily validate its ability to assess the entire semantic structure of a distributional model. [sent-186, score-0.351]
</p><p>85 , generating associates, or responding to a multiple choice synonym test) hence they represent only an indirect evaluation of a model, viewed through these specific tasks. [sent-189, score-0.129]
</p><p>86 It is worth mentioning that Baroni and Lenci (201 1) introduced a comprehensive technique that tries to assess simultaneously a variety of semantic relations like meronymy, hypernymy and coordination. [sent-190, score-0.254]
</p><p>87 Our measure does not enable us to assess these relations, but it could provide a valuable tool to explore other fine-grained features of the semantic structure. [sent-191, score-0.353]
</p><p>88 Indeed, while we intro-  duced SDT-ρ as a global measure over a set of test words, it can also be computed word by word. [sent-192, score-0.253]
</p><p>89 Indeed, we can compute how well a given semantic model can detect that “Art1” and “Art2” are the same word, by comparing their semantic distance to that of random pairs of words. [sent-193, score-0.256]
</p><p>90 Such a word-specific measure could assess the semantic stability of different parts of the lexicon such as concrete vs. [sent-194, score-0.448]
</p><p>91 Future work is needed to assess the extent to which the SDT-ρ measure and its word-level variant provide a general framework for DSMs evaluation without external resources. [sent-198, score-0.265]
</p><p>92 Finally, one concern that could be raised by our method is the fact that splitting words may affect the semantic structure of the model we want to assess because it may alter the lexical distribution in the corpus, resulting in unnaturally sparse statistics. [sent-199, score-0.262]
</p><p>93 There is in fact evidence that corpus attributes can have a big effect on the extracted model (Sridharan and Murphy, 2012; Lindsey et al. [sent-200, score-0.162]
</p><p>94 However, as shown by the high correlation scores,  the introduced pseudo-synonyms do not seem to have a dramatic effect on the model, at least as far as the derived SDT-ρ measure and its predictive power is concerned. [sent-202, score-0.383]
</p><p>95 However, even if the results are not directly affected in our case, future work needs to investigate the exact effect word splitting may have on the semantic model. [sent-205, score-0.23]
</p><p>96 Integrating experiential and distributional data to learn semantic representations. [sent-210, score-0.237]
</p><p>97 A solution to plato’s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge. [sent-265, score-0.128]
</p><p>98 Be wary of what your computer reads: The effects of corpus selection on measuring semantic relatedness. [sent-278, score-0.175]
</p><p>99 The university of south florida word association, rhyme, and word fragment norms. [sent-290, score-0.07]
</p><p>100 Modeling word meaning: distributional semantics and the sorpus quality-quantity trade-off. [sent-320, score-0.144]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('median', 0.414), ('associates', 0.202), ('landauer', 0.171), ('lsa', 0.168), ('dumais', 0.166), ('wikicorpus', 0.158), ('rank', 0.157), ('toefl', 0.151), ('measure', 0.146), ('overlap', 0.144), ('griffiths', 0.141), ('mic', 0.139), ('nelson', 0.139), ('synonym', 0.129), ('semantic', 0.128), ('norms', 0.122), ('dimensions', 0.12), ('correlation', 0.114), ('distributional', 0.109), ('reshef', 0.104), ('dsms', 0.086), ('cue', 0.084), ('psychological', 0.083), ('cosine', 0.08), ('assess', 0.079), ('behaviorally', 0.079), ('cognitives', 0.079), ('etudes', 0.079), ('farrell', 0.079), ('fawcett', 0.079), ('hutchison', 0.079), ('lewandowsky', 0.079), ('lindsey', 0.079), ('reese', 0.079), ('sridharan', 0.079), ('lenci', 0.075), ('computed', 0.072), ('behaviorbased', 0.07), ('effect', 0.067), ('harris', 0.066), ('luhn', 0.064), ('rek', 0.064), ('sojka', 0.064), ('paris', 0.063), ('gold', 0.062), ('probe', 0.06), ('free', 0.06), ('frequency', 0.06), ('baroni', 0.06), ('associations', 0.058), ('andrews', 0.058), ('derived', 0.056), ('varied', 0.055), ('alter', 0.055), ('priming', 0.055), ('left', 0.055), ('predicts', 0.055), ('emmanuel', 0.053), ('document', 0.053), ('stability', 0.05), ('murphy', 0.05), ('eh', 0.048), ('wc', 0.048), ('ranks', 0.048), ('big', 0.048), ('mentioning', 0.047), ('corpus', 0.047), ('trend', 0.047), ('lexicon', 0.045), ('going', 0.044), ('indeed', 0.044), ('gale', 0.043), ('hundred', 0.041), ('review', 0.041), ('answers', 0.041), ('randomly', 0.04), ('external', 0.04), ('averaged', 0.038), ('range', 0.038), ('dagan', 0.037), ('evaluates', 0.037), ('size', 0.036), ('mind', 0.036), ('correlations', 0.036), ('besides', 0.036), ('jones', 0.036), ('standards', 0.035), ('validate', 0.035), ('measures', 0.035), ('word', 0.035), ('conceptnet', 0.035), ('cosines', 0.035), ('finucane', 0.035), ('grossman', 0.035), ('lander', 0.035), ('mcevoy', 0.035), ('mcvean', 0.035), ('padro', 0.035), ('schematic', 0.035), ('stimulus', 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999994 <a title="31-tfidf-1" href="./acl-2013-A_corpus-based_evaluation_method_for_Distributional_Semantic_Models.html">31 acl-2013-A corpus-based evaluation method for Distributional Semantic Models</a></p>
<p>Author: Abdellah Fourtassi ; Emmanuel Dupoux</p><p>Abstract: Evaluation methods for Distributional Semantic Models typically rely on behaviorally derived gold standards. These methods are difficult to deploy in languages with scarce linguistic/behavioral resources. We introduce a corpus-based measure that evaluates the stability of the lexical semantic similarity space using a pseudo-synonym same-different detection task and no external resources. We show that it enables to predict two behaviorbased measures across a range of parameters in a Latent Semantic Analysis model.</p><p>2 0.15237783 <a title="31-tfidf-2" href="./acl-2013-Align%2C_Disambiguate_and_Walk%3A_A_Unified_Approach_for_Measuring_Semantic_Similarity.html">43 acl-2013-Align, Disambiguate and Walk: A Unified Approach for Measuring Semantic Similarity</a></p>
<p>Author: Mohammad Taher Pilehvar ; David Jurgens ; Roberto Navigli</p><p>Abstract: Semantic similarity is an essential component of many Natural Language Processing applications. However, prior methods for computing semantic similarity often operate at different levels, e.g., single words or entire documents, which requires adapting the method for each data type. We present a unified approach to semantic similarity that operates at multiple levels, all the way from comparing word senses to comparing text documents. Our method leverages a common probabilistic representation over word senses in order to compare different types of linguistic data. This unified representation shows state-ofthe-art performance on three tasks: seman- tic textual similarity, word similarity, and word sense coarsening.</p><p>3 0.11985739 <a title="31-tfidf-3" href="./acl-2013-Measuring_semantic_content_in_distributional_vectors.html">238 acl-2013-Measuring semantic content in distributional vectors</a></p>
<p>Author: Aurelie Herbelot ; Mohan Ganesalingam</p><p>Abstract: Some words are more contentful than others: for instance, make is intuitively more general than produce and fifteen is more ‘precise’ than a group. In this paper, we propose to measure the ‘semantic content’ of lexical items, as modelled by distributional representations. We investigate the hypothesis that semantic content can be computed using the KullbackLeibler (KL) divergence, an informationtheoretic measure of the relative entropy of two distributions. In a task focusing on retrieving the correct ordering of hyponym-hypernym pairs, the KL diver- gence achieves close to 80% precision but does not outperform a simpler (linguistically unmotivated) frequency measure. We suggest that this result illustrates the rather ‘intensional’ aspect of distributions.</p><p>4 0.11877895 <a title="31-tfidf-4" href="./acl-2013-A_New_Set_of_Norms_for_Semantic_Relatedness_Measures.html">12 acl-2013-A New Set of Norms for Semantic Relatedness Measures</a></p>
<p>Author: Sean Szumlanski ; Fernando Gomez ; Valerie K. Sims</p><p>Abstract: We have elicited human quantitative judgments of semantic relatedness for 122 pairs of nouns and compiled them into a new set of relatedness norms that we call Rel-122. Judgments from individual subjects in our study exhibit high average correlation to the resulting relatedness means (r = 0.77, σ = 0.09, N = 73), although not as high as Resnik’s (1995) upper bound for expected average human correlation to similarity means (r = 0.90). This suggests that human perceptions of relatedness are less strictly constrained than perceptions of similarity and establishes a clearer expectation for what constitutes human-like performance by a computational measure of semantic relatedness. We compare the results of several WordNet-based similarity and relatedness measures to our Rel-122 norms and demonstrate the limitations of WordNet for discovering general indications of semantic relatedness. We also offer a critique of the field’s reliance upon similarity norms to evaluate relatedness measures.</p><p>5 0.11238911 <a title="31-tfidf-5" href="./acl-2013-Models_of_Semantic_Representation_with_Visual_Attributes.html">249 acl-2013-Models of Semantic Representation with Visual Attributes</a></p>
<p>Author: Carina Silberer ; Vittorio Ferrari ; Mirella Lapata</p><p>Abstract: We consider the problem of grounding the meaning of words in the physical world and focus on the visual modality which we represent by visual attributes. We create a new large-scale taxonomy of visual attributes covering more than 500 concepts and their corresponding 688K images. We use this dataset to train attribute classifiers and integrate their predictions with text-based distributional models of word meaning. We show that these bimodal models give a better fit to human word association data compared to amodal models and word representations based on handcrafted norming data.</p><p>6 0.10736459 <a title="31-tfidf-6" href="./acl-2013-Identifying_Bad_Semantic_Neighbors_for_Improving_Distributional_Thesauri.html">185 acl-2013-Identifying Bad Semantic Neighbors for Improving Distributional Thesauri</a></p>
<p>7 0.1045532 <a title="31-tfidf-7" href="./acl-2013-A_relatedness_benchmark_to_test_the_role_of_determiners_in_compositional_distributional_semantics.html">32 acl-2013-A relatedness benchmark to test the role of determiners in compositional distributional semantics</a></p>
<p>8 0.10040323 <a title="31-tfidf-8" href="./acl-2013-Compositional-ly_Derived_Representations_of_Morphologically_Complex_Words_in_Distributional_Semantics.html">87 acl-2013-Compositional-ly Derived Representations of Morphologically Complex Words in Distributional Semantics</a></p>
<p>9 0.09737841 <a title="31-tfidf-9" href="./acl-2013-SEMILAR%3A_The_Semantic_Similarity_Toolkit.html">304 acl-2013-SEMILAR: The Semantic Similarity Toolkit</a></p>
<p>10 0.08626657 <a title="31-tfidf-10" href="./acl-2013-Building_and_Evaluating_a_Distributional_Memory_for_Croatian.html">76 acl-2013-Building and Evaluating a Distributional Memory for Croatian</a></p>
<p>11 0.084838219 <a title="31-tfidf-11" href="./acl-2013-Question_Answering_Using_Enhanced_Lexical_Semantic_Models.html">291 acl-2013-Question Answering Using Enhanced Lexical Semantic Models</a></p>
<p>12 0.080675855 <a title="31-tfidf-12" href="./acl-2013-Derivational_Smoothing_for_Syntactic_Distributional_Semantics.html">113 acl-2013-Derivational Smoothing for Syntactic Distributional Semantics</a></p>
<p>13 0.080196179 <a title="31-tfidf-13" href="./acl-2013-A_Structured_Distributional_Semantic_Model_for_Event_Co-reference.html">22 acl-2013-A Structured Distributional Semantic Model for Event Co-reference</a></p>
<p>14 0.079041846 <a title="31-tfidf-14" href="./acl-2013-Word_Association_Profiles_and_their_Use_for_Automated_Scoring_of_Essays.html">389 acl-2013-Word Association Profiles and their Use for Automated Scoring of Essays</a></p>
<p>15 0.076206073 <a title="31-tfidf-15" href="./acl-2013-Building_Comparable_Corpora_Based_on_Bilingual_LDA_Model.html">74 acl-2013-Building Comparable Corpora Based on Bilingual LDA Model</a></p>
<p>16 0.075775564 <a title="31-tfidf-16" href="./acl-2013-On_the_Predictability_of_Human_Assessment%3A_when_Matrix_Completion_Meets_NLP_Evaluation.html">263 acl-2013-On the Predictability of Human Assessment: when Matrix Completion Meets NLP Evaluation</a></p>
<p>17 0.074798793 <a title="31-tfidf-17" href="./acl-2013-Automated_Pyramid_Scoring_of_Summaries_using_Distributional_Semantics.html">59 acl-2013-Automated Pyramid Scoring of Summaries using Distributional Semantics</a></p>
<p>18 0.073906884 <a title="31-tfidf-18" href="./acl-2013-Offspring_from_Reproduction_Problems%3A_What_Replication_Failure_Teaches_Us.html">262 acl-2013-Offspring from Reproduction Problems: What Replication Failure Teaches Us</a></p>
<p>19 0.07347858 <a title="31-tfidf-19" href="./acl-2013-A_Two_Level_Model_for_Context_Sensitive_Inference_Rules.html">27 acl-2013-A Two Level Model for Context Sensitive Inference Rules</a></p>
<p>20 0.073427118 <a title="31-tfidf-20" href="./acl-2013-Context_Vector_Disambiguation_for_Bilingual_Lexicon_Extraction_from_Comparable_Corpora.html">93 acl-2013-Context Vector Disambiguation for Bilingual Lexicon Extraction from Comparable Corpora</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.202), (1, 0.082), (2, 0.041), (3, -0.144), (4, -0.034), (5, -0.113), (6, -0.014), (7, -0.002), (8, -0.046), (9, 0.025), (10, -0.017), (11, 0.036), (12, 0.077), (13, -0.024), (14, 0.021), (15, 0.064), (16, -0.053), (17, -0.062), (18, -0.011), (19, -0.003), (20, 0.011), (21, 0.026), (22, 0.03), (23, -0.063), (24, -0.062), (25, 0.067), (26, -0.009), (27, 0.051), (28, -0.086), (29, 0.009), (30, -0.042), (31, -0.041), (32, 0.061), (33, -0.009), (34, 0.021), (35, -0.003), (36, -0.0), (37, 0.081), (38, -0.002), (39, 0.019), (40, 0.022), (41, -0.02), (42, -0.096), (43, -0.046), (44, -0.047), (45, 0.048), (46, -0.048), (47, -0.052), (48, 0.014), (49, -0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9485997 <a title="31-lsi-1" href="./acl-2013-A_corpus-based_evaluation_method_for_Distributional_Semantic_Models.html">31 acl-2013-A corpus-based evaluation method for Distributional Semantic Models</a></p>
<p>Author: Abdellah Fourtassi ; Emmanuel Dupoux</p><p>Abstract: Evaluation methods for Distributional Semantic Models typically rely on behaviorally derived gold standards. These methods are difficult to deploy in languages with scarce linguistic/behavioral resources. We introduce a corpus-based measure that evaluates the stability of the lexical semantic similarity space using a pseudo-synonym same-different detection task and no external resources. We show that it enables to predict two behaviorbased measures across a range of parameters in a Latent Semantic Analysis model.</p><p>2 0.83128291 <a title="31-lsi-2" href="./acl-2013-Measuring_semantic_content_in_distributional_vectors.html">238 acl-2013-Measuring semantic content in distributional vectors</a></p>
<p>Author: Aurelie Herbelot ; Mohan Ganesalingam</p><p>Abstract: Some words are more contentful than others: for instance, make is intuitively more general than produce and fifteen is more ‘precise’ than a group. In this paper, we propose to measure the ‘semantic content’ of lexical items, as modelled by distributional representations. We investigate the hypothesis that semantic content can be computed using the KullbackLeibler (KL) divergence, an informationtheoretic measure of the relative entropy of two distributions. In a task focusing on retrieving the correct ordering of hyponym-hypernym pairs, the KL diver- gence achieves close to 80% precision but does not outperform a simpler (linguistically unmotivated) frequency measure. We suggest that this result illustrates the rather ‘intensional’ aspect of distributions.</p><p>3 0.80882359 <a title="31-lsi-3" href="./acl-2013-Identifying_Bad_Semantic_Neighbors_for_Improving_Distributional_Thesauri.html">185 acl-2013-Identifying Bad Semantic Neighbors for Improving Distributional Thesauri</a></p>
<p>Author: Olivier Ferret</p><p>Abstract: Distributional thesauri are now widely used in a large number of Natural Language Processing tasks. However, they are far from containing only interesting semantic relations. As a consequence, improving such thesaurus is an important issue that is mainly tackled indirectly through the improvement of semantic similarity measures. In this article, we propose a more direct approach focusing on the identification of the neighbors of a thesaurus entry that are not semantically linked to this entry. This identification relies on a discriminative classifier trained from unsupervised selected examples for building a distributional model of the entry in texts. Its bad neighbors are found by applying this classifier to a representative set of occurrences of each of these neighbors. We evaluate the interest of this method for a large set of English nouns with various frequencies.</p><p>4 0.78186035 <a title="31-lsi-4" href="./acl-2013-A_New_Set_of_Norms_for_Semantic_Relatedness_Measures.html">12 acl-2013-A New Set of Norms for Semantic Relatedness Measures</a></p>
<p>Author: Sean Szumlanski ; Fernando Gomez ; Valerie K. Sims</p><p>Abstract: We have elicited human quantitative judgments of semantic relatedness for 122 pairs of nouns and compiled them into a new set of relatedness norms that we call Rel-122. Judgments from individual subjects in our study exhibit high average correlation to the resulting relatedness means (r = 0.77, σ = 0.09, N = 73), although not as high as Resnik’s (1995) upper bound for expected average human correlation to similarity means (r = 0.90). This suggests that human perceptions of relatedness are less strictly constrained than perceptions of similarity and establishes a clearer expectation for what constitutes human-like performance by a computational measure of semantic relatedness. We compare the results of several WordNet-based similarity and relatedness measures to our Rel-122 norms and demonstrate the limitations of WordNet for discovering general indications of semantic relatedness. We also offer a critique of the field’s reliance upon similarity norms to evaluate relatedness measures.</p><p>5 0.76670265 <a title="31-lsi-5" href="./acl-2013-Building_and_Evaluating_a_Distributional_Memory_for_Croatian.html">76 acl-2013-Building and Evaluating a Distributional Memory for Croatian</a></p>
<p>Author: Jan Snajder ; Sebastian Pado ; Zeljko Agic</p><p>Abstract: We report on the first structured distributional semantic model for Croatian, DM.HR. It is constructed after the model of the English Distributional Memory (Baroni and Lenci, 2010), from a dependencyparsed Croatian web corpus, and covers about 2M lemmas. We give details on the linguistic processing and the design principles. An evaluation shows state-of-theart performance on a semantic similarity task with particularly good performance on nouns. The resource is freely available.</p><p>6 0.74680054 <a title="31-lsi-6" href="./acl-2013-A_relatedness_benchmark_to_test_the_role_of_determiners_in_compositional_distributional_semantics.html">32 acl-2013-A relatedness benchmark to test the role of determiners in compositional distributional semantics</a></p>
<p>7 0.74387461 <a title="31-lsi-7" href="./acl-2013-Offspring_from_Reproduction_Problems%3A_What_Replication_Failure_Teaches_Us.html">262 acl-2013-Offspring from Reproduction Problems: What Replication Failure Teaches Us</a></p>
<p>8 0.72868264 <a title="31-lsi-8" href="./acl-2013-DISSECT_-_DIStributional_SEmantics_Composition_Toolkit.html">103 acl-2013-DISSECT - DIStributional SEmantics Composition Toolkit</a></p>
<p>9 0.70142007 <a title="31-lsi-9" href="./acl-2013-SEMILAR%3A_The_Semantic_Similarity_Toolkit.html">304 acl-2013-SEMILAR: The Semantic Similarity Toolkit</a></p>
<p>10 0.67672092 <a title="31-lsi-10" href="./acl-2013-Creating_Similarity%3A_Lateral_Thinking_for_Vertical_Similarity_Judgments.html">96 acl-2013-Creating Similarity: Lateral Thinking for Vertical Similarity Judgments</a></p>
<p>11 0.66102129 <a title="31-lsi-11" href="./acl-2013-Compositional-ly_Derived_Representations_of_Morphologically_Complex_Words_in_Distributional_Semantics.html">87 acl-2013-Compositional-ly Derived Representations of Morphologically Complex Words in Distributional Semantics</a></p>
<p>12 0.66047859 <a title="31-lsi-12" href="./acl-2013-DKPro_Similarity%3A_An_Open_Source_Framework_for_Text_Similarity.html">104 acl-2013-DKPro Similarity: An Open Source Framework for Text Similarity</a></p>
<p>13 0.64041054 <a title="31-lsi-13" href="./acl-2013-Word_Association_Profiles_and_their_Use_for_Automated_Scoring_of_Essays.html">389 acl-2013-Word Association Profiles and their Use for Automated Scoring of Essays</a></p>
<p>14 0.63662392 <a title="31-lsi-14" href="./acl-2013-Automated_Pyramid_Scoring_of_Summaries_using_Distributional_Semantics.html">59 acl-2013-Automated Pyramid Scoring of Summaries using Distributional Semantics</a></p>
<p>15 0.63503677 <a title="31-lsi-15" href="./acl-2013-Derivational_Smoothing_for_Syntactic_Distributional_Semantics.html">113 acl-2013-Derivational Smoothing for Syntactic Distributional Semantics</a></p>
<p>16 0.62427247 <a title="31-lsi-16" href="./acl-2013-Align%2C_Disambiguate_and_Walk%3A_A_Unified_Approach_for_Measuring_Semantic_Similarity.html">43 acl-2013-Align, Disambiguate and Walk: A Unified Approach for Measuring Semantic Similarity</a></p>
<p>17 0.60614276 <a title="31-lsi-17" href="./acl-2013-Context_Vector_Disambiguation_for_Bilingual_Lexicon_Extraction_from_Comparable_Corpora.html">93 acl-2013-Context Vector Disambiguation for Bilingual Lexicon Extraction from Comparable Corpora</a></p>
<p>18 0.58130401 <a title="31-lsi-18" href="./acl-2013-Question_Answering_Using_Enhanced_Lexical_Semantic_Models.html">291 acl-2013-Question Answering Using Enhanced Lexical Semantic Models</a></p>
<p>19 0.57415771 <a title="31-lsi-19" href="./acl-2013-A_Comparison_of_Techniques_to_Automatically_Identify_Complex_Words..html">3 acl-2013-A Comparison of Techniques to Automatically Identify Complex Words.</a></p>
<p>20 0.56836349 <a title="31-lsi-20" href="./acl-2013-A_Structured_Distributional_Semantic_Model_for_Event_Co-reference.html">22 acl-2013-A Structured Distributional Semantic Model for Event Co-reference</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.067), (6, 0.038), (11, 0.074), (14, 0.272), (15, 0.012), (24, 0.07), (26, 0.038), (35, 0.122), (42, 0.034), (48, 0.059), (70, 0.036), (88, 0.024), (90, 0.035), (95, 0.068)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.82814735 <a title="31-lda-1" href="./acl-2013-Transfer_Learning_for_Constituency-Based_Grammars.html">357 acl-2013-Transfer Learning for Constituency-Based Grammars</a></p>
<p>Author: Yuan Zhang ; Regina Barzilay ; Amir Globerson</p><p>Abstract: In this paper, we consider the problem of cross-formalism transfer in parsing. We are interested in parsing constituencybased grammars such as HPSG and CCG using a small amount of data specific for the target formalism, and a large quantity of coarse CFG annotations from the Penn Treebank. While all of the target formalisms share a similar basic syntactic structure with Penn Treebank CFG, they also encode additional constraints and semantic features. To handle this apparent discrepancy, we design a probabilistic model that jointly generates CFG and target formalism parses. The model includes features of both parses, allowing trans- fer between the formalisms, while preserving parsing efficiency. We evaluate our approach on three constituency-based grammars CCG, HPSG, and LFG, augmented with the Penn Treebank-1. Our experiments show that across all three formalisms, the target parsers significantly benefit from the coarse annotations.1 —</p><p>same-paper 2 0.81370842 <a title="31-lda-2" href="./acl-2013-A_corpus-based_evaluation_method_for_Distributional_Semantic_Models.html">31 acl-2013-A corpus-based evaluation method for Distributional Semantic Models</a></p>
<p>Author: Abdellah Fourtassi ; Emmanuel Dupoux</p><p>Abstract: Evaluation methods for Distributional Semantic Models typically rely on behaviorally derived gold standards. These methods are difficult to deploy in languages with scarce linguistic/behavioral resources. We introduce a corpus-based measure that evaluates the stability of the lexical semantic similarity space using a pseudo-synonym same-different detection task and no external resources. We show that it enables to predict two behaviorbased measures across a range of parameters in a Latent Semantic Analysis model.</p><p>3 0.75269359 <a title="31-lda-3" href="./acl-2013-Semantic_Roles_for_String_to_Tree_Machine_Translation.html">314 acl-2013-Semantic Roles for String to Tree Machine Translation</a></p>
<p>Author: Marzieh Bazrafshan ; Daniel Gildea</p><p>Abstract: We experiment with adding semantic role information to a string-to-tree machine translation system based on the rule extraction procedure of Galley et al. (2004). We compare methods based on augmenting the set of nonterminals by adding semantic role labels, and altering the rule extraction process to produce a separate set of rules for each predicate that encompass its entire predicate-argument structure. Our results demonstrate that the second approach is effective in increasing the quality of translations.</p><p>4 0.73779786 <a title="31-lda-4" href="./acl-2013-A_New_Syntactic_Metric_for_Evaluation_of_Machine_Translation.html">13 acl-2013-A New Syntactic Metric for Evaluation of Machine Translation</a></p>
<p>Author: Melania Duma ; Cristina Vertan ; Wolfgang Menzel</p><p>Abstract: Machine translation (MT) evaluation aims at measuring the quality of a candidate translation by comparing it with a reference translation. This comparison can be performed on multiple levels: lexical, syntactic or semantic. In this paper, we propose a new syntactic metric for MT evaluation based on the comparison of the dependency structures of the reference and the candidate translations. The dependency structures are obtained by means of a Weighted Constraints Dependency Grammar parser. Based on experiments performed on English to German translations, we show that the new metric correlates well with human judgments at the system level. 1</p><p>5 0.69449425 <a title="31-lda-5" href="./acl-2013-Enlisting_the_Ghost%3A_Modeling_Empty_Categories_for_Machine_Translation.html">137 acl-2013-Enlisting the Ghost: Modeling Empty Categories for Machine Translation</a></p>
<p>Author: Bing Xiang ; Xiaoqiang Luo ; Bowen Zhou</p><p>Abstract: Empty categories (EC) are artificial elements in Penn Treebanks motivated by the government-binding (GB) theory to explain certain language phenomena such as pro-drop. ECs are ubiquitous in languages like Chinese, but they are tacitly ignored in most machine translation (MT) work because of their elusive nature. In this paper we present a comprehensive treatment of ECs by first recovering them with a structured MaxEnt model with a rich set of syntactic and lexical features, and then incorporating the predicted ECs into a Chinese-to-English machine translation task through multiple approaches, including the extraction of EC-specific sparse features. We show that the recovered empty categories not only improve the word alignment quality, but also lead to significant improvements in a large-scale state-of-the-art syntactic MT system.</p><p>6 0.64407814 <a title="31-lda-6" href="./acl-2013-A_Context_Free_TAG_Variant.html">4 acl-2013-A Context Free TAG Variant</a></p>
<p>7 0.61475891 <a title="31-lda-7" href="./acl-2013-Universal_Conceptual_Cognitive_Annotation_%28UCCA%29.html">367 acl-2013-Universal Conceptual Cognitive Annotation (UCCA)</a></p>
<p>8 0.60533869 <a title="31-lda-8" href="./acl-2013-PARMA%3A_A_Predicate_Argument_Aligner.html">267 acl-2013-PARMA: A Predicate Argument Aligner</a></p>
<p>9 0.60313779 <a title="31-lda-9" href="./acl-2013-Parsing_with_Compositional_Vector_Grammars.html">275 acl-2013-Parsing with Compositional Vector Grammars</a></p>
<p>10 0.60165763 <a title="31-lda-10" href="./acl-2013-Identifying_Bad_Semantic_Neighbors_for_Improving_Distributional_Thesauri.html">185 acl-2013-Identifying Bad Semantic Neighbors for Improving Distributional Thesauri</a></p>
<p>11 0.60030127 <a title="31-lda-11" href="./acl-2013-Explicit_and_Implicit_Syntactic_Features_for_Text_Classification.html">144 acl-2013-Explicit and Implicit Syntactic Features for Text Classification</a></p>
<p>12 0.5996331 <a title="31-lda-12" href="./acl-2013-Arguments_and_Modifiers_from_the_Learner%27s_Perspective.html">57 acl-2013-Arguments and Modifiers from the Learner's Perspective</a></p>
<p>13 0.59860134 <a title="31-lda-13" href="./acl-2013-Multigraph_Clustering_for_Unsupervised_Coreference_Resolution.html">252 acl-2013-Multigraph Clustering for Unsupervised Coreference Resolution</a></p>
<p>14 0.59715211 <a title="31-lda-14" href="./acl-2013-Text_Classification_based_on_the_Latent_Topics_of_Important_Sentences_extracted_by_the_PageRank_Algorithm.html">341 acl-2013-Text Classification based on the Latent Topics of Important Sentences extracted by the PageRank Algorithm</a></p>
<p>15 0.59349513 <a title="31-lda-15" href="./acl-2013-Large-scale_Semantic_Parsing_via_Schema_Matching_and_Lexicon_Extension.html">215 acl-2013-Large-scale Semantic Parsing via Schema Matching and Lexicon Extension</a></p>
<p>16 0.59235299 <a title="31-lda-16" href="./acl-2013-Paraphrase-Driven_Learning_for_Open_Question_Answering.html">272 acl-2013-Paraphrase-Driven Learning for Open Question Answering</a></p>
<p>17 0.59222507 <a title="31-lda-17" href="./acl-2013-Joint_Apposition_Extraction_with_Syntactic_and_Semantic_Constraints.html">205 acl-2013-Joint Apposition Extraction with Syntactic and Semantic Constraints</a></p>
<p>18 0.59113377 <a title="31-lda-18" href="./acl-2013-Crowd_Prefers_the_Middle_Path%3A_A_New_IAA_Metric_for_Crowdsourcing_Reveals_Turker_Biases_in_Query_Segmentation.html">99 acl-2013-Crowd Prefers the Middle Path: A New IAA Metric for Crowdsourcing Reveals Turker Biases in Query Segmentation</a></p>
<p>19 0.5910176 <a title="31-lda-19" href="./acl-2013-The_Effects_of_Lexical_Resource_Quality_on_Preference_Violation_Detection.html">344 acl-2013-The Effects of Lexical Resource Quality on Preference Violation Detection</a></p>
<p>20 0.58780289 <a title="31-lda-20" href="./acl-2013-Discovering_User_Interactions_in_Ideological_Discussions.html">121 acl-2013-Discovering User Interactions in Ideological Discussions</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
