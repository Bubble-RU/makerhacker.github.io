<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>256 acl-2013-Named Entity Recognition using Cross-lingual Resources: Arabic as an Example</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-256" href="#">acl2013-256</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>256 acl-2013-Named Entity Recognition using Cross-lingual Resources: Arabic as an Example</h1>
<br/><p>Source: <a title="acl-2013-256-pdf" href="http://aclweb.org/anthology//P/P13/P13-1153.pdf">pdf</a></p><p>Author: Kareem Darwish</p><p>Abstract: Some languages lack large knowledge bases and good discriminative features for Name Entity Recognition (NER) that can generalize to previously unseen named entities. One such language is Arabic, which: a) lacks a capitalization feature; and b) has relatively small knowledge bases, such as Wikipedia. In this work we address both problems by incorporating cross-lingual features and knowledge bases from English using cross-lingual links. We show that such features have a dramatic positive effect on recall. We show the effectiveness of cross-lingual features and resources on a standard dataset as well as on two new test sets that cover both news and microblogs. On the standard dataset, we achieved a 4.1% relative improvement in Fmeasure over the best reported result in the literature. The features led to improvements of 17.1% and 20.5% on the new news and mi- croblogs test sets respectively.</p><p>Reference: <a title="acl-2013-256-reference" href="../acl2013_reference/acl-2013-Named_Entity_Recognition_using_Cross-lingual_Resources%3A_Arabic_as_an_Example_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 qa  Abstract Some languages lack large knowledge bases and good discriminative features for Name Entity Recognition (NER) that can generalize to previously unseen named entities. [sent-3, score-0.322]
</p><p>2 One such language is Arabic, which: a) lacks a capitalization feature; and b) has relatively small knowledge bases, such as Wikipedia. [sent-4, score-0.352]
</p><p>3 We show the effectiveness of cross-lingual features and resources on a standard dataset as well as on two new test sets that cover both news and microblogs. [sent-7, score-0.285]
</p><p>4 5% on the new news and mi-  croblogs test sets respectively. [sent-12, score-0.166]
</p><p>5 To train an NER system, some of the following feature types are typically used (Benajiba and Rosso, 2008; Nadeau and Sekine, 2009): - Orthographic features: These features include capitalization, punctuation, existence of digits, etc. [sent-15, score-0.112]
</p><p>6 One of the most effective orthographic features is capitalization in English, which helps NER to generalize to new text of different genres. [sent-16, score-0.453]
</p><p>7 However, capitalization is not very useful in some languages such as German, and nonexistent in other languages such as Arabic. [sent-17, score-0.363]
</p><p>8 Further, even in English social media, capitalization may be inconsistent. [sent-18, score-0.309]
</p><p>9 - Contextual features: Certain words are indicative of the existence of named entities. [sent-19, score-0.192]
</p><p>10 For example, the word “said” is often preceded by a named entity of type “person” or “organization”. [sent-20, score-0.245]
</p><p>11 - Character-level features: These features typically include the leading and trailing letters of words. [sent-23, score-0.265]
</p><p>12 For example, a word ending with “ing” is typically not a named entity, while a word ending in “berg” is often a named entity. [sent-26, score-0.347]
</p><p>13 - Part-of-speech (POS) tags and morphological features: POS tags indicate (or counter-indicate) the possible presence of a named entity at word level or at word sequence level. [sent-27, score-0.314]
</p><p>14 Morphological features can mostly indicate the absence of named entities. [sent-28, score-0.212]
</p><p>15 However, pronouns are rarely ever attached to named entities. [sent-30, score-0.158]
</p><p>16 - Gazetteers: This feature checks the presence of a word or a sequence of words in large lists of named entities. [sent-31, score-0.226]
</p><p>17 However, Arabic lacks indicative orthographic features that generalize to previously unseen named entities. [sent-36, score-0.379]
</p><p>18 Ac s2s0o1ci3a Atiosnso fcoirat Cioonm foprut Caotimonpaulta Lti nognuails Lti cnsg,u piasgteics 1558–1567, of the Arabic gazetteers that were used for NER were small (Benajiba and Rosso, 2008), there has been efforts to build larger Arabic gazetteers (Attia et al. [sent-39, score-0.15]
</p><p>19 Since training and test parts of standard datasets for Arabic NER are drawn from the same genre in relatively close temporal proximity, a named entity recognizer that simply memorizes named entities in the training set generally performs well on such test sets. [sent-41, score-0.645]
</p><p>20 We illustrate the limited capacity of existing recognizers to generalize to previously unseen named en-  tities using two new test sets that include microblogs as well as news texts that cover local and international politics, economics, health, sports, entertainment, and science. [sent-44, score-0.366]
</p><p>21 As we will show later, recall is well below 50% for all named entity types on the new test sets. [sent-45, score-0.346]
</p><p>22 To address this problem, we introduce the use of cross-lingual links between a disadvantaged language, Arabic, and a language with good discriminative features and large resources, English, to improve Arabic NER. [sent-46, score-0.116]
</p><p>23 We also show how to use transliteration mining to improve NER, even when neither language has a capitalization (or similar) feature. [sent-48, score-0.511]
</p><p>24 The intuition is that if the translation of a word is in fact a transliteration, then the word is likely a named entity. [sent-49, score-0.203]
</p><p>25 Cross-lingual links are obtained using Wikipedia cross-language links and a large Machine Translation (MT) phrase table that is true cased, where word casing is preserved during training. [sent-50, score-0.179]
</p><p>26 We show the effectiveness of these new features on a  standard dataset as well as two new test sets. [sent-51, score-0.17]
</p><p>27 The contributions of this paper are as follows: - Using cross-lingual links to exploit orthographic features in other languages. [sent-52, score-0.164]
</p><p>28 - Introducing two new NER test sets for Arabic that include recent news as well as microblogs. [sent-55, score-0.166]
</p><p>29 The remainder of the paper is organized as follows: Section 2 provides related work; Section 3 describes the baseline system; Section 4 introduces the cross-lingual features and reports on their effectiveness; and Section 5 concludes the paper. [sent-62, score-0.119]
</p><p>30 (2010) used bilingual text to improve monolingual models including NER models for German, which lacks a good capitalization feature. [sent-71, score-0.352]
</p><p>31 Further, we are not aware of prior work on using TM (or transliteration  in general) as a cross lingual feature in any annotation task. [sent-86, score-0.213]
</p><p>32 (2007) used a maximum entropy classifier trained on a feature set that includes the use of gazetteers and a stopword list, appearance of a NE in the training set, leading and trailing word bigrams, and the tag of the previous word. [sent-95, score-0.237]
</p><p>33 They reported 80%, 37%, and 47% F-measure for locations, organizations, and persons respectively on the ANERCORP dataset that they created and publicly released. [sent-96, score-0.164]
</p><p>34 They reported 87%, 46%, and 52% F-measure for loca-  tions, organizations, and persons respectively. [sent-98, score-0.127]
</p><p>35 Using POS tagging generally improved recall at the expense of precision, leading to overall improvements in F-measure. [sent-101, score-0.152]
</p><p>36 Using all their suggested features, they reported 90%, 66%, and 73% F-measure for location, organization, and persons respectively. [sent-102, score-0.127]
</p><p>37 They did not report per category F-measure, but they reported overall 81%, 75%, and 78% macro-average F-measure for broadcast news and newswire on the ACE 2003, 2004, and 2005 datasets respectively. [sent-105, score-0.207]
</p><p>38 Abdul-Hamid and Darwish (2010) used a simplified feature set that relied primarily on character level features, namely leading and trailing letters in a word. [sent-112, score-0.236]
</p><p>39 They reported an F-measure of 76% and 81% for the ACE2005 and the ANERCorp datasets datasets respectively. [sent-114, score-0.123]
</p><p>40 (2012) performed NER on a different genre from news, namely Arabic Wikipedia articles, and reported recall values as low as 35. [sent-119, score-0.168]
</p><p>41 They used self training and recall oriented classification to improve recall, typically at the expense of precision. [sent-121, score-0.114]
</p><p>42 com/p / crfpp / 1560  cessful features that were reported by Benajiba et al. [sent-128, score-0.115]
</p><p>43 (2008) and Abdul-Hamid and Darwish (2010), namely the leading and trailing 1, 2, 3, and 4 letters in a word; whether a word appears in the gazetteer that was created by Benajiba et al. [sent-129, score-0.209]
</p><p>44 As mentioned earlier, the leading and trailing letters in a word may indicate or counter-indicate the presence of named entities. [sent-132, score-0.338]
</p><p>45 It is noteworthy that 69% of the named entities in the test part were seen during training. [sent-140, score-0.252]
</p><p>46 The first test set is composed of news snippets from the RSS feed of the Arabic (Egypt) version of news. [sent-142, score-0.197]
</p><p>47 The RSS feed contains the headline and the first 50-100 words in the news ar-  ticles. [sent-146, score-0.146]
</p><p>48 The set has news from over a dozen different news sources and covers international and local news, politics, financial news, health, sports, entertainment, and technology. [sent-147, score-0.23]
</p><p>49 The second set contains a set of 1,423 tweets that were randomly selected from tweets authored between November 23, 2011 and November 27, 2011. [sent-149, score-0.322]
</p><p>50 We scraped tweets from Twitter using the query “lang:ar” (language=Arabic). [sent-150, score-0.161]
</p><p>51 It is worth noting that only 27% of the named entities in the NEWS test set were observed in the training set (compared to 69% for ANERCORP). [sent-156, score-0.252]
</p><p>52 As Table 3 shows for the ANERCORP dataset, using only the tokens as features, where the labeler mainly memorizes previously seen named entities, yields higher results than the baseline results for the NEWS  dataset (Table 2 (b)). [sent-157, score-0.266]
</p><p>53 The results on the TWEETS test are very poor, with 24% of the named entities in the test set appearing in the training set. [sent-158, score-0.303]
</p><p>54 60a91turesonANERCORP  1561  4  Cross-lingual Features  We experimented with three different cross-lingual features that used Arabic and English Wikipedia cross-language links and a true-cased phrase table that was generated using Moses (Koehn et al. [sent-171, score-0.171]
</p><p>55 The snapshot has  348,873 titles including redirects, which are alternative names to articles. [sent-175, score-0.114]
</p><p>56 8 which includes 6,157,591 entries of Wikipedia titles and their “types”, such as “person”, “plant”, or “device”, where a title can have multiple types. [sent-178, score-0.115]
</p><p>57 The sentences were drawn from the UN parallel data along with a variety of parallel news data from LDC and the GALE project. [sent-182, score-0.115]
</p><p>58 1 Cross-lingual Capitalization As we mentioned earlier, Arabic lacks capitalization and Arabic names are often common Arabic words. [sent-185, score-0.386]
</p><p>59 To capture cross-lingual capitalization, we used the aforementioned true-cased phrase table at word and phrase levels as follows: Input: True-cased phrase table PT, sentence S containing n words w0. [sent-187, score-0.202]
</p><p>60 Table 4 reports on the results of the baseline system with the capitalization feature on the three datasets. [sent-222, score-0.401]
</p><p>61 In comparing baseline results in Table 2 and cross-lingual capitalization results in Table 4, recall consistently increased for all datasets, particularly for “persons” and “locations”. [sent-223, score-0.42]
</p><p>62 Precision dropped overall on the ANERCORP dataset and dropped substantially for the NEWS and TWEETS test sets. [sent-234, score-0.158]
</p><p>63 2 Transliteration Mining An alternative to capitalization can be transliteration mining. [sent-263, score-0.467]
</p><p>64 The intuition is that named entities are often transliterated, particularly the names of locations and persons. [sent-264, score-0.315]
</p><p>65 This feature is helpful if crosslingual resources do not have capitalization information, or if the “helper” language to be consulted does not have a useful capitalization feature. [sent-265, score-0.645]
</p><p>66 We performed transliteration mining (aka cognate matching) at word level for each Arabic word against all its possible translations in the phrase table. [sent-266, score-0.284]
</p><p>67 We  used a transliteration miner akin to that of El-Kahki et al. [sent-267, score-0.185]
</p><p>68 (201 1) that was trained using 3,452 parallel Arabic-English transliteration pairs. [sent-268, score-0.158]
</p><p>69 Again we used a weight similar to the one for cross-lingual capitalization and we rounded the values of the ratio the significant figure. [sent-274, score-0.309]
</p><p>70 If a word was not found in the phrase table, the  feature value was assigned null. [sent-276, score-0.11]
</p><p>71 Table 5 reports on the results using the baseline system with the transliteration mining feature. [sent-293, score-0.267]
</p><p>72 Like the capitalization feature, transliteration mining slightly lowered precision except for the TWEETS test set where the drop in precision was significant and positively increased recall, leading to an overall improvement in F-measure for all test sets. [sent-294, score-0.726]
</p><p>73 The similarity of results between using transliteration mining and word-level cross-lingual capitalization suggests that perhaps they can serve as surrogates. [sent-299, score-0.511]
</p><p>74 Since Wikipedia titles may have multiple DBpedia types, we opted to keep the most popular type (by count of how many Wikipedia titles are assigned a particular type) for each title, and we disregarded the rest. [sent-309, score-0.188]
</p><p>75 For translation, we generated two features using two translation resources,  namely the aforementioned phrase table and ArabicEnglish Wikipedia cross-lingual links. [sent-312, score-0.22]
</p><p>76 For both features (using the two translation methods), for an Arabic word sequence corresponding to the DBpedia entry, the first word in the sequence was assigned the feature “B-” plus the DBpedia type and subsequent words were assigned the featu? [sent-318, score-0.264]
</p><p>77 Using the phrase table for translation likely yielded improved coverage over using Wikipedia cross-lingual links. [sent-329, score-0.13]
</p><p>78 Using DBpedia consistently improved precision and recall for named entity types on all test sets, except for a small drop in precision for locations on the ANERCORP dataset and for locations and persons on the TWEETS test set. [sent-332, score-0.708]
</p><p>79 For the different test sets, improvements in recall ranged between 4. [sent-333, score-0.129]
</p><p>80 4  Putting it All Together  Table 7 reports on the results of using all aforementioned cross-lingual features together. [sent-349, score-0.123]
</p><p>81 As the results show, the impact of cross-lingual features on recall were much more pronounced on the NEWS and TWEETS test sets compared to the ANERCORP dataset. [sent-351, score-0.155]
</p><p>82 Further, the recall values for the ANERCORP dataset in the baseline experiments were much higher than those for the two other test sets. [sent-352, score-0.171]
</p><p>83 This confirms our suspicion that the reported values in the literature on the standard datasets are unrealistically high due to the similarity between the training and test sets. [sent-353, score-0.143]
</p><p>84 Hence, these high effectiveness results may not generalize to other test sets. [sent-354, score-0.121]
</p><p>85 e 92lativ lute/relative differences compared to baseline  differences compared to baseline  lingual features that we experimented with, the use of DBpedia led to improvements in both precision and recall (except for precision on the TWEETS test set). [sent-409, score-0.336]
</p><p>86 Other cross-lingual features yielded overall improvements in F-measure, mostly due to gains in recall, typically at the expense of precision. [sent-410, score-0.118]
</p><p>87 1564  Figure 1: ANERCORP Dataset Results  Figure 2: NEWS Test Set Results When using all the features together, one notable result is that precision dropped significantly for the TWEETS test sets. [sent-417, score-0.177]
</p><p>88 We examined the output for the TWEETS test set and here are some of the factors that affected precision: - the presence of words that would typically be named entities in news but would generally be regular words in tweets. [sent-418, score-0.398]
</p><p>89 - the use of dialectic words that may have transliter-  ations or a named entity as the most likely translation into English. [sent-420, score-0.367]
</p><p>90 However, since the MT system that we used was trained on modern standard Arabic, the dialectic word would not appear in training and would typically be translated/transliterated to the name “Che” (as in Che Guevara). [sent-431, score-0.141]
</p><p>91 - Since tweets are restricted in length, authors frequently use shortened versions of named entities. [sent-432, score-0.319]
</p><p>92 For example, tweets would mostly have “Morsi” instead of “Mohamed Morsi” and without trigger words such as “Dr. [sent-433, score-0.161]
</p><p>93 This same problem was present in the NEWS test set, because it was constructed from an RSS feed, and headlines, which are typically compact, had a higher representation in the test collection. [sent-463, score-0.133]
</p><p>94 We believe that this problem can be overcome by introducing new training data that include tweets (or other social text) and performing domain adaptation. [sent-468, score-0.161]
</p><p>95 1565  5  Conclusion  In this paper, we presented different cross-lingual features that can make use of linguistic properties and knowledge bases of other languages for NER. [sent-471, score-0.122]
</p><p>96 We used English as the “helper” language and we exploited the English capitalization feature and an English knowl-  edge base, DBpedia. [sent-473, score-0.336]
</p><p>97 If the helper language did not have capitalization, then transliteration mining could provide some of the benefit of capitalization. [sent-474, score-0.249]
</p><p>98 We believe that the proposed cross-lingual features can be used to help NER for other languages, particularly languages that lack good features that generalize well. [sent-476, score-0.205]
</p><p>99 We tested on a new news test set, NEWS, which has recent news articles (the same genre as the standard dataset), and indeed NER effectiveness was much lower. [sent-480, score-0.337]
</p><p>100 For the new NEWS test set, cross-lingual features led to a small increase in precision (1. [sent-481, score-0.183]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('arabic', 0.408), ('benajiba', 0.374), ('capitalization', 0.309), ('anercorp', 0.288), ('ner', 0.234), ('dbpedia', 0.17), ('darwish', 0.17), ('tweets', 0.161), ('transliteration', 0.158), ('named', 0.158), ('rosso', 0.14), ('tk', 0.119), ('wikipedia', 0.119), ('news', 0.115), ('trailing', 0.096), ('entity', 0.087), ('nadeau', 0.085), ('titles', 0.08), ('dialectic', 0.077), ('gazetteers', 0.075), ('persons', 0.066), ('links', 0.062), ('reported', 0.061), ('sekine', 0.061), ('iscaps', 0.058), ('phrase', 0.055), ('features', 0.054), ('pol', 0.054), ('locations', 0.052), ('crf', 0.051), ('test', 0.051), ('recall', 0.05), ('orthographic', 0.048), ('ace', 0.047), ('rss', 0.047), ('helper', 0.047), ('letters', 0.045), ('translation', 0.045), ('mining', 0.044), ('lacks', 0.043), ('entities', 0.043), ('generalize', 0.042), ('capitalized', 0.042), ('led', 0.041), ('bases', 0.041), ('sequence', 0.041), ('mayfield', 0.04), ('leading', 0.039), ('anersys', 0.038), ('farber', 0.038), ('istranpsliteration', 0.038), ('larkey', 0.038), ('memorizes', 0.038), ('morsi', 0.038), ('richman', 0.038), ('shaalan', 0.038), ('tabllpoeevr', 0.038), ('recognition', 0.038), ('stemmed', 0.038), ('mcnamee', 0.038), ('dataset', 0.037), ('aforementioned', 0.037), ('precision', 0.037), ('dropped', 0.035), ('title', 0.035), ('indicative', 0.034), ('tm', 0.034), ('names', 0.034), ('name', 0.033), ('expense', 0.033), ('baseline', 0.033), ('reports', 0.032), ('feed', 0.031), ('datasets', 0.031), ('attia', 0.031), ('typically', 0.031), ('absolute', 0.03), ('improved', 0.03), ('english', 0.03), ('relative', 0.03), ('november', 0.029), ('hermjakob', 0.029), ('pos', 0.029), ('namely', 0.029), ('cross', 0.028), ('morphological', 0.028), ('effectiveness', 0.028), ('assigned', 0.028), ('particularly', 0.028), ('mada', 0.028), ('entertainment', 0.028), ('burkett', 0.028), ('ranged', 0.028), ('genre', 0.028), ('feature', 0.027), ('akin', 0.027), ('transliterated', 0.027), ('udupa', 0.027), ('languages', 0.027), ('translations', 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999952 <a title="256-tfidf-1" href="./acl-2013-Named_Entity_Recognition_using_Cross-lingual_Resources%3A_Arabic_as_an_Example.html">256 acl-2013-Named Entity Recognition using Cross-lingual Resources: Arabic as an Example</a></p>
<p>Author: Kareem Darwish</p><p>Abstract: Some languages lack large knowledge bases and good discriminative features for Name Entity Recognition (NER) that can generalize to previously unseen named entities. One such language is Arabic, which: a) lacks a capitalization feature; and b) has relatively small knowledge bases, such as Wikipedia. In this work we address both problems by incorporating cross-lingual features and knowledge bases from English using cross-lingual links. We show that such features have a dramatic positive effect on recall. We show the effectiveness of cross-lingual features and resources on a standard dataset as well as on two new test sets that cover both news and microblogs. On the standard dataset, we achieved a 4.1% relative improvement in Fmeasure over the best reported result in the literature. The features led to improvements of 17.1% and 20.5% on the new news and mi- croblogs test sets respectively.</p><p>2 0.16446467 <a title="256-tfidf-2" href="./acl-2013-Language_Independent_Connectivity_Strength_Features_for_Phrase_Pivot_Statistical_Machine_Translation.html">214 acl-2013-Language Independent Connectivity Strength Features for Phrase Pivot Statistical Machine Translation</a></p>
<p>Author: Ahmed El Kholy ; Nizar Habash ; Gregor Leusch ; Evgeny Matusov ; Hassan Sawaf</p><p>Abstract: An important challenge to statistical machine translation (SMT) is the lack of parallel data for many language pairs. One common solution is to pivot through a third language for which there exist parallel corpora with the source and target languages. Although pivoting is a robust technique, it introduces some low quality translations. In this paper, we present two language-independent features to improve the quality of phrase-pivot based SMT. The features, source connectivity strength and target connectivity strength reflect the quality of projected alignments between the source and target phrases in the pivot phrase table. We show positive results (0.6 BLEU points) on Persian-Arabic SMT as a case study.</p><p>3 0.15745081 <a title="256-tfidf-3" href="./acl-2013-Identifying_Opinion_Subgroups_in_Arabic_Online_Discussions.html">187 acl-2013-Identifying Opinion Subgroups in Arabic Online Discussions</a></p>
<p>Author: Amjad Abu-Jbara ; Ben King ; Mona Diab ; Dragomir Radev</p><p>Abstract: In this paper, we use Arabic natural language processing techniques to analyze Arabic debates. The goal is to identify how the participants in a discussion split into subgroups with contrasting opinions. The members of each subgroup share the same opinion with respect to the discussion topic and an opposing opinion to the members of other subgroups. We use opinion mining techniques to identify opinion expressions and determine their polarities and their targets. We opinion predictions to represent the discussion in one of two formal representations: signed attitude network or a space of attitude vectors. We identify opinion subgroups by partitioning the signed network representation or by clustering the vector space representation. We evaluate the system using a data set of labeled discussions and show that it achieves good results.</p><p>4 0.15384191 <a title="256-tfidf-4" href="./acl-2013-Joint_Word_Alignment_and_Bilingual_Named_Entity_Recognition_Using_Dual_Decomposition.html">210 acl-2013-Joint Word Alignment and Bilingual Named Entity Recognition Using Dual Decomposition</a></p>
<p>Author: Mengqiu Wang ; Wanxiang Che ; Christopher D. Manning</p><p>Abstract: Translated bi-texts contain complementary language cues, and previous work on Named Entity Recognition (NER) has demonstrated improvements in performance over monolingual taggers by promoting agreement of tagging decisions between the two languages. However, most previous approaches to bilingual tagging assume word alignments are given as fixed input, which can cause cascading errors. We observe that NER label information can be used to correct alignment mistakes, and present a graphical model that performs bilingual NER tagging jointly with word alignment, by combining two monolingual tagging models with two unidirectional alignment models. We intro- duce additional cross-lingual edge factors that encourage agreements between tagging and alignment decisions. We design a dual decomposition inference algorithm to perform joint decoding over the combined alignment and NER output space. Experiments on the OntoNotes dataset demonstrate that our method yields significant improvements in both NER and word alignment over state-of-the-art monolingual baselines.</p><p>5 0.1501523 <a title="256-tfidf-5" href="./acl-2013-LABR%3A_A_Large_Scale_Arabic_Book_Reviews_Dataset.html">211 acl-2013-LABR: A Large Scale Arabic Book Reviews Dataset</a></p>
<p>Author: Mohamed Aly ; Amir Atiya</p><p>Abstract: We introduce LABR, the largest sentiment analysis dataset to-date for the Arabic language. It consists of over 63,000 book reviews, each rated on a scale of 1 to 5 stars. We investigate the properties of the the dataset, and present its statistics. We explore using the dataset for two tasks: sentiment polarity classification and rating classification. We provide standard splits of the dataset into training and testing, for both polarity and rating classification, in both balanced and unbalanced settings. We run baseline experiments on the dataset to establish a benchmark.</p><p>6 0.14318021 <a title="256-tfidf-6" href="./acl-2013-Microblogs_as_Parallel_Corpora.html">240 acl-2013-Microblogs as Parallel Corpora</a></p>
<p>7 0.1420448 <a title="256-tfidf-7" href="./acl-2013-Translating_Dialectal_Arabic_to_English.html">359 acl-2013-Translating Dialectal Arabic to English</a></p>
<p>8 0.12965997 <a title="256-tfidf-8" href="./acl-2013-Linking_Tweets_to_News%3A_A_Framework_to_Enrich_Short_Text_Data_in_Social_Media.html">233 acl-2013-Linking Tweets to News: A Framework to Enrich Short Text Data in Social Media</a></p>
<p>9 0.12559099 <a title="256-tfidf-9" href="./acl-2013-Detecting_Event-Related_Links_and_Sentiments_from_Social_Media_Texts.html">115 acl-2013-Detecting Event-Related Links and Sentiments from Social Media Texts</a></p>
<p>10 0.11788431 <a title="256-tfidf-10" href="./acl-2013-A_Tightly-coupled_Unsupervised_Clustering_and_Bilingual_Alignment_Model_for_Transliteration.html">25 acl-2013-A Tightly-coupled Unsupervised Clustering and Bilingual Alignment Model for Transliteration</a></p>
<p>11 0.11730623 <a title="256-tfidf-11" href="./acl-2013-Sentence_Level_Dialect_Identification_in_Arabic.html">317 acl-2013-Sentence Level Dialect Identification in Arabic</a></p>
<p>12 0.11224461 <a title="256-tfidf-12" href="./acl-2013-HYENA-live%3A_Fine-Grained_Online_Entity_Type_Classification_from_Natural-language_Text.html">179 acl-2013-HYENA-live: Fine-Grained Online Entity Type Classification from Natural-language Text</a></p>
<p>13 0.10581379 <a title="256-tfidf-13" href="./acl-2013-Towards_Accurate_Distant_Supervision_for_Relational_Facts_Extraction.html">352 acl-2013-Towards Accurate Distant Supervision for Relational Facts Extraction</a></p>
<p>14 0.10337421 <a title="256-tfidf-14" href="./acl-2013-Entity_Linking_for_Tweets.html">139 acl-2013-Entity Linking for Tweets</a></p>
<p>15 0.099974543 <a title="256-tfidf-15" href="./acl-2013-An_Information_Theoretic_Approach_to_Bilingual_Word_Clustering.html">47 acl-2013-An Information Theoretic Approach to Bilingual Word Clustering</a></p>
<p>16 0.098802477 <a title="256-tfidf-16" href="./acl-2013-FudanNLP%3A_A_Toolkit_for_Chinese_Natural_Language_Processing.html">164 acl-2013-FudanNLP: A Toolkit for Chinese Natural Language Processing</a></p>
<p>17 0.095118366 <a title="256-tfidf-17" href="./acl-2013-Name-aware_Machine_Translation.html">255 acl-2013-Name-aware Machine Translation</a></p>
<p>18 0.092347093 <a title="256-tfidf-18" href="./acl-2013-Cross-lingual_Projections_between_Languages_from_Different_Families.html">97 acl-2013-Cross-lingual Projections between Languages from Different Families</a></p>
<p>19 0.090794034 <a title="256-tfidf-19" href="./acl-2013-Task_Alternation_in_Parallel_Sentence_Retrieval_for_Twitter_Translation.html">338 acl-2013-Task Alternation in Parallel Sentence Retrieval for Twitter Translation</a></p>
<p>20 0.088415608 <a title="256-tfidf-20" href="./acl-2013-Extracting_bilingual_terminologies_from_comparable_corpora.html">154 acl-2013-Extracting bilingual terminologies from comparable corpora</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.205), (1, 0.03), (2, 0.063), (3, 0.069), (4, 0.131), (5, 0.072), (6, -0.058), (7, 0.057), (8, 0.144), (9, -0.085), (10, -0.053), (11, -0.086), (12, 0.004), (13, 0.016), (14, -0.054), (15, 0.038), (16, -0.024), (17, -0.047), (18, -0.085), (19, 0.061), (20, -0.058), (21, 0.051), (22, 0.063), (23, 0.172), (24, 0.035), (25, -0.001), (26, 0.036), (27, -0.106), (28, 0.075), (29, -0.124), (30, 0.022), (31, -0.062), (32, 0.072), (33, -0.037), (34, -0.044), (35, -0.022), (36, 0.022), (37, 0.1), (38, 0.072), (39, 0.189), (40, -0.007), (41, -0.08), (42, -0.014), (43, -0.009), (44, -0.016), (45, -0.026), (46, -0.013), (47, -0.041), (48, 0.034), (49, -0.071)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92639208 <a title="256-lsi-1" href="./acl-2013-Named_Entity_Recognition_using_Cross-lingual_Resources%3A_Arabic_as_an_Example.html">256 acl-2013-Named Entity Recognition using Cross-lingual Resources: Arabic as an Example</a></p>
<p>Author: Kareem Darwish</p><p>Abstract: Some languages lack large knowledge bases and good discriminative features for Name Entity Recognition (NER) that can generalize to previously unseen named entities. One such language is Arabic, which: a) lacks a capitalization feature; and b) has relatively small knowledge bases, such as Wikipedia. In this work we address both problems by incorporating cross-lingual features and knowledge bases from English using cross-lingual links. We show that such features have a dramatic positive effect on recall. We show the effectiveness of cross-lingual features and resources on a standard dataset as well as on two new test sets that cover both news and microblogs. On the standard dataset, we achieved a 4.1% relative improvement in Fmeasure over the best reported result in the literature. The features led to improvements of 17.1% and 20.5% on the new news and mi- croblogs test sets respectively.</p><p>2 0.73706728 <a title="256-lsi-2" href="./acl-2013-Sentence_Level_Dialect_Identification_in_Arabic.html">317 acl-2013-Sentence Level Dialect Identification in Arabic</a></p>
<p>Author: Heba Elfardy ; Mona Diab</p><p>Abstract: This paper introduces a supervised approach for performing sentence level dialect identification between Modern Standard Arabic and Egyptian Dialectal Arabic. We use token level labels to derive sentence-level features. These features are then used with other core and meta features to train a generative classifier that predicts the correct label for each sentence in the given input text. The system achieves an accuracy of 85.5% on an Arabic online-commentary dataset outperforming a previously proposed approach achieving 80.9% and reflecting a significant gain over a majority baseline of 5 1.9% and two strong baseline systems of 78.5% and 80.4%, respectively.</p><p>3 0.72781789 <a title="256-lsi-3" href="./acl-2013-Translating_Dialectal_Arabic_to_English.html">359 acl-2013-Translating Dialectal Arabic to English</a></p>
<p>Author: Hassan Sajjad ; Kareem Darwish ; Yonatan Belinkov</p><p>Abstract: We present a dialectal Egyptian Arabic to English statistical machine translation system that leverages dialectal to Modern Standard Arabic (MSA) adaptation. In contrast to previous work, we first narrow down the gap between Egyptian and MSA by applying an automatic characterlevel transformational model that changes Egyptian to EG0, which looks similar to MSA. The transformations include morphological, phonological and spelling changes. The transformation reduces the out-of-vocabulary (OOV) words from 5.2% to 2.6% and gives a gain of 1.87 BLEU points. Further, adapting large MSA/English parallel data increases the lexical coverage, reduces OOVs to 0.7% and leads to an absolute BLEU improvement of 2.73 points.</p><p>4 0.55339444 <a title="256-lsi-4" href="./acl-2013-Sorani_Kurdish_versus_Kurmanji_Kurdish%3A_An_Empirical_Comparison.html">327 acl-2013-Sorani Kurdish versus Kurmanji Kurdish: An Empirical Comparison</a></p>
<p>Author: Kyumars Sheykh Esmaili ; Shahin Salavati</p><p>Abstract: Resource scarcity along with diversity– both in dialect and script–are the two primary challenges in Kurdish language processing. In this paper we aim at addressing these two problems by (i) building a text corpus for Sorani and Kurmanji, the two main dialects of Kurdish, and (ii) highlighting some of the orthographic, phonological, and morphological differences between these two dialects from statistical and rule-based perspectives.</p><p>5 0.54561162 <a title="256-lsi-5" href="./acl-2013-Microblogs_as_Parallel_Corpora.html">240 acl-2013-Microblogs as Parallel Corpora</a></p>
<p>Author: Wang Ling ; Guang Xiang ; Chris Dyer ; Alan Black ; Isabel Trancoso</p><p>Abstract: In the ever-expanding sea of microblog data, there is a surprising amount of naturally occurring parallel text: some users create post multilingual messages targeting international audiences while others “retweet” translations. We present an efficient method for detecting these messages and extracting parallel segments from them. We have been able to extract over 1M Chinese-English parallel segments from Sina Weibo (the Chinese counterpart of Twitter) using only their public APIs. As a supplement to existing parallel training data, our automatically extracted parallel data yields substantial translation quality improvements in translating microblog text and modest improvements in translating edited news commentary. The resources in described in this paper are available at http://www.cs.cmu.edu/∼lingwang/utopia.</p><p>6 0.53360605 <a title="256-lsi-6" href="./acl-2013-Language_Independent_Connectivity_Strength_Features_for_Phrase_Pivot_Statistical_Machine_Translation.html">214 acl-2013-Language Independent Connectivity Strength Features for Phrase Pivot Statistical Machine Translation</a></p>
<p>7 0.51792485 <a title="256-lsi-7" href="./acl-2013-HYENA-live%3A_Fine-Grained_Online_Entity_Type_Classification_from_Natural-language_Text.html">179 acl-2013-HYENA-live: Fine-Grained Online Entity Type Classification from Natural-language Text</a></p>
<p>8 0.50214797 <a title="256-lsi-8" href="./acl-2013-Entity_Linking_for_Tweets.html">139 acl-2013-Entity Linking for Tweets</a></p>
<p>9 0.49309525 <a title="256-lsi-9" href="./acl-2013-Mapping_Source_to_Target_Strings_without_Alignment_by_Analogical_Learning%3A_A_Case_Study_with_Transliteration.html">236 acl-2013-Mapping Source to Target Strings without Alignment by Analogical Learning: A Case Study with Transliteration</a></p>
<p>10 0.48579347 <a title="256-lsi-10" href="./acl-2013-Linking_Tweets_to_News%3A_A_Framework_to_Enrich_Short_Text_Data_in_Social_Media.html">233 acl-2013-Linking Tweets to News: A Framework to Enrich Short Text Data in Social Media</a></p>
<p>11 0.48239177 <a title="256-lsi-11" href="./acl-2013-Towards_Accurate_Distant_Supervision_for_Relational_Facts_Extraction.html">352 acl-2013-Towards Accurate Distant Supervision for Relational Facts Extraction</a></p>
<p>12 0.48008892 <a title="256-lsi-12" href="./acl-2013-Fine-grained_Semantic_Typing_of_Emerging_Entities.html">160 acl-2013-Fine-grained Semantic Typing of Emerging Entities</a></p>
<p>13 0.45974278 <a title="256-lsi-13" href="./acl-2013-Enriching_Entity_Translation_Discovery_using_Selective_Temporality.html">138 acl-2013-Enriching Entity Translation Discovery using Selective Temporality</a></p>
<p>14 0.44931057 <a title="256-lsi-14" href="./acl-2013-Text-Driven_Toponym_Resolution_using_Indirect_Supervision.html">340 acl-2013-Text-Driven Toponym Resolution using Indirect Supervision</a></p>
<p>15 0.4471032 <a title="256-lsi-15" href="./acl-2013-Joint_Word_Alignment_and_Bilingual_Named_Entity_Recognition_Using_Dual_Decomposition.html">210 acl-2013-Joint Word Alignment and Bilingual Named Entity Recognition Using Dual Decomposition</a></p>
<p>16 0.43145779 <a title="256-lsi-16" href="./acl-2013-Machine_Translation_Detection_from_Monolingual_Web-Text.html">235 acl-2013-Machine Translation Detection from Monolingual Web-Text</a></p>
<p>17 0.42886308 <a title="256-lsi-17" href="./acl-2013-Bootstrapping_Entity_Translation_on_Weakly_Comparable_Corpora.html">71 acl-2013-Bootstrapping Entity Translation on Weakly Comparable Corpora</a></p>
<p>18 0.4252924 <a title="256-lsi-18" href="./acl-2013-Name-aware_Machine_Translation.html">255 acl-2013-Name-aware Machine Translation</a></p>
<p>19 0.42406231 <a title="256-lsi-19" href="./acl-2013-Resolving_Entity_Morphs_in_Censored_Data.html">301 acl-2013-Resolving Entity Morphs in Censored Data</a></p>
<p>20 0.40493539 <a title="256-lsi-20" href="./acl-2013-Accurate_Word_Segmentation_using_Transliteration_and_Language_Model_Projection.html">34 acl-2013-Accurate Word Segmentation using Transliteration and Language Model Projection</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.028), (6, 0.023), (11, 0.039), (24, 0.035), (26, 0.061), (35, 0.062), (42, 0.052), (48, 0.021), (70, 0.034), (88, 0.022), (90, 0.027), (95, 0.505)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.99529815 <a title="256-lda-1" href="./acl-2013-Improving_machine_translation_by_training_against_an_automatic_semantic_frame_based_evaluation_metric.html">195 acl-2013-Improving machine translation by training against an automatic semantic frame based evaluation metric</a></p>
<p>Author: Chi-kiu Lo ; Karteek Addanki ; Markus Saers ; Dekai Wu</p><p>Abstract: We present the first ever results showing that tuning a machine translation system against a semantic frame based objective function, MEANT, produces more robustly adequate translations than tuning against BLEU or TER as measured across commonly used metrics and human subjective evaluation. Moreover, for informal web forum data, human evaluators preferred MEANT-tuned systems over BLEU- or TER-tuned systems by a significantly wider margin than that for formal newswire—even though automatic semantic parsing might be expected to fare worse on informal language. We argue thatbypreserving the meaning ofthe trans- lations as captured by semantic frames right in the training process, an MT system is constrained to make more accurate choices of both lexical and reordering rules. As a result, MT systems tuned against semantic frame based MT evaluation metrics produce output that is more adequate. Tuning a machine translation system against a semantic frame based objective function is independent ofthe translation model paradigm, so, any translation model can benefit from the semantic knowledge incorporated to improve translation adequacy through our approach.</p><p>2 0.98974645 <a title="256-lda-2" href="./acl-2013-Translating_Dialectal_Arabic_to_English.html">359 acl-2013-Translating Dialectal Arabic to English</a></p>
<p>Author: Hassan Sajjad ; Kareem Darwish ; Yonatan Belinkov</p><p>Abstract: We present a dialectal Egyptian Arabic to English statistical machine translation system that leverages dialectal to Modern Standard Arabic (MSA) adaptation. In contrast to previous work, we first narrow down the gap between Egyptian and MSA by applying an automatic characterlevel transformational model that changes Egyptian to EG0, which looks similar to MSA. The transformations include morphological, phonological and spelling changes. The transformation reduces the out-of-vocabulary (OOV) words from 5.2% to 2.6% and gives a gain of 1.87 BLEU points. Further, adapting large MSA/English parallel data increases the lexical coverage, reduces OOVs to 0.7% and leads to an absolute BLEU improvement of 2.73 points.</p><p>same-paper 3 0.98942453 <a title="256-lda-3" href="./acl-2013-Named_Entity_Recognition_using_Cross-lingual_Resources%3A_Arabic_as_an_Example.html">256 acl-2013-Named Entity Recognition using Cross-lingual Resources: Arabic as an Example</a></p>
<p>Author: Kareem Darwish</p><p>Abstract: Some languages lack large knowledge bases and good discriminative features for Name Entity Recognition (NER) that can generalize to previously unseen named entities. One such language is Arabic, which: a) lacks a capitalization feature; and b) has relatively small knowledge bases, such as Wikipedia. In this work we address both problems by incorporating cross-lingual features and knowledge bases from English using cross-lingual links. We show that such features have a dramatic positive effect on recall. We show the effectiveness of cross-lingual features and resources on a standard dataset as well as on two new test sets that cover both news and microblogs. On the standard dataset, we achieved a 4.1% relative improvement in Fmeasure over the best reported result in the literature. The features led to improvements of 17.1% and 20.5% on the new news and mi- croblogs test sets respectively.</p><p>4 0.98137349 <a title="256-lda-4" href="./acl-2013-Syntactic_Patterns_versus_Word_Alignment%3A_Extracting_Opinion_Targets_from_Online_Reviews.html">336 acl-2013-Syntactic Patterns versus Word Alignment: Extracting Opinion Targets from Online Reviews</a></p>
<p>Author: Kang Liu ; Liheng Xu ; Jun Zhao</p><p>Abstract: Mining opinion targets is a fundamental and important task for opinion mining from online reviews. To this end, there are usually two kinds of methods: syntax based and alignment based methods. Syntax based methods usually exploited syntactic patterns to extract opinion targets, which were however prone to suffer from parsing errors when dealing with online informal texts. In contrast, alignment based methods used word alignment model to fulfill this task, which could avoid parsing errors without using parsing. However, there is no research focusing on which kind of method is more better when given a certain amount of reviews. To fill this gap, this paper empiri- cally studies how the performance of these two kinds of methods vary when changing the size, domain and language of the corpus. We further combine syntactic patterns with alignment model by using a partially supervised framework and investigate whether this combination is useful or not. In our experiments, we verify that our combination is effective on the corpus with small and medium size.</p><p>5 0.97677469 <a title="256-lda-5" href="./acl-2013-Latent_Semantic_Matching%3A_Application_to_Cross-language_Text_Categorization_without_Alignment_Information.html">217 acl-2013-Latent Semantic Matching: Application to Cross-language Text Categorization without Alignment Information</a></p>
<p>Author: Tsutomu Hirao ; Tomoharu Iwata ; Masaaki Nagata</p><p>Abstract: Unsupervised object matching (UOM) is a promising approach to cross-language natural language processing such as bilingual lexicon acquisition, parallel corpus construction, and cross-language text categorization, because it does not require labor-intensive linguistic resources. However, UOM only finds one-to-one correspondences from data sets with the same number of instances in source and target domains, and this prevents us from applying UOM to real-world cross-language natural language processing tasks. To alleviate these limitations, we proposes latent semantic matching, which embeds objects in both source and target language domains into a shared latent topic space. We demonstrate the effectiveness of our method on cross-language text categorization. The results show that our method outperforms conventional unsupervised object matching methods.</p><p>6 0.96943676 <a title="256-lda-6" href="./acl-2013-Adaptive_Parser-Centric_Text_Normalization.html">37 acl-2013-Adaptive Parser-Centric Text Normalization</a></p>
<p>7 0.95320225 <a title="256-lda-7" href="./acl-2013-Beam_Search_for_Solving_Substitution_Ciphers.html">66 acl-2013-Beam Search for Solving Substitution Ciphers</a></p>
<p>8 0.95227832 <a title="256-lda-8" href="./acl-2013-FrameNet_on_the_Way_to_Babel%3A_Creating_a_Bilingual_FrameNet_Using_Wiktionary_as_Interlingual_Connection.html">162 acl-2013-FrameNet on the Way to Babel: Creating a Bilingual FrameNet Using Wiktionary as Interlingual Connection</a></p>
<p>9 0.92747486 <a title="256-lda-9" href="./acl-2013-QuEst_-_A_translation_quality_estimation_framework.html">289 acl-2013-QuEst - A translation quality estimation framework</a></p>
<p>10 0.87251794 <a title="256-lda-10" href="./acl-2013-Using_Context_Vectors_in_Improving_a_Machine_Translation_System_with_Bridge_Language.html">374 acl-2013-Using Context Vectors in Improving a Machine Translation System with Bridge Language</a></p>
<p>11 0.8638888 <a title="256-lda-11" href="./acl-2013-English-to-Russian_MT_evaluation_campaign.html">135 acl-2013-English-to-Russian MT evaluation campaign</a></p>
<p>12 0.85823733 <a title="256-lda-12" href="./acl-2013-Name-aware_Machine_Translation.html">255 acl-2013-Name-aware Machine Translation</a></p>
<p>13 0.85172808 <a title="256-lda-13" href="./acl-2013-Sentence_Level_Dialect_Identification_in_Arabic.html">317 acl-2013-Sentence Level Dialect Identification in Arabic</a></p>
<p>14 0.83647174 <a title="256-lda-14" href="./acl-2013-Language_Independent_Connectivity_Strength_Features_for_Phrase_Pivot_Statistical_Machine_Translation.html">214 acl-2013-Language Independent Connectivity Strength Features for Phrase Pivot Statistical Machine Translation</a></p>
<p>15 0.8318491 <a title="256-lda-15" href="./acl-2013-Social_Text_Normalization_using_Contextual_Graph_Random_Walks.html">326 acl-2013-Social Text Normalization using Contextual Graph Random Walks</a></p>
<p>16 0.8293184 <a title="256-lda-16" href="./acl-2013-A_Decade_of_Automatic_Content_Evaluation_of_News_Summaries%3A_Reassessing_the_State_of_the_Art.html">5 acl-2013-A Decade of Automatic Content Evaluation of News Summaries: Reassessing the State of the Art</a></p>
<p>17 0.82233095 <a title="256-lda-17" href="./acl-2013-A_New_Syntactic_Metric_for_Evaluation_of_Machine_Translation.html">13 acl-2013-A New Syntactic Metric for Evaluation of Machine Translation</a></p>
<p>18 0.82209522 <a title="256-lda-18" href="./acl-2013-Dirt_Cheap_Web-Scale_Parallel_Text_from_the_Common_Crawl.html">120 acl-2013-Dirt Cheap Web-Scale Parallel Text from the Common Crawl</a></p>
<p>19 0.81874681 <a title="256-lda-19" href="./acl-2013-Microblogs_as_Parallel_Corpora.html">240 acl-2013-Microblogs as Parallel Corpora</a></p>
<p>20 0.80411923 <a title="256-lda-20" href="./acl-2013-Cross-lingual_Projections_between_Languages_from_Different_Families.html">97 acl-2013-Cross-lingual Projections between Languages from Different Families</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
