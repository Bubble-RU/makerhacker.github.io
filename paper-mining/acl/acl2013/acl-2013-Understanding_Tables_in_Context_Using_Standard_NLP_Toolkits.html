<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>365 acl-2013-Understanding Tables in Context Using Standard NLP Toolkits</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-365" href="#">acl2013-365</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>365 acl-2013-Understanding Tables in Context Using Standard NLP Toolkits</h1>
<br/><p>Source: <a title="acl-2013-365-pdf" href="http://aclweb.org/anthology//P/P13/P13-2116.pdf">pdf</a></p><p>Author: Vidhya Govindaraju ; Ce Zhang ; Christopher Re</p><p>Abstract: Tabular information in text documents contains a wealth of information, and so tables are a natural candidate for information extraction. There are many cues buried in both a table and its surrounding text that allow us to understand the meaning of the data in a table. We study how natural-language tools, such as part-of-speech tagging, dependency paths, and named-entity recognition, can be used to improve the quality of relation extraction from tables. In three domains we show that (1) a model that performs joint probabilistic inference across tabular and natural language features achieves an F1 score that is twice as high as either a puretable or pure-text system, and (2) using only shallower features or non-joint inference results in lower quality.</p><p>Reference: <a title="acl-2013-365-reference" href="../acl2013_reference/acl-2013-Understanding_Tables_in_Context_Using_Standard_NLP_Toolkits_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 There are many cues buried in both a table and its surrounding text that allow us to understand the meaning of the data in a table. [sent-2, score-0.289]
</p><p>2 We study how natural-language tools, such as part-of-speech tagging, dependency paths, and named-entity recognition, can be used to improve the quality of relation extraction from tables. [sent-3, score-0.256]
</p><p>3 Recent studies found billions of high-quality relations on the web in HTML (Cafarella et al. [sent-6, score-0.17]
</p><p>4 In financial applications, a huge amount of data is buried in the tables of corporate filings and earnings reports; in science, millions of journal articles contain billions of scientific facts in tables. [sent-8, score-0.558]
</p><p>5 Although tables describe precise, structured relations, tables are rarely written in a way that is self-describing, e. [sent-9, score-0.644]
</p><p>6 , tables may contain abbreviations or only informal schema information; in turn, the contents of tables are often ambiguously specified, which makes extracting the relations implicit in tabular data difficult. [sent-11, score-1.194]
</p><p>7 The text surrounding a table in a jour-  chrisre}@cs. [sent-13, score-0.135]
</p><p>8 edu nal article explains its contents to its intended audience, a human reader. [sent-15, score-0.077]
</p><p>9 For example, in a simple study, we demonstrate that humans can achieve more than 60% higher recall by jointly reading the text and tables in a journal article than by only looking at the tables. [sent-16, score-0.534]
</p><p>10 The conclusion of this experiment is not surprising, but it raises a question: How should a system combine tabular and natural-language features to understand tables in text? [sent-17, score-0.898]
</p><p>11 Most previous approaches use textual or tabular features separately, e. [sent-19, score-0.603]
</p><p>12 , tabular approaches that do not use text features (Dalvi et al. [sent-21, score-0.592]
</p><p>13 , 2003) or textual approaches that do not use tabular features (Mintz et al. [sent-23, score-0.603]
</p><p>14 (2007) proposed to learn the target relation independently from both table and surface textual features, and then combine the result us-  ing a linear combination of the predictions. [sent-26, score-0.16]
</p><p>15 In a similar spirit, we propose to use both types of features in our approach of relation extraction. [sent-27, score-0.147]
</p><p>16 Our proposed approach differs from prior approaches in two ways: (1) We use deeper–but standard–NLP features than prior approaches for table extraction. [sent-28, score-0.176]
</p><p>17 In contrast to the shallow, lexical features that prior approaches have used, we use standard NLP features, such as dependency paths, parts of speech, etc. [sent-29, score-0.129]
</p><p>18 Our hypothesis is that a deeper understanding of the text in which a table is embedded will lead to higher quality table extraction. [sent-30, score-0.279]
</p><p>19 (2) Our probabilistic model jointly uses both tabular and textual features. [sent-31, score-0.51]
</p><p>20 One advantage of a joint approach is that one can predict portions of the complicated predicate that is buried in a table. [sent-32, score-0.283]
</p><p>21 For example, in a geology journal article, we may read a measure658  Proce dingSsof oifa, th Beu 5l1gsarti Aan,An u aglu Mste 4e-ti9n2g 0 o1f3 t. [sent-33, score-0.358]
</p><p>22 33n where this rock was unearthed and in what geological time interval this rock appeared may notth b foerm satipone ocif thieesde iocnk ,th cryset lt afrabctlioena. [sent-131, score-0.322]
</p><p>23 OF2oadra each dleteom abseancien of, oweveal build ad b sasayltsict meamgm to extract orse s-h lataidoaknites b elftr. [sent-134, score-0.108]
</p><p>24 s 3,a wep cttearnns, achTiOie2v(Feig t 3wc)i anced aaOs hFigi. [sent-141, score-0.07]
</p><p>25 ,r  2  Motivating Human Study  We describe a simple human study that motivated our approach to jointly combine both  tabular features and natural language features to extract relations from tables. [sent-143, score-0.811]
</p><p>26 deaskiites s htowha a wt dwe rean gwe,a monstt ft tohe pvoast-lciodllisaiotne is that the text selud (rFirgo. [sent-180, score-0.044]
</p><p>27 Ind tihneg tw ao ytpaesb olfe ad ackoiteus,l thde ptotralovide valuable intfso (Krm2O+aNta2iOo wnt %e)v, Ke2On a fuondra cae sh anudm K2Oa/Nna2 Oreader, and theretfroenrde o,f aalcn-a kiadlineea alrc mmagmacash (iFnig. [sent-182, score-0.053]
</p><p>28 Wquenetl a thseskee sdam etsh sirgenifeic ngtley doespcartie fronmtists to manually  sre noat sdim l jyo a urersunlt oafl m gamrattici cdiflfeerse aationn. [sent-185, score-0.065]
</p><p>29 d extract relations fnoerarti ts hofe ad iPtice rotckr ino thleo Gagngdye bdeoltsm hoawin. [sent-186, score-0.169]
</p><p>30 y a Onpvdere Sarl,la, thweh adiackihte a osf dsiof ecreinta atgeess a rock type with eas Frigo. [sent-189, score-0.161]
</p><p>31 o jmoeu ofr tnhea pols a-corllitsi ocnl aeda, wtic reo kps frroomduced three variants: (1) the original document; (2) tableonly, which is the set of tables in the document (without the text) ; (3) text-only, which is the text of the document with the tables removed from the document. [sent-193, score-0.768]
</p><p>32 Each geoscientist was asked to read and extract the relations from one of the three variants. [sent-194, score-0.158]
</p><p>33 We then judged the precision and recall of their extraction, as shown in Figure 2. [sent-195, score-0.09]
</p><p>34 659  As shown in Figure 3, human readers not surprisingly achieve perfect precision on each of the variants, but lower recall on both the table-only and text-only variants. [sent-196, score-0.09]
</p><p>35 However, summing the recall of table-only (60%) and text-only (20%) variants together would  achieve only 80% recall; this implies that in the best case more than 20% of the extractions require that the human reader read the table and its surrounding text jointly. [sent-197, score-0.395]
</p><p>36 This motivates our approach, which uses a joint inference system to model features from a table and its surrounding text. [sent-199, score-0.457]
</p><p>37 We also propose to use deep linguistic features instead of shallower features to get as close as possible to the ability of human readers in understanding the surrounding text of a table. [sent-200, score-0.419]
</p><p>38 1 Experimental Setup We consider the task of constructing a geology knowledge base. [sent-206, score-0.316]
</p><p>39 Specifically, our goal is to extract a Rock-TotalOrganicCarbon relation that maps rock formations (e. [sent-207, score-0.281]
</p><p>40 2 We asked three geoscientists to annotate these journal articles manually to extract the Rock-TotalOrganicCarbon relation (1. [sent-215, score-0.12]
</p><p>41 We then extracted features following state-ofthe-art practices (see Figure 4) . [sent-220, score-0.082]
</p><p>42 To validate our hypothesis, we implement four systems, each of which has access to different types of data: (1) Table. [sent-222, score-0.071]
</p><p>43 This approach only has access to the text in a document and contains all the features mentioned in Wu and Weld (2010) and Mintz et al. [sent-227, score-0.166]
</p><p>44 The features used in (1) and (2) are shown in Figure 4. [sent-229, score-0.082]
</p><p>45 Using Table and Text, we extract all facts and their associated probability. [sent-233, score-0.107]
</p><p>46 Merge is a baseline approach that uses information from both tables and text. [sent-235, score-0.322]
</p><p>47 We build a joint approach that uses information from both tables and text. [sent-237, score-0.486]
</p><p>48 Recall that a key advantage of a joint approach is that we do not need to predict all arguments of the relation (if such a prediction is unwarranted from the data) . [sent-240, score-0.229]
</p><p>49 The inference is done by Gibbs sampling using our inference engine Elementary (Zhang and R e´, 2013) . [sent-241, score-0.24]
</p><p>50 2 End-to-End Quality We were able to validate that Joint achieves higher quality than the other three approaches we considered. [sent-244, score-0.189]
</p><p>51 Figure 5 shows the P/R curve of different approaches on three domains. [sent-245, score-0.083]
</p><p>52 At a recall of 10%, Joint achieves 3x higher precision than all other approaches. [sent-248, score-0.09]
</p><p>53 In our error analysis, we saw that tables in geology articles often contain ambiguous words; for example, 3http : //pdftohtml . [sent-249, score-0.638]
</p><p>54 2 Recall (a) Geology Domain Figure 5: End-to-end  Recall (b) Petrology Domain  Recall (c) Finance Domain  extraction quality on Petrology, Finance, and GeoDeepDive. [sent-261, score-0.155]
</p><p>55 recall is limited by the quality of state-of-the-art  The  table recognition software on PDFs. [sent-262, score-0.161]
</p><p>56 the word “Barnett” in a table may refer to either a location or a rock formation. [sent-263, score-0.161]
</p><p>57 By using features extracted from text, Joint achieves higher precision. [sent-264, score-0.082]
</p><p>58 For recall in the range of 0– 10%, Merge outperforms both Text and Table, with 3%–90% improvement in precision. [sent-265, score-0.09]
</p><p>59 In Geology, Merge has precision that is similar to Text and Table for the higher recall range (>10%) . [sent-266, score-0.09]
</p><p>60 In this domain, we found that relations that appeared in the text often  repeated relations described in the table. [sent-267, score-0.166]
</p><p>61 In other domains, such as Petrology, where the relations in text and tables have lower degrees of overlap, Merge significantly improves over Text and Table (Figure 5(b)) . [sent-268, score-0.427]
</p><p>62 We conducted a statistical significance test to check whether the improvement of Joint over the three other approaches is statistically significant. [sent-269, score-0.089]
</p><p>63 Figure 6 shows the results of the statistical significance test in which the null hypothesis is that the F1 scores of two approaches are the same. [sent-277, score-0.135]
</p><p>64 01, Joint has statistically significant improvement of F1 score over all three other approaches with each probability threshold. [sent-279, score-0.047]
</p><p>65 Linguistic Features  We validate the hypothesis that using linguistic features, e. [sent-282, score-0.117]
</p><p>66 , 2006) , helps improve the quality of our approach, called Joint. [sent-286, score-0.071]
</p><p>67 5+ +0 Figure 6: Approximate randomization test from Chinchor (1992) of F1 score with p = 0. [sent-290, score-0.053]
</p><p>68 01 on the impact of joint inference compared with pure-table or pure-text approaches for different probability thresholds. [sent-291, score-0.331]
</p><p>69 A + sign indicates that the F1 score of joint approach increased significantly. [sent-292, score-0.164]
</p><p>70 state-of-the-art approaches from the literature (see Figure 7) . [sent-297, score-0.047]
</p><p>71 Joint(-parse) removes features generated by the dependency parser and syntax parser. [sent-299, score-0.143]
</p><p>72 Similarly, Joint(-ner) (Joint(-pos)) removes all features related to NER (resp. [sent-300, score-0.143]
</p><p>73 Joint(-pos) also removes NER and parser features because the latter two are dependent on POS features. [sent-302, score-0.143]
</p><p>74 Figure 8 shows the P/R curve for all these variants on Geology, and Figure 9 shows the results of statistical significance  test. [sent-303, score-0.153]
</p><p>75 3  Recall  Figure 8: Lesion study of different features for Geology. [sent-310, score-0.118]
</p><p>76 + 5+0 Figure 9: Approximate randomization test of F1 score with p = 0. [sent-314, score-0.053]
</p><p>77 and Joint(-ner) is not significant because there are “easy-to-extract” facts in the highprobability range. [sent-318, score-0.087]
</p><p>78 4  Related Work  The intuition that context features might help table-related tasks has existed for decades. [sent-321, score-0.082]
</p><p>79 For example, Hurst and Nasukawa (2000) mentioned (as future work) that context features could be used to further improve their relation extraction approaches from tables. [sent-322, score-0.278]
</p><p>80 (2010) use bag-of-words features and hyperlinks to recommend new columns for web tables. [sent-324, score-0.126]
</p><p>81 (2007) extract features, including font size and title, from PDF documents in  which a table appears to help the table ranking task. [sent-326, score-0.055]
</p><p>82 They find that these features only contribute less than 2% to precision. [sent-327, score-0.082]
</p><p>83 In contrast, in our approach linguistic features are quite useful. [sent-328, score-0.082]
</p><p>84 The above approaches use context features that can be extracted without POS tagging or linguistic parsing. [sent-329, score-0.129]
</p><p>85 One aspect of our work is to demonstrate that traditional NLP tools can enhance the quality of table extraction. [sent-330, score-0.071]
</p><p>86 Extracting information from tables has been discussed by different communities in the last decade, including NLP (Wu and Lee, 2006; Tengli et al. [sent-331, score-0.322]
</p><p>87 This body of work considers only features derived from tables and does not examine richer NLP features as we do. [sent-339, score-0.486]
</p><p>88 While joint inference is popular, it is not clear when a joint inference system outper-  forms a more traditional NLP pipeline. [sent-340, score-0.568]
</p><p>89 Recent studies have reached a variety of conclusions: in some, joint inference helps extraction quality (McCallum, 2009; Poon and Domingos, 2007; Singh et al. [sent-341, score-0.439]
</p><p>90 , 2009) ; and in some, joint inference hurts extraction quality (Poon and Domingos, 2007; Eisner, 2009) . [sent-342, score-0.439]
</p><p>91 Our intuition is that joint inference is helpful in this application because our joint inference approach combines non-redundant signals (textual versus tabular) . [sent-343, score-0.568]
</p><p>92 5  Conclusion  To improve the quality of extractions of tabular data, we use standard NLP techniques to more deeply understand the text in which a table is embedded. [sent-344, score-0.622]
</p><p>93 We validate that deeper NLP features combined with a joint probabilistic model has a statistically significant impact on quality, i. [sent-345, score-0.385]
</p><p>94 WebTables: Exploring the power of tables on the web. [sent-359, score-0.322]
</p><p>95 WebSets: Extracting sets of entities from the web using unsupervised information extraction. [sent-371, score-0.044]
</p><p>96 Incorporating non-local information into information extraction systems by Gibbs sampling. [sent-393, score-0.084]
</p><p>97 Layout and language: Integrating spatial and linguistic knowledge for layout understanding tasks. [sent-397, score-0.108]
</p><p>98 TableSeer: Automatic table metadata extraction and searching in digital libraries. [sent-414, score-0.12]
</p><p>99 Bi-directional joint inference for entity resolution and segmentation using imperatively-defined factor graphs. [sent-439, score-0.284]
</p><p>100 A grammatical approach to understanding textual tables using two-dimensional scfgs. [sent-456, score-0.427]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tabular', 0.419), ('tables', 0.322), ('geology', 0.316), ('joint', 0.164), ('rock', 0.161), ('dalvi', 0.158), ('pinto', 0.121), ('inference', 0.12), ('buried', 0.119), ('petrology', 0.119), ('vidhya', 0.119), ('poon', 0.1), ('surrounding', 0.091), ('recall', 0.09), ('extraction', 0.084), ('wu', 0.082), ('features', 0.082), ('barnett', 0.079), ('govindaraju', 0.079), ('iptice', 0.079), ('tengli', 0.079), ('domingos', 0.077), ('variants', 0.075), ('mintz', 0.075), ('quality', 0.071), ('cafarella', 0.071), ('validate', 0.071), ('shallower', 0.07), ('hurst', 0.07), ('deeper', 0.068), ('merge', 0.066), ('relation', 0.065), ('prasenjit', 0.065), ('sre', 0.065), ('billions', 0.065), ('removes', 0.061), ('relations', 0.061), ('mitra', 0.058), ('layout', 0.058), ('textual', 0.055), ('extract', 0.055), ('randomization', 0.053), ('extractions', 0.053), ('ad', 0.053), ('facts', 0.052), ('marneffe', 0.052), ('ner', 0.052), ('afrl', 0.052), ('understanding', 0.05), ('fang', 0.05), ('ce', 0.05), ('singh', 0.049), ('finance', 0.047), ('xing', 0.047), ('weld', 0.047), ('approaches', 0.047), ('christopher', 0.047), ('hypothesis', 0.046), ('toutanova', 0.046), ('sigmod', 0.046), ('gibbs', 0.045), ('bruce', 0.045), ('cm', 0.045), ('web', 0.044), ('text', 0.044), ('andrew', 0.044), ('finkel', 0.043), ('read', 0.042), ('nlp', 0.042), ('wei', 0.042), ('article', 0.042), ('significance', 0.042), ('mccallum', 0.042), ('award', 0.041), ('combine', 0.04), ('shallow', 0.04), ('document', 0.04), ('zhang', 0.039), ('lee', 0.037), ('study', 0.036), ('jointly', 0.036), ('aaai', 0.036), ('digital', 0.036), ('curve', 0.036), ('paths', 0.036), ('contents', 0.035), ('conference', 0.035), ('understand', 0.035), ('anced', 0.035), ('wep', 0.035), ('cindy', 0.035), ('onl', 0.035), ('feig', 0.035), ('ambiguously', 0.035), ('etso', 0.035), ('ogf', 0.035), ('sourceforge', 0.035), ('jude', 0.035), ('shavlik', 0.035), ('highprobability', 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="365-tfidf-1" href="./acl-2013-Understanding_Tables_in_Context_Using_Standard_NLP_Toolkits.html">365 acl-2013-Understanding Tables in Context Using Standard NLP Toolkits</a></p>
<p>Author: Vidhya Govindaraju ; Ce Zhang ; Christopher Re</p><p>Abstract: Tabular information in text documents contains a wealth of information, and so tables are a natural candidate for information extraction. There are many cues buried in both a table and its surrounding text that allow us to understand the meaning of the data in a table. We study how natural-language tools, such as part-of-speech tagging, dependency paths, and named-entity recognition, can be used to improve the quality of relation extraction from tables. In three domains we show that (1) a model that performs joint probabilistic inference across tabular and natural language features achieves an F1 score that is twice as high as either a puretable or pure-text system, and (2) using only shallower features or non-joint inference results in lower quality.</p><p>2 0.10127402 <a title="365-tfidf-2" href="./acl-2013-Filling_Knowledge_Base_Gaps_for_Distant_Supervision_of_Relation_Extraction.html">159 acl-2013-Filling Knowledge Base Gaps for Distant Supervision of Relation Extraction</a></p>
<p>Author: Wei Xu ; Raphael Hoffmann ; Le Zhao ; Ralph Grishman</p><p>Abstract: Distant supervision has attracted recent interest for training information extraction systems because it does not require any human annotation but rather employs existing knowledge bases to heuristically label a training corpus. However, previous work has failed to address the problem of false negative training examples mislabeled due to the incompleteness of knowledge bases. To tackle this problem, we propose a simple yet novel framework that combines a passage retrieval model using coarse features into a state-of-the-art relation extractor using multi-instance learning with fine features. We adapt the information retrieval technique of pseudo- relevance feedback to expand knowledge bases, assuming entity pairs in top-ranked passages are more likely to express a relation. Our proposed technique significantly improves the quality of distantly supervised relation extraction, boosting recall from 47.7% to 61.2% with a consistently high level of precision of around 93% in the experiments.</p><p>3 0.10038092 <a title="365-tfidf-3" href="./acl-2013-Towards_Accurate_Distant_Supervision_for_Relational_Facts_Extraction.html">352 acl-2013-Towards Accurate Distant Supervision for Relational Facts Extraction</a></p>
<p>Author: Xingxing Zhang ; Jianwen Zhang ; Junyu Zeng ; Jun Yan ; Zheng Chen ; Zhifang Sui</p><p>Abstract: Distant supervision (DS) is an appealing learning method which learns from existing relational facts to extract more from a text corpus. However, the accuracy is still not satisfying. In this paper, we point out and analyze some critical factors in DS which have great impact on accuracy, including valid entity type detection, negative training examples construction and ensembles. We propose an approach to handle these factors. By experimenting on Wikipedia articles to extract the facts in Freebase (the top 92 relations), we show the impact of these three factors on the accuracy of DS and the remarkable improvement led by the proposed approach.</p><p>4 0.073924184 <a title="365-tfidf-4" href="./acl-2013-Hierarchical_Phrase_Table_Combination_for_Machine_Translation.html">181 acl-2013-Hierarchical Phrase Table Combination for Machine Translation</a></p>
<p>Author: Conghui Zhu ; Taro Watanabe ; Eiichiro Sumita ; Tiejun Zhao</p><p>Abstract: Typical statistical machine translation systems are batch trained with a given training data and their performances are largely influenced by the amount of data. With the growth of the available data across different domains, it is computationally demanding to perform batch training every time when new data comes. In face of the problem, we propose an efficient phrase table combination method. In particular, we train a Bayesian phrasal inversion transduction grammars for each domain separately. The learned phrase tables are hierarchically combined as if they are drawn from a hierarchical Pitman-Yor process. The performance measured by BLEU is at least as comparable to the traditional batch training method. Furthermore, each phrase table is trained separately in each domain, and while computational overhead is significantly reduced by training them in parallel.</p><p>5 0.073720306 <a title="365-tfidf-5" href="./acl-2013-Generating_Synthetic_Comparable_Questions_for_News_Articles.html">169 acl-2013-Generating Synthetic Comparable Questions for News Articles</a></p>
<p>Author: Oleg Rokhlenko ; Idan Szpektor</p><p>Abstract: We introduce the novel task of automatically generating questions that are relevant to a text but do not appear in it. One motivating example of its application is for increasing user engagement around news articles by suggesting relevant comparable questions, such as “is Beyonce a better singer than Madonna?”, for the user to answer. We present the first algorithm for the task, which consists of: (a) offline construction of a comparable question template database; (b) ranking of relevant templates to a given article; and (c) instantiation of templates only with entities in the article whose comparison under the template’s relation makes sense. We tested the suggestions generated by our algorithm via a Mechanical Turk experiment, which showed a significant improvement over the strongest baseline of more than 45% in all metrics.</p><p>6 0.066785187 <a title="365-tfidf-6" href="./acl-2013-Margin-based_Decomposed_Amortized_Inference.html">237 acl-2013-Margin-based Decomposed Amortized Inference</a></p>
<p>7 0.066508487 <a title="365-tfidf-7" href="./acl-2013-Joint_Inference_for_Heterogeneous_Dependency_Parsing.html">208 acl-2013-Joint Inference for Heterogeneous Dependency Parsing</a></p>
<p>8 0.066477701 <a title="365-tfidf-8" href="./acl-2013-PLIS%3A_a_Probabilistic_Lexical_Inference_System.html">269 acl-2013-PLIS: a Probabilistic Lexical Inference System</a></p>
<p>9 0.065120824 <a title="365-tfidf-9" href="./acl-2013-Learning_to_Extract_International_Relations_from_Political_Context.html">224 acl-2013-Learning to Extract International Relations from Political Context</a></p>
<p>10 0.063920923 <a title="365-tfidf-10" href="./acl-2013-Chinese_Parsing_Exploiting_Characters.html">80 acl-2013-Chinese Parsing Exploiting Characters</a></p>
<p>11 0.063454211 <a title="365-tfidf-11" href="./acl-2013-Fine-grained_Semantic_Typing_of_Emerging_Entities.html">160 acl-2013-Fine-grained Semantic Typing of Emerging Entities</a></p>
<p>12 0.06323947 <a title="365-tfidf-12" href="./acl-2013-Question_Answering_Using_Enhanced_Lexical_Semantic_Models.html">291 acl-2013-Question Answering Using Enhanced Lexical Semantic Models</a></p>
<p>13 0.062433701 <a title="365-tfidf-13" href="./acl-2013-FudanNLP%3A_A_Toolkit_for_Chinese_Natural_Language_Processing.html">164 acl-2013-FudanNLP: A Toolkit for Chinese Natural Language Processing</a></p>
<p>14 0.062073048 <a title="365-tfidf-14" href="./acl-2013-Joint_Word_Alignment_and_Bilingual_Named_Entity_Recognition_Using_Dual_Decomposition.html">210 acl-2013-Joint Word Alignment and Bilingual Named Entity Recognition Using Dual Decomposition</a></p>
<p>15 0.061581753 <a title="365-tfidf-15" href="./acl-2013-Graph-based_Semi-Supervised_Model_for_Joint_Chinese_Word_Segmentation_and_Part-of-Speech_Tagging.html">173 acl-2013-Graph-based Semi-Supervised Model for Joint Chinese Word Segmentation and Part-of-Speech Tagging</a></p>
<p>16 0.059704918 <a title="365-tfidf-16" href="./acl-2013-An_Infinite_Hierarchical_Bayesian_Model_of_Phrasal_Translation.html">46 acl-2013-An Infinite Hierarchical Bayesian Model of Phrasal Translation</a></p>
<p>17 0.058146451 <a title="365-tfidf-17" href="./acl-2013-Modeling_Human_Inference_Process_for_Textual_Entailment_Recognition.html">245 acl-2013-Modeling Human Inference Process for Textual Entailment Recognition</a></p>
<p>18 0.057538103 <a title="365-tfidf-18" href="./acl-2013-HYENA-live%3A_Fine-Grained_Online_Entity_Type_Classification_from_Natural-language_Text.html">179 acl-2013-HYENA-live: Fine-Grained Online Entity Type Classification from Natural-language Text</a></p>
<p>19 0.056562565 <a title="365-tfidf-19" href="./acl-2013-Mining_Equivalent_Relations_from_Linked_Data.html">242 acl-2013-Mining Equivalent Relations from Linked Data</a></p>
<p>20 0.05563283 <a title="365-tfidf-20" href="./acl-2013-Automatic_Coupling_of_Answer_Extraction_and_Information_Retrieval.html">60 acl-2013-Automatic Coupling of Answer Extraction and Information Retrieval</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.188), (1, 0.022), (2, -0.028), (3, -0.042), (4, 0.034), (5, 0.063), (6, -0.012), (7, -0.037), (8, 0.002), (9, -0.001), (10, 0.001), (11, -0.021), (12, -0.034), (13, 0.015), (14, -0.002), (15, -0.004), (16, -0.008), (17, 0.02), (18, -0.019), (19, -0.038), (20, -0.002), (21, 0.036), (22, -0.018), (23, 0.072), (24, 0.04), (25, 0.051), (26, -0.009), (27, -0.053), (28, -0.002), (29, -0.022), (30, 0.021), (31, 0.06), (32, 0.013), (33, 0.027), (34, -0.018), (35, 0.047), (36, 0.042), (37, -0.062), (38, -0.026), (39, 0.043), (40, -0.012), (41, -0.018), (42, -0.096), (43, -0.013), (44, 0.036), (45, -0.005), (46, -0.044), (47, 0.034), (48, -0.017), (49, 0.065)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94376975 <a title="365-lsi-1" href="./acl-2013-Understanding_Tables_in_Context_Using_Standard_NLP_Toolkits.html">365 acl-2013-Understanding Tables in Context Using Standard NLP Toolkits</a></p>
<p>Author: Vidhya Govindaraju ; Ce Zhang ; Christopher Re</p><p>Abstract: Tabular information in text documents contains a wealth of information, and so tables are a natural candidate for information extraction. There are many cues buried in both a table and its surrounding text that allow us to understand the meaning of the data in a table. We study how natural-language tools, such as part-of-speech tagging, dependency paths, and named-entity recognition, can be used to improve the quality of relation extraction from tables. In three domains we show that (1) a model that performs joint probabilistic inference across tabular and natural language features achieves an F1 score that is twice as high as either a puretable or pure-text system, and (2) using only shallower features or non-joint inference results in lower quality.</p><p>2 0.80786103 <a title="365-lsi-2" href="./acl-2013-Filling_Knowledge_Base_Gaps_for_Distant_Supervision_of_Relation_Extraction.html">159 acl-2013-Filling Knowledge Base Gaps for Distant Supervision of Relation Extraction</a></p>
<p>Author: Wei Xu ; Raphael Hoffmann ; Le Zhao ; Ralph Grishman</p><p>Abstract: Distant supervision has attracted recent interest for training information extraction systems because it does not require any human annotation but rather employs existing knowledge bases to heuristically label a training corpus. However, previous work has failed to address the problem of false negative training examples mislabeled due to the incompleteness of knowledge bases. To tackle this problem, we propose a simple yet novel framework that combines a passage retrieval model using coarse features into a state-of-the-art relation extractor using multi-instance learning with fine features. We adapt the information retrieval technique of pseudo- relevance feedback to expand knowledge bases, assuming entity pairs in top-ranked passages are more likely to express a relation. Our proposed technique significantly improves the quality of distantly supervised relation extraction, boosting recall from 47.7% to 61.2% with a consistently high level of precision of around 93% in the experiments.</p><p>3 0.71304476 <a title="365-lsi-3" href="./acl-2013-Towards_Accurate_Distant_Supervision_for_Relational_Facts_Extraction.html">352 acl-2013-Towards Accurate Distant Supervision for Relational Facts Extraction</a></p>
<p>Author: Xingxing Zhang ; Jianwen Zhang ; Junyu Zeng ; Jun Yan ; Zheng Chen ; Zhifang Sui</p><p>Abstract: Distant supervision (DS) is an appealing learning method which learns from existing relational facts to extract more from a text corpus. However, the accuracy is still not satisfying. In this paper, we point out and analyze some critical factors in DS which have great impact on accuracy, including valid entity type detection, negative training examples construction and ensembles. We propose an approach to handle these factors. By experimenting on Wikipedia articles to extract the facts in Freebase (the top 92 relations), we show the impact of these three factors on the accuracy of DS and the remarkable improvement led by the proposed approach.</p><p>4 0.69917274 <a title="365-lsi-4" href="./acl-2013-Large-scale_Semantic_Parsing_via_Schema_Matching_and_Lexicon_Extension.html">215 acl-2013-Large-scale Semantic Parsing via Schema Matching and Lexicon Extension</a></p>
<p>Author: Qingqing Cai ; Alexander Yates</p><p>Abstract: Supervised training procedures for semantic parsers produce high-quality semantic parsers, but they have difficulty scaling to large databases because of the sheer number of logical constants for which they must see labeled training data. We present a technique for developing semantic parsers for large databases based on a reduction to standard supervised training algorithms, schema matching, and pattern learning. Leveraging techniques from each of these areas, we develop a semantic parser for Freebase that is capable of parsing questions with an F1 that improves by 0.42 over a purely-supervised learning algorithm.</p><p>5 0.66672254 <a title="365-lsi-5" href="./acl-2013-Transfer_Learning_Based_Cross-lingual_Knowledge_Extraction_for_Wikipedia.html">356 acl-2013-Transfer Learning Based Cross-lingual Knowledge Extraction for Wikipedia</a></p>
<p>Author: Zhigang Wang ; Zhixing Li ; Juanzi Li ; Jie Tang ; Jeff Z. Pan</p><p>Abstract: Wikipedia infoboxes are a valuable source of structured knowledge for global knowledge sharing. However, infobox information is very incomplete and imbalanced among the Wikipedias in different languages. It is a promising but challenging problem to utilize the rich structured knowledge from a source language Wikipedia to help complete the missing infoboxes for a target language. In this paper, we formulate the problem of cross-lingual knowledge extraction from multilingual Wikipedia sources, and present a novel framework, called WikiCiKE, to solve this problem. An instancebased transfer learning method is utilized to overcome the problems of topic drift and translation errors. Our experimental results demonstrate that WikiCiKE outperforms the monolingual knowledge extraction method and the translation-based method.</p><p>6 0.66439426 <a title="365-lsi-6" href="./acl-2013-Fine-grained_Semantic_Typing_of_Emerging_Entities.html">160 acl-2013-Fine-grained Semantic Typing of Emerging Entities</a></p>
<p>7 0.65306908 <a title="365-lsi-7" href="./acl-2013-PLIS%3A_a_Probabilistic_Lexical_Inference_System.html">269 acl-2013-PLIS: a Probabilistic Lexical Inference System</a></p>
<p>8 0.6478579 <a title="365-lsi-8" href="./acl-2013-HEADY%3A_News_headline_abstraction_through_event_pattern_clustering.html">178 acl-2013-HEADY: News headline abstraction through event pattern clustering</a></p>
<p>9 0.64664865 <a title="365-lsi-9" href="./acl-2013-HYENA-live%3A_Fine-Grained_Online_Entity_Type_Classification_from_Natural-language_Text.html">179 acl-2013-HYENA-live: Fine-Grained Online Entity Type Classification from Natural-language Text</a></p>
<p>10 0.63353372 <a title="365-lsi-10" href="./acl-2013-Automatic_Interpretation_of_the_English_Possessive.html">61 acl-2013-Automatic Interpretation of the English Possessive</a></p>
<p>11 0.632851 <a title="365-lsi-11" href="./acl-2013-Leveraging_Domain-Independent_Information_in_Semantic_Parsing.html">228 acl-2013-Leveraging Domain-Independent Information in Semantic Parsing</a></p>
<p>12 0.62881202 <a title="365-lsi-12" href="./acl-2013-Text-Driven_Toponym_Resolution_using_Indirect_Supervision.html">340 acl-2013-Text-Driven Toponym Resolution using Indirect Supervision</a></p>
<p>13 0.61278123 <a title="365-lsi-13" href="./acl-2013-Generating_Synthetic_Comparable_Questions_for_News_Articles.html">169 acl-2013-Generating Synthetic Comparable Questions for News Articles</a></p>
<p>14 0.61159539 <a title="365-lsi-14" href="./acl-2013-Joint_Apposition_Extraction_with_Syntactic_and_Semantic_Constraints.html">205 acl-2013-Joint Apposition Extraction with Syntactic and Semantic Constraints</a></p>
<p>15 0.61084479 <a title="365-lsi-15" href="./acl-2013-Embedding_Semantic_Similarity_in_Tree_Kernels_for_Domain_Adaptation_of_Relation_Extraction.html">134 acl-2013-Embedding Semantic Similarity in Tree Kernels for Domain Adaptation of Relation Extraction</a></p>
<p>16 0.60847384 <a title="365-lsi-16" href="./acl-2013-Margin-based_Decomposed_Amortized_Inference.html">237 acl-2013-Margin-based Decomposed Amortized Inference</a></p>
<p>17 0.60273647 <a title="365-lsi-17" href="./acl-2013-The_Impact_of_Topic_Bias_on_Quality_Flaw_Prediction_in_Wikipedia.html">346 acl-2013-The Impact of Topic Bias on Quality Flaw Prediction in Wikipedia</a></p>
<p>18 0.58438766 <a title="365-lsi-18" href="./acl-2013-A_Novel_Classifier_Based_on_Quantum_Computation.html">14 acl-2013-A Novel Classifier Based on Quantum Computation</a></p>
<p>19 0.58431804 <a title="365-lsi-19" href="./acl-2013-Recognizing_Rare_Social_Phenomena_in_Conversation%3A_Empowerment_Detection_in_Support_Group_Chatrooms.html">298 acl-2013-Recognizing Rare Social Phenomena in Conversation: Empowerment Detection in Support Group Chatrooms</a></p>
<p>20 0.58174109 <a title="365-lsi-20" href="./acl-2013-Using_Conceptual_Class_Attributes_to_Characterize_Social_Media_Users.html">373 acl-2013-Using Conceptual Class Attributes to Characterize Social Media Users</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.06), (6, 0.024), (11, 0.069), (15, 0.018), (21, 0.017), (23, 0.263), (24, 0.046), (26, 0.061), (28, 0.011), (35, 0.079), (42, 0.067), (48, 0.041), (64, 0.01), (70, 0.056), (88, 0.023), (90, 0.025), (95, 0.07)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.81092232 <a title="365-lda-1" href="./acl-2013-Joint_Modeling_of_News_Reader%C3%A2%E2%80%A2%C5%BDs_and_Comment_Writer%C3%A2%E2%80%A2%C5%BDs_Emotions.html">209 acl-2013-Joint Modeling of News Readerâ•Žs and Comment Writerâ•Žs Emotions</a></p>
<p>Author: Huanhuan Liu ; Shoushan Li ; Guodong Zhou ; Chu-ren Huang ; Peifeng Li</p><p>Abstract: Emotion classification can be generally done from both the writer’s and reader’s perspectives. In this study, we find that two foundational tasks in emotion classification, i.e., reader’s emotion classification on the news and writer’s emotion classification on the comments, are strongly related to each other in terms of coarse-grained emotion categories, i.e., negative and positive. On the basis, we propose a respective way to jointly model these two tasks. In particular, a cotraining algorithm is proposed to improve semi-supervised learning of the two tasks. Experimental evaluation shows the effectiveness of our joint modeling approach. . 1</p><p>same-paper 2 0.75927418 <a title="365-lda-2" href="./acl-2013-Understanding_Tables_in_Context_Using_Standard_NLP_Toolkits.html">365 acl-2013-Understanding Tables in Context Using Standard NLP Toolkits</a></p>
<p>Author: Vidhya Govindaraju ; Ce Zhang ; Christopher Re</p><p>Abstract: Tabular information in text documents contains a wealth of information, and so tables are a natural candidate for information extraction. There are many cues buried in both a table and its surrounding text that allow us to understand the meaning of the data in a table. We study how natural-language tools, such as part-of-speech tagging, dependency paths, and named-entity recognition, can be used to improve the quality of relation extraction from tables. In three domains we show that (1) a model that performs joint probabilistic inference across tabular and natural language features achieves an F1 score that is twice as high as either a puretable or pure-text system, and (2) using only shallower features or non-joint inference results in lower quality.</p><p>3 0.73828858 <a title="365-lda-3" href="./acl-2013-Stacking_for_Statistical_Machine_Translation.html">328 acl-2013-Stacking for Statistical Machine Translation</a></p>
<p>Author: Majid Razmara ; Anoop Sarkar</p><p>Abstract: We propose the use of stacking, an ensemble learning technique, to the statistical machine translation (SMT) models. A diverse ensemble of weak learners is created using the same SMT engine (a hierarchical phrase-based system) by manipulating the training data and a strong model is created by combining the weak models on-the-fly. Experimental results on two language pairs and three different sizes of training data show significant improvements of up to 4 BLEU points over a conventionally trained SMT model.</p><p>4 0.70716208 <a title="365-lda-4" href="./acl-2013-Summarization_Through_Submodularity_and_Dispersion.html">333 acl-2013-Summarization Through Submodularity and Dispersion</a></p>
<p>Author: Anirban Dasgupta ; Ravi Kumar ; Sujith Ravi</p><p>Abstract: We propose a new optimization framework for summarization by generalizing the submodular framework of (Lin and Bilmes, 2011). In our framework the summarization desideratum is expressed as a sum of a submodular function and a nonsubmodular function, which we call dispersion; the latter uses inter-sentence dissimilarities in different ways in order to ensure non-redundancy of the summary. We consider three natural dispersion functions and show that a greedy algorithm can obtain an approximately optimal summary in all three cases. We conduct experiments on two corpora—DUC 2004 and user comments on news articles—and show that the performance of our algorithm outperforms those that rely only on submodularity.</p><p>5 0.57498389 <a title="365-lda-5" href="./acl-2013-Part-of-Speech_Induction_in_Dependency_Trees_for_Statistical_Machine_Translation.html">276 acl-2013-Part-of-Speech Induction in Dependency Trees for Statistical Machine Translation</a></p>
<p>Author: Akihiro Tamura ; Taro Watanabe ; Eiichiro Sumita ; Hiroya Takamura ; Manabu Okumura</p><p>Abstract: This paper proposes a nonparametric Bayesian method for inducing Part-ofSpeech (POS) tags in dependency trees to improve the performance of statistical machine translation (SMT). In particular, we extend the monolingual infinite tree model (Finkel et al., 2007) to a bilingual scenario: each hidden state (POS tag) of a source-side dependency tree emits a source word together with its aligned target word, either jointly (joint model), or independently (independent model). Evaluations of Japanese-to-English translation on the NTCIR-9 data show that our induced Japanese POS tags for dependency trees improve the performance of a forest- to-string SMT system. Our independent model gains over 1 point in BLEU by resolving the sparseness problem introduced in the joint model.</p><p>6 0.56929469 <a title="365-lda-6" href="./acl-2013-Easy-First_POS_Tagging_and_Dependency_Parsing_with_Beam_Search.html">132 acl-2013-Easy-First POS Tagging and Dependency Parsing with Beam Search</a></p>
<p>7 0.5685786 <a title="365-lda-7" href="./acl-2013-The_Effect_of_Higher-Order_Dependency_Features_in_Discriminative_Phrase-Structure_Parsing.html">343 acl-2013-The Effect of Higher-Order Dependency Features in Discriminative Phrase-Structure Parsing</a></p>
<p>8 0.5670656 <a title="365-lda-8" href="./acl-2013-Filling_Knowledge_Base_Gaps_for_Distant_Supervision_of_Relation_Extraction.html">159 acl-2013-Filling Knowledge Base Gaps for Distant Supervision of Relation Extraction</a></p>
<p>9 0.56540811 <a title="365-lda-9" href="./acl-2013-Sentiment_Relevance.html">318 acl-2013-Sentiment Relevance</a></p>
<p>10 0.56523418 <a title="365-lda-10" href="./acl-2013-Fast_and_Accurate_Shift-Reduce_Constituent_Parsing.html">155 acl-2013-Fast and Accurate Shift-Reduce Constituent Parsing</a></p>
<p>11 0.56482512 <a title="365-lda-11" href="./acl-2013-Graph_Propagation_for_Paraphrasing_Out-of-Vocabulary_Words_in_Statistical_Machine_Translation.html">174 acl-2013-Graph Propagation for Paraphrasing Out-of-Vocabulary Words in Statistical Machine Translation</a></p>
<p>12 0.56373274 <a title="365-lda-12" href="./acl-2013-An_Infinite_Hierarchical_Bayesian_Model_of_Phrasal_Translation.html">46 acl-2013-An Infinite Hierarchical Bayesian Model of Phrasal Translation</a></p>
<p>13 0.5635637 <a title="365-lda-13" href="./acl-2013-Co-regularizing_character-based_and_word-based_models_for_semi-supervised_Chinese_word_segmentation.html">82 acl-2013-Co-regularizing character-based and word-based models for semi-supervised Chinese word segmentation</a></p>
<p>14 0.56324959 <a title="365-lda-14" href="./acl-2013-FudanNLP%3A_A_Toolkit_for_Chinese_Natural_Language_Processing.html">164 acl-2013-FudanNLP: A Toolkit for Chinese Natural Language Processing</a></p>
<p>15 0.56286693 <a title="365-lda-15" href="./acl-2013-Embedding_Semantic_Similarity_in_Tree_Kernels_for_Domain_Adaptation_of_Relation_Extraction.html">134 acl-2013-Embedding Semantic Similarity in Tree Kernels for Domain Adaptation of Relation Extraction</a></p>
<p>16 0.56245375 <a title="365-lda-16" href="./acl-2013-Chinese_Parsing_Exploiting_Characters.html">80 acl-2013-Chinese Parsing Exploiting Characters</a></p>
<p>17 0.56220794 <a title="365-lda-17" href="./acl-2013-Parsing_with_Compositional_Vector_Grammars.html">275 acl-2013-Parsing with Compositional Vector Grammars</a></p>
<p>18 0.56163591 <a title="365-lda-18" href="./acl-2013-Collective_Annotation_of_Linguistic_Resources%3A_Basic_Principles_and_a_Formal_Model.html">83 acl-2013-Collective Annotation of Linguistic Resources: Basic Principles and a Formal Model</a></p>
<p>19 0.56144762 <a title="365-lda-19" href="./acl-2013-A_Sentence_Compression_Based_Framework_to_Query-Focused_Multi-Document_Summarization.html">18 acl-2013-A Sentence Compression Based Framework to Query-Focused Multi-Document Summarization</a></p>
<p>20 0.56111073 <a title="365-lda-20" href="./acl-2013-Learning_to_Order_Natural_Language_Texts.html">225 acl-2013-Learning to Order Natural Language Texts</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
