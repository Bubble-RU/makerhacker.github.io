<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>144 acl-2013-Explicit and Implicit Syntactic Features for Text Classification</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-144" href="#">acl2013-144</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>144 acl-2013-Explicit and Implicit Syntactic Features for Text Classification</h1>
<br/><p>Source: <a title="acl-2013-144-pdf" href="http://aclweb.org/anthology//P/P13/P13-2150.pdf">pdf</a></p><p>Author: Matt Post ; Shane Bergsma</p><p>Abstract: Syntactic features are useful for many text classification tasks. Among these, tree kernels (Collins and Duffy, 2001) have been perhaps the most robust and effective syntactic tool, appealing for their empirical success, but also because they do not require an answer to the difficult question of which tree features to use for a given task. We compare tree kernels to different explicit sets of tree features on five diverse tasks, and find that explicit features often perform as well as tree kernels on accuracy and always in orders of magnitude less time, and with smaller models. Since explicit features are easy to generate and use (with publicly avail- able tools) , we suggest they should always be included as baseline comparisons in tree kernel method evaluations.</p><p>Reference: <a title="acl-2013-144-reference" href="../acl2013_reference/acl-2013-Explicit_and_Implicit_Syntactic_Features_for_Text_Classification_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Among these, tree kernels (Collins and Duffy, 2001) have been perhaps the most robust and effective syntactic tool, appealing for their empirical success, but also because they do not require an answer to the difficult question of which tree features to use for a given task. [sent-2, score-1.108]
</p><p>2 We compare tree kernels to different explicit sets of tree features on five diverse tasks, and find that explicit features often perform as well as tree kernels on accuracy and always in orders of magnitude less time, and with smaller models. [sent-3, score-2.103]
</p><p>3 Since explicit features are easy to generate and use (with publicly avail-  able tools) , we suggest they should always be included as baseline comparisons in tree kernel method evaluations. [sent-4, score-0.636]
</p><p>4 1 Introduction Features computed over parse trees are useful for a range of discriminative tasks, including authorship attribution (Baayen et al. [sent-5, score-0.217]
</p><p>5 , 1996) , parse reranking (Collins and Duffy, 2002) , language modeling (Cherry and Quirk, 2008) , and native-language detection (Wong and Dras, 2011) . [sent-6, score-0.104]
</p><p>6 A major distinction among these uses of syntax is how the features are represented. [sent-7, score-0.055]
</p><p>7 The implicit approach uses tree kernels (Collins and Duffy, 2001) , which make predictions with inner products between tree pairs. [sent-8, score-0.944]
</p><p>8 These products can be computed efficiently with a dynamic program that produces weighted counts of all the shared tree fragments between a pair of trees, essentially incorporating all fragments without representing any of them explicitly. [sent-9, score-0.531]
</p><p>9 Tree kernel approaches have been applied successfully in many areas  of NLP (Collins and Duffy, 2002; Moschitti, 2004; Pighin and Moschitti, 2009) . [sent-10, score-0.152]
</p><p>10 Tree kernels were inspired in part by ideas from Data-Oriented Parsing (Scha, 1990; Bod, 1993) , which was in turn motivated by uncertainty about which fragments to include in a grammar. [sent-11, score-0.529]
</p><p>11 However, manual and automatic approaches to inducing tree fragments have recently been found to be useful in an explicit approach to text classification, which employs specific tree fragments as features in standard classifiers (Post, 2011; Wong and Dras, 2011; Swanson and Charniak, 2012) . [sent-12, score-0.978]
</p><p>12 These feature sets necessarily represent only a small subset of all possible tree patterns, leaving open the question of what further gains might be had from the unusued fragments. [sent-13, score-0.329]
</p><p>13 Somewhat surprisingly, explicit and implicit syntactic features have been explored largely independently. [sent-14, score-0.287]
</p><p>14 Here, we compare them on a range of classification tasks: (1,2) grammatical classification (is a sentence written by a human? [sent-15, score-0.204]
</p><p>15 ) , (3) question classification (what type  of answer is sought by this question? [sent-16, score-0.195]
</p><p>16 ) , and (4,5) native language prediction (what is the native language of a text’s author? [sent-17, score-0.334]
</p><p>17 Our main contribution is to show that an explicit syntactic feature set performs as well or better than tree kernels on each tested task, and in orders of magnitude less time. [sent-19, score-0.952]
</p><p>18 Since explicit features are simple to generate (with publicly available tools) and flexible to use, we recommend they be included as baseline comparisons in tree kernel method evaluations. [sent-20, score-0.636]
</p><p>19 c A2s0s1o3ci Aatsiosonc fioartio Cno fmorpu Ctoamtiopnuatalt Lioinngauli Lsitnicgsu,i psatgicess 866–872,  CFG rules Counts of depth-one contextfree grammar (CFG) productions obtained from the Berkeley parser (Petrov et al. [sent-24, score-0.043]
</p><p>20 C&J; features The parse-tree reranking  feature set of Charniak and Johnson (2005) , extracted from the Berkeley parse trees. [sent-26, score-0.159]
</p><p>21 TSG features We also parsed with a Bayesian tree substitution grammar (Post and Gildea, 2009, TSG)2 and extracted fragment counts from Viterbi derivations. [sent-27, score-0.365]
</p><p>22 We divided each dataset into training, dev, and test sets. [sent-30, score-0.033]
</p><p>23 We then trained an L2-regularized L1-loss support vector machine (-s 3) with a bias parameter of 1(-B 1) , optimizing the regularization parameter (-c) on the dev set over the range {0. [sent-31, score-0.063]
</p><p>24 For tree kernels, we used SVM-light-TK4 (Moschitti, 2004; Moschitti, 2006) with the default settings (-t 5 -D 1 -L 0 . [sent-39, score-0.253]
</p><p>25 We tuned the regularization parameter (-c) on the dev set in the same manner as described above, providing 4 GB of  memory to the kernel cache (-m 4000) . [sent-41, score-0.215]
</p><p>26 6 We used subset tree kernels, which compute the similarity between two trees by implicitly enumerating all possible fragments of the trees (in contrast with subtree kernels, where all fragments fully extend to the leaves) . [sent-42, score-0.619]
</p><p>27 1 Coarse grammatical classification Our first comparison is coarse grammatical classification, where the goal is to distinguish between human-written sentences and “pseudo-negative” sentences sampled from a trigram language model constructed from inprovement. [sent-45, score-0.313]
</p><p>28 htm 5Optimizing SVM-TK’s decay parameter (-L) did not improve test-set accuracy, but did increase training time (squaring the number of hyperparameter combinations to evaluate) , so we stuck with the default. [sent-54, score-0.033]
</p><p>29 We repeat Post’s experiments on the BLLIP dataset,7 using his exact data splits (Table 2) . [sent-64, score-0.095]
</p><p>30 To our knowledge, tree kernels have not been applied to this task. [sent-65, score-0.643]
</p><p>31 2  Fine grammatical classification  Real-world grammaticality judgments require much finer-grained distinctions than the coarse ones of the previous section (for example, marking dropped determiners or wrong verb inflections) . [sent-67, score-0.49]
</p><p>32 LDC2000T43 867  system  accuracy  CPU time  Wong & Dras60. [sent-71, score-0.051]
</p><p>33 8weeks Table 3: Fine-grained classification accuracy  (the Wong and Dras (2010) score is the highest score from the last column of their Table 3) . [sent-78, score-0.134]
</p><p>34 in into the parse trees from the positive data using GenERRate (Foster and Andersen, 2009) . [sent-82, score-0.101]
</p><p>35 Wong and Dras (2010) reported good results with parsers trained separately on the positive and negative sides of the training data and classifiers built from comparisons between the CFG productions of those parsers. [sent-84, score-0.113]
</p><p>36 We obtained their data splits (described as NoisyW WSJ in their paper)  and repeat their experiments here (Table 3) . [sent-85, score-0.095]
</p><p>37 3 Question Classification We look next at question classification (QC) . [sent-87, score-0.159]
</p><p>38 Li and Roth (2002) introduced the TREC-10 dataset,8 a set of questions paired with labels that categorize the question by the type of answer it seeks. [sent-88, score-0.112]
</p><p>39 The labels are organized hierarchically into six (coarse) top-level labels and fifty (fine) refinements. [sent-89, score-0.052]
</p><p>40 An example question from the ENTY/animal category is What was the first domesticated bird? [sent-90, score-0.076]
</p><p>41 Table 4 contains results predicting just the coarse labels. [sent-92, score-0.154]
</p><p>42 We compare to Pighin and Moschitti (2009) , and also repeat their experiments, finding a slightly better result for them. [sent-93, score-0.048]
</p><p>43 We also experimented with the refined version of the task, where we directly predict one of the fifty refined categories, and found nearly identical relative results, with the best explicit feature set (CFG) returning an accuracy of 83. [sent-111, score-0.276]
</p><p>44 2% accuracy when training on the full training set (5,500 examples)  with an SVM and bag-of-words features. [sent-115, score-0.117]
</p><p>45 4 Native language identification Native language identification (NLI) is the task of determining a text’s author’s native language. [sent-117, score-0.231]
</p><p>46 This is usually cast as a documentlevel task, since there are often not enough cues to identify native languages at smaller granularities. [sent-118, score-0.167]
</p><p>47 As such, this task presents a challenge to tree kernels, which are defined at the level of a single parse tree and have no obvious document-level extension. [sent-119, score-0.563]
</p><p>48 Table 5 therefore presents three evaluations: (a) sentencelevel accuracy, and document-level accuracy from (b) sentence-level voting and (c) direct, whole-document classification. [sent-120, score-0.083]
</p><p>49 In order to mitigate topic bias10 and other problems that have been reported with 9Pighin and Moschitti (2009) did not report results on this version of the task. [sent-122, score-0.034]
</p><p>50 , 2012) ,11 we preprocessed each dataset into two signaturestylized versions by replacing all words not in a stopword list. [sent-127, score-0.075]
</p><p>51 12 The first version replaces nonstopwords with word classes computed from surface-form signatures,13 and the second with POS tags. [sent-128, score-0.034]
</p><p>52 14 N-gram features are then taken from both stylized versions of the corpus. [sent-129, score-0.055]
</p><p>53 Restricting the feature representation to be topic-independent is standard-practice in stylometric tasks like authorship attribution, gender identification, and native-language identification (Mosteller and Wallace, 1984; Koppel et al. [sent-130, score-0.196]
</p><p>54 2  The first dataset is a seven-language subset of the International Corpus of Learner English, Version 2 (ICLE) (Granger et al. [sent-135, score-0.033]
</p><p>55 7 million words of English documents written by people with sixteen dif-  ferent native languages. [sent-137, score-0.167]
</p><p>56 Table 1 contains scores, including one reported by Wong and Dras (2011) , who used the CFG and C&J; features, and whose data splits we mirror. [sent-138, score-0.047]
</p><p>57 2 ACL Anthology Network We also experimented with native language classification on scientific documents using a version of the ACL Anthology Network (Radev et al. [sent-141, score-0.284]
</p><p>58 , 2009, AAN) annotated for experiments in stylemetric tasks, including a native/non-native author judgment (Bergsma et al. [sent-142, score-0.035]
</p><p>59 For NLI, we further annotated this dataset in a semi-automatic fashion for the five most-common native languages of ACL authors in our training era: English, Japanese, German, Chinese, and French. [sent-144, score-0.233]
</p><p>60 12The stopword list contains the set of 524 SMARTsystem stopwords used by Tomokiyo and Jones (2001) , plus punctuation and Latin abbreviations. [sent-147, score-0.042]
</p><p>61 test accuracy for coarse grammaticality, plotting test scores from models trained on 100, 300, 1k, 3k, 10k, 30k, and 100k instances. [sent-158, score-0.205]
</p><p>62 4  Discussion  Syntactic features improve upon the n-gram baseline for all tasks except whole-document classification for ICLE. [sent-159, score-0.173]
</p><p>63 Tree kernels are often among the best, but always trail (by orders of magnitude) when runtime is considered. [sent-160, score-0.482]
</p><p>64 Constructing the multi-class SVM-TK models for the NLI tasks in particular was computationally burdensome, requiring cpu-months of time. [sent-161, score-0.035]
</p><p>65 The C&J; features are similarly often the best, but incur a runtime cost due to the large models. [sent-162, score-0.086]
</p><p>66 CFG and TSG features balance performance, model size, and runtime. [sent-163, score-0.055]
</p><p>67 1 Training time versus accuracy Tree kernel training is quadratic in the size of the training data, and its empirical slowness is known. [sent-166, score-0.269]
</p><p>68 We compared models trained on the first 100, 300, 1k, 3k, 10k, 30k, and  100k data points of the coarse grammaticality dataset, split evenly between positive and negative examples (Figure 1) . [sent-168, score-0.369]
</p><p>69 SVM-TK improves over the TSG and CFG models in the limit, but at an extraordinary cost in training time: 100k training examples is already pushing the bounds of practicality for tree kernel learning, and generating curve’s next point would require several months of time. [sent-169, score-0.471]
</p><p>70 Approximate kernel methods designed to scale to large datasets address this (Severyn 869  and Moschitti, 2010) . [sent-172, score-0.152]
</p><p>71 We investigated the uSVM-TK toolkit,17 which enables tuning the tradeoff between training time and accuracy. [sent-173, score-0.033]
</p><p>72 While faster than SVM-TK, its performance was never better than explicit methods along both dimensions (time and accuracy) . [sent-174, score-0.139]
</p><p>73 2 Overfitting Overfitting is also a problem for kernel methods. [sent-176, score-0.152]
</p><p>74 The best models often had a huge number of support vectors, achieving near-perfect accuracy on the training set but making many errors on the dev. [sent-177, score-0.084]
</p><p>75 On the ICLE task, close to 75% of all the training examples were used as support vectors. [sent-179, score-0.033]
</p><p>76 We found only half as many support vectors used for the explicit representations, implying less error (Vapnik, 1998) , and saw much lower variance between training and testing performance. [sent-180, score-0.172]
</p><p>77 Our findings support the observations of Cumby and Roth (2003) , who point out that kernels introduce a large number of irrelevant features that may be especially harmful in small-data settings, and that, when possible, it is often better to have a set of explicit, relevant features. [sent-183, score-0.445]
</p><p>78 In other words, it is better to have the right features than all of them. [sent-184, score-0.055]
</p><p>79 Tree kernels provide a robust, efficiently-computable  measure of comparison, but they also skirt the difficult question, Which fragments? [sent-185, score-0.39]
</p><p>80 Table 6) presents an intuitive list from the coarse grammaticality task: phenomena such as balanced parenthetical phrases and quotations are associated with grammaticality, while small, flat, abstract rules indicate samples from the ngram model. [sent-188, score-0.369]
</p><p>81 The immediate interpretability of the explicit formalisms is another advantage, although recent work has shown that weights on the implicit features can also be obtained after a kind of linearization of the tree kernel (Pighin and Moschitti, 2009) . [sent-190, score-0.647]
</p><p>82 Ultimately, which features matter is taskdependent, and skirting the question is advantageous in many settings. [sent-191, score-0.175]
</p><p>83 But it is also encouraging that methods for selecting fragments and other tree features work so well, 17disi  . [sent-192, score-0.447]
</p><p>84 )) (NP DT JJ NNS) Table 6: The highest- and lowest-weighted TSG features (coarse grammaticality) . [sent-199, score-0.055]
</p><p>85 yielding quick, light-weight models that contrast with the heavy machinery of tree kernels. [sent-200, score-0.253]
</p><p>86 5  Conclusion  Tree kernels provide a robust measure of comparison between trees, effectively making use of all fragments. [sent-201, score-0.39]
</p><p>87 In addition to their flexibility and interpetability, explicit syntactic features of-  ten outperformed tree kernels in accuracy, and even where they did not, the cost was multiple orders of magnitude increase in both training and testing time. [sent-203, score-1.04]
</p><p>88 These results were consistent across a range of task types, dataset sizes, and classification arities (binary and multiclass) . [sent-204, score-0.116]
</p><p>89 We explored a range of data settings, but there are many others where tree kernels have been proven useful, such as parse tree reranking (Collins and Duffy, 2002; Shen and Joshi, 2003) , sentence subjectivity (Suzuki et al. [sent-206, score-1.0]
</p><p>90 There are also tree kernel variations such as dependency tree kernels (Culotta and Sorensen, 2004) and shallow semantic tree kernels (Moschitti et al. [sent-209, score-1.725]
</p><p>91 Outside the cave of shadows: Using syntactic annotation to enhance authorship attribution. [sent-214, score-0.119]
</p><p>92 New ranking algorithms for parsing and tagging: kernels over discrete structures, and the voted perceptron. [sent-244, score-0.39]
</p><p>93 Exploit-  ing syntactic and shallow semantic kernels for question answer classification. [sent-286, score-0.581]
</p><p>94 A study on convolution kernels for shallow semantic parsing. [sent-291, score-0.502]
</p><p>95 An SVMbased voting algorithm with application to parse reranking. [sent-358, score-0.089]
</p><p>96 Convolution kernels with feature selection for natural language processing tasks. [sent-363, score-0.39]
</p><p>97 Native tongues, lost and found: Resources and empirical evaluations in native language identification. [sent-373, score-0.167]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('kernels', 0.39), ('tree', 0.253), ('grammaticality', 0.215), ('moschitti', 0.204), ('native', 0.167), ('cfg', 0.159), ('tsg', 0.157), ('coarse', 0.154), ('kernel', 0.152), ('pighin', 0.143), ('fragments', 0.139), ('dras', 0.139), ('icle', 0.139), ('explicit', 0.139), ('wong', 0.131), ('duffy', 0.119), ('cl', 0.117), ('np', 0.092), ('tomokiyo', 0.09), ('nli', 0.09), ('anthology', 0.083), ('crftagger', 0.083), ('classification', 0.083), ('convolution', 0.078), ('collins', 0.077), ('post', 0.076), ('question', 0.076), ('authorship', 0.074), ('alessandro', 0.071), ('generrate', 0.068), ('jojo', 0.068), ('mosteller', 0.068), ('okanohara', 0.068), ('systemaccuracycpu', 0.068), ('culotta', 0.066), ('magnitude', 0.064), ('dev', 0.063), ('matt', 0.062), ('orders', 0.061), ('swanson', 0.06), ('prn', 0.06), ('severyn', 0.06), ('parse', 0.057), ('substitution', 0.057), ('cherry', 0.056), ('stylometric', 0.055), ('features', 0.055), ('bllip', 0.052), ('fifty', 0.052), ('granger', 0.052), ('koppel', 0.052), ('accuracy', 0.051), ('sorensen', 0.05), ('baayen', 0.05), ('pp', 0.049), ('fine', 0.048), ('repeat', 0.048), ('implicit', 0.048), ('vp', 0.048), ('tetreault', 0.048), ('reranking', 0.047), ('splits', 0.047), ('nigel', 0.046), ('syntactic', 0.045), ('charniak', 0.045), ('advantageous', 0.044), ('trees', 0.044), ('hour', 0.043), ('productions', 0.043), ('japanese', 0.042), ('attribution', 0.042), ('stopword', 0.042), ('dt', 0.041), ('shane', 0.041), ('literary', 0.041), ('bergsma', 0.039), ('minutes', 0.039), ('usa', 0.038), ('grammatical', 0.038), ('comparisons', 0.037), ('acl', 0.036), ('answer', 0.036), ('tasks', 0.035), ('wsj', 0.035), ('suzuki', 0.035), ('author', 0.035), ('shallow', 0.034), ('version', 0.034), ('training', 0.033), ('radev', 0.033), ('dataset', 0.033), ('identification', 0.032), ('fan', 0.032), ('voting', 0.032), ('overfitting', 0.032), ('runtime', 0.031), ('foster', 0.031), ('pronoun', 0.031), ('jones', 0.031), ('network', 0.03)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="144-tfidf-1" href="./acl-2013-Explicit_and_Implicit_Syntactic_Features_for_Text_Classification.html">144 acl-2013-Explicit and Implicit Syntactic Features for Text Classification</a></p>
<p>Author: Matt Post ; Shane Bergsma</p><p>Abstract: Syntactic features are useful for many text classification tasks. Among these, tree kernels (Collins and Duffy, 2001) have been perhaps the most robust and effective syntactic tool, appealing for their empirical success, but also because they do not require an answer to the difficult question of which tree features to use for a given task. We compare tree kernels to different explicit sets of tree features on five diverse tasks, and find that explicit features often perform as well as tree kernels on accuracy and always in orders of magnitude less time, and with smaller models. Since explicit features are easy to generate and use (with publicly avail- able tools) , we suggest they should always be included as baseline comparisons in tree kernel method evaluations.</p><p>2 0.29511607 <a title="144-tfidf-2" href="./acl-2013-Embedding_Semantic_Similarity_in_Tree_Kernels_for_Domain_Adaptation_of_Relation_Extraction.html">134 acl-2013-Embedding Semantic Similarity in Tree Kernels for Domain Adaptation of Relation Extraction</a></p>
<p>Author: Barbara Plank ; Alessandro Moschitti</p><p>Abstract: Relation Extraction (RE) is the task of extracting semantic relationships between entities in text. Recent studies on relation extraction are mostly supervised. The clear drawback of supervised methods is the need of training data: labeled data is expensive to obtain, and there is often a mismatch between the training data and the data the system will be applied to. This is the problem of domain adaptation. In this paper, we propose to combine (i) term generalization approaches such as word clustering and latent semantic analysis (LSA) and (ii) structured kernels to improve the adaptability of relation extractors to new text genres/domains. The empirical evaluation on ACE 2005 domains shows that a suitable combination of syntax and lexical generalization is very promising for domain adaptation.</p><p>3 0.24716631 <a title="144-tfidf-3" href="./acl-2013-Learning_Semantic_Textual_Similarity_with_Structural_Representations.html">222 acl-2013-Learning Semantic Textual Similarity with Structural Representations</a></p>
<p>Author: Aliaksei Severyn ; Massimo Nicosia ; Alessandro Moschitti</p><p>Abstract: Measuring semantic textual similarity (STS) is at the cornerstone of many NLP applications. Different from the majority of approaches, where a large number of pairwise similarity features are used to represent a text pair, our model features the following: (i) it directly encodes input texts into relational syntactic structures; (ii) relies on tree kernels to handle feature engineering automatically; (iii) combines both structural and feature vector representations in a single scoring model, i.e., in Support Vector Regression (SVR); and (iv) delivers significant improvement over the best STS systems.</p><p>4 0.16750666 <a title="144-tfidf-4" href="./acl-2013-Transfer_Learning_for_Constituency-Based_Grammars.html">357 acl-2013-Transfer Learning for Constituency-Based Grammars</a></p>
<p>Author: Yuan Zhang ; Regina Barzilay ; Amir Globerson</p><p>Abstract: In this paper, we consider the problem of cross-formalism transfer in parsing. We are interested in parsing constituencybased grammars such as HPSG and CCG using a small amount of data specific for the target formalism, and a large quantity of coarse CFG annotations from the Penn Treebank. While all of the target formalisms share a similar basic syntactic structure with Penn Treebank CFG, they also encode additional constraints and semantic features. To handle this apparent discrepancy, we design a probabilistic model that jointly generates CFG and target formalism parses. The model includes features of both parses, allowing trans- fer between the formalisms, while preserving parsing efficiency. We evaluate our approach on three constituency-based grammars CCG, HPSG, and LFG, augmented with the Penn Treebank-1. Our experiments show that across all three formalisms, the target parsers significantly benefit from the coarse annotations.1 —</p><p>5 0.15072316 <a title="144-tfidf-5" href="./acl-2013-Nonparametric_Bayesian_Inference_and_Efficient_Parsing_for_Tree-adjoining_Grammars.html">261 acl-2013-Nonparametric Bayesian Inference and Efficient Parsing for Tree-adjoining Grammars</a></p>
<p>Author: Elif Yamangil ; Stuart M. Shieber</p><p>Abstract: In the line of research extending statistical parsing to more expressive grammar formalisms, we demonstrate for the first time the use of tree-adjoining grammars (TAG). We present a Bayesian nonparametric model for estimating a probabilistic TAG from a parsed corpus, along with novel block sampling methods and approximation transformations for TAG that allow efficient parsing. Our work shows performance improvements on the Penn Treebank and finds more compact yet linguistically rich representations of the data, but more importantly provides techniques in grammar transformation and statistical inference that make practical the use of these more expressive systems, thereby enabling further experimentation along these lines.</p><p>6 0.14210929 <a title="144-tfidf-6" href="./acl-2013-A_Context_Free_TAG_Variant.html">4 acl-2013-A Context Free TAG Variant</a></p>
<p>7 0.14119294 <a title="144-tfidf-7" href="./acl-2013-Modelling_Annotator_Bias_with_Multi-task_Gaussian_Processes%3A_An_Application_to_Machine_Translation_Quality_Estimation.html">248 acl-2013-Modelling Annotator Bias with Multi-task Gaussian Processes: An Application to Machine Translation Quality Estimation</a></p>
<p>8 0.12293123 <a title="144-tfidf-8" href="./acl-2013-Question_Classification_Transfer.html">292 acl-2013-Question Classification Transfer</a></p>
<p>9 0.12201045 <a title="144-tfidf-9" href="./acl-2013-Recognizing_Identical_Events_with_Graph_Kernels.html">296 acl-2013-Recognizing Identical Events with Graph Kernels</a></p>
<p>10 0.11817048 <a title="144-tfidf-10" href="./acl-2013-Reconstructing_an_Indo-European_Family_Tree_from_Non-native_English_Texts.html">299 acl-2013-Reconstructing an Indo-European Family Tree from Non-native English Texts</a></p>
<p>11 0.11410574 <a title="144-tfidf-11" href="./acl-2013-Arguments_and_Modifiers_from_the_Learner%27s_Perspective.html">57 acl-2013-Arguments and Modifiers from the Learner's Perspective</a></p>
<p>12 0.099913739 <a title="144-tfidf-12" href="./acl-2013-Semantic_Frames_to_Predict_Stock_Price_Movement.html">310 acl-2013-Semantic Frames to Predict Stock Price Movement</a></p>
<p>13 0.096935377 <a title="144-tfidf-13" href="./acl-2013-Question_Answering_Using_Enhanced_Lexical_Semantic_Models.html">291 acl-2013-Question Answering Using Enhanced Lexical Semantic Models</a></p>
<p>14 0.087122872 <a title="144-tfidf-14" href="./acl-2013-The_Effect_of_Higher-Order_Dependency_Features_in_Discriminative_Phrase-Structure_Parsing.html">343 acl-2013-The Effect of Higher-Order Dependency Features in Discriminative Phrase-Structure Parsing</a></p>
<p>15 0.08585307 <a title="144-tfidf-15" href="./acl-2013-Adapting_Discriminative_Reranking_to_Grounded_Language_Learning.html">36 acl-2013-Adapting Discriminative Reranking to Grounded Language Learning</a></p>
<p>16 0.085342489 <a title="144-tfidf-16" href="./acl-2013-Parsing_with_Compositional_Vector_Grammars.html">275 acl-2013-Parsing with Compositional Vector Grammars</a></p>
<p>17 0.084688872 <a title="144-tfidf-17" href="./acl-2013-Semantic_Roles_for_String_to_Tree_Machine_Translation.html">314 acl-2013-Semantic Roles for String to Tree Machine Translation</a></p>
<p>18 0.078721114 <a title="144-tfidf-18" href="./acl-2013-Chinese_Parsing_Exploiting_Characters.html">80 acl-2013-Chinese Parsing Exploiting Characters</a></p>
<p>19 0.078666002 <a title="144-tfidf-19" href="./acl-2013-Machine_Translation_Detection_from_Monolingual_Web-Text.html">235 acl-2013-Machine Translation Detection from Monolingual Web-Text</a></p>
<p>20 0.077758186 <a title="144-tfidf-20" href="./acl-2013-An_Empirical_Examination_of_Challenges_in_Chinese_Parsing.html">44 acl-2013-An Empirical Examination of Challenges in Chinese Parsing</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.231), (1, -0.024), (2, -0.086), (3, -0.039), (4, -0.096), (5, 0.053), (6, 0.071), (7, -0.068), (8, 0.05), (9, 0.013), (10, 0.074), (11, 0.046), (12, 0.025), (13, -0.011), (14, -0.108), (15, -0.026), (16, 0.033), (17, 0.151), (18, -0.114), (19, 0.082), (20, 0.215), (21, 0.068), (22, 0.16), (23, -0.03), (24, -0.104), (25, -0.036), (26, 0.016), (27, -0.121), (28, -0.008), (29, 0.01), (30, -0.167), (31, 0.158), (32, 0.039), (33, -0.008), (34, -0.165), (35, 0.078), (36, 0.035), (37, -0.016), (38, 0.097), (39, 0.088), (40, -0.081), (41, 0.169), (42, 0.014), (43, -0.008), (44, 0.032), (45, -0.079), (46, 0.02), (47, -0.074), (48, 0.007), (49, 0.006)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95022428 <a title="144-lsi-1" href="./acl-2013-Explicit_and_Implicit_Syntactic_Features_for_Text_Classification.html">144 acl-2013-Explicit and Implicit Syntactic Features for Text Classification</a></p>
<p>Author: Matt Post ; Shane Bergsma</p><p>Abstract: Syntactic features are useful for many text classification tasks. Among these, tree kernels (Collins and Duffy, 2001) have been perhaps the most robust and effective syntactic tool, appealing for their empirical success, but also because they do not require an answer to the difficult question of which tree features to use for a given task. We compare tree kernels to different explicit sets of tree features on five diverse tasks, and find that explicit features often perform as well as tree kernels on accuracy and always in orders of magnitude less time, and with smaller models. Since explicit features are easy to generate and use (with publicly avail- able tools) , we suggest they should always be included as baseline comparisons in tree kernel method evaluations.</p><p>2 0.77499598 <a title="144-lsi-2" href="./acl-2013-Learning_Semantic_Textual_Similarity_with_Structural_Representations.html">222 acl-2013-Learning Semantic Textual Similarity with Structural Representations</a></p>
<p>Author: Aliaksei Severyn ; Massimo Nicosia ; Alessandro Moschitti</p><p>Abstract: Measuring semantic textual similarity (STS) is at the cornerstone of many NLP applications. Different from the majority of approaches, where a large number of pairwise similarity features are used to represent a text pair, our model features the following: (i) it directly encodes input texts into relational syntactic structures; (ii) relies on tree kernels to handle feature engineering automatically; (iii) combines both structural and feature vector representations in a single scoring model, i.e., in Support Vector Regression (SVR); and (iv) delivers significant improvement over the best STS systems.</p><p>3 0.74708074 <a title="144-lsi-3" href="./acl-2013-Embedding_Semantic_Similarity_in_Tree_Kernels_for_Domain_Adaptation_of_Relation_Extraction.html">134 acl-2013-Embedding Semantic Similarity in Tree Kernels for Domain Adaptation of Relation Extraction</a></p>
<p>Author: Barbara Plank ; Alessandro Moschitti</p><p>Abstract: Relation Extraction (RE) is the task of extracting semantic relationships between entities in text. Recent studies on relation extraction are mostly supervised. The clear drawback of supervised methods is the need of training data: labeled data is expensive to obtain, and there is often a mismatch between the training data and the data the system will be applied to. This is the problem of domain adaptation. In this paper, we propose to combine (i) term generalization approaches such as word clustering and latent semantic analysis (LSA) and (ii) structured kernels to improve the adaptability of relation extractors to new text genres/domains. The empirical evaluation on ACE 2005 domains shows that a suitable combination of syntax and lexical generalization is very promising for domain adaptation.</p><p>4 0.55689287 <a title="144-lsi-4" href="./acl-2013-A_Context_Free_TAG_Variant.html">4 acl-2013-A Context Free TAG Variant</a></p>
<p>Author: Ben Swanson ; Elif Yamangil ; Eugene Charniak ; Stuart Shieber</p><p>Abstract: We propose a new variant of TreeAdjoining Grammar that allows adjunction of full wrapping trees but still bears only context-free expressivity. We provide a transformation to context-free form, and a further reduction in probabilistic model size through factorization and pooling of parameters. This collapsed context-free form is used to implement efficient gram- mar estimation and parsing algorithms. We perform parsing experiments the Penn Treebank and draw comparisons to TreeSubstitution Grammars and between different variations in probabilistic model design. Examination of the most probable derivations reveals examples of the linguistically relevant structure that our variant makes possible.</p><p>5 0.54453665 <a title="144-lsi-5" href="./acl-2013-Nonparametric_Bayesian_Inference_and_Efficient_Parsing_for_Tree-adjoining_Grammars.html">261 acl-2013-Nonparametric Bayesian Inference and Efficient Parsing for Tree-adjoining Grammars</a></p>
<p>Author: Elif Yamangil ; Stuart M. Shieber</p><p>Abstract: In the line of research extending statistical parsing to more expressive grammar formalisms, we demonstrate for the first time the use of tree-adjoining grammars (TAG). We present a Bayesian nonparametric model for estimating a probabilistic TAG from a parsed corpus, along with novel block sampling methods and approximation transformations for TAG that allow efficient parsing. Our work shows performance improvements on the Penn Treebank and finds more compact yet linguistically rich representations of the data, but more importantly provides techniques in grammar transformation and statistical inference that make practical the use of these more expressive systems, thereby enabling further experimentation along these lines.</p><p>6 0.53568453 <a title="144-lsi-6" href="./acl-2013-Reconstructing_an_Indo-European_Family_Tree_from_Non-native_English_Texts.html">299 acl-2013-Reconstructing an Indo-European Family Tree from Non-native English Texts</a></p>
<p>7 0.51325911 <a title="144-lsi-7" href="./acl-2013-Arguments_and_Modifiers_from_the_Learner%27s_Perspective.html">57 acl-2013-Arguments and Modifiers from the Learner's Perspective</a></p>
<p>8 0.50034106 <a title="144-lsi-8" href="./acl-2013-Transfer_Learning_for_Constituency-Based_Grammars.html">357 acl-2013-Transfer Learning for Constituency-Based Grammars</a></p>
<p>9 0.49853516 <a title="144-lsi-9" href="./acl-2013-Semantic_Frames_to_Predict_Stock_Price_Movement.html">310 acl-2013-Semantic Frames to Predict Stock Price Movement</a></p>
<p>10 0.49525693 <a title="144-lsi-10" href="./acl-2013-General_binarization_for_parsing_and_translation.html">165 acl-2013-General binarization for parsing and translation</a></p>
<p>11 0.49377218 <a title="144-lsi-11" href="./acl-2013-Modelling_Annotator_Bias_with_Multi-task_Gaussian_Processes%3A_An_Application_to_Machine_Translation_Quality_Estimation.html">248 acl-2013-Modelling Annotator Bias with Multi-task Gaussian Processes: An Application to Machine Translation Quality Estimation</a></p>
<p>12 0.47881675 <a title="144-lsi-12" href="./acl-2013-The_Impact_of_Topic_Bias_on_Quality_Flaw_Prediction_in_Wikipedia.html">346 acl-2013-The Impact of Topic Bias on Quality Flaw Prediction in Wikipedia</a></p>
<p>13 0.45463043 <a title="144-lsi-13" href="./acl-2013-From_Natural_Language_Specifications_to_Program_Input_Parsers.html">163 acl-2013-From Natural Language Specifications to Program Input Parsers</a></p>
<p>14 0.4536294 <a title="144-lsi-14" href="./acl-2013-Adapting_Discriminative_Reranking_to_Grounded_Language_Learning.html">36 acl-2013-Adapting Discriminative Reranking to Grounded Language Learning</a></p>
<p>15 0.44294161 <a title="144-lsi-15" href="./acl-2013-A_Novel_Classifier_Based_on_Quantum_Computation.html">14 acl-2013-A Novel Classifier Based on Quantum Computation</a></p>
<p>16 0.44100678 <a title="144-lsi-16" href="./acl-2013-Joint_Apposition_Extraction_with_Syntactic_and_Semantic_Constraints.html">205 acl-2013-Joint Apposition Extraction with Syntactic and Semantic Constraints</a></p>
<p>17 0.4397392 <a title="144-lsi-17" href="./acl-2013-Dependency_Parser_Adaptation_with_Subtrees_from_Auto-Parsed_Target_Domain_Data.html">112 acl-2013-Dependency Parser Adaptation with Subtrees from Auto-Parsed Target Domain Data</a></p>
<p>18 0.41216755 <a title="144-lsi-18" href="./acl-2013-Using_Conceptual_Class_Attributes_to_Characterize_Social_Media_Users.html">373 acl-2013-Using Conceptual Class Attributes to Characterize Social Media Users</a></p>
<p>19 0.40322584 <a title="144-lsi-19" href="./acl-2013-Parsing_with_Compositional_Vector_Grammars.html">275 acl-2013-Parsing with Compositional Vector Grammars</a></p>
<p>20 0.40254551 <a title="144-lsi-20" href="./acl-2013-Enlisting_the_Ghost%3A_Modeling_Empty_Categories_for_Machine_Translation.html">137 acl-2013-Enlisting the Ghost: Modeling Empty Categories for Machine Translation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.047), (2, 0.012), (6, 0.05), (11, 0.053), (14, 0.033), (15, 0.017), (24, 0.065), (25, 0.184), (26, 0.078), (28, 0.017), (35, 0.077), (42, 0.054), (48, 0.045), (70, 0.071), (88, 0.053), (90, 0.019), (95, 0.056)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.84030282 <a title="144-lda-1" href="./acl-2013-Explicit_and_Implicit_Syntactic_Features_for_Text_Classification.html">144 acl-2013-Explicit and Implicit Syntactic Features for Text Classification</a></p>
<p>Author: Matt Post ; Shane Bergsma</p><p>Abstract: Syntactic features are useful for many text classification tasks. Among these, tree kernels (Collins and Duffy, 2001) have been perhaps the most robust and effective syntactic tool, appealing for their empirical success, but also because they do not require an answer to the difficult question of which tree features to use for a given task. We compare tree kernels to different explicit sets of tree features on five diverse tasks, and find that explicit features often perform as well as tree kernels on accuracy and always in orders of magnitude less time, and with smaller models. Since explicit features are easy to generate and use (with publicly avail- able tools) , we suggest they should always be included as baseline comparisons in tree kernel method evaluations.</p><p>2 0.81334656 <a title="144-lda-2" href="./acl-2013-Crawling_microblogging_services_to_gather_language-classified_URLs._Workflow_and_case_study.html">95 acl-2013-Crawling microblogging services to gather language-classified URLs. Workflow and case study</a></p>
<p>Author: Adrien Barbaresi</p><p>Abstract: We present a way to extract links from messages published on microblogging platforms and we classify them according to the language and possible relevance of their target in order to build a text corpus. Three platforms are taken into consideration: FriendFeed, identi.ca and Reddit, as they account for a relative diversity of user profiles and more importantly user languages. In order to explore them, we introduce a traversal algorithm based on user pages. As we target lesser-known languages, we try to focus on non-English posts by filtering out English text. Using mature open-source software from the NLP research field, a spell checker (as- pell) and a language identification system (langid .py), our case study and our benchmarks give an insight into the linguistic structure of the considered services.</p><p>3 0.765553 <a title="144-lda-3" href="./acl-2013-Why-Question_Answering_using_Intra-_and_Inter-Sentential_Causal_Relations.html">387 acl-2013-Why-Question Answering using Intra- and Inter-Sentential Causal Relations</a></p>
<p>Author: Jong-Hoon Oh ; Kentaro Torisawa ; Chikara Hashimoto ; Motoki Sano ; Stijn De Saeger ; Kiyonori Ohtake</p><p>Abstract: In this paper, we explore the utility of intra- and inter-sentential causal relations between terms or clauses as evidence for answering why-questions. To the best of our knowledge, this is the first work that uses both intra- and inter-sentential causal relations for why-QA. We also propose a method for assessing the appropriateness of causal relations as answers to a given question using the semantic orientation of excitation proposed by Hashimoto et al. (2012). By applying these ideas to Japanese why-QA, we improved precision by 4.4% against all the questions in our test set over the current state-of-theart system for Japanese why-QA. In addi- tion, unlike the state-of-the-art system, our system could achieve very high precision (83.2%) for 25% of all the questions in the test set by restricting its output to the confident answers only.</p><p>4 0.73223907 <a title="144-lda-4" href="./acl-2013-Can_Markov_Models_Over_Minimal_Translation_Units_Help_Phrase-Based_SMT%3F.html">77 acl-2013-Can Markov Models Over Minimal Translation Units Help Phrase-Based SMT?</a></p>
<p>Author: Nadir Durrani ; Alexander Fraser ; Helmut Schmid ; Hieu Hoang ; Philipp Koehn</p><p>Abstract: The phrase-based and N-gram-based SMT frameworks complement each other. While the former is better able to memorize, the latter provides a more principled model that captures dependencies across phrasal boundaries. Some work has been done to combine insights from these two frameworks. A recent successful attempt showed the advantage of using phrasebased search on top of an N-gram-based model. We probe this question in the reverse direction by investigating whether integrating N-gram-based translation and reordering models into a phrase-based decoder helps overcome the problematic phrasal independence assumption. A large scale evaluation over 8 language pairs shows that performance does significantly improve.</p><p>5 0.70041859 <a title="144-lda-5" href="./acl-2013-Sentiment_Relevance.html">318 acl-2013-Sentiment Relevance</a></p>
<p>Author: Christian Scheible ; Hinrich Schutze</p><p>Abstract: A number of different notions, including subjectivity, have been proposed for distinguishing parts of documents that convey sentiment from those that do not. We propose a new concept, sentiment relevance, to make this distinction and argue that it better reflects the requirements of sentiment analysis systems. We demonstrate experimentally that sentiment relevance and subjectivity are related, but different. Since no large amount of labeled training data for our new notion of sentiment relevance is available, we investigate two semi-supervised methods for creating sentiment relevance classifiers: a distant supervision approach that leverages structured information about the domain of the reviews; and transfer learning on feature representations based on lexical taxonomies that enables knowledge transfer. We show that both methods learn sentiment relevance classifiers that perform well.</p><p>6 0.6884551 <a title="144-lda-6" href="./acl-2013-A_Bayesian_Model_for_Joint_Unsupervised_Induction_of_Sentiment%2C_Aspect_and_Discourse_Representations.html">2 acl-2013-A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations</a></p>
<p>7 0.6839928 <a title="144-lda-7" href="./acl-2013-Unsupervised_Consonant-Vowel_Prediction_over_Hundreds_of_Languages.html">369 acl-2013-Unsupervised Consonant-Vowel Prediction over Hundreds of Languages</a></p>
<p>8 0.68191159 <a title="144-lda-8" href="./acl-2013-Parsing_with_Compositional_Vector_Grammars.html">275 acl-2013-Parsing with Compositional Vector Grammars</a></p>
<p>9 0.67869002 <a title="144-lda-9" href="./acl-2013-Chinese_Parsing_Exploiting_Characters.html">80 acl-2013-Chinese Parsing Exploiting Characters</a></p>
<p>10 0.67781901 <a title="144-lda-10" href="./acl-2013-Multigraph_Clustering_for_Unsupervised_Coreference_Resolution.html">252 acl-2013-Multigraph Clustering for Unsupervised Coreference Resolution</a></p>
<p>11 0.67737389 <a title="144-lda-11" href="./acl-2013-Generating_Synthetic_Comparable_Questions_for_News_Articles.html">169 acl-2013-Generating Synthetic Comparable Questions for News Articles</a></p>
<p>12 0.67722684 <a title="144-lda-12" href="./acl-2013-Co-regularizing_character-based_and_word-based_models_for_semi-supervised_Chinese_word_segmentation.html">82 acl-2013-Co-regularizing character-based and word-based models for semi-supervised Chinese word segmentation</a></p>
<p>13 0.67661631 <a title="144-lda-13" href="./acl-2013-Fast_and_Accurate_Shift-Reduce_Constituent_Parsing.html">155 acl-2013-Fast and Accurate Shift-Reduce Constituent Parsing</a></p>
<p>14 0.67476732 <a title="144-lda-14" href="./acl-2013-Using_Conceptual_Class_Attributes_to_Characterize_Social_Media_Users.html">373 acl-2013-Using Conceptual Class Attributes to Characterize Social Media Users</a></p>
<p>15 0.67381632 <a title="144-lda-15" href="./acl-2013-Learning_to_Order_Natural_Language_Texts.html">225 acl-2013-Learning to Order Natural Language Texts</a></p>
<p>16 0.67357594 <a title="144-lda-16" href="./acl-2013-Learning_to_Extract_International_Relations_from_Political_Context.html">224 acl-2013-Learning to Extract International Relations from Political Context</a></p>
<p>17 0.67277545 <a title="144-lda-17" href="./acl-2013-Bilingually-Guided_Monolingual_Dependency_Grammar_Induction.html">70 acl-2013-Bilingually-Guided Monolingual Dependency Grammar Induction</a></p>
<p>18 0.67262566 <a title="144-lda-18" href="./acl-2013-Collective_Annotation_of_Linguistic_Resources%3A_Basic_Principles_and_a_Formal_Model.html">83 acl-2013-Collective Annotation of Linguistic Resources: Basic Principles and a Formal Model</a></p>
<p>19 0.66982442 <a title="144-lda-19" href="./acl-2013-Summarization_Through_Submodularity_and_Dispersion.html">333 acl-2013-Summarization Through Submodularity and Dispersion</a></p>
<p>20 0.66973335 <a title="144-lda-20" href="./acl-2013-A_Context_Free_TAG_Variant.html">4 acl-2013-A Context Free TAG Variant</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
