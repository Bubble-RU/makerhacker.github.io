<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>296 acl-2013-Recognizing Identical Events with Graph Kernels</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-296" href="#">acl2013-296</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>296 acl-2013-Recognizing Identical Events with Graph Kernels</h1>
<br/><p>Source: <a title="acl-2013-296-pdf" href="http://aclweb.org/anthology//P/P13/P13-2139.pdf">pdf</a></p><p>Author: Goran Glavas ; Jan Snajder</p><p>Abstract: Identifying news stories that discuss the same real-world events is important for news tracking and retrieval. Most existing approaches rely on the traditional vector space model. We propose an approach for recognizing identical real-world events based on a structured, event-oriented document representation. We structure documents as graphs of event mentions and use graph kernels to measure the similarity between document pairs. Our experiments indicate that the proposed graph-based approach can outperform the traditional vector space model, and is especially suitable for distinguishing between topically similar, yet non-identical events.</p><p>Reference: <a title="acl-2013-296-reference" href="../acl2013_reference/acl-2013-Recognizing_Identical_Events_with_Graph_Kernels_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 glavas, Abstract Identifying news stories that discuss the same real-world events is important for news tracking and retrieval. [sent-2, score-0.673]
</p><p>2 We propose an approach for recognizing identical real-world events based on a structured, event-oriented document representation. [sent-4, score-0.292]
</p><p>3 We structure documents as graphs of event mentions and use graph kernels to measure the similarity between document pairs. [sent-5, score-1.198]
</p><p>4 Our experiments indicate that the proposed graph-based approach can outperform the traditional vector space model, and is especially suitable  for distinguishing between topically similar, yet non-identical events. [sent-6, score-0.215]
</p><p>5 Topic detection and tracking (TDT) aims to detect stories that discuss identical or directly related events, and track these stories as they evolve over time (Allan, 2002). [sent-8, score-0.696]
</p><p>6 Being able to identify the stories that describe the same real-world event is essential for TDT, and event-based information retrieval in general. [sent-9, score-0.678]
</p><p>7 In TDT, an event is defined as something happening in a certain place at a certain time (Yang et al. [sent-10, score-0.412]
</p><p>8 , 1999), while a topic is defined as a set of news stories related by some seminal real-world event (Allan, 2002). [sent-11, score-0.786]
</p><p>9 To identify news stories on the same topic, most TDT approaches rely on traditional vector space models (Salton et al. [sent-12, score-0.416]
</p><p>10 On the other hand, significant advances in sentence-level event extraction have been made  over the last decade, in particular as the result of j an . [sent-14, score-0.412]
</p><p>11 In this paper we bridge this gap and address the task of recognizing stories discussing identical events by considering structured representations from sentence-level events. [sent-22, score-0.526]
</p><p>12 More concretely, we structure news stories into event graphs built from individual event mentions extracted from text. [sent-23, score-1.483]
</p><p>13 To measure event-based similarity of news stories, we compare their event graphs using graph kernels (Borgwardt, 2007). [sent-24, score-1.141]
</p><p>14 We conduct preliminary experiments on two event-oriented tasks and show that the proposed approach can outperform traditional vector space model in recognizing identical real-world events. [sent-25, score-0.215]
</p><p>15 Moreover, we demonstrate that our approach is especially suitable for distinguishing between topically real-world events. [sent-26, score-0.141]
</p><p>16 The VSM is at the core of most approaches that identify sametopic news stories (Hatzivassiloglou et al. [sent-29, score-0.374]
</p><p>17 (2004) divide document terms into four semantic categories (locations, temporal expressions,  proper names, and general terms) and construct separate vector for each of them. [sent-41, score-0.157]
</p><p>18 Kumaran and Allan (2004) represent news stories with three different vectors, modeling all words, named-entity words, and all non-named-entity words occurring in documents. [sent-42, score-0.374]
</p><p>19 When available, recognition of identical events can rely on meta-information associated with news stories, such as document creation time (DCT). [sent-43, score-0.351]
</p><p>20 Atkinson and Van der Goot (2009) combine DCT with VSM, assuming that temporally distant news stories are unlikely to describe the same event. [sent-44, score-0.413]
</p><p>21 In research on event extraction, the task of recognizing identical events is known as event coreference resolution (Bejan and Harabagiu, 2010; Lee et al. [sent-45, score-1.173]
</p><p>22 There, however, the aim is to identify sentence-level event mentions referring to the same real-world events, and not stories that discuss identical events. [sent-47, score-0.903]
</p><p>23 3  Kernels on Event Graphs  To identify the news describing the same realworld event, we (1) structure event-oriented in-  formation from text into event graphs and (2) use graph kernels to measure the similarity between a pair of event graphs. [sent-48, score-1.587]
</p><p>24 1 Event graphs An event graph is a vertex- and edge-labeled mixed graph in which vertices represent individual event mentions and edges represent temporal relations between event mentions. [sent-50, score-2.219]
</p><p>25 We adopt a generic representation of event mentions, as proposed by Glava ˇs and Sˇnajder (2013): each mention consists of an anchor (a word that conveys the core meaning) and four types of arguments (agent, target, time, location). [sent-51, score-0.412]
</p><p>26 Furthermore, we consider four types of temporal relations between event mentions: before, after, overlap, and equal (Allen, 1983). [sent-52, score-0.537]
</p><p>27 As relations overlap and equal are symmetric, whereas before and after are not, an event graph may contain both directed and undirected edges. [sent-53, score-0.618]
</p><p>28 The construction of an event graph from a news story involves the extraction of event mentions (anchors and arguments) and the extraction of temporal relations between mentions. [sent-57, score-1.449]
</p><p>29 We use a supervised model (with 80% F1 extraction performance) based on a rich set of features similar to those proposed by Bethard (2008) to extract event anchors. [sent-58, score-0.412]
</p><p>30 We then employ a robust, rule-based approach proposed by Glava ˇs and Sˇnajder (2013) to extract generic event arguments. [sent-59, score-0.412]
</p><p>31 Finally, we employ a supervised model (60% micro-averaged F1 classification performance) with a rich set of features, similar to those proposed by Bethard (2008), to extract temporal relations between event mentions. [sent-60, score-0.537]
</p><p>32 A detailed description of the graph construction steps is outside the scope of this paper. [sent-61, score-0.206]
</p><p>33 2), we need to determine whether two event mentions co-refer. [sent-64, score-0.545]
</p><p>34 To resolve cross-document  event coreference, we use the model proposed by Glava ˇs and Sˇnajder (2013). [sent-65, score-0.412]
</p><p>35 In what follows, cf (m1 , m2) denotes whether event mentions m1 and m2 corefer (equals 1if mentions co-refer, 0 otherwise). [sent-67, score-0.719]
</p><p>36 2 Graph kernels Graph kernels are fast polynomial alternatives to traditional graph comparison techniques (e. [sent-69, score-0.666]
</p><p>37 , subgraph isomorphism), which provide an expressive measure of similarity between graphs (Borgwardt, 2007). [sent-71, score-0.251]
</p><p>38 We employ two different graph kernels: product graph kernel and weighted decomposition kernel. [sent-72, score-0.661]
</p><p>39 We chose these kernels because their general forms have intuitive interpretations for event matching. [sent-73, score-0.621]
</p><p>40 These particular kernels have shown to perform well on a number of tasks from chemoinformatics (Mah e´ et al. [sent-74, score-0.209]
</p><p>41 A product graph kernel (PGK) counts the common walks between two input graphs (G¨ artner et al. [sent-78, score-0.656]
</p><p>42 The graph product of two labeled graphs, G and denoted GP = G G0, is a graph with the vertex set  G0,  VP = ? [sent-80, score-0.593]
</p><p>43 Given event graphs G = (V, E, A, m, r) and G0 = (V0, E0, A0, m0, r0), we consider the vertices to be identically labeled if the corresponding event mentions co-refer, i. [sent-84, score-1.217]
</p><p>44 The edge set of the graph product depends on the type of the product. [sent-87, score-0.347]
</p><p>45 We experiment with two different products: tensor product and conormal product. [sent-88, score-0.438]
</p><p>46 In the tensor product, an edge is introduced iff the corresponding edges exist in both input graphs and the labels ofthose edges match (i. [sent-89, score-0.389]
</p><p>47 In the conormal product, an edge is introduced iff the corresponding edge exists in at least one input graph. [sent-93, score-0.306]
</p><p>48 Thus, a conormal product may compensate for omitted temporal relations in the input graphs. [sent-94, score-0.467]
</p><p>49 Let AP be the adjacency matrix of the graph product GP built from input graphs G and G0. [sent-95, score-0.464]
</p><p>50 The product graph kernel that counts common walks in G and G0 can be computed efficiently as:  KPG(G,G0) =  |XVP|[(I − λAP)−1]ij  (1)  iX,j=1  when λ < 1/t , where t is the maximum degree of a vertex in the graph product GP. [sent-96, score-0.849]
</p><p>51 A weighted decomposition kernel (WDK) compares small graph parts, called selectors, being matched according to an equality predicate. [sent-99, score-0.389]
</p><p>52 The importance of the match is weighted by the similarity of the contexts in which the matched selectors occur. [sent-100, score-0.149]
</p><p>53 Let S(G) be the set of all pairs (s, z), where s is the selector (subgraph of interest) and z is the context of s. [sent-103, score-0.135]
</p><p>54 In this case, similarly as above, the equality predicate δ(v, v0) for two vertices v ∈ G and v0 ∈ G0 holds if and) only wifo t vhee corresponding even∈t m Gentions m(v) and m0(v0) co-refer. [sent-107, score-0.148]
</p><p>55 Using selectors that consist of more than one vertex would require a more complex and perhaps a less intuitive definition of the equality predicate δ. [sent-108, score-0.21]
</p><p>56 The selector context Zv of vertex v is a subgraph of G that contains v and all its immediate neighbors. [sent-109, score-0.215]
</p><p>57 In other words, we consider as context all event mentions that are in a direct temporal relation with the selected mention. [sent-110, score-0.67]
</p><p>58 WDK between event graphs G and G0 is computed as: KWD(G,G0) =  X cf (m(v),m0(v0)) κ(Zv,Zv00)  v∈VGX,v0∈VG0  (2)  where κ(Zv, Zv00) is the context kernel measuring the similarity between the context Zv of selector v ∈ G and the context Zv00 of selector v0 ∈ G0. [sent-111, score-0.955]
</p><p>59 As an example, consider the following two story snippets describing the same sets of real-world events: Story 1: A Cezanne masterpiece worth at least $131 million that was the yanked from the wall of a Zurich  art gallery in 2008 has been recovered, Serbian police said today. [sent-114, score-0.214]
</p><p>60 Story 2: Serbian police have recovered a painting by French impressionist Paul Cezanne worth an estimated 100 million euros (131. [sent-116, score-0.162]
</p><p>61 The corresponding  event graphs  G and  G0  are  shown in Fig. [sent-122, score-0.564]
</p><p>62 There are three pairs of coreferent event mentions between G and G0: (yanked, stolen), (recovered, recovered), and (arrests, arrested). [sent-125, score-0.658]
</p><p>63 Accordingly, the product graph  P has three nodes. [sent-126, score-0.312]
</p><p>64 The dashed edge between vertices (yanked, stolen) and (arrests, arrested) exists only in the conormal product graph. [sent-127, score-0.485]
</p><p>65 6 Similarly, for the conormal product graph P we obtain the conormal PGK score of KPG = 9. [sent-131, score-0.784]
</p><p>66 9 where VP contains pairs of coreferent event mentions: (yanked, stolen), (recovered, recovered), and (arrests, arrested). [sent-133, score-0.525]
</p><p>67 4  Experiments  We conducted two preliminary experiments to investigate whether kernels on event graphs can be used to recognize identical events. [sent-134, score-0.865]
</p><p>68 In the first experiment, we classify pairs of news stories as either describing identical  real-world events or not. [sent-137, score-0.659]
</p><p>69 For this we need a collection of stories in which pairs of stories on identical events have been annotated as such. [sent-138, score-0.783]
</p><p>70 1 To this end, we use the news clusters of the EMM NewsBrief service (Steinberger et al. [sent-141, score-0.162]
</p><p>71 EMM clusters news stories from different sources using a document similarity score. [sent-143, score-0.514]
</p><p>72 7  Table 1: Results for recognition of identical events different clusters discuss the same event. [sent-165, score-0.265]
</p><p>73 The final dataset consists of 64 documents in 10 clusters, with 195 news pairs from the same clusters (positive pairs) and 1821 news pairs from different clusters (negative pairs). [sent-167, score-0.404]
</p><p>74 Furthermore, because EMM similarity score uses VSM cosine similarity as one of the features, VSM cosine similarity constitutes a competitive baseline on this dataset. [sent-170, score-0.162]
</p><p>75 For each graph kernel and the VSM baseline, we determine the optimal threshold on the train set and evaluate the classification per-  formance on the test set. [sent-172, score-0.312]
</p><p>76 The precision is consistently higher than recall for all kernels and the baseline. [sent-174, score-0.209]
</p><p>77 High precision is expected, as clusters represent topically dissimilar events. [sent-175, score-0.156]
</p><p>78 PGK models (both tensor and conormal) outperform the WDK model, indicating that common walks correlate better to event-based document similarity than common subgraphs. [sent-176, score-0.258]
</p><p>79 Individually, none of the graph kernels outperforms the baseline. [sent-177, score-0.415]
</p><p>80 To investigate whether the two kernels complement each other, we fed the 800  Original “Taliban militants have attacked a prison in north-west Pakistan, freeing at least 380 prisoners. [sent-178, score-0.368]
</p><p>81 ” Event-shifting paraphrase “Taliban militants have been arrested in north-west Pakistan. [sent-184, score-0.175]
</p><p>82 Finally, we combined the graph-based features with the VSM cosine similarity (SVM graph + VSM model). [sent-189, score-0.26]
</p><p>83 The combined model (SVM graph + VSM) significantly (at p < 0. [sent-192, score-0.206]
</p><p>84 In the second experiment we focus on the task of distinguishing between news stories that describe topically very similar, yet distinct events. [sent-196, score-0.515]
</p><p>85 For this purpose, we use a small set of event paraphrases, constructed as follows. [sent-197, score-0.412]
</p><p>86 We manually selected 10 news stories from EMM NewsBrief and altered each of them to obtain two meaning-preserving (event-preserving) and two meaning-changing (event-shifting) paraphrases. [sent-198, score-0.374]
</p><p>87 To obtain meaning-changing paraphrases, we asked human annotators to alter each story so that it topically resembles the original, but describes a different real-world event. [sent-201, score-0.155]
</p><p>88 The performance of graph kernel models and the VSM baseline is given in Table 3. [sent-222, score-0.312]
</p><p>89 However, when considering R-precision, only the conormal PGK model significantly (at p < 0. [sent-226, score-0.236]
</p><p>90 Inspection of the rankings reveals that graph kernels assign very low scores to negative pairs, i. [sent-229, score-0.415]
</p><p>91 5  Conclusion  We proposed a novel approach for recognizing identical events that relies on structured, graphbased representations of events described in a document. [sent-232, score-0.379]
</p><p>92 We use graph kernels as an expressive framework for modeling the similarity between structured events. [sent-233, score-0.469]
</p><p>93 Preliminary results on two event-similarity tasks are encouraging, indicating that our approach can outperform traditional vector-space model, and is suitable for distinguishing between topically very similar events. [sent-234, score-0.215]
</p><p>94 Further improvements could be obtained by increasing the accuracy of event coreference resolution, which has a direct influence on graph kernels. [sent-235, score-0.676]
</p><p>95 Besides a systematic evaluation on larger datasets, we intend to investigate the applications in event tracking and eventoriented information retrieval. [sent-237, score-0.484]
</p><p>96 A linguistic resource for discovering event structures and resolving event coreference. [sent-258, score-0.824]
</p><p>97 Exploring coref-  erence uncertainty of generically extracted event mentions. [sent-289, score-0.412]
</p><p>98 Text classification and named entities for new event detection. [sent-304, score-0.412]
</p><p>99 Graph kernels for molecular structure-activity relationship analysis with support vector machines. [sent-319, score-0.209]
</p><p>100 Timeml: Robust specification of event and temporal expressions in text. [sent-332, score-0.537]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('event', 0.412), ('stories', 0.266), ('conormal', 0.236), ('pgk', 0.213), ('kernels', 0.209), ('vsm', 0.207), ('graph', 0.206), ('wdk', 0.166), ('graphs', 0.152), ('mentions', 0.133), ('temporal', 0.125), ('events', 0.119), ('news', 0.108), ('vertices', 0.108), ('product', 0.106), ('kernel', 0.106), ('emm', 0.104), ('topically', 0.102), ('glava', 0.096), ('tdt', 0.096), ('tensor', 0.096), ('selector', 0.095), ('selectors', 0.095), ('yanked', 0.095), ('identical', 0.092), ('arrested', 0.091), ('stolen', 0.084), ('militants', 0.084), ('verhagen', 0.084), ('recovered', 0.083), ('arrests', 0.077), ('vertex', 0.075), ('coreferent', 0.073), ('tracking', 0.072), ('kpg', 0.071), ('taliban', 0.071), ('bejan', 0.069), ('najder', 0.066), ('zv', 0.063), ('menchetti', 0.063), ('pustejovsky', 0.062), ('kumaran', 0.058), ('coreference', 0.058), ('roser', 0.058), ('atkinson', 0.054), ('clusters', 0.054), ('similarity', 0.054), ('story', 0.053), ('edges', 0.053), ('allan', 0.053), ('goran', 0.052), ('sauri', 0.052), ('james', 0.051), ('recognizing', 0.049), ('borgwardt', 0.047), ('cezanne', 0.047), ('hammack', 0.047), ('kwd', 0.047), ('mah', 0.047), ('makkonen', 0.047), ('newsbrief', 0.047), ('painting', 0.047), ('gaizauskas', 0.046), ('subgraph', 0.045), ('walks', 0.044), ('salton', 0.044), ('artner', 0.042), ('anchors', 0.042), ('traditional', 0.042), ('cf', 0.041), ('hatzivassiloglou', 0.04), ('pairs', 0.04), ('equality', 0.04), ('svm', 0.039), ('der', 0.039), ('distinguishing', 0.039), ('cosmin', 0.039), ('goot', 0.039), ('dct', 0.039), ('setzer', 0.039), ('timeml', 0.039), ('pakistan', 0.039), ('prison', 0.039), ('decomposition', 0.037), ('attacked', 0.036), ('croatia', 0.036), ('giridhar', 0.036), ('timebank', 0.036), ('edge', 0.035), ('serbian', 0.035), ('zagreb', 0.035), ('describing', 0.034), ('vp', 0.033), ('zurich', 0.033), ('bethard', 0.033), ('outperform', 0.032), ('steinberger', 0.032), ('police', 0.032), ('document', 0.032), ('resolution', 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="296-tfidf-1" href="./acl-2013-Recognizing_Identical_Events_with_Graph_Kernels.html">296 acl-2013-Recognizing Identical Events with Graph Kernels</a></p>
<p>Author: Goran Glavas ; Jan Snajder</p><p>Abstract: Identifying news stories that discuss the same real-world events is important for news tracking and retrieval. Most existing approaches rely on the traditional vector space model. We propose an approach for recognizing identical real-world events based on a structured, event-oriented document representation. We structure documents as graphs of event mentions and use graph kernels to measure the similarity between document pairs. Our experiments indicate that the proposed graph-based approach can outperform the traditional vector space model, and is especially suitable for distinguishing between topically similar, yet non-identical events.</p><p>2 0.29758701 <a title="296-tfidf-2" href="./acl-2013-Argument_Inference_from_Relevant_Event_Mentions_in_Chinese_Argument_Extraction.html">56 acl-2013-Argument Inference from Relevant Event Mentions in Chinese Argument Extraction</a></p>
<p>Author: Peifeng Li ; Qiaoming Zhu ; Guodong Zhou</p><p>Abstract: As a paratactic language, sentence-level argument extraction in Chinese suffers much from the frequent occurrence of ellipsis with regard to inter-sentence arguments. To resolve such problem, this paper proposes a novel global argument inference model to explore specific relationships, such as Coreference, Sequence and Parallel, among relevant event mentions to recover those intersentence arguments in the sentence, discourse and document layers which represent the cohesion of an event or a topic. Evaluation on the ACE 2005 Chinese corpus justifies the effectiveness of our global argument inference model over a state-of-the-art baseline. 1</p><p>3 0.25583643 <a title="296-tfidf-3" href="./acl-2013-Extracting_Events_with_Informal_Temporal_References_in_Personal_Histories_in_Online_Communities.html">153 acl-2013-Extracting Events with Informal Temporal References in Personal Histories in Online Communities</a></p>
<p>Author: Miaomiao Wen ; Zeyu Zheng ; Hyeju Jang ; Guang Xiang ; Carolyn Penstein Rose</p><p>Abstract: We present a system for extracting the dates of illness events (year and month of the event occurrence) from posting histories in the context of an online medical support community. A temporal tagger retrieves and normalizes dates mentioned informally in social media to actual month and year referents. Building on this, an event date extraction system learns to integrate the likelihood of candidate dates extracted from time-rich sentences with temporal constraints extracted from eventrelated sentences. Our integrated model achieves 89.7% of the maximum performance given the performance of the temporal expression retrieval step.</p><p>4 0.2072743 <a title="296-tfidf-4" href="./acl-2013-Joint_Event_Extraction_via_Structured_Prediction_with_Global_Features.html">206 acl-2013-Joint Event Extraction via Structured Prediction with Global Features</a></p>
<p>Author: Qi Li ; Heng Ji ; Liang Huang</p><p>Abstract: Traditional approaches to the task of ACE event extraction usually rely on sequential pipelines with multiple stages, which suffer from error propagation since event triggers and arguments are predicted in isolation by independent local classifiers. By contrast, we propose a joint framework based on structured prediction which extracts triggers and arguments together so that the local predictions can be mutually improved. In addition, we propose to incorporate global features which explicitly capture the dependencies of multiple triggers and arguments. Experimental results show that our joint approach with local features outperforms the pipelined baseline, and adding global features further improves the performance significantly. Our approach advances state-ofthe-art sentence-level event extraction, and even outperforms previous argument labeling methods which use external knowledge from other sentences and documents.</p><p>5 0.16754851 <a title="296-tfidf-5" href="./acl-2013-A_Structured_Distributional_Semantic_Model_for_Event_Co-reference.html">22 acl-2013-A Structured Distributional Semantic Model for Event Co-reference</a></p>
<p>Author: Kartik Goyal ; Sujay Kumar Jauhar ; Huiying Li ; Mrinmaya Sachan ; Shashank Srivastava ; Eduard Hovy</p><p>Abstract: In this paper we present a novel approach to modelling distributional semantics that represents meaning as distributions over relations in syntactic neighborhoods. We argue that our model approximates meaning in compositional configurations more effectively than standard distributional vectors or bag-of-words models. We test our hypothesis on the problem of judging event coreferentiality, which involves compositional interactions in the predicate-argument structure of sentences, and demonstrate that our model outperforms both state-of-the-art window-based word embeddings as well as simple approaches to compositional semantics pre- viously employed in the literature.</p><p>6 0.16006757 <a title="296-tfidf-6" href="./acl-2013-Temporal_Signals_Help_Label_Temporal_Relations.html">339 acl-2013-Temporal Signals Help Label Temporal Relations</a></p>
<p>7 0.1539841 <a title="296-tfidf-7" href="./acl-2013-Learning_to_Extract_International_Relations_from_Political_Context.html">224 acl-2013-Learning to Extract International Relations from Political Context</a></p>
<p>8 0.15211621 <a title="296-tfidf-8" href="./acl-2013-Vector_Space_Model_for_Adaptation_in_Statistical_Machine_Translation.html">383 acl-2013-Vector Space Model for Adaptation in Statistical Machine Translation</a></p>
<p>9 0.1489872 <a title="296-tfidf-9" href="./acl-2013-Embedding_Semantic_Similarity_in_Tree_Kernels_for_Domain_Adaptation_of_Relation_Extraction.html">134 acl-2013-Embedding Semantic Similarity in Tree Kernels for Domain Adaptation of Relation Extraction</a></p>
<p>10 0.12812363 <a title="296-tfidf-10" href="./acl-2013-Multigraph_Clustering_for_Unsupervised_Coreference_Resolution.html">252 acl-2013-Multigraph Clustering for Unsupervised Coreference Resolution</a></p>
<p>11 0.12316604 <a title="296-tfidf-11" href="./acl-2013-Detecting_Event-Related_Links_and_Sentiments_from_Social_Media_Texts.html">115 acl-2013-Detecting Event-Related Links and Sentiments from Social Media Texts</a></p>
<p>12 0.12201045 <a title="296-tfidf-12" href="./acl-2013-Explicit_and_Implicit_Syntactic_Features_for_Text_Classification.html">144 acl-2013-Explicit and Implicit Syntactic Features for Text Classification</a></p>
<p>13 0.11704054 <a title="296-tfidf-13" href="./acl-2013-Probabilistic_Domain_Modelling_With_Contextualized_Distributional_Semantic_Vectors.html">283 acl-2013-Probabilistic Domain Modelling With Contextualized Distributional Semantic Vectors</a></p>
<p>14 0.11644331 <a title="296-tfidf-14" href="./acl-2013-PARMA%3A_A_Predicate_Argument_Aligner.html">267 acl-2013-PARMA: A Predicate Argument Aligner</a></p>
<p>15 0.095273353 <a title="296-tfidf-15" href="./acl-2013-Learning_Semantic_Textual_Similarity_with_Structural_Representations.html">222 acl-2013-Learning Semantic Textual Similarity with Structural Representations</a></p>
<p>16 0.091809854 <a title="296-tfidf-16" href="./acl-2013-Parsing_Graphs_with_Hyperedge_Replacement_Grammars.html">274 acl-2013-Parsing Graphs with Hyperedge Replacement Grammars</a></p>
<p>17 0.091746002 <a title="296-tfidf-17" href="./acl-2013-Modelling_Annotator_Bias_with_Multi-task_Gaussian_Processes%3A_An_Application_to_Machine_Translation_Quality_Estimation.html">248 acl-2013-Modelling Annotator Bias with Multi-task Gaussian Processes: An Application to Machine Translation Quality Estimation</a></p>
<p>18 0.088823229 <a title="296-tfidf-18" href="./acl-2013-HEADY%3A_News_headline_abstraction_through_event_pattern_clustering.html">178 acl-2013-HEADY: News headline abstraction through event pattern clustering</a></p>
<p>19 0.081846163 <a title="296-tfidf-19" href="./acl-2013-Linking_Tweets_to_News%3A_A_Framework_to_Enrich_Short_Text_Data_in_Social_Media.html">233 acl-2013-Linking Tweets to News: A Framework to Enrich Short Text Data in Social Media</a></p>
<p>20 0.080771163 <a title="296-tfidf-20" href="./acl-2013-Improving_pairwise_coreference_models_through_feature_space_hierarchy_learning.html">196 acl-2013-Improving pairwise coreference models through feature space hierarchy learning</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.187), (1, 0.103), (2, -0.021), (3, -0.136), (4, 0.061), (5, 0.269), (6, 0.029), (7, 0.19), (8, -0.035), (9, 0.04), (10, 0.037), (11, -0.066), (12, 0.062), (13, 0.018), (14, 0.02), (15, 0.013), (16, -0.113), (17, 0.021), (18, 0.028), (19, 0.087), (20, 0.106), (21, -0.163), (22, 0.097), (23, -0.052), (24, -0.13), (25, -0.12), (26, -0.119), (27, 0.032), (28, -0.143), (29, -0.049), (30, -0.071), (31, 0.118), (32, -0.061), (33, -0.008), (34, 0.073), (35, -0.038), (36, -0.039), (37, -0.026), (38, 0.008), (39, 0.035), (40, -0.057), (41, 0.083), (42, 0.051), (43, -0.055), (44, 0.013), (45, -0.076), (46, -0.036), (47, 0.037), (48, -0.043), (49, 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96477222 <a title="296-lsi-1" href="./acl-2013-Recognizing_Identical_Events_with_Graph_Kernels.html">296 acl-2013-Recognizing Identical Events with Graph Kernels</a></p>
<p>Author: Goran Glavas ; Jan Snajder</p><p>Abstract: Identifying news stories that discuss the same real-world events is important for news tracking and retrieval. Most existing approaches rely on the traditional vector space model. We propose an approach for recognizing identical real-world events based on a structured, event-oriented document representation. We structure documents as graphs of event mentions and use graph kernels to measure the similarity between document pairs. Our experiments indicate that the proposed graph-based approach can outperform the traditional vector space model, and is especially suitable for distinguishing between topically similar, yet non-identical events.</p><p>2 0.80153471 <a title="296-lsi-2" href="./acl-2013-Extracting_Events_with_Informal_Temporal_References_in_Personal_Histories_in_Online_Communities.html">153 acl-2013-Extracting Events with Informal Temporal References in Personal Histories in Online Communities</a></p>
<p>Author: Miaomiao Wen ; Zeyu Zheng ; Hyeju Jang ; Guang Xiang ; Carolyn Penstein Rose</p><p>Abstract: We present a system for extracting the dates of illness events (year and month of the event occurrence) from posting histories in the context of an online medical support community. A temporal tagger retrieves and normalizes dates mentioned informally in social media to actual month and year referents. Building on this, an event date extraction system learns to integrate the likelihood of candidate dates extracted from time-rich sentences with temporal constraints extracted from eventrelated sentences. Our integrated model achieves 89.7% of the maximum performance given the performance of the temporal expression retrieval step.</p><p>3 0.68175089 <a title="296-lsi-3" href="./acl-2013-Argument_Inference_from_Relevant_Event_Mentions_in_Chinese_Argument_Extraction.html">56 acl-2013-Argument Inference from Relevant Event Mentions in Chinese Argument Extraction</a></p>
<p>Author: Peifeng Li ; Qiaoming Zhu ; Guodong Zhou</p><p>Abstract: As a paratactic language, sentence-level argument extraction in Chinese suffers much from the frequent occurrence of ellipsis with regard to inter-sentence arguments. To resolve such problem, this paper proposes a novel global argument inference model to explore specific relationships, such as Coreference, Sequence and Parallel, among relevant event mentions to recover those intersentence arguments in the sentence, discourse and document layers which represent the cohesion of an event or a topic. Evaluation on the ACE 2005 Chinese corpus justifies the effectiveness of our global argument inference model over a state-of-the-art baseline. 1</p><p>4 0.63804412 <a title="296-lsi-4" href="./acl-2013-Joint_Event_Extraction_via_Structured_Prediction_with_Global_Features.html">206 acl-2013-Joint Event Extraction via Structured Prediction with Global Features</a></p>
<p>Author: Qi Li ; Heng Ji ; Liang Huang</p><p>Abstract: Traditional approaches to the task of ACE event extraction usually rely on sequential pipelines with multiple stages, which suffer from error propagation since event triggers and arguments are predicted in isolation by independent local classifiers. By contrast, we propose a joint framework based on structured prediction which extracts triggers and arguments together so that the local predictions can be mutually improved. In addition, we propose to incorporate global features which explicitly capture the dependencies of multiple triggers and arguments. Experimental results show that our joint approach with local features outperforms the pipelined baseline, and adding global features further improves the performance significantly. Our approach advances state-ofthe-art sentence-level event extraction, and even outperforms previous argument labeling methods which use external knowledge from other sentences and documents.</p><p>5 0.59948099 <a title="296-lsi-5" href="./acl-2013-Learning_to_Extract_International_Relations_from_Political_Context.html">224 acl-2013-Learning to Extract International Relations from Political Context</a></p>
<p>Author: Brendan O'Connor ; Brandon M. Stewart ; Noah A. Smith</p><p>Abstract: We describe a new probabilistic model for extracting events between major political actors from news corpora. Our unsupervised model brings together familiar components in natural language processing (like parsers and topic models) with contextual political information— temporal and dyad dependence—to infer latent event classes. We quantitatively evaluate the model’s performance on political science benchmarks: recovering expert-assigned event class valences, and detecting real-world conflict. We also conduct a small case study based on our model’s inferences. A supplementary appendix, and replication software/data are available online, at: http://brenocon.com/irevents</p><p>6 0.59089971 <a title="296-lsi-6" href="./acl-2013-Temporal_Signals_Help_Label_Temporal_Relations.html">339 acl-2013-Temporal Signals Help Label Temporal Relations</a></p>
<p>7 0.56798345 <a title="296-lsi-7" href="./acl-2013-A_Structured_Distributional_Semantic_Model_for_Event_Co-reference.html">22 acl-2013-A Structured Distributional Semantic Model for Event Co-reference</a></p>
<p>8 0.46424037 <a title="296-lsi-8" href="./acl-2013-Probabilistic_Domain_Modelling_With_Contextualized_Distributional_Semantic_Vectors.html">283 acl-2013-Probabilistic Domain Modelling With Contextualized Distributional Semantic Vectors</a></p>
<p>9 0.46358654 <a title="296-lsi-9" href="./acl-2013-Embedding_Semantic_Similarity_in_Tree_Kernels_for_Domain_Adaptation_of_Relation_Extraction.html">134 acl-2013-Embedding Semantic Similarity in Tree Kernels for Domain Adaptation of Relation Extraction</a></p>
<p>10 0.46144673 <a title="296-lsi-10" href="./acl-2013-Language-Independent_Discriminative_Parsing_of_Temporal_Expressions.html">212 acl-2013-Language-Independent Discriminative Parsing of Temporal Expressions</a></p>
<p>11 0.43161801 <a title="296-lsi-11" href="./acl-2013-Resolving_Entity_Morphs_in_Censored_Data.html">301 acl-2013-Resolving Entity Morphs in Censored Data</a></p>
<p>12 0.42929444 <a title="296-lsi-12" href="./acl-2013-HEADY%3A_News_headline_abstraction_through_event_pattern_clustering.html">178 acl-2013-HEADY: News headline abstraction through event pattern clustering</a></p>
<p>13 0.42054427 <a title="296-lsi-13" href="./acl-2013-Multigraph_Clustering_for_Unsupervised_Coreference_Resolution.html">252 acl-2013-Multigraph Clustering for Unsupervised Coreference Resolution</a></p>
<p>14 0.39931381 <a title="296-lsi-14" href="./acl-2013-What_causes_a_causal_relation%3F_Detecting_Causal_Triggers_in_Biomedical_Scientific_Discourse.html">386 acl-2013-What causes a causal relation? Detecting Causal Triggers in Biomedical Scientific Discourse</a></p>
<p>15 0.38976744 <a title="296-lsi-15" href="./acl-2013-PARMA%3A_A_Predicate_Argument_Aligner.html">267 acl-2013-PARMA: A Predicate Argument Aligner</a></p>
<p>16 0.38003266 <a title="296-lsi-16" href="./acl-2013-Enriching_Entity_Translation_Discovery_using_Selective_Temporality.html">138 acl-2013-Enriching Entity Translation Discovery using Selective Temporality</a></p>
<p>17 0.3717654 <a title="296-lsi-17" href="./acl-2013-Learning_Semantic_Textual_Similarity_with_Structural_Representations.html">222 acl-2013-Learning Semantic Textual Similarity with Structural Representations</a></p>
<p>18 0.35659119 <a title="296-lsi-18" href="./acl-2013-Improving_pairwise_coreference_models_through_feature_space_hierarchy_learning.html">196 acl-2013-Improving pairwise coreference models through feature space hierarchy learning</a></p>
<p>19 0.35658941 <a title="296-lsi-19" href="./acl-2013-Domain-Specific_Coreference_Resolution_with_Lexicalized_Features.html">130 acl-2013-Domain-Specific Coreference Resolution with Lexicalized Features</a></p>
<p>20 0.34546342 <a title="296-lsi-20" href="./acl-2013-Semantic_Frames_to_Predict_Stock_Price_Movement.html">310 acl-2013-Semantic Frames to Predict Stock Price Movement</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.033), (6, 0.029), (11, 0.04), (15, 0.019), (24, 0.031), (26, 0.046), (28, 0.012), (35, 0.059), (42, 0.035), (48, 0.028), (52, 0.014), (70, 0.48), (88, 0.039), (90, 0.028), (95, 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.97708398 <a title="296-lda-1" href="./acl-2013-Visual_Features_for_Linguists%3A_Basic_image_analysis_techniques_for_multimodally-curious_NLPers.html">384 acl-2013-Visual Features for Linguists: Basic image analysis techniques for multimodally-curious NLPers</a></p>
<p>Author: Elia Bruni ; Marco Baroni</p><p>Abstract: unkown-abstract</p><p>same-paper 2 0.9391008 <a title="296-lda-2" href="./acl-2013-Recognizing_Identical_Events_with_Graph_Kernels.html">296 acl-2013-Recognizing Identical Events with Graph Kernels</a></p>
<p>Author: Goran Glavas ; Jan Snajder</p><p>Abstract: Identifying news stories that discuss the same real-world events is important for news tracking and retrieval. Most existing approaches rely on the traditional vector space model. We propose an approach for recognizing identical real-world events based on a structured, event-oriented document representation. We structure documents as graphs of event mentions and use graph kernels to measure the similarity between document pairs. Our experiments indicate that the proposed graph-based approach can outperform the traditional vector space model, and is especially suitable for distinguishing between topically similar, yet non-identical events.</p><p>3 0.93409556 <a title="296-lda-3" href="./acl-2013-Computerized_Analysis_of_a_Verbal_Fluency_Test.html">89 acl-2013-Computerized Analysis of a Verbal Fluency Test</a></p>
<p>Author: James O. Ryan ; Serguei Pakhomov ; Susan Marino ; Charles Bernick ; Sarah Banks</p><p>Abstract: We present a system for automated phonetic clustering analysis of cognitive tests of phonemic verbal fluency, on which one must name words starting with a specific letter (e.g., ‘F’) for one minute. Test responses are typically subjected to manual phonetic clustering analysis that is labor-intensive and subject to inter-rater variability. Our system provides an automated alternative. In a pilot study, we applied this system to tests of 55 novice and experienced professional fighters (boxers and mixed martial artists) and found that experienced fighters produced significantly longer chains of phonetically similar words, while no differences were found in the total number of words produced. These findings are preliminary, but strongly suggest that our system can be used to detect subtle signs of brain damage due to repetitive head trauma in individuals that are otherwise unimpaired.</p><p>4 0.91942048 <a title="296-lda-4" href="./acl-2013-The_effect_of_non-tightness_on_Bayesian_estimation_of_PCFGs.html">348 acl-2013-The effect of non-tightness on Bayesian estimation of PCFGs</a></p>
<p>Author: Shay B. Cohen ; Mark Johnson</p><p>Abstract: Probabilistic context-free grammars have the unusual property of not always defining tight distributions (i.e., the sum of the “probabilities” of the trees the grammar generates can be less than one). This paper reviews how this non-tightness can arise and discusses its impact on Bayesian estimation of PCFGs. We begin by presenting the notion of “almost everywhere tight grammars” and show that linear CFGs follow it. We then propose three different ways of reinterpreting non-tight PCFGs to make them tight, show that the Bayesian estimators in Johnson et al. (2007) are correct under one of them, and provide MCMC samplers for the other two. We conclude with a discussion of the impact of tightness empirically.</p><p>5 0.90168214 <a title="296-lda-5" href="./acl-2013-Latent_Semantic_Tensor_Indexing_for_Community-based_Question_Answering.html">218 acl-2013-Latent Semantic Tensor Indexing for Community-based Question Answering</a></p>
<p>Author: Xipeng Qiu ; Le Tian ; Xuanjing Huang</p><p>Abstract: Retrieving similar questions is very important in community-based question answering(CQA) . In this paper, we propose a unified question retrieval model based on latent semantic indexing with tensor analysis, which can capture word associations among different parts of CQA triples simultaneously. Thus, our method can reduce lexical chasm of question retrieval with the help of the information of question content and answer parts. The experimental result shows that our method outperforms the traditional methods.</p><p>6 0.89470381 <a title="296-lda-6" href="./acl-2013-A_Shift-Reduce_Parsing_Algorithm_for_Phrase-based_String-to-Dependency_Translation.html">19 acl-2013-A Shift-Reduce Parsing Algorithm for Phrase-based String-to-Dependency Translation</a></p>
<p>7 0.88567239 <a title="296-lda-7" href="./acl-2013-Learning_Latent_Personas_of_Film_Characters.html">220 acl-2013-Learning Latent Personas of Film Characters</a></p>
<p>8 0.81476641 <a title="296-lda-8" href="./acl-2013-Transfer_Learning_Based_Cross-lingual_Knowledge_Extraction_for_Wikipedia.html">356 acl-2013-Transfer Learning Based Cross-lingual Knowledge Extraction for Wikipedia</a></p>
<p>9 0.67739743 <a title="296-lda-9" href="./acl-2013-Extracting_Events_with_Informal_Temporal_References_in_Personal_Histories_in_Online_Communities.html">153 acl-2013-Extracting Events with Informal Temporal References in Personal Histories in Online Communities</a></p>
<p>10 0.63341093 <a title="296-lda-10" href="./acl-2013-Models_of_Semantic_Representation_with_Visual_Attributes.html">249 acl-2013-Models of Semantic Representation with Visual Attributes</a></p>
<p>11 0.62463695 <a title="296-lda-11" href="./acl-2013-VSEM%3A_An_open_library_for_visual_semantics_representation.html">380 acl-2013-VSEM: An open library for visual semantics representation</a></p>
<p>12 0.6197961 <a title="296-lda-12" href="./acl-2013-Statistical_Machine_Translation_Improves_Question_Retrieval_in_Community_Question_Answering_via_Matrix_Factorization.html">329 acl-2013-Statistical Machine Translation Improves Question Retrieval in Community Question Answering via Matrix Factorization</a></p>
<p>13 0.59765249 <a title="296-lda-13" href="./acl-2013-Parsing_Graphs_with_Hyperedge_Replacement_Grammars.html">274 acl-2013-Parsing Graphs with Hyperedge Replacement Grammars</a></p>
<p>14 0.57843357 <a title="296-lda-14" href="./acl-2013-Chinese_Parsing_Exploiting_Characters.html">80 acl-2013-Chinese Parsing Exploiting Characters</a></p>
<p>15 0.57664919 <a title="296-lda-15" href="./acl-2013-Generalizing_Image_Captions_for_Image-Text_Parallel_Corpus.html">167 acl-2013-Generalizing Image Captions for Image-Text Parallel Corpus</a></p>
<p>16 0.55752456 <a title="296-lda-16" href="./acl-2013-Generating_Recommendation_Dialogs_by_Extracting_Information_from_User_Reviews.html">168 acl-2013-Generating Recommendation Dialogs by Extracting Information from User Reviews</a></p>
<p>17 0.55600607 <a title="296-lda-17" href="./acl-2013-Generating_Synthetic_Comparable_Questions_for_News_Articles.html">169 acl-2013-Generating Synthetic Comparable Questions for News Articles</a></p>
<p>18 0.5544343 <a title="296-lda-18" href="./acl-2013-Temporal_Signals_Help_Label_Temporal_Relations.html">339 acl-2013-Temporal Signals Help Label Temporal Relations</a></p>
<p>19 0.5419749 <a title="296-lda-19" href="./acl-2013-Handling_Ambiguities_of_Bilingual_Predicate-Argument_Structures_for_Statistical_Machine_Translation.html">180 acl-2013-Handling Ambiguities of Bilingual Predicate-Argument Structures for Statistical Machine Translation</a></p>
<p>20 0.54044849 <a title="296-lda-20" href="./acl-2013-General_binarization_for_parsing_and_translation.html">165 acl-2013-General binarization for parsing and translation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
