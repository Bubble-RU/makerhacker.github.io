<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>203 acl-2013-Is word-to-phone mapping better than phone-phone mapping for handling English words?</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-203" href="#">acl2013-203</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>203 acl-2013-Is word-to-phone mapping better than phone-phone mapping for handling English words?</h1>
<br/><p>Source: <a title="acl-2013-203-pdf" href="http://aclweb.org/anthology//P/P13/P13-2035.pdf">pdf</a></p><p>Author: Naresh Kumar Elluru ; Anandaswarup Vadapalli ; Raghavendra Elluru ; Hema Murthy ; Kishore Prahallad</p><p>Abstract: In this paper, we relook at the problem of pronunciation of English words using native phone set. Specifically, we investigate methods of pronouncing English words using Telugu phoneset in the con- text of Telugu Text-to-Speech. We compare phone-phone substitution and wordphone mapping for pronunciation of English words using Telugu phones. We are not considering other than native language phoneset in all our experiments. This differentiates our approach from other works in polyglot speech synthesis.</p><p>Reference: <a title="acl-2013-203-reference" href="../acl2013_reference/acl-2013-Is_word-to-phone_mapping_better_than_phone-phone_mapping_for_handling_English_words%3F_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Is word-to-phone mapping better than phone-phone mapping for handling English words? [sent-1, score-0.396]
</p><p>2 i it i Raghavendra Elluru Speech and Vision Lab IIIT Hyderabad, India raghavendra . [sent-5, score-0.036]
</p><p>3 Abstract In this paper, we relook at the problem of pronunciation of English words using native phone set. [sent-7, score-0.752]
</p><p>4 Specifically, we investigate methods of pronouncing English words using Telugu phoneset in the con-  text of Telugu Text-to-Speech. [sent-8, score-0.223]
</p><p>5 We compare phone-phone substitution and wordphone mapping for pronunciation of English words using Telugu phones. [sent-9, score-0.393]
</p><p>6 We are not considering other than native language phoneset in all our experiments. [sent-10, score-0.228]
</p><p>7 This differentiates our approach from other works in polyglot speech synthesis. [sent-11, score-0.283]
</p><p>8 Text processing and waveform generation are the two main components of a TTS system. [sent-13, score-0.064]
</p><p>9 The objective of the text processing component is to convert the given input text into an appropriate sequence of valid phonemic units. [sent-14, score-0.11]
</p><p>10 These phonemic units are then realized by the waveform generation component. [sent-15, score-0.118]
</p><p>11 For high quality speech synthesis, it is necessary that the text processing unit produce the appropriate sequence of phonemic units, for the given input text. [sent-16, score-0.206]
</p><p>12 In a multilingual country such as India, we commonly find Indian language text being freely interspersed with English words and phrases. [sent-19, score-0.055]
</p><p>13 in  re s earch  Hema Murthy Department of CSE IIT Madras, India hema @ i itm . [sent-22, score-0.094]
</p><p>14 Due to the growth of “code mixing” it has become necessary to develop strategies for dealing with such multilingual text in TTS systems. [sent-31, score-0.055]
</p><p>15 These multilingual TTS systems should be capable of synthesizing utterances which contain foreign language words or word groups, without sounding unnatural. [sent-32, score-0.306]
</p><p>16 The different ways of achieving multilingual  TTS synthesis are as follows (Traber et al. [sent-33, score-0.204]
</p><p>17 Separate TTS systems for each language: In this paradigm, a seperate TTS system is built for each language under consideration. [sent-37, score-0.024]
</p><p>18 Polyglot speech synthesis: This is a type of multilingual speech synthesis achieved using a single TTS system. [sent-41, score-0.396]
</p><p>19 This method involves recording a multi language speech corpus by someone who is fluent in multiple languages. [sent-42, score-0.12]
</p><p>20 This speech corpus is then used to build a multilingual TTS system. [sent-43, score-0.151]
</p><p>21 The primary issue with polyglot speech synthesis is that it requires development of a combined phoneset, incorporating phones from all the languages under consid-  eration. [sent-44, score-0.635]
</p><p>22 Also, finding a speaker fluent in mul196  Proce dingSsof oifa, th Beu 5l1gsarti Aan,An u aglu Mste 4e-ti9n2g 0 o1f3 t. [sent-46, score-0.081]
</p><p>23 c A2s0s1o3ci Aatsiosonc fioartio Cno fmorpu Ctoamtiopnuatalt Lioin gauli Lsitnicgsu,i psatgices 196–20 , tiple languages is not an easy task. [sent-48, score-0.022]
</p><p>24 Phone mapping: This type of multilingual synthesis is based upon phone mapping, whereby the phones of the foreign language are substituted with the closest sounding phones of the primary language. [sent-50, score-1.297]
</p><p>25 This method results in a strong foreign accent while synthesizing the foreign words. [sent-51, score-0.275]
</p><p>26 Also, if the sequence of the mapped phones does not exist or is not frequently occurring in the primary language, then the synthesized output quality would be poor. [sent-53, score-0.513]
</p><p>27 Hence, an average polyglot synthesis technique using HMM based synthesis and speaker adaptation has been proposed (Latorre et al. [sent-54, score-0.502]
</p><p>28 Such methods make use of speech data from dif-  ferent languages and different speakers. [sent-56, score-0.096]
</p><p>29 In this paper, we relook at the problem of pronunciation of English words using native phone set. [sent-57, score-0.752]
</p><p>30 Specifically, we investigate methods of pronouncing English words using Telugu phoneset in the context of Telugu Text-to-Speech. [sent-58, score-0.223]
</p><p>31 Our motivation for doing so, comes from our understanding of how humans pronounce foreign words while speaking. [sent-59, score-0.117]
</p><p>32 The speaker maps the foreign words to a sequence of phones of his/her native language while pronouncing that foreign word. [sent-60, score-0.75]
</p><p>33 For example, a native speaker of Telugu, while pronouncing an English word, mentally maps the English word to a sequence of Telugu phones as opposed to simply substituting English phones with the corresponding Telugu phones. [sent-61, score-0.799]
</p><p>34 Also, the receiver of the synthesized speech would be a Telugu native speaker, who may not have the knowledge of English phone set. [sent-62, score-0.887]
</p><p>35 Hence, approximating an English word using Telugu phone sequence may be more acceptable for a Telugu native speaker. [sent-63, score-0.659]
</p><p>36 We compare phone-phone substitution and  word-phone mapping (also referred to LTS rules) for the pronunciation of English words using Telugu phones. [sent-64, score-0.319]
</p><p>37 We are not considering other than native language phoneset in all our experiments. [sent-65, score-0.228]
</p><p>38 This differentiates our work from other works in polyglot speech synthesis. [sent-66, score-0.283]
</p><p>39 The English wordTelugu phone mapping is not a one to one mapping, as it is in the case of English phone-Telugu phone mapping. [sent-68, score-1.194]
</p><p>40 Each letter has a correspondence with one or more than one phones. [sent-69, score-0.163]
</p><p>41 As some letters do not have a equivalent pronunciation sound (the letter is not mapped to any phone) the term epsilon is used whenever there is a letter which does not have a mapping with a phone. [sent-70, score-0.763]
</p><p>42 To compare word-phone (W-P) mapping and phone-phone (P-P) mapping, we manually prepared word-phone and phone-phone mappings for 10 bilingual utterances and synthesized them using our baseline Telugu TTS system. [sent-71, score-0.497]
</p><p>43 We then per-  formed perceptual listening evaluations on these synthesized utterances, using five native speakers of Telugu as the subjects of the evaluations. [sent-72, score-0.625]
</p><p>44 The perceptual listening evaluations were setup both as MOS (mean opinion score) evaluations and as ABX evaluations. [sent-73, score-0.37]
</p><p>45 An explanation of MOS and ABX evaluations is given in Section 4. [sent-74, score-0.079]
</p><p>46 /5Pr0beafsline  Telugu TTS system with different pronunciation rules for English 197  An examination of the results in Table 2 shows that manually prepared word-phone mapping is preferred perceptually when compared to manual phone-phone mapping. [sent-79, score-0.444]
</p><p>47 48 indicates that native speakers accept W-P mapping for pronouncing English words in Telugu TTS. [sent-81, score-0.444]
</p><p>48 We propose a method of automatically generating these wordphone mapping from data. [sent-83, score-0.272]
</p><p>49 We experiment our approach by generating a word-phone mapping which maps each English word to a Telugu phone sequence (henceforth called EW-TP mapping). [sent-84, score-0.777]
</p><p>50 We report the accuracy of learning the word-phone mappings both on a held out test set and on a test set from a different domain. [sent-85, score-0.078]
</p><p>51 Finally, we incorporate this word-phone mapping in our baseline Telugu TTS system and demonstrate its usefulness by means of perceptual listening tests. [sent-86, score-0.41]
</p><p>52 3  Automatic generation of word-phone mapping  We have previously mentioned that letter to phone mapping is not a one to one mapping. [sent-87, score-1.047]
</p><p>53 Each letter may have a correspondence with one or more than one phones, or it may not have correspondence with any phone. [sent-88, score-0.194]
</p><p>54 As we require a fixed sized learning vector to build a model for learning word-  phone mapping rules, we need to align the letter (graphemic) and phone sequences. [sent-89, score-1.326]
</p><p>55 For this we use the automatic epsilon scattering method. [sent-90, score-0.26]
</p><p>56 1 Automatic Epsilon Scattering Method The idea in automatic epsilon scattering is to estimate the probabilities for one letter (grapheme) G to match with one phone P, and then use string alignment to introduce epsilons maximizing the probability of the word’s alignment path. [sent-92, score-0.944]
</p><p>57 The algorithm for automatic epsilon scattering is given below (Pagel et al. [sent-94, score-0.26]
</p><p>58 2  Evaluation and Results  Once the alignment between the each word and the corresponding phone sequence was complete, we built two phone models using Classification and Regression Trees (CART). [sent-97, score-1.103]
</p><p>59 For the first model, we used data from the CMU pronunciation dictionary where each English word had been aligned to a sequence of US English phones (EW-EP mapping). [sent-98, score-0.373]
</p><p>60 for each wordi in training set count with string alignment all possible G/P association for all possible epsilon positions in the phonetic transcription /* EM loop */ 2. [sent-100, score-0.222]
</p><p>61 for each wordi in traininYg set  alignment path = argmaxYP(Gi,Pj)  compute probnew(G,P) onYi, ajlignment path 3. [sent-101, score-0.07]
</p><p>62 if(prob6  =  prob  The second model was the EW-TP mapping. [sent-103, score-0.054]
</p><p>63 Once both the models had been built, they were used to predict the mapped phone sequences for each English word in the test data. [sent-104, score-0.524]
</p><p>64 For the purposes of testing, we performed the prediction on both held out test data as well as on test data from a different domain. [sent-105, score-0.076]
</p><p>65 The held out test data was prepared by removing every ninth word from the lex-  icon. [sent-106, score-0.074]
</p><p>66 As we knew the correct phone sequence for each word in the test data, a ground truth against which to compute the accuracy of prediction was available. [sent-107, score-0.696]
</p><p>67 We measured the accuracy of the prediction both at the letter level and at the word level. [sent-108, score-0.201]
</p><p>68 At the letter level, the accuracy was computed by counting the number of times the predicted letter to phone mapping matched with the ground truth. [sent-109, score-1.015]
</p><p>69 For computing the accuracy at the word level, we counted the number of times the predicted phone sequence of each word in the test data matched with the actual phone sequence for that word (derived from the ground truth). [sent-110, score-1.163]
</p><p>70 We also varied the size of the training data and then computed the prediction accuracy for each model. [sent-111, score-0.069]
</p><p>71 We did so in order to study the effect of training data size on the prediction accuracy. [sent-112, score-0.043]
</p><p>72 An examination of the results in the two tables shows that incrementally increasing the size of the training data results in an increase of the prediction accuracy. [sent-114, score-0.082]
</p><p>73 The native speakers of Indian lan-  guages prefer to speak what is written. [sent-115, score-0.146]
</p><p>74 As a result there are fewer variations in word-phone mapping as compared to US English. [sent-116, score-0.198]
</p><p>75 This is reflected in our results, which show that the word level prediction accuracy is higher for EW-TP mapping as compared to EW-EP mapping. [sent-117, score-0.267]
</p><p>76 198  - English phone mapping  Telugu phone mapping 4  Integrating word-phone mapping rules in TTS  For the purpose of perceptual evaluations we built a baseline TTS systems for Telugu using the HMM based speech synthesis technique (Zen et al. [sent-118, score-2.117]
</p><p>77 To conduct perceptual evaluations of the wordphone mapping rules built from data in 3. [sent-120, score-0.554]
</p><p>78 2, we incorporated these rules in our Telugu TTS system. [sent-121, score-0.032]
</p><p>79 A set of 25 bilingual sentences were synthesized by the Telugu TTS, and ten native speakers of Tel-  ugu performed perceptual evaluations on the synthesized utterances. [sent-123, score-0.748]
</p><p>80 As a baseline, we also synthesized the same 25 sentences by incorporating manually written word-phone mapping for the English words, instead of using the automatically generated word-phone mapping rules. [sent-124, score-0.584]
</p><p>81 The perceptual evaluations were set up both as MOS (mean opinion score) evaluations and as ABX evaluations. [sent-126, score-0.305]
</p><p>82 In the MOS evaluations, the listeners were asked to rate the synthesized utterances from all systems on a scale of 1to 5 (1being worst and 5 best), and the average scores for each system was calculated. [sent-127, score-0.348]
</p><p>83 In a typical ABX evaluation, the listeners are presented with the the same set of utterances synthesized using two systems A and B, and are asked to mark their preference for either A or B. [sent-129, score-0.374]
</p><p>84 The listeners also have an option of marking no preference. [sent-130, score-0.087]
</p><p>85 In this case, the listeners were asked to mark their preference between T A and T M. [sent-131, score-0.135]
</p><p>86 The results of the perceptual evaluations are shown in Table 5. [sent-132, score-0.226]
</p><p>87 /P2syr5e0ftms T M and T A  An examination of the results shows that perceptually there is no significant preference for the manual system over the automated system. [sent-136, score-0.099]
</p><p>88 5  Conclusions  In this paper we present a method of automatically learning word-phone mapping rules for synthesizing foreign words occurring in text. [sent-138, score-0.39]
</p><p>89 We show the effectiveness of the method by computing the accuracy of prediction and also by means of perceptual evaluations. [sent-139, score-0.216]
</p><p>90 The synthesized multilingual wave files are available for download at https : / /www . [sent-140, score-0.243]
</p><p>91 The authors would also like to thank all the native speakers who participated in the perceptual evaluations. [sent-145, score-0.293]
</p><p>92 In Proceedings ESCA/COCOSDA workshop on speech synthesis, Jenolan Caves, Australia. [sent-157, score-0.096]
</p><p>93 New approach to polygot speech generation by means of an HMM based speaker adaptable synthesizer. [sent-169, score-0.174]
</p><p>94 Letter to  sound rules for accented lexicon compression. [sent-177, score-0.077]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('phone', 0.498), ('telugu', 0.412), ('tts', 0.292), ('phones', 0.217), ('mapping', 0.198), ('synthesized', 0.188), ('epsilon', 0.152), ('mos', 0.152), ('synthesis', 0.149), ('polyglot', 0.147), ('perceptual', 0.147), ('letter', 0.132), ('phoneset', 0.123), ('scattering', 0.108), ('native', 0.105), ('pronunciation', 0.1), ('pronouncing', 0.1), ('abx', 0.098), ('speech', 0.096), ('foreign', 0.095), ('listeners', 0.087), ('evaluations', 0.079), ('iiit', 0.075), ('latorre', 0.074), ('wordphone', 0.074), ('india', 0.072), ('listening', 0.065), ('synthesizing', 0.065), ('speaker', 0.057), ('sequence', 0.056), ('multilingual', 0.055), ('phonemic', 0.054), ('prob', 0.054), ('hyderabad', 0.054), ('english', 0.053), ('utterances', 0.051), ('vision', 0.051), ('anandaswarup', 0.049), ('elluru', 0.049), ('probnew', 0.049), ('relook', 0.049), ('romaine', 0.049), ('traber', 0.049), ('wordi', 0.043), ('pagel', 0.043), ('waveform', 0.043), ('prediction', 0.043), ('lab', 0.041), ('prepared', 0.041), ('speakers', 0.041), ('hema', 0.04), ('sounding', 0.04), ('differentiates', 0.04), ('examination', 0.039), ('eurospeech', 0.038), ('zen', 0.038), ('raghavendra', 0.036), ('earch', 0.034), ('perceptually', 0.034), ('held', 0.033), ('uu', 0.033), ('campbell', 0.033), ('hmm', 0.033), ('rules', 0.032), ('correspondence', 0.031), ('ground', 0.029), ('mixing', 0.027), ('indian', 0.027), ('alignment', 0.027), ('mapped', 0.026), ('preference', 0.026), ('primary', 0.026), ('accuracy', 0.026), ('maps', 0.025), ('truth', 0.024), ('built', 0.024), ('fluent', 0.024), ('henceforth', 0.023), ('oxford', 0.023), ('sound', 0.023), ('asked', 0.022), ('keller', 0.022), ('mentally', 0.022), ('accented', 0.022), ('cart', 0.022), ('tiple', 0.022), ('graphemic', 0.022), ('isca', 0.022), ('lts', 0.022), ('pronounce', 0.022), ('generation', 0.021), ('substitution', 0.021), ('black', 0.02), ('accent', 0.02), ('itm', 0.02), ('huber', 0.02), ('lenzo', 0.02), ('knew', 0.02), ('mappings', 0.019), ('ipa', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="203-tfidf-1" href="./acl-2013-Is_word-to-phone_mapping_better_than_phone-phone_mapping_for_handling_English_words%3F.html">203 acl-2013-Is word-to-phone mapping better than phone-phone mapping for handling English words?</a></p>
<p>Author: Naresh Kumar Elluru ; Anandaswarup Vadapalli ; Raghavendra Elluru ; Hema Murthy ; Kishore Prahallad</p><p>Abstract: In this paper, we relook at the problem of pronunciation of English words using native phone set. Specifically, we investigate methods of pronouncing English words using Telugu phoneset in the con- text of Telugu Text-to-Speech. We compare phone-phone substitution and wordphone mapping for pronunciation of English words using Telugu phones. We are not considering other than native language phoneset in all our experiments. This differentiates our approach from other works in polyglot speech synthesis.</p><p>2 0.094750904 <a title="203-tfidf-2" href="./acl-2013-Two-Neighbor_Orientation_Model_with_Cross-Boundary_Global_Contexts.html">363 acl-2013-Two-Neighbor Orientation Model with Cross-Boundary Global Contexts</a></p>
<p>Author: Hendra Setiawan ; Bowen Zhou ; Bing Xiang ; Libin Shen</p><p>Abstract: Long distance reordering remains one of the greatest challenges in statistical machine translation research as the key contextual information may well be beyond the confine of translation units. In this paper, we propose Two-Neighbor Orientation (TNO) model that jointly models the orientation decisions between anchors and two neighboring multi-unit chunks which may cross phrase or rule boundaries. We explicitly model the longest span of such chunks, referred to as Maximal Orientation Span, to serve as a global parameter that constrains underlying local decisions. We integrate our proposed model into a state-of-the-art string-to-dependency translation system and demonstrate the efficacy of our proposal in a large-scale Chinese-to-English translation task. On NIST MT08 set, our most advanced model brings around +2.0 BLEU and -1.0 TER improvement.</p><p>3 0.068001717 <a title="203-tfidf-3" href="./acl-2013-Identification_of_Speakers_in_Novels.html">184 acl-2013-Identification of Speakers in Novels</a></p>
<p>Author: Hua He ; Denilson Barbosa ; Grzegorz Kondrak</p><p>Abstract: Speaker identification is the task of at- tributing utterances to characters in a literary narrative. It is challenging to auto- mate because the speakers of the majority ofutterances are not explicitly identified in novels. In this paper, we present a supervised machine learning approach for the task that incorporates several novel features. The experimental results show that our method is more accurate and general than previous approaches to the problem.</p><p>4 0.062980041 <a title="203-tfidf-4" href="./acl-2013-Computerized_Analysis_of_a_Verbal_Fluency_Test.html">89 acl-2013-Computerized Analysis of a Verbal Fluency Test</a></p>
<p>Author: James O. Ryan ; Serguei Pakhomov ; Susan Marino ; Charles Bernick ; Sarah Banks</p><p>Abstract: We present a system for automated phonetic clustering analysis of cognitive tests of phonemic verbal fluency, on which one must name words starting with a specific letter (e.g., ‘F’) for one minute. Test responses are typically subjected to manual phonetic clustering analysis that is labor-intensive and subject to inter-rater variability. Our system provides an automated alternative. In a pilot study, we applied this system to tests of 55 novice and experienced professional fighters (boxers and mixed martial artists) and found that experienced fighters produced significantly longer chains of phonetically similar words, while no differences were found in the total number of words produced. These findings are preliminary, but strongly suggest that our system can be used to detect subtle signs of brain damage due to repetitive head trauma in individuals that are otherwise unimpaired.</p><p>5 0.05451737 <a title="203-tfidf-5" href="./acl-2013-Meet_EDGAR%2C_a_tutoring_agent_at_MONSERRATE.html">239 acl-2013-Meet EDGAR, a tutoring agent at MONSERRATE</a></p>
<p>Author: Pedro Fialho ; Luisa Coheur ; Sergio Curto ; Pedro Claudio ; Angela Costa ; Alberto Abad ; Hugo Meinedo ; Isabel Trancoso</p><p>Abstract: In this paper we describe a platform for embodied conversational agents with tutoring goals, which takes as input written and spoken questions and outputs answers in both forms. The platform is developed within a game environment, and currently allows speech recognition and synthesis in Portuguese, English and Spanish. In this paper we focus on its understanding component that supports in-domain interactions, and also small talk. Most indomain interactions are answered using different similarity metrics, which compare the perceived utterances with questions/sentences in the agent’s knowledge base; small-talk capabilities are mainly due to AIML, a language largely used by the chatbots’ community. In this paper we also introduce EDGAR, the butler of MONSERRATE, which was developed in the aforementioned platform, and that answers tourists’ questions about MONSERRATE.</p><p>6 0.052713938 <a title="203-tfidf-6" href="./acl-2013-Simpler_unsupervised_POS_tagging_with_bilingual_projections.html">323 acl-2013-Simpler unsupervised POS tagging with bilingual projections</a></p>
<p>7 0.043334462 <a title="203-tfidf-7" href="./acl-2013-Grounded_Language_Learning_from_Video_Described_with_Sentences.html">175 acl-2013-Grounded Language Learning from Video Described with Sentences</a></p>
<p>8 0.039599292 <a title="203-tfidf-8" href="./acl-2013-Conditional_Random_Fields_for_Responsive_Surface_Realisation_using_Global_Features.html">90 acl-2013-Conditional Random Fields for Responsive Surface Realisation using Global Features</a></p>
<p>9 0.036523178 <a title="203-tfidf-9" href="./acl-2013-Training_Nondeficient_Variants_of_IBM-3_and_IBM-4_for_Word_Alignment.html">354 acl-2013-Training Nondeficient Variants of IBM-3 and IBM-4 for Word Alignment</a></p>
<p>10 0.035943415 <a title="203-tfidf-10" href="./acl-2013-Deceptive_Answer_Prediction_with_User_Preference_Graph.html">107 acl-2013-Deceptive Answer Prediction with User Preference Graph</a></p>
<p>11 0.035781849 <a title="203-tfidf-11" href="./acl-2013-Unsupervised_Consonant-Vowel_Prediction_over_Hundreds_of_Languages.html">369 acl-2013-Unsupervised Consonant-Vowel Prediction over Hundreds of Languages</a></p>
<p>12 0.033707116 <a title="203-tfidf-12" href="./acl-2013-Extracting_bilingual_terminologies_from_comparable_corpora.html">154 acl-2013-Extracting bilingual terminologies from comparable corpora</a></p>
<p>13 0.032392904 <a title="203-tfidf-13" href="./acl-2013-Implicatures_and_Nested_Beliefs_in_Approximate_Decentralized-POMDPs.html">190 acl-2013-Implicatures and Nested Beliefs in Approximate Decentralized-POMDPs</a></p>
<p>14 0.031244533 <a title="203-tfidf-14" href="./acl-2013-Reconstructing_an_Indo-European_Family_Tree_from_Non-native_English_Texts.html">299 acl-2013-Reconstructing an Indo-European Family Tree from Non-native English Texts</a></p>
<p>15 0.030931758 <a title="203-tfidf-15" href="./acl-2013-Evaluating_a_City_Exploration_Dialogue_System_with_Integrated_Question-Answering_and_Pedestrian_Navigation.html">141 acl-2013-Evaluating a City Exploration Dialogue System with Integrated Question-Answering and Pedestrian Navigation</a></p>
<p>16 0.030923035 <a title="203-tfidf-16" href="./acl-2013-Explicit_and_Implicit_Syntactic_Features_for_Text_Classification.html">144 acl-2013-Explicit and Implicit Syntactic Features for Text Classification</a></p>
<p>17 0.029799875 <a title="203-tfidf-17" href="./acl-2013-Leveraging_Domain-Independent_Information_in_Semantic_Parsing.html">228 acl-2013-Leveraging Domain-Independent Information in Semantic Parsing</a></p>
<p>18 0.029684676 <a title="203-tfidf-18" href="./acl-2013-Punctuation_Prediction_with_Transition-based_Parsing.html">288 acl-2013-Punctuation Prediction with Transition-based Parsing</a></p>
<p>19 0.029390268 <a title="203-tfidf-19" href="./acl-2013-IndoNet%3A_A_Multilingual_Lexical_Knowledge_Network_for_Indian_Languages.html">198 acl-2013-IndoNet: A Multilingual Lexical Knowledge Network for Indian Languages</a></p>
<p>20 0.028109429 <a title="203-tfidf-20" href="./acl-2013-Word_Alignment_Modeling_with_Context_Dependent_Deep_Neural_Network.html">388 acl-2013-Word Alignment Modeling with Context Dependent Deep Neural Network</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.077), (1, 0.006), (2, 0.01), (3, 0.002), (4, -0.009), (5, -0.024), (6, -0.003), (7, -0.014), (8, 0.01), (9, -0.003), (10, -0.043), (11, -0.018), (12, -0.027), (13, -0.019), (14, -0.028), (15, -0.051), (16, 0.002), (17, 0.016), (18, 0.015), (19, -0.028), (20, -0.053), (21, -0.04), (22, 0.057), (23, -0.044), (24, -0.009), (25, 0.044), (26, 0.014), (27, -0.018), (28, 0.005), (29, -0.014), (30, -0.018), (31, -0.019), (32, 0.016), (33, 0.034), (34, 0.033), (35, -0.006), (36, -0.013), (37, 0.034), (38, -0.047), (39, 0.089), (40, -0.024), (41, 0.052), (42, 0.002), (43, -0.011), (44, 0.031), (45, 0.01), (46, 0.08), (47, -0.033), (48, 0.04), (49, -0.049)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.89852333 <a title="203-lsi-1" href="./acl-2013-Is_word-to-phone_mapping_better_than_phone-phone_mapping_for_handling_English_words%3F.html">203 acl-2013-Is word-to-phone mapping better than phone-phone mapping for handling English words?</a></p>
<p>Author: Naresh Kumar Elluru ; Anandaswarup Vadapalli ; Raghavendra Elluru ; Hema Murthy ; Kishore Prahallad</p><p>Abstract: In this paper, we relook at the problem of pronunciation of English words using native phone set. Specifically, we investigate methods of pronouncing English words using Telugu phoneset in the con- text of Telugu Text-to-Speech. We compare phone-phone substitution and wordphone mapping for pronunciation of English words using Telugu phones. We are not considering other than native language phoneset in all our experiments. This differentiates our approach from other works in polyglot speech synthesis.</p><p>2 0.70902264 <a title="203-lsi-2" href="./acl-2013-Implicatures_and_Nested_Beliefs_in_Approximate_Decentralized-POMDPs.html">190 acl-2013-Implicatures and Nested Beliefs in Approximate Decentralized-POMDPs</a></p>
<p>Author: Adam Vogel ; Christopher Potts ; Dan Jurafsky</p><p>Abstract: Conversational implicatures involve reasoning about multiply nested belief structures. This complexity poses significant challenges for computational models of conversation and cognition. We show that agents in the multi-agent DecentralizedPOMDP reach implicature-rich interpretations simply as a by-product of the way they reason about each other to maximize joint utility. Our simulations involve a reference game of the sort studied in psychology and linguistics as well as a dynamic, interactional scenario involving implemented artificial agents.</p><p>3 0.69515896 <a title="203-lsi-3" href="./acl-2013-Identification_of_Speakers_in_Novels.html">184 acl-2013-Identification of Speakers in Novels</a></p>
<p>Author: Hua He ; Denilson Barbosa ; Grzegorz Kondrak</p><p>Abstract: Speaker identification is the task of at- tributing utterances to characters in a literary narrative. It is challenging to auto- mate because the speakers of the majority ofutterances are not explicitly identified in novels. In this paper, we present a supervised machine learning approach for the task that incorporates several novel features. The experimental results show that our method is more accurate and general than previous approaches to the problem.</p><p>4 0.55837107 <a title="203-lsi-4" href="./acl-2013-Computerized_Analysis_of_a_Verbal_Fluency_Test.html">89 acl-2013-Computerized Analysis of a Verbal Fluency Test</a></p>
<p>Author: James O. Ryan ; Serguei Pakhomov ; Susan Marino ; Charles Bernick ; Sarah Banks</p><p>Abstract: We present a system for automated phonetic clustering analysis of cognitive tests of phonemic verbal fluency, on which one must name words starting with a specific letter (e.g., ‘F’) for one minute. Test responses are typically subjected to manual phonetic clustering analysis that is labor-intensive and subject to inter-rater variability. Our system provides an automated alternative. In a pilot study, we applied this system to tests of 55 novice and experienced professional fighters (boxers and mixed martial artists) and found that experienced fighters produced significantly longer chains of phonetically similar words, while no differences were found in the total number of words produced. These findings are preliminary, but strongly suggest that our system can be used to detect subtle signs of brain damage due to repetitive head trauma in individuals that are otherwise unimpaired.</p><p>5 0.53750581 <a title="203-lsi-5" href="./acl-2013-An_Open_Source_Toolkit_for_Quantitative_Historical_Linguistics.html">48 acl-2013-An Open Source Toolkit for Quantitative Historical Linguistics</a></p>
<p>Author: Johann-Mattis List ; Steven Moran</p><p>Abstract: Given the increasing interest and development of computational and quantitative methods in historical linguistics, it is important that scholars have a basis for documenting, testing, evaluating, and sharing complex workflows. We present a novel open-source toolkit for quantitative tasks in historical linguistics that offers these features. This toolkit also serves as an interface between existing software packages and frequently used data formats, and it provides implementations of new and existing algorithms within a homogeneous framework. We illustrate the toolkit’s functionality with an exemplary workflow that starts with raw language data and ends with automatically calculated phonetic alignments, cognates and borrowings. We then illustrate evaluation metrics on gold standard datasets that are provided with the toolkit.</p><p>6 0.53037786 <a title="203-lsi-6" href="./acl-2013-Meet_EDGAR%2C_a_tutoring_agent_at_MONSERRATE.html">239 acl-2013-Meet EDGAR, a tutoring agent at MONSERRATE</a></p>
<p>7 0.52745372 <a title="203-lsi-7" href="./acl-2013-Conditional_Random_Fields_for_Responsive_Surface_Realisation_using_Global_Features.html">90 acl-2013-Conditional Random Fields for Responsive Surface Realisation using Global Features</a></p>
<p>8 0.48097306 <a title="203-lsi-8" href="./acl-2013-A_computational_approach_to_politeness_with_application_to_social_factors.html">30 acl-2013-A computational approach to politeness with application to social factors</a></p>
<p>9 0.47187012 <a title="203-lsi-9" href="./acl-2013-Unsupervised_Consonant-Vowel_Prediction_over_Hundreds_of_Languages.html">369 acl-2013-Unsupervised Consonant-Vowel Prediction over Hundreds of Languages</a></p>
<p>10 0.46907374 <a title="203-lsi-10" href="./acl-2013-Tag2Blog%3A_Narrative_Generation_from_Satellite_Tag_Data.html">337 acl-2013-Tag2Blog: Narrative Generation from Satellite Tag Data</a></p>
<p>11 0.45946968 <a title="203-lsi-11" href="./acl-2013-Sorani_Kurdish_versus_Kurmanji_Kurdish%3A_An_Empirical_Comparison.html">327 acl-2013-Sorani Kurdish versus Kurmanji Kurdish: An Empirical Comparison</a></p>
<p>12 0.45542204 <a title="203-lsi-12" href="./acl-2013-Reconstructing_an_Indo-European_Family_Tree_from_Non-native_English_Texts.html">299 acl-2013-Reconstructing an Indo-European Family Tree from Non-native English Texts</a></p>
<p>13 0.45192179 <a title="203-lsi-13" href="./acl-2013-Word_surprisal_predicts_N400_amplitude_during_reading.html">390 acl-2013-Word surprisal predicts N400 amplitude during reading</a></p>
<p>14 0.44910079 <a title="203-lsi-14" href="./acl-2013-Automatic_detection_of_deception_in_child-produced_speech_using_syntactic_complexity_features.html">63 acl-2013-Automatic detection of deception in child-produced speech using syntactic complexity features</a></p>
<p>15 0.44470257 <a title="203-lsi-15" href="./acl-2013-Combining_Referring_Expression_Generation_and_Surface_Realization%3A_A_Corpus-Based_Investigation_of_Architectures.html">86 acl-2013-Combining Referring Expression Generation and Surface Realization: A Corpus-Based Investigation of Architectures</a></p>
<p>16 0.44457081 <a title="203-lsi-16" href="./acl-2013-Typesetting_for_Improved_Readability_using_Lexical_and_Syntactic_Information.html">364 acl-2013-Typesetting for Improved Readability using Lexical and Syntactic Information</a></p>
<p>17 0.44007221 <a title="203-lsi-17" href="./acl-2013-Evaluating_a_City_Exploration_Dialogue_System_with_Integrated_Question-Answering_and_Pedestrian_Navigation.html">141 acl-2013-Evaluating a City Exploration Dialogue System with Integrated Question-Answering and Pedestrian Navigation</a></p>
<p>18 0.43553397 <a title="203-lsi-18" href="./acl-2013-Crawling_microblogging_services_to_gather_language-classified_URLs._Workflow_and_case_study.html">95 acl-2013-Crawling microblogging services to gather language-classified URLs. Workflow and case study</a></p>
<p>19 0.42552531 <a title="203-lsi-19" href="./acl-2013-Learning_Latent_Personas_of_Film_Characters.html">220 acl-2013-Learning Latent Personas of Film Characters</a></p>
<p>20 0.42064568 <a title="203-lsi-20" href="./acl-2013-Sign_Language_Lexical_Recognition_With_Propositional_Dynamic_Logic.html">321 acl-2013-Sign Language Lexical Recognition With Propositional Dynamic Logic</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.03), (6, 0.016), (11, 0.038), (24, 0.044), (26, 0.032), (28, 0.02), (35, 0.04), (42, 0.039), (48, 0.029), (70, 0.058), (88, 0.018), (90, 0.034), (94, 0.392), (95, 0.103)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.76228005 <a title="203-lda-1" href="./acl-2013-Is_word-to-phone_mapping_better_than_phone-phone_mapping_for_handling_English_words%3F.html">203 acl-2013-Is word-to-phone mapping better than phone-phone mapping for handling English words?</a></p>
<p>Author: Naresh Kumar Elluru ; Anandaswarup Vadapalli ; Raghavendra Elluru ; Hema Murthy ; Kishore Prahallad</p><p>Abstract: In this paper, we relook at the problem of pronunciation of English words using native phone set. Specifically, we investigate methods of pronouncing English words using Telugu phoneset in the con- text of Telugu Text-to-Speech. We compare phone-phone substitution and wordphone mapping for pronunciation of English words using Telugu phones. We are not considering other than native language phoneset in all our experiments. This differentiates our approach from other works in polyglot speech synthesis.</p><p>2 0.35715339 <a title="203-lda-2" href="./acl-2013-Name-aware_Machine_Translation.html">255 acl-2013-Name-aware Machine Translation</a></p>
<p>Author: Haibo Li ; Jing Zheng ; Heng Ji ; Qi Li ; Wen Wang</p><p>Abstract: We propose a Name-aware Machine Translation (MT) approach which can tightly integrate name processing into MT model, by jointly annotating parallel corpora, extracting name-aware translation grammar and rules, adding name phrase table and name translation driven decoding. Additionally, we also propose a new MT metric to appropriately evaluate the translation quality of informative words, by assigning different weights to different words according to their importance values in a document. Experiments on Chinese-English translation demonstrated the effectiveness of our approach on enhancing the quality of overall translation, name translation and word alignment over a high-quality MT baseline1 .</p><p>3 0.35703349 <a title="203-lda-3" href="./acl-2013-Social_Text_Normalization_using_Contextual_Graph_Random_Walks.html">326 acl-2013-Social Text Normalization using Contextual Graph Random Walks</a></p>
<p>Author: Hany Hassan ; Arul Menezes</p><p>Abstract: We introduce a social media text normalization system that can be deployed as a preprocessing step for Machine Translation and various NLP applications to handle social media text. The proposed system is based on unsupervised learning of the normalization equivalences from unlabeled text. The proposed approach uses Random Walks on a contextual similarity bipartite graph constructed from n-gram sequences on large unlabeled text corpus. We show that the proposed approach has a very high precision of (92.43) and a reasonable recall of (56.4). When used as a preprocessing step for a state-of-the-art machine translation system, the translation quality on social media text improved by 6%. The proposed approach is domain and language independent and can be deployed as a preprocessing step for any NLP application to handle social media text.</p><p>4 0.35676968 <a title="203-lda-4" href="./acl-2013-Microblogs_as_Parallel_Corpora.html">240 acl-2013-Microblogs as Parallel Corpora</a></p>
<p>Author: Wang Ling ; Guang Xiang ; Chris Dyer ; Alan Black ; Isabel Trancoso</p><p>Abstract: In the ever-expanding sea of microblog data, there is a surprising amount of naturally occurring parallel text: some users create post multilingual messages targeting international audiences while others “retweet” translations. We present an efficient method for detecting these messages and extracting parallel segments from them. We have been able to extract over 1M Chinese-English parallel segments from Sina Weibo (the Chinese counterpart of Twitter) using only their public APIs. As a supplement to existing parallel training data, our automatically extracted parallel data yields substantial translation quality improvements in translating microblog text and modest improvements in translating edited news commentary. The resources in described in this paper are available at http://www.cs.cmu.edu/∼lingwang/utopia.</p><p>5 0.35667503 <a title="203-lda-5" href="./acl-2013-Punctuation_Prediction_with_Transition-based_Parsing.html">288 acl-2013-Punctuation Prediction with Transition-based Parsing</a></p>
<p>Author: Dongdong Zhang ; Shuangzhi Wu ; Nan Yang ; Mu Li</p><p>Abstract: Punctuations are not available in automatic speech recognition outputs, which could create barriers to many subsequent text processing tasks. This paper proposes a novel method to predict punctuation symbols for the stream of words in transcribed speech texts. Our method jointly performs parsing and punctuation prediction by integrating a rich set of syntactic features when processing words from left to right. It can exploit a global view to capture long-range dependencies for punctuation prediction with linear complexity. The experimental results on the test data sets of IWSLT and TDT4 show that our method can achieve high-level performance in punctuation prediction over the stream of words in transcribed speech text. 1</p><p>6 0.3563931 <a title="203-lda-6" href="./acl-2013-Travatar%3A_A_Forest-to-String_Machine_Translation_Engine_based_on_Tree_Transducers.html">361 acl-2013-Travatar: A Forest-to-String Machine Translation Engine based on Tree Transducers</a></p>
<p>7 0.35539338 <a title="203-lda-7" href="./acl-2013-A_Tightly-coupled_Unsupervised_Clustering_and_Bilingual_Alignment_Model_for_Transliteration.html">25 acl-2013-A Tightly-coupled Unsupervised Clustering and Bilingual Alignment Model for Transliteration</a></p>
<p>8 0.3548758 <a title="203-lda-8" href="./acl-2013-Question_Classification_Transfer.html">292 acl-2013-Question Classification Transfer</a></p>
<p>9 0.35353684 <a title="203-lda-9" href="./acl-2013-Dirt_Cheap_Web-Scale_Parallel_Text_from_the_Common_Crawl.html">120 acl-2013-Dirt Cheap Web-Scale Parallel Text from the Common Crawl</a></p>
<p>10 0.35352975 <a title="203-lda-10" href="./acl-2013-Embedding_Semantic_Similarity_in_Tree_Kernels_for_Domain_Adaptation_of_Relation_Extraction.html">134 acl-2013-Embedding Semantic Similarity in Tree Kernels for Domain Adaptation of Relation Extraction</a></p>
<p>11 0.35300842 <a title="203-lda-11" href="./acl-2013-A_Decade_of_Automatic_Content_Evaluation_of_News_Summaries%3A_Reassessing_the_State_of_the_Art.html">5 acl-2013-A Decade of Automatic Content Evaluation of News Summaries: Reassessing the State of the Art</a></p>
<p>12 0.3527115 <a title="203-lda-12" href="./acl-2013-Dependency_Parser_Adaptation_with_Subtrees_from_Auto-Parsed_Target_Domain_Data.html">112 acl-2013-Dependency Parser Adaptation with Subtrees from Auto-Parsed Target Domain Data</a></p>
<p>13 0.35200953 <a title="203-lda-13" href="./acl-2013-Graph_Propagation_for_Paraphrasing_Out-of-Vocabulary_Words_in_Statistical_Machine_Translation.html">174 acl-2013-Graph Propagation for Paraphrasing Out-of-Vocabulary Words in Statistical Machine Translation</a></p>
<p>14 0.35181823 <a title="203-lda-14" href="./acl-2013-Fast_and_Accurate_Shift-Reduce_Constituent_Parsing.html">155 acl-2013-Fast and Accurate Shift-Reduce Constituent Parsing</a></p>
<p>15 0.35179222 <a title="203-lda-15" href="./acl-2013-PARMA%3A_A_Predicate_Argument_Aligner.html">267 acl-2013-PARMA: A Predicate Argument Aligner</a></p>
<p>16 0.350559 <a title="203-lda-16" href="./acl-2013-Cross-lingual_Projections_between_Languages_from_Different_Families.html">97 acl-2013-Cross-lingual Projections between Languages from Different Families</a></p>
<p>17 0.34909624 <a title="203-lda-17" href="./acl-2013-Learning_a_Phrase-based_Translation_Model_from_Monolingual_Data_with_Application_to_Domain_Adaptation.html">223 acl-2013-Learning a Phrase-based Translation Model from Monolingual Data with Application to Domain Adaptation</a></p>
<p>18 0.34789109 <a title="203-lda-18" href="./acl-2013-Enlisting_the_Ghost%3A_Modeling_Empty_Categories_for_Machine_Translation.html">137 acl-2013-Enlisting the Ghost: Modeling Empty Categories for Machine Translation</a></p>
<p>19 0.34770024 <a title="203-lda-19" href="./acl-2013-Joint_Inference_for_Fine-grained_Opinion_Extraction.html">207 acl-2013-Joint Inference for Fine-grained Opinion Extraction</a></p>
<p>20 0.34762529 <a title="203-lda-20" href="./acl-2013-Statistical_Machine_Translation_Improves_Question_Retrieval_in_Community_Question_Answering_via_Matrix_Factorization.html">329 acl-2013-Statistical Machine Translation Improves Question Retrieval in Community Question Answering via Matrix Factorization</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
