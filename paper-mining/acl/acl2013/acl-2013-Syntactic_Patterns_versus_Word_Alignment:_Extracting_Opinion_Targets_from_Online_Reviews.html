<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>336 acl-2013-Syntactic Patterns versus Word Alignment: Extracting Opinion Targets from Online Reviews</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-336" href="#">acl2013-336</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>336 acl-2013-Syntactic Patterns versus Word Alignment: Extracting Opinion Targets from Online Reviews</h1>
<br/><p>Source: <a title="acl-2013-336-pdf" href="http://aclweb.org/anthology//P/P13/P13-1172.pdf">pdf</a></p><p>Author: Kang Liu ; Liheng Xu ; Jun Zhao</p><p>Abstract: Mining opinion targets is a fundamental and important task for opinion mining from online reviews. To this end, there are usually two kinds of methods: syntax based and alignment based methods. Syntax based methods usually exploited syntactic patterns to extract opinion targets, which were however prone to suffer from parsing errors when dealing with online informal texts. In contrast, alignment based methods used word alignment model to fulfill this task, which could avoid parsing errors without using parsing. However, there is no research focusing on which kind of method is more better when given a certain amount of reviews. To fill this gap, this paper empiri- cally studies how the performance of these two kinds of methods vary when changing the size, domain and language of the corpus. We further combine syntactic patterns with alignment model by using a partially supervised framework and investigate whether this combination is useful or not. In our experiments, we verify that our combination is effective on the corpus with small and medium size.</p><p>Reference: <a title="acl-2013-336-reference" href="../acl2013_reference/acl-2013-Syntactic_Patterns_versus_Word_Alignment%3A_Extracting_Opinion_Targets_from_Online_Reviews_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 cn  Abstract Mining opinion targets is a fundamental and important task for opinion mining from online reviews. [sent-4, score-1.725]
</p><p>2 To this end, there are usually two kinds of methods: syntax based and alignment based methods. [sent-5, score-0.225]
</p><p>3 Syntax based methods usually exploited syntactic patterns to extract opinion targets, which were however prone to suffer from parsing errors when dealing with online informal texts. [sent-6, score-1.306]
</p><p>4 In contrast, alignment based methods used word alignment model to fulfill this task, which could avoid parsing errors without using parsing. [sent-7, score-0.393]
</p><p>5 However, there is no research focusing on which kind of method is more better when given a certain amount of reviews. [sent-8, score-0.056]
</p><p>6 To fill this gap, this paper empiri-  cally studies how the performance of these two kinds of methods vary when changing the size, domain and language of the corpus. [sent-9, score-0.061]
</p><p>7 We further combine syntactic patterns with alignment model by using a partially supervised framework and investigate whether this combination is useful or not. [sent-10, score-0.449]
</p><p>8 In our experiments, we verify that our combination is effective on the corpus with small and medium size. [sent-11, score-0.075]
</p><p>9 0, huge amount of user reviews are springing up on the Web. [sent-13, score-0.084]
</p><p>10 Mining opinions from these reviews become more and more urgent since that customers expect to obtain fine-grained information of products and manufacturers need to obtain immediate feedbacks from customers. [sent-14, score-0.283]
</p><p>11 In opinion mining, extracting opinion targets is a basic subtask. [sent-15, score-1.686]
</p><p>12 It is to extract a list of the objects which users express their opinions on and can provide the prior information of targets for opinion mining. [sent-16, score-1.088]
</p><p>13 To extract opinion targets, pervious approaches usually relied on opinion words which are the words used to express the opinions (Hu and Liu, 2004a; Popescu and Etzioni, 2005; Liu et al. [sent-18, score-1.521]
</p><p>14 Intuitively, opinion words often appear around and modify opinion targets, and there are opinion relations and associations between them. [sent-22, score-2.212]
</p><p>15 If we have known some words to be opinion words, the words which those opinion words modify will have high probability to be opinion targets. [sent-23, score-2.055]
</p><p>16 Therefore, identifying the aforementioned opinion relations between words is important for extracting opinion targets from reviews. [sent-24, score-1.796]
</p><p>17 To fulfill this aim, previous methods exploited the words co-occurrence information to indicate them (Hu and Liu, 2004a; Hu and Liu, 2004b). [sent-25, score-0.117]
</p><p>18 Obviously, these methods cannot obtain precise extraction because of the diverse expressions by reviewers, like long-span modified relations between words, etc. [sent-26, score-0.24]
</p><p>19 To handle this problem, several methods exploited syntactic information, where several heuristic pat-  terns based on syntactic parsing were designed (Popescu and Etzioni, 2005; Qiu et al. [sent-27, score-0.307]
</p><p>20 However, the sentences in online reviews usually have informal writing styles including grammar mistakes, typos, improper punctuation etc. [sent-30, score-0.191]
</p><p>21 As a result, the syntax-based methods which heavily depended on the parsing performance would suffer from parsing errors (Zhang et al. [sent-32, score-0.196]
</p><p>22 To improve the extraction performance, we can only employ some exquisite highprecision patterns. [sent-34, score-0.153]
</p><p>23 But this strategy is likely to miss many opinion targets and has lower recall with the increase of corpus size. [sent-35, score-1.035]
</p><p>24 (2012) formulated identifying opinion relations between words as an monolingual alignment process. [sent-37, score-0.925]
</p><p>25 A word can find its corresponding modifiers by using a word alignment 1754  Proce dingsS o f ita h,e B 5u1lgsta Arinan,u Aaulg Musete 4ti-n9g 2 o0f1 t3h. [sent-38, score-0.162]
</p><p>26 Without using syntactic parsing, the noises from parsing errors can be effectively avoided. [sent-41, score-0.196]
</p><p>27 Nevertheless, we notice that the alignment model is a statistical model which needs sufficient data to estimate parameters. [sent-42, score-0.182]
</p><p>28 When the data is insufficient, it would suffer from data sparseness and may make the performance decline. [sent-43, score-0.035]
</p><p>29 And which kind of methods can obtain better extraction performance with the variation of the size of the dataset? [sent-45, score-0.181]
</p><p>30 , 2012) had proved the effectiveness of WAM, they mainly performed experiments on the dataset with medium size. [sent-47, score-0.075]
</p><p>31 We are still curious about that when the size of dataset is larger or smaller, can we obtain the same conclusion? [sent-48, score-0.062]
</p><p>32 Moreover, opinions may be expressed in different ways with the variation of the domain and language of the corpus. [sent-50, score-0.072]
</p><p>33 To answer these questions, in this paper, we adopt a unified framework to extract opinion targets from reviews, in the key component of which we vary the methods between syntactic patterns and alignment model. [sent-52, score-1.481]
</p><p>34 Then we run the whole framework on the corpus with different size (from #500 to #1, 000, 000), domain (three domains) and language (Chinese and English) to empirically assess the performance variations and discuss which method is more effective. [sent-53, score-0.026]
</p><p>35 Furthermore, this paper naturally addresses another question: is it useful for opinion targets extraction when we combine syntactic patterns and word alignment model into a unified model? [sent-54, score-1.427]
</p><p>36 To this end, we employ a partially supervised alignment model (PSWAM) like (Gao et al. [sent-55, score-0.252]
</p><p>37 Based on the exquisitely designed high-precision syntactic patterns, we can obtain  some precisely modified relations between words in sentences, which provide a portion of links of the full alignments. [sent-58, score-0.298]
</p><p>38 Then, these partial alignment links can be regarded as the constrains for a standard unsupervised word alignment model. [sent-59, score-0.392]
</p><p>39 And each target candidate would find its modifier under the partial supervision. [sent-60, score-0.119]
</p><p>40 In this way, the errors generated in standard unsupervised WAM can be corrected. [sent-61, score-0.069]
</p><p>41 For example in Figure 1, “kindly” and “courteous” are incorrectly regarded as the modifiers for “foods” if the WAM is performed in an whole unsupervised framework. [sent-62, score-0.123]
</p><p>42 However, by using some high-precision syntactic patterns, we can assert “courteous” should be aligned to “services”, and “delicious” should be aligned to “foods”. [sent-63, score-0.098]
</p><p>43 Through combination under partial supervision, we can see “kindly” and “courteous” are correctly linked to “services”. [sent-64, score-0.035]
</p><p>44 , 2013), using PSWAM can not only inherit the advantages of WAM: effectively avoiding noises from syntactic parsing errors when dealing with  informal texts, but also can improve the mining performance by using partial supervision. [sent-67, score-0.38]
</p><p>45 However, is this kind of combination always useful for opinion target extraction? [sent-68, score-0.772]
</p><p>46 To access this problem, we also make comparison between PSWAM based method and the aforementioned methods in the same corpora with different size, language and domain. [sent-69, score-0.031]
</p><p>47 The experimental results show the combination by using PSWAM can be effective on dataset with small and medium size. [sent-70, score-0.075]
</p><p>48 1755  2  Related Work  Opinion target extraction isn’t a new task for opinion mining. [sent-71, score-0.8]
</p><p>49 There are much work focusing on this task, such as (Hu and Liu, 2004b; Ding et al. [sent-72, score-0.025]
</p><p>50 Totally, previous studies can be divided into two main categories: supervised and unsupervised methods. [sent-76, score-0.076]
</p><p>51 In supervised approaches, the opinion target extraction task was usually regarded as a sequence labeling problem (Jin and Huang, 2009; Li et al. [sent-77, score-0.937]
</p><p>52 It’s not only to extract a lexicon or list of opinion targets, but also to find out each opinion target mentions in reviews. [sent-81, score-1.47]
</p><p>53 Thus, the contextual words are usually selected as the features to indicate opinion targets in sentences. [sent-82, score-1.037]
</p><p>54 (2009) proposed a lexicalized HMM model to perform opinion mining. [sent-87, score-0.685]
</p><p>55 (2010) used CRFs model to extract opinion targets in reviews. [sent-90, score-1.045]
</p><p>56 proposed a Skip-Tree CRF model for opinion target extraction, which exploited three structures including linear-chain structure, syntactic structure, and conjunction structure. [sent-92, score-0.885]
</p><p>57 However, the main limitation of these supervised methods is the need of labeled training data. [sent-93, score-0.068]
</p><p>58 If the labeled training data is insufficient, the trained model would have unsatisfied extraction performance. [sent-94, score-0.059]
</p><p>59 And for different domains, we need label data independently,  which is obviously impracticable. [sent-96, score-0.03]
</p><p>60 Thus, many researches focused on unsupervised methods, which are mainly to extract a list of opinion targets from reviews. [sent-97, score-1.079]
</p><p>61 Similar to ours, most approaches regarded opinion words as the indicator for opinion targets. [sent-98, score-1.429]
</p><p>62 (Hu and Liu, 2004a) regarded the nearest adjective to an noun/noun phrase as its modifier. [sent-99, score-0.113]
</p><p>63 Then it exploited an association rule mining algorithm to mine the associations between them. [sent-100, score-0.221]
</p><p>64 Only using nearest neighbor rule to mine the modifier for each candidate cannot obtain precise results. [sent-102, score-0.148]
</p><p>65 Thus, (Popescu and Etzioni, 2005) used syntax information to extract opinion targets, which designed some syntactic patterns to capture the modified relations between words. [sent-103, score-1.184]
</p><p>66 , 2011) proposed a Double Propagation method to expand sentiment words and opinion targets iteratively, where they also exploited syn-  tactic relations between words. [sent-106, score-1.201]
</p><p>67 , 2011) didn’t only design syntactic patterns for capturing modified relations, but also designed patterns for capturing relations among opinion targets and relations among opinion words. [sent-108, score-2.389]
</p><p>68 However, the main limitation of Qiu’s method is that the patterns based on dependency parsing tree may miss many targets for the large corpora. [sent-109, score-0.625]
</p><p>69 Besides the patterns used in Qiu’s method, they adopted some other special designed patterns to increase recall. [sent-112, score-0.368]
</p><p>70 In addition they used the HITS (Kleinberg, 1999) algorithm to compute opinion target confidences to improve the precision. [sent-113, score-0.766]
</p><p>71 , 2012) formulated identifying opinion relations between words as an alignment process. [sent-115, score-0.925]
</p><p>72 They used a completely unsupervised WAM to capture opinion relations in sentences. [sent-116, score-0.827]
</p><p>73 Then the opinion targets were extracted in a standard random walk framework where two factors were considered: opinion relevance and target importance. [sent-117, score-1.774]
</p><p>74 , 2013) extend Liu’s method, which is similar to our method and also used a partially supervised alignment model to extract opinion targets from reviews. [sent-120, score-1.259]
</p><p>75 , 2013)) only performed experiments on the corpora with a medium size. [sent-123, score-0.075]
</p><p>76 Although both of them proved that WAM model is better than the methods based on syntactic patterns, they didn’t discuss the performance variation when dealing with the corpora with different sizes, especially when the size of the corpus is less than 1,000 and more than 10,000. [sent-124, score-0.168]
</p><p>77 Based on their conclusions, we still don’t know which kind of methods should be selected for opinion target extraction when given a certain amount of reviews. [sent-125, score-0.831]
</p><p>78 3  Opinion Target Extraction Methodology  To extract opinion targets from reviews, we adopt the framework proposed by (Liu et al. [sent-126, score-1.045]
</p><p>79 , 2012), which is a graph-based extraction framework and 1756  has two main components as follows. [sent-127, score-0.059]
</p><p>80 1) The first component is to capture opinion relations in sentences and estimate associations between opinion target candidates and potential opinion words. [sent-128, score-2.41]
</p><p>81 In this paper, we assume opinion targets to be nouns or noun phrases, and opinion words may be adjectives or verbs, which are usually adopted by (Hu and Liu, 2004a; Qiu et al. [sent-129, score-1.722]
</p><p>82 And a potential opinion relation is comprised of an opinion target candidate and its corresponding modified word. [sent-132, score-1.494]
</p><p>83 2) The second component is to estimate the confidence of each candidate. [sent-133, score-0.087]
</p><p>84 The candidates with higher confidence scores than a threshold will be extracted as opinion targets. [sent-134, score-0.736]
</p><p>85 In this procedure, we formulate the associations between opinion target candidates and potential opinion words in a bipartite graph. [sent-135, score-1.556]
</p><p>86 A random walk based algorithm is employed on this graph to estimate the confidence of each target candidate. [sent-136, score-0.139]
</p><p>87 In this paper, we fix the method in the sec-  ond component and vary the algorithms in the first component. [sent-137, score-0.069]
</p><p>88 In the first component, we respectively use syntactic patterns and unsupervised word alignment model (WAM) to capture opinion relations. [sent-138, score-1.115]
</p><p>89 In addition, we employ a partially supervised word alignment model (PSWAM) to incorporate syntactic information into WAM. [sent-139, score-0.324]
</p><p>90 1 Syntactic Patterns To capture opinion relations in sentences by using syntactic patterns, we employ the manual designed syntactic patterns proposed by (Qiu et al. [sent-145, score-1.18]
</p><p>91 Similar to Qiu, only the syntactic patterns based on the direct dependency are employed to guarantee the extraction qualities. [sent-147, score-0.359]
</p><p>92 The first type indicates that  one word depends on the other word without any additional words in their dependency path. [sent-149, score-0.037]
</p><p>93 htm tactic patterns precisely, we only use a few dependency relation labels outputted by Minipar, such as mod, pnmod, subj, desc etc. [sent-156, score-0.277]
</p><p>94 To make a clear explanation, we give out some syntactic pattern examples in Table 1. [sent-157, score-0.072]
</p><p>95 In these patterns, OC is a potential opinion word which is an adjective or a verb. [sent-158, score-0.739]
</p><p>96 TC is an opinion target candidate which is a noun or noun phrase. [sent-159, score-0.741]
</p><p>97 The item on the arrows means the dependency relation type. [sent-160, score-0.071]
</p><p>98 The item in parenthesis denotes the part-of-speech of the other word. [sent-161, score-0.034]
</p><p>99 In these examples, the first three patterns are based on the first direct dependency type and the last two patterns are based on the second direct dependency type. [sent-162, score-0.456]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('opinion', 0.685), ('targets', 0.316), ('wam', 0.288), ('qiu', 0.229), ('patterns', 0.163), ('pswam', 0.16), ('liu', 0.135), ('alignment', 0.132), ('courteous', 0.096), ('hu', 0.088), ('reviews', 0.084), ('relations', 0.079), ('associations', 0.078), ('medium', 0.075), ('syntactic', 0.072), ('exploited', 0.072), ('popescu', 0.071), ('etzioni', 0.06), ('extraction', 0.059), ('regarded', 0.059), ('foods', 0.057), ('target', 0.056), ('kindly', 0.052), ('tactic', 0.049), ('parsing', 0.049), ('jin', 0.049), ('fulfill', 0.045), ('extract', 0.044), ('opinions', 0.043), ('informal', 0.043), ('supervised', 0.042), ('designed', 0.042), ('specially', 0.042), ('dealing', 0.041), ('modified', 0.041), ('noises', 0.04), ('partially', 0.04), ('insufficient', 0.039), ('mining', 0.039), ('employ', 0.038), ('didn', 0.037), ('dependency', 0.037), ('component', 0.036), ('usually', 0.036), ('obtain', 0.036), ('suffer', 0.035), ('errors', 0.035), ('partial', 0.035), ('unsupervised', 0.034), ('item', 0.034), ('miss', 0.034), ('vary', 0.033), ('walk', 0.032), ('mine', 0.032), ('capturing', 0.032), ('kind', 0.031), ('prone', 0.031), ('aforementioned', 0.031), ('obviously', 0.03), ('modifiers', 0.03), ('crfs', 0.03), ('services', 0.03), ('syntax', 0.029), ('variation', 0.029), ('formulated', 0.029), ('capture', 0.029), ('hmm', 0.029), ('kinds', 0.028), ('improper', 0.028), ('exquisite', 0.028), ('manufacturers', 0.028), ('highprecision', 0.028), ('depended', 0.028), ('feedbacks', 0.028), ('lhxu', 0.028), ('liheng', 0.028), ('pervious', 0.028), ('desc', 0.028), ('urgent', 0.028), ('precisely', 0.028), ('direct', 0.028), ('modifier', 0.028), ('potential', 0.027), ('adjective', 0.027), ('nearest', 0.027), ('limitation', 0.026), ('inherit', 0.026), ('assert', 0.026), ('typos', 0.026), ('confidence', 0.026), ('size', 0.026), ('li', 0.026), ('wang', 0.025), ('focusing', 0.025), ('estimate', 0.025), ('precise', 0.025), ('notice', 0.025), ('delicious', 0.025), ('confidences', 0.025), ('candidates', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="336-tfidf-1" href="./acl-2013-Syntactic_Patterns_versus_Word_Alignment%3A_Extracting_Opinion_Targets_from_Online_Reviews.html">336 acl-2013-Syntactic Patterns versus Word Alignment: Extracting Opinion Targets from Online Reviews</a></p>
<p>Author: Kang Liu ; Liheng Xu ; Jun Zhao</p><p>Abstract: Mining opinion targets is a fundamental and important task for opinion mining from online reviews. To this end, there are usually two kinds of methods: syntax based and alignment based methods. Syntax based methods usually exploited syntactic patterns to extract opinion targets, which were however prone to suffer from parsing errors when dealing with online informal texts. In contrast, alignment based methods used word alignment model to fulfill this task, which could avoid parsing errors without using parsing. However, there is no research focusing on which kind of method is more better when given a certain amount of reviews. To fill this gap, this paper empiri- cally studies how the performance of these two kinds of methods vary when changing the size, domain and language of the corpus. We further combine syntactic patterns with alignment model by using a partially supervised framework and investigate whether this combination is useful or not. In our experiments, we verify that our combination is effective on the corpus with small and medium size.</p><p>2 0.7619673 <a title="336-tfidf-2" href="./acl-2013-Mining_Opinion_Words_and_Opinion_Targets_in_a_Two-Stage_Framework.html">244 acl-2013-Mining Opinion Words and Opinion Targets in a Two-Stage Framework</a></p>
<p>Author: Liheng Xu ; Kang Liu ; Siwei Lai ; Yubo Chen ; Jun Zhao</p><p>Abstract: This paper proposes a novel two-stage method for mining opinion words and opinion targets. In the first stage, we propose a Sentiment Graph Walking algorithm, which naturally incorporates syntactic patterns in a Sentiment Graph to extract opinion word/target candidates. Then random walking is employed to estimate confidence of candidates, which improves extraction accuracy by considering confidence of patterns. In the second stage, we adopt a self-learning strategy to refine the results from the first stage, especially for filtering out high-frequency noise terms and capturing the long-tail terms, which are not investigated by previous methods. The experimental results on three real world datasets demonstrate the effectiveness of our approach compared with stateof-the-art unsupervised methods.</p><p>3 0.66660267 <a title="336-tfidf-3" href="./acl-2013-Joint_Inference_for_Fine-grained_Opinion_Extraction.html">207 acl-2013-Joint Inference for Fine-grained Opinion Extraction</a></p>
<p>Author: Bishan Yang ; Claire Cardie</p><p>Abstract: This paper addresses the task of finegrained opinion extraction the identification of opinion-related entities: the opinion expressions, the opinion holders, and the targets of the opinions, and the relations between opinion expressions and their targets and holders. Most existing approaches tackle the extraction of opinion entities and opinion relations in a pipelined manner, where the interdependencies among different extraction stages are not captured. We propose a joint inference model that leverages knowledge from predictors that optimize subtasks – of opinion extraction, and seeks a globally optimal solution. Experimental results demonstrate that our joint inference approach significantly outperforms traditional pipeline methods and baselines that tackle subtasks in isolation for the problem of opinion extraction.</p><p>4 0.33543181 <a title="336-tfidf-4" href="./acl-2013-Identifying_Opinion_Subgroups_in_Arabic_Online_Discussions.html">187 acl-2013-Identifying Opinion Subgroups in Arabic Online Discussions</a></p>
<p>Author: Amjad Abu-Jbara ; Ben King ; Mona Diab ; Dragomir Radev</p><p>Abstract: In this paper, we use Arabic natural language processing techniques to analyze Arabic debates. The goal is to identify how the participants in a discussion split into subgroups with contrasting opinions. The members of each subgroup share the same opinion with respect to the discussion topic and an opposing opinion to the members of other subgroups. We use opinion mining techniques to identify opinion expressions and determine their polarities and their targets. We opinion predictions to represent the discussion in one of two formal representations: signed attitude network or a space of attitude vectors. We identify opinion subgroups by partitioning the signed network representation or by clustering the vector space representation. We evaluate the system using a data set of labeled discussions and show that it achieves good results.</p><p>5 0.17181838 <a title="336-tfidf-5" href="./acl-2013-Bi-directional_Inter-dependencies_of_Subjective_Expressions_and_Targets_and_their_Value_for_a_Joint_Model.html">67 acl-2013-Bi-directional Inter-dependencies of Subjective Expressions and Targets and their Value for a Joint Model</a></p>
<p>Author: Roman Klinger ; Philipp Cimiano</p><p>Abstract: Opinion mining is often regarded as a classification or segmentation task, involving the prediction of i) subjective expressions, ii) their target and iii) their polarity. Intuitively, these three variables are bidirectionally interdependent, but most work has either attempted to predict them in isolation or proposing pipeline-based approaches that cannot model the bidirectional interaction between these variables. Towards better understanding the interaction between these variables, we propose a model that allows for analyzing the relation of target and subjective phrases in both directions, thus providing an upper bound for the impact of a joint model in comparison to a pipeline model. We report results on two public datasets (cameras and cars), showing that our model outperforms state-ofthe-art models, as well as on a new dataset consisting of Twitter posts.</p><p>6 0.14597644 <a title="336-tfidf-6" href="./acl-2013-An_annotated_corpus_of_quoted_opinions_in_news_articles.html">49 acl-2013-An annotated corpus of quoted opinions in news articles</a></p>
<p>7 0.1348789 <a title="336-tfidf-7" href="./acl-2013-Detecting_Chronic_Critics_Based_on_Sentiment_Polarity_and_User%C3%A2%E2%80%A2%C5%BDs_Behavior_in_Social_Media.html">114 acl-2013-Detecting Chronic Critics Based on Sentiment Polarity and Userâ•Žs Behavior in Social Media</a></p>
<p>8 0.11110835 <a title="336-tfidf-8" href="./acl-2013-Exploiting_Topic_based_Twitter_Sentiment_for_Stock_Prediction.html">147 acl-2013-Exploiting Topic based Twitter Sentiment for Stock Prediction</a></p>
<p>9 0.10592078 <a title="336-tfidf-9" href="./acl-2013-LABR%3A_A_Large_Scale_Arabic_Book_Reviews_Dataset.html">211 acl-2013-LABR: A Large Scale Arabic Book Reviews Dataset</a></p>
<p>10 0.083816081 <a title="336-tfidf-10" href="./acl-2013-Non-Monotonic_Sentence_Alignment_via_Semisupervised_Learning.html">259 acl-2013-Non-Monotonic Sentence Alignment via Semisupervised Learning</a></p>
<p>11 0.081799112 <a title="336-tfidf-11" href="./acl-2013-Utterance-Level_Multimodal_Sentiment_Analysis.html">379 acl-2013-Utterance-Level Multimodal Sentiment Analysis</a></p>
<p>12 0.075331055 <a title="336-tfidf-12" href="./acl-2013-Detecting_Turnarounds_in_Sentiment_Analysis%3A_Thwarting.html">117 acl-2013-Detecting Turnarounds in Sentiment Analysis: Thwarting</a></p>
<p>13 0.074437186 <a title="336-tfidf-13" href="./acl-2013-Discovering_User_Interactions_in_Ideological_Discussions.html">121 acl-2013-Discovering User Interactions in Ideological Discussions</a></p>
<p>14 0.071135245 <a title="336-tfidf-14" href="./acl-2013-A_Bayesian_Model_for_Joint_Unsupervised_Induction_of_Sentiment%2C_Aspect_and_Discourse_Representations.html">2 acl-2013-A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations</a></p>
<p>15 0.070410073 <a title="336-tfidf-15" href="./acl-2013-A_Novel_Graph-based_Compact_Representation_of_Word_Alignment.html">15 acl-2013-A Novel Graph-based Compact Representation of Word Alignment</a></p>
<p>16 0.067305803 <a title="336-tfidf-16" href="./acl-2013-TopicSpam%3A_a_Topic-Model_based_approach_for_spam_detection.html">350 acl-2013-TopicSpam: a Topic-Model based approach for spam detection</a></p>
<p>17 0.063946694 <a title="336-tfidf-17" href="./acl-2013-A_Lightweight_and_High_Performance_Monolingual_Word_Aligner.html">9 acl-2013-A Lightweight and High Performance Monolingual Word Aligner</a></p>
<p>18 0.060933173 <a title="336-tfidf-18" href="./acl-2013-A_Tightly-coupled_Unsupervised_Clustering_and_Bilingual_Alignment_Model_for_Transliteration.html">25 acl-2013-A Tightly-coupled Unsupervised Clustering and Bilingual Alignment Model for Transliteration</a></p>
<p>19 0.059579704 <a title="336-tfidf-19" href="./acl-2013-Word_Alignment_Modeling_with_Context_Dependent_Deep_Neural_Network.html">388 acl-2013-Word Alignment Modeling with Context Dependent Deep Neural Network</a></p>
<p>20 0.058697578 <a title="336-tfidf-20" href="./acl-2013-Extracting_Definitions_and_Hypernym_Relations_relying_on_Syntactic_Dependencies_and_Support_Vector_Machines.html">152 acl-2013-Extracting Definitions and Hypernym Relations relying on Syntactic Dependencies and Support Vector Machines</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.178), (1, 0.209), (2, -0.078), (3, 0.302), (4, -0.175), (5, 0.255), (6, -0.472), (7, -0.237), (8, -0.232), (9, -0.179), (10, -0.272), (11, 0.08), (12, 0.054), (13, 0.008), (14, 0.006), (15, -0.014), (16, -0.038), (17, 0.006), (18, -0.012), (19, -0.057), (20, 0.036), (21, -0.012), (22, 0.015), (23, -0.084), (24, -0.033), (25, -0.013), (26, 0.021), (27, 0.043), (28, -0.004), (29, 0.054), (30, -0.007), (31, 0.023), (32, -0.015), (33, 0.023), (34, -0.016), (35, -0.027), (36, -0.036), (37, 0.024), (38, 0.037), (39, -0.002), (40, -0.044), (41, -0.004), (42, -0.021), (43, 0.038), (44, -0.011), (45, -0.021), (46, 0.014), (47, 0.055), (48, 0.016), (49, 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.98617649 <a title="336-lsi-1" href="./acl-2013-Mining_Opinion_Words_and_Opinion_Targets_in_a_Two-Stage_Framework.html">244 acl-2013-Mining Opinion Words and Opinion Targets in a Two-Stage Framework</a></p>
<p>Author: Liheng Xu ; Kang Liu ; Siwei Lai ; Yubo Chen ; Jun Zhao</p><p>Abstract: This paper proposes a novel two-stage method for mining opinion words and opinion targets. In the first stage, we propose a Sentiment Graph Walking algorithm, which naturally incorporates syntactic patterns in a Sentiment Graph to extract opinion word/target candidates. Then random walking is employed to estimate confidence of candidates, which improves extraction accuracy by considering confidence of patterns. In the second stage, we adopt a self-learning strategy to refine the results from the first stage, especially for filtering out high-frequency noise terms and capturing the long-tail terms, which are not investigated by previous methods. The experimental results on three real world datasets demonstrate the effectiveness of our approach compared with stateof-the-art unsupervised methods.</p><p>same-paper 2 0.98133385 <a title="336-lsi-2" href="./acl-2013-Syntactic_Patterns_versus_Word_Alignment%3A_Extracting_Opinion_Targets_from_Online_Reviews.html">336 acl-2013-Syntactic Patterns versus Word Alignment: Extracting Opinion Targets from Online Reviews</a></p>
<p>Author: Kang Liu ; Liheng Xu ; Jun Zhao</p><p>Abstract: Mining opinion targets is a fundamental and important task for opinion mining from online reviews. To this end, there are usually two kinds of methods: syntax based and alignment based methods. Syntax based methods usually exploited syntactic patterns to extract opinion targets, which were however prone to suffer from parsing errors when dealing with online informal texts. In contrast, alignment based methods used word alignment model to fulfill this task, which could avoid parsing errors without using parsing. However, there is no research focusing on which kind of method is more better when given a certain amount of reviews. To fill this gap, this paper empiri- cally studies how the performance of these two kinds of methods vary when changing the size, domain and language of the corpus. We further combine syntactic patterns with alignment model by using a partially supervised framework and investigate whether this combination is useful or not. In our experiments, we verify that our combination is effective on the corpus with small and medium size.</p><p>3 0.96077025 <a title="336-lsi-3" href="./acl-2013-Joint_Inference_for_Fine-grained_Opinion_Extraction.html">207 acl-2013-Joint Inference for Fine-grained Opinion Extraction</a></p>
<p>Author: Bishan Yang ; Claire Cardie</p><p>Abstract: This paper addresses the task of finegrained opinion extraction the identification of opinion-related entities: the opinion expressions, the opinion holders, and the targets of the opinions, and the relations between opinion expressions and their targets and holders. Most existing approaches tackle the extraction of opinion entities and opinion relations in a pipelined manner, where the interdependencies among different extraction stages are not captured. We propose a joint inference model that leverages knowledge from predictors that optimize subtasks – of opinion extraction, and seeks a globally optimal solution. Experimental results demonstrate that our joint inference approach significantly outperforms traditional pipeline methods and baselines that tackle subtasks in isolation for the problem of opinion extraction.</p><p>4 0.74049497 <a title="336-lsi-4" href="./acl-2013-Identifying_Opinion_Subgroups_in_Arabic_Online_Discussions.html">187 acl-2013-Identifying Opinion Subgroups in Arabic Online Discussions</a></p>
<p>Author: Amjad Abu-Jbara ; Ben King ; Mona Diab ; Dragomir Radev</p><p>Abstract: In this paper, we use Arabic natural language processing techniques to analyze Arabic debates. The goal is to identify how the participants in a discussion split into subgroups with contrasting opinions. The members of each subgroup share the same opinion with respect to the discussion topic and an opposing opinion to the members of other subgroups. We use opinion mining techniques to identify opinion expressions and determine their polarities and their targets. We opinion predictions to represent the discussion in one of two formal representations: signed attitude network or a space of attitude vectors. We identify opinion subgroups by partitioning the signed network representation or by clustering the vector space representation. We evaluate the system using a data set of labeled discussions and show that it achieves good results.</p><p>5 0.57084423 <a title="336-lsi-5" href="./acl-2013-Bi-directional_Inter-dependencies_of_Subjective_Expressions_and_Targets_and_their_Value_for_a_Joint_Model.html">67 acl-2013-Bi-directional Inter-dependencies of Subjective Expressions and Targets and their Value for a Joint Model</a></p>
<p>Author: Roman Klinger ; Philipp Cimiano</p><p>Abstract: Opinion mining is often regarded as a classification or segmentation task, involving the prediction of i) subjective expressions, ii) their target and iii) their polarity. Intuitively, these three variables are bidirectionally interdependent, but most work has either attempted to predict them in isolation or proposing pipeline-based approaches that cannot model the bidirectional interaction between these variables. Towards better understanding the interaction between these variables, we propose a model that allows for analyzing the relation of target and subjective phrases in both directions, thus providing an upper bound for the impact of a joint model in comparison to a pipeline model. We report results on two public datasets (cameras and cars), showing that our model outperforms state-ofthe-art models, as well as on a new dataset consisting of Twitter posts.</p><p>6 0.56277245 <a title="336-lsi-6" href="./acl-2013-An_annotated_corpus_of_quoted_opinions_in_news_articles.html">49 acl-2013-An annotated corpus of quoted opinions in news articles</a></p>
<p>7 0.54735047 <a title="336-lsi-7" href="./acl-2013-Detecting_Chronic_Critics_Based_on_Sentiment_Polarity_and_User%C3%A2%E2%80%A2%C5%BDs_Behavior_in_Social_Media.html">114 acl-2013-Detecting Chronic Critics Based on Sentiment Polarity and Userâ•Žs Behavior in Social Media</a></p>
<p>8 0.28442058 <a title="336-lsi-8" href="./acl-2013-Detecting_Turnarounds_in_Sentiment_Analysis%3A_Thwarting.html">117 acl-2013-Detecting Turnarounds in Sentiment Analysis: Thwarting</a></p>
<p>9 0.24565808 <a title="336-lsi-9" href="./acl-2013-TopicSpam%3A_a_Topic-Model_based_approach_for_spam_detection.html">350 acl-2013-TopicSpam: a Topic-Model based approach for spam detection</a></p>
<p>10 0.2357669 <a title="336-lsi-10" href="./acl-2013-Exploiting_Topic_based_Twitter_Sentiment_for_Stock_Prediction.html">147 acl-2013-Exploiting Topic based Twitter Sentiment for Stock Prediction</a></p>
<p>11 0.22488609 <a title="336-lsi-11" href="./acl-2013-Mining_Equivalent_Relations_from_Linked_Data.html">242 acl-2013-Mining Equivalent Relations from Linked Data</a></p>
<p>12 0.21604612 <a title="336-lsi-12" href="./acl-2013-Utterance-Level_Multimodal_Sentiment_Analysis.html">379 acl-2013-Utterance-Level Multimodal Sentiment Analysis</a></p>
<p>13 0.21299595 <a title="336-lsi-13" href="./acl-2013-HEADY%3A_News_headline_abstraction_through_event_pattern_clustering.html">178 acl-2013-HEADY: News headline abstraction through event pattern clustering</a></p>
<p>14 0.21142912 <a title="336-lsi-14" href="./acl-2013-A_user-centric_model_of_voting_intention_from_Social_Media.html">33 acl-2013-A user-centric model of voting intention from Social Media</a></p>
<p>15 0.21059029 <a title="336-lsi-15" href="./acl-2013-Extra-Linguistic_Constraints_on_Stance_Recognition_in_Ideological_Debates.html">151 acl-2013-Extra-Linguistic Constraints on Stance Recognition in Ideological Debates</a></p>
<p>16 0.20962405 <a title="336-lsi-16" href="./acl-2013-BRAINSUP%3A_Brainstorming_Support_for_Creative_Sentence_Generation.html">65 acl-2013-BRAINSUP: Brainstorming Support for Creative Sentence Generation</a></p>
<p>17 0.20407324 <a title="336-lsi-17" href="./acl-2013-A_Novel_Graph-based_Compact_Representation_of_Word_Alignment.html">15 acl-2013-A Novel Graph-based Compact Representation of Word Alignment</a></p>
<p>18 0.20237496 <a title="336-lsi-18" href="./acl-2013-Extracting_Definitions_and_Hypernym_Relations_relying_on_Syntactic_Dependencies_and_Support_Vector_Machines.html">152 acl-2013-Extracting Definitions and Hypernym Relations relying on Syntactic Dependencies and Support Vector Machines</a></p>
<p>19 0.19624425 <a title="336-lsi-19" href="./acl-2013-Understanding_Tables_in_Context_Using_Standard_NLP_Toolkits.html">365 acl-2013-Understanding Tables in Context Using Standard NLP Toolkits</a></p>
<p>20 0.19086297 <a title="336-lsi-20" href="./acl-2013-Large-scale_Semantic_Parsing_via_Schema_Matching_and_Lexicon_Extension.html">215 acl-2013-Large-scale Semantic Parsing via Schema Matching and Lexicon Extension</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.031), (6, 0.017), (11, 0.038), (24, 0.068), (26, 0.035), (35, 0.05), (42, 0.042), (48, 0.033), (70, 0.038), (88, 0.013), (90, 0.01), (95, 0.527)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.98919684 <a title="336-lda-1" href="./acl-2013-Improving_machine_translation_by_training_against_an_automatic_semantic_frame_based_evaluation_metric.html">195 acl-2013-Improving machine translation by training against an automatic semantic frame based evaluation metric</a></p>
<p>Author: Chi-kiu Lo ; Karteek Addanki ; Markus Saers ; Dekai Wu</p><p>Abstract: We present the first ever results showing that tuning a machine translation system against a semantic frame based objective function, MEANT, produces more robustly adequate translations than tuning against BLEU or TER as measured across commonly used metrics and human subjective evaluation. Moreover, for informal web forum data, human evaluators preferred MEANT-tuned systems over BLEU- or TER-tuned systems by a significantly wider margin than that for formal newswire—even though automatic semantic parsing might be expected to fare worse on informal language. We argue thatbypreserving the meaning ofthe trans- lations as captured by semantic frames right in the training process, an MT system is constrained to make more accurate choices of both lexical and reordering rules. As a result, MT systems tuned against semantic frame based MT evaluation metrics produce output that is more adequate. Tuning a machine translation system against a semantic frame based objective function is independent ofthe translation model paradigm, so, any translation model can benefit from the semantic knowledge incorporated to improve translation adequacy through our approach.</p><p>same-paper 2 0.98501289 <a title="336-lda-2" href="./acl-2013-Syntactic_Patterns_versus_Word_Alignment%3A_Extracting_Opinion_Targets_from_Online_Reviews.html">336 acl-2013-Syntactic Patterns versus Word Alignment: Extracting Opinion Targets from Online Reviews</a></p>
<p>Author: Kang Liu ; Liheng Xu ; Jun Zhao</p><p>Abstract: Mining opinion targets is a fundamental and important task for opinion mining from online reviews. To this end, there are usually two kinds of methods: syntax based and alignment based methods. Syntax based methods usually exploited syntactic patterns to extract opinion targets, which were however prone to suffer from parsing errors when dealing with online informal texts. In contrast, alignment based methods used word alignment model to fulfill this task, which could avoid parsing errors without using parsing. However, there is no research focusing on which kind of method is more better when given a certain amount of reviews. To fill this gap, this paper empiri- cally studies how the performance of these two kinds of methods vary when changing the size, domain and language of the corpus. We further combine syntactic patterns with alignment model by using a partially supervised framework and investigate whether this combination is useful or not. In our experiments, we verify that our combination is effective on the corpus with small and medium size.</p><p>3 0.98284459 <a title="336-lda-3" href="./acl-2013-Translating_Dialectal_Arabic_to_English.html">359 acl-2013-Translating Dialectal Arabic to English</a></p>
<p>Author: Hassan Sajjad ; Kareem Darwish ; Yonatan Belinkov</p><p>Abstract: We present a dialectal Egyptian Arabic to English statistical machine translation system that leverages dialectal to Modern Standard Arabic (MSA) adaptation. In contrast to previous work, we first narrow down the gap between Egyptian and MSA by applying an automatic characterlevel transformational model that changes Egyptian to EG0, which looks similar to MSA. The transformations include morphological, phonological and spelling changes. The transformation reduces the out-of-vocabulary (OOV) words from 5.2% to 2.6% and gives a gain of 1.87 BLEU points. Further, adapting large MSA/English parallel data increases the lexical coverage, reduces OOVs to 0.7% and leads to an absolute BLEU improvement of 2.73 points.</p><p>4 0.98256671 <a title="336-lda-4" href="./acl-2013-Named_Entity_Recognition_using_Cross-lingual_Resources%3A_Arabic_as_an_Example.html">256 acl-2013-Named Entity Recognition using Cross-lingual Resources: Arabic as an Example</a></p>
<p>Author: Kareem Darwish</p><p>Abstract: Some languages lack large knowledge bases and good discriminative features for Name Entity Recognition (NER) that can generalize to previously unseen named entities. One such language is Arabic, which: a) lacks a capitalization feature; and b) has relatively small knowledge bases, such as Wikipedia. In this work we address both problems by incorporating cross-lingual features and knowledge bases from English using cross-lingual links. We show that such features have a dramatic positive effect on recall. We show the effectiveness of cross-lingual features and resources on a standard dataset as well as on two new test sets that cover both news and microblogs. On the standard dataset, we achieved a 4.1% relative improvement in Fmeasure over the best reported result in the literature. The features led to improvements of 17.1% and 20.5% on the new news and mi- croblogs test sets respectively.</p><p>5 0.98151451 <a title="336-lda-5" href="./acl-2013-Latent_Semantic_Matching%3A_Application_to_Cross-language_Text_Categorization_without_Alignment_Information.html">217 acl-2013-Latent Semantic Matching: Application to Cross-language Text Categorization without Alignment Information</a></p>
<p>Author: Tsutomu Hirao ; Tomoharu Iwata ; Masaaki Nagata</p><p>Abstract: Unsupervised object matching (UOM) is a promising approach to cross-language natural language processing such as bilingual lexicon acquisition, parallel corpus construction, and cross-language text categorization, because it does not require labor-intensive linguistic resources. However, UOM only finds one-to-one correspondences from data sets with the same number of instances in source and target domains, and this prevents us from applying UOM to real-world cross-language natural language processing tasks. To alleviate these limitations, we proposes latent semantic matching, which embeds objects in both source and target language domains into a shared latent topic space. We demonstrate the effectiveness of our method on cross-language text categorization. The results show that our method outperforms conventional unsupervised object matching methods.</p><p>6 0.96595305 <a title="336-lda-6" href="./acl-2013-Adaptive_Parser-Centric_Text_Normalization.html">37 acl-2013-Adaptive Parser-Centric Text Normalization</a></p>
<p>7 0.94519132 <a title="336-lda-7" href="./acl-2013-FrameNet_on_the_Way_to_Babel%3A_Creating_a_Bilingual_FrameNet_Using_Wiktionary_as_Interlingual_Connection.html">162 acl-2013-FrameNet on the Way to Babel: Creating a Bilingual FrameNet Using Wiktionary as Interlingual Connection</a></p>
<p>8 0.94510889 <a title="336-lda-8" href="./acl-2013-Beam_Search_for_Solving_Substitution_Ciphers.html">66 acl-2013-Beam Search for Solving Substitution Ciphers</a></p>
<p>9 0.91212964 <a title="336-lda-9" href="./acl-2013-QuEst_-_A_translation_quality_estimation_framework.html">289 acl-2013-QuEst - A translation quality estimation framework</a></p>
<p>10 0.85593951 <a title="336-lda-10" href="./acl-2013-Using_Context_Vectors_in_Improving_a_Machine_Translation_System_with_Bridge_Language.html">374 acl-2013-Using Context Vectors in Improving a Machine Translation System with Bridge Language</a></p>
<p>11 0.85148203 <a title="336-lda-11" href="./acl-2013-Name-aware_Machine_Translation.html">255 acl-2013-Name-aware Machine Translation</a></p>
<p>12 0.84760553 <a title="336-lda-12" href="./acl-2013-English-to-Russian_MT_evaluation_campaign.html">135 acl-2013-English-to-Russian MT evaluation campaign</a></p>
<p>13 0.83922321 <a title="336-lda-13" href="./acl-2013-Sentence_Level_Dialect_Identification_in_Arabic.html">317 acl-2013-Sentence Level Dialect Identification in Arabic</a></p>
<p>14 0.81985521 <a title="336-lda-14" href="./acl-2013-Social_Text_Normalization_using_Contextual_Graph_Random_Walks.html">326 acl-2013-Social Text Normalization using Contextual Graph Random Walks</a></p>
<p>15 0.81751597 <a title="336-lda-15" href="./acl-2013-Language_Independent_Connectivity_Strength_Features_for_Phrase_Pivot_Statistical_Machine_Translation.html">214 acl-2013-Language Independent Connectivity Strength Features for Phrase Pivot Statistical Machine Translation</a></p>
<p>16 0.8116262 <a title="336-lda-16" href="./acl-2013-A_Decade_of_Automatic_Content_Evaluation_of_News_Summaries%3A_Reassessing_the_State_of_the_Art.html">5 acl-2013-A Decade of Automatic Content Evaluation of News Summaries: Reassessing the State of the Art</a></p>
<p>17 0.80891728 <a title="336-lda-17" href="./acl-2013-A_New_Syntactic_Metric_for_Evaluation_of_Machine_Translation.html">13 acl-2013-A New Syntactic Metric for Evaluation of Machine Translation</a></p>
<p>18 0.80867839 <a title="336-lda-18" href="./acl-2013-Dirt_Cheap_Web-Scale_Parallel_Text_from_the_Common_Crawl.html">120 acl-2013-Dirt Cheap Web-Scale Parallel Text from the Common Crawl</a></p>
<p>19 0.80372989 <a title="336-lda-19" href="./acl-2013-Microblogs_as_Parallel_Corpora.html">240 acl-2013-Microblogs as Parallel Corpora</a></p>
<p>20 0.78574532 <a title="336-lda-20" href="./acl-2013-Cross-lingual_Projections_between_Languages_from_Different_Families.html">97 acl-2013-Cross-lingual Projections between Languages from Different Families</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
