<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>382 acl-2013-Variational Inference for Structured NLP Models</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-382" href="#">acl2013-382</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>382 acl-2013-Variational Inference for Structured NLP Models</h1>
<br/><p>Source: <a title="acl-2013-382-pdf" href="http://aclweb.org/anthology//P/P13/P13-5006.pdf">pdf</a></p><p>Author: David Burkett ; Dan Klein</p><p>Abstract: unkown-abstract</p><p>Reference: <a title="acl-2013-382-reference" href="../acl2013_reference/acl-2013-Variational_Inference_for_Structured_NLP_Models_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Variational Inference for Structured NLP Models David Burkett and Dan Klein Computer Science Division University of California, Berkeley {dburkett , kle in} @ c s . [sent-1, score-0.09]
</p><p>2 edu  Description Historically, key breakthroughs in structured NLP models, such as chain CRFs or PCFGs, have relied on imposing careful constraints on the locality of features in order to permit efficient dynamic programming for computing expectations or finding the highest-scoring structures. [sent-3, score-0.618]
</p><p>3 In the NLP community, one increasingly popular approach is the use of variational methods for computing approximate distributions. [sent-5, score-0.581]
</p><p>4 The goal of the tutorial is to provide an introduction to variational methods for approximate in-  ference, particularly mean field approximation and belief propagation. [sent-6, score-1.299]
</p><p>5 Though the full derivations can be somewhat tedious, the resulting procedures are quite straightforward, and typically consist of an iterative process of individually updating specific components of the model, conditioned on the rest. [sent-8, score-0.244]
</p><p>6 Although we will provide some theoretical background, the main goal of the tutorial is to provide a concrete procedural guide to using these approximate inference techniques, illustrated with detailed walkthroughs of examples from recent NLP literature. [sent-9, score-0.651]
</p><p>7 Once both variational inference procedures have been described in detail, we’ll provide a summary comparison of the two, along with some intuition about which approach is appropriate when. [sent-10, score-0.721]
</p><p>8 We’ll also provide a guide to further exploration of the topic, briefly discussing other variational techniques, such as expectation propagation and convex relaxations, but concentrating mainly on providing pointers to additional resources for those who wish to learn more. [sent-11, score-0.892]
</p><p>9 Structured Models and Factor Graphs • Factor graph notation • Example structured NLP models • Inference 2. [sent-13, score-0.197]
</p><p>10 Mean Field • Warmup (iterated conditional modes) • Mean field procedure • Derivation of mean field update • Example 3. [sent-14, score-0.468]
</p><p>11 Structured Mean Field • Structured approximation • Computing structured updates • Example: Joint parsing and alignment 4. [sent-15, score-0.574]
</p><p>12 Belief Propagation • Intro  Messages and beliefs • Loopy BP 5. [sent-16, score-0.077]
</p><p>13 Structured Belief Propagation •  • sWagaerms)up (efficient products for mesExample: Word alignment • Example: Dependency parsing 6. [sent-17, score-0.138]
</p><p>14 Wrap-Up • Mean field vs BP • Other approximation techniques •  9 ProceediSnogfsia o,f B thuelg 5a1rista, A Annuugauslt M 4-e9eti 2n0g1 o3f. [sent-18, score-0.441]
</p><p>15 hc e2 A01ss3o Acisastoiocnia ftoiorn C foorm Cpoumtaptiuotnaatilo Lnianlg Luiinstgiucsis,pt iacgses 9–10, Presenter Bios David Burkett is a postdoctoral researcher in the Computer Science Division at the University of California, Berkeley. [sent-20, score-0.372]
</p><p>16 His interests are diverse, though, and he has worked on parsing, phrase alignment, language evolution, coreference resolution, and even video game AI. [sent-22, score-0.29]
</p><p>17 He has worked as an instructional assistant for multiple AI courses at Berkeley and won multiple Outstanding Graduate Student Instructor awards. [sent-23, score-0.42]
</p><p>18 His research includes many areas of statistical natural language processing, including grammar induction, parsing, machine translation, information extraction, document summarization, historical linguistics, and speech recognition. [sent-25, score-0.053]
</p><p>19 His academic awards include a Sloan Fellowship, a Microsoft Faculty Fellowship, an NSF CAREER Award, the ACM Grace Murray Hopper Award, Best Paper Awards at ACL, EMNLP and NAACL, and the UC Berkeley Distinguished Teaching Award. [sent-26, score-0.206]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('variational', 0.368), ('structured', 0.197), ('approximation', 0.189), ('field', 0.168), ('burkett', 0.161), ('belief', 0.156), ('awards', 0.154), ('berkeley', 0.144), ('inference', 0.137), ('bp', 0.135), ('mean', 0.132), ('fellowship', 0.132), ('propagation', 0.129), ('california', 0.127), ('approximate', 0.12), ('division', 0.118), ('worked', 0.118), ('ll', 0.113), ('award', 0.113), ('tutorial', 0.111), ('hopper', 0.097), ('procedures', 0.093), ('courses', 0.09), ('murray', 0.09), ('kle', 0.09), ('presenter', 0.09), ('loopy', 0.09), ('historically', 0.09), ('procedural', 0.09), ('postdoctoral', 0.084), ('acisastoiocnia', 0.084), ('iacgses', 0.084), ('lnianlg', 0.084), ('thuelg', 0.084), ('sloan', 0.084), ('professor', 0.084), ('guide', 0.083), ('derivation', 0.08), ('beliefs', 0.077), ('ftoiorn', 0.077), ('instructional', 0.077), ('computable', 0.077), ('assistant', 0.077), ('pointers', 0.077), ('tedious', 0.077), ('iterated', 0.074), ('pcfgs', 0.074), ('teaching', 0.074), ('ley', 0.074), ('impractical', 0.072), ('ference', 0.072), ('locality', 0.072), ('outstanding', 0.072), ('discussing', 0.072), ('alignment', 0.071), ('career', 0.069), ('grace', 0.069), ('intuition', 0.068), ('imposing', 0.068), ('parsing', 0.067), ('klein', 0.066), ('relaxations', 0.066), ('uc', 0.066), ('modes', 0.066), ('minimizes', 0.066), ('nlp', 0.065), ('researcher', 0.064), ('hc', 0.063), ('permit', 0.063), ('interests', 0.061), ('careful', 0.06), ('expectations', 0.058), ('resort', 0.058), ('won', 0.058), ('evolution', 0.058), ('game', 0.057), ('convex', 0.057), ('factor', 0.055), ('provide', 0.055), ('video', 0.054), ('relied', 0.053), ('historical', 0.053), ('impossible', 0.053), ('academic', 0.052), ('distinguished', 0.052), ('outline', 0.052), ('individually', 0.052), ('messages', 0.051), ('crfs', 0.051), ('wish', 0.051), ('derivations', 0.05), ('updates', 0.05), ('updating', 0.049), ('pruning', 0.049), ('graduate', 0.049), ('faculty', 0.048), ('beam', 0.047), ('computing', 0.047), ('increasingly', 0.046), ('seek', 0.046)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="382-tfidf-1" href="./acl-2013-Variational_Inference_for_Structured_NLP_Models.html">382 acl-2013-Variational Inference for Structured NLP Models</a></p>
<p>Author: David Burkett ; Dan Klein</p><p>Abstract: unkown-abstract</p><p>2 0.09828683 <a title="382-tfidf-2" href="./acl-2013-Decentralized_Entity-Level_Modeling_for_Coreference_Resolution.html">106 acl-2013-Decentralized Entity-Level Modeling for Coreference Resolution</a></p>
<p>Author: Greg Durrett ; David Hall ; Dan Klein</p><p>Abstract: Efficiently incorporating entity-level information is a challenge for coreference resolution systems due to the difficulty of exact inference over partitions. We describe an end-to-end discriminative probabilistic model for coreference that, along with standard pairwise features, enforces structural agreement constraints between specified properties of coreferent mentions. This model can be represented as a factor graph for each document that admits efficient inference via belief propagation. We show that our method can use entity-level information to outperform a basic pairwise system.</p><p>3 0.093920171 <a title="382-tfidf-3" href="./acl-2013-Semantic_Parsing_with_Combinatory_Categorial_Grammars.html">313 acl-2013-Semantic Parsing with Combinatory Categorial Grammars</a></p>
<p>Author: Yoav Artzi ; Nicholas FitzGerald ; Luke Zettlemoyer</p><p>Abstract: unkown-abstract</p><p>4 0.093292363 <a title="382-tfidf-4" href="./acl-2013-The_mathematics_of_language_learning.html">349 acl-2013-The mathematics of language learning</a></p>
<p>Author: Andras Kornai ; Gerald Penn ; James Rogers ; Anssi Yli-Jyra</p><p>Abstract: unkown-abstract</p><p>5 0.080639854 <a title="382-tfidf-5" href="./acl-2013-Joint_Word_Alignment_and_Bilingual_Named_Entity_Recognition_Using_Dual_Decomposition.html">210 acl-2013-Joint Word Alignment and Bilingual Named Entity Recognition Using Dual Decomposition</a></p>
<p>Author: Mengqiu Wang ; Wanxiang Che ; Christopher D. Manning</p><p>Abstract: Translated bi-texts contain complementary language cues, and previous work on Named Entity Recognition (NER) has demonstrated improvements in performance over monolingual taggers by promoting agreement of tagging decisions between the two languages. However, most previous approaches to bilingual tagging assume word alignments are given as fixed input, which can cause cascading errors. We observe that NER label information can be used to correct alignment mistakes, and present a graphical model that performs bilingual NER tagging jointly with word alignment, by combining two monolingual tagging models with two unidirectional alignment models. We intro- duce additional cross-lingual edge factors that encourage agreements between tagging and alignment decisions. We design a dual decomposition inference algorithm to perform joint decoding over the combined alignment and NER output space. Experiments on the OntoNotes dataset demonstrate that our method yields significant improvements in both NER and word alignment over state-of-the-art monolingual baselines.</p><p>6 0.078299314 <a title="382-tfidf-6" href="./acl-2013-Margin-based_Decomposed_Amortized_Inference.html">237 acl-2013-Margin-based Decomposed Amortized Inference</a></p>
<p>7 0.075796723 <a title="382-tfidf-7" href="./acl-2013-Mr._MIRA%3A_Open-Source_Large-Margin_Structured_Learning_on_MapReduce.html">251 acl-2013-Mr. MIRA: Open-Source Large-Margin Structured Learning on MapReduce</a></p>
<p>8 0.070151664 <a title="382-tfidf-8" href="./acl-2013-Improved_Bayesian_Logistic_Supervised_Topic_Models_with_Data_Augmentation.html">191 acl-2013-Improved Bayesian Logistic Supervised Topic Models with Data Augmentation</a></p>
<p>9 0.069315307 <a title="382-tfidf-9" href="./acl-2013-Implicatures_and_Nested_Beliefs_in_Approximate_Decentralized-POMDPs.html">190 acl-2013-Implicatures and Nested Beliefs in Approximate Decentralized-POMDPs</a></p>
<p>10 0.067313597 <a title="382-tfidf-10" href="./acl-2013-Graph-based_Semi-Supervised_Model_for_Joint_Chinese_Word_Segmentation_and_Part-of-Speech_Tagging.html">173 acl-2013-Graph-based Semi-Supervised Model for Joint Chinese Word Segmentation and Part-of-Speech Tagging</a></p>
<p>11 0.064507537 <a title="382-tfidf-11" href="./acl-2013-The_effect_of_non-tightness_on_Bayesian_estimation_of_PCFGs.html">348 acl-2013-The effect of non-tightness on Bayesian estimation of PCFGs</a></p>
<p>12 0.063745387 <a title="382-tfidf-12" href="./acl-2013-PLIS%3A_a_Probabilistic_Lexical_Inference_System.html">269 acl-2013-PLIS: a Probabilistic Lexical Inference System</a></p>
<p>13 0.062233817 <a title="382-tfidf-13" href="./acl-2013-Easy-First_POS_Tagging_and_Dependency_Parsing_with_Beam_Search.html">132 acl-2013-Easy-First POS Tagging and Dependency Parsing with Beam Search</a></p>
<p>14 0.06144033 <a title="382-tfidf-14" href="./acl-2013-Exact_Maximum_Inference_for_the_Fertility_Hidden_Markov_Model.html">143 acl-2013-Exact Maximum Inference for the Fertility Hidden Markov Model</a></p>
<p>15 0.056381736 <a title="382-tfidf-15" href="./acl-2013-An_Empirical_Examination_of_Challenges_in_Chinese_Parsing.html">44 acl-2013-An Empirical Examination of Challenges in Chinese Parsing</a></p>
<p>16 0.056323532 <a title="382-tfidf-16" href="./acl-2013-Transition-based_Dependency_Parsing_with_Selectional_Branching.html">358 acl-2013-Transition-based Dependency Parsing with Selectional Branching</a></p>
<p>17 0.054125108 <a title="382-tfidf-17" href="./acl-2013-Decipherment.html">108 acl-2013-Decipherment</a></p>
<p>18 0.053923897 <a title="382-tfidf-18" href="./acl-2013-Learning_to_Prune%3A_Context-Sensitive_Pruning_for_Syntactic_MT.html">226 acl-2013-Learning to Prune: Context-Sensitive Pruning for Syntactic MT</a></p>
<p>19 0.053854462 <a title="382-tfidf-19" href="./acl-2013-A_Lightweight_and_High_Performance_Monolingual_Word_Aligner.html">9 acl-2013-A Lightweight and High Performance Monolingual Word Aligner</a></p>
<p>20 0.052419707 <a title="382-tfidf-20" href="./acl-2013-Question_Answering_Using_Enhanced_Lexical_Semantic_Models.html">291 acl-2013-Question Answering Using Enhanced Lexical Semantic Models</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.137), (1, -0.031), (2, -0.039), (3, -0.01), (4, -0.024), (5, 0.024), (6, 0.056), (7, -0.007), (8, -0.07), (9, -0.018), (10, -0.017), (11, -0.071), (12, -0.015), (13, -0.093), (14, 0.036), (15, -0.033), (16, -0.02), (17, 0.052), (18, -0.003), (19, -0.029), (20, -0.033), (21, -0.001), (22, -0.031), (23, -0.002), (24, -0.014), (25, 0.039), (26, -0.09), (27, 0.084), (28, 0.117), (29, -0.017), (30, 0.063), (31, 0.004), (32, 0.008), (33, 0.042), (34, 0.026), (35, 0.027), (36, -0.01), (37, 0.037), (38, 0.076), (39, 0.015), (40, -0.018), (41, -0.021), (42, 0.017), (43, -0.022), (44, 0.023), (45, 0.038), (46, 0.023), (47, -0.007), (48, 0.005), (49, -0.043)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96207976 <a title="382-lsi-1" href="./acl-2013-Variational_Inference_for_Structured_NLP_Models.html">382 acl-2013-Variational Inference for Structured NLP Models</a></p>
<p>Author: David Burkett ; Dan Klein</p><p>Abstract: unkown-abstract</p><p>2 0.68479532 <a title="382-lsi-2" href="./acl-2013-Exact_Maximum_Inference_for_the_Fertility_Hidden_Markov_Model.html">143 acl-2013-Exact Maximum Inference for the Fertility Hidden Markov Model</a></p>
<p>Author: Chris Quirk</p><p>Abstract: The notion of fertility in word alignment (the number of words emitted by a single state) is useful but difficult to model. Initial attempts at modeling fertility used heuristic search methods. Recent approaches instead use more principled approximate inference techniques such as Gibbs sampling for parameter estimation. Yet in practice we also need the single best alignment, which is difficult to find using Gibbs. Building on recent advances in dual decomposition, this paper introduces an exact algorithm for finding the single best alignment with a fertility HMM. Finding the best alignment appears important, as this model leads to a substantial improvement in alignment quality.</p><p>3 0.64471859 <a title="382-lsi-3" href="./acl-2013-Nonconvex_Global_Optimization_for_Latent-Variable_Models.html">260 acl-2013-Nonconvex Global Optimization for Latent-Variable Models</a></p>
<p>Author: Matthew R. Gormley ; Jason Eisner</p><p>Abstract: Many models in NLP involve latent variables, such as unknown parses, tags, or alignments. Finding the optimal model parameters is then usually a difficult nonconvex optimization problem. The usual practice is to settle for local optimization methods such as EM or gradient ascent. We explore how one might instead search for a global optimum in parameter space, using branch-and-bound. Our method would eventually find the global maximum (up to a user-specified ?) if run for long enough, but at any point can return a suboptimal solution together with an upper bound on the global maximum. As an illustrative case, we study a generative model for dependency parsing. We search for the maximum-likelihood model parameters and corpus parse, subject to posterior constraints. We show how to formulate this as a mixed integer quadratic programming problem with nonlinear constraints. We use the Reformulation Linearization Technique to produce convex relaxations during branch-and-bound. Although these techniques do not yet provide a practical solution to our instance of this NP-hard problem, they sometimes find better solutions than Viterbi EM with random restarts, in the same time.</p><p>4 0.64024037 <a title="382-lsi-4" href="./acl-2013-Margin-based_Decomposed_Amortized_Inference.html">237 acl-2013-Margin-based Decomposed Amortized Inference</a></p>
<p>Author: Gourab Kundu ; Vivek Srikumar ; Dan Roth</p><p>Abstract: Given that structured output prediction is typically performed over entire datasets, one natural question is whether it is possible to re-use computation from earlier inference instances to speed up inference for future instances. Amortized inference has been proposed as a way to accomplish this. In this paper, first, we introduce a new amortized inference algorithm called the Margin-based Amortized Inference, which uses the notion of structured margin to identify inference problems for which previous solutions are provably optimal. Second, we introduce decomposed amortized inference, which is designed to address very large inference problems, where earlier amortization methods become less ef- fective. This approach works by decomposing the output structure and applying amortization piece-wise, thus increasing the chance that we can re-use previous solutions for parts of the output structure. These parts are then combined to a global coherent solution using Lagrangian relaxation. In our experiments, using the NLP tasks of semantic role labeling and entityrelation extraction, we demonstrate that with the margin-based algorithm, we need to call the inference engine only for a third of the test examples. Further, we show that the decomposed variant of margin-based amortized inference achieves a greater reduction in the number of inference calls.</p><p>5 0.59335655 <a title="382-lsi-5" href="./acl-2013-Joint_Word_Alignment_and_Bilingual_Named_Entity_Recognition_Using_Dual_Decomposition.html">210 acl-2013-Joint Word Alignment and Bilingual Named Entity Recognition Using Dual Decomposition</a></p>
<p>Author: Mengqiu Wang ; Wanxiang Che ; Christopher D. Manning</p><p>Abstract: Translated bi-texts contain complementary language cues, and previous work on Named Entity Recognition (NER) has demonstrated improvements in performance over monolingual taggers by promoting agreement of tagging decisions between the two languages. However, most previous approaches to bilingual tagging assume word alignments are given as fixed input, which can cause cascading errors. We observe that NER label information can be used to correct alignment mistakes, and present a graphical model that performs bilingual NER tagging jointly with word alignment, by combining two monolingual tagging models with two unidirectional alignment models. We intro- duce additional cross-lingual edge factors that encourage agreements between tagging and alignment decisions. We design a dual decomposition inference algorithm to perform joint decoding over the combined alignment and NER output space. Experiments on the OntoNotes dataset demonstrate that our method yields significant improvements in both NER and word alignment over state-of-the-art monolingual baselines.</p><p>6 0.5811612 <a title="382-lsi-6" href="./acl-2013-Supervised_Model_Learning_with_Feature_Grouping_based_on_a_Discrete_Constraint.html">334 acl-2013-Supervised Model Learning with Feature Grouping based on a Discrete Constraint</a></p>
<p>7 0.57531476 <a title="382-lsi-7" href="./acl-2013-Turning_on_the_Turbo%3A_Fast_Third-Order_Non-Projective_Turbo_Parsers.html">362 acl-2013-Turning on the Turbo: Fast Third-Order Non-Projective Turbo Parsers</a></p>
<p>8 0.55698234 <a title="382-lsi-8" href="./acl-2013-Training_Nondeficient_Variants_of_IBM-3_and_IBM-4_for_Word_Alignment.html">354 acl-2013-Training Nondeficient Variants of IBM-3 and IBM-4 for Word Alignment</a></p>
<p>9 0.55559206 <a title="382-lsi-9" href="./acl-2013-Decentralized_Entity-Level_Modeling_for_Coreference_Resolution.html">106 acl-2013-Decentralized Entity-Level Modeling for Coreference Resolution</a></p>
<p>10 0.52377528 <a title="382-lsi-10" href="./acl-2013-Unsupervised_Transcription_of_Historical_Documents.html">370 acl-2013-Unsupervised Transcription of Historical Documents</a></p>
<p>11 0.51689422 <a title="382-lsi-11" href="./acl-2013-Implicatures_and_Nested_Beliefs_in_Approximate_Decentralized-POMDPs.html">190 acl-2013-Implicatures and Nested Beliefs in Approximate Decentralized-POMDPs</a></p>
<p>12 0.49601176 <a title="382-lsi-12" href="./acl-2013-The_mathematics_of_language_learning.html">349 acl-2013-The mathematics of language learning</a></p>
<p>13 0.49460596 <a title="382-lsi-13" href="./acl-2013-Grounded_Language_Learning_from_Video_Described_with_Sentences.html">175 acl-2013-Grounded Language Learning from Video Described with Sentences</a></p>
<p>14 0.47815046 <a title="382-lsi-14" href="./acl-2013-Fast_and_Robust_Compressive_Summarization_with_Dual_Decomposition_and_Multi-Task_Learning.html">157 acl-2013-Fast and Robust Compressive Summarization with Dual Decomposition and Multi-Task Learning</a></p>
<p>15 0.47540998 <a title="382-lsi-15" href="./acl-2013-Leveraging_Domain-Independent_Information_in_Semantic_Parsing.html">228 acl-2013-Leveraging Domain-Independent Information in Semantic Parsing</a></p>
<p>16 0.46546209 <a title="382-lsi-16" href="./acl-2013-Improving_pairwise_coreference_models_through_feature_space_hierarchy_learning.html">196 acl-2013-Improving pairwise coreference models through feature space hierarchy learning</a></p>
<p>17 0.46125442 <a title="382-lsi-17" href="./acl-2013-Non-Monotonic_Sentence_Alignment_via_Semisupervised_Learning.html">259 acl-2013-Non-Monotonic Sentence Alignment via Semisupervised Learning</a></p>
<p>18 0.45851338 <a title="382-lsi-18" href="./acl-2013-Semantic_Parsing_with_Combinatory_Categorial_Grammars.html">313 acl-2013-Semantic Parsing with Combinatory Categorial Grammars</a></p>
<p>19 0.45646343 <a title="382-lsi-19" href="./acl-2013-Adapting_Discriminative_Reranking_to_Grounded_Language_Learning.html">36 acl-2013-Adapting Discriminative Reranking to Grounded Language Learning</a></p>
<p>20 0.45471755 <a title="382-lsi-20" href="./acl-2013-PLIS%3A_a_Probabilistic_Lexical_Inference_System.html">269 acl-2013-PLIS: a Probabilistic Lexical Inference System</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.069), (6, 0.062), (11, 0.053), (24, 0.024), (26, 0.027), (31, 0.038), (35, 0.076), (42, 0.079), (48, 0.054), (69, 0.232), (70, 0.077), (88, 0.075), (90, 0.026), (95, 0.033)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.85508525 <a title="382-lda-1" href="./acl-2013-Variational_Inference_for_Structured_NLP_Models.html">382 acl-2013-Variational Inference for Structured NLP Models</a></p>
<p>Author: David Burkett ; Dan Klein</p><p>Abstract: unkown-abstract</p><p>2 0.73598659 <a title="382-lda-2" href="./acl-2013-PAL%3A_A_Chatterbot_System_for_Answering_Domain-specific_Questions.html">266 acl-2013-PAL: A Chatterbot System for Answering Domain-specific Questions</a></p>
<p>Author: Yuanchao Liu ; Ming Liu ; Xiaolong Wang ; Limin Wang ; Jingjing Li</p><p>Abstract: In this paper, we propose PAL, a prototype chatterbot for answering non-obstructive psychological domain-specific questions. This system focuses on providing primary suggestions or helping people relieve pressure by extracting knowledge from online forums, based on which the chatterbot system is constructed. The strategies used by PAL, including semantic-extension-based question matching, solution management with personal information consideration, and XML-based knowledge pattern construction, are described and discussed. We also conduct a primary test for the feasibility of our system.</p><p>3 0.59387678 <a title="382-lda-3" href="./acl-2013-Universal_Conceptual_Cognitive_Annotation_%28UCCA%29.html">367 acl-2013-Universal Conceptual Cognitive Annotation (UCCA)</a></p>
<p>Author: Omri Abend ; Ari Rappoport</p><p>Abstract: Syntactic structures, by their nature, reflect first and foremost the formal constructions used for expressing meanings. This renders them sensitive to formal variation both within and across languages, and limits their value to semantic applications. We present UCCA, a novel multi-layered framework for semantic representation that aims to accommodate the semantic distinctions expressed through linguistic utterances. We demonstrate UCCA’s portability across domains and languages, and its relative insensitivity to meaning-preserving syntactic variation. We also show that UCCA can be effectively and quickly learned by annotators with no linguistic background, and describe the compilation of a UCCAannotated corpus.</p><p>4 0.58589828 <a title="382-lda-4" href="./acl-2013-Collective_Annotation_of_Linguistic_Resources%3A_Basic_Principles_and_a_Formal_Model.html">83 acl-2013-Collective Annotation of Linguistic Resources: Basic Principles and a Formal Model</a></p>
<p>Author: Ulle Endriss ; Raquel Fernandez</p><p>Abstract: Crowdsourcing, which offers new ways of cheaply and quickly gathering large amounts of information contributed by volunteers online, has revolutionised the collection of labelled data. Yet, to create annotated linguistic resources from this data, we face the challenge of having to combine the judgements of a potentially large group of annotators. In this paper we investigate how to aggregate individual annotations into a single collective annotation, taking inspiration from the field of social choice theory. We formulate a general formal model for collective annotation and propose several aggregation methods that go beyond the commonly used majority rule. We test some of our methods on data from a crowdsourcing experiment on textual entailment annotation.</p><p>5 0.58435845 <a title="382-lda-5" href="./acl-2013-Learning_to_Order_Natural_Language_Texts.html">225 acl-2013-Learning to Order Natural Language Texts</a></p>
<p>Author: Jiwei Tan ; Xiaojun Wan ; Jianguo Xiao</p><p>Abstract: Ordering texts is an important task for many NLP applications. Most previous works on summary sentence ordering rely on the contextual information (e.g. adjacent sentences) of each sentence in the source document. In this paper, we investigate a more challenging task of ordering a set of unordered sentences without any contextual information. We introduce a set of features to characterize the order and coherence of natural language texts, and use the learning to rank technique to determine the order of any two sentences. We also propose to use the genetic algorithm to determine the total order of all sentences. Evaluation results on a news corpus show the effectiveness of our proposed method. 1</p><p>6 0.58366477 <a title="382-lda-6" href="./acl-2013-Argument_Inference_from_Relevant_Event_Mentions_in_Chinese_Argument_Extraction.html">56 acl-2013-Argument Inference from Relevant Event Mentions in Chinese Argument Extraction</a></p>
<p>7 0.58323777 <a title="382-lda-7" href="./acl-2013-Multigraph_Clustering_for_Unsupervised_Coreference_Resolution.html">252 acl-2013-Multigraph Clustering for Unsupervised Coreference Resolution</a></p>
<p>8 0.57857931 <a title="382-lda-8" href="./acl-2013-Parsing_with_Compositional_Vector_Grammars.html">275 acl-2013-Parsing with Compositional Vector Grammars</a></p>
<p>9 0.57336724 <a title="382-lda-9" href="./acl-2013-Bilingually-Guided_Monolingual_Dependency_Grammar_Induction.html">70 acl-2013-Bilingually-Guided Monolingual Dependency Grammar Induction</a></p>
<p>10 0.57089984 <a title="382-lda-10" href="./acl-2013-Density_Maximization_in_Context-Sense_Metric_Space_for_All-words_WSD.html">111 acl-2013-Density Maximization in Context-Sense Metric Space for All-words WSD</a></p>
<p>11 0.56857204 <a title="382-lda-11" href="./acl-2013-Efficient_Implementation_of_Beam-Search_Incremental_Parsers.html">133 acl-2013-Efficient Implementation of Beam-Search Incremental Parsers</a></p>
<p>12 0.56687653 <a title="382-lda-12" href="./acl-2013-Combining_Intra-_and_Multi-sentential_Rhetorical_Parsing_for_Document-level_Discourse_Analysis.html">85 acl-2013-Combining Intra- and Multi-sentential Rhetorical Parsing for Document-level Discourse Analysis</a></p>
<p>13 0.56670463 <a title="382-lda-13" href="./acl-2013-Stop-probability_estimates_computed_on_a_large_corpus_improve_Unsupervised_Dependency_Parsing.html">331 acl-2013-Stop-probability estimates computed on a large corpus improve Unsupervised Dependency Parsing</a></p>
<p>14 0.56616247 <a title="382-lda-14" href="./acl-2013-A_Structured_Distributional_Semantic_Model_for_Event_Co-reference.html">22 acl-2013-A Structured Distributional Semantic Model for Event Co-reference</a></p>
<p>15 0.56604701 <a title="382-lda-15" href="./acl-2013-Models_of_Semantic_Representation_with_Visual_Attributes.html">249 acl-2013-Models of Semantic Representation with Visual Attributes</a></p>
<p>16 0.56493711 <a title="382-lda-16" href="./acl-2013-A_Sentence_Compression_Based_Framework_to_Query-Focused_Multi-Document_Summarization.html">18 acl-2013-A Sentence Compression Based Framework to Query-Focused Multi-Document Summarization</a></p>
<p>17 0.56485426 <a title="382-lda-17" href="./acl-2013-An_Infinite_Hierarchical_Bayesian_Model_of_Phrasal_Translation.html">46 acl-2013-An Infinite Hierarchical Bayesian Model of Phrasal Translation</a></p>
<p>18 0.56402004 <a title="382-lda-18" href="./acl-2013-Fast_and_Accurate_Shift-Reduce_Constituent_Parsing.html">155 acl-2013-Fast and Accurate Shift-Reduce Constituent Parsing</a></p>
<p>19 0.56394762 <a title="382-lda-19" href="./acl-2013-Graph-based_Local_Coherence_Modeling.html">172 acl-2013-Graph-based Local Coherence Modeling</a></p>
<p>20 0.56354231 <a title="382-lda-20" href="./acl-2013-Fast_and_Robust_Compressive_Summarization_with_Dual_Decomposition_and_Multi-Task_Learning.html">157 acl-2013-Fast and Robust Compressive Summarization with Dual Decomposition and Multi-Task Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
