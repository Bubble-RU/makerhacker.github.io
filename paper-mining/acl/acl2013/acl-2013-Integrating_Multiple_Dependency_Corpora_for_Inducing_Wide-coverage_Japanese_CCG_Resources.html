<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>199 acl-2013-Integrating Multiple Dependency Corpora for Inducing Wide-coverage Japanese CCG Resources</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-199" href="#">acl2013-199</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>199 acl-2013-Integrating Multiple Dependency Corpora for Inducing Wide-coverage Japanese CCG Resources</h1>
<br/><p>Source: <a title="acl-2013-199-pdf" href="http://aclweb.org/anthology//P/P13/P13-1103.pdf">pdf</a></p><p>Author: Sumire Uematsu ; Takuya Matsuzaki ; Hiroki Hanaoka ; Yusuke Miyao ; Hideki Mima</p><p>Abstract: This paper describes a method of inducing wide-coverage CCG resources for Japanese. While deep parsers with corpusinduced grammars have been emerging for some languages, those for Japanese have not been widely studied, mainly because most Japanese syntactic resources are dependency-based. Our method first integrates multiple dependency-based corpora into phrase structure trees and then converts the trees into CCG derivations. The method is empirically evaluated in terms of the coverage of the obtained lexi- con and the accuracy of parsing.</p><p>Reference: <a title="acl-2013-199-reference" href="../acl2013_reference/acl-2013-Integrating_Multiple_Dependency_Corpora_for_Inducing_Wide-coverage_Japanese_CCG_Resources_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 jp t akuya-Tmakauty sau M Mz aaktsiu @z nakii i‡ . [sent-4, score-0.165]
</p><p>2 jp Hiroki Hanaoka† Yusuke Miyao‡ Hideki Mima†  hanHaiorokkai@ H Hnain nia . [sent-6, score-0.223]
</p><p>3 †The University of Tokyo Hongo†T 7h-e3- U1,n Bivuenrskiytyo o, Tfo Tkoykoy,o Japan Abstract This paper describes a method of inducing wide-coverage CCG resources for Japanese. [sent-9, score-0.155]
</p><p>4 While deep parsers with corpusinduced grammars have been emerging for some languages, those for Japanese have not been widely studied, mainly because most Japanese syntactic resources are dependency-based. [sent-10, score-0.331]
</p><p>5 Our method first integrates multiple dependency-based corpora into phrase structure trees and then converts the trees into CCG derivations. [sent-11, score-0.399]
</p><p>6 The method is empirically evaluated in terms of the coverage of the obtained lexi-  con and the accuracy of parsing. [sent-12, score-0.14]
</p><p>7 This dominance is mainly because chunkbased dependency analysis looks most appropriate for Japanese syntax due to its morphosyntactic typology, which includes agglutination and scrambling (Bekki, 2010). [sent-15, score-0.299]
</p><p>8 However, it is also true that this type of analysis has prevented us from deeper syntactic analysis such as deep parsing (Clark and Curran, 2007) and logical inference (Bos et al. [sent-16, score-0.354]
</p><p>9 , 2004; Bos, 2007), both of which have been surpassing shallow parsing-based approaches in languages like English. [sent-17, score-0.065]
</p><p>10 In this paper, we present our work on inducing wide-coverage Japanese resources based on  ac . [sent-18, score-0.211]
</p><p>11 j p  ‡National Institute of Infomatics Hitots‡Nubaatisohni 2al- 1In-2st, Ctuhteiy oofd Ian, fToomkaytoic, sJapan combinatory categorial grammar (CCG) (Steedman, 2001). [sent-23, score-0.189]
</p><p>12 Our work is basically an extension of a seminal work on CCGbank (Hockenmaier and Steedman, 2007), in which the phrase structure trees of the Penn Treebank (PTB) (Marcus et al. [sent-24, score-0.243]
</p><p>13 , 1993) are converted into CCG derivations and a wide-coverage CCG lexicon is then extracted from these derivations. [sent-25, score-0.146]
</p><p>14 As CCGbank has enabled a variety of outstanding works on wide-coverage deep parsing for English, our resources are expected to significantly contribute to Japanese deep parsing. [sent-26, score-0.458]
</p><p>15 The application of the CCGbank method to Japanese is not trivial, as resources like PTB are not available in Japanese. [sent-27, score-0.078]
</p><p>16 The widely used resources for parsing research are the Kyoto corpus (Kawahara et al. [sent-28, score-0.202]
</p><p>17 , 2007), both of which are based on the dependency structures of chunks. [sent-30, score-0.091]
</p><p>18 Moreover, the relation between chunk-based dependency structures and CCG derivations is not obvious. [sent-31, score-0.2]
</p><p>19 In this work, we propose a method to integrate multiple dependency-based corpora into phrase structure trees augmented with predicate argument relations. [sent-32, score-0.254]
</p><p>20 We can then convert the phrase structure trees into CCG derivations. [sent-33, score-0.189]
</p><p>21 In the following, we describe the details of the integration method as well as Japanese-specific issues in the conversion into CCG derivations. [sent-34, score-0.103]
</p><p>22 The method is empirically evaluated in terms of the quality of the corpus conversion, the coverage of the obtained lexicon, and the accuracy of parsing with the obtained grammar. [sent-35, score-0.177]
</p><p>23 Additionally, we discuss problems that remain in Japanese resources from the viewpoint of developing CCG derivations. [sent-36, score-0.156]
</p><p>24 There are three primary contributions of this paper: 1) we show the first comprehensive results for Japanese CCG parsing, 2) we present a methodology for integrating multiple dependency-based re1042  Proce dingsS o f ita h,e B 5u1lgsta Arinan,u Aaulg Musete 4ti-n9g 2 o0f1 t3h. [sent-37, score-0.075]
</p><p>25 Ac s2s0o1ci3a Atiosnso fcoirat Cio nm foprut Caotimonpaulta Lti nognuails Lti cnsg,u piasgteics 1042–1051, I give NP: I0  S\NP/NP/NP  :  them NP :them0  money NP :money0  N P y:I0 λSx\NλySPλ:zg/iN. [sent-39, score-0.043]
</p><p>26 X/Y : f PYga : a → X Y : a XN\PYg : a →→ X X/Y : fX PYYga/ :Z a : g → Y\Z : g X\Y : f →→  : fa : fa X/Z : λx. [sent-43, score-0.142]
</p><p>27 sources to NinPgdauce CCG derivations, and 3) we investigate the possibility of further impconrotving CCG anal政y府sis by addはitional resou大rc使esを. [sent-46, score-0.03]
</p><p>28 1 ComNbPginaatory Categoriagla Grammar CCG is a syntactic theory widSceolnyt accepted in the NLP交 f渉ield. [sent-48, score-0.074]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ccg', 0.673), ('japanese', 0.331), ('ccgbank', 0.184), ('jp', 0.165), ('mima', 0.16), ('iida', 0.141), ('derivations', 0.109), ('kawahara', 0.104), ('steedman', 0.101), ('deep', 0.1), ('kurohashi', 0.098), ('bos', 0.091), ('ptb', 0.089), ('trees', 0.086), ('parsing', 0.085), ('resources', 0.078), ('inducing', 0.077), ('np', 0.072), ('conversion', 0.072), ('bekki', 0.071), ('prevented', 0.071), ('dns', 0.071), ('gx', 0.071), ('mz', 0.071), ('sasano', 0.071), ('zp', 0.071), ('fa', 0.071), ('surpassing', 0.065), ('ammar', 0.065), ('anal', 0.065), ('scrambling', 0.065), ('nei', 0.065), ('oofd', 0.065), ('tfo', 0.061), ('dominance', 0.058), ('nia', 0.058), ('dependency', 0.058), ('sx', 0.056), ('kudo', 0.056), ('converts', 0.056), ('yo', 0.056), ('ac', 0.056), ('empirically', 0.053), ('outstanding', 0.052), ('hockenmaier', 0.052), ('typology', 0.052), ('matsuzaki', 0.051), ('sis', 0.051), ('gr', 0.051), ('takuya', 0.049), ('fx', 0.049), ('con', 0.048), ('combinatory', 0.048), ('rc', 0.047), ('seminal', 0.046), ('integrating', 0.045), ('tokyo', 0.045), ('viewpoint', 0.044), ('dominated', 0.044), ('phrase', 0.044), ('lti', 0.043), ('miyao', 0.043), ('yusuke', 0.043), ('matsumoto', 0.043), ('enabled', 0.043), ('morphosyntactic', 0.043), ('money', 0.043), ('curran', 0.043), ('emerging', 0.042), ('kyoto', 0.042), ('hideki', 0.041), ('categorial', 0.041), ('poesio', 0.041), ('accepted', 0.041), ('trivial', 0.041), ('xn', 0.039), ('widely', 0.039), ('coverage', 0.039), ('mainly', 0.039), ('sm', 0.039), ('basically', 0.037), ('lexicon', 0.037), ('looks', 0.036), ('grammar', 0.035), ('japan', 0.035), ('integrates', 0.035), ('deeper', 0.034), ('remain', 0.034), ('structures', 0.033), ('syntactic', 0.033), ('marcus', 0.032), ('corpora', 0.032), ('augmented', 0.032), ('logical', 0.031), ('integration', 0.031), ('multiple', 0.03), ('possibility', 0.03), ('structure', 0.03), ('ian', 0.03), ('convert', 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="199-tfidf-1" href="./acl-2013-Integrating_Multiple_Dependency_Corpora_for_Inducing_Wide-coverage_Japanese_CCG_Resources.html">199 acl-2013-Integrating Multiple Dependency Corpora for Inducing Wide-coverage Japanese CCG Resources</a></p>
<p>Author: Sumire Uematsu ; Takuya Matsuzaki ; Hiroki Hanaoka ; Yusuke Miyao ; Hideki Mima</p><p>Abstract: This paper describes a method of inducing wide-coverage CCG resources for Japanese. While deep parsers with corpusinduced grammars have been emerging for some languages, those for Japanese have not been widely studied, mainly because most Japanese syntactic resources are dependency-based. Our method first integrates multiple dependency-based corpora into phrase structure trees and then converts the trees into CCG derivations. The method is empirically evaluated in terms of the coverage of the obtained lexi- con and the accuracy of parsing.</p><p>2 0.45695505 <a title="199-tfidf-2" href="./acl-2013-Using_CCG_categories_to_improve_Hindi_dependency_parsing.html">372 acl-2013-Using CCG categories to improve Hindi dependency parsing</a></p>
<p>Author: Bharat Ram Ambati ; Tejaswini Deoskar ; Mark Steedman</p><p>Abstract: We show that informative lexical categories from a strongly lexicalised formalism such as Combinatory Categorial Grammar (CCG) can improve dependency parsing of Hindi, a free word order language. We first describe a novel way to obtain a CCG lexicon and treebank from an existing dependency treebank, using a CCG parser. We use the output of a supertagger trained on the CCGbank as a feature for a state-of-the-art Hindi dependency parser (Malt). Our results show that using CCG categories improves the accuracy of Malt on long distance dependencies, for which it is known to have weak rates of recovery.</p><p>3 0.33362374 <a title="199-tfidf-3" href="./acl-2013-Transfer_Learning_for_Constituency-Based_Grammars.html">357 acl-2013-Transfer Learning for Constituency-Based Grammars</a></p>
<p>Author: Yuan Zhang ; Regina Barzilay ; Amir Globerson</p><p>Abstract: In this paper, we consider the problem of cross-formalism transfer in parsing. We are interested in parsing constituencybased grammars such as HPSG and CCG using a small amount of data specific for the target formalism, and a large quantity of coarse CFG annotations from the Penn Treebank. While all of the target formalisms share a similar basic syntactic structure with Penn Treebank CFG, they also encode additional constraints and semantic features. To handle this apparent discrepancy, we design a probabilistic model that jointly generates CFG and target formalism parses. The model includes features of both parses, allowing trans- fer between the formalisms, while preserving parsing efficiency. We evaluate our approach on three constituency-based grammars CCG, HPSG, and LFG, augmented with the Penn Treebank-1. Our experiments show that across all three formalisms, the target parsers significantly benefit from the coarse annotations.1 —</p><p>4 0.32539806 <a title="199-tfidf-4" href="./acl-2013-The_Role_of_Syntax_in_Vector_Space_Models_of_Compositional_Semantics.html">347 acl-2013-The Role of Syntax in Vector Space Models of Compositional Semantics</a></p>
<p>Author: Karl Moritz Hermann ; Phil Blunsom</p><p>Abstract: Modelling the compositional process by which the meaning of an utterance arises from the meaning of its parts is a fundamental task of Natural Language Processing. In this paper we draw upon recent advances in the learning of vector space representations of sentential semantics and the transparent interface between syntax and semantics provided by Combinatory Categorial Grammar to introduce Combinatory Categorial Autoencoders. This model leverages the CCG combinatory operators to guide a non-linear transformation of meaning within a sentence. We use this model to learn high dimensional embeddings for sentences and evaluate them in a range of tasks, demonstrating that the incorporation of syntax allows a concise model to learn representations that are both effective and general.</p><p>5 0.13341896 <a title="199-tfidf-5" href="./acl-2013-Accurate_Word_Segmentation_using_Transliteration_and_Language_Model_Projection.html">34 acl-2013-Accurate Word Segmentation using Transliteration and Language Model Projection</a></p>
<p>Author: Masato Hagiwara ; Satoshi Sekine</p><p>Abstract: Transliterated compound nouns not separated by whitespaces pose difficulty on word segmentation (WS) . Offline approaches have been proposed to split them using word statistics, but they rely on static lexicon, limiting their use. We propose an online approach, integrating source LM, and/or, back-transliteration and English LM. The experiments on Japanese and Chinese WS have shown that the proposed models achieve significant improvement over state-of-the-art, reducing 16% errors in Japanese.</p><p>6 0.11869 <a title="199-tfidf-6" href="./acl-2013-Semantic_Parsing_with_Combinatory_Categorial_Grammars.html">313 acl-2013-Semantic Parsing with Combinatory Categorial Grammars</a></p>
<p>7 0.088731021 <a title="199-tfidf-7" href="./acl-2013-Building_Japanese_Textual_Entailment_Specialized_Data_Sets_for_Inference_of_Basic_Sentence_Relations.html">75 acl-2013-Building Japanese Textual Entailment Specialized Data Sets for Inference of Basic Sentence Relations</a></p>
<p>8 0.086920761 <a title="199-tfidf-8" href="./acl-2013-Automated_Collocation_Suggestion_for_Japanese_Second_Language_Learners.html">58 acl-2013-Automated Collocation Suggestion for Japanese Second Language Learners</a></p>
<p>9 0.07830932 <a title="199-tfidf-9" href="./acl-2013-Part-of-Speech_Induction_in_Dependency_Trees_for_Statistical_Machine_Translation.html">276 acl-2013-Part-of-Speech Induction in Dependency Trees for Statistical Machine Translation</a></p>
<p>10 0.070164628 <a title="199-tfidf-10" href="./acl-2013-Chinese_Parsing_Exploiting_Characters.html">80 acl-2013-Chinese Parsing Exploiting Characters</a></p>
<p>11 0.064345032 <a title="199-tfidf-11" href="./acl-2013-Machine_Translation_Detection_from_Monolingual_Web-Text.html">235 acl-2013-Machine Translation Detection from Monolingual Web-Text</a></p>
<p>12 0.061526321 <a title="199-tfidf-12" href="./acl-2013-Survey_on_parsing_three_dependency_representations_for_English.html">335 acl-2013-Survey on parsing three dependency representations for English</a></p>
<p>13 0.058189258 <a title="199-tfidf-13" href="./acl-2013-Learning_to_Prune%3A_Context-Sensitive_Pruning_for_Syntactic_MT.html">226 acl-2013-Learning to Prune: Context-Sensitive Pruning for Syntactic MT</a></p>
<p>14 0.055985883 <a title="199-tfidf-14" href="./acl-2013-The_Effect_of_Higher-Order_Dependency_Features_in_Discriminative_Phrase-Structure_Parsing.html">343 acl-2013-The Effect of Higher-Order Dependency Features in Discriminative Phrase-Structure Parsing</a></p>
<p>15 0.054779656 <a title="199-tfidf-15" href="./acl-2013-A_Shift-Reduce_Parsing_Algorithm_for_Phrase-based_String-to-Dependency_Translation.html">19 acl-2013-A Shift-Reduce Parsing Algorithm for Phrase-based String-to-Dependency Translation</a></p>
<p>16 0.051405847 <a title="199-tfidf-16" href="./acl-2013-Semantic_Parsing_as_Machine_Translation.html">312 acl-2013-Semantic Parsing as Machine Translation</a></p>
<p>17 0.051001672 <a title="199-tfidf-17" href="./acl-2013-Subtree_Extractive_Summarization_via_Submodular_Maximization.html">332 acl-2013-Subtree Extractive Summarization via Submodular Maximization</a></p>
<p>18 0.047971025 <a title="199-tfidf-18" href="./acl-2013-Transition-based_Dependency_Parsing_with_Selectional_Branching.html">358 acl-2013-Transition-based Dependency Parsing with Selectional Branching</a></p>
<p>19 0.046599317 <a title="199-tfidf-19" href="./acl-2013-Is_a_204_cm_Man_Tall_or_Small_%3F_Acquisition_of_Numerical_Common_Sense_from_the_Web.html">202 acl-2013-Is a 204 cm Man Tall or Small ? Acquisition of Numerical Common Sense from the Web</a></p>
<p>20 0.045542799 <a title="199-tfidf-20" href="./acl-2013-Leveraging_Domain-Independent_Information_in_Semantic_Parsing.html">228 acl-2013-Leveraging Domain-Independent Information in Semantic Parsing</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.111), (1, -0.07), (2, -0.119), (3, -0.006), (4, -0.203), (5, -0.009), (6, 0.046), (7, -0.024), (8, 0.115), (9, -0.05), (10, 0.029), (11, 0.037), (12, 0.238), (13, -0.014), (14, -0.1), (15, 0.044), (16, 0.1), (17, 0.019), (18, -0.278), (19, 0.077), (20, 0.094), (21, -0.285), (22, -0.257), (23, 0.004), (24, 0.217), (25, 0.125), (26, -0.049), (27, 0.098), (28, 0.027), (29, -0.121), (30, 0.16), (31, -0.039), (32, -0.052), (33, 0.099), (34, -0.077), (35, 0.012), (36, -0.046), (37, 0.082), (38, -0.108), (39, 0.064), (40, -0.033), (41, 0.048), (42, -0.046), (43, 0.036), (44, -0.01), (45, -0.01), (46, -0.036), (47, 0.032), (48, 0.04), (49, -0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97470534 <a title="199-lsi-1" href="./acl-2013-Integrating_Multiple_Dependency_Corpora_for_Inducing_Wide-coverage_Japanese_CCG_Resources.html">199 acl-2013-Integrating Multiple Dependency Corpora for Inducing Wide-coverage Japanese CCG Resources</a></p>
<p>Author: Sumire Uematsu ; Takuya Matsuzaki ; Hiroki Hanaoka ; Yusuke Miyao ; Hideki Mima</p><p>Abstract: This paper describes a method of inducing wide-coverage CCG resources for Japanese. While deep parsers with corpusinduced grammars have been emerging for some languages, those for Japanese have not been widely studied, mainly because most Japanese syntactic resources are dependency-based. Our method first integrates multiple dependency-based corpora into phrase structure trees and then converts the trees into CCG derivations. The method is empirically evaluated in terms of the coverage of the obtained lexi- con and the accuracy of parsing.</p><p>2 0.8604098 <a title="199-lsi-2" href="./acl-2013-Using_CCG_categories_to_improve_Hindi_dependency_parsing.html">372 acl-2013-Using CCG categories to improve Hindi dependency parsing</a></p>
<p>Author: Bharat Ram Ambati ; Tejaswini Deoskar ; Mark Steedman</p><p>Abstract: We show that informative lexical categories from a strongly lexicalised formalism such as Combinatory Categorial Grammar (CCG) can improve dependency parsing of Hindi, a free word order language. We first describe a novel way to obtain a CCG lexicon and treebank from an existing dependency treebank, using a CCG parser. We use the output of a supertagger trained on the CCGbank as a feature for a state-of-the-art Hindi dependency parser (Malt). Our results show that using CCG categories improves the accuracy of Malt on long distance dependencies, for which it is known to have weak rates of recovery.</p><p>3 0.71765983 <a title="199-lsi-3" href="./acl-2013-Transfer_Learning_for_Constituency-Based_Grammars.html">357 acl-2013-Transfer Learning for Constituency-Based Grammars</a></p>
<p>Author: Yuan Zhang ; Regina Barzilay ; Amir Globerson</p><p>Abstract: In this paper, we consider the problem of cross-formalism transfer in parsing. We are interested in parsing constituencybased grammars such as HPSG and CCG using a small amount of data specific for the target formalism, and a large quantity of coarse CFG annotations from the Penn Treebank. While all of the target formalisms share a similar basic syntactic structure with Penn Treebank CFG, they also encode additional constraints and semantic features. To handle this apparent discrepancy, we design a probabilistic model that jointly generates CFG and target formalism parses. The model includes features of both parses, allowing trans- fer between the formalisms, while preserving parsing efficiency. We evaluate our approach on three constituency-based grammars CCG, HPSG, and LFG, augmented with the Penn Treebank-1. Our experiments show that across all three formalisms, the target parsers significantly benefit from the coarse annotations.1 —</p><p>4 0.6165216 <a title="199-lsi-4" href="./acl-2013-The_Role_of_Syntax_in_Vector_Space_Models_of_Compositional_Semantics.html">347 acl-2013-The Role of Syntax in Vector Space Models of Compositional Semantics</a></p>
<p>Author: Karl Moritz Hermann ; Phil Blunsom</p><p>Abstract: Modelling the compositional process by which the meaning of an utterance arises from the meaning of its parts is a fundamental task of Natural Language Processing. In this paper we draw upon recent advances in the learning of vector space representations of sentential semantics and the transparent interface between syntax and semantics provided by Combinatory Categorial Grammar to introduce Combinatory Categorial Autoencoders. This model leverages the CCG combinatory operators to guide a non-linear transformation of meaning within a sentence. We use this model to learn high dimensional embeddings for sentences and evaluate them in a range of tasks, demonstrating that the incorporation of syntax allows a concise model to learn representations that are both effective and general.</p><p>5 0.52939934 <a title="199-lsi-5" href="./acl-2013-Semantic_Parsing_with_Combinatory_Categorial_Grammars.html">313 acl-2013-Semantic Parsing with Combinatory Categorial Grammars</a></p>
<p>Author: Yoav Artzi ; Nicholas FitzGerald ; Luke Zettlemoyer</p><p>Abstract: unkown-abstract</p><p>6 0.29057068 <a title="199-lsi-6" href="./acl-2013-Survey_on_parsing_three_dependency_representations_for_English.html">335 acl-2013-Survey on parsing three dependency representations for English</a></p>
<p>7 0.25468335 <a title="199-lsi-7" href="./acl-2013-Large-scale_Semantic_Parsing_via_Schema_Matching_and_Lexicon_Extension.html">215 acl-2013-Large-scale Semantic Parsing via Schema Matching and Lexicon Extension</a></p>
<p>8 0.24493855 <a title="199-lsi-8" href="./acl-2013-ParGramBank%3A_The_ParGram_Parallel_Treebank.html">270 acl-2013-ParGramBank: The ParGram Parallel Treebank</a></p>
<p>9 0.23740636 <a title="199-lsi-9" href="./acl-2013-Accurate_Word_Segmentation_using_Transliteration_and_Language_Model_Projection.html">34 acl-2013-Accurate Word Segmentation using Transliteration and Language Model Projection</a></p>
<p>10 0.22213021 <a title="199-lsi-10" href="./acl-2013-Building_Japanese_Textual_Entailment_Specialized_Data_Sets_for_Inference_of_Basic_Sentence_Relations.html">75 acl-2013-Building Japanese Textual Entailment Specialized Data Sets for Inference of Basic Sentence Relations</a></p>
<p>11 0.2192774 <a title="199-lsi-11" href="./acl-2013-Is_a_204_cm_Man_Tall_or_Small_%3F_Acquisition_of_Numerical_Common_Sense_from_the_Web.html">202 acl-2013-Is a 204 cm Man Tall or Small ? Acquisition of Numerical Common Sense from the Web</a></p>
<p>12 0.21825638 <a title="199-lsi-12" href="./acl-2013-Joint_Inference_for_Heterogeneous_Dependency_Parsing.html">208 acl-2013-Joint Inference for Heterogeneous Dependency Parsing</a></p>
<p>13 0.21718904 <a title="199-lsi-13" href="./acl-2013-Parsing_with_Compositional_Vector_Grammars.html">275 acl-2013-Parsing with Compositional Vector Grammars</a></p>
<p>14 0.21374954 <a title="199-lsi-14" href="./acl-2013-Grounded_Unsupervised_Semantic_Parsing.html">176 acl-2013-Grounded Unsupervised Semantic Parsing</a></p>
<p>15 0.20645474 <a title="199-lsi-15" href="./acl-2013-Semantic_Neighborhoods_as_Hypergraphs.html">311 acl-2013-Semantic Neighborhoods as Hypergraphs</a></p>
<p>16 0.20257148 <a title="199-lsi-16" href="./acl-2013-Why-Question_Answering_using_Intra-_and_Inter-Sentential_Causal_Relations.html">387 acl-2013-Why-Question Answering using Intra- and Inter-Sentential Causal Relations</a></p>
<p>17 0.20118004 <a title="199-lsi-17" href="./acl-2013-Iterative_Transformation_of_Annotation_Guidelines_for_Constituency_Parsing.html">204 acl-2013-Iterative Transformation of Annotation Guidelines for Constituency Parsing</a></p>
<p>18 0.19539987 <a title="199-lsi-18" href="./acl-2013-Semantic_Parsing_as_Machine_Translation.html">312 acl-2013-Semantic Parsing as Machine Translation</a></p>
<p>19 0.19166227 <a title="199-lsi-19" href="./acl-2013-Coordination_Structures_in_Dependency_Treebanks.html">94 acl-2013-Coordination Structures in Dependency Treebanks</a></p>
<p>20 0.18864368 <a title="199-lsi-20" href="./acl-2013-Plurality%2C_Negation%2C_and_Quantification%3ATowards_Comprehensive_Quantifier_Scope_Disambiguation.html">280 acl-2013-Plurality, Negation, and Quantification:Towards Comprehensive Quantifier Scope Disambiguation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.017), (6, 0.019), (11, 0.096), (14, 0.022), (15, 0.398), (24, 0.014), (26, 0.022), (35, 0.025), (42, 0.182), (48, 0.018), (70, 0.046), (95, 0.042)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.89590991 <a title="199-lda-1" href="./acl-2013-Integrating_Multiple_Dependency_Corpora_for_Inducing_Wide-coverage_Japanese_CCG_Resources.html">199 acl-2013-Integrating Multiple Dependency Corpora for Inducing Wide-coverage Japanese CCG Resources</a></p>
<p>Author: Sumire Uematsu ; Takuya Matsuzaki ; Hiroki Hanaoka ; Yusuke Miyao ; Hideki Mima</p><p>Abstract: This paper describes a method of inducing wide-coverage CCG resources for Japanese. While deep parsers with corpusinduced grammars have been emerging for some languages, those for Japanese have not been widely studied, mainly because most Japanese syntactic resources are dependency-based. Our method first integrates multiple dependency-based corpora into phrase structure trees and then converts the trees into CCG derivations. The method is empirically evaluated in terms of the coverage of the obtained lexi- con and the accuracy of parsing.</p><p>2 0.84729666 <a title="199-lda-2" href="./acl-2013-Linguistic_Models_for_Analyzing_and_Detecting_Biased_Language.html">232 acl-2013-Linguistic Models for Analyzing and Detecting Biased Language</a></p>
<p>Author: Marta Recasens ; Cristian Danescu-Niculescu-Mizil ; Dan Jurafsky</p><p>Abstract: Unbiased language is a requirement for reference sources like encyclopedias and scientific texts. Bias is, nonetheless, ubiquitous, making it crucial to understand its nature and linguistic realization and hence detect bias automatically. To this end we analyze real instances of human edits designed to remove bias from Wikipedia articles. The analysis uncovers two classes of bias: framing bias, such as praising or perspective-specific words, which we link to the literature on subjectivity; and epistemological bias, related to whether propositions that are presupposed or entailed in the text are uncontroversially accepted as true. We identify common linguistic cues for these classes, including factive verbs, implicatives, hedges, and subjective inten- cs . sifiers. These insights help us develop features for a model to solve a new prediction task of practical importance: given a biased sentence, identify the bias-inducing word. Our linguistically-informed model performs almost as well as humans tested on the same task.</p><p>3 0.62579954 <a title="199-lda-3" href="./acl-2013-An_Information_Theoretic_Approach_to_Bilingual_Word_Clustering.html">47 acl-2013-An Information Theoretic Approach to Bilingual Word Clustering</a></p>
<p>Author: Manaal Faruqui ; Chris Dyer</p><p>Abstract: We present an information theoretic objective for bilingual word clustering that incorporates both monolingual distributional evidence as well as cross-lingual evidence from parallel corpora to learn high quality word clusters jointly in any number of languages. The monolingual component of our objective is the average mutual information of clusters of adjacent words in each language, while the bilingual component is the average mutual information of the aligned clusters. To evaluate our method, we use the word clusters in an NER system and demonstrate a statistically significant improvement in F1 score when using bilingual word clusters instead of monolingual clusters.</p><p>4 0.62235337 <a title="199-lda-4" href="./acl-2013-Offspring_from_Reproduction_Problems%3A_What_Replication_Failure_Teaches_Us.html">262 acl-2013-Offspring from Reproduction Problems: What Replication Failure Teaches Us</a></p>
<p>Author: Antske Fokkens ; Marieke van Erp ; Marten Postma ; Ted Pedersen ; Piek Vossen ; Nuno Freire</p><p>Abstract: Repeating experiments is an important instrument in the scientific toolbox to validate previous work and build upon existing work. We present two concrete use cases involving key techniques in the NLP domain for which we show that reproducing results is still difficult. We show that the deviation that can be found in reproduction efforts leads to questions about how our results should be interpreted. Moreover, investigating these deviations provides new insights and a deeper understanding of the examined techniques. We identify five aspects that can influence the outcomes of experiments that are typically not addressed in research papers. Our use cases show that these aspects may change the answer to research questions leading us to conclude that more care should be taken in interpreting our results and more research involving systematic testing of methods is required in our field.</p><p>5 0.57733482 <a title="199-lda-5" href="./acl-2013-SEMILAR%3A_The_Semantic_Similarity_Toolkit.html">304 acl-2013-SEMILAR: The Semantic Similarity Toolkit</a></p>
<p>Author: Vasile Rus ; Mihai Lintean ; Rajendra Banjade ; Nobal Niraula ; Dan Stefanescu</p><p>Abstract: We present in this paper SEMILAR, the SEMantic simILARity toolkit. SEMILAR implements a number of algorithms for assessing the semantic similarity between two texts. It is available as a Java library and as a Java standalone ap-plication offering GUI-based access to the implemented semantic similarity methods. Furthermore, it offers facilities for manual se-mantic similarity annotation by experts through its component SEMILAT (a SEMantic simILarity Annotation Tool). 1</p><p>6 0.55593473 <a title="199-lda-6" href="./acl-2013-Linking_Tweets_to_News%3A_A_Framework_to_Enrich_Short_Text_Data_in_Social_Media.html">233 acl-2013-Linking Tweets to News: A Framework to Enrich Short Text Data in Social Media</a></p>
<p>7 0.48894775 <a title="199-lda-7" href="./acl-2013-Combining_Referring_Expression_Generation_and_Surface_Realization%3A_A_Corpus-Based_Investigation_of_Architectures.html">86 acl-2013-Combining Referring Expression Generation and Surface Realization: A Corpus-Based Investigation of Architectures</a></p>
<p>8 0.47602153 <a title="199-lda-8" href="./acl-2013-Automatically_Predicting_Sentence_Translation_Difficulty.html">64 acl-2013-Automatically Predicting Sentence Translation Difficulty</a></p>
<p>9 0.46181715 <a title="199-lda-9" href="./acl-2013-Using_CCG_categories_to_improve_Hindi_dependency_parsing.html">372 acl-2013-Using CCG categories to improve Hindi dependency parsing</a></p>
<p>10 0.45320752 <a title="199-lda-10" href="./acl-2013-Joint_Event_Extraction_via_Structured_Prediction_with_Global_Features.html">206 acl-2013-Joint Event Extraction via Structured Prediction with Global Features</a></p>
<p>11 0.45069185 <a title="199-lda-11" href="./acl-2013-Distortion_Model_Considering_Rich_Context_for_Statistical_Machine_Translation.html">125 acl-2013-Distortion Model Considering Rich Context for Statistical Machine Translation</a></p>
<p>12 0.44571733 <a title="199-lda-12" href="./acl-2013-Robust_Automated_Natural_Language_Processing_with_Multiword_Expressions_and_Collocations.html">302 acl-2013-Robust Automated Natural Language Processing with Multiword Expressions and Collocations</a></p>
<p>13 0.4432514 <a title="199-lda-13" href="./acl-2013-Advancements_in_Reordering_Models_for_Statistical_Machine_Translation.html">40 acl-2013-Advancements in Reordering Models for Statistical Machine Translation</a></p>
<p>14 0.44209406 <a title="199-lda-14" href="./acl-2013-A_Multi-Domain_Translation_Model_Framework_for_Statistical_Machine_Translation.html">11 acl-2013-A Multi-Domain Translation Model Framework for Statistical Machine Translation</a></p>
<p>15 0.42830837 <a title="199-lda-15" href="./acl-2013-Additive_Neural_Networks_for_Statistical_Machine_Translation.html">38 acl-2013-Additive Neural Networks for Statistical Machine Translation</a></p>
<p>16 0.40888163 <a title="199-lda-16" href="./acl-2013-Post-Retrieval_Clustering_Using_Third-Order_Similarity_Measures.html">281 acl-2013-Post-Retrieval Clustering Using Third-Order Similarity Measures</a></p>
<p>17 0.40751263 <a title="199-lda-17" href="./acl-2013-Argument_Inference_from_Relevant_Event_Mentions_in_Chinese_Argument_Extraction.html">56 acl-2013-Argument Inference from Relevant Event Mentions in Chinese Argument Extraction</a></p>
<p>18 0.40297067 <a title="199-lda-18" href="./acl-2013-Vector_Space_Model_for_Adaptation_in_Statistical_Machine_Translation.html">383 acl-2013-Vector Space Model for Adaptation in Statistical Machine Translation</a></p>
<p>19 0.39787665 <a title="199-lda-19" href="./acl-2013-Easy-First_POS_Tagging_and_Dependency_Parsing_with_Beam_Search.html">132 acl-2013-Easy-First POS Tagging and Dependency Parsing with Beam Search</a></p>
<p>20 0.39517939 <a title="199-lda-20" href="./acl-2013-Learning_to_Order_Natural_Language_Texts.html">225 acl-2013-Learning to Order Natural Language Texts</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
