<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>145 acl-2013-Exploiting Qualitative Information from Automatic Word Alignment for Cross-lingual NLP Tasks</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-145" href="#">acl2013-145</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>145 acl-2013-Exploiting Qualitative Information from Automatic Word Alignment for Cross-lingual NLP Tasks</h1>
<br/><p>Source: <a title="acl-2013-145-pdf" href="http://aclweb.org/anthology//P/P13/P13-2135.pdf">pdf</a></p><p>Author: Jose G.C. de Souza ; Miquel Espla-Gomis ; Marco Turchi ; Matteo Negri</p><p>Abstract: The use of automatic word alignment to capture sentence-level semantic relations is common to a number of cross-lingual NLP applications. Despite its proved usefulness, however, word alignment information is typically considered from a quantitative point of view (e.g. the number of alignments), disregarding qualitative aspects (the importance of aligned terms). In this paper we demonstrate that integrating qualitative information can bring significant performance improvements with negligible impact on system complexity. Focusing on the cross-lingual textual en- tailment task, we contribute with a novel method that: i) significantly outperforms the state of the art, and ii) is portable, with limited loss in performance, to language pairs where training data are not available.</p><p>Reference: <a title="acl-2013-145-reference" href="../acl2013_reference/acl-2013-Exploiting_Qualitative_Information_from_Automatic_Word_Alignment_for_Cross-lingual_NLP_Tasks_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 de Souza Miquel Espl a`-Gomis FBK-irst, Universitat d’Alacant University of Trento Alacant, Spain Trento, Italy me spla@ dl s i . [sent-3, score-0.045]
</p><p>2 eu Abstract The use of automatic word alignment to capture sentence-level semantic relations is common to a number of cross-lingual NLP applications. [sent-6, score-0.111]
</p><p>3 Despite its proved usefulness, however, word alignment information is typically considered from a quantitative point of view (e. [sent-7, score-0.147]
</p><p>4 the number of alignments), disregarding qualitative aspects (the importance of aligned terms). [sent-9, score-0.248]
</p><p>5 In this paper we demonstrate that integrating qualitative information can bring significant performance improvements with negligible impact on system complexity. [sent-10, score-0.159]
</p><p>6 Focusing on the cross-lingual textual en-  tailment task, we contribute with a novel method that: i) significantly outperforms the state of the art, and ii) is portable, with limited loss in performance, to language pairs where training data are not available. [sent-11, score-0.093]
</p><p>7 So far, despite the relevance of the problem, research on multilingual applications has either circumvented the issue, or proposed partial solutions. [sent-13, score-0.027]
</p><p>8 When possible, the typical approach builds on the reduction to a monolingual task, burdening the process with dependencies from machine translation (MT) components. [sent-14, score-0.029]
</p><p>9 For instance, in crosslingual question answering and cross-lingual textual entailment (CLTE), intermediate MT steps are respectively performed to ease answer retrieval/presentation (Parton, 2012; Tanev et al. [sent-15, score-0.142]
</p><p>10 Direct solutions that avoid such pivoting strategies typically exploit similarity measures  that rely on bag-of-words representations. [sent-18, score-0.034]
</p><p>11 As an Marco Turchi Matteo Negri FBK-irst FBK-irst Trento, Italy Trento, Italy turchi @ fbk . [sent-19, score-0.086]
</p><p>12 , 2012) and CLTE (W¨ aschle and Fendrich, 2012) include features that consider the amount of equivalent terms that are found in the input sentence pairs. [sent-23, score-0.122]
</p><p>13 Such simplification, however, disregards the fact that semantic equivalence is not only proportional to the number of equivalent terms, but also to their importance. [sent-24, score-0.06]
</p><p>14 In other words, instead of checking what of a given sentence can be found in the other, current approaches limit the analysis to the amount of lexical elements they share, under the rough assumption that the more the better. [sent-25, score-0.026]
</p><p>15 In this paper we argue that: (1) Considering qualitative aspects of word alignments to identify sentence-level semantic relations  can bring significant performance improvements in cross-lingual NLP tasks. [sent-26, score-0.271]
</p><p>16 (2) Shallow linguistic processing techniques (often a constraint in real cross-lingual scenarios due to limited resources availability) can be leveraged to set up portable solutions that still outperform current bag-of-words methods. [sent-27, score-0.048]
</p><p>17 To support our claims we experiment with the CLTE task, which allows us to perform exhaustive comparative experiments due to the availability of comparable benchmarks for different language pairs. [sent-28, score-0.031]
</p><p>18 In the remainder of the paper, we: (1) Prove the effectiveness of our method over datasets for four language combinations; (2) Assess the portability of our models across languages in different testing conditions. [sent-29, score-0.032]
</p><p>19 2  Objectives and Method  We propose a supervised learning approach for identifying and classifying semantic relations between two sentences T1 and T2 written in different languages. [sent-30, score-0.026]
</p><p>20 c A2s0s1o3ci Aatsiosonc fioartio Cno fmorpu Ctoamtiopnuatalt Lioin gauli Lsitnicgsu,i psatgices 7 1–7 6,  labeled data are available for language pair L1-L2. [sent-33, score-0.077]
</p><p>21 (b): the L1-L2 CLTE model is used to cope with the unavailability of labeled data for L3-L4. [sent-34, score-0.038]
</p><p>22 , 2012b),1 we aim to capture a richer set of relations potentially relevant to other tasks. [sent-37, score-0.026]
</p><p>23 For instance, recognizing unrelatedness, forward and backward entailment relations, represents a core problem in cross-lingual document summarization (Lenci et al. [sent-38, score-0.131]
</p><p>24 , 2013), represents an ideal framework to evaluate such capabilities. [sent-44, score-0.022]
</p><p>25 Within this framework, our goal is to automatically identify the fol-  lowing entailment relations between T1 and T2: forward (T1 → T2), backward (T1 ← T2), bidirectional (T1 ↔ T2) and no entailme←nt. [sent-45, score-0.183]
</p><p>26 Our approach (see Figure 1) involves two core components: i) a word alignment model, and ii) a CLTE classifier. [sent-46, score-0.085]
</p><p>27 The former is trained on a parallel corpus, and associates equivalent terms in T1 and T2. [sent-47, score-0.093]
</p><p>28 The information about word alignments is used to extract quantitative (amount and distribution of the alignments) and qualitative features (importance of the aligned terms) to train the CLTE classifier. [sent-48, score-0.419]
</p><p>29 Although in principle both components need training data (respectively a parallel corpus and labeled CLTE data), our goal is to develop a method that is also portable across languages. [sent-49, score-0.126]
</p><p>30 To this aim, while the parallel corpus is necessary to train the word aligner for any language pair we want to deal with, the CLTE clas1A translation has to be semantically equivalent to the source sentence. [sent-50, score-0.133]
</p><p>31 sifier can be designed to learn from features that capture language independent knowledge. [sent-51, score-0.023]
</p><p>32 2 This  allows us to experiment in different testing conditions, namely: i) when CLTE training data are available for a given language pair (Figure 1a), and ii) when CLTE training data are missing, and a model trained on other language pairs has to be reused (Figure 1b-c). [sent-52, score-0.067]
</p><p>33 Considering word alignment information, we extract three different groups of features: AL, POS, and IDF. [sent-54, score-0.085]
</p><p>34 The AL group provides quantitative information about the aligned/unaligned words in each sentence T∗ of the pair. [sent-55, score-0.062]
</p><p>35 number of sequences of unaligned words, normalized by the length of T∗; 3. [sent-59, score-0.089]
</p><p>36 length of the longest a) sequence of aligned words, and b) sequence of unaligned words, both normalized by the length of T∗ ; 4. [sent-60, score-0.228]
</p><p>37 average length of a) the aligned word sequences, and b) the unaligned word sequences;  5. [sent-61, score-0.204]
</p><p>38 position of a) the first unaligned word, and b) the last unaligned word, both normalized by the lenght of T∗ ; 6. [sent-62, score-0.178]
</p><p>39 proportion of word n-grams in T∗ containing only aligned words (the feature was com2For instance, the fact that aligning all nouns and the most relevant terms in T1 and T2 is a good indicator of semantic equivalence. [sent-63, score-0.218]
</p><p>40 The POS group considers the part of speech (PoS) of the words in T∗ as a source of qualitative information about their importance. [sent-68, score-0.133]
</p><p>41 To compute these features we use the TreeTagger (Schmid, 1995), manually mapping the fine-grained set of assigned PoS labels into a more general set of tags (P) based on the universal PoS tag set by Petrov et al. [sent-69, score-0.064]
</p><p>42 POS features differentiate between aligned words (words in T1 that are aligned to one or more words in T2) and alignments (the edges connecting words in T1 and T2). [sent-71, score-0.37]
</p><p>43 Features considering the aligned words in T∗ are:  7. [sent-72, score-0.14]
</p><p>44 for each PoS tag p ∈ P, proportion of aligned wfoorr edasc ihn P T∗ tagged ∈w Pith, p p; 8. [sent-73, score-0.26]
</p><p>45 proportion of words in T1 aligned with words with the same PoS tag in T2 (and vice-versa); 9. [sent-74, score-0.236]
</p><p>46 for each PoS tag p ∈ P, proportion of words fino T1 tagged as p pw ∈hic Ph, are aligned otof wwoorrddss with the same tag in T2 (and vice-versa). [sent-75, score-0.301]
</p><p>47 proportion of alignments connecting words with the same PoS tag p; 11. [sent-77, score-0.238]
</p><p>48 for each PoS tag p ∈ P, proportion of alignments connecting two Pw,o prdrosp tagged as p. [sent-78, score-0.262]
</p><p>49 IDF, the last feature, uses the inverse document frequency (Salton and Buckley, 1988) as another source of qualitative information under the assumption that rare words (and, therefore, with higher IDF) are more informative: 12. [sent-79, score-0.133]
</p><p>50 summation of all the IDF scores of the aligned words in T∗ over the summation of  the IDF scores of all words in T∗. [sent-80, score-0.187]
</p><p>51 First, the typical one, in which the CLTE model is trained on labeled data for the same pair of languages L1–L2 of the test set. [sent-82, score-0.105]
</p><p>52 Then, simulating the less favorable situation in which labeled training data for L1–L2 are missing, we investigate the possibility to use existing CLTE models trained on labeled data for a different language pair L3–L4. [sent-83, score-0.143]
</p><p>53 To train the word alignment models we used the Europarl parallel corpus (Koehn, 2005), concatenated with the News Commentary corpus3 for three language pairs: De–En (2,079,049 sentences), Es–En (2,123,036 sentences), Fr–En (2,144,820 sentences). [sent-87, score-0.125]
</p><p>54 For It–En we only used  the parallel data available in Europarl (1,909,1 15 sentences) since this language pair is not covered by the News Commentary corpus. [sent-88, score-0.079]
</p><p>55 To build the word alignment models we used the MGIZA++ package (Gao and Vogel, 2008). [sent-90, score-0.085]
</p><p>56 4 We also explored three symmetrization techniques (Koehn et al. [sent-94, score-0.066]
</p><p>57 A greedy feature selection process on training data, with different combinations of word alignment models and symmetrization methods, indicated HMM/intersection as the best performing combination. [sent-96, score-0.185]
</p><p>58 5 Two binary classifiers were trained to separately check T1 → T2 and T1 ← T2, merging  their output to obtain the 4-clas←s judgments (e. [sent-100, score-0.028]
</p><p>59 1 Evaluation with CLTE training data Figure 2 shows the accuracy obtained by the different feature For the sake of comparison, state-of-the-art results achieved for each language combination at SemEval 2012 are also reported. [sent-104, score-0.022]
</p><p>60 8%), the top scores were obtained by the system described in (W¨ aschle and Fendrich, 2012), where a combination of binary classifiers for each entailment direction is trained with a mix-  groups. [sent-107, score-0.198]
</p><p>61 0, and d = 1) 6In Figures 2 and 3, the “*” indicates statistically significant improvements over the state of the art at p ≤ 0. [sent-113, score-0.138]
</p><p>62 Although such system exploits word-alignment information to some extent, this is only done at quantitative level (e. [sent-119, score-0.062]
</p><p>63 number of unaligned words, percentage of aligned words, length of the longest unaligned subsequence). [sent-121, score-0.317]
</p><p>64 , 2012), which uses a pure pivoting method (using Google Translate) and adaptive similarity functions based on “soft” cardinality for flexible term comparisons. [sent-124, score-0.09]
</p><p>65 As can be seen in Figure 2, the combination of all our features outperforms the state of the art for each language pair. [sent-128, score-0.157]
</p><p>66 Except for Es–En, that has very competitive stateof-the-art results, the combination ofAL with POS or IDF feature groups always outperforms the best systems. [sent-135, score-0.022]
</p><p>67 Furthermore, the performance increase  with qualitative features (POS and IDF) shows coherent trends across all language pairs. [sent-136, score-0.156]
</p><p>68 It is worth noting that, while we rely on a pure cross-lingual approach, both the state-of-the-art CLTE systems include features from the translation of T1 into the language of T2. [sent-137, score-0.078]
</p><p>69 For De–En, quantitative features alone achieve lower results compared to the other languages. [sent-138, score-0.085]
</p><p>70 This can be motivated by the higher difficulty in aligning De–En pairs (this hypothesis is supported by the fact that the average number of alignments per sentence pair is 18 for De–En, and >22 for the other combinations). [sent-139, score-0.148]
</p><p>71 Nevertheless, qualitative features lead to results comparable 7http : / /t ran s l e . [sent-140, score-0.156]
</p><p>72 The selection of the best performing features for each language pair produces further improvements of varying degrees in Es–En (from 67. [sent-143, score-0.088]
</p><p>73 All these configurations include the IDF feature (12) and the proportion of aligned –  –  words for each PoS category (7), proving the effectiveness of qualitative word alignment features. [sent-148, score-0.413]
</p><p>74 The fact that HMM/intersection is the best combination of alignment model and symmetrization method is interesting, since it contradicts the general notion that IBM models 3 and 4 perform better than HMM (Och and Ney, 2003). [sent-149, score-0.173]
</p><p>75 A possible explanation is that, while word alignment models are usually trained on parallel corpora, the majority of CLTE sentence pairs are not parallel. [sent-150, score-0.153]
</p><p>76 In this setting, where producing reliable alignments is more difficult, IBM models are less effective for at least two reasons. [sent-151, score-0.086]
</p><p>77 First, including a word fertility model, IBM 3 and 4 limit (typically to the half of the source sentence length) the number of target words that can be aligned with the nul l word. [sent-152, score-0.141]
</p><p>78 Therefore, when such limit is reached, these models tend to force low probability, hence less reliable, word alignments. [sent-153, score-0.026]
</p><p>79 Second, in IBM model 4, the larger distortion limit makes it possible to align distant words. [sent-154, score-0.026]
</p><p>80 In the case of non-parallel sentences, this often results in wrong or noisy alignments that affect final results. [sent-155, score-0.086]
</p><p>81 For these reasons,  CLTE data seem more suitable for the simpler and more conservative HMM model, and a precisionoriented symmetrization method like intersection. [sent-156, score-0.066]
</p><p>82 Confirming this would allow to reuse models trained for a given language pair in situations where CLTE training data is missing. [sent-159, score-0.067]
</p><p>83 This is a rather realistic situation since, while bitexts to train word aligners are easier to find, the availability of labeled CLTE data is far from being guaranteed. [sent-160, score-0.105]
</p><p>84 Our experiments have been carried out, over the same SemEval datasets, with two methods that do not use labeled data for the target language combination. [sent-161, score-0.038]
</p><p>85 The first one (method b in Figure 1) uses a CLTE model trained for a language pair L1–L2 for which labeled training data are avail774  able, and applies this model to a language pair  L3–L4 for which only parallel corpora are available. [sent-162, score-0.184]
</p><p>86 The second method (c in Figure 1) addresses the same problem, but exploits a combination of CLTE models trained for different language pairs. [sent-163, score-0.05]
</p><p>87 For each test set, the models trained for the other three language pairs are used in a voting scheme, in order to check whether they can complement each other to increase final results. [sent-164, score-0.075]
</p><p>88 Figure 3: Accuracy obtained by reusing CLTE models (alone and in a voting scheme). [sent-167, score-0.08]
</p><p>89 As shown in Figure 3, reusing models for a new language pair leads to results that still outperform the state of the art. [sent-168, score-0.119]
</p><p>90 6 Remarkably, when used for other language combinations, the Es–En, It–En, and Fr–En models always lead to results above, or equal to the state of the art. [sent-169, score-0.047]
</p><p>91 For similar languages such as Spanish, French, and Italian, the accuracy increase over the state of the art is up to 14. [sent-170, score-0.112]
</p><p>92 Although not always statistically significant and below the performance obtained in the ideal scenario where CLTE training data are available (full sys. [sent-177, score-0.022]
</p><p>93 ), such improvements suggest that our features can be re-used, at least to some extent, across different language settings. [sent-178, score-0.049]
</p><p>94 when tested on It–En) the De–En model still achieves results above the state of the art, and ii) on the De–En evaluation setting the worst model (Fr–En) still achieves state of the art results. [sent-182, score-0.159]
</p><p>95 The results obtained with the voting scheme suggest that our models can complement each other when used on a new language pair. [sent-183, score-0.047]
</p><p>96 Although statistically significant only over It–En data, voting results both outperform the state of the art and the results achieved by single models. [sent-184, score-0.159]
</p><p>97 4  Conclusion  We investigated the usefulness of qualitative information from automatic word alignment to identify semantic relations between sentences in different languages. [sent-185, score-0.244]
</p><p>98 With coherent results in CLTE, we demonstrated that features considering the importance of aligned terms can successfully integrate the quantitative evidence (number and proportion of aligned terms) used by previous supervised learning approaches. [sent-186, score-0.42]
</p><p>99 A study on the portability across languages of the learned models demonstrated that word alignment information  can be exploited to train reusable models for new language combinations where bitexts are available but CLTE labeled data are not. [sent-187, score-0.225]
</p><p>100 In Proceedings of the Third International Conference on Language Resources and Evaluation (LREC’02), pages 1464–1471, Las Palmas de Gran Canaria, Spain. [sent-231, score-0.045]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('clte', 0.715), ('negri', 0.261), ('matteo', 0.181), ('mehdad', 0.18), ('en', 0.177), ('qualitative', 0.133), ('yashar', 0.132), ('idf', 0.121), ('aligned', 0.115), ('semeval', 0.1), ('unaligned', 0.089), ('alignments', 0.086), ('alignment', 0.085), ('proportion', 0.08), ('entailment', 0.074), ('aschle', 0.074), ('es', 0.07), ('fr', 0.07), ('symmetrization', 0.066), ('pos', 0.066), ('art', 0.065), ('quantitative', 0.062), ('eal', 0.052), ('montr', 0.05), ('fbk', 0.05), ('alacant', 0.049), ('cosyne', 0.049), ('fendrich', 0.049), ('jimenez', 0.049), ('portable', 0.048), ('state', 0.047), ('voting', 0.047), ('textual', 0.046), ('bentivogli', 0.045), ('danilo', 0.045), ('luisa', 0.045), ('trento', 0.045), ('de', 0.045), ('hmm', 0.044), ('marchetti', 0.044), ('synchronization', 0.044), ('ibm', 0.042), ('alessandro', 0.041), ('monz', 0.041), ('tag', 0.041), ('tanev', 0.04), ('parallel', 0.04), ('pair', 0.039), ('europarl', 0.039), ('blatz', 0.038), ('labeled', 0.038), ('vogel', 0.036), ('bitexts', 0.036), ('summation', 0.036), ('turchi', 0.036), ('italy', 0.035), ('equivalence', 0.035), ('pivoting', 0.034), ('combinations', 0.034), ('reusing', 0.033), ('portability', 0.032), ('mt', 0.032), ('stephan', 0.031), ('connecting', 0.031), ('availability', 0.031), ('lenci', 0.031), ('salton', 0.03), ('cardinality', 0.03), ('forward', 0.03), ('regards', 0.029), ('marcello', 0.029), ('translation', 0.029), ('trained', 0.028), ('koehn', 0.028), ('multilingual', 0.027), ('jos', 0.027), ('commentary', 0.027), ('backward', 0.027), ('extent', 0.027), ('relations', 0.026), ('christoph', 0.026), ('limit', 0.026), ('pure', 0.026), ('bidirectional', 0.026), ('improvements', 0.026), ('weka', 0.025), ('equivalent', 0.025), ('considering', 0.025), ('ye', 0.025), ('ii', 0.024), ('tagged', 0.024), ('longest', 0.024), ('della', 0.023), ('aligning', 0.023), ('features', 0.023), ('ideal', 0.022), ('answering', 0.022), ('combination', 0.022), ('kouylekov', 0.022), ('milen', 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="145-tfidf-1" href="./acl-2013-Exploiting_Qualitative_Information_from_Automatic_Word_Alignment_for_Cross-lingual_NLP_Tasks.html">145 acl-2013-Exploiting Qualitative Information from Automatic Word Alignment for Cross-lingual NLP Tasks</a></p>
<p>Author: Jose G.C. de Souza ; Miquel Espla-Gomis ; Marco Turchi ; Matteo Negri</p><p>Abstract: The use of automatic word alignment to capture sentence-level semantic relations is common to a number of cross-lingual NLP applications. Despite its proved usefulness, however, word alignment information is typically considered from a quantitative point of view (e.g. the number of alignments), disregarding qualitative aspects (the importance of aligned terms). In this paper we demonstrate that integrating qualitative information can bring significant performance improvements with negligible impact on system complexity. Focusing on the cross-lingual textual en- tailment task, we contribute with a novel method that: i) significantly outperforms the state of the art, and ii) is portable, with limited loss in performance, to language pairs where training data are not available.</p><p>2 0.10382136 <a title="145-tfidf-2" href="./acl-2013-A_Lightweight_and_High_Performance_Monolingual_Word_Aligner.html">9 acl-2013-A Lightweight and High Performance Monolingual Word Aligner</a></p>
<p>Author: Xuchen Yao ; Benjamin Van Durme ; Chris Callison-Burch ; Peter Clark</p><p>Abstract: Fast alignment is essential for many natural language tasks. But in the setting of monolingual alignment, previous work has not been able to align more than one sentence pair per second. We describe a discriminatively trained monolingual word aligner that uses a Conditional Random Field to globally decode the best alignment with features drawn from source and target sentences. Using just part-of-speech tags and WordNet as external resources, our aligner gives state-of-the-art result, while being an order-of-magnitude faster than the previous best performing system.</p><p>3 0.098179951 <a title="145-tfidf-3" href="./acl-2013-Simpler_unsupervised_POS_tagging_with_bilingual_projections.html">323 acl-2013-Simpler unsupervised POS tagging with bilingual projections</a></p>
<p>Author: Long Duong ; Paul Cook ; Steven Bird ; Pavel Pecina</p><p>Abstract: We present an unsupervised approach to part-of-speech tagging based on projections of tags in a word-aligned bilingual parallel corpus. In contrast to the existing state-of-the-art approach of Das and Petrov, we have developed a substantially simpler method by automatically identifying “good” training sentences from the parallel corpus and applying self-training. In experimental results on eight languages, our method achieves state-of-the-art results. 1 Unsupervised part-of-speech tagging Currently, part-of-speech (POS) taggers are available for many highly spoken and well-resourced languages such as English, French, German, Italian, and Arabic. For example, Petrov et al. (2012) build supervised POS taggers for 22 languages using the TNT tagger (Brants, 2000), with an average accuracy of 95.2%. However, many widelyspoken languages including Bengali, Javanese, and Lahnda have little data manually labelled for POS, limiting supervised approaches to POS tagging for these languages. However, with the growing quantity of text available online, and in particular, multilingual parallel texts from sources such as multilingual websites, government documents and large archives ofhuman translations ofbooks, news, and so forth, unannotated parallel data is becoming more widely available. This parallel data can be exploited to bridge languages, and in particular, transfer information from a highly-resourced language to a lesser-resourced language, to build unsupervised POS taggers. In this paper, we propose an unsupervised approach to POS tagging in a similar vein to the work of Das and Petrov (201 1). In this approach, — — pecina@ ufal .mff .cuni . c z a parallel corpus for a more-resourced language having a POS tagger, and a lesser-resourced language, is word-aligned. These alignments are exploited to infer an unsupervised tagger for the target language (i.e., a tagger not requiring manuallylabelled data in the target language). Our approach is substantially simpler than that of Das and Petrov, the current state-of-the art, yet performs comparably well. 2 Related work There is a wealth of prior research on building unsupervised POS taggers. Some approaches have exploited similarities between typologically similar languages (e.g., Czech and Russian, or Telugu and Kannada) to estimate the transition probabilities for an HMM tagger for one language based on a corpus for another language (e.g., Hana et al., 2004; Feldman et al., 2006; Reddy and Sharoff, 2011). Other approaches have simultaneously tagged two languages based on alignments in a parallel corpus (e.g., Snyder et al., 2008). A number of studies have used tag projection to copy tag information from a resource-rich to a resource-poor language, based on word alignments in a parallel corpus. After alignment, the resource-rich language is tagged, and tags are projected from the source language to the target language based on the alignment (e.g., Yarowsky and Ngai, 2001 ; Das and Petrov, 2011). Das and Petrov (201 1) achieved the current state-of-the-art for unsupervised tagging by exploiting high confidence alignments to copy tags from the source language to the target language. Graph-based label propagation was used to automatically produce more labelled training data. First, a graph was constructed in which each vertex corresponds to a unique trigram, and edge weights represent the syntactic similarity between vertices. Labels were then propagated by optimizing a convex function to favor the same tags for closely related nodes 634 Proce dingSsof oifa, th Beu 5l1gsarti Aan,An u aglu Mste 4e-ti9n2g 0 o1f3 t.he ?c A2s0s1o3ci Aatsiosonc fioartio Cno fmorpu Ctoamtiopnuatalt Lioin gauli Lsitnicgsu,i psatgices 634–639, ModelCoverageAccuracy Many-to-1 alignments88%68% 1-to-1 alignments 68% 78% 1-to-1 alignments: Top 60k sents 91% 80% Table 1: Token coverage and accuracy of manyto-one and 1-to-1 alignments, as well as the top 60k sentences based on alignment score for 1-to-1 alignments, using directly-projected labels only. while keeping a uniform tag distribution for unrelated nodes. A tag dictionary was then extracted from the automatically labelled data, and this was used to constrain a feature-based HMM tagger. The method we propose here is simpler to that of Das and Petrov in that it does not require convex optimization for label propagation or a feature based HMM, yet it achieves comparable results. 3 Tagset Our tagger exploits the idea ofprojecting tag information from a resource-rich to resource-poor language. To facilitate this mapping, we adopt Petrov et al.’s (2012) twelve universal tags: NOUN, VERB, ADJ, ADV, PRON (pronouns), DET (de- terminers and articles), ADP (prepositions and postpositions), NUM (numerals), CONJ (conjunctions), PRT (particles), “.” (punctuation), and X (all other categories, e.g., foreign words, abbreviations). These twelve basic tags are common across taggers for most languages. Adopting a universal tagset avoids the need to map between a variety of different, languagespecific tagsets. Furthermore, it makes it possible to apply unsupervised tagging methods to languages for which no tagset is available, such as Telugu and Vietnamese. 4 A Simpler Unsupervised POS Tagger Here we describe our proposed tagger. The key idea is to maximize the amount of information gleaned from the source language, while limiting the amount of noise. We describe the seed model and then explain how it is successively refined through self-training and revision. 4.1 Seed Model The first step is to construct a seed tagger from directly-projected labels. Given a parallel corpus for a source and target language, Algorithm 1provides a method for building an unsupervised tagger for the target language. In typical applications, the source language would be a better-resourced language having a tagger, while the target language would be lesser-resourced, lacking a tagger and large amounts of manually POS-labelled data. Algorithm 1 Build seed model Algorithm 1Build seed model 1:Tag source side. 2: Word align the corpus with Giza++ and remove the many-to-one mappings. 3: Project tags from source to target using the remaining 1-to-1 alignments. 4: Select the top n sentences based on sentence alignment score. 5: Estimate emission and transition probabilities. 6: Build seed tagger T. We eliminate many-to-one alignments (Step 2). Keeping these would give more POS-tagged tokens for the target side, but also introduce noise. For example, suppose English and French were the source and target language, respectively. In this case alignments such as English laws (NNS) to French les (DT) lois (NNS) would be expected (Yarowsky and Ngai, 2001). However, in Step 3, where tags are projected from the source to target language, this would incorrectly tag French les as NN. We build a French tagger based on English– French data from the Europarl Corpus (Koehn, 2005). We also compare the accuracy and coverage of the tags obtained through direct projection using the French Melt POS tagger (Denis and Sagot, 2009). Table 1confirms that the one-to-one alignments indeed give higher accuracy but lower coverage than the many-to-one alignments. At this stage of the model we hypothesize that highconfidence tags are important, and hence eliminate the many-to-one alignments. In Step 4, in an effort to again obtain higher quality target language tags from direct projection, we eliminate all but the top n sentences based on their alignment scores, as provided by the aligner via IBM model 3. We heuristically set this cutoff × to 60k to balance the accuracy and size of the seed model.1 Returning to our preliminary English– French experiments in Table 1, this process gives improvements in both accuracy and coverage.2 1We considered values in the range 60–90k, but this choice had little impact on the accuracy of the model. 2We also considered using all projected labels for the top 60k sentences, not just 1-to-1 alignments, but in preliminary experiments this did not perform as well, possibly due to the previously-observed problems with many-to-one alignments. 635 The number of parameters for the emission probability is |V | |T| where V is the vocabulary and aTb iilsi ttyh eis tag |s e×t. TTh| ew htrearnesi Vtio ins probability, on atnhed other hand, has only |T|3 parameters for the trigram hmaondde,l we use. TB|ecause of this difference in number of parameters, in step 5, we use different strategies to estimate the emission and transition probabilities. The emission probability is estimated from all 60k selected sentences. However, for the transition probability, which has less parameters, we again focus on “better” sentences, by estimating this probability from only those sen- tences that have (1) token coverage > 90% (based on direct projection of tags from the source language), and (2) length > 4 tokens. These criteria aim to identify longer, mostly-tagged sentences, which we hypothesize are particularly useful as training data. In the case of our preliminary English–French experiments, roughly 62% of the 60k selected sentences meet these criteria and are used to estimate the transition probability. For unaligned words, we simply assign a random POS and very low probability, which does not substantially affect transition probability estimates. In Step 6 we build a tagger by feeding the estimated emission and transition probabilities into the TNT tagger (Brants, 2000), an implementation of a trigram HMM tagger. 4.2 Self training and revision For self training and revision, we use the seed model, along with the large number of target language sentences available that have been partially tagged through direct projection, in order to build a more accurate tagger. Algorithm 2 describes this process of self training and revision, and assumes that the parallel source–target corpus has been word aligned, with many-to-one alignments removed, and that the sentences are sorted by alignment score. In contrast to Algorithm 1, all sentences are used, not just the 60k sentences with the highest alignment scores. We believe that sentence alignment score might correspond to difficulty to tag. By sorting the sentences by alignment score, sentences which are more difficult to tag are tagged using a more mature model. Following Algorithm 1, we divide sentences into blocks of 60k. In step 3 the tagged block is revised by comparing the tags from the tagger with those obtained through direct projection. Suppose source Algorithm 2 Self training and revision 1:Divide target language sentences into blocks of n sentences. 2: Tag the first block with the seed tagger. 3: Revise the tagged block. 4: Train a new tagger on the tagged block. 5: Add the previous tagger’s lexicon to the new tagger. 6: Use the new tagger to tag the next block. 7: Goto 3 and repeat until all blocks are tagged. language word wis is aligned with target language word wjt with probability p(wjt |wsi), Tis is the tag for wis using the tagger availa|bwle for the source language, and Tjt is the tag for wjt using the tagger learned for the > S, where S is a threshold which we heuristically set to 0.7, we replace Tjt by Tis. Self-training can suffer from over-fitting, in which errors in the original model are repeated and amplified in the new model (McClosky et al., 2006). To avoid this, we remove the tag of any token that the model is uncertain of, i.e., if p(wjt |wsi) < S and Tjt Tis then Tjt = Null. So, on th|ew target side, aligned words have a tag from direct projection or no tag, and unaligned words have a tag assigned by our model. Step 4 estimates the emission and transition target language. If p(wtj|wis) = probabilities as in Algorithm 1. In Step 5, emission probabilities for lexical items in the previous model, but missing from the current model, are added to the current model. Later models therefore take advantage of information from earlier models, and have wider coverage. 5 Experimental Results Using parallel data from Europarl (Koehn, 2005) we apply our method to build taggers for the same eight target languages as Das and Petrov (201 1) Danish, Dutch, German, Greek, Italian, Portuguese, Spanish and Swedish with English as the source language. Our training data (Europarl) is a subset of the training data of Das and Petrov (who also used the ODS United Nations dataset which we were unable to obtain). The evaluation metric and test data are the same as that used by Das and Petrov. Our results are comparable to theirs, although our system is penalized by having less training data. We tag the source language with the Stanford POS tagger (Toutanova et al., 2003). — — 636 DanishDutchGermanGreekItalianPortugueseSpanishSwedishAverage Seed model83.781.183.677.878.684.981.478.981.3 Self training + revision 85.6 84.0 85.4 80.4 81.4 86.3 83.3 81.0 83.4 Das and Petrov (2011) 83.2 79.5 82.8 82.5 86.8 87.9 84.2 80.5 83.4 Table 2: Token-level POS tagging accuracy for our seed model, self training and revision, and the method of Das and Petrov (201 1). The best results on each language, and on average, are shown in bold. 1 1 Iteration 2 2 3 1 1 2 2 3 Iteration Figure 1: Overall accuracy, accuracy on known tokens, accuracy on unknown tokens, and proportion of known tokens for Italian (left) and Dutch (right). Table 2 shows results for our seed model, self training and revision, and the results reported by Das and Petrov. Self training and revision improve the accuracy for every language over the seed model, and gives an average improvement of roughly two percentage points. The average accuracy of self training and revision is on par with that reported by Das and Petrov. On individual languages, self training and revision and the method of Das and Petrov are split each performs better on half of the cases. Interestingly, our method achieves higher accuracies on Germanic languages the family of our source language, English while Das and Petrov perform better on Romance languages. This might be because our model relies on alignments, which might be more accurate for more-related languages, whereas Das and Petrov additionally rely on label propagation. Compared to Das and Petrov, our model performs poorest on Italian, in terms of percentage point difference in accuracy. Figure 1 (left panel) shows accuracy, accuracy on known words, accuracy on unknown words, and proportion of known tokens for each iteration of our model for Italian; iteration 0 is the seed model, and iteration 3 1 is the final model. Our model performs poorly on unknown words as indicated by the low accuracy on unknown words, and high accuracy on known — — — words compared to the overall accuracy. The poor performance on unknown words is expected because we do not use any language-specific rules to handle this case. Moreover, on average for the final model, approximately 10% of the test data tokens are unknown. One way to improve the performance of our tagger might be to reduce the proportion of unknown words by using a larger training corpus, as Das and Petrov did. We examine the impact of self-training and revision over training iterations. We find that for all languages, accuracy rises quickly in the first 5–6 iterations, and then subsequently improves only slightly. We exemplify this in Figure 1 (right panel) for Dutch. (Findings are similar for other languages.) Although accuracy does not increase much in later iterations, they may still have some benefit as the vocabulary size continues to grow. 6 Conclusion We have proposed a method for unsupervised POS tagging that performs on par with the current state- of-the-art (Das and Petrov, 2011), but is substantially less-sophisticated (specifically not requiring convex optimization or a feature-based HMM). The complexity of our algorithm is O(nlogn) compared to O(n2) for that of Das and Petrov 637 (201 1) where n is the size of training data.3 We made our code are available for download.4 In future work we intend to consider using a larger training corpus to reduce the proportion of unknown tokens and improve accuracy. Given the improvements of our model over that of Das and Petrov on languages from the same family as our source language, and the observation of Snyder et al. (2008) that a better tagger can be learned from a more-closely related language, we also plan to consider strategies for selecting an appropriate source language for a given target language. Using our final model with unsupervised HMM methods might improve the final performance too, i.e. use our final model as the initial state for HMM, then experiment with differ- ent inference algorithms such as Expectation Maximization (EM), Variational Bayers (VB) or Gibbs sampling (GS).5 Gao and Johnson (2008) compare EM, VB and GS for unsupervised English POS tagging. In many cases, GS outperformed other methods, thus we would like to try GS first for our model. 7 Acknowledgements This work is funded by Erasmus Mundus European Masters Program in Language and Communication Technologies (EM-LCT) and by the Czech Science Foundation (grant no. P103/12/G084). We would like to thank Prokopis Prokopidis for providing us the Greek Treebank and Antonia Marti for the Spanish CoNLL 06 dataset. Finally, we thank Siva Reddy and Spandana Gella for many discussions and suggestions. References Thorsten Brants. 2000. TnT: A statistical part-ofspeech tagger. In Proceedings of the sixth conference on Applied natural language processing (ANLP ’00), pages 224–231 . Seattle, Washington, USA. Dipanjan Das and Slav Petrov. 2011. Unsupervised part-of-speech tagging with bilingual graph-based projections. In Proceedings of 3We re-implemented label propagation from Das and Petrov (2011). It took over a day to complete this step on an eight core Intel Xeon 3.16GHz CPU with 32 Gb Ram, but only 15 minutes for our model. 4https://code.google.com/p/universal-tagger/ 5We in fact have tried EM, but it did not help. The overall performance dropped slightly. This might be because selftraining with revision already found the local maximal point. the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1 (ACL 2011), pages 600–609. Portland, Oregon, USA. Pascal Denis and Beno ıˆt Sagot. 2009. Coupling an annotated corpus and a morphosyntactic lexicon for state-of-the-art POS tagging with less human effort. In Proceedings of the 23rd PacificAsia Conference on Language, Information and Computation, pages 721–736. Hong Kong, China. Anna Feldman, Jirka Hana, and Chris Brew. 2006. A cross-language approach to rapid creation of new morpho-syntactically annotated resources. In Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’06), pages 549–554. Genoa, Italy. Jianfeng Gao and Mark Johnson. 2008. A comparison of bayesian estimators for unsupervised hidden markov model pos taggers. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08, pages 344–352. Association for Computational Linguistics, Stroudsburg, PA, USA. Jiri Hana, Anna Feldman, and Chris Brew. 2004. A resource-light approach to Russian morphology: Tagging Russian using Czech resources. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP ’04), pages 222–229. Barcelona, Spain. Philipp Koehn. 2005. Europarl: A Parallel Corpus for Statistical Machine Translation. In Proceedings of the Tenth Machine Translation Summit (MT Summit X), pages 79–86. AAMT, Phuket, Thailand. David McClosky, Eugene Charniak, and Mark Johnson. 2006. Effective self-training for parsing. In Proceedings of the main conference on Human Language Technology Conference ofthe North American Chapter of the Association of Computational Linguistics (HLT-NAACL ’06), pages 152–159. New York, USA. Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012. A universal part-of-speech tagset. In Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12), pages 2089–2096. Istanbul, Turkey. Siva Reddy and Serge Sharoff. 2011. Cross language POS Taggers (and other tools) for Indian 638 languages: An experiment with Kannada using Telugu resources. In Proceedings of the IJCNLP 2011 workshop on Cross Lingual Information Access: Computational Linguistics and the Information Need of Multilingual Societies (CLIA 2011). Chiang Mai, Thailand. Benjamin Snyder, Tahira Naseem, Jacob Eisenstein, and Regina Barzilay. 2008. Unsupervised multilingual learning for POS tagging. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP ’08), pages 1041–1050. Honolulu, Hawaii. Kristina Toutanova, Dan Klein, Christopher D. Manning, and Yoram Singer. 2003. Featurerich part-of-speech tagging with a cyclic dependency network. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology - Vol- ume 1 (NAACL ’03), pages 173–180. Edmonton, Canada. David Yarowsky and Grace Ngai. 2001 . Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora. In Proceedings of the Second Meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies (NAACL ’01), pages 1–8. Pittsburgh, Pennsylvania, USA. 639</p><p>4 0.083279714 <a title="145-tfidf-4" href="./acl-2013-Non-Monotonic_Sentence_Alignment_via_Semisupervised_Learning.html">259 acl-2013-Non-Monotonic Sentence Alignment via Semisupervised Learning</a></p>
<p>Author: Xiaojun Quan ; Chunyu Kit ; Yan Song</p><p>Abstract: This paper studies the problem of nonmonotonic sentence alignment, motivated by the observation that coupled sentences in real bitexts do not necessarily occur monotonically, and proposes a semisupervised learning approach based on two assumptions: (1) sentences with high affinity in one language tend to have their counterparts with similar relatedness in the other; and (2) initial alignment is readily available with existing alignment techniques. They are incorporated as two constraints into a semisupervised learning framework for optimization to produce a globally optimal solution. The evaluation with realworld legal data from a comprehensive legislation corpus shows that while exist- ing alignment algorithms suffer severely from non-monotonicity, this approach can work effectively on both monotonic and non-monotonic data.</p><p>5 0.079240814 <a title="145-tfidf-5" href="./acl-2013-Recognizing_Partial_Textual_Entailment.html">297 acl-2013-Recognizing Partial Textual Entailment</a></p>
<p>Author: Omer Levy ; Torsten Zesch ; Ido Dagan ; Iryna Gurevych</p><p>Abstract: Textual entailment is an asymmetric relation between two text fragments that describes whether one fragment can be inferred from the other. It thus cannot capture the notion that the target fragment is “almost entailed” by the given text. The recently suggested idea of partial textual entailment may remedy this problem. We investigate partial entailment under the faceted entailment model and the possibility of adapting existing textual entailment methods to this setting. Indeed, our results show that these methods are useful for rec- ognizing partial entailment. We also provide a preliminary assessment of how partial entailment may be used for recognizing (complete) textual entailment.</p><p>6 0.074518315 <a title="145-tfidf-6" href="./acl-2013-Cut_the_noise%3A_Mutually_reinforcing_reordering_and_alignments_for_improved_machine_translation.html">101 acl-2013-Cut the noise: Mutually reinforcing reordering and alignments for improved machine translation</a></p>
<p>7 0.072129384 <a title="145-tfidf-7" href="./acl-2013-Modeling_Human_Inference_Process_for_Textual_Entailment_Recognition.html">245 acl-2013-Modeling Human Inference Process for Textual Entailment Recognition</a></p>
<p>8 0.071640402 <a title="145-tfidf-8" href="./acl-2013-Microblogs_as_Parallel_Corpora.html">240 acl-2013-Microblogs as Parallel Corpora</a></p>
<p>9 0.071343377 <a title="145-tfidf-9" href="./acl-2013-Dirt_Cheap_Web-Scale_Parallel_Text_from_the_Common_Crawl.html">120 acl-2013-Dirt Cheap Web-Scale Parallel Text from the Common Crawl</a></p>
<p>10 0.069743104 <a title="145-tfidf-10" href="./acl-2013-Exact_Maximum_Inference_for_the_Fertility_Hidden_Markov_Model.html">143 acl-2013-Exact Maximum Inference for the Fertility Hidden Markov Model</a></p>
<p>11 0.069201164 <a title="145-tfidf-11" href="./acl-2013-Joint_Word_Alignment_and_Bilingual_Named_Entity_Recognition_Using_Dual_Decomposition.html">210 acl-2013-Joint Word Alignment and Bilingual Named Entity Recognition Using Dual Decomposition</a></p>
<p>12 0.067700572 <a title="145-tfidf-12" href="./acl-2013-Word_Alignment_Modeling_with_Context_Dependent_Deep_Neural_Network.html">388 acl-2013-Word Alignment Modeling with Context Dependent Deep Neural Network</a></p>
<p>13 0.064964078 <a title="145-tfidf-13" href="./acl-2013-Training_Nondeficient_Variants_of_IBM-3_and_IBM-4_for_Word_Alignment.html">354 acl-2013-Training Nondeficient Variants of IBM-3 and IBM-4 for Word Alignment</a></p>
<p>14 0.063140213 <a title="145-tfidf-14" href="./acl-2013-Question_Answering_Using_Enhanced_Lexical_Semantic_Models.html">291 acl-2013-Question Answering Using Enhanced Lexical Semantic Models</a></p>
<p>15 0.062454786 <a title="145-tfidf-15" href="./acl-2013-Part-of-Speech_Induction_in_Dependency_Trees_for_Statistical_Machine_Translation.html">276 acl-2013-Part-of-Speech Induction in Dependency Trees for Statistical Machine Translation</a></p>
<p>16 0.062308237 <a title="145-tfidf-16" href="./acl-2013-A_Novel_Graph-based_Compact_Representation_of_Word_Alignment.html">15 acl-2013-A Novel Graph-based Compact Representation of Word Alignment</a></p>
<p>17 0.061527342 <a title="145-tfidf-17" href="./acl-2013-Cross-lingual_Transfer_of_Semantic_Role_Labeling_Models.html">98 acl-2013-Cross-lingual Transfer of Semantic Role Labeling Models</a></p>
<p>18 0.060676534 <a title="145-tfidf-18" href="./acl-2013-A_Multi-Domain_Translation_Model_Framework_for_Statistical_Machine_Translation.html">11 acl-2013-A Multi-Domain Translation Model Framework for Statistical Machine Translation</a></p>
<p>19 0.059564371 <a title="145-tfidf-19" href="./acl-2013-Learning_a_Phrase-based_Translation_Model_from_Monolingual_Data_with_Application_to_Domain_Adaptation.html">223 acl-2013-Learning a Phrase-based Translation Model from Monolingual Data with Application to Domain Adaptation</a></p>
<p>20 0.058171786 <a title="145-tfidf-20" href="./acl-2013-Cross-lingual_Projections_between_Languages_from_Different_Families.html">97 acl-2013-Cross-lingual Projections between Languages from Different Families</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.158), (1, -0.048), (2, 0.057), (3, 0.004), (4, -0.005), (5, -0.014), (6, -0.05), (7, -0.011), (8, 0.004), (9, -0.03), (10, 0.015), (11, -0.068), (12, -0.022), (13, 0.014), (14, -0.019), (15, -0.012), (16, 0.056), (17, -0.015), (18, 0.049), (19, -0.075), (20, -0.007), (21, 0.006), (22, -0.031), (23, -0.013), (24, -0.042), (25, 0.077), (26, -0.102), (27, 0.002), (28, 0.026), (29, -0.085), (30, -0.055), (31, 0.128), (32, 0.037), (33, -0.001), (34, -0.058), (35, -0.038), (36, 0.049), (37, 0.034), (38, -0.006), (39, -0.001), (40, -0.019), (41, 0.002), (42, -0.004), (43, 0.035), (44, 0.05), (45, 0.084), (46, 0.022), (47, -0.034), (48, 0.076), (49, 0.034)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.89151555 <a title="145-lsi-1" href="./acl-2013-Exploiting_Qualitative_Information_from_Automatic_Word_Alignment_for_Cross-lingual_NLP_Tasks.html">145 acl-2013-Exploiting Qualitative Information from Automatic Word Alignment for Cross-lingual NLP Tasks</a></p>
<p>Author: Jose G.C. de Souza ; Miquel Espla-Gomis ; Marco Turchi ; Matteo Negri</p><p>Abstract: The use of automatic word alignment to capture sentence-level semantic relations is common to a number of cross-lingual NLP applications. Despite its proved usefulness, however, word alignment information is typically considered from a quantitative point of view (e.g. the number of alignments), disregarding qualitative aspects (the importance of aligned terms). In this paper we demonstrate that integrating qualitative information can bring significant performance improvements with negligible impact on system complexity. Focusing on the cross-lingual textual en- tailment task, we contribute with a novel method that: i) significantly outperforms the state of the art, and ii) is portable, with limited loss in performance, to language pairs where training data are not available.</p><p>2 0.79558188 <a title="145-lsi-2" href="./acl-2013-A_Lightweight_and_High_Performance_Monolingual_Word_Aligner.html">9 acl-2013-A Lightweight and High Performance Monolingual Word Aligner</a></p>
<p>Author: Xuchen Yao ; Benjamin Van Durme ; Chris Callison-Burch ; Peter Clark</p><p>Abstract: Fast alignment is essential for many natural language tasks. But in the setting of monolingual alignment, previous work has not been able to align more than one sentence pair per second. We describe a discriminatively trained monolingual word aligner that uses a Conditional Random Field to globally decode the best alignment with features drawn from source and target sentences. Using just part-of-speech tags and WordNet as external resources, our aligner gives state-of-the-art result, while being an order-of-magnitude faster than the previous best performing system.</p><p>3 0.68521363 <a title="145-lsi-3" href="./acl-2013-Non-Monotonic_Sentence_Alignment_via_Semisupervised_Learning.html">259 acl-2013-Non-Monotonic Sentence Alignment via Semisupervised Learning</a></p>
<p>Author: Xiaojun Quan ; Chunyu Kit ; Yan Song</p><p>Abstract: This paper studies the problem of nonmonotonic sentence alignment, motivated by the observation that coupled sentences in real bitexts do not necessarily occur monotonically, and proposes a semisupervised learning approach based on two assumptions: (1) sentences with high affinity in one language tend to have their counterparts with similar relatedness in the other; and (2) initial alignment is readily available with existing alignment techniques. They are incorporated as two constraints into a semisupervised learning framework for optimization to produce a globally optimal solution. The evaluation with realworld legal data from a comprehensive legislation corpus shows that while exist- ing alignment algorithms suffer severely from non-monotonicity, this approach can work effectively on both monotonic and non-monotonic data.</p><p>4 0.65689474 <a title="145-lsi-4" href="./acl-2013-Building_Japanese_Textual_Entailment_Specialized_Data_Sets_for_Inference_of_Basic_Sentence_Relations.html">75 acl-2013-Building Japanese Textual Entailment Specialized Data Sets for Inference of Basic Sentence Relations</a></p>
<p>Author: Kimi Kaneko ; Yusuke Miyao ; Daisuke Bekki</p><p>Abstract: This paper proposes a methodology for generating specialized Japanese data sets for textual entailment, which consists of pairs decomposed into basic sentence relations. We experimented with our methodology over a number of pairs taken from the RITE-2 data set. We compared our methodology with existing studies in terms of agreement, frequencies and times, and we evaluated its validity by investigating recognition accuracy.</p><p>5 0.62649292 <a title="145-lsi-5" href="./acl-2013-Training_Nondeficient_Variants_of_IBM-3_and_IBM-4_for_Word_Alignment.html">354 acl-2013-Training Nondeficient Variants of IBM-3 and IBM-4 for Word Alignment</a></p>
<p>Author: Thomas Schoenemann</p><p>Abstract: We derive variants of the fertility based models IBM-3 and IBM-4 that, while maintaining their zero and first order parameters, are nondeficient. Subsequently, we proceed to derive a method to compute a likely alignment and its neighbors as well as give a solution of EM training. The arising M-step energies are non-trivial and handled via projected gradient ascent. Our evaluation on gold alignments shows substantial improvements (in weighted Fmeasure) for the IBM-3. For the IBM4 there are no consistent improvements. Training the nondeficient IBM-5 in the regular way gives surprisingly good results. Using the resulting alignments for phrase- based translation systems offers no clear insights w.r.t. BLEU scores.</p><p>6 0.62282181 <a title="145-lsi-6" href="./acl-2013-Recognizing_Partial_Textual_Entailment.html">297 acl-2013-Recognizing Partial Textual Entailment</a></p>
<p>7 0.61336333 <a title="145-lsi-7" href="./acl-2013-Simpler_unsupervised_POS_tagging_with_bilingual_projections.html">323 acl-2013-Simpler unsupervised POS tagging with bilingual projections</a></p>
<p>8 0.59944427 <a title="145-lsi-8" href="./acl-2013-Modeling_Human_Inference_Process_for_Textual_Entailment_Recognition.html">245 acl-2013-Modeling Human Inference Process for Textual Entailment Recognition</a></p>
<p>9 0.58435935 <a title="145-lsi-9" href="./acl-2013-A_Novel_Graph-based_Compact_Representation_of_Word_Alignment.html">15 acl-2013-A Novel Graph-based Compact Representation of Word Alignment</a></p>
<p>10 0.56287014 <a title="145-lsi-10" href="./acl-2013-Joint_Word_Alignment_and_Bilingual_Named_Entity_Recognition_Using_Dual_Decomposition.html">210 acl-2013-Joint Word Alignment and Bilingual Named Entity Recognition Using Dual Decomposition</a></p>
<p>11 0.53096789 <a title="145-lsi-11" href="./acl-2013-Is_a_204_cm_Man_Tall_or_Small_%3F_Acquisition_of_Numerical_Common_Sense_from_the_Web.html">202 acl-2013-Is a 204 cm Man Tall or Small ? Acquisition of Numerical Common Sense from the Web</a></p>
<p>12 0.52796745 <a title="145-lsi-12" href="./acl-2013-Dirt_Cheap_Web-Scale_Parallel_Text_from_the_Common_Crawl.html">120 acl-2013-Dirt Cheap Web-Scale Parallel Text from the Common Crawl</a></p>
<p>13 0.52789903 <a title="145-lsi-13" href="./acl-2013-Exact_Maximum_Inference_for_the_Fertility_Hidden_Markov_Model.html">143 acl-2013-Exact Maximum Inference for the Fertility Hidden Markov Model</a></p>
<p>14 0.52533513 <a title="145-lsi-14" href="./acl-2013-A_Tightly-coupled_Unsupervised_Clustering_and_Bilingual_Alignment_Model_for_Transliteration.html">25 acl-2013-A Tightly-coupled Unsupervised Clustering and Bilingual Alignment Model for Transliteration</a></p>
<p>15 0.52245331 <a title="145-lsi-15" href="./acl-2013-Microblogs_as_Parallel_Corpora.html">240 acl-2013-Microblogs as Parallel Corpora</a></p>
<p>16 0.5217858 <a title="145-lsi-16" href="./acl-2013-An_Information_Theoretic_Approach_to_Bilingual_Word_Clustering.html">47 acl-2013-An Information Theoretic Approach to Bilingual Word Clustering</a></p>
<p>17 0.50606441 <a title="145-lsi-17" href="./acl-2013-Part-of-Speech_Induction_in_Dependency_Trees_for_Statistical_Machine_Translation.html">276 acl-2013-Part-of-Speech Induction in Dependency Trees for Statistical Machine Translation</a></p>
<p>18 0.48971409 <a title="145-lsi-18" href="./acl-2013-Cut_the_noise%3A_Mutually_reinforcing_reordering_and_alignments_for_improved_machine_translation.html">101 acl-2013-Cut the noise: Mutually reinforcing reordering and alignments for improved machine translation</a></p>
<p>19 0.48762935 <a title="145-lsi-19" href="./acl-2013-Cross-lingual_Transfer_of_Semantic_Role_Labeling_Models.html">98 acl-2013-Cross-lingual Transfer of Semantic Role Labeling Models</a></p>
<p>20 0.4769755 <a title="145-lsi-20" href="./acl-2013-Extracting_bilingual_terminologies_from_comparable_corpora.html">154 acl-2013-Extracting bilingual terminologies from comparable corpora</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.04), (6, 0.434), (11, 0.057), (24, 0.033), (26, 0.062), (35, 0.051), (42, 0.044), (48, 0.038), (64, 0.013), (70, 0.034), (88, 0.021), (90, 0.036), (95, 0.059)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.91413814 <a title="145-lda-1" href="./acl-2013-Reducing_Annotation_Effort_for_Quality_Estimation_via_Active_Learning.html">300 acl-2013-Reducing Annotation Effort for Quality Estimation via Active Learning</a></p>
<p>Author: Daniel Beck ; Lucia Specia ; Trevor Cohn</p><p>Abstract: Quality estimation models provide feedback on the quality of machine translated texts. They are usually trained on humanannotated datasets, which are very costly due to its task-specific nature. We investigate active learning techniques to reduce the size of these datasets and thus annotation effort. Experiments on a number of datasets show that with as little as 25% of the training instances it is possible to obtain similar or superior performance compared to that of the complete datasets. In other words, our active learning query strategies can not only reduce annotation effort but can also result in better quality predictors. ,t .</p><p>2 0.91332561 <a title="145-lda-2" href="./acl-2013-Exact_Maximum_Inference_for_the_Fertility_Hidden_Markov_Model.html">143 acl-2013-Exact Maximum Inference for the Fertility Hidden Markov Model</a></p>
<p>Author: Chris Quirk</p><p>Abstract: The notion of fertility in word alignment (the number of words emitted by a single state) is useful but difficult to model. Initial attempts at modeling fertility used heuristic search methods. Recent approaches instead use more principled approximate inference techniques such as Gibbs sampling for parameter estimation. Yet in practice we also need the single best alignment, which is difficult to find using Gibbs. Building on recent advances in dual decomposition, this paper introduces an exact algorithm for finding the single best alignment with a fertility HMM. Finding the best alignment appears important, as this model leads to a substantial improvement in alignment quality.</p><p>3 0.89981693 <a title="145-lda-3" href="./acl-2013-Sequential_Summarization%3A_A_New_Application_for_Timely_Updated_Twitter_Trending_Topics.html">319 acl-2013-Sequential Summarization: A New Application for Timely Updated Twitter Trending Topics</a></p>
<p>Author: Dehong Gao ; Wenjie Li ; Renxian Zhang</p><p>Abstract: The growth of the Web 2.0 technologies has led to an explosion of social networking media sites. Among them, Twitter is the most popular service by far due to its ease for realtime sharing of information. It collects millions of tweets per day and monitors what people are talking about in the trending topics updated timely. Then the question is how users can understand a topic in a short time when they are frustrated with the overwhelming and unorganized tweets. In this paper, this problem is approached by sequential summarization which aims to produce a sequential summary, i.e., a series of chronologically ordered short subsummaries that collectively provide a full story about topic development. Both the number and the content of sub-summaries are automatically identified by the proposed stream-based and semantic-based approaches. These approaches are evaluated in terms of sequence coverage, sequence novelty and sequence correlation and the effectiveness of their combination is demonstrated. 1 Introduction and Background Twitter, as a popular micro-blogging service, collects millions of real-time short text messages (known as tweets) every second. It acts as not only a public platform for posting trifles about users’ daily lives, but also a public reporter for real-time news. Twitter has shown its powerful ability in information delivery in many events, like the wildfires in San Diego and the earthquake in Japan. Nevertheless, the side effect is individual users usually sink deep under millions of flooding-in tweets. To alleviate this problem, the applications like whatthetrend 1 have evolved from Twitter to provide services that encourage users to edit explanatory tweets about a trending topic, which can be regarded as topic summaries. It is to some extent a good way to help users understand trending topics. 1 whatthetrend.com There is also pioneering research in automatic Twitter trending topic summarization. (O'Connor et al., 2010) explained Twitter trending topics by providing a list of significant terms. Users could utilize these terms to drill down to the tweets which are related to the trending topics. (Sharifi et al., 2010) attempted to provide a one-line summary for each trending topic using phrase reinforcement ranking. The relevance model employed by (Harabagiu and Hickl, 2011) generated summaries in larger size, i.e., 250word summaries, by synthesizing multiple high rank tweets. (Duan et al., 2012) incorporate the user influence and content quality information in timeline tweet summarization and employ reinforcement graph to generate summaries for trending topics. Twitter summarization is an emerging research area. Current approaches still followed the traditional summarization route and mainly focused on mining tweets of both significance and representativeness. Though, the summaries generated in such a way can sketch the most important aspects of the topic, they are incapable of providing full descriptions of the changes of the focus of a topic, and the temporal information or freshness of the tweets, especially for those newsworthy trending topics, like earthquake and sports meeting. As the main information producer in Twitter, the massive crowd keeps close pace with the development of trending topics and provide the timely updated information. The information dynamics and timeliness is an important consideration for Twitter summarization. That is why we propose sequential summarization in this work, which aims to produce sequential summaries to capture the temporal changes of mass focus. Our work resembles update summarization promoted by TAC 2 which required creating summaries with new information assuming the reader has already read some previous documents under the same topic. Given two chronologically ordered documents sets about a topic, the systems were asked to generate two 2 www.nist.gov/tac 567 summaries, and the second one should inform the user of new information only. In order to achieve this goal, existing approaches mainly emphasized the novelty of the subsequent summary (Li and Croft, 2006; Varma et al., 2009; Steinberger and Jezek, 2009). Different from update summarization, we focus more on the temporal change of trending topics. In particular, we need to automatically detect the “update points” among a myriad of related tweets. It is the goal of this paper to set up a new practical summarization application tailored for timely updated Twitter messages. With the aim of providing a full description of the focus changes and the records of the timeline of a trending topic, the systems are expected to discover the chronologically ordered sets of information by themselves and they are free to generate any number of update summaries according to the actual situations instead of a fixed number of summaries as specified in DUC/TAC. Our main contributions include novel approaches to sequential summarization and corresponding evaluation criteria for this new application. All of them will be detailed in the following sections. 2 Sequential Summarization Sequential summarization proposed here aims to generate a series of chronologically ordered subsummaries for a given Twitter trending topic. Each sub-summary is supposed to represent one main subtopic or one main aspect of the topic, while a sequential summary, made up by the subsummaries, should retain the order the information is delivered to the public. In such a way, the sequential summary is able to provide a general picture of the entire topic development. 2.1 Subtopic Segmentation One of the keys to sequential summarization is subtopic segmentation. How many subtopics have attracted the public attention, what are they, and how are they developed? It is important to provide the valuable and organized materials for more fine-grained summarization approaches. We proposed the following two approaches to automatically detect and chronologically order the subtopics. 2.1.1 Stream-based Subtopic Detection and Ordering Typically when a subtopic is popular enough, it will create a certain level of surge in the tweet stream. In other words, every surge in the tweet stream can be regarded as an indicator of the appearance of a subtopic that is worthy of being summarized. Our early investigation provides evidence to support this assumption. By examining the correlations between tweet content changes and volume changes in randomly selected topics, we have observed that the changes in tweet volume can really provide the clues of topic development or changes of crowd focus. The stream-based subtopic detection approach employs the offline peak area detection (Opad) algorithm (Shamma et al., 2010) to locate such surges by tracing tweet volume changes. It regards the collection of tweets at each such surge time range as a new subtopic. Offline Peak Area Detection (Opad) Algorithm 1: Input: TS (tweets stream, each twi with timestamp ti); peak interval window ∆? (in hour), and time stepℎ (ℎ ≪ ∆?); 2: Output: Peak Areas PA. 3: Initial: two time slots: ?′ = ? = ?0 + ∆?; Tweet numbers: ?′ = ? = ?????(?) 4: while (?? = ? + ℎ) < ??−1 5: update ?′ = ?? + ∆? and ?′ = ?????(?′) 6: if (?′ < ? And up-hilling) 7: output one peak area ??? 8: state of down-hilling 9: else 10: update ? = ?′ and ? = ?′ 11: state of up-hilling 12: 13: function ?????(?) 14: Count tweets in time interval T The subtopics detected by the Opad algorithm are naturally ordered in the timeline. 2.1.2 Semantic-based Subtopic Detection and Ordering Basically the stream-based approach monitors the changes of the level of user attention. It is easy to implement and intuitively works, but it fails to handle the cases where the posts about the same subtopic are received at different time ranges due to the difference of geographical and time zones. This may make some subtopics scattered into several time slots (peak areas) or one peak area mixed with more than one subtopic. In order to sequentially segment the subtopics from the semantic aspect, the semantic-based subtopic detection approach breaks the time order of tweet stream, and regards each tweet as an individual short document. It takes advantage of Dynamic Topic Modeling (David and Michael, 2006) to explore the tweet content. 568 DTM in nature is a clustering approach which can dynamically generate the subtopic underlying the topic. Any clustering approach requires a pre-specified cluster number. To avoid tuning the cluster number experimentally, the subtopic number required by the semantic-based approach is either calculated according to heuristics or determined by the number of the peak areas detected from the stream-based approach in this work. Unlike the stream-based approach, the subtopics formed by DTM are the sets of distributions of subtopic and word probabilities. They are time independent. Thus, the temporal order among these subtopics is not obvious and needs to be discovered. We use the probabilistic relationships between tweets and topics learned from DTM to assign each tweet to a subtopic that it most likely belongs to. Then the subtopics are ordered temporally according to the mean values of their tweets’ timestamps. 2.2 Sequential Summary Generation Once the subtopics are detected and ordered, the tweets belonging to each subtopic are ranked and the most significant one is extracted to generate the sub-summary regarding that subtopic. Two different ranking strategies are adopted to conform to two different subtopic detection mechanisms. For a tweet in a peak area, the linear combination of two measures is considered to independently. Each sub-summary is up to 140 characters in length to comply with the limit of tweet, but the annotators are free to choose the number of sub-summaries. It ends up with 6.3 and 4.8 sub-summaries on average in a sequential summary written by the two annotators respectively. These two sets of sequential summaries are regarded as reference summaries to evaluate system-generated summaries from the following three aspects. Sequence Coverage Sequence coverage measures the N-gram match between system-generated summaries and human-written summaries (stopword removed first). Considering temporal information is an important factor in sequential summaries, we evaluate its significance to be a sub-summary: (1) subtopic representativeness measured by the  cosine similarity between the tweet and the centroid of all the tweets in the same peak area; (2) crowding endorsement measured by the times that the tweet is re-tweeted normalized by the total number of re-tweeting. With the DTM model, the significance of the tweets is evaluated directly by word distribution per subtopic. MMR (Carbonell and Goldstein, 1998) is used to reduce redundancy in sub-summary generation. 3 Experiments and Evaluations The experiments are conducted on the 24 Twitter trending topics collected using Twitter APIs 3 . The statistics are shown in Table 1. Due to the shortage of gold-standard sequential summaries, we invite two annotators to read the chronologically ordered tweets, and write a series of sub-summaries for each topic 3https://dev.twitter.com/ propose the position-aware coverage measure by accommodating the position information in matching. Let S={s1, s2, sk} denote a … … …, sequential summary and si the ith sub-summary, N-gram coverage is defined as: ???????? =|? 1?|?∑?∈? ?∑? ? ?∈?∙ℎ ?∑ ? ?∈?-?ℎ? ?∑? ∈-? ?,? ? ? ?∈? ? ? ? ? ? ? (ℎ?(?-?-? ? ? ?) where, ??? = |? − ?| + 1, i and j denote the serial numbers of the sub-summaries in the systemgenerated summary ??? and the human-written summary ?ℎ? , respectively. ? serves as a coefficient to discount long-distance matched sub-summaries. We evaluate unigram, bigram, and skipped bigram matches. Like in ROUGE (Lin, 2004), the skip distance is up to four words.  Sequence Novelty Sequence novelty evaluates the average novelty of two successive sub-summaries. Information content (IC) has been used to measure the novelty of update summaries by (Aggarwal et al., 2009). In this paper, the novelty of a system569 generated sequential summary is defined as the average of IC increments of two adjacent subsummaries, ??????? =|?|1 − 1?∑>1(????− ????, ??−1) × where |?| is the number of sub-summaries in the sequential summary. ???? = ∑?∈?? ??? . ????, ??−1 = ∑?∈??∩??−1 ??? is the overlapped information in the two adjacent sub-summaries. ??? = ???? ?????????(?, ???) where w is a word, ???? is the inverse tweet frequency of w, and ??? is all the tweets in the trending topic. The relevance function is introduced to ensure that the information brought by new sub-summaries is not only novel but also related to the topic.  Sequence Correlation Sequence correlation evaluates the sequential matching degree between system-generated and human-written summaries. In statistics, Kendall’s tau coefficient is often used to measure the association between two sequences (Lapata, 2006). The basic idea is to count the concordant and discordant pairs which contain the same elements in two sequences. Borrowing this idea, for each sub-summary in a human-generated summary, we find its most matched subsummary (judged by the cosine similarity measure) in the corresponding system-generated summary and then define the correlation according to the concordance between the two matched sub-summary sequences. ??????????? 2(|#???????????????| |#???????????????|) − = ?(? − 1) where n is the number of human-written subsummaries. Tables 2 and 3 below present the evaluation results. For the stream-based approach, we set ∆t=3 hours experimentally. For the semanticbased approach, we compare three different approaches to defining the sub-topic number K: (1) Semantic-based 1: Following the approach proposed in (Li et al., 2007), we first derive the matrix of tweet cosine similarity. Given the 1norm of eigenvalues ?????? (? = 1, 2, ,?) of the similarity matrix and the ratios ?? = ??????/?2 , the subtopic number ? = ? + 1 if ?? − ??+1 > ? (? 0.4 ). (2) Semantic-based 2: Using the rule of thumb in (Wan and Yang, 2008), ? = √? , where n is the tweet number. (3) Combined: K is defined as the number of the peak areas detected from the Opad algorithm, meanwhile we use the … = tweets within peak areas as the tweets of DTM. This is our new idea. The experiments confirm the superiority of the semantic-based approach over the stream-based approach in summary content coverage and novelty evaluations, showing that the former is better at subtopic content modeling. The subsummaries generated by the stream-based approach have comparative sequence (i.e., order) correlation with the human summaries. Combining the advantages the two approaches leads to the best overall results. SCebomaSCs beonmtdivr1eac( ∆nrdδ-bm(ta=i∆g0-cs3e.t)5=d32U0 n.3ig510r32a7m B0 .i1g 6r3589a46m87 SB0 k.i1 gp8725r69ame173d Table 2. N-Gram Coverage Evaluation Sem CtraeonTmaA tmicapb-nplibentria ec3os-de.abcd N(a∆hs(o1evt∆=(sdetδ=3l2)t 0y).a4n)dCoN0r .o 73e vl071ea96lti783 oy nEvCalo0ur a. 3 tei3792ol3a489nt650io n 4 Concluding Remarks We start a new application for Twitter trending topics, i.e., sequential summarization, to reveal the developing scenario of the trending topics while retaining the order of information presentation. We develop several solutions to automatically detect, segment and order subtopics temporally, and extract the most significant tweets into the sub-summaries to compose sequential summaries. Empirically, the combination of the stream-based approach and the semantic-based approach leads to sequential summaries with high coverage, low redundancy, and good order. Acknowledgments The work described in this paper is supported by a Hong Kong RGC project (PolyU No. 5202/12E) and a National Nature Science Foundation of China (NSFC No. 61272291). References Aggarwal Gaurav, Sumbaly Roshan and Sinha Shakti. 2009. Update Summarization. Stanford: CS224N Final Projects. 570 Blei M. David and Jordan I. Michael. 2006. Dynamic topic models. In Proceedings of the 23rd international conference on Machine learning, 113120. Pittsburgh, Pennsylvania. Carbonell Jaime and Goldstein Jade. 1998. The use of MMR, diversity based reranking for reordering documents and producing summaries. In Proceedings of the 21st Annual International Conference on Research and Development in Information Retrieval, 335-336. Melbourne, Australia. Duan Yajuan, Chen Zhimin, Wei Furu, Zhou Ming and Heung-Yeung Shum. 2012. Twitter Topic Summarization by Ranking Tweets using Social Influence and Content Quality. In Proceedings of the 24th International Conference on Computational Linguistics, 763-780. Mumbai, India. Harabagiu Sanda and Hickl Andrew. 2011. Relevance Modeling for Microblog Summarization. In Proceedings of 5th International AAAI Conference on Weblogs and Social Media. Barcelona, Spain. Lapata Mirella. 2006. Automatic evaluation of information ordering: Kendall’s tau. Computational Linguistics, 32(4): 1-14. Li Wenyuan, Ng Wee-Keong, Liu Ying and Ong Kok-Leong. 2007. Enhancing the Effectiveness of Clustering with Spectra Analysis. IEEE Transactions on Knowledge and Data Engineering, 19(7):887-902. Li Xiaoyan and Croft W. Bruce. 2006. Improving novelty detection for general topics using sentence level information patterns. In Proceedings of the 15th ACM International Conference on Information and Knowledge Management, 238-247. New York, USA. Lin Chin-Yew. 2004. ROUGE: a Package for Automatic Evaluation of Summaries. In Proceedings of the ACL Workshop on Text Summarization Branches Out, 74-81 . Barcelona, Spain. Liu Fei, Liu Yang and Weng Fuliang. 2011. Why is “SXSW ” trending? Exploring Multiple Text Sources for Twitter Topic Summarization. In Proceedings of the ACL Workshop on Language in Social Media, 66-75. Portland, Oregon. O'Connor Brendan, Krieger Michel and Ahn David. 2010. TweetMotif: Exploratory Search and Topic Summarization for Twitter. In Proceedings of the 4th International AAAI Conference on Weblogs and Social Media, 384-385. Atlanta, Georgia. Shamma A. David, Kennedy Lyndon and Churchill F. Elizabeth. 2010. Tweetgeist: Can the Twitter Timeline Reveal the Structure of Broadcast Events? In Proceedings of the 2010 ACM Conference on Computer Supported Cooperative Work, 589-593. Savannah, Georgia, USA. Sharifi Beaux, Hutton Mark-Anthony and Kalita Jugal. 2010. Summarizing Microblogs Automatically. In Human Language Technologies: the 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, 685688. Los Angeles, California. Steinberger Josef and Jezek Karel. 2009. Update summarization based on novel topic distribution. In Proceedings of the 9th ACM Symposium on Document Engineering, 205-213. Munich, Germany. Varma Vasudeva, Bharat Vijay, Kovelamudi Sudheer, Praveen Bysani, Kumar K. N, Kranthi Reddy, Karuna Kumar and Nitin Maganti. 2009. IIIT Hyderabad at TAC 2009. In Proceedings of the 2009 Text Analysis Conference. GaithsBurg, Maryland. Wan Xiaojun and Yang Jianjun. 2008. Multidocument summarization using cluster-based link analysis. In Proceedings of the 3 1st Annual International Conference on Research and Development in Information Retrieval, 299-306. Singapore, Singapore. 571</p><p>same-paper 4 0.89469165 <a title="145-lda-4" href="./acl-2013-Exploiting_Qualitative_Information_from_Automatic_Word_Alignment_for_Cross-lingual_NLP_Tasks.html">145 acl-2013-Exploiting Qualitative Information from Automatic Word Alignment for Cross-lingual NLP Tasks</a></p>
<p>Author: Jose G.C. de Souza ; Miquel Espla-Gomis ; Marco Turchi ; Matteo Negri</p><p>Abstract: The use of automatic word alignment to capture sentence-level semantic relations is common to a number of cross-lingual NLP applications. Despite its proved usefulness, however, word alignment information is typically considered from a quantitative point of view (e.g. the number of alignments), disregarding qualitative aspects (the importance of aligned terms). In this paper we demonstrate that integrating qualitative information can bring significant performance improvements with negligible impact on system complexity. Focusing on the cross-lingual textual en- tailment task, we contribute with a novel method that: i) significantly outperforms the state of the art, and ii) is portable, with limited loss in performance, to language pairs where training data are not available.</p><p>5 0.84295374 <a title="145-lda-5" href="./acl-2013-Modeling_Thesis_Clarity_in_Student_Essays.html">246 acl-2013-Modeling Thesis Clarity in Student Essays</a></p>
<p>Author: Isaac Persing ; Vincent Ng</p><p>Abstract: Recently, researchers have begun exploring methods of scoring student essays with respect to particular dimensions of quality such as coherence, technical errors, and relevance to prompt, but there is relatively little work on modeling thesis clarity. We present a new annotated corpus and propose a learning-based approach to scoring essays along the thesis clarity dimension. Additionally, in order to provide more valuable feedback on why an essay is scored as it is, we propose a second learning-based approach to identifying what kinds of errors an essay has that may lower its thesis clarity score.</p><p>6 0.82473749 <a title="145-lda-6" href="./acl-2013-Joint_Word_Alignment_and_Bilingual_Named_Entity_Recognition_Using_Dual_Decomposition.html">210 acl-2013-Joint Word Alignment and Bilingual Named Entity Recognition Using Dual Decomposition</a></p>
<p>7 0.81154585 <a title="145-lda-7" href="./acl-2013-Adapting_Discriminative_Reranking_to_Grounded_Language_Learning.html">36 acl-2013-Adapting Discriminative Reranking to Grounded Language Learning</a></p>
<p>8 0.58948195 <a title="145-lda-8" href="./acl-2013-Annotating_named_entities_in_clinical_text_by_combining_pre-annotation_and_active_learning.html">52 acl-2013-Annotating named entities in clinical text by combining pre-annotation and active learning</a></p>
<p>9 0.5808171 <a title="145-lda-9" href="./acl-2013-Non-Monotonic_Sentence_Alignment_via_Semisupervised_Learning.html">259 acl-2013-Non-Monotonic Sentence Alignment via Semisupervised Learning</a></p>
<p>10 0.5784514 <a title="145-lda-10" href="./acl-2013-Using_Supervised_Bigram-based_ILP_for_Extractive_Summarization.html">377 acl-2013-Using Supervised Bigram-based ILP for Extractive Summarization</a></p>
<p>11 0.56945843 <a title="145-lda-11" href="./acl-2013-Summarization_Through_Submodularity_and_Dispersion.html">333 acl-2013-Summarization Through Submodularity and Dispersion</a></p>
<p>12 0.56426883 <a title="145-lda-12" href="./acl-2013-Towards_Robust_Abstractive_Multi-Document_Summarization%3A_A_Caseframe_Analysis_of_Centrality_and_Domain.html">353 acl-2013-Towards Robust Abstractive Multi-Document Summarization: A Caseframe Analysis of Centrality and Domain</a></p>
<p>13 0.56350404 <a title="145-lda-13" href="./acl-2013-Iterative_Transformation_of_Annotation_Guidelines_for_Constituency_Parsing.html">204 acl-2013-Iterative Transformation of Annotation Guidelines for Constituency Parsing</a></p>
<p>14 0.5579797 <a title="145-lda-14" href="./acl-2013-Fast_and_Robust_Compressive_Summarization_with_Dual_Decomposition_and_Multi-Task_Learning.html">157 acl-2013-Fast and Robust Compressive Summarization with Dual Decomposition and Multi-Task Learning</a></p>
<p>15 0.55153441 <a title="145-lda-15" href="./acl-2013-Cut_the_noise%3A_Mutually_reinforcing_reordering_and_alignments_for_improved_machine_translation.html">101 acl-2013-Cut the noise: Mutually reinforcing reordering and alignments for improved machine translation</a></p>
<p>16 0.54627794 <a title="145-lda-16" href="./acl-2013-Collective_Annotation_of_Linguistic_Resources%3A_Basic_Principles_and_a_Formal_Model.html">83 acl-2013-Collective Annotation of Linguistic Resources: Basic Principles and a Formal Model</a></p>
<p>17 0.54338181 <a title="145-lda-17" href="./acl-2013-Automated_Pyramid_Scoring_of_Summaries_using_Distributional_Semantics.html">59 acl-2013-Automated Pyramid Scoring of Summaries using Distributional Semantics</a></p>
<p>18 0.54024208 <a title="145-lda-18" href="./acl-2013-Grounded_Unsupervised_Semantic_Parsing.html">176 acl-2013-Grounded Unsupervised Semantic Parsing</a></p>
<p>19 0.53749621 <a title="145-lda-19" href="./acl-2013-Modelling_Annotator_Bias_with_Multi-task_Gaussian_Processes%3A_An_Application_to_Machine_Translation_Quality_Estimation.html">248 acl-2013-Modelling Annotator Bias with Multi-task Gaussian Processes: An Application to Machine Translation Quality Estimation</a></p>
<p>20 0.52037799 <a title="145-lda-20" href="./acl-2013-Domain-Independent_Abstract_Generation_for_Focused_Meeting_Summarization.html">129 acl-2013-Domain-Independent Abstract Generation for Focused Meeting Summarization</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
