<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>231 acl-2013-Linggle: a Web-scale Linguistic Search Engine for Words in Context</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-231" href="#">acl2013-231</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>231 acl-2013-Linggle: a Web-scale Linguistic Search Engine for Words in Context</h1>
<br/><p>Source: <a title="acl-2013-231-pdf" href="http://aclweb.org/anthology//P/P13/P13-4024.pdf">pdf</a></p><p>Author: Joanne Boisson ; Ting-Hui Kao ; Jian-Cheng Wu ; Tzu-Hsi Yen ; Jason S. Chang</p><p>Abstract: In this paper, we introduce a Web-scale linguistics search engine, Linggle, that retrieves lexical bundles in response to a given query. The query might contain keywords, wildcards, wild parts of speech (PoS), synonyms, and additional regular expression (RE) operators. In our approach, we incorporate inverted file indexing, PoS information from BNC, and semantic indexing based on Latent Dirichlet Allocation with Google Web 1T. The method involves parsing the query to transforming it into several keyword retrieval commands. Word chunks are retrieved with counts, further filtering the chunks with the query as a RE, and finally displaying the results according to the counts, similarities, and topics. Clusters of synonyms or conceptually related words are also provided. In addition, Linggle provides example sentences from The New York Times on demand. The current implementation of Linggle is the most functionally comprehensive, and is in principle language and dataset independent. We plan to extend Linggle to provide fast and convenient access to a wealth of linguistic information embodied in Web scale datasets including Google Web 1T and Google Books Ngram for many major languages in the world. 1</p><p>Reference: <a title="acl-2013-231-reference" href="../acl2013_reference/acl-2013-Linggle%3A_a_Web-scale_Linguistic_Search_Engine_for_Words_in_Context_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 com  ,  ,  ,  ,  Abstract In this paper, we introduce a Web-scale linguistics search engine, Linggle, that retrieves lexical bundles in response to a given query. [sent-9, score-0.105]
</p><p>2 The query might contain keywords, wildcards, wild parts of speech (PoS), synonyms, and additional regular expression (RE) operators. [sent-10, score-0.224]
</p><p>3 In our approach, we incorporate inverted file indexing, PoS information from BNC, and semantic indexing based on Latent Dirichlet Allocation with Google Web 1T. [sent-11, score-0.07]
</p><p>4 The method involves parsing the query to transforming it into several keyword retrieval commands. [sent-12, score-0.186]
</p><p>5 Word chunks are retrieved with counts, further filtering the chunks with the query as a RE, and finally displaying the results according to the counts, similarities, and topics. [sent-13, score-0.233]
</p><p>6 Clusters of synonyms or conceptually related words are also provided. [sent-14, score-0.133]
</p><p>7 We plan to extend Linggle to provide fast and convenient access to a wealth of linguistic information embodied in Web scale datasets including Google Web 1T and Google Books Ngram for many major languages in the world. [sent-17, score-0.097]
</p><p>8 Doubts concerning the usage of a preposition, the mandatory presence of a determiner, the correctness of the association of a verb with an object, or the need for synonyms of a term in a given context are issues that arise frequently. [sent-19, score-0.25]
</p><p>9 Printed collocation dictionaries and reference tools based on compiled corpora offer limited coverage of word usage while knowledge of collocations is vital to acquire a good level of linguistic competency. [sent-20, score-0.189]
</p><p>10 We propose to address these limitations with a comprehensive system aimed at helping the learners “know a word by the company it keeps” (Firth, 1957). [sent-21, score-0.084]
</p><p>11 The system based on Web-scaled datasets is designed to be a broad coverage language reference tool for English Second Language learners (ESL). [sent-24, score-0.075]
</p><p>12 It is conceived to search information related to word usage in context under various conditions. [sent-25, score-0.128]
</p><p>13 First, we build an inverted file index for the Google Web 1T n-grams to support queries with RE-like patterns including PoS and synonym matches. [sent-26, score-0.223]
</p><p>14 For example, for the query “$V $D +important role”, Linggle retrieves 4-grams that start with a verb and a determiner followed by a synonym of important and the keyword role (e. [sent-27, score-0.359]
</p><p>15 ” would retrieve two word chunks such as “sandy beach 413,300” and “rocky beach 16,800”. [sent-32, score-0.516]
</p><p>16 The n-gram search implementation is achieved through filtering, re-indexing, populating an HBase database with the Web 1T n-grams and augmenting them with the most frequent PoS for words (without disambiguation) derived from the British National Corpus (BNC). [sent-33, score-0.109]
</p><p>17 The n-grams returned for a query can then be linked to examples extracted from the New York Times Corpus (Sandhaus, 2008) in order to provide full sentential context for more effective learning. [sent-34, score-0.145]
</p><p>18 In some situations, the user might need to search for words in a specific syntactic relation (e. [sent-35, score-0.071]
</p><p>19 The query absorb $N in n-grams display mode returns all the nouns that follow the verb ordered by decreasing ngram counts. [sent-38, score-0.452]
</p><p>20 Some of these nouns might not be objects of the verb absorb. [sent-39, score-0.179]
</p><p>21 c A2s0s1o3ci Aatsiosonc fioartio Cno fmorpu Ctoamtiopnuatalt Lioin gauli Lsitnicgsu,i psatgices 139–14 , query in cluster display mode will control that two words have been labeled verb-object by a parser. [sent-42, score-0.291]
</p><p>22 For example the verb absorb takes clusters of objects related to the topics liquid, energy, money, knowledge, and population. [sent-44, score-0.401]
</p><p>23 ” This tendency of predicates to prefer certain classes of arguments is defined by Wilks (1978) as selectional preferences and widely reported in the literature. [sent-46, score-0.286]
</p><p>24 Erk and Padó (2010) extend experiments on selectional preference induction to inverse selectional preference, considering the restriction imposed on predicates. [sent-47, score-0.373]
</p><p>25 Inverse sectional preference is also implemented in linggle (e. [sent-48, score-0.742]
</p><p>26 Linggle presents clusters of synonymous collocates (adjectives, nouns and verbs) of a query keyword. [sent-51, score-0.329]
</p><p>27 We obtained the clusters by building on Lin and Pantel’s (2002) large-scale repository of dependencies and word similarity scores. [sent-52, score-0.237]
</p><p>28 Using the method proposed by Ritter and Etzioni (2010) we induce selectional preference with a Latent Dirichlet Allocation (LDA) model to seed the clusters. [sent-53, score-0.204]
</p><p>29 Then we present the syntax of the queries and the functionalities of the system (Section 3). [sent-56, score-0.178]
</p><p>30 We describe the details of implementation including the indexing of the n-grams and the clustering algorithm (Section 4) and draw perspective of development of Web scale search engines (Section 5). [sent-57, score-0.281]
</p><p>31 We present in this paper a linguistic search engine that provides a  more comprehensive and powerful set of query features. [sent-60, score-0.324]
</p><p>32 (2001) describe the implementation of the linguistic search engine Word Sketch (2001) that displays collocations and dependencies acquired from a large corpus such as the BNC. [sent-62, score-0.263]
</p><p>33 Word Sketch is not as flexible as typical search engines, only supporting a fixed set of queries. [sent-63, score-0.071]
</p><p>34 Recently, researchers have been attempting to go one step further and work with Web scale datasets, but it is difficult for an academic institute to crawl a dataset that is on par with the datasets built by search engine companies. [sent-64, score-0.204]
</p><p>35 In 2008, Chang described a prototype that enhances Google Web 1T bigrams with PoS tags and supports search in the dataset by wildcards (wild-PoS), to identify recurring collocations. [sent-66, score-0.183]
</p><p>36 In contrast to Linggle, NetSpeak does not support PoS wildcard or conceptual clustering. [sent-69, score-0.117]
</p><p>37 An important function in both Linggle and NetSpeak is synonym query. [sent-70, score-0.079]
</p><p>38 NetSpeak uses WordNet (Fellbaum 2010) synsets to support synonym match. [sent-71, score-0.079]
</p><p>39 Alternatively, one can use the distributional approach to similarity based on a very large corpus. [sent-73, score-0.095]
</p><p>40 Lin and Pantel (2002) report efforts to build a large repository of dependencies extracted from large corpora such as Wikipedia, and provide similarity between words (demo. [sent-74, score-0.109]
</p><p>41 We use these results both for handling synonym queries and to or…  ganize the n-grams into semantic classes. [sent-77, score-0.189]
</p><p>42 2003) to 140  the problem of inducing selectional preference. [sent-79, score-0.134]
</p><p>43 The arguments of the verb that are encountered in the corpus are treated as the words composing a document in the traditional model. [sent-81, score-0.099]
</p><p>44 The model seems to successfully infer the semantic classes that correspond to the preferred arguments of a verb. [sent-82, score-0.118]
</p><p>45 The topics are semi-automatically labeled with WordNet classes to produce a repository of human interpretable class-based selectional preference. [sent-83, score-0.382]
</p><p>46 This choice might be due to the fact that if most LDA topic heads are usually reasonable upon human inspection, some topics are also incoherent (Newman 2010) and lower frequency words are not handled as successfully. [sent-84, score-0.158]
</p><p>47 We control the coherence of the topics and rearrange them into human interpretable clusters using a distributional similarity measure. [sent-85, score-0.339]
</p><p>48 We exploit and combine the power of both LDA analysis and distributional similarity to provide meaningful semantic classes that are constrained with members of high similarity. [sent-93, score-0.174]
</p><p>49 Distributional similarity (Lin 1998) and LDA topics become two angles of attack to view language usage and corpus patterns. [sent-94, score-0.179]
</p><p>50 3  Linggle Functionalities  The syntax of Linggle queries involves basic regular expression of keywords enriched with wildcard PoS and synonyms. [sent-95, score-0.33]
</p><p>51 Linggle queries can be either pattern-based commands or natural language questions. [sent-96, score-0.153]
</p><p>52 The natural language queries are currently handled by simple string matching based on a limited set of questions and command pairs provided by a native speaker informant. [sent-97, score-0.11]
</p><p>53 1 Natural language queries The handling of queries formulated in natural language has been implemented with handcrafted patterns refined from a corpus of questions found on various websites. [sent-99, score-0.22]
</p><p>54 2 Syntax of queries  The syntax of the patterns for n-grams is shown in Table 1. [sent-108, score-0.142]
</p><p>55 The syntax supports two types of query functions: basic keyword search with regular expression capability and semantic search. [sent-109, score-0.4]
</p><p>56 Basic search operators enable the users to query zero, one or more arbitrary words up to five words. [sent-110, score-0.216]
</p><p>57 For example, the query “set off $N” is intended to search for all nouns in the right context of set off, within a maximum distance of three words. [sent-111, score-0.272]
</p><p>58 ” operator in front of a word represents a search for n-grams with or without the word. [sent-113, score-0.071]
</p><p>59 For example, a user wanting to determine whether to use the word to between listen and music can formulate the query “listen ? [sent-114, score-0.186]
</p><p>60 ” Yet another operation “|” is provided to search for information related to word choice. [sent-116, score-0.071]
</p><p>61 A set of PoS symbols (shown in Table 2) is defined to support queries that need more precision than the symbol *. [sent-121, score-0.11]
</p><p>62 Placed in front of a word, it is intended to search for synonyms in the context. [sent-125, score-0.204]
</p><p>63 For example the query “+sandy beach” would generate rocky beach, stony beach, barren beach in the top three results. [sent-126, score-0.43]
</p><p>64 The query “+abandoned beach” generates deserted, destroyed and empty beach at the top of the list. [sent-127, score-0.381]
</p><p>65 To support conceptual clustering of collocational n-grams, we need to 141  identify synonyms related to different senses of a given word. [sent-128, score-0.242]
</p><p>66 +*|aOtopresaZPSAWDoeyalnr tiseohricWn/owrfyatihsmpot erhsdioeLurcnith gwoelrdsqoueris A cluster button on the interface activates or cancels conceptual clustering. [sent-132, score-0.087]
</p><p>67 When Linggle is switched into a cluster display mode, adjectivenouns, verb-objects and subject-verb relations can be browsed based on the induced conceptual  clusters (see Figure 1). [sent-133, score-0.287]
</p><p>68 The New York Times Example Base In order to display complete sentence examples for users, the New York Times Corpus sentences are indexed by word. [sent-134, score-0.072]
</p><p>69 When the user searches for words in a specific syntactic relation, morphological query expansion is performed and patterns are used to increase both the coverage and the precision of the provided examples. [sent-135, score-0.186]
</p><p>70 For example, the bi-gram kill bacteria will be associated with the example sentence “The bacteria are killed by high temperatures. [sent-136, score-0.134]
</p><p>71 3 Semantic Clusters Two types of semantic clusters are provided in Linggle: selectional preference and clusters of synonyms. [sent-139, score-0.46]
</p><p>72 Selectional preference expresses for example that an apple is more likely to be eaten or cooked than to be killed or hanged. [sent-140, score-0.14]
</p><p>73 Different classes of arguments for a predicate (or of predicates for an argument) can be found automatically. [sent-141, score-0.152]
</p><p>74 The favorite class of objects for the verb drink is LIQUID with the noun water ranked at the top. [sent-142, score-0.123]
</p><p>75 We aim at grouping arguments and predicates into semantic clusters for better readability. [sent-144, score-0.201]
</p><p>76 For example, among the objects of the verb cultivate, the nouns tie and contact belong to the same level-two cluster. [sent-147, score-0.179]
</p><p>77 The clusters of symonyms displayed in Table 3 follow the same representation. [sent-151, score-0.166]
</p><p>78 4  Implementation of the system  In this section, we describe the implementation of Linggle, including how to index and store ngrams for a fast access (Section 4. [sent-152, score-0.069]
</p><p>79 The major advantages of using a NoSQL database is the excellent performance in querying the ability of storing large amounts of data across several servers and the capability to scale up when we have additional entries in the dataset, or additional datasets to add to the system. [sent-161, score-0.066]
</p><p>80 The first type is a selectional preference model between heads and modifiers. [sent-164, score-0.204]
</p><p>81 The second is a word/synonyms model in which a word is considered as a document in LDA and its synonyms as the words of the document. [sent-166, score-0.133]
</p><p>82 This second model has the effect of splitting the synonyms of a word into different topics, as shown in  Table 3. [sent-167, score-0.133]
</p><p>83 imGRBaibnue(ctlCdPir,5cnthj):SeimCsea(tcrio,elfasjt)rhineyspibmroedtlwaunrcietoCyfnbt=hewcosi×eclnraejs linwsPotridapn tsj 5  Clustering algorithm  The clustering algorithm combines topic modeling results and a semantic similarity measure. [sent-172, score-0.163]
</p><p>84 We combine the two distributional semantics approaches in a simple manner inspired by clustering by committee algorithm (CBC). [sent-178, score-0.1]
</p><p>85 The similarity measure is used to refine the LDA topics and to generate finer grain clusters. [sent-179, score-0.122]
</p><p>86 Conversely, LDA topics can also be seen as the seeds of our clustering algorithm. [sent-180, score-0.127]
</p><p>87 This algorithm intends to constrain the words that belong to a final cluster more strictly than LDA does in order to obtain clearly interpretable clusters. [sent-181, score-0.089]
</p><p>88 The exact same algorithm is applied to synonym models, for synonyms of nouns, adjectives and verbs (shown in Table 3). [sent-182, score-0.212]
</p><p>89 Table 4 shows the algorithm for constructing double layer clusters for a set S of objects of a verb v. [sent-183, score-0.251]
</p><p>90 The objects are first roughly split into classes, attributing a single topic to every object oi. [sent-184, score-0.109]
</p><p>91 More experiments could be done using the product of the per document-topic and the per topic-word LDA probabilities instead, in order to take into account the specific verb when assigning a topic to the object. [sent-186, score-0.106]
</p><p>92 At this stage, some classes are incoherent and that low frequency words that do not appear in the head of any topic are often misclassified. [sent-188, score-0.171]
</p><p>93 Words are rearranged between the classes and create new classes if necessary using the similarity measure. [sent-189, score-0.214]
</p><p>94 Any two classes are then merged if their similarity (computer accordingly to Table 5) is above s2=0. [sent-192, score-0.135]
</p><p>95 Finally, the classes that contain less than three  words are not displayed in Linggle and the predicate-arguments counts in the Web 1T are retrieved using a few hand crafted RE and morphological expansion of the nouns and the verbs. [sent-196, score-0.173]
</p><p>96 This algorithm appears to generate interpretable semantic classes and to be quite robust regarding the threshold parameters. [sent-197, score-0.129]
</p><p>97 The second one concerns the extension of the coverage of the example base with several large corpora such as Wikipedia and the extension of the coverage of the similarity measure. [sent-201, score-0.138]
</p><p>98 Linggle displays both word usage and word similarity information. [sent-205, score-0.152]
</p><p>99 Depending on the type of the input query, the results are displayed under the form of lists or clusters of n-grams. [sent-206, score-0.166]
</p><p>100 Word sketch: Extraction and display of significant collocations for lexicography. [sent-237, score-0.12]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('linggle', 0.672), ('beach', 0.236), ('lda', 0.172), ('query', 0.145), ('selectional', 0.134), ('synonyms', 0.133), ('clusters', 0.128), ('netspeak', 0.112), ('sempute', 0.112), ('queries', 0.11), ('absorb', 0.084), ('franken', 0.084), ('needleseek', 0.084), ('classes', 0.079), ('synonym', 0.079), ('display', 0.072), ('bnc', 0.071), ('search', 0.071), ('preference', 0.07), ('wildcard', 0.069), ('engine', 0.067), ('web', 0.067), ('topics', 0.066), ('ritter', 0.065), ('google', 0.065), ('potthast', 0.064), ('objects', 0.063), ('clustering', 0.061), ('verb', 0.06), ('pos', 0.059), ('usage', 0.057), ('similarity', 0.056), ('hbase', 0.056), ('nosql', 0.056), ('trenkmann', 0.056), ('nouns', 0.056), ('sketch', 0.055), ('repository', 0.053), ('interpretable', 0.05), ('rocky', 0.049), ('bacteria', 0.049), ('lse', 0.049), ('wildcards', 0.049), ('collocations', 0.048), ('conceptual', 0.048), ('pantel', 0.047), ('witten', 0.047), ('topic', 0.046), ('dream', 0.046), ('liquid', 0.046), ('sandy', 0.046), ('incoherent', 0.046), ('regular', 0.045), ('chunks', 0.044), ('chang', 0.044), ('collocation', 0.043), ('engines', 0.043), ('commands', 0.043), ('aimed', 0.043), ('edition', 0.043), ('keyword', 0.041), ('kilgarriff', 0.041), ('listen', 0.041), ('coverage', 0.041), ('comprehensive', 0.041), ('keywords', 0.04), ('etzioni', 0.039), ('displays', 0.039), ('benno', 0.039), ('arguments', 0.039), ('cluster', 0.039), ('distributional', 0.039), ('displayed', 0.038), ('implementation', 0.038), ('bank', 0.037), ('killed', 0.036), ('functionalities', 0.036), ('indexing', 0.036), ('stein', 0.035), ('inverse', 0.035), ('mode', 0.035), ('datasets', 0.034), ('apple', 0.034), ('inverted', 0.034), ('retrieves', 0.034), ('predicates', 0.034), ('dirichlet', 0.034), ('expression', 0.034), ('martin', 0.034), ('dekang', 0.034), ('newman', 0.033), ('lin', 0.033), ('allocation', 0.033), ('wu', 0.033), ('york', 0.032), ('scale', 0.032), ('syntax', 0.032), ('supports', 0.032), ('prototype', 0.031), ('access', 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999958 <a title="231-tfidf-1" href="./acl-2013-Linggle%3A_a_Web-scale_Linguistic_Search_Engine_for_Words_in_Context.html">231 acl-2013-Linggle: a Web-scale Linguistic Search Engine for Words in Context</a></p>
<p>Author: Joanne Boisson ; Ting-Hui Kao ; Jian-Cheng Wu ; Tzu-Hsi Yen ; Jason S. Chang</p><p>Abstract: In this paper, we introduce a Web-scale linguistics search engine, Linggle, that retrieves lexical bundles in response to a given query. The query might contain keywords, wildcards, wild parts of speech (PoS), synonyms, and additional regular expression (RE) operators. In our approach, we incorporate inverted file indexing, PoS information from BNC, and semantic indexing based on Latent Dirichlet Allocation with Google Web 1T. The method involves parsing the query to transforming it into several keyword retrieval commands. Word chunks are retrieved with counts, further filtering the chunks with the query as a RE, and finally displaying the results according to the counts, similarities, and topics. Clusters of synonyms or conceptually related words are also provided. In addition, Linggle provides example sentences from The New York Times on demand. The current implementation of Linggle is the most functionally comprehensive, and is in principle language and dataset independent. We plan to extend Linggle to provide fast and convenient access to a wealth of linguistic information embodied in Web scale datasets including Google Web 1T and Google Books Ngram for many major languages in the world. 1</p><p>2 0.13734412 <a title="231-tfidf-2" href="./acl-2013-Are_Semantically_Coherent_Topic_Models_Useful_for_Ad_Hoc_Information_Retrieval%3F.html">55 acl-2013-Are Semantically Coherent Topic Models Useful for Ad Hoc Information Retrieval?</a></p>
<p>Author: Romain Deveaud ; Eric SanJuan ; Patrice Bellot</p><p>Abstract: The current topic modeling approaches for Information Retrieval do not allow to explicitly model query-oriented latent topics. More, the semantic coherence of the topics has never been considered in this field. We propose a model-based feedback approach that learns Latent Dirichlet Allocation topic models on the top-ranked pseudo-relevant feedback, and we measure the semantic coherence of those topics. We perform a first experimental evaluation using two major TREC test collections. Results show that retrieval perfor- mances tend to be better when using topics with higher semantic coherence.</p><p>3 0.11568705 <a title="231-tfidf-3" href="./acl-2013-SPred%3A_Large-scale_Harvesting_of_Semantic_Predicates.html">306 acl-2013-SPred: Large-scale Harvesting of Semantic Predicates</a></p>
<p>Author: Tiziano Flati ; Roberto Navigli</p><p>Abstract: We present SPred, a novel method for the creation of large repositories of semantic predicates. We start from existing collocations to form lexical predicates (e.g., break ∗) and learn the semantic classes that best f∗it) tahned ∗ argument. Taon idco this, we extract failtl thhee ∗ occurrences ion Wikipedia ewxthraiccht match the predicate and abstract its arguments to general semantic classes (e.g., break BODY PART, break AGREEMENT, etc.). Our experiments show that we are able to create a large collection of semantic predicates from the Oxford Advanced Learner’s Dictionary with high precision and recall, and perform well against the most similar approach.</p><p>4 0.11131064 <a title="231-tfidf-4" href="./acl-2013-A_Two_Level_Model_for_Context_Sensitive_Inference_Rules.html">27 acl-2013-A Two Level Model for Context Sensitive Inference Rules</a></p>
<p>Author: Oren Melamud ; Jonathan Berant ; Ido Dagan ; Jacob Goldberger ; Idan Szpektor</p><p>Abstract: Automatic acquisition of inference rules for predicates has been commonly addressed by computing distributional similarity between vectors of argument words, operating at the word space level. A recent line of work, which addresses context sensitivity of rules, represented contexts in a latent topic space and computed similarity over topic vectors. We propose a novel two-level model, which computes similarities between word-level vectors that are biased by topic-level context representations. Evaluations on a naturallydistributed dataset show that our model significantly outperforms prior word-level and topic-level models. We also release a first context-sensitive inference rule set.</p><p>5 0.10592392 <a title="231-tfidf-5" href="./acl-2013-A_Random_Walk_Approach_to_Selectional_Preferences_Based_on_Preference_Ranking_and_Propagation.html">17 acl-2013-A Random Walk Approach to Selectional Preferences Based on Preference Ranking and Propagation</a></p>
<p>Author: Zhenhua Tian ; Hengheng Xiang ; Ziqi Liu ; Qinghua Zheng</p><p>Abstract: This paper presents an unsupervised random walk approach to alleviate data sparsity for selectional preferences. Based on the measure of preferences between predicates and arguments, the model aggregates all the transitions from a given predicate to its nearby predicates, and propagates their argument preferences as the given predicate’s smoothed preferences. Experimental results show that this approach outperforms several state-of-the-art methods on the pseudo-disambiguation task, and it better correlates with human plausibility judgements.</p><p>6 0.10576376 <a title="231-tfidf-6" href="./acl-2013-ICARUS_-_An_Extensible_Graphical_Search_Tool_for_Dependency_Treebanks.html">183 acl-2013-ICARUS - An Extensible Graphical Search Tool for Dependency Treebanks</a></p>
<p>7 0.094241433 <a title="231-tfidf-7" href="./acl-2013-Building_Comparable_Corpora_Based_on_Bilingual_LDA_Model.html">74 acl-2013-Building Comparable Corpora Based on Bilingual LDA Model</a></p>
<p>8 0.089239024 <a title="231-tfidf-8" href="./acl-2013-Automated_Collocation_Suggestion_for_Japanese_Second_Language_Learners.html">58 acl-2013-Automated Collocation Suggestion for Japanese Second Language Learners</a></p>
<p>9 0.087602288 <a title="231-tfidf-9" href="./acl-2013-Question_Analysis_for_Polish_Question_Answering.html">290 acl-2013-Question Analysis for Polish Question Answering</a></p>
<p>10 0.086726367 <a title="231-tfidf-10" href="./acl-2013-Crowd_Prefers_the_Middle_Path%3A_A_New_IAA_Metric_for_Crowdsourcing_Reveals_Turker_Biases_in_Query_Segmentation.html">99 acl-2013-Crowd Prefers the Middle Path: A New IAA Metric for Crowdsourcing Reveals Turker Biases in Query Segmentation</a></p>
<p>11 0.086644441 <a title="231-tfidf-11" href="./acl-2013-Paraphrasing_Adaptation_for_Web_Search_Ranking.html">273 acl-2013-Paraphrasing Adaptation for Web Search Ranking</a></p>
<p>12 0.085179791 <a title="231-tfidf-12" href="./acl-2013-Improved_Lexical_Acquisition_through_DPP-based_Verb_Clustering.html">192 acl-2013-Improved Lexical Acquisition through DPP-based Verb Clustering</a></p>
<p>13 0.079909585 <a title="231-tfidf-13" href="./acl-2013-Paraphrase-Driven_Learning_for_Open_Question_Answering.html">272 acl-2013-Paraphrase-Driven Learning for Open Question Answering</a></p>
<p>14 0.078262612 <a title="231-tfidf-14" href="./acl-2013-Broadcast_News_Story_Segmentation_Using_Manifold_Learning_on_Latent_Topic_Distributions.html">73 acl-2013-Broadcast News Story Segmentation Using Manifold Learning on Latent Topic Distributions</a></p>
<p>15 0.076207995 <a title="231-tfidf-15" href="./acl-2013-Incremental_Topic-Based_Translation_Model_Adaptation_for_Conversational_Spoken_Language_Translation.html">197 acl-2013-Incremental Topic-Based Translation Model Adaptation for Conversational Spoken Language Translation</a></p>
<p>16 0.075102799 <a title="231-tfidf-16" href="./acl-2013-Text_Classification_based_on_the_Latent_Topics_of_Important_Sentences_extracted_by_the_PageRank_Algorithm.html">341 acl-2013-Text Classification based on the Latent Topics of Important Sentences extracted by the PageRank Algorithm</a></p>
<p>17 0.075004697 <a title="231-tfidf-17" href="./acl-2013-Using_Lexical_Expansion_to_Learn_Inference_Rules_from_Sparse_Data.html">376 acl-2013-Using Lexical Expansion to Learn Inference Rules from Sparse Data</a></p>
<p>18 0.074957691 <a title="231-tfidf-18" href="./acl-2013-Detecting_Metaphor_by_Contextual_Analogy.html">116 acl-2013-Detecting Metaphor by Contextual Analogy</a></p>
<p>19 0.073659487 <a title="231-tfidf-19" href="./acl-2013-Align%2C_Disambiguate_and_Walk%3A_A_Unified_Approach_for_Measuring_Semantic_Similarity.html">43 acl-2013-Align, Disambiguate and Walk: A Unified Approach for Measuring Semantic Similarity</a></p>
<p>20 0.072347231 <a title="231-tfidf-20" href="./acl-2013-Topic_Modeling_Based_Classification_of_Clinical_Reports.html">351 acl-2013-Topic Modeling Based Classification of Clinical Reports</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.188), (1, 0.078), (2, 0.013), (3, -0.14), (4, 0.02), (5, -0.062), (6, -0.01), (7, -0.053), (8, -0.042), (9, -0.059), (10, 0.02), (11, 0.062), (12, 0.093), (13, 0.09), (14, 0.021), (15, -0.059), (16, 0.008), (17, 0.007), (18, 0.067), (19, 0.008), (20, -0.054), (21, 0.05), (22, -0.027), (23, -0.023), (24, 0.138), (25, -0.005), (26, -0.011), (27, 0.043), (28, -0.022), (29, 0.057), (30, 0.008), (31, 0.007), (32, -0.135), (33, -0.144), (34, -0.013), (35, -0.003), (36, 0.031), (37, -0.021), (38, 0.003), (39, 0.026), (40, -0.084), (41, -0.094), (42, 0.015), (43, 0.04), (44, -0.008), (45, -0.078), (46, -0.03), (47, 0.012), (48, 0.004), (49, -0.07)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93159658 <a title="231-lsi-1" href="./acl-2013-Linggle%3A_a_Web-scale_Linguistic_Search_Engine_for_Words_in_Context.html">231 acl-2013-Linggle: a Web-scale Linguistic Search Engine for Words in Context</a></p>
<p>Author: Joanne Boisson ; Ting-Hui Kao ; Jian-Cheng Wu ; Tzu-Hsi Yen ; Jason S. Chang</p><p>Abstract: In this paper, we introduce a Web-scale linguistics search engine, Linggle, that retrieves lexical bundles in response to a given query. The query might contain keywords, wildcards, wild parts of speech (PoS), synonyms, and additional regular expression (RE) operators. In our approach, we incorporate inverted file indexing, PoS information from BNC, and semantic indexing based on Latent Dirichlet Allocation with Google Web 1T. The method involves parsing the query to transforming it into several keyword retrieval commands. Word chunks are retrieved with counts, further filtering the chunks with the query as a RE, and finally displaying the results according to the counts, similarities, and topics. Clusters of synonyms or conceptually related words are also provided. In addition, Linggle provides example sentences from The New York Times on demand. The current implementation of Linggle is the most functionally comprehensive, and is in principle language and dataset independent. We plan to extend Linggle to provide fast and convenient access to a wealth of linguistic information embodied in Web scale datasets including Google Web 1T and Google Books Ngram for many major languages in the world. 1</p><p>2 0.62242013 <a title="231-lsi-2" href="./acl-2013-Are_Semantically_Coherent_Topic_Models_Useful_for_Ad_Hoc_Information_Retrieval%3F.html">55 acl-2013-Are Semantically Coherent Topic Models Useful for Ad Hoc Information Retrieval?</a></p>
<p>Author: Romain Deveaud ; Eric SanJuan ; Patrice Bellot</p><p>Abstract: The current topic modeling approaches for Information Retrieval do not allow to explicitly model query-oriented latent topics. More, the semantic coherence of the topics has never been considered in this field. We propose a model-based feedback approach that learns Latent Dirichlet Allocation topic models on the top-ranked pseudo-relevant feedback, and we measure the semantic coherence of those topics. We perform a first experimental evaluation using two major TREC test collections. Results show that retrieval perfor- mances tend to be better when using topics with higher semantic coherence.</p><p>3 0.61006105 <a title="231-lsi-3" href="./acl-2013-ICARUS_-_An_Extensible_Graphical_Search_Tool_for_Dependency_Treebanks.html">183 acl-2013-ICARUS - An Extensible Graphical Search Tool for Dependency Treebanks</a></p>
<p>Author: Markus Gartner ; Gregor Thiele ; Wolfgang Seeker ; Anders Bjorkelund ; Jonas Kuhn</p><p>Abstract: We present ICARUS, a versatile graphical search tool to query dependency treebanks. Search results can be inspected both quantitatively and qualitatively by means of frequency lists, tables, or dependency graphs. ICARUS also ships with plugins that enable it to interface with tool chains running either locally or remotely.</p><p>4 0.60638165 <a title="231-lsi-4" href="./acl-2013-Paraphrasing_Adaptation_for_Web_Search_Ranking.html">273 acl-2013-Paraphrasing Adaptation for Web Search Ranking</a></p>
<p>Author: Chenguang Wang ; Nan Duan ; Ming Zhou ; Ming Zhang</p><p>Abstract: Mismatch between queries and documents is a key issue for the web search task. In order to narrow down such mismatch, in this paper, we present an in-depth investigation on adapting a paraphrasing technique to web search from three aspects: a search-oriented paraphrasing model; an NDCG-based parameter optimization algorithm; an enhanced ranking model leveraging augmented features computed on paraphrases of original queries. Ex- periments performed on the large scale query-document data set show that, the search performance can be significantly improved, with +3.28% and +1.14% NDCG gains on dev and test sets respectively.</p><p>5 0.59477669 <a title="231-lsi-5" href="./acl-2013-Post-Retrieval_Clustering_Using_Third-Order_Similarity_Measures.html">281 acl-2013-Post-Retrieval Clustering Using Third-Order Similarity Measures</a></p>
<p>Author: Jose G. Moreno ; Gael Dias ; Guillaume Cleuziou</p><p>Abstract: Post-retrieval clustering is the task of clustering Web search results. Within this context, we propose a new methodology that adapts the classical K-means algorithm to a third-order similarity measure initially developed for NLP tasks. Results obtained with the definition of a new stopping criterion over the ODP-239 and the MORESQUE gold standard datasets evidence that our proposal outperforms all reported text-based approaches.</p><p>6 0.57775718 <a title="231-lsi-6" href="./acl-2013-ParaQuery%3A_Making_Sense_of_Paraphrase_Collections.html">271 acl-2013-ParaQuery: Making Sense of Paraphrase Collections</a></p>
<p>7 0.56483954 <a title="231-lsi-7" href="./acl-2013-Improved_Lexical_Acquisition_through_DPP-based_Verb_Clustering.html">192 acl-2013-Improved Lexical Acquisition through DPP-based Verb Clustering</a></p>
<p>8 0.54361546 <a title="231-lsi-8" href="./acl-2013-Diverse_Keyword_Extraction_from_Conversations.html">126 acl-2013-Diverse Keyword Extraction from Conversations</a></p>
<p>9 0.54343706 <a title="231-lsi-9" href="./acl-2013-Feature-Based_Selection_of_Dependency_Paths_in_Ad_Hoc_Information_Retrieval.html">158 acl-2013-Feature-Based Selection of Dependency Paths in Ad Hoc Information Retrieval</a></p>
<p>10 0.54198545 <a title="231-lsi-10" href="./acl-2013-PATHS%3A_A_System_for_Accessing_Cultural_Heritage_Collections.html">268 acl-2013-PATHS: A System for Accessing Cultural Heritage Collections</a></p>
<p>11 0.52516931 <a title="231-lsi-11" href="./acl-2013-Language_Acquisition_and_Probabilistic_Models%3A_keeping_it_simple.html">213 acl-2013-Language Acquisition and Probabilistic Models: keeping it simple</a></p>
<p>12 0.51264304 <a title="231-lsi-12" href="./acl-2013-A_Two_Level_Model_for_Context_Sensitive_Inference_Rules.html">27 acl-2013-A Two Level Model for Context Sensitive Inference Rules</a></p>
<p>13 0.51059347 <a title="231-lsi-13" href="./acl-2013-A_Random_Walk_Approach_to_Selectional_Preferences_Based_on_Preference_Ranking_and_Propagation.html">17 acl-2013-A Random Walk Approach to Selectional Preferences Based on Preference Ranking and Propagation</a></p>
<p>14 0.50953346 <a title="231-lsi-14" href="./acl-2013-The_Effects_of_Lexical_Resource_Quality_on_Preference_Violation_Detection.html">344 acl-2013-The Effects of Lexical Resource Quality on Preference Violation Detection</a></p>
<p>15 0.50778121 <a title="231-lsi-15" href="./acl-2013-Learning_Latent_Personas_of_Film_Characters.html">220 acl-2013-Learning Latent Personas of Film Characters</a></p>
<p>16 0.50351334 <a title="231-lsi-16" href="./acl-2013-Propminer%3A_A_Workflow_for_Interactive_Information_Extraction_and_Exploration_using_Dependency_Trees.html">285 acl-2013-Propminer: A Workflow for Interactive Information Extraction and Exploration using Dependency Trees</a></p>
<p>17 0.50279176 <a title="231-lsi-17" href="./acl-2013-A_Visual_Analytics_System_for_Cluster_Exploration.html">29 acl-2013-A Visual Analytics System for Cluster Exploration</a></p>
<p>18 0.49917254 <a title="231-lsi-18" href="./acl-2013-Mining_Equivalent_Relations_from_Linked_Data.html">242 acl-2013-Mining Equivalent Relations from Linked Data</a></p>
<p>19 0.49717897 <a title="231-lsi-19" href="./acl-2013-Building_and_Evaluating_a_Distributional_Memory_for_Croatian.html">76 acl-2013-Building and Evaluating a Distributional Memory for Croatian</a></p>
<p>20 0.49510872 <a title="231-lsi-20" href="./acl-2013-Automated_Collocation_Suggestion_for_Japanese_Second_Language_Learners.html">58 acl-2013-Automated Collocation Suggestion for Japanese Second Language Learners</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.064), (6, 0.021), (11, 0.067), (24, 0.077), (26, 0.039), (28, 0.018), (35, 0.128), (42, 0.073), (48, 0.063), (64, 0.017), (70, 0.034), (75, 0.195), (88, 0.032), (90, 0.033), (95, 0.05)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.8780309 <a title="231-lda-1" href="./acl-2013-An_annotated_corpus_of_quoted_opinions_in_news_articles.html">49 acl-2013-An annotated corpus of quoted opinions in news articles</a></p>
<p>Author: Tim O'Keefe ; James R. Curran ; Peter Ashwell ; Irena Koprinska</p><p>Abstract: Quotes are used in news articles as evidence of a person’s opinion, and thus are a useful target for opinion mining. However, labelling each quote with a polarity score directed at a textually-anchored target can ignore the broader issue that the speaker is commenting on. We address this by instead labelling quotes as supporting or opposing a clear expression of a point of view on a topic, called a position statement. Using this we construct a corpus covering 7 topics with 2,228 quotes.</p><p>same-paper 2 0.8459295 <a title="231-lda-2" href="./acl-2013-Linggle%3A_a_Web-scale_Linguistic_Search_Engine_for_Words_in_Context.html">231 acl-2013-Linggle: a Web-scale Linguistic Search Engine for Words in Context</a></p>
<p>Author: Joanne Boisson ; Ting-Hui Kao ; Jian-Cheng Wu ; Tzu-Hsi Yen ; Jason S. Chang</p><p>Abstract: In this paper, we introduce a Web-scale linguistics search engine, Linggle, that retrieves lexical bundles in response to a given query. The query might contain keywords, wildcards, wild parts of speech (PoS), synonyms, and additional regular expression (RE) operators. In our approach, we incorporate inverted file indexing, PoS information from BNC, and semantic indexing based on Latent Dirichlet Allocation with Google Web 1T. The method involves parsing the query to transforming it into several keyword retrieval commands. Word chunks are retrieved with counts, further filtering the chunks with the query as a RE, and finally displaying the results according to the counts, similarities, and topics. Clusters of synonyms or conceptually related words are also provided. In addition, Linggle provides example sentences from The New York Times on demand. The current implementation of Linggle is the most functionally comprehensive, and is in principle language and dataset independent. We plan to extend Linggle to provide fast and convenient access to a wealth of linguistic information embodied in Web scale datasets including Google Web 1T and Google Books Ngram for many major languages in the world. 1</p><p>3 0.72875625 <a title="231-lda-3" href="./acl-2013-Docent%3A_A_Document-Level_Decoder_for_Phrase-Based_Statistical_Machine_Translation.html">127 acl-2013-Docent: A Document-Level Decoder for Phrase-Based Statistical Machine Translation</a></p>
<p>Author: Christian Hardmeier ; Sara Stymne ; Jorg Tiedemann ; Joakim Nivre</p><p>Abstract: We describe Docent, an open-source decoder for statistical machine translation that breaks with the usual sentence-bysentence paradigm and translates complete documents as units. By taking translation to the document level, our decoder can handle feature models with arbitrary discourse-wide dependencies and constitutes an essential infrastructure component in the quest for discourse-aware SMT models. 1 Motivation Most of the research on statistical machine translation (SMT) that was conducted during the last 20 years treated every text as a “bag of sentences” and disregarded all relations between elements in different sentences. Systematic research into explicitly discourse-related problems has only begun very recently in the SMT community (Hardmeier, 2012) with work on topics such as pronominal anaphora (Le Nagard and Koehn, 2010; Hardmeier and Federico, 2010; Guillou, 2012), verb tense (Gong et al., 2012) and discourse connectives (Meyer et al., 2012). One of the problems that hamper the development of cross-sentence models for SMT is the fact that the assumption of sentence independence is at the heart of the dynamic programming (DP) beam search algorithm most commonly used for decoding in phrase-based SMT systems (Koehn et al., 2003). For integrating cross-sentence features into the decoding process, researchers had to adopt strategies like two-pass decoding (Le Nagard and Koehn, 2010). We have previously proposed an algorithm for document-level phrase-based SMT decoding (Hardmeier et al., 2012). Our decoding algorithm is based on local search instead of dynamic programming and permits the integration of 193 document-level models with unrestricted dependencies, so that a model score can be conditioned on arbitrary elements occurring anywhere in the input document or in the translation that is being generated. In this paper, we present an open-source implementation of this search algorithm. The decoder is written in C++ and follows an objectoriented design that makes it easy to extend it with new feature models, new search operations or different types of local search algorithms. The code is released under the GNU General Public License and published on Github1 to make it easy for other researchers to use it in their own experiments. 2 Document-Level Decoding with Local Search Our decoder is based on the phrase-based SMT model described by Koehn et al. (2003) and implemented, for example, in the popular Moses decoder (Koehn et al., 2007). Translation is performed by splitting the input sentence into a number of contiguous word sequences, called phrases, which are translated into the target lan- guage through a phrase dictionary lookup and optionally reordered. The choice between different translations of an ambiguous source phrase and the ordering of the target phrases are guided by a scoring function that combines a set of scores taken from the phrase table with scores from other models such as an n-gram language model. The actual translation process is realised as a search for the highest-scoring translation in the space of all the possible translations that could be generated given the models. The decoding approach that is implemented in Docent was first proposed by Hardmeier et al. (2012) and is based on local search. This means that it has a state corresponding to a complete, if possibly bad, translation of a document at every 1https : //github .com/chardmeier/docent/wiki Proce dingSsof oifa, th Beu 5l1gsarti Aan,An u aglu Mste 4e-ti9n2g 0 o1f3 t.he ?c A2s0s1o3ci Aatsiosonc fioartio Cno fmorpu Ctoamtiopnuatalt Lioin gauli Lsitnicgsu,i psatgices 193–198, stage of the search progress. Search proceeds by making small changes to the current search state in order to transform it gradually into a better translation. This differs from the DP algorithm used in other decoders, which starts with an empty translation and expands it bit by bit. It is similar to previous work on phrase-based SMT decoding by Langlais et al. (2007), but enables the creation of document-level models, which was not addressed by earlier approaches. Docent currently implements two search algorithms that are different generalisations of the hill climbing local search algorithm by Hardmeier et al. (2012). The original hill climbing algorithm starts with an initial state and generates possible successor states by randomly applying simple elementary operations to the state. After each operation, the new state is scored and accepted if its score is better than that of the previous state, else rejected. Search terminates when the decoder cannot find an acceptable successor state after a certain number of attempts, or when a maximum number of steps is reached. Simulated annealing is a stochastic variant of hill climbing that always accepts moves towards better states, but can also accept moves towards lower-scoring states with a certain probability that depends on a temperature parameter in order to escape local maxima. Local beam search generalises hill climbing in a different way by keeping a beam of a fixed number of multiple states at any time and randomly picking a state from the beam to modify at each move. The original hill climbing procedure can be recovered as a special case of either one of these search algorithms, by calling simulated annealing with a fixed temperature of 0 or local beam search with a beam size of 1. Initial states for the search process can be generated either by selecting a random segmentation with random translations from the phrase table in monotonic order, or by running DP beam search with sentence-local models as a first pass. For the second option, which generally yields better search results, Docent is linked with the Moses decoder and makes direct calls to the DP beam search algorithm implemented by Moses. In addition to these state initialisation procedures, Docent can save a search state to a disk file which can be loaded again in a subsequent decoding pass. This saves time especially when running repeated experiments from the same starting point obtained 194 by DP search. In order to explore the complete search space of phrase-based SMT, the search operations in a local search decoder must be able to change the phrase translations, the order of the output phrases and the segmentation of the source sentence into phrases. The three operations used by Hardmeier et al. (2012), change-phrase-translation, resegment and swap-phrases, jointly meet this requirement and are all implemented in Docent. Additionally, Docent features three extra operations, all of which affect the target word order: The movephrases operation moves a phrase to another location in the sentence. Unlike swap-phrases, it does not require that another phrase be moved in the opposite direction at the same time. A pair of operations called permute-phrases and linearisephrasescanreorderasequenceofphrasesintorandom order and back into the order corresponding to the source language. Since the search algorithm in Docent is stochastic, repeated runs of the decoder will gen- erally produce different output. However, the variance of the output is usually small, especially when initialising with a DP search pass, and it tends to be lower than the variance introduced by feature weight tuning (Hardmeier et al., 2012; Stymne et al., 2013a). 3 Available Feature Models In its current version, Docent implements a selection of sentence-local feature models that makes it possible to build a baseline system with a configuration comparable to that of a typical Moses baseline system. The published source code also includes prototype implementations of a few document-level models. These models should be considered work in progress and serve as a demonstration of the cross-sentence modelling capabilities of the decoder. They have not yet reached a state of maturity that would make them suitable for production use. The sentence-level models provided by Docent include the phrase table, n-gram language models implemented with the KenLM toolkit (Heafield, 2011), an unlexicalised distortion cost model with geometric decay (Koehn et al., 2003) and a word penalty cost. All of these features are designed to be compatible with the corresponding features in Moses. From among the typical set of baseline features in Moses, we have not implemented the lexicalised distortion model, but this model could easily be added if required. Docent uses the same binary file format for phrase tables as Moses, so the same training apparatus can be used. DP-based SMT decoders have a parameter called distortion limit that limits the difference in word order between the input and the MT output. In DP search, this is formally considered to be a parameter of the search algorithm because it affects the algorithmic complexity of the search by controlling how many translation options must be considered at each hypothesis expansion. The stochastic search algorithm in Docent does not require this limitation, but it can still be useful because the standard models of SMT do not model long-distance reordering well. Docent therefore includes a separate indicator feature to indicate a violated distortion limit. In conjunction with a very large weight, this feature can effectively ensure that the distortion limit is enforced. In contrast with the distortion limit parameter of a DP decoder, the weight ofour distortion limit feature can potentially be tuned to permit occasional distortion limit violations when they contribute to better translations. The document-level models included in Docent include a length parity model, a semantic language model as well as a collection of documentlevel readability models. The length parity model is a proof-of-concept model that ensures that all sentences in a document have either consistently odd or consistently even length. It serves mostly as a template to demonstrate how a simple documentlevel model can be implemented in the decoder. The semantic language model was originally proposed by Hardmeier et al. (2012) to improve lexical cohesion in a document. It is a cross-sentence model over sequences of content words that are scored based on their similarity in a word vector space. The readability models serve to improve the readability of the translation by encouraging the selection of easier and more consistent target words. They are described and demonstrated in more detail in section 5. Docent can read input files both in the NISTXML format commonly used to encode documents in MT shared tasks such as NIST or WMT and in the more elaborate MMAX format (Müller and Strube, 2003). The MMAX format makes it possible to include a wide range of discourselevel corpus annotations such as coreference links. 195 These annotations can then be accessed by the feature models. To allow for additional targetlanguage information such as morphological features of target words, Docent can handle simple word-level annotations that are encoded in the phrase table in the same way as target language factors in Moses. In order to optimise feature weights we have adapted the Moses tuning infrastructure to Docent. In this way we can take advantage of all its features, for instance using different optimisation algorithms such as MERT (Och, 2003) or PRO (Hopkins and May, 2011), and selective tuning of a subset of features. Since document features only give meaningful scores on the document level and not on the sentence level, we naturally perform optimisation on document level, which typically means that we need more data than for the optimisation of sentence-based decoding. The results we obtain are relatively stable and competitive with sentence-level optimisation of the same models (Stymne et al., 2013a). 4 Implementing Feature Models Efficiently While translating a document, the local search decoder attempts to make a great number of moves. For each move, a score must be computed and tested against the acceptance criterion. An overwhelming majority of the proposed moves will be rejected. In order to achieve reasonably fast decoding times, efficient scoring is paramount. Recomputing the scores of the whole document at every step would be far too slow for the decoder to be useful. Fortunately, score computation can be sped up in two ways. Knowledge about how the state to be scored was generated from its predecessor helps to limit recomputations to a minimum, and by adopting a two-step scoring procedure that just computes the scores that can be calculated with little effort at first, we need to compute the complete score only if the new state has some chance of being accepted. The scores of SMT feature models can usually be decomposed in some way over parts of the document. The traditional models borrowed from sentence-based decoding are necessarily decomposable at the sentence level, and in practice, all common models are designed to meet the constraints of DP beam search, which ensures that they can in fact be decomposed over even smaller sequences of just a few words. For genuine document-level features, this is not the case, but even these models can often be decomposed in some way, for instance over paragraphs, anaphoric links or lexical chains. To take advantage of this fact, feature models in Docent always have access to the previous state and its score and to a list of the state modifications that transform the previous state into the next. The scores of the new state are calculated by identifying the parts of a document that are affected by the modifications, subtracting the old scores of this part from the previous score and adding the new scores. This approach to scoring makes feature model implementation a bit more complicated than in DP search, but it gives the feature models full control over how they decompose a document while still permitting efficient decoding. A feature model class in Docent implements three methods. The initDocument method is called once per document when decoding starts. It straightforwardly computes the model score for the entire document from scratch. When a state is modified, the decoder first invokes the estimateScoreUpdate method. Rather than calculating the new score exactly, this method is only required to return an upper bound that reflects the maximum score that could possibly be achieved by this state. The search algorithm then checks this upper bound against the acceptance criterion. Only if the upper bound meets the criterion does it call the updateScore method to calculate the exact score, which is then checked against the acceptance criterion again. The motivation for this two-step procedure is that some models can compute an upper bound approximation much more efficiently than an exact score. For any model whose score is a log probability, a value of 0 is a loose upper bound that can be returned instantly, but in many cases, we can do much better. In the case of the n-gram language model, for instance, a more accurate upper bound can be computed cheaply by subtracting from the old score all log-probabilities of n-grams that are affected by the state modifications without adding the scores of the n-grams replacing them in the new state. This approximation can be calculated without doing any language model lookups at all. On the other hand, some models like the distortion cost or the word penalty are very cheap to compute, so that the estimateScoreUpdate method 196 can simply return the precise score as a tight up- per bound. If a state gets rejected because of a low score on one of the cheap models, this means we will never have to compute the more expensive feature scores at all. 5 Readability: A Case Study As a case study we report initial results on how document-wide features can be used in Docent in order to improve the readability oftexts by encouraging simple and consistent terminology (Stymne et al., 2013b). This work is a first step towards achieving joint SMT and text simplification, with the final goal of adapting MT to user groups such as people with reading disabilities. Lexical consistency modelling for SMT has been attempted before. The suggested approaches have been limited by the use of sentence-level decoders, however, and had to resort to procedures like post processing (Carpuat, 2009), multiple decoding runs with frozen counts from previous runs (Ture et al., 2012), or cache-based models (Tiedemann, 2010). In Docent, however, we al- ways have access to a full document translation, which makes it straightforward to include features directly into the decoder. We implemented four features on the document level. The first two features are type token ratio (TTR) and a reformulation of it, OVIX, which is less sensitive to text length. These ratios have been related to the “idea density” of a text (Mühlenbock and Kokkinakis, 2009). We also wanted to encourage consistent translations of words, for which we used the Q-value (Deléger et al., 2006), which has been proposed to measure term quality. We applied it on word level (QW) and phrase level (QP). These features need access to the full target document, which we have in Docent. In addition, we included two sentence-level count features for long words that have been used to measure the readability of Swedish texts (Mühlenbock and Kokkinakis, 2009). We tested our features on English–Swedish translation using the Europarl corpus. For training we used 1,488,322 sentences. As test data, we extracted 20 documents with a total of 690 sen- tences. We used the standard set of baseline features: 5-gram language model, translation model with 5 weights, a word penalty and a distortion penalty. BaselineReadability featuresComment de ärade ledamöterna (the honourableledamöterna (the members) / ni+ Removal of non-essential words Members) (you) på ett sådant sätt att (in such a way så att (so that) + Simplified expression that) gemenskapslagstiftningen (the gemenskapens lagstiftning (the + Shorter community legislation) community’s compound to genitive construction Världshandelsorganisationen (World WTO (WTO) legislation) − Changing Trade Organisation) long compound to E−nCg hliasnhg-biansged lo handlingsplanen (the action plan) ägnat särskild uppmärksamhet particular attention to) words by changing long åt (paid planen (the plan) särskilt uppmärksam − Removal på (particular attentive on) anbgb creomvipatoiounn of important word −− RBaedm grammar bpeocratuasnet wofo rcdhanged p−ar Bt aodf gspraeemcmh aarn dbe mcaisussieng o fv cehrban Table 2: Example translation snippets with comments FeatureBLEUOVIXLIX Baseline0.24356.8851.17 TTR 0.243 55.25 51.04 OVIX 0.243 54.65 51.00 QW 0.242 57.16 51.16 QP 0.243 57.07 51.06 All 0.235 47.80 49.29 Table 1: Results for adding single lexical consistency features to Docent To evaluate our system we used the BLEU score (Papineni et al., 2002) together with a set of readability metrics, since readability is what we hoped to improve by adding consistency features. Here we used OVIX to confirm a direct impact on con- sistency, and LIX (Björnsson, 1968), which is a common readability measure for Swedish. Unfortunately we do not have access to simplified translated text, so we calculate the MT metrics against a standard reference, which means that simple texts will likely have worse scores than complicated texts closer to the reference translation. We tuned the standard features using Moses and MERT, and then added each lexical consistency feature with a small weight, using a grid search approach to find values with a small impact. The results are shown in Table 1. As can be seen, for individual features the translation quality was maintained, with small improvements in LIX, and in OVIX for the TTR and OVIX features. For the combination we lost a little bit on translation quality, but there was a larger effect on the readability metrics. When we used larger weights, there was a bigger impact on the readability metrics, with a further decrease on MT quality. We also investigated what types of changes the readability features could lead to. Table 2 shows a sample of translations where the baseline is compared to systems with readability features. There are both cases where the readability features help 197 and cases where they are problematic. Overall, these examples show that our simple features can help achieve some interesting simplifications. There is still much work to do on how to take best advantage of the possibilities in Docent in order to achieve readable texts. This attempt shows the feasibility of the approach. We plan to extend this work for instance by better feature optimisation, by integrating part-of-speech tags into our features in order to focus on terms rather than common words, and by using simplified texts for evaluation and tuning. 6 Conclusions In this paper, we have presented Docent, an opensource document-level decoder for phrase-based SMT released under the GNU General Public License. Docent is the first decoder that permits the inclusion of feature models with unrestricted dependencies between arbitrary parts of the output, even crossing sentence boundaries. A number of research groups have recently started to investigate the interplay between SMT and discourse-level phenomena such as pronominal anaphora, verb tense selection and the generation of discourse connectives. We expect that the availability of a document-level decoder will make it substantially easier to leverage discourse information in SMT and make SMT models explore new ground beyond the next sentence boundary. References Carl-Hugo Björnsson. 1968. Läsbarhet. Liber, Stockholm. Marine Carpuat. 2009. One translation per discourse. In Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions (SEW-2009), pages 19–27, Boulder, Colorado. Louise Deléger, Magnus Merkel, and Pierre Zweigenbaum. 2006. Enriching medical terminologies: an approach based on aligned corpora. In International Congress of the European Federation for Medical Informatics, pages 747–752, Maastricht, The Netherlands. Zhengxian Gong, Min Zhang, Chew Lim Tan, and Guodong Zhou. 2012. N-gram-based tense models for statistical machine translation. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 276–285, Jeju Island, Korea. Liane Guillou. 2012. Improving pronoun translation for statistical machine translation. In Proceedings of the Student Research Workshop at the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 1–10, Avignon, France. Christian Hardmeier and Marcello Federico. 2010. Modelling pronominal anaphora in statistical machine translation. In Proceedings of the seventh International Workshop on Spoken Language Translation (IWSLT), pages 283–289, Paris, France. Christian Hardmeier, Joakim Nivre, and Jörg Tiedemann. 2012. Document-wide decoding for phrase-based statistical machine translation. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1179–1 190, Jeju Island, Korea. Christian Hardmeier. 2012. Discourse in statistical machine translation: A survey and a case study. Discours, 11. Kenneth Heafield. 2011. KenLM: faster and smaller language model queries. In Proceedings of the Sixth Workshop on Statistical Machine Translation, pages 187–197, Edinburgh, Scotland. Mark Hopkins and Jonathan ranking. In Proceedings on Empirical Methods in cessing, pages 1352–1362, May. 2011. Tuning as of the 2011 Conference Natural Language ProEdinburgh, Scotland. Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of the 2003 conference of the North American chapter of the Association for Computational Linguistics on Human Language Technology, pages 48–54, Edmonton. Philipp Koehn, Hieu Hoang, Alexandra Birch, et al. 2007. Moses: open source toolkit for Statistical Machine Translation. In Annual meeting of the Associationfor Computational Linguistics: Demonstration session, pages 177–180, Prague, Czech Republic. Philippe Langlais, Alexandre Patry, and Fabrizio Gotti. 2007. A greedy decoder for phrase-based statistical machine translation. In TMI-2007: Proceedings 198 of the 11th International Conference on Theoretical and Methodological Issues in Machine Translation, pages 104–1 13, Skövde, Sweden. Ronan Le Nagard and Philipp Koehn. 2010. Aiding pronoun translation with co-reference resolution. In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR, pages 252–261, Uppsala, Sweden. Thomas Meyer, Andrei Popescu-Belis, Najeh Hajlaoui, and Andrea Gesmundo. 2012. Machine translation of labeled discourse connectives. In Proceedings of the Tenth Biennial Conference of the Association for Machine Translation in the Americas (AMTA), San Diego, California, USA. Katarina Mühlenbock and Sofie Johansson Kokkinakis. 2009. LIX 68 revisited an extended readability. In Proceedings of the Corpus Linguistics Conference, Liverpool, UK. – Christoph Müller and Michael Strube. 2003. Multilevel annotation in MMAX. In Proceedings of the Fourth SIGdial Workshop on Discourse and Dialogue, pages 198–207, Sapporo, Japan. Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, pages 160–167, Sapporo, Japan. Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: A method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting ofthe Associationfor Computational Linguistics, pages 3 11–3 18, Philadelphia, Pennsylvania, USA. Sara Stymne, Christian Hardmeier, Jörg Tiedemann, and Joakim Nivre. 2013a. Feature weight optimization for discourse-level SMT. In Proceedings of the Workshop on Discourse in Machine Translation (DiscoMT), Sofia, Bulgaria. Sara Stymne, Jörg Tiedemann, Christian Hardmeier, and Joakim Nivre. 2013b. Statistical machine translation with readability constraints. In Proceedings of the 19th Nordic Conference of Computational Linguistics (NODALIDA 2013), pages 375–386, Oslo, Norway. Jörg Tiedemann. 2010. Context adaptation in statistical machine translation using models with exponentially decaying cache. In Proceedings of the ACL 2010 Workshop on Domain Adaptation for Natural Language Processing (DANLP), pages 8–15, Uppsala, Sweden. Ferhan Ture, Douglas W. Oard, and Philip Resnik. 2012. Encouraging consistent translation choices. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 417–426, Montréal, Canada.</p><p>4 0.71521568 <a title="231-lda-4" href="./acl-2013-Identifying_Bad_Semantic_Neighbors_for_Improving_Distributional_Thesauri.html">185 acl-2013-Identifying Bad Semantic Neighbors for Improving Distributional Thesauri</a></p>
<p>Author: Olivier Ferret</p><p>Abstract: Distributional thesauri are now widely used in a large number of Natural Language Processing tasks. However, they are far from containing only interesting semantic relations. As a consequence, improving such thesaurus is an important issue that is mainly tackled indirectly through the improvement of semantic similarity measures. In this article, we propose a more direct approach focusing on the identification of the neighbors of a thesaurus entry that are not semantically linked to this entry. This identification relies on a discriminative classifier trained from unsupervised selected examples for building a distributional model of the entry in texts. Its bad neighbors are found by applying this classifier to a representative set of occurrences of each of these neighbors. We evaluate the interest of this method for a large set of English nouns with various frequencies.</p><p>5 0.71429235 <a title="231-lda-5" href="./acl-2013-Text_Classification_based_on_the_Latent_Topics_of_Important_Sentences_extracted_by_the_PageRank_Algorithm.html">341 acl-2013-Text Classification based on the Latent Topics of Important Sentences extracted by the PageRank Algorithm</a></p>
<p>Author: Yukari Ogura ; Ichiro Kobayashi</p><p>Abstract: In this paper, we propose a method to raise the accuracy of text classification based on latent topics, reconsidering the techniques necessary for good classification for example, to decide important sentences in a document, the sentences with important words are usually regarded as important sentences. In this case, tf.idf is often used to decide important words. On the other hand, we apply the PageRank algorithm to rank important words in each document. Furthermore, before clustering documents, we refine the target documents by representing them as a collection of important sentences in each document. We then classify the documents based on latent information in the documents. As a clustering method, we employ the k-means algorithm and inves– tigate how our proposed method works for good clustering. We conduct experiments with Reuters-21578 corpus under various conditions of important sentence extraction, using latent and surface information for clustering, and have confirmed that our proposed method provides better result among various conditions for clustering.</p><p>6 0.7125122 <a title="231-lda-6" href="./acl-2013-The_Role_of_Syntax_in_Vector_Space_Models_of_Compositional_Semantics.html">347 acl-2013-The Role of Syntax in Vector Space Models of Compositional Semantics</a></p>
<p>7 0.71110988 <a title="231-lda-7" href="./acl-2013-Graph-based_Local_Coherence_Modeling.html">172 acl-2013-Graph-based Local Coherence Modeling</a></p>
<p>8 0.70730358 <a title="231-lda-8" href="./acl-2013-Combining_Intra-_and_Multi-sentential_Rhetorical_Parsing_for_Document-level_Discourse_Analysis.html">85 acl-2013-Combining Intra- and Multi-sentential Rhetorical Parsing for Document-level Discourse Analysis</a></p>
<p>9 0.70611674 <a title="231-lda-9" href="./acl-2013-Feature-Based_Selection_of_Dependency_Paths_in_Ad_Hoc_Information_Retrieval.html">158 acl-2013-Feature-Based Selection of Dependency Paths in Ad Hoc Information Retrieval</a></p>
<p>10 0.70102805 <a title="231-lda-10" href="./acl-2013-Crowd_Prefers_the_Middle_Path%3A_A_New_IAA_Metric_for_Crowdsourcing_Reveals_Turker_Biases_in_Query_Segmentation.html">99 acl-2013-Crowd Prefers the Middle Path: A New IAA Metric for Crowdsourcing Reveals Turker Biases in Query Segmentation</a></p>
<p>11 0.70086336 <a title="231-lda-11" href="./acl-2013-Large-scale_Semantic_Parsing_via_Schema_Matching_and_Lexicon_Extension.html">215 acl-2013-Large-scale Semantic Parsing via Schema Matching and Lexicon Extension</a></p>
<p>12 0.69995004 <a title="231-lda-12" href="./acl-2013-A_Structured_Distributional_Semantic_Model_for_Event_Co-reference.html">22 acl-2013-A Structured Distributional Semantic Model for Event Co-reference</a></p>
<p>13 0.69983447 <a title="231-lda-13" href="./acl-2013-Discovering_User_Interactions_in_Ideological_Discussions.html">121 acl-2013-Discovering User Interactions in Ideological Discussions</a></p>
<p>14 0.6991021 <a title="231-lda-14" href="./acl-2013-Measuring_semantic_content_in_distributional_vectors.html">238 acl-2013-Measuring semantic content in distributional vectors</a></p>
<p>15 0.69902891 <a title="231-lda-15" href="./acl-2013-Filling_Knowledge_Base_Gaps_for_Distant_Supervision_of_Relation_Extraction.html">159 acl-2013-Filling Knowledge Base Gaps for Distant Supervision of Relation Extraction</a></p>
<p>16 0.69874805 <a title="231-lda-16" href="./acl-2013-A_Bayesian_Model_for_Joint_Unsupervised_Induction_of_Sentiment%2C_Aspect_and_Discourse_Representations.html">2 acl-2013-A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations</a></p>
<p>17 0.69833869 <a title="231-lda-17" href="./acl-2013-Probabilistic_Domain_Modelling_With_Contextualized_Distributional_Semantic_Vectors.html">283 acl-2013-Probabilistic Domain Modelling With Contextualized Distributional Semantic Vectors</a></p>
<p>18 0.69706953 <a title="231-lda-18" href="./acl-2013-An_Infinite_Hierarchical_Bayesian_Model_of_Phrasal_Translation.html">46 acl-2013-An Infinite Hierarchical Bayesian Model of Phrasal Translation</a></p>
<p>19 0.69665891 <a title="231-lda-19" href="./acl-2013-Language_Acquisition_and_Probabilistic_Models%3A_keeping_it_simple.html">213 acl-2013-Language Acquisition and Probabilistic Models: keeping it simple</a></p>
<p>20 0.6953842 <a title="231-lda-20" href="./acl-2013-Learning_to_Order_Natural_Language_Texts.html">225 acl-2013-Learning to Order Natural Language Texts</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
