<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>43 acl-2013-Align, Disambiguate and Walk: A Unified Approach for Measuring Semantic Similarity</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-43" href="#">acl2013-43</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>43 acl-2013-Align, Disambiguate and Walk: A Unified Approach for Measuring Semantic Similarity</h1>
<br/><p>Source: <a title="acl-2013-43-pdf" href="http://aclweb.org/anthology//P/P13/P13-1132.pdf">pdf</a></p><p>Author: Mohammad Taher Pilehvar ; David Jurgens ; Roberto Navigli</p><p>Abstract: Semantic similarity is an essential component of many Natural Language Processing applications. However, prior methods for computing semantic similarity often operate at different levels, e.g., single words or entire documents, which requires adapting the method for each data type. We present a unified approach to semantic similarity that operates at multiple levels, all the way from comparing word senses to comparing text documents. Our method leverages a common probabilistic representation over word senses in order to compare different types of linguistic data. This unified representation shows state-ofthe-art performance on three tasks: seman- tic textual similarity, word similarity, and word sense coarsening.</p><p>Reference: <a title="acl-2013-43-reference" href="../acl2013_reference/acl-2013-Align%2C_Disambiguate_and_Walk%3A_A_Unified_Approach_for_Measuring_Semantic_Similarity_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 However, prior methods for computing semantic similarity often operate at different levels, e. [sent-4, score-0.374]
</p><p>2 We present a unified approach to semantic similarity that operates at multiple levels, all the way from comparing word senses to comparing text documents. [sent-7, score-0.863]
</p><p>3 Our method leverages a common probabilistic representation over word senses in order to compare different types of linguistic data. [sent-8, score-0.523]
</p><p>4 This unified representation shows state-ofthe-art performance on three tasks: seman-  tic textual similarity, word similarity, and word sense coarsening. [sent-9, score-0.55]
</p><p>5 For example, textual similarity enables relevant documents to be identified for information retrieval (Hliaoutakis et al. [sent-13, score-0.364]
</p><p>6 Approaches to semantic similarity have often operated at separate levels: methods for word similarity are rarely applied to documents or even single sentences (Budanitsky and Hirst, 2006; Radinsky et al. [sent-16, score-0.659]
</p><p>7 We propose a unified approach to semantic similarity across multiple representation levels from senses to documents, which offers two significant advantages. [sent-24, score-0.881]
</p><p>8 First, the method is applicable independently of the input type, which enables meaningful similarity comparisons across different scales of text or lexical levels. [sent-25, score-0.346]
</p><p>9 Second, by operating at the sense level, a unified approach is able to identify the semantic similarities that exist independently of the text’s lexical forms and any semantic ambiguity therein. [sent-26, score-0.655]
</p><p>10 However, a sense-based representation enables detection of the similarity between the meanings of the words, e. [sent-32, score-0.347]
</p><p>11 Second, we propose a novel alignment-based method for word sense dis1341  Proce dingsS o f ita h,e B 5u1lgsta Arinan,u Aaulg Musete 4ti-n9g 2 o0f1 t3h. [sent-38, score-0.327]
</p><p>12 Third, we demonstrate that this single representation can achieve state-of-the-art performance on three sim-  ilarity tasks, each operating at a different lexical level: (1) surpassing the highest scores on the SemEval-2012 task on textual similarity (Agirre et al. [sent-41, score-0.479]
</p><p>13 (2007) in a sensecoarsening task that measures sense similarity. [sent-43, score-0.348]
</p><p>14 2 A Unified Semantic Representation We propose a representation of any lexical item as a distribution over a set of word senses, referred to as the item’s semantic signature. [sent-44, score-0.353]
</p><p>15 We begin with a formal description of the representation at the sense level (Section 2. [sent-45, score-0.345]
</p><p>16 Following this, we describe our alignment-based disambiguation algorithm which enables us to produce sense-based semantic signatures for those lexical items (e. [sent-47, score-0.555]
</p><p>17 1 Semantic Signatures The WordNet ontology provides a rich network structure of semantic relatedness, connecting senses directly with their hypernyms, and providing information on semantically similar senses by virtue of their nearby locality in the network. [sent-56, score-0.912]
</p><p>18 Prior work has demonstrated that multinomials generated from random walks over WordNet can be successfully applied to linguistic tasks  such as word similarity (Hughes and Ramage, 2007; Agirre et al. [sent-59, score-0.36]
</p><p>19 Formally, we define the semantic signature of a lexical item as the multinomial distribution generated from the random walks over WordNet 3. [sent-62, score-0.605]
</p><p>20 0 where the set of seed nodes is the set of senses present in the item. [sent-63, score-0.393]
</p><p>21 This representation encompasses both when the item is itself a single sense and when the item is a sense-tagged sentence. [sent-64, score-0.507]
</p><p>22 Let M be the adjacency matrix for the WordNet network, where edges connect senses according to the relations defined in WordNet (e. [sent-66, score-0.393]
</p><p>23 We further enrich M by connecting a sense with all the other senses that appear in its disambiguated gloss. [sent-69, score-0.734]
</p><p>24 Given the set of  v(0)  senses S in a lexical item, the probability mass of is uniformly distributed across the senses si ∈ S, with the mass for all sj ∈/ S set to zero. [sent-71, score-0.898]
</p><p>25 The resulting probability vector is the semantic signature of the lexical item, as it has aggregated its senses’ similarities over the entire graph. [sent-78, score-0.4]
</p><p>26 For our semantic signatures we used the UKB2 off-the-shelf implementation of topicsensitive PageRank. [sent-79, score-0.381]
</p><p>27 2 Alignment-Based Disambiguation Commonly, semantic comparisons are between word pairs or sentence pairs that do not have their lexical content sense-annotated, despite the potential utility of sense annotation in making semantic comparisons. [sent-81, score-0.633]
</p><p>28 However, traditional forms of  v(t)  word sense disambiguation are difficult for short texts and single words because little or no contextual information is present to perform the disambiguation task. [sent-82, score-0.561]
</p><p>29 alignment-based sense disambiguation that leverages the content of the paired item in order to disambiguate each element. [sent-89, score-0.566]
</p><p>30 Leveraging the paired item enables our approach to disambiguate where traditional sense disambiguation methods can not due to insufficient context. [sent-90, score-0.572]
</p><p>31 Given two arbitrarily ordered texts, we seek the semantic alignment that maximizes the similarity of the senses of the context words in both texts. [sent-92, score-0.802]
</p><p>32 To find this maximum we use an alignment procedure which, for each word type wi in  item T1, assigns wi to the sense that has the maximal similarity to any sense of the word types in the compared text T2. [sent-93, score-1.018]
</p><p>33 Algorithm 1 formalizes the alignment process, which produces a sense disambiguated representation as a result. [sent-94, score-0.431]
</p><p>34 t Atios a part o,f d tehfien disambiguation procedure, we leverage the one sense per discourse heuristic of Yarowsky (1995); given all the word types in two compared lexical items, each type is assigned a single sense, even if it is used multiple times. [sent-99, score-0.498]
</p><p>35 Although such a sense assignment is potentially incorrect, assigning both types to the same sense results in a representation that does no worse than a surface-level comparison. [sent-101, score-0.635]
</p><p>36 The resulting alignment produces the following sets of senses: Pt1 = {managern1, firev4, worker1n} Pt2 = {{memapnlaogyeeren1, terminatev4, w}orkn3, bossn2} where Px denotes the corresponding set of senses of sentence x. [sent-106, score-0.428]
</p><p>37 In order to compare semantic signatures, we adopt the Cosine similarity measure as a baseline method. [sent-109, score-0.374]
</p><p>38 1343  However, a semantic signature is, in essence, a weighted ranking of the importance of WordNet senses for each lexical item. [sent-112, score-0.84]
</p><p>39 Our first measure provides a nonparametric similarity by comparing the similarity of the rankings for intersection of the senses in both semantic signatures. [sent-116, score-1.015]
</p><p>40 Let S denote the intersection of all senses with non-zero probability in both signatures and denote the rank of sense si ∈ S in signature j, where rank 1 denotes the highest rank. [sent-119, score-1.267]
</p><p>41 The sum of the two ranks ri1 and ri2 for a sense is then inverted, which (1) weights higher ranks more and (2) when summed, provides the maximal value when a sense has the same rank in both signatures. [sent-120, score-0.626]
</p><p>42 Then, to bound the similarity vPalue in [0, 1], we normalize the sum by its maximum value, (2i)−1, which occurs when each sense has thPe same rank in both signatures. [sent-122, score-0.584]
</p><p>43 Our second measure uses the ranking to identify the top-k senses in a signature, which are treated as the best representatives of the conceptual associates. [sent-124, score-0.393]
</p><p>44 Therefore, we consider the top-k senses as an unordered set, with equal importance in the signature. [sent-126, score-0.393]
</p><p>45 To compare two signatures, we compute the Jaccard Index of the two signatures’ sets:  Pi|=S|1  RJac(Uk,Vk) =||UUkk∪∩ VVkk||  (2)  where Uk denotes the set of k senses with the highest probability in the semantic signature U. [sent-127, score-0.739]
</p><p>46 3 Experiment 1: Textual Similarity Measuring semantic similarity of textual items has applications in a wide variety of NLP tasks. [sent-129, score-0.446]
</p><p>47 As our benchmark, we selected the recent SemEval2012 task on Semantic Textual Similarity (STS), which was concerned with measuring the semantic similarity of sentence pairs. [sent-130, score-0.416]
</p><p>48 The top-ranking participating systems in the SemEval-2012 task were generally supervised systems utilizing a variety of lexical resources and similarity measurement techniques. [sent-140, score-0.343]
</p><p>49 The STS task uses human similarity judgments on an ordinal scale from 0 to 5. [sent-166, score-0.319]
</p><p>50 Therefore, in ADW we adopted a similar approach to generating similarity values to that adopted by other participating systems, whereby a supervised system is trained to combine multiple similarity judgments to produce a final rating consistent with the human annotators. [sent-167, score-0.608]
</p><p>51 We used the scores calculated using all three of our semantic signature comparison methods as individual features. [sent-173, score-0.346]
</p><p>52 UKB initializes the algorithm from all senses of the words in the context of a word to be disambiguated. [sent-204, score-0.43]
</p><p>53 It then picks the most relevant sense of the word according to the resulting probability vector. [sent-205, score-0.327]
</p><p>54 As the lexical knowledge base of UKB, we used the same semantic network as that utilized by our approach for calculating semantic signatures. [sent-206, score-0.409]
</p><p>55 In addition, we present in the table correlation scores for four other similarity measures reported by B a¨r et al. [sent-208, score-0.381]
</p><p>56 (2012):  •  •  •  •  Pairwise Word Similarity that comprises of a siretw oisfe e W WoorrddN eSti-mbaislaerdit similarity measures proposed by Resnik (1995), Jiang and Conrath (1997), and Lin (1998b). [sent-209, score-0.306]
</p><p>57 The aggregation strategy proposed by Corley and Mihalcea (2005) has been utilized for extending these word-to-word similarity measures for calculating text-to-text similarities. [sent-210, score-0.409]
</p><p>58 Distributional Thesaurus where a similarity score bius computed similarly to ath satim oilfa rLitiny (1998a) using a distributional thesaurus obtained from a 10M dependency-parsed sentences of English newswire. [sent-212, score-0.327]
</p><p>59 four other similarity measures, using 10fold cross validation on the training datasets MSRpar (Mpar), MSRvid (Mvid), and SMTeuroparl (SMTe). [sent-219, score-0.307]
</p><p>60 Word similarity has been a key problem for lexical semantics, with significant efforts being made by approaches in distributional semantics to accurately identify synonymous words (Turney and Pantel, 2010). [sent-226, score-0.342]
</p><p>61 Different evaluation methods exist in the literature for evaluating the performance of a word-level semantic similarity measure; we adopted two well-established benchmarks: synonym recognition and correlating word  similarity judgments with those from human annotators. [sent-227, score-0.826]
</p><p>62 Ideally, a measure’s similarity judgments are expected to be highly correlated with those of humans. [sent-241, score-0.319]
</p><p>63 1 Experimental Setup Our alignment-based sense disambiguation transforms the task of comparing individual words into that of calculating the similarity of the bestmatching sense pair across the two words. [sent-245, score-0.995]
</p><p>64 The synonym mistakes reveal cases where senses of the two words are close in WordNet, indicating some relatedness. [sent-263, score-0.489]
</p><p>65 As can be seen from the Table, our approach with the Weighted Overlap signature comparison improves over the similar approach of Hughes and Ramage (2007) which, however, does not involve the disambiguation step and considers a word as a whole unit as represented by the set of its senses. [sent-269, score-0.374]
</p><p>66 5 Experiment 3: Sense Similarity WordNet is known to be a fine-grained sense inventory with many related word senses (Palmer et al. [sent-270, score-0.72]
</p><p>67 Accordingly, multiple approaches have attempted to identify highly similar senses in order to produce a coarse-grained sense inventory. [sent-272, score-0.683]
</p><p>68 We adopt this task as a way of evaluating our similarity measure at the sense level. [sent-273, score-0.538]
</p><p>69 1 Coarse-graining Background Earlier work on reducing the polysemy of sense  inventories has considered WordNet-based sense relatedness measures (Mihalcea and Moldovan, 2001) and corpus-based vector representations of 1347  ZAH uDpeg siWcrheoJCWsae otcOsahnl. [sent-275, score-0.718]
</p><p>70 Navigli (2006) proposed an automatic approach for mapping WordNet senses to the coarsegrained sense distinctions of the Oxford Dictio-  nary of English (ODE). [sent-280, score-0.683]
</p><p>71 The approach leverages semantic similarities in gloss definitions and the hierarchical relations between senses in the ODE to cluster WordNet senses. [sent-281, score-0.557]
</p><p>72 (2007) developed a supervised SVM classifier that utilized, as its features, several earlier sense relatedness techniques such as those implemented in the WordNet::Similarity package (Pedersen et al. [sent-283, score-0.37]
</p><p>73 The classifier also made use ofresources such as topic signatures data (Agirre and de Lacalle, 2004), the WordNet domain dataset (Magnini and Cavagli a`, 2000), and the mappings of WordNet senses to ODE senses produced by Navigli (2006). [sent-285, score-1.0]
</p><p>74 2 Experimental Setup We benchmark the accuracy of our similarity measure in grouping word senses against those of Navigli (2006) and Snow et al. [sent-287, score-0.678]
</p><p>75 (2007) on two datasets of manually-labeled sense groupings of WordNet senses: (1) sense groupings provided as a part of the Senseval-2 English Lexical Sample WSD task (Kilgarriff, 2001) which includes nouns, verbs and adjectives; (2) sense groupings included in the  OntoNotes project4 (Hovy et al. [sent-288, score-1.118]
</p><p>76 (2007) considered sense grouping as a binary classification task whereby for each word every possible pairing of senses has to be classified 4Sense groupings belong to a pre-version 1. [sent-293, score-0.783]
</p><p>77 To this end, we calculated the semantic similarity of each sense pair and then used a threshold value t to classify the pair as merged if similarity ≥ t and not-merged optahierr awsis me. [sent-308, score-0.912]
</p><p>78 Results are presented for all three of the measures of semantic signature comparison and for the three datasets: OntoNotes, Senseval-2, and  the two combined. [sent-315, score-0.404]
</p><p>79 Table 7 shows that our methodology yields improvements over previous work on both datasets and for all parts of speech, irrespective of the semantic signature comparison method used. [sent-318, score-0.405]
</p><p>80 Among the three methods, Weighted Overlap achieves the best performance, which demonstrates that our transformation of semantic signatures into ordered lists of concepts and calculating similarity by rank comparison has been helpful. [sent-319, score-0.684]
</p><p>81 Most similar to our approach are the methods of Islam and Inkpen (2008) and Corley and Mihalcea (2005), who performed a word-to-word similarity alignment; however, they did not operate at the sense level. [sent-330, score-0.538]
</p><p>82 (2009) used a similar semantic representation of short texts from random walks on WordNet, which was applied to paraphrase recognition and textual entailment. [sent-332, score-0.328]
</p><p>83 However, unlike our approach, their method does not perform sense disambiguation prior to building the representation  and therefore potentially suffers from ambiguity. [sent-333, score-0.462]
</p><p>84 A significant amount of effort has also been put into measuring similarity at the word level, frequently by approaches that use distributional semantics (Turney and Pantel, 2010). [sent-334, score-0.367]
</p><p>85 These methods use contextual features to represent semantics at the word level, whereas our approach represents word semantics at the sense level. [sent-335, score-0.364]
</p><p>86 Measures of sense relatedness have frequently leveraged the structural properties of WordNet (e. [sent-339, score-0.37]
</p><p>87 The main drawback with these approaches lies in the WordNet structure itself, where frequently two semantically sim-  ilar senses are distant in the WordNet hierarchy. [sent-343, score-0.393]
</p><p>88 Fewer works have focused on measuring the similarity as opposed to relatedness between senses. [sent-345, score-0.37]
</p><p>89 The topic signatures method of Agirre and Lopez (2003) represents each sense as a vector over corpusderived features in order to build comparable sense representations. [sent-346, score-0.794]
</p><p>90 –  –  7  Conclusions  This paper presents a unified approach for computing semantic similarity at multiple lexical levels, from word senses to texts. [sent-349, score-0.917]
</p><p>91 Our method leverages a common probabilistic representation at the sense  level for all types of linguistic data. [sent-350, score-0.383]
</p><p>92 We demonstrate that our semantic representation achieves state-of-the-art performance in three experiments using semantic similarity at different lexical levels (i. [sent-351, score-0.609]
</p><p>93 , sense, word, and text), surpassing the performance of previous similarity measures that are often specifically targeted for each level. [sent-353, score-0.356]
</p><p>94 In future work, we plan to explore the impact of the sense inventory-based network used in our semantic signatures. [sent-354, score-0.416]
</p><p>95 Specifically, we plan to investigate higher coverage inventories such as BabelNet (Navigli and Ponzetto, 2012a), which will handle texts with named entities and rare senses that are not in WordNet, and will also enable cross-lingual semantic similarity. [sent-355, score-0.519]
</p><p>96 A study on similarity and relatedness using distributional and WordNet-based approaches. [sent-371, score-0.368]
</p><p>97 UKP: Computing semantic textual similarity by combining multiple content similarity measures. [sent-384, score-0.694]
</p><p>98 Semantic text similarity using corpus-based word similarity and string similarity. [sent-500, score-0.533]
</p><p>99 Meaningful clustering of senses helps boost Word Sense Disambiguation performance. [sent-566, score-0.393]
</p><p>100 Using information content to evaluate semantic similarity in a taxonomy. [sent-600, score-0.374]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('senses', 0.393), ('sense', 0.29), ('similarity', 0.248), ('signature', 0.22), ('signatures', 0.214), ('wordnet', 0.17), ('agirre', 0.158), ('navigli', 0.153), ('msrpar', 0.127), ('semantic', 0.126), ('sts', 0.117), ('disambiguation', 0.117), ('tlsim', 0.102), ('jaccard', 0.098), ('ramage', 0.097), ('synonym', 0.096), ('toefl', 0.094), ('adw', 0.09), ('mpar', 0.082), ('item', 0.081), ('relatedness', 0.08), ('hughes', 0.079), ('ontonotes', 0.078), ('pearson', 0.077), ('correlation', 0.075), ('walks', 0.075), ('smteuroparl', 0.072), ('textual', 0.072), ('judgments', 0.071), ('snow', 0.069), ('manager', 0.069), ('roberto', 0.069), ('gabrilovich', 0.067), ('wsd', 0.063), ('groupings', 0.063), ('adwcos', 0.061), ('adwjac', 0.061), ('adwwo', 0.061), ('pilehvar', 0.061), ('taher', 0.061), ('tlsyn', 0.061), ('unified', 0.059), ('datasets', 0.059), ('measures', 0.058), ('si', 0.058), ('representation', 0.055), ('eneko', 0.055), ('msrvid', 0.054), ('onwn', 0.054), ('smtnews', 0.054), ('lexical', 0.054), ('utilized', 0.053), ('montreal', 0.053), ('walk', 0.052), ('disambiguated', 0.051), ('calculating', 0.05), ('bullinaria', 0.05), ('surpassing', 0.05), ('ukb', 0.05), ('multinomial', 0.049), ('borovets', 0.049), ('rubenstein', 0.047), ('weighted', 0.047), ('rank', 0.046), ('ari', 0.046), ('babelnet', 0.045), ('corley', 0.045), ('ode', 0.045), ('sim', 0.045), ('enables', 0.044), ('ranlp', 0.043), ('evgeniy', 0.043), ('measuring', 0.042), ('cosine', 0.042), ('allnrm', 0.041), ('elsayed', 0.041), ('halawi', 0.041), ('hliaoutakis', 0.041), ('maguitman', 0.041), ('mvid', 0.041), ('smte', 0.041), ('topicsensitive', 0.041), ('turney', 0.041), ('participating', 0.041), ('disambiguate', 0.04), ('distributional', 0.04), ('longest', 0.039), ('landauer', 0.039), ('thesaurus', 0.039), ('budanitsky', 0.039), ('salton', 0.038), ('leverages', 0.038), ('overlap', 0.038), ('word', 0.037), ('cavagli', 0.036), ('barr', 0.036), ('oier', 0.036), ('alignment', 0.035), ('spearman', 0.034), ('lopez', 0.034)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.000001 <a title="43-tfidf-1" href="./acl-2013-Align%2C_Disambiguate_and_Walk%3A_A_Unified_Approach_for_Measuring_Semantic_Similarity.html">43 acl-2013-Align, Disambiguate and Walk: A Unified Approach for Measuring Semantic Similarity</a></p>
<p>Author: Mohammad Taher Pilehvar ; David Jurgens ; Roberto Navigli</p><p>Abstract: Semantic similarity is an essential component of many Natural Language Processing applications. However, prior methods for computing semantic similarity often operate at different levels, e.g., single words or entire documents, which requires adapting the method for each data type. We present a unified approach to semantic similarity that operates at multiple levels, all the way from comparing word senses to comparing text documents. Our method leverages a common probabilistic representation over word senses in order to compare different types of linguistic data. This unified representation shows state-ofthe-art performance on three tasks: seman- tic textual similarity, word similarity, and word sense coarsening.</p><p>2 0.27855733 <a title="43-tfidf-2" href="./acl-2013-Density_Maximization_in_Context-Sense_Metric_Space_for_All-words_WSD.html">111 acl-2013-Density Maximization in Context-Sense Metric Space for All-words WSD</a></p>
<p>Author: Koichi Tanigaki ; Mitsuteru Shiba ; Tatsuji Munaka ; Yoshinori Sagisaka</p><p>Abstract: This paper proposes a novel smoothing model with a combinatorial optimization scheme for all-words word sense disambiguation from untagged corpora. By generalizing discrete senses to a continuum, we introduce a smoothing in context-sense space to cope with data-sparsity resulting from a large variety of linguistic context and sense, as well as to exploit senseinterdependency among the words in the same text string. Through the smoothing, all the optimal senses are obtained at one time under maximum marginal likelihood criterion, by competitive probabilistic kernels made to reinforce one another among nearby words, and to suppress conflicting sense hypotheses within the same word. Experimental results confirmed the superiority of the proposed method over conventional ones by showing the better performances beyond most-frequent-sense baseline performance where none of SemEval2 unsupervised systems reached.</p><p>3 0.22197095 <a title="43-tfidf-3" href="./acl-2013-Neighbors_Help%3A_Bilingual_Unsupervised_WSD_Using_Context.html">258 acl-2013-Neighbors Help: Bilingual Unsupervised WSD Using Context</a></p>
<p>Author: Sudha Bhingardive ; Samiulla Shaikh ; Pushpak Bhattacharyya</p><p>Abstract: Word Sense Disambiguation (WSD) is one of the toughest problems in NLP, and in WSD, verb disambiguation has proved to be extremely difficult, because of high degree of polysemy, too fine grained senses, absence of deep verb hierarchy and low inter annotator agreement in verb sense annotation. Unsupervised WSD has received widespread attention, but has performed poorly, specially on verbs. Recently an unsupervised bilingual EM based algorithm has been proposed, which makes use only of the raw counts of the translations in comparable corpora (Marathi and Hindi). But the performance of this approach is poor on verbs with accuracy level at 25-38%. We suggest a modifica- tion to this mentioned formulation, using context and semantic relatedness of neighboring words. An improvement of 17% 35% in the accuracy of verb WSD is obtained compared to the existing EM based approach. On a general note, the work can be looked upon as contributing to the framework of unsupervised WSD through context aware expectation maximization.</p><p>4 0.2216841 <a title="43-tfidf-4" href="./acl-2013-A_New_Set_of_Norms_for_Semantic_Relatedness_Measures.html">12 acl-2013-A New Set of Norms for Semantic Relatedness Measures</a></p>
<p>Author: Sean Szumlanski ; Fernando Gomez ; Valerie K. Sims</p><p>Abstract: We have elicited human quantitative judgments of semantic relatedness for 122 pairs of nouns and compiled them into a new set of relatedness norms that we call Rel-122. Judgments from individual subjects in our study exhibit high average correlation to the resulting relatedness means (r = 0.77, σ = 0.09, N = 73), although not as high as Resnik’s (1995) upper bound for expected average human correlation to similarity means (r = 0.90). This suggests that human perceptions of relatedness are less strictly constrained than perceptions of similarity and establishes a clearer expectation for what constitutes human-like performance by a computational measure of semantic relatedness. We compare the results of several WordNet-based similarity and relatedness measures to our Rel-122 norms and demonstrate the limitations of WordNet for discovering general indications of semantic relatedness. We also offer a critique of the field’s reliance upon similarity norms to evaluate relatedness measures.</p><p>5 0.22078435 <a title="43-tfidf-5" href="./acl-2013-FrameNet_on_the_Way_to_Babel%3A_Creating_a_Bilingual_FrameNet_Using_Wiktionary_as_Interlingual_Connection.html">162 acl-2013-FrameNet on the Way to Babel: Creating a Bilingual FrameNet Using Wiktionary as Interlingual Connection</a></p>
<p>Author: Silvana Hartmann ; Iryna Gurevych</p><p>Abstract: We present a new bilingual FrameNet lexicon for English and German. It is created through a simple, but powerful approach to construct a FrameNet in any language using Wiktionary as an interlingual representation. Our approach is based on a sense alignment of FrameNet and Wiktionary, and subsequent translation disambiguation into the target language. We perform a detailed evaluation of the created resource and a discussion of Wiktionary as an interlingual connection for the cross-language transfer of lexicalsemantic resources. The created resource is publicly available at http : / /www . ukp .tu-darmst adt .de / fnwkde / .</p><p>6 0.22055423 <a title="43-tfidf-6" href="./acl-2013-DKPro_WSD%3A_A_Generalized_UIMA-based_Framework_for_Word_Sense_Disambiguation.html">105 acl-2013-DKPro WSD: A Generalized UIMA-based Framework for Word Sense Disambiguation</a></p>
<p>7 0.19987825 <a title="43-tfidf-7" href="./acl-2013-SenseSpotting%3A_Never_let_your_parallel_data_tie_you_to_an_old_domain.html">316 acl-2013-SenseSpotting: Never let your parallel data tie you to an old domain</a></p>
<p>8 0.19526277 <a title="43-tfidf-8" href="./acl-2013-SEMILAR%3A_The_Semantic_Similarity_Toolkit.html">304 acl-2013-SEMILAR: The Semantic Similarity Toolkit</a></p>
<p>9 0.19523457 <a title="43-tfidf-9" href="./acl-2013-DKPro_Similarity%3A_An_Open_Source_Framework_for_Text_Similarity.html">104 acl-2013-DKPro Similarity: An Open Source Framework for Text Similarity</a></p>
<p>10 0.18005058 <a title="43-tfidf-10" href="./acl-2013-Detecting_Metaphor_by_Contextual_Analogy.html">116 acl-2013-Detecting Metaphor by Contextual Analogy</a></p>
<p>11 0.17618927 <a title="43-tfidf-11" href="./acl-2013-SPred%3A_Large-scale_Harvesting_of_Semantic_Predicates.html">306 acl-2013-SPred: Large-scale Harvesting of Semantic Predicates</a></p>
<p>12 0.16813271 <a title="43-tfidf-12" href="./acl-2013-Linking_and_Extending_an_Open_Multilingual_Wordnet.html">234 acl-2013-Linking and Extending an Open Multilingual Wordnet</a></p>
<p>13 0.15870254 <a title="43-tfidf-13" href="./acl-2013-Automatic_Term_Ambiguity_Detection.html">62 acl-2013-Automatic Term Ambiguity Detection</a></p>
<p>14 0.15464245 <a title="43-tfidf-14" href="./acl-2013-Understanding_Verbs_based_on_Overlapping_Verbs_Senses.html">366 acl-2013-Understanding Verbs based on Overlapping Verbs Senses</a></p>
<p>15 0.15237783 <a title="43-tfidf-15" href="./acl-2013-A_corpus-based_evaluation_method_for_Distributional_Semantic_Models.html">31 acl-2013-A corpus-based evaluation method for Distributional Semantic Models</a></p>
<p>16 0.15005606 <a title="43-tfidf-16" href="./acl-2013-Annotation_of_regular_polysemy_and_underspecification.html">53 acl-2013-Annotation of regular polysemy and underspecification</a></p>
<p>17 0.14773178 <a title="43-tfidf-17" href="./acl-2013-Learning_Semantic_Textual_Similarity_with_Structural_Representations.html">222 acl-2013-Learning Semantic Textual Similarity with Structural Representations</a></p>
<p>18 0.14302243 <a title="43-tfidf-18" href="./acl-2013-Creating_Similarity%3A_Lateral_Thinking_for_Vertical_Similarity_Judgments.html">96 acl-2013-Creating Similarity: Lateral Thinking for Vertical Similarity Judgments</a></p>
<p>19 0.13895838 <a title="43-tfidf-19" href="./acl-2013-Question_Answering_Using_Enhanced_Lexical_Semantic_Models.html">291 acl-2013-Question Answering Using Enhanced Lexical Semantic Models</a></p>
<p>20 0.13327445 <a title="43-tfidf-20" href="./acl-2013-Offspring_from_Reproduction_Problems%3A_What_Replication_Failure_Teaches_Us.html">262 acl-2013-Offspring from Reproduction Problems: What Replication Failure Teaches Us</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.27), (1, 0.114), (2, 0.084), (3, -0.275), (4, -0.062), (5, -0.228), (6, -0.215), (7, 0.094), (8, 0.023), (9, -0.065), (10, 0.018), (11, 0.155), (12, -0.102), (13, -0.118), (14, 0.247), (15, 0.078), (16, 0.064), (17, 0.097), (18, -0.07), (19, -0.009), (20, 0.036), (21, -0.033), (22, 0.008), (23, -0.043), (24, -0.083), (25, -0.041), (26, 0.057), (27, -0.032), (28, -0.019), (29, -0.072), (30, 0.038), (31, 0.03), (32, 0.068), (33, 0.029), (34, -0.014), (35, -0.112), (36, 0.031), (37, 0.037), (38, -0.027), (39, 0.028), (40, -0.018), (41, 0.007), (42, 0.0), (43, -0.008), (44, 0.053), (45, -0.017), (46, -0.023), (47, 0.001), (48, -0.084), (49, 0.038)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96956241 <a title="43-lsi-1" href="./acl-2013-Align%2C_Disambiguate_and_Walk%3A_A_Unified_Approach_for_Measuring_Semantic_Similarity.html">43 acl-2013-Align, Disambiguate and Walk: A Unified Approach for Measuring Semantic Similarity</a></p>
<p>Author: Mohammad Taher Pilehvar ; David Jurgens ; Roberto Navigli</p><p>Abstract: Semantic similarity is an essential component of many Natural Language Processing applications. However, prior methods for computing semantic similarity often operate at different levels, e.g., single words or entire documents, which requires adapting the method for each data type. We present a unified approach to semantic similarity that operates at multiple levels, all the way from comparing word senses to comparing text documents. Our method leverages a common probabilistic representation over word senses in order to compare different types of linguistic data. This unified representation shows state-ofthe-art performance on three tasks: seman- tic textual similarity, word similarity, and word sense coarsening.</p><p>2 0.8709169 <a title="43-lsi-2" href="./acl-2013-Density_Maximization_in_Context-Sense_Metric_Space_for_All-words_WSD.html">111 acl-2013-Density Maximization in Context-Sense Metric Space for All-words WSD</a></p>
<p>Author: Koichi Tanigaki ; Mitsuteru Shiba ; Tatsuji Munaka ; Yoshinori Sagisaka</p><p>Abstract: This paper proposes a novel smoothing model with a combinatorial optimization scheme for all-words word sense disambiguation from untagged corpora. By generalizing discrete senses to a continuum, we introduce a smoothing in context-sense space to cope with data-sparsity resulting from a large variety of linguistic context and sense, as well as to exploit senseinterdependency among the words in the same text string. Through the smoothing, all the optimal senses are obtained at one time under maximum marginal likelihood criterion, by competitive probabilistic kernels made to reinforce one another among nearby words, and to suppress conflicting sense hypotheses within the same word. Experimental results confirmed the superiority of the proposed method over conventional ones by showing the better performances beyond most-frequent-sense baseline performance where none of SemEval2 unsupervised systems reached.</p><p>3 0.82320297 <a title="43-lsi-3" href="./acl-2013-Neighbors_Help%3A_Bilingual_Unsupervised_WSD_Using_Context.html">258 acl-2013-Neighbors Help: Bilingual Unsupervised WSD Using Context</a></p>
<p>Author: Sudha Bhingardive ; Samiulla Shaikh ; Pushpak Bhattacharyya</p><p>Abstract: Word Sense Disambiguation (WSD) is one of the toughest problems in NLP, and in WSD, verb disambiguation has proved to be extremely difficult, because of high degree of polysemy, too fine grained senses, absence of deep verb hierarchy and low inter annotator agreement in verb sense annotation. Unsupervised WSD has received widespread attention, but has performed poorly, specially on verbs. Recently an unsupervised bilingual EM based algorithm has been proposed, which makes use only of the raw counts of the translations in comparable corpora (Marathi and Hindi). But the performance of this approach is poor on verbs with accuracy level at 25-38%. We suggest a modifica- tion to this mentioned formulation, using context and semantic relatedness of neighboring words. An improvement of 17% 35% in the accuracy of verb WSD is obtained compared to the existing EM based approach. On a general note, the work can be looked upon as contributing to the framework of unsupervised WSD through context aware expectation maximization.</p><p>4 0.82311493 <a title="43-lsi-4" href="./acl-2013-DKPro_WSD%3A_A_Generalized_UIMA-based_Framework_for_Word_Sense_Disambiguation.html">105 acl-2013-DKPro WSD: A Generalized UIMA-based Framework for Word Sense Disambiguation</a></p>
<p>Author: Tristan Miller ; Nicolai Erbs ; Hans-Peter Zorn ; Torsten Zesch ; Iryna Gurevych</p><p>Abstract: Implementations of word sense disambiguation (WSD) algorithms tend to be tied to a particular test corpus format and sense inventory. This makes it difficult to test their performance on new data sets, or to compare them against past algorithms implemented for different data sets. In this paper we present DKPro WSD, a freely licensed, general-purpose framework for WSD which is both modular and extensible. DKPro WSD abstracts the WSD process in such a way that test corpora, sense inventories, and algorithms can be freely swapped. Its UIMA-based architecture makes it easy to add support for new resources and algorithms. Related tasks such as word sense induction and entity linking are also supported.</p><p>5 0.75775027 <a title="43-lsi-5" href="./acl-2013-A_New_Set_of_Norms_for_Semantic_Relatedness_Measures.html">12 acl-2013-A New Set of Norms for Semantic Relatedness Measures</a></p>
<p>Author: Sean Szumlanski ; Fernando Gomez ; Valerie K. Sims</p><p>Abstract: We have elicited human quantitative judgments of semantic relatedness for 122 pairs of nouns and compiled them into a new set of relatedness norms that we call Rel-122. Judgments from individual subjects in our study exhibit high average correlation to the resulting relatedness means (r = 0.77, σ = 0.09, N = 73), although not as high as Resnik’s (1995) upper bound for expected average human correlation to similarity means (r = 0.90). This suggests that human perceptions of relatedness are less strictly constrained than perceptions of similarity and establishes a clearer expectation for what constitutes human-like performance by a computational measure of semantic relatedness. We compare the results of several WordNet-based similarity and relatedness measures to our Rel-122 norms and demonstrate the limitations of WordNet for discovering general indications of semantic relatedness. We also offer a critique of the field’s reliance upon similarity norms to evaluate relatedness measures.</p><p>6 0.75477332 <a title="43-lsi-6" href="./acl-2013-Linking_and_Extending_an_Open_Multilingual_Wordnet.html">234 acl-2013-Linking and Extending an Open Multilingual Wordnet</a></p>
<p>7 0.72443384 <a title="43-lsi-7" href="./acl-2013-FrameNet_on_the_Way_to_Babel%3A_Creating_a_Bilingual_FrameNet_Using_Wiktionary_as_Interlingual_Connection.html">162 acl-2013-FrameNet on the Way to Babel: Creating a Bilingual FrameNet Using Wiktionary as Interlingual Connection</a></p>
<p>8 0.72085118 <a title="43-lsi-8" href="./acl-2013-Annotation_of_regular_polysemy_and_underspecification.html">53 acl-2013-Annotation of regular polysemy and underspecification</a></p>
<p>9 0.71843398 <a title="43-lsi-9" href="./acl-2013-Creating_Similarity%3A_Lateral_Thinking_for_Vertical_Similarity_Judgments.html">96 acl-2013-Creating Similarity: Lateral Thinking for Vertical Similarity Judgments</a></p>
<p>10 0.71603447 <a title="43-lsi-10" href="./acl-2013-SEMILAR%3A_The_Semantic_Similarity_Toolkit.html">304 acl-2013-SEMILAR: The Semantic Similarity Toolkit</a></p>
<p>11 0.69221157 <a title="43-lsi-11" href="./acl-2013-Offspring_from_Reproduction_Problems%3A_What_Replication_Failure_Teaches_Us.html">262 acl-2013-Offspring from Reproduction Problems: What Replication Failure Teaches Us</a></p>
<p>12 0.68662548 <a title="43-lsi-12" href="./acl-2013-DKPro_Similarity%3A_An_Open_Source_Framework_for_Text_Similarity.html">104 acl-2013-DKPro Similarity: An Open Source Framework for Text Similarity</a></p>
<p>13 0.65928304 <a title="43-lsi-13" href="./acl-2013-Identifying_Bad_Semantic_Neighbors_for_Improving_Distributional_Thesauri.html">185 acl-2013-Identifying Bad Semantic Neighbors for Improving Distributional Thesauri</a></p>
<p>14 0.62832433 <a title="43-lsi-14" href="./acl-2013-SenseSpotting%3A_Never_let_your_parallel_data_tie_you_to_an_old_domain.html">316 acl-2013-SenseSpotting: Never let your parallel data tie you to an old domain</a></p>
<p>15 0.62612289 <a title="43-lsi-15" href="./acl-2013-Detecting_Metaphor_by_Contextual_Analogy.html">116 acl-2013-Detecting Metaphor by Contextual Analogy</a></p>
<p>16 0.62271202 <a title="43-lsi-16" href="./acl-2013-Automatic_Term_Ambiguity_Detection.html">62 acl-2013-Automatic Term Ambiguity Detection</a></p>
<p>17 0.61321533 <a title="43-lsi-17" href="./acl-2013-IndoNet%3A_A_Multilingual_Lexical_Knowledge_Network_for_Indian_Languages.html">198 acl-2013-IndoNet: A Multilingual Lexical Knowledge Network for Indian Languages</a></p>
<p>18 0.60286903 <a title="43-lsi-18" href="./acl-2013-Context_Vector_Disambiguation_for_Bilingual_Lexicon_Extraction_from_Comparable_Corpora.html">93 acl-2013-Context Vector Disambiguation for Bilingual Lexicon Extraction from Comparable Corpora</a></p>
<p>19 0.59293056 <a title="43-lsi-19" href="./acl-2013-Understanding_Verbs_based_on_Overlapping_Verbs_Senses.html">366 acl-2013-Understanding Verbs based on Overlapping Verbs Senses</a></p>
<p>20 0.58895701 <a title="43-lsi-20" href="./acl-2013-A_corpus-based_evaluation_method_for_Distributional_Semantic_Models.html">31 acl-2013-A corpus-based evaluation method for Distributional Semantic Models</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.141), (6, 0.032), (11, 0.062), (14, 0.016), (15, 0.031), (24, 0.036), (26, 0.024), (28, 0.015), (35, 0.107), (42, 0.038), (48, 0.07), (50, 0.13), (64, 0.015), (70, 0.038), (88, 0.052), (90, 0.037), (95, 0.094)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.90800649 <a title="43-lda-1" href="./acl-2013-Align%2C_Disambiguate_and_Walk%3A_A_Unified_Approach_for_Measuring_Semantic_Similarity.html">43 acl-2013-Align, Disambiguate and Walk: A Unified Approach for Measuring Semantic Similarity</a></p>
<p>Author: Mohammad Taher Pilehvar ; David Jurgens ; Roberto Navigli</p><p>Abstract: Semantic similarity is an essential component of many Natural Language Processing applications. However, prior methods for computing semantic similarity often operate at different levels, e.g., single words or entire documents, which requires adapting the method for each data type. We present a unified approach to semantic similarity that operates at multiple levels, all the way from comparing word senses to comparing text documents. Our method leverages a common probabilistic representation over word senses in order to compare different types of linguistic data. This unified representation shows state-ofthe-art performance on three tasks: seman- tic textual similarity, word similarity, and word sense coarsening.</p><p>2 0.82955235 <a title="43-lda-2" href="./acl-2013-SEMILAR%3A_The_Semantic_Similarity_Toolkit.html">304 acl-2013-SEMILAR: The Semantic Similarity Toolkit</a></p>
<p>Author: Vasile Rus ; Mihai Lintean ; Rajendra Banjade ; Nobal Niraula ; Dan Stefanescu</p><p>Abstract: We present in this paper SEMILAR, the SEMantic simILARity toolkit. SEMILAR implements a number of algorithms for assessing the semantic similarity between two texts. It is available as a Java library and as a Java standalone ap-plication offering GUI-based access to the implemented semantic similarity methods. Furthermore, it offers facilities for manual se-mantic similarity annotation by experts through its component SEMILAT (a SEMantic simILarity Annotation Tool). 1</p><p>3 0.81994295 <a title="43-lda-3" href="./acl-2013-Density_Maximization_in_Context-Sense_Metric_Space_for_All-words_WSD.html">111 acl-2013-Density Maximization in Context-Sense Metric Space for All-words WSD</a></p>
<p>Author: Koichi Tanigaki ; Mitsuteru Shiba ; Tatsuji Munaka ; Yoshinori Sagisaka</p><p>Abstract: This paper proposes a novel smoothing model with a combinatorial optimization scheme for all-words word sense disambiguation from untagged corpora. By generalizing discrete senses to a continuum, we introduce a smoothing in context-sense space to cope with data-sparsity resulting from a large variety of linguistic context and sense, as well as to exploit senseinterdependency among the words in the same text string. Through the smoothing, all the optimal senses are obtained at one time under maximum marginal likelihood criterion, by competitive probabilistic kernels made to reinforce one another among nearby words, and to suppress conflicting sense hypotheses within the same word. Experimental results confirmed the superiority of the proposed method over conventional ones by showing the better performances beyond most-frequent-sense baseline performance where none of SemEval2 unsupervised systems reached.</p><p>4 0.81894982 <a title="43-lda-4" href="./acl-2013-DKPro_WSD%3A_A_Generalized_UIMA-based_Framework_for_Word_Sense_Disambiguation.html">105 acl-2013-DKPro WSD: A Generalized UIMA-based Framework for Word Sense Disambiguation</a></p>
<p>Author: Tristan Miller ; Nicolai Erbs ; Hans-Peter Zorn ; Torsten Zesch ; Iryna Gurevych</p><p>Abstract: Implementations of word sense disambiguation (WSD) algorithms tend to be tied to a particular test corpus format and sense inventory. This makes it difficult to test their performance on new data sets, or to compare them against past algorithms implemented for different data sets. In this paper we present DKPro WSD, a freely licensed, general-purpose framework for WSD which is both modular and extensible. DKPro WSD abstracts the WSD process in such a way that test corpora, sense inventories, and algorithms can be freely swapped. Its UIMA-based architecture makes it easy to add support for new resources and algorithms. Related tasks such as word sense induction and entity linking are also supported.</p><p>5 0.81715417 <a title="43-lda-5" href="./acl-2013-A_Random_Walk_Approach_to_Selectional_Preferences_Based_on_Preference_Ranking_and_Propagation.html">17 acl-2013-A Random Walk Approach to Selectional Preferences Based on Preference Ranking and Propagation</a></p>
<p>Author: Zhenhua Tian ; Hengheng Xiang ; Ziqi Liu ; Qinghua Zheng</p><p>Abstract: This paper presents an unsupervised random walk approach to alleviate data sparsity for selectional preferences. Based on the measure of preferences between predicates and arguments, the model aggregates all the transitions from a given predicate to its nearby predicates, and propagates their argument preferences as the given predicate’s smoothed preferences. Experimental results show that this approach outperforms several state-of-the-art methods on the pseudo-disambiguation task, and it better correlates with human plausibility judgements.</p><p>6 0.81486654 <a title="43-lda-6" href="./acl-2013-Collective_Annotation_of_Linguistic_Resources%3A_Basic_Principles_and_a_Formal_Model.html">83 acl-2013-Collective Annotation of Linguistic Resources: Basic Principles and a Formal Model</a></p>
<p>7 0.81405318 <a title="43-lda-7" href="./acl-2013-Recognizing_Partial_Textual_Entailment.html">297 acl-2013-Recognizing Partial Textual Entailment</a></p>
<p>8 0.81333339 <a title="43-lda-8" href="./acl-2013-Text_Classification_from_Positive_and_Unlabeled_Data_using_Misclassified_Data_Correction.html">342 acl-2013-Text Classification from Positive and Unlabeled Data using Misclassified Data Correction</a></p>
<p>9 0.81155562 <a title="43-lda-9" href="./acl-2013-Scalable_Decipherment_for_Machine_Translation_via_Hash_Sampling.html">307 acl-2013-Scalable Decipherment for Machine Translation via Hash Sampling</a></p>
<p>10 0.81148654 <a title="43-lda-10" href="./acl-2013-Creating_Similarity%3A_Lateral_Thinking_for_Vertical_Similarity_Judgments.html">96 acl-2013-Creating Similarity: Lateral Thinking for Vertical Similarity Judgments</a></p>
<p>11 0.81098211 <a title="43-lda-11" href="./acl-2013-Margin-based_Decomposed_Amortized_Inference.html">237 acl-2013-Margin-based Decomposed Amortized Inference</a></p>
<p>12 0.80945355 <a title="43-lda-12" href="./acl-2013-Probabilistic_Sense_Sentiment_Similarity_through_Hidden_Emotions.html">284 acl-2013-Probabilistic Sense Sentiment Similarity through Hidden Emotions</a></p>
<p>13 0.80746377 <a title="43-lda-13" href="./acl-2013-Offspring_from_Reproduction_Problems%3A_What_Replication_Failure_Teaches_Us.html">262 acl-2013-Offspring from Reproduction Problems: What Replication Failure Teaches Us</a></p>
<p>14 0.80525076 <a title="43-lda-14" href="./acl-2013-Multimodal_DBN_for_Predicting_High-Quality_Answers_in_cQA_portals.html">254 acl-2013-Multimodal DBN for Predicting High-Quality Answers in cQA portals</a></p>
<p>15 0.80315322 <a title="43-lda-15" href="./acl-2013-Improved_Bayesian_Logistic_Supervised_Topic_Models_with_Data_Augmentation.html">191 acl-2013-Improved Bayesian Logistic Supervised Topic Models with Data Augmentation</a></p>
<p>16 0.80203086 <a title="43-lda-16" href="./acl-2013-PARMA%3A_A_Predicate_Argument_Aligner.html">267 acl-2013-PARMA: A Predicate Argument Aligner</a></p>
<p>17 0.80174035 <a title="43-lda-17" href="./acl-2013-Question_Answering_Using_Enhanced_Lexical_Semantic_Models.html">291 acl-2013-Question Answering Using Enhanced Lexical Semantic Models</a></p>
<p>18 0.79591835 <a title="43-lda-18" href="./acl-2013-Identifying_Bad_Semantic_Neighbors_for_Improving_Distributional_Thesauri.html">185 acl-2013-Identifying Bad Semantic Neighbors for Improving Distributional Thesauri</a></p>
<p>19 0.7933352 <a title="43-lda-19" href="./acl-2013-Large-scale_Semantic_Parsing_via_Schema_Matching_and_Lexicon_Extension.html">215 acl-2013-Large-scale Semantic Parsing via Schema Matching and Lexicon Extension</a></p>
<p>20 0.79269135 <a title="43-lda-20" href="./acl-2013-Stop-probability_estimates_computed_on_a_large_corpus_improve_Unsupervised_Dependency_Parsing.html">331 acl-2013-Stop-probability estimates computed on a large corpus improve Unsupervised Dependency Parsing</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
