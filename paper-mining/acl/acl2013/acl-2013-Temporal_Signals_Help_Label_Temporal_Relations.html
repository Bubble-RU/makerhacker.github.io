<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>339 acl-2013-Temporal Signals Help Label Temporal Relations</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-339" href="#">acl2013-339</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>339 acl-2013-Temporal Signals Help Label Temporal Relations</h1>
<br/><p>Source: <a title="acl-2013-339-pdf" href="http://aclweb.org/anthology//P/P13/P13-2114.pdf">pdf</a></p><p>Author: Leon Derczynski ; Robert Gaizauskas</p><p>Abstract: Automatically determining the temporal order of events and times in a text is difficult, though humans can readily perform this task. Sometimes events and times are related through use of an explicit co-ordination which gives information about the temporal relation: expressions like “before ” and “as soon as”. We investigate the r oˆle that these co-ordinating temporal signals have in determining the type of temporal relations in discourse. Using machine learning, we improve upon prior approaches to the problem, achieving over 80% accuracy at labelling the types of temporal relation between events and times that are related by temporal signals.</p><p>Reference: <a title="acl-2013-339-reference" href="../acl2013_reference/acl-2013-Temporal_Signals_Help_Label_Temporal_Relations_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 uk  Abstract Automatically determining the temporal order of events and times in a text is difficult, though humans can readily perform this task. [sent-4, score-0.825]
</p><p>2 Sometimes events and times are related through use of an explicit co-ordination which gives information about the temporal relation: expressions like “before ” and “as soon as”. [sent-5, score-0.78]
</p><p>3 We investigate the r oˆle that these co-ordinating temporal signals have in determining the type of temporal relations in discourse. [sent-6, score-1.645]
</p><p>4 Using machine learning, we improve upon prior approaches to the problem, achieving over 80% accuracy at labelling the types of temporal relation between events and times that are related by temporal signals. [sent-7, score-1.579]
</p><p>5 When we automatically extract temporal information, we are often concerned with events and times referred to collectively as temporal intervals. [sent-10, score-1.416]
</p><p>6 ” In order to extract an answer to this question from a document collection, we need to identify events related to persons becoming president and the times of those events. [sent-13, score-0.148]
</p><p>7 Crucially, however, we also need to identify the temporal relations between these events and times, perhaps, for example, by recognizing a temporal relation type from a set such as that of Allen (1983). [sent-14, score-1.606]
</p><p>8 This last task, temporal relation typing, is challenging, and is the focus of this paper. [sent-15, score-0.76]
</p><p>9 words act as discourse contain temporal ordering information that human readers can readily access, and indeed this hypothesis is borne out empirically (Bestgen and Vonk, 1999). [sent-16, score-0.723]
</p><p>10 In this paper, we present an in-depth examination into the role temporal signals can play in machine learning for temporal relation typing, within the framework of TimeML (Pustejovsky et al. [sent-17, score-1.631]
</p><p>11 –  2  Related Work  Temporal relation typing is not a new problem. [sent-19, score-0.447]
</p><p>12 The TempEval challenge series features relation typing as a key task (Verhagen et al. [sent-23, score-0.476]
</p><p>13 The take-home message from all this work is that temporal relation typing is a hard problem, even using advanced techniques and extensive engineering approaches rarely achieve over 60% on typing relations between two events or over 75% accuracy for those between an event and a time. [sent-25, score-1.645]
</p><p>14 Although we focus solely on determining the types of temporal relations, one must also identify which pairs of temporal intervals should be temporally related. [sent-31, score-1.337]
</p><p>15 Previous work has covered the tasks of identifying and typing temporal relations jointly with some success (Denis and Muller, 2011; Do et al. [sent-32, score-1.07]
</p><p>16 Investigations into using signals for temporal relation typing have had promising results. [sent-36, score-1.318]
</p><p>17 Lapata and Lascarides (2006) learn temporal structure according –  to these explicit signals, then predict temporal order-  ltprdbeiamsfTocerhdnmuatpsirdeowamhictxlopesrkdimghcnetpbasolyirhtmwaoerstncigowh-tanelr. [sent-37, score-1.264]
</p><p>18 c A2s0s1o3ci Aatsiosonc fioartio Cno fmorpu Ctoamtiopnuatalt Lioinngauli Lsitnicgsu,i psatgices 645–650, Event-event relationsEvent-time relations Non-signalled Signalled Overall Non-signalled Signalled Overall Baseline most-common-class41. [sent-43, score-0.119]
</p><p>19 5% 2 828  typing performance using the base feature set, for relations with and without a temporal signal. [sent-61, score-1.173]
</p><p>20 The system achieves a 22% error reduction on a simplified set of temporal relation types. [sent-63, score-0.82]
</p><p>21 Later, Derczynski and Gaizauskas (2010) saw a 50% error reduction in assignment of relation types on signalled relation instances from introducing simple features describing a temporal signal’s interaction with the events or times that it co-ordinates. [sent-64, score-1.257]
</p><p>22 The features for describing signals included the signal text itself and the signal’s position in the document relative to the intervals it co-ordinated. [sent-65, score-0.668]
</p><p>23 This led to a large increase in relation typing accuracy to 82. [sent-66, score-0.447]
</p><p>24 19% for signalled eventevent relations, using a maximum entropy classifier. [sent-67, score-0.255]
</p><p>25 Previous work has attempted to linguistically characterise temporal signals (Br e´e et al. [sent-68, score-0.871]
</p><p>26 Signal phrases typically fall  into one of three categories: monosemous as temporal signals (e. [sent-70, score-0.871]
</p><p>27 “during”, “when”); bisemous as temporal or spatial signals (e. [sent-72, score-0.871]
</p><p>28 “before ”); or polysemous with the temporal sense a minority class (e. [sent-74, score-0.632]
</p><p>29 Further, a signal phrase may take two arguments, though its arguments need not be in the immediate content and may be anaphoric. [sent-77, score-0.406]
</p><p>30 We leave the task of automatic signal annotation to future work, instead focusing on the impact that signals have on temporal relation typing. [sent-78, score-1.377]
</p><p>31 3  Experimental Setup  We only approach the relation typing task, and we use existing signal annotations that is, we do not attempt to automatically identify temporal signals. [sent-80, score-1.429]
</p><p>32 This corpus, TBsig,1 adds extra events, times and relations to TimeBank, in an effort to correct signal under-annotation in the original corpus (Derczynski and Gaizauskas, 2011). [sent-83, score-0.502]
</p><p>33 In these, we are interested only in the temporal relations that use a signal. [sent-85, score-0.751]
</p><p>34 There are 851 signals annotated in the corpus, co-ordinating 886 temporal re1See http://derczynski. [sent-86, score-0.871]
</p><p>35 For comparison, TimeBank has 688 signal annotations which co-ordinate 718 temporal relations (11. [sent-91, score-1.101]
</p><p>36 There are only 14 signalled time-time relations in this corpus, which is not enough to support any generalizations, and so we disregard this interval type pairing. [sent-94, score-0.304]
</p><p>37 As is common with statistical approaches to temporal relation typing, we also perform relation folding; that is, to reduce the number of possible classes, we sometimes invert argument order and relation type. [sent-95, score-1.058]
</p><p>38 For example, A BEFORE B and B AFTER A convey the same temporal relation, and so we can remove all AFTER-type relations by swapping their argument order and converting them to BEFORE relations. [sent-96, score-0.793]
</p><p>39 (2007)), and the text order of argument intervals (as in Hepple et al. [sent-104, score-0.092]
</p><p>40 –  Signal Ordering Textual ordering is important Swiigthn temporal signals; compare “rYinogu iswa imlkp pboerftoarnet you run” and “Before you walk you run”. [sent-106, score-0.694]
</p><p>41 We –  add features accounting for relative textual position of signal and arguments as per Derczynski and Gaizauskas (2010). [sent-107, score-0.411]
</p><p>42 To these we add a feature reporting whether the signal occurs in first, last, or mid-sentence position, and features to indicate whether each interval is in the same sentence as the signal. [sent-108, score-0.487]
</p><p>43 –  Collectively, these feature groups comprise the All feature set. [sent-130, score-0.104]
</p><p>44 This set contains the base and the signal ordering feature groups only, plus a single signal feature for the signal raw string. [sent-132, score-1.281]
</p><p>45 , 2003), maximum entropy (Daum ´e III, 2008), adaptive boosting (Freund and Schapire, 1997; Zhu et al. [sent-134, score-0.117]
</p><p>46 We use two baselines: most-common-class and a model trained with no signal features. [sent-137, score-0.35]
</p><p>47 Classifiers were evaluated by determining if the class they output matched the relation type in TB-sig. [sent-139, score-0.151]
</p><p>48 for both signalled and non-signalled temporal relation instances, we list performance with  a maximum entropy classifier and the base feature set 2With nestimators = 200, a minimum of one sample per node, and no maximum depth. [sent-143, score-1.136]
</p><p>49 Figure 1: Effect of training data size on relation typing performance. [sent-144, score-0.447]
</p><p>50 These are split into those that use a signal and those that do not, though no features relaying signal information are included. [sent-147, score-0.753]
</p><p>51 In order to assess the adequacy of the dataset in terms of size, we also examined performance using a maximum entropy classifier learned from varying subproportions of the training data. [sent-148, score-0.097]
</p><p>52 4  Analysis  The results in Table 2 echo earlier findings and intuition: temporal signals are useful in temporal relation typing. [sent-152, score-1.651]
</p><p>53 Results support that signals are not only helpful in event-event relation typing but also event-time typing. [sent-153, score-0.686]
</p><p>54 For comparison, inter-annotator agreement across all temporal relation labels, i. [sent-154, score-0.76]
</p><p>55 9% absolute performance increase over the DG2010 feature set for event-event relations (10. [sent-158, score-0.175]
</p><p>56 2% Table 3: Relation typing accuracy based on various feature combinations, using random forests. [sent-192, score-0.377]
</p><p>57 offer better performance under both feature sets, with the extended features achieving notable error reduction over DG2010 17. [sent-194, score-0.165]
</p><p>58 Linear support vector classification provided rapid labelling and comparable performance for event-event relations but was accuracy was not as good as random forests for event-time relation labelling. [sent-197, score-0.34]
</p><p>59 Note, figures reported earlier in Derczynski and Gaizauskas (2010) are not directly comparable to the DG2010 figures reported here, as here we are using the better-annotated TB-sig corpus, which contains a larger and more varied set of temporal signal annotations. [sent-198, score-1.054]
</p><p>60 7% of temporal relations that are co-ordinated with a signal, it is important to note the performance of conventional classification approaches on this subset of temporal relations. [sent-200, score-1.383]
</p><p>61 Specifically, the error reduction relative to the baseline that is achieved without signal features is much lower on relations that use signals than on nonsignalled relations (Table 1). [sent-201, score-0.954]
</p><p>62 Thus, temporal relations that use a signal appear to be more difficult to classify than other relations, unless signal information is present in the features. [sent-202, score-1.451]
</p><p>63 This may be due to differences in how signals are used by authors. [sent-203, score-0.239]
</p><p>64 One explanation is that signals may be used in the stead of temporal ordering information in surrounding discourse, such as modulations of dominant tense or aspect (Derczynski and Gaizauskas, 2013). [sent-204, score-0.985]
</p><p>65 Unlike earlier work using maxent, we experiment with a variety of classifiers, and find a consistent improvement in temporal relation typing using signal features. [sent-205, score-1.449]
</p><p>66 With the notable exception of adaptive boosting, classifiers with preference bias (Liu et al. [sent-206, score-0.069]
</p><p>67 We also investigated the impact of each feature group on the best-performing classifier (random forests with n = 200) through feature ablation. [sent-223, score-0.171]
</p><p>68 Ablation suggested that the signal text features (signal string, lower case string, head word and lemma) had most impact in event-event relation typing, though were second to syntax features in event-time relations. [sent-225, score-0.618]
</p><p>69 Removing other feature groups gave only minor performance decreases. [sent-226, score-0.098]
</p><p>70 We also experimented with adding feature groups to the base set one-by-one. [sent-227, score-0.131]
</p><p>71 All but DCT features gave above-baseline improvement, though argument ordering features were not very helpful for event-event relation typing. [sent-228, score-0.346]
</p><p>72 Signal text features gave the strongest improvement over baseline for event-event relations, but syntax gave a larger improvement for event-time relations. [sent-229, score-0.123]
</p><p>73 Accordingly, it may be useful to distinguish  between event-event and event-time relations when extracting temporal information using syntax (c. [sent-230, score-0.781]
</p><p>74 A strong above-baseline performance was still obtained even when signal text features were removed, which included the signal text itself. [sent-234, score-0.729]
</p><p>75 This was interesting, as signal phrases can indicate quite different temporal orderings (e. [sent-235, score-1.001]
</p><p>76 “Open the box before it rains ”, and the words used are typically critical to correct interpretation of the temporal relation. [sent-238, score-0.681]
</p><p>77 Further, the model is able to generalise beyond particular signal phrase choices. [sent-239, score-0.35]
</p><p>78 In this case, removing the syntactic features had the greatest (negative) impact on performance, though the absolute impact on event-event relations (a drop of 11. [sent-241, score-0.246]
</p><p>79 3%) was far lower than that on event-time relations (3. [sent-242, score-0.119]
</p><p>80 To examine helpful features, we trained a maxent classifier on the entire dataset and collected feature:value pairs. [sent-244, score-0.068]
</p><p>81 The ten largest-weighted pairings for eventevent relations (the hardest problem in overall temporal relation typing) are given in Table 5. [sent-246, score-0.917]
</p><p>82 It can be seen that BEGINS and INCLUDES relationships are not indicated if the arguments have no TimeML aspect assigned; this is what one might expect, given how aspect is used in English, with these temporal relation types corresponding to event starts and the progressive. [sent-260, score-0.871]
</p><p>83 Also, notice how a particular syntactic path, connecting adjacent nominalised event and the word in acting as a signal, indicate a temporal inclusion relationship. [sent-261, score-0.684]
</p><p>84 Temporal polysemy, where a word  has more than one possible temporal interpretation, is also observable here (Derczynski and Gaizauskas (201 1) examine this polysemy in depth). [sent-262, score-0.652]
</p><p>85 This is visible in how the temporal signal phrase “before ” is not, as one might expect, a strong indicator of a BEFORE or even AFTER relation, but of an ENDS relationship. [sent-263, score-0.982]
</p><p>86 5  Conclusion  This paper set out to investigate the r oˆle of temporal signals in predicting the type of temporal relation between two intervals. [sent-264, score-1.631]
</p><p>87 The paper demonstrated the utility of temporal signals in this task, and identified approaches for using the information these signals contain, which performed consistently better than the stateof-the-art across a range of machine learning classifiers. [sent-265, score-1.11]
</p><p>88 Further, it identified the impact that signal text, signal order and syntax features had in temporal relation typing of signalled relations. [sent-266, score-2.018]
</p><p>89 Firstly, the utility of signals prompts investigation into detecting which words in a given text occur as temporal signals. [sent-268, score-0.871]
</p><p>90 Secondly, it is intuitive that temporal signals explicitly indicate related pairs of intervals (i. [sent-269, score-0.94]
</p><p>91 So, the task of deciding which interval pair(s) a temporal signal co-ordinates must be approached. [sent-272, score-1.015]
</p><p>92 Although we have found a method for achieving  good temporal relation typing performance on a subset of temporal relations, the greater problem of general temporal relation typing remains. [sent-273, score-2.811]
</p><p>93 A better understanding of the semantics of events, times, signals and how they are related together through syntax may provide further insights into the temporal relation typing task. [sent-274, score-1.348]
</p><p>94 (2007) reached high temporal relation typing performance on one a subset ofrelations (events and times in the same sentence); we reach high temporal relation typing performance on another subset of relations those using a temporal signal. [sent-276, score-2.942]
</p><p>95 Identifying further explicit sources of temporal information applicable to new sets of relations may reveal promising paths for investigation. [sent-277, score-0.768]
</p><p>96 Towards a formalization of the semantics of some temporal prepositions. [sent-322, score-0.632]
</p><p>97 Predicting globallycoherent temporal structures from texts via endpoint inference and graph decomposition. [sent-360, score-0.632]
</p><p>98 LCC-TE: A hybrid approach to temporal relation identification in news text. [sent-450, score-0.76]
</p><p>99 TimeML: Robust specification of event and temporal expressions in text. [sent-494, score-0.685]
</p><p>100 Kernel based discourse relation recognition with temporal ordering information. [sent-544, score-0.851]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('temporal', 0.632), ('signal', 0.35), ('typing', 0.319), ('derczynski', 0.246), ('signals', 0.239), ('gaizauskas', 0.16), ('signalled', 0.152), ('relation', 0.128), ('relations', 0.119), ('timeml', 0.108), ('timebank', 0.102), ('events', 0.095), ('pustejovsky', 0.074), ('verhagen', 0.067), ('base', 0.065), ('ordering', 0.062), ('mani', 0.055), ('llorens', 0.05), ('begins', 0.05), ('intervals', 0.05), ('hepple', 0.046), ('dct', 0.046), ('setzer', 0.046), ('dagstuhl', 0.044), ('argument', 0.042), ('entropy', 0.041), ('reduction', 0.04), ('bestgen', 0.038), ('blaheta', 0.038), ('boguraev', 0.038), ('eventevent', 0.038), ('eventtime', 0.038), ('mirroshandel', 0.038), ('nonsignalled', 0.038), ('rennie', 0.038), ('svc', 0.038), ('swampillai', 0.038), ('labelling', 0.038), ('feature', 0.038), ('ends', 0.037), ('maxent', 0.036), ('forests', 0.035), ('yoshikawa', 0.033), ('tempeval', 0.033), ('times', 0.033), ('interval', 0.033), ('event', 0.033), ('classifier', 0.032), ('gave', 0.032), ('arguments', 0.032), ('bayes', 0.031), ('rains', 0.031), ('uzzaman', 0.031), ('syntax', 0.03), ('discourse', 0.029), ('boosting', 0.029), ('schilder', 0.029), ('denis', 0.029), ('features', 0.029), ('tense', 0.029), ('classifiers', 0.029), ('none', 0.028), ('pedregosa', 0.028), ('impact', 0.028), ('groups', 0.028), ('bethard', 0.027), ('br', 0.027), ('figures', 0.026), ('freund', 0.026), ('allen', 0.026), ('though', 0.024), ('maximum', 0.024), ('collectively', 0.024), ('aspect', 0.023), ('sheffield', 0.023), ('multiclass', 0.023), ('adaptive', 0.023), ('determining', 0.023), ('ve', 0.022), ('ablation', 0.022), ('na', 0.021), ('katz', 0.021), ('achieving', 0.021), ('string', 0.02), ('random', 0.02), ('president', 0.02), ('polysemy', 0.02), ('earlier', 0.02), ('error', 0.02), ('expressions', 0.02), ('chambers', 0.019), ('indicate', 0.019), ('crammer', 0.019), ('daum', 0.019), ('reporting', 0.018), ('absolute', 0.018), ('box', 0.018), ('uk', 0.018), ('paths', 0.017), ('notable', 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000011 <a title="339-tfidf-1" href="./acl-2013-Temporal_Signals_Help_Label_Temporal_Relations.html">339 acl-2013-Temporal Signals Help Label Temporal Relations</a></p>
<p>Author: Leon Derczynski ; Robert Gaizauskas</p><p>Abstract: Automatically determining the temporal order of events and times in a text is difficult, though humans can readily perform this task. Sometimes events and times are related through use of an explicit co-ordination which gives information about the temporal relation: expressions like “before ” and “as soon as”. We investigate the r oˆle that these co-ordinating temporal signals have in determining the type of temporal relations in discourse. Using machine learning, we improve upon prior approaches to the problem, achieving over 80% accuracy at labelling the types of temporal relation between events and times that are related by temporal signals.</p><p>2 0.31396756 <a title="339-tfidf-2" href="./acl-2013-Language-Independent_Discriminative_Parsing_of_Temporal_Expressions.html">212 acl-2013-Language-Independent Discriminative Parsing of Temporal Expressions</a></p>
<p>Author: Gabor Angeli ; Jakob Uszkoreit</p><p>Abstract: Temporal resolution systems are traditionally tuned to a particular language, requiring significant human effort to translate them to new languages. We present a language independent semantic parser for learning the interpretation of temporal phrases given only a corpus of utterances and the times they reference. We make use of a latent parse that encodes a language-flexible representation of time, and extract rich features over both the parse and associated temporal semantics. The parameters of the model are learned using a weakly supervised bootstrapping approach, without the need for manually tuned parameters or any other language expertise. We achieve state-of-the-art accuracy on all languages in the TempEval2 temporal normalization task, reporting a 4% improvement in both English and Spanish accuracy, and to our knowledge the first results for four other languages.</p><p>3 0.30083472 <a title="339-tfidf-3" href="./acl-2013-Extracting_Events_with_Informal_Temporal_References_in_Personal_Histories_in_Online_Communities.html">153 acl-2013-Extracting Events with Informal Temporal References in Personal Histories in Online Communities</a></p>
<p>Author: Miaomiao Wen ; Zeyu Zheng ; Hyeju Jang ; Guang Xiang ; Carolyn Penstein Rose</p><p>Abstract: We present a system for extracting the dates of illness events (year and month of the event occurrence) from posting histories in the context of an online medical support community. A temporal tagger retrieves and normalizes dates mentioned informally in social media to actual month and year referents. Building on this, an event date extraction system learns to integrate the likelihood of candidate dates extracted from time-rich sentences with temporal constraints extracted from eventrelated sentences. Our integrated model achieves 89.7% of the maximum performance given the performance of the temporal expression retrieval step.</p><p>4 0.16006757 <a title="339-tfidf-4" href="./acl-2013-Recognizing_Identical_Events_with_Graph_Kernels.html">296 acl-2013-Recognizing Identical Events with Graph Kernels</a></p>
<p>Author: Goran Glavas ; Jan Snajder</p><p>Abstract: Identifying news stories that discuss the same real-world events is important for news tracking and retrieval. Most existing approaches rely on the traditional vector space model. We propose an approach for recognizing identical real-world events based on a structured, event-oriented document representation. We structure documents as graphs of event mentions and use graph kernels to measure the similarity between document pairs. Our experiments indicate that the proposed graph-based approach can outperform the traditional vector space model, and is especially suitable for distinguishing between topically similar, yet non-identical events.</p><p>5 0.15335751 <a title="339-tfidf-5" href="./acl-2013-Enriching_Entity_Translation_Discovery_using_Selective_Temporality.html">138 acl-2013-Enriching Entity Translation Discovery using Selective Temporality</a></p>
<p>Author: Gae-won You ; Young-rok Cha ; Jinhan Kim ; Seung-won Hwang</p><p>Abstract: This paper studies named entity translation and proposes “selective temporality” as a new feature, as using temporal features may be harmful for translating “atemporal” entities. Our key contribution is building an automatic classifier to distinguish temporal and atemporal entities then align them in separate procedures to boost translation accuracy by 6. 1%.</p><p>6 0.11816476 <a title="339-tfidf-6" href="./acl-2013-FudanNLP%3A_A_Toolkit_for_Chinese_Natural_Language_Processing.html">164 acl-2013-FudanNLP: A Toolkit for Chinese Natural Language Processing</a></p>
<p>7 0.086519003 <a title="339-tfidf-7" href="./acl-2013-Aggregated_Word_Pair_Features_for_Implicit_Discourse_Relation_Disambiguation.html">41 acl-2013-Aggregated Word Pair Features for Implicit Discourse Relation Disambiguation</a></p>
<p>8 0.077766091 <a title="339-tfidf-8" href="./acl-2013-Resolving_Entity_Morphs_in_Censored_Data.html">301 acl-2013-Resolving Entity Morphs in Censored Data</a></p>
<p>9 0.075521268 <a title="339-tfidf-9" href="./acl-2013-Argument_Inference_from_Relevant_Event_Mentions_in_Chinese_Argument_Extraction.html">56 acl-2013-Argument Inference from Relevant Event Mentions in Chinese Argument Extraction</a></p>
<p>10 0.075424604 <a title="339-tfidf-10" href="./acl-2013-Leveraging_Synthetic_Discourse_Data_via_Multi-task_Learning_for_Implicit_Discourse_Relation_Recognition.html">229 acl-2013-Leveraging Synthetic Discourse Data via Multi-task Learning for Implicit Discourse Relation Recognition</a></p>
<p>11 0.0744766 <a title="339-tfidf-11" href="./acl-2013-Learning_to_Extract_International_Relations_from_Political_Context.html">224 acl-2013-Learning to Extract International Relations from Political Context</a></p>
<p>12 0.069816746 <a title="339-tfidf-12" href="./acl-2013-Automatic_Interpretation_of_the_English_Possessive.html">61 acl-2013-Automatic Interpretation of the English Possessive</a></p>
<p>13 0.066503577 <a title="339-tfidf-13" href="./acl-2013-A_Bayesian_Model_for_Joint_Unsupervised_Induction_of_Sentiment%2C_Aspect_and_Discourse_Representations.html">2 acl-2013-A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations</a></p>
<p>14 0.064651124 <a title="339-tfidf-14" href="./acl-2013-Fine-grained_Semantic_Typing_of_Emerging_Entities.html">160 acl-2013-Fine-grained Semantic Typing of Emerging Entities</a></p>
<p>15 0.061632689 <a title="339-tfidf-15" href="./acl-2013-Modeling_Human_Inference_Process_for_Textual_Entailment_Recognition.html">245 acl-2013-Modeling Human Inference Process for Textual Entailment Recognition</a></p>
<p>16 0.058299173 <a title="339-tfidf-16" href="./acl-2013-Learning_to_Order_Natural_Language_Texts.html">225 acl-2013-Learning to Order Natural Language Texts</a></p>
<p>17 0.057698902 <a title="339-tfidf-17" href="./acl-2013-Filling_Knowledge_Base_Gaps_for_Distant_Supervision_of_Relation_Extraction.html">159 acl-2013-Filling Knowledge Base Gaps for Distant Supervision of Relation Extraction</a></p>
<p>18 0.057074562 <a title="339-tfidf-18" href="./acl-2013-Mining_Equivalent_Relations_from_Linked_Data.html">242 acl-2013-Mining Equivalent Relations from Linked Data</a></p>
<p>19 0.054404289 <a title="339-tfidf-19" href="./acl-2013-What_causes_a_causal_relation%3F_Detecting_Causal_Triggers_in_Biomedical_Scientific_Discourse.html">386 acl-2013-What causes a causal relation? Detecting Causal Triggers in Biomedical Scientific Discourse</a></p>
<p>20 0.054378893 <a title="339-tfidf-20" href="./acl-2013-Generating_Synthetic_Comparable_Questions_for_News_Articles.html">169 acl-2013-Generating Synthetic Comparable Questions for News Articles</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.133), (1, 0.057), (2, -0.054), (3, -0.073), (4, 0.026), (5, 0.195), (6, 0.021), (7, 0.08), (8, 0.014), (9, 0.08), (10, 0.025), (11, -0.038), (12, -0.017), (13, 0.015), (14, -0.011), (15, -0.087), (16, -0.005), (17, -0.051), (18, -0.036), (19, -0.074), (20, 0.09), (21, -0.188), (22, 0.098), (23, 0.088), (24, -0.069), (25, -0.007), (26, -0.11), (27, -0.027), (28, -0.262), (29, -0.048), (30, 0.032), (31, 0.062), (32, 0.146), (33, -0.126), (34, 0.2), (35, -0.138), (36, -0.07), (37, -0.073), (38, -0.003), (39, 0.023), (40, -0.15), (41, -0.07), (42, -0.002), (43, 0.047), (44, 0.069), (45, 0.03), (46, 0.061), (47, -0.025), (48, 0.022), (49, -0.072)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96622223 <a title="339-lsi-1" href="./acl-2013-Temporal_Signals_Help_Label_Temporal_Relations.html">339 acl-2013-Temporal Signals Help Label Temporal Relations</a></p>
<p>Author: Leon Derczynski ; Robert Gaizauskas</p><p>Abstract: Automatically determining the temporal order of events and times in a text is difficult, though humans can readily perform this task. Sometimes events and times are related through use of an explicit co-ordination which gives information about the temporal relation: expressions like “before ” and “as soon as”. We investigate the r oˆle that these co-ordinating temporal signals have in determining the type of temporal relations in discourse. Using machine learning, we improve upon prior approaches to the problem, achieving over 80% accuracy at labelling the types of temporal relation between events and times that are related by temporal signals.</p><p>2 0.83545542 <a title="339-lsi-2" href="./acl-2013-Language-Independent_Discriminative_Parsing_of_Temporal_Expressions.html">212 acl-2013-Language-Independent Discriminative Parsing of Temporal Expressions</a></p>
<p>Author: Gabor Angeli ; Jakob Uszkoreit</p><p>Abstract: Temporal resolution systems are traditionally tuned to a particular language, requiring significant human effort to translate them to new languages. We present a language independent semantic parser for learning the interpretation of temporal phrases given only a corpus of utterances and the times they reference. We make use of a latent parse that encodes a language-flexible representation of time, and extract rich features over both the parse and associated temporal semantics. The parameters of the model are learned using a weakly supervised bootstrapping approach, without the need for manually tuned parameters or any other language expertise. We achieve state-of-the-art accuracy on all languages in the TempEval2 temporal normalization task, reporting a 4% improvement in both English and Spanish accuracy, and to our knowledge the first results for four other languages.</p><p>3 0.83452481 <a title="339-lsi-3" href="./acl-2013-Extracting_Events_with_Informal_Temporal_References_in_Personal_Histories_in_Online_Communities.html">153 acl-2013-Extracting Events with Informal Temporal References in Personal Histories in Online Communities</a></p>
<p>Author: Miaomiao Wen ; Zeyu Zheng ; Hyeju Jang ; Guang Xiang ; Carolyn Penstein Rose</p><p>Abstract: We present a system for extracting the dates of illness events (year and month of the event occurrence) from posting histories in the context of an online medical support community. A temporal tagger retrieves and normalizes dates mentioned informally in social media to actual month and year referents. Building on this, an event date extraction system learns to integrate the likelihood of candidate dates extracted from time-rich sentences with temporal constraints extracted from eventrelated sentences. Our integrated model achieves 89.7% of the maximum performance given the performance of the temporal expression retrieval step.</p><p>4 0.56228232 <a title="339-lsi-4" href="./acl-2013-Enriching_Entity_Translation_Discovery_using_Selective_Temporality.html">138 acl-2013-Enriching Entity Translation Discovery using Selective Temporality</a></p>
<p>Author: Gae-won You ; Young-rok Cha ; Jinhan Kim ; Seung-won Hwang</p><p>Abstract: This paper studies named entity translation and proposes “selective temporality” as a new feature, as using temporal features may be harmful for translating “atemporal” entities. Our key contribution is building an automatic classifier to distinguish temporal and atemporal entities then align them in separate procedures to boost translation accuracy by 6. 1%.</p><p>5 0.56188357 <a title="339-lsi-5" href="./acl-2013-Recognizing_Identical_Events_with_Graph_Kernels.html">296 acl-2013-Recognizing Identical Events with Graph Kernels</a></p>
<p>Author: Goran Glavas ; Jan Snajder</p><p>Abstract: Identifying news stories that discuss the same real-world events is important for news tracking and retrieval. Most existing approaches rely on the traditional vector space model. We propose an approach for recognizing identical real-world events based on a structured, event-oriented document representation. We structure documents as graphs of event mentions and use graph kernels to measure the similarity between document pairs. Our experiments indicate that the proposed graph-based approach can outperform the traditional vector space model, and is especially suitable for distinguishing between topically similar, yet non-identical events.</p><p>6 0.41480818 <a title="339-lsi-6" href="./acl-2013-Learning_to_Extract_International_Relations_from_Political_Context.html">224 acl-2013-Learning to Extract International Relations from Political Context</a></p>
<p>7 0.40570593 <a title="339-lsi-7" href="./acl-2013-Automatic_Interpretation_of_the_English_Possessive.html">61 acl-2013-Automatic Interpretation of the English Possessive</a></p>
<p>8 0.37495404 <a title="339-lsi-8" href="./acl-2013-Resolving_Entity_Morphs_in_Censored_Data.html">301 acl-2013-Resolving Entity Morphs in Censored Data</a></p>
<p>9 0.37132585 <a title="339-lsi-9" href="./acl-2013-Semantic_Neighborhoods_as_Hypergraphs.html">311 acl-2013-Semantic Neighborhoods as Hypergraphs</a></p>
<p>10 0.37112659 <a title="339-lsi-10" href="./acl-2013-Fluid_Construction_Grammar_for_Historical_and_Evolutionary_Linguistics.html">161 acl-2013-Fluid Construction Grammar for Historical and Evolutionary Linguistics</a></p>
<p>11 0.35936016 <a title="339-lsi-11" href="./acl-2013-Mining_Equivalent_Relations_from_Linked_Data.html">242 acl-2013-Mining Equivalent Relations from Linked Data</a></p>
<p>12 0.35524923 <a title="339-lsi-12" href="./acl-2013-Grounded_Language_Learning_from_Video_Described_with_Sentences.html">175 acl-2013-Grounded Language Learning from Video Described with Sentences</a></p>
<p>13 0.35442227 <a title="339-lsi-13" href="./acl-2013-Aggregated_Word_Pair_Features_for_Implicit_Discourse_Relation_Disambiguation.html">41 acl-2013-Aggregated Word Pair Features for Implicit Discourse Relation Disambiguation</a></p>
<p>14 0.35244352 <a title="339-lsi-14" href="./acl-2013-Modeling_Human_Inference_Process_for_Textual_Entailment_Recognition.html">245 acl-2013-Modeling Human Inference Process for Textual Entailment Recognition</a></p>
<p>15 0.34808356 <a title="339-lsi-15" href="./acl-2013-Argument_Inference_from_Relevant_Event_Mentions_in_Chinese_Argument_Extraction.html">56 acl-2013-Argument Inference from Relevant Event Mentions in Chinese Argument Extraction</a></p>
<p>16 0.34425125 <a title="339-lsi-16" href="./acl-2013-Building_Japanese_Textual_Entailment_Specialized_Data_Sets_for_Inference_of_Basic_Sentence_Relations.html">75 acl-2013-Building Japanese Textual Entailment Specialized Data Sets for Inference of Basic Sentence Relations</a></p>
<p>17 0.31550556 <a title="339-lsi-17" href="./acl-2013-Adapting_Discriminative_Reranking_to_Grounded_Language_Learning.html">36 acl-2013-Adapting Discriminative Reranking to Grounded Language Learning</a></p>
<p>18 0.31087062 <a title="339-lsi-18" href="./acl-2013-Plurality%2C_Negation%2C_and_Quantification%3ATowards_Comprehensive_Quantifier_Scope_Disambiguation.html">280 acl-2013-Plurality, Negation, and Quantification:Towards Comprehensive Quantifier Scope Disambiguation</a></p>
<p>19 0.30930719 <a title="339-lsi-19" href="./acl-2013-Is_a_204_cm_Man_Tall_or_Small_%3F_Acquisition_of_Numerical_Common_Sense_from_the_Web.html">202 acl-2013-Is a 204 cm Man Tall or Small ? Acquisition of Numerical Common Sense from the Web</a></p>
<p>20 0.30388027 <a title="339-lsi-20" href="./acl-2013-HEADY%3A_News_headline_abstraction_through_event_pattern_clustering.html">178 acl-2013-HEADY: News headline abstraction through event pattern clustering</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.049), (6, 0.039), (7, 0.02), (11, 0.085), (15, 0.012), (24, 0.046), (26, 0.041), (35, 0.053), (42, 0.044), (48, 0.027), (52, 0.287), (70, 0.104), (88, 0.027), (90, 0.024), (95, 0.048)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.83594722 <a title="339-lda-1" href="./acl-2013-Fluid_Construction_Grammar_for_Historical_and_Evolutionary_Linguistics.html">161 acl-2013-Fluid Construction Grammar for Historical and Evolutionary Linguistics</a></p>
<p>Author: Pieter Wellens ; Remi van Trijp ; Katrien Beuls ; Luc Steels</p><p>Abstract: Fluid Construction Grammar (FCG) is an open-source computational grammar formalism that is becoming increasingly popular for studying the history and evolution of language. This demonstration shows how FCG can be used to operationalise the cultural processes and cognitive mechanisms that underly language evolution and change.</p><p>same-paper 2 0.76304162 <a title="339-lda-2" href="./acl-2013-Temporal_Signals_Help_Label_Temporal_Relations.html">339 acl-2013-Temporal Signals Help Label Temporal Relations</a></p>
<p>Author: Leon Derczynski ; Robert Gaizauskas</p><p>Abstract: Automatically determining the temporal order of events and times in a text is difficult, though humans can readily perform this task. Sometimes events and times are related through use of an explicit co-ordination which gives information about the temporal relation: expressions like “before ” and “as soon as”. We investigate the r oˆle that these co-ordinating temporal signals have in determining the type of temporal relations in discourse. Using machine learning, we improve upon prior approaches to the problem, achieving over 80% accuracy at labelling the types of temporal relation between events and times that are related by temporal signals.</p><p>3 0.63052678 <a title="339-lda-3" href="./acl-2013-Categorization_of_Turkish_News_Documents_with_Morphological_Analysis.html">78 acl-2013-Categorization of Turkish News Documents with Morphological Analysis</a></p>
<p>Author: Burak Kerim AkkuÅ� ; Ruket Cakici</p><p>Abstract: Morphologically rich languages such as Turkish may benefit from morphological analysis in natural language tasks. In this study, we examine the effects of morphological analysis on text categorization task in Turkish. We use stems and word categories that are extracted with morphological analysis as main features and compare them with fixed length stemmers in a bag of words approach with several learning algorithms. We aim to show the effects of using varying degrees of morphological information.</p><p>4 0.60153359 <a title="339-lda-4" href="./acl-2013-Derivational_Smoothing_for_Syntactic_Distributional_Semantics.html">113 acl-2013-Derivational Smoothing for Syntactic Distributional Semantics</a></p>
<p>Author: Sebastian Pado ; Jan Snajder ; Britta Zeller</p><p>Abstract: Syntax-based vector spaces are used widely in lexical semantics and are more versatile than word-based spaces (Baroni and Lenci, 2010). However, they are also sparse, with resulting reliability and coverage problems. We address this problem by derivational smoothing, which uses knowledge about derivationally related words (oldish → old) to improve semantic similarity est→imates. We develop a set of derivational smoothing methods and evaluate them on two lexical semantics tasks in German. Even for models built from very large corpora, simple derivational smoothing can improve coverage considerably.</p><p>5 0.51232028 <a title="339-lda-5" href="./acl-2013-Extracting_Events_with_Informal_Temporal_References_in_Personal_Histories_in_Online_Communities.html">153 acl-2013-Extracting Events with Informal Temporal References in Personal Histories in Online Communities</a></p>
<p>Author: Miaomiao Wen ; Zeyu Zheng ; Hyeju Jang ; Guang Xiang ; Carolyn Penstein Rose</p><p>Abstract: We present a system for extracting the dates of illness events (year and month of the event occurrence) from posting histories in the context of an online medical support community. A temporal tagger retrieves and normalizes dates mentioned informally in social media to actual month and year referents. Building on this, an event date extraction system learns to integrate the likelihood of candidate dates extracted from time-rich sentences with temporal constraints extracted from eventrelated sentences. Our integrated model achieves 89.7% of the maximum performance given the performance of the temporal expression retrieval step.</p><p>6 0.50675917 <a title="339-lda-6" href="./acl-2013-Generating_Synthetic_Comparable_Questions_for_News_Articles.html">169 acl-2013-Generating Synthetic Comparable Questions for News Articles</a></p>
<p>7 0.50640643 <a title="339-lda-7" href="./acl-2013-Parsing_Graphs_with_Hyperedge_Replacement_Grammars.html">274 acl-2013-Parsing Graphs with Hyperedge Replacement Grammars</a></p>
<p>8 0.50618064 <a title="339-lda-8" href="./acl-2013-Transfer_Learning_Based_Cross-lingual_Knowledge_Extraction_for_Wikipedia.html">356 acl-2013-Transfer Learning Based Cross-lingual Knowledge Extraction for Wikipedia</a></p>
<p>9 0.50140423 <a title="339-lda-9" href="./acl-2013-Fast_and_Accurate_Shift-Reduce_Constituent_Parsing.html">155 acl-2013-Fast and Accurate Shift-Reduce Constituent Parsing</a></p>
<p>10 0.50041449 <a title="339-lda-10" href="./acl-2013-DErivBase%3A_Inducing_and_Evaluating_a_Derivational_Morphology_Resource_for_German.html">102 acl-2013-DErivBase: Inducing and Evaluating a Derivational Morphology Resource for German</a></p>
<p>11 0.49803397 <a title="339-lda-11" href="./acl-2013-Chinese_Parsing_Exploiting_Characters.html">80 acl-2013-Chinese Parsing Exploiting Characters</a></p>
<p>12 0.49600595 <a title="339-lda-12" href="./acl-2013-Learning_Latent_Personas_of_Film_Characters.html">220 acl-2013-Learning Latent Personas of Film Characters</a></p>
<p>13 0.49345908 <a title="339-lda-13" href="./acl-2013-Recognizing_Identical_Events_with_Graph_Kernels.html">296 acl-2013-Recognizing Identical Events with Graph Kernels</a></p>
<p>14 0.49301919 <a title="339-lda-14" href="./acl-2013-Easy-First_POS_Tagging_and_Dependency_Parsing_with_Beam_Search.html">132 acl-2013-Easy-First POS Tagging and Dependency Parsing with Beam Search</a></p>
<p>15 0.49256942 <a title="339-lda-15" href="./acl-2013-The_effect_of_non-tightness_on_Bayesian_estimation_of_PCFGs.html">348 acl-2013-The effect of non-tightness on Bayesian estimation of PCFGs</a></p>
<p>16 0.49087638 <a title="339-lda-16" href="./acl-2013-Paraphrase-Driven_Learning_for_Open_Question_Answering.html">272 acl-2013-Paraphrase-Driven Learning for Open Question Answering</a></p>
<p>17 0.4898279 <a title="339-lda-17" href="./acl-2013-Models_of_Semantic_Representation_with_Visual_Attributes.html">249 acl-2013-Models of Semantic Representation with Visual Attributes</a></p>
<p>18 0.48888016 <a title="339-lda-18" href="./acl-2013-The_Impact_of_Topic_Bias_on_Quality_Flaw_Prediction_in_Wikipedia.html">346 acl-2013-The Impact of Topic Bias on Quality Flaw Prediction in Wikipedia</a></p>
<p>19 0.48875964 <a title="339-lda-19" href="./acl-2013-Combining_Intra-_and_Multi-sentential_Rhetorical_Parsing_for_Document-level_Discourse_Analysis.html">85 acl-2013-Combining Intra- and Multi-sentential Rhetorical Parsing for Document-level Discourse Analysis</a></p>
<p>20 0.48816639 <a title="339-lda-20" href="./acl-2013-Statistical_Machine_Translation_Improves_Question_Retrieval_in_Community_Question_Answering_via_Matrix_Factorization.html">329 acl-2013-Statistical Machine Translation Improves Question Retrieval in Community Question Answering via Matrix Factorization</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
