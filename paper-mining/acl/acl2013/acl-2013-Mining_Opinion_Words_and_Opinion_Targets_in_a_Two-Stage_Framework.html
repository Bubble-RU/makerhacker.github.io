<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>244 acl-2013-Mining Opinion Words and Opinion Targets in a Two-Stage Framework</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-244" href="#">acl2013-244</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>244 acl-2013-Mining Opinion Words and Opinion Targets in a Two-Stage Framework</h1>
<br/><p>Source: <a title="acl-2013-244-pdf" href="http://aclweb.org/anthology//P/P13/P13-1173.pdf">pdf</a></p><p>Author: Liheng Xu ; Kang Liu ; Siwei Lai ; Yubo Chen ; Jun Zhao</p><p>Abstract: This paper proposes a novel two-stage method for mining opinion words and opinion targets. In the first stage, we propose a Sentiment Graph Walking algorithm, which naturally incorporates syntactic patterns in a Sentiment Graph to extract opinion word/target candidates. Then random walking is employed to estimate confidence of candidates, which improves extraction accuracy by considering confidence of patterns. In the second stage, we adopt a self-learning strategy to refine the results from the first stage, especially for filtering out high-frequency noise terms and capturing the long-tail terms, which are not investigated by previous methods. The experimental results on three real world datasets demonstrate the effectiveness of our approach compared with stateof-the-art unsupervised methods.</p><p>Reference: <a title="acl-2013-244-reference" href="../acl2013_reference/acl-2013-Mining_Opinion_Words_and_Opinion_Targets_in_a_Two-Stage_Framework_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Mining Opinion Words and Opinion Targets in a Two-Stage Framework Liheng Xu, Kang Liu, Siwei Lai, Yubo Chen and Jun Zhao National Laboratory of Pattern Recognition Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China {lhxu , kl iu, swlai , ybchen , j zhao} @ nlpr . [sent-1, score-0.024]
</p><p>2 cn  Abstract This paper proposes a novel two-stage method for mining opinion words and opinion targets. [sent-4, score-1.745]
</p><p>3 In the first stage, we propose a Sentiment Graph Walking algorithm, which naturally incorporates syntactic patterns in a Sentiment Graph to extract opinion word/target candidates. [sent-5, score-1.097]
</p><p>4 Then random walking is employed to estimate confidence of candidates, which improves extraction accuracy by considering confidence of patterns. [sent-6, score-0.394]
</p><p>5 In the second stage, we adopt a self-learning strategy to refine the results from the first stage, especially for filtering out high-frequency noise terms and capturing the long-tail terms, which are not investigated by previous methods. [sent-7, score-0.129]
</p><p>6 1 Introduction Opinion mining not only assists users to make informed purchase decisions, but also helps business organizations understand and act upon customer feedbacks on their products or services in real-time. [sent-9, score-0.172]
</p><p>7 Extracting opinion words and opinion targets are two key tasks in opinion mining. [sent-10, score-2.713]
</p><p>8 Opinion words refer to those terms indicating positive or negative sentiment. [sent-11, score-0.024]
</p><p>9 Opinion targets represent aspects or attributes of objects toward which opinions are expressed. [sent-12, score-0.226]
</p><p>10 Mining these terms from reviews of a specific domain allows a more thorough understanding of customers’ opinions. [sent-13, score-0.09]
</p><p>11 Opinion words and opinion targets often cooccur in reviews and there exist modified relations (called opinion relation in this paper) between them. [sent-14, score-2.005]
</p><p>12 For example, in the sentence “It has a clear screen”, “clear” is an opinion word and “screen” is an opinion target, and there is an opinion relation  between the two words. [sent-15, score-2.513]
</p><p>13 It is natural to identify such opinion relations through common syntactic patterns (also called opinion patterns in this paper) between opinion words and targets. [sent-16, score-2.843]
</p><p>14 For example, we can extract “clear” and “screen” by using a syntactic pattern “Adj-{mod}-Noun”, which captures tthacet opinion nre “lAatdioj-n{ m boedtw}e-Neno utnh”em, w. [sent-17, score-1.049]
</p><p>15 Aiclhthough previous works have shown the effectiveness of syntactic patterns for this task (Qiu et al. [sent-18, score-0.199]
</p><p>16 False Opinion Relations: As an example, the phrase “everyday at school” can be matched by a pattern “Adj-{mod}-(Prep)-{pcomp-n}-Noun”, bau pt ait t derones “nA’td bj-e{amr any s(Penretipm)-e{nptc oormiepn-tna}t-ioNno. [sent-21, score-0.184]
</p><p>17 Wn”e, call such relations that match opinion patterns but express no opinion false opinion relations. [sent-22, score-2.771]
</p><p>18 However, some high-frequency syntactic patterns can have very poor precision (Kessler and Nicolov, 2009). [sent-26, score-0.167]
</p><p>19 False Opinion Targets: In another case, the phrase “wonderful time” can be matched by an opinion pattern “Adj-{mod}-Noun”, which is widely iuosned p iantt previous {wmoorkds} (Popescu ahnidc hE it-s zioni, 2005; Qiu et al. [sent-27, score-0.949]
</p><p>20 As can be seen, this phrase does express a positive opinion but unfortunately “time” is not a valid opinion target for most domains such as MP3. [sent-29, score-1.698]
</p><p>21 Due to the lack of ground-truth knowledge for opinion targets, non-target terms introduced in this way can be hardly filtered out. [sent-31, score-0.874]
</p><p>22 Long-tail Opinion Targets: We further notice that previous works prone to extract opinion targets with high frequency (Hu and Liu, 2004; Popescu and Etzioni, 2005; Qiu et al. [sent-32, score-1.134]
</p><p>23 , 2009), and they often have difficulty in identifying the infrequent or long-tail opinion targets. [sent-34, score-0.854]
</p><p>24 Ac s2s0o1ci3a Atiosnso fcoirat Cio nm foprut Caotimonpaulta Lti nognuails Lti cnsg,u piasgteics 1764–17 3, To address the problems stated above, this paper proposes a two-stage framework for mining opinion words and opinion targets. [sent-37, score-1.745]
</p><p>25 The under-  lying motivation is analogous to the novel idea “Mine the Easy, Classify the Hard” (Dasgupta and Ng, 2009). [sent-38, score-0.029]
</p><p>26 In our first stage, we propose a Sentiment Graph Walking algorithm to cope with the false opinion relation problem, which mines easy cases of opinion words/targets. [sent-39, score-1.813]
</p><p>27 We speculate that it may be helpful to introduce a confidence score for each pattern. [sent-40, score-0.125]
</p><p>28 Concretely, we create a Sentiment Graph to model opinion relations among opinion word/target/pattern candidates and apply random walking to estimate confidence of them. [sent-41, score-2.064]
</p><p>29 Thus, confidence of pattern is considered in a unified process. [sent-42, score-0.195]
</p><p>30 Patterns that often extract false opinion relations will have low confidence, and terms introduced by low-confidence patterns will also have low confidence accordingly. [sent-43, score-1.265]
</p><p>31 In the second stage, we identify the hard cases, which aims to filter out false opinion targets and extract long-tail opinion targets. [sent-45, score-2.032]
</p><p>32 Previous supervised methods have been shown to achieve stateof-the-art results for this task (Wu et al. [sent-46, score-0.037]
</p><p>33 However, the big  challenge for fully supervised method is the lack of annotated training data. [sent-49, score-0.057]
</p><p>34 Specifically, we employ a semi-supervised classifier to refine the target results from the first stage, which uses some highly confident target candidates as the initial labeled examples. [sent-51, score-0.166]
</p><p>35 Our main contributions are as follows: • We propose a Sentiment Graph Walking algorithm otos em ain See opinion Gworardpsh a Wnadl opinion targets from reviews, which naturally incorporates confidence of syntactic pattern in a graph to improve extraction performance. [sent-53, score-2.301]
</p><p>36 To our best knowledge, the incorporation of pattern confidence in such a Sentiment Graph has never been studied before for opinion words/targets mining task (Section 3). [sent-54, score-1.106]
</p><p>37 • We adopt a self-learning method for refining opinion words/targets generated by oSre rnetfiimnienngt Graph Walking. [sent-55, score-0.891]
</p><p>38 Specifically, it can remove high-frequency noise terms and capture longtail opinion targets in corpora (Section 4). [sent-56, score-1.103]
</p><p>39 2  Related Work  In opinion words/targets mining task, most unsupervised methods rely on identifying opinion relations between opinion words and opinion targets. [sent-58, score-3.421]
</p><p>40 Hu and Liu (2004) proposed an association mining technique to extract opinion words/targets. [sent-59, score-0.935]
</p><p>41 The simple heuristic rules they used may potentially introduce many false opinion words/targets. [sent-60, score-0.973]
</p><p>42 To identify opinion relations more precisely, subsequent research work exploited syntax information. [sent-61, score-0.875]
</p><p>43 Popescu and Etzioni (2005) used manually complied syntactic patterns and Pointwise Mutual Information (PMI) to extract opinion words/targets. [sent-62, score-1.043]
</p><p>44 (2009) proposed a bootstrapping framework called Double Propagation which introduced eight heuristic syntactic rules. [sent-64, score-0.126]
</p><p>45 While manually defining syntactic patterns could be timeconsuming and error-prone, we learn syntactic patterns automatically from data. [sent-65, score-0.361]
</p><p>46 There have been extensive works on mining opinion words and opinion targets by syntactic pattern learning. [sent-66, score-2.119]
</p><p>47 Riloff and Wiebe (2003) performed pattern learning through bootstrapping while extracting subjective expressions. [sent-67, score-0.122]
</p><p>48 (2006) obtained various dependency relationship templates from an annotated movie corpus and applied them to supervised opinion words/targets extraction. [sent-69, score-0.886]
</p><p>49 (2007) adopted a supervised learning technique to search for useful syntactic patterns as contextual clues. [sent-71, score-0.204]
</p><p>50 , 2013), all of which apply syntactic pattern learning and adopt self-learning strategy. [sent-73, score-0.186]
</p><p>51 However, the task of (Wiebe and Riloff, 2005) was to classify sentiment orientations in sentence level, while ours needs to extract more detailed information in term level. [sent-74, score-0.203]
</p><p>52 There were also many works employed graphbased method (Li et al. [sent-77, score-0.052]
</p><p>53 , 2012), but none of previous works considered confidence of patterns in the graph. [sent-80, score-0.25]
</p><p>54 In supervised approaches, various kinds of models were applied, such as HMM (Jin and Ho, 2009), SVM (Wu et al. [sent-81, score-0.037]
</p><p>55 The downside of supervised methods was the difficulty of obtaining annotated training data in practical applications. [sent-84, score-0.106]
</p><p>56 Also, classifiers trained 1765  on one domain often fail to give satisfactory results when shifted to another domain. [sent-85, score-0.048]
</p><p>57 Our method does not rely on annotated training data. [sent-86, score-0.02]
</p><p>58 3  The First Stage: Sentiment Graph Walking Algorithm  In the first stage, we propose a graph-based algorithm called Sentiment Graph Walking to mine opinion words and opinion targets from reviews. [sent-87, score-1.947]
</p><p>59 , 2009), we regard all adjectives as opinion word candidates (OC) and all nouns or noun phrases as opinion target candidates (TC). [sent-91, score-1.812]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('opinion', 0.829), ('targets', 0.226), ('walking', 0.192), ('qiu', 0.122), ('patterns', 0.117), ('sentiment', 0.108), ('stage', 0.101), ('confidence', 0.101), ('false', 0.101), ('pattern', 0.094), ('popescu', 0.084), ('graph', 0.074), ('screen', 0.071), ('mod', 0.067), ('candidates', 0.067), ('zhuang', 0.061), ('mining', 0.059), ('riloff', 0.057), ('etzioni', 0.053), ('wiebe', 0.052), ('syntactic', 0.05), ('kessler', 0.049), ('extract', 0.047), ('relations', 0.046), ('nicolov', 0.046), ('hu', 0.044), ('adopt', 0.042), ('reviews', 0.042), ('xu', 0.041), ('refine', 0.039), ('jin', 0.038), ('ho', 0.038), ('liu', 0.038), ('mine', 0.037), ('supervised', 0.037), ('assists', 0.033), ('cooccur', 0.033), ('wildcards', 0.033), ('bau', 0.033), ('feedbacks', 0.033), ('lhxu', 0.033), ('liheng', 0.033), ('works', 0.032), ('mines', 0.031), ('ait', 0.031), ('jijkoun', 0.031), ('incorporates', 0.03), ('everyday', 0.029), ('lying', 0.029), ('wonderful', 0.029), ('nre', 0.029), ('kobayashi', 0.029), ('bootstrapping', 0.028), ('proposes', 0.028), ('zhao', 0.027), ('timeconsuming', 0.027), ('lai', 0.026), ('matched', 0.026), ('called', 0.026), ('clear', 0.026), ('amr', 0.025), ('purchase', 0.025), ('orientations', 0.025), ('difficulty', 0.025), ('zhu', 0.025), ('nlpr', 0.024), ('concretely', 0.024), ('customers', 0.024), ('thorough', 0.024), ('downside', 0.024), ('dasgupta', 0.024), ('satisfactory', 0.024), ('naturally', 0.024), ('terms', 0.024), ('shifted', 0.024), ('speculate', 0.024), ('noise', 0.024), ('incorporation', 0.023), ('prep', 0.023), ('oc', 0.023), ('cope', 0.023), ('classify', 0.023), ('kang', 0.022), ('heuristic', 0.022), ('em', 0.022), ('wu', 0.022), ('ain', 0.022), ('organizations', 0.022), ('hardly', 0.021), ('potentially', 0.021), ('automation', 0.021), ('td', 0.021), ('target', 0.02), ('lti', 0.02), ('graphbased', 0.02), ('iu', 0.02), ('confident', 0.02), ('express', 0.02), ('annotated', 0.02), ('refining', 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000008 <a title="244-tfidf-1" href="./acl-2013-Mining_Opinion_Words_and_Opinion_Targets_in_a_Two-Stage_Framework.html">244 acl-2013-Mining Opinion Words and Opinion Targets in a Two-Stage Framework</a></p>
<p>Author: Liheng Xu ; Kang Liu ; Siwei Lai ; Yubo Chen ; Jun Zhao</p><p>Abstract: This paper proposes a novel two-stage method for mining opinion words and opinion targets. In the first stage, we propose a Sentiment Graph Walking algorithm, which naturally incorporates syntactic patterns in a Sentiment Graph to extract opinion word/target candidates. Then random walking is employed to estimate confidence of candidates, which improves extraction accuracy by considering confidence of patterns. In the second stage, we adopt a self-learning strategy to refine the results from the first stage, especially for filtering out high-frequency noise terms and capturing the long-tail terms, which are not investigated by previous methods. The experimental results on three real world datasets demonstrate the effectiveness of our approach compared with stateof-the-art unsupervised methods.</p><p>2 0.76747078 <a title="244-tfidf-2" href="./acl-2013-Joint_Inference_for_Fine-grained_Opinion_Extraction.html">207 acl-2013-Joint Inference for Fine-grained Opinion Extraction</a></p>
<p>Author: Bishan Yang ; Claire Cardie</p><p>Abstract: This paper addresses the task of finegrained opinion extraction the identification of opinion-related entities: the opinion expressions, the opinion holders, and the targets of the opinions, and the relations between opinion expressions and their targets and holders. Most existing approaches tackle the extraction of opinion entities and opinion relations in a pipelined manner, where the interdependencies among different extraction stages are not captured. We propose a joint inference model that leverages knowledge from predictors that optimize subtasks – of opinion extraction, and seeks a globally optimal solution. Experimental results demonstrate that our joint inference approach significantly outperforms traditional pipeline methods and baselines that tackle subtasks in isolation for the problem of opinion extraction.</p><p>3 0.7619673 <a title="244-tfidf-3" href="./acl-2013-Syntactic_Patterns_versus_Word_Alignment%3A_Extracting_Opinion_Targets_from_Online_Reviews.html">336 acl-2013-Syntactic Patterns versus Word Alignment: Extracting Opinion Targets from Online Reviews</a></p>
<p>Author: Kang Liu ; Liheng Xu ; Jun Zhao</p><p>Abstract: Mining opinion targets is a fundamental and important task for opinion mining from online reviews. To this end, there are usually two kinds of methods: syntax based and alignment based methods. Syntax based methods usually exploited syntactic patterns to extract opinion targets, which were however prone to suffer from parsing errors when dealing with online informal texts. In contrast, alignment based methods used word alignment model to fulfill this task, which could avoid parsing errors without using parsing. However, there is no research focusing on which kind of method is more better when given a certain amount of reviews. To fill this gap, this paper empiri- cally studies how the performance of these two kinds of methods vary when changing the size, domain and language of the corpus. We further combine syntactic patterns with alignment model by using a partially supervised framework and investigate whether this combination is useful or not. In our experiments, we verify that our combination is effective on the corpus with small and medium size.</p><p>4 0.40791661 <a title="244-tfidf-4" href="./acl-2013-Identifying_Opinion_Subgroups_in_Arabic_Online_Discussions.html">187 acl-2013-Identifying Opinion Subgroups in Arabic Online Discussions</a></p>
<p>Author: Amjad Abu-Jbara ; Ben King ; Mona Diab ; Dragomir Radev</p><p>Abstract: In this paper, we use Arabic natural language processing techniques to analyze Arabic debates. The goal is to identify how the participants in a discussion split into subgroups with contrasting opinions. The members of each subgroup share the same opinion with respect to the discussion topic and an opposing opinion to the members of other subgroups. We use opinion mining techniques to identify opinion expressions and determine their polarities and their targets. We opinion predictions to represent the discussion in one of two formal representations: signed attitude network or a space of attitude vectors. We identify opinion subgroups by partitioning the signed network representation or by clustering the vector space representation. We evaluate the system using a data set of labeled discussions and show that it achieves good results.</p><p>5 0.17478146 <a title="244-tfidf-5" href="./acl-2013-An_annotated_corpus_of_quoted_opinions_in_news_articles.html">49 acl-2013-An annotated corpus of quoted opinions in news articles</a></p>
<p>Author: Tim O'Keefe ; James R. Curran ; Peter Ashwell ; Irena Koprinska</p><p>Abstract: Quotes are used in news articles as evidence of a person’s opinion, and thus are a useful target for opinion mining. However, labelling each quote with a polarity score directed at a textually-anchored target can ignore the broader issue that the speaker is commenting on. We address this by instead labelling quotes as supporting or opposing a clear expression of a point of view on a topic, called a position statement. Using this we construct a corpus covering 7 topics with 2,228 quotes.</p><p>6 0.17317562 <a title="244-tfidf-6" href="./acl-2013-Bi-directional_Inter-dependencies_of_Subjective_Expressions_and_Targets_and_their_Value_for_a_Joint_Model.html">67 acl-2013-Bi-directional Inter-dependencies of Subjective Expressions and Targets and their Value for a Joint Model</a></p>
<p>7 0.16462581 <a title="244-tfidf-7" href="./acl-2013-Detecting_Chronic_Critics_Based_on_Sentiment_Polarity_and_User%C3%A2%E2%80%A2%C5%BDs_Behavior_in_Social_Media.html">114 acl-2013-Detecting Chronic Critics Based on Sentiment Polarity and Userâ•Žs Behavior in Social Media</a></p>
<p>8 0.1472176 <a title="244-tfidf-8" href="./acl-2013-Exploiting_Topic_based_Twitter_Sentiment_for_Stock_Prediction.html">147 acl-2013-Exploiting Topic based Twitter Sentiment for Stock Prediction</a></p>
<p>9 0.12222871 <a title="244-tfidf-9" href="./acl-2013-Utterance-Level_Multimodal_Sentiment_Analysis.html">379 acl-2013-Utterance-Level Multimodal Sentiment Analysis</a></p>
<p>10 0.11901475 <a title="244-tfidf-10" href="./acl-2013-A_Bayesian_Model_for_Joint_Unsupervised_Induction_of_Sentiment%2C_Aspect_and_Discourse_Representations.html">2 acl-2013-A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations</a></p>
<p>11 0.1172223 <a title="244-tfidf-11" href="./acl-2013-LABR%3A_A_Large_Scale_Arabic_Book_Reviews_Dataset.html">211 acl-2013-LABR: A Large Scale Arabic Book Reviews Dataset</a></p>
<p>12 0.10611302 <a title="244-tfidf-12" href="./acl-2013-Sentiment_Relevance.html">318 acl-2013-Sentiment Relevance</a></p>
<p>13 0.098626792 <a title="244-tfidf-13" href="./acl-2013-Detecting_Turnarounds_in_Sentiment_Analysis%3A_Thwarting.html">117 acl-2013-Detecting Turnarounds in Sentiment Analysis: Thwarting</a></p>
<p>14 0.09546712 <a title="244-tfidf-14" href="./acl-2013-Identifying_Sentiment_Words_Using_an_Optimization-based_Model_without_Seed_Words.html">188 acl-2013-Identifying Sentiment Words Using an Optimization-based Model without Seed Words</a></p>
<p>15 0.080459677 <a title="244-tfidf-15" href="./acl-2013-Probabilistic_Sense_Sentiment_Similarity_through_Hidden_Emotions.html">284 acl-2013-Probabilistic Sense Sentiment Similarity through Hidden Emotions</a></p>
<p>16 0.076894864 <a title="244-tfidf-16" href="./acl-2013-Discovering_User_Interactions_in_Ideological_Discussions.html">121 acl-2013-Discovering User Interactions in Ideological Discussions</a></p>
<p>17 0.073266469 <a title="244-tfidf-17" href="./acl-2013-Exploring_Sentiment_in_Social_Media%3A_Bootstrapping_Subjectivity_Clues_from_Multilingual_Twitter_Streams.html">148 acl-2013-Exploring Sentiment in Social Media: Bootstrapping Subjectivity Clues from Multilingual Twitter Streams</a></p>
<p>18 0.069040231 <a title="244-tfidf-18" href="./acl-2013-TopicSpam%3A_a_Topic-Model_based_approach_for_spam_detection.html">350 acl-2013-TopicSpam: a Topic-Model based approach for spam detection</a></p>
<p>19 0.068976313 <a title="244-tfidf-19" href="./acl-2013-The_Haves_and_the_Have-Nots%3A_Leveraging_Unlabelled_Corpora_for_Sentiment_Analysis.html">345 acl-2013-The Haves and the Have-Nots: Leveraging Unlabelled Corpora for Sentiment Analysis</a></p>
<p>20 0.060991399 <a title="244-tfidf-20" href="./acl-2013-Detecting_Event-Related_Links_and_Sentiments_from_Social_Media_Texts.html">115 acl-2013-Detecting Event-Related Links and Sentiments from Social Media Texts</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.148), (1, 0.298), (2, -0.076), (3, 0.353), (4, -0.192), (5, 0.254), (6, -0.472), (7, -0.228), (8, -0.244), (9, -0.151), (10, -0.274), (11, 0.11), (12, 0.047), (13, 0.01), (14, -0.003), (15, -0.016), (16, -0.053), (17, 0.008), (18, -0.021), (19, -0.016), (20, 0.041), (21, -0.01), (22, 0.007), (23, -0.064), (24, -0.037), (25, -0.038), (26, 0.044), (27, 0.047), (28, -0.014), (29, 0.049), (30, 0.004), (31, 0.005), (32, -0.019), (33, 0.029), (34, -0.011), (35, -0.038), (36, -0.03), (37, 0.009), (38, 0.021), (39, -0.014), (40, -0.043), (41, -0.01), (42, -0.018), (43, 0.031), (44, -0.039), (45, -0.004), (46, 0.022), (47, 0.079), (48, 0.006), (49, 0.007)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99450582 <a title="244-lsi-1" href="./acl-2013-Mining_Opinion_Words_and_Opinion_Targets_in_a_Two-Stage_Framework.html">244 acl-2013-Mining Opinion Words and Opinion Targets in a Two-Stage Framework</a></p>
<p>Author: Liheng Xu ; Kang Liu ; Siwei Lai ; Yubo Chen ; Jun Zhao</p><p>Abstract: This paper proposes a novel two-stage method for mining opinion words and opinion targets. In the first stage, we propose a Sentiment Graph Walking algorithm, which naturally incorporates syntactic patterns in a Sentiment Graph to extract opinion word/target candidates. Then random walking is employed to estimate confidence of candidates, which improves extraction accuracy by considering confidence of patterns. In the second stage, we adopt a self-learning strategy to refine the results from the first stage, especially for filtering out high-frequency noise terms and capturing the long-tail terms, which are not investigated by previous methods. The experimental results on three real world datasets demonstrate the effectiveness of our approach compared with stateof-the-art unsupervised methods.</p><p>2 0.95767516 <a title="244-lsi-2" href="./acl-2013-Joint_Inference_for_Fine-grained_Opinion_Extraction.html">207 acl-2013-Joint Inference for Fine-grained Opinion Extraction</a></p>
<p>Author: Bishan Yang ; Claire Cardie</p><p>Abstract: This paper addresses the task of finegrained opinion extraction the identification of opinion-related entities: the opinion expressions, the opinion holders, and the targets of the opinions, and the relations between opinion expressions and their targets and holders. Most existing approaches tackle the extraction of opinion entities and opinion relations in a pipelined manner, where the interdependencies among different extraction stages are not captured. We propose a joint inference model that leverages knowledge from predictors that optimize subtasks – of opinion extraction, and seeks a globally optimal solution. Experimental results demonstrate that our joint inference approach significantly outperforms traditional pipeline methods and baselines that tackle subtasks in isolation for the problem of opinion extraction.</p><p>3 0.9543733 <a title="244-lsi-3" href="./acl-2013-Syntactic_Patterns_versus_Word_Alignment%3A_Extracting_Opinion_Targets_from_Online_Reviews.html">336 acl-2013-Syntactic Patterns versus Word Alignment: Extracting Opinion Targets from Online Reviews</a></p>
<p>Author: Kang Liu ; Liheng Xu ; Jun Zhao</p><p>Abstract: Mining opinion targets is a fundamental and important task for opinion mining from online reviews. To this end, there are usually two kinds of methods: syntax based and alignment based methods. Syntax based methods usually exploited syntactic patterns to extract opinion targets, which were however prone to suffer from parsing errors when dealing with online informal texts. In contrast, alignment based methods used word alignment model to fulfill this task, which could avoid parsing errors without using parsing. However, there is no research focusing on which kind of method is more better when given a certain amount of reviews. To fill this gap, this paper empiri- cally studies how the performance of these two kinds of methods vary when changing the size, domain and language of the corpus. We further combine syntactic patterns with alignment model by using a partially supervised framework and investigate whether this combination is useful or not. In our experiments, we verify that our combination is effective on the corpus with small and medium size.</p><p>4 0.76683116 <a title="244-lsi-4" href="./acl-2013-Identifying_Opinion_Subgroups_in_Arabic_Online_Discussions.html">187 acl-2013-Identifying Opinion Subgroups in Arabic Online Discussions</a></p>
<p>Author: Amjad Abu-Jbara ; Ben King ; Mona Diab ; Dragomir Radev</p><p>Abstract: In this paper, we use Arabic natural language processing techniques to analyze Arabic debates. The goal is to identify how the participants in a discussion split into subgroups with contrasting opinions. The members of each subgroup share the same opinion with respect to the discussion topic and an opposing opinion to the members of other subgroups. We use opinion mining techniques to identify opinion expressions and determine their polarities and their targets. We opinion predictions to represent the discussion in one of two formal representations: signed attitude network or a space of attitude vectors. We identify opinion subgroups by partitioning the signed network representation or by clustering the vector space representation. We evaluate the system using a data set of labeled discussions and show that it achieves good results.</p><p>5 0.59736669 <a title="244-lsi-5" href="./acl-2013-An_annotated_corpus_of_quoted_opinions_in_news_articles.html">49 acl-2013-An annotated corpus of quoted opinions in news articles</a></p>
<p>Author: Tim O'Keefe ; James R. Curran ; Peter Ashwell ; Irena Koprinska</p><p>Abstract: Quotes are used in news articles as evidence of a person’s opinion, and thus are a useful target for opinion mining. However, labelling each quote with a polarity score directed at a textually-anchored target can ignore the broader issue that the speaker is commenting on. We address this by instead labelling quotes as supporting or opposing a clear expression of a point of view on a topic, called a position statement. Using this we construct a corpus covering 7 topics with 2,228 quotes.</p><p>6 0.56406313 <a title="244-lsi-6" href="./acl-2013-Bi-directional_Inter-dependencies_of_Subjective_Expressions_and_Targets_and_their_Value_for_a_Joint_Model.html">67 acl-2013-Bi-directional Inter-dependencies of Subjective Expressions and Targets and their Value for a Joint Model</a></p>
<p>7 0.55316806 <a title="244-lsi-7" href="./acl-2013-Detecting_Chronic_Critics_Based_on_Sentiment_Polarity_and_User%C3%A2%E2%80%A2%C5%BDs_Behavior_in_Social_Media.html">114 acl-2013-Detecting Chronic Critics Based on Sentiment Polarity and Userâ•Žs Behavior in Social Media</a></p>
<p>8 0.34218433 <a title="244-lsi-8" href="./acl-2013-Detecting_Turnarounds_in_Sentiment_Analysis%3A_Thwarting.html">117 acl-2013-Detecting Turnarounds in Sentiment Analysis: Thwarting</a></p>
<p>9 0.27098924 <a title="244-lsi-9" href="./acl-2013-Exploiting_Topic_based_Twitter_Sentiment_for_Stock_Prediction.html">147 acl-2013-Exploiting Topic based Twitter Sentiment for Stock Prediction</a></p>
<p>10 0.26619017 <a title="244-lsi-10" href="./acl-2013-Utterance-Level_Multimodal_Sentiment_Analysis.html">379 acl-2013-Utterance-Level Multimodal Sentiment Analysis</a></p>
<p>11 0.25344118 <a title="244-lsi-11" href="./acl-2013-LABR%3A_A_Large_Scale_Arabic_Book_Reviews_Dataset.html">211 acl-2013-LABR: A Large Scale Arabic Book Reviews Dataset</a></p>
<p>12 0.23638767 <a title="244-lsi-12" href="./acl-2013-TopicSpam%3A_a_Topic-Model_based_approach_for_spam_detection.html">350 acl-2013-TopicSpam: a Topic-Model based approach for spam detection</a></p>
<p>13 0.21008232 <a title="244-lsi-13" href="./acl-2013-Extra-Linguistic_Constraints_on_Stance_Recognition_in_Ideological_Debates.html">151 acl-2013-Extra-Linguistic Constraints on Stance Recognition in Ideological Debates</a></p>
<p>14 0.19553949 <a title="244-lsi-14" href="./acl-2013-A_user-centric_model_of_voting_intention_from_Social_Media.html">33 acl-2013-A user-centric model of voting intention from Social Media</a></p>
<p>15 0.19006217 <a title="244-lsi-15" href="./acl-2013-HEADY%3A_News_headline_abstraction_through_event_pattern_clustering.html">178 acl-2013-HEADY: News headline abstraction through event pattern clustering</a></p>
<p>16 0.18533725 <a title="244-lsi-16" href="./acl-2013-Mining_Equivalent_Relations_from_Linked_Data.html">242 acl-2013-Mining Equivalent Relations from Linked Data</a></p>
<p>17 0.17486008 <a title="244-lsi-17" href="./acl-2013-Probabilistic_Sense_Sentiment_Similarity_through_Hidden_Emotions.html">284 acl-2013-Probabilistic Sense Sentiment Similarity through Hidden Emotions</a></p>
<p>18 0.17291258 <a title="244-lsi-18" href="./acl-2013-Co-Regression_for_Cross-Language_Review_Rating_Prediction.html">81 acl-2013-Co-Regression for Cross-Language Review Rating Prediction</a></p>
<p>19 0.17199486 <a title="244-lsi-19" href="./acl-2013-Sentiment_Relevance.html">318 acl-2013-Sentiment Relevance</a></p>
<p>20 0.16737166 <a title="244-lsi-20" href="./acl-2013-BRAINSUP%3A_Brainstorming_Support_for_Creative_Sentence_Generation.html">65 acl-2013-BRAINSUP: Brainstorming Support for Creative Sentence Generation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.036), (6, 0.015), (11, 0.049), (15, 0.015), (24, 0.379), (26, 0.05), (35, 0.039), (42, 0.046), (48, 0.029), (70, 0.033), (88, 0.011), (90, 0.018), (95, 0.176)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.96826822 <a title="244-lda-1" href="./acl-2013-Building_Comparable_Corpora_Based_on_Bilingual_LDA_Model.html">74 acl-2013-Building Comparable Corpora Based on Bilingual LDA Model</a></p>
<p>Author: Zede Zhu ; Miao Li ; Lei Chen ; Zhenxin Yang</p><p>Abstract: Comparable corpora are important basic resources in cross-language information processing. However, the existing methods of building comparable corpora, which use intertranslate words and relative features, cannot evaluate the topical relation between document pairs. This paper adopts the bilingual LDA model to predict the topical structures of the documents and proposes three algorithms of document similarity in different languages. Experiments show that the novel method can obtain similar documents with consistent top- ics own better adaptability and stability performance.</p><p>2 0.96521789 <a title="244-lda-2" href="./acl-2013-A_Visual_Analytics_System_for_Cluster_Exploration.html">29 acl-2013-A Visual Analytics System for Cluster Exploration</a></p>
<p>Author: Andreas Lamprecht ; Annette Hautli ; Christian Rohrdantz ; Tina Bogel</p><p>Abstract: This paper offers a new way of representing the results of automatic clustering algorithms by employing a Visual Analytics system which maps members of a cluster and their distance to each other onto a twodimensional space. A case study on Urdu complex predicates shows that the system allows for an appropriate investigation of linguistically motivated data. 1 Motivation In recent years, Visual Analytics systems have increasingly been used for the investigation of linguistic phenomena in a number of different areas, starting from literary analysis (Keim and Oelke, 2007) to the cross-linguistic comparison of language features (Mayer et al., 2010a; Mayer et al., 2010b; Rohrdantz et al., 2012a) and lexical semantic change (Rohrdantz et al., 2011; Heylen et al., 2012; Rohrdantz et al., 2012b). Visualization has also found its way into the field of computational linguistics by providing insights into methods such as machine translation (Collins et al., 2007; Albrecht et al., 2009) or discourse parsing (Zhao et al., 2012). One issue in computational linguistics is the interpretability of results coming from machine learning algorithms and the lack of insight they offer on the underlying data. This drawback often prevents theoretical linguists, who work with computational models and need to see patterns on large data sets, from drawing detailed conclusions. The present paper shows that a Visual Analytics system facilitates “analytical reasoning [...] by an interactive visual interface” (Thomas and Cook, 2006) and helps resolving this issue by offering a customizable, in-depth view on the statistically generated result and simultaneously an at-a-glance overview of the overall data set. In particular, we focus on the visual representa- tion of automatically generated clusters, in itself not a novel idea as it has been applied in other fields like the financial sector, biology or geography (Schreck et al., 2009). But as far as the literature is concerned, interactive systems are still less common, particularly in computational linguistics, and they have not been designed for the specific needs of theoretical linguists. This paper offers a method of visually encoding clusters and their internal coherence with an interactive user interface, which allows users to adjust underlying parameters and their views on the data depending on the particular research question. By this, we partly open up the “black box” of machine learning. The linguistic phenomenon under investigation, for which the system has originally been designed, is the varied behavior of nouns in N+V CP complex predicates in Urdu (e.g., memory+do = ‘to remember’) (Mohanan, 1994; Ahmed and Butt, 2011), where, depending on the lexical semantics of the noun, a set of different light verbs is chosen to form a complex predicate. The aim is an automatic detection of the different groups of nouns, based on their light verb distribution. Butt et al. (2012) present a static visualization for the phenomenon, whereas the present paper proposes an interactive system which alleviates some of the previous issues with respect to noise detection, filtering, data interaction and cluster coherence. For this, we proceed as follows: section 2 explains the proposed Visual Analytics system, followed by the linguistic case study in section 3. Section 4 concludes the paper. 2 The system The system requires a plain text file as input, where each line corresponds to one data object.In our case, each line corresponds to one Urdu noun (data object) and contains its unique ID (the name of the noun) and its bigram frequencies with the 109 Proce dingSsof oifa, th Beu 5l1gsarti Aan,An u aglu Mste 4e-ti9n2g 0 o1f3 t.he ?c A2s0s1o3ci Aatsiosonc fioartio Cno fmorpu Ctoamtiopnuatalt Lioin gauli Lsitnicgsu,i psatgices 109–1 4, four light verbs under investigation, namely kar ‘do’, ho ‘be’, hu ‘become’ and rakH ‘put’ ; an exemplary input file is shown in Figure 1. From a data analysis perspective, we have four- dimensional data objects, where each dimension corresponds to a bigram frequency previously extracted from a corpus. Note that more than four dimensions can be loaded and analyzed, but for the sake of simplicity we focus on the fourdimensional Urdu example for the remainder of this paper. Moreover, it is possible to load files containing absolute bigram frequencies and relative frequencies. When loading absolute frequencies, the program will automatically calculate the relative frequencies as they are the input for the clustering. The absolute frequencies, however, are still available and can be used for further processing (e.g. filtering). Figure 1: preview of appropriate file structures 2.1 Initial opening and processing of a file It is necessary to define a metric distance function between data objects for both clustering and visualization. Thus, each data object is represented through a high dimensional (in our example fourdimensional) numerical vector and we use the Euclidean distance to calculate the distances between pairs of data objects. The smaller the distance between two data objects, the more similar they are. For visualization, the high dimensional data is projected onto the two-dimensional space of a computer screen using a principal component analysis (PCA) algorithm1 . In the 2D projection, the distances between data objects in the highdimensional space, i.e. the dissimilarities of the bigram distributions, are preserved as accurately as possible. However, when projecting a highdimensional data space onto a lower dimension, some distinctions necessarily level out: two data objects may be far apart in the high-dimensional space, but end up closely together in the 2D projection. It is important to bear in mind that the 2D visualization is often quite insightful, but interpre1http://workshop.mkobos.com/201 1/java-pca- transformation-library/ tations have to be verified by interactively investigating the data. The initial clusters are calculated (in the highdimensional data space) using a default k-Means algorithm2 with k being a user-defined parameter. There is also the option of selecting another clustering algorithm, called the Greedy Variance Minimization3 (GVM), and an extension to include further algorithms is under development. 2.2 Configuration & Interaction 2.2.1 The main window The main window in Figure 2 consists of three areas, namely the configuration area (a), the visualization area (b) and the description area (c). The visualization area is mainly built with the piccolo2d library4 and initially shows data objects as colored circles with a variable diameter, where color indicates cluster membership (four clusters in this example). Hovering over a dot displays information on the particular noun, the cluster membership and the light verb distribution in the de- scription area to the right. By using the mouse wheel, the user can zoom in and out of the visualization. A very important feature for the task at hand is the possibility to select multiple data objects for further processing or for filtering, with a list of selected data objects shown in the description area. By right-clicking on these data objects, the user can assign a unique class (and class color) to them. Different clustering methods can be employed using the options item in the menu bar. Another feature of the system is that the user can fade in the cluster centroids (illustrated by a larger dot in the respective cluster color in Figure 2), where the overall feature distribution of the cluster can be examined in a tooltip hovering over the corresponding centroid. 2.2.2 Visually representing data objects To gain further insight into the data distribution based on the 2D projection, the user can choose between several ways to visualize the individual data objects, all of which are shown in Figure 3. The standard visualization type is shown on the left and consists of a circle which encodes cluster membership via color. 2http://java-ml.sourceforge.net/api/0.1.7/ (From the JML library) 3http://www.tomgibara.com/clustering/fast-spatial/ 4http://www.piccolo2d.org/ 110 Figure 2: Overview of the main window of the system, including the configuration area (a), the visualization area (b) and the description area (c). Large circles are cluster centroids. Figure 3: Different visualizations of data points Alternatively, normal glyphs and star glyphs can be displayed. The middle part of Figure 3 shows the data displayed with normal glyphs. In linestarinorthpsiflvtrheinorqsbgnutheviasnemdocwfya,proepfthlpdienaoecsr.nihetloa Titnghve det clockwise around the center according to their occurrence in the input file. This view has the advantage that overall feature dominance in a cluster can be seen at-a-glance. The visualization type on the right in Figure 3 agislnycpaehlxset. dnstHhioe nrset ,oarthngeolyrmlpinhae,l endings are connected, forming a “star”. As in the representation with the glyphs, this makes similar data objects easily recognizable and comparable with each other. 2.2.3 Filtering options Our systems offers options for filtering data ac- cording to different criteria. Filter by means of bigram occurrence By activating the bigram occurrence filtering, it is possible to only show those nouns, which occur in bigrams with a certain selected subset of all features (light verbs) only. This is especially useful when examining possible commonalities. Filter selected words Another opportunity of showing only items of interest is to select and display them separately. The PCA is recalculated for these data objects and the visualization is stretched to the whole area. 111 Filter selected cluster Additionally, the user can visualize a specific cluster of interest. Again, the PCA is recalculated and the visualization stretched to the whole area. The cluster can then be manually fine-tuned and cleaned, for instance by removing wrongly assigned items. 2.2.4 Options to handle overplotting Due to the nature of the data, much overplotting occurs. For example, there are many words, which only occur with one light verb. The PCA assigns the same position to these words and, as a consequence, only the top bigram can be viewed in the visualization. In order to improve visual access to overplotted data objects, several methods that allow for a more differentiated view of the data have been included and are described in the following paragraphs. Change transparency of data objects By modifying the transparency with the given slider, areas with a dense data population can be readily identified, as shown in the following example: Repositioning of data objects To reduce the overplotting in densely populated areas, data objects can be repositioned randomly having a fixed deviation from their initial position. The degree of deviation can be interactively determined by the user employing the corresponding slider: The user has the option to reposition either all data objects or only those that are selected in advance. Frequency filtering If the initial data contains absolute bigram frequencies, the user can filter the visualized words by frequency. For example, many nouns occur only once and therefore have an observed probability of 100% for co-occurring with one of the light verbs. In most cases it is useful to filter such data out. Scaling data objects If the user zooms beyond the maximum zoom factor, the data objects are scaled down. This is especially useful, if data objects are only partly covered by many other objects. In this case, they become fully visible, as shown in the following example: 2.3 Alternative views on the data In order to enable a holistic analysis it is often valuable to provide the user with different views on the data. Consequently, we have integrated the option to explore the data with further standard visualization methods. 2.3.1 Correlation matrix The correlation matrix in Figure 4 shows the correlations between features, which are visualized by circles using the following encoding: The size of a circle represents the correlation strength and the color indicates whether the corresponding features are negatively (white) or positively (black) correlated. Figure 4: example of a correlation matrix 2.3.2 Parallel coordinates The parallel coordinates diagram shows the distribution of the bigram frequencies over the different dimensions (Figure 5). Every noun is represented with a line, and shows, when hovered over, a tooltip with the most important information. To filter the visualized words, the user has the option of displaying previously selected data objects, or s/he can restrict the value range for a feature and show only the items which lie within this range. 2.3.3 Scatter plot matrix To further examine the relation between pairs of features, a scatter plot matrix can be used (Figure 6). The individual scatter plots give further insight into the correlation details of pairs of features. 112 Figure 5: Parallel coordinates diagram Figure 6: Example showing a scatter plot matrix. 3 Case study In principle, the Visual Analytics system presented above can be used for any kind of cluster visualization, but the built-in options and add-ons are particularly designed for the type of work that linguists tend to be interested in: on the one hand, the user wants to get a quick overview of the overall patterns in the phenomenon, but on the same time, the system needs to allow for an in-depth data inspection. Both is given in the system: The overall cluster result shown in Figure 2 depicts the coherence of clusters and therefore the overall pattern of the data set. The different glyph visualizations in Figure 3 illustrate the properties of each cluster. Single data points can be inspected in the description area. The randomization of overplotted data points helps to see concentrated cluster patterns where light verbs behave very similarly in different noun+verb complex predicates. The biggest advantage of the system lies in the ability for interaction: Figure 7 shows an example of the visualization used in Butt et al. (2012), the input being the same text file as shown in Figure 1. In this system, the relative frequencies of each noun with each light verb is correlated with color saturation the more saturated the color to the right of the noun, the higher the relative frequency of the light verb occurring with it. The number of the cluster (here, 3) and the respective nouns (e.g. kAm ‘work’) is shown to the left. The user does — not get information on the coherence of the cluster, nor does the visualization show prototypical cluster patterns. Figure 7: Cluster visualization in Butt et al. (2012) Moreover, the system in Figure 7 only has a limited set of interaction choices, with the consequence that the user is not able to adjust the underlying data set, e.g. by filtering out noise. However, Butt et al. (2012) report that the Urdu data is indeed very noisy and requires a manual cleaning of the data set before the actual clustering. In the system presented here, the user simply marks conspicuous regions in the visualization panel and removes the respective data points from the original data set. Other filtering mechanisms, e.g. the removal of low frequency items which occur due to data sparsity issues, can be removed from the overall data set by adjusting the parameters. A linguistically-relevant improvement lies in the display of cluster centroids, in other words the typical noun + light verb distribution of a cluster. This is particularly helpful when the linguist wants to pick out prototypical examples for the cluster in order to stipulate generalizations over the other cluster members. 113 4 Conclusion In this paper, we present a novel visual analytics system that helps to automatically analyze bigrams extracted from corpora. The main purpose is to enable a more informed and steered cluster analysis than currently possible with standard methods. This includes rich options for interaction, e.g. display configuration or data manipulation. Initially, the approach was motivated by a concrete research problem, but has much wider applicability as any kind of high-dimensional numerical data objects can be loaded and analyzed. However, the system still requires some basic understanding about the algorithms applied for clustering and projection in order to prevent the user to draw wrong conclusions based on artifacts. Bearing this potential pitfall in mind when performing the analysis, the system enables a much more insightful and informed analysis than standard noninteractive methods. In the future, we aim to conduct user experiments in order to learn more about how the functionality and usability could be further enhanced. Acknowledgments This work was partially funded by the German Research Foundation (DFG) under grant BU 1806/7-1 “Visual Analysis of Language Change and Use Patterns” and the German Fed- eral Ministry of Education and Research (BMBF) under grant 01461246 “VisArgue” under research grant. References Tafseer Ahmed and Miriam Butt. 2011. Discovering Semantic Classes for Urdu N-V Complex Predicates. In Proceedings of the international Conference on Computational Semantics (IWCS 2011), pages 305–309. Joshua Albrecht, Rebecca Hwa, and G. Elisabeta Marai. 2009. The Chinese Room: Visualization and Interaction to Understand and Correct Ambiguous Machine Translation. Comput. Graph. Forum, 28(3): 1047–1054. Miriam Butt, Tina B ¨ogel, Annette Hautli, Sebastian Sulger, and Tafseer Ahmed. 2012. Identifying Urdu Complex Predication via Bigram Extraction. In In Proceedings of COLING 2012, Technical Papers, pages 409 424, Mumbai, India. Christopher Collins, M. Sheelagh T. Carpendale, and Gerald Penn. 2007. Visualization of Uncertainty in Lattices to Support Decision-Making. In EuroVis 2007, pages 5 1–58. Eurographics Association. Kris Heylen, Dirk Speelman, and Dirk Geeraerts. 2012. Looking at word meaning. An interactive visualization of Semantic Vector Spaces for Dutch – synsets. In Proceedings of the EACL 2012 Joint Workshop of LINGVIS & UNCLH, pages 16–24. Daniel A. Keim and Daniela Oelke. 2007. Literature Fingerprinting: A New Method for Visual Literary Analysis. In IEEE VAST 2007, pages 115–122. IEEE. Thomas Mayer, Christian Rohrdantz, Miriam Butt, Frans Plank, and Daniel A. Keim. 2010a. Visualizing Vowel Harmony. Linguistic Issues in Language Technology, 4(Issue 2): 1–33, December. Thomas Mayer, Christian Rohrdantz, Frans Plank, Peter Bak, Miriam Butt, and Daniel A. Keim. 2010b. Consonant Co-Occurrence in Stems across Languages: Automatic Analysis and Visualization of a Phonotactic Constraint. In Proceedings of the 2010 Workshop on NLP andLinguistics: Finding the Common Ground, pages 70–78, Uppsala, Sweden, July. Association for Computational Linguistics. Tara Mohanan. 1994. Argument Structure in Hindi. Stanford: CSLI Publications. Christian Rohrdantz, Annette Hautli, Thomas Mayer, Miriam Butt, Frans Plank, and Daniel A. Keim. 2011. Towards Tracking Semantic Change by Visual Analytics. In ACL 2011 (Short Papers), pages 305–3 10, Portland, Oregon, USA, June. Association for Computational Linguistics. Christian Rohrdantz, Michael Hund, Thomas Mayer, Bernhard W ¨alchli, and Daniel A. Keim. 2012a. The World’s Languages Explorer: Visual Analysis of Language Features in Genealogical and Areal Contexts. Computer Graphics Forum, 3 1(3):935–944. Christian Rohrdantz, Andreas Niekler, Annette Hautli, Miriam Butt, and Daniel A. Keim. 2012b. Lexical Semantics and Distribution of Suffixes - A Visual Analysis. In Proceedings of the EACL 2012 Joint Workshop of LINGVIS & UNCLH, pages 7–15, April. Tobias Schreck, J ¨urgen Bernard, Tatiana von Landesberger, and J o¨rn Kohlhammer. 2009. Visual cluster analysis of trajectory data with interactive kohonen maps. Information Visualization, 8(1): 14–29. James J. Thomas and Kristin A. Cook. 2006. A Visual Analytics Agenda. IEEE Computer Graphics and Applications, 26(1): 10–13. Jian Zhao, Fanny Chevalier, Christopher Collins, and Ravin Balakrishnan. 2012. Facilitating Discourse Analysis with Interactive Visualization. IEEE Trans. Vis. Comput. Graph., 18(12):2639–2648. 114</p><p>3 0.95589578 <a title="244-lda-3" href="./acl-2013-Identification_of_Speakers_in_Novels.html">184 acl-2013-Identification of Speakers in Novels</a></p>
<p>Author: Hua He ; Denilson Barbosa ; Grzegorz Kondrak</p><p>Abstract: Speaker identification is the task of at- tributing utterances to characters in a literary narrative. It is challenging to auto- mate because the speakers of the majority ofutterances are not explicitly identified in novels. In this paper, we present a supervised machine learning approach for the task that incorporates several novel features. The experimental results show that our method is more accurate and general than previous approaches to the problem.</p><p>4 0.95128363 <a title="244-lda-4" href="./acl-2013-Bridging_Languages_through_Etymology%3A_The_case_of_cross_language_text_categorization.html">72 acl-2013-Bridging Languages through Etymology: The case of cross language text categorization</a></p>
<p>Author: Vivi Nastase ; Carlo Strapparava</p><p>Abstract: We propose the hypothesis that word etymology is useful for NLP applications as a bridge between languages. We support this hypothesis with experiments in crosslanguage (English-Italian) document categorization. In a straightforward bag-ofwords experimental set-up we add etymological ancestors of the words in the documents, and investigate the performance of a model built on English data, on Italian test data (and viceversa). The results show not only statistically significant, but a large improvement a jump of almost 40 points in F1-score over the raw (vanilla bag-ofwords) representation.</p><p>5 0.94672447 <a title="244-lda-5" href="./acl-2013-Does_Korean_defeat_phonotactic_word_segmentation%3F.html">128 acl-2013-Does Korean defeat phonotactic word segmentation?</a></p>
<p>Author: Robert Daland ; Kie Zuraw</p><p>Abstract: Computational models of infant word segmentation have not been tested on a wide range of languages. This paper applies a phonotactic segmentation model to Korean. In contrast to the undersegmentation pattern previously found in English and Russian, the model exhibited more oversegmentation errors and more errors overall. Despite the high error rate, analysis suggested that lexical acquisition might not be problematic, provided that infants attend only to frequently segmented items. 1</p><p>same-paper 6 0.94660902 <a title="244-lda-6" href="./acl-2013-Mining_Opinion_Words_and_Opinion_Targets_in_a_Two-Stage_Framework.html">244 acl-2013-Mining Opinion Words and Opinion Targets in a Two-Stage Framework</a></p>
<p>7 0.94633502 <a title="244-lda-7" href="./acl-2013-Leveraging_Synthetic_Discourse_Data_via_Multi-task_Learning_for_Implicit_Discourse_Relation_Recognition.html">229 acl-2013-Leveraging Synthetic Discourse Data via Multi-task Learning for Implicit Discourse Relation Recognition</a></p>
<p>8 0.93880689 <a title="244-lda-8" href="./acl-2013-ParaQuery%3A_Making_Sense_of_Paraphrase_Collections.html">271 acl-2013-ParaQuery: Making Sense of Paraphrase Collections</a></p>
<p>9 0.75529677 <a title="244-lda-9" href="./acl-2013-PhonMatrix%3A_Visualizing_co-occurrence_constraints_of_sounds.html">279 acl-2013-PhonMatrix: Visualizing co-occurrence constraints of sounds</a></p>
<p>10 0.75120831 <a title="244-lda-10" href="./acl-2013-Using_Supervised_Bigram-based_ILP_for_Extractive_Summarization.html">377 acl-2013-Using Supervised Bigram-based ILP for Extractive Summarization</a></p>
<p>11 0.744712 <a title="244-lda-11" href="./acl-2013-Evaluating_Text_Segmentation_using_Boundary_Edit_Distance.html">140 acl-2013-Evaluating Text Segmentation using Boundary Edit Distance</a></p>
<p>12 0.70681077 <a title="244-lda-12" href="./acl-2013-Character-to-Character_Sentiment_Analysis_in_Shakespeare%27s_Plays.html">79 acl-2013-Character-to-Character Sentiment Analysis in Shakespeare's Plays</a></p>
<p>13 0.70446634 <a title="244-lda-13" href="./acl-2013-Text_Classification_from_Positive_and_Unlabeled_Data_using_Misclassified_Data_Correction.html">342 acl-2013-Text Classification from Positive and Unlabeled Data using Misclassified Data Correction</a></p>
<p>14 0.70216888 <a title="244-lda-14" href="./acl-2013-Name-aware_Machine_Translation.html">255 acl-2013-Name-aware Machine Translation</a></p>
<p>15 0.70136517 <a title="244-lda-15" href="./acl-2013-Improving_Text_Simplification_Language_Modeling_Using_Unsimplified_Text_Data.html">194 acl-2013-Improving Text Simplification Language Modeling Using Unsimplified Text Data</a></p>
<p>16 0.69912362 <a title="244-lda-16" href="./acl-2013-Dirt_Cheap_Web-Scale_Parallel_Text_from_the_Common_Crawl.html">120 acl-2013-Dirt Cheap Web-Scale Parallel Text from the Common Crawl</a></p>
<p>17 0.6859901 <a title="244-lda-17" href="./acl-2013-A_Bayesian_Model_for_Joint_Unsupervised_Induction_of_Sentiment%2C_Aspect_and_Discourse_Representations.html">2 acl-2013-A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations</a></p>
<p>18 0.67958885 <a title="244-lda-18" href="./acl-2013-Crowd_Prefers_the_Middle_Path%3A_A_New_IAA_Metric_for_Crowdsourcing_Reveals_Turker_Biases_in_Query_Segmentation.html">99 acl-2013-Crowd Prefers the Middle Path: A New IAA Metric for Crowdsourcing Reveals Turker Biases in Query Segmentation</a></p>
<p>19 0.67431331 <a title="244-lda-19" href="./acl-2013-Identifying_Opinion_Subgroups_in_Arabic_Online_Discussions.html">187 acl-2013-Identifying Opinion Subgroups in Arabic Online Discussions</a></p>
<p>20 0.67423451 <a title="244-lda-20" href="./acl-2013-LABR%3A_A_Large_Scale_Arabic_Book_Reviews_Dataset.html">211 acl-2013-LABR: A Large Scale Arabic Book Reviews Dataset</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
