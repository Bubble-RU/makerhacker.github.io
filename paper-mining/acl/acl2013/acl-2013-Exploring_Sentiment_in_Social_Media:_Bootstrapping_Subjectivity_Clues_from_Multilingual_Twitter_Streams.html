<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>148 acl-2013-Exploring Sentiment in Social Media: Bootstrapping Subjectivity Clues from Multilingual Twitter Streams</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-148" href="#">acl2013-148</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>148 acl-2013-Exploring Sentiment in Social Media: Bootstrapping Subjectivity Clues from Multilingual Twitter Streams</h1>
<br/><p>Source: <a title="acl-2013-148-pdf" href="http://aclweb.org/anthology//P/P13/P13-2090.pdf">pdf</a></p><p>Author: Svitlana Volkova ; Theresa Wilson ; David Yarowsky</p><p>Abstract: We study subjective language media and create Twitter-specific lexicons via bootstrapping sentiment-bearing terms from multilingual Twitter streams. Starting with a domain-independent, highprecision sentiment lexicon and a large pool of unlabeled data, we bootstrap Twitter-specific sentiment lexicons, using a small amount of labeled data to guide the process. Our experiments on English, Spanish and Russian show that the resulting lexicons are effective for sentiment classification for many underexplored languages in social media.</p><p>Reference: <a title="acl-2013-148-reference" href="../acl2013_reference/acl-2013-Exploring_Sentiment_in_Social_Media%3A_Bootstrapping_Subjectivity_Clues_from_Multilingual_Twitter_Streams_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu Abstract We study subjective language media and create Twitter-specific lexicons via bootstrapping sentiment-bearing terms from multilingual Twitter streams. [sent-2, score-0.732]
</p><p>2 Starting with a domain-independent, highprecision sentiment lexicon and a large pool of unlabeled data, we bootstrap  Twitter-specific sentiment lexicons, using a small amount of labeled data to guide the process. [sent-3, score-1.076]
</p><p>3 Our experiments on English, Spanish and Russian show that the resulting lexicons are effective for sentiment classification for many underexplored languages in social media. [sent-4, score-0.735]
</p><p>4 1 Introduction The language that people use to express opinions and sentiment is extremely diverse. [sent-5, score-0.339]
</p><p>5 This is true for well-formed data, such as news and reviews, and it is particularly true for data from social media. [sent-6, score-0.089]
</p><p>6 Communication in social media is informal, abbreviations and misspellings abound, and the person communicating is often trying to be funny, creative, and entertaining. [sent-7, score-0.167]
</p><p>7 The dynamic nature of social media together with the extreme diversity of subjective language has implications for any system with the goal of analyzing sentiment in this domain. [sent-9, score-0.728]
</p><p>8 Even models trained specifically on social media data may degrade somewhat over time as topics change and new sentiment-bearing terms crop up. [sent-11, score-0.235]
</p><p>9 For example, the word “occupy” would not have been indicative of sentiment before 2011. [sent-12, score-0.339]
</p><p>10 Most of the previous work on sentiment lexicon construction relies on existing natural language Theresa Wilson HLTCOE Johns Hopkins University Baltimore, MD t aw@ j hu . [sent-13, score-0.593]
</p><p>11 , syntactic parsers (Wiebe, 2000), information extraction (IE) tools (Riloff in social and Wiebe, 2003) or rich lexical resources such as WordNet (Esuli and Sebastiani, 2006). [sent-18, score-0.089]
</p><p>12 However, such tools and lexical resources are not available for many languages spoken in social media. [sent-19, score-0.138]
</p><p>13 Any method for analyzing sentiment in microblogs or other social media streams must be easily adapted to (1) many  low-resource languages, (2) the dynamic nature of social media, and (3) working in a streaming mode with limited or no supervision. [sent-22, score-0.638]
</p><p>14 Although bootstrapping has been used for learning sentiment lexicons in other domains (Turney and Littman, 2002; Banea et al. [sent-23, score-0.703]
</p><p>15 , 2008), it has not yet been applied to learning sentiment lexicons for microblogs. [sent-24, score-0.553]
</p><p>16 In this paper, we present an approach for bootstrapping subjectivity clues from Twitter data, and evaluate our approach on English, Spanish and Russian Twitter streams. [sent-25, score-0.497]
</p><p>17 sentiment-bearing terms of similar orientation tend to co-occur at the tweet level (Turney and Littman, 2002); ii. [sent-29, score-0.256]
</p><p>18 sentiment-bearing terms of opposite orienta-  tion do not co-occur at the tweet level (Gamon and Aue, 2005); iii. [sent-30, score-0.202]
</p><p>19 the co-occurrence of domain-specific and domain-independent subjective terms serves as a signal of subjectivity. [sent-31, score-0.29]
</p><p>20 al (2012) classifies methods for bootstrapping subjectivity lexicons into two types: corpus-based and dictionary-based. [sent-35, score-0.668]
</p><p>21 Dictionary-based methods rely on existing lexical resources to bootstrap sentiment lexicons. [sent-36, score-0.44]
</p><p>22 (2009) use a thesaurus to aid in the construction of a sentiment lexicon for English. [sent-42, score-0.565]
</p><p>23 However, the lexical resources that dictionary-based methods need, do not yet exist for the majority of languages in social media. [sent-45, score-0.138]
</p><p>24 There is also a mismatch between the formality of many language resources, such as WordNet, and the extremely informal language of social media. [sent-46, score-0.089]
</p><p>25 Corpus-based methods extract subjectivity and sentiment lexicons from large amounts of unlabeled data using different similarity metrics to measure the relatedness between words. [sent-47, score-0.886]
</p><p>26 Hatzivassiloglou and McKeown (1997) were the first to explore automatically learning the polarity of words from corpora. [sent-48, score-0.213]
</p><p>27 Early work by Wiebe (2000) identifies clusters of subjectivity clues based on their distributional similarity, using a small amount of data to bootstrap the process. [sent-49, score-0.448]
</p><p>28 (2010) bootstrap sentiment lexicons for English from the web by using Pointwise Mutual Information (PMI) and graph propagation approach, respectively. [sent-51, score-0.654]
</p><p>29 Kaji and Kitsuregawa (2007) propose a method for building sentiment lexicon for Japanese from HTML pages. [sent-52, score-0.565]
</p><p>30 Kanayama and Nasukawa (2006) bootstrap subjectivity lexicons for Japanese by generating subjectivity candidates based on word co-occurrence patterns. [sent-56, score-0.923]
</p><p>31 In contrast to other corpus-based bootstrapping methods, we evaluate our approach on multiple languages, specifically English, Spanish, and Russian. [sent-57, score-0.15]
</p><p>32 Also, as our approach relies only on the availability of a bilingual dictionary for translating an English subjectivity lexicon and crowdsourcing for help in selecting seeds, it is more scalable and better able to handle the informality and the dynamic nature of social media. [sent-58, score-0.661]
</p><p>33 It also can be effectively used to bootstrap sentiment lexicons for any language for which a bilingual dictionary is available or can be automatically induced from parallel corpora. [sent-59, score-0.654]
</p><p>34 3  Data  For the experiments in this paper, we use three sets of data for each language: 1M unlabeled  tweets (BOOT) for bootstrapping Twitter-specific lexicons, 2K labeled tweets for development data (DEV), and 2K labeled tweets for evaluation (TEST). [sent-60, score-0.803]
</p><p>35 DEV is used for parameter tuning while bootstrapping, and TEST is used to evaluating the quality of the bootstrapped lexicons. [sent-61, score-0.2]
</p><p>36 We take English tweets from the corpus constructed by Burger et al. [sent-62, score-0.208]
</p><p>37 1 English tweets are identified automatically using a compression-based language identification (LID) tool (Bergsma et al. [sent-65, score-0.208]
</p><p>38 Therefore, for other languages we construct a new Twitter corpus by downloading tweets from followers of regionspecific news and media feeds. [sent-71, score-0.335]
</p><p>39 Sentiment labels for tweets in DEV and TEST sets for all languages are obtained using Amazon Mechanical Turk. [sent-72, score-0.257]
</p><p>40 For each tweet we collect an-  notations from five workers and use majority vote to determine the final label for the tweet. [sent-73, score-0.134]
</p><p>41 Table 1gives the distribution of tweets over sentiment labels for the development and test sets for English (E-DEV, E-TEST), Spanish (SDEV, S-TEST), and Russian (R-DEV, R-TEST). [sent-76, score-0.547]
</p><p>42 4  Lexicon Bootstrapping  To create a Twitter-specific sentiment lexicon for a given language, we start with a general-purpose, high-precision sentiment lexicon2 and bootstrap from the unlabeled data (BOOT) using the labeled development data (DEV) to guide the process. [sent-84, score-1.034]
</p><p>43 1 High-Precision Subjectivity Lexicons  For English we seed the bootstrapping process with the strongly subjective terms from the MPQA lexicon3 (Wilson et al. [sent-86, score-0.519]
</p><p>44 These terms have been previously shown to be highprecision for recognizing subjective sentences (Riloff and Wiebe, 2003). [sent-88, score-0.332]
</p><p>45 For the other languages, the subjective seed terms are obtained by translating English seed terms using a bilingual dictionary, and then collecting judgments about term subjectivity from Mechanical Turk. [sent-89, score-0.813]
</p><p>46 Terms that truly are strongly subjective in translation are used for seed terms in the new language, with term polarity projected from the English. [sent-90, score-0.651]
</p><p>47 Finally, we expand the lexicons with plurals and inflectional forms for adverbs, adjectives and verbs. [sent-91, score-0.289]
</p><p>48 2 Bootstrapping Approach To bootstrap, first the new lexicon LB(0) is seeded with the strongly subjective terms from the original lexicon LI. [sent-93, score-0.78]
</p><p>49 On each iteration i ≥ 1, tweets in the unlabeled. [sent-94, score-0.208]
</p><p>50 d Oatna are hlab iteelreadti using ≥the 1 ,le txwieceotns 2Other works on generating domain-specific sentiment lexicons e. [sent-96, score-0.553]
</p><p>51 If a tweet contains one or more terms from LB(i−1) it is considered subjective, otherwise objective. [sent-104, score-0.202]
</p><p>52 i4n tIof it contains both positive and negative terms, it is considered to be both. [sent-106, score-0.096]
</p><p>53 Then, for every term not in LB(i−1) that has a frequency ≥ θfreq, the probability of tthhaatt t hearms a being subjective is calculated as shown in Algorithm 1 line 10. [sent-107, score-0.291]
</p><p>54 The top θk terms with a subjective probability ≥ θpr are then added twoi LB(i) . [sent-108, score-0.29]
</p><p>55 bTjehcet polarity aobfi new ≥te θrms is determined based on the probability of the term appearing in positive or negative tweets as shown in line 18. [sent-109, score-0.586]
</p><p>56 5 The bootstrapping process terminates when there are no more new terms meeting the criteria to add. [sent-110, score-0.218]
</p><p>57 8 Table 2: The original and the bootstrapped (highlighted) lexicon term count (LI ⊂ LB) with polarity across languages (thousands). [sent-133, score-0.757]
</p><p>58 The set ofparameters optimized using a grid search on the development data using F-measure for subjectivity classification. [sent-134, score-0.304]
</p><p>59 In Table 2 we report size and term polarity from the original LI and the bootstrapped LB lexicons. [sent-141, score-0.482]
</p><p>60 For that we perform subjectivity and polarity classification using rule-based classifiers6 on the test data E-TEST, S-TEST and R-TEST. [sent-144, score-0.561]
</p><p>61 We consider how the various lexicons perform for rule-based classifiers for both subjectivity and polarity. [sent-145, score-0.518]
</p><p>62 The subjectivity classifier predicts that  a tweet is subjective if it contains a) at least one, or b) at least two subjective terms from the lexicon. [sent-146, score-0.95]
</p><p>63 For the polarity classifier, we predict a tweet to be positive (negative) if it contains at least one positive (negative) term taking into account negation. [sent-147, score-0.5]
</p><p>64 If the tweet contains both positive and negative terms, we take the majority label. [sent-148, score-0.23]
</p><p>65 For English we compare our bootstrapped lexicon LBE against the original lexicon LIE and strongly subjective terms from SentiWordNet 3. [sent-149, score-0.98]
</p><p>66 To make a fair comparison, we automatically expand SentiWordNet with noun plural forms and verb inflectional forms. [sent-151, score-0.075]
</p><p>67 In Figure 1 we report precision, recall 6Similar approach to a rule-based classification using terms from he MPQA lexicon (Riloff and Wiebe, 2003). [sent-152, score-0.367]
</p><p>68 They show that our bootstrapped lexicon significantly outperforms SentiWordNet for subjectivity classification. [sent-154, score-0.73]
</p><p>69 For polarity classification we get comparable F-measure but much higher recall for LBE compared to SWN. [sent-155, score-0.286]
</p><p>70 l 8a7 2r8 ity Figure 1: Precision (x-axis), recall (y-axis) and F-measure (in the table) for English: LIE = initial lexicon, LBE = bootstrapped lexicon, SWN = strongly subjective terms from SentiWordNet. [sent-159, score-0.557]
</p><p>71 For Spanish we compare our bootstrapped lexicon LSB against the original LIS lexicon, and the full and medium strength terms from the Spanish sentiment lexicon constructed by Perez-Rosas et el. [sent-160, score-1.133]
</p><p>72 We observe that our boot-  strapped lexicon yields significantly better performance for subjectivity classification compared to both full and medium strength terms. [sent-163, score-0.648]
</p><p>73 However, our bootstrapped lexicon yields lower recall and similar precision for polarity classification. [sent-164, score-0.668]
</p><p>74 l 6a5 6r48ity  Figure 2: Precision (x-axis), recall (y-axis) and Fmeasure (in the table) for Spanish: LIS = initial lexicon, LSB = bootstrapped lexicon, SF = full strength terms; SM = medium strength terms. [sent-168, score-0.336]
</p><p>75 508  For Russian we compare our bootstrapped lexicon LBR against the original LIR lexicon, and the Russian sentiment lexicon constructed by Chetviorkin and Loukachevitchet (2012). [sent-169, score-0.991]
</p><p>76 The external lexicon in Russian P was built for the domain of product reviews and does not include polarity judgments for subjective terms. [sent-170, score-0.709]
</p><p>77 As before, we expand the external lexicon with the inflectional forms for adverbs, adjectives and verbs. [sent-171, score-0.349]
</p><p>78 We find that for subjectivity our bootstrapped lexicon shows better performance compared to the external lexicon (5k terms). [sent-173, score-1.004]
</p><p>79 However, the expanded external lexicon (17k terms) yields higher recall with a significant drop in precision. [sent-174, score-0.303]
</p><p>80 Note that for Russian, we report polarity classification results for LBR and LIR lexicons only because P does not have polarity labels. [sent-175, score-0.684]
</p><p>81 a7r3ity  Figure 3: Precision (x-axis), recall (y-axis) and Fmeasure for Russian: LIR = initial lexicon, LBR = bootstrapped lexicon, P = external sentiment lexicon, PX = expanded external lexicon. [sent-179, score-0.664]
</p><p>82 We next perform error analysis for subjectivity and polarity classification for all languages and identify common errors to address them in future. [sent-180, score-0.61]
</p><p>83 For subjectivity classification we observe that applying part-of-speech tagging during the bootstrapping could improve results for all languages. [sent-181, score-0.498]
</p><p>84 We could further improve the quality of the lexicon and reduce false negative errors (subjective tweets classified as neutral) by focusing on sentiment-bearing terms such as adjective, adverbs and verbs. [sent-182, score-0.591]
</p><p>85 We also find subjective tweets with philosophical thoughts and opinions misclassified, especially in Russian, e. [sent-188, score-0.466]
</p><p>86 Such tweets are difficult to classify using lexicon-based approaches and require deeper linguistic analysis. [sent-191, score-0.208]
</p><p>87 False positive errors for subjectivity classification happen because some terms are weakly sub-  jective and can be used in both subjective and neutral tweets e. [sent-192, score-0.962]
</p><p>88 , the Russian term хвастаться (brag) is often used as subjective, but in a tweet никогда не стоит хвастаться будущим (never brag about your future) it is used as neutral. [sent-194, score-0.25]
</p><p>89 Similarly, the Spanish term buenas (good) is often used subjectively but it is used as neutral in the following tweet “@Diveke me falto el buenas! [sent-195, score-0.29]
</p><p>90 For polarity classification, most errors happen because our approach relies on either positive or negative polarity scores for a term but not both. [sent-198, score-0.625]
</p><p>91 Additional errors happen because tweets are very short and convey multiple messages (e. [sent-204, score-0.242]
</p><p>92 6  Conclusions  We propose a scalable and language independent bootstrapping approach for learning subjectivity clues from Twitter streams. [sent-209, score-0.497]
</p><p>93 We demonstrate the effectiveness of the bootstrapping procedure by comparing the resulting subjectivity lexicons with state-of the-art sentiment lexicons. [sent-210, score-1.007]
</p><p>94 The results confirm that the approach can be effectively exploited and further improved for subjectivity classification for many under-explored languages in social media. [sent-212, score-0.486]
</p><p>95 8During the bootstrapping we calculate probability for a term to be positive and negative, e. [sent-213, score-0.261]
</p><p>96 A bootstrapping method for building subjectivity lexicons for languages with scarce resources. [sent-237, score-0.717]
</p><p>97 Evaluation and extension of a polarity lexicon for German. [sent-256, score-0.439]
</p><p>98 Automatic identification of sentiment vocabulary: exploiting low association with known sentiment terms. [sent-271, score-0.678]
</p><p>99 Building lexicon for sentiment analysis from massive collection of html documents. [sent-288, score-0.565]
</p><p>100 Generating high-coverage semantic orientation lexicons from overtly marked words and a thesaurus. [sent-305, score-0.268]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('sentiment', 0.339), ('subjectivity', 0.304), ('lb', 0.253), ('lexicon', 0.226), ('subjective', 0.222), ('lexicons', 0.214), ('polarity', 0.213), ('libter', 0.212), ('tweets', 0.208), ('russian', 0.203), ('bootstrapped', 0.2), ('bootstrapping', 0.15), ('tweet', 0.134), ('twitter', 0.104), ('bootstrap', 0.101), ('spanish', 0.1), ('lbr', 0.094), ('subj', 0.089), ('social', 0.089), ('banea', 0.086), ('media', 0.078), ('esuli', 0.077), ('boot', 0.071), ('chetviorkin', 0.071), ('lir', 0.071), ('lsb', 0.071), ('wpol', 0.071), ('lbe', 0.069), ('term', 0.069), ('terms', 0.068), ('wiebe', 0.065), ('dev', 0.065), ('janyce', 0.064), ('sentiwordnet', 0.061), ('orientation', 0.054), ('negative', 0.054), ('carmen', 0.052), ('freq', 0.049), ('burger', 0.049), ('languages', 0.049), ('external', 0.048), ('riloff', 0.048), ('brag', 0.047), ('buenas', 0.047), ('clematide', 0.047), ('ppos', 0.047), ('psubj', 0.047), ('topk', 0.047), ('warm', 0.047), ('classification', 0.044), ('streams', 0.043), ('fmeasure', 0.043), ('clues', 0.043), ('inflectional', 0.042), ('positive', 0.042), ('andreevskaia', 0.042), ('velikovich', 0.042), ('highprecision', 0.042), ('informality', 0.042), ('rif', 0.042), ('baltimore', 0.041), ('sebastiani', 0.041), ('medium', 0.041), ('seed', 0.041), ('neutral', 0.04), ('johns', 0.039), ('lid', 0.038), ('iter', 0.038), ('clsp', 0.038), ('jijkoun', 0.038), ('strongly', 0.038), ('theresa', 0.038), ('turney', 0.038), ('thoughts', 0.036), ('que', 0.036), ('adverbs', 0.035), ('happen', 0.034), ('wilson', 0.034), ('negation', 0.034), ('md', 0.034), ('wordnet', 0.033), ('expand', 0.033), ('kaji', 0.033), ('strength', 0.033), ('misclassified', 0.032), ('hopkins', 0.032), ('english', 0.03), ('rada', 0.03), ('littman', 0.03), ('gamon', 0.03), ('kanayama', 0.03), ('rao', 0.03), ('unlabeled', 0.029), ('lis', 0.029), ('mpqa', 0.029), ('mihalcea', 0.029), ('recall', 0.029), ('pr', 0.029), ('hu', 0.028), ('gimpel', 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="148-tfidf-1" href="./acl-2013-Exploring_Sentiment_in_Social_Media%3A_Bootstrapping_Subjectivity_Clues_from_Multilingual_Twitter_Streams.html">148 acl-2013-Exploring Sentiment in Social Media: Bootstrapping Subjectivity Clues from Multilingual Twitter Streams</a></p>
<p>Author: Svitlana Volkova ; Theresa Wilson ; David Yarowsky</p><p>Abstract: We study subjective language media and create Twitter-specific lexicons via bootstrapping sentiment-bearing terms from multilingual Twitter streams. Starting with a domain-independent, highprecision sentiment lexicon and a large pool of unlabeled data, we bootstrap Twitter-specific sentiment lexicons, using a small amount of labeled data to guide the process. Our experiments on English, Spanish and Russian show that the resulting lexicons are effective for sentiment classification for many underexplored languages in social media.</p><p>2 0.33703265 <a title="148-tfidf-2" href="./acl-2013-Sentiment_Relevance.html">318 acl-2013-Sentiment Relevance</a></p>
<p>Author: Christian Scheible ; Hinrich Schutze</p><p>Abstract: A number of different notions, including subjectivity, have been proposed for distinguishing parts of documents that convey sentiment from those that do not. We propose a new concept, sentiment relevance, to make this distinction and argue that it better reflects the requirements of sentiment analysis systems. We demonstrate experimentally that sentiment relevance and subjectivity are related, but different. Since no large amount of labeled training data for our new notion of sentiment relevance is available, we investigate two semi-supervised methods for creating sentiment relevance classifiers: a distant supervision approach that leverages structured information about the domain of the reviews; and transfer learning on feature representations based on lexical taxonomies that enables knowledge transfer. We show that both methods learn sentiment relevance classifiers that perform well.</p><p>3 0.32140994 <a title="148-tfidf-3" href="./acl-2013-Detecting_Event-Related_Links_and_Sentiments_from_Social_Media_Texts.html">115 acl-2013-Detecting Event-Related Links and Sentiments from Social Media Texts</a></p>
<p>Author: Alexandra Balahur ; Hristo Tanev</p><p>Abstract: Nowadays, the importance of Social Media is constantly growing, as people often use such platforms to share mainstream media news and comment on the events that they relate to. As such, people no loger remain mere spectators to the events that happen in the world, but become part of them, commenting on their developments and the entities involved, sharing their opinions and distributing related content. This paper describes a system that links the main events detected from clusters of newspaper articles to tweets related to them, detects complementary information sources from the links they contain and subsequently applies sentiment analysis to classify them into positive, negative and neutral. In this manner, readers can follow the main events happening in the world, both from the perspective of mainstream as well as social media and the public’s perception on them. This system will be part of the EMM media monitoring framework working live and it will be demonstrated using Google Earth.</p><p>4 0.31803668 <a title="148-tfidf-4" href="./acl-2013-Identifying_Sentiment_Words_Using_an_Optimization-based_Model_without_Seed_Words.html">188 acl-2013-Identifying Sentiment Words Using an Optimization-based Model without Seed Words</a></p>
<p>Author: Hongliang Yu ; Zhi-Hong Deng ; Shiyingxue Li</p><p>Abstract: Sentiment Word Identification (SWI) is a basic technique in many sentiment analysis applications. Most existing researches exploit seed words, and lead to low robustness. In this paper, we propose a novel optimization-based model for SWI. Unlike previous approaches, our model exploits the sentiment labels of documents instead of seed words. Several experiments on real datasets show that WEED is effective and outperforms the state-of-the-art methods with seed words.</p><p>5 0.22949742 <a title="148-tfidf-5" href="./acl-2013-A_Bayesian_Model_for_Joint_Unsupervised_Induction_of_Sentiment%2C_Aspect_and_Discourse_Representations.html">2 acl-2013-A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations</a></p>
<p>Author: Angeliki Lazaridou ; Ivan Titov ; Caroline Sporleder</p><p>Abstract: We propose a joint model for unsupervised induction of sentiment, aspect and discourse information and show that by incorporating a notion of latent discourse relations in the model, we improve the prediction accuracy for aspect and sentiment polarity on the sub-sentential level. We deviate from the traditional view of discourse, as we induce types of discourse relations and associated discourse cues relevant to the considered opinion analysis task; consequently, the induced discourse relations play the role of opinion and aspect shifters. The quantitative analysis that we conducted indicated that the integration of a discourse model increased the prediction accuracy results with respect to the discourse-agnostic approach and the qualitative analysis suggests that the induced representations encode a meaningful discourse structure.</p><p>6 0.20376085 <a title="148-tfidf-6" href="./acl-2013-Identifying_Opinion_Subgroups_in_Arabic_Online_Discussions.html">187 acl-2013-Identifying Opinion Subgroups in Arabic Online Discussions</a></p>
<p>7 0.20358799 <a title="148-tfidf-7" href="./acl-2013-Exploiting_Topic_based_Twitter_Sentiment_for_Stock_Prediction.html">147 acl-2013-Exploiting Topic based Twitter Sentiment for Stock Prediction</a></p>
<p>8 0.1871938 <a title="148-tfidf-8" href="./acl-2013-Bi-directional_Inter-dependencies_of_Subjective_Expressions_and_Targets_and_their_Value_for_a_Joint_Model.html">67 acl-2013-Bi-directional Inter-dependencies of Subjective Expressions and Targets and their Value for a Joint Model</a></p>
<p>9 0.18659879 <a title="148-tfidf-9" href="./acl-2013-LABR%3A_A_Large_Scale_Arabic_Book_Reviews_Dataset.html">211 acl-2013-LABR: A Large Scale Arabic Book Reviews Dataset</a></p>
<p>10 0.17762272 <a title="148-tfidf-10" href="./acl-2013-Utterance-Level_Multimodal_Sentiment_Analysis.html">379 acl-2013-Utterance-Level Multimodal Sentiment Analysis</a></p>
<p>11 0.17527977 <a title="148-tfidf-11" href="./acl-2013-Dual_Training_and_Dual_Prediction_for_Polarity_Classification.html">131 acl-2013-Dual Training and Dual Prediction for Polarity Classification</a></p>
<p>12 0.16795087 <a title="148-tfidf-12" href="./acl-2013-Linking_Tweets_to_News%3A_A_Framework_to_Enrich_Short_Text_Data_in_Social_Media.html">233 acl-2013-Linking Tweets to News: A Framework to Enrich Short Text Data in Social Media</a></p>
<p>13 0.16729069 <a title="148-tfidf-13" href="./acl-2013-Multilingual_Affect_Polarity_and_Valence_Prediction_in_Metaphor-Rich_Texts.html">253 acl-2013-Multilingual Affect Polarity and Valence Prediction in Metaphor-Rich Texts</a></p>
<p>14 0.16615802 <a title="148-tfidf-14" href="./acl-2013-Using_Conceptual_Class_Attributes_to_Characterize_Social_Media_Users.html">373 acl-2013-Using Conceptual Class Attributes to Characterize Social Media Users</a></p>
<p>15 0.1643309 <a title="148-tfidf-15" href="./acl-2013-Character-to-Character_Sentiment_Analysis_in_Shakespeare%27s_Plays.html">79 acl-2013-Character-to-Character Sentiment Analysis in Shakespeare's Plays</a></p>
<p>16 0.15822145 <a title="148-tfidf-16" href="./acl-2013-The_Haves_and_the_Have-Nots%3A_Leveraging_Unlabelled_Corpora_for_Sentiment_Analysis.html">345 acl-2013-The Haves and the Have-Nots: Leveraging Unlabelled Corpora for Sentiment Analysis</a></p>
<p>17 0.14688778 <a title="148-tfidf-17" href="./acl-2013-Connotation_Lexicon%3A_A_Dash_of_Sentiment_Beneath_the_Surface_Meaning.html">91 acl-2013-Connotation Lexicon: A Dash of Sentiment Beneath the Surface Meaning</a></p>
<p>18 0.13539889 <a title="148-tfidf-18" href="./acl-2013-Detecting_Turnarounds_in_Sentiment_Analysis%3A_Thwarting.html">117 acl-2013-Detecting Turnarounds in Sentiment Analysis: Thwarting</a></p>
<p>19 0.1328847 <a title="148-tfidf-19" href="./acl-2013-Microblogs_as_Parallel_Corpora.html">240 acl-2013-Microblogs as Parallel Corpora</a></p>
<p>20 0.12955965 <a title="148-tfidf-20" href="./acl-2013-Generating_Recommendation_Dialogs_by_Extracting_Information_from_User_Reviews.html">168 acl-2013-Generating Recommendation Dialogs by Extracting Information from User Reviews</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.201), (1, 0.354), (2, 0.001), (3, 0.313), (4, -0.015), (5, -0.09), (6, 0.081), (7, 0.131), (8, 0.21), (9, -0.008), (10, 0.076), (11, -0.035), (12, 0.018), (13, -0.076), (14, 0.048), (15, 0.066), (16, 0.081), (17, -0.047), (18, 0.022), (19, 0.07), (20, 0.011), (21, 0.071), (22, -0.042), (23, 0.009), (24, 0.023), (25, -0.019), (26, -0.062), (27, 0.047), (28, -0.026), (29, 0.029), (30, -0.074), (31, -0.012), (32, -0.014), (33, -0.021), (34, 0.016), (35, 0.001), (36, 0.028), (37, 0.008), (38, -0.037), (39, -0.082), (40, -0.036), (41, 0.06), (42, 0.003), (43, -0.046), (44, -0.006), (45, 0.044), (46, 0.034), (47, 0.036), (48, 0.027), (49, 0.004)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9791705 <a title="148-lsi-1" href="./acl-2013-Exploring_Sentiment_in_Social_Media%3A_Bootstrapping_Subjectivity_Clues_from_Multilingual_Twitter_Streams.html">148 acl-2013-Exploring Sentiment in Social Media: Bootstrapping Subjectivity Clues from Multilingual Twitter Streams</a></p>
<p>Author: Svitlana Volkova ; Theresa Wilson ; David Yarowsky</p><p>Abstract: We study subjective language media and create Twitter-specific lexicons via bootstrapping sentiment-bearing terms from multilingual Twitter streams. Starting with a domain-independent, highprecision sentiment lexicon and a large pool of unlabeled data, we bootstrap Twitter-specific sentiment lexicons, using a small amount of labeled data to guide the process. Our experiments on English, Spanish and Russian show that the resulting lexicons are effective for sentiment classification for many underexplored languages in social media.</p><p>2 0.84103119 <a title="148-lsi-2" href="./acl-2013-Identifying_Sentiment_Words_Using_an_Optimization-based_Model_without_Seed_Words.html">188 acl-2013-Identifying Sentiment Words Using an Optimization-based Model without Seed Words</a></p>
<p>Author: Hongliang Yu ; Zhi-Hong Deng ; Shiyingxue Li</p><p>Abstract: Sentiment Word Identification (SWI) is a basic technique in many sentiment analysis applications. Most existing researches exploit seed words, and lead to low robustness. In this paper, we propose a novel optimization-based model for SWI. Unlike previous approaches, our model exploits the sentiment labels of documents instead of seed words. Several experiments on real datasets show that WEED is effective and outperforms the state-of-the-art methods with seed words.</p><p>3 0.83280951 <a title="148-lsi-3" href="./acl-2013-Detecting_Event-Related_Links_and_Sentiments_from_Social_Media_Texts.html">115 acl-2013-Detecting Event-Related Links and Sentiments from Social Media Texts</a></p>
<p>Author: Alexandra Balahur ; Hristo Tanev</p><p>Abstract: Nowadays, the importance of Social Media is constantly growing, as people often use such platforms to share mainstream media news and comment on the events that they relate to. As such, people no loger remain mere spectators to the events that happen in the world, but become part of them, commenting on their developments and the entities involved, sharing their opinions and distributing related content. This paper describes a system that links the main events detected from clusters of newspaper articles to tweets related to them, detects complementary information sources from the links they contain and subsequently applies sentiment analysis to classify them into positive, negative and neutral. In this manner, readers can follow the main events happening in the world, both from the perspective of mainstream as well as social media and the public’s perception on them. This system will be part of the EMM media monitoring framework working live and it will be demonstrated using Google Earth.</p><p>4 0.76941693 <a title="148-lsi-4" href="./acl-2013-Sentiment_Relevance.html">318 acl-2013-Sentiment Relevance</a></p>
<p>Author: Christian Scheible ; Hinrich Schutze</p><p>Abstract: A number of different notions, including subjectivity, have been proposed for distinguishing parts of documents that convey sentiment from those that do not. We propose a new concept, sentiment relevance, to make this distinction and argue that it better reflects the requirements of sentiment analysis systems. We demonstrate experimentally that sentiment relevance and subjectivity are related, but different. Since no large amount of labeled training data for our new notion of sentiment relevance is available, we investigate two semi-supervised methods for creating sentiment relevance classifiers: a distant supervision approach that leverages structured information about the domain of the reviews; and transfer learning on feature representations based on lexical taxonomies that enables knowledge transfer. We show that both methods learn sentiment relevance classifiers that perform well.</p><p>5 0.7579335 <a title="148-lsi-5" href="./acl-2013-Character-to-Character_Sentiment_Analysis_in_Shakespeare%27s_Plays.html">79 acl-2013-Character-to-Character Sentiment Analysis in Shakespeare's Plays</a></p>
<p>Author: Eric T. Nalisnick ; Henry S. Baird</p><p>Abstract: We present an automatic method for analyzing sentiment dynamics between characters in plays. This literary format’s structured dialogue allows us to make assumptions about who is participating in a conversation. Once we have an idea of who a character is speaking to, the sentiment in his or her speech can be attributed accordingly, allowing us to generate lists of a character’s enemies and allies as well as pinpoint scenes critical to a character’s emotional development. Results of experiments on Shakespeare’s plays are presented along with discussion of how this work can be extended to unstructured texts (i.e. novels).</p><p>6 0.74239206 <a title="148-lsi-6" href="./acl-2013-Detecting_Turnarounds_in_Sentiment_Analysis%3A_Thwarting.html">117 acl-2013-Detecting Turnarounds in Sentiment Analysis: Thwarting</a></p>
<p>7 0.69857025 <a title="148-lsi-7" href="./acl-2013-Dual_Training_and_Dual_Prediction_for_Polarity_Classification.html">131 acl-2013-Dual Training and Dual Prediction for Polarity Classification</a></p>
<p>8 0.6608296 <a title="148-lsi-8" href="./acl-2013-Connotation_Lexicon%3A_A_Dash_of_Sentiment_Beneath_the_Surface_Meaning.html">91 acl-2013-Connotation Lexicon: A Dash of Sentiment Beneath the Surface Meaning</a></p>
<p>9 0.65583014 <a title="148-lsi-9" href="./acl-2013-LABR%3A_A_Large_Scale_Arabic_Book_Reviews_Dataset.html">211 acl-2013-LABR: A Large Scale Arabic Book Reviews Dataset</a></p>
<p>10 0.60852313 <a title="148-lsi-10" href="./acl-2013-Exploiting_Topic_based_Twitter_Sentiment_for_Stock_Prediction.html">147 acl-2013-Exploiting Topic based Twitter Sentiment for Stock Prediction</a></p>
<p>11 0.6061452 <a title="148-lsi-11" href="./acl-2013-Aid_is_Out_There%3A_Looking_for_Help_from_Tweets_during_a_Large_Scale_Disaster.html">42 acl-2013-Aid is Out There: Looking for Help from Tweets during a Large Scale Disaster</a></p>
<p>12 0.56985384 <a title="148-lsi-12" href="./acl-2013-Utterance-Level_Multimodal_Sentiment_Analysis.html">379 acl-2013-Utterance-Level Multimodal Sentiment Analysis</a></p>
<p>13 0.55799842 <a title="148-lsi-13" href="./acl-2013-A_Bayesian_Model_for_Joint_Unsupervised_Induction_of_Sentiment%2C_Aspect_and_Discourse_Representations.html">2 acl-2013-A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations</a></p>
<p>14 0.55169994 <a title="148-lsi-14" href="./acl-2013-Detecting_Chronic_Critics_Based_on_Sentiment_Polarity_and_User%C3%A2%E2%80%A2%C5%BDs_Behavior_in_Social_Media.html">114 acl-2013-Detecting Chronic Critics Based on Sentiment Polarity and Userâ•Žs Behavior in Social Media</a></p>
<p>15 0.54735059 <a title="148-lsi-15" href="./acl-2013-The_Haves_and_the_Have-Nots%3A_Leveraging_Unlabelled_Corpora_for_Sentiment_Analysis.html">345 acl-2013-The Haves and the Have-Nots: Leveraging Unlabelled Corpora for Sentiment Analysis</a></p>
<p>16 0.54469883 <a title="148-lsi-16" href="./acl-2013-An_Empirical_Study_on_Uncertainty_Identification_in_Social_Media_Context.html">45 acl-2013-An Empirical Study on Uncertainty Identification in Social Media Context</a></p>
<p>17 0.53490096 <a title="148-lsi-17" href="./acl-2013-Exploiting_Social_Media_for_Natural_Language_Processing%3A_Bridging_the_Gap_between_Language-centric_and_Real-world_Applications.html">146 acl-2013-Exploiting Social Media for Natural Language Processing: Bridging the Gap between Language-centric and Real-world Applications</a></p>
<p>18 0.50957245 <a title="148-lsi-18" href="./acl-2013-Probabilistic_Sense_Sentiment_Similarity_through_Hidden_Emotions.html">284 acl-2013-Probabilistic Sense Sentiment Similarity through Hidden Emotions</a></p>
<p>19 0.50617784 <a title="148-lsi-19" href="./acl-2013-Generating_Recommendation_Dialogs_by_Extracting_Information_from_User_Reviews.html">168 acl-2013-Generating Recommendation Dialogs by Extracting Information from User Reviews</a></p>
<p>20 0.49340183 <a title="148-lsi-20" href="./acl-2013-Multilingual_Affect_Polarity_and_Valence_Prediction_in_Metaphor-Rich_Texts.html">253 acl-2013-Multilingual Affect Polarity and Valence Prediction in Metaphor-Rich Texts</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.048), (6, 0.029), (11, 0.089), (24, 0.05), (26, 0.11), (28, 0.011), (35, 0.067), (38, 0.015), (42, 0.032), (44, 0.011), (48, 0.02), (66, 0.233), (70, 0.037), (88, 0.055), (90, 0.022), (95, 0.073)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.81537592 <a title="148-lda-1" href="./acl-2013-Exploring_Sentiment_in_Social_Media%3A_Bootstrapping_Subjectivity_Clues_from_Multilingual_Twitter_Streams.html">148 acl-2013-Exploring Sentiment in Social Media: Bootstrapping Subjectivity Clues from Multilingual Twitter Streams</a></p>
<p>Author: Svitlana Volkova ; Theresa Wilson ; David Yarowsky</p><p>Abstract: We study subjective language media and create Twitter-specific lexicons via bootstrapping sentiment-bearing terms from multilingual Twitter streams. Starting with a domain-independent, highprecision sentiment lexicon and a large pool of unlabeled data, we bootstrap Twitter-specific sentiment lexicons, using a small amount of labeled data to guide the process. Our experiments on English, Spanish and Russian show that the resulting lexicons are effective for sentiment classification for many underexplored languages in social media.</p><p>2 0.70893353 <a title="148-lda-2" href="./acl-2013-Feature-Based_Selection_of_Dependency_Paths_in_Ad_Hoc_Information_Retrieval.html">158 acl-2013-Feature-Based Selection of Dependency Paths in Ad Hoc Information Retrieval</a></p>
<p>Author: K. Tamsin Maxwell ; Jon Oberlander ; W. Bruce Croft</p><p>Abstract: Techniques that compare short text segments using dependency paths (or simply, paths) appear in a wide range of automated language processing applications including question answering (QA). However, few models in ad hoc information retrieval (IR) use paths for document ranking due to the prohibitive cost of parsing a retrieval collection. In this paper, we introduce a flexible notion of paths that describe chains of words on a dependency path. These chains, or catenae, are readily applied in standard IR models. Informative catenae are selected using supervised machine learning with linguistically informed features and compared to both non-linguistic terms and catenae selected heuristically with filters derived from work on paths. Automatically selected catenae of 1-2 words deliver significant performance gains on three TREC collections.</p><p>3 0.68005413 <a title="148-lda-3" href="./acl-2013-Language_Independent_Connectivity_Strength_Features_for_Phrase_Pivot_Statistical_Machine_Translation.html">214 acl-2013-Language Independent Connectivity Strength Features for Phrase Pivot Statistical Machine Translation</a></p>
<p>Author: Ahmed El Kholy ; Nizar Habash ; Gregor Leusch ; Evgeny Matusov ; Hassan Sawaf</p><p>Abstract: An important challenge to statistical machine translation (SMT) is the lack of parallel data for many language pairs. One common solution is to pivot through a third language for which there exist parallel corpora with the source and target languages. Although pivoting is a robust technique, it introduces some low quality translations. In this paper, we present two language-independent features to improve the quality of phrase-pivot based SMT. The features, source connectivity strength and target connectivity strength reflect the quality of projected alignments between the source and target phrases in the pivot phrase table. We show positive results (0.6 BLEU points) on Persian-Arabic SMT as a case study.</p><p>4 0.61480033 <a title="148-lda-4" href="./acl-2013-Sentiment_Relevance.html">318 acl-2013-Sentiment Relevance</a></p>
<p>Author: Christian Scheible ; Hinrich Schutze</p><p>Abstract: A number of different notions, including subjectivity, have been proposed for distinguishing parts of documents that convey sentiment from those that do not. We propose a new concept, sentiment relevance, to make this distinction and argue that it better reflects the requirements of sentiment analysis systems. We demonstrate experimentally that sentiment relevance and subjectivity are related, but different. Since no large amount of labeled training data for our new notion of sentiment relevance is available, we investigate two semi-supervised methods for creating sentiment relevance classifiers: a distant supervision approach that leverages structured information about the domain of the reviews; and transfer learning on feature representations based on lexical taxonomies that enables knowledge transfer. We show that both methods learn sentiment relevance classifiers that perform well.</p><p>5 0.612432 <a title="148-lda-5" href="./acl-2013-Dual_Training_and_Dual_Prediction_for_Polarity_Classification.html">131 acl-2013-Dual Training and Dual Prediction for Polarity Classification</a></p>
<p>Author: Rui Xia ; Tao Wang ; Xuelei Hu ; Shoushan Li ; Chengqing Zong</p><p>Abstract: Bag-of-words (BOW) is now the most popular way to model text in machine learning based sentiment classification. However, the performance of such approach sometimes remains rather limited due to some fundamental deficiencies of the BOW model. In this paper, we focus on the polarity shift problem, and propose a novel approach, called dual training and dual prediction (DTDP), to address it. The basic idea of DTDP is to first generate artificial samples that are polarity-opposite to the original samples by polarity reversion, and then leverage both the original and opposite samples for (dual) training and (dual) prediction. Experimental results on four datasets demonstrate the effectiveness of the proposed approach for polarity classification. 1</p><p>6 0.6119923 <a title="148-lda-6" href="./acl-2013-Mapping_Source_to_Target_Strings_without_Alignment_by_Analogical_Learning%3A_A_Case_Study_with_Transliteration.html">236 acl-2013-Mapping Source to Target Strings without Alignment by Analogical Learning: A Case Study with Transliteration</a></p>
<p>7 0.60881048 <a title="148-lda-7" href="./acl-2013-Co-Regression_for_Cross-Language_Review_Rating_Prediction.html">81 acl-2013-Co-Regression for Cross-Language Review Rating Prediction</a></p>
<p>8 0.60781282 <a title="148-lda-8" href="./acl-2013-Explicit_and_Implicit_Syntactic_Features_for_Text_Classification.html">144 acl-2013-Explicit and Implicit Syntactic Features for Text Classification</a></p>
<p>9 0.6077584 <a title="148-lda-9" href="./acl-2013-A_Bayesian_Model_for_Joint_Unsupervised_Induction_of_Sentiment%2C_Aspect_and_Discourse_Representations.html">2 acl-2013-A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations</a></p>
<p>10 0.60455561 <a title="148-lda-10" href="./acl-2013-Unsupervised_Consonant-Vowel_Prediction_over_Hundreds_of_Languages.html">369 acl-2013-Unsupervised Consonant-Vowel Prediction over Hundreds of Languages</a></p>
<p>11 0.60338944 <a title="148-lda-11" href="./acl-2013-Summarization_Through_Submodularity_and_Dispersion.html">333 acl-2013-Summarization Through Submodularity and Dispersion</a></p>
<p>12 0.60286224 <a title="148-lda-12" href="./acl-2013-Crawling_microblogging_services_to_gather_language-classified_URLs._Workflow_and_case_study.html">95 acl-2013-Crawling microblogging services to gather language-classified URLs. Workflow and case study</a></p>
<p>13 0.59945822 <a title="148-lda-13" href="./acl-2013-Detecting_Turnarounds_in_Sentiment_Analysis%3A_Thwarting.html">117 acl-2013-Detecting Turnarounds in Sentiment Analysis: Thwarting</a></p>
<p>14 0.59741914 <a title="148-lda-14" href="./acl-2013-Improving_pairwise_coreference_models_through_feature_space_hierarchy_learning.html">196 acl-2013-Improving pairwise coreference models through feature space hierarchy learning</a></p>
<p>15 0.59679693 <a title="148-lda-15" href="./acl-2013-Universal_Dependency_Annotation_for_Multilingual_Parsing.html">368 acl-2013-Universal Dependency Annotation for Multilingual Parsing</a></p>
<p>16 0.59662354 <a title="148-lda-16" href="./acl-2013-Bilingually-Guided_Monolingual_Dependency_Grammar_Induction.html">70 acl-2013-Bilingually-Guided Monolingual Dependency Grammar Induction</a></p>
<p>17 0.59408748 <a title="148-lda-17" href="./acl-2013-Generating_Synthetic_Comparable_Questions_for_News_Articles.html">169 acl-2013-Generating Synthetic Comparable Questions for News Articles</a></p>
<p>18 0.59373134 <a title="148-lda-18" href="./acl-2013-Filling_Knowledge_Base_Gaps_for_Distant_Supervision_of_Relation_Extraction.html">159 acl-2013-Filling Knowledge Base Gaps for Distant Supervision of Relation Extraction</a></p>
<p>19 0.59341955 <a title="148-lda-19" href="./acl-2013-Real-World_Semi-Supervised_Learning_of_POS-Taggers_for_Low-Resource_Languages.html">295 acl-2013-Real-World Semi-Supervised Learning of POS-Taggers for Low-Resource Languages</a></p>
<p>20 0.59258926 <a title="148-lda-20" href="./acl-2013-Using_Conceptual_Class_Attributes_to_Characterize_Social_Media_Users.html">373 acl-2013-Using Conceptual Class Attributes to Characterize Social Media Users</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
