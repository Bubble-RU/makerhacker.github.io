<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>248 acl-2013-Modelling Annotator Bias with Multi-task Gaussian Processes: An Application to Machine Translation Quality Estimation</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-248" href="#">acl2013-248</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>248 acl-2013-Modelling Annotator Bias with Multi-task Gaussian Processes: An Application to Machine Translation Quality Estimation</h1>
<br/><p>Source: <a title="acl-2013-248-pdf" href="http://aclweb.org/anthology//P/P13/P13-1004.pdf">pdf</a></p><p>Author: Trevor Cohn ; Lucia Specia</p><p>Abstract: Annotating linguistic data is often a complex, time consuming and expensive endeavour. Even with strict annotation guidelines, human subjects often deviate in their analyses, each bringing different biases, interpretations of the task and levels of consistency. We present novel techniques for learning from the outputs of multiple annotators while accounting for annotator specific behaviour. These techniques use multi-task Gaussian Processes to learn jointly a series of annotator and metadata specific models, while explicitly representing correlations between models which can be learned directly from data. Our experiments on two machine translation quality estimation datasets show uniform significant accuracy gains from multi-task learning, and consistently outperform strong baselines.</p><p>Reference: <a title="acl-2013-248-reference" href="../acl2013_reference/acl-2013-Modelling_Annotator_Bias_with_Multi-task_Gaussian_Processes%3A_An_Application_to_Machine_Translation_Quality_Estimation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Even with strict annotation guidelines, human subjects often deviate in their analyses, each bringing different biases, interpretations of the task and levels of consistency. [sent-6, score-0.143]
</p><p>2 We present novel techniques for learning from the outputs of multiple annotators while accounting for annotator specific behaviour. [sent-7, score-0.345]
</p><p>3 These techniques use multi-task Gaussian Processes to learn jointly a series of annotator and metadata specific models, while explicitly representing correlations between models which can be learned directly from data. [sent-8, score-0.243]
</p><p>4 Our experiments on two machine translation quality estimation datasets show  uniform significant accuracy gains from multi-task learning, and consistently outperform strong baselines. [sent-9, score-0.32]
</p><p>5 Particularly in –  –  highly subjective annotation tasks, the differences between annotators cannot be captured by simple models such as scaling all instances of a certain annotator by a factor. [sent-15, score-0.4]
</p><p>6 This is the case, for example, of annotations on the quality of sentences generated using machine translation (MT) systems, which are often used to build quality estimation models (Blatz et al. [sent-17, score-0.379]
</p><p>7 For example, certain annotators may prefer translations produced by rulebased systems as these tend to be more grammatical, while others would prefer sentences produced by statistical systems with more adequate lexical choices. [sent-21, score-0.245]
</p><p>8 Likewise, some annotators can be biased by the complexity of the source sentence: lengthy sentences are often (subconsciously) assumed to be of low quality by some annotators. [sent-22, score-0.29]
</p><p>9 An extreme case is the judgement of quality through –  post-editing time: annotators have different typing speeds, as well as levels of expertise in the task of post-editing, proficiency levels in the language pair, and knowledge of the terminology used in particular sentences. [sent-23, score-0.371]
</p><p>10 Overall, these myriad of factors affecting quality judgements make the modelling of multiple annotators a very challenging problem. [sent-26, score-0.437]
</p><p>11 Most related work on quality assurance for data annotation has been developed in the context of  crowdsourcing. [sent-32, score-0.145]
</p><p>12 Common practices include filtering out annotators who substantially deviate from a gold-standard set or present unexpected behaviours (Raykar et al. [sent-33, score-0.247]
</p><p>13 Another relevant strand of work aims to model legitimate, systematic biases in annotators (including both non-experts and experts), such as the fact that some annotators tend to be more negative than others, and that some annotators use a wider or narrower range of values (Flach et al. [sent-39, score-0.678]
</p><p>14 In this paper we model the task of predicting the quality of sentence translations using datasets that have been annotated by several judges with different levels of expertise and reliability, containing translations from a variety of MT systems and on a range of different types of sentences. [sent-47, score-0.31]
</p><p>15 Our use of multi-task learning allows the modelling of a diversity of truths, while also recognising that they are rarely independent of one another (annotators often agree) by explicitly accounting for inter-annotator correlations. [sent-49, score-0.215]
</p><p>16 We develop multi-task learning models by representing intra-task transfer simply and explicitly as part of a parameterised kernel function. [sent-51, score-0.337]
</p><p>17 (2008) by explicitly modelling intra-task transfer, which is learned automatically from the data, in order to robustly handle outlier tasks and task variances. [sent-59, score-0.189]
</p><p>18 In addition to showing empirical performance gains on quality estimation applications, an important contribution of this paper is in introducing Gaussian Processes to the NLP community,1 a technique that has great potential to further performance in a wider range of NLP applications. [sent-61, score-0.201]
</p><p>19 2  Quality Estimation  Quality estimation (QE) for MT aims at providing  an estimate on the quality of each translated segment typically a sentence without access to reference translations. [sent-63, score-0.16]
</p><p>20 Examples of applications of QE include improving post-editing efficiency by filtering out low quality segments which would require more effort and time to correct than translating from scratch (Specia et al. [sent-65, score-0.14]
</p><p>21 , 2009), selecting high quality segments to be published as they are, without post-editing (Soricut and Echihabi, 2010), selecting a translation from either an MT system or a translation memory for post-editing (He et al. [sent-66, score-0.26]
</p><p>22 QE is generally addressed as a machine learning task using a variety of linear and kernel-based regression or classification algorithms to induce models from examples of translations described through a number of features and annotated for –  –  quality. [sent-70, score-0.248]
</p><p>23 As typical of subjective annotation tasks, QE datasets should contain multiple annotators to lead to models that are representative. [sent-79, score-0.324]
</p><p>24 Learning models from datasets annotated by multiple annotators remains an open challenge in QE, as we show in Section 4. [sent-86, score-0.273]
</p><p>25 The post-editing effort scores were produced independently by three professional translators based on a previously post-edited translation by a fourth translator. [sent-101, score-0.241]
</p><p>26 In an attempt to accommodate for systematic biases among annotators, the final effort score was computed as the weighted average be-  tween the three PE-effort scores, with more weight given to the judges with higher standard deviation from their own mean score. [sent-102, score-0.161]
</p><p>27 The post-editing was done by eight native speakers of Spanish, including five professional translators and three translation students. [sent-111, score-0.16]
</p><p>28 3  Gaussian Process Regression  Machine learning models for quality estimation typically treat the problem as regression, seeking to model the relationship between features of the text input and the human quality judgement as a continuous response variable. [sent-119, score-0.454]
</p><p>29 Popular choices include Support Vector Machines (SVMs), which have been shown to perform well for quality estimation (Callison-Burch et al. [sent-120, score-0.16]
</p><p>30 , 2012) using nonlinear kernel functions such as radial basis func34  tions. [sent-121, score-0.308]
</p><p>31 In this paper we consider Gaussian Processes (GP) (Rasmussen and Williams, 2006), a  probabilistic machine learning framework incorporating kernels and Bayesian non-parametrics, widely considered state-of-the-art for regression. [sent-122, score-0.184]
</p><p>32 In our regression task3 the data consists of n pairs D = {(xi, yi)}, where xi ∈ RF is a Fpdiamiresn Dsio=n al {fe(axture v}e,c twohr arned x yi ∈ RR is the response variable. [sent-126, score-0.292]
</p><p>33 Each instance is a t∈ran Rsl iasti othne a rnedthe feature vector encodes its linguistic features; the response variable is a numerical quality judgement: post editing time or likert score. [sent-127, score-0.253]
</p><p>34 Each response value is then generated from the function evaluated at the corresponding data point, yi = f(xi) + η, where η ∼ N(0, σn2) is added white-noise). [sent-130, score-0.172]
</p><p>35 (here, 0) and a covariance kernel function k(x, x0). [sent-135, score-0.322]
</p><p>36 This intuition is embodied in the squared exponential kernel (a. [sent-140, score-0.435]
</p><p>37 n)]T are the kernel evaluations betwe)en· t·hke( txest point and the training set, and {Kij = k(xi, xj)} is tahned k tehrene trl (gram) met,atr ainxd over the training points. [sent-164, score-0.336]
</p><p>38 GP regression also permits an analytic formulation of the marginal likelihood, p(y|X) = Rf p(y|X, f)p(f), awrghiinchal can lbieh uosde,d f(oyr| Xmo)d =el Rtraining (X are t)h,e training inputs). [sent-169, score-0.2]
</p><p>39 At first glance GPs resemble SVMs, which also admit kernels such as the popular squared exponential kernel in Eq. [sent-177, score-0.581]
</p><p>40 Moreover GPs provide greater flexibility in fitting the kernel hyperparameters even for complex composite  kernels. [sent-180, score-0.382]
</p><p>41 In typical usage, the kernel hyperparameters for an SVM are fit using held-out estimation, which is inefficient and often involves tying together parameters to limit the search complexity (e. [sent-181, score-0.342]
</p><p>42 Multiple-kernel learning (G¨ onen and Alpaydın, 2011) goes some way to addressing this problem within the SVM framework, however this technique is limited to reweighting linear combinations of kernels and has high computational complexity. [sent-184, score-0.184]
</p><p>43 1 Multi-task Gaussian Process Models Until now we have considered a standard regression scenario, where each training point is labelled with a single output variable. [sent-186, score-0.158]
</p><p>44 In order to model multiple different annotators jointly, i. [sent-187, score-0.196]
</p><p>45 ,seMd itso explain  the response values for all the instances for that task (subject to noise). [sent-196, score-0.205]
</p><p>46 This can be implemented by augmenting each input point with an additional task identity feature, which is paired with a single y response, and integrated into a GP model with the standard training and inference algorithms. [sent-205, score-0.141]
</p><p>47 4 In moving to a task-augmented data representation, we need to revise our kernel function. [sent-206, score-0.26]
</p><p>48 We use  a separable multi-task kernel (Bonilla et al. [sent-207, score-0.299]
</p><p>49 standard kernel over the input points, typically a squared exponential (see Eq. [sent-213, score-0.435]
</p><p>50 This corresponds to independent modelling of each task, although all models share the same data kernel, so this setting is not strictly equivalent to independent training with independent pertask data kernels (with different hyperparameters). [sent-220, score-0.511]
</p><p>51 Similarly, we might choose to use a single noise variance, σn2, or an independent noise variance hyperparameter per task. [sent-221, score-0.443]
</p><p>52 Pooled Another extreme is B = 1, which ignores the task identity, corresponding to pooling  the multi-task data into one large set. [sent-222, score-0.185]
</p><p>53 (201 1) present a method for applying GPs for modelling multi-annotator data using this pooling kernel with independent per-task noise terms. [sent-224, score-0.705]
</p><p>54 5 For dissimilar tasks, a high value of a allows each task to be modelled independently, while for more similar tasks low a allows the use of a large pool of 4Note that the separable kernel (Eq. [sent-231, score-0.386]
</p><p>55 3) gives rise to block structured kernel matrices which permit various optimisations (Bonilla et al. [sent-232, score-0.26]
</p><p>56 5Note that larger values of a need not affect the overall magnitude of k, which can be down-scaled by the σf2 factor in the data kernel (Eq. [sent-237, score-0.26]
</p><p>57 A scaled version of this kernel has  been shown to correspond to mean regularisation in SVMs when combined with a linear data kernel (Evgeniou et al. [sent-240, score-0.648]
</p><p>58 A similar multi-task kernel was proposed by Daum e´ III (2007), using a linear data kernel and a = 1, which has shown to result in excellent performance across a range of NLP problems. [sent-242, score-0.52]
</p><p>59 , to allow individual outlier annotators to be modelled independently of the others, by assigning a high value to ad. [sent-247, score-0.231]
</p><p>60 , all annotators are assumed to have similar quality in that they deviate from the mean to the same degree. [sent-250, score-0.407]
</p><p>61 In our quality estimation experiments we consider as metadata the MT system which produced the translation, and the identity of the source sentence being translated. [sent-256, score-0.354]
</p><p>62 One way of integrating such metadata would be to define a separate task for every observed combination of metadata values, in which case we treat the metadata as a task descriptor. [sent-258, score-0.478]
</p><p>63 Doing so naively would however incur a significant penalty, as each task will have very few training instances resulting in inaccurate models, even with the inter-task kernel approaches defined above. [sent-259, score-0.381]
</p><p>64 We instead extend the task-level kernels to use the task descriptors directly to represent task correlations. [sent-260, score-0.264]
</p><p>65 Let be a square covariance matrix  B(i)  for the ith task descriptor of M, with a column and row for each value (e. [sent-261, score-0.157]
</p><p>66 We redefine the task level kernel using paired inputs (x, m), where m are the task descriptors,  k? [sent-265, score-0.342]
</p><p>67 In our experiments we consider the Combined and Combined+ kernels, which allow the model to learn the relative importance of each descriptor in terms of independent modelling versus pooling the data. [sent-270, score-0.375]
</p><p>68 Baselines: The baselines use the SVM regression algorithm with radial basis function kernel and parameters γ, ? [sent-278, score-0.466]
</p><p>69 The simpler models were initialised with all hyperparameters set to one, while more complex models were initialised using the 6The software used to extract these (and other) features can be downloaded from http : / /www . [sent-284, score-0.218]
</p><p>70 8103  1:  Single-task  WMT 12 dataset,  learning  results  on the  trained and evaluated against  the weighted averaged response variable. [sent-309, score-0.16]
</p><p>71 is a  baseline which predicts the training mean, SVM uses the same system as the WMT12 QE task, and the remainder are GP regression models with different kernels (all include additive noise). [sent-310, score-0.304]
</p><p>72 For instance, models using ARD kernels were initialised from an equivalent isotropic kernel (which ties all the hyperparameters together), and independent per-task noise models were initialised from a single noise model. [sent-312, score-0.986]
</p><p>73 2  rPesponse  where yi −valˆ yues and yˆi are  Results  Our experiments aim to demonstrate the efficacy  of GP regression, both the single task and multitask settings, compared to competitive baselines. [sent-316, score-0.163]
</p><p>74 WMT12: Single task We start by comparing GP regression with alternative approaches using the WMT12 dataset on the standard task of predicting a weighted mean quality rating (as it was done in the WMT12 QE shared task). [sent-317, score-0.362]
</p><p>75 Table 1 shows the results for baseline approaches and the GP models, using a variety of different kernels (see Rasmussen and Williams (2006) for details of the kernel functions). [sent-318, score-0.406]
</p><p>76 In terms of kernels, the linear kernel performs comparatively worse than non-linear kernels. [sent-320, score-0.26]
</p><p>77 Shown above are the training mean baseline single-task learning approaches, and multitask learning models, with the columns showing macro average error rates over all three response values. [sent-342, score-0.374]
</p><p>78 All systems use a squared exponential ARD kernel in a product with the named taskkernel, and with added noise (per-task noise is denoted {N}, otherwise has shared noise). [sent-343, score-0.683]
</p><p>79 µ,  tial ARD kernel has the best performance under both measures of error, and for this reason we use this kernel in our subsequent experiments. [sent-344, score-0.52]
</p><p>80 First, the independently trained models do well, outperforming the pooled model with fixed noise, indicating that naively pooling the data is counter-productive and that there are annotatorspecific biases. [sent-352, score-0.433]
</p><p>81 Including per-annotator noise to the pooled model provides a boost in performance, however the best results are obtained using the Combined kernel which brings the strengths of both the independent and pooled settings. [sent-353, score-0.967]
</p><p>82 An explanation for the contradictory findings about the importance 38  of independent noise is that differences between annotators can already be explained by the MTL model using the multi-task kernel, and need not be explained as noise. [sent-355, score-0.395]
</p><p>83 01, weighting the value of pooling much more highly than independent training. [sent-360, score-0.219]
</p><p>84 To test this, we trained single-task, pooled and multi-task models on randomly sub-sampled training sets of different sizes, and plot their error rates in Figure 1. [sent-362, score-0.292]
</p><p>85 As expected, for very small datasets pooling outperforms single task learning, however for modest sized datasets of ≥ 90 training instances pooling was din dfeartiasore. [sent-363, score-0.563]
</p><p>86 The same experiments run with multiplyannotated instances showed much weaker performance, presumably due to the more limited sample of input points and poorer fit of the ARD kernel hyperparameters. [sent-371, score-0.302]
</p><p>87 We model the logarithm of the per-word post-editing time, in order to make the response variable more comparable between annotators and across sentences, and generally more Gaussian in shape. [sent-374, score-0.318]
</p><p>88 Single-task learning performs only a little better than these baselines, although some approaches such as the naive pooling perform terribly. [sent-381, score-0.182]
</p><p>89 Interestingly, adding the per-task noise models to the pooling approach greatly improves its performance. [sent-383, score-0.268]
</p><p>90 The multi-task learning methods performed best when using the annotator identity as the task descriptor, and less well for the MT system and sentence pair, where they only slightly improved over the baseline. [sent-384, score-0.252]
</p><p>91 The effect of adding per-task noise to these models was less marked than for the pooled models, as in the WMT12 experiments. [sent-386, score-0.378]
</p><p>92 Inspecting the learned hyperparameters, the combined mod-  els learned a large bias towards independent learning over pooling, in contrast to the WMT12 experiments. [sent-387, score-0.175]
</p><p>93 5  Conclusion  µ  This paper presented a novel approach for learning from human linguistic annotations by explicitly training models of individual annotators (and possibly additional metadata) using multi-task learning. [sent-389, score-0.314]
</p><p>94 Our method using Gaussian Processes is flexible, allowing easy learning of inter-dependences between different annotators and other task meta39  Model  µA µS  µT  Pooled SVM IndependentA SVM EasyAdapt SVM  MAE  RMSE  0. [sent-390, score-0.275]
</p><p>95 Shown above are the training mean and SVM baselines, single-task learning and multi-task learning results (micro average). [sent-435, score-0.18]
</p><p>96 The subscripts denote the task split: annotator (A), MT system (S) and sentence identity (T). [sent-436, score-0.214]
</p><p>97 Our experiments showed how our approach outperformed competitive baselines on two machine translation quality regression problems, including the highly challenging problem of predicting post-editing time. [sent-438, score-0.335]
</p><p>98 Further, our approach contributes to work based on cheap and fast crowdsourcing of linguistic annotation by minimising the need for careful data curation and quality control. [sent-445, score-0.145]
</p><p>99 Protein interaction detection in sentences via gaussian processes; a preliminary evaluation. [sent-529, score-0.152]
</p><p>100 Eliminating spammers and ranking annotators for crowdsourced labeling tasks. [sent-549, score-0.196]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('kernel', 0.26), ('qe', 0.257), ('pooled', 0.254), ('gp', 0.23), ('annotators', 0.196), ('ard', 0.175), ('gaussian', 0.152), ('kernels', 0.146), ('gps', 0.145), ('pooling', 0.144), ('rasmussen', 0.136), ('metadata', 0.132), ('easyadapt', 0.132), ('noise', 0.124), ('response', 0.122), ('regression', 0.12), ('mae', 0.118), ('squared', 0.111), ('annotator', 0.111), ('modelling', 0.102), ('specia', 0.097), ('bonilla', 0.097), ('quality', 0.094), ('translation', 0.083), ('hyperparameters', 0.082), ('mt', 0.08), ('raykar', 0.078), ('translators', 0.077), ('datasets', 0.077), ('hyperparameter', 0.075), ('independent', 0.075), ('williams', 0.074), ('svm', 0.073), ('multitask', 0.072), ('lucia', 0.069), ('processes', 0.069), ('initialised', 0.068), ('estimation', 0.066), ('mean', 0.066), ('alvarez', 0.066), ('groot', 0.066), ('kdata', 0.066), ('koponen', 0.066), ('exponential', 0.064), ('combined', 0.062), ('identity', 0.062), ('covariance', 0.062), ('mtl', 0.058), ('descriptor', 0.054), ('annotation', 0.051), ('deviate', 0.051), ('rmse', 0.051), ('blatz', 0.051), ('yi', 0.05), ('biases', 0.049), ('translations', 0.049), ('rogers', 0.048), ('smoothness', 0.048), ('radial', 0.048), ('effort', 0.046), ('tasks', 0.046), ('judgements', 0.045), ('variance', 0.045), ('alpayd', 0.044), ('combineda', 0.044), ('gpml', 0.044), ('heterotopic', 0.044), ('independenta', 0.044), ('plitt', 0.044), ('polajnar', 0.044), ('welinder', 0.044), ('marginal', 0.042), ('svms', 0.042), ('fm', 0.042), ('instances', 0.042), ('annotations', 0.042), ('task', 0.041), ('wider', 0.041), ('fitting', 0.04), ('judgement', 0.04), ('parameterised', 0.039), ('ipeirotis', 0.039), ('singly', 0.039), ('isotropic', 0.039), ('flach', 0.039), ('separable', 0.039), ('whitehill', 0.039), ('training', 0.038), ('baselines', 0.038), ('learning', 0.038), ('rf', 0.038), ('editing', 0.037), ('posterior', 0.036), ('provost', 0.036), ('shipeng', 0.036), ('streamline', 0.036), ('diag', 0.036), ('descriptors', 0.036), ('independently', 0.035), ('soricut', 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999845 <a title="248-tfidf-1" href="./acl-2013-Modelling_Annotator_Bias_with_Multi-task_Gaussian_Processes%3A_An_Application_to_Machine_Translation_Quality_Estimation.html">248 acl-2013-Modelling Annotator Bias with Multi-task Gaussian Processes: An Application to Machine Translation Quality Estimation</a></p>
<p>Author: Trevor Cohn ; Lucia Specia</p><p>Abstract: Annotating linguistic data is often a complex, time consuming and expensive endeavour. Even with strict annotation guidelines, human subjects often deviate in their analyses, each bringing different biases, interpretations of the task and levels of consistency. We present novel techniques for learning from the outputs of multiple annotators while accounting for annotator specific behaviour. These techniques use multi-task Gaussian Processes to learn jointly a series of annotator and metadata specific models, while explicitly representing correlations between models which can be learned directly from data. Our experiments on two machine translation quality estimation datasets show uniform significant accuracy gains from multi-task learning, and consistently outperform strong baselines.</p><p>2 0.31771281 <a title="248-tfidf-2" href="./acl-2013-QuEst_-_A_translation_quality_estimation_framework.html">289 acl-2013-QuEst - A translation quality estimation framework</a></p>
<p>Author: Lucia Specia ; ; ; Kashif Shah ; Jose G.C. de Souza ; Trevor Cohn</p><p>Abstract: We describe QUEST, an open source framework for machine translation quality estimation. The framework allows the extraction of several quality indicators from source segments, their translations, external resources (corpora, language models, topic models, etc.), as well as language tools (parsers, part-of-speech tags, etc.). It also provides machine learning algorithms to build quality estimation models. We benchmark the framework on a number of datasets and discuss the efficacy of features and algorithms.</p><p>3 0.29989696 <a title="248-tfidf-3" href="./acl-2013-Reducing_Annotation_Effort_for_Quality_Estimation_via_Active_Learning.html">300 acl-2013-Reducing Annotation Effort for Quality Estimation via Active Learning</a></p>
<p>Author: Daniel Beck ; Lucia Specia ; Trevor Cohn</p><p>Abstract: Quality estimation models provide feedback on the quality of machine translated texts. They are usually trained on humanannotated datasets, which are very costly due to its task-specific nature. We investigate active learning techniques to reduce the size of these datasets and thus annotation effort. Experiments on a number of datasets show that with as little as 25% of the training instances it is possible to obtain similar or superior performance compared to that of the complete datasets. In other words, our active learning query strategies can not only reduce annotation effort but can also result in better quality predictors. ,t .</p><p>4 0.1431632 <a title="248-tfidf-4" href="./acl-2013-Embedding_Semantic_Similarity_in_Tree_Kernels_for_Domain_Adaptation_of_Relation_Extraction.html">134 acl-2013-Embedding Semantic Similarity in Tree Kernels for Domain Adaptation of Relation Extraction</a></p>
<p>Author: Barbara Plank ; Alessandro Moschitti</p><p>Abstract: Relation Extraction (RE) is the task of extracting semantic relationships between entities in text. Recent studies on relation extraction are mostly supervised. The clear drawback of supervised methods is the need of training data: labeled data is expensive to obtain, and there is often a mismatch between the training data and the data the system will be applied to. This is the problem of domain adaptation. In this paper, we propose to combine (i) term generalization approaches such as word clustering and latent semantic analysis (LSA) and (ii) structured kernels to improve the adaptability of relation extractors to new text genres/domains. The empirical evaluation on ACE 2005 domains shows that a suitable combination of syntax and lexical generalization is very promising for domain adaptation.</p><p>5 0.14119294 <a title="248-tfidf-5" href="./acl-2013-Explicit_and_Implicit_Syntactic_Features_for_Text_Classification.html">144 acl-2013-Explicit and Implicit Syntactic Features for Text Classification</a></p>
<p>Author: Matt Post ; Shane Bergsma</p><p>Abstract: Syntactic features are useful for many text classification tasks. Among these, tree kernels (Collins and Duffy, 2001) have been perhaps the most robust and effective syntactic tool, appealing for their empirical success, but also because they do not require an answer to the difficult question of which tree features to use for a given task. We compare tree kernels to different explicit sets of tree features on five diverse tasks, and find that explicit features often perform as well as tree kernels on accuracy and always in orders of magnitude less time, and with smaller models. Since explicit features are easy to generate and use (with publicly avail- able tools) , we suggest they should always be included as baseline comparisons in tree kernel method evaluations.</p><p>6 0.13849321 <a title="248-tfidf-6" href="./acl-2013-On_the_Predictability_of_Human_Assessment%3A_when_Matrix_Completion_Meets_NLP_Evaluation.html">263 acl-2013-On the Predictability of Human Assessment: when Matrix Completion Meets NLP Evaluation</a></p>
<p>7 0.12348527 <a title="248-tfidf-7" href="./acl-2013-Collective_Annotation_of_Linguistic_Resources%3A_Basic_Principles_and_a_Formal_Model.html">83 acl-2013-Collective Annotation of Linguistic Resources: Basic Principles and a Formal Model</a></p>
<p>8 0.1101748 <a title="248-tfidf-8" href="./acl-2013-Learning_Semantic_Textual_Similarity_with_Structural_Representations.html">222 acl-2013-Learning Semantic Textual Similarity with Structural Representations</a></p>
<p>9 0.10505758 <a title="248-tfidf-9" href="./acl-2013-Annotating_named_entities_in_clinical_text_by_combining_pre-annotation_and_active_learning.html">52 acl-2013-Annotating named entities in clinical text by combining pre-annotation and active learning</a></p>
<p>10 0.10220879 <a title="248-tfidf-10" href="./acl-2013-SORT%3A_An_Interactive_Source-Rewriting_Tool_for_Improved_Translation.html">305 acl-2013-SORT: An Interactive Source-Rewriting Tool for Improved Translation</a></p>
<p>11 0.097562 <a title="248-tfidf-11" href="./acl-2013-A_Markov_Model_of_Machine_Translation_using_Non-parametric_Bayesian_Inference.html">10 acl-2013-A Markov Model of Machine Translation using Non-parametric Bayesian Inference</a></p>
<p>12 0.094030552 <a title="248-tfidf-12" href="./acl-2013-Models_of_Translation_Competitions.html">250 acl-2013-Models of Translation Competitions</a></p>
<p>13 0.091746002 <a title="248-tfidf-13" href="./acl-2013-Recognizing_Identical_Events_with_Graph_Kernels.html">296 acl-2013-Recognizing Identical Events with Graph Kernels</a></p>
<p>14 0.090644509 <a title="248-tfidf-14" href="./acl-2013-Learning_Non-linear_Features_for_Machine_Translation_Using_Gradient_Boosting_Machines.html">221 acl-2013-Learning Non-linear Features for Machine Translation Using Gradient Boosting Machines</a></p>
<p>15 0.090477452 <a title="248-tfidf-15" href="./acl-2013-English-to-Russian_MT_evaluation_campaign.html">135 acl-2013-English-to-Russian MT evaluation campaign</a></p>
<p>16 0.081834249 <a title="248-tfidf-16" href="./acl-2013-Co-Regression_for_Cross-Language_Review_Rating_Prediction.html">81 acl-2013-Co-Regression for Cross-Language Review Rating Prediction</a></p>
<p>17 0.081823364 <a title="248-tfidf-17" href="./acl-2013-Machine_Translation_Detection_from_Monolingual_Web-Text.html">235 acl-2013-Machine Translation Detection from Monolingual Web-Text</a></p>
<p>18 0.081543639 <a title="248-tfidf-18" href="./acl-2013-Scalable_Decipherment_for_Machine_Translation_via_Hash_Sampling.html">307 acl-2013-Scalable Decipherment for Machine Translation via Hash Sampling</a></p>
<p>19 0.080789074 <a title="248-tfidf-19" href="./acl-2013-Additive_Neural_Networks_for_Statistical_Machine_Translation.html">38 acl-2013-Additive Neural Networks for Statistical Machine Translation</a></p>
<p>20 0.079534292 <a title="248-tfidf-20" href="./acl-2013-Improving_machine_translation_by_training_against_an_automatic_semantic_frame_based_evaluation_metric.html">195 acl-2013-Improving machine translation by training against an automatic semantic frame based evaluation metric</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.236), (1, -0.015), (2, 0.085), (3, -0.006), (4, -0.018), (5, -0.011), (6, 0.058), (7, -0.019), (8, 0.038), (9, 0.086), (10, -0.035), (11, 0.063), (12, -0.121), (13, 0.019), (14, -0.19), (15, -0.061), (16, -0.141), (17, 0.076), (18, 0.05), (19, -0.026), (20, 0.201), (21, 0.027), (22, -0.134), (23, 0.045), (24, -0.161), (25, -0.04), (26, -0.062), (27, 0.03), (28, -0.059), (29, 0.078), (30, -0.121), (31, 0.014), (32, 0.128), (33, 0.08), (34, -0.207), (35, 0.077), (36, 0.04), (37, 0.043), (38, -0.028), (39, 0.125), (40, -0.103), (41, -0.009), (42, 0.093), (43, -0.069), (44, 0.054), (45, -0.152), (46, -0.036), (47, 0.1), (48, -0.002), (49, -0.07)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93190074 <a title="248-lsi-1" href="./acl-2013-Modelling_Annotator_Bias_with_Multi-task_Gaussian_Processes%3A_An_Application_to_Machine_Translation_Quality_Estimation.html">248 acl-2013-Modelling Annotator Bias with Multi-task Gaussian Processes: An Application to Machine Translation Quality Estimation</a></p>
<p>Author: Trevor Cohn ; Lucia Specia</p><p>Abstract: Annotating linguistic data is often a complex, time consuming and expensive endeavour. Even with strict annotation guidelines, human subjects often deviate in their analyses, each bringing different biases, interpretations of the task and levels of consistency. We present novel techniques for learning from the outputs of multiple annotators while accounting for annotator specific behaviour. These techniques use multi-task Gaussian Processes to learn jointly a series of annotator and metadata specific models, while explicitly representing correlations between models which can be learned directly from data. Our experiments on two machine translation quality estimation datasets show uniform significant accuracy gains from multi-task learning, and consistently outperform strong baselines.</p><p>2 0.83189154 <a title="248-lsi-2" href="./acl-2013-Reducing_Annotation_Effort_for_Quality_Estimation_via_Active_Learning.html">300 acl-2013-Reducing Annotation Effort for Quality Estimation via Active Learning</a></p>
<p>Author: Daniel Beck ; Lucia Specia ; Trevor Cohn</p><p>Abstract: Quality estimation models provide feedback on the quality of machine translated texts. They are usually trained on humanannotated datasets, which are very costly due to its task-specific nature. We investigate active learning techniques to reduce the size of these datasets and thus annotation effort. Experiments on a number of datasets show that with as little as 25% of the training instances it is possible to obtain similar or superior performance compared to that of the complete datasets. In other words, our active learning query strategies can not only reduce annotation effort but can also result in better quality predictors. ,t .</p><p>3 0.80920023 <a title="248-lsi-3" href="./acl-2013-QuEst_-_A_translation_quality_estimation_framework.html">289 acl-2013-QuEst - A translation quality estimation framework</a></p>
<p>Author: Lucia Specia ; ; ; Kashif Shah ; Jose G.C. de Souza ; Trevor Cohn</p><p>Abstract: We describe QUEST, an open source framework for machine translation quality estimation. The framework allows the extraction of several quality indicators from source segments, their translations, external resources (corpora, language models, topic models, etc.), as well as language tools (parsers, part-of-speech tags, etc.). It also provides machine learning algorithms to build quality estimation models. We benchmark the framework on a number of datasets and discuss the efficacy of features and algorithms.</p><p>4 0.72146606 <a title="248-lsi-4" href="./acl-2013-On_the_Predictability_of_Human_Assessment%3A_when_Matrix_Completion_Meets_NLP_Evaluation.html">263 acl-2013-On the Predictability of Human Assessment: when Matrix Completion Meets NLP Evaluation</a></p>
<p>Author: Guillaume Wisniewski</p><p>Abstract: This paper tackles the problem of collecting reliable human assessments. We show that knowing multiple scores for each example instead of a single score results in a more reliable estimation of a system quality. To reduce the cost of collecting these multiple ratings, we propose to use matrix completion techniques to predict some scores knowing only scores of other judges and some common ratings. Even if prediction performance is pretty low, decisions made using the predicted score proved to be more reliable than decision based on a single rating of each example.</p><p>5 0.60767943 <a title="248-lsi-5" href="./acl-2013-Annotating_named_entities_in_clinical_text_by_combining_pre-annotation_and_active_learning.html">52 acl-2013-Annotating named entities in clinical text by combining pre-annotation and active learning</a></p>
<p>Author: Maria Skeppstedt</p><p>Abstract: For expanding a corpus of clinical text, annotated for named entities, a method that combines pre-tagging with a version of active learning is proposed. In order to facilitate annotation and to avoid bias, two alternative automatic pre-taggings are presented to the annotator, without revealing which of them is given a higher confidence by the pre-tagging system. The task of the annotator is to select the correct version among these two alternatives. To minimise the instances in which none of the presented pre-taggings is correct, the texts presented to the annotator are actively selected from a pool of unlabelled text, with the selection criterion that one of the presented pre-taggings should have a high probability of being correct, while still being useful for improving the result of an automatic classifier.</p><p>6 0.54805112 <a title="248-lsi-6" href="./acl-2013-The_Impact_of_Topic_Bias_on_Quality_Flaw_Prediction_in_Wikipedia.html">346 acl-2013-The Impact of Topic Bias on Quality Flaw Prediction in Wikipedia</a></p>
<p>7 0.54801536 <a title="248-lsi-7" href="./acl-2013-English-to-Russian_MT_evaluation_campaign.html">135 acl-2013-English-to-Russian MT evaluation campaign</a></p>
<p>8 0.54584885 <a title="248-lsi-8" href="./acl-2013-Models_of_Translation_Competitions.html">250 acl-2013-Models of Translation Competitions</a></p>
<p>9 0.51556349 <a title="248-lsi-9" href="./acl-2013-SORT%3A_An_Interactive_Source-Rewriting_Tool_for_Improved_Translation.html">305 acl-2013-SORT: An Interactive Source-Rewriting Tool for Improved Translation</a></p>
<p>10 0.51174003 <a title="248-lsi-10" href="./acl-2013-Explicit_and_Implicit_Syntactic_Features_for_Text_Classification.html">144 acl-2013-Explicit and Implicit Syntactic Features for Text Classification</a></p>
<p>11 0.48857918 <a title="248-lsi-11" href="./acl-2013-Automatically_Predicting_Sentence_Translation_Difficulty.html">64 acl-2013-Automatically Predicting Sentence Translation Difficulty</a></p>
<p>12 0.4874143 <a title="248-lsi-12" href="./acl-2013-Collective_Annotation_of_Linguistic_Resources%3A_Basic_Principles_and_a_Formal_Model.html">83 acl-2013-Collective Annotation of Linguistic Resources: Basic Principles and a Formal Model</a></p>
<p>13 0.48060545 <a title="248-lsi-13" href="./acl-2013-A_Novel_Classifier_Based_on_Quantum_Computation.html">14 acl-2013-A Novel Classifier Based on Quantum Computation</a></p>
<p>14 0.46217588 <a title="248-lsi-14" href="./acl-2013-Recognizing_Rare_Social_Phenomena_in_Conversation%3A_Empowerment_Detection_in_Support_Group_Chatrooms.html">298 acl-2013-Recognizing Rare Social Phenomena in Conversation: Empowerment Detection in Support Group Chatrooms</a></p>
<p>15 0.44183519 <a title="248-lsi-15" href="./acl-2013-TransDoop%3A_A_Map-Reduce_based_Crowdsourced_Translation_for_Complex_Domain.html">355 acl-2013-TransDoop: A Map-Reduce based Crowdsourced Translation for Complex Domain</a></p>
<p>16 0.43654558 <a title="248-lsi-16" href="./acl-2013-Embedding_Semantic_Similarity_in_Tree_Kernels_for_Domain_Adaptation_of_Relation_Extraction.html">134 acl-2013-Embedding Semantic Similarity in Tree Kernels for Domain Adaptation of Relation Extraction</a></p>
<p>17 0.43553919 <a title="248-lsi-17" href="./acl-2013-Learning_Semantic_Textual_Similarity_with_Structural_Representations.html">222 acl-2013-Learning Semantic Textual Similarity with Structural Representations</a></p>
<p>18 0.43231466 <a title="248-lsi-18" href="./acl-2013-Part-of-speech_tagging_with_antagonistic_adversaries.html">277 acl-2013-Part-of-speech tagging with antagonistic adversaries</a></p>
<p>19 0.42498666 <a title="248-lsi-19" href="./acl-2013-Mapping_Source_to_Target_Strings_without_Alignment_by_Analogical_Learning%3A_A_Case_Study_with_Transliteration.html">236 acl-2013-Mapping Source to Target Strings without Alignment by Analogical Learning: A Case Study with Transliteration</a></p>
<p>20 0.41901538 <a title="248-lsi-20" href="./acl-2013-Machine_Translation_Detection_from_Monolingual_Web-Text.html">235 acl-2013-Machine Translation Detection from Monolingual Web-Text</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.066), (6, 0.092), (11, 0.038), (15, 0.013), (24, 0.041), (26, 0.068), (28, 0.011), (35, 0.084), (42, 0.052), (48, 0.038), (70, 0.076), (88, 0.016), (90, 0.05), (95, 0.082), (99, 0.206)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.86943936 <a title="248-lda-1" href="./acl-2013-Using_Integer_Linear_Programming_in_Concept-to-Text_Generation_to_Produce_More_Compact_Texts.html">375 acl-2013-Using Integer Linear Programming in Concept-to-Text Generation to Produce More Compact Texts</a></p>
<p>Author: Gerasimos Lampouras ; Ion Androutsopoulos</p><p>Abstract: We present an ILP model of concept-totext generation. Unlike pipeline architectures, our model jointly considers the choices in content selection, lexicalization, and aggregation to avoid greedy decisions and produce more compact texts.</p><p>same-paper 2 0.82437563 <a title="248-lda-2" href="./acl-2013-Modelling_Annotator_Bias_with_Multi-task_Gaussian_Processes%3A_An_Application_to_Machine_Translation_Quality_Estimation.html">248 acl-2013-Modelling Annotator Bias with Multi-task Gaussian Processes: An Application to Machine Translation Quality Estimation</a></p>
<p>Author: Trevor Cohn ; Lucia Specia</p><p>Abstract: Annotating linguistic data is often a complex, time consuming and expensive endeavour. Even with strict annotation guidelines, human subjects often deviate in their analyses, each bringing different biases, interpretations of the task and levels of consistency. We present novel techniques for learning from the outputs of multiple annotators while accounting for annotator specific behaviour. These techniques use multi-task Gaussian Processes to learn jointly a series of annotator and metadata specific models, while explicitly representing correlations between models which can be learned directly from data. Our experiments on two machine translation quality estimation datasets show uniform significant accuracy gains from multi-task learning, and consistently outperform strong baselines.</p><p>3 0.82047707 <a title="248-lda-3" href="./acl-2013-ImpAr%3A_A_Deterministic_Algorithm_for_Implicit_Semantic_Role_Labelling.html">189 acl-2013-ImpAr: A Deterministic Algorithm for Implicit Semantic Role Labelling</a></p>
<p>Author: Egoitz Laparra ; German Rigau</p><p>Abstract: This paper presents a novel deterministic algorithm for implicit Semantic Role Labeling. The system exploits a very simple but relevant discursive property, the argument coherence over different instances of a predicate. The algorithm solves the implicit arguments sequentially, exploiting not only explicit but also the implicit arguments previously solved. In addition, we empirically demonstrate that the algorithm obtains very competitive and robust performances with respect to supervised approaches that require large amounts of costly training data.</p><p>4 0.76589143 <a title="248-lda-4" href="./acl-2013-The_Effect_of_Higher-Order_Dependency_Features_in_Discriminative_Phrase-Structure_Parsing.html">343 acl-2013-The Effect of Higher-Order Dependency Features in Discriminative Phrase-Structure Parsing</a></p>
<p>Author: Greg Coppola ; Mark Steedman</p><p>Abstract: Higher-order dependency features are known to improve dependency parser accuracy. We investigate the incorporation of such features into a cube decoding phrase-structure parser. We find considerable gains in accuracy on the range of standard metrics. What is especially interesting is that we find strong, statistically significant gains on dependency recovery on out-of-domain tests (Brown vs. WSJ). This suggests that higher-order dependency features are not simply overfitting the training material.</p><p>5 0.69103515 <a title="248-lda-5" href="./acl-2013-Collective_Annotation_of_Linguistic_Resources%3A_Basic_Principles_and_a_Formal_Model.html">83 acl-2013-Collective Annotation of Linguistic Resources: Basic Principles and a Formal Model</a></p>
<p>Author: Ulle Endriss ; Raquel Fernandez</p><p>Abstract: Crowdsourcing, which offers new ways of cheaply and quickly gathering large amounts of information contributed by volunteers online, has revolutionised the collection of labelled data. Yet, to create annotated linguistic resources from this data, we face the challenge of having to combine the judgements of a potentially large group of annotators. In this paper we investigate how to aggregate individual annotations into a single collective annotation, taking inspiration from the field of social choice theory. We formulate a general formal model for collective annotation and propose several aggregation methods that go beyond the commonly used majority rule. We test some of our methods on data from a crowdsourcing experiment on textual entailment annotation.</p><p>6 0.68795407 <a title="248-lda-6" href="./acl-2013-Adapting_Discriminative_Reranking_to_Grounded_Language_Learning.html">36 acl-2013-Adapting Discriminative Reranking to Grounded Language Learning</a></p>
<p>7 0.67986131 <a title="248-lda-7" href="./acl-2013-Models_of_Translation_Competitions.html">250 acl-2013-Models of Translation Competitions</a></p>
<p>8 0.67807847 <a title="248-lda-8" href="./acl-2013-Joint_Word_Alignment_and_Bilingual_Named_Entity_Recognition_Using_Dual_Decomposition.html">210 acl-2013-Joint Word Alignment and Bilingual Named Entity Recognition Using Dual Decomposition</a></p>
<p>9 0.67109782 <a title="248-lda-9" href="./acl-2013-Modeling_Thesis_Clarity_in_Student_Essays.html">246 acl-2013-Modeling Thesis Clarity in Student Essays</a></p>
<p>10 0.66879302 <a title="248-lda-10" href="./acl-2013-Automated_Pyramid_Scoring_of_Summaries_using_Distributional_Semantics.html">59 acl-2013-Automated Pyramid Scoring of Summaries using Distributional Semantics</a></p>
<p>11 0.66596645 <a title="248-lda-11" href="./acl-2013-Statistical_Machine_Translation_Improves_Question_Retrieval_in_Community_Question_Answering_via_Matrix_Factorization.html">329 acl-2013-Statistical Machine Translation Improves Question Retrieval in Community Question Answering via Matrix Factorization</a></p>
<p>12 0.66590357 <a title="248-lda-12" href="./acl-2013-A_Sentence_Compression_Based_Framework_to_Query-Focused_Multi-Document_Summarization.html">18 acl-2013-A Sentence Compression Based Framework to Query-Focused Multi-Document Summarization</a></p>
<p>13 0.66550702 <a title="248-lda-13" href="./acl-2013-Language-Independent_Discriminative_Parsing_of_Temporal_Expressions.html">212 acl-2013-Language-Independent Discriminative Parsing of Temporal Expressions</a></p>
<p>14 0.66507179 <a title="248-lda-14" href="./acl-2013-Embedding_Semantic_Similarity_in_Tree_Kernels_for_Domain_Adaptation_of_Relation_Extraction.html">134 acl-2013-Embedding Semantic Similarity in Tree Kernels for Domain Adaptation of Relation Extraction</a></p>
<p>15 0.66466498 <a title="248-lda-15" href="./acl-2013-Summarization_Through_Submodularity_and_Dispersion.html">333 acl-2013-Summarization Through Submodularity and Dispersion</a></p>
<p>16 0.66028446 <a title="248-lda-16" href="./acl-2013-Explicit_and_Implicit_Syntactic_Features_for_Text_Classification.html">144 acl-2013-Explicit and Implicit Syntactic Features for Text Classification</a></p>
<p>17 0.65994787 <a title="248-lda-17" href="./acl-2013-A_Lightweight_and_High_Performance_Monolingual_Word_Aligner.html">9 acl-2013-A Lightweight and High Performance Monolingual Word Aligner</a></p>
<p>18 0.65887648 <a title="248-lda-18" href="./acl-2013-An_Infinite_Hierarchical_Bayesian_Model_of_Phrasal_Translation.html">46 acl-2013-An Infinite Hierarchical Bayesian Model of Phrasal Translation</a></p>
<p>19 0.65860969 <a title="248-lda-19" href="./acl-2013-Non-Monotonic_Sentence_Alignment_via_Semisupervised_Learning.html">259 acl-2013-Non-Monotonic Sentence Alignment via Semisupervised Learning</a></p>
<p>20 0.65748543 <a title="248-lda-20" href="./acl-2013-Using_Supervised_Bigram-based_ILP_for_Extractive_Summarization.html">377 acl-2013-Using Supervised Bigram-based ILP for Extractive Summarization</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
