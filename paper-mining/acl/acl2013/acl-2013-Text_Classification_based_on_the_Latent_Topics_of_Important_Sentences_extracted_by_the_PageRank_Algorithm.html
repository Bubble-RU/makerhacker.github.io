<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>341 acl-2013-Text Classification based on the Latent Topics of Important Sentences extracted by the PageRank Algorithm</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-341" href="#">acl2013-341</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>341 acl-2013-Text Classification based on the Latent Topics of Important Sentences extracted by the PageRank Algorithm</h1>
<br/><p>Source: <a title="acl-2013-341-pdf" href="http://aclweb.org/anthology//P/P13/P13-3007.pdf">pdf</a></p><p>Author: Yukari Ogura ; Ichiro Kobayashi</p><p>Abstract: In this paper, we propose a method to raise the accuracy of text classification based on latent topics, reconsidering the techniques necessary for good classification for example, to decide important sentences in a document, the sentences with important words are usually regarded as important sentences. In this case, tf.idf is often used to decide important words. On the other hand, we apply the PageRank algorithm to rank important words in each document. Furthermore, before clustering documents, we refine the target documents by representing them as a collection of important sentences in each document. We then classify the documents based on latent information in the documents. As a clustering method, we employ the k-means algorithm and inves– tigate how our proposed method works for good clustering. We conduct experiments with Reuters-21578 corpus under various conditions of important sentence extraction, using latent and surface information for clustering, and have confirmed that our proposed method provides better result among various conditions for clustering.</p><p>Reference: <a title="acl-2013-341-reference" href="../acl2013_reference/acl-2013-Text_Classification_based_on_the_Latent_Topics_of_Important_Sentences_extracted_by_the_PageRank_Algorithm_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 On the other hand, we apply the PageRank algorithm to rank important words in each document. [sent-5, score-0.311]
</p><p>2 Furthermore, before clustering documents, we refine the target documents by representing them as a collection of important sentences in each document. [sent-6, score-0.858]
</p><p>3 We then classify the documents based on latent information in the documents. [sent-7, score-0.525]
</p><p>4 As a clustering method, we employ the k-means algorithm and inves–  tigate how our proposed method works for good clustering. [sent-8, score-0.382]
</p><p>5 We conduct experiments with Reuters-21578 corpus under various conditions of important sentence extraction, using latent and surface information for clustering, and have confirmed that our proposed method provides better result among various conditions for clustering. [sent-9, score-0.603]
</p><p>6 1 Introduction Text classification is an essential issue in the field of natural language processing and many techniques using latent topics have so far been proposed and used under many purposes. [sent-10, score-0.541]
</p><p>7 In this paper, we aim to raise the accuracy of text classification using latent information by reconsidering elemental techniques necessary for good classification in the following three points: 1) important words extraction 46 koba} @ i . [sent-11, score-0.83]
</p><p>8 j p s to decide important words in documents is a crucial issue for text classification, tf. [sent-14, score-0.684]
</p><p>9 , 1998) for the issue, because the algorithm scores the centrality of a node in a graph, and important words should be regarded as having the centrality (Hassan et al. [sent-17, score-0.687]
</p><p>10 Besides, the algorithm can detect centrality in any kind of graph, so we can find important words for any purposes. [sent-19, score-0.457]
</p><p>11 This is because we use latent information to classify documents, and documents with high topic coherence tend to have high PMI of words in the documents (Newman et al. [sent-21, score-0.997]
</p><p>12 So, we construct a graph from a viewpoint of text classification based on latent topics. [sent-23, score-0.574]
</p><p>13 2) Refinement of the original documents we recompile the original documents with a collection of the extracted important sentences in order to refine the original documents for more sensitive to be classified. [sent-24, score-1.334]
</p><p>14 3) Information used for classification we use latent information estimated by latent Dirichlet allocation (LDA) (Blei et al. [sent-25, score-0.533]
</p><p>15 , 2003) to classify documents, and compare the results of the cases using both surface and latent information. [sent-26, score-0.286]
</p><p>16 We experiment text classification with Reuters-21578 corpus; evaluate the result of our method with the results of those which have various other settings for classification; —  —  and show the usefulness of our proposed method. [sent-27, score-0.294]
</p><p>17 , 2007), they have applied a random-walk model on a graph constructed based on the words which co-occur within a given window size, e. [sent-33, score-0.197]
</p><p>18 (2005) have introduced association rule mining to decide important words for text classification. [sent-38, score-0.364]
</p><p>19 have used a PageRank-style algorithm to rank words and shown their method is useful for text classification. [sent-40, score-0.219]
</p><p>20 They apply topic-specific PageRank  to a graph of both words and documents, and introduce Polarity PageRank, a new semi-supervised sentiment classifier that integrates lexicon induction with document classification. [sent-43, score-0.356]
</p><p>21 As a study related to topic detection by important words obtained by the PageRank algorithm, Kubek et al. [sent-44, score-0.351]
</p><p>22 (201 1) has detected topics in a document by constructing a graph of word co-occurrence and applied the PageRank algorithm on it. [sent-45, score-0.503]
</p><p>23 To weight words is not the issue for only text classification, but also an important issue for text summarization, Erkan et al. [sent-46, score-0.363]
</p><p>24 They use PageRank scores to extract sentences which have centrality among other sentences for generating a summary from multi-documents. [sent-49, score-0.418]
</p><p>25 On the other hand, since our method is to classify texts based on latent information. [sent-50, score-0.277]
</p><p>26 The graph used in our method is constructed based on word cooccurrence so that important words which are sensitive to latent information can be extracted by the PageRank algorithm. [sent-51, score-0.693]
</p><p>27 1 Extraction of important words To decide important words, tf. [sent-54, score-0.488]
</p><p>28 idf is often adopted, whereas, another methods expressing various relation among words in a form of a graph have been 47 proposed (2005; Hassan et al. [sent-55, score-0.233]
</p><p>29 , 2007) shows that the PageRank score is more clear to rank important words rather than tf. [sent-58, score-0.252]
</p><p>30 In this study, we refer to their method and use PageRank algorithm to decide important words. [sent-60, score-0.37]
</p><p>31 The algorithm has been used as the basic algorithm of Google search engine, and also used for many application to rank target information based on the centrality of information represented in the form of a graph. [sent-63, score-0.35]
</p><p>32 In this study, the important words are selected based on PageRank score of a graph which represents the relation among words. [sent-64, score-0.358]
</p><p>33 In other words, in order to obtain good important sentences for classi-  fication, it is of crucial to have a good graph (Zhu et al. [sent-65, score-0.404]
</p><p>34 , 2005) because the result will be considerably changed depending on what kind of a graph we will have for important words. [sent-66, score-0.353]
</p><p>35 In this study, since we use latent information for text classification, therefore, we construct a graph representing the relation of words from a viewpoint topic coherence. [sent-67, score-0.628]
</p><p>36 We then apply the PageRank algorithm to this graph to obtain a score for every word which is a measurement of its centrality the centrality of a word corresponds to the importance of a word. [sent-71, score-0.586]
</p><p>37 A small portion of a graph might look like the graph in Figure 1. [sent-72, score-0.298]
</p><p>38 2 Refinement of target documents After selecting important words, the important sentences are extracted until a predefined ratio of whole sentences in each document based on the selected  important words, and then we reproduce refined documents with a collection of extracted important sentences. [sent-74, score-1.855]
</p><p>39 An important sentence is decided by how many important words are included in the sentence. [sent-75, score-0.438]
</p><p>40 The refined documents are composed of the important sentences extracted from a viewpoint of latent information, i. [sent-76, score-0.981]
</p><p>41 , word co-occurrence, so they are proper to be classified based on latent information. [sent-78, score-0.245]
</p><p>42 3  Clustering based on latent topics  After obtaining a collection of refined documents for classification, we adopt LDA to estimate the latent topic probabilistic distributions over the target documents and use them for clustering. [sent-80, score-1.475]
</p><p>43 In this study, we use the topic probability distribution over documents to make a topic vector for each document, and then calculate the similarity among documents. [sent-81, score-0.509]
</p><p>44 1Important words determination The important words are decided based on tf. [sent-84, score-0.325]
</p><p>45 As for the words decided based on PageRank scores, we firstly have to make a graph on which the PargeRank algorithm is applied. [sent-86, score-0.324]
</p><p>46 In our study, we construct a graph based on word co-occurrence. [sent-87, score-0.185]
</p><p>47 So, important words are selected based on the words which have centrality in terms of word cooccurrence. [sent-88, score-0.446]
</p><p>48 In particular, in our study we select co-occurred words in each three sentences in a document, taking account of the influence of contextual information. [sent-89, score-0.185]
</p><p>49 2 Refinement of the target documents  After selecting the important words, we select the sentences with at least one of the words within the top 3 PageRank score as important sentences in each document, and then we reproduce refined documents with a collection of the extracted important sentences. [sent-91, score-1.565]
</p><p>50 3 Clustering based on latent topics As for the refined document obtained in step 2, the latent topics are estimated by means of LDA. [sent-93, score-1.04]
</p><p>51 Here, we decide the number of latent topics k in the target documents by measuring the value of perplexity P(w) shown in equation (1). [sent-94, score-0.842]
</p><p>52 The similarity of documents are measured by the Jenshen-Shannon divergence shown in equation (2). [sent-95, score-0.363]
</p><p>53 P(w) = exp(−N1∑log(∑θmzϕzwmn)) ∑mn  ∑z  (1) Here, N is the number of all words in the target documents, wmn is the n-th word in the m-th document; θ is the topic probabilistic distribu-  tion for the documents, and ϕ is the word probabilistic distribution for every topic. [sent-96, score-0.246]
</p><p>54 DJS(P||Q)  =12(∑xP(x)logPR((xx))+∑xlogQR((xx))) P(x) +2 Q(x) where,R(x)  4  =  (2)  Experiment  We evaluate our proposed method by comparing the accuracy of document clustering between our method and the method using tf. [sent-97, score-0.577]
</p><p>55 1 Experimental settings As the documents for experiments, we use Reuters21578 dataset 1 collected from the Reuters newswire in 1987. [sent-100, score-0.28]
</p><p>56 In our proposed method, the refined documents consisting of important sentences extracted from the original documents are classified, therefore, if there are not many sentences in a document, we will not be able to verify the usefulness of our proposed method. [sent-101, score-1.297]
</p><p>57 So, we use the documents which have more than 5 sentences in themselves. [sent-102, score-0.374]
</p><p>58 Of the  135 potential topic categories in Reuters-21578, referring to other clustering study (Erkan, 2006; 2005; Subramanya et al. [sent-103, score-0.473]
</p><p>59 com/resources/testcollections/reuters21578/ sequel, we use 792 documents whose number of words is 15,835 for experiments the 792 documents are the all documents which have more than 5 sentences in themselves in the corpus. [sent-109, score-0.982]
</p><p>60 The number of latent topics is decided by perplexity, and we decide the optimal number of topics by the minimum value of the average of 10 times trial, changing the number of topics ranging from 1 to 30. [sent-115, score-0.896]
</p><p>61 As the first step for clustering with our method, in this study we employ the k-means clustering algorithm because it is a representative and a simple –  clustering algorithm. [sent-116, score-0.867]
</p><p>62 As for a document di, li is the label provided to di by the clustering algorithm, and αi is the correct label for di. [sent-119, score-0.415]
</p><p>63 map (li) is the label provided to di by the k-means clustering algorithm. [sent-122, score-0.289]
</p><p>64 F =|C1|c∑i∈CF (ci)  (4)  As the initial data for the k-means clustering algorithm, a correct document of each category is randomly selected and provided. [sent-124, score-0.381]
</p><p>65 3 Experiment results To obtain the final result of the experiment, we applied the k-means clustering algorithm for 10 times 49  for the data set and averaged the results. [sent-127, score-0.314]
</p><p>66 Here, in the case of clustering the documents based on the topic probabilistic distribution by LDA, the topic distribution over documents θ is changed in every estimation. [sent-128, score-1.184]
</p><p>67 Therefore, we estimated θ for 8 times and then applied the k-means clustering algorithm with each θ for 10 times. [sent-129, score-0.348]
</p><p>68 The number of latent topics was estimated as 11by perplexity. [sent-131, score-0.406]
</p><p>69 To measure the latent similarity among documents, we construct topic vectors with the topic probabilistic distribution, and then adopt the Jensen-Shannon divergence to measures it, on the other hand, in the case of using document vectors we adopt cosine similarity. [sent-133, score-0.75]
</p><p>70 Table 1 and Table 2 show the cases of with and without refining the original documents by recom-  piling the original documents with the important sentences. [sent-134, score-0.855]
</p><p>71 v42a8397l5u10e Table 1: Extracting important sentences  Table 2: Without extracting important sentences  SCJiemnos ihlnare nit-sySim haielna nsrioutnyreA0c . [sent-138, score-0.552]
</p><p>72 43a20l65ue  Table 3, 4 show the number of words and sentences after applying each method to decide important words. [sent-140, score-0.453]
</p><p>73 idf, in the case that we use the same number of sentences in the experiment to experiment under the same conditions. [sent-144, score-0.202]
</p><p>74 4  Discussion  We see from the experiment results that as for the measures based on the Jenshen-Shannon divergence, both accuracy and F-value of the case where refined documents are clustered is better than the case where the original documents are clustered. [sent-152, score-0.933]
</p><p>75 We have conducted t-test to confirm whether or not there is significant difference between the cases: with and without extracting important sentences. [sent-153, score-0.231]
</p><p>76 When extracting important sentences, although the size ofthe document set to be clustered is smaller than the original set, the accuracy increases. [sent-155, score-0.464]
</p><p>77 So, it can be said that necessary information for clustering is adequately extracted from the original document set. [sent-156, score-0.472]
</p><p>78 From this, we have confirmed that the documents are well refined for better clustering by recompiling the documents with important sentences. [sent-157, score-1.174]
</p><p>79 We think the reason for this is because only important sentences representing the contents of a document are remained by refining the original documents and then it would become easier to measure the difference between probabilistic distributions of topics in a document. [sent-158, score-0.958]
</p><p>80 Moreover, as for extracting important sentences, we confirmed that the accuracy of the case of using PageRank scores is better than the case of using tf. [sent-159, score-0.434]
</p><p>81 By this, constructing a graph based on word co-occurrence of each 3 sentences in a document works well to rank important words, taking account of the context of the word. [sent-161, score-0.573]
</p><p>82 Therefore, the extraction of sentences including the words with high tf. [sent-172, score-0.174]
</p><p>83 The reason for low accuracy in the case of using cosine similarity for clustering is that it was observed that the range of similarity between documents is small, therefore, the identification of different categorized documents was not well achieved. [sent-174, score-0.911]
</p><p>84 Table 5 and Table 6 show the accuracy and Fvalue to the number of latent topics, respectively. [sent-175, score-0.267]
</p><p>85 idf in the case of the number of topics is 9,10,and 11. [sent-177, score-0.201]
</p><p>86 In particular, the highest score is made when the number of topics is 10 for  both evaluation measures we think the reason for this is because we used document sets of 10 categories, therefore, it is natural to make the highest score when the number of topics is 10. [sent-178, score-0.464]
</p><p>87 So, we had better look at the score of the case where the number of topics is 10 to compare the ability of clustering. [sent-179, score-0.201]
</p><p>88 By the result, we can say that PageRank is better in refining the documents so as they suit to be classified based on latent information. [sent-180, score-0.609]
</p><p>89 —  5  Conclusions  In this study, we have proposed a method of text clustering based on latent topics of important sentences in a document. [sent-181, score-0.987]
</p><p>90 The important sentences are extracted through important words decided by the PageRank algorithm. [sent-182, score-0.583]
</p><p>91 In order to verify the usefulness of our proposed method, we have conducted text clustering experiments with Reuters-21578 corpus under various conditions we have adopted either PageRank scores or tf. [sent-183, score-0.523]
</p><p>92 idf to decide important words for important sentence extraction, and then adopted the k-means clustering algorithm for the documents recompiled with the extracted important sentences based on either latent or surface informa—  tion. [sent-184, score-1.663]
</p><p>93 We see from the results of the experiments that the clustering based on latent information is generally better than that based on surface information in terms of clustering accuracy. [sent-185, score-0.754]
</p><p>94 Furthermore, deciding important words with PageRank scores is better than that with tf. [sent-186, score-0.25]
</p><p>95 Compared to the number of the extracted words in important sentences between PageRank scores and tf. [sent-188, score-0.395]
</p><p>96 idf, we see that the number of sentences extracted based on PageRank scores is smaller than that based on tf. [sent-189, score-0.186]
</p><p>97 idf, therefore, it can be thought that more contextsensitive sentences are extracted by adopting PageRank scores to decide important words. [sent-190, score-0.493]
</p><p>98 As future work, since clustering accuracy will be changed by how many sentences are compiled in a refined document set, therefore, we will consider a more sophisticated way of selecting proper important sentences. [sent-191, score-0.913]
</p><p>99 Or, to avoid the problem of selecting sentences, we will also directly use the words extracted as important words for clustering. [sent-192, score-0.342]
</p><p>100 Moreover, at this moment, we use only k-means clustering algorithm, so we will adopt our proposed method to other various clustering methods to confirm the usefulness of our method. [sent-193, score-0.702]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('pagerank', 0.611), ('documents', 0.28), ('clustering', 0.255), ('latent', 0.203), ('centrality', 0.189), ('topics', 0.169), ('important', 0.161), ('graph', 0.149), ('refined', 0.136), ('document', 0.126), ('erkan', 0.125), ('decide', 0.118), ('topic', 0.099), ('sentences', 0.094), ('classification', 0.093), ('hassan', 0.082), ('brin', 0.075), ('gunes', 0.068), ('kubek', 0.068), ('yukari', 0.068), ('zaiane', 0.068), ('decided', 0.068), ('accuracy', 0.064), ('confirmed', 0.062), ('newman', 0.061), ('reconsidering', 0.06), ('algorithm', 0.059), ('usefulness', 0.058), ('refinement', 0.057), ('viewpoint', 0.056), ('ogura', 0.056), ('refining', 0.054), ('textrank', 0.053), ('extracted', 0.051), ('lexrank', 0.05), ('scheible', 0.05), ('lda', 0.05), ('cooccurrence', 0.049), ('words', 0.048), ('subramanya', 0.046), ('coherence', 0.045), ('divergence', 0.045), ('rada', 0.044), ('study', 0.043), ('changed', 0.043), ('rank', 0.043), ('extracting', 0.042), ('classified', 0.042), ('referring', 0.042), ('classify', 0.042), ('summarization', 0.041), ('scores', 0.041), ('surface', 0.041), ('original', 0.04), ('issue', 0.04), ('raise', 0.039), ('adopt', 0.038), ('equation', 0.038), ('experiment', 0.038), ('text', 0.037), ('proposed', 0.036), ('construct', 0.036), ('xx', 0.036), ('refine', 0.035), ('categories', 0.034), ('perplexity', 0.034), ('probabilistic', 0.034), ('estimated', 0.034), ('conditions', 0.034), ('di', 0.034), ('selecting', 0.034), ('collection', 0.033), ('sentiment', 0.033), ('reproduce', 0.032), ('extraction', 0.032), ('case', 0.032), ('method', 0.032), ('clustered', 0.031), ('adopted', 0.031), ('verify', 0.031), ('distribution', 0.031), ('osmar', 0.03), ('suit', 0.03), ('gory', 0.03), ('sequel', 0.03), ('acq', 0.03), ('koba', 0.03), ('softsupervised', 0.03), ('fers', 0.03), ('mz', 0.03), ('unger', 0.03), ('eoacricahti', 0.03), ('confirm', 0.028), ('mihalcea', 0.028), ('contextsensitive', 0.028), ('logpr', 0.028), ('hypertextual', 0.028), ('isdn', 0.028), ('ochanomizu', 0.028), ('samer', 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="341-tfidf-1" href="./acl-2013-Text_Classification_based_on_the_Latent_Topics_of_Important_Sentences_extracted_by_the_PageRank_Algorithm.html">341 acl-2013-Text Classification based on the Latent Topics of Important Sentences extracted by the PageRank Algorithm</a></p>
<p>Author: Yukari Ogura ; Ichiro Kobayashi</p><p>Abstract: In this paper, we propose a method to raise the accuracy of text classification based on latent topics, reconsidering the techniques necessary for good classification for example, to decide important sentences in a document, the sentences with important words are usually regarded as important sentences. In this case, tf.idf is often used to decide important words. On the other hand, we apply the PageRank algorithm to rank important words in each document. Furthermore, before clustering documents, we refine the target documents by representing them as a collection of important sentences in each document. We then classify the documents based on latent information in the documents. As a clustering method, we employ the k-means algorithm and inves– tigate how our proposed method works for good clustering. We conduct experiments with Reuters-21578 corpus under various conditions of important sentence extraction, using latent and surface information for clustering, and have confirmed that our proposed method provides better result among various conditions for clustering.</p><p>2 0.2758342 <a title="341-tfidf-2" href="./acl-2013-High-quality_Training_Data_Selection_using_Latent_Topics_for_Graph-based_Semi-supervised_Learning.html">182 acl-2013-High-quality Training Data Selection using Latent Topics for Graph-based Semi-supervised Learning</a></p>
<p>Author: Akiko Eriguchi ; Ichiro Kobayashi</p><p>Abstract: In a multi-class document categorization using graph-based semi-supervised learning (GBSSL), it is essential to construct a proper graph expressing the relation among nodes and to use a reasonable categorization algorithm. Furthermore, it is also important to provide high-quality correct data as training data. In this context, we propose a method to construct a similarity graph by employing both surface information and latent information to express similarity between nodes and a method to select high-quality training data for GBSSL by means of the PageR- ank algorithm. Experimenting on Reuters21578 corpus, we have confirmed that our proposed methods work well for raising the accuracy of a multi-class document categorization.</p><p>3 0.21182038 <a title="341-tfidf-3" href="./acl-2013-Are_Semantically_Coherent_Topic_Models_Useful_for_Ad_Hoc_Information_Retrieval%3F.html">55 acl-2013-Are Semantically Coherent Topic Models Useful for Ad Hoc Information Retrieval?</a></p>
<p>Author: Romain Deveaud ; Eric SanJuan ; Patrice Bellot</p><p>Abstract: The current topic modeling approaches for Information Retrieval do not allow to explicitly model query-oriented latent topics. More, the semantic coherence of the topics has never been considered in this field. We propose a model-based feedback approach that learns Latent Dirichlet Allocation topic models on the top-ranked pseudo-relevant feedback, and we measure the semantic coherence of those topics. We perform a first experimental evaluation using two major TREC test collections. Results show that retrieval perfor- mances tend to be better when using topics with higher semantic coherence.</p><p>4 0.17652532 <a title="341-tfidf-4" href="./acl-2013-Building_Comparable_Corpora_Based_on_Bilingual_LDA_Model.html">74 acl-2013-Building Comparable Corpora Based on Bilingual LDA Model</a></p>
<p>Author: Zede Zhu ; Miao Li ; Lei Chen ; Zhenxin Yang</p><p>Abstract: Comparable corpora are important basic resources in cross-language information processing. However, the existing methods of building comparable corpora, which use intertranslate words and relative features, cannot evaluate the topical relation between document pairs. This paper adopts the bilingual LDA model to predict the topical structures of the documents and proposes three algorithms of document similarity in different languages. Experiments show that the novel method can obtain similar documents with consistent top- ics own better adaptability and stability performance.</p><p>5 0.16579469 <a title="341-tfidf-5" href="./acl-2013-Latent_Semantic_Matching%3A_Application_to_Cross-language_Text_Categorization_without_Alignment_Information.html">217 acl-2013-Latent Semantic Matching: Application to Cross-language Text Categorization without Alignment Information</a></p>
<p>Author: Tsutomu Hirao ; Tomoharu Iwata ; Masaaki Nagata</p><p>Abstract: Unsupervised object matching (UOM) is a promising approach to cross-language natural language processing such as bilingual lexicon acquisition, parallel corpus construction, and cross-language text categorization, because it does not require labor-intensive linguistic resources. However, UOM only finds one-to-one correspondences from data sets with the same number of instances in source and target domains, and this prevents us from applying UOM to real-world cross-language natural language processing tasks. To alleviate these limitations, we proposes latent semantic matching, which embeds objects in both source and target language domains into a shared latent topic space. We demonstrate the effectiveness of our method on cross-language text categorization. The results show that our method outperforms conventional unsupervised object matching methods.</p><p>6 0.1506404 <a title="341-tfidf-6" href="./acl-2013-Topic_Modeling_Based_Classification_of_Clinical_Reports.html">351 acl-2013-Topic Modeling Based Classification of Clinical Reports</a></p>
<p>7 0.12008629 <a title="341-tfidf-7" href="./acl-2013-A_System_for_Summarizing_Scientific_Topics_Starting_from_Keywords.html">23 acl-2013-A System for Summarizing Scientific Topics Starting from Keywords</a></p>
<p>8 0.1152233 <a title="341-tfidf-8" href="./acl-2013-Broadcast_News_Story_Segmentation_Using_Manifold_Learning_on_Latent_Topic_Distributions.html">73 acl-2013-Broadcast News Story Segmentation Using Manifold Learning on Latent Topic Distributions</a></p>
<p>9 0.11440659 <a title="341-tfidf-9" href="./acl-2013-Text_Classification_from_Positive_and_Unlabeled_Data_using_Misclassified_Data_Correction.html">342 acl-2013-Text Classification from Positive and Unlabeled Data using Misclassified Data Correction</a></p>
<p>10 0.1037398 <a title="341-tfidf-10" href="./acl-2013-An_Information_Theoretic_Approach_to_Bilingual_Word_Clustering.html">47 acl-2013-An Information Theoretic Approach to Bilingual Word Clustering</a></p>
<p>11 0.094339602 <a title="341-tfidf-11" href="./acl-2013-Graph-based_Local_Coherence_Modeling.html">172 acl-2013-Graph-based Local Coherence Modeling</a></p>
<p>12 0.090691 <a title="341-tfidf-12" href="./acl-2013-The_Haves_and_the_Have-Nots%3A_Leveraging_Unlabelled_Corpora_for_Sentiment_Analysis.html">345 acl-2013-The Haves and the Have-Nots: Leveraging Unlabelled Corpora for Sentiment Analysis</a></p>
<p>13 0.090640783 <a title="341-tfidf-13" href="./acl-2013-Exploiting_Topic_based_Twitter_Sentiment_for_Stock_Prediction.html">147 acl-2013-Exploiting Topic based Twitter Sentiment for Stock Prediction</a></p>
<p>14 0.090254255 <a title="341-tfidf-14" href="./acl-2013-Discovering_User_Interactions_in_Ideological_Discussions.html">121 acl-2013-Discovering User Interactions in Ideological Discussions</a></p>
<p>15 0.089728199 <a title="341-tfidf-15" href="./acl-2013-Identifying_Sentiment_Words_Using_an_Optimization-based_Model_without_Seed_Words.html">188 acl-2013-Identifying Sentiment Words Using an Optimization-based Model without Seed Words</a></p>
<p>16 0.087568857 <a title="341-tfidf-16" href="./acl-2013-A_Two_Level_Model_for_Context_Sensitive_Inference_Rules.html">27 acl-2013-A Two Level Model for Context Sensitive Inference Rules</a></p>
<p>17 0.084164083 <a title="341-tfidf-17" href="./acl-2013-Post-Retrieval_Clustering_Using_Third-Order_Similarity_Measures.html">281 acl-2013-Post-Retrieval Clustering Using Third-Order Similarity Measures</a></p>
<p>18 0.083082281 <a title="341-tfidf-18" href="./acl-2013-Incremental_Topic-Based_Translation_Model_Adaptation_for_Conversational_Spoken_Language_Translation.html">197 acl-2013-Incremental Topic-Based Translation Model Adaptation for Conversational Spoken Language Translation</a></p>
<p>19 0.080318533 <a title="341-tfidf-19" href="./acl-2013-Dirt_Cheap_Web-Scale_Parallel_Text_from_the_Common_Crawl.html">120 acl-2013-Dirt Cheap Web-Scale Parallel Text from the Common Crawl</a></p>
<p>20 0.079885289 <a title="341-tfidf-20" href="./acl-2013-Align%2C_Disambiguate_and_Walk%3A_A_Unified_Approach_for_Measuring_Semantic_Similarity.html">43 acl-2013-Align, Disambiguate and Walk: A Unified Approach for Measuring Semantic Similarity</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.198), (1, 0.14), (2, 0.046), (3, -0.049), (4, 0.089), (5, -0.087), (6, 0.073), (7, -0.008), (8, -0.203), (9, -0.1), (10, 0.151), (11, 0.057), (12, 0.076), (13, 0.121), (14, 0.013), (15, -0.005), (16, -0.042), (17, 0.088), (18, -0.097), (19, 0.019), (20, -0.044), (21, 0.019), (22, 0.012), (23, -0.046), (24, 0.004), (25, 0.005), (26, -0.031), (27, -0.051), (28, -0.044), (29, -0.028), (30, -0.06), (31, -0.025), (32, -0.08), (33, 0.004), (34, 0.039), (35, -0.054), (36, -0.131), (37, -0.014), (38, 0.022), (39, 0.007), (40, -0.02), (41, 0.068), (42, 0.077), (43, 0.077), (44, -0.049), (45, 0.008), (46, 0.028), (47, 0.061), (48, 0.017), (49, -0.046)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9742732 <a title="341-lsi-1" href="./acl-2013-Text_Classification_based_on_the_Latent_Topics_of_Important_Sentences_extracted_by_the_PageRank_Algorithm.html">341 acl-2013-Text Classification based on the Latent Topics of Important Sentences extracted by the PageRank Algorithm</a></p>
<p>Author: Yukari Ogura ; Ichiro Kobayashi</p><p>Abstract: In this paper, we propose a method to raise the accuracy of text classification based on latent topics, reconsidering the techniques necessary for good classification for example, to decide important sentences in a document, the sentences with important words are usually regarded as important sentences. In this case, tf.idf is often used to decide important words. On the other hand, we apply the PageRank algorithm to rank important words in each document. Furthermore, before clustering documents, we refine the target documents by representing them as a collection of important sentences in each document. We then classify the documents based on latent information in the documents. As a clustering method, we employ the k-means algorithm and inves– tigate how our proposed method works for good clustering. We conduct experiments with Reuters-21578 corpus under various conditions of important sentence extraction, using latent and surface information for clustering, and have confirmed that our proposed method provides better result among various conditions for clustering.</p><p>2 0.84450257 <a title="341-lsi-2" href="./acl-2013-High-quality_Training_Data_Selection_using_Latent_Topics_for_Graph-based_Semi-supervised_Learning.html">182 acl-2013-High-quality Training Data Selection using Latent Topics for Graph-based Semi-supervised Learning</a></p>
<p>Author: Akiko Eriguchi ; Ichiro Kobayashi</p><p>Abstract: In a multi-class document categorization using graph-based semi-supervised learning (GBSSL), it is essential to construct a proper graph expressing the relation among nodes and to use a reasonable categorization algorithm. Furthermore, it is also important to provide high-quality correct data as training data. In this context, we propose a method to construct a similarity graph by employing both surface information and latent information to express similarity between nodes and a method to select high-quality training data for GBSSL by means of the PageR- ank algorithm. Experimenting on Reuters21578 corpus, we have confirmed that our proposed methods work well for raising the accuracy of a multi-class document categorization.</p><p>3 0.79646069 <a title="341-lsi-3" href="./acl-2013-Latent_Semantic_Matching%3A_Application_to_Cross-language_Text_Categorization_without_Alignment_Information.html">217 acl-2013-Latent Semantic Matching: Application to Cross-language Text Categorization without Alignment Information</a></p>
<p>Author: Tsutomu Hirao ; Tomoharu Iwata ; Masaaki Nagata</p><p>Abstract: Unsupervised object matching (UOM) is a promising approach to cross-language natural language processing such as bilingual lexicon acquisition, parallel corpus construction, and cross-language text categorization, because it does not require labor-intensive linguistic resources. However, UOM only finds one-to-one correspondences from data sets with the same number of instances in source and target domains, and this prevents us from applying UOM to real-world cross-language natural language processing tasks. To alleviate these limitations, we proposes latent semantic matching, which embeds objects in both source and target language domains into a shared latent topic space. We demonstrate the effectiveness of our method on cross-language text categorization. The results show that our method outperforms conventional unsupervised object matching methods.</p><p>4 0.78044194 <a title="341-lsi-4" href="./acl-2013-Are_Semantically_Coherent_Topic_Models_Useful_for_Ad_Hoc_Information_Retrieval%3F.html">55 acl-2013-Are Semantically Coherent Topic Models Useful for Ad Hoc Information Retrieval?</a></p>
<p>Author: Romain Deveaud ; Eric SanJuan ; Patrice Bellot</p><p>Abstract: The current topic modeling approaches for Information Retrieval do not allow to explicitly model query-oriented latent topics. More, the semantic coherence of the topics has never been considered in this field. We propose a model-based feedback approach that learns Latent Dirichlet Allocation topic models on the top-ranked pseudo-relevant feedback, and we measure the semantic coherence of those topics. We perform a first experimental evaluation using two major TREC test collections. Results show that retrieval perfor- mances tend to be better when using topics with higher semantic coherence.</p><p>5 0.77754629 <a title="341-lsi-5" href="./acl-2013-Building_Comparable_Corpora_Based_on_Bilingual_LDA_Model.html">74 acl-2013-Building Comparable Corpora Based on Bilingual LDA Model</a></p>
<p>Author: Zede Zhu ; Miao Li ; Lei Chen ; Zhenxin Yang</p><p>Abstract: Comparable corpora are important basic resources in cross-language information processing. However, the existing methods of building comparable corpora, which use intertranslate words and relative features, cannot evaluate the topical relation between document pairs. This paper adopts the bilingual LDA model to predict the topical structures of the documents and proposes three algorithms of document similarity in different languages. Experiments show that the novel method can obtain similar documents with consistent top- ics own better adaptability and stability performance.</p><p>6 0.77509338 <a title="341-lsi-6" href="./acl-2013-Topic_Modeling_Based_Classification_of_Clinical_Reports.html">351 acl-2013-Topic Modeling Based Classification of Clinical Reports</a></p>
<p>7 0.74987417 <a title="341-lsi-7" href="./acl-2013-Diverse_Keyword_Extraction_from_Conversations.html">126 acl-2013-Diverse Keyword Extraction from Conversations</a></p>
<p>8 0.74226111 <a title="341-lsi-8" href="./acl-2013-Are_School-of-thought_Words_Characterizable%3F.html">54 acl-2013-Are School-of-thought Words Characterizable?</a></p>
<p>9 0.73816758 <a title="341-lsi-9" href="./acl-2013-Broadcast_News_Story_Segmentation_Using_Manifold_Learning_on_Latent_Topic_Distributions.html">73 acl-2013-Broadcast News Story Segmentation Using Manifold Learning on Latent Topic Distributions</a></p>
<p>10 0.64592111 <a title="341-lsi-10" href="./acl-2013-A_System_for_Summarizing_Scientific_Topics_Starting_from_Keywords.html">23 acl-2013-A System for Summarizing Scientific Topics Starting from Keywords</a></p>
<p>11 0.62261808 <a title="341-lsi-11" href="./acl-2013-Evolutionary_Hierarchical_Dirichlet_Process_for_Timeline_Summarization.html">142 acl-2013-Evolutionary Hierarchical Dirichlet Process for Timeline Summarization</a></p>
<p>12 0.61032689 <a title="341-lsi-12" href="./acl-2013-Text_Classification_from_Positive_and_Unlabeled_Data_using_Misclassified_Data_Correction.html">342 acl-2013-Text Classification from Positive and Unlabeled Data using Misclassified Data Correction</a></p>
<p>13 0.60675967 <a title="341-lsi-13" href="./acl-2013-Bridging_Languages_through_Etymology%3A_The_case_of_cross_language_text_categorization.html">72 acl-2013-Bridging Languages through Etymology: The case of cross language text categorization</a></p>
<p>14 0.57003254 <a title="341-lsi-14" href="./acl-2013-Exploiting_Topic_based_Twitter_Sentiment_for_Stock_Prediction.html">147 acl-2013-Exploiting Topic based Twitter Sentiment for Stock Prediction</a></p>
<p>15 0.56219381 <a title="341-lsi-15" href="./acl-2013-Improved_Bayesian_Logistic_Supervised_Topic_Models_with_Data_Augmentation.html">191 acl-2013-Improved Bayesian Logistic Supervised Topic Models with Data Augmentation</a></p>
<p>16 0.54177719 <a title="341-lsi-16" href="./acl-2013-Natural_Language_Models_for_Predicting_Programming_Comments.html">257 acl-2013-Natural Language Models for Predicting Programming Comments</a></p>
<p>17 0.53903735 <a title="341-lsi-17" href="./acl-2013-Scaling_Semi-supervised_Naive_Bayes_with_Feature_Marginals.html">309 acl-2013-Scaling Semi-supervised Naive Bayes with Feature Marginals</a></p>
<p>18 0.53597516 <a title="341-lsi-18" href="./acl-2013-Incremental_Topic-Based_Translation_Model_Adaptation_for_Conversational_Spoken_Language_Translation.html">197 acl-2013-Incremental Topic-Based Translation Model Adaptation for Conversational Spoken Language Translation</a></p>
<p>19 0.5341633 <a title="341-lsi-19" href="./acl-2013-Learning_Latent_Personas_of_Film_Characters.html">220 acl-2013-Learning Latent Personas of Film Characters</a></p>
<p>20 0.53350461 <a title="341-lsi-20" href="./acl-2013-Linggle%3A_a_Web-scale_Linguistic_Search_Engine_for_Words_in_Context.html">231 acl-2013-Linggle: a Web-scale Linguistic Search Engine for Words in Context</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.039), (6, 0.02), (11, 0.072), (24, 0.09), (26, 0.049), (35, 0.146), (41, 0.082), (42, 0.059), (48, 0.045), (70, 0.037), (88, 0.028), (90, 0.177), (95, 0.06)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.93270624 <a title="341-lda-1" href="./acl-2013-High-quality_Training_Data_Selection_using_Latent_Topics_for_Graph-based_Semi-supervised_Learning.html">182 acl-2013-High-quality Training Data Selection using Latent Topics for Graph-based Semi-supervised Learning</a></p>
<p>Author: Akiko Eriguchi ; Ichiro Kobayashi</p><p>Abstract: In a multi-class document categorization using graph-based semi-supervised learning (GBSSL), it is essential to construct a proper graph expressing the relation among nodes and to use a reasonable categorization algorithm. Furthermore, it is also important to provide high-quality correct data as training data. In this context, we propose a method to construct a similarity graph by employing both surface information and latent information to express similarity between nodes and a method to select high-quality training data for GBSSL by means of the PageR- ank algorithm. Experimenting on Reuters21578 corpus, we have confirmed that our proposed methods work well for raising the accuracy of a multi-class document categorization.</p><p>2 0.92239231 <a title="341-lda-2" href="./acl-2013-Entity_Linking_for_Tweets.html">139 acl-2013-Entity Linking for Tweets</a></p>
<p>Author: Xiaohua Liu ; Yitong Li ; Haocheng Wu ; Ming Zhou ; Furu Wei ; Yi Lu</p><p>Abstract: We study the task of entity linking for tweets, which tries to associate each mention in a tweet with a knowledge base entry. Two main challenges of this task are the dearth of information in a single tweet and the rich entity mention variations. To address these challenges, we propose a collective inference method that simultaneously resolves a set of mentions. Particularly, our model integrates three kinds of similarities, i.e., mention-entry similarity, entry-entry similarity, and mention-mention similarity, to enrich the context for entity linking, and to address irregular mentions that are not covered by the entity-variation dictionary. We evaluate our method on a publicly available data set and demonstrate the effectiveness of our method.</p><p>3 0.90750241 <a title="341-lda-3" href="./acl-2013-Word_surprisal_predicts_N400_amplitude_during_reading.html">390 acl-2013-Word surprisal predicts N400 amplitude during reading</a></p>
<p>Author: Stefan L. Frank ; Leun J. Otten ; Giulia Galli ; Gabriella Vigliocco</p><p>Abstract: We investigated the effect of word surprisal on the EEG signal during sentence reading. On each word of 205 experimental sentences, surprisal was estimated by three types of language model: Markov models, probabilistic phrasestructure grammars, and recurrent neural networks. Four event-related potential components were extracted from the EEG of 24 readers of the same sentences. Surprisal estimates under each model type formed a significant predictor of the amplitude of the N400 component only, with more surprising words resulting in more negative N400s. This effect was mostly due to content words. These findings provide support for surprisal as a gener- ally applicable measure of processing difficulty during language comprehension.</p><p>4 0.90035778 <a title="341-lda-4" href="./acl-2013-Incremental_Topic-Based_Translation_Model_Adaptation_for_Conversational_Spoken_Language_Translation.html">197 acl-2013-Incremental Topic-Based Translation Model Adaptation for Conversational Spoken Language Translation</a></p>
<p>Author: Sanjika Hewavitharana ; Dennis Mehay ; Sankaranarayanan Ananthakrishnan ; Prem Natarajan</p><p>Abstract: We describe a translation model adaptation approach for conversational spoken language translation (CSLT), which encourages the use of contextually appropriate translation options from relevant training conversations. Our approach employs a monolingual LDA topic model to derive a similarity measure between the test conversation and the set of training conversations, which is used to bias translation choices towards the current context. A significant novelty of our adaptation technique is its incremental nature; we continuously update the topic distribution on the evolving test conversation as new utterances become available. Thus, our approach is well-suited to the causal constraint of spoken conversations. On an English-to-Iraqi CSLT task, the proposed approach gives significant improvements over a baseline system as measured by BLEU, TER, and NIST. Interestingly, the incremental approach outperforms a non-incremental oracle that has up-front knowledge of the whole conversation.</p><p>5 0.87593353 <a title="341-lda-5" href="./acl-2013-On_the_Predictability_of_Human_Assessment%3A_when_Matrix_Completion_Meets_NLP_Evaluation.html">263 acl-2013-On the Predictability of Human Assessment: when Matrix Completion Meets NLP Evaluation</a></p>
<p>Author: Guillaume Wisniewski</p><p>Abstract: This paper tackles the problem of collecting reliable human assessments. We show that knowing multiple scores for each example instead of a single score results in a more reliable estimation of a system quality. To reduce the cost of collecting these multiple ratings, we propose to use matrix completion techniques to predict some scores knowing only scores of other judges and some common ratings. Even if prediction performance is pretty low, decisions made using the predicted score proved to be more reliable than decision based on a single rating of each example.</p><p>same-paper 6 0.87543887 <a title="341-lda-6" href="./acl-2013-Text_Classification_based_on_the_Latent_Topics_of_Important_Sentences_extracted_by_the_PageRank_Algorithm.html">341 acl-2013-Text Classification based on the Latent Topics of Important Sentences extracted by the PageRank Algorithm</a></p>
<p>7 0.86023897 <a title="341-lda-7" href="./acl-2013-Shallow_Local_Multi-Bottom-up_Tree_Transducers_in_Statistical_Machine_Translation.html">320 acl-2013-Shallow Local Multi-Bottom-up Tree Transducers in Statistical Machine Translation</a></p>
<p>8 0.8422659 <a title="341-lda-8" href="./acl-2013-Integrating_Phrase-based_Reordering_Features_into_a_Chart-based_Decoder_for_Machine_Translation.html">200 acl-2013-Integrating Phrase-based Reordering Features into a Chart-based Decoder for Machine Translation</a></p>
<p>9 0.82631493 <a title="341-lda-9" href="./acl-2013-Crowd_Prefers_the_Middle_Path%3A_A_New_IAA_Metric_for_Crowdsourcing_Reveals_Turker_Biases_in_Query_Segmentation.html">99 acl-2013-Crowd Prefers the Middle Path: A New IAA Metric for Crowdsourcing Reveals Turker Biases in Query Segmentation</a></p>
<p>10 0.80310094 <a title="341-lda-10" href="./acl-2013-Generating_Recommendation_Dialogs_by_Extracting_Information_from_User_Reviews.html">168 acl-2013-Generating Recommendation Dialogs by Extracting Information from User Reviews</a></p>
<p>11 0.80101031 <a title="341-lda-11" href="./acl-2013-Diverse_Keyword_Extraction_from_Conversations.html">126 acl-2013-Diverse Keyword Extraction from Conversations</a></p>
<p>12 0.79661369 <a title="341-lda-12" href="./acl-2013-Models_of_Translation_Competitions.html">250 acl-2013-Models of Translation Competitions</a></p>
<p>13 0.79349518 <a title="341-lda-13" href="./acl-2013-A_Context_Free_TAG_Variant.html">4 acl-2013-A Context Free TAG Variant</a></p>
<p>14 0.78355366 <a title="341-lda-14" href="./acl-2013-Graph-based_Local_Coherence_Modeling.html">172 acl-2013-Graph-based Local Coherence Modeling</a></p>
<p>15 0.78295541 <a title="341-lda-15" href="./acl-2013-An_Infinite_Hierarchical_Bayesian_Model_of_Phrasal_Translation.html">46 acl-2013-An Infinite Hierarchical Bayesian Model of Phrasal Translation</a></p>
<p>16 0.77744198 <a title="341-lda-16" href="./acl-2013-Learning_to_Prune%3A_Context-Sensitive_Pruning_for_Syntactic_MT.html">226 acl-2013-Learning to Prune: Context-Sensitive Pruning for Syntactic MT</a></p>
<p>17 0.77179384 <a title="341-lda-17" href="./acl-2013-Linggle%3A_a_Web-scale_Linguistic_Search_Engine_for_Words_in_Context.html">231 acl-2013-Linggle: a Web-scale Linguistic Search Engine for Words in Context</a></p>
<p>18 0.77087635 <a title="341-lda-18" href="./acl-2013-Semantic_Parsing_as_Machine_Translation.html">312 acl-2013-Semantic Parsing as Machine Translation</a></p>
<p>19 0.76949656 <a title="341-lda-19" href="./acl-2013-Graph_Propagation_for_Paraphrasing_Out-of-Vocabulary_Words_in_Statistical_Machine_Translation.html">174 acl-2013-Graph Propagation for Paraphrasing Out-of-Vocabulary Words in Statistical Machine Translation</a></p>
<p>20 0.76942712 <a title="341-lda-20" href="./acl-2013-Semantic_Roles_for_String_to_Tree_Machine_Translation.html">314 acl-2013-Semantic Roles for String to Tree Machine Translation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
