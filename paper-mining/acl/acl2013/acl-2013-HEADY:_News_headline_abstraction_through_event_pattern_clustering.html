<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>178 acl-2013-HEADY: News headline abstraction through event pattern clustering</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-178" href="#">acl2013-178</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>178 acl-2013-HEADY: News headline abstraction through event pattern clustering</h1>
<br/><p>Source: <a title="acl-2013-178-pdf" href="http://aclweb.org/anthology//P/P13/P13-1122.pdf">pdf</a></p><p>Author: Enrique Alfonseca ; Daniele Pighin ; Guillermo Garrido</p><p>Abstract: This paper presents HEADY: a novel, abstractive approach for headline generation from news collections. From a web-scale corpus of English news, we mine syntactic patterns that a Noisy-OR model generalizes into event descriptions. At inference time, we query the model with the patterns observed in an unseen news collection, identify the event that better captures the gist of the collection and retrieve the most appropriate pattern to generate a headline. HEADY improves over a state-of-theart open-domain title abstraction method, bridging half of the gap that separates it from extractive methods using humangenerated titles in manual evaluations, and performs comparably to human-generated headlines as evaluated with ROUGE.</p><p>Reference: <a title="acl-2013-178-reference" href="../acl2013_reference/acl-2013-HEADY%3A_News_headline_abstraction_through_event_pattern_clustering_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('headlin', 0.794), ('heady', 0.324), ('pattern', 0.166), ('topics', 0.149), ('titl', 0.131), ('carmelo', 0.109), ('msc', 0.109), ('ei', 0.088), ('wed', 0.086), ('roug', 0.079), ('filippov', 0.078), ('actress', 0.078), ('nnp', 0.077), ('ent', 0.07), ('collect', 0.069), ('marry', 0.055), ('armstrong', 0.054), ('crawley', 0.054), ('extractpattern', 0.054), ('theron', 0.054)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="178-tfidf-1" href="./acl-2013-HEADY%3A_News_headline_abstraction_through_event_pattern_clustering.html">178 acl-2013-HEADY: News headline abstraction through event pattern clustering</a></p>
<p>Author: Enrique Alfonseca ; Daniele Pighin ; Guillermo Garrido</p><p>Abstract: This paper presents HEADY: a novel, abstractive approach for headline generation from news collections. From a web-scale corpus of English news, we mine syntactic patterns that a Noisy-OR model generalizes into event descriptions. At inference time, we query the model with the patterns observed in an unseen news collection, identify the event that better captures the gist of the collection and retrieve the most appropriate pattern to generate a headline. HEADY improves over a state-of-theart open-domain title abstraction method, bridging half of the gap that separates it from extractive methods using humangenerated titles in manual evaluations, and performs comparably to human-generated headlines as evaluated with ROUGE.</p><p>2 0.09531682 <a title="178-tfidf-2" href="./acl-2013-Fine-grained_Semantic_Typing_of_Emerging_Entities.html">160 acl-2013-Fine-grained Semantic Typing of Emerging Entities</a></p>
<p>Author: Ndapandula Nakashole ; Tomasz Tylenda ; Gerhard Weikum</p><p>Abstract: Methods for information extraction (IE) and knowledge base (KB) construction have been intensively studied. However, a largely under-explored case is tapping into highly dynamic sources like news streams and social media, where new entities are continuously emerging. In this paper, we present a method for discovering and semantically typing newly emerging out-ofKB entities, thus improving the freshness and recall of ontology-based IE and improving the precision and semantic rigor of open IE. Our method is based on a probabilistic model that feeds weights into integer linear programs that leverage type signatures of relational phrases and type correlation or disjointness constraints. Our experimental evaluation, based on crowdsourced user studies, show our method performing significantly better than prior work.</p><p>3 0.092664056 <a title="178-tfidf-3" href="./acl-2013-A_Sentence_Compression_Based_Framework_to_Query-Focused_Multi-Document_Summarization.html">18 acl-2013-A Sentence Compression Based Framework to Query-Focused Multi-Document Summarization</a></p>
<p>Author: Lu Wang ; Hema Raghavan ; Vittorio Castelli ; Radu Florian ; Claire Cardie</p><p>Abstract: We consider the problem of using sentence compression techniques to facilitate queryfocused multi-document summarization. We present a sentence-compression-based framework for the task, and design a series of learning-based compression models built on parse trees. An innovative beam search decoder is proposed to efficiently find highly probable compressions. Under this framework, we show how to integrate various indicative metrics such as linguistic motivation and query relevance into the compression process by deriving a novel formulation of a compression scoring function. Our best model achieves statistically significant improvement over the state-of-the-art systems on several metrics (e.g. 8.0% and 5.4% improvements in ROUGE-2 respectively) for the DUC 2006 and 2007 summarization task. ,</p><p>4 0.07767266 <a title="178-tfidf-4" href="./acl-2013-A_Decade_of_Automatic_Content_Evaluation_of_News_Summaries%3A_Reassessing_the_State_of_the_Art.html">5 acl-2013-A Decade of Automatic Content Evaluation of News Summaries: Reassessing the State of the Art</a></p>
<p>Author: Peter A. Rankel ; John M. Conroy ; Hoa Trang Dang ; Ani Nenkova</p><p>Abstract: How good are automatic content metrics for news summary evaluation? Here we provide a detailed answer to this question, with a particular focus on assessing the ability of automatic evaluations to identify statistically significant differences present in manual evaluation of content. Using four years of data from the Text Analysis Conference, we analyze the performance of eight ROUGE variants in terms of accuracy, precision and recall in finding significantly different systems. Our experiments show that some of the neglected variants of ROUGE, based on higher order n-grams and syntactic dependencies, are most accurate across the years; the commonly used ROUGE-1 scores find too many significant differences between systems which manual evaluation would deem comparable. We also test combinations ofROUGE variants and find that they considerably improve the accuracy of automatic prediction.</p><p>5 0.075285345 <a title="178-tfidf-5" href="./acl-2013-Entity_Linking_for_Tweets.html">139 acl-2013-Entity Linking for Tweets</a></p>
<p>Author: Xiaohua Liu ; Yitong Li ; Haocheng Wu ; Ming Zhou ; Furu Wei ; Yi Lu</p><p>Abstract: We study the task of entity linking for tweets, which tries to associate each mention in a tweet with a knowledge base entry. Two main challenges of this task are the dearth of information in a single tweet and the rich entity mention variations. To address these challenges, we propose a collective inference method that simultaneously resolves a set of mentions. Particularly, our model integrates three kinds of similarities, i.e., mention-entry similarity, entry-entry similarity, and mention-mention similarity, to enrich the context for entity linking, and to address irregular mentions that are not covered by the entity-variation dictionary. We evaluate our method on a publicly available data set and demonstrate the effectiveness of our method.</p><p>6 0.06396988 <a title="178-tfidf-6" href="./acl-2013-Fast_and_Robust_Compressive_Summarization_with_Dual_Decomposition_and_Multi-Task_Learning.html">157 acl-2013-Fast and Robust Compressive Summarization with Dual Decomposition and Multi-Task Learning</a></p>
<p>7 0.057675123 <a title="178-tfidf-7" href="./acl-2013-Named_Entity_Recognition_using_Cross-lingual_Resources%3A_Arabic_as_an_Example.html">256 acl-2013-Named Entity Recognition using Cross-lingual Resources: Arabic as an Example</a></p>
<p>8 0.05634528 <a title="178-tfidf-8" href="./acl-2013-Improving_Text_Simplification_Language_Modeling_Using_Unsimplified_Text_Data.html">194 acl-2013-Improving Text Simplification Language Modeling Using Unsimplified Text Data</a></p>
<p>9 0.054332796 <a title="178-tfidf-9" href="./acl-2013-Large-scale_Semantic_Parsing_via_Schema_Matching_and_Lexicon_Extension.html">215 acl-2013-Large-scale Semantic Parsing via Schema Matching and Lexicon Extension</a></p>
<p>10 0.053854346 <a title="178-tfidf-10" href="./acl-2013-Learning_Entity_Representation_for_Entity_Disambiguation.html">219 acl-2013-Learning Entity Representation for Entity Disambiguation</a></p>
<p>11 0.052419618 <a title="178-tfidf-11" href="./acl-2013-An_improved_MDL-based_compression_algorithm_for_unsupervised_word_segmentation.html">50 acl-2013-An improved MDL-based compression algorithm for unsupervised word segmentation</a></p>
<p>12 0.051887263 <a title="178-tfidf-12" href="./acl-2013-Towards_Accurate_Distant_Supervision_for_Relational_Facts_Extraction.html">352 acl-2013-Towards Accurate Distant Supervision for Relational Facts Extraction</a></p>
<p>13 0.051765241 <a title="178-tfidf-13" href="./acl-2013-Generating_Synthetic_Comparable_Questions_for_News_Articles.html">169 acl-2013-Generating Synthetic Comparable Questions for News Articles</a></p>
<p>14 0.051643543 <a title="178-tfidf-14" href="./acl-2013-BRAINSUP%3A_Brainstorming_Support_for_Creative_Sentence_Generation.html">65 acl-2013-BRAINSUP: Brainstorming Support for Creative Sentence Generation</a></p>
<p>15 0.051018026 <a title="178-tfidf-15" href="./acl-2013-Graph-based_Local_Coherence_Modeling.html">172 acl-2013-Graph-based Local Coherence Modeling</a></p>
<p>16 0.050155185 <a title="178-tfidf-16" href="./acl-2013-Paraphrase-Driven_Learning_for_Open_Question_Answering.html">272 acl-2013-Paraphrase-Driven Learning for Open Question Answering</a></p>
<p>17 0.048617568 <a title="178-tfidf-17" href="./acl-2013-Mining_Opinion_Words_and_Opinion_Targets_in_a_Two-Stage_Framework.html">244 acl-2013-Mining Opinion Words and Opinion Targets in a Two-Stage Framework</a></p>
<p>18 0.046737667 <a title="178-tfidf-18" href="./acl-2013-HYENA-live%3A_Fine-Grained_Online_Entity_Type_Classification_from_Natural-language_Text.html">179 acl-2013-HYENA-live: Fine-Grained Online Entity Type Classification from Natural-language Text</a></p>
<p>19 0.046298198 <a title="178-tfidf-19" href="./acl-2013-Domain-Independent_Abstract_Generation_for_Focused_Meeting_Summarization.html">129 acl-2013-Domain-Independent Abstract Generation for Focused Meeting Summarization</a></p>
<p>20 0.045611009 <a title="178-tfidf-20" href="./acl-2013-Generalizing_Image_Captions_for_Image-Text_Parallel_Corpus.html">167 acl-2013-Generalizing Image Captions for Image-Text Parallel Corpus</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.127), (1, -0.032), (2, -0.009), (3, -0.046), (4, -0.017), (5, -0.007), (6, -0.011), (7, -0.03), (8, 0.107), (9, -0.012), (10, 0.013), (11, 0.02), (12, 0.046), (13, 0.011), (14, -0.01), (15, -0.001), (16, 0.02), (17, 0.064), (18, -0.019), (19, 0.054), (20, -0.031), (21, 0.027), (22, -0.023), (23, -0.019), (24, 0.033), (25, -0.004), (26, 0.027), (27, -0.025), (28, 0.085), (29, -0.021), (30, -0.041), (31, -0.014), (32, 0.037), (33, 0.03), (34, -0.016), (35, 0.08), (36, -0.0), (37, 0.05), (38, -0.03), (39, 0.02), (40, -0.012), (41, -0.079), (42, -0.025), (43, 0.042), (44, 0.008), (45, 0.024), (46, 0.025), (47, 0.012), (48, -0.014), (49, -0.061)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.87603593 <a title="178-lsi-1" href="./acl-2013-HEADY%3A_News_headline_abstraction_through_event_pattern_clustering.html">178 acl-2013-HEADY: News headline abstraction through event pattern clustering</a></p>
<p>Author: Enrique Alfonseca ; Daniele Pighin ; Guillermo Garrido</p><p>Abstract: This paper presents HEADY: a novel, abstractive approach for headline generation from news collections. From a web-scale corpus of English news, we mine syntactic patterns that a Noisy-OR model generalizes into event descriptions. At inference time, we query the model with the patterns observed in an unseen news collection, identify the event that better captures the gist of the collection and retrieve the most appropriate pattern to generate a headline. HEADY improves over a state-of-theart open-domain title abstraction method, bridging half of the gap that separates it from extractive methods using humangenerated titles in manual evaluations, and performs comparably to human-generated headlines as evaluated with ROUGE.</p><p>2 0.7880553 <a title="178-lsi-2" href="./acl-2013-Fine-grained_Semantic_Typing_of_Emerging_Entities.html">160 acl-2013-Fine-grained Semantic Typing of Emerging Entities</a></p>
<p>Author: Ndapandula Nakashole ; Tomasz Tylenda ; Gerhard Weikum</p><p>Abstract: Methods for information extraction (IE) and knowledge base (KB) construction have been intensively studied. However, a largely under-explored case is tapping into highly dynamic sources like news streams and social media, where new entities are continuously emerging. In this paper, we present a method for discovering and semantically typing newly emerging out-ofKB entities, thus improving the freshness and recall of ontology-based IE and improving the precision and semantic rigor of open IE. Our method is based on a probabilistic model that feeds weights into integer linear programs that leverage type signatures of relational phrases and type correlation or disjointness constraints. Our experimental evaluation, based on crowdsourced user studies, show our method performing significantly better than prior work.</p><p>3 0.71641886 <a title="178-lsi-3" href="./acl-2013-Towards_Accurate_Distant_Supervision_for_Relational_Facts_Extraction.html">352 acl-2013-Towards Accurate Distant Supervision for Relational Facts Extraction</a></p>
<p>Author: Xingxing Zhang ; Jianwen Zhang ; Junyu Zeng ; Jun Yan ; Zheng Chen ; Zhifang Sui</p><p>Abstract: Distant supervision (DS) is an appealing learning method which learns from existing relational facts to extract more from a text corpus. However, the accuracy is still not satisfying. In this paper, we point out and analyze some critical factors in DS which have great impact on accuracy, including valid entity type detection, negative training examples construction and ensembles. We propose an approach to handle these factors. By experimenting on Wikipedia articles to extract the facts in Freebase (the top 92 relations), we show the impact of these three factors on the accuracy of DS and the remarkable improvement led by the proposed approach.</p><p>4 0.70304316 <a title="178-lsi-4" href="./acl-2013-Learning_Entity_Representation_for_Entity_Disambiguation.html">219 acl-2013-Learning Entity Representation for Entity Disambiguation</a></p>
<p>Author: Zhengyan He ; Shujie Liu ; Mu Li ; Ming Zhou ; Longkai Zhang ; Houfeng Wang</p><p>Abstract: We propose a novel entity disambiguation model, based on Deep Neural Network (DNN). Instead of utilizing simple similarity measures and their disjoint combinations, our method directly optimizes document and entity representations for a given similarity measure. Stacked Denoising Auto-encoders are first employed to learn an initial document representation in an unsupervised pre-training stage. A supervised fine-tuning stage follows to optimize the representation towards the similarity measure. Experiment results show that our method achieves state-of-the-art performance on two public datasets without any manually designed features, even beating complex collective approaches.</p><p>5 0.69776624 <a title="178-lsi-5" href="./acl-2013-Graph-based_Local_Coherence_Modeling.html">172 acl-2013-Graph-based Local Coherence Modeling</a></p>
<p>Author: Camille Guinaudeau ; Michael Strube</p><p>Abstract: We propose a computationally efficient graph-based approach for local coherence modeling. We evaluate our system on three tasks: sentence ordering, summary coherence rating and readability assessment. The performance is comparable to entity grid based approaches though these rely on a computationally expensive training phase and face data sparsity problems.</p><p>6 0.68082315 <a title="178-lsi-6" href="./acl-2013-Using_Integer_Linear_Programming_in_Concept-to-Text_Generation_to_Produce_More_Compact_Texts.html">375 acl-2013-Using Integer Linear Programming in Concept-to-Text Generation to Produce More Compact Texts</a></p>
<p>7 0.67746544 <a title="178-lsi-7" href="./acl-2013-Using_Supervised_Bigram-based_ILP_for_Extractive_Summarization.html">377 acl-2013-Using Supervised Bigram-based ILP for Extractive Summarization</a></p>
<p>8 0.67679691 <a title="178-lsi-8" href="./acl-2013-HYENA-live%3A_Fine-Grained_Online_Entity_Type_Classification_from_Natural-language_Text.html">179 acl-2013-HYENA-live: Fine-Grained Online Entity Type Classification from Natural-language Text</a></p>
<p>9 0.65117681 <a title="178-lsi-9" href="./acl-2013-Entity_Linking_for_Tweets.html">139 acl-2013-Entity Linking for Tweets</a></p>
<p>10 0.62744892 <a title="178-lsi-10" href="./acl-2013-Filling_Knowledge_Base_Gaps_for_Distant_Supervision_of_Relation_Extraction.html">159 acl-2013-Filling Knowledge Base Gaps for Distant Supervision of Relation Extraction</a></p>
<p>11 0.61398453 <a title="178-lsi-11" href="./acl-2013-A_Decade_of_Automatic_Content_Evaluation_of_News_Summaries%3A_Reassessing_the_State_of_the_Art.html">5 acl-2013-A Decade of Automatic Content Evaluation of News Summaries: Reassessing the State of the Art</a></p>
<p>12 0.60919714 <a title="178-lsi-12" href="./acl-2013-Towards_Robust_Abstractive_Multi-Document_Summarization%3A_A_Caseframe_Analysis_of_Centrality_and_Domain.html">353 acl-2013-Towards Robust Abstractive Multi-Document Summarization: A Caseframe Analysis of Centrality and Domain</a></p>
<p>13 0.59884256 <a title="178-lsi-13" href="./acl-2013-A_Statistical_NLG_Framework_for_Aggregated_Planning_and_Realization.html">21 acl-2013-A Statistical NLG Framework for Aggregated Planning and Realization</a></p>
<p>14 0.58415318 <a title="178-lsi-14" href="./acl-2013-Text-Driven_Toponym_Resolution_using_Indirect_Supervision.html">340 acl-2013-Text-Driven Toponym Resolution using Indirect Supervision</a></p>
<p>15 0.58003592 <a title="178-lsi-15" href="./acl-2013-Learning_to_Order_Natural_Language_Texts.html">225 acl-2013-Learning to Order Natural Language Texts</a></p>
<p>16 0.5792954 <a title="178-lsi-16" href="./acl-2013-Domain-Independent_Abstract_Generation_for_Focused_Meeting_Summarization.html">129 acl-2013-Domain-Independent Abstract Generation for Focused Meeting Summarization</a></p>
<p>17 0.57378316 <a title="178-lsi-17" href="./acl-2013-Summarization_Through_Submodularity_and_Dispersion.html">333 acl-2013-Summarization Through Submodularity and Dispersion</a></p>
<p>18 0.55749214 <a title="178-lsi-18" href="./acl-2013-Understanding_Tables_in_Context_Using_Standard_NLP_Toolkits.html">365 acl-2013-Understanding Tables in Context Using Standard NLP Toolkits</a></p>
<p>19 0.55529398 <a title="178-lsi-19" href="./acl-2013-Subtree_Extractive_Summarization_via_Submodular_Maximization.html">332 acl-2013-Subtree Extractive Summarization via Submodular Maximization</a></p>
<p>20 0.55207396 <a title="178-lsi-20" href="./acl-2013-Fast_and_Robust_Compressive_Summarization_with_Dual_Decomposition_and_Multi-Task_Learning.html">157 acl-2013-Fast and Robust Compressive Summarization with Dual Decomposition and Multi-Task Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(4, 0.017), (8, 0.075), (9, 0.013), (38, 0.013), (41, 0.049), (42, 0.011), (53, 0.227), (55, 0.014), (76, 0.032), (86, 0.024), (87, 0.063), (90, 0.05), (93, 0.281), (95, 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.79366785 <a title="178-lda-1" href="./acl-2013-Linguistic_Models_for_Analyzing_and_Detecting_Biased_Language.html">232 acl-2013-Linguistic Models for Analyzing and Detecting Biased Language</a></p>
<p>Author: Marta Recasens ; Cristian Danescu-Niculescu-Mizil ; Dan Jurafsky</p><p>Abstract: Unbiased language is a requirement for reference sources like encyclopedias and scientific texts. Bias is, nonetheless, ubiquitous, making it crucial to understand its nature and linguistic realization and hence detect bias automatically. To this end we analyze real instances of human edits designed to remove bias from Wikipedia articles. The analysis uncovers two classes of bias: framing bias, such as praising or perspective-specific words, which we link to the literature on subjectivity; and epistemological bias, related to whether propositions that are presupposed or entailed in the text are uncontroversially accepted as true. We identify common linguistic cues for these classes, including factive verbs, implicatives, hedges, and subjective inten- cs . sifiers. These insights help us develop features for a model to solve a new prediction task of practical importance: given a biased sentence, identify the bias-inducing word. Our linguistically-informed model performs almost as well as humans tested on the same task.</p><p>same-paper 2 0.7429927 <a title="178-lda-2" href="./acl-2013-HEADY%3A_News_headline_abstraction_through_event_pattern_clustering.html">178 acl-2013-HEADY: News headline abstraction through event pattern clustering</a></p>
<p>Author: Enrique Alfonseca ; Daniele Pighin ; Guillermo Garrido</p><p>Abstract: This paper presents HEADY: a novel, abstractive approach for headline generation from news collections. From a web-scale corpus of English news, we mine syntactic patterns that a Noisy-OR model generalizes into event descriptions. At inference time, we query the model with the patterns observed in an unseen news collection, identify the event that better captures the gist of the collection and retrieve the most appropriate pattern to generate a headline. HEADY improves over a state-of-theart open-domain title abstraction method, bridging half of the gap that separates it from extractive methods using humangenerated titles in manual evaluations, and performs comparably to human-generated headlines as evaluated with ROUGE.</p><p>3 0.73175853 <a title="178-lda-3" href="./acl-2013-Modeling_Thesis_Clarity_in_Student_Essays.html">246 acl-2013-Modeling Thesis Clarity in Student Essays</a></p>
<p>Author: Isaac Persing ; Vincent Ng</p><p>Abstract: Recently, researchers have begun exploring methods of scoring student essays with respect to particular dimensions of quality such as coherence, technical errors, and relevance to prompt, but there is relatively little work on modeling thesis clarity. We present a new annotated corpus and propose a learning-based approach to scoring essays along the thesis clarity dimension. Additionally, in order to provide more valuable feedback on why an essay is scored as it is, we propose a second learning-based approach to identifying what kinds of errors an essay has that may lower its thesis clarity score.</p><p>4 0.70893872 <a title="178-lda-4" href="./acl-2013-Detecting_Event-Related_Links_and_Sentiments_from_Social_Media_Texts.html">115 acl-2013-Detecting Event-Related Links and Sentiments from Social Media Texts</a></p>
<p>Author: Alexandra Balahur ; Hristo Tanev</p><p>Abstract: Nowadays, the importance of Social Media is constantly growing, as people often use such platforms to share mainstream media news and comment on the events that they relate to. As such, people no loger remain mere spectators to the events that happen in the world, but become part of them, commenting on their developments and the entities involved, sharing their opinions and distributing related content. This paper describes a system that links the main events detected from clusters of newspaper articles to tweets related to them, detects complementary information sources from the links they contain and subsequently applies sentiment analysis to classify them into positive, negative and neutral. In this manner, readers can follow the main events happening in the world, both from the perspective of mainstream as well as social media and the public’s perception on them. This system will be part of the EMM media monitoring framework working live and it will be demonstrated using Google Earth.</p><p>5 0.66787821 <a title="178-lda-5" href="./acl-2013-Large-scale_Semantic_Parsing_via_Schema_Matching_and_Lexicon_Extension.html">215 acl-2013-Large-scale Semantic Parsing via Schema Matching and Lexicon Extension</a></p>
<p>Author: Qingqing Cai ; Alexander Yates</p><p>Abstract: Supervised training procedures for semantic parsers produce high-quality semantic parsers, but they have difficulty scaling to large databases because of the sheer number of logical constants for which they must see labeled training data. We present a technique for developing semantic parsers for large databases based on a reduction to standard supervised training algorithms, schema matching, and pattern learning. Leveraging techniques from each of these areas, we develop a semantic parser for Freebase that is capable of parsing questions with an F1 that improves by 0.42 over a purely-supervised learning algorithm.</p><p>6 0.66731369 <a title="178-lda-6" href="./acl-2013-A_Lightweight_and_High_Performance_Monolingual_Word_Aligner.html">9 acl-2013-A Lightweight and High Performance Monolingual Word Aligner</a></p>
<p>7 0.66544014 <a title="178-lda-7" href="./acl-2013-The_Role_of_Syntax_in_Vector_Space_Models_of_Compositional_Semantics.html">347 acl-2013-The Role of Syntax in Vector Space Models of Compositional Semantics</a></p>
<p>8 0.66501087 <a title="178-lda-8" href="./acl-2013-Generalized_Reordering_Rules_for_Improved_SMT.html">166 acl-2013-Generalized Reordering Rules for Improved SMT</a></p>
<p>9 0.66490638 <a title="178-lda-9" href="./acl-2013-Identifying_Opinion_Subgroups_in_Arabic_Online_Discussions.html">187 acl-2013-Identifying Opinion Subgroups in Arabic Online Discussions</a></p>
<p>10 0.66419125 <a title="178-lda-10" href="./acl-2013-Generating_Recommendation_Dialogs_by_Extracting_Information_from_User_Reviews.html">168 acl-2013-Generating Recommendation Dialogs by Extracting Information from User Reviews</a></p>
<p>11 0.66385764 <a title="178-lda-11" href="./acl-2013-Training_Nondeficient_Variants_of_IBM-3_and_IBM-4_for_Word_Alignment.html">354 acl-2013-Training Nondeficient Variants of IBM-3 and IBM-4 for Word Alignment</a></p>
<p>12 0.66361582 <a title="178-lda-12" href="./acl-2013-Syntactic_Patterns_versus_Word_Alignment%3A_Extracting_Opinion_Targets_from_Online_Reviews.html">336 acl-2013-Syntactic Patterns versus Word Alignment: Extracting Opinion Targets from Online Reviews</a></p>
<p>13 0.66329771 <a title="178-lda-13" href="./acl-2013-Cut_the_noise%3A_Mutually_reinforcing_reordering_and_alignments_for_improved_machine_translation.html">101 acl-2013-Cut the noise: Mutually reinforcing reordering and alignments for improved machine translation</a></p>
<p>14 0.66302025 <a title="178-lda-14" href="./acl-2013-Non-Monotonic_Sentence_Alignment_via_Semisupervised_Learning.html">259 acl-2013-Non-Monotonic Sentence Alignment via Semisupervised Learning</a></p>
<p>15 0.66296291 <a title="178-lda-15" href="./acl-2013-Accurate_Word_Segmentation_using_Transliteration_and_Language_Model_Projection.html">34 acl-2013-Accurate Word Segmentation using Transliteration and Language Model Projection</a></p>
<p>16 0.66272265 <a title="178-lda-16" href="./acl-2013-Implicatures_and_Nested_Beliefs_in_Approximate_Decentralized-POMDPs.html">190 acl-2013-Implicatures and Nested Beliefs in Approximate Decentralized-POMDPs</a></p>
<p>17 0.66212046 <a title="178-lda-17" href="./acl-2013-Language_Independent_Connectivity_Strength_Features_for_Phrase_Pivot_Statistical_Machine_Translation.html">214 acl-2013-Language Independent Connectivity Strength Features for Phrase Pivot Statistical Machine Translation</a></p>
<p>18 0.66180432 <a title="178-lda-18" href="./acl-2013-A_Tightly-coupled_Unsupervised_Clustering_and_Bilingual_Alignment_Model_for_Transliteration.html">25 acl-2013-A Tightly-coupled Unsupervised Clustering and Bilingual Alignment Model for Transliteration</a></p>
<p>19 0.66161901 <a title="178-lda-19" href="./acl-2013-Parsing_with_Compositional_Vector_Grammars.html">275 acl-2013-Parsing with Compositional Vector Grammars</a></p>
<p>20 0.66159415 <a title="178-lda-20" href="./acl-2013-Exploring_Sentiment_in_Social_Media%3A_Bootstrapping_Subjectivity_Clues_from_Multilingual_Twitter_Streams.html">148 acl-2013-Exploring Sentiment in Social Media: Bootstrapping Subjectivity Clues from Multilingual Twitter Streams</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
