<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>363 acl-2013-Two-Neighbor Orientation Model with Cross-Boundary Global Contexts</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-363" href="#">acl2013-363</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>363 acl-2013-Two-Neighbor Orientation Model with Cross-Boundary Global Contexts</h1>
<br/><p>Source: <a title="acl-2013-363-pdf" href="http://aclweb.org/anthology//P/P13/P13-1124.pdf">pdf</a></p><p>Author: Hendra Setiawan ; Bowen Zhou ; Bing Xiang ; Libin Shen</p><p>Abstract: Long distance reordering remains one of the greatest challenges in statistical machine translation research as the key contextual information may well be beyond the confine of translation units. In this paper, we propose Two-Neighbor Orientation (TNO) model that jointly models the orientation decisions between anchors and two neighboring multi-unit chunks which may cross phrase or rule boundaries. We explicitly model the longest span of such chunks, referred to as Maximal Orientation Span, to serve as a global parameter that constrains underlying local decisions. We integrate our proposed model into a state-of-the-art string-to-dependency translation system and demonstrate the efficacy of our proposal in a large-scale Chinese-to-English translation task. On NIST MT08 set, our most advanced model brings around +2.0 BLEU and -1.0 TER improvement.</p><p>Reference: <a title="acl-2013-363-reference" href="../acl2013_reference/acl-2013-Two-Neighbor_Orientation_Model_with_Cross-Boundary_Global_Contexts_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tno', 0.324), ('mos', 0.304), ('anch', 0.294), ('ory', 0.275), ('reord', 0.268), ('mr', 0.214), ('spo', 0.173), ('ml', 0.167), ('cl', 0.166), ('chunk', 0.158), ('slex', 0.154), ('cr', 0.154), ('xd', 0.143), ('xb', 0.119), ('ol', 0.119), ('mosl', 0.116), ('mosr', 0.116), ('smt', 0.106), ('pml', 0.102), ('neighb', 0.1)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="363-tfidf-1" href="./acl-2013-Two-Neighbor_Orientation_Model_with_Cross-Boundary_Global_Contexts.html">363 acl-2013-Two-Neighbor Orientation Model with Cross-Boundary Global Contexts</a></p>
<p>Author: Hendra Setiawan ; Bowen Zhou ; Bing Xiang ; Libin Shen</p><p>Abstract: Long distance reordering remains one of the greatest challenges in statistical machine translation research as the key contextual information may well be beyond the confine of translation units. In this paper, we propose Two-Neighbor Orientation (TNO) model that jointly models the orientation decisions between anchors and two neighboring multi-unit chunks which may cross phrase or rule boundaries. We explicitly model the longest span of such chunks, referred to as Maximal Orientation Span, to serve as a global parameter that constrains underlying local decisions. We integrate our proposed model into a state-of-the-art string-to-dependency translation system and demonstrate the efficacy of our proposal in a large-scale Chinese-to-English translation task. On NIST MT08 set, our most advanced model brings around +2.0 BLEU and -1.0 TER improvement.</p><p>2 0.27733102 <a title="363-tfidf-2" href="./acl-2013-Cut_the_noise%3A_Mutually_reinforcing_reordering_and_alignments_for_improved_machine_translation.html">101 acl-2013-Cut the noise: Mutually reinforcing reordering and alignments for improved machine translation</a></p>
<p>Author: Karthik Visweswariah ; Mitesh M. Khapra ; Ananthakrishnan Ramanathan</p><p>Abstract: Preordering of a source language sentence to match target word order has proved to be useful for improving machine translation systems. Previous work has shown that a reordering model can be learned from high quality manual word alignments to improve machine translation performance. In this paper, we focus on further improving the performance of the reordering model (and thereby machine translation) by using a larger corpus of sentence aligned data for which manual word alignments are not available but automatic machine generated alignments are available. The main challenge we tackle is to generate quality data for training the reordering model in spite of the machine align- ments being noisy. To mitigate the effect of noisy machine alignments, we propose a novel approach that improves reorderings produced given noisy alignments and also improves word alignments using information from the reordering model. This approach generates alignments that are 2.6 f-Measure points better than a baseline supervised aligner. The data generated allows us to train a reordering model that gives an improvement of 1.8 BLEU points on the NIST MT-08 Urdu-English evaluation set over a reordering model that only uses manual word alignments, and a gain of 5.2 BLEU points over a standard phrase-based baseline.</p><p>3 0.2352645 <a title="363-tfidf-3" href="./acl-2013-Generalized_Reordering_Rules_for_Improved_SMT.html">166 acl-2013-Generalized Reordering Rules for Improved SMT</a></p>
<p>Author: Fei Huang ; Cezar Pendus</p><p>Abstract: We present a simple yet effective approach to syntactic reordering for Statistical Machine Translation (SMT). Instead of solely relying on the top-1 best-matching rule for source sentence preordering, we generalize fully lexicalized rules into partially lexicalized and unlexicalized rules to broaden the rule coverage. Furthermore, , we consider multiple permutations of all the matching rules, and select the final reordering path based on the weighed sum of reordering probabilities of these rules. Our experiments in English-Chinese and English-Japanese translations demonstrate the effectiveness of the proposed approach: we observe consistent and significant improvement in translation quality across multiple test sets in both language pairs judged by both humans and automatic metric. 1</p><p>4 0.23279478 <a title="363-tfidf-4" href="./acl-2013-Advancements_in_Reordering_Models_for_Statistical_Machine_Translation.html">40 acl-2013-Advancements in Reordering Models for Statistical Machine Translation</a></p>
<p>Author: Minwei Feng ; Jan-Thorsten Peter ; Hermann Ney</p><p>Abstract: In this paper, we propose a novel reordering model based on sequence labeling techniques. Our model converts the reordering problem into a sequence labeling problem, i.e. a tagging task. Results on five Chinese-English NIST tasks show that our model improves the baseline system by 1.32 BLEU and 1.53 TER on average. Results of comparative study with other seven widely used reordering models will also be reported.</p><p>5 0.20092827 <a title="363-tfidf-5" href="./acl-2013-A_Shift-Reduce_Parsing_Algorithm_for_Phrase-based_String-to-Dependency_Translation.html">19 acl-2013-A Shift-Reduce Parsing Algorithm for Phrase-based String-to-Dependency Translation</a></p>
<p>Author: Yang Liu</p><p>Abstract: We introduce a shift-reduce parsing algorithm for phrase-based string-todependency translation. As the algorithm generates dependency trees for partial translations left-to-right in decoding, it allows for efficient integration of both n-gram and dependency language models. To resolve conflicts in shift-reduce parsing, we propose a maximum entropy model trained on the derivation graph of training data. As our approach combines the merits of phrase-based and string-todependency models, it achieves significant improvements over the two baselines on the NIST Chinese-English datasets.</p><p>6 0.17268427 <a title="363-tfidf-6" href="./acl-2013-Integrating_Phrase-based_Reordering_Features_into_a_Chart-based_Decoder_for_Machine_Translation.html">200 acl-2013-Integrating Phrase-based Reordering Features into a Chart-based Decoder for Machine Translation</a></p>
<p>7 0.15593702 <a title="363-tfidf-7" href="./acl-2013-Travatar%3A_A_Forest-to-String_Machine_Translation_Engine_based_on_Tree_Transducers.html">361 acl-2013-Travatar: A Forest-to-String Machine Translation Engine based on Tree Transducers</a></p>
<p>8 0.12746347 <a title="363-tfidf-8" href="./acl-2013-Learning_a_Phrase-based_Translation_Model_from_Monolingual_Data_with_Application_to_Domain_Adaptation.html">223 acl-2013-Learning a Phrase-based Translation Model from Monolingual Data with Application to Domain Adaptation</a></p>
<p>9 0.11484978 <a title="363-tfidf-9" href="./acl-2013-Semantic_Roles_for_String_to_Tree_Machine_Translation.html">314 acl-2013-Semantic Roles for String to Tree Machine Translation</a></p>
<p>10 0.11352275 <a title="363-tfidf-10" href="./acl-2013-Additive_Neural_Networks_for_Statistical_Machine_Translation.html">38 acl-2013-Additive Neural Networks for Statistical Machine Translation</a></p>
<p>11 0.11070126 <a title="363-tfidf-11" href="./acl-2013-Docent%3A_A_Document-Level_Decoder_for_Phrase-Based_Statistical_Machine_Translation.html">127 acl-2013-Docent: A Document-Level Decoder for Phrase-Based Statistical Machine Translation</a></p>
<p>12 0.10980699 <a title="363-tfidf-12" href="./acl-2013-A_Multi-Domain_Translation_Model_Framework_for_Statistical_Machine_Translation.html">11 acl-2013-A Multi-Domain Translation Model Framework for Statistical Machine Translation</a></p>
<p>13 0.10849797 <a title="363-tfidf-13" href="./acl-2013-Shallow_Local_Multi-Bottom-up_Tree_Transducers_in_Statistical_Machine_Translation.html">320 acl-2013-Shallow Local Multi-Bottom-up Tree Transducers in Statistical Machine Translation</a></p>
<p>14 0.10796046 <a title="363-tfidf-14" href="./acl-2013-Improving_machine_translation_by_training_against_an_automatic_semantic_frame_based_evaluation_metric.html">195 acl-2013-Improving machine translation by training against an automatic semantic frame based evaluation metric</a></p>
<p>15 0.10556564 <a title="363-tfidf-15" href="./acl-2013-Integrating_Translation_Memory_into_Phrase-Based_Machine_Translation_during_Decoding.html">201 acl-2013-Integrating Translation Memory into Phrase-Based Machine Translation during Decoding</a></p>
<p>16 0.10189038 <a title="363-tfidf-16" href="./acl-2013-Can_Markov_Models_Over_Minimal_Translation_Units_Help_Phrase-Based_SMT%3F.html">77 acl-2013-Can Markov Models Over Minimal Translation Units Help Phrase-Based SMT?</a></p>
<p>17 0.098327123 <a title="363-tfidf-17" href="./acl-2013-Hierarchical_Phrase_Table_Combination_for_Machine_Translation.html">181 acl-2013-Hierarchical Phrase Table Combination for Machine Translation</a></p>
<p>18 0.095113382 <a title="363-tfidf-18" href="./acl-2013-An_Infinite_Hierarchical_Bayesian_Model_of_Phrasal_Translation.html">46 acl-2013-An Infinite Hierarchical Bayesian Model of Phrasal Translation</a></p>
<p>19 0.093375571 <a title="363-tfidf-19" href="./acl-2013-A_Markov_Model_of_Machine_Translation_using_Non-parametric_Bayesian_Inference.html">10 acl-2013-A Markov Model of Machine Translation using Non-parametric Bayesian Inference</a></p>
<p>20 0.091075197 <a title="363-tfidf-20" href="./acl-2013-Name-aware_Machine_Translation.html">255 acl-2013-Name-aware Machine Translation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.234), (1, 0.133), (2, 0.14), (3, 0.118), (4, 0.081), (5, -0.038), (6, -0.065), (7, -0.037), (8, -0.021), (9, 0.061), (10, -0.016), (11, 0.047), (12, 0.064), (13, -0.056), (14, 0.088), (15, -0.04), (16, 0.012), (17, -0.014), (18, 0.001), (19, -0.048), (20, 0.112), (21, -0.113), (22, 0.007), (23, 0.167), (24, -0.004), (25, 0.005), (26, 0.051), (27, -0.132), (28, 0.104), (29, 0.08), (30, -0.005), (31, 0.003), (32, -0.008), (33, 0.022), (34, 0.004), (35, 0.002), (36, -0.01), (37, -0.012), (38, -0.043), (39, 0.013), (40, 0.011), (41, -0.014), (42, -0.016), (43, -0.05), (44, -0.034), (45, -0.022), (46, 0.027), (47, -0.028), (48, -0.038), (49, 0.001)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.91963172 <a title="363-lsi-1" href="./acl-2013-Generalized_Reordering_Rules_for_Improved_SMT.html">166 acl-2013-Generalized Reordering Rules for Improved SMT</a></p>
<p>Author: Fei Huang ; Cezar Pendus</p><p>Abstract: We present a simple yet effective approach to syntactic reordering for Statistical Machine Translation (SMT). Instead of solely relying on the top-1 best-matching rule for source sentence preordering, we generalize fully lexicalized rules into partially lexicalized and unlexicalized rules to broaden the rule coverage. Furthermore, , we consider multiple permutations of all the matching rules, and select the final reordering path based on the weighed sum of reordering probabilities of these rules. Our experiments in English-Chinese and English-Japanese translations demonstrate the effectiveness of the proposed approach: we observe consistent and significant improvement in translation quality across multiple test sets in both language pairs judged by both humans and automatic metric. 1</p><p>same-paper 2 0.89669603 <a title="363-lsi-2" href="./acl-2013-Two-Neighbor_Orientation_Model_with_Cross-Boundary_Global_Contexts.html">363 acl-2013-Two-Neighbor Orientation Model with Cross-Boundary Global Contexts</a></p>
<p>Author: Hendra Setiawan ; Bowen Zhou ; Bing Xiang ; Libin Shen</p><p>Abstract: Long distance reordering remains one of the greatest challenges in statistical machine translation research as the key contextual information may well be beyond the confine of translation units. In this paper, we propose Two-Neighbor Orientation (TNO) model that jointly models the orientation decisions between anchors and two neighboring multi-unit chunks which may cross phrase or rule boundaries. We explicitly model the longest span of such chunks, referred to as Maximal Orientation Span, to serve as a global parameter that constrains underlying local decisions. We integrate our proposed model into a state-of-the-art string-to-dependency translation system and demonstrate the efficacy of our proposal in a large-scale Chinese-to-English translation task. On NIST MT08 set, our most advanced model brings around +2.0 BLEU and -1.0 TER improvement.</p><p>3 0.86890012 <a title="363-lsi-3" href="./acl-2013-Integrating_Phrase-based_Reordering_Features_into_a_Chart-based_Decoder_for_Machine_Translation.html">200 acl-2013-Integrating Phrase-based Reordering Features into a Chart-based Decoder for Machine Translation</a></p>
<p>Author: ThuyLinh Nguyen ; Stephan Vogel</p><p>Abstract: Hiero translation models have two limitations compared to phrase-based models: 1) Limited hypothesis space; 2) No lexicalized reordering model. We propose an extension of Hiero called PhrasalHiero to address Hiero’s second problem. Phrasal-Hiero still has the same hypothesis space as the original Hiero but incorporates a phrase-based distance cost feature and lexicalized reodering features into the chart decoder. The work consists of two parts: 1) for each Hiero translation derivation, find its corresponding dis- continuous phrase-based path. 2) Extend the chart decoder to incorporate features from the phrase-based path. We achieve significant improvement over both Hiero and phrase-based baselines for ArabicEnglish, Chinese-English and GermanEnglish translation.</p><p>4 0.84744567 <a title="363-lsi-4" href="./acl-2013-Advancements_in_Reordering_Models_for_Statistical_Machine_Translation.html">40 acl-2013-Advancements in Reordering Models for Statistical Machine Translation</a></p>
<p>Author: Minwei Feng ; Jan-Thorsten Peter ; Hermann Ney</p><p>Abstract: In this paper, we propose a novel reordering model based on sequence labeling techniques. Our model converts the reordering problem into a sequence labeling problem, i.e. a tagging task. Results on five Chinese-English NIST tasks show that our model improves the baseline system by 1.32 BLEU and 1.53 TER on average. Results of comparative study with other seven widely used reordering models will also be reported.</p><p>5 0.82705915 <a title="363-lsi-5" href="./acl-2013-Distortion_Model_Considering_Rich_Context_for_Statistical_Machine_Translation.html">125 acl-2013-Distortion Model Considering Rich Context for Statistical Machine Translation</a></p>
<p>Author: Isao Goto ; Masao Utiyama ; Eiichiro Sumita ; Akihiro Tamura ; Sadao Kurohashi</p><p>Abstract: This paper proposes new distortion models for phrase-based SMT. In decoding, a distortion model estimates the source word position to be translated next (NP) given the last translated source word position (CP). We propose a distortion model that can consider the word at the CP, a word at an NP candidate, and the context of the CP and the NP candidate simultaneously. Moreover, we propose a further improved model that considers richer context by discriminating label sequences that specify spans from the CP to NP candidates. It enables our model to learn the effect of relative word order among NP candidates as well as to learn the effect of distances from the training data. In our experiments, our model improved 2.9 BLEU points for Japanese-English and 2.6 BLEU points for Chinese-English translation compared to the lexical reordering models.</p><p>6 0.82621008 <a title="363-lsi-6" href="./acl-2013-Cut_the_noise%3A_Mutually_reinforcing_reordering_and_alignments_for_improved_machine_translation.html">101 acl-2013-Cut the noise: Mutually reinforcing reordering and alignments for improved machine translation</a></p>
<p>7 0.82595927 <a title="363-lsi-7" href="./acl-2013-Can_Markov_Models_Over_Minimal_Translation_Units_Help_Phrase-Based_SMT%3F.html">77 acl-2013-Can Markov Models Over Minimal Translation Units Help Phrase-Based SMT?</a></p>
<p>8 0.62944728 <a title="363-lsi-8" href="./acl-2013-A_Shift-Reduce_Parsing_Algorithm_for_Phrase-based_String-to-Dependency_Translation.html">19 acl-2013-A Shift-Reduce Parsing Algorithm for Phrase-based String-to-Dependency Translation</a></p>
<p>9 0.62746853 <a title="363-lsi-9" href="./acl-2013-Travatar%3A_A_Forest-to-String_Machine_Translation_Engine_based_on_Tree_Transducers.html">361 acl-2013-Travatar: A Forest-to-String Machine Translation Engine based on Tree Transducers</a></p>
<p>10 0.61918229 <a title="363-lsi-10" href="./acl-2013-Shallow_Local_Multi-Bottom-up_Tree_Transducers_in_Statistical_Machine_Translation.html">320 acl-2013-Shallow Local Multi-Bottom-up Tree Transducers in Statistical Machine Translation</a></p>
<p>11 0.5813849 <a title="363-lsi-11" href="./acl-2013-Integrating_Translation_Memory_into_Phrase-Based_Machine_Translation_during_Decoding.html">201 acl-2013-Integrating Translation Memory into Phrase-Based Machine Translation during Decoding</a></p>
<p>12 0.55133247 <a title="363-lsi-12" href="./acl-2013-Docent%3A_A_Document-Level_Decoder_for_Phrase-Based_Statistical_Machine_Translation.html">127 acl-2013-Docent: A Document-Level Decoder for Phrase-Based Statistical Machine Translation</a></p>
<p>13 0.53374463 <a title="363-lsi-13" href="./acl-2013-Semantic_Parsing_as_Machine_Translation.html">312 acl-2013-Semantic Parsing as Machine Translation</a></p>
<p>14 0.52941495 <a title="363-lsi-14" href="./acl-2013-Stacking_for_Statistical_Machine_Translation.html">328 acl-2013-Stacking for Statistical Machine Translation</a></p>
<p>15 0.51008117 <a title="363-lsi-15" href="./acl-2013-Learning_to_Prune%3A_Context-Sensitive_Pruning_for_Syntactic_MT.html">226 acl-2013-Learning to Prune: Context-Sensitive Pruning for Syntactic MT</a></p>
<p>16 0.50159699 <a title="363-lsi-16" href="./acl-2013-Learning_Non-linear_Features_for_Machine_Translation_Using_Gradient_Boosting_Machines.html">221 acl-2013-Learning Non-linear Features for Machine Translation Using Gradient Boosting Machines</a></p>
<p>17 0.4932909 <a title="363-lsi-17" href="./acl-2013-An_Infinite_Hierarchical_Bayesian_Model_of_Phrasal_Translation.html">46 acl-2013-An Infinite Hierarchical Bayesian Model of Phrasal Translation</a></p>
<p>18 0.49255633 <a title="363-lsi-18" href="./acl-2013-Bilingual_Data_Cleaning_for_SMT_using_Graph-based_Random_Walk.html">68 acl-2013-Bilingual Data Cleaning for SMT using Graph-based Random Walk</a></p>
<p>19 0.48741159 <a title="363-lsi-19" href="./acl-2013-Deepfix%3A_Statistical_Post-editing_of_Statistical_Machine_Translation_Using_Deep_Syntactic_Analysis.html">110 acl-2013-Deepfix: Statistical Post-editing of Statistical Machine Translation Using Deep Syntactic Analysis</a></p>
<p>20 0.48664993 <a title="363-lsi-20" href="./acl-2013-A_Markov_Model_of_Machine_Translation_using_Non-parametric_Bayesian_Inference.html">10 acl-2013-A Markov Model of Machine Translation using Non-parametric Bayesian Inference</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(8, 0.091), (9, 0.277), (41, 0.079), (42, 0.02), (53, 0.231), (55, 0.024), (76, 0.018), (87, 0.085), (90, 0.053), (95, 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.88424349 <a title="363-lda-1" href="./acl-2013-Tag2Blog%3A_Narrative_Generation_from_Satellite_Tag_Data.html">337 acl-2013-Tag2Blog: Narrative Generation from Satellite Tag Data</a></p>
<p>Author: Kapila Ponnamperuma ; Advaith Siddharthan ; Cheng Zeng ; Chris Mellish ; Rene van der Wal</p><p>Abstract: The aim of the Tag2Blog system is to bring satellite tagged wild animals “to life” through narratives that place their movements in an ecological context. Our motivation is to use such automatically generated texts to enhance public engagement with a specific species reintroduction programme, although the protocols developed here can be applied to any animal or other movement study that involves signal data from tags. We are working with one of the largest nature conservation charities in Europe in this regard, focusing on a single species, the red kite. We describe a system that interprets a sequence of locational fixes obtained from a satellite tagged individual, and constructs a story around its use of the landscape.</p><p>2 0.81930929 <a title="363-lda-2" href="./acl-2013-The_effect_of_non-tightness_on_Bayesian_estimation_of_PCFGs.html">348 acl-2013-The effect of non-tightness on Bayesian estimation of PCFGs</a></p>
<p>Author: Shay B. Cohen ; Mark Johnson</p><p>Abstract: Probabilistic context-free grammars have the unusual property of not always defining tight distributions (i.e., the sum of the “probabilities” of the trees the grammar generates can be less than one). This paper reviews how this non-tightness can arise and discusses its impact on Bayesian estimation of PCFGs. We begin by presenting the notion of “almost everywhere tight grammars” and show that linear CFGs follow it. We then propose three different ways of reinterpreting non-tight PCFGs to make them tight, show that the Bayesian estimators in Johnson et al. (2007) are correct under one of them, and provide MCMC samplers for the other two. We conclude with a discussion of the impact of tightness empirically.</p><p>3 0.80424595 <a title="363-lda-3" href="./acl-2013-Automated_Pyramid_Scoring_of_Summaries_using_Distributional_Semantics.html">59 acl-2013-Automated Pyramid Scoring of Summaries using Distributional Semantics</a></p>
<p>Author: Rebecca J. Passonneau ; Emily Chen ; Weiwei Guo ; Dolores Perin</p><p>Abstract: The pyramid method for content evaluation of automated summarizers produces scores that are shown to correlate well with manual scores used in educational assessment of students’ summaries. This motivates the development of a more accurate automated method to compute pyramid scores. Of three methods tested here, the one that performs best relies on latent semantics.</p><p>4 0.7993387 <a title="363-lda-4" href="./acl-2013-Discriminative_Approach_to_Fill-in-the-Blank_Quiz_Generation_for_Language_Learners.html">122 acl-2013-Discriminative Approach to Fill-in-the-Blank Quiz Generation for Language Learners</a></p>
<p>Author: Keisuke Sakaguchi ; Yuki Arase ; Mamoru Komachi</p><p>Abstract: We propose discriminative methods to generate semantic distractors of fill-in-theblank quiz for language learners using a large-scale language learners’ corpus. Unlike previous studies, the proposed methods aim at satisfying both reliability and validity of generated distractors; distractors should be exclusive against answers to avoid multiple answers in one quiz, and distractors should discriminate learners’ proficiency. Detailed user evaluation with 3 native and 23 non-native speakers of English shows that our methods achieve better reliability and validity than previous methods.</p><p>same-paper 5 0.79543108 <a title="363-lda-5" href="./acl-2013-Two-Neighbor_Orientation_Model_with_Cross-Boundary_Global_Contexts.html">363 acl-2013-Two-Neighbor Orientation Model with Cross-Boundary Global Contexts</a></p>
<p>Author: Hendra Setiawan ; Bowen Zhou ; Bing Xiang ; Libin Shen</p><p>Abstract: Long distance reordering remains one of the greatest challenges in statistical machine translation research as the key contextual information may well be beyond the confine of translation units. In this paper, we propose Two-Neighbor Orientation (TNO) model that jointly models the orientation decisions between anchors and two neighboring multi-unit chunks which may cross phrase or rule boundaries. We explicitly model the longest span of such chunks, referred to as Maximal Orientation Span, to serve as a global parameter that constrains underlying local decisions. We integrate our proposed model into a state-of-the-art string-to-dependency translation system and demonstrate the efficacy of our proposal in a large-scale Chinese-to-English translation task. On NIST MT08 set, our most advanced model brings around +2.0 BLEU and -1.0 TER improvement.</p><p>6 0.78668344 <a title="363-lda-6" href="./acl-2013-FudanNLP%3A_A_Toolkit_for_Chinese_Natural_Language_Processing.html">164 acl-2013-FudanNLP: A Toolkit for Chinese Natural Language Processing</a></p>
<p>7 0.75926733 <a title="363-lda-7" href="./acl-2013-Iterative_Transformation_of_Annotation_Guidelines_for_Constituency_Parsing.html">204 acl-2013-Iterative Transformation of Annotation Guidelines for Constituency Parsing</a></p>
<p>8 0.71883494 <a title="363-lda-8" href="./acl-2013-Cross-lingual_Projections_between_Languages_from_Different_Families.html">97 acl-2013-Cross-lingual Projections between Languages from Different Families</a></p>
<p>9 0.71649301 <a title="363-lda-9" href="./acl-2013-The_mathematics_of_language_learning.html">349 acl-2013-The mathematics of language learning</a></p>
<p>10 0.713705 <a title="363-lda-10" href="./acl-2013-Discriminative_Learning_with_Natural_Annotations%3A_Word_Segmentation_as_a_Case_Study.html">123 acl-2013-Discriminative Learning with Natural Annotations: Word Segmentation as a Case Study</a></p>
<p>11 0.71340501 <a title="363-lda-11" href="./acl-2013-Learning_to_lemmatise_Polish_noun_phrases.html">227 acl-2013-Learning to lemmatise Polish noun phrases</a></p>
<p>12 0.7116254 <a title="363-lda-12" href="./acl-2013-Adapting_Discriminative_Reranking_to_Grounded_Language_Learning.html">36 acl-2013-Adapting Discriminative Reranking to Grounded Language Learning</a></p>
<p>13 0.7067045 <a title="363-lda-13" href="./acl-2013-Coordination_Structures_in_Dependency_Treebanks.html">94 acl-2013-Coordination Structures in Dependency Treebanks</a></p>
<p>14 0.70377862 <a title="363-lda-14" href="./acl-2013-Nonconvex_Global_Optimization_for_Latent-Variable_Models.html">260 acl-2013-Nonconvex Global Optimization for Latent-Variable Models</a></p>
<p>15 0.70363712 <a title="363-lda-15" href="./acl-2013-Parsing_with_Compositional_Vector_Grammars.html">275 acl-2013-Parsing with Compositional Vector Grammars</a></p>
<p>16 0.70168012 <a title="363-lda-16" href="./acl-2013-A_Shift-Reduce_Parsing_Algorithm_for_Phrase-based_String-to-Dependency_Translation.html">19 acl-2013-A Shift-Reduce Parsing Algorithm for Phrase-based String-to-Dependency Translation</a></p>
<p>17 0.70045096 <a title="363-lda-17" href="./acl-2013-A_Context_Free_TAG_Variant.html">4 acl-2013-A Context Free TAG Variant</a></p>
<p>18 0.70008028 <a title="363-lda-18" href="./acl-2013-A_user-centric_model_of_voting_intention_from_Social_Media.html">33 acl-2013-A user-centric model of voting intention from Social Media</a></p>
<p>19 0.69915545 <a title="363-lda-19" href="./acl-2013-Syntactic_Patterns_versus_Word_Alignment%3A_Extracting_Opinion_Targets_from_Online_Reviews.html">336 acl-2013-Syntactic Patterns versus Word Alignment: Extracting Opinion Targets from Online Reviews</a></p>
<p>20 0.69869965 <a title="363-lda-20" href="./acl-2013-Non-Monotonic_Sentence_Alignment_via_Semisupervised_Learning.html">259 acl-2013-Non-Monotonic Sentence Alignment via Semisupervised Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
