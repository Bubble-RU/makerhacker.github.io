<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>211 acl-2013-LABR: A Large Scale Arabic Book Reviews Dataset</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-211" href="#">acl2013-211</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>211 acl-2013-LABR: A Large Scale Arabic Book Reviews Dataset</h1>
<br/><p>Source: <a title="acl-2013-211-pdf" href="http://aclweb.org/anthology//P/P13/P13-2088.pdf">pdf</a></p><p>Author: Mohamed Aly ; Amir Atiya</p><p>Abstract: We introduce LABR, the largest sentiment analysis dataset to-date for the Arabic language. It consists of over 63,000 book reviews, each rated on a scale of 1 to 5 stars. We investigate the properties of the the dataset, and present its statistics. We explore using the dataset for two tasks: sentiment polarity classification and rating classification. We provide standard splits of the dataset into training and testing, for both polarity and rating classification, in both balanced and unbalanced settings. We run baseline experiments on the dataset to establish a benchmark.</p><p>Reference: <a title="acl-2013-211-reference" href="../acl2013_reference/acl-2013-LABR%3A_A_Large_Scale_Arabic_Book_Reviews_Dataset_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 info Abstract We introduce LABR, the largest sentiment analysis dataset to-date for the Arabic language. [sent-2, score-0.45]
</p><p>2 It consists of over 63,000 book reviews, each rated on a scale of 1 to 5 stars. [sent-3, score-0.255]
</p><p>3 We investigate the properties of the the dataset, and present its statistics. [sent-4, score-0.036]
</p><p>4 We explore using the dataset for two tasks: sentiment polarity classification and rating classification. [sent-5, score-0.799]
</p><p>5 We provide standard splits of the dataset into training and testing, for both polarity and rating classification, in both balanced and unbalanced settings. [sent-6, score-0.838]
</p><p>6 We run baseline experiments on the  dataset to establish a benchmark. [sent-7, score-0.137]
</p><p>7 1 Introduction The internet is full of platforms where users can express their opinions about different subjects, from movies and commercial products to books and restaurants. [sent-8, score-0.218]
</p><p>8 With the explosion of social media, this has become easier and more prevalent than ever. [sent-9, score-0.029]
</p><p>9 Mining these troves of unstructured text has become a very active area of research with lots of applications. [sent-10, score-0.034]
</p><p>10 a movie or book review, into either having a positive or negative sentiment. [sent-14, score-0.377]
</p><p>11 Another form involves predicting the actual rating of a review, e. [sent-15, score-0.226]
</p><p>12 predicting the number of stars on a scale from 1to 5 stars. [sent-17, score-0.037]
</p><p>13 Most of the current research has focused on building sentiment analysis applications for the English language (Pang and Lee, 2008; Liu, 2010; Korayem et al. [sent-18, score-0.285]
</p><p>14 In particular, there has been little work on sentiment analysis in Arabic (Abbasi et al. [sent-20, score-0.285]
</p><p>15 , 2011; Amir Atiya Computer Engineering Department Cairo University Giza, Egypt ami r@ alumni . [sent-22, score-0.028]
</p><p>16 In this work, we try to address the lack of large-scale Arabic sentiment analysis datasets in this field, in the hope of sparking more interest in research in Arabic sentiment analysis and related tasks. [sent-30, score-0.57]
</p><p>17 It is a set of over 63K book reviews, each with a rating of 1to 5 stars. [sent-32, score-0.4]
</p><p>18 We make the following contributions: (1)  We present the largest Arabic sentiment analysis dataset to-date (up to our knowledge); (2) We provide standard splits for the dataset into training and testing sets. [sent-33, score-0.613]
</p><p>19 The dataset and the splits are publicly available at www. [sent-35, score-0.191]
</p><p>20 info/datasets; (3) We explore the structure and properties of the dataset, and perform baseline experiments for two tasks: sentiment polarity classification and rating classification. [sent-37, score-0.733]
</p><p>21 2  Related Work  A few Arabic sentiment analysis datasets have been collected in the past couple of years, we mention the relevant two sets: OCA Opinion Corpus for Arabic (Rushdi-Saleh et al. [sent-38, score-0.285]
</p><p>22 , 2011b) contains 500 movie reviews in Arabic, collected from forums and websites. [sent-39, score-0.598]
</p><p>23 It is divided into 250 positive and 250 negative reviews, although the division is not standard in that there is no rating for neutral reviews i. [sent-40, score-0.994]
</p><p>24 for 10-star rating systems, ratings above and including 5 are con-  sidered positive and those below 5 are considered negative. [sent-42, score-0.362]
</p><p>25 AWATIF is a multi-genre corpus for Modern Standard Arabic sentiment analysis (Abdul494  Proce dingSsof oifa, th Beu 5l1gsarti Aan,An u aglu Mste 4e-ti9n2g 0 o1f3 t. [sent-43, score-0.285]
</p><p>26 ant o tko e kn esn s p e re r e rv eive wi ew3, 6735 6  Number of tokens4,134,853  Number of sentences342,199 Table 1: Important Dataset Statistics. [sent-50, score-0.032]
</p><p>27 The plot shows the number of reviews for each rating. [sent-52, score-0.638]
</p><p>28 It consists of about 2855 sentences of news wire stories, 5342 sentences from Wikipedia talk pages, and 2532 threaded conversations from web forums. [sent-54, score-0.034]
</p><p>29 3  Dataset Collection  We downloaded over 220,000 reviews from the book readers social network www. [sent-55, score-0.768]
</p><p>30 These reviews were from the first 2143 books in the list of Best  Arabic Books. [sent-58, score-0.736]
</p><p>31 After harvesting the reviews, we found out that over 70% of them were not in Arabic, either because some non-Arabic books exist in the list, or because of existing translations of some of the books in other languages. [sent-59, score-0.342]
</p><p>32 After filtering out the non-Arabic reviews, and performing several pre-processing steps to clean up HTML tags and other unwanted content, we ended up with 63,257 Arabic reviews. [sent-60, score-0.03]
</p><p>33 4  Dataset Properties  The dataset contains 63,257 reviews that were submitted by 16,486 users for 2,13 1 different books. [sent-61, score-0.714]
</p><p>34 Table 1 contains some important facts about the dataset and Fig. [sent-65, score-0.102]
</p><p>35 We consider as positive reviews those with ratings 4 or 5, and negative reviews those with ratings 1 or 2. [sent-67, score-1.41]
</p><p>36 Reviews with rating 3 are considered neutral and not included in the polarity classification. [sent-68, score-0.357]
</p><p>37 The number of positive reviews is much larger than that of negative reviews. [sent-69, score-0.735]
</p><p>38 We believe this is because the books we got reviews for were the most popular books, and the top rated ones had many more reviews than the the least popular books. [sent-70, score-1.384]
</p><p>39 The average book got almost 30 reviews with the median being 6. [sent-73, score-0.86]
</p><p>40 2c, most books and users have few reviews, and vice versa. [sent-77, score-0.218]
</p><p>41 Figures 2a-b show a box plot of the number of reviews per user and book. [sent-78, score-0.806]
</p><p>42 We notice that books (and users) tend to have (give) positive reviews than negative reviews, where the median number of positive reviews per book is 5 while that for negative reviews is only 2  (and similarly for reviews per user). [sent-79, score-3.201]
</p><p>43 The reviews were tokenized and “rough” sentence counts were computed (by looking for punctuation characters). [sent-82, score-0.565]
</p><p>44 4, the average number of sentences per review is 5. [sent-84, score-0.153]
</p><p>45 4, and the average number of tokens per sentence is 12. [sent-85, score-0.122]
</p><p>46 Figures 3a-b show that the distribution is similar for positive and negative reviews. [sent-86, score-0.17]
</p><p>47 3c shows a plot of the frequency of the tokens in the vocabulary in a loglog scale, which conforms to Zipf’s law (Manning and Schütze, 2000). [sent-88, score-0.155]
</p><p>48 5  Experiments  We explored using the dataset for two tasks: (a) Sentiment polarity classification: where the goal is to predict if the review is positive i. [sent-89, score-0.394]
</p><p>49 with rating 1or 2; and (b) 495  Figure 2: Users and Books Statistics. [sent-93, score-0.226]
</p><p>50 (a) Box plot of the number of reviews per user for all, positive, and negative reviews. [sent-94, score-0.841]
</p><p>51 The red line denotes the median, and the edges of the box the quartiles. [sent-95, score-0.054]
</p><p>52 (b) the number of reviews per book for all, positive, and negative reviews. [sent-96, score-0.9]
</p><p>53 (a) the number of tokens per review for all, positive, and negative reviews. [sent-99, score-0.292]
</p><p>54 Rating classification: where the goal is to predict the rating of the review on a scale of 1 to 5. [sent-102, score-0.344]
</p><p>55 To this end, we divided the dataset into separate training and test sets, with a ratio of 8:2. [sent-103, score-0.102]
</p><p>56 Table 2 shows the number of reviews in the training and test sets for each of the two tasks for the balanced and unbalanced splits, while Fig. [sent-108, score-0.888]
</p><p>57 4 shows the breakdown of these numbers per class. [sent-109, score-0.1]
</p><p>58 We report two measures: the total classification accuracy (percentage of correctly classified test examples) and weighted F1 measure (Manning and Schütze, 2000). [sent-113, score-0.056]
</p><p>59 We notice that: (a) The total accuracy and weighted F1 are quite correlated and go hand-inhand. [sent-118, score-0.03]
</p><p>60 (c) The unbalanced setting seems eas496  FeaturesTf-IdfMNBBaBlNancBedSVMMNBUnbBaNlaBncedSVM  Tab1gle+2 3:gTaskYN1eo:sPla0 . [sent-120, score-0.198]
</p><p>61 98 o07d185el,  1g+2g is using unigrams + bigrams, and 1g+2g+3g is using trigrams. [sent-132, score-0.035]
</p><p>62 Tf-Idf indicates whether tf-idf weighting was used or not. [sent-133, score-0.029]
</p><p>63 (a) Histogram of the number of training and test reviews for the polarity classification task for balanced (solid) and unbalanced (hatched) cases. [sent-164, score-1.042]
</p><p>64 In the balanced set, all classes have the same number of reviews as the  smallest class, which is done by down-sampling the larger classes. [sent-166, score-0.723]
</p><p>65 This might be because the unbalanced sets contain more training examples to make use of. [sent-168, score-0.198]
</p><p>66 (d) SVM does much better in the unbalanced setting, while MNB is slightly better than SVM in the balanced setting. [sent-169, score-0.323]
</p><p>67 6  Conclusion and Future Work  In this work we presented the largest Arabic sentiment analysis dataset to-date. [sent-171, score-0.422]
</p><p>68 We explored its properties and statistics, provided standard splits, and performed several baseline experiments to establish a benchmark. [sent-172, score-0.103]
</p><p>69 We plan next to work more on the dataset to get sentence-level polarity labels, and to extract  Arabic sentiment lexicon and explore its potential. [sent-174, score-0.517]
</p><p>70 Furthermore, we also plan to explore using Arabic-specific and more powerful features. [sent-175, score-0.032]
</p><p>71 Awatif: A multi-genre corpus for modern standard arabic subjectivity and sentiment analysis. [sent-189, score-0.722]
</p><p>72 Samar: A system for subjectivity and sentiment analysis of arabic social media. [sent-201, score-0.712]
</p><p>73 opinion preprint  Elarnaoty, Samir AbdelRahman, and Aly 2012. [sent-204, score-0.065]
</p><p>74 A machine learning approach for holder extraction in arabic language. [sent-205, score-0.343]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('reviews', 0.565), ('arabic', 0.315), ('sentiment', 0.285), ('rating', 0.226), ('unbalanced', 0.198), ('book', 0.174), ('books', 0.171), ('muhammad', 0.136), ('balanced', 0.125), ('korayem', 0.116), ('labr', 0.116), ('dataset', 0.102), ('polarity', 0.098), ('splits', 0.089), ('negative', 0.089), ('subjectivity', 0.083), ('pang', 0.082), ('median', 0.082), ('positive', 0.081), ('review', 0.081), ('mona', 0.079), ('elarnaoty', 0.078), ('pez', 0.078), ('diab', 0.075), ('plot', 0.073), ('per', 0.072), ('naive', 0.071), ('opinion', 0.065), ('bayes', 0.063), ('awatif', 0.063), ('oca', 0.063), ('aly', 0.063), ('mnb', 0.063), ('mohamed', 0.062), ('egypt', 0.057), ('pedregosa', 0.057), ('cairo', 0.057), ('classification', 0.056), ('ratings', 0.055), ('box', 0.054), ('bernoulli', 0.052), ('mart', 0.052), ('mohammed', 0.051), ('tokens', 0.05), ('users', 0.047), ('rated', 0.044), ('python', 0.044), ('arxiv', 0.043), ('ure', 0.043), ('user', 0.042), ('tze', 0.042), ('sch', 0.041), ('got', 0.039), ('modern', 0.039), ('multinomial', 0.037), ('scale', 0.037), ('properties', 0.036), ('largest', 0.035), ('unigrams', 0.035), ('establish', 0.035), ('crandall', 0.034), ('abbasi', 0.034), ('bnb', 0.034), ('samir', 0.034), ('troves', 0.034), ('wire', 0.034), ('movie', 0.033), ('neutral', 0.033), ('smallest', 0.033), ('svm', 0.032), ('explore', 0.032), ('foundations', 0.032), ('esn', 0.032), ('samar', 0.032), ('conforms', 0.032), ('urs', 0.032), ('explored', 0.032), ('notice', 0.03), ('tois', 0.03), ('bler', 0.03), ('unwanted', 0.03), ('brucher', 0.03), ('cournapeau', 0.03), ('dubourg', 0.03), ('passos', 0.03), ('perrot', 0.03), ('vanderplas', 0.03), ('bigrams', 0.029), ('weighting', 0.029), ('social', 0.029), ('giza', 0.029), ('manning', 0.028), ('class', 0.028), ('ami', 0.028), ('gramfort', 0.028), ('grisel', 0.028), ('thirion', 0.028), ('breakdown', 0.028), ('holder', 0.028), ('info', 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999997 <a title="211-tfidf-1" href="./acl-2013-LABR%3A_A_Large_Scale_Arabic_Book_Reviews_Dataset.html">211 acl-2013-LABR: A Large Scale Arabic Book Reviews Dataset</a></p>
<p>Author: Mohamed Aly ; Amir Atiya</p><p>Abstract: We introduce LABR, the largest sentiment analysis dataset to-date for the Arabic language. It consists of over 63,000 book reviews, each rated on a scale of 1 to 5 stars. We investigate the properties of the the dataset, and present its statistics. We explore using the dataset for two tasks: sentiment polarity classification and rating classification. We provide standard splits of the dataset into training and testing, for both polarity and rating classification, in both balanced and unbalanced settings. We run baseline experiments on the dataset to establish a benchmark.</p><p>2 0.36585605 <a title="211-tfidf-2" href="./acl-2013-Co-Regression_for_Cross-Language_Review_Rating_Prediction.html">81 acl-2013-Co-Regression for Cross-Language Review Rating Prediction</a></p>
<p>Author: Xiaojun Wan</p><p>Abstract: The task of review rating prediction can be well addressed by using regression algorithms if there is a reliable training set of reviews with human ratings. In this paper, we aim to investigate a more challenging task of crosslanguage review rating prediction, which makes use of only rated reviews in a source language (e.g. English) to predict the rating scores of unrated reviews in a target language (e.g. German). We propose a new coregression algorithm to address this task by leveraging unlabeled reviews. Evaluation results on several datasets show that our proposed co-regression algorithm can consistently improve the prediction results. 1</p><p>3 0.26254562 <a title="211-tfidf-3" href="./acl-2013-Identifying_Opinion_Subgroups_in_Arabic_Online_Discussions.html">187 acl-2013-Identifying Opinion Subgroups in Arabic Online Discussions</a></p>
<p>Author: Amjad Abu-Jbara ; Ben King ; Mona Diab ; Dragomir Radev</p><p>Abstract: In this paper, we use Arabic natural language processing techniques to analyze Arabic debates. The goal is to identify how the participants in a discussion split into subgroups with contrasting opinions. The members of each subgroup share the same opinion with respect to the discussion topic and an opposing opinion to the members of other subgroups. We use opinion mining techniques to identify opinion expressions and determine their polarities and their targets. We opinion predictions to represent the discussion in one of two formal representations: signed attitude network or a space of attitude vectors. We identify opinion subgroups by partitioning the signed network representation or by clustering the vector space representation. We evaluate the system using a data set of labeled discussions and show that it achieves good results.</p><p>4 0.24888572 <a title="211-tfidf-4" href="./acl-2013-Sentiment_Relevance.html">318 acl-2013-Sentiment Relevance</a></p>
<p>Author: Christian Scheible ; Hinrich Schutze</p><p>Abstract: A number of different notions, including subjectivity, have been proposed for distinguishing parts of documents that convey sentiment from those that do not. We propose a new concept, sentiment relevance, to make this distinction and argue that it better reflects the requirements of sentiment analysis systems. We demonstrate experimentally that sentiment relevance and subjectivity are related, but different. Since no large amount of labeled training data for our new notion of sentiment relevance is available, we investigate two semi-supervised methods for creating sentiment relevance classifiers: a distant supervision approach that leverages structured information about the domain of the reviews; and transfer learning on feature representations based on lexical taxonomies that enables knowledge transfer. We show that both methods learn sentiment relevance classifiers that perform well.</p><p>5 0.24733558 <a title="211-tfidf-5" href="./acl-2013-Identifying_Sentiment_Words_Using_an_Optimization-based_Model_without_Seed_Words.html">188 acl-2013-Identifying Sentiment Words Using an Optimization-based Model without Seed Words</a></p>
<p>Author: Hongliang Yu ; Zhi-Hong Deng ; Shiyingxue Li</p><p>Abstract: Sentiment Word Identification (SWI) is a basic technique in many sentiment analysis applications. Most existing researches exploit seed words, and lead to low robustness. In this paper, we propose a novel optimization-based model for SWI. Unlike previous approaches, our model exploits the sentiment labels of documents instead of seed words. Several experiments on real datasets show that WEED is effective and outperforms the state-of-the-art methods with seed words.</p><p>6 0.20561202 <a title="211-tfidf-6" href="./acl-2013-A_Bayesian_Model_for_Joint_Unsupervised_Induction_of_Sentiment%2C_Aspect_and_Discourse_Representations.html">2 acl-2013-A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations</a></p>
<p>7 0.18659879 <a title="211-tfidf-7" href="./acl-2013-Exploring_Sentiment_in_Social_Media%3A_Bootstrapping_Subjectivity_Clues_from_Multilingual_Twitter_Streams.html">148 acl-2013-Exploring Sentiment in Social Media: Bootstrapping Subjectivity Clues from Multilingual Twitter Streams</a></p>
<p>8 0.16956863 <a title="211-tfidf-8" href="./acl-2013-Utterance-Level_Multimodal_Sentiment_Analysis.html">379 acl-2013-Utterance-Level Multimodal Sentiment Analysis</a></p>
<p>9 0.15381743 <a title="211-tfidf-9" href="./acl-2013-Generating_Recommendation_Dialogs_by_Extracting_Information_from_User_Reviews.html">168 acl-2013-Generating Recommendation Dialogs by Extracting Information from User Reviews</a></p>
<p>10 0.1517857 <a title="211-tfidf-10" href="./acl-2013-Dual_Training_and_Dual_Prediction_for_Polarity_Classification.html">131 acl-2013-Dual Training and Dual Prediction for Polarity Classification</a></p>
<p>11 0.15070085 <a title="211-tfidf-11" href="./acl-2013-Character-to-Character_Sentiment_Analysis_in_Shakespeare%27s_Plays.html">79 acl-2013-Character-to-Character Sentiment Analysis in Shakespeare's Plays</a></p>
<p>12 0.1501523 <a title="211-tfidf-12" href="./acl-2013-Named_Entity_Recognition_using_Cross-lingual_Resources%3A_Arabic_as_an_Example.html">256 acl-2013-Named Entity Recognition using Cross-lingual Resources: Arabic as an Example</a></p>
<p>13 0.14764024 <a title="211-tfidf-13" href="./acl-2013-Detecting_Turnarounds_in_Sentiment_Analysis%3A_Thwarting.html">117 acl-2013-Detecting Turnarounds in Sentiment Analysis: Thwarting</a></p>
<p>14 0.14595678 <a title="211-tfidf-14" href="./acl-2013-Probabilistic_Sense_Sentiment_Similarity_through_Hidden_Emotions.html">284 acl-2013-Probabilistic Sense Sentiment Similarity through Hidden Emotions</a></p>
<p>15 0.14591391 <a title="211-tfidf-15" href="./acl-2013-The_Haves_and_the_Have-Nots%3A_Leveraging_Unlabelled_Corpora_for_Sentiment_Analysis.html">345 acl-2013-The Haves and the Have-Nots: Leveraging Unlabelled Corpora for Sentiment Analysis</a></p>
<p>16 0.14401206 <a title="211-tfidf-16" href="./acl-2013-Detecting_Event-Related_Links_and_Sentiments_from_Social_Media_Texts.html">115 acl-2013-Detecting Event-Related Links and Sentiments from Social Media Texts</a></p>
<p>17 0.12067006 <a title="211-tfidf-17" href="./acl-2013-TopicSpam%3A_a_Topic-Model_based_approach_for_spam_detection.html">350 acl-2013-TopicSpam: a Topic-Model based approach for spam detection</a></p>
<p>18 0.1172223 <a title="211-tfidf-18" href="./acl-2013-Mining_Opinion_Words_and_Opinion_Targets_in_a_Two-Stage_Framework.html">244 acl-2013-Mining Opinion Words and Opinion Targets in a Two-Stage Framework</a></p>
<p>19 0.11305447 <a title="211-tfidf-19" href="./acl-2013-Exploiting_Topic_based_Twitter_Sentiment_for_Stock_Prediction.html">147 acl-2013-Exploiting Topic based Twitter Sentiment for Stock Prediction</a></p>
<p>20 0.10834722 <a title="211-tfidf-20" href="./acl-2013-Scaling_Semi-supervised_Naive_Bayes_with_Feature_Marginals.html">309 acl-2013-Scaling Semi-supervised Naive Bayes with Feature Marginals</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.159), (1, 0.3), (2, -0.013), (3, 0.294), (4, -0.087), (5, -0.079), (6, -0.008), (7, -0.002), (8, 0.033), (9, 0.095), (10, 0.098), (11, -0.015), (12, -0.034), (13, -0.002), (14, -0.04), (15, 0.073), (16, -0.061), (17, -0.013), (18, 0.01), (19, 0.177), (20, -0.03), (21, 0.043), (22, -0.001), (23, 0.123), (24, 0.018), (25, -0.099), (26, -0.021), (27, -0.031), (28, -0.006), (29, -0.166), (30, -0.098), (31, -0.015), (32, 0.063), (33, -0.019), (34, 0.054), (35, 0.007), (36, -0.073), (37, 0.107), (38, 0.02), (39, 0.059), (40, 0.021), (41, -0.088), (42, -0.097), (43, 0.073), (44, 0.079), (45, 0.003), (46, -0.016), (47, -0.032), (48, -0.044), (49, 0.01)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98340774 <a title="211-lsi-1" href="./acl-2013-LABR%3A_A_Large_Scale_Arabic_Book_Reviews_Dataset.html">211 acl-2013-LABR: A Large Scale Arabic Book Reviews Dataset</a></p>
<p>Author: Mohamed Aly ; Amir Atiya</p><p>Abstract: We introduce LABR, the largest sentiment analysis dataset to-date for the Arabic language. It consists of over 63,000 book reviews, each rated on a scale of 1 to 5 stars. We investigate the properties of the the dataset, and present its statistics. We explore using the dataset for two tasks: sentiment polarity classification and rating classification. We provide standard splits of the dataset into training and testing, for both polarity and rating classification, in both balanced and unbalanced settings. We run baseline experiments on the dataset to establish a benchmark.</p><p>2 0.76413101 <a title="211-lsi-2" href="./acl-2013-Detecting_Turnarounds_in_Sentiment_Analysis%3A_Thwarting.html">117 acl-2013-Detecting Turnarounds in Sentiment Analysis: Thwarting</a></p>
<p>Author: Ankit Ramteke ; Akshat Malu ; Pushpak Bhattacharyya ; J. Saketha Nath</p><p>Abstract: Thwarting and sarcasm are two uncharted territories in sentiment analysis, the former because of the lack of training corpora and the latter because of the enormous amount of world knowledge it demands. In this paper, we propose a working definition of thwarting amenable to machine learning and create a system that detects if the document is thwarted or not. We focus on identifying thwarting in product reviews, especially in the camera domain. An ontology of the camera domain is created. Thwarting is looked upon as the phenomenon of polarity reversal at a higher level of ontology compared to the polarity expressed at the lower level. This notion of thwarting defined with respect to an ontology is novel, to the best of our knowledge. A rule based implementation building upon this idea forms our baseline. We show that machine learning with annotated corpora (thwarted/nonthwarted) is more effective than the rule based system. Because of the skewed distribution of thwarting, we adopt the Areaunder-the-Curve measure of performance. To the best of our knowledge, this is the first attempt at the difficult problem of thwarting detection, which we hope will at Akshat Malu Dept. of Computer Science & Engg., Indian Institute of Technology Bombay, Mumbai, India. akshatmalu@ cse .i itb .ac .in J. Saketha Nath Dept. of Computer Science & Engg., Indian Institute of Technology Bombay, Mumbai, India. s aketh@ cse .i itb .ac .in least provide a baseline system to compare against. 1 Credits The authors thank the lexicographers at Center for Indian Language Technology (CFILT) at IIT Bombay for their support for this work. 2</p><p>3 0.72672093 <a title="211-lsi-3" href="./acl-2013-Sentiment_Relevance.html">318 acl-2013-Sentiment Relevance</a></p>
<p>Author: Christian Scheible ; Hinrich Schutze</p><p>Abstract: A number of different notions, including subjectivity, have been proposed for distinguishing parts of documents that convey sentiment from those that do not. We propose a new concept, sentiment relevance, to make this distinction and argue that it better reflects the requirements of sentiment analysis systems. We demonstrate experimentally that sentiment relevance and subjectivity are related, but different. Since no large amount of labeled training data for our new notion of sentiment relevance is available, we investigate two semi-supervised methods for creating sentiment relevance classifiers: a distant supervision approach that leverages structured information about the domain of the reviews; and transfer learning on feature representations based on lexical taxonomies that enables knowledge transfer. We show that both methods learn sentiment relevance classifiers that perform well.</p><p>4 0.72113496 <a title="211-lsi-4" href="./acl-2013-Identifying_Sentiment_Words_Using_an_Optimization-based_Model_without_Seed_Words.html">188 acl-2013-Identifying Sentiment Words Using an Optimization-based Model without Seed Words</a></p>
<p>Author: Hongliang Yu ; Zhi-Hong Deng ; Shiyingxue Li</p><p>Abstract: Sentiment Word Identification (SWI) is a basic technique in many sentiment analysis applications. Most existing researches exploit seed words, and lead to low robustness. In this paper, we propose a novel optimization-based model for SWI. Unlike previous approaches, our model exploits the sentiment labels of documents instead of seed words. Several experiments on real datasets show that WEED is effective and outperforms the state-of-the-art methods with seed words.</p><p>5 0.71900481 <a title="211-lsi-5" href="./acl-2013-Co-Regression_for_Cross-Language_Review_Rating_Prediction.html">81 acl-2013-Co-Regression for Cross-Language Review Rating Prediction</a></p>
<p>Author: Xiaojun Wan</p><p>Abstract: The task of review rating prediction can be well addressed by using regression algorithms if there is a reliable training set of reviews with human ratings. In this paper, we aim to investigate a more challenging task of crosslanguage review rating prediction, which makes use of only rated reviews in a source language (e.g. English) to predict the rating scores of unrated reviews in a target language (e.g. German). We propose a new coregression algorithm to address this task by leveraging unlabeled reviews. Evaluation results on several datasets show that our proposed co-regression algorithm can consistently improve the prediction results. 1</p><p>6 0.69662601 <a title="211-lsi-6" href="./acl-2013-Character-to-Character_Sentiment_Analysis_in_Shakespeare%27s_Plays.html">79 acl-2013-Character-to-Character Sentiment Analysis in Shakespeare's Plays</a></p>
<p>7 0.69554776 <a title="211-lsi-7" href="./acl-2013-Dual_Training_and_Dual_Prediction_for_Polarity_Classification.html">131 acl-2013-Dual Training and Dual Prediction for Polarity Classification</a></p>
<p>8 0.63795042 <a title="211-lsi-8" href="./acl-2013-Exploring_Sentiment_in_Social_Media%3A_Bootstrapping_Subjectivity_Clues_from_Multilingual_Twitter_Streams.html">148 acl-2013-Exploring Sentiment in Social Media: Bootstrapping Subjectivity Clues from Multilingual Twitter Streams</a></p>
<p>9 0.60204637 <a title="211-lsi-9" href="./acl-2013-Identifying_Opinion_Subgroups_in_Arabic_Online_Discussions.html">187 acl-2013-Identifying Opinion Subgroups in Arabic Online Discussions</a></p>
<p>10 0.59552103 <a title="211-lsi-10" href="./acl-2013-Utterance-Level_Multimodal_Sentiment_Analysis.html">379 acl-2013-Utterance-Level Multimodal Sentiment Analysis</a></p>
<p>11 0.52736044 <a title="211-lsi-11" href="./acl-2013-Connotation_Lexicon%3A_A_Dash_of_Sentiment_Beneath_the_Surface_Meaning.html">91 acl-2013-Connotation Lexicon: A Dash of Sentiment Beneath the Surface Meaning</a></p>
<p>12 0.51733565 <a title="211-lsi-12" href="./acl-2013-Generating_Recommendation_Dialogs_by_Extracting_Information_from_User_Reviews.html">168 acl-2013-Generating Recommendation Dialogs by Extracting Information from User Reviews</a></p>
<p>13 0.51258296 <a title="211-lsi-13" href="./acl-2013-Probabilistic_Sense_Sentiment_Similarity_through_Hidden_Emotions.html">284 acl-2013-Probabilistic Sense Sentiment Similarity through Hidden Emotions</a></p>
<p>14 0.5096851 <a title="211-lsi-14" href="./acl-2013-The_Haves_and_the_Have-Nots%3A_Leveraging_Unlabelled_Corpora_for_Sentiment_Analysis.html">345 acl-2013-The Haves and the Have-Nots: Leveraging Unlabelled Corpora for Sentiment Analysis</a></p>
<p>15 0.50097126 <a title="211-lsi-15" href="./acl-2013-A_Bayesian_Model_for_Joint_Unsupervised_Induction_of_Sentiment%2C_Aspect_and_Discourse_Representations.html">2 acl-2013-A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations</a></p>
<p>16 0.48195642 <a title="211-lsi-16" href="./acl-2013-TopicSpam%3A_a_Topic-Model_based_approach_for_spam_detection.html">350 acl-2013-TopicSpam: a Topic-Model based approach for spam detection</a></p>
<p>17 0.46740884 <a title="211-lsi-17" href="./acl-2013-An_annotated_corpus_of_quoted_opinions_in_news_articles.html">49 acl-2013-An annotated corpus of quoted opinions in news articles</a></p>
<p>18 0.43573794 <a title="211-lsi-18" href="./acl-2013-Sentence_Level_Dialect_Identification_in_Arabic.html">317 acl-2013-Sentence Level Dialect Identification in Arabic</a></p>
<p>19 0.43123448 <a title="211-lsi-19" href="./acl-2013-Detecting_Event-Related_Links_and_Sentiments_from_Social_Media_Texts.html">115 acl-2013-Detecting Event-Related Links and Sentiments from Social Media Texts</a></p>
<p>20 0.41347119 <a title="211-lsi-20" href="./acl-2013-Exploiting_Topic_based_Twitter_Sentiment_for_Stock_Prediction.html">147 acl-2013-Exploiting Topic based Twitter Sentiment for Stock Prediction</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.069), (6, 0.028), (11, 0.05), (14, 0.016), (15, 0.03), (24, 0.046), (26, 0.09), (31, 0.189), (35, 0.057), (42, 0.025), (48, 0.038), (52, 0.023), (70, 0.027), (88, 0.058), (90, 0.021), (95, 0.158)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.90704393 <a title="211-lda-1" href="./acl-2013-An_Open_Source_Toolkit_for_Quantitative_Historical_Linguistics.html">48 acl-2013-An Open Source Toolkit for Quantitative Historical Linguistics</a></p>
<p>Author: Johann-Mattis List ; Steven Moran</p><p>Abstract: Given the increasing interest and development of computational and quantitative methods in historical linguistics, it is important that scholars have a basis for documenting, testing, evaluating, and sharing complex workflows. We present a novel open-source toolkit for quantitative tasks in historical linguistics that offers these features. This toolkit also serves as an interface between existing software packages and frequently used data formats, and it provides implementations of new and existing algorithms within a homogeneous framework. We illustrate the toolkit’s functionality with an exemplary workflow that starts with raw language data and ends with automatically calculated phonetic alignments, cognates and borrowings. We then illustrate evaluation metrics on gold standard datasets that are provided with the toolkit.</p><p>2 0.89445674 <a title="211-lda-2" href="./acl-2013-Linking_and_Extending_an_Open_Multilingual_Wordnet.html">234 acl-2013-Linking and Extending an Open Multilingual Wordnet</a></p>
<p>Author: Francis Bond ; Ryan Foster</p><p>Abstract: We create an open multilingual wordnet with large wordnets for over 26 languages and smaller ones for 57 languages. It is made by combining wordnets with open licences, data from Wiktionary and the Unicode Common Locale Data Repository. Overall there are over 2 million senses for over 100 thousand concepts, linking over 1.4 million words in hundreds of languages.</p><p>same-paper 3 0.8665086 <a title="211-lda-3" href="./acl-2013-LABR%3A_A_Large_Scale_Arabic_Book_Reviews_Dataset.html">211 acl-2013-LABR: A Large Scale Arabic Book Reviews Dataset</a></p>
<p>Author: Mohamed Aly ; Amir Atiya</p><p>Abstract: We introduce LABR, the largest sentiment analysis dataset to-date for the Arabic language. It consists of over 63,000 book reviews, each rated on a scale of 1 to 5 stars. We investigate the properties of the the dataset, and present its statistics. We explore using the dataset for two tasks: sentiment polarity classification and rating classification. We provide standard splits of the dataset into training and testing, for both polarity and rating classification, in both balanced and unbalanced settings. We run baseline experiments on the dataset to establish a benchmark.</p><p>4 0.83069515 <a title="211-lda-4" href="./acl-2013-Semantic_Parsing_with_Combinatory_Categorial_Grammars.html">313 acl-2013-Semantic Parsing with Combinatory Categorial Grammars</a></p>
<p>Author: Yoav Artzi ; Nicholas FitzGerald ; Luke Zettlemoyer</p><p>Abstract: unkown-abstract</p><p>5 0.80459684 <a title="211-lda-5" href="./acl-2013-Universal_Conceptual_Cognitive_Annotation_%28UCCA%29.html">367 acl-2013-Universal Conceptual Cognitive Annotation (UCCA)</a></p>
<p>Author: Omri Abend ; Ari Rappoport</p><p>Abstract: Syntactic structures, by their nature, reflect first and foremost the formal constructions used for expressing meanings. This renders them sensitive to formal variation both within and across languages, and limits their value to semantic applications. We present UCCA, a novel multi-layered framework for semantic representation that aims to accommodate the semantic distinctions expressed through linguistic utterances. We demonstrate UCCA’s portability across domains and languages, and its relative insensitivity to meaning-preserving syntactic variation. We also show that UCCA can be effectively and quickly learned by annotators with no linguistic background, and describe the compilation of a UCCAannotated corpus.</p><p>6 0.78558666 <a title="211-lda-6" href="./acl-2013-Using_Context_Vectors_in_Improving_a_Machine_Translation_System_with_Bridge_Language.html">374 acl-2013-Using Context Vectors in Improving a Machine Translation System with Bridge Language</a></p>
<p>7 0.73570299 <a title="211-lda-7" href="./acl-2013-Cross-lingual_Projections_between_Languages_from_Different_Families.html">97 acl-2013-Cross-lingual Projections between Languages from Different Families</a></p>
<p>8 0.73316509 <a title="211-lda-8" href="./acl-2013-Dirt_Cheap_Web-Scale_Parallel_Text_from_the_Common_Crawl.html">120 acl-2013-Dirt Cheap Web-Scale Parallel Text from the Common Crawl</a></p>
<p>9 0.73251867 <a title="211-lda-9" href="./acl-2013-Social_Text_Normalization_using_Contextual_Graph_Random_Walks.html">326 acl-2013-Social Text Normalization using Contextual Graph Random Walks</a></p>
<p>10 0.72850049 <a title="211-lda-10" href="./acl-2013-Dual_Training_and_Dual_Prediction_for_Polarity_Classification.html">131 acl-2013-Dual Training and Dual Prediction for Polarity Classification</a></p>
<p>11 0.72763771 <a title="211-lda-11" href="./acl-2013-Microblogs_as_Parallel_Corpora.html">240 acl-2013-Microblogs as Parallel Corpora</a></p>
<p>12 0.72464657 <a title="211-lda-12" href="./acl-2013-Mapping_Source_to_Target_Strings_without_Alignment_by_Analogical_Learning%3A_A_Case_Study_with_Transliteration.html">236 acl-2013-Mapping Source to Target Strings without Alignment by Analogical Learning: A Case Study with Transliteration</a></p>
<p>13 0.72196436 <a title="211-lda-13" href="./acl-2013-SenseSpotting%3A_Never_let_your_parallel_data_tie_you_to_an_old_domain.html">316 acl-2013-SenseSpotting: Never let your parallel data tie you to an old domain</a></p>
<p>14 0.72110528 <a title="211-lda-14" href="./acl-2013-Detecting_Turnarounds_in_Sentiment_Analysis%3A_Thwarting.html">117 acl-2013-Detecting Turnarounds in Sentiment Analysis: Thwarting</a></p>
<p>15 0.72105718 <a title="211-lda-15" href="./acl-2013-QuEst_-_A_translation_quality_estimation_framework.html">289 acl-2013-QuEst - A translation quality estimation framework</a></p>
<p>16 0.71937692 <a title="211-lda-16" href="./acl-2013-Domain-Specific_Coreference_Resolution_with_Lexicalized_Features.html">130 acl-2013-Domain-Specific Coreference Resolution with Lexicalized Features</a></p>
<p>17 0.71877587 <a title="211-lda-17" href="./acl-2013-Co-Regression_for_Cross-Language_Review_Rating_Prediction.html">81 acl-2013-Co-Regression for Cross-Language Review Rating Prediction</a></p>
<p>18 0.71811259 <a title="211-lda-18" href="./acl-2013-Question_Classification_Transfer.html">292 acl-2013-Question Classification Transfer</a></p>
<p>19 0.71210623 <a title="211-lda-19" href="./acl-2013-A_Decade_of_Automatic_Content_Evaluation_of_News_Summaries%3A_Reassessing_the_State_of_the_Art.html">5 acl-2013-A Decade of Automatic Content Evaluation of News Summaries: Reassessing the State of the Art</a></p>
<p>20 0.71195763 <a title="211-lda-20" href="./acl-2013-FrameNet_on_the_Way_to_Babel%3A_Creating_a_Bilingual_FrameNet_Using_Wiktionary_as_Interlingual_Connection.html">162 acl-2013-FrameNet on the Way to Babel: Creating a Bilingual FrameNet Using Wiktionary as Interlingual Connection</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
