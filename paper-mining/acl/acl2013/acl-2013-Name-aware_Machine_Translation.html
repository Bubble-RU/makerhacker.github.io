<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>255 acl-2013-Name-aware Machine Translation</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-255" href="#">acl2013-255</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>255 acl-2013-Name-aware Machine Translation</h1>
<br/><p>Source: <a title="acl-2013-255-pdf" href="http://aclweb.org/anthology//P/P13/P13-1059.pdf">pdf</a></p><p>Author: Haibo Li ; Jing Zheng ; Heng Ji ; Qi Li ; Wen Wang</p><p>Abstract: We propose a Name-aware Machine Translation (MT) approach which can tightly integrate name processing into MT model, by jointly annotating parallel corpora, extracting name-aware translation grammar and rules, adding name phrase table and name translation driven decoding. Additionally, we also propose a new MT metric to appropriately evaluate the translation quality of informative words, by assigning different weights to different words according to their importance values in a document. Experiments on Chinese-English translation demonstrated the effectiveness of our approach on enhancing the quality of overall translation, name translation and word alignment over a high-quality MT baseline1 .</p><p>Reference: <a title="acl-2013-255-reference" href="../acl2013_reference/acl-2013-Name-aware_Machine_Translation_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 com  Abstract We propose a Name-aware Machine Translation (MT) approach which can tightly integrate name processing into MT model, by jointly annotating parallel corpora, extracting name-aware translation grammar and rules, adding name phrase table and name translation driven decoding. [sent-5, score-2.175]
</p><p>2 Additionally, we also propose a new MT metric to appropriately evaluate the translation quality of informative words, by assigning different weights to different words according to their importance values in a document. [sent-6, score-0.317]
</p><p>3 Experiments on Chinese-English translation demonstrated the effectiveness of our approach on enhancing the quality of overall translation,  name translation and word alignment over a high-quality MT baseline1 . [sent-7, score-1.053]
</p><p>4 Traditional MT approaches focus on the fluency and accuracy of the overall translation but fall short in their ability to translate certain content words including critical information, especially names. [sent-16, score-0.229]
</p><p>5 tgz  A typical statistical MT system can only translate 60% person names correctly (Ji et al. [sent-22, score-0.254]
</p><p>6 Incorrect segmentation and translation of names which often carry central meanings of a sentence can also yield incorrect translation of long contexts. [sent-24, score-0.679]
</p><p>7 , 2002)) treat all words equally, but names have relative low frequency in text (about 6% in newswire and only 3% in web documents) and thus are vastly outnumbered by function words and common nouns, etc. [sent-26, score-0.221]
</p><p>8 • Name translations pose a greater complexity bNeacmauese tr athnsel asetito nofs names gisr open caonmd highly dynamic. [sent-28, score-0.287]
</p><p>9 It is also important to acknowledge that there are many fundamental differences between the translation of names and other tokens, depending on whether a name is rendered phonetically, semantically, or a mixture  of both (Ji et al. [sent-29, score-0.965]
</p><p>10 Tightly integrate joint bilingual name tagging into MT training by coordinating tagged 604  ProceedingSsof oifa, th Beu 5l1gsarti Aan,An uuaglu Mste 4e-ti9n2g 0 o1f3 t. [sent-34, score-0.668]
</p><p>11 c A2s0s1o3ci Aatsiosonc fioartio Cno fmorpu Ctoamtiopnuatalt Lioinngauli Lsitnicgsu,i psatgicess 604–614,  names in parallel corpora, updating word segmentation, word alignment and grammar extraction (Section 3. [sent-36, score-0.406]
</p><p>12 Tightly integrate name tagging and translation into MT decoding via name-aware grammar (Section 3. [sent-39, score-0.883]
</p><p>13 Optimize name translation and context translation simultaneously and conduct name translation driven decoding with language model (LM) based selection (Section 3. [sent-42, score-1.77]
</p><p>14 Propose a new MT evaluation metric which can discriminate names and non-informative words (Section 4). [sent-45, score-0.272]
</p><p>15 , 2009) based on hierarchical phrase-based translation framework (Chiang, 2005). [sent-47, score-0.229]
</p><p>16 Given an input sentence in the source language, translation into the target language is cast as a search problem, where the goal is to find the highest-probability derivation that generates the source-side sentence, using the rules in our SCFG. [sent-63, score-0.262]
</p><p>17 The source-side derivation corresponds to a synchronous targetside derivation and the terminal yield ofthis targetside derivation is the output of the system. [sent-64, score-0.155]
</p><p>18 3  Name-aware MT  We tightly integrate name processing into the above baseline to construct a NAMT model. [sent-66, score-0.642]
</p><p>19 1 Training This basic training process of NAMT requires us to apply a bilingual name tagger to annotate parallel training corpora. [sent-69, score-0.717]
</p><p>20 Traditional name tagging approaches for single languages cannot address this requirement because they were all built on data and resources which are specific to each language without using any cross-lingual features. [sent-70, score-0.569]
</p><p>21 In addition, due to separate decoding processes the results on parallel data may not be consistent across languages. [sent-71, score-0.129]
</p><p>22 We developed a bilingual joint name tagger (Li et al. [sent-72, score-0.641]
</p><p>23 , 2012) based on conditional random fields that incorporates both monolingual and cross-lingual features and conducts joint inference, so that name tagging from two lan-  guages can mutually enhance each other and therefore inconsistent results can be corrected simultaneously. [sent-73, score-0.6]
</p><p>24 4% bilingual pair F-measure with automatic alignment as reported in (Li et al. [sent-76, score-0.147]
</p><p>25 t bilingual name tagger to extract three types of names: (Person (PER), Organization (ORG) and Geo-political entities (GPE)) from both the source side and the target side. [sent-79, score-0.673]
</p><p>26 We ignore two kinds of names: multi-word names with conflicting boundaries in two languages and  names only identified in one side of a parallel sentence. [sent-81, score-0.55]
</p><p>27 First, we replace tagged name pairs with their entity types, and then use Giza++ and symmetrization heuristics to regenerate word alignment. [sent-83, score-0.558]
</p><p>28 Since the name tags appear very frequently, the existence of such tags yields improvement in word alignment quality. [sent-84, score-0.595]
</p><p>29 The re-aligned parallel corpora are used to train our NAMT system based on SCFG. [sent-85, score-0.105]
</p><p>30 Since the joint name tagger ensures that each tagged source name has a corresponding translation on the target side (and vice versa), we can extract SCFG rules by treating the tagged names as non-terminals. [sent-86, score-1.571]
</p><p>31 However, the original parallel corpora contain many high-frequency names, which can already be handled well by the baseline MT. [sent-87, score-0.136]
</p><p>32 Some of these names carry special meanings that may influence translations of the neighboring words, and thus replacing them with non-terminals can lead to information loss and weaken the translation model. [sent-88, score-0.516]
</p><p>33 To address this issue, we merged the name-replaced  parallel data with the original parallel data and extract grammars from the combined corpus. [sent-89, score-0.152]
</p><p>34 after name tagging it becomes •  • ••  Ëe  GPE Íù ? [sent-93, score-0.569]
</p><p>35 Both sentence pairs are kept in the combined data to build the translation model. [sent-97, score-0.229]
</p><p>36 2 Decoding During decoding phase, we extract names with the baseline monolingual name tagger described in (Li et al. [sent-99, score-0.91]
</p><p>37 Its performance is comparable to the best reported results on Chinese name tagging on Automatic Content Extraction (ACE) data (Ji and Grishman, 2006; Florian et al. [sent-101, score-0.609]
</p><p>38 Then we apply a state-of-the-art name translation system (Ji et al. [sent-104, score-0.744]
</p><p>39 In our NAMT framework, we add the following extensions to name translation. [sent-107, score-0.515]
</p><p>40 This classifier works reasonably well in most cases (about 92% classification accuracy), except when a common Chinese last name appears as the first character of a foreign 606  name, such as “1‰” which can be translated either as “Jolie” or “Zhu Li”. [sent-109, score-0.551]
</p><p>41 For those names with fewer than five instances in the training data, we use the name translation system to provide translations; for the rest of the names, we leave them to the baseline MT model to handle. [sent-110, score-0.996]
</p><p>42 The joint bilingual name tagger was also exploited to mine bilingual name translation pairs from parallel training corpora. [sent-111, score-1.528]
</p><p>43 The mapping score between a Chinese name and an English name was computed by the number of aligned tokens. [sent-112, score-1.03]
</p><p>44 A name pair is extracted if the mapping score is the highest among all combinations and the name types on both sides are identical. [sent-113, score-1.03]
</p><p>45 It is necessary to incorporate word alignment as additional constraints because the order of names is often changed after translation. [sent-114, score-0.301]
</p><p>46 Finally, the extracted 9,963 unique name translation pairs were also used to create an additional name phrase table for NAMT. [sent-115, score-1.259]
</p><p>47 Manual evaluation on 2,000 name pairs showed the accuracy is 86%. [sent-116, score-0.515]
</p><p>48 The non-terminals in SCFG rules are rewritten  to the extracted names during decoding, therefore allow unseen names in the test data to be translated. [sent-117, score-0.442]
</p><p>49 Finally, based on LMs, our decoder exploits the dynamically created phrase table from name translation, competing with originally extracted rules, to find the best translation for the input sentence. [sent-118, score-0.744]
</p><p>50 , 2006) assign the same weights to all tokens equally. [sent-121, score-0.084]
</p><p>51 In order to properly evaluate the translation quality of NAMT methods, we propose to modify the BLEU metric so that they can dynamically assign more weights to names during evaluation. [sent-124, score-0.538]
</p><p>52 BLEU considers the correspondence between a system translation and a human translation:  BLEU = BP · exp? [sent-125, score-0.229]
</p><p>53 cThh ed weight o af saenn n-gram in reference translation is the sum of weights of all tokens it contains. [sent-134, score-0.353]
</p><p>54 When we sum up the total weight of all n-grams of a candidate translation, some n-grams may contain tokens which do not exist in reference translation. [sent-136, score-0.087]
</p><p>55 We assign the lowest weight of tokens in reference translation to these rare tokens. [sent-137, score-0.316]
</p><p>56 We also add an item, name penalty NP, to  penalize the output sentences which contain too many or too few names: NP =  e−(vu−1)2/2σ  (8)  where u is the number of name tokens in system translation and v is the number of name tokens in reference translation. [sent-138, score-1.967]
</p><p>57 (9)  This new metric can also be applied to evaluate MT approaches which emphasize other types of facts such as events, by simply replacing name tokens by other fact tokens. [sent-141, score-0.613]
</p><p>58 We also used some translation lexicon data and Wikipedia translations. [sent-145, score-0.229]
</p><p>59 The joint name tagger extracted 1,890,335 name pairs (295,087 Persons, 1,269,056 Geopolitical entities and 326,192 Organizations). [sent-150, score-1.089]
</p><p>60 LM1 is a 7-gram LM trained on the target side of Chinese-English and Egyptian ArabicEnglish parallel text, English monolingual discussion forums data R1-R4 released in BOLT Phase  1 (LDC2012E04, LDC2012E16, LDC2012E21, LDC2012E54), and English Gigaword Fifth Edition (LDC201 1T07). [sent-152, score-0.203]
</p><p>61 LM3 is a 4-gram LM trained on the web genre among the target side of all parallel text (i. [sent-154, score-0.108]
</p><p>62 , web text from pre-BOLT parallel text and BOLT released discussion forum parallel text). [sent-156, score-0.185]
</p><p>63 Note that for LM4 training data, some transcripts were quick transcripts and quick rich transcripts released by LDC, and some were generated by running flexible alignment ofclosed captions or speech recognition output from LDC on the audio data (Venkataraman et al. [sent-158, score-0.301]
</p><p>64 We asked four annotators to annotate names in four reference translations of each sentence and an expert annotator to adjudicate result-  s. [sent-161, score-0.327]
</p><p>65 The detailed statistics and name distribution of each test data set is shown in Table 1. [sent-162, score-0.515]
</p><p>66 The percentage of names occurred fewer than 5 times in training data are listed in the brackets in the last column of the table. [sent-163, score-0.221]
</p><p>67 2 Overall Performance Besides the new name-aware MT metric, we also adopt two traditional metrics, TER to evaluate the overall translation performance and Named Entity Weak Accuracy (NEWA) (Hermjakob et al. [sent-165, score-0.229]
</p><p>68 Using a manually assembled name variant table, we also support the matching of name variants (e. [sent-170, score-1.03]
</p><p>69 d12s9)<405 For better comparison with NAMT, besides the original baseline, we develop the other baseline system by adding name translation table into the phrase table (NPhrase). [sent-177, score-0.775]
</p><p>70 Table 2 presents the performance of overall translation and name translation. [sent-178, score-0.744]
</p><p>71 The gains are more significant for formal genres than informal genres mainly because most of the training data for name tagging and name translation were from newswire. [sent-182, score-1.435]
</p><p>72 Furthermore, using external name translation table only did not improve translation quality in most test sets except for BOLT2. [sent-183, score-0.973]
</p><p>73 Many errors from the baseline MT approach occurred because some parts of out-of-vocabulary names were mistakenly segmented into common words. [sent-185, score-0.346]
</p><p>74 For example, the baseline MT system mistakenly translated a person name “Y (Sun Honglei)” into “Sun red thunder”. [sent-186, score-0.709]
</p><p>75 In informal genres such as discussion forums and web blogs,  ¢  even common names often appear in rare forms due to misspelling or morphing. [sent-187, score-0.293]
</p><p>76 For example, “e8l (Obama)” was mistakenly translated into “Ma Olympic”. [sent-188, score-0.13]
</p><p>77 But our NAMT approach successfully identified and translated this name and also generated better overall translation: “Guo Meimei ’s power is also really strong , ah , really admire her”. [sent-195, score-0.708]
</p><p>78 The annotators rated each translation from 1 (very bad) to 5 (very  good) and made their judgments based on whether the translation is understandable and conveys the same meaning. [sent-204, score-0.458]
</p><p>79 The detailed procedure following NAMT framework is as follows:  (1) Ran the joint bilingual name tagger; (2) Replaced each name string with its name type (PER, ORG or GPE), and ran Giza++ on the replaced sentences; (3) Ran Giza++ on the words within  Alig nment (%). [sent-214, score-1.612]
</p><p>80 In order to compare with the upper-bound gains, we also measured the performance of applying ground-truth name tagging with the above procedures. [sent-217, score-0.569]
</p><p>81 6% words are within names, therefore the upper-bound gains on overall word alignment is only 1. [sent-223, score-0.12]
</p><p>82 5 Remaining Error Analysis Although the proposed model has significantly enhanced translation quality, some challenges remain. [sent-230, score-0.229]
</p><p>83 We found that the gains of our NAMT approach were mainly achieved for names with one or two components. [sent-234, score-0.261]
</p><p>84 When the name structure becomes too complicated to parse, name tagging and name translation are likely to produce errors, especially  Àß  for long nested organizations. [sent-235, score-1.828]
</p><p>85 @” (Anti-malfeasance Bureau of Gutian County Procuratorate) consists of a nested organization name with a GPE as modifier: “ä 0 b” (Gutian County Procuratorate) and an ORG name: “Í? [sent-237, score-0.557]
</p><p>86 Some organization abbreviations are also difficult to extract because our name taggers have  ¿  ¿  610  ý  #name tokens/#all tokens(%)  Figure 3: Word alignment gains according to the percentage of name words in each sentence. [sent-241, score-1.192]
</p><p>87 For example, without knowing that “FAW” refers to “First Automotive Works” in “FAW has also utilized the capital market to directly finance, and now owns three domestic listed companies”, our system mistakenly labeled it as a GPE. [sent-243, score-0.094]
</p><p>88 The same challenge exists in name alignment and translation (for example, “ ? [sent-244, score-0.824]
</p><p>89 6  Related Work  Two types of humble strategies were previously attempted to build name translation components which operate in tandem and loosely integrate into conventional statistical MT systems: 1. [sent-267, score-0.776]
</p><p>90 Post-processing: in a cross-lingual information retrieval or question answering framework, online query names can be utilized to obtain translation and post-edit MT output (Parton et al. [sent-273, score-0.45]
</p><p>91 It is challenging to decide when to use name translation results. [sent-276, score-0.744]
</p><p>92 The LM selection method often assigns an inappropriate weight to the additional name translation table because it is constructed independently from translation of context words; therefore after weighted voting most correct name translations are not used in the final translation output. [sent-278, score-1.783]
</p><p>93 More importantly, in these approaches the MT model was still mostly treated as a “black-box” because neither the translation model nor the LM was updated or adapted specifically for names. [sent-280, score-0.229]
</p><p>94 But little reported work has shown the impact of joint  611  name tagging on overall word alignment. [sent-292, score-0.569]
</p><p>95 Most of the previous name translation work combined supervised transliteration approaches with LM based re-scoring (Knight and Graehl, 1998; Al-Onaizan and Knight, 2002; Huang et al. [sent-293, score-0.782]
</p><p>96 Some recent research used comparable corpora to mine name translation pairs (Feng et al. [sent-295, score-0.813]
</p><p>97 In contrast, our name pair mining approach described in this paper does not require any machine translation or transliteration features. [sent-301, score-0.782]
</p><p>98 7  Conclusions and Future Work  We developed  a name-aware  MT framework  which tightly integrates name tagging and name translation into training and decoding of MT. [sent-302, score-1.43]
</p><p>99 Experiments on Chinese-English translation demonstrated the effectiveness of our approach over a high-quality MT baseline in both overall translation and name translation, especially for formal genres. [sent-303, score-1.004]
</p><p>100 We also plan to jointly optimize MT and name tagging by propagating multiple word segmentation and name annotation hypotheses in lattice structure to statistical MT and conduct latticebased decoding (Dyer et al. [sent-306, score-1.137]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('name', 0.515), ('proceeding', 0.384), ('namt', 0.331), ('translation', 0.229), ('names', 0.221), ('mt', 0.196), ('parton', 0.12), ('ji', 0.108), ('bleu', 0.106), ('lm', 0.095), ('mistakenly', 0.094), ('gpe', 0.09), ('alignment', 0.08), ('parallel', 0.076), ('bilingual', 0.067), ('translations', 0.066), ('lms', 0.064), ('tightly', 0.064), ('penalty', 0.059), ('tagger', 0.059), ('admire', 0.055), ('countweight', 0.055), ('newa', 0.055), ('weightt', 0.055), ('tagging', 0.054), ('zheng', 0.053), ('decoding', 0.053), ('carpuat', 0.051), ('metric', 0.051), ('really', 0.051), ('cassidy', 0.049), ('tokens', 0.047), ('chinese', 0.047), ('bolt', 0.045), ('bp', 0.045), ('scfg', 0.044), ('transcripts', 0.044), ('entity', 0.043), ('snover', 0.042), ('organization', 0.042), ('exp', 0.041), ('genres', 0.041), ('reference', 0.04), ('clip', 0.04), ('guo', 0.04), ('mckeown', 0.04), ('comparable', 0.04), ('gains', 0.04), ('america', 0.039), ('li', 0.039), ('transliteration', 0.038), ('named', 0.038), ('weights', 0.037), ('pages', 0.037), ('clipped', 0.037), ('countclip', 0.037), ('cpandidates', 0.037), ('faw', 0.037), ('ggppee', 0.037), ('gutian', 0.037), ('kutsumi', 0.037), ('meimei', 0.037), ('procuratorate', 0.037), ('srinterp', 0.037), ('unhcr', 0.037), ('translated', 0.036), ('paclic', 0.036), ('ma', 0.035), ('ldc', 0.034), ('heng', 0.034), ('released', 0.033), ('derivation', 0.033), ('person', 0.033), ('venkataraman', 0.033), ('appeals', 0.033), ('bureau', 0.033), ('khadivi', 0.033), ('side', 0.032), ('integrate', 0.032), ('ter', 0.032), ('forums', 0.031), ('baseline', 0.031), ('monolingual', 0.031), ('idf', 0.03), ('aswani', 0.03), ('county', 0.03), ('babych', 0.03), ('repair', 0.03), ('dayne', 0.03), ('colingacl', 0.03), ('corpora', 0.029), ('darpa', 0.029), ('extraction', 0.029), ('grishman', 0.029), ('org', 0.029), ('quick', 0.028), ('fung', 0.028), ('zitouni', 0.028), ('targetside', 0.028), ('shao', 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="255-tfidf-1" href="./acl-2013-Name-aware_Machine_Translation.html">255 acl-2013-Name-aware Machine Translation</a></p>
<p>Author: Haibo Li ; Jing Zheng ; Heng Ji ; Qi Li ; Wen Wang</p><p>Abstract: We propose a Name-aware Machine Translation (MT) approach which can tightly integrate name processing into MT model, by jointly annotating parallel corpora, extracting name-aware translation grammar and rules, adding name phrase table and name translation driven decoding. Additionally, we also propose a new MT metric to appropriately evaluate the translation quality of informative words, by assigning different weights to different words according to their importance values in a document. Experiments on Chinese-English translation demonstrated the effectiveness of our approach on enhancing the quality of overall translation, name translation and word alignment over a high-quality MT baseline1 .</p><p>2 0.16268323 <a title="255-tfidf-2" href="./acl-2013-Learning_a_Phrase-based_Translation_Model_from_Monolingual_Data_with_Application_to_Domain_Adaptation.html">223 acl-2013-Learning a Phrase-based Translation Model from Monolingual Data with Application to Domain Adaptation</a></p>
<p>Author: Jiajun Zhang ; Chengqing Zong</p><p>Abstract: Currently, almost all of the statistical machine translation (SMT) models are trained with the parallel corpora in some specific domains. However, when it comes to a language pair or a different domain without any bilingual resources, the traditional SMT loses its power. Recently, some research works study the unsupervised SMT for inducing a simple word-based translation model from the monolingual corpora. It successfully bypasses the constraint of bitext for SMT and obtains a relatively promising result. In this paper, we take a step forward and propose a simple but effective method to induce a phrase-based model from the monolingual corpora given an automatically-induced translation lexicon or a manually-edited translation dictionary. We apply our method for the domain adaptation task and the extensive experiments show that our proposed method can substantially improve the translation quality. 1</p><p>3 0.15695465 <a title="255-tfidf-3" href="./acl-2013-Improving_machine_translation_by_training_against_an_automatic_semantic_frame_based_evaluation_metric.html">195 acl-2013-Improving machine translation by training against an automatic semantic frame based evaluation metric</a></p>
<p>Author: Chi-kiu Lo ; Karteek Addanki ; Markus Saers ; Dekai Wu</p><p>Abstract: We present the first ever results showing that tuning a machine translation system against a semantic frame based objective function, MEANT, produces more robustly adequate translations than tuning against BLEU or TER as measured across commonly used metrics and human subjective evaluation. Moreover, for informal web forum data, human evaluators preferred MEANT-tuned systems over BLEU- or TER-tuned systems by a significantly wider margin than that for formal newswire—even though automatic semantic parsing might be expected to fare worse on informal language. We argue thatbypreserving the meaning ofthe trans- lations as captured by semantic frames right in the training process, an MT system is constrained to make more accurate choices of both lexical and reordering rules. As a result, MT systems tuned against semantic frame based MT evaluation metrics produce output that is more adequate. Tuning a machine translation system against a semantic frame based objective function is independent ofthe translation model paradigm, so, any translation model can benefit from the semantic knowledge incorporated to improve translation adequacy through our approach.</p><p>4 0.13827994 <a title="255-tfidf-4" href="./acl-2013-Bootstrapping_Entity_Translation_on_Weakly_Comparable_Corpora.html">71 acl-2013-Bootstrapping Entity Translation on Weakly Comparable Corpora</a></p>
<p>Author: Taesung Lee ; Seung-won Hwang</p><p>Abstract: This paper studies the problem of mining named entity translations from comparable corpora with some “asymmetry”. Unlike the previous approaches relying on the “symmetry” found in parallel corpora, the proposed method is tolerant to asymmetry often found in comparable corpora, by distinguishing different semantics of relations of entity pairs to selectively propagate seed entity translations on weakly comparable corpora. Our experimental results on English-Chinese corpora show that our selective propagation approach outperforms the previous approaches in named entity translation in terms of the mean reciprocal rank by up to 0.16 for organization names, and 0.14 in a low com- parability case.</p><p>5 0.13827397 <a title="255-tfidf-5" href="./acl-2013-A_Markov_Model_of_Machine_Translation_using_Non-parametric_Bayesian_Inference.html">10 acl-2013-A Markov Model of Machine Translation using Non-parametric Bayesian Inference</a></p>
<p>Author: Yang Feng ; Trevor Cohn</p><p>Abstract: Most modern machine translation systems use phrase pairs as translation units, allowing for accurate modelling of phraseinternal translation and reordering. However phrase-based approaches are much less able to model sentence level effects between different phrase-pairs. We propose a new model to address this imbalance, based on a word-based Markov model of translation which generates target translations left-to-right. Our model encodes word and phrase level phenomena by conditioning translation decisions on previous decisions and uses a hierarchical Pitman-Yor Process prior to provide dynamic adaptive smoothing. This mechanism implicitly supports not only traditional phrase pairs, but also gapping phrases which are non-consecutive in the source. Our experiments on Chinese to English and Arabic to English translation show consistent improvements over competitive baselines, of up to +3.4 BLEU.</p><p>6 0.13587879 <a title="255-tfidf-6" href="./acl-2013-A_Multi-Domain_Translation_Model_Framework_for_Statistical_Machine_Translation.html">11 acl-2013-A Multi-Domain Translation Model Framework for Statistical Machine Translation</a></p>
<p>7 0.13546291 <a title="255-tfidf-7" href="./acl-2013-Scalable_Decipherment_for_Machine_Translation_via_Hash_Sampling.html">307 acl-2013-Scalable Decipherment for Machine Translation via Hash Sampling</a></p>
<p>8 0.13271621 <a title="255-tfidf-8" href="./acl-2013-Travatar%3A_A_Forest-to-String_Machine_Translation_Engine_based_on_Tree_Transducers.html">361 acl-2013-Travatar: A Forest-to-String Machine Translation Engine based on Tree Transducers</a></p>
<p>9 0.12993436 <a title="255-tfidf-9" href="./acl-2013-Dirt_Cheap_Web-Scale_Parallel_Text_from_the_Common_Crawl.html">120 acl-2013-Dirt Cheap Web-Scale Parallel Text from the Common Crawl</a></p>
<p>10 0.12548673 <a title="255-tfidf-10" href="./acl-2013-A_Tightly-coupled_Unsupervised_Clustering_and_Bilingual_Alignment_Model_for_Transliteration.html">25 acl-2013-A Tightly-coupled Unsupervised Clustering and Bilingual Alignment Model for Transliteration</a></p>
<p>11 0.12263224 <a title="255-tfidf-11" href="./acl-2013-English-to-Russian_MT_evaluation_campaign.html">135 acl-2013-English-to-Russian MT evaluation campaign</a></p>
<p>12 0.12160539 <a title="255-tfidf-12" href="./acl-2013-Machine_Translation_Detection_from_Monolingual_Web-Text.html">235 acl-2013-Machine Translation Detection from Monolingual Web-Text</a></p>
<p>13 0.12001682 <a title="255-tfidf-13" href="./acl-2013-Semantic_Roles_for_String_to_Tree_Machine_Translation.html">314 acl-2013-Semantic Roles for String to Tree Machine Translation</a></p>
<p>14 0.11635523 <a title="255-tfidf-14" href="./acl-2013-A_New_Syntactic_Metric_for_Evaluation_of_Machine_Translation.html">13 acl-2013-A New Syntactic Metric for Evaluation of Machine Translation</a></p>
<p>15 0.11403506 <a title="255-tfidf-15" href="./acl-2013-Extracting_bilingual_terminologies_from_comparable_corpora.html">154 acl-2013-Extracting bilingual terminologies from comparable corpora</a></p>
<p>16 0.11350355 <a title="255-tfidf-16" href="./acl-2013-Advancements_in_Reordering_Models_for_Statistical_Machine_Translation.html">40 acl-2013-Advancements in Reordering Models for Statistical Machine Translation</a></p>
<p>17 0.11127645 <a title="255-tfidf-17" href="./acl-2013-Learning_to_Prune%3A_Context-Sensitive_Pruning_for_Syntactic_MT.html">226 acl-2013-Learning to Prune: Context-Sensitive Pruning for Syntactic MT</a></p>
<p>18 0.11082238 <a title="255-tfidf-18" href="./acl-2013-Hierarchical_Phrase_Table_Combination_for_Machine_Translation.html">181 acl-2013-Hierarchical Phrase Table Combination for Machine Translation</a></p>
<p>19 0.10999527 <a title="255-tfidf-19" href="./acl-2013-Joint_Word_Alignment_and_Bilingual_Named_Entity_Recognition_Using_Dual_Decomposition.html">210 acl-2013-Joint Word Alignment and Bilingual Named Entity Recognition Using Dual Decomposition</a></p>
<p>20 0.10969835 <a title="255-tfidf-20" href="./acl-2013-Semantic_Parsing_as_Machine_Translation.html">312 acl-2013-Semantic Parsing as Machine Translation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.268), (1, -0.142), (2, 0.174), (3, 0.088), (4, 0.089), (5, 0.049), (6, -0.059), (7, 0.011), (8, 0.061), (9, 0.052), (10, -0.015), (11, -0.011), (12, -0.035), (13, 0.053), (14, 0.017), (15, -0.003), (16, -0.007), (17, -0.023), (18, -0.04), (19, 0.022), (20, 0.005), (21, -0.076), (22, -0.023), (23, 0.069), (24, -0.035), (25, -0.016), (26, -0.016), (27, 0.005), (28, 0.085), (29, 0.022), (30, 0.022), (31, -0.063), (32, 0.024), (33, -0.041), (34, -0.022), (35, -0.018), (36, -0.065), (37, 0.082), (38, 0.041), (39, -0.062), (40, -0.035), (41, 0.039), (42, 0.046), (43, -0.048), (44, 0.018), (45, -0.033), (46, -0.039), (47, -0.066), (48, 0.05), (49, -0.055)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97009861 <a title="255-lsi-1" href="./acl-2013-Name-aware_Machine_Translation.html">255 acl-2013-Name-aware Machine Translation</a></p>
<p>Author: Haibo Li ; Jing Zheng ; Heng Ji ; Qi Li ; Wen Wang</p><p>Abstract: We propose a Name-aware Machine Translation (MT) approach which can tightly integrate name processing into MT model, by jointly annotating parallel corpora, extracting name-aware translation grammar and rules, adding name phrase table and name translation driven decoding. Additionally, we also propose a new MT metric to appropriately evaluate the translation quality of informative words, by assigning different weights to different words according to their importance values in a document. Experiments on Chinese-English translation demonstrated the effectiveness of our approach on enhancing the quality of overall translation, name translation and word alignment over a high-quality MT baseline1 .</p><p>2 0.77538145 <a title="255-lsi-2" href="./acl-2013-Context-Dependent_Multilingual_Lexical_Lookup_for_Under-Resourced_Languages.html">92 acl-2013-Context-Dependent Multilingual Lexical Lookup for Under-Resourced Languages</a></p>
<p>Author: Lian Tze Lim ; Lay-Ki Soon ; Tek Yong Lim ; Enya Kong Tang ; Bali Ranaivo-Malancon</p><p>Abstract: Current approaches for word sense disambiguation and translation selection typically require lexical resources or large bilingual corpora with rich information fields and annotations, which are often infeasible for under-resourced languages. We extract translation context knowledge from a bilingual comparable corpora of a richer-resourced language pair, and inject it into a multilingual lexicon. The multilin- gual lexicon can then be used to perform context-dependent lexical lookup on texts of any language, including under-resourced ones. Evaluations on a prototype lookup tool, trained on a English–Malay bilingual Wikipedia corpus, show a precision score of 0.65 (baseline 0.55) and mean reciprocal rank score of 0.81 (baseline 0.771). Based on the early encouraging results, the context-dependent lexical lookup tool may be developed further into an intelligent reading aid, to help users grasp the gist of a second or foreign language text.</p><p>3 0.75273931 <a title="255-lsi-3" href="./acl-2013-Bootstrapping_Entity_Translation_on_Weakly_Comparable_Corpora.html">71 acl-2013-Bootstrapping Entity Translation on Weakly Comparable Corpora</a></p>
<p>Author: Taesung Lee ; Seung-won Hwang</p><p>Abstract: This paper studies the problem of mining named entity translations from comparable corpora with some “asymmetry”. Unlike the previous approaches relying on the “symmetry” found in parallel corpora, the proposed method is tolerant to asymmetry often found in comparable corpora, by distinguishing different semantics of relations of entity pairs to selectively propagate seed entity translations on weakly comparable corpora. Our experimental results on English-Chinese corpora show that our selective propagation approach outperforms the previous approaches in named entity translation in terms of the mean reciprocal rank by up to 0.16 for organization names, and 0.14 in a low com- parability case.</p><p>4 0.74670368 <a title="255-lsi-4" href="./acl-2013-Mapping_Source_to_Target_Strings_without_Alignment_by_Analogical_Learning%3A_A_Case_Study_with_Transliteration.html">236 acl-2013-Mapping Source to Target Strings without Alignment by Analogical Learning: A Case Study with Transliteration</a></p>
<p>Author: Phillippe Langlais</p><p>Abstract: Analogical learning over strings is a holistic model that has been investigated by a few authors as a means to map forms of a source language to forms of a target language. In this study, we revisit this learning paradigm and apply it to the transliteration task. We show that alone, it performs worse than a statistical phrase-based machine translation engine, but the combination of both approaches outperforms each one taken separately, demonstrating the usefulness of the information captured by a so-called formal analogy.</p><p>5 0.74070913 <a title="255-lsi-5" href="./acl-2013-Bilingual_Data_Cleaning_for_SMT_using_Graph-based_Random_Walk.html">68 acl-2013-Bilingual Data Cleaning for SMT using Graph-based Random Walk</a></p>
<p>Author: Lei Cui ; Dongdong Zhang ; Shujie Liu ; Mu Li ; Ming Zhou</p><p>Abstract: The quality of bilingual data is a key factor in Statistical Machine Translation (SMT). Low-quality bilingual data tends to produce incorrect translation knowledge and also degrades translation modeling performance. Previous work often used supervised learning methods to filter lowquality data, but a fair amount of human labeled examples are needed which are not easy to obtain. To reduce the reliance on labeled examples, we propose an unsupervised method to clean bilingual data. The method leverages the mutual reinforcement between the sentence pairs and the extracted phrase pairs, based on the observation that better sentence pairs often lead to better phrase extraction and vice versa. End-to-end experiments show that the proposed method substantially improves the performance in largescale Chinese-to-English translation tasks.</p><p>6 0.73610985 <a title="255-lsi-6" href="./acl-2013-Travatar%3A_A_Forest-to-String_Machine_Translation_Engine_based_on_Tree_Transducers.html">361 acl-2013-Travatar: A Forest-to-String Machine Translation Engine based on Tree Transducers</a></p>
<p>7 0.73534459 <a title="255-lsi-7" href="./acl-2013-A_Novel_Translation_Framework_Based_on_Rhetorical_Structure_Theory.html">16 acl-2013-A Novel Translation Framework Based on Rhetorical Structure Theory</a></p>
<p>8 0.72685432 <a title="255-lsi-8" href="./acl-2013-A_Markov_Model_of_Machine_Translation_using_Non-parametric_Bayesian_Inference.html">10 acl-2013-A Markov Model of Machine Translation using Non-parametric Bayesian Inference</a></p>
<p>9 0.72209603 <a title="255-lsi-9" href="./acl-2013-English-to-Russian_MT_evaluation_campaign.html">135 acl-2013-English-to-Russian MT evaluation campaign</a></p>
<p>10 0.71433818 <a title="255-lsi-10" href="./acl-2013-Improving_machine_translation_by_training_against_an_automatic_semantic_frame_based_evaluation_metric.html">195 acl-2013-Improving machine translation by training against an automatic semantic frame based evaluation metric</a></p>
<p>11 0.70944804 <a title="255-lsi-11" href="./acl-2013-Deepfix%3A_Statistical_Post-editing_of_Statistical_Machine_Translation_Using_Deep_Syntactic_Analysis.html">110 acl-2013-Deepfix: Statistical Post-editing of Statistical Machine Translation Using Deep Syntactic Analysis</a></p>
<p>12 0.70732272 <a title="255-lsi-12" href="./acl-2013-Automatically_Predicting_Sentence_Translation_Difficulty.html">64 acl-2013-Automatically Predicting Sentence Translation Difficulty</a></p>
<p>13 0.70638484 <a title="255-lsi-13" href="./acl-2013-Dirt_Cheap_Web-Scale_Parallel_Text_from_the_Common_Crawl.html">120 acl-2013-Dirt Cheap Web-Scale Parallel Text from the Common Crawl</a></p>
<p>14 0.7012167 <a title="255-lsi-14" href="./acl-2013-Learning_a_Phrase-based_Translation_Model_from_Monolingual_Data_with_Application_to_Domain_Adaptation.html">223 acl-2013-Learning a Phrase-based Translation Model from Monolingual Data with Application to Domain Adaptation</a></p>
<p>15 0.69319719 <a title="255-lsi-15" href="./acl-2013-TransDoop%3A_A_Map-Reduce_based_Crowdsourced_Translation_for_Complex_Domain.html">355 acl-2013-TransDoop: A Map-Reduce based Crowdsourced Translation for Complex Domain</a></p>
<p>16 0.68945462 <a title="255-lsi-16" href="./acl-2013-Task_Alternation_in_Parallel_Sentence_Retrieval_for_Twitter_Translation.html">338 acl-2013-Task Alternation in Parallel Sentence Retrieval for Twitter Translation</a></p>
<p>17 0.68893087 <a title="255-lsi-17" href="./acl-2013-Extracting_bilingual_terminologies_from_comparable_corpora.html">154 acl-2013-Extracting bilingual terminologies from comparable corpora</a></p>
<p>18 0.68727076 <a title="255-lsi-18" href="./acl-2013-Semantic_Parsing_as_Machine_Translation.html">312 acl-2013-Semantic Parsing as Machine Translation</a></p>
<p>19 0.68417466 <a title="255-lsi-19" href="./acl-2013-SORT%3A_An_Interactive_Source-Rewriting_Tool_for_Improved_Translation.html">305 acl-2013-SORT: An Interactive Source-Rewriting Tool for Improved Translation</a></p>
<p>20 0.67697126 <a title="255-lsi-20" href="./acl-2013-Integrating_Translation_Memory_into_Phrase-Based_Machine_Translation_during_Decoding.html">201 acl-2013-Integrating Translation Memory into Phrase-Based Machine Translation during Decoding</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.042), (6, 0.035), (11, 0.048), (15, 0.018), (24, 0.073), (26, 0.051), (35, 0.058), (42, 0.092), (48, 0.029), (70, 0.047), (77, 0.187), (88, 0.029), (90, 0.037), (95, 0.155)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.92034936 <a title="255-lda-1" href="./acl-2013-Mining_Informal_Language_from_Chinese_Microtext%3A_Joint_Word_Recognition_and_Segmentation.html">243 acl-2013-Mining Informal Language from Chinese Microtext: Joint Word Recognition and Segmentation</a></p>
<p>Author: Aobo Wang ; Min-Yen Kan</p><p>Abstract: We address the problem of informal word recognition in Chinese microblogs. A key problem is the lack of word delimiters in Chinese. We exploit this reliance as an opportunity: recognizing the relation between informal word recognition and Chinese word segmentation, we propose to model the two tasks jointly. Our joint inference method significantly outperforms baseline systems that conduct the tasks individually or sequentially.</p><p>same-paper 2 0.8460145 <a title="255-lda-2" href="./acl-2013-Name-aware_Machine_Translation.html">255 acl-2013-Name-aware Machine Translation</a></p>
<p>Author: Haibo Li ; Jing Zheng ; Heng Ji ; Qi Li ; Wen Wang</p><p>Abstract: We propose a Name-aware Machine Translation (MT) approach which can tightly integrate name processing into MT model, by jointly annotating parallel corpora, extracting name-aware translation grammar and rules, adding name phrase table and name translation driven decoding. Additionally, we also propose a new MT metric to appropriately evaluate the translation quality of informative words, by assigning different weights to different words according to their importance values in a document. Experiments on Chinese-English translation demonstrated the effectiveness of our approach on enhancing the quality of overall translation, name translation and word alignment over a high-quality MT baseline1 .</p><p>3 0.84382105 <a title="255-lda-3" href="./acl-2013-Hierarchical_Phrase_Table_Combination_for_Machine_Translation.html">181 acl-2013-Hierarchical Phrase Table Combination for Machine Translation</a></p>
<p>Author: Conghui Zhu ; Taro Watanabe ; Eiichiro Sumita ; Tiejun Zhao</p><p>Abstract: Typical statistical machine translation systems are batch trained with a given training data and their performances are largely influenced by the amount of data. With the growth of the available data across different domains, it is computationally demanding to perform batch training every time when new data comes. In face of the problem, we propose an efficient phrase table combination method. In particular, we train a Bayesian phrasal inversion transduction grammars for each domain separately. The learned phrase tables are hierarchically combined as if they are drawn from a hierarchical Pitman-Yor process. The performance measured by BLEU is at least as comparable to the traditional batch training method. Furthermore, each phrase table is trained separately in each domain, and while computational overhead is significantly reduced by training them in parallel.</p><p>4 0.755651 <a title="255-lda-4" href="./acl-2013-Microblogs_as_Parallel_Corpora.html">240 acl-2013-Microblogs as Parallel Corpora</a></p>
<p>Author: Wang Ling ; Guang Xiang ; Chris Dyer ; Alan Black ; Isabel Trancoso</p><p>Abstract: In the ever-expanding sea of microblog data, there is a surprising amount of naturally occurring parallel text: some users create post multilingual messages targeting international audiences while others “retweet” translations. We present an efficient method for detecting these messages and extracting parallel segments from them. We have been able to extract over 1M Chinese-English parallel segments from Sina Weibo (the Chinese counterpart of Twitter) using only their public APIs. As a supplement to existing parallel training data, our automatically extracted parallel data yields substantial translation quality improvements in translating microblog text and modest improvements in translating edited news commentary. The resources in described in this paper are available at http://www.cs.cmu.edu/∼lingwang/utopia.</p><p>5 0.75053596 <a title="255-lda-5" href="./acl-2013-Learning_a_Phrase-based_Translation_Model_from_Monolingual_Data_with_Application_to_Domain_Adaptation.html">223 acl-2013-Learning a Phrase-based Translation Model from Monolingual Data with Application to Domain Adaptation</a></p>
<p>Author: Jiajun Zhang ; Chengqing Zong</p><p>Abstract: Currently, almost all of the statistical machine translation (SMT) models are trained with the parallel corpora in some specific domains. However, when it comes to a language pair or a different domain without any bilingual resources, the traditional SMT loses its power. Recently, some research works study the unsupervised SMT for inducing a simple word-based translation model from the monolingual corpora. It successfully bypasses the constraint of bitext for SMT and obtains a relatively promising result. In this paper, we take a step forward and propose a simple but effective method to induce a phrase-based model from the monolingual corpora given an automatically-induced translation lexicon or a manually-edited translation dictionary. We apply our method for the domain adaptation task and the extensive experiments show that our proposed method can substantially improve the translation quality. 1</p><p>6 0.74995136 <a title="255-lda-6" href="./acl-2013-Vector_Space_Model_for_Adaptation_in_Statistical_Machine_Translation.html">383 acl-2013-Vector Space Model for Adaptation in Statistical Machine Translation</a></p>
<p>7 0.74989688 <a title="255-lda-7" href="./acl-2013-Dirt_Cheap_Web-Scale_Parallel_Text_from_the_Common_Crawl.html">120 acl-2013-Dirt Cheap Web-Scale Parallel Text from the Common Crawl</a></p>
<p>8 0.74271452 <a title="255-lda-8" href="./acl-2013-Cross-lingual_Projections_between_Languages_from_Different_Families.html">97 acl-2013-Cross-lingual Projections between Languages from Different Families</a></p>
<p>9 0.74221349 <a title="255-lda-9" href="./acl-2013-A_Tightly-coupled_Unsupervised_Clustering_and_Bilingual_Alignment_Model_for_Transliteration.html">25 acl-2013-A Tightly-coupled Unsupervised Clustering and Bilingual Alignment Model for Transliteration</a></p>
<p>10 0.74133492 <a title="255-lda-10" href="./acl-2013-Joint_Inference_for_Fine-grained_Opinion_Extraction.html">207 acl-2013-Joint Inference for Fine-grained Opinion Extraction</a></p>
<p>11 0.74015021 <a title="255-lda-11" href="./acl-2013-Punctuation_Prediction_with_Transition-based_Parsing.html">288 acl-2013-Punctuation Prediction with Transition-based Parsing</a></p>
<p>12 0.73865896 <a title="255-lda-12" href="./acl-2013-A_Decade_of_Automatic_Content_Evaluation_of_News_Summaries%3A_Reassessing_the_State_of_the_Art.html">5 acl-2013-A Decade of Automatic Content Evaluation of News Summaries: Reassessing the State of the Art</a></p>
<p>13 0.73817527 <a title="255-lda-13" href="./acl-2013-Bilingual_Data_Cleaning_for_SMT_using_Graph-based_Random_Walk.html">68 acl-2013-Bilingual Data Cleaning for SMT using Graph-based Random Walk</a></p>
<p>14 0.73615086 <a title="255-lda-14" href="./acl-2013-Travatar%3A_A_Forest-to-String_Machine_Translation_Engine_based_on_Tree_Transducers.html">361 acl-2013-Travatar: A Forest-to-String Machine Translation Engine based on Tree Transducers</a></p>
<p>15 0.73601443 <a title="255-lda-15" href="./acl-2013-Task_Alternation_in_Parallel_Sentence_Retrieval_for_Twitter_Translation.html">338 acl-2013-Task Alternation in Parallel Sentence Retrieval for Twitter Translation</a></p>
<p>16 0.73543346 <a title="255-lda-16" href="./acl-2013-Learning_to_Prune%3A_Context-Sensitive_Pruning_for_Syntactic_MT.html">226 acl-2013-Learning to Prune: Context-Sensitive Pruning for Syntactic MT</a></p>
<p>17 0.7349208 <a title="255-lda-17" href="./acl-2013-Graph_Propagation_for_Paraphrasing_Out-of-Vocabulary_Words_in_Statistical_Machine_Translation.html">174 acl-2013-Graph Propagation for Paraphrasing Out-of-Vocabulary Words in Statistical Machine Translation</a></p>
<p>18 0.7348516 <a title="255-lda-18" href="./acl-2013-Integrating_Translation_Memory_into_Phrase-Based_Machine_Translation_during_Decoding.html">201 acl-2013-Integrating Translation Memory into Phrase-Based Machine Translation during Decoding</a></p>
<p>19 0.7341373 <a title="255-lda-19" href="./acl-2013-Question_Answering_Using_Enhanced_Lexical_Semantic_Models.html">291 acl-2013-Question Answering Using Enhanced Lexical Semantic Models</a></p>
<p>20 0.73337859 <a title="255-lda-20" href="./acl-2013-Cut_the_noise%3A_Mutually_reinforcing_reordering_and_alignments_for_improved_machine_translation.html">101 acl-2013-Cut the noise: Mutually reinforcing reordering and alignments for improved machine translation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
