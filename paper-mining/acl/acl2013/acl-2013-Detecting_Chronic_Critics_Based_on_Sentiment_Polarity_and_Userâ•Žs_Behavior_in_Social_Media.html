<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>114 acl-2013-Detecting Chronic Critics Based on Sentiment Polarity and Userâ•Žs Behavior in Social Media</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-114" href="#">acl2013-114</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>114 acl-2013-Detecting Chronic Critics Based on Sentiment Polarity and Userâ•Žs Behavior in Social Media</h1>
<br/><p>Source: <a title="acl-2013-114-pdf" href="http://aclweb.org/anthology//P/P13/P13-3016.pdf">pdf</a></p><p>Author: Sho Takase ; Akiko Murakami ; Miki Enoki ; Naoaki Okazaki ; Kentaro Inui</p><p>Abstract: There are some chronic critics who always complain about the entity in social media. We are working to automatically detect these chronic critics to prevent the spread of bad rumors about the reputation of the entity. In social media, most comments are informal, and, there are sarcastic and incomplete contexts. This means that it is difficult for current NLP technology such as opinion mining to recognize the complaints. As an alternative approach for social media, we can assume that users who share the same opinions will link to each other. Thus, we propose a method that combines opinion mining with graph analysis for the connections between users to identify the chronic critics. Our ex- perimental results show that the proposed method outperforms analysis based only on opinion mining techniques.</p><p>Reference: <a title="acl-2013-114-reference" href="../acl2013_reference/acl-2013-Detecting_Chronic_Critics_Based_on_Sentiment_Polarity_and_User%C3%A2%E2%80%A2%C5%BDs_Behavior_in_Social_Media_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 cookmu  Abstract There are some chronic critics who always complain about the entity in social media. [sent-7, score-1.259]
</p><p>2 We are working to automatically detect these chronic critics to prevent the spread of bad rumors about the reputation of the entity. [sent-8, score-1.25]
</p><p>3 This means that it is difficult for current NLP technology such as opinion mining to recognize the complaints. [sent-10, score-0.25]
</p><p>4 As an alternative approach for social media, we can assume that users who share the same opinions will link to each other. [sent-11, score-0.283]
</p><p>5 Thus, we propose a method that combines opinion mining with graph analysis for the connections between users to identify the chronic critics. [sent-12, score-1.266]
</p><p>6 Our ex-  perimental results show that the proposed method outperforms analysis based only on opinion mining techniques. [sent-13, score-0.25]
</p><p>7 1 Introduction On a social media website, there may be millions of users and large numbers of comments. [sent-14, score-0.335]
</p><p>8 Some complaints are expressed by a specific user who is always criticizing a specific target en-  tity (in this example, Company A). [sent-23, score-0.261]
</p><p>9 We call this user a chronic critic of that entity, a person who is deliberately trying to harm the reputation of the entity. [sent-24, score-1.032]
</p><p>10 That is, a chronic critic is trying to run a negative campaign against the entity. [sent-25, score-0.853]
</p><p>11 If the entity is aware of its own chronic critics, then it is able to take prompt action to stop the malicious complaints. [sent-26, score-0.802]
</p><p>12 In contrast, if the chronic critics are justified, then the entity should address the concerns to limit the damage. [sent-28, score-1.142]
</p><p>13 Hence, to handle malicious rumors, it is important to detect the chronic critics. [sent-29, score-0.754]
</p><p>14 However, it is generally quite difficult for a computer to detect a chronic critic’s comments, since especially the comments in social media are often quite informal. [sent-30, score-0.929]
</p><p>15 For example, if Company A has been involved in a widely recognized fiasco, then some chronic critics might sarcastically write “good job” or “wonderful” about Company A. [sent-32, score-1.058]
</p><p>16 Some chronic critics bash a target entity solely with sarcasm, so they damage the target with positive words. [sent-34, score-1.27]
</p><p>17 It is exceedingly difficult to directly detect these chronic critics based on their comments. [sent-35, score-1.094]
</p><p>18 To find chronic critics for a given entity, we need to identify the actual target of the complaints. [sent-37, score-1.122]
</p><p>19 Switching to the behavior of each user, in social media we often see that users who have similar ideas will tend to cooperate with each other. [sent-45, score-0.335]
</p><p>20 Because chronic critics share the purpose of attacking some target’s reputation, they may also decide to cooperate. [sent-49, score-1.058]
</p><p>21 For this reason, to detect chronic critics, we believe that information about the connections among users will be effective. [sent-50, score-1.005]
</p><p>22 In this paper, we present a method that combines opinion mining based on NLP and graph analysis of the connections among users to recognize the chronic critics. [sent-51, score-1.29]
</p><p>23 In the experiments, we demonstrate the difficulty in detecting chronic critics by analyzing only the individual comments. [sent-52, score-1.078]
</p><p>24 Section 3 presents the proposed method which applies the opinion mining and graph analysis. [sent-60, score-0.321]
</p><p>25 (201 1a) proposed a method that predicts the political polarity of a social media user based on the connections between users and tags. [sent-82, score-0.62]
</p><p>26 They demonstrated that label propagation on the graph representing the connections between users is effective. [sent-83, score-0.383]
</p><p>27 Murakami and Raymond (2010) proposed a method that uses the connections between users to predict each user’s opinion, i. [sent-86, score-0.297]
</p><p>28 To address these problem, we analyzed the behavior of the users to predict the connections between users. [sent-91, score-0.273]
</p><p>29 They used the content in the comments and the number of linked users as features. [sent-95, score-0.235]
</p><p>30 (2012) required manually annotated data for training or as seeds, we extract the seeds for the graph analysis automatically through opinion mining. [sent-100, score-0.286]
</p><p>31 The proposed method has two phases, opinion mining and graph analysis. [sent-102, score-0.321]
</p><p>32 First, we extract a few chronic critics by analyzing the opinions of many users referencing the target entity. [sent-103, score-1.346]
</p><p>33 For the opinion mining, we are initially looking for users who strongly criticize the target entity. [sent-104, score-0.402]
</p><p>34 In Figure 1, given Company A as a target entity, we  find users “b” and “e” since they said “Working for Company A is really awful” and “This product from Company A is useless”. [sent-105, score-0.259]
</p><p>35 However, we may miss the other chronic critics since they used sarcasm and incomplete contexts. [sent-106, score-1.153]
</p><p>36 Next, we find the users who are linked to the 111  Figure 1: Overview of proposed method  chronic critics that were detected through opinion mining. [sent-107, score-1.443]
</p><p>37 We built a graph in which the users are represented by nodes and the links between the users are represented by edges. [sent-108, score-0.421]
</p><p>38 We recognize additional chronic critics based on the graph analysis. [sent-109, score-1.153]
</p><p>39 In the example of Figure 1, we find more chronic critics not recognized by the opinion mining, such as “a” and “c”, because they are linked to the chronic critics “b” and “e”. [sent-110, score-2.302]
</p><p>40 In this section,  we explain the opinion mining and graph analysis. [sent-111, score-0.297]
</p><p>41 1 Opinion Mining As defined in Section 1, we defined a user who frequently criticizes a target entity as a chronic critic. [sent-114, score-0.956]
</p><p>42 Therefore, we classify the tweets of each user into critical or non-critical and label any users who complain about the target entity many times as chronic critics. [sent-115, score-1.388]
</p><p>43 In Twitter, this means we ignore a reply that is a response to a specific user named username (written in the format “@username response”) and QT that is a mention in a quoted tweet from username (written in the format “mention RT @username: quoted tweet”). [sent-117, score-0.387]
</p><p>44 The proposed method determines whether a tweet complains about the target entity by investigating a  critical phrase and the target of the phrase. [sent-119, score-0.474]
</p><p>45 Figure 2: Example of critic tweet ative polarity by using declinable words. [sent-125, score-0.358]
</p><p>46 However, because there are many informal tweets and because most users omit the grammatical case in tweets, the sentiment analyzer often fails to cap-  ture any target. [sent-131, score-0.425]
</p><p>47 Since a chronic critic frequently complains about the target entity, we can predict that most of the tweets written by a chronic critic of the target entity will be critical tweets. [sent-142, score-2.195]
</p><p>48 Therefore, we can calculate a ratio of critical tweets for all of the tweets about the target entity. [sent-143, score-0.476]
</p><p>49 scorei=Nnii  (1)  Ni is the number of all tweets about the target entity and ni is the number of critical tweets about the entity by that user 2. [sent-145, score-0.727]
</p><p>50 We extract the top M users based on scorei as chronic critics. [sent-146, score-0.896]
</p><p>51 2 Graph Analysis In social media, it is often very difficult to determine whether a tweet is critical since many tweets include sarcasm or incomplete contexts. [sent-148, score-0.547]
</p><p>52 The opinion mining may miss numerous complaints with sarcasm or incomplete contexts. [sent-149, score-0.378]
</p><p>53 In social media, we assume that users having the same opinion interact with each other in order to demonstrate the  correctness of their opinion. [sent-151, score-0.417]
</p><p>54 In particular, since the purpose of chronic critics is to spread the bad reputation, we assume that they want to assist each other. [sent-152, score-1.096]
</p><p>55 We supplement the opinion mining by a graph analysis using this assumption. [sent-153, score-0.297]
</p><p>56 Thus, we make a graph representing connections among the users and use label propagation on the graph based on the results of the opinion mining as the seeds. [sent-154, score-0.68]
</p><p>57 This implies that a user who spreads the opinion of another of agrees with the author of that opinion. [sent-156, score-0.246]
</p><p>58 In Twitter, a user can spread an opinion as an RT, which is a reposting of a tweet by a username (written in the format “RT @username: tweet”). [sent-157, score-0.514]
</p><p>59 (201 1b) demonstrated that they can make a graph representing the connections among users who support each others opinions by using RTs. [sent-159, score-0.373]
</p><p>60 , um}) as nodes, gwrhaeprhe ui sco mnn uescetrss w (Uith uj {vuia an edge t)h aast 2The formula (1) assigns a high score to a user if the user  only produces one or two tweets about the target entity and those tweets are negative. [sent-165, score-0.73]
</p><p>61 To prevent this, we disregard the users whose the number of tweets are fewer than 5. [sent-166, score-0.339]
</p><p>62 has weight wij (0 ≤ wij ≤ 1) and wij corresponds to the degree to( 0w ≤hic wh ui supports uj. [sent-167, score-0.372]
</p><p>63 wij=21(Rriij+rRjji)  (2)  is the total RT tweets of uj by ui and Ri is the number of RTs by ui. [sent-169, score-0.252]
</p><p>64 We find more new chronic critics by label propagation on the graph. [sent-175, score-1.097]
</p><p>65 We use the chronic critics obtained by the opinion mining as seeds. [sent-176, score-1.284]
</p><p>66 It is assumed that a user who supports the target entity is not a chronic critic. [sent-177, score-0.927]
</p><p>67 The scores of chronic critics obtained by the opinion mining are 1 and the score of the target entity is set to −1. [sent-191, score-1.432]
</p><p>68 That is, if the users support each other, the scores of the users are close to each other. [sent-195, score-0.35]
</p><p>69 We believe that if the distance between users on the graph is large, then users slightly support each other. [sent-198, score-0.421]
</p><p>70 The twitter search API returns the tweets that contain an input query. [sent-220, score-0.24]
</p><p>71 We found many critical tweets about these target entities. [sent-223, score-0.312]
</p><p>72 We want to extract the users who frequently express a public opinion related to a target entity. [sent-226, score-0.423]
</p><p>73 For this reason, we eliminated users whose the number of tweets except conversation (i. [sent-227, score-0.339]
</p><p>74 In addition, to eliminate bots that automatically post specific tweets, we eliminated users whose conversational tweets were fewer than 2. [sent-230, score-0.339]
</p><p>75 To satisfy our definition, a chronic critic must tweet about the target entity many times. [sent-232, score-1.126]
</p><p>76 on the top 300 users based on the number of tweets as our experimental users. [sent-235, score-0.339]
</p><p>77 Table 1 shows the total numbers of tweets by the top 300 users, excluding the account of the target entity. [sent-236, score-0.254]
</p><p>78 We created an evaluation set by manually dividing the experimental users into chronic critics and regular users. [sent-237, score-1.233]
</p><p>79 A chronic critic actively com-  plained and tried to harm the reputation of the target entity. [sent-238, score-1.013]
</p><p>80 We also regarded a user who frequently reposted a critic’s tweets and unfavorable news about the target entity as a chronic critic. [sent-239, score-1.116]
</p><p>81 For the experimental users tweeting about CompanyA, we asked two human annotators to judge whether a user was a chronic critic based on one month of tweets. [sent-240, score-1.134]
</p><p>82 Table 1 expresses the number of chronic critics for each target entity in the evaluation set. [sent-244, score-1.206]
</p><p>83 For the experimental users tweeting about Politician A, we randomly extracted 50 users randomly to calculate Cohen’s kappa, which is displayed in Table 1. [sent-245, score-0.373]
</p><p>84 We evaluated the effects of combining the opinion mining with the graph analysis. [sent-246, score-0.297]
</p><p>85 We compared opinion mining (OM), graph analysis (GA), and the combination of opinion mining and graph analysis (our proposed method). [sent-247, score-0.618]
</p><p>86 GA randomly selected M users from experimental users as seeds and takes the average of the results obtained by  performing label propagation three times. [sent-248, score-0.441]
</p><p>87 The number of chronic critics extracted by the opinion mining (i. [sent-249, score-1.284]
</p><p>88 02 and accepted a user with a score over the threshold as a chronic critic. [sent-258, score-0.779]
</p><p>89 "&  '  Table 2: Users connected with the target entity  Target entityUsersNon-critics  PCoolmitipcainayn A A74453359 chronic critics while retaining high precision of OM. [sent-295, score-1.231]
</p><p>90 Therefore, the combination of the opinion mining and the graph analysis improved the performance of recognizing the chronic critics. [sent-296, score-0.993]
</p><p>91 In addition, some chronic critics do not express criticism clearly in their own tweets. [sent-300, score-1.058]
</p><p>92 However, the proposed method recognized most chronic critics that complain with these methods based on the GA. [sent-305, score-1.12]
</p><p>93 It cannot reasonably be assumed that a user who supports the account of the target entity is a chronic critic. [sent-306, score-0.953]
</p><p>94 We believe that using the account corrects for mistakes in selecting the seed chronic critics. [sent-308, score-0.722]
</p><p>95 Therefore, incorporating the account into the graph analysis can correct for errors in the seeding of chronic critics. [sent-313, score-0.793]
</p><p>96 However, some chronic critics were connected with the target’s account  and reposted tweets from the account. [sent-314, score-1.298]
</p><p>97 We were able to find most of the chronic critics by extracting the users linked to each other. [sent-318, score-1.256]
</p><p>98 This means we need high accuracy in selecting the seeds to correctly capture chronic critics. [sent-320, score-0.748]
</p><p>99 Because we used the users extracted by the opinion mining as the seeds, the proposed method outperformed OM and GA. [sent-321, score-0.425]
</p><p>100 5  Conclusion  In this paper, we proposed a method that uses not only opinion mining but graph analysis of the connections between users to detect chronic critics. [sent-322, score-1.326]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('chronic', 0.696), ('critics', 0.362), ('users', 0.175), ('company', 0.175), ('tweets', 0.164), ('opinion', 0.163), ('critic', 0.157), ('tweet', 0.125), ('wij', 0.108), ('connections', 0.098), ('entity', 0.084), ('critical', 0.084), ('user', 0.083), ('media', 0.081), ('social', 0.079), ('conover', 0.076), ('username', 0.076), ('twitter', 0.076), ('om', 0.072), ('graph', 0.071), ('reputation', 0.07), ('politician', 0.067), ('target', 0.064), ('mining', 0.063), ('speriosu', 0.058), ('barbosa', 0.058), ('complaints', 0.057), ('criticizing', 0.057), ('sentiment', 0.055), ('comment', 0.055), ('davidov', 0.052), ('seeds', 0.052), ('sarcasm', 0.05), ('ui', 0.048), ('polarity', 0.047), ('incomplete', 0.045), ('rt', 0.045), ('murakami', 0.044), ('ogino', 0.043), ('uj', 0.04), ('ga', 0.04), ('propagation', 0.039), ('spread', 0.038), ('complain', 0.038), ('connor', 0.038), ('comments', 0.037), ('kanayama', 0.036), ('detect', 0.036), ('japanese', 0.036), ('awful', 0.035), ('bunsetsu', 0.033), ('political', 0.033), ('spammers', 0.031), ('analyzer', 0.031), ('opinions', 0.029), ('complains', 0.029), ('complaint', 0.029), ('criticizes', 0.029), ('declinable', 0.029), ('flammini', 0.029), ('fool', 0.029), ('higashiyama', 0.029), ('miki', 0.029), ('reposting', 0.029), ('shiho', 0.029), ('inui', 0.027), ('reply', 0.027), ('account', 0.026), ('harm', 0.026), ('um', 0.026), ('profanity', 0.025), ('rumors', 0.025), ('calves', 0.025), ('ratkiewicz', 0.025), ('reposted', 0.025), ('scorei', 0.025), ('feng', 0.025), ('connected', 0.025), ('ul', 0.024), ('recognize', 0.024), ('neutral', 0.024), ('weblogs', 0.024), ('proposed', 0.024), ('hiroshi', 0.023), ('tumasjan', 0.023), ('filippo', 0.023), ('gon', 0.023), ('tweeting', 0.023), ('akiko', 0.023), ('linked', 0.023), ('working', 0.023), ('malicious', 0.022), ('spammer', 0.022), ('bollen', 0.021), ('oppose', 0.021), ('public', 0.021), ('qt', 0.02), ('analyzing', 0.02), ('yang', 0.02), ('really', 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="114-tfidf-1" href="./acl-2013-Detecting_Chronic_Critics_Based_on_Sentiment_Polarity_and_User%C3%A2%E2%80%A2%C5%BDs_Behavior_in_Social_Media.html">114 acl-2013-Detecting Chronic Critics Based on Sentiment Polarity and Userâ•Žs Behavior in Social Media</a></p>
<p>Author: Sho Takase ; Akiko Murakami ; Miki Enoki ; Naoaki Okazaki ; Kentaro Inui</p><p>Abstract: There are some chronic critics who always complain about the entity in social media. We are working to automatically detect these chronic critics to prevent the spread of bad rumors about the reputation of the entity. In social media, most comments are informal, and, there are sarcastic and incomplete contexts. This means that it is difficult for current NLP technology such as opinion mining to recognize the complaints. As an alternative approach for social media, we can assume that users who share the same opinions will link to each other. Thus, we propose a method that combines opinion mining with graph analysis for the connections between users to identify the chronic critics. Our ex- perimental results show that the proposed method outperforms analysis based only on opinion mining techniques.</p><p>2 0.19363707 <a title="114-tfidf-2" href="./acl-2013-Detecting_Event-Related_Links_and_Sentiments_from_Social_Media_Texts.html">115 acl-2013-Detecting Event-Related Links and Sentiments from Social Media Texts</a></p>
<p>Author: Alexandra Balahur ; Hristo Tanev</p><p>Abstract: Nowadays, the importance of Social Media is constantly growing, as people often use such platforms to share mainstream media news and comment on the events that they relate to. As such, people no loger remain mere spectators to the events that happen in the world, but become part of them, commenting on their developments and the entities involved, sharing their opinions and distributing related content. This paper describes a system that links the main events detected from clusters of newspaper articles to tweets related to them, detects complementary information sources from the links they contain and subsequently applies sentiment analysis to classify them into positive, negative and neutral. In this manner, readers can follow the main events happening in the world, both from the perspective of mainstream as well as social media and the public’s perception on them. This system will be part of the EMM media monitoring framework working live and it will be demonstrated using Google Earth.</p><p>3 0.16462581 <a title="114-tfidf-3" href="./acl-2013-Mining_Opinion_Words_and_Opinion_Targets_in_a_Two-Stage_Framework.html">244 acl-2013-Mining Opinion Words and Opinion Targets in a Two-Stage Framework</a></p>
<p>Author: Liheng Xu ; Kang Liu ; Siwei Lai ; Yubo Chen ; Jun Zhao</p><p>Abstract: This paper proposes a novel two-stage method for mining opinion words and opinion targets. In the first stage, we propose a Sentiment Graph Walking algorithm, which naturally incorporates syntactic patterns in a Sentiment Graph to extract opinion word/target candidates. Then random walking is employed to estimate confidence of candidates, which improves extraction accuracy by considering confidence of patterns. In the second stage, we adopt a self-learning strategy to refine the results from the first stage, especially for filtering out high-frequency noise terms and capturing the long-tail terms, which are not investigated by previous methods. The experimental results on three real world datasets demonstrate the effectiveness of our approach compared with stateof-the-art unsupervised methods.</p><p>4 0.16024218 <a title="114-tfidf-4" href="./acl-2013-Joint_Inference_for_Fine-grained_Opinion_Extraction.html">207 acl-2013-Joint Inference for Fine-grained Opinion Extraction</a></p>
<p>Author: Bishan Yang ; Claire Cardie</p><p>Abstract: This paper addresses the task of finegrained opinion extraction the identification of opinion-related entities: the opinion expressions, the opinion holders, and the targets of the opinions, and the relations between opinion expressions and their targets and holders. Most existing approaches tackle the extraction of opinion entities and opinion relations in a pipelined manner, where the interdependencies among different extraction stages are not captured. We propose a joint inference model that leverages knowledge from predictors that optimize subtasks – of opinion extraction, and seeks a globally optimal solution. Experimental results demonstrate that our joint inference approach significantly outperforms traditional pipeline methods and baselines that tackle subtasks in isolation for the problem of opinion extraction.</p><p>5 0.14569762 <a title="114-tfidf-5" href="./acl-2013-Linking_Tweets_to_News%3A_A_Framework_to_Enrich_Short_Text_Data_in_Social_Media.html">233 acl-2013-Linking Tweets to News: A Framework to Enrich Short Text Data in Social Media</a></p>
<p>Author: Weiwei Guo ; Hao Li ; Heng Ji ; Mona Diab</p><p>Abstract: Many current Natural Language Processing [NLP] techniques work well assuming a large context of text as input data. However they become ineffective when applied to short texts such as Twitter feeds. To overcome the issue, we want to find a related newswire document to a given tweet to provide contextual support for NLP tasks. This requires robust modeling and understanding of the semantics of short texts. The contribution of the paper is two-fold: 1. we introduce the Linking-Tweets-toNews task as well as a dataset of linked tweet-news pairs, which can benefit many NLP applications; 2. in contrast to previ- ous research which focuses on lexical features within the short texts (text-to-word information), we propose a graph based latent variable model that models the inter short text correlations (text-to-text information). This is motivated by the observation that a tweet usually only covers one aspect of an event. We show that using tweet specific feature (hashtag) and news specific feature (named entities) as well as temporal constraints, we are able to extract text-to-text correlations, and thus completes the semantic picture of a short text. Our experiments show significant improvement of our new model over baselines with three evaluation metrics in the new task.</p><p>6 0.1348789 <a title="114-tfidf-6" href="./acl-2013-Syntactic_Patterns_versus_Word_Alignment%3A_Extracting_Opinion_Targets_from_Online_Reviews.html">336 acl-2013-Syntactic Patterns versus Word Alignment: Extracting Opinion Targets from Online Reviews</a></p>
<p>7 0.12252143 <a title="114-tfidf-7" href="./acl-2013-Exploiting_Topic_based_Twitter_Sentiment_for_Stock_Prediction.html">147 acl-2013-Exploiting Topic based Twitter Sentiment for Stock Prediction</a></p>
<p>8 0.12191732 <a title="114-tfidf-8" href="./acl-2013-Exploring_Sentiment_in_Social_Media%3A_Bootstrapping_Subjectivity_Clues_from_Multilingual_Twitter_Streams.html">148 acl-2013-Exploring Sentiment in Social Media: Bootstrapping Subjectivity Clues from Multilingual Twitter Streams</a></p>
<p>9 0.1188503 <a title="114-tfidf-9" href="./acl-2013-A_Stacking-based_Approach_to_Twitter_User_Geolocation_Prediction.html">20 acl-2013-A Stacking-based Approach to Twitter User Geolocation Prediction</a></p>
<p>10 0.11791617 <a title="114-tfidf-10" href="./acl-2013-Identifying_Opinion_Subgroups_in_Arabic_Online_Discussions.html">187 acl-2013-Identifying Opinion Subgroups in Arabic Online Discussions</a></p>
<p>11 0.11355986 <a title="114-tfidf-11" href="./acl-2013-An_Empirical_Study_on_Uncertainty_Identification_in_Social_Media_Context.html">45 acl-2013-An Empirical Study on Uncertainty Identification in Social Media Context</a></p>
<p>12 0.11127314 <a title="114-tfidf-12" href="./acl-2013-A_user-centric_model_of_voting_intention_from_Social_Media.html">33 acl-2013-A user-centric model of voting intention from Social Media</a></p>
<p>13 0.11047958 <a title="114-tfidf-13" href="./acl-2013-Exploiting_Social_Media_for_Natural_Language_Processing%3A_Bridging_the_Gap_between_Language-centric_and_Real-world_Applications.html">146 acl-2013-Exploiting Social Media for Natural Language Processing: Bridging the Gap between Language-centric and Real-world Applications</a></p>
<p>14 0.10916115 <a title="114-tfidf-14" href="./acl-2013-Sequential_Summarization%3A_A_New_Application_for_Timely_Updated_Twitter_Trending_Topics.html">319 acl-2013-Sequential Summarization: A New Application for Timely Updated Twitter Trending Topics</a></p>
<p>15 0.10645386 <a title="114-tfidf-15" href="./acl-2013-Microblogs_as_Parallel_Corpora.html">240 acl-2013-Microblogs as Parallel Corpora</a></p>
<p>16 0.10368227 <a title="114-tfidf-16" href="./acl-2013-Entity_Linking_for_Tweets.html">139 acl-2013-Entity Linking for Tweets</a></p>
<p>17 0.1003947 <a title="114-tfidf-17" href="./acl-2013-Using_Conceptual_Class_Attributes_to_Characterize_Social_Media_Users.html">373 acl-2013-Using Conceptual Class Attributes to Characterize Social Media Users</a></p>
<p>18 0.088554546 <a title="114-tfidf-18" href="./acl-2013-Identifying_Sentiment_Words_Using_an_Optimization-based_Model_without_Seed_Words.html">188 acl-2013-Identifying Sentiment Words Using an Optimization-based Model without Seed Words</a></p>
<p>19 0.0823742 <a title="114-tfidf-19" href="./acl-2013-Resolving_Entity_Morphs_in_Censored_Data.html">301 acl-2013-Resolving Entity Morphs in Censored Data</a></p>
<p>20 0.071833923 <a title="114-tfidf-20" href="./acl-2013-Deceptive_Answer_Prediction_with_User_Preference_Graph.html">107 acl-2013-Deceptive Answer Prediction with User Preference Graph</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.132), (1, 0.202), (2, -0.004), (3, 0.16), (4, 0.059), (5, 0.107), (6, -0.003), (7, 0.024), (8, 0.097), (9, -0.159), (10, -0.155), (11, 0.034), (12, 0.06), (13, -0.05), (14, 0.021), (15, 0.001), (16, 0.044), (17, 0.011), (18, 0.001), (19, -0.031), (20, 0.027), (21, 0.036), (22, 0.01), (23, -0.042), (24, -0.02), (25, 0.022), (26, 0.041), (27, 0.063), (28, -0.007), (29, 0.018), (30, 0.009), (31, -0.018), (32, -0.0), (33, 0.063), (34, -0.037), (35, 0.018), (36, -0.041), (37, -0.021), (38, -0.017), (39, -0.009), (40, 0.017), (41, -0.009), (42, 0.011), (43, 0.009), (44, 0.024), (45, -0.053), (46, -0.017), (47, 0.009), (48, 0.051), (49, 0.005)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95460254 <a title="114-lsi-1" href="./acl-2013-Detecting_Chronic_Critics_Based_on_Sentiment_Polarity_and_User%C3%A2%E2%80%A2%C5%BDs_Behavior_in_Social_Media.html">114 acl-2013-Detecting Chronic Critics Based on Sentiment Polarity and Userâ•Žs Behavior in Social Media</a></p>
<p>Author: Sho Takase ; Akiko Murakami ; Miki Enoki ; Naoaki Okazaki ; Kentaro Inui</p><p>Abstract: There are some chronic critics who always complain about the entity in social media. We are working to automatically detect these chronic critics to prevent the spread of bad rumors about the reputation of the entity. In social media, most comments are informal, and, there are sarcastic and incomplete contexts. This means that it is difficult for current NLP technology such as opinion mining to recognize the complaints. As an alternative approach for social media, we can assume that users who share the same opinions will link to each other. Thus, we propose a method that combines opinion mining with graph analysis for the connections between users to identify the chronic critics. Our ex- perimental results show that the proposed method outperforms analysis based only on opinion mining techniques.</p><p>2 0.77292854 <a title="114-lsi-2" href="./acl-2013-Exploiting_Social_Media_for_Natural_Language_Processing%3A_Bridging_the_Gap_between_Language-centric_and_Real-world_Applications.html">146 acl-2013-Exploiting Social Media for Natural Language Processing: Bridging the Gap between Language-centric and Real-world Applications</a></p>
<p>Author: Simone Paolo Ponzetto ; Andrea Zielinski</p><p>Abstract: unkown-abstract</p><p>3 0.72911012 <a title="114-lsi-3" href="./acl-2013-An_Empirical_Study_on_Uncertainty_Identification_in_Social_Media_Context.html">45 acl-2013-An Empirical Study on Uncertainty Identification in Social Media Context</a></p>
<p>Author: Zhongyu Wei ; Junwen Chen ; Wei Gao ; Binyang Li ; Lanjun Zhou ; Yulan He ; Kam-Fai Wong</p><p>Abstract: Uncertainty text detection is important to many social-media-based applications since more and more users utilize social media platforms (e.g., Twitter, Facebook, etc.) as information source to produce or derive interpretations based on them. However, existing uncertainty cues are ineffective in social media context because of its specific characteristics. In this paper, we propose a variant of annotation scheme for uncertainty identification and construct the first uncertainty corpus based on tweets. We then conduct experiments on the generated tweets corpus to study the effectiveness of different types of features for uncertainty text identification.</p><p>4 0.7252087 <a title="114-lsi-4" href="./acl-2013-Detecting_Event-Related_Links_and_Sentiments_from_Social_Media_Texts.html">115 acl-2013-Detecting Event-Related Links and Sentiments from Social Media Texts</a></p>
<p>Author: Alexandra Balahur ; Hristo Tanev</p><p>Abstract: Nowadays, the importance of Social Media is constantly growing, as people often use such platforms to share mainstream media news and comment on the events that they relate to. As such, people no loger remain mere spectators to the events that happen in the world, but become part of them, commenting on their developments and the entities involved, sharing their opinions and distributing related content. This paper describes a system that links the main events detected from clusters of newspaper articles to tweets related to them, detects complementary information sources from the links they contain and subsequently applies sentiment analysis to classify them into positive, negative and neutral. In this manner, readers can follow the main events happening in the world, both from the perspective of mainstream as well as social media and the public’s perception on them. This system will be part of the EMM media monitoring framework working live and it will be demonstrated using Google Earth.</p><p>5 0.72140163 <a title="114-lsi-5" href="./acl-2013-A_Stacking-based_Approach_to_Twitter_User_Geolocation_Prediction.html">20 acl-2013-A Stacking-based Approach to Twitter User Geolocation Prediction</a></p>
<p>Author: Bo Han ; Paul Cook ; Timothy Baldwin</p><p>Abstract: We implement a city-level geolocation prediction system for Twitter users. The system infers a user’s location based on both tweet text and user-declared metadata using a stacking approach. We demonstrate that the stacking method substantially outperforms benchmark methods, achieving 49% accuracy on a benchmark dataset. We further evaluate our method on a recent crawl of Twitter data to investigate the impact of temporal factors on model generalisation. Our results suggest that user-declared location metadata is more sensitive to temporal change than the text of Twitter messages. We also describe two ways of accessing/demoing our system.</p><p>6 0.6771245 <a title="114-lsi-6" href="./acl-2013-A_user-centric_model_of_voting_intention_from_Social_Media.html">33 acl-2013-A user-centric model of voting intention from Social Media</a></p>
<p>7 0.6263144 <a title="114-lsi-7" href="./acl-2013-Linking_Tweets_to_News%3A_A_Framework_to_Enrich_Short_Text_Data_in_Social_Media.html">233 acl-2013-Linking Tweets to News: A Framework to Enrich Short Text Data in Social Media</a></p>
<p>8 0.58406818 <a title="114-lsi-8" href="./acl-2013-Aid_is_Out_There%3A_Looking_for_Help_from_Tweets_during_a_Large_Scale_Disaster.html">42 acl-2013-Aid is Out There: Looking for Help from Tweets during a Large Scale Disaster</a></p>
<p>9 0.5736323 <a title="114-lsi-9" href="./acl-2013-Sequential_Summarization%3A_A_New_Application_for_Timely_Updated_Twitter_Trending_Topics.html">319 acl-2013-Sequential Summarization: A New Application for Timely Updated Twitter Trending Topics</a></p>
<p>10 0.56690496 <a title="114-lsi-10" href="./acl-2013-Resolving_Entity_Morphs_in_Censored_Data.html">301 acl-2013-Resolving Entity Morphs in Censored Data</a></p>
<p>11 0.53701216 <a title="114-lsi-11" href="./acl-2013-Exploiting_Topic_based_Twitter_Sentiment_for_Stock_Prediction.html">147 acl-2013-Exploiting Topic based Twitter Sentiment for Stock Prediction</a></p>
<p>12 0.53620607 <a title="114-lsi-12" href="./acl-2013-Using_Conceptual_Class_Attributes_to_Characterize_Social_Media_Users.html">373 acl-2013-Using Conceptual Class Attributes to Characterize Social Media Users</a></p>
<p>13 0.52919722 <a title="114-lsi-13" href="./acl-2013-Mining_Opinion_Words_and_Opinion_Targets_in_a_Two-Stage_Framework.html">244 acl-2013-Mining Opinion Words and Opinion Targets in a Two-Stage Framework</a></p>
<p>14 0.51693058 <a title="114-lsi-14" href="./acl-2013-Identifying_Opinion_Subgroups_in_Arabic_Online_Discussions.html">187 acl-2013-Identifying Opinion Subgroups in Arabic Online Discussions</a></p>
<p>15 0.51611739 <a title="114-lsi-15" href="./acl-2013-Joint_Inference_for_Fine-grained_Opinion_Extraction.html">207 acl-2013-Joint Inference for Fine-grained Opinion Extraction</a></p>
<p>16 0.51498395 <a title="114-lsi-16" href="./acl-2013-Bi-directional_Inter-dependencies_of_Subjective_Expressions_and_Targets_and_their_Value_for_a_Joint_Model.html">67 acl-2013-Bi-directional Inter-dependencies of Subjective Expressions and Targets and their Value for a Joint Model</a></p>
<p>17 0.51059961 <a title="114-lsi-17" href="./acl-2013-Syntactic_Patterns_versus_Word_Alignment%3A_Extracting_Opinion_Targets_from_Online_Reviews.html">336 acl-2013-Syntactic Patterns versus Word Alignment: Extracting Opinion Targets from Online Reviews</a></p>
<p>18 0.50526303 <a title="114-lsi-18" href="./acl-2013-Exploring_Sentiment_in_Social_Media%3A_Bootstrapping_Subjectivity_Clues_from_Multilingual_Twitter_Streams.html">148 acl-2013-Exploring Sentiment in Social Media: Bootstrapping Subjectivity Clues from Multilingual Twitter Streams</a></p>
<p>19 0.50285274 <a title="114-lsi-19" href="./acl-2013-Crawling_microblogging_services_to_gather_language-classified_URLs._Workflow_and_case_study.html">95 acl-2013-Crawling microblogging services to gather language-classified URLs. Workflow and case study</a></p>
<p>20 0.46384317 <a title="114-lsi-20" href="./acl-2013-Microblogs_as_Parallel_Corpora.html">240 acl-2013-Microblogs as Parallel Corpora</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.027), (4, 0.018), (6, 0.04), (11, 0.05), (15, 0.03), (24, 0.041), (26, 0.087), (28, 0.013), (35, 0.05), (38, 0.015), (42, 0.03), (48, 0.05), (55, 0.263), (63, 0.011), (70, 0.04), (88, 0.042), (90, 0.036), (95, 0.072)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.77292746 <a title="114-lda-1" href="./acl-2013-Detecting_Chronic_Critics_Based_on_Sentiment_Polarity_and_User%C3%A2%E2%80%A2%C5%BDs_Behavior_in_Social_Media.html">114 acl-2013-Detecting Chronic Critics Based on Sentiment Polarity and Userâ•Žs Behavior in Social Media</a></p>
<p>Author: Sho Takase ; Akiko Murakami ; Miki Enoki ; Naoaki Okazaki ; Kentaro Inui</p><p>Abstract: There are some chronic critics who always complain about the entity in social media. We are working to automatically detect these chronic critics to prevent the spread of bad rumors about the reputation of the entity. In social media, most comments are informal, and, there are sarcastic and incomplete contexts. This means that it is difficult for current NLP technology such as opinion mining to recognize the complaints. As an alternative approach for social media, we can assume that users who share the same opinions will link to each other. Thus, we propose a method that combines opinion mining with graph analysis for the connections between users to identify the chronic critics. Our ex- perimental results show that the proposed method outperforms analysis based only on opinion mining techniques.</p><p>2 0.75676072 <a title="114-lda-2" href="./acl-2013-Typesetting_for_Improved_Readability_using_Lexical_and_Syntactic_Information.html">364 acl-2013-Typesetting for Improved Readability using Lexical and Syntactic Information</a></p>
<p>Author: Ahmed Salama ; Kemal Oflazer ; Susan Hagan</p><p>Abstract: We present results from our study ofwhich uses syntactically and semantically motivated information to group segments of sentences into unbreakable units for the purpose of typesetting those sentences in a region of a fixed width, using an otherwise standard dynamic programming line breaking algorithm, to minimize raggedness. In addition to a rule-based baseline segmenter, we use a very modest size text, manually annotated with positions of breaks, to train a maximum entropy classifier, relying on an extensive set of lexical and syntactic features, which can then predict whether or not to break after a certain word position in a sentence. We also use a simple genetic algorithm to search for a subset of the features optimizing F1, to arrive at a set of features that delivers 89.2% Precision, 90.2% Recall (89.7% F1) on a test set, improving the rule-based baseline by about 11points and the classifier trained on all features by about 1point in F1. 1 Introduction and Motivation Current best practice in typography focuses on several interrelated factors (Humar et al., 2008; Tinkel, 1996). These factors include typeface selection, the color of the type and its contrast with the background, the size of the type, the length of the lines of type in the body of the text, the media in which the type will live, the distance between each line of type, and the appearance of the justified or ragged right side edge of the paragraphs, which should maintain either the appearance of a straight line on both sides of the block of type (justified) or create a gentle wave on the ragged right side edge. cmu .edu hagan @ cmu .edu This paper addresses one aspect of current “best practice,” concerning the alignment of text in a paragraph. While current practice values that gentle “wave,” which puts the focus on the elegant look of the overall paragraph, it does so at the expense of meaning-making features. Meaningmaking features enable typesetting to maintain the integrity of phrases within sentences, giving those interests equal consideration with the overall look of the paragraph. Figure 1 (a) shows a text fragment typeset without any regard to natural breaks while (b) shows an example of a typesetting that we would like to get, where many natural breaks are respected. While current practice works well enough for native speakers, fluency problems for non-native speakers lead to uncertainty when the beginning and end of English phrases are interrupted by the need to move to the next line of the text before completing the phrase. This pause is a potential problem for readers because they try to interpret content words, relate them to their referents and anticipate the role of the next word, as they encounter them in the text (Just and Carpenter, 1980). While incorrect anticipation might not be problematic for native speakers, who can quickly re-adjust, non-native speakers may find inaccurate anticipation more troublesome. This problem could be more significant because English as a second language (ESL) readers are engaged not only in understanding a foreign language, but also in processing the “anticipated text” as they read a partial phrase, and move to the next line in the text, only to discover that they anticipated meaning incorrectly. Even native speakers with less skill may experience difficulty comprehending text and work with young readers suggests that ”[c]omprehension difficulties may be localized at points of high processing demands whether from syntax or other sources” (Perfetti et al., 2005). As ESL readers process a partial phrase, and move to 719 ProceedingSsof oifa, th Beu 5l1gsarti Aan,An uuaglu Mste 4e-ti9n2g 0 o1f3 t.he ?c A2s0s1o3ci Aatsiosonc fioartio Cno fmorpu Ctoamtiopnuatalt Lioinngauli Lsitnicgsu,i psatgices 719–724, the next line in the text, instances of incorrectly anticipated meaning would logically increase processing demands to a greater degree. Additionally, as readers make meaning, we assume that they don’t parse their thoughts using the same phrasal divisions “needed to diagram a sentence.” Our perspective not only relies on the immediacy assumption, but also develops as an outgrowth of other ways that we make meaning outside of the form or function rules of grammar. Specifically, Halliday and Hasan (1976) found that rules of grammar do not explain how cohesive principals engage readers in meaning making across sentences. In order to make meaning across sentences, readers must be able to refer anaphorically backward to the previous sentence, and cataphorically forward to the next sentence. Along similar lines, readers of a single sentence assume that transitive verbs will include a direct object, and will therefore speculate about what that object might be, and sometimes get it wrong. Thus proper typesetting of a segment of text must explore ways to help readers avoid incorrect anticipation, while also considering those moments in the text where readers tend to pause in order to integrate the meaning of a phrase. Those decisions depend on the context. A phrasal break between a one-word subject and its verb tends to be more unattractive, because the reader does not have to make sense of relationships between the noun/subject and related adjectives before moving on to the verb. In this case, the reader will be more likely to anticipate the verb to come. However, a break between a subject preceded by multiple adjectives and its verb is likely to be more useful to a reader (if not ideal), because the relationships between the noun and its related adjectives are more likely to have thematic importance leading to longer gaze time on the relevant words in the subject phrase (Just and Carpenter, 1980). We are not aware of any prior work for bringing computational linguistic techniques to bear on this problem. A relatively recent study (Levasseur et al., 2006) that accounted only for breaks at commas and ends of sentences, found that even those breaks improved reading fluency. While the participants in that study were younger (7 to 9+ years old), the study is relevant because the challenges those young participants face, are faced again when readers of any age encounter new and complicated texts that present words they do not know, and ideas they have never considered. On the other hand, there is ample work on the basic algorithm to place a sequence of words in a typesetting area with a certain width, commonly known as the optimal line breaking problem (e.g., Plass (1981), Knuth and Plass (1981)). This problem is quite well-understood and basic variants are usually studied as an elementary example application of dynamic programming. In this paper we explore the problem of learning where to break sentences in order to avoid the problems discussed above. Once such unbreakable segments are identified, a simple application of the dynamic programming algorithm for optimal line breaking, using unbreakable segments as “words”, easily typesets the text to a given width area. 2 Text Breaks The rationale for content breaks is linked to our interest in preventing inaccurate anticipation, which is based on the immediacy assumption. The immediacy assumption (Just and Carpenter, 1980) considers, among other things, the reader’s interest in trying to relate content words to their referents as soon as possible. Prior context also encourages the reader to anticipate a particular role or case for the next word, such as agent or the manner in which something is done.Therefore, in defining our breaks, we consider not only the need to maintain the syntactic integrity of phrases, such as the prepositional phrase, but also the semantic integrity across syntactical divisions. For example, semantic integrity is important when transitive verbs anticipate direct objects. Strictly speaking, we define a bad break as one that will cause (i) unintended anaphoric collocation, (ii) unintended cataphoric collocation, or (iii) incorrect anticipation. Using these broad constraints, we derived a set of about 30 rules that define acceptable and nonacceptable breaks, with exceptions based on context and other special cases. Some of the rules are very simple and are only related to the word posi- tion in the sentence: • • Break at the end of a sentence. Keep the first and last words of a sentence wKietehp pth teh rest sotf a aint.d The rest of the rule set are more complex and depend on the structure of the sentence in question, 720 . s anct ions and UN charge s o f gro s s right s abuse s Mi l ary tens i it ons on the Korean peninsula have risen to the i highe st level for years r with the communi st st ate under the youthful Kim threatening nuclear war in re sponse t o UN s anct i s impo s ed a ft e r it s thi rd at omi c t e st l on ast month . It ha s al s o (a) Text with standard typesetting from US s anct i s and UN charge s o f gro s s right s abu s e s . Mi l ary t en s i s on it on on the Ko rean penin sul a have r i en t o the i highe st l s r eve l for year s with the communi st st at e unde r the youthful Kim threat ening nuc l ear war in re spon s e t o UN s anct i s impo s ed a ft e r it s thi rd at omi c t e st l on ast month . (b) Text with syntax-directed typesetting , , Figure 1: Short fragment of text with standard typesetting (a) and with syntax and semantics motivated typesetting (b), both in a 75 character width. e.g.: • • • Keep a single word subject with the verb. Keep an appositive phrase with the noun it renames. Do not break inside a prepositional phrase. • • • Keep marooned prepositions with the word they modify. Keep the verb, the object and the preposition together ei nv a phrasal bvjeercbt phrase. Keep a gerund clause with its adverbial complement. There are exceptions to these rules in certain cases such as overly long phrases. 3 Experimental Setup Our data set consists of a modest set of 150 sentences (3918 tokens) selected from four different documents and manually annotated by a human expert relying on the 30 or so rules. The annotation consists of marking after each token whether one is allowed to break at that position or not.1 We developed three systems for predicting breaks: a rule-based baseline system, a maximumentropy classifier that learns to classify breaks us- ing about 100 lexical, syntactic and collocational features, and a maximum entropy classifier that uses a subset of these features selected by a simple genetic algorithm in a hill-climbing fashion. We evaluated our classifiers intrinsically using the usual measures: 1We expect to make our annotated data available upon the publication of the paper. • Precision: Percentage of the breaks posited tPhraetc were actually ctaogrere octf bthreeak bsre aink tshe p goldstandard hand-annotated data. It is possible to get 100% precision by putting a single break at the end. • Recall: Percentage of the actual breaks correctly posited. tIatg ies possible ttou get 1e0ak0%s c recall by positing a break after each token. F1: The geometric mean of precision and recFall divided by their average. It should be noted that when a text is typeset into an area of width of a certain number of characters, an erroneous break need not necessarily lead to an actual break in the final output, that is an error may • not be too bad. On the other hand, a missed break while not hurting the readability of the text may actually lead to a long segment that may eventually worsen raggedness in the final typesetting. Baseline Classifier We implemented a subset of the rules (those that rely only on lexical and partof-speech information), as a baseline rule-based break classifier. The baseline classifier avoids breaks: • • • after the first word in a sentence, quote or parentheses, before the last word in a sentence, quote or parentheses, asntd w between a punctuation mark following a bweotrwde or b aet wpueennct two nco nmsearckuti vfoel punctuation marks. It posits breaks (i) before a word following a punctuation, and (ii) before prepositions, auxiliary verbs, coordinating conjunctions, subordinate conjunctions, relative pronouns, relative adverbs, conjunctive adverbs, and correlative conjunctions. 721 Maximum Entropy Classifier We used the CRF++ Tool2 but with the option to run it only as a maximum entropy classifier (Berger et al., 1996), to train a classifier. We used a large set of about 100 features grouped into the following categories: • • Lexical features: These features include the tLoekxeinca aln fde athtuer ePsO:S T tag efo fre athtuer previous, current and the next word. We also encode whether the word is part of a compound noun or a verb, or is an adjective that subcategorizes a specific preposition in WordNet, (e.g., familiar with). Constituency structure features: These are Cunolnesxtiictauleinzecdy f setarutucrtuers eth faeat ttaurkees i:nt To aecsecou anret in the parse tree, for a word and its previous and next words, the labels of the parent, the grandparent and their siblings, and number of siblings they have. We also consider the label of the closest common ancestor for a word and its next word. • • Dependency structure features: These are unlDeexipceanldizeendc yfe satrtuurcteus eth faeat essentially capture the number of dependency relation links that cross-over a given word boundary. The motivation for these comes from the desire to limit the amount of information that would need to be carried over that boundary, assuming this would be captured by the number of dependency links over the break point. Baseline feature: This feature reflects Bwahseethlienre the rule-based baseline break classifier posits a break at this point or not. We use the following tools to process the sentences to extract some of these features: • Stanford constituency and dependency parsers, (De Marneffe et al., 2006; Klein and Manning, 2002; Klein and Manning, 2003), • • lemmatization tool in NLTK (Bird, 2006), WordNet for compound (Fellbaum, 1998). nouns and verbs 2Available at http : / / crfpp . googlecode .com/ svn /t runk / doc / index . html . TabPFRle1r c:ailsRoenultsBfra78os09me.l491inBaeslMin89eE078-a.nA382dlMaxi98mE09-.uG27mAEntropy break classifiers Maximum Entropy Classifier with GA Feature Selection We used a genetic algorithm on a development data set, to select a subset of the features above. Basically, we start with a randomly selected set of features and through mutation and crossover try to obtain feature combinations that perform better over the development set in terms of F1 score. After a few hundred generations of this kind of hill-climbing, we get a subset of features that perform the best. 4 Results Our current evaluation is only intrinsic in that we measure our performance in getting the break and no-break points correctly in a test set. The results are shown in Table 1. The column ME-All shows the results for a maximum entropy classifier using all the features and the column ME-GA shows the results for a maximum entropy classifier using about 50 of the about 100 features available, as selected by the genetic algorithm. Our best system delivers 89.2% precision and 90.2% recall (with 89.7% F1), improving the rulebased baseline by about 11points and the classifier trained on all features by about 1point in F1. After processing our test set with the ME-GA classifier, we can feed the segments into a standard word-wrapping dynamic programming algorithm (along with a maximum width) and obtain a typeset version with minimum raggedness on the right margin. This algorithm is fast enough to use even dynamically when resizing a window if the text is displayed in a browser on a screen. Figure 1 (b) displays an example of a small fragment of text typeset using the output of our best break classifier. One can immediately note that this typesetting has more raggedness overall, but avoids the bad breaks in (a). We are currently in the process of designing a series of experiments for extrinsic evaluation to determine if such typeset text helps comprehension for secondary language learners. 722 4.1 Error Analysis An analysis of the errors our best classifier makes (which may or may not be translated into an actual error in the final typesetting) shows that the majority of the errors basically can be categorized into the following groups: • Incorrect breaks posited for multiword colloIcnatcioornrse (e.g., akcst *po of weda fr,o3r rmuulel*ti of law, far ahead* of, raining cats* and dogs, etc.) • Missed breaks after a verb (e.g., calls | an act of war, proceeded to | implement, etc.) Missed breaks before or after prepositions or aMdvisesrebdia blsre (e.g., ethfoer day after | tehpeo wsitoiroldns realized, every .kgi.n,d th | of interference) We expect to overcome such cases by increasing our training data size significantly by using our classifier to break new texts and then have a human annotator to manually correct the breaks. • 5 Conclusions and Future Work We have used syntactically motivated information to help in typesetting text to facilitate better understanding of English text especially by secondary language learners, by avoiding breaks which may cause unnecessary anticipation errors. We have cast this as a classification problem to indicate whether to break after a certain word or not, by taking into account a variety of features. Our best system maximum entropy framework uses about 50 such features, which were selected using a genetic algorithm and performs significantly better than a rule-based break classifier and better than a maximum entropy classifier that uses all available features. We are currently working on extending this work in two main directions: We are designing a set of experiments to extrinsically test whether typesetting by our system improves reading ease and comprehension. We are also looking into a break labeling scheme that is not binary but based on a notion of “badness” perhaps quantized into 3-4 grades, that would allow flexibility between preventing bad breaks and minimizing raggedness. For instance, breaking a noun-phrase right after an initial the may be considered very bad. On the other hand, although it is desirable to keep an object NP together with the preceding transitive verb, – 3* indicates a spurious incorrect break, | indicates a misse*d i nbrdeiacka.t breaking before the object NP, could be OK, if not doing so causes an inordinate amount of raggedness. Then the final typesetting stage can optimize a combination of raggedness and the total “bad- ness” of all the breaks it posits. Acknowledgements This publication was made possible by grant NPRP-09-873-1-129 from the Qatar National Research Fund (a member of the Qatar Foundation). Susan Hagan acknowledges the generous support of the Qatar Foundation through Carnegie Mellon University’s Seed Research program. The statements made herein are solely the responsibility of this author(s), and not necessarily those of the Qatar Foundation. References Adam Berger, Stephen Della Pietra, and Vincent Della Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics, 22(1):39–71. Steven Bird. 2006. NLTK: The natural language toolkit. In Proceedings of the COLING/ACL, pages 69–72. Association for Computational Linguistics. Marie-Catherine De Marneffe, Bill MacCartney, and Christopher D Manning. 2006. Generating typed dependency parses from phrase structure parses. In Proceedings of LREC, volume 6, pages 449–454. Christiane Fellbaum. 1998. WordNet: An electronic lexical database. The MIT Press. M. A. K. Halliday and R. Hasan. 1976. Cohesion in English. Longman, London. I. Humar, M. Gradisar, and T. Turk. 2008. The impact of color combinations on the legibility of a web page text presented on crt displays. International Journal of Industrial Ergonomics, 38(1 1-12):885–899. Marcel A. Just and Patricia A. Carpenter. 1980. A theory of reading: From eye fixations to comprehension. Psychological Review, 87:329–354. Dan Klein and Christopher D. Manning. 2002. Fast exact inference with a factored model for natural language parsing. Advances in Neural Information Processing Systems, 15(2003):3–10. Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume 1, pages 423–430. Asso- ciation for Computational Linguistics. 723 Donald E Knuth and Michael F. Plass. 1981. Breaking paragraphs into lines. Software: Practice and Experience, 11(11): 1119–1 184. Valerie Marciarille Levasseur, Paul Macaruso, Laura Conway Palumbo, and Donald Shankweiler. 2006. Syntactically cued text facilitates oral reading fluency in developing readers. Applied Psycholinguistics, 27(3):423–445. C. A. Perfetti, N. Landi, and J. Oakhill. 2005. The acquisition of reading comprehension skill. In M. J. Snowling and C. Hulme, editors, The science of reading: A handbook, pages 227–247. Blackwell, Oxford. Michael Frederick Plass. 1981. Optimal Pagination Techniques for Automatic Typesetting Systems. Ph.D. thesis, Stanford University. K. Tinkel. 1996. Taking it in: What makes type easier to read. Adobe Magazine, pages 40–50. 724</p><p>3 0.52373433 <a title="114-lda-3" href="./acl-2013-Mapping_Source_to_Target_Strings_without_Alignment_by_Analogical_Learning%3A_A_Case_Study_with_Transliteration.html">236 acl-2013-Mapping Source to Target Strings without Alignment by Analogical Learning: A Case Study with Transliteration</a></p>
<p>Author: Phillippe Langlais</p><p>Abstract: Analogical learning over strings is a holistic model that has been investigated by a few authors as a means to map forms of a source language to forms of a target language. In this study, we revisit this learning paradigm and apply it to the transliteration task. We show that alone, it performs worse than a statistical phrase-based machine translation engine, but the combination of both approaches outperforms each one taken separately, demonstrating the usefulness of the information captured by a so-called formal analogy.</p><p>4 0.51683962 <a title="114-lda-4" href="./acl-2013-Sentiment_Relevance.html">318 acl-2013-Sentiment Relevance</a></p>
<p>Author: Christian Scheible ; Hinrich Schutze</p><p>Abstract: A number of different notions, including subjectivity, have been proposed for distinguishing parts of documents that convey sentiment from those that do not. We propose a new concept, sentiment relevance, to make this distinction and argue that it better reflects the requirements of sentiment analysis systems. We demonstrate experimentally that sentiment relevance and subjectivity are related, but different. Since no large amount of labeled training data for our new notion of sentiment relevance is available, we investigate two semi-supervised methods for creating sentiment relevance classifiers: a distant supervision approach that leverages structured information about the domain of the reviews; and transfer learning on feature representations based on lexical taxonomies that enables knowledge transfer. We show that both methods learn sentiment relevance classifiers that perform well.</p><p>5 0.51633132 <a title="114-lda-5" href="./acl-2013-Explicit_and_Implicit_Syntactic_Features_for_Text_Classification.html">144 acl-2013-Explicit and Implicit Syntactic Features for Text Classification</a></p>
<p>Author: Matt Post ; Shane Bergsma</p><p>Abstract: Syntactic features are useful for many text classification tasks. Among these, tree kernels (Collins and Duffy, 2001) have been perhaps the most robust and effective syntactic tool, appealing for their empirical success, but also because they do not require an answer to the difficult question of which tree features to use for a given task. We compare tree kernels to different explicit sets of tree features on five diverse tasks, and find that explicit features often perform as well as tree kernels on accuracy and always in orders of magnitude less time, and with smaller models. Since explicit features are easy to generate and use (with publicly avail- able tools) , we suggest they should always be included as baseline comparisons in tree kernel method evaluations.</p><p>6 0.51124126 <a title="114-lda-6" href="./acl-2013-Dual_Training_and_Dual_Prediction_for_Polarity_Classification.html">131 acl-2013-Dual Training and Dual Prediction for Polarity Classification</a></p>
<p>7 0.51119947 <a title="114-lda-7" href="./acl-2013-A_Lattice-based_Framework_for_Joint_Chinese_Word_Segmentation%2C_POS_Tagging_and_Parsing.html">7 acl-2013-A Lattice-based Framework for Joint Chinese Word Segmentation, POS Tagging and Parsing</a></p>
<p>8 0.51031333 <a title="114-lda-8" href="./acl-2013-Linking_Tweets_to_News%3A_A_Framework_to_Enrich_Short_Text_Data_in_Social_Media.html">233 acl-2013-Linking Tweets to News: A Framework to Enrich Short Text Data in Social Media</a></p>
<p>9 0.50865549 <a title="114-lda-9" href="./acl-2013-Detecting_Turnarounds_in_Sentiment_Analysis%3A_Thwarting.html">117 acl-2013-Detecting Turnarounds in Sentiment Analysis: Thwarting</a></p>
<p>10 0.50647765 <a title="114-lda-10" href="./acl-2013-Real-World_Semi-Supervised_Learning_of_POS-Taggers_for_Low-Resource_Languages.html">295 acl-2013-Real-World Semi-Supervised Learning of POS-Taggers for Low-Resource Languages</a></p>
<p>11 0.50631076 <a title="114-lda-11" href="./acl-2013-A_Bayesian_Model_for_Joint_Unsupervised_Induction_of_Sentiment%2C_Aspect_and_Discourse_Representations.html">2 acl-2013-A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations</a></p>
<p>12 0.50618362 <a title="114-lda-12" href="./acl-2013-Improving_pairwise_coreference_models_through_feature_space_hierarchy_learning.html">196 acl-2013-Improving pairwise coreference models through feature space hierarchy learning</a></p>
<p>13 0.50411451 <a title="114-lda-13" href="./acl-2013-Identifying_Sentiment_Words_Using_an_Optimization-based_Model_without_Seed_Words.html">188 acl-2013-Identifying Sentiment Words Using an Optimization-based Model without Seed Words</a></p>
<p>14 0.50298655 <a title="114-lda-14" href="./acl-2013-Cross-lingual_Projections_between_Languages_from_Different_Families.html">97 acl-2013-Cross-lingual Projections between Languages from Different Families</a></p>
<p>15 0.50211793 <a title="114-lda-15" href="./acl-2013-Summarization_Through_Submodularity_and_Dispersion.html">333 acl-2013-Summarization Through Submodularity and Dispersion</a></p>
<p>16 0.50087345 <a title="114-lda-16" href="./acl-2013-Online_Relative_Margin_Maximization_for_Statistical_Machine_Translation.html">264 acl-2013-Online Relative Margin Maximization for Statistical Machine Translation</a></p>
<p>17 0.5008291 <a title="114-lda-17" href="./acl-2013-Bilingually-Guided_Monolingual_Dependency_Grammar_Induction.html">70 acl-2013-Bilingually-Guided Monolingual Dependency Grammar Induction</a></p>
<p>18 0.50033379 <a title="114-lda-18" href="./acl-2013-LABR%3A_A_Large_Scale_Arabic_Book_Reviews_Dataset.html">211 acl-2013-LABR: A Large Scale Arabic Book Reviews Dataset</a></p>
<p>19 0.50016814 <a title="114-lda-19" href="./acl-2013-Unsupervised_Consonant-Vowel_Prediction_over_Hundreds_of_Languages.html">369 acl-2013-Unsupervised Consonant-Vowel Prediction over Hundreds of Languages</a></p>
<p>20 0.50003356 <a title="114-lda-20" href="./acl-2013-Text_Classification_from_Positive_and_Unlabeled_Data_using_Misclassified_Data_Correction.html">342 acl-2013-Text Classification from Positive and Unlabeled Data using Misclassified Data Correction</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
