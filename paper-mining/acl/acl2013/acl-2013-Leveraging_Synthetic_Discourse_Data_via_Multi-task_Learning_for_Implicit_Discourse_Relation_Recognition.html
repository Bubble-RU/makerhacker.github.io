<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>229 acl-2013-Leveraging Synthetic Discourse Data via Multi-task Learning for Implicit Discourse Relation Recognition</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2013" href="../home/acl2013_home.html">acl2013</a> <a title="acl-2013-229" href="#">acl2013-229</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>229 acl-2013-Leveraging Synthetic Discourse Data via Multi-task Learning for Implicit Discourse Relation Recognition</h1>
<br/><p>Source: <a title="acl-2013-229-pdf" href="http://aclweb.org/anthology//P/P13/P13-1047.pdf">pdf</a></p><p>Author: Man Lan ; Yu Xu ; Zhengyu Niu</p><p>Abstract: To overcome the shortage of labeled data for implicit discourse relation recognition, previous works attempted to automatically generate training data by removing explicit discourse connectives from sentences and then built models on these synthetic implicit examples. However, a previous study (Sporleder and Lascarides, 2008) showed that models trained on these synthetic data do not generalize very well to natural (i.e. genuine) implicit discourse data. In this work we revisit this issue and present a multi-task learning based system which can effectively use synthetic data for implicit discourse relation recognition. Results on PDTB data show that under the multi-task learning framework our models with the use of the prediction of explicit discourse connectives as auxiliary learning tasks, can achieve an averaged F1 improvement of 5.86% over baseline models.</p><p>Reference: <a title="acl-2013-229-reference" href="../acl2013_reference/acl-2013-Leveraging_Synthetic_Discourse_Data_via_Multi-task_Learning_for_Implicit_Discourse_Relation_Recognition_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('discours', 0.596), ('synthet', 0.417), ('implicit', 0.355), ('bllip', 0.263), ('pdtb', 0.257), ('auxy', 0.191), ('imp', 0.174), ('exp', 0.112), ('sporl', 0.102), ('lascarid', 0.1), ('connect', 0.093), ('pitl', 0.087), ('ando', 0.077), ('aso', 0.076), ('explicit', 0.068), ('mtl', 0.063), ('ebxlp', 0.057), ('mxlp', 0.057), ('echihab', 0.053), ('marcu', 0.05)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999946 <a title="229-tfidf-1" href="./acl-2013-Leveraging_Synthetic_Discourse_Data_via_Multi-task_Learning_for_Implicit_Discourse_Relation_Recognition.html">229 acl-2013-Leveraging Synthetic Discourse Data via Multi-task Learning for Implicit Discourse Relation Recognition</a></p>
<p>Author: Man Lan ; Yu Xu ; Zhengyu Niu</p><p>Abstract: To overcome the shortage of labeled data for implicit discourse relation recognition, previous works attempted to automatically generate training data by removing explicit discourse connectives from sentences and then built models on these synthetic implicit examples. However, a previous study (Sporleder and Lascarides, 2008) showed that models trained on these synthetic data do not generalize very well to natural (i.e. genuine) implicit discourse data. In this work we revisit this issue and present a multi-task learning based system which can effectively use synthetic data for implicit discourse relation recognition. Results on PDTB data show that under the multi-task learning framework our models with the use of the prediction of explicit discourse connectives as auxiliary learning tasks, can achieve an averaged F1 improvement of 5.86% over baseline models.</p><p>2 0.52773917 <a title="229-tfidf-2" href="./acl-2013-Aggregated_Word_Pair_Features_for_Implicit_Discourse_Relation_Disambiguation.html">41 acl-2013-Aggregated Word Pair Features for Implicit Discourse Relation Disambiguation</a></p>
<p>Author: Or Biran ; Kathleen McKeown</p><p>Abstract: We present a reformulation of the word pair features typically used for the task of disambiguating implicit relations in the Penn Discourse Treebank. Our word pair features achieve significantly higher performance than the previous formulation when evaluated without additional features. In addition, we present results for a full system using additional features which achieves close to state of the art performance without resorting to gold syntactic parses or to context outside the relation.</p><p>3 0.3952035 <a title="229-tfidf-3" href="./acl-2013-A_Bayesian_Model_for_Joint_Unsupervised_Induction_of_Sentiment%2C_Aspect_and_Discourse_Representations.html">2 acl-2013-A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations</a></p>
<p>Author: Angeliki Lazaridou ; Ivan Titov ; Caroline Sporleder</p><p>Abstract: We propose a joint model for unsupervised induction of sentiment, aspect and discourse information and show that by incorporating a notion of latent discourse relations in the model, we improve the prediction accuracy for aspect and sentiment polarity on the sub-sentential level. We deviate from the traditional view of discourse, as we induce types of discourse relations and associated discourse cues relevant to the considered opinion analysis task; consequently, the induced discourse relations play the role of opinion and aspect shifters. The quantitative analysis that we conducted indicated that the integration of a discourse model increased the prediction accuracy results with respect to the discourse-agnostic approach and the qualitative analysis suggests that the induced representations encode a meaningful discourse structure.</p><p>4 0.36750174 <a title="229-tfidf-4" href="./acl-2013-Combining_Intra-_and_Multi-sentential_Rhetorical_Parsing_for_Document-level_Discourse_Analysis.html">85 acl-2013-Combining Intra- and Multi-sentential Rhetorical Parsing for Document-level Discourse Analysis</a></p>
<p>Author: Shafiq Joty ; Giuseppe Carenini ; Raymond Ng ; Yashar Mehdad</p><p>Abstract: We propose a novel approach for developing a two-stage document-level discourse parser. Our parser builds a discourse tree by applying an optimal parsing algorithm to probabilities inferred from two Conditional Random Fields: one for intrasentential parsing and the other for multisentential parsing. We present two approaches to combine these two stages of discourse parsing effectively. A set of empirical evaluations over two different datasets demonstrates that our discourse parser significantly outperforms the stateof-the-art, often by a wide margin.</p><p>5 0.22271797 <a title="229-tfidf-5" href="./acl-2013-ImpAr%3A_A_Deterministic_Algorithm_for_Implicit_Semantic_Role_Labelling.html">189 acl-2013-ImpAr: A Deterministic Algorithm for Implicit Semantic Role Labelling</a></p>
<p>Author: Egoitz Laparra ; German Rigau</p><p>Abstract: This paper presents a novel deterministic algorithm for implicit Semantic Role Labeling. The system exploits a very simple but relevant discursive property, the argument coherence over different instances of a predicate. The algorithm solves the implicit arguments sequentially, exploiting not only explicit but also the implicit arguments previously solved. In addition, we empirically demonstrate that the algorithm obtains very competitive and robust performances with respect to supervised approaches that require large amounts of costly training data.</p><p>6 0.18723485 <a title="229-tfidf-6" href="./acl-2013-What_causes_a_causal_relation%3F_Detecting_Causal_Triggers_in_Biomedical_Scientific_Discourse.html">386 acl-2013-What causes a causal relation? Detecting Causal Triggers in Biomedical Scientific Discourse</a></p>
<p>7 0.1325697 <a title="229-tfidf-7" href="./acl-2013-A_Novel_Translation_Framework_Based_on_Rhetorical_Structure_Theory.html">16 acl-2013-A Novel Translation Framework Based on Rhetorical Structure Theory</a></p>
<p>8 0.12971587 <a title="229-tfidf-8" href="./acl-2013-Argument_Inference_from_Relevant_Event_Mentions_in_Chinese_Argument_Extraction.html">56 acl-2013-Argument Inference from Relevant Event Mentions in Chinese Argument Extraction</a></p>
<p>9 0.079805516 <a title="229-tfidf-9" href="./acl-2013-Sentiment_Relevance.html">318 acl-2013-Sentiment Relevance</a></p>
<p>10 0.077379115 <a title="229-tfidf-10" href="./acl-2013-Recognizing_Rare_Social_Phenomena_in_Conversation%3A_Empowerment_Detection_in_Support_Group_Chatrooms.html">298 acl-2013-Recognizing Rare Social Phenomena in Conversation: Empowerment Detection in Support Group Chatrooms</a></p>
<p>11 0.076179691 <a title="229-tfidf-11" href="./acl-2013-Plurality%2C_Negation%2C_and_Quantification%3ATowards_Comprehensive_Quantifier_Scope_Disambiguation.html">280 acl-2013-Plurality, Negation, and Quantification:Towards Comprehensive Quantifier Scope Disambiguation</a></p>
<p>12 0.068051085 <a title="229-tfidf-12" href="./acl-2013-Graph-based_Local_Coherence_Modeling.html">172 acl-2013-Graph-based Local Coherence Modeling</a></p>
<p>13 0.064387679 <a title="229-tfidf-13" href="./acl-2013-Explicit_and_Implicit_Syntactic_Features_for_Text_Classification.html">144 acl-2013-Explicit and Implicit Syntactic Features for Text Classification</a></p>
<p>14 0.063930497 <a title="229-tfidf-14" href="./acl-2013-Temporal_Signals_Help_Label_Temporal_Relations.html">339 acl-2013-Temporal Signals Help Label Temporal Relations</a></p>
<p>15 0.062852927 <a title="229-tfidf-15" href="./acl-2013-Random_Walk_Factoid_Annotation_for_Collective_Discourse.html">293 acl-2013-Random Walk Factoid Annotation for Collective Discourse</a></p>
<p>16 0.058548383 <a title="229-tfidf-16" href="./acl-2013-Generating_Synthetic_Comparable_Questions_for_News_Articles.html">169 acl-2013-Generating Synthetic Comparable Questions for News Articles</a></p>
<p>17 0.05683171 <a title="229-tfidf-17" href="./acl-2013-Bi-directional_Inter-dependencies_of_Subjective_Expressions_and_Targets_and_their_Value_for_a_Joint_Model.html">67 acl-2013-Bi-directional Inter-dependencies of Subjective Expressions and Targets and their Value for a Joint Model</a></p>
<p>18 0.055050351 <a title="229-tfidf-18" href="./acl-2013-Docent%3A_A_Document-Level_Decoder_for_Phrase-Based_Statistical_Machine_Translation.html">127 acl-2013-Docent: A Document-Level Decoder for Phrase-Based Statistical Machine Translation</a></p>
<p>19 0.053156335 <a title="229-tfidf-19" href="./acl-2013-Nonconvex_Global_Optimization_for_Latent-Variable_Models.html">260 acl-2013-Nonconvex Global Optimization for Latent-Variable Models</a></p>
<p>20 0.052986354 <a title="229-tfidf-20" href="./acl-2013-A_Context_Free_TAG_Variant.html">4 acl-2013-A Context Free TAG Variant</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.135), (1, -0.076), (2, -0.074), (3, -0.015), (4, 0.102), (5, -0.014), (6, -0.041), (7, -0.101), (8, 0.012), (9, 0.238), (10, -0.115), (11, -0.054), (12, -0.272), (13, -0.078), (14, 0.033), (15, 0.185), (16, 0.27), (17, -0.051), (18, -0.038), (19, 0.241), (20, 0.0), (21, 0.073), (22, 0.011), (23, 0.111), (24, -0.207), (25, -0.13), (26, 0.025), (27, 0.131), (28, -0.008), (29, 0.034), (30, 0.107), (31, 0.064), (32, 0.067), (33, -0.001), (34, -0.041), (35, 0.272), (36, -0.181), (37, -0.0), (38, -0.043), (39, -0.038), (40, -0.057), (41, 0.058), (42, 0.048), (43, 0.067), (44, -0.052), (45, 0.001), (46, -0.05), (47, 0.065), (48, -0.008), (49, -0.007)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95848358 <a title="229-lsi-1" href="./acl-2013-Leveraging_Synthetic_Discourse_Data_via_Multi-task_Learning_for_Implicit_Discourse_Relation_Recognition.html">229 acl-2013-Leveraging Synthetic Discourse Data via Multi-task Learning for Implicit Discourse Relation Recognition</a></p>
<p>Author: Man Lan ; Yu Xu ; Zhengyu Niu</p><p>Abstract: To overcome the shortage of labeled data for implicit discourse relation recognition, previous works attempted to automatically generate training data by removing explicit discourse connectives from sentences and then built models on these synthetic implicit examples. However, a previous study (Sporleder and Lascarides, 2008) showed that models trained on these synthetic data do not generalize very well to natural (i.e. genuine) implicit discourse data. In this work we revisit this issue and present a multi-task learning based system which can effectively use synthetic data for implicit discourse relation recognition. Results on PDTB data show that under the multi-task learning framework our models with the use of the prediction of explicit discourse connectives as auxiliary learning tasks, can achieve an averaged F1 improvement of 5.86% over baseline models.</p><p>2 0.77594823 <a title="229-lsi-2" href="./acl-2013-Aggregated_Word_Pair_Features_for_Implicit_Discourse_Relation_Disambiguation.html">41 acl-2013-Aggregated Word Pair Features for Implicit Discourse Relation Disambiguation</a></p>
<p>Author: Or Biran ; Kathleen McKeown</p><p>Abstract: We present a reformulation of the word pair features typically used for the task of disambiguating implicit relations in the Penn Discourse Treebank. Our word pair features achieve significantly higher performance than the previous formulation when evaluated without additional features. In addition, we present results for a full system using additional features which achieves close to state of the art performance without resorting to gold syntactic parses or to context outside the relation.</p><p>3 0.72780031 <a title="229-lsi-3" href="./acl-2013-Combining_Intra-_and_Multi-sentential_Rhetorical_Parsing_for_Document-level_Discourse_Analysis.html">85 acl-2013-Combining Intra- and Multi-sentential Rhetorical Parsing for Document-level Discourse Analysis</a></p>
<p>Author: Shafiq Joty ; Giuseppe Carenini ; Raymond Ng ; Yashar Mehdad</p><p>Abstract: We propose a novel approach for developing a two-stage document-level discourse parser. Our parser builds a discourse tree by applying an optimal parsing algorithm to probabilities inferred from two Conditional Random Fields: one for intrasentential parsing and the other for multisentential parsing. We present two approaches to combine these two stages of discourse parsing effectively. A set of empirical evaluations over two different datasets demonstrates that our discourse parser significantly outperforms the stateof-the-art, often by a wide margin.</p><p>4 0.6736328 <a title="229-lsi-4" href="./acl-2013-A_Bayesian_Model_for_Joint_Unsupervised_Induction_of_Sentiment%2C_Aspect_and_Discourse_Representations.html">2 acl-2013-A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations</a></p>
<p>Author: Angeliki Lazaridou ; Ivan Titov ; Caroline Sporleder</p><p>Abstract: We propose a joint model for unsupervised induction of sentiment, aspect and discourse information and show that by incorporating a notion of latent discourse relations in the model, we improve the prediction accuracy for aspect and sentiment polarity on the sub-sentential level. We deviate from the traditional view of discourse, as we induce types of discourse relations and associated discourse cues relevant to the considered opinion analysis task; consequently, the induced discourse relations play the role of opinion and aspect shifters. The quantitative analysis that we conducted indicated that the integration of a discourse model increased the prediction accuracy results with respect to the discourse-agnostic approach and the qualitative analysis suggests that the induced representations encode a meaningful discourse structure.</p><p>5 0.47932959 <a title="229-lsi-5" href="./acl-2013-What_causes_a_causal_relation%3F_Detecting_Causal_Triggers_in_Biomedical_Scientific_Discourse.html">386 acl-2013-What causes a causal relation? Detecting Causal Triggers in Biomedical Scientific Discourse</a></p>
<p>Author: Claudiu Mihaila ; Sophia Ananiadou</p><p>Abstract: Current domain-specific information extraction systems represent an important resource for biomedical researchers, who need to process vaster amounts of knowledge in short times. Automatic discourse causality recognition can further improve their workload by suggesting possible causal connections and aiding in the curation of pathway models. We here describe an approach to the automatic identification of discourse causality triggers in the biomedical domain using machine learning. We create several baselines and experiment with various parameter settings for three algorithms, i.e., Conditional Random Fields (CRF), Support Vector Machines (SVM) and Random Forests (RF). Also, we evaluate the impact of lexical, syntactic and semantic features on each of the algorithms and look at er- rors. The best performance of 79.35% F-score is achieved by CRFs when using all three feature types.</p><p>6 0.41647708 <a title="229-lsi-6" href="./acl-2013-Random_Walk_Factoid_Annotation_for_Collective_Discourse.html">293 acl-2013-Random Walk Factoid Annotation for Collective Discourse</a></p>
<p>7 0.38145414 <a title="229-lsi-7" href="./acl-2013-ImpAr%3A_A_Deterministic_Algorithm_for_Implicit_Semantic_Role_Labelling.html">189 acl-2013-ImpAr: A Deterministic Algorithm for Implicit Semantic Role Labelling</a></p>
<p>8 0.36196986 <a title="229-lsi-8" href="./acl-2013-A_Novel_Translation_Framework_Based_on_Rhetorical_Structure_Theory.html">16 acl-2013-A Novel Translation Framework Based on Rhetorical Structure Theory</a></p>
<p>9 0.35603929 <a title="229-lsi-9" href="./acl-2013-Recognizing_Rare_Social_Phenomena_in_Conversation%3A_Empowerment_Detection_in_Support_Group_Chatrooms.html">298 acl-2013-Recognizing Rare Social Phenomena in Conversation: Empowerment Detection in Support Group Chatrooms</a></p>
<p>10 0.29351372 <a title="229-lsi-10" href="./acl-2013-Plurality%2C_Negation%2C_and_Quantification%3ATowards_Comprehensive_Quantifier_Scope_Disambiguation.html">280 acl-2013-Plurality, Negation, and Quantification:Towards Comprehensive Quantifier Scope Disambiguation</a></p>
<p>11 0.27916855 <a title="229-lsi-11" href="./acl-2013-Graph-based_Local_Coherence_Modeling.html">172 acl-2013-Graph-based Local Coherence Modeling</a></p>
<p>12 0.27518776 <a title="229-lsi-12" href="./acl-2013-A_Statistical_NLG_Framework_for_Aggregated_Planning_and_Realization.html">21 acl-2013-A Statistical NLG Framework for Aggregated Planning and Realization</a></p>
<p>13 0.26515973 <a title="229-lsi-13" href="./acl-2013-Sentiment_Relevance.html">318 acl-2013-Sentiment Relevance</a></p>
<p>14 0.25448447 <a title="229-lsi-14" href="./acl-2013-Learning_to_Order_Natural_Language_Texts.html">225 acl-2013-Learning to Order Natural Language Texts</a></p>
<p>15 0.24952812 <a title="229-lsi-15" href="./acl-2013-Argument_Inference_from_Relevant_Event_Mentions_in_Chinese_Argument_Extraction.html">56 acl-2013-Argument Inference from Relevant Event Mentions in Chinese Argument Extraction</a></p>
<p>16 0.23632118 <a title="229-lsi-16" href="./acl-2013-BRAINSUP%3A_Brainstorming_Support_for_Creative_Sentence_Generation.html">65 acl-2013-BRAINSUP: Brainstorming Support for Creative Sentence Generation</a></p>
<p>17 0.23312818 <a title="229-lsi-17" href="./acl-2013-Why-Question_Answering_using_Intra-_and_Inter-Sentential_Causal_Relations.html">387 acl-2013-Why-Question Answering using Intra- and Inter-Sentential Causal Relations</a></p>
<p>18 0.22972396 <a title="229-lsi-18" href="./acl-2013-Universal_Conceptual_Cognitive_Annotation_%28UCCA%29.html">367 acl-2013-Universal Conceptual Cognitive Annotation (UCCA)</a></p>
<p>19 0.22799206 <a title="229-lsi-19" href="./acl-2013-Using_Integer_Linear_Programming_in_Concept-to-Text_Generation_to_Produce_More_Compact_Texts.html">375 acl-2013-Using Integer Linear Programming in Concept-to-Text Generation to Produce More Compact Texts</a></p>
<p>20 0.22665533 <a title="229-lsi-20" href="./acl-2013-A_System_for_Summarizing_Scientific_Topics_Starting_from_Keywords.html">23 acl-2013-A System for Summarizing Scientific Topics Starting from Keywords</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.163), (8, 0.086), (41, 0.035), (44, 0.023), (53, 0.255), (55, 0.127), (76, 0.02), (86, 0.01), (87, 0.084), (90, 0.017), (95, 0.053)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.85762483 <a title="229-lda-1" href="./acl-2013-Joint_Apposition_Extraction_with_Syntactic_and_Semantic_Constraints.html">205 acl-2013-Joint Apposition Extraction with Syntactic and Semantic Constraints</a></p>
<p>Author: Will Radford ; James R. Curran</p><p>Abstract: Appositions are adjacent NPs used to add information to a discourse. We propose systems exploiting syntactic and semantic constraints to extract appositions from OntoNotes. Our joint log-linear model outperforms the state-of-the-art Favre and Hakkani-T u¨r (2009) model by ∼10% on HBarokakdacnais-tT News, a9n)d m aocdheielv beys ∼541.03%% oFnscore on multiple genres.</p><p>2 0.85500294 <a title="229-lda-2" href="./acl-2013-Extending_an_interoperable_platform_to_facilitate_the_creation_of_multilingual_and_multimodal_NLP_applications.html">150 acl-2013-Extending an interoperable platform to facilitate the creation of multilingual and multimodal NLP applications</a></p>
<p>Author: Georgios Kontonatsios ; Paul Thompson ; Riza Theresa Batista-Navarro ; Claudiu Mihaila ; Ioannis Korkontzelos ; Sophia Ananiadou</p><p>Abstract: U-Compare is a UIMA-based workflow construction platform for building natural language processing (NLP) applications from heterogeneous language resources (LRs), without the need for programming skills. U-Compare has been adopted within the context of the METANET Network of Excellence, and over 40 LRs that process 15 European languages have been added to the U-Compare component library. In line with METANET’s aims of increasing communication between citizens of different European countries, U-Compare has been extended to facilitate the development of a wider range of applications, including both mul- tilingual and multimodal workflows. The enhancements exploit the UIMA Subject of Analysis (Sofa) mechanism, that allows different facets of the input data to be represented. We demonstrate how our customised extensions to U-Compare allow the construction and testing of NLP applications that transform the input data in different ways, e.g., machine translation, automatic summarisation and text-to-speech.</p><p>same-paper 3 0.85111266 <a title="229-lda-3" href="./acl-2013-Leveraging_Synthetic_Discourse_Data_via_Multi-task_Learning_for_Implicit_Discourse_Relation_Recognition.html">229 acl-2013-Leveraging Synthetic Discourse Data via Multi-task Learning for Implicit Discourse Relation Recognition</a></p>
<p>Author: Man Lan ; Yu Xu ; Zhengyu Niu</p><p>Abstract: To overcome the shortage of labeled data for implicit discourse relation recognition, previous works attempted to automatically generate training data by removing explicit discourse connectives from sentences and then built models on these synthetic implicit examples. However, a previous study (Sporleder and Lascarides, 2008) showed that models trained on these synthetic data do not generalize very well to natural (i.e. genuine) implicit discourse data. In this work we revisit this issue and present a multi-task learning based system which can effectively use synthetic data for implicit discourse relation recognition. Results on PDTB data show that under the multi-task learning framework our models with the use of the prediction of explicit discourse connectives as auxiliary learning tasks, can achieve an averaged F1 improvement of 5.86% over baseline models.</p><p>4 0.84352762 <a title="229-lda-4" href="./acl-2013-FrameNet_on_the_Way_to_Babel%3A_Creating_a_Bilingual_FrameNet_Using_Wiktionary_as_Interlingual_Connection.html">162 acl-2013-FrameNet on the Way to Babel: Creating a Bilingual FrameNet Using Wiktionary as Interlingual Connection</a></p>
<p>Author: Silvana Hartmann ; Iryna Gurevych</p><p>Abstract: We present a new bilingual FrameNet lexicon for English and German. It is created through a simple, but powerful approach to construct a FrameNet in any language using Wiktionary as an interlingual representation. Our approach is based on a sense alignment of FrameNet and Wiktionary, and subsequent translation disambiguation into the target language. We perform a detailed evaluation of the created resource and a discussion of Wiktionary as an interlingual connection for the cross-language transfer of lexicalsemantic resources. The created resource is publicly available at http : / /www . ukp .tu-darmst adt .de / fnwkde / .</p><p>5 0.84315419 <a title="229-lda-5" href="./acl-2013-PAL%3A_A_Chatterbot_System_for_Answering_Domain-specific_Questions.html">266 acl-2013-PAL: A Chatterbot System for Answering Domain-specific Questions</a></p>
<p>Author: Yuanchao Liu ; Ming Liu ; Xiaolong Wang ; Limin Wang ; Jingjing Li</p><p>Abstract: In this paper, we propose PAL, a prototype chatterbot for answering non-obstructive psychological domain-specific questions. This system focuses on providing primary suggestions or helping people relieve pressure by extracting knowledge from online forums, based on which the chatterbot system is constructed. The strategies used by PAL, including semantic-extension-based question matching, solution management with personal information consideration, and XML-based knowledge pattern construction, are described and discussed. We also conduct a primary test for the feasibility of our system.</p><p>6 0.83589214 <a title="229-lda-6" href="./acl-2013-Feature-Based_Selection_of_Dependency_Paths_in_Ad_Hoc_Information_Retrieval.html">158 acl-2013-Feature-Based Selection of Dependency Paths in Ad Hoc Information Retrieval</a></p>
<p>7 0.83358735 <a title="229-lda-7" href="./acl-2013-Part-of-Speech_Induction_in_Dependency_Trees_for_Statistical_Machine_Translation.html">276 acl-2013-Part-of-Speech Induction in Dependency Trees for Statistical Machine Translation</a></p>
<p>8 0.8330189 <a title="229-lda-8" href="./acl-2013-Aggregated_Word_Pair_Features_for_Implicit_Discourse_Relation_Disambiguation.html">41 acl-2013-Aggregated Word Pair Features for Implicit Discourse Relation Disambiguation</a></p>
<p>9 0.83258927 <a title="229-lda-9" href="./acl-2013-A_Tightly-coupled_Unsupervised_Clustering_and_Bilingual_Alignment_Model_for_Transliteration.html">25 acl-2013-A Tightly-coupled Unsupervised Clustering and Bilingual Alignment Model for Transliteration</a></p>
<p>10 0.82648242 <a title="229-lda-10" href="./acl-2013-Improving_Chinese_Word_Segmentation_on_Micro-blog_Using_Rich_Punctuations.html">193 acl-2013-Improving Chinese Word Segmentation on Micro-blog Using Rich Punctuations</a></p>
<p>11 0.81738311 <a title="229-lda-11" href="./acl-2013-Development_and_Analysis_of_NLP_Pipelines_in_Argo.html">118 acl-2013-Development and Analysis of NLP Pipelines in Argo</a></p>
<p>12 0.81505007 <a title="229-lda-12" href="./acl-2013-Semantic_Roles_for_String_to_Tree_Machine_Translation.html">314 acl-2013-Semantic Roles for String to Tree Machine Translation</a></p>
<p>13 0.80827731 <a title="229-lda-13" href="./acl-2013-Explicit_and_Implicit_Syntactic_Features_for_Text_Classification.html">144 acl-2013-Explicit and Implicit Syntactic Features for Text Classification</a></p>
<p>14 0.8077538 <a title="229-lda-14" href="./acl-2013-Is_a_204_cm_Man_Tall_or_Small_%3F_Acquisition_of_Numerical_Common_Sense_from_the_Web.html">202 acl-2013-Is a 204 cm Man Tall or Small ? Acquisition of Numerical Common Sense from the Web</a></p>
<p>15 0.80718106 <a title="229-lda-15" href="./acl-2013-Multilingual_Affect_Polarity_and_Valence_Prediction_in_Metaphor-Rich_Texts.html">253 acl-2013-Multilingual Affect Polarity and Valence Prediction in Metaphor-Rich Texts</a></p>
<p>16 0.80617148 <a title="229-lda-16" href="./acl-2013-A_user-centric_model_of_voting_intention_from_Social_Media.html">33 acl-2013-A user-centric model of voting intention from Social Media</a></p>
<p>17 0.80569863 <a title="229-lda-17" href="./acl-2013-An_improved_MDL-based_compression_algorithm_for_unsupervised_word_segmentation.html">50 acl-2013-An improved MDL-based compression algorithm for unsupervised word segmentation</a></p>
<p>18 0.80493814 <a title="229-lda-18" href="./acl-2013-Dual_Training_and_Dual_Prediction_for_Polarity_Classification.html">131 acl-2013-Dual Training and Dual Prediction for Polarity Classification</a></p>
<p>19 0.80473566 <a title="229-lda-19" href="./acl-2013-ImpAr%3A_A_Deterministic_Algorithm_for_Implicit_Semantic_Role_Labelling.html">189 acl-2013-ImpAr: A Deterministic Algorithm for Implicit Semantic Role Labelling</a></p>
<p>20 0.80433387 <a title="229-lda-20" href="./acl-2013-Universal_Conceptual_Cognitive_Annotation_%28UCCA%29.html">367 acl-2013-Universal Conceptual Cognitive Annotation (UCCA)</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
