<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>335 acl-2011-Why Initialization Matters for IBM Model 1: Multiple Optima and Non-Strict Convexity</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-335" href="../acl2011/acl-2011-Why_Initialization_Matters_for_IBM_Model_1%3A_Multiple_Optima_and_Non-Strict_Convexity.html">acl2011-335</a> <a title="acl-2011-335-reference" href="#">acl2011-335-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>335 acl-2011-Why Initialization Matters for IBM Model 1: Multiple Optima and Non-Strict Convexity</h1>
<br/><p>Source: <a title="acl-2011-335-pdf" href="http://aclweb.org/anthology//P/P11/P11-2081.pdf">pdf</a></p><p>Author: Kristina Toutanova ; Michel Galley</p><p>Abstract: Contrary to popular belief, we show that the optimal parameters for IBM Model 1 are not unique. We demonstrate that, for a large class of words, IBM Model 1 is indifferent among a continuum of ways to allocate probability mass to their translations. We study the magnitude of the variance in optimal model parameters using a linear programming approach as well as multiple random trials, and demonstrate that it results in variance in test set log-likelihood and alignment error rate.</p><br/>
<h2>reference text</h2><p>Taylor Berg-Kirkpatrick, Alexandre Bouchard-C oˆt´ e, John DeNero, and Dan Klein. 2010. Painless unsupervised learning with features. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics. Association for Computational Linguistics. Adam Berger and John Lafferty. 1999. Information retrieval as statistical translation. In Proceedings of the 1999 ACM SIGIR Conference on Research and Development in Information Retrieval. Stephen Boyd and Lieven Vandenberghe. 2004. Convex Optimization. Cambridge University Press. Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della Pietra, and Robert. L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estima-  tion. Computational Linguistics, 19:263–31 1. Chris Callison-Burch, Philipp Koehn, Christof Monz, Kay Peterson, and Omar Zaidan, editors. 2010. Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR. A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977. Maximum likelihood from incomplete data via the em algorithm. Journal of the royal statistical society, series B, 39(1). Pinar Duygulu, Kobus Barnard, Nando de Freitas, P. Duygulu, K. Barnard, and David Forsyth. 2002. Object recognition as machine translation: Learning a lexicon for a fixed image vocabulary. In Proceedings of ECCV. Volker Kaibel, Marc E. Pfetsch, and TU Berlin. 2002. Some algorithmic problems in polytope theory. In Dagstuhl Seminars, pages 23–47. N. Karmarkar. 1984. A new polynomial-time algorithm for linear programming. Combinatorica, 4:373–395, December. Franz Josef Och and Hermann Ney. 2000. Improved statistical alignment models. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics. Ralf Steinberger, Bruno Pouliquen, Anna Widiger, Camelia Ignat, Tomaz Erjavec, and Dan Tufis. 2006. The JRC-acquis: A multilingual aligned parallel corpus with 20+ languages. In Proceedings of the 5th  International Conference on Language Resources and Evaluation (LREC). Stephan Vogel, Hermann Ney, and Christoph Tillmann. 1996. HMM-based word alignment in statistical translation. In Proceedings of the 16th Int. Conf. on Computational Linguistics (COLING). Association for Computational Linguistics. 466 Appendix A: Convex functions and convex optimization problems We denote the domain of a function f by dom f. Definition A function f : Rn → R is convex if and only if dom f is a convex set and →for Rall i x, y v∈e dx oifm an df annldy iθf ≥ d o0m, mθ f≤ 1s: a f(θx + (1 − θ)y) θf(x) + (1 − θ)f(y) (6) Definition A function f is strictly convex iff dom f is a convex set and for all x y ∈ dom f and θ > 0, θ < 1: f(θx + (1 − θ)y) < θf(x) + (1 − θ)f(y) (7) Definition A convex optimization problem is defined by:  ≤  =  min f0 (x) subject to fi(x)  ...  ≤ 0, i= 1  k  ajTx = bj,j = 1...l Where the functions f0 to fk are convex and the equality constraints are affine.  It can be shown that the that satisfy the constraints) optimum for the problem is strictly convex then any global optimum.  feasible set (the set of points is convex and that any local is a global optimum. If f0 local optimum is the unique</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
