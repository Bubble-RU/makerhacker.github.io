<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>204 acl-2011-Learning Word Vectors for Sentiment Analysis</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-204" href="../acl2011/acl-2011-Learning_Word_Vectors_for_Sentiment_Analysis.html">acl2011-204</a> <a title="acl-2011-204-reference" href="#">acl2011-204-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>204 acl-2011-Learning Word Vectors for Sentiment Analysis</h1>
<br/><p>Source: <a title="acl-2011-204-pdf" href="http://aclweb.org/anthology//P/P11/P11-1015.pdf">pdf</a></p><p>Author: Andrew L. Maas ; Raymond E. Daly ; Peter T. Pham ; Dan Huang ; Andrew Y. Ng ; Christopher Potts</p><p>Abstract: Unsupervised vector-based approaches to semantics can model rich lexical meanings, but they largely fail to capture sentiment information that is central to many word meanings and important for a wide range of NLP tasks. We present a model that uses a mix of unsupervised and supervised techniques to learn word vectors capturing semanticterm–documentinformation as well as rich sentiment content. The proposed model can leverage both continuous and multi-dimensional sentiment information as well as non-sentiment annotations. We instantiate the model to utilize the document-level sentiment polarity annotations present in many online documents (e.g. star ratings). We evaluate the model using small, widely used sentiment and subjectivity corpora and find it out-performs several previously introduced methods for sentiment classification. We also introduce a large dataset , of movie reviews to serve as a more robust benchmark for work in this area.</p><br/>
<h2>reference text</h2><p>C. O. Alm, D. Roth, and R. Sproat. 2005. Emotions from text: machine learning for text-based emotion prediction. In Proceedings of HLT/EMNLP, pages 579–586. A. Andreevskaia and S. Bergler. 2006. Mining Word-  Net for fuzzy sentiment: sentiment tag extraction from WordNet glosses. In Proceedings of the European ACL, pages 209–216. Y. Bengio, R. Ducharme, P. Vincent, and C. Jauvin. 2003. a neural probabilistic language model. Journal of Machine Learning Research, 3: 1137–1 155, August. D. M. Blei, A. Y. Ng, and M. I. Jordan. 2003. Latent dirichlet allocation. Journal of Machine Learning Research, 3:993–1022, May. J. Boyd-Graber and P. Resnik. 2010. Holistic sentiment analysis across languages: multilingual supervised latent Dirichlet allocation. In Proceedings of EMNLP, pages 45–55. R. Collobert and J. Weston. 2008. A unified architecture for natural language processing. In Proceedings of the ICML, pages 160–167. S. Deerwester, S. T. Dumais, G. W. Furnas, T. K. Landauer, and R. Harshman. 1990. Indexing by latent semantic analysis. Journal of the American Society for Information Science, 41:391–407, September. R. E. Fan, K. W. Chang, C. J. Hsieh, X. R. Wang, and C. J. Lin. 2008. LIBLINEAR: A library for large linear classification. The Journal of Machine Learning Research, 9: 187 1–1874, August. J. R. Finkel and C. D. Manning. 2009. Joint parsing and named entity recognition. In Proceedings of NAACL, pages 326–334.  A. B. Goldberg and J. Zhu. 2006. Seeing stars when there aren’t many stars: graph-based semi-supervised learning for sentiment categorization. In TextGraphs: HLT/NAACL Workshop on Graph-based Algorithms for Natural Language Processing, pages 45–52. T. Jay. 2000. Why We Curse: A Neuro-PsychoF. Li, M. Huang, and X. Zhu. 2010. Sentiment analysis with global topics and local dependency. In Proceedings of AAAI, pages 137 1–1376. C. Lin and Y. He. 2009. Joint sentiment/topic model for sentiment analysis. In Proceeding of the 18th ACM Conference on Information and Knowledge Management, pages 375–384. J. Martineau and T. Finin. 2009. Delta tfidf: an improved feature space for sentiment analysis. In Proceedings of the 3rd AAAI International Conference on Weblogs and Social Media, pages 258–261 . A. Mnih and G. E. Hinton. 2007. Three new graphical models for statistical language modelling. In Proceedings of the ICML, pages 641–648. G. Paltoglou and M. Thelwall. 2010. A study ofinformation retrieval weighting schemes for sentiment analysis. In Proceedings of the ACL, pages 1386–1395. B. Pang and L. Lee. 2004. A sentimental education: sentiment analysis using subjectivity summarization based on minimum cuts. In Proceedings of the ACL, pages 271–278.  B. Pang and L. Lee. 2005. Seeing stars: exploiting class relationships for sentiment categorization with respect to rating scales. In Proceedings of ACL, pages 115– 124. B. Pang, L. Lee, and S. Vaithyanathan. 2002. Thumbs up? sentiment classification using machine learning techniques. In Proceedings of EMNLP, pages 79–86. C. Potts. 2007. The expressive dimension. Theoretical Linguistics, 33: 165–197. B. Snyder and R. Barzilay. 2007. Multiple aspect ranking using the good grief algorithm. In Proceedings of NAACL, pages 300–307. M. Steyvers and T. L. Griffiths. 2006. Probabilistic topic models. In T. Landauer, D McNamara, S. Dennis, and W. Kintsch, editors, Latent SemanticAnalysis: A Road to Meaning. J. Turian, L. Ratinov, and Y. Bengio. 2010. Word representations: A simple and general method for semisupervised learning. In Proceedings of the ACL, page 384394. P. D. Turney and P. Pantel. 2010. From frequency to meaning: vector space models of semantics. Journal of Artificial Intelligence Research, 37: 141–188. H. Wallach, D. Mimno, and A. McCallum. 2009. Re-  DA..pStMKhoKsaeicep/.lr,aAnylnUnmoTe.fhsC1ted9yMLorAde9yaa..nnmdoWD.ifn.SghIpnatkepseicnUh.m.se Ja.onBhi regB?feEvnexjrpasmliornast—i,oPnhdsirlanfdteh1l-. CT.t.pWNWohrIifainCPslSskIitoaeK,nnlpMag,wJ,r.Lpo,eDWauNspgAi1e.sGs:9bf7oew6ar,32gh–as5,y1ne–apdn963t8rdRi11mo.S.HreswnAam.tragntaemlryo.2004.2sniI. 0IPnro5Pc.reJustoUcsdein dhowgisanpog-fsmad 2006. Sentiment clas-  s Mihfiaicfytae.triso.n ofCo mmopvuieta rteiovnieawls In utseilnligge cnocnet,ex 2t2u:a1l1 v0a–le1n2c5e1,50  aPrreo cyeoeud?in Fginsod ifn AgA stAroI,n pga agneds 7 w6e1a–k76 o9p.inion clauses. In</p>
<br/>
<br/><br/><br/></body>
</html>
