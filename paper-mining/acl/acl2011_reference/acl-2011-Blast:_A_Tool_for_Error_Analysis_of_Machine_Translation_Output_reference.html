<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>62 acl-2011-Blast: A Tool for Error Analysis of Machine Translation Output</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-62" href="../acl2011/acl-2011-Blast%3A_A_Tool_for_Error_Analysis_of_Machine_Translation_Output.html">acl2011-62</a> <a title="acl-2011-62-reference" href="#">acl2011-62-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>62 acl-2011-Blast: A Tool for Error Analysis of Machine Translation Output</h1>
<br/><p>Source: <a title="acl-2011-62-pdf" href="http://aclweb.org/anthology//P/P11/P11-4010.pdf">pdf</a></p><p>Author: Sara Stymne</p><p>Abstract: We present BLAST, an open source tool for error analysis of machine translation (MT) output. We believe that error analysis, i.e., to identify and classify MT errors, should be an integral part ofMT development, since it gives a qualitative view, which is not obtained by standard evaluation methods. BLAST can aid MT researchers and users in this process, by providing an easy-to-use graphical user interface. It is designed to be flexible, and can be used with any MT system, language pair, and error typology. The annotation task can be aided by highlighting similarities with a reference translation.</p><br/>
<h2>reference text</h2><p>Lars Ahrenberg, Magnus Merkel, and Michael Petterstedt. 2003. Interactive word alignment for language engineering. In Proceedings of EACL, pages 49–52, Budapest, Hungary. Colin Bannard and Chris Callison-Burch. 2005. Para-  phrasing with bilingual parallel corpora. In Proceedings of ACL, pages 597–604, Ann Arbor, Michigan, USA. Chris Callison-Burch, Cameron Fordyce, Philipp Koehn, Christof Monz, and Josh Schroeder. 2007. (Meta-) evaluation of machine translation. In Proceedings of WMT, pages 136–158, Prague, Czech Republic, June. Michael Denkowski and Alon Lavie. 2010. METEORNEXT and the METEOR paraphrase tables: Improved evaluation support for five target languages. In Proceedings of WMT and MetricsMATR, pages 339–342, Uppsala, Sweden. Mireia Farr u´s, Marta R. Costa-juss a`, Jos e´ B. Mari n˜o, and Jos e´ A. R. Fonollosa. 2010. Linguistic-based evaluation criteria to identify statistical machine translation errors. In Proceedings of EAMT, pages 52–57, Saint Rapha ¨el, France. 61 Mary Flanagan. 1994. Error classification for MT evaluation. In Proceedings of AMTA, pages 65–72, Columbia, Maryland, USA. Ariadna Font Llitj ´os and Jaime Carbonell. 2004. The translation correction tool: English-Spanish user studies. In Proceedings of LREC, pages 347–350, Lisbon, Portugal. Meghan Lammie Glenn, Stephanie Strassel, Lauren  Friedman, and Haejoong Lee. 2008. Management of large annotation projects involving multiple human judges: a case study of GALE machine translation post-editing. In Proceedings of LREC, pages 2957– 2960, Marrakech, Morocco. Eduard Hovy, Margaret King, and Andrei Popescu-Belis. 2002. Principles of context-based machine translation evaluation. Machine Translation, 17(1):43–75. Masaki Murata, Kiyotaka Uchimoto, Qing Ma, Toshiyuki Kanamaru, and Hitoshi Isahara. 2005. Analysis of machine translation systems’ errors in tense, aspect, and modality. In Proceedings of PACLIC 19, pages 155–166, Taipei, Taiwan. Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: A method for automatic evaluation of machine translation. In Proceedings of ACL, pages 311–318, Philadelphia, Pennsylvania, USA. Maja Popovi´ c, Adri a` de Gisper, Deepa Gupta, Patrik Lambert, Hermann Ney, Jos e´ Mari n˜o, and Rafael Banchs. 2006. Morpho-syntactic information for automatic error analysis of statistical machine translation output. In Proceedings of WMT, pages 1–6, New York City, New York, USA. Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John Makhoul. 2006. A study of translation edit rate with targeted human notation. In Proceedings of AMTA, pages 223–23 1, Cambridge,  Massachusetts, USA. Sara Stymne and Lars Ahrenberg. 2010. Using a grammar checker for evaluation and postprocessing of statistical machine translation. In Proceedings of LREC, pages 2175–2181, Valetta, Malta. David Vilar, Jia Xu, Luis Fernando D’Haro, and Hermann Ney. 2006. Error analysis of machine translation output. In Proceedings of LREC, pages 697–702, Genoa, Italy.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
