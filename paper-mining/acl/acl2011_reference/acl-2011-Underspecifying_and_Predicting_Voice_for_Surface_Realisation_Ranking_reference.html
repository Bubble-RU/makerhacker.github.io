<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>317 acl-2011-Underspecifying and Predicting Voice for Surface Realisation Ranking</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2011" href="../home/acl2011_home.html">acl2011</a> <a title="acl-2011-317" href="../acl2011/acl-2011-Underspecifying_and_Predicting_Voice_for_Surface_Realisation_Ranking.html">acl2011-317</a> <a title="acl-2011-317-reference" href="#">acl2011-317-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>317 acl-2011-Underspecifying and Predicting Voice for Surface Realisation Ranking</h1>
<br/><p>Source: <a title="acl-2011-317-pdf" href="http://aclweb.org/anthology//P/P11/P11-1101.pdf">pdf</a></p><p>Author: Sina Zarriess ; Aoife Cahill ; Jonas Kuhn</p><p>Abstract: This paper addresses a data-driven surface realisation model based on a large-scale reversible grammar of German. We investigate the relationship between the surface realisation performance and the character of the input to generation, i.e. its degree of underspecification. We extend a syntactic surface realisation system, which can be trained to choose among word order variants, such that the candidate set includes active and passive variants. This allows us to study the interaction of voice and word order alternations in realistic German corpus data. We show that with an appropriately underspecified input, a linguistically informed realisation model trained to regenerate strings from the underlying semantic representation achieves 91.5% accuracy (over a baseline of 82.5%) in the prediction of the original voice. 1</p><br/>
<h2>reference text</h2><br/>
<br/><br/><br/></body>
</html>
