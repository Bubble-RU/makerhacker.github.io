<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>56 nips-2009-Conditional Neural Fields</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-56" href="#">nips2009-56</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>56 nips-2009-Conditional Neural Fields</h1>
<br/><p>Source: <a title="nips-2009-56-pdf" href="http://papers.nips.cc/paper/3869-conditional-neural-fields.pdf">pdf</a></p><p>Author: Jian Peng, Liefeng Bo, Jinbo Xu</p><p>Abstract: Conditional random ﬁelds (CRF) are widely used for sequence labeling such as natural language processing and biological sequence analysis. Most CRF models use a linear potential function to represent the relationship between input features and output. However, in many real-world applications such as protein structure prediction and handwriting recognition, the relationship between input features and output is highly complex and nonlinear, which cannot be accurately modeled by a linear function. To model the nonlinear relationship between input and output we propose a new conditional probabilistic graphical model, Conditional Neural Fields (CNF), for sequence labeling. CNF extends CRF by adding one (or possibly more) middle layer between input and output. The middle layer consists of a number of gate functions, each acting as a local neuron or feature extractor to capture the nonlinear relationship between input and output. Therefore, conceptually CNF is much more expressive than CRF. Experiments on two widely-used benchmarks indicate that CNF performs signiﬁcantly better than a number of popular methods. In particular, CNF is the best among approximately 10 machine learning methods for protein secondary structure prediction and also among a few of the best methods for handwriting recognition.</p><p>Reference: <a title="nips-2009-56-reference" href="../nips2009_reference/nips-2009-Conditional_Neural_Fields_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('cnf', 0.875), ('crf', 0.259), ('protein', 0.208), ('gat', 0.078), ('lbfgs', 0.071), ('mmmn', 0.071), ('yassp', 0.071), ('yt', 0.063), ('lay', 0.062), ('chicago', 0.06), ('sequ', 0.06), ('output', 0.057), ('psipr', 0.056), ('hmm', 0.055), ('hid', 0.05), ('hyperparamet', 0.048), ('field', 0.048), ('ss', 0.047), ('handwrit', 0.047), ('network', 0.043)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="56-tfidf-1" href="./nips-2009-Conditional_Neural_Fields.html">56 nips-2009-Conditional Neural Fields</a></p>
<p>2 0.094751433 <a title="56-tfidf-2" href="./nips-2009-Conditional_Random_Fields_with_High-Order_Features_for_Sequence_Labeling.html">57 nips-2009-Conditional Random Fields with High-Order Features for Sequence Labeling</a></p>
<p>3 0.056564774 <a title="56-tfidf-3" href="./nips-2009-Periodic_Step_Size_Adaptation_for_Single_Pass_On-line_Learning.html">189 nips-2009-Periodic Step Size Adaptation for Single Pass On-line Learning</a></p>
<p>4 0.055128727 <a title="56-tfidf-4" href="./nips-2009-Free_energy_score_space.html">97 nips-2009-Free energy score space</a></p>
<p>5 0.052215453 <a title="56-tfidf-5" href="./nips-2009-Distribution_Matching_for_Transduction.html">72 nips-2009-Distribution Matching for Transduction</a></p>
<p>6 0.05209722 <a title="56-tfidf-6" href="./nips-2009-Evaluating_multi-class_learning_strategies_in_a_generative_hierarchical_framework_for_object_detection.html">84 nips-2009-Evaluating multi-class learning strategies in a generative hierarchical framework for object detection</a></p>
<p>7 0.051289767 <a title="56-tfidf-7" href="./nips-2009-Training_Factor_Graphs_with_Reinforcement_Learning_for_Efficient_MAP_Inference.html">250 nips-2009-Training Factor Graphs with Reinforcement Learning for Efficient MAP Inference</a></p>
<p>8 0.04692553 <a title="56-tfidf-8" href="./nips-2009-A_Rate_Distortion_Approach_for_Semi-Supervised_Conditional_Random_Fields.html">15 nips-2009-A Rate Distortion Approach for Semi-Supervised Conditional Random Fields</a></p>
<p>9 0.046880372 <a title="56-tfidf-9" href="./nips-2009-3D_Object_Recognition_with_Deep_Belief_Nets.html">2 nips-2009-3D Object Recognition with Deep Belief Nets</a></p>
<p>10 0.046617288 <a title="56-tfidf-10" href="./nips-2009-Measuring_Invariances_in_Deep_Networks.html">151 nips-2009-Measuring Invariances in Deep Networks</a></p>
<p>11 0.044918697 <a title="56-tfidf-11" href="./nips-2009-Sharing_Features_among_Dynamical_Systems_with_Beta_Processes.html">217 nips-2009-Sharing Features among Dynamical Systems with Beta Processes</a></p>
<p>12 0.043841962 <a title="56-tfidf-12" href="./nips-2009-Time-Varying_Dynamic_Bayesian_Networks.html">246 nips-2009-Time-Varying Dynamic Bayesian Networks</a></p>
<p>13 0.041415434 <a title="56-tfidf-13" href="./nips-2009-An_LP_View_of_the_M-best_MAP_problem.html">31 nips-2009-An LP View of the M-best MAP problem</a></p>
<p>14 0.040593933 <a title="56-tfidf-14" href="./nips-2009-Kernel_Methods_for_Deep_Learning.html">119 nips-2009-Kernel Methods for Deep Learning</a></p>
<p>15 0.038554285 <a title="56-tfidf-15" href="./nips-2009-Extending_Phase_Mechanism_to_Differential_Motion_Opponency_for_Motion_Pop-out.html">88 nips-2009-Extending Phase Mechanism to Differential Motion Opponency for Motion Pop-out</a></p>
<p>16 0.037365329 <a title="56-tfidf-16" href="./nips-2009-Semi-supervised_Regression_using_Hessian_energy_with_an_application_to_semi-supervised_dimensionality_reduction.html">214 nips-2009-Semi-supervised Regression using Hessian energy with an application to semi-supervised dimensionality reduction</a></p>
<p>17 0.036417548 <a title="56-tfidf-17" href="./nips-2009-Non-stationary_continuous_dynamic_Bayesian_networks.html">168 nips-2009-Non-stationary continuous dynamic Bayesian networks</a></p>
<p>18 0.03611226 <a title="56-tfidf-18" href="./nips-2009-Multi-Label_Prediction_via_Compressed_Sensing.html">157 nips-2009-Multi-Label Prediction via Compressed Sensing</a></p>
<p>19 0.035802417 <a title="56-tfidf-19" href="./nips-2009-Neural_Implementation_of_Hierarchical_Bayesian_Inference_by_Importance_Sampling.html">162 nips-2009-Neural Implementation of Hierarchical Bayesian Inference by Importance Sampling</a></p>
<p>20 0.035628609 <a title="56-tfidf-20" href="./nips-2009-Label_Selection_on_Graphs.html">122 nips-2009-Label Selection on Graphs</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.116), (1, -0.008), (2, -0.002), (3, -0.008), (4, 0.003), (5, -0.011), (6, 0.036), (7, 0.062), (8, 0.03), (9, 0.022), (10, -0.029), (11, -0.013), (12, 0.026), (13, 0.039), (14, -0.022), (15, -0.027), (16, 0.093), (17, 0.007), (18, -0.015), (19, -0.035), (20, 0.023), (21, -0.018), (22, -0.051), (23, -0.071), (24, -0.032), (25, -0.088), (26, 0.039), (27, -0.05), (28, 0.017), (29, 0.03), (30, 0.013), (31, 0.124), (32, 0.021), (33, -0.005), (34, -0.051), (35, -0.014), (36, -0.019), (37, 0.026), (38, 0.019), (39, -0.056), (40, 0.004), (41, 0.014), (42, 0.031), (43, 0.004), (44, 0.063), (45, 0.086), (46, 0.006), (47, -0.009), (48, -0.021), (49, 0.033)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.83378059 <a title="56-lsi-1" href="./nips-2009-Conditional_Neural_Fields.html">56 nips-2009-Conditional Neural Fields</a></p>
<p>2 0.58307612 <a title="56-lsi-2" href="./nips-2009-Conditional_Random_Fields_with_High-Order_Features_for_Sequence_Labeling.html">57 nips-2009-Conditional Random Fields with High-Order Features for Sequence Labeling</a></p>
<p>3 0.54921347 <a title="56-lsi-3" href="./nips-2009-Free_energy_score_space.html">97 nips-2009-Free energy score space</a></p>
<p>4 0.49318719 <a title="56-lsi-4" href="./nips-2009-Toward_Provably_Correct_Feature_Selection_in_Arbitrary_Domains.html">248 nips-2009-Toward Provably Correct Feature Selection in Arbitrary Domains</a></p>
<p>5 0.48205745 <a title="56-lsi-5" href="./nips-2009-FACTORIE%3A_Probabilistic_Programming_via_Imperatively_Defined_Factor_Graphs.html">89 nips-2009-FACTORIE: Probabilistic Programming via Imperatively Defined Factor Graphs</a></p>
<p>6 0.4744643 <a title="56-lsi-6" href="./nips-2009-Periodic_Step_Size_Adaptation_for_Single_Pass_On-line_Learning.html">189 nips-2009-Periodic Step Size Adaptation for Single Pass On-line Learning</a></p>
<p>7 0.46432576 <a title="56-lsi-7" href="./nips-2009-Distribution_Matching_for_Transduction.html">72 nips-2009-Distribution Matching for Transduction</a></p>
<p>8 0.460547 <a title="56-lsi-8" href="./nips-2009-Learning_Label_Embeddings_for_Nearest-Neighbor_Multi-class_Classification_with_an_Application_to_Speech_Recognition.html">127 nips-2009-Learning Label Embeddings for Nearest-Neighbor Multi-class Classification with an Application to Speech Recognition</a></p>
<p>9 0.45617747 <a title="56-lsi-9" href="./nips-2009-Unsupervised_feature_learning_for_audio_classification_using_convolutional_deep_belief_networks.html">253 nips-2009-Unsupervised feature learning for audio classification using convolutional deep belief networks</a></p>
<p>10 0.44452262 <a title="56-lsi-10" href="./nips-2009-Sharing_Features_among_Dynamical_Systems_with_Beta_Processes.html">217 nips-2009-Sharing Features among Dynamical Systems with Beta Processes</a></p>
<p>11 0.44356003 <a title="56-lsi-11" href="./nips-2009-3D_Object_Recognition_with_Deep_Belief_Nets.html">2 nips-2009-3D Object Recognition with Deep Belief Nets</a></p>
<p>12 0.43933421 <a title="56-lsi-12" href="./nips-2009-Non-stationary_continuous_dynamic_Bayesian_networks.html">168 nips-2009-Non-stationary continuous dynamic Bayesian networks</a></p>
<p>13 0.43725806 <a title="56-lsi-13" href="./nips-2009-Accelerating_Bayesian_Structural_Inference_for_Non-Decomposable_Gaussian_Graphical_Models.html">23 nips-2009-Accelerating Bayesian Structural Inference for Non-Decomposable Gaussian Graphical Models</a></p>
<p>14 0.42442763 <a title="56-lsi-14" href="./nips-2009-Breaking_Boundaries_Between_Induction_Time_and_Diagnosis_Time_Active_Information_Acquisition.html">49 nips-2009-Breaking Boundaries Between Induction Time and Diagnosis Time Active Information Acquisition</a></p>
<p>15 0.4203997 <a title="56-lsi-15" href="./nips-2009-A_Rate_Distortion_Approach_for_Semi-Supervised_Conditional_Random_Fields.html">15 nips-2009-A Rate Distortion Approach for Semi-Supervised Conditional Random Fields</a></p>
<p>16 0.41824266 <a title="56-lsi-16" href="./nips-2009-Entropic_Graph_Regularization_in_Non-Parametric_Semi-Supervised_Classification.html">82 nips-2009-Entropic Graph Regularization in Non-Parametric Semi-Supervised Classification</a></p>
<p>17 0.41696414 <a title="56-lsi-17" href="./nips-2009-Nonparametric_Bayesian_Models_for_Unsupervised_Event_Coreference_Resolution.html">171 nips-2009-Nonparametric Bayesian Models for Unsupervised Event Coreference Resolution</a></p>
<p>18 0.41509971 <a title="56-lsi-18" href="./nips-2009-Training_Factor_Graphs_with_Reinforcement_Learning_for_Efficient_MAP_Inference.html">250 nips-2009-Training Factor Graphs with Reinforcement Learning for Efficient MAP Inference</a></p>
<p>19 0.40704909 <a title="56-lsi-19" href="./nips-2009-An_Integer_Projected_Fixed_Point_Method_for_Graph_Matching_and_MAP_Inference.html">30 nips-2009-An Integer Projected Fixed Point Method for Graph Matching and MAP Inference</a></p>
<p>20 0.40513691 <a title="56-lsi-20" href="./nips-2009-Inter-domain_Gaussian_Processes_for_Sparse_Inference_using_Inducing_Features.html">117 nips-2009-Inter-domain Gaussian Processes for Sparse Inference using Inducing Features</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(4, 0.026), (9, 0.153), (11, 0.019), (24, 0.015), (31, 0.128), (37, 0.021), (55, 0.014), (60, 0.073), (87, 0.261), (89, 0.031), (96, 0.129)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.71528459 <a title="56-lda-1" href="./nips-2009-Heterogeneous_multitask_learning_with_joint_sparsity_constraints.html">108 nips-2009-Heterogeneous multitask learning with joint sparsity constraints</a></p>
<p>same-paper 2 0.71258461 <a title="56-lda-2" href="./nips-2009-Conditional_Neural_Fields.html">56 nips-2009-Conditional Neural Fields</a></p>
<p>3 0.64859974 <a title="56-lda-3" href="./nips-2009-Periodic_Step_Size_Adaptation_for_Single_Pass_On-line_Learning.html">189 nips-2009-Periodic Step Size Adaptation for Single Pass On-line Learning</a></p>
<p>4 0.64594245 <a title="56-lda-4" href="./nips-2009-Efficient_and_Accurate_Lp-Norm_Multiple_Kernel_Learning.html">80 nips-2009-Efficient and Accurate Lp-Norm Multiple Kernel Learning</a></p>
<p>5 0.64322305 <a title="56-lda-5" href="./nips-2009-Manifold_Embeddings_for_Model-Based_Reinforcement_Learning_under_Partial_Observability.html">145 nips-2009-Manifold Embeddings for Model-Based Reinforcement Learning under Partial Observability</a></p>
<p>6 0.64035922 <a title="56-lda-6" href="./nips-2009-Sparsistent_Learning_of_Varying-coefficient_Models_with_Structural_Changes.html">225 nips-2009-Sparsistent Learning of Varying-coefficient Models with Structural Changes</a></p>
<p>7 0.63894683 <a title="56-lda-7" href="./nips-2009-Fast_subtree_kernels_on_graphs.html">95 nips-2009-Fast subtree kernels on graphs</a></p>
<p>8 0.63749301 <a title="56-lda-8" href="./nips-2009-Robust_Value_Function_Approximation_Using_Bilinear_Programming.html">209 nips-2009-Robust Value Function Approximation Using Bilinear Programming</a></p>
<p>9 0.63428783 <a title="56-lda-9" href="./nips-2009-Learning_to_Explore_and_Exploit_in_POMDPs.html">134 nips-2009-Learning to Explore and Exploit in POMDPs</a></p>
<p>10 0.63349056 <a title="56-lda-10" href="./nips-2009-A_Parameter-free_Hedging_Algorithm.html">14 nips-2009-A Parameter-free Hedging Algorithm</a></p>
<p>11 0.63329172 <a title="56-lda-11" href="./nips-2009-Maximum_likelihood_trajectories_for_continuous-time_Markov_chains.html">150 nips-2009-Maximum likelihood trajectories for continuous-time Markov chains</a></p>
<p>12 0.63263685 <a title="56-lda-12" href="./nips-2009-Learning_in_Markov_Random_Fields_using_Tempered_Transitions.html">132 nips-2009-Learning in Markov Random Fields using Tempered Transitions</a></p>
<p>13 0.63160026 <a title="56-lda-13" href="./nips-2009-Regularized_Distance_Metric_Learning%3ATheory_and_Algorithm.html">202 nips-2009-Regularized Distance Metric Learning:Theory and Algorithm</a></p>
<p>14 0.63056684 <a title="56-lda-14" href="./nips-2009-A_Fast%2C_Consistent_Kernel_Two-Sample_Test.html">8 nips-2009-A Fast, Consistent Kernel Two-Sample Test</a></p>
<p>15 0.6271677 <a title="56-lda-15" href="./nips-2009-Time-Varying_Dynamic_Bayesian_Networks.html">246 nips-2009-Time-Varying Dynamic Bayesian Networks</a></p>
<p>16 0.62586153 <a title="56-lda-16" href="./nips-2009-Lattice_Regression.html">124 nips-2009-Lattice Regression</a></p>
<p>17 0.62552273 <a title="56-lda-17" href="./nips-2009-Fast_Graph_Laplacian_Regularized_Kernel_Learning_via_Semidefinite%E2%80%93Quadratic%E2%80%93Linear_Programming.html">92 nips-2009-Fast Graph Laplacian Regularized Kernel Learning via Semidefinite–Quadratic–Linear Programming</a></p>
<p>18 0.62502491 <a title="56-lda-18" href="./nips-2009-Monte_Carlo_Sampling_for_Regret_Minimization_in_Extensive_Games.html">156 nips-2009-Monte Carlo Sampling for Regret Minimization in Extensive Games</a></p>
<p>19 0.62471038 <a title="56-lda-19" href="./nips-2009-Streaming_k-means_approximation.html">234 nips-2009-Streaming k-means approximation</a></p>
<p>20 0.62438881 <a title="56-lda-20" href="./nips-2009-Discriminative_Network_Models_of_Schizophrenia.html">70 nips-2009-Discriminative Network Models of Schizophrenia</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
