<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>222 nips-2009-Sparse Estimation Using General Likelihoods and Non-Factorial Priors</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-222" href="#">nips2009-222</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>222 nips-2009-Sparse Estimation Using General Likelihoods and Non-Factorial Priors</h1>
<br/><p>Source: <a title="nips-2009-222-pdf" href="http://papers.nips.cc/paper/3681-sparse-estimation-using-general-likelihoods-and-non-factorial-priors.pdf">pdf</a></p><p>Author: David P. Wipf, Srikantan S. Nagarajan</p><p>Abstract: Finding maximally sparse representations from overcomplete feature dictionaries frequently involves minimizing a cost function composed of a likelihood (or data ﬁt) term and a prior (or penalty function) that favors sparsity. While typically the prior is factorial, here we examine non-factorial alternatives that have a number of desirable properties relevant to sparse estimation and are easily implemented using an efﬁcient and globally-convergent, reweighted 1 -norm minimization procedure. The ﬁrst method under consideration arises from the sparse Bayesian learning (SBL) framework. Although based on a highly non-convex underlying cost function, in the context of canonical sparse estimation problems, we prove uniform superiority of this method over the Lasso in that, (i) it can never do worse, and (ii) for any dictionary and sparsity proﬁle, there will always exist cases where it does better. These results challenge the prevailing reliance on strictly convex penalty functions for ﬁnding sparse solutions. We then derive a new non-factorial variant with similar properties that exhibits further performance improvements in some empirical tests. For both of these methods, as well as traditional factorial analogs, we demonstrate the effectiveness of reweighted 1 -norm algorithms in handling more general sparse estimation problems involving classiﬁcation, group feature selection, and non-negativity constraints. As a byproduct of this development, a rigorous reformulation of sparse Bayesian classiﬁcation (e.g., the relevance vector machine) is derived that, unlike the original, involves no approximation steps and descends a well-deﬁned objective function. 1</p><p>Reference: <a title="nips-2009-222-reference" href="../nips2009_reference/nips-2009-Sparse_Estimation_Using_General_Likelihoods_and_Non-Factorial_Priors_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('gsbl', 0.471), ('reweight', 0.456), ('sbl', 0.433), ('penal', 0.211), ('spars', 0.177), ('coef', 0.165), ('bfs', 0.144), ('spark', 0.141), ('wi', 0.124), ('lasso', 0.121), ('concav', 0.119), ('nagaras', 0.118), ('wipf', 0.088), ('it', 0.086), ('xi', 0.079), ('gbu', 0.071), ('xsbl', 0.071), ('cand', 0.064), ('dict', 0.062), ('bayes', 0.058)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="222-tfidf-1" href="./nips-2009-Sparse_Estimation_Using_General_Likelihoods_and_Non-Factorial_Priors.html">222 nips-2009-Sparse Estimation Using General Likelihoods and Non-Factorial Priors</a></p>
<p>2 0.13647763 <a title="222-tfidf-2" href="./nips-2009-Thresholding_Procedures_for_High_Dimensional_Variable_Selection_and_Statistical_Estimation.html">245 nips-2009-Thresholding Procedures for High Dimensional Variable Selection and Statistical Estimation</a></p>
<p>3 0.12365359 <a title="222-tfidf-3" href="./nips-2009-Learning_with_Compressible_Priors.html">138 nips-2009-Learning with Compressible Priors</a></p>
<p>4 0.11647492 <a title="222-tfidf-4" href="./nips-2009-Time-Varying_Dynamic_Bayesian_Networks.html">246 nips-2009-Time-Varying Dynamic Bayesian Networks</a></p>
<p>5 0.11464509 <a title="222-tfidf-5" href="./nips-2009-Sparse_and_Locally_Constant_Gaussian_Graphical_Models.html">224 nips-2009-Sparse and Locally Constant Gaussian Graphical Models</a></p>
<p>6 0.11026917 <a title="222-tfidf-6" href="./nips-2009-A_unified_framework_for_high-dimensional_analysis_of_%24M%24-estimators_with_decomposable_regularizers.html">20 nips-2009-A unified framework for high-dimensional analysis of $M$-estimators with decomposable regularizers</a></p>
<p>7 0.10518463 <a title="222-tfidf-7" href="./nips-2009-Sparsistent_Learning_of_Varying-coefficient_Models_with_Structural_Changes.html">225 nips-2009-Sparsistent Learning of Varying-coefficient Models with Structural Changes</a></p>
<p>8 0.097995542 <a title="222-tfidf-8" href="./nips-2009-Data-driven_calibration_of_linear_estimators_with_minimal_penalties.html">64 nips-2009-Data-driven calibration of linear estimators with minimal penalties</a></p>
<p>9 0.091288581 <a title="222-tfidf-9" href="./nips-2009-No_evidence_for_active_sparsification_in_the_visual_cortex.html">164 nips-2009-No evidence for active sparsification in the visual cortex</a></p>
<p>10 0.089770995 <a title="222-tfidf-10" href="./nips-2009-Multi-Label_Prediction_via_Compressed_Sensing.html">157 nips-2009-Multi-Label Prediction via Compressed Sensing</a></p>
<p>11 0.085266531 <a title="222-tfidf-11" href="./nips-2009-Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations.html">167 nips-2009-Non-Parametric Bayesian Dictionary Learning for Sparse Image Representations</a></p>
<p>12 0.08386191 <a title="222-tfidf-12" href="./nips-2009-Robust_Principal_Component_Analysis%3A_Exact_Recovery_of_Corrupted_Low-Rank_Matrices_via_Convex_Optimization.html">208 nips-2009-Robust Principal Component Analysis: Exact Recovery of Corrupted Low-Rank Matrices via Convex Optimization</a></p>
<p>13 0.081902988 <a title="222-tfidf-13" href="./nips-2009-Group_Sparse_Coding.html">104 nips-2009-Group Sparse Coding</a></p>
<p>14 0.073353797 <a title="222-tfidf-14" href="./nips-2009-Nonlinear_Learning_using_Local_Coordinate_Coding.html">169 nips-2009-Nonlinear Learning using Local Coordinate Coding</a></p>
<p>15 0.07151857 <a title="222-tfidf-15" href="./nips-2009-Orthogonal_Matching_Pursuit_From_Noisy_Random_Measurements%3A_A_New_Analysis.html">185 nips-2009-Orthogonal Matching Pursuit From Noisy Random Measurements: A New Analysis</a></p>
<p>16 0.070687011 <a title="222-tfidf-16" href="./nips-2009-Heterogeneous_multitask_learning_with_joint_sparsity_constraints.html">108 nips-2009-Heterogeneous multitask learning with joint sparsity constraints</a></p>
<p>17 0.065903537 <a title="222-tfidf-17" href="./nips-2009-Directed_Regression.html">67 nips-2009-Directed Regression</a></p>
<p>18 0.065147199 <a title="222-tfidf-18" href="./nips-2009-Lower_bounds_on_minimax_rates_for_nonparametric_regression_with_additive_sparsity_and_smoothness.html">144 nips-2009-Lower bounds on minimax rates for nonparametric regression with additive sparsity and smoothness</a></p>
<p>19 0.064418651 <a title="222-tfidf-19" href="./nips-2009-Convex_Relaxation_of_Mixture_Regression_with_Efficient_Algorithms.html">61 nips-2009-Convex Relaxation of Mixture Regression with Efficient Algorithms</a></p>
<p>20 0.06400951 <a title="222-tfidf-20" href="./nips-2009-Potential-Based_Agnostic_Boosting.html">193 nips-2009-Potential-Based Agnostic Boosting</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.202), (1, 0.053), (2, 0.053), (3, -0.077), (4, 0.007), (5, 0.046), (6, 0.015), (7, -0.202), (8, -0.063), (9, -0.066), (10, 0.069), (11, 0.038), (12, 0.053), (13, 0.041), (14, 0.029), (15, -0.012), (16, 0.037), (17, -0.039), (18, 0.022), (19, 0.032), (20, 0.062), (21, 0.069), (22, -0.037), (23, -0.028), (24, 0.023), (25, -0.063), (26, -0.048), (27, 0.02), (28, 0.115), (29, -0.018), (30, 0.044), (31, 0.014), (32, -0.049), (33, 0.022), (34, 0.014), (35, 0.028), (36, 0.067), (37, -0.032), (38, -0.024), (39, -0.03), (40, -0.037), (41, -0.021), (42, -0.032), (43, -0.066), (44, 0.112), (45, -0.003), (46, 0.024), (47, 0.038), (48, 0.002), (49, 0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9312225 <a title="222-lsi-1" href="./nips-2009-Sparse_Estimation_Using_General_Likelihoods_and_Non-Factorial_Priors.html">222 nips-2009-Sparse Estimation Using General Likelihoods and Non-Factorial Priors</a></p>
<p>2 0.81372726 <a title="222-lsi-2" href="./nips-2009-Orthogonal_Matching_Pursuit_From_Noisy_Random_Measurements%3A_A_New_Analysis.html">185 nips-2009-Orthogonal Matching Pursuit From Noisy Random Measurements: A New Analysis</a></p>
<p>3 0.78759676 <a title="222-lsi-3" href="./nips-2009-Thresholding_Procedures_for_High_Dimensional_Variable_Selection_and_Statistical_Estimation.html">245 nips-2009-Thresholding Procedures for High Dimensional Variable Selection and Statistical Estimation</a></p>
<p>4 0.74266392 <a title="222-lsi-4" href="./nips-2009-Efficient_Recovery_of_Jointly_Sparse_Vectors.html">79 nips-2009-Efficient Recovery of Jointly Sparse Vectors</a></p>
<p>5 0.7193194 <a title="222-lsi-5" href="./nips-2009-Nonparametric_Greedy_Algorithms_for_the_Sparse_Learning_Problem.html">173 nips-2009-Nonparametric Greedy Algorithms for the Sparse Learning Problem</a></p>
<p>6 0.70427084 <a title="222-lsi-6" href="./nips-2009-Learning_with_Compressible_Priors.html">138 nips-2009-Learning with Compressible Priors</a></p>
<p>7 0.70190513 <a title="222-lsi-7" href="./nips-2009-Grouped_Orthogonal_Matching_Pursuit_for_Variable_Selection_and_Prediction.html">105 nips-2009-Grouped Orthogonal Matching Pursuit for Variable Selection and Prediction</a></p>
<p>8 0.68601108 <a title="222-lsi-8" href="./nips-2009-Asymptotic_Analysis_of_MAP_Estimation_via_the_Replica_Method_and_Compressed_Sensing.html">36 nips-2009-Asymptotic Analysis of MAP Estimation via the Replica Method and Compressed Sensing</a></p>
<p>9 0.68157381 <a title="222-lsi-9" href="./nips-2009-A_unified_framework_for_high-dimensional_analysis_of_%24M%24-estimators_with_decomposable_regularizers.html">20 nips-2009-A unified framework for high-dimensional analysis of $M$-estimators with decomposable regularizers</a></p>
<p>10 0.65682435 <a title="222-lsi-10" href="./nips-2009-Sparsistent_Learning_of_Varying-coefficient_Models_with_Structural_Changes.html">225 nips-2009-Sparsistent Learning of Varying-coefficient Models with Structural Changes</a></p>
<p>11 0.6165086 <a title="222-lsi-11" href="./nips-2009-Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations.html">167 nips-2009-Non-Parametric Bayesian Dictionary Learning for Sparse Image Representations</a></p>
<p>12 0.61014962 <a title="222-lsi-12" href="./nips-2009-Efficient_Learning_using_Forward-Backward_Splitting.html">76 nips-2009-Efficient Learning using Forward-Backward Splitting</a></p>
<p>13 0.59526098 <a title="222-lsi-13" href="./nips-2009-Compressed_Least-Squares_Regression.html">55 nips-2009-Compressed Least-Squares Regression</a></p>
<p>14 0.58751619 <a title="222-lsi-14" href="./nips-2009-Sparse_and_Locally_Constant_Gaussian_Graphical_Models.html">224 nips-2009-Sparse and Locally Constant Gaussian Graphical Models</a></p>
<p>15 0.58479929 <a title="222-lsi-15" href="./nips-2009-No_evidence_for_active_sparsification_in_the_visual_cortex.html">164 nips-2009-No evidence for active sparsification in the visual cortex</a></p>
<p>16 0.57838941 <a title="222-lsi-16" href="./nips-2009-Directed_Regression.html">67 nips-2009-Directed Regression</a></p>
<p>17 0.56637257 <a title="222-lsi-17" href="./nips-2009-Robust_Principal_Component_Analysis%3A_Exact_Recovery_of_Corrupted_Low-Rank_Matrices_via_Convex_Optimization.html">208 nips-2009-Robust Principal Component Analysis: Exact Recovery of Corrupted Low-Rank Matrices via Convex Optimization</a></p>
<p>18 0.56131619 <a title="222-lsi-18" href="./nips-2009-Posterior_vs_Parameter_Sparsity_in_Latent_Variable_Models.html">192 nips-2009-Posterior vs Parameter Sparsity in Latent Variable Models</a></p>
<p>19 0.55645329 <a title="222-lsi-19" href="./nips-2009-On_the_Convergence_of_the_Concave-Convex_Procedure.html">180 nips-2009-On the Convergence of the Concave-Convex Procedure</a></p>
<p>20 0.55018222 <a title="222-lsi-20" href="./nips-2009-A_Gaussian_Tree_Approximation_for_Integer_Least-Squares.html">10 nips-2009-A Gaussian Tree Approximation for Integer Least-Squares</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(4, 0.012), (9, 0.262), (11, 0.035), (24, 0.012), (31, 0.119), (37, 0.012), (57, 0.254), (60, 0.059), (89, 0.031), (96, 0.113)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.82562023 <a title="222-lda-1" href="./nips-2009-Sparse_Estimation_Using_General_Likelihoods_and_Non-Factorial_Priors.html">222 nips-2009-Sparse Estimation Using General Likelihoods and Non-Factorial Priors</a></p>
<p>2 0.77190131 <a title="222-lda-2" href="./nips-2009-Manifold_Embeddings_for_Model-Based_Reinforcement_Learning_under_Partial_Observability.html">145 nips-2009-Manifold Embeddings for Model-Based Reinforcement Learning under Partial Observability</a></p>
<p>3 0.77124727 <a title="222-lda-3" href="./nips-2009-Time-Varying_Dynamic_Bayesian_Networks.html">246 nips-2009-Time-Varying Dynamic Bayesian Networks</a></p>
<p>4 0.76893687 <a title="222-lda-4" href="./nips-2009-Learning_Non-Linear_Combinations_of_Kernels.html">128 nips-2009-Learning Non-Linear Combinations of Kernels</a></p>
<p>5 0.76865113 <a title="222-lda-5" href="./nips-2009-Large_Scale_Nonparametric_Bayesian_Inference%3A_Data_Parallelisation_in_the_Indian_Buffet_Process.html">123 nips-2009-Large Scale Nonparametric Bayesian Inference: Data Parallelisation in the Indian Buffet Process</a></p>
<p>6 0.76708043 <a title="222-lda-6" href="./nips-2009-Bayesian_Source_Localization_with_the_Multivariate_Laplace_Prior.html">41 nips-2009-Bayesian Source Localization with the Multivariate Laplace Prior</a></p>
<p>7 0.76686513 <a title="222-lda-7" href="./nips-2009-Improving_Existing_Fault_Recovery_Policies.html">113 nips-2009-Improving Existing Fault Recovery Policies</a></p>
<p>8 0.76667303 <a title="222-lda-8" href="./nips-2009-Conditional_Neural_Fields.html">56 nips-2009-Conditional Neural Fields</a></p>
<p>9 0.76666957 <a title="222-lda-9" href="./nips-2009-Help_or_Hinder%3A_Bayesian_Models_of_Social_Goal_Inference.html">107 nips-2009-Help or Hinder: Bayesian Models of Social Goal Inference</a></p>
<p>10 0.76666158 <a title="222-lda-10" href="./nips-2009-Learning_in_Markov_Random_Fields_using_Tempered_Transitions.html">132 nips-2009-Learning in Markov Random Fields using Tempered Transitions</a></p>
<p>11 0.76636302 <a title="222-lda-11" href="./nips-2009-Speeding_up_Magnetic_Resonance_Image_Acquisition_by_Bayesian_Multi-Slice_Adaptive_Compressed_Sensing.html">228 nips-2009-Speeding up Magnetic Resonance Image Acquisition by Bayesian Multi-Slice Adaptive Compressed Sensing</a></p>
<p>12 0.7654292 <a title="222-lda-12" href="./nips-2009-Kernels_and_learning_curves_for_Gaussian_process_regression_on_random_graphs.html">120 nips-2009-Kernels and learning curves for Gaussian process regression on random graphs</a></p>
<p>13 0.76539761 <a title="222-lda-13" href="./nips-2009-Streaming_k-means_approximation.html">234 nips-2009-Streaming k-means approximation</a></p>
<p>14 0.76525819 <a title="222-lda-14" href="./nips-2009-Kernel_Choice_and_Classifiability_for_RKHS_Embeddings_of_Probability_Distributions.html">118 nips-2009-Kernel Choice and Classifiability for RKHS Embeddings of Probability Distributions</a></p>
<p>15 0.76485115 <a title="222-lda-15" href="./nips-2009-Directed_Regression.html">67 nips-2009-Directed Regression</a></p>
<p>16 0.76378614 <a title="222-lda-16" href="./nips-2009-Maximum_likelihood_trajectories_for_continuous-time_Markov_chains.html">150 nips-2009-Maximum likelihood trajectories for continuous-time Markov chains</a></p>
<p>17 0.76358819 <a title="222-lda-17" href="./nips-2009-Multiple_Incremental_Decremental_Learning_of_Support_Vector_Machines.html">160 nips-2009-Multiple Incremental Decremental Learning of Support Vector Machines</a></p>
<p>18 0.76357025 <a title="222-lda-18" href="./nips-2009-Potential-Based_Agnostic_Boosting.html">193 nips-2009-Potential-Based Agnostic Boosting</a></p>
<p>19 0.76307672 <a title="222-lda-19" href="./nips-2009-Measuring_Invariances_in_Deep_Networks.html">151 nips-2009-Measuring Invariances in Deep Networks</a></p>
<p>20 0.76291412 <a title="222-lda-20" href="./nips-2009-Rank-Approximate_Nearest_Neighbor_Search%3A_Retaining_Meaning_and_Speed_in_High_Dimensions.html">198 nips-2009-Rank-Approximate Nearest Neighbor Search: Retaining Meaning and Speed in High Dimensions</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
