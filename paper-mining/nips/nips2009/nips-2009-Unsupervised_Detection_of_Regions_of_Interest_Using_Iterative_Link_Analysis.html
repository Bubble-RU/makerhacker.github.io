<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>251 nips-2009-Unsupervised Detection of Regions of Interest Using Iterative Link Analysis</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-251" href="#">nips2009-251</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>251 nips-2009-Unsupervised Detection of Regions of Interest Using Iterative Link Analysis</h1>
<br/><p>Source: <a title="nips-2009-251-pdf" href="http://papers.nips.cc/paper/3680-unsupervised-detection-of-regions-of-interest-using-iterative-link-analysis.pdf">pdf</a></p><p>Author: Gunhee Kim, Antonio Torralba</p><p>Abstract: This paper proposes a fast and scalable alternating optimization technique to detect regions of interest (ROIs) in cluttered Web images without labels. The proposed approach discovers highly probable regions of object instances by iteratively repeating the following two functions: (1) choose the exemplar set (i.e. a small number of highly ranked reference ROIs) across the dataset and (2) reﬁne the ROIs of each image with respect to the exemplar set. These two subproblems are formulated as ranking in two different similarity networks of ROI hypotheses by link analysis. The experiments with the PASCAL 06 dataset show that our unsupervised localization performance is better than one of state-of-the-art techniques and comparable to supervised methods. Also, we test the scalability of our approach with ﬁve objects in Flickr dataset consisting of more than 200K images. 1</p><p>Reference: <a title="nips-2009-251-reference" href="../nips2009_reference/nips-2009-Unsupervised_Detection_of_Regions_of_Interest_Using_Iterative_Link_Analysis_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract This paper proposes a fast and scalable alternating optimization technique to detect regions of interest (ROIs) in cluttered Web images without labels. [sent-5, score-0.275]
</p><p>2 The proposed approach discovers highly probable regions of object instances by iteratively repeating the following two functions: (1) choose the exemplar set (i. [sent-6, score-0.179]
</p><p>3 a small number of highly ranked reference ROIs) across the dataset and (2) reﬁne the ROIs of each image with respect to the exemplar set. [sent-8, score-0.304]
</p><p>4 These two subproblems are formulated as ranking in two different similarity networks of ROI hypotheses by link analysis. [sent-9, score-0.299]
</p><p>5 The experiments with the PASCAL 06 dataset show that our unsupervised localization performance is better than one of state-of-the-art techniques and comparable to supervised methods. [sent-10, score-0.368]
</p><p>6 Also, we test the scalability of our approach with ﬁve objects in Flickr dataset consisting of more than 200K images. [sent-11, score-0.199]
</p><p>7 1  Introduction  This paper proposes an unsupervised approach to the detection of regions of interest (ROIs) from a Web-sized dataset (Fig. [sent-12, score-0.292]
</p><p>8 We deﬁne the regions of interest as highly probable rectangular regions of object instances in the images. [sent-14, score-0.196]
</p><p>9 For example, [3, 5] showed comparative studies in which ROI detection is useful to learn more accurate models, which leads to nontrivial improvement of classiﬁcation and localization performance. [sent-16, score-0.231]
</p><p>10 In the recognition of indoor scenes [17], the local regions that contain objects may have special meaning to characterize the scene description. [sent-17, score-0.152]
</p><p>11 Also, many Web applications allow a user to attach notes on user-speciﬁed regions in a cluttered image (e. [sent-18, score-0.198]
</p><p>12 Our solution to the problem of unsupervised ROI detection is inspired by an alternating optimization. [sent-22, score-0.212]
</p><p>13 Given a Web-sized dataset, our algorithm detects bounding box-shaped ROIs that are statistically signiﬁcant across the dataset in an unsupervised manner. [sent-26, score-0.196]
</p><p>14 The yellow boxes are groundtruth labels, and the red and blue ones are ROIs detected by the proposed method. [sent-27, score-0.228]
</p><p>15 1  The unsupervised ROI detection can be though of as a chicken-and-egg problem between (1) ﬁnding exemplars of objects in the dataset and (2) localizing object instances in each image. [sent-28, score-0.424]
</p><p>16 If classrepresentative exemplars are given, the detection of objects in images is solvable (i. [sent-29, score-0.328]
</p><p>17 Given an image set, ﬁrst we assume that each image itself is the best ROI (i. [sent-35, score-0.228]
</p><p>18 Then a small number of highly ranked ones among the selected ROIs are chosen as exemplars (called hub seeking), which serve as references to reﬁne the ROIs of each image (called ROI reﬁnement). [sent-38, score-0.645]
</p><p>19 The two steps are formulated as ranking in two different similarity networks of ROI hypotheses by link analysis. [sent-40, score-0.299]
</p><p>20 The hub seeking corresponds to ﬁnding a central and diverse hub set in a network of the selected ROIs (i. [sent-41, score-0.9]
</p><p>21 The ROI reﬁnement is the ranking in a bipartite graph between the hub sets and all possible ROI hypotheses of each image (i. [sent-44, score-0.732]
</p><p>22 Our work is closely related to topics on ROI detection [3, 5, 17, 14], unsupervised localization [9, 24, 21, 18, 1, 12], and online image collection [13, 19, 6]. [sent-47, score-0.439]
</p><p>23 The ROI detection and unsupervised localization share a similar goal of detecting the regions of objects in cluttered images. [sent-48, score-0.487]
</p><p>24 The main objective of online image collection is to collect relevant images from highly noisy data queried by keywords from the Web. [sent-51, score-0.276]
</p><p>25 Its main limitation is that much of the previous work requires additional assumptions such as a small number of seed images in the beginning [13], texts and HTML tags associated with images [19], and user-labeled images [6]. [sent-52, score-0.384]
</p><p>26 Recently, link analysis techniques on visual similarity networks were successfully exploited in computer vision problems [12, 15, 11, 16]. [sent-54, score-0.182]
</p><p>27 [12] is similar to ours in that the unsupervised classiﬁcation and localization are the main objectives. [sent-57, score-0.245]
</p><p>28 [11] successfully applied the PageRank technique to a large-scale image search, but unlike ours their approach is evaluated with quite clean images and sub-image level localization is not dealt with. [sent-59, score-0.393]
</p><p>29 Likewise, [16] also exploited the matching graph of a large-scale image set, but the localization was not discussed. [sent-60, score-0.321]
</p><p>30 Our approach shows superior results over a state-of-the-art unsupervised localization method [18] for the PASCAL 06 dataset. [sent-63, score-0.245]
</p><p>31 For example, the localization of 200K images took only 4. [sent-65, score-0.279]
</p><p>32 The objective of image retrieval is to quickly index and search the nearest images to a given query. [sent-73, score-0.242]
</p><p>33 On the other hand, our goal is to localize objects in every single image of a dataset without supervision. [sent-74, score-0.26]
</p><p>34 The ﬁrst task is to deﬁne a set of ROI hypotheses from the image set R = {R1 , R2 , . [sent-79, score-0.235]
</p><p>35 , ram } of an image Ia enumerates all plausible bounding boxes, and at least one of them is supposed to be a good object annotation. [sent-86, score-0.21]
</p><p>36 Then the bounding boxes to enclose those minimum paths are added to the ROI hypothesis set. [sent-99, score-0.163]
</p><p>37 Note that the hypothesis set always includes the image itself as the largest candidate, and the average set size is about 50. [sent-102, score-0.164]
</p><p>38 1  The Algorithm Similarity Networks and Link Analysis Techniques  All inferences in our approach are based on the link analysis of k-nearest neighbor similarity network between ROI hypotheses. [sent-113, score-0.184]
</p><p>39 The similarity network is a weighted graph G = (V, E, W), where V is the set of vertices that are ROI hypotheses. [sent-114, score-0.157]
</p><p>40 Given a similarity matrix G, it computes the same length of PageRank vector p, which assigns a ranked score to each vertex of the network. [sent-121, score-0.174]
</p><p>41 Intuitively, the PageRank scores of the network of ROI hypotheses are indices of the goodness of hypotheses. [sent-122, score-0.2]
</p><p>42 The basic idea of our approach is to jointly optimize the ROI selection of each image and the examplar detection among the selected ROIs. [sent-128, score-0.24]
</p><p>43 Even though this initialization is quite poor, highly ranked hubs among the ROIs are likely to be much more reliable. [sent-131, score-0.154]
</p><p>44 Then, the hub sets are exploited to reﬁne the ROIs of each images by the function Hub seeking (Step 5). [sent-133, score-0.598]
</p><p>45 In turn, those reﬁned ROIs are likely to lead to a better hub set at the next iteration. [sent-134, score-0.354]
</p><p>46 The alternating iterations of those two functions are expected to lead convergence for not only the best ROI selection of each image but also the most representative ROIs of the data set. [sent-135, score-0.152]
</p><p>47 Conceptually, both functions share a similar ranking problem to 3  Figure 3: Examples of hub images. [sent-140, score-0.403]
</p><p>48 The pictures illustrate highest-ranked images in 10,000 randomly selected images from ﬁve objects of our Flickr dataset and all {train+val}images from two objects of the PASCAL06. [sent-141, score-0.526]
</p><p>49 Our key assumption is as follows: Provided that the similarity network includes a sufﬁciently large number of images, the hub images are likely to be good references. [sent-145, score-0.608]
</p><p>50 This is based on the ﬁnding of our previous work [12]: If each visual entity votes for others that are similar to itself, this democratic voting can reveal the dominant statistics of the image set. [sent-146, score-0.178]
</p><p>51 Although the images in a dataset are highly variable, the more repetitive visual information may get more similarity votes, which can be easily and quickly discovered as hubs by link analysis. [sent-147, score-0.502]
</p><p>52 It illustrates topranked images of our dataset in which the objects are clearly shown in the center with signiﬁcant size. [sent-150, score-0.274]
</p><p>53 Since we deal with discrete patches from unordered natural images on the Web, it is extremely difﬁcult to analytically understand several important behaviors of our algorithm such as convexity, convergence, sensitivity to initial guess, and quality of our solution. [sent-152, score-0.15]
</p><p>54 Algorithm 1 The Algorithm Input: ROI hypothesis R associated with image set I. [sent-158, score-0.164]
</p><p>55 3: H(t) ← Hub seeking(G(t) ), where the hub set H(t) ⊂ S (t) for all Ia ∈ I unless ROI selection of Ia is not changed for several consecutive times do (t) (t) 4: sa ← ROI reﬁnement(H(t) , Ra ), where sa : ROI selection of Ia , Ra : ROI hypotheses of Ia . [sent-162, score-0.581]
</p><p>56 (2) Ra , ROI hypotheses of Ia (t) Output: (1) The selected ROIs sa (⊂ Ra ). [sent-173, score-0.22]
</p><p>57 a  Hub Seeking with Centrality and Diversity  The goal of this step is to detect a hub set H(t) from S (t) by analyzing the network G(t) . [sent-178, score-0.434]
</p><p>58 In other words, the selected hub set should be not only highly ranked but also diverse enough not to lose various aspects of an object. [sent-180, score-0.489]
</p><p>59 To meet this requirement, we design the hub seeking inspired by Mean Shift [7]. [sent-181, score-0.445]
</p><p>60 Then each window iteratively moves into the direction of 4  Figure 4: (a) An example of a bipartite graph between the hub set and ROI hypotheses of an image. [sent-183, score-0.618]
</p><p>61 The similarity between hubs and hypotheses is captured by Wo and the afﬁnity between the hypotheses by Wi . [sent-184, score-0.378]
</p><p>62 The hub set is sorted by PageRank values from left and right. [sent-185, score-0.354]
</p><p>63 The ranking of hypotheses is represented by jet colormap from red (high) to blue (low). [sent-193, score-0.3]
</p><p>64 At T = 0, the selected ROI is an image itself but is converged to the real object after T = 5. [sent-206, score-0.222]
</p><p>65 In Step 3, we compute the vector m that assigns the local maximum vertex within the window of each vertex in G(t) . [sent-221, score-0.145]
</p><p>66 4  ROI Reﬁnement  Formally, this step is to deﬁne a nonparametric function for each image fa : Ra → R+ (positive real number) with respect to the hub set H(t) . [sent-227, score-0.468]
</p><p>67 In order to solve this problem, we ﬁrst construct an augmented bipartite graph W between the hub set H(t) and all possible ROIs Ra as shown in Step 2 of Algorithm 3 (see Fig. [sent-229, score-0.471]
</p><p>68 Then the matrix W represents the similarity voting between the ROI candidates and the hub set. [sent-232, score-0.425]
</p><p>69 Even though the red hypothesis is the maximum, several hypotheses near the dark gray car have signiﬁcant values. [sent-239, score-0.272]
</p><p>70 1, those hypotheses are allowed to augment each other, so the maximum ROI is changed to a hypothesis on the car. [sent-241, score-0.171]
</p><p>71 In terms of link analysis, if a random surfer visits nodes of ROI hypotheses (Ra ), it jumps to other hypotheses with probability α or other hubs with 1 − α. [sent-242, score-0.397]
</p><p>72 Since the nearby hypotheses share large portions of rectangles, they have higher similarity, which results in more votes for nearby hypotheses. [sent-243, score-0.157]
</p><p>73 ) If the dataset size |I| > N , we randomly sample N images from I and construct initial consideration set Ic ⊂ I. [sent-251, score-0.196]
</p><p>74 The images are collected by a query that consists of one object word and one context word. [sent-263, score-0.19]
</p><p>75 We downloaded images of the objects {butterﬂy+insect(69,990), classic+car(265,731), motorcycle+bike(106,590), sunﬂower(165,235), giraffe+zoo(53,620)}. [sent-264, score-0.206]
</p><p>76 1  Performance Tests  The input of our algorithm consists of unlabeled images, which may include a single object (called as weakly supervised) or multiple objects (called unsupervised). [sent-267, score-0.192]
</p><p>77 For unsupervised cases, we perform not only localization but also classiﬁcation according to object types. [sent-268, score-0.307]
</p><p>78 The PASCAL 06 dataset is so challenging to use that only very rare previous work has used it for unsupervised localization. [sent-269, score-0.162]
</p><p>79 However, our approach requires only images as an input, and thus all of the {train+val+test} images are used without discrimination between them. [sent-272, score-0.256]
</p><p>80 Note that our task is an image annotation not a learning problem that requires training and testing steps. [sent-273, score-0.149]
</p><p>81 Promisingly, the performances of our approach for bicycle and motorbike are comparable, and those for bus, cat, and dog objects are superior to the bests of the supervised methods in VOC06. [sent-286, score-0.317]
</p><p>82 Here we evaluate how well our approach works for unsupervised classiﬁcation and localization tasks (i. [sent-288, score-0.245]
</p><p>83 images of multiple objects without any annotation are given). [sent-290, score-0.241]
</p><p>84 Note that our localization and that of [18] are unsupervised, but the VOC06 localization is supervised. [sent-314, score-0.302]
</p><p>85 (d)−(f) PR curves for unsupervised localization of ours (blue) and [18] (magenta). [sent-330, score-0.268]
</p><p>86 For comparison, we also represent the results of our weakly supervised localization (red) and the best of VOC 06 (green). [sent-331, score-0.258]
</p><p>87 ) We also show the unsupervised localization performance as PRcurves in Fig. [sent-334, score-0.245]
</p><p>88 5% randomly selected images of datasets, and they are used as limited but approximate indices of performance measures. [sent-342, score-0.174]
</p><p>89 7, the performances of 500 images ﬂuctuate, but the results of the dataset size above 5K are stable. [sent-354, score-0.222]
</p><p>90 Since the maximum number of images at each running of the algorithm is bounded by N (= 10, 000), the computation times are linear to the number of images, and the performances of the data size above N are similar each other. [sent-356, score-0.154]
</p><p>91 Here we test the goodness of selected ROIs from a different view: robustness of ROI detection against random network formation. [sent-358, score-0.205]
</p><p>92 For example, given an image Ia , we can generate 100 sets of 200 randomly selected images that include Ia . [sent-359, score-0.288]
</p><p>93 (a) PR curves for ﬁve objects of our Flickr dataset by varying dataset sizes from 500 to 200K. [sent-363, score-0.237]
</p><p>94 (b) The log-log plot between the number of images and computation times for the car object. [sent-364, score-0.191]
</p><p>95 The frequencies of particular ROIs are represented by the thickness of bounding boxes and the jet colormap from red (high) to blue (low). [sent-373, score-0.219]
</p><p>96 5  Discussion  We proposed an alternating optimization approach for scalable unsupervised ROI detection by analyzing the statistics of similarity links between ROI hypotheses. [sent-393, score-0.283]
</p><p>97 Both tests with PASCAL 06 and Flickr datasets showed that our approach is not only comparable to other unsupervised and supervised techniques but also applicable to real images on the Web. [sent-394, score-0.308]
</p><p>98 The yellow boxes are groundtruth labels, and the red and blue ones are ROIs detected by the proposed method. [sent-399, score-0.228]
</p><p>99 Using multiple segmentations to discover objects and their extent in image collections. [sent-522, score-0.192]
</p><p>100 Discovering objects and their location in images image features. [sent-545, score-0.32]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('roi', 0.646), ('hub', 0.354), ('rois', 0.315), ('localization', 0.151), ('pagerank', 0.146), ('ia', 0.13), ('images', 0.128), ('hypotheses', 0.121), ('image', 0.114), ('ra', 0.114), ('unsupervised', 0.094), ('flickr', 0.092), ('seeking', 0.091), ('pascal', 0.08), ('detection', 0.08), ('objects', 0.078), ('similarity', 0.071), ('bicycle', 0.071), ('dataset', 0.068), ('hubs', 0.065), ('car', 0.063), ('bipartite', 0.063), ('object', 0.062), ('link', 0.058), ('val', 0.057), ('supervised', 0.055), ('ranked', 0.055), ('network', 0.055), ('dog', 0.055), ('boxes', 0.055), ('scalability', 0.053), ('sa', 0.053), ('weakly', 0.052), ('voc', 0.052), ('hypothesis', 0.05), ('regions', 0.05), ('ranking', 0.049), ('window', 0.049), ('raj', 0.049), ('vertex', 0.048), ('nement', 0.047), ('selected', 0.046), ('iccv', 0.045), ('sc', 0.044), ('exemplars', 0.042), ('web', 0.039), ('reachable', 0.039), ('groundtruth', 0.039), ('wo', 0.039), ('alternating', 0.038), ('red', 0.038), ('blue', 0.037), ('detected', 0.037), ('votes', 0.036), ('annotation', 0.035), ('maxima', 0.035), ('cluttered', 0.034), ('bounding', 0.034), ('highly', 0.034), ('nv', 0.033), ('ic', 0.033), ('exemplar', 0.033), ('annotated', 0.032), ('bests', 0.032), ('butter', 0.032), ('colormap', 0.032), ('gunhee', 0.032), ('surfer', 0.032), ('zoo', 0.032), ('cvpr', 0.031), ('tests', 0.031), ('graph', 0.031), ('centrality', 0.028), ('owers', 0.028), ('visual', 0.028), ('dent', 0.028), ('russell', 0.027), ('repetitive', 0.026), ('faloutsos', 0.026), ('performances', 0.026), ('torralba', 0.025), ('exploited', 0.025), ('perturbation', 0.025), ('detect', 0.025), ('roc', 0.024), ('indoor', 0.024), ('enclose', 0.024), ('goodness', 0.024), ('giraffe', 0.024), ('discovered', 0.024), ('jet', 0.023), ('hog', 0.023), ('rai', 0.023), ('curves', 0.023), ('augmented', 0.023), ('sun', 0.023), ('pr', 0.022), ('extremely', 0.022), ('www', 0.022), ('yellow', 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="251-tfidf-1" href="./nips-2009-Unsupervised_Detection_of_Regions_of_Interest_Using_Iterative_Link_Analysis.html">251 nips-2009-Unsupervised Detection of Regions of Interest Using Iterative Link Analysis</a></p>
<p>Author: Gunhee Kim, Antonio Torralba</p><p>Abstract: This paper proposes a fast and scalable alternating optimization technique to detect regions of interest (ROIs) in cluttered Web images without labels. The proposed approach discovers highly probable regions of object instances by iteratively repeating the following two functions: (1) choose the exemplar set (i.e. a small number of highly ranked reference ROIs) across the dataset and (2) reﬁne the ROIs of each image with respect to the exemplar set. These two subproblems are formulated as ranking in two different similarity networks of ROI hypotheses by link analysis. The experiments with the PASCAL 06 dataset show that our unsupervised localization performance is better than one of state-of-the-art techniques and comparable to supervised methods. Also, we test the scalability of our approach with ﬁve objects in Flickr dataset consisting of more than 200K images. 1</p><p>2 0.39909729 <a title="251-tfidf-2" href="./nips-2009-Hierarchical_Mixture_of_Classification_Experts_Uncovers_Interactions_between_Brain_Regions.html">110 nips-2009-Hierarchical Mixture of Classification Experts Uncovers Interactions between Brain Regions</a></p>
<p>Author: Bangpeng Yao, Dirk Walther, Diane Beck, Li Fei-fei</p><p>Abstract: The human brain can be described as containing a number of functional regions. These regions, as well as the connections between them, play a key role in information processing in the brain. However, most existing multi-voxel pattern analysis approaches either treat multiple regions as one large uniform region or several independent regions, ignoring the connections between them. In this paper we propose to model such connections in an Hidden Conditional Random Field (HCRF) framework, where the classiďŹ er of one region of interest (ROI) makes predictions based on not only its voxels but also the predictions from ROIs that it connects to. Furthermore, we propose a structural learning method in the HCRF framework to automatically uncover the connections between ROIs. We illustrate this approach with fMRI data acquired while human subjects viewed images of different natural scene categories and show that our model can improve the top-level (the classiďŹ er combining information from all ROIs) and ROI-level prediction accuracy, as well as uncover some meaningful connections between ROIs. 1</p><p>3 0.12396407 <a title="251-tfidf-3" href="./nips-2009-Region-based_Segmentation_and_Object_Detection.html">201 nips-2009-Region-based Segmentation and Object Detection</a></p>
<p>Author: Stephen Gould, Tianshi Gao, Daphne Koller</p><p>Abstract: Object detection and multi-class image segmentation are two closely related tasks that can be greatly improved when solved jointly by feeding information from one task to the other [10, 11]. However, current state-of-the-art models use a separate representation for each task making joint inference clumsy and leaving the classiﬁcation of many parts of the scene ambiguous. In this work, we propose a hierarchical region-based approach to joint object detection and image segmentation. Our approach simultaneously reasons about pixels, regions and objects in a coherent probabilistic model. Pixel appearance features allow us to perform well on classifying amorphous background classes, while the explicit representation of regions facilitate the computation of more sophisticated features necessary for object detection. Importantly, our model gives a single uniﬁed description of the scene—we explain every pixel in the image and enforce global consistency between all random variables in our model. We run experiments on the challenging Street Scene dataset [2] and show signiﬁcant improvement over state-of-the-art results for object detection accuracy. 1</p><p>4 0.12377311 <a title="251-tfidf-4" href="./nips-2009-Segmenting_Scenes_by_Matching_Image_Composites.html">211 nips-2009-Segmenting Scenes by Matching Image Composites</a></p>
<p>Author: Bryan Russell, Alyosha Efros, Josef Sivic, Bill Freeman, Andrew Zisserman</p><p>Abstract: In this paper, we investigate how, given an image, similar images sharing the same global description can help with unsupervised scene segmentation. In contrast to recent work in semantic alignment of scenes, we allow an input image to be explained by partial matches of similar scenes. This allows for a better explanation of the input scenes. We perform MRF-based segmentation that optimizes over matches, while respecting boundary information. The recovered segments are then used to re-query a large database of images to retrieve better matches for the target regions. We show improved performance in detecting the principal occluding and contact boundaries for the scene over previous methods on data gathered from the LabelMe database.</p><p>5 0.11997212 <a title="251-tfidf-5" href="./nips-2009-Discriminative_Network_Models_of_Schizophrenia.html">70 nips-2009-Discriminative Network Models of Schizophrenia</a></p>
<p>Author: Irina Rish, Benjamin Thyreau, Bertrand Thirion, Marion Plaze, Marie-laure Paillere-martinot, Catherine Martelli, Jean-luc Martinot, Jean-baptiste Poline, Guillermo A. Cecchi</p><p>Abstract: Schizophrenia is a complex psychiatric disorder that has eluded a characterization in terms of local abnormalities of brain activity, and is hypothesized to affect the collective, “emergent” working of the brain. We propose a novel data-driven approach to capture emergent features using functional brain networks [4] extracted from fMRI data, and demonstrate its advantage over traditional region-of-interest (ROI) and local, task-speciﬁc linear activation analyzes. Our results suggest that schizophrenia is indeed associated with disruption of global brain properties related to its functioning as a network, which cannot be explained by alteration of local activation patterns. Moreover, further exploitation of interactions by sparse Markov Random Field classiﬁers shows clear gain over linear methods, such as Gaussian Naive Bayes and SVM, allowing to reach 86% accuracy (over 50% baseline - random guess), which is quite remarkable given that it is based on a single fMRI experiment using a simple auditory task. 1</p><p>6 0.11256163 <a title="251-tfidf-6" href="./nips-2009-Structured_output_regression_for_detection_with_partial_truncation.html">236 nips-2009-Structured output regression for detection with partial truncation</a></p>
<p>7 0.11063871 <a title="251-tfidf-7" href="./nips-2009-Breaking_Boundaries_Between_Induction_Time_and_Diagnosis_Time_Active_Information_Acquisition.html">49 nips-2009-Breaking Boundaries Between Induction Time and Diagnosis Time Active Information Acquisition</a></p>
<p>8 0.11043513 <a title="251-tfidf-8" href="./nips-2009-Exploring_Functional_Connectivities_of_the_Human_Brain_using_Multivariate_Information_Analysis.html">86 nips-2009-Exploring Functional Connectivities of the Human Brain using Multivariate Information Analysis</a></p>
<p>9 0.097601339 <a title="251-tfidf-9" href="./nips-2009-A_Bayesian_Model_for_Simultaneous_Image_Clustering%2C_Annotation_and_Object_Segmentation.html">5 nips-2009-A Bayesian Model for Simultaneous Image Clustering, Annotation and Object Segmentation</a></p>
<p>10 0.094993576 <a title="251-tfidf-10" href="./nips-2009-Filtering_Abstract_Senses_From_Image_Search_Results.html">96 nips-2009-Filtering Abstract Senses From Image Search Results</a></p>
<p>11 0.085504524 <a title="251-tfidf-11" href="./nips-2009-Learning_models_of_object_structure.html">133 nips-2009-Learning models of object structure</a></p>
<p>12 0.082607225 <a title="251-tfidf-12" href="./nips-2009-Constructing_Topological_Maps_using_Markov_Random_Fields_and_Loop-Closure_Detection.html">58 nips-2009-Constructing Topological Maps using Markov Random Fields and Loop-Closure Detection</a></p>
<p>13 0.079206251 <a title="251-tfidf-13" href="./nips-2009-Graph-based_Consensus_Maximization_among_Multiple_Supervised_and_Unsupervised_Models.html">102 nips-2009-Graph-based Consensus Maximization among Multiple Supervised and Unsupervised Models</a></p>
<p>14 0.077786945 <a title="251-tfidf-14" href="./nips-2009-Group_Sparse_Coding.html">104 nips-2009-Group Sparse Coding</a></p>
<p>15 0.076605573 <a title="251-tfidf-15" href="./nips-2009-Evaluating_multi-class_learning_strategies_in_a_generative_hierarchical_framework_for_object_detection.html">84 nips-2009-Evaluating multi-class learning strategies in a generative hierarchical framework for object detection</a></p>
<p>16 0.074064821 <a title="251-tfidf-16" href="./nips-2009-Occlusive_Components_Analysis.html">175 nips-2009-Occlusive Components Analysis</a></p>
<p>17 0.072820984 <a title="251-tfidf-17" href="./nips-2009-Beyond_Categories%3A_The_Visual_Memex_Model_for_Reasoning_About_Object_Relationships.html">44 nips-2009-Beyond Categories: The Visual Memex Model for Reasoning About Object Relationships</a></p>
<p>18 0.071952239 <a title="251-tfidf-18" href="./nips-2009-Semi-Supervised_Learning_in_Gigantic_Image_Collections.html">212 nips-2009-Semi-Supervised Learning in Gigantic Image Collections</a></p>
<p>19 0.061409809 <a title="251-tfidf-19" href="./nips-2009-An_Additive_Latent_Feature_Model_for_Transparent_Object_Recognition.html">28 nips-2009-An Additive Latent Feature Model for Transparent Object Recognition</a></p>
<p>20 0.060243398 <a title="251-tfidf-20" href="./nips-2009-A_Biologically_Plausible_Model_for_Rapid_Natural_Scene_Identification.html">6 nips-2009-A Biologically Plausible Model for Rapid Natural Scene Identification</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.183), (1, -0.153), (2, -0.164), (3, -0.003), (4, -0.042), (5, 0.216), (6, -0.065), (7, -0.123), (8, -0.08), (9, -0.039), (10, 0.03), (11, -0.05), (12, 0.075), (13, 0.018), (14, -0.08), (15, -0.002), (16, -0.056), (17, -0.127), (18, 0.17), (19, 0.004), (20, -0.058), (21, 0.038), (22, -0.019), (23, 0.162), (24, -0.026), (25, -0.072), (26, -0.046), (27, -0.013), (28, 0.094), (29, -0.009), (30, 0.082), (31, -0.08), (32, 0.048), (33, -0.089), (34, 0.027), (35, 0.289), (36, 0.033), (37, -0.031), (38, 0.031), (39, -0.022), (40, -0.087), (41, -0.022), (42, 0.059), (43, 0.057), (44, -0.003), (45, -0.069), (46, -0.097), (47, 0.169), (48, -0.071), (49, 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.90941554 <a title="251-lsi-1" href="./nips-2009-Unsupervised_Detection_of_Regions_of_Interest_Using_Iterative_Link_Analysis.html">251 nips-2009-Unsupervised Detection of Regions of Interest Using Iterative Link Analysis</a></p>
<p>Author: Gunhee Kim, Antonio Torralba</p><p>Abstract: This paper proposes a fast and scalable alternating optimization technique to detect regions of interest (ROIs) in cluttered Web images without labels. The proposed approach discovers highly probable regions of object instances by iteratively repeating the following two functions: (1) choose the exemplar set (i.e. a small number of highly ranked reference ROIs) across the dataset and (2) reﬁne the ROIs of each image with respect to the exemplar set. These two subproblems are formulated as ranking in two different similarity networks of ROI hypotheses by link analysis. The experiments with the PASCAL 06 dataset show that our unsupervised localization performance is better than one of state-of-the-art techniques and comparable to supervised methods. Also, we test the scalability of our approach with ﬁve objects in Flickr dataset consisting of more than 200K images. 1</p><p>2 0.80303735 <a title="251-lsi-2" href="./nips-2009-Hierarchical_Mixture_of_Classification_Experts_Uncovers_Interactions_between_Brain_Regions.html">110 nips-2009-Hierarchical Mixture of Classification Experts Uncovers Interactions between Brain Regions</a></p>
<p>Author: Bangpeng Yao, Dirk Walther, Diane Beck, Li Fei-fei</p><p>Abstract: The human brain can be described as containing a number of functional regions. These regions, as well as the connections between them, play a key role in information processing in the brain. However, most existing multi-voxel pattern analysis approaches either treat multiple regions as one large uniform region or several independent regions, ignoring the connections between them. In this paper we propose to model such connections in an Hidden Conditional Random Field (HCRF) framework, where the classiďŹ er of one region of interest (ROI) makes predictions based on not only its voxels but also the predictions from ROIs that it connects to. Furthermore, we propose a structural learning method in the HCRF framework to automatically uncover the connections between ROIs. We illustrate this approach with fMRI data acquired while human subjects viewed images of different natural scene categories and show that our model can improve the top-level (the classiďŹ er combining information from all ROIs) and ROI-level prediction accuracy, as well as uncover some meaningful connections between ROIs. 1</p><p>3 0.52792519 <a title="251-lsi-3" href="./nips-2009-Exploring_Functional_Connectivities_of_the_Human_Brain_using_Multivariate_Information_Analysis.html">86 nips-2009-Exploring Functional Connectivities of the Human Brain using Multivariate Information Analysis</a></p>
<p>Author: Barry Chai, Dirk Walther, Diane Beck, Li Fei-fei</p><p>Abstract: In this study, we present a new method for establishing fMRI pattern-based functional connectivity between brain regions by estimating their multivariate mutual information. Recent advances in the numerical approximation of highdimensional probability distributions allow us to successfully estimate mutual information from scarce fMRI data. We also show that selecting voxels based on the multivariate mutual information of local activity patterns with respect to ground truth labels leads to higher decoding accuracy than established voxel selection methods. We validate our approach with a 6-way scene categorization fMRI experiment. Multivariate information analysis is able to ﬁnd strong information sharing between PPA and RSC, consistent with existing neuroscience studies on scenes. Furthermore, an exploratory whole-brain analysis uncovered other brain regions that share information with the PPA-RSC scene network.</p><p>4 0.44803837 <a title="251-lsi-4" href="./nips-2009-Breaking_Boundaries_Between_Induction_Time_and_Diagnosis_Time_Active_Information_Acquisition.html">49 nips-2009-Breaking Boundaries Between Induction Time and Diagnosis Time Active Information Acquisition</a></p>
<p>Author: Ashish Kapoor, Eric Horvitz</p><p>Abstract: To date, the processes employed for active information acquisition during periods of learning and diagnosis have been considered as separate and have been applied in distinct phases of analysis. While active learning centers on the collection of information about training cases in order to build better predictive models, diagnosis uses ﬁxed predictive models for guiding the collection of observations about a speciﬁc test case at hand. We introduce a model and inferential methods that bridge these phases of analysis into a holistic approach to information acquisition that considers simultaneously the extension of the predictive model and the probing of a case at hand. The bridging of active learning and real-time diagnostic feature acquisition leads to a new class of policies for learning and diagnosis. 1</p><p>5 0.44287321 <a title="251-lsi-5" href="./nips-2009-Discriminative_Network_Models_of_Schizophrenia.html">70 nips-2009-Discriminative Network Models of Schizophrenia</a></p>
<p>Author: Irina Rish, Benjamin Thyreau, Bertrand Thirion, Marion Plaze, Marie-laure Paillere-martinot, Catherine Martelli, Jean-luc Martinot, Jean-baptiste Poline, Guillermo A. Cecchi</p><p>Abstract: Schizophrenia is a complex psychiatric disorder that has eluded a characterization in terms of local abnormalities of brain activity, and is hypothesized to affect the collective, “emergent” working of the brain. We propose a novel data-driven approach to capture emergent features using functional brain networks [4] extracted from fMRI data, and demonstrate its advantage over traditional region-of-interest (ROI) and local, task-speciﬁc linear activation analyzes. Our results suggest that schizophrenia is indeed associated with disruption of global brain properties related to its functioning as a network, which cannot be explained by alteration of local activation patterns. Moreover, further exploitation of interactions by sparse Markov Random Field classiﬁers shows clear gain over linear methods, such as Gaussian Naive Bayes and SVM, allowing to reach 86% accuracy (over 50% baseline - random guess), which is quite remarkable given that it is based on a single fMRI experiment using a simple auditory task. 1</p><p>6 0.44014525 <a title="251-lsi-6" href="./nips-2009-Learning_models_of_object_structure.html">133 nips-2009-Learning models of object structure</a></p>
<p>7 0.42459217 <a title="251-lsi-7" href="./nips-2009-Region-based_Segmentation_and_Object_Detection.html">201 nips-2009-Region-based Segmentation and Object Detection</a></p>
<p>8 0.42280468 <a title="251-lsi-8" href="./nips-2009-Evaluating_multi-class_learning_strategies_in_a_generative_hierarchical_framework_for_object_detection.html">84 nips-2009-Evaluating multi-class learning strategies in a generative hierarchical framework for object detection</a></p>
<p>9 0.40995666 <a title="251-lsi-9" href="./nips-2009-Segmenting_Scenes_by_Matching_Image_Composites.html">211 nips-2009-Segmenting Scenes by Matching Image Composites</a></p>
<p>10 0.40099615 <a title="251-lsi-10" href="./nips-2009-A_Bayesian_Model_for_Simultaneous_Image_Clustering%2C_Annotation_and_Object_Segmentation.html">5 nips-2009-A Bayesian Model for Simultaneous Image Clustering, Annotation and Object Segmentation</a></p>
<p>11 0.36754483 <a title="251-lsi-11" href="./nips-2009-Structured_output_regression_for_detection_with_partial_truncation.html">236 nips-2009-Structured output regression for detection with partial truncation</a></p>
<p>12 0.36211705 <a title="251-lsi-12" href="./nips-2009-Beyond_Categories%3A_The_Visual_Memex_Model_for_Reasoning_About_Object_Relationships.html">44 nips-2009-Beyond Categories: The Visual Memex Model for Reasoning About Object Relationships</a></p>
<p>13 0.36027074 <a title="251-lsi-13" href="./nips-2009-Graph-based_Consensus_Maximization_among_Multiple_Supervised_and_Unsupervised_Models.html">102 nips-2009-Graph-based Consensus Maximization among Multiple Supervised and Unsupervised Models</a></p>
<p>14 0.33267334 <a title="251-lsi-14" href="./nips-2009-Occlusive_Components_Analysis.html">175 nips-2009-Occlusive Components Analysis</a></p>
<p>15 0.32591885 <a title="251-lsi-15" href="./nips-2009-An_Additive_Latent_Feature_Model_for_Transparent_Object_Recognition.html">28 nips-2009-An Additive Latent Feature Model for Transparent Object Recognition</a></p>
<p>16 0.31146216 <a title="251-lsi-16" href="./nips-2009-Filtering_Abstract_Senses_From_Image_Search_Results.html">96 nips-2009-Filtering Abstract Senses From Image Search Results</a></p>
<p>17 0.30714551 <a title="251-lsi-17" href="./nips-2009-Maximin_affinity_learning_of_image_segmentation.html">149 nips-2009-Maximin affinity learning of image segmentation</a></p>
<p>18 0.30518666 <a title="251-lsi-18" href="./nips-2009-Fast_Image_Deconvolution_using_Hyper-Laplacian_Priors.html">93 nips-2009-Fast Image Deconvolution using Hyper-Laplacian Priors</a></p>
<p>19 0.2966271 <a title="251-lsi-19" href="./nips-2009-Exponential_Family_Graph_Matching_and_Ranking.html">87 nips-2009-Exponential Family Graph Matching and Ranking</a></p>
<p>20 0.2964856 <a title="251-lsi-20" href="./nips-2009-Group_Sparse_Coding.html">104 nips-2009-Group Sparse Coding</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(24, 0.03), (25, 0.079), (31, 0.01), (35, 0.079), (36, 0.065), (39, 0.44), (55, 0.012), (58, 0.044), (61, 0.011), (71, 0.032), (86, 0.082), (91, 0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.98298818 <a title="251-lda-1" href="./nips-2009-Hierarchical_Learning_of_Dimensional_Biases_in_Human_Categorization.html">109 nips-2009-Hierarchical Learning of Dimensional Biases in Human Categorization</a></p>
<p>Author: Adam Sanborn, Nick Chater, Katherine A. Heller</p><p>Abstract: Existing models of categorization typically represent to-be-classiﬁed items as points in a multidimensional space. While from a mathematical point of view, an inﬁnite number of basis sets can be used to represent points in this space, the choice of basis set is psychologically crucial. People generally choose the same basis dimensions – and have a strong preference to generalize along the axes of these dimensions, but not “diagonally”. What makes some choices of dimension special? We explore the idea that the dimensions used by people echo the natural variation in the environment. Speciﬁcally, we present a rational model that does not assume dimensions, but learns the same type of dimensional generalizations that people display. This bias is shaped by exposing the model to many categories with a structure hypothesized to be like those which children encounter. The learning behaviour of the model captures the developmental shift from roughly “isotropic” for children to the axis-aligned generalization that adults show. 1</p><p>2 0.94498456 <a title="251-lda-2" href="./nips-2009-Compositionality_of_optimal_control_laws.html">54 nips-2009-Compositionality of optimal control laws</a></p>
<p>Author: Emanuel Todorov</p><p>Abstract: We present a theory of compositionality in stochastic optimal control, showing how task-optimal controllers can be constructed from certain primitives. The primitives are themselves feedback controllers pursuing their own agendas. They are mixed in proportion to how much progress they are making towards their agendas and how compatible their agendas are with the present task. The resulting composite control law is provably optimal when the problem belongs to a certain class. This class is rather general and yet has a number of unique properties – one of which is that the Bellman equation can be made linear even for non-linear or discrete dynamics. This gives rise to the compositionality developed here. In the special case of linear dynamics and Gaussian noise our framework yields analytical solutions (i.e. non-linear mixtures of LQG controllers) without requiring the ﬁnal cost to be quadratic. More generally, a natural set of control primitives can be constructed by applying SVD to Green’s function of the Bellman equation. We illustrate the theory in the context of human arm movements. The ideas of optimality and compositionality are both very prominent in the ﬁeld of motor control, yet they have been difﬁcult to reconcile. Our work makes this possible.</p><p>3 0.92961621 <a title="251-lda-3" href="./nips-2009-Graph-based_Consensus_Maximization_among_Multiple_Supervised_and_Unsupervised_Models.html">102 nips-2009-Graph-based Consensus Maximization among Multiple Supervised and Unsupervised Models</a></p>
<p>Author: Jing Gao, Feng Liang, Wei Fan, Yizhou Sun, Jiawei Han</p><p>Abstract: Ensemble classiﬁers such as bagging, boosting and model averaging are known to have improved accuracy and robustness over a single model. Their potential, however, is limited in applications which have no access to raw data but to the meta-level model output. In this paper, we study ensemble learning with output from multiple supervised and unsupervised models, a topic where little work has been done. Although unsupervised models, such as clustering, do not directly generate label prediction for each individual, they provide useful constraints for the joint prediction of a set of related objects. We propose to consolidate a classiﬁcation solution by maximizing the consensus among both supervised predictions and unsupervised constraints. We cast this ensemble task as an optimization problem on a bipartite graph, where the objective function favors the smoothness of the prediction over the graph, as well as penalizing deviations from the initial labeling provided by supervised models. We solve this problem through iterative propagation of probability estimates among neighboring nodes. Our method can also be interpreted as conducting a constrained embedding in a transformed space, or a ranking on the graph. Experimental results on three real applications demonstrate the beneﬁts of the proposed method over existing alternatives1 . 1</p><p>same-paper 4 0.91532743 <a title="251-lda-4" href="./nips-2009-Unsupervised_Detection_of_Regions_of_Interest_Using_Iterative_Link_Analysis.html">251 nips-2009-Unsupervised Detection of Regions of Interest Using Iterative Link Analysis</a></p>
<p>Author: Gunhee Kim, Antonio Torralba</p><p>Abstract: This paper proposes a fast and scalable alternating optimization technique to detect regions of interest (ROIs) in cluttered Web images without labels. The proposed approach discovers highly probable regions of object instances by iteratively repeating the following two functions: (1) choose the exemplar set (i.e. a small number of highly ranked reference ROIs) across the dataset and (2) reﬁne the ROIs of each image with respect to the exemplar set. These two subproblems are formulated as ranking in two different similarity networks of ROI hypotheses by link analysis. The experiments with the PASCAL 06 dataset show that our unsupervised localization performance is better than one of state-of-the-art techniques and comparable to supervised methods. Also, we test the scalability of our approach with ﬁve objects in Flickr dataset consisting of more than 200K images. 1</p><p>5 0.90132397 <a title="251-lda-5" href="./nips-2009-Hierarchical_Mixture_of_Classification_Experts_Uncovers_Interactions_between_Brain_Regions.html">110 nips-2009-Hierarchical Mixture of Classification Experts Uncovers Interactions between Brain Regions</a></p>
<p>Author: Bangpeng Yao, Dirk Walther, Diane Beck, Li Fei-fei</p><p>Abstract: The human brain can be described as containing a number of functional regions. These regions, as well as the connections between them, play a key role in information processing in the brain. However, most existing multi-voxel pattern analysis approaches either treat multiple regions as one large uniform region or several independent regions, ignoring the connections between them. In this paper we propose to model such connections in an Hidden Conditional Random Field (HCRF) framework, where the classiďŹ er of one region of interest (ROI) makes predictions based on not only its voxels but also the predictions from ROIs that it connects to. Furthermore, we propose a structural learning method in the HCRF framework to automatically uncover the connections between ROIs. We illustrate this approach with fMRI data acquired while human subjects viewed images of different natural scene categories and show that our model can improve the top-level (the classiďŹ er combining information from all ROIs) and ROI-level prediction accuracy, as well as uncover some meaningful connections between ROIs. 1</p><p>6 0.6945101 <a title="251-lda-6" href="./nips-2009-Abstraction_and_Relational_learning.html">21 nips-2009-Abstraction and Relational learning</a></p>
<p>7 0.65513688 <a title="251-lda-7" href="./nips-2009-Matrix_Completion_from_Power-Law_Distributed_Samples.html">148 nips-2009-Matrix Completion from Power-Law Distributed Samples</a></p>
<p>8 0.64133531 <a title="251-lda-8" href="./nips-2009-Explaining_human_multiple_object_tracking_as_resource-constrained_approximate_inference_in_a_dynamic_probabilistic_model.html">85 nips-2009-Explaining human multiple object tracking as resource-constrained approximate inference in a dynamic probabilistic model</a></p>
<p>9 0.63800532 <a title="251-lda-9" href="./nips-2009-Beyond_Categories%3A_The_Visual_Memex_Model_for_Reasoning_About_Object_Relationships.html">44 nips-2009-Beyond Categories: The Visual Memex Model for Reasoning About Object Relationships</a></p>
<p>10 0.6369313 <a title="251-lda-10" href="./nips-2009-Modelling_Relational_Data_using_Bayesian_Clustered_Tensor_Factorization.html">155 nips-2009-Modelling Relational Data using Bayesian Clustered Tensor Factorization</a></p>
<p>11 0.63524204 <a title="251-lda-11" href="./nips-2009-Modeling_the_spacing_effect_in_sequential_category_learning.html">154 nips-2009-Modeling the spacing effect in sequential category learning</a></p>
<p>12 0.62721068 <a title="251-lda-12" href="./nips-2009-Learning_models_of_object_structure.html">133 nips-2009-Learning models of object structure</a></p>
<p>13 0.6185115 <a title="251-lda-13" href="./nips-2009-A_Game-Theoretic_Approach_to_Hypergraph_Clustering.html">9 nips-2009-A Game-Theoretic Approach to Hypergraph Clustering</a></p>
<p>14 0.6184563 <a title="251-lda-14" href="./nips-2009-Individuation%2C_Identification_and_Object_Discovery.html">115 nips-2009-Individuation, Identification and Object Discovery</a></p>
<p>15 0.61822599 <a title="251-lda-15" href="./nips-2009-Perceptual_Multistability_as_Markov_Chain_Monte_Carlo_Inference.html">188 nips-2009-Perceptual Multistability as Markov Chain Monte Carlo Inference</a></p>
<p>16 0.61039615 <a title="251-lda-16" href="./nips-2009-Learning_Brain_Connectivity_of_Alzheimer%27s_Disease_from_Neuroimaging_Data.html">125 nips-2009-Learning Brain Connectivity of Alzheimer's Disease from Neuroimaging Data</a></p>
<p>17 0.59979355 <a title="251-lda-17" href="./nips-2009-Functional_network_reorganization_in_motor_cortex_can_be_explained_by_reward-modulated_Hebbian_learning.html">99 nips-2009-Functional network reorganization in motor cortex can be explained by reward-modulated Hebbian learning</a></p>
<p>18 0.59861124 <a title="251-lda-18" href="./nips-2009-Human_Rademacher_Complexity.html">112 nips-2009-Human Rademacher Complexity</a></p>
<p>19 0.58364755 <a title="251-lda-19" href="./nips-2009-Exploring_Functional_Connectivities_of_the_Human_Brain_using_Multivariate_Information_Analysis.html">86 nips-2009-Exploring Functional Connectivities of the Human Brain using Multivariate Information Analysis</a></p>
<p>20 0.58152652 <a title="251-lda-20" href="./nips-2009-Quantification_and_the_language_of_thought.html">196 nips-2009-Quantification and the language of thought</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
