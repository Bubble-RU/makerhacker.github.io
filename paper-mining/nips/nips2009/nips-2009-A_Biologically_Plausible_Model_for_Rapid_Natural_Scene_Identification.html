<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>6 nips-2009-A Biologically Plausible Model for Rapid Natural Scene Identification</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-6" href="#">nips2009-6</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>6 nips-2009-A Biologically Plausible Model for Rapid Natural Scene Identification</h1>
<br/><p>Source: <a title="nips-2009-6-pdf" href="http://papers.nips.cc/paper/3785-a-biologically-plausible-model-for-rapid-natural-scene-identification.pdf">pdf</a></p><p>Author: Sennay Ghebreab, Steven Scholte, Victor Lamme, Arnold Smeulders</p><p>Abstract: Contrast statistics of the majority of natural images conform to a Weibull distribution. This property of natural images may facilitate efficient and very rapid extraction of a scene's visual gist. Here we investigated whether a neural response model based on the Wei bull contrast distribution captures visual information that humans use to rapidly identify natural scenes. In a learning phase, we measured EEG activity of 32 subjects viewing brief flashes of 700 natural scenes. From these neural measurements and the contrast statistics of the natural image stimuli, we derived an across subject Wei bull response model. We used this model to predict the EEG responses to 100 new natural scenes and estimated which scene the subject viewed by finding the best match between the model predictions and the observed EEG responses. In almost 90 percent of the cases our model accurately predicted the observed scene. Moreover, in most failed cases, the scene mistaken for the observed scene was visually similar to the observed scene itself. Similar results were obtained in a separate experiment in which 16 other subjects where presented with artificial occlusion models of natural images. Together, these results suggest that Weibull contrast statistics of natural images contain a considerable amount of visual gist information to warrant rapid image identification.</p><p>Reference: <a title="nips-2009-6-reference" href="../nips2009_reference/nips-2009-A_Biologically_Plausible_Model_for_Rapid_Natural_Scene_Identification_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('weibul', 0.459), ('bul', 0.375), ('eeg', 0.346), ('lgn', 0.257), ('filt', 0.256), ('im', 0.246), ('wei', 0.231), ('contrast', 0.231), ('respons', 0.198), ('scen', 0.144), ('octav', 0.114), ('gain', 0.089), ('scholte', 0.086), ('ge', 0.081), ('spat', 0.079), ('channel', 0.069), ('subject', 0.065), ('bank', 0.065), ('amsterdam', 0.064), ('netherland', 0.061)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="6-tfidf-1" href="./nips-2009-A_Biologically_Plausible_Model_for_Rapid_Natural_Scene_Identification.html">6 nips-2009-A Biologically Plausible Model for Rapid Natural Scene Identification</a></p>
<p>Author: Sennay Ghebreab, Steven Scholte, Victor Lamme, Arnold Smeulders</p><p>Abstract: Contrast statistics of the majority of natural images conform to a Weibull distribution. This property of natural images may facilitate efficient and very rapid extraction of a scene's visual gist. Here we investigated whether a neural response model based on the Wei bull contrast distribution captures visual information that humans use to rapidly identify natural scenes. In a learning phase, we measured EEG activity of 32 subjects viewing brief flashes of 700 natural scenes. From these neural measurements and the contrast statistics of the natural image stimuli, we derived an across subject Wei bull response model. We used this model to predict the EEG responses to 100 new natural scenes and estimated which scene the subject viewed by finding the best match between the model predictions and the observed EEG responses. In almost 90 percent of the cases our model accurately predicted the observed scene. Moreover, in most failed cases, the scene mistaken for the observed scene was visually similar to the observed scene itself. Similar results were obtained in a separate experiment in which 16 other subjects where presented with artificial occlusion models of natural images. Together, these results suggest that Weibull contrast statistics of natural images contain a considerable amount of visual gist information to warrant rapid image identification.</p><p>2 0.19579981 <a title="6-tfidf-2" href="./nips-2009-Optimizing_Multi-Class_Spatio-Spectral_Filters_via_Bayes_Error_Estimation_for_EEG_Classification.html">184 nips-2009-Optimizing Multi-Class Spatio-Spectral Filters via Bayes Error Estimation for EEG Classification</a></p>
<p>Author: Wenming Zheng, Zhouchen Lin</p><p>Abstract: The method of common spatio-spectral patterns (CSSPs) is an extension of common spatial patterns (CSPs) by utilizing the technique of delay embedding to alleviate the adverse effects of noises and artifacts on the electroencephalogram (EEG) classiﬁcation. Although the CSSPs method has shown to be more powerful than the CSPs method in the EEG classiﬁcation, this method is only suitable for two-class EEG classiﬁcation problems. In this paper, we generalize the two-class CSSPs method to multi-class cases. To this end, we ﬁrst develop a novel theory of multi-class Bayes error estimation and then present the multi-class CSSPs (MCSSPs) method based on this Bayes error theoretical framework. By minimizing the estimated closed-form Bayes error, we obtain the optimal spatio-spectral ﬁlters of MCSSPs. To demonstrate the effectiveness of the proposed method, we conduct extensive experiments on the BCI competition 2005 data set. The experimental results show that our method signiﬁcantly outperforms the previous multi-class CSPs (MCSPs) methods in the EEG classiﬁcation.</p><p>3 0.18565282 <a title="6-tfidf-3" href="./nips-2009-Segmenting_Scenes_by_Matching_Image_Composites.html">211 nips-2009-Segmenting Scenes by Matching Image Composites</a></p>
<p>Author: Bryan Russell, Alyosha Efros, Josef Sivic, Bill Freeman, Andrew Zisserman</p><p>Abstract: In this paper, we investigate how, given an image, similar images sharing the same global description can help with unsupervised scene segmentation. In contrast to recent work in semantic alignment of scenes, we allow an input image to be explained by partial matches of similar scenes. This allows for a better explanation of the input scenes. We perform MRF-based segmentation that optimizes over matches, while respecting boundary information. The recovered segments are then used to re-query a large database of images to retrieve better matches for the target regions. We show improved performance in detecting the principal occluding and contact boundaries for the scene over previous methods on data gathered from the LabelMe database.</p><p>4 0.11509564 <a title="6-tfidf-4" href="./nips-2009-Time-Varying_Dynamic_Bayesian_Networks.html">246 nips-2009-Time-Varying Dynamic Bayesian Networks</a></p>
<p>Author: Le Song, Mladen Kolar, Eric P. Xing</p><p>Abstract: Directed graphical models such as Bayesian networks are a favored formalism for modeling the dependency structures in complex multivariate systems such as those encountered in biology and neural science. When a system is undergoing dynamic transformation, temporally rewiring networks are needed for capturing the dynamic causal inﬂuences between covariates. In this paper, we propose time-varying dynamic Bayesian networks (TV-DBN) for modeling the structurally varying directed dependency structures underlying non-stationary biological/neural time series. This is a challenging problem due the non-stationarity and sample scarcity of time series data. We present a kernel reweighted 1 -regularized auto-regressive procedure for this problem which enjoys nice properties such as computational efﬁciency and provable asymptotic consistency. To our knowledge, this is the ﬁrst practical and statistically sound method for structure learning of TVDBNs. We applied TV-DBNs to time series measurements during yeast cell cycle and brain response to visual stimuli. In both cases, TV-DBNs reveal interesting dynamics underlying the respective biological systems. 1</p><p>5 0.11440372 <a title="6-tfidf-5" href="./nips-2009-Subject_independent_EEG-based_BCI_decoding.html">237 nips-2009-Subject independent EEG-based BCI decoding</a></p>
<p>Author: Siamac Fazli, Cristian Grozea, Marton Danoczy, Benjamin Blankertz, Florin Popescu, Klaus-Robert Müller</p><p>Abstract: In the quest to make Brain Computer Interfacing (BCI) more usable, dry electrodes have emerged that get rid of the initial 30 minutes required for placing an electrode cap. Another time consuming step is the required individualized adaptation to the BCI user, which involves another 30 minutes calibration for assessing a subject’s brain signature. In this paper we aim to also remove this calibration proceedure from BCI setup time by means of machine learning. In particular, we harvest a large database of EEG BCI motor imagination recordings (83 subjects) for constructing a library of subject-speciﬁc spatio-temporal ﬁlters and derive a subject independent BCI classiﬁer. Our ofﬂine results indicate that BCI-na¨ve ı users could start real-time BCI use with no prior calibration at only a very moderate performance loss.</p><p>6 0.10759836 <a title="6-tfidf-6" href="./nips-2009-The_%27tree-dependent_components%27_of_natural_scenes_are_edge_filters.html">241 nips-2009-The 'tree-dependent components' of natural scenes are edge filters</a></p>
<p>7 0.099152498 <a title="6-tfidf-7" href="./nips-2009-Region-based_Segmentation_and_Object_Detection.html">201 nips-2009-Region-based Segmentation and Object Detection</a></p>
<p>8 0.098176271 <a title="6-tfidf-8" href="./nips-2009-Filtering_Abstract_Senses_From_Image_Search_Results.html">96 nips-2009-Filtering Abstract Senses From Image Search Results</a></p>
<p>9 0.095571846 <a title="6-tfidf-9" href="./nips-2009-Extending_Phase_Mechanism_to_Differential_Motion_Opponency_for_Motion_Pop-out.html">88 nips-2009-Extending Phase Mechanism to Differential Motion Opponency for Motion Pop-out</a></p>
<p>10 0.090125866 <a title="6-tfidf-10" href="./nips-2009-Estimating_image_bases_for_visual_image_reconstruction_from_human_brain_activity.html">83 nips-2009-Estimating image bases for visual image reconstruction from human brain activity</a></p>
<p>11 0.089939319 <a title="6-tfidf-11" href="./nips-2009-Statistical_Models_of_Linear_and_Nonlinear_Contextual_Interactions_in_Early_Visual_Processing.html">231 nips-2009-Statistical Models of Linear and Nonlinear Contextual Interactions in Early Visual Processing</a></p>
<p>12 0.089576021 <a title="6-tfidf-12" href="./nips-2009-Bayesian_estimation_of_orientation_preference_maps.html">43 nips-2009-Bayesian estimation of orientation preference maps</a></p>
<p>13 0.088909701 <a title="6-tfidf-13" href="./nips-2009-Learning_transport_operators_for_image_manifolds.html">137 nips-2009-Learning transport operators for image manifolds</a></p>
<p>14 0.084611356 <a title="6-tfidf-14" href="./nips-2009-A_Bayesian_Model_for_Simultaneous_Image_Clustering%2C_Annotation_and_Object_Segmentation.html">5 nips-2009-A Bayesian Model for Simultaneous Image Clustering, Annotation and Object Segmentation</a></p>
<p>15 0.082005739 <a title="6-tfidf-15" href="./nips-2009-Constructing_Topological_Maps_using_Markov_Random_Fields_and_Loop-Closure_Detection.html">58 nips-2009-Constructing Topological Maps using Markov Random Fields and Loop-Closure Detection</a></p>
<p>16 0.081572585 <a title="6-tfidf-16" href="./nips-2009-Occlusive_Components_Analysis.html">175 nips-2009-Occlusive Components Analysis</a></p>
<p>17 0.076325715 <a title="6-tfidf-17" href="./nips-2009-No_evidence_for_active_sparsification_in_the_visual_cortex.html">164 nips-2009-No evidence for active sparsification in the visual cortex</a></p>
<p>18 0.075047381 <a title="6-tfidf-18" href="./nips-2009-Learning_models_of_object_structure.html">133 nips-2009-Learning models of object structure</a></p>
<p>19 0.071447529 <a title="6-tfidf-19" href="./nips-2009-A_joint_maximum-entropy_model_for_binary_neural_population_patterns_and_continuous_signals.html">19 nips-2009-A joint maximum-entropy model for binary neural population patterns and continuous signals</a></p>
<p>20 0.069809839 <a title="6-tfidf-20" href="./nips-2009-Augmenting_Feature-driven_fMRI_Analyses%3A_Semi-supervised_learning_and_resting_state_activity.html">38 nips-2009-Augmenting Feature-driven fMRI Analyses: Semi-supervised learning and resting state activity</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.183), (1, -0.097), (2, -0.154), (3, 0.01), (4, -0.116), (5, 0.072), (6, -0.032), (7, 0.016), (8, -0.14), (9, -0.056), (10, -0.014), (11, -0.007), (12, -0.052), (13, -0.018), (14, 0.028), (15, 0.047), (16, -0.063), (17, 0.041), (18, 0.013), (19, -0.05), (20, 0.049), (21, 0.083), (22, -0.132), (23, 0.147), (24, 0.062), (25, -0.017), (26, -0.11), (27, 0.038), (28, -0.057), (29, -0.052), (30, 0.011), (31, -0.065), (32, -0.022), (33, -0.088), (34, 0.15), (35, -0.053), (36, 0.037), (37, 0.034), (38, 0.101), (39, -0.128), (40, 0.043), (41, 0.066), (42, 0.031), (43, 0.026), (44, 0.018), (45, 0.008), (46, -0.008), (47, -0.002), (48, 0.144), (49, 0.001)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.90188867 <a title="6-lsi-1" href="./nips-2009-A_Biologically_Plausible_Model_for_Rapid_Natural_Scene_Identification.html">6 nips-2009-A Biologically Plausible Model for Rapid Natural Scene Identification</a></p>
<p>Author: Sennay Ghebreab, Steven Scholte, Victor Lamme, Arnold Smeulders</p><p>Abstract: Contrast statistics of the majority of natural images conform to a Weibull distribution. This property of natural images may facilitate efficient and very rapid extraction of a scene's visual gist. Here we investigated whether a neural response model based on the Wei bull contrast distribution captures visual information that humans use to rapidly identify natural scenes. In a learning phase, we measured EEG activity of 32 subjects viewing brief flashes of 700 natural scenes. From these neural measurements and the contrast statistics of the natural image stimuli, we derived an across subject Wei bull response model. We used this model to predict the EEG responses to 100 new natural scenes and estimated which scene the subject viewed by finding the best match between the model predictions and the observed EEG responses. In almost 90 percent of the cases our model accurately predicted the observed scene. Moreover, in most failed cases, the scene mistaken for the observed scene was visually similar to the observed scene itself. Similar results were obtained in a separate experiment in which 16 other subjects where presented with artificial occlusion models of natural images. Together, these results suggest that Weibull contrast statistics of natural images contain a considerable amount of visual gist information to warrant rapid image identification.</p><p>2 0.65843207 <a title="6-lsi-2" href="./nips-2009-Optimizing_Multi-Class_Spatio-Spectral_Filters_via_Bayes_Error_Estimation_for_EEG_Classification.html">184 nips-2009-Optimizing Multi-Class Spatio-Spectral Filters via Bayes Error Estimation for EEG Classification</a></p>
<p>Author: Wenming Zheng, Zhouchen Lin</p><p>Abstract: The method of common spatio-spectral patterns (CSSPs) is an extension of common spatial patterns (CSPs) by utilizing the technique of delay embedding to alleviate the adverse effects of noises and artifacts on the electroencephalogram (EEG) classiﬁcation. Although the CSSPs method has shown to be more powerful than the CSPs method in the EEG classiﬁcation, this method is only suitable for two-class EEG classiﬁcation problems. In this paper, we generalize the two-class CSSPs method to multi-class cases. To this end, we ﬁrst develop a novel theory of multi-class Bayes error estimation and then present the multi-class CSSPs (MCSSPs) method based on this Bayes error theoretical framework. By minimizing the estimated closed-form Bayes error, we obtain the optimal spatio-spectral ﬁlters of MCSSPs. To demonstrate the effectiveness of the proposed method, we conduct extensive experiments on the BCI competition 2005 data set. The experimental results show that our method signiﬁcantly outperforms the previous multi-class CSPs (MCSPs) methods in the EEG classiﬁcation.</p><p>3 0.65015906 <a title="6-lsi-3" href="./nips-2009-Subject_independent_EEG-based_BCI_decoding.html">237 nips-2009-Subject independent EEG-based BCI decoding</a></p>
<p>Author: Siamac Fazli, Cristian Grozea, Marton Danoczy, Benjamin Blankertz, Florin Popescu, Klaus-Robert Müller</p><p>Abstract: In the quest to make Brain Computer Interfacing (BCI) more usable, dry electrodes have emerged that get rid of the initial 30 minutes required for placing an electrode cap. Another time consuming step is the required individualized adaptation to the BCI user, which involves another 30 minutes calibration for assessing a subject’s brain signature. In this paper we aim to also remove this calibration proceedure from BCI setup time by means of machine learning. In particular, we harvest a large database of EEG BCI motor imagination recordings (83 subjects) for constructing a library of subject-speciﬁc spatio-temporal ﬁlters and derive a subject independent BCI classiﬁer. Our ofﬂine results indicate that BCI-na¨ve ı users could start real-time BCI use with no prior calibration at only a very moderate performance loss.</p><p>4 0.55080181 <a title="6-lsi-4" href="./nips-2009-Statistical_Models_of_Linear_and_Nonlinear_Contextual_Interactions_in_Early_Visual_Processing.html">231 nips-2009-Statistical Models of Linear and Nonlinear Contextual Interactions in Early Visual Processing</a></p>
<p>Author: Ruben Coen-cagli, Peter Dayan, Odelia Schwartz</p><p>Abstract: A central hypothesis about early visual processing is that it represents inputs in a coordinate system matched to the statistics of natural scenes. Simple versions of this lead to Gabor–like receptive ﬁelds and divisive gain modulation from local surrounds; these have led to inﬂuential neural and psychological models of visual processing. However, these accounts are based on an incomplete view of the visual context surrounding each point. Here, we consider an approximate model of linear and non–linear correlations between the responses of spatially distributed Gaborlike receptive ﬁelds, which, when trained on an ensemble of natural scenes, uniﬁes a range of spatial context effects. The full model accounts for neural surround data in primary visual cortex (V1), provides a statistical foundation for perceptual phenomena associated with Li’s (2002) hypothesis that V1 builds a saliency map, and ﬁts data on the tilt illusion. 1</p><p>5 0.53550833 <a title="6-lsi-5" href="./nips-2009-Segmenting_Scenes_by_Matching_Image_Composites.html">211 nips-2009-Segmenting Scenes by Matching Image Composites</a></p>
<p>Author: Bryan Russell, Alyosha Efros, Josef Sivic, Bill Freeman, Andrew Zisserman</p><p>Abstract: In this paper, we investigate how, given an image, similar images sharing the same global description can help with unsupervised scene segmentation. In contrast to recent work in semantic alignment of scenes, we allow an input image to be explained by partial matches of similar scenes. This allows for a better explanation of the input scenes. We perform MRF-based segmentation that optimizes over matches, while respecting boundary information. The recovered segments are then used to re-query a large database of images to retrieve better matches for the target regions. We show improved performance in detecting the principal occluding and contact boundaries for the scene over previous methods on data gathered from the LabelMe database.</p><p>6 0.51785785 <a title="6-lsi-6" href="./nips-2009-Occlusive_Components_Analysis.html">175 nips-2009-Occlusive Components Analysis</a></p>
<p>7 0.49440223 <a title="6-lsi-7" href="./nips-2009-Estimating_image_bases_for_visual_image_reconstruction_from_human_brain_activity.html">83 nips-2009-Estimating image bases for visual image reconstruction from human brain activity</a></p>
<p>8 0.46826732 <a title="6-lsi-8" href="./nips-2009-The_%27tree-dependent_components%27_of_natural_scenes_are_edge_filters.html">241 nips-2009-The 'tree-dependent components' of natural scenes are edge filters</a></p>
<p>9 0.45674485 <a title="6-lsi-9" href="./nips-2009-Fast_Image_Deconvolution_using_Hyper-Laplacian_Priors.html">93 nips-2009-Fast Image Deconvolution using Hyper-Laplacian Priors</a></p>
<p>10 0.45272878 <a title="6-lsi-10" href="./nips-2009-A_Bayesian_Model_for_Simultaneous_Image_Clustering%2C_Annotation_and_Object_Segmentation.html">5 nips-2009-A Bayesian Model for Simultaneous Image Clustering, Annotation and Object Segmentation</a></p>
<p>11 0.43992677 <a title="6-lsi-11" href="./nips-2009-Nonparametric_Bayesian_Texture_Learning_and_Synthesis.html">172 nips-2009-Nonparametric Bayesian Texture Learning and Synthesis</a></p>
<p>12 0.43555838 <a title="6-lsi-12" href="./nips-2009-Sequential_effects_reflect_parallel_learning_of_multiple_environmental_regularities.html">216 nips-2009-Sequential effects reflect parallel learning of multiple environmental regularities</a></p>
<p>13 0.43534857 <a title="6-lsi-13" href="./nips-2009-An_Additive_Latent_Feature_Model_for_Transparent_Object_Recognition.html">28 nips-2009-An Additive Latent Feature Model for Transparent Object Recognition</a></p>
<p>14 0.42914516 <a title="6-lsi-14" href="./nips-2009-Filtering_Abstract_Senses_From_Image_Search_Results.html">96 nips-2009-Filtering Abstract Senses From Image Search Results</a></p>
<p>15 0.42568561 <a title="6-lsi-15" href="./nips-2009-Region-based_Segmentation_and_Object_Detection.html">201 nips-2009-Region-based Segmentation and Object Detection</a></p>
<p>16 0.42231175 <a title="6-lsi-16" href="./nips-2009-Learning_transport_operators_for_image_manifolds.html">137 nips-2009-Learning transport operators for image manifolds</a></p>
<p>17 0.42207292 <a title="6-lsi-17" href="./nips-2009-Bayesian_estimation_of_orientation_preference_maps.html">43 nips-2009-Bayesian estimation of orientation preference maps</a></p>
<p>18 0.42035094 <a title="6-lsi-18" href="./nips-2009-An_Online_Algorithm_for_Large_Scale_Image_Similarity_Learning.html">32 nips-2009-An Online Algorithm for Large Scale Image Similarity Learning</a></p>
<p>19 0.41517183 <a title="6-lsi-19" href="./nips-2009-Structural_inference_affects_depth_perception_in_the_context_of_potential_occlusion.html">235 nips-2009-Structural inference affects depth perception in the context of potential occlusion</a></p>
<p>20 0.4024868 <a title="6-lsi-20" href="./nips-2009-Slow%2C_Decorrelated_Features_for_Pretraining_Complex_Cell-like_Networks.html">219 nips-2009-Slow, Decorrelated Features for Pretraining Complex Cell-like Networks</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(4, 0.019), (9, 0.227), (11, 0.032), (31, 0.11), (37, 0.032), (49, 0.342), (60, 0.061), (69, 0.011), (96, 0.056)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.73411238 <a title="6-lda-1" href="./nips-2009-A_Biologically_Plausible_Model_for_Rapid_Natural_Scene_Identification.html">6 nips-2009-A Biologically Plausible Model for Rapid Natural Scene Identification</a></p>
<p>Author: Sennay Ghebreab, Steven Scholte, Victor Lamme, Arnold Smeulders</p><p>Abstract: Contrast statistics of the majority of natural images conform to a Weibull distribution. This property of natural images may facilitate efficient and very rapid extraction of a scene's visual gist. Here we investigated whether a neural response model based on the Wei bull contrast distribution captures visual information that humans use to rapidly identify natural scenes. In a learning phase, we measured EEG activity of 32 subjects viewing brief flashes of 700 natural scenes. From these neural measurements and the contrast statistics of the natural image stimuli, we derived an across subject Wei bull response model. We used this model to predict the EEG responses to 100 new natural scenes and estimated which scene the subject viewed by finding the best match between the model predictions and the observed EEG responses. In almost 90 percent of the cases our model accurately predicted the observed scene. Moreover, in most failed cases, the scene mistaken for the observed scene was visually similar to the observed scene itself. Similar results were obtained in a separate experiment in which 16 other subjects where presented with artificial occlusion models of natural images. Together, these results suggest that Weibull contrast statistics of natural images contain a considerable amount of visual gist information to warrant rapid image identification.</p><p>2 0.71622682 <a title="6-lda-2" href="./nips-2009-Exploring_Functional_Connectivities_of_the_Human_Brain_using_Multivariate_Information_Analysis.html">86 nips-2009-Exploring Functional Connectivities of the Human Brain using Multivariate Information Analysis</a></p>
<p>Author: Barry Chai, Dirk Walther, Diane Beck, Li Fei-fei</p><p>Abstract: In this study, we present a new method for establishing fMRI pattern-based functional connectivity between brain regions by estimating their multivariate mutual information. Recent advances in the numerical approximation of highdimensional probability distributions allow us to successfully estimate mutual information from scarce fMRI data. We also show that selecting voxels based on the multivariate mutual information of local activity patterns with respect to ground truth labels leads to higher decoding accuracy than established voxel selection methods. We validate our approach with a 6-way scene categorization fMRI experiment. Multivariate information analysis is able to ﬁnd strong information sharing between PPA and RSC, consistent with existing neuroscience studies on scenes. Furthermore, an exploratory whole-brain analysis uncovered other brain regions that share information with the PPA-RSC scene network.</p><p>3 0.7151404 <a title="6-lda-3" href="./nips-2009-Evaluating_multi-class_learning_strategies_in_a_generative_hierarchical_framework_for_object_detection.html">84 nips-2009-Evaluating multi-class learning strategies in a generative hierarchical framework for object detection</a></p>
<p>Author: Sanja Fidler, Marko Boben, Ales Leonardis</p><p>Abstract: Multi-class object learning and detection is a challenging problem due to the large number of object classes and their high visual variability. Specialized detectors usually excel in performance, while joint representations optimize sharing and reduce inference time — but are complex to train. Conveniently, sequential class learning cuts down training time by transferring existing knowledge to novel classes, but cannot fully exploit the shareability of features among object classes and might depend on ordering of classes during learning. In hierarchical frameworks these issues have been little explored. In this paper, we provide a rigorous experimental analysis of various multiple object class learning strategies within a generative hierarchical framework. Speciﬁcally, we propose, evaluate and compare three important types of multi-class learning: 1.) independent training of individual categories, 2.) joint training of classes, and 3.) sequential learning of classes. We explore and compare their computational behavior (space and time) and detection performance as a function of the number of learned object classes on several recognition datasets. We show that sequential training achieves the best trade-off between inference and training times at a comparable detection performance and could thus be used to learn the classes on a larger scale. 1</p><p>4 0.63469881 <a title="6-lda-4" href="./nips-2009-Hierarchical_Mixture_of_Classification_Experts_Uncovers_Interactions_between_Brain_Regions.html">110 nips-2009-Hierarchical Mixture of Classification Experts Uncovers Interactions between Brain Regions</a></p>
<p>Author: Bangpeng Yao, Dirk Walther, Diane Beck, Li Fei-fei</p><p>Abstract: The human brain can be described as containing a number of functional regions. These regions, as well as the connections between them, play a key role in information processing in the brain. However, most existing multi-voxel pattern analysis approaches either treat multiple regions as one large uniform region or several independent regions, ignoring the connections between them. In this paper we propose to model such connections in an Hidden Conditional Random Field (HCRF) framework, where the classiďŹ er of one region of interest (ROI) makes predictions based on not only its voxels but also the predictions from ROIs that it connects to. Furthermore, we propose a structural learning method in the HCRF framework to automatically uncover the connections between ROIs. We illustrate this approach with fMRI data acquired while human subjects viewed images of different natural scene categories and show that our model can improve the top-level (the classiďŹ er combining information from all ROIs) and ROI-level prediction accuracy, as well as uncover some meaningful connections between ROIs. 1</p><p>5 0.62416029 <a title="6-lda-5" href="./nips-2009-Discriminative_Network_Models_of_Schizophrenia.html">70 nips-2009-Discriminative Network Models of Schizophrenia</a></p>
<p>Author: Irina Rish, Benjamin Thyreau, Bertrand Thirion, Marion Plaze, Marie-laure Paillere-martinot, Catherine Martelli, Jean-luc Martinot, Jean-baptiste Poline, Guillermo A. Cecchi</p><p>Abstract: Schizophrenia is a complex psychiatric disorder that has eluded a characterization in terms of local abnormalities of brain activity, and is hypothesized to affect the collective, “emergent” working of the brain. We propose a novel data-driven approach to capture emergent features using functional brain networks [4] extracted from fMRI data, and demonstrate its advantage over traditional region-of-interest (ROI) and local, task-speciﬁc linear activation analyzes. Our results suggest that schizophrenia is indeed associated with disruption of global brain properties related to its functioning as a network, which cannot be explained by alteration of local activation patterns. Moreover, further exploitation of interactions by sparse Markov Random Field classiﬁers shows clear gain over linear methods, such as Gaussian Naive Bayes and SVM, allowing to reach 86% accuracy (over 50% baseline - random guess), which is quite remarkable given that it is based on a single fMRI experiment using a simple auditory task. 1</p><p>6 0.61798275 <a title="6-lda-6" href="./nips-2009-Boosting_with_Spatial_Regularization.html">47 nips-2009-Boosting with Spatial Regularization</a></p>
<p>7 0.61290783 <a title="6-lda-7" href="./nips-2009-Learning_in_Markov_Random_Fields_using_Tempered_Transitions.html">132 nips-2009-Learning in Markov Random Fields using Tempered Transitions</a></p>
<p>8 0.61290711 <a title="6-lda-8" href="./nips-2009-Bayesian_Source_Localization_with_the_Multivariate_Laplace_Prior.html">41 nips-2009-Bayesian Source Localization with the Multivariate Laplace Prior</a></p>
<p>9 0.61152399 <a title="6-lda-9" href="./nips-2009-Estimating_image_bases_for_visual_image_reconstruction_from_human_brain_activity.html">83 nips-2009-Estimating image bases for visual image reconstruction from human brain activity</a></p>
<p>10 0.61148202 <a title="6-lda-10" href="./nips-2009-Learning_transport_operators_for_image_manifolds.html">137 nips-2009-Learning transport operators for image manifolds</a></p>
<p>11 0.61025447 <a title="6-lda-11" href="./nips-2009-Kernels_and_learning_curves_for_Gaussian_process_regression_on_random_graphs.html">120 nips-2009-Kernels and learning curves for Gaussian process regression on random graphs</a></p>
<p>12 0.60993797 <a title="6-lda-12" href="./nips-2009-An_Online_Algorithm_for_Large_Scale_Image_Similarity_Learning.html">32 nips-2009-An Online Algorithm for Large Scale Image Similarity Learning</a></p>
<p>13 0.60982078 <a title="6-lda-13" href="./nips-2009-Gaussian_process_regression_with_Student-t_likelihood.html">100 nips-2009-Gaussian process regression with Student-t likelihood</a></p>
<p>14 0.6096037 <a title="6-lda-14" href="./nips-2009-Code-specific_policy_gradient_rules_for_spiking_neurons.html">52 nips-2009-Code-specific policy gradient rules for spiking neurons</a></p>
<p>15 0.60955215 <a title="6-lda-15" href="./nips-2009-Lattice_Regression.html">124 nips-2009-Lattice Regression</a></p>
<p>16 0.60926974 <a title="6-lda-16" href="./nips-2009-Statistical_Analysis_of_Semi-Supervised_Learning%3A_The_Limit_of_Infinite_Unlabelled_Data.html">229 nips-2009-Statistical Analysis of Semi-Supervised Learning: The Limit of Infinite Unlabelled Data</a></p>
<p>17 0.60896796 <a title="6-lda-17" href="./nips-2009-Conditional_Neural_Fields.html">56 nips-2009-Conditional Neural Fields</a></p>
<p>18 0.60894895 <a title="6-lda-18" href="./nips-2009-Speeding_up_Magnetic_Resonance_Image_Acquisition_by_Bayesian_Multi-Slice_Adaptive_Compressed_Sensing.html">228 nips-2009-Speeding up Magnetic Resonance Image Acquisition by Bayesian Multi-Slice Adaptive Compressed Sensing</a></p>
<p>19 0.60850459 <a title="6-lda-19" href="./nips-2009-Nonlinear_Learning_using_Local_Coordinate_Coding.html">169 nips-2009-Nonlinear Learning using Local Coordinate Coding</a></p>
<p>20 0.60837919 <a title="6-lda-20" href="./nips-2009-Sharing_Features_among_Dynamical_Systems_with_Beta_Processes.html">217 nips-2009-Sharing Features among Dynamical Systems with Beta Processes</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
