<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>18 nips-2009-A Stochastic approximation method for inference in probabilistic graphical models</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-18" href="#">nips2009-18</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>18 nips-2009-A Stochastic approximation method for inference in probabilistic graphical models</h1>
<br/><p>Source: <a title="nips-2009-18-pdf" href="http://papers.nips.cc/paper/3823-a-stochastic-approximation-method-for-inference-in-probabilistic-graphical-models.pdf">pdf</a></p><p>Author: Peter Carbonetto, Matthew King, Firas Hamze</p><p>Abstract: We describe a new algorithmic framework for inference in probabilistic models, and apply it to inference for latent Dirichlet allocation (LDA). Our framework adopts the methodology of variational inference, but unlike existing variational methods such as mean ﬁeld and expectation propagation it is not restricted to tractable classes of approximating distributions. Our approach can also be viewed as a “population-based” sequential Monte Carlo (SMC) method, but unlike existing SMC methods there is no need to design the artiﬁcial sequence of distributions. Signiﬁcantly, our framework oﬀers a principled means to exchange the variance of an importance sampling estimate for the bias incurred through variational approximation. We conduct experiments on a diﬃcult inference problem in population genetics, a problem that is related to inference for LDA. The results of these experiments suggest that our method can oﬀer improvements in stability and accuracy over existing methods, and at a comparable cost. 1</p><p>Reference: <a title="nips-2009-18-reference" href="../nips2009_reference/nips-2009-A_Stochastic_approximation_method_for_inference_in_probabilistic_graphical_models_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 A Stochastic approximation method for inference in probabilistic graphical models  Peter Carbonetto Dept. [sent-1, score-0.198]
</p><p>2 ca  Abstract We describe a new algorithmic framework for inference in probabilistic models, and apply it to inference for latent Dirichlet allocation (LDA). [sent-15, score-0.272]
</p><p>3 Our framework adopts the methodology of variational inference, but unlike existing variational methods such as mean ﬁeld and expectation propagation it is not restricted to tractable classes of approximating distributions. [sent-16, score-0.772]
</p><p>4 Signiﬁcantly, our framework oﬀers a principled means to exchange the variance of an importance sampling estimate for the bias incurred through variational approximation. [sent-18, score-0.624]
</p><p>5 We conduct experiments on a diﬃcult inference problem in population genetics, a problem that is related to inference for LDA. [sent-19, score-0.36]
</p><p>6 1  Introduction  Over the past several decades, researchers in many diﬀerent ﬁelds—statistics, economics, physics, genetics and machine learning—have focused on coming up with more accurate and more eﬃcient approximate solutions to intractable probabilistic inference problems. [sent-21, score-0.191]
</p><p>7 The key idea behind variational inference is to come up with a family of approximating distributions p(x; θ) that have “nice” analytic properties, then to ˆ optimize some criterion in order to ﬁnd the distribution parameterized by θ that most closely matches the target posterior p(x). [sent-24, score-0.592]
</p><p>8 All variational inference algorithms, including belief propagation and its generalizations [32], expectation propagation [22] and mean ﬁeld [19], can be derived from a common objective, the Kullback-Leibler (K-L) divergence [9]. [sent-25, score-0.503]
</p><p>9 The major drawback of variational methods is that the best approximating distribution may still impose an unrealistic or questionable factorization, leading to excessively biased estimates (see Fig. [sent-26, score-0.431]
</p><p>10 In this paper, we describe a new variational method that does not have this limitation: it adopts the methodology of variational inference without being restricted to tractable classes of approximate 1  distributions (see Fig. [sent-28, score-0.758]
</p><p>11 The catch is that the variational objective (the K-L divergence) is diﬃcult to optimize because its gradient cannot be computed exactly. [sent-30, score-0.349]
</p><p>12 Large gradient descent steps may quickly lead to a degenerate sample, so we introduce a mechanism that safeguards the variance of the Monte Carlo estimate at each iteration (Sec. [sent-32, score-0.236]
</p><p>13 This variance safeguard mechanism does not make the standard eﬀective sample size (ESS) approximation [14], hence it is likely to more accurately monitor the variance of the sample. [sent-35, score-0.425]
</p><p>14 Indirectly, the variance safeguard provides a way to obtain an estimator that has low variance in exchange for (hopefully small) bias. [sent-36, score-0.397]
</p><p>15 To our knowledge, our algorithm is the ﬁrst general means of achieving such a trade-oﬀ and, in so doing, it draws meaningful connections between Monte Carlo and variational methods. [sent-37, score-0.294]
</p><p>16 The advantage of our stochastic approximation method with respect to other variational methods is rather straightforward: it does not restrict the class of variational densities by making assumptions about their structure. [sent-38, score-0.861]
</p><p>17 However, whe advantage of our approach compared to Monte Carlo methods such as annealed importance sampling (AIS) [24] is less obvious. [sent-39, score-0.248]
</p><p>18 It is our conjecture that this automatic selection, when combined with the variance safeguard, is more eﬃcient than setting the sequence by hand, say, via tempered transitions [12, 18, 24]. [sent-42, score-0.195]
</p><p>19 We illustrate our approach on the problem of inferring population structure from a cohort of genotyped sequences using Figure 1: The guiding princithe mixture model of Pritchard et al. [sent-45, score-0.174]
</p><p>20 For many population genetics applications, such as wildlife conser- interest p(x), yet remains within vation [8], it is crucial to accurately characterize the conﬁdence the deﬁned set of tractable probin a solution. [sent-49, score-0.312]
</p><p>21 The implementation of our approach on the population structure model demonstrates improvements in both accuracy and reliability over MCMC and SMC alternatives, and at a comparable computational cost. [sent-55, score-0.174]
</p><p>22 The latent Dirichlet allocation (LDA) model [4] is very similar to the population structure model of [26], under the assumption of ﬁxed Dirichlet priors. [sent-56, score-0.26]
</p><p>23 [11] use a variational approximation to formulate a Metropolis-Hastings proposal. [sent-61, score-0.356]
</p><p>24 Recent work on adaptive MCMC [1] combines ideas from both stochastic approximation and MCMC to automatically learn better proposal distributions. [sent-62, score-0.261]
</p><p>25 Our work is also unrelated to the paper [20] with a similar title, where stochastic approximation is applied to improving the Wang-Landau algorithm. [sent-63, score-0.212]
</p><p>26 Younes [33] employs stochastic approximation to compute the maximum likelihood estimate of an undirected graphical model. [sent-64, score-0.289]
</p><p>27 Also, the cross-entropy method [10] uses importance sampling and optimization for inference, but exhibits no similarity to our work beyond that. [sent-65, score-0.196]
</p><p>28 ) Also, each word has a latent topic indicator zdi ∈ {1, . [sent-76, score-0.214]
</p><p>29 Observing the jth vocabulary item in the kth topic occurs with probability βkj . [sent-80, score-0.191]
</p><p>30 Implementations of approximate inference in LDA include MCMC [15, 26] and variational inference with a mean ﬁeld approximation [4, 30]. [sent-85, score-0.542]
</p><p>31 From the importance sampling identity [2], we can obtain an unbiased estimate of (2) by drawing n samples from a proposal q(x) and evaluating importance weights w(x) = p(x)/q(x). [sent-91, score-0.568]
</p><p>32 (Usually p(x) can only be evaluated up to a normalizing constant, in which case the asymptotically unbiased normalized importance sampling estimator [2] is used instead. [sent-92, score-0.27]
</p><p>33 s=1 w(x  1 n  (3)  Unless great care is taken is in designing the proposal q(x), the Monte Carlo estimator will exhibit astronomically high variance for all but the smallest problems. [sent-94, score-0.183]
</p><p>34 Instead, we construct a Monte Carlo estimate (3) by replacing p(x) with an alternate target p(x; θ) that resembles it, so ˆ that all importance weights are evaluated with respect to this alternate target. [sent-95, score-0.304]
</p><p>35 ) This new estimator is biased, but we minimize the bias by solving a variational optimization problem. [sent-99, score-0.328]
</p><p>36 - Stochastic approximation step: take gradient descent step θk = θk−1 −αk gk , where gk is a Monte Carlo estimate of the gradient of the K-L divergence, and αk is the variancesafeguarded step size. [sent-104, score-0.488]
</p><p>37 - SMC step: update samples and importance weights to reﬂect new density p(x; θk ). [sent-105, score-0.283]
</p><p>38 At each iteration, the algorithm selects a new target p(x; θk ) by optimizing ˆ the variational objective. [sent-110, score-0.373]
</p><p>39 Next, the samples are revised in order to compute the stochastic gradient gk+1 at the next iteration. [sent-111, score-0.263]
</p><p>40 Since SMC is eﬀectively a framework for conducting importance sampling over a sequence of distributions, we describe a “variance safeguard” mechanism (Sec. [sent-112, score-0.23]
</p><p>41 5) that directly regulates increases in variance at each step by preventing the iterates θk from moving too quickly. [sent-114, score-0.183]
</p><p>42 Since this is a stochastic approximation method, asymptotic convergence of θk to a minimizer of the objective is guaranteed under basic theory of stochastic approximation [29]. [sent-116, score-0.424]
</p><p>43 And asymptotic variance results from the SMC literature [12] tell us that the Monte Carlo estimates will converge almost surely to the target expectation (2) so long as p(x; θk ) ˆ approaches p(x). [sent-118, score-0.243]
</p><p>44 A crucial condition is that the stochastic estimates of the gradient be unbiased. [sent-119, score-0.269]
</p><p>45 To recap, the probabilistic inference recipe we propose has ﬁve main ingredients: one, a family of approximating distributions that admits the target (Sec. [sent-121, score-0.298]
</p><p>46 1); two, a variational optimization problem framed using the K-L divergence measure (Sec. [sent-123, score-0.342]
</p><p>47 2); three, a stochastic approximation method for ﬁnding a solution to the variational optimization problem (Sec. [sent-125, score-0.506]
</p><p>48 3); four, the implementation of a sequential Monte Carlo method for constructing stochastic estimates of the gradient of the variational objective (Sec 3. [sent-127, score-0.61]
</p><p>49 4); and ﬁve, a way to safeguard the variance of the importance weights at each iteration of the stochastic approximation algorithm (Sec. [sent-128, score-0.666]
</p><p>50 1  The family of approximating distributions  The ﬁrst implementation step is the design of a family of approximating distributions p(x; θ) ˆ parameterized by vector θ. [sent-132, score-0.295]
</p><p>51 2  The variational objective  The Kullback Leibler (K-L) divergence [9] asymmetrically measures the distance between the target distribution p(x) = p(x; θ⋆ ) and approximating distribution p(x; θ), ˆ ˆ ⋆ ⋆ F (θ) = Ep( · ; θ) [a(X)], θ − θ + c(θ ) − c(θ), (6) ˆ the optimal choice being θ = θ⋆ . [sent-153, score-0.494]
</p><p>52 With a collection of samples x(s) with importance weights w(s) , for s = 1, . [sent-157, score-0.249]
</p><p>53 3  Stochastic approximation  Instead of insisting on making progress toward a minimizer of f (θ) at every iteration, as in gradient descent, stochastic approximation only requires that progress be achieved on average. [sent-165, score-0.329]
</p><p>54 The Robbins-Monro algorithm [28] iteratively adjusts the control variable θ according to θk+1 = θk − αk gk , (9) where gk is a noisy observation of f (θk ), and {αk } is a sequence of step sizes. [sent-166, score-0.273]
</p><p>55 Due to poor conditioning, we advocate replacing the gradient descent −1 search direction ∆θk = −gk in (9) by the quasi-Newton search direction ∆θk = −Bk gk , where Bk is a damped quasi-Newton (BFGS) approximation of the Hessian [25]. [sent-169, score-0.256]
</p><p>56 4  Sequential Monte Carlo  In the ﬁrst step of SMC, samples x1(s) are drawn from a proposal density q1 (x) = p(x; θ1 ) so ˆ that the initial importance weights are uniform. [sent-176, score-0.375]
</p><p>57 The insight of [12] is that if we choose the densities pk (x1:k ) wisely, we can update the importance weights wk (x1:k ) = ˜ ˜ pk (x1:k )/˜k (x1:k ) without having to look at the entire history. [sent-178, score-0.305]
</p><p>58 5  Safeguarding the variance  A key component of the algorithm is a mechanism that enables the practitioner to regulate the variance of the importance weights and, by extension, the variance of the Monte Carlo estimate of E[ϕ(X)]. [sent-189, score-0.525]
</p><p>59 The trouble with taking a full step (9) is that the Gibbs kernel (12) may be unable to eﬀectively migrate the particles toward the new target, in which case the the importance weights will overcompensate for this failure, quickly leading to a degenerate population. [sent-190, score-0.274]
</p><p>60 Note that since our variance safeguard scheme is myopic, the behaviour of the algorithm can be sensitive to the number of iterations. [sent-214, score-0.263]
</p><p>61 In our experience, the quadratic approximation to the importance weights (13) was unstable as it occasionally recommended strange step sizes, but a naive importance weight update without Rao-Blackwellization yielded a reliable bound on (14). [sent-218, score-0.446]
</p><p>62 Since the importance weights initially have zero variance, no positive step size will satisfy (14). [sent-220, score-0.234]
</p><p>63 Resampling will still be necessary over long sequences to prevent the population from degenerating. [sent-222, score-0.174]
</p><p>64 population text corpus structure documents individuals Microsatellite genetic markers have been used to determine the ⇔ topics demes genealogy of human populations, and to assess individuals’ anlanguages loci cestry in inferring disease risks [16]. [sent-225, score-0.533]
</p><p>65 The problem is that all vocabulary alleles these tasks require deﬁning a priori population structure. [sent-226, score-0.306]
</p><p>66 [26] oﬀers a solution to this Figure 5: Correspondence beconundrum by simultaneously identifying both patterns of pop- tween LDA [4] and the populaulation subdivision and the ancestry of individuals from highly tion structure [26] models. [sent-228, score-0.261]
</p><p>67 We used the software CoaSim [21] to simulate the evolution of genetic markers following a coalescent process. [sent-235, score-0.365]
</p><p>68 The coalescent is a lineage of alleles in a sample traced backward in time to their common ancestor allele, and the coalescent process is the stochastic process that generates the genealogy [17]. [sent-236, score-0.814]
</p><p>69 We introduced divergence events at various coalescent times (see Fig. [sent-237, score-0.281]
</p><p>70 We simulated the markers twice with scaled mutation rates of 2 and 1 2 , and for each rate we simulated 60 samples from the coalescent process (15 diploid individuals from each of the 4 populations). [sent-240, score-0.63]
</p><p>71 6  Figure 7: Variance in estimates of the admixture distance and admixture level taken over 20 trials. [sent-243, score-0.576]
</p><p>72 The goal is to obtain posterior estimates that recover the correct population structure (Fig. [sent-244, score-0.238]
</p><p>73 The admixture disFigure 6: The structured coalescent process tance between individuals d and d′ is with divergence events at coalescent times T = K (17) 0, 1 , 1, 2. [sent-247, score-0.95]
</p><p>74 The width of the branches represents ϕ(τd , τd′ ) ≡ 1 k=1 |τdk − τd′ k |, 2 2 eﬀective population size, and the arrow points and the admixture level of the dth individual is backward in time. [sent-248, score-0.488]
</p><p>75 We compared our algorithm to MCMC as implemented in the software Structure [26], and to another SMC algorithm, annealed importance sampling (AIS) [24], with a uniform tempering schedule. [sent-251, score-0.248]
</p><p>76 Also, note that our intent was not to present an exhaustive comparison of Monte Carlo methods, so we did not compare to population MCMC [18], for example, which has advantages similar to AIS. [sent-253, score-0.174]
</p><p>77 9 for the stochastic interior-point method, safeguards β = 0. [sent-258, score-0.197]
</p><p>78 We set the initial iterate of stochastic approximation to ⋆ ⋆ φ = γ = ηkj = ηj . [sent-262, score-0.212]
</p><p>79 7 shows the variance in the estimates of the admixture level and admixture distance over the independent trials. [sent-268, score-0.676]
</p><p>80 To produce these plots, at every K we took the individual d or pair (d, d′ ) that exhibited the most variance in the estimate of E[ϕ(τd , τd′ )] and E[ψ(τd )]. [sent-269, score-0.197]
</p><p>81 What we observe is that the stochastic approximation method produced signiﬁcantly more consistent estimates in almost all cases, whereas AIS oﬀered little or no improvement over MCMC. [sent-270, score-0.276]
</p><p>82 8 shows estimates from MCMC and stochastic approximation selected trials under a mutation 1 rate of 2 and K = 4 (left-hand side), and under a mutation rate of 2 and K = 3 (right-hand side). [sent-273, score-0.515]
</p><p>83 The mean and standard deviation of the admixture distance statistic are drawn as matrices. [sent-275, score-0.302]
</p><p>84 The 60 rows and 60 columns in each matrix correspond to individuals sorted by their true population label; the rows and columns are ordered so that they correspond to the populations 1 through 4 in Fig. [sent-276, score-0.452]
</p><p>85 In each “mean” matrix, a light square means that two individuals share little ancestry in common, and a dark square means that two individuals have similar ancestry. [sent-278, score-0.441]
</p><p>86 ”) of the admixture distance statistic for two independent trials and at two diﬀerent simulation settings. [sent-284, score-0.355]
</p><p>87 it successfully assigned individuals to their coalescent populations based on the sampled alleles w. [sent-288, score-0.604]
</p><p>88 As expected, the individuals from populations 3 and 4 were hardest to distinguish, hence the high standard deviation in the bottom-right entries of the matrix. [sent-289, score-0.278]
</p><p>89 The results of the second trial are less satisfying: MCMC failed to distinguish between individuals from populations 3 and 4, and it decided rather arbitrarily to partition the samples originating from population 2. [sent-290, score-0.593]
</p><p>90 This trend is repeated in the more challenging inference scenario with K = 3 and a mutation rate of 2 (right-hand side). [sent-297, score-0.186]
</p><p>91 The stochastic approximation method also exhibited some variance under these conditions, but importantly it did not place nearly so much conﬁdence in its solutions; observe the high standard deviation in the matrix entries corresponding to the individuals from population 3. [sent-300, score-0.729]
</p><p>92 5  Conclusions and discussion  In this paper, we proposed a new approach to probabilistic inference grounded on variational, Monte Carlo and stochastic approximation methodology. [sent-301, score-0.305]
</p><p>93 We demonstrated that our sophisticated method pays oﬀ in terms of producing more consistent, reliable estimates for a real and challenging inference problem in population genetics. [sent-302, score-0.331]
</p><p>94 Some of the components such as the variance safeguard have not been independently validated, so we cannot fully attest to how critical they are, at least beyond the motivation we already gave. [sent-303, score-0.263]
</p><p>95 We have argued for the generality of our inference approach, but ultimately the success of our scheme hinges on a good choice of the variational approximation. [sent-305, score-0.387]
</p><p>96 An interior-point stochastic approximation method and an L1-regularized delta rule. [sent-342, score-0.212]
</p><p>97 Gene genealogies, variation and evolution: a primer in coalescent theory. [sent-423, score-0.233]
</p><p>98 CoaSim: a ﬂexible environment for simulating genetic data under coalescent models. [sent-454, score-0.299]
</p><p>99 A collapsed variational Bayesian inference algorithm for latent Dirichlet allocation. [sent-505, score-0.433]
</p><p>100 Stochastic processes on graphs with cycles: geometric and variational approaches. [sent-510, score-0.294]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('variational', 0.294), ('admixture', 0.256), ('smc', 0.244), ('coalescent', 0.233), ('carlo', 0.193), ('monte', 0.193), ('individuals', 0.18), ('mcmc', 0.18), ('population', 0.174), ('safeguard', 0.163), ('xa', 0.159), ('importance', 0.15), ('stochastic', 0.15), ('zdi', 0.122), ('lda', 0.118), ('ais', 0.102), ('variance', 0.1), ('genetics', 0.098), ('kj', 0.098), ('populations', 0.098), ('gk', 0.098), ('alleles', 0.093), ('mutation', 0.093), ('inference', 0.093), ('xb', 0.087), ('ancestry', 0.081), ('wdi', 0.081), ('sk', 0.08), ('target', 0.079), ('dirichlet', 0.077), ('approximating', 0.073), ('di', 0.073), ('mkj', 0.07), ('pritchard', 0.07), ('genetic', 0.066), ('markers', 0.066), ('estimates', 0.064), ('exhibited', 0.063), ('approximation', 0.062), ('tempered', 0.061), ('densities', 0.061), ('kk', 0.06), ('backward', 0.058), ('erent', 0.058), ('samples', 0.058), ('gradient', 0.055), ('family', 0.053), ('wk', 0.053), ('trials', 0.053), ('annealed', 0.052), ('proposal', 0.049), ('divergence', 0.048), ('xk', 0.048), ('doucet', 0.047), ('ess', 0.047), ('sequential', 0.047), ('draw', 0.047), ('dk', 0.047), ('coasim', 0.047), ('genealogy', 0.047), ('microsatellite', 0.047), ('proximating', 0.047), ('safeguarded', 0.047), ('safeguards', 0.047), ('schierup', 0.047), ('stephens', 0.047), ('latent', 0.046), ('sampling', 0.046), ('topic', 0.046), ('statistic', 0.046), ('freitas', 0.045), ('trial', 0.043), ('step', 0.043), ('graphical', 0.043), ('lk', 0.042), ('weights', 0.041), ('carbonetto', 0.041), ('damped', 0.041), ('tractable', 0.04), ('unbiased', 0.04), ('allocation', 0.04), ('particles', 0.04), ('failed', 0.04), ('answers', 0.04), ('iterates', 0.04), ('vocabulary', 0.039), ('ep', 0.038), ('adopts', 0.037), ('ndk', 0.037), ('markov', 0.037), ('kth', 0.036), ('jth', 0.036), ('ectively', 0.035), ('eld', 0.034), ('estimator', 0.034), ('propagation', 0.034), ('sequence', 0.034), ('estimate', 0.034), ('item', 0.034), ('density', 0.034)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999994 <a title="18-tfidf-1" href="./nips-2009-A_Stochastic_approximation_method_for_inference_in_probabilistic_graphical_models.html">18 nips-2009-A Stochastic approximation method for inference in probabilistic graphical models</a></p>
<p>Author: Peter Carbonetto, Matthew King, Firas Hamze</p><p>Abstract: We describe a new algorithmic framework for inference in probabilistic models, and apply it to inference for latent Dirichlet allocation (LDA). Our framework adopts the methodology of variational inference, but unlike existing variational methods such as mean ﬁeld and expectation propagation it is not restricted to tractable classes of approximating distributions. Our approach can also be viewed as a “population-based” sequential Monte Carlo (SMC) method, but unlike existing SMC methods there is no need to design the artiﬁcial sequence of distributions. Signiﬁcantly, our framework oﬀers a principled means to exchange the variance of an importance sampling estimate for the bias incurred through variational approximation. We conduct experiments on a diﬃcult inference problem in population genetics, a problem that is related to inference for LDA. The results of these experiments suggest that our method can oﬀer improvements in stability and accuracy over existing methods, and at a comparable cost. 1</p><p>2 0.17549804 <a title="18-tfidf-2" href="./nips-2009-Variational_Inference_for_the_Nested_Chinese_Restaurant_Process.html">255 nips-2009-Variational Inference for the Nested Chinese Restaurant Process</a></p>
<p>Author: Chong Wang, David M. Blei</p><p>Abstract: The nested Chinese restaurant process (nCRP) is a powerful nonparametric Bayesian model for learning tree-based hierarchies from data. Since its posterior distribution is intractable, current inference methods have all relied on MCMC sampling. In this paper, we develop an alternative inference technique based on variational methods. To employ variational methods, we derive a tree-based stick-breaking construction of the nCRP mixture model, and a novel variational algorithm that efﬁciently explores a posterior over a large set of combinatorial structures. We demonstrate the use of this approach for text and hand written digits modeling, where we show we can adapt the nCRP to continuous data as well. 1</p><p>3 0.14565077 <a title="18-tfidf-3" href="./nips-2009-Learning_in_Markov_Random_Fields_using_Tempered_Transitions.html">132 nips-2009-Learning in Markov Random Fields using Tempered Transitions</a></p>
<p>Author: Ruslan Salakhutdinov</p><p>Abstract: Markov random ﬁelds (MRF’s), or undirected graphical models, provide a powerful framework for modeling complex dependencies among random variables. Maximum likelihood learning in MRF’s is hard due to the presence of the global normalizing constant. In this paper we consider a class of stochastic approximation algorithms of the Robbins-Monro type that use Markov chain Monte Carlo to do approximate maximum likelihood learning. We show that using MCMC operators based on tempered transitions enables the stochastic approximation algorithm to better explore highly multimodal distributions, which considerably improves parameter estimates in large, densely-connected MRF’s. Our results on MNIST and NORB datasets demonstrate that we can successfully learn good generative models of high-dimensional, richly structured data that perform well on digit and object recognition tasks.</p><p>4 0.13571766 <a title="18-tfidf-4" href="./nips-2009-Learning_Bregman_Distance_Functions_and_Its_Application_for_Semi-Supervised_Clustering.html">126 nips-2009-Learning Bregman Distance Functions and Its Application for Semi-Supervised Clustering</a></p>
<p>Author: Lei Wu, Rong Jin, Steven C. Hoi, Jianke Zhu, Nenghai Yu</p><p>Abstract: Learning distance functions with side information plays a key role in many machine learning and data mining applications. Conventional approaches often assume a Mahalanobis distance function. These approaches are limited in two aspects: (i) they are computationally expensive (even infeasible) for high dimensional data because the size of the metric is in the square of dimensionality; (ii) they assume a ﬁxed metric for the entire input space and therefore are unable to handle heterogeneous data. In this paper, we propose a novel scheme that learns nonlinear Bregman distance functions from side information using a nonparametric approach that is similar to support vector machines. The proposed scheme avoids the assumption of ﬁxed metric by implicitly deriving a local distance from the Hessian matrix of a convex function that is used to generate the Bregman distance function. We also present an efﬁcient learning algorithm for the proposed scheme for distance function learning. The extensive experiments with semi-supervised clustering show the proposed technique (i) outperforms the state-of-the-art approaches for distance function learning, and (ii) is computationally efﬁcient for high dimensional data. 1</p><p>5 0.13510877 <a title="18-tfidf-5" href="./nips-2009-Decoupling_Sparsity_and_Smoothness_in_the_Discrete_Hierarchical_Dirichlet_Process.html">65 nips-2009-Decoupling Sparsity and Smoothness in the Discrete Hierarchical Dirichlet Process</a></p>
<p>Author: Chong Wang, David M. Blei</p><p>Abstract: We present a nonparametric hierarchical Bayesian model of document collections that decouples sparsity and smoothness in the component distributions (i.e., the “topics”). In the sparse topic model (sparseTM), each topic is represented by a bank of selector variables that determine which terms appear in the topic. Thus each topic is associated with a subset of the vocabulary, and topic smoothness is modeled on this subset. We develop an efﬁcient Gibbs sampler for the sparseTM that includes a general-purpose method for sampling from a Dirichlet mixture with a combinatorial number of components. We demonstrate the sparseTM on four real-world datasets. Compared to traditional approaches, the empirical results will show that sparseTMs give better predictive performance with simpler inferred models. 1</p><p>6 0.11614585 <a title="18-tfidf-6" href="./nips-2009-Replicated_Softmax%3A_an_Undirected_Topic_Model.html">204 nips-2009-Replicated Softmax: an Undirected Topic Model</a></p>
<p>7 0.11134259 <a title="18-tfidf-7" href="./nips-2009-Gaussian_process_regression_with_Student-t_likelihood.html">100 nips-2009-Gaussian process regression with Student-t likelihood</a></p>
<p>8 0.10924574 <a title="18-tfidf-8" href="./nips-2009-Sensitivity_analysis_in_HMMs_with_application_to_likelihood_maximization.html">215 nips-2009-Sensitivity analysis in HMMs with application to likelihood maximization</a></p>
<p>9 0.10890643 <a title="18-tfidf-9" href="./nips-2009-Bayesian_Nonparametric_Models_on_Decomposable_Graphs.html">40 nips-2009-Bayesian Nonparametric Models on Decomposable Graphs</a></p>
<p>10 0.10584427 <a title="18-tfidf-10" href="./nips-2009-Rethinking_LDA%3A_Why_Priors_Matter.html">205 nips-2009-Rethinking LDA: Why Priors Matter</a></p>
<p>11 0.10451233 <a title="18-tfidf-11" href="./nips-2009-Perceptual_Multistability_as_Markov_Chain_Monte_Carlo_Inference.html">188 nips-2009-Perceptual Multistability as Markov Chain Monte Carlo Inference</a></p>
<p>12 0.099593915 <a title="18-tfidf-12" href="./nips-2009-Neural_Implementation_of_Hierarchical_Bayesian_Inference_by_Importance_Sampling.html">162 nips-2009-Neural Implementation of Hierarchical Bayesian Inference by Importance Sampling</a></p>
<p>13 0.09678185 <a title="18-tfidf-13" href="./nips-2009-Parallel_Inference_for_Latent_Dirichlet_Allocation_on_Graphics_Processing_Units.html">186 nips-2009-Parallel Inference for Latent Dirichlet Allocation on Graphics Processing Units</a></p>
<p>14 0.096668132 <a title="18-tfidf-14" href="./nips-2009-Neurometric_function_analysis_of_population_codes.html">163 nips-2009-Neurometric function analysis of population codes</a></p>
<p>15 0.093045592 <a title="18-tfidf-15" href="./nips-2009-Particle-based_Variational_Inference_for_Continuous_Systems.html">187 nips-2009-Particle-based Variational Inference for Continuous Systems</a></p>
<p>16 0.091910541 <a title="18-tfidf-16" href="./nips-2009-Free_energy_score_space.html">97 nips-2009-Free energy score space</a></p>
<p>17 0.08954227 <a title="18-tfidf-17" href="./nips-2009-The_Wisdom_of_Crowds_in_the_Recollection_of_Order_Information.html">244 nips-2009-The Wisdom of Crowds in the Recollection of Order Information</a></p>
<p>18 0.086335033 <a title="18-tfidf-18" href="./nips-2009-Variational_Gaussian-process_factor_analysis_for_modeling_spatio-temporal_data.html">254 nips-2009-Variational Gaussian-process factor analysis for modeling spatio-temporal data</a></p>
<p>19 0.083954923 <a title="18-tfidf-19" href="./nips-2009-Convergent_Temporal-Difference_Learning_with_Arbitrary_Smooth_Function_Approximation.html">60 nips-2009-Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation</a></p>
<p>20 0.083099738 <a title="18-tfidf-20" href="./nips-2009-A_Bayesian_Analysis_of_Dynamics_in_Free_Recall.html">4 nips-2009-A Bayesian Analysis of Dynamics in Free Recall</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.251), (1, -0.053), (2, 0.03), (3, -0.119), (4, 0.123), (5, -0.208), (6, 0.027), (7, 0.047), (8, -0.08), (9, 0.034), (10, -0.04), (11, -0.008), (12, 0.014), (13, 0.045), (14, 0.06), (15, -0.089), (16, -0.117), (17, -0.078), (18, -0.011), (19, -0.082), (20, -0.1), (21, -0.045), (22, 0.035), (23, -0.05), (24, 0.065), (25, -0.067), (26, -0.035), (27, 0.098), (28, -0.042), (29, -0.018), (30, 0.133), (31, -0.03), (32, -0.193), (33, 0.024), (34, 0.029), (35, 0.138), (36, 0.016), (37, -0.027), (38, 0.082), (39, 0.016), (40, -0.036), (41, 0.053), (42, 0.089), (43, -0.185), (44, -0.033), (45, 0.062), (46, 0.102), (47, -0.014), (48, -0.031), (49, 0.007)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95791101 <a title="18-lsi-1" href="./nips-2009-A_Stochastic_approximation_method_for_inference_in_probabilistic_graphical_models.html">18 nips-2009-A Stochastic approximation method for inference in probabilistic graphical models</a></p>
<p>Author: Peter Carbonetto, Matthew King, Firas Hamze</p><p>Abstract: We describe a new algorithmic framework for inference in probabilistic models, and apply it to inference for latent Dirichlet allocation (LDA). Our framework adopts the methodology of variational inference, but unlike existing variational methods such as mean ﬁeld and expectation propagation it is not restricted to tractable classes of approximating distributions. Our approach can also be viewed as a “population-based” sequential Monte Carlo (SMC) method, but unlike existing SMC methods there is no need to design the artiﬁcial sequence of distributions. Signiﬁcantly, our framework oﬀers a principled means to exchange the variance of an importance sampling estimate for the bias incurred through variational approximation. We conduct experiments on a diﬃcult inference problem in population genetics, a problem that is related to inference for LDA. The results of these experiments suggest that our method can oﬀer improvements in stability and accuracy over existing methods, and at a comparable cost. 1</p><p>2 0.65674502 <a title="18-lsi-2" href="./nips-2009-Variational_Inference_for_the_Nested_Chinese_Restaurant_Process.html">255 nips-2009-Variational Inference for the Nested Chinese Restaurant Process</a></p>
<p>Author: Chong Wang, David M. Blei</p><p>Abstract: The nested Chinese restaurant process (nCRP) is a powerful nonparametric Bayesian model for learning tree-based hierarchies from data. Since its posterior distribution is intractable, current inference methods have all relied on MCMC sampling. In this paper, we develop an alternative inference technique based on variational methods. To employ variational methods, we derive a tree-based stick-breaking construction of the nCRP mixture model, and a novel variational algorithm that efﬁciently explores a posterior over a large set of combinatorial structures. We demonstrate the use of this approach for text and hand written digits modeling, where we show we can adapt the nCRP to continuous data as well. 1</p><p>3 0.61863691 <a title="18-lsi-3" href="./nips-2009-Parallel_Inference_for_Latent_Dirichlet_Allocation_on_Graphics_Processing_Units.html">186 nips-2009-Parallel Inference for Latent Dirichlet Allocation on Graphics Processing Units</a></p>
<p>Author: Feng Yan, Ningyi Xu, Yuan Qi</p><p>Abstract: The recent emergence of Graphics Processing Units (GPUs) as general-purpose parallel computing devices provides us with new opportunities to develop scalable learning methods for massive data. In this work, we consider the problem of parallelizing two inference methods on GPUs for latent Dirichlet Allocation (LDA) models, collapsed Gibbs sampling (CGS) and collapsed variational Bayesian (CVB). To address limited memory constraints on GPUs, we propose a novel data partitioning scheme that effectively reduces the memory cost. This partitioning scheme also balances the computational cost on each multiprocessor and enables us to easily avoid memory access conﬂicts. We use data streaming to handle extremely large datasets. Extensive experiments showed that our parallel inference methods consistently produced LDA models with the same predictive power as sequential training methods did but with 26x speedup for CGS and 196x speedup for CVB on a GPU with 30 multiprocessors. The proposed partitioning scheme and data streaming make our approach scalable with more multiprocessors. Furthermore, they can be used as general techniques to parallelize other machine learning models. 1</p><p>4 0.58998603 <a title="18-lsi-4" href="./nips-2009-Decoupling_Sparsity_and_Smoothness_in_the_Discrete_Hierarchical_Dirichlet_Process.html">65 nips-2009-Decoupling Sparsity and Smoothness in the Discrete Hierarchical Dirichlet Process</a></p>
<p>Author: Chong Wang, David M. Blei</p><p>Abstract: We present a nonparametric hierarchical Bayesian model of document collections that decouples sparsity and smoothness in the component distributions (i.e., the “topics”). In the sparse topic model (sparseTM), each topic is represented by a bank of selector variables that determine which terms appear in the topic. Thus each topic is associated with a subset of the vocabulary, and topic smoothness is modeled on this subset. We develop an efﬁcient Gibbs sampler for the sparseTM that includes a general-purpose method for sampling from a Dirichlet mixture with a combinatorial number of components. We demonstrate the sparseTM on four real-world datasets. Compared to traditional approaches, the empirical results will show that sparseTMs give better predictive performance with simpler inferred models. 1</p><p>5 0.57426375 <a title="18-lsi-5" href="./nips-2009-Learning_in_Markov_Random_Fields_using_Tempered_Transitions.html">132 nips-2009-Learning in Markov Random Fields using Tempered Transitions</a></p>
<p>Author: Ruslan Salakhutdinov</p><p>Abstract: Markov random ﬁelds (MRF’s), or undirected graphical models, provide a powerful framework for modeling complex dependencies among random variables. Maximum likelihood learning in MRF’s is hard due to the presence of the global normalizing constant. In this paper we consider a class of stochastic approximation algorithms of the Robbins-Monro type that use Markov chain Monte Carlo to do approximate maximum likelihood learning. We show that using MCMC operators based on tempered transitions enables the stochastic approximation algorithm to better explore highly multimodal distributions, which considerably improves parameter estimates in large, densely-connected MRF’s. Our results on MNIST and NORB datasets demonstrate that we can successfully learn good generative models of high-dimensional, richly structured data that perform well on digit and object recognition tasks.</p><p>6 0.57371759 <a title="18-lsi-6" href="./nips-2009-Replicated_Softmax%3A_an_Undirected_Topic_Model.html">204 nips-2009-Replicated Softmax: an Undirected Topic Model</a></p>
<p>7 0.53920931 <a title="18-lsi-7" href="./nips-2009-Perceptual_Multistability_as_Markov_Chain_Monte_Carlo_Inference.html">188 nips-2009-Perceptual Multistability as Markov Chain Monte Carlo Inference</a></p>
<p>8 0.49388987 <a title="18-lsi-8" href="./nips-2009-The_Wisdom_of_Crowds_in_the_Recollection_of_Order_Information.html">244 nips-2009-The Wisdom of Crowds in the Recollection of Order Information</a></p>
<p>9 0.49113962 <a title="18-lsi-9" href="./nips-2009-Dirichlet-Bernoulli_Alignment%3A_A_Generative_Model_for_Multi-Class_Multi-Label_Multi-Instance_Corpora.html">68 nips-2009-Dirichlet-Bernoulli Alignment: A Generative Model for Multi-Class Multi-Label Multi-Instance Corpora</a></p>
<p>10 0.49098432 <a title="18-lsi-10" href="./nips-2009-Free_energy_score_space.html">97 nips-2009-Free energy score space</a></p>
<p>11 0.48907825 <a title="18-lsi-11" href="./nips-2009-Bayesian_Belief_Polarization.html">39 nips-2009-Bayesian Belief Polarization</a></p>
<p>12 0.48566064 <a title="18-lsi-12" href="./nips-2009-Gaussian_process_regression_with_Student-t_likelihood.html">100 nips-2009-Gaussian process regression with Student-t likelihood</a></p>
<p>13 0.47324955 <a title="18-lsi-13" href="./nips-2009-Rethinking_LDA%3A_Why_Priors_Matter.html">205 nips-2009-Rethinking LDA: Why Priors Matter</a></p>
<p>14 0.45549521 <a title="18-lsi-14" href="./nips-2009-Spatial_Normalized_Gamma_Processes.html">226 nips-2009-Spatial Normalized Gamma Processes</a></p>
<p>15 0.44542411 <a title="18-lsi-15" href="./nips-2009-Particle-based_Variational_Inference_for_Continuous_Systems.html">187 nips-2009-Particle-based Variational Inference for Continuous Systems</a></p>
<p>16 0.44479871 <a title="18-lsi-16" href="./nips-2009-Neural_Implementation_of_Hierarchical_Bayesian_Inference_by_Importance_Sampling.html">162 nips-2009-Neural Implementation of Hierarchical Bayesian Inference by Importance Sampling</a></p>
<p>17 0.43756944 <a title="18-lsi-17" href="./nips-2009-Large_Scale_Nonparametric_Bayesian_Inference%3A_Data_Parallelisation_in_the_Indian_Buffet_Process.html">123 nips-2009-Large Scale Nonparametric Bayesian Inference: Data Parallelisation in the Indian Buffet Process</a></p>
<p>18 0.4283891 <a title="18-lsi-18" href="./nips-2009-Accelerating_Bayesian_Structural_Inference_for_Non-Decomposable_Gaussian_Graphical_Models.html">23 nips-2009-Accelerating Bayesian Structural Inference for Non-Decomposable Gaussian Graphical Models</a></p>
<p>19 0.40191793 <a title="18-lsi-19" href="./nips-2009-Neurometric_function_analysis_of_population_codes.html">163 nips-2009-Neurometric function analysis of population codes</a></p>
<p>20 0.39749452 <a title="18-lsi-20" href="./nips-2009-Bayesian_Nonparametric_Models_on_Decomposable_Graphs.html">40 nips-2009-Bayesian Nonparametric Models on Decomposable Graphs</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.24), (7, 0.015), (21, 0.012), (24, 0.065), (25, 0.066), (35, 0.068), (36, 0.105), (39, 0.051), (55, 0.012), (58, 0.073), (61, 0.038), (71, 0.085), (81, 0.021), (86, 0.06), (91, 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.80535817 <a title="18-lda-1" href="./nips-2009-A_Stochastic_approximation_method_for_inference_in_probabilistic_graphical_models.html">18 nips-2009-A Stochastic approximation method for inference in probabilistic graphical models</a></p>
<p>Author: Peter Carbonetto, Matthew King, Firas Hamze</p><p>Abstract: We describe a new algorithmic framework for inference in probabilistic models, and apply it to inference for latent Dirichlet allocation (LDA). Our framework adopts the methodology of variational inference, but unlike existing variational methods such as mean ﬁeld and expectation propagation it is not restricted to tractable classes of approximating distributions. Our approach can also be viewed as a “population-based” sequential Monte Carlo (SMC) method, but unlike existing SMC methods there is no need to design the artiﬁcial sequence of distributions. Signiﬁcantly, our framework oﬀers a principled means to exchange the variance of an importance sampling estimate for the bias incurred through variational approximation. We conduct experiments on a diﬃcult inference problem in population genetics, a problem that is related to inference for LDA. The results of these experiments suggest that our method can oﬀer improvements in stability and accuracy over existing methods, and at a comparable cost. 1</p><p>2 0.78076595 <a title="18-lda-2" href="./nips-2009-AUC_optimization_and_the_two-sample_problem.html">3 nips-2009-AUC optimization and the two-sample problem</a></p>
<p>Author: Nicolas Vayatis, Marine Depecker, Stéphan J. Clémençcon</p><p>Abstract: The purpose of the paper is to explore the connection between multivariate homogeneity tests and AUC optimization. The latter problem has recently received much attention in the statistical learning literature. From the elementary observation that, in the two-sample problem setup, the null assumption corresponds to the situation where the area under the optimal ROC curve is equal to 1/2, we propose a two-stage testing method based on data splitting. A nearly optimal scoring function in the AUC sense is ﬁrst learnt from one of the two half-samples. Data from the remaining half-sample are then projected onto the real line and eventually ranked according to the scoring function computed at the ﬁrst stage. The last step amounts to performing a standard Mann-Whitney Wilcoxon test in the onedimensional framework. We show that the learning step of the procedure does not affect the consistency of the test as well as its properties in terms of power, provided the ranking produced is accurate enough in the AUC sense. The results of a numerical experiment are eventually displayed in order to show the efﬁciency of the method. 1</p><p>3 0.64589679 <a title="18-lda-3" href="./nips-2009-Training_Factor_Graphs_with_Reinforcement_Learning_for_Efficient_MAP_Inference.html">250 nips-2009-Training Factor Graphs with Reinforcement Learning for Efficient MAP Inference</a></p>
<p>Author: Khashayar Rohanimanesh, Sameer Singh, Andrew McCallum, Michael J. Black</p><p>Abstract: Large, relational factor graphs with structure deﬁned by ﬁrst-order logic or other languages give rise to notoriously difﬁcult inference problems. Because unrolling the structure necessary to represent distributions over all hypotheses has exponential blow-up, solutions are often derived from MCMC. However, because of limitations in the design and parameterization of the jump function, these samplingbased methods suffer from local minima—the system must transition through lower-scoring conﬁgurations before arriving at a better MAP solution. This paper presents a new method of explicitly selecting fruitful downward jumps by leveraging reinforcement learning (RL). Rather than setting parameters to maximize the likelihood of the training data, parameters of the factor graph are treated as a log-linear function approximator and learned with methods of temporal difference (TD); MAP inference is performed by executing the resulting policy on held out test data. Our method allows efﬁcient gradient updates since only factors in the neighborhood of variables affected by an action need to be computed—we bypass the need to compute marginals entirely. Our method yields dramatic empirical success, producing new state-of-the-art results on a complex joint model of ontology alignment, with a 48% reduction in error over state-of-the-art in that domain. 1</p><p>4 0.63468516 <a title="18-lda-4" href="./nips-2009-Improving_Existing_Fault_Recovery_Policies.html">113 nips-2009-Improving Existing Fault Recovery Policies</a></p>
<p>Author: Guy Shani, Christopher Meek</p><p>Abstract: An automated recovery system is a key component in a large data center. Such a system typically employs a hand-made controller created by an expert. While such controllers capture many important aspects of the recovery process, they are often not systematically optimized to reduce costs such as server downtime. In this paper we describe a passive policy learning approach for improving existing recovery policies without exploration. We explain how to use data gathered from the interactions of the hand-made controller with the system, to create an improved controller. We suggest learning an indeﬁnite horizon Partially Observable Markov Decision Process, a model for decision making under uncertainty, and solve it using a point-based algorithm. We describe the complete process, starting with data gathering, model learning, model checking procedures, and computing a policy. 1</p><p>5 0.63467467 <a title="18-lda-5" href="./nips-2009-Sensitivity_analysis_in_HMMs_with_application_to_likelihood_maximization.html">215 nips-2009-Sensitivity analysis in HMMs with application to likelihood maximization</a></p>
<p>Author: Pierre-arnaud Coquelin, Romain Deguest, Rémi Munos</p><p>Abstract: This paper considers a sensitivity analysis in Hidden Markov Models with continuous state and observation spaces. We propose an Inﬁnitesimal Perturbation Analysis (IPA) on the ﬁltering distribution with respect to some parameters of the model. We describe a methodology for using any algorithm that estimates the ﬁltering density, such as Sequential Monte Carlo methods, to design an algorithm that estimates its gradient. The resulting IPA estimator is proven to be asymptotically unbiased, consistent and has computational complexity linear in the number of particles. We consider an application of this analysis to the problem of identifying unknown parameters of the model given a sequence of observations. We derive an IPA estimator for the gradient of the log-likelihood, which may be used in a gradient method for the purpose of likelihood maximization. We illustrate the method with several numerical experiments.</p><p>6 0.6329605 <a title="18-lda-6" href="./nips-2009-Bayesian_Nonparametric_Models_on_Decomposable_Graphs.html">40 nips-2009-Bayesian Nonparametric Models on Decomposable Graphs</a></p>
<p>7 0.63295513 <a title="18-lda-7" href="./nips-2009-Bayesian_Source_Localization_with_the_Multivariate_Laplace_Prior.html">41 nips-2009-Bayesian Source Localization with the Multivariate Laplace Prior</a></p>
<p>8 0.63269037 <a title="18-lda-8" href="./nips-2009-Learning_in_Markov_Random_Fields_using_Tempered_Transitions.html">132 nips-2009-Learning in Markov Random Fields using Tempered Transitions</a></p>
<p>9 0.63249803 <a title="18-lda-9" href="./nips-2009-Zero-shot_Learning_with_Semantic_Output_Codes.html">260 nips-2009-Zero-shot Learning with Semantic Output Codes</a></p>
<p>10 0.63125122 <a title="18-lda-10" href="./nips-2009-Free_energy_score_space.html">97 nips-2009-Free energy score space</a></p>
<p>11 0.6302765 <a title="18-lda-11" href="./nips-2009-Nonparametric_Latent_Feature_Models_for_Link_Prediction.html">174 nips-2009-Nonparametric Latent Feature Models for Link Prediction</a></p>
<p>12 0.62786615 <a title="18-lda-12" href="./nips-2009-Spatial_Normalized_Gamma_Processes.html">226 nips-2009-Spatial Normalized Gamma Processes</a></p>
<p>13 0.62663895 <a title="18-lda-13" href="./nips-2009-Construction_of_Nonparametric_Bayesian_Models_from_Parametric_Bayes_Equations.html">59 nips-2009-Construction of Nonparametric Bayesian Models from Parametric Bayes Equations</a></p>
<p>14 0.6254251 <a title="18-lda-14" href="./nips-2009-Learning_a_Small_Mixture_of_Trees.html">129 nips-2009-Learning a Small Mixture of Trees</a></p>
<p>15 0.62425137 <a title="18-lda-15" href="./nips-2009-Sharing_Features_among_Dynamical_Systems_with_Beta_Processes.html">217 nips-2009-Sharing Features among Dynamical Systems with Beta Processes</a></p>
<p>16 0.62397242 <a title="18-lda-16" href="./nips-2009-Nonlinear_Learning_using_Local_Coordinate_Coding.html">169 nips-2009-Nonlinear Learning using Local Coordinate Coding</a></p>
<p>17 0.62184495 <a title="18-lda-17" href="./nips-2009-Distribution-Calibrated_Hierarchical_Classification.html">71 nips-2009-Distribution-Calibrated Hierarchical Classification</a></p>
<p>18 0.62073648 <a title="18-lda-18" href="./nips-2009-Particle-based_Variational_Inference_for_Continuous_Systems.html">187 nips-2009-Particle-based Variational Inference for Continuous Systems</a></p>
<p>19 0.62055963 <a title="18-lda-19" href="./nips-2009-Distribution_Matching_for_Transduction.html">72 nips-2009-Distribution Matching for Transduction</a></p>
<p>20 0.6188069 <a title="18-lda-20" href="./nips-2009-Learning_from_Neighboring_Strokes%3A_Combining_Appearance_and_Context_for_Multi-Domain_Sketch_Recognition.html">131 nips-2009-Learning from Neighboring Strokes: Combining Appearance and Context for Multi-Domain Sketch Recognition</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
