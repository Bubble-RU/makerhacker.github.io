<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>215 nips-2009-Sensitivity analysis in HMMs with application to likelihood maximization</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-215" href="#">nips2009-215</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>215 nips-2009-Sensitivity analysis in HMMs with application to likelihood maximization</h1>
<br/><p>Source: <a title="nips-2009-215-pdf" href="http://papers.nips.cc/paper/3648-sensitivity-analysis-in-hmms-with-application-to-likelihood-maximization.pdf">pdf</a></p><p>Author: Pierre-arnaud Coquelin, Romain Deguest, Rémi Munos</p><p>Abstract: This paper considers a sensitivity analysis in Hidden Markov Models with continuous state and observation spaces. We propose an Inﬁnitesimal Perturbation Analysis (IPA) on the ﬁltering distribution with respect to some parameters of the model. We describe a methodology for using any algorithm that estimates the ﬁltering density, such as Sequential Monte Carlo methods, to design an algorithm that estimates its gradient. The resulting IPA estimator is proven to be asymptotically unbiased, consistent and has computational complexity linear in the number of particles. We consider an application of this analysis to the problem of identifying unknown parameters of the model given a sequence of observations. We derive an IPA estimator for the gradient of the log-likelihood, which may be used in a gradient method for the purpose of likelihood maximization. We illustrate the method with several numerical experiments.</p><p>Reference: <a title="nips-2009-215-reference" href="../nips2009_reference/nips-2009-Sensitivity_analysis_in_HMMs_with_application_to_likelihood_maximization_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Sensitivity analysis in HMMs with application to likelihood maximization  Pierre-Arnaud Coquelin, Vekia, Lille, France  Romain Deguest∗ Columbia University, New York City, NY 10027  pacoquelin@vekia. [sent-1, score-0.067]
</p><p>2 fr  Abstract This paper considers a sensitivity analysis in Hidden Markov Models with continuous state and observation spaces. [sent-5, score-0.103]
</p><p>3 We describe a methodology for using any algorithm that estimates the ﬁltering density, such as Sequential Monte Carlo methods, to design an algorithm that estimates its gradient. [sent-7, score-0.04]
</p><p>4 The resulting IPA estimator is proven to be asymptotically unbiased, consistent and has computational complexity linear in the number of particles. [sent-8, score-0.177]
</p><p>5 We derive an IPA estimator for the gradient of the log-likelihood, which may be used in a gradient method for the purpose of likelihood maximization. [sent-10, score-0.342]
</p><p>6 1 Introduction We consider a parameterized hidden Markov model (HMM) deﬁned on continuous state and observation spaces. [sent-12, score-0.108]
</p><p>7 The HMM is deﬁned by a state process (Xt )t≥0 ∈ X and an observation process (Yt )t≥1 ∈ Y that are parameterized by a continuous parameter θ = (θ1 , . [sent-13, score-0.117]
</p><p>8 The state process is a Markov chain taking its values in a (measurable) state space X, with initial probability measure µ ∈ M(X) (i. [sent-17, score-0.129]
</p><p>9 X0 ∼ µ) and Markov transition kernel K(θ, xt , dxt+1 ). [sent-19, score-0.448]
</p><p>10 We assume that we can sample this Markov chain using a transition function F and independent random numbers, i. [sent-20, score-0.073]
</p><p>11 For simplicity, we adopt the notations F (θ, x−1 , u) Fµ (θ, u), where Fµ is the ﬁrst transition function (i. [sent-27, score-0.03]
</p><p>12 Since the transition and observation processes are parameterized by the parameter θ, the state Xt and the observation Yt processes depend explicitly on θ. [sent-32, score-0.121]
</p><p>13 One of the main interest in HMMs is to recover the state at time n given a sequence of past observations (y1 , . [sent-37, score-0.062]
</p><p>14 The ﬁltering distribution (or belief state) πn (dxn )  P(Xn ∈ dxn |Y1:n = y1:n )  is the distribution of Xn conditioned on the information y1:n . [sent-41, score-0.065]
</p><p>15 Our contribution is an Inﬁnitesimal Perturbation Analysis (IPA) that estimates the gradient ∇πn (where ∇ refers to the derivative with respect to the ∫ parameter θ) of the ﬁltering distribution πn . [sent-43, score-0.152]
</p><p>16 We also consider as application, the problem of parameter identiﬁcation in HMMs which consists in estimating the (unknown) parameter θ∗ of the model that has served to generate the sequence of observations. [sent-45, score-0.054]
</p><p>17 In a Maximum Likelihood (ML) approach, one searches for the parameter θ that maximizes the likelihood (or its logarithm) given the sequence of observations. [sent-46, score-0.067]
</p><p>18 The log-likelihood of parameter θ is deﬁned by ln (θ) log pθ (y1:n ) where pθ (y1:n ) dy1:n P(Y1:n (θ) ∈ dy1:n ). [sent-47, score-0.094]
</p><p>19 ˆ The Maximum Likelihood (ML) estimator θn arg maxθ∈Θ ln (θ) is asymptotically consistent ˆ (in the sense that θn converges almost surely to the true parameter θ∗ when n → ∞ under some identiﬁably conditions and mild assumptions on the model, see Theorem 2 of [DM01]). [sent-48, score-0.29]
</p><p>20 Thus, using the ML approach, the parameter identiﬁcation problem reduces to an optimization problem. [sent-49, score-0.027]
</p><p>21 Our second contribution is a sensitivity analysis of the predictive distribution ∇πt+1|t , for t < n, which enables to estimate the gradient ∇ln (θ) of the log-likelihood function, which may be used in a (stochastic) gradient method for the purpose of optimizing the likelihood. [sent-50, score-0.208]
</p><p>22 The approach is numerically illustrated on two parameter identiﬁcation problems (autoregressive model and a stochastic volatility model) and compared to other approaches (EM algorithm, the Kalman ﬁlter, and the Likelihood ratio approach) when these latter apply. [sent-51, score-0.147]
</p><p>23 2  Links with other works  First, let us mention that we are interested in the continuous state case since numerous applications in signal processing, ﬁnance, robotics, or telecommunications naturally ﬁt in this framework. [sent-52, score-0.096]
</p><p>24 For illustration, a challenging example in ﬁnance is the problem of parameter estimation in the stochastic volatility model, which is a non-linear nonGaussian continuous space HMM parameterized by three continuous parameters (see e. [sent-57, score-0.244]
</p><p>25 A usual approach for parameter estimation consists in performing a maximum likelihood estimation (MLE), i. [sent-60, score-0.133]
</p><p>26 For ﬁnite state space problems, the Expectation Maximization (EM) algorithm is a popular method for solving the MLE problem. [sent-63, score-0.043]
</p><p>27 However, in continuous space problems, see [CM05], the EM algorithm is difﬁcult to use mainly because the Expectation part relies on the estimation of the posterior path measure which is intractable in many situations. [sent-64, score-0.05]
</p><p>28 An alternative method consists in using brute force optimization methods based on the evaluation of the likelihood such as grid-based or simulated annealing methods. [sent-66, score-0.04]
</p><p>29 These approaches, which can be seen as black-box optimization are not very efﬁcient in high dimensional parameter spaces. [sent-67, score-0.027]
</p><p>30 2  Another approach is to treat the parameter as part of the state variable and then compute the optimal ﬁlter (see [DFG01] and [Sto02]). [sent-68, score-0.07]
</p><p>31 In this case, the Bayesian posterior distribution of the parameter is a marginal of the optimal ﬁlter. [sent-69, score-0.027]
</p><p>32 A last solution consists in using an optimization procedure based on the evaluation of the gradient of the log-likelihood function with respect to the parameter. [sent-71, score-0.076]
</p><p>33 The idea was to use a likelihood ratio approach (also called score method) to evaluate the gradient of the likelihood. [sent-75, score-0.166]
</p><p>34 This approach suffers from high variance of the estimator, in particular for problems with small noise in the dynamic. [sent-76, score-0.043]
</p><p>35 To tackle this issue, [PDS05] proposed to use a marginal particle ﬁlter instead of a simple path-based particle ﬁlter as Monte Carlo approximation method. [sent-77, score-0.244]
</p><p>36 This approach is efﬁcient in terms of variance reduction but its computational complexity becomes quadratic in the number of particles instead of being linear, like in path-based particle methods. [sent-78, score-0.248]
</p><p>37 The IPA approach proposed in this paper is an alternative gradient-based maximum likelihood approach. [sent-79, score-0.04]
</p><p>38 Compared with works on gradient approaches previously cited, the IPA provides usually a lower variance estimators than the likelihood ratio methods, and its numerical complexity is linear in the number of particles. [sent-80, score-0.23]
</p><p>39 Other works related to ours are the so-called tangent ﬁlter approach described in [CGN01] for dynamics coming from a discretization of a diffusion process, and the Finite-Difference (FD) approach described in a different setting (i. [sent-81, score-0.041]
</p><p>40 policy gradient in Partially Observable Markov Decision Processes) in [CDM08]. [sent-83, score-0.076]
</p><p>41 A similar FD estimator could be designed in our setting too but the resulting FD estimator would be biased (like usual FD schemes) whereas the IPA estimator is not. [sent-84, score-0.402]
</p><p>42 3  Sequential Monte Carlo methods (SMC)  Given a measurable test function f : X → R, we have: ∫ ∏n ∏n f (xn ) t=0 K(xt−1 , dxt )Gt (xt ) E[f (Xn ) t=0 Gt (Xt )] ∫ ∏n ∏n . [sent-85, score-0.073]
</p><p>43 = πn (f ) E[f (Xn )|Y1:n = y1:n ] = E[ t=0 Gt (Xt )] t=0 K(xt−1 , dxt )Gt (xt ) (2) where we used the simpliﬁed notation: Gt (xt ) g(xt , yt ) and G0 (x0 ) 1. [sent-86, score-0.116]
</p><p>44 But it should be mentioned that other methods (such as Extended Kalman ﬁlter, quantization methods, Markov Chain Monte Carlo methods) may be used as well to build the IPA estimator that we propose in the next section. [sent-89, score-0.128]
</p><p>45 The basic SMC method, called Bootstrap Filter, see [DFG01] for details, approximates πn (f ) by an ∑N 1 N empirical distribution πn (f ) N i=1 f (xi ) made of N particles x1:N . [sent-90, score-0.083]
</p><p>46 n n Algorithm 1 Generic Sequential Monte Carlo for t = 1 to n do iid i i i Sampling: Sample ui t−1 ∼ ν and set xt = F (xt−1 , ut−1 ), ∀i ∈ {1, . [sent-91, score-0.499]
</p><p>47 Then deﬁne the i importance sampling weights wt =  Gt (ei ) xt PN , xj j=1 Gt (et )  Resampling: Set xi = xki , ∀i ∈ {1, . [sent-95, score-0.535]
</p><p>48 , N }, where k1:N are indices selected from the weights t t 1:N wt . [sent-98, score-0.09]
</p><p>49 end for ∑N 1 N RETURN: πn (f ) = N i=1 f (xi ) n The sampling (or transition) step generates a successor particle population x1:N according to the t 1:N state dynamics from the previous population x1:N . [sent-99, score-0.189]
</p><p>50 The importance sampling weights wt are evalt−1 uated, and the resampling (or selection) step resamples (with replacement) N particles x1:N from t 1:N the set x1:N according to the weights wt . [sent-100, score-0.252]
</p><p>51 t t 1:N The simplest version introduced in [GSS93] chooses the selection indices kt by an independent 1:N sampling from the set {1, . [sent-107, score-0.042]
</p><p>52 , N } according to a multinomial distribution with parameters wt , j i i. [sent-110, score-0.067]
</p><p>53 The idea is to replicate the particles in proportion to their weights. [sent-113, score-0.083]
</p><p>54 Many variants have been proposed in the literature, among which the stratiﬁed resampling method [Kit96] which is optimal in terms of variance minimization. [sent-114, score-0.078]
</p><p>55 For our purpose we note that under mild conditions on f , πn (f ) is an asymptotically unbiased (see [DMDP07] for the asymptotic expression of the bias) and consistent estimator of πn (f ). [sent-118, score-0.249]
</p><p>56 Although IPA is known for having a lower variance than SF in general, as far as we know, it has never been used in this context. [sent-123, score-0.043]
</p><p>57 (5) E[ t=0 Gt (Xt )] We now state some sufﬁcient conditions under which the previous derivations are sound. [sent-128, score-0.043]
</p><p>58 continuously differentiable at Xn (θ), and for all 1 ≤ t ≤ n, Gt is a. [sent-134, score-0.053]
</p><p>59 continuously differentiable at (θ, Xt (θ)), • θ → f (Xn (θ)) and for all 1 ≤ t ≤ n, θ → Gt (θ, Xt (θ)) are a. [sent-136, score-0.053]
</p><p>60 continuous and piecewise differentiable throughout Θ, • Let D be the random subset of Θ at which f (Xn (θ)) or one Gt (θ, Xt (θ)) fails to be differ∏n entiable. [sent-138, score-0.056]
</p><p>61 differentiability of the path θ → (X0 , X1 , · · · , Xn )(θ) is equivalent to requiring that for all θ ∈ Θ, the transition function F is a. [sent-143, score-0.03]
</p><p>62 Under the assumptions of Proposition 1, the estimator In deﬁned by (6) has a bias −1 N N O(N ) and is consistent with ∇πn (f ), i. [sent-151, score-0.146]
</p><p>63 Applying those results to the test function H f (Xn )Zn + Rn (f (Xn ) − πn (f )), using the representation (5) of the gradient, we deduce that the SMC estimator (6) is asymptotically unbiased and consistent with ∇πn (f ). [sent-158, score-0.237]
</p><p>64 Now the asymptotic variance is O(N −1 ) since the Central Limit Theorem (see e. [sent-159, score-0.065]
</p><p>65 [Del04, DM08]) applies to the IPA estimator (6) of (5). [sent-161, score-0.128]
</p><p>66 Notice that the computation of the gradient estimator requires O(nN md) (where m is the dimension of X) elementary operations, which is linear in the number of particles N and linear in the number of parameters d, and has memory requirement O(N md). [sent-163, score-0.287]
</p><p>67 Using similar arguments as those detailed in proofs of Propositions 1 and 2, we have that this estimator is asymptotically unbiased and consistent with ∇ln (θ). [sent-167, score-0.205]
</p><p>68 The resulting gradient algorithm is described in Algorithm 3. [sent-168, score-0.076]
</p><p>69 Algorithm 3 Likelihood Maximization by gradient ascent using the IPA estimator of ∇ln (θ) for k = 1, 2, . [sent-174, score-0.221]
</p><p>70 , Number of gradient steps do N Initialize J0 = 0 for t = 1 to n do For all i ∈ {1, . [sent-177, score-0.076]
</p><p>71 i and compute the weights wt =  i i Set (xi , zt , rt ) = where k1:N are indices selected t end for N Perform a gradient ascent step: θk = θk−1 + γk Jn (θk−1 ) end for  6  ,  t  1  0. [sent-181, score-0.435]
</p><p>72 where Ut ∼ N (0, 1) and Vt ∼ N (0, 1) are independent sequences of random variables, and θ = (φ, σ, β) is a three-dimensional parameter in (R+ )3 . [sent-218, score-0.027]
</p><p>73 Stochastic volatility model is very popular in the ﬁeld of quantitative ﬁnance [ME07] to evaluate derivative securities, such as options. [sent-219, score-0.114]
</p><p>74 Xt Yt  = φXt−1 + σUt , = β exp (Xt /2) Vt ,  (8)  where again Ut ∼ N (0, 1) and Vt ∼ N (0, 1) and the parameter θ = (φ, σ, β) ∈ (R+ ) . [sent-227, score-0.027]
</p><p>75 1 Parameter identiﬁcation Figure 1 shows the results of our IPA gradient estimator for the AR1 parameter identiﬁcation problem and compares those with two other methods: Kalman ﬁlter (K) and EM (which apply since the model is linear-Gaussian). [sent-229, score-0.231]
</p><p>76 Notice the apparent bias of the three methods in the estimation of θ∗ (even for Kalman which provides here the exact ﬁltering distribution) since the number of observations n = 500 is ﬁnite. [sent-234, score-0.043]
</p><p>77 For IPA, we used N = 102 particles and 150 gradient iterations. [sent-235, score-0.159]
</p><p>78 The IPA method applies to general models, for example, to the stochastic volatility model. [sent-244, score-0.12]
</p><p>79 0) using IPA with n = 103 observations and N = 102 particles (no comparison is made here since Kalman does not apply and EM becomes more complicated). [sent-248, score-0.102]
</p><p>80 2 Variance study for Score and IPA algorithms IPA and Score methods provide gradient estimators for general models. [sent-250, score-0.121]
</p><p>81 We compare the variance of the corresponding estimators of the gradient ∇ln for the AR1 since for this model we know its exact value (using Kalman). [sent-251, score-0.164]
</p><p>82 8 1  2  3  Parameter number  Figure 2: Box-and-whiskers plots of the three parameters (φ, σ, β) estimates for the IPA method applied to the stochastic volatility model with θ = (0. [sent-261, score-0.14]
</p><p>83 The IPA estimator performs better than the Score estimator for small values of σ. [sent-268, score-0.256]
</p><p>84 On the other hand, in case of huge variance in the state model, it is better to use the Score estimator. [sent-269, score-0.086]
</p><p>85 4  Figure 3: Variance of the log-likelihood derivative ∂σ ln computed with both the IPA and Score methods. [sent-276, score-0.096]
</p><p>86 Let us mention that the variance of the IPA (as well as Score) estimator increases when the number of observations n increases. [sent-283, score-0.217]
</p><p>87 However, under weak conditions on the HMM [LM00], the ﬁltering distribution and its gradient forget exponentially fast the initial distribution. [sent-284, score-0.076]
</p><p>88 This property has already been used for EM estimators in [CM05] to show that ﬁxed-lag smoothing drastically reduces the variance without signiﬁcantly raising the bias. [sent-285, score-0.088]
</p><p>89 Similar smoothing (either ﬁxed-lag or discounted) would provide efﬁcient variance reduction techniques for the IPA estimator as well. [sent-286, score-0.171]
</p><p>90 6  Conclusions  We proposed a sensitivity analysis in HMMs based on an Inﬁnitesimal Perturbation Analysis and provided a computationally efﬁcient gradient estimator that provides an interesting alternative to the usual Score method. [sent-287, score-0.256]
</p><p>91 We showed how this analysis may be used for estimating the gradient of the log-likelihood in a gradient-based likelihood maximization approach for the purpose of parameter identiﬁcation. [sent-288, score-0.192]
</p><p>92 Finally let us mention that estimators of higher-order derivatives (e. [sent-289, score-0.072]
</p><p>93 On the use of particle ﬁltering for maximum likelihood parameter estimation. [sent-316, score-0.189]
</p><p>94 Asymptotics of the maximum likelihood estimator for general hidden markov models. [sent-331, score-0.232]
</p><p>95 Limit theorems for weighted samples with applications to sequential monte carlo methods. [sent-336, score-0.11]
</p><p>96 Parameter estimation in general state-space models using particle methods. [sent-347, score-0.146]
</p><p>97 Particle-based methods for parameter estimation and tracking : numerical experiments. [sent-356, score-0.077]
</p><p>98 Novel approach to nonlinear and nongaussian bayesian state estimation. [sent-368, score-0.075]
</p><p>99 Monte-Carlo ﬁlter and smoother for non-Gaussian nonlinear state space models. [sent-372, score-0.043]
</p><p>100 Exponential forgetting and geometric ergodicity in hidden markov models. [sent-387, score-0.064]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('gt', 0.54), ('ipa', 0.485), ('xt', 0.418), ('xn', 0.148), ('estimator', 0.128), ('rt', 0.127), ('kalman', 0.126), ('zt', 0.125), ('particle', 0.122), ('smc', 0.121), ('ut', 0.086), ('ltering', 0.085), ('gk', 0.085), ('volatility', 0.085), ('particles', 0.083), ('xk', 0.08), ('gradient', 0.076), ('zn', 0.071), ('hmms', 0.069), ('ln', 0.067), ('wt', 0.067), ('yt', 0.067), ('dxn', 0.065), ('ui', 0.057), ('nitesimal', 0.055), ('lter', 0.054), ('perturbation', 0.05), ('score', 0.05), ('xi', 0.05), ('em', 0.049), ('dxt', 0.049), ('markov', 0.046), ('estimators', 0.045), ('doucet', 0.044), ('fd', 0.044), ('rn', 0.043), ('state', 0.043), ('variance', 0.043), ('chain', 0.043), ('carlo', 0.041), ('monte', 0.041), ('likelihood', 0.04), ('hmm', 0.036), ('resampling', 0.035), ('stochastic', 0.035), ('sensitivity', 0.034), ('nance', 0.033), ('sf', 0.033), ('coquelin', 0.032), ('deguest', 0.032), ('douc', 0.032), ('dyt', 0.032), ('legland', 0.032), ('nongaussian', 0.032), ('deduce', 0.032), ('identi', 0.031), ('asymptotically', 0.031), ('vt', 0.03), ('differentiable', 0.03), ('transition', 0.03), ('derivative', 0.029), ('lille', 0.028), ('sequential', 0.028), ('proposition', 0.028), ('unbiased', 0.028), ('maximization', 0.027), ('mention', 0.027), ('parameter', 0.027), ('continuous', 0.026), ('numerical', 0.026), ('jt', 0.026), ('france', 0.025), ('measurable', 0.024), ('iid', 0.024), ('estimation', 0.024), ('del', 0.024), ('dynamics', 0.024), ('indices', 0.023), ('jn', 0.023), ('autoregressive', 0.023), ('ml', 0.023), ('augmented', 0.023), ('continuously', 0.023), ('asymptotic', 0.022), ('purpose', 0.022), ('parameterized', 0.021), ('mle', 0.021), ('estimates', 0.02), ('observations', 0.019), ('surely', 0.019), ('kluwer', 0.019), ('kt', 0.019), ('hidden', 0.018), ('pn', 0.018), ('consistent', 0.018), ('usual', 0.018), ('md', 0.017), ('tangent', 0.017), ('fk', 0.017), ('ascent', 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="215-tfidf-1" href="./nips-2009-Sensitivity_analysis_in_HMMs_with_application_to_likelihood_maximization.html">215 nips-2009-Sensitivity analysis in HMMs with application to likelihood maximization</a></p>
<p>Author: Pierre-arnaud Coquelin, Romain Deguest, Rémi Munos</p><p>Abstract: This paper considers a sensitivity analysis in Hidden Markov Models with continuous state and observation spaces. We propose an Inﬁnitesimal Perturbation Analysis (IPA) on the ﬁltering distribution with respect to some parameters of the model. We describe a methodology for using any algorithm that estimates the ﬁltering density, such as Sequential Monte Carlo methods, to design an algorithm that estimates its gradient. The resulting IPA estimator is proven to be asymptotically unbiased, consistent and has computational complexity linear in the number of particles. We consider an application of this analysis to the problem of identifying unknown parameters of the model given a sequence of observations. We derive an IPA estimator for the gradient of the log-likelihood, which may be used in a gradient method for the purpose of likelihood maximization. We illustrate the method with several numerical experiments.</p><p>2 0.22421494 <a title="215-tfidf-2" href="./nips-2009-On_Stochastic_and_Worst-case_Models_for_Investing.html">178 nips-2009-On Stochastic and Worst-case Models for Investing</a></p>
<p>Author: Elad Hazan, Satyen Kale</p><p>Abstract: In practice, most investing is done assuming a probabilistic model of stock price returns known as the Geometric Brownian Motion (GBM). While often an acceptable approximation, the GBM model is not always valid empirically. This motivates a worst-case approach to investing, called universal portfolio management, where the objective is to maximize wealth relative to the wealth earned by the best ﬁxed portfolio in hindsight. In this paper we tie the two approaches, and design an investment strategy which is universal in the worst-case, and yet capable of exploiting the mostly valid GBM model. Our method is based on new and improved regret bounds for online convex optimization with exp-concave loss functions. 1</p><p>3 0.21854854 <a title="215-tfidf-3" href="./nips-2009-Accelerated_Gradient_Methods_for_Stochastic_Optimization_and_Online_Learning.html">22 nips-2009-Accelerated Gradient Methods for Stochastic Optimization and Online Learning</a></p>
<p>Author: Chonghai Hu, Weike Pan, James T. Kwok</p><p>Abstract: Regularized risk minimization often involves non-smooth optimization, either because of the loss function (e.g., hinge loss) or the regularizer (e.g., ℓ1 -regularizer). Gradient methods, though highly scalable and easy to implement, are known to converge slowly. In this paper, we develop a novel accelerated gradient method for stochastic optimization while still preserving their computational simplicity and scalability. The proposed algorithm, called SAGE (Stochastic Accelerated GradiEnt), exhibits fast convergence rates on stochastic composite optimization with convex or strongly convex objectives. Experimental results show that SAGE is faster than recent (sub)gradient methods including FOLOS, SMIDAS and SCD. Moreover, SAGE can also be extended for online learning, resulting in a simple algorithm but with the best regret bounds currently known for these problems. 1</p><p>4 0.21492775 <a title="215-tfidf-4" href="./nips-2009-Slow_Learners_are_Fast.html">220 nips-2009-Slow Learners are Fast</a></p>
<p>Author: Martin Zinkevich, John Langford, Alex J. Smola</p><p>Abstract: Online learning algorithms have impressive convergence properties when it comes to risk minimization and convex games on very large problems. However, they are inherently sequential in their design which prevents them from taking advantage of modern multi-core architectures. In this paper we prove that online learning with delayed updates converges well, thereby facilitating parallel online learning. 1</p><p>5 0.18805781 <a title="215-tfidf-5" href="./nips-2009-Modeling_the_spacing_effect_in_sequential_category_learning.html">154 nips-2009-Modeling the spacing effect in sequential category learning</a></p>
<p>Author: Hongjing Lu, Matthew Weiden, Alan L. Yuille</p><p>Abstract: We develop a Bayesian sequential model for category learning. The sequential model updates two category parameters, the mean and the variance, over time. We deﬁne conjugate temporal priors to enable closed form solutions to be obtained. This model can be easily extended to supervised and unsupervised learning involving multiple categories. To model the spacing effect, we introduce a generic prior in the temporal updating stage to capture a learning preference, namely, less change for repetition and more change for variation. Finally, we show how this approach can be generalized to efﬁciently perform model selection to decide whether observations are from one or multiple categories.</p><p>6 0.16637769 <a title="215-tfidf-6" href="./nips-2009-Beyond_Convexity%3A_Online_Submodular_Minimization.html">45 nips-2009-Beyond Convexity: Online Submodular Minimization</a></p>
<p>7 0.16406868 <a title="215-tfidf-7" href="./nips-2009-Adaptive_Regularization_of_Weight_Vectors.html">27 nips-2009-Adaptive Regularization of Weight Vectors</a></p>
<p>8 0.16078553 <a title="215-tfidf-8" href="./nips-2009-On_Learning_Rotations.html">177 nips-2009-On Learning Rotations</a></p>
<p>9 0.11996707 <a title="215-tfidf-9" href="./nips-2009-Information-theoretic_lower_bounds_on_the_oracle_complexity_of_convex_optimization.html">116 nips-2009-Information-theoretic lower bounds on the oracle complexity of convex optimization</a></p>
<p>10 0.11127857 <a title="215-tfidf-10" href="./nips-2009-Regularized_Distance_Metric_Learning%3ATheory_and_Algorithm.html">202 nips-2009-Regularized Distance Metric Learning:Theory and Algorithm</a></p>
<p>11 0.11054564 <a title="215-tfidf-11" href="./nips-2009-Manifold_Regularization_for_SIR_with_Rate_Root-n_Convergence.html">146 nips-2009-Manifold Regularization for SIR with Rate Root-n Convergence</a></p>
<p>12 0.10924574 <a title="215-tfidf-12" href="./nips-2009-A_Stochastic_approximation_method_for_inference_in_probabilistic_graphical_models.html">18 nips-2009-A Stochastic approximation method for inference in probabilistic graphical models</a></p>
<p>13 0.099735945 <a title="215-tfidf-13" href="./nips-2009-White_Functionals_for_Anomaly_Detection_in_Dynamical_Systems.html">257 nips-2009-White Functionals for Anomaly Detection in Dynamical Systems</a></p>
<p>14 0.096666507 <a title="215-tfidf-14" href="./nips-2009-Generalization_Errors_and_Learning_Curves_for_Regression_with_Multi-task_Gaussian_Processes.html">101 nips-2009-Generalization Errors and Learning Curves for Regression with Multi-task Gaussian Processes</a></p>
<p>15 0.094221808 <a title="215-tfidf-15" href="./nips-2009-A_Neural_Implementation_of_the_Kalman_Filter.html">13 nips-2009-A Neural Implementation of the Kalman Filter</a></p>
<p>16 0.089546755 <a title="215-tfidf-16" href="./nips-2009-Speeding_up_Magnetic_Resonance_Image_Acquisition_by_Bayesian_Multi-Slice_Adaptive_Compressed_Sensing.html">228 nips-2009-Speeding up Magnetic Resonance Image Acquisition by Bayesian Multi-Slice Adaptive Compressed Sensing</a></p>
<p>17 0.085998967 <a title="215-tfidf-17" href="./nips-2009-Learning_in_Markov_Random_Fields_using_Tempered_Transitions.html">132 nips-2009-Learning in Markov Random Fields using Tempered Transitions</a></p>
<p>18 0.085394323 <a title="215-tfidf-18" href="./nips-2009-Time-Varying_Dynamic_Bayesian_Networks.html">246 nips-2009-Time-Varying Dynamic Bayesian Networks</a></p>
<p>19 0.080660194 <a title="215-tfidf-19" href="./nips-2009-A_General_Projection_Property_for_Distribution_Families.html">11 nips-2009-A General Projection Property for Distribution Families</a></p>
<p>20 0.080142044 <a title="215-tfidf-20" href="./nips-2009-An_Integer_Projected_Fixed_Point_Method_for_Graph_Matching_and_MAP_Inference.html">30 nips-2009-An Integer Projected Fixed Point Method for Graph Matching and MAP Inference</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.19), (1, 0.184), (2, 0.155), (3, -0.111), (4, 0.334), (5, 0.184), (6, 0.089), (7, 0.092), (8, -0.025), (9, -0.057), (10, 0.114), (11, 0.113), (12, -0.051), (13, -0.06), (14, -0.001), (15, -0.082), (16, -0.191), (17, -0.029), (18, 0.035), (19, 0.015), (20, 0.081), (21, 0.003), (22, 0.064), (23, 0.109), (24, -0.035), (25, 0.026), (26, 0.069), (27, 0.018), (28, -0.056), (29, -0.031), (30, 0.083), (31, 0.016), (32, 0.025), (33, -0.038), (34, 0.03), (35, 0.028), (36, 0.012), (37, -0.003), (38, 0.039), (39, 0.029), (40, 0.029), (41, 0.074), (42, -0.033), (43, -0.017), (44, 0.003), (45, -0.003), (46, 0.026), (47, 0.015), (48, 0.025), (49, -0.015)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97876543 <a title="215-lsi-1" href="./nips-2009-Sensitivity_analysis_in_HMMs_with_application_to_likelihood_maximization.html">215 nips-2009-Sensitivity analysis in HMMs with application to likelihood maximization</a></p>
<p>Author: Pierre-arnaud Coquelin, Romain Deguest, Rémi Munos</p><p>Abstract: This paper considers a sensitivity analysis in Hidden Markov Models with continuous state and observation spaces. We propose an Inﬁnitesimal Perturbation Analysis (IPA) on the ﬁltering distribution with respect to some parameters of the model. We describe a methodology for using any algorithm that estimates the ﬁltering density, such as Sequential Monte Carlo methods, to design an algorithm that estimates its gradient. The resulting IPA estimator is proven to be asymptotically unbiased, consistent and has computational complexity linear in the number of particles. We consider an application of this analysis to the problem of identifying unknown parameters of the model given a sequence of observations. We derive an IPA estimator for the gradient of the log-likelihood, which may be used in a gradient method for the purpose of likelihood maximization. We illustrate the method with several numerical experiments.</p><p>2 0.82414895 <a title="215-lsi-2" href="./nips-2009-On_Stochastic_and_Worst-case_Models_for_Investing.html">178 nips-2009-On Stochastic and Worst-case Models for Investing</a></p>
<p>Author: Elad Hazan, Satyen Kale</p><p>Abstract: In practice, most investing is done assuming a probabilistic model of stock price returns known as the Geometric Brownian Motion (GBM). While often an acceptable approximation, the GBM model is not always valid empirically. This motivates a worst-case approach to investing, called universal portfolio management, where the objective is to maximize wealth relative to the wealth earned by the best ﬁxed portfolio in hindsight. In this paper we tie the two approaches, and design an investment strategy which is universal in the worst-case, and yet capable of exploiting the mostly valid GBM model. Our method is based on new and improved regret bounds for online convex optimization with exp-concave loss functions. 1</p><p>3 0.79730046 <a title="215-lsi-3" href="./nips-2009-Adaptive_Regularization_of_Weight_Vectors.html">27 nips-2009-Adaptive Regularization of Weight Vectors</a></p>
<p>Author: Koby Crammer, Alex Kulesza, Mark Dredze</p><p>Abstract: We present AROW, a new online learning algorithm that combines several useful properties: large margin training, conﬁdence weighting, and the capacity to handle non-separable data. AROW performs adaptive regularization of the prediction function upon seeing each new instance, allowing it to perform especially well in the presence of label noise. We derive a mistake bound, similar in form to the second order perceptron bound, that does not assume separability. We also relate our algorithm to recent conﬁdence-weighted online learning techniques and show empirically that AROW achieves state-of-the-art performance and notable robustness in the case of non-separable data. 1</p><p>4 0.76655519 <a title="215-lsi-4" href="./nips-2009-Accelerated_Gradient_Methods_for_Stochastic_Optimization_and_Online_Learning.html">22 nips-2009-Accelerated Gradient Methods for Stochastic Optimization and Online Learning</a></p>
<p>Author: Chonghai Hu, Weike Pan, James T. Kwok</p><p>Abstract: Regularized risk minimization often involves non-smooth optimization, either because of the loss function (e.g., hinge loss) or the regularizer (e.g., ℓ1 -regularizer). Gradient methods, though highly scalable and easy to implement, are known to converge slowly. In this paper, we develop a novel accelerated gradient method for stochastic optimization while still preserving their computational simplicity and scalability. The proposed algorithm, called SAGE (Stochastic Accelerated GradiEnt), exhibits fast convergence rates on stochastic composite optimization with convex or strongly convex objectives. Experimental results show that SAGE is faster than recent (sub)gradient methods including FOLOS, SMIDAS and SCD. Moreover, SAGE can also be extended for online learning, resulting in a simple algorithm but with the best regret bounds currently known for these problems. 1</p><p>5 0.71017522 <a title="215-lsi-5" href="./nips-2009-Modeling_the_spacing_effect_in_sequential_category_learning.html">154 nips-2009-Modeling the spacing effect in sequential category learning</a></p>
<p>Author: Hongjing Lu, Matthew Weiden, Alan L. Yuille</p><p>Abstract: We develop a Bayesian sequential model for category learning. The sequential model updates two category parameters, the mean and the variance, over time. We deﬁne conjugate temporal priors to enable closed form solutions to be obtained. This model can be easily extended to supervised and unsupervised learning involving multiple categories. To model the spacing effect, we introduce a generic prior in the temporal updating stage to capture a learning preference, namely, less change for repetition and more change for variation. Finally, we show how this approach can be generalized to efﬁciently perform model selection to decide whether observations are from one or multiple categories.</p><p>6 0.69427639 <a title="215-lsi-6" href="./nips-2009-On_Learning_Rotations.html">177 nips-2009-On Learning Rotations</a></p>
<p>7 0.648996 <a title="215-lsi-7" href="./nips-2009-Slow_Learners_are_Fast.html">220 nips-2009-Slow Learners are Fast</a></p>
<p>8 0.49193838 <a title="215-lsi-8" href="./nips-2009-Information-theoretic_lower_bounds_on_the_oracle_complexity_of_convex_optimization.html">116 nips-2009-Information-theoretic lower bounds on the oracle complexity of convex optimization</a></p>
<p>9 0.48455518 <a title="215-lsi-9" href="./nips-2009-Manifold_Regularization_for_SIR_with_Rate_Root-n_Convergence.html">146 nips-2009-Manifold Regularization for SIR with Rate Root-n Convergence</a></p>
<p>10 0.47526231 <a title="215-lsi-10" href="./nips-2009-A_General_Projection_Property_for_Distribution_Families.html">11 nips-2009-A General Projection Property for Distribution Families</a></p>
<p>11 0.4551686 <a title="215-lsi-11" href="./nips-2009-Beyond_Convexity%3A_Online_Submodular_Minimization.html">45 nips-2009-Beyond Convexity: Online Submodular Minimization</a></p>
<p>12 0.41552117 <a title="215-lsi-12" href="./nips-2009-Generalization_Errors_and_Learning_Curves_for_Regression_with_Multi-task_Gaussian_Processes.html">101 nips-2009-Generalization Errors and Learning Curves for Regression with Multi-task Gaussian Processes</a></p>
<p>13 0.41279054 <a title="215-lsi-13" href="./nips-2009-An_Integer_Projected_Fixed_Point_Method_for_Graph_Matching_and_MAP_Inference.html">30 nips-2009-An Integer Projected Fixed Point Method for Graph Matching and MAP Inference</a></p>
<p>14 0.41194108 <a title="215-lsi-14" href="./nips-2009-Learning_in_Markov_Random_Fields_using_Tempered_Transitions.html">132 nips-2009-Learning in Markov Random Fields using Tempered Transitions</a></p>
<p>15 0.36838314 <a title="215-lsi-15" href="./nips-2009-White_Functionals_for_Anomaly_Detection_in_Dynamical_Systems.html">257 nips-2009-White Functionals for Anomaly Detection in Dynamical Systems</a></p>
<p>16 0.3535122 <a title="215-lsi-16" href="./nips-2009-Speeding_up_Magnetic_Resonance_Image_Acquisition_by_Bayesian_Multi-Slice_Adaptive_Compressed_Sensing.html">228 nips-2009-Speeding up Magnetic Resonance Image Acquisition by Bayesian Multi-Slice Adaptive Compressed Sensing</a></p>
<p>17 0.34842163 <a title="215-lsi-17" href="./nips-2009-Time-Varying_Dynamic_Bayesian_Networks.html">246 nips-2009-Time-Varying Dynamic Bayesian Networks</a></p>
<p>18 0.32965925 <a title="215-lsi-18" href="./nips-2009-Particle-based_Variational_Inference_for_Continuous_Systems.html">187 nips-2009-Particle-based Variational Inference for Continuous Systems</a></p>
<p>19 0.31515458 <a title="215-lsi-19" href="./nips-2009-Discrete_MDL_Predicts_in_Total_Variation.html">69 nips-2009-Discrete MDL Predicts in Total Variation</a></p>
<p>20 0.30506659 <a title="215-lsi-20" href="./nips-2009-Efficient_Learning_using_Forward-Backward_Splitting.html">76 nips-2009-Efficient Learning using Forward-Backward Splitting</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.033), (24, 0.039), (25, 0.06), (35, 0.072), (36, 0.091), (39, 0.049), (48, 0.191), (58, 0.107), (61, 0.059), (62, 0.023), (66, 0.021), (71, 0.098), (86, 0.042)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.83350384 <a title="215-lda-1" href="./nips-2009-Rank-Approximate_Nearest_Neighbor_Search%3A_Retaining_Meaning_and_Speed_in_High_Dimensions.html">198 nips-2009-Rank-Approximate Nearest Neighbor Search: Retaining Meaning and Speed in High Dimensions</a></p>
<p>Author: Parikshit Ram, Dongryeol Lee, Hua Ouyang, Alexander G. Gray</p><p>Abstract: The long-standing problem of efďŹ cient nearest-neighbor (NN) search has ubiquitous applications ranging from astrophysics to MP3 ďŹ ngerprinting to bioinformatics to movie recommendations. As the dimensionality of the dataset increases, exact NN search becomes computationally prohibitive; (1+đ?&oelig;&ndash;) distance-approximate NN search can provide large speedups but risks losing the meaning of NN search present in the ranks (ordering) of the distances. This paper presents a simple, practical algorithm allowing the user to, for the ďŹ rst time, directly control the true accuracy of NN search (in terms of ranks) while still achieving the large speedups over exact NN. Experiments on high-dimensional datasets show that our algorithm often achieves faster and more accurate results than the best-known distance-approximate method, with much more stable behavior. 1</p><p>same-paper 2 0.83298469 <a title="215-lda-2" href="./nips-2009-Sensitivity_analysis_in_HMMs_with_application_to_likelihood_maximization.html">215 nips-2009-Sensitivity analysis in HMMs with application to likelihood maximization</a></p>
<p>Author: Pierre-arnaud Coquelin, Romain Deguest, Rémi Munos</p><p>Abstract: This paper considers a sensitivity analysis in Hidden Markov Models with continuous state and observation spaces. We propose an Inﬁnitesimal Perturbation Analysis (IPA) on the ﬁltering distribution with respect to some parameters of the model. We describe a methodology for using any algorithm that estimates the ﬁltering density, such as Sequential Monte Carlo methods, to design an algorithm that estimates its gradient. The resulting IPA estimator is proven to be asymptotically unbiased, consistent and has computational complexity linear in the number of particles. We consider an application of this analysis to the problem of identifying unknown parameters of the model given a sequence of observations. We derive an IPA estimator for the gradient of the log-likelihood, which may be used in a gradient method for the purpose of likelihood maximization. We illustrate the method with several numerical experiments.</p><p>3 0.80488271 <a title="215-lda-3" href="./nips-2009-Entropic_Graph_Regularization_in_Non-Parametric_Semi-Supervised_Classification.html">82 nips-2009-Entropic Graph Regularization in Non-Parametric Semi-Supervised Classification</a></p>
<p>Author: Amarnag Subramanya, Jeff A. Bilmes</p><p>Abstract: We prove certain theoretical properties of a graph-regularized transductive learning objective that is based on minimizing a Kullback-Leibler divergence based loss. These include showing that the iterative alternating minimization procedure used to minimize the objective converges to the correct solution and deriving a test for convergence. We also propose a graph node ordering algorithm that is cache cognizant and leads to a linear speedup in parallel computations. This ensures that the algorithm scales to large data sets. By making use of empirical evaluation on the TIMIT and Switchboard I corpora, we show this approach is able to outperform other state-of-the-art SSL approaches. In one instance, we solve a problem on a 120 million node graph. 1</p><p>4 0.72891098 <a title="215-lda-4" href="./nips-2009-Efficient_Match_Kernel_between_Sets_of_Features_for_Visual_Recognition.html">77 nips-2009-Efficient Match Kernel between Sets of Features for Visual Recognition</a></p>
<p>Author: Liefeng Bo, Cristian Sminchisescu</p><p>Abstract: In visual recognition, the images are frequently modeled as unordered collections of local features (bags). We show that bag-of-words representations commonly used in conjunction with linear classiﬁers can be viewed as special match kernels, which count 1 if two local features fall into the same regions partitioned by visual words and 0 otherwise. Despite its simplicity, this quantization is too coarse, motivating research into the design of match kernels that more accurately measure the similarity between local features. However, it is impractical to use such kernels for large datasets due to their signiﬁcant computational cost. To address this problem, we propose efﬁcient match kernels (EMK) that map local features to a low dimensional feature space and average the resulting vectors to form a setlevel feature. The local feature maps are learned so their inner products preserve, to the best possible, the values of the speciﬁed kernel function. Classiﬁers based on EMK are linear both in the number of images and in the number of local features. We demonstrate that EMK are extremely efﬁcient and achieve the current state of the art in three difﬁcult computer vision datasets: Scene-15, Caltech-101 and Caltech-256. 1</p><p>5 0.70826292 <a title="215-lda-5" href="./nips-2009-A_Stochastic_approximation_method_for_inference_in_probabilistic_graphical_models.html">18 nips-2009-A Stochastic approximation method for inference in probabilistic graphical models</a></p>
<p>Author: Peter Carbonetto, Matthew King, Firas Hamze</p><p>Abstract: We describe a new algorithmic framework for inference in probabilistic models, and apply it to inference for latent Dirichlet allocation (LDA). Our framework adopts the methodology of variational inference, but unlike existing variational methods such as mean ﬁeld and expectation propagation it is not restricted to tractable classes of approximating distributions. Our approach can also be viewed as a “population-based” sequential Monte Carlo (SMC) method, but unlike existing SMC methods there is no need to design the artiﬁcial sequence of distributions. Signiﬁcantly, our framework oﬀers a principled means to exchange the variance of an importance sampling estimate for the bias incurred through variational approximation. We conduct experiments on a diﬃcult inference problem in population genetics, a problem that is related to inference for LDA. The results of these experiments suggest that our method can oﬀer improvements in stability and accuracy over existing methods, and at a comparable cost. 1</p><p>6 0.69960845 <a title="215-lda-6" href="./nips-2009-Improving_Existing_Fault_Recovery_Policies.html">113 nips-2009-Improving Existing Fault Recovery Policies</a></p>
<p>7 0.69428378 <a title="215-lda-7" href="./nips-2009-Bayesian_Source_Localization_with_the_Multivariate_Laplace_Prior.html">41 nips-2009-Bayesian Source Localization with the Multivariate Laplace Prior</a></p>
<p>8 0.69247538 <a title="215-lda-8" href="./nips-2009-Training_Factor_Graphs_with_Reinforcement_Learning_for_Efficient_MAP_Inference.html">250 nips-2009-Training Factor Graphs with Reinforcement Learning for Efficient MAP Inference</a></p>
<p>9 0.68881828 <a title="215-lda-9" href="./nips-2009-Bayesian_Nonparametric_Models_on_Decomposable_Graphs.html">40 nips-2009-Bayesian Nonparametric Models on Decomposable Graphs</a></p>
<p>10 0.68096846 <a title="215-lda-10" href="./nips-2009-AUC_optimization_and_the_two-sample_problem.html">3 nips-2009-AUC optimization and the two-sample problem</a></p>
<p>11 0.679672 <a title="215-lda-11" href="./nips-2009-Free_energy_score_space.html">97 nips-2009-Free energy score space</a></p>
<p>12 0.6795854 <a title="215-lda-12" href="./nips-2009-Multi-Label_Prediction_via_Sparse_Infinite_CCA.html">158 nips-2009-Multi-Label Prediction via Sparse Infinite CCA</a></p>
<p>13 0.67637438 <a title="215-lda-13" href="./nips-2009-Sparse_and_Locally_Constant_Gaussian_Graphical_Models.html">224 nips-2009-Sparse and Locally Constant Gaussian Graphical Models</a></p>
<p>14 0.67516178 <a title="215-lda-14" href="./nips-2009-Maximum_likelihood_trajectories_for_continuous-time_Markov_chains.html">150 nips-2009-Maximum likelihood trajectories for continuous-time Markov chains</a></p>
<p>15 0.67457181 <a title="215-lda-15" href="./nips-2009-Nonparametric_Latent_Feature_Models_for_Link_Prediction.html">174 nips-2009-Nonparametric Latent Feature Models for Link Prediction</a></p>
<p>16 0.67354119 <a title="215-lda-16" href="./nips-2009-Accelerated_Gradient_Methods_for_Stochastic_Optimization_and_Online_Learning.html">22 nips-2009-Accelerated Gradient Methods for Stochastic Optimization and Online Learning</a></p>
<p>17 0.67352283 <a title="215-lda-17" href="./nips-2009-Sharing_Features_among_Dynamical_Systems_with_Beta_Processes.html">217 nips-2009-Sharing Features among Dynamical Systems with Beta Processes</a></p>
<p>18 0.67303771 <a title="215-lda-18" href="./nips-2009-Particle-based_Variational_Inference_for_Continuous_Systems.html">187 nips-2009-Particle-based Variational Inference for Continuous Systems</a></p>
<p>19 0.67269212 <a title="215-lda-19" href="./nips-2009-An_Additive_Latent_Feature_Model_for_Transparent_Object_Recognition.html">28 nips-2009-An Additive Latent Feature Model for Transparent Object Recognition</a></p>
<p>20 0.67241943 <a title="215-lda-20" href="./nips-2009-Gaussian_process_regression_with_Student-t_likelihood.html">100 nips-2009-Gaussian process regression with Student-t likelihood</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
