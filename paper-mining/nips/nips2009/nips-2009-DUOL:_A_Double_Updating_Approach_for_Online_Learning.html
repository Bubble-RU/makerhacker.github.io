<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>63 nips-2009-DUOL: A Double Updating Approach for Online Learning</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-63" href="#">nips2009-63</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>63 nips-2009-DUOL: A Double Updating Approach for Online Learning</h1>
<br/><p>Source: <a title="nips-2009-63-pdf" href="http://papers.nips.cc/paper/3787-duol-a-double-updating-approach-for-online-learning.pdf">pdf</a></p><p>Author: Peilin Zhao, Steven C. Hoi, Rong Jin</p><p>Abstract: In most online learning algorithms, the weights assigned to the misclassiﬁed examples (or support vectors) remain unchanged during the entire learning process. This is clearly insufﬁcient since when a new misclassiﬁed example is added to the pool of support vectors, we generally expect it to affect the weights for the existing support vectors. In this paper, we propose a new online learning method, termed Double Updating Online Learning, or DUOL for short. Instead of only assigning a ﬁxed weight to the misclassiﬁed example received in current trial, the proposed online learning algorithm also tries to update the weight for one of the existing support vectors. We show that the mistake bound can be signiﬁcantly improved by the proposed online learning method. Encouraging experimental results show that the proposed technique is in general considerably more effective than the state-of-the-art online learning algorithms. 1</p><p>Reference: <a title="nips-2009-63-reference" href="../nips2009_reference/nips-2009-DUOL%3A_A_Double_Updating_Approach_for_Online_Learning_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract In most online learning algorithms, the weights assigned to the misclassiﬁed examples (or support vectors) remain unchanged during the entire learning process. [sent-19, score-0.384]
</p><p>2 This is clearly insufﬁcient since when a new misclassiﬁed example is added to the pool of support vectors, we generally expect it to affect the weights for the existing support vectors. [sent-20, score-0.261]
</p><p>3 In this paper, we propose a new online learning method, termed Double Updating Online Learning, or DUOL for short. [sent-21, score-0.239]
</p><p>4 Instead of only assigning a ﬁxed weight to the misclassiﬁed example received in current trial, the proposed online learning algorithm also tries to update the weight for one of the existing support vectors. [sent-22, score-0.483]
</p><p>5 We show that the mistake bound can be signiﬁcantly improved by the proposed online learning method. [sent-23, score-0.378]
</p><p>6 Encouraging experimental results show that the proposed technique is in general considerably more effective than the state-of-the-art online learning algorithms. [sent-24, score-0.27]
</p><p>7 Most online learning algorithms work by assigning a ﬁxed weight to a new example when it is misclassiﬁed. [sent-28, score-0.303]
</p><p>8 This is clearly insufﬁcient because when a new example is added to the pool of support vectors, we expect it to affect the weights assigned to the existing support vectors received in previous trials. [sent-30, score-0.364]
</p><p>9 Although several online algorithms are capable of updating the example weights as the learning process goes, most of them are designed for the purposes other than improving the classiﬁcation accuracy and reducing the mistake bound. [sent-31, score-0.507]
</p><p>10 , 2005), online learning algorithms are proposed to adjust the example weights in order to ﬁt in the constraint of ﬁxed number of support vectors; in (Cesa-Bianchi & Gentile, 2006), example weights are adjusted to track the drifting concepts. [sent-35, score-0.469]
</p><p>11 In this paper, we propose a new formulation for online learning that aims to dynamically update the example weights in order to improve the classiﬁcation accuracy as well as the mistake bound. [sent-36, score-0.428]
</p><p>12 Instead of only assigning a weight to the misclassiﬁed example that is received in current trial, the proposed online learning algorithm also updates the weight for one of the existing support vectors. [sent-37, score-0.481]
</p><p>13 The key question in the proposed online learning approach is which one of the existing support vectors should be selected for weight updating. [sent-40, score-0.465]
</p><p>14 To this end, we employ an analysis for double updating online learning that is based on the recent work of online convex programming by incremental dual ascent (Shalev-Shwartz & Singer, 2006). [sent-41, score-0.685]
</p><p>15 Our analysis shows that under certain conditions, the proposed online learning algorithm can signiﬁcantly reduce the mistake bound of the existing online algorithms. [sent-42, score-0.635]
</p><p>16 This result is further veriﬁed empirically by extensive experiments and comparison to the state-of-the-art algorithms for online learning. [sent-43, score-0.267]
</p><p>17 Section 2 reviews the related work for online learning. [sent-45, score-0.239]
</p><p>18 Section 3 presents the proposed “double updating” approach to online learning. [sent-46, score-0.252]
</p><p>19 One of the most well-known online approaches is the Perceptron algorithm (Rosenblatt, 1958; Freund & Schapire, 1999), which updates the learning function by adding a new example with a constant weight into the current set of support vectors when it is misclassiﬁed. [sent-54, score-0.452]
</p><p>20 Recently a number of online learning algorithms have been developed based on the criterion of maximum margin (Crammer & Singer, 2003; Gentile, 2001; Kivinen et al. [sent-55, score-0.314]
</p><p>21 Empirical studies showed that the maximum margin based online learning algorithms are generally more effective than the Perceptron algorithm. [sent-62, score-0.287]
</p><p>22 However, despite the difference, most online learning algorithms only update the weight of the newly added support vector, and keep the weights of the existing support vectors unchanged. [sent-63, score-0.663]
</p><p>23 This constraint could signiﬁcantly limit the effect of online learning. [sent-64, score-0.239]
</p><p>24 Besides the studies for regular online learning, several algorithms are proposed for online learning with ﬁxed budget. [sent-65, score-0.519]
</p><p>25 In these studies, the total number of support vectors is required to be bounded either by a theoretical bound or by a manually ﬁxed budget. [sent-66, score-0.187]
</p><p>26 Example algorithms for ﬁxed budget online learning include (Weston & Bordes, 2005; Crammer et al. [sent-67, score-0.323]
</p><p>27 The key idea of these algorithms is to dynamically update the weights of the existing support vectors as a new support vector is added, and the support vector with the least weight will be discarded when the number of support vectors exceeds the budget. [sent-71, score-0.669]
</p><p>28 The idea of discarding support vectors is also used in studies (Kivinen et al. [sent-72, score-0.186]
</p><p>29 , 2008), a new “projection” approach is proposed for online learning that ensures the number of support vectors is bounded. [sent-76, score-0.411]
</p><p>30 Besides, in (Cesa-Bianchi & Gentile, 2006), an online learning algorithm is proposed to handle the drifting concept, in which the weights of the existing support vectors are reduced whenever a new support vector is added. [sent-77, score-0.584]
</p><p>31 Although these online learning algorithms are capable of dynamically adjusting the weights of support vectors, they are designed to either ﬁt in the budget of the number of support vectors or to handle drifting concepts, not to improve the classiﬁcation accuracy and the mistake bound. [sent-78, score-0.762]
</p><p>32 The proposed online learning algorithm is closely related to the recent work of online convex programming by incremental dual ascent (Shalev-Shwartz & Singer, 2006). [sent-79, score-0.523]
</p><p>33 Although the idea of simultaneously updating the weights of multiple support vectors was mentioned in (Shalev-Shwartz & Singer, 2006), no efﬁcient updating algorithm was explicitly proposed. [sent-80, score-0.381]
</p><p>34 As will be shown later, the online algorithm proposed in this work shares the same computational cost as that of conventional online learning algorithms, despite the need of updating weights of two support vectors. [sent-81, score-0.753]
</p><p>35 1 Motivation We consider an online learning trial t with an incoming example that is misclassiﬁed. [sent-83, score-0.262]
</p><p>36 , αn ) ∈ [0, C]n the weights assigned to the support vectors in D, where C is a predeﬁned constant. [sent-93, score-0.208]
</p><p>37 The resulting classiﬁer, denoted by f (x), is expressed as n  f (x) =  αi yi κ(x, xi )  (1)  i=1  Let (xa , ya ) be the misclassiﬁed example received in the trial t, i. [sent-94, score-0.405]
</p><p>38 Let (xa , ya ) be an example misclassiﬁed by the current classiﬁer f (x) = n i=1 αi yi κ(x, xi ), i. [sent-99, score-0.357]
</p><p>39 Let f (x) = βya κ(x, xa ) + f (x) be the updated classiﬁer with β > 0. [sent-102, score-0.213]
</p><p>40 There exists at least one support vector xi ∈ D such that yi f (xi ) > yi f (xi ). [sent-103, score-0.268]
</p><p>41 It follows from the fact that: ∃xi ∈ D, yi ya κ(xi , xa ) < 0 when ya f (xa ) < 0. [sent-105, score-0.764]
</p><p>42 In the case when ya f (xa ) ≤ −γ, it is easy to verify that there exists some support vector (xb , yb ) who satisﬁes βya yb k(xa , xb ) ≤ −γ/n; at the meantime, it can be shown that when the classiﬁcation conﬁdence of (xb , yb ) is less than γ/n, i. [sent-107, score-1.565]
</p><p>43 , yb f (xb ) ≤ γ/n, such support vector will be misclassiﬁed after the classiﬁer is updated with the example (xa , ya ). [sent-109, score-0.676]
</p><p>44 In order to alleviate this problem, we propose to update the weight for the existing support vector whose classiﬁcation conﬁdence is signiﬁcantly affected by the new misclassiﬁed example. [sent-110, score-0.17]
</p><p>45 In particular, we consider a support vector (xb , yb ) ∈ D for weight updating if it satisﬁes the following two conditions • yb f (xb ) ≤ 0, i. [sent-111, score-0.858]
</p><p>46 , support vector (xb , yb ) is misclassiﬁed by the current classiﬁer f (x) • k(xb , xa )ya yb ≤ −ρ where ρ ≥ 0 is a predeﬁned threshold, i. [sent-113, score-0.927]
</p><p>47 , support vector (xb , yb ) “conﬂicts” with the new misclassiﬁed example (xa , ya ). [sent-115, score-0.662]
</p><p>48 We refer to the support vector satisfying the above conditions as auxiliary example. [sent-116, score-0.158]
</p><p>49 It is clear that by adding the misclassiﬁed example (xa , ya ) to classiﬁer f (x) with weight β, the classiﬁcation score of (xb , yb ) will be reduced by at least βρ, which could lead to the misclassiﬁcation of the auxiliary example (xb , yb ). [sent-117, score-0.995]
</p><p>50 To avoid such a mistake, we propose to update the weights for both (xa , ya ) and (xb , yb ) simultaneously. [sent-118, score-0.62]
</p><p>51 In the next section, we show the details of the double updating algorithm for online learning, and the analysis for mistake bound. [sent-119, score-0.526]
</p><p>52 Our analysis follows closely the previous work on the relationship between online learning and the dual formulation of SVM (Shalev-Shwartz & Singer, 2006), in which the online learning is interpreted as an efﬁcient updating rule for maximizing the objective function in the dual form of SVM. [sent-120, score-0.636]
</p><p>53 If an online learning algorithm A is designed to ensure that all ∆t is bounded from the below by a positive constant ∆, then the number of mistakes made by A when trained over a sequence of trials (x1 , y1 ), . [sent-122, score-0.35]
</p><p>54 In our analysis, we will show that ∆, which is referred to as the bounding constant for the improvement in the objective function, could be signiﬁcantly improved when updating the weight for both the newly misclassiﬁed example and the auxiliary example. [sent-126, score-0.208]
</p><p>55 For the remaining part of this paper, we denote by (xb , yb ) an auxiliary example that satisﬁes the two conditions speciﬁed before. [sent-127, score-0.378]
</p><p>56 , αn−1 )) ∈ Rn−1 to denote the weights assigned to all the support vectors in D except (xb , yb ). [sent-131, score-0.524]
</p><p>57 , yn−1 ) ∈ [−1, 1]n−1 the class labels assigned to all the examples in D except for (xb , yb ). [sent-135, score-0.331]
</p><p>58 We deﬁne sa = κ(xa , xa ), sb = κ(xb , xb ), sab = κ(xa , xb ), wab = ya yb sab . [sent-136, score-1.503]
</p><p>59 (4) According to the assumption of auxiliary example, we have wab = sab ya yb ≤ −ρ. [sent-137, score-0.725]
</p><p>60 Finally, we denote by γb the weight for the auxiliary example (xb , yb ) that is used in the current classiﬁer f (x), and by γa and γb the updated weights for (xa , ya ) and (xb , yb ), respectively. [sent-138, score-1.028]
</p><p>61 2  Double Updating Online Learning  Recall an auxiliary example (xb , yb ) should satisfy two conditions (I) yb f (xb ) ≤ 0, and (II) wab ≤ −ρ. [sent-141, score-0.759]
</p><p>62 In addition, the new example (xa , ya ) received in the current iteration t is misclassiﬁed, i. [sent-142, score-0.275]
</p><p>63 Following the framework of dual formulation for online learning, the following lemma shows how to compute ∆t , i. [sent-145, score-0.271]
</p><p>64 , the improvement in the objective function of dual SVM by adjusting weights for (xa , ya ) and (xb , yb ). [sent-147, score-0.649]
</p><p>65 It is straightforward to verify that the dual function of min  ft  2 Hκ +C  t i=1  (6)  (yi ft (xi )),  denoted by Dt (γ1 , . [sent-150, score-0.499]
</p><p>66 , γt ) =  t  γi − i=1  γi yi ft (xi ) + i=1 t i=1  1 ft 2  2 Hκ  (7)  where 0 ≤ γi ≤ C, i = 1, . [sent-156, score-0.519]
</p><p>67 , t and ft (·) = γi yi κ(·, xi ) is the current classiﬁer. [sent-159, score-0.334]
</p><p>68 Note that this constraint does not come directly from the box constraint that the weight for example (xb , yb ) is in the range [0, C], i. [sent-173, score-0.352]
</p><p>69 , sb 2 g(∆γb ) = ∆γb (1 − yb ft−1 (xb ) − wab γa ) − ∆γb 2 Since wab ≤ −ρ and yb ft−1 (xb ) ≤ 0, it is clear that ∆γb ≥ 0 when maximizing g(∆γb ), which results in the constraint ∆γb ≥ 0. [sent-178, score-0.802]
</p><p>70 Assume C > γb + 1/(1 − ρ) for the selected auxiliary example (xb , yb ). [sent-181, score-0.378]
</p><p>71 We have the following bound for ∆, when updating the weights for the new example (xa , ya ) and the auxiliary example (xb , yb ) ∆≥  1 1 + min (1 + ρ)2 , (C − γ)2 2 2  Proof. [sent-188, score-0.783]
</p><p>72 The ﬁnal remaining question is how to identify the auxiliary example (xb , yb ) efﬁciently, which requires efﬁciently updating the classiﬁcation score yi f (xi ) for all the support vectors. [sent-191, score-0.648]
</p><p>73 This updating procedure ensures that the computational cost of double updating online learning is O(n), where n is the number of support vectors, similar to that of the kernel online learning algorithm. [sent-194, score-0.867]
</p><p>74 We denote by Ms the number of mistakes when we made a single update without ﬁnding appropriate auxiliary example. [sent-205, score-0.179]
</p><p>75 1 Experimental Testbed and Setup We now evaluate the empirical performance of the proposed double updating online learning (DUOL) algorithm. [sent-214, score-0.427]
</p><p>76 Finally, as an ideal yardstick, we also implement a full online SVM algorithm (“Online-SVM”) (Shalev-Shwartz & Singer, 2006), which updates all the support vectors in each trial, and is thus computationally extremely intensive as will be revealed in our study. [sent-222, score-0.416]
</p><p>77 We evaluate the online learning performance by measuring mistake rate, i. [sent-234, score-0.351]
</p><p>78 , the ratio of the number of mistakes made by the online learning algorithm over the total number of examples received for predictions. [sent-236, score-0.361]
</p><p>79 In addition, to examine the sparsity of the resulting classiﬁers, we also evaluate the number of support vectors produced by each online learning algorithm. [sent-237, score-0.398]
</p><p>80 Figure 2 to 6 show the mistake rates of all online learning algorithms in comparison over trials. [sent-243, score-0.379]
</p><p>81 We observe that Online-SVM yields considerably better performance than the other online learning algorithms for dataset “german”, “splice”, “spambase”, and “MITFace”, however, at the price of extremely high computational cost. [sent-244, score-0.285]
</p><p>82 For most cases, the running time of Online-SVM is two order, sometimes three order, higher than the other online learning algorithms, making it 1  http://www. [sent-245, score-0.239]
</p><p>83 For the remaining part of this section, we restrict our discussion to the other six baseline online learning algorithms. [sent-257, score-0.258]
</p><p>84 We also notice that the agg-ROMMA and the two PA algorithms consume considerably larger numbers of support vectors than the other three algorithms. [sent-261, score-0.205]
</p><p>85 Second, comparing with all six competing algorithms, we observe that DUOL achieves signiﬁcantly smaller mistake rates than the other single-updating algorithms in all cases. [sent-264, score-0.159]
</p><p>86 This shows that the proposed double updating approach is effective in improving the online prediction performance. [sent-265, score-0.427]
</p><p>87 By examining the sparsity of resulting classiﬁers, we observed that DUOL results in sparser classiﬁers than the three aggressive online learning algorithms, and denser classiﬁers than the three non-aggressive algorithms. [sent-266, score-0.266]
</p><p>88 Third, according to the results of running time, we observe that DUOL is overall efﬁcient compared to the state-of-the-art online learning algorithms. [sent-267, score-0.239]
</p><p>89 677  Conclusions  This paper presented a novel “double updating” approach to online learning named as “DUOL”, which not only updates the weight of the newly added support vector, but also adjusts the weight of one existing support vector that seriously conﬂicts with the new support vector. [sent-512, score-0.668]
</p><p>90 We show that the mistake bound for an online classiﬁcation task can be signiﬁcantly reduced by the proposed DUOL algorithms. [sent-513, score-0.378]
</p><p>91 Future work will address issues of multi-class double updating online learning. [sent-516, score-0.414]
</p><p>92 4  PA−I PA−II Online−SVM DUOL  Online average number of support vectors  Online average rate of mistakes  0. [sent-519, score-0.321]
</p><p>93 25  0  200  400 600 Number of samples  800  0  1000  (a) average rate of mistakes  0  200  400 600 Number of samples  800  1000  0  (b) average number of support vectors  200  400 600 Number of samples  800  1000  (c) average time cost (log10 t)  Figure 2: Evaluation on the german dataset. [sent-527, score-0.455]
</p><p>94 9)  3  2  average time cost (log10 t)  Online average rate of mistakes  Online average number of support vectors  Perceptron ROMMA agg−ROMMA ALMA (0. [sent-537, score-0.37]
</p><p>95 9)  7000  average time cost (log10 t)  Online average rate of mistakes  Online average number of support vectors  Perceptron ROMMA agg−ROMMA ALMA (0. [sent-568, score-0.37]
</p><p>96 27  0  2000  4000  6000 8000 10000 Number of samples  12000  14000  −2  16000  (b) average number of support vectors  0  2000  4000  6000 8000 10000 Number of samples  12000  14000  16000  (c) average time cost (log10 t)  Figure 5: Evaluation on the a7a dataset. [sent-570, score-0.273]
</p><p>97 3500  Online average rate of mistakes  Online average number of support vectors  Perceptron ROMMA agg−ROMMA ALMA (0. [sent-572, score-0.321]
</p><p>98 5 Number of samples  2  (a) average rate of mistakes  2. [sent-591, score-0.157]
</p><p>99 5 4  x 10  (b) average number of support vectors  −2  0  0. [sent-595, score-0.184]
</p><p>100 The forgetron: A kernel-based perceptron on a ﬁxed budget. [sent-655, score-0.198]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('romma', 0.421), ('duol', 0.4), ('yb', 0.316), ('xb', 0.271), ('ya', 0.25), ('online', 0.239), ('ft', 0.227), ('xa', 0.199), ('perceptron', 0.198), ('pa', 0.161), ('misclassi', 0.158), ('alma', 0.158), ('agg', 0.138), ('mistake', 0.112), ('mistakes', 0.097), ('support', 0.096), ('updating', 0.094), ('crammer', 0.086), ('double', 0.081), ('yi', 0.065), ('wab', 0.065), ('gentile', 0.063), ('vectors', 0.063), ('auxiliary', 0.062), ('yt', 0.057), ('rosenblatt', 0.053), ('singer', 0.053), ('kivinen', 0.051), ('xt', 0.047), ('md', 0.045), ('xi', 0.042), ('wmin', 0.042), ('dekel', 0.04), ('sb', 0.04), ('svm', 0.039), ('classi', 0.039), ('spambase', 0.037), ('weight', 0.036), ('ii', 0.035), ('weights', 0.034), ('splice', 0.034), ('st', 0.032), ('mitface', 0.032), ('orabona', 0.032), ('sab', 0.032), ('dual', 0.032), ('budget', 0.029), ('algorithms', 0.028), ('et', 0.027), ('aggressive', 0.027), ('sa', 0.027), ('drifting', 0.025), ('average', 0.025), ('german', 0.025), ('received', 0.025), ('cost', 0.024), ('trial', 0.023), ('dynamically', 0.023), ('er', 0.022), ('freund', 0.022), ('almap', 0.021), ('cavallanti', 0.021), ('forgetron', 0.021), ('dt', 0.021), ('schapire', 0.021), ('margin', 0.02), ('end', 0.02), ('evaluation', 0.02), ('samples', 0.02), ('update', 0.02), ('six', 0.019), ('bordes', 0.018), ('williamson', 0.018), ('fink', 0.018), ('existing', 0.018), ('considerably', 0.018), ('updates', 0.018), ('adjusting', 0.017), ('cheng', 0.017), ('fti', 0.017), ('nanyang', 0.017), ('added', 0.017), ('newly', 0.016), ('keshet', 0.016), ('icts', 0.016), ('ms', 0.015), ('rate', 0.015), ('singapore', 0.015), ('assigned', 0.015), ('score', 0.015), ('prede', 0.015), ('cation', 0.014), ('bound', 0.014), ('updated', 0.014), ('li', 0.014), ('bounded', 0.014), ('jmlr', 0.014), ('conventional', 0.014), ('min', 0.013), ('proposed', 0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="63-tfidf-1" href="./nips-2009-DUOL%3A_A_Double_Updating_Approach_for_Online_Learning.html">63 nips-2009-DUOL: A Double Updating Approach for Online Learning</a></p>
<p>Author: Peilin Zhao, Steven C. Hoi, Rong Jin</p><p>Abstract: In most online learning algorithms, the weights assigned to the misclassiﬁed examples (or support vectors) remain unchanged during the entire learning process. This is clearly insufﬁcient since when a new misclassiﬁed example is added to the pool of support vectors, we generally expect it to affect the weights for the existing support vectors. In this paper, we propose a new online learning method, termed Double Updating Online Learning, or DUOL for short. Instead of only assigning a ﬁxed weight to the misclassiﬁed example received in current trial, the proposed online learning algorithm also tries to update the weight for one of the existing support vectors. We show that the mistake bound can be signiﬁcantly improved by the proposed online learning method. Encouraging experimental results show that the proposed technique is in general considerably more effective than the state-of-the-art online learning algorithms. 1</p><p>2 0.24156162 <a title="63-tfidf-2" href="./nips-2009-Learning_Bregman_Distance_Functions_and_Its_Application_for_Semi-Supervised_Clustering.html">126 nips-2009-Learning Bregman Distance Functions and Its Application for Semi-Supervised Clustering</a></p>
<p>Author: Lei Wu, Rong Jin, Steven C. Hoi, Jianke Zhu, Nenghai Yu</p><p>Abstract: Learning distance functions with side information plays a key role in many machine learning and data mining applications. Conventional approaches often assume a Mahalanobis distance function. These approaches are limited in two aspects: (i) they are computationally expensive (even infeasible) for high dimensional data because the size of the metric is in the square of dimensionality; (ii) they assume a ﬁxed metric for the entire input space and therefore are unable to handle heterogeneous data. In this paper, we propose a novel scheme that learns nonlinear Bregman distance functions from side information using a nonparametric approach that is similar to support vector machines. The proposed scheme avoids the assumption of ﬁxed metric by implicitly deriving a local distance from the Hessian matrix of a convex function that is used to generate the Bregman distance function. We also present an efﬁcient learning algorithm for the proposed scheme for distance function learning. The extensive experiments with semi-supervised clustering show the proposed technique (i) outperforms the state-of-the-art approaches for distance function learning, and (ii) is computationally efﬁcient for high dimensional data. 1</p><p>3 0.14159453 <a title="63-tfidf-3" href="./nips-2009-Beyond_Convexity%3A_Online_Submodular_Minimization.html">45 nips-2009-Beyond Convexity: Online Submodular Minimization</a></p>
<p>Author: Elad Hazan, Satyen Kale</p><p>Abstract: We consider an online decision problem over a discrete space in which the loss function is submodular. We give algorithms which are computationally efﬁcient and are Hannan-consistent in both the full information and bandit settings. 1</p><p>4 0.12931842 <a title="63-tfidf-4" href="./nips-2009-Slow_Learners_are_Fast.html">220 nips-2009-Slow Learners are Fast</a></p>
<p>Author: Martin Zinkevich, John Langford, Alex J. Smola</p><p>Abstract: Online learning algorithms have impressive convergence properties when it comes to risk minimization and convex games on very large problems. However, they are inherently sequential in their design which prevents them from taking advantage of modern multi-core architectures. In this paper we prove that online learning with delayed updates converges well, thereby facilitating parallel online learning. 1</p><p>5 0.098143362 <a title="63-tfidf-5" href="./nips-2009-Adaptive_Regularization_of_Weight_Vectors.html">27 nips-2009-Adaptive Regularization of Weight Vectors</a></p>
<p>Author: Koby Crammer, Alex Kulesza, Mark Dredze</p><p>Abstract: We present AROW, a new online learning algorithm that combines several useful properties: large margin training, conﬁdence weighting, and the capacity to handle non-separable data. AROW performs adaptive regularization of the prediction function upon seeing each new instance, allowing it to perform especially well in the presence of label noise. We derive a mistake bound, similar in form to the second order perceptron bound, that does not assume separability. We also relate our algorithm to recent conﬁdence-weighted online learning techniques and show empirically that AROW achieves state-of-the-art performance and notable robustness in the case of non-separable data. 1</p><p>6 0.097651124 <a title="63-tfidf-6" href="./nips-2009-On_Stochastic_and_Worst-case_Models_for_Investing.html">178 nips-2009-On Stochastic and Worst-case Models for Investing</a></p>
<p>7 0.089099653 <a title="63-tfidf-7" href="./nips-2009-Online_Learning_of_Assignments.html">181 nips-2009-Online Learning of Assignments</a></p>
<p>8 0.079750635 <a title="63-tfidf-8" href="./nips-2009-Regularized_Distance_Metric_Learning%3ATheory_and_Algorithm.html">202 nips-2009-Regularized Distance Metric Learning:Theory and Algorithm</a></p>
<p>9 0.068175226 <a title="63-tfidf-9" href="./nips-2009-A_Stochastic_approximation_method_for_inference_in_probabilistic_graphical_models.html">18 nips-2009-A Stochastic approximation method for inference in probabilistic graphical models</a></p>
<p>10 0.060300998 <a title="63-tfidf-10" href="./nips-2009-Accelerated_Gradient_Methods_for_Stochastic_Optimization_and_Online_Learning.html">22 nips-2009-Accelerated Gradient Methods for Stochastic Optimization and Online Learning</a></p>
<p>11 0.05524103 <a title="63-tfidf-11" href="./nips-2009-A_joint_maximum-entropy_model_for_binary_neural_population_patterns_and_continuous_signals.html">19 nips-2009-A joint maximum-entropy model for binary neural population patterns and continuous signals</a></p>
<p>12 0.050531089 <a title="63-tfidf-12" href="./nips-2009-Multiple_Incremental_Decremental_Learning_of_Support_Vector_Machines.html">160 nips-2009-Multiple Incremental Decremental Learning of Support Vector Machines</a></p>
<p>13 0.049934901 <a title="63-tfidf-13" href="./nips-2009-Dual_Averaging_Method_for_Regularized_Stochastic_Learning_and_Online_Optimization.html">73 nips-2009-Dual Averaging Method for Regularized Stochastic Learning and Online Optimization</a></p>
<p>14 0.047088973 <a title="63-tfidf-14" href="./nips-2009-Label_Selection_on_Graphs.html">122 nips-2009-Label Selection on Graphs</a></p>
<p>15 0.045672636 <a title="63-tfidf-15" href="./nips-2009-On_Learning_Rotations.html">177 nips-2009-On Learning Rotations</a></p>
<p>16 0.045531813 <a title="63-tfidf-16" href="./nips-2009-Efficient_Learning_using_Forward-Backward_Splitting.html">76 nips-2009-Efficient Learning using Forward-Backward Splitting</a></p>
<p>17 0.043038793 <a title="63-tfidf-17" href="./nips-2009-Kernel_Choice_and_Classifiability_for_RKHS_Embeddings_of_Probability_Distributions.html">118 nips-2009-Kernel Choice and Classifiability for RKHS Embeddings of Probability Distributions</a></p>
<p>18 0.041799951 <a title="63-tfidf-18" href="./nips-2009-Learning_a_Small_Mixture_of_Trees.html">129 nips-2009-Learning a Small Mixture of Trees</a></p>
<p>19 0.041443236 <a title="63-tfidf-19" href="./nips-2009-Distribution_Matching_for_Transduction.html">72 nips-2009-Distribution Matching for Transduction</a></p>
<p>20 0.034990471 <a title="63-tfidf-20" href="./nips-2009-Boosting_with_Spatial_Regularization.html">47 nips-2009-Boosting with Spatial Regularization</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.113), (1, 0.117), (2, 0.057), (3, -0.045), (4, 0.139), (5, 0.116), (6, -0.078), (7, 0.101), (8, -0.054), (9, 0.073), (10, -0.012), (11, -0.01), (12, 0.075), (13, 0.042), (14, -0.024), (15, -0.02), (16, 0.071), (17, -0.037), (18, 0.025), (19, -0.032), (20, -0.196), (21, -0.134), (22, -0.038), (23, -0.088), (24, 0.022), (25, 0.103), (26, -0.081), (27, 0.121), (28, -0.004), (29, -0.135), (30, -0.026), (31, -0.071), (32, -0.105), (33, 0.017), (34, 0.171), (35, 0.019), (36, 0.112), (37, -0.024), (38, 0.045), (39, -0.027), (40, 0.13), (41, 0.036), (42, 0.108), (43, -0.029), (44, 0.043), (45, 0.071), (46, 0.069), (47, 0.013), (48, -0.108), (49, 0.009)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94751871 <a title="63-lsi-1" href="./nips-2009-DUOL%3A_A_Double_Updating_Approach_for_Online_Learning.html">63 nips-2009-DUOL: A Double Updating Approach for Online Learning</a></p>
<p>Author: Peilin Zhao, Steven C. Hoi, Rong Jin</p><p>Abstract: In most online learning algorithms, the weights assigned to the misclassiﬁed examples (or support vectors) remain unchanged during the entire learning process. This is clearly insufﬁcient since when a new misclassiﬁed example is added to the pool of support vectors, we generally expect it to affect the weights for the existing support vectors. In this paper, we propose a new online learning method, termed Double Updating Online Learning, or DUOL for short. Instead of only assigning a ﬁxed weight to the misclassiﬁed example received in current trial, the proposed online learning algorithm also tries to update the weight for one of the existing support vectors. We show that the mistake bound can be signiﬁcantly improved by the proposed online learning method. Encouraging experimental results show that the proposed technique is in general considerably more effective than the state-of-the-art online learning algorithms. 1</p><p>2 0.69256943 <a title="63-lsi-2" href="./nips-2009-Learning_Bregman_Distance_Functions_and_Its_Application_for_Semi-Supervised_Clustering.html">126 nips-2009-Learning Bregman Distance Functions and Its Application for Semi-Supervised Clustering</a></p>
<p>Author: Lei Wu, Rong Jin, Steven C. Hoi, Jianke Zhu, Nenghai Yu</p><p>Abstract: Learning distance functions with side information plays a key role in many machine learning and data mining applications. Conventional approaches often assume a Mahalanobis distance function. These approaches are limited in two aspects: (i) they are computationally expensive (even infeasible) for high dimensional data because the size of the metric is in the square of dimensionality; (ii) they assume a ﬁxed metric for the entire input space and therefore are unable to handle heterogeneous data. In this paper, we propose a novel scheme that learns nonlinear Bregman distance functions from side information using a nonparametric approach that is similar to support vector machines. The proposed scheme avoids the assumption of ﬁxed metric by implicitly deriving a local distance from the Hessian matrix of a convex function that is used to generate the Bregman distance function. We also present an efﬁcient learning algorithm for the proposed scheme for distance function learning. The extensive experiments with semi-supervised clustering show the proposed technique (i) outperforms the state-of-the-art approaches for distance function learning, and (ii) is computationally efﬁcient for high dimensional data. 1</p><p>3 0.46368381 <a title="63-lsi-3" href="./nips-2009-Slow_Learners_are_Fast.html">220 nips-2009-Slow Learners are Fast</a></p>
<p>Author: Martin Zinkevich, John Langford, Alex J. Smola</p><p>Abstract: Online learning algorithms have impressive convergence properties when it comes to risk minimization and convex games on very large problems. However, they are inherently sequential in their design which prevents them from taking advantage of modern multi-core architectures. In this paper we prove that online learning with delayed updates converges well, thereby facilitating parallel online learning. 1</p><p>4 0.44424552 <a title="63-lsi-4" href="./nips-2009-Beyond_Convexity%3A_Online_Submodular_Minimization.html">45 nips-2009-Beyond Convexity: Online Submodular Minimization</a></p>
<p>Author: Elad Hazan, Satyen Kale</p><p>Abstract: We consider an online decision problem over a discrete space in which the loss function is submodular. We give algorithms which are computationally efﬁcient and are Hannan-consistent in both the full information and bandit settings. 1</p><p>5 0.43859333 <a title="63-lsi-5" href="./nips-2009-Adaptive_Regularization_of_Weight_Vectors.html">27 nips-2009-Adaptive Regularization of Weight Vectors</a></p>
<p>Author: Koby Crammer, Alex Kulesza, Mark Dredze</p><p>Abstract: We present AROW, a new online learning algorithm that combines several useful properties: large margin training, conﬁdence weighting, and the capacity to handle non-separable data. AROW performs adaptive regularization of the prediction function upon seeing each new instance, allowing it to perform especially well in the presence of label noise. We derive a mistake bound, similar in form to the second order perceptron bound, that does not assume separability. We also relate our algorithm to recent conﬁdence-weighted online learning techniques and show empirically that AROW achieves state-of-the-art performance and notable robustness in the case of non-separable data. 1</p><p>6 0.4325861 <a title="63-lsi-6" href="./nips-2009-Efficient_Bregman_Range_Search.html">74 nips-2009-Efficient Bregman Range Search</a></p>
<p>7 0.40304199 <a title="63-lsi-7" href="./nips-2009-Multiple_Incremental_Decremental_Learning_of_Support_Vector_Machines.html">160 nips-2009-Multiple Incremental Decremental Learning of Support Vector Machines</a></p>
<p>8 0.37625554 <a title="63-lsi-8" href="./nips-2009-Regularized_Distance_Metric_Learning%3ATheory_and_Algorithm.html">202 nips-2009-Regularized Distance Metric Learning:Theory and Algorithm</a></p>
<p>9 0.36899799 <a title="63-lsi-9" href="./nips-2009-Streaming_k-means_approximation.html">234 nips-2009-Streaming k-means approximation</a></p>
<p>10 0.34640813 <a title="63-lsi-10" href="./nips-2009-On_Stochastic_and_Worst-case_Models_for_Investing.html">178 nips-2009-On Stochastic and Worst-case Models for Investing</a></p>
<p>11 0.33616179 <a title="63-lsi-11" href="./nips-2009-Online_Learning_of_Assignments.html">181 nips-2009-Online Learning of Assignments</a></p>
<p>12 0.3350656 <a title="63-lsi-12" href="./nips-2009-Dual_Averaging_Method_for_Regularized_Stochastic_Learning_and_Online_Optimization.html">73 nips-2009-Dual Averaging Method for Regularized Stochastic Learning and Online Optimization</a></p>
<p>13 0.32815263 <a title="63-lsi-13" href="./nips-2009-A_Stochastic_approximation_method_for_inference_in_probabilistic_graphical_models.html">18 nips-2009-A Stochastic approximation method for inference in probabilistic graphical models</a></p>
<p>14 0.32238427 <a title="63-lsi-14" href="./nips-2009-Structural_inference_affects_depth_perception_in_the_context_of_potential_occlusion.html">235 nips-2009-Structural inference affects depth perception in the context of potential occlusion</a></p>
<p>15 0.30405182 <a title="63-lsi-15" href="./nips-2009-On_Learning_Rotations.html">177 nips-2009-On Learning Rotations</a></p>
<p>16 0.29785058 <a title="63-lsi-16" href="./nips-2009-Efficient_Learning_using_Forward-Backward_Splitting.html">76 nips-2009-Efficient Learning using Forward-Backward Splitting</a></p>
<p>17 0.28457937 <a title="63-lsi-17" href="./nips-2009-Multi-Step_Dyna_Planning_for_Policy_Evaluation_and_Control.html">159 nips-2009-Multi-Step Dyna Planning for Policy Evaluation and Control</a></p>
<p>18 0.27867651 <a title="63-lsi-18" href="./nips-2009-Adapting_to_the_Shifting_Intent_of_Search_Queries.html">24 nips-2009-Adapting to the Shifting Intent of Search Queries</a></p>
<p>19 0.27768639 <a title="63-lsi-19" href="./nips-2009-Distribution_Matching_for_Transduction.html">72 nips-2009-Distribution Matching for Transduction</a></p>
<p>20 0.27447984 <a title="63-lsi-20" href="./nips-2009-Accelerated_Gradient_Methods_for_Stochastic_Optimization_and_Online_Learning.html">22 nips-2009-Accelerated Gradient Methods for Stochastic Optimization and Online Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(24, 0.081), (25, 0.054), (27, 0.445), (35, 0.023), (36, 0.105), (39, 0.02), (58, 0.042), (71, 0.032), (86, 0.044), (91, 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.72974747 <a title="63-lda-1" href="./nips-2009-DUOL%3A_A_Double_Updating_Approach_for_Online_Learning.html">63 nips-2009-DUOL: A Double Updating Approach for Online Learning</a></p>
<p>Author: Peilin Zhao, Steven C. Hoi, Rong Jin</p><p>Abstract: In most online learning algorithms, the weights assigned to the misclassiﬁed examples (or support vectors) remain unchanged during the entire learning process. This is clearly insufﬁcient since when a new misclassiﬁed example is added to the pool of support vectors, we generally expect it to affect the weights for the existing support vectors. In this paper, we propose a new online learning method, termed Double Updating Online Learning, or DUOL for short. Instead of only assigning a ﬁxed weight to the misclassiﬁed example received in current trial, the proposed online learning algorithm also tries to update the weight for one of the existing support vectors. We show that the mistake bound can be signiﬁcantly improved by the proposed online learning method. Encouraging experimental results show that the proposed technique is in general considerably more effective than the state-of-the-art online learning algorithms. 1</p><p>2 0.63191688 <a title="63-lda-2" href="./nips-2009-Nonparametric_Bayesian_Models_for_Unsupervised_Event_Coreference_Resolution.html">171 nips-2009-Nonparametric Bayesian Models for Unsupervised Event Coreference Resolution</a></p>
<p>Author: Cosmin Bejan, Matthew Titsworth, Andrew Hickl, Sanda Harabagiu</p><p>Abstract: We present a sequence of unsupervised, nonparametric Bayesian models for clustering complex linguistic objects. In this approach, we consider a potentially inﬁnite number of features and categorical outcomes. We evaluated these models for the task of within- and cross-document event coreference on two corpora. All the models we investigated show signiﬁcant improvements when compared against an existing baseline for this task.</p><p>3 0.51486909 <a title="63-lda-3" href="./nips-2009-Rethinking_LDA%3A_Why_Priors_Matter.html">205 nips-2009-Rethinking LDA: Why Priors Matter</a></p>
<p>Author: Andrew McCallum, David M. Mimno, Hanna M. Wallach</p><p>Abstract: Implementations of topic models typically use symmetric Dirichlet priors with ﬁxed concentration parameters, with the implicit assumption that such “smoothing parameters” have little practical effect. In this paper, we explore several classes of structured priors for topic models. We ﬁnd that an asymmetric Dirichlet prior over the document–topic distributions has substantial advantages over a symmetric prior, while an asymmetric prior over the topic–word distributions provides no real beneﬁt. Approximation of this prior structure through simple, efﬁcient hyperparameter optimization steps is sufﬁcient to achieve these performance gains. The prior structure we advocate substantially increases the robustness of topic models to variations in the number of topics and to the highly skewed word frequency distributions common in natural language. Since this prior structure can be implemented using efﬁcient algorithms that add negligible cost beyond standard inference techniques, we recommend it as a new standard for topic modeling. 1</p><p>4 0.37712944 <a title="63-lda-4" href="./nips-2009-Adaptive_Regularization_of_Weight_Vectors.html">27 nips-2009-Adaptive Regularization of Weight Vectors</a></p>
<p>Author: Koby Crammer, Alex Kulesza, Mark Dredze</p><p>Abstract: We present AROW, a new online learning algorithm that combines several useful properties: large margin training, conﬁdence weighting, and the capacity to handle non-separable data. AROW performs adaptive regularization of the prediction function upon seeing each new instance, allowing it to perform especially well in the presence of label noise. We derive a mistake bound, similar in form to the second order perceptron bound, that does not assume separability. We also relate our algorithm to recent conﬁdence-weighted online learning techniques and show empirically that AROW achieves state-of-the-art performance and notable robustness in the case of non-separable data. 1</p><p>5 0.36910528 <a title="63-lda-5" href="./nips-2009-Group_Sparse_Coding.html">104 nips-2009-Group Sparse Coding</a></p>
<p>Author: Samy Bengio, Fernando Pereira, Yoram Singer, Dennis Strelow</p><p>Abstract: Bag-of-words document representations are often used in text, image and video processing. While it is relatively easy to determine a suitable word dictionary for text documents, there is no simple mapping from raw images or videos to dictionary terms. The classical approach builds a dictionary using vector quantization over a large set of useful visual descriptors extracted from a training set, and uses a nearest-neighbor algorithm to count the number of occurrences of each dictionary word in documents to be encoded. More robust approaches have been proposed recently that represent each visual descriptor as a sparse weighted combination of dictionary words. While favoring a sparse representation at the level of visual descriptors, those methods however do not ensure that images have sparse representation. In this work, we use mixed-norm regularization to achieve sparsity at the image level as well as a small overall dictionary. This approach can also be used to encourage using the same dictionary words for all the images in a class, providing a discriminative signal in the construction of image representations. Experimental results on a benchmark image classiﬁcation dataset show that when compact image or dictionary representations are needed for computational efﬁciency, the proposed approach yields better mean average precision in classiﬁcation. 1</p><p>6 0.33591416 <a title="63-lda-6" href="./nips-2009-Noisy_Generalized_Binary_Search.html">166 nips-2009-Noisy Generalized Binary Search</a></p>
<p>7 0.32913318 <a title="63-lda-7" href="./nips-2009-Submodularity_Cuts_and_Applications.html">239 nips-2009-Submodularity Cuts and Applications</a></p>
<p>8 0.32780081 <a title="63-lda-8" href="./nips-2009-Beyond_Convexity%3A_Online_Submodular_Minimization.html">45 nips-2009-Beyond Convexity: Online Submodular Minimization</a></p>
<p>9 0.32775772 <a title="63-lda-9" href="./nips-2009-Learning_a_Small_Mixture_of_Trees.html">129 nips-2009-Learning a Small Mixture of Trees</a></p>
<p>10 0.32639983 <a title="63-lda-10" href="./nips-2009-Label_Selection_on_Graphs.html">122 nips-2009-Label Selection on Graphs</a></p>
<p>11 0.32586047 <a title="63-lda-11" href="./nips-2009-On_the_Convergence_of_the_Concave-Convex_Procedure.html">180 nips-2009-On the Convergence of the Concave-Convex Procedure</a></p>
<p>12 0.32510361 <a title="63-lda-12" href="./nips-2009-Distribution_Matching_for_Transduction.html">72 nips-2009-Distribution Matching for Transduction</a></p>
<p>13 0.32451111 <a title="63-lda-13" href="./nips-2009-Kernel_Choice_and_Classifiability_for_RKHS_Embeddings_of_Probability_Distributions.html">118 nips-2009-Kernel Choice and Classifiability for RKHS Embeddings of Probability Distributions</a></p>
<p>14 0.32447106 <a title="63-lda-14" href="./nips-2009-Nonlinear_Learning_using_Local_Coordinate_Coding.html">169 nips-2009-Nonlinear Learning using Local Coordinate Coding</a></p>
<p>15 0.32257661 <a title="63-lda-15" href="./nips-2009-Distribution-Calibrated_Hierarchical_Classification.html">71 nips-2009-Distribution-Calibrated Hierarchical Classification</a></p>
<p>16 0.32246754 <a title="63-lda-16" href="./nips-2009-A_unified_framework_for_high-dimensional_analysis_of_%24M%24-estimators_with_decomposable_regularizers.html">20 nips-2009-A unified framework for high-dimensional analysis of $M$-estimators with decomposable regularizers</a></p>
<p>17 0.32197627 <a title="63-lda-17" href="./nips-2009-Slow_Learners_are_Fast.html">220 nips-2009-Slow Learners are Fast</a></p>
<p>18 0.32195309 <a title="63-lda-18" href="./nips-2009-Potential-Based_Agnostic_Boosting.html">193 nips-2009-Potential-Based Agnostic Boosting</a></p>
<p>19 0.32171121 <a title="63-lda-19" href="./nips-2009-Robust_Nonparametric_Regression_with_Metric-Space_Valued_Output.html">207 nips-2009-Robust Nonparametric Regression with Metric-Space Valued Output</a></p>
<p>20 0.32047731 <a title="63-lda-20" href="./nips-2009-A_Rate_Distortion_Approach_for_Semi-Supervised_Conditional_Random_Fields.html">15 nips-2009-A Rate Distortion Approach for Semi-Supervised Conditional Random Fields</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
