<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>63 nips-2009-DUOL: A Double Updating Approach for Online Learning</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-63" href="#">nips2009-63</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>63 nips-2009-DUOL: A Double Updating Approach for Online Learning</h1>
<br/><p>Source: <a title="nips-2009-63-pdf" href="http://papers.nips.cc/paper/3787-duol-a-double-updating-approach-for-online-learning.pdf">pdf</a></p><p>Author: Peilin Zhao, Steven C. Hoi, Rong Jin</p><p>Abstract: In most online learning algorithms, the weights assigned to the misclassiﬁed examples (or support vectors) remain unchanged during the entire learning process. This is clearly insufﬁcient since when a new misclassiﬁed example is added to the pool of support vectors, we generally expect it to affect the weights for the existing support vectors. In this paper, we propose a new online learning method, termed Double Updating Online Learning, or DUOL for short. Instead of only assigning a ﬁxed weight to the misclassiﬁed example received in current trial, the proposed online learning algorithm also tries to update the weight for one of the existing support vectors. We show that the mistake bound can be signiﬁcantly improved by the proposed online learning method. Encouraging experimental results show that the proposed technique is in general considerably more effective than the state-of-the-art online learning algorithms. 1</p><p>Reference: <a title="nips-2009-63-reference" href="../nips2009_reference/nips-2009-DUOL%3A_A_Double_Updating_Approach_for_Online_Learning_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('romm', 0.431), ('duol', 0.41), ('yb', 0.324), ('xb', 0.277), ('ya', 0.256), ('onlin', 0.245), ('ft', 0.233), ('xa', 0.204), ('perceptron', 0.202), ('mistak', 0.18), ('pa', 0.164), ('alm', 0.162), ('misclass', 0.143), ('cram', 0.085), ('upd', 0.072), ('doubl', 0.068), ('yi', 0.066), ('wab', 0.066), ('gentil', 0.065), ('auxy', 0.063)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="63-tfidf-1" href="./nips-2009-DUOL%3A_A_Double_Updating_Approach_for_Online_Learning.html">63 nips-2009-DUOL: A Double Updating Approach for Online Learning</a></p>
<p>Author: Peilin Zhao, Steven C. Hoi, Rong Jin</p><p>Abstract: In most online learning algorithms, the weights assigned to the misclassiﬁed examples (or support vectors) remain unchanged during the entire learning process. This is clearly insufﬁcient since when a new misclassiﬁed example is added to the pool of support vectors, we generally expect it to affect the weights for the existing support vectors. In this paper, we propose a new online learning method, termed Double Updating Online Learning, or DUOL for short. Instead of only assigning a ﬁxed weight to the misclassiﬁed example received in current trial, the proposed online learning algorithm also tries to update the weight for one of the existing support vectors. We show that the mistake bound can be signiﬁcantly improved by the proposed online learning method. Encouraging experimental results show that the proposed technique is in general considerably more effective than the state-of-the-art online learning algorithms. 1</p><p>2 0.24954472 <a title="63-tfidf-2" href="./nips-2009-Learning_Bregman_Distance_Functions_and_Its_Application_for_Semi-Supervised_Clustering.html">126 nips-2009-Learning Bregman Distance Functions and Its Application for Semi-Supervised Clustering</a></p>
<p>Author: Lei Wu, Rong Jin, Steven C. Hoi, Jianke Zhu, Nenghai Yu</p><p>Abstract: Learning distance functions with side information plays a key role in many machine learning and data mining applications. Conventional approaches often assume a Mahalanobis distance function. These approaches are limited in two aspects: (i) they are computationally expensive (even infeasible) for high dimensional data because the size of the metric is in the square of dimensionality; (ii) they assume a ﬁxed metric for the entire input space and therefore are unable to handle heterogeneous data. In this paper, we propose a novel scheme that learns nonlinear Bregman distance functions from side information using a nonparametric approach that is similar to support vector machines. The proposed scheme avoids the assumption of ﬁxed metric by implicitly deriving a local distance from the Hessian matrix of a convex function that is used to generate the Bregman distance function. We also present an efﬁcient learning algorithm for the proposed scheme for distance function learning. The extensive experiments with semi-supervised clustering show the proposed technique (i) outperforms the state-of-the-art approaches for distance function learning, and (ii) is computationally efﬁcient for high dimensional data. 1</p><p>3 0.14676142 <a title="63-tfidf-3" href="./nips-2009-Beyond_Convexity%3A_Online_Submodular_Minimization.html">45 nips-2009-Beyond Convexity: Online Submodular Minimization</a></p>
<p>Author: Elad Hazan, Satyen Kale</p><p>Abstract: We consider an online decision problem over a discrete space in which the loss function is submodular. We give algorithms which are computationally efﬁcient and are Hannan-consistent in both the full information and bandit settings. 1</p><p>4 0.13697119 <a title="63-tfidf-4" href="./nips-2009-Slow_Learners_are_Fast.html">220 nips-2009-Slow Learners are Fast</a></p>
<p>Author: Martin Zinkevich, John Langford, Alex J. Smola</p><p>Abstract: Online learning algorithms have impressive convergence properties when it comes to risk minimization and convex games on very large problems. However, they are inherently sequential in their design which prevents them from taking advantage of modern multi-core architectures. In this paper we prove that online learning with delayed updates converges well, thereby facilitating parallel online learning. 1</p><p>5 0.10315775 <a title="63-tfidf-5" href="./nips-2009-Adaptive_Regularization_of_Weight_Vectors.html">27 nips-2009-Adaptive Regularization of Weight Vectors</a></p>
<p>Author: Koby Crammer, Alex Kulesza, Mark Dredze</p><p>Abstract: We present AROW, a new online learning algorithm that combines several useful properties: large margin training, conﬁdence weighting, and the capacity to handle non-separable data. AROW performs adaptive regularization of the prediction function upon seeing each new instance, allowing it to perform especially well in the presence of label noise. We derive a mistake bound, similar in form to the second order perceptron bound, that does not assume separability. We also relate our algorithm to recent conﬁdence-weighted online learning techniques and show empirically that AROW achieves state-of-the-art performance and notable robustness in the case of non-separable data. 1</p><p>6 0.098738253 <a title="63-tfidf-6" href="./nips-2009-On_Stochastic_and_Worst-case_Models_for_Investing.html">178 nips-2009-On Stochastic and Worst-case Models for Investing</a></p>
<p>7 0.098172918 <a title="63-tfidf-7" href="./nips-2009-Online_Learning_of_Assignments.html">181 nips-2009-Online Learning of Assignments</a></p>
<p>8 0.08795312 <a title="63-tfidf-8" href="./nips-2009-Regularized_Distance_Metric_Learning%3ATheory_and_Algorithm.html">202 nips-2009-Regularized Distance Metric Learning:Theory and Algorithm</a></p>
<p>9 0.076516353 <a title="63-tfidf-9" href="./nips-2009-A_Stochastic_approximation_method_for_inference_in_probabilistic_graphical_models.html">18 nips-2009-A Stochastic approximation method for inference in probabilistic graphical models</a></p>
<p>10 0.060921732 <a title="63-tfidf-10" href="./nips-2009-Accelerated_Gradient_Methods_for_Stochastic_Optimization_and_Online_Learning.html">22 nips-2009-Accelerated Gradient Methods for Stochastic Optimization and Online Learning</a></p>
<p>11 0.056226786 <a title="63-tfidf-11" href="./nips-2009-A_joint_maximum-entropy_model_for_binary_neural_population_patterns_and_continuous_signals.html">19 nips-2009-A joint maximum-entropy model for binary neural population patterns and continuous signals</a></p>
<p>12 0.055313028 <a title="63-tfidf-12" href="./nips-2009-Learning_a_Small_Mixture_of_Trees.html">129 nips-2009-Learning a Small Mixture of Trees</a></p>
<p>13 0.05164307 <a title="63-tfidf-13" href="./nips-2009-Multiple_Incremental_Decremental_Learning_of_Support_Vector_Machines.html">160 nips-2009-Multiple Incremental Decremental Learning of Support Vector Machines</a></p>
<p>14 0.051457308 <a title="63-tfidf-14" href="./nips-2009-Label_Selection_on_Graphs.html">122 nips-2009-Label Selection on Graphs</a></p>
<p>15 0.049148589 <a title="63-tfidf-15" href="./nips-2009-On_Learning_Rotations.html">177 nips-2009-On Learning Rotations</a></p>
<p>16 0.049091768 <a title="63-tfidf-16" href="./nips-2009-Dual_Averaging_Method_for_Regularized_Stochastic_Learning_and_Online_Optimization.html">73 nips-2009-Dual Averaging Method for Regularized Stochastic Learning and Online Optimization</a></p>
<p>17 0.043656707 <a title="63-tfidf-17" href="./nips-2009-Efficient_Learning_using_Forward-Backward_Splitting.html">76 nips-2009-Efficient Learning using Forward-Backward Splitting</a></p>
<p>18 0.041890137 <a title="63-tfidf-18" href="./nips-2009-Kernel_Choice_and_Classifiability_for_RKHS_Embeddings_of_Probability_Distributions.html">118 nips-2009-Kernel Choice and Classifiability for RKHS Embeddings of Probability Distributions</a></p>
<p>19 0.041100401 <a title="63-tfidf-19" href="./nips-2009-Help_or_Hinder%3A_Bayesian_Models_of_Social_Goal_Inference.html">107 nips-2009-Help or Hinder: Bayesian Models of Social Goal Inference</a></p>
<p>20 0.036951408 <a title="63-tfidf-20" href="./nips-2009-Modeling_the_spacing_effect_in_sequential_category_learning.html">154 nips-2009-Modeling the spacing effect in sequential category learning</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.108), (1, 0.051), (2, 0.151), (3, 0.089), (4, -0.097), (5, -0.009), (6, -0.028), (7, 0.101), (8, 0.006), (9, 0.044), (10, 0.032), (11, 0.041), (12, 0.033), (13, -0.096), (14, -0.027), (15, -0.015), (16, 0.044), (17, 0.007), (18, 0.129), (19, 0.092), (20, -0.125), (21, -0.097), (22, -0.045), (23, 0.045), (24, 0.064), (25, -0.161), (26, -0.068), (27, -0.078), (28, 0.043), (29, -0.0), (30, 0.102), (31, -0.008), (32, -0.037), (33, 0.05), (34, 0.099), (35, 0.001), (36, 0.037), (37, 0.012), (38, -0.036), (39, -0.064), (40, 0.16), (41, -0.063), (42, 0.095), (43, -0.038), (44, 0.197), (45, -0.049), (46, -0.04), (47, 0.051), (48, -0.103), (49, -0.005)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92547834 <a title="63-lsi-1" href="./nips-2009-DUOL%3A_A_Double_Updating_Approach_for_Online_Learning.html">63 nips-2009-DUOL: A Double Updating Approach for Online Learning</a></p>
<p>Author: Peilin Zhao, Steven C. Hoi, Rong Jin</p><p>Abstract: In most online learning algorithms, the weights assigned to the misclassiﬁed examples (or support vectors) remain unchanged during the entire learning process. This is clearly insufﬁcient since when a new misclassiﬁed example is added to the pool of support vectors, we generally expect it to affect the weights for the existing support vectors. In this paper, we propose a new online learning method, termed Double Updating Online Learning, or DUOL for short. Instead of only assigning a ﬁxed weight to the misclassiﬁed example received in current trial, the proposed online learning algorithm also tries to update the weight for one of the existing support vectors. We show that the mistake bound can be signiﬁcantly improved by the proposed online learning method. Encouraging experimental results show that the proposed technique is in general considerably more effective than the state-of-the-art online learning algorithms. 1</p><p>2 0.65259182 <a title="63-lsi-2" href="./nips-2009-Learning_Bregman_Distance_Functions_and_Its_Application_for_Semi-Supervised_Clustering.html">126 nips-2009-Learning Bregman Distance Functions and Its Application for Semi-Supervised Clustering</a></p>
<p>Author: Lei Wu, Rong Jin, Steven C. Hoi, Jianke Zhu, Nenghai Yu</p><p>Abstract: Learning distance functions with side information plays a key role in many machine learning and data mining applications. Conventional approaches often assume a Mahalanobis distance function. These approaches are limited in two aspects: (i) they are computationally expensive (even infeasible) for high dimensional data because the size of the metric is in the square of dimensionality; (ii) they assume a ﬁxed metric for the entire input space and therefore are unable to handle heterogeneous data. In this paper, we propose a novel scheme that learns nonlinear Bregman distance functions from side information using a nonparametric approach that is similar to support vector machines. The proposed scheme avoids the assumption of ﬁxed metric by implicitly deriving a local distance from the Hessian matrix of a convex function that is used to generate the Bregman distance function. We also present an efﬁcient learning algorithm for the proposed scheme for distance function learning. The extensive experiments with semi-supervised clustering show the proposed technique (i) outperforms the state-of-the-art approaches for distance function learning, and (ii) is computationally efﬁcient for high dimensional data. 1</p><p>3 0.47872129 <a title="63-lsi-3" href="./nips-2009-Slow_Learners_are_Fast.html">220 nips-2009-Slow Learners are Fast</a></p>
<p>Author: Martin Zinkevich, John Langford, Alex J. Smola</p><p>Abstract: Online learning algorithms have impressive convergence properties when it comes to risk minimization and convex games on very large problems. However, they are inherently sequential in their design which prevents them from taking advantage of modern multi-core architectures. In this paper we prove that online learning with delayed updates converges well, thereby facilitating parallel online learning. 1</p><p>4 0.45203367 <a title="63-lsi-4" href="./nips-2009-Adaptive_Regularization_of_Weight_Vectors.html">27 nips-2009-Adaptive Regularization of Weight Vectors</a></p>
<p>Author: Koby Crammer, Alex Kulesza, Mark Dredze</p><p>Abstract: We present AROW, a new online learning algorithm that combines several useful properties: large margin training, conﬁdence weighting, and the capacity to handle non-separable data. AROW performs adaptive regularization of the prediction function upon seeing each new instance, allowing it to perform especially well in the presence of label noise. We derive a mistake bound, similar in form to the second order perceptron bound, that does not assume separability. We also relate our algorithm to recent conﬁdence-weighted online learning techniques and show empirically that AROW achieves state-of-the-art performance and notable robustness in the case of non-separable data. 1</p><p>5 0.44249097 <a title="63-lsi-5" href="./nips-2009-Beyond_Convexity%3A_Online_Submodular_Minimization.html">45 nips-2009-Beyond Convexity: Online Submodular Minimization</a></p>
<p>Author: Elad Hazan, Satyen Kale</p><p>Abstract: We consider an online decision problem over a discrete space in which the loss function is submodular. We give algorithms which are computationally efﬁcient and are Hannan-consistent in both the full information and bandit settings. 1</p><p>6 0.41216284 <a title="63-lsi-6" href="./nips-2009-Efficient_Bregman_Range_Search.html">74 nips-2009-Efficient Bregman Range Search</a></p>
<p>7 0.38859203 <a title="63-lsi-7" href="./nips-2009-On_Stochastic_and_Worst-case_Models_for_Investing.html">178 nips-2009-On Stochastic and Worst-case Models for Investing</a></p>
<p>8 0.36615244 <a title="63-lsi-8" href="./nips-2009-Regularized_Distance_Metric_Learning%3ATheory_and_Algorithm.html">202 nips-2009-Regularized Distance Metric Learning:Theory and Algorithm</a></p>
<p>9 0.34029573 <a title="63-lsi-9" href="./nips-2009-A_Stochastic_approximation_method_for_inference_in_probabilistic_graphical_models.html">18 nips-2009-A Stochastic approximation method for inference in probabilistic graphical models</a></p>
<p>10 0.33790618 <a title="63-lsi-10" href="./nips-2009-Dual_Averaging_Method_for_Regularized_Stochastic_Learning_and_Online_Optimization.html">73 nips-2009-Dual Averaging Method for Regularized Stochastic Learning and Online Optimization</a></p>
<p>11 0.33742398 <a title="63-lsi-11" href="./nips-2009-Streaming_k-means_approximation.html">234 nips-2009-Streaming k-means approximation</a></p>
<p>12 0.3270019 <a title="63-lsi-12" href="./nips-2009-Multiple_Incremental_Decremental_Learning_of_Support_Vector_Machines.html">160 nips-2009-Multiple Incremental Decremental Learning of Support Vector Machines</a></p>
<p>13 0.3225089 <a title="63-lsi-13" href="./nips-2009-Online_Learning_of_Assignments.html">181 nips-2009-Online Learning of Assignments</a></p>
<p>14 0.31493485 <a title="63-lsi-14" href="./nips-2009-Multi-Step_Dyna_Planning_for_Policy_Evaluation_and_Control.html">159 nips-2009-Multi-Step Dyna Planning for Policy Evaluation and Control</a></p>
<p>15 0.30676469 <a title="63-lsi-15" href="./nips-2009-Efficient_Learning_using_Forward-Backward_Splitting.html">76 nips-2009-Efficient Learning using Forward-Backward Splitting</a></p>
<p>16 0.30490133 <a title="63-lsi-16" href="./nips-2009-On_Learning_Rotations.html">177 nips-2009-On Learning Rotations</a></p>
<p>17 0.3006188 <a title="63-lsi-17" href="./nips-2009-Distribution_Matching_for_Transduction.html">72 nips-2009-Distribution Matching for Transduction</a></p>
<p>18 0.27988937 <a title="63-lsi-18" href="./nips-2009-Sensitivity_analysis_in_HMMs_with_application_to_likelihood_maximization.html">215 nips-2009-Sensitivity analysis in HMMs with application to likelihood maximization</a></p>
<p>19 0.26032028 <a title="63-lsi-19" href="./nips-2009-Accelerated_Gradient_Methods_for_Stochastic_Optimization_and_Online_Learning.html">22 nips-2009-Accelerated Gradient Methods for Stochastic Optimization and Online Learning</a></p>
<p>20 0.25825453 <a title="63-lsi-20" href="./nips-2009-Learning_a_Small_Mixture_of_Trees.html">129 nips-2009-Learning a Small Mixture of Trees</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(5, 0.433), (9, 0.158), (11, 0.095), (24, 0.026), (31, 0.041), (60, 0.034), (89, 0.013), (96, 0.06)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.60352278 <a title="63-lda-1" href="./nips-2009-DUOL%3A_A_Double_Updating_Approach_for_Online_Learning.html">63 nips-2009-DUOL: A Double Updating Approach for Online Learning</a></p>
<p>Author: Peilin Zhao, Steven C. Hoi, Rong Jin</p><p>Abstract: In most online learning algorithms, the weights assigned to the misclassiﬁed examples (or support vectors) remain unchanged during the entire learning process. This is clearly insufﬁcient since when a new misclassiﬁed example is added to the pool of support vectors, we generally expect it to affect the weights for the existing support vectors. In this paper, we propose a new online learning method, termed Double Updating Online Learning, or DUOL for short. Instead of only assigning a ﬁxed weight to the misclassiﬁed example received in current trial, the proposed online learning algorithm also tries to update the weight for one of the existing support vectors. We show that the mistake bound can be signiﬁcantly improved by the proposed online learning method. Encouraging experimental results show that the proposed technique is in general considerably more effective than the state-of-the-art online learning algorithms. 1</p><p>2 0.52927333 <a title="63-lda-2" href="./nips-2009-Polynomial_Semantic_Indexing.html">190 nips-2009-Polynomial Semantic Indexing</a></p>
<p>Author: Bing Bai, Jason Weston, David Grangier, Ronan Collobert, Kunihiko Sadamasa, Yanjun Qi, Corinna Cortes, Mehryar Mohri</p><p>Abstract: We present a class of nonlinear (polynomial) models that are discriminatively trained to directly map from the word content in a query-document or documentdocument pair to a ranking score. Dealing with polynomial models on word features is computationally challenging. We propose a low-rank (but diagonal preserving) representation of our polynomial models to induce feasible memory and computation requirements. We provide an empirical study on retrieval tasks based on Wikipedia documents, where we obtain state-of-the-art performance while providing realistically scalable methods. 1</p><p>3 0.49855077 <a title="63-lda-3" href="./nips-2009-Unsupervised_Detection_of_Regions_of_Interest_Using_Iterative_Link_Analysis.html">251 nips-2009-Unsupervised Detection of Regions of Interest Using Iterative Link Analysis</a></p>
<p>Author: Gunhee Kim, Antonio Torralba</p><p>Abstract: This paper proposes a fast and scalable alternating optimization technique to detect regions of interest (ROIs) in cluttered Web images without labels. The proposed approach discovers highly probable regions of object instances by iteratively repeating the following two functions: (1) choose the exemplar set (i.e. a small number of highly ranked reference ROIs) across the dataset and (2) reﬁne the ROIs of each image with respect to the exemplar set. These two subproblems are formulated as ranking in two different similarity networks of ROI hypotheses by link analysis. The experiments with the PASCAL 06 dataset show that our unsupervised localization performance is better than one of state-of-the-art techniques and comparable to supervised methods. Also, we test the scalability of our approach with ﬁve objects in Flickr dataset consisting of more than 200K images. 1</p><p>4 0.41562042 <a title="63-lda-4" href="./nips-2009-Online_Learning_of_Assignments.html">181 nips-2009-Online Learning of Assignments</a></p>
<p>Author: Matthew Streeter, Daniel Golovin, Andreas Krause</p><p>Abstract: Which ads should we display in sponsored search in order to maximize our revenue? How should we dynamically rank information sources to maximize the value of the ranking? These applications exhibit strong diminishing returns: Redundancy decreases the marginal utility of each ad or information source. We show that these and other problems can be formalized as repeatedly selecting an assignment of items to positions to maximize a sequence of monotone submodular functions that arrive one by one. We present an efﬁcient algorithm for this general problem and analyze it in the no-regret model. Our algorithm possesses strong theoretical guarantees, such as a performance ratio that converges to the optimal constant of 1 − 1/e. We empirically evaluate our algorithm on two real-world online optimization problems on the web: ad allocation with submodular utilities, and dynamically ranking blogs to detect information cascades. 1</p><p>5 0.41491097 <a title="63-lda-5" href="./nips-2009-Bootstrapping_from_Game_Tree_Search.html">48 nips-2009-Bootstrapping from Game Tree Search</a></p>
<p>Author: Joel Veness, David Silver, Alan Blair, William W. Cohen</p><p>Abstract: In this paper we introduce a new algorithm for updating the parameters of a heuristic evaluation function, by updating the heuristic towards the values computed by an alpha-beta search. Our algorithm differs from previous approaches to learning from search, such as Samuel’s checkers player and the TD-Leaf algorithm, in two key ways. First, we update all nodes in the search tree, rather than a single node. Second, we use the outcome of a deep search, instead of the outcome of a subsequent search, as the training signal for the evaluation function. We implemented our algorithm in a chess program Meep, using a linear heuristic function. After initialising its weight vector to small random values, Meep was able to learn high quality weights from self-play alone. When tested online against human opponents, Meep played at a master level, the best performance of any chess program with a heuristic learned entirely from self-play. 1</p><p>6 0.40774244 <a title="63-lda-6" href="./nips-2009-Predicting_the_Optimal_Spacing_of_Study%3A_A_Multiscale_Context_Model_of_Memory.html">194 nips-2009-Predicting the Optimal Spacing of Study: A Multiscale Context Model of Memory</a></p>
<p>7 0.40626025 <a title="63-lda-7" href="./nips-2009-Adaptive_Regularization_for_Transductive_Support_Vector_Machine.html">26 nips-2009-Adaptive Regularization for Transductive Support Vector Machine</a></p>
<p>8 0.40542719 <a title="63-lda-8" href="./nips-2009-Bayesian_estimation_of_orientation_preference_maps.html">43 nips-2009-Bayesian estimation of orientation preference maps</a></p>
<p>9 0.40454099 <a title="63-lda-9" href="./nips-2009-Beyond_Convexity%3A_Online_Submodular_Minimization.html">45 nips-2009-Beyond Convexity: Online Submodular Minimization</a></p>
<p>10 0.40433571 <a title="63-lda-10" href="./nips-2009-Strategy_Grafting_in_Extensive_Games.html">232 nips-2009-Strategy Grafting in Extensive Games</a></p>
<p>11 0.39849269 <a title="63-lda-11" href="./nips-2009-Monte_Carlo_Sampling_for_Regret_Minimization_in_Extensive_Games.html">156 nips-2009-Monte Carlo Sampling for Regret Minimization in Extensive Games</a></p>
<p>12 0.39635792 <a title="63-lda-12" href="./nips-2009-Information-theoretic_lower_bounds_on_the_oracle_complexity_of_convex_optimization.html">116 nips-2009-Information-theoretic lower bounds on the oracle complexity of convex optimization</a></p>
<p>13 0.39256352 <a title="63-lda-13" href="./nips-2009-Adapting_to_the_Shifting_Intent_of_Search_Queries.html">24 nips-2009-Adapting to the Shifting Intent of Search Queries</a></p>
<p>14 0.3918958 <a title="63-lda-14" href="./nips-2009-Slow_Learners_are_Fast.html">220 nips-2009-Slow Learners are Fast</a></p>
<p>15 0.38938075 <a title="63-lda-15" href="./nips-2009-On_Stochastic_and_Worst-case_Models_for_Investing.html">178 nips-2009-On Stochastic and Worst-case Models for Investing</a></p>
<p>16 0.38632292 <a title="63-lda-16" href="./nips-2009-Ranking_Measures_and_Loss_Functions_in_Learning_to_Rank.html">199 nips-2009-Ranking Measures and Loss Functions in Learning to Rank</a></p>
<p>17 0.38630798 <a title="63-lda-17" href="./nips-2009-Nash_Equilibria_of_Static_Prediction_Games.html">161 nips-2009-Nash Equilibria of Static Prediction Games</a></p>
<p>18 0.38600847 <a title="63-lda-18" href="./nips-2009-Learning_to_Rank_by_Optimizing_NDCG_Measure.html">136 nips-2009-Learning to Rank by Optimizing NDCG Measure</a></p>
<p>19 0.38540477 <a title="63-lda-19" href="./nips-2009-Dual_Averaging_Method_for_Regularized_Stochastic_Learning_and_Online_Optimization.html">73 nips-2009-Dual Averaging Method for Regularized Stochastic Learning and Online Optimization</a></p>
<p>20 0.38407105 <a title="63-lda-20" href="./nips-2009-Solving_Stochastic_Games.html">221 nips-2009-Solving Stochastic Games</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
