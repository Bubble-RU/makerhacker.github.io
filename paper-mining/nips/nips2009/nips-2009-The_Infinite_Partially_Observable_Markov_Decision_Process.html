<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>242 nips-2009-The Infinite Partially Observable Markov Decision Process</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-242" href="#">nips2009-242</a> knowledge-graph by maker-knowledge-mining</p><h1>242 nips-2009-The Infinite Partially Observable Markov Decision Process</h1>
<br/><p>Source: <a title="nips-2009-242-pdf" href="http://papers.nips.cc/paper/3780-the-infinite-partially-observable-markov-decision-process.pdf">pdf</a></p><p>Author: Finale Doshi-velez</p><p>Abstract: The Partially Observable Markov Decision Process (POMDP) framework has proven useful in planning domains where agents must balance actions that provide knowledge and actions that provide reward. Unfortunately, most POMDPs are complex structures with a large number of parameters. In many real-world problems, both the structure and the parameters are difﬁcult to specify from domain knowledge alone. Recent work in Bayesian reinforcement learning has made headway in learning POMDP models; however, this work has largely focused on learning the parameters of the POMDP model. We deﬁne an inﬁnite POMDP (iPOMDP) model that does not require knowledge of the size of the state space; instead, it assumes that the number of visited states will grow as the agent explores its world and only models visited states explicitly. We demonstrate the iPOMDP on several standard problems. 1</p><p>Reference: <a title="nips-2009-242-reference" href="../nips2009_reference/nips-2009-The_Infinite_Partially_Observable_Markov_Decision_Process_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('pomdp', 0.506), ('ipomdp', 0.417), ('ag', 0.38), ('reward', 0.352), ('transit', 0.136), ('ihm', 0.133), ('lineworld', 0.133), ('loopworld', 0.133), ('believ', 0.132), ('door', 0.107), ('corrid', 0.095), ('bm', 0.094), ('episod', 0.092), ('dirichlet', 0.091), ('pineau', 0.085), ('beam', 0.081), ('plan', 0.08), ('visit', 0.076), ('ffbs', 0.076), ('sa', 0.074)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="242-tfidf-1" href="./nips-2009-The_Infinite_Partially_Observable_Markov_Decision_Process.html">242 nips-2009-The Infinite Partially Observable Markov Decision Process</a></p>
<p>2 0.38438371 <a title="242-tfidf-2" href="./nips-2009-Complexity_of_Decentralized_Control%3A_Special_Cases.html">53 nips-2009-Complexity of Decentralized Control: Special Cases</a></p>
<p>3 0.3664563 <a title="242-tfidf-3" href="./nips-2009-Help_or_Hinder%3A_Bayesian_Models_of_Social_Goal_Inference.html">107 nips-2009-Help or Hinder: Bayesian Models of Social Goal Inference</a></p>
<p>4 0.26072568 <a title="242-tfidf-4" href="./nips-2009-Improving_Existing_Fault_Recovery_Policies.html">113 nips-2009-Improving Existing Fault Recovery Policies</a></p>
<p>5 0.20525101 <a title="242-tfidf-5" href="./nips-2009-Training_Factor_Graphs_with_Reinforcement_Learning_for_Efficient_MAP_Inference.html">250 nips-2009-Training Factor Graphs with Reinforcement Learning for Efficient MAP Inference</a></p>
<p>6 0.18865317 <a title="242-tfidf-6" href="./nips-2009-Learning_to_Explore_and_Exploit_in_POMDPs.html">134 nips-2009-Learning to Explore and Exploit in POMDPs</a></p>
<p>7 0.17559212 <a title="242-tfidf-7" href="./nips-2009-Skill_Discovery_in_Continuous_Reinforcement_Learning_Domains_using_Skill_Chaining.html">218 nips-2009-Skill Discovery in Continuous Reinforcement Learning Domains using Skill Chaining</a></p>
<p>8 0.17073052 <a title="242-tfidf-8" href="./nips-2009-Code-specific_policy_gradient_rules_for_spiking_neurons.html">52 nips-2009-Code-specific policy gradient rules for spiking neurons</a></p>
<p>9 0.10022859 <a title="242-tfidf-9" href="./nips-2009-Manifold_Embeddings_for_Model-Based_Reinforcement_Learning_under_Partial_Observability.html">145 nips-2009-Manifold Embeddings for Model-Based Reinforcement Learning under Partial Observability</a></p>
<p>10 0.0983252 <a title="242-tfidf-10" href="./nips-2009-Solving_Stochastic_Games.html">221 nips-2009-Solving Stochastic Games</a></p>
<p>11 0.093232892 <a title="242-tfidf-11" href="./nips-2009-Learning_in_Markov_Random_Fields_using_Tempered_Transitions.html">132 nips-2009-Learning in Markov Random Fields using Tempered Transitions</a></p>
<p>12 0.081782416 <a title="242-tfidf-12" href="./nips-2009-Bayesian_Belief_Polarization.html">39 nips-2009-Bayesian Belief Polarization</a></p>
<p>13 0.074819922 <a title="242-tfidf-13" href="./nips-2009-A_Generalized_Natural_Actor-Critic_Algorithm.html">12 nips-2009-A Generalized Natural Actor-Critic Algorithm</a></p>
<p>14 0.069818981 <a title="242-tfidf-14" href="./nips-2009-Rethinking_LDA%3A_Why_Priors_Matter.html">205 nips-2009-Rethinking LDA: Why Priors Matter</a></p>
<p>15 0.068766035 <a title="242-tfidf-15" href="./nips-2009-Online_Learning_of_Assignments.html">181 nips-2009-Online Learning of Assignments</a></p>
<p>16 0.061982386 <a title="242-tfidf-16" href="./nips-2009-A_Bayesian_Analysis_of_Dynamics_in_Free_Recall.html">4 nips-2009-A Bayesian Analysis of Dynamics in Free Recall</a></p>
<p>17 0.060628053 <a title="242-tfidf-17" href="./nips-2009-Nonparametric_Bayesian_Models_for_Unsupervised_Event_Coreference_Resolution.html">171 nips-2009-Nonparametric Bayesian Models for Unsupervised Event Coreference Resolution</a></p>
<p>18 0.060337298 <a title="242-tfidf-18" href="./nips-2009-Sharing_Features_among_Dynamical_Systems_with_Beta_Processes.html">217 nips-2009-Sharing Features among Dynamical Systems with Beta Processes</a></p>
<p>19 0.060297858 <a title="242-tfidf-19" href="./nips-2009-Convergent_Temporal-Difference_Learning_with_Arbitrary_Smooth_Function_Approximation.html">60 nips-2009-Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation</a></p>
<p>20 0.056101251 <a title="242-tfidf-20" href="./nips-2009-Large_Scale_Nonparametric_Bayesian_Inference%3A_Data_Parallelisation_in_the_Indian_Buffet_Process.html">123 nips-2009-Large Scale Nonparametric Bayesian Inference: Data Parallelisation in the Indian Buffet Process</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.167), (1, -0.058), (2, 0.109), (3, 0.297), (4, 0.39), (5, 0.263), (6, -0.004), (7, 0.025), (8, -0.008), (9, -0.022), (10, -0.093), (11, 0.111), (12, 0.041), (13, -0.009), (14, 0.085), (15, 0.052), (16, 0.041), (17, -0.069), (18, 0.035), (19, 0.096), (20, 0.072), (21, -0.044), (22, 0.031), (23, 0.179), (24, 0.172), (25, -0.019), (26, 0.1), (27, 0.085), (28, 0.064), (29, 0.068), (30, -0.026), (31, 0.019), (32, 0.021), (33, 0.025), (34, 0.045), (35, 0.034), (36, -0.026), (37, -0.001), (38, -0.025), (39, -0.015), (40, -0.012), (41, -0.008), (42, 0.023), (43, 0.036), (44, 0.021), (45, -0.024), (46, -0.013), (47, -0.044), (48, 0.025), (49, -0.03)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94006038 <a title="242-lsi-1" href="./nips-2009-The_Infinite_Partially_Observable_Markov_Decision_Process.html">242 nips-2009-The Infinite Partially Observable Markov Decision Process</a></p>
<p>2 0.91572541 <a title="242-lsi-2" href="./nips-2009-Complexity_of_Decentralized_Control%3A_Special_Cases.html">53 nips-2009-Complexity of Decentralized Control: Special Cases</a></p>
<p>3 0.88947284 <a title="242-lsi-3" href="./nips-2009-Help_or_Hinder%3A_Bayesian_Models_of_Social_Goal_Inference.html">107 nips-2009-Help or Hinder: Bayesian Models of Social Goal Inference</a></p>
<p>4 0.86584622 <a title="242-lsi-4" href="./nips-2009-Skill_Discovery_in_Continuous_Reinforcement_Learning_Domains_using_Skill_Chaining.html">218 nips-2009-Skill Discovery in Continuous Reinforcement Learning Domains using Skill Chaining</a></p>
<p>5 0.83631766 <a title="242-lsi-5" href="./nips-2009-Learning_to_Explore_and_Exploit_in_POMDPs.html">134 nips-2009-Learning to Explore and Exploit in POMDPs</a></p>
<p>6 0.51151687 <a title="242-lsi-6" href="./nips-2009-Training_Factor_Graphs_with_Reinforcement_Learning_for_Efficient_MAP_Inference.html">250 nips-2009-Training Factor Graphs with Reinforcement Learning for Efficient MAP Inference</a></p>
<p>7 0.50834745 <a title="242-lsi-7" href="./nips-2009-Multi-Step_Dyna_Planning_for_Policy_Evaluation_and_Control.html">159 nips-2009-Multi-Step Dyna Planning for Policy Evaluation and Control</a></p>
<p>8 0.50007272 <a title="242-lsi-8" href="./nips-2009-Improving_Existing_Fault_Recovery_Policies.html">113 nips-2009-Improving Existing Fault Recovery Policies</a></p>
<p>9 0.44115046 <a title="242-lsi-9" href="./nips-2009-A_Generalized_Natural_Actor-Critic_Algorithm.html">12 nips-2009-A Generalized Natural Actor-Critic Algorithm</a></p>
<p>10 0.4231804 <a title="242-lsi-10" href="./nips-2009-Manifold_Embeddings_for_Model-Based_Reinforcement_Learning_under_Partial_Observability.html">145 nips-2009-Manifold Embeddings for Model-Based Reinforcement Learning under Partial Observability</a></p>
<p>11 0.33671278 <a title="242-lsi-11" href="./nips-2009-Solving_Stochastic_Games.html">221 nips-2009-Solving Stochastic Games</a></p>
<p>12 0.3348543 <a title="242-lsi-12" href="./nips-2009-Code-specific_policy_gradient_rules_for_spiking_neurons.html">52 nips-2009-Code-specific policy gradient rules for spiking neurons</a></p>
<p>13 0.32702962 <a title="242-lsi-13" href="./nips-2009-Bayesian_Belief_Polarization.html">39 nips-2009-Bayesian Belief Polarization</a></p>
<p>14 0.29090217 <a title="242-lsi-14" href="./nips-2009-Maximum_likelihood_trajectories_for_continuous-time_Markov_chains.html">150 nips-2009-Maximum likelihood trajectories for continuous-time Markov chains</a></p>
<p>15 0.28163394 <a title="242-lsi-15" href="./nips-2009-Convergent_Temporal-Difference_Learning_with_Arbitrary_Smooth_Function_Approximation.html">60 nips-2009-Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation</a></p>
<p>16 0.26570204 <a title="242-lsi-16" href="./nips-2009-Learning_in_Markov_Random_Fields_using_Tempered_Transitions.html">132 nips-2009-Learning in Markov Random Fields using Tempered Transitions</a></p>
<p>17 0.23403805 <a title="242-lsi-17" href="./nips-2009-Discrete_MDL_Predicts_in_Total_Variation.html">69 nips-2009-Discrete MDL Predicts in Total Variation</a></p>
<p>18 0.23185019 <a title="242-lsi-18" href="./nips-2009-Perceptual_Multistability_as_Markov_Chain_Monte_Carlo_Inference.html">188 nips-2009-Perceptual Multistability as Markov Chain Monte Carlo Inference</a></p>
<p>19 0.2277303 <a title="242-lsi-19" href="./nips-2009-Particle-based_Variational_Inference_for_Continuous_Systems.html">187 nips-2009-Particle-based Variational Inference for Continuous Systems</a></p>
<p>20 0.22543925 <a title="242-lsi-20" href="./nips-2009-Modelling_Relational_Data_using_Bayesian_Clustered_Tensor_Factorization.html">155 nips-2009-Modelling Relational Data using Bayesian Clustered Tensor Factorization</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(9, 0.197), (11, 0.038), (31, 0.186), (37, 0.016), (48, 0.29), (60, 0.068), (69, 0.012), (89, 0.01), (96, 0.064)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.78402251 <a title="242-lda-1" href="./nips-2009-Who%E2%80%99s_Doing_What%3A_Joint_Modeling_of_Names_and_Verbs_for_Simultaneous_Face_and_Pose_Annotation.html">259 nips-2009-Who’s Doing What: Joint Modeling of Names and Verbs for Simultaneous Face and Pose Annotation</a></p>
<p>same-paper 2 0.76453102 <a title="242-lda-2" href="./nips-2009-The_Infinite_Partially_Observable_Markov_Decision_Process.html">242 nips-2009-The Infinite Partially Observable Markov Decision Process</a></p>
<p>3 0.74573934 <a title="242-lda-3" href="./nips-2009-Spatial_Normalized_Gamma_Processes.html">226 nips-2009-Spatial Normalized Gamma Processes</a></p>
<p>4 0.73998964 <a title="242-lda-4" href="./nips-2009-Estimating_image_bases_for_visual_image_reconstruction_from_human_brain_activity.html">83 nips-2009-Estimating image bases for visual image reconstruction from human brain activity</a></p>
<p>5 0.69823658 <a title="242-lda-5" href="./nips-2009-Learning_to_Explore_and_Exploit_in_POMDPs.html">134 nips-2009-Learning to Explore and Exploit in POMDPs</a></p>
<p>6 0.69430757 <a title="242-lda-6" href="./nips-2009-Training_Factor_Graphs_with_Reinforcement_Learning_for_Efficient_MAP_Inference.html">250 nips-2009-Training Factor Graphs with Reinforcement Learning for Efficient MAP Inference</a></p>
<p>7 0.69271731 <a title="242-lda-7" href="./nips-2009-Positive_Semidefinite_Metric_Learning_with_Boosting.html">191 nips-2009-Positive Semidefinite Metric Learning with Boosting</a></p>
<p>8 0.69077742 <a title="242-lda-8" href="./nips-2009-Semi-supervised_Regression_using_Hessian_energy_with_an_application_to_semi-supervised_dimensionality_reduction.html">214 nips-2009-Semi-supervised Regression using Hessian energy with an application to semi-supervised dimensionality reduction</a></p>
<p>9 0.68820405 <a title="242-lda-9" href="./nips-2009-Nonparametric_Bayesian_Texture_Learning_and_Synthesis.html">172 nips-2009-Nonparametric Bayesian Texture Learning and Synthesis</a></p>
<p>10 0.68661886 <a title="242-lda-10" href="./nips-2009-Measuring_model_complexity_with_the_prior_predictive.html">152 nips-2009-Measuring model complexity with the prior predictive</a></p>
<p>11 0.68591893 <a title="242-lda-11" href="./nips-2009-Local_Rules_for_Global_MAP%3A_When_Do_They_Work_%3F.html">141 nips-2009-Local Rules for Global MAP: When Do They Work ?</a></p>
<p>12 0.68062359 <a title="242-lda-12" href="./nips-2009-Maximum_likelihood_trajectories_for_continuous-time_Markov_chains.html">150 nips-2009-Maximum likelihood trajectories for continuous-time Markov chains</a></p>
<p>13 0.67618012 <a title="242-lda-13" href="./nips-2009-Learning_in_Markov_Random_Fields_using_Tempered_Transitions.html">132 nips-2009-Learning in Markov Random Fields using Tempered Transitions</a></p>
<p>14 0.67421252 <a title="242-lda-14" href="./nips-2009-Regularized_Distance_Metric_Learning%3ATheory_and_Algorithm.html">202 nips-2009-Regularized Distance Metric Learning:Theory and Algorithm</a></p>
<p>15 0.67361039 <a title="242-lda-15" href="./nips-2009-Bayesian_Source_Localization_with_the_Multivariate_Laplace_Prior.html">41 nips-2009-Bayesian Source Localization with the Multivariate Laplace Prior</a></p>
<p>16 0.67159092 <a title="242-lda-16" href="./nips-2009-Lattice_Regression.html">124 nips-2009-Lattice Regression</a></p>
<p>17 0.66865987 <a title="242-lda-17" href="./nips-2009-Kernels_and_learning_curves_for_Gaussian_process_regression_on_random_graphs.html">120 nips-2009-Kernels and learning curves for Gaussian process regression on random graphs</a></p>
<p>18 0.66764379 <a title="242-lda-18" href="./nips-2009-Code-specific_policy_gradient_rules_for_spiking_neurons.html">52 nips-2009-Code-specific policy gradient rules for spiking neurons</a></p>
<p>19 0.66601878 <a title="242-lda-19" href="./nips-2009-An_Online_Algorithm_for_Large_Scale_Image_Similarity_Learning.html">32 nips-2009-An Online Algorithm for Large Scale Image Similarity Learning</a></p>
<p>20 0.66576278 <a title="242-lda-20" href="./nips-2009-Manifold_Embeddings_for_Model-Based_Reinforcement_Learning_under_Partial_Observability.html">145 nips-2009-Manifold Embeddings for Model-Based Reinforcement Learning under Partial Observability</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
