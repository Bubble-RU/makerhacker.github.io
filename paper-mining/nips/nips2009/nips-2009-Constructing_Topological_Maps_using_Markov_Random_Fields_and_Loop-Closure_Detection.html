<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>58 nips-2009-Constructing Topological Maps using Markov Random Fields and Loop-Closure Detection</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-58" href="#">nips2009-58</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>58 nips-2009-Constructing Topological Maps using Markov Random Fields and Loop-Closure Detection</h1>
<br/><p>Source: <a title="nips-2009-58-pdf" href="http://papers.nips.cc/paper/3861-constructing-topological-maps-using-markov-random-fields-and-loop-closure-detection.pdf">pdf</a></p><p>Author: Roy Anati, Kostas Daniilidis</p><p>Abstract: We present a system which constructs a topological map of an environment given a sequence of images. This system includes a novel image similarity score which uses dynamic programming to match images using both the appearance and relative positions of local features simultaneously. Additionally, an MRF is constructed to model the probability of loop-closures. A locally optimal labeling is found using Loopy-BP. Finally we outline a method to generate a topological map from loop closure data. Results, presented on four urban sequences and one indoor sequence, outperform the state of the art. 1</p><p>Reference: <a title="nips-2009-58-reference" href="../nips2009_reference/nips-2009-Constructing_Topological_Maps_using_Markov_Random_Fields_and_Loop-Closure_Detection_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract We present a system which constructs a topological map of an environment given a sequence of images. [sent-3, score-0.481]
</p><p>2 This system includes a novel image similarity score which uses dynamic programming to match images using both the appearance and relative positions of local features simultaneously. [sent-4, score-0.844]
</p><p>3 Finally we outline a method to generate a topological map from loop closure data. [sent-7, score-0.627]
</p><p>4 Results, presented on four urban sequences and one indoor sequence, outperform the state of the art. [sent-8, score-0.222]
</p><p>5 1  Introduction  The task of generating a topological map from video data has gained prominence in recent years. [sent-9, score-0.497]
</p><p>6 Topological maps can correct for the drift in visual odometry systems and can be part of hybrid representations where the environment is represented metrically locally but topologically globally. [sent-12, score-0.216]
</p><p>7 We identify two challenges in constructing a topological map from video: how can we say whether two images have been taken from the same place; and how can we reduce the original set of thousands of video frames to a reduced representative set of keyframes for path planning. [sent-13, score-1.03]
</p><p>8 Video guarantees that keyframes will be reachable to each other but it also provides temporal ordering constraints on deciding about loop closures. [sent-15, score-0.471]
</p><p>9 The paper has three innovations: We deﬁne a novel image similarity score which uses dynamic programming to match images using both the appearance and the layout of the features in the environment. [sent-16, score-0.8]
</p><p>10 Finally, we show how the temporal assumption can be used to generate compact topological maps using minimum dominating sets. [sent-18, score-0.563]
</p><p>11 We formally deﬁne a topological map T as a graph T = (K, ET ), where K is a set of keyframes and ET edges describing connectivity between keyframes. [sent-19, score-0.907]
</p><p>12 We will see later that keyframes are representatives of locations. [sent-20, score-0.33]
</p><p>13 We desire the following properties of T : Loop closure For any two locations i, j ∈ K, ET contains the edge (i, j) if and only if it is possible to reach location j from location i without passing through any other location k ∈ K. [sent-21, score-0.275]
</p><p>14 1  Spatial distinctiveness Two images from “different locations” cannot be represented by the same keyframe. [sent-23, score-0.2]
</p><p>15 Note that spatial distinctiveness requires that we distinguish between separate locations, however compactness encourages agglomeration of geographically similar images. [sent-24, score-0.195]
</p><p>16 This distinction is important, as lack of compactness does not lead to errors in either path planning or visual odometry while breaking spatial distinctiveness does. [sent-25, score-0.379]
</p><p>17 Our approach to building topological maps is divided into three modules: calculating image similarity, detecting loop closures, and map construction. [sent-26, score-0.83]
</p><p>18 Starting with I, a sequence of n images, the result of calculating image similarity scores is a matrix Mn×n where Mij represents a relative similarity between images i and j. [sent-29, score-0.676]
</p><p>19 In section 2 we describe how we use local image features to compute the matrix M . [sent-30, score-0.181]
</p><p>20 To detect loop-closures we have to discretize M into a binary decision matrix Dn×n where Dij = 1 indicates that images i and j are geographically equivalent and form a loop closure. [sent-31, score-0.365]
</p><p>21 In the ﬁnal step, the topological map T is generated from D. [sent-33, score-0.44]
</p><p>22 We calculate the set of keyframes K and their associated connectivity ET using the minimum dominating set of the graph represented by D (Section 4). [sent-34, score-0.58]
</p><p>23 Related Work The state of the art in topological mapping of images is the FAB-MAP [8] algorithm. [sent-35, score-0.468]
</p><p>24 Bayesian inference is also used in [1] where bags of words on local image descriptors model locations whose consistency is validated with epipolar geometry. [sent-38, score-0.317]
</p><p>25 [14] incorporate both odometry and appearance and maintain several hypotheses of topological maps. [sent-40, score-0.498]
</p><p>26 [17] deﬁne maps on two levels, creating global (topological) maps by matching independent local (metric) data and combining loop -closure detection with visual SLAM (Self Localization and Mapping). [sent-42, score-0.334]
</p><p>27 Tomatis et al [17] detect loop closures by examining the modality of the robot position’s density function (PDF). [sent-44, score-0.377]
</p><p>28 Approaches like [3] [19] [18] and [9] represent the environment using only an image similarity matrix. [sent-46, score-0.296]
</p><p>29 Booij et al [3] use the similarity matrix to deﬁne a weighted graph for robot navigation. [sent-47, score-0.318]
</p><p>30 Navigation is conducted on a node by node basis, using new observations and epipolar geometry to estimate the direction of the next node. [sent-48, score-0.211]
</p><p>31 Valgren et al [19] avoid exhaustively computing the similarity matrix by searching for and sampling cells which are more likely to describe existing loop-closures. [sent-49, score-0.208]
</p><p>32 Fraundoerfer et al [9] use hierarchical vocabulary trees [13] to quickly compute image similarity scores. [sent-51, score-0.34]
</p><p>33 Our approach advances the state of the art by using a powerful image alignment score without employing full epipolar geometry, and more robust loop colsure detection by applying MRF inference on the similarity matrix. [sent-58, score-0.8]
</p><p>34 It is together with [4] the only video-based approach that provides a greatly reduced set of nodes for the ﬁnal topological representation, making thus path planning tractable. [sent-59, score-0.473]
</p><p>35 2  2  Image similarity score  For any two images i and j, we calculate the similarity score Mij in three steps: generate image features, sort image features into sequences, calculate optimal alignment between both sequences. [sent-60, score-1.188]
</p><p>36 To detect and generate image features we use Scale Invariant Feature Transform (SIFT) [12]. [sent-61, score-0.235]
</p><p>37 However, to mitigate perceptual aliasing, we take advantage of the fact that features represent real world structures with ﬁxed spatial arrangements and therefore the similarity score should take their relative positions into account. [sent-64, score-0.433]
</p><p>38 Instead, we make the assumption that the gravity vector is known so that we can split image position into bearing and elevation and we take into account only the bearing of each feature. [sent-67, score-0.3]
</p><p>39 We then search for an optimal alignment between pairs of sequences, incorporating both the value and ordering of SIFT features into our similarity score. [sent-69, score-0.355]
</p><p>40 Sequence alignment To solve for the optimal alignment between two ordered sequences of features we employ dynamic programming. [sent-70, score-0.508]
</p><p>41 Since bearing is not given with respect to an absolute orientation, ordering is meant only cyclically, which can be handled easily in dynamic programming by replicating one of the input sequences. [sent-74, score-0.207]
</p><p>42 Modifying the ﬁrst and last rows of the score matrix to allow for arbitrary start and end locations yields the optimal cyclical alignment in most cases. [sent-75, score-0.4]
</p><p>43 The score of the optimal alignment between both sequences of features provides the basis for the similarity score between two images and the entries of the matrix M . [sent-77, score-0.867]
</p><p>44 3 Loop closure-detection using MRF Using the image similarity measure matrix M , we use Markov Random Fields to detect loopclosures. [sent-80, score-0.35]
</p><p>45 A lattice H is deﬁned as an n × n lattice of binary nodes where a node vi,j represents the probability of images i and j forming a loop-closure. [sent-81, score-0.401]
</p><p>46 Loops closures in the score matrix M appear as one of three possible shapes. [sent-84, score-0.221]
</p><p>47 In an intersection the score matrix contains an ellipse. [sent-85, score-0.188]
</p><p>48 Therefore we deﬁne lattice H with eight way connectivity, as it better captures the structure of possible loop closures. [sent-89, score-0.218]
</p><p>49 As adjacent nodes in H represent sequential images in the sequence, we expect signiﬁcant overlap in their content. [sent-90, score-0.183]
</p><p>50 Sudden changes occur when either a loop is just closed (sudden increase) or when a loop closure is complete (sudden decrease) or due to noise caused by a sudden occlusion in one of the scenes. [sent-92, score-0.404]
</p><p>51 By imposing smoothness on the labeling we capture loop closures while discarding noise. [sent-93, score-0.274]
</p><p>52 We model every node and every edge in H as a node in the cluster graph C. [sent-100, score-0.228]
</p><p>53 We initialize the cluster graph directly from the lattice H with ψi,j = φi,j for nodes and ψi,j,k,l = φi,j,k,l for edges. [sent-104, score-0.186]
</p><p>54 The MAP labeling found here deﬁnes our matrix D determining whether two images i and j close a loop. [sent-105, score-0.179]
</p><p>55 4 Constructing the topological map Finally the decision matrix D is used to deﬁne keyframes K and determine the map connectivity ET . [sent-109, score-0.913]
</p><p>56 Since there is no guarantee that D found through belief propagation is symmetric, we initially treat D as an adjacency matrix for a directed graph, and then remove the direction from all the edges resulting in a symmetric graph D = D ∨ DT . [sent-111, score-0.219]
</p><p>57 It is possible to use the graph deﬁned by D as a topological map. [sent-112, score-0.394]
</p><p>58 We ﬁnd the keyframes K by ﬁnding the minimum dominating set of D . [sent-117, score-0.483]
</p><p>59 The dominating set itself serves as our keyframes K. [sent-120, score-0.483]
</p><p>60 Each dominating node k ∈ K is also associated with the set of nodes it dominates Nk . [sent-121, score-0.271]
</p><p>61 4  Algorithm 1: Approximate Minimum Dominating Set Input: Adjacency matric D Output: K,{Nk : k ∈ K} K←∅ while D is not empty do k ← node with largest degree K ← K ∪ {k} Nk ← {k} ∪ N b(k) Remove all nodes Nk from matrix D end  5  Experiments  The system was applied to ﬁve image sequences. [sent-128, score-0.25]
</p><p>62 Results are shown for the system as described, as well as for FAB-MAP ([8]) and for different methods of calculating image similarity scores. [sent-129, score-0.342]
</p><p>63 The Ladybug is composed of ﬁve wide-angle lens camera arranged in circle around the base and one camera on top facing upwards. [sent-131, score-0.242]
</p><p>64 The resulting output is a sequence of frames each containing a set of images captured by the six cameras. [sent-132, score-0.247]
</p><p>65 For the outdoor sequences the camera was mounted on top of a vehicle which was driven around an urban setting, in this case the cities of Philadelphia and Pittsburgh. [sent-133, score-0.491]
</p><p>66 In the indoor sequence, the camera was mounted on a tripod set on a cart and moved inside the building covering the ground and 1st ﬂoors. [sent-134, score-0.286]
</p><p>67 Ladybug images were processed independently for each camera using the SIFT detector and extractor provided in the VLFeat toolbox [20]. [sent-135, score-0.25]
</p><p>68 The resulting features for every camera were merged into a single set and sorted by their spherical coordinates. [sent-136, score-0.239]
</p><p>69 The two remaining sequences, City Centre and New College were captured in an outdoor setting by Cummins [7] from a limited ﬁeld of view camera mounted on a mobile robot. [sent-137, score-0.285]
</p><p>70 All the outdoor sequences were provided with GPS location of the vehicle / robot. [sent-139, score-0.288]
</p><p>71 of frames 852 1,266 1,256 1,237 1,073  Camera Type spherical spherical spherical limited ﬁeld of view limited ﬁeld of view  Format raw Ladybug stream ﬁle raw Ladybug stream ﬁle rectiﬁed images standard images standard images  Table 1: Summary of image sequences processed. [sent-144, score-0.87]
</p><p>72 For the indoor sequence the position of the camera was manually determined using building schematics at an arbitrary scale. [sent-147, score-0.262]
</p><p>73 Parameters Both the image similarity scores and the MRF contain a number of parameters that need to be set. [sent-150, score-0.296]
</p><p>74 When calculating the image similarity score, there are ﬁve parameters. [sent-151, score-0.342]
</p><p>75 In addition, dynamic programming requires three parameters to deﬁne the score of an optimal alignment: smatch ,sgap ,smiss . [sent-153, score-0.332]
</p><p>76 smatch is the value by which the score of an alignment is improved by including correctly matched pairs of features. [sent-154, score-0.351]
</p><p>77 sgap is the cost of ignoring a feature in the optimal alignment (insertion and deletion), and smiss is the cost of including incorrectly matched pairs (substitution). [sent-155, score-0.236]
</p><p>78 Finally we use w = 30 as our window size, to avoid calculating similarity scores for images taken within very short time of each 1  The Pittsburgh dataset has been provided by Google for research purposes  5  Precision Recall  Indoors 91. [sent-158, score-0.339]
</p><p>79 Results In addition to the image similarity score deﬁned above, we also processed the image SIF sequences using alternative similarity measures. [sent-177, score-0.837]
</p><p>80 We show results for Mij T = number of SIFT REC matches, Mij = number of reciprocal SIFT matches (the intersection of matches from image i to image j and from j to i). [sent-178, score-0.314]
</p><p>81 To process spherical images using FAB-MAP we limited ourselves to using images captured by camera 0 (Directly forwards / backwards). [sent-180, score-0.488]
</p><p>82 Figure 2 shows precision-recall curves for all sequences and similarity measures. [sent-181, score-0.271]
</p><p>83 Table 2 shows the results of performing inference on the image similarity matrices. [sent-185, score-0.296]
</p><p>84 Finally ﬁgure 3 shows the topological map resulting from running dominating sets on the decision matrices D. [sent-186, score-0.593]
</p><p>85 The blue dots represent the locations of the keyframes K with the edges ET drawn in blue. [sent-188, score-0.496]
</p><p>86 6 Outlook We presented a system that constructs purely topological maps from video sequences captured from moving vehicles. [sent-191, score-0.614]
</p><p>87 A highly accurate image similarity score is found by a cyclical alignment of sorted feature sequences. [sent-193, score-0.638]
</p><p>88 This score is then reﬁned via loopy-belief propagation to detect loop-closures. [sent-194, score-0.235]
</p><p>89 Finally we constructed a topological map for the sequence in question. [sent-195, score-0.481]
</p><p>90 This map can be used for either path planning or for bundle adjustment in visual SLAM systems. [sent-196, score-0.232]
</p><p>91 The bottleneck of the system is computing the image similarity score. [sent-197, score-0.296]
</p><p>92 In addition to implementing score calculation with a parallel algorithm (either on a multicore machine or using graphics hardware), we plan to construct approximations to our image similarity score. [sent-199, score-0.434]
</p><p>93 These include using visual bags of words in a hierarchical fashion [13] and building the score matrix M incrementally [19, 18]. [sent-200, score-0.233]
</p><p>94 8  Recall  Recall  (d) City Centre  (e) New College  Figure 2: Precision-recall curves for different thresholds on image similarity scores. [sent-272, score-0.296]
</p><p>95 Blue dots represent positions of keyframes K with edges ET drawn in blue. [sent-274, score-0.482]
</p><p>96 Blue dots represent positions of keyframes K with edges ET drawn in blue. [sent-277, score-0.482]
</p><p>97 Pruning the image set for appearance based robot localization. [sent-303, score-0.252]
</p><p>98 Monocular visual odometry in urban environments using an omnidirectional camera. [sent-381, score-0.301]
</p><p>99 Hybrid simultaneous localization and map building: a natural integration of topological and metric. [sent-388, score-0.44]
</p><p>100 Incremental spectral clustering and its application to topological mapping. [sent-395, score-0.339]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('topological', 0.339), ('keyframes', 0.33), ('sift', 0.248), ('indoors', 0.165), ('similarity', 0.164), ('dominating', 0.153), ('alignment', 0.142), ('loop', 0.141), ('score', 0.138), ('philadelphia', 0.136), ('mij', 0.132), ('image', 0.132), ('images', 0.129), ('robotics', 0.124), ('camera', 0.121), ('fab', 0.118), ('ladybug', 0.118), ('sequences', 0.107), ('city', 0.102), ('pittsburgh', 0.102), ('map', 0.101), ('booij', 0.094), ('odometry', 0.094), ('omnidirectional', 0.094), ('college', 0.093), ('centre', 0.087), ('nk', 0.085), ('bearing', 0.084), ('mrf', 0.083), ('compactness', 0.083), ('closures', 0.083), ('epipolar', 0.083), ('precision', 0.081), ('lattice', 0.077), ('vehicle', 0.077), ('sudden', 0.076), ('maps', 0.071), ('traversal', 0.071), ('cummins', 0.071), ('distinctiveness', 0.071), ('smatch', 0.071), ('tmatch', 0.071), ('tomatis', 0.071), ('valgren', 0.071), ('spherical', 0.069), ('dynamic', 0.068), ('dots', 0.068), ('appearance', 0.065), ('node', 0.064), ('cyclical', 0.062), ('mounted', 0.062), ('outdoor', 0.062), ('urban', 0.062), ('recall', 0.062), ('locations', 0.058), ('automation', 0.057), ('video', 0.057), ('robot', 0.055), ('programming', 0.055), ('graph', 0.055), ('nodes', 0.054), ('detect', 0.054), ('indoor', 0.053), ('visual', 0.051), ('atlas', 0.05), ('ground', 0.05), ('labeling', 0.05), ('intersection', 0.05), ('features', 0.049), ('ranganathan', 0.047), ('schematics', 0.047), ('sgap', 0.047), ('slam', 0.047), ('smiss', 0.047), ('vlfeat', 0.047), ('zivkovic', 0.047), ('closure', 0.046), ('calculating', 0.046), ('truth', 0.045), ('edge', 0.045), ('bags', 0.044), ('positions', 0.044), ('et', 0.044), ('propagation', 0.043), ('planning', 0.043), ('location', 0.042), ('connectivity', 0.042), ('dmax', 0.041), ('fb', 0.041), ('geographically', 0.041), ('icra', 0.041), ('sequence', 0.041), ('symmetric', 0.041), ('adjacency', 0.04), ('captured', 0.04), ('edges', 0.04), ('aliasing', 0.038), ('mitigate', 0.038), ('frames', 0.037), ('path', 0.037)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999946 <a title="58-tfidf-1" href="./nips-2009-Constructing_Topological_Maps_using_Markov_Random_Fields_and_Loop-Closure_Detection.html">58 nips-2009-Constructing Topological Maps using Markov Random Fields and Loop-Closure Detection</a></p>
<p>Author: Roy Anati, Kostas Daniilidis</p><p>Abstract: We present a system which constructs a topological map of an environment given a sequence of images. This system includes a novel image similarity score which uses dynamic programming to match images using both the appearance and relative positions of local features simultaneously. Additionally, an MRF is constructed to model the probability of loop-closures. A locally optimal labeling is found using Loopy-BP. Finally we outline a method to generate a topological map from loop closure data. Results, presented on four urban sequences and one indoor sequence, outperform the state of the art. 1</p><p>2 0.14234369 <a title="58-tfidf-2" href="./nips-2009-Segmenting_Scenes_by_Matching_Image_Composites.html">211 nips-2009-Segmenting Scenes by Matching Image Composites</a></p>
<p>Author: Bryan Russell, Alyosha Efros, Josef Sivic, Bill Freeman, Andrew Zisserman</p><p>Abstract: In this paper, we investigate how, given an image, similar images sharing the same global description can help with unsupervised scene segmentation. In contrast to recent work in semantic alignment of scenes, we allow an input image to be explained by partial matches of similar scenes. This allows for a better explanation of the input scenes. We perform MRF-based segmentation that optimizes over matches, while respecting boundary information. The recovered segments are then used to re-query a large database of images to retrieve better matches for the target regions. We show improved performance in detecting the principal occluding and contact boundaries for the scene over previous methods on data gathered from the LabelMe database.</p><p>3 0.12868318 <a title="58-tfidf-3" href="./nips-2009-Learning_models_of_object_structure.html">133 nips-2009-Learning models of object structure</a></p>
<p>Author: Joseph Schlecht, Kobus Barnard</p><p>Abstract: We present an approach for learning stochastic geometric models of object categories from single view images. We focus here on models expressible as a spatially contiguous assemblage of blocks. Model topologies are learned across groups of images, and one or more such topologies is linked to an object category (e.g. chairs). Fitting learned topologies to an image can be used to identify the object class, as well as detail its geometry. The latter goes beyond labeling objects, as it provides the geometric structure of particular instances. We learn the models using joint statistical inference over category parameters, camera parameters, and instance parameters. These produce an image likelihood through a statistical imaging model. We use trans-dimensional sampling to explore topology hypotheses, and alternate between Metropolis-Hastings and stochastic dynamics to explore instance parameters. Experiments on images of furniture objects such as tables and chairs suggest that this is an effective approach for learning models that encode simple representations of category geometry and the statistics thereof, and support inferring both category and geometry on held out single view images. 1</p><p>4 0.097133353 <a title="58-tfidf-4" href="./nips-2009-Local_Rules_for_Global_MAP%3A_When_Do_They_Work_%3F.html">141 nips-2009-Local Rules for Global MAP: When Do They Work ?</a></p>
<p>Author: Kyomin Jung, Pushmeet Kohli, Devavrat Shah</p><p>Abstract: We consider the question of computing Maximum A Posteriori (MAP) assignment in an arbitrary pair-wise Markov Random Field (MRF). We present a randomized iterative algorithm based on simple local updates. The algorithm, starting with an arbitrary initial assignment, updates it in each iteration by ﬁrst, picking a random node, then selecting an (appropriately chosen) random local neighborhood and optimizing over this local neighborhood. Somewhat surprisingly, we show that this algorithm ﬁnds a near optimal assignment within n log 2 n iterations with high probability for any n node pair-wise MRF with geometry (i.e. MRF graph with polynomial growth) with the approximation error depending on (in a reasonable manner) the geometric growth rate of the graph and the average radius of the local neighborhood – this allows for a graceful tradeoff between the complexity of the algorithm and the approximation error. Through extensive simulations, we show that our algorithm ﬁnds extremely good approximate solutions for various kinds of MRFs with geometry.</p><p>5 0.088255435 <a title="58-tfidf-5" href="./nips-2009-Learning_transport_operators_for_image_manifolds.html">137 nips-2009-Learning transport operators for image manifolds</a></p>
<p>Author: Benjamin Culpepper, Bruno A. Olshausen</p><p>Abstract: We describe an unsupervised manifold learning algorithm that represents a surface through a compact description of operators that traverse it. The operators are based on matrix exponentials, which are the solution to a system of ﬁrst-order linear differential equations. The matrix exponents are represented by a basis that is adapted to the statistics of the data so that the inﬁnitesimal generator for a trajectory along the underlying manifold can be produced by linearly composing a few elements. The method is applied to recover topological structure from low dimensional synthetic data, and to model local structure in how natural images change over time and scale. 1</p><p>6 0.08467181 <a title="58-tfidf-6" href="./nips-2009-Bayesian_estimation_of_orientation_preference_maps.html">43 nips-2009-Bayesian estimation of orientation preference maps</a></p>
<p>7 0.082607225 <a title="58-tfidf-7" href="./nips-2009-Unsupervised_Detection_of_Regions_of_Interest_Using_Iterative_Link_Analysis.html">251 nips-2009-Unsupervised Detection of Regions of Interest Using Iterative Link Analysis</a></p>
<p>8 0.082414202 <a title="58-tfidf-8" href="./nips-2009-Region-based_Segmentation_and_Object_Detection.html">201 nips-2009-Region-based Segmentation and Object Detection</a></p>
<p>9 0.081243753 <a title="58-tfidf-9" href="./nips-2009-A_Biologically_Plausible_Model_for_Rapid_Natural_Scene_Identification.html">6 nips-2009-A Biologically Plausible Model for Rapid Natural Scene Identification</a></p>
<p>10 0.079046808 <a title="58-tfidf-10" href="./nips-2009-An_Integer_Projected_Fixed_Point_Method_for_Graph_Matching_and_MAP_Inference.html">30 nips-2009-An Integer Projected Fixed Point Method for Graph Matching and MAP Inference</a></p>
<p>11 0.079018325 <a title="58-tfidf-11" href="./nips-2009-Filtering_Abstract_Senses_From_Image_Search_Results.html">96 nips-2009-Filtering Abstract Senses From Image Search Results</a></p>
<p>12 0.078270711 <a title="58-tfidf-12" href="./nips-2009-Efficient_Match_Kernel_between_Sets_of_Features_for_Visual_Recognition.html">77 nips-2009-Efficient Match Kernel between Sets of Features for Visual Recognition</a></p>
<p>13 0.077810183 <a title="58-tfidf-13" href="./nips-2009-Learning_from_Neighboring_Strokes%3A_Combining_Appearance_and_Context_for_Multi-Domain_Sketch_Recognition.html">131 nips-2009-Learning from Neighboring Strokes: Combining Appearance and Context for Multi-Domain Sketch Recognition</a></p>
<p>14 0.077194102 <a title="58-tfidf-14" href="./nips-2009-Lattice_Regression.html">124 nips-2009-Lattice Regression</a></p>
<p>15 0.077118866 <a title="58-tfidf-15" href="./nips-2009-Training_Factor_Graphs_with_Reinforcement_Learning_for_Efficient_MAP_Inference.html">250 nips-2009-Training Factor Graphs with Reinforcement Learning for Efficient MAP Inference</a></p>
<p>16 0.076734774 <a title="58-tfidf-16" href="./nips-2009-Discriminative_Network_Models_of_Schizophrenia.html">70 nips-2009-Discriminative Network Models of Schizophrenia</a></p>
<p>17 0.07391572 <a title="58-tfidf-17" href="./nips-2009-A_Bayesian_Model_for_Simultaneous_Image_Clustering%2C_Annotation_and_Object_Segmentation.html">5 nips-2009-A Bayesian Model for Simultaneous Image Clustering, Annotation and Object Segmentation</a></p>
<p>18 0.072496012 <a title="58-tfidf-18" href="./nips-2009-Speeding_up_Magnetic_Resonance_Image_Acquisition_by_Bayesian_Multi-Slice_Adaptive_Compressed_Sensing.html">228 nips-2009-Speeding up Magnetic Resonance Image Acquisition by Bayesian Multi-Slice Adaptive Compressed Sensing</a></p>
<p>19 0.071902968 <a title="58-tfidf-19" href="./nips-2009-Sparse_and_Locally_Constant_Gaussian_Graphical_Models.html">224 nips-2009-Sparse and Locally Constant Gaussian Graphical Models</a></p>
<p>20 0.07149417 <a title="58-tfidf-20" href="./nips-2009-Free_energy_score_space.html">97 nips-2009-Free energy score space</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.217), (1, -0.106), (2, -0.114), (3, -0.032), (4, -0.058), (5, 0.114), (6, 0.03), (7, 0.038), (8, 0.05), (9, -0.09), (10, -0.04), (11, 0.046), (12, 0.062), (13, 0.064), (14, -0.052), (15, -0.024), (16, -0.022), (17, -0.023), (18, -0.0), (19, -0.096), (20, 0.021), (21, 0.014), (22, 0.051), (23, -0.015), (24, 0.034), (25, 0.061), (26, 0.047), (27, -0.018), (28, -0.026), (29, 0.019), (30, 0.029), (31, 0.139), (32, -0.031), (33, 0.016), (34, -0.05), (35, 0.039), (36, 0.108), (37, -0.03), (38, -0.019), (39, 0.06), (40, -0.052), (41, 0.043), (42, -0.056), (43, 0.041), (44, -0.109), (45, 0.113), (46, -0.066), (47, -0.09), (48, 0.066), (49, -0.084)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96211898 <a title="58-lsi-1" href="./nips-2009-Constructing_Topological_Maps_using_Markov_Random_Fields_and_Loop-Closure_Detection.html">58 nips-2009-Constructing Topological Maps using Markov Random Fields and Loop-Closure Detection</a></p>
<p>Author: Roy Anati, Kostas Daniilidis</p><p>Abstract: We present a system which constructs a topological map of an environment given a sequence of images. This system includes a novel image similarity score which uses dynamic programming to match images using both the appearance and relative positions of local features simultaneously. Additionally, an MRF is constructed to model the probability of loop-closures. A locally optimal labeling is found using Loopy-BP. Finally we outline a method to generate a topological map from loop closure data. Results, presented on four urban sequences and one indoor sequence, outperform the state of the art. 1</p><p>2 0.66129839 <a title="58-lsi-2" href="./nips-2009-Segmenting_Scenes_by_Matching_Image_Composites.html">211 nips-2009-Segmenting Scenes by Matching Image Composites</a></p>
<p>Author: Bryan Russell, Alyosha Efros, Josef Sivic, Bill Freeman, Andrew Zisserman</p><p>Abstract: In this paper, we investigate how, given an image, similar images sharing the same global description can help with unsupervised scene segmentation. In contrast to recent work in semantic alignment of scenes, we allow an input image to be explained by partial matches of similar scenes. This allows for a better explanation of the input scenes. We perform MRF-based segmentation that optimizes over matches, while respecting boundary information. The recovered segments are then used to re-query a large database of images to retrieve better matches for the target regions. We show improved performance in detecting the principal occluding and contact boundaries for the scene over previous methods on data gathered from the LabelMe database.</p><p>3 0.61013258 <a title="58-lsi-3" href="./nips-2009-Nonparametric_Bayesian_Texture_Learning_and_Synthesis.html">172 nips-2009-Nonparametric Bayesian Texture Learning and Synthesis</a></p>
<p>Author: Long Zhu, Yuanahao Chen, Bill Freeman, Antonio Torralba</p><p>Abstract: We present a nonparametric Bayesian method for texture learning and synthesis. A texture image is represented by a 2D Hidden Markov Model (2DHMM) where the hidden states correspond to the cluster labeling of textons and the transition matrix encodes their spatial layout (the compatibility between adjacent textons). The 2DHMM is coupled with the Hierarchical Dirichlet process (HDP) which allows the number of textons and the complexity of transition matrix grow as the input texture becomes irregular. The HDP makes use of Dirichlet process prior which favors regular textures by penalizing the model complexity. This framework (HDP-2DHMM) learns the texton vocabulary and their spatial layout jointly and automatically. The HDP-2DHMM results in a compact representation of textures which allows fast texture synthesis with comparable rendering quality over the state-of-the-art patch-based rendering methods. We also show that the HDP2DHMM can be applied to perform image segmentation and synthesis. The preliminary results suggest that HDP-2DHMM is generally useful for further applications in low-level vision problems. 1</p><p>4 0.60365558 <a title="58-lsi-4" href="./nips-2009-An_Integer_Projected_Fixed_Point_Method_for_Graph_Matching_and_MAP_Inference.html">30 nips-2009-An Integer Projected Fixed Point Method for Graph Matching and MAP Inference</a></p>
<p>Author: Marius Leordeanu, Martial Hebert, Rahul Sukthankar</p><p>Abstract: Graph matching and MAP inference are essential problems in computer vision and machine learning. We introduce a novel algorithm that can accommodate both problems and solve them efﬁciently. Recent graph matching algorithms are based on a general quadratic programming formulation, which takes in consideration both unary and second-order terms reﬂecting the similarities in local appearance as well as in the pairwise geometric relationships between the matched features. This problem is NP-hard, therefore most algorithms ﬁnd approximate solutions by relaxing the original problem. They ﬁnd the optimal continuous solution of the modiﬁed problem, ignoring during optimization the original discrete constraints. Then the continuous solution is quickly binarized at the end, but very little attention is put into this ﬁnal discretization step. In this paper we argue that the stage in which a discrete solution is found is crucial for good performance. We propose an efﬁcient algorithm, with climbing and convergence properties, that optimizes in the discrete domain the quadratic score, and it gives excellent results either by itself or by starting from the solution returned by any graph matching algorithm. In practice it outperforms state-or-the art graph matching algorithms and it also signiﬁcantly improves their performance if used in combination. When applied to MAP inference, the algorithm is a parallel extension of Iterated Conditional Modes (ICM) with climbing and convergence properties that make it a compelling alternative to the sequential ICM. In our experiments on MAP inference our algorithm proved its effectiveness by signiﬁcantly outperforming [13], ICM and Max-Product Belief Propagation. 1</p><p>5 0.59688807 <a title="58-lsi-5" href="./nips-2009-Fast_Image_Deconvolution_using_Hyper-Laplacian_Priors.html">93 nips-2009-Fast Image Deconvolution using Hyper-Laplacian Priors</a></p>
<p>Author: Dilip Krishnan, Rob Fergus</p><p>Abstract: The heavy-tailed distribution of gradients in natural scenes have proven effective priors for a range of problems such as denoising, deblurring and super-resolution. α These distributions are well modeled by a hyper-Laplacian p(x) ∝ e−k|x| , typically with 0.5 ≤ α ≤ 0.8. However, the use of sparse distributions makes the problem non-convex and impractically slow to solve for multi-megapixel images. In this paper we describe a deconvolution approach that is several orders of magnitude faster than existing techniques that use hyper-Laplacian priors. We adopt an alternating minimization scheme where one of the two phases is a non-convex problem that is separable over pixels. This per-pixel sub-problem may be solved with a lookup table (LUT). Alternatively, for two speciﬁc values of α, 1/2 and 2/3 an analytic solution can be found, by ﬁnding the roots of a cubic and quartic polynomial, respectively. Our approach (using either LUTs or analytic formulae) is able to deconvolve a 1 megapixel image in less than ∼3 seconds, achieving comparable quality to existing methods such as iteratively reweighted least squares (IRLS) that take ∼20 minutes. Furthermore, our method is quite general and can easily be extended to related image processing problems, beyond the deconvolution application demonstrated. 1</p><p>6 0.56516689 <a title="58-lsi-6" href="./nips-2009-A_Biologically_Plausible_Model_for_Rapid_Natural_Scene_Identification.html">6 nips-2009-A Biologically Plausible Model for Rapid Natural Scene Identification</a></p>
<p>7 0.56430829 <a title="58-lsi-7" href="./nips-2009-Learning_from_Neighboring_Strokes%3A_Combining_Appearance_and_Context_for_Multi-Domain_Sketch_Recognition.html">131 nips-2009-Learning from Neighboring Strokes: Combining Appearance and Context for Multi-Domain Sketch Recognition</a></p>
<p>8 0.55898309 <a title="58-lsi-8" href="./nips-2009-An_Online_Algorithm_for_Large_Scale_Image_Similarity_Learning.html">32 nips-2009-An Online Algorithm for Large Scale Image Similarity Learning</a></p>
<p>9 0.55724502 <a title="58-lsi-9" href="./nips-2009-Learning_transport_operators_for_image_manifolds.html">137 nips-2009-Learning transport operators for image manifolds</a></p>
<p>10 0.55389047 <a title="58-lsi-10" href="./nips-2009-Whose_Vote_Should_Count_More%3A_Optimal_Integration_of_Labels_from_Labelers_of_Unknown_Expertise.html">258 nips-2009-Whose Vote Should Count More: Optimal Integration of Labels from Labelers of Unknown Expertise</a></p>
<p>11 0.53567034 <a title="58-lsi-11" href="./nips-2009-Maximin_affinity_learning_of_image_segmentation.html">149 nips-2009-Maximin affinity learning of image segmentation</a></p>
<p>12 0.51271617 <a title="58-lsi-12" href="./nips-2009-Lattice_Regression.html">124 nips-2009-Lattice Regression</a></p>
<p>13 0.50113672 <a title="58-lsi-13" href="./nips-2009-A_Bayesian_Model_for_Simultaneous_Image_Clustering%2C_Annotation_and_Object_Segmentation.html">5 nips-2009-A Bayesian Model for Simultaneous Image Clustering, Annotation and Object Segmentation</a></p>
<p>14 0.50053388 <a title="58-lsi-14" href="./nips-2009-Learning_models_of_object_structure.html">133 nips-2009-Learning models of object structure</a></p>
<p>15 0.48969901 <a title="58-lsi-15" href="./nips-2009-Estimating_image_bases_for_visual_image_reconstruction_from_human_brain_activity.html">83 nips-2009-Estimating image bases for visual image reconstruction from human brain activity</a></p>
<p>16 0.4894869 <a title="58-lsi-16" href="./nips-2009-Local_Rules_for_Global_MAP%3A_When_Do_They_Work_%3F.html">141 nips-2009-Local Rules for Global MAP: When Do They Work ?</a></p>
<p>17 0.48800448 <a title="58-lsi-17" href="./nips-2009-Perceptual_Multistability_as_Markov_Chain_Monte_Carlo_Inference.html">188 nips-2009-Perceptual Multistability as Markov Chain Monte Carlo Inference</a></p>
<p>18 0.46620935 <a title="58-lsi-18" href="./nips-2009-Speeding_up_Magnetic_Resonance_Image_Acquisition_by_Bayesian_Multi-Slice_Adaptive_Compressed_Sensing.html">228 nips-2009-Speeding up Magnetic Resonance Image Acquisition by Bayesian Multi-Slice Adaptive Compressed Sensing</a></p>
<p>19 0.4660868 <a title="58-lsi-19" href="./nips-2009-A_Gaussian_Tree_Approximation_for_Integer_Least-Squares.html">10 nips-2009-A Gaussian Tree Approximation for Integer Least-Squares</a></p>
<p>20 0.46001551 <a title="58-lsi-20" href="./nips-2009-An_Additive_Latent_Feature_Model_for_Transparent_Object_Recognition.html">28 nips-2009-An Additive Latent Feature Model for Transparent Object Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(21, 0.015), (24, 0.019), (25, 0.075), (35, 0.087), (36, 0.106), (39, 0.088), (58, 0.069), (61, 0.011), (71, 0.05), (81, 0.021), (82, 0.289), (86, 0.083), (91, 0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.82912368 <a title="58-lda-1" href="./nips-2009-Constructing_Topological_Maps_using_Markov_Random_Fields_and_Loop-Closure_Detection.html">58 nips-2009-Constructing Topological Maps using Markov Random Fields and Loop-Closure Detection</a></p>
<p>Author: Roy Anati, Kostas Daniilidis</p><p>Abstract: We present a system which constructs a topological map of an environment given a sequence of images. This system includes a novel image similarity score which uses dynamic programming to match images using both the appearance and relative positions of local features simultaneously. Additionally, an MRF is constructed to model the probability of loop-closures. A locally optimal labeling is found using Loopy-BP. Finally we outline a method to generate a topological map from loop closure data. Results, presented on four urban sequences and one indoor sequence, outperform the state of the art. 1</p><p>2 0.69526672 <a title="58-lda-2" href="./nips-2009-Maximum_likelihood_trajectories_for_continuous-time_Markov_chains.html">150 nips-2009-Maximum likelihood trajectories for continuous-time Markov chains</a></p>
<p>Author: Theodore J. Perkins</p><p>Abstract: Continuous-time Markov chains are used to model systems in which transitions between states as well as the time the system spends in each state are random. Many computational problems related to such chains have been solved, including determining state distributions as a function of time, parameter estimation, and control. However, the problem of inferring most likely trajectories, where a trajectory is a sequence of states as well as the amount of time spent in each state, appears unsolved. We study three versions of this problem: (i) an initial value problem, in which an initial state is given and we seek the most likely trajectory until a given ﬁnal time, (ii) a boundary value problem, in which initial and ﬁnal states and times are given, and we seek the most likely trajectory connecting them, and (iii) trajectory inference under partial observability, analogous to ﬁnding maximum likelihood trajectories for hidden Markov models. We show that maximum likelihood trajectories are not always well-deﬁned, and describe a polynomial time test for well-deﬁnedness. When well-deﬁnedness holds, we show that each of the three problems can be solved in polynomial time, and we develop efﬁcient dynamic programming algorithms for doing so. 1</p><p>3 0.59235156 <a title="58-lda-3" href="./nips-2009-Training_Factor_Graphs_with_Reinforcement_Learning_for_Efficient_MAP_Inference.html">250 nips-2009-Training Factor Graphs with Reinforcement Learning for Efficient MAP Inference</a></p>
<p>Author: Khashayar Rohanimanesh, Sameer Singh, Andrew McCallum, Michael J. Black</p><p>Abstract: Large, relational factor graphs with structure deﬁned by ﬁrst-order logic or other languages give rise to notoriously difﬁcult inference problems. Because unrolling the structure necessary to represent distributions over all hypotheses has exponential blow-up, solutions are often derived from MCMC. However, because of limitations in the design and parameterization of the jump function, these samplingbased methods suffer from local minima—the system must transition through lower-scoring conﬁgurations before arriving at a better MAP solution. This paper presents a new method of explicitly selecting fruitful downward jumps by leveraging reinforcement learning (RL). Rather than setting parameters to maximize the likelihood of the training data, parameters of the factor graph are treated as a log-linear function approximator and learned with methods of temporal difference (TD); MAP inference is performed by executing the resulting policy on held out test data. Our method allows efﬁcient gradient updates since only factors in the neighborhood of variables affected by an action need to be computed—we bypass the need to compute marginals entirely. Our method yields dramatic empirical success, producing new state-of-the-art results on a complex joint model of ontology alignment, with a 48% reduction in error over state-of-the-art in that domain. 1</p><p>4 0.57332981 <a title="58-lda-4" href="./nips-2009-Modelling_Relational_Data_using_Bayesian_Clustered_Tensor_Factorization.html">155 nips-2009-Modelling Relational Data using Bayesian Clustered Tensor Factorization</a></p>
<p>Author: Ilya Sutskever, Joshua B. Tenenbaum, Ruslan Salakhutdinov</p><p>Abstract: We consider the problem of learning probabilistic models for complex relational structures between various types of objects. A model can help us “understand” a dataset of relational facts in at least two ways, by ﬁnding interpretable structure in the data, and by supporting predictions, or inferences about whether particular unobserved relations are likely to be true. Often there is a tradeoff between these two aims: cluster-based models yield more easily interpretable representations, while factorization-based approaches have given better predictive performance on large data sets. We introduce the Bayesian Clustered Tensor Factorization (BCTF) model, which embeds a factorized representation of relations in a nonparametric Bayesian clustering framework. Inference is fully Bayesian but scales well to large data sets. The model simultaneously discovers interpretable clusters and yields predictive performance that matches or beats previous probabilistic models for relational data.</p><p>5 0.56848097 <a title="58-lda-5" href="./nips-2009-Neural_Implementation_of_Hierarchical_Bayesian_Inference_by_Importance_Sampling.html">162 nips-2009-Neural Implementation of Hierarchical Bayesian Inference by Importance Sampling</a></p>
<p>Author: Lei Shi, Thomas L. Griffiths</p><p>Abstract: The goal of perception is to infer the hidden states in the hierarchical process by which sensory data are generated. Human behavior is consistent with the optimal statistical solution to this problem in many tasks, including cue combination and orientation detection. Understanding the neural mechanisms underlying this behavior is of particular importance, since probabilistic computations are notoriously challenging. Here we propose a simple mechanism for Bayesian inference which involves averaging over a few feature detection neurons which ﬁre at a rate determined by their similarity to a sensory stimulus. This mechanism is based on a Monte Carlo method known as importance sampling, commonly used in computer science and statistics. Moreover, a simple extension to recursive importance sampling can be used to perform hierarchical Bayesian inference. We identify a scheme for implementing importance sampling with spiking neurons, and show that this scheme can account for human behavior in cue combination and the oblique effect. 1</p><p>6 0.56834513 <a title="58-lda-6" href="./nips-2009-Multi-Label_Prediction_via_Sparse_Infinite_CCA.html">158 nips-2009-Multi-Label Prediction via Sparse Infinite CCA</a></p>
<p>7 0.56779075 <a title="58-lda-7" href="./nips-2009-Perceptual_Multistability_as_Markov_Chain_Monte_Carlo_Inference.html">188 nips-2009-Perceptual Multistability as Markov Chain Monte Carlo Inference</a></p>
<p>8 0.56731933 <a title="58-lda-8" href="./nips-2009-Learning_from_Neighboring_Strokes%3A_Combining_Appearance_and_Context_for_Multi-Domain_Sketch_Recognition.html">131 nips-2009-Learning from Neighboring Strokes: Combining Appearance and Context for Multi-Domain Sketch Recognition</a></p>
<p>9 0.56725711 <a title="58-lda-9" href="./nips-2009-Nonparametric_Latent_Feature_Models_for_Link_Prediction.html">174 nips-2009-Nonparametric Latent Feature Models for Link Prediction</a></p>
<p>10 0.56569254 <a title="58-lda-10" href="./nips-2009-An_Additive_Latent_Feature_Model_for_Transparent_Object_Recognition.html">28 nips-2009-An Additive Latent Feature Model for Transparent Object Recognition</a></p>
<p>11 0.56402016 <a title="58-lda-11" href="./nips-2009-Discriminative_Network_Models_of_Schizophrenia.html">70 nips-2009-Discriminative Network Models of Schizophrenia</a></p>
<p>12 0.56094187 <a title="58-lda-12" href="./nips-2009-Learning_models_of_object_structure.html">133 nips-2009-Learning models of object structure</a></p>
<p>13 0.56012583 <a title="58-lda-13" href="./nips-2009-Manifold_Embeddings_for_Model-Based_Reinforcement_Learning_under_Partial_Observability.html">145 nips-2009-Manifold Embeddings for Model-Based Reinforcement Learning under Partial Observability</a></p>
<p>14 0.56001008 <a title="58-lda-14" href="./nips-2009-Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations.html">167 nips-2009-Non-Parametric Bayesian Dictionary Learning for Sparse Image Representations</a></p>
<p>15 0.55962723 <a title="58-lda-15" href="./nips-2009-Human_Rademacher_Complexity.html">112 nips-2009-Human Rademacher Complexity</a></p>
<p>16 0.55868089 <a title="58-lda-16" href="./nips-2009-Improving_Existing_Fault_Recovery_Policies.html">113 nips-2009-Improving Existing Fault Recovery Policies</a></p>
<p>17 0.55857396 <a title="58-lda-17" href="./nips-2009-Learning_transport_operators_for_image_manifolds.html">137 nips-2009-Learning transport operators for image manifolds</a></p>
<p>18 0.55751759 <a title="58-lda-18" href="./nips-2009-Non-stationary_continuous_dynamic_Bayesian_networks.html">168 nips-2009-Non-stationary continuous dynamic Bayesian networks</a></p>
<p>19 0.55659747 <a title="58-lda-19" href="./nips-2009-Accelerating_Bayesian_Structural_Inference_for_Non-Decomposable_Gaussian_Graphical_Models.html">23 nips-2009-Accelerating Bayesian Structural Inference for Non-Decomposable Gaussian Graphical Models</a></p>
<p>20 0.55651468 <a title="58-lda-20" href="./nips-2009-Learning_in_Markov_Random_Fields_using_Tempered_Transitions.html">132 nips-2009-Learning in Markov Random Fields using Tempered Transitions</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
