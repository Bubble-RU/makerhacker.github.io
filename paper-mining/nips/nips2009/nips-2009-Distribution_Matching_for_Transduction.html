<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>72 nips-2009-Distribution Matching for Transduction</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-72" href="#">nips2009-72</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>72 nips-2009-Distribution Matching for Transduction</h1>
<br/><p>Source: <a title="nips-2009-72-pdf" href="http://papers.nips.cc/paper/3666-distribution-matching-for-transduction.pdf">pdf</a></p><p>Author: Novi Quadrianto, James Petterson, Alex J. Smola</p><p>Abstract: Many transductive inference algorithms assume that distributions over training and test estimates should be related, e.g. by providing a large margin of separation on both sets. We use this idea to design a transduction algorithm which can be used without modiﬁcation for classiﬁcation, regression, and structured estimation. At its heart we exploit the fact that for a good learner the distributions over the outputs on training and test sets should match. This is a classical two-sample problem which can be solved efﬁciently in its most general form by using distance measures in Hilbert Space. It turns out that a number of existing heuristics can be viewed as special cases of our approach. 1</p><p>Reference: <a title="nips-2009-72-reference" href="../nips2009_reference/nips-2009-Distribution_Matching_for_Transduction_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 org  Abstract Many transductive inference algorithms assume that distributions over training and test estimates should be related, e. [sent-9, score-0.488]
</p><p>2 We use this idea to design a transduction algorithm which can be used without modiﬁcation for classiﬁcation, regression, and structured estimation. [sent-12, score-0.707]
</p><p>3 At its heart we exploit the fact that for a good learner the distributions over the outputs on training and test sets should match. [sent-13, score-0.267]
</p><p>4 1  Introduction  Transduction relies on the fundamental assumption that training and test data should exhibit similar behavior. [sent-16, score-0.186]
</p><p>5 For instance, in large margin classiﬁcation a popular concept is to assume that both training and test data should be separable with a large margin [4]. [sent-17, score-0.388]
</p><p>6 A similar matching assumption is made by [8, 15] in requiring that class means are balanced between training and test set. [sent-18, score-0.404]
</p><p>7 Such matching assumptions are well founded: after all, we assume that both training data X = {x1 , . [sent-20, score-0.259]
</p><p>8 It therefore follows that for any function (or set of functions) f : X → R the distribution of f (x) where x ∼ p(x) should also behave in the same way on both training and test set. [sent-27, score-0.186]
</p><p>9 That is, it is applicable without much need for customization to all estimation problems, whether structured or not. [sent-33, score-0.119]
</p><p>10 At its heart it uses the following: rather than minimizing only the empirical risk, regularized risk, log-posterior, or related quantities obtained only on the training set, let us add a divergence term characterizing the mismatch in distributions between training and test set. [sent-37, score-0.365]
</p><p>11 Moreover, we show that for certain choices of kernels we are able to recover a number of existing transduction constraints as a special case. [sent-39, score-0.666]
</p><p>12 That said, while 1  distribution matching always holds thus making our method always applicable, it is not entirely clear whether the cluster assumption is always satisﬁed (e. [sent-44, score-0.194]
</p><p>13 Distribution matching, however, comes with a nontrivial price: the objective of the optimization problem ceases to be convex except for rather special cases (which correspond to algorithms that have been proposed as previous work). [sent-47, score-0.112]
</p><p>14 While this is a downside, it is a property inherent in most transduction algorithms — after all, we are dealing with algorithms to obtain self-consistent labelings, predictions, or regressions on the data and there may exist more than one potential solution. [sent-48, score-0.634]
</p><p>15 Moreover, denote by X, Y sets of data and labels of the training set and by X , Y test data and labels respectively. [sent-50, score-0.278]
</p><p>16 In general, when designing an estimator one attempts to minimize some regularized risk functional Rreg [f, X, Y ] :=  m  1 m  l(xi , yi , f ) + λΩ[f ]  (1)  i=1  or alternatively (in a Bayesian setting) one deals with a log-posterior probability m  log p(yi |xi , f ) + log p(f ) + const. [sent-51, score-0.149]
</p><p>17 f typically is a mapping X → R (for scalar problems such as regression or classiﬁcation) or X → Rd (for multivariate problems such as named entity tagging, image annotation, matching, ranking, or more generally the clique potentials of graphical models). [sent-53, score-0.393]
</p><p>18 , f (xm )} the applications of our estimator (and any related quantities) to training and test set respectively. [sent-64, score-0.186]
</p><p>19 After all, we want that the empirical risk on the training and test sets match. [sent-67, score-0.243]
</p><p>20 This reasoning leads us to the following additional term for the objective function of a transduction problem: D(f (X), f (X ))  (4)  Here D(f (X), f (X )) denotes the distance between the two distributions f (X) and f (X ). [sent-69, score-0.798]
</p><p>21 This leads to an overall objective for learning Rtrain [f, X, Y ] + γD(f (X), f (X )) for some γ > 0  (5)  when performing transductive inference. [sent-70, score-0.302]
</p><p>22 Mean Matching for Classiﬁcation Joachims [8] uses the following balancing constraint in the objective function of a binary classiﬁer where y (x) = sgn(f (x)) for f (x) = w, x . [sent-80, score-0.162]
</p><p>23 In order to ˆ balance the outputs between training and test set, [8] imposes the linear constraint 1 m  m  f (xi ) = i=1  1 m  m  f (xi ). [sent-81, score-0.218]
</p><p>24 (8)  i=1  Assuming a linear kernel k on R this constraint is equivalent to requiring that µ[f (X)] =  1 m  m  f (xi ), · = i=1  1 m  m  f (xi ), · = µ[f (X )]. [sent-82, score-0.149]
</p><p>25 [5] propose to perform transduction by a requiring that the conditional class probabilities on training and test set match. [sent-88, score-0.877]
</p><p>26 That is, for classiﬁers generating a distribution of the form yi ∼ p(yi |xi , w) they require that the marginal class probability on the test set matches the empirical class probability on the training set. [sent-89, score-0.278]
</p><p>27 Again, this can be cast in terms of distribution matching via 1 µ[g ◦ f (X)] = m  m  i=1  1 g ◦ f (xi ), · = m  m  g ◦ f (xi ), · = µ[g ◦ f (X )] i=1  1 Here g(χ) = 1+e−χ denotes the likelihood of y = 1 in logistic regression for the model p(y|χ) = 1 1+e−yχ . [sent-90, score-0.2]
</p><p>28 In other words, generalizing distribution matching to apply to transforms other than the logistic leads us directly to our new transduction criterion. [sent-96, score-0.795]
</p><p>29 From left to right: induction scores on the training set; test set; transduction scores on the training set; test set; Note that while the margin distributions on training and test set are very different for induction, the ones for transduction match rather well. [sent-98, score-2.116]
</p><p>30 Distribution Matching for Regression A similar idea for transduction was proposed by [10] in the context of regression: requiring that both means and predictive variances of the estimate agree between training and test set. [sent-100, score-0.877]
</p><p>31 For a heteroscedastic regression estimate this constraint between training and test set is met simply by ensuring that the distributions over ﬁrst and second order moments of a Gaussian exponential family distribution match. [sent-101, score-0.298]
</p><p>32 The same goal can be achieved by using a polynomial kernel of second degree on the estimates, which shows that regression transduction can be viewed as a special case. [sent-102, score-0.765]
</p><p>33 Large Margin Hypothesis A key assumption in transduction is that a good hypothesis is characterized by a large margin of separation on both training and test set. [sent-103, score-0.921]
</p><p>34 Generalizations of this approach to multiclass and structured estimation settings is not entirely trivial and requires a number of heuristic choices (e. [sent-107, score-0.267]
</p><p>35 Instead, if we require that the distribution of values f (x, ·) on X match those on X, we automatically obtain a loss function which enforces the large margin hypothesis whenever it is actually achievable on the training set. [sent-110, score-0.234]
</p><p>36 4  Algorithm  Streaming Approximation In general, minimizing D(f (X), f (X )) is computationally infeasible since the estimation of the distributional distance requires access to f (X) and f (X ) rather than evaluations on a small sample. [sent-115, score-0.144]
</p><p>37 4  ˆ Stochastic Gradient Descent The fact that the estimator of the distance D decomposes into an average over a function of pairs from the training and test set respectively means that we can use Di as a stochastic approximation. [sent-124, score-0.289]
</p><p>38 ¯ ¯ end for Remark: The streaming formulation does not impose any in-principle limitation regarding matching sample sizes. [sent-129, score-0.195]
</p><p>39 DC programming has been used extensively in almost any other transductive algorithms to deal with non-convexity of the objective function. [sent-134, score-0.302]
</p><p>40 In order to minimize an additively decomposable objective function as in our transductive estimation, we could use stochastic gradient descent on the convex upper bound. [sent-137, score-0.518]
</p><p>41 Note that here the convex upper bound is given by a sum over the convex upper bounds for all terms. [sent-138, score-0.16]
</p><p>42 This strategy, however, is deﬁcient in a signiﬁcant aspect: the convex upper bounds on each of the loss terms become increasingly loose as we move f away from the current point of approximation. [sent-139, score-0.115]
</p><p>43 It would be considerably better if we updated the upper bound after every stochastic gradient descent step. [sent-140, score-0.177]
</p><p>44 This variant, however, is identical to stochastic gradient descent on the original objective function due to the following: ¯ ∂x F (x)|x=x = ∂x F (x, x0 )|x=x = ∂x G(x)|x=x − ∂x H(x)|x=x for all x0 . [sent-141, score-0.177]
</p><p>45 (17) 0  0  0  0  In other words, in order to compute the gradient of the upper bound we need not compute the upper bound itself. [sent-142, score-0.115]
</p><p>46 Instead we may use the nonconvex objective directly, hence we did not pursue DC programming approach and Algorithm 1 applies. [sent-143, score-0.116]
</p><p>47 5  Experiments  To demonstrate the applicability of our approach, we apply transduction to binary and multiclass classiﬁcation both on toy datasets from the UCI repository [16] and the LibSVM site [17], plus 5  a larger scale multi-category classiﬁcation dataset with 3. [sent-144, score-0.909]
</p><p>48 We also perform experiments on a structured estimation problem, i. [sent-146, score-0.119]
</p><p>49 Japanese named entity recognition task and CoNLL-2000 base NP chunking task. [sent-148, score-0.329]
</p><p>50 Algorithms Since we are not aware of other transductive algorithms which can be applied easily to all the problems we consider, we choose problem-speciﬁc transduction algorithms as competitors. [sent-149, score-0.895]
</p><p>51 This method is a variant of transductive SVM algorithm [8] tailored for linear semi-supervised binary classiﬁcation on large and sparse datasets and involves switching of more than a single pair of labels at a time. [sent-151, score-0.395]
</p><p>52 For multiclass categorization we pick a Gaussian processes based transductive algorithm with distribution matching term (GPDistMatch) [5]. [sent-152, score-0.567]
</p><p>53 We use stochastic gradient descent for optimization in both inductive and transductive settings for binary and multiclass losses. [sent-153, score-0.634]
</p><p>54 More speciﬁcally, for transduction we use the Gaussian RBF kernel to compare distributions in (14). [sent-154, score-0.735]
</p><p>55 Note that, in the multiclass case, the additional distribution matching term measures the distance between multivariate functions. [sent-155, score-0.323]
</p><p>56 Since we anticipate the relevant length scale in the margin distribution to be in the order of 1 (after all, we use a loss function, i. [sent-158, score-0.168]
</p><p>57 a hinge loss, which uses a margin of 1) we pick a Gaussian RBF kernel width of 0. [sent-160, score-0.209]
</p><p>58 Moreover, to take scaling in the number of classes √ into account we choose a kernel width of 0. [sent-162, score-0.108]
</p><p>59 We split data equally into training and test sets, performing model selection on the training set and assessing performance on the test set. [sent-166, score-0.411]
</p><p>60 In these small scale experiments, we tune hyperparameters via 5-fold cross validation on the entire training set. [sent-167, score-0.13]
</p><p>61 More speciﬁcally, in the model selection stage, for transduction we adjust the regularization λ and the transductive weight term γ (obviously, for inductive inference we only need to adjust λ). [sent-169, score-0.964]
</p><p>62 For GP transduction both the regularization and divergence parameters were adjusted. [sent-172, score-0.634]
</p><p>63 Results The experimental results are summarized in Figure 2 for a binary setting and in Table 1 for a multiclass problem. [sent-173, score-0.168]
</p><p>64 In 23 binary datasets, transduction outperforms the inductive setup in 20 of them. [sent-174, score-0.756]
</p><p>65 Arguably, our proposed transductive method performs on a par with state-of-the-art transductive approach for each learning problem. [sent-175, score-0.522]
</p><p>66 In the binary estimation, out of 23 datasets, our method performs signiﬁcantly worse than MultiSwitch transduction algorithm in 4 datasets (adult, bupa, pima, and svmguide3) and signiﬁcantly better on 2 datasets (ionosphere and pageblock), using a one-sided paired t-test with 95% conﬁdence. [sent-176, score-0.757]
</p><p>67 Further, by casting the transductive solution as an online optimization method, our approach scales well. [sent-182, score-0.261]
</p><p>68 Larger Scale Experiments Since one of the key points of our approach is that it can be applied to large problems, we performed transduction on the DMOZ ontology [20] of topics. [sent-183, score-0.702]
</p><p>69 DistMatch: distribution matching (ours) and MultiSwitch: Multi switch transductive SVM, [14]. [sent-190, score-0.422]
</p><p>70 DistMatch: distribution matching (ours) and GPDistMatch: Gaussian Process transduction, [5]. [sent-193, score-0.161]
</p><p>71 060 vehicle Table 2: Error rate on the DMOZ ontology for increasing training / test set sizes. [sent-224, score-0.288]
</p><p>72 training / test set size 50,000 100,000 200,000 400,000 800,000 1,600,000 induction 0. [sent-225, score-0.334]
</p><p>73 250 transduction Table 3: Error rate on the DMOZ ontology for ﬁxed training set size of 100,000 samples. [sent-237, score-0.8]
</p><p>74 test set size 100,000 200,000 400,000 800,000 1,600,000 induction 0. [sent-238, score-0.236]
</p><p>75 329 transduction Table 4: Accuracy, precision, recall and Fβ=1 score on the Japanese named entity task. [sent-248, score-0.9]
</p><p>76 62 Table 5: Accuracy, precision, recall and Fβ=1 score on the CoNLL-2000 base NP chunking task. [sent-257, score-0.165]
</p><p>77 To our knowledge, our proposed transduction method is the only one that scales very well due to the stochastic approximation. [sent-269, score-0.69]
</p><p>78 For each experiment, we split data into training and test sets. [sent-270, score-0.225]
</p><p>79 Model selection is perform on the training set by putting aside part of the training data as a validation set which is then used exclusively for tuning the hyperparameters. [sent-271, score-0.263]
</p><p>80 In large scale transduction two issues matter: ﬁrstly, the algorithm needs to be scalable with respect to the training set size. [sent-272, score-0.802]
</p><p>81 Secondly, we need to be able to scale the algorithm with respect to the test set. [sent-273, score-0.12]
</p><p>82 Note that Table 2 uses an equal split between training and test sets, while Table 3 uses an unequal split where the test 7  set has many more observations. [sent-275, score-0.352]
</p><p>83 We see that the algorithm improves with increasing data size, both for training and test sets. [sent-276, score-0.186]
</p><p>84 We suspect that a locationdependent transduction score would be useful in this context – i. [sent-278, score-0.685]
</p><p>85 instead of only minimizing the discrepancy between decision function values on training and test set D(f (X), f (X )) we could also introduce local features D((X, f (X)), (X , f (X ))). [sent-280, score-0.186]
</p><p>86 Japanese Named Entity Recognition Experiments A key advantage of our transduction algorithm is it can be applied to structured estimation without modiﬁcation. [sent-281, score-0.753]
</p><p>87 The data contains 716 Japanese sentences with 17 annotated named entities. [sent-283, score-0.145]
</p><p>88 That is, we have clique potentials joining adjacent labels (yi , yi+1 ), but which are independent of the text itself, and clique potentials joining words and labels (xi , yi ). [sent-288, score-0.536]
</p><p>89 For the latter, though, we want to enforce that clique potentials are distributed in the same way between training and test set. [sent-290, score-0.325]
</p><p>90 the chain length itself is a random variable, we perform distribution matching on a per-token basis — we oversample each token 10 times in our experiments. [sent-294, score-0.161]
</p><p>91 The additional distribution matching term is then measuring the distance between these over-sampled clique potentials. [sent-296, score-0.283]
</p><p>92 As before, we split data equally into training and test sets and put aside part of the training data as a validation set which is used exclusively for tuning the hyperparameters. [sent-297, score-0.39]
</p><p>93 We report results in Table 4, that is precision (fraction of name tags which match the reference tags), recall (fraction of reference tags returned), and their harmonic mean, Fβ=1 are reported. [sent-299, score-0.206]
</p><p>94 CoNLL-2000 Base NP Chunking Experiments Our second structured estimation experiment is the CoNLL-2000 base NP chunking dataset [13] as provided in the CRF++ toolkit. [sent-301, score-0.233]
</p><p>95 Similarly to Japanese named entity recognition task, 1D chain CRFs with only ﬁrst order Markov dependency between chunk tags are modeled. [sent-304, score-0.366]
</p><p>96 The same experimental setup as in named entity experiments is used. [sent-306, score-0.215]
</p><p>97 6  Summary and Discussion  We proposed a transductive estimation algorithm which is a) simple, b) general c) scalable and d) works well when compared to the state of the art algorithms applied to each speciﬁc problem. [sent-309, score-0.345]
</p><p>98 Not only is it useful for classical binary and multiclass categorization problems but it also applies to ontologies and structured estimation problems. [sent-310, score-0.317]
</p><p>99 It is not surprising that it performs very comparably to existing algorithms, since they can, in many cases, be seen as special instances of the general purpose distribution matching setting. [sent-311, score-0.193]
</p><p>100 Early results for named entity recognition with conditional random ﬁelds, feature induction and web enhanced lexicons. [sent-423, score-0.363]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('transduction', 0.634), ('transductive', 0.261), ('matching', 0.161), ('distmatch', 0.157), ('induction', 0.148), ('xi', 0.144), ('multiclass', 0.115), ('named', 0.113), ('japanese', 0.112), ('dmoz', 0.105), ('multiswitch', 0.105), ('entity', 0.102), ('margin', 0.101), ('training', 0.098), ('yi', 0.092), ('test', 0.088), ('crf', 0.085), ('chunking', 0.084), ('tags', 0.082), ('gpdistmatch', 0.079), ('rtrain', 0.079), ('clique', 0.075), ('nonconvex', 0.075), ('structured', 0.073), ('inductive', 0.069), ('chunk', 0.069), ('rtner', 0.069), ('ontology', 0.068), ('potentials', 0.064), ('ex', 0.061), ('kernel', 0.06), ('requiring', 0.057), ('risk', 0.057), ('np', 0.057), ('dc', 0.057), ('stochastic', 0.056), ('crfs', 0.056), ('binary', 0.053), ('bupa', 0.052), ('pageblock', 0.052), ('satimage', 0.052), ('score', 0.051), ('distributional', 0.051), ('xm', 0.05), ('width', 0.048), ('descent', 0.047), ('distance', 0.047), ('classi', 0.046), ('estimation', 0.046), ('anu', 0.046), ('rsise', 0.046), ('labels', 0.046), ('rbf', 0.042), ('sml', 0.042), ('precision', 0.042), ('objective', 0.041), ('distributions', 0.041), ('upper', 0.041), ('sigir', 0.04), ('heart', 0.04), ('repository', 0.04), ('regression', 0.039), ('pima', 0.039), ('multi', 0.039), ('split', 0.039), ('convex', 0.039), ('scalable', 0.038), ('canberra', 0.037), ('joining', 0.037), ('hilbert', 0.036), ('nicta', 0.036), ('balancing', 0.036), ('aside', 0.036), ('datasets', 0.035), ('reasoning', 0.035), ('loss', 0.035), ('streaming', 0.034), ('iris', 0.034), ('alex', 0.034), ('vehicle', 0.034), ('adult', 0.034), ('gradient', 0.033), ('entirely', 0.033), ('smola', 0.033), ('uci', 0.033), ('constraint', 0.032), ('scale', 0.032), ('availability', 0.032), ('sentences', 0.032), ('ionosphere', 0.032), ('special', 0.032), ('table', 0.031), ('di', 0.031), ('editors', 0.031), ('exclusively', 0.031), ('usps', 0.031), ('categorization', 0.03), ('base', 0.03), ('gretton', 0.03), ('zien', 0.03)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999923 <a title="72-tfidf-1" href="./nips-2009-Distribution_Matching_for_Transduction.html">72 nips-2009-Distribution Matching for Transduction</a></p>
<p>Author: Novi Quadrianto, James Petterson, Alex J. Smola</p><p>Abstract: Many transductive inference algorithms assume that distributions over training and test estimates should be related, e.g. by providing a large margin of separation on both sets. We use this idea to design a transduction algorithm which can be used without modiﬁcation for classiﬁcation, regression, and structured estimation. At its heart we exploit the fact that for a good learner the distributions over the outputs on training and test sets should match. This is a classical two-sample problem which can be solved efﬁciently in its most general form by using distance measures in Hilbert Space. It turns out that a number of existing heuristics can be viewed as special cases of our approach. 1</p><p>2 0.11106321 <a title="72-tfidf-2" href="./nips-2009-Breaking_Boundaries_Between_Induction_Time_and_Diagnosis_Time_Active_Information_Acquisition.html">49 nips-2009-Breaking Boundaries Between Induction Time and Diagnosis Time Active Information Acquisition</a></p>
<p>Author: Ashish Kapoor, Eric Horvitz</p><p>Abstract: To date, the processes employed for active information acquisition during periods of learning and diagnosis have been considered as separate and have been applied in distinct phases of analysis. While active learning centers on the collection of information about training cases in order to build better predictive models, diagnosis uses ﬁxed predictive models for guiding the collection of observations about a speciﬁc test case at hand. We introduce a model and inferential methods that bridge these phases of analysis into a holistic approach to information acquisition that considers simultaneously the extension of the predictive model and the probing of a case at hand. The bridging of active learning and real-time diagnostic feature acquisition leads to a new class of policies for learning and diagnosis. 1</p><p>3 0.10976627 <a title="72-tfidf-3" href="./nips-2009-Conditional_Random_Fields_with_High-Order_Features_for_Sequence_Labeling.html">57 nips-2009-Conditional Random Fields with High-Order Features for Sequence Labeling</a></p>
<p>Author: Nan Ye, Wee S. Lee, Hai L. Chieu, Dan Wu</p><p>Abstract: Dependencies among neighbouring labels in a sequence is an important source of information for sequence labeling problems. However, only dependencies between adjacent labels are commonly exploited in practice because of the high computational complexity of typical inference algorithms when longer distance dependencies are taken into account. In this paper, we show that it is possible to design efﬁcient inference algorithms for a conditional random ﬁeld using features that depend on long consecutive label sequences (high-order features), as long as the number of distinct label sequences used in the features is small. This leads to efﬁcient learning algorithms for these conditional random ﬁelds. We show experimentally that exploiting dependencies using high-order features can lead to substantial performance improvements for some problems and discuss conditions under which high-order features can be effective. 1</p><p>4 0.1030855 <a title="72-tfidf-4" href="./nips-2009-Entropic_Graph_Regularization_in_Non-Parametric_Semi-Supervised_Classification.html">82 nips-2009-Entropic Graph Regularization in Non-Parametric Semi-Supervised Classification</a></p>
<p>Author: Amarnag Subramanya, Jeff A. Bilmes</p><p>Abstract: We prove certain theoretical properties of a graph-regularized transductive learning objective that is based on minimizing a Kullback-Leibler divergence based loss. These include showing that the iterative alternating minimization procedure used to minimize the objective converges to the correct solution and deriving a test for convergence. We also propose a graph node ordering algorithm that is cache cognizant and leads to a linear speedup in parallel computations. This ensures that the algorithm scales to large data sets. By making use of empirical evaluation on the TIMIT and Switchboard I corpora, we show this approach is able to outperform other state-of-the-art SSL approaches. In one instance, we solve a problem on a 120 million node graph. 1</p><p>5 0.10084178 <a title="72-tfidf-5" href="./nips-2009-Exponential_Family_Graph_Matching_and_Ranking.html">87 nips-2009-Exponential Family Graph Matching and Ranking</a></p>
<p>Author: James Petterson, Jin Yu, Julian J. Mcauley, Tibério S. Caetano</p><p>Abstract: We present a method for learning max-weight matching predictors in bipartite graphs. The method consists of performing maximum a posteriori estimation in exponential families with sufﬁcient statistics that encode permutations and data features. Although inference is in general hard, we show that for one very relevant application–document ranking–exact inference is efﬁcient. For general model instances, an appropriate sampler is readily available. Contrary to existing max-margin matching models, our approach is statistically consistent and, in addition, experiments with increasing sample sizes indicate superior improvement over such models. We apply the method to graph matching in computer vision as well as to a standard benchmark dataset for learning document ranking, in which we obtain state-of-the-art results, in particular improving on max-margin variants. The drawback of this method with respect to max-margin alternatives is its runtime for large graphs, which is comparatively high. 1</p><p>6 0.092222877 <a title="72-tfidf-6" href="./nips-2009-Kernel_Choice_and_Classifiability_for_RKHS_Embeddings_of_Probability_Distributions.html">118 nips-2009-Kernel Choice and Classifiability for RKHS Embeddings of Probability Distributions</a></p>
<p>7 0.091129124 <a title="72-tfidf-7" href="./nips-2009-Distribution-Calibrated_Hierarchical_Classification.html">71 nips-2009-Distribution-Calibrated Hierarchical Classification</a></p>
<p>8 0.08678478 <a title="72-tfidf-8" href="./nips-2009-Learning_a_Small_Mixture_of_Trees.html">129 nips-2009-Learning a Small Mixture of Trees</a></p>
<p>9 0.077432349 <a title="72-tfidf-9" href="./nips-2009-Adaptive_Regularization_for_Transductive_Support_Vector_Machine.html">26 nips-2009-Adaptive Regularization for Transductive Support Vector Machine</a></p>
<p>10 0.076587379 <a title="72-tfidf-10" href="./nips-2009-Structured_output_regression_for_detection_with_partial_truncation.html">236 nips-2009-Structured output regression for detection with partial truncation</a></p>
<p>11 0.076398239 <a title="72-tfidf-11" href="./nips-2009-Boosting_with_Spatial_Regularization.html">47 nips-2009-Boosting with Spatial Regularization</a></p>
<p>12 0.075816043 <a title="72-tfidf-12" href="./nips-2009-Posterior_vs_Parameter_Sparsity_in_Latent_Variable_Models.html">192 nips-2009-Posterior vs Parameter Sparsity in Latent Variable Models</a></p>
<p>13 0.074207567 <a title="72-tfidf-13" href="./nips-2009-Convex_Relaxation_of_Mixture_Regression_with_Efficient_Algorithms.html">61 nips-2009-Convex Relaxation of Mixture Regression with Efficient Algorithms</a></p>
<p>14 0.073642969 <a title="72-tfidf-14" href="./nips-2009-Multi-Label_Prediction_via_Compressed_Sensing.html">157 nips-2009-Multi-Label Prediction via Compressed Sensing</a></p>
<p>15 0.072261982 <a title="72-tfidf-15" href="./nips-2009-A_Rate_Distortion_Approach_for_Semi-Supervised_Conditional_Random_Fields.html">15 nips-2009-A Rate Distortion Approach for Semi-Supervised Conditional Random Fields</a></p>
<p>16 0.072081201 <a title="72-tfidf-16" href="./nips-2009-Statistical_Analysis_of_Semi-Supervised_Learning%3A_The_Limit_of_Infinite_Unlabelled_Data.html">229 nips-2009-Statistical Analysis of Semi-Supervised Learning: The Limit of Infinite Unlabelled Data</a></p>
<p>17 0.071977198 <a title="72-tfidf-17" href="./nips-2009-Learning_Non-Linear_Combinations_of_Kernels.html">128 nips-2009-Learning Non-Linear Combinations of Kernels</a></p>
<p>18 0.071490437 <a title="72-tfidf-18" href="./nips-2009-Non-stationary_continuous_dynamic_Bayesian_networks.html">168 nips-2009-Non-stationary continuous dynamic Bayesian networks</a></p>
<p>19 0.06953305 <a title="72-tfidf-19" href="./nips-2009-Slow_Learners_are_Fast.html">220 nips-2009-Slow Learners are Fast</a></p>
<p>20 0.069019102 <a title="72-tfidf-20" href="./nips-2009-From_PAC-Bayes_Bounds_to_KL_Regularization.html">98 nips-2009-From PAC-Bayes Bounds to KL Regularization</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.245), (1, 0.089), (2, -0.077), (3, 0.03), (4, -0.023), (5, -0.051), (6, -0.071), (7, 0.031), (8, -0.07), (9, 0.05), (10, 0.033), (11, -0.012), (12, -0.015), (13, -0.054), (14, 0.025), (15, 0.034), (16, 0.017), (17, -0.072), (18, 0.035), (19, -0.077), (20, 0.063), (21, -0.113), (22, -0.001), (23, 0.087), (24, 0.024), (25, 0.149), (26, 0.06), (27, 0.063), (28, 0.021), (29, -0.01), (30, -0.055), (31, -0.093), (32, -0.017), (33, 0.101), (34, -0.002), (35, 0.039), (36, -0.059), (37, -0.034), (38, -0.025), (39, -0.026), (40, -0.043), (41, 0.026), (42, -0.056), (43, 0.066), (44, 0.022), (45, 0.06), (46, -0.028), (47, 0.005), (48, -0.091), (49, -0.051)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94379324 <a title="72-lsi-1" href="./nips-2009-Distribution_Matching_for_Transduction.html">72 nips-2009-Distribution Matching for Transduction</a></p>
<p>Author: Novi Quadrianto, James Petterson, Alex J. Smola</p><p>Abstract: Many transductive inference algorithms assume that distributions over training and test estimates should be related, e.g. by providing a large margin of separation on both sets. We use this idea to design a transduction algorithm which can be used without modiﬁcation for classiﬁcation, regression, and structured estimation. At its heart we exploit the fact that for a good learner the distributions over the outputs on training and test sets should match. This is a classical two-sample problem which can be solved efﬁciently in its most general form by using distance measures in Hilbert Space. It turns out that a number of existing heuristics can be viewed as special cases of our approach. 1</p><p>2 0.69450271 <a title="72-lsi-2" href="./nips-2009-Multiple_Incremental_Decremental_Learning_of_Support_Vector_Machines.html">160 nips-2009-Multiple Incremental Decremental Learning of Support Vector Machines</a></p>
<p>Author: Masayuki Karasuyama, Ichiro Takeuchi</p><p>Abstract: We propose a multiple incremental decremental algorithm of Support Vector Machine (SVM). Conventional single incremental decremental SVM can update the trained model efﬁciently when single data point is added to or removed from the training set. When we add and/or remove multiple data points, this algorithm is time-consuming because we need to repeatedly apply it to each data point. The proposed algorithm is computationally more efﬁcient when multiple data points are added and/or removed simultaneously. The single incremental decremental algorithm is built on an optimization technique called parametric programming. We extend the idea and introduce multi-parametric programming for developing the proposed algorithm. Experimental results on synthetic and real data sets indicate that the proposed algorithm can signiﬁcantly reduce the computational cost of multiple incremental decremental operation. Our approach is especially useful for online SVM learning in which we need to remove old data points and add new data points in a short amount of time.</p><p>3 0.68816698 <a title="72-lsi-3" href="./nips-2009-Periodic_Step_Size_Adaptation_for_Single_Pass_On-line_Learning.html">189 nips-2009-Periodic Step Size Adaptation for Single Pass On-line Learning</a></p>
<p>Author: Chun-nan Hsu, Yu-ming Chang, Hanshen Huang, Yuh-jye Lee</p><p>Abstract: It has been established that the second-order stochastic gradient descent (2SGD) method can potentially achieve generalization performance as well as empirical optimum in a single pass (i.e., epoch) through the training examples. However, 2SGD requires computing the inverse of the Hessian matrix of the loss function, which is prohibitively expensive. This paper presents Periodic Step-size Adaptation (PSA), which approximates the Jacobian matrix of the mapping function and explores a linear relation between the Jacobian and Hessian to approximate the Hessian periodically and achieve near-optimal results in experiments on a wide variety of models and tasks. 1</p><p>4 0.67516643 <a title="72-lsi-4" href="./nips-2009-Distribution-Calibrated_Hierarchical_Classification.html">71 nips-2009-Distribution-Calibrated Hierarchical Classification</a></p>
<p>Author: Ofer Dekel</p><p>Abstract: While many advances have already been made in hierarchical classiﬁcation learning, we take a step back and examine how a hierarchical classiﬁcation problem should be formally deﬁned. We pay particular attention to the fact that many arbitrary decisions go into the design of the label taxonomy that is given with the training data. Moreover, many hand-designed taxonomies are unbalanced and misrepresent the class structure in the underlying data distribution. We attempt to correct these problems by using the data distribution itself to calibrate the hierarchical classiﬁcation loss function. This distribution-based correction must be done with care, to avoid introducing unmanageable statistical dependencies into the learning problem. This leads us off the beaten path of binomial-type estimation and into the unfamiliar waters of geometric-type estimation. In this paper, we present a new calibrated deﬁnition of statistical risk for hierarchical classiﬁcation, an unbiased estimator for this risk, and a new algorithmic reduction from hierarchical classiﬁcation to cost-sensitive classiﬁcation.</p><p>5 0.67508477 <a title="72-lsi-5" href="./nips-2009-Breaking_Boundaries_Between_Induction_Time_and_Diagnosis_Time_Active_Information_Acquisition.html">49 nips-2009-Breaking Boundaries Between Induction Time and Diagnosis Time Active Information Acquisition</a></p>
<p>Author: Ashish Kapoor, Eric Horvitz</p><p>Abstract: To date, the processes employed for active information acquisition during periods of learning and diagnosis have been considered as separate and have been applied in distinct phases of analysis. While active learning centers on the collection of information about training cases in order to build better predictive models, diagnosis uses ﬁxed predictive models for guiding the collection of observations about a speciﬁc test case at hand. We introduce a model and inferential methods that bridge these phases of analysis into a holistic approach to information acquisition that considers simultaneously the extension of the predictive model and the probing of a case at hand. The bridging of active learning and real-time diagnostic feature acquisition leads to a new class of policies for learning and diagnosis. 1</p><p>6 0.65825331 <a title="72-lsi-6" href="./nips-2009-Conditional_Neural_Fields.html">56 nips-2009-Conditional Neural Fields</a></p>
<p>7 0.62340868 <a title="72-lsi-7" href="./nips-2009-Efficient_Large-Scale_Distributed_Training_of_Conditional_Maximum_Entropy_Models.html">75 nips-2009-Efficient Large-Scale Distributed Training of Conditional Maximum Entropy Models</a></p>
<p>8 0.6067757 <a title="72-lsi-8" href="./nips-2009-A_Rate_Distortion_Approach_for_Semi-Supervised_Conditional_Random_Fields.html">15 nips-2009-A Rate Distortion Approach for Semi-Supervised Conditional Random Fields</a></p>
<p>9 0.59328866 <a title="72-lsi-9" href="./nips-2009-Learning_from_Multiple_Partially_Observed_Views_-_an_Application_to_Multilingual_Text_Categorization.html">130 nips-2009-Learning from Multiple Partially Observed Views - an Application to Multilingual Text Categorization</a></p>
<p>10 0.58935875 <a title="72-lsi-10" href="./nips-2009-Dirichlet-Bernoulli_Alignment%3A_A_Generative_Model_for_Multi-Class_Multi-Label_Multi-Instance_Corpora.html">68 nips-2009-Dirichlet-Bernoulli Alignment: A Generative Model for Multi-Class Multi-Label Multi-Instance Corpora</a></p>
<p>11 0.58861989 <a title="72-lsi-11" href="./nips-2009-Heavy-Tailed_Symmetric_Stochastic_Neighbor_Embedding.html">106 nips-2009-Heavy-Tailed Symmetric Stochastic Neighbor Embedding</a></p>
<p>12 0.58053446 <a title="72-lsi-12" href="./nips-2009-Learning_Label_Embeddings_for_Nearest-Neighbor_Multi-class_Classification_with_an_Application_to_Speech_Recognition.html">127 nips-2009-Learning Label Embeddings for Nearest-Neighbor Multi-class Classification with an Application to Speech Recognition</a></p>
<p>13 0.56959462 <a title="72-lsi-13" href="./nips-2009-Kernel_Choice_and_Classifiability_for_RKHS_Embeddings_of_Probability_Distributions.html">118 nips-2009-Kernel Choice and Classifiability for RKHS Embeddings of Probability Distributions</a></p>
<p>14 0.56558943 <a title="72-lsi-14" href="./nips-2009-Label_Selection_on_Graphs.html">122 nips-2009-Label Selection on Graphs</a></p>
<p>15 0.56321067 <a title="72-lsi-15" href="./nips-2009-Adaptive_Regularization_for_Transductive_Support_Vector_Machine.html">26 nips-2009-Adaptive Regularization for Transductive Support Vector Machine</a></p>
<p>16 0.55990779 <a title="72-lsi-16" href="./nips-2009-Posterior_vs_Parameter_Sparsity_in_Latent_Variable_Models.html">192 nips-2009-Posterior vs Parameter Sparsity in Latent Variable Models</a></p>
<p>17 0.54942399 <a title="72-lsi-17" href="./nips-2009-Boosting_with_Spatial_Regularization.html">47 nips-2009-Boosting with Spatial Regularization</a></p>
<p>18 0.54761535 <a title="72-lsi-18" href="./nips-2009-Free_energy_score_space.html">97 nips-2009-Free energy score space</a></p>
<p>19 0.546574 <a title="72-lsi-19" href="./nips-2009-Learning_a_Small_Mixture_of_Trees.html">129 nips-2009-Learning a Small Mixture of Trees</a></p>
<p>20 0.54101926 <a title="72-lsi-20" href="./nips-2009-Sparse_Estimation_Using_General_Likelihoods_and_Non-Factorial_Priors.html">222 nips-2009-Sparse Estimation Using General Likelihoods and Non-Factorial Priors</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(7, 0.021), (8, 0.197), (21, 0.021), (24, 0.062), (25, 0.048), (35, 0.056), (36, 0.142), (39, 0.05), (58, 0.094), (61, 0.029), (71, 0.071), (81, 0.015), (86, 0.098), (91, 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.8467167 <a title="72-lda-1" href="./nips-2009-Distribution_Matching_for_Transduction.html">72 nips-2009-Distribution Matching for Transduction</a></p>
<p>Author: Novi Quadrianto, James Petterson, Alex J. Smola</p><p>Abstract: Many transductive inference algorithms assume that distributions over training and test estimates should be related, e.g. by providing a large margin of separation on both sets. We use this idea to design a transduction algorithm which can be used without modiﬁcation for classiﬁcation, regression, and structured estimation. At its heart we exploit the fact that for a good learner the distributions over the outputs on training and test sets should match. This is a classical two-sample problem which can be solved efﬁciently in its most general form by using distance measures in Hilbert Space. It turns out that a number of existing heuristics can be viewed as special cases of our approach. 1</p><p>2 0.83303368 <a title="72-lda-2" href="./nips-2009-Asymptotically_Optimal_Regularization_in_Smooth_Parametric_Models.html">37 nips-2009-Asymptotically Optimal Regularization in Smooth Parametric Models</a></p>
<p>Author: Percy Liang, Guillaume Bouchard, Francis R. Bach, Michael I. Jordan</p><p>Abstract: Many types of regularization schemes have been employed in statistical learning, each motivated by some assumption about the problem domain. In this paper, we present a uniﬁed asymptotic analysis of smooth regularizers, which allows us to see how the validity of these assumptions impacts the success of a particular regularizer. In addition, our analysis motivates an algorithm for optimizing regularization parameters, which in turn can be analyzed within our framework. We apply our analysis to several examples, including hybrid generative-discriminative learning and multi-task learning. 1</p><p>3 0.7483322 <a title="72-lda-3" href="./nips-2009-Training_Factor_Graphs_with_Reinforcement_Learning_for_Efficient_MAP_Inference.html">250 nips-2009-Training Factor Graphs with Reinforcement Learning for Efficient MAP Inference</a></p>
<p>Author: Khashayar Rohanimanesh, Sameer Singh, Andrew McCallum, Michael J. Black</p><p>Abstract: Large, relational factor graphs with structure deﬁned by ﬁrst-order logic or other languages give rise to notoriously difﬁcult inference problems. Because unrolling the structure necessary to represent distributions over all hypotheses has exponential blow-up, solutions are often derived from MCMC. However, because of limitations in the design and parameterization of the jump function, these samplingbased methods suffer from local minima—the system must transition through lower-scoring conﬁgurations before arriving at a better MAP solution. This paper presents a new method of explicitly selecting fruitful downward jumps by leveraging reinforcement learning (RL). Rather than setting parameters to maximize the likelihood of the training data, parameters of the factor graph are treated as a log-linear function approximator and learned with methods of temporal difference (TD); MAP inference is performed by executing the resulting policy on held out test data. Our method allows efﬁcient gradient updates since only factors in the neighborhood of variables affected by an action need to be computed—we bypass the need to compute marginals entirely. Our method yields dramatic empirical success, producing new state-of-the-art results on a complex joint model of ontology alignment, with a 48% reduction in error over state-of-the-art in that domain. 1</p><p>4 0.74558789 <a title="72-lda-4" href="./nips-2009-Learning_a_Small_Mixture_of_Trees.html">129 nips-2009-Learning a Small Mixture of Trees</a></p>
<p>Author: M. P. Kumar, Daphne Koller</p><p>Abstract: The problem of approximating a given probability distribution using a simpler distribution plays an important role in several areas of machine learning, for example variational inference and classiﬁcation. Within this context, we consider the task of learning a mixture of tree distributions. Although mixtures of trees can be learned by minimizing the KL-divergence using an EM algorithm, its success depends heavily on the initialization. We propose an efﬁcient strategy for obtaining a good initial set of trees that attempts to cover the entire observed distribution by minimizing the α-divergence with α = ∞. We formulate the problem using the fractional covering framework and present a convergent sequential algorithm that only relies on solving a convex program at each iteration. Compared to previous methods, our approach results in a signiﬁcantly smaller mixture of trees that provides similar or better accuracies. We demonstrate the usefulness of our approach by learning pictorial structures for face recognition.</p><p>5 0.74509126 <a title="72-lda-5" href="./nips-2009-Learning_in_Markov_Random_Fields_using_Tempered_Transitions.html">132 nips-2009-Learning in Markov Random Fields using Tempered Transitions</a></p>
<p>Author: Ruslan Salakhutdinov</p><p>Abstract: Markov random ﬁelds (MRF’s), or undirected graphical models, provide a powerful framework for modeling complex dependencies among random variables. Maximum likelihood learning in MRF’s is hard due to the presence of the global normalizing constant. In this paper we consider a class of stochastic approximation algorithms of the Robbins-Monro type that use Markov chain Monte Carlo to do approximate maximum likelihood learning. We show that using MCMC operators based on tempered transitions enables the stochastic approximation algorithm to better explore highly multimodal distributions, which considerably improves parameter estimates in large, densely-connected MRF’s. Our results on MNIST and NORB datasets demonstrate that we can successfully learn good generative models of high-dimensional, richly structured data that perform well on digit and object recognition tasks.</p><p>6 0.74460441 <a title="72-lda-6" href="./nips-2009-Zero-shot_Learning_with_Semantic_Output_Codes.html">260 nips-2009-Zero-shot Learning with Semantic Output Codes</a></p>
<p>7 0.74318868 <a title="72-lda-7" href="./nips-2009-Nonlinear_Learning_using_Local_Coordinate_Coding.html">169 nips-2009-Nonlinear Learning using Local Coordinate Coding</a></p>
<p>8 0.73828697 <a title="72-lda-8" href="./nips-2009-Distribution-Calibrated_Hierarchical_Classification.html">71 nips-2009-Distribution-Calibrated Hierarchical Classification</a></p>
<p>9 0.73793054 <a title="72-lda-9" href="./nips-2009-Kernel_Choice_and_Classifiability_for_RKHS_Embeddings_of_Probability_Distributions.html">118 nips-2009-Kernel Choice and Classifiability for RKHS Embeddings of Probability Distributions</a></p>
<p>10 0.73681056 <a title="72-lda-10" href="./nips-2009-An_Integer_Projected_Fixed_Point_Method_for_Graph_Matching_and_MAP_Inference.html">30 nips-2009-An Integer Projected Fixed Point Method for Graph Matching and MAP Inference</a></p>
<p>11 0.73677492 <a title="72-lda-11" href="./nips-2009-Bayesian_Source_Localization_with_the_Multivariate_Laplace_Prior.html">41 nips-2009-Bayesian Source Localization with the Multivariate Laplace Prior</a></p>
<p>12 0.73643732 <a title="72-lda-12" href="./nips-2009-Group_Sparse_Coding.html">104 nips-2009-Group Sparse Coding</a></p>
<p>13 0.73626196 <a title="72-lda-13" href="./nips-2009-A_Stochastic_approximation_method_for_inference_in_probabilistic_graphical_models.html">18 nips-2009-A Stochastic approximation method for inference in probabilistic graphical models</a></p>
<p>14 0.73464358 <a title="72-lda-14" href="./nips-2009-Sharing_Features_among_Dynamical_Systems_with_Beta_Processes.html">217 nips-2009-Sharing Features among Dynamical Systems with Beta Processes</a></p>
<p>15 0.73395026 <a title="72-lda-15" href="./nips-2009-Exponential_Family_Graph_Matching_and_Ranking.html">87 nips-2009-Exponential Family Graph Matching and Ranking</a></p>
<p>16 0.7338683 <a title="72-lda-16" href="./nips-2009-Slow_Learners_are_Fast.html">220 nips-2009-Slow Learners are Fast</a></p>
<p>17 0.73383844 <a title="72-lda-17" href="./nips-2009-Adaptive_Regularization_of_Weight_Vectors.html">27 nips-2009-Adaptive Regularization of Weight Vectors</a></p>
<p>18 0.73316586 <a title="72-lda-18" href="./nips-2009-AUC_optimization_and_the_two-sample_problem.html">3 nips-2009-AUC optimization and the two-sample problem</a></p>
<p>19 0.7324146 <a title="72-lda-19" href="./nips-2009-Efficient_and_Accurate_Lp-Norm_Multiple_Kernel_Learning.html">80 nips-2009-Efficient and Accurate Lp-Norm Multiple Kernel Learning</a></p>
<p>20 0.73239833 <a title="72-lda-20" href="./nips-2009-Nonparametric_Latent_Feature_Models_for_Link_Prediction.html">174 nips-2009-Nonparametric Latent Feature Models for Link Prediction</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
