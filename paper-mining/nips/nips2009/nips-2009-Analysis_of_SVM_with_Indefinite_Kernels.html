<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>33 nips-2009-Analysis of SVM with Indefinite Kernels</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-33" href="#">nips2009-33</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>33 nips-2009-Analysis of SVM with Indefinite Kernels</h1>
<br/><p>Source: <a title="nips-2009-33-pdf" href="http://papers.nips.cc/paper/3661-analysis-of-svm-with-indefinite-kernels.pdf">pdf</a></p><p>Author: Yiming Ying, Colin Campbell, Mark Girolami</p><p>Abstract: The recent introduction of indeﬁnite SVM by Luss and d’Aspremont [15] has effectively demonstrated SVM classiﬁcation with a non-positive semi-deﬁnite kernel (indeﬁnite kernel). This paper studies the properties of the objective function introduced there. In particular, we show that the objective function is continuously differentiable and its gradient can be explicitly computed. Indeed, we further show that its gradient is Lipschitz continuous. The main idea behind our analysis is that the objective function is smoothed by the penalty term, in its saddle (min-max) representation, measuring the distance between the indeﬁnite kernel matrix and the proxy positive semi-deﬁnite one. Our elementary result greatly facilitates the application of gradient-based algorithms. Based on our analysis, we further develop Nesterov’s smooth optimization approach [17, 18] for indeﬁnite SVM which has an optimal convergence rate for smooth problems. Experiments on various benchmark datasets validate our analysis and demonstrate the efﬁciency of our proposed algorithms.</p><p>Reference: <a title="nips-2009-33-reference" href="../nips2009_reference/nips-2009-Analysis_of_SVM_with_Indefinite_Kernels_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Building, G12 8QQ, United Kingdom  Abstract The recent introduction of indeﬁnite SVM by Luss and d’Aspremont [15] has effectively demonstrated SVM classiﬁcation with a non-positive semi-deﬁnite kernel (indeﬁnite kernel). [sent-4, score-0.106]
</p><p>2 This paper studies the properties of the objective function introduced there. [sent-5, score-0.098]
</p><p>3 In particular, we show that the objective function is continuously differentiable and its gradient can be explicitly computed. [sent-6, score-0.305]
</p><p>4 The main idea behind our analysis is that the objective function is smoothed by the penalty term, in its saddle (min-max) representation, measuring the distance between the indeﬁnite kernel matrix and the proxy positive semi-deﬁnite one. [sent-8, score-0.463]
</p><p>5 Our elementary result greatly facilitates the application of gradient-based algorithms. [sent-9, score-0.101]
</p><p>6 Based on our analysis, we further develop Nesterov’s smooth optimization approach [17, 18] for indeﬁnite SVM which has an optimal convergence rate for smooth problems. [sent-10, score-0.437]
</p><p>7 1 Introduction Kernel methods [5, 24] such as Support Vector Machines (SVM) have recently attracted much attention due to their good generalization performance and appealing optimization approaches. [sent-12, score-0.102]
</p><p>8 The basic idea of kernel methods is to map the data into a high dimensional (even inﬁnite-dimensional) feature space through a kernel function. [sent-13, score-0.212]
</p><p>9 The kernel function over samples forms a similarity kernel matrix which is usually required to be positive semi-deﬁnite (PSD). [sent-14, score-0.312]
</p><p>10 The PSD property of the similarity matrix ensures that the SVM can be efﬁciently solved by a convex quadratic programming. [sent-15, score-0.168]
</p><p>11 However, many potential kernel matrices could be non-positive semi-deﬁnite. [sent-16, score-0.106]
</p><p>12 Such cases are quite common in applications such as the sigmoid kernel [14] for various values of the hyper-parameters, hyperbolic tangent kernels [25], and the protein sequence similarity measures derived from SmithWaterman and BLAST score [23]. [sent-17, score-0.268]
</p><p>13 The problem of learning with a non-PSD similarity matrix (indeﬁnite kernel) has recently attracted considerable attention [4, 8, 9, 14, 20, 21, 26]. [sent-18, score-0.105]
</p><p>14 One widely used method is to convert the indeﬁnite kernel matrix into a PSD one by using the spectrum transformation. [sent-19, score-0.18]
</p><p>15 The denoise method neglects the negative eigenvalues [8, 21], ﬂip [8] takes the absolute value of all eigenvalues, shift [22] shifts eigenvalues to be positive by adding a positive constant, and the diffusion method [11] takes the exponentials of eigenvalues. [sent-20, score-0.271]
</p><p>16 In [9], the classiﬁcation problem with indeﬁnite kernels is regarded as the minimization of the distance between convex hulls in the pseudo-Euclidean space. [sent-23, score-0.127]
</p><p>17 In [20], general Reproducing Kernel Kreˇn spaces (RKKS) with indeﬁnite ı kernels are introduced which allows a general representer theorem and regularization formulations. [sent-24, score-0.163]
</p><p>18 Training a SVM with an indeﬁnite kernel was viewed as a learning the kernel 1  matrix problem [13] i. [sent-26, score-0.26]
</p><p>19 learning a proxy PSD kernel matrix to approximate the indeﬁnite one. [sent-28, score-0.227]
</p><p>20 Without realizing that the objective function is differentiable, the authors quadratically smoothed the objective function, and then formulated two approximate algorithms including the projected gradient method and the analytic center cutting plane method. [sent-29, score-0.696]
</p><p>21 In this paper we follow the formulation of SVM with indeﬁnite kernels proposed in [15]. [sent-30, score-0.107]
</p><p>22 We mainly establish the differentiability of the objective function (see its precise deﬁnition in equation (3)) and prove that it is, indeed, differentiable with Lipschitz continuous gradient. [sent-31, score-0.314]
</p><p>23 This elementary result suggests there is no need to smooth the objective function which greatly facilitates the application of gradient-based algorithms. [sent-32, score-0.349]
</p><p>24 The main idea behind our analysis is from its saddle (min-max) representation which involves a penalty term in the form of Frobenius norm of matrices, measuring the distance between the indeﬁnite kernel matrix and the proxy PSD one. [sent-33, score-0.297]
</p><p>25 This penalty term can be regarded as a Moreau-Yosida regularization term [12] to smooth out the objective function. [sent-34, score-0.277]
</p><p>26 There, we ﬁrst show that the objective function of interest is continuously differentiable and its gradient function can be explicitly computed. [sent-38, score-0.305]
</p><p>27 Based on our analysis, in Section 4 we propose a simpliﬁed formulation of the projected gradient method presented in [15] and show that it has a convergence rate of O(1/k) where k is the iteration number. [sent-40, score-0.403]
</p><p>28 We further develop Nesterov’s smooth optimization approach [17, 18] for indeﬁnite SVM which has an optimal convergence rate of O(1/k 2 ) for smooth problems. [sent-41, score-0.437]
</p><p>29 Suppose that K is a positive semi-deﬁnite kernel matrix (proxy kernel matrix) on inputs x. [sent-55, score-0.285]
</p><p>30 Since we assume that K is positive semi-deﬁnite, the above problem is a standard convex quadratic program [2] and a global solution can be efﬁciently obtained by, e. [sent-60, score-0.118]
</p><p>31 Suppose now we are only given an indeﬁnite kernel matrix K0 ∈ S n . [sent-63, score-0.154]
</p><p>32 Luss and d’Aspremont [15] proposed the following max-min approach to simultaneously learn a proxy PSD kernel matrix K for the indeﬁnite matrix K0 and the SVM classiﬁcation: 1 minK maxα α e − 2 α Y KY α + ρ K − K0 2 F (1) s. [sent-64, score-0.275]
</p><p>33 F By the min-max theorem [2], problem (1) is equivalent to max minn L(α, K). [sent-68, score-0.2]
</p><p>34 (2) α∈Q1 K∈S+  For simplicity, we refer to the following function deﬁned by f (α) = minn L(α, K) K∈S+  (3)  as the objective function. [sent-69, score-0.144]
</p><p>35 We also call the associated function L(α, K) the saddle representation of the objective function f . [sent-71, score-0.168]
</p><p>36 2  For ﬁxed α ∈ Q1 , the optimization K(α) = arg minK 0 L(α, K) is equivalent to a projection to n the semi-deﬁnite cone S+ . [sent-72, score-0.125]
</p><p>37 Indeed, it was shown in [15] that the optimal solution is given by K(α) = (K0 + Y αα Y /(4ρ))+  (4)  n  where, for any matrix A ∈ S , the notation A+ denotes the positive part of A by simply setting n its negative eigenvalues to zero. [sent-73, score-0.151]
</p><p>38 The next lemma tells us that the optimal solution K ∗ belongs to a bounded domain in n S+ . [sent-80, score-0.118]
</p><p>39 Problem (2) is equivalent to the formulation maxα∈Q1 minK∈Q2 L(α, K) and the objective function can be deﬁned by f (α) = min L(α, K) K∈Q2  n where Q2 := K ∈ S+ : λmax (K) ≤ λmax (K0 ) +  nC 2 4ρ  (5)  . [sent-82, score-0.135]
</p><p>40 By the saddle theorem [2], we have L(α∗ , K ∗ ) = minK∈Q2 L(α∗ , K). [sent-84, score-0.134]
</p><p>41 α Y KY α, in the objective function deﬁned by (5), it can not be written as the above special form, and hence the theorem there can not be applied to our case. [sent-96, score-0.162]
</p><p>42 3 Differentiability of the Objective Function The following lemma outlines a very useful characterization of differentiable properties of the optimal value function [3, Theorem 4. [sent-97, score-0.194]
</p><p>43 Furthermore, if for α ∈ U , L(α, ·) has a unique minimizer x(α) over Q then f is differentiable at α and the gradient of f is given by f (α) = ∂α L(α, x(α)). [sent-104, score-0.202]
</p><p>44 Applying the above lemma to the objective function f deﬁned by equation (5), we have: Theorem 1. [sent-105, score-0.189]
</p><p>45 The objective function f deﬁned by (3) (equivalently by (5)) is differentiable and its gradient is given by f (α) = e − Y (K0 + Y αα Y /(4ρ))+ Y α. [sent-106, score-0.272]
</p><p>46 Noting that ∂K L(α, K) = − 1 Y αα Y + 2ρ(K − K0 ) and adding the above two ﬁrst2 order optimaility inequalities together, we have − K2 −K1 2 ≥ 0 which means that K1 = K2 , and F hence completes the proof of the uniqueness of K(α). [sent-113, score-0.127]
</p><p>47 3  Indeed, we can go further to establish the Lipschitz continuity of f based on the strongly convex property of L(α, ·). [sent-118, score-0.143]
</p><p>48 Consequently, (α2 α2 − α1 α1 ) F Y (α2 α2 − α1 α1 )Y F ≤ (7) 4ρ 4ρ where the last inequality follows from the fact that Y is an orthonormal matrix since yi ∈ {±1} and Y = diag(y1 , . [sent-132, score-0.131]
</p><p>49 Putting this back into inequality (7) completes the proof of the lemma. [sent-137, score-0.134]
</p><p>50 K(α1 ) − K(α2 )  F  ≤  It is interesting to point out that the above lemma can be alternatively established by delicate techniques in matrix analysis. [sent-138, score-0.139]
</p><p>51 The perturbation inequality in matrix analysis [1, Lemma VII. [sent-148, score-0.131]
</p><p>52 F From the above lemma, we can establish the Lipschitz continuity of the gradient of the objective function. [sent-153, score-0.257]
</p><p>53 The gradient of the objective function given by (6) is Lipschitz continuous with Lipschitz 2 constant L = λmax (K0 ) + nC i. [sent-155, score-0.234]
</p><p>54 for any α1 , α2 ∈ Q1 the following inequality holds f (α1 ) − ρ 2 f (α2 ) ≤ λmax (K0 )) + nC /ρ α1 − α2 . [sent-157, score-0.108]
</p><p>55 Table 1: Pseudo-code of projected gradient method  4  Smooth Optimization Algorithms  This section is based on the theoretical analysis above, mainly Theorem 2. [sent-177, score-0.274]
</p><p>56 We ﬁrst outline a simpliﬁed version of the projected gradient method proposed in [15] and show it has a convergence rate of O(1/k) where k is the iteration number. [sent-178, score-0.366]
</p><p>57 We can further develop a smooth optimization approach [17, 18] for indeﬁnite SVM (5). [sent-179, score-0.222]
</p><p>58 This scheme has an optimal convergence rate O(1/k 2 ) for smooth problems which has been applied to various problems, e. [sent-180, score-0.244]
</p><p>59 1  Simpliﬁed Projected Gradient Method  In [15], the objective function was smoothed by adding a quadratic term (see details in Section 3 there) and then they proposed a projected gradient algorithm to solve this approximation problem. [sent-184, score-0.44]
</p><p>60 Using the explicit gradient representation in Theorem 1 we formulate its simpliﬁed version in Table 1 where the projection PQ1 : Rn → Q1 is deﬁned, for any β ∈ Rn , by PQ1 (β) = arg min α − β α∈Q1  2  . [sent-185, score-0.126]
</p><p>61 Let γ ≥ λmax (K0 ) + nC and {αk : k ∈ N} be given by the simpliﬁed projected ρ gradient method in Table 1. [sent-194, score-0.248]
</p><p>62 For any α ∈ Q1 , the following inequality holds f (αk+1 ) ≥ f (α) + γ αk − αk+1 , α − αk + γ αk − αk+1 2 . [sent-195, score-0.108]
</p><p>63 Let γ ≥ λmax (K0 ) + nC and the iteration sequence {αk : k ∈ N} be given by the ρ simpliﬁed projected gradient method in Table 1. [sent-207, score-0.328]
</p><p>64 Then, we have that γ αk+1 − αk 2 , (12) f (αk+1 ) ≥ f (αk ) + 2 Moreover, γ max f (α) − f (αk ) ≤ α0 − α∗ 2 (13) α∈Q1 2k where α∗ is an optimal solution of problem maxα∈Q1 f (α). [sent-208, score-0.117]
</p><p>65 Table 2: Pseudo-code of ﬁrst-order Nesterov’s smooth optimization method Proof. [sent-222, score-0.248]
</p><p>66 From the above theorem, the sequence {f (αk ) : k ∈ N} is monotonically increasing and the iteration complexity of SPGM is O(L/ε) for ﬁnding an ε-optimal solution. [sent-227, score-0.153]
</p><p>67 2  Nesterov’s Smooth Optimization Method  In [18, 17], Nesterov proposed an efﬁcient smooth optimization method for solving convex programming problems of the form min g(x) x∈U  where g is a convex function with Lipschitz continuous gradient, and U is a closed convex set in Rn . [sent-229, score-0.495]
</p><p>68 The smooth optimization approach needs to introduce a proxy-function d(x) associated with the set U . [sent-231, score-0.274]
</p><p>69 It is assumed to be continuous and strongly convex on U with convexity parameter σ > 0. [sent-232, score-0.119]
</p><p>70 Then, a speciﬁc ﬁrst-order smooth optimization scheme detailed in [18] can be then applied to the function g with convergence rate in O( L/ε). [sent-236, score-0.289]
</p><p>71 Translating the ﬁrst-order Nesterov’s scheme [18, Section 3] to our problem (5), we can get the smooth optimization algorithm for indeﬁnite SVM, see its pseudo-code in Table 2. [sent-240, score-0.251]
</p><p>72 The convergence of this optimal method was shown in [18]: ∗ 2  ∗ maxα∈Q1 f (α) − f (γk ) ≤ 4L α0 −α (k+1)(k+2) where α is one of the optimal solutions. [sent-245, score-0.118]
</p><p>73 In [15], the objective function is smoothed by adding a quadratic term and then they further 6  proposed a projected gradient algorithm and analytic center cutting plane method (ACCPM)1 . [sent-252, score-0.573]
</p><p>74 As proved in Theorem 3, the number of iterations of the projected gradient method is usually O(L/ε). [sent-253, score-0.248]
</p><p>75 However, this method needs to use interior methods at each iteration which would be slow for large scale datasets. [sent-257, score-0.158]
</p><p>76 Chen and Ye [4] reformulated indeﬁnite SVM as an appealing semi-inﬁnite quadratically constrained linear programming (SIQCLP) without applying extra smoothing techniques. [sent-258, score-0.209]
</p><p>77 The iteration complexity of semi-inﬁnite linear programming is usually O(1/ε3 ). [sent-260, score-0.164]
</p><p>78 The main limitation of this approach is that one needs to save the subset of increasing quadratically constrained conditions indexed by n × n matrices and iteratively solve a quadratically constrained linear programming (QCLP). [sent-263, score-0.362]
</p><p>79 This tends to make the algorithm inefﬁcient during the iteration process, although pruning techniques were proposed to avoid too many quadratically constrained conditions. [sent-269, score-0.216]
</p><p>80 Based on our theoretical results (Theorem 2), Nesterov’s smooth optimization method can be applied. [sent-270, score-0.248]
</p><p>81 The complexity of this smooth optimization method (SMM) mainly relies on the eigenvalue decomposition on Step 2 listed in Table 2 which costs O(n3 ). [sent-271, score-0.32]
</p><p>82 The ﬁrst-order smooth optimization approach [17, 18] has iteration complexity O( L/ε) for ﬁnding an ε-optimal solution. [sent-273, score-0.348]
</p><p>83 Hence, from theoretical comparison the complexity of smoothing optimization is better than the simpliﬁed projected gradient method (SPGM) and SIQCLP. [sent-275, score-0.366]
</p><p>84 5 Experimental Validation We run our proposed smooth optimization approach and simpliﬁed projected gradient method on various datasets to validate our analysis. [sent-279, score-0.526]
</p><p>85 In each data split, as in [4] we ﬁrst generate a Gaussian kernel matrix K with the hyper-parameter determined by cross-validation on the training data using LIBSVM and then construct indeﬁnite matrices by adding a small noisy matrix i. [sent-283, score-0.243]
</p><p>86 SIQCLP needs much more time since, in each iteration, it needs to solves a quadratically constrained linear programming. [sent-295, score-0.24]
</p><p>87 In Figure 1, we plot the objective values versus iteration on Sonar and Diabetes for SMM, SPGM, and ACCPM. [sent-296, score-0.178]
</p><p>88 The SIQCLP approach is not included here since its objective value is not based on the iteration w. [sent-297, score-0.178]
</p><p>89 the variable α which does not directly yield an increasing iteration sequence of objective values in contrast to those of the other three algorithms. [sent-300, score-0.178]
</p><p>90 17s  Table 3: Average test set accuracy (%) and CPU time in seconds (s) of different algorithms where λmax (λmin ) denotes the average maximum (minimum) eigenvalues of the indeﬁnite kernel matrix over training samples. [sent-365, score-0.205]
</p><p>91 However, ACCPM needs more time in each iteration than SMM and this observation becomes more apparent for the relatively large datasets shown in the time comparison of Table 3. [sent-374, score-0.159]
</p><p>92 6  Conclusion  In this paper we analyzed the regularization formulation for training SVM with indeﬁnite kernels proposed by Luss and d’Aspremont [15]. [sent-375, score-0.136]
</p><p>93 We show that the objective function of interest is continuously differentiable with Lipschitz continuous gradient. [sent-376, score-0.245]
</p><p>94 Our elementary analysis greatly facilitates the application of gradient-based methods. [sent-377, score-0.101]
</p><p>95 We formulated a simpliﬁed version of the projected gradient method presented in [15] and showed that it has a convergence rate of O(1/k). [sent-378, score-0.286]
</p><p>96 We further developed Nesterov’s smooth optimization method [17, 18] for Indeﬁnite SVM which has an optimal convergence rate of O(1/k 2 ) for smooth problems. [sent-379, score-0.463]
</p><p>97 Experiments on various datasets validate our analysis and the efﬁciency of our proposed optimization approach. [sent-380, score-0.128]
</p><p>98 We are also applying this method to real biological datasets such as protein sequence analysis using sequence alignment measures. [sent-382, score-0.124]
</p><p>99 A study on sigmoid kernels for SVM and the training of non-psd kernels by smo-type methods. [sent-469, score-0.169]
</p><p>100 An analysis of transformation on non-positive semideﬁnite similarity matrix for kernel machines. [sent-550, score-0.181]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('inde', 0.557), ('smm', 0.301), ('spgm', 0.255), ('accpm', 0.232), ('lipschitz', 0.178), ('smooth', 0.15), ('nesterov', 0.145), ('svm', 0.142), ('siqclp', 0.139), ('nc', 0.131), ('projected', 0.124), ('psd', 0.122), ('mink', 0.122), ('luss', 0.116), ('nite', 0.113), ('kernel', 0.106), ('quadratically', 0.102), ('gradient', 0.098), ('objective', 0.098), ('lemma', 0.091), ('max', 0.09), ('ky', 0.087), ('inequality', 0.083), ('aspremont', 0.082), ('iteration', 0.08), ('differentiable', 0.076), ('diabetes', 0.074), ('proxy', 0.073), ('optimization', 0.072), ('saddle', 0.07), ('simpli', 0.07), ('kernels', 0.07), ('qclp', 0.07), ('theorem', 0.064), ('sonar', 0.063), ('convex', 0.057), ('needs', 0.052), ('completes', 0.051), ('eigenvalues', 0.051), ('matrix', 0.048), ('minn', 0.046), ('complexity', 0.046), ('smoothed', 0.043), ('adding', 0.041), ('mosek', 0.041), ('bristol', 0.041), ('differentiability', 0.041), ('worthy', 0.041), ('elementary', 0.04), ('analytic', 0.038), ('programming', 0.038), ('convergence', 0.038), ('continuous', 0.038), ('cutting', 0.037), ('formulation', 0.037), ('noting', 0.037), ('protein', 0.036), ('nn', 0.036), ('quadratic', 0.036), ('establish', 0.035), ('applying', 0.035), ('uniqueness', 0.035), ('diag', 0.034), ('facilitates', 0.034), ('constrained', 0.034), ('continuously', 0.033), ('plane', 0.032), ('kingdom', 0.031), ('attracted', 0.03), ('sigmoid', 0.029), ('validate', 0.029), ('scheme', 0.029), ('regularization', 0.029), ('arg', 0.028), ('ionosphere', 0.028), ('rn', 0.028), ('minimizer', 0.028), ('table', 0.028), ('monotonically', 0.027), ('usps', 0.027), ('indeed', 0.027), ('optimal', 0.027), ('similarity', 0.027), ('greatly', 0.027), ('datasets', 0.027), ('continuity', 0.026), ('method', 0.026), ('consequently', 0.026), ('mainly', 0.026), ('proximity', 0.026), ('cristianini', 0.026), ('accelerate', 0.026), ('diffusion', 0.026), ('optimality', 0.025), ('positive', 0.025), ('cone', 0.025), ('united', 0.025), ('go', 0.025), ('holds', 0.025), ('convexity', 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="33-tfidf-1" href="./nips-2009-Analysis_of_SVM_with_Indefinite_Kernels.html">33 nips-2009-Analysis of SVM with Indefinite Kernels</a></p>
<p>Author: Yiming Ying, Colin Campbell, Mark Girolami</p><p>Abstract: The recent introduction of indeﬁnite SVM by Luss and d’Aspremont [15] has effectively demonstrated SVM classiﬁcation with a non-positive semi-deﬁnite kernel (indeﬁnite kernel). This paper studies the properties of the objective function introduced there. In particular, we show that the objective function is continuously differentiable and its gradient can be explicitly computed. Indeed, we further show that its gradient is Lipschitz continuous. The main idea behind our analysis is that the objective function is smoothed by the penalty term, in its saddle (min-max) representation, measuring the distance between the indeﬁnite kernel matrix and the proxy positive semi-deﬁnite one. Our elementary result greatly facilitates the application of gradient-based algorithms. Based on our analysis, we further develop Nesterov’s smooth optimization approach [17, 18] for indeﬁnite SVM which has an optimal convergence rate for smooth problems. Experiments on various benchmark datasets validate our analysis and demonstrate the efﬁciency of our proposed algorithms.</p><p>2 0.12988304 <a title="33-tfidf-2" href="./nips-2009-Sparse_Metric_Learning_via_Smooth_Optimization.html">223 nips-2009-Sparse Metric Learning via Smooth Optimization</a></p>
<p>Author: Yiming Ying, Kaizhu Huang, Colin Campbell</p><p>Abstract: In this paper we study the problem of learning a low-rank (sparse) distance matrix. We propose a novel metric learning model which can simultaneously conduct dimension reduction and learn a distance matrix. The sparse representation involves a mixed-norm regularization which is non-convex. We then show that it can be equivalently formulated as a convex saddle (min-max) problem. From this saddle representation, we develop an efﬁcient smooth optimization approach [17] for sparse metric learning, although the learning model is based on a nondifferentiable loss function. Finally, we run experiments to validate the effectiveness and efﬁciency of our sparse metric learning model on various datasets.</p><p>3 0.11084911 <a title="33-tfidf-3" href="./nips-2009-Learning_Non-Linear_Combinations_of_Kernels.html">128 nips-2009-Learning Non-Linear Combinations of Kernels</a></p>
<p>Author: Corinna Cortes, Mehryar Mohri, Afshin Rostamizadeh</p><p>Abstract: This paper studies the general problem of learning kernels based on a polynomial combination of base kernels. We analyze this problem in the case of regression and the kernel ridge regression algorithm. We examine the corresponding learning kernel optimization problem, show how that minimax problem can be reduced to a simpler minimization problem, and prove that the global solution of this problem always lies on the boundary. We give a projection-based gradient descent algorithm for solving the optimization problem, shown empirically to converge in few iterations. Finally, we report the results of extensive experiments with this algorithm using several publicly available datasets demonstrating the effectiveness of our technique.</p><p>4 0.084482446 <a title="33-tfidf-4" href="./nips-2009-Information-theoretic_lower_bounds_on_the_oracle_complexity_of_convex_optimization.html">116 nips-2009-Information-theoretic lower bounds on the oracle complexity of convex optimization</a></p>
<p>Author: Alekh Agarwal, Martin J. Wainwright, Peter L. Bartlett, Pradeep K. Ravikumar</p><p>Abstract: Despite a large literature on upper bounds on complexity of convex optimization, relatively less attention has been paid to the fundamental hardness of these problems. Given the extensive use of convex optimization in machine learning and statistics, gaining a understanding of these complexity-theoretic issues is important. In this paper, we study the complexity of stochastic convex optimization in an oracle model of computation. We improve upon known results and obtain tight minimax complexity estimates for various function classes. We also discuss implications of these results for the understanding the inherent complexity of large-scale learning and estimation problems. 1</p><p>5 0.080909893 <a title="33-tfidf-5" href="./nips-2009-Efficient_and_Accurate_Lp-Norm_Multiple_Kernel_Learning.html">80 nips-2009-Efficient and Accurate Lp-Norm Multiple Kernel Learning</a></p>
<p>Author: Marius Kloft, Ulf Brefeld, Pavel Laskov, Klaus-Robert Müller, Alexander Zien, Sören Sonnenburg</p><p>Abstract: Learning linear combinations of multiple kernels is an appealing strategy when the right choice of features is unknown. Previous approaches to multiple kernel learning (MKL) promote sparse kernel combinations to support interpretability. Unfortunately, 1 -norm MKL is hardly observed to outperform trivial baselines in practical applications. To allow for robust kernel mixtures, we generalize MKL to arbitrary p -norms. We devise new insights on the connection between several existing MKL formulations and develop two efﬁcient interleaved optimization strategies for arbitrary p > 1. Empirically, we demonstrate that the interleaved optimization strategies are much faster compared to the traditionally used wrapper approaches. Finally, we apply p -norm MKL to real-world problems from computational biology, showing that non-sparse MKL achieves accuracies that go beyond the state-of-the-art. 1</p><p>6 0.079663701 <a title="33-tfidf-6" href="./nips-2009-Convex_Relaxation_of_Mixture_Regression_with_Efficient_Algorithms.html">61 nips-2009-Convex Relaxation of Mixture Regression with Efficient Algorithms</a></p>
<p>7 0.07850717 <a title="33-tfidf-7" href="./nips-2009-Matrix_Completion_from_Noisy_Entries.html">147 nips-2009-Matrix Completion from Noisy Entries</a></p>
<p>8 0.07547304 <a title="33-tfidf-8" href="./nips-2009-On_the_Algorithmics_and_Applications_of_a_Mixed-norm_based_Kernel_Learning_Formulation.html">179 nips-2009-On the Algorithmics and Applications of a Mixed-norm based Kernel Learning Formulation</a></p>
<p>9 0.07443437 <a title="33-tfidf-9" href="./nips-2009-Kernel_Choice_and_Classifiability_for_RKHS_Embeddings_of_Probability_Distributions.html">118 nips-2009-Kernel Choice and Classifiability for RKHS Embeddings of Probability Distributions</a></p>
<p>10 0.074173242 <a title="33-tfidf-10" href="./nips-2009-Fast_Graph_Laplacian_Regularized_Kernel_Learning_via_Semidefinite%E2%80%93Quadratic%E2%80%93Linear_Programming.html">92 nips-2009-Fast Graph Laplacian Regularized Kernel Learning via Semidefinite–Quadratic–Linear Programming</a></p>
<p>11 0.071992472 <a title="33-tfidf-11" href="./nips-2009-Data-driven_calibration_of_linear_estimators_with_minimal_penalties.html">64 nips-2009-Data-driven calibration of linear estimators with minimal penalties</a></p>
<p>12 0.070427746 <a title="33-tfidf-12" href="./nips-2009-Kernels_and_learning_curves_for_Gaussian_process_regression_on_random_graphs.html">120 nips-2009-Kernels and learning curves for Gaussian process regression on random graphs</a></p>
<p>13 0.068480834 <a title="33-tfidf-13" href="./nips-2009-Kernel_Methods_for_Deep_Learning.html">119 nips-2009-Kernel Methods for Deep Learning</a></p>
<p>14 0.065315291 <a title="33-tfidf-14" href="./nips-2009-Sufficient_Conditions_for_Agnostic_Active_Learnable.html">240 nips-2009-Sufficient Conditions for Agnostic Active Learnable</a></p>
<p>15 0.063547522 <a title="33-tfidf-15" href="./nips-2009-Efficient_Match_Kernel_between_Sets_of_Features_for_Visual_Recognition.html">77 nips-2009-Efficient Match Kernel between Sets of Features for Visual Recognition</a></p>
<p>16 0.060785931 <a title="33-tfidf-16" href="./nips-2009-Fast_subtree_kernels_on_graphs.html">95 nips-2009-Fast subtree kernels on graphs</a></p>
<p>17 0.060762402 <a title="33-tfidf-17" href="./nips-2009-Efficient_Recovery_of_Jointly_Sparse_Vectors.html">79 nips-2009-Efficient Recovery of Jointly Sparse Vectors</a></p>
<p>18 0.060420349 <a title="33-tfidf-18" href="./nips-2009-Multiple_Incremental_Decremental_Learning_of_Support_Vector_Machines.html">160 nips-2009-Multiple Incremental Decremental Learning of Support Vector Machines</a></p>
<p>19 0.05829227 <a title="33-tfidf-19" href="./nips-2009-Distribution_Matching_for_Transduction.html">72 nips-2009-Distribution Matching for Transduction</a></p>
<p>20 0.058154311 <a title="33-tfidf-20" href="./nips-2009-Sparse_and_Locally_Constant_Gaussian_Graphical_Models.html">224 nips-2009-Sparse and Locally Constant Gaussian Graphical Models</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.179), (1, 0.155), (2, -0.022), (3, 0.082), (4, -0.045), (5, -0.027), (6, 0.01), (7, 0.075), (8, -0.011), (9, 0.032), (10, 0.1), (11, -0.072), (12, 0.027), (13, 0.057), (14, -0.095), (15, -0.056), (16, -0.009), (17, -0.034), (18, -0.076), (19, -0.007), (20, -0.012), (21, -0.057), (22, 0.019), (23, 0.021), (24, -0.059), (25, -0.038), (26, -0.006), (27, -0.072), (28, 0.065), (29, 0.005), (30, 0.014), (31, -0.054), (32, -0.005), (33, 0.024), (34, -0.025), (35, 0.008), (36, -0.027), (37, -0.066), (38, -0.009), (39, 0.061), (40, -0.045), (41, -0.039), (42, -0.102), (43, -0.024), (44, -0.058), (45, 0.045), (46, -0.03), (47, -0.038), (48, -0.088), (49, -0.015)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95195973 <a title="33-lsi-1" href="./nips-2009-Analysis_of_SVM_with_Indefinite_Kernels.html">33 nips-2009-Analysis of SVM with Indefinite Kernels</a></p>
<p>Author: Yiming Ying, Colin Campbell, Mark Girolami</p><p>Abstract: The recent introduction of indeﬁnite SVM by Luss and d’Aspremont [15] has effectively demonstrated SVM classiﬁcation with a non-positive semi-deﬁnite kernel (indeﬁnite kernel). This paper studies the properties of the objective function introduced there. In particular, we show that the objective function is continuously differentiable and its gradient can be explicitly computed. Indeed, we further show that its gradient is Lipschitz continuous. The main idea behind our analysis is that the objective function is smoothed by the penalty term, in its saddle (min-max) representation, measuring the distance between the indeﬁnite kernel matrix and the proxy positive semi-deﬁnite one. Our elementary result greatly facilitates the application of gradient-based algorithms. Based on our analysis, we further develop Nesterov’s smooth optimization approach [17, 18] for indeﬁnite SVM which has an optimal convergence rate for smooth problems. Experiments on various benchmark datasets validate our analysis and demonstrate the efﬁciency of our proposed algorithms.</p><p>2 0.73103207 <a title="33-lsi-2" href="./nips-2009-Fast_Graph_Laplacian_Regularized_Kernel_Learning_via_Semidefinite%E2%80%93Quadratic%E2%80%93Linear_Programming.html">92 nips-2009-Fast Graph Laplacian Regularized Kernel Learning via Semidefinite–Quadratic–Linear Programming</a></p>
<p>Author: Xiao-ming Wu, Anthony M. So, Zhenguo Li, Shuo-yen R. Li</p><p>Abstract: Kernel learning is a powerful framework for nonlinear data modeling. Using the kernel trick, a number of problems have been formulated as semideﬁnite programs (SDPs). These include Maximum Variance Unfolding (MVU) (Weinberger et al., 2004) in nonlinear dimensionality reduction, and Pairwise Constraint Propagation (PCP) (Li et al., 2008) in constrained clustering. Although in theory SDPs can be efﬁciently solved, the high computational complexity incurred in numerically processing the huge linear matrix inequality constraints has rendered the SDP approach unscalable. In this paper, we show that a large class of kernel learning problems can be reformulated as semideﬁnite-quadratic-linear programs (SQLPs), which only contain a simple positive semideﬁnite constraint, a second-order cone constraint and a number of linear constraints. These constraints are much easier to process numerically, and the gain in speedup over previous approaches is at least of the order m2.5 , where m is the matrix dimension. Experimental results are also presented to show the superb computational efﬁciency of our approach.</p><p>3 0.66526377 <a title="33-lsi-3" href="./nips-2009-Efficient_Recovery_of_Jointly_Sparse_Vectors.html">79 nips-2009-Efficient Recovery of Jointly Sparse Vectors</a></p>
<p>Author: Liang Sun, Jun Liu, Jianhui Chen, Jieping Ye</p><p>Abstract: We consider the reconstruction of sparse signals in the multiple measurement vector (MMV) model, in which the signal, represented as a matrix, consists of a set of jointly sparse vectors. MMV is an extension of the single measurement vector (SMV) model employed in standard compressive sensing (CS). Recent theoretical studies focus on the convex relaxation of the MMV problem based on the (2, 1)-norm minimization, which is an extension of the well-known 1-norm minimization employed in SMV. However, the resulting convex optimization problem in MMV is signiﬁcantly much more difﬁcult to solve than the one in SMV. Existing algorithms reformulate it as a second-order cone programming (SOCP) or semideﬁnite programming (SDP) problem, which is computationally expensive to solve for problems of moderate size. In this paper, we propose a new (dual) reformulation of the convex optimization problem in MMV and develop an efﬁcient algorithm based on the prox-method. Interestingly, our theoretical analysis reveals the close connection between the proposed reformulation and multiple kernel learning. Our simulation studies demonstrate the scalability of the proposed algorithm.</p><p>4 0.65311468 <a title="33-lsi-4" href="./nips-2009-Learning_Non-Linear_Combinations_of_Kernels.html">128 nips-2009-Learning Non-Linear Combinations of Kernels</a></p>
<p>Author: Corinna Cortes, Mehryar Mohri, Afshin Rostamizadeh</p><p>Abstract: This paper studies the general problem of learning kernels based on a polynomial combination of base kernels. We analyze this problem in the case of regression and the kernel ridge regression algorithm. We examine the corresponding learning kernel optimization problem, show how that minimax problem can be reduced to a simpler minimization problem, and prove that the global solution of this problem always lies on the boundary. We give a projection-based gradient descent algorithm for solving the optimization problem, shown empirically to converge in few iterations. Finally, we report the results of extensive experiments with this algorithm using several publicly available datasets demonstrating the effectiveness of our technique.</p><p>5 0.63895261 <a title="33-lsi-5" href="./nips-2009-Sparse_Metric_Learning_via_Smooth_Optimization.html">223 nips-2009-Sparse Metric Learning via Smooth Optimization</a></p>
<p>Author: Yiming Ying, Kaizhu Huang, Colin Campbell</p><p>Abstract: In this paper we study the problem of learning a low-rank (sparse) distance matrix. We propose a novel metric learning model which can simultaneously conduct dimension reduction and learn a distance matrix. The sparse representation involves a mixed-norm regularization which is non-convex. We then show that it can be equivalently formulated as a convex saddle (min-max) problem. From this saddle representation, we develop an efﬁcient smooth optimization approach [17] for sparse metric learning, although the learning model is based on a nondifferentiable loss function. Finally, we run experiments to validate the effectiveness and efﬁciency of our sparse metric learning model on various datasets.</p><p>6 0.63606673 <a title="33-lsi-6" href="./nips-2009-On_the_Convergence_of_the_Concave-Convex_Procedure.html">180 nips-2009-On the Convergence of the Concave-Convex Procedure</a></p>
<p>7 0.61094987 <a title="33-lsi-7" href="./nips-2009-Efficient_and_Accurate_Lp-Norm_Multiple_Kernel_Learning.html">80 nips-2009-Efficient and Accurate Lp-Norm Multiple Kernel Learning</a></p>
<p>8 0.60147965 <a title="33-lsi-8" href="./nips-2009-Dual_Averaging_Method_for_Regularized_Stochastic_Learning_and_Online_Optimization.html">73 nips-2009-Dual Averaging Method for Regularized Stochastic Learning and Online Optimization</a></p>
<p>9 0.57888532 <a title="33-lsi-9" href="./nips-2009-Positive_Semidefinite_Metric_Learning_with_Boosting.html">191 nips-2009-Positive Semidefinite Metric Learning with Boosting</a></p>
<p>10 0.5742656 <a title="33-lsi-10" href="./nips-2009-Matrix_Completion_from_Noisy_Entries.html">147 nips-2009-Matrix Completion from Noisy Entries</a></p>
<p>11 0.56507427 <a title="33-lsi-11" href="./nips-2009-Efficient_Learning_using_Forward-Backward_Splitting.html">76 nips-2009-Efficient Learning using Forward-Backward Splitting</a></p>
<p>12 0.56449354 <a title="33-lsi-12" href="./nips-2009-Periodic_Step_Size_Adaptation_for_Single_Pass_On-line_Learning.html">189 nips-2009-Periodic Step Size Adaptation for Single Pass On-line Learning</a></p>
<p>13 0.5566209 <a title="33-lsi-13" href="./nips-2009-Multiple_Incremental_Decremental_Learning_of_Support_Vector_Machines.html">160 nips-2009-Multiple Incremental Decremental Learning of Support Vector Machines</a></p>
<p>14 0.54925048 <a title="33-lsi-14" href="./nips-2009-On_the_Algorithmics_and_Applications_of_a_Mixed-norm_based_Kernel_Learning_Formulation.html">179 nips-2009-On the Algorithmics and Applications of a Mixed-norm based Kernel Learning Formulation</a></p>
<p>15 0.53803521 <a title="33-lsi-15" href="./nips-2009-Kernel_Choice_and_Classifiability_for_RKHS_Embeddings_of_Probability_Distributions.html">118 nips-2009-Kernel Choice and Classifiability for RKHS Embeddings of Probability Distributions</a></p>
<p>16 0.52448618 <a title="33-lsi-16" href="./nips-2009-Convex_Relaxation_of_Mixture_Regression_with_Efficient_Algorithms.html">61 nips-2009-Convex Relaxation of Mixture Regression with Efficient Algorithms</a></p>
<p>17 0.5190649 <a title="33-lsi-17" href="./nips-2009-Distribution_Matching_for_Transduction.html">72 nips-2009-Distribution Matching for Transduction</a></p>
<p>18 0.51818192 <a title="33-lsi-18" href="./nips-2009-Information-theoretic_lower_bounds_on_the_oracle_complexity_of_convex_optimization.html">116 nips-2009-Information-theoretic lower bounds on the oracle complexity of convex optimization</a></p>
<p>19 0.50717366 <a title="33-lsi-19" href="./nips-2009-Robust_Principal_Component_Analysis%3A_Exact_Recovery_of_Corrupted_Low-Rank_Matrices_via_Convex_Optimization.html">208 nips-2009-Robust Principal Component Analysis: Exact Recovery of Corrupted Low-Rank Matrices via Convex Optimization</a></p>
<p>20 0.50670981 <a title="33-lsi-20" href="./nips-2009-An_Integer_Projected_Fixed_Point_Method_for_Graph_Matching_and_MAP_Inference.html">30 nips-2009-An Integer Projected Fixed Point Method for Graph Matching and MAP Inference</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(7, 0.011), (24, 0.062), (25, 0.062), (35, 0.044), (36, 0.098), (39, 0.032), (58, 0.112), (61, 0.369), (71, 0.024), (86, 0.1)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.90500981 <a title="33-lda-1" href="./nips-2009-Differential_Use_of_Implicit_Negative_Evidence_in_Generative_and_Discriminative_Language_Learning.html">66 nips-2009-Differential Use of Implicit Negative Evidence in Generative and Discriminative Language Learning</a></p>
<p>Author: Anne Hsu, Thomas L. Griffiths</p><p>Abstract: A classic debate in cognitive science revolves around understanding how children learn complex linguistic rules, such as those governing restrictions on verb alternations, without negative evidence. Traditionally, formal learnability arguments have been used to claim that such learning is impossible without the aid of innate language-speciﬁc knowledge. However, recently, researchers have shown that statistical models are capable of learning complex rules from only positive evidence. These two kinds of learnability analyses differ in their assumptions about the distribution from which linguistic input is generated. The former analyses assume that learners seek to identify grammatical sentences in a way that is robust to the distribution from which the sentences are generated, analogous to discriminative approaches in machine learning. The latter assume that learners are trying to estimate a generative model, with sentences being sampled from that model. We show that these two learning approaches differ in their use of implicit negative evidence – the absence of a sentence – when learning verb alternations, and demonstrate that human learners can produce results consistent with the predictions of both approaches, depending on how the learning problem is presented. 1</p><p>2 0.87746239 <a title="33-lda-2" href="./nips-2009-The_Infinite_Partially_Observable_Markov_Decision_Process.html">242 nips-2009-The Infinite Partially Observable Markov Decision Process</a></p>
<p>Author: Finale Doshi-velez</p><p>Abstract: The Partially Observable Markov Decision Process (POMDP) framework has proven useful in planning domains where agents must balance actions that provide knowledge and actions that provide reward. Unfortunately, most POMDPs are complex structures with a large number of parameters. In many real-world problems, both the structure and the parameters are difﬁcult to specify from domain knowledge alone. Recent work in Bayesian reinforcement learning has made headway in learning POMDP models; however, this work has largely focused on learning the parameters of the POMDP model. We deﬁne an inﬁnite POMDP (iPOMDP) model that does not require knowledge of the size of the state space; instead, it assumes that the number of visited states will grow as the agent explores its world and only models visited states explicitly. We demonstrate the iPOMDP on several standard problems. 1</p><p>3 0.87559336 <a title="33-lda-3" href="./nips-2009-Convergent_Temporal-Difference_Learning_with_Arbitrary_Smooth_Function_Approximation.html">60 nips-2009-Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation</a></p>
<p>Author: Shalabh Bhatnagar, Doina Precup, David Silver, Richard S. Sutton, Hamid R. Maei, Csaba Szepesvári</p><p>Abstract: We introduce the ﬁrst temporal-difference learning algorithms that converge with smooth value function approximators, such as neural networks. Conventional temporal-difference (TD) methods, such as TD(λ), Q-learning and Sarsa have been used successfully with function approximation in many applications. However, it is well known that off-policy sampling, as well as nonlinear function approximation, can cause these algorithms to become unstable (i.e., the parameters of the approximator may diverge). Sutton et al. (2009a, 2009b) solved the problem of off-policy learning with linear TD algorithms by introducing a new objective function, related to the Bellman error, and algorithms that perform stochastic gradient-descent on this function. These methods can be viewed as natural generalizations to previous TD methods, as they converge to the same limit points when used with linear function approximation methods. We generalize this work to nonlinear function approximation. We present a Bellman error objective function and two gradient-descent TD algorithms that optimize it. We prove the asymptotic almost-sure convergence of both algorithms, for any ﬁnite Markov decision process and any smooth value function approximator, to a locally optimal solution. The algorithms are incremental and the computational complexity per time step scales linearly with the number of parameters of the approximator. Empirical results obtained in the game of Go demonstrate the algorithms’ effectiveness. 1</p><p>4 0.83717757 <a title="33-lda-4" href="./nips-2009-Data-driven_calibration_of_linear_estimators_with_minimal_penalties.html">64 nips-2009-Data-driven calibration of linear estimators with minimal penalties</a></p>
<p>Author: Sylvain Arlot, Francis R. Bach</p><p>Abstract: This paper tackles the problem of selecting among several linear estimators in non-parametric regression; this includes model selection for linear regression, the choice of a regularization parameter in kernel ridge regression or spline smoothing, and the choice of a kernel in multiple kernel learning. We propose a new algorithm which ﬁrst estimates consistently the variance of the noise, based upon the concept of minimal penalty which was previously introduced in the context of model selection. Then, plugging our variance estimate in Mallows’ CL penalty is proved to lead to an algorithm satisfying an oracle inequality. Simulation experiments with kernel ridge regression and multiple kernel learning show that the proposed algorithm often improves signiﬁcantly existing calibration procedures such as 10-fold cross-validation or generalized cross-validation. 1</p><p>same-paper 5 0.82017618 <a title="33-lda-5" href="./nips-2009-Analysis_of_SVM_with_Indefinite_Kernels.html">33 nips-2009-Analysis of SVM with Indefinite Kernels</a></p>
<p>Author: Yiming Ying, Colin Campbell, Mark Girolami</p><p>Abstract: The recent introduction of indeﬁnite SVM by Luss and d’Aspremont [15] has effectively demonstrated SVM classiﬁcation with a non-positive semi-deﬁnite kernel (indeﬁnite kernel). This paper studies the properties of the objective function introduced there. In particular, we show that the objective function is continuously differentiable and its gradient can be explicitly computed. Indeed, we further show that its gradient is Lipschitz continuous. The main idea behind our analysis is that the objective function is smoothed by the penalty term, in its saddle (min-max) representation, measuring the distance between the indeﬁnite kernel matrix and the proxy positive semi-deﬁnite one. Our elementary result greatly facilitates the application of gradient-based algorithms. Based on our analysis, we further develop Nesterov’s smooth optimization approach [17, 18] for indeﬁnite SVM which has an optimal convergence rate for smooth problems. Experiments on various benchmark datasets validate our analysis and demonstrate the efﬁciency of our proposed algorithms.</p><p>6 0.70233601 <a title="33-lda-6" href="./nips-2009-Multi-Step_Dyna_Planning_for_Policy_Evaluation_and_Control.html">159 nips-2009-Multi-Step Dyna Planning for Policy Evaluation and Control</a></p>
<p>7 0.65605277 <a title="33-lda-7" href="./nips-2009-Learning_to_Explore_and_Exploit_in_POMDPs.html">134 nips-2009-Learning to Explore and Exploit in POMDPs</a></p>
<p>8 0.61980224 <a title="33-lda-8" href="./nips-2009-Skill_Discovery_in_Continuous_Reinforcement_Learning_Domains_using_Skill_Chaining.html">218 nips-2009-Skill Discovery in Continuous Reinforcement Learning Domains using Skill Chaining</a></p>
<p>9 0.60842258 <a title="33-lda-9" href="./nips-2009-Help_or_Hinder%3A_Bayesian_Models_of_Social_Goal_Inference.html">107 nips-2009-Help or Hinder: Bayesian Models of Social Goal Inference</a></p>
<p>10 0.60480559 <a title="33-lda-10" href="./nips-2009-A_Generalized_Natural_Actor-Critic_Algorithm.html">12 nips-2009-A Generalized Natural Actor-Critic Algorithm</a></p>
<p>11 0.60386741 <a title="33-lda-11" href="./nips-2009-Training_Factor_Graphs_with_Reinforcement_Learning_for_Efficient_MAP_Inference.html">250 nips-2009-Training Factor Graphs with Reinforcement Learning for Efficient MAP Inference</a></p>
<p>12 0.60137254 <a title="33-lda-12" href="./nips-2009-Asymptotically_Optimal_Regularization_in_Smooth_Parametric_Models.html">37 nips-2009-Asymptotically Optimal Regularization in Smooth Parametric Models</a></p>
<p>13 0.59189188 <a title="33-lda-13" href="./nips-2009-Improving_Existing_Fault_Recovery_Policies.html">113 nips-2009-Improving Existing Fault Recovery Policies</a></p>
<p>14 0.58467364 <a title="33-lda-14" href="./nips-2009-Manifold_Embeddings_for_Model-Based_Reinforcement_Learning_under_Partial_Observability.html">145 nips-2009-Manifold Embeddings for Model-Based Reinforcement Learning under Partial Observability</a></p>
<p>15 0.56781328 <a title="33-lda-15" href="./nips-2009-Accelerated_Gradient_Methods_for_Stochastic_Optimization_and_Online_Learning.html">22 nips-2009-Accelerated Gradient Methods for Stochastic Optimization and Online Learning</a></p>
<p>16 0.56636465 <a title="33-lda-16" href="./nips-2009-Robust_Nonparametric_Regression_with_Metric-Space_Valued_Output.html">207 nips-2009-Robust Nonparametric Regression with Metric-Space Valued Output</a></p>
<p>17 0.56520659 <a title="33-lda-17" href="./nips-2009-Sensitivity_analysis_in_HMMs_with_application_to_likelihood_maximization.html">215 nips-2009-Sensitivity analysis in HMMs with application to likelihood maximization</a></p>
<p>18 0.55869734 <a title="33-lda-18" href="./nips-2009-Asymptotic_Analysis_of_MAP_Estimation_via_the_Replica_Method_and_Compressed_Sensing.html">36 nips-2009-Asymptotic Analysis of MAP Estimation via the Replica Method and Compressed Sensing</a></p>
<p>19 0.5520969 <a title="33-lda-19" href="./nips-2009-Bootstrapping_from_Game_Tree_Search.html">48 nips-2009-Bootstrapping from Game Tree Search</a></p>
<p>20 0.54603797 <a title="33-lda-20" href="./nips-2009-Fast%2C_smooth_and_adaptive_regression_in_metric_spaces.html">91 nips-2009-Fast, smooth and adaptive regression in metric spaces</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
