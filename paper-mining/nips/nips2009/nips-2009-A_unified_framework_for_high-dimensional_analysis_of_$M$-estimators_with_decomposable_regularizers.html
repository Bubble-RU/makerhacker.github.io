<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>20 nips-2009-A unified framework for high-dimensional analysis of $M$-estimators with decomposable regularizers</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-20" href="#">nips2009-20</a> knowledge-graph by maker-knowledge-mining</p><h1>20 nips-2009-A unified framework for high-dimensional analysis of $M$-estimators with decomposable regularizers</h1>
<br/><p>Source: <a title="nips-2009-20-pdf" href="http://papers.nips.cc/paper/3765-a-unified-framework-for-high-dimensional-analysis-of-m-estimators-with-decomposable-regularizers.pdf">pdf</a></p><p>Author: Sahand Negahban, Bin Yu, Martin J. Wainwright, Pradeep K. Ravikumar</p><p>Abstract: High-dimensional statistical inference deals with models in which the the number of parameters p is comparable to or larger than the sample size n. Since it is usually impossible to obtain consistent procedures unless p/n → 0, a line of recent work has studied models with various types of structure (e.g., sparse vectors; block-structured matrices; low-rank matrices; Markov assumptions). In such settings, a general approach to estimation is to solve a regularized convex program (known as a regularized M -estimator) which combines a loss function (measuring how well the model ﬁts the data) with some regularization function that encourages the assumed structure. The goal of this paper is to provide a uniﬁed framework for establishing consistency and convergence rates for such regularized M estimators under high-dimensional scaling. We state one main theorem and show how it can be used to re-derive several existing results, and also to obtain several new results on consistency and convergence rates. Our analysis also identiﬁes two key properties of loss and regularization functions, referred to as restricted strong convexity and decomposability, that ensure the corresponding regularized M -estimators have fast convergence rates. 1</p><p>Reference: <a title="nips-2009-20-reference" href="../nips2009_reference/nips-2009-A_unified_framework_for_high-dimensional_analysis_of_%24M%24-estimators_with_decomposable_regularizers_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('rp', 0.47), ('subspac', 0.339), ('rsc', 0.247), ('regul', 0.231), ('lasso', 0.203), ('rq', 0.2), ('rk', 0.198), ('raskutt', 0.18), ('decompos', 0.173), ('nuclear', 0.146), ('spars', 0.124), ('corol', 0.12), ('loss', 0.117), ('collect', 0.109), ('sm', 0.097), ('sat', 0.095), ('regress', 0.094), ('convex', 0.091), ('bickel', 0.089), ('suppos', 0.087)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999952 <a title="20-tfidf-1" href="./nips-2009-A_unified_framework_for_high-dimensional_analysis_of_%24M%24-estimators_with_decomposable_regularizers.html">20 nips-2009-A unified framework for high-dimensional analysis of $M$-estimators with decomposable regularizers</a></p>
<p>2 0.2745094 <a title="20-tfidf-2" href="./nips-2009-Thresholding_Procedures_for_High_Dimensional_Variable_Selection_and_Statistical_Estimation.html">245 nips-2009-Thresholding Procedures for High Dimensional Variable Selection and Statistical Estimation</a></p>
<p>3 0.21381007 <a title="20-tfidf-3" href="./nips-2009-Lower_bounds_on_minimax_rates_for_nonparametric_regression_with_additive_sparsity_and_smoothness.html">144 nips-2009-Lower bounds on minimax rates for nonparametric regression with additive sparsity and smoothness</a></p>
<p>4 0.1748876 <a title="20-tfidf-4" href="./nips-2009-Sparsistent_Learning_of_Varying-coefficient_Models_with_Structural_Changes.html">225 nips-2009-Sparsistent Learning of Varying-coefficient Models with Structural Changes</a></p>
<p>5 0.16216224 <a title="20-tfidf-5" href="./nips-2009-Sparse_and_Locally_Constant_Gaussian_Graphical_Models.html">224 nips-2009-Sparse and Locally Constant Gaussian Graphical Models</a></p>
<p>6 0.15347031 <a title="20-tfidf-6" href="./nips-2009-Matrix_Completion_from_Noisy_Entries.html">147 nips-2009-Matrix Completion from Noisy Entries</a></p>
<p>7 0.14972083 <a title="20-tfidf-7" href="./nips-2009-Robust_Principal_Component_Analysis%3A_Exact_Recovery_of_Corrupted_Low-Rank_Matrices_via_Convex_Optimization.html">208 nips-2009-Robust Principal Component Analysis: Exact Recovery of Corrupted Low-Rank Matrices via Convex Optimization</a></p>
<p>8 0.14044237 <a title="20-tfidf-8" href="./nips-2009-Submanifold_density_estimation.html">238 nips-2009-Submanifold density estimation</a></p>
<p>9 0.13051577 <a title="20-tfidf-9" href="./nips-2009-Semi-supervised_Regression_using_Hessian_energy_with_an_application_to_semi-supervised_dimensionality_reduction.html">214 nips-2009-Semi-supervised Regression using Hessian energy with an application to semi-supervised dimensionality reduction</a></p>
<p>10 0.12956209 <a title="20-tfidf-10" href="./nips-2009-Multi-Label_Prediction_via_Compressed_Sensing.html">157 nips-2009-Multi-Label Prediction via Compressed Sensing</a></p>
<p>11 0.11254627 <a title="20-tfidf-11" href="./nips-2009-Data-driven_calibration_of_linear_estimators_with_minimal_penalties.html">64 nips-2009-Data-driven calibration of linear estimators with minimal penalties</a></p>
<p>12 0.11026917 <a title="20-tfidf-12" href="./nips-2009-Sparse_Estimation_Using_General_Likelihoods_and_Non-Factorial_Priors.html">222 nips-2009-Sparse Estimation Using General Likelihoods and Non-Factorial Priors</a></p>
<p>13 0.10700832 <a title="20-tfidf-13" href="./nips-2009-Compressed_Least-Squares_Regression.html">55 nips-2009-Compressed Least-Squares Regression</a></p>
<p>14 0.10395355 <a title="20-tfidf-14" href="./nips-2009-Asymptotically_Optimal_Regularization_in_Smooth_Parametric_Models.html">37 nips-2009-Asymptotically Optimal Regularization in Smooth Parametric Models</a></p>
<p>15 0.09958981 <a title="20-tfidf-15" href="./nips-2009-Orthogonal_Matching_Pursuit_From_Noisy_Random_Measurements%3A_A_New_Analysis.html">185 nips-2009-Orthogonal Matching Pursuit From Noisy Random Measurements: A New Analysis</a></p>
<p>16 0.094518058 <a title="20-tfidf-16" href="./nips-2009-Information-theoretic_lower_bounds_on_the_oracle_complexity_of_convex_optimization.html">116 nips-2009-Information-theoretic lower bounds on the oracle complexity of convex optimization</a></p>
<p>17 0.092437744 <a title="20-tfidf-17" href="./nips-2009-Nonparametric_Greedy_Algorithms_for_the_Sparse_Learning_Problem.html">173 nips-2009-Nonparametric Greedy Algorithms for the Sparse Learning Problem</a></p>
<p>18 0.091448158 <a title="20-tfidf-18" href="./nips-2009-From_PAC-Bayes_Bounds_to_KL_Regularization.html">98 nips-2009-From PAC-Bayes Bounds to KL Regularization</a></p>
<p>19 0.088643864 <a title="20-tfidf-19" href="./nips-2009-Directed_Regression.html">67 nips-2009-Directed Regression</a></p>
<p>20 0.086515598 <a title="20-tfidf-20" href="./nips-2009-Semi-supervised_Learning_using_Sparse_Eigenfunction_Bases.html">213 nips-2009-Semi-supervised Learning using Sparse Eigenfunction Bases</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.273), (1, 0.124), (2, 0.105), (3, -0.174), (4, -0.022), (5, 0.051), (6, -0.053), (7, -0.293), (8, -0.049), (9, -0.105), (10, 0.066), (11, 0.055), (12, -0.051), (13, 0.039), (14, -0.037), (15, -0.036), (16, 0.085), (17, -0.043), (18, -0.026), (19, 0.073), (20, -0.003), (21, 0.042), (22, -0.039), (23, 0.122), (24, -0.11), (25, 0.07), (26, 0.022), (27, 0.051), (28, 0.059), (29, -0.019), (30, 0.05), (31, -0.004), (32, 0.027), (33, 0.134), (34, 0.034), (35, -0.076), (36, 0.052), (37, -0.034), (38, 0.001), (39, 0.031), (40, -0.04), (41, -0.007), (42, -0.008), (43, 0.062), (44, -0.045), (45, -0.049), (46, -0.105), (47, -0.019), (48, -0.049), (49, 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95494562 <a title="20-lsi-1" href="./nips-2009-A_unified_framework_for_high-dimensional_analysis_of_%24M%24-estimators_with_decomposable_regularizers.html">20 nips-2009-A unified framework for high-dimensional analysis of $M$-estimators with decomposable regularizers</a></p>
<p>2 0.84050292 <a title="20-lsi-2" href="./nips-2009-Thresholding_Procedures_for_High_Dimensional_Variable_Selection_and_Statistical_Estimation.html">245 nips-2009-Thresholding Procedures for High Dimensional Variable Selection and Statistical Estimation</a></p>
<p>3 0.78582168 <a title="20-lsi-3" href="./nips-2009-Nonparametric_Greedy_Algorithms_for_the_Sparse_Learning_Problem.html">173 nips-2009-Nonparametric Greedy Algorithms for the Sparse Learning Problem</a></p>
<p>4 0.77804619 <a title="20-lsi-4" href="./nips-2009-Lower_bounds_on_minimax_rates_for_nonparametric_regression_with_additive_sparsity_and_smoothness.html">144 nips-2009-Lower bounds on minimax rates for nonparametric regression with additive sparsity and smoothness</a></p>
<p>5 0.75823867 <a title="20-lsi-5" href="./nips-2009-Grouped_Orthogonal_Matching_Pursuit_for_Variable_Selection_and_Prediction.html">105 nips-2009-Grouped Orthogonal Matching Pursuit for Variable Selection and Prediction</a></p>
<p>6 0.72660917 <a title="20-lsi-6" href="./nips-2009-Orthogonal_Matching_Pursuit_From_Noisy_Random_Measurements%3A_A_New_Analysis.html">185 nips-2009-Orthogonal Matching Pursuit From Noisy Random Measurements: A New Analysis</a></p>
<p>7 0.70000291 <a title="20-lsi-7" href="./nips-2009-Sparsistent_Learning_of_Varying-coefficient_Models_with_Structural_Changes.html">225 nips-2009-Sparsistent Learning of Varying-coefficient Models with Structural Changes</a></p>
<p>8 0.68856591 <a title="20-lsi-8" href="./nips-2009-Sparse_Estimation_Using_General_Likelihoods_and_Non-Factorial_Priors.html">222 nips-2009-Sparse Estimation Using General Likelihoods and Non-Factorial Priors</a></p>
<p>9 0.65101773 <a title="20-lsi-9" href="./nips-2009-Sparse_and_Locally_Constant_Gaussian_Graphical_Models.html">224 nips-2009-Sparse and Locally Constant Gaussian Graphical Models</a></p>
<p>10 0.64927882 <a title="20-lsi-10" href="./nips-2009-Submanifold_density_estimation.html">238 nips-2009-Submanifold density estimation</a></p>
<p>11 0.63835686 <a title="20-lsi-11" href="./nips-2009-Matrix_Completion_from_Noisy_Entries.html">147 nips-2009-Matrix Completion from Noisy Entries</a></p>
<p>12 0.62942421 <a title="20-lsi-12" href="./nips-2009-Heterogeneous_multitask_learning_with_joint_sparsity_constraints.html">108 nips-2009-Heterogeneous multitask learning with joint sparsity constraints</a></p>
<p>13 0.60327095 <a title="20-lsi-13" href="./nips-2009-Asymptotic_Analysis_of_MAP_Estimation_via_the_Replica_Method_and_Compressed_Sensing.html">36 nips-2009-Asymptotic Analysis of MAP Estimation via the Replica Method and Compressed Sensing</a></p>
<p>14 0.59690845 <a title="20-lsi-14" href="./nips-2009-Compressed_Least-Squares_Regression.html">55 nips-2009-Compressed Least-Squares Regression</a></p>
<p>15 0.58210659 <a title="20-lsi-15" href="./nips-2009-Robust_Nonparametric_Regression_with_Metric-Space_Valued_Output.html">207 nips-2009-Robust Nonparametric Regression with Metric-Space Valued Output</a></p>
<p>16 0.58167672 <a title="20-lsi-16" href="./nips-2009-Robust_Principal_Component_Analysis%3A_Exact_Recovery_of_Corrupted_Low-Rank_Matrices_via_Convex_Optimization.html">208 nips-2009-Robust Principal Component Analysis: Exact Recovery of Corrupted Low-Rank Matrices via Convex Optimization</a></p>
<p>17 0.56503659 <a title="20-lsi-17" href="./nips-2009-Data-driven_calibration_of_linear_estimators_with_minimal_penalties.html">64 nips-2009-Data-driven calibration of linear estimators with minimal penalties</a></p>
<p>18 0.56442869 <a title="20-lsi-18" href="./nips-2009-Directed_Regression.html">67 nips-2009-Directed Regression</a></p>
<p>19 0.56103867 <a title="20-lsi-19" href="./nips-2009-Fast_Learning_from_Non-i.i.d._Observations.html">94 nips-2009-Fast Learning from Non-i.i.d. Observations</a></p>
<p>20 0.55761713 <a title="20-lsi-20" href="./nips-2009-Information-theoretic_lower_bounds_on_the_oracle_complexity_of_convex_optimization.html">116 nips-2009-Information-theoretic lower bounds on the oracle complexity of convex optimization</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(9, 0.411), (11, 0.023), (17, 0.02), (30, 0.131), (31, 0.134), (60, 0.061), (89, 0.062), (96, 0.064)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.98840058 <a title="20-lda-1" href="./nips-2009-Indian_Buffet_Processes_with_Power-law_Behavior.html">114 nips-2009-Indian Buffet Processes with Power-law Behavior</a></p>
<p>2 0.97808063 <a title="20-lda-2" href="./nips-2009-Exponential_Family_Graph_Matching_and_Ranking.html">87 nips-2009-Exponential Family Graph Matching and Ranking</a></p>
<p>3 0.97329229 <a title="20-lda-3" href="./nips-2009-Differential_Use_of_Implicit_Negative_Evidence_in_Generative_and_Discriminative_Language_Learning.html">66 nips-2009-Differential Use of Implicit Negative Evidence in Generative and Discriminative Language Learning</a></p>
<p>same-paper 4 0.96276242 <a title="20-lda-4" href="./nips-2009-A_unified_framework_for_high-dimensional_analysis_of_%24M%24-estimators_with_decomposable_regularizers.html">20 nips-2009-A unified framework for high-dimensional analysis of $M$-estimators with decomposable regularizers</a></p>
<p>5 0.9535104 <a title="20-lda-5" href="./nips-2009-Robust_Principal_Component_Analysis%3A_Exact_Recovery_of_Corrupted_Low-Rank_Matrices_via_Convex_Optimization.html">208 nips-2009-Robust Principal Component Analysis: Exact Recovery of Corrupted Low-Rank Matrices via Convex Optimization</a></p>
<p>6 0.9526242 <a title="20-lda-6" href="./nips-2009-Large_Scale_Nonparametric_Bayesian_Inference%3A_Data_Parallelisation_in_the_Indian_Buffet_Process.html">123 nips-2009-Large Scale Nonparametric Bayesian Inference: Data Parallelisation in the Indian Buffet Process</a></p>
<p>7 0.95075023 <a title="20-lda-7" href="./nips-2009-Sharing_Features_among_Dynamical_Systems_with_Beta_Processes.html">217 nips-2009-Sharing Features among Dynamical Systems with Beta Processes</a></p>
<p>8 0.94933581 <a title="20-lda-8" href="./nips-2009-Free_energy_score_space.html">97 nips-2009-Free energy score space</a></p>
<p>9 0.94856894 <a title="20-lda-9" href="./nips-2009-A_General_Projection_Property_for_Distribution_Families.html">11 nips-2009-A General Projection Property for Distribution Families</a></p>
<p>10 0.9485451 <a title="20-lda-10" href="./nips-2009-%24L_1%24-Penalized_Robust_Estimation_for_a_Class_of_Inverse_Problems_Arising_in_Multiview_Geometry.html">1 nips-2009-$L 1$-Penalized Robust Estimation for a Class of Inverse Problems Arising in Multiview Geometry</a></p>
<p>11 0.94846553 <a title="20-lda-11" href="./nips-2009-On_the_Convergence_of_the_Concave-Convex_Procedure.html">180 nips-2009-On the Convergence of the Concave-Convex Procedure</a></p>
<p>12 0.94833833 <a title="20-lda-12" href="./nips-2009-Functional_network_reorganization_in_motor_cortex_can_be_explained_by_reward-modulated_Hebbian_learning.html">99 nips-2009-Functional network reorganization in motor cortex can be explained by reward-modulated Hebbian learning</a></p>
<p>13 0.9481442 <a title="20-lda-13" href="./nips-2009-Group_Sparse_Coding.html">104 nips-2009-Group Sparse Coding</a></p>
<p>14 0.94813675 <a title="20-lda-14" href="./nips-2009-A_Neural_Implementation_of_the_Kalman_Filter.html">13 nips-2009-A Neural Implementation of the Kalman Filter</a></p>
<p>15 0.94792408 <a title="20-lda-15" href="./nips-2009-Nonlinear_Learning_using_Local_Coordinate_Coding.html">169 nips-2009-Nonlinear Learning using Local Coordinate Coding</a></p>
<p>16 0.94774407 <a title="20-lda-16" href="./nips-2009-Construction_of_Nonparametric_Bayesian_Models_from_Parametric_Bayes_Equations.html">59 nips-2009-Construction of Nonparametric Bayesian Models from Parametric Bayes Equations</a></p>
<p>17 0.94772857 <a title="20-lda-17" href="./nips-2009-No_evidence_for_active_sparsification_in_the_visual_cortex.html">164 nips-2009-No evidence for active sparsification in the visual cortex</a></p>
<p>18 0.94762051 <a title="20-lda-18" href="./nips-2009-Noisy_Generalized_Binary_Search.html">166 nips-2009-Noisy Generalized Binary Search</a></p>
<p>19 0.94750679 <a title="20-lda-19" href="./nips-2009-A_Game-Theoretic_Approach_to_Hypergraph_Clustering.html">9 nips-2009-A Game-Theoretic Approach to Hypergraph Clustering</a></p>
<p>20 0.94744921 <a title="20-lda-20" href="./nips-2009-Structured_output_regression_for_detection_with_partial_truncation.html">236 nips-2009-Structured output regression for detection with partial truncation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
