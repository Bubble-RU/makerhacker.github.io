<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>76 nips-2009-Efficient Learning using Forward-Backward Splitting</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-76" href="#">nips2009-76</a> knowledge-graph by maker-knowledge-mining</p><h1>76 nips-2009-Efficient Learning using Forward-Backward Splitting</h1>
<br/><p>Source: <a title="nips-2009-76-pdf" href="http://papers.nips.cc/paper/3793-efficient-learning-using-forward-backward-splitting.pdf">pdf</a></p><p>Author: Yoram Singer, John C. Duchi</p><p>Abstract: We describe, analyze, and experiment with a new framework for empirical loss minimization with regularization. Our algorithmic framework alternates between two phases. On each iteration we ﬁrst perform an unconstrained gradient descent step. We then cast and solve an instantaneous optimization problem that trades off minimization of a regularization term while keeping close proximity to the result of the ﬁrst phase. This yields a simple yet effective algorithm for both batch penalized risk minimization and online learning. Furthermore, the two phase approach enables sparse solutions when used in conjunction with regularization functions that promote sparsity, such as ℓ1 . We derive concrete and very simple algorithms for minimization of loss functions with ℓ1 , ℓ2 , ℓ2 , and ℓ∞ regularization. We 2 also show how to construct efﬁcient algorithms for mixed-norm ℓ1 /ℓq regularization. We further extend the algorithms and give efﬁcient implementations for very high-dimensional data with sparsity. We demonstrate the potential of the proposed framework in experiments with synthetic and natural datasets. 1</p><p>Reference: <a title="nips-2009-76-reference" href="../nips2009_reference/nips-2009-Efficient_Learning_using_Forward-Backward_Splitting_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('obo', 0.67), ('wt', 0.62), ('subgrady', 0.227), ('pegaso', 0.095), ('regret', 0.09), ('folo', 0.082), ('regul', 0.076), ('spars', 0.071), ('lands', 0.068), ('ft', 0.067), ('onlin', 0.065), ('loss', 0.056), ('minw', 0.055), ('grady', 0.052), ('mnist', 0.049), ('convex', 0.049), ('nnz', 0.047), ('upd', 0.042), ('ip', 0.042), ('batch', 0.039)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="76-tfidf-1" href="./nips-2009-Efficient_Learning_using_Forward-Backward_Splitting.html">76 nips-2009-Efficient Learning using Forward-Backward Splitting</a></p>
<p>2 0.10272022 <a title="76-tfidf-2" href="./nips-2009-Beyond_Convexity%3A_Online_Submodular_Minimization.html">45 nips-2009-Beyond Convexity: Online Submodular Minimization</a></p>
<p>3 0.093678989 <a title="76-tfidf-3" href="./nips-2009-Time-Varying_Dynamic_Bayesian_Networks.html">246 nips-2009-Time-Varying Dynamic Bayesian Networks</a></p>
<p>4 0.092303507 <a title="76-tfidf-4" href="./nips-2009-Convex_Relaxation_of_Mixture_Regression_with_Efficient_Algorithms.html">61 nips-2009-Convex Relaxation of Mixture Regression with Efficient Algorithms</a></p>
<p>5 0.090230778 <a title="76-tfidf-5" href="./nips-2009-Slow_Learners_are_Fast.html">220 nips-2009-Slow Learners are Fast</a></p>
<p>6 0.077587314 <a title="76-tfidf-6" href="./nips-2009-A_Parameter-free_Hedging_Algorithm.html">14 nips-2009-A Parameter-free Hedging Algorithm</a></p>
<p>7 0.069424398 <a title="76-tfidf-7" href="./nips-2009-Sensitivity_analysis_in_HMMs_with_application_to_likelihood_maximization.html">215 nips-2009-Sensitivity analysis in HMMs with application to likelihood maximization</a></p>
<p>8 0.06774231 <a title="76-tfidf-8" href="./nips-2009-A_unified_framework_for_high-dimensional_analysis_of_%24M%24-estimators_with_decomposable_regularizers.html">20 nips-2009-A unified framework for high-dimensional analysis of $M$-estimators with decomposable regularizers</a></p>
<p>9 0.066103734 <a title="76-tfidf-9" href="./nips-2009-Dual_Averaging_Method_for_Regularized_Stochastic_Learning_and_Online_Optimization.html">73 nips-2009-Dual Averaging Method for Regularized Stochastic Learning and Online Optimization</a></p>
<p>10 0.065836012 <a title="76-tfidf-10" href="./nips-2009-Potential-Based_Agnostic_Boosting.html">193 nips-2009-Potential-Based Agnostic Boosting</a></p>
<p>11 0.065526411 <a title="76-tfidf-11" href="./nips-2009-On_Stochastic_and_Worst-case_Models_for_Investing.html">178 nips-2009-On Stochastic and Worst-case Models for Investing</a></p>
<p>12 0.058957599 <a title="76-tfidf-12" href="./nips-2009-Accelerated_Gradient_Methods_for_Stochastic_Optimization_and_Online_Learning.html">22 nips-2009-Accelerated Gradient Methods for Stochastic Optimization and Online Learning</a></p>
<p>13 0.052558947 <a title="76-tfidf-13" href="./nips-2009-Replacing_supervised_classification_learning_by_Slow_Feature_Analysis_in_spiking_neural_networks.html">203 nips-2009-Replacing supervised classification learning by Slow Feature Analysis in spiking neural networks</a></p>
<p>14 0.050481889 <a title="76-tfidf-14" href="./nips-2009-Sparse_and_Locally_Constant_Gaussian_Graphical_Models.html">224 nips-2009-Sparse and Locally Constant Gaussian Graphical Models</a></p>
<p>15 0.047210835 <a title="76-tfidf-15" href="./nips-2009-Structured_output_regression_for_detection_with_partial_truncation.html">236 nips-2009-Structured output regression for detection with partial truncation</a></p>
<p>16 0.046647236 <a title="76-tfidf-16" href="./nips-2009-Multi-Label_Prediction_via_Compressed_Sensing.html">157 nips-2009-Multi-Label Prediction via Compressed Sensing</a></p>
<p>17 0.045837395 <a title="76-tfidf-17" href="./nips-2009-Robust_Principal_Component_Analysis%3A_Exact_Recovery_of_Corrupted_Low-Rank_Matrices_via_Convex_Optimization.html">208 nips-2009-Robust Principal Component Analysis: Exact Recovery of Corrupted Low-Rank Matrices via Convex Optimization</a></p>
<p>18 0.044644553 <a title="76-tfidf-18" href="./nips-2009-Thresholding_Procedures_for_High_Dimensional_Variable_Selection_and_Statistical_Estimation.html">245 nips-2009-Thresholding Procedures for High Dimensional Variable Selection and Statistical Estimation</a></p>
<p>19 0.043656707 <a title="76-tfidf-19" href="./nips-2009-DUOL%3A_A_Double_Updating_Approach_for_Online_Learning.html">63 nips-2009-DUOL: A Double Updating Approach for Online Learning</a></p>
<p>20 0.042719059 <a title="76-tfidf-20" href="./nips-2009-Information-theoretic_lower_bounds_on_the_oracle_complexity_of_convex_optimization.html">116 nips-2009-Information-theoretic lower bounds on the oracle complexity of convex optimization</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.13), (1, 0.06), (2, 0.105), (3, 0.019), (4, -0.087), (5, 0.012), (6, -0.025), (7, -0.004), (8, -0.036), (9, -0.02), (10, 0.026), (11, -0.006), (12, 0.037), (13, 0.039), (14, -0.011), (15, 0.02), (16, 0.044), (17, -0.007), (18, 0.028), (19, -0.038), (20, -0.007), (21, -0.017), (22, -0.047), (23, -0.004), (24, -0.022), (25, 0.006), (26, -0.012), (27, 0.056), (28, -0.006), (29, 0.146), (30, 0.051), (31, 0.029), (32, -0.028), (33, -0.03), (34, 0.058), (35, 0.088), (36, -0.055), (37, -0.0), (38, -0.048), (39, -0.035), (40, -0.103), (41, -0.065), (42, 0.013), (43, -0.059), (44, 0.099), (45, -0.107), (46, -0.044), (47, -0.031), (48, 0.006), (49, -0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.86310762 <a title="76-lsi-1" href="./nips-2009-Efficient_Learning_using_Forward-Backward_Splitting.html">76 nips-2009-Efficient Learning using Forward-Backward Splitting</a></p>
<p>2 0.67536598 <a title="76-lsi-2" href="./nips-2009-Dual_Averaging_Method_for_Regularized_Stochastic_Learning_and_Online_Optimization.html">73 nips-2009-Dual Averaging Method for Regularized Stochastic Learning and Online Optimization</a></p>
<p>3 0.66989881 <a title="76-lsi-3" href="./nips-2009-Slow_Learners_are_Fast.html">220 nips-2009-Slow Learners are Fast</a></p>
<p>4 0.60496801 <a title="76-lsi-4" href="./nips-2009-Periodic_Step_Size_Adaptation_for_Single_Pass_On-line_Learning.html">189 nips-2009-Periodic Step Size Adaptation for Single Pass On-line Learning</a></p>
<p>5 0.60259169 <a title="76-lsi-5" href="./nips-2009-A_Parameter-free_Hedging_Algorithm.html">14 nips-2009-A Parameter-free Hedging Algorithm</a></p>
<p>6 0.52896535 <a title="76-lsi-6" href="./nips-2009-Probabilistic_Relational_PCA.html">195 nips-2009-Probabilistic Relational PCA</a></p>
<p>7 0.52044201 <a title="76-lsi-7" href="./nips-2009-On_Stochastic_and_Worst-case_Models_for_Investing.html">178 nips-2009-On Stochastic and Worst-case Models for Investing</a></p>
<p>8 0.51438826 <a title="76-lsi-8" href="./nips-2009-Directed_Regression.html">67 nips-2009-Directed Regression</a></p>
<p>9 0.50361198 <a title="76-lsi-9" href="./nips-2009-Bilinear_classifiers_for_visual_recognition.html">46 nips-2009-Bilinear classifiers for visual recognition</a></p>
<p>10 0.49062771 <a title="76-lsi-10" href="./nips-2009-DUOL%3A_A_Double_Updating_Approach_for_Online_Learning.html">63 nips-2009-DUOL: A Double Updating Approach for Online Learning</a></p>
<p>11 0.48810145 <a title="76-lsi-11" href="./nips-2009-Efficient_Large-Scale_Distributed_Training_of_Conditional_Maximum_Entropy_Models.html">75 nips-2009-Efficient Large-Scale Distributed Training of Conditional Maximum Entropy Models</a></p>
<p>12 0.48286584 <a title="76-lsi-12" href="./nips-2009-Beyond_Convexity%3A_Online_Submodular_Minimization.html">45 nips-2009-Beyond Convexity: Online Submodular Minimization</a></p>
<p>13 0.4813135 <a title="76-lsi-13" href="./nips-2009-Multiple_Incremental_Decremental_Learning_of_Support_Vector_Machines.html">160 nips-2009-Multiple Incremental Decremental Learning of Support Vector Machines</a></p>
<p>14 0.46319515 <a title="76-lsi-14" href="./nips-2009-Potential-Based_Agnostic_Boosting.html">193 nips-2009-Potential-Based Agnostic Boosting</a></p>
<p>15 0.45967543 <a title="76-lsi-15" href="./nips-2009-Ensemble_Nystrom_Method.html">81 nips-2009-Ensemble Nystrom Method</a></p>
<p>16 0.45407838 <a title="76-lsi-16" href="./nips-2009-Adapting_to_the_Shifting_Intent_of_Search_Queries.html">24 nips-2009-Adapting to the Shifting Intent of Search Queries</a></p>
<p>17 0.45276895 <a title="76-lsi-17" href="./nips-2009-On_the_Convergence_of_the_Concave-Convex_Procedure.html">180 nips-2009-On the Convergence of the Concave-Convex Procedure</a></p>
<p>18 0.45230725 <a title="76-lsi-18" href="./nips-2009-Convex_Relaxation_of_Mixture_Regression_with_Efficient_Algorithms.html">61 nips-2009-Convex Relaxation of Mixture Regression with Efficient Algorithms</a></p>
<p>19 0.43874109 <a title="76-lsi-19" href="./nips-2009-Sparse_Estimation_Using_General_Likelihoods_and_Non-Factorial_Priors.html">222 nips-2009-Sparse Estimation Using General Likelihoods and Non-Factorial Priors</a></p>
<p>20 0.42716059 <a title="76-lsi-20" href="./nips-2009-Sensitivity_analysis_in_HMMs_with_application_to_likelihood_maximization.html">215 nips-2009-Sensitivity analysis in HMMs with application to likelihood maximization</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(4, 0.014), (9, 0.22), (11, 0.062), (20, 0.273), (31, 0.085), (37, 0.01), (40, 0.013), (60, 0.052), (89, 0.023), (96, 0.106)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.89646357 <a title="76-lda-1" href="./nips-2009-Canonical_Time_Warping_for_Alignment_of_Human_Behavior.html">50 nips-2009-Canonical Time Warping for Alignment of Human Behavior</a></p>
<p>2 0.82277966 <a title="76-lda-2" href="./nips-2009-Speaker_Comparison_with_Inner_Product_Discriminant_Functions.html">227 nips-2009-Speaker Comparison with Inner Product Discriminant Functions</a></p>
<p>same-paper 3 0.72800463 <a title="76-lda-3" href="./nips-2009-Efficient_Learning_using_Forward-Backward_Splitting.html">76 nips-2009-Efficient Learning using Forward-Backward Splitting</a></p>
<p>4 0.68715036 <a title="76-lda-4" href="./nips-2009-On_Stochastic_and_Worst-case_Models_for_Investing.html">178 nips-2009-On Stochastic and Worst-case Models for Investing</a></p>
<p>5 0.68690509 <a title="76-lda-5" href="./nips-2009-Monte_Carlo_Sampling_for_Regret_Minimization_in_Extensive_Games.html">156 nips-2009-Monte Carlo Sampling for Regret Minimization in Extensive Games</a></p>
<p>6 0.68667966 <a title="76-lda-6" href="./nips-2009-Adapting_to_the_Shifting_Intent_of_Search_Queries.html">24 nips-2009-Adapting to the Shifting Intent of Search Queries</a></p>
<p>7 0.68525398 <a title="76-lda-7" href="./nips-2009-Learning_Non-Linear_Combinations_of_Kernels.html">128 nips-2009-Learning Non-Linear Combinations of Kernels</a></p>
<p>8 0.68524814 <a title="76-lda-8" href="./nips-2009-Adaptive_Regularization_for_Transductive_Support_Vector_Machine.html">26 nips-2009-Adaptive Regularization for Transductive Support Vector Machine</a></p>
<p>9 0.68499351 <a title="76-lda-9" href="./nips-2009-Time-Varying_Dynamic_Bayesian_Networks.html">246 nips-2009-Time-Varying Dynamic Bayesian Networks</a></p>
<p>10 0.68476832 <a title="76-lda-10" href="./nips-2009-Kernel_Choice_and_Classifiability_for_RKHS_Embeddings_of_Probability_Distributions.html">118 nips-2009-Kernel Choice and Classifiability for RKHS Embeddings of Probability Distributions</a></p>
<p>11 0.68451464 <a title="76-lda-11" href="./nips-2009-Learning_to_Rank_by_Optimizing_NDCG_Measure.html">136 nips-2009-Learning to Rank by Optimizing NDCG Measure</a></p>
<p>12 0.68396837 <a title="76-lda-12" href="./nips-2009-Slow_Learners_are_Fast.html">220 nips-2009-Slow Learners are Fast</a></p>
<p>13 0.68396783 <a title="76-lda-13" href="./nips-2009-Manifold_Embeddings_for_Model-Based_Reinforcement_Learning_under_Partial_Observability.html">145 nips-2009-Manifold Embeddings for Model-Based Reinforcement Learning under Partial Observability</a></p>
<p>14 0.68389362 <a title="76-lda-14" href="./nips-2009-Directed_Regression.html">67 nips-2009-Directed Regression</a></p>
<p>15 0.68347949 <a title="76-lda-15" href="./nips-2009-Beyond_Convexity%3A_Online_Submodular_Minimization.html">45 nips-2009-Beyond Convexity: Online Submodular Minimization</a></p>
<p>16 0.68236971 <a title="76-lda-16" href="./nips-2009-Efficient_and_Accurate_Lp-Norm_Multiple_Kernel_Learning.html">80 nips-2009-Efficient and Accurate Lp-Norm Multiple Kernel Learning</a></p>
<p>17 0.68218446 <a title="76-lda-17" href="./nips-2009-Speeding_up_Magnetic_Resonance_Image_Acquisition_by_Bayesian_Multi-Slice_Adaptive_Compressed_Sensing.html">228 nips-2009-Speeding up Magnetic Resonance Image Acquisition by Bayesian Multi-Slice Adaptive Compressed Sensing</a></p>
<p>18 0.68214595 <a title="76-lda-18" href="./nips-2009-Help_or_Hinder%3A_Bayesian_Models_of_Social_Goal_Inference.html">107 nips-2009-Help or Hinder: Bayesian Models of Social Goal Inference</a></p>
<p>19 0.68136114 <a title="76-lda-19" href="./nips-2009-Nash_Equilibria_of_Static_Prediction_Games.html">161 nips-2009-Nash Equilibria of Static Prediction Games</a></p>
<p>20 0.68111217 <a title="76-lda-20" href="./nips-2009-Multiple_Incremental_Decremental_Learning_of_Support_Vector_Machines.html">160 nips-2009-Multiple Incremental Decremental Learning of Support Vector Machines</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
