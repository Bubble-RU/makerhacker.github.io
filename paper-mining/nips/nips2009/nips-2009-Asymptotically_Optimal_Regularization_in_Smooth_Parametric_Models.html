<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>37 nips-2009-Asymptotically Optimal Regularization in Smooth Parametric Models</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-37" href="#">nips2009-37</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>37 nips-2009-Asymptotically Optimal Regularization in Smooth Parametric Models</h1>
<br/><p>Source: <a title="nips-2009-37-pdf" href="http://papers.nips.cc/paper/3693-asymptotically-optimal-regularization-in-smooth-parametric-models.pdf">pdf</a></p><p>Author: Percy Liang, Guillaume Bouchard, Francis R. Bach, Michael I. Jordan</p><p>Abstract: Many types of regularization schemes have been employed in statistical learning, each motivated by some assumption about the problem domain. In this paper, we present a uniÔ¨Åed asymptotic analysis of smooth regularizers, which allows us to see how the validity of these assumptions impacts the success of a particular regularizer. In addition, our analysis motivates an algorithm for optimizing regularization parameters, which in turn can be analyzed within our framework. We apply our analysis to several examples, including hybrid generative-discriminative learning and multi-task learning. 1</p><p>Reference: <a title="nips-2009-37-reference" href="../nips2009_reference/nips-2009-Asymptotically_Optimal_Regularization_in_Smooth_Parametric_Models_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('lugin', 0.536), ('risk', 0.378), ('def', 0.292), ('rac', 0.278), ('plugin', 0.243), ('regul', 0.216), ('ln', 0.157), ('orac', 0.153), ('vx', 0.149), ('misspec', 0.139), ('asymptot', 0.132), ('cv', 0.129), ('tr', 0.127), ('rn', 0.12), ('argmin', 0.117), ('xy', 0.11), ('nregul', 0.099), ('unregul', 0.08), ('tein', 0.079), ('hybrid', 0.071)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999997 <a title="37-tfidf-1" href="./nips-2009-Asymptotically_Optimal_Regularization_in_Smooth_Parametric_Models.html">37 nips-2009-Asymptotically Optimal Regularization in Smooth Parametric Models</a></p>
<p>2 0.21150777 <a title="37-tfidf-2" href="./nips-2009-Data-driven_calibration_of_linear_estimators_with_minimal_penalties.html">64 nips-2009-Data-driven calibration of linear estimators with minimal penalties</a></p>
<p>3 0.20156364 <a title="37-tfidf-3" href="./nips-2009-From_PAC-Bayes_Bounds_to_KL_Regularization.html">98 nips-2009-From PAC-Bayes Bounds to KL Regularization</a></p>
<p>4 0.16156103 <a title="37-tfidf-4" href="./nips-2009-Compressed_Least-Squares_Regression.html">55 nips-2009-Compressed Least-Squares Regression</a></p>
<p>5 0.13109906 <a title="37-tfidf-5" href="./nips-2009-Information-theoretic_lower_bounds_on_the_oracle_complexity_of_convex_optimization.html">116 nips-2009-Information-theoretic lower bounds on the oracle complexity of convex optimization</a></p>
<p>6 0.1106881 <a title="37-tfidf-6" href="./nips-2009-Generalization_Errors_and_Learning_Curves_for_Regression_with_Multi-task_Gaussian_Processes.html">101 nips-2009-Generalization Errors and Learning Curves for Regression with Multi-task Gaussian Processes</a></p>
<p>7 0.10395355 <a title="37-tfidf-7" href="./nips-2009-A_unified_framework_for_high-dimensional_analysis_of_%24M%24-estimators_with_decomposable_regularizers.html">20 nips-2009-A unified framework for high-dimensional analysis of $M$-estimators with decomposable regularizers</a></p>
<p>8 0.091658667 <a title="37-tfidf-8" href="./nips-2009-Fast_Learning_from_Non-i.i.d._Observations.html">94 nips-2009-Fast Learning from Non-i.i.d. Observations</a></p>
<p>9 0.083801761 <a title="37-tfidf-9" href="./nips-2009-Fast%2C_smooth_and_adaptive_regression_in_metric_spaces.html">91 nips-2009-Fast, smooth and adaptive regression in metric spaces</a></p>
<p>10 0.079402328 <a title="37-tfidf-10" href="./nips-2009-Ranking_Measures_and_Loss_Functions_in_Learning_to_Rank.html">199 nips-2009-Ranking Measures and Loss Functions in Learning to Rank</a></p>
<p>11 0.074859075 <a title="37-tfidf-11" href="./nips-2009-Distribution-Calibrated_Hierarchical_Classification.html">71 nips-2009-Distribution-Calibrated Hierarchical Classification</a></p>
<p>12 0.072175972 <a title="37-tfidf-12" href="./nips-2009-Canonical_Time_Warping_for_Alignment_of_Human_Behavior.html">50 nips-2009-Canonical Time Warping for Alignment of Human Behavior</a></p>
<p>13 0.07087341 <a title="37-tfidf-13" href="./nips-2009-Semi-supervised_Regression_using_Hessian_energy_with_an_application_to_semi-supervised_dimensionality_reduction.html">214 nips-2009-Semi-supervised Regression using Hessian energy with an application to semi-supervised dimensionality reduction</a></p>
<p>14 0.069494128 <a title="37-tfidf-14" href="./nips-2009-Kernels_and_learning_curves_for_Gaussian_process_regression_on_random_graphs.html">120 nips-2009-Kernels and learning curves for Gaussian process regression on random graphs</a></p>
<p>15 0.063143983 <a title="37-tfidf-15" href="./nips-2009-A_Parameter-free_Hedging_Algorithm.html">14 nips-2009-A Parameter-free Hedging Algorithm</a></p>
<p>16 0.062870532 <a title="37-tfidf-16" href="./nips-2009-Statistical_Analysis_of_Semi-Supervised_Learning%3A_The_Limit_of_Infinite_Unlabelled_Data.html">229 nips-2009-Statistical Analysis of Semi-Supervised Learning: The Limit of Infinite Unlabelled Data</a></p>
<p>17 0.060372148 <a title="37-tfidf-17" href="./nips-2009-Thresholding_Procedures_for_High_Dimensional_Variable_Selection_and_Statistical_Estimation.html">245 nips-2009-Thresholding Procedures for High Dimensional Variable Selection and Statistical Estimation</a></p>
<p>18 0.059938483 <a title="37-tfidf-18" href="./nips-2009-Regularized_Distance_Metric_Learning%3ATheory_and_Algorithm.html">202 nips-2009-Regularized Distance Metric Learning:Theory and Algorithm</a></p>
<p>19 0.05908376 <a title="37-tfidf-19" href="./nips-2009-Kernel_Choice_and_Classifiability_for_RKHS_Embeddings_of_Probability_Distributions.html">118 nips-2009-Kernel Choice and Classifiability for RKHS Embeddings of Probability Distributions</a></p>
<p>20 0.058777295 <a title="37-tfidf-20" href="./nips-2009-Sufficient_Conditions_for_Agnostic_Active_Learnable.html">240 nips-2009-Sufficient Conditions for Agnostic Active Learnable</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.161), (1, 0.097), (2, 0.113), (3, -0.102), (4, -0.015), (5, 0.011), (6, -0.032), (7, -0.087), (8, 0.038), (9, -0.069), (10, 0.013), (11, 0.093), (12, -0.07), (13, 0.11), (14, -0.007), (15, -0.045), (16, 0.104), (17, 0.024), (18, -0.137), (19, -0.157), (20, -0.136), (21, -0.117), (22, 0.019), (23, 0.146), (24, 0.103), (25, 0.207), (26, 0.007), (27, -0.006), (28, -0.134), (29, 0.078), (30, 0.129), (31, -0.023), (32, -0.067), (33, -0.101), (34, 0.009), (35, 0.035), (36, -0.061), (37, 0.052), (38, 0.001), (39, 0.073), (40, -0.006), (41, 0.014), (42, -0.061), (43, 0.103), (44, -0.055), (45, 0.227), (46, 0.06), (47, 0.027), (48, -0.026), (49, 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92122513 <a title="37-lsi-1" href="./nips-2009-Asymptotically_Optimal_Regularization_in_Smooth_Parametric_Models.html">37 nips-2009-Asymptotically Optimal Regularization in Smooth Parametric Models</a></p>
<p>2 0.73563659 <a title="37-lsi-2" href="./nips-2009-From_PAC-Bayes_Bounds_to_KL_Regularization.html">98 nips-2009-From PAC-Bayes Bounds to KL Regularization</a></p>
<p>3 0.62662822 <a title="37-lsi-3" href="./nips-2009-Fast_Learning_from_Non-i.i.d._Observations.html">94 nips-2009-Fast Learning from Non-i.i.d. Observations</a></p>
<p>4 0.61530882 <a title="37-lsi-4" href="./nips-2009-Data-driven_calibration_of_linear_estimators_with_minimal_penalties.html">64 nips-2009-Data-driven calibration of linear estimators with minimal penalties</a></p>
<p>5 0.58557415 <a title="37-lsi-5" href="./nips-2009-Compressed_Least-Squares_Regression.html">55 nips-2009-Compressed Least-Squares Regression</a></p>
<p>6 0.5229308 <a title="37-lsi-6" href="./nips-2009-Fast%2C_smooth_and_adaptive_regression_in_metric_spaces.html">91 nips-2009-Fast, smooth and adaptive regression in metric spaces</a></p>
<p>7 0.46291402 <a title="37-lsi-7" href="./nips-2009-Learning_from_Multiple_Partially_Observed_Views_-_an_Application_to_Multilingual_Text_Categorization.html">130 nips-2009-Learning from Multiple Partially Observed Views - an Application to Multilingual Text Categorization</a></p>
<p>8 0.43812776 <a title="37-lsi-8" href="./nips-2009-Information-theoretic_lower_bounds_on_the_oracle_complexity_of_convex_optimization.html">116 nips-2009-Information-theoretic lower bounds on the oracle complexity of convex optimization</a></p>
<p>9 0.43162352 <a title="37-lsi-9" href="./nips-2009-Generalization_Errors_and_Learning_Curves_for_Regression_with_Multi-task_Gaussian_Processes.html">101 nips-2009-Generalization Errors and Learning Curves for Regression with Multi-task Gaussian Processes</a></p>
<p>10 0.425199 <a title="37-lsi-10" href="./nips-2009-Lattice_Regression.html">124 nips-2009-Lattice Regression</a></p>
<p>11 0.41662553 <a title="37-lsi-11" href="./nips-2009-Heterogeneous_multitask_learning_with_joint_sparsity_constraints.html">108 nips-2009-Heterogeneous multitask learning with joint sparsity constraints</a></p>
<p>12 0.38357174 <a title="37-lsi-12" href="./nips-2009-Discrete_MDL_Predicts_in_Total_Variation.html">69 nips-2009-Discrete MDL Predicts in Total Variation</a></p>
<p>13 0.38095528 <a title="37-lsi-13" href="./nips-2009-Distribution-Calibrated_Hierarchical_Classification.html">71 nips-2009-Distribution-Calibrated Hierarchical Classification</a></p>
<p>14 0.37031847 <a title="37-lsi-14" href="./nips-2009-A_unified_framework_for_high-dimensional_analysis_of_%24M%24-estimators_with_decomposable_regularizers.html">20 nips-2009-A unified framework for high-dimensional analysis of $M$-estimators with decomposable regularizers</a></p>
<p>15 0.35616693 <a title="37-lsi-15" href="./nips-2009-Dual_Averaging_Method_for_Regularized_Stochastic_Learning_and_Online_Optimization.html">73 nips-2009-Dual Averaging Method for Regularized Stochastic Learning and Online Optimization</a></p>
<p>16 0.32760158 <a title="37-lsi-16" href="./nips-2009-Robust_Nonparametric_Regression_with_Metric-Space_Valued_Output.html">207 nips-2009-Robust Nonparametric Regression with Metric-Space Valued Output</a></p>
<p>17 0.31968769 <a title="37-lsi-17" href="./nips-2009-Optimal_Scoring_for_Unsupervised_Learning.html">182 nips-2009-Optimal Scoring for Unsupervised Learning</a></p>
<p>18 0.31646708 <a title="37-lsi-18" href="./nips-2009-Ensemble_Nystrom_Method.html">81 nips-2009-Ensemble Nystrom Method</a></p>
<p>19 0.31566602 <a title="37-lsi-19" href="./nips-2009-Bilinear_classifiers_for_visual_recognition.html">46 nips-2009-Bilinear classifiers for visual recognition</a></p>
<p>20 0.31358048 <a title="37-lsi-20" href="./nips-2009-A_Parameter-free_Hedging_Algorithm.html">14 nips-2009-A Parameter-free Hedging Algorithm</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(9, 0.225), (11, 0.061), (31, 0.105), (37, 0.021), (60, 0.067), (89, 0.021), (91, 0.305), (96, 0.088)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.83459234 <a title="37-lda-1" href="./nips-2009-Structural_inference_affects_depth_perception_in_the_context_of_potential_occlusion.html">235 nips-2009-Structural inference affects depth perception in the context of potential occlusion</a></p>
<p>2 0.79301453 <a title="37-lda-2" href="./nips-2009-Unsupervised_feature_learning_for_audio_classification_using_convolutional_deep_belief_networks.html">253 nips-2009-Unsupervised feature learning for audio classification using convolutional deep belief networks</a></p>
<p>3 0.79098225 <a title="37-lda-3" href="./nips-2009-Nonlinear_directed_acyclic_structure_learning_with_weakly_additive_noise_models.html">170 nips-2009-Nonlinear directed acyclic structure learning with weakly additive noise models</a></p>
<p>same-paper 4 0.7368753 <a title="37-lda-4" href="./nips-2009-Asymptotically_Optimal_Regularization_in_Smooth_Parametric_Models.html">37 nips-2009-Asymptotically Optimal Regularization in Smooth Parametric Models</a></p>
<p>5 0.69135559 <a title="37-lda-5" href="./nips-2009-Segmenting_Scenes_by_Matching_Image_Composites.html">211 nips-2009-Segmenting Scenes by Matching Image Composites</a></p>
<p>6 0.66251272 <a title="37-lda-6" href="./nips-2009-Adaptive_Regularization_for_Transductive_Support_Vector_Machine.html">26 nips-2009-Adaptive Regularization for Transductive Support Vector Machine</a></p>
<p>7 0.6593309 <a title="37-lda-7" href="./nips-2009-Bayesian_Source_Localization_with_the_Multivariate_Laplace_Prior.html">41 nips-2009-Bayesian Source Localization with the Multivariate Laplace Prior</a></p>
<p>8 0.65925574 <a title="37-lda-8" href="./nips-2009-Speeding_up_Magnetic_Resonance_Image_Acquisition_by_Bayesian_Multi-Slice_Adaptive_Compressed_Sensing.html">228 nips-2009-Speeding up Magnetic Resonance Image Acquisition by Bayesian Multi-Slice Adaptive Compressed Sensing</a></p>
<p>9 0.65921879 <a title="37-lda-9" href="./nips-2009-Slow_Learners_are_Fast.html">220 nips-2009-Slow Learners are Fast</a></p>
<p>10 0.65897828 <a title="37-lda-10" href="./nips-2009-Learning_in_Markov_Random_Fields_using_Tempered_Transitions.html">132 nips-2009-Learning in Markov Random Fields using Tempered Transitions</a></p>
<p>11 0.65789098 <a title="37-lda-11" href="./nips-2009-Large_Scale_Nonparametric_Bayesian_Inference%3A_Data_Parallelisation_in_the_Indian_Buffet_Process.html">123 nips-2009-Large Scale Nonparametric Bayesian Inference: Data Parallelisation in the Indian Buffet Process</a></p>
<p>12 0.65772182 <a title="37-lda-12" href="./nips-2009-Adapting_to_the_Shifting_Intent_of_Search_Queries.html">24 nips-2009-Adapting to the Shifting Intent of Search Queries</a></p>
<p>13 0.65770966 <a title="37-lda-13" href="./nips-2009-Improving_Existing_Fault_Recovery_Policies.html">113 nips-2009-Improving Existing Fault Recovery Policies</a></p>
<p>14 0.6577003 <a title="37-lda-14" href="./nips-2009-Beyond_Convexity%3A_Online_Submodular_Minimization.html">45 nips-2009-Beyond Convexity: Online Submodular Minimization</a></p>
<p>15 0.65761966 <a title="37-lda-15" href="./nips-2009-Manifold_Embeddings_for_Model-Based_Reinforcement_Learning_under_Partial_Observability.html">145 nips-2009-Manifold Embeddings for Model-Based Reinforcement Learning under Partial Observability</a></p>
<p>16 0.65723872 <a title="37-lda-16" href="./nips-2009-Learning_to_Rank_by_Optimizing_NDCG_Measure.html">136 nips-2009-Learning to Rank by Optimizing NDCG Measure</a></p>
<p>17 0.65706944 <a title="37-lda-17" href="./nips-2009-Kernels_and_learning_curves_for_Gaussian_process_regression_on_random_graphs.html">120 nips-2009-Kernels and learning curves for Gaussian process regression on random graphs</a></p>
<p>18 0.65688348 <a title="37-lda-18" href="./nips-2009-Dual_Averaging_Method_for_Regularized_Stochastic_Learning_and_Online_Optimization.html">73 nips-2009-Dual Averaging Method for Regularized Stochastic Learning and Online Optimization</a></p>
<p>19 0.65665513 <a title="37-lda-19" href="./nips-2009-Rank-Approximate_Nearest_Neighbor_Search%3A_Retaining_Meaning_and_Speed_in_High_Dimensions.html">198 nips-2009-Rank-Approximate Nearest Neighbor Search: Retaining Meaning and Speed in High Dimensions</a></p>
<p>20 0.65630519 <a title="37-lda-20" href="./nips-2009-On_Stochastic_and_Worst-case_Models_for_Investing.html">178 nips-2009-On Stochastic and Worst-case Models for Investing</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
