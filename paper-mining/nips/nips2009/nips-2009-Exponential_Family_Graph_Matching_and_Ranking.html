<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>87 nips-2009-Exponential Family Graph Matching and Ranking</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-87" href="#">nips2009-87</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>87 nips-2009-Exponential Family Graph Matching and Ranking</h1>
<br/><p>Source: <a title="nips-2009-87-pdf" href="http://papers.nips.cc/paper/3800-exponential-family-graph-matching-and-ranking.pdf">pdf</a></p><p>Author: James Petterson, Jin Yu, Julian J. Mcauley, Tibério S. Caetano</p><p>Abstract: We present a method for learning max-weight matching predictors in bipartite graphs. The method consists of performing maximum a posteriori estimation in exponential families with sufﬁcient statistics that encode permutations and data features. Although inference is in general hard, we show that for one very relevant application–document ranking–exact inference is efﬁcient. For general model instances, an appropriate sampler is readily available. Contrary to existing max-margin matching models, our approach is statistically consistent and, in addition, experiments with increasing sample sizes indicate superior improvement over such models. We apply the method to graph matching in computer vision as well as to a standard benchmark dataset for learning document ranking, in which we obtain state-of-the-art results, in particular improving on max-margin variants. The drawback of this method with respect to max-margin alternatives is its runtime for large graphs, which is comparatively high. 1</p><p>Reference: <a title="nips-2009-87-reference" href="../nips2009_reference/nips-2009-Exponential_Family_Graph_Matching_and_Ranking_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('xiy', 0.281), ('rankmatch', 0.256), ('ndcg', 0.236), ('sortnet', 0.23), ('docu', 0.22), ('rank', 0.219), ('bipartit', 0.198), ('dorm', 0.179), ('argmax', 0.171), ('qk', 0.166), ('query', 0.166), ('structured', 0.165), ('adarank', 0.164), ('match', 0.161), ('xn', 0.156), ('ohsum', 0.153), ('structrank', 0.153), ('wiy', 0.153), ('xij', 0.134), ('isorank', 0.128)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="87-tfidf-1" href="./nips-2009-Exponential_Family_Graph_Matching_and_Ranking.html">87 nips-2009-Exponential Family Graph Matching and Ranking</a></p>
<p>Author: James Petterson, Jin Yu, Julian J. Mcauley, Tibério S. Caetano</p><p>Abstract: We present a method for learning max-weight matching predictors in bipartite graphs. The method consists of performing maximum a posteriori estimation in exponential families with sufﬁcient statistics that encode permutations and data features. Although inference is in general hard, we show that for one very relevant application–document ranking–exact inference is efﬁcient. For general model instances, an appropriate sampler is readily available. Contrary to existing max-margin matching models, our approach is statistically consistent and, in addition, experiments with increasing sample sizes indicate superior improvement over such models. We apply the method to graph matching in computer vision as well as to a standard benchmark dataset for learning document ranking, in which we obtain state-of-the-art results, in particular improving on max-margin variants. The drawback of this method with respect to max-margin alternatives is its runtime for large graphs, which is comparatively high. 1</p><p>2 0.33049804 <a title="87-tfidf-2" href="./nips-2009-Learning_to_Rank_by_Optimizing_NDCG_Measure.html">136 nips-2009-Learning to Rank by Optimizing NDCG Measure</a></p>
<p>Author: Hamed Valizadegan, Rong Jin, Ruofei Zhang, Jianchang Mao</p><p>Abstract: Learning to rank is a relatively new ﬁeld of study, aiming to learn a ranking function from a set of training data with relevancy labels. The ranking algorithms are often evaluated using information retrieval measures, such as Normalized Discounted Cumulative Gain (NDCG) [1] and Mean Average Precision (MAP) [2]. Until recently, most learning to rank algorithms were not using a loss function related to the above mentioned evaluation measures. The main difﬁculty in direct optimization of these measures is that they depend on the ranks of documents, not the numerical values output by the ranking function. We propose a probabilistic framework that addresses this challenge by optimizing the expectation of NDCG over all the possible permutations of documents. A relaxation strategy is used to approximate the average of NDCG over the space of permutation, and a bound optimization approach is proposed to make the computation efﬁcient. Extensive experiments show that the proposed algorithm outperforms state-of-the-art ranking algorithms on several benchmark data sets. 1</p><p>3 0.29410079 <a title="87-tfidf-3" href="./nips-2009-Ranking_Measures_and_Loss_Functions_in_Learning_to_Rank.html">199 nips-2009-Ranking Measures and Loss Functions in Learning to Rank</a></p>
<p>Author: Wei Chen, Tie-yan Liu, Yanyan Lan, Zhi-ming Ma, Hang Li</p><p>Abstract: Learning to rank has become an important research topic in machine learning. While most learning-to-rank methods learn the ranking functions by minimizing loss functions, it is the ranking measures (such as NDCG and MAP) that are used to evaluate the performance of the learned ranking functions. In this work, we reveal the relationship between ranking measures and loss functions in learningto-rank methods, such as Ranking SVM, RankBoost, RankNet, and ListMLE. We show that the loss functions of these methods are upper bounds of the measurebased ranking errors. As a result, the minimization of these loss functions will lead to the maximization of the ranking measures. The key to obtaining this result is to model ranking as a sequence of classiﬁcation tasks, and deﬁne a so-called essential loss for ranking as the weighted sum of the classiﬁcation errors of individual tasks in the sequence. We have proved that the essential loss is both an upper bound of the measure-based ranking errors, and a lower bound of the loss functions in the aforementioned methods. Our proof technique also suggests a way to modify existing loss functions to make them tighter bounds of the measure-based ranking errors. Experimental results on benchmark datasets show that the modiﬁcations can lead to better ranking performances, demonstrating the correctness of our theoretical analysis. 1</p><p>4 0.23710018 <a title="87-tfidf-4" href="./nips-2009-Polynomial_Semantic_Indexing.html">190 nips-2009-Polynomial Semantic Indexing</a></p>
<p>Author: Bing Bai, Jason Weston, David Grangier, Ronan Collobert, Kunihiko Sadamasa, Yanjun Qi, Corinna Cortes, Mehryar Mohri</p><p>Abstract: We present a class of nonlinear (polynomial) models that are discriminatively trained to directly map from the word content in a query-document or documentdocument pair to a ranking score. Dealing with polynomial models on word features is computationally challenging. We propose a low-rank (but diagonal preserving) representation of our polynomial models to induce feasible memory and computation requirements. We provide an empirical study on retrieval tasks based on Wikipedia documents, where we obtain state-of-the-art performance while providing realistically scalable methods. 1</p><p>5 0.16067487 <a title="87-tfidf-5" href="./nips-2009-Statistical_Consistency_of_Top-k_Ranking.html">230 nips-2009-Statistical Consistency of Top-k Ranking</a></p>
<p>Author: Fen Xia, Tie-yan Liu, Hang Li</p><p>Abstract: This paper is concerned with the consistency analysis on listwise ranking methods. Among various ranking methods, the listwise methods have competitive performances on benchmark datasets and are regarded as one of the state-of-the-art approaches. Most listwise ranking methods manage to optimize ranking on the whole list (permutation) of objects, however, in practical applications such as information retrieval, correct ranking at the top k positions is much more important. This paper aims to analyze whether existing listwise ranking methods are statistically consistent in the top-k setting. For this purpose, we deﬁne a top-k ranking framework, where the true loss (and thus the risks) are deﬁned on the basis of top-k subgroup of permutations. This framework can include the permutationlevel ranking framework proposed in previous work as a special case. Based on the new framework, we derive sufﬁcient conditions for a listwise ranking method to be consistent with the top-k true loss, and show an effective way of modifying the surrogate loss functions in existing methods to satisfy these conditions. Experimental results show that after the modiﬁcations, the methods can work signiﬁcantly better than their original versions. 1</p><p>6 0.12522328 <a title="87-tfidf-6" href="./nips-2009-Segmenting_Scenes_by_Matching_Image_Composites.html">211 nips-2009-Segmenting Scenes by Matching Image Composites</a></p>
<p>7 0.11698724 <a title="87-tfidf-7" href="./nips-2009-Linear-time_Algorithms_for_Pairwise_Statistical_Problems.html">139 nips-2009-Linear-time Algorithms for Pairwise Statistical Problems</a></p>
<p>8 0.10512951 <a title="87-tfidf-8" href="./nips-2009-Replicated_Softmax%3A_an_Undirected_Topic_Model.html">204 nips-2009-Replicated Softmax: an Undirected Topic Model</a></p>
<p>9 0.089532763 <a title="87-tfidf-9" href="./nips-2009-Rank-Approximate_Nearest_Neighbor_Search%3A_Retaining_Meaning_and_Speed_in_High_Dimensions.html">198 nips-2009-Rank-Approximate Nearest Neighbor Search: Retaining Meaning and Speed in High Dimensions</a></p>
<p>10 0.086784877 <a title="87-tfidf-10" href="./nips-2009-Robust_Principal_Component_Analysis%3A_Exact_Recovery_of_Corrupted_Low-Rank_Matrices_via_Convex_Optimization.html">208 nips-2009-Robust Principal Component Analysis: Exact Recovery of Corrupted Low-Rank Matrices via Convex Optimization</a></p>
<p>11 0.084713228 <a title="87-tfidf-11" href="./nips-2009-Distribution_Matching_for_Transduction.html">72 nips-2009-Distribution Matching for Transduction</a></p>
<p>12 0.080819339 <a title="87-tfidf-12" href="./nips-2009-Noisy_Generalized_Binary_Search.html">166 nips-2009-Noisy Generalized Binary Search</a></p>
<p>13 0.080602042 <a title="87-tfidf-13" href="./nips-2009-Rethinking_LDA%3A_Why_Priors_Matter.html">205 nips-2009-Rethinking LDA: Why Priors Matter</a></p>
<p>14 0.07586094 <a title="87-tfidf-14" href="./nips-2009-Graph-based_Consensus_Maximization_among_Multiple_Supervised_and_Unsupervised_Models.html">102 nips-2009-Graph-based Consensus Maximization among Multiple Supervised and Unsupervised Models</a></p>
<p>15 0.075514063 <a title="87-tfidf-15" href="./nips-2009-An_LP_View_of_the_M-best_MAP_problem.html">31 nips-2009-An LP View of the M-best MAP problem</a></p>
<p>16 0.07285776 <a title="87-tfidf-16" href="./nips-2009-AUC_optimization_and_the_two-sample_problem.html">3 nips-2009-AUC optimization and the two-sample problem</a></p>
<p>17 0.071102619 <a title="87-tfidf-17" href="./nips-2009-Bilinear_classifiers_for_visual_recognition.html">46 nips-2009-Bilinear classifiers for visual recognition</a></p>
<p>18 0.070978507 <a title="87-tfidf-18" href="./nips-2009-Fast_subtree_kernels_on_graphs.html">95 nips-2009-Fast subtree kernels on graphs</a></p>
<p>19 0.07037279 <a title="87-tfidf-19" href="./nips-2009-Locality-sensitive_binary_codes_from_shift-invariant_kernels.html">142 nips-2009-Locality-sensitive binary codes from shift-invariant kernels</a></p>
<p>20 0.067930855 <a title="87-tfidf-20" href="./nips-2009-Filtering_Abstract_Senses_From_Image_Search_Results.html">96 nips-2009-Filtering Abstract Senses From Image Search Results</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.237), (1, 0.107), (2, -0.042), (3, 0.037), (4, 0.096), (5, -0.331), (6, -0.274), (7, 0.004), (8, -0.007), (9, -0.084), (10, -0.217), (11, -0.075), (12, -0.043), (13, 0.071), (14, 0.042), (15, 0.058), (16, -0.04), (17, -0.09), (18, 0.01), (19, -0.01), (20, 0.03), (21, 0.052), (22, -0.046), (23, -0.039), (24, 0.078), (25, -0.019), (26, 0.015), (27, 0.036), (28, 0.04), (29, 0.058), (30, -0.005), (31, 0.022), (32, -0.01), (33, 0.047), (34, -0.051), (35, 0.014), (36, 0.084), (37, 0.012), (38, -0.043), (39, -0.045), (40, -0.03), (41, -0.021), (42, -0.058), (43, -0.004), (44, 0.06), (45, -0.003), (46, -0.008), (47, -0.074), (48, 0.021), (49, 0.034)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.91190982 <a title="87-lsi-1" href="./nips-2009-Learning_to_Rank_by_Optimizing_NDCG_Measure.html">136 nips-2009-Learning to Rank by Optimizing NDCG Measure</a></p>
<p>Author: Hamed Valizadegan, Rong Jin, Ruofei Zhang, Jianchang Mao</p><p>Abstract: Learning to rank is a relatively new ﬁeld of study, aiming to learn a ranking function from a set of training data with relevancy labels. The ranking algorithms are often evaluated using information retrieval measures, such as Normalized Discounted Cumulative Gain (NDCG) [1] and Mean Average Precision (MAP) [2]. Until recently, most learning to rank algorithms were not using a loss function related to the above mentioned evaluation measures. The main difﬁculty in direct optimization of these measures is that they depend on the ranks of documents, not the numerical values output by the ranking function. We propose a probabilistic framework that addresses this challenge by optimizing the expectation of NDCG over all the possible permutations of documents. A relaxation strategy is used to approximate the average of NDCG over the space of permutation, and a bound optimization approach is proposed to make the computation efﬁcient. Extensive experiments show that the proposed algorithm outperforms state-of-the-art ranking algorithms on several benchmark data sets. 1</p><p>same-paper 2 0.89752811 <a title="87-lsi-2" href="./nips-2009-Exponential_Family_Graph_Matching_and_Ranking.html">87 nips-2009-Exponential Family Graph Matching and Ranking</a></p>
<p>Author: James Petterson, Jin Yu, Julian J. Mcauley, Tibério S. Caetano</p><p>Abstract: We present a method for learning max-weight matching predictors in bipartite graphs. The method consists of performing maximum a posteriori estimation in exponential families with sufﬁcient statistics that encode permutations and data features. Although inference is in general hard, we show that for one very relevant application–document ranking–exact inference is efﬁcient. For general model instances, an appropriate sampler is readily available. Contrary to existing max-margin matching models, our approach is statistically consistent and, in addition, experiments with increasing sample sizes indicate superior improvement over such models. We apply the method to graph matching in computer vision as well as to a standard benchmark dataset for learning document ranking, in which we obtain state-of-the-art results, in particular improving on max-margin variants. The drawback of this method with respect to max-margin alternatives is its runtime for large graphs, which is comparatively high. 1</p><p>3 0.81930828 <a title="87-lsi-3" href="./nips-2009-Ranking_Measures_and_Loss_Functions_in_Learning_to_Rank.html">199 nips-2009-Ranking Measures and Loss Functions in Learning to Rank</a></p>
<p>Author: Wei Chen, Tie-yan Liu, Yanyan Lan, Zhi-ming Ma, Hang Li</p><p>Abstract: Learning to rank has become an important research topic in machine learning. While most learning-to-rank methods learn the ranking functions by minimizing loss functions, it is the ranking measures (such as NDCG and MAP) that are used to evaluate the performance of the learned ranking functions. In this work, we reveal the relationship between ranking measures and loss functions in learningto-rank methods, such as Ranking SVM, RankBoost, RankNet, and ListMLE. We show that the loss functions of these methods are upper bounds of the measurebased ranking errors. As a result, the minimization of these loss functions will lead to the maximization of the ranking measures. The key to obtaining this result is to model ranking as a sequence of classiﬁcation tasks, and deﬁne a so-called essential loss for ranking as the weighted sum of the classiﬁcation errors of individual tasks in the sequence. We have proved that the essential loss is both an upper bound of the measure-based ranking errors, and a lower bound of the loss functions in the aforementioned methods. Our proof technique also suggests a way to modify existing loss functions to make them tighter bounds of the measure-based ranking errors. Experimental results on benchmark datasets show that the modiﬁcations can lead to better ranking performances, demonstrating the correctness of our theoretical analysis. 1</p><p>4 0.78903306 <a title="87-lsi-4" href="./nips-2009-Polynomial_Semantic_Indexing.html">190 nips-2009-Polynomial Semantic Indexing</a></p>
<p>Author: Bing Bai, Jason Weston, David Grangier, Ronan Collobert, Kunihiko Sadamasa, Yanjun Qi, Corinna Cortes, Mehryar Mohri</p><p>Abstract: We present a class of nonlinear (polynomial) models that are discriminatively trained to directly map from the word content in a query-document or documentdocument pair to a ranking score. Dealing with polynomial models on word features is computationally challenging. We propose a low-rank (but diagonal preserving) representation of our polynomial models to induce feasible memory and computation requirements. We provide an empirical study on retrieval tasks based on Wikipedia documents, where we obtain state-of-the-art performance while providing realistically scalable methods. 1</p><p>5 0.75446635 <a title="87-lsi-5" href="./nips-2009-Statistical_Consistency_of_Top-k_Ranking.html">230 nips-2009-Statistical Consistency of Top-k Ranking</a></p>
<p>Author: Fen Xia, Tie-yan Liu, Hang Li</p><p>Abstract: This paper is concerned with the consistency analysis on listwise ranking methods. Among various ranking methods, the listwise methods have competitive performances on benchmark datasets and are regarded as one of the state-of-the-art approaches. Most listwise ranking methods manage to optimize ranking on the whole list (permutation) of objects, however, in practical applications such as information retrieval, correct ranking at the top k positions is much more important. This paper aims to analyze whether existing listwise ranking methods are statistically consistent in the top-k setting. For this purpose, we deﬁne a top-k ranking framework, where the true loss (and thus the risks) are deﬁned on the basis of top-k subgroup of permutations. This framework can include the permutationlevel ranking framework proposed in previous work as a special case. Based on the new framework, we derive sufﬁcient conditions for a listwise ranking method to be consistent with the top-k true loss, and show an effective way of modifying the surrogate loss functions in existing methods to satisfy these conditions. Experimental results show that after the modiﬁcations, the methods can work signiﬁcantly better than their original versions. 1</p><p>6 0.60484296 <a title="87-lsi-6" href="./nips-2009-Rank-Approximate_Nearest_Neighbor_Search%3A_Retaining_Meaning_and_Speed_in_High_Dimensions.html">198 nips-2009-Rank-Approximate Nearest Neighbor Search: Retaining Meaning and Speed in High Dimensions</a></p>
<p>7 0.50743592 <a title="87-lsi-7" href="./nips-2009-Riffled_Independence_for_Ranked_Data.html">206 nips-2009-Riffled Independence for Ranked Data</a></p>
<p>8 0.46716565 <a title="87-lsi-8" href="./nips-2009-Streaming_Pointwise_Mutual_Information.html">233 nips-2009-Streaming Pointwise Mutual Information</a></p>
<p>9 0.46005097 <a title="87-lsi-9" href="./nips-2009-The_Wisdom_of_Crowds_in_the_Recollection_of_Order_Information.html">244 nips-2009-The Wisdom of Crowds in the Recollection of Order Information</a></p>
<p>10 0.45147905 <a title="87-lsi-10" href="./nips-2009-Dirichlet-Bernoulli_Alignment%3A_A_Generative_Model_for_Multi-Class_Multi-Label_Multi-Instance_Corpora.html">68 nips-2009-Dirichlet-Bernoulli Alignment: A Generative Model for Multi-Class Multi-Label Multi-Instance Corpora</a></p>
<p>11 0.44950944 <a title="87-lsi-11" href="./nips-2009-AUC_optimization_and_the_two-sample_problem.html">3 nips-2009-AUC optimization and the two-sample problem</a></p>
<p>12 0.41202495 <a title="87-lsi-12" href="./nips-2009-An_Online_Algorithm_for_Large_Scale_Image_Similarity_Learning.html">32 nips-2009-An Online Algorithm for Large Scale Image Similarity Learning</a></p>
<p>13 0.41115028 <a title="87-lsi-13" href="./nips-2009-Replicated_Softmax%3A_an_Undirected_Topic_Model.html">204 nips-2009-Replicated Softmax: an Undirected Topic Model</a></p>
<p>14 0.38731489 <a title="87-lsi-14" href="./nips-2009-Matrix_Completion_from_Power-Law_Distributed_Samples.html">148 nips-2009-Matrix Completion from Power-Law Distributed Samples</a></p>
<p>15 0.38543871 <a title="87-lsi-15" href="./nips-2009-Robust_Principal_Component_Analysis%3A_Exact_Recovery_of_Corrupted_Low-Rank_Matrices_via_Convex_Optimization.html">208 nips-2009-Robust Principal Component Analysis: Exact Recovery of Corrupted Low-Rank Matrices via Convex Optimization</a></p>
<p>16 0.38320965 <a title="87-lsi-16" href="./nips-2009-Linear-time_Algorithms_for_Pairwise_Statistical_Problems.html">139 nips-2009-Linear-time Algorithms for Pairwise Statistical Problems</a></p>
<p>17 0.38222769 <a title="87-lsi-17" href="./nips-2009-Distribution_Matching_for_Transduction.html">72 nips-2009-Distribution Matching for Transduction</a></p>
<p>18 0.37771073 <a title="87-lsi-18" href="./nips-2009-Bilinear_classifiers_for_visual_recognition.html">46 nips-2009-Bilinear classifiers for visual recognition</a></p>
<p>19 0.37238589 <a title="87-lsi-19" href="./nips-2009-Adapting_to_the_Shifting_Intent_of_Search_Queries.html">24 nips-2009-Adapting to the Shifting Intent of Search Queries</a></p>
<p>20 0.34587902 <a title="87-lsi-20" href="./nips-2009-Distribution-Calibrated_Hierarchical_Classification.html">71 nips-2009-Distribution-Calibrated Hierarchical Classification</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(4, 0.017), (9, 0.197), (11, 0.041), (30, 0.352), (31, 0.095), (37, 0.022), (60, 0.101), (89, 0.019), (96, 0.067)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.777776 <a title="87-lda-1" href="./nips-2009-Differential_Use_of_Implicit_Negative_Evidence_in_Generative_and_Discriminative_Language_Learning.html">66 nips-2009-Differential Use of Implicit Negative Evidence in Generative and Discriminative Language Learning</a></p>
<p>Author: Anne Hsu, Thomas L. Griffiths</p><p>Abstract: A classic debate in cognitive science revolves around understanding how children learn complex linguistic rules, such as those governing restrictions on verb alternations, without negative evidence. Traditionally, formal learnability arguments have been used to claim that such learning is impossible without the aid of innate language-speciﬁc knowledge. However, recently, researchers have shown that statistical models are capable of learning complex rules from only positive evidence. These two kinds of learnability analyses differ in their assumptions about the distribution from which linguistic input is generated. The former analyses assume that learners seek to identify grammatical sentences in a way that is robust to the distribution from which the sentences are generated, analogous to discriminative approaches in machine learning. The latter assume that learners are trying to estimate a generative model, with sentences being sampled from that model. We show that these two learning approaches differ in their use of implicit negative evidence – the absence of a sentence – when learning verb alternations, and demonstrate that human learners can produce results consistent with the predictions of both approaches, depending on how the learning problem is presented. 1</p><p>2 0.7712037 <a title="87-lda-2" href="./nips-2009-Indian_Buffet_Processes_with_Power-law_Behavior.html">114 nips-2009-Indian Buffet Processes with Power-law Behavior</a></p>
<p>Author: Yee W. Teh, Dilan Gorur</p><p>Abstract: The Indian buffet process (IBP) is an exchangeable distribution over binary matrices used in Bayesian nonparametric featural models. In this paper we propose a three-parameter generalization of the IBP exhibiting power-law behavior. We achieve this by generalizing the beta process (the de Finetti measure of the IBP) to the stable-beta process and deriving the IBP corresponding to it. We ﬁnd interesting relationships between the stable-beta process and the Pitman-Yor process (another stochastic process used in Bayesian nonparametric models with interesting power-law properties). We derive a stick-breaking construction for the stable-beta process, and ﬁnd that our power-law IBP is a good model for word occurrences in document corpora. 1</p><p>same-paper 3 0.68623346 <a title="87-lda-3" href="./nips-2009-Exponential_Family_Graph_Matching_and_Ranking.html">87 nips-2009-Exponential Family Graph Matching and Ranking</a></p>
<p>Author: James Petterson, Jin Yu, Julian J. Mcauley, Tibério S. Caetano</p><p>Abstract: We present a method for learning max-weight matching predictors in bipartite graphs. The method consists of performing maximum a posteriori estimation in exponential families with sufﬁcient statistics that encode permutations and data features. Although inference is in general hard, we show that for one very relevant application–document ranking–exact inference is efﬁcient. For general model instances, an appropriate sampler is readily available. Contrary to existing max-margin matching models, our approach is statistically consistent and, in addition, experiments with increasing sample sizes indicate superior improvement over such models. We apply the method to graph matching in computer vision as well as to a standard benchmark dataset for learning document ranking, in which we obtain state-of-the-art results, in particular improving on max-margin variants. The drawback of this method with respect to max-margin alternatives is its runtime for large graphs, which is comparatively high. 1</p><p>4 0.60829365 <a title="87-lda-4" href="./nips-2009-Learning_to_Rank_by_Optimizing_NDCG_Measure.html">136 nips-2009-Learning to Rank by Optimizing NDCG Measure</a></p>
<p>Author: Hamed Valizadegan, Rong Jin, Ruofei Zhang, Jianchang Mao</p><p>Abstract: Learning to rank is a relatively new ﬁeld of study, aiming to learn a ranking function from a set of training data with relevancy labels. The ranking algorithms are often evaluated using information retrieval measures, such as Normalized Discounted Cumulative Gain (NDCG) [1] and Mean Average Precision (MAP) [2]. Until recently, most learning to rank algorithms were not using a loss function related to the above mentioned evaluation measures. The main difﬁculty in direct optimization of these measures is that they depend on the ranks of documents, not the numerical values output by the ranking function. We propose a probabilistic framework that addresses this challenge by optimizing the expectation of NDCG over all the possible permutations of documents. A relaxation strategy is used to approximate the average of NDCG over the space of permutation, and a bound optimization approach is proposed to make the computation efﬁcient. Extensive experiments show that the proposed algorithm outperforms state-of-the-art ranking algorithms on several benchmark data sets. 1</p><p>5 0.59339315 <a title="87-lda-5" href="./nips-2009-Large_Scale_Nonparametric_Bayesian_Inference%3A_Data_Parallelisation_in_the_Indian_Buffet_Process.html">123 nips-2009-Large Scale Nonparametric Bayesian Inference: Data Parallelisation in the Indian Buffet Process</a></p>
<p>Author: Finale Doshi-velez, Shakir Mohamed, Zoubin Ghahramani, David A. Knowles</p><p>Abstract: Nonparametric Bayesian models provide a framework for ﬂexible probabilistic modelling of complex datasets. Unfortunately, the high-dimensional averages required for Bayesian methods can be slow, especially with the unbounded representations used by nonparametric models. We address the challenge of scaling Bayesian inference to the increasingly large datasets found in real-world applications. We focus on parallelisation of inference in the Indian Buffet Process (IBP), which allows data points to have an unbounded number of sparse latent features. Our novel MCMC sampler divides a large data set between multiple processors and uses message passing to compute the global likelihoods and posteriors. This algorithm, the ﬁrst parallel inference scheme for IBP-based models, scales to datasets orders of magnitude larger than have previously been possible. 1</p><p>6 0.58552998 <a title="87-lda-6" href="./nips-2009-Ranking_Measures_and_Loss_Functions_in_Learning_to_Rank.html">199 nips-2009-Ranking Measures and Loss Functions in Learning to Rank</a></p>
<p>7 0.58258379 <a title="87-lda-7" href="./nips-2009-Nonparametric_Latent_Feature_Models_for_Link_Prediction.html">174 nips-2009-Nonparametric Latent Feature Models for Link Prediction</a></p>
<p>8 0.5808261 <a title="87-lda-8" href="./nips-2009-Multi-Label_Prediction_via_Sparse_Infinite_CCA.html">158 nips-2009-Multi-Label Prediction via Sparse Infinite CCA</a></p>
<p>9 0.57666945 <a title="87-lda-9" href="./nips-2009-Sharing_Features_among_Dynamical_Systems_with_Beta_Processes.html">217 nips-2009-Sharing Features among Dynamical Systems with Beta Processes</a></p>
<p>10 0.57337666 <a title="87-lda-10" href="./nips-2009-An_Infinite_Factor_Model_Hierarchy_Via_a_Noisy-Or_Mechanism.html">29 nips-2009-An Infinite Factor Model Hierarchy Via a Noisy-Or Mechanism</a></p>
<p>11 0.5726319 <a title="87-lda-11" href="./nips-2009-Replicated_Softmax%3A_an_Undirected_Topic_Model.html">204 nips-2009-Replicated Softmax: an Undirected Topic Model</a></p>
<p>12 0.57152712 <a title="87-lda-12" href="./nips-2009-Statistical_Consistency_of_Top-k_Ranking.html">230 nips-2009-Statistical Consistency of Top-k Ranking</a></p>
<p>13 0.57050639 <a title="87-lda-13" href="./nips-2009-Semi-supervised_Learning_using_Sparse_Eigenfunction_Bases.html">213 nips-2009-Semi-supervised Learning using Sparse Eigenfunction Bases</a></p>
<p>14 0.5697155 <a title="87-lda-14" href="./nips-2009-Learning_in_Markov_Random_Fields_using_Tempered_Transitions.html">132 nips-2009-Learning in Markov Random Fields using Tempered Transitions</a></p>
<p>15 0.56865948 <a title="87-lda-15" href="./nips-2009-Multi-Label_Prediction_via_Compressed_Sensing.html">157 nips-2009-Multi-Label Prediction via Compressed Sensing</a></p>
<p>16 0.56788582 <a title="87-lda-16" href="./nips-2009-Semi-Supervised_Learning_in_Gigantic_Image_Collections.html">212 nips-2009-Semi-Supervised Learning in Gigantic Image Collections</a></p>
<p>17 0.56635183 <a title="87-lda-17" href="./nips-2009-Adaptive_Regularization_for_Transductive_Support_Vector_Machine.html">26 nips-2009-Adaptive Regularization for Transductive Support Vector Machine</a></p>
<p>18 0.56612116 <a title="87-lda-18" href="./nips-2009-Rethinking_LDA%3A_Why_Priors_Matter.html">205 nips-2009-Rethinking LDA: Why Priors Matter</a></p>
<p>19 0.5659129 <a title="87-lda-19" href="./nips-2009-Whose_Vote_Should_Count_More%3A_Optimal_Integration_of_Labels_from_Labelers_of_Unknown_Expertise.html">258 nips-2009-Whose Vote Should Count More: Optimal Integration of Labels from Labelers of Unknown Expertise</a></p>
<p>20 0.56584525 <a title="87-lda-20" href="./nips-2009-Decoupling_Sparsity_and_Smoothness_in_the_Discrete_Hierarchical_Dirichlet_Process.html">65 nips-2009-Decoupling Sparsity and Smoothness in the Discrete Hierarchical Dirichlet Process</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
