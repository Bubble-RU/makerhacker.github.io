<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>113 nips-2009-Improving Existing Fault Recovery Policies</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-113" href="#">nips2009-113</a> knowledge-graph by maker-knowledge-mining</p><h1>113 nips-2009-Improving Existing Fault Recovery Policies</h1>
<br/><p>Source: <a title="nips-2009-113-pdf" href="http://papers.nips.cc/paper/3877-improving-existing-fault-recovery-policies.pdf">pdf</a></p><p>Author: Guy Shani, Christopher Meek</p><p>Abstract: An automated recovery system is a key component in a large data center. Such a system typically employs a hand-made controller created by an expert. While such controllers capture many important aspects of the recovery process, they are often not systematically optimized to reduce costs such as server downtime. In this paper we describe a passive policy learning approach for improving existing recovery policies without exploration. We explain how to use data gathered from the interactions of the hand-made controller with the system, to create an improved controller. We suggest learning an indeÔ¨Ånite horizon Partially Observable Markov Decision Process, a model for decision making under uncertainty, and solve it using a point-based algorithm. We describe the complete process, starting with data gathering, model learning, model checking procedures, and computing a policy. 1</p><p>Reference: <a title="nips-2009-113-reference" href="../nips2009_reference/nips-2009-Improving_Existing_Fault_Recovery_Policies_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('policy', 0.593), ('repair', 0.454), ('pomdp', 0.399), ('esc', 0.315), ('hist', 0.152), ('execut', 0.125), ('cost', 0.116), ('recovery', 0.11), ('healthy', 0.089), ('sess', 0.083), ('perse', 0.083), ('watchdog', 0.079), ('reboot', 0.063), ('fail', 0.063), ('check', 0.054), ('josh', 0.05), ('autopilot', 0.047), ('act', 0.047), ('littm', 0.046), ('control', 0.044)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="113-tfidf-1" href="./nips-2009-Improving_Existing_Fault_Recovery_Policies.html">113 nips-2009-Improving Existing Fault Recovery Policies</a></p>
<p>2 0.26072568 <a title="113-tfidf-2" href="./nips-2009-The_Infinite_Partially_Observable_Markov_Decision_Process.html">242 nips-2009-The Infinite Partially Observable Markov Decision Process</a></p>
<p>3 0.24219503 <a title="113-tfidf-3" href="./nips-2009-Manifold_Embeddings_for_Model-Based_Reinforcement_Learning_under_Partial_Observability.html">145 nips-2009-Manifold Embeddings for Model-Based Reinforcement Learning under Partial Observability</a></p>
<p>4 0.21808131 <a title="113-tfidf-4" href="./nips-2009-Robust_Value_Function_Approximation_Using_Bilinear_Programming.html">209 nips-2009-Robust Value Function Approximation Using Bilinear Programming</a></p>
<p>5 0.17291214 <a title="113-tfidf-5" href="./nips-2009-A_Generalized_Natural_Actor-Critic_Algorithm.html">12 nips-2009-A Generalized Natural Actor-Critic Algorithm</a></p>
<p>6 0.16184586 <a title="113-tfidf-6" href="./nips-2009-Training_Factor_Graphs_with_Reinforcement_Learning_for_Efficient_MAP_Inference.html">250 nips-2009-Training Factor Graphs with Reinforcement Learning for Efficient MAP Inference</a></p>
<p>7 0.16120656 <a title="113-tfidf-7" href="./nips-2009-Learning_to_Explore_and_Exploit_in_POMDPs.html">134 nips-2009-Learning to Explore and Exploit in POMDPs</a></p>
<p>8 0.12782721 <a title="113-tfidf-8" href="./nips-2009-Skill_Discovery_in_Continuous_Reinforcement_Learning_Domains_using_Skill_Chaining.html">218 nips-2009-Skill Discovery in Continuous Reinforcement Learning Domains using Skill Chaining</a></p>
<p>9 0.11586405 <a title="113-tfidf-9" href="./nips-2009-Complexity_of_Decentralized_Control%3A_Special_Cases.html">53 nips-2009-Complexity of Decentralized Control: Special Cases</a></p>
<p>10 0.10731508 <a title="113-tfidf-10" href="./nips-2009-Convergent_Temporal-Difference_Learning_with_Arbitrary_Smooth_Function_Approximation.html">60 nips-2009-Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation</a></p>
<p>11 0.10463192 <a title="113-tfidf-11" href="./nips-2009-Solving_Stochastic_Games.html">221 nips-2009-Solving Stochastic Games</a></p>
<p>12 0.087337531 <a title="113-tfidf-12" href="./nips-2009-Multi-Step_Dyna_Planning_for_Policy_Evaluation_and_Control.html">159 nips-2009-Multi-Step Dyna Planning for Policy Evaluation and Control</a></p>
<p>13 0.076364182 <a title="113-tfidf-13" href="./nips-2009-A_Smoothed_Approximate_Linear_Program.html">16 nips-2009-A Smoothed Approximate Linear Program</a></p>
<p>14 0.066614233 <a title="113-tfidf-14" href="./nips-2009-Localizing_Bugs_in_Program_Executions_with_Graphical_Models.html">143 nips-2009-Localizing Bugs in Program Executions with Graphical Models</a></p>
<p>15 0.064374134 <a title="113-tfidf-15" href="./nips-2009-Breaking_Boundaries_Between_Induction_Time_and_Diagnosis_Time_Active_Information_Acquisition.html">49 nips-2009-Breaking Boundaries Between Induction Time and Diagnosis Time Active Information Acquisition</a></p>
<p>16 0.058004852 <a title="113-tfidf-16" href="./nips-2009-Monte_Carlo_Sampling_for_Regret_Minimization_in_Extensive_Games.html">156 nips-2009-Monte Carlo Sampling for Regret Minimization in Extensive Games</a></p>
<p>17 0.051518362 <a title="113-tfidf-17" href="./nips-2009-Bayesian_Belief_Polarization.html">39 nips-2009-Bayesian Belief Polarization</a></p>
<p>18 0.042247508 <a title="113-tfidf-18" href="./nips-2009-Compositionality_of_optimal_control_laws.html">54 nips-2009-Compositionality of optimal control laws</a></p>
<p>19 0.039749715 <a title="113-tfidf-19" href="./nips-2009-Thresholding_Procedures_for_High_Dimensional_Variable_Selection_and_Statistical_Estimation.html">245 nips-2009-Thresholding Procedures for High Dimensional Variable Selection and Statistical Estimation</a></p>
<p>20 0.037373487 <a title="113-tfidf-20" href="./nips-2009-Robust_Principal_Component_Analysis%3A_Exact_Recovery_of_Corrupted_Low-Rank_Matrices_via_Convex_Optimization.html">208 nips-2009-Robust Principal Component Analysis: Exact Recovery of Corrupted Low-Rank Matrices via Convex Optimization</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.124), (1, -0.004), (2, 0.098), (3, 0.184), (4, 0.304), (5, 0.25), (6, -0.058), (7, -0.008), (8, -0.045), (9, -0.05), (10, -0.105), (11, 0.066), (12, 0.063), (13, -0.0), (14, -0.0), (15, 0.001), (16, 0.003), (17, -0.053), (18, -0.024), (19, -0.084), (20, -0.138), (21, 0.097), (22, 0.012), (23, -0.095), (24, -0.09), (25, 0.039), (26, -0.198), (27, -0.094), (28, 0.004), (29, -0.035), (30, -0.028), (31, 0.021), (32, 0.063), (33, -0.047), (34, 0.006), (35, 0.017), (36, 0.037), (37, -0.036), (38, -0.062), (39, -0.019), (40, 0.075), (41, -0.019), (42, 0.036), (43, 0.034), (44, -0.077), (45, -0.014), (46, -0.083), (47, -0.009), (48, 0.085), (49, -0.038)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93550706 <a title="113-lsi-1" href="./nips-2009-Improving_Existing_Fault_Recovery_Policies.html">113 nips-2009-Improving Existing Fault Recovery Policies</a></p>
<p>2 0.84376681 <a title="113-lsi-2" href="./nips-2009-Manifold_Embeddings_for_Model-Based_Reinforcement_Learning_under_Partial_Observability.html">145 nips-2009-Manifold Embeddings for Model-Based Reinforcement Learning under Partial Observability</a></p>
<p>3 0.79341656 <a title="113-lsi-3" href="./nips-2009-A_Generalized_Natural_Actor-Critic_Algorithm.html">12 nips-2009-A Generalized Natural Actor-Critic Algorithm</a></p>
<p>4 0.78430682 <a title="113-lsi-4" href="./nips-2009-Robust_Value_Function_Approximation_Using_Bilinear_Programming.html">209 nips-2009-Robust Value Function Approximation Using Bilinear Programming</a></p>
<p>5 0.76063693 <a title="113-lsi-5" href="./nips-2009-Learning_to_Explore_and_Exploit_in_POMDPs.html">134 nips-2009-Learning to Explore and Exploit in POMDPs</a></p>
<p>6 0.67597151 <a title="113-lsi-6" href="./nips-2009-A_Smoothed_Approximate_Linear_Program.html">16 nips-2009-A Smoothed Approximate Linear Program</a></p>
<p>7 0.65508801 <a title="113-lsi-7" href="./nips-2009-Multi-Step_Dyna_Planning_for_Policy_Evaluation_and_Control.html">159 nips-2009-Multi-Step Dyna Planning for Policy Evaluation and Control</a></p>
<p>8 0.61870253 <a title="113-lsi-8" href="./nips-2009-Training_Factor_Graphs_with_Reinforcement_Learning_for_Efficient_MAP_Inference.html">250 nips-2009-Training Factor Graphs with Reinforcement Learning for Efficient MAP Inference</a></p>
<p>9 0.60887438 <a title="113-lsi-9" href="./nips-2009-Skill_Discovery_in_Continuous_Reinforcement_Learning_Domains_using_Skill_Chaining.html">218 nips-2009-Skill Discovery in Continuous Reinforcement Learning Domains using Skill Chaining</a></p>
<p>10 0.5152384 <a title="113-lsi-10" href="./nips-2009-Convergent_Temporal-Difference_Learning_with_Arbitrary_Smooth_Function_Approximation.html">60 nips-2009-Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation</a></p>
<p>11 0.47861183 <a title="113-lsi-11" href="./nips-2009-The_Infinite_Partially_Observable_Markov_Decision_Process.html">242 nips-2009-The Infinite Partially Observable Markov Decision Process</a></p>
<p>12 0.39342201 <a title="113-lsi-12" href="./nips-2009-Solving_Stochastic_Games.html">221 nips-2009-Solving Stochastic Games</a></p>
<p>13 0.36961621 <a title="113-lsi-13" href="./nips-2009-Complexity_of_Decentralized_Control%3A_Special_Cases.html">53 nips-2009-Complexity of Decentralized Control: Special Cases</a></p>
<p>14 0.29150069 <a title="113-lsi-14" href="./nips-2009-Breaking_Boundaries_Between_Induction_Time_and_Diagnosis_Time_Active_Information_Acquisition.html">49 nips-2009-Breaking Boundaries Between Induction Time and Diagnosis Time Active Information Acquisition</a></p>
<p>15 0.26385885 <a title="113-lsi-15" href="./nips-2009-Compositionality_of_optimal_control_laws.html">54 nips-2009-Compositionality of optimal control laws</a></p>
<p>16 0.244984 <a title="113-lsi-16" href="./nips-2009-Bayesian_Belief_Polarization.html">39 nips-2009-Bayesian Belief Polarization</a></p>
<p>17 0.24159479 <a title="113-lsi-17" href="./nips-2009-Randomized_Pruning%3A_Efficiently_Calculating_Expectations_in_Large_Dynamic_Programs.html">197 nips-2009-Randomized Pruning: Efficiently Calculating Expectations in Large Dynamic Programs</a></p>
<p>18 0.23416039 <a title="113-lsi-18" href="./nips-2009-Learning_Label_Embeddings_for_Nearest-Neighbor_Multi-class_Classification_with_an_Application_to_Speech_Recognition.html">127 nips-2009-Learning Label Embeddings for Nearest-Neighbor Multi-class Classification with an Application to Speech Recognition</a></p>
<p>19 0.23318549 <a title="113-lsi-19" href="./nips-2009-A_Parameter-free_Hedging_Algorithm.html">14 nips-2009-A Parameter-free Hedging Algorithm</a></p>
<p>20 0.22508535 <a title="113-lsi-20" href="./nips-2009-Localizing_Bugs_in_Program_Executions_with_Graphical_Models.html">143 nips-2009-Localizing Bugs in Program Executions with Graphical Models</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(9, 0.179), (11, 0.055), (24, 0.011), (27, 0.014), (31, 0.118), (34, 0.014), (37, 0.023), (60, 0.064), (89, 0.017), (90, 0.276), (96, 0.095)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.75597543 <a title="113-lda-1" href="./nips-2009-Factor_Modeling_for_Advertisement_Targeting.html">90 nips-2009-Factor Modeling for Advertisement Targeting</a></p>
<p>same-paper 2 0.73458081 <a title="113-lda-2" href="./nips-2009-Improving_Existing_Fault_Recovery_Policies.html">113 nips-2009-Improving Existing Fault Recovery Policies</a></p>
<p>3 0.71130568 <a title="113-lda-3" href="./nips-2009-Learning_with_Compressible_Priors.html">138 nips-2009-Learning with Compressible Priors</a></p>
<p>4 0.69957012 <a title="113-lda-4" href="./nips-2009-An_Online_Algorithm_for_Large_Scale_Image_Similarity_Learning.html">32 nips-2009-An Online Algorithm for Large Scale Image Similarity Learning</a></p>
<p>5 0.65207422 <a title="113-lda-5" href="./nips-2009-Adaptive_Regularization_for_Transductive_Support_Vector_Machine.html">26 nips-2009-Adaptive Regularization for Transductive Support Vector Machine</a></p>
<p>6 0.64627755 <a title="113-lda-6" href="./nips-2009-Manifold_Embeddings_for_Model-Based_Reinforcement_Learning_under_Partial_Observability.html">145 nips-2009-Manifold Embeddings for Model-Based Reinforcement Learning under Partial Observability</a></p>
<p>7 0.64327514 <a title="113-lda-7" href="./nips-2009-Learning_in_Markov_Random_Fields_using_Tempered_Transitions.html">132 nips-2009-Learning in Markov Random Fields using Tempered Transitions</a></p>
<p>8 0.64312351 <a title="113-lda-8" href="./nips-2009-Monte_Carlo_Sampling_for_Regret_Minimization_in_Extensive_Games.html">156 nips-2009-Monte Carlo Sampling for Regret Minimization in Extensive Games</a></p>
<p>9 0.64219522 <a title="113-lda-9" href="./nips-2009-Regularized_Distance_Metric_Learning%3ATheory_and_Algorithm.html">202 nips-2009-Regularized Distance Metric Learning:Theory and Algorithm</a></p>
<p>10 0.64182258 <a title="113-lda-10" href="./nips-2009-Maximum_likelihood_trajectories_for_continuous-time_Markov_chains.html">150 nips-2009-Maximum likelihood trajectories for continuous-time Markov chains</a></p>
<p>11 0.6416226 <a title="113-lda-11" href="./nips-2009-Kernels_and_learning_curves_for_Gaussian_process_regression_on_random_graphs.html">120 nips-2009-Kernels and learning curves for Gaussian process regression on random graphs</a></p>
<p>12 0.64087129 <a title="113-lda-12" href="./nips-2009-Bayesian_Source_Localization_with_the_Multivariate_Laplace_Prior.html">41 nips-2009-Bayesian Source Localization with the Multivariate Laplace Prior</a></p>
<p>13 0.63958693 <a title="113-lda-13" href="./nips-2009-Rank-Approximate_Nearest_Neighbor_Search%3A_Retaining_Meaning_and_Speed_in_High_Dimensions.html">198 nips-2009-Rank-Approximate Nearest Neighbor Search: Retaining Meaning and Speed in High Dimensions</a></p>
<p>14 0.6390729 <a title="113-lda-14" href="./nips-2009-Lattice_Regression.html">124 nips-2009-Lattice Regression</a></p>
<p>15 0.63863397 <a title="113-lda-15" href="./nips-2009-Learning_to_Explore_and_Exploit_in_POMDPs.html">134 nips-2009-Learning to Explore and Exploit in POMDPs</a></p>
<p>16 0.63704008 <a title="113-lda-16" href="./nips-2009-Conditional_Neural_Fields.html">56 nips-2009-Conditional Neural Fields</a></p>
<p>17 0.63580579 <a title="113-lda-17" href="./nips-2009-Speeding_up_Magnetic_Resonance_Image_Acquisition_by_Bayesian_Multi-Slice_Adaptive_Compressed_Sensing.html">228 nips-2009-Speeding up Magnetic Resonance Image Acquisition by Bayesian Multi-Slice Adaptive Compressed Sensing</a></p>
<p>18 0.63532442 <a title="113-lda-18" href="./nips-2009-Fast_subtree_kernels_on_graphs.html">95 nips-2009-Fast subtree kernels on graphs</a></p>
<p>19 0.63505888 <a title="113-lda-19" href="./nips-2009-Large_Scale_Nonparametric_Bayesian_Inference%3A_Data_Parallelisation_in_the_Indian_Buffet_Process.html">123 nips-2009-Large Scale Nonparametric Bayesian Inference: Data Parallelisation in the Indian Buffet Process</a></p>
<p>20 0.63474214 <a title="113-lda-20" href="./nips-2009-The_Infinite_Partially_Observable_Markov_Decision_Process.html">242 nips-2009-The Infinite Partially Observable Markov Decision Process</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
