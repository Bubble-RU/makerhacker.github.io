<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>50 nips-2009-Canonical Time Warping for Alignment of Human Behavior</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-50" href="#">nips2009-50</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>50 nips-2009-Canonical Time Warping for Alignment of Human Behavior</h1>
<br/><p>Source: <a title="nips-2009-50-pdf" href="http://papers.nips.cc/paper/3728-canonical-time-warping-for-alignment-of-human-behavior.pdf">pdf</a></p><p>Author: Feng Zhou, Fernando Torre</p><p>Abstract: Alignment of time series is an important problem to solve in many scientiﬁc disciplines. In particular, temporal alignment of two or more subjects performing similar activities is a challenging problem due to the large temporal scale difference between human actions as well as the inter/intra subject variability. In this paper we present canonical time warping (CTW), an extension of canonical correlation analysis (CCA) for spatio-temporal alignment of human motion between two subjects. CTW extends previous work on CCA in two ways: (i) it combines CCA with dynamic time warping (DTW), and (ii) it extends CCA by allowing local spatial deformations. We show CTW’s effectiveness in three experiments: alignment of synthetic data, alignment of motion capture data of two subjects performing similar actions, and alignment of similar facial expressions made by two people. Our results demonstrate that CTW provides both visually and qualitatively better alignment than state-of-the-art techniques based on DTW. 1</p><p>Reference: <a title="nips-2009-50-reference" href="../nips2009_reference/nips-2009-Canonical_Time_Warping_for_Alignment_of_Human_Behavior_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ctw', 0.382), ('vx', 0.372), ('vy', 0.372), ('align', 0.334), ('warp', 0.269), ('cca', 0.268), ('dtw', 0.218), ('wy', 0.202), ('wx', 0.18), ('nx', 0.162), ('jctw', 0.119), ('canon', 0.116), ('pt', 0.112), ('ry', 0.096), ('ky', 0.089), ('kx', 0.085), ('ny', 0.069), ('dy', 0.068), ('py', 0.067), ('rx', 0.062)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="50-tfidf-1" href="./nips-2009-Canonical_Time_Warping_for_Alignment_of_Human_Behavior.html">50 nips-2009-Canonical Time Warping for Alignment of Human Behavior</a></p>
<p>Author: Feng Zhou, Fernando Torre</p><p>Abstract: Alignment of time series is an important problem to solve in many scientiﬁc disciplines. In particular, temporal alignment of two or more subjects performing similar activities is a challenging problem due to the large temporal scale difference between human actions as well as the inter/intra subject variability. In this paper we present canonical time warping (CTW), an extension of canonical correlation analysis (CCA) for spatio-temporal alignment of human motion between two subjects. CTW extends previous work on CCA in two ways: (i) it combines CCA with dynamic time warping (DTW), and (ii) it extends CCA by allowing local spatial deformations. We show CTW’s effectiveness in three experiments: alignment of synthetic data, alignment of motion capture data of two subjects performing similar actions, and alignment of similar facial expressions made by two people. Our results demonstrate that CTW provides both visually and qualitatively better alignment than state-of-the-art techniques based on DTW. 1</p><p>2 0.323964 <a title="50-tfidf-2" href="./nips-2009-Multi-Label_Prediction_via_Sparse_Infinite_CCA.html">158 nips-2009-Multi-Label Prediction via Sparse Infinite CCA</a></p>
<p>Author: Piyush Rai, Hal Daume</p><p>Abstract: Canonical Correlation Analysis (CCA) is a useful technique for modeling dependencies between two (or more) sets of variables. Building upon the recently suggested probabilistic interpretation of CCA, we propose a nonparametric, fully Bayesian framework that can automatically select the number of correlation components, and effectively capture the sparsity underlying the projections. In addition, given (partially) labeled data, our algorithm can also be used as a (semi)supervised dimensionality reduction technique, and can be applied to learn useful predictive features in the context of learning a set of related tasks. Experimental results demonstrate the efﬁcacy of the proposed approach for both CCA as a stand-alone problem, and when applied to multi-label prediction. 1</p><p>3 0.18778864 <a title="50-tfidf-3" href="./nips-2009-fMRI-Based_Inter-Subject_Cortical_Alignment_Using_Functional_Connectivity.html">261 nips-2009-fMRI-Based Inter-Subject Cortical Alignment Using Functional Connectivity</a></p>
<p>Author: Bryan Conroy, Ben Singer, James Haxby, Peter J. Ramadge</p><p>Abstract: The inter-subject alignment of functional MRI (fMRI) data is important for improving the statistical power of fMRI group analyses. In contrast to existing anatomically-based methods, we propose a novel multi-subject algorithm that derives a functional correspondence by aligning spatial patterns of functional connectivity across a set of subjects. We test our method on fMRI data collected during a movie viewing experiment. By cross-validating the results of our algorithm, we show that the correspondence successfully generalizes to a secondary movie dataset not used to derive the alignment. 1</p><p>4 0.15952909 <a title="50-tfidf-4" href="./nips-2009-Bilinear_classifiers_for_visual_recognition.html">46 nips-2009-Bilinear classifiers for visual recognition</a></p>
<p>Author: Hamed Pirsiavash, Deva Ramanan, Charless C. Fowlkes</p><p>Abstract: We describe an algorithm for learning bilinear SVMs. Bilinear classiﬁers are a discriminative variant of bilinear models, which capture the dependence of data on multiple factors. Such models are particularly appropriate for visual data that is better represented as a matrix or tensor, rather than a vector. Matrix encodings allow for more natural regularization through rank restriction. For example, a rank-one scanning-window classiﬁer yields a separable ﬁlter. Low-rank models have fewer parameters and so are easier to regularize and faster to score at run-time. We learn low-rank models with bilinear classiﬁers. We also use bilinear classiﬁers for transfer learning by sharing linear factors between different classiﬁcation tasks. Bilinear classiﬁers are trained with biconvex programs. Such programs are optimized with coordinate descent, where each coordinate step requires solving a convex program - in our case, we use a standard off-the-shelf SVM solver. We demonstrate bilinear SVMs on difﬁcult problems of people detection in video sequences and action classiﬁcation of video sequences, achieving state-of-the-art results in both. 1</p><p>5 0.13726141 <a title="50-tfidf-5" href="./nips-2009-Estimating_image_bases_for_visual_image_reconstruction_from_human_brain_activity.html">83 nips-2009-Estimating image bases for visual image reconstruction from human brain activity</a></p>
<p>Author: Yusuke Fujiwara, Yoichi Miyawaki, Yukiyasu Kamitani</p><p>Abstract: Image representation based on image bases provides a framework for understanding neural representation of visual perception. A recent fMRI study has shown that arbitrary contrast-deﬁned visual images can be reconstructed from fMRI activity patterns using a combination of multi-scale local image bases. In the reconstruction model, the mapping from an fMRI activity pattern to the contrasts of the image bases was learned from measured fMRI responses to visual images. But the shapes of the images bases were ﬁxed, and thus may not be optimal for reconstruction. Here, we propose a method to build a reconstruction model in which image bases are automatically extracted from the measured data. We constructed a probabilistic model that relates the fMRI activity space to the visual image space via a set of latent variables. The mapping from the latent variables to the visual image space can be regarded as a set of image bases. We found that spatially localized, multi-scale image bases were estimated near the fovea, and that the model using the estimated image bases was able to accurately reconstruct novel visual images. The proposed method provides a means to discover a novel functional mapping between stimuli and brain activity patterns.</p><p>6 0.075764976 <a title="50-tfidf-6" href="./nips-2009-A_Sparse_Non-Parametric_Approach_for_Single_Channel_Separation_of_Known_Sounds.html">17 nips-2009-A Sparse Non-Parametric Approach for Single Channel Separation of Known Sounds</a></p>
<p>7 0.072175972 <a title="50-tfidf-7" href="./nips-2009-Asymptotically_Optimal_Regularization_in_Smooth_Parametric_Models.html">37 nips-2009-Asymptotically Optimal Regularization in Smooth Parametric Models</a></p>
<p>8 0.06363973 <a title="50-tfidf-8" href="./nips-2009-Constructing_Topological_Maps_using_Markov_Random_Fields_and_Loop-Closure_Detection.html">58 nips-2009-Constructing Topological Maps using Markov Random Fields and Loop-Closure Detection</a></p>
<p>9 0.059293527 <a title="50-tfidf-9" href="./nips-2009-Structured_output_regression_for_detection_with_partial_truncation.html">236 nips-2009-Structured output regression for detection with partial truncation</a></p>
<p>10 0.055721462 <a title="50-tfidf-10" href="./nips-2009-Indian_Buffet_Processes_with_Power-law_Behavior.html">114 nips-2009-Indian Buffet Processes with Power-law Behavior</a></p>
<p>11 0.055106524 <a title="50-tfidf-11" href="./nips-2009-Segmenting_Scenes_by_Matching_Image_Composites.html">211 nips-2009-Segmenting Scenes by Matching Image Composites</a></p>
<p>12 0.052630663 <a title="50-tfidf-12" href="./nips-2009-Variational_Gaussian-process_factor_analysis_for_modeling_spatio-temporal_data.html">254 nips-2009-Variational Gaussian-process factor analysis for modeling spatio-temporal data</a></p>
<p>13 0.050283037 <a title="50-tfidf-13" href="./nips-2009-Abstraction_and_Relational_learning.html">21 nips-2009-Abstraction and Relational learning</a></p>
<p>14 0.039023627 <a title="50-tfidf-14" href="./nips-2009-Learning_transport_operators_for_image_manifolds.html">137 nips-2009-Learning transport operators for image manifolds</a></p>
<p>15 0.0365716 <a title="50-tfidf-15" href="./nips-2009-Learning_models_of_object_structure.html">133 nips-2009-Learning models of object structure</a></p>
<p>16 0.035947375 <a title="50-tfidf-16" href="./nips-2009-Construction_of_Nonparametric_Bayesian_Models_from_Parametric_Bayes_Equations.html">59 nips-2009-Construction of Nonparametric Bayesian Models from Parametric Bayes Equations</a></p>
<p>17 0.035794374 <a title="50-tfidf-17" href="./nips-2009-Training_Factor_Graphs_with_Reinforcement_Learning_for_Efficient_MAP_Inference.html">250 nips-2009-Training Factor Graphs with Reinforcement Learning for Efficient MAP Inference</a></p>
<p>18 0.034863651 <a title="50-tfidf-18" href="./nips-2009-Augmenting_Feature-driven_fMRI_Analyses%3A_Semi-supervised_learning_and_resting_state_activity.html">38 nips-2009-Augmenting Feature-driven fMRI Analyses: Semi-supervised learning and resting state activity</a></p>
<p>19 0.034757707 <a title="50-tfidf-19" href="./nips-2009-Sharing_Features_among_Dynamical_Systems_with_Beta_Processes.html">217 nips-2009-Sharing Features among Dynamical Systems with Beta Processes</a></p>
<p>20 0.034392882 <a title="50-tfidf-20" href="./nips-2009-Matrix_Completion_from_Noisy_Entries.html">147 nips-2009-Matrix Completion from Noisy Entries</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.109), (1, 0.008), (2, -0.04), (3, 0.031), (4, -0.027), (5, 0.052), (6, 0.018), (7, -0.05), (8, 0.015), (9, -0.046), (10, -0.061), (11, 0.068), (12, 0.12), (13, 0.06), (14, -0.039), (15, 0.212), (16, -0.077), (17, 0.355), (18, -0.012), (19, -0.085), (20, -0.208), (21, 0.088), (22, 0.079), (23, 0.044), (24, -0.064), (25, 0.066), (26, 0.168), (27, -0.103), (28, 0.034), (29, 0.118), (30, 0.05), (31, 0.042), (32, -0.252), (33, 0.126), (34, -0.076), (35, 0.165), (36, 0.047), (37, -0.004), (38, 0.018), (39, -0.029), (40, 0.076), (41, 0.091), (42, -0.015), (43, -0.04), (44, 0.022), (45, 0.058), (46, -0.12), (47, -0.004), (48, -0.09), (49, -0.102)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95467454 <a title="50-lsi-1" href="./nips-2009-Canonical_Time_Warping_for_Alignment_of_Human_Behavior.html">50 nips-2009-Canonical Time Warping for Alignment of Human Behavior</a></p>
<p>Author: Feng Zhou, Fernando Torre</p><p>Abstract: Alignment of time series is an important problem to solve in many scientiﬁc disciplines. In particular, temporal alignment of two or more subjects performing similar activities is a challenging problem due to the large temporal scale difference between human actions as well as the inter/intra subject variability. In this paper we present canonical time warping (CTW), an extension of canonical correlation analysis (CCA) for spatio-temporal alignment of human motion between two subjects. CTW extends previous work on CCA in two ways: (i) it combines CCA with dynamic time warping (DTW), and (ii) it extends CCA by allowing local spatial deformations. We show CTW’s effectiveness in three experiments: alignment of synthetic data, alignment of motion capture data of two subjects performing similar actions, and alignment of similar facial expressions made by two people. Our results demonstrate that CTW provides both visually and qualitatively better alignment than state-of-the-art techniques based on DTW. 1</p><p>2 0.67479014 <a title="50-lsi-2" href="./nips-2009-Multi-Label_Prediction_via_Sparse_Infinite_CCA.html">158 nips-2009-Multi-Label Prediction via Sparse Infinite CCA</a></p>
<p>Author: Piyush Rai, Hal Daume</p><p>Abstract: Canonical Correlation Analysis (CCA) is a useful technique for modeling dependencies between two (or more) sets of variables. Building upon the recently suggested probabilistic interpretation of CCA, we propose a nonparametric, fully Bayesian framework that can automatically select the number of correlation components, and effectively capture the sparsity underlying the projections. In addition, given (partially) labeled data, our algorithm can also be used as a (semi)supervised dimensionality reduction technique, and can be applied to learn useful predictive features in the context of learning a set of related tasks. Experimental results demonstrate the efﬁcacy of the proposed approach for both CCA as a stand-alone problem, and when applied to multi-label prediction. 1</p><p>3 0.4477872 <a title="50-lsi-3" href="./nips-2009-Bilinear_classifiers_for_visual_recognition.html">46 nips-2009-Bilinear classifiers for visual recognition</a></p>
<p>Author: Hamed Pirsiavash, Deva Ramanan, Charless C. Fowlkes</p><p>Abstract: We describe an algorithm for learning bilinear SVMs. Bilinear classiﬁers are a discriminative variant of bilinear models, which capture the dependence of data on multiple factors. Such models are particularly appropriate for visual data that is better represented as a matrix or tensor, rather than a vector. Matrix encodings allow for more natural regularization through rank restriction. For example, a rank-one scanning-window classiﬁer yields a separable ﬁlter. Low-rank models have fewer parameters and so are easier to regularize and faster to score at run-time. We learn low-rank models with bilinear classiﬁers. We also use bilinear classiﬁers for transfer learning by sharing linear factors between different classiﬁcation tasks. Bilinear classiﬁers are trained with biconvex programs. Such programs are optimized with coordinate descent, where each coordinate step requires solving a convex program - in our case, we use a standard off-the-shelf SVM solver. We demonstrate bilinear SVMs on difﬁcult problems of people detection in video sequences and action classiﬁcation of video sequences, achieving state-of-the-art results in both. 1</p><p>4 0.41437572 <a title="50-lsi-4" href="./nips-2009-fMRI-Based_Inter-Subject_Cortical_Alignment_Using_Functional_Connectivity.html">261 nips-2009-fMRI-Based Inter-Subject Cortical Alignment Using Functional Connectivity</a></p>
<p>Author: Bryan Conroy, Ben Singer, James Haxby, Peter J. Ramadge</p><p>Abstract: The inter-subject alignment of functional MRI (fMRI) data is important for improving the statistical power of fMRI group analyses. In contrast to existing anatomically-based methods, we propose a novel multi-subject algorithm that derives a functional correspondence by aligning spatial patterns of functional connectivity across a set of subjects. We test our method on fMRI data collected during a movie viewing experiment. By cross-validating the results of our algorithm, we show that the correspondence successfully generalizes to a secondary movie dataset not used to derive the alignment. 1</p><p>5 0.38010907 <a title="50-lsi-5" href="./nips-2009-Estimating_image_bases_for_visual_image_reconstruction_from_human_brain_activity.html">83 nips-2009-Estimating image bases for visual image reconstruction from human brain activity</a></p>
<p>Author: Yusuke Fujiwara, Yoichi Miyawaki, Yukiyasu Kamitani</p><p>Abstract: Image representation based on image bases provides a framework for understanding neural representation of visual perception. A recent fMRI study has shown that arbitrary contrast-deﬁned visual images can be reconstructed from fMRI activity patterns using a combination of multi-scale local image bases. In the reconstruction model, the mapping from an fMRI activity pattern to the contrasts of the image bases was learned from measured fMRI responses to visual images. But the shapes of the images bases were ﬁxed, and thus may not be optimal for reconstruction. Here, we propose a method to build a reconstruction model in which image bases are automatically extracted from the measured data. We constructed a probabilistic model that relates the fMRI activity space to the visual image space via a set of latent variables. The mapping from the latent variables to the visual image space can be regarded as a set of image bases. We found that spatially localized, multi-scale image bases were estimated near the fovea, and that the model using the estimated image bases was able to accurately reconstruct novel visual images. The proposed method provides a means to discover a novel functional mapping between stimuli and brain activity patterns.</p><p>6 0.21078628 <a title="50-lsi-6" href="./nips-2009-Probabilistic_Relational_PCA.html">195 nips-2009-Probabilistic Relational PCA</a></p>
<p>7 0.20680535 <a title="50-lsi-7" href="./nips-2009-Abstraction_and_Relational_learning.html">21 nips-2009-Abstraction and Relational learning</a></p>
<p>8 0.20592283 <a title="50-lsi-8" href="./nips-2009-Indian_Buffet_Processes_with_Power-law_Behavior.html">114 nips-2009-Indian Buffet Processes with Power-law Behavior</a></p>
<p>9 0.17337322 <a title="50-lsi-9" href="./nips-2009-Constructing_Topological_Maps_using_Markov_Random_Fields_and_Loop-Closure_Detection.html">58 nips-2009-Constructing Topological Maps using Markov Random Fields and Loop-Closure Detection</a></p>
<p>10 0.17250592 <a title="50-lsi-10" href="./nips-2009-Structured_output_regression_for_detection_with_partial_truncation.html">236 nips-2009-Structured output regression for detection with partial truncation</a></p>
<p>11 0.17040917 <a title="50-lsi-11" href="./nips-2009-Dirichlet-Bernoulli_Alignment%3A_A_Generative_Model_for_Multi-Class_Multi-Label_Multi-Instance_Corpora.html">68 nips-2009-Dirichlet-Bernoulli Alignment: A Generative Model for Multi-Class Multi-Label Multi-Instance Corpora</a></p>
<p>12 0.15833437 <a title="50-lsi-12" href="./nips-2009-The_Ordered_Residual_Kernel_for_Robust_Motion_Subspace_Clustering.html">243 nips-2009-The Ordered Residual Kernel for Robust Motion Subspace Clustering</a></p>
<p>13 0.15606214 <a title="50-lsi-13" href="./nips-2009-Variational_Gaussian-process_factor_analysis_for_modeling_spatio-temporal_data.html">254 nips-2009-Variational Gaussian-process factor analysis for modeling spatio-temporal data</a></p>
<p>14 0.15522516 <a title="50-lsi-14" href="./nips-2009-Heterogeneous_multitask_learning_with_joint_sparsity_constraints.html">108 nips-2009-Heterogeneous multitask learning with joint sparsity constraints</a></p>
<p>15 0.15355639 <a title="50-lsi-15" href="./nips-2009-Replacing_supervised_classification_learning_by_Slow_Feature_Analysis_in_spiking_neural_networks.html">203 nips-2009-Replacing supervised classification learning by Slow Feature Analysis in spiking neural networks</a></p>
<p>16 0.15323153 <a title="50-lsi-16" href="./nips-2009-Skill_Discovery_in_Continuous_Reinforcement_Learning_Domains_using_Skill_Chaining.html">218 nips-2009-Skill Discovery in Continuous Reinforcement Learning Domains using Skill Chaining</a></p>
<p>17 0.14944288 <a title="50-lsi-17" href="./nips-2009-Learning_transport_operators_for_image_manifolds.html">137 nips-2009-Learning transport operators for image manifolds</a></p>
<p>18 0.14937547 <a title="50-lsi-18" href="./nips-2009-Asymptotically_Optimal_Regularization_in_Smooth_Parametric_Models.html">37 nips-2009-Asymptotically Optimal Regularization in Smooth Parametric Models</a></p>
<p>19 0.14367627 <a title="50-lsi-19" href="./nips-2009-Convergent_Temporal-Difference_Learning_with_Arbitrary_Smooth_Function_Approximation.html">60 nips-2009-Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation</a></p>
<p>20 0.14362626 <a title="50-lsi-20" href="./nips-2009-Robust_Value_Function_Approximation_Using_Bilinear_Programming.html">209 nips-2009-Robust Value Function Approximation Using Bilinear Programming</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(9, 0.162), (11, 0.023), (20, 0.524), (31, 0.045), (37, 0.012), (60, 0.048), (89, 0.011), (96, 0.05)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.66445076 <a title="50-lda-1" href="./nips-2009-Canonical_Time_Warping_for_Alignment_of_Human_Behavior.html">50 nips-2009-Canonical Time Warping for Alignment of Human Behavior</a></p>
<p>Author: Feng Zhou, Fernando Torre</p><p>Abstract: Alignment of time series is an important problem to solve in many scientiﬁc disciplines. In particular, temporal alignment of two or more subjects performing similar activities is a challenging problem due to the large temporal scale difference between human actions as well as the inter/intra subject variability. In this paper we present canonical time warping (CTW), an extension of canonical correlation analysis (CCA) for spatio-temporal alignment of human motion between two subjects. CTW extends previous work on CCA in two ways: (i) it combines CCA with dynamic time warping (DTW), and (ii) it extends CCA by allowing local spatial deformations. We show CTW’s effectiveness in three experiments: alignment of synthetic data, alignment of motion capture data of two subjects performing similar actions, and alignment of similar facial expressions made by two people. Our results demonstrate that CTW provides both visually and qualitatively better alignment than state-of-the-art techniques based on DTW. 1</p><p>2 0.54918134 <a title="50-lda-2" href="./nips-2009-Speaker_Comparison_with_Inner_Product_Discriminant_Functions.html">227 nips-2009-Speaker Comparison with Inner Product Discriminant Functions</a></p>
<p>Author: Zahi Karam, Douglas Sturim, William M. Campbell</p><p>Abstract: Speaker comparison, the process of ﬁnding the speaker similarity between two speech signals, occupies a central role in a variety of applications—speaker veriﬁcation, clustering, and identiﬁcation. Speaker comparison can be placed in a geometric framework by casting the problem as a model comparison process. For a given speech signal, feature vectors are produced and used to adapt a Gaussian mixture model (GMM). Speaker comparison can then be viewed as the process of compensating and ﬁnding metrics on the space of adapted models. We propose a framework, inner product discriminant functions (IPDFs), which extends many common techniques for speaker comparison—support vector machines, joint factor analysis, and linear scoring. The framework uses inner products between the parameter vectors of GMM models motivated by several statistical methods. Compensation of nuisances is performed via linear transforms on GMM parameter vectors. Using the IPDF framework, we show that many current techniques are simple variations of each other. We demonstrate, on a 2006 NIST speaker recognition evaluation task, new scoring methods using IPDFs which produce excellent error rates and require signiﬁcantly less computation than current techniques.</p><p>3 0.39394155 <a title="50-lda-3" href="./nips-2009-Efficient_Learning_using_Forward-Backward_Splitting.html">76 nips-2009-Efficient Learning using Forward-Backward Splitting</a></p>
<p>Author: Yoram Singer, John C. Duchi</p><p>Abstract: We describe, analyze, and experiment with a new framework for empirical loss minimization with regularization. Our algorithmic framework alternates between two phases. On each iteration we ﬁrst perform an unconstrained gradient descent step. We then cast and solve an instantaneous optimization problem that trades off minimization of a regularization term while keeping close proximity to the result of the ﬁrst phase. This yields a simple yet effective algorithm for both batch penalized risk minimization and online learning. Furthermore, the two phase approach enables sparse solutions when used in conjunction with regularization functions that promote sparsity, such as ℓ1 . We derive concrete and very simple algorithms for minimization of loss functions with ℓ1 , ℓ2 , ℓ2 , and ℓ∞ regularization. We 2 also show how to construct efﬁcient algorithms for mixed-norm ℓ1 /ℓq regularization. We further extend the algorithms and give efﬁcient implementations for very high-dimensional data with sparsity. We demonstrate the potential of the proposed framework in experiments with synthetic and natural datasets. 1</p><p>4 0.32829925 <a title="50-lda-4" href="./nips-2009-Help_or_Hinder%3A_Bayesian_Models_of_Social_Goal_Inference.html">107 nips-2009-Help or Hinder: Bayesian Models of Social Goal Inference</a></p>
<p>Author: Tomer Ullman, Chris Baker, Owen Macindoe, Owain Evans, Noah Goodman, Joshua B. Tenenbaum</p><p>Abstract: Everyday social interactions are heavily inﬂuenced by our snap judgments about others’ goals. Even young infants can infer the goals of intentional agents from observing how they interact with objects and other agents in their environment: e.g., that one agent is ‘helping’ or ‘hindering’ another’s attempt to get up a hill or open a box. We propose a model for how people can infer these social goals from actions, based on inverse planning in multiagent Markov decision problems (MDPs). The model infers the goal most likely to be driving an agent’s behavior by assuming the agent acts approximately rationally given environmental constraints and its model of other agents present. We also present behavioral evidence in support of this model over a simpler, perceptual cue-based alternative. 1</p><p>5 0.32782966 <a title="50-lda-5" href="./nips-2009-Multi-Label_Prediction_via_Compressed_Sensing.html">157 nips-2009-Multi-Label Prediction via Compressed Sensing</a></p>
<p>Author: John Langford, Tong Zhang, Daniel J. Hsu, Sham M. Kakade</p><p>Abstract: We consider multi-label prediction problems with large output spaces under the assumption of output sparsity – that the target (label) vectors have small support. We develop a general theory for a variant of the popular error correcting output code scheme, using ideas from compressed sensing for exploiting this sparsity. The method can be regarded as a simple reduction from multi-label regression problems to binary regression problems. We show that the number of subproblems need only be logarithmic in the total number of possible labels, making this approach radically more efﬁcient than others. We also state and prove robustness guarantees for this method in the form of regret transform bounds (in general), and also provide a more detailed analysis for the linear prediction setting. 1</p><p>6 0.32775331 <a title="50-lda-6" href="./nips-2009-Distribution-Calibrated_Hierarchical_Classification.html">71 nips-2009-Distribution-Calibrated Hierarchical Classification</a></p>
<p>7 0.32747379 <a title="50-lda-7" href="./nips-2009-Adapting_to_the_Shifting_Intent_of_Search_Queries.html">24 nips-2009-Adapting to the Shifting Intent of Search Queries</a></p>
<p>8 0.32729679 <a title="50-lda-8" href="./nips-2009-On_Stochastic_and_Worst-case_Models_for_Investing.html">178 nips-2009-On Stochastic and Worst-case Models for Investing</a></p>
<p>9 0.32723555 <a title="50-lda-9" href="./nips-2009-Large_Scale_Nonparametric_Bayesian_Inference%3A_Data_Parallelisation_in_the_Indian_Buffet_Process.html">123 nips-2009-Large Scale Nonparametric Bayesian Inference: Data Parallelisation in the Indian Buffet Process</a></p>
<p>10 0.32716596 <a title="50-lda-10" href="./nips-2009-Slow_Learners_are_Fast.html">220 nips-2009-Slow Learners are Fast</a></p>
<p>11 0.32708979 <a title="50-lda-11" href="./nips-2009-Label_Selection_on_Graphs.html">122 nips-2009-Label Selection on Graphs</a></p>
<p>12 0.32707703 <a title="50-lda-12" href="./nips-2009-Time-Varying_Dynamic_Bayesian_Networks.html">246 nips-2009-Time-Varying Dynamic Bayesian Networks</a></p>
<p>13 0.32692075 <a title="50-lda-13" href="./nips-2009-Multiple_Incremental_Decremental_Learning_of_Support_Vector_Machines.html">160 nips-2009-Multiple Incremental Decremental Learning of Support Vector Machines</a></p>
<p>14 0.32680571 <a title="50-lda-14" href="./nips-2009-Variational_Gaussian-process_factor_analysis_for_modeling_spatio-temporal_data.html">254 nips-2009-Variational Gaussian-process factor analysis for modeling spatio-temporal data</a></p>
<p>15 0.32678261 <a title="50-lda-15" href="./nips-2009-Breaking_Boundaries_Between_Induction_Time_and_Diagnosis_Time_Active_Information_Acquisition.html">49 nips-2009-Breaking Boundaries Between Induction Time and Diagnosis Time Active Information Acquisition</a></p>
<p>16 0.32662648 <a title="50-lda-16" href="./nips-2009-Robust_Principal_Component_Analysis%3A_Exact_Recovery_of_Corrupted_Low-Rank_Matrices_via_Convex_Optimization.html">208 nips-2009-Robust Principal Component Analysis: Exact Recovery of Corrupted Low-Rank Matrices via Convex Optimization</a></p>
<p>17 0.32657176 <a title="50-lda-17" href="./nips-2009-A_Bayesian_Analysis_of_Dynamics_in_Free_Recall.html">4 nips-2009-A Bayesian Analysis of Dynamics in Free Recall</a></p>
<p>18 0.32650083 <a title="50-lda-18" href="./nips-2009-Gaussian_process_regression_with_Student-t_likelihood.html">100 nips-2009-Gaussian process regression with Student-t likelihood</a></p>
<p>19 0.32647422 <a title="50-lda-19" href="./nips-2009-Structured_output_regression_for_detection_with_partial_truncation.html">236 nips-2009-Structured output regression for detection with partial truncation</a></p>
<p>20 0.32644266 <a title="50-lda-20" href="./nips-2009-Conditional_Random_Fields_with_High-Order_Features_for_Sequence_Labeling.html">57 nips-2009-Conditional Random Fields with High-Order Features for Sequence Labeling</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
