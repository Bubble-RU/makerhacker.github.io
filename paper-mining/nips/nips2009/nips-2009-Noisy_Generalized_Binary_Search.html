<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>166 nips-2009-Noisy Generalized Binary Search</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-166" href="#">nips2009-166</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>166 nips-2009-Noisy Generalized Binary Search</h1>
<br/><p>Source: <a title="nips-2009-166-pdf" href="http://papers.nips.cc/paper/3721-noisy-generalized-binary-search.pdf">pdf</a></p><p>Author: Robert Nowak</p><p>Abstract: This paper addresses the problem of noisy Generalized Binary Search (GBS). GBS is a well-known greedy algorithm for determining a binary-valued hypothesis through a sequence of strategically selected queries. At each step, a query is selected that most evenly splits the hypotheses under consideration into two disjoint subsets, a natural generalization of the idea underlying classic binary search. GBS is used in many applications, including fault testing, machine diagnostics, disease diagnosis, job scheduling, image processing, computer vision, and active learning. In most of these cases, the responses to queries can be noisy. Past work has provided a partial characterization of GBS, but existing noise-tolerant versions of GBS are suboptimal in terms of query complexity. This paper presents an optimal algorithm for noisy GBS and demonstrates its application to learning multidimensional threshold functions. 1</p><p>Reference: <a title="nips-2009-166-reference" href="../nips2009_reference/nips-2009-Noisy_Generalized_Binary_Search_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 GBS is a well-known greedy algorithm for determining a binary-valued hypothesis through a sequence of strategically selected queries. [sent-4, score-0.268]
</p><p>2 At each step, a query is selected that most evenly splits the hypotheses under consideration into two disjoint subsets, a natural generalization of the idea underlying classic binary search. [sent-5, score-0.561]
</p><p>3 In most of these cases, the responses to queries can be noisy. [sent-7, score-0.221]
</p><p>4 Past work has provided a partial characterization of GBS, but existing noise-tolerant versions of GBS are suboptimal in terms of query complexity. [sent-8, score-0.308]
</p><p>5 This paper presents an optimal algorithm for noisy GBS and demonstrates its application to learning multidimensional threshold functions. [sent-9, score-0.248]
</p><p>6 In this paper, H will be called the hypothesis space and X will be called the query space. [sent-12, score-0.37]
</p><p>7 The goal is to determine h∗ through as few queries from X as possible. [sent-15, score-0.2]
</p><p>8 For each query x ∈ X , the value h∗ (x), corrupted with independently distributed binary noise, is observed. [sent-16, score-0.339]
</p><p>9 If the queries were noiseless, then they are usually called membership queries to distinguish them from other types of queries [Ang01]; here we will simply refer to them as queries. [sent-17, score-0.6]
</p><p>10 However, there exists a greedy procedure that yields query sequences that are within an O(log |H|) factor of the optimal search tree depth [GG74, KPB99, Lov85, AMM+ 98, Das04], where |H| denotes the cardinality of H. [sent-22, score-0.434]
</p><p>11 The greedy procedure is referred to as Generalized Binary Search (GBS) [Das04, Now08] or the splitting algorithm [KPB99, Lov85, GG74]), and it reduces to classic binary search in special cases [Now08]. [sent-23, score-0.263]
</p><p>12 At each step GBS selects a query that results in the most even split of the hypotheses under consideration into two subsets responding +1 and −1, respectively, to the query. [sent-25, score-0.395]
</p><p>13 The correct response to the query eliminates one of these two subsets from further consideration. [sent-26, score-0.346]
</p><p>14 Since the hypotheses are assumed to be distinct, it is clear that GBS terminates in at most |H| queries (since it is always possible to ﬁnd query that eliminates at least 1  Noisy Generalized Binary Search (NGBS) initialize: p0 uniform over H. [sent-27, score-0.583]
</p><p>15 hypothesis selected at each step: hi := arg maxh∈H pi (h)  (a)  (b)  Figure 1: Generalized binary search (GBS) algorithm and a noise-tolerant variant (NGBS). [sent-39, score-0.85]
</p><p>16 In general, the number of queries required can be bounded in terms of a combinatorial parameter of H called the extended teaching dimension [Ang01, Heg95] (also see [HPRW96] for related work). [sent-43, score-0.226]
</p><p>17 Alternatively, there exists a geometric relation between the pair (X , H), called the neighborly condition, that is sufﬁcient to bound the number of queries needed [Now08]. [sent-44, score-0.439]
</p><p>18 In many (if not most) applications it is unrealistic to assume that the responses to queries are without error. [sent-46, score-0.221]
</p><p>19 Noise-tolerant versions of classic binary search have been well-studied. [sent-47, score-0.235]
</p><p>20 The classic binary search problem is equivalent to learning a one-dimensional binary-valued threshold function by selecting point evaluations of the function according to a bisection procedure. [sent-48, score-0.281]
</p><p>21 A noisy version of classic binary search was studied ﬁrst in the context of channel coding with feedback [Hor63]. [sent-49, score-0.327]
</p><p>22 The idea is to follow the GBS algorithm, but to repeat the query at each step multiple times in order to decide whether the response is more probably +1 or −1. [sent-52, score-0.324]
</p><p>23 The strategy of repeating queries has been suggested as a general approach for devising noise-tolerant learning algorithms [K¨ a06]. [sent-53, score-0.2]
</p><p>24 This simple approach has been a¨ studied in the context of noisy versions of classic binary search and shown to be suboptimal [KK07]. [sent-54, score-0.354]
</p><p>25 Since classic binary search is a special case of the general problem, it follows immediately that the approach proposed in [Now08] is suboptimal. [sent-55, score-0.217]
</p><p>26 The number of queries an algorithm requires to conﬁdently identify h∗ is called the query complexity of the algorithm. [sent-58, score-0.513]
</p><p>27 The query complexity of the new algorithm is optimal, and we are not aware of any other algorithm with this capability. [sent-59, score-0.335]
</p><p>28 It is also shown that optimal convergence rate and query complexity is achieved for a broad class of geometrical hypotheses arising in image recovery and binary classiﬁcation. [sent-60, score-0.489]
</p><p>29 We show that our algorithm achieves the optimal query complexity for actively learning multidimensional threshold functions in noisy conditions. [sent-63, score-0.539]
</p><p>30 Speciﬁcally, assume that the binary response y ∈ {−1, 1} to each query x ∈ X is an independent realization of the random variable Y satisfying P(Y = h∗ (x)) > P(Y = −h∗ (x)), where h∗ ∈ H is ﬁxed but unknown. [sent-70, score-0.401]
</p><p>31 If a query x is repeated more than once, then each response is 2  an independent realization of Y . [sent-72, score-0.304]
</p><p>32 Deﬁne the noise-level for the query x as αx := P(Y = −h∗ (x)). [sent-73, score-0.265]
</p><p>33 The measure p0 can be viewed as an initial weighting over the hypothesis class, expressing the fact that all hypothesis are equally reasonable prior to making queries. [sent-78, score-0.21]
</p><p>34 After each query and response (xi , yi ), i = 0, 1, . [sent-79, score-0.351]
</p><p>35 , the distribution is updated according to pi+1 (h) ∝ pi (h) β (1−zi (h))/2 (1 − β)(1+zi (h))/2 , (1) where zi (h) = h(xi )yi , h ∈ H, β is any constant satisfying 0 < β < 1/2, and pi+1 (h) is normalized to satisfy h∈H pi+1 (h) = 1 . [sent-82, score-0.578]
</p><p>36 The hypothesis with the largest weight is selected at each step: hi := arg maxh∈H pi (h). [sent-85, score-0.703]
</p><p>37 A similar procedure has been shown to be optimal for noisy (classic) binary search problem [BZ74, KK07]. [sent-88, score-0.25]
</p><p>38 The crucial distinction here is that GBS calls for a fundamentally different approach to query selection. [sent-89, score-0.265]
</p><p>39 The query selection at each step must be informative with respect to the distribution pi . [sent-90, score-0.774]
</p><p>40 For example, if the weighted prediction h∈H pi (h)h(x) is close to zero for a certain x, then a label at that point is informative due to the large disagreement among the hypotheses. [sent-91, score-0.463]
</p><p>41 This paper shows that a slight variation of the query selection in the NGBS algorithm in Figure 1 yields an algorithm with optimal query complexity. [sent-93, score-0.631]
</p><p>42 The main interest of this paper is an algorithm that drives the error to zero exponentially fast, and this requires the query selection criterion to be modiﬁed slightly. [sent-98, score-0.33]
</p><p>43 , close to +1 or −1 for all queries), and therefore the responses to all queries are relatively certain and non-informative. [sent-104, score-0.221]
</p><p>44 A similar effect is true in the case of noisy (classic) binary search [BZ74, KK07]. [sent-106, score-0.219]
</p><p>45 To address this issue, the query selection criterion is modiﬁed via randomization so that the response to the selected query is always highly uncertain. [sent-107, score-0.673]
</p><p>46 In order to state the modiﬁed selection procedure and the main results, observe that the query space X can be partitioned into equivalence subsets such that every h ∈ H is constant for all queries in each such subset. [sent-108, score-0.553]
</p><p>47 In particular, observe that the query selection step in NGBS is equivalent to an optimization over A rather that X itself. [sent-113, score-0.311]
</p><p>48 The randomization of the query selection step is based on the notion of neighboring sets in A. [sent-114, score-0.429]
</p><p>49 Note that the query selection step is identical to that of the original NGBS algorithm, unless there exist two neighboring sets with strongly bipolar weighted responses. [sent-117, score-0.408]
</p><p>50 In the latter case, a query is randomly selected from one of these two sets with equal probability, which guarantees a highly uncertain response. [sent-118, score-0.32]
</p><p>51 If there exists neighboring sets A and A with h∈H pi (h)h(A) > b and h∈H pi (h)h(A ) < −b , then select xi from A or A with probability 1/2 each. [sent-128, score-1.057]
</p><p>52 Otherwise select xi from the set Amin = arg minA∈A | h∈H pi (h)h(A)|. [sent-129, score-0.521]
</p><p>53 hypothesis selected at each step: hi := arg maxh∈H pi (h) Figure 2: Modiﬁed NGBS algorithm. [sent-134, score-0.703]
</p><p>54 exponential convergence rate of classic binary search hinges on the fact that the hypotheses can be ordered with respect to X . [sent-135, score-0.31]
</p><p>55 Deﬁnition 2 The pair (X , H) is said to be neighborly if the neighborhood graph of A is connected (i. [sent-137, score-0.215]
</p><p>56 , for every pair of sets in A there exists a sequence of neighboring sets that begins at one of the pair and ends with the other). [sent-139, score-0.199]
</p><p>57 In essence, the neighborly condition simply means that each hypothesis is locally distinguishable from all others. [sent-140, score-0.303]
</p><p>58 The neighborly condition was ﬁrst introduced in [Now08] in the analysis of GBS. [sent-142, score-0.198]
</p><p>59 It is shown in Section 3 that the neighborly condition holds for the important case of hypothesis spaces consisting of multidimensional threshold functions. [sent-143, score-0.404]
</p><p>60 No other algorithm can solve the noisy GBS problem with a lower query complexity. [sent-154, score-0.381]
</p><p>61 The query complexity of the modiﬁed NGBS algorithm can be derived as follows. [sent-155, score-0.313]
</p><p>62 The number of queries required to ensure that P(hn = h∗ ) ≤ δ is n ≥ λ−1 log |H| = O(log |H| ), which is the δ δ optimal query complexity. [sent-157, score-0.516]
</p><p>63 More formally, the classic noisy binary search problem satisﬁes the assumptions of Theorem 2 [Now08], 1  “ Note that the factor 1 −  β(1−α) 1−β  −  α(1−β) β  ”  in the exponential rate parameter λ is a positive constant  strictly less than 1. [sent-159, score-0.35]
</p><p>64 It is known that the optimal query complexity for noisy classic binary search is O(log |H| ) [BZ74, KK07]. [sent-162, score-0.633]
</p><p>65 δ We contrast this with the simple noise-tolerant GBS algorithm based on repeating each query in the standard GBS algorithm of Figure 1(a) multiple times to control the noise (see [K¨ a06, Now08] for a¨ related derivations). [sent-163, score-0.309]
</p><p>66 It follows from Chernoff’s bound that the query complexity of determining the log(1/δ) correct label for a single query with conﬁdence at least 1 − δ is O( |1/2−α|2 ). [sent-164, score-0.598]
</p><p>67 Suppose that GBS requires n0 queries in the noiseless situation. [sent-165, score-0.243]
</p><p>68 Then using the union bound, we require O( log(n0 /δ) ) |1/2−α|2 queries at each step to guarantee that the labels determined for all n0 queries are correct with probability 1 − δ. [sent-166, score-0.42]
</p><p>69 If (X , H) is neighborly, then GBS requires n0 = O(log |H|) queries in noiseless conditions [Now08]. [sent-167, score-0.243]
</p><p>70 Therefore, under the conditions of Theorem 2, the query complexity of the simple noise-tolerant GBS algorithm is O(log |H| log logδ|H| ), a logarithmic factor worse than the optimal query complexity. [sent-168, score-0.646]
</p><p>71 , X is a subset of Rd ), and the queries are points in Rd . [sent-172, score-0.2]
</p><p>72 Note that hypotheses of this form can be used to represent nonlinear decision surfaces by applying a nonlinear mapping to the query space. [sent-174, score-0.433]
</p><p>73 Based on the discussion at the end of the previous section, we conclude that the query complexity of the modiﬁed NGBS algorithm is O(log |H|); this is the optimal up to constant factors. [sent-178, score-0.366]
</p><p>74 4  Agnostic Algorithms  We also mention the possibility of agnostic algorithms guaranteed to ﬁnd the best hypothesis in H even if the optimal hypothesis h∗ is not in H and/or the assumptions of Theorem 2 or 3 do not hold. [sent-180, score-0.287]
</p><p>75 The following theorem, proved in [Now09], demonstrates an agnostic algorithm that performs almost as well as empirical risk minimization (ERM) in general, and has the optimal O(log |H|/δ) query complexity when the conditions of Theorem 2 hold. [sent-182, score-0.39]
</p><p>76 Theorem 4 Let PX denote a probability distribution on X and suppose we have a query budget of n. [sent-183, score-0.286]
</p><p>77 Let h1 denote the hypothesis selected by modiﬁed NGBS using n/3 of the queries and let h2 denote the hypothesis selected by ERM from n/3 queries drawn independently from PX . [sent-184, score-0.684]
</p><p>78 Draw the remaining n/3 queries independently from P∆ , the restriction of PX to the set ∆ ⊂ X on which h1 and h2 disagree, and let R∆ (h1 ) and R∆ (h2 ) denote the average number of errors made by h1 and h2 on these queries. [sent-185, score-0.2]
</p><p>79 pi  Note that because p0 is assumed to be uniform, C0 = |H| − 1. [sent-197, score-0.463]
</p><p>80 Let δi = (1 + h pi (h) zi (h))/2, the weighted proportion of hypotheses that agree with yi . [sent-204, score-0.673]
</p><p>81 Note that h pi (h) β (1−zi (h))/2 (1 − β)(1+zi (h))/2 = h:zi (h)=−1 pi (h)β + h:zi (h)=1 pi (h)(1 − β) = (1 − δi )β + δi (1 − β). [sent-206, score-1.389]
</p><p>82 Thus, pi+1 (h) = pi (h)  β (1−zi (h))/2 (1 − β)(1+zi (h))/2 (1 − δi )β + δi (1 − β)  Denote the reciprocal of the update factor for pi+1 (h∗ ) by γi :=  (1 − δi )β + δi (1 − β) , β (1−Zi (h∗ ))/2 (1 − β)(1+Zi (h∗ ))/2  (3)  where zi (h∗ ) = h∗ (xi )yi , and observe that pi+1 (h∗ ) = pi (h∗ )/γi . [sent-207, score-1.013]
</p><p>83 Thus, Ci+1 (1 − pi (h∗ )/γi )pi (h∗ ) γi − pi (h∗ ) = = . [sent-208, score-0.926]
</p><p>84 ∗ )/γ (1 − p (h∗ )) Ci pi (h 1 − pi (h∗ ) i i Now to bound maxpi E[Ci+1 /Ci |pi ] < 1 we will show that maxpi E[γi |pi ] < 1. [sent-209, score-1.003]
</p><p>85 To accomplish this, we will assume that pi is arbitrary. [sent-210, score-0.463]
</p><p>86 Deﬁne δA = (1 + h pi (h)h(A))/2, the proportion of hypotheses that take the value +1 on A. [sent-212, score-0.556]
</p><p>87 If h∗ (Ai ) = +1, then E[γi |pi , Ai ]  = =  + + + (1 − δAi )β + δAi (1 − β) δ + β + (1 − δAi )(1 − β) (1 − qi ) + Ai qi 1−β β β(1 − qi ) qi (1 − β) + + δAi + (1 − δAi ) . [sent-216, score-0.412]
</p><p>88 Similarly, if h∗ (Ai ) = −1, then  β(1 − qi ) qi (1 − β) + 1−β β  By assumption qi ≤ α < 1/2, and since α < β < 1/2 the factor α(1−β) β  β(1−qi ) 1−β  − =: γi (Ai )  +  qi (1−β) β  ≤  β(1−α) 1−β  +  < 1. [sent-218, score-0.429]
</p><p>89 The neighborly condition guarantees that there exists a sequence of neighboring sets beginning at A and ending at A . [sent-231, score-0.322]
</p><p>90 First suppose that there do not exist neighboring sets A and A with W (pi , A) > bi and W (pi , A ) < −bi . [sent-235, score-0.202]
</p><p>91 Then by Lemma 1, this implies that bi ≤ c∗ , and according the query selection step of the modiﬁed NGBS algorithm, + Ai = arg minA |W (pi , A)|. [sent-236, score-0.422]
</p><p>92 Now suppose that there exist neighboring sets A and A with W (pi , A) > bi and W (pi , A ) < −bi . [sent-239, score-0.202]
</p><p>93 If h∗ (A) = h∗ (A ) = +1, then applying (4) results in 1 − bi 1 + bi 1 1 + bi 1 (1 + + (1 − ε0 )) = (2 − ε0 ) ≤ 1 − ε0 /4 , 2 2 2 2 2 since bi > 0. [sent-242, score-0.336]
</p><p>94 Hence,  E[γi |pi , Ai ∈ {A, A }] ≤ = ≤  1 + + + + (1 + δA − δA + (1 − 0 )(1 − δA + δA )) 2 1 (1 + pi (h∗ ) − pi (−h∗ ) + (1 − 0 )(1 − pi (h∗ ) + pi (−h∗ ))) 2 ε0 1 (1 + pi (h∗ ) + (1 − 0 )(1 − pi (h∗ ))) = 1 − (1 − pi (h∗ )) , 2 2  since the bound is maximized when pi (−h∗ ) = 0. [sent-247, score-3.742]
</p><p>95 Now bound E[γi |pi ] by the maximum of the conditional bounds above to obtain ε0 ε0 ε0 E[γi |pi ] ≤ max 1 − (1 − pi (h∗ )) , 1 − , 1 − (1 − c∗ ) , 2 4 2 and thus it is easy to see that E 5. [sent-248, score-0.501]
</p><p>96 3  Ci+1 |pi Ci  =  ε0 ε0 E [γi |pi ] − pi (h∗ ) ≤ 1 − min (1 − c∗ ), ∗) 1 − pi (h 2 4  . [sent-249, score-0.926]
</p><p>97 Proof of Theorem 3  First we show that the pair (Rd , H) is neighborly (Deﬁnition 2). [sent-250, score-0.197]
</p><p>98 Since the offsets b of the hypotheses are all less than c in magnitude, it follows that the distance from the origin to the nearest point of the decision surface of every hypothesis is at most c. [sent-257, score-0.254]
</p><p>99 Lastly, note that the modiﬁed NGBS algorithm involves computing h∈H pi (h)h(A) for all A ∈ A at each step. [sent-260, score-0.485]
</p><p>100 Generalized teaching dimensions and the query complexity of learning. [sent-340, score-0.317]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('gbs', 0.506), ('pi', 0.463), ('ngbs', 0.375), ('query', 0.265), ('ai', 0.201), ('queries', 0.2), ('neighborly', 0.18), ('cn', 0.106), ('hypothesis', 0.105), ('qi', 0.103), ('noisy', 0.094), ('hypotheses', 0.093), ('classic', 0.092), ('bi', 0.084), ('binary', 0.074), ('hn', 0.072), ('amm', 0.071), ('hi', 0.071), ('zi', 0.07), ('mina', 0.066), ('pn', 0.063), ('multidimensional', 0.063), ('modi', 0.059), ('neighboring', 0.059), ('maxh', 0.052), ('ci', 0.051), ('search', 0.051), ('polytopes', 0.049), ('yi', 0.047), ('agnostic', 0.046), ('noiseless', 0.043), ('px', 0.043), ('surfaces', 0.042), ('active', 0.042), ('randomization', 0.041), ('rd', 0.041), ('response', 0.039), ('threshold', 0.038), ('selected', 0.037), ('dp', 0.033), ('dpr', 0.033), ('raghavan', 0.033), ('strategically', 0.033), ('decision', 0.033), ('theorem', 0.032), ('optimal', 0.031), ('xi', 0.031), ('maxpi', 0.029), ('arg', 0.027), ('bisection', 0.026), ('scheduling', 0.026), ('teaching', 0.026), ('acta', 0.026), ('intersections', 0.026), ('complexity', 0.026), ('generalized', 0.026), ('selection', 0.026), ('suboptimal', 0.025), ('erm', 0.025), ('eliminates', 0.025), ('sequence', 0.024), ('greedy', 0.024), ('every', 0.023), ('determining', 0.023), ('job', 0.023), ('governing', 0.023), ('noises', 0.023), ('satisfying', 0.023), ('tree', 0.023), ('exists', 0.023), ('diagnosis', 0.022), ('constant', 0.022), ('outlined', 0.022), ('algorithm', 0.022), ('sign', 0.021), ('suppose', 0.021), ('responses', 0.021), ('step', 0.02), ('log', 0.02), ('minx', 0.02), ('disease', 0.02), ('exist', 0.02), ('bound', 0.019), ('nowak', 0.019), ('geometry', 0.019), ('bounds', 0.019), ('proof', 0.019), ('maximized', 0.019), ('condition', 0.018), ('versions', 0.018), ('neighborhood', 0.018), ('sets', 0.018), ('drive', 0.018), ('pair', 0.017), ('subsets', 0.017), ('exponentially', 0.017), ('proofs', 0.017), ('situations', 0.017), ('factor', 0.017), ('channel', 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="166-tfidf-1" href="./nips-2009-Noisy_Generalized_Binary_Search.html">166 nips-2009-Noisy Generalized Binary Search</a></p>
<p>Author: Robert Nowak</p><p>Abstract: This paper addresses the problem of noisy Generalized Binary Search (GBS). GBS is a well-known greedy algorithm for determining a binary-valued hypothesis through a sequence of strategically selected queries. At each step, a query is selected that most evenly splits the hypotheses under consideration into two disjoint subsets, a natural generalization of the idea underlying classic binary search. GBS is used in many applications, including fault testing, machine diagnostics, disease diagnosis, job scheduling, image processing, computer vision, and active learning. In most of these cases, the responses to queries can be noisy. Past work has provided a partial characterization of GBS, but existing noise-tolerant versions of GBS are suboptimal in terms of query complexity. This paper presents an optimal algorithm for noisy GBS and demonstrates its application to learning multidimensional threshold functions. 1</p><p>2 0.21219808 <a title="166-tfidf-2" href="./nips-2009-Conditional_Random_Fields_with_High-Order_Features_for_Sequence_Labeling.html">57 nips-2009-Conditional Random Fields with High-Order Features for Sequence Labeling</a></p>
<p>Author: Nan Ye, Wee S. Lee, Hai L. Chieu, Dan Wu</p><p>Abstract: Dependencies among neighbouring labels in a sequence is an important source of information for sequence labeling problems. However, only dependencies between adjacent labels are commonly exploited in practice because of the high computational complexity of typical inference algorithms when longer distance dependencies are taken into account. In this paper, we show that it is possible to design efﬁcient inference algorithms for a conditional random ﬁeld using features that depend on long consecutive label sequences (high-order features), as long as the number of distinct label sequences used in the features is small. This leads to efﬁcient learning algorithms for these conditional random ﬁelds. We show experimentally that exploiting dependencies using high-order features can lead to substantial performance improvements for some problems and discuss conditions under which high-order features can be effective. 1</p><p>3 0.14297727 <a title="166-tfidf-3" href="./nips-2009-fMRI-Based_Inter-Subject_Cortical_Alignment_Using_Functional_Connectivity.html">261 nips-2009-fMRI-Based Inter-Subject Cortical Alignment Using Functional Connectivity</a></p>
<p>Author: Bryan Conroy, Ben Singer, James Haxby, Peter J. Ramadge</p><p>Abstract: The inter-subject alignment of functional MRI (fMRI) data is important for improving the statistical power of fMRI group analyses. In contrast to existing anatomically-based methods, we propose a novel multi-subject algorithm that derives a functional correspondence by aligning spatial patterns of functional connectivity across a set of subjects. We test our method on fMRI data collected during a movie viewing experiment. By cross-validating the results of our algorithm, we show that the correspondence successfully generalizes to a secondary movie dataset not used to derive the alignment. 1</p><p>4 0.12996611 <a title="166-tfidf-4" href="./nips-2009-Linear-time_Algorithms_for_Pairwise_Statistical_Problems.html">139 nips-2009-Linear-time Algorithms for Pairwise Statistical Problems</a></p>
<p>Author: Parikshit Ram, Dongryeol Lee, William March, Alexander G. Gray</p><p>Abstract: Several key computational bottlenecks in machine learning involve pairwise distance computations, including all-nearest-neighbors (ďŹ nding the nearest neighbor(s) for each point, e.g. in manifold learning) and kernel summations (e.g. in kernel density estimation or kernel machines). We consider the general, bichromatic case for these problems, in addition to the scientiďŹ c problem of N-body simulation. In this paper we show for the ďŹ rst time O(đ?&lsquo;  ) worst case runtimes for practical algorithms for these problems based on the cover tree data structure [1]. 1</p><p>5 0.12540264 <a title="166-tfidf-5" href="./nips-2009-Optimizing_Multi-Class_Spatio-Spectral_Filters_via_Bayes_Error_Estimation_for_EEG_Classification.html">184 nips-2009-Optimizing Multi-Class Spatio-Spectral Filters via Bayes Error Estimation for EEG Classification</a></p>
<p>Author: Wenming Zheng, Zhouchen Lin</p><p>Abstract: The method of common spatio-spectral patterns (CSSPs) is an extension of common spatial patterns (CSPs) by utilizing the technique of delay embedding to alleviate the adverse effects of noises and artifacts on the electroencephalogram (EEG) classiﬁcation. Although the CSSPs method has shown to be more powerful than the CSPs method in the EEG classiﬁcation, this method is only suitable for two-class EEG classiﬁcation problems. In this paper, we generalize the two-class CSSPs method to multi-class cases. To this end, we ﬁrst develop a novel theory of multi-class Bayes error estimation and then present the multi-class CSSPs (MCSSPs) method based on this Bayes error theoretical framework. By minimizing the estimated closed-form Bayes error, we obtain the optimal spatio-spectral ﬁlters of MCSSPs. To demonstrate the effectiveness of the proposed method, we conduct extensive experiments on the BCI competition 2005 data set. The experimental results show that our method signiﬁcantly outperforms the previous multi-class CSPs (MCSPs) methods in the EEG classiﬁcation.</p><p>6 0.12343463 <a title="166-tfidf-6" href="./nips-2009-Entropic_Graph_Regularization_in_Non-Parametric_Semi-Supervised_Classification.html">82 nips-2009-Entropic Graph Regularization in Non-Parametric Semi-Supervised Classification</a></p>
<p>7 0.12101271 <a title="166-tfidf-7" href="./nips-2009-An_Online_Algorithm_for_Large_Scale_Image_Similarity_Learning.html">32 nips-2009-An Online Algorithm for Large Scale Image Similarity Learning</a></p>
<p>8 0.10026145 <a title="166-tfidf-8" href="./nips-2009-Polynomial_Semantic_Indexing.html">190 nips-2009-Polynomial Semantic Indexing</a></p>
<p>9 0.079084896 <a title="166-tfidf-9" href="./nips-2009-Potential-Based_Agnostic_Boosting.html">193 nips-2009-Potential-Based Agnostic Boosting</a></p>
<p>10 0.078768089 <a title="166-tfidf-10" href="./nips-2009-Rank-Approximate_Nearest_Neighbor_Search%3A_Retaining_Meaning_and_Speed_in_High_Dimensions.html">198 nips-2009-Rank-Approximate Nearest Neighbor Search: Retaining Meaning and Speed in High Dimensions</a></p>
<p>11 0.072595201 <a title="166-tfidf-11" href="./nips-2009-Convex_Relaxation_of_Mixture_Regression_with_Efficient_Algorithms.html">61 nips-2009-Convex Relaxation of Mixture Regression with Efficient Algorithms</a></p>
<p>12 0.069168434 <a title="166-tfidf-12" href="./nips-2009-Information-theoretic_lower_bounds_on_the_oracle_complexity_of_convex_optimization.html">116 nips-2009-Information-theoretic lower bounds on the oracle complexity of convex optimization</a></p>
<p>13 0.066527866 <a title="166-tfidf-13" href="./nips-2009-Variational_Inference_for_the_Nested_Chinese_Restaurant_Process.html">255 nips-2009-Variational Inference for the Nested Chinese Restaurant Process</a></p>
<p>14 0.064450875 <a title="166-tfidf-14" href="./nips-2009-Segmenting_Scenes_by_Matching_Image_Composites.html">211 nips-2009-Segmenting Scenes by Matching Image Composites</a></p>
<p>15 0.06422969 <a title="166-tfidf-15" href="./nips-2009-Sufficient_Conditions_for_Agnostic_Active_Learnable.html">240 nips-2009-Sufficient Conditions for Agnostic Active Learnable</a></p>
<p>16 0.064088948 <a title="166-tfidf-16" href="./nips-2009-Adapting_to_the_Shifting_Intent_of_Search_Queries.html">24 nips-2009-Adapting to the Shifting Intent of Search Queries</a></p>
<p>17 0.062646501 <a title="166-tfidf-17" href="./nips-2009-Locality-sensitive_binary_codes_from_shift-invariant_kernels.html">142 nips-2009-Locality-sensitive binary codes from shift-invariant kernels</a></p>
<p>18 0.060405493 <a title="166-tfidf-18" href="./nips-2009-Complexity_of_Decentralized_Control%3A_Special_Cases.html">53 nips-2009-Complexity of Decentralized Control: Special Cases</a></p>
<p>19 0.060224742 <a title="166-tfidf-19" href="./nips-2009-Learning_a_Small_Mixture_of_Trees.html">129 nips-2009-Learning a Small Mixture of Trees</a></p>
<p>20 0.058762461 <a title="166-tfidf-20" href="./nips-2009-From_PAC-Bayes_Bounds_to_KL_Regularization.html">98 nips-2009-From PAC-Bayes Bounds to KL Regularization</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.166), (1, 0.06), (2, -0.001), (3, 0.003), (4, -0.017), (5, 0.008), (6, -0.109), (7, -0.023), (8, -0.028), (9, -0.055), (10, -0.075), (11, 0.043), (12, 0.113), (13, 0.065), (14, 0.043), (15, -0.037), (16, 0.235), (17, 0.029), (18, -0.07), (19, -0.039), (20, 0.322), (21, 0.012), (22, -0.116), (23, 0.035), (24, 0.025), (25, -0.106), (26, -0.074), (27, -0.07), (28, -0.086), (29, 0.184), (30, 0.029), (31, 0.033), (32, -0.059), (33, -0.024), (34, -0.098), (35, 0.076), (36, -0.074), (37, -0.17), (38, 0.084), (39, -0.14), (40, 0.088), (41, 0.056), (42, 0.031), (43, -0.075), (44, 0.061), (45, -0.066), (46, -0.031), (47, 0.021), (48, -0.017), (49, 0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96529502 <a title="166-lsi-1" href="./nips-2009-Noisy_Generalized_Binary_Search.html">166 nips-2009-Noisy Generalized Binary Search</a></p>
<p>Author: Robert Nowak</p><p>Abstract: This paper addresses the problem of noisy Generalized Binary Search (GBS). GBS is a well-known greedy algorithm for determining a binary-valued hypothesis through a sequence of strategically selected queries. At each step, a query is selected that most evenly splits the hypotheses under consideration into two disjoint subsets, a natural generalization of the idea underlying classic binary search. GBS is used in many applications, including fault testing, machine diagnostics, disease diagnosis, job scheduling, image processing, computer vision, and active learning. In most of these cases, the responses to queries can be noisy. Past work has provided a partial characterization of GBS, but existing noise-tolerant versions of GBS are suboptimal in terms of query complexity. This paper presents an optimal algorithm for noisy GBS and demonstrates its application to learning multidimensional threshold functions. 1</p><p>2 0.60269904 <a title="166-lsi-2" href="./nips-2009-fMRI-Based_Inter-Subject_Cortical_Alignment_Using_Functional_Connectivity.html">261 nips-2009-fMRI-Based Inter-Subject Cortical Alignment Using Functional Connectivity</a></p>
<p>Author: Bryan Conroy, Ben Singer, James Haxby, Peter J. Ramadge</p><p>Abstract: The inter-subject alignment of functional MRI (fMRI) data is important for improving the statistical power of fMRI group analyses. In contrast to existing anatomically-based methods, we propose a novel multi-subject algorithm that derives a functional correspondence by aligning spatial patterns of functional connectivity across a set of subjects. We test our method on fMRI data collected during a movie viewing experiment. By cross-validating the results of our algorithm, we show that the correspondence successfully generalizes to a secondary movie dataset not used to derive the alignment. 1</p><p>3 0.56378847 <a title="166-lsi-3" href="./nips-2009-Conditional_Random_Fields_with_High-Order_Features_for_Sequence_Labeling.html">57 nips-2009-Conditional Random Fields with High-Order Features for Sequence Labeling</a></p>
<p>Author: Nan Ye, Wee S. Lee, Hai L. Chieu, Dan Wu</p><p>Abstract: Dependencies among neighbouring labels in a sequence is an important source of information for sequence labeling problems. However, only dependencies between adjacent labels are commonly exploited in practice because of the high computational complexity of typical inference algorithms when longer distance dependencies are taken into account. In this paper, we show that it is possible to design efﬁcient inference algorithms for a conditional random ﬁeld using features that depend on long consecutive label sequences (high-order features), as long as the number of distinct label sequences used in the features is small. This leads to efﬁcient learning algorithms for these conditional random ﬁelds. We show experimentally that exploiting dependencies using high-order features can lead to substantial performance improvements for some problems and discuss conditions under which high-order features can be effective. 1</p><p>4 0.55023396 <a title="166-lsi-4" href="./nips-2009-Optimizing_Multi-Class_Spatio-Spectral_Filters_via_Bayes_Error_Estimation_for_EEG_Classification.html">184 nips-2009-Optimizing Multi-Class Spatio-Spectral Filters via Bayes Error Estimation for EEG Classification</a></p>
<p>Author: Wenming Zheng, Zhouchen Lin</p><p>Abstract: The method of common spatio-spectral patterns (CSSPs) is an extension of common spatial patterns (CSPs) by utilizing the technique of delay embedding to alleviate the adverse effects of noises and artifacts on the electroencephalogram (EEG) classiﬁcation. Although the CSSPs method has shown to be more powerful than the CSPs method in the EEG classiﬁcation, this method is only suitable for two-class EEG classiﬁcation problems. In this paper, we generalize the two-class CSSPs method to multi-class cases. To this end, we ﬁrst develop a novel theory of multi-class Bayes error estimation and then present the multi-class CSSPs (MCSSPs) method based on this Bayes error theoretical framework. By minimizing the estimated closed-form Bayes error, we obtain the optimal spatio-spectral ﬁlters of MCSSPs. To demonstrate the effectiveness of the proposed method, we conduct extensive experiments on the BCI competition 2005 data set. The experimental results show that our method signiﬁcantly outperforms the previous multi-class CSPs (MCSPs) methods in the EEG classiﬁcation.</p><p>5 0.47119671 <a title="166-lsi-5" href="./nips-2009-Linear-time_Algorithms_for_Pairwise_Statistical_Problems.html">139 nips-2009-Linear-time Algorithms for Pairwise Statistical Problems</a></p>
<p>Author: Parikshit Ram, Dongryeol Lee, William March, Alexander G. Gray</p><p>Abstract: Several key computational bottlenecks in machine learning involve pairwise distance computations, including all-nearest-neighbors (ďŹ nding the nearest neighbor(s) for each point, e.g. in manifold learning) and kernel summations (e.g. in kernel density estimation or kernel machines). We consider the general, bichromatic case for these problems, in addition to the scientiďŹ c problem of N-body simulation. In this paper we show for the ďŹ rst time O(đ?&lsquo;  ) worst case runtimes for practical algorithms for these problems based on the cover tree data structure [1]. 1</p><p>6 0.46765974 <a title="166-lsi-6" href="./nips-2009-An_Online_Algorithm_for_Large_Scale_Image_Similarity_Learning.html">32 nips-2009-An Online Algorithm for Large Scale Image Similarity Learning</a></p>
<p>7 0.45946419 <a title="166-lsi-7" href="./nips-2009-Rank-Approximate_Nearest_Neighbor_Search%3A_Retaining_Meaning_and_Speed_in_High_Dimensions.html">198 nips-2009-Rank-Approximate Nearest Neighbor Search: Retaining Meaning and Speed in High Dimensions</a></p>
<p>8 0.42475331 <a title="166-lsi-8" href="./nips-2009-Entropic_Graph_Regularization_in_Non-Parametric_Semi-Supervised_Classification.html">82 nips-2009-Entropic Graph Regularization in Non-Parametric Semi-Supervised Classification</a></p>
<p>9 0.39589843 <a title="166-lsi-9" href="./nips-2009-Potential-Based_Agnostic_Boosting.html">193 nips-2009-Potential-Based Agnostic Boosting</a></p>
<p>10 0.38583907 <a title="166-lsi-10" href="./nips-2009-Discrete_MDL_Predicts_in_Total_Variation.html">69 nips-2009-Discrete MDL Predicts in Total Variation</a></p>
<p>11 0.34977111 <a title="166-lsi-11" href="./nips-2009-Sufficient_Conditions_for_Agnostic_Active_Learnable.html">240 nips-2009-Sufficient Conditions for Agnostic Active Learnable</a></p>
<p>12 0.31852356 <a title="166-lsi-12" href="./nips-2009-Information-theoretic_lower_bounds_on_the_oracle_complexity_of_convex_optimization.html">116 nips-2009-Information-theoretic lower bounds on the oracle complexity of convex optimization</a></p>
<p>13 0.31315663 <a title="166-lsi-13" href="./nips-2009-Submodularity_Cuts_and_Applications.html">239 nips-2009-Submodularity Cuts and Applications</a></p>
<p>14 0.30858988 <a title="166-lsi-14" href="./nips-2009-A_Data-Driven_Approach_to_Modeling_Choice.html">7 nips-2009-A Data-Driven Approach to Modeling Choice</a></p>
<p>15 0.29604077 <a title="166-lsi-15" href="./nips-2009-Fast%2C_smooth_and_adaptive_regression_in_metric_spaces.html">91 nips-2009-Fast, smooth and adaptive regression in metric spaces</a></p>
<p>16 0.29255268 <a title="166-lsi-16" href="./nips-2009-Adapting_to_the_Shifting_Intent_of_Search_Queries.html">24 nips-2009-Adapting to the Shifting Intent of Search Queries</a></p>
<p>17 0.29157361 <a title="166-lsi-17" href="./nips-2009-Unsupervised_Feature_Selection_for_the_%24k%24-means_Clustering_Problem.html">252 nips-2009-Unsupervised Feature Selection for the $k$-means Clustering Problem</a></p>
<p>18 0.28975329 <a title="166-lsi-18" href="./nips-2009-Variational_Inference_for_the_Nested_Chinese_Restaurant_Process.html">255 nips-2009-Variational Inference for the Nested Chinese Restaurant Process</a></p>
<p>19 0.28941336 <a title="166-lsi-19" href="./nips-2009-Dirichlet-Bernoulli_Alignment%3A_A_Generative_Model_for_Multi-Class_Multi-Label_Multi-Instance_Corpora.html">68 nips-2009-Dirichlet-Bernoulli Alignment: A Generative Model for Multi-Class Multi-Label Multi-Instance Corpora</a></p>
<p>20 0.27535498 <a title="166-lsi-20" href="./nips-2009-Grouped_Orthogonal_Matching_Pursuit_for_Variable_Selection_and_Prediction.html">105 nips-2009-Grouped Orthogonal Matching Pursuit for Variable Selection and Prediction</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(24, 0.087), (25, 0.07), (35, 0.038), (36, 0.154), (39, 0.035), (58, 0.049), (71, 0.044), (81, 0.02), (86, 0.097), (91, 0.296)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.97817123 <a title="166-lda-1" href="./nips-2009-Bayesian_Belief_Polarization.html">39 nips-2009-Bayesian Belief Polarization</a></p>
<p>Author: Alan Jern, Kai-min Chang, Charles Kemp</p><p>Abstract: Empirical studies have documented cases of belief polarization, where two people with opposing prior beliefs both strengthen their beliefs after observing the same evidence. Belief polarization is frequently offered as evidence of human irrationality, but we demonstrate that this phenomenon is consistent with a fully Bayesian approach to belief revision. Simulation results indicate that belief polarization is not only possible but relatively common within the set of Bayesian models that we consider. Suppose that Carol has requested a promotion at her company and has received a score of 50 on an aptitude test. Alice, one of the company’s managers, began with a high opinion of Carol and became even more conﬁdent of her abilities after seeing her test score. Bob, another manager, began with a low opinion of Carol and became even less conﬁdent about her qualiﬁcations after seeing her score. On the surface, it may appear that either Alice or Bob is behaving irrationally, since the same piece of evidence has led them to update their beliefs about Carol in opposite directions. This situation is an example of belief polarization [1, 2], a widely studied phenomenon that is often taken as evidence of human irrationality [3, 4]. In some cases, however, belief polarization may appear much more sensible when all the relevant information is taken into account. Suppose, for instance, that Alice was familiar with the aptitude test and knew that it was scored out of 60, but that Bob was less familiar with the test and assumed that the score was a percentage. Even though only one interpretation of the score can be correct, Alice and Bob have both made rational inferences given their assumptions about the test. Some instances of belief polarization are almost certain to qualify as genuine departures from rational inference, but we argue in this paper that others will be entirely compatible with a rational approach. Distinguishing between these cases requires a precise normative standard against which human inferences can be compared. We suggest that Bayesian inference provides this normative standard, and present a set of Bayesian models that includes cases where polarization can and cannot emerge. Our work is in the spirit of previous studies that use careful rational analyses in order to illuminate apparently irrational human behavior (e.g. [5, 6, 7]). Previous studies of belief polarization have occasionally taken a Bayesian approach, but often the goal is to show how belief polarization can emerge as a consequence of approximate inference in a Bayesian model that is subject to memory constraints or processing limitations [8]. In contrast, we demonstrate that some examples of polarization are compatible with a fully Bayesian approach. Other formal accounts of belief polarization have relied on complex versions of utility theory [9], or have focused on continuous hypothesis spaces [10] unlike the discrete hypothesis spaces usually considered by psychological studies of belief polarization. We focus on discrete hypothesis spaces and require no additional machinery beyond the basics of Bayesian inference. We begin by introducing the belief revision phenomena considered in this paper and developing a Bayesian approach that clariﬁes whether and when these phenomena should be considered irrational. We then consider several Bayesian models that are capable of producing belief polarization and illustrate them with concrete examples. Having demonstrated that belief polarization is compatible 1 (a) Contrary updating (i) Divergence (ii) (b) Parallel updating Convergence A P (h1 ) 0.5 0.5 0.5 B Prior beliefs Updated beliefs Prior beliefs Updated beliefs Prior beliefs Updated beliefs Figure 1: Examples of belief updating behaviors for two individuals, A (solid line) and B (dashed line). The individuals begin with different beliefs about hypothesis h1 . After observing the same set of evidence, their beliefs may (a) move in opposite directions or (b) move in the same direction. with a Bayesian approach, we present simulations suggesting that this phenomenon is relatively generic within the space of models that we consider. We ﬁnish with some general comments on human rationality and normative models. 1 Belief revision phenomena The term “belief polarization” is generally used to describe situations in which two people observe the same evidence and update their respective beliefs in the directions of their priors. A study by Lord, et al. [1] provides one classic example in which participants read about two studies, one of which concluded that the death penalty deters crime and another which concluded that the death penalty has no effect on crime. After exposure to this mixed evidence, supporters of the death penalty strengthened their support and opponents strengthened their opposition. We will treat belief polarization as a special case of contrary updating, a phenomenon where two people update their beliefs in opposite directions after observing the same evidence (Figure 1a). We distinguish between two types of contrary updating. Belief divergence refers to cases in which the person with the stronger belief in some hypothesis increases the strength of his or her belief and the person with the weaker belief in the hypothesis decreases the strength of his or her belief (Figure 1a(i)). Divergence therefore includes cases of traditional belief polarization. The opposite of divergence is belief convergence (Figure 1a(ii)), in which the person with the stronger belief decreases the strength of his or her belief and the person with the weaker belief increases the strength of his or her belief. Contrary updating may be contrasted with parallel updating (Figure 1b), in which the two people update their beliefs in the same direction. Throughout this paper, we consider only situations in which both people change their beliefs after observing some evidence. All such situations can be unambiguously classiﬁed as instances of parallel or contrary updating. Parallel updating is clearly compatible with a normative approach, but the normative status of divergence and convergence is less clear. Many authors argue that divergence is irrational, and many of the same authors also propose that convergence is rational [2, 3]. For example, Baron [3] writes that “Normatively, we might expect that beliefs move toward the middle of the range when people are presented with mixed evidence.” (p. 210) The next section presents a formal analysis that challenges the conventional wisdom about these phenomena and clariﬁes the cases where they can be considered rational. 2 A Bayesian approach to belief revision Since belief revision involves inference under uncertainty, Bayesian inference provides the appropriate normative standard. Consider a problem where two people observe data d that bear on some hypothesis h1 . Let P1 (·) and P2 (·) be distributions that capture the two people’s respective beliefs. Contrary updating occurs whenever one person’s belief in h1 increases and the other person’s belief in h1 decreases, or when [P1 (h1 |d) − P1 (h1 )] [P2 (h1 |d) − P2 (h1 )] < 0 . 2 (1) Family 1 (a) H (c) (d) (e) V H D Family 2 (b) V V V D H D H D H (f) (g) V V D H D (h) V H D H D Figure 2: (a) A simple Bayesian network that cannot produce either belief divergence or belief convergence. (b) – (h) All possible three-node Bayes nets subject to the constraints described in the text. Networks in Family 1 can produce only parallel updating, but networks in Family 2 can produce both parallel and contrary updating. We will use Bayesian networks to capture the relationships between H, D, and any other variables that are relevant to the situation under consideration. For example, Figure 2a captures the idea that the data D are probabilistically generated from hypothesis H. The remaining networks in Figure 2 show several other ways in which D and H may be related, and will be discussed later. We assume that the two individuals agree on the variables that are relevant to a problem and agree about the relationships between these variables. We can formalize this idea by requiring that both people agree on the structure and the conditional probability distributions (CPDs) of a network N that captures relationships between the relevant variables, and that they differ only in the priors they assign to the root nodes of N . If N is the Bayes net in Figure 2a, then we assume that the two people must agree on the distribution P (D|H), although they may have different priors P1 (H) and P2 (H). If two people agree on network N but have different priors on the root nodes, we can create a single expanded Bayes net to simulate the inferences of both individuals. The expanded network is created by adding a background knowledge node B that sends directed edges to all root nodes in N , and acts as a switch that sets different root node priors for the two different individuals. Given this expanded network, distributions P1 and P2 in Equation 1 can be recovered by conditioning on the value of the background knowledge node and rewritten as [P (h1 |d, b1 ) − P (h1 |b1 )] [P (h1 |d, b2 ) − P (h1 |b2 )] < 0 (2) where P (·) represents the probability distribution captured by the expanded network. Suppose that there are exactly two mutually exclusive hypotheses. For example, h1 and h0 might state that the death penalty does or does not deter crime. In this case Equation 2 implies that contrary updating occurs when [P (d|h1 , b1 ) − P (d|h0 , b1 )] [P (d|h1 , b2 ) − P (d|h0 , b2 )] < 0 . (3) Equation 3 is derived in the supporting material, and leads immediately to the following result: R1: If H is a binary variable and D and B are conditionally independent given H, then contrary updating is impossible. Result R1 follows from the observation that if D and B are conditionally independent given H, then the product in Equation 3 is equal to (P (d|h1 ) − P (d|h0 ))2 , which cannot be less than zero. R1 implies that the simple Bayes net in Figure 2a is incapable of producing contrary updating, an observation previously made by Lopes [11]. Our analysis may help to explain the common intuition that belief divergence is irrational, since many researchers seem to implicitly adopt a model in which H and D are the only relevant variables. Network 2a, however, is too simple to capture the causal relationships that are present in many real world situations. For example, the promotion example at the beginning of this paper is best captured using a network with an additional node that represents the grading scale for the aptitude test. Networks with many nodes may be needed for some real world problems, but here we explore the space of three-node networks. We restrict our attention to connected graphs in which D has no outgoing edges, motivated by the idea that the three variables should be linked and that the data are the ﬁnal result of some generative process. The seven graphs that meet these conditions are shown in Figures 2b–h, where the additional variable has been labeled V . These Bayes nets illustrate cases in which (b) V is an additional 3 Models Conventional wisdom Family 1 Family 2 Belief divergence Belief convergence Parallel updating Table 1: The ﬁrst column represents the conventional wisdom about which belief revision phenomena are normative. The models in the remaining columns include all three-node Bayes nets. This set of models can be partitioned into those that support both belief divergence and convergence (Family 2) and those that support neither (Family 1). piece of evidence that bears on H, (c) V informs the prior probability of H, (d)–(e) D is generated by an intervening variable V , (f) V is an additional generating factor of D, (g) V informs both the prior probability of H and the likelihood of D, and (h) H and D are both effects of V . The graphs in Figure 2 have been organized into two families. R1 implies that none of the graphs in Family 1 is capable of producing contrary updating. The next section demonstrates by example that all three of the graphs in Family 2 are capable of producing contrary updating. Table 1 compares the two families of Bayes nets to the informal conclusions about normative approaches that are often found in the psychological literature. As previously noted, the conventional wisdom holds that belief divergence is irrational but that convergence and parallel updating are both rational. Our analysis suggests that this position has little support. Depending on the causal structure of the problem under consideration, a rational approach should allow both divergence and convergence or neither. Although we focus in this paper on Bayes nets with no more than three nodes, the class of all network structures can be partitioned into those that can (Family 2) and cannot (Family 1) produce contrary updating. R1 is true for Bayes nets of any size and characterizes one group of networks that belong to Family 1. Networks where the data provide no information about the hypotheses must also fail to produce contrary updating. Note that if D and H are conditionally independent given B, then the left side of Equation 3 is equal to zero, meaning contrary updating cannot occur. We conjecture that all remaining networks can produce contrary updating if the cardinalities of the nodes and the CPDs are chosen appropriately. Future studies can attempt to verify this conjecture and to precisely characterize the CPDs that lead to contrary updating. 3 Examples of rational belief divergence We now present four scenarios that can be modeled by the three-node Bayes nets in Family 2. Our purpose in developing these examples is to demonstrate that these networks can produce belief divergence and to provide some everyday examples in which this behavior is both normative and intuitive. 3.1 Example 1: Promotion We ﬁrst consider a scenario that can be captured by Bayes net 2f, in which the data depend on two independent factors. Recall the scenario described at the beginning of this paper: Alice and Bob are responsible for deciding whether to promote Carol. For simplicity, we consider a case where the data represent a binary outcome—whether or not Carol’s r´ sum´ indicates that she is included e e in The Directory of Notable People—rather than her score on an aptitude test. Alice believes that The Directory is a reputable publication but Bob believes it is illegitimate. This situation is represented by the Bayes net and associated CPDs in Figure 3a. In the tables, the hypothesis space H = {‘Unqualiﬁed’ = 0, ‘Qualiﬁed’ = 1} represents whether or not Carol is qualiﬁed for the promotion, the additional factor V = {‘Disreputable’ = 0, ‘Reputable’ = 1} represents whether The Directory is a reputable publication, and the data variable D = {‘Not included’ = 0, ‘Included’ = 1} represents whether Carol is featured in it. The actual probabilities were chosen to reﬂect the fact that only an unqualiﬁed person is likely to pad their r´ sum´ by mentioning a disreputable publication, but that e e 4 (a) B Alice Bob (b) P(V=1) 0.01 0.9 B Alice Bob V B Alice Bob P(H=1) 0.6 0.4 V H D V 0 0 1 1 H 0 1 0 1 V 0 1 P(D=1) 0.5 0.1 0.1 0.9 (c) P(H=1) 0.1 0.9 H V 0 0 1 1 D H 0 1 0 1 P(D=1) 0.4 0.01 0.4 0.6 (d) B Alice Bob P(V=0) P(V=1) P(V=2) P(V=3) 0.6 0.2 0.1 0.1 0.1 0.1 0.2 0.6 B Alice Bob P(V1=1) 0.9 0.1 P(H=1) 1 1 0 0 H B Alice Bob V1 V V 0 1 2 3 P(V=1) 0.9 0.1 D V 0 1 2 3 P(D=0) P(D=1) P(D=2) P(D=3) 0.7 0.1 0.1 0.1 0.1 0.7 0.1 0.1 0.1 0.1 0.7 0.1 0.1 0.1 0.1 0.7 V1 0 0 1 1 V2 0 1 0 1 P(H=1) 0.5 0.1 0.5 0.9 P(V2=1) 0.5 0.5 V2 H D V2 0 1 P(D=1) 0.1 0.9 Figure 3: The Bayes nets and conditional probability distributions used in (a) Example 1: Promotion, (b) Example 2: Religious belief, (c) Example 3: Election polls, (d) Example 4: Political belief. only a qualiﬁed person is likely to be included in The Directory if it is reputable. Note that Alice and Bob agree on the conditional probability distribution for D, but assign different priors to V and H. Alice and Bob therefore interpret the meaning of Carol’s presence in The Directory differently, resulting in the belief divergence shown in Figure 4a. This scenario is one instance of a large number of belief divergence cases that can be attributed to two individuals possessing different mental models of how the observed evidence was generated. For instance, suppose now that Alice and Bob are both on an admissions committee and are evaluating a recommendation letter for an applicant. Although the letter is positive, it is not enthusiastic. Alice, who has less experience reading recommendation letters interprets the letter as a strong endorsement. Bob, however, takes the lack of enthusiasm as an indication that the author has some misgivings [12]. As in the promotion scenario, the differences in Alice’s and Bob’s experience can be effectively represented by the priors they assign to the H and V nodes in a Bayes net of the form in Figure 2f. 3.2 Example 2: Religious belief We now consider a scenario captured by Bayes net 2g. In our example for Bayes net 2f, the status of an additional factor V affected how Alice and Bob interpreted the data D, but did not shape their prior beliefs about H. In many cases, however, the additional factor V will inﬂuence both people’s prior beliefs about H as well as their interpretation of the relationship between D and H. Bayes net 2g captures this situation, and we provide a concrete example inspired by an experiment conducted by Batson [13]. Suppose that Alice believes in a “Christian universe:” she believes in the divinity of Jesus Christ and expects that followers of Christ will be persecuted. Bob, on the other hand, believes in a “secular universe.” This belief leads him to doubt Christ’s divinity, but to believe that if Christ were divine, his followers would likely be protected rather than persecuted. Now suppose that both Alice and Bob observe that Christians are, in fact, persecuted, and reassess the probability of Christ’s divinity. This situation is represented by the Bayes net and associated CPDs in Figure 3b. In the tables, the hypothesis space H = {‘Human’ = 0, ‘Divine’ = 1} represents the divinity of Jesus Christ, the additional factor V = {‘Secular’ = 0, ‘Christian’ = 1} represents the nature of the universe, and the data variable D = {‘Not persecuted’ = 0, ‘Persecuted’ = 1} represents whether Christians are subject to persecution. The exact probabilities were chosen to reﬂect the fact that, regardless of worldview, people will agree on a “base rate” of persecution given that Christ is not divine, but that more persecution is expected if the Christian worldview is correct than if the secular worldview is correct. Unlike in the previous scenario, Alice and Bob agree on the CPDs for both D and H, but 5 (a) (b) P (H = 1) (d) 1 1 1 0.5 1 (c) 0.5 0.5 A 0.5 B 0 0 0 Prior beliefs Updated beliefs Prior beliefs Updated beliefs 0 Prior beliefs Updated beliefs Prior beliefs Updated beliefs Figure 4: Belief revision outcomes for (a) Example 1: Promotion, (b) Example 2: Religious belief, (c) Example 3: Election polls, and (d) Example 4: Political belief. In all four plots, the updated beliefs for Alice (solid line) and Bob (dashed line) are computed after observing the data described in the text. The plots conﬁrm that all four of our example networks can lead to belief divergence. differ in the priors they assign to V . As a result, Alice and Bob disagree about whether persecution supports or undermines a Christian worldview, which leads to the divergence shown in Figure 4b. This scenario is analogous to many real world situations in which one person has knowledge that the other does not. For instance, in a police interrogation, someone with little knowledge of the case (V ) might take a suspect’s alibi (D) as strong evidence of their innocence (H). However, a detective with detailed knowledge of the case may assign a higher prior probability to the subject’s guilt based on other circumstantial evidence, and may also notice a detail in the suspect’s alibi that only the culprit would know, thus making the statement strong evidence of guilt. In all situations of this kind, although two people possess different background knowledge, their inferences are normative given that knowledge, consistent with the Bayes net in Figure 2g. 3.3 Example 3: Election polls We now consider two qualitatively different cases that are both captured by Bayes net 2h. The networks considered so far have all included a direct link between H and D. In our next two examples, we consider cases where the hypotheses and observed data are not directly linked, but are coupled by means of one or more unobserved causal factors. Suppose that an upcoming election will be contested by two Republican candidates, Rogers and Rudolph, and two Democratic candidates, Davis and Daly. Alice and Bob disagree about the various candidates’ chances of winning, with Alice favoring the two Republicans and Bob favoring the two Democrats. Two polls were recently released, one indicating that Rogers was most likely to win the election and the other indicating that Daly was most likely to win. After considering these polls, they both assess the likelihood that a Republican will win the election. This situation is represented by the Bayes net and associated CPDs in Figure 3c. In the tables, the hypothesis space H = {‘Democrat wins’ = 0, ‘Republican wins’ = 1} represents the winning party, the variable V = {‘Rogers’ = 0, ‘Rudolph’ = 1, ‘Davis’ = 2, ‘Daly’ = 3} represents the winning candidate, and the data variables D1 = D2 = {‘Rogers’ = 0, ‘Rudolph’ = 1, ‘Davis’ = 2, ‘Daly’ = 3} represent the results of the two polls. The exact probabilities were chosen to reﬂect the fact that the polls are likely to reﬂect the truth with some noise, but whether a Democrat or Republican wins is completely determined by the winning candidate V . In Figure 3c, only a single D node is shown because D1 and D2 have identical CPDs. The resulting belief divergence is shown in Figure 4c. Note that in this scenario, Alice’s and Bob’s different priors cause them to discount the poll that disagrees with their existing beliefs as noise, thus causing their prior beliefs to be reinforced by the mixed data. This scenario was inspired by the death penalty study [1] alluded to earlier, in which a set of mixed results caused supporters and opponents of the death penalty to strengthen their existing beliefs. We do not claim that people’s behavior in this study can be explained with exactly the model employed here, but our analysis does show that selective interpretation of evidence is sometimes consistent with a rational approach. 6 3.4 Example 4: Political belief We conclude with a second illustration of Bayes net 2h in which two people agree on the interpretation of an observed piece of evidence but disagree about the implications of that evidence. In this scenario, Alice and Bob are two economists with different philosophies about how the federal government should approach a major recession. Alice believes that the federal government should increase its own spending to stimulate economic activity; Bob believes that the government should decrease its spending and reduce taxes instead, providing taxpayers with more spending money. A new bill has just been proposed and an independent study found that the bill was likely to increase federal spending. Alice and Bob now assess the likelihood that this piece of legislation will improve the economic climate. This scenario can be modeled by the Bayes net and associated CPDs in Figure 3d. In the tables, the hypothesis space H = {‘Bad policy’ = 0, ‘Good policy’ = 1} represents whether the new bill is good for the economy and the data variable D = {‘No spending’ = 0, ‘Spending increase’ = 1} represents the conclusions of the independent study. Unlike in previous scenarios, we introduce two additional factors, V 1 = {‘Fiscally conservative’ = 0, ‘Fiscally liberal’ = 1}, which represents the optimal economic philosophy, and V 2 = {‘No spending’ = 0, ‘Spending increase’ = 1}, which represents the spending policy of the new bill. The exact probabilities in the tables were chosen to reﬂect the fact that if the bill does not increase spending, the policy it enacts may still be good for other reasons. A uniform prior was placed on V 2 for both people, reﬂecting the fact that they have no prior expectations about the spending in the bill. However, the priors placed on V 1 for Alice and Bob reﬂect their different beliefs about the best economic policy. The resulting belief divergence behavior is shown in Figure 4d. The model used in this scenario bears a strong resemblance to the probabilogical model of attitude change developed by McGuire [14] in which V 1 and V 2 might be logical “premises” that entail the “conclusion” H. 4 How common is contrary updating? We have now described four concrete cases where belief divergence is captured by a normative approach. It is possible, however, that belief divergence is relatively rare within the Bayes nets of Family 2, and that our four examples are exotic special cases that depend on carefully selected CPDs. To rule out this possibility, we ran simulations to explore the space of all possible CPDs for the three networks in Family 2. We initially considered cases where H, D, and V were binary variables, and ran two simulations for each model. In one simulation, the priors and each row of each CPD were sampled from a symmetric Beta distribution with parameter 0.1, resulting in probabilities highly biased toward 0 and 1. In the second simulation, the probabilities were sampled from a uniform distribution. In each trial, a single set of CPDs were generated and then two different priors were generated for each root node in the graph to simulate two individuals, consistent with our assumption that two individuals may have different priors but must agree about the conditional probabilities. 20,000 trials were carried out in each simulation, and the proportion of trials that led to convergence and divergence was computed. Trials were only counted as instances of convergence or divergence if |P (H = 1|D = 1) − P (H = 1)| > for both individuals, with = 1 × 10−5 . The results of these simulations are shown in Table 2. The supporting material proves that divergence and convergence are equally common, and therefore the percentages in the table show the frequencies for contrary updating of either type. Our primary question was whether contrary updating is rare or anomalous. In all but the third simulation, contrary updating constituted a substantial proportion of trials, suggesting that the phenomenon is relatively generic. We were also interested in whether this behavior relied on particular settings of the CPDs. The fact that percentages for the uniform distribution are approximately the same or greater than for the biased distribution indicates that contrary updating appears to be a relatively generic behavior for the Bayes nets we considered. More generally, these results directly challenge the suggestion that normative accounts are not suited for modeling belief divergence. The last two columns of Table 2 show results for two simulations with the same Bayes net, the only difference being whether V was treated as 2-valued (binary) or 4-valued. The 4-valued case is included because both Examples 3 and 4 considered multi-valued additional factor variables V . 7 2-valued V V H Biased Uniform 4-valued V V V V D 9.6% 18.2% D H 12.7% 16.0% H D 0% 0% H D 23.3% 20.0% Table 2: Simulation results. The percentages indicate the proportion of trials that produced contrary updating using the speciﬁed Bayes net (column) and probability distributions (row). The prior and conditional probabilities were either sampled from a Beta(0.1, 0.1) distribution (biased) or a Beta(1, 1) distribution (uniform). The probabilities for the simulation results shown in the last column were sampled from a Dirichlet([0.1, 0.1, 0.1, 0.1]) distribution (biased) or a Dirichlet([1, 1, 1, 1]) distribution (uniform). In Example 4, we used two binary variables, but we could have equivalently used a single 4-valued variable. Belief convergence and divergence are not possible in the binary case, a result that is proved in the supporting material. We believe, however, that convergence and divergence are fairly common whenever V takes three or more values, and the simulation in the last column of the table conﬁrms this claim for the 4-valued case. Given that belief divergence seems relatively common in the space of all Bayes nets, it is natural to explore whether cases of rational divergence are regularly encountered in the real world. One possible approach is to analyze a large database of networks that capture everyday belief revision problems, and to determine what proportion of networks lead to rational divergence. Future studies can explore this issue, but our simulations suggest that contrary updating is likely to arise in cases where it is necessary to move beyond a simple model like the one in Figure 2a and consider several causal factors. 5 Conclusion This paper presented a family of Bayes nets that can account for belief divergence, a phenomenon that is typically considered to be incompatible with normative accounts. We provided four concrete examples that illustrate how this family of networks can capture a variety of settings where belief divergence can emerge from rational statistical inference. We also described a series of simulations that suggest that belief divergence is not only possible but relatively common within the family of networks that we considered. Our work suggests that belief polarization should not always be taken as evidence of irrationality, and that researchers who aim to document departures from rationality may wish to consider alternative phenomena instead. One such phenomenon might be called “inevitable belief reinforcement” and occurs when supporters of a hypothesis update their belief in the same direction for all possible data sets d. For example, a gambler will demonstrate inevitable belief reinforcement if he or she becomes increasingly convinced that a roulette wheel is biased towards red regardless of whether the next spin produces red, black, or green. This phenomenon is provably inconsistent with any fully Bayesian approach, and therefore provides strong evidence of irrationality. Although we propose that some instances of polarization are compatible with a Bayesian approach, we do not claim that human inferences are always or even mostly rational. We suggest, however, that characterizing normative behavior can require careful thought, and that formal analyses are invaluable for assessing the rationality of human inferences. In some cases, a formal analysis will provide an appropriate baseline for understanding how human inferences depart from rational norms. In other cases, a formal analysis will suggest that an apparently irrational inference makes sense once all of the relevant information is taken into account. 8 References [1] C. G. Lord, L. Ross, and M. R. Lepper. Biased assimilation and attitude polarization: The effects of prior theories on subsequently considered evidence. Journal of Personality and Social Psychology, 37(1):2098–2109, 1979. [2] L. Ross and M. R. Lepper. The perseverance of beliefs: Empirical and normative considerations. In New directions for methodology of social and behavioral science: Fallible judgment in behavioral research. Jossey-Bass, San Francisco, 1980. [3] J. Baron. Thinking and Deciding. Cambridge University Press, Cambridge, 4th edition, 2008. [4] A. Gerber and D. Green. Misperceptions about perceptual bias. Annual Review of Political Science, 2:189–210, 1999. [5] M. Oaksford and N. Chater. A rational analysis of the selection task as optimal data selection. Psychological Review, 101(4):608–631, 1994. [6] U. Hahn and M. Oaksford. The rationality of informal argumentation: A Bayesian approach to reasoning fallacies. Psychological Review, 114(3):704–732, 2007. [7] S. Sher and C. R. M. McKenzie. Framing effects and rationality. In N. Chater and M. Oaksford, editors, The probablistic mind: Prospects for Bayesian cognitive science. Oxford University Press, Oxford, 2008. [8] B. O’Connor. Biased evidence assimilation under bounded Bayesian rationality. Master’s thesis, Stanford University, 2006. [9] A. Zimper and A. Ludwig. Attitude polarization. Technical report, Mannheim Research Institute for the Economics of Aging, 2007. [10] A. K. Dixit and J. W. Weibull. Political polarization. Proceedings of the National Academy of Sciences, 104(18):7351–7356, 2007. [11] L. L. Lopes. Averaging rules and adjustment processes in Bayesian inference. Bulletin of the Psychonomic Society, 23(6):509–512, 1985. [12] A. Harris, A. Corner, and U. Hahn. “Damned by faint praise”: A Bayesian account. In A. D. De Groot and G. Heymans, editors, Proceedings of the 31th Annual Conference of the Cognitive Science Society, Austin, TX, 2009. Cognitive Science Society. [13] C. D. Batson. Rational processing or rationalization? The effect of disconﬁrming information on a stated religious belief. Journal of Personality and Social Psychology, 32(1):176–184, 1975. [14] W. J. McGuire. The probabilogical model of cognitive structure and attitude change. In R. E. Petty, T. M. Ostrom, and T. C. Brock, editors, Cognitive Responses in Persuasion. Lawrence Erlbaum Associates, 1981. 9</p><p>2 0.95023894 <a title="166-lda-2" href="./nips-2009-Who%E2%80%99s_Doing_What%3A_Joint_Modeling_of_Names_and_Verbs_for_Simultaneous_Face_and_Pose_Annotation.html">259 nips-2009-Who’s Doing What: Joint Modeling of Names and Verbs for Simultaneous Face and Pose Annotation</a></p>
<p>Author: Jie Luo, Barbara Caputo, Vittorio Ferrari</p><p>Abstract: Given a corpus of news items consisting of images accompanied by text captions, we want to ﬁnd out “who’s doing what”, i.e. associate names and action verbs in the captions to the face and body pose of the persons in the images. We present a joint model for simultaneously solving the image-caption correspondences and learning visual appearance models for the face and pose classes occurring in the corpus. These models can then be used to recognize people and actions in novel images without captions. We demonstrate experimentally that our joint ‘face and pose’ model solves the correspondence problem better than earlier models covering only the face, and that it can perform recognition of new uncaptioned images. 1</p><p>3 0.91555482 <a title="166-lda-3" href="./nips-2009-Code-specific_policy_gradient_rules_for_spiking_neurons.html">52 nips-2009-Code-specific policy gradient rules for spiking neurons</a></p>
<p>Author: Henning Sprekeler, Guillaume Hennequin, Wulfram Gerstner</p><p>Abstract: Although it is widely believed that reinforcement learning is a suitable tool for describing behavioral learning, the mechanisms by which it can be implemented in networks of spiking neurons are not fully understood. Here, we show that different learning rules emerge from a policy gradient approach depending on which features of the spike trains are assumed to inﬂuence the reward signals, i.e., depending on which neural code is in effect. We use the framework of Williams (1992) to derive learning rules for arbitrary neural codes. For illustration, we present policy-gradient rules for three different example codes - a spike count code, a spike timing code and the most general “full spike train” code - and test them on simple model problems. In addition to classical synaptic learning, we derive learning rules for intrinsic parameters that control the excitability of the neuron. The spike count learning rule has structural similarities with established Bienenstock-Cooper-Munro rules. If the distribution of the relevant spike train features belongs to the natural exponential family, the learning rules have a characteristic shape that raises interesting prediction problems. 1</p><p>4 0.86084878 <a title="166-lda-4" href="./nips-2009-Semi-supervised_Learning_using_Sparse_Eigenfunction_Bases.html">213 nips-2009-Semi-supervised Learning using Sparse Eigenfunction Bases</a></p>
<p>Author: Kaushik Sinha, Mikhail Belkin</p><p>Abstract: We present a new framework for semi-supervised learning with sparse eigenfunction bases of kernel matrices. It turns out that when the data has clustered, that is, when the high density regions are sufﬁciently separated by low density valleys, each high density area corresponds to a unique representative eigenvector. Linear combination of such eigenvectors (or, more precisely, of their Nystrom extensions) provide good candidates for good classiﬁcation functions when the cluster assumption holds. By ﬁrst choosing an appropriate basis of these eigenvectors from unlabeled data and then using labeled data with Lasso to select a classiﬁer in the span of these eigenvectors, we obtain a classiﬁer, which has a very sparse representation in this basis. Importantly, the sparsity corresponds naturally to the cluster assumption. Experimental results on a number of real-world data-sets show that our method is competitive with the state of the art semi-supervised learning algorithms and outperforms the natural base-line algorithm (Lasso in the Kernel PCA basis). 1</p><p>same-paper 5 0.8404386 <a title="166-lda-5" href="./nips-2009-Noisy_Generalized_Binary_Search.html">166 nips-2009-Noisy Generalized Binary Search</a></p>
<p>Author: Robert Nowak</p><p>Abstract: This paper addresses the problem of noisy Generalized Binary Search (GBS). GBS is a well-known greedy algorithm for determining a binary-valued hypothesis through a sequence of strategically selected queries. At each step, a query is selected that most evenly splits the hypotheses under consideration into two disjoint subsets, a natural generalization of the idea underlying classic binary search. GBS is used in many applications, including fault testing, machine diagnostics, disease diagnosis, job scheduling, image processing, computer vision, and active learning. In most of these cases, the responses to queries can be noisy. Past work has provided a partial characterization of GBS, but existing noise-tolerant versions of GBS are suboptimal in terms of query complexity. This paper presents an optimal algorithm for noisy GBS and demonstrates its application to learning multidimensional threshold functions. 1</p><p>6 0.68955493 <a title="166-lda-6" href="./nips-2009-Nonlinear_Learning_using_Local_Coordinate_Coding.html">169 nips-2009-Nonlinear Learning using Local Coordinate Coding</a></p>
<p>7 0.68353081 <a title="166-lda-7" href="./nips-2009-STDP_enables_spiking_neurons_to_detect_hidden_causes_of_their_inputs.html">210 nips-2009-STDP enables spiking neurons to detect hidden causes of their inputs</a></p>
<p>8 0.67933446 <a title="166-lda-8" href="./nips-2009-Time-rescaling_methods_for_the_estimation_and_assessment_of_non-Poisson_neural_encoding_models.html">247 nips-2009-Time-rescaling methods for the estimation and assessment of non-Poisson neural encoding models</a></p>
<p>9 0.64545929 <a title="166-lda-9" href="./nips-2009-Locality-sensitive_binary_codes_from_shift-invariant_kernels.html">142 nips-2009-Locality-sensitive binary codes from shift-invariant kernels</a></p>
<p>10 0.64167541 <a title="166-lda-10" href="./nips-2009-Statistical_Analysis_of_Semi-Supervised_Learning%3A_The_Limit_of_Infinite_Unlabelled_Data.html">229 nips-2009-Statistical Analysis of Semi-Supervised Learning: The Limit of Infinite Unlabelled Data</a></p>
<p>11 0.63898134 <a title="166-lda-11" href="./nips-2009-Learning_a_Small_Mixture_of_Trees.html">129 nips-2009-Learning a Small Mixture of Trees</a></p>
<p>12 0.63851357 <a title="166-lda-12" href="./nips-2009-Kernel_Choice_and_Classifiability_for_RKHS_Embeddings_of_Probability_Distributions.html">118 nips-2009-Kernel Choice and Classifiability for RKHS Embeddings of Probability Distributions</a></p>
<p>13 0.63850594 <a title="166-lda-13" href="./nips-2009-A_joint_maximum-entropy_model_for_binary_neural_population_patterns_and_continuous_signals.html">19 nips-2009-A joint maximum-entropy model for binary neural population patterns and continuous signals</a></p>
<p>14 0.63752925 <a title="166-lda-14" href="./nips-2009-3D_Object_Recognition_with_Deep_Belief_Nets.html">2 nips-2009-3D Object Recognition with Deep Belief Nets</a></p>
<p>15 0.63649857 <a title="166-lda-15" href="./nips-2009-Adaptive_Regularization_of_Weight_Vectors.html">27 nips-2009-Adaptive Regularization of Weight Vectors</a></p>
<p>16 0.63471669 <a title="166-lda-16" href="./nips-2009-Correlation_Coefficients_are_Insufficient_for_Analyzing_Spike_Count_Dependencies.html">62 nips-2009-Correlation Coefficients are Insufficient for Analyzing Spike Count Dependencies</a></p>
<p>17 0.63125896 <a title="166-lda-17" href="./nips-2009-Distribution_Matching_for_Transduction.html">72 nips-2009-Distribution Matching for Transduction</a></p>
<p>18 0.63085788 <a title="166-lda-18" href="./nips-2009-An_Infinite_Factor_Model_Hierarchy_Via_a_Noisy-Or_Mechanism.html">29 nips-2009-An Infinite Factor Model Hierarchy Via a Noisy-Or Mechanism</a></p>
<p>19 0.63032538 <a title="166-lda-19" href="./nips-2009-Potential-Based_Agnostic_Boosting.html">193 nips-2009-Potential-Based Agnostic Boosting</a></p>
<p>20 0.62865347 <a title="166-lda-20" href="./nips-2009-Replacing_supervised_classification_learning_by_Slow_Feature_Analysis_in_spiking_neural_networks.html">203 nips-2009-Replacing supervised classification learning by Slow Feature Analysis in spiking neural networks</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
