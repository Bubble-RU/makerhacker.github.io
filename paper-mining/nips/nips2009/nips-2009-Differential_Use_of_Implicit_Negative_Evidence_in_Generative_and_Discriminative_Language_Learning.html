<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>66 nips-2009-Differential Use of Implicit Negative Evidence in Generative and Discriminative Language Learning</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-66" href="#">nips2009-66</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>66 nips-2009-Differential Use of Implicit Negative Evidence in Generative and Discriminative Language Learning</h1>
<br/><p>Source: <a title="nips-2009-66-pdf" href="http://papers.nips.cc/paper/3760-differential-use-of-implicit-negative-evidence-in-generative-and-discriminative-language-learning.pdf">pdf</a></p><p>Author: Anne Hsu, Thomas L. Griffiths</p><p>Abstract: A classic debate in cognitive science revolves around understanding how children learn complex linguistic rules, such as those governing restrictions on verb alternations, without negative evidence. Traditionally, formal learnability arguments have been used to claim that such learning is impossible without the aid of innate language-speciﬁc knowledge. However, recently, researchers have shown that statistical models are capable of learning complex rules from only positive evidence. These two kinds of learnability analyses differ in their assumptions about the distribution from which linguistic input is generated. The former analyses assume that learners seek to identify grammatical sentences in a way that is robust to the distribution from which the sentences are generated, analogous to discriminative approaches in machine learning. The latter assume that learners are trying to estimate a generative model, with sentences being sampled from that model. We show that these two learning approaches differ in their use of implicit negative evidence – the absence of a sentence – when learning verb alternations, and demonstrate that human learners can produce results consistent with the predictions of both approaches, depending on how the learning problem is presented. 1</p><p>Reference: <a title="nips-2009-66-reference" href="../nips2009_reference/nips-2009-Differential_Use_of_Implicit_Negative_Evidence_in_Generative_and_Discriminative_Language_Learning_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('sent', 0.628), ('verb', 0.485), ('gram', 0.435), ('langu', 0.187), ('ungram', 0.18), ('particip', 0.157), ('discrimin', 0.093), ('nagid', 0.085), ('lingu', 0.067), ('tomb', 0.065), ('hbm', 0.064), ('spok', 0.056), ('evid', 0.054), ('ern', 0.053), ('semz', 0.053), ('heard', 0.051), ('deb', 0.05), ('noun', 0.05), ('gramm', 0.048), ('childr', 0.048)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="66-tfidf-1" href="./nips-2009-Differential_Use_of_Implicit_Negative_Evidence_in_Generative_and_Discriminative_Language_Learning.html">66 nips-2009-Differential Use of Implicit Negative Evidence in Generative and Discriminative Language Learning</a></p>
<p>2 0.30586067 <a title="66-tfidf-2" href="./nips-2009-Who%E2%80%99s_Doing_What%3A_Joint_Modeling_of_Names_and_Verbs_for_Simultaneous_Face_and_Pose_Annotation.html">259 nips-2009-Who’s Doing What: Joint Modeling of Names and Verbs for Simultaneous Face and Pose Annotation</a></p>
<p>3 0.15865113 <a title="66-tfidf-3" href="./nips-2009-Quantification_and_the_language_of_thought.html">196 nips-2009-Quantification and the language of thought</a></p>
<p>4 0.12723622 <a title="66-tfidf-4" href="./nips-2009-Randomized_Pruning%3A_Efficiently_Calculating_Expectations_in_Large_Dynamic_Programs.html">197 nips-2009-Randomized Pruning: Efficiently Calculating Expectations in Large Dynamic Programs</a></p>
<p>5 0.10116745 <a title="66-tfidf-5" href="./nips-2009-Abstraction_and_Relational_learning.html">21 nips-2009-Abstraction and Relational learning</a></p>
<p>6 0.093434967 <a title="66-tfidf-6" href="./nips-2009-A_Fast%2C_Consistent_Kernel_Two-Sample_Test.html">8 nips-2009-A Fast, Consistent Kernel Two-Sample Test</a></p>
<p>7 0.077906109 <a title="66-tfidf-7" href="./nips-2009-Human_Rademacher_Complexity.html">112 nips-2009-Human Rademacher Complexity</a></p>
<p>8 0.065271087 <a title="66-tfidf-8" href="./nips-2009-Streaming_Pointwise_Mutual_Information.html">233 nips-2009-Streaming Pointwise Mutual Information</a></p>
<p>9 0.064876884 <a title="66-tfidf-9" href="./nips-2009-Discriminative_Network_Models_of_Schizophrenia.html">70 nips-2009-Discriminative Network Models of Schizophrenia</a></p>
<p>10 0.063054167 <a title="66-tfidf-10" href="./nips-2009-Individuation%2C_Identification_and_Object_Discovery.html">115 nips-2009-Individuation, Identification and Object Discovery</a></p>
<p>11 0.062477354 <a title="66-tfidf-11" href="./nips-2009-Hierarchical_Learning_of_Dimensional_Biases_in_Human_Categorization.html">109 nips-2009-Hierarchical Learning of Dimensional Biases in Human Categorization</a></p>
<p>12 0.061553199 <a title="66-tfidf-12" href="./nips-2009-Adaptive_Design_Optimization_in_Experiments_with_People.html">25 nips-2009-Adaptive Design Optimization in Experiments with People</a></p>
<p>13 0.048080292 <a title="66-tfidf-13" href="./nips-2009-A_Bayesian_Analysis_of_Dynamics_in_Free_Recall.html">4 nips-2009-A Bayesian Analysis of Dynamics in Free Recall</a></p>
<p>14 0.04073789 <a title="66-tfidf-14" href="./nips-2009-Zero-shot_Learning_with_Semantic_Output_Codes.html">260 nips-2009-Zero-shot Learning with Semantic Output Codes</a></p>
<p>15 0.040722102 <a title="66-tfidf-15" href="./nips-2009-FACTORIE%3A_Probabilistic_Programming_via_Imperatively_Defined_Factor_Graphs.html">89 nips-2009-FACTORIE: Probabilistic Programming via Imperatively Defined Factor Graphs</a></p>
<p>16 0.038324282 <a title="66-tfidf-16" href="./nips-2009-Distribution_Matching_for_Transduction.html">72 nips-2009-Distribution Matching for Transduction</a></p>
<p>17 0.036094666 <a title="66-tfidf-17" href="./nips-2009-Posterior_vs_Parameter_Sparsity_in_Latent_Variable_Models.html">192 nips-2009-Posterior vs Parameter Sparsity in Latent Variable Models</a></p>
<p>18 0.034959767 <a title="66-tfidf-18" href="./nips-2009-Nonlinear_directed_acyclic_structure_learning_with_weakly_additive_noise_models.html">170 nips-2009-Nonlinear directed acyclic structure learning with weakly additive noise models</a></p>
<p>19 0.032444861 <a title="66-tfidf-19" href="./nips-2009-Augmenting_Feature-driven_fMRI_Analyses%3A_Semi-supervised_learning_and_resting_state_activity.html">38 nips-2009-Augmenting Feature-driven fMRI Analyses: Semi-supervised learning and resting state activity</a></p>
<p>20 0.032210603 <a title="66-tfidf-20" href="./nips-2009-Unsupervised_feature_learning_for_audio_classification_using_convolutional_deep_belief_networks.html">253 nips-2009-Unsupervised feature learning for audio classification using convolutional deep belief networks</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.086), (1, -0.003), (2, -0.066), (3, 0.06), (4, 0.038), (5, -0.024), (6, 0.017), (7, 0.051), (8, 0.096), (9, -0.01), (10, 0.113), (11, 0.087), (12, -0.188), (13, 0.075), (14, 0.054), (15, 0.012), (16, 0.016), (17, 0.078), (18, -0.039), (19, -0.038), (20, -0.069), (21, -0.036), (22, 0.146), (23, 0.003), (24, -0.2), (25, -0.208), (26, -0.125), (27, 0.313), (28, 0.132), (29, 0.015), (30, 0.004), (31, 0.029), (32, -0.053), (33, 0.005), (34, 0.096), (35, -0.102), (36, -0.119), (37, 0.075), (38, -0.195), (39, 0.103), (40, -0.052), (41, 0.19), (42, -0.05), (43, -0.018), (44, -0.053), (45, 0.146), (46, -0.15), (47, 0.067), (48, 0.055), (49, -0.001)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96895546 <a title="66-lsi-1" href="./nips-2009-Differential_Use_of_Implicit_Negative_Evidence_in_Generative_and_Discriminative_Language_Learning.html">66 nips-2009-Differential Use of Implicit Negative Evidence in Generative and Discriminative Language Learning</a></p>
<p>2 0.7480219 <a title="66-lsi-2" href="./nips-2009-Who%E2%80%99s_Doing_What%3A_Joint_Modeling_of_Names_and_Verbs_for_Simultaneous_Face_and_Pose_Annotation.html">259 nips-2009-Who’s Doing What: Joint Modeling of Names and Verbs for Simultaneous Face and Pose Annotation</a></p>
<p>3 0.47342071 <a title="66-lsi-3" href="./nips-2009-Quantification_and_the_language_of_thought.html">196 nips-2009-Quantification and the language of thought</a></p>
<p>4 0.46855286 <a title="66-lsi-4" href="./nips-2009-Randomized_Pruning%3A_Efficiently_Calculating_Expectations_in_Large_Dynamic_Programs.html">197 nips-2009-Randomized Pruning: Efficiently Calculating Expectations in Large Dynamic Programs</a></p>
<p>5 0.46518707 <a title="66-lsi-5" href="./nips-2009-Streaming_Pointwise_Mutual_Information.html">233 nips-2009-Streaming Pointwise Mutual Information</a></p>
<p>6 0.31587121 <a title="66-lsi-6" href="./nips-2009-Abstraction_and_Relational_learning.html">21 nips-2009-Abstraction and Relational learning</a></p>
<p>7 0.3051399 <a title="66-lsi-7" href="./nips-2009-Posterior_vs_Parameter_Sparsity_in_Latent_Variable_Models.html">192 nips-2009-Posterior vs Parameter Sparsity in Latent Variable Models</a></p>
<p>8 0.29775119 <a title="66-lsi-8" href="./nips-2009-A_Fast%2C_Consistent_Kernel_Two-Sample_Test.html">8 nips-2009-A Fast, Consistent Kernel Two-Sample Test</a></p>
<p>9 0.29711697 <a title="66-lsi-9" href="./nips-2009-Adaptive_Design_Optimization_in_Experiments_with_People.html">25 nips-2009-Adaptive Design Optimization in Experiments with People</a></p>
<p>10 0.25533018 <a title="66-lsi-10" href="./nips-2009-Human_Rademacher_Complexity.html">112 nips-2009-Human Rademacher Complexity</a></p>
<p>11 0.22783075 <a title="66-lsi-11" href="./nips-2009-The_Wisdom_of_Crowds_in_the_Recollection_of_Order_Information.html">244 nips-2009-The Wisdom of Crowds in the Recollection of Order Information</a></p>
<p>12 0.22619379 <a title="66-lsi-12" href="./nips-2009-Bayesian_Belief_Polarization.html">39 nips-2009-Bayesian Belief Polarization</a></p>
<p>13 0.20859976 <a title="66-lsi-13" href="./nips-2009-Individuation%2C_Identification_and_Object_Discovery.html">115 nips-2009-Individuation, Identification and Object Discovery</a></p>
<p>14 0.17767775 <a title="66-lsi-14" href="./nips-2009-Discriminative_Network_Models_of_Schizophrenia.html">70 nips-2009-Discriminative Network Models of Schizophrenia</a></p>
<p>15 0.17326872 <a title="66-lsi-15" href="./nips-2009-Structured_output_regression_for_detection_with_partial_truncation.html">236 nips-2009-Structured output regression for detection with partial truncation</a></p>
<p>16 0.16537303 <a title="66-lsi-16" href="./nips-2009-Measuring_model_complexity_with_the_prior_predictive.html">152 nips-2009-Measuring model complexity with the prior predictive</a></p>
<p>17 0.16313878 <a title="66-lsi-17" href="./nips-2009-FACTORIE%3A_Probabilistic_Programming_via_Imperatively_Defined_Factor_Graphs.html">89 nips-2009-FACTORIE: Probabilistic Programming via Imperatively Defined Factor Graphs</a></p>
<p>18 0.16135959 <a title="66-lsi-18" href="./nips-2009-Perceptual_Multistability_as_Markov_Chain_Monte_Carlo_Inference.html">188 nips-2009-Perceptual Multistability as Markov Chain Monte Carlo Inference</a></p>
<p>19 0.1596012 <a title="66-lsi-19" href="./nips-2009-Nonparametric_Bayesian_Models_for_Unsupervised_Event_Coreference_Resolution.html">171 nips-2009-Nonparametric Bayesian Models for Unsupervised Event Coreference Resolution</a></p>
<p>20 0.15178742 <a title="66-lsi-20" href="./nips-2009-Sequential_effects_reflect_parallel_learning_of_multiple_environmental_regularities.html">216 nips-2009-Sequential effects reflect parallel learning of multiple environmental regularities</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(9, 0.177), (11, 0.014), (30, 0.37), (31, 0.052), (37, 0.02), (60, 0.144), (89, 0.024), (96, 0.051)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.73762369 <a title="66-lda-1" href="./nips-2009-Differential_Use_of_Implicit_Negative_Evidence_in_Generative_and_Discriminative_Language_Learning.html">66 nips-2009-Differential Use of Implicit Negative Evidence in Generative and Discriminative Language Learning</a></p>
<p>2 0.71387154 <a title="66-lda-2" href="./nips-2009-Indian_Buffet_Processes_with_Power-law_Behavior.html">114 nips-2009-Indian Buffet Processes with Power-law Behavior</a></p>
<p>3 0.62488222 <a title="66-lda-3" href="./nips-2009-Exponential_Family_Graph_Matching_and_Ranking.html">87 nips-2009-Exponential Family Graph Matching and Ranking</a></p>
<p>4 0.54334736 <a title="66-lda-4" href="./nips-2009-Streaming_Pointwise_Mutual_Information.html">233 nips-2009-Streaming Pointwise Mutual Information</a></p>
<p>5 0.54177839 <a title="66-lda-5" href="./nips-2009-Dirichlet-Bernoulli_Alignment%3A_A_Generative_Model_for_Multi-Class_Multi-Label_Multi-Instance_Corpora.html">68 nips-2009-Dirichlet-Bernoulli Alignment: A Generative Model for Multi-Class Multi-Label Multi-Instance Corpora</a></p>
<p>6 0.54130018 <a title="66-lda-6" href="./nips-2009-Maximin_affinity_learning_of_image_segmentation.html">149 nips-2009-Maximin affinity learning of image segmentation</a></p>
<p>7 0.539536 <a title="66-lda-7" href="./nips-2009-Semi-Supervised_Learning_in_Gigantic_Image_Collections.html">212 nips-2009-Semi-Supervised Learning in Gigantic Image Collections</a></p>
<p>8 0.53873461 <a title="66-lda-8" href="./nips-2009-Modelling_Relational_Data_using_Bayesian_Clustered_Tensor_Factorization.html">155 nips-2009-Modelling Relational Data using Bayesian Clustered Tensor Factorization</a></p>
<p>9 0.53730786 <a title="66-lda-9" href="./nips-2009-Individuation%2C_Identification_and_Object_Discovery.html">115 nips-2009-Individuation, Identification and Object Discovery</a></p>
<p>10 0.53700811 <a title="66-lda-10" href="./nips-2009-Modeling_Social_Annotation_Data_with_Content_Relevance_using_a_Topic_Model.html">153 nips-2009-Modeling Social Annotation Data with Content Relevance using a Topic Model</a></p>
<p>11 0.5334326 <a title="66-lda-11" href="./nips-2009-Nonparametric_Latent_Feature_Models_for_Link_Prediction.html">174 nips-2009-Nonparametric Latent Feature Models for Link Prediction</a></p>
<p>12 0.53334981 <a title="66-lda-12" href="./nips-2009-Learning_to_Rank_by_Optimizing_NDCG_Measure.html">136 nips-2009-Learning to Rank by Optimizing NDCG Measure</a></p>
<p>13 0.53242171 <a title="66-lda-13" href="./nips-2009-Modeling_the_spacing_effect_in_sequential_category_learning.html">154 nips-2009-Modeling the spacing effect in sequential category learning</a></p>
<p>14 0.52485567 <a title="66-lda-14" href="./nips-2009-Large_Scale_Nonparametric_Bayesian_Inference%3A_Data_Parallelisation_in_the_Indian_Buffet_Process.html">123 nips-2009-Large Scale Nonparametric Bayesian Inference: Data Parallelisation in the Indian Buffet Process</a></p>
<p>15 0.52373117 <a title="66-lda-15" href="./nips-2009-Multi-Label_Prediction_via_Sparse_Infinite_CCA.html">158 nips-2009-Multi-Label Prediction via Sparse Infinite CCA</a></p>
<p>16 0.52291566 <a title="66-lda-16" href="./nips-2009-Whose_Vote_Should_Count_More%3A_Optimal_Integration_of_Labels_from_Labelers_of_Unknown_Expertise.html">258 nips-2009-Whose Vote Should Count More: Optimal Integration of Labels from Labelers of Unknown Expertise</a></p>
<p>17 0.5226115 <a title="66-lda-17" href="./nips-2009-Semi-supervised_Learning_using_Sparse_Eigenfunction_Bases.html">213 nips-2009-Semi-supervised Learning using Sparse Eigenfunction Bases</a></p>
<p>18 0.5205521 <a title="66-lda-18" href="./nips-2009-Replicated_Softmax%3A_an_Undirected_Topic_Model.html">204 nips-2009-Replicated Softmax: an Undirected Topic Model</a></p>
<p>19 0.51910895 <a title="66-lda-19" href="./nips-2009-Ranking_Measures_and_Loss_Functions_in_Learning_to_Rank.html">199 nips-2009-Ranking Measures and Loss Functions in Learning to Rank</a></p>
<p>20 0.51768214 <a title="66-lda-20" href="./nips-2009-Decoupling_Sparsity_and_Smoothness_in_the_Discrete_Hierarchical_Dirichlet_Process.html">65 nips-2009-Decoupling Sparsity and Smoothness in the Discrete Hierarchical Dirichlet Process</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
