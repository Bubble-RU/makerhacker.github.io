<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>118 nips-2009-Kernel Choice and Classifiability for RKHS Embeddings of Probability Distributions</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-118" href="#">nips2009-118</a> knowledge-graph by maker-knowledge-mining</p><h1>118 nips-2009-Kernel Choice and Classifiability for RKHS Embeddings of Probability Distributions</h1>
<br/><p>Source: <a title="nips-2009-118-pdf" href="http://papers.nips.cc/paper/3750-kernel-choice-and-classifiability-for-rkhs-embeddings-of-probability-distributions.pdf">pdf</a></p><p>Author: Kenji Fukumizu, Arthur Gretton, Gert R. Lanckriet, Bernhard Schölkopf, Bharath K. Sriperumbudur</p><p>Abstract: Embeddings of probability measures into reproducing kernel Hilbert spaces have been proposed as a straightforward and practical means of representing and comparing probabilities. In particular, the distance between embeddings (the maximum mean discrepancy, or MMD) has several key advantages over many classical metrics on distributions, namely easy computability, fast convergence and low bias of ﬁnite sample estimates. An important requirement of the embedding RKHS is that it be characteristic: in this case, the MMD between two distributions is zero if and only if the distributions coincide. Three new results on the MMD are introduced in the present study. First, it is established that MMD corresponds to the optimal risk of a kernel classiﬁer, thus forming a natural link between the distance between distributions and their ease of classiﬁcation. An important consequence is that a kernel must be characteristic to guarantee classiﬁability between distributions in the RKHS. Second, the class of characteristic kernels is broadened to incorporate all strictly positive deﬁnite kernels: these include non-translation invariant kernels and kernels on non-compact domains. Third, a generalization of the MMD is proposed for families of kernels, as the supremum over MMDs on a class of kernels (for instance the Gaussian kernels with different bandwidths). This extension is necessary to obtain a single distance measure if a large selection or class of characteristic kernels is potentially appropriate. This generalization is reasonable, given that it corresponds to the problem of learning the kernel by minimizing the risk of the corresponding kernel classiﬁer. The generalized MMD is shown to have consistent ﬁnite sample estimates, and its performance is demonstrated on a homogeneity testing example. 1</p><p>Reference: <a title="nips-2009-118-reference" href="../nips2009_reference/nips-2009-Kernel_Choice_and_Classifiability_for_RKHS_Embeddings_of_Probability_Distributions_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('mmd', 0.477), ('kernel', 0.375), ('pm', 0.338), ('qn', 0.338), ('pd', 0.188), ('parz', 0.17), ('charact', 0.161), ('strictly', 0.156), ('rkhs', 0.141), ('kcon', 0.106), ('kg', 0.106), ('rfk', 0.106), ('gretton', 0.097), ('risk', 0.095), ('yi', 0.088), ('rd', 0.088), ('um', 0.087), ('fukumizu', 0.086), ('ki', 0.085), ('fsvm', 0.085)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999958 <a title="118-tfidf-1" href="./nips-2009-Kernel_Choice_and_Classifiability_for_RKHS_Embeddings_of_Probability_Distributions.html">118 nips-2009-Kernel Choice and Classifiability for RKHS Embeddings of Probability Distributions</a></p>
<p>2 0.40700316 <a title="118-tfidf-2" href="./nips-2009-A_Fast%2C_Consistent_Kernel_Two-Sample_Test.html">8 nips-2009-A Fast, Consistent Kernel Two-Sample Test</a></p>
<p>3 0.21366177 <a title="118-tfidf-3" href="./nips-2009-Learning_Non-Linear_Combinations_of_Kernels.html">128 nips-2009-Learning Non-Linear Combinations of Kernels</a></p>
<p>4 0.17920968 <a title="118-tfidf-4" href="./nips-2009-Kernel_Methods_for_Deep_Learning.html">119 nips-2009-Kernel Methods for Deep Learning</a></p>
<p>5 0.16772026 <a title="118-tfidf-5" href="./nips-2009-Kernels_and_learning_curves_for_Gaussian_process_regression_on_random_graphs.html">120 nips-2009-Kernels and learning curves for Gaussian process regression on random graphs</a></p>
<p>6 0.14320931 <a title="118-tfidf-6" href="./nips-2009-Fast_subtree_kernels_on_graphs.html">95 nips-2009-Fast subtree kernels on graphs</a></p>
<p>7 0.1326838 <a title="118-tfidf-7" href="./nips-2009-Efficient_Match_Kernel_between_Sets_of_Features_for_Visual_Recognition.html">77 nips-2009-Efficient Match Kernel between Sets of Features for Visual Recognition</a></p>
<p>8 0.13173237 <a title="118-tfidf-8" href="./nips-2009-Data-driven_calibration_of_linear_estimators_with_minimal_penalties.html">64 nips-2009-Data-driven calibration of linear estimators with minimal penalties</a></p>
<p>9 0.12825988 <a title="118-tfidf-9" href="./nips-2009-Which_graphical_models_are_difficult_to_learn%3F.html">256 nips-2009-Which graphical models are difficult to learn?</a></p>
<p>10 0.12488214 <a title="118-tfidf-10" href="./nips-2009-From_PAC-Bayes_Bounds_to_KL_Regularization.html">98 nips-2009-From PAC-Bayes Bounds to KL Regularization</a></p>
<p>11 0.10999006 <a title="118-tfidf-11" href="./nips-2009-Efficient_and_Accurate_Lp-Norm_Multiple_Kernel_Learning.html">80 nips-2009-Efficient and Accurate Lp-Norm Multiple Kernel Learning</a></p>
<p>12 0.10761103 <a title="118-tfidf-12" href="./nips-2009-Locality-sensitive_binary_codes_from_shift-invariant_kernels.html">142 nips-2009-Locality-sensitive binary codes from shift-invariant kernels</a></p>
<p>13 0.10603634 <a title="118-tfidf-13" href="./nips-2009-Linear-time_Algorithms_for_Pairwise_Statistical_Problems.html">139 nips-2009-Linear-time Algorithms for Pairwise Statistical Problems</a></p>
<p>14 0.10475495 <a title="118-tfidf-14" href="./nips-2009-Analysis_of_SVM_with_Indefinite_Kernels.html">33 nips-2009-Analysis of SVM with Indefinite Kernels</a></p>
<p>15 0.099298924 <a title="118-tfidf-15" href="./nips-2009-Fast_Graph_Laplacian_Regularized_Kernel_Learning_via_Semidefinite%E2%80%93Quadratic%E2%80%93Linear_Programming.html">92 nips-2009-Fast Graph Laplacian Regularized Kernel Learning via Semidefinite–Quadratic–Linear Programming</a></p>
<p>16 0.093086332 <a title="118-tfidf-16" href="./nips-2009-Distribution_Matching_for_Transduction.html">72 nips-2009-Distribution Matching for Transduction</a></p>
<p>17 0.092581749 <a title="118-tfidf-17" href="./nips-2009-On_the_Algorithmics_and_Applications_of_a_Mixed-norm_based_Kernel_Learning_Formulation.html">179 nips-2009-On the Algorithmics and Applications of a Mixed-norm based Kernel Learning Formulation</a></p>
<p>18 0.08643914 <a title="118-tfidf-18" href="./nips-2009-Occlusive_Components_Analysis.html">175 nips-2009-Occlusive Components Analysis</a></p>
<p>19 0.083935656 <a title="118-tfidf-19" href="./nips-2009-Robust_Nonparametric_Regression_with_Metric-Space_Valued_Output.html">207 nips-2009-Robust Nonparametric Regression with Metric-Space Valued Output</a></p>
<p>20 0.083676204 <a title="118-tfidf-20" href="./nips-2009-Statistical_Analysis_of_Semi-Supervised_Learning%3A_The_Limit_of_Infinite_Unlabelled_Data.html">229 nips-2009-Statistical Analysis of Semi-Supervised Learning: The Limit of Infinite Unlabelled Data</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.212), (1, 0.115), (2, 0.078), (3, -0.271), (4, 0.11), (5, 0.002), (6, 0.057), (7, 0.26), (8, 0.149), (9, -0.135), (10, 0.1), (11, -0.026), (12, 0.031), (13, 0.021), (14, 0.038), (15, 0.027), (16, -0.034), (17, -0.048), (18, -0.068), (19, -0.062), (20, -0.115), (21, -0.007), (22, 0.062), (23, 0.169), (24, -0.016), (25, -0.165), (26, -0.031), (27, 0.019), (28, -0.076), (29, -0.144), (30, -0.085), (31, -0.042), (32, 0.004), (33, 0.045), (34, 0.006), (35, 0.148), (36, -0.126), (37, -0.02), (38, 0.114), (39, -0.038), (40, -0.027), (41, -0.03), (42, 0.138), (43, -0.068), (44, 0.069), (45, 0.038), (46, -0.032), (47, -0.059), (48, 0.009), (49, 0.086)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9426142 <a title="118-lsi-1" href="./nips-2009-Kernel_Choice_and_Classifiability_for_RKHS_Embeddings_of_Probability_Distributions.html">118 nips-2009-Kernel Choice and Classifiability for RKHS Embeddings of Probability Distributions</a></p>
<p>2 0.87080026 <a title="118-lsi-2" href="./nips-2009-A_Fast%2C_Consistent_Kernel_Two-Sample_Test.html">8 nips-2009-A Fast, Consistent Kernel Two-Sample Test</a></p>
<p>3 0.74957061 <a title="118-lsi-3" href="./nips-2009-Learning_Non-Linear_Combinations_of_Kernels.html">128 nips-2009-Learning Non-Linear Combinations of Kernels</a></p>
<p>4 0.67978489 <a title="118-lsi-4" href="./nips-2009-Kernel_Methods_for_Deep_Learning.html">119 nips-2009-Kernel Methods for Deep Learning</a></p>
<p>5 0.63862914 <a title="118-lsi-5" href="./nips-2009-Efficient_Match_Kernel_between_Sets_of_Features_for_Visual_Recognition.html">77 nips-2009-Efficient Match Kernel between Sets of Features for Visual Recognition</a></p>
<p>6 0.62484592 <a title="118-lsi-6" href="./nips-2009-Kernels_and_learning_curves_for_Gaussian_process_regression_on_random_graphs.html">120 nips-2009-Kernels and learning curves for Gaussian process regression on random graphs</a></p>
<p>7 0.59148002 <a title="118-lsi-7" href="./nips-2009-Fast_Graph_Laplacian_Regularized_Kernel_Learning_via_Semidefinite%E2%80%93Quadratic%E2%80%93Linear_Programming.html">92 nips-2009-Fast Graph Laplacian Regularized Kernel Learning via Semidefinite–Quadratic–Linear Programming</a></p>
<p>8 0.59067714 <a title="118-lsi-8" href="./nips-2009-Fast_subtree_kernels_on_graphs.html">95 nips-2009-Fast subtree kernels on graphs</a></p>
<p>9 0.51931125 <a title="118-lsi-9" href="./nips-2009-Data-driven_calibration_of_linear_estimators_with_minimal_penalties.html">64 nips-2009-Data-driven calibration of linear estimators with minimal penalties</a></p>
<p>10 0.5025025 <a title="118-lsi-10" href="./nips-2009-Analysis_of_SVM_with_Indefinite_Kernels.html">33 nips-2009-Analysis of SVM with Indefinite Kernels</a></p>
<p>11 0.45589757 <a title="118-lsi-11" href="./nips-2009-Linear-time_Algorithms_for_Pairwise_Statistical_Problems.html">139 nips-2009-Linear-time Algorithms for Pairwise Statistical Problems</a></p>
<p>12 0.44337708 <a title="118-lsi-12" href="./nips-2009-Efficient_and_Accurate_Lp-Norm_Multiple_Kernel_Learning.html">80 nips-2009-Efficient and Accurate Lp-Norm Multiple Kernel Learning</a></p>
<p>13 0.42354837 <a title="118-lsi-13" href="./nips-2009-Distribution_Matching_for_Transduction.html">72 nips-2009-Distribution Matching for Transduction</a></p>
<p>14 0.42053318 <a title="118-lsi-14" href="./nips-2009-Robust_Nonparametric_Regression_with_Metric-Space_Valued_Output.html">207 nips-2009-Robust Nonparametric Regression with Metric-Space Valued Output</a></p>
<p>15 0.41537362 <a title="118-lsi-15" href="./nips-2009-Multiple_Incremental_Decremental_Learning_of_Support_Vector_Machines.html">160 nips-2009-Multiple Incremental Decremental Learning of Support Vector Machines</a></p>
<p>16 0.39903206 <a title="118-lsi-16" href="./nips-2009-The_Ordered_Residual_Kernel_for_Robust_Motion_Subspace_Clustering.html">243 nips-2009-The Ordered Residual Kernel for Robust Motion Subspace Clustering</a></p>
<p>17 0.39534733 <a title="118-lsi-17" href="./nips-2009-Speaker_Comparison_with_Inner_Product_Discriminant_Functions.html">227 nips-2009-Speaker Comparison with Inner Product Discriminant Functions</a></p>
<p>18 0.39435145 <a title="118-lsi-18" href="./nips-2009-Fast%2C_smooth_and_adaptive_regression_in_metric_spaces.html">91 nips-2009-Fast, smooth and adaptive regression in metric spaces</a></p>
<p>19 0.37883243 <a title="118-lsi-19" href="./nips-2009-Locality-sensitive_binary_codes_from_shift-invariant_kernels.html">142 nips-2009-Locality-sensitive binary codes from shift-invariant kernels</a></p>
<p>20 0.37816942 <a title="118-lsi-20" href="./nips-2009-AUC_optimization_and_the_two-sample_problem.html">3 nips-2009-AUC optimization and the two-sample problem</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(9, 0.228), (11, 0.051), (31, 0.06), (60, 0.034), (83, 0.193), (89, 0.052), (96, 0.253)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.85583687 <a title="118-lda-1" href="./nips-2009-A_Fast%2C_Consistent_Kernel_Two-Sample_Test.html">8 nips-2009-A Fast, Consistent Kernel Two-Sample Test</a></p>
<p>2 0.85433745 <a title="118-lda-2" href="./nips-2009-A_Parameter-free_Hedging_Algorithm.html">14 nips-2009-A Parameter-free Hedging Algorithm</a></p>
<p>3 0.84847891 <a title="118-lda-3" href="./nips-2009-Periodic_Step_Size_Adaptation_for_Single_Pass_On-line_Learning.html">189 nips-2009-Periodic Step Size Adaptation for Single Pass On-line Learning</a></p>
<p>4 0.84110594 <a title="118-lda-4" href="./nips-2009-Efficient_and_Accurate_Lp-Norm_Multiple_Kernel_Learning.html">80 nips-2009-Efficient and Accurate Lp-Norm Multiple Kernel Learning</a></p>
<p>5 0.83964384 <a title="118-lda-5" href="./nips-2009-Sparsistent_Learning_of_Varying-coefficient_Models_with_Structural_Changes.html">225 nips-2009-Sparsistent Learning of Varying-coefficient Models with Structural Changes</a></p>
<p>6 0.83845174 <a title="118-lda-6" href="./nips-2009-Robust_Value_Function_Approximation_Using_Bilinear_Programming.html">209 nips-2009-Robust Value Function Approximation Using Bilinear Programming</a></p>
<p>same-paper 7 0.81527114 <a title="118-lda-7" href="./nips-2009-Kernel_Choice_and_Classifiability_for_RKHS_Embeddings_of_Probability_Distributions.html">118 nips-2009-Kernel Choice and Classifiability for RKHS Embeddings of Probability Distributions</a></p>
<p>8 0.76781189 <a title="118-lda-8" href="./nips-2009-Monte_Carlo_Sampling_for_Regret_Minimization_in_Extensive_Games.html">156 nips-2009-Monte Carlo Sampling for Regret Minimization in Extensive Games</a></p>
<p>9 0.76142955 <a title="118-lda-9" href="./nips-2009-Directed_Regression.html">67 nips-2009-Directed Regression</a></p>
<p>10 0.75823957 <a title="118-lda-10" href="./nips-2009-A_Smoothed_Approximate_Linear_Program.html">16 nips-2009-A Smoothed Approximate Linear Program</a></p>
<p>11 0.75491035 <a title="118-lda-11" href="./nips-2009-Ensemble_Nystrom_Method.html">81 nips-2009-Ensemble Nystrom Method</a></p>
<p>12 0.75453621 <a title="118-lda-12" href="./nips-2009-Time-Varying_Dynamic_Bayesian_Networks.html">246 nips-2009-Time-Varying Dynamic Bayesian Networks</a></p>
<p>13 0.7533583 <a title="118-lda-13" href="./nips-2009-On_Stochastic_and_Worst-case_Models_for_Investing.html">178 nips-2009-On Stochastic and Worst-case Models for Investing</a></p>
<p>14 0.75319195 <a title="118-lda-14" href="./nips-2009-Manifold_Embeddings_for_Model-Based_Reinforcement_Learning_under_Partial_Observability.html">145 nips-2009-Manifold Embeddings for Model-Based Reinforcement Learning under Partial Observability</a></p>
<p>15 0.75266016 <a title="118-lda-15" href="./nips-2009-Nash_Equilibria_of_Static_Prediction_Games.html">161 nips-2009-Nash Equilibria of Static Prediction Games</a></p>
<p>16 0.74559301 <a title="118-lda-16" href="./nips-2009-AUC_optimization_and_the_two-sample_problem.html">3 nips-2009-AUC optimization and the two-sample problem</a></p>
<p>17 0.74553955 <a title="118-lda-17" href="./nips-2009-Adapting_to_the_Shifting_Intent_of_Search_Queries.html">24 nips-2009-Adapting to the Shifting Intent of Search Queries</a></p>
<p>18 0.74313676 <a title="118-lda-18" href="./nips-2009-DUOL%3A_A_Double_Updating_Approach_for_Online_Learning.html">63 nips-2009-DUOL: A Double Updating Approach for Online Learning</a></p>
<p>19 0.74234939 <a title="118-lda-19" href="./nips-2009-Learning_Non-Linear_Combinations_of_Kernels.html">128 nips-2009-Learning Non-Linear Combinations of Kernels</a></p>
<p>20 0.7419948 <a title="118-lda-20" href="./nips-2009-Help_or_Hinder%3A_Bayesian_Models_of_Social_Goal_Inference.html">107 nips-2009-Help or Hinder: Bayesian Models of Social Goal Inference</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
