<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>49 nips-2009-Breaking Boundaries Between Induction Time and Diagnosis Time Active Information Acquisition</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-49" href="#">nips2009-49</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>49 nips-2009-Breaking Boundaries Between Induction Time and Diagnosis Time Active Information Acquisition</h1>
<br/><p>Source: <a title="nips-2009-49-pdf" href="http://papers.nips.cc/paper/3653-breaking-boundaries-between-induction-time-and-diagnosis-time-active-information-acquisition.pdf">pdf</a></p><p>Author: Ashish Kapoor, Eric Horvitz</p><p>Abstract: To date, the processes employed for active information acquisition during periods of learning and diagnosis have been considered as separate and have been applied in distinct phases of analysis. While active learning centers on the collection of information about training cases in order to build better predictive models, diagnosis uses ﬁxed predictive models for guiding the collection of observations about a speciﬁc test case at hand. We introduce a model and inferential methods that bridge these phases of analysis into a holistic approach to information acquisition that considers simultaneously the extension of the predictive model and the probing of a case at hand. The bridging of active learning and real-time diagnostic feature acquisition leads to a new class of policies for learning and diagnosis. 1</p><p>Reference: <a title="nips-2009-49-reference" href="../nips2009_reference/nips-2009-Breaking_Boundaries_Between_Induction_Time_and_Diagnosis_Time_Active_Information_Acquisition_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 While active learning centers on the collection of information about training cases in order to build better predictive models, diagnosis uses ﬁxed predictive models for guiding the collection of observations about a speciﬁc test case at hand. [sent-2, score-1.302]
</p><p>2 We introduce a model and inferential methods that bridge these phases of analysis into a holistic approach to information acquisition that considers simultaneously the extension of the predictive model and the probing of a case at hand. [sent-3, score-0.536]
</p><p>3 The bridging of active learning and real-time diagnostic feature acquisition leads to a new class of policies for learning and diagnosis. [sent-4, score-0.778]
</p><p>4 1  Introduction  Consider a real-world problem scenario where the challenge is to diagnose a patient who presents with several salient symptoms by performing inference with a probabilistic diagnostic model. [sent-5, score-0.299]
</p><p>5 The diagnostic model is trained from a database of patients, where training cases may have missing features. [sent-6, score-0.397]
</p><p>6 Assume we have at our discretion an evidential budget that enables us to acquire additional information so as to make a good diagnosis. [sent-7, score-0.206]
</p><p>7 Traditionally, such a budget has been spent solely on performing real-time observations about the case at hand, for example, by carrying out additional tests on a patient presenting to a physician with some previously identiﬁed complaints, signs, and symptoms. [sent-8, score-0.23]
</p><p>8 However, there lies another opportunity to improving diagnostic models—that of allocating some or all of the evidential budget to extending some portion of the training database, and then learning an updated diagnostic model for use in inference about the case at hand. [sent-9, score-0.545]
</p><p>9 This broader perspective on diagnostic reasoning has real-world implications. [sent-10, score-0.25]
</p><p>10 For instance, investing efforts to observe features that are currently missing in training cases, such as missing details on presenting symptoms or on outcomes of prior patient cases, might preempt the need for carrying out a painful or risky medical test on the patient at hand. [sent-11, score-0.719]
</p><p>11 To date, the process of diagnosis has focused on the use of a ﬁxed predictive model, which in turn is used to generate recommendations for the observations to gather. [sent-13, score-0.661]
</p><p>12 Similarly, efforts in active learning have focused on gathering information about the training cases in order to build better predictive models. [sent-14, score-0.573]
</p><p>13 The active collection of the different types of missing information under a budget, spanning methods that have been referred to separately as learning and diagnosis, is graphically depicted in Figure 1. [sent-15, score-0.372]
</p><p>14 While diagnosis-time information acquisition methods focus on acquiring information about the test case at hand, induction-time methods focus on collecting information about training cases for learning a good predictive model. [sent-16, score-0.733]
</p><p>15 We shall describe methods that weave together these two perspectives on information acquisition that have been handled separately to date, yielding a holistic approach to evidence collection in the context of the larger learning and prediction system. [sent-17, score-0.462]
</p><p>16 The 1  Training Cases (Possibly Incomplete)  Diagnosis Time Information Acquisition  Induction Time Information Acquisition  Predictive Model  Diagnostic Challenge (Possibly Incomplete)  Figure 1: Illustration of induction-time and diagnosis-time active information acquisition. [sent-18, score-0.284]
</p><p>17 Induction-time active learning focuses on acquiring information for the pool of data used to train a diagnostic model; diagnosis-time information acquisition focuses on the next best observations to acquire from the test case at hand. [sent-19, score-1.115]
</p><p>18 methodology applies to situations where there is a single diagnostic challenge, as well as broader conceptions of diagnosis over streams of cases over time. [sent-20, score-0.775]
</p><p>19 We take a decision-theoretic perspective on the joint consideration of observations about the case at hand and about options for extending the training set. [sent-21, score-0.257]
</p><p>20 We start by directly modeling how the training data might affect the outcome of the predictions about test cases at hand, thus, relaxing the common assumption that a predictive model is ﬁxed during diagnosis. [sent-22, score-0.32]
</p><p>21 Real-world diagnostic applications have made this assumption to date, often employing an information-theoretic or decision theoreticcriterion, such as value of information (VOI), during diagnosis to collect data about the case at hand. [sent-23, score-0.69]
</p><p>22 The holistic method can guide the acquisition of data for training cases that are missing arbitrary combinations of features and labels. [sent-24, score-0.752]
</p><p>23 The methodology extends active learning beyond the situation where training is done from a case library of completely speciﬁed instances, where each case contains a complete set of observations. [sent-25, score-0.378]
</p><p>24 We shall show how the more holistic active-learning approach allows for a ﬁne-grained triaging of information to acquire by deliberating in parallel about the value of acquiring missing information from cases either in the training or the test set. [sent-26, score-0.644]
</p><p>25 2  Related Research  As we mentioned, efforts to date on the use of active learning for training classiﬁcation models have largely focused on the task of acquiring labels, and assume that all of the features are observed in advance. [sent-27, score-0.649]
</p><p>26 There has been limited work on methods for actively selecting missing features for instantiation. [sent-29, score-0.209]
</p><p>27 Speciﬁcally, they solve a problem that can be viewed as the inverse of traditional active learning; given class labels, they seek to determine the best features to compute for each instance such that a good predictive model can be trained under a budget. [sent-32, score-0.523]
</p><p>28 Even rarer are attempts to unify active acquisition of features with the acquisition of missing class labels. [sent-33, score-1.119]
</p><p>29 Research on this more general active learning includes work with graphical probabilistic models by Tong and Koller [14] and by Saar-Tsechansky et al. [sent-34, score-0.284]
</p><p>30 Several methods have been used for guiding data acquisition at diagnosis time. [sent-36, score-0.883]
</p><p>31 The goal is to identify the best additional observations to acquire for making inferences and for ultimately taking actions given inferences about the class of a test case at hand [4, 5, 6, 7, 12]. [sent-37, score-0.249]
</p><p>32 The methods move beyond the task of parameter and structure estimation explored in the prior studies of active learning and directly model statistical relationships amongst the data points. [sent-43, score-0.284]
</p><p>33 Assume that we are given a training corpus with n independent training instances Di = {(xi , ti )}. [sent-44, score-0.253]
</p><p>34 Here, xi are the d dimensional features and their labels are denoted as ti . [sent-45, score-0.24]
</p><p>35 The training cases can be incomplete; not all of the labels and features in the training set D are observed. [sent-46, score-0.449]
</p><p>36 Let us consider a test data point as x∗ where our task is to recover the label t∗ for the test case1 . [sent-48, score-0.234]
</p><p>37 Given a budget for acquiring information, our goal is to determine the missing components either from the training set or among the missing features in the test case so that we make the best prediction on t∗ . [sent-50, score-0.654]
</p><p>38 Approaches to active learning leverage the statistical relationships among sets of observations within cases with their class labels. [sent-51, score-0.388]
</p><p>39 , Dn ) ∗ ∗  (1)  Here, xo represents the observed components of the test case and we deﬁne the set of all observed ∗ h h o o variables in the training corpus as Do = {D1 , . [sent-55, score-0.361]
</p><p>40 We note that the strategy of directly modeling the statistical dependencies among all of the training data and the test case is a departure from most existing classiﬁcation methods. [sent-60, score-0.268]
</p><p>41 Given a training corpus, most methods try to ﬁt a model or learn a classiﬁer that best explains the training data and use this learned model to classify test cases. [sent-61, score-0.286]
</p><p>42 Directly modeling the dependency of the test label t∗ on the training and the test data as described in Equation 1 allows us to reason about next best information to observe by considering how posterior distributions changes with the acquisition of missing information. [sent-63, score-0.824]
</p><p>43 1  Decision-Theoretic Selective Sampling  We are interested in selectively sampling unobserved information, either about the training set or the test case, in order to make a better prediction. [sent-66, score-0.307]
</p><p>44 However, performing such nonmyopic analyses is prohibitively expensive for many active learning heuristics [7]. [sent-68, score-0.284]
</p><p>45 That is starting from an empty set, the algorithm selects one element at a time according to the active learning criterion. [sent-70, score-0.284]
</p><p>46 The decision-theoretic selective sampling criterion we use estimates the values of acquiring information, which in turn can be used as a guiding principle in active learning. [sent-74, score-0.567]
</p><p>47 We can quantify such 1 For simplicity, we limit our discussion to a single test point; the analysis described generalizes directly to considering larger set of test points  3  value in terms of information gain. [sent-75, score-0.248]
</p><p>48 By considering this reduction in uncertainty along with the cost of obtaining such information, we can formulate a selective sampling criterion. [sent-78, score-0.282]
</p><p>49 Unlike VOI, the proposed criteria does not require that the gain from selective sampling and the cost of observing observation have the same currency; consequently, ROI can be used more generally. [sent-85, score-0.26]
</p><p>50 Note, the proposed framework for active information acquisition easily extends to scenarios where the cost and the beneﬁts of the system can be measure in a single currency and VOI can be applied. [sent-86, score-0.718]
</p><p>51 Also note that while the ROI formulation we introduces considers a single test, similar computations can be done for a larger set of test points by considering the joint entropy over the test labels. [sent-87, score-0.312]
</p><p>52 We now describe how we can model the joint statistics among the training and the test cases simultaneously. [sent-89, score-0.268]
</p><p>53 First, we consider individual data instances and model the joint distribution of features and labels of the instance as a Markov Random Field (MRF)2 . [sent-98, score-0.285]
</p><p>54 4  Experiments and Results  We shall compare proposed active information acquisition, which does not distinguish between induction-time and diagnosis-time analyses, against other alternatives on a synthetic dataset and two real-world applications. [sent-134, score-0.355]
</p><p>55 The signiﬁcant gains we obtained over approaches that limit themselves to separately consider induction-time or diagnosis-time information acquisition suggests that the holistic perspective can provide broader and more efﬁcient options to acquire information. [sent-136, score-0.634]
</p><p>56 1  Experiments with Synthetic Data  We ﬁrst sought to evaluate the basic operation of the proposed framework with a synthetic training set of Boolean data generated by randomly sampling labels with a fair coin toss. [sent-138, score-0.325]
</p><p>57 Out of the 14 features, seven are randomly generated using a fair coin toss, while the rest of the features are generated by multiplying the label with all of the seven randomly generated features individually. [sent-140, score-0.29]
</p><p>58 Further, we consider a 50-50 train and test split and assume that 25% of the total bits are unobserved and that the target of the selective sampling procedure is to determine the best next observations to make so as to best predict the labels for the test cases. [sent-146, score-0.642]
</p><p>59 We assume that the cost of observing a label in the training data is directly proportional to the possible number of features that can be computed for every data point (that is, c(d) = Dim). [sent-147, score-0.331]
</p><p>60 We set the costs of observing labels of test cases to inﬁnity; consequently the active learning methods never observe them. [sent-149, score-0.674]
</p><p>61 We compared the joint selection (Diagnosis+Induction) advocated in this work with 1) diagnosistime active information acquisition (Diagnosis), where information bits are sampled only from the test case at hand and 2) induction-time active acquisition (Induction). [sent-150, score-1.432]
</p><p>62 In addition, we considered two different ﬂavors of induction-time active inquisition where either only features or only labels were allowed to be sampled. [sent-151, score-0.499]
</p><p>63 In all of the cases, we used ROI for active learning as described in section 3. [sent-153, score-0.284]
</p><p>64 Figure 2 (left) shows the recognition results with increasing costs during active acquisition of information. [sent-156, score-0.69]
</p><p>65 We plot the overall classiﬁcation accuracy over the test set on the y-axis and the cost incurred on the x-axis. [sent-157, score-0.242]
</p><p>66 Each point on the graph signiﬁes an average recognition on the test set over 10 random training and test splits. [sent-158, score-0.322]
</p><p>67 First, Diagnosis+Induction obtains better recognition results for a ﬁxed incurred cost, outperforming the diagnosis-time sampling strategy as well as all the ﬂavors of induction-time information acquisition. [sent-160, score-0.198]
</p><p>68 Also, we note that the induction (features-only) stops abruptly for the synthetic case as most of the features in the learning problem are uninformative; after initial rounds the algorithm stops sampling. [sent-163, score-0.587]
</p><p>69 In summary, all of the active methods for active 6  Boolean  0. [sent-164, score-0.568]
</p><p>70 information acquisition do better than random; however, Induction+Diagnosis strategy achieves best combination of recognition performance and cost efﬁciency. [sent-191, score-0.474]
</p><p>71 In order to analyze different sampling methods, we look at the sampling behavior of different active learning mechanisms. [sent-192, score-0.438]
</p><p>72 Figure 3 (left) illustrates the statistics of sampled information at the termination of the active learning procedure. [sent-193, score-0.309]
</p><p>73 The bars with different shades denote the sampling distribution amongst training labels, training features and the test features, which are generated by averaging over the 10 runs. [sent-194, score-0.46]
</p><p>74 While the Induction (features only), Induction (labels only) and diagnosis strategy just acquire labels, features for training data and features for the test cases respectively, the Diagnosis+Induction approaches show acquisition of information from different kinds of sources. [sent-195, score-1.416]
</p><p>75 We note that the random sampling strategy also samples from both labels and features; however, as indicated by Figure 2 (left) this strategy is not optimal as it does not take the cost structure into account. [sent-196, score-0.357]
</p><p>76 Diagnosis+Induction is the most ﬂexible scheme and it aims to acquire information from all facets of the classiﬁcation problem by properly considering gains in predictive power and balancing it with the cost of information acquisition. [sent-197, score-0.324]
</p><p>77 2  Experiment on Pathﬁnder Data  Availability and access of large medical databases enables us to build better predictive models for various diagnostic purposes. [sent-199, score-0.251]
</p><p>78 While most efforts have focused on active data acquisition for diagnosis only [5], our framework promises a broader set of options to a diagnostician, where he can reason whether to perform additional tests on a patient or seek more information about the training set. [sent-200, score-1.464]
</p><p>79 We analyze one such scenario where the goal is to build a predictive model that would guide surgical pathologists who study the lymphatic system with the diagnosis of lymph-node diseases. [sent-201, score-0.677]
</p><p>80 The features signify sets of histological features viewed at low and high power under the microscope that an expert surgical pathologist believed could be informative to that label. [sent-203, score-0.261]
</p><p>81 For this experiment, we consider random splits 30 training examples and 18 test cases and again assume that 25% of the total bits are unobserved. [sent-205, score-0.287]
</p><p>82 As before, x-axis and y-axis denote costs incurred and overall classiﬁcation accuracy on the test data over 10 random training and test splits. [sent-208, score-0.411]
</p><p>83 However, one difference in this experiment is the fact that Random sampling strategy outperforms active Diagnosis and active Induction (features only). [sent-210, score-0.69]
</p><p>84 This suggests that the labels in the training cases are highly informative when compared to the features. [sent-211, score-0.288]
</p><p>85 This in turn is reﬂected by the similar performance of Diagnosis+Induction with Induction and Induction (only) towards the end of active learning run. [sent-212, score-0.284]
</p><p>86 This further reinforces the validity of the hypothesis that the training labels are very informative. [sent-214, score-0.212]
</p><p>87 On analyzing the sampling behavior of different methods (Figure 3 (middle)) we again ﬁnd that the Diagnosis+Induction approaches show acquisition of information from different kinds of sources. [sent-215, score-0.402]
</p><p>88 However, we also note that the proportion of sampled training labels is remarkably few and very similar for both Diagnosis+Induction 7  1 0. [sent-216, score-0.212]
</p><p>89 1 0  Figure 3: Statistics of different information selected in active learning. [sent-243, score-0.284]
</p><p>90 In summary, Diagnosis+Induction again provides best recognition rates at low costs, demonstrating the effectiveness of the uniﬁed perspective on active learning. [sent-245, score-0.358]
</p><p>91 3  Experiments on Congressional Voting Records  Surveys have been popular information gathering tools, however, the cost of acquiring information by surveying can be costly and is often fraught with missing information. [sent-247, score-0.278]
</p><p>92 Intelligent information acquisition with active learning promises efﬁcient use of limited resources. [sent-248, score-0.642]
</p><p>93 The holistic perspective on data acquisition can help avoid probing subjects for potentially risky or expensive questions by considering accessible information (for example, information such as demographics, age, etc. [sent-249, score-0.576]
</p><p>94 We consider 10 random splits with 100 training instances and 335 test cases and report results averaged over these splits. [sent-258, score-0.278]
</p><p>95 Each point on the graph signiﬁes an average recognition on the test set over 10 random training and test splits. [sent-260, score-0.322]
</p><p>96 Similar to the earlier experiments, we see improvement in recognition accuracy on the test set for different sampling schemes. [sent-261, score-0.235]
</p><p>97 By considering information gain and the cost structure through ROI, Diagnosis+Induction is able to achieve the best combination of recognition performance and cost efﬁciency. [sent-265, score-0.228]
</p><p>98 5  Conclusion  We introduced a scheme for active data acquisition that removes the separation between diagnosistime and induction-time active information acquisition. [sent-266, score-0.93]
</p><p>99 We ran several experiments that showed the effectiveness of combining diagnosis-time and induction-time active learning. [sent-268, score-0.284]
</p><p>100 Feature value acquisition in testing: a sequential batch test algorithm. [sent-341, score-0.423]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('diagnosis', 0.521), ('induction', 0.404), ('acquisition', 0.325), ('active', 0.284), ('diagnostic', 0.169), ('xo', 0.169), ('roi', 0.14), ('labels', 0.118), ('voi', 0.112), ('holistic', 0.102), ('test', 0.098), ('features', 0.097), ('training', 0.094), ('acquire', 0.093), ('missing', 0.088), ('acquiring', 0.088), ('predictive', 0.082), ('selective', 0.081), ('sampling', 0.077), ('budget', 0.076), ('di', 0.074), ('cost', 0.072), ('gf', 0.066), ('patient', 0.063), ('observations', 0.058), ('considering', 0.052), ('consequently', 0.049), ('costs', 0.049), ('bits', 0.049), ('date', 0.049), ('avors', 0.049), ('cases', 0.046), ('strategy', 0.045), ('incurred', 0.044), ('perspective', 0.042), ('voting', 0.04), ('instances', 0.04), ('nder', 0.04), ('broader', 0.039), ('label', 0.038), ('unobserved', 0.038), ('budgeted', 0.037), ('currency', 0.037), ('diagnose', 0.037), ('diagnosistime', 0.037), ('evidential', 0.037), ('horvitz', 0.037), ('lizotte', 0.037), ('parise', 0.037), ('pathfinder', 0.037), ('pathologists', 0.037), ('surgical', 0.037), ('efforts', 0.037), ('guiding', 0.037), ('synthetic', 0.036), ('seek', 0.035), ('gm', 0.035), ('tong', 0.035), ('shall', 0.035), ('computations', 0.034), ('options', 0.033), ('greiner', 0.033), ('carrying', 0.033), ('melville', 0.033), ('promises', 0.033), ('recognition', 0.032), ('posterior', 0.031), ('dependencies', 0.031), ('bp', 0.031), ('loopy', 0.031), ('observing', 0.03), ('boolean', 0.03), ('symptoms', 0.03), ('gathering', 0.03), ('joint', 0.03), ('informative', 0.03), ('seven', 0.029), ('accuracy', 0.028), ('committee', 0.028), ('informational', 0.028), ('risky', 0.028), ('votes', 0.028), ('undirected', 0.028), ('expected', 0.027), ('classi', 0.027), ('incomplete', 0.027), ('marginalize', 0.027), ('krause', 0.027), ('probing', 0.027), ('dn', 0.026), ('vf', 0.025), ('stops', 0.025), ('termination', 0.025), ('aims', 0.025), ('ti', 0.025), ('independence', 0.025), ('determine', 0.025), ('actively', 0.024), ('dh', 0.024), ('historical', 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="49-tfidf-1" href="./nips-2009-Breaking_Boundaries_Between_Induction_Time_and_Diagnosis_Time_Active_Information_Acquisition.html">49 nips-2009-Breaking Boundaries Between Induction Time and Diagnosis Time Active Information Acquisition</a></p>
<p>Author: Ashish Kapoor, Eric Horvitz</p><p>Abstract: To date, the processes employed for active information acquisition during periods of learning and diagnosis have been considered as separate and have been applied in distinct phases of analysis. While active learning centers on the collection of information about training cases in order to build better predictive models, diagnosis uses ﬁxed predictive models for guiding the collection of observations about a speciﬁc test case at hand. We introduce a model and inferential methods that bridge these phases of analysis into a holistic approach to information acquisition that considers simultaneously the extension of the predictive model and the probing of a case at hand. The bridging of active learning and real-time diagnostic feature acquisition leads to a new class of policies for learning and diagnosis. 1</p><p>2 0.11106321 <a title="49-tfidf-2" href="./nips-2009-Distribution_Matching_for_Transduction.html">72 nips-2009-Distribution Matching for Transduction</a></p>
<p>Author: Novi Quadrianto, James Petterson, Alex J. Smola</p><p>Abstract: Many transductive inference algorithms assume that distributions over training and test estimates should be related, e.g. by providing a large margin of separation on both sets. We use this idea to design a transduction algorithm which can be used without modiﬁcation for classiﬁcation, regression, and structured estimation. At its heart we exploit the fact that for a good learner the distributions over the outputs on training and test sets should match. This is a classical two-sample problem which can be solved efﬁciently in its most general form by using distance measures in Hilbert Space. It turns out that a number of existing heuristics can be viewed as special cases of our approach. 1</p><p>3 0.11063871 <a title="49-tfidf-3" href="./nips-2009-Unsupervised_Detection_of_Regions_of_Interest_Using_Iterative_Link_Analysis.html">251 nips-2009-Unsupervised Detection of Regions of Interest Using Iterative Link Analysis</a></p>
<p>Author: Gunhee Kim, Antonio Torralba</p><p>Abstract: This paper proposes a fast and scalable alternating optimization technique to detect regions of interest (ROIs) in cluttered Web images without labels. The proposed approach discovers highly probable regions of object instances by iteratively repeating the following two functions: (1) choose the exemplar set (i.e. a small number of highly ranked reference ROIs) across the dataset and (2) reﬁne the ROIs of each image with respect to the exemplar set. These two subproblems are formulated as ranking in two different similarity networks of ROI hypotheses by link analysis. The experiments with the PASCAL 06 dataset show that our unsupervised localization performance is better than one of state-of-the-art techniques and comparable to supervised methods. Also, we test the scalability of our approach with ﬁve objects in Flickr dataset consisting of more than 200K images. 1</p><p>4 0.089725658 <a title="49-tfidf-4" href="./nips-2009-Sufficient_Conditions_for_Agnostic_Active_Learnable.html">240 nips-2009-Sufficient Conditions for Agnostic Active Learnable</a></p>
<p>Author: Liwei Wang</p><p>Abstract: We study pool-based active learning in the presence of noise, i.e. the agnostic setting. Previous works have shown that the effectiveness of agnostic active learning depends on the learning problem and the hypothesis space. Although there are many cases on which active learning is very useful, it is also easy to construct examples that no active learning algorithm can have advantage. In this paper, we propose intuitively reasonable sufﬁcient conditions under which agnostic active learning algorithm is strictly superior to passive supervised learning. We show that under some noise condition, if the Bayesian classiﬁcation boundary and the underlying distribution are smooth to a ﬁnite order, active learning achieves polynomial improvement in the label complexity; if the boundary and the distribution are inﬁnitely smooth, the improvement is exponential.</p><p>5 0.070518233 <a title="49-tfidf-5" href="./nips-2009-Conditional_Random_Fields_with_High-Order_Features_for_Sequence_Labeling.html">57 nips-2009-Conditional Random Fields with High-Order Features for Sequence Labeling</a></p>
<p>Author: Nan Ye, Wee S. Lee, Hai L. Chieu, Dan Wu</p><p>Abstract: Dependencies among neighbouring labels in a sequence is an important source of information for sequence labeling problems. However, only dependencies between adjacent labels are commonly exploited in practice because of the high computational complexity of typical inference algorithms when longer distance dependencies are taken into account. In this paper, we show that it is possible to design efﬁcient inference algorithms for a conditional random ﬁeld using features that depend on long consecutive label sequences (high-order features), as long as the number of distinct label sequences used in the features is small. This leads to efﬁcient learning algorithms for these conditional random ﬁelds. We show experimentally that exploiting dependencies using high-order features can lead to substantial performance improvements for some problems and discuss conditions under which high-order features can be effective. 1</p><p>6 0.067471683 <a title="49-tfidf-6" href="./nips-2009-An_Infinite_Factor_Model_Hierarchy_Via_a_Noisy-Or_Mechanism.html">29 nips-2009-An Infinite Factor Model Hierarchy Via a Noisy-Or Mechanism</a></p>
<p>7 0.058216013 <a title="49-tfidf-7" href="./nips-2009-Hierarchical_Mixture_of_Classification_Experts_Uncovers_Interactions_between_Brain_Regions.html">110 nips-2009-Hierarchical Mixture of Classification Experts Uncovers Interactions between Brain Regions</a></p>
<p>8 0.058196746 <a title="49-tfidf-8" href="./nips-2009-Label_Selection_on_Graphs.html">122 nips-2009-Label Selection on Graphs</a></p>
<p>9 0.056914069 <a title="49-tfidf-9" href="./nips-2009-Improving_Existing_Fault_Recovery_Policies.html">113 nips-2009-Improving Existing Fault Recovery Policies</a></p>
<p>10 0.056109782 <a title="49-tfidf-10" href="./nips-2009-3D_Object_Recognition_with_Deep_Belief_Nets.html">2 nips-2009-3D Object Recognition with Deep Belief Nets</a></p>
<p>11 0.054980285 <a title="49-tfidf-11" href="./nips-2009-Speeding_up_Magnetic_Resonance_Image_Acquisition_by_Bayesian_Multi-Slice_Adaptive_Compressed_Sensing.html">228 nips-2009-Speeding up Magnetic Resonance Image Acquisition by Bayesian Multi-Slice Adaptive Compressed Sensing</a></p>
<p>12 0.051729508 <a title="49-tfidf-12" href="./nips-2009-Semi-Supervised_Learning_in_Gigantic_Image_Collections.html">212 nips-2009-Semi-Supervised Learning in Gigantic Image Collections</a></p>
<p>13 0.051387865 <a title="49-tfidf-13" href="./nips-2009-Multi-Label_Prediction_via_Compressed_Sensing.html">157 nips-2009-Multi-Label Prediction via Compressed Sensing</a></p>
<p>14 0.051109392 <a title="49-tfidf-14" href="./nips-2009-Posterior_vs_Parameter_Sparsity_in_Latent_Variable_Models.html">192 nips-2009-Posterior vs Parameter Sparsity in Latent Variable Models</a></p>
<p>15 0.050695926 <a title="49-tfidf-15" href="./nips-2009-Distribution-Calibrated_Hierarchical_Classification.html">71 nips-2009-Distribution-Calibrated Hierarchical Classification</a></p>
<p>16 0.049790747 <a title="49-tfidf-16" href="./nips-2009-Discriminative_Network_Models_of_Schizophrenia.html">70 nips-2009-Discriminative Network Models of Schizophrenia</a></p>
<p>17 0.048570853 <a title="49-tfidf-17" href="./nips-2009-Nonparametric_Latent_Feature_Models_for_Link_Prediction.html">174 nips-2009-Nonparametric Latent Feature Models for Link Prediction</a></p>
<p>18 0.048450515 <a title="49-tfidf-18" href="./nips-2009-Entropic_Graph_Regularization_in_Non-Parametric_Semi-Supervised_Classification.html">82 nips-2009-Entropic Graph Regularization in Non-Parametric Semi-Supervised Classification</a></p>
<p>19 0.046885546 <a title="49-tfidf-19" href="./nips-2009-Whose_Vote_Should_Count_More%3A_Optimal_Integration_of_Labels_from_Labelers_of_Unknown_Expertise.html">258 nips-2009-Whose Vote Should Count More: Optimal Integration of Labels from Labelers of Unknown Expertise</a></p>
<p>20 0.045885585 <a title="49-tfidf-20" href="./nips-2009-An_LP_View_of_the_M-best_MAP_problem.html">31 nips-2009-An LP View of the M-best MAP problem</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.171), (1, -0.027), (2, -0.03), (3, -0.045), (4, -0.028), (5, -0.017), (6, 0.008), (7, -0.051), (8, -0.1), (9, -0.01), (10, -0.035), (11, 0.011), (12, -0.033), (13, -0.045), (14, -0.001), (15, 0.017), (16, 0.079), (17, -0.013), (18, 0.045), (19, -0.07), (20, 0.027), (21, -0.036), (22, -0.018), (23, 0.118), (24, 0.033), (25, 0.021), (26, -0.081), (27, 0.009), (28, 0.028), (29, -0.026), (30, -0.034), (31, -0.085), (32, 0.022), (33, 0.07), (34, 0.058), (35, 0.174), (36, 0.04), (37, -0.031), (38, 0.005), (39, -0.032), (40, -0.094), (41, 0.043), (42, -0.018), (43, 0.044), (44, -0.002), (45, -0.084), (46, 0.012), (47, 0.099), (48, -0.089), (49, -0.103)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92104471 <a title="49-lsi-1" href="./nips-2009-Breaking_Boundaries_Between_Induction_Time_and_Diagnosis_Time_Active_Information_Acquisition.html">49 nips-2009-Breaking Boundaries Between Induction Time and Diagnosis Time Active Information Acquisition</a></p>
<p>Author: Ashish Kapoor, Eric Horvitz</p><p>Abstract: To date, the processes employed for active information acquisition during periods of learning and diagnosis have been considered as separate and have been applied in distinct phases of analysis. While active learning centers on the collection of information about training cases in order to build better predictive models, diagnosis uses ﬁxed predictive models for guiding the collection of observations about a speciﬁc test case at hand. We introduce a model and inferential methods that bridge these phases of analysis into a holistic approach to information acquisition that considers simultaneously the extension of the predictive model and the probing of a case at hand. The bridging of active learning and real-time diagnostic feature acquisition leads to a new class of policies for learning and diagnosis. 1</p><p>2 0.58129394 <a title="49-lsi-2" href="./nips-2009-Sufficient_Conditions_for_Agnostic_Active_Learnable.html">240 nips-2009-Sufficient Conditions for Agnostic Active Learnable</a></p>
<p>Author: Liwei Wang</p><p>Abstract: We study pool-based active learning in the presence of noise, i.e. the agnostic setting. Previous works have shown that the effectiveness of agnostic active learning depends on the learning problem and the hypothesis space. Although there are many cases on which active learning is very useful, it is also easy to construct examples that no active learning algorithm can have advantage. In this paper, we propose intuitively reasonable sufﬁcient conditions under which agnostic active learning algorithm is strictly superior to passive supervised learning. We show that under some noise condition, if the Bayesian classiﬁcation boundary and the underlying distribution are smooth to a ﬁnite order, active learning achieves polynomial improvement in the label complexity; if the boundary and the distribution are inﬁnitely smooth, the improvement is exponential.</p><p>3 0.54861104 <a title="49-lsi-3" href="./nips-2009-Distribution_Matching_for_Transduction.html">72 nips-2009-Distribution Matching for Transduction</a></p>
<p>Author: Novi Quadrianto, James Petterson, Alex J. Smola</p><p>Abstract: Many transductive inference algorithms assume that distributions over training and test estimates should be related, e.g. by providing a large margin of separation on both sets. We use this idea to design a transduction algorithm which can be used without modiﬁcation for classiﬁcation, regression, and structured estimation. At its heart we exploit the fact that for a good learner the distributions over the outputs on training and test sets should match. This is a classical two-sample problem which can be solved efﬁciently in its most general form by using distance measures in Hilbert Space. It turns out that a number of existing heuristics can be viewed as special cases of our approach. 1</p><p>4 0.54829764 <a title="49-lsi-4" href="./nips-2009-Learning_Label_Embeddings_for_Nearest-Neighbor_Multi-class_Classification_with_an_Application_to_Speech_Recognition.html">127 nips-2009-Learning Label Embeddings for Nearest-Neighbor Multi-class Classification with an Application to Speech Recognition</a></p>
<p>Author: Natasha Singh-miller, Michael Collins</p><p>Abstract: We consider the problem of using nearest neighbor methods to provide a conditional probability estimate, P (y|a), when the number of labels y is large and the labels share some underlying structure. We propose a method for learning label embeddings (similar to error-correcting output codes (ECOCs)) to model the similarity between labels within a nearest neighbor framework. The learned ECOCs and nearest neighbor information are used to provide conditional probability estimates. We apply these estimates to the problem of acoustic modeling for speech recognition. We demonstrate signiﬁcant improvements in terms of word error rate (WER) on a lecture recognition task over a state-of-the-art baseline GMM model. 1</p><p>5 0.51939183 <a title="49-lsi-5" href="./nips-2009-Unsupervised_Detection_of_Regions_of_Interest_Using_Iterative_Link_Analysis.html">251 nips-2009-Unsupervised Detection of Regions of Interest Using Iterative Link Analysis</a></p>
<p>Author: Gunhee Kim, Antonio Torralba</p><p>Abstract: This paper proposes a fast and scalable alternating optimization technique to detect regions of interest (ROIs) in cluttered Web images without labels. The proposed approach discovers highly probable regions of object instances by iteratively repeating the following two functions: (1) choose the exemplar set (i.e. a small number of highly ranked reference ROIs) across the dataset and (2) reﬁne the ROIs of each image with respect to the exemplar set. These two subproblems are formulated as ranking in two different similarity networks of ROI hypotheses by link analysis. The experiments with the PASCAL 06 dataset show that our unsupervised localization performance is better than one of state-of-the-art techniques and comparable to supervised methods. Also, we test the scalability of our approach with ﬁve objects in Flickr dataset consisting of more than 200K images. 1</p><p>6 0.51808643 <a title="49-lsi-6" href="./nips-2009-Hierarchical_Mixture_of_Classification_Experts_Uncovers_Interactions_between_Brain_Regions.html">110 nips-2009-Hierarchical Mixture of Classification Experts Uncovers Interactions between Brain Regions</a></p>
<p>7 0.50400901 <a title="49-lsi-7" href="./nips-2009-Potential-Based_Agnostic_Boosting.html">193 nips-2009-Potential-Based Agnostic Boosting</a></p>
<p>8 0.50188559 <a title="49-lsi-8" href="./nips-2009-Distribution-Calibrated_Hierarchical_Classification.html">71 nips-2009-Distribution-Calibrated Hierarchical Classification</a></p>
<p>9 0.48289263 <a title="49-lsi-9" href="./nips-2009-Graph-based_Consensus_Maximization_among_Multiple_Supervised_and_Unsupervised_Models.html">102 nips-2009-Graph-based Consensus Maximization among Multiple Supervised and Unsupervised Models</a></p>
<p>10 0.45994866 <a title="49-lsi-10" href="./nips-2009-Learning_from_Multiple_Partially_Observed_Views_-_an_Application_to_Multilingual_Text_Categorization.html">130 nips-2009-Learning from Multiple Partially Observed Views - an Application to Multilingual Text Categorization</a></p>
<p>11 0.45857227 <a title="49-lsi-11" href="./nips-2009-Label_Selection_on_Graphs.html">122 nips-2009-Label Selection on Graphs</a></p>
<p>12 0.45402822 <a title="49-lsi-12" href="./nips-2009-Conditional_Random_Fields_with_High-Order_Features_for_Sequence_Labeling.html">57 nips-2009-Conditional Random Fields with High-Order Features for Sequence Labeling</a></p>
<p>13 0.45373073 <a title="49-lsi-13" href="./nips-2009-Multi-Label_Prediction_via_Compressed_Sensing.html">157 nips-2009-Multi-Label Prediction via Compressed Sensing</a></p>
<p>14 0.45361802 <a title="49-lsi-14" href="./nips-2009-Dirichlet-Bernoulli_Alignment%3A_A_Generative_Model_for_Multi-Class_Multi-Label_Multi-Instance_Corpora.html">68 nips-2009-Dirichlet-Bernoulli Alignment: A Generative Model for Multi-Class Multi-Label Multi-Instance Corpora</a></p>
<p>15 0.44101763 <a title="49-lsi-15" href="./nips-2009-An_Infinite_Factor_Model_Hierarchy_Via_a_Noisy-Or_Mechanism.html">29 nips-2009-An Infinite Factor Model Hierarchy Via a Noisy-Or Mechanism</a></p>
<p>16 0.43279696 <a title="49-lsi-16" href="./nips-2009-Whose_Vote_Should_Count_More%3A_Optimal_Integration_of_Labels_from_Labelers_of_Unknown_Expertise.html">258 nips-2009-Whose Vote Should Count More: Optimal Integration of Labels from Labelers of Unknown Expertise</a></p>
<p>17 0.42961627 <a title="49-lsi-17" href="./nips-2009-Human_Rademacher_Complexity.html">112 nips-2009-Human Rademacher Complexity</a></p>
<p>18 0.42146409 <a title="49-lsi-18" href="./nips-2009-Speeding_up_Magnetic_Resonance_Image_Acquisition_by_Bayesian_Multi-Slice_Adaptive_Compressed_Sensing.html">228 nips-2009-Speeding up Magnetic Resonance Image Acquisition by Bayesian Multi-Slice Adaptive Compressed Sensing</a></p>
<p>19 0.41407686 <a title="49-lsi-19" href="./nips-2009-Large_Scale_Nonparametric_Bayesian_Inference%3A_Data_Parallelisation_in_the_Indian_Buffet_Process.html">123 nips-2009-Large Scale Nonparametric Bayesian Inference: Data Parallelisation in the Indian Buffet Process</a></p>
<p>20 0.40343347 <a title="49-lsi-20" href="./nips-2009-Conditional_Neural_Fields.html">56 nips-2009-Conditional Neural Fields</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(7, 0.013), (24, 0.068), (25, 0.079), (35, 0.064), (36, 0.109), (39, 0.066), (51, 0.01), (58, 0.08), (71, 0.063), (81, 0.02), (86, 0.065), (91, 0.013), (94, 0.256)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.80921024 <a title="49-lda-1" href="./nips-2009-Breaking_Boundaries_Between_Induction_Time_and_Diagnosis_Time_Active_Information_Acquisition.html">49 nips-2009-Breaking Boundaries Between Induction Time and Diagnosis Time Active Information Acquisition</a></p>
<p>Author: Ashish Kapoor, Eric Horvitz</p><p>Abstract: To date, the processes employed for active information acquisition during periods of learning and diagnosis have been considered as separate and have been applied in distinct phases of analysis. While active learning centers on the collection of information about training cases in order to build better predictive models, diagnosis uses ﬁxed predictive models for guiding the collection of observations about a speciﬁc test case at hand. We introduce a model and inferential methods that bridge these phases of analysis into a holistic approach to information acquisition that considers simultaneously the extension of the predictive model and the probing of a case at hand. The bridging of active learning and real-time diagnostic feature acquisition leads to a new class of policies for learning and diagnosis. 1</p><p>2 0.72258407 <a title="49-lda-2" href="./nips-2009-Multi-Label_Prediction_via_Sparse_Infinite_CCA.html">158 nips-2009-Multi-Label Prediction via Sparse Infinite CCA</a></p>
<p>Author: Piyush Rai, Hal Daume</p><p>Abstract: Canonical Correlation Analysis (CCA) is a useful technique for modeling dependencies between two (or more) sets of variables. Building upon the recently suggested probabilistic interpretation of CCA, we propose a nonparametric, fully Bayesian framework that can automatically select the number of correlation components, and effectively capture the sparsity underlying the projections. In addition, given (partially) labeled data, our algorithm can also be used as a (semi)supervised dimensionality reduction technique, and can be applied to learn useful predictive features in the context of learning a set of related tasks. Experimental results demonstrate the efﬁcacy of the proposed approach for both CCA as a stand-alone problem, and when applied to multi-label prediction. 1</p><p>3 0.62464541 <a title="49-lda-3" href="./nips-2009-Nonparametric_Latent_Feature_Models_for_Link_Prediction.html">174 nips-2009-Nonparametric Latent Feature Models for Link Prediction</a></p>
<p>Author: Kurt Miller, Michael I. Jordan, Thomas L. Griffiths</p><p>Abstract: As the availability and importance of relational data—such as the friendships summarized on a social networking website—increases, it becomes increasingly important to have good models for such data. The kinds of latent structure that have been considered for use in predicting links in such networks have been relatively limited. In particular, the machine learning community has focused on latent class models, adapting Bayesian nonparametric methods to jointly infer how many latent classes there are while learning which entities belong to each class. We pursue a similar approach with a richer kind of latent variable—latent features—using a Bayesian nonparametric approach to simultaneously infer the number of features at the same time we learn which entities have each feature. Our model combines these inferred features with known covariates in order to perform link prediction. We demonstrate that the greater expressiveness of this approach allows us to improve performance on three datasets. 1</p><p>4 0.62367302 <a title="49-lda-4" href="./nips-2009-Free_energy_score_space.html">97 nips-2009-Free energy score space</a></p>
<p>Author: Alessandro Perina, Marco Cristani, Umberto Castellani, Vittorio Murino, Nebojsa Jojic</p><p>Abstract: A score function induced by a generative model of the data can provide a feature vector of a ﬁxed dimension for each data sample. Data samples themselves may be of differing lengths (e.g., speech segments, or other sequence data), but as a score function is based on the properties of the data generation process, it produces a ﬁxed-length vector in a highly informative space, typically referred to as a “score space”. Discriminative classiﬁers have been shown to achieve higher performance in appropriately chosen score spaces than is achievable by either the corresponding generative likelihood-based classiﬁers, or the discriminative classiﬁers using standard feature extractors. In this paper, we present a novel score space that exploits the free energy associated with a generative model. The resulting free energy score space (FESS) takes into account latent structure of the data at various levels, and can be trivially shown to lead to classiﬁcation performance that at least matches the performance of the free energy classiﬁer based on the same generative model, and the same factorization of the posterior. We also show that in several typical vision and computational biology applications the classiﬁers optimized in FESS outperform the corresponding pure generative approaches, as well as a number of previous approaches to combining discriminating and generative models.</p><p>5 0.62113261 <a title="49-lda-5" href="./nips-2009-Learning_a_Small_Mixture_of_Trees.html">129 nips-2009-Learning a Small Mixture of Trees</a></p>
<p>Author: M. P. Kumar, Daphne Koller</p><p>Abstract: The problem of approximating a given probability distribution using a simpler distribution plays an important role in several areas of machine learning, for example variational inference and classiﬁcation. Within this context, we consider the task of learning a mixture of tree distributions. Although mixtures of trees can be learned by minimizing the KL-divergence using an EM algorithm, its success depends heavily on the initialization. We propose an efﬁcient strategy for obtaining a good initial set of trees that attempts to cover the entire observed distribution by minimizing the α-divergence with α = ∞. We formulate the problem using the fractional covering framework and present a convergent sequential algorithm that only relies on solving a convex program at each iteration. Compared to previous methods, our approach results in a signiﬁcantly smaller mixture of trees that provides similar or better accuracies. We demonstrate the usefulness of our approach by learning pictorial structures for face recognition.</p><p>6 0.62045741 <a title="49-lda-6" href="./nips-2009-Bayesian_Source_Localization_with_the_Multivariate_Laplace_Prior.html">41 nips-2009-Bayesian Source Localization with the Multivariate Laplace Prior</a></p>
<p>7 0.6203692 <a title="49-lda-7" href="./nips-2009-Zero-shot_Learning_with_Semantic_Output_Codes.html">260 nips-2009-Zero-shot Learning with Semantic Output Codes</a></p>
<p>8 0.61961198 <a title="49-lda-8" href="./nips-2009-Nonlinear_Learning_using_Local_Coordinate_Coding.html">169 nips-2009-Nonlinear Learning using Local Coordinate Coding</a></p>
<p>9 0.61528373 <a title="49-lda-9" href="./nips-2009-Bayesian_Nonparametric_Models_on_Decomposable_Graphs.html">40 nips-2009-Bayesian Nonparametric Models on Decomposable Graphs</a></p>
<p>10 0.61516416 <a title="49-lda-10" href="./nips-2009-A_Stochastic_approximation_method_for_inference_in_probabilistic_graphical_models.html">18 nips-2009-A Stochastic approximation method for inference in probabilistic graphical models</a></p>
<p>11 0.61515743 <a title="49-lda-11" href="./nips-2009-Learning_in_Markov_Random_Fields_using_Tempered_Transitions.html">132 nips-2009-Learning in Markov Random Fields using Tempered Transitions</a></p>
<p>12 0.61495709 <a title="49-lda-12" href="./nips-2009-Multi-Label_Prediction_via_Compressed_Sensing.html">157 nips-2009-Multi-Label Prediction via Compressed Sensing</a></p>
<p>13 0.6144948 <a title="49-lda-13" href="./nips-2009-Spatial_Normalized_Gamma_Processes.html">226 nips-2009-Spatial Normalized Gamma Processes</a></p>
<p>14 0.61388254 <a title="49-lda-14" href="./nips-2009-Learning_from_Neighboring_Strokes%3A_Combining_Appearance_and_Context_for_Multi-Domain_Sketch_Recognition.html">131 nips-2009-Learning from Neighboring Strokes: Combining Appearance and Context for Multi-Domain Sketch Recognition</a></p>
<p>15 0.61328781 <a title="49-lda-15" href="./nips-2009-Construction_of_Nonparametric_Bayesian_Models_from_Parametric_Bayes_Equations.html">59 nips-2009-Construction of Nonparametric Bayesian Models from Parametric Bayes Equations</a></p>
<p>16 0.61300844 <a title="49-lda-16" href="./nips-2009-Sharing_Features_among_Dynamical_Systems_with_Beta_Processes.html">217 nips-2009-Sharing Features among Dynamical Systems with Beta Processes</a></p>
<p>17 0.61179608 <a title="49-lda-17" href="./nips-2009-Human_Rademacher_Complexity.html">112 nips-2009-Human Rademacher Complexity</a></p>
<p>18 0.61129504 <a title="49-lda-18" href="./nips-2009-Neural_Implementation_of_Hierarchical_Bayesian_Inference_by_Importance_Sampling.html">162 nips-2009-Neural Implementation of Hierarchical Bayesian Inference by Importance Sampling</a></p>
<p>19 0.60973084 <a title="49-lda-19" href="./nips-2009-Modelling_Relational_Data_using_Bayesian_Clustered_Tensor_Factorization.html">155 nips-2009-Modelling Relational Data using Bayesian Clustered Tensor Factorization</a></p>
<p>20 0.60878974 <a title="49-lda-20" href="./nips-2009-Label_Selection_on_Graphs.html">122 nips-2009-Label Selection on Graphs</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
