<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>60 nips-2009-Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2009" href="../home/nips2009_home.html">nips2009</a> <a title="nips-2009-60" href="#">nips2009-60</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>60 nips-2009-Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation</h1>
<br/><p>Source: <a title="nips-2009-60-pdf" href="http://papers.nips.cc/paper/3809-convergent-temporal-difference-learning-with-arbitrary-smooth-function-approximation.pdf">pdf</a></p><p>Author: Shalabh Bhatnagar, Doina Precup, David Silver, Richard S. Sutton, Hamid R. Maei, Csaba Szepesvári</p><p>Abstract: We introduce the ﬁrst temporal-difference learning algorithms that converge with smooth value function approximators, such as neural networks. Conventional temporal-difference (TD) methods, such as TD(λ), Q-learning and Sarsa have been used successfully with function approximation in many applications. However, it is well known that off-policy sampling, as well as nonlinear function approximation, can cause these algorithms to become unstable (i.e., the parameters of the approximator may diverge). Sutton et al. (2009a, 2009b) solved the problem of off-policy learning with linear TD algorithms by introducing a new objective function, related to the Bellman error, and algorithms that perform stochastic gradient-descent on this function. These methods can be viewed as natural generalizations to previous TD methods, as they converge to the same limit points when used with linear function approximation methods. We generalize this work to nonlinear function approximation. We present a Bellman error objective function and two gradient-descent TD algorithms that optimize it. We prove the asymptotic almost-sure convergence of both algorithms, for any ﬁnite Markov decision process and any smooth value function approximator, to a locally optimal solution. The algorithms are incremental and the computational complexity per time step scales linearly with the number of parameters of the approximator. Empirical results obtained in the game of Go demonstrate the algorithms’ effectiveness. 1</p><p>Reference: <a title="nips-2009-60-reference" href="../nips2009_reference/nips-2009-Convergent_Temporal-Difference_Learning_with_Arbitrary_Smooth_Function_Approximation_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('td', 0.501), ('wk', 0.499), ('tdc', 0.332), ('sutton', 0.256), ('sk', 0.175), ('policy', 0.147), ('bellm', 0.134), ('rg', 0.125), ('nonlinear', 0.116), ('tsitsikl', 0.095), ('baird', 0.095), ('mspbe', 0.095), ('reinforc', 0.092), ('tang', 0.084), ('hk', 0.079), ('barto', 0.077), ('szepesv', 0.076), ('converg', 0.076), ('project', 0.074), ('mae', 0.071)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999958 <a title="60-tfidf-1" href="./nips-2009-Convergent_Temporal-Difference_Learning_with_Arbitrary_Smooth_Function_Approximation.html">60 nips-2009-Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation</a></p>
<p>2 0.15284595 <a title="60-tfidf-2" href="./nips-2009-Compositionality_of_optimal_control_laws.html">54 nips-2009-Compositionality of optimal control laws</a></p>
<p>3 0.13667218 <a title="60-tfidf-3" href="./nips-2009-Training_Factor_Graphs_with_Reinforcement_Learning_for_Efficient_MAP_Inference.html">250 nips-2009-Training Factor Graphs with Reinforcement Learning for Efficient MAP Inference</a></p>
<p>4 0.13507719 <a title="60-tfidf-4" href="./nips-2009-Multi-Step_Dyna_Planning_for_Policy_Evaluation_and_Control.html">159 nips-2009-Multi-Step Dyna Planning for Policy Evaluation and Control</a></p>
<p>5 0.1218621 <a title="60-tfidf-5" href="./nips-2009-Robust_Value_Function_Approximation_Using_Bilinear_Programming.html">209 nips-2009-Robust Value Function Approximation Using Bilinear Programming</a></p>
<p>6 0.10731508 <a title="60-tfidf-6" href="./nips-2009-Improving_Existing_Fault_Recovery_Policies.html">113 nips-2009-Improving Existing Fault Recovery Policies</a></p>
<p>7 0.10719521 <a title="60-tfidf-7" href="./nips-2009-Solving_Stochastic_Games.html">221 nips-2009-Solving Stochastic Games</a></p>
<p>8 0.098098069 <a title="60-tfidf-8" href="./nips-2009-Manifold_Embeddings_for_Model-Based_Reinforcement_Learning_under_Partial_Observability.html">145 nips-2009-Manifold Embeddings for Model-Based Reinforcement Learning under Partial Observability</a></p>
<p>9 0.096411444 <a title="60-tfidf-9" href="./nips-2009-Efficient_Large-Scale_Distributed_Training_of_Conditional_Maximum_Entropy_Models.html">75 nips-2009-Efficient Large-Scale Distributed Training of Conditional Maximum Entropy Models</a></p>
<p>10 0.091977015 <a title="60-tfidf-10" href="./nips-2009-A_Stochastic_approximation_method_for_inference_in_probabilistic_graphical_models.html">18 nips-2009-A Stochastic approximation method for inference in probabilistic graphical models</a></p>
<p>11 0.079527862 <a title="60-tfidf-11" href="./nips-2009-A_Generalized_Natural_Actor-Critic_Algorithm.html">12 nips-2009-A Generalized Natural Actor-Critic Algorithm</a></p>
<p>12 0.074178867 <a title="60-tfidf-12" href="./nips-2009-Sparsistent_Learning_of_Varying-coefficient_Models_with_Structural_Changes.html">225 nips-2009-Sparsistent Learning of Varying-coefficient Models with Structural Changes</a></p>
<p>13 0.068651721 <a title="60-tfidf-13" href="./nips-2009-Bootstrapping_from_Game_Tree_Search.html">48 nips-2009-Bootstrapping from Game Tree Search</a></p>
<p>14 0.06331981 <a title="60-tfidf-14" href="./nips-2009-Complexity_of_Decentralized_Control%3A_Special_Cases.html">53 nips-2009-Complexity of Decentralized Control: Special Cases</a></p>
<p>15 0.06330625 <a title="60-tfidf-15" href="./nips-2009-Learning_in_Markov_Random_Fields_using_Tempered_Transitions.html">132 nips-2009-Learning in Markov Random Fields using Tempered Transitions</a></p>
<p>16 0.062279489 <a title="60-tfidf-16" href="./nips-2009-Skill_Discovery_in_Continuous_Reinforcement_Learning_Domains_using_Skill_Chaining.html">218 nips-2009-Skill Discovery in Continuous Reinforcement Learning Domains using Skill Chaining</a></p>
<p>17 0.060297858 <a title="60-tfidf-17" href="./nips-2009-The_Infinite_Partially_Observable_Markov_Decision_Process.html">242 nips-2009-The Infinite Partially Observable Markov Decision Process</a></p>
<p>18 0.059671227 <a title="60-tfidf-18" href="./nips-2009-Analysis_of_SVM_with_Indefinite_Kernels.html">33 nips-2009-Analysis of SVM with Indefinite Kernels</a></p>
<p>19 0.058678914 <a title="60-tfidf-19" href="./nips-2009-Bayesian_Nonparametric_Models_on_Decomposable_Graphs.html">40 nips-2009-Bayesian Nonparametric Models on Decomposable Graphs</a></p>
<p>20 0.053638149 <a title="60-tfidf-20" href="./nips-2009-Maximum_likelihood_trajectories_for_continuous-time_Markov_chains.html">150 nips-2009-Maximum likelihood trajectories for continuous-time Markov chains</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2009_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.142), (1, 0.026), (2, 0.108), (3, 0.095), (4, 0.173), (5, 0.13), (6, -0.019), (7, -0.02), (8, -0.025), (9, -0.033), (10, -0.064), (11, 0.001), (12, 0.033), (13, -0.023), (14, -0.082), (15, -0.03), (16, -0.006), (17, 0.005), (18, 0.015), (19, -0.061), (20, -0.082), (21, 0.036), (22, -0.048), (23, -0.067), (24, -0.129), (25, 0.089), (26, -0.094), (27, -0.055), (28, -0.024), (29, -0.138), (30, -0.003), (31, -0.024), (32, -0.029), (33, 0.05), (34, 0.013), (35, -0.021), (36, 0.06), (37, 0.054), (38, -0.011), (39, 0.012), (40, -0.102), (41, 0.049), (42, 0.03), (43, -0.002), (44, 0.087), (45, -0.035), (46, 0.079), (47, 0.093), (48, -0.181), (49, -0.084)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.90399343 <a title="60-lsi-1" href="./nips-2009-Convergent_Temporal-Difference_Learning_with_Arbitrary_Smooth_Function_Approximation.html">60 nips-2009-Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation</a></p>
<p>2 0.79911214 <a title="60-lsi-2" href="./nips-2009-Multi-Step_Dyna_Planning_for_Policy_Evaluation_and_Control.html">159 nips-2009-Multi-Step Dyna Planning for Policy Evaluation and Control</a></p>
<p>3 0.7249676 <a title="60-lsi-3" href="./nips-2009-Compositionality_of_optimal_control_laws.html">54 nips-2009-Compositionality of optimal control laws</a></p>
<p>4 0.67309535 <a title="60-lsi-4" href="./nips-2009-Robust_Value_Function_Approximation_Using_Bilinear_Programming.html">209 nips-2009-Robust Value Function Approximation Using Bilinear Programming</a></p>
<p>5 0.61062127 <a title="60-lsi-5" href="./nips-2009-A_Generalized_Natural_Actor-Critic_Algorithm.html">12 nips-2009-A Generalized Natural Actor-Critic Algorithm</a></p>
<p>6 0.59690028 <a title="60-lsi-6" href="./nips-2009-A_Smoothed_Approximate_Linear_Program.html">16 nips-2009-A Smoothed Approximate Linear Program</a></p>
<p>7 0.59037131 <a title="60-lsi-7" href="./nips-2009-Improving_Existing_Fault_Recovery_Policies.html">113 nips-2009-Improving Existing Fault Recovery Policies</a></p>
<p>8 0.55491281 <a title="60-lsi-8" href="./nips-2009-Manifold_Embeddings_for_Model-Based_Reinforcement_Learning_under_Partial_Observability.html">145 nips-2009-Manifold Embeddings for Model-Based Reinforcement Learning under Partial Observability</a></p>
<p>9 0.49610966 <a title="60-lsi-9" href="./nips-2009-Solving_Stochastic_Games.html">221 nips-2009-Solving Stochastic Games</a></p>
<p>10 0.47805458 <a title="60-lsi-10" href="./nips-2009-Bootstrapping_from_Game_Tree_Search.html">48 nips-2009-Bootstrapping from Game Tree Search</a></p>
<p>11 0.46980464 <a title="60-lsi-11" href="./nips-2009-Training_Factor_Graphs_with_Reinforcement_Learning_for_Efficient_MAP_Inference.html">250 nips-2009-Training Factor Graphs with Reinforcement Learning for Efficient MAP Inference</a></p>
<p>12 0.46261543 <a title="60-lsi-12" href="./nips-2009-Periodic_Step_Size_Adaptation_for_Single_Pass_On-line_Learning.html">189 nips-2009-Periodic Step Size Adaptation for Single Pass On-line Learning</a></p>
<p>13 0.43997216 <a title="60-lsi-13" href="./nips-2009-Learning_to_Explore_and_Exploit_in_POMDPs.html">134 nips-2009-Learning to Explore and Exploit in POMDPs</a></p>
<p>14 0.4336713 <a title="60-lsi-14" href="./nips-2009-A_Stochastic_approximation_method_for_inference_in_probabilistic_graphical_models.html">18 nips-2009-A Stochastic approximation method for inference in probabilistic graphical models</a></p>
<p>15 0.43224323 <a title="60-lsi-15" href="./nips-2009-Efficient_Large-Scale_Distributed_Training_of_Conditional_Maximum_Entropy_Models.html">75 nips-2009-Efficient Large-Scale Distributed Training of Conditional Maximum Entropy Models</a></p>
<p>16 0.39448828 <a title="60-lsi-16" href="./nips-2009-Maximum_likelihood_trajectories_for_continuous-time_Markov_chains.html">150 nips-2009-Maximum likelihood trajectories for continuous-time Markov chains</a></p>
<p>17 0.39431345 <a title="60-lsi-17" href="./nips-2009-On_the_Convergence_of_the_Concave-Convex_Procedure.html">180 nips-2009-On the Convergence of the Concave-Convex Procedure</a></p>
<p>18 0.39407417 <a title="60-lsi-18" href="./nips-2009-Ensemble_Nystrom_Method.html">81 nips-2009-Ensemble Nystrom Method</a></p>
<p>19 0.38879487 <a title="60-lsi-19" href="./nips-2009-Slow_Learners_are_Fast.html">220 nips-2009-Slow Learners are Fast</a></p>
<p>20 0.38678545 <a title="60-lsi-20" href="./nips-2009-Bayesian_Belief_Polarization.html">39 nips-2009-Bayesian Belief Polarization</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2009_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(4, 0.012), (9, 0.201), (11, 0.035), (24, 0.012), (31, 0.141), (37, 0.022), (60, 0.035), (82, 0.341), (89, 0.021), (96, 0.084)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.76164716 <a title="60-lda-1" href="./nips-2009-Multi-Step_Dyna_Planning_for_Policy_Evaluation_and_Control.html">159 nips-2009-Multi-Step Dyna Planning for Policy Evaluation and Control</a></p>
<p>2 0.73152864 <a title="60-lda-2" href="./nips-2009-Skill_Discovery_in_Continuous_Reinforcement_Learning_Domains_using_Skill_Chaining.html">218 nips-2009-Skill Discovery in Continuous Reinforcement Learning Domains using Skill Chaining</a></p>
<p>same-paper 3 0.7138443 <a title="60-lda-3" href="./nips-2009-Convergent_Temporal-Difference_Learning_with_Arbitrary_Smooth_Function_Approximation.html">60 nips-2009-Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation</a></p>
<p>4 0.67921495 <a title="60-lda-4" href="./nips-2009-Non-Parametric_Bayesian_Dictionary_Learning_for_Sparse_Image_Representations.html">167 nips-2009-Non-Parametric Bayesian Dictionary Learning for Sparse Image Representations</a></p>
<p>5 0.60315698 <a title="60-lda-5" href="./nips-2009-Maximum_likelihood_trajectories_for_continuous-time_Markov_chains.html">150 nips-2009-Maximum likelihood trajectories for continuous-time Markov chains</a></p>
<p>6 0.60113716 <a title="60-lda-6" href="./nips-2009-Manifold_Embeddings_for_Model-Based_Reinforcement_Learning_under_Partial_Observability.html">145 nips-2009-Manifold Embeddings for Model-Based Reinforcement Learning under Partial Observability</a></p>
<p>7 0.60086328 <a title="60-lda-7" href="./nips-2009-Bayesian_Source_Localization_with_the_Multivariate_Laplace_Prior.html">41 nips-2009-Bayesian Source Localization with the Multivariate Laplace Prior</a></p>
<p>8 0.59846735 <a title="60-lda-8" href="./nips-2009-Regularized_Distance_Metric_Learning%3ATheory_and_Algorithm.html">202 nips-2009-Regularized Distance Metric Learning:Theory and Algorithm</a></p>
<p>9 0.59738606 <a title="60-lda-9" href="./nips-2009-Lattice_Regression.html">124 nips-2009-Lattice Regression</a></p>
<p>10 0.59700155 <a title="60-lda-10" href="./nips-2009-The_Infinite_Partially_Observable_Markov_Decision_Process.html">242 nips-2009-The Infinite Partially Observable Markov Decision Process</a></p>
<p>11 0.5968864 <a title="60-lda-11" href="./nips-2009-Learning_in_Markov_Random_Fields_using_Tempered_Transitions.html">132 nips-2009-Learning in Markov Random Fields using Tempered Transitions</a></p>
<p>12 0.5962742 <a title="60-lda-12" href="./nips-2009-Learning_to_Explore_and_Exploit_in_POMDPs.html">134 nips-2009-Learning to Explore and Exploit in POMDPs</a></p>
<p>13 0.59609151 <a title="60-lda-13" href="./nips-2009-Kernels_and_learning_curves_for_Gaussian_process_regression_on_random_graphs.html">120 nips-2009-Kernels and learning curves for Gaussian process regression on random graphs</a></p>
<p>14 0.59534967 <a title="60-lda-14" href="./nips-2009-Positive_Semidefinite_Metric_Learning_with_Boosting.html">191 nips-2009-Positive Semidefinite Metric Learning with Boosting</a></p>
<p>15 0.59523946 <a title="60-lda-15" href="./nips-2009-Improving_Existing_Fault_Recovery_Policies.html">113 nips-2009-Improving Existing Fault Recovery Policies</a></p>
<p>16 0.59361374 <a title="60-lda-16" href="./nips-2009-Semi-supervised_Regression_using_Hessian_energy_with_an_application_to_semi-supervised_dimensionality_reduction.html">214 nips-2009-Semi-supervised Regression using Hessian energy with an application to semi-supervised dimensionality reduction</a></p>
<p>17 0.59310824 <a title="60-lda-17" href="./nips-2009-Fast_Graph_Laplacian_Regularized_Kernel_Learning_via_Semidefinite%E2%80%93Quadratic%E2%80%93Linear_Programming.html">92 nips-2009-Fast Graph Laplacian Regularized Kernel Learning via Semidefinite–Quadratic–Linear Programming</a></p>
<p>18 0.59288037 <a title="60-lda-18" href="./nips-2009-Rank-Approximate_Nearest_Neighbor_Search%3A_Retaining_Meaning_and_Speed_in_High_Dimensions.html">198 nips-2009-Rank-Approximate Nearest Neighbor Search: Retaining Meaning and Speed in High Dimensions</a></p>
<p>19 0.59252363 <a title="60-lda-19" href="./nips-2009-Fast%2C_smooth_and_adaptive_regression_in_metric_spaces.html">91 nips-2009-Fast, smooth and adaptive regression in metric spaces</a></p>
<p>20 0.59178835 <a title="60-lda-20" href="./nips-2009-Conditional_Neural_Fields.html">56 nips-2009-Conditional Neural Fields</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
