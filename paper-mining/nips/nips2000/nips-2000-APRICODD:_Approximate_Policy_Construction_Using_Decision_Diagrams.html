<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1 nips-2000-APRICODD: Approximate Policy Construction Using Decision Diagrams</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2000" href="../home/nips2000_home.html">nips2000</a> <a title="nips-2000-1" href="#">nips2000-1</a> knowledge-graph by maker-knowledge-mining</p><h1>1 nips-2000-APRICODD: Approximate Policy Construction Using Decision Diagrams</h1>
<br/><p>Source: <a title="nips-2000-1-pdf" href="http://papers.nips.cc/paper/1840-apricodd-approximate-policy-construction-using-decision-diagrams.pdf">pdf</a></p><p>Author: Robert St-Aubin, Jesse Hoey, Craig Boutilier</p><p>Abstract: We propose a method of approximate dynamic programming for Markov decision processes (MDPs) using algebraic decision diagrams (ADDs). We produce near-optimal value functions and policies with much lower time and space requirements than exact dynamic programming. Our method reduces the sizes of the intermediate value functions generated during value iteration by replacing the values at the terminals of the ADD with ranges of values. Our method is demonstrated on a class of large MDPs (with up to 34 billion states), and we compare the results with the optimal value functions.</p><p>Reference: <a title="nips-2000-1-reference" href="../nips2000_reference/nips-2000-APRICODD%3A_Approximate_Policy_Construction_Using_Decision_Diagrams_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('reord', 0.451), ('diagram', 0.438), ('prun', 0.294), ('shuffl', 0.19), ('policy', 0.179), ('vn', 0.169), ('mdps', 0.149), ('span', 0.149), ('it', 0.14), ('strengths', 0.139), ('hoey', 0.136), ('pjc', 0.136), ('craig', 0.127), ('ad', 0.119), ('sift', 0.109), ('valu', 0.105), ('bool', 0.104), ('decid', 0.104), ('dbn', 0.094), ('reward', 0.087)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="1-tfidf-1" href="./nips-2000-APRICODD%3A_Approximate_Policy_Construction_Using_Decision_Diagrams.html">1 nips-2000-APRICODD: Approximate Policy Construction Using Decision Diagrams</a></p>
<p>2 0.13437875 <a title="1-tfidf-2" href="./nips-2000-%60N-Body%27_Problems_in_Statistical_Learning.html">148 nips-2000-`N-Body' Problems in Statistical Learning</a></p>
<p>3 0.12810118 <a title="1-tfidf-3" href="./nips-2000-Balancing_Multiple_Sources_of_Reward_in_Reinforcement_Learning.html">28 nips-2000-Balancing Multiple Sources of Reward in Reinforcement Learning</a></p>
<p>4 0.12417544 <a title="1-tfidf-4" href="./nips-2000-Using_Free_Energies_to_Represent_Q-values_in_a_Multiagent_Reinforcement_Learning_Task.html">142 nips-2000-Using Free Energies to Represent Q-values in a Multiagent Reinforcement Learning Task</a></p>
<p>5 0.12349407 <a title="1-tfidf-5" href="./nips-2000-Reinforcement_Learning_with_Function_Approximation_Converges_to_a_Region.html">112 nips-2000-Reinforcement Learning with Function Approximation Converges to a Region</a></p>
<p>6 0.11711916 <a title="1-tfidf-6" href="./nips-2000-Automated_State_Abstraction_for_Options_using_the_U-Tree_Algorithm.html">26 nips-2000-Automated State Abstraction for Options using the U-Tree Algorithm</a></p>
<p>7 0.10083389 <a title="1-tfidf-7" href="./nips-2000-Exact_Solutions_to_Time-Dependent_MDPs.html">48 nips-2000-Exact Solutions to Time-Dependent MDPs</a></p>
<p>8 0.093434945 <a title="1-tfidf-8" href="./nips-2000-Decomposition_of_Reinforcement_Learning_for_Admission_Control_of_Self-Similar_Call_Arrival_Processes.html">39 nips-2000-Decomposition of Reinforcement Learning for Admission Control of Self-Similar Call Arrival Processes</a></p>
<p>9 0.087892905 <a title="1-tfidf-9" href="./nips-2000-Tree-Based_Modeling_and_Estimation_of_Gaussian_Processes_on_Graphs_with_Cycles.html">140 nips-2000-Tree-Based Modeling and Estimation of Gaussian Processes on Graphs with Cycles</a></p>
<p>10 0.085739553 <a title="1-tfidf-10" href="./nips-2000-Kernel-Based_Reinforcement_Learning_in_Average-Cost_Problems%3A_An_Application_to_Optimal_Portfolio_Choice.html">73 nips-2000-Kernel-Based Reinforcement Learning in Average-Cost Problems: An Application to Optimal Portfolio Choice</a></p>
<p>11 0.073199637 <a title="1-tfidf-11" href="./nips-2000-Programmable_Reinforcement_Learning_Agents.html">105 nips-2000-Programmable Reinforcement Learning Agents</a></p>
<p>12 0.068950444 <a title="1-tfidf-12" href="./nips-2000-Dopamine_Bonuses.html">43 nips-2000-Dopamine Bonuses</a></p>
<p>13 0.063981988 <a title="1-tfidf-13" href="./nips-2000-Hierarchical_Memory-Based_Reinforcement_Learning.html">63 nips-2000-Hierarchical Memory-Based Reinforcement Learning</a></p>
<p>14 0.063899279 <a title="1-tfidf-14" href="./nips-2000-Gaussianization.html">60 nips-2000-Gaussianization</a></p>
<p>15 0.057592753 <a title="1-tfidf-15" href="./nips-2000-Second_Order_Approximations_for_Probability_Models.html">114 nips-2000-Second Order Approximations for Probability Models</a></p>
<p>16 0.056651816 <a title="1-tfidf-16" href="./nips-2000-Discovering_Hidden_Variables%3A_A_Structure-Based_Approach.html">41 nips-2000-Discovering Hidden Variables: A Structure-Based Approach</a></p>
<p>17 0.055569779 <a title="1-tfidf-17" href="./nips-2000-Weak_Learners_and_Improved_Rates_of_Convergence_in_Boosting.html">145 nips-2000-Weak Learners and Improved Rates of Convergence in Boosting</a></p>
<p>18 0.053944256 <a title="1-tfidf-18" href="./nips-2000-Active_Learning_for_Parameter_Estimation_in_Bayesian_Networks.html">17 nips-2000-Active Learning for Parameter Estimation in Bayesian Networks</a></p>
<p>19 0.051255293 <a title="1-tfidf-19" href="./nips-2000-A_Tighter_Bound_for_Graphical_Models.html">13 nips-2000-A Tighter Bound for Graphical Models</a></p>
<p>20 0.050138496 <a title="1-tfidf-20" href="./nips-2000-Sparse_Greedy_Gaussian_Process_Regression.html">120 nips-2000-Sparse Greedy Gaussian Process Regression</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2000_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.18), (1, 0.01), (2, -0.096), (3, 0.228), (4, -0.102), (5, 0.012), (6, -0.012), (7, 0.07), (8, -0.077), (9, 0.04), (10, -0.055), (11, 0.019), (12, -0.012), (13, -0.074), (14, 0.039), (15, -0.044), (16, 0.041), (17, -0.063), (18, 0.037), (19, -0.108), (20, 0.009), (21, -0.051), (22, 0.066), (23, -0.037), (24, 0.053), (25, -0.034), (26, 0.002), (27, -0.033), (28, -0.058), (29, 0.072), (30, -0.09), (31, 0.054), (32, 0.043), (33, -0.066), (34, -0.09), (35, 0.167), (36, 0.122), (37, -0.06), (38, -0.091), (39, -0.072), (40, 0.204), (41, 0.07), (42, 0.023), (43, 0.046), (44, -0.097), (45, -0.206), (46, 0.05), (47, 0.002), (48, 0.068), (49, 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92557615 <a title="1-lsi-1" href="./nips-2000-APRICODD%3A_Approximate_Policy_Construction_Using_Decision_Diagrams.html">1 nips-2000-APRICODD: Approximate Policy Construction Using Decision Diagrams</a></p>
<p>2 0.61127865 <a title="1-lsi-2" href="./nips-2000-Exact_Solutions_to_Time-Dependent_MDPs.html">48 nips-2000-Exact Solutions to Time-Dependent MDPs</a></p>
<p>3 0.59131867 <a title="1-lsi-3" href="./nips-2000-%60N-Body%27_Problems_in_Statistical_Learning.html">148 nips-2000-`N-Body' Problems in Statistical Learning</a></p>
<p>4 0.57236779 <a title="1-lsi-4" href="./nips-2000-On_Iterative_Krylov-Dogleg_Trust-Region_Steps_for_Solving_Neural_Networks_Nonlinear_Least_Squares_Problems.html">93 nips-2000-On Iterative Krylov-Dogleg Trust-Region Steps for Solving Neural Networks Nonlinear Least Squares Problems</a></p>
<p>5 0.50235349 <a title="1-lsi-5" href="./nips-2000-Reinforcement_Learning_with_Function_Approximation_Converges_to_a_Region.html">112 nips-2000-Reinforcement Learning with Function Approximation Converges to a Region</a></p>
<p>6 0.48032033 <a title="1-lsi-6" href="./nips-2000-Decomposition_of_Reinforcement_Learning_for_Admission_Control_of_Self-Similar_Call_Arrival_Processes.html">39 nips-2000-Decomposition of Reinforcement Learning for Admission Control of Self-Similar Call Arrival Processes</a></p>
<p>7 0.42286882 <a title="1-lsi-7" href="./nips-2000-Programmable_Reinforcement_Learning_Agents.html">105 nips-2000-Programmable Reinforcement Learning Agents</a></p>
<p>8 0.42212242 <a title="1-lsi-8" href="./nips-2000-Balancing_Multiple_Sources_of_Reward_in_Reinforcement_Learning.html">28 nips-2000-Balancing Multiple Sources of Reward in Reinforcement Learning</a></p>
<p>9 0.42182299 <a title="1-lsi-9" href="./nips-2000-Using_Free_Energies_to_Represent_Q-values_in_a_Multiagent_Reinforcement_Learning_Task.html">142 nips-2000-Using Free Energies to Represent Q-values in a Multiagent Reinforcement Learning Task</a></p>
<p>10 0.41242576 <a title="1-lsi-10" href="./nips-2000-Automated_State_Abstraction_for_Options_using_the_U-Tree_Algorithm.html">26 nips-2000-Automated State Abstraction for Options using the U-Tree Algorithm</a></p>
<p>11 0.40412575 <a title="1-lsi-11" href="./nips-2000-Fast_Training_of_Support_Vector_Classifiers.html">52 nips-2000-Fast Training of Support Vector Classifiers</a></p>
<p>12 0.39703968 <a title="1-lsi-12" href="./nips-2000-Tree-Based_Modeling_and_Estimation_of_Gaussian_Processes_on_Graphs_with_Cycles.html">140 nips-2000-Tree-Based Modeling and Estimation of Gaussian Processes on Graphs with Cycles</a></p>
<p>13 0.36315066 <a title="1-lsi-13" href="./nips-2000-Sequentially_Fitting_%60%60Inclusive%27%27_Trees_for_Inference_in_Noisy-OR_Networks.html">115 nips-2000-Sequentially Fitting ``Inclusive'' Trees for Inference in Noisy-OR Networks</a></p>
<p>14 0.35882294 <a title="1-lsi-14" href="./nips-2000-Who_Does_What%3F_A_Novel_Algorithm_to_Determine_Function_Localization.html">147 nips-2000-Who Does What? A Novel Algorithm to Determine Function Localization</a></p>
<p>15 0.33451068 <a title="1-lsi-15" href="./nips-2000-Kernel-Based_Reinforcement_Learning_in_Average-Cost_Problems%3A_An_Application_to_Optimal_Portfolio_Choice.html">73 nips-2000-Kernel-Based Reinforcement Learning in Average-Cost Problems: An Application to Optimal Portfolio Choice</a></p>
<p>16 0.32610145 <a title="1-lsi-16" href="./nips-2000-Hierarchical_Memory-Based_Reinforcement_Learning.html">63 nips-2000-Hierarchical Memory-Based Reinforcement Learning</a></p>
<p>17 0.32567525 <a title="1-lsi-17" href="./nips-2000-Active_Learning_for_Parameter_Estimation_in_Bayesian_Networks.html">17 nips-2000-Active Learning for Parameter Estimation in Bayesian Networks</a></p>
<p>18 0.31448385 <a title="1-lsi-18" href="./nips-2000-Active_Support_Vector_Machine_Classification.html">18 nips-2000-Active Support Vector Machine Classification</a></p>
<p>19 0.29137135 <a title="1-lsi-19" href="./nips-2000-Sparse_Greedy_Gaussian_Process_Regression.html">120 nips-2000-Sparse Greedy Gaussian Process Regression</a></p>
<p>20 0.2912097 <a title="1-lsi-20" href="./nips-2000-Dopamine_Bonuses.html">43 nips-2000-Dopamine Bonuses</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2000_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(9, 0.105), (11, 0.031), (16, 0.064), (21, 0.028), (26, 0.026), (38, 0.035), (51, 0.383), (54, 0.057), (74, 0.014), (76, 0.04), (84, 0.121)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.71718895 <a title="1-lda-1" href="./nips-2000-APRICODD%3A_Approximate_Policy_Construction_Using_Decision_Diagrams.html">1 nips-2000-APRICODD: Approximate Policy Construction Using Decision Diagrams</a></p>
<p>2 0.58203644 <a title="1-lda-2" href="./nips-2000-Sparse_Representation_for_Gaussian_Process_Models.html">122 nips-2000-Sparse Representation for Gaussian Process Models</a></p>
<p>3 0.43568343 <a title="1-lda-3" href="./nips-2000-Incorporating_Second-Order_Functional_Knowledge_for_Better_Option_Pricing.html">69 nips-2000-Incorporating Second-Order Functional Knowledge for Better Option Pricing</a></p>
<p>4 0.43543404 <a title="1-lda-4" href="./nips-2000-Learning_Switching_Linear_Models_of_Human_Motion.html">80 nips-2000-Learning Switching Linear Models of Human Motion</a></p>
<p>5 0.43437624 <a title="1-lda-5" href="./nips-2000-Automated_State_Abstraction_for_Options_using_the_U-Tree_Algorithm.html">26 nips-2000-Automated State Abstraction for Options using the U-Tree Algorithm</a></p>
<p>6 0.43352887 <a title="1-lda-6" href="./nips-2000-Tree-Based_Modeling_and_Estimation_of_Gaussian_Processes_on_Graphs_with_Cycles.html">140 nips-2000-Tree-Based Modeling and Estimation of Gaussian Processes on Graphs with Cycles</a></p>
<p>7 0.43195468 <a title="1-lda-7" href="./nips-2000-Propagation_Algorithms_for_Variational_Bayesian_Learning.html">106 nips-2000-Propagation Algorithms for Variational Bayesian Learning</a></p>
<p>8 0.43179673 <a title="1-lda-8" href="./nips-2000-Improved_Output_Coding_for_Classification_Using_Continuous_Relaxation.html">68 nips-2000-Improved Output Coding for Classification Using Continuous Relaxation</a></p>
<p>9 0.43118912 <a title="1-lda-9" href="./nips-2000-Data_Clustering_by_Markovian_Relaxation_and_the_Information_Bottleneck_Method.html">38 nips-2000-Data Clustering by Markovian Relaxation and the Information Bottleneck Method</a></p>
<p>10 0.43101183 <a title="1-lda-10" href="./nips-2000-Kernel-Based_Reinforcement_Learning_in_Average-Cost_Problems%3A_An_Application_to_Optimal_Portfolio_Choice.html">73 nips-2000-Kernel-Based Reinforcement Learning in Average-Cost Problems: An Application to Optimal Portfolio Choice</a></p>
<p>11 0.43096137 <a title="1-lda-11" href="./nips-2000-Balancing_Multiple_Sources_of_Reward_in_Reinforcement_Learning.html">28 nips-2000-Balancing Multiple Sources of Reward in Reinforcement Learning</a></p>
<p>12 0.42985633 <a title="1-lda-12" href="./nips-2000-High-temperature_Expansions_for_Learning_Models_of_Nonnegative_Data.html">64 nips-2000-High-temperature Expansions for Learning Models of Nonnegative Data</a></p>
<p>13 0.42846698 <a title="1-lda-13" href="./nips-2000-Mixtures_of_Gaussian_Processes.html">85 nips-2000-Mixtures of Gaussian Processes</a></p>
<p>14 0.42827249 <a title="1-lda-14" href="./nips-2000-Support_Vector_Novelty_Detection_Applied_to_Jet_Engine_Vibration_Spectra.html">128 nips-2000-Support Vector Novelty Detection Applied to Jet Engine Vibration Spectra</a></p>
<p>15 0.42459658 <a title="1-lda-15" href="./nips-2000-Explaining_Away_in_Weight_Space.html">49 nips-2000-Explaining Away in Weight Space</a></p>
<p>16 0.42376211 <a title="1-lda-16" href="./nips-2000-Reinforcement_Learning_with_Function_Approximation_Converges_to_a_Region.html">112 nips-2000-Reinforcement Learning with Function Approximation Converges to a Region</a></p>
<p>17 0.42365742 <a title="1-lda-17" href="./nips-2000-Rate-coded_Restricted_Boltzmann_Machines_for_Face_Recognition.html">107 nips-2000-Rate-coded Restricted Boltzmann Machines for Face Recognition</a></p>
<p>18 0.42349967 <a title="1-lda-18" href="./nips-2000-Higher-Order_Statistical_Properties_Arising_from_the_Non-Stationarity_of_Natural_Signals.html">65 nips-2000-Higher-Order Statistical Properties Arising from the Non-Stationarity of Natural Signals</a></p>
<p>19 0.42277765 <a title="1-lda-19" href="./nips-2000-Learning_and_Tracking_Cyclic_Human_Motion.html">82 nips-2000-Learning and Tracking Cyclic Human Motion</a></p>
<p>20 0.42254096 <a title="1-lda-20" href="./nips-2000-Weak_Learners_and_Improved_Rates_of_Convergence_in_Boosting.html">145 nips-2000-Weak Learners and Improved Rates of Convergence in Boosting</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
