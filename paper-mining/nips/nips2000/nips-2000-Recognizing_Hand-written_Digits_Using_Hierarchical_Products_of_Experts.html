<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>108 nips-2000-Recognizing Hand-written Digits Using Hierarchical Products of Experts</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2000" href="../home/nips2000_home.html">nips2000</a> <a title="nips-2000-108" href="#">nips2000-108</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>108 nips-2000-Recognizing Hand-written Digits Using Hierarchical Products of Experts</h1>
<br/><p>Source: <a title="nips-2000-108-pdf" href="http://papers.nips.cc/paper/1807-recognizing-hand-written-digits-using-hierarchical-products-of-experts.pdf">pdf</a></p><p>Author: Guy Mayraz, Geoffrey E. Hinton</p><p>Abstract: The product of experts learning procedure [1] can discover a set of stochastic binary features that constitute a non-linear generative model of handwritten images of digits. The quality of generative models learned in this way can be assessed by learning a separate model for each class of digit and then comparing the unnormalized probabilities of test images under the 10 different class-specific models. To improve discriminative performance, it is helpful to learn a hierarchy of separate models for each digit class. Each model in the hierarchy has one layer of hidden units and the nth level model is trained on data that consists of the activities of the hidden units in the already trained (n - l)th level model. After training, each level produces a separate, unnormalized log probabilty score. With a three-level hierarchy for each of the 10 digit classes, a test image produces 30 scores which can be used as inputs to a supervised, logistic classification network that is trained on separate data. On the MNIST database, our system is comparable with current state-of-the-art discriminative methods, demonstrating that the product of experts learning procedure can produce effective generative models of high-dimensional data. 1 Learning products of stochastic binary experts Hinton [1] describes a learning algorithm for probabilistic generative models that are composed of a number of experts. Each expert specifies a probability distribution over the visible variables and the experts are combined by multiplying these distributions together and renormalizing. (1) where d is a data vector in a discrete space, Om is all the parameters of individual model m, Pm(dIOm) is the probability of d under model m, and c is an index over all possible vectors in the data space. A Restricted Boltzmann machine [2, 3] is a special case of a product of experts in which each expert is a single, binary stochastic hidden unit that has symmetrical connections to a set of visible units, and connections between the hidden units are forbidden. Inference in an RBM is much easier than in a general Boltzmann machine and it is also much easier than in a causal belief net because there is no explaining away. There is therefore no need to perform any iteration to determine the activities of the hidden units. The hidden states, Sj , are conditionally independent given the visible states, Si, and the distribution of Sj is given by the standard logistic function : 1 p(Sj = 1) = (2) 1 + exp( - Li WijSi) Conversely, the hidden states of an RBM are marginally dependent so it is easy for an RBM to learn population codes in which units may be highly correlated. It is hard to do this in causal belief nets with one hidden layer because the generative model of a causal belief net assumes marginal independence. An RBM can be trained using the standard Boltzmann machine learning algorithm which follows a noisy but unbiased estimate of the gradient of the log likelihood of the data. One way to implement this algorithm is to start the network with a data vector on the visible units and then to alternate between updating all of the hidden units in parallel and updating all of the visible units in parallel. Each update picks a binary state for a unit from its posterior distribution given the current states of all the units in the other set. If this alternating Gibbs sampling is run to equilibrium, there is a very simple way to update the weights so as to minimize the Kullback-Leibler divergence, QOIIQoo, between the data distribution, QO, and the equilibrium distribution of fantasies over the visible units, Qoo, produced by the RBM [4]: flWij oc QO - Q~ (3) where < SiSj >Qo is the expected value of SiSj when data is clamped on the visible units and the hidden states are sampled from their conditional distribution given the data, and Q ~ is the expected value of SiSj after prolonged Gibbs sampling. This learning rule does not work well because it can take a long time to approach thermal equilibrium and the sampling noise in the estimate of  Q ~ can swamp the gradient. [1] shows that it is far more effective to minimize the difference between QOllQoo and Q111Qoo where Q1 is the distribution of the one-step reconstructions of the data that are produced by first picking binary hidden states from their conditional distribution given the data and then picking binary visible states from their conditional distribution given the hidden states. The exact gradient of this</p><p>Reference: <a title="nips-2000-108-reference" href="../nips2000_reference/nips-2000-Recognizing_Hand-written_Digits_Using_Hierarchical_Products_of_Experts_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Abstract The product of experts learning procedure [1] can discover a set of stochastic binary features that constitute a non-linear generative model of handwritten images of digits. [sent-4, score-0.846]
</p><p>2 The quality of generative models learned in this way can be assessed by learning a separate model for each class of digit and then comparing the unnormalized probabilities of test images under the 10 different class-specific models. [sent-5, score-0.61]
</p><p>3 To improve discriminative performance, it is helpful to learn a hierarchy of separate models for each digit class. [sent-6, score-0.482]
</p><p>4 Each model in the hierarchy has one layer of hidden units and the nth level model is trained on data that consists of the activities of the hidden units in the already trained (n - l)th level model. [sent-7, score-1.492]
</p><p>5 After training, each level produces a separate, unnormalized log probabilty score. [sent-8, score-0.217]
</p><p>6 With a three-level hierarchy for each of the 10 digit classes, a test image produces 30 scores which can be used as inputs to a supervised, logistic classification network that is trained on separate data. [sent-9, score-0.635]
</p><p>7 On the MNIST database, our system is comparable with current state-of-the-art discriminative methods, demonstrating that the product of experts learning procedure can produce effective generative models of high-dimensional data. [sent-10, score-0.705]
</p><p>8 1 Learning products of stochastic binary experts Hinton [1] describes a learning algorithm for probabilistic generative models that are composed of a number of experts. [sent-11, score-0.711]
</p><p>9 Each expert specifies a probability distribution over the visible variables and the experts are combined by multiplying these distributions together and renormalizing. [sent-12, score-0.806]
</p><p>10 A Restricted Boltzmann machine [2, 3] is a special case of a product of experts in which each expert is a single, binary stochastic hidden unit that has symmetrical connections to a set of visible units, and connections between the hidden units are forbidden. [sent-14, score-1.765]
</p><p>11 Inference in an RBM is much easier than in a general Boltzmann machine and it is also much easier  than in a causal belief net because there is no explaining away. [sent-15, score-0.517]
</p><p>12 There is therefore no need to perform any iteration to determine the activities of the hidden units. [sent-16, score-0.268]
</p><p>13 It is hard to do this in causal belief nets with one hidden layer because the generative model of a causal belief net assumes marginal independence. [sent-18, score-0.995]
</p><p>14 An RBM can be trained using the standard Boltzmann machine learning algorithm which follows a noisy but unbiased estimate of the gradient of the log likelihood of the data. [sent-19, score-0.239]
</p><p>15 One way to implement this algorithm is to start the network with a data vector on the visible units and then to alternate between updating all of the hidden units in parallel and updating all of the visible units in parallel. [sent-20, score-1.815]
</p><p>16 Each update picks a binary state for a unit from its posterior distribution given the current states of all the units in the other set. [sent-21, score-0.709]
</p><p>17 This learning rule does not work well because it can take a long time to approach thermal equilibrium and the sampling noise in the estimate of  Q ~ can swamp the gradient. [sent-23, score-0.315]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('rbm', 0.334), ('visible', 0.323), ('units', 0.256), ('experts', 0.251), ('sisj', 0.201), ('qo', 0.199), ('hidden', 0.195), ('generative', 0.178), ('flwij', 0.155), ('causal', 0.136), ('digit', 0.136), ('binary', 0.129), ('sj', 0.126), ('hierarchy', 0.121), ('equilibrium', 0.113), ('contrastive', 0.112), ('states', 0.108), ('unnormalized', 0.105), ('divergence', 0.104), ('boltzmann', 0.101), ('separate', 0.095), ('oc', 0.095), ('logistic', 0.091), ('expert', 0.091), ('picking', 0.091), ('discriminative', 0.091), ('trained', 0.09), ('belief', 0.089), ('effective', 0.081), ('updating', 0.078), ('net', 0.073), ('activities', 0.073), ('gibbs', 0.073), ('easier', 0.069), ('hinton', 0.067), ('guy', 0.067), ('fantasies', 0.067), ('qoiiqoo', 0.067), ('qollqoo', 0.067), ('qoo', 0.067), ('swamp', 0.067), ('wijsi', 0.067), ('stochastic', 0.065), ('gradient', 0.063), ('nth', 0.061), ('picks', 0.061), ('prolonged', 0.061), ('safely', 0.061), ('conditional', 0.06), ('distribution', 0.059), ('produced', 0.059), ('produces', 0.059), ('product', 0.057), ('assessed', 0.056), ('reconstructions', 0.056), ('om', 0.056), ('connections', 0.055), ('unit', 0.054), ('london', 0.054), ('level', 0.053), ('mnist', 0.053), ('alternating', 0.053), ('marginally', 0.053), ('geoffrey', 0.053), ('minimize', 0.052), ('products', 0.052), ('ignored', 0.05), ('thermal', 0.05), ('alternate', 0.05), ('nets', 0.05), ('layer', 0.049), ('sampling', 0.048), ('discover', 0.047), ('unbiased', 0.047), ('clamped', 0.047), ('demonstrating', 0.047), ('conversely', 0.047), ('pm', 0.047), ('scores', 0.043), ('queen', 0.043), ('update', 0.042), ('multiplying', 0.042), ('population', 0.042), ('explaining', 0.042), ('conditionally', 0.042), ('wcin', 0.042), ('digits', 0.04), ('recognizing', 0.04), ('handwritten', 0.04), ('specifies', 0.04), ('images', 0.04), ('learn', 0.039), ('machine', 0.039), ('college', 0.039), ('constitute', 0.039), ('rule', 0.037), ('gatsby', 0.037), ('codes', 0.036), ('composed', 0.036), ('hierarchical', 0.036)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="108-tfidf-1" href="./nips-2000-Recognizing_Hand-written_Digits_Using_Hierarchical_Products_of_Experts.html">108 nips-2000-Recognizing Hand-written Digits Using Hierarchical Products of Experts</a></p>
<p>Author: Guy Mayraz, Geoffrey E. Hinton</p><p>Abstract: The product of experts learning procedure [1] can discover a set of stochastic binary features that constitute a non-linear generative model of handwritten images of digits. The quality of generative models learned in this way can be assessed by learning a separate model for each class of digit and then comparing the unnormalized probabilities of test images under the 10 different class-specific models. To improve discriminative performance, it is helpful to learn a hierarchy of separate models for each digit class. Each model in the hierarchy has one layer of hidden units and the nth level model is trained on data that consists of the activities of the hidden units in the already trained (n - l)th level model. After training, each level produces a separate, unnormalized log probabilty score. With a three-level hierarchy for each of the 10 digit classes, a test image produces 30 scores which can be used as inputs to a supervised, logistic classification network that is trained on separate data. On the MNIST database, our system is comparable with current state-of-the-art discriminative methods, demonstrating that the product of experts learning procedure can produce effective generative models of high-dimensional data. 1 Learning products of stochastic binary experts Hinton [1] describes a learning algorithm for probabilistic generative models that are composed of a number of experts. Each expert specifies a probability distribution over the visible variables and the experts are combined by multiplying these distributions together and renormalizing. (1) where d is a data vector in a discrete space, Om is all the parameters of individual model m, Pm(dIOm) is the probability of d under model m, and c is an index over all possible vectors in the data space. A Restricted Boltzmann machine [2, 3] is a special case of a product of experts in which each expert is a single, binary stochastic hidden unit that has symmetrical connections to a set of visible units, and connections between the hidden units are forbidden. Inference in an RBM is much easier than in a general Boltzmann machine and it is also much easier than in a causal belief net because there is no explaining away. There is therefore no need to perform any iteration to determine the activities of the hidden units. The hidden states, Sj , are conditionally independent given the visible states, Si, and the distribution of Sj is given by the standard logistic function : 1 p(Sj = 1) = (2) 1 + exp( - Li WijSi) Conversely, the hidden states of an RBM are marginally dependent so it is easy for an RBM to learn population codes in which units may be highly correlated. It is hard to do this in causal belief nets with one hidden layer because the generative model of a causal belief net assumes marginal independence. An RBM can be trained using the standard Boltzmann machine learning algorithm which follows a noisy but unbiased estimate of the gradient of the log likelihood of the data. One way to implement this algorithm is to start the network with a data vector on the visible units and then to alternate between updating all of the hidden units in parallel and updating all of the visible units in parallel. Each update picks a binary state for a unit from its posterior distribution given the current states of all the units in the other set. If this alternating Gibbs sampling is run to equilibrium, there is a very simple way to update the weights so as to minimize the Kullback-Leibler divergence, QOIIQoo, between the data distribution, QO, and the equilibrium distribution of fantasies over the visible units, Qoo, produced by the RBM [4]: flWij oc QO - Q~ (3) where < SiSj >Qo is the expected value of SiSj when data is clamped on the visible units and the hidden states are sampled from their conditional distribution given the data, and Q ~ is the expected value of SiSj after prolonged Gibbs sampling. This learning rule does not work well because it can take a long time to approach thermal equilibrium and the sampling noise in the estimate of  Q ~ can swamp the gradient. [1] shows that it is far more effective to minimize the difference between QOllQoo and Q111Qoo where Q1 is the distribution of the one-step reconstructions of the data that are produced by first picking binary hidden states from their conditional distribution given the data and then picking binary visible states from their conditional distribution given the hidden states. The exact gradient of this</p><p>2 0.3904123 <a title="108-tfidf-2" href="./nips-2000-Rate-coded_Restricted_Boltzmann_Machines_for_Face_Recognition.html">107 nips-2000-Rate-coded Restricted Boltzmann Machines for Face Recognition</a></p>
<p>Author: Yee Whye Teh, Geoffrey E. Hinton</p><p>Abstract: We describe a neurally-inspired, unsupervised learning algorithm that builds a non-linear generative model for pairs of face images from the same individual. Individuals are then recognized by finding the highest relative probability pair among all pairs that consist of a test image and an image whose identity is known. Our method compares favorably with other methods in the literature. The generative model consists of a single layer of rate-coded, non-linear feature detectors and it has the property that, given a data vector, the true posterior probability distribution over the feature detector activities can be inferred rapidly without iteration or approximation. The weights of the feature detectors are learned by comparing the correlations of pixel intensities and feature activations in two phases: When the network is observing real data and when it is observing reconstructions of real data generated from the feature activations.</p><p>3 0.20261574 <a title="108-tfidf-3" href="./nips-2000-Using_Free_Energies_to_Represent_Q-values_in_a_Multiagent_Reinforcement_Learning_Task.html">142 nips-2000-Using Free Energies to Represent Q-values in a Multiagent Reinforcement Learning Task</a></p>
<p>Author: Brian Sallans, Geoffrey E. Hinton</p><p>Abstract: The problem of reinforcement learning in large factored Markov decision processes is explored. The Q-value of a state-action pair is approximated by the free energy of a product of experts network. Network parameters are learned on-line using a modified SARSA algorithm which minimizes the inconsistency of the Q-values of consecutive state-action pairs. Actions are chosen based on the current value estimates by fixing the current state and sampling actions from the network using Gibbs sampling. The algorithm is tested on a co-operative multi-agent task. The product of experts model is found to perform comparably to table-based Q-Iearning for small instances of the task, and continues to perform well when the problem becomes too large for a table-based representation.</p><p>4 0.12891227 <a title="108-tfidf-4" href="./nips-2000-Propagation_Algorithms_for_Variational_Bayesian_Learning.html">106 nips-2000-Propagation Algorithms for Variational Bayesian Learning</a></p>
<p>Author: Zoubin Ghahramani, Matthew J. Beal</p><p>Abstract: Variational approximations are becoming a widespread tool for Bayesian learning of graphical models. We provide some theoretical results for the variational updates in a very general family of conjugate-exponential graphical models. We show how the belief propagation and the junction tree algorithms can be used in the inference step of variational Bayesian learning. Applying these results to the Bayesian analysis of linear-Gaussian state-space models we obtain a learning procedure that exploits the Kalman smoothing propagation, while integrating over all model parameters. We demonstrate how this can be used to infer the hidden state dimensionality of the state-space model in a variety of synthetic problems and one real high-dimensional data set. 1</p><p>5 0.12173077 <a title="108-tfidf-5" href="./nips-2000-Discovering_Hidden_Variables%3A_A_Structure-Based_Approach.html">41 nips-2000-Discovering Hidden Variables: A Structure-Based Approach</a></p>
<p>Author: Gal Elidan, Noam Lotner, Nir Friedman, Daphne Koller</p><p>Abstract: A serious problem in learning probabilistic models is the presence of hidden variables. These variables are not observed, yet interact with several of the observed variables. As such, they induce seemingly complex dependencies among the latter. In recent years, much attention has been devoted to the development of algorithms for learning parameters, and in some cases structure, in the presence of hidden variables. In this paper, we address the related problem of detecting hidden variables that interact with the observed variables. This problem is of interest both for improving our understanding of the domain and as a preliminary step that guides the learning procedure towards promising models. A very natural approach is to search for</p><p>6 0.11426388 <a title="108-tfidf-6" href="./nips-2000-Overfitting_in_Neural_Nets%3A_Backpropagation%2C_Conjugate_Gradient%2C_and_Early_Stopping.html">97 nips-2000-Overfitting in Neural Nets: Backpropagation, Conjugate Gradient, and Early Stopping</a></p>
<p>7 0.11296694 <a title="108-tfidf-7" href="./nips-2000-Structure_Learning_in_Human_Causal_Induction.html">127 nips-2000-Structure Learning in Human Causal Induction</a></p>
<p>8 0.08985576 <a title="108-tfidf-8" href="./nips-2000-Beyond_Maximum_Likelihood_and_Density_Estimation%3A_A_Sample-Based_Criterion_for_Unsupervised_Learning_of_Complex_Models.html">31 nips-2000-Beyond Maximum Likelihood and Density Estimation: A Sample-Based Criterion for Unsupervised Learning of Complex Models</a></p>
<p>9 0.080954216 <a title="108-tfidf-9" href="./nips-2000-A_Tighter_Bound_for_Graphical_Models.html">13 nips-2000-A Tighter Bound for Graphical Models</a></p>
<p>10 0.079911098 <a title="108-tfidf-10" href="./nips-2000-Partially_Observable_SDE_Models_for_Image_Sequence_Recognition_Tasks.html">98 nips-2000-Partially Observable SDE Models for Image Sequence Recognition Tasks</a></p>
<p>11 0.076636538 <a title="108-tfidf-11" href="./nips-2000-High-temperature_Expansions_for_Learning_Models_of_Nonnegative_Data.html">64 nips-2000-High-temperature Expansions for Learning Models of Nonnegative Data</a></p>
<p>12 0.074014053 <a title="108-tfidf-12" href="./nips-2000-Second_Order_Approximations_for_Probability_Models.html">114 nips-2000-Second Order Approximations for Probability Models</a></p>
<p>13 0.072442904 <a title="108-tfidf-13" href="./nips-2000-Improved_Output_Coding_for_Classification_Using_Continuous_Relaxation.html">68 nips-2000-Improved Output Coding for Classification Using Continuous Relaxation</a></p>
<p>14 0.067931429 <a title="108-tfidf-14" href="./nips-2000-Vicinal_Risk_Minimization.html">144 nips-2000-Vicinal Risk Minimization</a></p>
<p>15 0.064879306 <a title="108-tfidf-15" href="./nips-2000-An_Information_Maximization_Approach_to_Overcomplete_and_Recurrent_Representations.html">24 nips-2000-An Information Maximization Approach to Overcomplete and Recurrent Representations</a></p>
<p>16 0.06008435 <a title="108-tfidf-16" href="./nips-2000-Factored_Semi-Tied_Covariance_Matrices.html">51 nips-2000-Factored Semi-Tied Covariance Matrices</a></p>
<p>17 0.059947595 <a title="108-tfidf-17" href="./nips-2000-On_Reversing_Jensen%27s_Inequality.html">94 nips-2000-On Reversing Jensen's Inequality</a></p>
<p>18 0.059527025 <a title="108-tfidf-18" href="./nips-2000-A_Gradient-Based_Boosting_Algorithm_for_Regression_Problems.html">3 nips-2000-A Gradient-Based Boosting Algorithm for Regression Problems</a></p>
<p>19 0.059201851 <a title="108-tfidf-19" href="./nips-2000-Occam%27s_Razor.html">92 nips-2000-Occam's Razor</a></p>
<p>20 0.058586963 <a title="108-tfidf-20" href="./nips-2000-A_Variational_Mean-Field_Theory_for_Sigmoidal_Belief_Networks.html">14 nips-2000-A Variational Mean-Field Theory for Sigmoidal Belief Networks</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2000_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.214), (1, -0.065), (2, 0.153), (3, -0.123), (4, 0.119), (5, -0.008), (6, 0.096), (7, -0.065), (8, 0.213), (9, 0.087), (10, 0.134), (11, -0.507), (12, 0.262), (13, -0.078), (14, 0.113), (15, 0.068), (16, 0.015), (17, -0.017), (18, -0.028), (19, -0.165), (20, -0.01), (21, 0.178), (22, 0.038), (23, 0.076), (24, -0.031), (25, 0.009), (26, -0.071), (27, -0.01), (28, -0.008), (29, -0.004), (30, -0.1), (31, -0.048), (32, -0.05), (33, 0.061), (34, 0.107), (35, -0.025), (36, 0.005), (37, -0.018), (38, -0.039), (39, 0.036), (40, -0.01), (41, -0.036), (42, 0.028), (43, 0.039), (44, 0.065), (45, 0.056), (46, -0.019), (47, 0.013), (48, -0.029), (49, 0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97533244 <a title="108-lsi-1" href="./nips-2000-Recognizing_Hand-written_Digits_Using_Hierarchical_Products_of_Experts.html">108 nips-2000-Recognizing Hand-written Digits Using Hierarchical Products of Experts</a></p>
<p>Author: Guy Mayraz, Geoffrey E. Hinton</p><p>Abstract: The product of experts learning procedure [1] can discover a set of stochastic binary features that constitute a non-linear generative model of handwritten images of digits. The quality of generative models learned in this way can be assessed by learning a separate model for each class of digit and then comparing the unnormalized probabilities of test images under the 10 different class-specific models. To improve discriminative performance, it is helpful to learn a hierarchy of separate models for each digit class. Each model in the hierarchy has one layer of hidden units and the nth level model is trained on data that consists of the activities of the hidden units in the already trained (n - l)th level model. After training, each level produces a separate, unnormalized log probabilty score. With a three-level hierarchy for each of the 10 digit classes, a test image produces 30 scores which can be used as inputs to a supervised, logistic classification network that is trained on separate data. On the MNIST database, our system is comparable with current state-of-the-art discriminative methods, demonstrating that the product of experts learning procedure can produce effective generative models of high-dimensional data. 1 Learning products of stochastic binary experts Hinton [1] describes a learning algorithm for probabilistic generative models that are composed of a number of experts. Each expert specifies a probability distribution over the visible variables and the experts are combined by multiplying these distributions together and renormalizing. (1) where d is a data vector in a discrete space, Om is all the parameters of individual model m, Pm(dIOm) is the probability of d under model m, and c is an index over all possible vectors in the data space. A Restricted Boltzmann machine [2, 3] is a special case of a product of experts in which each expert is a single, binary stochastic hidden unit that has symmetrical connections to a set of visible units, and connections between the hidden units are forbidden. Inference in an RBM is much easier than in a general Boltzmann machine and it is also much easier than in a causal belief net because there is no explaining away. There is therefore no need to perform any iteration to determine the activities of the hidden units. The hidden states, Sj , are conditionally independent given the visible states, Si, and the distribution of Sj is given by the standard logistic function : 1 p(Sj = 1) = (2) 1 + exp( - Li WijSi) Conversely, the hidden states of an RBM are marginally dependent so it is easy for an RBM to learn population codes in which units may be highly correlated. It is hard to do this in causal belief nets with one hidden layer because the generative model of a causal belief net assumes marginal independence. An RBM can be trained using the standard Boltzmann machine learning algorithm which follows a noisy but unbiased estimate of the gradient of the log likelihood of the data. One way to implement this algorithm is to start the network with a data vector on the visible units and then to alternate between updating all of the hidden units in parallel and updating all of the visible units in parallel. Each update picks a binary state for a unit from its posterior distribution given the current states of all the units in the other set. If this alternating Gibbs sampling is run to equilibrium, there is a very simple way to update the weights so as to minimize the Kullback-Leibler divergence, QOIIQoo, between the data distribution, QO, and the equilibrium distribution of fantasies over the visible units, Qoo, produced by the RBM [4]: flWij oc QO - Q~ (3) where < SiSj >Qo is the expected value of SiSj when data is clamped on the visible units and the hidden states are sampled from their conditional distribution given the data, and Q ~ is the expected value of SiSj after prolonged Gibbs sampling. This learning rule does not work well because it can take a long time to approach thermal equilibrium and the sampling noise in the estimate of  Q ~ can swamp the gradient. [1] shows that it is far more effective to minimize the difference between QOllQoo and Q111Qoo where Q1 is the distribution of the one-step reconstructions of the data that are produced by first picking binary hidden states from their conditional distribution given the data and then picking binary visible states from their conditional distribution given the hidden states. The exact gradient of this</p><p>2 0.84193891 <a title="108-lsi-2" href="./nips-2000-Rate-coded_Restricted_Boltzmann_Machines_for_Face_Recognition.html">107 nips-2000-Rate-coded Restricted Boltzmann Machines for Face Recognition</a></p>
<p>Author: Yee Whye Teh, Geoffrey E. Hinton</p><p>Abstract: We describe a neurally-inspired, unsupervised learning algorithm that builds a non-linear generative model for pairs of face images from the same individual. Individuals are then recognized by finding the highest relative probability pair among all pairs that consist of a test image and an image whose identity is known. Our method compares favorably with other methods in the literature. The generative model consists of a single layer of rate-coded, non-linear feature detectors and it has the property that, given a data vector, the true posterior probability distribution over the feature detector activities can be inferred rapidly without iteration or approximation. The weights of the feature detectors are learned by comparing the correlations of pixel intensities and feature activations in two phases: When the network is observing real data and when it is observing reconstructions of real data generated from the feature activations.</p><p>3 0.5409413 <a title="108-lsi-3" href="./nips-2000-Using_Free_Energies_to_Represent_Q-values_in_a_Multiagent_Reinforcement_Learning_Task.html">142 nips-2000-Using Free Energies to Represent Q-values in a Multiagent Reinforcement Learning Task</a></p>
<p>Author: Brian Sallans, Geoffrey E. Hinton</p><p>Abstract: The problem of reinforcement learning in large factored Markov decision processes is explored. The Q-value of a state-action pair is approximated by the free energy of a product of experts network. Network parameters are learned on-line using a modified SARSA algorithm which minimizes the inconsistency of the Q-values of consecutive state-action pairs. Actions are chosen based on the current value estimates by fixing the current state and sampling actions from the network using Gibbs sampling. The algorithm is tested on a co-operative multi-agent task. The product of experts model is found to perform comparably to table-based Q-Iearning for small instances of the task, and continues to perform well when the problem becomes too large for a table-based representation.</p><p>4 0.43633312 <a title="108-lsi-4" href="./nips-2000-Overfitting_in_Neural_Nets%3A_Backpropagation%2C_Conjugate_Gradient%2C_and_Early_Stopping.html">97 nips-2000-Overfitting in Neural Nets: Backpropagation, Conjugate Gradient, and Early Stopping</a></p>
<p>Author: Rich Caruana, Steve Lawrence, C. Lee Giles</p><p>Abstract: The conventional wisdom is that backprop nets with excess hidden units generalize poorly. We show that nets with excess capacity generalize well when trained with backprop and early stopping. Experiments suggest two reasons for this: 1) Overfitting can vary significantly in different regions of the model. Excess capacity allows better fit to regions of high non-linearity, and backprop often avoids overfitting the regions of low non-linearity. 2) Regardless of size, nets learn task subcomponents in similar sequence. Big nets pass through stages similar to those learned by smaller nets. Early stopping can stop training the large net when it generalizes comparably to a smaller net. We also show that conjugate gradient can yield worse generalization because it overfits regions of low non-linearity when learning to fit regions of high non-linearity.</p><p>5 0.4357703 <a title="108-lsi-5" href="./nips-2000-Discovering_Hidden_Variables%3A_A_Structure-Based_Approach.html">41 nips-2000-Discovering Hidden Variables: A Structure-Based Approach</a></p>
<p>Author: Gal Elidan, Noam Lotner, Nir Friedman, Daphne Koller</p><p>Abstract: A serious problem in learning probabilistic models is the presence of hidden variables. These variables are not observed, yet interact with several of the observed variables. As such, they induce seemingly complex dependencies among the latter. In recent years, much attention has been devoted to the development of algorithms for learning parameters, and in some cases structure, in the presence of hidden variables. In this paper, we address the related problem of detecting hidden variables that interact with the observed variables. This problem is of interest both for improving our understanding of the domain and as a preliminary step that guides the learning procedure towards promising models. A very natural approach is to search for</p><p>6 0.36872241 <a title="108-lsi-6" href="./nips-2000-Structure_Learning_in_Human_Causal_Induction.html">127 nips-2000-Structure Learning in Human Causal Induction</a></p>
<p>7 0.32617301 <a title="108-lsi-7" href="./nips-2000-Beyond_Maximum_Likelihood_and_Density_Estimation%3A_A_Sample-Based_Criterion_for_Unsupervised_Learning_of_Complex_Models.html">31 nips-2000-Beyond Maximum Likelihood and Density Estimation: A Sample-Based Criterion for Unsupervised Learning of Complex Models</a></p>
<p>8 0.30601853 <a title="108-lsi-8" href="./nips-2000-Propagation_Algorithms_for_Variational_Bayesian_Learning.html">106 nips-2000-Propagation Algorithms for Variational Bayesian Learning</a></p>
<p>9 0.2917909 <a title="108-lsi-9" href="./nips-2000-Partially_Observable_SDE_Models_for_Image_Sequence_Recognition_Tasks.html">98 nips-2000-Partially Observable SDE Models for Image Sequence Recognition Tasks</a></p>
<p>10 0.2826868 <a title="108-lsi-10" href="./nips-2000-High-temperature_Expansions_for_Learning_Models_of_Nonnegative_Data.html">64 nips-2000-High-temperature Expansions for Learning Models of Nonnegative Data</a></p>
<p>11 0.27088758 <a title="108-lsi-11" href="./nips-2000-Improved_Output_Coding_for_Classification_Using_Continuous_Relaxation.html">68 nips-2000-Improved Output Coding for Classification Using Continuous Relaxation</a></p>
<p>12 0.23606072 <a title="108-lsi-12" href="./nips-2000-A_Gradient-Based_Boosting_Algorithm_for_Regression_Problems.html">3 nips-2000-A Gradient-Based Boosting Algorithm for Regression Problems</a></p>
<p>13 0.23193021 <a title="108-lsi-13" href="./nips-2000-Stability_and_Noise_in_Biochemical_Switches.html">125 nips-2000-Stability and Noise in Biochemical Switches</a></p>
<p>14 0.22464092 <a title="108-lsi-14" href="./nips-2000-Position_Variance%2C_Recurrence_and_Perceptual_Learning.html">102 nips-2000-Position Variance, Recurrence and Perceptual Learning</a></p>
<p>15 0.22278374 <a title="108-lsi-15" href="./nips-2000-One_Microphone_Source_Separation.html">96 nips-2000-One Microphone Source Separation</a></p>
<p>16 0.22143756 <a title="108-lsi-16" href="./nips-2000-Accumulator_Networks%3A_Suitors_of_Local_Probability_Propagation.html">15 nips-2000-Accumulator Networks: Suitors of Local Probability Propagation</a></p>
<p>17 0.21428879 <a title="108-lsi-17" href="./nips-2000-Occam%27s_Razor.html">92 nips-2000-Occam's Razor</a></p>
<p>18 0.20576686 <a title="108-lsi-18" href="./nips-2000-Competition_and_Arbors_in_Ocular_Dominance.html">34 nips-2000-Competition and Arbors in Ocular Dominance</a></p>
<p>19 0.20357408 <a title="108-lsi-19" href="./nips-2000-Computing_with_Finite_and_Infinite_Networks.html">35 nips-2000-Computing with Finite and Infinite Networks</a></p>
<p>20 0.20223758 <a title="108-lsi-20" href="./nips-2000-Second_Order_Approximations_for_Probability_Models.html">114 nips-2000-Second Order Approximations for Probability Models</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2000_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.03), (17, 0.084), (33, 0.027), (36, 0.069), (38, 0.018), (52, 0.359), (55, 0.047), (62, 0.07), (65, 0.037), (67, 0.059), (75, 0.011), (76, 0.032), (90, 0.047)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.78482997 <a title="108-lda-1" href="./nips-2000-Recognizing_Hand-written_Digits_Using_Hierarchical_Products_of_Experts.html">108 nips-2000-Recognizing Hand-written Digits Using Hierarchical Products of Experts</a></p>
<p>Author: Guy Mayraz, Geoffrey E. Hinton</p><p>Abstract: The product of experts learning procedure [1] can discover a set of stochastic binary features that constitute a non-linear generative model of handwritten images of digits. The quality of generative models learned in this way can be assessed by learning a separate model for each class of digit and then comparing the unnormalized probabilities of test images under the 10 different class-specific models. To improve discriminative performance, it is helpful to learn a hierarchy of separate models for each digit class. Each model in the hierarchy has one layer of hidden units and the nth level model is trained on data that consists of the activities of the hidden units in the already trained (n - l)th level model. After training, each level produces a separate, unnormalized log probabilty score. With a three-level hierarchy for each of the 10 digit classes, a test image produces 30 scores which can be used as inputs to a supervised, logistic classification network that is trained on separate data. On the MNIST database, our system is comparable with current state-of-the-art discriminative methods, demonstrating that the product of experts learning procedure can produce effective generative models of high-dimensional data. 1 Learning products of stochastic binary experts Hinton [1] describes a learning algorithm for probabilistic generative models that are composed of a number of experts. Each expert specifies a probability distribution over the visible variables and the experts are combined by multiplying these distributions together and renormalizing. (1) where d is a data vector in a discrete space, Om is all the parameters of individual model m, Pm(dIOm) is the probability of d under model m, and c is an index over all possible vectors in the data space. A Restricted Boltzmann machine [2, 3] is a special case of a product of experts in which each expert is a single, binary stochastic hidden unit that has symmetrical connections to a set of visible units, and connections between the hidden units are forbidden. Inference in an RBM is much easier than in a general Boltzmann machine and it is also much easier than in a causal belief net because there is no explaining away. There is therefore no need to perform any iteration to determine the activities of the hidden units. The hidden states, Sj , are conditionally independent given the visible states, Si, and the distribution of Sj is given by the standard logistic function : 1 p(Sj = 1) = (2) 1 + exp( - Li WijSi) Conversely, the hidden states of an RBM are marginally dependent so it is easy for an RBM to learn population codes in which units may be highly correlated. It is hard to do this in causal belief nets with one hidden layer because the generative model of a causal belief net assumes marginal independence. An RBM can be trained using the standard Boltzmann machine learning algorithm which follows a noisy but unbiased estimate of the gradient of the log likelihood of the data. One way to implement this algorithm is to start the network with a data vector on the visible units and then to alternate between updating all of the hidden units in parallel and updating all of the visible units in parallel. Each update picks a binary state for a unit from its posterior distribution given the current states of all the units in the other set. If this alternating Gibbs sampling is run to equilibrium, there is a very simple way to update the weights so as to minimize the Kullback-Leibler divergence, QOIIQoo, between the data distribution, QO, and the equilibrium distribution of fantasies over the visible units, Qoo, produced by the RBM [4]: flWij oc QO - Q~ (3) where < SiSj >Qo is the expected value of SiSj when data is clamped on the visible units and the hidden states are sampled from their conditional distribution given the data, and Q ~ is the expected value of SiSj after prolonged Gibbs sampling. This learning rule does not work well because it can take a long time to approach thermal equilibrium and the sampling noise in the estimate of  Q ~ can swamp the gradient. [1] shows that it is far more effective to minimize the difference between QOllQoo and Q111Qoo where Q1 is the distribution of the one-step reconstructions of the data that are produced by first picking binary hidden states from their conditional distribution given the data and then picking binary visible states from their conditional distribution given the hidden states. The exact gradient of this</p><p>2 0.42355588 <a title="108-lda-2" href="./nips-2000-Rate-coded_Restricted_Boltzmann_Machines_for_Face_Recognition.html">107 nips-2000-Rate-coded Restricted Boltzmann Machines for Face Recognition</a></p>
<p>Author: Yee Whye Teh, Geoffrey E. Hinton</p><p>Abstract: We describe a neurally-inspired, unsupervised learning algorithm that builds a non-linear generative model for pairs of face images from the same individual. Individuals are then recognized by finding the highest relative probability pair among all pairs that consist of a test image and an image whose identity is known. Our method compares favorably with other methods in the literature. The generative model consists of a single layer of rate-coded, non-linear feature detectors and it has the property that, given a data vector, the true posterior probability distribution over the feature detector activities can be inferred rapidly without iteration or approximation. The weights of the feature detectors are learned by comparing the correlations of pixel intensities and feature activations in two phases: When the network is observing real data and when it is observing reconstructions of real data generated from the feature activations.</p><p>3 0.4051376 <a title="108-lda-3" href="./nips-2000-Using_Free_Energies_to_Represent_Q-values_in_a_Multiagent_Reinforcement_Learning_Task.html">142 nips-2000-Using Free Energies to Represent Q-values in a Multiagent Reinforcement Learning Task</a></p>
<p>Author: Brian Sallans, Geoffrey E. Hinton</p><p>Abstract: The problem of reinforcement learning in large factored Markov decision processes is explored. The Q-value of a state-action pair is approximated by the free energy of a product of experts network. Network parameters are learned on-line using a modified SARSA algorithm which minimizes the inconsistency of the Q-values of consecutive state-action pairs. Actions are chosen based on the current value estimates by fixing the current state and sampling actions from the network using Gibbs sampling. The algorithm is tested on a co-operative multi-agent task. The product of experts model is found to perform comparably to table-based Q-Iearning for small instances of the task, and continues to perform well when the problem becomes too large for a table-based representation.</p><p>4 0.36959267 <a title="108-lda-4" href="./nips-2000-A_Tighter_Bound_for_Graphical_Models.html">13 nips-2000-A Tighter Bound for Graphical Models</a></p>
<p>Author: Martijn A. R. Leisink, Hilbert J. Kappen</p><p>Abstract: We present a method to bound the partition function of a Boltzmann machine neural network with any odd order polynomial. This is a direct extension of the mean field bound, which is first order. We show that the third order bound is strictly better than mean field. Additionally we show the rough outline how this bound is applicable to sigmoid belief networks. Numerical experiments indicate that an error reduction of a factor two is easily reached in the region where expansion based approximations are useful. 1</p><p>5 0.34144056 <a title="108-lda-5" href="./nips-2000-Incorporating_Second-Order_Functional_Knowledge_for_Better_Option_Pricing.html">69 nips-2000-Incorporating Second-Order Functional Knowledge for Better Option Pricing</a></p>
<p>Author: Charles Dugas, Yoshua Bengio, François Bélisle, Claude Nadeau, René Garcia</p><p>Abstract: Incorporating prior knowledge of a particular task into the architecture of a learning algorithm can greatly improve generalization performance. We study here a case where we know that the function to be learned is non-decreasing in two of its arguments and convex in one of them. For this purpose we propose a class of functions similar to multi-layer neural networks but (1) that has those properties, (2) is a universal approximator of continuous functions with these and other properties. We apply this new class of functions to the task of modeling the price of call options. Experiments show improvements on regressing the price of call options using the new types of function classes that incorporate the a priori constraints.</p><p>6 0.33857164 <a title="108-lda-6" href="./nips-2000-Partially_Observable_SDE_Models_for_Image_Sequence_Recognition_Tasks.html">98 nips-2000-Partially Observable SDE Models for Image Sequence Recognition Tasks</a></p>
<p>7 0.33787093 <a title="108-lda-7" href="./nips-2000-Occam%27s_Razor.html">92 nips-2000-Occam's Razor</a></p>
<p>8 0.33590108 <a title="108-lda-8" href="./nips-2000-Propagation_Algorithms_for_Variational_Bayesian_Learning.html">106 nips-2000-Propagation Algorithms for Variational Bayesian Learning</a></p>
<p>9 0.33497375 <a title="108-lda-9" href="./nips-2000-Kernel_Expansions_with_Unlabeled_Examples.html">74 nips-2000-Kernel Expansions with Unlabeled Examples</a></p>
<p>10 0.33401191 <a title="108-lda-10" href="./nips-2000-Automated_State_Abstraction_for_Options_using_the_U-Tree_Algorithm.html">26 nips-2000-Automated State Abstraction for Options using the U-Tree Algorithm</a></p>
<p>11 0.33250448 <a title="108-lda-11" href="./nips-2000-A_Productive%2C_Systematic_Framework_for_the_Representation_of_Visual_Structure.html">10 nips-2000-A Productive, Systematic Framework for the Representation of Visual Structure</a></p>
<p>12 0.3308295 <a title="108-lda-12" href="./nips-2000-Regularized_Winnow_Methods.html">111 nips-2000-Regularized Winnow Methods</a></p>
<p>13 0.32982442 <a title="108-lda-13" href="./nips-2000-Learning_Segmentation_by_Random_Walks.html">79 nips-2000-Learning Segmentation by Random Walks</a></p>
<p>14 0.32885709 <a title="108-lda-14" href="./nips-2000-A_New_Approximate_Maximal_Margin_Classification_Algorithm.html">7 nips-2000-A New Approximate Maximal Margin Classification Algorithm</a></p>
<p>15 0.32839602 <a title="108-lda-15" href="./nips-2000-Algorithms_for_Non-negative_Matrix_Factorization.html">22 nips-2000-Algorithms for Non-negative Matrix Factorization</a></p>
<p>16 0.32551825 <a title="108-lda-16" href="./nips-2000-Processing_of_Time_Series_by_Neural_Circuits_with_Biologically_Realistic_Synaptic_Dynamics.html">104 nips-2000-Processing of Time Series by Neural Circuits with Biologically Realistic Synaptic Dynamics</a></p>
<p>17 0.32426775 <a title="108-lda-17" href="./nips-2000-Balancing_Multiple_Sources_of_Reward_in_Reinforcement_Learning.html">28 nips-2000-Balancing Multiple Sources of Reward in Reinforcement Learning</a></p>
<p>18 0.32312036 <a title="108-lda-18" href="./nips-2000-A_Linear_Programming_Approach_to_Novelty_Detection.html">4 nips-2000-A Linear Programming Approach to Novelty Detection</a></p>
<p>19 0.32217056 <a title="108-lda-19" href="./nips-2000-Fast_Training_of_Support_Vector_Classifiers.html">52 nips-2000-Fast Training of Support Vector Classifiers</a></p>
<p>20 0.32207525 <a title="108-lda-20" href="./nips-2000-Learning_Switching_Linear_Models_of_Human_Motion.html">80 nips-2000-Learning Switching Linear Models of Human Motion</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
