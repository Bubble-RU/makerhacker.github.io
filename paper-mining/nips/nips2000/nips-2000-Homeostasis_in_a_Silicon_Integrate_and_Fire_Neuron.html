<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>67 nips-2000-Homeostasis in a Silicon Integrate and Fire Neuron</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2000" href="../home/nips2000_home.html">nips2000</a> <a title="nips-2000-67" href="#">nips2000-67</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>67 nips-2000-Homeostasis in a Silicon Integrate and Fire Neuron</h1>
<br/><p>Source: <a title="nips-2000-67-pdf" href="http://papers.nips.cc/paper/1923-homeostasis-in-a-silicon-integrate-and-fire-neuron.pdf">pdf</a></p><p>Author: Shih-Chii Liu, Bradley A. Minch</p><p>Abstract: In this work, we explore homeostasis in a silicon integrate-and-fire neuron. The neuron adapts its firing rate over long time periods on the order of seconds or minutes so that it returns to its spontaneous firing rate after a lasting perturbation. Homeostasis is implemented via two schemes. One scheme looks at the presynaptic activity and adapts the synaptic weight depending on the presynaptic spiking rate. The second scheme adapts the synaptic</p><p>Reference: <a title="nips-2000-67-reference" href="../nips2000_reference/nips-2000-Homeostasis_in_a_Silicon_Integrate_and_Fire_Neuron_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract In this work, we explore homeostasis in a silicon integrate-and-fire neuron. [sent-10, score-0.221]
</p><p>2 The neuron adapts its firing rate over long time periods on the order of seconds or minutes so that it returns to its spontaneous firing rate after a lasting perturbation. [sent-11, score-1.16]
</p><p>3 One scheme looks at the presynaptic activity and adapts the synaptic weight depending on the presynaptic spiking rate. [sent-13, score-1.186]
</p><p>4 The second scheme adapts the synaptic "threshold" depending on the neuron's activity. [sent-14, score-0.176]
</p><p>5 The threshold is lowered if the neuron's activity decreases over a long time and is increased for prolonged increase in postsynaptic activity. [sent-15, score-0.447]
</p><p>6 The results shown here are measured from a chip fabricated in a 2-J. [sent-17, score-0.039]
</p><p>7 1 Introduction We explored long-time constant adaptation mechanisms in a simple integrate-and-fire silicon neuron. [sent-19, score-0.597]
</p><p>8 Many researchers have postulated constant adaptation mechanisms which, for example, preserve the firing rate of the neuron over long time invervals (Liu et al. [sent-20, score-1.184]
</p><p>9 1998) or use the presynaptic spiking statistics to adapt the spiking rate of the neuron so that the distribution of this spiking rate is uniformly distributed (Stemmler and Koch 1999). [sent-21, score-1.947]
</p><p>10 1999) where if the K or Na conductances are perturbed by adding antagonists, the cell returns to its original spiking rate in a couple of days. [sent-23, score-0.571]
</p><p>11 This work differs from previous work that explore the adaptation of the firing threshold and the gain of the neuron through the regulation of Hodgkin-Huxley like conductances (Shin and Koch 1999) and regulation of the neuron to perturbation in the conductances (Simoni and DeWeerth 1999). [sent-24, score-1.566]
</p><p>12 Our neuron circuit is a simple integrate-and-fire neuron and  lepse  Spike  Vm Irefr  Vrl  JUL  VOl -:-  output, Vo  >---'---  -:-  - - - -. [sent-25, score-0.947]
</p><p>13 I  C2  Pbase  /~/ v,IV)::ectm :  lepse  -=-j  :  \ \  I I \  I  -. [sent-27, score-0.05]
</p><p>14 _/ "",  Figure 1: Schematic of neuron circuit with long time constant mechanisms for presynaptic adaptation. [sent-33, score-1.141]
</p><p>15 our adaptation mechanisms have time constants of seconds to minutes. [sent-34, score-0.513]
</p><p>16 We also describe adaptation of the synaptic weight to presynaptic spiking rates. [sent-35, score-0.993]
</p><p>17 This presynaptic adaptation models the contrast gain control curves of cortical simple cells (Ohzawa et al. [sent-36, score-0.735]
</p><p>18 We fabricated two different circuits in a 2-pm CMOS process. [sent-38, score-0.039]
</p><p>19 One circuit implements presynaptic adaptation and the other circuit implements postsynaptic adaptation. [sent-39, score-1.011]
</p><p>20 The long time constant adaptation mechanisms use tunnelling and injection mechanisms to remove charge from and to add charge onto a floating gate (Diorio et al. [sent-40, score-1.267]
</p><p>21 We added these mechanisms to a simple integrate-and-fire neuron circuit (Mead 1989). [sent-42, score-0.692]
</p><p>22 This circuit (shown in Figure 1) takes an input current, lepsc, which charges up the membrane, V m . [sent-43, score-0.212]
</p><p>23 When the membrane exceeds a threshold, the output of the neuron, Vo , spikes. [sent-44, score-0.079]
</p><p>24 The spiking rate of the neuron, fo is determined by the input current, lepsc , that is, fo = m lepsc where 1 . [sent-45, score-0.761]
</p><p>25 2 Adaptation mechanisms in silicon neuron circuit In order to permit continuous operation with only positive polarity bias voltages, we use two distinct mechanisms to modify the floating-gate charges in our neuron circuits. [sent-47, score-1.463]
</p><p>26 We use Fowler-Nordheim tunneling through high-quality gate oxide to remove electrons from the floating gates (Lenzlinger and Snow 1969). [sent-48, score-0.535]
</p><p>27 Here, we apply a large voltage across the oxide, which reduces the width of the Si-Si0 2 energy barrier to such an extent that electrons are likely to tunnel through the barrier. [sent-49, score-0.417]
</p><p>28 The tunneling current is given approximately by -/'o I tun- t e- vo/voz , where Vox = V'tun - Vfg is the voltage across the tunneling oxide and lot and Vo are measurable device parameters. [sent-50, score-0.665]
</p><p>29 For the 400-A oxides that are typical of a 2-l-ć&lsaquo;˘m CMOS process, a typical value of Vo is 1000 V and an oxide voltage of about 30 V is required to obtain an appreciable tunneling current. [sent-51, score-0.491]
</p><p>30 We use subthreshold channel hot-electron injection in an nMOS transistor (Diorio, Minch, and Hasler 1999) to add electrons to the floating gates. [sent-52, score-0.605]
</p><p>31 In this process, electrons in the channel of the nMOS transistor accelerate in the high electric field that exists in the depletion region near the drain, gaining enough energy to surmount the Si-Si0 2 energy barrier  (about 3. [sent-53, score-0.325]
</p><p>32 To facilitate the hot-electron injection process, we locally increase the substrate doping density of the nMOS transistor using the p-base layer that is normally used to form the base of a vertical npn bipolar transistor. [sent-55, score-0.368]
</p><p>33 The p-base substrate implant simultaneously increases the electric field at the drain end of the channel and increases the nMOS transistor's threshold voltage from 0. [sent-56, score-0.615]
</p><p>34 8 V to about 6 V, permitting subthreshold operation at gate voltages that permit the collection of the injected electrons by the floating gate. [sent-57, score-0.414]
</p><p>35 The hot-electron injection current is given approximately by 1- . [sent-58, score-0.21]
</p><p>36 40 20 50  100  150  200  250  300  350  Presynaptic frequency (Hz) Figure 2: Adaptation curves of synaptic efficacy to presynaptic frequencies using long time constant adaptation mechanisms. [sent-80, score-0.904]
</p><p>37 3  Experimental results  We measured the transient and steady-state spiking rates of the neuron around four different steady-state presynaptic rates of 100Hz, 150Hz, 200Hz, and 250Hz. [sent-83, score-1.14]
</p><p>38 In these measurements, the drain of the pbase injection transistor was set at 4V and the tunnelling voltage was set at 35. [sent-84, score-0.822]
</p><p>39 For each steady-state presynaptic rate, we presented step increases and decreases in the presynaptic rate of 15Hz, 30Hz, 45Hz, and 60Hz. [sent-86, score-0.905]
</p><p>40 The instantaneous postsynaptic rate is plotted along one the four steep curves in Figure 2. [sent-87, score-0.286]
</p><p>41 After every change in the presynaptic rate, we returned the presynaptic rate to its steady-state value before we presented the next change in presynaptic rate. [sent-88, score-1.224]
</p><p>42 The transient gain of the curves decreases for higher input spiking rates. [sent-89, score-0.626]
</p><p>43 We also recorded the dynamics of the adaptation mechanisms by measuring the spiking rate of the neuron when the presynaptic frequency was decreased at time (t=O) from 350 Hz to 300 Hz as shown in Figure 3. [sent-91, score-1.663]
</p><p>44 The system adapts over a time constant of minutes back to the initial output frequency. [sent-92, score-0.251]
</p><p>45 These data show that the synaptic efficacy adapted to a higher weight value over time. [sent-93, score-0.12]
</p><p>46 The time constant of adaptation can be increased by either increasing the tunnelling voltage or the pbase injector's drain voltage, Vd. [sent-94, score-0.903]
</p><p>47 ::l  &  ,rn  ~ITnr  ~  20  ::l  0  10 00  100  200  300  400  500  600  700  800  900  Time (sec) Figure 3: Temporal adaptation of spiking rate of neuron to a decrease in the presynaptic frequency from 350Hz to 300Hz. [sent-101, score-1.479]
</p><p>48 4 Postsynaptic adaptation In the second mechanism, the neuron's spiking rate determines the synaptic "threshold". [sent-103, score-0.79]
</p><p>49 The schematic of this adaptation circuitry is shown in Figure 4. [sent-104, score-0.346]
</p><p>50 The floating-gate pbase transistor provides a quiescent input to the neuron so that the neuron fires at a quiescent rate. [sent-105, score-1.124]
</p><p>51 The tunneling mechanism is always turned on so the neuron's spiking rate increases in time if the neuron does not spike. [sent-106, score-1.102]
</p><p>52 However the injection mechanism turns on when the neuron spikes. [sent-107, score-0.612]
</p><p>53 The time constant of these mechanisms is in terms of seconds to minutes. [sent-108, score-0.308]
</p><p>54 The increase in the floating-gate voltage is equivalent to a decrease in the synaptic threshold. [sent-109, score-0.442]
</p><p>55 If the neuron's activity is high, the injection mechanism turns on thus decreasing the floatinggate voltage and the input current to the neuron. [sent-110, score-0.611]
</p><p>56 These two opposing mechanisms ensure that the cell will remain at a constant activity under steady-state conditions. [sent-111, score-0.265]
</p><p>57 In other words, the threshold of the neuron is modulated by its output spiking rate. [sent-112, score-0.816]
</p><p>58 The threshold of the neuron continuously decreases and each output spike increases the threshold. [sent-113, score-0.637]
</p><p>59 1 can be used to solve for V/ gD , thus leading us to the following expression for the steady-state input current, linD: kV/ gO  linD = lopbe----rJ'T = Im/(foT/j)"Y where 1m is a preconstant and 'Y is close to 1. [sent-116, score-0.035]
</p><p>60 2  Transient analysis  When a positive step voltage is applied to v;,,,,, the step change, floating gate. [sent-118, score-0.458]
</p><p>61 The initial transient current is :  ~V,  is coupled into the  ! [sent-119, score-0.182]
</p><p>62 111 /--  Membrane voltage, Vm  I  Adaptation I circuitry ~ \  -l V -lI tun  . [sent-124, score-0.036]
</p><p>63 I  ~~_________-_čˇŻ_____ V~f9~__________~// \\ Figure 4: Schematic of neuron circuit with long time constant mechanisms for postsynaptic adaptation. [sent-130, score-0.937]
</p><p>64 and the initial increase in the postsynaptic firing rate is k~V  fo  + dfo = foe""fYT. [sent-131, score-0.566]
</p><p>65 If we assume that the step input, Vin = 10g(li) (where fi is the firing rate of the presynaptic neuron), then the change in the floating-gate voltage is described by ~ V = dfd Ii- We then solve for dfo,  dfo k~V = e UT fo  -  -  k dfi 1 ~ --. [sent-132, score-1.154]
</p><p>66 Ur Ii  (5)  Equation 5 shows that the transient change in the neuron's spiking rate is proportional to the input contrast in the firing rate. [sent-133, score-0.775]
</p><p>67 With time, the floating-gate voltage adapts back to the steady-state condition, so the spiking rate returns to fo. [sent-134, score-0.835]
</p><p>68 3  Experimental results  In these experiments, we set the tunneling voltage, vtun to 28V, and the injection voltage to 6. [sent-136, score-0.586]
</p><p>69 2V into the floating-gate voltage and then measured the output frequency of the neuron over a period of 10 minutes. [sent-138, score-0.731]
</p><p>70 The output of this experiment is shown in Figure 5. [sent-139, score-0.033]
</p><p>71 The frequency dropped from about 19Hz to 13Hz but the circuit adapted after this initial perturbation and the spiking rate of the neuron returned to about 19Hz over 26min. [sent-140, score-1.084]
</p><p>72 A similar experiment is performed but this time a step increase of O. [sent-141, score-0.11]
</p><p>73 2V was coupled into the floating gate node (shown in Figure 5). [sent-142, score-0.221]
</p><p>74 Initially, the neuron's rate increased from 20Hz to 28Hz but over a long period of minutes, the firing rate returned to 20Hz. [sent-143, score-0.494]
</p><p>75 5 Conclusion In this work, we show how long-time constant adaptation mechanisms can be added to a silicon integrate-and-fire neuron in a normal CMOS process. [sent-144, score-0.982]
</p><p>76 These homeostatic mechanisms can be combined with short time constant synaptic depressing synapses on the same neuron to provide a range of adapting mechanisms. [sent-145, score-0.746]
</p><p>77 The presynaptic adaptation mechanism can also account for the contrast gain curves of cortical simple cells. [sent-146, score-0.788]
</p><p>78 &  =s 0  200  400  600  800  1000  1200  1400  1600  Time (sec) Figure 5: Response of silicon neuron to an increase and a decrease of a step input of 0. [sent-157, score-0.646]
</p><p>79 The curve shows that the adaptation time constant is in the order of about 10 min. [sent-159, score-0.337]
</p><p>80 Plasticity in the intrinsic excitability of cortical pyramidal neurons. [sent-168, score-0.033]
</p><p>81 A model neuron with activitydependent conductances regulated by multiple calcium sensors. [sent-188, score-0.476]
</p><p>82 Dynamic range and sensitivity adaptation in a silicon spiking neuron. [sent-204, score-0.694]
</p><p>83 How voltage-dependent conductances can adapt to maximize the information encoded by neuronal firing rate. [sent-215, score-0.24]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('neuron', 0.385), ('presynaptic', 0.324), ('spiking', 0.323), ('voltage', 0.274), ('adaptation', 0.251), ('mechanisms', 0.18), ('injection', 0.174), ('tunneling', 0.138), ('circuit', 0.127), ('firing', 0.122), ('rate', 0.121), ('silicon', 0.12), ('postsynaptic', 0.12), ('floating', 0.118), ('transistor', 0.118), ('electrons', 0.109), ('transient', 0.108), ('dfo', 0.101), ('homeostasis', 0.101), ('minch', 0.101), ('nmos', 0.101), ('pbase', 0.101), ('synaptic', 0.095), ('conductances', 0.091), ('adapts', 0.081), ('cmos', 0.079), ('drain', 0.079), ('oxide', 0.079), ('dfd', 0.076), ('lepsc', 0.076), ('tunnelling', 0.076), ('threshold', 0.075), ('vo', 0.068), ('diorio', 0.065), ('gate', 0.065), ('fo', 0.065), ('decreases', 0.061), ('schematic', 0.059), ('koch', 0.059), ('returned', 0.055), ('gain', 0.054), ('mechanism', 0.053), ('minutes', 0.051), ('charges', 0.05), ('desai', 0.05), ('deweerth', 0.05), ('lepse', 0.05), ('lind', 0.05), ('ohzawa', 0.05), ('quiescent', 0.05), ('simoni', 0.05), ('stemmler', 0.05), ('subthreshold', 0.05), ('constant', 0.046), ('membrane', 0.046), ('curves', 0.045), ('hasler', 0.043), ('lenzlinger', 0.043), ('neuro', 0.043), ('shin', 0.043), ('seconds', 0.042), ('increases', 0.042), ('spike', 0.041), ('time', 0.04), ('activity', 0.039), ('hz', 0.039), ('fabricated', 0.039), ('mead', 0.039), ('substrate', 0.039), ('liu', 0.039), ('regulation', 0.039), ('frequency', 0.039), ('long', 0.039), ('change', 0.038), ('coupled', 0.038), ('increase', 0.037), ('charge', 0.036), ('circuitry', 0.036), ('voltages', 0.036), ('vm', 0.036), ('permit', 0.036), ('decrease', 0.036), ('current', 0.036), ('increased', 0.036), ('returns', 0.036), ('channel', 0.036), ('input', 0.035), ('barrier', 0.034), ('snow', 0.034), ('perturbation', 0.034), ('step', 0.033), ('output', 0.033), ('cortical', 0.033), ('sec', 0.032), ('implements', 0.031), ('contrast', 0.028), ('electric', 0.028), ('adapt', 0.027), ('remove', 0.026), ('efficacy', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999997 <a title="67-tfidf-1" href="./nips-2000-Homeostasis_in_a_Silicon_Integrate_and_Fire_Neuron.html">67 nips-2000-Homeostasis in a Silicon Integrate and Fire Neuron</a></p>
<p>Author: Shih-Chii Liu, Bradley A. Minch</p><p>Abstract: In this work, we explore homeostasis in a silicon integrate-and-fire neuron. The neuron adapts its firing rate over long time periods on the order of seconds or minutes so that it returns to its spontaneous firing rate after a lasting perturbation. Homeostasis is implemented via two schemes. One scheme looks at the presynaptic activity and adapts the synaptic weight depending on the presynaptic spiking rate. The second scheme adapts the synaptic</p><p>2 0.310774 <a title="67-tfidf-2" href="./nips-2000-A_Silicon_Primitive_for_Competitive_Learning.html">11 nips-2000-A Silicon Primitive for Competitive Learning</a></p>
<p>Author: David Hsu, Miguel Figueroa, Chris Diorio</p><p>Abstract: Competitive learning is a technique for training classification and clustering networks. We have designed and fabricated an 11transistor primitive, that we term an automaximizing bump circuit, that implements competitive learning dynamics. The circuit performs a similarity computation, affords nonvolatile storage, and implements simultaneous local adaptation and computation. We show that our primitive is suitable for implementing competitive learning in VLSI, and demonstrate its effectiveness in a standard clustering task.</p><p>3 0.18061791 <a title="67-tfidf-3" href="./nips-2000-Temporally_Dependent_Plasticity%3A_An_Information_Theoretic_Account.html">129 nips-2000-Temporally Dependent Plasticity: An Information Theoretic Account</a></p>
<p>Author: Gal Chechik, Naftali Tishby</p><p>Abstract: The paradigm of Hebbian learning has recently received a novel interpretation with the discovery of synaptic plasticity that depends on the relative timing of pre and post synaptic spikes. This paper derives a temporally dependent learning rule from the basic principle of mutual information maximization and studies its relation to the experimentally observed plasticity. We find that a supervised spike-dependent learning rule sharing similar structure with the experimentally observed plasticity increases mutual information to a stable near optimal level. Moreover, the analysis reveals how the temporal structure of time-dependent learning rules is determined by the temporal filter applied by neurons over their inputs. These results suggest experimental prediction as to the dependency of the learning rule on neuronal biophysical parameters 1</p><p>4 0.16345438 <a title="67-tfidf-4" href="./nips-2000-Multiple_Timescales_of_Adaptation_in_a_Neural_Code.html">88 nips-2000-Multiple Timescales of Adaptation in a Neural Code</a></p>
<p>Author: Adrienne L. Fairhall, Geoffrey D. Lewen, William Bialek, Robert R. de Ruyter van Steveninck</p><p>Abstract: Many neural systems extend their dynamic range by adaptation. We examine the timescales of adaptation in the context of dynamically modulated rapidly-varying stimuli, and demonstrate in the fly visual system that adaptation to the statistical ensemble of the stimulus dynamically maximizes information transmission about the time-dependent stimulus. Further, while the rate response has long transients, the adaptation takes place on timescales consistent with optimal variance estimation.</p><p>5 0.16259634 <a title="67-tfidf-5" href="./nips-2000-What_Can_a_Single_Neuron_Compute%3F.html">146 nips-2000-What Can a Single Neuron Compute?</a></p>
<p>Author: Blaise Agüera y Arcas, Adrienne L. Fairhall, William Bialek</p><p>Abstract: In this paper we formulate a description of the computation performed by a neuron as a combination of dimensional reduction and nonlinearity. We implement this description for the HodgkinHuxley model, identify the most relevant dimensions and find the nonlinearity. A two dimensional description already captures a significant fraction of the information that spikes carry about dynamic inputs. This description also shows that computation in the Hodgkin-Huxley model is more complex than a simple integrateand-fire or perceptron model. 1</p><p>6 0.13865624 <a title="67-tfidf-6" href="./nips-2000-Finding_the_Key_to_a_Synapse.html">55 nips-2000-Finding the Key to a Synapse</a></p>
<p>7 0.11259821 <a title="67-tfidf-7" href="./nips-2000-Who_Does_What%3F_A_Novel_Algorithm_to_Determine_Function_Localization.html">147 nips-2000-Who Does What? A Novel Algorithm to Determine Function Localization</a></p>
<p>8 0.10958463 <a title="67-tfidf-8" href="./nips-2000-Processing_of_Time_Series_by_Neural_Circuits_with_Biologically_Realistic_Synaptic_Dynamics.html">104 nips-2000-Processing of Time Series by Neural Circuits with Biologically Realistic Synaptic Dynamics</a></p>
<p>9 0.085548341 <a title="67-tfidf-9" href="./nips-2000-Four-legged_Walking_Gait_Control_Using_a_Neuromorphic_Chip_Interfaced_to_a_Support_Vector_Learning_Algorithm.html">57 nips-2000-Four-legged Walking Gait Control Using a Neuromorphic Chip Interfaced to a Support Vector Learning Algorithm</a></p>
<p>10 0.084591456 <a title="67-tfidf-10" href="./nips-2000-Divisive_and_Subtractive_Mask_Effects%3A_Linking_Psychophysics_and_Biophysics.html">42 nips-2000-Divisive and Subtractive Mask Effects: Linking Psychophysics and Biophysics</a></p>
<p>11 0.074952535 <a title="67-tfidf-11" href="./nips-2000-Spike-Timing-Dependent_Learning_for_Oscillatory_Networks.html">124 nips-2000-Spike-Timing-Dependent Learning for Oscillatory Networks</a></p>
<p>12 0.070109874 <a title="67-tfidf-12" href="./nips-2000-Foundations_for_a_Circuit_Complexity_Theory_of_Sensory_Processing.html">56 nips-2000-Foundations for a Circuit Complexity Theory of Sensory Processing</a></p>
<p>13 0.068256967 <a title="67-tfidf-13" href="./nips-2000-Dendritic_Compartmentalization_Could_Underlie_Competition_and_Attentional_Biasing_of_Simultaneous_Visual_Stimuli.html">40 nips-2000-Dendritic Compartmentalization Could Underlie Competition and Attentional Biasing of Simultaneous Visual Stimuli</a></p>
<p>14 0.053807676 <a title="67-tfidf-14" href="./nips-2000-Universality_and_Individuality_in_a_Neural_Code.html">141 nips-2000-Universality and Individuality in a Neural Code</a></p>
<p>15 0.045147732 <a title="67-tfidf-15" href="./nips-2000-Permitted_and_Forbidden_Sets_in_Symmetric_Threshold-Linear_Networks.html">100 nips-2000-Permitted and Forbidden Sets in Symmetric Threshold-Linear Networks</a></p>
<p>16 0.044590242 <a title="67-tfidf-16" href="./nips-2000-Learning_Winner-take-all_Competition_Between_Groups_of_Neurons_in_Lateral_Inhibitory_Networks.html">81 nips-2000-Learning Winner-take-all Competition Between Groups of Neurons in Lateral Inhibitory Networks</a></p>
<p>17 0.038226381 <a title="67-tfidf-17" href="./nips-2000-Place_Cells_and_Spatial_Navigation_Based_on_2D_Visual_Feature_Extraction%2C_Path_Integration%2C_and_Reinforcement_Learning.html">101 nips-2000-Place Cells and Spatial Navigation Based on 2D Visual Feature Extraction, Path Integration, and Reinforcement Learning</a></p>
<p>18 0.037093528 <a title="67-tfidf-18" href="./nips-2000-Combining_ICA_and_Top-Down_Attention_for_Robust_Speech_Recognition.html">33 nips-2000-Combining ICA and Top-Down Attention for Robust Speech Recognition</a></p>
<p>19 0.03678621 <a title="67-tfidf-19" href="./nips-2000-Smart_Vision_Chip_Fabricated_Using_Three_Dimensional_Integration_Technology.html">118 nips-2000-Smart Vision Chip Fabricated Using Three Dimensional Integration Technology</a></p>
<p>20 0.034619212 <a title="67-tfidf-20" href="./nips-2000-Periodic_Component_Analysis%3A_An_Eigenvalue_Method_for_Representing_Periodic_Structure_in_Speech.html">99 nips-2000-Periodic Component Analysis: An Eigenvalue Method for Representing Periodic Structure in Speech</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2000_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.129), (1, -0.21), (2, -0.3), (3, -0.043), (4, 0.046), (5, -0.051), (6, -0.055), (7, 0.148), (8, -0.068), (9, 0.121), (10, -0.037), (11, -0.002), (12, -0.046), (13, -0.423), (14, -0.128), (15, 0.063), (16, 0.005), (17, -0.047), (18, -0.021), (19, -0.006), (20, 0.068), (21, 0.046), (22, 0.085), (23, 0.043), (24, 0.069), (25, 0.104), (26, 0.007), (27, 0.016), (28, 0.042), (29, -0.007), (30, -0.054), (31, 0.081), (32, -0.168), (33, 0.082), (34, -0.054), (35, 0.067), (36, -0.015), (37, 0.056), (38, -0.007), (39, 0.055), (40, -0.092), (41, -0.011), (42, 0.197), (43, -0.08), (44, -0.159), (45, -0.085), (46, -0.018), (47, 0.058), (48, -0.063), (49, 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98825246 <a title="67-lsi-1" href="./nips-2000-Homeostasis_in_a_Silicon_Integrate_and_Fire_Neuron.html">67 nips-2000-Homeostasis in a Silicon Integrate and Fire Neuron</a></p>
<p>Author: Shih-Chii Liu, Bradley A. Minch</p><p>Abstract: In this work, we explore homeostasis in a silicon integrate-and-fire neuron. The neuron adapts its firing rate over long time periods on the order of seconds or minutes so that it returns to its spontaneous firing rate after a lasting perturbation. Homeostasis is implemented via two schemes. One scheme looks at the presynaptic activity and adapts the synaptic weight depending on the presynaptic spiking rate. The second scheme adapts the synaptic</p><p>2 0.8801719 <a title="67-lsi-2" href="./nips-2000-A_Silicon_Primitive_for_Competitive_Learning.html">11 nips-2000-A Silicon Primitive for Competitive Learning</a></p>
<p>Author: David Hsu, Miguel Figueroa, Chris Diorio</p><p>Abstract: Competitive learning is a technique for training classification and clustering networks. We have designed and fabricated an 11transistor primitive, that we term an automaximizing bump circuit, that implements competitive learning dynamics. The circuit performs a similarity computation, affords nonvolatile storage, and implements simultaneous local adaptation and computation. We show that our primitive is suitable for implementing competitive learning in VLSI, and demonstrate its effectiveness in a standard clustering task.</p><p>3 0.40147713 <a title="67-lsi-3" href="./nips-2000-Temporally_Dependent_Plasticity%3A_An_Information_Theoretic_Account.html">129 nips-2000-Temporally Dependent Plasticity: An Information Theoretic Account</a></p>
<p>Author: Gal Chechik, Naftali Tishby</p><p>Abstract: The paradigm of Hebbian learning has recently received a novel interpretation with the discovery of synaptic plasticity that depends on the relative timing of pre and post synaptic spikes. This paper derives a temporally dependent learning rule from the basic principle of mutual information maximization and studies its relation to the experimentally observed plasticity. We find that a supervised spike-dependent learning rule sharing similar structure with the experimentally observed plasticity increases mutual information to a stable near optimal level. Moreover, the analysis reveals how the temporal structure of time-dependent learning rules is determined by the temporal filter applied by neurons over their inputs. These results suggest experimental prediction as to the dependency of the learning rule on neuronal biophysical parameters 1</p><p>4 0.38668779 <a title="67-lsi-4" href="./nips-2000-Who_Does_What%3F_A_Novel_Algorithm_to_Determine_Function_Localization.html">147 nips-2000-Who Does What? A Novel Algorithm to Determine Function Localization</a></p>
<p>Author: Ranit Aharonov-Barki, Isaac Meilijson, Eytan Ruppin</p><p>Abstract: We introduce a novel algorithm, termed PPA (Performance Prediction Algorithm), that quantitatively measures the contributions of elements of a neural system to the tasks it performs. The algorithm identifies the neurons or areas which participate in a cognitive or behavioral task, given data about performance decrease in a small set of lesions. It also allows the accurate prediction of performances due to multi-element lesions. The effectiveness of the new algorithm is demonstrated in two models of recurrent neural networks with complex interactions among the elements. The algorithm is scalable and applicable to the analysis of large neural networks. Given the recent advances in reversible inactivation techniques, it has the potential to significantly contribute to the understanding of the organization of biological nervous systems, and to shed light on the long-lasting debate about local versus distributed computation in the brain.</p><p>5 0.38499117 <a title="67-lsi-5" href="./nips-2000-Four-legged_Walking_Gait_Control_Using_a_Neuromorphic_Chip_Interfaced_to_a_Support_Vector_Learning_Algorithm.html">57 nips-2000-Four-legged Walking Gait Control Using a Neuromorphic Chip Interfaced to a Support Vector Learning Algorithm</a></p>
<p>Author: Susanne Still, Bernhard Schölkopf, Klaus Hepp, Rodney J. Douglas</p><p>Abstract: To control the walking gaits of a four-legged robot we present a novel neuromorphic VLSI chip that coordinates the relative phasing of the robot's legs similar to how spinal Central Pattern Generators are believed to control vertebrate locomotion [3]. The chip controls the leg movements by driving motors with time varying voltages which are the outputs of a small network of coupled oscillators. The characteristics of the chip's output voltages depend on a set of input parameters. The relationship between input parameters and output voltages can be computed analytically for an idealized system. In practice, however, this ideal relationship is only approximately true due to transistor mismatch and offsets. Fine tuning of the chip's input parameters is done automatically by the robotic system, using an unsupervised Support Vector (SV) learning algorithm introduced recently [7]. The learning requires only that the description of the desired output is given. The machine learns from (unlabeled) examples how to set the parameters to the chip in order to obtain a desired motor behavior.</p><p>6 0.36058101 <a title="67-lsi-6" href="./nips-2000-Finding_the_Key_to_a_Synapse.html">55 nips-2000-Finding the Key to a Synapse</a></p>
<p>7 0.35755935 <a title="67-lsi-7" href="./nips-2000-Multiple_Timescales_of_Adaptation_in_a_Neural_Code.html">88 nips-2000-Multiple Timescales of Adaptation in a Neural Code</a></p>
<p>8 0.35134569 <a title="67-lsi-8" href="./nips-2000-What_Can_a_Single_Neuron_Compute%3F.html">146 nips-2000-What Can a Single Neuron Compute?</a></p>
<p>9 0.30610666 <a title="67-lsi-9" href="./nips-2000-Divisive_and_Subtractive_Mask_Effects%3A_Linking_Psychophysics_and_Biophysics.html">42 nips-2000-Divisive and Subtractive Mask Effects: Linking Psychophysics and Biophysics</a></p>
<p>10 0.2748743 <a title="67-lsi-10" href="./nips-2000-Foundations_for_a_Circuit_Complexity_Theory_of_Sensory_Processing.html">56 nips-2000-Foundations for a Circuit Complexity Theory of Sensory Processing</a></p>
<p>11 0.24213725 <a title="67-lsi-11" href="./nips-2000-Processing_of_Time_Series_by_Neural_Circuits_with_Biologically_Realistic_Synaptic_Dynamics.html">104 nips-2000-Processing of Time Series by Neural Circuits with Biologically Realistic Synaptic Dynamics</a></p>
<p>12 0.1976891 <a title="67-lsi-12" href="./nips-2000-The_Interplay_of_Symbolic_and_Subsymbolic_Processes_in_Anagram_Problem_Solving.html">132 nips-2000-The Interplay of Symbolic and Subsymbolic Processes in Anagram Problem Solving</a></p>
<p>13 0.1922837 <a title="67-lsi-13" href="./nips-2000-Spike-Timing-Dependent_Learning_for_Oscillatory_Networks.html">124 nips-2000-Spike-Timing-Dependent Learning for Oscillatory Networks</a></p>
<p>14 0.17519835 <a title="67-lsi-14" href="./nips-2000-Stability_and_Noise_in_Biochemical_Switches.html">125 nips-2000-Stability and Noise in Biochemical Switches</a></p>
<p>15 0.17355286 <a title="67-lsi-15" href="./nips-2000-Dendritic_Compartmentalization_Could_Underlie_Competition_and_Attentional_Biasing_of_Simultaneous_Visual_Stimuli.html">40 nips-2000-Dendritic Compartmentalization Could Underlie Competition and Attentional Biasing of Simultaneous Visual Stimuli</a></p>
<p>16 0.13902476 <a title="67-lsi-16" href="./nips-2000-Universality_and_Individuality_in_a_Neural_Code.html">141 nips-2000-Universality and Individuality in a Neural Code</a></p>
<p>17 0.13596952 <a title="67-lsi-17" href="./nips-2000-Robust_Reinforcement_Learning.html">113 nips-2000-Robust Reinforcement Learning</a></p>
<p>18 0.13585876 <a title="67-lsi-18" href="./nips-2000-Competition_and_Arbors_in_Ocular_Dominance.html">34 nips-2000-Competition and Arbors in Ocular Dominance</a></p>
<p>19 0.13253143 <a title="67-lsi-19" href="./nips-2000-High-temperature_Expansions_for_Learning_Models_of_Nonnegative_Data.html">64 nips-2000-High-temperature Expansions for Learning Models of Nonnegative Data</a></p>
<p>20 0.12158928 <a title="67-lsi-20" href="./nips-2000-Bayesian_Video_Shot_Segmentation.html">30 nips-2000-Bayesian Video Shot Segmentation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2000_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(17, 0.046), (18, 0.025), (32, 0.012), (33, 0.02), (42, 0.054), (55, 0.012), (59, 0.05), (62, 0.026), (67, 0.03), (69, 0.011), (76, 0.023), (81, 0.035), (90, 0.019), (91, 0.011), (93, 0.509)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94720167 <a title="67-lda-1" href="./nips-2000-Homeostasis_in_a_Silicon_Integrate_and_Fire_Neuron.html">67 nips-2000-Homeostasis in a Silicon Integrate and Fire Neuron</a></p>
<p>Author: Shih-Chii Liu, Bradley A. Minch</p><p>Abstract: In this work, we explore homeostasis in a silicon integrate-and-fire neuron. The neuron adapts its firing rate over long time periods on the order of seconds or minutes so that it returns to its spontaneous firing rate after a lasting perturbation. Homeostasis is implemented via two schemes. One scheme looks at the presynaptic activity and adapts the synaptic weight depending on the presynaptic spiking rate. The second scheme adapts the synaptic</p><p>2 0.64899278 <a title="67-lda-2" href="./nips-2000-Periodic_Component_Analysis%3A_An_Eigenvalue_Method_for_Representing_Periodic_Structure_in_Speech.html">99 nips-2000-Periodic Component Analysis: An Eigenvalue Method for Representing Periodic Structure in Speech</a></p>
<p>Author: Lawrence K. Saul, Jont B. Allen</p><p>Abstract: An eigenvalue method is developed for analyzing periodic structure in speech. Signals are analyzed by a matrix diagonalization reminiscent of methods for principal component analysis (PCA) and independent component analysis (ICA). Our method-called periodic component analysis (1l</p><p>3 0.37750942 <a title="67-lda-3" href="./nips-2000-A_Silicon_Primitive_for_Competitive_Learning.html">11 nips-2000-A Silicon Primitive for Competitive Learning</a></p>
<p>Author: David Hsu, Miguel Figueroa, Chris Diorio</p><p>Abstract: Competitive learning is a technique for training classification and clustering networks. We have designed and fabricated an 11transistor primitive, that we term an automaximizing bump circuit, that implements competitive learning dynamics. The circuit performs a similarity computation, affords nonvolatile storage, and implements simultaneous local adaptation and computation. We show that our primitive is suitable for implementing competitive learning in VLSI, and demonstrate its effectiveness in a standard clustering task.</p><p>4 0.2340638 <a title="67-lda-4" href="./nips-2000-What_Can_a_Single_Neuron_Compute%3F.html">146 nips-2000-What Can a Single Neuron Compute?</a></p>
<p>Author: Blaise Agüera y Arcas, Adrienne L. Fairhall, William Bialek</p><p>Abstract: In this paper we formulate a description of the computation performed by a neuron as a combination of dimensional reduction and nonlinearity. We implement this description for the HodgkinHuxley model, identify the most relevant dimensions and find the nonlinearity. A two dimensional description already captures a significant fraction of the information that spikes carry about dynamic inputs. This description also shows that computation in the Hodgkin-Huxley model is more complex than a simple integrateand-fire or perceptron model. 1</p><p>5 0.22359766 <a title="67-lda-5" href="./nips-2000-Multiple_Timescales_of_Adaptation_in_a_Neural_Code.html">88 nips-2000-Multiple Timescales of Adaptation in a Neural Code</a></p>
<p>Author: Adrienne L. Fairhall, Geoffrey D. Lewen, William Bialek, Robert R. de Ruyter van Steveninck</p><p>Abstract: Many neural systems extend their dynamic range by adaptation. We examine the timescales of adaptation in the context of dynamically modulated rapidly-varying stimuli, and demonstrate in the fly visual system that adaptation to the statistical ensemble of the stimulus dynamically maximizes information transmission about the time-dependent stimulus. Further, while the rate response has long transients, the adaptation takes place on timescales consistent with optimal variance estimation.</p><p>6 0.21229628 <a title="67-lda-6" href="./nips-2000-Dendritic_Compartmentalization_Could_Underlie_Competition_and_Attentional_Biasing_of_Simultaneous_Visual_Stimuli.html">40 nips-2000-Dendritic Compartmentalization Could Underlie Competition and Attentional Biasing of Simultaneous Visual Stimuli</a></p>
<p>7 0.19779086 <a title="67-lda-7" href="./nips-2000-Noise_Suppression_Based_on_Neurophysiologically-motivated_SNR_Estimation_for_Robust_Speech_Recognition.html">91 nips-2000-Noise Suppression Based on Neurophysiologically-motivated SNR Estimation for Robust Speech Recognition</a></p>
<p>8 0.19592701 <a title="67-lda-8" href="./nips-2000-Temporally_Dependent_Plasticity%3A_An_Information_Theoretic_Account.html">129 nips-2000-Temporally Dependent Plasticity: An Information Theoretic Account</a></p>
<p>9 0.19023755 <a title="67-lda-9" href="./nips-2000-Finding_the_Key_to_a_Synapse.html">55 nips-2000-Finding the Key to a Synapse</a></p>
<p>10 0.18693674 <a title="67-lda-10" href="./nips-2000-Spike-Timing-Dependent_Learning_for_Oscillatory_Networks.html">124 nips-2000-Spike-Timing-Dependent Learning for Oscillatory Networks</a></p>
<p>11 0.18223616 <a title="67-lda-11" href="./nips-2000-Four-legged_Walking_Gait_Control_Using_a_Neuromorphic_Chip_Interfaced_to_a_Support_Vector_Learning_Algorithm.html">57 nips-2000-Four-legged Walking Gait Control Using a Neuromorphic Chip Interfaced to a Support Vector Learning Algorithm</a></p>
<p>12 0.17347002 <a title="67-lda-12" href="./nips-2000-Modelling_Spatial_Recall%2C_Mental_Imagery_and_Neglect.html">87 nips-2000-Modelling Spatial Recall, Mental Imagery and Neglect</a></p>
<p>13 0.17008276 <a title="67-lda-13" href="./nips-2000-Divisive_and_Subtractive_Mask_Effects%3A_Linking_Psychophysics_and_Biophysics.html">42 nips-2000-Divisive and Subtractive Mask Effects: Linking Psychophysics and Biophysics</a></p>
<p>14 0.15653245 <a title="67-lda-14" href="./nips-2000-Processing_of_Time_Series_by_Neural_Circuits_with_Biologically_Realistic_Synaptic_Dynamics.html">104 nips-2000-Processing of Time Series by Neural Circuits with Biologically Realistic Synaptic Dynamics</a></p>
<p>15 0.14990841 <a title="67-lda-15" href="./nips-2000-Stability_and_Noise_in_Biochemical_Switches.html">125 nips-2000-Stability and Noise in Biochemical Switches</a></p>
<p>16 0.13904943 <a title="67-lda-16" href="./nips-2000-Universality_and_Individuality_in_a_Neural_Code.html">141 nips-2000-Universality and Individuality in a Neural Code</a></p>
<p>17 0.13820842 <a title="67-lda-17" href="./nips-2000-Dopamine_Bonuses.html">43 nips-2000-Dopamine Bonuses</a></p>
<p>18 0.13777211 <a title="67-lda-18" href="./nips-2000-Explaining_Away_in_Weight_Space.html">49 nips-2000-Explaining Away in Weight Space</a></p>
<p>19 0.13768516 <a title="67-lda-19" href="./nips-2000-Natural_Sound_Statistics_and_Divisive_Normalization_in_the_Auditory_System.html">89 nips-2000-Natural Sound Statistics and Divisive Normalization in the Auditory System</a></p>
<p>20 0.13470969 <a title="67-lda-20" href="./nips-2000-Probabilistic_Semantic_Video_Indexing.html">103 nips-2000-Probabilistic Semantic Video Indexing</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
