<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>55 nips-2000-Finding the Key to a Synapse</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2000" href="../home/nips2000_home.html">nips2000</a> <a title="nips-2000-55" href="#">nips2000-55</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>55 nips-2000-Finding the Key to a Synapse</h1>
<br/><p>Source: <a title="nips-2000-55-pdf" href="http://papers.nips.cc/paper/1813-finding-the-key-to-a-synapse.pdf">pdf</a></p><p>Author: Thomas Natschläger, Wolfgang Maass</p><p>Abstract: Experimental data have shown that synapses are heterogeneous: different synapses respond with different sequences of amplitudes of postsynaptic responses to the same spike train. Neither the role of synaptic dynamics itself nor the role of the heterogeneity of synaptic dynamics for computations in neural circuits is well understood. We present in this article methods that make it feasible to compute for a given synapse with known synaptic parameters the spike train that is optimally fitted to the synapse, for example in the sense that it produces the largest sum of postsynaptic responses. To our surprise we find that most of these optimally fitted spike trains match common firing patterns of specific types of neurons that are discussed in the literature.</p><p>Reference: <a title="nips-2000-55-reference" href="../nips2000_reference/nips-2000-Finding_the_Key_to_a_Synapse_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 at  Abstract Experimental data have shown that synapses are heterogeneous: different synapses respond with different sequences of amplitudes of postsynaptic responses to the same spike train. [sent-4, score-1.318]
</p><p>2 Neither the role of synaptic dynamics itself nor the role of the heterogeneity of synaptic dynamics for computations in neural circuits is well understood. [sent-5, score-0.452]
</p><p>3 We present in this article methods that make it feasible to compute for a given synapse with known synaptic parameters the spike train that is optimally fitted to the synapse, for example in the sense that it produces the largest sum of postsynaptic responses. [sent-6, score-1.763]
</p><p>4 To our surprise we find that most of these optimally fitted spike trains match common firing patterns of specific types of neurons that are discussed in the literature. [sent-7, score-1.096]
</p><p>5 1 Introduction A large number of experimental studies have shown that biological synapses have an inherent dynamics, which controls how the pattern of amplitudes of postsynaptic responses depends on the temporal pattern of the incoming spike train. [sent-8, score-1.208]
</p><p>6 Various quantitative models have been proposed involving a small number of characteristic parameters, that allow us to predict the response of a given synapse to a given spike train once proper values for these characteristic synaptic parameters have been found. [sent-9, score-1.375]
</p><p>7 The analysis of this article is based on the model of [1], where three parameters U, F, D control the dynamics of a synapse and a fourth parameter A - which corresponds to the synaptic "weight" in static synapse models - scales the absolute sizes of the postsynaptic responses. [sent-10, score-1.403]
</p><p>8 The resulting model predicts the amplitude Ak for the kth spike in a spike train with interspike intervals (lSI's) . [sent-11, score-1.196]
</p><p>9 These dynamic variables evolve in dependence of the synaptic parameters U, F, D and the interspike intervals of the incoming ITo be precise: the term Uk-1Rk-l in Eq. [sent-19, score-0.295]
</p><p>10 Shown is the distribution of values for inhibitory synapses investigated in [2] which can be grouped into three mayor classes: facilitating (Ft), depressing (F2) and recovering (F3). [sent-32, score-0.4]
</p><p>11 Shown are the amplitudes Uk • Rk (height of vertical bar) of the postsynaptic response of a FI-type and a F2-type synapse to an irregular input spike train. [sent-34, score-1.284]
</p><p>12 The parameters for synapses fA and F2 are the mean values for the synapse types FI and F2 reported in [2]: (U, D, F) =(0. [sent-35, score-0.887]
</p><p>13 2 It is reported in [2] that the synaptic parameters U, F, D are quite heterogeneous, even within a single neural circuit (see Fig. [sent-38, score-0.276]
</p><p>14 The synapses investigated in [2] can be grouped into three major classes: facilitating (FI), depressing (F2) and recovering (F3). [sent-41, score-0.397]
</p><p>15 IB compares the output of a typical FI-type and a typical F2-type synapse in response to a typical irregular spike train. [sent-43, score-1.013]
</p><p>16 One can see that the same input spike train yields markedly different outputs at these two synapses. [sent-44, score-0.607]
</p><p>17 In this article we address the question which temporal pattern of a spike train is optimally fitted to a given synapse characterized by the three parameters U, F, D in a certain sense. [sent-45, score-1.434]
</p><p>18 One possible choice is to look for the temporal pattern of a spike train which produces the largest integral of synaptic current. [sent-46, score-0.979]
</p><p>19 Note that in the case where the dendritic integration is =l approximately linear the integral of synaptic current is proportional to the sum 'E~ A . [sent-47, score-0.167]
</p><p>20 For example one can use them also to compute the spike train which produces the largest peak of the postsynaptic membrane voltage. [sent-51, score-0.916]
</p><p>21 However, in the following we will focus on the question which temporal pattern of a spike train produces the largest sum 'E~=l A· Uk . [sent-52, score-0.812]
</p><p>22 Rk of postsynaptic responses (or equivalently the largest integral of postsynaptic current). [sent-53, score-0.523]
</p><p>23 More precisely, we fix a time interval T , a minimum value ~min for lSI's, a natural number N , and synaptic parameters U, F, D . [sent-54, score-0.201]
</p><p>24 We then look for that spike train with N spikes during T and lSI's 2:: ~min that maximizes 'E~=l A· Uk' Rk. [sent-55, score-0.652]
</p><p>25 (2)  k=l  In Section 2 of this article we present an algorithmic approach based on dynamic program2It should be noted that this deterministic model predicts the cumulative response of a population of stochastic release sites that make up a synaptic connection. [sent-62, score-0.382]
</p><p>26 ming that is guaranteed to find the optimal solution of this problem (up to discretization errors), and exhibit for major types of synapses temporal patterns of spike trains that are optimally fitted to these synapses. [sent-63, score-1.323]
</p><p>27 In Section 3 we present a faster heuristic method for computing optimally fitted spike trains, and apply it to analyze how their temporal pattern depends on the number N of allowed spikes during time interval T, i. [sent-64, score-0.823]
</p><p>28 Furthermore we analyze in Section 3 how changes in the synaptic parameters U, F, D affect the temporal pattern of the optimally fitted spike train. [sent-67, score-0.958]
</p><p>29 2  Computing Optimal Spike Trains for Common Types of Synapses  Dynamic Programming For T = 1000 msec and N = 10 there are about 2100 spike trains among which one wants to find the optimally fitted one. [sent-68, score-0.932]
</p><p>30 We show that a computationally feasible solution to this complex optimization problem can be achieved via dynamic programming. [sent-69, score-0.089]
</p><p>31 In our case Xk is the triple (Uk, Rk, tk) consisting of the values of the dynamic variables U and R used to calculate the amplitude A . [sent-75, score-0.091]
</p><p>32 Rk of the kth postsynaptic response, and the time tk of the arrival of the kth spike at the synapse. [sent-77, score-0.871]
</p><p>33 The "action" ak is the length Ilk E [Il min , T - tkJ of the kth lSI in the spike train that we construct, where Ilmin is the smallest possible size of an lSI (we have set Ilmin = 5 msec in our computations). [sent-78, score-0.925]
</p><p>34 , the amplitude of the postsynaptic response for the kth spike. [sent-86, score-0.389]
</p><p>35 3 The "Key" to a Synapse We have applied the dynamic programming approach to three major types of synapses reported in [2]. [sent-99, score-0.545]
</p><p>36 We refer informally to the temporal pattern of N spikes that maximizes the response of a particular synapse as the "key" to this synapse. [sent-103, score-0.707]
</p><p>37 3 that the "keys" for the inhibitory synapses Fi and F2 are rather specific in the sense that they exhibit a substantially smaller postsynaptic response on any other of the major types of inhibitory synapses reported in [2]. [sent-105, score-1.091]
</p><p>38 The specificity of a "key" to a synapse is most pronounced for spiking frequencies f below 20 Hz. [sent-106, score-0.543]
</p><p>39 One may speculate that due to this feature a neuron can activate - even without changing its firing rate - a particular subpopulation of its target neurons by generating a series of action potentials with a suitable temporal pattern, see 3When one solves Eq. [sent-107, score-0.35]
</p><p>40 8  time [sec]  u  Figure 2: Spike trains that maximize the sum of postsynaptic responses for three common types of synapses (T = 0. [sent-126, score-0.723]
</p><p>41 The parameters for synapses Fi, F2, and F3 are the mean values for the synapse types FI, F2 and F3 reported in [2] : (U, D, F} = (0. [sent-128, score-0.887]
</p><p>42 key to synapse  response of a response of a Fl-type synapse F2-type synapse  Fl  I  II I I I I I I I I I I I I key to synapse  III  F2  ({/ %  II  II  81%  I  I  Figure 3: Specificity of optimal spike trains. [sent-132, score-2.578]
</p><p>43 The optimal spike trains for synapses Fl and F2 - the "keys" to the synapses Fl and F2 - obtained for T = 0. [sent-133, score-1.188]
</p><p>44 8 sec and N = 15 spikes are tested on the synapses Fl and F2 . [sent-134, score-0.425]
</p><p>45 If the "key" to synapse Fl (F2 ) is tested on the synapse Fl (F2 ) this synapse produces the maximal (l00 %) postsynaptic response. [sent-135, score-1.634]
</p><p>46 If on the other hand the "key" to synapse Fl (F2) is tested on synapse F2 (Fl ) this synapse produces significantly less postsynaptic response. [sent-136, score-1.599]
</p><p>47 Recent experiments [5, 6] show that neuromodulators can control the firing mode of cortical neurons. [sent-139, score-0.217]
</p><p>48 In [5] it is shown that bursting neurons may switch to regular firing if norepinephine is applied. [sent-140, score-0.358]
</p><p>49 Together with the specificity of synapses to certain temporal patterns these findings point to one possible mechanism how neuromodulators can change the effective connectivity of a neural circuit. [sent-141, score-0.539]
</p><p>50 Relation to discharge patterns A noteworthy aspect of the "keys" shown in Fig. [sent-142, score-0.104]
</p><p>51 7) is that they correspond to common firing patterns ("accommodating", "non-accommodating", "stuttering", "bursting" and "regular firing") of neocortical interneurons reported under controlled conditions in vitro [2, 5] and in vivo [7]. [sent-145, score-0.34]
</p><p>52 For example the temporal patterns of the "keys" to the synapses Fl , F2, and F3 are similar to the discharge patterns of "accommodating" [2], "bursting" [5, 7], and "stuttering" [2] cells respectively. [sent-146, score-0.479]
</p><p>53 5B), where we have set  synaptic response  synaptic response  -te--=------. [sent-154, score-0.48]
</p><p>54 _-=-~< III 1 1 1  i 0-I  F2  (1-  key to synapse F2  Fl l o - -  key to synapse Fl  11111111 I I I I I I I  Fl  Figure 4: Preferential addressing of postsynaptic targets. [sent-159, score-1.299]
</p><p>55 Due to the specificity of a "key" to a synapse a presynaptic neuron may address (i. [sent-160, score-0.636]
</p><p>56 evoke stronger response at) either neuron A or B, depending on the temporal pattern of the spike train (with the same frequency f = NIT) it produces (T = 0. [sent-162, score-0.913]
</p><p>57 Rk if the key to synapse Pi is applied to synapse Pi, i = 1,2,3. [sent-168, score-0.958]
</p><p>58 For A we used the value of G max (in nS) reported in [2]. [sent-172, score-0.106]
</p><p>59 Whereas the values of G max vary strongly among different synapse types (see Fig. [sent-177, score-0.537]
</p><p>60 5B), the resulting maximal response of a synapse to its proper "key" is almost the same for each synapse. [sent-178, score-0.55]
</p><p>61 Hence, one may speculate that the system is designed in such a way that each synapse should have an equal influence on the postsynaptic neuron when it receives its optimal spike train. [sent-179, score-1.248]
</p><p>62 3 Exploring the Parameter Space Sequential Quadratic Programming The numerical approach for approximately computing optimal spike trains that was used in section 2 is sufficiently fast so that an average PC can carry out any of the computations whose results were reported in Fig. [sent-181, score-0.74]
</p><p>63 We refer the reader to [8] for the mathematical background of this technique and to [4] for more details about the application of SQP for approximately computing optimal spike trains. [sent-184, score-0.56]
</p><p>64 Optimal Spike Trains for Different Firing Rates First we used SQP to explore the effect of the spike frequency f = N IT on the temporal pattern of the optimal spike train. [sent-185, score-1.138]
</p><p>65 For the synapses PI, P2 , and Pa we computed the optimal spike trains for frequencies 4We used the implementation (function constr) which is contained in the MATLAB Optimization Toolbox (see http : //www . [sent-186, score-0.916]
</p><p>66 g  ~ ~  keys to  35 1  I I 1 I I I I I I I 1 1 1I II "-. [sent-191, score-0.101]
</p><p>67 20 1 ~ 15 1  11 11  30 11 111 11111 11111 111111  synapse  40 ~  ~  --  40 11 1 11111 111 11111111111 11111111111111  ~  111111 11111 11  F2  keys to  III  25 111 11111 1 11 1 11 111 1 II I  -h  20 1 1 111 1 1 1 1 111 1 1  0  0. [sent-193, score-0.543]
</p><p>68 8  time [sec]  Figure 6: Dependence of the optimal spike train of the synapses spike frequency f = NIT (T = 1 sec, N = 15, . [sent-208, score-1.421]
</p><p>69 10  synapse  40 111111111 11111 1111 111 1 11 11 1 111 111 111 1  ~ 35  Q)  15 1 11 11 1 1  F3  I I I  I I I  II II  I I I  I I I  II II  II II  III  III  1111  I I I  FL F2 ,  I I I  and  F3  on the  II II II I II III 1111  1111 11111  11111  i  i  i  i  0  0. [sent-222, score-0.442]
</p><p>70 75  time [sec]  Figure 7: Dependence of the optimal spike train on the synaptic parameter U. [sent-225, score-0.844]
</p><p>71 It is shown how the optimal spike train changes if the parameter U is varied. [sent-226, score-0.677]
</p><p>72 The other two parameters are set to the value corresponding to synapse F3: D = 144 msec and F = 62 msec. [sent-227, score-0.647]
</p><p>73 The black bar to the left marks the range of values (mean ± std) reported in [2] for the parameter U. [sent-228, score-0.127]
</p><p>74 To the right of each spike train we have plotted the corresponding value of J = Ef=i ukRk (gray bars). [sent-229, score-0.607]
</p><p>75 For synapses Fi and F2 the characteristic spike pattern (Fi . [sent-233, score-0.808]
</p><p>76 In contrast, the optimal spike train for synapse F3 has a phase transition from "stuttering" to "non-accommodating" at about 20 Hz. [sent-240, score-1.093]
</p><p>77 The Impact of Individual Synaptic Parameters We will now address the question how the optimal spike train depends on the individual synaptic parameters U, F, and D. [sent-241, score-0.875]
</p><p>78 The results for the case of F3-type synapses and the parameter U are summarized in Fig. [sent-242, score-0.323]
</p><p>79 For results with regard to other parameters and synapse types we refer to [4]. [sent-244, score-0.563]
</p><p>80 7 with a black bar the range of U for F3-type synapses reported in [2]. [sent-246, score-0.373]
</p><p>81 It can be seen that within this parameter range we find "regu]ar" and "bursting" spike patterns. [sent-247, score-0.498]
</p><p>82 Note that the sum of postsynaptic responses J (gray horizontal bars in Fig. [sent-248, score-0.259]
</p><p>83 This seems to be interesting since the parameter U is closely related to the initial release probability of a synapse, and it is a common assumption that the "strength" of a synapse is proportional to its initial release probability. [sent-253, score-0.536]
</p><p>84 4 Discussion We have presented two complementary computational approaches for computing spike trains that optimize a given response criterion for a given synapse. [sent-254, score-0.694]
</p><p>85 One of these methods is based on dynamic programming (similar as in reinforcement learning), the other one on sequential quadratic programming. [sent-255, score-0.132]
</p><p>86 These computational methods are not restricted to any particular choice of the optimality criterion and the synaptic model. [sent-256, score-0.196]
</p><p>87 It turns out that the spike trains that maximize the response of Fl-, F2- and F3-type synapses (see Fig. [sent-260, score-0.945]
</p><p>88 1) are well known firing patterns like "accommodating", "bursting" and "regular firing" of specific neuron types. [sent-261, score-0.261]
</p><p>89 Furthermore for Fl- and F3-type synapses the optimal spike train agrees with the most often found firing pattern of presynaptic neurons reported in [2], whereas for F2-type synapses there is no such agreement; see [4]. [sent-262, score-1.542]
</p><p>90 This observation provides the first glimpse at a possible functional role of the specific combinations of synapse types and neuron types that was recently found in [2]. [sent-263, score-0.669]
</p><p>91 Another noteworthy aspect of the optimal spike trains is their specificity for a given synapse (see Fig. [sent-264, score-1.216]
</p><p>92 : suitable temporal firing patterns activate preferentially specific types of synapses. [sent-266, score-0.373]
</p><p>93 One potential functional role of such specificity to temporal firing patterns is the possibility of preferential addressing of postsynaptic target neurons (see Fig. [sent-267, score-0.79]
</p><p>94 Note that there is experimental evidence that cortical neurons can switch their intrinsic firing behavior from "bursting" to "regular" depending on neuromodulator mediated inputs [5, 6]. [sent-269, score-0.253]
</p><p>95 This findings provide support for the idea of preferential addressing of postsynaptic targets implemented by the interplay of dynamic synapses and the intrinsic firing behavior of the presynaptic neuron. [sent-270, score-0.84]
</p><p>96 Organizing principles for a diversity of GABAergic interneurons and synapses in the neocortex. [sent-287, score-0.315]
</p><p>97 Computing the optimally fitted spike train for a synapse. [sent-297, score-0.768]
</p><p>98 Control of firing mode of corticotectal and corticopontine layer V burst generating neurons by norepinephrine. [sent-308, score-0.231]
</p><p>99 Ionic mechanisms underlying repetitive high frequency burst firing in supragranular cortical neurons. [sent-317, score-0.238]
</p><p>100 Dynamic properties of corticothalamic neurons and local cortical interneurons generating fast rhytmic (30-40 hz) spike bursts. [sent-324, score-0.592]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('spike', 0.472), ('synapse', 0.442), ('synapses', 0.272), ('postsynaptic', 0.228), ('rk', 0.194), ('fl', 0.185), ('msec', 0.171), ('synaptic', 0.167), ('firing', 0.154), ('train', 0.135), ('xk', 0.131), ('trains', 0.128), ('uk', 0.119), ('sec', 0.108), ('keys', 0.101), ('specificity', 0.101), ('bursting', 0.101), ('fitted', 0.088), ('temporal', 0.086), ('fi', 0.076), ('reported', 0.075), ('key', 0.074), ('response', 0.073), ('optimally', 0.073), ('accommodating', 0.067), ('stuttering', 0.067), ('ii', 0.066), ('dynamic', 0.065), ('types', 0.064), ('lsi', 0.062), ('kth', 0.062), ('iii', 0.06), ('ak', 0.051), ('nit', 0.05), ('preferential', 0.05), ('sqp', 0.05), ('jk', 0.049), ('neurons', 0.048), ('tk', 0.047), ('patterns', 0.046), ('spikes', 0.045), ('produces', 0.045), ('optimal', 0.044), ('interneurons', 0.043), ('amplitudes', 0.043), ('article', 0.043), ('programming', 0.043), ('addressing', 0.039), ('maass', 0.039), ('pattern', 0.038), ('role', 0.038), ('neuron', 0.038), ('largest', 0.036), ('maximal', 0.035), ('release', 0.034), ('wang', 0.034), ('min', 0.034), ('heterogeneous', 0.034), ('ilk', 0.034), ('ilmin', 0.034), ('natschlager', 0.034), ('neuromodulators', 0.034), ('parameters', 0.034), ('regular', 0.033), ('presynaptic', 0.032), ('max', 0.031), ('responses', 0.031), ('optimality', 0.029), ('inhibitory', 0.029), ('cortical', 0.029), ('noteworthy', 0.029), ('discharge', 0.029), ('burst', 0.029), ('facilitating', 0.029), ('interspike', 0.029), ('parameter', 0.026), ('amplitude', 0.026), ('bar', 0.026), ('characteristic', 0.026), ('hz', 0.026), ('depressing', 0.026), ('irregular', 0.026), ('frequency', 0.026), ('major', 0.026), ('summarized', 0.025), ('speculate', 0.024), ('discretization', 0.024), ('sequential', 0.024), ('optimization', 0.024), ('address', 0.023), ('refer', 0.023), ('specific', 0.023), ('fa', 0.023), ('gray', 0.022), ('grouped', 0.022), ('recovering', 0.022), ('neocortical', 0.022), ('switch', 0.022), ('dynamics', 0.021), ('computing', 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="55-tfidf-1" href="./nips-2000-Finding_the_Key_to_a_Synapse.html">55 nips-2000-Finding the Key to a Synapse</a></p>
<p>Author: Thomas Natschläger, Wolfgang Maass</p><p>Abstract: Experimental data have shown that synapses are heterogeneous: different synapses respond with different sequences of amplitudes of postsynaptic responses to the same spike train. Neither the role of synaptic dynamics itself nor the role of the heterogeneity of synaptic dynamics for computations in neural circuits is well understood. We present in this article methods that make it feasible to compute for a given synapse with known synaptic parameters the spike train that is optimally fitted to the synapse, for example in the sense that it produces the largest sum of postsynaptic responses. To our surprise we find that most of these optimally fitted spike trains match common firing patterns of specific types of neurons that are discussed in the literature.</p><p>2 0.35874942 <a title="55-tfidf-2" href="./nips-2000-What_Can_a_Single_Neuron_Compute%3F.html">146 nips-2000-What Can a Single Neuron Compute?</a></p>
<p>Author: Blaise Agüera y Arcas, Adrienne L. Fairhall, William Bialek</p><p>Abstract: In this paper we formulate a description of the computation performed by a neuron as a combination of dimensional reduction and nonlinearity. We implement this description for the HodgkinHuxley model, identify the most relevant dimensions and find the nonlinearity. A two dimensional description already captures a significant fraction of the information that spikes carry about dynamic inputs. This description also shows that computation in the Hodgkin-Huxley model is more complex than a simple integrateand-fire or perceptron model. 1</p><p>3 0.28530157 <a title="55-tfidf-3" href="./nips-2000-Temporally_Dependent_Plasticity%3A_An_Information_Theoretic_Account.html">129 nips-2000-Temporally Dependent Plasticity: An Information Theoretic Account</a></p>
<p>Author: Gal Chechik, Naftali Tishby</p><p>Abstract: The paradigm of Hebbian learning has recently received a novel interpretation with the discovery of synaptic plasticity that depends on the relative timing of pre and post synaptic spikes. This paper derives a temporally dependent learning rule from the basic principle of mutual information maximization and studies its relation to the experimentally observed plasticity. We find that a supervised spike-dependent learning rule sharing similar structure with the experimentally observed plasticity increases mutual information to a stable near optimal level. Moreover, the analysis reveals how the temporal structure of time-dependent learning rules is determined by the temporal filter applied by neurons over their inputs. These results suggest experimental prediction as to the dependency of the learning rule on neuronal biophysical parameters 1</p><p>4 0.25702965 <a title="55-tfidf-4" href="./nips-2000-Processing_of_Time_Series_by_Neural_Circuits_with_Biologically_Realistic_Synaptic_Dynamics.html">104 nips-2000-Processing of Time Series by Neural Circuits with Biologically Realistic Synaptic Dynamics</a></p>
<p>Author: Thomas Natschläger, Wolfgang Maass, Eduardo D. Sontag, Anthony M. Zador</p><p>Abstract: Experimental data show that biological synapses behave quite differently from the symbolic synapses in common artificial neural network models. Biological synapses are dynamic, i.e., their</p><p>5 0.21368811 <a title="55-tfidf-5" href="./nips-2000-Universality_and_Individuality_in_a_Neural_Code.html">141 nips-2000-Universality and Individuality in a Neural Code</a></p>
<p>Author: Elad Schneidman, Naama Brenner, Naftali Tishby, Robert R. de Ruyter van Steveninck, William Bialek</p><p>Abstract: The problem of neural coding is to understand how sequences of action potentials (spikes) are related to sensory stimuli, motor outputs, or (ultimately) thoughts and intentions. One clear question is whether the same coding rules are used by different neurons, or by corresponding neurons in different individuals. We present a quantitative formulation of this problem using ideas from information theory, and apply this approach to the analysis of experiments in the fly visual system. We find significant individual differences in the structure of the code, particularly in the way that temporal patterns of spikes are used to convey information beyond that available from variations in spike rate. On the other hand, all the flies in our ensemble exhibit a high coding efficiency, so that every spike carries the same amount of information in all the individuals. Thus the neural code has a quantifiable mixture of individuality and universality. 1</p><p>6 0.1648967 <a title="55-tfidf-6" href="./nips-2000-Multiple_Timescales_of_Adaptation_in_a_Neural_Code.html">88 nips-2000-Multiple Timescales of Adaptation in a Neural Code</a></p>
<p>7 0.13865624 <a title="55-tfidf-7" href="./nips-2000-Homeostasis_in_a_Silicon_Integrate_and_Fire_Neuron.html">67 nips-2000-Homeostasis in a Silicon Integrate and Fire Neuron</a></p>
<p>8 0.13607879 <a title="55-tfidf-8" href="./nips-2000-Spike-Timing-Dependent_Learning_for_Oscillatory_Networks.html">124 nips-2000-Spike-Timing-Dependent Learning for Oscillatory Networks</a></p>
<p>9 0.12747298 <a title="55-tfidf-9" href="./nips-2000-Dendritic_Compartmentalization_Could_Underlie_Competition_and_Attentional_Biasing_of_Simultaneous_Visual_Stimuli.html">40 nips-2000-Dendritic Compartmentalization Could Underlie Competition and Attentional Biasing of Simultaneous Visual Stimuli</a></p>
<p>10 0.085207663 <a title="55-tfidf-10" href="./nips-2000-A_Silicon_Primitive_for_Competitive_Learning.html">11 nips-2000-A Silicon Primitive for Competitive Learning</a></p>
<p>11 0.061865162 <a title="55-tfidf-11" href="./nips-2000-Divisive_and_Subtractive_Mask_Effects%3A_Linking_Psychophysics_and_Biophysics.html">42 nips-2000-Divisive and Subtractive Mask Effects: Linking Psychophysics and Biophysics</a></p>
<p>12 0.05351137 <a title="55-tfidf-12" href="./nips-2000-Natural_Sound_Statistics_and_Divisive_Normalization_in_the_Auditory_System.html">89 nips-2000-Natural Sound Statistics and Divisive Normalization in the Auditory System</a></p>
<p>13 0.052702453 <a title="55-tfidf-13" href="./nips-2000-Place_Cells_and_Spatial_Navigation_Based_on_2D_Visual_Feature_Extraction%2C_Path_Integration%2C_and_Reinforcement_Learning.html">101 nips-2000-Place Cells and Spatial Navigation Based on 2D Visual Feature Extraction, Path Integration, and Reinforcement Learning</a></p>
<p>14 0.049223054 <a title="55-tfidf-14" href="./nips-2000-Emergence_of_Movement_Sensitive_Neurons%27_Properties_by_Learning_a_Sparse_Code_for_Natural_Moving_Images.html">45 nips-2000-Emergence of Movement Sensitive Neurons' Properties by Learning a Sparse Code for Natural Moving Images</a></p>
<p>15 0.047226645 <a title="55-tfidf-15" href="./nips-2000-Exact_Solutions_to_Time-Dependent_MDPs.html">48 nips-2000-Exact Solutions to Time-Dependent MDPs</a></p>
<p>16 0.042891558 <a title="55-tfidf-16" href="./nips-2000-Who_Does_What%3F_A_Novel_Algorithm_to_Determine_Function_Localization.html">147 nips-2000-Who Does What? A Novel Algorithm to Determine Function Localization</a></p>
<p>17 0.042596411 <a title="55-tfidf-17" href="./nips-2000-Competition_and_Arbors_in_Ocular_Dominance.html">34 nips-2000-Competition and Arbors in Ocular Dominance</a></p>
<p>18 0.042176105 <a title="55-tfidf-18" href="./nips-2000-Second_Order_Approximations_for_Probability_Models.html">114 nips-2000-Second Order Approximations for Probability Models</a></p>
<p>19 0.041322619 <a title="55-tfidf-19" href="./nips-2000-Permitted_and_Forbidden_Sets_in_Symmetric_Threshold-Linear_Networks.html">100 nips-2000-Permitted and Forbidden Sets in Symmetric Threshold-Linear Networks</a></p>
<p>20 0.039999437 <a title="55-tfidf-20" href="./nips-2000-Speech_Denoising_and_Dereverberation_Using_Probabilistic_Models.html">123 nips-2000-Speech Denoising and Dereverberation Using Probabilistic Models</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2000_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.178), (1, -0.272), (2, -0.39), (3, -0.082), (4, 0.062), (5, -0.031), (6, -0.125), (7, 0.334), (8, -0.082), (9, 0.077), (10, -0.021), (11, -0.102), (12, 0.021), (13, 0.034), (14, -0.001), (15, 0.034), (16, 0.011), (17, 0.091), (18, -0.05), (19, -0.001), (20, -0.16), (21, -0.097), (22, -0.11), (23, 0.058), (24, -0.128), (25, -0.028), (26, 0.034), (27, -0.006), (28, -0.011), (29, 0.135), (30, 0.025), (31, 0.066), (32, 0.01), (33, -0.025), (34, -0.065), (35, -0.013), (36, 0.05), (37, 0.002), (38, -0.03), (39, -0.032), (40, 0.036), (41, -0.047), (42, -0.072), (43, 0.004), (44, 0.035), (45, 0.029), (46, -0.012), (47, 0.045), (48, -0.047), (49, -0.009)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98688161 <a title="55-lsi-1" href="./nips-2000-Finding_the_Key_to_a_Synapse.html">55 nips-2000-Finding the Key to a Synapse</a></p>
<p>Author: Thomas Natschläger, Wolfgang Maass</p><p>Abstract: Experimental data have shown that synapses are heterogeneous: different synapses respond with different sequences of amplitudes of postsynaptic responses to the same spike train. Neither the role of synaptic dynamics itself nor the role of the heterogeneity of synaptic dynamics for computations in neural circuits is well understood. We present in this article methods that make it feasible to compute for a given synapse with known synaptic parameters the spike train that is optimally fitted to the synapse, for example in the sense that it produces the largest sum of postsynaptic responses. To our surprise we find that most of these optimally fitted spike trains match common firing patterns of specific types of neurons that are discussed in the literature.</p><p>2 0.76419449 <a title="55-lsi-2" href="./nips-2000-What_Can_a_Single_Neuron_Compute%3F.html">146 nips-2000-What Can a Single Neuron Compute?</a></p>
<p>Author: Blaise Agüera y Arcas, Adrienne L. Fairhall, William Bialek</p><p>Abstract: In this paper we formulate a description of the computation performed by a neuron as a combination of dimensional reduction and nonlinearity. We implement this description for the HodgkinHuxley model, identify the most relevant dimensions and find the nonlinearity. A two dimensional description already captures a significant fraction of the information that spikes carry about dynamic inputs. This description also shows that computation in the Hodgkin-Huxley model is more complex than a simple integrateand-fire or perceptron model. 1</p><p>3 0.7318235 <a title="55-lsi-3" href="./nips-2000-Temporally_Dependent_Plasticity%3A_An_Information_Theoretic_Account.html">129 nips-2000-Temporally Dependent Plasticity: An Information Theoretic Account</a></p>
<p>Author: Gal Chechik, Naftali Tishby</p><p>Abstract: The paradigm of Hebbian learning has recently received a novel interpretation with the discovery of synaptic plasticity that depends on the relative timing of pre and post synaptic spikes. This paper derives a temporally dependent learning rule from the basic principle of mutual information maximization and studies its relation to the experimentally observed plasticity. We find that a supervised spike-dependent learning rule sharing similar structure with the experimentally observed plasticity increases mutual information to a stable near optimal level. Moreover, the analysis reveals how the temporal structure of time-dependent learning rules is determined by the temporal filter applied by neurons over their inputs. These results suggest experimental prediction as to the dependency of the learning rule on neuronal biophysical parameters 1</p><p>4 0.56580943 <a title="55-lsi-4" href="./nips-2000-Universality_and_Individuality_in_a_Neural_Code.html">141 nips-2000-Universality and Individuality in a Neural Code</a></p>
<p>Author: Elad Schneidman, Naama Brenner, Naftali Tishby, Robert R. de Ruyter van Steveninck, William Bialek</p><p>Abstract: The problem of neural coding is to understand how sequences of action potentials (spikes) are related to sensory stimuli, motor outputs, or (ultimately) thoughts and intentions. One clear question is whether the same coding rules are used by different neurons, or by corresponding neurons in different individuals. We present a quantitative formulation of this problem using ideas from information theory, and apply this approach to the analysis of experiments in the fly visual system. We find significant individual differences in the structure of the code, particularly in the way that temporal patterns of spikes are used to convey information beyond that available from variations in spike rate. On the other hand, all the flies in our ensemble exhibit a high coding efficiency, so that every spike carries the same amount of information in all the individuals. Thus the neural code has a quantifiable mixture of individuality and universality. 1</p><p>5 0.55934358 <a title="55-lsi-5" href="./nips-2000-Processing_of_Time_Series_by_Neural_Circuits_with_Biologically_Realistic_Synaptic_Dynamics.html">104 nips-2000-Processing of Time Series by Neural Circuits with Biologically Realistic Synaptic Dynamics</a></p>
<p>Author: Thomas Natschläger, Wolfgang Maass, Eduardo D. Sontag, Anthony M. Zador</p><p>Abstract: Experimental data show that biological synapses behave quite differently from the symbolic synapses in common artificial neural network models. Biological synapses are dynamic, i.e., their</p><p>6 0.47825703 <a title="55-lsi-6" href="./nips-2000-Spike-Timing-Dependent_Learning_for_Oscillatory_Networks.html">124 nips-2000-Spike-Timing-Dependent Learning for Oscillatory Networks</a></p>
<p>7 0.47368416 <a title="55-lsi-7" href="./nips-2000-Multiple_Timescales_of_Adaptation_in_a_Neural_Code.html">88 nips-2000-Multiple Timescales of Adaptation in a Neural Code</a></p>
<p>8 0.41422915 <a title="55-lsi-8" href="./nips-2000-Homeostasis_in_a_Silicon_Integrate_and_Fire_Neuron.html">67 nips-2000-Homeostasis in a Silicon Integrate and Fire Neuron</a></p>
<p>9 0.336128 <a title="55-lsi-9" href="./nips-2000-Dendritic_Compartmentalization_Could_Underlie_Competition_and_Attentional_Biasing_of_Simultaneous_Visual_Stimuli.html">40 nips-2000-Dendritic Compartmentalization Could Underlie Competition and Attentional Biasing of Simultaneous Visual Stimuli</a></p>
<p>10 0.24505682 <a title="55-lsi-10" href="./nips-2000-Exact_Solutions_to_Time-Dependent_MDPs.html">48 nips-2000-Exact Solutions to Time-Dependent MDPs</a></p>
<p>11 0.18013605 <a title="55-lsi-11" href="./nips-2000-APRICODD%3A_Approximate_Policy_Construction_Using_Decision_Diagrams.html">1 nips-2000-APRICODD: Approximate Policy Construction Using Decision Diagrams</a></p>
<p>12 0.1775831 <a title="55-lsi-12" href="./nips-2000-Who_Does_What%3F_A_Novel_Algorithm_to_Determine_Function_Localization.html">147 nips-2000-Who Does What? A Novel Algorithm to Determine Function Localization</a></p>
<p>13 0.16881417 <a title="55-lsi-13" href="./nips-2000-A_Silicon_Primitive_for_Competitive_Learning.html">11 nips-2000-A Silicon Primitive for Competitive Learning</a></p>
<p>14 0.1687016 <a title="55-lsi-14" href="./nips-2000-Hippocampally-Dependent_Consolidation_in_a_Hierarchical_Model_of_Neocortex.html">66 nips-2000-Hippocampally-Dependent Consolidation in a Hierarchical Model of Neocortex</a></p>
<p>15 0.16266786 <a title="55-lsi-15" href="./nips-2000-Decomposition_of_Reinforcement_Learning_for_Admission_Control_of_Self-Similar_Call_Arrival_Processes.html">39 nips-2000-Decomposition of Reinforcement Learning for Admission Control of Self-Similar Call Arrival Processes</a></p>
<p>16 0.15947756 <a title="55-lsi-16" href="./nips-2000-Efficient_Learning_of_Linear_Perceptrons.html">44 nips-2000-Efficient Learning of Linear Perceptrons</a></p>
<p>17 0.15697017 <a title="55-lsi-17" href="./nips-2000-Robust_Reinforcement_Learning.html">113 nips-2000-Robust Reinforcement Learning</a></p>
<p>18 0.15601903 <a title="55-lsi-18" href="./nips-2000-Kernel-Based_Reinforcement_Learning_in_Average-Cost_Problems%3A_An_Application_to_Optimal_Portfolio_Choice.html">73 nips-2000-Kernel-Based Reinforcement Learning in Average-Cost Problems: An Application to Optimal Portfolio Choice</a></p>
<p>19 0.15138759 <a title="55-lsi-19" href="./nips-2000-Accumulator_Networks%3A_Suitors_of_Local_Probability_Propagation.html">15 nips-2000-Accumulator Networks: Suitors of Local Probability Propagation</a></p>
<p>20 0.15042275 <a title="55-lsi-20" href="./nips-2000-Natural_Sound_Statistics_and_Divisive_Normalization_in_the_Auditory_System.html">89 nips-2000-Natural Sound Statistics and Divisive Normalization in the Auditory System</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2000_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.036), (17, 0.082), (32, 0.017), (33, 0.033), (42, 0.049), (55, 0.018), (62, 0.051), (65, 0.021), (67, 0.041), (76, 0.039), (79, 0.013), (81, 0.114), (87, 0.317), (90, 0.039), (93, 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.82178283 <a title="55-lda-1" href="./nips-2000-Finding_the_Key_to_a_Synapse.html">55 nips-2000-Finding the Key to a Synapse</a></p>
<p>Author: Thomas Natschläger, Wolfgang Maass</p><p>Abstract: Experimental data have shown that synapses are heterogeneous: different synapses respond with different sequences of amplitudes of postsynaptic responses to the same spike train. Neither the role of synaptic dynamics itself nor the role of the heterogeneity of synaptic dynamics for computations in neural circuits is well understood. We present in this article methods that make it feasible to compute for a given synapse with known synaptic parameters the spike train that is optimally fitted to the synapse, for example in the sense that it produces the largest sum of postsynaptic responses. To our surprise we find that most of these optimally fitted spike trains match common firing patterns of specific types of neurons that are discussed in the literature.</p><p>2 0.49347761 <a title="55-lda-2" href="./nips-2000-Processing_of_Time_Series_by_Neural_Circuits_with_Biologically_Realistic_Synaptic_Dynamics.html">104 nips-2000-Processing of Time Series by Neural Circuits with Biologically Realistic Synaptic Dynamics</a></p>
<p>Author: Thomas Natschläger, Wolfgang Maass, Eduardo D. Sontag, Anthony M. Zador</p><p>Abstract: Experimental data show that biological synapses behave quite differently from the symbolic synapses in common artificial neural network models. Biological synapses are dynamic, i.e., their</p><p>3 0.45839721 <a title="55-lda-3" href="./nips-2000-Probabilistic_Semantic_Video_Indexing.html">103 nips-2000-Probabilistic Semantic Video Indexing</a></p>
<p>Author: Milind R. Naphade, Igor Kozintsev, Thomas S. Huang</p><p>Abstract: We propose a novel probabilistic framework for semantic video indexing. We define probabilistic multimedia objects (multijects) to map low-level media features to high-level semantic labels. A graphical network of such multijects (multinet) captures scene context by discovering intra-frame as well as inter-frame dependency relations between the concepts. The main contribution is a novel application of a factor graph framework to model this network. We model relations between semantic concepts in terms of their co-occurrence as well as the temporal dependencies between these concepts within video shots. Using the sum-product algorithm [1] for approximate or exact inference in these factor graph multinets, we attempt to correct errors made during isolated concept detection by forcing high-level constraints. This results in a significant improvement in the overall detection performance. 1</p><p>4 0.45382854 <a title="55-lda-4" href="./nips-2000-The_Unscented_Particle_Filter.html">137 nips-2000-The Unscented Particle Filter</a></p>
<p>Author: Rudolph van der Merwe, Arnaud Doucet, Nando de Freitas, Eric A. Wan</p><p>Abstract: In this paper, we propose a new particle filter based on sequential importance sampling. The algorithm uses a bank of unscented filters to obtain the importance proposal distribution. This proposal has two very</p><p>5 0.45320514 <a title="55-lda-5" href="./nips-2000-Universality_and_Individuality_in_a_Neural_Code.html">141 nips-2000-Universality and Individuality in a Neural Code</a></p>
<p>Author: Elad Schneidman, Naama Brenner, Naftali Tishby, Robert R. de Ruyter van Steveninck, William Bialek</p><p>Abstract: The problem of neural coding is to understand how sequences of action potentials (spikes) are related to sensory stimuli, motor outputs, or (ultimately) thoughts and intentions. One clear question is whether the same coding rules are used by different neurons, or by corresponding neurons in different individuals. We present a quantitative formulation of this problem using ideas from information theory, and apply this approach to the analysis of experiments in the fly visual system. We find significant individual differences in the structure of the code, particularly in the way that temporal patterns of spikes are used to convey information beyond that available from variations in spike rate. On the other hand, all the flies in our ensemble exhibit a high coding efficiency, so that every spike carries the same amount of information in all the individuals. Thus the neural code has a quantifiable mixture of individuality and universality. 1</p><p>6 0.42785215 <a title="55-lda-6" href="./nips-2000-Hippocampally-Dependent_Consolidation_in_a_Hierarchical_Model_of_Neocortex.html">66 nips-2000-Hippocampally-Dependent Consolidation in a Hierarchical Model of Neocortex</a></p>
<p>7 0.42582279 <a title="55-lda-7" href="./nips-2000-Multiple_Timescales_of_Adaptation_in_a_Neural_Code.html">88 nips-2000-Multiple Timescales of Adaptation in a Neural Code</a></p>
<p>8 0.4256314 <a title="55-lda-8" href="./nips-2000-Dendritic_Compartmentalization_Could_Underlie_Competition_and_Attentional_Biasing_of_Simultaneous_Visual_Stimuli.html">40 nips-2000-Dendritic Compartmentalization Could Underlie Competition and Attentional Biasing of Simultaneous Visual Stimuli</a></p>
<p>9 0.41598737 <a title="55-lda-9" href="./nips-2000-What_Can_a_Single_Neuron_Compute%3F.html">146 nips-2000-What Can a Single Neuron Compute?</a></p>
<p>10 0.38613832 <a title="55-lda-10" href="./nips-2000-Dopamine_Bonuses.html">43 nips-2000-Dopamine Bonuses</a></p>
<p>11 0.38354596 <a title="55-lda-11" href="./nips-2000-Explaining_Away_in_Weight_Space.html">49 nips-2000-Explaining Away in Weight Space</a></p>
<p>12 0.38262829 <a title="55-lda-12" href="./nips-2000-The_Early_Word_Catches_the_Weights.html">131 nips-2000-The Early Word Catches the Weights</a></p>
<p>13 0.38023868 <a title="55-lda-13" href="./nips-2000-Learning_Switching_Linear_Models_of_Human_Motion.html">80 nips-2000-Learning Switching Linear Models of Human Motion</a></p>
<p>14 0.37586969 <a title="55-lda-14" href="./nips-2000-Partially_Observable_SDE_Models_for_Image_Sequence_Recognition_Tasks.html">98 nips-2000-Partially Observable SDE Models for Image Sequence Recognition Tasks</a></p>
<p>15 0.36859384 <a title="55-lda-15" href="./nips-2000-A_New_Approximate_Maximal_Margin_Classification_Algorithm.html">7 nips-2000-A New Approximate Maximal Margin Classification Algorithm</a></p>
<p>16 0.36837289 <a title="55-lda-16" href="./nips-2000-Natural_Sound_Statistics_and_Divisive_Normalization_in_the_Auditory_System.html">89 nips-2000-Natural Sound Statistics and Divisive Normalization in the Auditory System</a></p>
<p>17 0.36710995 <a title="55-lda-17" href="./nips-2000-Interactive_Parts_Model%3A_An_Application_to_Recognition_of_On-line_Cursive_Script.html">71 nips-2000-Interactive Parts Model: An Application to Recognition of On-line Cursive Script</a></p>
<p>18 0.36660612 <a title="55-lda-18" href="./nips-2000-Position_Variance%2C_Recurrence_and_Perceptual_Learning.html">102 nips-2000-Position Variance, Recurrence and Perceptual Learning</a></p>
<p>19 0.36616254 <a title="55-lda-19" href="./nips-2000-Periodic_Component_Analysis%3A_An_Eigenvalue_Method_for_Representing_Periodic_Structure_in_Speech.html">99 nips-2000-Periodic Component Analysis: An Eigenvalue Method for Representing Periodic Structure in Speech</a></p>
<p>20 0.36576349 <a title="55-lda-20" href="./nips-2000-Spike-Timing-Dependent_Learning_for_Oscillatory_Networks.html">124 nips-2000-Spike-Timing-Dependent Learning for Oscillatory Networks</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
