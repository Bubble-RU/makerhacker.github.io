<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>89 nips-2000-Natural Sound Statistics and Divisive Normalization in the Auditory System</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2000" href="../home/nips2000_home.html">nips2000</a> <a title="nips-2000-89" href="#">nips2000-89</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>89 nips-2000-Natural Sound Statistics and Divisive Normalization in the Auditory System</h1>
<br/><p>Source: <a title="nips-2000-89-pdf" href="http://papers.nips.cc/paper/1860-natural-sound-statistics-and-divisive-normalization-in-the-auditory-system.pdf">pdf</a></p><p>Author: Odelia Schwartz, Eero P. Simoncelli</p><p>Abstract: We explore the statistical properties of natural sound stimuli preprocessed with a bank of linear filters. The responses of such filters exhibit a striking form of statistical dependency, in which the response variance of each filter grows with the response amplitude of filters tuned for nearby frequencies. These dependencies may be substantially reduced using an operation known as divisive normalization, in which the response of each filter is divided by a weighted sum of the rectified responses of other filters. The weights may be chosen to maximize the independence of the normalized responses for an ensemble of natural sounds. We demonstrate that the resulting model accounts for nonlinearities in the response characteristics of the auditory nerve, by comparing model simulations to electrophysiological recordings. In previous work (NIPS, 1998) we demonstrated that an analogous model derived from the statistics of natural images accounts for non-linear properties of neurons in primary visual cortex. Thus, divisive normalization appears to be a generic mechanism for eliminating a type of statistical dependency that is prevalent in natural signals of different modalities. Signals in the real world are highly structured. For example, natural sounds typically contain both harmonic and rythmic structure. It is reasonable to assume that biological auditory systems are designed to represent these structures in an efficient manner [e.g., 1,2]. Specifically, Barlow hypothesized that a role of early sensory processing is to remove redundancy in the sensory input, resulting in a set of neural responses that are statistically independent. Experimentally, one can test this hypothesis by examining the statistical properties of neural responses under natural stimulation conditions [e.g., 3,4], or the statistical dependency of pairs (or groups) of neural responses. Due to their technical difficulty, such multi-cellular experiments are only recently becoming possible, and the earliest reports in vision appear consistent with the hypothesis [e.g., 5]. An alternative approach, which we follow here, is to develop a neural model from the statistics of natural signals and show that response properties of this model are similar to those of biological sensory neurons. A number of researchers have derived linear filter models using statistical criterion. For visual images, this results in linear filters localized in frequency, orientation and phase [6, 7]. Similar work in audition has yielded filters localized in frequency and phase [8]. Although these linear models provide an important starting point for neural modeling, sensory neurons are highly nonlinear. In addition, the statistical properties of natural signals are too complex to expect a linear transformation to result in an independent set of components. Recent results indicate that nonlinear gain control plays an important role in neural processing. Ruderman and Bialek [9] have shown that division by a local estimate of standard deviation can increase the entropy of responses of center-surround filters to natural images. Such a model is consistent with the properties of neurons in the retina and lateral geniculate nucleus. Heeger and colleagues have shown that the nonlinear behaviors of neurons in primary visual cortex may be described using a form of gain control known as divisive normalization [10], in which the response of a linear kernel is rectified and divided by the sum of other rectified kernel responses and a constant. We have recently shown that the responses of oriented linear filters exhibit nonlinear statistical dependencies that may be substantially reduced using a variant of this model, in which the normalization signal is computed from a weighted sum of other rectified kernel responses [11, 12]. The resulting model, with weighting parameters determined from image statistics, accounts qualitatively for physiological nonlinearities observed in primary visual cortex. In this paper, we demonstrate that the responses of bandpass linear filters to natural sounds exhibit striking statistical dependencies, analogous to those found in visual images. A divisive normalization procedure can substantially remove these dependencies. We show that this model, with parameters optimized for a collection of natural sounds, can account for nonlinear behaviors of neurons at the level of the auditory nerve. Specifically, we show that: 1) the shape offrequency tuning curves varies with sound pressure level, even though the underlying linear filters are fixed; and 2) superposition of a non-optimal tone suppresses the response of a linear filter in a divisive fashion, and the amount of suppression depends on the distance between the frequency of the tone and the preferred frequency of the filter. 1 Empirical observations of natural sound statistics The basic statistical properties of natural sounds, as observed through a linear filter, have been previously documented by Attias [13]. In particular, he showed that, as with visual images, the spectral energy falls roughly according to a power law, and that the histograms of filter responses are more kurtotic than a Gaussian (i.e., they have a sharp peak at zero, and very long tails). Here we examine the joint statistical properties of a pair of linear filters tuned for nearby temporal frequencies. We choose a fixed set of filters that have been widely used in modeling the peripheral auditory system [14]. Figure 1 shows joint histograms of the instantaneous responses of a particular pair of linear filters to five different types of natural sound, and white noise. First note that the responses are approximately decorrelated: the expected value of the y-axis value is roughly zero for all values of the x-axis variable. The responses are not, however, statistically independent: the width of the distribution of responses of one filter increases with the response amplitude of the other filter. If the two responses were statistically independent, then the response of the first filter should not provide any information about the distribution of responses of the other filter. We have found that this type of variance dependency (sometimes accompanied by linear correlation) occurs in a wide range of natural sounds, ranging from animal sounds to music. We emphasize that this dependency is a property of natural sounds, and is not due purely to our choice of linear filters. For example, no such dependency is observed when the input consists of white noise (see Fig. 1). The strength of this dependency varies for different pairs of linear filters . In addition, we see this type of dependency between instantaneous responses of a single filter at two Speech o -1 Drums • Monkey Cat White noise Nocturnal nature I~ ~; ~ • Figure 1: Joint conditional histogram of instantaneous linear responses of two bandpass filters with center frequencies 2000 and 2840 Hz. Pixel intensity corresponds to frequency of occurrence of a given pair of values, except that each column has been independently rescaled to fill the full intensity range. For the natural sounds, responses are not independent: the standard deviation of the ordinate is roughly proportional to the magnitude of the abscissa. Natural sounds were recorded from CDs and converted to sampling frequency of 22050 Hz. nearby time instants. Since the dependency involves the variance of the responses, we can substantially reduce it by dividing. In particular, the response of each filter is divided by a weighted sum of responses of other rectified filters and an additive constant. Specifically: L2 Ri = 2: (1) 12 j WjiLj + 0'2 where Li is the instantaneous linear response of filter i, strength of suppression of filter i by filter j. 0' is a constant and Wji controls the We would like to choose the parameters of the model (the weights Wji, and the constant 0') to optimize the independence of the normalized response to an ensemble of natural sounds. Such an optimization is quite computationally expensive. We instead assume a Gaussian form for the underlying conditional distribution, as described in [15]: P (LiILj,j E Ni ) '</p><p>Reference: <a title="nips-2000-89-reference" href="../nips2000_reference/nips-2000-Natural_Sound_Statistics_and_Divisive_Normalization_in_the_Auditory_System_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Natural sound statistics and divisive normalization in the auditory system  Odelia Schwartz Center for Neural Science New York University odelia@cns. [sent-1, score-1.018]
</p><p>2 edu  Abstract We explore the statistical properties of natural sound stimuli preprocessed with a bank of linear filters. [sent-6, score-0.601]
</p><p>3 The responses of such filters exhibit a striking form of statistical dependency, in which the response variance of each filter grows with the response amplitude of filters tuned for nearby frequencies. [sent-7, score-1.355]
</p><p>4 These dependencies may be substantially reduced using an operation known as divisive normalization, in which the response of each filter is divided by a weighted sum of the rectified responses of other filters. [sent-8, score-1.122]
</p><p>5 The weights may be chosen to maximize the independence of the normalized responses for an ensemble of natural sounds. [sent-9, score-0.596]
</p><p>6 We demonstrate that the resulting model accounts for nonlinearities in the response characteristics of the auditory nerve, by comparing model simulations to electrophysiological recordings. [sent-10, score-0.662]
</p><p>7 In previous work (NIPS, 1998) we demonstrated that an analogous model derived from the statistics of natural images accounts for non-linear properties of neurons in primary visual cortex. [sent-11, score-0.681]
</p><p>8 Thus, divisive normalization appears to be a generic mechanism for eliminating a type of statistical dependency that is prevalent in natural signals of different modalities. [sent-12, score-0.898]
</p><p>9 For example, natural sounds typically contain both harmonic and rythmic structure. [sent-14, score-0.358]
</p><p>10 It is reasonable to assume that biological auditory systems are designed to represent these structures in an efficient manner [e. [sent-15, score-0.298]
</p><p>11 Specifically, Barlow hypothesized that a role of early sensory processing is to remove redundancy in the sensory input, resulting in a set of neural responses that are statistically independent. [sent-18, score-0.541]
</p><p>12 Experimentally, one can test this hypothesis by examining the statistical properties of neural responses under natural stimulation conditions [e. [sent-19, score-0.63]
</p><p>13 , 3,4], or the statistical dependency of pairs (or groups) of neural responses. [sent-21, score-0.251]
</p><p>14 An alternative approach, which we follow here, is to develop a neural model from the statistics of natural signals and show that response properties of this model are similar to those of biological sensory neurons. [sent-25, score-0.674]
</p><p>15 A number of researchers have derived linear filter models using statistical criterion. [sent-26, score-0.313]
</p><p>16 For visual images, this results in linear filters localized in frequency, orientation and phase [6, 7]. [sent-27, score-0.379]
</p><p>17 Similar work in audition has yielded filters localized in frequency and phase [8]. [sent-28, score-0.39]
</p><p>18 Although these linear models provide an important starting point for neural modeling, sensory neurons are highly nonlinear. [sent-29, score-0.219]
</p><p>19 In addition, the statistical properties of natural signals are too complex to expect a linear transformation to result in an independent set of components. [sent-30, score-0.399]
</p><p>20 Recent results indicate that nonlinear gain control plays an important role in neural processing. [sent-31, score-0.182]
</p><p>21 Ruderman and Bialek [9] have shown that division by a local estimate of standard deviation can increase the entropy of responses of center-surround filters to natural images. [sent-32, score-0.713]
</p><p>22 Such a model is consistent with the properties of neurons in the retina and lateral geniculate nucleus. [sent-33, score-0.259]
</p><p>23 We have recently shown that the responses of oriented linear filters exhibit nonlinear statistical dependencies that may be substantially reduced using a variant of this model, in which the normalization signal is computed from a weighted sum of other rectified kernel responses [11, 12]. [sent-35, score-1.415]
</p><p>24 The resulting model, with weighting parameters determined from image statistics, accounts qualitatively for physiological nonlinearities observed in primary visual cortex. [sent-36, score-0.347]
</p><p>25 In this paper, we demonstrate that the responses of bandpass linear filters to natural sounds exhibit striking statistical dependencies, analogous to those found in visual images. [sent-37, score-1.171]
</p><p>26 A divisive normalization procedure can substantially remove these dependencies. [sent-38, score-0.495]
</p><p>27 We show that this model, with parameters optimized for a collection of natural sounds, can account for nonlinear behaviors of neurons at the level of the auditory nerve. [sent-39, score-0.634]
</p><p>28 1 Empirical observations of natural sound statistics The basic statistical properties of natural sounds, as observed through a linear filter, have been previously documented by Attias [13]. [sent-41, score-0.842]
</p><p>29 In particular, he showed that, as with visual images, the spectral energy falls roughly according to a power law, and that the histograms of filter responses are more kurtotic than a Gaussian (i. [sent-42, score-0.671]
</p><p>30 Here we examine the joint statistical properties of a pair of linear filters tuned for nearby temporal frequencies. [sent-45, score-0.555]
</p><p>31 We choose a fixed set of filters that have been widely used in modeling the peripheral auditory system [14]. [sent-46, score-0.56]
</p><p>32 Figure 1 shows joint histograms of the instantaneous responses of a particular pair of linear filters to five different types of natural sound, and white noise. [sent-47, score-0.979]
</p><p>33 First note that the responses are approximately decorrelated: the expected value of the y-axis value is roughly zero for all values of the x-axis variable. [sent-48, score-0.324]
</p><p>34 The responses are not, however, statistically independent: the width of the distribution of responses of one filter increases with the response amplitude of the other filter. [sent-49, score-0.946]
</p><p>35 If the two responses were statistically independent, then the response of the first filter should not provide any information about the distribution of responses of the other filter. [sent-50, score-0.946]
</p><p>36 We have found that this type of variance dependency (sometimes accompanied by linear correlation) occurs in a wide range of natural sounds, ranging from animal sounds to music. [sent-51, score-0.611]
</p><p>37 We emphasize that this dependency is a property of natural sounds, and is not due purely to our choice of linear filters. [sent-52, score-0.421]
</p><p>38 For example, no such dependency is observed when the input consists of white noise (see Fig. [sent-53, score-0.203]
</p><p>39 The strength of this dependency varies for different pairs of linear filters . [sent-55, score-0.535]
</p><p>40 Pixel intensity corresponds to frequency of occurrence of a given pair of values, except that each column has been independently rescaled to fill the full intensity range. [sent-57, score-0.238]
</p><p>41 For the natural sounds, responses are not independent: the standard deviation of the ordinate is roughly proportional to the magnitude of the abscissa. [sent-58, score-0.525]
</p><p>42 Natural sounds were recorded from CDs and converted to sampling frequency of 22050 Hz. [sent-59, score-0.289]
</p><p>43 Since the dependency involves the variance of the responses, we can substantially reduce it by dividing. [sent-61, score-0.219]
</p><p>44 In particular, the response of each filter is divided by a weighted sum of responses of other rectified filters and an additive constant. [sent-62, score-1.026]
</p><p>45 Specifically: L2  Ri  = 2:  (1)  12  j  WjiLj + 0'2  where Li is the instantaneous linear response of filter i, strength of suppression of filter i by filter j. [sent-63, score-1.038]
</p><p>46 0'  is a constant and Wji controls the  We would like to choose the parameters of the model (the weights Wji, and the constant 0') to optimize the independence of the normalized response to an ensemble of natural sounds. [sent-64, score-0.472]
</p><p>47 We instead assume a Gaussian form for the underlying conditional distribution, as described in [15]:  P (LiILj,j E Ni ) '" N(O;  L wjiL; +  0'2)  j  where Ni is the neighborhood of linear filters that may affect filter i. [sent-66, score-0.524]
</p><p>48 We then maximize this expression over the sound data at each time t to obtain the parameters:  (2)  We solve for the optimal parameters numerically, using conjugate gradient descent. [sent-67, score-0.203]
</p><p>49 , doubling the input strength would lead to a doubling of 0') . [sent-70, score-0.158]
</p><p>50 4  I  I  I : 0 \,-_ _ _ _----:--' I I  I  Other squared I filter resRonses \ I  I  ,  *'  I  Other squared filter responses  Figure 2: Nonlinear whitening of a natural auditory signal with a divisive normalization model. [sent-71, score-1.648]
</p><p>51 The histogram on the left shows the statistical dependency of the responses of two linear bandpass filters. [sent-72, score-0.663]
</p><p>52 The joint histogram on the right shows the approximate independence of the normalized coefficients. [sent-73, score-0.145]
</p><p>53 A natural sound is passed through a bank of linear filters (only 2 depicted for readability). [sent-75, score-0.716]
</p><p>54 The responses of the filters to a natural sound exhibit a strong statistical dependency. [sent-76, score-1.006]
</p><p>55 Normalization largely removes this dependency, such that vertical cross sections through the joint conditional histogram are all roughly the same. [sent-77, score-0.14]
</p><p>56 For the simulations in the next section, we use a set of Gammatone filters as the linear front end [14]. [sent-78, score-0.279]
</p><p>57 We choose a primary filter with center frequency 2000 Hz. [sent-79, score-0.461]
</p><p>58 We also choose a neighborhood of filters for the normalization signal: 16 filters with center frequencies 205 to 4768 Hz, and replicas of all filters temporally shifted by 100, 200, and 300 samples. [sent-80, score-0.963]
</p><p>59 We compute optimal values for u and the normalization weights Wj using equation (2), based on statistics of a natural sound ensemble containing 9 animal and speech sounds, each approximately 6 seconds long. [sent-81, score-0.786]
</p><p>60 physiology We compare the normalized responses of the primary filter in our model (with all parameter values held fixed at the optimal values described above) to data recorded electrophysiologically from auditory nerve. [sent-83, score-0.958]
</p><p>61 Figure 3 shows data from a "two-tone suppression" experiment, in which the response to an optimal tone is suppressed by the presence of a second tone of non-optimal frequency. [sent-84, score-0.675]
</p><p>62 Two-tone suppression is often demonstrated by showing that the rate-level function of the optimal tone alone is shifted to the right in the presence of a non-optimal tone. [sent-85, score-0.405]
</p><p>63 In both cell and model, we obtain a larger rightward shift when the non-optimal tone is relatively close in frequency to the optimal tone, and almost no rightward shift when the non-optimal tone is more than two times the optimal frequency. [sent-86, score-0.876]
</p><p>64 In the model, this behavior is due to the fact that the strength of statistical dependency (and thus the strength of normalization weighting) falls with the frequency separation of a pair of filters. [sent-87, score-0.73]
</p><p>65 , 1978) 120 ,---~-~-~-~-~_____,  --e- no mask  -e-e-  Q)  -e-  mask  ~ 100  = 1. [sent-89, score-0.22]
</p><p>66 1  60  "0  c  40  ro  Q)  ::;; 20  30  40  50  60  Decibels  70  80  1ro ,-------~-~-~_____,  -e-  Q)  "§ 100  -e-  20  30  70  80  --e- no mask  -e-  mask = 1. [sent-93, score-0.362]
</p><p>67 5S·CF  Q)  ~ 80  ro  J:::  ~ 6O  '6  c 40  ro  Q)  ::;; ro 50  60  Decibels  70  80  20  30  70  80  m  80  --e- no mask mask = 2. [sent-94, score-0.646]
</p><p>68 00*CF  Q)  ~ 100 Q)  ~ 80  ro  J:::  ~ 6O  '6  c 40  ro Q)  ::;; ro 40  50  60  Decibels  70  80  ro  30  40  60  60  Decibels  Figure 3: Two tone suppression data. [sent-95, score-0.973]
</p><p>69 Each plot shows neural response as a function of SPL for a single tone (circles), and for a tone in the presence of a secondary suppressive tone at 80 dB SPL (squares). [sent-96, score-1.032]
</p><p>70 The maximum mean response rate in the model is scaled to fit the cell data. [sent-97, score-0.263]
</p><p>71 , 1971) 120' , - - - - - - - - - - - - - - - - , OJ 100  1;;  ;U  80  ~  rn  J:::60  o  en '6 40 c rn OJ  ::;; 20  Frequency  Frequency  Figure 4: Frequency tuning curves for cell and model for different sound pressure levels. [sent-100, score-0.503]
</p><p>72 Figure 4 shows frequency tuning for different sound pressure levels. [sent-102, score-0.489]
</p><p>73 As the sound pressure level (SPL) increases, the frequency tuning becomes broader, developing a "shoulder" and a secondary mode. [sent-103, score-0.535]
</p><p>74 Both cell and model show similar behavior, despite the fact that we are not fitting the model to these data: all parameters in the model are chosen by optimizing the independence of the responses to the ensemble of natural sound statistics. [sent-104, score-1.033]
</p><p>75 This result is particularly interesting because the data have been in the literature for many years, and are generally interpreted to mean that the frequency tuning properties of these cells varies with SPL. [sent-105, score-0.307]
</p><p>76 Our model suggests an alternative interpretation: the fundamental frequency tuning is determined by a fixed linear kernel, and is modulated by a divisive nonlinearity. [sent-106, score-0.538]
</p><p>77 3 Discussion We have developed a weighted divisive normalization model for early auditory processing. [sent-107, score-0.86]
</p><p>78 Both the form and parameters of the model are determined from natural sound statistics. [sent-108, score-0.448]
</p><p>79 We have shown that the model can account for some prominent nonlinearities occurring at the level of the auditory nerve. [sent-109, score-0.452]
</p><p>80 A number of authors have suggested forms of divisive gain control in auditory models. [sent-110, score-0.645]
</p><p>81 [18] suggest that gain control in early auditory processing is consistent with psychophysical data and might be advantageous for applications of noise removal. [sent-112, score-0.45]
</p><p>82 Our work may provide theoretical justification for such models of divisive gain control in the auditory system. [sent-116, score-0.645]
</p><p>83 In particular, normalization must be presumably implemented using lateral or feedback connections between neurons [e. [sent-119, score-0.349]
</p><p>84 The normalization signal of the model is computed and applied instantaneously, and thus lacks temporal dynamical properties [e. [sent-122, score-0.384]
</p><p>85 In addition, we have not made any distinction between nonlinearities that arise mechanically in the cochlea, and nonlinearities that arise at the neural level. [sent-125, score-0.252]
</p><p>86 It is likely that normalization occurs at least partially in outer hair cells [21,22]. [sent-126, score-0.252]
</p><p>87 Our modeling uses parameters optimized for a fixed ensemble of natural sounds. [sent-128, score-0.302]
</p><p>88 It seems likely that the model can be extended to account for levels of processing beyond the auditory nerve. [sent-131, score-0.342]
</p><p>89 [23] suggest that co-modulation masking release in auditory cortex results from the statistical structure of natural sound. [sent-133, score-0.582]
</p><p>90 But ultimately, it seems likely that one must also consider the auditory tasks, such as localization and recognition, that the organism must perform. [sent-134, score-0.298]
</p><p>91 Efficient coding of natural scenes in the lateral geniculate nucleus: Experimental test of a computational theory. [sent-145, score-0.288]
</p><p>92 Sparse coding and decorrelation in primary visual cortex during natural vision. [sent-152, score-0.384]
</p><p>93 The 'independent components' of natural scenes are edge filters. [sent-158, score-0.201]
</p><p>94 Natural image statistics and divisive normalization: Modeling nonlinearities and adaptation in cortical neurons. [sent-183, score-0.417]
</p><p>95 An efficient implementation of the patterson and holdworth auditory filter bank. [sent-192, score-0.508]
</p><p>96 Modeling the joint statistics of images in the wavelet domain. [sent-195, score-0.157]
</p><p>97 Two-tone suppression in auditory nerve of the cat: Rateintensity and temporal analyses. [sent-199, score-0.539]
</p><p>98 Some effects of stimulus intensity on response of auditory nerve fibers in the squirell monkey. [sent-206, score-0.532]
</p><p>99 Linearity and normalization in simple cells of the macaque primary visual cortex. [sent-220, score-0.361]
</p><p>100 Responses of auditory-cortex neurons to structural features of natural sounds. [sent-229, score-0.268]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('auditory', 0.298), ('responses', 0.285), ('tone', 0.279), ('divisive', 0.234), ('filters', 0.227), ('filter', 0.21), ('normalization', 0.21), ('sound', 0.203), ('natural', 0.201), ('dependency', 0.168), ('sounds', 0.157), ('ro', 0.142), ('frequency', 0.132), ('suppression', 0.126), ('response', 0.117), ('mask', 0.11), ('nonlinearities', 0.11), ('decibels', 0.108), ('rectified', 0.105), ('cell', 0.102), ('primary', 0.082), ('nerve', 0.081), ('spl', 0.081), ('pressure', 0.078), ('tuning', 0.076), ('statistics', 0.073), ('visual', 0.069), ('sensory', 0.068), ('gain', 0.067), ('neurons', 0.067), ('ensemble', 0.066), ('instantaneous', 0.063), ('properties', 0.061), ('cat', 0.058), ('bandpass', 0.055), ('attias', 0.055), ('adv', 0.054), ('doubling', 0.054), ('javel', 0.054), ('nelken', 0.054), ('odelia', 0.054), ('wji', 0.054), ('histogram', 0.052), ('linear', 0.052), ('cf', 0.052), ('statistical', 0.051), ('substantially', 0.051), ('strength', 0.05), ('statistically', 0.049), ('accounts', 0.049), ('joint', 0.049), ('nearby', 0.047), ('divided', 0.047), ('heeger', 0.046), ('info', 0.046), ('geniculate', 0.046), ('secondary', 0.046), ('schwartz', 0.046), ('control', 0.046), ('independence', 0.044), ('model', 0.044), ('rightward', 0.042), ('simoncelli', 0.042), ('hair', 0.042), ('lateral', 0.041), ('early', 0.039), ('roughly', 0.039), ('exhibit', 0.039), ('physiology', 0.039), ('ruderman', 0.039), ('varies', 0.038), ('dependencies', 0.038), ('center', 0.037), ('nonlinear', 0.037), ('olshausen', 0.037), ('physiological', 0.037), ('wang', 0.037), ('intensity', 0.036), ('modeling', 0.035), ('weighted', 0.035), ('white', 0.035), ('images', 0.035), ('striking', 0.035), ('neighborhood', 0.035), ('ni', 0.035), ('lacks', 0.035), ('falls', 0.035), ('pair', 0.034), ('temporal', 0.034), ('signals', 0.034), ('bank', 0.033), ('histograms', 0.033), ('animal', 0.033), ('cortex', 0.032), ('volume', 0.032), ('neural', 0.032), ('bell', 0.031), ('localized', 0.031), ('presumably', 0.031), ('behaviors', 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="89-tfidf-1" href="./nips-2000-Natural_Sound_Statistics_and_Divisive_Normalization_in_the_Auditory_System.html">89 nips-2000-Natural Sound Statistics and Divisive Normalization in the Auditory System</a></p>
<p>Author: Odelia Schwartz, Eero P. Simoncelli</p><p>Abstract: We explore the statistical properties of natural sound stimuli preprocessed with a bank of linear filters. The responses of such filters exhibit a striking form of statistical dependency, in which the response variance of each filter grows with the response amplitude of filters tuned for nearby frequencies. These dependencies may be substantially reduced using an operation known as divisive normalization, in which the response of each filter is divided by a weighted sum of the rectified responses of other filters. The weights may be chosen to maximize the independence of the normalized responses for an ensemble of natural sounds. We demonstrate that the resulting model accounts for nonlinearities in the response characteristics of the auditory nerve, by comparing model simulations to electrophysiological recordings. In previous work (NIPS, 1998) we demonstrated that an analogous model derived from the statistics of natural images accounts for non-linear properties of neurons in primary visual cortex. Thus, divisive normalization appears to be a generic mechanism for eliminating a type of statistical dependency that is prevalent in natural signals of different modalities. Signals in the real world are highly structured. For example, natural sounds typically contain both harmonic and rythmic structure. It is reasonable to assume that biological auditory systems are designed to represent these structures in an efficient manner [e.g., 1,2]. Specifically, Barlow hypothesized that a role of early sensory processing is to remove redundancy in the sensory input, resulting in a set of neural responses that are statistically independent. Experimentally, one can test this hypothesis by examining the statistical properties of neural responses under natural stimulation conditions [e.g., 3,4], or the statistical dependency of pairs (or groups) of neural responses. Due to their technical difficulty, such multi-cellular experiments are only recently becoming possible, and the earliest reports in vision appear consistent with the hypothesis [e.g., 5]. An alternative approach, which we follow here, is to develop a neural model from the statistics of natural signals and show that response properties of this model are similar to those of biological sensory neurons. A number of researchers have derived linear filter models using statistical criterion. For visual images, this results in linear filters localized in frequency, orientation and phase [6, 7]. Similar work in audition has yielded filters localized in frequency and phase [8]. Although these linear models provide an important starting point for neural modeling, sensory neurons are highly nonlinear. In addition, the statistical properties of natural signals are too complex to expect a linear transformation to result in an independent set of components. Recent results indicate that nonlinear gain control plays an important role in neural processing. Ruderman and Bialek [9] have shown that division by a local estimate of standard deviation can increase the entropy of responses of center-surround filters to natural images. Such a model is consistent with the properties of neurons in the retina and lateral geniculate nucleus. Heeger and colleagues have shown that the nonlinear behaviors of neurons in primary visual cortex may be described using a form of gain control known as divisive normalization [10], in which the response of a linear kernel is rectified and divided by the sum of other rectified kernel responses and a constant. We have recently shown that the responses of oriented linear filters exhibit nonlinear statistical dependencies that may be substantially reduced using a variant of this model, in which the normalization signal is computed from a weighted sum of other rectified kernel responses [11, 12]. The resulting model, with weighting parameters determined from image statistics, accounts qualitatively for physiological nonlinearities observed in primary visual cortex. In this paper, we demonstrate that the responses of bandpass linear filters to natural sounds exhibit striking statistical dependencies, analogous to those found in visual images. A divisive normalization procedure can substantially remove these dependencies. We show that this model, with parameters optimized for a collection of natural sounds, can account for nonlinear behaviors of neurons at the level of the auditory nerve. Specifically, we show that: 1) the shape offrequency tuning curves varies with sound pressure level, even though the underlying linear filters are fixed; and 2) superposition of a non-optimal tone suppresses the response of a linear filter in a divisive fashion, and the amount of suppression depends on the distance between the frequency of the tone and the preferred frequency of the filter. 1 Empirical observations of natural sound statistics The basic statistical properties of natural sounds, as observed through a linear filter, have been previously documented by Attias [13]. In particular, he showed that, as with visual images, the spectral energy falls roughly according to a power law, and that the histograms of filter responses are more kurtotic than a Gaussian (i.e., they have a sharp peak at zero, and very long tails). Here we examine the joint statistical properties of a pair of linear filters tuned for nearby temporal frequencies. We choose a fixed set of filters that have been widely used in modeling the peripheral auditory system [14]. Figure 1 shows joint histograms of the instantaneous responses of a particular pair of linear filters to five different types of natural sound, and white noise. First note that the responses are approximately decorrelated: the expected value of the y-axis value is roughly zero for all values of the x-axis variable. The responses are not, however, statistically independent: the width of the distribution of responses of one filter increases with the response amplitude of the other filter. If the two responses were statistically independent, then the response of the first filter should not provide any information about the distribution of responses of the other filter. We have found that this type of variance dependency (sometimes accompanied by linear correlation) occurs in a wide range of natural sounds, ranging from animal sounds to music. We emphasize that this dependency is a property of natural sounds, and is not due purely to our choice of linear filters. For example, no such dependency is observed when the input consists of white noise (see Fig. 1). The strength of this dependency varies for different pairs of linear filters . In addition, we see this type of dependency between instantaneous responses of a single filter at two Speech o -1 Drums • Monkey Cat White noise Nocturnal nature I~ ~; ~ • Figure 1: Joint conditional histogram of instantaneous linear responses of two bandpass filters with center frequencies 2000 and 2840 Hz. Pixel intensity corresponds to frequency of occurrence of a given pair of values, except that each column has been independently rescaled to fill the full intensity range. For the natural sounds, responses are not independent: the standard deviation of the ordinate is roughly proportional to the magnitude of the abscissa. Natural sounds were recorded from CDs and converted to sampling frequency of 22050 Hz. nearby time instants. Since the dependency involves the variance of the responses, we can substantially reduce it by dividing. In particular, the response of each filter is divided by a weighted sum of responses of other rectified filters and an additive constant. Specifically: L2 Ri = 2: (1) 12 j WjiLj + 0'2 where Li is the instantaneous linear response of filter i, strength of suppression of filter i by filter j. 0' is a constant and Wji controls the We would like to choose the parameters of the model (the weights Wji, and the constant 0') to optimize the independence of the normalized response to an ensemble of natural sounds. Such an optimization is quite computationally expensive. We instead assume a Gaussian form for the underlying conditional distribution, as described in [15]: P (LiILj,j E Ni ) '</p><p>2 0.17916915 <a title="89-tfidf-2" href="./nips-2000-A_New_Model_of_Spatial_Representation_in_Multimodal_Brain_Areas.html">8 nips-2000-A New Model of Spatial Representation in Multimodal Brain Areas</a></p>
<p>Author: Sophie Denève, Jean-René Duhamel, Alexandre Pouget</p><p>Abstract: Most models of spatial representations in the cortex assume cells with limited receptive fields that are defined in a particular egocentric frame of reference. However, cells outside of primary sensory cortex are either gain modulated by postural input or partially shifting. We show that solving classical spatial tasks, like sensory prediction, multi-sensory integration, sensory-motor transformation and motor control requires more complicated intermediate representations that are not invariant in one frame of reference. We present an iterative basis function map that performs these spatial tasks optimally with gain modulated and partially shifting units, and tests it against neurophysiological and neuropsychological data. In order to perform an action directed toward an object, it is necessary to have a representation of its spatial location. The brain must be able to use spatial cues coming from different modalities (e.g. vision, audition, touch, proprioception), combine them to infer the position of the object, and compute the appropriate movement. These cues are in different frames of reference corresponding to different sensory or motor modalities. Visual inputs are primarily encoded in retinotopic maps, auditory inputs are encoded in head centered maps and tactile cues are encoded in skin-centered maps. Going from one frame of reference to the other might seem easy. For example, the head-centered position of an object can be approximated by the sum of its retinotopic position and the eye position. However, positions are represented by population codes in the brain, and computing a head-centered map from a retinotopic map is a more complex computation than the underlying sum. Moreover, as we get closer to sensory-motor areas it seems reasonable to assume Spksls 150 100 50 o Figure 1: Response of a VIP cell to visual stimuli appearing in different part of the screen, for three different eye positions. The level of grey represent the frequency of discharge (In spikes per seconds). The white cross is the fixation point (the head is fixed). The cell's receptive field is moving with the eyes, but only partially. Here the receptive field shift is 60% of the total gaze shift. Moreover this cell is gain modulated by eye position (adapted from Duhamel et al). that the representations should be useful for sensory-motor transformations, rather than encode an</p><p>3 0.1542206 <a title="89-tfidf-3" href="./nips-2000-Noise_Suppression_Based_on_Neurophysiologically-motivated_SNR_Estimation_for_Robust_Speech_Recognition.html">91 nips-2000-Noise Suppression Based on Neurophysiologically-motivated SNR Estimation for Robust Speech Recognition</a></p>
<p>Author: Jürgen Tchorz, Michael Kleinschmidt, Birger Kollmeier</p><p>Abstract: A novel noise suppression scheme for speech signals is proposed which is based on a neurophysiologically-motivated estimation of the local signal-to-noise ratio (SNR) in different frequency channels. For SNR-estimation, the input signal is transformed into so-called Amplitude Modulation Spectrograms (AMS), which represent both spectral and temporal characteristics of the respective analysis frame, and which imitate the representation of modulation frequencies in higher stages of the mammalian auditory system. A neural network is used to analyse AMS patterns generated from noisy speech and estimates the local SNR. Noise suppression is achieved by attenuating frequency channels according to their SNR. The noise suppression algorithm is evaluated in speakerindependent digit recognition experiments and compared to noise suppression by Spectral Subtraction. 1</p><p>4 0.15403619 <a title="89-tfidf-4" href="./nips-2000-Divisive_and_Subtractive_Mask_Effects%3A_Linking_Psychophysics_and_Biophysics.html">42 nips-2000-Divisive and Subtractive Mask Effects: Linking Psychophysics and Biophysics</a></p>
<p>Author: Barbara Zenger, Christof Koch</p><p>Abstract: We describe an analogy between psychophysically measured effects in contrast masking, and the behavior of a simple integrate-andfire neuron that receives time-modulated inhibition. In the psychophysical experiments, we tested observers ability to discriminate contrasts of peripheral Gabor patches in the presence of collinear Gabor flankers. The data reveal a complex interaction pattern that we account for by assuming that flankers provide divisive inhibition to the target unit for low target contrasts, but provide subtractive inhibition to the target unit for higher target contrasts. A similar switch from divisive to subtractive inhibition is observed in an integrate-and-fire unit that receives inhibition modulated in time such that the cell spends part of the time in a high-inhibition state and part of the time in a low-inhibition state. The similarity between the effects suggests that one may cause the other. The biophysical model makes testable predictions for physiological single-cell recordings. 1 Psychophysics Visual images of Gabor patches are thought to excite a small and specific subset of neurons in the primary visual cortex and beyond. By measuring psychophysically in humans the contrast detection and discrimination thresholds of peripheral Gabor patches, one can estimate the sensitivity of this subset of neurons. Furthermore, spatial interactions between different neuronal populations can be probed by testing the effects of additional Gabor patches (masks) on performance. Such experiments have revealed a highly configuration-specific pattern of excitatory and inhibitory spatial interactions [1, 2]. 1.1 Methods Two vertical Gabor patches with a spatial frequency of 4cyc/deg were presented at 4 deg eccentricity left and right of fixation, and observers had to report which patch had the higher contrast (spatial 2AFC). In the</p><p>5 0.14425139 <a title="89-tfidf-5" href="./nips-2000-Processing_of_Time_Series_by_Neural_Circuits_with_Biologically_Realistic_Synaptic_Dynamics.html">104 nips-2000-Processing of Time Series by Neural Circuits with Biologically Realistic Synaptic Dynamics</a></p>
<p>Author: Thomas Natschläger, Wolfgang Maass, Eduardo D. Sontag, Anthony M. Zador</p><p>Abstract: Experimental data show that biological synapses behave quite differently from the symbolic synapses in common artificial neural network models. Biological synapses are dynamic, i.e., their</p><p>6 0.14097293 <a title="89-tfidf-6" href="./nips-2000-Higher-Order_Statistical_Properties_Arising_from_the_Non-Stationarity_of_Natural_Signals.html">65 nips-2000-Higher-Order Statistical Properties Arising from the Non-Stationarity of Natural Signals</a></p>
<p>7 0.13522236 <a title="89-tfidf-7" href="./nips-2000-Multiple_Timescales_of_Adaptation_in_a_Neural_Code.html">88 nips-2000-Multiple Timescales of Adaptation in a Neural Code</a></p>
<p>8 0.12783356 <a title="89-tfidf-8" href="./nips-2000-Explaining_Away_in_Weight_Space.html">49 nips-2000-Explaining Away in Weight Space</a></p>
<p>9 0.12345298 <a title="89-tfidf-9" href="./nips-2000-Place_Cells_and_Spatial_Navigation_Based_on_2D_Visual_Feature_Extraction%2C_Path_Integration%2C_and_Reinforcement_Learning.html">101 nips-2000-Place Cells and Spatial Navigation Based on 2D Visual Feature Extraction, Path Integration, and Reinforcement Learning</a></p>
<p>10 0.1230951 <a title="89-tfidf-10" href="./nips-2000-One_Microphone_Source_Separation.html">96 nips-2000-One Microphone Source Separation</a></p>
<p>11 0.11225614 <a title="89-tfidf-11" href="./nips-2000-A_Comparison_of_Image_Processing_Techniques_for_Visual_Speech_Recognition_Applications.html">2 nips-2000-A Comparison of Image Processing Techniques for Visual Speech Recognition Applications</a></p>
<p>12 0.10654561 <a title="89-tfidf-12" href="./nips-2000-Periodic_Component_Analysis%3A_An_Eigenvalue_Method_for_Representing_Periodic_Structure_in_Speech.html">99 nips-2000-Periodic Component Analysis: An Eigenvalue Method for Representing Periodic Structure in Speech</a></p>
<p>13 0.10446048 <a title="89-tfidf-13" href="./nips-2000-Dendritic_Compartmentalization_Could_Underlie_Competition_and_Attentional_Biasing_of_Simultaneous_Visual_Stimuli.html">40 nips-2000-Dendritic Compartmentalization Could Underlie Competition and Attentional Biasing of Simultaneous Visual Stimuli</a></p>
<p>14 0.10215869 <a title="89-tfidf-14" href="./nips-2000-Emergence_of_Movement_Sensitive_Neurons%27_Properties_by_Learning_a_Sparse_Code_for_Natural_Moving_Images.html">45 nips-2000-Emergence of Movement Sensitive Neurons' Properties by Learning a Sparse Code for Natural Moving Images</a></p>
<p>15 0.099072911 <a title="89-tfidf-15" href="./nips-2000-Learning_Joint_Statistical_Models_for_Audio-Visual_Fusion_and_Segregation.html">78 nips-2000-Learning Joint Statistical Models for Audio-Visual Fusion and Segregation</a></p>
<p>16 0.093411095 <a title="89-tfidf-16" href="./nips-2000-Redundancy_and_Dimensionality_Reduction_in_Sparse-Distributed_Representations_of_Natural_Objects_in_Terms_of_Their_Local_Features.html">109 nips-2000-Redundancy and Dimensionality Reduction in Sparse-Distributed Representations of Natural Objects in Terms of Their Local Features</a></p>
<p>17 0.090810992 <a title="89-tfidf-17" href="./nips-2000-The_Unscented_Particle_Filter.html">137 nips-2000-The Unscented Particle Filter</a></p>
<p>18 0.08555866 <a title="89-tfidf-18" href="./nips-2000-A_Productive%2C_Systematic_Framework_for_the_Representation_of_Visual_Structure.html">10 nips-2000-A Productive, Systematic Framework for the Representation of Visual Structure</a></p>
<p>19 0.082160458 <a title="89-tfidf-19" href="./nips-2000-Color_Opponency_Constitutes_a_Sparse_Representation_for_the_Chromatic_Structure_of_Natural_Scenes.html">32 nips-2000-Color Opponency Constitutes a Sparse Representation for the Chromatic Structure of Natural Scenes</a></p>
<p>20 0.078345701 <a title="89-tfidf-20" href="./nips-2000-Spike-Timing-Dependent_Learning_for_Oscillatory_Networks.html">124 nips-2000-Spike-Timing-Dependent Learning for Oscillatory Networks</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2000_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.232), (1, -0.246), (2, -0.085), (3, 0.153), (4, -0.081), (5, -0.039), (6, -0.041), (7, -0.117), (8, 0.162), (9, -0.11), (10, 0.025), (11, 0.06), (12, -0.104), (13, 0.054), (14, 0.1), (15, -0.146), (16, 0.021), (17, 0.17), (18, -0.084), (19, -0.053), (20, -0.027), (21, 0.01), (22, -0.093), (23, -0.036), (24, 0.209), (25, -0.125), (26, -0.018), (27, 0.05), (28, 0.113), (29, -0.112), (30, 0.064), (31, 0.05), (32, -0.036), (33, 0.081), (34, -0.091), (35, 0.142), (36, -0.055), (37, -0.088), (38, 0.007), (39, 0.123), (40, -0.027), (41, -0.015), (42, 0.014), (43, -0.08), (44, 0.026), (45, 0.134), (46, -0.013), (47, -0.002), (48, 0.009), (49, 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97866744 <a title="89-lsi-1" href="./nips-2000-Natural_Sound_Statistics_and_Divisive_Normalization_in_the_Auditory_System.html">89 nips-2000-Natural Sound Statistics and Divisive Normalization in the Auditory System</a></p>
<p>Author: Odelia Schwartz, Eero P. Simoncelli</p><p>Abstract: We explore the statistical properties of natural sound stimuli preprocessed with a bank of linear filters. The responses of such filters exhibit a striking form of statistical dependency, in which the response variance of each filter grows with the response amplitude of filters tuned for nearby frequencies. These dependencies may be substantially reduced using an operation known as divisive normalization, in which the response of each filter is divided by a weighted sum of the rectified responses of other filters. The weights may be chosen to maximize the independence of the normalized responses for an ensemble of natural sounds. We demonstrate that the resulting model accounts for nonlinearities in the response characteristics of the auditory nerve, by comparing model simulations to electrophysiological recordings. In previous work (NIPS, 1998) we demonstrated that an analogous model derived from the statistics of natural images accounts for non-linear properties of neurons in primary visual cortex. Thus, divisive normalization appears to be a generic mechanism for eliminating a type of statistical dependency that is prevalent in natural signals of different modalities. Signals in the real world are highly structured. For example, natural sounds typically contain both harmonic and rythmic structure. It is reasonable to assume that biological auditory systems are designed to represent these structures in an efficient manner [e.g., 1,2]. Specifically, Barlow hypothesized that a role of early sensory processing is to remove redundancy in the sensory input, resulting in a set of neural responses that are statistically independent. Experimentally, one can test this hypothesis by examining the statistical properties of neural responses under natural stimulation conditions [e.g., 3,4], or the statistical dependency of pairs (or groups) of neural responses. Due to their technical difficulty, such multi-cellular experiments are only recently becoming possible, and the earliest reports in vision appear consistent with the hypothesis [e.g., 5]. An alternative approach, which we follow here, is to develop a neural model from the statistics of natural signals and show that response properties of this model are similar to those of biological sensory neurons. A number of researchers have derived linear filter models using statistical criterion. For visual images, this results in linear filters localized in frequency, orientation and phase [6, 7]. Similar work in audition has yielded filters localized in frequency and phase [8]. Although these linear models provide an important starting point for neural modeling, sensory neurons are highly nonlinear. In addition, the statistical properties of natural signals are too complex to expect a linear transformation to result in an independent set of components. Recent results indicate that nonlinear gain control plays an important role in neural processing. Ruderman and Bialek [9] have shown that division by a local estimate of standard deviation can increase the entropy of responses of center-surround filters to natural images. Such a model is consistent with the properties of neurons in the retina and lateral geniculate nucleus. Heeger and colleagues have shown that the nonlinear behaviors of neurons in primary visual cortex may be described using a form of gain control known as divisive normalization [10], in which the response of a linear kernel is rectified and divided by the sum of other rectified kernel responses and a constant. We have recently shown that the responses of oriented linear filters exhibit nonlinear statistical dependencies that may be substantially reduced using a variant of this model, in which the normalization signal is computed from a weighted sum of other rectified kernel responses [11, 12]. The resulting model, with weighting parameters determined from image statistics, accounts qualitatively for physiological nonlinearities observed in primary visual cortex. In this paper, we demonstrate that the responses of bandpass linear filters to natural sounds exhibit striking statistical dependencies, analogous to those found in visual images. A divisive normalization procedure can substantially remove these dependencies. We show that this model, with parameters optimized for a collection of natural sounds, can account for nonlinear behaviors of neurons at the level of the auditory nerve. Specifically, we show that: 1) the shape offrequency tuning curves varies with sound pressure level, even though the underlying linear filters are fixed; and 2) superposition of a non-optimal tone suppresses the response of a linear filter in a divisive fashion, and the amount of suppression depends on the distance between the frequency of the tone and the preferred frequency of the filter. 1 Empirical observations of natural sound statistics The basic statistical properties of natural sounds, as observed through a linear filter, have been previously documented by Attias [13]. In particular, he showed that, as with visual images, the spectral energy falls roughly according to a power law, and that the histograms of filter responses are more kurtotic than a Gaussian (i.e., they have a sharp peak at zero, and very long tails). Here we examine the joint statistical properties of a pair of linear filters tuned for nearby temporal frequencies. We choose a fixed set of filters that have been widely used in modeling the peripheral auditory system [14]. Figure 1 shows joint histograms of the instantaneous responses of a particular pair of linear filters to five different types of natural sound, and white noise. First note that the responses are approximately decorrelated: the expected value of the y-axis value is roughly zero for all values of the x-axis variable. The responses are not, however, statistically independent: the width of the distribution of responses of one filter increases with the response amplitude of the other filter. If the two responses were statistically independent, then the response of the first filter should not provide any information about the distribution of responses of the other filter. We have found that this type of variance dependency (sometimes accompanied by linear correlation) occurs in a wide range of natural sounds, ranging from animal sounds to music. We emphasize that this dependency is a property of natural sounds, and is not due purely to our choice of linear filters. For example, no such dependency is observed when the input consists of white noise (see Fig. 1). The strength of this dependency varies for different pairs of linear filters . In addition, we see this type of dependency between instantaneous responses of a single filter at two Speech o -1 Drums • Monkey Cat White noise Nocturnal nature I~ ~; ~ • Figure 1: Joint conditional histogram of instantaneous linear responses of two bandpass filters with center frequencies 2000 and 2840 Hz. Pixel intensity corresponds to frequency of occurrence of a given pair of values, except that each column has been independently rescaled to fill the full intensity range. For the natural sounds, responses are not independent: the standard deviation of the ordinate is roughly proportional to the magnitude of the abscissa. Natural sounds were recorded from CDs and converted to sampling frequency of 22050 Hz. nearby time instants. Since the dependency involves the variance of the responses, we can substantially reduce it by dividing. In particular, the response of each filter is divided by a weighted sum of responses of other rectified filters and an additive constant. Specifically: L2 Ri = 2: (1) 12 j WjiLj + 0'2 where Li is the instantaneous linear response of filter i, strength of suppression of filter i by filter j. 0' is a constant and Wji controls the We would like to choose the parameters of the model (the weights Wji, and the constant 0') to optimize the independence of the normalized response to an ensemble of natural sounds. Such an optimization is quite computationally expensive. We instead assume a Gaussian form for the underlying conditional distribution, as described in [15]: P (LiILj,j E Ni ) '</p><p>2 0.60639036 <a title="89-lsi-2" href="./nips-2000-Divisive_and_Subtractive_Mask_Effects%3A_Linking_Psychophysics_and_Biophysics.html">42 nips-2000-Divisive and Subtractive Mask Effects: Linking Psychophysics and Biophysics</a></p>
<p>Author: Barbara Zenger, Christof Koch</p><p>Abstract: We describe an analogy between psychophysically measured effects in contrast masking, and the behavior of a simple integrate-andfire neuron that receives time-modulated inhibition. In the psychophysical experiments, we tested observers ability to discriminate contrasts of peripheral Gabor patches in the presence of collinear Gabor flankers. The data reveal a complex interaction pattern that we account for by assuming that flankers provide divisive inhibition to the target unit for low target contrasts, but provide subtractive inhibition to the target unit for higher target contrasts. A similar switch from divisive to subtractive inhibition is observed in an integrate-and-fire unit that receives inhibition modulated in time such that the cell spends part of the time in a high-inhibition state and part of the time in a low-inhibition state. The similarity between the effects suggests that one may cause the other. The biophysical model makes testable predictions for physiological single-cell recordings. 1 Psychophysics Visual images of Gabor patches are thought to excite a small and specific subset of neurons in the primary visual cortex and beyond. By measuring psychophysically in humans the contrast detection and discrimination thresholds of peripheral Gabor patches, one can estimate the sensitivity of this subset of neurons. Furthermore, spatial interactions between different neuronal populations can be probed by testing the effects of additional Gabor patches (masks) on performance. Such experiments have revealed a highly configuration-specific pattern of excitatory and inhibitory spatial interactions [1, 2]. 1.1 Methods Two vertical Gabor patches with a spatial frequency of 4cyc/deg were presented at 4 deg eccentricity left and right of fixation, and observers had to report which patch had the higher contrast (spatial 2AFC). In the</p><p>3 0.52731031 <a title="89-lsi-3" href="./nips-2000-A_New_Model_of_Spatial_Representation_in_Multimodal_Brain_Areas.html">8 nips-2000-A New Model of Spatial Representation in Multimodal Brain Areas</a></p>
<p>Author: Sophie Denève, Jean-René Duhamel, Alexandre Pouget</p><p>Abstract: Most models of spatial representations in the cortex assume cells with limited receptive fields that are defined in a particular egocentric frame of reference. However, cells outside of primary sensory cortex are either gain modulated by postural input or partially shifting. We show that solving classical spatial tasks, like sensory prediction, multi-sensory integration, sensory-motor transformation and motor control requires more complicated intermediate representations that are not invariant in one frame of reference. We present an iterative basis function map that performs these spatial tasks optimally with gain modulated and partially shifting units, and tests it against neurophysiological and neuropsychological data. In order to perform an action directed toward an object, it is necessary to have a representation of its spatial location. The brain must be able to use spatial cues coming from different modalities (e.g. vision, audition, touch, proprioception), combine them to infer the position of the object, and compute the appropriate movement. These cues are in different frames of reference corresponding to different sensory or motor modalities. Visual inputs are primarily encoded in retinotopic maps, auditory inputs are encoded in head centered maps and tactile cues are encoded in skin-centered maps. Going from one frame of reference to the other might seem easy. For example, the head-centered position of an object can be approximated by the sum of its retinotopic position and the eye position. However, positions are represented by population codes in the brain, and computing a head-centered map from a retinotopic map is a more complex computation than the underlying sum. Moreover, as we get closer to sensory-motor areas it seems reasonable to assume Spksls 150 100 50 o Figure 1: Response of a VIP cell to visual stimuli appearing in different part of the screen, for three different eye positions. The level of grey represent the frequency of discharge (In spikes per seconds). The white cross is the fixation point (the head is fixed). The cell's receptive field is moving with the eyes, but only partially. Here the receptive field shift is 60% of the total gaze shift. Moreover this cell is gain modulated by eye position (adapted from Duhamel et al). that the representations should be useful for sensory-motor transformations, rather than encode an</p><p>4 0.5210371 <a title="89-lsi-4" href="./nips-2000-Higher-Order_Statistical_Properties_Arising_from_the_Non-Stationarity_of_Natural_Signals.html">65 nips-2000-Higher-Order Statistical Properties Arising from the Non-Stationarity of Natural Signals</a></p>
<p>Author: Lucas C. Parra, Clay Spence, Paul Sajda</p><p>Abstract: We present evidence that several higher-order statistical properties of natural images and signals can be explained by a stochastic model which simply varies scale of an otherwise stationary Gaussian process. We discuss two interesting consequences. The first is that a variety of natural signals can be related through a common model of spherically invariant random processes, which have the attractive property that the joint densities can be constructed from the one dimensional marginal. The second is that in some cases the non-stationarity assumption and only second order methods can be explicitly exploited to find a linear basis that is equivalent to independent components obtained with higher-order methods. This is demonstrated on spectro-temporal components of speech. 1</p><p>5 0.48213989 <a title="89-lsi-5" href="./nips-2000-Redundancy_and_Dimensionality_Reduction_in_Sparse-Distributed_Representations_of_Natural_Objects_in_Terms_of_Their_Local_Features.html">109 nips-2000-Redundancy and Dimensionality Reduction in Sparse-Distributed Representations of Natural Objects in Terms of Their Local Features</a></p>
<p>Author: Penio S. Penev</p><p>Abstract: Low-dimensional representations are key to solving problems in highlevel vision, such as face compression and recognition. Factorial coding strategies for reducing the redundancy present in natural images on the basis of their second-order statistics have been successful in accounting for both psychophysical and neurophysiological properties of early vision. Class-specific representations are presumably formed later, at the higher-level stages of cortical processing. Here we show that when retinotopic factorial codes are derived for ensembles of natural objects, such as human faces, not only redundancy, but also dimensionality is reduced. We also show that objects are built from parts in a non-Gaussian fashion which allows these local-feature codes to have dimensionalities that are substantially lower than the respective Nyquist sampling rates.</p><p>6 0.47432971 <a title="89-lsi-6" href="./nips-2000-Dendritic_Compartmentalization_Could_Underlie_Competition_and_Attentional_Biasing_of_Simultaneous_Visual_Stimuli.html">40 nips-2000-Dendritic Compartmentalization Could Underlie Competition and Attentional Biasing of Simultaneous Visual Stimuli</a></p>
<p>7 0.43784317 <a title="89-lsi-7" href="./nips-2000-Periodic_Component_Analysis%3A_An_Eigenvalue_Method_for_Representing_Periodic_Structure_in_Speech.html">99 nips-2000-Periodic Component Analysis: An Eigenvalue Method for Representing Periodic Structure in Speech</a></p>
<p>8 0.43068716 <a title="89-lsi-8" href="./nips-2000-Explaining_Away_in_Weight_Space.html">49 nips-2000-Explaining Away in Weight Space</a></p>
<p>9 0.42447311 <a title="89-lsi-9" href="./nips-2000-Noise_Suppression_Based_on_Neurophysiologically-motivated_SNR_Estimation_for_Robust_Speech_Recognition.html">91 nips-2000-Noise Suppression Based on Neurophysiologically-motivated SNR Estimation for Robust Speech Recognition</a></p>
<p>10 0.41777611 <a title="89-lsi-10" href="./nips-2000-Place_Cells_and_Spatial_Navigation_Based_on_2D_Visual_Feature_Extraction%2C_Path_Integration%2C_and_Reinforcement_Learning.html">101 nips-2000-Place Cells and Spatial Navigation Based on 2D Visual Feature Extraction, Path Integration, and Reinforcement Learning</a></p>
<p>11 0.41643625 <a title="89-lsi-11" href="./nips-2000-Processing_of_Time_Series_by_Neural_Circuits_with_Biologically_Realistic_Synaptic_Dynamics.html">104 nips-2000-Processing of Time Series by Neural Circuits with Biologically Realistic Synaptic Dynamics</a></p>
<p>12 0.39914513 <a title="89-lsi-12" href="./nips-2000-Color_Opponency_Constitutes_a_Sparse_Representation_for_the_Chromatic_Structure_of_Natural_Scenes.html">32 nips-2000-Color Opponency Constitutes a Sparse Representation for the Chromatic Structure of Natural Scenes</a></p>
<p>13 0.38863081 <a title="89-lsi-13" href="./nips-2000-Multiple_Timescales_of_Adaptation_in_a_Neural_Code.html">88 nips-2000-Multiple Timescales of Adaptation in a Neural Code</a></p>
<p>14 0.38307029 <a title="89-lsi-14" href="./nips-2000-One_Microphone_Source_Separation.html">96 nips-2000-One Microphone Source Separation</a></p>
<p>15 0.35727149 <a title="89-lsi-15" href="./nips-2000-Emergence_of_Movement_Sensitive_Neurons%27_Properties_by_Learning_a_Sparse_Code_for_Natural_Moving_Images.html">45 nips-2000-Emergence of Movement Sensitive Neurons' Properties by Learning a Sparse Code for Natural Moving Images</a></p>
<p>16 0.33537158 <a title="89-lsi-16" href="./nips-2000-The_Unscented_Particle_Filter.html">137 nips-2000-The Unscented Particle Filter</a></p>
<p>17 0.33187729 <a title="89-lsi-17" href="./nips-2000-A_Comparison_of_Image_Processing_Techniques_for_Visual_Speech_Recognition_Applications.html">2 nips-2000-A Comparison of Image Processing Techniques for Visual Speech Recognition Applications</a></p>
<p>18 0.29948997 <a title="89-lsi-18" href="./nips-2000-Speech_Denoising_and_Dereverberation_Using_Probabilistic_Models.html">123 nips-2000-Speech Denoising and Dereverberation Using Probabilistic Models</a></p>
<p>19 0.29580584 <a title="89-lsi-19" href="./nips-2000-Dopamine_Bonuses.html">43 nips-2000-Dopamine Bonuses</a></p>
<p>20 0.283025 <a title="89-lsi-20" href="./nips-2000-Learning_Joint_Statistical_Models_for_Audio-Visual_Fusion_and_Segregation.html">78 nips-2000-Learning Joint Statistical Models for Audio-Visual Fusion and Segregation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2000_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.32), (10, 0.033), (17, 0.129), (33, 0.068), (42, 0.062), (54, 0.011), (55, 0.024), (62, 0.031), (65, 0.019), (67, 0.051), (76, 0.031), (79, 0.02), (81, 0.05), (90, 0.025), (91, 0.016), (97, 0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.85866362 <a title="89-lda-1" href="./nips-2000-Natural_Sound_Statistics_and_Divisive_Normalization_in_the_Auditory_System.html">89 nips-2000-Natural Sound Statistics and Divisive Normalization in the Auditory System</a></p>
<p>Author: Odelia Schwartz, Eero P. Simoncelli</p><p>Abstract: We explore the statistical properties of natural sound stimuli preprocessed with a bank of linear filters. The responses of such filters exhibit a striking form of statistical dependency, in which the response variance of each filter grows with the response amplitude of filters tuned for nearby frequencies. These dependencies may be substantially reduced using an operation known as divisive normalization, in which the response of each filter is divided by a weighted sum of the rectified responses of other filters. The weights may be chosen to maximize the independence of the normalized responses for an ensemble of natural sounds. We demonstrate that the resulting model accounts for nonlinearities in the response characteristics of the auditory nerve, by comparing model simulations to electrophysiological recordings. In previous work (NIPS, 1998) we demonstrated that an analogous model derived from the statistics of natural images accounts for non-linear properties of neurons in primary visual cortex. Thus, divisive normalization appears to be a generic mechanism for eliminating a type of statistical dependency that is prevalent in natural signals of different modalities. Signals in the real world are highly structured. For example, natural sounds typically contain both harmonic and rythmic structure. It is reasonable to assume that biological auditory systems are designed to represent these structures in an efficient manner [e.g., 1,2]. Specifically, Barlow hypothesized that a role of early sensory processing is to remove redundancy in the sensory input, resulting in a set of neural responses that are statistically independent. Experimentally, one can test this hypothesis by examining the statistical properties of neural responses under natural stimulation conditions [e.g., 3,4], or the statistical dependency of pairs (or groups) of neural responses. Due to their technical difficulty, such multi-cellular experiments are only recently becoming possible, and the earliest reports in vision appear consistent with the hypothesis [e.g., 5]. An alternative approach, which we follow here, is to develop a neural model from the statistics of natural signals and show that response properties of this model are similar to those of biological sensory neurons. A number of researchers have derived linear filter models using statistical criterion. For visual images, this results in linear filters localized in frequency, orientation and phase [6, 7]. Similar work in audition has yielded filters localized in frequency and phase [8]. Although these linear models provide an important starting point for neural modeling, sensory neurons are highly nonlinear. In addition, the statistical properties of natural signals are too complex to expect a linear transformation to result in an independent set of components. Recent results indicate that nonlinear gain control plays an important role in neural processing. Ruderman and Bialek [9] have shown that division by a local estimate of standard deviation can increase the entropy of responses of center-surround filters to natural images. Such a model is consistent with the properties of neurons in the retina and lateral geniculate nucleus. Heeger and colleagues have shown that the nonlinear behaviors of neurons in primary visual cortex may be described using a form of gain control known as divisive normalization [10], in which the response of a linear kernel is rectified and divided by the sum of other rectified kernel responses and a constant. We have recently shown that the responses of oriented linear filters exhibit nonlinear statistical dependencies that may be substantially reduced using a variant of this model, in which the normalization signal is computed from a weighted sum of other rectified kernel responses [11, 12]. The resulting model, with weighting parameters determined from image statistics, accounts qualitatively for physiological nonlinearities observed in primary visual cortex. In this paper, we demonstrate that the responses of bandpass linear filters to natural sounds exhibit striking statistical dependencies, analogous to those found in visual images. A divisive normalization procedure can substantially remove these dependencies. We show that this model, with parameters optimized for a collection of natural sounds, can account for nonlinear behaviors of neurons at the level of the auditory nerve. Specifically, we show that: 1) the shape offrequency tuning curves varies with sound pressure level, even though the underlying linear filters are fixed; and 2) superposition of a non-optimal tone suppresses the response of a linear filter in a divisive fashion, and the amount of suppression depends on the distance between the frequency of the tone and the preferred frequency of the filter. 1 Empirical observations of natural sound statistics The basic statistical properties of natural sounds, as observed through a linear filter, have been previously documented by Attias [13]. In particular, he showed that, as with visual images, the spectral energy falls roughly according to a power law, and that the histograms of filter responses are more kurtotic than a Gaussian (i.e., they have a sharp peak at zero, and very long tails). Here we examine the joint statistical properties of a pair of linear filters tuned for nearby temporal frequencies. We choose a fixed set of filters that have been widely used in modeling the peripheral auditory system [14]. Figure 1 shows joint histograms of the instantaneous responses of a particular pair of linear filters to five different types of natural sound, and white noise. First note that the responses are approximately decorrelated: the expected value of the y-axis value is roughly zero for all values of the x-axis variable. The responses are not, however, statistically independent: the width of the distribution of responses of one filter increases with the response amplitude of the other filter. If the two responses were statistically independent, then the response of the first filter should not provide any information about the distribution of responses of the other filter. We have found that this type of variance dependency (sometimes accompanied by linear correlation) occurs in a wide range of natural sounds, ranging from animal sounds to music. We emphasize that this dependency is a property of natural sounds, and is not due purely to our choice of linear filters. For example, no such dependency is observed when the input consists of white noise (see Fig. 1). The strength of this dependency varies for different pairs of linear filters . In addition, we see this type of dependency between instantaneous responses of a single filter at two Speech o -1 Drums • Monkey Cat White noise Nocturnal nature I~ ~; ~ • Figure 1: Joint conditional histogram of instantaneous linear responses of two bandpass filters with center frequencies 2000 and 2840 Hz. Pixel intensity corresponds to frequency of occurrence of a given pair of values, except that each column has been independently rescaled to fill the full intensity range. For the natural sounds, responses are not independent: the standard deviation of the ordinate is roughly proportional to the magnitude of the abscissa. Natural sounds were recorded from CDs and converted to sampling frequency of 22050 Hz. nearby time instants. Since the dependency involves the variance of the responses, we can substantially reduce it by dividing. In particular, the response of each filter is divided by a weighted sum of responses of other rectified filters and an additive constant. Specifically: L2 Ri = 2: (1) 12 j WjiLj + 0'2 where Li is the instantaneous linear response of filter i, strength of suppression of filter i by filter j. 0' is a constant and Wji controls the We would like to choose the parameters of the model (the weights Wji, and the constant 0') to optimize the independence of the normalized response to an ensemble of natural sounds. Such an optimization is quite computationally expensive. We instead assume a Gaussian form for the underlying conditional distribution, as described in [15]: P (LiILj,j E Ni ) '</p><p>2 0.85311031 <a title="89-lda-2" href="./nips-2000-One_Microphone_Source_Separation.html">96 nips-2000-One Microphone Source Separation</a></p>
<p>Author: Sam T. Roweis</p><p>Abstract: Source separation, or computational auditory scene analysis , attempts to extract individual acoustic objects from input which contains a mixture of sounds from different sources, altered by the acoustic environment. Unmixing algorithms such as lCA and its extensions recover sources by reweighting multiple observation sequences, and thus cannot operate when only a single observation signal is available. I present a technique called refiltering which recovers sources by a nonstationary reweighting (</p><p>3 0.4875266 <a title="89-lda-3" href="./nips-2000-The_Early_Word_Catches_the_Weights.html">131 nips-2000-The Early Word Catches the Weights</a></p>
<p>Author: Mark A. Smith, Garrison W. Cottrell, Karen L. Anderson</p><p>Abstract: The strong correlation between the frequency of words and their naming latency has been well documented. However, as early as 1973, the Age of Acquisition (AoA) of a word was alleged to be the actual variable of interest, but these studies seem to have been ignored in most of the literature. Recently, there has been a resurgence of interest in AoA. While some studies have shown that frequency has no effect when AoA is controlled for, more recent studies have found independent contributions of frequency and AoA. Connectionist models have repeatedly shown strong effects of frequency, but little attention has been paid to whether they can also show AoA effects. Indeed, several researchers have explicitly claimed that they cannot show AoA effects. In this work, we explore these claims using a simple feed forward neural network. We find a significant contribution of AoA to naming latency, as well as conditions under which frequency provides an independent contribution. 1 Background Naming latency is the time between the presentation of a picture or written word and the beginning of the correct utterance of that word. It is undisputed that there are significant differences in the naming latency of many words, even when controlling word length, syllabic complexity, and other structural variants. The cause of differences in naming latency has been the subject of numerous studies. Earlier studies found that the frequency with which a word appears in spoken English is the best determinant of its naming latency (Oldfield & Wingfield, 1965). More recent psychological studies, however, show that the age at which a word is learned, or its Age of Acquisition (AoA), may be a better predictor of naming latency. Further, in many multiple regression analyses, frequency is not found to be significant when AoA is controlled for (Brown & Watson, 1987; Carroll & White, 1973; Morrison et al. 1992; Morrison & Ellis, 1995). These studies show that frequency and AoA are highly correlated (typically r =-.6) explaining the confound of older studies on frequency. However, still more recent studies question this finding and find that both AoA and frequency are significant and contribute independently to naming latency (Ellis & Morrison, 1998; Gerhand & Barry, 1998,1999). Much like their psychological counterparts, connectionist networks also show very strong frequency effects. However, the ability of a connectionist network to show AoA effects has been doubted (Gerhand & Barry, 1998; Morrison & Ellis, 1995). Most of these claims are based on the well known fact that connectionist networks exhibit</p><p>4 0.483118 <a title="89-lda-4" href="./nips-2000-Noise_Suppression_Based_on_Neurophysiologically-motivated_SNR_Estimation_for_Robust_Speech_Recognition.html">91 nips-2000-Noise Suppression Based on Neurophysiologically-motivated SNR Estimation for Robust Speech Recognition</a></p>
<p>Author: Jürgen Tchorz, Michael Kleinschmidt, Birger Kollmeier</p><p>Abstract: A novel noise suppression scheme for speech signals is proposed which is based on a neurophysiologically-motivated estimation of the local signal-to-noise ratio (SNR) in different frequency channels. For SNR-estimation, the input signal is transformed into so-called Amplitude Modulation Spectrograms (AMS), which represent both spectral and temporal characteristics of the respective analysis frame, and which imitate the representation of modulation frequencies in higher stages of the mammalian auditory system. A neural network is used to analyse AMS patterns generated from noisy speech and estimates the local SNR. Noise suppression is achieved by attenuating frequency channels according to their SNR. The noise suppression algorithm is evaluated in speakerindependent digit recognition experiments and compared to noise suppression by Spectral Subtraction. 1</p><p>5 0.46891201 <a title="89-lda-5" href="./nips-2000-Speech_Denoising_and_Dereverberation_Using_Probabilistic_Models.html">123 nips-2000-Speech Denoising and Dereverberation Using Probabilistic Models</a></p>
<p>Author: Hagai Attias, John C. Platt, Alex Acero, Li Deng</p><p>Abstract: This paper presents a unified probabilistic framework for denoising and dereverberation of speech signals. The framework transforms the denoising and dereverberation problems into Bayes-optimal signal estimation. The key idea is to use a strong speech model that is pre-trained on a large data set of clean speech. Computational efficiency is achieved by using variational EM, working in the frequency domain, and employing conjugate priors. The framework covers both single and multiple microphones. We apply this approach to noisy reverberant speech signals and get results substantially better than standard methods.</p><p>6 0.46555611 <a title="89-lda-6" href="./nips-2000-Periodic_Component_Analysis%3A_An_Eigenvalue_Method_for_Representing_Periodic_Structure_in_Speech.html">99 nips-2000-Periodic Component Analysis: An Eigenvalue Method for Representing Periodic Structure in Speech</a></p>
<p>7 0.46393484 <a title="89-lda-7" href="./nips-2000-Divisive_and_Subtractive_Mask_Effects%3A_Linking_Psychophysics_and_Biophysics.html">42 nips-2000-Divisive and Subtractive Mask Effects: Linking Psychophysics and Biophysics</a></p>
<p>8 0.45329773 <a title="89-lda-8" href="./nips-2000-Multiple_Timescales_of_Adaptation_in_a_Neural_Code.html">88 nips-2000-Multiple Timescales of Adaptation in a Neural Code</a></p>
<p>9 0.45110989 <a title="89-lda-9" href="./nips-2000-Ensemble_Learning_and_Linear_Response_Theory_for_ICA.html">46 nips-2000-Ensemble Learning and Linear Response Theory for ICA</a></p>
<p>10 0.44578171 <a title="89-lda-10" href="./nips-2000-A_New_Model_of_Spatial_Representation_in_Multimodal_Brain_Areas.html">8 nips-2000-A New Model of Spatial Representation in Multimodal Brain Areas</a></p>
<p>11 0.44095349 <a title="89-lda-11" href="./nips-2000-What_Can_a_Single_Neuron_Compute%3F.html">146 nips-2000-What Can a Single Neuron Compute?</a></p>
<p>12 0.43625417 <a title="89-lda-12" href="./nips-2000-Processing_of_Time_Series_by_Neural_Circuits_with_Biologically_Realistic_Synaptic_Dynamics.html">104 nips-2000-Processing of Time Series by Neural Circuits with Biologically Realistic Synaptic Dynamics</a></p>
<p>13 0.43355176 <a title="89-lda-13" href="./nips-2000-Rate-coded_Restricted_Boltzmann_Machines_for_Face_Recognition.html">107 nips-2000-Rate-coded Restricted Boltzmann Machines for Face Recognition</a></p>
<p>14 0.43191811 <a title="89-lda-14" href="./nips-2000-Convergence_of_Large_Margin_Separable_Linear_Classification.html">37 nips-2000-Convergence of Large Margin Separable Linear Classification</a></p>
<p>15 0.43170813 <a title="89-lda-15" href="./nips-2000-A_Comparison_of_Image_Processing_Techniques_for_Visual_Speech_Recognition_Applications.html">2 nips-2000-A Comparison of Image Processing Techniques for Visual Speech Recognition Applications</a></p>
<p>16 0.43155929 <a title="89-lda-16" href="./nips-2000-Text_Classification_using_String_Kernels.html">130 nips-2000-Text Classification using String Kernels</a></p>
<p>17 0.43111995 <a title="89-lda-17" href="./nips-2000-A_Productive%2C_Systematic_Framework_for_the_Representation_of_Visual_Structure.html">10 nips-2000-A Productive, Systematic Framework for the Representation of Visual Structure</a></p>
<p>18 0.42960605 <a title="89-lda-18" href="./nips-2000-A_New_Approximate_Maximal_Margin_Classification_Algorithm.html">7 nips-2000-A New Approximate Maximal Margin Classification Algorithm</a></p>
<p>19 0.42956319 <a title="89-lda-19" href="./nips-2000-Kernel_Expansions_with_Unlabeled_Examples.html">74 nips-2000-Kernel Expansions with Unlabeled Examples</a></p>
<p>20 0.42859367 <a title="89-lda-20" href="./nips-2000-Explaining_Away_in_Weight_Space.html">49 nips-2000-Explaining Away in Weight Space</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
