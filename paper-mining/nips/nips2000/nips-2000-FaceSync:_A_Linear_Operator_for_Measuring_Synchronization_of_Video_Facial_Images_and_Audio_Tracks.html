<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>50 nips-2000-FaceSync: A Linear Operator for Measuring Synchronization of Video Facial Images and Audio Tracks</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2000" href="../home/nips2000_home.html">nips2000</a> <a title="nips-2000-50" href="#">nips2000-50</a> knowledge-graph by maker-knowledge-mining</p><h1>50 nips-2000-FaceSync: A Linear Operator for Measuring Synchronization of Video Facial Images and Audio Tracks</h1>
<br/><p>Source: <a title="nips-2000-50-pdf" href="http://papers.nips.cc/paper/1921-facesync-a-linear-operator-for-measuring-synchronization-of-video-facial-images-and-audio-tracks.pdf">pdf</a></p><p>Author: Malcolm Slaney, Michele Covell</p><p>Abstract: FaceSync is an optimal linear algorithm that finds the degree of synchronization between the audio and image recordings of a human speaker. Using canonical correlation, it finds the best direction to combine all the audio and image data, projecting them onto a single axis. FaceSync uses Pearson's correlation to measure the degree of synchronization between the audio and image data. We derive the optimal linear transform to combine the audio and visual information and describe an implementation that avoids the numerical problems caused by computing the correlation matrices. 1 Motivation In many applications, we want to know about the synchronization between an audio signal and the corresponding image data. In a teleconferencing system, we might want to know which of the several people imaged by a camera is heard by the microphones; then, we can direct the camera to the speaker. In post-production for a film, clean audio dialog is often dubbed over the video; we want to adjust the audio signal so that the lip-sync is perfect. When analyzing a film, we want to know when the person talking is in the shot, instead of off camera. When evaluating the quality of dubbed films, we can measure of how well the translated words and audio fit the actor's face. This paper describes an algorithm, FaceSync, that measures the degree of synchronization between the video image of a face and the associated audio signal. We can do this task by synthesizing the talking face, using techniques such as Video Rewrite [1], and then comparing the synthesized video with the test video. That process, however, is expensive. Our solution finds a linear operator that, when applied to the audio and video signals, generates an audio-video-synchronization-error signal. The linear operator gathers information from throughout the image and thus allows us to do the computation inexpensively. Hershey and Movellan [2] describe an approach based on measuring the mutual information between the audio signal and individual pixels in the video. The correlation between the audio signal, x, and one pixel in the image y, is given by Pearson's correlation, r. The mutual information between these two variables is given by f(x,y) = -1/2 log(l-?). They create movies that show the regions of the video that have high correlation with the audio; 1. Currently at IBM Almaden Research, 650 Harry Road, San Jose, CA 95120. 2. Currently at Yes Video. com, 2192 Fortune Drive, San Jose, CA 95131. Standard Deviation of Testing Data FaceSync</p><p>Reference: <a title="nips-2000-50-reference" href="../nips2000_reference/nips-2000-FaceSync%3A_A_Linear_Operator_for_Measuring_Synchronization_of_Video_Facial_Images_and_Audio_Tracks_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('audio', 0.606), ('facesynt', 0.371), ('video', 0.303), ('synchron', 0.263), ('film', 0.201), ('dub', 0.172), ('jos', 0.148), ('malcolm', 0.148), ('im', 0.14), ('pearson', 0.134), ('talk', 0.124), ('correl', 0.108), ('want', 0.106), ('fac', 0.103), ('synthes', 0.093), ('camer', 0.09), ('covel', 0.074), ('hershey', 0.074), ('teleconf', 0.074), ('mut', 0.073)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="50-tfidf-1" href="./nips-2000-FaceSync%3A_A_Linear_Operator_for_Measuring_Synchronization_of_Video_Facial_Images_and_Audio_Tracks.html">50 nips-2000-FaceSync: A Linear Operator for Measuring Synchronization of Video Facial Images and Audio Tracks</a></p>
<p>2 0.55751222 <a title="50-tfidf-2" href="./nips-2000-Learning_Joint_Statistical_Models_for_Audio-Visual_Fusion_and_Segregation.html">78 nips-2000-Learning Joint Statistical Models for Audio-Visual Fusion and Segregation</a></p>
<p>3 0.17507698 <a title="50-tfidf-3" href="./nips-2000-Machine_Learning_for_Video-Based_Rendering.html">83 nips-2000-Machine Learning for Video-Based Rendering</a></p>
<p>4 0.1467379 <a title="50-tfidf-4" href="./nips-2000-Bayesian_Video_Shot_Segmentation.html">30 nips-2000-Bayesian Video Shot Segmentation</a></p>
<p>5 0.13840063 <a title="50-tfidf-5" href="./nips-2000-Emergence_of_Movement_Sensitive_Neurons%27_Properties_by_Learning_a_Sparse_Code_for_Natural_Moving_Images.html">45 nips-2000-Emergence of Movement Sensitive Neurons' Properties by Learning a Sparse Code for Natural Moving Images</a></p>
<p>6 0.12782481 <a title="50-tfidf-6" href="./nips-2000-Probabilistic_Semantic_Video_Indexing.html">103 nips-2000-Probabilistic Semantic Video Indexing</a></p>
<p>7 0.10981619 <a title="50-tfidf-7" href="./nips-2000-Rate-coded_Restricted_Boltzmann_Machines_for_Face_Recognition.html">107 nips-2000-Rate-coded Restricted Boltzmann Machines for Face Recognition</a></p>
<p>8 0.086699076 <a title="50-tfidf-8" href="./nips-2000-A_Comparison_of_Image_Processing_Techniques_for_Visual_Speech_Recognition_Applications.html">2 nips-2000-A Comparison of Image Processing Techniques for Visual Speech Recognition Applications</a></p>
<p>9 0.07214193 <a title="50-tfidf-9" href="./nips-2000-The_Manhattan_World_Assumption%3A_Regularities_in_Scene_Statistics_which_Enable_Bayesian_Inference.html">135 nips-2000-The Manhattan World Assumption: Regularities in Scene Statistics which Enable Bayesian Inference</a></p>
<p>10 0.069922715 <a title="50-tfidf-10" href="./nips-2000-Learning_and_Tracking_Cyclic_Human_Motion.html">82 nips-2000-Learning and Tracking Cyclic Human Motion</a></p>
<p>11 0.048384987 <a title="50-tfidf-11" href="./nips-2000-One_Microphone_Source_Separation.html">96 nips-2000-One Microphone Source Separation</a></p>
<p>12 0.047481135 <a title="50-tfidf-12" href="./nips-2000-Keeping_Flexible_Active_Contours_on_Track_using_Metropolis_Updates.html">72 nips-2000-Keeping Flexible Active Contours on Track using Metropolis Updates</a></p>
<p>13 0.046064388 <a title="50-tfidf-13" href="./nips-2000-Feature_Correspondence%3A_A_Markov_Chain_Monte_Carlo_Approach.html">53 nips-2000-Feature Correspondence: A Markov Chain Monte Carlo Approach</a></p>
<p>14 0.042422213 <a title="50-tfidf-14" href="./nips-2000-Higher-Order_Statistical_Properties_Arising_from_the_Non-Stationarity_of_Natural_Signals.html">65 nips-2000-Higher-Order Statistical Properties Arising from the Non-Stationarity of Natural Signals</a></p>
<p>15 0.040546689 <a title="50-tfidf-15" href="./nips-2000-From_Mixtures_of_Mixtures_to_Adaptive_Transform_Coding.html">59 nips-2000-From Mixtures of Mixtures to Adaptive Transform Coding</a></p>
<p>16 0.040009644 <a title="50-tfidf-16" href="./nips-2000-Accumulator_Networks%3A_Suitors_of_Local_Probability_Propagation.html">15 nips-2000-Accumulator Networks: Suitors of Local Probability Propagation</a></p>
<p>17 0.038609885 <a title="50-tfidf-17" href="./nips-2000-Speech_Denoising_and_Dereverberation_Using_Probabilistic_Models.html">123 nips-2000-Speech Denoising and Dereverberation Using Probabilistic Models</a></p>
<p>18 0.038024861 <a title="50-tfidf-18" href="./nips-2000-Color_Opponency_Constitutes_a_Sparse_Representation_for_the_Chromatic_Structure_of_Natural_Scenes.html">32 nips-2000-Color Opponency Constitutes a Sparse Representation for the Chromatic Structure of Natural Scenes</a></p>
<p>19 0.036636207 <a title="50-tfidf-19" href="./nips-2000-Temporally_Dependent_Plasticity%3A_An_Information_Theoretic_Account.html">129 nips-2000-Temporally Dependent Plasticity: An Information Theoretic Account</a></p>
<p>20 0.03582973 <a title="50-tfidf-20" href="./nips-2000-Partially_Observable_SDE_Models_for_Image_Sequence_Recognition_Tasks.html">98 nips-2000-Partially Observable SDE Models for Image Sequence Recognition Tasks</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2000_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.124), (1, -0.074), (2, -0.238), (3, -0.242), (4, -0.024), (5, -0.163), (6, 0.317), (7, 0.371), (8, -0.065), (9, -0.227), (10, 0.054), (11, -0.147), (12, 0.159), (13, -0.107), (14, 0.099), (15, -0.102), (16, -0.173), (17, 0.084), (18, 0.019), (19, 0.041), (20, -0.019), (21, 0.051), (22, 0.04), (23, 0.031), (24, -0.042), (25, -0.03), (26, 0.022), (27, 0.019), (28, -0.019), (29, 0.016), (30, 0.062), (31, 0.002), (32, 0.066), (33, -0.021), (34, 0.105), (35, 0.08), (36, -0.007), (37, -0.094), (38, -0.084), (39, 0.068), (40, -0.018), (41, -0.184), (42, -0.011), (43, 0.017), (44, -0.008), (45, -0.077), (46, -0.06), (47, -0.024), (48, 0.103), (49, -0.015)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9766522 <a title="50-lsi-1" href="./nips-2000-FaceSync%3A_A_Linear_Operator_for_Measuring_Synchronization_of_Video_Facial_Images_and_Audio_Tracks.html">50 nips-2000-FaceSync: A Linear Operator for Measuring Synchronization of Video Facial Images and Audio Tracks</a></p>
<p>2 0.87342054 <a title="50-lsi-2" href="./nips-2000-Learning_Joint_Statistical_Models_for_Audio-Visual_Fusion_and_Segregation.html">78 nips-2000-Learning Joint Statistical Models for Audio-Visual Fusion and Segregation</a></p>
<p>3 0.54841679 <a title="50-lsi-3" href="./nips-2000-Machine_Learning_for_Video-Based_Rendering.html">83 nips-2000-Machine Learning for Video-Based Rendering</a></p>
<p>4 0.35796461 <a title="50-lsi-4" href="./nips-2000-Bayesian_Video_Shot_Segmentation.html">30 nips-2000-Bayesian Video Shot Segmentation</a></p>
<p>5 0.32391337 <a title="50-lsi-5" href="./nips-2000-Emergence_of_Movement_Sensitive_Neurons%27_Properties_by_Learning_a_Sparse_Code_for_Natural_Moving_Images.html">45 nips-2000-Emergence of Movement Sensitive Neurons' Properties by Learning a Sparse Code for Natural Moving Images</a></p>
<p>6 0.28621554 <a title="50-lsi-6" href="./nips-2000-Probabilistic_Semantic_Video_Indexing.html">103 nips-2000-Probabilistic Semantic Video Indexing</a></p>
<p>7 0.23565364 <a title="50-lsi-7" href="./nips-2000-Rate-coded_Restricted_Boltzmann_Machines_for_Face_Recognition.html">107 nips-2000-Rate-coded Restricted Boltzmann Machines for Face Recognition</a></p>
<p>8 0.18349065 <a title="50-lsi-8" href="./nips-2000-A_Comparison_of_Image_Processing_Techniques_for_Visual_Speech_Recognition_Applications.html">2 nips-2000-A Comparison of Image Processing Techniques for Visual Speech Recognition Applications</a></p>
<p>9 0.17639025 <a title="50-lsi-9" href="./nips-2000-Learning_and_Tracking_Cyclic_Human_Motion.html">82 nips-2000-Learning and Tracking Cyclic Human Motion</a></p>
<p>10 0.17614196 <a title="50-lsi-10" href="./nips-2000-The_Manhattan_World_Assumption%3A_Regularities_in_Scene_Statistics_which_Enable_Bayesian_Inference.html">135 nips-2000-The Manhattan World Assumption: Regularities in Scene Statistics which Enable Bayesian Inference</a></p>
<p>11 0.14653923 <a title="50-lsi-11" href="./nips-2000-Higher-Order_Statistical_Properties_Arising_from_the_Non-Stationarity_of_Natural_Signals.html">65 nips-2000-Higher-Order Statistical Properties Arising from the Non-Stationarity of Natural Signals</a></p>
<p>12 0.14176194 <a title="50-lsi-12" href="./nips-2000-One_Microphone_Source_Separation.html">96 nips-2000-One Microphone Source Separation</a></p>
<p>13 0.13488655 <a title="50-lsi-13" href="./nips-2000-Feature_Correspondence%3A_A_Markov_Chain_Monte_Carlo_Approach.html">53 nips-2000-Feature Correspondence: A Markov Chain Monte Carlo Approach</a></p>
<p>14 0.12222691 <a title="50-lsi-14" href="./nips-2000-Color_Opponency_Constitutes_a_Sparse_Representation_for_the_Chromatic_Structure_of_Natural_Scenes.html">32 nips-2000-Color Opponency Constitutes a Sparse Representation for the Chromatic Structure of Natural Scenes</a></p>
<p>15 0.11523491 <a title="50-lsi-15" href="./nips-2000-The_Early_Word_Catches_the_Weights.html">131 nips-2000-The Early Word Catches the Weights</a></p>
<p>16 0.11485174 <a title="50-lsi-16" href="./nips-2000-Sex_with_Support_Vector_Machines.html">116 nips-2000-Sex with Support Vector Machines</a></p>
<p>17 0.11280546 <a title="50-lsi-17" href="./nips-2000-Periodic_Component_Analysis%3A_An_Eigenvalue_Method_for_Representing_Periodic_Structure_in_Speech.html">99 nips-2000-Periodic Component Analysis: An Eigenvalue Method for Representing Periodic Structure in Speech</a></p>
<p>18 0.10771675 <a title="50-lsi-18" href="./nips-2000-%60N-Body%27_Problems_in_Statistical_Learning.html">148 nips-2000-`N-Body' Problems in Statistical Learning</a></p>
<p>19 0.1034476 <a title="50-lsi-19" href="./nips-2000-Keeping_Flexible_Active_Contours_on_Track_using_Metropolis_Updates.html">72 nips-2000-Keeping Flexible Active Contours on Track using Metropolis Updates</a></p>
<p>20 0.097100653 <a title="50-lsi-20" href="./nips-2000-From_Mixtures_of_Mixtures_to_Adaptive_Transform_Coding.html">59 nips-2000-From Mixtures of Mixtures to Adaptive Transform Coding</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2000_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(9, 0.087), (16, 0.044), (38, 0.071), (59, 0.524), (61, 0.012), (64, 0.017), (74, 0.037), (84, 0.057)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.71206516 <a title="50-lda-1" href="./nips-2000-FaceSync%3A_A_Linear_Operator_for_Measuring_Synchronization_of_Video_Facial_Images_and_Audio_Tracks.html">50 nips-2000-FaceSync: A Linear Operator for Measuring Synchronization of Video Facial Images and Audio Tracks</a></p>
<p>2 0.38034341 <a title="50-lda-2" href="./nips-2000-The_Kernel_Gibbs_Sampler.html">133 nips-2000-The Kernel Gibbs Sampler</a></p>
<p>3 0.24025425 <a title="50-lda-3" href="./nips-2000-Emergence_of_Movement_Sensitive_Neurons%27_Properties_by_Learning_a_Sparse_Code_for_Natural_Moving_Images.html">45 nips-2000-Emergence of Movement Sensitive Neurons' Properties by Learning a Sparse Code for Natural Moving Images</a></p>
<p>4 0.23886454 <a title="50-lda-4" href="./nips-2000-The_Use_of_Classifiers_in_Sequential_Inference.html">138 nips-2000-The Use of Classifiers in Sequential Inference</a></p>
<p>5 0.23383367 <a title="50-lda-5" href="./nips-2000-Color_Opponency_Constitutes_a_Sparse_Representation_for_the_Chromatic_Structure_of_Natural_Scenes.html">32 nips-2000-Color Opponency Constitutes a Sparse Representation for the Chromatic Structure of Natural Scenes</a></p>
<p>6 0.2336472 <a title="50-lda-6" href="./nips-2000-The_Unscented_Particle_Filter.html">137 nips-2000-The Unscented Particle Filter</a></p>
<p>7 0.23320797 <a title="50-lda-7" href="./nips-2000-Redundancy_and_Dimensionality_Reduction_in_Sparse-Distributed_Representations_of_Natural_Objects_in_Terms_of_Their_Local_Features.html">109 nips-2000-Redundancy and Dimensionality Reduction in Sparse-Distributed Representations of Natural Objects in Terms of Their Local Features</a></p>
<p>8 0.23037596 <a title="50-lda-8" href="./nips-2000-Partially_Observable_SDE_Models_for_Image_Sequence_Recognition_Tasks.html">98 nips-2000-Partially Observable SDE Models for Image Sequence Recognition Tasks</a></p>
<p>9 0.22811867 <a title="50-lda-9" href="./nips-2000-Data_Clustering_by_Markovian_Relaxation_and_the_Information_Bottleneck_Method.html">38 nips-2000-Data Clustering by Markovian Relaxation and the Information Bottleneck Method</a></p>
<p>10 0.22771135 <a title="50-lda-10" href="./nips-2000-Keeping_Flexible_Active_Contours_on_Track_using_Metropolis_Updates.html">72 nips-2000-Keeping Flexible Active Contours on Track using Metropolis Updates</a></p>
<p>11 0.22752756 <a title="50-lda-11" href="./nips-2000-Support_Vector_Novelty_Detection_Applied_to_Jet_Engine_Vibration_Spectra.html">128 nips-2000-Support Vector Novelty Detection Applied to Jet Engine Vibration Spectra</a></p>
<p>12 0.22702688 <a title="50-lda-12" href="./nips-2000-Learning_and_Tracking_Cyclic_Human_Motion.html">82 nips-2000-Learning and Tracking Cyclic Human Motion</a></p>
<p>13 0.22617294 <a title="50-lda-13" href="./nips-2000-Automatic_Choice_of_Dimensionality_for_PCA.html">27 nips-2000-Automatic Choice of Dimensionality for PCA</a></p>
<p>14 0.22583206 <a title="50-lda-14" href="./nips-2000-Reinforcement_Learning_with_Function_Approximation_Converges_to_a_Region.html">112 nips-2000-Reinforcement Learning with Function Approximation Converges to a Region</a></p>
<p>15 0.22543958 <a title="50-lda-15" href="./nips-2000-Machine_Learning_for_Video-Based_Rendering.html">83 nips-2000-Machine Learning for Video-Based Rendering</a></p>
<p>16 0.22510943 <a title="50-lda-16" href="./nips-2000-Text_Classification_using_String_Kernels.html">130 nips-2000-Text Classification using String Kernels</a></p>
<p>17 0.2250289 <a title="50-lda-17" href="./nips-2000-A_Neural_Probabilistic_Language_Model.html">6 nips-2000-A Neural Probabilistic Language Model</a></p>
<p>18 0.22495541 <a title="50-lda-18" href="./nips-2000-Rate-coded_Restricted_Boltzmann_Machines_for_Face_Recognition.html">107 nips-2000-Rate-coded Restricted Boltzmann Machines for Face Recognition</a></p>
<p>19 0.22479683 <a title="50-lda-19" href="./nips-2000-A_PAC-Bayesian_Margin_Bound_for_Linear_Classifiers%3A_Why_SVMs_work.html">9 nips-2000-A PAC-Bayesian Margin Bound for Linear Classifiers: Why SVMs work</a></p>
<p>20 0.22365719 <a title="50-lda-20" href="./nips-2000-Kernel_Expansions_with_Unlabeled_Examples.html">74 nips-2000-Kernel Expansions with Unlabeled Examples</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
