<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>133 nips-2000-The Kernel Gibbs Sampler</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2000" href="../home/nips2000_home.html">nips2000</a> <a title="nips-2000-133" href="#">nips2000-133</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>133 nips-2000-The Kernel Gibbs Sampler</h1>
<br/><p>Source: <a title="nips-2000-133-pdf" href="http://papers.nips.cc/paper/1802-the-kernel-gibbs-sampler.pdf">pdf</a></p><p>Author: Thore Graepel, Ralf Herbrich</p><p>Abstract: We present an algorithm that samples the hypothesis space of kernel classifiers. Given a uniform prior over normalised weight vectors and a likelihood based on a model of label noise leads to a piecewise constant posterior that can be sampled by the kernel Gibbs sampler (KGS). The KGS is a Markov Chain Monte Carlo method that chooses a random direction in parameter space and samples from the resulting piecewise constant density along the line chosen. The KGS can be used as an analytical tool for the exploration of Bayesian transduction, Bayes point machines, active learning, and evidence-based model selection on small data sets that are contaminated with label noise. For a simple toy example we demonstrate experimentally how a Bayes point machine based on the KGS outperforms an SVM that is incapable of taking into account label noise. 1</p><p>Reference: <a title="nips-2000-133-reference" href="../nips2000_reference/nips-2000-The_Kernel_Gibbs_Sampler_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('kgs', 0.402), ('label', 0.279), ('pwlz', 0.256), ('kernel', 0.249), ('bayes', 0.218), ('sampl', 0.196), ('wj', 0.192), ('transduc', 0.189), ('nois', 0.159), ('bpm', 0.157), ('gib', 0.155), ('piecew', 0.149), ('wbp', 0.146), ('postery', 0.146), ('nci', 0.126), ('svm', 0.098), ('berlin', 0.095), ('contamin', 0.094), ('remp', 0.094), ('bay', 0.09)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="133-tfidf-1" href="./nips-2000-The_Kernel_Gibbs_Sampler.html">133 nips-2000-The Kernel Gibbs Sampler</a></p>
<p>2 0.35823369 <a title="133-tfidf-2" href="./nips-2000-Large_Scale_Bayes_Point_Machines.html">75 nips-2000-Large Scale Bayes Point Machines</a></p>
<p>3 0.23849478 <a title="133-tfidf-3" href="./nips-2000-Kernel_Expansions_with_Unlabeled_Examples.html">74 nips-2000-Kernel Expansions with Unlabeled Examples</a></p>
<p>4 0.22977416 <a title="133-tfidf-4" href="./nips-2000-A_PAC-Bayesian_Margin_Bound_for_Linear_Classifiers%3A_Why_SVMs_work.html">9 nips-2000-A PAC-Bayesian Margin Bound for Linear Classifiers: Why SVMs work</a></p>
<p>5 0.19176874 <a title="133-tfidf-5" href="./nips-2000-The_Kernel_Trick_for_Distances.html">134 nips-2000-The Kernel Trick for Distances</a></p>
<p>6 0.16693665 <a title="133-tfidf-6" href="./nips-2000-Text_Classification_using_String_Kernels.html">130 nips-2000-Text Classification using String Kernels</a></p>
<p>7 0.15014033 <a title="133-tfidf-7" href="./nips-2000-From_Margin_to_Sparsity.html">58 nips-2000-From Margin to Sparsity</a></p>
<p>8 0.14937404 <a title="133-tfidf-8" href="./nips-2000-Sparse_Representation_for_Gaussian_Process_Models.html">122 nips-2000-Sparse Representation for Gaussian Process Models</a></p>
<p>9 0.1471301 <a title="133-tfidf-9" href="./nips-2000-Sparse_Kernel_Principal_Component_Analysis.html">121 nips-2000-Sparse Kernel Principal Component Analysis</a></p>
<p>10 0.14663477 <a title="133-tfidf-10" href="./nips-2000-Regularization_with_Dot-Product_Kernels.html">110 nips-2000-Regularization with Dot-Product Kernels</a></p>
<p>11 0.14385171 <a title="133-tfidf-11" href="./nips-2000-A_Linear_Programming_Approach_to_Novelty_Detection.html">4 nips-2000-A Linear Programming Approach to Novelty Detection</a></p>
<p>12 0.14097305 <a title="133-tfidf-12" href="./nips-2000-Propagation_Algorithms_for_Variational_Bayesian_Learning.html">106 nips-2000-Propagation Algorithms for Variational Bayesian Learning</a></p>
<p>13 0.13219295 <a title="133-tfidf-13" href="./nips-2000-Computing_with_Finite_and_Infinite_Networks.html">35 nips-2000-Computing with Finite and Infinite Networks</a></p>
<p>14 0.12647165 <a title="133-tfidf-14" href="./nips-2000-Feature_Selection_for_SVMs.html">54 nips-2000-Feature Selection for SVMs</a></p>
<p>15 0.12386472 <a title="133-tfidf-15" href="./nips-2000-Feature_Correspondence%3A_A_Markov_Chain_Monte_Carlo_Approach.html">53 nips-2000-Feature Correspondence: A Markov Chain Monte Carlo Approach</a></p>
<p>16 0.1195989 <a title="133-tfidf-16" href="./nips-2000-Active_Learning_for_Parameter_Estimation_in_Bayesian_Networks.html">17 nips-2000-Active Learning for Parameter Estimation in Bayesian Networks</a></p>
<p>17 0.11919452 <a title="133-tfidf-17" href="./nips-2000-Learning_Curves_for_Gaussian_Processes_Regression%3A_A_Framework_for_Good_Approximations.html">77 nips-2000-Learning Curves for Gaussian Processes Regression: A Framework for Good Approximations</a></p>
<p>18 0.11868179 <a title="133-tfidf-18" href="./nips-2000-Regularized_Winnow_Methods.html">111 nips-2000-Regularized Winnow Methods</a></p>
<p>19 0.11777756 <a title="133-tfidf-19" href="./nips-2000-On_a_Connection_between_Kernel_PCA_and_Metric_Multidimensional_Scaling.html">95 nips-2000-On a Connection between Kernel PCA and Metric Multidimensional Scaling</a></p>
<p>20 0.11658546 <a title="133-tfidf-20" href="./nips-2000-Sparse_Greedy_Gaussian_Process_Regression.html">120 nips-2000-Sparse Greedy Gaussian Process Regression</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2000_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.331), (1, 0.269), (2, 0.157), (3, -0.045), (4, -0.084), (5, 0.018), (6, 0.001), (7, 0.051), (8, 0.121), (9, -0.013), (10, 0.202), (11, -0.061), (12, -0.006), (13, 0.013), (14, -0.051), (15, 0.071), (16, 0.112), (17, 0.067), (18, -0.071), (19, -0.055), (20, -0.141), (21, 0.126), (22, -0.147), (23, 0.105), (24, 0.043), (25, 0.021), (26, -0.061), (27, -0.03), (28, -0.045), (29, 0.121), (30, -0.083), (31, 0.06), (32, 0.057), (33, -0.059), (34, -0.069), (35, -0.157), (36, 0.012), (37, 0.065), (38, 0.045), (39, 0.164), (40, 0.121), (41, 0.09), (42, -0.122), (43, -0.034), (44, 0.093), (45, -0.162), (46, -0.002), (47, -0.097), (48, 0.097), (49, 0.052)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94513154 <a title="133-lsi-1" href="./nips-2000-The_Kernel_Gibbs_Sampler.html">133 nips-2000-The Kernel Gibbs Sampler</a></p>
<p>2 0.81769001 <a title="133-lsi-2" href="./nips-2000-Large_Scale_Bayes_Point_Machines.html">75 nips-2000-Large Scale Bayes Point Machines</a></p>
<p>3 0.59863359 <a title="133-lsi-3" href="./nips-2000-Kernel_Expansions_with_Unlabeled_Examples.html">74 nips-2000-Kernel Expansions with Unlabeled Examples</a></p>
<p>4 0.55786633 <a title="133-lsi-4" href="./nips-2000-Feature_Correspondence%3A_A_Markov_Chain_Monte_Carlo_Approach.html">53 nips-2000-Feature Correspondence: A Markov Chain Monte Carlo Approach</a></p>
<p>5 0.52665764 <a title="133-lsi-5" href="./nips-2000-A_PAC-Bayesian_Margin_Bound_for_Linear_Classifiers%3A_Why_SVMs_work.html">9 nips-2000-A PAC-Bayesian Margin Bound for Linear Classifiers: Why SVMs work</a></p>
<p>6 0.47477767 <a title="133-lsi-6" href="./nips-2000-A_Mathematical_Programming_Approach_to_the_Kernel_Fisher_Algorithm.html">5 nips-2000-A Mathematical Programming Approach to the Kernel Fisher Algorithm</a></p>
<p>7 0.47438124 <a title="133-lsi-7" href="./nips-2000-The_Kernel_Trick_for_Distances.html">134 nips-2000-The Kernel Trick for Distances</a></p>
<p>8 0.46310189 <a title="133-lsi-8" href="./nips-2000-Fast_Training_of_Support_Vector_Classifiers.html">52 nips-2000-Fast Training of Support Vector Classifiers</a></p>
<p>9 0.44482601 <a title="133-lsi-9" href="./nips-2000-From_Margin_to_Sparsity.html">58 nips-2000-From Margin to Sparsity</a></p>
<p>10 0.44298223 <a title="133-lsi-10" href="./nips-2000-Text_Classification_using_String_Kernels.html">130 nips-2000-Text Classification using String Kernels</a></p>
<p>11 0.4392001 <a title="133-lsi-11" href="./nips-2000-On_a_Connection_between_Kernel_PCA_and_Metric_Multidimensional_Scaling.html">95 nips-2000-On a Connection between Kernel PCA and Metric Multidimensional Scaling</a></p>
<p>12 0.42485511 <a title="133-lsi-12" href="./nips-2000-Regularization_with_Dot-Product_Kernels.html">110 nips-2000-Regularization with Dot-Product Kernels</a></p>
<p>13 0.42422411 <a title="133-lsi-13" href="./nips-2000-Incremental_and_Decremental_Support_Vector_Machine_Learning.html">70 nips-2000-Incremental and Decremental Support Vector Machine Learning</a></p>
<p>14 0.40526587 <a title="133-lsi-14" href="./nips-2000-A_Linear_Programming_Approach_to_Novelty_Detection.html">4 nips-2000-A Linear Programming Approach to Novelty Detection</a></p>
<p>15 0.38817427 <a title="133-lsi-15" href="./nips-2000-Active_Learning_for_Parameter_Estimation_in_Bayesian_Networks.html">17 nips-2000-Active Learning for Parameter Estimation in Bayesian Networks</a></p>
<p>16 0.38491696 <a title="133-lsi-16" href="./nips-2000-Improved_Output_Coding_for_Classification_Using_Continuous_Relaxation.html">68 nips-2000-Improved Output Coding for Classification Using Continuous Relaxation</a></p>
<p>17 0.38166019 <a title="133-lsi-17" href="./nips-2000-Propagation_Algorithms_for_Variational_Bayesian_Learning.html">106 nips-2000-Propagation Algorithms for Variational Bayesian Learning</a></p>
<p>18 0.38064045 <a title="133-lsi-18" href="./nips-2000-Sparse_Representation_for_Gaussian_Process_Models.html">122 nips-2000-Sparse Representation for Gaussian Process Models</a></p>
<p>19 0.38003832 <a title="133-lsi-19" href="./nips-2000-Efficient_Learning_of_Linear_Perceptrons.html">44 nips-2000-Efficient Learning of Linear Perceptrons</a></p>
<p>20 0.3787674 <a title="133-lsi-20" href="./nips-2000-Computing_with_Finite_and_Infinite_Networks.html">35 nips-2000-Computing with Finite and Infinite Networks</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2000_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(9, 0.168), (11, 0.045), (16, 0.055), (21, 0.01), (32, 0.109), (38, 0.038), (54, 0.038), (59, 0.239), (67, 0.018), (74, 0.032), (76, 0.012), (80, 0.022), (84, 0.092), (88, 0.012), (96, 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.8769083 <a title="133-lda-1" href="./nips-2000-FaceSync%3A_A_Linear_Operator_for_Measuring_Synchronization_of_Video_Facial_Images_and_Audio_Tracks.html">50 nips-2000-FaceSync: A Linear Operator for Measuring Synchronization of Video Facial Images and Audio Tracks</a></p>
<p>same-paper 2 0.76324451 <a title="133-lda-2" href="./nips-2000-The_Kernel_Gibbs_Sampler.html">133 nips-2000-The Kernel Gibbs Sampler</a></p>
<p>3 0.68417072 <a title="133-lda-3" href="./nips-2000-Large_Scale_Bayes_Point_Machines.html">75 nips-2000-Large Scale Bayes Point Machines</a></p>
<p>4 0.66253066 <a title="133-lda-4" href="./nips-2000-Learning_Joint_Statistical_Models_for_Audio-Visual_Fusion_and_Segregation.html">78 nips-2000-Learning Joint Statistical Models for Audio-Visual Fusion and Segregation</a></p>
<p>5 0.64261985 <a title="133-lda-5" href="./nips-2000-A_PAC-Bayesian_Margin_Bound_for_Linear_Classifiers%3A_Why_SVMs_work.html">9 nips-2000-A PAC-Bayesian Margin Bound for Linear Classifiers: Why SVMs work</a></p>
<p>6 0.62854213 <a title="133-lda-6" href="./nips-2000-From_Margin_to_Sparsity.html">58 nips-2000-From Margin to Sparsity</a></p>
<p>7 0.61889547 <a title="133-lda-7" href="./nips-2000-A_New_Approximate_Maximal_Margin_Classification_Algorithm.html">7 nips-2000-A New Approximate Maximal Margin Classification Algorithm</a></p>
<p>8 0.61329919 <a title="133-lda-8" href="./nips-2000-Constrained_Independent_Component_Analysis.html">36 nips-2000-Constrained Independent Component Analysis</a></p>
<p>9 0.61303693 <a title="133-lda-9" href="./nips-2000-Periodic_Component_Analysis%3A_An_Eigenvalue_Method_for_Representing_Periodic_Structure_in_Speech.html">99 nips-2000-Periodic Component Analysis: An Eigenvalue Method for Representing Periodic Structure in Speech</a></p>
<p>10 0.61263794 <a title="133-lda-10" href="./nips-2000-Automatic_Choice_of_Dimensionality_for_PCA.html">27 nips-2000-Automatic Choice of Dimensionality for PCA</a></p>
<p>11 0.61199909 <a title="133-lda-11" href="./nips-2000-Regularized_Winnow_Methods.html">111 nips-2000-Regularized Winnow Methods</a></p>
<p>12 0.61029172 <a title="133-lda-12" href="./nips-2000-Speech_Denoising_and_Dereverberation_Using_Probabilistic_Models.html">123 nips-2000-Speech Denoising and Dereverberation Using Probabilistic Models</a></p>
<p>13 0.60903347 <a title="133-lda-13" href="./nips-2000-Reinforcement_Learning_with_Function_Approximation_Converges_to_a_Region.html">112 nips-2000-Reinforcement Learning with Function Approximation Converges to a Region</a></p>
<p>14 0.60901874 <a title="133-lda-14" href="./nips-2000-Feature_Selection_for_SVMs.html">54 nips-2000-Feature Selection for SVMs</a></p>
<p>15 0.60748136 <a title="133-lda-15" href="./nips-2000-Higher-Order_Statistical_Properties_Arising_from_the_Non-Stationarity_of_Natural_Signals.html">65 nips-2000-Higher-Order Statistical Properties Arising from the Non-Stationarity of Natural Signals</a></p>
<p>16 0.60699308 <a title="133-lda-16" href="./nips-2000-A_Linear_Programming_Approach_to_Novelty_Detection.html">4 nips-2000-A Linear Programming Approach to Novelty Detection</a></p>
<p>17 0.60494965 <a title="133-lda-17" href="./nips-2000-Feature_Correspondence%3A_A_Markov_Chain_Monte_Carlo_Approach.html">53 nips-2000-Feature Correspondence: A Markov Chain Monte Carlo Approach</a></p>
<p>18 0.60490525 <a title="133-lda-18" href="./nips-2000-Factored_Semi-Tied_Covariance_Matrices.html">51 nips-2000-Factored Semi-Tied Covariance Matrices</a></p>
<p>19 0.60437828 <a title="133-lda-19" href="./nips-2000-Active_Support_Vector_Machine_Classification.html">18 nips-2000-Active Support Vector Machine Classification</a></p>
<p>20 0.60427868 <a title="133-lda-20" href="./nips-2000-Kernel_Expansions_with_Unlabeled_Examples.html">74 nips-2000-Kernel Expansions with Unlabeled Examples</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
