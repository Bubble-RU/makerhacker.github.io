<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>111 nips-2000-Regularized Winnow Methods</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2000" href="../home/nips2000_home.html">nips2000</a> <a title="nips-2000-111" href="#">nips2000-111</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>111 nips-2000-Regularized Winnow Methods</h1>
<br/><p>Source: <a title="nips-2000-111-pdf" href="http://papers.nips.cc/paper/1833-regularized-winnow-methods.pdf">pdf</a></p><p>Author: Tong Zhang</p><p>Abstract: In theory, the Winnow multiplicative update has certain advantages over the Perceptron additive update when there are many irrelevant attributes. Recently, there has been much effort on enhancing the Perceptron algorithm by using regularization, leading to a class of linear classification methods called support vector machines. Similarly, it is also possible to apply the regularization idea to the Winnow algorithm, which gives methods we call regularized Winnows. We show that the resulting methods compare with the basic Winnows in a similar way that a support vector machine compares with the Perceptron. We investigate algorithmic issues and learning properties of the derived methods. Some experimental results will also be provided to illustrate different methods.</p><p>Reference: <a title="nips-2000-111-reference" href="../nips2000_reference/nips-2000-Regularized_Winnow_Methods_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('winnow', 0.749), ('wj', 0.331), ('perceptron', 0.213), ('regul', 0.203), ('dual', 0.147), ('hyperpl', 0.128), ('mistak', 0.127), ('unnorm', 0.115), ('ilwll', 0.113), ('svm', 0.101), ('upd', 0.099), ('xiy', 0.096), ('yi', 0.091), ('tj', 0.08), ('bound', 0.074), ('discrimin', 0.058), ('weight', 0.057), ('max', 0.054), ('shal', 0.054), ('misclass', 0.053)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="111-tfidf-1" href="./nips-2000-Regularized_Winnow_Methods.html">111 nips-2000-Regularized Winnow Methods</a></p>
<p>2 0.23033682 <a title="111-tfidf-2" href="./nips-2000-From_Margin_to_Sparsity.html">58 nips-2000-From Margin to Sparsity</a></p>
<p>3 0.19180407 <a title="111-tfidf-3" href="./nips-2000-Convergence_of_Large_Margin_Separable_Linear_Classification.html">37 nips-2000-Convergence of Large Margin Separable Linear Classification</a></p>
<p>4 0.13113628 <a title="111-tfidf-4" href="./nips-2000-Large_Scale_Bayes_Point_Machines.html">75 nips-2000-Large Scale Bayes Point Machines</a></p>
<p>5 0.12762713 <a title="111-tfidf-5" href="./nips-2000-A_New_Approximate_Maximal_Margin_Classification_Algorithm.html">7 nips-2000-A New Approximate Maximal Margin Classification Algorithm</a></p>
<p>6 0.11868179 <a title="111-tfidf-6" href="./nips-2000-The_Kernel_Gibbs_Sampler.html">133 nips-2000-The Kernel Gibbs Sampler</a></p>
<p>7 0.11240055 <a title="111-tfidf-7" href="./nips-2000-Active_Support_Vector_Machine_Classification.html">18 nips-2000-Active Support Vector Machine Classification</a></p>
<p>8 0.092448533 <a title="111-tfidf-8" href="./nips-2000-Kernel_Expansions_with_Unlabeled_Examples.html">74 nips-2000-Kernel Expansions with Unlabeled Examples</a></p>
<p>9 0.087095268 <a title="111-tfidf-9" href="./nips-2000-Efficient_Learning_of_Linear_Perceptrons.html">44 nips-2000-Efficient Learning of Linear Perceptrons</a></p>
<p>10 0.085691333 <a title="111-tfidf-10" href="./nips-2000-A_PAC-Bayesian_Margin_Bound_for_Linear_Classifiers%3A_Why_SVMs_work.html">9 nips-2000-A PAC-Bayesian Margin Bound for Linear Classifiers: Why SVMs work</a></p>
<p>11 0.076534912 <a title="111-tfidf-11" href="./nips-2000-Weak_Learners_and_Improved_Rates_of_Convergence_in_Boosting.html">145 nips-2000-Weak Learners and Improved Rates of Convergence in Boosting</a></p>
<p>12 0.075756289 <a title="111-tfidf-12" href="./nips-2000-Feature_Selection_for_SVMs.html">54 nips-2000-Feature Selection for SVMs</a></p>
<p>13 0.070314288 <a title="111-tfidf-13" href="./nips-2000-Algorithmic_Stability_and_Generalization_Performance.html">21 nips-2000-Algorithmic Stability and Generalization Performance</a></p>
<p>14 0.067789875 <a title="111-tfidf-14" href="./nips-2000-A_Linear_Programming_Approach_to_Novelty_Detection.html">4 nips-2000-A Linear Programming Approach to Novelty Detection</a></p>
<p>15 0.065909855 <a title="111-tfidf-15" href="./nips-2000-Support_Vector_Novelty_Detection_Applied_to_Jet_Engine_Vibration_Spectra.html">128 nips-2000-Support Vector Novelty Detection Applied to Jet Engine Vibration Spectra</a></p>
<p>16 0.060150251 <a title="111-tfidf-16" href="./nips-2000-On_Reversing_Jensen%27s_Inequality.html">94 nips-2000-On Reversing Jensen's Inequality</a></p>
<p>17 0.055523671 <a title="111-tfidf-17" href="./nips-2000-Incremental_and_Decremental_Support_Vector_Machine_Learning.html">70 nips-2000-Incremental and Decremental Support Vector Machine Learning</a></p>
<p>18 0.054802611 <a title="111-tfidf-18" href="./nips-2000-Learning_Continuous_Distributions%3A_Simulations_With_Field_Theoretic_Priors.html">76 nips-2000-Learning Continuous Distributions: Simulations With Field Theoretic Priors</a></p>
<p>19 0.054539606 <a title="111-tfidf-19" href="./nips-2000-Regularization_with_Dot-Product_Kernels.html">110 nips-2000-Regularization with Dot-Product Kernels</a></p>
<p>20 0.051930863 <a title="111-tfidf-20" href="./nips-2000-A_Tighter_Bound_for_Graphical_Models.html">13 nips-2000-A Tighter Bound for Graphical Models</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2000_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.186), (1, 0.144), (2, 0.128), (3, 0.053), (4, 0.042), (5, 0.076), (6, 0.225), (7, -0.031), (8, 0.037), (9, 0.004), (10, -0.021), (11, -0.035), (12, -0.013), (13, 0.076), (14, 0.016), (15, -0.097), (16, 0.08), (17, 0.126), (18, 0.06), (19, 0.132), (20, -0.181), (21, 0.01), (22, 0.031), (23, -0.036), (24, 0.182), (25, 0.075), (26, 0.019), (27, 0.006), (28, -0.019), (29, -0.062), (30, 0.02), (31, -0.056), (32, -0.166), (33, -0.084), (34, -0.022), (35, -0.078), (36, -0.045), (37, -0.063), (38, 0.01), (39, -0.011), (40, -0.028), (41, -0.02), (42, 0.095), (43, 0.084), (44, 0.067), (45, -0.003), (46, -0.136), (47, -0.171), (48, -0.076), (49, -0.034)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.90992349 <a title="111-lsi-1" href="./nips-2000-Regularized_Winnow_Methods.html">111 nips-2000-Regularized Winnow Methods</a></p>
<p>2 0.73602068 <a title="111-lsi-2" href="./nips-2000-Convergence_of_Large_Margin_Separable_Linear_Classification.html">37 nips-2000-Convergence of Large Margin Separable Linear Classification</a></p>
<p>3 0.63458401 <a title="111-lsi-3" href="./nips-2000-A_New_Approximate_Maximal_Margin_Classification_Algorithm.html">7 nips-2000-A New Approximate Maximal Margin Classification Algorithm</a></p>
<p>4 0.60513067 <a title="111-lsi-4" href="./nips-2000-From_Margin_to_Sparsity.html">58 nips-2000-From Margin to Sparsity</a></p>
<p>5 0.54820013 <a title="111-lsi-5" href="./nips-2000-Active_Support_Vector_Machine_Classification.html">18 nips-2000-Active Support Vector Machine Classification</a></p>
<p>6 0.53825355 <a title="111-lsi-6" href="./nips-2000-Efficient_Learning_of_Linear_Perceptrons.html">44 nips-2000-Efficient Learning of Linear Perceptrons</a></p>
<p>7 0.43834123 <a title="111-lsi-7" href="./nips-2000-Large_Scale_Bayes_Point_Machines.html">75 nips-2000-Large Scale Bayes Point Machines</a></p>
<p>8 0.43455532 <a title="111-lsi-8" href="./nips-2000-Incremental_and_Decremental_Support_Vector_Machine_Learning.html">70 nips-2000-Incremental and Decremental Support Vector Machine Learning</a></p>
<p>9 0.397333 <a title="111-lsi-9" href="./nips-2000-Kernel_Expansions_with_Unlabeled_Examples.html">74 nips-2000-Kernel Expansions with Unlabeled Examples</a></p>
<p>10 0.38819769 <a title="111-lsi-10" href="./nips-2000-A_PAC-Bayesian_Margin_Bound_for_Linear_Classifiers%3A_Why_SVMs_work.html">9 nips-2000-A PAC-Bayesian Margin Bound for Linear Classifiers: Why SVMs work</a></p>
<p>11 0.34509844 <a title="111-lsi-11" href="./nips-2000-Weak_Learners_and_Improved_Rates_of_Convergence_in_Boosting.html">145 nips-2000-Weak Learners and Improved Rates of Convergence in Boosting</a></p>
<p>12 0.29861367 <a title="111-lsi-12" href="./nips-2000-The_Kernel_Gibbs_Sampler.html">133 nips-2000-The Kernel Gibbs Sampler</a></p>
<p>13 0.2861549 <a title="111-lsi-13" href="./nips-2000-Feature_Selection_for_SVMs.html">54 nips-2000-Feature Selection for SVMs</a></p>
<p>14 0.2612339 <a title="111-lsi-14" href="./nips-2000-A_Linear_Programming_Approach_to_Novelty_Detection.html">4 nips-2000-A Linear Programming Approach to Novelty Detection</a></p>
<p>15 0.2575275 <a title="111-lsi-15" href="./nips-2000-Improved_Output_Coding_for_Classification_Using_Continuous_Relaxation.html">68 nips-2000-Improved Output Coding for Classification Using Continuous Relaxation</a></p>
<p>16 0.23704247 <a title="111-lsi-16" href="./nips-2000-High-temperature_Expansions_for_Learning_Models_of_Nonnegative_Data.html">64 nips-2000-High-temperature Expansions for Learning Models of Nonnegative Data</a></p>
<p>17 0.23604248 <a title="111-lsi-17" href="./nips-2000-On_Reversing_Jensen%27s_Inequality.html">94 nips-2000-On Reversing Jensen's Inequality</a></p>
<p>18 0.23547551 <a title="111-lsi-18" href="./nips-2000-Support_Vector_Novelty_Detection_Applied_to_Jet_Engine_Vibration_Spectra.html">128 nips-2000-Support Vector Novelty Detection Applied to Jet Engine Vibration Spectra</a></p>
<p>19 0.23134546 <a title="111-lsi-19" href="./nips-2000-Tree-Based_Modeling_and_Estimation_of_Gaussian_Processes_on_Graphs_with_Cycles.html">140 nips-2000-Tree-Based Modeling and Estimation of Gaussian Processes on Graphs with Cycles</a></p>
<p>20 0.22141287 <a title="111-lsi-20" href="./nips-2000-Algebraic_Information_Geometry_for_Learning_Machines_with_Singularities.html">20 nips-2000-Algebraic Information Geometry for Learning Machines with Singularities</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2000_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(6, 0.018), (9, 0.121), (11, 0.031), (16, 0.083), (21, 0.04), (23, 0.221), (32, 0.019), (38, 0.028), (54, 0.029), (67, 0.025), (74, 0.018), (76, 0.016), (84, 0.083), (88, 0.012), (96, 0.094), (97, 0.054)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.79340756 <a title="111-lda-1" href="./nips-2000-Permitted_and_Forbidden_Sets_in_Symmetric_Threshold-Linear_Networks.html">100 nips-2000-Permitted and Forbidden Sets in Symmetric Threshold-Linear Networks</a></p>
<p>2 0.76091021 <a title="111-lda-2" href="./nips-2000-Computing_with_Finite_and_Infinite_Networks.html">35 nips-2000-Computing with Finite and Infinite Networks</a></p>
<p>same-paper 3 0.75541091 <a title="111-lda-3" href="./nips-2000-Regularized_Winnow_Methods.html">111 nips-2000-Regularized Winnow Methods</a></p>
<p>4 0.70130819 <a title="111-lda-4" href="./nips-2000-Learning_Winner-take-all_Competition_Between_Groups_of_Neurons_in_Lateral_Inhibitory_Networks.html">81 nips-2000-Learning Winner-take-all Competition Between Groups of Neurons in Lateral Inhibitory Networks</a></p>
<p>5 0.64244032 <a title="111-lda-5" href="./nips-2000-From_Margin_to_Sparsity.html">58 nips-2000-From Margin to Sparsity</a></p>
<p>6 0.62492776 <a title="111-lda-6" href="./nips-2000-Constrained_Independent_Component_Analysis.html">36 nips-2000-Constrained Independent Component Analysis</a></p>
<p>7 0.60795319 <a title="111-lda-7" href="./nips-2000-A_New_Approximate_Maximal_Margin_Classification_Algorithm.html">7 nips-2000-A New Approximate Maximal Margin Classification Algorithm</a></p>
<p>8 0.59586746 <a title="111-lda-8" href="./nips-2000-Convergence_of_Large_Margin_Separable_Linear_Classification.html">37 nips-2000-Convergence of Large Margin Separable Linear Classification</a></p>
<p>9 0.59476405 <a title="111-lda-9" href="./nips-2000-Higher-Order_Statistical_Properties_Arising_from_the_Non-Stationarity_of_Natural_Signals.html">65 nips-2000-Higher-Order Statistical Properties Arising from the Non-Stationarity of Natural Signals</a></p>
<p>10 0.58355141 <a title="111-lda-10" href="./nips-2000-Generalized_Belief_Propagation.html">62 nips-2000-Generalized Belief Propagation</a></p>
<p>11 0.57318151 <a title="111-lda-11" href="./nips-2000-A_PAC-Bayesian_Margin_Bound_for_Linear_Classifiers%3A_Why_SVMs_work.html">9 nips-2000-A PAC-Bayesian Margin Bound for Linear Classifiers: Why SVMs work</a></p>
<p>12 0.57102787 <a title="111-lda-12" href="./nips-2000-Gaussianization.html">60 nips-2000-Gaussianization</a></p>
<p>13 0.57043988 <a title="111-lda-13" href="./nips-2000-Data_Clustering_by_Markovian_Relaxation_and_the_Information_Bottleneck_Method.html">38 nips-2000-Data Clustering by Markovian Relaxation and the Information Bottleneck Method</a></p>
<p>14 0.57013381 <a title="111-lda-14" href="./nips-2000-Reinforcement_Learning_with_Function_Approximation_Converges_to_a_Region.html">112 nips-2000-Reinforcement Learning with Function Approximation Converges to a Region</a></p>
<p>15 0.57005537 <a title="111-lda-15" href="./nips-2000-A_Variational_Mean-Field_Theory_for_Sigmoidal_Belief_Networks.html">14 nips-2000-A Variational Mean-Field Theory for Sigmoidal Belief Networks</a></p>
<p>16 0.56856674 <a title="111-lda-16" href="./nips-2000-Large_Scale_Bayes_Point_Machines.html">75 nips-2000-Large Scale Bayes Point Machines</a></p>
<p>17 0.56688148 <a title="111-lda-17" href="./nips-2000-Automatic_Choice_of_Dimensionality_for_PCA.html">27 nips-2000-Automatic Choice of Dimensionality for PCA</a></p>
<p>18 0.56523484 <a title="111-lda-18" href="./nips-2000-Kernel-Based_Reinforcement_Learning_in_Average-Cost_Problems%3A_An_Application_to_Optimal_Portfolio_Choice.html">73 nips-2000-Kernel-Based Reinforcement Learning in Average-Cost Problems: An Application to Optimal Portfolio Choice</a></p>
<p>19 0.56499684 <a title="111-lda-19" href="./nips-2000-High-temperature_Expansions_for_Learning_Models_of_Nonnegative_Data.html">64 nips-2000-High-temperature Expansions for Learning Models of Nonnegative Data</a></p>
<p>20 0.56491876 <a title="111-lda-20" href="./nips-2000-Support_Vector_Novelty_Detection_Applied_to_Jet_Engine_Vibration_Spectra.html">128 nips-2000-Support Vector Novelty Detection Applied to Jet Engine Vibration Spectra</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
