<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>42 nips-2000-Divisive and Subtractive Mask Effects: Linking Psychophysics and Biophysics</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2000" href="../home/nips2000_home.html">nips2000</a> <a title="nips-2000-42" href="#">nips2000-42</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>42 nips-2000-Divisive and Subtractive Mask Effects: Linking Psychophysics and Biophysics</h1>
<br/><p>Source: <a title="nips-2000-42-pdf" href="http://papers.nips.cc/paper/1816-divisive-and-subtractive-mask-effects-linking-psychophysics-and-biophysics.pdf">pdf</a></p><p>Author: Barbara Zenger, Christof Koch</p><p>Abstract: We describe an analogy between psychophysically measured effects in contrast masking, and the behavior of a simple integrate-andfire neuron that receives time-modulated inhibition. In the psychophysical experiments, we tested observers ability to discriminate contrasts of peripheral Gabor patches in the presence of collinear Gabor flankers. The data reveal a complex interaction pattern that we account for by assuming that flankers provide divisive inhibition to the target unit for low target contrasts, but provide subtractive inhibition to the target unit for higher target contrasts. A similar switch from divisive to subtractive inhibition is observed in an integrate-and-fire unit that receives inhibition modulated in time such that the cell spends part of the time in a high-inhibition state and part of the time in a low-inhibition state. The similarity between the effects suggests that one may cause the other. The biophysical model makes testable predictions for physiological single-cell recordings. 1 Psychophysics Visual images of Gabor patches are thought to excite a small and specific subset of neurons in the primary visual cortex and beyond. By measuring psychophysically in humans the contrast detection and discrimination thresholds of peripheral Gabor patches, one can estimate the sensitivity of this subset of neurons. Furthermore, spatial interactions between different neuronal populations can be probed by testing the effects of additional Gabor patches (masks) on performance. Such experiments have revealed a highly configuration-specific pattern of excitatory and inhibitory spatial interactions [1, 2]. 1.1 Methods Two vertical Gabor patches with a spatial frequency of 4cyc/deg were presented at 4 deg eccentricity left and right of fixation, and observers had to report which patch had the higher contrast (spatial 2AFC). In the</p><p>Reference: <a title="nips-2000-42-reference" href="../nips2000_reference/nips-2000-Divisive_and_Subtractive_Mask_Effects%3A_Linking_Psychophysics_and_Biophysics_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract We describe an analogy between psychophysically measured effects in contrast masking, and the behavior of a simple integrate-andfire neuron that receives time-modulated inhibition. [sent-5, score-0.314]
</p><p>2 In the psychophysical experiments, we tested observers ability to discriminate contrasts of peripheral Gabor patches in the presence of collinear Gabor flankers. [sent-6, score-0.511]
</p><p>3 The data reveal a complex interaction pattern that we account for by assuming that flankers provide divisive inhibition to the target unit for low target contrasts, but provide subtractive inhibition to the target unit for higher target contrasts. [sent-7, score-2.084]
</p><p>4 A similar switch from divisive to subtractive inhibition is observed in an integrate-and-fire unit that receives inhibition modulated in time such that the cell spends part of the time in a high-inhibition state and part of the time in a low-inhibition state. [sent-8, score-1.703]
</p><p>5 The similarity between the effects suggests that one may cause the other. [sent-9, score-0.077]
</p><p>6 The biophysical model makes testable predictions for physiological single-cell recordings. [sent-10, score-0.106]
</p><p>7 1  Psychophysics  Visual images of Gabor patches are thought to excite a small and specific subset of neurons in the primary visual cortex and beyond. [sent-11, score-0.28]
</p><p>8 By measuring psychophysically in humans the contrast detection and discrimination thresholds of peripheral Gabor patches, one can estimate the sensitivity of this subset of neurons. [sent-12, score-0.515]
</p><p>9 Furthermore, spatial interactions between different neuronal populations can be probed by testing the effects of additional Gabor patches (masks) on performance. [sent-13, score-0.322]
</p><p>10 Such experiments have revealed a highly configuration-specific pattern of excitatory and inhibitory spatial interactions [1, 2]. [sent-14, score-0.286]
</p><p>11 1  Methods  Two vertical Gabor patches with a spatial frequency of 4cyc/deg were presented at 4 deg eccentricity left and right of fixation, and observers had to report which patch had the higher contrast (spatial 2AFC). [sent-16, score-0.498]
</p><p>12 lA),  the two targets were each flanked by two collinear Gabor patches of 40% contrast, presented above and below the targets (at a distance of 0. [sent-18, score-0.427]
</p><p>13 Observers fixated a central cross, which was visible before and during each trial, and then initiated the trial by pressing the space bar on the computer keyboard. [sent-22, score-0.041]
</p><p>14 Two circular cues appeared for 180ms to indicate the locations of the two targets (to minimize spatial uncertainty). [sent-23, score-0.139]
</p><p>15 A blank stimulus of randomized length (500msÂą100ms) was followed by a 83ms stimulus presentation. [sent-24, score-0.062]
</p><p>16 Observers indicated which target had the higher contrast ("left" or "right") by specified keys. [sent-26, score-0.282]
</p><p>17 Seven observers with normal or corrected-to-normal vision participated in the experiment. [sent-30, score-0.15]
</p><p>18 We used color-bit stealing to increase the number of grey levels that can be displayed [4]. [sent-35, score-0.046]
</p><p>19 To remove some of the effects of inter-observer variability from our data analysis, the entire data set of each observer was first normalized by his or her average performance across all conditions, and only then averages and standard errors were computed. [sent-37, score-0.114]
</p><p>20 The mean standard errors across all conditions and contrast levels are presented as bars in Figs. [sent-38, score-0.166]
</p><p>21 2  Results  In the absence of flankers (circles, Fig. [sent-41, score-0.213]
</p><p>22 IB), discrimination thresholds first decrease from absolute detection threshold at 8. [sent-42, score-0.333]
</p><p>23 As common in sensory psychophysics , we assume that the contrast discrimination thresholds can be derived from an underlying sigmoidal contrastresponse function r(c) (see Fig. [sent-44, score-0.514]
</p><p>24 lC, solid curve), together with the assumption that some fixed response difference ~r = 1 is required for correct discrimination [2]. [sent-45, score-0.198]
</p><p>25 In other words, for any fixed pedestal contrast c, the discrimination threshold ~c satisfies r(c + ~c) = r(c) + 1. [sent-46, score-0.471]
</p><p>26 Our underlying assumption is that at the decision stage, the level of noise in the signal is independent of the response magnitude. [sent-47, score-0.139]
</p><p>27 Neuronal noise, on the other hand, is usually well characterized by a Poisson process, that is, the noise level increases with increasing response. [sent-48, score-0.131]
</p><p>28 Little evidence exists, however, that this "early" response dependent noise actually limits the performance. [sent-49, score-0.101]
</p><p>29 It is conceivable that this early noise is relatively small, that the performance-limiting noise is added at a later processing stage, and that this noise is independent of the response magnitude. [sent-50, score-0.173]
</p><p>30 To describe the response r of the system to a single, well-isolated, target as a function of its contrast c we adopt the function suggested by Foley (1994) [2]: acP risolated(C) = r! [sent-51, score-0.347]
</p><p>31 ,-q (1) cP - Q + th For plausible parameters (c, Cth > 0) this function is proportional to cP for cÂŤ Cth  B  A G-<)  no flanks  I SEM  0% 1%  4%  16%  60%  Pedestal contrast c  D  C 10  c. [sent-52, score-0.419]
</p><p>32 >  25%  50% Contrast  75%  100  SEM  8%  Ul  0  0% 1%  4%  16%  60%  Pedestal contrast c  Figure 1: (A) Sample stimuli without flanks and with flanks. [sent-61, score-0.419]
</p><p>33 (B) Discrimination thresholds average across seven observers for flanked (diamond) and unflanked (circles) targets. [sent-62, score-0.422]
</p><p>34 (C) Contrast response functions used for model prediction in (B). [sent-63, score-0.065]
</p><p>35 (D) Discrimination performance averaged across four observers for different flank contrasts. [sent-64, score-0.16]
</p><p>36 1Bi solid line) fit well the psychophysical data (open circles). [sent-71, score-0.096]
</p><p>37 What happens to the dipper function when the two targets are flanked by Gabor patches of 40% contrast? [sent-72, score-0.282]
</p><p>38 In the presence of flankers, contrast discrimination thresholds (diamonds, Fig. [sent-73, score-0.412]
</p><p>39 IB) first decrease, then increase, then decrease again, and finally increase again, following a W-shaped function. [sent-74, score-0.08]
</p><p>40 Depending on target contrast, one can distinguish two distinctive flanker effects: for targets of 40% contrast or less, flankers impair discrimination. [sent-75, score-0.688]
</p><p>41 In the masking literature such suppressive effects are often attributed to a divisive input from the mask to the target; in other words, the flanks seem to reduce the target's gain [2]. [sent-76, score-0.758]
</p><p>42 For targets of 50% or more (four rightmost data points in Fig. [sent-77, score-0.074]
</p><p>43 IB), contrast performance is about the same irrespective of whether flankers are present or not; at these high target contrasts, flankers apparently cease to contribute to the target's gain control. [sent-78, score-0.776]
</p><p>44 Following this concept, we define two model parameters to describe the effects of the flankers: the first parameter, Co, determines the maximal target contrast at which gain control is still effective; the second parameter, b, determines the strength of  the gain control. [sent-79, score-0.495]
</p><p>45 The subtractive constant d is not a free parameter, but is determined by imposing that r be continuous at C = Co, i. [sent-82, score-0.332]
</p><p>46 no flanks 20% flanks 40% flanks 70% flanks q b a p b b Co Co Co Cth Fig. [sent-88, score-0.852]
</p><p>47 3% Increasing the flanker contrast leads both to an increase in the strength of gain control b and to an increase in the range Co in which gain control is effective. [sent-106, score-0.513]
</p><p>48 The predicted discrimination performance is shown superimposed on the data in Fig. [sent-107, score-0.133]
</p><p>49 As one can see, the model captures the behavior of the data reasonably well, considering that for each combined fit there are only four parameters to fit the unflanked data and two additional parameters for each W curve. [sent-109, score-0.071]
</p><p>50 Or, put differently, we use but two degrees of freedom to go from the unflanked to the flanked conditions. [sent-110, score-0.166]
</p><p>51 2  Biophysics  While the above model explains the data, it remains a puzzle how the switch from divisive to subtractive is implemented neuronally. [sent-111, score-0.787]
</p><p>52 Here, we show that time-modulated inhibition can naturally account for the observed switch, without assuming inputdependent changes in the network. [sent-112, score-0.348]
</p><p>53 To simulate the behavior of individual neurons we use a variant of the leaky integrate-and-fire unit (battery Ee = 70mV, capacitance C = 200pF, leak conductance 9pass = IOnS, and firing threshold vth = 20mV, see Fig. [sent-115, score-0.305]
</p><p>54 Excitatory and inhibitory synaptic input are modeled as changes in the conductances ge and gi, respectively. [sent-117, score-0.193]
</p><p>55 Whenever the membrane potential Vm exceeds threshold (Vih), a spike is initiated and the membrane potential Vm is reset to v;. [sent-118, score-0.094]
</p><p>56 2  Simulations  Firing rates for increasing excitation (ge) at various levels of inhibtion (gi) are shown in Fig. [sent-123, score-0.119]
</p><p>57 For low excitatory input the cell never fires, because the input current is counter-balanced by the leakage current, thus preventing the cell from reaching its firing threshold. [sent-125, score-0.376]
</p><p>58 Once the cell does start firing, firing rates first increase very fast, but then rapidly converge against a linear function, whose slope is independent of gi. [sent-126, score-0.364]
</p><p>59 When the inhibitory input is modulated in time and switches between a low  B  A  N JC4oor---------------------~400r---------------------~  c  20ns,  -9j=OnS  ~300  c  9j  - 9 j = 10nS  (\) ~200  rrnn m0DDm  OnS Oms  100ms  200ms  - 9 j =OnS  0-  (\) . [sent-127, score-0.131]
</p><p>60 _~_ _ _ _~_ __ '  0  5  10  15  ge in nS  20  5  10  15  20  ge in nS  Figure 3: Simulations of circuit model with constant inhibition (A) or timemdoulated inhbition (dashed line in (B)). [sent-154, score-0.702]
</p><p>61 This simple single-cell model matches the psychophysics remarkably well. [sent-155, score-0.102]
</p><p>62 inhibition state (gi = glow) and a high inhibition state (gi = ghigh), the results look different (Fig. [sent-156, score-0.79]
</p><p>63 The cell fires part of the time like a lowly inhibited cell, part of the time like a highly inhibited cell, explaining why the overall firing rate resemble weighted averages of the curves for constant gi. [sent-158, score-0.456]
</p><p>64 A comparison of the noinhibition curve (gj = 0) and the curve for time-modulated inhbition demonstrates that inhibition switches from a divisive mode to a subtractive mode for increasing ge. [sent-159, score-1.133]
</p><p>65 The ge-Ievel at which the switch occurs depends on the level of inhibition in the high-inhibition state (here ghigh=20nS). [sent-160, score-0.555]
</p><p>66 The strength of divisive inhibition depends on the percentage of time R that the cell spends in the high-inhibition state; in the example shown as a dashed line in Fig. [sent-161, score-0.841]
</p><p>67 2B, the cell spends on average half of the time in the high-inhibition stage (thus R=50%), and remains the rest of the time in the low-inhibition stage. [sent-162, score-0.213]
</p><p>68 3  Discussion  Both the psychophysical data and the biophysical model show a switch from divisive to subtractive inhibition. [sent-163, score-0.915]
</p><p>69 While these assumptions all seem quite plausible, there remains the question of why one would assume time-modulated inhbition in the first place. [sent-165, score-0.113]
</p><p>70 Here we suggest three different mechanisms: First, the time-modulation might reflect inhibitory input by synchronized interneurons [7], i. [sent-166, score-0.159]
</p><p>71 , sometimes a large number of them fire at the same time (high-inhibition state) while at other times almost none ofthe inhibitory cells fire (low-inhibition state). [sent-168, score-0.097]
</p><p>72 A second plausible implementation (which gives very similar results) assumes that there is only one transition and that the low- and high-inhibition state follow each other sequentially (rather than flipping back and forth as suggested in Fig. [sent-169, score-0.087]
</p><p>73 Indeed, cells in primary visual cortex often show a transient response at stimulus onset (which may reflect the low-inhibition state), followed by a smaller level of sustained response (which may reflect the high-inhibition state). [sent-171, score-0.434]
</p><p>74 In this context, R would simply reflect the time delay between the onset of excitation and inhibition (with a large R representing brief delays before inhibition sets in). [sent-172, score-0.825]
</p><p>75 Finally, low- and high- inhibition states may reflect different subtypes of neurons which receive different amount of surround inhibition. [sent-173, score-0.574]
</p><p>76 In other words, some neurons are strongly inhibited (high-inhibition state) while others are not (low-inhibition state). [sent-174, score-0.195]
</p><p>77 The mean response of all the neurons will show a divisive inhibition in the range where the inhibited neurons are shut off completely, but will show a subtractive inhibition as soon as the inhibited units start firing. [sent-176, score-1.774]
</p><p>78 To summarize on a more abstract level: any mechanism that will average firing rates of different 9i states, rather than averaging different inhibitory inputs 9i, will lead to a mechanism that shows this switch from divisive to subtractive inhibition. [sent-177, score-0.989]
</p><p>79 The remaining differences between the psychophysically estimated contrast-response functions (Fig. [sent-178, score-0.071]
</p><p>80 Ie) and the firing rates of the circuit model (Fig. [sent-179, score-0.207]
</p><p>81 3B) seem to reflect mainly oversimplifications in the biophysical model. [sent-180, score-0.136]
</p><p>82 Saturation at high ge values, for instance, could be achieved by assuming refractory periods or other firing-rate adaptation mechanisms. [sent-181, score-0.143]
</p><p>83 The very steep slope directly after the switch from divisive to subtractive inhibition would disappear if the simple integrate-andfire unit would be replaced by a more realistic unit in which - due to stochastic linearization - the firing rate rises more gradually once the threshold is crossed. [sent-182, score-1.42]
</p><p>84 In any case, one does not expect a precise match between the two functions, as psychophysical performance presumably relies on a variety of different neurons with different dynamic ranges. [sent-183, score-0.189]
</p><p>85 We believe that such a link between a biophysical model and psychophysical data is in principle possible, but have favored here simplicity at the expense of achieving a more quantitative match. [sent-185, score-0.17]
</p><p>86 Our analysis of the circuit model shows that the psychophysical data can be explained without assuming complex interaction patterns between different neuronal units. [sent-186, score-0.19]
</p><p>87 While we have no reason to believe that the switching-mechanism from divisive to subtractive inhibition will become ineffective when considering large number of neurons, it does not require a large network. [sent-187, score-0.971]
</p><p>88 Our model makes two clear predictions: first, the contrast-response function of single neurons should show - in the presence of flankers - a switch from divisive to subtractive inhibition (Fig. [sent-189, score-1.399]
</p><p>89 Physiological studies have measured how stimuli outside the classical receptive field affect the absolute response level of the target unit [8, 9]. [sent-192, score-0.303]
</p><p>90 Distinguishing subtractive and divisive inhibition, however, requires that, in addition, surround effects on the slope of the contrast-response functions are estimated. [sent-193, score-0.842]
</p><p>91 Such experiments have been carried out by Sengpiel et al [10] in cat primary visual cortex. [sent-194, score-0.108]
</p><p>92 Their extracellular recordings show that when a target grating is surrounded by a high-contrast annulus, inhibition is indeed well described by a divisive effect on the response. [sent-195, score-0.755]
</p><p>93 It remains to be seen, however, whether surround annuli whose contrast is lower than the target contrast will act subtractively. [sent-196, score-0.561]
</p><p>94 The second prediction is that inhibition is bistable, i. [sent-197, score-0.348]
</p><p>95 Lateral interactions between spatial channels: Suppression and facilitation revealed by lateral masking experiments. [sent-206, score-0.189]
</p><p>96 Human luminance pattern-vision mechanisms: masking experiments require a new model. [sent-210, score-0.117]
</p><p>97 Colour bit-stealing to enhance the luminance resolution of digital displays on a single pixel basis. [sent-219, score-0.056]
</p><p>98 Contrast dependence of contextual effects in primate visual cortex. [sent-247, score-0.12]
</p><p>99 Collinear stimuli regulate visual responses depending on cell's contrast threshold. [sent-257, score-0.249]
</p><p>100 Different mechanisms underlie three inhibitory phenomena in cat area 17. [sent-267, score-0.163]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('inhibition', 0.348), ('subtractive', 0.332), ('divisive', 0.291), ('flankers', 0.213), ('flanks', 0.213), ('gabor', 0.184), ('contrast', 0.166), ('co', 0.141), ('discrimination', 0.133), ('switch', 0.122), ('flanker', 0.119), ('pedestal', 0.119), ('risolated', 0.119), ('target', 0.116), ('firing', 0.115), ('patches', 0.113), ('thresholds', 0.113), ('observers', 0.113), ('inhibited', 0.102), ('psychophysics', 0.102), ('cell', 0.1), ('inhibitory', 0.097), ('psychophysical', 0.096), ('ge', 0.096), ('caltech', 0.095), ('flanked', 0.095), ('neurons', 0.093), ('contrasts', 0.086), ('cth', 0.082), ('effects', 0.077), ('targets', 0.074), ('biophysical', 0.074), ('collinear', 0.071), ('inhbition', 0.071), ('ons', 0.071), ('psychophysically', 0.071), ('slope', 0.071), ('spends', 0.071), ('surround', 0.071), ('unflanked', 0.071), ('gain', 0.068), ('ib', 0.067), ('spatial', 0.065), ('response', 0.065), ('reflect', 0.062), ('excitatory', 0.061), ('masking', 0.061), ('circuit', 0.06), ('gi', 0.058), ('increasing', 0.057), ('luminance', 0.056), ('threshold', 0.053), ('mask', 0.048), ('flank', 0.047), ('ghigh', 0.047), ('pasadena', 0.047), ('polat', 0.047), ('refractory', 0.047), ('sengpiel', 0.047), ('staircase', 0.047), ('state', 0.047), ('increase', 0.046), ('unit', 0.044), ('biophysics', 0.043), ('visual', 0.043), ('remains', 0.042), ('lc', 0.042), ('initiated', 0.041), ('deg', 0.041), ('sem', 0.041), ('barbara', 0.041), ('stimuli', 0.04), ('plausible', 0.04), ('level', 0.038), ('vision', 0.037), ('onset', 0.037), ('observer', 0.037), ('america', 0.037), ('fires', 0.037), ('noise', 0.036), ('circles', 0.035), ('cat', 0.034), ('switches', 0.034), ('vm', 0.034), ('decrease', 0.034), ('neuronal', 0.034), ('interactions', 0.033), ('peripheral', 0.032), ('physiological', 0.032), ('mechanisms', 0.032), ('rates', 0.032), ('line', 0.031), ('primary', 0.031), ('stimulus', 0.031), ('days', 0.03), ('revealed', 0.03), ('seven', 0.03), ('excitation', 0.03), ('ul', 0.03), ('ns', 0.03)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.000001 <a title="42-tfidf-1" href="./nips-2000-Divisive_and_Subtractive_Mask_Effects%3A_Linking_Psychophysics_and_Biophysics.html">42 nips-2000-Divisive and Subtractive Mask Effects: Linking Psychophysics and Biophysics</a></p>
<p>Author: Barbara Zenger, Christof Koch</p><p>Abstract: We describe an analogy between psychophysically measured effects in contrast masking, and the behavior of a simple integrate-andfire neuron that receives time-modulated inhibition. In the psychophysical experiments, we tested observers ability to discriminate contrasts of peripheral Gabor patches in the presence of collinear Gabor flankers. The data reveal a complex interaction pattern that we account for by assuming that flankers provide divisive inhibition to the target unit for low target contrasts, but provide subtractive inhibition to the target unit for higher target contrasts. A similar switch from divisive to subtractive inhibition is observed in an integrate-and-fire unit that receives inhibition modulated in time such that the cell spends part of the time in a high-inhibition state and part of the time in a low-inhibition state. The similarity between the effects suggests that one may cause the other. The biophysical model makes testable predictions for physiological single-cell recordings. 1 Psychophysics Visual images of Gabor patches are thought to excite a small and specific subset of neurons in the primary visual cortex and beyond. By measuring psychophysically in humans the contrast detection and discrimination thresholds of peripheral Gabor patches, one can estimate the sensitivity of this subset of neurons. Furthermore, spatial interactions between different neuronal populations can be probed by testing the effects of additional Gabor patches (masks) on performance. Such experiments have revealed a highly configuration-specific pattern of excitatory and inhibitory spatial interactions [1, 2]. 1.1 Methods Two vertical Gabor patches with a spatial frequency of 4cyc/deg were presented at 4 deg eccentricity left and right of fixation, and observers had to report which patch had the higher contrast (spatial 2AFC). In the</p><p>2 0.16600415 <a title="42-tfidf-2" href="./nips-2000-Dendritic_Compartmentalization_Could_Underlie_Competition_and_Attentional_Biasing_of_Simultaneous_Visual_Stimuli.html">40 nips-2000-Dendritic Compartmentalization Could Underlie Competition and Attentional Biasing of Simultaneous Visual Stimuli</a></p>
<p>Author: Kevin A. Archie, Bartlett W. Mel</p><p>Abstract: Neurons in area V4 have relatively large receptive fields (RFs), so multiple visual features are simultaneously</p><p>3 0.15403619 <a title="42-tfidf-3" href="./nips-2000-Natural_Sound_Statistics_and_Divisive_Normalization_in_the_Auditory_System.html">89 nips-2000-Natural Sound Statistics and Divisive Normalization in the Auditory System</a></p>
<p>Author: Odelia Schwartz, Eero P. Simoncelli</p><p>Abstract: We explore the statistical properties of natural sound stimuli preprocessed with a bank of linear filters. The responses of such filters exhibit a striking form of statistical dependency, in which the response variance of each filter grows with the response amplitude of filters tuned for nearby frequencies. These dependencies may be substantially reduced using an operation known as divisive normalization, in which the response of each filter is divided by a weighted sum of the rectified responses of other filters. The weights may be chosen to maximize the independence of the normalized responses for an ensemble of natural sounds. We demonstrate that the resulting model accounts for nonlinearities in the response characteristics of the auditory nerve, by comparing model simulations to electrophysiological recordings. In previous work (NIPS, 1998) we demonstrated that an analogous model derived from the statistics of natural images accounts for non-linear properties of neurons in primary visual cortex. Thus, divisive normalization appears to be a generic mechanism for eliminating a type of statistical dependency that is prevalent in natural signals of different modalities. Signals in the real world are highly structured. For example, natural sounds typically contain both harmonic and rythmic structure. It is reasonable to assume that biological auditory systems are designed to represent these structures in an efficient manner [e.g., 1,2]. Specifically, Barlow hypothesized that a role of early sensory processing is to remove redundancy in the sensory input, resulting in a set of neural responses that are statistically independent. Experimentally, one can test this hypothesis by examining the statistical properties of neural responses under natural stimulation conditions [e.g., 3,4], or the statistical dependency of pairs (or groups) of neural responses. Due to their technical difficulty, such multi-cellular experiments are only recently becoming possible, and the earliest reports in vision appear consistent with the hypothesis [e.g., 5]. An alternative approach, which we follow here, is to develop a neural model from the statistics of natural signals and show that response properties of this model are similar to those of biological sensory neurons. A number of researchers have derived linear filter models using statistical criterion. For visual images, this results in linear filters localized in frequency, orientation and phase [6, 7]. Similar work in audition has yielded filters localized in frequency and phase [8]. Although these linear models provide an important starting point for neural modeling, sensory neurons are highly nonlinear. In addition, the statistical properties of natural signals are too complex to expect a linear transformation to result in an independent set of components. Recent results indicate that nonlinear gain control plays an important role in neural processing. Ruderman and Bialek [9] have shown that division by a local estimate of standard deviation can increase the entropy of responses of center-surround filters to natural images. Such a model is consistent with the properties of neurons in the retina and lateral geniculate nucleus. Heeger and colleagues have shown that the nonlinear behaviors of neurons in primary visual cortex may be described using a form of gain control known as divisive normalization [10], in which the response of a linear kernel is rectified and divided by the sum of other rectified kernel responses and a constant. We have recently shown that the responses of oriented linear filters exhibit nonlinear statistical dependencies that may be substantially reduced using a variant of this model, in which the normalization signal is computed from a weighted sum of other rectified kernel responses [11, 12]. The resulting model, with weighting parameters determined from image statistics, accounts qualitatively for physiological nonlinearities observed in primary visual cortex. In this paper, we demonstrate that the responses of bandpass linear filters to natural sounds exhibit striking statistical dependencies, analogous to those found in visual images. A divisive normalization procedure can substantially remove these dependencies. We show that this model, with parameters optimized for a collection of natural sounds, can account for nonlinear behaviors of neurons at the level of the auditory nerve. Specifically, we show that: 1) the shape offrequency tuning curves varies with sound pressure level, even though the underlying linear filters are fixed; and 2) superposition of a non-optimal tone suppresses the response of a linear filter in a divisive fashion, and the amount of suppression depends on the distance between the frequency of the tone and the preferred frequency of the filter. 1 Empirical observations of natural sound statistics The basic statistical properties of natural sounds, as observed through a linear filter, have been previously documented by Attias [13]. In particular, he showed that, as with visual images, the spectral energy falls roughly according to a power law, and that the histograms of filter responses are more kurtotic than a Gaussian (i.e., they have a sharp peak at zero, and very long tails). Here we examine the joint statistical properties of a pair of linear filters tuned for nearby temporal frequencies. We choose a fixed set of filters that have been widely used in modeling the peripheral auditory system [14]. Figure 1 shows joint histograms of the instantaneous responses of a particular pair of linear filters to five different types of natural sound, and white noise. First note that the responses are approximately decorrelated: the expected value of the y-axis value is roughly zero for all values of the x-axis variable. The responses are not, however, statistically independent: the width of the distribution of responses of one filter increases with the response amplitude of the other filter. If the two responses were statistically independent, then the response of the first filter should not provide any information about the distribution of responses of the other filter. We have found that this type of variance dependency (sometimes accompanied by linear correlation) occurs in a wide range of natural sounds, ranging from animal sounds to music. We emphasize that this dependency is a property of natural sounds, and is not due purely to our choice of linear filters. For example, no such dependency is observed when the input consists of white noise (see Fig. 1). The strength of this dependency varies for different pairs of linear filters . In addition, we see this type of dependency between instantaneous responses of a single filter at two Speech o -1 Drums • Monkey Cat White noise Nocturnal nature I~ ~; ~ • Figure 1: Joint conditional histogram of instantaneous linear responses of two bandpass filters with center frequencies 2000 and 2840 Hz. Pixel intensity corresponds to frequency of occurrence of a given pair of values, except that each column has been independently rescaled to fill the full intensity range. For the natural sounds, responses are not independent: the standard deviation of the ordinate is roughly proportional to the magnitude of the abscissa. Natural sounds were recorded from CDs and converted to sampling frequency of 22050 Hz. nearby time instants. Since the dependency involves the variance of the responses, we can substantially reduce it by dividing. In particular, the response of each filter is divided by a weighted sum of responses of other rectified filters and an additive constant. Specifically: L2 Ri = 2: (1) 12 j WjiLj + 0'2 where Li is the instantaneous linear response of filter i, strength of suppression of filter i by filter j. 0' is a constant and Wji controls the We would like to choose the parameters of the model (the weights Wji, and the constant 0') to optimize the independence of the normalized response to an ensemble of natural sounds. Such an optimization is quite computationally expensive. We instead assume a Gaussian form for the underlying conditional distribution, as described in [15]: P (LiILj,j E Ni ) '</p><p>4 0.11880311 <a title="42-tfidf-4" href="./nips-2000-Place_Cells_and_Spatial_Navigation_Based_on_2D_Visual_Feature_Extraction%2C_Path_Integration%2C_and_Reinforcement_Learning.html">101 nips-2000-Place Cells and Spatial Navigation Based on 2D Visual Feature Extraction, Path Integration, and Reinforcement Learning</a></p>
<p>Author: Angelo Arleo, Fabrizio Smeraldi, Stéphane Hug, Wulfram Gerstner</p><p>Abstract: We model hippocampal place cells and head-direction cells by combining allothetic (visual) and idiothetic (proprioceptive) stimuli. Visual input, provided by a video camera on a miniature robot, is preprocessed by a set of Gabor filters on 31 nodes of a log-polar retinotopic graph. Unsupervised Hebbian learning is employed to incrementally build a population of localized overlapping place fields. Place cells serve as basis functions for reinforcement learning. Experimental results for goal-oriented navigation of a mobile robot are presented.</p><p>5 0.11585049 <a title="42-tfidf-5" href="./nips-2000-Learning_Winner-take-all_Competition_Between_Groups_of_Neurons_in_Lateral_Inhibitory_Networks.html">81 nips-2000-Learning Winner-take-all Competition Between Groups of Neurons in Lateral Inhibitory Networks</a></p>
<p>Author: Xiaohui Xie, Richard H. R. Hahnloser, H. Sebastian Seung</p><p>Abstract: It has long been known that lateral inhibition in neural networks can lead to a winner-take-all competition, so that only a single neuron is active at a steady state. Here we show how to organize lateral inhibition so that groups of neurons compete to be active. Given a collection of potentially overlapping groups, the inhibitory connectivity is set by a formula that can be interpreted as arising from a simple learning rule. Our analysis demonstrates that such inhibition generally results in winner-take-all competition between the given groups, with the exception of some degenerate cases. In a broader context, the network serves as a particular illustration of the general distinction between permitted and forbidden sets, which was introduced recently. From this viewpoint, the computational function of our network is to store and retrieve memories as permitted sets of coactive neurons. In traditional winner-take-all networks, lateral inhibition is used to enforce a localized, or</p><p>6 0.094180502 <a title="42-tfidf-6" href="./nips-2000-Position_Variance%2C_Recurrence_and_Perceptual_Learning.html">102 nips-2000-Position Variance, Recurrence and Perceptual Learning</a></p>
<p>7 0.090903968 <a title="42-tfidf-7" href="./nips-2000-Multiple_Timescales_of_Adaptation_in_a_Neural_Code.html">88 nips-2000-Multiple Timescales of Adaptation in a Neural Code</a></p>
<p>8 0.084591456 <a title="42-tfidf-8" href="./nips-2000-Homeostasis_in_a_Silicon_Integrate_and_Fire_Neuron.html">67 nips-2000-Homeostasis in a Silicon Integrate and Fire Neuron</a></p>
<p>9 0.083642364 <a title="42-tfidf-9" href="./nips-2000-A_New_Model_of_Spatial_Representation_in_Multimodal_Brain_Areas.html">8 nips-2000-A New Model of Spatial Representation in Multimodal Brain Areas</a></p>
<p>10 0.081630863 <a title="42-tfidf-10" href="./nips-2000-Temporally_Dependent_Plasticity%3A_An_Information_Theoretic_Account.html">129 nips-2000-Temporally Dependent Plasticity: An Information Theoretic Account</a></p>
<p>11 0.078404345 <a title="42-tfidf-11" href="./nips-2000-Spike-Timing-Dependent_Learning_for_Oscillatory_Networks.html">124 nips-2000-Spike-Timing-Dependent Learning for Oscillatory Networks</a></p>
<p>12 0.072089851 <a title="42-tfidf-12" href="./nips-2000-A_Productive%2C_Systematic_Framework_for_the_Representation_of_Visual_Structure.html">10 nips-2000-A Productive, Systematic Framework for the Representation of Visual Structure</a></p>
<p>13 0.068555698 <a title="42-tfidf-13" href="./nips-2000-Stability_and_Noise_in_Biochemical_Switches.html">125 nips-2000-Stability and Noise in Biochemical Switches</a></p>
<p>14 0.067678839 <a title="42-tfidf-14" href="./nips-2000-Adaptive_Object_Representation_with_Hierarchically-Distributed_Memory_Sites.html">19 nips-2000-Adaptive Object Representation with Hierarchically-Distributed Memory Sites</a></p>
<p>15 0.065815724 <a title="42-tfidf-15" href="./nips-2000-What_Can_a_Single_Neuron_Compute%3F.html">146 nips-2000-What Can a Single Neuron Compute?</a></p>
<p>16 0.061865162 <a title="42-tfidf-16" href="./nips-2000-Finding_the_Key_to_a_Synapse.html">55 nips-2000-Finding the Key to a Synapse</a></p>
<p>17 0.058612484 <a title="42-tfidf-17" href="./nips-2000-Foundations_for_a_Circuit_Complexity_Theory_of_Sensory_Processing.html">56 nips-2000-Foundations for a Circuit Complexity Theory of Sensory Processing</a></p>
<p>18 0.057709325 <a title="42-tfidf-18" href="./nips-2000-Processing_of_Time_Series_by_Neural_Circuits_with_Biologically_Realistic_Synaptic_Dynamics.html">104 nips-2000-Processing of Time Series by Neural Circuits with Biologically Realistic Synaptic Dynamics</a></p>
<p>19 0.057683613 <a title="42-tfidf-19" href="./nips-2000-Dopamine_Bonuses.html">43 nips-2000-Dopamine Bonuses</a></p>
<p>20 0.057382118 <a title="42-tfidf-20" href="./nips-2000-Emergence_of_Movement_Sensitive_Neurons%27_Properties_by_Learning_a_Sparse_Code_for_Natural_Moving_Images.html">45 nips-2000-Emergence of Movement Sensitive Neurons' Properties by Learning a Sparse Code for Natural Moving Images</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2000_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.172), (1, -0.196), (2, -0.175), (3, -0.008), (4, -0.02), (5, -0.009), (6, 0.064), (7, -0.126), (8, 0.094), (9, -0.053), (10, 0.035), (11, 0.1), (12, -0.045), (13, -0.004), (14, 0.045), (15, -0.009), (16, 0.024), (17, 0.018), (18, -0.03), (19, -0.028), (20, -0.014), (21, 0.11), (22, 0.062), (23, -0.048), (24, 0.079), (25, -0.047), (26, -0.12), (27, -0.016), (28, 0.128), (29, -0.008), (30, -0.002), (31, 0.031), (32, -0.116), (33, 0.01), (34, -0.031), (35, 0.07), (36, -0.129), (37, -0.219), (38, -0.032), (39, 0.239), (40, -0.08), (41, -0.016), (42, -0.048), (43, -0.025), (44, -0.066), (45, -0.091), (46, 0.076), (47, -0.188), (48, -0.065), (49, 0.072)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96425515 <a title="42-lsi-1" href="./nips-2000-Divisive_and_Subtractive_Mask_Effects%3A_Linking_Psychophysics_and_Biophysics.html">42 nips-2000-Divisive and Subtractive Mask Effects: Linking Psychophysics and Biophysics</a></p>
<p>Author: Barbara Zenger, Christof Koch</p><p>Abstract: We describe an analogy between psychophysically measured effects in contrast masking, and the behavior of a simple integrate-andfire neuron that receives time-modulated inhibition. In the psychophysical experiments, we tested observers ability to discriminate contrasts of peripheral Gabor patches in the presence of collinear Gabor flankers. The data reveal a complex interaction pattern that we account for by assuming that flankers provide divisive inhibition to the target unit for low target contrasts, but provide subtractive inhibition to the target unit for higher target contrasts. A similar switch from divisive to subtractive inhibition is observed in an integrate-and-fire unit that receives inhibition modulated in time such that the cell spends part of the time in a high-inhibition state and part of the time in a low-inhibition state. The similarity between the effects suggests that one may cause the other. The biophysical model makes testable predictions for physiological single-cell recordings. 1 Psychophysics Visual images of Gabor patches are thought to excite a small and specific subset of neurons in the primary visual cortex and beyond. By measuring psychophysically in humans the contrast detection and discrimination thresholds of peripheral Gabor patches, one can estimate the sensitivity of this subset of neurons. Furthermore, spatial interactions between different neuronal populations can be probed by testing the effects of additional Gabor patches (masks) on performance. Such experiments have revealed a highly configuration-specific pattern of excitatory and inhibitory spatial interactions [1, 2]. 1.1 Methods Two vertical Gabor patches with a spatial frequency of 4cyc/deg were presented at 4 deg eccentricity left and right of fixation, and observers had to report which patch had the higher contrast (spatial 2AFC). In the</p><p>2 0.77456808 <a title="42-lsi-2" href="./nips-2000-Dendritic_Compartmentalization_Could_Underlie_Competition_and_Attentional_Biasing_of_Simultaneous_Visual_Stimuli.html">40 nips-2000-Dendritic Compartmentalization Could Underlie Competition and Attentional Biasing of Simultaneous Visual Stimuli</a></p>
<p>Author: Kevin A. Archie, Bartlett W. Mel</p><p>Abstract: Neurons in area V4 have relatively large receptive fields (RFs), so multiple visual features are simultaneously</p><p>3 0.56911969 <a title="42-lsi-3" href="./nips-2000-Natural_Sound_Statistics_and_Divisive_Normalization_in_the_Auditory_System.html">89 nips-2000-Natural Sound Statistics and Divisive Normalization in the Auditory System</a></p>
<p>Author: Odelia Schwartz, Eero P. Simoncelli</p><p>Abstract: We explore the statistical properties of natural sound stimuli preprocessed with a bank of linear filters. The responses of such filters exhibit a striking form of statistical dependency, in which the response variance of each filter grows with the response amplitude of filters tuned for nearby frequencies. These dependencies may be substantially reduced using an operation known as divisive normalization, in which the response of each filter is divided by a weighted sum of the rectified responses of other filters. The weights may be chosen to maximize the independence of the normalized responses for an ensemble of natural sounds. We demonstrate that the resulting model accounts for nonlinearities in the response characteristics of the auditory nerve, by comparing model simulations to electrophysiological recordings. In previous work (NIPS, 1998) we demonstrated that an analogous model derived from the statistics of natural images accounts for non-linear properties of neurons in primary visual cortex. Thus, divisive normalization appears to be a generic mechanism for eliminating a type of statistical dependency that is prevalent in natural signals of different modalities. Signals in the real world are highly structured. For example, natural sounds typically contain both harmonic and rythmic structure. It is reasonable to assume that biological auditory systems are designed to represent these structures in an efficient manner [e.g., 1,2]. Specifically, Barlow hypothesized that a role of early sensory processing is to remove redundancy in the sensory input, resulting in a set of neural responses that are statistically independent. Experimentally, one can test this hypothesis by examining the statistical properties of neural responses under natural stimulation conditions [e.g., 3,4], or the statistical dependency of pairs (or groups) of neural responses. Due to their technical difficulty, such multi-cellular experiments are only recently becoming possible, and the earliest reports in vision appear consistent with the hypothesis [e.g., 5]. An alternative approach, which we follow here, is to develop a neural model from the statistics of natural signals and show that response properties of this model are similar to those of biological sensory neurons. A number of researchers have derived linear filter models using statistical criterion. For visual images, this results in linear filters localized in frequency, orientation and phase [6, 7]. Similar work in audition has yielded filters localized in frequency and phase [8]. Although these linear models provide an important starting point for neural modeling, sensory neurons are highly nonlinear. In addition, the statistical properties of natural signals are too complex to expect a linear transformation to result in an independent set of components. Recent results indicate that nonlinear gain control plays an important role in neural processing. Ruderman and Bialek [9] have shown that division by a local estimate of standard deviation can increase the entropy of responses of center-surround filters to natural images. Such a model is consistent with the properties of neurons in the retina and lateral geniculate nucleus. Heeger and colleagues have shown that the nonlinear behaviors of neurons in primary visual cortex may be described using a form of gain control known as divisive normalization [10], in which the response of a linear kernel is rectified and divided by the sum of other rectified kernel responses and a constant. We have recently shown that the responses of oriented linear filters exhibit nonlinear statistical dependencies that may be substantially reduced using a variant of this model, in which the normalization signal is computed from a weighted sum of other rectified kernel responses [11, 12]. The resulting model, with weighting parameters determined from image statistics, accounts qualitatively for physiological nonlinearities observed in primary visual cortex. In this paper, we demonstrate that the responses of bandpass linear filters to natural sounds exhibit striking statistical dependencies, analogous to those found in visual images. A divisive normalization procedure can substantially remove these dependencies. We show that this model, with parameters optimized for a collection of natural sounds, can account for nonlinear behaviors of neurons at the level of the auditory nerve. Specifically, we show that: 1) the shape offrequency tuning curves varies with sound pressure level, even though the underlying linear filters are fixed; and 2) superposition of a non-optimal tone suppresses the response of a linear filter in a divisive fashion, and the amount of suppression depends on the distance between the frequency of the tone and the preferred frequency of the filter. 1 Empirical observations of natural sound statistics The basic statistical properties of natural sounds, as observed through a linear filter, have been previously documented by Attias [13]. In particular, he showed that, as with visual images, the spectral energy falls roughly according to a power law, and that the histograms of filter responses are more kurtotic than a Gaussian (i.e., they have a sharp peak at zero, and very long tails). Here we examine the joint statistical properties of a pair of linear filters tuned for nearby temporal frequencies. We choose a fixed set of filters that have been widely used in modeling the peripheral auditory system [14]. Figure 1 shows joint histograms of the instantaneous responses of a particular pair of linear filters to five different types of natural sound, and white noise. First note that the responses are approximately decorrelated: the expected value of the y-axis value is roughly zero for all values of the x-axis variable. The responses are not, however, statistically independent: the width of the distribution of responses of one filter increases with the response amplitude of the other filter. If the two responses were statistically independent, then the response of the first filter should not provide any information about the distribution of responses of the other filter. We have found that this type of variance dependency (sometimes accompanied by linear correlation) occurs in a wide range of natural sounds, ranging from animal sounds to music. We emphasize that this dependency is a property of natural sounds, and is not due purely to our choice of linear filters. For example, no such dependency is observed when the input consists of white noise (see Fig. 1). The strength of this dependency varies for different pairs of linear filters . In addition, we see this type of dependency between instantaneous responses of a single filter at two Speech o -1 Drums • Monkey Cat White noise Nocturnal nature I~ ~; ~ • Figure 1: Joint conditional histogram of instantaneous linear responses of two bandpass filters with center frequencies 2000 and 2840 Hz. Pixel intensity corresponds to frequency of occurrence of a given pair of values, except that each column has been independently rescaled to fill the full intensity range. For the natural sounds, responses are not independent: the standard deviation of the ordinate is roughly proportional to the magnitude of the abscissa. Natural sounds were recorded from CDs and converted to sampling frequency of 22050 Hz. nearby time instants. Since the dependency involves the variance of the responses, we can substantially reduce it by dividing. In particular, the response of each filter is divided by a weighted sum of responses of other rectified filters and an additive constant. Specifically: L2 Ri = 2: (1) 12 j WjiLj + 0'2 where Li is the instantaneous linear response of filter i, strength of suppression of filter i by filter j. 0' is a constant and Wji controls the We would like to choose the parameters of the model (the weights Wji, and the constant 0') to optimize the independence of the normalized response to an ensemble of natural sounds. Such an optimization is quite computationally expensive. We instead assume a Gaussian form for the underlying conditional distribution, as described in [15]: P (LiILj,j E Ni ) '</p><p>4 0.44514784 <a title="42-lsi-4" href="./nips-2000-A_New_Model_of_Spatial_Representation_in_Multimodal_Brain_Areas.html">8 nips-2000-A New Model of Spatial Representation in Multimodal Brain Areas</a></p>
<p>Author: Sophie Denève, Jean-René Duhamel, Alexandre Pouget</p><p>Abstract: Most models of spatial representations in the cortex assume cells with limited receptive fields that are defined in a particular egocentric frame of reference. However, cells outside of primary sensory cortex are either gain modulated by postural input or partially shifting. We show that solving classical spatial tasks, like sensory prediction, multi-sensory integration, sensory-motor transformation and motor control requires more complicated intermediate representations that are not invariant in one frame of reference. We present an iterative basis function map that performs these spatial tasks optimally with gain modulated and partially shifting units, and tests it against neurophysiological and neuropsychological data. In order to perform an action directed toward an object, it is necessary to have a representation of its spatial location. The brain must be able to use spatial cues coming from different modalities (e.g. vision, audition, touch, proprioception), combine them to infer the position of the object, and compute the appropriate movement. These cues are in different frames of reference corresponding to different sensory or motor modalities. Visual inputs are primarily encoded in retinotopic maps, auditory inputs are encoded in head centered maps and tactile cues are encoded in skin-centered maps. Going from one frame of reference to the other might seem easy. For example, the head-centered position of an object can be approximated by the sum of its retinotopic position and the eye position. However, positions are represented by population codes in the brain, and computing a head-centered map from a retinotopic map is a more complex computation than the underlying sum. Moreover, as we get closer to sensory-motor areas it seems reasonable to assume Spksls 150 100 50 o Figure 1: Response of a VIP cell to visual stimuli appearing in different part of the screen, for three different eye positions. The level of grey represent the frequency of discharge (In spikes per seconds). The white cross is the fixation point (the head is fixed). The cell's receptive field is moving with the eyes, but only partially. Here the receptive field shift is 60% of the total gaze shift. Moreover this cell is gain modulated by eye position (adapted from Duhamel et al). that the representations should be useful for sensory-motor transformations, rather than encode an</p><p>5 0.38432482 <a title="42-lsi-5" href="./nips-2000-Spike-Timing-Dependent_Learning_for_Oscillatory_Networks.html">124 nips-2000-Spike-Timing-Dependent Learning for Oscillatory Networks</a></p>
<p>Author: Silvia Scarpetta, Zhaoping Li, John A. Hertz</p><p>Abstract: We apply to oscillatory networks a class of learning rules in which synaptic weights change proportional to pre- and post-synaptic activity, with a kernel A(r) measuring the effect for a postsynaptic spike a time r after the presynaptic one. The resulting synaptic matrices have an outer-product form in which the oscillating patterns are represented as complex vectors. In a simple model, the even part of A(r) enhances the resonant response to learned stimulus by reducing the effective damping, while the odd part determines the frequency of oscillation. We relate our model to the olfactory cortex and hippocampus and their presumed roles in forming associative memories and input representations. 1</p><p>6 0.37504777 <a title="42-lsi-6" href="./nips-2000-Multiple_Timescales_of_Adaptation_in_a_Neural_Code.html">88 nips-2000-Multiple Timescales of Adaptation in a Neural Code</a></p>
<p>7 0.32880062 <a title="42-lsi-7" href="./nips-2000-A_Productive%2C_Systematic_Framework_for_the_Representation_of_Visual_Structure.html">10 nips-2000-A Productive, Systematic Framework for the Representation of Visual Structure</a></p>
<p>8 0.32259917 <a title="42-lsi-8" href="./nips-2000-Homeostasis_in_a_Silicon_Integrate_and_Fire_Neuron.html">67 nips-2000-Homeostasis in a Silicon Integrate and Fire Neuron</a></p>
<p>9 0.30921865 <a title="42-lsi-9" href="./nips-2000-Dopamine_Bonuses.html">43 nips-2000-Dopamine Bonuses</a></p>
<p>10 0.30489787 <a title="42-lsi-10" href="./nips-2000-Place_Cells_and_Spatial_Navigation_Based_on_2D_Visual_Feature_Extraction%2C_Path_Integration%2C_and_Reinforcement_Learning.html">101 nips-2000-Place Cells and Spatial Navigation Based on 2D Visual Feature Extraction, Path Integration, and Reinforcement Learning</a></p>
<p>11 0.29708177 <a title="42-lsi-11" href="./nips-2000-The_Early_Word_Catches_the_Weights.html">131 nips-2000-The Early Word Catches the Weights</a></p>
<p>12 0.27886453 <a title="42-lsi-12" href="./nips-2000-Adaptive_Object_Representation_with_Hierarchically-Distributed_Memory_Sites.html">19 nips-2000-Adaptive Object Representation with Hierarchically-Distributed Memory Sites</a></p>
<p>13 0.27781075 <a title="42-lsi-13" href="./nips-2000-Color_Opponency_Constitutes_a_Sparse_Representation_for_the_Chromatic_Structure_of_Natural_Scenes.html">32 nips-2000-Color Opponency Constitutes a Sparse Representation for the Chromatic Structure of Natural Scenes</a></p>
<p>14 0.27472994 <a title="42-lsi-14" href="./nips-2000-Learning_Winner-take-all_Competition_Between_Groups_of_Neurons_in_Lateral_Inhibitory_Networks.html">81 nips-2000-Learning Winner-take-all Competition Between Groups of Neurons in Lateral Inhibitory Networks</a></p>
<p>15 0.26879215 <a title="42-lsi-15" href="./nips-2000-Stability_and_Noise_in_Biochemical_Switches.html">125 nips-2000-Stability and Noise in Biochemical Switches</a></p>
<p>16 0.26648393 <a title="42-lsi-16" href="./nips-2000-Position_Variance%2C_Recurrence_and_Perceptual_Learning.html">102 nips-2000-Position Variance, Recurrence and Perceptual Learning</a></p>
<p>17 0.26518434 <a title="42-lsi-17" href="./nips-2000-Who_Does_What%3F_A_Novel_Algorithm_to_Determine_Function_Localization.html">147 nips-2000-Who Does What? A Novel Algorithm to Determine Function Localization</a></p>
<p>18 0.23909242 <a title="42-lsi-18" href="./nips-2000-Bayesian_Video_Shot_Segmentation.html">30 nips-2000-Bayesian Video Shot Segmentation</a></p>
<p>19 0.23303157 <a title="42-lsi-19" href="./nips-2000-Processing_of_Time_Series_by_Neural_Circuits_with_Biologically_Realistic_Synaptic_Dynamics.html">104 nips-2000-Processing of Time Series by Neural Circuits with Biologically Realistic Synaptic Dynamics</a></p>
<p>20 0.21888238 <a title="42-lsi-20" href="./nips-2000-Emergence_of_Movement_Sensitive_Neurons%27_Properties_by_Learning_a_Sparse_Code_for_Natural_Moving_Images.html">45 nips-2000-Emergence of Movement Sensitive Neurons' Properties by Learning a Sparse Code for Natural Moving Images</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2000_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.018), (10, 0.028), (17, 0.123), (33, 0.034), (42, 0.464), (54, 0.012), (55, 0.038), (62, 0.031), (65, 0.019), (67, 0.036), (76, 0.032), (79, 0.019), (81, 0.026), (90, 0.016), (93, 0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.90588039 <a title="42-lda-1" href="./nips-2000-Divisive_and_Subtractive_Mask_Effects%3A_Linking_Psychophysics_and_Biophysics.html">42 nips-2000-Divisive and Subtractive Mask Effects: Linking Psychophysics and Biophysics</a></p>
<p>Author: Barbara Zenger, Christof Koch</p><p>Abstract: We describe an analogy between psychophysically measured effects in contrast masking, and the behavior of a simple integrate-andfire neuron that receives time-modulated inhibition. In the psychophysical experiments, we tested observers ability to discriminate contrasts of peripheral Gabor patches in the presence of collinear Gabor flankers. The data reveal a complex interaction pattern that we account for by assuming that flankers provide divisive inhibition to the target unit for low target contrasts, but provide subtractive inhibition to the target unit for higher target contrasts. A similar switch from divisive to subtractive inhibition is observed in an integrate-and-fire unit that receives inhibition modulated in time such that the cell spends part of the time in a high-inhibition state and part of the time in a low-inhibition state. The similarity between the effects suggests that one may cause the other. The biophysical model makes testable predictions for physiological single-cell recordings. 1 Psychophysics Visual images of Gabor patches are thought to excite a small and specific subset of neurons in the primary visual cortex and beyond. By measuring psychophysically in humans the contrast detection and discrimination thresholds of peripheral Gabor patches, one can estimate the sensitivity of this subset of neurons. Furthermore, spatial interactions between different neuronal populations can be probed by testing the effects of additional Gabor patches (masks) on performance. Such experiments have revealed a highly configuration-specific pattern of excitatory and inhibitory spatial interactions [1, 2]. 1.1 Methods Two vertical Gabor patches with a spatial frequency of 4cyc/deg were presented at 4 deg eccentricity left and right of fixation, and observers had to report which patch had the higher contrast (spatial 2AFC). In the</p><p>2 0.84125376 <a title="42-lda-2" href="./nips-2000-Multiple_Timescales_of_Adaptation_in_a_Neural_Code.html">88 nips-2000-Multiple Timescales of Adaptation in a Neural Code</a></p>
<p>Author: Adrienne L. Fairhall, Geoffrey D. Lewen, William Bialek, Robert R. de Ruyter van Steveninck</p><p>Abstract: Many neural systems extend their dynamic range by adaptation. We examine the timescales of adaptation in the context of dynamically modulated rapidly-varying stimuli, and demonstrate in the fly visual system that adaptation to the statistical ensemble of the stimulus dynamically maximizes information transmission about the time-dependent stimulus. Further, while the rate response has long transients, the adaptation takes place on timescales consistent with optimal variance estimation.</p><p>3 0.59641606 <a title="42-lda-3" href="./nips-2000-Dendritic_Compartmentalization_Could_Underlie_Competition_and_Attentional_Biasing_of_Simultaneous_Visual_Stimuli.html">40 nips-2000-Dendritic Compartmentalization Could Underlie Competition and Attentional Biasing of Simultaneous Visual Stimuli</a></p>
<p>Author: Kevin A. Archie, Bartlett W. Mel</p><p>Abstract: Neurons in area V4 have relatively large receptive fields (RFs), so multiple visual features are simultaneously</p><p>4 0.44720265 <a title="42-lda-4" href="./nips-2000-A_New_Model_of_Spatial_Representation_in_Multimodal_Brain_Areas.html">8 nips-2000-A New Model of Spatial Representation in Multimodal Brain Areas</a></p>
<p>Author: Sophie Denève, Jean-René Duhamel, Alexandre Pouget</p><p>Abstract: Most models of spatial representations in the cortex assume cells with limited receptive fields that are defined in a particular egocentric frame of reference. However, cells outside of primary sensory cortex are either gain modulated by postural input or partially shifting. We show that solving classical spatial tasks, like sensory prediction, multi-sensory integration, sensory-motor transformation and motor control requires more complicated intermediate representations that are not invariant in one frame of reference. We present an iterative basis function map that performs these spatial tasks optimally with gain modulated and partially shifting units, and tests it against neurophysiological and neuropsychological data. In order to perform an action directed toward an object, it is necessary to have a representation of its spatial location. The brain must be able to use spatial cues coming from different modalities (e.g. vision, audition, touch, proprioception), combine them to infer the position of the object, and compute the appropriate movement. These cues are in different frames of reference corresponding to different sensory or motor modalities. Visual inputs are primarily encoded in retinotopic maps, auditory inputs are encoded in head centered maps and tactile cues are encoded in skin-centered maps. Going from one frame of reference to the other might seem easy. For example, the head-centered position of an object can be approximated by the sum of its retinotopic position and the eye position. However, positions are represented by population codes in the brain, and computing a head-centered map from a retinotopic map is a more complex computation than the underlying sum. Moreover, as we get closer to sensory-motor areas it seems reasonable to assume Spksls 150 100 50 o Figure 1: Response of a VIP cell to visual stimuli appearing in different part of the screen, for three different eye positions. The level of grey represent the frequency of discharge (In spikes per seconds). The white cross is the fixation point (the head is fixed). The cell's receptive field is moving with the eyes, but only partially. Here the receptive field shift is 60% of the total gaze shift. Moreover this cell is gain modulated by eye position (adapted from Duhamel et al). that the representations should be useful for sensory-motor transformations, rather than encode an</p><p>5 0.42750844 <a title="42-lda-5" href="./nips-2000-Natural_Sound_Statistics_and_Divisive_Normalization_in_the_Auditory_System.html">89 nips-2000-Natural Sound Statistics and Divisive Normalization in the Auditory System</a></p>
<p>Author: Odelia Schwartz, Eero P. Simoncelli</p><p>Abstract: We explore the statistical properties of natural sound stimuli preprocessed with a bank of linear filters. The responses of such filters exhibit a striking form of statistical dependency, in which the response variance of each filter grows with the response amplitude of filters tuned for nearby frequencies. These dependencies may be substantially reduced using an operation known as divisive normalization, in which the response of each filter is divided by a weighted sum of the rectified responses of other filters. The weights may be chosen to maximize the independence of the normalized responses for an ensemble of natural sounds. We demonstrate that the resulting model accounts for nonlinearities in the response characteristics of the auditory nerve, by comparing model simulations to electrophysiological recordings. In previous work (NIPS, 1998) we demonstrated that an analogous model derived from the statistics of natural images accounts for non-linear properties of neurons in primary visual cortex. Thus, divisive normalization appears to be a generic mechanism for eliminating a type of statistical dependency that is prevalent in natural signals of different modalities. Signals in the real world are highly structured. For example, natural sounds typically contain both harmonic and rythmic structure. It is reasonable to assume that biological auditory systems are designed to represent these structures in an efficient manner [e.g., 1,2]. Specifically, Barlow hypothesized that a role of early sensory processing is to remove redundancy in the sensory input, resulting in a set of neural responses that are statistically independent. Experimentally, one can test this hypothesis by examining the statistical properties of neural responses under natural stimulation conditions [e.g., 3,4], or the statistical dependency of pairs (or groups) of neural responses. Due to their technical difficulty, such multi-cellular experiments are only recently becoming possible, and the earliest reports in vision appear consistent with the hypothesis [e.g., 5]. An alternative approach, which we follow here, is to develop a neural model from the statistics of natural signals and show that response properties of this model are similar to those of biological sensory neurons. A number of researchers have derived linear filter models using statistical criterion. For visual images, this results in linear filters localized in frequency, orientation and phase [6, 7]. Similar work in audition has yielded filters localized in frequency and phase [8]. Although these linear models provide an important starting point for neural modeling, sensory neurons are highly nonlinear. In addition, the statistical properties of natural signals are too complex to expect a linear transformation to result in an independent set of components. Recent results indicate that nonlinear gain control plays an important role in neural processing. Ruderman and Bialek [9] have shown that division by a local estimate of standard deviation can increase the entropy of responses of center-surround filters to natural images. Such a model is consistent with the properties of neurons in the retina and lateral geniculate nucleus. Heeger and colleagues have shown that the nonlinear behaviors of neurons in primary visual cortex may be described using a form of gain control known as divisive normalization [10], in which the response of a linear kernel is rectified and divided by the sum of other rectified kernel responses and a constant. We have recently shown that the responses of oriented linear filters exhibit nonlinear statistical dependencies that may be substantially reduced using a variant of this model, in which the normalization signal is computed from a weighted sum of other rectified kernel responses [11, 12]. The resulting model, with weighting parameters determined from image statistics, accounts qualitatively for physiological nonlinearities observed in primary visual cortex. In this paper, we demonstrate that the responses of bandpass linear filters to natural sounds exhibit striking statistical dependencies, analogous to those found in visual images. A divisive normalization procedure can substantially remove these dependencies. We show that this model, with parameters optimized for a collection of natural sounds, can account for nonlinear behaviors of neurons at the level of the auditory nerve. Specifically, we show that: 1) the shape offrequency tuning curves varies with sound pressure level, even though the underlying linear filters are fixed; and 2) superposition of a non-optimal tone suppresses the response of a linear filter in a divisive fashion, and the amount of suppression depends on the distance between the frequency of the tone and the preferred frequency of the filter. 1 Empirical observations of natural sound statistics The basic statistical properties of natural sounds, as observed through a linear filter, have been previously documented by Attias [13]. In particular, he showed that, as with visual images, the spectral energy falls roughly according to a power law, and that the histograms of filter responses are more kurtotic than a Gaussian (i.e., they have a sharp peak at zero, and very long tails). Here we examine the joint statistical properties of a pair of linear filters tuned for nearby temporal frequencies. We choose a fixed set of filters that have been widely used in modeling the peripheral auditory system [14]. Figure 1 shows joint histograms of the instantaneous responses of a particular pair of linear filters to five different types of natural sound, and white noise. First note that the responses are approximately decorrelated: the expected value of the y-axis value is roughly zero for all values of the x-axis variable. The responses are not, however, statistically independent: the width of the distribution of responses of one filter increases with the response amplitude of the other filter. If the two responses were statistically independent, then the response of the first filter should not provide any information about the distribution of responses of the other filter. We have found that this type of variance dependency (sometimes accompanied by linear correlation) occurs in a wide range of natural sounds, ranging from animal sounds to music. We emphasize that this dependency is a property of natural sounds, and is not due purely to our choice of linear filters. For example, no such dependency is observed when the input consists of white noise (see Fig. 1). The strength of this dependency varies for different pairs of linear filters . In addition, we see this type of dependency between instantaneous responses of a single filter at two Speech o -1 Drums • Monkey Cat White noise Nocturnal nature I~ ~; ~ • Figure 1: Joint conditional histogram of instantaneous linear responses of two bandpass filters with center frequencies 2000 and 2840 Hz. Pixel intensity corresponds to frequency of occurrence of a given pair of values, except that each column has been independently rescaled to fill the full intensity range. For the natural sounds, responses are not independent: the standard deviation of the ordinate is roughly proportional to the magnitude of the abscissa. Natural sounds were recorded from CDs and converted to sampling frequency of 22050 Hz. nearby time instants. Since the dependency involves the variance of the responses, we can substantially reduce it by dividing. In particular, the response of each filter is divided by a weighted sum of responses of other rectified filters and an additive constant. Specifically: L2 Ri = 2: (1) 12 j WjiLj + 0'2 where Li is the instantaneous linear response of filter i, strength of suppression of filter i by filter j. 0' is a constant and Wji controls the We would like to choose the parameters of the model (the weights Wji, and the constant 0') to optimize the independence of the normalized response to an ensemble of natural sounds. Such an optimization is quite computationally expensive. We instead assume a Gaussian form for the underlying conditional distribution, as described in [15]: P (LiILj,j E Ni ) '</p><p>6 0.39031684 <a title="42-lda-6" href="./nips-2000-A_Productive%2C_Systematic_Framework_for_the_Representation_of_Visual_Structure.html">10 nips-2000-A Productive, Systematic Framework for the Representation of Visual Structure</a></p>
<p>7 0.38831288 <a title="42-lda-7" href="./nips-2000-Stability_and_Noise_in_Biochemical_Switches.html">125 nips-2000-Stability and Noise in Biochemical Switches</a></p>
<p>8 0.3856132 <a title="42-lda-8" href="./nips-2000-Finding_the_Key_to_a_Synapse.html">55 nips-2000-Finding the Key to a Synapse</a></p>
<p>9 0.37450191 <a title="42-lda-9" href="./nips-2000-What_Can_a_Single_Neuron_Compute%3F.html">146 nips-2000-What Can a Single Neuron Compute?</a></p>
<p>10 0.37262809 <a title="42-lda-10" href="./nips-2000-Spike-Timing-Dependent_Learning_for_Oscillatory_Networks.html">124 nips-2000-Spike-Timing-Dependent Learning for Oscillatory Networks</a></p>
<p>11 0.37089729 <a title="42-lda-11" href="./nips-2000-Dopamine_Bonuses.html">43 nips-2000-Dopamine Bonuses</a></p>
<p>12 0.35057536 <a title="42-lda-12" href="./nips-2000-Position_Variance%2C_Recurrence_and_Perceptual_Learning.html">102 nips-2000-Position Variance, Recurrence and Perceptual Learning</a></p>
<p>13 0.34123975 <a title="42-lda-13" href="./nips-2000-Processing_of_Time_Series_by_Neural_Circuits_with_Biologically_Realistic_Synaptic_Dynamics.html">104 nips-2000-Processing of Time Series by Neural Circuits with Biologically Realistic Synaptic Dynamics</a></p>
<p>14 0.33183926 <a title="42-lda-14" href="./nips-2000-Universality_and_Individuality_in_a_Neural_Code.html">141 nips-2000-Universality and Individuality in a Neural Code</a></p>
<p>15 0.32482234 <a title="42-lda-15" href="./nips-2000-Explaining_Away_in_Weight_Space.html">49 nips-2000-Explaining Away in Weight Space</a></p>
<p>16 0.32430398 <a title="42-lda-16" href="./nips-2000-The_Early_Word_Catches_the_Weights.html">131 nips-2000-The Early Word Catches the Weights</a></p>
<p>17 0.32187086 <a title="42-lda-17" href="./nips-2000-Place_Cells_and_Spatial_Navigation_Based_on_2D_Visual_Feature_Extraction%2C_Path_Integration%2C_and_Reinforcement_Learning.html">101 nips-2000-Place Cells and Spatial Navigation Based on 2D Visual Feature Extraction, Path Integration, and Reinforcement Learning</a></p>
<p>18 0.31482887 <a title="42-lda-18" href="./nips-2000-Noise_Suppression_Based_on_Neurophysiologically-motivated_SNR_Estimation_for_Robust_Speech_Recognition.html">91 nips-2000-Noise Suppression Based on Neurophysiologically-motivated SNR Estimation for Robust Speech Recognition</a></p>
<p>19 0.30765054 <a title="42-lda-19" href="./nips-2000-Modelling_Spatial_Recall%2C_Mental_Imagery_and_Neglect.html">87 nips-2000-Modelling Spatial Recall, Mental Imagery and Neglect</a></p>
<p>20 0.30286109 <a title="42-lda-20" href="./nips-2000-Learning_Switching_Linear_Models_of_Human_Motion.html">80 nips-2000-Learning Switching Linear Models of Human Motion</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
