<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>135 nips-2000-The Manhattan World Assumption: Regularities in Scene Statistics which Enable Bayesian Inference</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2000" href="../home/nips2000_home.html">nips2000</a> <a title="nips-2000-135" href="#">nips2000-135</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>135 nips-2000-The Manhattan World Assumption: Regularities in Scene Statistics which Enable Bayesian Inference</h1>
<br/><p>Source: <a title="nips-2000-135-pdf" href="http://papers.nips.cc/paper/1804-the-manhattan-world-assumption-regularities-in-scene-statistics-which-enable-bayesian-inference.pdf">pdf</a></p><p>Author: James M. Coughlan, Alan L. Yuille</p><p>Abstract: Preliminary work by the authors made use of the so-called</p><p>Reference: <a title="nips-2000-135-reference" href="../nips2000_reference/nips-2000-The_Manhattan_World_Assumption%3A_Regularities_in_Scene_Statistics_which_Enable_Bayesian_Inference_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('manhat', 0.426), ('edg', 0.306), ('ory', 0.268), ('scen', 0.221), ('im', 0.203), ('pon', 0.202), ('camer', 0.175), ('ea', 0.167), ('rur', 0.157), ('eil', 0.155), ('room', 0.144), ('mil', 0.138), ('cartes', 0.135), ('indo', 0.135), ('pof', 0.135), ('world', 0.12), ('coughl', 0.112), ('eillmil', 0.112), ('unalign', 0.112), ('pixel', 0.106)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="135-tfidf-1" href="./nips-2000-The_Manhattan_World_Assumption%3A_Regularities_in_Scene_Statistics_which_Enable_Bayesian_Inference.html">135 nips-2000-The Manhattan World Assumption: Regularities in Scene Statistics which Enable Bayesian Inference</a></p>
<p>Author: James M. Coughlan, Alan L. Yuille</p><p>Abstract: Preliminary work by the authors made use of the so-called</p><p>2 0.15319583 <a title="135-tfidf-2" href="./nips-2000-Emergence_of_Movement_Sensitive_Neurons%27_Properties_by_Learning_a_Sparse_Code_for_Natural_Moving_Images.html">45 nips-2000-Emergence of Movement Sensitive Neurons' Properties by Learning a Sparse Code for Natural Moving Images</a></p>
<p>Author: Rafal Bogacz, Malcolm W. Brown, Christophe G. Giraud-Carrier</p><p>Abstract: Olshausen & Field demonstrated that a learning algorithm that attempts to generate a sparse code for natural scenes develops a complete family of localised, oriented, bandpass receptive fields, similar to those of 'simple cells' in VI. This paper describes an algorithm which finds a sparse code for sequences of images that preserves information about the input. This algorithm when trained on natural video sequences develops bases representing the movement in particular directions with particular speeds, similar to the receptive fields of the movement-sensitive cells observed in cortical visual areas. Furthermore, in contrast to previous approaches to learning direction selectivity, the timing of neuronal activity encodes the phase of the movement, so the precise timing of spikes is crucially important to the information encoding.</p><p>3 0.13736546 <a title="135-tfidf-3" href="./nips-2000-Discovering_Hidden_Variables%3A_A_Structure-Based_Approach.html">41 nips-2000-Discovering Hidden Variables: A Structure-Based Approach</a></p>
<p>Author: Gal Elidan, Noam Lotner, Nir Friedman, Daphne Koller</p><p>Abstract: A serious problem in learning probabilistic models is the presence of hidden variables. These variables are not observed, yet interact with several of the observed variables. As such, they induce seemingly complex dependencies among the latter. In recent years, much attention has been devoted to the development of algorithms for learning parameters, and in some cases structure, in the presence of hidden variables. In this paper, we address the related problem of detecting hidden variables that interact with the observed variables. This problem is of interest both for improving our understanding of the domain and as a preliminary step that guides the learning procedure towards promising models. A very natural approach is to search for</p><p>4 0.11847497 <a title="135-tfidf-4" href="./nips-2000-Rate-coded_Restricted_Boltzmann_Machines_for_Face_Recognition.html">107 nips-2000-Rate-coded Restricted Boltzmann Machines for Face Recognition</a></p>
<p>Author: Yee Whye Teh, Geoffrey E. Hinton</p><p>Abstract: We describe a neurally-inspired, unsupervised learning algorithm that builds a non-linear generative model for pairs of face images from the same individual. Individuals are then recognized by finding the highest relative probability pair among all pairs that consist of a test image and an image whose identity is known. Our method compares favorably with other methods in the literature. The generative model consists of a single layer of rate-coded, non-linear feature detectors and it has the property that, given a data vector, the true posterior probability distribution over the feature detector activities can be inferred rapidly without iteration or approximation. The weights of the feature detectors are learned by comparing the correlations of pixel intensities and feature activations in two phases: When the network is observing real data and when it is observing reconstructions of real data generated from the feature activations.</p><p>5 0.11815113 <a title="135-tfidf-5" href="./nips-2000-A_Comparison_of_Image_Processing_Techniques_for_Visual_Speech_Recognition_Applications.html">2 nips-2000-A Comparison of Image Processing Techniques for Visual Speech Recognition Applications</a></p>
<p>Author: Michael S. Gray, Terrence J. Sejnowski, Javier R. Movellan</p><p>Abstract: We examine eight different techniques for developing visual representations in machine vision tasks. In particular we compare different versions of principal component and independent component analysis in combination with stepwise regression methods for variable selection. We found that local methods, based on the statistics of image patches, consistently outperformed global methods based on the statistics of entire images. This result is consistent with previous work on emotion and facial expression recognition. In addition, the use of a stepwise regression technique for selecting variables and regions of interest substantially boosted performance. 1</p><p>6 0.099034488 <a title="135-tfidf-6" href="./nips-2000-Feature_Correspondence%3A_A_Markov_Chain_Monte_Carlo_Approach.html">53 nips-2000-Feature Correspondence: A Markov Chain Monte Carlo Approach</a></p>
<p>7 0.097593121 <a title="135-tfidf-7" href="./nips-2000-Accumulator_Networks%3A_Suitors_of_Local_Probability_Propagation.html">15 nips-2000-Accumulator Networks: Suitors of Local Probability Propagation</a></p>
<p>8 0.094572932 <a title="135-tfidf-8" href="./nips-2000-Color_Opponency_Constitutes_a_Sparse_Representation_for_the_Chromatic_Structure_of_Natural_Scenes.html">32 nips-2000-Color Opponency Constitutes a Sparse Representation for the Chromatic Structure of Natural Scenes</a></p>
<p>9 0.09284696 <a title="135-tfidf-9" href="./nips-2000-Learning_and_Tracking_Cyclic_Human_Motion.html">82 nips-2000-Learning and Tracking Cyclic Human Motion</a></p>
<p>10 0.082097314 <a title="135-tfidf-10" href="./nips-2000-Learning_Segmentation_by_Random_Walks.html">79 nips-2000-Learning Segmentation by Random Walks</a></p>
<p>11 0.080901653 <a title="135-tfidf-11" href="./nips-2000-Tree-Based_Modeling_and_Estimation_of_Gaussian_Processes_on_Graphs_with_Cycles.html">140 nips-2000-Tree-Based Modeling and Estimation of Gaussian Processes on Graphs with Cycles</a></p>
<p>12 0.074028775 <a title="135-tfidf-12" href="./nips-2000-Adaptive_Object_Representation_with_Hierarchically-Distributed_Memory_Sites.html">19 nips-2000-Adaptive Object Representation with Hierarchically-Distributed Memory Sites</a></p>
<p>13 0.07214193 <a title="135-tfidf-13" href="./nips-2000-FaceSync%3A_A_Linear_Operator_for_Measuring_Synchronization_of_Video_Facial_Images_and_Audio_Tracks.html">50 nips-2000-FaceSync: A Linear Operator for Measuring Synchronization of Video Facial Images and Audio Tracks</a></p>
<p>14 0.071052745 <a title="135-tfidf-14" href="./nips-2000-Shape_Context%3A_A_New_Descriptor_for_Shape_Matching_and_Object_Recognition.html">117 nips-2000-Shape Context: A New Descriptor for Shape Matching and Object Recognition</a></p>
<p>15 0.062297825 <a title="135-tfidf-15" href="./nips-2000-Natural_Sound_Statistics_and_Divisive_Normalization_in_the_Auditory_System.html">89 nips-2000-Natural Sound Statistics and Divisive Normalization in the Auditory System</a></p>
<p>16 0.060458038 <a title="135-tfidf-16" href="./nips-2000-From_Mixtures_of_Mixtures_to_Adaptive_Transform_Coding.html">59 nips-2000-From Mixtures of Mixtures to Adaptive Transform Coding</a></p>
<p>17 0.059964556 <a title="135-tfidf-17" href="./nips-2000-Place_Cells_and_Spatial_Navigation_Based_on_2D_Visual_Feature_Extraction%2C_Path_Integration%2C_and_Reinforcement_Learning.html">101 nips-2000-Place Cells and Spatial Navigation Based on 2D Visual Feature Extraction, Path Integration, and Reinforcement Learning</a></p>
<p>18 0.059180833 <a title="135-tfidf-18" href="./nips-2000-Active_Support_Vector_Machine_Classification.html">18 nips-2000-Active Support Vector Machine Classification</a></p>
<p>19 0.055790439 <a title="135-tfidf-19" href="./nips-2000-Probabilistic_Semantic_Video_Indexing.html">103 nips-2000-Probabilistic Semantic Video Indexing</a></p>
<p>20 0.054943293 <a title="135-tfidf-20" href="./nips-2000-A_Productive%2C_Systematic_Framework_for_the_Representation_of_Visual_Structure.html">10 nips-2000-A Productive, Systematic Framework for the Representation of Visual Structure</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2000_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.184), (1, -0.039), (2, -0.139), (3, -0.095), (4, 0.024), (5, -0.17), (6, 0.08), (7, -0.027), (8, -0.03), (9, 0.013), (10, -0.002), (11, -0.04), (12, 0.018), (13, 0.043), (14, -0.137), (15, -0.01), (16, 0.176), (17, -0.012), (18, 0.006), (19, -0.065), (20, 0.146), (21, -0.051), (22, -0.0), (23, 0.011), (24, 0.054), (25, 0.097), (26, -0.093), (27, -0.008), (28, 0.082), (29, 0.01), (30, 0.072), (31, 0.067), (32, -0.316), (33, -0.011), (34, -0.12), (35, 0.072), (36, -0.031), (37, -0.177), (38, 0.027), (39, 0.15), (40, 0.079), (41, -0.008), (42, -0.091), (43, -0.122), (44, -0.037), (45, 0.077), (46, -0.04), (47, 0.054), (48, -0.04), (49, -0.037)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94888526 <a title="135-lsi-1" href="./nips-2000-The_Manhattan_World_Assumption%3A_Regularities_in_Scene_Statistics_which_Enable_Bayesian_Inference.html">135 nips-2000-The Manhattan World Assumption: Regularities in Scene Statistics which Enable Bayesian Inference</a></p>
<p>Author: James M. Coughlan, Alan L. Yuille</p><p>Abstract: Preliminary work by the authors made use of the so-called</p><p>2 0.54597884 <a title="135-lsi-2" href="./nips-2000-Color_Opponency_Constitutes_a_Sparse_Representation_for_the_Chromatic_Structure_of_Natural_Scenes.html">32 nips-2000-Color Opponency Constitutes a Sparse Representation for the Chromatic Structure of Natural Scenes</a></p>
<p>Author: Te-Won Lee, Thomas Wachtler, Terrence J. Sejnowski</p><p>Abstract: The human visual system encodes the chromatic signals conveyed by the three types of retinal cone photoreceptors in an opponent fashion. This color opponency has been shown to constitute an efficient encoding by spectral decorrelation of the receptor signals. We analyze the spatial and chromatic structure of natural scenes by decomposing the spectral images into a set of linear basis functions such that they constitute a representation with minimal redundancy. Independent component analysis finds the basis functions that transforms the spatiochromatic data such that the outputs (activations) are statistically as independent as possible, i.e. least redundant. The resulting basis functions show strong opponency along an achromatic direction (luminance edges), along a blueyellow direction, and along a red-blue direction. Furthermore, the resulting activations have very sparse distributions, suggesting that the use of color opponency in the human visual system achieves a highly efficient representation of colors. Our findings suggest that color opponency is a result of the properties of natural spectra and not solely a consequence of the overlapping cone spectral sensitivities. 1 Statistical structure of natural scenes Efficient encoding of visual sensory information is an important task for information processing systems and its study may provide insights into coding principles of biological visual systems. An important goal of sensory information processing Electronic version available at www. cnl. salk . edu/</p><p>3 0.53913504 <a title="135-lsi-3" href="./nips-2000-Learning_Segmentation_by_Random_Walks.html">79 nips-2000-Learning Segmentation by Random Walks</a></p>
<p>Author: Marina Meila, Jianbo Shi</p><p>Abstract: We present a new view of image segmentation by pairwise similarities. We interpret the similarities as edge flows in a Markov random walk and study the eigenvalues and eigenvectors of the walk's transition matrix. This interpretation shows that spectral methods for clustering and segmentation have a probabilistic foundation. In particular, we prove that the Normalized Cut method arises naturally from our framework. Finally, the framework provides a principled method for learning the similarity function as a combination of features. 1</p><p>4 0.5279395 <a title="135-lsi-4" href="./nips-2000-Emergence_of_Movement_Sensitive_Neurons%27_Properties_by_Learning_a_Sparse_Code_for_Natural_Moving_Images.html">45 nips-2000-Emergence of Movement Sensitive Neurons' Properties by Learning a Sparse Code for Natural Moving Images</a></p>
<p>Author: Rafal Bogacz, Malcolm W. Brown, Christophe G. Giraud-Carrier</p><p>Abstract: Olshausen & Field demonstrated that a learning algorithm that attempts to generate a sparse code for natural scenes develops a complete family of localised, oriented, bandpass receptive fields, similar to those of 'simple cells' in VI. This paper describes an algorithm which finds a sparse code for sequences of images that preserves information about the input. This algorithm when trained on natural video sequences develops bases representing the movement in particular directions with particular speeds, similar to the receptive fields of the movement-sensitive cells observed in cortical visual areas. Furthermore, in contrast to previous approaches to learning direction selectivity, the timing of neuronal activity encodes the phase of the movement, so the precise timing of spikes is crucially important to the information encoding.</p><p>5 0.44704843 <a title="135-lsi-5" href="./nips-2000-Rate-coded_Restricted_Boltzmann_Machines_for_Face_Recognition.html">107 nips-2000-Rate-coded Restricted Boltzmann Machines for Face Recognition</a></p>
<p>Author: Yee Whye Teh, Geoffrey E. Hinton</p><p>Abstract: We describe a neurally-inspired, unsupervised learning algorithm that builds a non-linear generative model for pairs of face images from the same individual. Individuals are then recognized by finding the highest relative probability pair among all pairs that consist of a test image and an image whose identity is known. Our method compares favorably with other methods in the literature. The generative model consists of a single layer of rate-coded, non-linear feature detectors and it has the property that, given a data vector, the true posterior probability distribution over the feature detector activities can be inferred rapidly without iteration or approximation. The weights of the feature detectors are learned by comparing the correlations of pixel intensities and feature activations in two phases: When the network is observing real data and when it is observing reconstructions of real data generated from the feature activations.</p><p>6 0.44417366 <a title="135-lsi-6" href="./nips-2000-Accumulator_Networks%3A_Suitors_of_Local_Probability_Propagation.html">15 nips-2000-Accumulator Networks: Suitors of Local Probability Propagation</a></p>
<p>7 0.43648937 <a title="135-lsi-7" href="./nips-2000-Feature_Correspondence%3A_A_Markov_Chain_Monte_Carlo_Approach.html">53 nips-2000-Feature Correspondence: A Markov Chain Monte Carlo Approach</a></p>
<p>8 0.41922981 <a title="135-lsi-8" href="./nips-2000-A_Comparison_of_Image_Processing_Techniques_for_Visual_Speech_Recognition_Applications.html">2 nips-2000-A Comparison of Image Processing Techniques for Visual Speech Recognition Applications</a></p>
<p>9 0.40153548 <a title="135-lsi-9" href="./nips-2000-Learning_and_Tracking_Cyclic_Human_Motion.html">82 nips-2000-Learning and Tracking Cyclic Human Motion</a></p>
<p>10 0.36684993 <a title="135-lsi-10" href="./nips-2000-Competition_and_Arbors_in_Ocular_Dominance.html">34 nips-2000-Competition and Arbors in Ocular Dominance</a></p>
<p>11 0.3343721 <a title="135-lsi-11" href="./nips-2000-Discovering_Hidden_Variables%3A_A_Structure-Based_Approach.html">41 nips-2000-Discovering Hidden Variables: A Structure-Based Approach</a></p>
<p>12 0.32729301 <a title="135-lsi-12" href="./nips-2000-Higher-Order_Statistical_Properties_Arising_from_the_Non-Stationarity_of_Natural_Signals.html">65 nips-2000-Higher-Order Statistical Properties Arising from the Non-Stationarity of Natural Signals</a></p>
<p>13 0.32504764 <a title="135-lsi-13" href="./nips-2000-Adaptive_Object_Representation_with_Hierarchically-Distributed_Memory_Sites.html">19 nips-2000-Adaptive Object Representation with Hierarchically-Distributed Memory Sites</a></p>
<p>14 0.31794196 <a title="135-lsi-14" href="./nips-2000-Redundancy_and_Dimensionality_Reduction_in_Sparse-Distributed_Representations_of_Natural_Objects_in_Terms_of_Their_Local_Features.html">109 nips-2000-Redundancy and Dimensionality Reduction in Sparse-Distributed Representations of Natural Objects in Terms of Their Local Features</a></p>
<p>15 0.27260244 <a title="135-lsi-15" href="./nips-2000-Bayesian_Video_Shot_Segmentation.html">30 nips-2000-Bayesian Video Shot Segmentation</a></p>
<p>16 0.26033297 <a title="135-lsi-16" href="./nips-2000-Sequentially_Fitting_%60%60Inclusive%27%27_Trees_for_Inference_in_Noisy-OR_Networks.html">115 nips-2000-Sequentially Fitting ``Inclusive'' Trees for Inference in Noisy-OR Networks</a></p>
<p>17 0.2586841 <a title="135-lsi-17" href="./nips-2000-Smart_Vision_Chip_Fabricated_Using_Three_Dimensional_Integration_Technology.html">118 nips-2000-Smart Vision Chip Fabricated Using Three Dimensional Integration Technology</a></p>
<p>18 0.25259176 <a title="135-lsi-18" href="./nips-2000-Active_Support_Vector_Machine_Classification.html">18 nips-2000-Active Support Vector Machine Classification</a></p>
<p>19 0.25040725 <a title="135-lsi-19" href="./nips-2000-Tree-Based_Modeling_and_Estimation_of_Gaussian_Processes_on_Graphs_with_Cycles.html">140 nips-2000-Tree-Based Modeling and Estimation of Gaussian Processes on Graphs with Cycles</a></p>
<p>20 0.24726689 <a title="135-lsi-20" href="./nips-2000-Structure_Learning_in_Human_Causal_Induction.html">127 nips-2000-Structure Learning in Human Causal Induction</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2000_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.015), (9, 0.064), (11, 0.028), (16, 0.033), (21, 0.022), (38, 0.046), (55, 0.457), (61, 0.01), (67, 0.01), (74, 0.051), (76, 0.023), (80, 0.012), (84, 0.14)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.78106403 <a title="135-lda-1" href="./nips-2000-The_Manhattan_World_Assumption%3A_Regularities_in_Scene_Statistics_which_Enable_Bayesian_Inference.html">135 nips-2000-The Manhattan World Assumption: Regularities in Scene Statistics which Enable Bayesian Inference</a></p>
<p>Author: James M. Coughlan, Alan L. Yuille</p><p>Abstract: Preliminary work by the authors made use of the so-called</p><p>2 0.57581168 <a title="135-lda-2" href="./nips-2000-Noise_Suppression_Based_on_Neurophysiologically-motivated_SNR_Estimation_for_Robust_Speech_Recognition.html">91 nips-2000-Noise Suppression Based on Neurophysiologically-motivated SNR Estimation for Robust Speech Recognition</a></p>
<p>Author: Jürgen Tchorz, Michael Kleinschmidt, Birger Kollmeier</p><p>Abstract: A novel noise suppression scheme for speech signals is proposed which is based on a neurophysiologically-motivated estimation of the local signal-to-noise ratio (SNR) in different frequency channels. For SNR-estimation, the input signal is transformed into so-called Amplitude Modulation Spectrograms (AMS), which represent both spectral and temporal characteristics of the respective analysis frame, and which imitate the representation of modulation frequencies in higher stages of the mammalian auditory system. A neural network is used to analyse AMS patterns generated from noisy speech and estimates the local SNR. Noise suppression is achieved by attenuating frequency channels according to their SNR. The noise suppression algorithm is evaluated in speakerindependent digit recognition experiments and compared to noise suppression by Spectral Subtraction. 1</p><p>3 0.53894281 <a title="135-lda-3" href="./nips-2000-Beyond_Maximum_Likelihood_and_Density_Estimation%3A_A_Sample-Based_Criterion_for_Unsupervised_Learning_of_Complex_Models.html">31 nips-2000-Beyond Maximum Likelihood and Density Estimation: A Sample-Based Criterion for Unsupervised Learning of Complex Models</a></p>
<p>Author: Sepp Hochreiter, Michael Mozer</p><p>Abstract: The goal of many unsupervised learning procedures is to bring two probability distributions into alignment. Generative models such as Gaussian mixtures and Boltzmann machines can be cast in this light, as can recoding models such as ICA and projection pursuit. We propose a novel sample-based error measure for these classes of models, which applies even in situations where maximum likelihood (ML) and probability density estimation-based formulations cannot be applied, e.g., models that are nonlinear or have intractable posteriors. Furthermore, our sample-based error measure avoids the difficulties of approximating a density function. We prove that with an unconstrained model, (1) our approach converges on the correct solution as the number of samples goes to infinity, and (2) the expected solution of our approach in the generative framework is the ML solution. Finally, we evaluate our approach via simulations of linear and nonlinear models on mixture of Gaussians and ICA problems. The experiments show the broad applicability and generality of our approach. 1</p><p>4 0.3324782 <a title="135-lda-4" href="./nips-2000-Rate-coded_Restricted_Boltzmann_Machines_for_Face_Recognition.html">107 nips-2000-Rate-coded Restricted Boltzmann Machines for Face Recognition</a></p>
<p>Author: Yee Whye Teh, Geoffrey E. Hinton</p><p>Abstract: We describe a neurally-inspired, unsupervised learning algorithm that builds a non-linear generative model for pairs of face images from the same individual. Individuals are then recognized by finding the highest relative probability pair among all pairs that consist of a test image and an image whose identity is known. Our method compares favorably with other methods in the literature. The generative model consists of a single layer of rate-coded, non-linear feature detectors and it has the property that, given a data vector, the true posterior probability distribution over the feature detector activities can be inferred rapidly without iteration or approximation. The weights of the feature detectors are learned by comparing the correlations of pixel intensities and feature activations in two phases: When the network is observing real data and when it is observing reconstructions of real data generated from the feature activations.</p><p>5 0.33128718 <a title="135-lda-5" href="./nips-2000-A_Gradient-Based_Boosting_Algorithm_for_Regression_Problems.html">3 nips-2000-A Gradient-Based Boosting Algorithm for Regression Problems</a></p>
<p>Author: Richard S. Zemel, Toniann Pitassi</p><p>Abstract: In adaptive boosting, several weak learners trained sequentially are combined to boost the overall algorithm performance. Recently adaptive boosting methods for classification problems have been derived as gradient descent algorithms. This formulation justifies key elements and parameters in the methods, all chosen to optimize a single common objective function. We propose an analogous formulation for adaptive boosting of regression problems, utilizing a novel objective function that leads to a simple boosting algorithm. We prove that this method reduces training error, and compare its performance to other regression methods. The aim of boosting algorithms is to</p><p>6 0.3300395 <a title="135-lda-6" href="./nips-2000-Probabilistic_Semantic_Video_Indexing.html">103 nips-2000-Probabilistic Semantic Video Indexing</a></p>
<p>7 0.32791901 <a title="135-lda-7" href="./nips-2000-Sequentially_Fitting_%60%60Inclusive%27%27_Trees_for_Inference_in_Noisy-OR_Networks.html">115 nips-2000-Sequentially Fitting ``Inclusive'' Trees for Inference in Noisy-OR Networks</a></p>
<p>8 0.32722312 <a title="135-lda-8" href="./nips-2000-Discovering_Hidden_Variables%3A_A_Structure-Based_Approach.html">41 nips-2000-Discovering Hidden Variables: A Structure-Based Approach</a></p>
<p>9 0.32585657 <a title="135-lda-9" href="./nips-2000-Improved_Output_Coding_for_Classification_Using_Continuous_Relaxation.html">68 nips-2000-Improved Output Coding for Classification Using Continuous Relaxation</a></p>
<p>10 0.32578391 <a title="135-lda-10" href="./nips-2000-Learning_Segmentation_by_Random_Walks.html">79 nips-2000-Learning Segmentation by Random Walks</a></p>
<p>11 0.32391995 <a title="135-lda-11" href="./nips-2000-Emergence_of_Movement_Sensitive_Neurons%27_Properties_by_Learning_a_Sparse_Code_for_Natural_Moving_Images.html">45 nips-2000-Emergence of Movement Sensitive Neurons' Properties by Learning a Sparse Code for Natural Moving Images</a></p>
<p>12 0.32244837 <a title="135-lda-12" href="./nips-2000-Propagation_Algorithms_for_Variational_Bayesian_Learning.html">106 nips-2000-Propagation Algorithms for Variational Bayesian Learning</a></p>
<p>13 0.32192934 <a title="135-lda-13" href="./nips-2000-Tree-Based_Modeling_and_Estimation_of_Gaussian_Processes_on_Graphs_with_Cycles.html">140 nips-2000-Tree-Based Modeling and Estimation of Gaussian Processes on Graphs with Cycles</a></p>
<p>14 0.32179019 <a title="135-lda-14" href="./nips-2000-Accumulator_Networks%3A_Suitors_of_Local_Probability_Propagation.html">15 nips-2000-Accumulator Networks: Suitors of Local Probability Propagation</a></p>
<p>15 0.32050645 <a title="135-lda-15" href="./nips-2000-Algorithmic_Stability_and_Generalization_Performance.html">21 nips-2000-Algorithmic Stability and Generalization Performance</a></p>
<p>16 0.31935707 <a title="135-lda-16" href="./nips-2000-A_Productive%2C_Systematic_Framework_for_the_Representation_of_Visual_Structure.html">10 nips-2000-A Productive, Systematic Framework for the Representation of Visual Structure</a></p>
<p>17 0.31871399 <a title="135-lda-17" href="./nips-2000-Bayesian_Video_Shot_Segmentation.html">30 nips-2000-Bayesian Video Shot Segmentation</a></p>
<p>18 0.3185893 <a title="135-lda-18" href="./nips-2000-Generalized_Belief_Propagation.html">62 nips-2000-Generalized Belief Propagation</a></p>
<p>19 0.3182784 <a title="135-lda-19" href="./nips-2000-Keeping_Flexible_Active_Contours_on_Track_using_Metropolis_Updates.html">72 nips-2000-Keeping Flexible Active Contours on Track using Metropolis Updates</a></p>
<p>20 0.31740028 <a title="135-lda-20" href="./nips-2000-Incorporating_Second-Order_Functional_Knowledge_for_Better_Option_Pricing.html">69 nips-2000-Incorporating Second-Order Functional Knowledge for Better Option Pricing</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
