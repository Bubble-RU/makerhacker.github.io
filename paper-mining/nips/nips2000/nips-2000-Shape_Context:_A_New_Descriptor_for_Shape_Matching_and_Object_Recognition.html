<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>117 nips-2000-Shape Context: A New Descriptor for Shape Matching and Object Recognition</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2000" href="../home/nips2000_home.html">nips2000</a> <a title="nips-2000-117" href="#">nips2000-117</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>117 nips-2000-Shape Context: A New Descriptor for Shape Matching and Object Recognition</h1>
<br/><p>Source: <a title="nips-2000-117-pdf" href="http://papers.nips.cc/paper/1913-shape-context-a-new-descriptor-for-shape-matching-and-object-recognition.pdf">pdf</a></p><p>Author: Serge Belongie, Jitendra Malik, Jan Puzicha</p><p>Abstract: We develop an approach to object recognition based on matching shapes and using a resulting measure of similarity in a nearest neighbor classifier. The key algorithmic problem here is that of finding pointwise correspondences between an image shape and a stored prototype shape. We introduce a new shape descriptor, the shape context, which makes this possible, using a simple and robust algorithm. The shape context at a point captures the distribution over relative positions of other shape points and thus summarizes global shape in a rich, local descriptor. We demonstrate that shape contexts greatly simplify recovery of correspondences between points of two given shapes. Once shapes are aligned, shape contexts are used to define a robust score for measuring shape similarity. We have used this score in a nearest-neighbor classifier for recognition of hand written digits as well as 3D objects, using exactly the same distance function. On the benchmark MNIST dataset of handwritten digits, this yields an error rate of 0.63%, outperforming other published techniques. 1</p><p>Reference: <a title="nips-2000-117-reference" href="../nips2000_reference/nips-2000-Shape_Context%3A_A_New_Descriptor_for_Shape_Matching_and_Object_Recognition_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Shape Context: A new descriptor for shape matching and object recognition  Serge Belongie, Jitendra Malik and Jan Puzicha Department of Electrical Engineering and Computer Sciences University of California at Berkeley Berkeley, CA 94720, USA {sjb, malik,puzicha} @cs. [sent-1, score-1.271]
</p><p>2 edu  Abstract We develop an approach to object recognition based on matching shapes and using a resulting measure of similarity in a nearest neighbor classifier. [sent-3, score-0.857]
</p><p>3 The key algorithmic problem here is that of finding pointwise correspondences between an image shape and a stored prototype shape. [sent-4, score-1.015]
</p><p>4 We introduce a new shape descriptor, the shape context, which makes this possible, using a simple and robust algorithm. [sent-5, score-1.148]
</p><p>5 The shape context at a point captures the distribution over relative positions of other shape points and thus summarizes global shape in a rich, local descriptor. [sent-6, score-1.972]
</p><p>6 We demonstrate that shape contexts greatly simplify recovery of correspondences between points of two given shapes. [sent-7, score-0.923]
</p><p>7 Once shapes are aligned, shape contexts are used to define a robust score for measuring shape similarity. [sent-8, score-1.454]
</p><p>8 We have used this score in a nearest-neighbor classifier for recognition of hand written digits as well as 3D objects, using exactly the same distance function. [sent-9, score-0.411]
</p><p>9 On the benchmark MNIST dataset of handwritten digits, this yields an error rate of 0. [sent-10, score-0.111]
</p><p>10 1  Introduction  The last decade has seen increased application of statistical pattern recognition techniques to the problem of object recognition from images. [sent-12, score-0.342]
</p><p>11 Typically, an image block with n pixels is regarded as an n dimensional feature vector formed by concatenating the brightness values of the pixels. [sent-13, score-0.169]
</p><p>12 Impressive performance has been demonstrated on datasets such as digits and faces. [sent-17, score-0.078]
</p><p>13 A vector of pixel brightness values is a somewhat unsatisfactory representation of an object. [sent-18, score-0.146]
</p><p>14 to translation, scale and small amount of rotation must be obtained by suitable pre-processing or by the use of enormous amounts of training data [12]. [sent-21, score-0.038]
</p><p>15 The literature in computer vision and pattern recognition is full of definitions of shape descriptors and distance measures, ranging from moments and Fourier descriptors to the Hausdorff distance and the medial axis transform. [sent-24, score-1.18]
</p><p>16 ) Most of these approaches suffer from one of two difficulties: (1) Mapping the shape to a small number of numbers, e. [sent-26, score-0.574]
</p><p>17 This has motivated approaches such as [1] who find key points or landmarks, and recognize objects using the spatial arrangements of point sets. [sent-33, score-0.274]
</p><p>18 However not all objects have distinguished key points (think of a circle for instance), and using key points alone sacrifices the shape information available in smooth portions of object contours. [sent-34, score-1.04]
</p><p>19 Our approach therefore uses a general representation of shape - a set of points sampled from the contours on the object. [sent-35, score-0.731]
</p><p>20 Each point is associated with a novel descriptor, the shape context, which describes the coarse arrangement of the rest of the shape with respect to the point. [sent-36, score-1.189]
</p><p>21 This descriptor will be different for different points on a single shape S; however corresponding (homologous) points on similar shapes Sand S' will tend to have similar shape contexts. [sent-37, score-1.616]
</p><p>22 Correspondences between the point sets of S and S' can be found by solving a bipartite weighted graph matching problem with edge weights Cij defined by the similarity of the shape contexts of points i and j. [sent-38, score-1.269]
</p><p>23 Given correspondences, we can effectively calculate the similarity between the shapes S and S'. [sent-39, score-0.198]
</p><p>24 This similarity measure is then employed in a nearest-neighbor classifier for object recognition. [sent-40, score-0.26]
</p><p>25 The core of our work is the concept of shape contexts and its use for solving the correspondence problem between two shapes. [sent-41, score-0.714]
</p><p>26 It can be compared to an alternative framework for matching point sets due to Gold, Rangarajan and collaborators (e. [sent-42, score-0.347]
</p><p>27 They propose an iterative optimization algorithm to jointly determine point correspondences and underlying image transformations. [sent-45, score-0.229]
</p><p>28 The cost measure is Euclidean distance between the first point set and a transformed version of the second point set. [sent-46, score-0.241]
</p><p>29 Another related approach is elastic graph matching [11] which also leads to a difficult stochastic optimization problem. [sent-48, score-0.306]
</p><p>30 2  Matching with Shape Contexts  In our approach, a shape is represented by a discrete set of points sampled from the internal or external contours on the shape. [sent-49, score-0.731]
</p><p>31 These can be obtained as locations of edge pixels as found by an edge detector, giving us a set P = {PI, . [sent-50, score-0.163]
</p><p>32 We prefer to sample the shape with roughly uniform spacing, though this is also not critical. [sent-56, score-0.574]
</p><p>33 For each point Pi on the first shape, we want to find the "best" matching point qj on the second shape. [sent-59, score-0.388]
</p><p>34 This is a correspondence problem similar to that in stereopsis. [sent-60, score-0.031]
</p><p>35 Experience there suggests that matching is easier if one uses a rich local descriptor instead of just the brightness at a single pixel or edge location. [sent-61, score-0.741]
</p><p>36 In this paper, we propose a descriptor, the shape context, that could play such a role in shape matching. [sent-63, score-1.148]
</p><p>37 Consider the set of vectors originating from a point to all other sample points on a shape. [sent-64, score-0.127]
</p><p>38 These vectors express the configuration of the entire shape relative to the reference point. [sent-65, score-0.574]
</p><p>39 Obviously, this set of n - 1 vectors is a rich  . [sent-66, score-0.067]
</p><p>40 (b)  (a)  (d)  (c)  (e)  Figure 1: Shape context computation and matching. [sent-107, score-0.094]
</p><p>41 (c) Diagram of log-polar histogram bins used in computing the shape contexts. [sent-109, score-0.629]
</p><p>42 (d-f) Example shape contexts for reference samples marked by 0,0,  <-  2000  4000  6000  BOOO  0. [sent-111, score-0.719]
</p><p>43 01  10000  10 3  size of training set  104  size of training set  Figure 2: Handwritten digit recognition on the MNIST dataset. [sent-112, score-0.216]
</p><p>44 Left: Test set errors of a 1-NN classifier using SSD and Shape Distance (SD) measures. [sent-113, score-0.043]
</p><p>45 Right: Detail of performance curve for Shape Distance, including results with training set sizes of 15,000 and 20,000. [sent-114, score-0.038]
</p><p>46 Results are shown on a semilog-x scale for K = 1, 3, 5 nearest neighbors. [sent-115, score-0.056]
</p><p>47 3  Classification using Shape Context matching  Matching shapes enables us to define distances between shapes; given such a distance measure a straightforward strategy for recognition is to use a K -NN classifier. [sent-116, score-0.773]
</p><p>48 In the following two case studies we used 100 point samples selected from the Canny edges of each image. [sent-117, score-0.072]
</p><p>49 We employed a regularized TPS transformation model and used 3 iterations of shape context matching and TPS re-estimation. [sent-118, score-1.005]
</p><p>50 After matching, we estimated shape distances as the weighted sum of three terms: shape context distance, image appearance distance and bending energy. [sent-119, score-1.59]
</p><p>51 We measure shape context distance between shapes P and Q as the symmetric sum of shape context matching costs over best matching points, i. [sent-120, score-2.279]
</p><p>52 LP argminC (p,T(q)) + ~ LQ argminC (p,T(q)) n qEQ m PEP pE  (1)  qE  where T(čˇŻ) denotes the estimated TPS shape transformation. [sent-125, score-0.574]
</p><p>53 We use a term Dac (P, Q) for appearance cost, defined as the sum of squared brightness differences in Gaussian windows around corresponding image points. [sent-126, score-0.276]
</p><p>54 This score is computed after the thin plate spline transformation T has been applied to best warp the images into alignment. [sent-127, score-0.124]
</p><p>55 The third term Dbe (P, Q) corresponds to the 'amount' of transformation necessary to align the shapes. [sent-128, score-0.031]
</p><p>56 In the TPS case the bending energy is a natural measure (see [4, 2]). [sent-129, score-0.089]
</p><p>57 Case study 1: Digit recognition Here we present results on the MNIST dataset of handwritten digits, which consists of 60,000 training and 10,000 test digits [12]. [sent-130, score-0.303]
</p><p>58 Nearest neighbor classifiers have the property that as the number of examples n in the training set goes to infinity, the I-NN error converges to a value ~ 2E*, where E* is the Bayes Risk (for K-NN, K -+ 00 and K/n -+ 0, the error -+ E*). [sent-131, score-0.127]
</p><p>59 2, our shape distance is compared to SSD (sum of squared differences between pixel brightness values). [sent-134, score-0.918]
</p><p>60 On the MNIST dataset nearly 30 algorithms have been compared (http://www. [sent-135, score-0.035]
</p><p>61 The lowest test set error rate published at this time is 0. [sent-140, score-0.076]
</p><p>62 7% for a boosted LeNet-4 with a training set of size  O. [sent-141, score-0.038]
</p><p>63 of prototypes per object  (a)  (b)  Figure 3: 3D object recognition. [sent-150, score-0.59]
</p><p>64 (a) Comparison of test set error for SSD, Shape Distance (SD), and Shape Distance with K-medoid prototypes (SD-proto) vs. [sent-151, score-0.312]
</p><p>65 For SSD and SD, we varied the number of prototypes uniformly for all objects. [sent-153, score-0.283]
</p><p>66 For SD-proto, the number of prototypes per object depended on the within-object variation as well as the between-object similarity. [sent-154, score-0.488]
</p><p>67 (b) K-medoid prototype views for two different examples, using an average of 4 prototypes per object. [sent-155, score-0.576]
</p><p>68 60,000 X 10 synthetic distortions per training digit. [sent-156, score-0.081]
</p><p>69 Our error rate using 20,000 training examples and 3-NN is 0. [sent-157, score-0.067]
</p><p>70 Case study 2: 3D object recognition Our next experiment involves the 20 common household objects from the COIL-20 database [13]. [sent-159, score-0.353]
</p><p>71 We prepared our training sets by selecting a number of equally spaced views for each object and using the remaining views for testing. [sent-160, score-0.298]
</p><p>72 The matching algorithm is exactly the same as for digits. [sent-161, score-0.306]
</p><p>73 3(a) shows the performance using 1-NN on the weighted shape distance compared to a straightforward sum of squared differences (SSD). [sent-163, score-0.831]
</p><p>74 SSD performs very well on this easy database due to the lack of variation in lighting [8]. [sent-164, score-0.066]
</p><p>75 Since the objects in the COIL-20 database have differing variability with respect to viewing angle, it is natural to ask whether prototypes can be allocated more efficiently. [sent-165, score-0.45]
</p><p>76 We have developed a novel editing algorithm based on shape distance and K-medoid clustering. [sent-166, score-0.755]
</p><p>77 K-medoids can be seen as a variant of K-means that restricts prototype positions to data points. [sent-167, score-0.215]
</p><p>78 First a matrix of pairwise similarities between all possible prototypes is computed. [sent-168, score-0.283]
</p><p>79 The number of prototypes is selected by a greedy splitting strategy starting from one prototype per category. [sent-170, score-0.575]
</p><p>80 We choose the cluster to split based on the associated overall misclassification error. [sent-171, score-0.067]
</p><p>81 This continues until the overall misclassification error has dropped below a criterion level. [sent-172, score-0.065]
</p><p>82 As seen, more prototypes are allocated to categories with high within class variability. [sent-175, score-0.334]
</p><p>83 3 shows the improved classification performance using this prototype selection strategy instead of equally-spaced views. [sent-177, score-0.218]
</p><p>84 4% error rate with an average of only 4 two-dimensional views for each three-dimensional object, thanks to the flexibility provided by the matching algorithm. [sent-179, score-0.399]
</p><p>85 4  Conclusion  We have presented a new approach to computing shape similarity and correspondences based on the shape context descriptor. [sent-180, score-1.452]
</p><p>86 The standard invariances are built in for free, and as a consequence we developed a classifier that is highly effective even when only a small number of training examples are available. [sent-182, score-0.141]
</p><p>87 B and the German Research Foundation (DFG) by Emmy Noether grant PU-165/1. [sent-184, score-0.028]
</p><p>88 New algorithms for 2D and 3D point matching: pose estimation and correspondence. [sent-225, score-0.041]
</p><p>89 View-based recognition using an eigenspace approximation to the Hausdorff measure. [sent-232, score-0.105]
</p><p>90 A shortest augmenting path algorithm for dense and sparse linear assignment problems. [sent-242, score-0.031]
</p><p>91 Distortion invariant object recognition in the dynamic link architecture. [sent-254, score-0.237]
</p><p>92 Visual learning and recognition of 3-D objects from appearance. [sent-268, score-0.185]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('shape', 0.574), ('matching', 0.306), ('prototypes', 0.283), ('prototype', 0.186), ('ssd', 0.179), ('descriptor', 0.154), ('correspondences', 0.154), ('shapes', 0.142), ('object', 0.132), ('distance', 0.13), ('tps', 0.12), ('contexts', 0.109), ('brightness', 0.108), ('recognition', 0.105), ('descriptors', 0.103), ('context', 0.094), ('points', 0.086), ('mnist', 0.081), ('objects', 0.08), ('digits', 0.078), ('pami', 0.077), ('edge', 0.068), ('rich', 0.067), ('views', 0.064), ('cvpr', 0.061), ('berkeley', 0.061), ('argminc', 0.06), ('belongie', 0.06), ('bending', 0.06), ('hausdorff', 0.06), ('invariances', 0.06), ('malik', 0.06), ('november', 0.06), ('rangarajan', 0.06), ('sd', 0.057), ('nearest', 0.056), ('similarity', 0.056), ('june', 0.055), ('score', 0.055), ('bins', 0.055), ('allocated', 0.051), ('editing', 0.051), ('gold', 0.051), ('handwritten', 0.047), ('published', 0.047), ('per', 0.043), ('classifier', 0.043), ('point', 0.041), ('key', 0.041), ('contours', 0.038), ('spline', 0.038), ('training', 0.038), ('pixel', 0.038), ('marked', 0.036), ('appearance', 0.036), ('misclassification', 0.036), ('database', 0.036), ('differences', 0.036), ('dataset', 0.035), ('digit', 0.035), ('moments', 0.035), ('image', 0.034), ('sampled', 0.033), ('squared', 0.032), ('strategy', 0.032), ('transformation', 0.031), ('correspondence', 0.031), ('neighbor', 0.031), ('cluster', 0.031), ('assignment', 0.031), ('selected', 0.031), ('pi', 0.031), ('clusters', 0.03), ('variation', 0.03), ('sum', 0.03), ('weighted', 0.029), ('positions', 0.029), ('distances', 0.029), ('measure', 0.029), ('error', 0.029), ('grant', 0.028), ('pixels', 0.027), ('pages', 0.027), ('oren', 0.026), ('martial', 0.026), ('von', 0.026), ('loses', 0.026), ('osuna', 0.026), ('pappu', 0.026), ('pedestrian', 0.026), ('arrangements', 0.026), ('pointwise', 0.026), ('lange', 0.026), ('fundamentally', 0.026), ('puzicha', 0.026), ('landmarks', 0.026), ('puerto', 0.026), ('rico', 0.026), ('positional', 0.026), ('jan', 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="117-tfidf-1" href="./nips-2000-Shape_Context%3A_A_New_Descriptor_for_Shape_Matching_and_Object_Recognition.html">117 nips-2000-Shape Context: A New Descriptor for Shape Matching and Object Recognition</a></p>
<p>Author: Serge Belongie, Jitendra Malik, Jan Puzicha</p><p>Abstract: We develop an approach to object recognition based on matching shapes and using a resulting measure of similarity in a nearest neighbor classifier. The key algorithmic problem here is that of finding pointwise correspondences between an image shape and a stored prototype shape. We introduce a new shape descriptor, the shape context, which makes this possible, using a simple and robust algorithm. The shape context at a point captures the distribution over relative positions of other shape points and thus summarizes global shape in a rich, local descriptor. We demonstrate that shape contexts greatly simplify recovery of correspondences between points of two given shapes. Once shapes are aligned, shape contexts are used to define a robust score for measuring shape similarity. We have used this score in a nearest-neighbor classifier for recognition of hand written digits as well as 3D objects, using exactly the same distance function. On the benchmark MNIST dataset of handwritten digits, this yields an error rate of 0.63%, outperforming other published techniques. 1</p><p>2 0.16157044 <a title="117-tfidf-2" href="./nips-2000-A_Productive%2C_Systematic_Framework_for_the_Representation_of_Visual_Structure.html">10 nips-2000-A Productive, Systematic Framework for the Representation of Visual Structure</a></p>
<p>Author: Shimon Edelman, Nathan Intrator</p><p>Abstract: We describe a unified framework for the understanding of structure representation in primate vision. A model derived from this framework is shown to be effectively systematic in that it has the ability to interpret and associate together objects that are related through a rearrangement of common</p><p>3 0.11747338 <a title="117-tfidf-3" href="./nips-2000-Feature_Correspondence%3A_A_Markov_Chain_Monte_Carlo_Approach.html">53 nips-2000-Feature Correspondence: A Markov Chain Monte Carlo Approach</a></p>
<p>Author: Frank Dellaert, Steven M. Seitz, Sebastian Thrun, Charles E. Thorpe</p><p>Abstract: When trying to recover 3D structure from a set of images, the most difficult problem is establishing the correspondence between the measurements. Most existing approaches assume that features can be tracked across frames, whereas methods that exploit rigidity constraints to facilitate matching do so only under restricted camera motion. In this paper we propose a Bayesian approach that avoids the brittleness associated with singling out one</p><p>4 0.088298485 <a title="117-tfidf-4" href="./nips-2000-Rate-coded_Restricted_Boltzmann_Machines_for_Face_Recognition.html">107 nips-2000-Rate-coded Restricted Boltzmann Machines for Face Recognition</a></p>
<p>Author: Yee Whye Teh, Geoffrey E. Hinton</p><p>Abstract: We describe a neurally-inspired, unsupervised learning algorithm that builds a non-linear generative model for pairs of face images from the same individual. Individuals are then recognized by finding the highest relative probability pair among all pairs that consist of a test image and an image whose identity is known. Our method compares favorably with other methods in the literature. The generative model consists of a single layer of rate-coded, non-linear feature detectors and it has the property that, given a data vector, the true posterior probability distribution over the feature detector activities can be inferred rapidly without iteration or approximation. The weights of the feature detectors are learned by comparing the correlations of pixel intensities and feature activations in two phases: When the network is observing real data and when it is observing reconstructions of real data generated from the feature activations.</p><p>5 0.085509755 <a title="117-tfidf-5" href="./nips-2000-Partially_Observable_SDE_Models_for_Image_Sequence_Recognition_Tasks.html">98 nips-2000-Partially Observable SDE Models for Image Sequence Recognition Tasks</a></p>
<p>Author: Javier R. Movellan, Paul Mineiro, Ruth J. Williams</p><p>Abstract: This paper explores a framework for recognition of image sequences using partially observable stochastic differential equation (SDE) models. Monte-Carlo importance sampling techniques are used for efficient estimation of sequence likelihoods and sequence likelihood gradients. Once the network dynamics are learned, we apply the SDE models to sequence recognition tasks in a manner similar to the way Hidden Markov models (HMMs) are commonly applied. The potential advantage of SDEs over HMMS is the use of continuous state dynamics. We present encouraging results for a video sequence recognition task in which SDE models provided excellent performance when compared to hidden Markov models. 1</p><p>6 0.08522626 <a title="117-tfidf-6" href="./nips-2000-Interactive_Parts_Model%3A_An_Application_to_Recognition_of_On-line_Cursive_Script.html">71 nips-2000-Interactive Parts Model: An Application to Recognition of On-line Cursive Script</a></p>
<p>7 0.075966708 <a title="117-tfidf-7" href="./nips-2000-Data_Clustering_by_Markovian_Relaxation_and_the_Information_Bottleneck_Method.html">38 nips-2000-Data Clustering by Markovian Relaxation and the Information Bottleneck Method</a></p>
<p>8 0.075687945 <a title="117-tfidf-8" href="./nips-2000-Adaptive_Object_Representation_with_Hierarchically-Distributed_Memory_Sites.html">19 nips-2000-Adaptive Object Representation with Hierarchically-Distributed Memory Sites</a></p>
<p>9 0.073372595 <a title="117-tfidf-9" href="./nips-2000-Keeping_Flexible_Active_Contours_on_Track_using_Metropolis_Updates.html">72 nips-2000-Keeping Flexible Active Contours on Track using Metropolis Updates</a></p>
<p>10 0.068263389 <a title="117-tfidf-10" href="./nips-2000-A_Comparison_of_Image_Processing_Techniques_for_Visual_Speech_Recognition_Applications.html">2 nips-2000-A Comparison of Image Processing Techniques for Visual Speech Recognition Applications</a></p>
<p>11 0.063786104 <a title="117-tfidf-11" href="./nips-2000-Support_Vector_Novelty_Detection_Applied_to_Jet_Engine_Vibration_Spectra.html">128 nips-2000-Support Vector Novelty Detection Applied to Jet Engine Vibration Spectra</a></p>
<p>12 0.060993623 <a title="117-tfidf-12" href="./nips-2000-Large_Scale_Bayes_Point_Machines.html">75 nips-2000-Large Scale Bayes Point Machines</a></p>
<p>13 0.057020202 <a title="117-tfidf-13" href="./nips-2000-The_Manhattan_World_Assumption%3A_Regularities_in_Scene_Statistics_which_Enable_Bayesian_Inference.html">135 nips-2000-The Manhattan World Assumption: Regularities in Scene Statistics which Enable Bayesian Inference</a></p>
<p>14 0.054412335 <a title="117-tfidf-14" href="./nips-2000-An_Adaptive_Metric_Machine_for_Pattern_Classification.html">23 nips-2000-An Adaptive Metric Machine for Pattern Classification</a></p>
<p>15 0.051577508 <a title="117-tfidf-15" href="./nips-2000-Learning_Segmentation_by_Random_Walks.html">79 nips-2000-Learning Segmentation by Random Walks</a></p>
<p>16 0.05007787 <a title="117-tfidf-16" href="./nips-2000-A_Support_Vector_Method_for_Clustering.html">12 nips-2000-A Support Vector Method for Clustering</a></p>
<p>17 0.049480937 <a title="117-tfidf-17" href="./nips-2000-Weak_Learners_and_Improved_Rates_of_Convergence_in_Boosting.html">145 nips-2000-Weak Learners and Improved Rates of Convergence in Boosting</a></p>
<p>18 0.048311759 <a title="117-tfidf-18" href="./nips-2000-%60N-Body%27_Problems_in_Statistical_Learning.html">148 nips-2000-`N-Body' Problems in Statistical Learning</a></p>
<p>19 0.047285788 <a title="117-tfidf-19" href="./nips-2000-Higher-Order_Statistical_Properties_Arising_from_the_Non-Stationarity_of_Natural_Signals.html">65 nips-2000-Higher-Order Statistical Properties Arising from the Non-Stationarity of Natural Signals</a></p>
<p>20 0.046994172 <a title="117-tfidf-20" href="./nips-2000-Accumulator_Networks%3A_Suitors_of_Local_Probability_Propagation.html">15 nips-2000-Accumulator Networks: Suitors of Local Probability Propagation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2000_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.18), (1, -0.014), (2, 0.049), (3, 0.073), (4, -0.062), (5, 0.049), (6, 0.134), (7, -0.03), (8, 0.085), (9, 0.144), (10, 0.046), (11, 0.102), (12, 0.186), (13, 0.013), (14, -0.092), (15, -0.015), (16, -0.018), (17, -0.114), (18, -0.051), (19, 0.054), (20, -0.013), (21, -0.131), (22, -0.088), (23, 0.154), (24, 0.049), (25, 0.251), (26, -0.05), (27, -0.016), (28, -0.092), (29, 0.159), (30, 0.088), (31, 0.131), (32, -0.061), (33, 0.008), (34, 0.005), (35, -0.092), (36, -0.069), (37, 0.087), (38, -0.032), (39, -0.125), (40, 0.086), (41, 0.017), (42, -0.026), (43, -0.228), (44, -0.114), (45, 0.193), (46, 0.13), (47, -0.15), (48, 0.041), (49, -0.115)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98392248 <a title="117-lsi-1" href="./nips-2000-Shape_Context%3A_A_New_Descriptor_for_Shape_Matching_and_Object_Recognition.html">117 nips-2000-Shape Context: A New Descriptor for Shape Matching and Object Recognition</a></p>
<p>Author: Serge Belongie, Jitendra Malik, Jan Puzicha</p><p>Abstract: We develop an approach to object recognition based on matching shapes and using a resulting measure of similarity in a nearest neighbor classifier. The key algorithmic problem here is that of finding pointwise correspondences between an image shape and a stored prototype shape. We introduce a new shape descriptor, the shape context, which makes this possible, using a simple and robust algorithm. The shape context at a point captures the distribution over relative positions of other shape points and thus summarizes global shape in a rich, local descriptor. We demonstrate that shape contexts greatly simplify recovery of correspondences between points of two given shapes. Once shapes are aligned, shape contexts are used to define a robust score for measuring shape similarity. We have used this score in a nearest-neighbor classifier for recognition of hand written digits as well as 3D objects, using exactly the same distance function. On the benchmark MNIST dataset of handwritten digits, this yields an error rate of 0.63%, outperforming other published techniques. 1</p><p>2 0.62150472 <a title="117-lsi-2" href="./nips-2000-A_Productive%2C_Systematic_Framework_for_the_Representation_of_Visual_Structure.html">10 nips-2000-A Productive, Systematic Framework for the Representation of Visual Structure</a></p>
<p>Author: Shimon Edelman, Nathan Intrator</p><p>Abstract: We describe a unified framework for the understanding of structure representation in primate vision. A model derived from this framework is shown to be effectively systematic in that it has the ability to interpret and associate together objects that are related through a rearrangement of common</p><p>3 0.59660226 <a title="117-lsi-3" href="./nips-2000-Feature_Correspondence%3A_A_Markov_Chain_Monte_Carlo_Approach.html">53 nips-2000-Feature Correspondence: A Markov Chain Monte Carlo Approach</a></p>
<p>Author: Frank Dellaert, Steven M. Seitz, Sebastian Thrun, Charles E. Thorpe</p><p>Abstract: When trying to recover 3D structure from a set of images, the most difficult problem is establishing the correspondence between the measurements. Most existing approaches assume that features can be tracked across frames, whereas methods that exploit rigidity constraints to facilitate matching do so only under restricted camera motion. In this paper we propose a Bayesian approach that avoids the brittleness associated with singling out one</p><p>4 0.39633477 <a title="117-lsi-4" href="./nips-2000-Partially_Observable_SDE_Models_for_Image_Sequence_Recognition_Tasks.html">98 nips-2000-Partially Observable SDE Models for Image Sequence Recognition Tasks</a></p>
<p>Author: Javier R. Movellan, Paul Mineiro, Ruth J. Williams</p><p>Abstract: This paper explores a framework for recognition of image sequences using partially observable stochastic differential equation (SDE) models. Monte-Carlo importance sampling techniques are used for efficient estimation of sequence likelihoods and sequence likelihood gradients. Once the network dynamics are learned, we apply the SDE models to sequence recognition tasks in a manner similar to the way Hidden Markov models (HMMs) are commonly applied. The potential advantage of SDEs over HMMS is the use of continuous state dynamics. We present encouraging results for a video sequence recognition task in which SDE models provided excellent performance when compared to hidden Markov models. 1</p><p>5 0.35559288 <a title="117-lsi-5" href="./nips-2000-Adaptive_Object_Representation_with_Hierarchically-Distributed_Memory_Sites.html">19 nips-2000-Adaptive Object Representation with Hierarchically-Distributed Memory Sites</a></p>
<p>Author: Bosco S. Tjan</p><p>Abstract: Theories of object recognition often assume that only one representation scheme is used within one visual-processing pathway. Versatility of the visual system comes from having multiple visual-processing pathways, each specialized in a different category of objects. We propose a theoretically simpler alternative, capable of explaining the same set of data and more. A single primary visual-processing pathway, loosely modular, is assumed. Memory modules are attached to sites along this pathway. Object-identity decision is made independently at each site. A site's response time is a monotonic-decreasing function of its confidence regarding its decision. An observer's response is the first-arriving response from any site. The effective representation(s) of such a system, determined empirically, can appear to be specialized for different tasks and stimuli, consistent with recent clinical and functional-imaging findings. This, however, merely reflects a decision being made at its appropriate level of abstraction. The system itself is intrinsically flexible and adaptive.</p><p>6 0.31023961 <a title="117-lsi-6" href="./nips-2000-Interactive_Parts_Model%3A_An_Application_to_Recognition_of_On-line_Cursive_Script.html">71 nips-2000-Interactive Parts Model: An Application to Recognition of On-line Cursive Script</a></p>
<p>7 0.30104256 <a title="117-lsi-7" href="./nips-2000-The_Manhattan_World_Assumption%3A_Regularities_in_Scene_Statistics_which_Enable_Bayesian_Inference.html">135 nips-2000-The Manhattan World Assumption: Regularities in Scene Statistics which Enable Bayesian Inference</a></p>
<p>8 0.28385046 <a title="117-lsi-8" href="./nips-2000-Data_Clustering_by_Markovian_Relaxation_and_the_Information_Bottleneck_Method.html">38 nips-2000-Data Clustering by Markovian Relaxation and the Information Bottleneck Method</a></p>
<p>9 0.28030661 <a title="117-lsi-9" href="./nips-2000-Rate-coded_Restricted_Boltzmann_Machines_for_Face_Recognition.html">107 nips-2000-Rate-coded Restricted Boltzmann Machines for Face Recognition</a></p>
<p>10 0.27578914 <a title="117-lsi-10" href="./nips-2000-Learning_Segmentation_by_Random_Walks.html">79 nips-2000-Learning Segmentation by Random Walks</a></p>
<p>11 0.25802004 <a title="117-lsi-11" href="./nips-2000-A_Comparison_of_Image_Processing_Techniques_for_Visual_Speech_Recognition_Applications.html">2 nips-2000-A Comparison of Image Processing Techniques for Visual Speech Recognition Applications</a></p>
<p>12 0.22866535 <a title="117-lsi-12" href="./nips-2000-Keeping_Flexible_Active_Contours_on_Track_using_Metropolis_Updates.html">72 nips-2000-Keeping Flexible Active Contours on Track using Metropolis Updates</a></p>
<p>13 0.22677472 <a title="117-lsi-13" href="./nips-2000-Redundancy_and_Dimensionality_Reduction_in_Sparse-Distributed_Representations_of_Natural_Objects_in_Terms_of_Their_Local_Features.html">109 nips-2000-Redundancy and Dimensionality Reduction in Sparse-Distributed Representations of Natural Objects in Terms of Their Local Features</a></p>
<p>14 0.21877682 <a title="117-lsi-14" href="./nips-2000-Support_Vector_Novelty_Detection_Applied_to_Jet_Engine_Vibration_Spectra.html">128 nips-2000-Support Vector Novelty Detection Applied to Jet Engine Vibration Spectra</a></p>
<p>15 0.21818531 <a title="117-lsi-15" href="./nips-2000-%60N-Body%27_Problems_in_Statistical_Learning.html">148 nips-2000-`N-Body' Problems in Statistical Learning</a></p>
<p>16 0.21330459 <a title="117-lsi-16" href="./nips-2000-An_Adaptive_Metric_Machine_for_Pattern_Classification.html">23 nips-2000-An Adaptive Metric Machine for Pattern Classification</a></p>
<p>17 0.18692969 <a title="117-lsi-17" href="./nips-2000-Accumulator_Networks%3A_Suitors_of_Local_Probability_Propagation.html">15 nips-2000-Accumulator Networks: Suitors of Local Probability Propagation</a></p>
<p>18 0.18592209 <a title="117-lsi-18" href="./nips-2000-Sparse_Greedy_Gaussian_Process_Regression.html">120 nips-2000-Sparse Greedy Gaussian Process Regression</a></p>
<p>19 0.17938751 <a title="117-lsi-19" href="./nips-2000-Large_Scale_Bayes_Point_Machines.html">75 nips-2000-Large Scale Bayes Point Machines</a></p>
<p>20 0.17822875 <a title="117-lsi-20" href="./nips-2000-Discovering_Hidden_Variables%3A_A_Structure-Based_Approach.html">41 nips-2000-Discovering Hidden Variables: A Structure-Based Approach</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2000_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.037), (11, 0.325), (17, 0.103), (32, 0.031), (33, 0.045), (45, 0.01), (54, 0.023), (55, 0.053), (62, 0.025), (65, 0.011), (67, 0.054), (75, 0.023), (76, 0.043), (79, 0.027), (81, 0.031), (90, 0.043), (97, 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.85667706 <a title="117-lda-1" href="./nips-2000-Shape_Context%3A_A_New_Descriptor_for_Shape_Matching_and_Object_Recognition.html">117 nips-2000-Shape Context: A New Descriptor for Shape Matching and Object Recognition</a></p>
<p>Author: Serge Belongie, Jitendra Malik, Jan Puzicha</p><p>Abstract: We develop an approach to object recognition based on matching shapes and using a resulting measure of similarity in a nearest neighbor classifier. The key algorithmic problem here is that of finding pointwise correspondences between an image shape and a stored prototype shape. We introduce a new shape descriptor, the shape context, which makes this possible, using a simple and robust algorithm. The shape context at a point captures the distribution over relative positions of other shape points and thus summarizes global shape in a rich, local descriptor. We demonstrate that shape contexts greatly simplify recovery of correspondences between points of two given shapes. Once shapes are aligned, shape contexts are used to define a robust score for measuring shape similarity. We have used this score in a nearest-neighbor classifier for recognition of hand written digits as well as 3D objects, using exactly the same distance function. On the benchmark MNIST dataset of handwritten digits, this yields an error rate of 0.63%, outperforming other published techniques. 1</p><p>2 0.44225353 <a title="117-lda-2" href="./nips-2000-A_Productive%2C_Systematic_Framework_for_the_Representation_of_Visual_Structure.html">10 nips-2000-A Productive, Systematic Framework for the Representation of Visual Structure</a></p>
<p>Author: Shimon Edelman, Nathan Intrator</p><p>Abstract: We describe a unified framework for the understanding of structure representation in primate vision. A model derived from this framework is shown to be effectively systematic in that it has the ability to interpret and associate together objects that are related through a rearrangement of common</p><p>3 0.41896918 <a title="117-lda-3" href="./nips-2000-Sparse_Representation_for_Gaussian_Process_Models.html">122 nips-2000-Sparse Representation for Gaussian Process Models</a></p>
<p>Author: Lehel Csatč´¸, Manfred Opper</p><p>Abstract: We develop an approach for a sparse representation for Gaussian Process (GP) models in order to overcome the limitations of GPs caused by large data sets. The method is based on a combination of a Bayesian online algorithm together with a sequential construction of a relevant subsample of the data which fully specifies the prediction of the model. Experimental results on toy examples and large real-world data sets indicate the efficiency of the approach.</p><p>4 0.41440779 <a title="117-lda-4" href="./nips-2000-Propagation_Algorithms_for_Variational_Bayesian_Learning.html">106 nips-2000-Propagation Algorithms for Variational Bayesian Learning</a></p>
<p>Author: Zoubin Ghahramani, Matthew J. Beal</p><p>Abstract: Variational approximations are becoming a widespread tool for Bayesian learning of graphical models. We provide some theoretical results for the variational updates in a very general family of conjugate-exponential graphical models. We show how the belief propagation and the junction tree algorithms can be used in the inference step of variational Bayesian learning. Applying these results to the Bayesian analysis of linear-Gaussian state-space models we obtain a learning procedure that exploits the Kalman smoothing propagation, while integrating over all model parameters. We demonstrate how this can be used to infer the hidden state dimensionality of the state-space model in a variety of synthetic problems and one real high-dimensional data set. 1</p><p>5 0.4093028 <a title="117-lda-5" href="./nips-2000-Processing_of_Time_Series_by_Neural_Circuits_with_Biologically_Realistic_Synaptic_Dynamics.html">104 nips-2000-Processing of Time Series by Neural Circuits with Biologically Realistic Synaptic Dynamics</a></p>
<p>Author: Thomas Natschläger, Wolfgang Maass, Eduardo D. Sontag, Anthony M. Zador</p><p>Abstract: Experimental data show that biological synapses behave quite differently from the symbolic synapses in common artificial neural network models. Biological synapses are dynamic, i.e., their</p><p>6 0.40866026 <a title="117-lda-6" href="./nips-2000-Kernel_Expansions_with_Unlabeled_Examples.html">74 nips-2000-Kernel Expansions with Unlabeled Examples</a></p>
<p>7 0.40543991 <a title="117-lda-7" href="./nips-2000-Learning_Segmentation_by_Random_Walks.html">79 nips-2000-Learning Segmentation by Random Walks</a></p>
<p>8 0.4053753 <a title="117-lda-8" href="./nips-2000-A_New_Approximate_Maximal_Margin_Classification_Algorithm.html">7 nips-2000-A New Approximate Maximal Margin Classification Algorithm</a></p>
<p>9 0.40381178 <a title="117-lda-9" href="./nips-2000-Partially_Observable_SDE_Models_for_Image_Sequence_Recognition_Tasks.html">98 nips-2000-Partially Observable SDE Models for Image Sequence Recognition Tasks</a></p>
<p>10 0.40110621 <a title="117-lda-10" href="./nips-2000-Rate-coded_Restricted_Boltzmann_Machines_for_Face_Recognition.html">107 nips-2000-Rate-coded Restricted Boltzmann Machines for Face Recognition</a></p>
<p>11 0.39993089 <a title="117-lda-11" href="./nips-2000-A_Linear_Programming_Approach_to_Novelty_Detection.html">4 nips-2000-A Linear Programming Approach to Novelty Detection</a></p>
<p>12 0.39932674 <a title="117-lda-12" href="./nips-2000-The_Kernel_Gibbs_Sampler.html">133 nips-2000-The Kernel Gibbs Sampler</a></p>
<p>13 0.39874643 <a title="117-lda-13" href="./nips-2000-Gaussianization.html">60 nips-2000-Gaussianization</a></p>
<p>14 0.39635071 <a title="117-lda-14" href="./nips-2000-Fast_Training_of_Support_Vector_Classifiers.html">52 nips-2000-Fast Training of Support Vector Classifiers</a></p>
<p>15 0.3962 <a title="117-lda-15" href="./nips-2000-What_Can_a_Single_Neuron_Compute%3F.html">146 nips-2000-What Can a Single Neuron Compute?</a></p>
<p>16 0.39618245 <a title="117-lda-16" href="./nips-2000-Large_Scale_Bayes_Point_Machines.html">75 nips-2000-Large Scale Bayes Point Machines</a></p>
<p>17 0.39579812 <a title="117-lda-17" href="./nips-2000-Algorithmic_Stability_and_Generalization_Performance.html">21 nips-2000-Algorithmic Stability and Generalization Performance</a></p>
<p>18 0.3954874 <a title="117-lda-18" href="./nips-2000-Position_Variance%2C_Recurrence_and_Perceptual_Learning.html">102 nips-2000-Position Variance, Recurrence and Perceptual Learning</a></p>
<p>19 0.39544708 <a title="117-lda-19" href="./nips-2000-Convergence_of_Large_Margin_Separable_Linear_Classification.html">37 nips-2000-Convergence of Large Margin Separable Linear Classification</a></p>
<p>20 0.39522615 <a title="117-lda-20" href="./nips-2000-A_PAC-Bayesian_Margin_Bound_for_Linear_Classifiers%3A_Why_SVMs_work.html">9 nips-2000-A PAC-Bayesian Margin Bound for Linear Classifiers: Why SVMs work</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
