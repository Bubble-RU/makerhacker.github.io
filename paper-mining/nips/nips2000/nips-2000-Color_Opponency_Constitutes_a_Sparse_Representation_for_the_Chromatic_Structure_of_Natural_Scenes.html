<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>32 nips-2000-Color Opponency Constitutes a Sparse Representation for the Chromatic Structure of Natural Scenes</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2000" href="../home/nips2000_home.html">nips2000</a> <a title="nips-2000-32" href="#">nips2000-32</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>32 nips-2000-Color Opponency Constitutes a Sparse Representation for the Chromatic Structure of Natural Scenes</h1>
<br/><p>Source: <a title="nips-2000-32-pdf" href="http://papers.nips.cc/paper/1909-color-opponency-constitutes-a-sparse-representation-for-the-chromatic-structure-of-natural-scenes.pdf">pdf</a></p><p>Author: Te-Won Lee, Thomas Wachtler, Terrence J. Sejnowski</p><p>Abstract: The human visual system encodes the chromatic signals conveyed by the three types of retinal cone photoreceptors in an opponent fashion. This color opponency has been shown to constitute an efficient encoding by spectral decorrelation of the receptor signals. We analyze the spatial and chromatic structure of natural scenes by decomposing the spectral images into a set of linear basis functions such that they constitute a representation with minimal redundancy. Independent component analysis finds the basis functions that transforms the spatiochromatic data such that the outputs (activations) are statistically as independent as possible, i.e. least redundant. The resulting basis functions show strong opponency along an achromatic direction (luminance edges), along a blueyellow direction, and along a red-blue direction. Furthermore, the resulting activations have very sparse distributions, suggesting that the use of color opponency in the human visual system achieves a highly efficient representation of colors. Our findings suggest that color opponency is a result of the properties of natural spectra and not solely a consequence of the overlapping cone spectral sensitivities. 1 Statistical structure of natural scenes Efficient encoding of visual sensory information is an important task for information processing systems and its study may provide insights into coding principles of biological visual systems. An important goal of sensory information processing Electronic version available at www. cnl. salk . edu/</p><p>Reference: <a title="nips-2000-32-reference" href="../nips2000_reference/nips-2000-Color_Opponency_Constitutes_a_Sparse_Representation_for_the_Chromatic_Structure_of_Natural_Scenes_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract The human visual system encodes the chromatic signals conveyed by the three types of retinal cone photoreceptors in an opponent fashion. [sent-3, score-1.062]
</p><p>2 This color opponency has been shown to constitute an efficient encoding by spectral decorrelation of the receptor signals. [sent-4, score-0.857]
</p><p>3 We analyze the spatial and chromatic structure of natural scenes by decomposing the spectral images into a set of linear basis functions such that they constitute a representation with minimal redundancy. [sent-5, score-1.252]
</p><p>4 Independent component analysis finds the basis functions that transforms the spatiochromatic data such that the outputs (activations) are statistically as independent as possible, i. [sent-6, score-0.565]
</p><p>5 The resulting basis functions show strong opponency along an achromatic direction (luminance edges), along a blueyellow direction, and along a red-blue direction. [sent-9, score-0.846]
</p><p>6 Furthermore, the resulting activations have very sparse distributions, suggesting that the use of color opponency in the human visual system achieves a highly efficient representation of colors. [sent-10, score-0.853]
</p><p>7 Our findings suggest that color opponency is a result of the properties of natural spectra and not solely a consequence of the overlapping cone spectral sensitivities. [sent-11, score-1.165]
</p><p>8 1  Statistical structure of natural scenes  Efficient encoding of visual sensory information is an important task for information processing systems and its study may provide insights into coding principles of biological visual systems. [sent-12, score-0.497]
</p><p>9 An important goal of sensory information processing Electronic version available at www. [sent-13, score-0.037]
</p><p>10 is to transform the input signals such that the redundancy between the inputs is reduced. [sent-17, score-0.103]
</p><p>11 In natural scenes, the image intensity is highly predictable from neighboring measurements and an efficient representation preserves the information while the neuronal output is minimized. [sent-18, score-0.258]
</p><p>12 Recently, several methods have been proposed for finding efficient codes for achromatic images of natural scenes [1, 2, 3, 4]. [sent-19, score-0.432]
</p><p>13 While luminance dominates the structure of the visual world, color vision provides important additional information about our environment. [sent-20, score-0.579]
</p><p>14 redundancy reducing representations for the chromatic structure of natural scenes. [sent-23, score-0.723]
</p><p>15 2  Learning efficient representation for chromatic image  Our goal was to find efficient representations of the chromatic sensory information such that its spatial and chromatic redundancy is reduced significantly. [sent-24, score-1.811]
</p><p>16 The method we used for finding statistically efficient representations is independent component analysis (ICA). [sent-25, score-0.187]
</p><p>17 ICA is a way of finding a linear non-orthogonal co-ordinate system in multivariate data that minimizes mutual information among the axial projections of the data. [sent-26, score-0.033]
</p><p>18 The directions of the axes of this co-ordinate system (basis functions) are determined by both second and higher-order statistics of the original data, compared to Principal Component Analysis (PCA) which is used solely in second order statistics and has orthogonal basis functions. [sent-27, score-0.391]
</p><p>19 The goal of ICA is to perform a linear transform which makes the resulting source outputs as statistically independent from each other as possible [5]. [sent-28, score-0.071]
</p><p>20 A small patch of the observed image is stretched into a vector x that can be represented as a linear combination of sources components Si such that  x=As,  (1)  where A is a scalar square matrix and the columns of A are the basis functions. [sent-30, score-0.4]
</p><p>21 Since A and s are unknown the goal of ICA is to adapt the basis functions by estimating s so that the individual components Si are statistically independent and this adaptation process minimizes the mutual information between the components Si. [sent-31, score-0.553]
</p><p>22 In our experiments, we used the infomax learning rule with natural gradient extension and the learning algorithm for the basis functions is  (2) where I is the identity matrix, rp(s) = - 8p~(W3s and sT denotes the matrix transpose of s . [sent-33, score-0.457]
</p><p>23 A is the change of the basis functions that is added to A. [sent-36, score-0.354]
</p><p>24 In other words, our experiments do not constrain the coefficients to have a  a)  b)  <[n m[  700  Figure 1: Linear decomposition of an observed spectral image patch into its basis functions. [sent-44, score-0.491]
</p><p>25 The algorithm converged to a solution of maximal independence and the distributions of the coefficients were approximated by exponential power densities. [sent-46, score-0.043]
</p><p>26 We investigated samples of spectral images of natural scenes as illustrated in Figure 1. [sent-47, score-0.344]
</p><p>27 We analyzed a set of hyperspectral images [7] with a size of 256 x 256 pixels. [sent-48, score-0.068]
</p><p>28 Each pixel is represented by radiance values for 31 wavebands of 10 nm width, sampled in 10 nm steps between 400 and 700 nm. [sent-49, score-0.353]
</p><p>29 The images were recorded around Bristol, either outdoors, or inside the glass houses of Bristol Botanical Gardens. [sent-53, score-0.068]
</p><p>30 We chose eight of these images which had been obtained outdoors under apparently different illumination conditions. [sent-54, score-0.112]
</p><p>31 The vector of 31 spectral radiance values of each pixel was converted to a vector of 3 cone excitation values whose components were the inner products of the radiance vector with the vectors of L-, M-, and S-cone sensitivity values [8], respectively. [sent-55, score-0.758]
</p><p>32 From the entire image data set, 7x7 pixel image patches were chosen randomly, yielding 7x7x3 = 147 dimensional vectors. [sent-56, score-0.359]
</p><p>33 The learning process was done in 500 steps, each using a set of spectra of 40000 image patches, 5000 chosen randomly from each of the eight images. [sent-57, score-0.109]
</p><p>34 A set of basis functions for 7x7 pixel patches was obtained, with each pixel containing the logarithms of the excitations of the three human cone photo receptors that represented the receptor signals in the human retina [8, 9]. [sent-58, score-1.209]
</p><p>35 To visualize the learned basis functions, we  used the method by Ruderman et al. [sent-59, score-0.253]
</p><p>36 [9] and plotted for each basis function a 7 x 7 pixel matrix, with the color of each pixel indicating the combination of L, M, and S cone responses as follows. [sent-60, score-1.15]
</p><p>37 The values for each patch were normalized to values between a and 255, with a cone excitation corresponding to a value of 128. [sent-61, score-0.392]
</p><p>38 Thus, the R, G, and B components of each pixel represent the relative excitations of L, M, and S cones, respectively. [sent-62, score-0.193]
</p><p>39 To further illustrate the chromatic properties of the basis functions, we convert the L, M, S vector of each pixel to its projection onto the isoluminant plane of a cone-opponent color space similar to the color spaces of MacLeod and Boynton[lO] and Derrington et al[l1]. [sent-63, score-1.695]
</p><p>40 In our plots, the horizontal axis corresponds to the response of an L cone versus M cone opponent mechanism, the vertical axis corresponds to S cone modulation. [sent-64, score-1.144]
</p><p>41 For each pixel of the basis functions, a point is plotted at its corresponding location in that color space. [sent-65, score-0.741]
</p><p>42 The color of the points are the same as used for the pixels in the top part of the figure. [sent-66, score-0.407]
</p><p>43 Thus, although only the projection onto the isoluminant plane is shown, the third dimension (i. [sent-67, score-0.1]
</p><p>44 , luminance) can be inferred by the brightness of the points. [sent-69, score-0.058]
</p><p>45 Figure 2a shows the learned leA basis functions in a pseudo color representation. [sent-70, score-0.72]
</p><p>46 Figure 2b shows the color space coordinates of the chromaticities of the pixels in each basis function. [sent-71, score-0.825]
</p><p>47 The peA basis functions and their corresponding color space coordinates are shown in Figure 2c and 2d respectively. [sent-72, score-0.752]
</p><p>48 Both representations are in order of decreasing L 2 -norm. [sent-73, score-0.057]
</p><p>49 The peA results show a global spatial representation and their opponent basis functions lie mostly along the coordinate axes of the cone-opponent color space. [sent-74, score-1.107]
</p><p>50 In addition, there are functions that imply mixtures of non-opponent colors. [sent-75, score-0.101]
</p><p>51 In contrast to peA basis functions, the leA basis functions are localized and oriented. [sent-76, score-0.646]
</p><p>52 When ordered by decreasing L 2 -norm, achromatic basis functions tend to appear before chromatic basis functions. [sent-77, score-1.234]
</p><p>53 This reflects the fact that in the natural environment, luminance variations are generally larger than chromatic variations [7]. [sent-78, score-0.782]
</p><p>54 The achromatic basis functions are localized and oriented, similar to those found in the analysis of grayscale natural images [1, 2]. [sent-79, score-0.675]
</p><p>55 Most ofthe chromatic basis functions, particularly those with strong contributions, are color opponent, i. [sent-80, score-1.107]
</p><p>56 , the chromaticities of their pixels lie roughly along a line through the origin of our color space. [sent-82, score-0.593]
</p><p>57 Most chromatic basis functions with relatively high contributions are modulated between light blue and dark yellow, in the plane defined by luminance and S-cone modulation. [sent-83, score-1.071]
</p><p>58 Those with lower L 2 -norm are highly localized, but still are mostly oriented. [sent-84, score-0.048]
</p><p>59 There are other chromatic basis functions with tilted orientations, corresponding to blue versus orange colors. [sent-85, score-0.957]
</p><p>60 The chromaticities of these basis functions occupy mainly the second and fourth quadrant. [sent-86, score-0.487]
</p><p>61 The basis functions with lowest contributions are less strictly aligned in color space, but still tend to be color opponent, mostly along a bluish-green/orange direction. [sent-87, score-1.224]
</p><p>62 There are no basis functions with chromaticities along the horizontal axis, corresponding to pure L versus M cone opponency, like peA basis functions in Figure 2d [9]. [sent-88, score-1.244]
</p><p>63 The tilted orientations of the opponency axes most likely reflects the distribution of the chromaticities in our images. [sent-89, score-0.522]
</p><p>64 In natural images, L-M and S coordinates in our color space are negatively correlated [12]. [sent-90, score-0.501]
</p><p>65 leA finds the directions that correspond to maximally decorrelated signals, i. [sent-91, score-0.043]
</p><p>66 peA did not yield basis functions in these directions, probably because it is limited by the orthogonality constraint. [sent-94, score-0.354]
</p><p>67 While it is known that chromatic properties of neurons in the lateral geniculate nucleus (LGN) of primates correspond to variations along the axes of cone-opponency ('cardinal axes') [11], cortical neurons show sensitivities for intermediate directions [13]. [sent-95, score-0.92]
</p><p>68 3  Discussion  This result shows that the independence criterion alone is sufficient to learn efficient image codes. [sent-97, score-0.124]
</p><p>69 Although no sparseness constraint was used, the obtained coefficients are extremely sparse, i. [sent-98, score-0.069]
</p><p>70 the data x are encoded in the sources s in such a way that the coefficients of s are mostly around zero; there is only a small percentage of informative values (non-zero coefficients). [sent-100, score-0.117]
</p><p>71 From an information coding perspective this assumes that we can encode and decode the chromatic image patches with only a small percentage of the basis functions. [sent-101, score-1.031]
</p><p>72 In contrast, Gaussian densities are not sparsely distributed and a large portion of the basis functions is required to represent the chromatic images. [sent-102, score-0.842]
</p><p>73 The normalized kurtosis value is one measure of sparseness and the average kurtosis value was 19. [sent-103, score-0.082]
</p><p>74 Interestingly the basis functions in Figure2a produced only sparse coefficients except for basis function 7 (green basis function) that resulted in a nearly uniform distribution, suggesting that this basis function is active almost all the time. [sent-106, score-1.21]
</p><p>75 The reason may be that a green color component is present in almost all image patches of the natural scenes. [sent-107, score-0.704]
</p><p>76 The basis functions obtained with the exponential power distributions or the simple Laplacian prior were statistically most efficient. [sent-109, score-0.425]
</p><p>77 In this sense, the basis functions that produce sparse distributions are statistically efficient codes. [sent-110, score-0.537]
</p><p>78 To quantitatively measure the encoding difference we compared the coding efficiency between leA and peA using Shannon's theorem to obtain a lower bound on the number of bits required to encode a spatiochromatic pattern [4]. [sent-111, score-0.306]
</p><p>79 The average number of bits required to encode 40000 patches randomly selected from the 8 images in Figure 1 with a fixed noise coding precision of O' x = 0. [sent-112, score-0.314]
</p><p>80 Note that the encoding difference for achromatic image patches using leA and peA is about 20% in favor of leA [4]. [sent-116, score-0.336]
</p><p>81 The encoding difference in the chromatic case is significantly higher (> 100%) and suggests that there is a large amount of chromatic redundancy in the natural scenes. [sent-117, score-1.201]
</p><p>82 leA was able to further reduce the redundancy between its components, and its basis functions therefore represent more efficient codes. [sent-122, score-0.48]
</p><p>83 In general, the leA results support the argument that basis functions for efficient coding of chromatic natural images are non-orthogonal. [sent-123, score-1.133]
</p><p>84 We used rectangular sensitivities with absorptions between 420 and 480 nm ("S"), 490 and 550 nm ("M"), and 560 and 620 nm ("L"), respectively. [sent-125, score-0.346]
</p><p>85 The resulting basis functions were as strongly color opponent as for the case of overlapping cone sensitivities. [sent-126, score-1.197]
</p><p>86 This suggests that the correlations of radiance values in natural spectra are  (b)  EBEBEEEBEBEBEEEBEEEB EBEBEEEBEEEBEBEBEBEE EErnrnrnEEBJOJOJEEEB EBrnrnrnrnrnEEBJEEEB EBEBEB+ ~ EElEElrnEEl EBEBEB I ~ EElEEEElEB ~ tIJrnEEEE ~ EEEElEflEEl ~B1EElEEl ~ ~ EEEEEEEljEE ~,~ -f. [sent-127, score-0.235]
</p><p>87 The R, G, and B values of the color of each pixel correspond to the relative excitation of L-, M-, and S-cones, respectively. [sent-130, score-0.545]
</p><p>88 (b) Chromaticities of the lCA basis functions, plotted in cone-opponent color space coordinates. [sent-131, score-0.619]
</p><p>89 Each dot represents the coordinate of a pixel of the respective basis function, projected onto the isoluminant plane. [sent-132, score-0.442]
</p><p>90 Luminance can be inferred from the brightness of the dot. [sent-133, score-0.058]
</p><p>91 (c) 147 PCA spatiochromatic basis functions and (d) Corresponding PCA chromaticities. [sent-136, score-0.465]
</p><p>92 sufficiently high to require a color opponent code in order to represent the chromatic structure efficiently. [sent-137, score-1.049]
</p><p>93 In summary, our findings strongly suggest color opponency is not a mere consequence of the overlapping cone spectral sensitivities but moreover an attempt to represent the intrinsic spatiochromatic structure of natural scenes in a statistically efficient manner. [sent-138, score-1.622]
</p><p>94 Emergence of simple-cell receptive field properties by learning a sparse code for natural images. [sent-142, score-0.157]
</p><p>95 The 'independent components' of natural scenes are edge filters. [sent-149, score-0.195]
</p><p>96 Independent component filters of natural images compared with simple cells in primary visual cortex. [sent-155, score-0.257]
</p><p>97 A probablistic framwork for the adaptation and comparison of image codes. [sent-165, score-0.095]
</p><p>98 Statistics of cone responses to natural images: Implications for visual coding. [sent-218, score-0.447]
</p><p>99 Chromaticity diagram showing cone excitation by stimuli of equal luminance. [sent-226, score-0.344]
</p><p>100 Trichromacy, opponent colours coding and optimum colour information transmission in the retina. [sent-256, score-0.222]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('chromatic', 0.488), ('color', 0.366), ('cone', 0.287), ('basis', 0.253), ('opponency', 0.222), ('opponent', 0.16), ('lea', 0.15), ('chromaticities', 0.133), ('sensitivities', 0.133), ('pixel', 0.122), ('luminance', 0.121), ('pea', 0.112), ('achromatic', 0.111), ('spatiochromatic', 0.111), ('patches', 0.105), ('natural', 0.103), ('functions', 0.101), ('axes', 0.095), ('scenes', 0.092), ('macleod', 0.089), ('radiance', 0.089), ('spectral', 0.081), ('receptor', 0.076), ('nm', 0.071), ('statistically', 0.071), ('america', 0.069), ('images', 0.068), ('redundancy', 0.068), ('isoluminant', 0.067), ('image', 0.066), ('ica', 0.065), ('coding', 0.062), ('efficient', 0.058), ('visual', 0.057), ('excitation', 0.057), ('sparse', 0.054), ('encoding', 0.054), ('along', 0.053), ('optical', 0.052), ('patch', 0.048), ('mostly', 0.048), ('bits', 0.048), ('society', 0.044), ('derrington', 0.044), ('ebebeb', 0.044), ('krauskopf', 0.044), ('outdoors', 0.044), ('tilted', 0.044), ('directions', 0.043), ('spectra', 0.043), ('coefficients', 0.043), ('pixels', 0.041), ('localized', 0.039), ('salk', 0.038), ('blue', 0.038), ('eb', 0.038), ('excitations', 0.038), ('geniculate', 0.038), ('sensory', 0.037), ('contributions', 0.037), ('ee', 0.036), ('signals', 0.035), ('human', 0.035), ('variations', 0.035), ('lca', 0.035), ('bristol', 0.035), ('green', 0.035), ('laplacian', 0.035), ('nucleus', 0.035), ('structure', 0.035), ('si', 0.034), ('plane', 0.033), ('findings', 0.033), ('mutual', 0.033), ('versus', 0.033), ('components', 0.033), ('coordinates', 0.032), ('brightness', 0.032), ('ruderman', 0.032), ('representation', 0.031), ('encode', 0.031), ('journal', 0.031), ('pca', 0.03), ('activations', 0.03), ('axis', 0.03), ('horizontal', 0.03), ('overlapping', 0.03), ('representations', 0.029), ('component', 0.029), ('adaptation', 0.029), ('orientations', 0.028), ('rp', 0.028), ('der', 0.028), ('kurtosis', 0.028), ('decreasing', 0.028), ('percentage', 0.026), ('bell', 0.026), ('blind', 0.026), ('sparseness', 0.026), ('inferred', 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="32-tfidf-1" href="./nips-2000-Color_Opponency_Constitutes_a_Sparse_Representation_for_the_Chromatic_Structure_of_Natural_Scenes.html">32 nips-2000-Color Opponency Constitutes a Sparse Representation for the Chromatic Structure of Natural Scenes</a></p>
<p>Author: Te-Won Lee, Thomas Wachtler, Terrence J. Sejnowski</p><p>Abstract: The human visual system encodes the chromatic signals conveyed by the three types of retinal cone photoreceptors in an opponent fashion. This color opponency has been shown to constitute an efficient encoding by spectral decorrelation of the receptor signals. We analyze the spatial and chromatic structure of natural scenes by decomposing the spectral images into a set of linear basis functions such that they constitute a representation with minimal redundancy. Independent component analysis finds the basis functions that transforms the spatiochromatic data such that the outputs (activations) are statistically as independent as possible, i.e. least redundant. The resulting basis functions show strong opponency along an achromatic direction (luminance edges), along a blueyellow direction, and along a red-blue direction. Furthermore, the resulting activations have very sparse distributions, suggesting that the use of color opponency in the human visual system achieves a highly efficient representation of colors. Our findings suggest that color opponency is a result of the properties of natural spectra and not solely a consequence of the overlapping cone spectral sensitivities. 1 Statistical structure of natural scenes Efficient encoding of visual sensory information is an important task for information processing systems and its study may provide insights into coding principles of biological visual systems. An important goal of sensory information processing Electronic version available at www. cnl. salk . edu/</p><p>2 0.16352159 <a title="32-tfidf-2" href="./nips-2000-Emergence_of_Movement_Sensitive_Neurons%27_Properties_by_Learning_a_Sparse_Code_for_Natural_Moving_Images.html">45 nips-2000-Emergence of Movement Sensitive Neurons' Properties by Learning a Sparse Code for Natural Moving Images</a></p>
<p>Author: Rafal Bogacz, Malcolm W. Brown, Christophe G. Giraud-Carrier</p><p>Abstract: Olshausen & Field demonstrated that a learning algorithm that attempts to generate a sparse code for natural scenes develops a complete family of localised, oriented, bandpass receptive fields, similar to those of 'simple cells' in VI. This paper describes an algorithm which finds a sparse code for sequences of images that preserves information about the input. This algorithm when trained on natural video sequences develops bases representing the movement in particular directions with particular speeds, similar to the receptive fields of the movement-sensitive cells observed in cortical visual areas. Furthermore, in contrast to previous approaches to learning direction selectivity, the timing of neuronal activity encodes the phase of the movement, so the precise timing of spikes is crucially important to the information encoding.</p><p>3 0.16330032 <a title="32-tfidf-3" href="./nips-2000-A_Comparison_of_Image_Processing_Techniques_for_Visual_Speech_Recognition_Applications.html">2 nips-2000-A Comparison of Image Processing Techniques for Visual Speech Recognition Applications</a></p>
<p>Author: Michael S. Gray, Terrence J. Sejnowski, Javier R. Movellan</p><p>Abstract: We examine eight different techniques for developing visual representations in machine vision tasks. In particular we compare different versions of principal component and independent component analysis in combination with stepwise regression methods for variable selection. We found that local methods, based on the statistics of image patches, consistently outperformed global methods based on the statistics of entire images. This result is consistent with previous work on emotion and facial expression recognition. In addition, the use of a stepwise regression technique for selecting variables and regions of interest substantially boosted performance. 1</p><p>4 0.093669116 <a title="32-tfidf-4" href="./nips-2000-Higher-Order_Statistical_Properties_Arising_from_the_Non-Stationarity_of_Natural_Signals.html">65 nips-2000-Higher-Order Statistical Properties Arising from the Non-Stationarity of Natural Signals</a></p>
<p>Author: Lucas C. Parra, Clay Spence, Paul Sajda</p><p>Abstract: We present evidence that several higher-order statistical properties of natural images and signals can be explained by a stochastic model which simply varies scale of an otherwise stationary Gaussian process. We discuss two interesting consequences. The first is that a variety of natural signals can be related through a common model of spherically invariant random processes, which have the attractive property that the joint densities can be constructed from the one dimensional marginal. The second is that in some cases the non-stationarity assumption and only second order methods can be explicitly exploited to find a linear basis that is equivalent to independent components obtained with higher-order methods. This is demonstrated on spectro-temporal components of speech. 1</p><p>5 0.082160458 <a title="32-tfidf-5" href="./nips-2000-Natural_Sound_Statistics_and_Divisive_Normalization_in_the_Auditory_System.html">89 nips-2000-Natural Sound Statistics and Divisive Normalization in the Auditory System</a></p>
<p>Author: Odelia Schwartz, Eero P. Simoncelli</p><p>Abstract: We explore the statistical properties of natural sound stimuli preprocessed with a bank of linear filters. The responses of such filters exhibit a striking form of statistical dependency, in which the response variance of each filter grows with the response amplitude of filters tuned for nearby frequencies. These dependencies may be substantially reduced using an operation known as divisive normalization, in which the response of each filter is divided by a weighted sum of the rectified responses of other filters. The weights may be chosen to maximize the independence of the normalized responses for an ensemble of natural sounds. We demonstrate that the resulting model accounts for nonlinearities in the response characteristics of the auditory nerve, by comparing model simulations to electrophysiological recordings. In previous work (NIPS, 1998) we demonstrated that an analogous model derived from the statistics of natural images accounts for non-linear properties of neurons in primary visual cortex. Thus, divisive normalization appears to be a generic mechanism for eliminating a type of statistical dependency that is prevalent in natural signals of different modalities. Signals in the real world are highly structured. For example, natural sounds typically contain both harmonic and rythmic structure. It is reasonable to assume that biological auditory systems are designed to represent these structures in an efficient manner [e.g., 1,2]. Specifically, Barlow hypothesized that a role of early sensory processing is to remove redundancy in the sensory input, resulting in a set of neural responses that are statistically independent. Experimentally, one can test this hypothesis by examining the statistical properties of neural responses under natural stimulation conditions [e.g., 3,4], or the statistical dependency of pairs (or groups) of neural responses. Due to their technical difficulty, such multi-cellular experiments are only recently becoming possible, and the earliest reports in vision appear consistent with the hypothesis [e.g., 5]. An alternative approach, which we follow here, is to develop a neural model from the statistics of natural signals and show that response properties of this model are similar to those of biological sensory neurons. A number of researchers have derived linear filter models using statistical criterion. For visual images, this results in linear filters localized in frequency, orientation and phase [6, 7]. Similar work in audition has yielded filters localized in frequency and phase [8]. Although these linear models provide an important starting point for neural modeling, sensory neurons are highly nonlinear. In addition, the statistical properties of natural signals are too complex to expect a linear transformation to result in an independent set of components. Recent results indicate that nonlinear gain control plays an important role in neural processing. Ruderman and Bialek [9] have shown that division by a local estimate of standard deviation can increase the entropy of responses of center-surround filters to natural images. Such a model is consistent with the properties of neurons in the retina and lateral geniculate nucleus. Heeger and colleagues have shown that the nonlinear behaviors of neurons in primary visual cortex may be described using a form of gain control known as divisive normalization [10], in which the response of a linear kernel is rectified and divided by the sum of other rectified kernel responses and a constant. We have recently shown that the responses of oriented linear filters exhibit nonlinear statistical dependencies that may be substantially reduced using a variant of this model, in which the normalization signal is computed from a weighted sum of other rectified kernel responses [11, 12]. The resulting model, with weighting parameters determined from image statistics, accounts qualitatively for physiological nonlinearities observed in primary visual cortex. In this paper, we demonstrate that the responses of bandpass linear filters to natural sounds exhibit striking statistical dependencies, analogous to those found in visual images. A divisive normalization procedure can substantially remove these dependencies. We show that this model, with parameters optimized for a collection of natural sounds, can account for nonlinear behaviors of neurons at the level of the auditory nerve. Specifically, we show that: 1) the shape offrequency tuning curves varies with sound pressure level, even though the underlying linear filters are fixed; and 2) superposition of a non-optimal tone suppresses the response of a linear filter in a divisive fashion, and the amount of suppression depends on the distance between the frequency of the tone and the preferred frequency of the filter. 1 Empirical observations of natural sound statistics The basic statistical properties of natural sounds, as observed through a linear filter, have been previously documented by Attias [13]. In particular, he showed that, as with visual images, the spectral energy falls roughly according to a power law, and that the histograms of filter responses are more kurtotic than a Gaussian (i.e., they have a sharp peak at zero, and very long tails). Here we examine the joint statistical properties of a pair of linear filters tuned for nearby temporal frequencies. We choose a fixed set of filters that have been widely used in modeling the peripheral auditory system [14]. Figure 1 shows joint histograms of the instantaneous responses of a particular pair of linear filters to five different types of natural sound, and white noise. First note that the responses are approximately decorrelated: the expected value of the y-axis value is roughly zero for all values of the x-axis variable. The responses are not, however, statistically independent: the width of the distribution of responses of one filter increases with the response amplitude of the other filter. If the two responses were statistically independent, then the response of the first filter should not provide any information about the distribution of responses of the other filter. We have found that this type of variance dependency (sometimes accompanied by linear correlation) occurs in a wide range of natural sounds, ranging from animal sounds to music. We emphasize that this dependency is a property of natural sounds, and is not due purely to our choice of linear filters. For example, no such dependency is observed when the input consists of white noise (see Fig. 1). The strength of this dependency varies for different pairs of linear filters . In addition, we see this type of dependency between instantaneous responses of a single filter at two Speech o -1 Drums • Monkey Cat White noise Nocturnal nature I~ ~; ~ • Figure 1: Joint conditional histogram of instantaneous linear responses of two bandpass filters with center frequencies 2000 and 2840 Hz. Pixel intensity corresponds to frequency of occurrence of a given pair of values, except that each column has been independently rescaled to fill the full intensity range. For the natural sounds, responses are not independent: the standard deviation of the ordinate is roughly proportional to the magnitude of the abscissa. Natural sounds were recorded from CDs and converted to sampling frequency of 22050 Hz. nearby time instants. Since the dependency involves the variance of the responses, we can substantially reduce it by dividing. In particular, the response of each filter is divided by a weighted sum of responses of other rectified filters and an additive constant. Specifically: L2 Ri = 2: (1) 12 j WjiLj + 0'2 where Li is the instantaneous linear response of filter i, strength of suppression of filter i by filter j. 0' is a constant and Wji controls the We would like to choose the parameters of the model (the weights Wji, and the constant 0') to optimize the independence of the normalized response to an ensemble of natural sounds. Such an optimization is quite computationally expensive. We instead assume a Gaussian form for the underlying conditional distribution, as described in [15]: P (LiILj,j E Ni ) '</p><p>6 0.069529794 <a title="32-tfidf-6" href="./nips-2000-Bayes_Networks_on_Ice%3A_Robotic_Search_for_Antarctic_Meteorites.html">29 nips-2000-Bayes Networks on Ice: Robotic Search for Antarctic Meteorites</a></p>
<p>7 0.06876111 <a title="32-tfidf-7" href="./nips-2000-The_Manhattan_World_Assumption%3A_Regularities_in_Scene_Statistics_which_Enable_Bayesian_Inference.html">135 nips-2000-The Manhattan World Assumption: Regularities in Scene Statistics which Enable Bayesian Inference</a></p>
<p>8 0.068093419 <a title="32-tfidf-8" href="./nips-2000-Redundancy_and_Dimensionality_Reduction_in_Sparse-Distributed_Representations_of_Natural_Objects_in_Terms_of_Their_Local_Features.html">109 nips-2000-Redundancy and Dimensionality Reduction in Sparse-Distributed Representations of Natural Objects in Terms of Their Local Features</a></p>
<p>9 0.068076536 <a title="32-tfidf-9" href="./nips-2000-From_Mixtures_of_Mixtures_to_Adaptive_Transform_Coding.html">59 nips-2000-From Mixtures of Mixtures to Adaptive Transform Coding</a></p>
<p>10 0.067573145 <a title="32-tfidf-10" href="./nips-2000-Learning_Joint_Statistical_Models_for_Audio-Visual_Fusion_and_Segregation.html">78 nips-2000-Learning Joint Statistical Models for Audio-Visual Fusion and Segregation</a></p>
<p>11 0.067426153 <a title="32-tfidf-11" href="./nips-2000-Sparse_Kernel_Principal_Component_Analysis.html">121 nips-2000-Sparse Kernel Principal Component Analysis</a></p>
<p>12 0.066737719 <a title="32-tfidf-12" href="./nips-2000-Rate-coded_Restricted_Boltzmann_Machines_for_Face_Recognition.html">107 nips-2000-Rate-coded Restricted Boltzmann Machines for Face Recognition</a></p>
<p>13 0.066644855 <a title="32-tfidf-13" href="./nips-2000-Sparse_Greedy_Gaussian_Process_Regression.html">120 nips-2000-Sparse Greedy Gaussian Process Regression</a></p>
<p>14 0.066312127 <a title="32-tfidf-14" href="./nips-2000-Place_Cells_and_Spatial_Navigation_Based_on_2D_Visual_Feature_Extraction%2C_Path_Integration%2C_and_Reinforcement_Learning.html">101 nips-2000-Place Cells and Spatial Navigation Based on 2D Visual Feature Extraction, Path Integration, and Reinforcement Learning</a></p>
<p>15 0.065572314 <a title="32-tfidf-15" href="./nips-2000-A_New_Model_of_Spatial_Representation_in_Multimodal_Brain_Areas.html">8 nips-2000-A New Model of Spatial Representation in Multimodal Brain Areas</a></p>
<p>16 0.063869022 <a title="32-tfidf-16" href="./nips-2000-Adaptive_Object_Representation_with_Hierarchically-Distributed_Memory_Sites.html">19 nips-2000-Adaptive Object Representation with Hierarchically-Distributed Memory Sites</a></p>
<p>17 0.06202006 <a title="32-tfidf-17" href="./nips-2000-A_Productive%2C_Systematic_Framework_for_the_Representation_of_Visual_Structure.html">10 nips-2000-A Productive, Systematic Framework for the Representation of Visual Structure</a></p>
<p>18 0.061540294 <a title="32-tfidf-18" href="./nips-2000-Combining_ICA_and_Top-Down_Attention_for_Robust_Speech_Recognition.html">33 nips-2000-Combining ICA and Top-Down Attention for Robust Speech Recognition</a></p>
<p>19 0.05687486 <a title="32-tfidf-19" href="./nips-2000-Multiple_Timescales_of_Adaptation_in_a_Neural_Code.html">88 nips-2000-Multiple Timescales of Adaptation in a Neural Code</a></p>
<p>20 0.055658385 <a title="32-tfidf-20" href="./nips-2000-Generalizable_Singular_Value_Decomposition_for_Ill-posed_Datasets.html">61 nips-2000-Generalizable Singular Value Decomposition for Ill-posed Datasets</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2000_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.174), (1, -0.11), (2, 0.03), (3, 0.154), (4, -0.05), (5, 0.052), (6, 0.099), (7, -0.089), (8, 0.083), (9, -0.063), (10, -0.182), (11, -0.062), (12, -0.078), (13, 0.027), (14, -0.192), (15, 0.071), (16, -0.121), (17, 0.093), (18, -0.127), (19, -0.044), (20, -0.036), (21, -0.152), (22, -0.024), (23, -0.076), (24, 0.083), (25, -0.01), (26, 0.006), (27, -0.056), (28, 0.016), (29, -0.052), (30, 0.071), (31, -0.007), (32, 0.025), (33, -0.034), (34, -0.008), (35, 0.189), (36, -0.006), (37, 0.074), (38, 0.042), (39, 0.101), (40, -0.067), (41, -0.115), (42, 0.012), (43, 0.145), (44, -0.019), (45, -0.157), (46, 0.094), (47, -0.065), (48, 0.027), (49, -0.059)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97108859 <a title="32-lsi-1" href="./nips-2000-Color_Opponency_Constitutes_a_Sparse_Representation_for_the_Chromatic_Structure_of_Natural_Scenes.html">32 nips-2000-Color Opponency Constitutes a Sparse Representation for the Chromatic Structure of Natural Scenes</a></p>
<p>Author: Te-Won Lee, Thomas Wachtler, Terrence J. Sejnowski</p><p>Abstract: The human visual system encodes the chromatic signals conveyed by the three types of retinal cone photoreceptors in an opponent fashion. This color opponency has been shown to constitute an efficient encoding by spectral decorrelation of the receptor signals. We analyze the spatial and chromatic structure of natural scenes by decomposing the spectral images into a set of linear basis functions such that they constitute a representation with minimal redundancy. Independent component analysis finds the basis functions that transforms the spatiochromatic data such that the outputs (activations) are statistically as independent as possible, i.e. least redundant. The resulting basis functions show strong opponency along an achromatic direction (luminance edges), along a blueyellow direction, and along a red-blue direction. Furthermore, the resulting activations have very sparse distributions, suggesting that the use of color opponency in the human visual system achieves a highly efficient representation of colors. Our findings suggest that color opponency is a result of the properties of natural spectra and not solely a consequence of the overlapping cone spectral sensitivities. 1 Statistical structure of natural scenes Efficient encoding of visual sensory information is an important task for information processing systems and its study may provide insights into coding principles of biological visual systems. An important goal of sensory information processing Electronic version available at www. cnl. salk . edu/</p><p>2 0.75664818 <a title="32-lsi-2" href="./nips-2000-Emergence_of_Movement_Sensitive_Neurons%27_Properties_by_Learning_a_Sparse_Code_for_Natural_Moving_Images.html">45 nips-2000-Emergence of Movement Sensitive Neurons' Properties by Learning a Sparse Code for Natural Moving Images</a></p>
<p>Author: Rafal Bogacz, Malcolm W. Brown, Christophe G. Giraud-Carrier</p><p>Abstract: Olshausen & Field demonstrated that a learning algorithm that attempts to generate a sparse code for natural scenes develops a complete family of localised, oriented, bandpass receptive fields, similar to those of 'simple cells' in VI. This paper describes an algorithm which finds a sparse code for sequences of images that preserves information about the input. This algorithm when trained on natural video sequences develops bases representing the movement in particular directions with particular speeds, similar to the receptive fields of the movement-sensitive cells observed in cortical visual areas. Furthermore, in contrast to previous approaches to learning direction selectivity, the timing of neuronal activity encodes the phase of the movement, so the precise timing of spikes is crucially important to the information encoding.</p><p>3 0.68772 <a title="32-lsi-3" href="./nips-2000-A_Comparison_of_Image_Processing_Techniques_for_Visual_Speech_Recognition_Applications.html">2 nips-2000-A Comparison of Image Processing Techniques for Visual Speech Recognition Applications</a></p>
<p>Author: Michael S. Gray, Terrence J. Sejnowski, Javier R. Movellan</p><p>Abstract: We examine eight different techniques for developing visual representations in machine vision tasks. In particular we compare different versions of principal component and independent component analysis in combination with stepwise regression methods for variable selection. We found that local methods, based on the statistics of image patches, consistently outperformed global methods based on the statistics of entire images. This result is consistent with previous work on emotion and facial expression recognition. In addition, the use of a stepwise regression technique for selecting variables and regions of interest substantially boosted performance. 1</p><p>4 0.50634784 <a title="32-lsi-4" href="./nips-2000-Redundancy_and_Dimensionality_Reduction_in_Sparse-Distributed_Representations_of_Natural_Objects_in_Terms_of_Their_Local_Features.html">109 nips-2000-Redundancy and Dimensionality Reduction in Sparse-Distributed Representations of Natural Objects in Terms of Their Local Features</a></p>
<p>Author: Penio S. Penev</p><p>Abstract: Low-dimensional representations are key to solving problems in highlevel vision, such as face compression and recognition. Factorial coding strategies for reducing the redundancy present in natural images on the basis of their second-order statistics have been successful in accounting for both psychophysical and neurophysiological properties of early vision. Class-specific representations are presumably formed later, at the higher-level stages of cortical processing. Here we show that when retinotopic factorial codes are derived for ensembles of natural objects, such as human faces, not only redundancy, but also dimensionality is reduced. We also show that objects are built from parts in a non-Gaussian fashion which allows these local-feature codes to have dimensionalities that are substantially lower than the respective Nyquist sampling rates.</p><p>5 0.4734607 <a title="32-lsi-5" href="./nips-2000-The_Manhattan_World_Assumption%3A_Regularities_in_Scene_Statistics_which_Enable_Bayesian_Inference.html">135 nips-2000-The Manhattan World Assumption: Regularities in Scene Statistics which Enable Bayesian Inference</a></p>
<p>Author: James M. Coughlan, Alan L. Yuille</p><p>Abstract: Preliminary work by the authors made use of the so-called</p><p>6 0.41774094 <a title="32-lsi-6" href="./nips-2000-Bayes_Networks_on_Ice%3A_Robotic_Search_for_Antarctic_Meteorites.html">29 nips-2000-Bayes Networks on Ice: Robotic Search for Antarctic Meteorites</a></p>
<p>7 0.40580571 <a title="32-lsi-7" href="./nips-2000-Higher-Order_Statistical_Properties_Arising_from_the_Non-Stationarity_of_Natural_Signals.html">65 nips-2000-Higher-Order Statistical Properties Arising from the Non-Stationarity of Natural Signals</a></p>
<p>8 0.37723643 <a title="32-lsi-8" href="./nips-2000-Natural_Sound_Statistics_and_Divisive_Normalization_in_the_Auditory_System.html">89 nips-2000-Natural Sound Statistics and Divisive Normalization in the Auditory System</a></p>
<p>9 0.31203148 <a title="32-lsi-9" href="./nips-2000-From_Mixtures_of_Mixtures_to_Adaptive_Transform_Coding.html">59 nips-2000-From Mixtures of Mixtures to Adaptive Transform Coding</a></p>
<p>10 0.29230821 <a title="32-lsi-10" href="./nips-2000-Learning_Segmentation_by_Random_Walks.html">79 nips-2000-Learning Segmentation by Random Walks</a></p>
<p>11 0.275399 <a title="32-lsi-11" href="./nips-2000-Divisive_and_Subtractive_Mask_Effects%3A_Linking_Psychophysics_and_Biophysics.html">42 nips-2000-Divisive and Subtractive Mask Effects: Linking Psychophysics and Biophysics</a></p>
<p>12 0.27451128 <a title="32-lsi-12" href="./nips-2000-Place_Cells_and_Spatial_Navigation_Based_on_2D_Visual_Feature_Extraction%2C_Path_Integration%2C_and_Reinforcement_Learning.html">101 nips-2000-Place Cells and Spatial Navigation Based on 2D Visual Feature Extraction, Path Integration, and Reinforcement Learning</a></p>
<p>13 0.26375994 <a title="32-lsi-13" href="./nips-2000-Rate-coded_Restricted_Boltzmann_Machines_for_Face_Recognition.html">107 nips-2000-Rate-coded Restricted Boltzmann Machines for Face Recognition</a></p>
<p>14 0.26302236 <a title="32-lsi-14" href="./nips-2000-Who_Does_What%3F_A_Novel_Algorithm_to_Determine_Function_Localization.html">147 nips-2000-Who Does What? A Novel Algorithm to Determine Function Localization</a></p>
<p>15 0.26061186 <a title="32-lsi-15" href="./nips-2000-Generalizable_Singular_Value_Decomposition_for_Ill-posed_Datasets.html">61 nips-2000-Generalizable Singular Value Decomposition for Ill-posed Datasets</a></p>
<p>16 0.25678307 <a title="32-lsi-16" href="./nips-2000-Sparse_Greedy_Gaussian_Process_Regression.html">120 nips-2000-Sparse Greedy Gaussian Process Regression</a></p>
<p>17 0.25420675 <a title="32-lsi-17" href="./nips-2000-Combining_ICA_and_Top-Down_Attention_for_Robust_Speech_Recognition.html">33 nips-2000-Combining ICA and Top-Down Attention for Robust Speech Recognition</a></p>
<p>18 0.24690075 <a title="32-lsi-18" href="./nips-2000-Ensemble_Learning_and_Linear_Response_Theory_for_ICA.html">46 nips-2000-Ensemble Learning and Linear Response Theory for ICA</a></p>
<p>19 0.22569267 <a title="32-lsi-19" href="./nips-2000-Constrained_Independent_Component_Analysis.html">36 nips-2000-Constrained Independent Component Analysis</a></p>
<p>20 0.22212271 <a title="32-lsi-20" href="./nips-2000-Bayesian_Video_Shot_Segmentation.html">30 nips-2000-Bayesian Video Shot Segmentation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2000_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.01), (4, 0.013), (6, 0.014), (10, 0.014), (17, 0.577), (33, 0.036), (42, 0.015), (55, 0.034), (62, 0.018), (65, 0.029), (67, 0.041), (76, 0.019), (79, 0.019), (81, 0.021), (90, 0.019), (91, 0.015), (97, 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99593395 <a title="32-lda-1" href="./nips-2000-Color_Opponency_Constitutes_a_Sparse_Representation_for_the_Chromatic_Structure_of_Natural_Scenes.html">32 nips-2000-Color Opponency Constitutes a Sparse Representation for the Chromatic Structure of Natural Scenes</a></p>
<p>Author: Te-Won Lee, Thomas Wachtler, Terrence J. Sejnowski</p><p>Abstract: The human visual system encodes the chromatic signals conveyed by the three types of retinal cone photoreceptors in an opponent fashion. This color opponency has been shown to constitute an efficient encoding by spectral decorrelation of the receptor signals. We analyze the spatial and chromatic structure of natural scenes by decomposing the spectral images into a set of linear basis functions such that they constitute a representation with minimal redundancy. Independent component analysis finds the basis functions that transforms the spatiochromatic data such that the outputs (activations) are statistically as independent as possible, i.e. least redundant. The resulting basis functions show strong opponency along an achromatic direction (luminance edges), along a blueyellow direction, and along a red-blue direction. Furthermore, the resulting activations have very sparse distributions, suggesting that the use of color opponency in the human visual system achieves a highly efficient representation of colors. Our findings suggest that color opponency is a result of the properties of natural spectra and not solely a consequence of the overlapping cone spectral sensitivities. 1 Statistical structure of natural scenes Efficient encoding of visual sensory information is an important task for information processing systems and its study may provide insights into coding principles of biological visual systems. An important goal of sensory information processing Electronic version available at www. cnl. salk . edu/</p><p>2 0.99545789 <a title="32-lda-2" href="./nips-2000-The_Manhattan_World_Assumption%3A_Regularities_in_Scene_Statistics_which_Enable_Bayesian_Inference.html">135 nips-2000-The Manhattan World Assumption: Regularities in Scene Statistics which Enable Bayesian Inference</a></p>
<p>Author: James M. Coughlan, Alan L. Yuille</p><p>Abstract: Preliminary work by the authors made use of the so-called</p><p>3 0.99339771 <a title="32-lda-3" href="./nips-2000-Sparse_Kernel_Principal_Component_Analysis.html">121 nips-2000-Sparse Kernel Principal Component Analysis</a></p>
<p>Author: Michael E. Tipping</p><p>Abstract: 'Kernel' principal component analysis (PCA) is an elegant nonlinear generalisation of the popular linear data analysis method, where a kernel function implicitly defines a nonlinear transformation into a feature space wherein standard PCA is performed. Unfortunately, the technique is not 'sparse', since the components thus obtained are expressed in terms of kernels associated with every training vector. This paper shows that by approximating the covariance matrix in feature space by a reduced number of example vectors, using a maximum-likelihood approach, we may obtain a highly sparse form of kernel PCA without loss of effectiveness. 1</p><p>4 0.99222642 <a title="32-lda-4" href="./nips-2000-Foundations_for_a_Circuit_Complexity_Theory_of_Sensory_Processing.html">56 nips-2000-Foundations for a Circuit Complexity Theory of Sensory Processing</a></p>
<p>Author: Robert A. Legenstein, Wolfgang Maass</p><p>Abstract: We introduce total wire length as salient complexity measure for an analysis of the circuit complexity of sensory processing in biological neural systems and neuromorphic engineering. This new complexity measure is applied to a set of basic computational problems that apparently need to be solved by circuits for translation- and scale-invariant sensory processing. We exhibit new circuit design strategies for these new benchmark functions that can be implemented within realistic complexity bounds, in particular with linear or almost linear total wire length.</p><p>5 0.99058098 <a title="32-lda-5" href="./nips-2000-Feature_Selection_for_SVMs.html">54 nips-2000-Feature Selection for SVMs</a></p>
<p>Author: Jason Weston, Sayan Mukherjee, Olivier Chapelle, Massimiliano Pontil, Tomaso Poggio, Vladimir Vapnik</p><p>Abstract: We introduce a method of feature selection for Support Vector Machines. The method is based upon finding those features which minimize bounds on the leave-one-out error. This search can be efficiently performed via gradient descent. The resulting algorithms are shown to be superior to some standard feature selection algorithms on both toy data and real-life problems of face recognition, pedestrian detection and analyzing DNA micro array data.</p><p>6 0.93568641 <a title="32-lda-6" href="./nips-2000-A_Comparison_of_Image_Processing_Techniques_for_Visual_Speech_Recognition_Applications.html">2 nips-2000-A Comparison of Image Processing Techniques for Visual Speech Recognition Applications</a></p>
<p>7 0.861435 <a title="32-lda-7" href="./nips-2000-Rate-coded_Restricted_Boltzmann_Machines_for_Face_Recognition.html">107 nips-2000-Rate-coded Restricted Boltzmann Machines for Face Recognition</a></p>
<p>8 0.85898232 <a title="32-lda-8" href="./nips-2000-Text_Classification_using_String_Kernels.html">130 nips-2000-Text Classification using String Kernels</a></p>
<p>9 0.83615971 <a title="32-lda-9" href="./nips-2000-Emergence_of_Movement_Sensitive_Neurons%27_Properties_by_Learning_a_Sparse_Code_for_Natural_Moving_Images.html">45 nips-2000-Emergence of Movement Sensitive Neurons' Properties by Learning a Sparse Code for Natural Moving Images</a></p>
<p>10 0.83097577 <a title="32-lda-10" href="./nips-2000-A_Mathematical_Programming_Approach_to_the_Kernel_Fisher_Algorithm.html">5 nips-2000-A Mathematical Programming Approach to the Kernel Fisher Algorithm</a></p>
<p>11 0.82662654 <a title="32-lda-11" href="./nips-2000-A_Linear_Programming_Approach_to_Novelty_Detection.html">4 nips-2000-A Linear Programming Approach to Novelty Detection</a></p>
<p>12 0.82402247 <a title="32-lda-12" href="./nips-2000-On_a_Connection_between_Kernel_PCA_and_Metric_Multidimensional_Scaling.html">95 nips-2000-On a Connection between Kernel PCA and Metric Multidimensional Scaling</a></p>
<p>13 0.81780046 <a title="32-lda-13" href="./nips-2000-The_Kernel_Gibbs_Sampler.html">133 nips-2000-The Kernel Gibbs Sampler</a></p>
<p>14 0.81644225 <a title="32-lda-14" href="./nips-2000-Factored_Semi-Tied_Covariance_Matrices.html">51 nips-2000-Factored Semi-Tied Covariance Matrices</a></p>
<p>15 0.81298399 <a title="32-lda-15" href="./nips-2000-Learning_and_Tracking_Cyclic_Human_Motion.html">82 nips-2000-Learning and Tracking Cyclic Human Motion</a></p>
<p>16 0.80713475 <a title="32-lda-16" href="./nips-2000-Smart_Vision_Chip_Fabricated_Using_Three_Dimensional_Integration_Technology.html">118 nips-2000-Smart Vision Chip Fabricated Using Three Dimensional Integration Technology</a></p>
<p>17 0.80488139 <a title="32-lda-17" href="./nips-2000-Constrained_Independent_Component_Analysis.html">36 nips-2000-Constrained Independent Component Analysis</a></p>
<p>18 0.80368227 <a title="32-lda-18" href="./nips-2000-Generalizable_Singular_Value_Decomposition_for_Ill-posed_Datasets.html">61 nips-2000-Generalizable Singular Value Decomposition for Ill-posed Datasets</a></p>
<p>19 0.79957056 <a title="32-lda-19" href="./nips-2000-Minimum_Bayes_Error_Feature_Selection_for_Continuous_Speech_Recognition.html">84 nips-2000-Minimum Bayes Error Feature Selection for Continuous Speech Recognition</a></p>
<p>20 0.79809558 <a title="32-lda-20" href="./nips-2000-Gaussianization.html">60 nips-2000-Gaussianization</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
