<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>10 nips-2000-A Productive, Systematic Framework for the Representation of Visual Structure</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2000" href="../home/nips2000_home.html">nips2000</a> <a title="nips-2000-10" href="#">nips2000-10</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>10 nips-2000-A Productive, Systematic Framework for the Representation of Visual Structure</h1>
<br/><p>Source: <a title="nips-2000-10-pdf" href="http://papers.nips.cc/paper/1827-a-productive-systematic-framework-for-the-representation-of-visual-structure.pdf">pdf</a></p><p>Author: Shimon Edelman, Nathan Intrator</p><p>Abstract: We describe a unified framework for the understanding of structure representation in primate vision. A model derived from this framework is shown to be effectively systematic in that it has the ability to interpret and associate together objects that are related through a rearrangement of common</p><p>Reference: <a title="nips-2000-10-reference" href="../nips2000_reference/nips-2000-A_Productive%2C_Systematic_Framework_for_the_Representation_of_Visual_Structure_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 A productive, systematic framework for the representation of visual structure  Shimon Edelman 232 Uris Hall, Dept. [sent-1, score-0.478]
</p><p>2 edu  Abstract We describe a unified framework for the understanding of structure representation in primate vision. [sent-4, score-0.304]
</p><p>3 A model derived from this framework is shown to be effectively systematic in that it has the ability to interpret and associate together objects that are related through a rearrangement of common "middle-scale" parts, represented as image fragments. [sent-5, score-0.373]
</p><p>4 The model addresses the same concerns as previous work on compositional representation through the use of what+where receptive fields and attentional gain modulation. [sent-6, score-0.543]
</p><p>5 It does not require prior exposure to the individual parts, and avoids the need for abstract symbolic binding. [sent-7, score-0.061]
</p><p>6 1  The problem of structure representation  The focus of theoretical discussion in visual object processing has recently started to shift from problems of recognition and categorization to the representation of object structure. [sent-8, score-0.985]
</p><p>7 Although view- or appearance-based solutions for these problems proved effective on a variety of object classes [1], the "holistic" nature of this approach - the lack of explicit representation of relational structure - limits its appeal as a general framework for visual representation [2]. [sent-9, score-0.742]
</p><p>8 The main challenges in the processing of structure are productivity and systematicity, two traits commonly attributed to human cognition. [sent-10, score-0.225]
</p><p>9 A visual system is productive if it is open-ended, that is, if it can deal effectively with a potentially infinite set of objects. [sent-11, score-0.33]
</p><p>10 A visual representation is systematic if a well-defined change in the spatial configuration of the object (e. [sent-12, score-0.704]
</p><p>11 , swapping top and bottom parts) causes a principled change in the representation (e. [sent-14, score-0.228]
</p><p>12 , the interchange of the representations of top and bottom parts [3, 2]). [sent-16, score-0.206]
</p><p>13 A solution commonly offered to the twin problems of productivity and systematicity is compositional representation, in which symbols standing for generic parts drawn from a small repertoire are bound together by categorical symbolically coded relations [4]. [sent-17, score-0.465]
</p><p>14 2  The Chorus of Fragments  In visual representation, the need for symbolic binding may be alleviated by using location in the visual field in lieu of the abstract frame that encodes object structure. [sent-18, score-0.9]
</p><p>15 Intuitively, the constituents of the object are then bound to each other by virtue of residing in their proper places in the visual field; this can be thought of as a pegboard, whose spatial structure supports the arrangement of parts suspended from its pegs. [sent-19, score-0.769]
</p><p>16 This scheme exhibits shallow compositionality, which can be enhanced by allowing the "pegboard" mechanism to operate at different spatial scales, yielding effective systematicity across levels of resolution. [sent-20, score-0.287]
</p><p>17 , representing each object fragment in terms of its similarities to some basis shapes) will render the scheme productive. [sent-23, score-0.311]
</p><p>18 We call this approach to the representation of structure the Chorus of Fragments (CoF; [5]). [sent-24, score-0.189]
</p><p>19 The representation of spatially anchored object fragments postulated by the CoF model can be supported by what+where neurons, each tuned both to a certain shape class and to a certain range of locations in the visual field. [sent-27, score-1.052]
</p><p>20 Such cells have been found in the monkey in areas V4 and posterior IT [6], and in the prefrontal cortex [7]. [sent-28, score-0.173]
</p><p>21 Indeed, modulatory effects of object-centered attention on classical RF structure (gain fields) have been found in area V4 [8]. [sent-31, score-0.215]
</p><p>22 2  Implemented model  Our implementation of the CoF model involves what+where cells with attentionmodulated gain fields, and is aimed at productive and systematic treatment of composite shapes in object-centered coordinates. [sent-33, score-0.888]
</p><p>23 It operates directly on gray-level images, pre-processed by a model of the primary visual cortex [9], with complexcell responses modified to use the MAX operation suggested in [10]. [sent-34, score-0.26]
</p><p>24 In the model, one what+where unit is assigned to the top and one to the bottom fragment of the visual field, each extracted by an appropriately configured Gaussian gain profile (Figure 2, left). [sent-35, score-0.541]
</p><p>25 The units are trained (1) to discriminate among five objects, (2) to tolerate translation within the hemifield, and (3) to provide an estimate of the reliability of its output, through an autoassociation mechanism attempting to reconstruct the stimulus image [11, 12]. [sent-36, score-0.34]
</p><p>26 Within each hemifield, the five outputs of a unit can provide a coarse coding of novel objects belonging to the familiar category, in a manner useful for translation-tolerant recognition [13]. [sent-37, score-0.431]
</p><p>27 The reliability estimate carries information about category, allowing outputs for objects from other categories to be squelched. [sent-38, score-0.195]
</p><p>28 Most importantly, due to the spatial localization of the unit's receptive field, the system can distinguish between different configurations of the same shapes, while noting the fragment-wise similarities. [sent-39, score-0.173]
</p><p>29 We assume that during learning the system performs multiple fixations of the target object, effectively providing the what+where units with a basis for spanning the  o "1 above center"  I  I  L_ ----  Wld~~~~~~. [sent-40, score-0.151]
</p><p>30 j  , "1 below center"  where l  "9"  "something below center"  Figure 1: Left: the CoF model conceptualized as a "computation cube" trained to distinguish among three fragments (1, 6, 9), each possibly appearing at two locations (above or below the center of attention). [sent-42, score-0.412]
</p><p>31 A parallel may be drawn between the computation cube and a cortical hypercolumn; in the inferotemporal cortex, cells selective for specific shapes may be arranged in columns, with the dimension perpendicular to the cortical surface encoding different variants of the same shape [14]. [sent-43, score-0.523]
</p><p>32 It is not known whether the attention-centered location of the shape, which affects the responses of V4 cells [8], is mapped in an orderly fashion onto some physical dimension(s) of the cortex. [sent-44, score-0.235]
</p><p>33 Right: the estimation of the marginal probabilities of shapes, which can be used to decide whether to allocate a unit coding for their composition, can be carried out simply by summing the activities of units along the different dimensions of the computation cube. [sent-45, score-0.149]
</p><p>34 It is up to the model, however, to figure out that the objects may be composed of recurring fragments, and to self-organize in a manner that would allow it to deal with novel configurations of those fragments. [sent-47, score-0.186]
</p><p>35 This problem, which arises both at the level of fragments and of their constituent features, can be addressed within the Minimum Description Length (MDL) framework. [sent-48, score-0.329]
</p><p>36 Specifically, we propose to construct receptive fields (RFs) for composite objects so as to capture the deviation from independence between the probability distributions of the responses of RFs tuned to their fragments. [sent-49, score-0.614]
</p><p>37 This implies a savings in the description length of the composite object. [sent-50, score-0.22]
</p><p>38 Suppose, for example, that r /l is the response of a unit tuned roughly to the top half of the character 6 and r h - the response of a unit tuned to its bottom half. [sent-51, score-0.476]
</p><p>39 By this criterion, a composite RF will be constructed that recognizes the two "parts"  of the character 6 when they are appropriately located: the probability on the LHS of eq. [sent-53, score-0.256]
</p><p>40 1 in that case would be proportional to 1/10, while the probability of the RHS would be proportional to 1/100 (assuming that all characters are equiprobable, and that their fragments never appear in isolation). [sent-54, score-0.329]
</p><p>41 At the same time, a composite RF tuned, say, to 6 above 3 (see section 3) will not be allocated, because the probability of such a complex feature as measured by either the RHS or the LHS of eq. [sent-55, score-0.22]
</p><p>42 We note that this feature analysis can be performed on the marginal probabilities of the corresponding fragments, which are by definition less sensitive to image parameters such as the exact location or scale, and can be based on a family of features (cf. [sent-57, score-0.168]
</p><p>43 A discussion of this approach and of its relationship to the reconstruction constraint we impose when training the fragment-tuned modules is beyond the scope of this paper. [sent-59, score-0.064]
</p><p>44 A parallel can be drawn between the MDL framework just outlined and the findings concerning what+where cells and gain fields in the shape processing pathway in the monkey cortex. [sent-60, score-0.521]
</p><p>45 The computational experiments described below concentrate on these novel characteristics of our model, rather than on the standard MDL machinery. [sent-62, score-0.057]
</p><p>46 Reconstruction error (modulatory signal)  Classification (output signal)  Figure 2: The CoF model, trained on five composite objects (lover 6,2 over 7, etc. [sent-63, score-0.396]
</p><p>47 Left: the model consists of two what+where units, responsible for the bottom and the top fragments of the stimulus, respectively. [sent-65, score-0.483]
</p><p>48 Gain fields (boxes labeled below center and above center) steer each input fragment to the appropriate unit. [sent-66, score-0.22]
</p><p>49 The learning mechanism (RIC, for Reconstruction/Classification) was implemented as a radial basis function network. [sent-67, score-0.059]
</p><p>50 Multiple fixations of the stimulus (of which three are illustrated), along with Gaussian windows selecting stimulus fragments, allow the system to learn what+where responses. [sent-70, score-0.202]
</p><p>51 A cell would only be allocated to a given fragment if it recurs in the company of a variety of other fragments, as warranted by the ratio between their joint probability and the product of the corresponding marginal probabilities (cf. [sent-71, score-0.129]
</p><p>52 The first experiment (reported elsewhere [13)), involved animal-like shapes and aimed at demonstrating basic productivity and systematicity. [sent-75, score-0.281]
</p><p>53 We found that the CoF model is capable of systematically interpreting composite objects to which it was not previously exposed (for example, a half-goat and half-lion chimera is represented as such, by an ensemble of units trained to discriminate between three altogether different animals). [sent-76, score-0.557]
</p><p>54 In the second experiment, a version of the CoF model (Figure 2) was charged with learning to reuse fragments of the members of the training set - five bipartite objects composed of shapes of numerals from 1 through 0 - in interpreting novel compositions of the same fragments. [sent-77, score-0.751]
</p><p>55 The gain field mechanism built into the CoF model allowed it to respond largely systematically to the learned fragments even when these were shown in novel locations, both absolute, and relative (Figure 3, left). [sent-78, score-0.686]
</p><p>56 The third experiment addressed a basic prediction of the CoF model, stemming from its reliance on what+where mechanisms: the interaction between effects of shape and location in object representation. [sent-79, score-0.497]
</p><p>57 Such interaction had been found in a psychophysical study [15], in which the task was 4-alternative forced-choice classification of two-part stimuli consisting of simple geometric shapes (cube, cylinder, sphere, cone) . [sent-80, score-0.227]
</p><p>58 The composite stimuli were defined by two variables, shape and location, each of which could be same, neutral, or different in the prime and the target (yielding 9 conditions altogether). [sent-81, score-0.366]
</p><p>59 Response times of human subjects revealed effects of shape and location (what+where) , but not of shape alone; the pattern of priming across the nine conditions was replicated by the CoF model (correlation between model and human data r = 0. [sent-82, score-0.657]
</p><p>60 85), using the same stimuli as in the psychophysical experiment. [sent-83, score-0.074]
</p><p>61 4  Discussion  Because CoF relies on retinotopy rather than on abstract binding, its representation of spatial structure is location-specific; so is the treatment of structure by the human visual system, as indicated by a number of findings. [sent-84, score-0.702]
</p><p>62 For example, priming in a subliminal perception task was found to be confined to a quadrant of the visual field [16]. [sent-85, score-0.372]
</p><p>63 Moreover, location (as it figures in the CoF model) should be interpreted relative to the focus of attention, rather than retinotopically [17]. [sent-87, score-0.12]
</p><p>64 The idea that global relationships (hence, large-scale structure) have precedence over local ones [18], which is central to our approach, has withstood extensive testing in the past two decades. [sent-88, score-0.137]
</p><p>65 Even with the perceptual salience of the global and local structure equated, subjects are able to process the relations among elements before the elements themselves are identified [19]. [sent-89, score-0.166]
</p><p>66 More generally, humans are limited in their ability to represent spatial structure, in that the representation of spatial relations requires spatial attention. [sent-90, score-0.497]
</p><p>67 For example, visual search is difficult when  above  0. [sent-91, score-0.173]
</p><p>68 005  Figure 3: Left: the response of the CoF model to a novel composite object, 6 (which only appeared in the bottom position in the training set) over 3 (which was only seen in the top position) . [sent-120, score-0.469]
</p><p>69 The interpretations offered by the model were correct in 94 out of the 100 possible test cases (10 digits on top x 10 digits on the bottom) in this experiment. [sent-121, score-0.131]
</p><p>70 Note: in the test scenario, each unit (above and below) must be fed each of the two input fragments (above and below), hence the 20 bars in the plots of the model's output. [sent-122, score-0.388]
</p><p>71 Right: the non-monotonic dependence of the mean entropy per output unit (ordinate axis on the right; dashed line) on the spread constant a of the radial basis functions (abscissa) indicates that entropy alone should not be used as a training criterion in object representation systems. [sent-123, score-0.399]
</p><p>72 targets differ from distractors only in the spatial relation between their elements, as if ". [sent-124, score-0.115]
</p><p>73 The CoF model offers a unified framework, rooted in the MDL principle, for the understanding of these behavioral findings and of the functional significance of what+where receptive fields and attentional gain modulation. [sent-131, score-0.418]
</p><p>74 It extends the previous use of gain fields in the modeling of translation invariance [21] and of objectcentered herni-neglect [22], and highlights a parallel between whaHwhere cells and probabilistic approaches to structure representation in computational vision (e. [sent-132, score-0.49]
</p><p>75 The representational framework we described is both productive and effectively systematic. [sent-135, score-0.197]
</p><p>76 Specifically, it has the ability, as a matter of principle, to recognize as such objects that are related through a rearrangement of mesoscopic parts, without being taught those parts individually, and without the need for abstract symbolic binding. [sent-136, score-0.326]
</p><p>77 Where view-based theories of human object recognition break down: the role of structure in human shape perception. [sent-144, score-0.596]
</p><p>78 Neuronal selectivities to complex object features in the ventral visual pathway of the macaque cerebral cortex. [sent-175, score-0.536]
</p><p>79 Integration of what and where in the primate prefrontal cortex. [sent-185, score-0.082]
</p><p>80 Columns for visual features of objects in monkey inferotemporal cortex. [sent-243, score-0.467]
</p><p>81 On the representation of object structure in human vision: evidence from differential priming of shape and location. [sent-249, score-0.675]
</p><p>82 Forest before trees: The precedence of global features in visual perception. [sent-262, score-0.322]
</p><p>83 A probabilistic approach to object recognition using local photometry and global geometry. [sent-304, score-0.328]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('cof', 0.45), ('fragments', 0.329), ('object', 0.23), ('composite', 0.22), ('visual', 0.173), ('shapes', 0.153), ('objects', 0.129), ('location', 0.12), ('spatial', 0.115), ('productive', 0.113), ('systematicity', 0.113), ('gain', 0.11), ('shape', 0.11), ('representation', 0.11), ('mdl', 0.11), ('fields', 0.092), ('parts', 0.088), ('binding', 0.084), ('constituents', 0.084), ('priming', 0.084), ('productivity', 0.084), ('attentional', 0.081), ('fragment', 0.081), ('structure', 0.079), ('rf', 0.076), ('systematic', 0.076), ('stimulus', 0.073), ('edelman', 0.073), ('bottom', 0.067), ('cube', 0.066), ('reliability', 0.066), ('reconstruction', 0.064), ('tuned', 0.064), ('cells', 0.064), ('human', 0.062), ('symbolic', 0.061), ('monkey', 0.061), ('mechanism', 0.059), ('unit', 0.059), ('field', 0.059), ('receptive', 0.058), ('attention', 0.058), ('novel', 0.057), ('chorus', 0.056), ('compositional', 0.056), ('compositionality', 0.056), ('fixations', 0.056), ('hemifield', 0.056), ('inferotemporal', 0.056), ('intrator', 0.056), ('lhs', 0.056), ('pegboard', 0.056), ('perceiving', 0.056), ('precedence', 0.056), ('rhs', 0.056), ('subliminal', 0.056), ('recognition', 0.053), ('psychology', 0.052), ('responses', 0.051), ('units', 0.051), ('top', 0.051), ('allocated', 0.048), ('prefrontal', 0.048), ('rearrangement', 0.048), ('retinotopy', 0.048), ('features', 0.048), ('five', 0.047), ('coarse', 0.047), ('center', 0.047), ('cognitive', 0.046), ('global', 0.045), ('effectively', 0.044), ('aimed', 0.044), ('discriminate', 0.044), ('offered', 0.044), ('pathway', 0.044), ('rfs', 0.044), ('relations', 0.042), ('macaque', 0.041), ('altogether', 0.041), ('modulatory', 0.041), ('unified', 0.041), ('framework', 0.04), ('coding', 0.039), ('response', 0.038), ('coded', 0.038), ('psychophysical', 0.038), ('effects', 0.037), ('nips', 0.037), ('cortical', 0.037), ('model', 0.036), ('systematically', 0.036), ('extensive', 0.036), ('category', 0.036), ('character', 0.036), ('rh', 0.036), ('treatment', 0.036), ('stimuli', 0.036), ('vision', 0.035), ('primate', 0.034)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="10-tfidf-1" href="./nips-2000-A_Productive%2C_Systematic_Framework_for_the_Representation_of_Visual_Structure.html">10 nips-2000-A Productive, Systematic Framework for the Representation of Visual Structure</a></p>
<p>Author: Shimon Edelman, Nathan Intrator</p><p>Abstract: We describe a unified framework for the understanding of structure representation in primate vision. A model derived from this framework is shown to be effectively systematic in that it has the ability to interpret and associate together objects that are related through a rearrangement of common</p><p>2 0.16157044 <a title="10-tfidf-2" href="./nips-2000-Shape_Context%3A_A_New_Descriptor_for_Shape_Matching_and_Object_Recognition.html">117 nips-2000-Shape Context: A New Descriptor for Shape Matching and Object Recognition</a></p>
<p>Author: Serge Belongie, Jitendra Malik, Jan Puzicha</p><p>Abstract: We develop an approach to object recognition based on matching shapes and using a resulting measure of similarity in a nearest neighbor classifier. The key algorithmic problem here is that of finding pointwise correspondences between an image shape and a stored prototype shape. We introduce a new shape descriptor, the shape context, which makes this possible, using a simple and robust algorithm. The shape context at a point captures the distribution over relative positions of other shape points and thus summarizes global shape in a rich, local descriptor. We demonstrate that shape contexts greatly simplify recovery of correspondences between points of two given shapes. Once shapes are aligned, shape contexts are used to define a robust score for measuring shape similarity. We have used this score in a nearest-neighbor classifier for recognition of hand written digits as well as 3D objects, using exactly the same distance function. On the benchmark MNIST dataset of handwritten digits, this yields an error rate of 0.63%, outperforming other published techniques. 1</p><p>3 0.14634034 <a title="10-tfidf-3" href="./nips-2000-Dendritic_Compartmentalization_Could_Underlie_Competition_and_Attentional_Biasing_of_Simultaneous_Visual_Stimuli.html">40 nips-2000-Dendritic Compartmentalization Could Underlie Competition and Attentional Biasing of Simultaneous Visual Stimuli</a></p>
<p>Author: Kevin A. Archie, Bartlett W. Mel</p><p>Abstract: Neurons in area V4 have relatively large receptive fields (RFs), so multiple visual features are simultaneously</p><p>4 0.13995817 <a title="10-tfidf-4" href="./nips-2000-Adaptive_Object_Representation_with_Hierarchically-Distributed_Memory_Sites.html">19 nips-2000-Adaptive Object Representation with Hierarchically-Distributed Memory Sites</a></p>
<p>Author: Bosco S. Tjan</p><p>Abstract: Theories of object recognition often assume that only one representation scheme is used within one visual-processing pathway. Versatility of the visual system comes from having multiple visual-processing pathways, each specialized in a different category of objects. We propose a theoretically simpler alternative, capable of explaining the same set of data and more. A single primary visual-processing pathway, loosely modular, is assumed. Memory modules are attached to sites along this pathway. Object-identity decision is made independently at each site. A site's response time is a monotonic-decreasing function of its confidence regarding its decision. An observer's response is the first-arriving response from any site. The effective representation(s) of such a system, determined empirically, can appear to be specialized for different tasks and stimuli, consistent with recent clinical and functional-imaging findings. This, however, merely reflects a decision being made at its appropriate level of abstraction. The system itself is intrinsically flexible and adaptive.</p><p>5 0.13370278 <a title="10-tfidf-5" href="./nips-2000-A_New_Model_of_Spatial_Representation_in_Multimodal_Brain_Areas.html">8 nips-2000-A New Model of Spatial Representation in Multimodal Brain Areas</a></p>
<p>Author: Sophie Denève, Jean-René Duhamel, Alexandre Pouget</p><p>Abstract: Most models of spatial representations in the cortex assume cells with limited receptive fields that are defined in a particular egocentric frame of reference. However, cells outside of primary sensory cortex are either gain modulated by postural input or partially shifting. We show that solving classical spatial tasks, like sensory prediction, multi-sensory integration, sensory-motor transformation and motor control requires more complicated intermediate representations that are not invariant in one frame of reference. We present an iterative basis function map that performs these spatial tasks optimally with gain modulated and partially shifting units, and tests it against neurophysiological and neuropsychological data. In order to perform an action directed toward an object, it is necessary to have a representation of its spatial location. The brain must be able to use spatial cues coming from different modalities (e.g. vision, audition, touch, proprioception), combine them to infer the position of the object, and compute the appropriate movement. These cues are in different frames of reference corresponding to different sensory or motor modalities. Visual inputs are primarily encoded in retinotopic maps, auditory inputs are encoded in head centered maps and tactile cues are encoded in skin-centered maps. Going from one frame of reference to the other might seem easy. For example, the head-centered position of an object can be approximated by the sum of its retinotopic position and the eye position. However, positions are represented by population codes in the brain, and computing a head-centered map from a retinotopic map is a more complex computation than the underlying sum. Moreover, as we get closer to sensory-motor areas it seems reasonable to assume Spksls 150 100 50 o Figure 1: Response of a VIP cell to visual stimuli appearing in different part of the screen, for three different eye positions. The level of grey represent the frequency of discharge (In spikes per seconds). The white cross is the fixation point (the head is fixed). The cell's receptive field is moving with the eyes, but only partially. Here the receptive field shift is 60% of the total gaze shift. Moreover this cell is gain modulated by eye position (adapted from Duhamel et al). that the representations should be useful for sensory-motor transformations, rather than encode an</p><p>6 0.12407416 <a title="10-tfidf-6" href="./nips-2000-Place_Cells_and_Spatial_Navigation_Based_on_2D_Visual_Feature_Extraction%2C_Path_Integration%2C_and_Reinforcement_Learning.html">101 nips-2000-Place Cells and Spatial Navigation Based on 2D Visual Feature Extraction, Path Integration, and Reinforcement Learning</a></p>
<p>7 0.11801723 <a title="10-tfidf-7" href="./nips-2000-The_Use_of_MDL_to_Select_among_Computational_Models_of_Cognition.html">139 nips-2000-The Use of MDL to Select among Computational Models of Cognition</a></p>
<p>8 0.1118425 <a title="10-tfidf-8" href="./nips-2000-Modelling_Spatial_Recall%2C_Mental_Imagery_and_Neglect.html">87 nips-2000-Modelling Spatial Recall, Mental Imagery and Neglect</a></p>
<p>9 0.097014114 <a title="10-tfidf-9" href="./nips-2000-Position_Variance%2C_Recurrence_and_Perceptual_Learning.html">102 nips-2000-Position Variance, Recurrence and Perceptual Learning</a></p>
<p>10 0.092230603 <a title="10-tfidf-10" href="./nips-2000-Redundancy_and_Dimensionality_Reduction_in_Sparse-Distributed_Representations_of_Natural_Objects_in_Terms_of_Their_Local_Features.html">109 nips-2000-Redundancy and Dimensionality Reduction in Sparse-Distributed Representations of Natural Objects in Terms of Their Local Features</a></p>
<p>11 0.08621747 <a title="10-tfidf-11" href="./nips-2000-A_Comparison_of_Image_Processing_Techniques_for_Visual_Speech_Recognition_Applications.html">2 nips-2000-A Comparison of Image Processing Techniques for Visual Speech Recognition Applications</a></p>
<p>12 0.08555866 <a title="10-tfidf-12" href="./nips-2000-Natural_Sound_Statistics_and_Divisive_Normalization_in_the_Auditory_System.html">89 nips-2000-Natural Sound Statistics and Divisive Normalization in the Auditory System</a></p>
<p>13 0.081790276 <a title="10-tfidf-13" href="./nips-2000-Multiple_Timescales_of_Adaptation_in_a_Neural_Code.html">88 nips-2000-Multiple Timescales of Adaptation in a Neural Code</a></p>
<p>14 0.075366624 <a title="10-tfidf-14" href="./nips-2000-Emergence_of_Movement_Sensitive_Neurons%27_Properties_by_Learning_a_Sparse_Code_for_Natural_Moving_Images.html">45 nips-2000-Emergence of Movement Sensitive Neurons' Properties by Learning a Sparse Code for Natural Moving Images</a></p>
<p>15 0.073909797 <a title="10-tfidf-15" href="./nips-2000-Rate-coded_Restricted_Boltzmann_Machines_for_Face_Recognition.html">107 nips-2000-Rate-coded Restricted Boltzmann Machines for Face Recognition</a></p>
<p>16 0.072089851 <a title="10-tfidf-16" href="./nips-2000-Divisive_and_Subtractive_Mask_Effects%3A_Linking_Psychophysics_and_Biophysics.html">42 nips-2000-Divisive and Subtractive Mask Effects: Linking Psychophysics and Biophysics</a></p>
<p>17 0.068038002 <a title="10-tfidf-17" href="./nips-2000-The_Interplay_of_Symbolic_and_Subsymbolic_Processes_in_Anagram_Problem_Solving.html">132 nips-2000-The Interplay of Symbolic and Subsymbolic Processes in Anagram Problem Solving</a></p>
<p>18 0.06202006 <a title="10-tfidf-18" href="./nips-2000-Color_Opponency_Constitutes_a_Sparse_Representation_for_the_Chromatic_Structure_of_Natural_Scenes.html">32 nips-2000-Color Opponency Constitutes a Sparse Representation for the Chromatic Structure of Natural Scenes</a></p>
<p>19 0.06076825 <a title="10-tfidf-19" href="./nips-2000-Accumulator_Networks%3A_Suitors_of_Local_Probability_Propagation.html">15 nips-2000-Accumulator Networks: Suitors of Local Probability Propagation</a></p>
<p>20 0.057967283 <a title="10-tfidf-20" href="./nips-2000-Automatic_Choice_of_Dimensionality_for_PCA.html">27 nips-2000-Automatic Choice of Dimensionality for PCA</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2000_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.211), (1, -0.166), (2, -0.033), (3, 0.072), (4, -0.055), (5, 0.056), (6, 0.199), (7, -0.096), (8, 0.28), (9, -0.01), (10, 0.031), (11, 0.174), (12, 0.045), (13, 0.095), (14, -0.02), (15, 0.052), (16, -0.0), (17, -0.137), (18, -0.095), (19, 0.106), (20, -0.031), (21, -0.01), (22, -0.007), (23, 0.075), (24, 0.052), (25, 0.078), (26, -0.005), (27, -0.057), (28, -0.079), (29, 0.087), (30, -0.03), (31, 0.178), (32, -0.127), (33, 0.014), (34, -0.053), (35, -0.18), (36, -0.032), (37, 0.011), (38, -0.096), (39, -0.149), (40, -0.023), (41, 0.1), (42, 0.065), (43, -0.064), (44, -0.085), (45, 0.001), (46, 0.036), (47, -0.108), (48, 0.018), (49, -0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97087365 <a title="10-lsi-1" href="./nips-2000-A_Productive%2C_Systematic_Framework_for_the_Representation_of_Visual_Structure.html">10 nips-2000-A Productive, Systematic Framework for the Representation of Visual Structure</a></p>
<p>Author: Shimon Edelman, Nathan Intrator</p><p>Abstract: We describe a unified framework for the understanding of structure representation in primate vision. A model derived from this framework is shown to be effectively systematic in that it has the ability to interpret and associate together objects that are related through a rearrangement of common</p><p>2 0.64856303 <a title="10-lsi-2" href="./nips-2000-Shape_Context%3A_A_New_Descriptor_for_Shape_Matching_and_Object_Recognition.html">117 nips-2000-Shape Context: A New Descriptor for Shape Matching and Object Recognition</a></p>
<p>Author: Serge Belongie, Jitendra Malik, Jan Puzicha</p><p>Abstract: We develop an approach to object recognition based on matching shapes and using a resulting measure of similarity in a nearest neighbor classifier. The key algorithmic problem here is that of finding pointwise correspondences between an image shape and a stored prototype shape. We introduce a new shape descriptor, the shape context, which makes this possible, using a simple and robust algorithm. The shape context at a point captures the distribution over relative positions of other shape points and thus summarizes global shape in a rich, local descriptor. We demonstrate that shape contexts greatly simplify recovery of correspondences between points of two given shapes. Once shapes are aligned, shape contexts are used to define a robust score for measuring shape similarity. We have used this score in a nearest-neighbor classifier for recognition of hand written digits as well as 3D objects, using exactly the same distance function. On the benchmark MNIST dataset of handwritten digits, this yields an error rate of 0.63%, outperforming other published techniques. 1</p><p>3 0.54688042 <a title="10-lsi-3" href="./nips-2000-Dendritic_Compartmentalization_Could_Underlie_Competition_and_Attentional_Biasing_of_Simultaneous_Visual_Stimuli.html">40 nips-2000-Dendritic Compartmentalization Could Underlie Competition and Attentional Biasing of Simultaneous Visual Stimuli</a></p>
<p>Author: Kevin A. Archie, Bartlett W. Mel</p><p>Abstract: Neurons in area V4 have relatively large receptive fields (RFs), so multiple visual features are simultaneously</p><p>4 0.53957939 <a title="10-lsi-4" href="./nips-2000-Adaptive_Object_Representation_with_Hierarchically-Distributed_Memory_Sites.html">19 nips-2000-Adaptive Object Representation with Hierarchically-Distributed Memory Sites</a></p>
<p>Author: Bosco S. Tjan</p><p>Abstract: Theories of object recognition often assume that only one representation scheme is used within one visual-processing pathway. Versatility of the visual system comes from having multiple visual-processing pathways, each specialized in a different category of objects. We propose a theoretically simpler alternative, capable of explaining the same set of data and more. A single primary visual-processing pathway, loosely modular, is assumed. Memory modules are attached to sites along this pathway. Object-identity decision is made independently at each site. A site's response time is a monotonic-decreasing function of its confidence regarding its decision. An observer's response is the first-arriving response from any site. The effective representation(s) of such a system, determined empirically, can appear to be specialized for different tasks and stimuli, consistent with recent clinical and functional-imaging findings. This, however, merely reflects a decision being made at its appropriate level of abstraction. The system itself is intrinsically flexible and adaptive.</p><p>5 0.48695245 <a title="10-lsi-5" href="./nips-2000-A_New_Model_of_Spatial_Representation_in_Multimodal_Brain_Areas.html">8 nips-2000-A New Model of Spatial Representation in Multimodal Brain Areas</a></p>
<p>Author: Sophie Denève, Jean-René Duhamel, Alexandre Pouget</p><p>Abstract: Most models of spatial representations in the cortex assume cells with limited receptive fields that are defined in a particular egocentric frame of reference. However, cells outside of primary sensory cortex are either gain modulated by postural input or partially shifting. We show that solving classical spatial tasks, like sensory prediction, multi-sensory integration, sensory-motor transformation and motor control requires more complicated intermediate representations that are not invariant in one frame of reference. We present an iterative basis function map that performs these spatial tasks optimally with gain modulated and partially shifting units, and tests it against neurophysiological and neuropsychological data. In order to perform an action directed toward an object, it is necessary to have a representation of its spatial location. The brain must be able to use spatial cues coming from different modalities (e.g. vision, audition, touch, proprioception), combine them to infer the position of the object, and compute the appropriate movement. These cues are in different frames of reference corresponding to different sensory or motor modalities. Visual inputs are primarily encoded in retinotopic maps, auditory inputs are encoded in head centered maps and tactile cues are encoded in skin-centered maps. Going from one frame of reference to the other might seem easy. For example, the head-centered position of an object can be approximated by the sum of its retinotopic position and the eye position. However, positions are represented by population codes in the brain, and computing a head-centered map from a retinotopic map is a more complex computation than the underlying sum. Moreover, as we get closer to sensory-motor areas it seems reasonable to assume Spksls 150 100 50 o Figure 1: Response of a VIP cell to visual stimuli appearing in different part of the screen, for three different eye positions. The level of grey represent the frequency of discharge (In spikes per seconds). The white cross is the fixation point (the head is fixed). The cell's receptive field is moving with the eyes, but only partially. Here the receptive field shift is 60% of the total gaze shift. Moreover this cell is gain modulated by eye position (adapted from Duhamel et al). that the representations should be useful for sensory-motor transformations, rather than encode an</p><p>6 0.48400849 <a title="10-lsi-6" href="./nips-2000-Modelling_Spatial_Recall%2C_Mental_Imagery_and_Neglect.html">87 nips-2000-Modelling Spatial Recall, Mental Imagery and Neglect</a></p>
<p>7 0.45506239 <a title="10-lsi-7" href="./nips-2000-The_Use_of_MDL_to_Select_among_Computational_Models_of_Cognition.html">139 nips-2000-The Use of MDL to Select among Computational Models of Cognition</a></p>
<p>8 0.45103657 <a title="10-lsi-8" href="./nips-2000-The_Interplay_of_Symbolic_and_Subsymbolic_Processes_in_Anagram_Problem_Solving.html">132 nips-2000-The Interplay of Symbolic and Subsymbolic Processes in Anagram Problem Solving</a></p>
<p>9 0.43474048 <a title="10-lsi-9" href="./nips-2000-Redundancy_and_Dimensionality_Reduction_in_Sparse-Distributed_Representations_of_Natural_Objects_in_Terms_of_Their_Local_Features.html">109 nips-2000-Redundancy and Dimensionality Reduction in Sparse-Distributed Representations of Natural Objects in Terms of Their Local Features</a></p>
<p>10 0.40391663 <a title="10-lsi-10" href="./nips-2000-Place_Cells_and_Spatial_Navigation_Based_on_2D_Visual_Feature_Extraction%2C_Path_Integration%2C_and_Reinforcement_Learning.html">101 nips-2000-Place Cells and Spatial Navigation Based on 2D Visual Feature Extraction, Path Integration, and Reinforcement Learning</a></p>
<p>11 0.36938411 <a title="10-lsi-11" href="./nips-2000-Divisive_and_Subtractive_Mask_Effects%3A_Linking_Psychophysics_and_Biophysics.html">42 nips-2000-Divisive and Subtractive Mask Effects: Linking Psychophysics and Biophysics</a></p>
<p>12 0.32292077 <a title="10-lsi-12" href="./nips-2000-A_Comparison_of_Image_Processing_Techniques_for_Visual_Speech_Recognition_Applications.html">2 nips-2000-A Comparison of Image Processing Techniques for Visual Speech Recognition Applications</a></p>
<p>13 0.31534636 <a title="10-lsi-13" href="./nips-2000-Feature_Correspondence%3A_A_Markov_Chain_Monte_Carlo_Approach.html">53 nips-2000-Feature Correspondence: A Markov Chain Monte Carlo Approach</a></p>
<p>14 0.28234488 <a title="10-lsi-14" href="./nips-2000-Who_Does_What%3F_A_Novel_Algorithm_to_Determine_Function_Localization.html">147 nips-2000-Who Does What? A Novel Algorithm to Determine Function Localization</a></p>
<p>15 0.27725536 <a title="10-lsi-15" href="./nips-2000-Dopamine_Bonuses.html">43 nips-2000-Dopamine Bonuses</a></p>
<p>16 0.2639921 <a title="10-lsi-16" href="./nips-2000-Partially_Observable_SDE_Models_for_Image_Sequence_Recognition_Tasks.html">98 nips-2000-Partially Observable SDE Models for Image Sequence Recognition Tasks</a></p>
<p>17 0.25926718 <a title="10-lsi-17" href="./nips-2000-Position_Variance%2C_Recurrence_and_Perceptual_Learning.html">102 nips-2000-Position Variance, Recurrence and Perceptual Learning</a></p>
<p>18 0.25662103 <a title="10-lsi-18" href="./nips-2000-Multiple_Timescales_of_Adaptation_in_a_Neural_Code.html">88 nips-2000-Multiple Timescales of Adaptation in a Neural Code</a></p>
<p>19 0.25108013 <a title="10-lsi-19" href="./nips-2000-Natural_Sound_Statistics_and_Divisive_Normalization_in_the_Auditory_System.html">89 nips-2000-Natural Sound Statistics and Divisive Normalization in the Auditory System</a></p>
<p>20 0.24813507 <a title="10-lsi-20" href="./nips-2000-Interactive_Parts_Model%3A_An_Application_to_Recognition_of_On-line_Cursive_Script.html">71 nips-2000-Interactive Parts Model: An Application to Recognition of On-line Cursive Script</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2000_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(4, 0.015), (10, 0.037), (11, 0.014), (17, 0.124), (22, 0.018), (32, 0.025), (33, 0.039), (36, 0.086), (42, 0.032), (54, 0.192), (55, 0.073), (56, 0.012), (62, 0.021), (65, 0.021), (67, 0.038), (72, 0.019), (76, 0.042), (79, 0.011), (81, 0.032), (90, 0.02), (97, 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.88894004 <a title="10-lda-1" href="./nips-2000-A_Productive%2C_Systematic_Framework_for_the_Representation_of_Visual_Structure.html">10 nips-2000-A Productive, Systematic Framework for the Representation of Visual Structure</a></p>
<p>Author: Shimon Edelman, Nathan Intrator</p><p>Abstract: We describe a unified framework for the understanding of structure representation in primate vision. A model derived from this framework is shown to be effectively systematic in that it has the ability to interpret and associate together objects that are related through a rearrangement of common</p><p>2 0.86750525 <a title="10-lda-2" href="./nips-2000-Tree-Based_Modeling_and_Estimation_of_Gaussian_Processes_on_Graphs_with_Cycles.html">140 nips-2000-Tree-Based Modeling and Estimation of Gaussian Processes on Graphs with Cycles</a></p>
<p>Author: Martin J. Wainwright, Erik B. Sudderth, Alan S. Willsky</p><p>Abstract: We present the embedded trees algorithm, an iterative technique for estimation of Gaussian processes defined on arbitrary graphs. By exactly solving a series of modified problems on embedded spanning trees, it computes the conditional means with an efficiency comparable to or better than other techniques. Unlike other methods, the embedded trees algorithm also computes exact error covariances. The error covariance computation is most efficient for graphs in which removing a small number of edges reveals an embedded tree. In this context, we demonstrate that sparse loopy graphs can provide a significant increase in modeling power relative to trees, with only a minor increase in estimation complexity. 1</p><p>3 0.860569 <a title="10-lda-3" href="./nips-2000-Computing_with_Finite_and_Infinite_Networks.html">35 nips-2000-Computing with Finite and Infinite Networks</a></p>
<p>Author: Ole Winther</p><p>Abstract: Using statistical mechanics results, I calculate learning curves (average generalization error) for Gaussian processes (GPs) and Bayesian neural networks (NNs) used for regression. Applying the results to learning a teacher defined by a two-layer network, I can directly compare GP and Bayesian NN learning. I find that a GP in general requires CJ (d S )-training examples to learn input features of order s (d is the input dimension), whereas a NN can learn the task with order the number of adjustable weights training examples. Since a GP can be considered as an infinite NN, the results show that even in the Bayesian approach, it is important to limit the complexity of the learning machine. The theoretical findings are confirmed in simulations with analytical GP learning and a NN mean field algorithm.</p><p>4 0.71678853 <a title="10-lda-4" href="./nips-2000-Sparse_Representation_for_Gaussian_Process_Models.html">122 nips-2000-Sparse Representation for Gaussian Process Models</a></p>
<p>Author: Lehel Csatč´¸, Manfred Opper</p><p>Abstract: We develop an approach for a sparse representation for Gaussian Process (GP) models in order to overcome the limitations of GPs caused by large data sets. The method is based on a combination of a Bayesian online algorithm together with a sequential construction of a relevant subsample of the data which fully specifies the prediction of the model. Experimental results on toy examples and large real-world data sets indicate the efficiency of the approach.</p><p>5 0.61917877 <a title="10-lda-5" href="./nips-2000-A_Tighter_Bound_for_Graphical_Models.html">13 nips-2000-A Tighter Bound for Graphical Models</a></p>
<p>Author: Martijn A. R. Leisink, Hilbert J. Kappen</p><p>Abstract: We present a method to bound the partition function of a Boltzmann machine neural network with any odd order polynomial. This is a direct extension of the mean field bound, which is first order. We show that the third order bound is strictly better than mean field. Additionally we show the rough outline how this bound is applicable to sigmoid belief networks. Numerical experiments indicate that an error reduction of a factor two is easily reached in the region where expansion based approximations are useful. 1</p><p>6 0.61183095 <a title="10-lda-6" href="./nips-2000-Gaussianization.html">60 nips-2000-Gaussianization</a></p>
<p>7 0.58940333 <a title="10-lda-7" href="./nips-2000-Propagation_Algorithms_for_Variational_Bayesian_Learning.html">106 nips-2000-Propagation Algorithms for Variational Bayesian Learning</a></p>
<p>8 0.58687359 <a title="10-lda-8" href="./nips-2000-Processing_of_Time_Series_by_Neural_Circuits_with_Biologically_Realistic_Synaptic_Dynamics.html">104 nips-2000-Processing of Time Series by Neural Circuits with Biologically Realistic Synaptic Dynamics</a></p>
<p>9 0.58084089 <a title="10-lda-9" href="./nips-2000-Partially_Observable_SDE_Models_for_Image_Sequence_Recognition_Tasks.html">98 nips-2000-Partially Observable SDE Models for Image Sequence Recognition Tasks</a></p>
<p>10 0.57943922 <a title="10-lda-10" href="./nips-2000-Using_Free_Energies_to_Represent_Q-values_in_a_Multiagent_Reinforcement_Learning_Task.html">142 nips-2000-Using Free Energies to Represent Q-values in a Multiagent Reinforcement Learning Task</a></p>
<p>11 0.57790959 <a title="10-lda-11" href="./nips-2000-A_Comparison_of_Image_Processing_Techniques_for_Visual_Speech_Recognition_Applications.html">2 nips-2000-A Comparison of Image Processing Techniques for Visual Speech Recognition Applications</a></p>
<p>12 0.57698107 <a title="10-lda-12" href="./nips-2000-Interactive_Parts_Model%3A_An_Application_to_Recognition_of_On-line_Cursive_Script.html">71 nips-2000-Interactive Parts Model: An Application to Recognition of On-line Cursive Script</a></p>
<p>13 0.5706951 <a title="10-lda-13" href="./nips-2000-Rate-coded_Restricted_Boltzmann_Machines_for_Face_Recognition.html">107 nips-2000-Rate-coded Restricted Boltzmann Machines for Face Recognition</a></p>
<p>14 0.56669754 <a title="10-lda-14" href="./nips-2000-On_Iterative_Krylov-Dogleg_Trust-Region_Steps_for_Solving_Neural_Networks_Nonlinear_Least_Squares_Problems.html">93 nips-2000-On Iterative Krylov-Dogleg Trust-Region Steps for Solving Neural Networks Nonlinear Least Squares Problems</a></p>
<p>15 0.56608218 <a title="10-lda-15" href="./nips-2000-A_New_Model_of_Spatial_Representation_in_Multimodal_Brain_Areas.html">8 nips-2000-A New Model of Spatial Representation in Multimodal Brain Areas</a></p>
<p>16 0.56493431 <a title="10-lda-16" href="./nips-2000-A_Mathematical_Programming_Approach_to_the_Kernel_Fisher_Algorithm.html">5 nips-2000-A Mathematical Programming Approach to the Kernel Fisher Algorithm</a></p>
<p>17 0.5602138 <a title="10-lda-17" href="./nips-2000-On_Reversing_Jensen%27s_Inequality.html">94 nips-2000-On Reversing Jensen's Inequality</a></p>
<p>18 0.55767417 <a title="10-lda-18" href="./nips-2000-Factored_Semi-Tied_Covariance_Matrices.html">51 nips-2000-Factored Semi-Tied Covariance Matrices</a></p>
<p>19 0.55664122 <a title="10-lda-19" href="./nips-2000-A_New_Approximate_Maximal_Margin_Classification_Algorithm.html">7 nips-2000-A New Approximate Maximal Margin Classification Algorithm</a></p>
<p>20 0.55632126 <a title="10-lda-20" href="./nips-2000-An_Adaptive_Metric_Machine_for_Pattern_Classification.html">23 nips-2000-An Adaptive Metric Machine for Pattern Classification</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
