<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>168 nips-2006-Reducing Calibration Time For Brain-Computer Interfaces: A Clustering Approach</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-168" href="#">nips2006-168</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>168 nips-2006-Reducing Calibration Time For Brain-Computer Interfaces: A Clustering Approach</h1>
<br/><p>Source: <a title="nips-2006-168-pdf" href="http://papers.nips.cc/paper/2985-reducing-calibration-time-for-brain-computer-interfaces-a-clustering-approach.pdf">pdf</a></p><p>Author: Matthias Krauledat, Michael Schröder, Benjamin Blankertz, Klaus-Robert Müller</p><p>Abstract: Up to now even subjects that are experts in the use of machine learning based BCI systems still have to undergo a calibration session of about 20-30 min. From this data their (movement) intentions are so far infered. We now propose a new paradigm that allows to completely omit such calibration and instead transfer knowledge from prior sessions. To achieve this goal we ﬁrst deﬁne normalized CSP features and distances in-between. Second, we derive prototypical features across sessions: (a) by clustering or (b) by feature concatenation methods. Finally, we construct a classiﬁer based on these individualized prototypes and show that, indeed, classiﬁers can be successfully transferred to a new session for a number of subjects.</p><p>Reference: <a title="nips-2006-168-reference" href="../nips2006_reference/nips-2006-Reducing_Calibration_Time_For_Brain-Computer_Interfaces%3A_A_Clustering_Approach_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 de 2  Abstract Up to now even subjects that are experts in the use of machine learning based BCI systems still have to undergo a calibration session of about 20-30 min. [sent-7, score-0.491]
</p><p>2 We now propose a new paradigm that allows to completely omit such calibration and instead transfer knowledge from prior sessions. [sent-9, score-0.139]
</p><p>3 Second, we derive prototypical features across sessions: (a) by clustering or (b) by feature concatenation methods. [sent-11, score-0.105]
</p><p>4 Finally, we construct a classiﬁer based on these individualized prototypes and show that, indeed, classiﬁers can be successfully transferred to a new session for a number of subjects. [sent-12, score-0.362]
</p><p>5 1 Introduction BCI systems typically require training on the subject side and on the decoding side (e. [sent-13, score-0.128]
</p><p>6 While some approaches rely on operant conditioning with extensive subject training (e. [sent-16, score-0.088]
</p><p>7 But when following our philosophy of ’letting the machines learn’, a calibration session of approximately 20-30 min was so far required, even for subjects that are beyond the status of BCI novices. [sent-21, score-0.491]
</p><p>8 The present contribution studies to what extent we can omit this brief calibration period. [sent-22, score-0.139]
</p><p>9 In other words, is it possible to successfully transfer information from prior BCI sessions of the same subject that may have taken place days or even weeks ago? [sent-23, score-0.24]
</p><p>10 While this question is of high practical importance to the BCI ﬁeld, it has so far only been addressed in [10] in the context of transfering channel selection results from subject to subject. [sent-24, score-0.091]
</p><p>11 Note that EEG (electroencephalogram) patterns typically vary strongly from one session to another, due to different psychological pre-conditions of the subject. [sent-27, score-0.264]
</p><p>12 A subject might for example show different states of fatigue and attention, or use diverse strategies for movement imagination across sessions. [sent-28, score-0.146]
</p><p>13 A successful session to session transfer should thus capture generic ’invariant’ discriminative features of the BCI task. [sent-29, score-0.528]
</p><p>14 For this we ﬁrst transform the EEG feature set from each prior session into a ’standard’ format (section 2) and normalize it. [sent-30, score-0.264]
</p><p>15 2) is established in CSP ﬁlter space, we can cluster existing CSP ﬁlters in order to obtain the most salient prototypical CSP-type ﬁlters for a subject across sessions (section 3. [sent-38, score-0.328]
</p><p>16 To this end, we use the IBICA algorithm [12, 13] for computing prototypes by a robust ICA decomposition (section 3. [sent-40, score-0.094]
</p><p>17 We will show that these new CSP prototypes are physiologically meaningful and furthermore are highly robust representations which are less easily distorted by noise artifacts. [sent-42, score-0.094]
</p><p>18 2 Experiments and Data Our BCI system uses Event-Related (De-)Synchronization (ERD/ERS) phenomena [3] in EEG signals related to hand and foot imagery as classes for control. [sent-43, score-0.241]
</p><p>19 The term refers to a de– or increasing band power in speciﬁc frequency bands of the EEG signal during the imagination of movements. [sent-44, score-0.041]
</p><p>20 For the present study we investigate data from experiments with 6 healthy subjects: aw (13 sessions), al (8 sessions), cm (4 sessions), ie (4 sessions), ay (5 sessions) and ch (4 sessions). [sent-48, score-0.146]
</p><p>21 These are all the subjects that participated in at least 4 BCI sessions. [sent-49, score-0.088]
</p><p>22 Each session started with the recording of calibration data, followed by a machine learning phase and a feedback phase of varying duration. [sent-50, score-0.441]
</p><p>23 All following retrospective analyses were performed on the calibration data only. [sent-51, score-0.139]
</p><p>24 During the experiments the subjects were seated in a comfortable chair with arm rests. [sent-52, score-0.088]
</p><p>25 For the recording of the calibration data every 4. [sent-53, score-0.139]
</p><p>26 5–6 seconds one of 3 different visual stimuli was presented, indicating a motor imagery task the subject should perform during the following 3–3. [sent-54, score-0.19]
</p><p>27 The randomized and balanced motor imagery tasks investigated for all subjects except ay were left hand (l), right hand (r), and right foot (f ). [sent-56, score-0.489]
</p><p>28 Subject ay only performed left- and right hand tasks. [sent-57, score-0.106]
</p><p>29 Between 120 and 200 trials were performed during the calibration phase of one session for each motor imagery class. [sent-58, score-0.621]
</p><p>30 The EMG and EOG channels were exclusively used to ensure that the subjects performed no real limb or eye movements correlated with the mental tasks. [sent-61, score-0.19]
</p><p>31 As their activity can directly (via artifacts) or indirectly (via afferent signals from muscles and joint receptors) be reﬂected in the EEG channels they could be detected by the classiﬁer. [sent-62, score-0.116]
</p><p>32 Controlling EMG and EOG ensured that the classiﬁer operated on true EEG signals only. [sent-63, score-0.037]
</p><p>33 In any case the chosen spectral interval comprised the subject speciﬁc frequency bands that contained motor-related activity. [sent-67, score-0.063]
</p><p>34 For each subject a subset of EEG channels was determined that had been recorded for all of the subject’s sessions. [sent-68, score-0.114]
</p><p>35 These subsets typically contained 40 to 45 channels which were densely located (according to the international 10-20 system) over the more central areas of the scalp (see scalp maps in following sections). [sent-69, score-0.113]
</p><p>36 The EEG channels of each subject were reduced to the determined subset before proceeding with the calculation of Common Spatial Patterns (CSP) for different (subject speciﬁc) binary classiﬁcation tasks. [sent-70, score-0.114]
</p><p>37 1 Introduction of Common Spatial Patterns (CSP) The common spatial pattern (CSP) algorithm is very useful in calculating spatial ﬁlters for detecting ERD/ERS effects ([15]) and can be applied to ERD-based BCIs, see [11]. [sent-74, score-0.062]
</p><p>38 , spatial ﬁlters) that maximize variance for one class and simultaneously minimize variance for the other class. [sent-78, score-0.085]
</p><p>39 After having band-pass ﬁltered the EEG signals to the rhythms of interest, high variance reﬂects a strong rhythm and low variance a weak (or attenuated) rhythm. [sent-79, score-0.124]
</p><p>40 Let us take the example of discriminating left hand vs. [sent-80, score-0.079]
</p><p>41 The ﬁltered signal corresponding to the desynchronization of the left hand motor cortex is characterized by a strong motor rhythm during imagination of right hand movements (left hand is in idle state), and by an attenuated motor rhythm during left hand imagination. [sent-82, score-0.632]
</p><p>42 5  60  70  10  20  30  40  50  60  0  70  Dimension 1  Figure 1: Left: Non-euclidean distance matrix for 78 CSP ﬁlters of imagined left hand and foot movement. [sent-85, score-0.244]
</p><p>43 Filters that minimize the variance for the imagined left hand are plotted as red crosses, foot movement imagery ﬁlters are shown as blue dots. [sent-88, score-0.348]
</p><p>44 Cluster centers detected by IBICA are marked with magenta circles. [sent-89, score-0.07]
</p><p>45 the class of right hand trials and at the same time minimizing variance for left hand trials. [sent-91, score-0.231]
</p><p>46 Furthermore the CSP algorithm calculates the dual ﬁlter that will focus on the area of the right hand and it will even calculate several ﬁlters for both optimizations by considering the remaining orthogonal subspaces. [sent-92, score-0.053]
</p><p>47 The projection that is given by the i-th row of matrix Q has a relative variance of di (i-th element of D) for trials of class 1 and relative variance 1 − di for trials of class 2. [sent-96, score-0.272]
</p><p>48 If di is near 1 the ﬁlter given by the i-th row of Q maximizes variance for class 1, and since 1 − di is near 0, minimizes variance for class 2. [sent-97, score-0.128]
</p><p>49 Typically one would retain projections corresponding to the three highest eigenvalues di , i. [sent-98, score-0.055]
</p><p>50 c1 ∗ c2 ) m(c1 , c2 ) = arccos( |c1 | ∗ |c2 | When applying this measure to a set of CSP ﬁlters (ci )i≤n , one can generate the distance matrix D = (m(ci , c j ))i, j≤n , which can then be used to ﬁnd prototypical examples of CSP ﬁlters. [sent-109, score-0.095]
</p><p>51 1 shows an example of a distance matrix for 78 CSP ﬁlters for the discrimination of the variance during imagined left hand movement and foot movement. [sent-111, score-0.313]
</p><p>52 Based on the left hand signals, three CSP ﬁlters showing the lowest  Single Linkage Dendrogram  1. [sent-112, score-0.079]
</p><p>53 Cluster centers detected by IBICA are used as CSP prototypes. [sent-118, score-0.049]
</p><p>54 The same number of 3 × 13 ﬁlters were chosen for the foot signals. [sent-121, score-0.089]
</p><p>55 , ﬁlters with the largest eigenvalues are grouped together, then ﬁlters with the second largest eigenvalues etc. [sent-124, score-0.062]
</p><p>56 This is especially true for ﬁlters for the minimization of variance in left hand trials. [sent-127, score-0.106]
</p><p>57 3 Finding Clusters in CSP space The idea to ﬁnd CSP ﬁlters that recur in the processing of different sessions of a single subject is very appealing, since these ﬁlters can be re-used for efﬁcient classiﬁcation of unseen data. [sent-129, score-0.24]
</p><p>58 2 shows a hierarchical clustering tree (see [19]) of CSP ﬁlters of different sessions for subject al. [sent-131, score-0.24]
</p><p>59 This method was originally intended to ﬁnd estimators of the super-Gaussian source signals from a mixture of signals. [sent-136, score-0.037]
</p><p>60 By projecting the data onto the hypersphere and using the angle distance, it has been demonstrated that the correct source signals can be found even in high-dimensional data. [sent-137, score-0.061]
</p><p>61 k j=1 If z lies in a densely populated region of the hypersphere, then the average distance to its neighbors is small, whereas if it lies in a sparse region, the average distance is high. [sent-148, score-0.054]
</p><p>62 The data points with the smallest γ are good candidates for prototypical CSP ﬁlters since they are similar to other ﬁlters in the comparison set. [sent-149, score-0.068]
</p><p>63 The left part shows a comparison of ordinary CSP with three methods that do not require calibration. [sent-155, score-0.145]
</p><p>64 The top row represents data of all sessions in original order. [sent-159, score-0.203]
</p><p>65 The ordinary CSP method does not take any historical data from prior sessions into account (second row). [sent-161, score-0.324]
</p><p>66 It uses training data only from the ﬁrst half of the current session. [sent-162, score-0.047]
</p><p>67 This serves as a baseline to show the general quality of the data, since half of the session data is generally enough to train a classiﬁer that is well adapted to the second half of the session. [sent-163, score-0.308]
</p><p>68 Note that this evaluation only corresponds to a real BCI scenario where many calibration trials of the same day are available. [sent-164, score-0.211]
</p><p>69 3 (fourth row), or use a combination of row three and four that results in a concatenation of CSP ﬁlters and derived CSP prototypes (ﬁfth row). [sent-167, score-0.137]
</p><p>70 Feature concatenation is an effective method that has been shown to improve CSP-based classiﬁers considerably (see [22]). [sent-168, score-0.037]
</p><p>71 3 expands the training sets for rows three, four and ﬁve for the ﬁrst 10, 20 or 30 trials per class of the data of the new session. [sent-171, score-0.097]
</p><p>72 In the methods of row 4 and 5, only LDA proﬁts from the new data, whereas CSP prototypes are calculated exclusively on historic data as before. [sent-172, score-0.178]
</p><p>73 This approach is compared against the ordinary CSP approach that now only uses the same small amount of training data from the new session. [sent-173, score-0.144]
</p><p>74 1, has been cross-validated such that each available session was used as a test session instead of the last one. [sent-175, score-0.528]
</p><p>75 5 Results The underlying question of this paper is whether information gathered from previous experimental sessions can prove its value in a new session. [sent-176, score-0.177]
</p><p>76 In an ideal case existing CSP ﬁlters and LDA classiﬁers could be used to start the feedback phase of the new session immediately, without the need to collect new calibration data. [sent-177, score-0.422]
</p><p>77 While the ordinary CSP method uses half of the new session for training, the three methods HIST, PROTO and CONCAT exclusively use historic data for the calculation of CSP ﬁlters and LDA. [sent-204, score-0.483]
</p><p>78 For subjects al, ay and ch its result is even comparable to that of ordinary CSP. [sent-208, score-0.301]
</p><p>79 The three methods HIST, PROTO and CONCAT clearly outperform ordinary CSP. [sent-211, score-0.119]
</p><p>80 Interestingly the best zero-training method CONCAT is only outperformed by ordinary CSP if the latter has a head start of 30 trials per class. [sent-212, score-0.191]
</p><p>81 For subjects al, ay and ch, the classiﬁcation error of CONCAT is of the same magnitude as the ordinary (training-based) CSP-approach. [sent-215, score-0.26]
</p><p>82 Another way to at least reduce the necessary preparation time for a new experimental session is to record only very few new trials and combine them with data from previous sessions in order to get a quicker start. [sent-218, score-0.513]
</p><p>83 We simulate this strategy by allowing the new methods HIST, PROTO and CONCAT to take a look also on the ﬁrst 10, 20 or 30 trials per class of the new session. [sent-219, score-0.072]
</p><p>84 Here the inﬂuence of the number of initial training trials becomes visible. [sent-223, score-0.097]
</p><p>85 If no new data is available, the ordinary classiﬁcation approach of course can not produce any output, whereas the history-based methods, e. [sent-224, score-0.119]
</p><p>86 All methods gain performance in terms of smaller test errors as more and more trials are added. [sent-227, score-0.072]
</p><p>87 Only after training on at least 30 trials per class, ordinary CSP reaches the classiﬁcation level that CONCAT had already shown without any training data of the current session. [sent-228, score-0.241]
</p><p>88 5 shows some prototypical CSP ﬁlters as detected by IBICA clustering for subject al and left hand vs. [sent-230, score-0.268]
</p><p>89 , many entries are close to 0), and the few large entries are located on neurophysiologically important areas: Filters 1–2 and 4–6 cover the motor cortices corresponding to imagined hand movements, while ﬁlter 3 focuses on the central foot area. [sent-234, score-0.256]
</p><p>90 This shows that the cluster centers are spatial ﬁlters that meet our neurophysiological ex-  CSP Prototype Filters 0. [sent-235, score-0.093]
</p><p>91 BBCI) recently aquired the ability to dispense with extensive subject training and now allow to infer a blueprint of the subject’s volition from a short calibration session of approximately 30 min. [sent-241, score-0.491]
</p><p>92 The next step along this line to make BCI more practical is to strive for zero calibration time. [sent-243, score-0.139]
</p><p>93 Note that the construction of a classiﬁer that is invariant against session to session changes, say, due to different vigilance, focus or motor imagination across sessions is a hard task. [sent-245, score-0.811]
</p><p>94 Our contribution shows that experienced BCI subjects do not necessarily need to perform a new calibration period in a new experiment. [sent-246, score-0.258]
</p><p>95 Finding clusters of CSP parameters for old sessions, novel prototypical CSP ﬁlters can be derived, for which the neurophysiological validity could be shown exemplarily. [sent-248, score-0.089]
</p><p>96 This means that experienced subjects are predictable to an extent that they do not require calibration anymore. [sent-250, score-0.258]
</p><p>97 hand selecting the ﬁlters for PROTO, by adjusting for the distribution changes in the new session, e. [sent-253, score-0.053]
</p><p>98 Sajda, “Linear spatial integration for single trial detection in encephalography”, NeuroImage, 7(1): 223–230, 2002. [sent-325, score-0.065]
</p><p>99 Curio, “The Berlin Brain-Computer Interface: EEG-based communication without subject training”, IEEE Trans. [sent-346, score-0.063]
</p><p>100 Pfurtscheller, “Optimal spatial ﬁltering of single trial EEG during imagined hand movement”, IEEE Trans. [sent-377, score-0.167]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('csp', 0.703), ('session', 0.264), ('lters', 0.254), ('bci', 0.205), ('sessions', 0.177), ('eeg', 0.162), ('concat', 0.154), ('calibration', 0.139), ('lda', 0.124), ('ordinary', 0.119), ('ller', 0.089), ('foot', 0.089), ('subjects', 0.088), ('ibica', 0.084), ('proto', 0.084), ('blankertz', 0.078), ('prototypes', 0.074), ('trials', 0.072), ('prototypical', 0.068), ('curio', 0.067), ('dornhege', 0.067), ('motor', 0.065), ('subject', 0.063), ('imagery', 0.062), ('hist', 0.061), ('filters', 0.056), ('ay', 0.053), ('hand', 0.053), ('channels', 0.051), ('imagined', 0.049), ('historic', 0.049), ('classi', 0.048), ('eog', 0.042), ('meinecke', 0.042), ('movement', 0.042), ('imagination', 0.041), ('ch', 0.041), ('pfurtscheller', 0.039), ('concatenation', 0.037), ('signals', 0.037), ('harmeling', 0.037), ('mds', 0.037), ('krauledat', 0.037), ('interfaces', 0.035), ('trial', 0.034), ('rhythm', 0.033), ('emg', 0.033), ('berlin', 0.033), ('interface', 0.032), ('eigenvalues', 0.031), ('birbaumer', 0.031), ('scalp', 0.031), ('experienced', 0.031), ('spatial', 0.031), ('hz', 0.031), ('al', 0.03), ('exclusively', 0.029), ('detected', 0.028), ('bbci', 0.028), ('dendrogram', 0.028), ('transfering', 0.028), ('historical', 0.028), ('distance', 0.027), ('variance', 0.027), ('row', 0.026), ('ers', 0.026), ('left', 0.026), ('brain', 0.026), ('prototype', 0.026), ('lr', 0.026), ('training', 0.025), ('attenuated', 0.024), ('individualized', 0.024), ('matthews', 0.024), ('scatterplot', 0.024), ('hinterberger', 0.024), ('losch', 0.024), ('hypersphere', 0.024), ('cox', 0.024), ('di', 0.024), ('lter', 0.023), ('half', 0.022), ('movements', 0.022), ('aw', 0.022), ('ramoser', 0.022), ('centers', 0.021), ('ltered', 0.021), ('neurophysiological', 0.021), ('interfacing', 0.021), ('schr', 0.021), ('magenta', 0.021), ('side', 0.02), ('er', 0.02), ('cluster', 0.02), ('ica', 0.02), ('robust', 0.02), ('lf', 0.02), ('desynchronization', 0.02), ('phase', 0.019), ('validation', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999923 <a title="168-tfidf-1" href="./nips-2006-Reducing_Calibration_Time_For_Brain-Computer_Interfaces%3A_A_Clustering_Approach.html">168 nips-2006-Reducing Calibration Time For Brain-Computer Interfaces: A Clustering Approach</a></p>
<p>Author: Matthias Krauledat, Michael Schröder, Benjamin Blankertz, Klaus-Robert Müller</p><p>Abstract: Up to now even subjects that are experts in the use of machine learning based BCI systems still have to undergo a calibration session of about 20-30 min. From this data their (movement) intentions are so far infered. We now propose a new paradigm that allows to completely omit such calibration and instead transfer knowledge from prior sessions. To achieve this goal we ﬁrst deﬁne normalized CSP features and distances in-between. Second, we derive prototypical features across sessions: (a) by clustering or (b) by feature concatenation methods. Finally, we construct a classiﬁer based on these individualized prototypes and show that, indeed, classiﬁers can be successfully transferred to a new session for a number of subjects.</p><p>2 0.66387022 <a title="168-tfidf-2" href="./nips-2006-Logistic_Regression_for_Single_Trial_EEG_Classification.html">126 nips-2006-Logistic Regression for Single Trial EEG Classification</a></p>
<p>Author: Ryota Tomioka, Kazuyuki Aihara, Klaus-Robert Müller</p><p>Abstract: We propose a novel framework for the classiﬁcation of single trial ElectroEncephaloGraphy (EEG), based on regularized logistic regression. Framed in this robust statistical framework no prior feature extraction or outlier removal is required. We present two variations of parameterizing the regression function: (a) with a full rank symmetric matrix coeﬃcient and (b) as a diﬀerence of two rank=1 matrices. In the ﬁrst case, the problem is convex and the logistic regression is optimal under a generative model. The latter case is shown to be related to the Common Spatial Pattern (CSP) algorithm, which is a popular technique in Brain Computer Interfacing. The regression coeﬃcients can also be topographically mapped onto the scalp similarly to CSP projections, which allows neuro-physiological interpretation. Simulations on 162 BCI datasets demonstrate that classiﬁcation accuracy and robustness compares favorably against conventional CSP based classiﬁers. 1</p><p>3 0.31891742 <a title="168-tfidf-3" href="./nips-2006-Adaptive_Spatial_Filters_with_predefined_Region_of_Interest_for_EEG_based_Brain-Computer-Interfaces.html">22 nips-2006-Adaptive Spatial Filters with predefined Region of Interest for EEG based Brain-Computer-Interfaces</a></p>
<p>Author: Moritz Grosse-wentrup, Klaus Gramann, Martin Buss</p><p>Abstract: The performance of EEG-based Brain-Computer-Interfaces (BCIs) critically depends on the extraction of features from the EEG carrying information relevant for the classiﬁcation of different mental states. For BCIs employing imaginary movements of different limbs, the method of Common Spatial Patterns (CSP) has been shown to achieve excellent classiﬁcation results. The CSP-algorithm however suffers from a lack of robustness, requiring training data without artifacts for good performance. To overcome this lack of robustness, we propose an adaptive spatial ﬁlter that replaces the training data in the CSP approach by a-priori information. More speciﬁcally, we design an adaptive spatial ﬁlter that maximizes the ratio of the variance of the electric ﬁeld originating in a predeﬁned region of interest (ROI) and the overall variance of the measured EEG. Since it is known that the component of the EEG used for discriminating imaginary movements originates in the motor cortex, we design two adaptive spatial ﬁlters with the ROIs centered in the hand areas of the left and right motor cortex. We then use these to classify EEG data recorded during imaginary movements of the right and left hand of three subjects, and show that the adaptive spatial ﬁlters outperform the CSP-algorithm, enabling classiﬁcation rates of up to 94.7 % without artifact rejection. 1</p><p>4 0.14698458 <a title="168-tfidf-4" href="./nips-2006-Aggregating_Classification_Accuracy_across_Time%3A_Application_to_Single_Trial_EEG.html">24 nips-2006-Aggregating Classification Accuracy across Time: Application to Single Trial EEG</a></p>
<p>Author: Steven Lemm, Christin Schäfer, Gabriel Curio</p><p>Abstract: We present a method for binary on-line classiﬁcation of triggered but temporally blurred events that are embedded in noisy time series in the context of on-line discrimination between left and right imaginary hand-movement. In particular the goal of the binary classiﬁcation problem is to obtain the decision, as fast and as reliably as possible from the recorded EEG single trials. To provide a probabilistic decision at every time-point t the presented method gathers information from two distinct sequences of features across time. In order to incorporate decisions from prior time-points we suggest an appropriate weighting scheme, that emphasizes time instances, providing a higher discriminatory power between the instantaneous class distributions of each feature, where the discriminatory power is quantiﬁed in terms of the Bayes error of misclassiﬁcation. The eﬀectiveness of this procedure is veriﬁed by its successful application in the 3rd BCI competition. Disclosure of the data after the competition revealed this approach to be superior with single trial error rates as low as 10.7, 11.5 and 16.7% for the three diﬀerent subjects under study. 1</p><p>5 0.063331589 <a title="168-tfidf-5" href="./nips-2006-Nonlinear_physically-based_models_for_decoding_motor-cortical_population_activity.html">148 nips-2006-Nonlinear physically-based models for decoding motor-cortical population activity</a></p>
<p>Author: Gregory Shakhnarovich, Sung-phil Kim, Michael J. Black</p><p>Abstract: Neural motor prostheses (NMPs) require the accurate decoding of motor cortical population activity for the control of an artiﬁcial motor system. Previous work on cortical decoding for NMPs has focused on the recovery of hand kinematics. Human NMPs however may require the control of computer cursors or robotic devices with very different physical and dynamical properties. Here we show that the ﬁring rates of cells in the primary motor cortex of non-human primates can be used to control the parameters of an artiﬁcial physical system exhibiting realistic dynamics. The model represents 2D hand motion in terms of a point mass connected to a system of idealized springs. The nonlinear spring coefﬁcients are estimated from the ﬁring rates of neurons in the motor cortex. We evaluate linear and a nonlinear decoding algorithms using neural recordings from two monkeys performing two different tasks. We found that the decoded spring coefﬁcients produced accurate hand trajectories compared with state-of-the-art methods for direct decoding of hand kinematics. Furthermore, using a physically-based system produced decoded movements that were more “natural” in that their frequency spectrum more closely matched that of natural hand movements. 1</p><p>6 0.058070563 <a title="168-tfidf-6" href="./nips-2006-Emergence_of_conjunctive_visual_features_by_quadratic_independent_component_analysis.html">76 nips-2006-Emergence of conjunctive visual features by quadratic independent component analysis</a></p>
<p>7 0.058011353 <a title="168-tfidf-7" href="./nips-2006-A_Nonparametric_Approach_to_Bottom-Up_Visual_Saliency.html">8 nips-2006-A Nonparametric Approach to Bottom-Up Visual Saliency</a></p>
<p>8 0.057923026 <a title="168-tfidf-8" href="./nips-2006-Efficient_Learning_of_Sparse_Representations_with_an_Energy-Based_Model.html">72 nips-2006-Efficient Learning of Sparse Representations with an Energy-Based Model</a></p>
<p>9 0.0535492 <a title="168-tfidf-9" href="./nips-2006-Effects_of_Stress_and_Genotype_on_Meta-parameter_Dynamics_in_Reinforcement_Learning.html">71 nips-2006-Effects of Stress and Genotype on Meta-parameter Dynamics in Reinforcement Learning</a></p>
<p>10 0.053271499 <a title="168-tfidf-10" href="./nips-2006-Context_Effects_in_Category_Learning%3A_An_Investigation_of_Four_Probabilistic_Models.html">58 nips-2006-Context Effects in Category Learning: An Investigation of Four Probabilistic Models</a></p>
<p>11 0.052203566 <a title="168-tfidf-11" href="./nips-2006-Temporal_and_Cross-Subject_Probabilistic_Models_for_fMRI_Prediction_Tasks.html">188 nips-2006-Temporal and Cross-Subject Probabilistic Models for fMRI Prediction Tasks</a></p>
<p>12 0.048295807 <a title="168-tfidf-12" href="./nips-2006-Sparse_Representation_for_Signal_Classification.html">179 nips-2006-Sparse Representation for Signal Classification</a></p>
<p>13 0.048030626 <a title="168-tfidf-13" href="./nips-2006-Detecting_Humans_via_Their_Pose.html">66 nips-2006-Detecting Humans via Their Pose</a></p>
<p>14 0.044116627 <a title="168-tfidf-14" href="./nips-2006-Multiple_timescales_and_uncertainty_in_motor_adaptation.html">141 nips-2006-Multiple timescales and uncertainty in motor adaptation</a></p>
<p>15 0.042075872 <a title="168-tfidf-15" href="./nips-2006-Modeling_General_and_Specific_Aspects_of_Documents_with_a_Probabilistic_Topic_Model.html">133 nips-2006-Modeling General and Specific Aspects of Documents with a Probabilistic Topic Model</a></p>
<p>16 0.042002957 <a title="168-tfidf-16" href="./nips-2006-A_Probabilistic_Algorithm_Integrating_Source_Localization_and_Noise_Suppression_of_MEG_and_EEG_data.html">12 nips-2006-A Probabilistic Algorithm Integrating Source Localization and Noise Suppression of MEG and EEG data</a></p>
<p>17 0.040428616 <a title="168-tfidf-17" href="./nips-2006-Causal_inference_in_sensorimotor_integration.html">49 nips-2006-Causal inference in sensorimotor integration</a></p>
<p>18 0.039442625 <a title="168-tfidf-18" href="./nips-2006-Blind_source_separation_for_over-determined_delayed_mixtures.html">46 nips-2006-Blind source separation for over-determined delayed mixtures</a></p>
<p>19 0.039351489 <a title="168-tfidf-19" href="./nips-2006-Learning_Structural_Equation_Models_for_fMRI.html">113 nips-2006-Learning Structural Equation Models for fMRI</a></p>
<p>20 0.038632859 <a title="168-tfidf-20" href="./nips-2006-Inducing_Metric_Violations_in_Human_Similarity_Judgements.html">97 nips-2006-Inducing Metric Violations in Human Similarity Judgements</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2006_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.145), (1, -0.017), (2, 0.146), (3, -0.095), (4, -0.607), (5, -0.148), (6, -0.017), (7, 0.302), (8, 0.122), (9, -0.12), (10, -0.012), (11, -0.009), (12, 0.133), (13, 0.101), (14, -0.042), (15, 0.102), (16, -0.174), (17, 0.036), (18, 0.07), (19, -0.03), (20, -0.046), (21, 0.017), (22, 0.001), (23, 0.009), (24, -0.02), (25, -0.017), (26, 0.025), (27, 0.006), (28, -0.017), (29, 0.01), (30, 0.041), (31, 0.054), (32, -0.117), (33, 0.073), (34, 0.083), (35, -0.026), (36, -0.024), (37, 0.046), (38, -0.013), (39, 0.085), (40, 0.032), (41, 0.044), (42, 0.0), (43, 0.032), (44, 0.012), (45, -0.089), (46, 0.032), (47, -0.023), (48, -0.036), (49, 0.008)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96984977 <a title="168-lsi-1" href="./nips-2006-Reducing_Calibration_Time_For_Brain-Computer_Interfaces%3A_A_Clustering_Approach.html">168 nips-2006-Reducing Calibration Time For Brain-Computer Interfaces: A Clustering Approach</a></p>
<p>Author: Matthias Krauledat, Michael Schröder, Benjamin Blankertz, Klaus-Robert Müller</p><p>Abstract: Up to now even subjects that are experts in the use of machine learning based BCI systems still have to undergo a calibration session of about 20-30 min. From this data their (movement) intentions are so far infered. We now propose a new paradigm that allows to completely omit such calibration and instead transfer knowledge from prior sessions. To achieve this goal we ﬁrst deﬁne normalized CSP features and distances in-between. Second, we derive prototypical features across sessions: (a) by clustering or (b) by feature concatenation methods. Finally, we construct a classiﬁer based on these individualized prototypes and show that, indeed, classiﬁers can be successfully transferred to a new session for a number of subjects.</p><p>2 0.88434267 <a title="168-lsi-2" href="./nips-2006-Logistic_Regression_for_Single_Trial_EEG_Classification.html">126 nips-2006-Logistic Regression for Single Trial EEG Classification</a></p>
<p>Author: Ryota Tomioka, Kazuyuki Aihara, Klaus-Robert Müller</p><p>Abstract: We propose a novel framework for the classiﬁcation of single trial ElectroEncephaloGraphy (EEG), based on regularized logistic regression. Framed in this robust statistical framework no prior feature extraction or outlier removal is required. We present two variations of parameterizing the regression function: (a) with a full rank symmetric matrix coeﬃcient and (b) as a diﬀerence of two rank=1 matrices. In the ﬁrst case, the problem is convex and the logistic regression is optimal under a generative model. The latter case is shown to be related to the Common Spatial Pattern (CSP) algorithm, which is a popular technique in Brain Computer Interfacing. The regression coeﬃcients can also be topographically mapped onto the scalp similarly to CSP projections, which allows neuro-physiological interpretation. Simulations on 162 BCI datasets demonstrate that classiﬁcation accuracy and robustness compares favorably against conventional CSP based classiﬁers. 1</p><p>3 0.82279634 <a title="168-lsi-3" href="./nips-2006-Adaptive_Spatial_Filters_with_predefined_Region_of_Interest_for_EEG_based_Brain-Computer-Interfaces.html">22 nips-2006-Adaptive Spatial Filters with predefined Region of Interest for EEG based Brain-Computer-Interfaces</a></p>
<p>Author: Moritz Grosse-wentrup, Klaus Gramann, Martin Buss</p><p>Abstract: The performance of EEG-based Brain-Computer-Interfaces (BCIs) critically depends on the extraction of features from the EEG carrying information relevant for the classiﬁcation of different mental states. For BCIs employing imaginary movements of different limbs, the method of Common Spatial Patterns (CSP) has been shown to achieve excellent classiﬁcation results. The CSP-algorithm however suffers from a lack of robustness, requiring training data without artifacts for good performance. To overcome this lack of robustness, we propose an adaptive spatial ﬁlter that replaces the training data in the CSP approach by a-priori information. More speciﬁcally, we design an adaptive spatial ﬁlter that maximizes the ratio of the variance of the electric ﬁeld originating in a predeﬁned region of interest (ROI) and the overall variance of the measured EEG. Since it is known that the component of the EEG used for discriminating imaginary movements originates in the motor cortex, we design two adaptive spatial ﬁlters with the ROIs centered in the hand areas of the left and right motor cortex. We then use these to classify EEG data recorded during imaginary movements of the right and left hand of three subjects, and show that the adaptive spatial ﬁlters outperform the CSP-algorithm, enabling classiﬁcation rates of up to 94.7 % without artifact rejection. 1</p><p>4 0.58574593 <a title="168-lsi-4" href="./nips-2006-Aggregating_Classification_Accuracy_across_Time%3A_Application_to_Single_Trial_EEG.html">24 nips-2006-Aggregating Classification Accuracy across Time: Application to Single Trial EEG</a></p>
<p>Author: Steven Lemm, Christin Schäfer, Gabriel Curio</p><p>Abstract: We present a method for binary on-line classiﬁcation of triggered but temporally blurred events that are embedded in noisy time series in the context of on-line discrimination between left and right imaginary hand-movement. In particular the goal of the binary classiﬁcation problem is to obtain the decision, as fast and as reliably as possible from the recorded EEG single trials. To provide a probabilistic decision at every time-point t the presented method gathers information from two distinct sequences of features across time. In order to incorporate decisions from prior time-points we suggest an appropriate weighting scheme, that emphasizes time instances, providing a higher discriminatory power between the instantaneous class distributions of each feature, where the discriminatory power is quantiﬁed in terms of the Bayes error of misclassiﬁcation. The eﬀectiveness of this procedure is veriﬁed by its successful application in the 3rd BCI competition. Disclosure of the data after the competition revealed this approach to be superior with single trial error rates as low as 10.7, 11.5 and 16.7% for the three diﬀerent subjects under study. 1</p><p>5 0.20269819 <a title="168-lsi-5" href="./nips-2006-Nonlinear_physically-based_models_for_decoding_motor-cortical_population_activity.html">148 nips-2006-Nonlinear physically-based models for decoding motor-cortical population activity</a></p>
<p>Author: Gregory Shakhnarovich, Sung-phil Kim, Michael J. Black</p><p>Abstract: Neural motor prostheses (NMPs) require the accurate decoding of motor cortical population activity for the control of an artiﬁcial motor system. Previous work on cortical decoding for NMPs has focused on the recovery of hand kinematics. Human NMPs however may require the control of computer cursors or robotic devices with very different physical and dynamical properties. Here we show that the ﬁring rates of cells in the primary motor cortex of non-human primates can be used to control the parameters of an artiﬁcial physical system exhibiting realistic dynamics. The model represents 2D hand motion in terms of a point mass connected to a system of idealized springs. The nonlinear spring coefﬁcients are estimated from the ﬁring rates of neurons in the motor cortex. We evaluate linear and a nonlinear decoding algorithms using neural recordings from two monkeys performing two different tasks. We found that the decoded spring coefﬁcients produced accurate hand trajectories compared with state-of-the-art methods for direct decoding of hand kinematics. Furthermore, using a physically-based system produced decoded movements that were more “natural” in that their frequency spectrum more closely matched that of natural hand movements. 1</p><p>6 0.19443433 <a title="168-lsi-6" href="./nips-2006-Efficient_Learning_of_Sparse_Representations_with_an_Energy-Based_Model.html">72 nips-2006-Efficient Learning of Sparse Representations with an Energy-Based Model</a></p>
<p>7 0.18188532 <a title="168-lsi-7" href="./nips-2006-Sparse_Multinomial_Logistic_Regression_via_Bayesian_L1_Regularisation.html">178 nips-2006-Sparse Multinomial Logistic Regression via Bayesian L1 Regularisation</a></p>
<p>8 0.167119 <a title="168-lsi-8" href="./nips-2006-Ordinal_Regression_by_Extended_Binary_Classification.html">156 nips-2006-Ordinal Regression by Extended Binary Classification</a></p>
<p>9 0.16110633 <a title="168-lsi-9" href="./nips-2006-Sparse_Representation_for_Signal_Classification.html">179 nips-2006-Sparse Representation for Signal Classification</a></p>
<p>10 0.16075109 <a title="168-lsi-10" href="./nips-2006-Emergence_of_conjunctive_visual_features_by_quadratic_independent_component_analysis.html">76 nips-2006-Emergence of conjunctive visual features by quadratic independent component analysis</a></p>
<p>11 0.16069974 <a title="168-lsi-11" href="./nips-2006-Context_Effects_in_Category_Learning%3A_An_Investigation_of_Four_Probabilistic_Models.html">58 nips-2006-Context Effects in Category Learning: An Investigation of Four Probabilistic Models</a></p>
<p>12 0.15474975 <a title="168-lsi-12" href="./nips-2006-Efficient_Methods_for_Privacy_Preserving_Face_Detection.html">73 nips-2006-Efficient Methods for Privacy Preserving Face Detection</a></p>
<p>13 0.1533339 <a title="168-lsi-13" href="./nips-2006-Inducing_Metric_Violations_in_Human_Similarity_Judgements.html">97 nips-2006-Inducing Metric Violations in Human Similarity Judgements</a></p>
<p>14 0.15122272 <a title="168-lsi-14" href="./nips-2006-Map-Reduce_for_Machine_Learning_on_Multicore.html">129 nips-2006-Map-Reduce for Machine Learning on Multicore</a></p>
<p>15 0.14981754 <a title="168-lsi-15" href="./nips-2006-Statistical_Modeling_of_Images_with_Fields_of_Gaussian_Scale_Mixtures.html">182 nips-2006-Statistical Modeling of Images with Fields of Gaussian Scale Mixtures</a></p>
<p>16 0.14642768 <a title="168-lsi-16" href="./nips-2006-Temporal_and_Cross-Subject_Probabilistic_Models_for_fMRI_Prediction_Tasks.html">188 nips-2006-Temporal and Cross-Subject Probabilistic Models for fMRI Prediction Tasks</a></p>
<p>17 0.13838597 <a title="168-lsi-17" href="./nips-2006-Learnability_and_the_doubling_dimension.html">109 nips-2006-Learnability and the doubling dimension</a></p>
<p>18 0.13460085 <a title="168-lsi-18" href="./nips-2006-Tighter_PAC-Bayes_Bounds.html">193 nips-2006-Tighter PAC-Bayes Bounds</a></p>
<p>19 0.13130929 <a title="168-lsi-19" href="./nips-2006-Large_Margin_Component_Analysis.html">105 nips-2006-Large Margin Component Analysis</a></p>
<p>20 0.13063188 <a title="168-lsi-20" href="./nips-2006-Detecting_Humans_via_Their_Pose.html">66 nips-2006-Detecting Humans via Their Pose</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2006_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(1, 0.092), (3, 0.023), (7, 0.049), (9, 0.039), (12, 0.01), (13, 0.146), (20, 0.017), (22, 0.067), (34, 0.023), (35, 0.171), (44, 0.06), (57, 0.058), (65, 0.03), (69, 0.015), (71, 0.017), (90, 0.01), (95, 0.04), (98, 0.041)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.80468374 <a title="168-lda-1" href="./nips-2006-Reducing_Calibration_Time_For_Brain-Computer_Interfaces%3A_A_Clustering_Approach.html">168 nips-2006-Reducing Calibration Time For Brain-Computer Interfaces: A Clustering Approach</a></p>
<p>Author: Matthias Krauledat, Michael Schröder, Benjamin Blankertz, Klaus-Robert Müller</p><p>Abstract: Up to now even subjects that are experts in the use of machine learning based BCI systems still have to undergo a calibration session of about 20-30 min. From this data their (movement) intentions are so far infered. We now propose a new paradigm that allows to completely omit such calibration and instead transfer knowledge from prior sessions. To achieve this goal we ﬁrst deﬁne normalized CSP features and distances in-between. Second, we derive prototypical features across sessions: (a) by clustering or (b) by feature concatenation methods. Finally, we construct a classiﬁer based on these individualized prototypes and show that, indeed, classiﬁers can be successfully transferred to a new session for a number of subjects.</p><p>2 0.69633079 <a title="168-lda-2" href="./nips-2006-Learning_Motion_Style_Synthesis_from_Perceptual_Observations.html">111 nips-2006-Learning Motion Style Synthesis from Perceptual Observations</a></p>
<p>Author: Lorenzo Torresani, Peggy Hackney, Christoph Bregler</p><p>Abstract: This paper presents an algorithm for synthesis of human motion in speciﬁed styles. We use a theory of movement observation (Laban Movement Analysis) to describe movement styles as points in a multi-dimensional perceptual space. We cast the task of learning to synthesize desired movement styles as a regression problem: sequences generated via space-time interpolation of motion capture data are used to learn a nonlinear mapping between animation parameters and movement styles in perceptual space. We demonstrate that the learned model can apply a variety of motion styles to pre-recorded motion sequences and it can extrapolate styles not originally included in the training data. 1</p><p>3 0.69436663 <a title="168-lda-3" href="./nips-2006-Logistic_Regression_for_Single_Trial_EEG_Classification.html">126 nips-2006-Logistic Regression for Single Trial EEG Classification</a></p>
<p>Author: Ryota Tomioka, Kazuyuki Aihara, Klaus-Robert Müller</p><p>Abstract: We propose a novel framework for the classiﬁcation of single trial ElectroEncephaloGraphy (EEG), based on regularized logistic regression. Framed in this robust statistical framework no prior feature extraction or outlier removal is required. We present two variations of parameterizing the regression function: (a) with a full rank symmetric matrix coeﬃcient and (b) as a diﬀerence of two rank=1 matrices. In the ﬁrst case, the problem is convex and the logistic regression is optimal under a generative model. The latter case is shown to be related to the Common Spatial Pattern (CSP) algorithm, which is a popular technique in Brain Computer Interfacing. The regression coeﬃcients can also be topographically mapped onto the scalp similarly to CSP projections, which allows neuro-physiological interpretation. Simulations on 162 BCI datasets demonstrate that classiﬁcation accuracy and robustness compares favorably against conventional CSP based classiﬁers. 1</p><p>4 0.67242569 <a title="168-lda-4" href="./nips-2006-Fast_Iterative_Kernel_PCA.html">79 nips-2006-Fast Iterative Kernel PCA</a></p>
<p>Author: Nicol N. Schraudolph, Simon Günter, S.v.n. Vishwanathan</p><p>Abstract: We introduce two methods to improve convergence of the Kernel Hebbian Algorithm (KHA) for iterative kernel PCA. KHA has a scalar gain parameter which is either held constant or decreased as 1/t, leading to slow convergence. Our KHA/et algorithm accelerates KHA by incorporating the reciprocal of the current estimated eigenvalues as a gain vector. We then derive and apply Stochastic MetaDescent (SMD) to KHA/et; this further speeds convergence by performing gain adaptation in RKHS. Experimental results for kernel PCA and spectral clustering of USPS digits as well as motion capture and image de-noising problems conﬁrm that our methods converge substantially faster than conventional KHA. 1</p><p>5 0.66325033 <a title="168-lda-5" href="./nips-2006-Bayesian_Model_Scoring_in_Markov_Random_Fields.html">43 nips-2006-Bayesian Model Scoring in Markov Random Fields</a></p>
<p>Author: Sridevi Parise, Max Welling</p><p>Abstract: Scoring structures of undirected graphical models by means of evaluating the marginal likelihood is very hard. The main reason is the presence of the partition function which is intractable to evaluate, let alone integrate over. We propose to approximate the marginal likelihood by employing two levels of approximation: we assume normality of the posterior (the Laplace approximation) and approximate all remaining intractable quantities using belief propagation and the linear response approximation. This results in a fast procedure for model scoring. Empirically, we ﬁnd that our procedure has about two orders of magnitude better accuracy than standard BIC methods for small datasets, but deteriorates when the size of the dataset grows. 1</p><p>6 0.58529443 <a title="168-lda-6" href="./nips-2006-Aggregating_Classification_Accuracy_across_Time%3A_Application_to_Single_Trial_EEG.html">24 nips-2006-Aggregating Classification Accuracy across Time: Application to Single Trial EEG</a></p>
<p>7 0.58179522 <a title="168-lda-7" href="./nips-2006-Adaptive_Spatial_Filters_with_predefined_Region_of_Interest_for_EEG_based_Brain-Computer-Interfaces.html">22 nips-2006-Adaptive Spatial Filters with predefined Region of Interest for EEG based Brain-Computer-Interfaces</a></p>
<p>8 0.57032424 <a title="168-lda-8" href="./nips-2006-Graph_Laplacian_Regularization_for_Large-Scale_Semidefinite_Programming.html">87 nips-2006-Graph Laplacian Regularization for Large-Scale Semidefinite Programming</a></p>
<p>9 0.55745029 <a title="168-lda-9" href="./nips-2006-Generalized_Maximum_Margin_Clustering_and_Unsupervised_Kernel_Learning.html">83 nips-2006-Generalized Maximum Margin Clustering and Unsupervised Kernel Learning</a></p>
<p>10 0.55661398 <a title="168-lda-10" href="./nips-2006-Analysis_of_Empirical_Bayesian_Methods_for_Neuroelectromagnetic_Source_Localization.html">32 nips-2006-Analysis of Empirical Bayesian Methods for Neuroelectromagnetic Source Localization</a></p>
<p>11 0.55606568 <a title="168-lda-11" href="./nips-2006-Denoising_and_Dimension_Reduction_in_Feature_Space.html">65 nips-2006-Denoising and Dimension Reduction in Feature Space</a></p>
<p>12 0.55246693 <a title="168-lda-12" href="./nips-2006-Active_learning_for_misspecified_generalized_linear_models.html">20 nips-2006-Active learning for misspecified generalized linear models</a></p>
<p>13 0.55230194 <a title="168-lda-13" href="./nips-2006-Simplifying_Mixture_Models_through_Function_Approximation.html">175 nips-2006-Simplifying Mixture Models through Function Approximation</a></p>
<p>14 0.55137271 <a title="168-lda-14" href="./nips-2006-Online_Classification_for_Complex_Problems_Using_Simultaneous_Projections.html">152 nips-2006-Online Classification for Complex Problems Using Simultaneous Projections</a></p>
<p>15 0.55030102 <a title="168-lda-15" href="./nips-2006-A_Complexity-Distortion_Approach_to_Joint_Pattern_Alignment.html">3 nips-2006-A Complexity-Distortion Approach to Joint Pattern Alignment</a></p>
<p>16 0.54740995 <a title="168-lda-16" href="./nips-2006-Clustering_Under_Prior_Knowledge_with_Application_to_Image_Segmentation.html">51 nips-2006-Clustering Under Prior Knowledge with Application to Image Segmentation</a></p>
<p>17 0.54713839 <a title="168-lda-17" href="./nips-2006-Real-time_adaptive_information-theoretic_optimization_of_neurophysiology_experiments.html">165 nips-2006-Real-time adaptive information-theoretic optimization of neurophysiology experiments</a></p>
<p>18 0.54332721 <a title="168-lda-18" href="./nips-2006-Training_Conditional_Random_Fields_for_Maximum_Labelwise_Accuracy.html">195 nips-2006-Training Conditional Random Fields for Maximum Labelwise Accuracy</a></p>
<p>19 0.54084939 <a title="168-lda-19" href="./nips-2006-MLLE%3A_Modified_Locally_Linear_Embedding_Using_Multiple_Weights.html">127 nips-2006-MLLE: Modified Locally Linear Embedding Using Multiple Weights</a></p>
<p>20 0.54068273 <a title="168-lda-20" href="./nips-2006-Convex_Repeated_Games_and_Fenchel_Duality.html">61 nips-2006-Convex Repeated Games and Fenchel Duality</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
