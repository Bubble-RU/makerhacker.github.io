<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>74 nips-2006-Efficient Structure Learning of Markov Networks using $L 1$-Regularization</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-74" href="#">nips2006-74</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>74 nips-2006-Efficient Structure Learning of Markov Networks using $L 1$-Regularization</h1>
<br/><p>Source: <a title="nips-2006-74-pdf" href="http://papers.nips.cc/paper/3003-efficient-structure-learning-of-markov-networks-using-l_1-regularization.pdf">pdf</a></p><p>Author: Su-in Lee, Varun Ganapathi, Daphne Koller</p><p>Abstract: Markov networks are commonly used in a wide variety of applications, ranging from computer vision, to natural language, to computational biology. In most current applications, even those that rely heavily on learned models, the structure of the Markov network is constructed by hand, due to the lack of effective algorithms for learning Markov network structure from data. In this paper, we provide a computationally efﬁcient method for learning Markov network structure from data. Our method is based on the use of L1 regularization on the weights of the log-linear model, which has the effect of biasing the model towards solutions where many of the parameters are zero. This formulation converts the Markov network learning problem into a convex optimization problem in a continuous space, which can be solved using efﬁcient gradient methods. A key issue in this setting is the (unavoidable) use of approximate inference, which can lead to errors in the gradient computation when the network structure is dense. Thus, we explore the use of different feature introduction schemes and compare their performance. We provide results for our method on synthetic data, and on two real world data sets: pixel values in the MNIST data, and genetic sequence variations in the human HapMap data. We show that our L1 -based method achieves considerably higher generalization performance than the more standard L2 -based method (a Gaussian parameter prior) or pure maximum-likelihood learning. We also show that we can learn MRF network structure at a computational cost that is not much greater than learning parameters alone, demonstrating the existence of a feasible method for this important problem.</p><p>Reference: <a title="nips-2006-74-reference" href="../nips2006_reference/nips-2006-Efficient_Structure_Learning_of_Markov_Networks_using_%24L_1%24-Regularization_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('fk', 0.401), ('feat', 0.267), ('hapmap', 0.213), ('cmll', 0.21), ('network', 0.177), ('graft', 0.166), ('pietr', 0.166), ('markov', 0.164), ('dell', 0.155), ('inact', 0.152), ('bp', 0.146), ('perkin', 0.139), ('gain', 0.137), ('grady', 0.137), ('inf', 0.137), ('synthet', 0.116), ('heur', 0.113), ('genet', 0.112), ('structure', 0.109), ('mrf', 0.106)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="74-tfidf-1" href="./nips-2006-Efficient_Structure_Learning_of_Markov_Networks_using_%24L_1%24-Regularization.html">74 nips-2006-Efficient Structure Learning of Markov Networks using $L 1$-Regularization</a></p>
<p>2 0.17389789 <a title="74-tfidf-2" href="./nips-2006-Using_Combinatorial_Optimization_within_Max-Product_Belief_Propagation.html">201 nips-2006-Using Combinatorial Optimization within Max-Product Belief Propagation</a></p>
<p>3 0.15860194 <a title="74-tfidf-3" href="./nips-2006-A_Nonparametric_Bayesian_Method_for_Inferring_Features_From_Similarity_Judgments.html">9 nips-2006-A Nonparametric Bayesian Method for Inferring Features From Similarity Judgments</a></p>
<p>4 0.14307283 <a title="74-tfidf-4" href="./nips-2006-Unsupervised_Learning_of_a_Probabilistic_Grammar_for_Object_Detection_and_Parsing.html">199 nips-2006-Unsupervised Learning of a Probabilistic Grammar for Object Detection and Parsing</a></p>
<p>5 0.14099264 <a title="74-tfidf-5" href="./nips-2006-Bayesian_Model_Scoring_in_Markov_Random_Fields.html">43 nips-2006-Bayesian Model Scoring in Markov Random Fields</a></p>
<p>6 0.1321687 <a title="74-tfidf-6" href="./nips-2006-Distributed_Inference_in_Dynamical_Systems.html">69 nips-2006-Distributed Inference in Dynamical Systems</a></p>
<p>7 0.12586235 <a title="74-tfidf-7" href="./nips-2006-Max-margin_classification_of_incomplete_data.html">130 nips-2006-Max-margin classification of incomplete data</a></p>
<p>8 0.11815716 <a title="74-tfidf-8" href="./nips-2006-Scalable_Discriminative_Learning_for_Natural_Language_Parsing_and_Translation.html">172 nips-2006-Scalable Discriminative Learning for Natural Language Parsing and Translation</a></p>
<p>9 0.11779001 <a title="74-tfidf-9" href="./nips-2006-Approximate_inference_using_planar_graph_decomposition.html">35 nips-2006-Approximate inference using planar graph decomposition</a></p>
<p>10 0.11392669 <a title="74-tfidf-10" href="./nips-2006-Learning_Dense_3D_Correspondence.html">110 nips-2006-Learning Dense 3D Correspondence</a></p>
<p>11 0.11356207 <a title="74-tfidf-11" href="./nips-2006-Efficient_sparse_coding_algorithms.html">75 nips-2006-Efficient sparse coding algorithms</a></p>
<p>12 0.11278613 <a title="74-tfidf-12" href="./nips-2006-Conditional_mean_field.html">57 nips-2006-Conditional mean field</a></p>
<p>13 0.10583187 <a title="74-tfidf-13" href="./nips-2006-Efficient_Learning_of_Sparse_Representations_with_an_Energy-Based_Model.html">72 nips-2006-Efficient Learning of Sparse Representations with an Energy-Based Model</a></p>
<p>14 0.10178571 <a title="74-tfidf-14" href="./nips-2006-Modeling_Dyadic_Data_with_Binary_Latent_Factors.html">132 nips-2006-Modeling Dyadic Data with Binary Latent Factors</a></p>
<p>15 0.097071633 <a title="74-tfidf-15" href="./nips-2006-Learning_Structural_Equation_Models_for_fMRI.html">113 nips-2006-Learning Structural Equation Models for fMRI</a></p>
<p>16 0.096968882 <a title="74-tfidf-16" href="./nips-2006-Inferring_Network_Structure_from_Co-Occurrences.html">98 nips-2006-Inferring Network Structure from Co-Occurrences</a></p>
<p>17 0.096834965 <a title="74-tfidf-17" href="./nips-2006-The_Neurodynamics_of_Belief_Propagation_on_Binary_Markov_Random_Fields.html">190 nips-2006-The Neurodynamics of Belief Propagation on Binary Markov Random Fields</a></p>
<p>18 0.096663386 <a title="74-tfidf-18" href="./nips-2006-Sparse_Multinomial_Logistic_Regression_via_Bayesian_L1_Regularisation.html">178 nips-2006-Sparse Multinomial Logistic Regression via Bayesian L1 Regularisation</a></p>
<p>19 0.094626278 <a title="74-tfidf-19" href="./nips-2006-Support_Vector_Machines_on_a_Budget.html">186 nips-2006-Support Vector Machines on a Budget</a></p>
<p>20 0.092869222 <a title="74-tfidf-20" href="./nips-2006-Implicit_Surfaces_with_Globally_Regularised_and_Compactly_Supported_Basis_Functions.html">95 nips-2006-Implicit Surfaces with Globally Regularised and Compactly Supported Basis Functions</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2006_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.315), (1, -0.077), (2, 0.015), (3, -0.122), (4, -0.054), (5, 0.114), (6, 0.021), (7, -0.032), (8, -0.073), (9, -0.083), (10, 0.097), (11, -0.018), (12, -0.011), (13, -0.031), (14, 0.146), (15, 0.007), (16, 0.066), (17, 0.08), (18, 0.056), (19, -0.07), (20, -0.117), (21, 0.075), (22, -0.081), (23, -0.076), (24, -0.16), (25, 0.011), (26, 0.101), (27, 0.042), (28, 0.032), (29, -0.022), (30, 0.072), (31, 0.039), (32, 0.046), (33, -0.019), (34, 0.114), (35, -0.027), (36, -0.113), (37, -0.019), (38, 0.037), (39, 0.076), (40, -0.08), (41, -0.065), (42, 0.065), (43, 0.019), (44, 0.044), (45, -0.023), (46, -0.044), (47, -0.016), (48, 0.039), (49, 0.042)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95430768 <a title="74-lsi-1" href="./nips-2006-Efficient_Structure_Learning_of_Markov_Networks_using_%24L_1%24-Regularization.html">74 nips-2006-Efficient Structure Learning of Markov Networks using $L 1$-Regularization</a></p>
<p>2 0.76551419 <a title="74-lsi-2" href="./nips-2006-Using_Combinatorial_Optimization_within_Max-Product_Belief_Propagation.html">201 nips-2006-Using Combinatorial Optimization within Max-Product Belief Propagation</a></p>
<p>3 0.67041969 <a title="74-lsi-3" href="./nips-2006-Max-margin_classification_of_incomplete_data.html">130 nips-2006-Max-margin classification of incomplete data</a></p>
<p>4 0.66394633 <a title="74-lsi-4" href="./nips-2006-Bayesian_Model_Scoring_in_Markov_Random_Fields.html">43 nips-2006-Bayesian Model Scoring in Markov Random Fields</a></p>
<p>5 0.65651745 <a title="74-lsi-5" href="./nips-2006-A_Nonparametric_Bayesian_Method_for_Inferring_Features_From_Similarity_Judgments.html">9 nips-2006-A Nonparametric Bayesian Method for Inferring Features From Similarity Judgments</a></p>
<p>6 0.65199417 <a title="74-lsi-6" href="./nips-2006-Unsupervised_Learning_of_a_Probabilistic_Grammar_for_Object_Detection_and_Parsing.html">199 nips-2006-Unsupervised Learning of a Probabilistic Grammar for Object Detection and Parsing</a></p>
<p>7 0.64005286 <a title="74-lsi-7" href="./nips-2006-The_Neurodynamics_of_Belief_Propagation_on_Binary_Markov_Random_Fields.html">190 nips-2006-The Neurodynamics of Belief Propagation on Binary Markov Random Fields</a></p>
<p>8 0.62398714 <a title="74-lsi-8" href="./nips-2006-iLSTD%3A_Eligibility_Traces_and_Convergence_Analysis.html">202 nips-2006-iLSTD: Eligibility Traces and Convergence Analysis</a></p>
<p>9 0.61179328 <a title="74-lsi-9" href="./nips-2006-Modeling_Dyadic_Data_with_Binary_Latent_Factors.html">132 nips-2006-Modeling Dyadic Data with Binary Latent Factors</a></p>
<p>10 0.61052322 <a title="74-lsi-10" href="./nips-2006-Learning_Dense_3D_Correspondence.html">110 nips-2006-Learning Dense 3D Correspondence</a></p>
<p>11 0.60872102 <a title="74-lsi-11" href="./nips-2006-Sparse_Multinomial_Logistic_Regression_via_Bayesian_L1_Regularisation.html">178 nips-2006-Sparse Multinomial Logistic Regression via Bayesian L1 Regularisation</a></p>
<p>12 0.57648128 <a title="74-lsi-12" href="./nips-2006-Combining_causal_and_similarity-based_reasoning.html">53 nips-2006-Combining causal and similarity-based reasoning</a></p>
<p>13 0.57233608 <a title="74-lsi-13" href="./nips-2006-Comparative_Gene_Prediction_using_Conditional_Random_Fields.html">54 nips-2006-Comparative Gene Prediction using Conditional Random Fields</a></p>
<p>14 0.56740451 <a title="74-lsi-14" href="./nips-2006-Multi-Task_Feature_Learning.html">138 nips-2006-Multi-Task Feature Learning</a></p>
<p>15 0.55819827 <a title="74-lsi-15" href="./nips-2006-Inferring_Network_Structure_from_Co-Occurrences.html">98 nips-2006-Inferring Network Structure from Co-Occurrences</a></p>
<p>16 0.55754554 <a title="74-lsi-16" href="./nips-2006-Implicit_Surfaces_with_Globally_Regularised_and_Compactly_Supported_Basis_Functions.html">95 nips-2006-Implicit Surfaces with Globally Regularised and Compactly Supported Basis Functions</a></p>
<p>17 0.55438799 <a title="74-lsi-17" href="./nips-2006-Multi-dynamic_Bayesian_Networks.html">139 nips-2006-Multi-dynamic Bayesian Networks</a></p>
<p>18 0.55391157 <a title="74-lsi-18" href="./nips-2006-Distributed_Inference_in_Dynamical_Systems.html">69 nips-2006-Distributed Inference in Dynamical Systems</a></p>
<p>19 0.54098731 <a title="74-lsi-19" href="./nips-2006-Learning_annotated_hierarchies_from_relational_data.html">115 nips-2006-Learning annotated hierarchies from relational data</a></p>
<p>20 0.53394467 <a title="74-lsi-20" href="./nips-2006-Speakers_optimize_information_density_through_syntactic_reduction.html">180 nips-2006-Speakers optimize information density through syntactic reduction</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2006_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(22, 0.048), (24, 0.364), (34, 0.087), (45, 0.096), (46, 0.051), (53, 0.12), (61, 0.106), (72, 0.047)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.83831906 <a title="74-lda-1" href="./nips-2006-Prediction_on_a_Graph_with_a_Perceptron.html">163 nips-2006-Prediction on a Graph with a Perceptron</a></p>
<p>same-paper 2 0.74156994 <a title="74-lda-2" href="./nips-2006-Efficient_Structure_Learning_of_Markov_Networks_using_%24L_1%24-Regularization.html">74 nips-2006-Efficient Structure Learning of Markov Networks using $L 1$-Regularization</a></p>
<p>3 0.64242518 <a title="74-lda-3" href="./nips-2006-Modeling_Dyadic_Data_with_Binary_Latent_Factors.html">132 nips-2006-Modeling Dyadic Data with Binary Latent Factors</a></p>
<p>4 0.59572268 <a title="74-lda-4" href="./nips-2006-Using_Combinatorial_Optimization_within_Max-Product_Belief_Propagation.html">201 nips-2006-Using Combinatorial Optimization within Max-Product Belief Propagation</a></p>
<p>5 0.58617496 <a title="74-lda-5" href="./nips-2006-Multiple_timescales_and_uncertainty_in_motor_adaptation.html">141 nips-2006-Multiple timescales and uncertainty in motor adaptation</a></p>
<p>6 0.56944704 <a title="74-lda-6" href="./nips-2006-Approximate_inference_using_planar_graph_decomposition.html">35 nips-2006-Approximate inference using planar graph decomposition</a></p>
<p>7 0.56374824 <a title="74-lda-7" href="./nips-2006-Balanced_Graph_Matching.html">39 nips-2006-Balanced Graph Matching</a></p>
<p>8 0.56117505 <a title="74-lda-8" href="./nips-2006-Learning_on_Graph_with_Laplacian_Regularization.html">117 nips-2006-Learning on Graph with Laplacian Regularization</a></p>
<p>9 0.55801654 <a title="74-lda-9" href="./nips-2006-Learning_with_Hypergraphs%3A_Clustering%2C_Classification%2C_and_Embedding.html">123 nips-2006-Learning with Hypergraphs: Clustering, Classification, and Embedding</a></p>
<p>10 0.55713153 <a title="74-lda-10" href="./nips-2006-Fast_Iterative_Kernel_PCA.html">79 nips-2006-Fast Iterative Kernel PCA</a></p>
<p>11 0.55124032 <a title="74-lda-11" href="./nips-2006-Bayesian_Model_Scoring_in_Markov_Random_Fields.html">43 nips-2006-Bayesian Model Scoring in Markov Random Fields</a></p>
<p>12 0.55069947 <a title="74-lda-12" href="./nips-2006-Distributed_Inference_in_Dynamical_Systems.html">69 nips-2006-Distributed Inference in Dynamical Systems</a></p>
<p>13 0.54989845 <a title="74-lda-13" href="./nips-2006-Learning_Nonparametric_Models_for_Probabilistic_Imitation.html">112 nips-2006-Learning Nonparametric Models for Probabilistic Imitation</a></p>
<p>14 0.54875785 <a title="74-lda-14" href="./nips-2006-Near-Uniform_Sampling_of_Combinatorial_Spaces_Using_XOR_Constraints.html">144 nips-2006-Near-Uniform Sampling of Combinatorial Spaces Using XOR Constraints</a></p>
<p>15 0.54775685 <a title="74-lda-15" href="./nips-2006-Temporal_and_Cross-Subject_Probabilistic_Models_for_fMRI_Prediction_Tasks.html">188 nips-2006-Temporal and Cross-Subject Probabilistic Models for fMRI Prediction Tasks</a></p>
<p>16 0.54695994 <a title="74-lda-16" href="./nips-2006-Stochastic_Relational_Models_for_Discriminative_Link_Prediction.html">183 nips-2006-Stochastic Relational Models for Discriminative Link Prediction</a></p>
<p>17 0.54631335 <a title="74-lda-17" href="./nips-2006-A_Kernel_Method_for_the_Two-Sample-Problem.html">5 nips-2006-A Kernel Method for the Two-Sample-Problem</a></p>
<p>18 0.54363 <a title="74-lda-18" href="./nips-2006-Relational_Learning_with_Gaussian_Processes.html">169 nips-2006-Relational Learning with Gaussian Processes</a></p>
<p>19 0.54348975 <a title="74-lda-19" href="./nips-2006-Conditional_Random_Sampling%3A_A_Sketch-based_Sampling_Technique_for_Sparse_Data.html">56 nips-2006-Conditional Random Sampling: A Sketch-based Sampling Technique for Sparse Data</a></p>
<p>20 0.54140741 <a title="74-lda-20" href="./nips-2006-Speakers_optimize_information_density_through_syntactic_reduction.html">180 nips-2006-Speakers optimize information density through syntactic reduction</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
