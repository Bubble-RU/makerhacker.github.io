<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>130 nips-2006-Max-margin classification of incomplete data</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-130" href="#">nips2006-130</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>130 nips-2006-Max-margin classification of incomplete data</h1>
<br/><p>Source: <a title="nips-2006-130-pdf" href="http://papers.nips.cc/paper/3024-max-margin-classification-of-incomplete-data.pdf">pdf</a></p><p>Author: Gal Chechik, Geremy Heitz, Gal Elidan, Pieter Abbeel, Daphne Koller</p><p>Abstract: We consider the problem of learning classiﬁers for structurally incomplete data, where some objects have a subset of features inherently absent due to complex relationships between the features. The common approach for handling missing features is to begin with a preprocessing phase that completes the missing features, and then use a standard classiﬁcation procedure. In this paper we show how incomplete data can be classiﬁed directly without any completion of the missing features using a max-margin learning framework. We formulate this task using a geometrically-inspired objective function, and discuss two optimization approaches: The linearly separable case is written as a set of convex feasibility problems, and the non-separable case has a non-convex objective that we optimize iteratively. By avoiding the pre-processing phase in which the data is completed, these approaches oﬀer considerable computational savings. More importantly, we show that by elegantly handling complex patterns of missing values, our approach is both competitive with other methods when the values are missing at random and outperforms them when the missing values have non-trivial structure. We demonstrate our results on two real-world problems: edge prediction in metabolic pathways, and automobile detection in natural images. 1</p><p>Reference: <a title="nips-2006-130-reference" href="../nips2006_reference/nips-2006-Max-margin_classification_of_incomplete_data_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('miss', 0.506), ('enzym', 0.441), ('di', 0.207), ('metabol', 0.196), ('wxi', 0.193), ('feat', 0.18), ('structurally', 0.172), ('landmark', 0.157), ('react', 0.133), ('inst', 0.122), ('geomet', 0.11), ('si', 0.109), ('imput', 0.107), ('flag', 0.099), ('fork', 0.099), ('xi', 0.098), ('yi', 0.097), ('knn', 0.094), ('xj', 0.089), ('margin', 0.087)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999997 <a title="130-tfidf-1" href="./nips-2006-Max-margin_classification_of_incomplete_data.html">130 nips-2006-Max-margin classification of incomplete data</a></p>
<p>2 0.13112403 <a title="130-tfidf-2" href="./nips-2006-Combining_causal_and_similarity-based_reasoning.html">53 nips-2006-Combining causal and similarity-based reasoning</a></p>
<p>3 0.12586235 <a title="130-tfidf-3" href="./nips-2006-Efficient_Structure_Learning_of_Markov_Networks_using_%24L_1%24-Regularization.html">74 nips-2006-Efficient Structure Learning of Markov Networks using $L 1$-Regularization</a></p>
<p>4 0.12492507 <a title="130-tfidf-4" href="./nips-2006-Modeling_Human_Motion_Using_Binary_Latent_Variables.html">134 nips-2006-Modeling Human Motion Using Binary Latent Variables</a></p>
<p>5 0.12134261 <a title="130-tfidf-5" href="./nips-2006-Clustering_Under_Prior_Knowledge_with_Application_to_Image_Segmentation.html">51 nips-2006-Clustering Under Prior Knowledge with Application to Image Segmentation</a></p>
<p>6 0.1169869 <a title="130-tfidf-6" href="./nips-2006-Image_Retrieval_and_Classification_Using_Local_Distance_Functions.html">94 nips-2006-Image Retrieval and Classification Using Local Distance Functions</a></p>
<p>7 0.11542241 <a title="130-tfidf-7" href="./nips-2006-Generalized_Maximum_Margin_Clustering_and_Unsupervised_Kernel_Learning.html">83 nips-2006-Generalized Maximum Margin Clustering and Unsupervised Kernel Learning</a></p>
<p>8 0.11448285 <a title="130-tfidf-8" href="./nips-2006-Modeling_Dyadic_Data_with_Binary_Latent_Factors.html">132 nips-2006-Modeling Dyadic Data with Binary Latent Factors</a></p>
<p>9 0.094643705 <a title="130-tfidf-9" href="./nips-2006-Information_Bottleneck_for_Non_Co-Occurrence_Data.html">100 nips-2006-Information Bottleneck for Non Co-Occurrence Data</a></p>
<p>10 0.091406628 <a title="130-tfidf-10" href="./nips-2006-Large_Margin_Component_Analysis.html">105 nips-2006-Large Margin Component Analysis</a></p>
<p>11 0.089034192 <a title="130-tfidf-11" href="./nips-2006-Learning_Dense_3D_Correspondence.html">110 nips-2006-Learning Dense 3D Correspondence</a></p>
<p>12 0.08771085 <a title="130-tfidf-12" href="./nips-2006-Denoising_and_Dimension_Reduction_in_Feature_Space.html">65 nips-2006-Denoising and Dimension Reduction in Feature Space</a></p>
<p>13 0.086922623 <a title="130-tfidf-13" href="./nips-2006-A_Nonparametric_Bayesian_Method_for_Inferring_Features_From_Similarity_Judgments.html">9 nips-2006-A Nonparametric Bayesian Method for Inferring Features From Similarity Judgments</a></p>
<p>14 0.085423745 <a title="130-tfidf-14" href="./nips-2006-Generalized_Regularized_Least-Squares_Learning_with_Predefined_Features_in_a_Hilbert_Space.html">84 nips-2006-Generalized Regularized Least-Squares Learning with Predefined Features in a Hilbert Space</a></p>
<p>15 0.084519818 <a title="130-tfidf-15" href="./nips-2006-Approximate_Correspondences_in_High_Dimensions.html">34 nips-2006-Approximate Correspondences in High Dimensions</a></p>
<p>16 0.08319474 <a title="130-tfidf-16" href="./nips-2006-Support_Vector_Machines_on_a_Budget.html">186 nips-2006-Support Vector Machines on a Budget</a></p>
<p>17 0.080248497 <a title="130-tfidf-17" href="./nips-2006-A_Nonparametric_Approach_to_Bottom-Up_Visual_Saliency.html">8 nips-2006-A Nonparametric Approach to Bottom-Up Visual Saliency</a></p>
<p>18 0.078777261 <a title="130-tfidf-18" href="./nips-2006-A_Local_Learning_Approach_for_Clustering.html">7 nips-2006-A Local Learning Approach for Clustering</a></p>
<p>19 0.077979125 <a title="130-tfidf-19" href="./nips-2006-Manifold_Denoising.html">128 nips-2006-Manifold Denoising</a></p>
<p>20 0.07744883 <a title="130-tfidf-20" href="./nips-2006-Sparse_Representation_for_Signal_Classification.html">179 nips-2006-Sparse Representation for Signal Classification</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2006_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.259), (1, -0.086), (2, 0.078), (3, -0.058), (4, -0.033), (5, -0.01), (6, 0.018), (7, 0.05), (8, 0.069), (9, 0.012), (10, 0.038), (11, -0.06), (12, 0.018), (13, -0.015), (14, 0.04), (15, -0.016), (16, -0.047), (17, 0.095), (18, -0.084), (19, -0.042), (20, -0.036), (21, 0.045), (22, -0.106), (23, 0.048), (24, -0.006), (25, 0.025), (26, 0.061), (27, -0.021), (28, 0.035), (29, -0.076), (30, -0.02), (31, 0.059), (32, 0.104), (33, -0.006), (34, 0.131), (35, 0.077), (36, -0.152), (37, 0.09), (38, -0.026), (39, 0.086), (40, 0.054), (41, -0.163), (42, 0.103), (43, 0.061), (44, 0.071), (45, 0.213), (46, 0.07), (47, -0.016), (48, 0.035), (49, -0.042)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9256326 <a title="130-lsi-1" href="./nips-2006-Max-margin_classification_of_incomplete_data.html">130 nips-2006-Max-margin classification of incomplete data</a></p>
<p>2 0.65853065 <a title="130-lsi-2" href="./nips-2006-Multiple_Instance_Learning_for_Computer_Aided_Diagnosis.html">140 nips-2006-Multiple Instance Learning for Computer Aided Diagnosis</a></p>
<p>3 0.6287874 <a title="130-lsi-3" href="./nips-2006-Large_Margin_Component_Analysis.html">105 nips-2006-Large Margin Component Analysis</a></p>
<p>4 0.62354702 <a title="130-lsi-4" href="./nips-2006-Efficient_Structure_Learning_of_Markov_Networks_using_%24L_1%24-Regularization.html">74 nips-2006-Efficient Structure Learning of Markov Networks using $L 1$-Regularization</a></p>
<p>5 0.62307322 <a title="130-lsi-5" href="./nips-2006-Modeling_Dyadic_Data_with_Binary_Latent_Factors.html">132 nips-2006-Modeling Dyadic Data with Binary Latent Factors</a></p>
<p>6 0.56855965 <a title="130-lsi-6" href="./nips-2006-Combining_causal_and_similarity-based_reasoning.html">53 nips-2006-Combining causal and similarity-based reasoning</a></p>
<p>7 0.56435317 <a title="130-lsi-7" href="./nips-2006-Approximate_Correspondences_in_High_Dimensions.html">34 nips-2006-Approximate Correspondences in High Dimensions</a></p>
<p>8 0.54273206 <a title="130-lsi-8" href="./nips-2006-Comparative_Gene_Prediction_using_Conditional_Random_Fields.html">54 nips-2006-Comparative Gene Prediction using Conditional Random Fields</a></p>
<p>9 0.53517956 <a title="130-lsi-9" href="./nips-2006-Aggregating_Classification_Accuracy_across_Time%3A_Application_to_Single_Trial_EEG.html">24 nips-2006-Aggregating Classification Accuracy across Time: Application to Single Trial EEG</a></p>
<p>10 0.53064603 <a title="130-lsi-10" href="./nips-2006-Learning_Dense_3D_Correspondence.html">110 nips-2006-Learning Dense 3D Correspondence</a></p>
<p>11 0.51792318 <a title="130-lsi-11" href="./nips-2006-Subordinate_class_recognition_using_relational_object_models.html">185 nips-2006-Subordinate class recognition using relational object models</a></p>
<p>12 0.51764542 <a title="130-lsi-12" href="./nips-2006-A_Nonparametric_Bayesian_Method_for_Inferring_Features_From_Similarity_Judgments.html">9 nips-2006-A Nonparametric Bayesian Method for Inferring Features From Similarity Judgments</a></p>
<p>13 0.51452857 <a title="130-lsi-13" href="./nips-2006-Sparse_Representation_for_Signal_Classification.html">179 nips-2006-Sparse Representation for Signal Classification</a></p>
<p>14 0.50867271 <a title="130-lsi-14" href="./nips-2006-Learning_to_Model_Spatial_Dependency%3A_Semi-Supervised_Discriminative_Random_Fields.html">118 nips-2006-Learning to Model Spatial Dependency: Semi-Supervised Discriminative Random Fields</a></p>
<p>15 0.50248235 <a title="130-lsi-15" href="./nips-2006-Multi-Task_Feature_Learning.html">138 nips-2006-Multi-Task Feature Learning</a></p>
<p>16 0.48194265 <a title="130-lsi-16" href="./nips-2006-Information_Bottleneck_for_Non_Co-Occurrence_Data.html">100 nips-2006-Information Bottleneck for Non Co-Occurrence Data</a></p>
<p>17 0.47927406 <a title="130-lsi-17" href="./nips-2006-iLSTD%3A_Eligibility_Traces_and_Convergence_Analysis.html">202 nips-2006-iLSTD: Eligibility Traces and Convergence Analysis</a></p>
<p>18 0.4763529 <a title="130-lsi-18" href="./nips-2006-Image_Retrieval_and_Classification_Using_Local_Distance_Functions.html">94 nips-2006-Image Retrieval and Classification Using Local Distance Functions</a></p>
<p>19 0.47046959 <a title="130-lsi-19" href="./nips-2006-Isotonic_Conditional_Random_Fields_and_Local_Sentiment_Flow.html">101 nips-2006-Isotonic Conditional Random Fields and Local Sentiment Flow</a></p>
<p>20 0.45668343 <a title="130-lsi-20" href="./nips-2006-Learning_annotated_hierarchies_from_relational_data.html">115 nips-2006-Learning annotated hierarchies from relational data</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2006_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(22, 0.03), (24, 0.022), (30, 0.253), (34, 0.118), (45, 0.133), (46, 0.057), (53, 0.089), (61, 0.125), (72, 0.077)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.80335647 <a title="130-lda-1" href="./nips-2006-Learning_Nonparametric_Models_for_Probabilistic_Imitation.html">112 nips-2006-Learning Nonparametric Models for Probabilistic Imitation</a></p>
<p>same-paper 2 0.77808368 <a title="130-lda-2" href="./nips-2006-Max-margin_classification_of_incomplete_data.html">130 nips-2006-Max-margin classification of incomplete data</a></p>
<p>3 0.76460785 <a title="130-lda-3" href="./nips-2006-Kernels_on_Structured_Objects_Through_Nested_Histograms.html">103 nips-2006-Kernels on Structured Objects Through Nested Histograms</a></p>
<p>4 0.70303464 <a title="130-lda-4" href="./nips-2006-Simplifying_Mixture_Models_through_Function_Approximation.html">175 nips-2006-Simplifying Mixture Models through Function Approximation</a></p>
<p>5 0.69904834 <a title="130-lda-5" href="./nips-2006-Modeling_Dyadic_Data_with_Binary_Latent_Factors.html">132 nips-2006-Modeling Dyadic Data with Binary Latent Factors</a></p>
<p>6 0.69721359 <a title="130-lda-6" href="./nips-2006-Using_Combinatorial_Optimization_within_Max-Product_Belief_Propagation.html">201 nips-2006-Using Combinatorial Optimization within Max-Product Belief Propagation</a></p>
<p>7 0.69661456 <a title="130-lda-7" href="./nips-2006-Learning_to_Traverse_Image_Manifolds.html">120 nips-2006-Learning to Traverse Image Manifolds</a></p>
<p>8 0.69638371 <a title="130-lda-8" href="./nips-2006-Tighter_PAC-Bayes_Bounds.html">193 nips-2006-Tighter PAC-Bayes Bounds</a></p>
<p>9 0.69635236 <a title="130-lda-9" href="./nips-2006-Chained_Boosting.html">50 nips-2006-Chained Boosting</a></p>
<p>10 0.69579732 <a title="130-lda-10" href="./nips-2006-Multi-Task_Feature_Learning.html">138 nips-2006-Multi-Task Feature Learning</a></p>
<p>11 0.69577861 <a title="130-lda-11" href="./nips-2006-A_Nonparametric_Approach_to_Bottom-Up_Visual_Saliency.html">8 nips-2006-A Nonparametric Approach to Bottom-Up Visual Saliency</a></p>
<p>12 0.69557965 <a title="130-lda-12" href="./nips-2006-Analysis_of_Representations_for_Domain_Adaptation.html">33 nips-2006-Analysis of Representations for Domain Adaptation</a></p>
<p>13 0.69413352 <a title="130-lda-13" href="./nips-2006-Sparse_Multinomial_Logistic_Regression_via_Bayesian_L1_Regularisation.html">178 nips-2006-Sparse Multinomial Logistic Regression via Bayesian L1 Regularisation</a></p>
<p>14 0.69345158 <a title="130-lda-14" href="./nips-2006-Theory_and_Dynamics_of_Perceptual_Bistability.html">192 nips-2006-Theory and Dynamics of Perceptual Bistability</a></p>
<p>15 0.6932494 <a title="130-lda-15" href="./nips-2006-Approximate_Correspondences_in_High_Dimensions.html">34 nips-2006-Approximate Correspondences in High Dimensions</a></p>
<p>16 0.69282484 <a title="130-lda-16" href="./nips-2006-Bayesian_Ensemble_Learning.html">41 nips-2006-Bayesian Ensemble Learning</a></p>
<p>17 0.69274986 <a title="130-lda-17" href="./nips-2006-Relational_Learning_with_Gaussian_Processes.html">169 nips-2006-Relational Learning with Gaussian Processes</a></p>
<p>18 0.69272268 <a title="130-lda-18" href="./nips-2006-Learning_on_Graph_with_Laplacian_Regularization.html">117 nips-2006-Learning on Graph with Laplacian Regularization</a></p>
<p>19 0.69220501 <a title="130-lda-19" href="./nips-2006-Fast_Discriminative_Visual_Codebooks_using_Randomized_Clustering_Forests.html">78 nips-2006-Fast Discriminative Visual Codebooks using Randomized Clustering Forests</a></p>
<p>20 0.69208467 <a title="130-lda-20" href="./nips-2006-Data_Integration_for_Classification_Problems_Employing_Gaussian_Process_Priors.html">64 nips-2006-Data Integration for Classification Problems Employing Gaussian Process Priors</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
