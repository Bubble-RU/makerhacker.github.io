<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>62 nips-2006-Correcting Sample Selection Bias by Unlabeled Data</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-62" href="#">nips2006-62</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>62 nips-2006-Correcting Sample Selection Bias by Unlabeled Data</h1>
<br/><p>Source: <a title="nips-2006-62-pdf" href="http://papers.nips.cc/paper/3075-correcting-sample-selection-bias-by-unlabeled-data.pdf">pdf</a></p><p>Author: Jiayuan Huang, Arthur Gretton, Karsten M. Borgwardt, Bernhard Schölkopf, Alex J. Smola</p><p>Abstract: We consider the scenario where training and test data are drawn from different distributions, commonly referred to as sample selection bias. Most algorithms for this setting try to ﬁrst recover sampling distributions and then make appropriate corrections based on the distribution estimate. We present a nonparametric method which directly produces resampling weights without distribution estimation. Our method works by matching distributions between training and testing sets in feature space. Experimental results demonstrate that our method works well in practice.</p><p>Reference: <a title="nips-2006-62-reference" href="../nips2006_reference/nips-2006-Correcting_Sample_Selection_Bias_by_Unlabeled_Data_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 de  Abstract We consider the scenario where training and test data are drawn from different distributions, commonly referred to as sample selection bias. [sent-16, score-0.296]
</p><p>2 Most algorithms for this setting try to ﬁrst recover sampling distributions and then make appropriate corrections based on the distribution estimate. [sent-17, score-0.123]
</p><p>3 Our method works by matching distributions between training and testing sets in feature space. [sent-19, score-0.173]
</p><p>4 1 Introduction The default assumption in many learning scenarios is that training and test data are independently and identically (iid) drawn from the same distribution. [sent-21, score-0.155]
</p><p>5 When the distributions on training and test set do not match, we are facing sample selection bias or covariate shift. [sent-22, score-0.384]
</p><p>6 Speciﬁcally, given a domain of patterns X and labels Y, we obtain training samples Z = {(x1 , y1 ), . [sent-23, score-0.089]
</p><p>7 , (xm , ym )} ⊆ X × Y from ′ ′ a Borel probability distribution Pr(x, y), and test samples Z ′ = {(x′ , y1 ), . [sent-26, score-0.088]
</p><p>8 Although there exists previous work addressing this problem [2, 5, 8, 9, 12, 16, 20], sample selection bias is typically ignored in standard estimation algorithms. [sent-30, score-0.193]
</p><p>9 Nonetheless, in reality the problem occurs rather frequently : While the available data have been collected in a biased manner, the test is usually performed over a more general target population. [sent-31, score-0.18]
</p><p>10 Suppose we wish to generate a model to diagnose breast cancer. [sent-34, score-0.142]
</p><p>11 Suppose, moreover, that most women who participate in the breast screening test are middle-aged and likely to have attended the screening in the preceding 3 years. [sent-35, score-0.3]
</p><p>12 Consequently our sample includes mostly older women and those who have low risk of breast cancer because they have been tested before. [sent-36, score-0.421]
</p><p>13 The examples do not reﬂect the general population with respect to age (which amounts to a bias in Pr(x)) and they only contain very few diseased cases (i. [sent-37, score-0.141]
</p><p>14 Gene expression proﬁle studies using DNA microarrays are used in tumor diagnosis. [sent-41, score-0.174]
</p><p>15 A common problem is that the samples are obtained using certain protocols, microarray platforms and analysis techniques. [sent-42, score-0.082]
</p><p>16 The test cases are recorded under different conditions, resulting in a different distribution of gene expression values. [sent-44, score-0.154]
</p><p>17 In this paper, we utilize the availability of unlabeled data to direct a sample selection de-biasing procedure for various learning methods. [sent-45, score-0.135]
</p><p>18 Unlike previous work we infer the resampling weight directly by distribution matching between training and testing sets in feature space in a non-parametric  manner. [sent-46, score-0.17]
</p><p>19 We do not require the estimation of biased densities or selection probabilities [20, 2, 12], or the assumption that probabilities of the different classes are known [8]. [sent-47, score-0.245]
</p><p>20 Rather, we account for the difference between Pr(x, y) and Pr′ (x, y) by reweighting the training points such that the means of the training and test points in a reproducing kernel Hilbert space (RKHS) are close. [sent-48, score-0.498]
</p><p>21 We call this reweighting process kernel mean matching (KMM). [sent-49, score-0.346]
</p><p>22 The required optimisation is a simple QP problem, and the reweighted sample can be incorporated straightforwardly into several different regression and classiﬁcation algorithms. [sent-51, score-0.18]
</p><p>23 We apply our method to a variety of regression and classiﬁcation benchmarks from UCI and elsewhere, as well as to classiﬁcation of microarrays from prostate and breast cancer patients. [sent-52, score-0.487]
</p><p>24 These experiments demonstrate that KMM greatly improves learning performance compared with training on unweighted data, and that our reweighting scheme can in some cases outperform reweighting using the true sample bias distribution. [sent-53, score-0.892]
</p><p>25 In other words, the conditional probabilities of y|x remain unchanged (this particular case of sample selection bias has been termed covariate shift [12]). [sent-57, score-0.253]
</p><p>26 However, since typically we only observe examples (x, y) drawn from Pr(x, y) rather than Pr′ (x, y), we resort to computing the empirical average m 1 Remp [Z, θ, l(x, y, θ)] = l(xi , yi , θ). [sent-62, score-0.136]
</p><p>27 The training set is drawn from Pr, however what we would really like is to minimize R[Pr′ , θ, l] as we wish to generalize to test examples drawn from Pr′ . [sent-66, score-0.242]
</p><p>28 An observation from the ﬁeld of importance sampling is that ′ R[Pr ′ , θ, l(x, y, θ)] = E(x,y)∼Pr′ [l(x, y, θ)] = E(x,y)∼Pr Pr (x,y) l(x, y, θ) (3) Pr(x,y) = R[Pr, θ, β(x, y)l(x, y, θ)],  :=β(x,y)  (4)  provided that the support of Pr′ is contained in the support of Pr. [sent-67, score-0.197]
</p><p>29 When Pr and Pr′ differ only in Pr(x) and Pr′ (x), we have β(x, y) = Pr′ (x)/Pr(x), where β is a reweighting factor for the training examples. [sent-71, score-0.317]
</p><p>30 This is closely related to the methods in [20, 8], as they have to either estimate the selection probabilities or have prior knowledge of the class distributions. [sent-74, score-0.08]
</p><p>31 Although intuitive, this approach has two major problems: ﬁrst, it only works whenever the density estimates for Pr and Pr′ (or potentially, the selection probabilities or class distributions) are good. [sent-75, score-0.08]
</p><p>32 Second, estimating both densities just for the purpose of computing reweighting coefﬁcients may be overkill: we may be able to directly estimate the coefﬁcients βi := β(xi , yi ) without having to estimate the two distributions. [sent-77, score-0.307]
</p><p>33 Support Vector Classiﬁcation: Utilizing the setting of [17]we can have the following minimization problem (the original SVMs can be formulated in the same way): minimize θ,ξ  1 θ 2  m 2  +C  βi ξi  (6a)  i=1  subject to φ(xi , yi ) − φ(xi , y), θ ≥ 1 − ξi /∆(yi , y) for all y ∈ Y, and ξi ≥ 0. [sent-81, score-0.096]
</p><p>34 (6b)  ′  Here, φ(x, y) is a feature map from X × Y into a feature space F, where θ ∈ F and ∆(y, y ) denotes a discrepancy function between y and y ′ . [sent-82, score-0.109]
</p><p>35 The advantage of this formulation is that it can be solved as easily as solving the standard penalized regression problem. [sent-95, score-0.078]
</p><p>36 1 Kernel Mean Matching and its relation to importance sampling Let Φ : X → F be a map into a feature space F and denote by µ : P → F the expectation operator  µ(Pr) := Ex∼Pr(x) [Φ(x)] . [sent-98, score-0.18]
</p><p>37 The use of feature space means to compare distributions is further explored in [3]. [sent-103, score-0.09]
</p><p>38 (10) β  This is the kernel mean matching (KMM) procedure. [sent-105, score-0.119]
</p><p>39 2 Convergence of reweighted means in feature space Lemma 2 shows that in principle, if we knew Pr and µ[Pr′ ], we could fully recover Pr′ by solving a simple quadratic program. [sent-112, score-0.133]
</p><p>40 Instead, we only have samples X and X ′ of size m and m′ , drawn iid from Pr and Pr′ respectively. [sent-114, score-0.089]
</p><p>41 However, it is to be expected that empirical averages will differ from each other due to ﬁnite sample size effects. [sent-116, score-0.138]
</p><p>42 Lemma 3 If β(x) ∈ [0, B] is some ﬁxed function of x ∈ X, then given xi ∼ Pr iid such that β(xi ) 1 has ﬁnite mean and non-zero variance, the sample mean m i β(xi ) converges in distribution to a B Gaussian with mean β(x)d Pr(x) and standard deviation bounded by 2√m . [sent-119, score-0.262]
</p><p>43 Our second result demonstrates the deviation between the empirical means of Pr′ and β(x) Pr in feature space, given β(x) is chosen perfectly in the population sense. [sent-124, score-0.156]
</p><p>44 In particular, this result shows that convergence of these two means will be slow if there is a large difference in the probability mass of Pr′ and Pr (and thus the bound B on the ratio of probability masses is large). [sent-125, score-0.075]
</p><p>45 This means that, for very different distributions we need a large equivalent sample size to get reasonable convergence. [sent-133, score-0.114]
</p><p>46 3 Empirical KMM optimization To ﬁnd suitable values of β ∈ Rm we want to minimize the discrepancy between means subject m 1 to constraints βi ∈ [0, B] and | m i=1 βi − 1| ≤ ǫ. [sent-136, score-0.111]
</p><p>47 The objective function is given by the discrepancy term between the two empirical m′ m means. [sent-138, score-0.074]
</p><p>48 The red line is a second reference result, derived only from the training data via OLS, and predicts the test data very poorly. [sent-158, score-0.129]
</p><p>49 The other three dashed lines are ﬁt with weighted ordinary least square (WOLS), using one of three weighting schemes: the ratio of the underlying training and test densities, KMM, and the information criterion of [12]. [sent-159, score-0.199]
</p><p>50 4  (a)  x from q0 true fitting model OLS fitting x q0  x from q1 OLS fitting xq1  0  0. [sent-172, score-0.12]
</p><p>51 2  ratio  KMM  IC  OLS  (b)  Figure 1: (a) Polynomial models of degree 1 ﬁt with OLS and WOLS;(b) Average performances of three WOLS methods and OLS on the test data in (a). [sent-182, score-0.11]
</p><p>52 Labels are Ratio for ratio of test to training density; KMM for our approach; min IC for the approach of [12]; and OLS for the model trained on the labeled test points. [sent-183, score-0.239]
</p><p>53 2 Real world datasets We next test our approach on real world data sets, from which we select training examples using a deliberately biased procedure (as in [20, 9]). [sent-185, score-0.305]
</p><p>54 To describe our biased selection scheme, we need to deﬁne an additional random variable si for each point in the pool of possible training samples, where si = 1 means the ith sample is included, and si = 0 indicates an excluded sample. [sent-186, score-0.483]
</p><p>55 Two situations are considered: the selection bias corresponds to our assumption regarding the relation between the training and test distributions, and P (si = 1|xi , yi ) = P (si |xi ); or si is dependent only on yi , i. [sent-187, score-0.433]
</p><p>56 In the following, we compare our method (labeled KMM) against two others: a baseline unweighted method (unweighted), in which no modiﬁcation is made, and a weighting by the inverse of the true sampling distribution (importance sampling), as in [20, 9]. [sent-190, score-0.303]
</p><p>57 We emphasise, however, that our method does not require any prior knowledge of the true sampling probabilities. [sent-191, score-0.095]
</p><p>58 In our experiments, we used a Gaussian kernel exp(−σ xi − xj 2 ) in our kernel classiﬁcation and √ √ regression algorithms, and parameters ǫ = ( m − 1)/ m and B = 1000 in the optimization (12). [sent-192, score-0.216]
</p><p>59 02 0  1  2  3  4 5 6 biased feature  7  8  0  9  (a) Simple bias on features  0. [sent-210, score-0.231]
</p><p>60 1  optimal weights inverse of true sampling probabilites  10  0. [sent-217, score-0.095]
</p><p>61 01  0  1  2 3 4 training set proportion  (c) Bias on labels  0 0  5  (d)  β  10  20  30  40  50  vs inverse sampling prob. [sent-222, score-0.183]
</p><p>62 Figure 2: Classiﬁcation performance analysis on breast cancer dataset from UCI. [sent-223, score-0.325]
</p><p>63 The data are randomly split into training and test sets, where the proportion of examples used for training varies from 10% to 50%. [sent-228, score-0.239]
</p><p>64 First, we consider a biased sampling scheme based on the input features, of which there are nine, with integer values from 0 to 9. [sent-231, score-0.239]
</p><p>65 Since smaller feature values predominate in the unbiased data, we sample according to P (s = 1|x ≤ 5) = 0. [sent-232, score-0.09]
</p><p>66 Performance is shown in Figure 2(a): we consistently outperform the unweighted method, and match or exceed the performance obtained using the known distribution ratio. [sent-236, score-0.184]
</p><p>67 Next, we consider a sampling bias that operates jointly across multiple features. [sent-237, score-0.177]
</p><p>68 We select samples less often when they are further from the sample mean x over the training data, i. [sent-238, score-0.17]
</p><p>69 Performance of our method in 2(b) is again better than the unweighted case, and as good as or better than reweighting using the sampling model. [sent-241, score-0.506]
</p><p>70 Finally, we consider a simple biased sampling scheme which depends only on the label y: P (s = 1|y = 1) = 0. [sent-242, score-0.263]
</p><p>71 Fig-  ure 2(d) shows the weights β are proportional to the inverse of true sampling probabilities: positive examples have higher weights and negative ones have lower weights. [sent-246, score-0.117]
</p><p>72 2 Further Benchmark Datasets We next compare the performance on further benchmark datasets1 by selecting training data via various biased sampling schemes. [sent-249, score-0.3]
</p><p>73 Speciﬁcally, for the sampling distribution bias on labels, we use P (s = 1|y) = exp(a + by)/(1 + exp(a + by)) (datasets 1 to 5), or the simple step distribution P (s = 1|y = 1) = a, P (s = 1|y = −1) = b (datasets 6 and 7). [sent-250, score-0.177]
</p><p>74 For the remaining datasets, we generate biased sampling schemes over their features. [sent-251, score-0.211]
</p><p>75 Denoting the minimum value of the projection as m and the mean as m, we apply a normal distribution with mean m + (m − m)/a and variance (m − m)/b as the biased sampling scheme. [sent-253, score-0.259]
</p><p>76 We use penalized LMS for regression problems and SVM for classiﬁcation problems. [sent-255, score-0.078]
</p><p>77 To evaluate generalization performance, we utilize the normalized mean i −µ 1 square error (NMSE) given by n n (yvar yi ) for regression problems, and the average test error i=1 for classiﬁcation problems. [sent-256, score-0.197]
</p><p>78 In 13 out of 23 experiments, our reweighting approach is the most accurate (see Table 1), despite having no prior information about the bias of the test sample (and, in some cases, despite the additional fact that the data reweighting does not conform to our key assumption 1). [sent-257, score-0.657]
</p><p>79 In addition, the KMM always improves test performance compared with the unweighted case. [sent-258, score-0.27]
</p><p>80 Two additional points should be borne in mind: ﬁrst, we use the same σ for the kernel mean matching and the SVM, as listed in Table 1. [sent-259, score-0.119]
</p><p>81 This is not surprising, since a reweighting would further reduce the effective number of points used for training, resulting in insufﬁcient data for learning. [sent-262, score-0.227]
</p><p>82 Table 1: Test results for three methods on 18 datasets with different sampling schemes. [sent-263, score-0.133]
</p><p>83 The results are averages over 10 trials for regression problems (marked *) and 30 trials for classiﬁcation problems. [sent-264, score-0.129]
</p><p>84 We used a Gaussian kernel of size σ for both the kernel mean matching and the SVM/LMS regression, and set B = 1000. [sent-265, score-0.167]
</p><p>85 3 Tumor Diagnosis using Microarrays Our next benchmark is a dataset of 102 microarrays from prostate cancer patients [13]. [sent-420, score-0.367]
</p><p>86 Each of these microarrays measures the expression levels of 12,600 genes. [sent-421, score-0.123]
</p><p>87 The dataset comprises 50 samples from normal tissues (positive label) and 52 from tumor tissues (negative label). [sent-422, score-0.166]
</p><p>88 We simulate the realisitc scenario that two sets of microarrays A and B are given with dissimilar proportions of tumor samples, and we want to perform cancer diagnosis via classiﬁcation, training on A and predicting 1 Regression data from http://www. [sent-423, score-0.439]
</p><p>89 Sets with numbers in brackets are examined by different sampling schemes. [sent-428, score-0.095]
</p><p>90 We select training examples via the biased selection scheme P (s = 1|y = 1) = 0. [sent-430, score-0.285]
</p><p>91 We then perform SVM classiﬁcation for the unweighted, KMM, and importance sampling approaches. [sent-434, score-0.147]
</p><p>92 The experiment was repeated over 500 independent draws from the dataset according to our biased scheme; the 500 resulting test errors are plotted in [7]. [sent-435, score-0.205]
</p><p>93 The KMM achieves much higher accuracy levels than the unweighted approach, and is very close to the importance sampling approach. [sent-436, score-0.331]
</p><p>94 We study a very similar scenario on two breast cancer microarray datasets from [4] and [19], measuring the expression levels of 2,166 common genes for normal and cancer patients [18]. [sent-437, score-0.647]
</p><p>95 Our reweighting method achieves signiﬁcant improvement in classiﬁcation accuracy over the unweighted SVM (see [7]). [sent-439, score-0.411]
</p><p>96 Correcting sample selection bias in maximum entropy density estimation. [sent-456, score-0.193]
</p><p>97 Estrogen receptor status in breast cancer is associated with remarkably distinct gene expression patterns. [sent-479, score-0.417]
</p><p>98 A method for inferring label sampling mechanisms in semisupervised learning. [sent-508, score-0.119]
</p><p>99 Cross-platform analysis of cancer microarray data improves gene expression based classiﬁcation of phenotypes. [sent-570, score-0.328]
</p><p>100 Predicting the clinical status of human breast cancer by using gene expression proﬁles. [sent-585, score-0.417]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('pr', 0.714), ('kmm', 0.283), ('reweighting', 0.227), ('unweighted', 0.184), ('cancer', 0.158), ('ols', 0.153), ('breast', 0.142), ('biased', 0.116), ('wols', 0.115), ('sampling', 0.095), ('microarrays', 0.085), ('bias', 0.082), ('iy', 0.077), ('reweighted', 0.071), ('xi', 0.068), ('remp', 0.067), ('training', 0.065), ('test', 0.064), ('microarray', 0.058), ('usps', 0.058), ('ailerons', 0.058), ('sample', 0.057), ('yi', 0.057), ('si', 0.054), ('classi', 0.054), ('selection', 0.054), ('gene', 0.052), ('importance', 0.052), ('regression', 0.052), ('tumor', 0.051), ('gretton', 0.05), ('prostate', 0.05), ('lemma', 0.05), ('kernel', 0.048), ('matching', 0.047), ('ratio', 0.046), ('borgwardt', 0.046), ('correcting', 0.046), ('discrepancy', 0.043), ('fitting', 0.04), ('iid', 0.039), ('minimize', 0.039), ('haberman', 0.038), ('lms', 0.038), ('nmse', 0.038), ('rreg', 0.038), ('datasets', 0.038), ('expression', 0.038), ('population', 0.037), ('rkhs', 0.036), ('risk', 0.036), ('ic', 0.035), ('covariate', 0.034), ('huang', 0.034), ('tissues', 0.033), ('warnat', 0.033), ('screening', 0.033), ('feature', 0.033), ('empirical', 0.031), ('ex', 0.031), ('arthur', 0.03), ('nicta', 0.03), ('cients', 0.03), ('svm', 0.03), ('scenario', 0.03), ('cation', 0.03), ('means', 0.029), ('women', 0.028), ('scheme', 0.028), ('distributions', 0.028), ('coef', 0.027), ('diagnosis', 0.027), ('status', 0.027), ('waterloo', 0.027), ('deviation', 0.026), ('penalized', 0.026), ('trials', 0.026), ('drawn', 0.026), ('probabilities', 0.026), ('dataset', 0.025), ('mpi', 0.025), ('resampling', 0.025), ('patients', 0.025), ('support', 0.025), ('averages', 0.025), ('differ', 0.025), ('label', 0.024), ('samples', 0.024), ('mean', 0.024), ('benchmark', 0.024), ('weighting', 0.024), ('unlabeled', 0.024), ('proportions', 0.023), ('kij', 0.023), ('proportion', 0.023), ('densities', 0.023), ('smola', 0.022), ('examples', 0.022), ('improves', 0.022), ('nonetheless', 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000012 <a title="62-tfidf-1" href="./nips-2006-Correcting_Sample_Selection_Bias_by_Unlabeled_Data.html">62 nips-2006-Correcting Sample Selection Bias by Unlabeled Data</a></p>
<p>Author: Jiayuan Huang, Arthur Gretton, Karsten M. Borgwardt, Bernhard Schölkopf, Alex J. Smola</p><p>Abstract: We consider the scenario where training and test data are drawn from different distributions, commonly referred to as sample selection bias. Most algorithms for this setting try to ﬁrst recover sampling distributions and then make appropriate corrections based on the distribution estimate. We present a nonparametric method which directly produces resampling weights without distribution estimation. Our method works by matching distributions between training and testing sets in feature space. Experimental results demonstrate that our method works well in practice.</p><p>2 0.29242697 <a title="62-tfidf-2" href="./nips-2006-Automated_Hierarchy_Discovery_for_Planning_in_Partially_Observable_Environments.html">38 nips-2006-Automated Hierarchy Discovery for Planning in Partially Observable Environments</a></p>
<p>Author: Laurent Charlin, Pascal Poupart, Romy Shioda</p><p>Abstract: Planning in partially observable domains is a notoriously difﬁcult problem. However, in many real-world scenarios, planning can be simpliﬁed by decomposing the task into a hierarchy of smaller planning problems. Several approaches have been proposed to optimize a policy that decomposes according to a hierarchy speciﬁed a priori. In this paper, we investigate the problem of automatically discovering the hierarchy. More precisely, we frame the optimization of a hierarchical policy as a non-convex optimization problem that can be solved with general non-linear solvers, a mixed-integer non-linear approximation or a form of bounded hierarchical policy iteration. By encoding the hierarchical structure as variables of the optimization problem, we can automatically discover a hierarchy. Our method is ﬂexible enough to allow any parts of the hierarchy to be speciﬁed based on prior knowledge while letting the optimization discover the unknown parts. It can also discover hierarchical policies, including recursive policies, that are more compact (potentially inﬁnitely fewer parameters) and often easier to understand given the decomposition induced by the hierarchy. 1</p><p>3 0.15881056 <a title="62-tfidf-3" href="./nips-2006-Natural_Actor-Critic_for_Road_Traffic_Optimisation.html">143 nips-2006-Natural Actor-Critic for Road Traffic Optimisation</a></p>
<p>Author: Silvia Richter, Douglas Aberdeen, Jin Yu</p><p>Abstract: Current road-trafﬁc optimisation practice around the world is a combination of hand tuned policies with a small degree of automatic adaption. Even state-ofthe-art research controllers need good models of the road trafﬁc, which cannot be obtained directly from existing sensors. We use a policy-gradient reinforcement learning approach to directly optimise the trafﬁc signals, mapping currently deployed sensor observations to control signals. Our trained controllers are (theoretically) compatible with the trafﬁc system used in Sydney and many other cities around the world. We apply two policy-gradient methods: (1) the recent natural actor-critic algorithm, and (2) a vanilla policy-gradient algorithm for comparison. Along the way we extend natural-actor critic approaches to work for distributed and online inﬁnite-horizon problems. 1</p><p>4 0.1234615 <a title="62-tfidf-4" href="./nips-2006-Bayesian_Policy_Gradient_Algorithms.html">44 nips-2006-Bayesian Policy Gradient Algorithms</a></p>
<p>Author: Mohammad Ghavamzadeh, Yaakov Engel</p><p>Abstract: Policy gradient methods are reinforcement learning algorithms that adapt a parameterized policy by following a performance gradient estimate. Conventional policy gradient methods use Monte-Carlo techniques to estimate this gradient. Since Monte Carlo methods tend to have high variance, a large number of samples is required, resulting in slow convergence. In this paper, we propose a Bayesian framework that models the policy gradient as a Gaussian process. This reduces the number of samples needed to obtain accurate gradient estimates. Moreover, estimates of the natural gradient as well as a measure of the uncertainty in the gradient estimates are provided at little extra cost. 1</p><p>5 0.10463791 <a title="62-tfidf-5" href="./nips-2006-Active_learning_for_misspecified_generalized_linear_models.html">20 nips-2006-Active learning for misspecified generalized linear models</a></p>
<p>Author: Francis R. Bach</p><p>Abstract: Active learning refers to algorithmic frameworks aimed at selecting training data points in order to reduce the number of required training data points and/or improve the generalization performance of a learning method. In this paper, we present an asymptotic analysis of active learning for generalized linear models. Our analysis holds under the common practical situation of model misspeciﬁcation, and is based on realistic assumptions regarding the nature of the sampling distributions, which are usually neither independent nor identical. We derive unbiased estimators of generalization performance, as well as estimators of expected reduction in generalization error after adding a new training data point, that allow us to optimize its sampling distribution through a convex optimization problem. Our analysis naturally leads to an algorithm for sequential active learning which is applicable for all tasks supported by generalized linear models (e.g., binary classiﬁcation, multi-class classiﬁcation, regression) and can be applied in non-linear settings through the use of Mercer kernels. 1</p><p>6 0.099834763 <a title="62-tfidf-6" href="./nips-2006-Mutagenetic_tree_Fisher_kernel_improves_prediction_of_HIV_drug_resistance_from_viral_genotype.html">142 nips-2006-Mutagenetic tree Fisher kernel improves prediction of HIV drug resistance from viral genotype</a></p>
<p>7 0.090481915 <a title="62-tfidf-7" href="./nips-2006-Comparative_Gene_Prediction_using_Conditional_Random_Fields.html">54 nips-2006-Comparative Gene Prediction using Conditional Random Fields</a></p>
<p>8 0.087754592 <a title="62-tfidf-8" href="./nips-2006-Tighter_PAC-Bayes_Bounds.html">193 nips-2006-Tighter PAC-Bayes Bounds</a></p>
<p>9 0.086052254 <a title="62-tfidf-9" href="./nips-2006-A_Kernel_Method_for_the_Two-Sample-Problem.html">5 nips-2006-A Kernel Method for the Two-Sample-Problem</a></p>
<p>10 0.081956975 <a title="62-tfidf-10" href="./nips-2006-On_Transductive_Regression.html">150 nips-2006-On Transductive Regression</a></p>
<p>11 0.075691491 <a title="62-tfidf-11" href="./nips-2006-Mixture_Regression_for_Covariate_Shift.html">131 nips-2006-Mixture Regression for Covariate Shift</a></p>
<p>12 0.070727699 <a title="62-tfidf-12" href="./nips-2006-Denoising_and_Dimension_Reduction_in_Feature_Space.html">65 nips-2006-Denoising and Dimension Reduction in Feature Space</a></p>
<p>13 0.06810803 <a title="62-tfidf-13" href="./nips-2006-PAC-Bayes_Bounds_for_the_Risk_of_the_Majority_Vote_and_the_Variance_of_the_Gibbs_Classifier.html">157 nips-2006-PAC-Bayes Bounds for the Risk of the Majority Vote and the Variance of the Gibbs Classifier</a></p>
<p>14 0.067812011 <a title="62-tfidf-14" href="./nips-2006-Attribute-efficient_learning_of_decision_lists_and_linear_threshold_functions_under_unconcentrated_distributions.html">37 nips-2006-Attribute-efficient learning of decision lists and linear threshold functions under unconcentrated distributions</a></p>
<p>15 0.066095755 <a title="62-tfidf-15" href="./nips-2006-Support_Vector_Machines_on_a_Budget.html">186 nips-2006-Support Vector Machines on a Budget</a></p>
<p>16 0.064831309 <a title="62-tfidf-16" href="./nips-2006-Generalized_Regularized_Least-Squares_Learning_with_Predefined_Features_in_a_Hilbert_Space.html">84 nips-2006-Generalized Regularized Least-Squares Learning with Predefined Features in a Hilbert Space</a></p>
<p>17 0.062565558 <a title="62-tfidf-17" href="./nips-2006-Near-Uniform_Sampling_of_Combinatorial_Spaces_Using_XOR_Constraints.html">144 nips-2006-Near-Uniform Sampling of Combinatorial Spaces Using XOR Constraints</a></p>
<p>18 0.061809726 <a title="62-tfidf-18" href="./nips-2006-Dirichlet-Enhanced_Spam_Filtering_based_on_Biased_Samples.html">68 nips-2006-Dirichlet-Enhanced Spam Filtering based on Biased Samples</a></p>
<p>19 0.060992047 <a title="62-tfidf-19" href="./nips-2006-Clustering_Under_Prior_Knowledge_with_Application_to_Image_Segmentation.html">51 nips-2006-Clustering Under Prior Knowledge with Application to Image Segmentation</a></p>
<p>20 0.058108173 <a title="62-tfidf-20" href="./nips-2006-Sparse_Multinomial_Logistic_Regression_via_Bayesian_L1_Regularisation.html">178 nips-2006-Sparse Multinomial Logistic Regression via Bayesian L1 Regularisation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2006_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.205), (1, 0.056), (2, -0.07), (3, -0.085), (4, 0.002), (5, 0.119), (6, -0.003), (7, 0.022), (8, 0.231), (9, 0.05), (10, -0.088), (11, -0.046), (12, 0.038), (13, -0.057), (14, -0.098), (15, -0.003), (16, -0.021), (17, -0.068), (18, 0.008), (19, 0.12), (20, 0.014), (21, -0.255), (22, -0.177), (23, -0.045), (24, 0.106), (25, -0.217), (26, 0.285), (27, 0.113), (28, 0.076), (29, -0.091), (30, 0.074), (31, -0.093), (32, 0.148), (33, 0.141), (34, -0.046), (35, -0.051), (36, -0.072), (37, -0.03), (38, -0.009), (39, -0.066), (40, -0.057), (41, -0.047), (42, 0.023), (43, 0.132), (44, 0.034), (45, -0.019), (46, 0.001), (47, 0.039), (48, 0.02), (49, 0.004)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94800121 <a title="62-lsi-1" href="./nips-2006-Correcting_Sample_Selection_Bias_by_Unlabeled_Data.html">62 nips-2006-Correcting Sample Selection Bias by Unlabeled Data</a></p>
<p>Author: Jiayuan Huang, Arthur Gretton, Karsten M. Borgwardt, Bernhard Schölkopf, Alex J. Smola</p><p>Abstract: We consider the scenario where training and test data are drawn from different distributions, commonly referred to as sample selection bias. Most algorithms for this setting try to ﬁrst recover sampling distributions and then make appropriate corrections based on the distribution estimate. We present a nonparametric method which directly produces resampling weights without distribution estimation. Our method works by matching distributions between training and testing sets in feature space. Experimental results demonstrate that our method works well in practice.</p><p>2 0.73614478 <a title="62-lsi-2" href="./nips-2006-Automated_Hierarchy_Discovery_for_Planning_in_Partially_Observable_Environments.html">38 nips-2006-Automated Hierarchy Discovery for Planning in Partially Observable Environments</a></p>
<p>Author: Laurent Charlin, Pascal Poupart, Romy Shioda</p><p>Abstract: Planning in partially observable domains is a notoriously difﬁcult problem. However, in many real-world scenarios, planning can be simpliﬁed by decomposing the task into a hierarchy of smaller planning problems. Several approaches have been proposed to optimize a policy that decomposes according to a hierarchy speciﬁed a priori. In this paper, we investigate the problem of automatically discovering the hierarchy. More precisely, we frame the optimization of a hierarchical policy as a non-convex optimization problem that can be solved with general non-linear solvers, a mixed-integer non-linear approximation or a form of bounded hierarchical policy iteration. By encoding the hierarchical structure as variables of the optimization problem, we can automatically discover a hierarchy. Our method is ﬂexible enough to allow any parts of the hierarchy to be speciﬁed based on prior knowledge while letting the optimization discover the unknown parts. It can also discover hierarchical policies, including recursive policies, that are more compact (potentially inﬁnitely fewer parameters) and often easier to understand given the decomposition induced by the hierarchy. 1</p><p>3 0.70577508 <a title="62-lsi-3" href="./nips-2006-Natural_Actor-Critic_for_Road_Traffic_Optimisation.html">143 nips-2006-Natural Actor-Critic for Road Traffic Optimisation</a></p>
<p>Author: Silvia Richter, Douglas Aberdeen, Jin Yu</p><p>Abstract: Current road-trafﬁc optimisation practice around the world is a combination of hand tuned policies with a small degree of automatic adaption. Even state-ofthe-art research controllers need good models of the road trafﬁc, which cannot be obtained directly from existing sensors. We use a policy-gradient reinforcement learning approach to directly optimise the trafﬁc signals, mapping currently deployed sensor observations to control signals. Our trained controllers are (theoretically) compatible with the trafﬁc system used in Sydney and many other cities around the world. We apply two policy-gradient methods: (1) the recent natural actor-critic algorithm, and (2) a vanilla policy-gradient algorithm for comparison. Along the way we extend natural-actor critic approaches to work for distributed and online inﬁnite-horizon problems. 1</p><p>4 0.51674259 <a title="62-lsi-4" href="./nips-2006-Mutagenetic_tree_Fisher_kernel_improves_prediction_of_HIV_drug_resistance_from_viral_genotype.html">142 nips-2006-Mutagenetic tree Fisher kernel improves prediction of HIV drug resistance from viral genotype</a></p>
<p>Author: Tobias Sing, Niko Beerenwinkel</p><p>Abstract: Starting with the work of Jaakkola and Haussler, a variety of approaches have been proposed for coupling domain-speciﬁc generative models with statistical learning methods. The link is established by a kernel function which provides a similarity measure based inherently on the underlying model. In computational biology, the full promise of this framework has rarely ever been exploited, as most kernels are derived from very generic models, such as sequence proﬁles or hidden Markov models. Here, we introduce the MTreeMix kernel, which is based on a generative model tailored to the underlying biological mechanism. Speciﬁcally, the kernel quantiﬁes the similarity of evolutionary escape from antiviral drug pressure between two viral sequence samples. We compare this novel kernel to a standard, evolution-agnostic amino acid encoding in the prediction of HIV drug resistance from genotype, using support vector regression. The results show signiﬁcant improvements in predictive performance across 17 anti-HIV drugs. Thus, in our study, the generative-discriminative paradigm is key to bridging the gap between population genetic modeling and clinical decision making. 1</p><p>5 0.46768594 <a title="62-lsi-5" href="./nips-2006-Bayesian_Policy_Gradient_Algorithms.html">44 nips-2006-Bayesian Policy Gradient Algorithms</a></p>
<p>Author: Mohammad Ghavamzadeh, Yaakov Engel</p><p>Abstract: Policy gradient methods are reinforcement learning algorithms that adapt a parameterized policy by following a performance gradient estimate. Conventional policy gradient methods use Monte-Carlo techniques to estimate this gradient. Since Monte Carlo methods tend to have high variance, a large number of samples is required, resulting in slow convergence. In this paper, we propose a Bayesian framework that models the policy gradient as a Gaussian process. This reduces the number of samples needed to obtain accurate gradient estimates. Moreover, estimates of the natural gradient as well as a measure of the uncertainty in the gradient estimates are provided at little extra cost. 1</p><p>6 0.45618898 <a title="62-lsi-6" href="./nips-2006-Near-Uniform_Sampling_of_Combinatorial_Spaces_Using_XOR_Constraints.html">144 nips-2006-Near-Uniform Sampling of Combinatorial Spaces Using XOR Constraints</a></p>
<p>7 0.42975333 <a title="62-lsi-7" href="./nips-2006-A_Kernel_Method_for_the_Two-Sample-Problem.html">5 nips-2006-A Kernel Method for the Two-Sample-Problem</a></p>
<p>8 0.36158007 <a title="62-lsi-8" href="./nips-2006-On_Transductive_Regression.html">150 nips-2006-On Transductive Regression</a></p>
<p>9 0.35865396 <a title="62-lsi-9" href="./nips-2006-Tighter_PAC-Bayes_Bounds.html">193 nips-2006-Tighter PAC-Bayes Bounds</a></p>
<p>10 0.35208642 <a title="62-lsi-10" href="./nips-2006-Mixture_Regression_for_Covariate_Shift.html">131 nips-2006-Mixture Regression for Covariate Shift</a></p>
<p>11 0.33225554 <a title="62-lsi-11" href="./nips-2006-Attribute-efficient_learning_of_decision_lists_and_linear_threshold_functions_under_unconcentrated_distributions.html">37 nips-2006-Attribute-efficient learning of decision lists and linear threshold functions under unconcentrated distributions</a></p>
<p>12 0.31754628 <a title="62-lsi-12" href="./nips-2006-Dirichlet-Enhanced_Spam_Filtering_based_on_Biased_Samples.html">68 nips-2006-Dirichlet-Enhanced Spam Filtering based on Biased Samples</a></p>
<p>13 0.31706923 <a title="62-lsi-13" href="./nips-2006-Multiple_Instance_Learning_for_Computer_Aided_Diagnosis.html">140 nips-2006-Multiple Instance Learning for Computer Aided Diagnosis</a></p>
<p>14 0.30935118 <a title="62-lsi-14" href="./nips-2006-Active_learning_for_misspecified_generalized_linear_models.html">20 nips-2006-Active learning for misspecified generalized linear models</a></p>
<p>15 0.2926797 <a title="62-lsi-15" href="./nips-2006-Sparse_Multinomial_Logistic_Regression_via_Bayesian_L1_Regularisation.html">178 nips-2006-Sparse Multinomial Logistic Regression via Bayesian L1 Regularisation</a></p>
<p>16 0.27785203 <a title="62-lsi-16" href="./nips-2006-Comparative_Gene_Prediction_using_Conditional_Random_Fields.html">54 nips-2006-Comparative Gene Prediction using Conditional Random Fields</a></p>
<p>17 0.2764706 <a title="62-lsi-17" href="./nips-2006-Support_Vector_Machines_on_a_Budget.html">186 nips-2006-Support Vector Machines on a Budget</a></p>
<p>18 0.25824699 <a title="62-lsi-18" href="./nips-2006-Learning_to_Model_Spatial_Dependency%3A_Semi-Supervised_Discriminative_Random_Fields.html">118 nips-2006-Learning to Model Spatial Dependency: Semi-Supervised Discriminative Random Fields</a></p>
<p>19 0.25786892 <a title="62-lsi-19" href="./nips-2006-An_Application_of_Reinforcement_Learning_to_Aerobatic_Helicopter_Flight.html">25 nips-2006-An Application of Reinforcement Learning to Aerobatic Helicopter Flight</a></p>
<p>20 0.24908535 <a title="62-lsi-20" href="./nips-2006-Gaussian_and_Wishart_Hyperkernels.html">82 nips-2006-Gaussian and Wishart Hyperkernels</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2006_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(1, 0.099), (3, 0.012), (7, 0.051), (9, 0.046), (20, 0.021), (22, 0.473), (44, 0.063), (57, 0.042), (65, 0.038), (69, 0.03), (83, 0.014), (90, 0.014)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.99534261 <a title="62-lda-1" href="./nips-2006-Randomized_PCA_Algorithms_with_Regret_Bounds_that_are_Logarithmic_in_the_Dimension.html">164 nips-2006-Randomized PCA Algorithms with Regret Bounds that are Logarithmic in the Dimension</a></p>
<p>Author: Manfred K. Warmuth, Dima Kuzmin</p><p>Abstract: We design an on-line algorithm for Principal Component Analysis. In each trial the current instance is projected onto a probabilistically chosen low dimensional subspace. The total expected quadratic approximation error equals the total quadratic approximation error of the best subspace chosen in hindsight plus some additional term that grows linearly in dimension of the subspace but logarithmically in the dimension of the instances. 1</p><p>2 0.96025604 <a title="62-lda-2" href="./nips-2006-High-Dimensional_Graphical_Model_Selection_Using_%24%5Cell_1%24-Regularized_Logistic_Regression.html">92 nips-2006-High-Dimensional Graphical Model Selection Using $\ell 1$-Regularized Logistic Regression</a></p>
<p>Author: Martin J. Wainwright, John D. Lafferty, Pradeep K. Ravikumar</p><p>Abstract: We focus on the problem of estimating the graph structure associated with a discrete Markov random ﬁeld. We describe a method based on 1 regularized logistic regression, in which the neighborhood of any given node is estimated by performing logistic regression subject to an 1 -constraint. Our framework applies to the high-dimensional setting, in which both the number of nodes p and maximum neighborhood sizes d are allowed to grow as a function of the number of observations n. Our main result is to establish suﬃcient conditions on the triple (n, p, d) for the method to succeed in consistently estimating the neighborhood of every node in the graph simultaneously. Under certain mutual incoherence conditions analogous to those imposed in previous work on linear regression, we prove that consistent neighborhood selection can be obtained as long as the number of observations n grows more quickly than 6d6 log d + 2d5 log p, thereby establishing that logarithmic growth in the number of samples n relative to graph size p is suﬃcient to achieve neighborhood consistency. Keywords: Graphical models; Markov random ﬁelds; structure learning; 1 -regularization; model selection; convex risk minimization; high-dimensional asymptotics; concentration. 1</p><p>same-paper 3 0.93655908 <a title="62-lda-3" href="./nips-2006-Correcting_Sample_Selection_Bias_by_Unlabeled_Data.html">62 nips-2006-Correcting Sample Selection Bias by Unlabeled Data</a></p>
<p>Author: Jiayuan Huang, Arthur Gretton, Karsten M. Borgwardt, Bernhard Schölkopf, Alex J. Smola</p><p>Abstract: We consider the scenario where training and test data are drawn from different distributions, commonly referred to as sample selection bias. Most algorithms for this setting try to ﬁrst recover sampling distributions and then make appropriate corrections based on the distribution estimate. We present a nonparametric method which directly produces resampling weights without distribution estimation. Our method works by matching distributions between training and testing sets in feature space. Experimental results demonstrate that our method works well in practice.</p><p>4 0.92972469 <a title="62-lda-4" href="./nips-2006-Scalable_Discriminative_Learning_for_Natural_Language_Parsing_and_Translation.html">172 nips-2006-Scalable Discriminative Learning for Natural Language Parsing and Translation</a></p>
<p>Author: Joseph Turian, Benjamin Wellington, I. D. Melamed</p><p>Abstract: Parsing and translating natural languages can be viewed as problems of predicting tree structures. For machine learning approaches to these predictions, the diversity and high dimensionality of the structures involved mandate very large training sets. This paper presents a purely discriminative learning method that scales up well to problems of this size. Its accuracy was at least as good as other comparable methods on a standard parsing task. To our knowledge, it is the ﬁrst purely discriminative learning algorithm for translation with treestructured models. Unlike other popular methods, this method does not require a great deal of feature engineering a priori, because it performs feature selection over a compound feature space as it learns. Experiments demonstrate the method’s versatility, accuracy, and eﬃciency. Relevant software is freely available at http://nlp.cs.nyu.edu/parser and http://nlp.cs.nyu.edu/GenPar. 1</p><p>5 0.74012309 <a title="62-lda-5" href="./nips-2006-implicit_Online_Learning_with_Kernels.html">203 nips-2006-implicit Online Learning with Kernels</a></p>
<p>Author: Li Cheng, Dale Schuurmans, Shaojun Wang, Terry Caelli, S.v.n. Vishwanathan</p><p>Abstract: We present two new algorithms for online learning in reproducing kernel Hilbert spaces. Our ﬁrst algorithm, ILK (implicit online learning with kernels), employs a new, implicit update technique that can be applied to a wide variety of convex loss functions. We then introduce a bounded memory version, SILK (sparse ILK), that maintains a compact representation of the predictor without compromising solution quality, even in non-stationary environments. We prove loss bounds and analyze the convergence rate of both. Experimental evidence shows that our proposed algorithms outperform current methods on synthetic and real data. 1</p><p>6 0.7168293 <a title="62-lda-6" href="./nips-2006-Real-time_adaptive_information-theoretic_optimization_of_neurophysiology_experiments.html">165 nips-2006-Real-time adaptive information-theoretic optimization of neurophysiology experiments</a></p>
<p>7 0.70493126 <a title="62-lda-7" href="./nips-2006-Logistic_Regression_for_Single_Trial_EEG_Classification.html">126 nips-2006-Logistic Regression for Single Trial EEG Classification</a></p>
<p>8 0.7048409 <a title="62-lda-8" href="./nips-2006-Convex_Repeated_Games_and_Fenchel_Duality.html">61 nips-2006-Convex Repeated Games and Fenchel Duality</a></p>
<p>9 0.68759823 <a title="62-lda-9" href="./nips-2006-Training_Conditional_Random_Fields_for_Maximum_Labelwise_Accuracy.html">195 nips-2006-Training Conditional Random Fields for Maximum Labelwise Accuracy</a></p>
<p>10 0.67769992 <a title="62-lda-10" href="./nips-2006-Dirichlet-Enhanced_Spam_Filtering_based_on_Biased_Samples.html">68 nips-2006-Dirichlet-Enhanced Spam Filtering based on Biased Samples</a></p>
<p>11 0.65679979 <a title="62-lda-11" href="./nips-2006-A_Kernel_Subspace_Method_by_Stochastic_Realization_for_Learning_Nonlinear_Dynamical_Systems.html">6 nips-2006-A Kernel Subspace Method by Stochastic Realization for Learning Nonlinear Dynamical Systems</a></p>
<p>12 0.65176928 <a title="62-lda-12" href="./nips-2006-Towards_a_general_independent_subspace_analysis.html">194 nips-2006-Towards a general independent subspace analysis</a></p>
<p>13 0.6479193 <a title="62-lda-13" href="./nips-2006-Mixture_Regression_for_Covariate_Shift.html">131 nips-2006-Mixture Regression for Covariate Shift</a></p>
<p>14 0.64284676 <a title="62-lda-14" href="./nips-2006-Differential_Entropic_Clustering_of_Multivariate_Gaussians.html">67 nips-2006-Differential Entropic Clustering of Multivariate Gaussians</a></p>
<p>15 0.64225137 <a title="62-lda-15" href="./nips-2006-A_PAC-Bayes_Risk_Bound_for_General_Loss_Functions.html">11 nips-2006-A PAC-Bayes Risk Bound for General Loss Functions</a></p>
<p>16 0.64090914 <a title="62-lda-16" href="./nips-2006-Generalized_Maximum_Margin_Clustering_and_Unsupervised_Kernel_Learning.html">83 nips-2006-Generalized Maximum Margin Clustering and Unsupervised Kernel Learning</a></p>
<p>17 0.63664097 <a title="62-lda-17" href="./nips-2006-Linearly-solvable_Markov_decision_problems.html">124 nips-2006-Linearly-solvable Markov decision problems</a></p>
<p>18 0.63121825 <a title="62-lda-18" href="./nips-2006-Online_Classification_for_Complex_Problems_Using_Simultaneous_Projections.html">152 nips-2006-Online Classification for Complex Problems Using Simultaneous Projections</a></p>
<p>19 0.62918991 <a title="62-lda-19" href="./nips-2006-A_Kernel_Method_for_the_Two-Sample-Problem.html">5 nips-2006-A Kernel Method for the Two-Sample-Problem</a></p>
<p>20 0.62804407 <a title="62-lda-20" href="./nips-2006-Active_learning_for_misspecified_generalized_linear_models.html">20 nips-2006-Active learning for misspecified generalized linear models</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
