<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>189 nips-2006-Temporal dynamics of information content carried by neurons in the primary visual cortex</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-189" href="#">nips2006-189</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>189 nips-2006-Temporal dynamics of information content carried by neurons in the primary visual cortex</h1>
<br/><p>Source: <a title="nips-2006-189-pdf" href="http://papers.nips.cc/paper/3096-temporal-dynamics-of-information-content-carried-by-neurons-in-the-primary-visual-cortex.pdf">pdf</a></p><p>Author: Danko Nikolić, Stefan Haeusler, Wolf Singer, Wolfgang Maass</p><p>Abstract: We use multi-electrode recordings from cat primary visual cortex and investigate whether a simple linear classifier can extract information about the presented stimuli. We find that information is extractable and that it even lasts for several hundred milliseconds after the stimulus has been removed. In a fast sequence of stimulus presentation, information about both new and old stimuli is present simultaneously and nonlinear relations between these stimuli can be extracted. These results suggest nonlinear properties of cortical representations. The important implications of these properties for the nonlinear brain theory are discussed.</p><p>Reference: <a title="nips-2006-189-reference" href="../nips2006_reference/nips-2006-Temporal_dynamics_of_information_content_carried_by_neurons_in_the_primary_visual_cortex_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Temporal dynamics of information content carried by neurons in the primary visual cortex  Danko NikoliC* Department of Neurophysiology Max-Planck-Institute for Brain Research, Frankfurt (Main), Germany danko@mpih -frankfurt. [sent-1, score-0.273]
</p><p>2 at  Abstract We use multi-electrode recordings from cat primary visual cortex and investigate whether a simple linear classifier can extract information about the presented stimuli. [sent-9, score-0.77]
</p><p>3 We find that information is extractable and that it even lasts for several hundred milliseconds after the stimulus has been removed. [sent-10, score-0.33]
</p><p>4 In a fast sequence of stimulus presentation, information about both new and old stimuli is present simultaneously and nonlinear relations between these stimuli can be extracted. [sent-11, score-0.602]
</p><p>5 It has also been argued that the recurrent neuronal circuits in the visual cortex are highly complex and thus, that notions such as "feedforward" and "feedback" are inadequate concepts for the analysis of nonlinear dynamical systems [2]. [sent-16, score-0.415]
</p><p>6 Furthermore, current theories do not take in account the precise timing of neuronal activity and synchronicity in responses, which should play an important computational role [3] . [sent-17, score-0.396]
</p><p>7 This information was extracted by algorithms from machine learning that classified the patterns of neuronal responses to different images. [sent-21, score-0.356]
</p><p>8 200 400 600 o  500 [  Time [ms]  Figure 1: A: An example of a visual stimulus in relation to the constellation of receptive fields (gray rectangles) from one Michigan probe. [sent-26, score-0.243]
</p><p>9 B: Spike times recorded from one electrode across 50 stimulus presentations and for two stimulation sequences (ABC and DBC). [sent-27, score-0.368]
</p><p>10 • We show that also neurons in cat primary visual cortex (area 17) and under anesthesia contain information about previously shown images and that this information lasts even longer. [sent-31, score-0.559]
</p><p>11 • We analyze the information content in neuronal activity recorded simultaneously from multiple electrodes. [sent-32, score-0.386]
</p><p>12 • We analyze the information about a previously shown stimulus for rapid sequences of images and how the information about consecutive images in a sequence is superimposed (i. [sent-33, score-0.285]
</p><p>13 ~  ,  Time [ms]  Figure 2: The abi lity of a linear classifier to determine which of the letters A or D was previously used as a stimul us. [sent-60, score-0.39]
</p><p>14 The classification performance is shown as a fu nction of time passed between the initiation of the experimental trial and the moment at which a sample of neuronal activity that was taken for training/test of the classifier. [sent-61, score-0.545]
</p><p>15 The classificatio n performance peaks at about 200 ms (reaching almost 100% accuracy) and remains high until at least 700 ms. [sent-62, score-0.329]
</p><p>16 The stimuli consisted of single white letters with elementary features suitable for area 17 and spanning approximately 5° of visual angle. [sent-76, score-0.303]
</p><p>17 In each stimulation condition either a single letter was presented or a sequence of up to three letters. [sent-80, score-0.426]
</p><p>18 For presentation of single letters we used letters A and D each presented for 100 ms. [sent-81, score-0.326]
</p><p>19 Stimulus sequences were made with letters A, B, C, D, and E and we compared either the responses across the sequences ABC, DBC, and ADC (cat 1) or across sequences ABE, CBE, ADE, and CDE (cats 2 and 3). [sent-82, score-0.366]
</p><p>20 Each member of a sequence was presented for 100 ms and the blank delay-period separating the presentation of letters lasted also 100 ms. [sent-83, score-0.518]
</p><p>21 Each stimulation condition (single letter or a sequence) was presented 50 to 150 times and the order of presentation was randomized across the stimulation conditions. [sent-84, score-0.649]
</p><p>22 Example raster plots of responses to two different sets of stimuli can be seen in Fig. [sent-85, score-0.237]
</p><p>23 We therefore used only units with mean firing rates ::::: 10 Hz and pooled single units with less frequent firings into multi-unit signals. [sent-92, score-0.226]
</p><p>24 A linear classifier was trained to discriminate between pairs of stimuli on the basis of the convolved spike trains at time points t E {O, 10, . [sent-95, score-0.609]
</p><p>25 , 700} ms after stimulus onset (using only the vectors of 66 to 124 values of the convolved time series at time t). [sent-98, score-0.471]
</p><p>26 T  A second type of classifier, which we refer to as R i n t , was trained to carry out such classification simultaneously for all time points t E {ISO, 160, . [sent-100, score-0.298]
</p><p>27 If not otherwise stated, the results for type R t classifiers are reported. [sent-105, score-0.405]
</p><p>28 A linear classifier applied to the convolved spike data (i. [sent-106, score-0.426]
</p><p>29 The time constant of 20 ms reflects the temporal properties of synaptic receptors and of the membrane. [sent-109, score-0.283]
</p><p>30 A classification is obtained due to the firing threshold of the I&F; neuron. [sent-110, score-0.354]
</p><p>31 The classifiers were trained with linear-kernel support vector machines with parameter G chosen to be 10 in case of 50 samples per stimulus class and 50 in case of 150 samples per stimulus. [sent-111, score-0.547]
</p><p>32 The classification performance was estimated with lO-fold cross validation in which we balanced the number of examples for the training and for the test class. [sent-112, score-0.238]
</p><p>33 1  Results High classification performance  As observed in IT [5], the classification performance peaks also in area 17 at about 200 ms after the stimulus onset. [sent-116, score-0.901]
</p><p>34 Therefore, a classifier can detect the identity of the stimulus with high reliability. [sent-117, score-0.47]
</p><p>35 In contrast to [5] information about stimuli is in our data available much longer and can last up to 700 ms after the stimulus onset (Fig. [sent-118, score-0.587]
</p><p>36 2  Memory for the past stimuli  We also find that even when new stimuli are presented, information about old stimuli is not erased. [sent-121, score-0.464]
</p><p>37 Instead, neuronal activity continued to maintain information about the previously presented stimuli. [sent-122, score-0.334]
</p><p>38 3 we show that classifiers can extract substantial information about the first image well after this image is removed and when new images are shown. [sent-124, score-0.438]
</p><p>39 Thus, the system maintains a memory of previous activations and this memory lasts at least several hundred milliseconds. [sent-125, score-0.231]
</p><p>40 Note that the information remains in memory even if neuronal rate responses decrease for a brief period of time and approach the level that is close to that of spontaneous activity. [sent-126, score-0.381]
</p><p>41 3  Simultaneous availability of different pieces of information  Simultaneous presence of information about different stimuli is a necessary prerequisite for efficient coding. [sent-128, score-0.24]
</p><p>42 4A shows that classifiers can identify the second letter in the sequence. [sent-130, score-0.624]
</p><p>43 4B we show the results of an experiment in which both the first and second letter were varied simultaneously. [sent-132, score-0.249]
</p><p>44 During the period from 250 to 300 ms information about both letters was available. [sent-134, score-0.356]
</p><p>45 This information can be used to perform a nonlinear XOR classification function, i. [sent-135, score-0.286]
</p><p>46 4C we show XOR classification based on the information extracted from the two classifiers in Fig. [sent-139, score-0.634]
</p><p>47 We compared these results with the performance of a single linear classifier that was trained to extract XOR information directly from the brain responses (solid line). [sent-142, score-0.593]
</p><p>48 As this classifier was linear, the nonlinear component of the computation could have been performed only by the brain. [sent-143, score-0.365]
</p><p>49 The classification performance was in both cases well above the chance level (horizontal dotted line in Fig. [sent-144, score-0.238]
</p><p>50 AID  100  C  B  80 N  ~  ~-;:- 80  c  co  Q)  '§  U  Q)  E 0 t:: ~ ,Eu  (fi ef  a. [sent-148, score-0.249]
</p><p>51 -:: c  20 0  0  AIC  100  E  B  80 N  ~  ~-;:- 80  Q)  c u  co  Q)  E 0 t:: ~ ,Eu  (fi ef  a. [sent-153, score-0.249]
</p><p>52 /  20 0  co Q)  ~  80 N  c u  co  co Q)  ~  Cat ;31  0  100  200  300 Time [ms]  400  500  600  0 700  . [sent-167, score-0.747]
</p><p>53 -:: c  co Q)  ~  Figure 3: Classifiers were trained to identify the first letter in the sequences ABC vs. [sent-169, score-0.6]
</p><p>54 In one case (cat 1) information about the first letter remained present even with multiple exchanges of the stimuli, i. [sent-173, score-0.278]
</p><p>55 4  Neural code  It is also important to understand how this information is encoded in neuronal activity. [sent-179, score-0.27]
</p><p>56 5 shows lower bounds for the informatio n contents of neuronal firing rates . [sent-181, score-0.359]
</p><p>57 The ability of the classifiers to distinguish between two stimuli was positively correlated to the difference in the average firing rate responses to these stimuli. [sent-182, score-0.766]
</p><p>58 In contrast to [5], we also fo und that in addition to rate responses, the precise ti ming relationships between neuronal spiking events carry important information about stimulus identity. [sent-191, score-0.438]
</p><p>59 We could demonstrate that jitter induces a significant drop in classification performance even for time points as far as 200 ms past the stimulus onset (the rightmost panel of Fig. [sent-198, score-0.802]
</p><p>60 We also investigated the 'synaptic' weights of the classifiers and this enabled us to study the temporal evolution of the code. [sent-200, score-0.44]
</p><p>61 We asked the foll owing question: Do the same pieces of information indicate the identity of a stimulus early and late in the stimulation sequence? [sent-201, score-0.347]
</p><p>62 The res ults indicated that the neuronal code was invariant during a single stimulation-response event (e. [sent-203, score-0.283]
</p><p>63 , on-  A  A  100 ~-;:- 80 c U co ID E 0 60 t:: ~ ,Eu 40 (fief 20 0  ~-;:c u co ID E 0 t:: ~ ,Eu  (fief  a. [sent-205, score-0.498]
</p><p>64 -::  "  -  -  c co  Mean fi ring rate  0  AIC  100 80 60 40 20 0 100 80 60 40 20 0  80 N  ~  a. [sent-213, score-0.286]
</p><p>65 - - - 1st letter - - - 2nd letter  AIC  BID  E  )-;. [sent-219, score-0.498]
</p><p>66 ·  Cat3 - - - XOR Extern al XOR  o  100  200  300  400  500  600  700  Time [ms]  Figure 4: Classification of the second letter in a sequence and of a combination of letters. [sent-221, score-0.278]
</p><p>67 A: Performance of a classifier trained to identify the second letter in the sequences ABC and ADC. [sent-222, score-0.659]
</p><p>68 Two classifiers identified either the first or the second letter of the following four sequences: ABE, CBE, ADE, and CDE . [sent-226, score-0.624]
</p><p>69 C: The same data as in B but a linear classifier was trained to compute the XOR function of the 2 bits encoded by the 2 choices AIC and BID (solid line). [sent-227, score-0.346]
</p><p>70 The dashed line indicates the performance of a control calculation made by an external computation of the XOR function that was based on the information extracted by the classifiers whose performance fu nctions are plotted in B. [sent-228, score-0.541]
</p><p>71 responses to the presentation of a letter) but changed across such events (e. [sent-229, score-0.225]
</p><p>72 , off-response to the same letter or on-response to the subsequent letter)(Fig. [sent-231, score-0.249]
</p><p>73 Finally, as in [5], an application of nonlinear radial-basis kernels did not produce significan t improvement in the number of correct classifications when compared to linear kernels and this was the case for type R t classifiers for which the improvement never exceeded 2% (results not shown) . [sent-233, score-0.462]
</p><p>74 However, the performance of type R int classifiers increased considerably (~8 % ) when they were trai ned with nonli near as opposed to linear kernels (time interval t = [150, 450] ms, res ults not shown). [sent-234, score-0.564]
</p><p>75 4  Discussion  In the present study we fi nd that information about preceding visual stimuli is preserved for several hundred ms in neurons of the primary vis ual cortex of anesthesized cats. [sent-235, score-0.749]
</p><p>76 These results are consistent to those reported by [5] who investigated neuronal activity in awake state and in a higher cortical area (IT-cortex). [sent-236, score-0.361]
</p><p>77 We show that information about a previously shown stimulus can last in visual cortex up to 700 ms, much longer than reported for IT-cortex. [sent-237, score-0.316]
</p><p>78 Hence, we can conclude that it is a general property of cortical networks to contain information about the stimuli in a distributed and time-dynamic manner. [sent-238, score-0.232]
</p><p>79 Thus, a trained classifier is capable to reliably determine fro m a short sample of this distributed activity the identity of previously presented stimuli. [sent-239, score-0.474]
</p><p>80 AID  100  C  B  160 N  ~  ~-;:- 80  c  co  Q)  "§  U  Q)  60  E 0 t:: ~ ,Eu  . [sent-240, score-0.249]
</p><p>81 -:: c  0  E  B  80 N  ~  ~-;:- 80  Q)  c u  co  Q)  "§  60  E 0 t:: ~ ,Eu  Cl  40  (fief  I  20  a. [sent-265, score-0.249]
</p><p>82 ~  co Q)  ~  80 N  Q)  c u  co  co Q)  ~  "§  60  Cl  -. [sent-279, score-0.747]
</p><p>83 -:: c  co Q)  ~  Figure 5 : The relation between classifier's performance and i) the mean firing rates (dash-dotted lines) and ii) the difference in the mean firing rates between two stimulation conditions (8 fold magnified, dashed lines). [sent-292, score-0.714]
</p><p>84 During the 1st letter presentation  After the 1st letter presentation  During the 2nd letter presentation  20  20  20  co 15  15  15  . [sent-295, score-1.395]
</p><p>85 :  e "0  o  5 10 15 20 SD of the jitter [ms]  o  5 10 15 20 SD of the jitter [ms]  o  5 10 15 20 SD of the jitter [ms]  Figure 6 : Drop in performance for the classifiers in Fig. [sent-301, score-0.74]
</p><p>86 For cat 1, these peaks were t E {60, 120, 200} ms and for cat 3, t E {40, 120, 230} ms. [sent-305, score-0.661]
</p><p>87 A standard deviation of only a few milliseconds decreased the classification performance significantly. [sent-308, score-0.284]
</p><p>88 Furthermore, the system's memory for the past stimulation is not necessarily erased by the presentation of a new stimulus, but it is instead possible to extract information about m Ultiple stim uli simultaneously. [sent-309, score-0.454]
</p><p>89 We show that different pieces of information are superimposed to each other and that they allow extraction of nonli near relations between the stim uli such as the XOR function. [sent-310, score-0.225]
</p><p>90 t readout In  Rt readout  100 60  60  40  40 ~  20  'c 20 ::>  80 ~~  c u  t1l Ql  E 0 t:: ~ o u  ~#  x  60  -  . [sent-312, score-0.292]
</p><p>91 Rint classifier was trained on the time intervals t = [150,450] ms and on the data in Fig. [sent-318, score-0.591]
</p><p>92 The performance drop of a type R int classifier during the presentation of the third letter indicates that the neural code has changed since the presentation of the second letter. [sent-320, score-1.006]
</p><p>93 B: Weight vector of the type R int classifier used in A. [sent-321, score-0.375]
</p><p>94 C: Weight vectors of the type R t classifier shown in A for t E {200, 300, 400} ms. [sent-322, score-0.338]
</p><p>95 Our results indicate that the neuronal code is not only contained in rate responses but that the precise spike-timing relations matter as well and that they carry additional and important information about the stimulus. [sent-323, score-0.434]
</p><p>96 Furthermore, almost all information extracted by the state-of-the-art nonlinear classifiers can be extracted by using simple linear classification mechanisms. [sent-324, score-0.721]
</p><p>97 Hence, similarly to our classifiers, cortical neurons should also be able to read out such information from distributed neuronal activity. [sent-326, score-0.351]
</p><p>98 These results have important implications for theories of brain function and for understanding the nature of computations performed by natural neuronal circuits. [sent-327, score-0.361]
</p><p>99 Fast readout of object identity from macaque inferior temporal cortex. [sent-374, score-0.269]
</p><p>100 Detection and assessment of near-zero delays in neuronal spiking activity. [sent-386, score-0.236]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('classifiers', 0.375), ('classifier', 0.308), ('letter', 0.249), ('co', 0.249), ('ms', 0.245), ('neuronal', 0.205), ('classification', 0.2), ('cat', 0.185), ('xor', 0.165), ('firing', 0.154), ('aic', 0.146), ('readout', 0.146), ('stimuli', 0.145), ('stimulus', 0.134), ('presentation', 0.133), ('fief', 0.125), ('stimulation', 0.119), ('cl', 0.11), ('jitter', 0.109), ('cats', 0.104), ('responses', 0.092), ('id', 0.086), ('letters', 0.082), ('cortex', 0.077), ('visual', 0.076), ('lasts', 0.072), ('bid', 0.072), ('activity', 0.071), ('sequences', 0.064), ('ade', 0.062), ('cbe', 0.062), ('dbc', 0.062), ('probes', 0.062), ('rfs', 0.062), ('rint', 0.062), ('abc', 0.062), ('spike', 0.06), ('neurons', 0.059), ('cortical', 0.058), ('convolved', 0.058), ('graz', 0.058), ('nonlinear', 0.057), ('memory', 0.055), ('brain', 0.054), ('recorded', 0.051), ('abe', 0.05), ('hundred', 0.049), ('milliseconds', 0.046), ('peaks', 0.046), ('hz', 0.046), ('resulted', 0.044), ('maass', 0.044), ('michigan', 0.044), ('drop', 0.042), ('cde', 0.042), ('danko', 0.042), ('frankfurt', 0.042), ('haeusler', 0.042), ('nonli', 0.042), ('pancuronium', 0.042), ('stim', 0.042), ('uli', 0.042), ('ults', 0.042), ('aid', 0.041), ('sd', 0.041), ('timing', 0.041), ('theories', 0.04), ('precise', 0.039), ('temporal', 0.038), ('trained', 0.038), ('performance', 0.038), ('fi', 0.037), ('int', 0.037), ('pieces', 0.037), ('computations', 0.036), ('code', 0.036), ('units', 0.036), ('onset', 0.034), ('extract', 0.034), ('schneider', 0.033), ('constellation', 0.033), ('coefficients', 0.033), ('relations', 0.033), ('primary', 0.032), ('spiking', 0.031), ('fu', 0.031), ('type', 0.03), ('extracted', 0.03), ('simultaneously', 0.03), ('sequence', 0.029), ('inferior', 0.029), ('presented', 0.029), ('information', 0.029), ('identity', 0.028), ('macaque', 0.028), ('frame', 0.027), ('investigated', 0.027), ('austria', 0.026), ('implications', 0.026), ('singer', 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000008 <a title="189-tfidf-1" href="./nips-2006-Temporal_dynamics_of_information_content_carried_by_neurons_in_the_primary_visual_cortex.html">189 nips-2006-Temporal dynamics of information content carried by neurons in the primary visual cortex</a></p>
<p>Author: Danko Nikolić, Stefan Haeusler, Wolf Singer, Wolfgang Maass</p><p>Abstract: We use multi-electrode recordings from cat primary visual cortex and investigate whether a simple linear classifier can extract information about the presented stimuli. We find that information is extractable and that it even lasts for several hundred milliseconds after the stimulus has been removed. In a fast sequence of stimulus presentation, information about both new and old stimuli is present simultaneously and nonlinear relations between these stimuli can be extracted. These results suggest nonlinear properties of cortical representations. The important implications of these properties for the nonlinear brain theory are discussed.</p><p>2 0.17494629 <a title="189-tfidf-2" href="./nips-2006-Neurophysiological_Evidence_of_Cooperative_Mechanisms_for_Stereo_Computation.html">145 nips-2006-Neurophysiological Evidence of Cooperative Mechanisms for Stereo Computation</a></p>
<p>Author: Jason M. Samonds, Brian R. Potetz, Tai S. Lee</p><p>Abstract: Although there has been substantial progress in understanding the neurophysiological mechanisms of stereopsis, how neurons interact in a network during stereo computation remains unclear. Computational models on stereopsis suggest local competition and long-range cooperation are important for resolving ambiguity during stereo matching. To test these predictions, we simultaneously recorded from multiple neurons in V1 of awake, behaving macaques while presenting surfaces of different depths rendered in dynamic random dot stereograms. We found that the interaction between pairs of neurons was a function of similarity in receptive fields, as well as of the input stimulus. Neurons coding the same depth experienced common inhibition early in their responses for stimuli presented at their nonpreferred disparities. They experienced mutual facilitation later in their responses for stimulation at their preferred disparity. These findings are consistent with a local competition mechanism that first removes gross mismatches, and a global cooperative mechanism that further refines depth estimates. 1 In trod u ction The human visual system is able to extract three-dimensional (3D) structures in random noise stereograms even when such images evoke no perceptible patterns when viewed monocularly [1]. Bela Julesz proposed that this is accomplished by a stereopsis mechanism that detects correlated shifts in 2D noise patterns between the two eyes. He also suggested that this mechanism likely involves cooperative neural processing early in the visual system. Marr and Poggio formalized the computational constraints for solving stereo matching (Fig. 1a) and devised an algorithm that can discover the underlying 3D structures in a variety of random dot stereogram patterns [2]. Their algorithm was based on two rules: (1) each element or feature is unique (i.e., can be assigned only one disparity) and (2) surfaces of objects are cohesive (i.e., depth changes gradually across space). To describe their algorithm in neurophysiological terms, we can consider neurons in primary visual cortex as simple element or feature detectors. The first rule is implemented by introducing competitive interactions (mutual inhibition) among neurons of different disparity tuning at each location (Fig. 1b, blue solid horizontal or vertical lines), allowing only one disparity to be detected at each location. The second rule is implemented by introducing cooperative interactions (mutual facilitation) among neurons tuned to the same depth (image disparity) across different spatial locations (Fig. 1b, along the red dashed diagonal lines). In other words, a disparity estimate at one location is more likely to be correct if neighboring locations have similar disparity estimates. A dynamic system under such constraints can relax to a stable global disparity map. Here, we present neurophysiological evidence of interactions between disparity-tuned neurons in the primary visual cortex that is consistent with this general approach. We sampled from a variety of spatially distributed disparity tuned neurons (see electrodes Fig. 1b) while displaying DRDS stimuli defined at various disparities (see stimulus Fig.1b). We then measured the dynamics of interactions by assessing the temporal evolution of correlation in neural responses. a Left Image b Right Image Electrodes Disparity Left Image ? Stimulus Right Image Figure 1: (a) Left and right images of random dot stereogram (right image has been shifted to the right). (b) 1D graphical depiction of competition (blue solid lines) and cooperation (red dashed lines) among disparity-tuned neurons with respect to space as defined by Marr and Poggio’s stereo algorithm [2]. 2 2.1 Methods Recording and stimulation a Posterior - Anterior Recordings were made in V1 of two awake, behaving macaques. We simultaneously recorded from 4-8 electrodes providing data from up to 10 neurons in a single recording session (some electrodes recorded from as many as 3 neurons). We collected data from 112 neurons that provided 224 pairs for cross-correlation analysis. For stimuli, we used 12 Hz dynamic random dot stereograms (DRDS; 25% density black and white pixels on a mean luminance background) presented in a 3.5-degree aperture. Liquid crystal shutter goggles were used to present random dot patterns to each eye separately. Eleven horizontal disparities between the two eyes, ranging from ±0.9 degrees, were tested. Seventy-four neurons (66%) had significant disparity tuning and 99 pairs (44%) were comprised of neurons that both had significant disparity tuning (1-way ANOVA, p<0.05). b 5mm Medial - Lateral 100µV 0.2ms 1° Figure 2: (a) Example recording session from five electrodes in V1. (b) Receptive field (white box—arrow represents direction preference) and random dot stereogram locations for same recording session (small red square is the fixation spot). 2.2 Data analysis Interaction between neurons was described as</p><p>3 0.098854072 <a title="189-tfidf-3" href="./nips-2006-Context_dependent_amplification_of_both_rate_and_event-correlation_in_a_VLSI_network_of_spiking_neurons.html">59 nips-2006-Context dependent amplification of both rate and event-correlation in a VLSI network of spiking neurons</a></p>
<p>Author: Elisabetta Chicca, Giacomo Indiveri, Rodney J. Douglas</p><p>Abstract: Cooperative competitive networks are believed to play a central role in cortical processing and have been shown to exhibit a wide set of useful computational properties. We propose a VLSI implementation of a spiking cooperative competitive network and show how it can perform context dependent computation both in the mean ﬁring rate domain and in spike timing correlation space. In the mean rate case the network ampliﬁes the activity of neurons belonging to the selected stimulus and suppresses the activity of neurons receiving weaker stimuli. In the event correlation case, the recurrent network ampliﬁes with a higher gain the correlation between neurons which receive highly correlated inputs while leaving the mean ﬁring rate unaltered. We describe the network architecture and present experimental data demonstrating its context dependent computation capabilities. 1</p><p>4 0.098751947 <a title="189-tfidf-4" href="./nips-2006-Temporal_Coding_using_the_Response_Properties_of_Spiking_Neurons.html">187 nips-2006-Temporal Coding using the Response Properties of Spiking Neurons</a></p>
<p>Author: Thomas Voegtlin</p><p>Abstract: In biological neurons, the timing of a spike depends on the timing of synaptic currents, in a way that is classically described by the Phase Response Curve. This has implications for temporal coding: an action potential that arrives on a synapse has an implicit meaning, that depends on the position of the postsynaptic neuron on the ﬁring cycle. Here we show that this implicit code can be used to perform computations. Using theta neurons, we derive a spike-timing dependent learning rule from an error criterion. We demonstrate how to train an auto-encoder neural network using this rule. 1</p><p>5 0.096822187 <a title="189-tfidf-5" href="./nips-2006-Uncertainty%2C_phase_and_oscillatory_hippocampal_recall.html">197 nips-2006-Uncertainty, phase and oscillatory hippocampal recall</a></p>
<p>Author: Máté Lengyel, Peter Dayan</p><p>Abstract: Many neural areas, notably, the hippocampus, show structured, dynamical, population behavior such as coordinated oscillations. It has long been observed that such oscillations provide a substrate for representing analog information in the ﬁring phases of neurons relative to the underlying population rhythm. However, it has become increasingly clear that it is essential for neural populations to represent uncertainty about the information they capture, and the substantial recent work on neural codes for uncertainty has omitted any analysis of oscillatory systems. Here, we observe that, since neurons in an oscillatory network need not only ﬁre once in each cycle (or even at all), uncertainty about the analog quantities each neuron represents by its ﬁring phase might naturally be reported through the degree of concentration of the spikes that it ﬁres. We apply this theory to memory in a model of oscillatory associative recall in hippocampal area CA3. Although it is not well treated in the literature, representing and manipulating uncertainty is fundamental to competent memory; our theory enables us to view CA3 as an effective uncertainty-aware, retrieval system. 1</p><p>6 0.094865173 <a title="189-tfidf-6" href="./nips-2006-Optimal_Change-Detection_and_Spiking_Neurons.html">154 nips-2006-Optimal Change-Detection and Spiking Neurons</a></p>
<p>7 0.09041921 <a title="189-tfidf-7" href="./nips-2006-Real-time_adaptive_information-theoretic_optimization_of_neurophysiology_experiments.html">165 nips-2006-Real-time adaptive information-theoretic optimization of neurophysiology experiments</a></p>
<p>8 0.076473415 <a title="189-tfidf-8" href="./nips-2006-Attentional_Processing_on_a_Spike-Based_VLSI_Neural_Network.html">36 nips-2006-Attentional Processing on a Spike-Based VLSI Neural Network</a></p>
<p>9 0.073428996 <a title="189-tfidf-9" href="./nips-2006-Predicting_spike_times_from_subthreshold_dynamics_of_a_neuron.html">162 nips-2006-Predicting spike times from subthreshold dynamics of a neuron</a></p>
<p>10 0.070784457 <a title="189-tfidf-10" href="./nips-2006-Information_Bottleneck_Optimization_and_Independent_Component_Extraction_with_Spiking_Neurons.html">99 nips-2006-Information Bottleneck Optimization and Independent Component Extraction with Spiking Neurons</a></p>
<p>11 0.063897096 <a title="189-tfidf-11" href="./nips-2006-A_Bayesian_Approach_to_Diffusion_Models_of_Decision-Making_and_Response_Time.html">1 nips-2006-A Bayesian Approach to Diffusion Models of Decision-Making and Response Time</a></p>
<p>12 0.059744466 <a title="189-tfidf-12" href="./nips-2006-A_Probabilistic_Algorithm_Integrating_Source_Localization_and_Noise_Suppression_of_MEG_and_EEG_data.html">12 nips-2006-A Probabilistic Algorithm Integrating Source Localization and Noise Suppression of MEG and EEG data</a></p>
<p>13 0.058594517 <a title="189-tfidf-13" href="./nips-2006-Near-Uniform_Sampling_of_Combinatorial_Spaces_Using_XOR_Constraints.html">144 nips-2006-Near-Uniform Sampling of Combinatorial Spaces Using XOR Constraints</a></p>
<p>14 0.057981923 <a title="189-tfidf-14" href="./nips-2006-Emergence_of_conjunctive_visual_features_by_quadratic_independent_component_analysis.html">76 nips-2006-Emergence of conjunctive visual features by quadratic independent component analysis</a></p>
<p>15 0.056409221 <a title="189-tfidf-15" href="./nips-2006-A_Nonparametric_Approach_to_Bottom-Up_Visual_Saliency.html">8 nips-2006-A Nonparametric Approach to Bottom-Up Visual Saliency</a></p>
<p>16 0.053650927 <a title="189-tfidf-16" href="./nips-2006-Theory_and_Dynamics_of_Perceptual_Bistability.html">192 nips-2006-Theory and Dynamics of Perceptual Bistability</a></p>
<p>17 0.053009793 <a title="189-tfidf-17" href="./nips-2006-A_selective_attention_multi--chip_system_with_dynamic_synapses_and_spiking_neurons.html">18 nips-2006-A selective attention multi--chip system with dynamic synapses and spiking neurons</a></p>
<p>18 0.052967951 <a title="189-tfidf-18" href="./nips-2006-A_recipe_for_optimizing_a_time-histogram.html">17 nips-2006-A recipe for optimizing a time-histogram</a></p>
<p>19 0.051827155 <a title="189-tfidf-19" href="./nips-2006-Recursive_ICA.html">167 nips-2006-Recursive ICA</a></p>
<p>20 0.051180813 <a title="189-tfidf-20" href="./nips-2006-Nonlinear_physically-based_models_for_decoding_motor-cortical_population_activity.html">148 nips-2006-Nonlinear physically-based models for decoding motor-cortical population activity</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2006_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.133), (1, -0.201), (2, 0.046), (3, 0.016), (4, -0.029), (5, -0.026), (6, 0.004), (7, -0.018), (8, -0.003), (9, -0.017), (10, 0.049), (11, 0.021), (12, -0.066), (13, -0.042), (14, -0.078), (15, -0.029), (16, 0.037), (17, -0.024), (18, -0.063), (19, -0.036), (20, 0.006), (21, 0.046), (22, 0.025), (23, -0.047), (24, 0.023), (25, -0.012), (26, 0.028), (27, -0.069), (28, 0.039), (29, 0.012), (30, -0.015), (31, 0.014), (32, 0.111), (33, 0.063), (34, -0.094), (35, 0.033), (36, 0.053), (37, 0.061), (38, -0.144), (39, -0.026), (40, -0.15), (41, 0.025), (42, 0.078), (43, 0.012), (44, 0.141), (45, -0.082), (46, 0.022), (47, 0.077), (48, -0.044), (49, -0.007)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95113671 <a title="189-lsi-1" href="./nips-2006-Temporal_dynamics_of_information_content_carried_by_neurons_in_the_primary_visual_cortex.html">189 nips-2006-Temporal dynamics of information content carried by neurons in the primary visual cortex</a></p>
<p>Author: Danko Nikolić, Stefan Haeusler, Wolf Singer, Wolfgang Maass</p><p>Abstract: We use multi-electrode recordings from cat primary visual cortex and investigate whether a simple linear classifier can extract information about the presented stimuli. We find that information is extractable and that it even lasts for several hundred milliseconds after the stimulus has been removed. In a fast sequence of stimulus presentation, information about both new and old stimuli is present simultaneously and nonlinear relations between these stimuli can be extracted. These results suggest nonlinear properties of cortical representations. The important implications of these properties for the nonlinear brain theory are discussed.</p><p>2 0.64277214 <a title="189-lsi-2" href="./nips-2006-Neurophysiological_Evidence_of_Cooperative_Mechanisms_for_Stereo_Computation.html">145 nips-2006-Neurophysiological Evidence of Cooperative Mechanisms for Stereo Computation</a></p>
<p>Author: Jason M. Samonds, Brian R. Potetz, Tai S. Lee</p><p>Abstract: Although there has been substantial progress in understanding the neurophysiological mechanisms of stereopsis, how neurons interact in a network during stereo computation remains unclear. Computational models on stereopsis suggest local competition and long-range cooperation are important for resolving ambiguity during stereo matching. To test these predictions, we simultaneously recorded from multiple neurons in V1 of awake, behaving macaques while presenting surfaces of different depths rendered in dynamic random dot stereograms. We found that the interaction between pairs of neurons was a function of similarity in receptive fields, as well as of the input stimulus. Neurons coding the same depth experienced common inhibition early in their responses for stimuli presented at their nonpreferred disparities. They experienced mutual facilitation later in their responses for stimulation at their preferred disparity. These findings are consistent with a local competition mechanism that first removes gross mismatches, and a global cooperative mechanism that further refines depth estimates. 1 In trod u ction The human visual system is able to extract three-dimensional (3D) structures in random noise stereograms even when such images evoke no perceptible patterns when viewed monocularly [1]. Bela Julesz proposed that this is accomplished by a stereopsis mechanism that detects correlated shifts in 2D noise patterns between the two eyes. He also suggested that this mechanism likely involves cooperative neural processing early in the visual system. Marr and Poggio formalized the computational constraints for solving stereo matching (Fig. 1a) and devised an algorithm that can discover the underlying 3D structures in a variety of random dot stereogram patterns [2]. Their algorithm was based on two rules: (1) each element or feature is unique (i.e., can be assigned only one disparity) and (2) surfaces of objects are cohesive (i.e., depth changes gradually across space). To describe their algorithm in neurophysiological terms, we can consider neurons in primary visual cortex as simple element or feature detectors. The first rule is implemented by introducing competitive interactions (mutual inhibition) among neurons of different disparity tuning at each location (Fig. 1b, blue solid horizontal or vertical lines), allowing only one disparity to be detected at each location. The second rule is implemented by introducing cooperative interactions (mutual facilitation) among neurons tuned to the same depth (image disparity) across different spatial locations (Fig. 1b, along the red dashed diagonal lines). In other words, a disparity estimate at one location is more likely to be correct if neighboring locations have similar disparity estimates. A dynamic system under such constraints can relax to a stable global disparity map. Here, we present neurophysiological evidence of interactions between disparity-tuned neurons in the primary visual cortex that is consistent with this general approach. We sampled from a variety of spatially distributed disparity tuned neurons (see electrodes Fig. 1b) while displaying DRDS stimuli defined at various disparities (see stimulus Fig.1b). We then measured the dynamics of interactions by assessing the temporal evolution of correlation in neural responses. a Left Image b Right Image Electrodes Disparity Left Image ? Stimulus Right Image Figure 1: (a) Left and right images of random dot stereogram (right image has been shifted to the right). (b) 1D graphical depiction of competition (blue solid lines) and cooperation (red dashed lines) among disparity-tuned neurons with respect to space as defined by Marr and Poggio’s stereo algorithm [2]. 2 2.1 Methods Recording and stimulation a Posterior - Anterior Recordings were made in V1 of two awake, behaving macaques. We simultaneously recorded from 4-8 electrodes providing data from up to 10 neurons in a single recording session (some electrodes recorded from as many as 3 neurons). We collected data from 112 neurons that provided 224 pairs for cross-correlation analysis. For stimuli, we used 12 Hz dynamic random dot stereograms (DRDS; 25% density black and white pixels on a mean luminance background) presented in a 3.5-degree aperture. Liquid crystal shutter goggles were used to present random dot patterns to each eye separately. Eleven horizontal disparities between the two eyes, ranging from ±0.9 degrees, were tested. Seventy-four neurons (66%) had significant disparity tuning and 99 pairs (44%) were comprised of neurons that both had significant disparity tuning (1-way ANOVA, p<0.05). b 5mm Medial - Lateral 100µV 0.2ms 1° Figure 2: (a) Example recording session from five electrodes in V1. (b) Receptive field (white box—arrow represents direction preference) and random dot stereogram locations for same recording session (small red square is the fixation spot). 2.2 Data analysis Interaction between neurons was described as</p><p>3 0.50097263 <a title="189-lsi-3" href="./nips-2006-A_Bayesian_Approach_to_Diffusion_Models_of_Decision-Making_and_Response_Time.html">1 nips-2006-A Bayesian Approach to Diffusion Models of Decision-Making and Response Time</a></p>
<p>Author: Michael D. Lee, Ian G. Fuss, Daniel J. Navarro</p><p>Abstract: We present a computational Bayesian approach for Wiener diffusion models, which are prominent accounts of response time distributions in decision-making. We ﬁrst develop a general closed-form analytic approximation to the response time distributions for one-dimensional diffusion processes, and derive the required Wiener diffusion as a special case. We use this result to undertake Bayesian modeling of benchmark data, using posterior sampling to draw inferences about the interesting psychological parameters. With the aid of the benchmark data, we show the Bayesian account has several advantages, including dealing naturally with the parameter variation needed to account for some key features of the data, and providing quantitative measures to guide decisions about model construction. 1</p><p>4 0.47143477 <a title="189-lsi-4" href="./nips-2006-Theory_and_Dynamics_of_Perceptual_Bistability.html">192 nips-2006-Theory and Dynamics of Perceptual Bistability</a></p>
<p>Author: Paul R. Schrater, Rashmi Sundareswara</p><p>Abstract: Perceptual Bistability refers to the phenomenon of spontaneously switching between two or more interpretations of an image under continuous viewing. Although switching behavior is increasingly well characterized, the origins remain elusive. We propose that perceptual switching naturally arises from the brain’s search for best interpretations while performing Bayesian inference. In particular, we propose that the brain explores a posterior distribution over image interpretations at a rapid time scale via a sampling-like process and updates its interpretation when a sampled interpretation is better than the discounted value of its current interpretation. We formalize the theory, explicitly derive switching rate distributions and discuss qualitative properties of the theory including the effect of changes in the posterior distribution on switching rates. Finally, predictions of the theory are shown to be consistent with measured changes in human switching dynamics to Necker cube stimuli induced by context.</p><p>5 0.43854263 <a title="189-lsi-5" href="./nips-2006-Uncertainty%2C_phase_and_oscillatory_hippocampal_recall.html">197 nips-2006-Uncertainty, phase and oscillatory hippocampal recall</a></p>
<p>Author: Máté Lengyel, Peter Dayan</p><p>Abstract: Many neural areas, notably, the hippocampus, show structured, dynamical, population behavior such as coordinated oscillations. It has long been observed that such oscillations provide a substrate for representing analog information in the ﬁring phases of neurons relative to the underlying population rhythm. However, it has become increasingly clear that it is essential for neural populations to represent uncertainty about the information they capture, and the substantial recent work on neural codes for uncertainty has omitted any analysis of oscillatory systems. Here, we observe that, since neurons in an oscillatory network need not only ﬁre once in each cycle (or even at all), uncertainty about the analog quantities each neuron represents by its ﬁring phase might naturally be reported through the degree of concentration of the spikes that it ﬁres. We apply this theory to memory in a model of oscillatory associative recall in hippocampal area CA3. Although it is not well treated in the literature, representing and manipulating uncertainty is fundamental to competent memory; our theory enables us to view CA3 as an effective uncertainty-aware, retrieval system. 1</p><p>6 0.43515998 <a title="189-lsi-6" href="./nips-2006-Near-Uniform_Sampling_of_Combinatorial_Spaces_Using_XOR_Constraints.html">144 nips-2006-Near-Uniform Sampling of Combinatorial Spaces Using XOR Constraints</a></p>
<p>7 0.42244431 <a title="189-lsi-7" href="./nips-2006-Real-time_adaptive_information-theoretic_optimization_of_neurophysiology_experiments.html">165 nips-2006-Real-time adaptive information-theoretic optimization of neurophysiology experiments</a></p>
<p>8 0.41527912 <a title="189-lsi-8" href="./nips-2006-Context_dependent_amplification_of_both_rate_and_event-correlation_in_a_VLSI_network_of_spiking_neurons.html">59 nips-2006-Context dependent amplification of both rate and event-correlation in a VLSI network of spiking neurons</a></p>
<p>9 0.40766004 <a title="189-lsi-9" href="./nips-2006-Optimal_Change-Detection_and_Spiking_Neurons.html">154 nips-2006-Optimal Change-Detection and Spiking Neurons</a></p>
<p>10 0.38087529 <a title="189-lsi-10" href="./nips-2006-Temporal_Coding_using_the_Response_Properties_of_Spiking_Neurons.html">187 nips-2006-Temporal Coding using the Response Properties of Spiking Neurons</a></p>
<p>11 0.3764025 <a title="189-lsi-11" href="./nips-2006-Attentional_Processing_on_a_Spike-Based_VLSI_Neural_Network.html">36 nips-2006-Attentional Processing on a Spike-Based VLSI Neural Network</a></p>
<p>12 0.35534036 <a title="189-lsi-12" href="./nips-2006-Causal_inference_in_sensorimotor_integration.html">49 nips-2006-Causal inference in sensorimotor integration</a></p>
<p>13 0.34010759 <a title="189-lsi-13" href="./nips-2006-Predicting_spike_times_from_subthreshold_dynamics_of_a_neuron.html">162 nips-2006-Predicting spike times from subthreshold dynamics of a neuron</a></p>
<p>14 0.34000564 <a title="189-lsi-14" href="./nips-2006-Nonlinear_physically-based_models_for_decoding_motor-cortical_population_activity.html">148 nips-2006-Nonlinear physically-based models for decoding motor-cortical population activity</a></p>
<p>15 0.33817676 <a title="189-lsi-15" href="./nips-2006-Learning_Structural_Equation_Models_for_fMRI.html">113 nips-2006-Learning Structural Equation Models for fMRI</a></p>
<p>16 0.30507824 <a title="189-lsi-16" href="./nips-2006-A_selective_attention_multi--chip_system_with_dynamic_synapses_and_spiking_neurons.html">18 nips-2006-A selective attention multi--chip system with dynamic synapses and spiking neurons</a></p>
<p>17 0.30213803 <a title="189-lsi-17" href="./nips-2006-An_Information_Theoretic_Framework_for_Eukaryotic_Gradient_Sensing.html">29 nips-2006-An Information Theoretic Framework for Eukaryotic Gradient Sensing</a></p>
<p>18 0.30077714 <a title="189-lsi-18" href="./nips-2006-Information_Bottleneck_Optimization_and_Independent_Component_Extraction_with_Spiking_Neurons.html">99 nips-2006-Information Bottleneck Optimization and Independent Component Extraction with Spiking Neurons</a></p>
<p>19 0.29797611 <a title="189-lsi-19" href="./nips-2006-A_Theory_of_Retinal_Population_Coding.html">16 nips-2006-A Theory of Retinal Population Coding</a></p>
<p>20 0.29529586 <a title="189-lsi-20" href="./nips-2006-Context_Effects_in_Category_Learning%3A_An_Investigation_of_Four_Probabilistic_Models.html">58 nips-2006-Context Effects in Category Learning: An Investigation of Four Probabilistic Models</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2006_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(1, 0.075), (3, 0.032), (6, 0.016), (7, 0.046), (9, 0.042), (22, 0.024), (30, 0.403), (44, 0.044), (57, 0.048), (65, 0.032), (69, 0.025), (71, 0.107), (82, 0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.76381439 <a title="189-lda-1" href="./nips-2006-Temporal_dynamics_of_information_content_carried_by_neurons_in_the_primary_visual_cortex.html">189 nips-2006-Temporal dynamics of information content carried by neurons in the primary visual cortex</a></p>
<p>Author: Danko Nikolić, Stefan Haeusler, Wolf Singer, Wolfgang Maass</p><p>Abstract: We use multi-electrode recordings from cat primary visual cortex and investigate whether a simple linear classifier can extract information about the presented stimuli. We find that information is extractable and that it even lasts for several hundred milliseconds after the stimulus has been removed. In a fast sequence of stimulus presentation, information about both new and old stimuli is present simultaneously and nonlinear relations between these stimuli can be extracted. These results suggest nonlinear properties of cortical representations. The important implications of these properties for the nonlinear brain theory are discussed.</p><p>2 0.46396571 <a title="189-lda-2" href="./nips-2006-Simplifying_Mixture_Models_through_Function_Approximation.html">175 nips-2006-Simplifying Mixture Models through Function Approximation</a></p>
<p>Author: Kai Zhang, James T. Kwok</p><p>Abstract: Finite mixture model is a powerful tool in many statistical learning problems. In this paper, we propose a general, structure-preserving approach to reduce its model complexity, which can bring signiﬁcant computational beneﬁts in many applications. The basic idea is to group the original mixture components into compact clusters, and then minimize an upper bound on the approximation error between the original and simpliﬁed models. By adopting the L2 norm as the distance measure between mixture models, we can derive closed-form solutions that are more robust and reliable than using the KL-based distance measure. Moreover, the complexity of our algorithm is only linear in the sample size and dimensionality. Experiments on density estimation and clustering-based image segmentation demonstrate its outstanding performance in terms of both speed and accuracy.</p><p>3 0.37704945 <a title="189-lda-3" href="./nips-2006-Modelling_transcriptional_regulation_using_Gaussian_Processes.html">135 nips-2006-Modelling transcriptional regulation using Gaussian Processes</a></p>
<p>Author: Neil D. Lawrence, Guido Sanguinetti, Magnus Rattray</p><p>Abstract: Modelling the dynamics of transcriptional processes in the cell requires the knowledge of a number of key biological quantities. While some of them are relatively easy to measure, such as mRNA decay rates and mRNA abundance levels, it is still very hard to measure the active concentration levels of the transcription factor proteins that drive the process and the sensitivity of target genes to these concentrations. In this paper we show how these quantities for a given transcription factor can be inferred from gene expression levels of a set of known target genes. We treat the protein concentration as a latent function with a Gaussian process prior, and include the sensitivities, mRNA decay rates and baseline expression levels as hyperparameters. We apply this procedure to a human leukemia dataset, focusing on the tumour repressor p53 and obtaining results in good accordance with recent biological studies.</p><p>4 0.36947602 <a title="189-lda-4" href="./nips-2006-The_Robustness-Performance_Tradeoff_in_Markov_Decision_Processes.html">191 nips-2006-The Robustness-Performance Tradeoff in Markov Decision Processes</a></p>
<p>Author: Huan Xu, Shie Mannor</p><p>Abstract: Computation of a satisfactory control policy for a Markov decision process when the parameters of the model are not exactly known is a problem encountered in many practical applications. The traditional robust approach is based on a worstcase analysis and may lead to an overly conservative policy. In this paper we consider the tradeoff between nominal performance and the worst case performance over all possible models. Based on parametric linear programming, we propose a method that computes the whole set of Pareto efﬁcient policies in the performancerobustness plane when only the reward parameters are subject to uncertainty. In the more general case when the transition probabilities are also subject to error, we show that the strategy with the “optimal” tradeoff might be non-Markovian and hence is in general not tractable. 1</p><p>5 0.3686094 <a title="189-lda-5" href="./nips-2006-Fundamental_Limitations_of_Spectral_Clustering.html">80 nips-2006-Fundamental Limitations of Spectral Clustering</a></p>
<p>Author: Boaz Nadler, Meirav Galun</p><p>Abstract: Spectral clustering methods are common graph-based approaches to clustering of data. Spectral clustering algorithms typically start from local information encoded in a weighted graph on the data and cluster according to the global eigenvectors of the corresponding (normalized) similarity matrix. One contribution of this paper is to present fundamental limitations of this general local to global approach. We show that based only on local information, the normalized cut functional is not a suitable measure for the quality of clustering. Further, even with a suitable similarity measure, we show that the ﬁrst few eigenvectors of such adjacency matrices cannot successfully cluster datasets that contain structures at different scales of size and density. Based on these ﬁndings, a second contribution of this paper is a novel diffusion based measure to evaluate the coherence of individual clusters. Our measure can be used in conjunction with any bottom-up graph-based clustering method, it is scale-free and can determine coherent clusters at all scales. We present both synthetic examples and real image segmentation problems where various spectral clustering algorithms fail. In contrast, using this coherence measure ﬁnds the expected clusters at all scales. Keywords: Clustering, kernels, learning theory. 1</p><p>6 0.36210018 <a title="189-lda-6" href="./nips-2006-Attentional_Processing_on_a_Spike-Based_VLSI_Neural_Network.html">36 nips-2006-Attentional Processing on a Spike-Based VLSI Neural Network</a></p>
<p>7 0.35946307 <a title="189-lda-7" href="./nips-2006-Neurophysiological_Evidence_of_Cooperative_Mechanisms_for_Stereo_Computation.html">145 nips-2006-Neurophysiological Evidence of Cooperative Mechanisms for Stereo Computation</a></p>
<p>8 0.35839573 <a title="189-lda-8" href="./nips-2006-Temporal_Coding_using_the_Response_Properties_of_Spiking_Neurons.html">187 nips-2006-Temporal Coding using the Response Properties of Spiking Neurons</a></p>
<p>9 0.33508304 <a title="189-lda-9" href="./nips-2006-Information_Bottleneck_Optimization_and_Independent_Component_Extraction_with_Spiking_Neurons.html">99 nips-2006-Information Bottleneck Optimization and Independent Component Extraction with Spiking Neurons</a></p>
<p>10 0.33325526 <a title="189-lda-10" href="./nips-2006-Predicting_spike_times_from_subthreshold_dynamics_of_a_neuron.html">162 nips-2006-Predicting spike times from subthreshold dynamics of a neuron</a></p>
<p>11 0.32452649 <a title="189-lda-11" href="./nips-2006-Context_dependent_amplification_of_both_rate_and_event-correlation_in_a_VLSI_network_of_spiking_neurons.html">59 nips-2006-Context dependent amplification of both rate and event-correlation in a VLSI network of spiking neurons</a></p>
<p>12 0.31978935 <a title="189-lda-12" href="./nips-2006-Optimal_Change-Detection_and_Spiking_Neurons.html">154 nips-2006-Optimal Change-Detection and Spiking Neurons</a></p>
<p>13 0.31475431 <a title="189-lda-13" href="./nips-2006-Real-time_adaptive_information-theoretic_optimization_of_neurophysiology_experiments.html">165 nips-2006-Real-time adaptive information-theoretic optimization of neurophysiology experiments</a></p>
<p>14 0.30544969 <a title="189-lda-14" href="./nips-2006-Recursive_ICA.html">167 nips-2006-Recursive ICA</a></p>
<p>15 0.2977348 <a title="189-lda-15" href="./nips-2006-A_Nonparametric_Approach_to_Bottom-Up_Visual_Saliency.html">8 nips-2006-A Nonparametric Approach to Bottom-Up Visual Saliency</a></p>
<p>16 0.2972624 <a title="189-lda-16" href="./nips-2006-A_Theory_of_Retinal_Population_Coding.html">16 nips-2006-A Theory of Retinal Population Coding</a></p>
<p>17 0.29715586 <a title="189-lda-17" href="./nips-2006-An_Information_Theoretic_Framework_for_Eukaryotic_Gradient_Sensing.html">29 nips-2006-An Information Theoretic Framework for Eukaryotic Gradient Sensing</a></p>
<p>18 0.29640341 <a title="189-lda-18" href="./nips-2006-Effects_of_Stress_and_Genotype_on_Meta-parameter_Dynamics_in_Reinforcement_Learning.html">71 nips-2006-Effects of Stress and Genotype on Meta-parameter Dynamics in Reinforcement Learning</a></p>
<p>19 0.29556361 <a title="189-lda-19" href="./nips-2006-Denoising_and_Dimension_Reduction_in_Feature_Space.html">65 nips-2006-Denoising and Dimension Reduction in Feature Space</a></p>
<p>20 0.29394874 <a title="189-lda-20" href="./nips-2006-Learning_Nonparametric_Models_for_Probabilistic_Imitation.html">112 nips-2006-Learning Nonparametric Models for Probabilistic Imitation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
