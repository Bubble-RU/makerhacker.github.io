<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>49 nips-2006-Causal inference in sensorimotor integration</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-49" href="#">nips2006-49</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>49 nips-2006-Causal inference in sensorimotor integration</h1>
<br/><p>Source: <a title="nips-2006-49-pdf" href="http://papers.nips.cc/paper/3141-causal-inference-in-sensorimotor-integration.pdf">pdf</a></p><p>Author: Konrad P. Körding, Joshua B. Tenenbaum</p><p>Abstract: Many recent studies analyze how data from different modalities can be combined. Often this is modeled as a system that optimally combines several sources of information about the same variable. However, it has long been realized that this information combining depends on the interpretation of the data. Two cues that are perceived by different modalities can have different causal relationships: (1) They can both have the same cause, in this case we should fully integrate both cues into a joint estimate. (2) They can have distinct causes, in which case information should be processed independently. In many cases we will not know if there is one joint cause or two independent causes that are responsible for the cues. Here we model this situation as a Bayesian estimation problem. We are thus able to explain some experiments on visual auditory cue combination as well as some experiments on visual proprioceptive cue integration. Our analysis shows that the problem solved by people when they combine cues to produce a movement is much more complicated than is usually assumed, because they need to infer the causal structure that is underlying their sensory experience.</p><p>Reference: <a title="nips-2006-49-reference" href="../nips2006_reference/nips-2006-Causal_inference_in_sensorimotor_integration_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Two cues that are perceived by different modalities can have different causal relationships: (1) They can both have the same cause, in this case we should fully integrate both cues into a joint estimate. [sent-8, score-0.681]
</p><p>2 In many cases we will not know if there is one joint cause or two independent causes that are responsible for the cues. [sent-10, score-0.29]
</p><p>3 We are thus able to explain some experiments on visual auditory cue combination as well as some experiments on visual proprioceptive cue integration. [sent-12, score-1.083]
</p><p>4 Our analysis shows that the problem solved by people when they combine cues to produce a movement is much more complicated than is usually assumed, because they need to infer the causal structure that is underlying their sensory experience. [sent-13, score-0.644]
</p><p>5 Traditionally, cue combination is formalized as a simple weighted combination of estimates coming from each modality (Fig 1A). [sent-17, score-0.435]
</p><p>6 Research often focuses on exploring in which coordinate system the problem is being solved [2, 3] and how much weight is given to each variable as a function of the uncertainty in each modality and the prior[4, 5, 6, 7, 8]. [sent-21, score-0.33]
</p><p>7 However, in many cases people can not be certain of the causal structure. [sent-25, score-0.367]
</p><p>8 If two cues share a common cause (as in Fig 1B) they should clearly be combined. [sent-26, score-0.317]
</p><p>9 In such cases people can not know which of the two models to use and have to estimate the causal structure of the problem along with the parameter values. [sent-28, score-0.442]
</p><p>10 C) In many cases people will be unable to know if one common cause or two independent causes are responsible for the cues. [sent-34, score-0.477]
</p><p>11 In that case people will have to estimate which causal structure is present from the properties of their sensory stimuli. [sent-35, score-0.455]
</p><p>12 2 Cue combination: one common cause A large number of recent studies have interpreted the results from cue combination studies in a Bayesian framework[13]. [sent-38, score-0.412]
</p><p>13 We discuss the case of visuoauditory integration as the statistical relations are identical in other cue combination cases. [sent-39, score-0.269]
</p><p>14 It is acknowledged that if a signal is coming from a speciﬁc position the signal received by the nervous system in each modality will be noisy. [sent-41, score-0.534]
</p><p>15 If the real position of a stimulus is xreal then the nervous system will not be able to directly know this variable but the visual modality will obtain a noisy estimate thereof x vis . [sent-42, score-1.247]
</p><p>16 Typically it is assumed that in the process that the visually perceived position is a noisy version of the real position x vis = xreal +noise. [sent-43, score-0.99]
</p><p>17 A statistical treatment thus results in p(xvis |xreal ) = N (xreal − xvis , σvis ) where σvis is the variance introduced by the visual modality and N (μ, σ) stands for a Gaussian distribution with mean μ and standard deviation σ. [sent-44, score-0.484]
</p><p>18 If two cues are available, for example vision and audition then it is assumed that both cues x vis and xaud provide noisy observations of the relevant variable x real . [sent-45, score-0.855]
</p><p>19 These papers assumed that we have two sources of information about one and the same variable and have shown that in psychophysical experiments people often show this kind of optimal integration and that the weights can be predicted from the variances [13, 14, 15, 4, 16]. [sent-50, score-0.336]
</p><p>20 3 Combination of visual and auditory cues: uncertainty about the causal structure Here we consider the range of experiments where people hear a tone and simultaneously see a visual stimulus that may or may not come from the same position. [sent-53, score-1.224]
</p><p>21 Subjects are asked to estimate which direction the tone is coming from and point to that direction – placing this experiment in the realm of sensorimotor integration. [sent-54, score-0.31]
</p><p>22 Subjects are asked to estimate which direction the tone is coming from and do so with a motor response. [sent-55, score-0.341]
</p><p>23 To optimally estimate where the tone is coming from people need to infer the causal structure (Fig 1 C) and decide if they should assume a single cause or two causes. [sent-56, score-0.717]
</p><p>24 For different distances between the visual and the auditory stimulus they analyzed the strategies people use to estimate the position of the auditory stimuli (see ﬁgure 2). [sent-59, score-1.139]
</p><p>25 It has long been realized that integration of different cues should only occur if the cues have the same cause [9, 10, 8, 19]. [sent-60, score-0.573]
</p><p>26 2 Inference The probability that the two signals are from the same source will only weakly depend on the spatial prior but mostly depend on the distance Δ av = xaud − xvis between visually and auditory perceived positions. [sent-67, score-0.812]
</p><p>27 We thus obtain: p(same|Δav ) psame p(Δav |same) = p(different|Δav ) (1 − psame )p(Δav |different)  (5)  Using p(same|Δav ) + p(different|Δav ) = 1 we can readily calculate the probability p(same|Δ av ) of the two signals coming from the same source. [sent-68, score-0.373]
</p><p>28 Using Equation 4 we can then calculate the optimal solution which is: x = p(same|Δav )ˆsame + (1 − p(same|Δav ))ˆdifferent ˆ x x  (6)  We know the optimal estimates in the same case already from equation 3 and in the different case the optimal estimate exclusively relies on the auditory signal. [sent-69, score-0.322]
</p><p>29 We furthermore assume that the position sensed by the sensory system is a noisy version of x observed = x + where is drawn from a ˆ Gaussian with zero mean and a standard deviation of σ motor . [sent-70, score-0.443]
</p><p>30 In both auditory and visual trials the noise will have two sources, motor noise and sensory noise. [sent-78, score-0.638]
</p><p>31 Even if people knew perfectly where a stimulus was coming from they would make small errors at pointing because their motor system is not perfect. [sent-79, score-0.467]
</p><p>32 We assume that visual only trials are dominated by motor noise, stemming from motor errors and memory errors and that the noise in the visual trials is essentially exclusively motor noise (σ vis = 0. [sent-80, score-1.105]
</p><p>33 5 deg and because variances are added linearly σ aud = 82 − 2. [sent-84, score-0.26]
</p><p>34 A Bayes  B  Visual stimulus  Gain α [%]  Bayes unoptimized  Auditory stimulus Gain>0  MAP  C  Gain<0 mean  Combination Experiment Wallace et al  Estimated one cause Estimated two causes  One cause -5  Two causes 0 Position [deg]  -5  Figure 2: Uncertainty if one or two causes are relevant. [sent-87, score-0.672]
</p><p>35 A) The gain, the relative weight of vision for the estimation of the position of the auditory signal is shown. [sent-89, score-0.472]
</p><p>36 It is plotted as a function of the spatial disparity, the distance between visual and auditory stimulus. [sent-90, score-0.44]
</p><p>37 A gain value of α = 100% implies that subjects only use visual information. [sent-91, score-0.377]
</p><p>38 A negative α means that on average subjects point away from the visual stimulus. [sent-92, score-0.306]
</p><p>39 The visual stimulus is always at -5 deg (solid line) and the auditory stimulus is always straight ahead at 0deg(dotted line). [sent-95, score-0.596]
</p><p>40 Visual perception is very low noise and the perceived position x vis is shown as red dots (each dot is one trial). [sent-96, score-0.578]
</p><p>41 Auditory perception is noisy and the perceived auditory position x aud is shown as black dots. [sent-97, score-0.78]
</p><p>42 In the white area where the subject perceive two causes, the average position of perceived auditory signals is further to the right. [sent-98, score-0.602]
</p><p>43 From the speciﬁcations of the experiments we know that the distribution of auditory sources has a width of 20deg relative to the ﬁxation point and we assume that this width is known to the subjects from repeated trials. [sent-105, score-0.506]
</p><p>44 The model predicts the counterintuitive ﬁnding that the trials where people inferred two causes exhibit negative gain. [sent-111, score-0.316]
</p><p>45 On some trials noise in the auditory signal will make it appear as if the auditory signal is very close to the visual signal. [sent-118, score-0.8]
</p><p>46 In this case the system will infer that both have the same source and part of the reported high gain for the fused cases will be because noise already perturbed the auditory signal towards the visual. [sent-119, score-0.424]
</p><p>47 However, on some trials the auditory signal will be randomly perturbed away from the visual signal. [sent-120, score-0.517]
</p><p>48 5 Maximum A Posteriori over causal structure In the derivations above we assumed that people are fully Bayesian, in the sense that they consider both possible structures for cue-integration and integrate over them to arrive at an optimal decision. [sent-125, score-0.367]
</p><p>49 This difference is observed because the MAP model strongly underestimates the uncertainty in the single cause case and strongly overestimates the uncertainty in the dual cause case (Fig 2C). [sent-131, score-0.432]
</p><p>50 The Bayesian model on the other hand always considers that it could be wrong, leading to more variance in the single cause case and less in the dual cause case. [sent-132, score-0.359]
</p><p>51 This effect goes away if we assume that people underestimate the variance of the auditory source relative to the ﬁxation spot (data not shown). [sent-134, score-0.434]
</p><p>52 In summary, the problem of crossmodal integration is much more complicated than it seems as it necessitates inference of the causal structure. [sent-137, score-0.294]
</p><p>53 4 Combination of visual and proprioceptive cues Typical experiments in movement psychophysics where a virtual reality display is used to disturb the perceived position of the hand lead to an analogous problem. [sent-139, score-0.897]
</p><p>54 In these experiments subjects proprioceptively feel their hand somewhere, but they cannot see their hand; at the same time, they visually perceive a cursor somewhere. [sent-140, score-0.714]
</p><p>55 Subjects again can not be sure if the seen cursor position and the felt hand position are cues about the same variable (hand=cursor) or if each of them are independent and the experiment is just cheating them leading to the same causal structure inference problem described above. [sent-141, score-1.25]
</p><p>56 In these experiments one hand is moving a cursor to either the position of a visually displayed (v) target or the position of the other hand (p). [sent-144, score-0.979]
</p><p>57 People need to estimate two distinct variables: (1) the direction in which they are to move their arm, a visually perceived variable, the so-called movement vector (MV) and (2) a proprioceptively perceived variable, the conﬁguration of their joints (J). [sent-145, score-0.453]
</p><p>58 Subjects obtain visual information about the position of the cursor and they obtain proprioceptive information from feeling the position of their hand. [sent-146, score-1.062]
</p><p>59 Traditionally it would have been assumed that the seen cursor position and the proprioceptively felt hand position are cues caused by one single variable, the hand. [sent-147, score-1.062]
</p><p>60 As a result, the position of the cursor uniquely deﬁnes the conﬁguration of the joints and vice versa. [sent-148, score-0.56]
</p><p>61 As in the cue combination case above there should not be full cue combination but instead each variable (MV) and (J) should be estimated separately. [sent-149, score-0.398]
</p><p>62 In this experiment a situation is produced where the visual position of a cursor is different from the actual position of the right hand. [sent-150, score-0.915]
</p><p>63 The experimental studies then report the gain α, the linear weight α of vision on the estimate of (MV) and (J) in both the visual and the proprioceptive target conditions(ﬁgure 3A and B). [sent-154, score-0.564]
</p><p>64 If people only inferred about one common cause then the weight of vision should always be the same, indicating that more than just one cause is assumed by the subjects. [sent-155, score-0.506]
</p><p>65 In the sensorimotor integration case there is uncertainty about the alignment of the two coordinate systems. [sent-158, score-0.342]
</p><p>66 When using information from one coordinate system for an estimation in a different coordinate system there is uncertainty about the alignment of the coordinate systems. [sent-160, score-0.392]
</p><p>67 This means that when we use visual information to estimate the position of a joint in joint space our visual system appears to be more noisy and vice versa. [sent-161, score-0.666]
</p><p>68 As we are only interested in estimates along one dimension and can model the uncertainty about the alignment of the coordinate systems as a one dimensional Gaussian with width σ trans . [sent-162, score-0.328]
</p><p>69 When using information from one modality for estimations of a variable in the other coordinate system we need 2 2 2 to use σef f ective = σmodality + σtrans . [sent-163, score-0.26]
</p><p>70 The two target conditions in the experiments, moving the cursor to a visual target (v) and moving the cursor to the position of the other hand (p) produce two different estimation problems. [sent-164, score-1.362]
</p><p>71 When we try to move a cursor to a visually displayed target we must compute MV in visual space. [sent-165, score-0.71]
</p><p>72 If to the contrary we try to move a cursor with one hand to the position of the other hand then we must calculate MV in joint space. [sent-166, score-0.722]
</p><p>73 Altogether people are faced with 4 problems, they have to estimate (MV) and (J) in both the visual (v) condition and the proprioceptive (p) condition. [sent-168, score-0.572]
</p><p>74 2 Probabilistic model As above we assume that visual and proprioceptive uncertainty lead to probability distributions in the respective space that are characterized by Gaussians of width σ vis and σprop . [sent-170, score-0.746]
</p><p>75 Under these circumstances it is only important how likely on average people ﬁnd that the two percepts are uniﬁed (p unif ied = psame p(Δpv |same)). [sent-173, score-0.357]
</p><p>76 We assume that when moving the cursor to a visual target the average squared deviation of the cursor and the target in visual space is minimized. [sent-174, score-1.345]
</p><p>77 We assume that when moving the cursor to a proprioceptive target the average squared deviation of the cursor and the target in proprioceptive space is minimized. [sent-175, score-1.253]
</p><p>78 Apart from this difference the whole derivation of the equations is identical to the one above for the auditory visual integration. [sent-176, score-0.44]
</p><p>79 3 Tool use Above we assumed that cursor and hand either have the same cause (the position of the hand, or different causes and are therefore unrelated. [sent-179, score-0.861]
</p><p>80 The cursor could be seen as a tool that is seen displaced relative to our hand. [sent-181, score-0.52]
</p><p>81 As tools are typically short the probability is largest that the tip of a tool is at the position of the hand and this probability will decay with increasing distance between the hand and the position of the tool. [sent-183, score-0.62]
</p><p>82 The distance between the tip of the tool and the hand is thus another random variable that is assumed to be Gaussian with width σtool (see ﬁg. [sent-184, score-0.3]
</p><p>83 The cursor will be close to the position of the hand. [sent-194, score-0.56]
</p><p>84 model has several parameters, important the uncertainties of proprioception and of the coordinate transformation compared to the visual uncertainty. [sent-197, score-0.32]
</p><p>85 He estimated σ vis = 1cm,σprop = 3cm,σtrans = 5cm. [sent-206, score-0.295]
</p><p>86 The image of an arm is rendered on top of the cursor position. [sent-210, score-0.452]
</p><p>87 In our interpretation, the rendering of the arm makes the probability much higher that actually the position of the visual display is the position of the hand and p unif ied would be much higher. [sent-212, score-0.74]
</p><p>88 5 Analysis if subjects view a cursor as a tool Another possible model that seemed very likely to us was assuming that the cursor should appear somewhere close to the hand modeling the cursor hand relationship as another Gaussian variable (Fig 3E). [sent-214, score-1.62]
</p><p>89 We ﬁt the 3 parameters of this model, the uncertainty of proprioception and the coordinate transformation relative to the visual uncertainty as well as the width of the Gaussian describing the tool. [sent-215, score-0.474]
</p><p>90 Sober and Sabes [5, 6] explain the ﬁnding that two variables are estimated by the ﬁnding that cortex exhibits two important streams of information processing, one for visual processing and the other for motor tasks [20]. [sent-222, score-0.307]
</p><p>91 If people see a cursor close to their hand they do not assume that they actually see their hand. [sent-224, score-0.652]
</p><p>92 The models that we introduced can be understood as special instantiations of a model where the cursor position relative to the hand is drawn from a general probability distribution. [sent-225, score-0.627]
</p><p>93 5 Discussion An impressive range of recent studies show that people do not just estimate one variable in situations of cue combination [5, 6, 17, 18]. [sent-226, score-0.487]
</p><p>94 Here we have shown that the statistical problem that people solve in such situations involves an inference about the causal structure. [sent-227, score-0.396]
</p><p>95 The problem faced by the nervous system is similar to cognitive problems that occur in the context of causal induction. [sent-229, score-0.294]
</p><p>96 Many experiments show that people and in particular infants interpret events in terms of cause and effect [11, 21, 22]. [sent-230, score-0.333]
</p><p>97 Demonstration of cue recruitment: change in visual appearance by means of pavlovian conditioning. [sent-241, score-0.312]
</p><p>98 A theory of causal learning in children: causal maps and bayes nets. [sent-312, score-0.36]
</p><p>99 Optimal integration of texture and motion cues to depth. [sent-329, score-0.256]
</p><p>100 Integration of proprioceptive and visual position-information: An experimentally supported model. [sent-338, score-0.34]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('cursor', 0.398), ('vis', 0.295), ('auditory', 0.247), ('aud', 0.22), ('visual', 0.193), ('people', 0.187), ('causal', 0.18), ('cues', 0.171), ('xreal', 0.169), ('position', 0.162), ('prop', 0.162), ('proprioceptive', 0.147), ('cause', 0.146), ('av', 0.134), ('tool', 0.122), ('perceived', 0.121), ('modality', 0.121), ('cue', 0.119), ('xvis', 0.119), ('motor', 0.114), ('subjects', 0.113), ('trans', 0.113), ('xaud', 0.102), ('mv', 0.094), ('causes', 0.088), ('sober', 0.088), ('integration', 0.085), ('sensorimotor', 0.083), ('nervous', 0.071), ('gain', 0.071), ('uncertainty', 0.07), ('psame', 0.068), ('sabes', 0.068), ('tone', 0.067), ('hand', 0.067), ('coordinate', 0.066), ('combination', 0.065), ('coming', 0.065), ('explains', 0.062), ('neurosci', 0.059), ('stimulus', 0.058), ('fig', 0.056), ('arm', 0.054), ('deviation', 0.051), ('visually', 0.051), ('felt', 0.051), ('hairston', 0.051), ('ied', 0.051), ('print', 0.051), ('proprioceptively', 0.051), ('unif', 0.051), ('wallace', 0.051), ('asked', 0.05), ('estimate', 0.045), ('psychol', 0.044), ('system', 0.043), ('sensory', 0.043), ('width', 0.041), ('studies', 0.041), ('trials', 0.041), ('target', 0.04), ('deg', 0.04), ('tip', 0.04), ('weighing', 0.04), ('signals', 0.038), ('alignment', 0.038), ('modalities', 0.038), ('movement', 0.036), ('signal', 0.036), ('sources', 0.034), ('multisensory', 0.034), ('perceive', 0.034), ('proprioception', 0.034), ('shams', 0.034), ('xestimated', 0.034), ('xtrue', 0.034), ('bayesian', 0.033), ('moving', 0.032), ('res', 0.031), ('noisy', 0.03), ('know', 0.03), ('variable', 0.03), ('audition', 0.029), ('hear', 0.029), ('stein', 0.029), ('wolpert', 0.029), ('inference', 0.029), ('move', 0.028), ('deviations', 0.027), ('uncertainties', 0.027), ('sci', 0.027), ('everyday', 0.027), ('konrad', 0.027), ('somewhere', 0.027), ('vaughan', 0.027), ('vision', 0.027), ('infer', 0.027), ('uni', 0.027), ('predictions', 0.026), ('responsible', 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999958 <a title="49-tfidf-1" href="./nips-2006-Causal_inference_in_sensorimotor_integration.html">49 nips-2006-Causal inference in sensorimotor integration</a></p>
<p>Author: Konrad P. Körding, Joshua B. Tenenbaum</p><p>Abstract: Many recent studies analyze how data from different modalities can be combined. Often this is modeled as a system that optimally combines several sources of information about the same variable. However, it has long been realized that this information combining depends on the interpretation of the data. Two cues that are perceived by different modalities can have different causal relationships: (1) They can both have the same cause, in this case we should fully integrate both cues into a joint estimate. (2) They can have distinct causes, in which case information should be processed independently. In many cases we will not know if there is one joint cause or two independent causes that are responsible for the cues. Here we model this situation as a Bayesian estimation problem. We are thus able to explain some experiments on visual auditory cue combination as well as some experiments on visual proprioceptive cue integration. Our analysis shows that the problem solved by people when they combine cues to produce a movement is much more complicated than is usually assumed, because they need to infer the causal structure that is underlying their sensory experience.</p><p>2 0.14943753 <a title="49-tfidf-2" href="./nips-2006-Nonlinear_physically-based_models_for_decoding_motor-cortical_population_activity.html">148 nips-2006-Nonlinear physically-based models for decoding motor-cortical population activity</a></p>
<p>Author: Gregory Shakhnarovich, Sung-phil Kim, Michael J. Black</p><p>Abstract: Neural motor prostheses (NMPs) require the accurate decoding of motor cortical population activity for the control of an artiﬁcial motor system. Previous work on cortical decoding for NMPs has focused on the recovery of hand kinematics. Human NMPs however may require the control of computer cursors or robotic devices with very different physical and dynamical properties. Here we show that the ﬁring rates of cells in the primary motor cortex of non-human primates can be used to control the parameters of an artiﬁcial physical system exhibiting realistic dynamics. The model represents 2D hand motion in terms of a point mass connected to a system of idealized springs. The nonlinear spring coefﬁcients are estimated from the ﬁring rates of neurons in the motor cortex. We evaluate linear and a nonlinear decoding algorithms using neural recordings from two monkeys performing two different tasks. We found that the decoded spring coefﬁcients produced accurate hand trajectories compared with state-of-the-art methods for direct decoding of hand kinematics. Furthermore, using a physically-based system produced decoded movements that were more “natural” in that their frequency spectrum more closely matched that of natural hand movements. 1</p><p>3 0.13319403 <a title="49-tfidf-3" href="./nips-2006-Combining_causal_and_similarity-based_reasoning.html">53 nips-2006-Combining causal and similarity-based reasoning</a></p>
<p>Author: Charles Kemp, Patrick Shafto, Allison Berke, Joshua B. Tenenbaum</p><p>Abstract: Everyday inductive reasoning draws on many kinds of knowledge, including knowledge about relationships between properties and knowledge about relationships between objects. Previous accounts of inductive reasoning generally focus on just one kind of knowledge: models of causal reasoning often focus on relationships between properties, and models of similarity-based reasoning often focus on similarity relationships between objects. We present a Bayesian model of inductive reasoning that incorporates both kinds of knowledge, and show that it accounts well for human inferences about the properties of biological species. 1</p><p>4 0.098750532 <a title="49-tfidf-4" href="./nips-2006-Multiple_timescales_and_uncertainty_in_motor_adaptation.html">141 nips-2006-Multiple timescales and uncertainty in motor adaptation</a></p>
<p>Author: Konrad P. Körding, Joshua B. Tenenbaum, Reza Shadmehr</p><p>Abstract: Our motor system changes due to causes that span multiple timescales. For example, muscle response can change because of fatigue, a condition where the disturbance has a fast timescale or because of disease where the disturbance is much slower. Here we hypothesize that the nervous system adapts in a way that reﬂects the temporal properties of such potential disturbances. According to a Bayesian formulation of this idea, movement error results in a credit assignment problem: what timescale is responsible for this disturbance? The adaptation schedule inﬂuences the behavior of the optimal learner, changing estimates at different timescales as well as the uncertainty. A system that adapts in this way predicts many properties observed in saccadic gain adaptation. It well predicts the timecourses of motor adaptation in cases of partial sensory deprivation and reversals of the adaptation direction.</p><p>5 0.080343276 <a title="49-tfidf-5" href="./nips-2006-Adaptive_Spatial_Filters_with_predefined_Region_of_Interest_for_EEG_based_Brain-Computer-Interfaces.html">22 nips-2006-Adaptive Spatial Filters with predefined Region of Interest for EEG based Brain-Computer-Interfaces</a></p>
<p>Author: Moritz Grosse-wentrup, Klaus Gramann, Martin Buss</p><p>Abstract: The performance of EEG-based Brain-Computer-Interfaces (BCIs) critically depends on the extraction of features from the EEG carrying information relevant for the classiﬁcation of different mental states. For BCIs employing imaginary movements of different limbs, the method of Common Spatial Patterns (CSP) has been shown to achieve excellent classiﬁcation results. The CSP-algorithm however suffers from a lack of robustness, requiring training data without artifacts for good performance. To overcome this lack of robustness, we propose an adaptive spatial ﬁlter that replaces the training data in the CSP approach by a-priori information. More speciﬁcally, we design an adaptive spatial ﬁlter that maximizes the ratio of the variance of the electric ﬁeld originating in a predeﬁned region of interest (ROI) and the overall variance of the measured EEG. Since it is known that the component of the EEG used for discriminating imaginary movements originates in the motor cortex, we design two adaptive spatial ﬁlters with the ROIs centered in the hand areas of the left and right motor cortex. We then use these to classify EEG data recorded during imaginary movements of the right and left hand of three subjects, and show that the adaptive spatial ﬁlters outperform the CSP-algorithm, enabling classiﬁcation rates of up to 94.7 % without artifact rejection. 1</p><p>6 0.080304556 <a title="49-tfidf-6" href="./nips-2006-Learning_Structural_Equation_Models_for_fMRI.html">113 nips-2006-Learning Structural Equation Models for fMRI</a></p>
<p>7 0.067763358 <a title="49-tfidf-7" href="./nips-2006-A_Nonparametric_Approach_to_Bottom-Up_Visual_Saliency.html">8 nips-2006-A Nonparametric Approach to Bottom-Up Visual Saliency</a></p>
<p>8 0.062959462 <a title="49-tfidf-8" href="./nips-2006-A_Probabilistic_Algorithm_Integrating_Source_Localization_and_Noise_Suppression_of_MEG_and_EEG_data.html">12 nips-2006-A Probabilistic Algorithm Integrating Source Localization and Noise Suppression of MEG and EEG data</a></p>
<p>9 0.061664637 <a title="49-tfidf-9" href="./nips-2006-An_EM_Algorithm_for_Localizing_Multiple_Sound_Sources_in_Reverberant_Environments.html">27 nips-2006-An EM Algorithm for Localizing Multiple Sound Sources in Reverberant Environments</a></p>
<p>10 0.058666792 <a title="49-tfidf-10" href="./nips-2006-Fast_Discriminative_Visual_Codebooks_using_Randomized_Clustering_Forests.html">78 nips-2006-Fast Discriminative Visual Codebooks using Randomized Clustering Forests</a></p>
<p>11 0.057956144 <a title="49-tfidf-11" href="./nips-2006-Learning_to_parse_images_of_articulated_bodies.html">122 nips-2006-Learning to parse images of articulated bodies</a></p>
<p>12 0.057516839 <a title="49-tfidf-12" href="./nips-2006-Blind_source_separation_for_over-determined_delayed_mixtures.html">46 nips-2006-Blind source separation for over-determined delayed mixtures</a></p>
<p>13 0.056024328 <a title="49-tfidf-13" href="./nips-2006-Aggregating_Classification_Accuracy_across_Time%3A_Application_to_Single_Trial_EEG.html">24 nips-2006-Aggregating Classification Accuracy across Time: Application to Single Trial EEG</a></p>
<p>14 0.050406259 <a title="49-tfidf-14" href="./nips-2006-Recursive_ICA.html">167 nips-2006-Recursive ICA</a></p>
<p>15 0.050179686 <a title="49-tfidf-15" href="./nips-2006-A_Bayesian_Approach_to_Diffusion_Models_of_Decision-Making_and_Response_Time.html">1 nips-2006-A Bayesian Approach to Diffusion Models of Decision-Making and Response Time</a></p>
<p>16 0.045618787 <a title="49-tfidf-16" href="./nips-2006-Theory_and_Dynamics_of_Perceptual_Bistability.html">192 nips-2006-Theory and Dynamics of Perceptual Bistability</a></p>
<p>17 0.045534082 <a title="49-tfidf-17" href="./nips-2006-Graph-Based_Visual_Saliency.html">86 nips-2006-Graph-Based Visual Saliency</a></p>
<p>18 0.044670135 <a title="49-tfidf-18" href="./nips-2006-Inducing_Metric_Violations_in_Human_Similarity_Judgements.html">97 nips-2006-Inducing Metric Violations in Human Similarity Judgements</a></p>
<p>19 0.044573441 <a title="49-tfidf-19" href="./nips-2006-Optimal_Change-Detection_and_Spiking_Neurons.html">154 nips-2006-Optimal Change-Detection and Spiking Neurons</a></p>
<p>20 0.043140627 <a title="49-tfidf-20" href="./nips-2006-Context_Effects_in_Category_Learning%3A_An_Investigation_of_Four_Probabilistic_Models.html">58 nips-2006-Context Effects in Category Learning: An Investigation of Four Probabilistic Models</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2006_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.14), (1, -0.059), (2, 0.082), (3, -0.096), (4, -0.11), (5, -0.097), (6, 0.044), (7, 0.012), (8, -0.018), (9, -0.05), (10, 0.031), (11, 0.027), (12, -0.047), (13, -0.014), (14, -0.068), (15, -0.114), (16, 0.049), (17, -0.058), (18, -0.117), (19, -0.008), (20, 0.002), (21, 0.053), (22, -0.057), (23, 0.0), (24, 0.036), (25, 0.047), (26, -0.059), (27, -0.082), (28, -0.052), (29, -0.016), (30, -0.071), (31, -0.124), (32, 0.2), (33, -0.136), (34, -0.207), (35, 0.003), (36, -0.115), (37, -0.166), (38, 0.015), (39, -0.108), (40, -0.075), (41, -0.209), (42, -0.016), (43, 0.024), (44, 0.039), (45, 0.088), (46, -0.072), (47, -0.068), (48, -0.04), (49, -0.084)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96080637 <a title="49-lsi-1" href="./nips-2006-Causal_inference_in_sensorimotor_integration.html">49 nips-2006-Causal inference in sensorimotor integration</a></p>
<p>Author: Konrad P. Körding, Joshua B. Tenenbaum</p><p>Abstract: Many recent studies analyze how data from different modalities can be combined. Often this is modeled as a system that optimally combines several sources of information about the same variable. However, it has long been realized that this information combining depends on the interpretation of the data. Two cues that are perceived by different modalities can have different causal relationships: (1) They can both have the same cause, in this case we should fully integrate both cues into a joint estimate. (2) They can have distinct causes, in which case information should be processed independently. In many cases we will not know if there is one joint cause or two independent causes that are responsible for the cues. Here we model this situation as a Bayesian estimation problem. We are thus able to explain some experiments on visual auditory cue combination as well as some experiments on visual proprioceptive cue integration. Our analysis shows that the problem solved by people when they combine cues to produce a movement is much more complicated than is usually assumed, because they need to infer the causal structure that is underlying their sensory experience.</p><p>2 0.75998813 <a title="49-lsi-2" href="./nips-2006-Multiple_timescales_and_uncertainty_in_motor_adaptation.html">141 nips-2006-Multiple timescales and uncertainty in motor adaptation</a></p>
<p>Author: Konrad P. Körding, Joshua B. Tenenbaum, Reza Shadmehr</p><p>Abstract: Our motor system changes due to causes that span multiple timescales. For example, muscle response can change because of fatigue, a condition where the disturbance has a fast timescale or because of disease where the disturbance is much slower. Here we hypothesize that the nervous system adapts in a way that reﬂects the temporal properties of such potential disturbances. According to a Bayesian formulation of this idea, movement error results in a credit assignment problem: what timescale is responsible for this disturbance? The adaptation schedule inﬂuences the behavior of the optimal learner, changing estimates at different timescales as well as the uncertainty. A system that adapts in this way predicts many properties observed in saccadic gain adaptation. It well predicts the timecourses of motor adaptation in cases of partial sensory deprivation and reversals of the adaptation direction.</p><p>3 0.74151713 <a title="49-lsi-3" href="./nips-2006-Nonlinear_physically-based_models_for_decoding_motor-cortical_population_activity.html">148 nips-2006-Nonlinear physically-based models for decoding motor-cortical population activity</a></p>
<p>Author: Gregory Shakhnarovich, Sung-phil Kim, Michael J. Black</p><p>Abstract: Neural motor prostheses (NMPs) require the accurate decoding of motor cortical population activity for the control of an artiﬁcial motor system. Previous work on cortical decoding for NMPs has focused on the recovery of hand kinematics. Human NMPs however may require the control of computer cursors or robotic devices with very different physical and dynamical properties. Here we show that the ﬁring rates of cells in the primary motor cortex of non-human primates can be used to control the parameters of an artiﬁcial physical system exhibiting realistic dynamics. The model represents 2D hand motion in terms of a point mass connected to a system of idealized springs. The nonlinear spring coefﬁcients are estimated from the ﬁring rates of neurons in the motor cortex. We evaluate linear and a nonlinear decoding algorithms using neural recordings from two monkeys performing two different tasks. We found that the decoded spring coefﬁcients produced accurate hand trajectories compared with state-of-the-art methods for direct decoding of hand kinematics. Furthermore, using a physically-based system produced decoded movements that were more “natural” in that their frequency spectrum more closely matched that of natural hand movements. 1</p><p>4 0.59208256 <a title="49-lsi-4" href="./nips-2006-Combining_causal_and_similarity-based_reasoning.html">53 nips-2006-Combining causal and similarity-based reasoning</a></p>
<p>Author: Charles Kemp, Patrick Shafto, Allison Berke, Joshua B. Tenenbaum</p><p>Abstract: Everyday inductive reasoning draws on many kinds of knowledge, including knowledge about relationships between properties and knowledge about relationships between objects. Previous accounts of inductive reasoning generally focus on just one kind of knowledge: models of causal reasoning often focus on relationships between properties, and models of similarity-based reasoning often focus on similarity relationships between objects. We present a Bayesian model of inductive reasoning that incorporates both kinds of knowledge, and show that it accounts well for human inferences about the properties of biological species. 1</p><p>5 0.41088811 <a title="49-lsi-5" href="./nips-2006-Adaptive_Spatial_Filters_with_predefined_Region_of_Interest_for_EEG_based_Brain-Computer-Interfaces.html">22 nips-2006-Adaptive Spatial Filters with predefined Region of Interest for EEG based Brain-Computer-Interfaces</a></p>
<p>Author: Moritz Grosse-wentrup, Klaus Gramann, Martin Buss</p><p>Abstract: The performance of EEG-based Brain-Computer-Interfaces (BCIs) critically depends on the extraction of features from the EEG carrying information relevant for the classiﬁcation of different mental states. For BCIs employing imaginary movements of different limbs, the method of Common Spatial Patterns (CSP) has been shown to achieve excellent classiﬁcation results. The CSP-algorithm however suffers from a lack of robustness, requiring training data without artifacts for good performance. To overcome this lack of robustness, we propose an adaptive spatial ﬁlter that replaces the training data in the CSP approach by a-priori information. More speciﬁcally, we design an adaptive spatial ﬁlter that maximizes the ratio of the variance of the electric ﬁeld originating in a predeﬁned region of interest (ROI) and the overall variance of the measured EEG. Since it is known that the component of the EEG used for discriminating imaginary movements originates in the motor cortex, we design two adaptive spatial ﬁlters with the ROIs centered in the hand areas of the left and right motor cortex. We then use these to classify EEG data recorded during imaginary movements of the right and left hand of three subjects, and show that the adaptive spatial ﬁlters outperform the CSP-algorithm, enabling classiﬁcation rates of up to 94.7 % without artifact rejection. 1</p><p>6 0.36219251 <a title="49-lsi-6" href="./nips-2006-Aggregating_Classification_Accuracy_across_Time%3A_Application_to_Single_Trial_EEG.html">24 nips-2006-Aggregating Classification Accuracy across Time: Application to Single Trial EEG</a></p>
<p>7 0.36035445 <a title="49-lsi-7" href="./nips-2006-Large_Margin_Multi-channel_Analog-to-Digital_Conversion_with_Applications_to_Neural_Prosthesis.html">107 nips-2006-Large Margin Multi-channel Analog-to-Digital Conversion with Applications to Neural Prosthesis</a></p>
<p>8 0.35812193 <a title="49-lsi-8" href="./nips-2006-Temporal_dynamics_of_information_content_carried_by_neurons_in_the_primary_visual_cortex.html">189 nips-2006-Temporal dynamics of information content carried by neurons in the primary visual cortex</a></p>
<p>9 0.33636329 <a title="49-lsi-9" href="./nips-2006-Learning_Structural_Equation_Models_for_fMRI.html">113 nips-2006-Learning Structural Equation Models for fMRI</a></p>
<p>10 0.2999042 <a title="49-lsi-10" href="./nips-2006-Similarity_by_Composition.html">174 nips-2006-Similarity by Composition</a></p>
<p>11 0.29692405 <a title="49-lsi-11" href="./nips-2006-Theory_and_Dynamics_of_Perceptual_Bistability.html">192 nips-2006-Theory and Dynamics of Perceptual Bistability</a></p>
<p>12 0.2937313 <a title="49-lsi-12" href="./nips-2006-Robotic_Grasping_of_Novel_Objects.html">170 nips-2006-Robotic Grasping of Novel Objects</a></p>
<p>13 0.29351148 <a title="49-lsi-13" href="./nips-2006-Context_Effects_in_Category_Learning%3A_An_Investigation_of_Four_Probabilistic_Models.html">58 nips-2006-Context Effects in Category Learning: An Investigation of Four Probabilistic Models</a></p>
<p>14 0.28030428 <a title="49-lsi-14" href="./nips-2006-An_EM_Algorithm_for_Localizing_Multiple_Sound_Sources_in_Reverberant_Environments.html">27 nips-2006-An EM Algorithm for Localizing Multiple Sound Sources in Reverberant Environments</a></p>
<p>15 0.27294153 <a title="49-lsi-15" href="./nips-2006-Learning_Nonparametric_Models_for_Probabilistic_Imitation.html">112 nips-2006-Learning Nonparametric Models for Probabilistic Imitation</a></p>
<p>16 0.26945144 <a title="49-lsi-16" href="./nips-2006-Effects_of_Stress_and_Genotype_on_Meta-parameter_Dynamics_in_Reinforcement_Learning.html">71 nips-2006-Effects of Stress and Genotype on Meta-parameter Dynamics in Reinforcement Learning</a></p>
<p>17 0.26613551 <a title="49-lsi-17" href="./nips-2006-Speakers_optimize_information_density_through_syntactic_reduction.html">180 nips-2006-Speakers optimize information density through syntactic reduction</a></p>
<p>18 0.26089978 <a title="49-lsi-18" href="./nips-2006-A_Bayesian_Approach_to_Diffusion_Models_of_Decision-Making_and_Response_Time.html">1 nips-2006-A Bayesian Approach to Diffusion Models of Decision-Making and Response Time</a></p>
<p>19 0.26069704 <a title="49-lsi-19" href="./nips-2006-A_Theory_of_Retinal_Population_Coding.html">16 nips-2006-A Theory of Retinal Population Coding</a></p>
<p>20 0.25656885 <a title="49-lsi-20" href="./nips-2006-Blind_source_separation_for_over-determined_delayed_mixtures.html">46 nips-2006-Blind source separation for over-determined delayed mixtures</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2006_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(1, 0.087), (3, 0.021), (7, 0.041), (9, 0.047), (20, 0.039), (22, 0.035), (34, 0.011), (44, 0.061), (47, 0.023), (57, 0.051), (65, 0.049), (69, 0.021), (71, 0.035), (90, 0.017), (99, 0.381)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.86278749 <a title="49-lda-1" href="./nips-2006-Handling_Advertisements_of_Unknown_Quality_in_Search_Advertising.html">89 nips-2006-Handling Advertisements of Unknown Quality in Search Advertising</a></p>
<p>Author: Sandeep Pandey, Christopher Olston</p><p>Abstract: We consider how a search engine should select advertisements to display with search results, in order to maximize its revenue. Under the standard “pay-per-click” arrangement, revenue depends on how well the displayed advertisements appeal to users. The main diﬃculty stems from new advertisements whose degree of appeal has yet to be determined. Often the only reliable way of determining appeal is exploration via display to users, which detracts from exploitation of other advertisements known to have high appeal. Budget constraints and ﬁnite advertisement lifetimes make it necessary to explore as well as exploit. In this paper we study the tradeoﬀ between exploration and exploitation, modeling advertisement placement as a multi-armed bandit problem. We extend traditional bandit formulations to account for budget constraints that occur in search engine advertising markets, and derive theoretical bounds on the performance of a family of algorithms. We measure empirical performance via extensive experiments over real-world data. 1</p><p>same-paper 2 0.74279404 <a title="49-lda-2" href="./nips-2006-Causal_inference_in_sensorimotor_integration.html">49 nips-2006-Causal inference in sensorimotor integration</a></p>
<p>Author: Konrad P. Körding, Joshua B. Tenenbaum</p><p>Abstract: Many recent studies analyze how data from different modalities can be combined. Often this is modeled as a system that optimally combines several sources of information about the same variable. However, it has long been realized that this information combining depends on the interpretation of the data. Two cues that are perceived by different modalities can have different causal relationships: (1) They can both have the same cause, in this case we should fully integrate both cues into a joint estimate. (2) They can have distinct causes, in which case information should be processed independently. In many cases we will not know if there is one joint cause or two independent causes that are responsible for the cues. Here we model this situation as a Bayesian estimation problem. We are thus able to explain some experiments on visual auditory cue combination as well as some experiments on visual proprioceptive cue integration. Our analysis shows that the problem solved by people when they combine cues to produce a movement is much more complicated than is usually assumed, because they need to infer the causal structure that is underlying their sensory experience.</p><p>3 0.6218549 <a title="49-lda-3" href="./nips-2006-Multiple_Instance_Learning_for_Computer_Aided_Diagnosis.html">140 nips-2006-Multiple Instance Learning for Computer Aided Diagnosis</a></p>
<p>Author: Murat Dundar, Balaji Krishnapuram, R. B. Rao, Glenn M. Fung</p><p>Abstract: Many computer aided diagnosis (CAD) problems can be best modelled as a multiple-instance learning (MIL) problem with unbalanced data: i.e. , the training data typically consists of a few positive bags, and a very large number of negative instances. Existing MIL algorithms are much too computationally expensive for these datasets. We describe CH, a framework for learning a Convex Hull representation of multiple instances that is signiﬁcantly faster than existing MIL algorithms. Our CH framework applies to any standard hyperplane-based learning algorithm, and for some algorithms, is guaranteed to ﬁnd the global optimal solution. Experimental studies on two different CAD applications further demonstrate that the proposed algorithm signiﬁcantly improves diagnostic accuracy when compared to both MIL and traditional classiﬁers. Although not designed for standard MIL problems (which have both positive and negative bags and relatively balanced datasets), comparisons against other MIL methods on benchmark problems also indicate that the proposed method is competitive with the state-of-the-art.</p><p>4 0.3616707 <a title="49-lda-4" href="./nips-2006-Analysis_of_Empirical_Bayesian_Methods_for_Neuroelectromagnetic_Source_Localization.html">32 nips-2006-Analysis of Empirical Bayesian Methods for Neuroelectromagnetic Source Localization</a></p>
<p>Author: Rey Ramírez, Jason Palmer, Scott Makeig, Bhaskar D. Rao, David P. Wipf</p><p>Abstract: The ill-posed nature of the MEG/EEG source localization problem requires the incorporation of prior assumptions when choosing an appropriate solution out of an inﬁnite set of candidates. Bayesian methods are useful in this capacity because they allow these assumptions to be explicitly quantiﬁed. Recently, a number of empirical Bayesian approaches have been proposed that attempt a form of model selection by using the data to guide the search for an appropriate prior. While seemingly quite different in many respects, we apply a unifying framework based on automatic relevance determination (ARD) that elucidates various attributes of these methods and suggests directions for improvement. We also derive theoretical properties of this methodology related to convergence, local minima, and localization bias and explore connections with established algorithms. 1</p><p>5 0.36133093 <a title="49-lda-5" href="./nips-2006-Denoising_and_Dimension_Reduction_in_Feature_Space.html">65 nips-2006-Denoising and Dimension Reduction in Feature Space</a></p>
<p>Author: Mikio L. Braun, Klaus-Robert Müller, Joachim M. Buhmann</p><p>Abstract: We show that the relevant information about a classiﬁcation problem in feature space is contained up to negligible error in a ﬁnite number of leading kernel PCA components if the kernel matches the underlying learning problem. Thus, kernels not only transform data sets such that good generalization can be achieved even by linear discriminant functions, but this transformation is also performed in a manner which makes economic use of feature space dimensions. In the best case, kernels provide efﬁcient implicit representations of the data to perform classiﬁcation. Practically, we propose an algorithm which enables us to recover the subspace and dimensionality relevant for good classiﬁcation. Our algorithm can therefore be applied (1) to analyze the interplay of data set and kernel in a geometric fashion, (2) to help in model selection, and to (3) de-noise in feature space in order to yield better classiﬁcation results. 1</p><p>6 0.35536781 <a title="49-lda-6" href="./nips-2006-Recursive_ICA.html">167 nips-2006-Recursive ICA</a></p>
<p>7 0.35287115 <a title="49-lda-7" href="./nips-2006-A_Complexity-Distortion_Approach_to_Joint_Pattern_Alignment.html">3 nips-2006-A Complexity-Distortion Approach to Joint Pattern Alignment</a></p>
<p>8 0.35225752 <a title="49-lda-8" href="./nips-2006-Temporal_Coding_using_the_Response_Properties_of_Spiking_Neurons.html">187 nips-2006-Temporal Coding using the Response Properties of Spiking Neurons</a></p>
<p>9 0.35208148 <a title="49-lda-9" href="./nips-2006-Simplifying_Mixture_Models_through_Function_Approximation.html">175 nips-2006-Simplifying Mixture Models through Function Approximation</a></p>
<p>10 0.35203326 <a title="49-lda-10" href="./nips-2006-Generalized_Maximum_Margin_Clustering_and_Unsupervised_Kernel_Learning.html">83 nips-2006-Generalized Maximum Margin Clustering and Unsupervised Kernel Learning</a></p>
<p>11 0.35168532 <a title="49-lda-11" href="./nips-2006-Predicting_spike_times_from_subthreshold_dynamics_of_a_neuron.html">162 nips-2006-Predicting spike times from subthreshold dynamics of a neuron</a></p>
<p>12 0.34999311 <a title="49-lda-12" href="./nips-2006-Clustering_Under_Prior_Knowledge_with_Application_to_Image_Segmentation.html">51 nips-2006-Clustering Under Prior Knowledge with Application to Image Segmentation</a></p>
<p>13 0.34995556 <a title="49-lda-13" href="./nips-2006-Fast_Iterative_Kernel_PCA.html">79 nips-2006-Fast Iterative Kernel PCA</a></p>
<p>14 0.34968022 <a title="49-lda-14" href="./nips-2006-Optimal_Change-Detection_and_Spiking_Neurons.html">154 nips-2006-Optimal Change-Detection and Spiking Neurons</a></p>
<p>15 0.3493267 <a title="49-lda-15" href="./nips-2006-Learning_on_Graph_with_Laplacian_Regularization.html">117 nips-2006-Learning on Graph with Laplacian Regularization</a></p>
<p>16 0.34905434 <a title="49-lda-16" href="./nips-2006-Information_Bottleneck_Optimization_and_Independent_Component_Extraction_with_Spiking_Neurons.html">99 nips-2006-Information Bottleneck Optimization and Independent Component Extraction with Spiking Neurons</a></p>
<p>17 0.34826481 <a title="49-lda-17" href="./nips-2006-Emergence_of_conjunctive_visual_features_by_quadratic_independent_component_analysis.html">76 nips-2006-Emergence of conjunctive visual features by quadratic independent component analysis</a></p>
<p>18 0.34801078 <a title="49-lda-18" href="./nips-2006-Real-time_adaptive_information-theoretic_optimization_of_neurophysiology_experiments.html">165 nips-2006-Real-time adaptive information-theoretic optimization of neurophysiology experiments</a></p>
<p>19 0.34767905 <a title="49-lda-19" href="./nips-2006-Stratification_Learning%3A_Detecting_Mixed_Density_and_Dimensionality_in_High_Dimensional_Point_Clouds.html">184 nips-2006-Stratification Learning: Detecting Mixed Density and Dimensionality in High Dimensional Point Clouds</a></p>
<p>20 0.34704766 <a title="49-lda-20" href="./nips-2006-Learning_Nonparametric_Models_for_Probabilistic_Imitation.html">112 nips-2006-Learning Nonparametric Models for Probabilistic Imitation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
