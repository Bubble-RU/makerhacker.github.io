<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>15 nips-2006-A Switched Gaussian Process for Estimating Disparity and Segmentation in Binocular Stereo</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-15" href="#">nips2006-15</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>15 nips-2006-A Switched Gaussian Process for Estimating Disparity and Segmentation in Binocular Stereo</h1>
<br/><p>Source: <a title="nips-2006-15-pdf" href="http://papers.nips.cc/paper/2964-a-switched-gaussian-process-for-estimating-disparity-and-segmentation-in-binocular-stereo.pdf">pdf</a></p><p>Author: Oliver Williams</p><p>Abstract: This paper describes a Gaussian process framework for inferring pixel-wise disparity and bi-layer segmentation of a scene given a stereo pair of images. The Gaussian process covariance is parameterized by a foreground-backgroundocclusion segmentation label to model both smooth regions and discontinuities. As such, we call our model a switched Gaussian process. We propose a greedy incremental algorithm for adding observations from the data and assigning segmentation labels. Two observation schedules are proposed: the ﬁrst treats scanlines as independent, the second uses an active learning criterion to select a sparse subset of points to measure. We show that this probabilistic framework has comparable performance to the state-of-the-art. 1</p><p>Reference: <a title="nips-2006-15-reference" href="../nips2006_reference/nips-2006-A_Switched_Gaussian_Process_for_Estimating_Disparity_and_Segmentation_in_Binocular_Stereo_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 uk  Abstract This paper describes a Gaussian process framework for inferring pixel-wise disparity and bi-layer segmentation of a scene given a stereo pair of images. [sent-4, score-1.21]
</p><p>2 The Gaussian process covariance is parameterized by a foreground-backgroundocclusion segmentation label to model both smooth regions and discontinuities. [sent-5, score-0.48]
</p><p>3 As such, we call our model a switched Gaussian process. [sent-6, score-0.121]
</p><p>4 We propose a greedy incremental algorithm for adding observations from the data and assigning segmentation labels. [sent-7, score-0.628]
</p><p>5 Two observation schedules are proposed: the ﬁrst treats scanlines as independent, the second uses an active learning criterion to select a sparse subset of points to measure. [sent-8, score-0.477]
</p><p>6 1  Introduction  Given two views of the same scene, this paper addresses the dual objectives of inferring depth and segmentation in scenes with perceptually distinct foreground and background layers. [sent-10, score-0.827]
</p><p>7 We do this in a probabilistic framework using a Gaussian process prior to model the geometry of typical scenes of this type. [sent-11, score-0.097]
</p><p>8 Our approach has two properties of interest to practitioners: ﬁrstly, it can be employed incrementally which is useful for circumstances in which the time allowed for processing is constrained or variable; secondly it is probabilistic enabling fusion with other sources of scene information. [sent-12, score-0.164]
</p><p>9 However the inspiration for the work in this paper is [5] in which both segmentation and depth are estimated in a uniﬁed framework based around graph cuts. [sent-16, score-0.425]
</p><p>10 Gaussian process regression has previously been used in connection with stereo images in [6] to learn the non-linear mapping between matched left-right image points and scene points as an alternative to photogrammetric camera calibration [7]. [sent-18, score-0.647]
</p><p>11 In this paper we use a Gaussian process to help discover the initially unknown left-right matches in a complex scene: a camera calibration procedure might then be used to determine actual 3D scene geometry. [sent-19, score-0.233]
</p><p>12 2 describes our Gaussian process framework for inferring depth (disparity) and segmentation from stereo measurements. [sent-21, score-0.721]
</p><p>13 This schematic shows some of the important features in short baseline binocular stereo for an horizontal strip of pixels. [sent-27, score-0.249]
</p><p>14 Transitions between foreground and background at the right edge of a foreground object will induce a discontinuity from high to low disparity. [sent-28, score-0.632]
</p><p>15 Background–foreground transitions at the left edge of the foreground induce an occlusion region in which scene points visible in the left image are not visible in the right. [sent-29, score-0.838]
</p><p>16 com/vision/cambridge/i2i  2  Single frame disparity estimation  This framework is intended for use with short baseline stereo, in which the two images are taken slightly to the left and the right of a midpoint (see Fig. [sent-32, score-0.513]
</p><p>17 This means that most features visible in one image are visible in the other, albeit at a different location: for a given point x in the left image L(x), our aim is therefore to infer the location of the same scene point in the right image R(x ). [sent-34, score-0.541]
</p><p>18 We assume that both L and R have been rectiﬁed [7] such that all corresponding points have the same vertical coordinate; hence if x = [x y]T then x = [x − d(x) y]T where d(x) is called the disparity map for points x in the left image. [sent-35, score-0.612]
</p><p>19 1): Discontinuity Discontinuities occur where one pixel belongs to the foreground and its neighbour belongs to the background. [sent-38, score-0.376]
</p><p>20 Occlusion At background–foreground transitions (travelling horizontally from left to right), there will be a region of pixels in the left image that are not visible in the right since they are occluded by the foreground [3]. [sent-39, score-0.649]
</p><p>21 Such locations correspond to scene points in the background layer, however their disparity is undeﬁned. [sent-40, score-0.784]
</p><p>22 The next subsection describes a prior for disparity that attempts to capture these characteristics by modelling the bi-layer segmentation. [sent-41, score-0.583]
</p><p>23 1  A Gaussian process prior for disparity  We model the prior distribution of a disparity map to be a Gaussian process (GP) [9]. [sent-43, score-1.038]
</p><p>24 GPs are deﬁned by a mean function f (·) and a covariance function c(·, ·) which in turn deﬁne the joint distribution of disparities at a set of points {xi , . [sent-44, score-0.218]
</p><p>25 , d(xn )|f, c = Normal (f , C)  (1)  where fi = f (xi ) and Cij = c(xi , xj ). [sent-50, score-0.1]
</p><p>26 In order to specify a mean and covariance function that give typical disparity maps an high probability, we introduce a latent segmentation variable s(x) ∈ {F, B, O} for each point in the left image. [sent-51, score-0.882]
</p><p>27 This encodes whether a point belongs to the foreground (F), background (B) or is occluded (O) and makes it possible to model the fact that disparities in the background/foreground are smooth (spatially correlated) within their layers and are independent across layers. [sent-52, score-0.588]
</p><p>28 For a given segmentation,  the covariance function is  2  De−α xi −xj c(xi , xj ; s) = Dδ(xi − xj )  0  s(xi ) = s(xj ) = O s(xi ) = s(xj ) = O s(xi ) = s(xj )  (2)  where D is the maximum disparity in the scene and δ is the Dirac delta function. [sent-53, score-0.854]
</p><p>29 , the disparities are independent) unless they share the same segmentation label. [sent-56, score-0.453]
</p><p>30 01 for all of the experiments shown in this paper (the points x are measured in pixel units). [sent-58, score-0.108]
</p><p>31 It will be convenient in what follows to deﬁne the covariance for sets of points such that c(X , X ; s) = C(s) ∈ Rn×n where the element Cij is the covariance of the ith element of X and j th element of X . [sent-59, score-0.196]
</p><p>32 The prior mean is also deﬁned according to segmentation to reﬂect the fact that the foreground is at greater disparity (nearer the camera) than the background 0. [sent-60, score-1.16]
</p><p>33 5D s(x) = O Because of the independence induced by the discrete labels s(x), we call this prior model a switched Gaussian process. [sent-64, score-0.149]
</p><p>34 ¯ ¯ L2 (x + a) + R2 (x + a + d)  (4)  This cost has been shown in practice to be effective for disparity estimation [11]. [sent-68, score-0.45]
</p><p>35 We follow the approach of [12] for this in which a parabola is ﬁtted around the disparity with minimum score m(x, d) ≈ ad2 + bd + c. [sent-70, score-0.45]
</p><p>36 Interpreting this as the inverse logarithm of a Gaussian distribution gives d(x) = µ(x) + with µ(x) =  b −a  and v(x) =  1 2a  where  ∼ Normal (0, v(x))  (5)  being the observation mean and variance. [sent-71, score-0.112]
</p><p>37 Given a segmentation and a set of noisy measurements at locations X = {xi , . [sent-72, score-0.506]
</p><p>38 , xn }, the GP can be used to predict the disparity at a new point P (d(x)|X ). [sent-75, score-0.496]
</p><p>39 3  Segmentation likelihood  The previous discussion has assumed that the segmentation is known, yet this will rarely be the case in practice: s must therefore be inferred from the data together with the disparity. [sent-84, score-0.412]
</p><p>40 For a given set of observations, the probability that they are a sample from the GP prior is given by n T˜ ˜ (7) E(X ) = log P µ|s, v = − µ − f (s) C(s)−1 µ − f (s) − log det C(s) − log 2π. [sent-85, score-0.171]
</p><p>41 The next section describes an algorithm that uses this quantity to infer a segmentation whilst incorporating observations. [sent-87, score-0.391]
</p><p>42 3  Incremental incorporation of measurements and model selection  We propose an incremental and greedy algorithm for ﬁnding a segmentation. [sent-88, score-0.275]
</p><p>43 Measurements are incorporated one at a time and the evidence of adding the ith observation to each of the three segmentation layers is computed based on the preceding i − 1 observations and their labels. [sent-89, score-0.674]
</p><p>44 The ith point is labelled according to which gave the greatest evidence. [sent-90, score-0.132]
</p><p>45 Since the three segmentation layers are independent, some of the cost of com˜ ˜ ˜ puting and storing the large matrix C −1 is avoided by constructing F −1 and B −1 instead where ˜ = c(XF , XF ) and B = c(XB , XB ). [sent-95, score-0.411]
</p><p>46 Observations assigned to the occlusion layer are independent ˜ F of all other points and contain no useful information. [sent-96, score-0.206]
</p><p>47 As shown in [13], the GP framework easily facilitates incremental incorporation of observations by repeatedly updating the matrix inverse required in the prediction equations (6). [sent-98, score-0.253]
</p><p>48 ∆Ej (xi ) = log(rj ) −  Algorithm 1 gives pseudo-code for the incremental incorporation of a measurement and greedy labelling. [sent-101, score-0.253]
</p><p>49 As with Gaussian Process regression in general, this algorithm scales as O(n2 ) for storage and O(n3 ) for time and it is therefore impractical to make an observation at every pixel for images of useful size. [sent-102, score-0.156]
</p><p>50 Factorize the image into several sub-images and treat each one independently. [sent-104, score-0.081]
</p><p>51 The next subsection demonstrates this when each scanline (row of pixels) is handled independently. [sent-105, score-0.268]
</p><p>52 Only make measurements at a sparse subset of locations. [sent-107, score-0.134]
</p><p>53 2 describes an active learning approach for identifying optimally informative observation points. [sent-109, score-0.265]
</p><p>54 1  Independent scanline observation schedule  By handling the image pixels one row at a time, the problem becomes one-dimensional. [sent-111, score-0.458]
</p><p>55 Disparity and segmentation maps inferred by treating each scanline independently. [sent-113, score-0.616]
</p><p>56 (c) ˜ Inferred segmentation s(x) with F = white, B = grey (orange) and O = black. [sent-116, score-0.35]
</p><p>57 1 shows the segmentation for a typical image from which it can be seen that, moving horizontally from right to left, the only “legal” transitions in segmentation are B → F, F → O and O → B. [sent-122, score-0.866]
</p><p>58 Both the disparities and segmentation are, subjectively, accurate however there are a number of “streaky” artifacts caused by the fact that there is no vertical sharing of information. [sent-126, score-0.507]
</p><p>59 The occlusion class could therefore be more accurately described as a general outlier category. [sent-128, score-0.091]
</p><p>60 2  Active selection of sparse measurement locations  As shown above, our GP model scales badly with the number of observations. [sent-130, score-0.194]
</p><p>61 Rather than introduce artiﬁcial independencies, the observation schedule in this section copes with the O(n3 ) scaling by making measurements at only a sparse set of locations. [sent-132, score-0.264]
</p><p>62 Obvious ways of implementing this include choosing n locations either at random or in a grid pattern, however these fail to exploit information that can be readily obtained from both the image data and the current predictions made by the model. [sent-133, score-0.204]
</p><p>63 Hence, we propose an active approach, similar to that in [14]: given the ﬁrst i − 1 observations, observe the point which maximally reduces the entropy of the GP [8] ∆H(x) = H P (d|Xi−1 ) − H P (d|Xi−1 ∪ x) = − 1 log det Σ + 2  1 2  log det Σ + const. [sent-134, score-0.304]
</p><p>64 (11)  where Σ and Σ are the posterior covariances of the GP over all points in the image before and after making an observation at x. [sent-135, score-0.228]
</p><p>65 To compute the entire posterior for each observation would be prohibitively expense; instead we approximate it by the product of the marginal distributions at each  (a)  (b)  (c)  Figure 3: Predictions after sparse active observation schedule. [sent-136, score-0.366]
</p><p>66 This ﬁgure shows the predictions made by the GP model with observations at 1000 image locations for the images used in Fig. [sent-137, score-0.329]
</p><p>67 (a) Mean predicted disparity µ(x); (b) Predictive uncertainty v (x); (c) Inferred segmentation. [sent-139, score-0.482]
</p><p>68 , ignore off-diagonal elements in Σ) which gives ∆H(x) ≈ 1 log v (x) − log v(x) where ˜ 2 v (x) is the predicted variance from (6) and v(x) is the measurement variance. [sent-142, score-0.146]
</p><p>69 v(x)  (12)  Here the numerator drives the system to make observations at points with greatest predictive uncertainty. [sent-144, score-0.211]
</p><p>70 However, this is balanced by the denominator to avoid making observations at points where there is no information to be obtained from the data (e. [sent-145, score-0.159]
</p><p>71 To initialize the active algorithm, 64 initial observations are made in a evenly spaced grid over the image. [sent-149, score-0.236]
</p><p>72 Following this, points are selected using the utility function (12) and incorporated into the GP model using Algorithm 1. [sent-150, score-0.092]
</p><p>73 Predicting disparity in the scanline factorization was straightforward because a segmentation label had been assigned to every pixel. [sent-151, score-1.043]
</p><p>74 With sparse measurements, only the observation points have been labelled and to predict disparity at an arbitrary location a segmentation label must also be inferred. [sent-152, score-1.123]
</p><p>75 3 shows the results of using this active observation schedule with n = 1000 for the images of Fig. [sent-157, score-0.303]
</p><p>76 As expected, by restoring 2D spatial coherence the results are smoother and have none of the streaky artifacts induced by the scanline factorization. [sent-159, score-0.336]
</p><p>77 3% of the points used by the scanline factorization, the active algorithm has still managed to capture the important features in the scenes. [sent-161, score-0.411]
</p><p>78 4b demonstrates further the beneﬁts of selecting the points in an active framework compared to taking points at random. [sent-165, score-0.272]
</p><p>79 10 active random % mislabelled points  8  6  4  2  0  0  (a)  500 1000 1500 number of observations n  2000  (b)  Figure 4: Advantage of active point selection. [sent-166, score-0.495]
</p><p>80 3 with spots (blue) corresponding to observation locations selected by the active criterion. [sent-168, score-0.306]
</p><p>81 (b) This plot compares the accuracy of the segmentation against the number of sparse observations when the observation locations are chosen at random and using our active schedule. [sent-169, score-0.845]
</p><p>82 Accuracy is measured as the percentage of mislabelled pixels compared to a hand-labelled ground truth segmentation. [sent-170, score-0.095]
</p><p>83 The active strategy achieves better accuracy with fewer observations. [sent-171, score-0.177]
</p><p>84 (a)  (b)  (c)  Figure 5: Improved segmentation by fusion with colour. [sent-172, score-0.4]
</p><p>85 (a) Pixel-wise energy term V (x) combining segmentation predictions from both the switched GP posterior and a colour model; (b) Segmentation returned by the Viterbi algorithm. [sent-173, score-0.716]
</p><p>86 3  Adding colour information  The best segmentation accuracies using stereo information alone are around 1% labelling errors (with n ≥ 1000). [sent-178, score-0.781]
</p><p>87 In [5], superior segmentation results are achieved by incorporating colour information. [sent-179, score-0.554]
</p><p>88 ˜ ˜  (14)  We represent the colour distribution using a 10 × 10 × 10 bin histogram in red-green-blue colour space. [sent-181, score-0.408]
</p><p>89 As in [5], we treat each scanline as a binary HMM and use the Viterbi algorithm to ﬁnd a segmentation. [sent-185, score-0.204]
</p><p>90 We suspect that our result can be improved with a more sophisticated colour model. [sent-191, score-0.204]
</p><p>91 4  Discussion  We have proposed a Gaussian process model for disparity, switched by a latent segmentation variable. [sent-192, score-0.512]
</p><p>92 We call this a switched Gaussian process and have proposed an incremental greedy algorithm  for ﬁtting this model to data and inferring a segmentation. [sent-193, score-0.361]
</p><p>93 We have demonstrated that by using a sparse model with points selected according to an active learning criterion, an accuracy can be achieved that is comparable to the state of the art [5]. [sent-194, score-0.345]
</p><p>94 We believe there are four key strengths to this probabilistic framework: Flexibility The incremental nature of the algorithm makes it possible to set the number of observations n according to time or quality constraints. [sent-195, score-0.209]
</p><p>95 However, higher quality results require n > 1000 observations which reduces the execution speed to a few seconds per image. [sent-200, score-0.122]
</p><p>96 Accuracy We have shown that (for large n) this technique achieves an accuracy comparable to the state of the art. [sent-201, score-0.078]
</p><p>97 A taxonomy and evaluation of desnse two-frame stereo correspondence algorithms. [sent-285, score-0.172]
</p><p>98 Incremental estimation of dense depth maps from image sequences. [sent-293, score-0.156]
</p><p>99 Fast forward selection to speed up sparse gaussian process regression. [sent-310, score-0.151]
</p><p>100 A unifying view of sparse approximate Gaussian n process regression. [sent-317, score-0.101]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('disparity', 0.45), ('segmentation', 0.35), ('foreground', 0.259), ('xf', 0.227), ('scanline', 0.204), ('colour', 0.204), ('gp', 0.191), ('stereo', 0.172), ('active', 0.142), ('xi', 0.134), ('switched', 0.121), ('incremental', 0.115), ('scene', 0.114), ('disparities', 0.103), ('xb', 0.103), ('observations', 0.094), ('occlusion', 0.091), ('ej', 0.086), ('locations', 0.082), ('observation', 0.082), ('image', 0.081), ('qf', 0.078), ('streaky', 0.078), ('binocular', 0.077), ('depth', 0.075), ('measurements', 0.074), ('background', 0.073), ('xo', 0.068), ('points', 0.065), ('subsection', 0.064), ('visible', 0.062), ('lc', 0.062), ('inferred', 0.062), ('layers', 0.061), ('sparse', 0.06), ('rj', 0.059), ('occlusions', 0.058), ('qt', 0.058), ('labelling', 0.055), ('occluded', 0.055), ('rf', 0.055), ('artifacts', 0.054), ('xj', 0.053), ('measurement', 0.052), ('mislabelled', 0.052), ('qui', 0.052), ('scanlines', 0.052), ('greatest', 0.052), ('gaussian', 0.05), ('covariance', 0.05), ('layer', 0.05), ('det', 0.05), ('fusion', 0.05), ('labelled', 0.049), ('schedule', 0.048), ('fi', 0.047), ('xn', 0.046), ('horizontally', 0.045), ('incorporation', 0.044), ('pixel', 0.043), ('pixels', 0.043), ('comparable', 0.043), ('camera', 0.043), ('inferring', 0.042), ('greedy', 0.042), ('discontinuity', 0.041), ('schedules', 0.041), ('process', 0.041), ('predictions', 0.041), ('describes', 0.041), ('transitions', 0.04), ('label', 0.039), ('switching', 0.038), ('belongs', 0.037), ('cij', 0.036), ('kolmogorov', 0.036), ('vision', 0.035), ('accuracy', 0.035), ('calibration', 0.035), ('qj', 0.035), ('segmentations', 0.035), ('treats', 0.035), ('legal', 0.033), ('left', 0.032), ('predicted', 0.032), ('rasmussen', 0.032), ('unde', 0.032), ('log', 0.031), ('ith', 0.031), ('images', 0.031), ('viterbi', 0.031), ('logarithm', 0.03), ('xs', 0.03), ('evidence', 0.029), ('prior', 0.028), ('scenes', 0.028), ('execution', 0.028), ('location', 0.028), ('utility', 0.027), ('adding', 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="15-tfidf-1" href="./nips-2006-A_Switched_Gaussian_Process_for_Estimating_Disparity_and_Segmentation_in_Binocular_Stereo.html">15 nips-2006-A Switched Gaussian Process for Estimating Disparity and Segmentation in Binocular Stereo</a></p>
<p>Author: Oliver Williams</p><p>Abstract: This paper describes a Gaussian process framework for inferring pixel-wise disparity and bi-layer segmentation of a scene given a stereo pair of images. The Gaussian process covariance is parameterized by a foreground-backgroundocclusion segmentation label to model both smooth regions and discontinuities. As such, we call our model a switched Gaussian process. We propose a greedy incremental algorithm for adding observations from the data and assigning segmentation labels. Two observation schedules are proposed: the ﬁrst treats scanlines as independent, the second uses an active learning criterion to select a sparse subset of points to measure. We show that this probabilistic framework has comparable performance to the state-of-the-art. 1</p><p>2 0.30447379 <a title="15-tfidf-2" href="./nips-2006-Neurophysiological_Evidence_of_Cooperative_Mechanisms_for_Stereo_Computation.html">145 nips-2006-Neurophysiological Evidence of Cooperative Mechanisms for Stereo Computation</a></p>
<p>Author: Jason M. Samonds, Brian R. Potetz, Tai S. Lee</p><p>Abstract: Although there has been substantial progress in understanding the neurophysiological mechanisms of stereopsis, how neurons interact in a network during stereo computation remains unclear. Computational models on stereopsis suggest local competition and long-range cooperation are important for resolving ambiguity during stereo matching. To test these predictions, we simultaneously recorded from multiple neurons in V1 of awake, behaving macaques while presenting surfaces of different depths rendered in dynamic random dot stereograms. We found that the interaction between pairs of neurons was a function of similarity in receptive fields, as well as of the input stimulus. Neurons coding the same depth experienced common inhibition early in their responses for stimuli presented at their nonpreferred disparities. They experienced mutual facilitation later in their responses for stimulation at their preferred disparity. These findings are consistent with a local competition mechanism that first removes gross mismatches, and a global cooperative mechanism that further refines depth estimates. 1 In trod u ction The human visual system is able to extract three-dimensional (3D) structures in random noise stereograms even when such images evoke no perceptible patterns when viewed monocularly [1]. Bela Julesz proposed that this is accomplished by a stereopsis mechanism that detects correlated shifts in 2D noise patterns between the two eyes. He also suggested that this mechanism likely involves cooperative neural processing early in the visual system. Marr and Poggio formalized the computational constraints for solving stereo matching (Fig. 1a) and devised an algorithm that can discover the underlying 3D structures in a variety of random dot stereogram patterns [2]. Their algorithm was based on two rules: (1) each element or feature is unique (i.e., can be assigned only one disparity) and (2) surfaces of objects are cohesive (i.e., depth changes gradually across space). To describe their algorithm in neurophysiological terms, we can consider neurons in primary visual cortex as simple element or feature detectors. The first rule is implemented by introducing competitive interactions (mutual inhibition) among neurons of different disparity tuning at each location (Fig. 1b, blue solid horizontal or vertical lines), allowing only one disparity to be detected at each location. The second rule is implemented by introducing cooperative interactions (mutual facilitation) among neurons tuned to the same depth (image disparity) across different spatial locations (Fig. 1b, along the red dashed diagonal lines). In other words, a disparity estimate at one location is more likely to be correct if neighboring locations have similar disparity estimates. A dynamic system under such constraints can relax to a stable global disparity map. Here, we present neurophysiological evidence of interactions between disparity-tuned neurons in the primary visual cortex that is consistent with this general approach. We sampled from a variety of spatially distributed disparity tuned neurons (see electrodes Fig. 1b) while displaying DRDS stimuli defined at various disparities (see stimulus Fig.1b). We then measured the dynamics of interactions by assessing the temporal evolution of correlation in neural responses. a Left Image b Right Image Electrodes Disparity Left Image ? Stimulus Right Image Figure 1: (a) Left and right images of random dot stereogram (right image has been shifted to the right). (b) 1D graphical depiction of competition (blue solid lines) and cooperation (red dashed lines) among disparity-tuned neurons with respect to space as defined by Marr and Poggio’s stereo algorithm [2]. 2 2.1 Methods Recording and stimulation a Posterior - Anterior Recordings were made in V1 of two awake, behaving macaques. We simultaneously recorded from 4-8 electrodes providing data from up to 10 neurons in a single recording session (some electrodes recorded from as many as 3 neurons). We collected data from 112 neurons that provided 224 pairs for cross-correlation analysis. For stimuli, we used 12 Hz dynamic random dot stereograms (DRDS; 25% density black and white pixels on a mean luminance background) presented in a 3.5-degree aperture. Liquid crystal shutter goggles were used to present random dot patterns to each eye separately. Eleven horizontal disparities between the two eyes, ranging from ±0.9 degrees, were tested. Seventy-four neurons (66%) had significant disparity tuning and 99 pairs (44%) were comprised of neurons that both had significant disparity tuning (1-way ANOVA, p<0.05). b 5mm Medial - Lateral 100µV 0.2ms 1° Figure 2: (a) Example recording session from five electrodes in V1. (b) Receptive field (white box—arrow represents direction preference) and random dot stereogram locations for same recording session (small red square is the fixation spot). 2.2 Data analysis Interaction between neurons was described as</p><p>3 0.20227721 <a title="15-tfidf-3" href="./nips-2006-Clustering_Under_Prior_Knowledge_with_Application_to_Image_Segmentation.html">51 nips-2006-Clustering Under Prior Knowledge with Application to Image Segmentation</a></p>
<p>Author: Dong S. Cheng, Vittorio Murino, Mário Figueiredo</p><p>Abstract: This paper proposes a new approach to model-based clustering under prior knowledge. The proposed formulation can be interpreted from two different angles: as penalized logistic regression, where the class labels are only indirectly observed (via the probability density of each class); as ﬁnite mixture learning under a grouping prior. To estimate the parameters of the proposed model, we derive a (generalized) EM algorithm with a closed-form E-step, in contrast with other recent approaches to semi-supervised probabilistic clustering which require Gibbs sampling or suboptimal shortcuts. We show that our approach is ideally suited for image segmentation: it avoids the combinatorial nature Markov random ﬁeld priors, and opens the door to more sophisticated spatial priors (e.g., wavelet-based) in a simple and computationally efﬁcient way. Finally, we extend our formulation to work in unsupervised, semi-supervised, or discriminative modes. 1</p><p>4 0.11613467 <a title="15-tfidf-4" href="./nips-2006-Online_Clustering_of_Moving_Hyperplanes.html">153 nips-2006-Online Clustering of Moving Hyperplanes</a></p>
<p>Author: René Vidal</p><p>Abstract: We propose a recursive algorithm for clustering trajectories lying in multiple moving hyperplanes. Starting from a given or random initial condition, we use normalized gradient descent to update the coefﬁcients of a time varying polynomial whose degree is the number of hyperplanes and whose derivatives at a trajectory give an estimate of the vector normal to the hyperplane containing that trajectory. As time proceeds, the estimates of the hyperplane normals are shown to track their true values in a stable fashion. The segmentation of the trajectories is then obtained by clustering their associated normal vectors. The ﬁnal result is a simple recursive algorithm for segmenting a variable number of moving hyperplanes. We test our algorithm on the segmentation of dynamic scenes containing rigid motions and dynamic textures, e.g., a bird ﬂoating on water. Our method not only segments the bird motion from the surrounding water motion, but also determines patterns of motion in the scene (e.g., periodic motion) directly from the temporal evolution of the estimated polynomial coefﬁcients. Our experiments also show that our method can deal with appearing and disappearing motions in the scene.</p><p>5 0.11026929 <a title="15-tfidf-5" href="./nips-2006-Data_Integration_for_Classification_Problems_Employing_Gaussian_Process_Priors.html">64 nips-2006-Data Integration for Classification Problems Employing Gaussian Process Priors</a></p>
<p>Author: Mark Girolami, Mingjun Zhong</p><p>Abstract: By adopting Gaussian process priors a fully Bayesian solution to the problem of integrating possibly heterogeneous data sets within a classiﬁcation setting is presented. Approximate inference schemes employing Variational & Expectation Propagation based methods are developed and rigorously assessed. We demonstrate our approach to integrating multiple data sets on a large scale protein fold prediction problem where we infer the optimal combinations of covariance functions and achieve state-of-the-art performance without resorting to any ad hoc parameter tuning and classiﬁer combination. 1</p><p>6 0.10235995 <a title="15-tfidf-6" href="./nips-2006-Blind_Motion_Deblurring_Using_Image_Statistics.html">45 nips-2006-Blind Motion Deblurring Using Image Statistics</a></p>
<p>7 0.092233792 <a title="15-tfidf-7" href="./nips-2006-Active_learning_for_misspecified_generalized_linear_models.html">20 nips-2006-Active learning for misspecified generalized linear models</a></p>
<p>8 0.077425204 <a title="15-tfidf-8" href="./nips-2006-A_Nonparametric_Approach_to_Bottom-Up_Visual_Saliency.html">8 nips-2006-A Nonparametric Approach to Bottom-Up Visual Saliency</a></p>
<p>9 0.077242635 <a title="15-tfidf-9" href="./nips-2006-Stochastic_Relational_Models_for_Discriminative_Link_Prediction.html">183 nips-2006-Stochastic Relational Models for Discriminative Link Prediction</a></p>
<p>10 0.075323246 <a title="15-tfidf-10" href="./nips-2006-Fundamental_Limitations_of_Spectral_Clustering.html">80 nips-2006-Fundamental Limitations of Spectral Clustering</a></p>
<p>11 0.072636329 <a title="15-tfidf-11" href="./nips-2006-Unsupervised_Regression_with_Applications_to_Nonlinear_System_Identification.html">200 nips-2006-Unsupervised Regression with Applications to Nonlinear System Identification</a></p>
<p>12 0.069585957 <a title="15-tfidf-12" href="./nips-2006-Learning_to_parse_images_of_articulated_bodies.html">122 nips-2006-Learning to parse images of articulated bodies</a></p>
<p>13 0.067804977 <a title="15-tfidf-13" href="./nips-2006-Recursive_ICA.html">167 nips-2006-Recursive ICA</a></p>
<p>14 0.066888817 <a title="15-tfidf-14" href="./nips-2006-Fast_Discriminative_Visual_Codebooks_using_Randomized_Clustering_Forests.html">78 nips-2006-Fast Discriminative Visual Codebooks using Randomized Clustering Forests</a></p>
<p>15 0.066774309 <a title="15-tfidf-15" href="./nips-2006-Greedy_Layer-Wise_Training_of_Deep_Networks.html">88 nips-2006-Greedy Layer-Wise Training of Deep Networks</a></p>
<p>16 0.065336071 <a title="15-tfidf-16" href="./nips-2006-Efficient_sparse_coding_algorithms.html">75 nips-2006-Efficient sparse coding algorithms</a></p>
<p>17 0.064284727 <a title="15-tfidf-17" href="./nips-2006-Bayesian_Image_Super-resolution%2C_Continued.html">42 nips-2006-Bayesian Image Super-resolution, Continued</a></p>
<p>18 0.064275958 <a title="15-tfidf-18" href="./nips-2006-Simplifying_Mixture_Models_through_Function_Approximation.html">175 nips-2006-Simplifying Mixture Models through Function Approximation</a></p>
<p>19 0.063932948 <a title="15-tfidf-19" href="./nips-2006-Modeling_Human_Motion_Using_Binary_Latent_Variables.html">134 nips-2006-Modeling Human Motion Using Binary Latent Variables</a></p>
<p>20 0.061649498 <a title="15-tfidf-20" href="./nips-2006-Efficient_Structure_Learning_of_Markov_Networks_using_%24L_1%24-Regularization.html">74 nips-2006-Efficient Structure Learning of Markov Networks using $L 1$-Regularization</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2006_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.211), (1, -0.012), (2, 0.131), (3, -0.025), (4, 0.052), (5, -0.019), (6, -0.026), (7, -0.058), (8, -0.009), (9, 0.11), (10, 0.117), (11, -0.059), (12, -0.015), (13, 0.029), (14, -0.068), (15, 0.22), (16, 0.124), (17, -0.085), (18, 0.016), (19, 0.187), (20, -0.1), (21, 0.107), (22, 0.149), (23, 0.021), (24, 0.205), (25, -0.221), (26, -0.04), (27, -0.202), (28, 0.106), (29, 0.135), (30, -0.028), (31, 0.002), (32, 0.011), (33, 0.013), (34, -0.269), (35, -0.001), (36, 0.058), (37, 0.029), (38, -0.104), (39, 0.138), (40, 0.128), (41, -0.056), (42, 0.05), (43, 0.008), (44, -0.061), (45, -0.136), (46, 0.0), (47, 0.026), (48, -0.096), (49, 0.097)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94626117 <a title="15-lsi-1" href="./nips-2006-A_Switched_Gaussian_Process_for_Estimating_Disparity_and_Segmentation_in_Binocular_Stereo.html">15 nips-2006-A Switched Gaussian Process for Estimating Disparity and Segmentation in Binocular Stereo</a></p>
<p>Author: Oliver Williams</p><p>Abstract: This paper describes a Gaussian process framework for inferring pixel-wise disparity and bi-layer segmentation of a scene given a stereo pair of images. The Gaussian process covariance is parameterized by a foreground-backgroundocclusion segmentation label to model both smooth regions and discontinuities. As such, we call our model a switched Gaussian process. We propose a greedy incremental algorithm for adding observations from the data and assigning segmentation labels. Two observation schedules are proposed: the ﬁrst treats scanlines as independent, the second uses an active learning criterion to select a sparse subset of points to measure. We show that this probabilistic framework has comparable performance to the state-of-the-art. 1</p><p>2 0.71380371 <a title="15-lsi-2" href="./nips-2006-Neurophysiological_Evidence_of_Cooperative_Mechanisms_for_Stereo_Computation.html">145 nips-2006-Neurophysiological Evidence of Cooperative Mechanisms for Stereo Computation</a></p>
<p>Author: Jason M. Samonds, Brian R. Potetz, Tai S. Lee</p><p>Abstract: Although there has been substantial progress in understanding the neurophysiological mechanisms of stereopsis, how neurons interact in a network during stereo computation remains unclear. Computational models on stereopsis suggest local competition and long-range cooperation are important for resolving ambiguity during stereo matching. To test these predictions, we simultaneously recorded from multiple neurons in V1 of awake, behaving macaques while presenting surfaces of different depths rendered in dynamic random dot stereograms. We found that the interaction between pairs of neurons was a function of similarity in receptive fields, as well as of the input stimulus. Neurons coding the same depth experienced common inhibition early in their responses for stimuli presented at their nonpreferred disparities. They experienced mutual facilitation later in their responses for stimulation at their preferred disparity. These findings are consistent with a local competition mechanism that first removes gross mismatches, and a global cooperative mechanism that further refines depth estimates. 1 In trod u ction The human visual system is able to extract three-dimensional (3D) structures in random noise stereograms even when such images evoke no perceptible patterns when viewed monocularly [1]. Bela Julesz proposed that this is accomplished by a stereopsis mechanism that detects correlated shifts in 2D noise patterns between the two eyes. He also suggested that this mechanism likely involves cooperative neural processing early in the visual system. Marr and Poggio formalized the computational constraints for solving stereo matching (Fig. 1a) and devised an algorithm that can discover the underlying 3D structures in a variety of random dot stereogram patterns [2]. Their algorithm was based on two rules: (1) each element or feature is unique (i.e., can be assigned only one disparity) and (2) surfaces of objects are cohesive (i.e., depth changes gradually across space). To describe their algorithm in neurophysiological terms, we can consider neurons in primary visual cortex as simple element or feature detectors. The first rule is implemented by introducing competitive interactions (mutual inhibition) among neurons of different disparity tuning at each location (Fig. 1b, blue solid horizontal or vertical lines), allowing only one disparity to be detected at each location. The second rule is implemented by introducing cooperative interactions (mutual facilitation) among neurons tuned to the same depth (image disparity) across different spatial locations (Fig. 1b, along the red dashed diagonal lines). In other words, a disparity estimate at one location is more likely to be correct if neighboring locations have similar disparity estimates. A dynamic system under such constraints can relax to a stable global disparity map. Here, we present neurophysiological evidence of interactions between disparity-tuned neurons in the primary visual cortex that is consistent with this general approach. We sampled from a variety of spatially distributed disparity tuned neurons (see electrodes Fig. 1b) while displaying DRDS stimuli defined at various disparities (see stimulus Fig.1b). We then measured the dynamics of interactions by assessing the temporal evolution of correlation in neural responses. a Left Image b Right Image Electrodes Disparity Left Image ? Stimulus Right Image Figure 1: (a) Left and right images of random dot stereogram (right image has been shifted to the right). (b) 1D graphical depiction of competition (blue solid lines) and cooperation (red dashed lines) among disparity-tuned neurons with respect to space as defined by Marr and Poggio’s stereo algorithm [2]. 2 2.1 Methods Recording and stimulation a Posterior - Anterior Recordings were made in V1 of two awake, behaving macaques. We simultaneously recorded from 4-8 electrodes providing data from up to 10 neurons in a single recording session (some electrodes recorded from as many as 3 neurons). We collected data from 112 neurons that provided 224 pairs for cross-correlation analysis. For stimuli, we used 12 Hz dynamic random dot stereograms (DRDS; 25% density black and white pixels on a mean luminance background) presented in a 3.5-degree aperture. Liquid crystal shutter goggles were used to present random dot patterns to each eye separately. Eleven horizontal disparities between the two eyes, ranging from ±0.9 degrees, were tested. Seventy-four neurons (66%) had significant disparity tuning and 99 pairs (44%) were comprised of neurons that both had significant disparity tuning (1-way ANOVA, p<0.05). b 5mm Medial - Lateral 100µV 0.2ms 1° Figure 2: (a) Example recording session from five electrodes in V1. (b) Receptive field (white box—arrow represents direction preference) and random dot stereogram locations for same recording session (small red square is the fixation spot). 2.2 Data analysis Interaction between neurons was described as</p><p>3 0.50940484 <a title="15-lsi-3" href="./nips-2006-Clustering_Under_Prior_Knowledge_with_Application_to_Image_Segmentation.html">51 nips-2006-Clustering Under Prior Knowledge with Application to Image Segmentation</a></p>
<p>Author: Dong S. Cheng, Vittorio Murino, Mário Figueiredo</p><p>Abstract: This paper proposes a new approach to model-based clustering under prior knowledge. The proposed formulation can be interpreted from two different angles: as penalized logistic regression, where the class labels are only indirectly observed (via the probability density of each class); as ﬁnite mixture learning under a grouping prior. To estimate the parameters of the proposed model, we derive a (generalized) EM algorithm with a closed-form E-step, in contrast with other recent approaches to semi-supervised probabilistic clustering which require Gibbs sampling or suboptimal shortcuts. We show that our approach is ideally suited for image segmentation: it avoids the combinatorial nature Markov random ﬁeld priors, and opens the door to more sophisticated spatial priors (e.g., wavelet-based) in a simple and computationally efﬁcient way. Finally, we extend our formulation to work in unsupervised, semi-supervised, or discriminative modes. 1</p><p>4 0.48437002 <a title="15-lsi-4" href="./nips-2006-Online_Clustering_of_Moving_Hyperplanes.html">153 nips-2006-Online Clustering of Moving Hyperplanes</a></p>
<p>Author: René Vidal</p><p>Abstract: We propose a recursive algorithm for clustering trajectories lying in multiple moving hyperplanes. Starting from a given or random initial condition, we use normalized gradient descent to update the coefﬁcients of a time varying polynomial whose degree is the number of hyperplanes and whose derivatives at a trajectory give an estimate of the vector normal to the hyperplane containing that trajectory. As time proceeds, the estimates of the hyperplane normals are shown to track their true values in a stable fashion. The segmentation of the trajectories is then obtained by clustering their associated normal vectors. The ﬁnal result is a simple recursive algorithm for segmenting a variable number of moving hyperplanes. We test our algorithm on the segmentation of dynamic scenes containing rigid motions and dynamic textures, e.g., a bird ﬂoating on water. Our method not only segments the bird motion from the surrounding water motion, but also determines patterns of motion in the scene (e.g., periodic motion) directly from the temporal evolution of the estimated polynomial coefﬁcients. Our experiments also show that our method can deal with appearing and disappearing motions in the scene.</p><p>5 0.37451893 <a title="15-lsi-5" href="./nips-2006-Similarity_by_Composition.html">174 nips-2006-Similarity by Composition</a></p>
<p>Author: Oren Boiman, Michal Irani</p><p>Abstract: We propose a new approach for measuring similarity between two signals, which is applicable to many machine learning tasks, and to many signal types. We say that a signal S1 is “similar” to a signal S2 if it is “easy” to compose S1 from few large contiguous chunks of S2 . Obviously, if we use small enough pieces, then any signal can be composed of any other. Therefore, the larger those pieces are, the more similar S1 is to S2 . This induces a local similarity score at every point in the signal, based on the size of its supported surrounding region. These local scores can in turn be accumulated in a principled information-theoretic way into a global similarity score of the entire S1 to S2 . “Similarity by Composition” can be applied between pairs of signals, between groups of signals, and also between different portions of the same signal. It can therefore be employed in a wide variety of machine learning problems (clustering, classiﬁcation, retrieval, segmentation, attention, saliency, labelling, etc.), and can be applied to a wide range of signal types (images, video, audio, biological data, etc.) We show a few such examples. 1</p><p>6 0.3653788 <a title="15-lsi-6" href="./nips-2006-Blind_Motion_Deblurring_Using_Image_Statistics.html">45 nips-2006-Blind Motion Deblurring Using Image Statistics</a></p>
<p>7 0.33797786 <a title="15-lsi-7" href="./nips-2006-Clustering_appearance_and_shape_by_learning_jigsaws.html">52 nips-2006-Clustering appearance and shape by learning jigsaws</a></p>
<p>8 0.33383837 <a title="15-lsi-8" href="./nips-2006-Robotic_Grasping_of_Novel_Objects.html">170 nips-2006-Robotic Grasping of Novel Objects</a></p>
<p>9 0.3025161 <a title="15-lsi-9" href="./nips-2006-Temporal_dynamics_of_information_content_carried_by_neurons_in_the_primary_visual_cortex.html">189 nips-2006-Temporal dynamics of information content carried by neurons in the primary visual cortex</a></p>
<p>10 0.30127832 <a title="15-lsi-10" href="./nips-2006-Statistical_Modeling_of_Images_with_Fields_of_Gaussian_Scale_Mixtures.html">182 nips-2006-Statistical Modeling of Images with Fields of Gaussian Scale Mixtures</a></p>
<p>11 0.28860411 <a title="15-lsi-11" href="./nips-2006-Stochastic_Relational_Models_for_Discriminative_Link_Prediction.html">183 nips-2006-Stochastic Relational Models for Discriminative Link Prediction</a></p>
<p>12 0.28739798 <a title="15-lsi-12" href="./nips-2006-Learning_Structural_Equation_Models_for_fMRI.html">113 nips-2006-Learning Structural Equation Models for fMRI</a></p>
<p>13 0.28275558 <a title="15-lsi-13" href="./nips-2006-Learning_to_parse_images_of_articulated_bodies.html">122 nips-2006-Learning to parse images of articulated bodies</a></p>
<p>14 0.27856553 <a title="15-lsi-14" href="./nips-2006-Learning_to_Model_Spatial_Dependency%3A_Semi-Supervised_Discriminative_Random_Fields.html">118 nips-2006-Learning to Model Spatial Dependency: Semi-Supervised Discriminative Random Fields</a></p>
<p>15 0.27709541 <a title="15-lsi-15" href="./nips-2006-Data_Integration_for_Classification_Problems_Employing_Gaussian_Process_Priors.html">64 nips-2006-Data Integration for Classification Problems Employing Gaussian Process Priors</a></p>
<p>16 0.27349848 <a title="15-lsi-16" href="./nips-2006-Linearly-solvable_Markov_decision_problems.html">124 nips-2006-Linearly-solvable Markov decision problems</a></p>
<p>17 0.27181125 <a title="15-lsi-17" href="./nips-2006-Efficient_Methods_for_Privacy_Preserving_Face_Detection.html">73 nips-2006-Efficient Methods for Privacy Preserving Face Detection</a></p>
<p>18 0.26407763 <a title="15-lsi-18" href="./nips-2006-Bayesian_Image_Super-resolution%2C_Continued.html">42 nips-2006-Bayesian Image Super-resolution, Continued</a></p>
<p>19 0.26333123 <a title="15-lsi-19" href="./nips-2006-Active_learning_for_misspecified_generalized_linear_models.html">20 nips-2006-Active learning for misspecified generalized linear models</a></p>
<p>20 0.25513411 <a title="15-lsi-20" href="./nips-2006-Relational_Learning_with_Gaussian_Processes.html">169 nips-2006-Relational Learning with Gaussian Processes</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2006_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(1, 0.112), (3, 0.056), (7, 0.07), (9, 0.036), (20, 0.013), (22, 0.03), (44, 0.059), (48, 0.296), (57, 0.102), (65, 0.038), (69, 0.06), (71, 0.028), (90, 0.017)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.79575706 <a title="15-lda-1" href="./nips-2006-A_Switched_Gaussian_Process_for_Estimating_Disparity_and_Segmentation_in_Binocular_Stereo.html">15 nips-2006-A Switched Gaussian Process for Estimating Disparity and Segmentation in Binocular Stereo</a></p>
<p>Author: Oliver Williams</p><p>Abstract: This paper describes a Gaussian process framework for inferring pixel-wise disparity and bi-layer segmentation of a scene given a stereo pair of images. The Gaussian process covariance is parameterized by a foreground-backgroundocclusion segmentation label to model both smooth regions and discontinuities. As such, we call our model a switched Gaussian process. We propose a greedy incremental algorithm for adding observations from the data and assigning segmentation labels. Two observation schedules are proposed: the ﬁrst treats scanlines as independent, the second uses an active learning criterion to select a sparse subset of points to measure. We show that this probabilistic framework has comparable performance to the state-of-the-art. 1</p><p>2 0.7038343 <a title="15-lda-2" href="./nips-2006-Learning_to_Model_Spatial_Dependency%3A_Semi-Supervised_Discriminative_Random_Fields.html">118 nips-2006-Learning to Model Spatial Dependency: Semi-Supervised Discriminative Random Fields</a></p>
<p>Author: Chi-hoon Lee, Shaojun Wang, Feng Jiao, Dale Schuurmans, Russell Greiner</p><p>Abstract: We present a novel, semi-supervised approach to training discriminative random ﬁelds (DRFs) that efﬁciently exploits labeled and unlabeled training data to achieve improved accuracy in a variety of image processing tasks. We formulate DRF training as a form of MAP estimation that combines conditional loglikelihood on labeled data, given a data-dependent prior, with a conditional entropy regularizer deﬁned on unlabeled data. Although the training objective is no longer concave, we develop an efﬁcient local optimization procedure that produces classiﬁers that are more accurate than ones based on standard supervised DRF training. We then apply our semi-supervised approach to train DRFs to segment both synthetic and real data sets, and demonstrate signiﬁcant improvements over supervised DRFs in each case.</p><p>3 0.55020159 <a title="15-lda-3" href="./nips-2006-A_Nonparametric_Approach_to_Bottom-Up_Visual_Saliency.html">8 nips-2006-A Nonparametric Approach to Bottom-Up Visual Saliency</a></p>
<p>Author: Wolf Kienzle, Felix A. Wichmann, Matthias O. Franz, Bernhard Schölkopf</p><p>Abstract: This paper addresses the bottom-up inﬂuence of local image information on human eye movements. Most existing computational models use a set of biologically plausible linear ﬁlters, e.g., Gabor or Difference-of-Gaussians ﬁlters as a front-end, the outputs of which are nonlinearly combined into a real number that indicates visual saliency. Unfortunately, this requires many design parameters such as the number, type, and size of the front-end ﬁlters, as well as the choice of nonlinearities, weighting and normalization schemes etc., for which biological plausibility cannot always be justiﬁed. As a result, these parameters have to be chosen in a more or less ad hoc way. Here, we propose to learn a visual saliency model directly from human eye movement data. The model is rather simplistic and essentially parameter-free, and therefore contrasts recent developments in the ﬁeld that usually aim at higher prediction rates at the cost of additional parameters and increasing model complexity. Experimental results show that—despite the lack of any biological prior knowledge—our model performs comparably to existing approaches, and in fact learns image features that resemble ﬁndings from several previous studies. In particular, its maximally excitatory stimuli have center-surround structure, similar to receptive ﬁelds in the early human visual system. 1</p><p>4 0.54453415 <a title="15-lda-4" href="./nips-2006-Approximate_Correspondences_in_High_Dimensions.html">34 nips-2006-Approximate Correspondences in High Dimensions</a></p>
<p>Author: Kristen Grauman, Trevor Darrell</p><p>Abstract: Pyramid intersection is an efﬁcient method for computing an approximate partial matching between two sets of feature vectors. We introduce a novel pyramid embedding based on a hierarchy of non-uniformly shaped bins that takes advantage of the underlying structure of the feature space and remains accurate even for sets with high-dimensional feature vectors. The matching similarity is computed in linear time and forms a Mercer kernel. Whereas previous matching approximation algorithms suffer from distortion factors that increase linearly with the feature dimension, we demonstrate that our approach can maintain constant accuracy even as the feature dimension increases. When used as a kernel in a discriminative classiﬁer, our approach achieves improved object recognition results over a state-of-the-art set kernel. 1</p><p>5 0.54203492 <a title="15-lda-5" href="./nips-2006-Recursive_ICA.html">167 nips-2006-Recursive ICA</a></p>
<p>Author: Honghao Shan, Lingyun Zhang, Garrison W. Cottrell</p><p>Abstract: Independent Component Analysis (ICA) is a popular method for extracting independent features from visual data. However, as a fundamentally linear technique, there is always nonlinear residual redundancy that is not captured by ICA. Hence there have been many attempts to try to create a hierarchical version of ICA, but so far none of the approaches have a natural way to apply them more than once. Here we show that there is a relatively simple technique that transforms the absolute values of the outputs of a previous application of ICA into a normal distribution, to which ICA maybe applied again. This results in a recursive ICA algorithm that may be applied any number of times in order to extract higher order structure from previous layers. 1</p><p>6 0.54084563 <a title="15-lda-6" href="./nips-2006-Part-based_Probabilistic_Point_Matching_using_Equivalence_Constraints.html">160 nips-2006-Part-based Probabilistic Point Matching using Equivalence Constraints</a></p>
<p>7 0.53362495 <a title="15-lda-7" href="./nips-2006-Analysis_of_Empirical_Bayesian_Methods_for_Neuroelectromagnetic_Source_Localization.html">32 nips-2006-Analysis of Empirical Bayesian Methods for Neuroelectromagnetic Source Localization</a></p>
<p>8 0.53166425 <a title="15-lda-8" href="./nips-2006-Bayesian_Image_Super-resolution%2C_Continued.html">42 nips-2006-Bayesian Image Super-resolution, Continued</a></p>
<p>9 0.53151566 <a title="15-lda-9" href="./nips-2006-Learning_Dense_3D_Correspondence.html">110 nips-2006-Learning Dense 3D Correspondence</a></p>
<p>10 0.53139931 <a title="15-lda-10" href="./nips-2006-Learning_to_Rank_with_Nonsmooth_Cost_Functions.html">119 nips-2006-Learning to Rank with Nonsmooth Cost Functions</a></p>
<p>11 0.53110731 <a title="15-lda-11" href="./nips-2006-Efficient_Learning_of_Sparse_Representations_with_an_Energy-Based_Model.html">72 nips-2006-Efficient Learning of Sparse Representations with an Energy-Based Model</a></p>
<p>12 0.52987027 <a title="15-lda-12" href="./nips-2006-Large_Margin_Hidden_Markov_Models_for_Automatic_Speech_Recognition.html">106 nips-2006-Large Margin Hidden Markov Models for Automatic Speech Recognition</a></p>
<p>13 0.52983767 <a title="15-lda-13" href="./nips-2006-A_Complexity-Distortion_Approach_to_Joint_Pattern_Alignment.html">3 nips-2006-A Complexity-Distortion Approach to Joint Pattern Alignment</a></p>
<p>14 0.52967352 <a title="15-lda-14" href="./nips-2006-Learning_Nonparametric_Models_for_Probabilistic_Imitation.html">112 nips-2006-Learning Nonparametric Models for Probabilistic Imitation</a></p>
<p>15 0.52931762 <a title="15-lda-15" href="./nips-2006-Clustering_Under_Prior_Knowledge_with_Application_to_Image_Segmentation.html">51 nips-2006-Clustering Under Prior Knowledge with Application to Image Segmentation</a></p>
<p>16 0.52602762 <a title="15-lda-16" href="./nips-2006-Stratification_Learning%3A_Detecting_Mixed_Density_and_Dimensionality_in_High_Dimensional_Point_Clouds.html">184 nips-2006-Stratification Learning: Detecting Mixed Density and Dimensionality in High Dimensional Point Clouds</a></p>
<p>17 0.52551085 <a title="15-lda-17" href="./nips-2006-Simplifying_Mixture_Models_through_Function_Approximation.html">175 nips-2006-Simplifying Mixture Models through Function Approximation</a></p>
<p>18 0.52526498 <a title="15-lda-18" href="./nips-2006-Bayesian_Model_Scoring_in_Markov_Random_Fields.html">43 nips-2006-Bayesian Model Scoring in Markov Random Fields</a></p>
<p>19 0.52519834 <a title="15-lda-19" href="./nips-2006-Graph_Laplacian_Regularization_for_Large-Scale_Semidefinite_Programming.html">87 nips-2006-Graph Laplacian Regularization for Large-Scale Semidefinite Programming</a></p>
<p>20 0.52516025 <a title="15-lda-20" href="./nips-2006-Denoising_and_Dimension_Reduction_in_Feature_Space.html">65 nips-2006-Denoising and Dimension Reduction in Feature Space</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
