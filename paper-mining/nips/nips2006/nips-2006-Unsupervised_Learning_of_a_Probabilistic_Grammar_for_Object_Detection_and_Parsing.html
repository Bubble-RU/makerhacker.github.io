<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>199 nips-2006-Unsupervised Learning of a Probabilistic Grammar for Object Detection and Parsing</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-199" href="#">nips2006-199</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>199 nips-2006-Unsupervised Learning of a Probabilistic Grammar for Object Detection and Parsing</h1>
<br/><p>Source: <a title="nips-2006-199-pdf" href="http://papers.nips.cc/paper/3021-unsupervised-learning-of-a-probabilistic-grammar-for-object-detection-and-parsing.pdf">pdf</a></p><p>Author: Yuanhao Chen, Long Zhu, Alan L. Yuille</p><p>Abstract: We describe an unsupervised method for learning a probabilistic grammar of an object from a set of training examples. Our approach is invariant to the scale and rotation of the objects. We illustrate our approach using thirteen objects from the Caltech 101 database. In addition, we learn the model of a hybrid object class where we do not know the speciﬁc object or its position, scale or pose. This is illustrated by learning a hybrid class consisting of faces, motorbikes, and airplanes. The individual objects can be recovered as different aspects of the grammar for the object class. In all cases, we validate our results by learning the probability grammars from training datasets and evaluating them on the test datasets. We compare our method to alternative approaches. The advantages of our approach is the speed of inference (under one second), the parsing of the object, and increased accuracy of performance. Moreover, our approach is very general and can be applied to a large range of objects and structures. 1</p><p>Reference: <a title="nips-2006-199-reference" href="../nips2006_reference/nips-2006-Unsupervised_Learning_of_a_Probabilistic_Grammar_for_Object_Detection_and_Parsing_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract We describe an unsupervised method for learning a probabilistic grammar of an object from a set of training examples. [sent-8, score-0.509]
</p><p>2 Our approach is invariant to the scale and rotation of the objects. [sent-9, score-0.342]
</p><p>3 We illustrate our approach using thirteen objects from the Caltech 101 database. [sent-10, score-0.145]
</p><p>4 In addition, we learn the model of a hybrid object class where we do not know the speciﬁc object or its position, scale or pose. [sent-11, score-0.589]
</p><p>5 This is illustrated by learning a hybrid class consisting of faces, motorbikes, and airplanes. [sent-12, score-0.226]
</p><p>6 The individual objects can be recovered as different aspects of the grammar for the object class. [sent-13, score-0.41]
</p><p>7 In all cases, we validate our results by learning the probability grammars from training datasets and evaluating them on the test datasets. [sent-14, score-0.211]
</p><p>8 The advantages of our approach is the speed of inference (under one second), the parsing of the object, and increased accuracy of performance. [sent-16, score-0.167]
</p><p>9 In particular, there are exciting new probability models [1, 3, 4, 5, 6, 11] deﬁned on structured relational systems such as graphs or grammars. [sent-19, score-0.217]
</p><p>10 In particular, we need efﬁcient algorithms to learn the models from training data and to perform inference on new examples. [sent-22, score-0.237]
</p><p>11 In this paper we develop an algorithm called “structure induction” (or “structure pursuit”) which we use to learn the probability model in an unsupervised manner from a set of training data. [sent-24, score-0.235]
</p><p>12 The form of the resulting graph structure ensures that inference can be performed rapidly for new data. [sent-26, score-0.242]
</p><p>13 6%  Figure 1: We have learnt probability grammars for these ten objects in the Caltech 101 database, obtaining scores over 90 % for most objects. [sent-37, score-0.372]
</p><p>14 Our application is to the detection, recognition, and parsing of objects in images. [sent-41, score-0.193]
</p><p>15 The training data consists of a set of images where the target object is present but at an unknown location. [sent-42, score-0.148]
</p><p>16 Firstly, a wide range of applicability which we demonstrate by learning models for 13 object categories from the Caltech-101 [16], Figure (1,5). [sent-45, score-0.179]
</p><p>17 Secondly, the approach is invariant to rotation and a large range of scale of the objects. [sent-46, score-0.342]
</p><p>18 Thirdly, the approach is able to deal with object classes, which we illustrate by learning a hybrid class consisting of faces, motorbikes and airplane. [sent-47, score-0.437]
</p><p>19 1  Background Representation, Inference and Learning  Structured models deﬁne a probability distribution on structured relational systems such as graphs or grammars. [sent-50, score-0.217]
</p><p>20 This includes many standard models of probability distributions deﬁned on graphs – for example, graphs with ﬁxed structure, such as MRF’s [2] or Conditional Random Fields [3], or Probabilistic Context Free Grammars (PCFG’s) [4] where the structure is variable. [sent-51, score-0.265]
</p><p>21 In this paper, we will be concerned with models that combine probabilistic grammars with MRF’s. [sent-54, score-0.348]
</p><p>22 The grammars are based on AND-OR graphs [1, 5, 6], which relate to mixtures of trees [7]. [sent-55, score-0.233]
</p><p>23 This merging of MRF’s with probabilistic grammars results in structured models which have great representational power. [sent-56, score-0.45]
</p><p>24 There has been considerable interest in inference algorithms for these structured models, for example McAllester et al [1] describe how dynamic programming algorithms (e. [sent-57, score-0.241]
</p><p>25 Our paper is concerned with the task of unsupervised learning of structured models for applications to detecting, recognizing, and representing visual objects. [sent-60, score-0.274]
</p><p>26 For MRF models, the number of graph nodes is ﬁxed and structure induction consists of determining the connections between the nodes and the forms of the corresponding potentials. [sent-63, score-0.285]
</p><p>27 For these graphs, an effective strategy is feature induction [8] which is also known as feature pursuit [9]. [sent-64, score-0.334]
</p><p>28 Learning the structure of grammars in an unsupervised way is more difﬁcult. [sent-68, score-0.338]
</p><p>29 Klein and Manning [4] have developed unsupervised learning of PCFG’s for parsing natural language, but here the structure of grammar is speciﬁed. [sent-69, score-0.474]
</p><p>30 In short, to our knowledge, there is no unsupervised learning algorithm for structure induction for a Probabilistic Grammar-MRF model. [sent-71, score-0.32]
</p><p>31 Moreover, our vision application requires the ability to learn the model of the target object in the presence of unknown background structure. [sent-72, score-0.353]
</p><p>32 The leaf nodes of the graph will be image features that are described by MRF’s. [sent-77, score-0.174]
</p><p>33 Instead of using the full PCFG, we restrict the grammar to containing one OR-node. [sent-78, score-0.208]
</p><p>34 The simplest type of child node is a histogram model (far left panel of ﬁgure (2)). [sent-82, score-0.156]
</p><p>35 We can obtain more complex models by adding MRF models in the form of triples, see ﬁgure (2) left to right. [sent-83, score-0.134]
</p><p>36 Combination of triples can be expressed in a junction tree representation, see the sixth and seventh panels of ﬁgure (2). [sent-84, score-0.354]
</p><p>37 In more abstract terms, we deﬁne a set of rules R(x, y) for allowable parses of input x to a parse tree y. [sent-87, score-0.152]
</p><p>38 These rules have potentials φ(x, r, t) for a production rule r ∈ R(x, y) and ψ(x, wM , t) for the MRF models (see details in the technical report), where t are nuisance parameters (e. [sent-88, score-0.138]
</p><p>39 The wG are the grammar parameters and the wM are the MRF parameters. [sent-91, score-0.208]
</p><p>40 The structure of the model is determined by the / set W . [sent-93, score-0.13]
</p><p>41 We now face three tasks: (I) structure learning, (II) parameter learning to estimate w, and (III) inference to estimate y. [sent-96, score-0.186]
</p><p>42 For each structure we deﬁne a score given by its ﬁt to the data. [sent-107, score-0.23]
</p><p>43 We refer to the model ﬁts, P (x|w ∈ W ) and P (x|w ∈ W ), as the scores for structure W and W respectively. [sent-112, score-0.13]
</p><p>44 , N (τ )}, where N (τ ) is the number of features in image τ . [sent-120, score-0.128]
</p><p>45 Each feature is represented by a pair xi = (zi , Ai ), where zi is the location of the feature in the image and Ai is an appearance vector. [sent-121, score-0.24]
</p><p>46 The image features are detected by the Kadir-Brady operator [13], and their appearance is calculated by the SIFT operator [14]. [sent-122, score-0.216]
</p><p>47 These operators ensure that the features are invariant to scale, rotation, and some appearance variations. [sent-123, score-0.23]
</p><p>48 The default background model for the image is to deﬁne a histogram model over the positions and appearance of the image features, see ﬁrst panel of ﬁgure (2). [sent-124, score-0.42]
</p><p>49 Next we use triples of image features as the basic building blocks to construct a model. [sent-125, score-0.292]
</p><p>50 Our model will be constructed by adding new triplets to the existing model, as shown in the ﬁrst few panels of ﬁgure (2). [sent-126, score-0.387]
</p><p>51 Each triplet will be represented by a triplet model which is given by Gaussian distributions on spatial position and on appearance P (x|M = 1, T) = G(z|T(µG , ΣG )G(A|µA , ΣA ), where µG , µA , ΣG , ΣA are the means and covariances of the positions and appearances. [sent-127, score-0.815]
</p><p>52 The {Mi } are missing data index variables [15], and T denotes transformations due to rotation and scaling. [sent-128, score-0.232]
</p><p>53 The major advantage of using triplets is that they have geometrical properties which are independent of the scale and rotation of the triplet. [sent-129, score-0.524]
</p><p>54 Thus we can decompose the representation of the triplet into two types of properties: (i) those which are independent of scale and rotation, (ii) those that depend explicitly on scale and rotation. [sent-131, score-0.439]
</p><p>55 By using the invariant properties, we can perform rapid search over triplets when position, scale, and rotation are unknown. [sent-132, score-0.568]
</p><p>56 In addition, two triplets can be easily combined by a common edge to form a more complex model – see sixth panel of ﬁgure (2). [sent-133, score-0.322]
</p><p>57 This representation is suitable for the junction tree algorithm [2], which enables rapid inference. [sent-134, score-0.133]
</p><p>58 For structure learning, we face the task of how to expand the set W of non-zero parameters to a new set W . [sent-135, score-0.211]
</p><p>59 This gives rise to a triplet vocabulary consisting of triplets that frequently occur in the dataset. [sent-141, score-0.647]
</p><p>60 These are used to make proposals for which triplets to include in the model, and hence for how to expand the set W of non-zero parameters. [sent-142, score-0.374]
</p><p>61 Initialize G to be the root node with the background model, and let G∗ = G. [sent-146, score-0.175]
</p><p>62 2  Structure Induction: Learning the Probabilistic Grammar MRF  We now have the necessary background to describe our structure induction algorithm. [sent-151, score-0.327]
</p><p>63 2), this is equivalent to setting all of the model parameters w to be zero (except those for the background model). [sent-156, score-0.136]
</p><p>64 We can estimate the parameters of this model and score the model as described in section (2. [sent-157, score-0.244]
</p><p>65 Next we seek to expand the structure of this model. [sent-159, score-0.171]
</p><p>66 To do this, we use the triplet vocabularies to make proposals. [sent-160, score-0.373]
</p><p>67 Since the current model is the background model, the only structure change allowed is to add a triplet model as one child of the root node (i. [sent-161, score-0.741]
</p><p>68 to create the background plus triple model described in the previous section, see ﬁgure (2)). [sent-163, score-0.186]
</p><p>69 We consider all members of the triplet vocabulary as candidates, using their cluster means and covariances as prior probabilities on their geometry and attribute properties. [sent-164, score-0.448]
</p><p>70 Then, for all these triples we construct the background plus triplet model, estimate their parameters and score them. [sent-165, score-0.683]
</p><p>71 We accept the one with highest score as the new structure. [sent-166, score-0.148]
</p><p>72 As the graph structure grows, we now have more ways to expand the graph. [sent-167, score-0.217]
</p><p>73 We can add a new triplet as a child of the root node. [sent-168, score-0.432]
</p><p>74 Then we use the triplet vocabulary to propose possible triplets, which partially overlap with the current model (and give them prior probabilities on their parameters as before). [sent-172, score-0.463]
</p><p>75 We select the one with highest score as the new graph model. [sent-175, score-0.194]
</p><p>76 If the score increase is not sufﬁcient, we cease building the graph model. [sent-176, score-0.234]
</p><p>77 2 – –  Experimental Results Learning Individual Objects Models  In this section, we demonstrate the performance of our models for thirteen objects chosen from the Caltech-101 dataset. [sent-200, score-0.212]
</p><p>78 K-means clustering (typically, K is set to 150) was used to learn the triplet vocabularies (see Zhu, Chen, Yuille 2006 for details). [sent-202, score-0.443]
</p><p>79 A score of 90 % means that we get a true positive rate of 90 % and a false positive rate of 10 %. [sent-206, score-0.148]
</p><p>80 The models for individual objects classes, learnt from the proposed algorithm, are illustrated in ﬁgure (5). [sent-209, score-0.301]
</p><p>81 less than one second (including the processing of features and inference) for the image with the size of 320*240. [sent-215, score-0.128]
</p><p>82 2  Invariance to Rotation and Scale  This section shows that we can learn and detect objects even when the rotation (in the image) and the scale are unknown (within a range). [sent-218, score-0.414]
</p><p>83 In this experiment, orientation information, output from feature detector, is used to model the geometry distributions of the triplets. [sent-219, score-0.156]
</p><p>84 The relative angle between the orientation of each feature and the orientation of the edge of tri-angle is calculated to make the model invariant to rotation. [sent-220, score-0.313]
</p><p>85 A face model is learnt from the training images with normalized scale and orientation. [sent-223, score-0.289]
</p><p>86 We tested this model on the testing data with 360degree in-plane rotation and another testing data with rotation and scaling together. [sent-224, score-0.44]
</p><p>87 The parsing results (rotation+scale) are illustrated in Figure (6). [sent-229, score-0.14]
</p><p>88 3  Learning Classes of Models  In this section, we show that we can learn a model for an object class. [sent-231, score-0.23]
</p><p>89 We use a hybrid class which consists of faces, airplanes, and motorbikes. [sent-232, score-0.189]
</p><p>90 In other words, we know that one object is present in each image but we do not know which. [sent-233, score-0.186]
</p><p>91 Similarly, we test the hybrid model on examples selected randomly from these three datasets. [sent-235, score-0.237]
</p><p>92 The learnt hybrid model is illustrated in Figure (7). [sent-236, score-0.381]
</p><p>93 Table (1) shows the performance for the hybrid model. [sent-238, score-0.189]
</p><p>94 5  Discussion  This paper showed that it is possible to perform unsupervised learning to determine a probabilistic grammar combined with a Markov Random Fields. [sent-241, score-0.361]
</p><p>95 Our approach is based on structure pursuit where the object model is built up in an iterative manner (similar to feature pursuit used for MRF’s and CRF’s). [sent-242, score-0.479]
</p><p>96 The building blocks of our model are triplets of features, whose invariance properties can be exploited for rapid computation. [sent-243, score-0.418]
</p><p>97 Our application is to the detection and parsing of objects. [sent-244, score-0.152]
</p><p>98 We demonstrated: (a) that we can learn probabilistic models for a variety of different objects, (b) that our approach is invariant to scale and  Figure 8: Parsed Results by Hybrid Model (left three panels). [sent-245, score-0.355]
</p><p>99 rotation, (c) that we can learn models for hybrid classes, and (d) that we can perform inference rapidly in under one second. [sent-247, score-0.44]
</p><p>100 By using a richer vocabulary of features we can learn a more sophisticated generative grammar which will be able to represent objects in greater detail and deal with signiﬁcant variations in viewpoint and appearance. [sent-249, score-0.514]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('triplet', 0.323), ('mrf', 0.305), ('triplets', 0.232), ('grammar', 0.208), ('rotation', 0.196), ('hybrid', 0.189), ('grammars', 0.175), ('induction', 0.157), ('score', 0.148), ('pcfg', 0.136), ('motorbikes', 0.136), ('faces', 0.129), ('triples', 0.124), ('yuille', 0.124), ('object', 0.112), ('parsed', 0.109), ('gure', 0.108), ('panels', 0.107), ('learnt', 0.107), ('parsing', 0.103), ('pursuit', 0.099), ('airplanes', 0.094), ('wg', 0.094), ('angeles', 0.093), ('vocabulary', 0.092), ('structured', 0.092), ('objects', 0.09), ('expand', 0.089), ('invariant', 0.088), ('appearance', 0.088), ('background', 0.088), ('los', 0.087), ('structure', 0.082), ('unsupervised', 0.081), ('chen', 0.077), ('parse', 0.076), ('image', 0.074), ('probabilistic', 0.072), ('learn', 0.07), ('em', 0.07), ('orientation', 0.069), ('zhu', 0.068), ('models', 0.067), ('rf', 0.066), ('saddle', 0.066), ('mcallester', 0.066), ('child', 0.065), ('inference', 0.064), ('uai', 0.063), ('zettlemoyer', 0.063), ('crf', 0.06), ('scale', 0.058), ('graphs', 0.058), ('wm', 0.055), ('diagrams', 0.055), ('thirteen', 0.055), ('manning', 0.055), ('features', 0.054), ('proposals', 0.053), ('rapid', 0.052), ('rapidly', 0.05), ('vocabularies', 0.05), ('triple', 0.05), ('constellation', 0.05), ('pietra', 0.05), ('detection', 0.049), ('model', 0.048), ('programming', 0.046), ('ta', 0.046), ('della', 0.046), ('caltech', 0.046), ('klein', 0.046), ('invariance', 0.046), ('graph', 0.046), ('root', 0.044), ('fields', 0.044), ('representational', 0.044), ('chair', 0.044), ('node', 0.043), ('tree', 0.043), ('sixth', 0.042), ('inducing', 0.042), ('rotated', 0.042), ('face', 0.04), ('building', 0.04), ('subtree', 0.04), ('dynamic', 0.039), ('feature', 0.039), ('nuisance', 0.038), ('geometrical', 0.038), ('junction', 0.038), ('collins', 0.038), ('illustrated', 0.037), ('missing', 0.036), ('training', 0.036), ('vision', 0.035), ('concerned', 0.034), ('covariances', 0.033), ('intelligence', 0.033), ('rules', 0.033)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999911 <a title="199-tfidf-1" href="./nips-2006-Unsupervised_Learning_of_a_Probabilistic_Grammar_for_Object_Detection_and_Parsing.html">199 nips-2006-Unsupervised Learning of a Probabilistic Grammar for Object Detection and Parsing</a></p>
<p>Author: Yuanhao Chen, Long Zhu, Alan L. Yuille</p><p>Abstract: We describe an unsupervised method for learning a probabilistic grammar of an object from a set of training examples. Our approach is invariant to the scale and rotation of the objects. We illustrate our approach using thirteen objects from the Caltech 101 database. In addition, we learn the model of a hybrid object class where we do not know the speciﬁc object or its position, scale or pose. This is illustrated by learning a hybrid class consisting of faces, motorbikes, and airplanes. The individual objects can be recovered as different aspects of the grammar for the object class. In all cases, we validate our results by learning the probability grammars from training datasets and evaluating them on the test datasets. We compare our method to alternative approaches. The advantages of our approach is the speed of inference (under one second), the parsing of the object, and increased accuracy of performance. Moreover, our approach is very general and can be applied to a large range of objects and structures. 1</p><p>2 0.15577833 <a title="199-tfidf-2" href="./nips-2006-Image_Retrieval_and_Classification_Using_Local_Distance_Functions.html">94 nips-2006-Image Retrieval and Classification Using Local Distance Functions</a></p>
<p>Author: Andrea Frome, Yoram Singer, Jitendra Malik</p><p>Abstract: In this paper we introduce and experiment with a framework for learning local perceptual distance functions for visual recognition. We learn a distance function for each training image as a combination of elementary distances between patch-based visual features. We apply these combined local distance functions to the tasks of image retrieval and classiﬁcation of novel images. On the Caltech 101 object recognition benchmark, we achieve 60.3% mean recognition across classes using 15 training images per class, which is better than the best published performance by Zhang, et al. 1</p><p>3 0.15024295 <a title="199-tfidf-3" href="./nips-2006-Efficient_Structure_Learning_of_Markov_Networks_using_%24L_1%24-Regularization.html">74 nips-2006-Efficient Structure Learning of Markov Networks using $L 1$-Regularization</a></p>
<p>Author: Su-in Lee, Varun Ganapathi, Daphne Koller</p><p>Abstract: Markov networks are commonly used in a wide variety of applications, ranging from computer vision, to natural language, to computational biology. In most current applications, even those that rely heavily on learned models, the structure of the Markov network is constructed by hand, due to the lack of effective algorithms for learning Markov network structure from data. In this paper, we provide a computationally efﬁcient method for learning Markov network structure from data. Our method is based on the use of L1 regularization on the weights of the log-linear model, which has the effect of biasing the model towards solutions where many of the parameters are zero. This formulation converts the Markov network learning problem into a convex optimization problem in a continuous space, which can be solved using efﬁcient gradient methods. A key issue in this setting is the (unavoidable) use of approximate inference, which can lead to errors in the gradient computation when the network structure is dense. Thus, we explore the use of different feature introduction schemes and compare their performance. We provide results for our method on synthetic data, and on two real world data sets: pixel values in the MNIST data, and genetic sequence variations in the human HapMap data. We show that our L1 -based method achieves considerably higher generalization performance than the more standard L2 -based method (a Gaussian parameter prior) or pure maximum-likelihood learning. We also show that we can learn MRF network structure at a computational cost that is not much greater than learning parameters alone, demonstrating the existence of a feasible method for this important problem.</p><p>4 0.13243139 <a title="199-tfidf-4" href="./nips-2006-Subordinate_class_recognition_using_relational_object_models.html">185 nips-2006-Subordinate class recognition using relational object models</a></p>
<p>Author: Aharon B. Hillel, Daphna Weinshall</p><p>Abstract: We address the problem of sub-ordinate class recognition, like the distinction between different types of motorcycles. Our approach is motivated by observations from cognitive psychology, which identify parts as the deﬁning component of basic level categories (like motorcycles), while sub-ordinate categories are more often deﬁned by part properties (like ’jagged wheels’). Accordingly, we suggest a two-stage algorithm: First, a relational part based object model is learnt using unsegmented object images from the inclusive class (e.g., motorcycles in general). The model is then used to build a class-speciﬁc vector representation for images, where each entry corresponds to a model’s part. In the second stage we train a standard discriminative classiﬁer to classify subclass instances (e.g., cross motorcycles) based on the class-speciﬁc vector representation. We describe extensive experimental results with several subclasses. The proposed algorithm typically gives better results than a competing one-step algorithm, or a two stage algorithm where classiﬁcation is based on a model of the sub-ordinate class. 1</p><p>5 0.11501876 <a title="199-tfidf-5" href="./nips-2006-Learning_to_parse_images_of_articulated_bodies.html">122 nips-2006-Learning to parse images of articulated bodies</a></p>
<p>Author: Deva Ramanan</p><p>Abstract: We consider the machine vision task of pose estimation from static images, specifically for the case of articulated objects. This problem is hard because of the large number of degrees of freedom to be estimated. Following a established line of research, pose estimation is framed as inference in a probabilistic model. In our experience however, the success of many approaches often lie in the power of the features. Our primary contribution is a novel casting of visual inference as an iterative parsing process, where one sequentially learns better and better features tuned to a particular image. We show quantitative results for human pose estimation on a database of over 300 images that suggest our algorithm is competitive with or surpasses the state-of-the-art. Since our procedure is quite general (it does not rely on face or skin detection), we also use it to estimate the poses of horses in the Weizmann database. 1</p><p>6 0.11451565 <a title="199-tfidf-6" href="./nips-2006-Adaptor_Grammars%3A_A_Framework_for_Specifying_Compositional_Nonparametric_Bayesian_Models.html">23 nips-2006-Adaptor Grammars: A Framework for Specifying Compositional Nonparametric Bayesian Models</a></p>
<p>7 0.11377425 <a title="199-tfidf-7" href="./nips-2006-Approximate_inference_using_planar_graph_decomposition.html">35 nips-2006-Approximate inference using planar graph decomposition</a></p>
<p>8 0.11149643 <a title="199-tfidf-8" href="./nips-2006-Fast_Discriminative_Visual_Codebooks_using_Randomized_Clustering_Forests.html">78 nips-2006-Fast Discriminative Visual Codebooks using Randomized Clustering Forests</a></p>
<p>9 0.11130415 <a title="199-tfidf-9" href="./nips-2006-Scalable_Discriminative_Learning_for_Natural_Language_Parsing_and_Translation.html">172 nips-2006-Scalable Discriminative Learning for Natural Language Parsing and Translation</a></p>
<p>10 0.11071312 <a title="199-tfidf-10" href="./nips-2006-Using_Combinatorial_Optimization_within_Max-Product_Belief_Propagation.html">201 nips-2006-Using Combinatorial Optimization within Max-Product Belief Propagation</a></p>
<p>11 0.10101794 <a title="199-tfidf-11" href="./nips-2006-Detecting_Humans_via_Their_Pose.html">66 nips-2006-Detecting Humans via Their Pose</a></p>
<p>12 0.090627238 <a title="199-tfidf-12" href="./nips-2006-Learning_annotated_hierarchies_from_relational_data.html">115 nips-2006-Learning annotated hierarchies from relational data</a></p>
<p>13 0.087950848 <a title="199-tfidf-13" href="./nips-2006-Learning_Dense_3D_Correspondence.html">110 nips-2006-Learning Dense 3D Correspondence</a></p>
<p>14 0.077840939 <a title="199-tfidf-14" href="./nips-2006-Chained_Boosting.html">50 nips-2006-Chained Boosting</a></p>
<p>15 0.07541883 <a title="199-tfidf-15" href="./nips-2006-The_Neurodynamics_of_Belief_Propagation_on_Binary_Markov_Random_Fields.html">190 nips-2006-The Neurodynamics of Belief Propagation on Binary Markov Random Fields</a></p>
<p>16 0.073936969 <a title="199-tfidf-16" href="./nips-2006-Distributed_Inference_in_Dynamical_Systems.html">69 nips-2006-Distributed Inference in Dynamical Systems</a></p>
<p>17 0.068002813 <a title="199-tfidf-17" href="./nips-2006-Clustering_Under_Prior_Knowledge_with_Application_to_Image_Segmentation.html">51 nips-2006-Clustering Under Prior Knowledge with Application to Image Segmentation</a></p>
<p>18 0.067892753 <a title="199-tfidf-18" href="./nips-2006-A_Nonparametric_Approach_to_Bottom-Up_Visual_Saliency.html">8 nips-2006-A Nonparametric Approach to Bottom-Up Visual Saliency</a></p>
<p>19 0.067439094 <a title="199-tfidf-19" href="./nips-2006-Max-margin_classification_of_incomplete_data.html">130 nips-2006-Max-margin classification of incomplete data</a></p>
<p>20 0.066784479 <a title="199-tfidf-20" href="./nips-2006-Training_Conditional_Random_Fields_for_Maximum_Labelwise_Accuracy.html">195 nips-2006-Training Conditional Random Fields for Maximum Labelwise Accuracy</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2006_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.225), (1, 0.037), (2, 0.151), (3, -0.11), (4, 0.124), (5, -0.029), (6, -0.081), (7, -0.068), (8, -0.019), (9, -0.227), (10, 0.036), (11, 0.01), (12, -0.026), (13, 0.076), (14, 0.092), (15, -0.016), (16, -0.025), (17, 0.073), (18, 0.095), (19, 0.098), (20, -0.004), (21, 0.074), (22, -0.01), (23, -0.012), (24, 0.024), (25, -0.006), (26, 0.058), (27, -0.053), (28, -0.02), (29, -0.083), (30, -0.004), (31, 0.017), (32, -0.066), (33, -0.002), (34, 0.025), (35, -0.066), (36, -0.105), (37, -0.145), (38, 0.12), (39, 0.046), (40, -0.045), (41, 0.146), (42, -0.024), (43, 0.009), (44, 0.072), (45, -0.045), (46, -0.017), (47, 0.064), (48, 0.047), (49, 0.007)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93604004 <a title="199-lsi-1" href="./nips-2006-Unsupervised_Learning_of_a_Probabilistic_Grammar_for_Object_Detection_and_Parsing.html">199 nips-2006-Unsupervised Learning of a Probabilistic Grammar for Object Detection and Parsing</a></p>
<p>Author: Yuanhao Chen, Long Zhu, Alan L. Yuille</p><p>Abstract: We describe an unsupervised method for learning a probabilistic grammar of an object from a set of training examples. Our approach is invariant to the scale and rotation of the objects. We illustrate our approach using thirteen objects from the Caltech 101 database. In addition, we learn the model of a hybrid object class where we do not know the speciﬁc object or its position, scale or pose. This is illustrated by learning a hybrid class consisting of faces, motorbikes, and airplanes. The individual objects can be recovered as different aspects of the grammar for the object class. In all cases, we validate our results by learning the probability grammars from training datasets and evaluating them on the test datasets. We compare our method to alternative approaches. The advantages of our approach is the speed of inference (under one second), the parsing of the object, and increased accuracy of performance. Moreover, our approach is very general and can be applied to a large range of objects and structures. 1</p><p>2 0.65154541 <a title="199-lsi-2" href="./nips-2006-Learning_to_parse_images_of_articulated_bodies.html">122 nips-2006-Learning to parse images of articulated bodies</a></p>
<p>Author: Deva Ramanan</p><p>Abstract: We consider the machine vision task of pose estimation from static images, specifically for the case of articulated objects. This problem is hard because of the large number of degrees of freedom to be estimated. Following a established line of research, pose estimation is framed as inference in a probabilistic model. In our experience however, the success of many approaches often lie in the power of the features. Our primary contribution is a novel casting of visual inference as an iterative parsing process, where one sequentially learns better and better features tuned to a particular image. We show quantitative results for human pose estimation on a database of over 300 images that suggest our algorithm is competitive with or surpasses the state-of-the-art. Since our procedure is quite general (it does not rely on face or skin detection), we also use it to estimate the poses of horses in the Weizmann database. 1</p><p>3 0.64268637 <a title="199-lsi-3" href="./nips-2006-Subordinate_class_recognition_using_relational_object_models.html">185 nips-2006-Subordinate class recognition using relational object models</a></p>
<p>Author: Aharon B. Hillel, Daphna Weinshall</p><p>Abstract: We address the problem of sub-ordinate class recognition, like the distinction between different types of motorcycles. Our approach is motivated by observations from cognitive psychology, which identify parts as the deﬁning component of basic level categories (like motorcycles), while sub-ordinate categories are more often deﬁned by part properties (like ’jagged wheels’). Accordingly, we suggest a two-stage algorithm: First, a relational part based object model is learnt using unsegmented object images from the inclusive class (e.g., motorcycles in general). The model is then used to build a class-speciﬁc vector representation for images, where each entry corresponds to a model’s part. In the second stage we train a standard discriminative classiﬁer to classify subclass instances (e.g., cross motorcycles) based on the class-speciﬁc vector representation. We describe extensive experimental results with several subclasses. The proposed algorithm typically gives better results than a competing one-step algorithm, or a two stage algorithm where classiﬁcation is based on a model of the sub-ordinate class. 1</p><p>4 0.60513705 <a title="199-lsi-4" href="./nips-2006-Efficient_Structure_Learning_of_Markov_Networks_using_%24L_1%24-Regularization.html">74 nips-2006-Efficient Structure Learning of Markov Networks using $L 1$-Regularization</a></p>
<p>Author: Su-in Lee, Varun Ganapathi, Daphne Koller</p><p>Abstract: Markov networks are commonly used in a wide variety of applications, ranging from computer vision, to natural language, to computational biology. In most current applications, even those that rely heavily on learned models, the structure of the Markov network is constructed by hand, due to the lack of effective algorithms for learning Markov network structure from data. In this paper, we provide a computationally efﬁcient method for learning Markov network structure from data. Our method is based on the use of L1 regularization on the weights of the log-linear model, which has the effect of biasing the model towards solutions where many of the parameters are zero. This formulation converts the Markov network learning problem into a convex optimization problem in a continuous space, which can be solved using efﬁcient gradient methods. A key issue in this setting is the (unavoidable) use of approximate inference, which can lead to errors in the gradient computation when the network structure is dense. Thus, we explore the use of different feature introduction schemes and compare their performance. We provide results for our method on synthetic data, and on two real world data sets: pixel values in the MNIST data, and genetic sequence variations in the human HapMap data. We show that our L1 -based method achieves considerably higher generalization performance than the more standard L2 -based method (a Gaussian parameter prior) or pure maximum-likelihood learning. We also show that we can learn MRF network structure at a computational cost that is not much greater than learning parameters alone, demonstrating the existence of a feasible method for this important problem.</p><p>5 0.60323566 <a title="199-lsi-5" href="./nips-2006-Using_Combinatorial_Optimization_within_Max-Product_Belief_Propagation.html">201 nips-2006-Using Combinatorial Optimization within Max-Product Belief Propagation</a></p>
<p>Author: Daniel Tarlow, Gal Elidan, Daphne Koller, John C. Duchi</p><p>Abstract: In general, the problem of computing a maximum a posteriori (MAP) assignment in a Markov random ﬁeld (MRF) is computationally intractable. However, in certain subclasses of MRF, an optimal or close-to-optimal assignment can be found very efﬁciently using combinatorial optimization algorithms: certain MRFs with mutual exclusion constraints can be solved using bipartite matching, and MRFs with regular potentials can be solved using minimum cut methods. However, these solutions do not apply to the many MRFs that contain such tractable components as sub-networks, but also other non-complying potentials. In this paper, we present a new method, called C OMPOSE, for exploiting combinatorial optimization for sub-networks within the context of a max-product belief propagation algorithm. C OMPOSE uses combinatorial optimization for computing exact maxmarginals for an entire sub-network; these can then be used for inference in the context of the network as a whole. We describe highly efﬁcient methods for computing max-marginals for subnetworks corresponding both to bipartite matchings and to regular networks. We present results on both synthetic and real networks encoding correspondence problems between images, which involve both matching constraints and pairwise geometric constraints. We compare to a range of current methods, showing that the ability of C OMPOSE to transmit information globally across the network leads to improved convergence, decreased running time, and higher-scoring assignments.</p><p>6 0.59110755 <a title="199-lsi-6" href="./nips-2006-Image_Retrieval_and_Classification_Using_Local_Distance_Functions.html">94 nips-2006-Image Retrieval and Classification Using Local Distance Functions</a></p>
<p>7 0.59027338 <a title="199-lsi-7" href="./nips-2006-The_Neurodynamics_of_Belief_Propagation_on_Binary_Markov_Random_Fields.html">190 nips-2006-The Neurodynamics of Belief Propagation on Binary Markov Random Fields</a></p>
<p>8 0.57045901 <a title="199-lsi-8" href="./nips-2006-Clustering_appearance_and_shape_by_learning_jigsaws.html">52 nips-2006-Clustering appearance and shape by learning jigsaws</a></p>
<p>9 0.55751479 <a title="199-lsi-9" href="./nips-2006-Adaptor_Grammars%3A_A_Framework_for_Specifying_Compositional_Nonparametric_Bayesian_Models.html">23 nips-2006-Adaptor Grammars: A Framework for Specifying Compositional Nonparametric Bayesian Models</a></p>
<p>10 0.52037668 <a title="199-lsi-10" href="./nips-2006-Fast_Discriminative_Visual_Codebooks_using_Randomized_Clustering_Forests.html">78 nips-2006-Fast Discriminative Visual Codebooks using Randomized Clustering Forests</a></p>
<p>11 0.51728958 <a title="199-lsi-11" href="./nips-2006-Scalable_Discriminative_Learning_for_Natural_Language_Parsing_and_Translation.html">172 nips-2006-Scalable Discriminative Learning for Natural Language Parsing and Translation</a></p>
<p>12 0.51632851 <a title="199-lsi-12" href="./nips-2006-Detecting_Humans_via_Their_Pose.html">66 nips-2006-Detecting Humans via Their Pose</a></p>
<p>13 0.51550663 <a title="199-lsi-13" href="./nips-2006-Robotic_Grasping_of_Novel_Objects.html">170 nips-2006-Robotic Grasping of Novel Objects</a></p>
<p>14 0.47560975 <a title="199-lsi-14" href="./nips-2006-Learning_annotated_hierarchies_from_relational_data.html">115 nips-2006-Learning annotated hierarchies from relational data</a></p>
<p>15 0.45411298 <a title="199-lsi-15" href="./nips-2006-Learning_Dense_3D_Correspondence.html">110 nips-2006-Learning Dense 3D Correspondence</a></p>
<p>16 0.45019105 <a title="199-lsi-16" href="./nips-2006-Statistical_Modeling_of_Images_with_Fields_of_Gaussian_Scale_Mixtures.html">182 nips-2006-Statistical Modeling of Images with Fields of Gaussian Scale Mixtures</a></p>
<p>17 0.41686004 <a title="199-lsi-17" href="./nips-2006-Max-margin_classification_of_incomplete_data.html">130 nips-2006-Max-margin classification of incomplete data</a></p>
<p>18 0.41373315 <a title="199-lsi-18" href="./nips-2006-Multi-dynamic_Bayesian_Networks.html">139 nips-2006-Multi-dynamic Bayesian Networks</a></p>
<p>19 0.41168034 <a title="199-lsi-19" href="./nips-2006-Efficient_Methods_for_Privacy_Preserving_Face_Detection.html">73 nips-2006-Efficient Methods for Privacy Preserving Face Detection</a></p>
<p>20 0.40510035 <a title="199-lsi-20" href="./nips-2006-Comparative_Gene_Prediction_using_Conditional_Random_Fields.html">54 nips-2006-Comparative Gene Prediction using Conditional Random Fields</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2006_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(1, 0.051), (7, 0.561), (9, 0.025), (12, 0.018), (20, 0.019), (21, 0.014), (22, 0.042), (44, 0.046), (57, 0.102), (65, 0.034), (69, 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.98660761 <a title="199-lda-1" href="./nips-2006-On_the_Relation_Between_Low_Density_Separation%2C_Spectral_Clustering_and_Graph_Cuts.html">151 nips-2006-On the Relation Between Low Density Separation, Spectral Clustering and Graph Cuts</a></p>
<p>Author: Hariharan Narayanan, Mikhail Belkin, Partha Niyogi</p><p>Abstract: One of the intuitions underlying many graph-based methods for clustering and semi-supervised learning, is that class or cluster boundaries pass through areas of low probability density. In this paper we provide some formal analysis of that notion for a probability distribution. We introduce a notion of weighted boundary volume, which measures the length of the class/cluster boundary weighted by the density of the underlying probability distribution. We show that sizes of the cuts of certain commonly used data adjacency graphs converge to this continuous weighted volume of the boundary. keywords: Clustering, Semi-Supervised Learning 1</p><p>same-paper 2 0.96528167 <a title="199-lda-2" href="./nips-2006-Unsupervised_Learning_of_a_Probabilistic_Grammar_for_Object_Detection_and_Parsing.html">199 nips-2006-Unsupervised Learning of a Probabilistic Grammar for Object Detection and Parsing</a></p>
<p>Author: Yuanhao Chen, Long Zhu, Alan L. Yuille</p><p>Abstract: We describe an unsupervised method for learning a probabilistic grammar of an object from a set of training examples. Our approach is invariant to the scale and rotation of the objects. We illustrate our approach using thirteen objects from the Caltech 101 database. In addition, we learn the model of a hybrid object class where we do not know the speciﬁc object or its position, scale or pose. This is illustrated by learning a hybrid class consisting of faces, motorbikes, and airplanes. The individual objects can be recovered as different aspects of the grammar for the object class. In all cases, we validate our results by learning the probability grammars from training datasets and evaluating them on the test datasets. We compare our method to alternative approaches. The advantages of our approach is the speed of inference (under one second), the parsing of the object, and increased accuracy of performance. Moreover, our approach is very general and can be applied to a large range of objects and structures. 1</p><p>3 0.93196964 <a title="199-lda-3" href="./nips-2006-Map-Reduce_for_Machine_Learning_on_Multicore.html">129 nips-2006-Map-Reduce for Machine Learning on Multicore</a></p>
<p>Author: Cheng-tao Chu, Sang K. Kim, Yi-an Lin, Yuanyuan Yu, Gary Bradski, Kunle Olukotun, Andrew Y. Ng</p><p>Abstract: We are at the beginning of the multicore era. Computers will have increasingly many cores (processors), but there is still no good programming framework for these architectures, and thus no simple and uniﬁed way for machine learning to take advantage of the potential speed up. In this paper, we develop a broadly applicable parallel programming method, one that is easily applied to many different learning algorithms. Our work is in distinct contrast to the tradition in machine learning of designing (often ingenious) ways to speed up a single algorithm at a time. Speciﬁcally, we show that algorithms that ﬁt the Statistical Query model [15] can be written in a certain “summation form,” which allows them to be easily parallelized on multicore computers. We adapt Google’s map-reduce [7] paradigm to demonstrate this parallel speed up technique on a variety of learning algorithms including locally weighted linear regression (LWLR), k-means, logistic regression (LR), naive Bayes (NB), SVM, ICA, PCA, gaussian discriminant analysis (GDA), EM, and backpropagation (NN). Our experimental results show basically linear speedup with an increasing number of processors. 1</p><p>4 0.90697759 <a title="199-lda-4" href="./nips-2006-An_Efficient_Method_for_Gradient-Based_Adaptation_of_Hyperparameters_in_SVM_Models.html">28 nips-2006-An Efficient Method for Gradient-Based Adaptation of Hyperparameters in SVM Models</a></p>
<p>Author: S. S. Keerthi, Vikas Sindhwani, Olivier Chapelle</p><p>Abstract: We consider the task of tuning hyperparameters in SVM models based on minimizing a smooth performance validation function, e.g., smoothed k-fold crossvalidation error, using non-linear optimization techniques. The key computation in this approach is that of the gradient of the validation function with respect to hyperparameters. We show that for large-scale problems involving a wide choice of kernel-based models and validation functions, this computation can be very efﬁciently done; often within just a fraction of the training time. Empirical results show that a near-optimal set of hyperparameters can be identiﬁed by our approach with very few training rounds and gradient computations. . 1</p><p>5 0.86973614 <a title="199-lda-5" href="./nips-2006-The_Neurodynamics_of_Belief_Propagation_on_Binary_Markov_Random_Fields.html">190 nips-2006-The Neurodynamics of Belief Propagation on Binary Markov Random Fields</a></p>
<p>Author: Thomas Ott, Ruedi Stoop</p><p>Abstract: We rigorously establish a close relationship between message passing algorithms and models of neurodynamics by showing that the equations of a continuous Hopﬁeld network can be derived from the equations of belief propagation on a binary Markov random ﬁeld. As Hopﬁeld networks are equipped with a Lyapunov function, convergence is guaranteed. As a consequence, in the limit of many weak connections per neuron, Hopﬁeld networks exactly implement a continuous-time variant of belief propagation starting from message initialisations that prevent from running into convergence problems. Our results lead to a better understanding of the role of message passing algorithms in real biological neural networks.</p><p>6 0.82363951 <a title="199-lda-6" href="./nips-2006-Convergence_of_Laplacian_Eigenmaps.html">60 nips-2006-Convergence of Laplacian Eigenmaps</a></p>
<p>7 0.76853049 <a title="199-lda-7" href="./nips-2006-Fundamental_Limitations_of_Spectral_Clustering.html">80 nips-2006-Fundamental Limitations of Spectral Clustering</a></p>
<p>8 0.67448258 <a title="199-lda-8" href="./nips-2006-Manifold_Denoising.html">128 nips-2006-Manifold Denoising</a></p>
<p>9 0.66919792 <a title="199-lda-9" href="./nips-2006-Bayesian_Model_Scoring_in_Markov_Random_Fields.html">43 nips-2006-Bayesian Model Scoring in Markov Random Fields</a></p>
<p>10 0.66593844 <a title="199-lda-10" href="./nips-2006-Learning_to_Rank_with_Nonsmooth_Cost_Functions.html">119 nips-2006-Learning to Rank with Nonsmooth Cost Functions</a></p>
<p>11 0.65367031 <a title="199-lda-11" href="./nips-2006-Analysis_of_Representations_for_Domain_Adaptation.html">33 nips-2006-Analysis of Representations for Domain Adaptation</a></p>
<p>12 0.64977902 <a title="199-lda-12" href="./nips-2006-Learning_Dense_3D_Correspondence.html">110 nips-2006-Learning Dense 3D Correspondence</a></p>
<p>13 0.6418069 <a title="199-lda-13" href="./nips-2006-Image_Retrieval_and_Classification_Using_Local_Distance_Functions.html">94 nips-2006-Image Retrieval and Classification Using Local Distance Functions</a></p>
<p>14 0.6360504 <a title="199-lda-14" href="./nips-2006-Stability_of_%24K%24-Means_Clustering.html">181 nips-2006-Stability of $K$-Means Clustering</a></p>
<p>15 0.6341027 <a title="199-lda-15" href="./nips-2006-Analysis_of_Contour_Motions.html">31 nips-2006-Analysis of Contour Motions</a></p>
<p>16 0.63190711 <a title="199-lda-16" href="./nips-2006-Similarity_by_Composition.html">174 nips-2006-Similarity by Composition</a></p>
<p>17 0.63154227 <a title="199-lda-17" href="./nips-2006-Balanced_Graph_Matching.html">39 nips-2006-Balanced Graph Matching</a></p>
<p>18 0.62921351 <a title="199-lda-18" href="./nips-2006-Learning_with_Hypergraphs%3A_Clustering%2C_Classification%2C_and_Embedding.html">123 nips-2006-Learning with Hypergraphs: Clustering, Classification, and Embedding</a></p>
<p>19 0.62770307 <a title="199-lda-19" href="./nips-2006-Subordinate_class_recognition_using_relational_object_models.html">185 nips-2006-Subordinate class recognition using relational object models</a></p>
<p>20 0.62426448 <a title="199-lda-20" href="./nips-2006-Prediction_on_a_Graph_with_a_Perceptron.html">163 nips-2006-Prediction on a Graph with a Perceptron</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
