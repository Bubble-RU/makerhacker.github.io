<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>148 nips-2006-Nonlinear physically-based models for decoding motor-cortical population activity</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-148" href="#">nips2006-148</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>148 nips-2006-Nonlinear physically-based models for decoding motor-cortical population activity</h1>
<br/><p>Source: <a title="nips-2006-148-pdf" href="http://papers.nips.cc/paper/3050-nonlinear-physically-based-models-for-decoding-motor-cortical-population-activity.pdf">pdf</a></p><p>Author: Gregory Shakhnarovich, Sung-phil Kim, Michael J. Black</p><p>Abstract: Neural motor prostheses (NMPs) require the accurate decoding of motor cortical population activity for the control of an artiﬁcial motor system. Previous work on cortical decoding for NMPs has focused on the recovery of hand kinematics. Human NMPs however may require the control of computer cursors or robotic devices with very different physical and dynamical properties. Here we show that the ﬁring rates of cells in the primary motor cortex of non-human primates can be used to control the parameters of an artiﬁcial physical system exhibiting realistic dynamics. The model represents 2D hand motion in terms of a point mass connected to a system of idealized springs. The nonlinear spring coefﬁcients are estimated from the ﬁring rates of neurons in the motor cortex. We evaluate linear and a nonlinear decoding algorithms using neural recordings from two monkeys performing two different tasks. We found that the decoded spring coefﬁcients produced accurate hand trajectories compared with state-of-the-art methods for direct decoding of hand kinematics. Furthermore, using a physically-based system produced decoded movements that were more “natural” in that their frequency spectrum more closely matched that of natural hand movements. 1</p><p>Reference: <a title="nips-2006-148-reference" href="../nips2006_reference/nips-2006-Nonlinear_physically-based_models_for_decoding_motor-cortical_population_activity_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('decod', 0.513), ('ka', 0.233), ('kinem', 0.232), ('sbm', 0.186), ('vx', 0.186), ('spring', 0.166), ('springs', 0.166), ('ring', 0.159), ('cort', 0.156), ('curs', 0.15), ('mov', 0.149), ('kb', 0.148), ('monkey', 0.148), ('mae', 0.129), ('stiff', 0.117), ('wrist', 0.117), ('mot', 0.115), ('phys', 0.097), ('cc', 0.093), ('donoghu', 0.093)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="148-tfidf-1" href="./nips-2006-Nonlinear_physically-based_models_for_decoding_motor-cortical_population_activity.html">148 nips-2006-Nonlinear physically-based models for decoding motor-cortical population activity</a></p>
<p>Author: Gregory Shakhnarovich, Sung-phil Kim, Michael J. Black</p><p>Abstract: Neural motor prostheses (NMPs) require the accurate decoding of motor cortical population activity for the control of an artiﬁcial motor system. Previous work on cortical decoding for NMPs has focused on the recovery of hand kinematics. Human NMPs however may require the control of computer cursors or robotic devices with very different physical and dynamical properties. Here we show that the ﬁring rates of cells in the primary motor cortex of non-human primates can be used to control the parameters of an artiﬁcial physical system exhibiting realistic dynamics. The model represents 2D hand motion in terms of a point mass connected to a system of idealized springs. The nonlinear spring coefﬁcients are estimated from the ﬁring rates of neurons in the motor cortex. We evaluate linear and a nonlinear decoding algorithms using neural recordings from two monkeys performing two different tasks. We found that the decoded spring coefﬁcients produced accurate hand trajectories compared with state-of-the-art methods for direct decoding of hand kinematics. Furthermore, using a physically-based system produced decoded movements that were more “natural” in that their frequency spectrum more closely matched that of natural hand movements. 1</p><p>2 0.2467726 <a title="148-tfidf-2" href="./nips-2006-Efficient_Learning_of_Sparse_Representations_with_an_Energy-Based_Model.html">72 nips-2006-Efficient Learning of Sparse Representations with an Energy-Based Model</a></p>
<p>Author: Marc'aurelio Ranzato, Christopher Poultney, Sumit Chopra, Yann L. Cun</p><p>Abstract: We describe a novel unsupervised method for learning sparse, overcomplete features. The model uses a linear encoder, and a linear decoder preceded by a sparsifying non-linearity that turns a code vector into a quasi-binary sparse code vector. Given an input, the optimal code minimizes the distance between the output of the decoder and the input patch while being as similar as possible to the encoder output. Learning proceeds in a two-phase EM-like fashion: (1) compute the minimum-energy code vector, (2) adjust the parameters of the encoder and decoder so as to decrease the energy. The model produces “stroke detectors” when trained on handwritten numerals, and Gabor-like ﬁlters when trained on natural image patches. Inference and learning are very fast, requiring no preprocessing, and no expensive sampling. Using the proposed unsupervised method to initialize the ﬁrst layer of a convolutional network, we achieved an error rate slightly lower than the best reported result on the MNIST dataset. Finally, an extension of the method is described to learn topographical ﬁlter maps. 1</p><p>3 0.11581831 <a title="148-tfidf-3" href="./nips-2006-Uncertainty%2C_phase_and_oscillatory_hippocampal_recall.html">197 nips-2006-Uncertainty, phase and oscillatory hippocampal recall</a></p>
<p>Author: Máté Lengyel, Peter Dayan</p><p>Abstract: Many neural areas, notably, the hippocampus, show structured, dynamical, population behavior such as coordinated oscillations. It has long been observed that such oscillations provide a substrate for representing analog information in the ﬁring phases of neurons relative to the underlying population rhythm. However, it has become increasingly clear that it is essential for neural populations to represent uncertainty about the information they capture, and the substantial recent work on neural codes for uncertainty has omitted any analysis of oscillatory systems. Here, we observe that, since neurons in an oscillatory network need not only ﬁre once in each cycle (or even at all), uncertainty about the analog quantities each neuron represents by its ﬁring phase might naturally be reported through the degree of concentration of the spikes that it ﬁres. We apply this theory to memory in a model of oscillatory associative recall in hippocampal area CA3. Although it is not well treated in the literature, representing and manipulating uncertainty is fundamental to competent memory; our theory enables us to view CA3 as an effective uncertainty-aware, retrieval system. 1</p><p>4 0.10651681 <a title="148-tfidf-4" href="./nips-2006-Large_Scale_Hidden_Semi-Markov_SVMs.html">108 nips-2006-Large Scale Hidden Semi-Markov SVMs</a></p>
<p>Author: Gunnar Rätsch, Sören Sonnenburg</p><p>Abstract: We describe Hidden Semi-Markov Support Vector Machines (SHM SVMs), an extension of HM SVMs to semi-Markov chains. This allows us to predict segmentations of sequences based on segment-based features measuring properties such as the length of the segment. We propose a novel technique to partition the problem into sub-problems. The independently obtained partial solutions can then be recombined in an efﬁcient way, which allows us to solve label sequence learning problems with several thousands of labeled sequences. We have tested our algorithm for predicting gene structures, an important problem in computational biology. Results on a well-known model organism illustrate the great potential of SHM SVMs in computational biology. 1</p><p>5 0.1024644 <a title="148-tfidf-5" href="./nips-2006-Causal_inference_in_sensorimotor_integration.html">49 nips-2006-Causal inference in sensorimotor integration</a></p>
<p>Author: Konrad P. Körding, Joshua B. Tenenbaum</p><p>Abstract: Many recent studies analyze how data from different modalities can be combined. Often this is modeled as a system that optimally combines several sources of information about the same variable. However, it has long been realized that this information combining depends on the interpretation of the data. Two cues that are perceived by different modalities can have different causal relationships: (1) They can both have the same cause, in this case we should fully integrate both cues into a joint estimate. (2) They can have distinct causes, in which case information should be processed independently. In many cases we will not know if there is one joint cause or two independent causes that are responsible for the cues. Here we model this situation as a Bayesian estimation problem. We are thus able to explain some experiments on visual auditory cue combination as well as some experiments on visual proprioceptive cue integration. Our analysis shows that the problem solved by people when they combine cues to produce a movement is much more complicated than is usually assumed, because they need to infer the causal structure that is underlying their sensory experience.</p><p>6 0.099848956 <a title="148-tfidf-6" href="./nips-2006-Temporal_Coding_using_the_Response_Properties_of_Spiking_Neurons.html">187 nips-2006-Temporal Coding using the Response Properties of Spiking Neurons</a></p>
<p>7 0.093919642 <a title="148-tfidf-7" href="./nips-2006-Learning_Nonparametric_Models_for_Probabilistic_Imitation.html">112 nips-2006-Learning Nonparametric Models for Probabilistic Imitation</a></p>
<p>8 0.089959867 <a title="148-tfidf-8" href="./nips-2006-Optimal_Change-Detection_and_Spiking_Neurons.html">154 nips-2006-Optimal Change-Detection and Spiking Neurons</a></p>
<p>9 0.088324107 <a title="148-tfidf-9" href="./nips-2006-Context_dependent_amplification_of_both_rate_and_event-correlation_in_a_VLSI_network_of_spiking_neurons.html">59 nips-2006-Context dependent amplification of both rate and event-correlation in a VLSI network of spiking neurons</a></p>
<p>10 0.087743603 <a title="148-tfidf-10" href="./nips-2006-Learning_Motion_Style_Synthesis_from_Perceptual_Observations.html">111 nips-2006-Learning Motion Style Synthesis from Perceptual Observations</a></p>
<p>11 0.083411232 <a title="148-tfidf-11" href="./nips-2006-Attentional_Processing_on_a_Spike-Based_VLSI_Neural_Network.html">36 nips-2006-Attentional Processing on a Spike-Based VLSI Neural Network</a></p>
<p>12 0.082416594 <a title="148-tfidf-12" href="./nips-2006-Modeling_Human_Motion_Using_Binary_Latent_Variables.html">134 nips-2006-Modeling Human Motion Using Binary Latent Variables</a></p>
<p>13 0.07897085 <a title="148-tfidf-13" href="./nips-2006-Large_Margin_Multi-channel_Analog-to-Digital_Conversion_with_Applications_to_Neural_Prosthesis.html">107 nips-2006-Large Margin Multi-channel Analog-to-Digital Conversion with Applications to Neural Prosthesis</a></p>
<p>14 0.077708483 <a title="148-tfidf-14" href="./nips-2006-Information_Bottleneck_Optimization_and_Independent_Component_Extraction_with_Spiking_Neurons.html">99 nips-2006-Information Bottleneck Optimization and Independent Component Extraction with Spiking Neurons</a></p>
<p>15 0.074570179 <a title="148-tfidf-15" href="./nips-2006-Unsupervised_Regression_with_Applications_to_Nonlinear_System_Identification.html">200 nips-2006-Unsupervised Regression with Applications to Nonlinear System Identification</a></p>
<p>16 0.072421975 <a title="148-tfidf-16" href="./nips-2006-Adaptive_Spatial_Filters_with_predefined_Region_of_Interest_for_EEG_based_Brain-Computer-Interfaces.html">22 nips-2006-Adaptive Spatial Filters with predefined Region of Interest for EEG based Brain-Computer-Interfaces</a></p>
<p>17 0.071621969 <a title="148-tfidf-17" href="./nips-2006-Temporal_dynamics_of_information_content_carried_by_neurons_in_the_primary_visual_cortex.html">189 nips-2006-Temporal dynamics of information content carried by neurons in the primary visual cortex</a></p>
<p>18 0.070592478 <a title="148-tfidf-18" href="./nips-2006-Online_Clustering_of_Moving_Hyperplanes.html">153 nips-2006-Online Clustering of Moving Hyperplanes</a></p>
<p>19 0.068158023 <a title="148-tfidf-19" href="./nips-2006-A_selective_attention_multi--chip_system_with_dynamic_synapses_and_spiking_neurons.html">18 nips-2006-A selective attention multi--chip system with dynamic synapses and spiking neurons</a></p>
<p>20 0.067764722 <a title="148-tfidf-20" href="./nips-2006-A_Theory_of_Retinal_Population_Coding.html">16 nips-2006-A Theory of Retinal Population Coding</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2006_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.199), (1, 0.095), (2, 0.022), (3, -0.085), (4, 0.079), (5, -0.086), (6, -0.019), (7, 0.013), (8, 0.027), (9, 0.064), (10, 0.045), (11, -0.085), (12, 0.0), (13, -0.122), (14, 0.094), (15, -0.043), (16, 0.02), (17, 0.077), (18, -0.032), (19, 0.028), (20, -0.051), (21, -0.054), (22, 0.016), (23, -0.016), (24, 0.058), (25, 0.085), (26, -0.057), (27, -0.043), (28, -0.112), (29, -0.048), (30, 0.065), (31, -0.167), (32, -0.086), (33, -0.014), (34, -0.212), (35, 0.063), (36, -0.134), (37, -0.028), (38, -0.011), (39, -0.056), (40, 0.14), (41, 0.214), (42, -0.026), (43, -0.041), (44, -0.083), (45, -0.233), (46, 0.029), (47, 0.019), (48, 0.027), (49, 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93260533 <a title="148-lsi-1" href="./nips-2006-Nonlinear_physically-based_models_for_decoding_motor-cortical_population_activity.html">148 nips-2006-Nonlinear physically-based models for decoding motor-cortical population activity</a></p>
<p>Author: Gregory Shakhnarovich, Sung-phil Kim, Michael J. Black</p><p>Abstract: Neural motor prostheses (NMPs) require the accurate decoding of motor cortical population activity for the control of an artiﬁcial motor system. Previous work on cortical decoding for NMPs has focused on the recovery of hand kinematics. Human NMPs however may require the control of computer cursors or robotic devices with very different physical and dynamical properties. Here we show that the ﬁring rates of cells in the primary motor cortex of non-human primates can be used to control the parameters of an artiﬁcial physical system exhibiting realistic dynamics. The model represents 2D hand motion in terms of a point mass connected to a system of idealized springs. The nonlinear spring coefﬁcients are estimated from the ﬁring rates of neurons in the motor cortex. We evaluate linear and a nonlinear decoding algorithms using neural recordings from two monkeys performing two different tasks. We found that the decoded spring coefﬁcients produced accurate hand trajectories compared with state-of-the-art methods for direct decoding of hand kinematics. Furthermore, using a physically-based system produced decoded movements that were more “natural” in that their frequency spectrum more closely matched that of natural hand movements. 1</p><p>2 0.54280317 <a title="148-lsi-2" href="./nips-2006-Large_Margin_Multi-channel_Analog-to-Digital_Conversion_with_Applications_to_Neural_Prosthesis.html">107 nips-2006-Large Margin Multi-channel Analog-to-Digital Conversion with Applications to Neural Prosthesis</a></p>
<p>Author: Amit Gore, Shantanu Chakrabartty</p><p>Abstract: A key challenge in designing analog-to-digital converters for cortically implanted prosthesis is to sense and process high-dimensional neural signals recorded by the micro-electrode arrays. In this paper, we describe a novel architecture for analog-to-digital (A/D) conversion that combines Σ∆ conversion with spatial de-correlation within a single module. The architecture called multiple-input multiple-output (MIMO) Σ∆ is based on a min-max gradient descent optimization of a regularized linear cost function that naturally lends to an A/D formulation. Using an online formulation, the architecture can adapt to slow variations in cross-channel correlations, observed due to relative motion of the microelectrodes with respect to the signal sources. Experimental results with real recorded multi-channel neural data demonstrate the effectiveness of the proposed algorithm in alleviating cross-channel redundancy across electrodes and performing data-compression directly at the A/D converter. 1</p><p>3 0.52580464 <a title="148-lsi-3" href="./nips-2006-Learning_Nonparametric_Models_for_Probabilistic_Imitation.html">112 nips-2006-Learning Nonparametric Models for Probabilistic Imitation</a></p>
<p>Author: David B. Grimes, Daniel R. Rashid, Rajesh P. Rao</p><p>Abstract: Learning by imitation represents an important mechanism for rapid acquisition of new behaviors in humans and robots. A critical requirement for learning by imitation is the ability to handle uncertainty arising from the observation process as well as the imitator’s own dynamics and interactions with the environment. In this paper, we present a new probabilistic method for inferring imitative actions that takes into account both the observations of the teacher as well as the imitator’s dynamics. Our key contribution is a nonparametric learning method which generalizes to systems with very different dynamics. Rather than relying on a known forward model of the dynamics, our approach learns a nonparametric forward model via exploration. Leveraging advances in approximate inference in graphical models, we show how the learned forward model can be directly used to plan an imitating sequence. We provide experimental results for two systems: a biomechanical model of the human arm and a 25-degrees-of-freedom humanoid robot. We demonstrate that the proposed method can be used to learn appropriate motor inputs to the model arm which imitates the desired movements. A second set of results demonstrates dynamically stable full-body imitation of a human teacher by the humanoid robot. 1</p><p>4 0.52091992 <a title="148-lsi-4" href="./nips-2006-Efficient_Learning_of_Sparse_Representations_with_an_Energy-Based_Model.html">72 nips-2006-Efficient Learning of Sparse Representations with an Energy-Based Model</a></p>
<p>Author: Marc'aurelio Ranzato, Christopher Poultney, Sumit Chopra, Yann L. Cun</p><p>Abstract: We describe a novel unsupervised method for learning sparse, overcomplete features. The model uses a linear encoder, and a linear decoder preceded by a sparsifying non-linearity that turns a code vector into a quasi-binary sparse code vector. Given an input, the optimal code minimizes the distance between the output of the decoder and the input patch while being as similar as possible to the encoder output. Learning proceeds in a two-phase EM-like fashion: (1) compute the minimum-energy code vector, (2) adjust the parameters of the encoder and decoder so as to decrease the energy. The model produces “stroke detectors” when trained on handwritten numerals, and Gabor-like ﬁlters when trained on natural image patches. Inference and learning are very fast, requiring no preprocessing, and no expensive sampling. Using the proposed unsupervised method to initialize the ﬁrst layer of a convolutional network, we achieved an error rate slightly lower than the best reported result on the MNIST dataset. Finally, an extension of the method is described to learn topographical ﬁlter maps. 1</p><p>5 0.49024275 <a title="148-lsi-5" href="./nips-2006-Causal_inference_in_sensorimotor_integration.html">49 nips-2006-Causal inference in sensorimotor integration</a></p>
<p>Author: Konrad P. Körding, Joshua B. Tenenbaum</p><p>Abstract: Many recent studies analyze how data from different modalities can be combined. Often this is modeled as a system that optimally combines several sources of information about the same variable. However, it has long been realized that this information combining depends on the interpretation of the data. Two cues that are perceived by different modalities can have different causal relationships: (1) They can both have the same cause, in this case we should fully integrate both cues into a joint estimate. (2) They can have distinct causes, in which case information should be processed independently. In many cases we will not know if there is one joint cause or two independent causes that are responsible for the cues. Here we model this situation as a Bayesian estimation problem. We are thus able to explain some experiments on visual auditory cue combination as well as some experiments on visual proprioceptive cue integration. Our analysis shows that the problem solved by people when they combine cues to produce a movement is much more complicated than is usually assumed, because they need to infer the causal structure that is underlying their sensory experience.</p><p>6 0.48847997 <a title="148-lsi-6" href="./nips-2006-An_Application_of_Reinforcement_Learning_to_Aerobatic_Helicopter_Flight.html">25 nips-2006-An Application of Reinforcement Learning to Aerobatic Helicopter Flight</a></p>
<p>7 0.47655663 <a title="148-lsi-7" href="./nips-2006-Robotic_Grasping_of_Novel_Objects.html">170 nips-2006-Robotic Grasping of Novel Objects</a></p>
<p>8 0.43539232 <a title="148-lsi-8" href="./nips-2006-Learning_Motion_Style_Synthesis_from_Perceptual_Observations.html">111 nips-2006-Learning Motion Style Synthesis from Perceptual Observations</a></p>
<p>9 0.42025828 <a title="148-lsi-9" href="./nips-2006-Online_Clustering_of_Moving_Hyperplanes.html">153 nips-2006-Online Clustering of Moving Hyperplanes</a></p>
<p>10 0.41526869 <a title="148-lsi-10" href="./nips-2006-Multiple_timescales_and_uncertainty_in_motor_adaptation.html">141 nips-2006-Multiple timescales and uncertainty in motor adaptation</a></p>
<p>11 0.41161808 <a title="148-lsi-11" href="./nips-2006-Large_Scale_Hidden_Semi-Markov_SVMs.html">108 nips-2006-Large Scale Hidden Semi-Markov SVMs</a></p>
<p>12 0.38833958 <a title="148-lsi-12" href="./nips-2006-A_Theory_of_Retinal_Population_Coding.html">16 nips-2006-A Theory of Retinal Population Coding</a></p>
<p>13 0.38299689 <a title="148-lsi-13" href="./nips-2006-Efficient_sparse_coding_algorithms.html">75 nips-2006-Efficient sparse coding algorithms</a></p>
<p>14 0.33399692 <a title="148-lsi-14" href="./nips-2006-Modeling_Human_Motion_Using_Binary_Latent_Variables.html">134 nips-2006-Modeling Human Motion Using Binary Latent Variables</a></p>
<p>15 0.32604548 <a title="148-lsi-15" href="./nips-2006-Nonnegative_Sparse_PCA.html">149 nips-2006-Nonnegative Sparse PCA</a></p>
<p>16 0.3216517 <a title="148-lsi-16" href="./nips-2006-Uncertainty%2C_phase_and_oscillatory_hippocampal_recall.html">197 nips-2006-Uncertainty, phase and oscillatory hippocampal recall</a></p>
<p>17 0.31417459 <a title="148-lsi-17" href="./nips-2006-Sparse_Representation_for_Signal_Classification.html">179 nips-2006-Sparse Representation for Signal Classification</a></p>
<p>18 0.31192389 <a title="148-lsi-18" href="./nips-2006-Adaptive_Spatial_Filters_with_predefined_Region_of_Interest_for_EEG_based_Brain-Computer-Interfaces.html">22 nips-2006-Adaptive Spatial Filters with predefined Region of Interest for EEG based Brain-Computer-Interfaces</a></p>
<p>19 0.30700183 <a title="148-lsi-19" href="./nips-2006-Predicting_spike_times_from_subthreshold_dynamics_of_a_neuron.html">162 nips-2006-Predicting spike times from subthreshold dynamics of a neuron</a></p>
<p>20 0.30620208 <a title="148-lsi-20" href="./nips-2006-Temporal_Coding_using_the_Response_Properties_of_Spiking_Neurons.html">187 nips-2006-Temporal Coding using the Response Properties of Spiking Neurons</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2006_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(22, 0.159), (34, 0.094), (45, 0.064), (46, 0.052), (53, 0.068), (61, 0.069), (72, 0.078), (73, 0.325)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.75793546 <a title="148-lda-1" href="./nips-2006-Nonlinear_physically-based_models_for_decoding_motor-cortical_population_activity.html">148 nips-2006-Nonlinear physically-based models for decoding motor-cortical population activity</a></p>
<p>Author: Gregory Shakhnarovich, Sung-phil Kim, Michael J. Black</p><p>Abstract: Neural motor prostheses (NMPs) require the accurate decoding of motor cortical population activity for the control of an artiﬁcial motor system. Previous work on cortical decoding for NMPs has focused on the recovery of hand kinematics. Human NMPs however may require the control of computer cursors or robotic devices with very different physical and dynamical properties. Here we show that the ﬁring rates of cells in the primary motor cortex of non-human primates can be used to control the parameters of an artiﬁcial physical system exhibiting realistic dynamics. The model represents 2D hand motion in terms of a point mass connected to a system of idealized springs. The nonlinear spring coefﬁcients are estimated from the ﬁring rates of neurons in the motor cortex. We evaluate linear and a nonlinear decoding algorithms using neural recordings from two monkeys performing two different tasks. We found that the decoded spring coefﬁcients produced accurate hand trajectories compared with state-of-the-art methods for direct decoding of hand kinematics. Furthermore, using a physically-based system produced decoded movements that were more “natural” in that their frequency spectrum more closely matched that of natural hand movements. 1</p><p>2 0.69411558 <a title="148-lda-2" href="./nips-2006-Multiple_timescales_and_uncertainty_in_motor_adaptation.html">141 nips-2006-Multiple timescales and uncertainty in motor adaptation</a></p>
<p>Author: Konrad P. Körding, Joshua B. Tenenbaum, Reza Shadmehr</p><p>Abstract: Our motor system changes due to causes that span multiple timescales. For example, muscle response can change because of fatigue, a condition where the disturbance has a fast timescale or because of disease where the disturbance is much slower. Here we hypothesize that the nervous system adapts in a way that reﬂects the temporal properties of such potential disturbances. According to a Bayesian formulation of this idea, movement error results in a credit assignment problem: what timescale is responsible for this disturbance? The adaptation schedule inﬂuences the behavior of the optimal learner, changing estimates at different timescales as well as the uncertainty. A system that adapts in this way predicts many properties observed in saccadic gain adaptation. It well predicts the timecourses of motor adaptation in cases of partial sensory deprivation and reversals of the adaptation direction.</p><p>3 0.61647803 <a title="148-lda-3" href="./nips-2006-Generalized_Regularized_Least-Squares_Learning_with_Predefined_Features_in_a_Hilbert_Space.html">84 nips-2006-Generalized Regularized Least-Squares Learning with Predefined Features in a Hilbert Space</a></p>
<p>Author: Wenye Li, Kin-hong Lee, Kwong-sak Leung</p><p>Abstract: Kernel-based regularized learning seeks a model in a hypothesis space by minimizing the empirical error and the model’s complexity. Based on the representer theorem, the solution consists of a linear combination of translates of a kernel. This paper investigates a generalized form of representer theorem for kernel-based learning. After mapping predeﬁned features and translates of a kernel simultaneously onto a hypothesis space by a speciﬁc way of constructing kernels, we proposed a new algorithm by utilizing a generalized regularizer which leaves part of the space unregularized. Using a squared-loss function in calculating the empirical error, a simple convex solution is obtained which combines predeﬁned features with translates of the kernel. Empirical evaluations have conﬁrmed the effectiveness of the algorithm for supervised learning tasks.</p><p>4 0.58376211 <a title="148-lda-4" href="./nips-2006-Large_Margin_Multi-channel_Analog-to-Digital_Conversion_with_Applications_to_Neural_Prosthesis.html">107 nips-2006-Large Margin Multi-channel Analog-to-Digital Conversion with Applications to Neural Prosthesis</a></p>
<p>Author: Amit Gore, Shantanu Chakrabartty</p><p>Abstract: A key challenge in designing analog-to-digital converters for cortically implanted prosthesis is to sense and process high-dimensional neural signals recorded by the micro-electrode arrays. In this paper, we describe a novel architecture for analog-to-digital (A/D) conversion that combines Σ∆ conversion with spatial de-correlation within a single module. The architecture called multiple-input multiple-output (MIMO) Σ∆ is based on a min-max gradient descent optimization of a regularized linear cost function that naturally lends to an A/D formulation. Using an online formulation, the architecture can adapt to slow variations in cross-channel correlations, observed due to relative motion of the microelectrodes with respect to the signal sources. Experimental results with real recorded multi-channel neural data demonstrate the effectiveness of the proposed algorithm in alleviating cross-channel redundancy across electrodes and performing data-compression directly at the A/D converter. 1</p><p>5 0.58316815 <a title="148-lda-5" href="./nips-2006-A_recipe_for_optimizing_a_time-histogram.html">17 nips-2006-A recipe for optimizing a time-histogram</a></p>
<p>Author: Hideaki Shimazaki, Shigeru Shinomoto</p><p>Abstract: The time-histogram method is a handy tool for capturing the instantaneous rate of spike occurrence. In most of the neurophysiological literature, the bin size that critically determines the goodness of the ﬁt of the time-histogram to the underlying rate has been selected by individual researchers in an unsystematic manner. We propose an objective method for selecting the bin size of a time-histogram from the spike data, so that the time-histogram best approximates the unknown underlying rate. The resolution of the histogram increases, or the optimal bin size decreases, with the number of spike sequences sampled. It is notable that the optimal bin size diverges if only a small number of experimental trials are available from a moderately ﬂuctuating rate process. In this case, any attempt to characterize the underlying spike rate will lead to spurious results. Given a paucity of data, our method can also suggest how many more trials are needed until the set of data can be analyzed with the required resolution. 1</p><p>6 0.5801065 <a title="148-lda-6" href="./nips-2006-Adaptive_Spatial_Filters_with_predefined_Region_of_Interest_for_EEG_based_Brain-Computer-Interfaces.html">22 nips-2006-Adaptive Spatial Filters with predefined Region of Interest for EEG based Brain-Computer-Interfaces</a></p>
<p>7 0.57133484 <a title="148-lda-7" href="./nips-2006-Statistical_Modeling_of_Images_with_Fields_of_Gaussian_Scale_Mixtures.html">182 nips-2006-Statistical Modeling of Images with Fields of Gaussian Scale Mixtures</a></p>
<p>8 0.5660997 <a title="148-lda-8" href="./nips-2006-Learning_Structural_Equation_Models_for_fMRI.html">113 nips-2006-Learning Structural Equation Models for fMRI</a></p>
<p>9 0.54089326 <a title="148-lda-9" href="./nips-2006-Reducing_Calibration_Time_For_Brain-Computer_Interfaces%3A_A_Clustering_Approach.html">168 nips-2006-Reducing Calibration Time For Brain-Computer Interfaces: A Clustering Approach</a></p>
<p>10 0.53632772 <a title="148-lda-10" href="./nips-2006-Logistic_Regression_for_Single_Trial_EEG_Classification.html">126 nips-2006-Logistic Regression for Single Trial EEG Classification</a></p>
<p>11 0.52595508 <a title="148-lda-11" href="./nips-2006-The_Neurodynamics_of_Belief_Propagation_on_Binary_Markov_Random_Fields.html">190 nips-2006-The Neurodynamics of Belief Propagation on Binary Markov Random Fields</a></p>
<p>12 0.52485108 <a title="148-lda-12" href="./nips-2006-Aggregating_Classification_Accuracy_across_Time%3A_Application_to_Single_Trial_EEG.html">24 nips-2006-Aggregating Classification Accuracy across Time: Application to Single Trial EEG</a></p>
<p>13 0.50073612 <a title="148-lda-13" href="./nips-2006-Neurophysiological_Evidence_of_Cooperative_Mechanisms_for_Stereo_Computation.html">145 nips-2006-Neurophysiological Evidence of Cooperative Mechanisms for Stereo Computation</a></p>
<p>14 0.49756986 <a title="148-lda-14" href="./nips-2006-Sparse_Representation_for_Signal_Classification.html">179 nips-2006-Sparse Representation for Signal Classification</a></p>
<p>15 0.49725688 <a title="148-lda-15" href="./nips-2006-Temporal_and_Cross-Subject_Probabilistic_Models_for_fMRI_Prediction_Tasks.html">188 nips-2006-Temporal and Cross-Subject Probabilistic Models for fMRI Prediction Tasks</a></p>
<p>16 0.4960537 <a title="148-lda-16" href="./nips-2006-Conditional_mean_field.html">57 nips-2006-Conditional mean field</a></p>
<p>17 0.49188042 <a title="148-lda-17" href="./nips-2006-A_Probabilistic_Algorithm_Integrating_Source_Localization_and_Noise_Suppression_of_MEG_and_EEG_data.html">12 nips-2006-A Probabilistic Algorithm Integrating Source Localization and Noise Suppression of MEG and EEG data</a></p>
<p>18 0.49047625 <a title="148-lda-18" href="./nips-2006-Recursive_ICA.html">167 nips-2006-Recursive ICA</a></p>
<p>19 0.49043703 <a title="148-lda-19" href="./nips-2006-A_Theory_of_Retinal_Population_Coding.html">16 nips-2006-A Theory of Retinal Population Coding</a></p>
<p>20 0.48832142 <a title="148-lda-20" href="./nips-2006-Context_Effects_in_Category_Learning%3A_An_Investigation_of_Four_Probabilistic_Models.html">58 nips-2006-Context Effects in Category Learning: An Investigation of Four Probabilistic Models</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
