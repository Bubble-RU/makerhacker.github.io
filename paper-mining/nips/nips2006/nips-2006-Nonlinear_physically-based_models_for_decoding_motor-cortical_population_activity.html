<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>148 nips-2006-Nonlinear physically-based models for decoding motor-cortical population activity</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2006" href="../home/nips2006_home.html">nips2006</a> <a title="nips-2006-148" href="#">nips2006-148</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>148 nips-2006-Nonlinear physically-based models for decoding motor-cortical population activity</h1>
<br/><p>Source: <a title="nips-2006-148-pdf" href="http://papers.nips.cc/paper/3050-nonlinear-physically-based-models-for-decoding-motor-cortical-population-activity.pdf">pdf</a></p><p>Author: Gregory Shakhnarovich, Sung-phil Kim, Michael J. Black</p><p>Abstract: Neural motor prostheses (NMPs) require the accurate decoding of motor cortical population activity for the control of an artiﬁcial motor system. Previous work on cortical decoding for NMPs has focused on the recovery of hand kinematics. Human NMPs however may require the control of computer cursors or robotic devices with very different physical and dynamical properties. Here we show that the ﬁring rates of cells in the primary motor cortex of non-human primates can be used to control the parameters of an artiﬁcial physical system exhibiting realistic dynamics. The model represents 2D hand motion in terms of a point mass connected to a system of idealized springs. The nonlinear spring coefﬁcients are estimated from the ﬁring rates of neurons in the motor cortex. We evaluate linear and a nonlinear decoding algorithms using neural recordings from two monkeys performing two different tasks. We found that the decoded spring coefﬁcients produced accurate hand trajectories compared with state-of-the-art methods for direct decoding of hand kinematics. Furthermore, using a physically-based system produced decoded movements that were more “natural” in that their frequency spectrum more closely matched that of natural hand movements. 1</p><p>Reference: <a title="nips-2006-148-reference" href="../nips2006_reference/nips-2006-Nonlinear_physically-based_models_for_decoding_motor-cortical_population_activity_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Nonlinear physically-based models for decoding motor-cortical population activity  Gregory Shakhnarovich Sung-Phil Kim Michael J. [sent-1, score-0.532]
</p><p>2 edu  Abstract Neural motor prostheses (NMPs) require the accurate decoding of motor cortical population activity for the control of an artiﬁcial motor system. [sent-4, score-1.796]
</p><p>3 Previous work on cortical decoding for NMPs has focused on the recovery of hand kinematics. [sent-5, score-0.654]
</p><p>4 Human NMPs however may require the control of computer cursors or robotic devices with very different physical and dynamical properties. [sent-6, score-0.395]
</p><p>5 Here we show that the ﬁring rates of cells in the primary motor cortex of non-human primates can be used to control the parameters of an artiﬁcial physical system exhibiting realistic dynamics. [sent-7, score-0.688]
</p><p>6 The model represents 2D hand motion in terms of a point mass connected to a system of idealized springs. [sent-8, score-0.229]
</p><p>7 The nonlinear spring coefﬁcients are estimated from the ﬁring rates of neurons in the motor cortex. [sent-9, score-0.609]
</p><p>8 We evaluate linear and a nonlinear decoding algorithms using neural recordings from two monkeys performing two different tasks. [sent-10, score-0.618]
</p><p>9 We found that the decoded spring coefﬁcients produced accurate hand trajectories compared with state-of-the-art methods for direct decoding of hand kinematics. [sent-11, score-0.842]
</p><p>10 Furthermore, using a physically-based system produced decoded movements that were more “natural” in that their frequency spectrum more closely matched that of natural hand movements. [sent-12, score-0.329]
</p><p>11 1  Introduction  Neural motor prostheses (NMPs) aim to restore lost motor function to people with intact cerebral motor areas who, through disease or injury, have lost the ability to control their limbs. [sent-13, score-1.138]
</p><p>12 Central to these devices is a method for decoding the ﬁring activity of motor cortical neurons to produce a voluntary control signal. [sent-14, score-1.192]
</p><p>13 A number of groups have recently demonstrated the real-time neural control of 2D or 3D computer cursors or simple robotic limbs in monkeys [1, 13, 18, 20, 22] and humans [6]. [sent-15, score-0.409]
</p><p>14 Previous work on decoding motor cortical signals however has focused on modeling the relationship between neural ﬁring rates and simple hand kinematics including hand direction, speed, position, velocity, or acceleration [2, 4, 8, 10]. [sent-16, score-1.391]
</p><p>15 While the relationship between neural ﬁring rates and hand kinematics is well established in ablebodied monkeys, the situation of a human NMP is quite different. [sent-17, score-0.41]
</p><p>16 For a paralyzed human, the NMP represents an artiﬁcial motor system with different physical properties than the intact human motor system. [sent-18, score-0.881]
</p><p>17 In particular, a human NMP may involve the control of devices as different as computer cursors or robotic wheelchairs. [sent-19, score-0.342]
</p><p>18 It remains an open question whether motor cortical neurons can successfully control such varied systems with dynamics that are quite different from human limbs. [sent-20, score-0.738]
</p><p>19 Here we propose a model that makes a ﬁrst step toward neural control of novel artiﬁcial motor systems. [sent-21, score-0.493]
</p><p>20 We show that motor cortical ﬁring rates can be nonlinearly related to the parameters of an idealized physical system. [sent-22, score-0.751]
</p><p>21 Our model decodes the dynamics of hand movement directly from the neural activity. [sent-24, score-0.418]
</p><p>22 A model incorporating direct cortical control of dynamics has been proposed in [19]. [sent-27, score-0.36]
</p><p>23 In that work, observed images were assumed to have been generated by a pen connected to a set of springs, the trajectory of the pen controlled by varying the stiffness of the springs according to a digit-speciﬁc “motor program”. [sent-34, score-0.4]
</p><p>24 The goal was to infer the motor program from an observed image, in order to classify the digit. [sent-35, score-0.362]
</p><p>25 In the context of neural decoding, the image observation is replaced with the recorded neural signal, from which we need to recover the “motor program”, and thus the intended movement. [sent-36, score-0.201]
</p><p>26 One particularly important difference is that the neural decoder may be learned in a supervised procedure, where the groud truth for the movement associated with a given neural signal is known. [sent-38, score-0.4]
</p><p>27 An advantage of this spring-based model (SBM) over previous kinematics-based decoding methods is that the realistic dynamics of the model produce smoother recovered movement. [sent-39, score-0.469]
</p><p>28 We show that the motions are more natural in that they better match the power spectrum of true hand movements. [sent-40, score-0.205]
</p><p>29 This suggests that the control of a physical system (even an artiﬁcial one) may prove more natural for a human NMP. [sent-41, score-0.303]
</p><p>30 The experimental setup we consider in this paper involves an electrode array, implanted in the arm/hand area of the MI cortex of a behaving monkey [17]. [sent-42, score-0.224]
</p><p>31 The animals are trained to control the cursor by moving the endpoint of a two-link manipulandum constrained to a plane, much like a human would use a computer mouse [11, 13]. [sent-43, score-0.424]
</p><p>32 Neural data and hand kinematics were recorded from two monkeys performing two different tasks. [sent-44, score-0.374]
</p><p>33 The data was separated into training and testing segments and we quantitatively compared a variety of popular linear and nonlinear algorithms for decoding hand kinematics and the spring coefﬁcients of our SBM. [sent-45, score-0.828]
</p><p>34 Moreover, movement reconstructed with the SBM has a power spectrum signiﬁcantly closer to that of natural movement. [sent-47, score-0.383]
</p><p>35 These results suggest that the control of idealized physical systems with real-time nonlinear decoding algorithms may form the basis for a practical human NMP. [sent-48, score-0.821]
</p><p>36 2  The spring-based model  Decoding neural activity in N cells involves estimating the values of a hidden state X(t) at time t given an observed sequence of ﬁring rates Z(0) . [sent-53, score-0.208]
</p><p>37 In contrast, direct (or discriminative) methods learn a function that maps ﬁring rates over some preceding temporal window into hand kinematics. [sent-60, score-0.18]
</p><p>38 All these previous methods have focused on direct decoding of kinematic properties of the hand movement and have ignored the arm dynamics. [sent-62, score-0.882]
</p><p>39 1  Parametrization of dynamics  Our approach to incorporating dynamics into the decoding process has been inspired by the following model of [5], sketched out in Figure 1. [sent-64, score-0.528]
</p><p>40 Without loss of generality, let the work area (that fully contains the movement range) be an axis-aligned square [−L, L] × [−L, L]. [sent-65, score-0.201]
</p><p>41 Suppose that the position of the wrist at time t is [x(t), y(t)]. [sent-71, score-0.181]
</p><p>42 Then the springs A and B apply forces determined by Hooke’s law, namely, kA (t) (L − x(t))) and −kB (t) (x(t) + L), where kA (t) and kB (t) are the stiffness coefﬁcients of A and B at time t. [sent-72, score-0.26]
</p><p>43 To reﬂect physical constraints on movement in the real world, the model presumes a point mass m in the center of the wrist (i. [sent-73, score-0.418]
</p><p>44 Furthermore, it is assumed that the movement is damped by a viscous force proportional to the instantaneous velocity, −βvx (t). [sent-76, score-0.201]
</p><p>45 In summary, according to Newton’s second law the acceleration of the hand at time t is given by m · ax (t) = kA (t) · (L − x(t)) − kB (t) · (L + x(t)) − β · vx (t),  (1)  where vx (t) is the instantaneous velocity of the wrist at time t along the x axis. [sent-78, score-0.707]
</p><p>46 Control of movement in this model is realized through varying the stiffness coefﬁcients of the springs: given the current position of the wrist x, the desired acceleration a is achieved by setting kA (t) and kB (t) so as to solve (1). [sent-79, score-0.552]
</p><p>47 We can now recover the underlying parameters K = [kA , kB , kC , kD ] for the observed movement by applying (1) at each time step as follows. [sent-83, score-0.201]
</p><p>48 First we estimate the velocities vx (t) = x(t + 1) − x(t) ˆ and accelerations ax (t) = vx (t + 1) − vx (t). [sent-84, score-0.572]
</p><p>49 Then, we substitute (2) into (1), yielding ˆ ˆ ˆ m · ax (t) + vx (t) + κ · (L + x(t)) ˆ ˆ ˆ . [sent-85, score-0.23]
</p><p>50 2  Decoding neural activity  We now turn to our main goal: inferring the desired movement from a recorded neural signal. [sent-89, score-0.483]
</p><p>51 In the training stage, we take a data set in which we have both the recorded neural signal Z(t) and the observed trajectory of hand positions X(t) associated  with that signal. [sent-91, score-0.283]
</p><p>52 For direct kinematic decoding this means inference g : Z(t) → X(t). [sent-93, score-0.543]
</p><p>53 For decoding with the SBM, this means inference of spring coefﬁcients in the SBM, g : Z(t) → K(t), followed by the calculation K(t) → X(t) as described above. [sent-94, score-0.563]
</p><p>54 The SBM formulation also requires a preprocessing step for the training data: we need to convert the observed position trajectory X to the trajectory through K, acording to (3). [sent-95, score-0.218]
</p><p>55 The linear ﬁlter (LF) approach [13] consists of modeling the mapping from ﬁring rate to movement by a linear transformation W that is applied on a concatenated ﬁring rate vector for a ﬁxed history depth l: ˜ X(t) = x0 + WZ(t), (4) where x0 is a constant (bias) term and ˜ Z(t) = ZT (t − l), . [sent-98, score-0.201]
</p><p>56 The transformation W is ﬁt to the training data by solving the least squares problem, and then used at the decoding stage to predict values of X. [sent-103, score-0.41]
</p><p>57 However, their application to the task of neural decoding has been limited to the directional center-out task [15]. [sent-112, score-0.484]
</p><p>58 Here we evaluate SV regression as a method for decoding more general 2D movement. [sent-113, score-0.41]
</p><p>59 A variety of other decoding approaches has been proposed in the literature. [sent-116, score-0.41]
</p><p>60 Our ﬁndings can be summarized as follows, for both kinematic decoding and decoding with the spring-based model. [sent-119, score-0.91]
</p><p>61 In the following section, we focus on experiments with the linear ﬁlter (the de-facto standard decoding method today) and SVM, which achieved the overall best results in our experiments. [sent-124, score-0.41]
</p><p>62 The neural signal was obtained with a Cyberkinetics microelectrode array [9] (96 electrodes) implanted in the arm/hand area of MI cortex. [sent-126, score-0.174]
</p><p>63 Sequential reaching movement , described in [13] Reach targets and a hand position feedback cursor were presented on a video screen in front of the monkey. [sent-128, score-0.549]
</p><p>64 Hand kinematics and neural activity were simultaneously recorded while the animal performed the task. [sent-139, score-0.388]
</p><p>65 when the cursor remained within the target for a duration drawn for each target randomly between 3 and 10 seconds). [sent-143, score-0.261]
</p><p>66 The recorded neural activity was converted to spike trains by computer-assisted spike-sorting software, and the spike counts were calculated in non-overlapping 70ms windows. [sent-144, score-0.27]
</p><p>67 The hand kinematics (obtained by recording the 2D position of the manipulandum) were averaged within each window, to produce an aligned representation. [sent-145, score-0.357]
</p><p>68 1  Evaluation protocol  In each of the data sets, we selected a segment of the recording to train all the decoders, and a subsequent segment to test the decoding accuracy. [sent-147, score-0.569]
</p><p>69 Tuning of parameters (the kernel parameters of the SVM or the mass and viscosity of the spring model) was done on a held-out portion of the training segment. [sent-148, score-0.196]
</p><p>70 N Power spectrum reconstruction : One of the objectives of a practical decoding algorithm, especially in the context of assistive technology, is to produce movement that appears “natural”. [sent-155, score-0.693]
</p><p>71 As a criterion for evaluating the degree of “naturalness” we use the similarity between power spectrum densities of the true movement and the reconstructed one. [sent-156, score-0.383]
</p><p>72 2  Results  The reported results for SVM were obtained with quadratic kernel, k(x, y) = (x · y + 1)2 ; the tradeoff term c was ﬁxed to 100, and the insensitivity parameter was set to 5 for the spring coefﬁcient and 2 for direct position decoding. [sent-159, score-0.27]
</p><p>73 Moreover, it is apparent that the decoding accuracy of the SBM is on par with that of the conventional kinematic decoding (the observed differences were not signiﬁcant at the 0. [sent-202, score-0.91]
</p><p>74 unit, db/sample  40  20  Figure 2: Example of power spectrum densities for true hand trajectory (dotted black), reconstruction with SVM-kinematics (dashed blue) and reconstruction with SVM-SBM (solid red). [sent-205, score-0.277]
</p><p>75 2 sec, a typical example of the movement reconstructed with SVM on kinematics versus SVM on spring coefﬁcients. [sent-219, score-0.557]
</p><p>76 The accuracy in terms of deviation from ground truth is similar, however the estimate produced by the direct kinematic decoding is signiﬁcantly more “ragged”. [sent-220, score-0.543]
</p><p>77 Quantitavely, this can be assessed by calculating the L1 norm between the power spectrum densities of the true and reconstructed hand trajectories. [sent-222, score-0.266]
</p><p>78 Table 3: Estimated L1 norm between power spectrum density of true and reconstructed trajectories. [sent-225, score-0.182]
</p><p>79 15  4  Discussion  The spring-based model proposed in this paper represents a ﬁrst attempt to directly incorporate realistic physical constraints into a neural decoding model. [sent-250, score-0.594]
</p><p>80 Our experiments illustrate that the coefﬁcients of an idealized physical system can be decoded from motor cortical ﬁring rates, without sttistically signiﬁcant loss of decoding accuracy compared to more standard direct decoding of kinematics. [sent-251, score-1.667]
</p><p>81 An advantage of such an approach is that the physical properties of the system damp high frequency motions resulting in decoded movements that inherently have the properties of natural movement, with no ad-hoc smoothing. [sent-252, score-0.273]
</p><p>82 Future work should consider more sophisticated physical models such as a simulated robotic arm and a biophysically motivated musculoskeletal system. [sent-253, score-0.285]
</p><p>83 In particular using a robotic feedback device we can simulate the physical system of springs presented here such that the monkeys control a device with the properties of our model. [sent-257, score-0.572]
</p><p>84 We hypothesize that the accuracy of decoding spring coefﬁcients from motor cortical activity in this condition will improve. [sent-258, score-1.125]
</p><p>85 This would suggest that matching the decoding model to the physical system being controlled will improve decoding accuracy. [sent-259, score-0.968]
</p><p>86 We plan to test human cursor control with kinematic and physically-based decoders. [sent-261, score-0.394]
</p><p>87 This could be a ﬁrst step toward the neural control of mechanical actuators in the physical world. [sent-263, score-0.282]
</p><p>88 Relations of motor cortex neural discharge to kinematics of passive and active elbow movements in the monkey. [sent-292, score-0.629]
</p><p>89 Probabilistic inference of hand motion from neural activity in motor cortex. [sent-302, score-0.56]
</p><p>90 Braingate neuromotor prosthesis: Nature and use of neural control signals. [sent-332, score-0.172]
</p><p>91 Primary motor cortex and free arm movements to visual targets in three-dimensional space. [sent-345, score-0.467]
</p><p>92 positional gradients and population coding of movement direction from various movement origins. [sent-347, score-0.443]
</p><p>93 Spatiotemporal tuning of motor cortical neurons for hand position and velocity. [sent-367, score-0.682]
</p><p>94 Brainmachine interface: Instant neural control of a movement signal. [sent-398, score-0.373]
</p><p>95 Statistical encoding model for a primary motor cortical brain-machine interface. [sent-412, score-0.514]
</p><p>96 Reliability of signals from a chronically implanted, silicon-based electrode array in non-human primate primary motor cortex. [sent-437, score-0.437]
</p><p>97 Direct cortical control of muscle activation in voluntary arm movements: a model. [sent-450, score-0.346]
</p><p>98 Real-time prediction of hand trajectory by ensembles of cortical neurons in primates. [sent-463, score-0.359]
</p><p>99 Bayesian population decoding of motor cortical activity using a Kalman ﬁlter. [sent-472, score-1.013]
</p><p>100 Closed-loop neural control of cursor motion using a Kalman ﬁlter. [sent-481, score-0.321]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('decoding', 0.41), ('motor', 0.321), ('ka', 0.214), ('movement', 0.201), ('sbm', 0.171), ('vx', 0.171), ('cortical', 0.16), ('ring', 0.153), ('spring', 0.153), ('springs', 0.153), ('cursor', 0.149), ('kinematics', 0.142), ('kb', 0.136), ('mae', 0.119), ('physical', 0.11), ('idealized', 0.107), ('stiffness', 0.107), ('wrist', 0.107), ('control', 0.098), ('monkeys', 0.095), ('fellows', 0.093), ('kinematic', 0.09), ('cc', 0.086), ('donoghue', 0.086), ('manipulandum', 0.086), ('nmp', 0.086), ('nmps', 0.086), ('hand', 0.084), ('spectrum', 0.082), ('activity', 0.081), ('robotic', 0.078), ('position', 0.074), ('neural', 0.074), ('trajectory', 0.072), ('coef', 0.071), ('kalman', 0.07), ('decoded', 0.068), ('cients', 0.068), ('ccx', 0.064), ('ccy', 0.064), ('cursors', 0.064), ('hatsopoulos', 0.064), ('acceleration', 0.063), ('svm', 0.062), ('reconstructed', 0.061), ('monkey', 0.06), ('dynamics', 0.059), ('ax', 0.059), ('human', 0.057), ('movements', 0.057), ('recording', 0.057), ('lter', 0.057), ('implanted', 0.056), ('target', 0.056), ('arm', 0.054), ('rates', 0.053), ('recorded', 0.053), ('velocity', 0.052), ('segment', 0.051), ('decoder', 0.051), ('kd', 0.047), ('kc', 0.047), ('neurophysiology', 0.046), ('devices', 0.045), ('array', 0.044), ('neurons', 0.043), ('direct', 0.043), ('actuator', 0.043), ('gao', 0.043), ('musculoskeletal', 0.043), ('prostheses', 0.043), ('ragged', 0.043), ('viscosity', 0.043), ('xt', 0.042), ('population', 0.041), ('program', 0.041), ('screen', 0.041), ('nonlinear', 0.039), ('electrode', 0.039), ('power', 0.039), ('system', 0.038), ('animal', 0.038), ('carmena', 0.037), ('lebedev', 0.037), ('shoham', 0.037), ('kim', 0.036), ('cortex', 0.035), ('echo', 0.034), ('pen', 0.034), ('voluntary', 0.034), ('schwartz', 0.034), ('intact', 0.034), ('bienenstock', 0.034), ('endpoint', 0.034), ('friction', 0.034), ('behaving', 0.034), ('paninski', 0.034), ('primary', 0.033), ('muscles', 0.032), ('spike', 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999893 <a title="148-tfidf-1" href="./nips-2006-Nonlinear_physically-based_models_for_decoding_motor-cortical_population_activity.html">148 nips-2006-Nonlinear physically-based models for decoding motor-cortical population activity</a></p>
<p>Author: Gregory Shakhnarovich, Sung-phil Kim, Michael J. Black</p><p>Abstract: Neural motor prostheses (NMPs) require the accurate decoding of motor cortical population activity for the control of an artiﬁcial motor system. Previous work on cortical decoding for NMPs has focused on the recovery of hand kinematics. Human NMPs however may require the control of computer cursors or robotic devices with very different physical and dynamical properties. Here we show that the ﬁring rates of cells in the primary motor cortex of non-human primates can be used to control the parameters of an artiﬁcial physical system exhibiting realistic dynamics. The model represents 2D hand motion in terms of a point mass connected to a system of idealized springs. The nonlinear spring coefﬁcients are estimated from the ﬁring rates of neurons in the motor cortex. We evaluate linear and a nonlinear decoding algorithms using neural recordings from two monkeys performing two different tasks. We found that the decoded spring coefﬁcients produced accurate hand trajectories compared with state-of-the-art methods for direct decoding of hand kinematics. Furthermore, using a physically-based system produced decoded movements that were more “natural” in that their frequency spectrum more closely matched that of natural hand movements. 1</p><p>2 0.17793776 <a title="148-tfidf-2" href="./nips-2006-Adaptive_Spatial_Filters_with_predefined_Region_of_Interest_for_EEG_based_Brain-Computer-Interfaces.html">22 nips-2006-Adaptive Spatial Filters with predefined Region of Interest for EEG based Brain-Computer-Interfaces</a></p>
<p>Author: Moritz Grosse-wentrup, Klaus Gramann, Martin Buss</p><p>Abstract: The performance of EEG-based Brain-Computer-Interfaces (BCIs) critically depends on the extraction of features from the EEG carrying information relevant for the classiﬁcation of different mental states. For BCIs employing imaginary movements of different limbs, the method of Common Spatial Patterns (CSP) has been shown to achieve excellent classiﬁcation results. The CSP-algorithm however suffers from a lack of robustness, requiring training data without artifacts for good performance. To overcome this lack of robustness, we propose an adaptive spatial ﬁlter that replaces the training data in the CSP approach by a-priori information. More speciﬁcally, we design an adaptive spatial ﬁlter that maximizes the ratio of the variance of the electric ﬁeld originating in a predeﬁned region of interest (ROI) and the overall variance of the measured EEG. Since it is known that the component of the EEG used for discriminating imaginary movements originates in the motor cortex, we design two adaptive spatial ﬁlters with the ROIs centered in the hand areas of the left and right motor cortex. We then use these to classify EEG data recorded during imaginary movements of the right and left hand of three subjects, and show that the adaptive spatial ﬁlters outperform the CSP-algorithm, enabling classiﬁcation rates of up to 94.7 % without artifact rejection. 1</p><p>3 0.14943753 <a title="148-tfidf-3" href="./nips-2006-Causal_inference_in_sensorimotor_integration.html">49 nips-2006-Causal inference in sensorimotor integration</a></p>
<p>Author: Konrad P. Körding, Joshua B. Tenenbaum</p><p>Abstract: Many recent studies analyze how data from different modalities can be combined. Often this is modeled as a system that optimally combines several sources of information about the same variable. However, it has long been realized that this information combining depends on the interpretation of the data. Two cues that are perceived by different modalities can have different causal relationships: (1) They can both have the same cause, in this case we should fully integrate both cues into a joint estimate. (2) They can have distinct causes, in which case information should be processed independently. In many cases we will not know if there is one joint cause or two independent causes that are responsible for the cues. Here we model this situation as a Bayesian estimation problem. We are thus able to explain some experiments on visual auditory cue combination as well as some experiments on visual proprioceptive cue integration. Our analysis shows that the problem solved by people when they combine cues to produce a movement is much more complicated than is usually assumed, because they need to infer the causal structure that is underlying their sensory experience.</p><p>4 0.1182742 <a title="148-tfidf-4" href="./nips-2006-Uncertainty%2C_phase_and_oscillatory_hippocampal_recall.html">197 nips-2006-Uncertainty, phase and oscillatory hippocampal recall</a></p>
<p>Author: Máté Lengyel, Peter Dayan</p><p>Abstract: Many neural areas, notably, the hippocampus, show structured, dynamical, population behavior such as coordinated oscillations. It has long been observed that such oscillations provide a substrate for representing analog information in the ﬁring phases of neurons relative to the underlying population rhythm. However, it has become increasingly clear that it is essential for neural populations to represent uncertainty about the information they capture, and the substantial recent work on neural codes for uncertainty has omitted any analysis of oscillatory systems. Here, we observe that, since neurons in an oscillatory network need not only ﬁre once in each cycle (or even at all), uncertainty about the analog quantities each neuron represents by its ﬁring phase might naturally be reported through the degree of concentration of the spikes that it ﬁres. We apply this theory to memory in a model of oscillatory associative recall in hippocampal area CA3. Although it is not well treated in the literature, representing and manipulating uncertainty is fundamental to competent memory; our theory enables us to view CA3 as an effective uncertainty-aware, retrieval system. 1</p><p>5 0.11578614 <a title="148-tfidf-5" href="./nips-2006-Multiple_timescales_and_uncertainty_in_motor_adaptation.html">141 nips-2006-Multiple timescales and uncertainty in motor adaptation</a></p>
<p>Author: Konrad P. Körding, Joshua B. Tenenbaum, Reza Shadmehr</p><p>Abstract: Our motor system changes due to causes that span multiple timescales. For example, muscle response can change because of fatigue, a condition where the disturbance has a fast timescale or because of disease where the disturbance is much slower. Here we hypothesize that the nervous system adapts in a way that reﬂects the temporal properties of such potential disturbances. According to a Bayesian formulation of this idea, movement error results in a credit assignment problem: what timescale is responsible for this disturbance? The adaptation schedule inﬂuences the behavior of the optimal learner, changing estimates at different timescales as well as the uncertainty. A system that adapts in this way predicts many properties observed in saccadic gain adaptation. It well predicts the timecourses of motor adaptation in cases of partial sensory deprivation and reversals of the adaptation direction.</p><p>6 0.11262552 <a title="148-tfidf-6" href="./nips-2006-Aggregating_Classification_Accuracy_across_Time%3A_Application_to_Single_Trial_EEG.html">24 nips-2006-Aggregating Classification Accuracy across Time: Application to Single Trial EEG</a></p>
<p>7 0.10111612 <a title="148-tfidf-7" href="./nips-2006-Large_Scale_Hidden_Semi-Markov_SVMs.html">108 nips-2006-Large Scale Hidden Semi-Markov SVMs</a></p>
<p>8 0.099499889 <a title="148-tfidf-8" href="./nips-2006-Context_dependent_amplification_of_both_rate_and_event-correlation_in_a_VLSI_network_of_spiking_neurons.html">59 nips-2006-Context dependent amplification of both rate and event-correlation in a VLSI network of spiking neurons</a></p>
<p>9 0.086340025 <a title="148-tfidf-9" href="./nips-2006-Temporal_Coding_using_the_Response_Properties_of_Spiking_Neurons.html">187 nips-2006-Temporal Coding using the Response Properties of Spiking Neurons</a></p>
<p>10 0.085171789 <a title="148-tfidf-10" href="./nips-2006-Learning_Nonparametric_Models_for_Probabilistic_Imitation.html">112 nips-2006-Learning Nonparametric Models for Probabilistic Imitation</a></p>
<p>11 0.08051914 <a title="148-tfidf-11" href="./nips-2006-Logistic_Regression_for_Single_Trial_EEG_Classification.html">126 nips-2006-Logistic Regression for Single Trial EEG Classification</a></p>
<p>12 0.077341594 <a title="148-tfidf-12" href="./nips-2006-Learning_Motion_Style_Synthesis_from_Perceptual_Observations.html">111 nips-2006-Learning Motion Style Synthesis from Perceptual Observations</a></p>
<p>13 0.077123098 <a title="148-tfidf-13" href="./nips-2006-Optimal_Change-Detection_and_Spiking_Neurons.html">154 nips-2006-Optimal Change-Detection and Spiking Neurons</a></p>
<p>14 0.069261231 <a title="148-tfidf-14" href="./nips-2006-Information_Bottleneck_Optimization_and_Independent_Component_Extraction_with_Spiking_Neurons.html">99 nips-2006-Information Bottleneck Optimization and Independent Component Extraction with Spiking Neurons</a></p>
<p>15 0.067512356 <a title="148-tfidf-15" href="./nips-2006-Blind_source_separation_for_over-determined_delayed_mixtures.html">46 nips-2006-Blind source separation for over-determined delayed mixtures</a></p>
<p>16 0.064953476 <a title="148-tfidf-16" href="./nips-2006-Real-time_adaptive_information-theoretic_optimization_of_neurophysiology_experiments.html">165 nips-2006-Real-time adaptive information-theoretic optimization of neurophysiology experiments</a></p>
<p>17 0.064091414 <a title="148-tfidf-17" href="./nips-2006-A_Nonparametric_Approach_to_Bottom-Up_Visual_Saliency.html">8 nips-2006-A Nonparametric Approach to Bottom-Up Visual Saliency</a></p>
<p>18 0.063331589 <a title="148-tfidf-18" href="./nips-2006-Reducing_Calibration_Time_For_Brain-Computer_Interfaces%3A_A_Clustering_Approach.html">168 nips-2006-Reducing Calibration Time For Brain-Computer Interfaces: A Clustering Approach</a></p>
<p>19 0.060728967 <a title="148-tfidf-19" href="./nips-2006-Efficient_Learning_of_Sparse_Representations_with_an_Energy-Based_Model.html">72 nips-2006-Efficient Learning of Sparse Representations with an Energy-Based Model</a></p>
<p>20 0.060406253 <a title="148-tfidf-20" href="./nips-2006-Unsupervised_Regression_with_Applications_to_Nonlinear_System_Identification.html">200 nips-2006-Unsupervised Regression with Applications to Nonlinear System Identification</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2006_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.186), (1, -0.157), (2, 0.068), (3, -0.041), (4, -0.203), (5, -0.084), (6, -0.001), (7, 0.026), (8, 0.011), (9, -0.02), (10, -0.063), (11, -0.035), (12, -0.117), (13, 0.023), (14, -0.042), (15, -0.049), (16, -0.074), (17, -0.053), (18, -0.081), (19, -0.029), (20, 0.047), (21, 0.018), (22, -0.073), (23, -0.005), (24, -0.015), (25, 0.048), (26, -0.113), (27, -0.029), (28, -0.017), (29, 0.067), (30, -0.059), (31, -0.129), (32, 0.228), (33, -0.157), (34, -0.154), (35, -0.117), (36, -0.056), (37, -0.109), (38, 0.091), (39, -0.122), (40, -0.053), (41, -0.131), (42, 0.008), (43, -0.007), (44, -0.02), (45, 0.04), (46, 0.017), (47, 0.041), (48, 0.071), (49, -0.114)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96092236 <a title="148-lsi-1" href="./nips-2006-Nonlinear_physically-based_models_for_decoding_motor-cortical_population_activity.html">148 nips-2006-Nonlinear physically-based models for decoding motor-cortical population activity</a></p>
<p>Author: Gregory Shakhnarovich, Sung-phil Kim, Michael J. Black</p><p>Abstract: Neural motor prostheses (NMPs) require the accurate decoding of motor cortical population activity for the control of an artiﬁcial motor system. Previous work on cortical decoding for NMPs has focused on the recovery of hand kinematics. Human NMPs however may require the control of computer cursors or robotic devices with very different physical and dynamical properties. Here we show that the ﬁring rates of cells in the primary motor cortex of non-human primates can be used to control the parameters of an artiﬁcial physical system exhibiting realistic dynamics. The model represents 2D hand motion in terms of a point mass connected to a system of idealized springs. The nonlinear spring coefﬁcients are estimated from the ﬁring rates of neurons in the motor cortex. We evaluate linear and a nonlinear decoding algorithms using neural recordings from two monkeys performing two different tasks. We found that the decoded spring coefﬁcients produced accurate hand trajectories compared with state-of-the-art methods for direct decoding of hand kinematics. Furthermore, using a physically-based system produced decoded movements that were more “natural” in that their frequency spectrum more closely matched that of natural hand movements. 1</p><p>2 0.77717084 <a title="148-lsi-2" href="./nips-2006-Causal_inference_in_sensorimotor_integration.html">49 nips-2006-Causal inference in sensorimotor integration</a></p>
<p>Author: Konrad P. Körding, Joshua B. Tenenbaum</p><p>Abstract: Many recent studies analyze how data from different modalities can be combined. Often this is modeled as a system that optimally combines several sources of information about the same variable. However, it has long been realized that this information combining depends on the interpretation of the data. Two cues that are perceived by different modalities can have different causal relationships: (1) They can both have the same cause, in this case we should fully integrate both cues into a joint estimate. (2) They can have distinct causes, in which case information should be processed independently. In many cases we will not know if there is one joint cause or two independent causes that are responsible for the cues. Here we model this situation as a Bayesian estimation problem. We are thus able to explain some experiments on visual auditory cue combination as well as some experiments on visual proprioceptive cue integration. Our analysis shows that the problem solved by people when they combine cues to produce a movement is much more complicated than is usually assumed, because they need to infer the causal structure that is underlying their sensory experience.</p><p>3 0.71400321 <a title="148-lsi-3" href="./nips-2006-Multiple_timescales_and_uncertainty_in_motor_adaptation.html">141 nips-2006-Multiple timescales and uncertainty in motor adaptation</a></p>
<p>Author: Konrad P. Körding, Joshua B. Tenenbaum, Reza Shadmehr</p><p>Abstract: Our motor system changes due to causes that span multiple timescales. For example, muscle response can change because of fatigue, a condition where the disturbance has a fast timescale or because of disease where the disturbance is much slower. Here we hypothesize that the nervous system adapts in a way that reﬂects the temporal properties of such potential disturbances. According to a Bayesian formulation of this idea, movement error results in a credit assignment problem: what timescale is responsible for this disturbance? The adaptation schedule inﬂuences the behavior of the optimal learner, changing estimates at different timescales as well as the uncertainty. A system that adapts in this way predicts many properties observed in saccadic gain adaptation. It well predicts the timecourses of motor adaptation in cases of partial sensory deprivation and reversals of the adaptation direction.</p><p>4 0.54628211 <a title="148-lsi-4" href="./nips-2006-Adaptive_Spatial_Filters_with_predefined_Region_of_Interest_for_EEG_based_Brain-Computer-Interfaces.html">22 nips-2006-Adaptive Spatial Filters with predefined Region of Interest for EEG based Brain-Computer-Interfaces</a></p>
<p>Author: Moritz Grosse-wentrup, Klaus Gramann, Martin Buss</p><p>Abstract: The performance of EEG-based Brain-Computer-Interfaces (BCIs) critically depends on the extraction of features from the EEG carrying information relevant for the classiﬁcation of different mental states. For BCIs employing imaginary movements of different limbs, the method of Common Spatial Patterns (CSP) has been shown to achieve excellent classiﬁcation results. The CSP-algorithm however suffers from a lack of robustness, requiring training data without artifacts for good performance. To overcome this lack of robustness, we propose an adaptive spatial ﬁlter that replaces the training data in the CSP approach by a-priori information. More speciﬁcally, we design an adaptive spatial ﬁlter that maximizes the ratio of the variance of the electric ﬁeld originating in a predeﬁned region of interest (ROI) and the overall variance of the measured EEG. Since it is known that the component of the EEG used for discriminating imaginary movements originates in the motor cortex, we design two adaptive spatial ﬁlters with the ROIs centered in the hand areas of the left and right motor cortex. We then use these to classify EEG data recorded during imaginary movements of the right and left hand of three subjects, and show that the adaptive spatial ﬁlters outperform the CSP-algorithm, enabling classiﬁcation rates of up to 94.7 % without artifact rejection. 1</p><p>5 0.52916282 <a title="148-lsi-5" href="./nips-2006-Large_Margin_Multi-channel_Analog-to-Digital_Conversion_with_Applications_to_Neural_Prosthesis.html">107 nips-2006-Large Margin Multi-channel Analog-to-Digital Conversion with Applications to Neural Prosthesis</a></p>
<p>Author: Amit Gore, Shantanu Chakrabartty</p><p>Abstract: A key challenge in designing analog-to-digital converters for cortically implanted prosthesis is to sense and process high-dimensional neural signals recorded by the micro-electrode arrays. In this paper, we describe a novel architecture for analog-to-digital (A/D) conversion that combines Σ∆ conversion with spatial de-correlation within a single module. The architecture called multiple-input multiple-output (MIMO) Σ∆ is based on a min-max gradient descent optimization of a regularized linear cost function that naturally lends to an A/D formulation. Using an online formulation, the architecture can adapt to slow variations in cross-channel correlations, observed due to relative motion of the microelectrodes with respect to the signal sources. Experimental results with real recorded multi-channel neural data demonstrate the effectiveness of the proposed algorithm in alleviating cross-channel redundancy across electrodes and performing data-compression directly at the A/D converter. 1</p><p>6 0.50244242 <a title="148-lsi-6" href="./nips-2006-Aggregating_Classification_Accuracy_across_Time%3A_Application_to_Single_Trial_EEG.html">24 nips-2006-Aggregating Classification Accuracy across Time: Application to Single Trial EEG</a></p>
<p>7 0.39840776 <a title="148-lsi-7" href="./nips-2006-Learning_Nonparametric_Models_for_Probabilistic_Imitation.html">112 nips-2006-Learning Nonparametric Models for Probabilistic Imitation</a></p>
<p>8 0.38822636 <a title="148-lsi-8" href="./nips-2006-An_Application_of_Reinforcement_Learning_to_Aerobatic_Helicopter_Flight.html">25 nips-2006-An Application of Reinforcement Learning to Aerobatic Helicopter Flight</a></p>
<p>9 0.38490504 <a title="148-lsi-9" href="./nips-2006-Temporal_dynamics_of_information_content_carried_by_neurons_in_the_primary_visual_cortex.html">189 nips-2006-Temporal dynamics of information content carried by neurons in the primary visual cortex</a></p>
<p>10 0.384657 <a title="148-lsi-10" href="./nips-2006-Large_Scale_Hidden_Semi-Markov_SVMs.html">108 nips-2006-Large Scale Hidden Semi-Markov SVMs</a></p>
<p>11 0.38291717 <a title="148-lsi-11" href="./nips-2006-Effects_of_Stress_and_Genotype_on_Meta-parameter_Dynamics_in_Reinforcement_Learning.html">71 nips-2006-Effects of Stress and Genotype on Meta-parameter Dynamics in Reinforcement Learning</a></p>
<p>12 0.360484 <a title="148-lsi-12" href="./nips-2006-Uncertainty%2C_phase_and_oscillatory_hippocampal_recall.html">197 nips-2006-Uncertainty, phase and oscillatory hippocampal recall</a></p>
<p>13 0.34779781 <a title="148-lsi-13" href="./nips-2006-Robotic_Grasping_of_Novel_Objects.html">170 nips-2006-Robotic Grasping of Novel Objects</a></p>
<p>14 0.3174063 <a title="148-lsi-14" href="./nips-2006-A_Theory_of_Retinal_Population_Coding.html">16 nips-2006-A Theory of Retinal Population Coding</a></p>
<p>15 0.30571118 <a title="148-lsi-15" href="./nips-2006-Combining_causal_and_similarity-based_reasoning.html">53 nips-2006-Combining causal and similarity-based reasoning</a></p>
<p>16 0.29087234 <a title="148-lsi-16" href="./nips-2006-A_selective_attention_multi--chip_system_with_dynamic_synapses_and_spiking_neurons.html">18 nips-2006-A selective attention multi--chip system with dynamic synapses and spiking neurons</a></p>
<p>17 0.28620535 <a title="148-lsi-17" href="./nips-2006-Learning_Motion_Style_Synthesis_from_Perceptual_Observations.html">111 nips-2006-Learning Motion Style Synthesis from Perceptual Observations</a></p>
<p>18 0.27319688 <a title="148-lsi-18" href="./nips-2006-Unsupervised_Regression_with_Applications_to_Nonlinear_System_Identification.html">200 nips-2006-Unsupervised Regression with Applications to Nonlinear System Identification</a></p>
<p>19 0.26044953 <a title="148-lsi-19" href="./nips-2006-Sparse_Representation_for_Signal_Classification.html">179 nips-2006-Sparse Representation for Signal Classification</a></p>
<p>20 0.25613162 <a title="148-lsi-20" href="./nips-2006-Temporal_Coding_using_the_Response_Properties_of_Spiking_Neurons.html">187 nips-2006-Temporal Coding using the Response Properties of Spiking Neurons</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2006_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(1, 0.09), (3, 0.034), (7, 0.051), (9, 0.058), (12, 0.012), (20, 0.011), (22, 0.053), (44, 0.054), (47, 0.358), (57, 0.054), (65, 0.036), (69, 0.032), (71, 0.035), (93, 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.84518772 <a title="148-lda-1" href="./nips-2006-Multiple_timescales_and_uncertainty_in_motor_adaptation.html">141 nips-2006-Multiple timescales and uncertainty in motor adaptation</a></p>
<p>Author: Konrad P. Körding, Joshua B. Tenenbaum, Reza Shadmehr</p><p>Abstract: Our motor system changes due to causes that span multiple timescales. For example, muscle response can change because of fatigue, a condition where the disturbance has a fast timescale or because of disease where the disturbance is much slower. Here we hypothesize that the nervous system adapts in a way that reﬂects the temporal properties of such potential disturbances. According to a Bayesian formulation of this idea, movement error results in a credit assignment problem: what timescale is responsible for this disturbance? The adaptation schedule inﬂuences the behavior of the optimal learner, changing estimates at different timescales as well as the uncertainty. A system that adapts in this way predicts many properties observed in saccadic gain adaptation. It well predicts the timecourses of motor adaptation in cases of partial sensory deprivation and reversals of the adaptation direction.</p><p>same-paper 2 0.80497867 <a title="148-lda-2" href="./nips-2006-Nonlinear_physically-based_models_for_decoding_motor-cortical_population_activity.html">148 nips-2006-Nonlinear physically-based models for decoding motor-cortical population activity</a></p>
<p>Author: Gregory Shakhnarovich, Sung-phil Kim, Michael J. Black</p><p>Abstract: Neural motor prostheses (NMPs) require the accurate decoding of motor cortical population activity for the control of an artiﬁcial motor system. Previous work on cortical decoding for NMPs has focused on the recovery of hand kinematics. Human NMPs however may require the control of computer cursors or robotic devices with very different physical and dynamical properties. Here we show that the ﬁring rates of cells in the primary motor cortex of non-human primates can be used to control the parameters of an artiﬁcial physical system exhibiting realistic dynamics. The model represents 2D hand motion in terms of a point mass connected to a system of idealized springs. The nonlinear spring coefﬁcients are estimated from the ﬁring rates of neurons in the motor cortex. We evaluate linear and a nonlinear decoding algorithms using neural recordings from two monkeys performing two different tasks. We found that the decoded spring coefﬁcients produced accurate hand trajectories compared with state-of-the-art methods for direct decoding of hand kinematics. Furthermore, using a physically-based system produced decoded movements that were more “natural” in that their frequency spectrum more closely matched that of natural hand movements. 1</p><p>3 0.40314838 <a title="148-lda-3" href="./nips-2006-Recursive_ICA.html">167 nips-2006-Recursive ICA</a></p>
<p>Author: Honghao Shan, Lingyun Zhang, Garrison W. Cottrell</p><p>Abstract: Independent Component Analysis (ICA) is a popular method for extracting independent features from visual data. However, as a fundamentally linear technique, there is always nonlinear residual redundancy that is not captured by ICA. Hence there have been many attempts to try to create a hierarchical version of ICA, but so far none of the approaches have a natural way to apply them more than once. Here we show that there is a relatively simple technique that transforms the absolute values of the outputs of a previous application of ICA into a normal distribution, to which ICA maybe applied again. This results in a recursive ICA algorithm that may be applied any number of times in order to extract higher order structure from previous layers. 1</p><p>4 0.40276873 <a title="148-lda-4" href="./nips-2006-Denoising_and_Dimension_Reduction_in_Feature_Space.html">65 nips-2006-Denoising and Dimension Reduction in Feature Space</a></p>
<p>Author: Mikio L. Braun, Klaus-Robert Müller, Joachim M. Buhmann</p><p>Abstract: We show that the relevant information about a classiﬁcation problem in feature space is contained up to negligible error in a ﬁnite number of leading kernel PCA components if the kernel matches the underlying learning problem. Thus, kernels not only transform data sets such that good generalization can be achieved even by linear discriminant functions, but this transformation is also performed in a manner which makes economic use of feature space dimensions. In the best case, kernels provide efﬁcient implicit representations of the data to perform classiﬁcation. Practically, we propose an algorithm which enables us to recover the subspace and dimensionality relevant for good classiﬁcation. Our algorithm can therefore be applied (1) to analyze the interplay of data set and kernel in a geometric fashion, (2) to help in model selection, and to (3) de-noise in feature space in order to yield better classiﬁcation results. 1</p><p>5 0.39918783 <a title="148-lda-5" href="./nips-2006-Generalized_Maximum_Margin_Clustering_and_Unsupervised_Kernel_Learning.html">83 nips-2006-Generalized Maximum Margin Clustering and Unsupervised Kernel Learning</a></p>
<p>Author: Hamed Valizadegan, Rong Jin</p><p>Abstract: Maximum margin clustering was proposed lately and has shown promising performance in recent studies [1, 2]. It extends the theory of support vector machine to unsupervised learning. Despite its good performance, there are three major problems with maximum margin clustering that question its eﬃciency for real-world applications. First, it is computationally expensive and diﬃcult to scale to large-scale datasets because the number of parameters in maximum margin clustering is quadratic in the number of examples. Second, it requires data preprocessing to ensure that any clustering boundary will pass through the origins, which makes it unsuitable for clustering unbalanced dataset. Third, it is sensitive to the choice of kernel functions, and requires external procedure to determine the appropriate values for the parameters of kernel functions. In this paper, we propose “generalized maximum margin clustering” framework that addresses the above three problems simultaneously. The new framework generalizes the maximum margin clustering algorithm by allowing any clustering boundaries including those not passing through the origins. It signiﬁcantly improves the computational eﬃciency by reducing the number of parameters. Furthermore, the new framework is able to automatically determine the appropriate kernel matrix without any labeled data. Finally, we show a formal connection between maximum margin clustering and spectral clustering. We demonstrate the eﬃciency of the generalized maximum margin clustering algorithm using both synthetic datasets and real datasets from the UCI repository. 1</p><p>6 0.39586619 <a title="148-lda-6" href="./nips-2006-Simplifying_Mixture_Models_through_Function_Approximation.html">175 nips-2006-Simplifying Mixture Models through Function Approximation</a></p>
<p>7 0.39575335 <a title="148-lda-7" href="./nips-2006-Temporal_Coding_using_the_Response_Properties_of_Spiking_Neurons.html">187 nips-2006-Temporal Coding using the Response Properties of Spiking Neurons</a></p>
<p>8 0.3953425 <a title="148-lda-8" href="./nips-2006-Causal_inference_in_sensorimotor_integration.html">49 nips-2006-Causal inference in sensorimotor integration</a></p>
<p>9 0.39530382 <a title="148-lda-9" href="./nips-2006-Graph_Laplacian_Regularization_for_Large-Scale_Semidefinite_Programming.html">87 nips-2006-Graph Laplacian Regularization for Large-Scale Semidefinite Programming</a></p>
<p>10 0.39492705 <a title="148-lda-10" href="./nips-2006-Analysis_of_Empirical_Bayesian_Methods_for_Neuroelectromagnetic_Source_Localization.html">32 nips-2006-Analysis of Empirical Bayesian Methods for Neuroelectromagnetic Source Localization</a></p>
<p>11 0.3942709 <a title="148-lda-11" href="./nips-2006-Emergence_of_conjunctive_visual_features_by_quadratic_independent_component_analysis.html">76 nips-2006-Emergence of conjunctive visual features by quadratic independent component analysis</a></p>
<p>12 0.39380279 <a title="148-lda-12" href="./nips-2006-PG-means%3A_learning_the_number_of_clusters_in_data.html">158 nips-2006-PG-means: learning the number of clusters in data</a></p>
<p>13 0.39378703 <a title="148-lda-13" href="./nips-2006-Stratification_Learning%3A_Detecting_Mixed_Density_and_Dimensionality_in_High_Dimensional_Point_Clouds.html">184 nips-2006-Stratification Learning: Detecting Mixed Density and Dimensionality in High Dimensional Point Clouds</a></p>
<p>14 0.39295569 <a title="148-lda-14" href="./nips-2006-A_Complexity-Distortion_Approach_to_Joint_Pattern_Alignment.html">3 nips-2006-A Complexity-Distortion Approach to Joint Pattern Alignment</a></p>
<p>15 0.39281377 <a title="148-lda-15" href="./nips-2006-Predicting_spike_times_from_subthreshold_dynamics_of_a_neuron.html">162 nips-2006-Predicting spike times from subthreshold dynamics of a neuron</a></p>
<p>16 0.39267123 <a title="148-lda-16" href="./nips-2006-MLLE%3A_Modified_Locally_Linear_Embedding_Using_Multiple_Weights.html">127 nips-2006-MLLE: Modified Locally Linear Embedding Using Multiple Weights</a></p>
<p>17 0.39255732 <a title="148-lda-17" href="./nips-2006-Real-time_adaptive_information-theoretic_optimization_of_neurophysiology_experiments.html">165 nips-2006-Real-time adaptive information-theoretic optimization of neurophysiology experiments</a></p>
<p>18 0.39134133 <a title="148-lda-18" href="./nips-2006-Information_Bottleneck_Optimization_and_Independent_Component_Extraction_with_Spiking_Neurons.html">99 nips-2006-Information Bottleneck Optimization and Independent Component Extraction with Spiking Neurons</a></p>
<p>19 0.38997492 <a title="148-lda-19" href="./nips-2006-Clustering_Under_Prior_Knowledge_with_Application_to_Image_Segmentation.html">51 nips-2006-Clustering Under Prior Knowledge with Application to Image Segmentation</a></p>
<p>20 0.38961139 <a title="148-lda-20" href="./nips-2006-Active_learning_for_misspecified_generalized_linear_models.html">20 nips-2006-Active learning for misspecified generalized linear models</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
