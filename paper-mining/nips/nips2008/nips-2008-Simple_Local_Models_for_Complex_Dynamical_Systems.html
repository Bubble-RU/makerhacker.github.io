<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>211 nips-2008-Simple Local Models for Complex Dynamical Systems</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-211" href="#">nips2008-211</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>211 nips-2008-Simple Local Models for Complex Dynamical Systems</h1>
<br/><p>Source: <a title="nips-2008-211-pdf" href="http://papers.nips.cc/paper/3503-simple-local-models-for-complex-dynamical-systems.pdf">pdf</a></p><p>Author: Erik Talvitie, Satinder P. Singh</p><p>Abstract: We present a novel mathematical formalism for the idea of a “local model” of an uncontrolled dynamical system, a model that makes only certain predictions in only certain situations. As a result of its restricted responsibilities, a local model may be far simpler than a complete model of the system. We then show how one might combine several local models to produce a more detailed model. We demonstrate our ability to learn a collection of local models on a large-scale example and do a preliminary empirical comparison of learning a collection of local models and some other model learning methods. 1</p><p>Reference: <a title="nips-2008-211-reference" href="../nips2008_reference/nips-2008-Simple_Local_Models_for_Complex_Dynamical_Systems_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract We present a novel mathematical formalism for the idea of a “local model” of an uncontrolled dynamical system, a model that makes only certain predictions in only certain situations. [sent-3, score-0.339]
</p><p>2 We demonstrate our ability to learn a collection of local models on a large-scale example and do a preliminary empirical comparison of learning a collection of local models and some other model learning methods. [sent-6, score-0.573]
</p><p>3 It can be much simpler to answer abstract questions like “Where will the ball bounce? [sent-11, score-0.344]
</p><p>4 We call sequences of observations tests and let T be the set of all possible tests of all lengths. [sent-31, score-0.808]
</p><p>5 The set of all def histories H is deﬁned: H = {t ∈ T : p(t|φ) > 0} ∪ {φ}. [sent-50, score-0.365]
</p><p>6 A union test T ⊆ T is a set of tests such that if t ∈ T then no preﬁx of t is in T . [sent-60, score-0.491]
</p><p>7 The measure of complexity that we will adopt is called the linear dimension [6] and is deﬁned as the rank of the “system dynamics matrix” (the inﬁnite matrix of predictions whose ij th entry is p(tj |hi ) for all tj ∈ T and hi ∈ H). [sent-64, score-0.419]
</p><p>8 2  Local Models  In contrast to a complete model, a local model has limited prediction responsibilities and hence makes only certain predictions in certain situations. [sent-68, score-0.482]
</p><p>9 Given a set of tests of interest T I and a set of histories of interest HI , a local model is any model that generates the predictions of interest: p(t|h) for all t ∈ T I and h ∈ HI . [sent-70, score-1.365]
</p><p>10 We will assume, in general, that the tests of interest are union tests. [sent-71, score-0.589]
</p><p>11 A set of histories of interest HI is semi-Markov iff h, h′ ∈ HI ∪ {φ} and ht ∈ HI for some t ∈ T , implies that either h′ t ∈ HI or p(h′ t|φ) = 0. [sent-75, score-0.493]
</p><p>12 The ball moves along the line, changing direction when it hits the edge. [sent-78, score-0.365]
</p><p>13 Figure 1: 1D Ball Bounce  One natural local model would make one-step predictions about only one pixel, p. [sent-82, score-0.419]
</p><p>14 It has two tests of interest: the set of all one-step tests in which the pixel p is black, and the set of all one-step tests in which p is white. [sent-83, score-1.278]
</p><p>15 This local model answers the question “What is the chance the ball will be in pixel p next? [sent-85, score-0.597]
</p><p>16 Another, even more restricted local model would be one that has the same tests of interest, but whose histories of interest are only those that end with pixel p being black. [sent-88, score-1.137]
</p><p>17 This local model would essentially answer the question “When the ball is in pixel p, what is the chance that it will stick? [sent-89, score-0.627]
</p><p>18 ” In order to make this prediction, the local model can ignore all detail; the prediction for the test of interest is always 0. [sent-90, score-0.421]
</p><p>19 In general, as in the examples above, we expect that many details about the world are irrelevant to making the predictions of interest and could be ignored in order to simplify the local model. [sent-93, score-0.511]
</p><p>20 [10], given tests and histories of interest, we will show how to convert a primitive observation sequence into an 2  abstract observation sequence that ignores unnecessary detail. [sent-97, score-0.926]
</p><p>21 A complete model of the abstracted system can be used as a local model in the original, primitive system. [sent-98, score-0.509]
</p><p>22 First, we construct an intermediate system which makes predictions for all tests, but only updates at histories of interest. [sent-100, score-0.607]
</p><p>23 Then we further abstract the system by ignoring details irrelevant to making predictions for just the tests of interest. [sent-101, score-0.716]
</p><p>24 1  Abstracting Details for Local Predictions  Incorporating Histories Of Interest: Intuitively, since a local model is never asked to make a prediction at a history outside of HI , one way to simplify it is to only update its predictions at histories of interest. [sent-103, score-0.882]
</p><p>25 Essentially, it “wakes up” whenever a history of interest occurs, sees what observation sequence happened since it was last awake, updates, and then goes dormant until the next history of interest. [sent-104, score-0.463]
</p><p>26 We call the sequences of observations that happen between histories of interest bridging tests. [sent-105, score-0.899]
</p><p>27 The set of bridging tests T B is induced by the set of histories of interest. [sent-106, score-1.092]
</p><p>28 A test t ∈ T is a bridging test iff for all j < |t|, and all h ∈ HI , ht[1. [sent-108, score-0.493]
</p><p>29 Conceptually, we transform the primitive observation sequence into a sequence of abstract observations in which each observation corresponds to a bridging test. [sent-115, score-0.678]
</p><p>30 Note that even when the primitive system has a small number of observations, the T E system can have inﬁnitely many, because there can be an inﬁnity of bridging tests. [sent-117, score-0.714]
</p><p>31 However, because it does not Figure 2: Mapping experience in the original update between histories of interest, a model of T E system to experience in the TE system, and may be simpler than a model of the original system. [sent-118, score-0.582]
</p><p>32 This system has linear dimension O(2k), intuitively because the ball has 2 possible directions and k possible positions. [sent-121, score-0.416]
</p><p>33 The bridging tests, then, are all possible ways the ball could travel to an edge and back. [sent-123, score-0.679]
</p><p>34 The probability of each bridging test depends only on the current direction of the ball. [sent-124, score-0.431]
</p><p>35 If the linear dimension of a dynamical system is n then, given a semi-Markov set of histories of interest HI , the linear dimension of the induced T E system, nT E ≤ n. [sent-128, score-0.674]
</p><p>36 (Sketch) The linear dimension of a system is the rank of the system dynamics matrix (SDM) corresponding to the system [6]. [sent-130, score-0.383]
</p><p>37 The matrix corresponding to the T E system is the submatrix of the SDM of the original system with only columns and rows corresponding to histories and tests that are sequences of bridging tests. [sent-131, score-1.334]
</p><p>38 We next show that a model of the TE system can make predictions for all tests t ∈ T in all histories of interest h ∈ HI . [sent-134, score-1.186]
</p><p>39 Speciﬁcally, we show that the prediction for any test in a history of interest can be expressed as a prediction of a union test in T E. [sent-135, score-0.458]
</p><p>40 For the following, note that every history of interest h ∈ HI can be written as a corresponding sequence of bridging tests, which we will call sh . [sent-136, score-0.775]
</p><p>41 Also, we will use the subscript T E to distinguish predictions pT E (t|h) in T E from predictions p(t|h) in the original system. [sent-137, score-0.384]
</p><p>42 First suppose t can be written as a sequence of bridging tests st . [sent-142, score-0.878]
</p><p>43 If t does not correspond to a sequence of bridging tests, we can re-write it as the concatenation of two tests: t = t1 t2 such that t1 is the longest preﬁx of t that is a sequence of bridging tests (which may be null) and t2 ∈ T B . [sent-144, score-1.254]
</p><p>44 To calculate p(t2 |ht1 ) note that 3  def  there must be a set of bridging tests Bt2 which have t2 as a preﬁx: Bt2 = {b ∈ T B : b[1. [sent-147, score-0.845]
</p><p>45 The probability of seeing t2 is the probability of seeing any of the bridging tests in Bt2 . [sent-151, score-0.786]
</p><p>46 Since tests of interest are union tests, to make the prediction of interest p(T |h) for some T ∈ T I and h ∈ HI using a model of T E, we have simply p(T |h) = pT E (ST |sh ) = t∈T pT E (St |sh ). [sent-154, score-0.822]
</p><p>47 A model of T E is simpler than a complete model of the system because it only makes predictions at histories of interest. [sent-155, score-0.747]
</p><p>48 We can further simplify our modeling task by focusing on predicting the tests of interest. [sent-157, score-0.384]
</p><p>49 Since all histories are of interest, bridging tests are single observations, and T E is exactly equivalent to the original system. [sent-159, score-1.092]
</p><p>50 However, note that in order to make the predictions of interest, one must only know whether the ball is neighboring or on the pixel. [sent-160, score-0.502]
</p><p>51 So, we need only distinguish observations in which the ball is nearby, and we can group the rest into one abstract observation: “the ball is far from the pixel. [sent-161, score-0.594]
</p><p>52 ” In general we will attempt to abstract away unnecessary details of bridging tests by aliasing bridging tests that are equivalent with respect to making the predictions of interest. [sent-162, score-1.764]
</p><p>53 Speciﬁcally, we will deﬁne a partition, or a many-to-one mapping, from T E observations (the bridging tests T B ) to abstract observations A. [sent-163, score-0.866]
</p><p>54 We will then use a model of the abstract system with A as its observations (see Figure 2) as our local model. [sent-164, score-0.343]
</p><p>55 So, A must have the following properties: (1) we must be able to express the tests of interest as a union of sequences of abstract observations in A and (2) an abstracted history must contain enough detail to make accurate predictions for the tests of interest. [sent-165, score-1.451]
</p><p>56 We assume that tests of interest are unions of one-step tests (i. [sent-168, score-0.924]
</p><p>57 One natural example that satisﬁes this assumption is where the local model makes one-step predictions for a particular dimension of a vector-valued observation. [sent-171, score-0.416]
</p><p>58 There is no fundamental barrier to treating tests of interest that are arbitrary union tests, but the development of the general case is more complex. [sent-172, score-0.589]
</p><p>59 Note that if a union test T ⊂ O, then the equivalent T E union test, ST , consists of every bridging def test that begins with an observation in T . [sent-173, score-0.739]
</p><p>60 So, if T I partitions O, then S I ={ST : T ∈ T I } partitions B the bridging tests, T , according to their ﬁrst observation. [sent-174, score-0.402]
</p><p>61 For instance, in our 1D Ball Bounce, in order to make accurate predictions for one pixel it does not sufﬁce to observe that pixel and ignore the rest. [sent-177, score-0.527]
</p><p>62 An observation abstraction A is accurate with respect to T I iff for any two primitive histories h1 = o1 . [sent-182, score-0.584]
</p><p>63 The system we are abstracting is T E, so the observations are bridging tests. [sent-189, score-0.58]
</p><p>64 Furthermore, an accurate reﬁnement is one that only aliases two histories if they result in the same predictions for the tests of interest. [sent-192, score-0.932]
</p><p>65 Thus, we can use an abstract history to make exactly the same predictions for the tests of interest that we would make if we had access to the primitive history. [sent-193, score-0.982]
</p><p>66 If the linear dimension of a dynamical system is n then the linear dimension of any local model M, nM ≤ nT E ≤ n. [sent-197, score-0.435]
</p><p>67 4  Learning a local model: We are given tests and histories of interest and an accurate abstraction. [sent-201, score-1.026]
</p><p>68 To learn a local model, we ﬁrst translate the primitive trajectories into T E trajectories using the histories of interest, and then translate the T E trajectories into abstract trajectories using the accurate abstraction (as in Figure 2). [sent-202, score-0.852]
</p><p>69 Each local model M ∈ M has tests of interest TM , I histories of interest HM , and is an exact model of the abstract system induced by a given accurate def I reﬁnement, AM . [sent-207, score-1.391]
</p><p>70 At any history h, the set of models Mh = {M ∈ M : h ∈ HM } is available to make predictions for their tests of interest. [sent-208, score-0.789]
</p><p>71 However, we may wish to make predictions that are not speciﬁcally of interest to any local model. [sent-209, score-0.511]
</p><p>72 We will make a modeling assumption that allows us to efﬁciently combine the predictions of local models:  Deﬁnition 7. [sent-211, score-0.414]
</p><p>73 i=1 A domain expert specifying the structure of a collection of local models should strive to satisfy this property as best as possible since, given this assumption, a collection of local models can be used to make many more predictions than can be made by each individual model. [sent-219, score-0.763]
</p><p>74 We can compute the predictions of ﬁner-grained tests (intersections of tests of interest) by multiplying predictions together. [sent-220, score-1.152]
</p><p>75 We can also compute the predictions of unions of tests of interest using the standard formula: Pr(A ∪ B) = Pr(A) + Pr(B) − Pr(A ∩ B). [sent-221, score-0.732]
</p><p>76 At any history h for which Mh = ∅, a collection of local models can be used to make predictions for any union test that can be constructed by unioning/intersecting the tests of interest of the models in Mh . [sent-222, score-1.292]
</p><p>77 A collection of local models can selectively focus on making the most important predictions well, ignoring or approximating less important predictions to save on representational complexity. [sent-225, score-0.684]
</p><p>78 As such, if every one-step test is expressible as an intersection of tests of interest of models in Mh at every h, then M is a complete model. [sent-238, score-0.686]
</p><p>79 If it does not, predictions made using M will be approximate, even if each local model in M makes its predictions of interest exactly. [sent-240, score-0.705]
</p><p>80 When learning a collection of local models in this paper, we assume that tests and histories of interest as well as an accurate reﬁnement for each model are given. [sent-242, score-1.171]
</p><p>81 Automatically splitting a system into simple local models is an interesting, challenging problem, and ripe ground for future research. [sent-245, score-0.329]
</p><p>82 Thus our structural assumptions can be veriﬁed using statistical tests on the data while DBN assumptions cannot be directly veriﬁed. [sent-252, score-0.384]
</p><p>83 These distributions are like local models that make one-step predictions about their variable. [sent-255, score-0.445]
</p><p>84 Update rules are essentially local models with pre and post-conditions playing the roles of histories and tests of interest. [sent-263, score-0.959]
</p><p>85 In the image is a 2 × 2 pixel ball and a wall of 6 × 4 pixel bricks. [sent-275, score-0.529]
</p><p>86 After the ball hits a brick, the brick disappears. [sent-276, score-0.516]
</p><p>87 When the ball hits the bottom wall, it bounces at a randomly selected angle. [sent-277, score-0.365]
</p><p>88 ” After the ball hits a dark brick, all bricks require two hits rather than one to break. [sent-280, score-0.604]
</p><p>89 After the ball hits a light brick, all bricks require only one hit to break. [sent-281, score-0.552]
</p><p>90 Quite naturally, we have local models to predict how the bricks (rows 1-2), the ball (row 3), and the background (row 4) will behave. [sent-288, score-0.648]
</p><p>91 This structure satisﬁes the mutual conditional independence property, and since every pixel is predicted by some model at every history, we can make fully detailed 64× 42 pixel one-step predictions. [sent-289, score-0.411]
</p><p>92 To take advantage of this, for each type of local model 1 Note: there are 30 bricks b, 2,688 pixels p, 2,183 possible positions p for the ball, and 9 possible directions d the ball could come from, including the case in the ﬁrst step, where the ball simply appears in a pixel. [sent-295, score-0.943]
</p><p>93 (12 in total, since there is a ball model for each of the 9 directions) we combine all translated trajectories associated with various positions and use them to train a single shared model. [sent-307, score-0.387]
</p><p>94 Our learned local models were ﬁrst-order Markov except the one responsible for predicting what will happen to a brick when the ball hits it. [sent-314, score-0.76]
</p><p>95 We learned a model of the 1D Ball Bounce of size 5 and 20 using two collections of local models with no parameter tying (using PSRs and POMDPs as local models respectively), two ﬂat models (a PSR and a POMDP), and a DBN 2 . [sent-333, score-0.645]
</p><p>96 One predicts the color of the pixel in the next time step in histories when the ball is not in the immediate neighborhood about the pixel. [sent-335, score-0.751]
</p><p>97 The other model applies when the ball is in the pixel. [sent-337, score-0.335]
</p><p>98 This model distinguishes bridging tests in which the ball went to the left, the right, or stayed on the pixel in the ﬁrst step. [sent-339, score-1.262]
</p><p>99 This collection of local models satisﬁes the mutual conditional independence property and allows prediction of primitive one-step tests. [sent-340, score-0.44]
</p><p>100 The collections of local models both perform well, outperforming the ﬂat models (dashed lines). [sent-352, score-0.336]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('bridging', 0.402), ('tests', 0.384), ('histories', 0.306), ('ball', 0.277), ('predictions', 0.192), ('hi', 0.171), ('local', 0.159), ('brick', 0.151), ('bricks', 0.151), ('satinder', 0.147), ('psr', 0.134), ('interest', 0.127), ('pixel', 0.126), ('history', 0.119), ('dbn', 0.119), ('bounce', 0.117), ('oi', 0.113), ('system', 0.109), ('pomdp', 0.095), ('primitive', 0.094), ('episodes', 0.094), ('nement', 0.094), ('hits', 0.088), ('talvitie', 0.084), ('union', 0.078), ('sdm', 0.075), ('dynamical', 0.072), ('sh', 0.068), ('arcade', 0.067), ('psrs', 0.067), ('abstraction', 0.063), ('models', 0.061), ('mh', 0.061), ('st', 0.059), ('def', 0.059), ('collections', 0.055), ('wolfe', 0.054), ('pt', 0.054), ('tying', 0.054), ('accurate', 0.05), ('pre', 0.049), ('relational', 0.049), ('collection', 0.049), ('trajectories', 0.045), ('abstracted', 0.044), ('singh', 0.044), ('pixels', 0.044), ('color', 0.042), ('game', 0.041), ('uncontrolled', 0.04), ('observations', 0.04), ('independence', 0.039), ('prediction', 0.038), ('observation', 0.038), ('distinguishes', 0.038), ('dbns', 0.038), ('simpler', 0.037), ('hit', 0.036), ('erik', 0.036), ('model', 0.035), ('pomdps', 0.034), ('te', 0.034), ('britton', 0.034), ('soni', 0.034), ('complete', 0.033), ('world', 0.033), ('make', 0.033), ('sequence', 0.033), ('iff', 0.033), ('hm', 0.033), ('pr', 0.031), ('ignoring', 0.031), ('combine', 0.03), ('dimension', 0.03), ('experience', 0.03), ('answer', 0.03), ('markov', 0.029), ('unions', 0.029), ('abstracting', 0.029), ('michael', 0.029), ('test', 0.029), ('james', 0.028), ('observable', 0.027), ('ht', 0.027), ('toolkit', 0.027), ('happened', 0.027), ('nir', 0.027), ('every', 0.026), ('likelihood', 0.026), ('rank', 0.026), ('predictive', 0.026), ('responsibilities', 0.025), ('daphne', 0.025), ('happen', 0.024), ('submatrix', 0.024), ('dogs', 0.024), ('intelligence', 0.023), ('re', 0.023), ('state', 0.023), ('applies', 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="211-tfidf-1" href="./nips-2008-Simple_Local_Models_for_Complex_Dynamical_Systems.html">211 nips-2008-Simple Local Models for Complex Dynamical Systems</a></p>
<p>Author: Erik Talvitie, Satinder P. Singh</p><p>Abstract: We present a novel mathematical formalism for the idea of a “local model” of an uncontrolled dynamical system, a model that makes only certain predictions in only certain situations. As a result of its restricted responsibilities, a local model may be far simpler than a complete model of the system. We then show how one might combine several local models to produce a more detailed model. We demonstrate our ability to learn a collection of local models on a large-scale example and do a preliminary empirical comparison of learning a collection of local models and some other model learning methods. 1</p><p>2 0.11887159 <a title="211-tfidf-2" href="./nips-2008-Multi-Agent_Filtering_with_Infinitely_Nested_Beliefs.html">141 nips-2008-Multi-Agent Filtering with Infinitely Nested Beliefs</a></p>
<p>Author: Luke Zettlemoyer, Brian Milch, Leslie P. Kaelbling</p><p>Abstract: In partially observable worlds with many agents, nested beliefs are formed when agents simultaneously reason about the unknown state of the world and the beliefs of the other agents. The multi-agent ﬁltering problem is to efﬁciently represent and update these beliefs through time as the agents act in the world. In this paper, we formally deﬁne an inﬁnite sequence of nested beliefs about the state of the world at the current time t, and present a ﬁltering algorithm that maintains a ﬁnite representation which can be used to generate these beliefs. In some cases, this representation can be updated exactly in constant time; we also present a simple approximation scheme to compact beliefs if they become too complex. In experiments, we demonstrate efﬁcient ﬁltering in a range of multi-agent domains. 1</p><p>3 0.061469372 <a title="211-tfidf-3" href="./nips-2008-Domain_Adaptation_with_Multiple_Sources.html">65 nips-2008-Domain Adaptation with Multiple Sources</a></p>
<p>Author: Yishay Mansour, Mehryar Mohri, Afshin Rostamizadeh</p><p>Abstract: This paper presents a theoretical analysis of the problem of domain adaptation with multiple sources. For each source domain, the distribution over the input points as well as a hypothesis with error at most ǫ are given. The problem consists of combining these hypotheses to derive a hypothesis with small error with respect to the target domain. We present several theoretical results relating to this problem. In particular, we prove that standard convex combinations of the source hypotheses may in fact perform very poorly and that, instead, combinations weighted by the source distributions beneﬁt from favorable theoretical guarantees. Our main result shows that, remarkably, for any ﬁxed target function, there exists a distribution weighted combining rule that has a loss of at most ǫ with respect to any target mixture of the source distributions. We further generalize the setting from a single target function to multiple consistent target functions and show the existence of a combining rule with error at most 3ǫ. Finally, we report empirical results for a multiple source adaptation problem with a real-world dataset.</p><p>4 0.059290122 <a title="211-tfidf-4" href="./nips-2008-Multi-task_Gaussian_Process_Learning_of_Robot_Inverse_Dynamics.html">146 nips-2008-Multi-task Gaussian Process Learning of Robot Inverse Dynamics</a></p>
<p>Author: Christopher Williams, Stefan Klanke, Sethu Vijayakumar, Kian M. Chai</p><p>Abstract: The inverse dynamics problem for a robotic manipulator is to compute the torques needed at the joints to drive it along a given trajectory; it is beneﬁcial to be able to learn this function for adaptive control. A robotic manipulator will often need to be controlled while holding different loads in its end effector, giving rise to a multi-task learning problem. By placing independent Gaussian process priors over the latent functions of the inverse dynamics, we obtain a multi-task Gaussian process prior for handling multiple loads, where the inter-task similarity depends on the underlying inertial parameters. Experiments demonstrate that this multi-task formulation is effective in sharing information among the various loads, and generally improves performance over either learning only on single tasks or pooling the data over all tasks. 1</p><p>5 0.058011163 <a title="211-tfidf-5" href="./nips-2008-Playing_Pinball_with_non-invasive_BCI.html">180 nips-2008-Playing Pinball with non-invasive BCI</a></p>
<p>Author: Matthias Krauledat, Konrad Grzeska, Max Sagebaum, Benjamin Blankertz, Carmen Vidaurre, Klaus-Robert Müller, Michael Schröder</p><p>Abstract: Compared to invasive Brain-Computer Interfaces (BCI), non-invasive BCI systems based on Electroencephalogram (EEG) signals have not been applied successfully for precisely timed control tasks. In the present study, however, we demonstrate and report on the interaction of subjects with a real device: a pinball machine. Results of this study clearly show that fast and well-timed control well beyond chance level is possible, even though the environment is extremely rich and requires precisely timed and complex predictive behavior. Using machine learning methods for mental state decoding, BCI-based pinball control is possible within the ﬁrst session without the necessity to employ lengthy subject training. The current study shows clearly that very compelling control with excellent timing and dynamics is possible for a non-invasive BCI. 1</p><p>6 0.057313543 <a title="211-tfidf-6" href="./nips-2008-Using_Bayesian_Dynamical_Systems_for_Motion_Template_Libraries.html">247 nips-2008-Using Bayesian Dynamical Systems for Motion Template Libraries</a></p>
<p>7 0.057061736 <a title="211-tfidf-7" href="./nips-2008-From_Online_to_Batch_Learning_with_Cutoff-Averaging.html">88 nips-2008-From Online to Batch Learning with Cutoff-Averaging</a></p>
<p>8 0.056534622 <a title="211-tfidf-8" href="./nips-2008-Policy_Search_for_Motor_Primitives_in_Robotics.html">181 nips-2008-Policy Search for Motor Primitives in Robotics</a></p>
<p>9 0.055562444 <a title="211-tfidf-9" href="./nips-2008-Particle_Filter-based_Policy_Gradient_in_POMDPs.html">177 nips-2008-Particle Filter-based Policy Gradient in POMDPs</a></p>
<p>10 0.055154499 <a title="211-tfidf-10" href="./nips-2008-Learning_to_Use_Working_Memory_in_Partially_Observable_Environments_through_Dopaminergic_Reinforcement.html">121 nips-2008-Learning to Use Working Memory in Partially Observable Environments through Dopaminergic Reinforcement</a></p>
<p>11 0.055125259 <a title="211-tfidf-11" href="./nips-2008-Modeling_human_function_learning_with_Gaussian_processes.html">138 nips-2008-Modeling human function learning with Gaussian processes</a></p>
<p>12 0.054744966 <a title="211-tfidf-12" href="./nips-2008-Hierarchical_Fisher_Kernels_for_Longitudinal_Data.html">97 nips-2008-Hierarchical Fisher Kernels for Longitudinal Data</a></p>
<p>13 0.05274022 <a title="211-tfidf-13" href="./nips-2008-Finding_Latent_Causes_in_Causal_Networks%3A_an_Efficient_Approach_Based_on_Markov_Blankets.html">86 nips-2008-Finding Latent Causes in Causal Networks: an Efficient Approach Based on Markov Blankets</a></p>
<p>14 0.05071095 <a title="211-tfidf-14" href="./nips-2008-Estimation_of_Information_Theoretic_Measures_for_Continuous_Random_Variables.html">76 nips-2008-Estimation of Information Theoretic Measures for Continuous Random Variables</a></p>
<p>15 0.050534677 <a title="211-tfidf-15" href="./nips-2008-A_Convergent_%24O%28n%29%24_Temporal-difference_Algorithm_for_Off-policy_Learning_with_Linear_Function_Approximation.html">1 nips-2008-A Convergent $O(n)$ Temporal-difference Algorithm for Off-policy Learning with Linear Function Approximation</a></p>
<p>16 0.049764626 <a title="211-tfidf-16" href="./nips-2008-Integrating_Locally_Learned_Causal_Structures_with_Overlapping_Variables.html">108 nips-2008-Integrating Locally Learned Causal Structures with Overlapping Variables</a></p>
<p>17 0.04945042 <a title="211-tfidf-17" href="./nips-2008-Performance_analysis_for_L%5C_2_kernel_classification.html">178 nips-2008-Performance analysis for L\ 2 kernel classification</a></p>
<p>18 0.048657525 <a title="211-tfidf-18" href="./nips-2008-Evaluating_probabilities_under_high-dimensional_latent_variable_models.html">77 nips-2008-Evaluating probabilities under high-dimensional latent variable models</a></p>
<p>19 0.048580874 <a title="211-tfidf-19" href="./nips-2008-Non-stationary_dynamic_Bayesian_networks.html">152 nips-2008-Non-stationary dynamic Bayesian networks</a></p>
<p>20 0.047602594 <a title="211-tfidf-20" href="./nips-2008-The_Infinite_Factorial_Hidden_Markov_Model.html">234 nips-2008-The Infinite Factorial Hidden Markov Model</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2008_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.15), (1, 0.054), (2, 0.042), (3, -0.041), (4, 0.054), (5, -0.008), (6, 0.015), (7, 0.053), (8, 0.063), (9, 0.016), (10, 0.006), (11, 0.057), (12, 0.028), (13, -0.003), (14, 0.015), (15, 0.015), (16, -0.014), (17, -0.028), (18, -0.064), (19, 0.067), (20, 0.02), (21, -0.022), (22, 0.058), (23, 0.082), (24, 0.103), (25, -0.051), (26, -0.019), (27, 0.012), (28, 0.087), (29, 0.087), (30, 0.072), (31, 0.055), (32, 0.037), (33, -0.017), (34, -0.003), (35, -0.1), (36, 0.13), (37, 0.072), (38, -0.014), (39, 0.043), (40, -0.065), (41, -0.039), (42, 0.113), (43, 0.008), (44, -0.002), (45, 0.012), (46, -0.059), (47, 0.05), (48, -0.072), (49, 0.073)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93505287 <a title="211-lsi-1" href="./nips-2008-Simple_Local_Models_for_Complex_Dynamical_Systems.html">211 nips-2008-Simple Local Models for Complex Dynamical Systems</a></p>
<p>Author: Erik Talvitie, Satinder P. Singh</p><p>Abstract: We present a novel mathematical formalism for the idea of a “local model” of an uncontrolled dynamical system, a model that makes only certain predictions in only certain situations. As a result of its restricted responsibilities, a local model may be far simpler than a complete model of the system. We then show how one might combine several local models to produce a more detailed model. We demonstrate our ability to learn a collection of local models on a large-scale example and do a preliminary empirical comparison of learning a collection of local models and some other model learning methods. 1</p><p>2 0.74300432 <a title="211-lsi-2" href="./nips-2008-Multi-Agent_Filtering_with_Infinitely_Nested_Beliefs.html">141 nips-2008-Multi-Agent Filtering with Infinitely Nested Beliefs</a></p>
<p>Author: Luke Zettlemoyer, Brian Milch, Leslie P. Kaelbling</p><p>Abstract: In partially observable worlds with many agents, nested beliefs are formed when agents simultaneously reason about the unknown state of the world and the beliefs of the other agents. The multi-agent ﬁltering problem is to efﬁciently represent and update these beliefs through time as the agents act in the world. In this paper, we formally deﬁne an inﬁnite sequence of nested beliefs about the state of the world at the current time t, and present a ﬁltering algorithm that maintains a ﬁnite representation which can be used to generate these beliefs. In some cases, this representation can be updated exactly in constant time; we also present a simple approximation scheme to compact beliefs if they become too complex. In experiments, we demonstrate efﬁcient ﬁltering in a range of multi-agent domains. 1</p><p>3 0.61232424 <a title="211-lsi-3" href="./nips-2008-Bayesian_Model_of_Behaviour_in_Economic_Games.html">33 nips-2008-Bayesian Model of Behaviour in Economic Games</a></p>
<p>Author: Debajyoti Ray, Brooks King-casas, P. R. Montague, Peter Dayan</p><p>Abstract: Classical game theoretic approaches that make strong rationality assumptions have difﬁculty modeling human behaviour in economic games. We investigate the role of ﬁnite levels of iterated reasoning and non-selﬁsh utility functions in a Partially Observable Markov Decision Process model that incorporates game theoretic notions of interactivity. Our generative model captures a broad class of characteristic behaviours in a multi-round Investor-Trustee game. We invert the generative process for a recognition model that is used to classify 200 subjects playing this game against randomly matched opponents. 1</p><p>4 0.57041621 <a title="211-lsi-4" href="./nips-2008-Skill_Characterization_Based_on_Betweenness.html">212 nips-2008-Skill Characterization Based on Betweenness</a></p>
<p>Author: Ozgur Simsek, Andre S. Barreto</p><p>Abstract: We present a characterization of a useful class of skills based on a graphical representation of an agent’s interaction with its environment. Our characterization uses betweenness, a measure of centrality on graphs. It captures and generalizes (at least intuitively) the bottleneck concept, which has inspired many of the existing skill-discovery algorithms. Our characterization may be used directly to form a set of skills suitable for a given task. More importantly, it serves as a useful guide for developing incremental skill-discovery algorithms that do not rely on knowing or representing the interaction graph in its entirety. 1</p><p>5 0.50872856 <a title="211-lsi-5" href="./nips-2008-Kernel_Change-point_Analysis.html">111 nips-2008-Kernel Change-point Analysis</a></p>
<p>Author: Zaïd Harchaoui, Eric Moulines, Francis R. Bach</p><p>Abstract: We introduce a kernel-based method for change-point analysis within a sequence of temporal observations. Change-point analysis of an unlabelled sample of observations consists in, ﬁrst, testing whether a change in the distribution occurs within the sample, and second, if a change occurs, estimating the change-point instant after which the distribution of the observations switches from one distribution to another different distribution. We propose a test statistic based upon the maximum kernel Fisher discriminant ratio as a measure of homogeneity between segments. We derive its limiting distribution under the null hypothesis (no change occurs), and establish the consistency under the alternative hypothesis (a change occurs). This allows to build a statistical hypothesis testing procedure for testing the presence of a change-point, with a prescribed false-alarm probability and detection probability tending to one in the large-sample setting. If a change actually occurs, the test statistic also yields an estimator of the change-point location. Promising experimental results in temporal segmentation of mental tasks from BCI data and pop song indexation are presented. 1</p><p>6 0.46440205 <a title="211-lsi-6" href="./nips-2008-Kernel-ARMA_for_Hand_Tracking_and_Brain-Machine_interfacing_During_3D_Motor_Control.html">110 nips-2008-Kernel-ARMA for Hand Tracking and Brain-Machine interfacing During 3D Motor Control</a></p>
<p>7 0.46048325 <a title="211-lsi-7" href="./nips-2008-Probabilistic_detection_of_short_events%2C_with_application_to_critical_care_monitoring.html">186 nips-2008-Probabilistic detection of short events, with application to critical care monitoring</a></p>
<p>8 0.4427951 <a title="211-lsi-8" href="./nips-2008-From_Online_to_Batch_Learning_with_Cutoff-Averaging.html">88 nips-2008-From Online to Batch Learning with Cutoff-Averaging</a></p>
<p>9 0.43517512 <a title="211-lsi-9" href="./nips-2008-Online_Models_for_Content_Optimization.html">169 nips-2008-Online Models for Content Optimization</a></p>
<p>10 0.43278149 <a title="211-lsi-10" href="./nips-2008-The_Mondrian_Process.html">236 nips-2008-The Mondrian Process</a></p>
<p>11 0.43186679 <a title="211-lsi-11" href="./nips-2008-Local_Gaussian_Process_Regression_for_Real_Time_Online_Model_Learning.html">125 nips-2008-Local Gaussian Process Regression for Real Time Online Model Learning</a></p>
<p>12 0.42686966 <a title="211-lsi-12" href="./nips-2008-Learning_a_discriminative_hidden_part_model_for_human_action_recognition.html">119 nips-2008-Learning a discriminative hidden part model for human action recognition</a></p>
<p>13 0.41986629 <a title="211-lsi-13" href="./nips-2008-A_rational_model_of_preference_learning_and_choice_prediction_by_children.html">10 nips-2008-A rational model of preference learning and choice prediction by children</a></p>
<p>14 0.41228008 <a title="211-lsi-14" href="./nips-2008-Integrating_Locally_Learned_Causal_Structures_with_Overlapping_Variables.html">108 nips-2008-Integrating Locally Learned Causal Structures with Overlapping Variables</a></p>
<p>15 0.41173494 <a title="211-lsi-15" href="./nips-2008-Hierarchical_Semi-Markov_Conditional_Random_Fields_for_Recursive_Sequential_Data.html">98 nips-2008-Hierarchical Semi-Markov Conditional Random Fields for Recursive Sequential Data</a></p>
<p>16 0.40797392 <a title="211-lsi-16" href="./nips-2008-Finding_Latent_Causes_in_Causal_Networks%3A_an_Efficient_Approach_Based_on_Markov_Blankets.html">86 nips-2008-Finding Latent Causes in Causal Networks: an Efficient Approach Based on Markov Blankets</a></p>
<p>17 0.40280759 <a title="211-lsi-17" href="./nips-2008-Nonlinear_causal_discovery_with_additive_noise_models.html">153 nips-2008-Nonlinear causal discovery with additive noise models</a></p>
<p>18 0.39969805 <a title="211-lsi-18" href="./nips-2008-Adapting_to_a_Market_Shock%3A_Optimal_Sequential_Market-Making.html">13 nips-2008-Adapting to a Market Shock: Optimal Sequential Market-Making</a></p>
<p>19 0.39563027 <a title="211-lsi-19" href="./nips-2008-Multi-resolution_Exploration_in_Continuous_Spaces.html">144 nips-2008-Multi-resolution Exploration in Continuous Spaces</a></p>
<p>20 0.38494954 <a title="211-lsi-20" href="./nips-2008-Playing_Pinball_with_non-invasive_BCI.html">180 nips-2008-Playing Pinball with non-invasive BCI</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2008_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(4, 0.021), (6, 0.056), (7, 0.058), (12, 0.067), (15, 0.013), (28, 0.227), (44, 0.207), (54, 0.014), (57, 0.081), (59, 0.023), (63, 0.032), (77, 0.038), (78, 0.012), (83, 0.063)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.86089903 <a title="211-lda-1" href="./nips-2008-Bayesian_Exponential_Family_PCA.html">31 nips-2008-Bayesian Exponential Family PCA</a></p>
<p>Author: Shakir Mohamed, Zoubin Ghahramani, Katherine A. Heller</p><p>Abstract: Principal Components Analysis (PCA) has become established as one of the key tools for dimensionality reduction when dealing with real valued data. Approaches such as exponential family PCA and non-negative matrix factorisation have successfully extended PCA to non-Gaussian data types, but these techniques fail to take advantage of Bayesian inference and can suffer from problems of overﬁtting and poor generalisation. This paper presents a fully probabilistic approach to PCA, which is generalised to the exponential family, based on Hybrid Monte Carlo sampling. We describe the model which is based on a factorisation of the observed data matrix, and show performance of the model on both synthetic and real data. 1</p><p>same-paper 2 0.85255998 <a title="211-lda-2" href="./nips-2008-Simple_Local_Models_for_Complex_Dynamical_Systems.html">211 nips-2008-Simple Local Models for Complex Dynamical Systems</a></p>
<p>Author: Erik Talvitie, Satinder P. Singh</p><p>Abstract: We present a novel mathematical formalism for the idea of a “local model” of an uncontrolled dynamical system, a model that makes only certain predictions in only certain situations. As a result of its restricted responsibilities, a local model may be far simpler than a complete model of the system. We then show how one might combine several local models to produce a more detailed model. We demonstrate our ability to learn a collection of local models on a large-scale example and do a preliminary empirical comparison of learning a collection of local models and some other model learning methods. 1</p><p>3 0.7814545 <a title="211-lda-3" href="./nips-2008-A_Scalable_Hierarchical_Distributed_Language_Model.html">4 nips-2008-A Scalable Hierarchical Distributed Language Model</a></p>
<p>Author: Andriy Mnih, Geoffrey E. Hinton</p><p>Abstract: Neural probabilistic language models (NPLMs) have been shown to be competitive with and occasionally superior to the widely-used n-gram language models. The main drawback of NPLMs is their extremely long training and testing times. Morin and Bengio have proposed a hierarchical language model built around a binary tree of words, which was two orders of magnitude faster than the nonhierarchical model it was based on. However, it performed considerably worse than its non-hierarchical counterpart in spite of using a word tree created using expert knowledge. We introduce a fast hierarchical language model along with a simple feature-based algorithm for automatic construction of word trees from the data. We then show that the resulting models can outperform non-hierarchical neural models as well as the best n-gram models. 1</p><p>4 0.7805773 <a title="211-lda-4" href="./nips-2008-Temporal_Dynamics_of_Cognitive_Control.html">231 nips-2008-Temporal Dynamics of Cognitive Control</a></p>
<p>Author: Jeremy Reynolds, Michael C. Mozer</p><p>Abstract: Cognitive control refers to the ﬂexible deployment of memory and attention in response to task demands and current goals. Control is often studied experimentally by presenting sequences of stimuli, some demanding a response, and others modulating the stimulus-response mapping. In these tasks, participants must maintain information about the current stimulus-response mapping in working memory. Prominent theories of cognitive control use recurrent neural nets to implement working memory, and optimize memory utilization via reinforcement learning. We present a novel perspective on cognitive control in which working memory representations are intrinsically probabilistic, and control operations that maintain and update working memory are dynamically determined via probabilistic inference. We show that our model provides a parsimonious account of behavioral and neuroimaging data, and suggest that it offers an elegant conceptualization of control in which behavior can be cast as optimal, subject to limitations on learning and the rate of information processing. Moreover, our model provides insight into how task instructions can be directly translated into appropriate behavior and then efﬁciently reﬁned with subsequent task experience. 1</p><p>5 0.77456808 <a title="211-lda-5" href="./nips-2008-Learning_Hybrid_Models_for_Image_Annotation_with_Partially_Labeled_Data.html">116 nips-2008-Learning Hybrid Models for Image Annotation with Partially Labeled Data</a></p>
<p>Author: Xuming He, Richard S. Zemel</p><p>Abstract: Extensive labeled data for image annotation systems, which learn to assign class labels to image regions, is difﬁcult to obtain. We explore a hybrid model framework for utilizing partially labeled data that integrates a generative topic model for image appearance with discriminative label prediction. We propose three alternative formulations for imposing a spatial smoothness prior on the image labels. Tests of the new models and some baseline approaches on three real image datasets demonstrate the effectiveness of incorporating the latent structure. 1</p><p>6 0.77414685 <a title="211-lda-6" href="./nips-2008-Partially_Observed_Maximum_Entropy_Discrimination_Markov_Networks.html">176 nips-2008-Partially Observed Maximum Entropy Discrimination Markov Networks</a></p>
<p>7 0.77265936 <a title="211-lda-7" href="./nips-2008-Learning_Transformational_Invariants_from_Natural_Movies.html">118 nips-2008-Learning Transformational Invariants from Natural Movies</a></p>
<p>8 0.77225637 <a title="211-lda-8" href="./nips-2008-Modeling_human_function_learning_with_Gaussian_processes.html">138 nips-2008-Modeling human function learning with Gaussian processes</a></p>
<p>9 0.77221423 <a title="211-lda-9" href="./nips-2008-Kernelized_Sorting.html">113 nips-2008-Kernelized Sorting</a></p>
<p>10 0.77196324 <a title="211-lda-10" href="./nips-2008-Continuously-adaptive_discretization_for_message-passing_algorithms.html">50 nips-2008-Continuously-adaptive discretization for message-passing algorithms</a></p>
<p>11 0.77176332 <a title="211-lda-11" href="./nips-2008-Relative_Performance_Guarantees_for_Approximate_Inference_in_Latent_Dirichlet_Allocation.html">197 nips-2008-Relative Performance Guarantees for Approximate Inference in Latent Dirichlet Allocation</a></p>
<p>12 0.77101338 <a title="211-lda-12" href="./nips-2008-Regularized_Policy_Iteration.html">195 nips-2008-Regularized Policy Iteration</a></p>
<p>13 0.7708866 <a title="211-lda-13" href="./nips-2008-Clustering_via_LP-based_Stabilities.html">48 nips-2008-Clustering via LP-based Stabilities</a></p>
<p>14 0.7704789 <a title="211-lda-14" href="./nips-2008-Model_Selection_in_Gaussian_Graphical_Models%3A_High-Dimensional_Consistency_of_%5Cboldmath%24%5Cell_1%24-regularized_MLE.html">135 nips-2008-Model Selection in Gaussian Graphical Models: High-Dimensional Consistency of \boldmath$\ell 1$-regularized MLE</a></p>
<p>15 0.76997817 <a title="211-lda-15" href="./nips-2008-Semi-supervised_Learning_with_Weakly-Related_Unlabeled_Data_%3A_Towards_Better_Text_Categorization.html">205 nips-2008-Semi-supervised Learning with Weakly-Related Unlabeled Data : Towards Better Text Categorization</a></p>
<p>16 0.76925296 <a title="211-lda-16" href="./nips-2008-Using_Bayesian_Dynamical_Systems_for_Motion_Template_Libraries.html">247 nips-2008-Using Bayesian Dynamical Systems for Motion Template Libraries</a></p>
<p>17 0.76836777 <a title="211-lda-17" href="./nips-2008-Human_Active_Learning.html">101 nips-2008-Human Active Learning</a></p>
<p>18 0.76674038 <a title="211-lda-18" href="./nips-2008-Robust_Near-Isometric_Matching_via_Structured_Learning_of_Graphical_Models.html">201 nips-2008-Robust Near-Isometric Matching via Structured Learning of Graphical Models</a></p>
<p>19 0.76635057 <a title="211-lda-19" href="./nips-2008-Supervised_Exponential_Family_Principal_Component_Analysis_via_Convex_Optimization.html">227 nips-2008-Supervised Exponential Family Principal Component Analysis via Convex Optimization</a></p>
<p>20 0.7660743 <a title="211-lda-20" href="./nips-2008-Unsupervised_Learning_of_Visual_Sense_Models_for_Polysemous_Words.html">246 nips-2008-Unsupervised Learning of Visual Sense Models for Polysemous Words</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
