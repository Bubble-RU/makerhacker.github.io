<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>90 nips-2008-Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-90" href="#">nips2008-90</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>90 nips-2008-Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity</h1>
<br/><p>Source: <a title="nips-2008-90-pdf" href="http://papers.nips.cc/paper/3494-gaussian-process-factor-analysis-for-low-dimensional-single-trial-analysis-of-neural-population-activity.pdf">pdf</a></p><p>Author: Byron M. Yu, John P. Cunningham, Gopal Santhanam, Stephen I. Ryu, Krishna V. Shenoy, Maneesh Sahani</p><p>Abstract: We consider the problem of extracting smooth, low-dimensional neural trajectories that summarize the activity recorded simultaneously from tens to hundreds of neurons on individual experimental trials. Current methods for extracting neural trajectories involve a two-stage process: the data are ﬁrst “denoised” by smoothing over time, then a static dimensionality reduction technique is applied. We ﬁrst describe extensions of the two-stage methods that allow the degree of smoothing to be chosen in a principled way, and account for spiking variability that may vary both across neurons and across time. We then present a novel method for extracting neural trajectories, Gaussian-process factor analysis (GPFA), which uniﬁes the smoothing and dimensionality reduction operations in a common probabilistic framework. We applied these methods to the activity of 61 neurons recorded simultaneously in macaque premotor and motor cortices during reach planning and execution. By adopting a goodness-of-ﬁt metric that measures how well the activity of each neuron can be predicted by all other recorded neurons, we found that GPFA provided a better characterization of the population activity than the two-stage methods. 1</p><p>Reference: <a title="nips-2008-90-reference" href="../nips2008_reference/nips-2008-Gaussian-process_factor_analysis_for_low-dimensional_single-trial_analysis_of_neural_population_activity_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity Byron M. [sent-1, score-0.25]
</p><p>2 uk  Abstract We consider the problem of extracting smooth, low-dimensional neural trajectories that summarize the activity recorded simultaneously from tens to hundreds of neurons on individual experimental trials. [sent-9, score-0.579]
</p><p>3 Current methods for extracting neural trajectories involve a two-stage process: the data are ﬁrst “denoised” by smoothing over time, then a static dimensionality reduction technique is applied. [sent-10, score-0.492]
</p><p>4 We ﬁrst describe extensions of the two-stage methods that allow the degree of smoothing to be chosen in a principled way, and account for spiking variability that may vary both across neurons and across time. [sent-11, score-0.332]
</p><p>5 We then present a novel method for extracting neural trajectories, Gaussian-process factor analysis (GPFA), which uniﬁes the smoothing and dimensionality reduction operations in a common probabilistic framework. [sent-12, score-0.39]
</p><p>6 We applied these methods to the activity of 61 neurons recorded simultaneously in macaque premotor and motor cortices during reach planning and execution. [sent-13, score-0.521]
</p><p>7 By adopting a goodness-of-ﬁt metric that measures how well the activity of each neuron can be predicted by all other recorded neurons, we found that GPFA provided a better characterization of the population activity than the two-stage methods. [sent-14, score-0.536]
</p><p>8 1  Introduction  Neural responses are typically studied by averaging noisy spiking activity across multiple experimental trials to obtain ﬁring rates that vary smoothly over time. [sent-15, score-0.251]
</p><p>9 However, particularly in cognitive tasks (such as motor planning or decision making) where the neural responses are more a reﬂection of internal processing rather than external stimulus drive, the timecourse of the neural responses may differ on nominally identical trials. [sent-16, score-0.233]
</p><p>10 The approach adopted by recent studies is to consider each neuron being recorded as a noisy sensor reﬂecting the timeevolution of an underlying neural process [3, 5, 6, 7, 8, 9, 10]. [sent-19, score-0.287]
</p><p>11 The goal is to uncover this neural process by extracting a smooth, low-dimensional neural trajectory from the noisy, high-dimensional recorded activity on a single-trial basis. [sent-20, score-0.56]
</p><p>12 The neural trajectory provides a compact representation of 1  the high-dimensional recorded activity as it evolves over time, thereby facilitating data visualization and studies of neural dynamics under different experimental conditions. [sent-21, score-0.563]
</p><p>13 A common method to extract neural trajectories is to ﬁrst estimate a smooth ﬁring rate proﬁle for each neuron on a single trial (e. [sent-22, score-0.317]
</p><p>14 , by convolving each spike train with a Gaussian kernel), then apply a static dimensionality reduction technique (e. [sent-24, score-0.212]
</p><p>15 Numerous linear and non-linear dimensionality reduction techniques exist, but to our knowledge only PCA [8, 9, 11] and locally linear embedding (LLE) [6, 7, 10, 14] have been applied in this context to neural data. [sent-28, score-0.207]
</p><p>16 While this two-stage method of performing smoothing then dimensionality reduction has provided informative low-dimensional views of neural population activity, there are several aspects that can be improved. [sent-29, score-0.352]
</p><p>17 Even if a probabilistic dimensionality reduction algorithm is used, the likelihoods would not be comparable because different smoothing kernels yield different smoothed data. [sent-33, score-0.268]
</p><p>18 (ii) The same kernel width is typically used for all spike trains, which implicitly assumes that the neural population activity evolves with a single timescale. [sent-34, score-0.45]
</p><p>19 (iii) PCA and LLE have no explicit noise model and, therefore, have difﬁculty distinguishing between spiking noise (whose variance may vary both across neurons and across time) and changes in the underlying lowdimensional neural state. [sent-36, score-0.408]
</p><p>20 (iv) Because the smoothing and dimensionality reduction are performed sequentially, there is no way for the dimensionality reduction algorithm to inﬂuence the degree or form of smoothing used. [sent-37, score-0.497]
</p><p>21 For (i), we adopt a goodness-of-ﬁt metric that measures how well the activity of each neuron can be predicted by the activity of all other recorded neurons, based on data not used for model ﬁtting. [sent-40, score-0.522]
</p><p>22 This metric can be used to compare different smoothing kernels and allows for the degree of smoothness to be chosen in a principled way. [sent-41, score-0.238]
</p><p>23 In Section 6, we will use this as a common metric by which different methods for extracting neural trajectories are compared. [sent-42, score-0.272]
</p><p>24 For (iii), we can apply the square-root transform to stabilize the spiking noise variance and factor analysis (FA) [15] to explicitly model possibly different independent noise variances for different neurons. [sent-43, score-0.18]
</p><p>25 Next, we introduce Gaussian-process factor analysis (GPFA), which uniﬁes the smoothing and dimensionality reduction operations in a common probabilistic framework. [sent-45, score-0.256]
</p><p>26 GPFA takes steps toward addressing all of the issues (i)–(iv) described above, and is shown in Section 6 to provide a better characterization of the recorded population activity than the two-stage methods. [sent-46, score-0.302]
</p><p>27 Because GPFA performs the smoothing and dimensionality reduction operations simultaneously rather than sequentially, the degree of smoothness and the relationship between the low-dimensional neural trajectory and the high-dimensional recorded activity can be jointly optimized. [sent-47, score-0.801]
</p><p>28 Different dimensions in the low-dimensional space (within which the neural state evolves) can have different timescales, whose optimal values can be found automatically by ﬁtting the GPFA model to the recorded activity. [sent-48, score-0.366]
</p><p>29 As in FA, GPFA speciﬁes an explicit noise model that allows different neurons to have different independent noise variances. [sent-49, score-0.184]
</p><p>30 The time series model involves Gaussian processes (GP), which only require the speciﬁcation of the correlation structure of the neural state over time. [sent-50, score-0.159]
</p><p>31 A critical assumption when attempting to extract a low-dimensional neural trajectory is that the recorded activity evolves within a low-dimensional manifold. [sent-51, score-0.513]
</p><p>32 Previous studies have typically assumed that the neural trajectories lie in a three-dimensional space for ease of visualization. [sent-52, score-0.186]
</p><p>33 After describing the experimental setup in Section 5, we apply the  2  developed methods to neural activity recorded in premotor and motor cortices during reach planning and execution in Section 6. [sent-56, score-0.527]
</p><p>34 2  Gaussian-process factor analysis  The motivation for GPFA can be traced back to the use of PCA for extracting informative lowdimensional views of high-dimensional neural data. [sent-57, score-0.161]
</p><p>35 Second, PCA assumes that the spiking noise variance is time independent; however, neurons are known to change their ﬁring rates, and therefore noise variances, over time. [sent-62, score-0.207]
</p><p>36 As will be shown in Section 6, the square-rooted counts can be better characterized by further replacing PCA/PPCA with FA [15], which allows different neurons to have different independent noise variances. [sent-68, score-0.18]
</p><p>37 Extracting a smooth, low-dimensional neural trajectory can therefore be viewed as a compromise between the low-dimensional projection of each data point found by FA and the desire to string them together using a smooth function over time. [sent-76, score-0.19]
</p><p>38 Let y:,t ∈ Rq×1 be the high-dimensional vector of square-rooted spike counts recorded at timepoint t ∈ {1, . [sent-79, score-0.353]
</p><p>39 , T }, where q is the number of neurons being recorded simultaneously. [sent-82, score-0.212]
</p><p>40 We seek to extract a corresponding low-dimensional latent neural state x:,t ∈ Rp×1 at each timepoint, where p is the dimensionality of the state space (p < q). [sent-83, score-0.302]
</p><p>41 For notational convenience, we group the neural states from all timepoints into a neural trajectory denoted by the matrix X = [x:,1 , . [sent-84, score-0.298]
</p><p>42 The neural states x:,t at different timepoints are related through Gaussian processes, which embody the notion that the neural trajectories should be smooth. [sent-96, score-0.323]
</p><p>43 The form of the GP covariance can be chosen to provide different smoothing properties on the neural trajectories. [sent-101, score-0.258]
</p><p>44 The SE covariance 2 is deﬁned by its signal variance σf,i ∈ R+ , characteristic timescale τi ∈ R+ , and noise variance 2 σn,i ∈ R+ . [sent-106, score-0.166]
</p><p>45 By direct analogy to FA, we deﬁned the prior 2 2 distribution of the neural state x:,t at each timepoint t to be N (0, I) by setting σf,i = 1 − σn,i , 2 2 where 0 < σn,i ≤ 1. [sent-108, score-0.228]
</p><p>46 Note that the degree of smoothness (deﬁned by the timescales) and the relationship between the low-dimensional neural trajectory and the high-dimensional recorded activity (deﬁned by C) are jointly optimized. [sent-116, score-0.545]
</p><p>47 Although the learned timescales were initialization-dependent, their distributions were similar for different initializations. [sent-119, score-0.173]
</p><p>48 In particular, most learned timescales were less than 150 ms, but there were usually one or two larger timescales around 300 and 500 ms. [sent-120, score-0.32]
</p><p>49 Applying the singular value decomposition, Cx:,t can be rewritten as UC (DC VC x:,t ), where ˜ the columns of UC ∈ Rq×p are orthonormal and x:,t = DC VC x:,t ∈ Rp×1 is referred to as the orthonormalized neural state at timepoint t. [sent-122, score-0.519]
</p><p>50 Especially when the number of state dimensions p is large, the ordering facilitates the identiﬁcation and visualization of the dimensions of the orthonormalized neural trajectory that are most important for explaining the recorded activity. [sent-126, score-0.784]
</p><p>51 Because the columns of UC are orthonormal, one can readily picture how the low-dimensional trajectory relates to the high-dimensional space of recorded activity, in much the same spirit as for PCA. [sent-127, score-0.213]
</p><p>52 Neither the classic approach of comparing cross-validated likelihoods nor the Bayesian approach of comparing marginal likelihoods is applicable here, for the same reason that they cannot be used to select the appropriate degree of smoothness in the two-stage methods. [sent-131, score-0.167]
</p><p>53 The idea is to leave out one neuron at a time and ask how well each method is able to predict the activity of that neuron, given the activity of all other recorded neurons. [sent-134, score-0.464]
</p><p>54 For GPFA, the model prediction for neuron ˆ j is yj,: = E [yj,: | Y−j,: ], where yj,: is the jth row of Y and Y−j,: ∈ R(q−1)×T represents all but 4  the jth row of Y . [sent-135, score-0.218]
</p><p>55 The prediction error is deﬁned as the sum-of-squared errors between the model prediction and the observed square-rooted spike count across all neurons and timepoints. [sent-138, score-0.287]
</p><p>56 One can ﬁrst estimate the neural trajectory using all but the jth neuron P (X | Y−j,: ), then map this estimate ˆ back out into the space of recorded activity for the jth neuron using (1) to obtain yj,: . [sent-140, score-0.646]
</p><p>57 Equivalently, one can convert P (X | Y−j,: ) into its orthonormalized form before mapping it out into the space of recorded activity using the jth row of UC . [sent-141, score-0.597]
</p><p>58 Because the orthonormalized dimensions are ordered, ˜ we can evaluate the prediction error using only the top p orthonormalized dimensions of x:,t , where ˜ p ∈ {1, . [sent-142, score-0.77]
</p><p>59 This reduced GPFA model can make use of a larger number p of timescales than its ˜ effective dimensionality p. [sent-146, score-0.25]
</p><p>60 ˜  4  Linear and non-linear dynamical systems  Another way to extract neural trajectories is by deﬁning a parametric dynamical model that describes how the low-dimensional neural state evolves over time. [sent-147, score-0.552]
</p><p>61 In contrast, the GP approach described in Section 2 requires only the speciﬁcation of the covariance structure, thus allowing different smoothing properties to be applied in a seamless way. [sent-157, score-0.206]
</p><p>62 5  Behavioral task and neural recordings  The details of the neural recordings and behavioral task can be found elsewhere [22]. [sent-168, score-0.166]
</p><p>63 Neural activity was recorded using a 96-electrode array (Cyberkinetics, Foxborough, MA) in dorsal premotor and motor cortices. [sent-172, score-0.336]
</p><p>64 Only those units (61 single and multi-units, experiment G20040123) with robust delay period activity were included in our analyses. [sent-173, score-0.168]
</p><p>65 For reduced GPFA, the horizontal axis corresponds to p rather than p, where the prediction error is com˜ puted using only the top p orthonormalized dimensions of a ˜ GPFA model ﬁt with p = 15. [sent-178, score-0.43]
</p><p>66 Analyses in this ﬁgure are based on 56 trials for the reach target at distance 60 mm and direction 135°. [sent-180, score-0.165]
</p><p>67 Results  We considered neural data for one reach target at a time, ranging from 200 ms before reach target onset to movement end. [sent-181, score-0.458]
</p><p>68 This period comprised the 200 ms pre-target time, the randomly chosen delay period (200–700 ms), the monkey’s reaction time (mean±s. [sent-182, score-0.153]
</p><p>69 Spike counts were taken in non-overlapping 20 ms bins, then square-rooted. [sent-185, score-0.176]
</p><p>70 We also considered smoothing spike trains directly, which yielded qualitatively similar results for the two-stage methods. [sent-187, score-0.197]
</p><p>71 1 shows the prediction error for PPCA (red) and FA (green) for different kernel widths and state dimensionalities. [sent-190, score-0.167]
</p><p>72 First, FA yielded lower prediction error than PPCA across a range of kernel widths and state dimensionalities. [sent-192, score-0.225]
</p><p>73 Second, for these data, the optimal smoothing kernel width (s. [sent-194, score-0.189]
</p><p>74 It is tempting to try to relate this optimal smoothing kernel width (40 ms) to the timescales τi learned by GPFA, since the SE covariance has the same shape as the Gaussian smoothing kernel. [sent-199, score-0.537]
</p><p>75 However, nearly all of the timescales learned by GPFA are greater than 40 ms. [sent-200, score-0.173]
</p><p>76 This apparent mismatch can be understood by considering the equivalent kernel of the SE covariance [23], which takes on a sinclike shape whose main lobe is generally far narrower than a Gaussian kernel with the same width parameter. [sent-201, score-0.188]
</p><p>77 It is therefore reasonable that the timescales learned by GPFA are larger than the optimal smoothing kernel width. [sent-202, score-0.321]
</p><p>78 Furthermore, GPFA (dashed black) performed as well or better than the two-stage methods and the ﬁrst-order AR model, regardless of the state dimensionality or kernel width used. [sent-208, score-0.214]
</p><p>79 As described in Section 3, the prediction error can also be computed for a reduced GPFA model (solid black) using only the top p orthonormalized dimensions, in this ˜ case based on a GPFA model ﬁt with p = 15 state dimensions. [sent-209, score-0.434]
</p><p>80 Thus, removing the lowest ﬁve orthonormalized dimensions decreased the GPFA prediction error. [sent-212, score-0.407]
</p><p>81 These latter ﬁndings can be understood by examining the orthonormalized neural trajectories extracted by GPFA shown in Fig. [sent-214, score-0.477]
</p><p>82 The traces plotted are the orthonormalized form of E[X | Y ]. [sent-216, score-0.318]
</p><p>83 Each panel corresponds to one of the 15 dimensions of the orthonormalized neural state, which is plotted versus time. [sent-219, score-0.446]
</p><p>84 The orthonormalized neural trajectory for one trial comprises one black trace from each panel. [sent-220, score-0.498]
</p><p>85 Dots indicate time of reach target onset (red), go cue (green), and movement onset (blue). [sent-221, score-0.206]
</p><p>86 Each trajectory corresponds to planning and executing a reach to the target at distance 60 mm and direction 135°. [sent-225, score-0.238]
</p><p>87 For clarity, only 10 trials with delay periods longer than 400 ms are plotted. [sent-226, score-0.194]
</p><p>88 Furthermore, the neural trajectories around the time of the arm movement are well-aligned on movement onset. [sent-228, score-0.238]
</p><p>89 These observations are consistent with previous analyses of the same dataset [22], as well as other studies of neural activity collected during similar tasks in the same cortical areas. [sent-229, score-0.243]
</p><p>90 Whereas the top 10 orthonormalized dimensions (upper and middle rows) show repeatable temporal structure across trials, the bottom ﬁve dimensions (lower row) appear to be largely capturing noise. [sent-230, score-0.469]
</p><p>91 1: when the bottom ﬁve orthonormalized dimensions were removed, the GPFA prediction error decreased. [sent-233, score-0.407]
</p><p>92 It still remains to be explained why the GPFA prediction error using only the top 10 orthonormalized dimensions is lower than that obtained by directly ﬁtting a GPFA model with p = 10. [sent-234, score-0.43]
</p><p>93 Thus, the top 10 orthonormalized dimensions can make use of up to 15 timescales. [sent-237, score-0.363]
</p><p>94 By ﬁtting a GPFA model with a large number of state dimensions p (each with its own timescale) and taking only the top p = p∗ orthonormalized dimensions, we can obtain ˜ neural trajectories whose effective dimensionality is smaller than the number of timescales at play. [sent-239, score-0.852]
</p><p>95 2, we consider the effective dimensionality of the recorded population activity to be p∗ = 10. [sent-242, score-0.382]
</p><p>96 In other words, the linear subspace within which the recorded activity evolved during reach planning and execution for this particular target was 10dimensional. [sent-243, score-0.397]
</p><p>97 Across the 14 reach targets, the effective dimensionality ranged from 8 to 12. [sent-244, score-0.152]
</p><p>98 Based on the trajectories obtained by GPFA, one can then attempt to deﬁne an appropriate dynamical model that describes how the neural state evolves over time. [sent-249, score-0.376]
</p><p>99 7  Compared with two-stage methods, the choice of GP covariance allows for more explicit speciﬁcation of the smoothing properties of the low-dimensional trajectories. [sent-250, score-0.175]
</p><p>100 In future work, we would like to couple the covariance structure of the one-dimensional GPs, which would allow for a richer description of the multi-dimensional neural state x:,t evolving over time. [sent-256, score-0.203]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('gpfa', 0.736), ('orthonormalized', 0.291), ('fa', 0.157), ('timescales', 0.147), ('recorded', 0.135), ('activity', 0.13), ('ppca', 0.123), ('ms', 0.115), ('smoothing', 0.108), ('ar', 0.107), ('trajectories', 0.103), ('gp', 0.095), ('timepoint', 0.092), ('neural', 0.083), ('dimensionality', 0.08), ('trajectory', 0.078), ('neurons', 0.077), ('dimensions', 0.072), ('reach', 0.072), ('neuron', 0.069), ('covariance', 0.067), ('spike', 0.065), ('smoothness', 0.062), ('counts', 0.061), ('dynamical', 0.06), ('timescale', 0.057), ('se', 0.057), ('rq', 0.057), ('pca', 0.056), ('ki', 0.055), ('timepoints', 0.054), ('evolves', 0.054), ('state', 0.053), ('extracting', 0.051), ('churchland', 0.046), ('black', 0.046), ('spiking', 0.046), ('uc', 0.045), ('poisson', 0.044), ('prediction', 0.044), ('reduction', 0.044), ('noise', 0.042), ('onset', 0.042), ('width', 0.041), ('jth', 0.041), ('trials', 0.041), ('premotor', 0.04), ('kernel', 0.04), ('delay', 0.038), ('population', 0.037), ('planning', 0.036), ('likelihoods', 0.036), ('metric', 0.035), ('across', 0.034), ('lle', 0.034), ('extract', 0.033), ('degree', 0.033), ('ring', 0.033), ('solid', 0.032), ('motor', 0.031), ('comput', 0.031), ('green', 0.031), ('adv', 0.031), ('jayaraman', 0.031), ('maneesh', 0.031), ('polarity', 0.031), ('seamless', 0.031), ('analyses', 0.03), ('widths', 0.03), ('smooth', 0.029), ('mm', 0.028), ('yu', 0.027), ('opin', 0.027), ('ryu', 0.027), ('briggman', 0.027), ('cx', 0.027), ('kristan', 0.027), ('lowdimensional', 0.027), ('traces', 0.027), ('variances', 0.027), ('learned', 0.026), ('movement', 0.026), ('vc', 0.026), ('neurosci', 0.025), ('abarbanel', 0.025), ('curr', 0.025), ('neurobiol', 0.025), ('santhanam', 0.025), ('orthonormalization', 0.025), ('shenoy', 0.025), ('sys', 0.025), ('target', 0.024), ('jointly', 0.024), ('yielded', 0.024), ('operations', 0.024), ('stationary', 0.024), ('gaussian', 0.023), ('static', 0.023), ('model', 0.023), ('info', 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="90-tfidf-1" href="./nips-2008-Gaussian-process_factor_analysis_for_low-dimensional_single-trial_analysis_of_neural_population_activity.html">90 nips-2008-Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity</a></p>
<p>Author: Byron M. Yu, John P. Cunningham, Gopal Santhanam, Stephen I. Ryu, Krishna V. Shenoy, Maneesh Sahani</p><p>Abstract: We consider the problem of extracting smooth, low-dimensional neural trajectories that summarize the activity recorded simultaneously from tens to hundreds of neurons on individual experimental trials. Current methods for extracting neural trajectories involve a two-stage process: the data are ﬁrst “denoised” by smoothing over time, then a static dimensionality reduction technique is applied. We ﬁrst describe extensions of the two-stage methods that allow the degree of smoothing to be chosen in a principled way, and account for spiking variability that may vary both across neurons and across time. We then present a novel method for extracting neural trajectories, Gaussian-process factor analysis (GPFA), which uniﬁes the smoothing and dimensionality reduction operations in a common probabilistic framework. We applied these methods to the activity of 61 neurons recorded simultaneously in macaque premotor and motor cortices during reach planning and execution. By adopting a goodness-of-ﬁt metric that measures how well the activity of each neuron can be predicted by all other recorded neurons, we found that GPFA provided a better characterization of the population activity than the two-stage methods. 1</p><p>2 0.095926411 <a title="90-tfidf-2" href="./nips-2008-Extracting_State_Transition_Dynamics_from_Multiple_Spike_Trains_with_Correlated_Poisson_HMM.html">81 nips-2008-Extracting State Transition Dynamics from Multiple Spike Trains with Correlated Poisson HMM</a></p>
<p>Author: Kentaro Katahira, Jun Nishikawa, Kazuo Okanoya, Masato Okada</p><p>Abstract: Neural activity is non-stationary and varies across time. Hidden Markov Models (HMMs) have been used to track the state transition among quasi-stationary discrete neural states. Within this context, independent Poisson models have been used for the output distribution of HMMs; hence, the model is incapable of tracking the change in correlation without modulating the ﬁring rate. To achieve this, we applied a multivariate Poisson distribution with correlation terms for the output distribution of HMMs. We formulated a Variational Bayes (VB) inference for the model. The VB could automatically determine the appropriate number of hidden states and correlation types while avoiding the overlearning problem. We developed an efﬁcient algorithm for computing posteriors using the recursive relationship of a multivariate Poisson distribution. We demonstrated the performance of our method on synthetic data and a real spike train recorded from a songbird. 1</p><p>3 0.090445101 <a title="90-tfidf-3" href="./nips-2008-Accelerating_Bayesian_Inference_over_Nonlinear_Differential_Equations_with_Gaussian_Processes.html">12 nips-2008-Accelerating Bayesian Inference over Nonlinear Differential Equations with Gaussian Processes</a></p>
<p>Author: Ben Calderhead, Mark Girolami, Neil D. Lawrence</p><p>Abstract: Identiﬁcation and comparison of nonlinear dynamical system models using noisy and sparse experimental data is a vital task in many ﬁelds, however current methods are computationally expensive and prone to error due in part to the nonlinear nature of the likelihood surfaces induced. We present an accelerated sampling procedure which enables Bayesian inference of parameters in nonlinear ordinary and delay differential equations via the novel use of Gaussian processes (GP). Our method involves GP regression over time-series data, and the resulting derivative and time delay estimates make parameter inference possible without solving the dynamical system explicitly, resulting in dramatic savings of computational time. We demonstrate the speed and statistical accuracy of our approach using examples of both ordinary and delay differential equations, and provide a comprehensive comparison with current state of the art methods. 1</p><p>4 0.089971051 <a title="90-tfidf-4" href="./nips-2008-Modeling_Short-term_Noise_Dependence_of_Spike_Counts_in_Macaque_Prefrontal_Cortex.html">137 nips-2008-Modeling Short-term Noise Dependence of Spike Counts in Macaque Prefrontal Cortex</a></p>
<p>Author: Arno Onken, Steffen Grünewälder, Matthias Munk, Klaus Obermayer</p><p>Abstract: Correlations between spike counts are often used to analyze neural coding. The noise is typically assumed to be Gaussian. Yet, this assumption is often inappropriate, especially for low spike counts. In this study, we present copulas as an alternative approach. With copulas it is possible to use arbitrary marginal distributions such as Poisson or negative binomial that are better suited for modeling noise distributions of spike counts. Furthermore, copulas place a wide range of dependence structures at the disposal and can be used to analyze higher order interactions. We develop a framework to analyze spike count data by means of copulas. Methods for parameter inference based on maximum likelihood estimates and for computation of mutual information are provided. We apply the method to our data recorded from macaque prefrontal cortex. The data analysis leads to three ﬁndings: (1) copula-based distributions provide signiﬁcantly better ﬁts than discretized multivariate normal distributions; (2) negative binomial margins ﬁt the data signiﬁcantly better than Poisson margins; and (3) the dependence structure carries 12% of the mutual information between stimuli and responses. 1</p><p>5 0.082627907 <a title="90-tfidf-5" href="./nips-2008-Spike_Feature_Extraction_Using_Informative_Samples.html">220 nips-2008-Spike Feature Extraction Using Informative Samples</a></p>
<p>Author: Zhi Yang, Qi Zhao, Wentai Liu</p><p>Abstract: This paper presents a spike feature extraction algorithm that targets real-time spike sorting and facilitates miniaturized microchip implementation. The proposed algorithm has been evaluated on synthesized waveforms and experimentally recorded sequences. When compared with many spike sorting approaches our algorithm demonstrates improved speed, accuracy and allows unsupervised execution. A preliminary hardware implementation has been realized using an integrated microchip interfaced with a personal computer. 1</p><p>6 0.075306237 <a title="90-tfidf-6" href="./nips-2008-Dependent_Dirichlet_Process_Spike_Sorting.html">59 nips-2008-Dependent Dirichlet Process Spike Sorting</a></p>
<p>7 0.068523318 <a title="90-tfidf-7" href="./nips-2008-Self-organization_using_synaptic_plasticity.html">204 nips-2008-Self-organization using synaptic plasticity</a></p>
<p>8 0.067010991 <a title="90-tfidf-8" href="./nips-2008-Bayesian_Kernel_Shaping_for_Learning_Control.html">32 nips-2008-Bayesian Kernel Shaping for Learning Control</a></p>
<p>9 0.066296905 <a title="90-tfidf-9" href="./nips-2008-Look_Ma%2C_No_Hands%3A_Analyzing_the_Monotonic_Feature_Abstraction_for_Text_Classification.html">128 nips-2008-Look Ma, No Hands: Analyzing the Monotonic Feature Abstraction for Text Classification</a></p>
<p>10 0.065942734 <a title="90-tfidf-10" href="./nips-2008-Kernel-ARMA_for_Hand_Tracking_and_Brain-Machine_interfacing_During_3D_Motor_Control.html">110 nips-2008-Kernel-ARMA for Hand Tracking and Brain-Machine interfacing During 3D Motor Control</a></p>
<p>11 0.060493309 <a title="90-tfidf-11" href="./nips-2008-Diffeomorphic_Dimensionality_Reduction.html">61 nips-2008-Diffeomorphic Dimensionality Reduction</a></p>
<p>12 0.059651904 <a title="90-tfidf-12" href="./nips-2008-Temporal_Dynamics_of_Cognitive_Control.html">231 nips-2008-Temporal Dynamics of Cognitive Control</a></p>
<p>13 0.056902315 <a title="90-tfidf-13" href="./nips-2008-Multi-task_Gaussian_Process_Learning_of_Robot_Inverse_Dynamics.html">146 nips-2008-Multi-task Gaussian Process Learning of Robot Inverse Dynamics</a></p>
<p>14 0.056249399 <a title="90-tfidf-14" href="./nips-2008-Temporal_Difference_Based_Actor_Critic_Learning_-_Convergence_and_Neural_Implementation.html">230 nips-2008-Temporal Difference Based Actor Critic Learning - Convergence and Neural Implementation</a></p>
<p>15 0.054489624 <a title="90-tfidf-15" href="./nips-2008-Using_Bayesian_Dynamical_Systems_for_Motion_Template_Libraries.html">247 nips-2008-Using Bayesian Dynamical Systems for Motion Template Libraries</a></p>
<p>16 0.053597651 <a title="90-tfidf-16" href="./nips-2008-Efficient_Sampling_for_Gaussian_Process_Inference_using_Control_Variables.html">71 nips-2008-Efficient Sampling for Gaussian Process Inference using Control Variables</a></p>
<p>17 0.052922558 <a title="90-tfidf-17" href="./nips-2008-Sparse_Convolved_Gaussian_Processes_for_Multi-output_Regression.html">213 nips-2008-Sparse Convolved Gaussian Processes for Multi-output Regression</a></p>
<p>18 0.052164629 <a title="90-tfidf-18" href="./nips-2008-Cell_Assemblies_in_Large_Sparse_Inhibitory_Networks_of_Biologically_Realistic_Spiking_Neurons.html">43 nips-2008-Cell Assemblies in Large Sparse Inhibitory Networks of Biologically Realistic Spiking Neurons</a></p>
<p>19 0.051489115 <a title="90-tfidf-19" href="./nips-2008-Supervised_Exponential_Family_Principal_Component_Analysis_via_Convex_Optimization.html">227 nips-2008-Supervised Exponential Family Principal Component Analysis via Convex Optimization</a></p>
<p>20 0.050904248 <a title="90-tfidf-20" href="./nips-2008-Interpreting_the_neural_code_with_Formal_Concept_Analysis.html">109 nips-2008-Interpreting the neural code with Formal Concept Analysis</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2008_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.15), (1, 0.054), (2, 0.142), (3, 0.122), (4, -0.029), (5, -0.005), (6, 0.007), (7, 0.053), (8, 0.006), (9, 0.029), (10, 0.09), (11, -0.005), (12, 0.002), (13, 0.012), (14, 0.092), (15, -0.014), (16, -0.025), (17, 0.065), (18, -0.01), (19, -0.061), (20, -0.016), (21, -0.074), (22, -0.001), (23, -0.016), (24, -0.015), (25, 0.017), (26, -0.025), (27, 0.072), (28, -0.012), (29, 0.011), (30, -0.01), (31, 0.008), (32, 0.001), (33, -0.043), (34, 0.026), (35, -0.028), (36, 0.04), (37, 0.092), (38, -0.031), (39, 0.026), (40, 0.031), (41, -0.016), (42, -0.029), (43, -0.033), (44, -0.035), (45, -0.011), (46, 0.091), (47, -0.042), (48, -0.012), (49, 0.144)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93211812 <a title="90-lsi-1" href="./nips-2008-Gaussian-process_factor_analysis_for_low-dimensional_single-trial_analysis_of_neural_population_activity.html">90 nips-2008-Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity</a></p>
<p>Author: Byron M. Yu, John P. Cunningham, Gopal Santhanam, Stephen I. Ryu, Krishna V. Shenoy, Maneesh Sahani</p><p>Abstract: We consider the problem of extracting smooth, low-dimensional neural trajectories that summarize the activity recorded simultaneously from tens to hundreds of neurons on individual experimental trials. Current methods for extracting neural trajectories involve a two-stage process: the data are ﬁrst “denoised” by smoothing over time, then a static dimensionality reduction technique is applied. We ﬁrst describe extensions of the two-stage methods that allow the degree of smoothing to be chosen in a principled way, and account for spiking variability that may vary both across neurons and across time. We then present a novel method for extracting neural trajectories, Gaussian-process factor analysis (GPFA), which uniﬁes the smoothing and dimensionality reduction operations in a common probabilistic framework. We applied these methods to the activity of 61 neurons recorded simultaneously in macaque premotor and motor cortices during reach planning and execution. By adopting a goodness-of-ﬁt metric that measures how well the activity of each neuron can be predicted by all other recorded neurons, we found that GPFA provided a better characterization of the population activity than the two-stage methods. 1</p><p>2 0.59734815 <a title="90-lsi-2" href="./nips-2008-Multi-task_Gaussian_Process_Learning_of_Robot_Inverse_Dynamics.html">146 nips-2008-Multi-task Gaussian Process Learning of Robot Inverse Dynamics</a></p>
<p>Author: Christopher Williams, Stefan Klanke, Sethu Vijayakumar, Kian M. Chai</p><p>Abstract: The inverse dynamics problem for a robotic manipulator is to compute the torques needed at the joints to drive it along a given trajectory; it is beneﬁcial to be able to learn this function for adaptive control. A robotic manipulator will often need to be controlled while holding different loads in its end effector, giving rise to a multi-task learning problem. By placing independent Gaussian process priors over the latent functions of the inverse dynamics, we obtain a multi-task Gaussian process prior for handling multiple loads, where the inter-task similarity depends on the underlying inertial parameters. Experiments demonstrate that this multi-task formulation is effective in sharing information among the various loads, and generally improves performance over either learning only on single tasks or pooling the data over all tasks. 1</p><p>3 0.58016634 <a title="90-lsi-3" href="./nips-2008-Sparse_Convolved_Gaussian_Processes_for_Multi-output_Regression.html">213 nips-2008-Sparse Convolved Gaussian Processes for Multi-output Regression</a></p>
<p>Author: Mauricio Alvarez, Neil D. Lawrence</p><p>Abstract: We present a sparse approximation approach for dependent output Gaussian processes (GP). Employing a latent function framework, we apply the convolution process formalism to establish dependencies between output variables, where each latent function is represented as a GP. Based on these latent functions, we establish an approximation scheme using a conditional independence assumption between the output processes, leading to an approximation of the full covariance which is determined by the locations at which the latent functions are evaluated. We show results of the proposed methodology for synthetic data and real world applications on pollution prediction and a sensor network. 1</p><p>4 0.57085401 <a title="90-lsi-4" href="./nips-2008-Kernel-ARMA_for_Hand_Tracking_and_Brain-Machine_interfacing_During_3D_Motor_Control.html">110 nips-2008-Kernel-ARMA for Hand Tracking and Brain-Machine interfacing During 3D Motor Control</a></p>
<p>Author: Lavi Shpigelman, Hagai Lalazar, Eilon Vaadia</p><p>Abstract: Using machine learning algorithms to decode intended behavior from neural activity serves a dual purpose. First, these tools allow patients to interact with their environment through a Brain-Machine Interface (BMI). Second, analyzing the characteristics of such methods can reveal the relative signiﬁcance of various features of neural activity, task stimuli, and behavior. In this study we adapted, implemented and tested a machine learning method called Kernel Auto-Regressive Moving Average (KARMA), for the task of inferring movements from neural activity in primary motor cortex. Our version of this algorithm is used in an online learning setting and is updated after a sequence of inferred movements is completed. We ﬁrst used it to track real hand movements executed by a monkey in a standard 3D reaching task. We then applied it in a closed-loop BMI setting to infer intended movement, while the monkey’s arms were comfortably restrained, thus performing the task using the BMI alone. KARMA is a recurrent method that learns a nonlinear model of output dynamics. It uses similarity functions (termed kernels) to compare between inputs. These kernels can be structured to incorporate domain knowledge into the method. We compare KARMA to various state-of-the-art methods by evaluating tracking performance and present results from the KARMA based BMI experiments. 1</p><p>5 0.55639368 <a title="90-lsi-5" href="./nips-2008-Local_Gaussian_Process_Regression_for_Real_Time_Online_Model_Learning.html">125 nips-2008-Local Gaussian Process Regression for Real Time Online Model Learning</a></p>
<p>Author: Duy Nguyen-tuong, Jan R. Peters, Matthias Seeger</p><p>Abstract: Learning in real-time applications, e.g., online approximation of the inverse dynamics model for model-based robot control, requires fast online regression techniques. Inspired by local learning, we propose a method to speed up standard Gaussian process regression (GPR) with local GP models (LGP). The training data is partitioned in local regions, for each an individual GP model is trained. The prediction for a query point is performed by weighted estimation using nearby local models. Unlike other GP approximations, such as mixtures of experts, we use a distance based measure for partitioning of the data and weighted prediction. The proposed method achieves online learning and prediction in real-time. Comparisons with other non-parametric regression methods show that LGP has higher accuracy than LWPR and close to the performance of standard GPR and ν-SVR. 1</p><p>6 0.52107596 <a title="90-lsi-6" href="./nips-2008-Extracting_State_Transition_Dynamics_from_Multiple_Spike_Trains_with_Correlated_Poisson_HMM.html">81 nips-2008-Extracting State Transition Dynamics from Multiple Spike Trains with Correlated Poisson HMM</a></p>
<p>7 0.50878108 <a title="90-lsi-7" href="./nips-2008-Accelerating_Bayesian_Inference_over_Nonlinear_Differential_Equations_with_Gaussian_Processes.html">12 nips-2008-Accelerating Bayesian Inference over Nonlinear Differential Equations with Gaussian Processes</a></p>
<p>8 0.49974924 <a title="90-lsi-8" href="./nips-2008-Diffeomorphic_Dimensionality_Reduction.html">61 nips-2008-Diffeomorphic Dimensionality Reduction</a></p>
<p>9 0.49440497 <a title="90-lsi-9" href="./nips-2008-Localized_Sliced_Inverse_Regression.html">126 nips-2008-Localized Sliced Inverse Regression</a></p>
<p>10 0.49056917 <a title="90-lsi-10" href="./nips-2008-Stochastic_Relational_Models_for_Large-scale_Dyadic_Data_using_MCMC.html">221 nips-2008-Stochastic Relational Models for Large-scale Dyadic Data using MCMC</a></p>
<p>11 0.48684734 <a title="90-lsi-11" href="./nips-2008-A_general_framework_for_investigating_how_far_the_decoding_process_in_the_brain_can_be_simplified.html">8 nips-2008-A general framework for investigating how far the decoding process in the brain can be simplified</a></p>
<p>12 0.48175639 <a title="90-lsi-12" href="./nips-2008-Bayesian_Exponential_Family_PCA.html">31 nips-2008-Bayesian Exponential Family PCA</a></p>
<p>13 0.47985098 <a title="90-lsi-13" href="./nips-2008-Cell_Assemblies_in_Large_Sparse_Inhibitory_Networks_of_Biologically_Realistic_Spiking_Neurons.html">43 nips-2008-Cell Assemblies in Large Sparse Inhibitory Networks of Biologically Realistic Spiking Neurons</a></p>
<p>14 0.47508213 <a title="90-lsi-14" href="./nips-2008-Bayesian_Kernel_Shaping_for_Learning_Control.html">32 nips-2008-Bayesian Kernel Shaping for Learning Control</a></p>
<p>15 0.47085109 <a title="90-lsi-15" href="./nips-2008-Tracking_Changing_Stimuli_in_Continuous_Attractor_Neural_Networks.html">240 nips-2008-Tracking Changing Stimuli in Continuous Attractor Neural Networks</a></p>
<p>16 0.46560815 <a title="90-lsi-16" href="./nips-2008-Efficient_Sampling_for_Gaussian_Process_Inference_using_Control_Variables.html">71 nips-2008-Efficient Sampling for Gaussian Process Inference using Control Variables</a></p>
<p>17 0.45791826 <a title="90-lsi-17" href="./nips-2008-Self-organization_using_synaptic_plasticity.html">204 nips-2008-Self-organization using synaptic plasticity</a></p>
<p>18 0.45442885 <a title="90-lsi-18" href="./nips-2008-Supervised_Exponential_Family_Principal_Component_Analysis_via_Convex_Optimization.html">227 nips-2008-Supervised Exponential Family Principal Component Analysis via Convex Optimization</a></p>
<p>19 0.45103681 <a title="90-lsi-19" href="./nips-2008-Dependent_Dirichlet_Process_Spike_Sorting.html">59 nips-2008-Dependent Dirichlet Process Spike Sorting</a></p>
<p>20 0.44105893 <a title="90-lsi-20" href="./nips-2008-Short-Term_Depression_in_VLSI_Stochastic_Synapse.html">209 nips-2008-Short-Term Depression in VLSI Stochastic Synapse</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2008_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(6, 0.08), (7, 0.096), (12, 0.047), (15, 0.303), (25, 0.011), (28, 0.148), (57, 0.076), (59, 0.019), (63, 0.016), (71, 0.018), (77, 0.048), (83, 0.05)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.92887062 <a title="90-lda-1" href="./nips-2008-Psychiatry%3A_Insights_into_depression_through_normative_decision-making_models.html">187 nips-2008-Psychiatry: Insights into depression through normative decision-making models</a></p>
<p>Author: Quentin J. Huys, Joshua Vogelstein, Peter Dayan</p><p>Abstract: Decision making lies at the very heart of many psychiatric diseases. It is also a central theoretical concern in a wide variety of ﬁelds and has undergone detailed, in-depth, analyses. We take as an example Major Depressive Disorder (MDD), applying insights from a Bayesian reinforcement learning framework. We focus on anhedonia and helplessness. Helplessness—a core element in the conceptualizations of MDD that has lead to major advances in its treatment, pharmacological and neurobiological understanding—is formalized as a simple prior over the outcome entropy of actions in uncertain environments. Anhedonia, which is an equally fundamental aspect of the disease, is related to the effective reward size. These formulations allow for the design of speciﬁc tasks to measure anhedonia and helplessness behaviorally. We show that these behavioral measures capture explicit, questionnaire-based cognitions. We also provide evidence that these tasks may allow classiﬁcation of subjects into healthy and MDD groups based purely on a behavioural measure and avoiding any verbal reports. There are strong ties between decision making and psychiatry, with maladaptive decisions and behaviors being very prominent in people with psychiatric disorders. Depression is classically seen as following life events such as divorces and job losses. Longitudinal studies, however, have revealed that a signiﬁcant fraction of the stressors associated with depression do in fact follow MDD onset, and that they are likely due to maladaptive behaviors prominent in MDD (Kendler et al., 1999). Clinically effective ’talking’ therapies for MDD such as cognitive and dialectical behavior therapies (DeRubeis et al., 1999; Bortolotti et al., 2008; Gotlib and Hammen, 2002; Power, 2005) explicitly concentrate on altering patients’ maladaptive behaviors and decision making processes. Decision making is a promising avenue into psychiatry for at least two more reasons. First, it offers powerful analytical tools. Control problems related to decision making are prevalent in a huge diversity of ﬁelds, ranging from ecology to economics, computer science and engineering. These ﬁelds have produced well-founded and thoroughly characterized frameworks within which many issues in decision making can be framed. Here, we will focus on framing issues identiﬁed in psychiatric settings within a normative decision making framework. Its second major strength comes from its relationship to neurobiology, and particularly those neuromodulatory systems which are powerfully affected by all major clinically effective pharmacotherapies in psychiatry. The understanding of these systems has beneﬁted signiﬁcantly from theoretical accounts of optimal control such as reinforcement learning (Montague et al., 1996; Kapur and Remington, 1996; Smith et al., 1999; Yu and Dayan, 2005; Dayan and Yu, 2006). Such accounts may be useful to identify in more speciﬁc terms the roles of the neuromodulators in psychiatry (Smith et al., 2004; Williams and Dayan, 2005; Moutoussis et al., 2008; Dayan and Huys, 2008). ∗ qhuys@cantab.net, joshuav@jhu.edu, dayan@gatsby.ucl.ac.uk; www.gatsby.ucl.ac.uk/∼qhuys/pub.html 1 Master Yoked Control Figure 1: The learned helplessness (LH) paradigm. Three sets of rats are used in a sequence of two tasks. In the ﬁrst task, rats are exposed to escapable or inescapable shocks. Shocks come on at random times. The master rat is given escapable shocks: it can switch off the shock by performing an action, usually turning a wheel mounted in front of it. The yoked rat is exposed to precisely the same shocks as the master rat, i.e its shocks are terminated when the master rat terminates the shock. Thus its shocks are inescapable, there is nothing it can do itself to terminate them. A third set of rats is not exposed to shocks. Then, all three sets of rats are exposed to a shuttlebox escape task. Shocks again come on at random times, and rats have to shuttle to the other side of the box to terminate the shock. Only yoked rats fail to acquire the escape response. Yoked rats generally fail to acquire a wide variety of instrumental behaviours, either determined by reward or, as here, by punishment contingencies. This paper represents an initial attempt at validating this approach experimentally. We will frame core notions of MDD in a reinforcement learning framework and use it to design behavioral decision making experiments. More speciﬁcally, we will concentrate on two concepts central to current thinking about MDD: anhedonia and learned helplessness (LH, Maier and Seligman 1976; Maier and Watkins 2005). We formulate helplessness parametrically as prior beliefs on aspects of decision trees, and anhedonia as the effective reward size. This allows us to use choice behavior to infer the degree to which subjects’ behavioral choices are characterized by either of these. For validation, we correlate the parameters inferred from subjects’ behavior with standard, questionnaire-based measures of hopelessness and anhedonia, and ﬁnally use the inferred parameters alone to attempt to recover the diagnostic classiﬁcation. 1 Core concepts: helplessness and anhedonia The basic LH paradigm is explained in ﬁgure 1. Its importance is manifold: the effect of inescapable shock on subsequent learning is sensitive to most classes of clinically effective antidepressants; it has arguably been a motivation framework for the development of the main talking therapies for depression (cognitive behavioural therapy, Williams (1992), it has motivated the development of further, yet more speciﬁc animal models (Willner, 1997), and it has been the basis of very speciﬁc research into the cognitive basis of depression (Peterson et al., 1993). Behavioral control is the central concept in LH: yoked and master rat do not differ in terms of the amount of shock (stress) they have experienced, only in terms of the behavioural control over it. It is not a standard notion in reinforcement learning, and there are several ways one could translate the concept into RL terms. At a simple level, there is intuitively more behavioural control if, when repeating one action, the same outcome occurs again and again, than if this were not true. Thus, at a very ﬁrst level, control might be related to the outcome entropy of actions (see Maier and Seligman 1976 for an early formulation). Of course, this is too simple. If all available actions deterministically led to the same outcome, the agent has very little control. Finally, if one were able to achieve all outcomes except for the one one cares about (in the rats’ case switching off or avoiding the shock), we would again not say that there is much control (see Huys (2007); Huys and Dayan (2007) for a more detailed discussion). Despite its obvious limitations, we will here concentrate on the simplest notion for reasons of mathematical expediency. 2 0.6 0.5 Exploration vs Exploitation Predictive Distributions Q(aknown)−Q(aunknown) P(reward a known ) 0.7 2 0 1 2 3 4 5 0.4 0.3 0.2 Choose blue slot machine 0.5 0 −0.5 0.1 0 1 1 2 3 4 5 Reward −1 Choose orange slot machine 1 High control Low control 2 3 4 5 Tree depth Figure 2: Effect of γ on predictions, Q-values and exploration behaviour. Assume a slot machine (blue) has been chosen ﬁve times, with possible rewards 1-5, and that reward 2 has been obtained twice, and reward 4 three times (inset in left panel). Left: Predictive distribution for a prior with negative γ (low control) in light gray, and large γ (extensive control) in dark gray. We see that, if the agent believes he has much control (and outcome distributions have low entropy), the predictive distribution puts all mass on the observations. Right: Assume now the agent gets up to 5 more pulls (tree depth 1-5) between the blue slot machine and a new, orange slot machine. The orange slot machine’s predictive distribution is ﬂat as it has never been tried, and its expected value is therefore 3. The plot shows the difference between the values for the two slot machines. First consider the agent only has one more pull to take. In this case, independently of the priors about control, the agent will choose the blue machine, because it is just slightly better than average. Note though that the difference is more pronounced if the agent has a high control prior. But things change if the agent has two or more choices. Now, it is worth trying out the new machine if the agent has a high-control prior. For in that case, if the new machine turns out to yield a large reward on the ﬁrst try, it is likely to do so again for the second and subsequent times. Thus, the prior about control determines the exploration bonus. The second central concept in current conceptions of MDD is that of reward sensitivity. Anhedonia, an inability to enjoy previously enjoyable things, is one of two symptoms necessary for the diagnosis of depression (American Psychiatric Association, 1994). A number of tasks in the literature have attempted to measure reward sensitivity behaviourally. While these generally concur in ﬁnding decreased reward sensitivity in subjects with MDD, these results need further clariﬁcation. Some studies show interactions between reward and punishment sensitivities with respect to MDD, but important aspects of the tasks are not clearly understood. For instance, Henriques et al. (1994); Henriques and Davidson (2000) show decreased resonsiveness of MDD subjects to rewards, but equally show decreased resonsiveness of healthy subjects to punishments. Pizzagalli et al. (2005) introduced an asymmetrically rewarded perceptual discrimination task and show that the rate of change of the response bias is anticorrelated with subjects’ anhedonic symptoms. Exactly how decreased reward responsivity can account for this is at pressent not clear. Great care has to be taken to disentangle these two concepts. Anhedonia and helplessness both provide good reasons for not taking an action: either because the reinforcements associated with the action are insufﬁcient (anhedonia), or because the outcome is not judged a likely result of taking some particular action (if actions are thought to have large outcome entropy). 2 A Bayesian formulation of control We consider a scenario where subjects have no knowledge of the outcome distributions of actions, but rather learn about them. This means that their prior beliefs about the outcome distributions are not overwhelmed by the likelihood of observations, and may thus have measurable effects on their action choices. In terms of RL, this means that agents do not know the decision tree of the problem they face. Control is formulated as a prior distribution on the outcome distributions, and thereby as a prior distribution on the decision trees. The concentration parameter α of a Dirichlet process can very simply parametrise entropy, and, if used as a prior, allow for very efﬁcient updates of the predictive distributions of actions. Let us assume we have actions A which have as outcomes rewards R, and keep count Nt (r, a) = 3 k:k < 0. Here, we included a regressor for the AGE as that was a confounding variable in our subject sample. Furthermore, if it is true that anhedonia, as expressed by the questionnaire, relates to reward sensitivity speciﬁcally, we should be able to write a similar regression for the learning rate ǫ (from equation 5) ǫ(BDIa, AGE) = θǫ BDIa + cǫ AGE + ζǫ but ﬁnd that θǫ is not different from zero. Figure 4 shows the ML values for the parameters of interest (emphasized in blue in the equations) and conﬁrms that people who express higher levels of anhedonia do indeed show less reward sensitivity, but do not differ in terms of learning rate. If it were the case that subjects with higher BDIa score were just less attentive to the task, one might also expect an effect of BDIa on learning rate. 3.2 Control Validation: The control task is new, and we ﬁrst need to ascertain that subjects were indeed sensitive to main features of the task. We thus ﬁt both a RW-learning rule (as in the previous section, but adjusted for the varying number of available actions), and the full control model. Importantly, both these models have two parameters, but only the full control model has a notion of outcome entropy, and evaluations a tree. The chance probability of subjects’ actions was 0.37, meaning that, on average, there were just under three machines on the screen. The probability of the actions under the RW-learning rule was better at 0.48, and that of the full control model 0.54. These differences are highly signiﬁcant as the total number of choices is 29600. Thus, we conclude that subjects were indeed sensitive to the manipulation of outcome entropy, and that they did look ahead in a tree. Prior belief about control: Applying the procedure from the previous task to the main task, we write the main parameters of equations 2 and 4 as functions of the questionnaire measures and infer linear parameters: γ1 (BDIa, BHS, age) = χγ1 BHS + θγ1 BDIa + cγ1 AGE + ζγ1 γ2 (BDIa, BHS, age) = χγ2 BHS + θγ2 BDIa + cγ2 AGE + ζγ2 β(BDIa, BHS, age) = χβ BHS + θβ BDIa + cβ AGE + ζβ Importantly, because the BDIa scores and the BHS scores are correlated in our sample (they tend to be large for the subjects with MDD), we include the cross-terms (θγ1 , θγ2 , χγ ), as we are interested in the speciﬁc effects of BDIa on β, as before, and of BHS on γ. 6 3 control γ 2 Figure 6: Classiﬁcation. Controls are shown as black dots, and depressed subjects as red crosses. The blue line is a linear classiﬁer. Thus, the patients and controls can be approximately classiﬁed purely on the basis of behaviour. 1 0 83% correct 69% sensitivity 94% specificity −1 −2 2 4 6 8 10 12 14 16 reward sensitivity β We here infer and display two separate values γ1 and γ2 . These correspond to the level of control in the ﬁrst and the second half of the experiment. In fact, to parallel the LH experiments better, the slot machines in the ﬁrst 50 rooms were actually very noisy (low true γ), which means that subjects were here exposed to low levels of control just like the yoked rats in the original experiment. In the second half of the experiment on the other hand, slot machines tended to be quite reliable (high true γ). Figure 5 shows again the ML values for the parameters of interest (emphasized in blue in the equations). Again, we ﬁnd that our parameter estimate are very signiﬁcantly different from zero (> three standard deviations). The effect of the BHS score on the prior beliefs about control γ is much stronger in the second half than of the experiment in the ﬁrst half, i.e. the effect of BHS on the prior belief about control is particularly prominent when subjects are in a high-control environment and have previously been exposed to a low-control environment. This is an interesting parallel to the learned helplessness experiments in animals. 3.3 Classiﬁcation Finally we combine the two tasks. We integrate out the learning rate ǫ, which we had found not be related to the questionnaire measures (c.f. ﬁgure 4), and use the distribution over β from the ﬁrst task as a prior distribution on β for the second task. We also put weak priors on γ and infer both β and γ for the second task on a subject-by-subject basis. Figure 6 shows the posterior values for γ and β for MDD and healthy subjects and the ability of a linear classiﬁer to classify them. 4 Discussion In this paper, we have attempted to provide a speciﬁc formulation of core psychiatric concepts in reinforcement learning terms, i.e. hopelessness as a prior belief about controllability, and anhedonia as reward sensitivity. We have brieﬂy explained how we expect these formulations to have effect in a behavioural situation, have presented a behavioral task explicitly designed to be sensitive to our formulations, and shown that people’s verbal expression of hopelessness and anhedonia do have speciﬁc behavioral impacts. Subjects who express anhedonia display insensitivity to rewards and those expressing hopelessness behave as if they had prior beliefs that outcome distributions of actions (slot machines) are very broad. Finally, we have shown that these purely behavioural measures are also predictive of their psychiatric status, in that we were able to classify patients and healthy controls purely on the basis of performance. Several aspects of this work are novel. There have been previous attempts to map aspects of psychiatric dysfunction onto speciﬁc parametrizations (Cohen et al., 1996; Smith et al., 2004; Williams and Dayan, 2005; Moutoussis et al., 2008), but we believe that our work represents the ﬁrst attempt to a) apply it to MDD; b) make formal predictions about subject behavior c) present strong evidence linking anhedonia speciﬁcally to reward insensitivity across two tasks d) combine tasks to tease helplessness and anhedonia apart and e) to use the behavioral inferences for classiﬁcation. The latter point is particularly important, as it will determine any potential clinical signiﬁcance (Veiel, 1997). In the future, rather than cross-validating with respect to say DSM-IV criteria, it may also be important to validate measures such as ours in their own right in longitudinal studies. 7 Several important caveats do remain. First, the populations are not fully matched for age. We included age as an additional regressor and found all results to be robust. Secondly, only the healthy subjects were remunerated. However, repeating the analyses presented using only the MDD subjects yields the same results (data not shown). Thirdly, we have not yet fully mirrored the LH experiments. We have so far only tested the transfer from a low-control environment to a high-control environment. To make statements like those in animal learned helplessness experiments, the transfer from high-control to low-control environments will need to be examined, too. Fourth, the notion of control we have used is very simple, and more complex notions should certainly be tested (see Dayan and Huys 2008). Fifth, and maybe most importantly, we have so far only attempted to classify MDD and healthy subjects, and can thus not yet make any statements about the speciﬁcity of these effects with respect to MDD. Finally, it will be important to replicate these results independently, and possibly in a different modality. Nevertheless, we believe these results to be very encouraging. Acknowledgments: This work would not have been possible without the help of Sarah Hollingsworth Lisanby, Kenneth Miller and Ramin V. Parsey. We would also like to thank Nathaniel Daw and Hanneke EM Den Ouden and Ren´ Hen for invaluable discussions. Support for this work was provided by the Gatsby Charitable e Foundation (PD), a UCL Bogue Fellowship and the Swartz Foundation (QH) and a Columbia University startup grant to Kenneth Miller. References American Psychiatric Association (1994). Diagnostic and Statistical Manual of Mental Disorders. American Psychiatric Association Press. Bortolotti, B., Menchetti, M., Bellini, F., Montaguti, M. B., and Berardi, D. (2008). Psychological interventions for major depression in primary care: a meta-analytic review of randomized controlled trials. Gen Hosp Psychiatry, 30(4):293–302. Cohen, J. D., Braver, T. S., and O’Reilly, R. C. (1996). A computational approach to prefrontal cortex, cognitive control and schizophrenia: recent developments and current challenges. Philos Trans R Soc Lond B Biol Sci, 351(1346):1515–1527. Daw, N. D., O’Doherty, J. P., Dayan, P., Seymour, B., and Dolan, R. J. (2006). Cortical substrates for exploratory decisions in humans. Nature, 441(7095):876–879. Dayan, P. and Huys, Q. J. M. (2008). Serotonin, inhibition, and negative mood. PLoS Comput Biol, 4(2):e4. Dayan, P. and Yu, A. J. (2006). Phasic norepinephrine: a neural interrupt signal for unexpected events. Network, 17(4):335– 350. DeRubeis, R. J., Gelfand, L. A., Tang, T. Z., and Simons, A. D. (1999). Medications versus cognitive behavior therapy for severely depressed outpatients: mega-analysis of four randomized comparisons. Am J Psychiatry, 156(7):1007–1013. First, M. B., Spitzer, R. L., Gibbon, M., and Williams, J. B. (2002a). Structured Clinical Interview for DSM-IV-TR Axis I Disorders, Research Version, Non-Patient Edition. (SCID-I/NP). Biometrics Research, New York State Psychiatric Institute. First, M. B., Spitzer, R. L., Gibbon, M., and Williams, J. B. (2002b). Structured Clinical Interview for DSM-IV-TR Axis I Disorders, Research Version, Patient Edition. (SCID-I/P). Biometrics Research, New York State Psychiatric Institute. Gotlib, I. H. and Hammen, C. L., editors (2002). Handbook of Depression. The Guilford Press. Henriques, J. B. and Davidson, R. J. (2000). Decreased responsiveness to reward in depression. Cognition and Emotion, 14(5):711–24. Henriques, J. B., Glowacki, J. M., and Davidson, R. J. (1994). Reward fails to alter response bias in depression. J Abnorm Psychol, 103(3):460–6. Huys, Q. J. M. (2007). Reinforcers and control. Towards a computational ætiology of depression. PhD thesis, Gatsby Computational Neuroscience Unit, UCL, University of London. Huys, Q. J. M. and Dayan, P. (2007). A bayesian formulation of behavioral control. Under Review, 0:00. Kapur, S. and Remington, G. (1996). Serotonin-dopamine interaction and its relevance to schizophrenia. Am J Psychiatry, 153(4):466–76. Kendler, K. S., Karkowski, L. M., and Prescott, C. A. (1999). Causal relationship between stressful life events and the onset of major depression. Am. J. Psychiatry, 156:837–41. Maier, S. and Seligman, M. (1976). Learned Helplessness: Theory and Evidence. Journal of Experimental Psychology: General, 105(1):3–46. Maier, S. F. and Watkins, L. R. (2005). Stressor controllability and learned helplessness: the roles of the dorsal raphe nucleus, serotonin, and corticotropin-releasing factor. Neurosci. Biobehav. Rev., 29(4-5):829–41. Montague, P. R., Dayan, P., and Sejnowski, T. J. (1996). A framework for mesencephalic dopamine systems based on predictive hebbian learning. J. Neurosci., 16(5):1936–47. Moutoussis, M., Bentall, R. P., Williams, J., and Dayan, P. (2008). A temporal difference account of avoidance learning. Network, 19(2):137–160. Peterson, C., Maier, S. F., and Seligman, M. E. P. (1993). Learned Helplessness: A theory for the age of personal control. OUP, Oxford, UK. Pizzagalli, D. A., Jahn, A. L., and O’Shea, J. P. (2005). Toward an objective characterization of an anhedonic phenotype: a signal-detection approach. Biol Psychiatry, 57(4):319–327. Power, M., editor (2005). Mood Disorders: A Handbook of Science and Practice. John Wiley and Sons, paperback edition. Smith, A., Li, M., Becker, S., and Kapur, S. (2004). A model of antipsychotic action in conditioned avoidance: a computational approach. Neuropsychopharm., 29(6):1040–9. Smith, K. A., Morris, J. S., Friston, K. J., Cowen, P. J., and Dolan, R. J. (1999). Brain mechanisms associated with depressive relapse and associated cognitive impairment following acute tryptophan depletion. Br. J. Psychiatry, 174:525–9. Veiel, H. O. F. (1997). A preliminary proﬁle of neuropsychological deﬁcits associated with major depression. J. Clin. Exp. Neuropsychol., 19:587–603. Williams, J. and Dayan, P. (2005). Dopamine, learning, and impulsivity: a biological account of attentiondeﬁcit/hyperactivity disorder. J Child Adolesc Psychopharmacol, 15(2):160–79; discussion 157–9. Williams, J. M. G. (1992). The psychological treatment of depression. Routledge. Willner, P. (1997). Validity, reliability and utility of the chronic mild stress model of depression: a 10-year review and evaluation. Psychopharm, 134:319–29. Yu, A. J. and Dayan, P. (2005). Uncertainty, neuromodulation, and attention. Neuron, 46(4):681–692. 8</p><p>same-paper 2 0.82838023 <a title="90-lda-2" href="./nips-2008-Gaussian-process_factor_analysis_for_low-dimensional_single-trial_analysis_of_neural_population_activity.html">90 nips-2008-Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity</a></p>
<p>Author: Byron M. Yu, John P. Cunningham, Gopal Santhanam, Stephen I. Ryu, Krishna V. Shenoy, Maneesh Sahani</p><p>Abstract: We consider the problem of extracting smooth, low-dimensional neural trajectories that summarize the activity recorded simultaneously from tens to hundreds of neurons on individual experimental trials. Current methods for extracting neural trajectories involve a two-stage process: the data are ﬁrst “denoised” by smoothing over time, then a static dimensionality reduction technique is applied. We ﬁrst describe extensions of the two-stage methods that allow the degree of smoothing to be chosen in a principled way, and account for spiking variability that may vary both across neurons and across time. We then present a novel method for extracting neural trajectories, Gaussian-process factor analysis (GPFA), which uniﬁes the smoothing and dimensionality reduction operations in a common probabilistic framework. We applied these methods to the activity of 61 neurons recorded simultaneously in macaque premotor and motor cortices during reach planning and execution. By adopting a goodness-of-ﬁt metric that measures how well the activity of each neuron can be predicted by all other recorded neurons, we found that GPFA provided a better characterization of the population activity than the two-stage methods. 1</p><p>3 0.75306863 <a title="90-lda-3" href="./nips-2008-Clustered_Multi-Task_Learning%3A_A_Convex_Formulation.html">47 nips-2008-Clustered Multi-Task Learning: A Convex Formulation</a></p>
<p>Author: Laurent Jacob, Jean-philippe Vert, Francis R. Bach</p><p>Abstract: In multi-task learning several related tasks are considered simultaneously, with the hope that by an appropriate sharing of information across tasks, each task may beneﬁt from the others. In the context of learning linear functions for supervised classiﬁcation or regression, this can be achieved by including a priori information about the weight vectors associated with the tasks, and how they are expected to be related to each other. In this paper, we assume that tasks are clustered into groups, which are unknown beforehand, and that tasks within a group have similar weight vectors. We design a new spectral norm that encodes this a priori assumption, without the prior knowledge of the partition of tasks into groups, resulting in a new convex optimization formulation for multi-task learning. We show in simulations on synthetic examples and on the IEDB MHC-I binding dataset, that our approach outperforms well-known convex methods for multi-task learning, as well as related non-convex methods dedicated to the same problem. 1</p><p>4 0.71928722 <a title="90-lda-4" href="./nips-2008-Structured_ranking_learning_using_cumulative_distribution_networks.html">224 nips-2008-Structured ranking learning using cumulative distribution networks</a></p>
<p>Author: Jim C. Huang, Brendan J. Frey</p><p>Abstract: Ranking is at the heart of many information retrieval applications. Unlike standard regression or classiﬁcation in which we predict outputs independently, in ranking we are interested in predicting structured outputs so that misranking one object can signiﬁcantly affect whether we correctly rank the other objects. In practice, the problem of ranking involves a large number of objects to be ranked and either approximate structured prediction methods are required, or assumptions of independence between object scores must be made in order to make the problem tractable. We present a probabilistic method for learning to rank using the graphical modelling framework of cumulative distribution networks (CDNs), where we can take into account the structure inherent to the problem of ranking by modelling the joint cumulative distribution functions (CDFs) over multiple pairwise preferences. We apply our framework to the problem of document retrieval in the case of the OHSUMED benchmark dataset. We will show that the RankNet, ListNet and ListMLE probabilistic models can be viewed as particular instances of CDNs and that our proposed framework allows for the exploration of a broad class of ﬂexible structured loss functionals for learning to rank. 1</p><p>5 0.60851341 <a title="90-lda-5" href="./nips-2008-Dynamic_visual_attention%3A_searching_for_coding_length_increments.html">66 nips-2008-Dynamic visual attention: searching for coding length increments</a></p>
<p>Author: Xiaodi Hou, Liqing Zhang</p><p>Abstract: A visual attention system should respond placidly when common stimuli are presented, while at the same time keep alert to anomalous visual inputs. In this paper, a dynamic visual attention model based on the rarity of features is proposed. We introduce the Incremental Coding Length (ICL) to measure the perspective entropy gain of each feature. The objective of our model is to maximize the entropy of the sampled visual features. In order to optimize energy consumption, the limit amount of energy of the system is re-distributed amongst features according to their Incremental Coding Length. By selecting features with large coding length increments, the computational system can achieve attention selectivity in both static and dynamic scenes. We demonstrate that the proposed model achieves superior accuracy in comparison to mainstream approaches in static saliency map generation. Moreover, we also show that our model captures several less-reported dynamic visual search behaviors, such as attentional swing and inhibition of return. 1</p><p>6 0.60851055 <a title="90-lda-6" href="./nips-2008-Nonparametric_regression_and_classification_with_joint_sparsity_constraints.html">155 nips-2008-Nonparametric regression and classification with joint sparsity constraints</a></p>
<p>7 0.60484266 <a title="90-lda-7" href="./nips-2008-Estimating_vector_fields_using_sparse_basis_field_expansions.html">75 nips-2008-Estimating vector fields using sparse basis field expansions</a></p>
<p>8 0.5961827 <a title="90-lda-8" href="./nips-2008-Dimensionality_Reduction_for_Data_in_Multiple_Feature_Representations.html">63 nips-2008-Dimensionality Reduction for Data in Multiple Feature Representations</a></p>
<p>9 0.5949769 <a title="90-lda-9" href="./nips-2008-Regularized_Learning_with_Networks_of_Features.html">194 nips-2008-Regularized Learning with Networks of Features</a></p>
<p>10 0.59470505 <a title="90-lda-10" href="./nips-2008-Temporal_Dynamics_of_Cognitive_Control.html">231 nips-2008-Temporal Dynamics of Cognitive Control</a></p>
<p>11 0.59426755 <a title="90-lda-11" href="./nips-2008-Modeling_Short-term_Noise_Dependence_of_Spike_Counts_in_Macaque_Prefrontal_Cortex.html">137 nips-2008-Modeling Short-term Noise Dependence of Spike Counts in Macaque Prefrontal Cortex</a></p>
<p>12 0.59066862 <a title="90-lda-12" href="./nips-2008-Posterior_Consistency_of_the_Silverman_g-prior_in_Bayesian_Model_Choice.html">182 nips-2008-Posterior Consistency of the Silverman g-prior in Bayesian Model Choice</a></p>
<p>13 0.59047383 <a title="90-lda-13" href="./nips-2008-An_improved_estimator_of_Variance_Explained_in_the_presence_of_noise.html">24 nips-2008-An improved estimator of Variance Explained in the presence of noise</a></p>
<p>14 0.59039026 <a title="90-lda-14" href="./nips-2008-Supervised_Dictionary_Learning.html">226 nips-2008-Supervised Dictionary Learning</a></p>
<p>15 0.58999133 <a title="90-lda-15" href="./nips-2008-Robust_Regression_and_Lasso.html">202 nips-2008-Robust Regression and Lasso</a></p>
<p>16 0.58904743 <a title="90-lda-16" href="./nips-2008-Grouping_Contours_Via_a_Related_Image.html">95 nips-2008-Grouping Contours Via a Related Image</a></p>
<p>17 0.58784229 <a title="90-lda-17" href="./nips-2008-PSDBoost%3A_Matrix-Generation_Linear_Programming_for_Positive_Semidefinite_Matrices_Learning.html">175 nips-2008-PSDBoost: Matrix-Generation Linear Programming for Positive Semidefinite Matrices Learning</a></p>
<p>18 0.58491462 <a title="90-lda-18" href="./nips-2008-Bayesian_Experimental_Design_of_Magnetic_Resonance_Imaging_Sequences.html">30 nips-2008-Bayesian Experimental Design of Magnetic Resonance Imaging Sequences</a></p>
<p>19 0.58409274 <a title="90-lda-19" href="./nips-2008-Differentiable_Sparse_Coding.html">62 nips-2008-Differentiable Sparse Coding</a></p>
<p>20 0.5839926 <a title="90-lda-20" href="./nips-2008-Sparse_Convolved_Gaussian_Processes_for_Multi-output_Regression.html">213 nips-2008-Sparse Convolved Gaussian Processes for Multi-output Regression</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
