<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>99 nips-2008-High-dimensional support union recovery in multivariate regression</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-99" href="#">nips2008-99</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>99 nips-2008-High-dimensional support union recovery in multivariate regression</h1>
<br/><p>Source: <a title="nips-2008-99-pdf" href="http://papers.nips.cc/paper/3432-high-dimensional-support-union-recovery-in-multivariate-regression.pdf">pdf</a></p><p>Author: Guillaume R. Obozinski, Martin J. Wainwright, Michael I. Jordan</p><p>Abstract: We study the behavior of block 1 / 2 regularization for multivariate regression, where a K-dimensional response vector is regressed upon a ﬁxed set of p covariates. The problem of support union recovery is to recover the subset of covariates that are active in at least one of the regression problems. Studying this problem under high-dimensional scaling (where the problem parameters as well as sample size n tend to inﬁnity simultaneously), our main result is to show that exact recovery is possible once the order parameter given by θ 1 / 2 (n, p, s) : = n/[2ψ(B ∗ ) log(p − s)] exceeds a critical threshold. Here n is the sample size, p is the ambient dimension of the regression model, s is the size of the union of supports, and ψ(B ∗ ) is a sparsity-overlap function that measures a combination of the sparsities and overlaps of the K-regression coefﬁcient vectors that constitute the model. This sparsity-overlap function reveals that block 1 / 2 regularization for multivariate regression never harms performance relative to a naive 1 -approach, and can yield substantial improvements in sample complexity (up to a factor of K) when the regression vectors are suitably orthogonal relative to the design. We complement our theoretical results with simulations that demonstrate the sharpness of the result, even for relatively small problems. 1</p><p>Reference: <a title="nips-2008-99-reference" href="../nips2008_reference/nips-2008-High-dimensional_support_union_recovery_in_multivariate_regression_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('bs', 0.513), ('ss', 0.407), ('xs', 0.319), ('lasso', 0.238), ('zs', 0.211), ('regress', 0.169), ('cmax', 0.159), ('sk', 0.148), ('recovery', 0.138), ('las', 0.121), ('mn', 0.119), ('amby', 0.096), ('matrix', 0.092), ('dmax', 0.091), ('cmin', 0.091), ('regul', 0.084), ('un', 0.083), ('lemm', 0.081), ('orthogon', 0.077), ('spars', 0.076)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="99-tfidf-1" href="./nips-2008-High-dimensional_support_union_recovery_in_multivariate_regression.html">99 nips-2008-High-dimensional support union recovery in multivariate regression</a></p>
<p>2 0.37694228 <a title="99-tfidf-2" href="./nips-2008-Phase_transitions_for_high-dimensional_joint_support_recovery.html">179 nips-2008-Phase transitions for high-dimensional joint support recovery</a></p>
<p>3 0.27657911 <a title="99-tfidf-3" href="./nips-2008-Model_Selection_in_Gaussian_Graphical_Models%3A_High-Dimensional_Consistency_of_%5Cboldmath%24%5Cell_1%24-regularized_MLE.html">135 nips-2008-Model Selection in Gaussian Graphical Models: High-Dimensional Consistency of \boldmath$\ell 1$-regularized MLE</a></p>
<p>4 0.20585404 <a title="99-tfidf-4" href="./nips-2008-Robust_Regression_and_Lasso.html">202 nips-2008-Robust Regression and Lasso</a></p>
<p>5 0.18197 <a title="99-tfidf-5" href="./nips-2008-Multi-stage_Convex_Relaxation_for_Learning_with_Sparse_Regularization.html">145 nips-2008-Multi-stage Convex Relaxation for Learning with Sparse Regularization</a></p>
<p>6 0.14638029 <a title="99-tfidf-6" href="./nips-2008-An_Homotopy_Algorithm_for_the_Lasso_with_Online_Observations.html">21 nips-2008-An Homotopy Algorithm for the Lasso with Online Observations</a></p>
<p>7 0.1020002 <a title="99-tfidf-7" href="./nips-2008-Sparse_Online_Learning_via_Truncated_Gradient.html">214 nips-2008-Sparse Online Learning via Truncated Gradient</a></p>
<p>8 0.098327607 <a title="99-tfidf-8" href="./nips-2008-Sparse_Signal_Recovery_Using_Markov_Random_Fields.html">215 nips-2008-Sparse Signal Recovery Using Markov Random Fields</a></p>
<p>9 0.094741002 <a title="99-tfidf-9" href="./nips-2008-Resolution_Limits_of_Sparse_Coding_in_High_Dimensions.html">198 nips-2008-Resolution Limits of Sparse Coding in High Dimensions</a></p>
<p>10 0.080130935 <a title="99-tfidf-10" href="./nips-2008-Estimating_vector_fields_using_sparse_basis_field_expansions.html">75 nips-2008-Estimating vector fields using sparse basis field expansions</a></p>
<p>11 0.07632935 <a title="99-tfidf-11" href="./nips-2008-Differentiable_Sparse_Coding.html">62 nips-2008-Differentiable Sparse Coding</a></p>
<p>12 0.074868724 <a title="99-tfidf-12" href="./nips-2008-Inferring_rankings_under_constrained_sensing.html">106 nips-2008-Inferring rankings under constrained sensing</a></p>
<p>13 0.070199549 <a title="99-tfidf-13" href="./nips-2008-A_Convergent_%24O%28n%29%24_Temporal-difference_Algorithm_for_Off-policy_Learning_with_Linear_Function_Approximation.html">1 nips-2008-A Convergent $O(n)$ Temporal-difference Algorithm for Off-policy Learning with Linear Function Approximation</a></p>
<p>14 0.06994912 <a title="99-tfidf-14" href="./nips-2008-An_interior-point_stochastic_approximation_method_and_an_L1-regularized_delta_rule.html">25 nips-2008-An interior-point stochastic approximation method and an L1-regularized delta rule</a></p>
<p>15 0.069598123 <a title="99-tfidf-15" href="./nips-2008-On_the_Complexity_of_Linear_Prediction%3A_Risk_Bounds%2C_Margin_Bounds%2C_and_Regularization.html">161 nips-2008-On the Complexity of Linear Prediction: Risk Bounds, Margin Bounds, and Regularization</a></p>
<p>16 0.067614265 <a title="99-tfidf-16" href="./nips-2008-Nonparametric_regression_and_classification_with_joint_sparsity_constraints.html">155 nips-2008-Nonparametric regression and classification with joint sparsity constraints</a></p>
<p>17 0.06620086 <a title="99-tfidf-17" href="./nips-2008-Translated_Learning%3A_Transfer_Learning_across_Different_Feature_Spaces.html">242 nips-2008-Translated Learning: Transfer Learning across Different Feature Spaces</a></p>
<p>18 0.065898567 <a title="99-tfidf-18" href="./nips-2008-Exploring_Large_Feature_Spaces_with_Hierarchical_Multiple_Kernel_Learning.html">79 nips-2008-Exploring Large Feature Spaces with Hierarchical Multiple Kernel Learning</a></p>
<p>19 0.06543608 <a title="99-tfidf-19" href="./nips-2008-Regularized_Learning_with_Networks_of_Features.html">194 nips-2008-Regularized Learning with Networks of Features</a></p>
<p>20 0.064538494 <a title="99-tfidf-20" href="./nips-2008-Clusters_and_Coarse_Partitions_in_LP_Relaxations.html">49 nips-2008-Clusters and Coarse Partitions in LP Relaxations</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2008_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.224), (1, 0.067), (2, 0.088), (3, -0.179), (4, 0.108), (5, 0.093), (6, 0.093), (7, 0.192), (8, -0.1), (9, -0.117), (10, -0.028), (11, -0.283), (12, -0.052), (13, 0.021), (14, -0.042), (15, 0.004), (16, -0.076), (17, 0.096), (18, 0.041), (19, 0.013), (20, -0.014), (21, -0.058), (22, -0.045), (23, -0.05), (24, 0.052), (25, -0.047), (26, 0.014), (27, 0.186), (28, 0.088), (29, 0.086), (30, 0.013), (31, -0.046), (32, -0.085), (33, -0.067), (34, -0.011), (35, -0.036), (36, 0.104), (37, -0.006), (38, 0.034), (39, 0.006), (40, 0.004), (41, 0.013), (42, 0.122), (43, -0.136), (44, -0.052), (45, -0.006), (46, -0.04), (47, 0.023), (48, -0.018), (49, -0.052)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94288754 <a title="99-lsi-1" href="./nips-2008-High-dimensional_support_union_recovery_in_multivariate_regression.html">99 nips-2008-High-dimensional support union recovery in multivariate regression</a></p>
<p>2 0.90357649 <a title="99-lsi-2" href="./nips-2008-Phase_transitions_for_high-dimensional_joint_support_recovery.html">179 nips-2008-Phase transitions for high-dimensional joint support recovery</a></p>
<p>3 0.77368778 <a title="99-lsi-3" href="./nips-2008-Robust_Regression_and_Lasso.html">202 nips-2008-Robust Regression and Lasso</a></p>
<p>4 0.71847653 <a title="99-lsi-4" href="./nips-2008-Model_Selection_in_Gaussian_Graphical_Models%3A_High-Dimensional_Consistency_of_%5Cboldmath%24%5Cell_1%24-regularized_MLE.html">135 nips-2008-Model Selection in Gaussian Graphical Models: High-Dimensional Consistency of \boldmath$\ell 1$-regularized MLE</a></p>
<p>5 0.61000103 <a title="99-lsi-5" href="./nips-2008-An_Homotopy_Algorithm_for_the_Lasso_with_Online_Observations.html">21 nips-2008-An Homotopy Algorithm for the Lasso with Online Observations</a></p>
<p>6 0.60318965 <a title="99-lsi-6" href="./nips-2008-Multi-stage_Convex_Relaxation_for_Learning_with_Sparse_Regularization.html">145 nips-2008-Multi-stage Convex Relaxation for Learning with Sparse Regularization</a></p>
<p>7 0.53038251 <a title="99-lsi-7" href="./nips-2008-Covariance_Estimation_for_High_Dimensional_Data_Vectors_Using_the_Sparse_Matrix_Transform.html">54 nips-2008-Covariance Estimation for High Dimensional Data Vectors Using the Sparse Matrix Transform</a></p>
<p>8 0.49382555 <a title="99-lsi-8" href="./nips-2008-Nonparametric_regression_and_classification_with_joint_sparsity_constraints.html">155 nips-2008-Nonparametric regression and classification with joint sparsity constraints</a></p>
<p>9 0.48107439 <a title="99-lsi-9" href="./nips-2008-Inferring_rankings_under_constrained_sensing.html">106 nips-2008-Inferring rankings under constrained sensing</a></p>
<p>10 0.47196224 <a title="99-lsi-10" href="./nips-2008-Sparse_Signal_Recovery_Using_Markov_Random_Fields.html">215 nips-2008-Sparse Signal Recovery Using Markov Random Fields</a></p>
<p>11 0.40904036 <a title="99-lsi-11" href="./nips-2008-Resolution_Limits_of_Sparse_Coding_in_High_Dimensions.html">198 nips-2008-Resolution Limits of Sparse Coding in High Dimensions</a></p>
<p>12 0.40754223 <a title="99-lsi-12" href="./nips-2008-Privacy-preserving_logistic_regression.html">185 nips-2008-Privacy-preserving logistic regression</a></p>
<p>13 0.40402833 <a title="99-lsi-13" href="./nips-2008-An_interior-point_stochastic_approximation_method_and_an_L1-regularized_delta_rule.html">25 nips-2008-An interior-point stochastic approximation method and an L1-regularized delta rule</a></p>
<p>14 0.3973307 <a title="99-lsi-14" href="./nips-2008-One_sketch_for_all%3A_Theory_and_Application_of_Conditional_Random_Sampling.html">167 nips-2008-One sketch for all: Theory and Application of Conditional Random Sampling</a></p>
<p>15 0.38774019 <a title="99-lsi-15" href="./nips-2008-Adaptive_Forward-Backward_Greedy_Algorithm_for_Sparse_Learning_with_Linear_Models.html">14 nips-2008-Adaptive Forward-Backward Greedy Algorithm for Sparse Learning with Linear Models</a></p>
<p>16 0.38605049 <a title="99-lsi-16" href="./nips-2008-Sparse_probabilistic_projections.html">216 nips-2008-Sparse probabilistic projections</a></p>
<p>17 0.38448539 <a title="99-lsi-17" href="./nips-2008-Estimating_vector_fields_using_sparse_basis_field_expansions.html">75 nips-2008-Estimating vector fields using sparse basis field expansions</a></p>
<p>18 0.36891106 <a title="99-lsi-18" href="./nips-2008-Near-minimax_recursive_density_estimation_on_the_binary_hypercube.html">149 nips-2008-Near-minimax recursive density estimation on the binary hypercube</a></p>
<p>19 0.36224392 <a title="99-lsi-19" href="./nips-2008-Sparse_Online_Learning_via_Truncated_Gradient.html">214 nips-2008-Sparse Online Learning via Truncated Gradient</a></p>
<p>20 0.3465499 <a title="99-lsi-20" href="./nips-2008-A_spatially_varying_two-sample_recombinant_coalescent%2C_with_applications_to_HIV_escape_response.html">11 nips-2008-A spatially varying two-sample recombinant coalescent, with applications to HIV escape response</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2008_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(7, 0.197), (30, 0.07), (38, 0.022), (40, 0.112), (60, 0.026), (63, 0.292), (64, 0.088), (71, 0.082)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.88849866 <a title="99-lda-1" href="./nips-2008-High-dimensional_support_union_recovery_in_multivariate_regression.html">99 nips-2008-High-dimensional support union recovery in multivariate regression</a></p>
<p>2 0.84754282 <a title="99-lda-2" href="./nips-2008-Phase_transitions_for_high-dimensional_joint_support_recovery.html">179 nips-2008-Phase transitions for high-dimensional joint support recovery</a></p>
<p>3 0.83713394 <a title="99-lda-3" href="./nips-2008-Dynamic_visual_attention%3A_searching_for_coding_length_increments.html">66 nips-2008-Dynamic visual attention: searching for coding length increments</a></p>
<p>4 0.83685237 <a title="99-lda-4" href="./nips-2008-Resolution_Limits_of_Sparse_Coding_in_High_Dimensions.html">198 nips-2008-Resolution Limits of Sparse Coding in High Dimensions</a></p>
<p>5 0.83086926 <a title="99-lda-5" href="./nips-2008-Model_Selection_in_Gaussian_Graphical_Models%3A_High-Dimensional_Consistency_of_%5Cboldmath%24%5Cell_1%24-regularized_MLE.html">135 nips-2008-Model Selection in Gaussian Graphical Models: High-Dimensional Consistency of \boldmath$\ell 1$-regularized MLE</a></p>
<p>6 0.82985979 <a title="99-lda-6" href="./nips-2008-Covariance_Estimation_for_High_Dimensional_Data_Vectors_Using_the_Sparse_Matrix_Transform.html">54 nips-2008-Covariance Estimation for High Dimensional Data Vectors Using the Sparse Matrix Transform</a></p>
<p>7 0.82401913 <a title="99-lda-7" href="./nips-2008-Sparse_Signal_Recovery_Using_Markov_Random_Fields.html">215 nips-2008-Sparse Signal Recovery Using Markov Random Fields</a></p>
<p>8 0.81984323 <a title="99-lda-8" href="./nips-2008-Learning_a_discriminative_hidden_part_model_for_human_action_recognition.html">119 nips-2008-Learning a discriminative hidden part model for human action recognition</a></p>
<p>9 0.81980932 <a title="99-lda-9" href="./nips-2008-Signal-to-Noise_Ratio_Analysis_of_Policy_Gradient_Algorithms.html">210 nips-2008-Signal-to-Noise Ratio Analysis of Policy Gradient Algorithms</a></p>
<p>10 0.79367816 <a title="99-lda-10" href="./nips-2008-ICA_based_on_a_Smooth_Estimation_of_the_Differential_Entropy.html">102 nips-2008-ICA based on a Smooth Estimation of the Differential Entropy</a></p>
<p>11 0.77972615 <a title="99-lda-11" href="./nips-2008-Robust_Regression_and_Lasso.html">202 nips-2008-Robust Regression and Lasso</a></p>
<p>12 0.77592629 <a title="99-lda-12" href="./nips-2008-Reducing_statistical_dependencies_in_natural_signals_using_radial_Gaussianization.html">192 nips-2008-Reducing statistical dependencies in natural signals using radial Gaussianization</a></p>
<p>13 0.77573156 <a title="99-lda-13" href="./nips-2008-The_Conjoint_Effect_of_Divisive_Normalization_and_Orientation_Selectivity_on_Redundancy_Reduction.html">232 nips-2008-The Conjoint Effect of Divisive Normalization and Orientation Selectivity on Redundancy Reduction</a></p>
<p>14 0.7747972 <a title="99-lda-14" href="./nips-2008-Policy_Search_for_Motor_Primitives_in_Robotics.html">181 nips-2008-Policy Search for Motor Primitives in Robotics</a></p>
<p>15 0.77412838 <a title="99-lda-15" href="./nips-2008-MDPs_with_Non-Deterministic_Policies.html">131 nips-2008-MDPs with Non-Deterministic Policies</a></p>
<p>16 0.7698704 <a title="99-lda-16" href="./nips-2008-Inferring_rankings_under_constrained_sensing.html">106 nips-2008-Inferring rankings under constrained sensing</a></p>
<p>17 0.76901096 <a title="99-lda-17" href="./nips-2008-Regularized_Learning_with_Networks_of_Features.html">194 nips-2008-Regularized Learning with Networks of Features</a></p>
<p>18 0.76846349 <a title="99-lda-18" href="./nips-2008-Multi-stage_Convex_Relaxation_for_Learning_with_Sparse_Regularization.html">145 nips-2008-Multi-stage Convex Relaxation for Learning with Sparse Regularization</a></p>
<p>19 0.76842493 <a title="99-lda-19" href="./nips-2008-Efficient_Exact_Inference_in_Planar_Ising_Models.html">69 nips-2008-Efficient Exact Inference in Planar Ising Models</a></p>
<p>20 0.76671958 <a title="99-lda-20" href="./nips-2008-Estimating_vector_fields_using_sparse_basis_field_expansions.html">75 nips-2008-Estimating vector fields using sparse basis field expansions</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
