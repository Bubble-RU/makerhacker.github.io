<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>133 nips-2008-Mind the Duality Gap: Logarithmic regret algorithms for online optimization</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-133" href="#">nips2008-133</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>133 nips-2008-Mind the Duality Gap: Logarithmic regret algorithms for online optimization</h1>
<br/><p>Source: <a title="nips-2008-133-pdf" href="http://papers.nips.cc/paper/3484-mind-the-duality-gap-logarithmic-regret-algorithms-for-online-optimization.pdf">pdf</a></p><p>Author: Shai Shalev-shwartz, Sham M. Kakade</p><p>Abstract: We describe a primal-dual framework for the design and analysis of online strongly convex optimization algorithms. Our framework yields the tightest known logarithmic regret bounds for Follow-The-Leader and for the gradient descent algorithm proposed in Hazan et al. [2006]. We then show that one can interpolate between these two extreme cases. In particular, we derive a new algorithm that shares the computational simplicity of gradient descent but achieves lower regret in many practical situations. Finally, we further extend our framework for generalized strongly convex functions. 1</p><p>Reference: <a title="nips-2008-133-reference" href="../nips2008_reference/nips-2008-Mind_the_Duality_Gap%3A_Logarithmic_regret_algorithms_for_online_optimization_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Mind the Duality Gap: Logarithmic regret algorithms for online optimization Sham M. [sent-1, score-0.496]
</p><p>2 org  Abstract We describe a primal-dual framework for the design and analysis of online strongly convex optimization algorithms. [sent-4, score-0.781]
</p><p>3 Our framework yields the tightest known logarithmic regret bounds for Follow-The-Leader and for the gradient descent algorithm proposed in Hazan et al. [sent-5, score-0.569]
</p><p>4 In particular, we derive a new algorithm that shares the computational simplicity of gradient descent but achieves lower regret in many practical situations. [sent-8, score-0.398]
</p><p>5 Finally, we further extend our framework for generalized strongly convex functions. [sent-9, score-0.568]
</p><p>6 1  Introduction  In recent years, online regret minimizing algorithms have become widely used and empirically successful algorithms for many machine learning problems. [sent-10, score-0.492]
</p><p>7 Most of these empirically successful algorithms are based on algorithms which are tailored to gen√ eral convex functions, whose regret is O( T ). [sent-13, score-0.629]
</p><p>8 Rather recently, there is a growing body of work providing online algorithms for strongly convex loss functions, with regret guarantees that are only O(log T ). [sent-14, score-1.078]
</p><p>9 These algorithms have potential to be highly applicable since many machine learning optimization problems are in fact strongly convex — either with strongly convex loss functions (e. [sent-15, score-1.26]
</p><p>10 log loss, square loss) or, indirectly, via strongly convex regularizers (e. [sent-17, score-0.523]
</p><p>11 Note that in this later case, the loss function itself may only be just convex but a strongly convex regularizer effectively makes this a strongly convex optimization problem (e. [sent-20, score-1.482]
</p><p>12 The aim of this paper is to provide a template for deriving a wider class of regret-minimizing algorithms for online strongly convex programming. [sent-23, score-0.819]
</p><p>13 Online convex optimization takes place in a sequence of consecutive rounds. [sent-24, score-0.38]
</p><p>14 At each round, the learner predicts a vector wt ∈ S ⊂ Rn , and the environment responds with a convex loss function, t : S → R. [sent-25, score-0.706]
</p><p>15 Roughly speaking, the family of regret minimizing algorithms (for general convex functions) can be seen as varying on two axes, the ‘style’ and the ‘aggressiveness’ of the update. [sent-28, score-0.604]
</p><p>16 In addition to online algorithms’ relative simplicity, the empirical successes are also due to having these two knobs to tune for the problem at hand (which determine the nature of the regret bound). [sent-29, score-0.42]
</p><p>17 By style, we mean updates which favor either rotational invariance (such as gradient descent like update rules) or sparsity (like the multiplicative updates). [sent-30, score-0.27]
</p><p>18 In contrast, there is a family of algorithms which more aggressively update the loss when there is a margin mistake. [sent-34, score-0.264]
</p><p>19 First, the framework works with a complexity function, which determines the style of algorithm and the nature of the regret guarantee (If this function is the L2 norm, then one obtains gradient like updates, and if this function is the KLdistance, then one obtains multiplicative updates). [sent-39, score-0.507]
</p><p>20 Here, the the primal objective function is t=1 t (w) (where t is the loss function provided at round t), and one can construct a dual objective function Dt (·), which only depends on the loss functions 1 , 2 , . [sent-41, score-0.716]
</p><p>21 The algorithm works by incrementally increasing the dual objective value (in an online manner), which can be done since each Dt is only a function of the previous loss functions. [sent-45, score-0.587]
</p><p>22 The level of aggressiveness is seen to be how fast the algorithm is attempting to increase the dual objective value. [sent-47, score-0.452]
</p><p>23 This paper focuses on extending the duality framework for online convex programming to the case of strongly convex functions. [sent-48, score-1.12]
</p><p>24 This analysis provides a more uniﬁed and intuitive view of the extant algorithms for online strongly convex programming. [sent-49, score-0.764]
</p><p>25 An important observation we make is that any σ-strongly convex loss function can be rewritten as i (w) = f (w) + gi (w), where f is a ﬁxed σstrongly convex function (i. [sent-50, score-0.781]
</p><p>26 f does not depend on i), and gi is a convex function. [sent-52, score-0.396]
</p><p>27 Therefore, after t t online rounds, the amount of intrinsic strong convexity we have in the primal objective i=1 t (w) 1 is at least σ t. [sent-53, score-0.299]
</p><p>28 Furthermore, the template algorithm serves as a vehicle for deriving new algorithms (which enjoy logarithmic regret guarantees). [sent-59, score-0.484]
</p><p>29 Next, we further generalize our algorithmic framework to include strongly convex complexity functions f with respect to arbitrary norms · . [sent-64, score-0.741]
</p><p>30 6 we conclude with a side-by-side comparison of our algorithmic framework for strongly convex functions and the framework for (non-strongly) convex functions given in Shalev-Shwartz [2007]. [sent-67, score-1.078]
</p><p>31 The dual norm is deﬁned as λ = sup{ x, λ : x ≤ 1}. [sent-90, score-0.302]
</p><p>32 For example, the Euclidean norm, x 2 = ( x, x )1/2 is dual to itself and the L1 norm, x 1 = i |xi |, is dual to the L∞ norm, x ∞ = maxi |xi |. [sent-91, score-0.498]
</p><p>33 , T : Deﬁne wt = − σ  1  1:(t−1)  λt 1:(t−1)  σt 2 + gt (w) and suffer loss t (w) = 2 w t+1 t+1 λ1 , . [sent-95, score-0.842]
</p><p>34 Here the algorithm’s decision wt is the best decision with respect to the previous losses. [sent-110, score-0.318]
</p><p>35 This presentation exposes the implicit role of the dual variables. [sent-111, score-0.249]
</p><p>36 We next recall a few deﬁnitions from convex analysis. [sent-114, score-0.299]
</p><p>37 A function f is σ-strongly convex if σ f (αu + (1 − α)v) ≤ αf (u) + (1 − α)f (v) − α (1 − α) u − v 2 . [sent-115, score-0.299]
</p><p>38 If a function f is σ-strongly convex then the function g(w) = f (w) − σ w 2 is convex. [sent-118, score-0.299]
</p><p>39 Lemma 1 Let f be a closed and convex function and let ∂f (w ) be its differential set at w . [sent-129, score-0.329]
</p><p>40 ,λT  3  t=1  T  λt ) −  t=1  T  gt (λt ) ≤ min f (w) + w  gt (w) . [sent-134, score-0.874]
</p><p>41 The dual view of FTL will help us to derive a family of logarithmic regret algorithms for online convex optimization with strongly convex functions. [sent-136, score-1.712]
</p><p>42 Recall that FTL algorithm is deﬁned as follows: t−1  wt = argmin w  i (w)  . [sent-137, score-0.318]
</p><p>43 (2)  i=1  For each i ∈ [t − 1] deﬁne gi (w) = i (w) − σi w 2 , where σi is the largest scalar such that gi is 2 still a convex function. [sent-138, score-0.493]
</p><p>44 The assumption that i is σ-strongly convex guarantees that σi ≥ σ. [sent-139, score-0.299]
</p><p>45 2) is to maximize the following dual objective function Dt (λ1 , . [sent-143, score-0.316]
</p><p>46 The relation between the optimal dual variables and 1 t−1 the optimal primal vector is given by (see again Sec. [sent-151, score-0.34]
</p><p>47 In particular, under this assumption, we have that the above setting for wt is in fact a minimizer of the primal objective, since (λt , . [sent-158, score-0.365]
</p><p>48 , λt ) maximizes the dual 1 t−1 objective (see the appendix). [sent-161, score-0.316]
</p><p>49 Since t (w) = σt w 2 + gt (w) and v ∈ ∂ t (w) we have that λ ∈ ∂gt (w). [sent-199, score-0.423]
</p><p>50 , T : Deﬁne wt = − σ  1  1:(t−1)  λt 1:(t−1)  σt t (w) = 2 λt+1 , . [sent-217, score-0.295]
</p><p>51 the t 1  Receive a function  Update  w  2  + gt (w) and suffer loss  t (wt )  following holds  ∃λt ∈ ∂gt (wt ), s. [sent-222, score-0.587]
</p><p>52 , λt , λt ) t−1 1 t 1  Figure 2: A primal-dual algorithmic framework for online convex optimization. [sent-230, score-0.591]
</p><p>53 (8) holds with equality, and this leads to the previous regret bound holding with equality. [sent-240, score-0.276]
</p><p>54 Here, we extend the analysis and derive a more general algorithmic framework for online optimization. [sent-244, score-0.292]
</p><p>55 We ﬁrst make the important observation that Lemma 2 is not speciﬁc to the FTL algorithm and in fact holds for any conﬁguration of dual variables. [sent-246, score-0.312]
</p><p>56 Consider an arbitrary sequence of dual variables: (λ2 ), (λ3 , λ3 ), . [sent-247, score-0.279]
</p><p>57 (7) with the following inequality that holds for any sequence of dual variables: T  T t=1  ∆t = DT +1 (λT +1 , . [sent-256, score-0.319]
</p><p>58 1) is equivalent to optimizing the dual variables at each online round. [sent-283, score-0.432]
</p><p>59 [2007] suggested the following update rule for differentiable strongly convex function wt+1 = wt −  1 σ1:t  t (wt )  (12)  . [sent-288, score-0.916]
</p><p>60 Using a simple inductive argument, it is possible to show that the above update rule is equivalent to the following update rule of the dual variables (λt+1 , . [sent-289, score-0.466]
</p><p>61 The former makes the largest possible increase of the dual while the latter makes the smallest possible increase that still satisﬁes the sufﬁcient dual increase requirement. [sent-300, score-0.498]
</p><p>62 Intuitively, the FTL method should have smaller regret as it consumes more of its potential earlier in the optimization process. [sent-301, score-0.287]
</p><p>63 However, its computational complexity is large as it requires a full blown optimization procedure at each online round. [sent-302, score-0.287]
</p><p>64 A possible compromise is to fully optimize the dual objective but only with respect to a small number of dual variables. [sent-303, score-0.638]
</p><p>65 In the extreme case, we optimize only with respect to the last dual variable. [sent-304, score-0.348]
</p><p>66 The computational complexity of performing this update is often small as we optimize over a single dual vector. [sent-310, score-0.384]
</p><p>67 5  Generalized strongly convex functions  In this section, we extend our algorithmic framework to deal with generalized strongly convex functions. [sent-312, score-1.206]
</p><p>68 Deﬁnition 1 A continuous function f is σ-strongly convex over a convex set S with respect to a norm · if S is contained in the domain of f and for all v, u ∈ S and α ∈ [0, 1] we have σ (14) f (α v + (1 − α) u) ≤ α f (v) + (1 − α) f (u) − α (1 − α) v − u 2 . [sent-314, score-0.674]
</p><p>69 2 2  is strongly convex with respect to the  n  1 Example 4 The function f (w) = i=1 wi log(wi / n ) is strongly convex over the probability simn plex, S = {w ∈ R+ : w 1 = 1}, with respect to the L1 norm. [sent-317, score-1.092]
</p><p>70 1 Example 5 For q ∈ (1, 2), the function f (w) = 2(q−1) w 2 is strongly convex over S = Rn with q 1 respect to the Lq norm. [sent-319, score-0.546]
</p><p>71 In the appendix, we list several important properties of strongly convex functions. [sent-322, score-0.523]
</p><p>72 In particular, the Fenchel conjugate of a strongly convex function is differentiable. [sent-323, score-0.575]
</p><p>73 6  I NPUT: A strongly convex function f  I NPUT: A σ-strongly convex function f  F OR t = 1, 2, . [sent-324, score-0.822]
</p><p>74 , T :  1) Deﬁne wt =  „ t « λ √ f − 1:(t−1) t  2) Receive a function 3) Suffer loss 4) Update  1) Deﬁne wt =  2) Receive a function  t  3) Suffer loss  t (wt )  λt+1 , . [sent-330, score-0.762]
</p><p>75 there  „  −  t  λt 1:(t−1) σ1:t  «  = σf + gt  t (wt )  λt+1 , . [sent-335, score-0.423]
</p><p>76 , λt , λt ) 1 t−1  Figure 3: Primal-dual template algorithms for general online convex optimization (left) and online strongly P  convex optimization (right). [sent-352, score-1.35]
</p><p>77 t i=1  ai , and for notational convenient, we implicitly assume that  Consider the case where for all t, t can be written as σt f + gt where f is 1-strongly convex with respect to some norm · and gt is a convex function. [sent-355, score-1.52]
</p><p>78 We also make the simplifying assumption that σt is known to the forecaster before he deﬁnes wt . [sent-356, score-0.295]
</p><p>79 For each round t, we now deﬁne the primal objective to be t−1  Pt (w) = σ1:(t−1) f (w) +  gi (w) . [sent-357, score-0.295]
</p><p>80 (15)  i=1  The dual objective is (see again Sec. [sent-358, score-0.316]
</p><p>81 (16)  i=1  An algorithmic framework for online optimization in the presence of general strongly convex functions is given on the right-hand side of Fig. [sent-363, score-0.92]
</p><p>82 The following theorem provides a logarithmic regret bound for the algorithmic framework given on the right-hand side of Fig. [sent-365, score-0.481]
</p><p>83 , T be a sequence of functions such that for all t ∈ [T ], t = σt f + gt for f being strongly convex w. [sent-370, score-1.006]
</p><p>84 3 (right) satisﬁes T  T t (wt ) t=1  where vt ∈ ∂gt (wt ) and ·  − min w  t (w) t=1  ≤  1 2  T t=1  vt 2 , σ1:t  (17)  is the norm dual to · . [sent-375, score-0.51]
</p><p>85 B  6  Summary  In this paper, we extended the primal-dual algorithmic framework for general convex functions from Shalev-Shwartz and Singer [2006], Shalev-Shwartz [2007] to strongly convex functions. [sent-377, score-0.982]
</p><p>86 The left algorithm is the primal-dual algorithm for general convex functions from Shalev-Shwartz and Singer [2006], Shalev-Shwartz [2007]. [sent-380, score-0.375]
</p><p>87 , λt ) are the dual variables at time t, and Dt (·) is the dual objective 1 t 7  function at time t (which is a lower bound on primal value). [sent-384, score-0.656]
</p><p>88 The function f is the gradient of the conjugate function of f , which can be viewed as a projection √ the dual variables back into the priof mal space. [sent-385, score-0.385]
</p><p>89 , 2001, Kivinen and Warmuth, 1997], which specializes to gradient descent when f is the squared 2-norm or the exponentiated gradient descent algorithm when f is the relative entropy. [sent-388, score-0.328]
</p><p>90 At the most aggressive extreme, where Dt is maximized at √ round, we each t−1 have ‘Follow the Regularized Leader’, which is wt = arg minw i=1 i (w) + t f (w). [sent-389, score-0.45]
</p><p>91 The right algorithm in Figure 3 is our new contribution for strongly convex functions. [sent-392, score-0.546]
</p><p>92 Any σstrongly convex loss function can be decomposed into t = σf + gt , where gt is convex. [sent-393, score-1.231]
</p><p>93 The algorithm for strongly convex functions is different in two ways. [sent-394, score-0.576]
</p><p>94 Second, more subtly, the condition on the dual variables (in Step 4) is only determined by the subgradient of gt , rather than the subgradient of t . [sent-396, score-0.801]
</p><p>95 At the most aggressive end of the spectrum, where Dt is maximized at each round, we have the t−1 ‘Follow the Leader’ (FTL) algorithm: wt = arg minw i=1 i (w). [sent-397, score-0.45]
</p><p>96 At the least aggressive end, 1 we have the gradient descent algorithm of Hazan et al. [sent-398, score-0.285]
</p><p>97 Our template algorithm suggests a natural compromise, which is to optimize the dual objective but only with respect to a small number of dual variables (say the most current dual variable) — we coin this algorithm online coordinate-dual-ascent. [sent-404, score-1.144]
</p><p>98 This variant update still enjoys a logarithmic regret bound. [sent-406, score-0.432]
</p><p>99 Optimal strategies and minimax lower bounds for online convex games. [sent-412, score-0.489]
</p><p>100 Mirror descent and nonlinear projected subgradient methods for convex optimization. [sent-424, score-0.429]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('gt', 0.423), ('ftl', 0.339), ('convex', 0.299), ('wt', 0.295), ('dt', 0.259), ('dual', 0.249), ('regret', 0.236), ('strongly', 0.224), ('online', 0.162), ('hazan', 0.127), ('fenchel', 0.118), ('aggressiveness', 0.113), ('gi', 0.097), ('duality', 0.091), ('logarithmic', 0.091), ('vt', 0.09), ('aggressive', 0.088), ('loss', 0.086), ('algorithmic', 0.085), ('update', 0.077), ('descent', 0.076), ('primal', 0.07), ('objective', 0.067), ('gradient', 0.063), ('round', 0.061), ('singer', 0.06), ('crammer', 0.058), ('lemma', 0.058), ('template', 0.055), ('subgradient', 0.054), ('extreme', 0.053), ('norm', 0.053), ('conjugate', 0.052), ('optimization', 0.051), ('pt', 0.048), ('algorithms', 0.047), ('nput', 0.045), ('retrospect', 0.045), ('warmup', 0.045), ('framework', 0.045), ('minw', 0.042), ('holds', 0.04), ('technological', 0.039), ('toyota', 0.039), ('blown', 0.039), ('borwein', 0.039), ('grove', 0.039), ('leader', 0.039), ('letters', 0.039), ('appendix', 0.038), ('suffer', 0.038), ('equality', 0.037), ('style', 0.036), ('beck', 0.036), ('abernethy', 0.036), ('mirror', 0.036), ('receive', 0.035), ('et', 0.035), ('uni', 0.035), ('complexity', 0.035), ('shai', 0.034), ('maximizer', 0.034), ('nineteenth', 0.034), ('deriving', 0.032), ('aggressively', 0.032), ('kivinen', 0.032), ('view', 0.032), ('updates', 0.031), ('sham', 0.03), ('functions', 0.03), ('closed', 0.03), ('bartlett', 0.03), ('sequence', 0.03), ('scalars', 0.029), ('chicago', 0.029), ('enjoys', 0.028), ('minimax', 0.028), ('proof', 0.028), ('min', 0.028), ('exponentiated', 0.027), ('hebrew', 0.027), ('compromise', 0.027), ('learner', 0.026), ('satis', 0.026), ('denoted', 0.025), ('maximized', 0.025), ('growing', 0.024), ('euclidean', 0.024), ('side', 0.024), ('respect', 0.023), ('optimize', 0.023), ('multiplicative', 0.023), ('obtains', 0.023), ('algorithm', 0.023), ('tune', 0.022), ('family', 0.022), ('argmax', 0.022), ('rule', 0.021), ('conclude', 0.021), ('variables', 0.021)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999899 <a title="133-tfidf-1" href="./nips-2008-Mind_the_Duality_Gap%3A_Logarithmic_regret_algorithms_for_online_optimization.html">133 nips-2008-Mind the Duality Gap: Logarithmic regret algorithms for online optimization</a></p>
<p>Author: Shai Shalev-shwartz, Sham M. Kakade</p><p>Abstract: We describe a primal-dual framework for the design and analysis of online strongly convex optimization algorithms. Our framework yields the tightest known logarithmic regret bounds for Follow-The-Leader and for the gradient descent algorithm proposed in Hazan et al. [2006]. We then show that one can interpolate between these two extreme cases. In particular, we derive a new algorithm that shares the computational simplicity of gradient descent but achieves lower regret in many practical situations. Finally, we further extend our framework for generalized strongly convex functions. 1</p><p>2 0.31414804 <a title="133-tfidf-2" href="./nips-2008-On_the_Generalization_Ability_of_Online_Strongly_Convex_Programming_Algorithms.html">164 nips-2008-On the Generalization Ability of Online Strongly Convex Programming Algorithms</a></p>
<p>Author: Sham M. Kakade, Ambuj Tewari</p><p>Abstract: This paper examines the generalization properties of online convex programming algorithms when the loss function is Lipschitz and strongly convex. Our main result is a sharp bound, that holds with high probability, on the excess risk of the output of an online algorithm in terms of the average regret. This allows one to use recent algorithms with logarithmic cumulative regret guarantees to achieve fast convergence rates for the excess risk with high probability. As a corollary, we characterize the convergence rate of P EGASOS (with high probability), a recently proposed method for solving the SVM optimization problem. 1</p><p>3 0.19997661 <a title="133-tfidf-3" href="./nips-2008-Sparse_Online_Learning_via_Truncated_Gradient.html">214 nips-2008-Sparse Online Learning via Truncated Gradient</a></p>
<p>Author: John Langford, Lihong Li, Tong Zhang</p><p>Abstract: We propose a general method called truncated gradient to induce sparsity in the weights of online-learning algorithms with convex loss. This method has several essential properties. First, the degree of sparsity is continuous—a parameter controls the rate of sparsiﬁcation from no sparsiﬁcation to total sparsiﬁcation. Second, the approach is theoretically motivated, and an instance of it can be regarded as an online counterpart of the popular L1 -regularization method in the batch setting. We prove small rates of sparsiﬁcation result in only small additional regret with respect to typical online-learning guarantees. Finally, the approach works well empirically. We apply it to several datasets and ﬁnd for datasets with large numbers of features, substantial sparsity is discoverable. 1</p><p>4 0.18574648 <a title="133-tfidf-4" href="./nips-2008-On_the_Complexity_of_Linear_Prediction%3A_Risk_Bounds%2C_Margin_Bounds%2C_and_Regularization.html">161 nips-2008-On the Complexity of Linear Prediction: Risk Bounds, Margin Bounds, and Regularization</a></p>
<p>Author: Sham M. Kakade, Karthik Sridharan, Ambuj Tewari</p><p>Abstract: This work characterizes the generalization ability of algorithms whose predictions are linear in the input vector. To this end, we provide sharp bounds for Rademacher and Gaussian complexities of (constrained) linear classes, which directly lead to a number of generalization bounds. This derivation provides simpliﬁed proofs of a number of corollaries including: risk bounds for linear prediction (including settings where the weight vectors are constrained by either L2 or L1 constraints), margin bounds (including both L2 and L1 margins, along with more general notions based on relative entropy), a proof of the PAC-Bayes theorem, and upper bounds on L2 covering numbers (with Lp norm constraints and relative entropy constraints). In addition to providing a uniﬁed analysis, the results herein provide some of the sharpest risk and margin bounds. Interestingly, our results show that the uniform convergence rates of empirical risk minimization algorithms tightly match the regret bounds of online learning algorithms for linear prediction, up to a constant factor of 2. 1</p><p>5 0.17595372 <a title="133-tfidf-5" href="./nips-2008-Online_Metric_Learning_and_Fast_Similarity_Search.html">168 nips-2008-Online Metric Learning and Fast Similarity Search</a></p>
<p>Author: Prateek Jain, Brian Kulis, Inderjit S. Dhillon, Kristen Grauman</p><p>Abstract: Metric learning algorithms can provide useful distance functions for a variety of domains, and recent work has shown good accuracy for problems where the learner can access all distance constraints at once. However, in many real applications, constraints are only available incrementally, thus necessitating methods that can perform online updates to the learned metric. Existing online algorithms offer bounds on worst-case performance, but typically do not perform well in practice as compared to their ofﬂine counterparts. We present a new online metric learning algorithm that updates a learned Mahalanobis metric based on LogDet regularization and gradient descent. We prove theoretical worst-case performance bounds, and empirically compare the proposed method against existing online metric learning algorithms. To further boost the practicality of our approach, we develop an online locality-sensitive hashing scheme which leads to efﬁcient updates to data structures used for fast approximate similarity search. We demonstrate our algorithm on multiple datasets and show that it outperforms relevant baselines.</p><p>6 0.14209321 <a title="133-tfidf-6" href="./nips-2008-Multi-stage_Convex_Relaxation_for_Learning_with_Sparse_Regularization.html">145 nips-2008-Multi-stage Convex Relaxation for Learning with Sparse Regularization</a></p>
<p>7 0.14173627 <a title="133-tfidf-7" href="./nips-2008-Structured_ranking_learning_using_cumulative_distribution_networks.html">224 nips-2008-Structured ranking learning using cumulative distribution networks</a></p>
<p>8 0.13269225 <a title="133-tfidf-8" href="./nips-2008-Fast_Rates_for_Regularized_Objectives.html">85 nips-2008-Fast Rates for Regularized Objectives</a></p>
<p>9 0.12353391 <a title="133-tfidf-9" href="./nips-2008-Online_Optimization_in_X-Armed_Bandits.html">170 nips-2008-Online Optimization in X-Armed Bandits</a></p>
<p>10 0.1208652 <a title="133-tfidf-10" href="./nips-2008-Linear_Classification_and_Selective_Sampling_Under_Low_Noise_Conditions.html">123 nips-2008-Linear Classification and Selective Sampling Under Low Noise Conditions</a></p>
<p>11 0.12026633 <a title="133-tfidf-11" href="./nips-2008-Tighter_Bounds_for_Structured_Estimation.html">239 nips-2008-Tighter Bounds for Structured Estimation</a></p>
<p>12 0.116397 <a title="133-tfidf-12" href="./nips-2008-Clustering_via_LP-based_Stabilities.html">48 nips-2008-Clustering via LP-based Stabilities</a></p>
<p>13 0.11511074 <a title="133-tfidf-13" href="./nips-2008-From_Online_to_Batch_Learning_with_Cutoff-Averaging.html">88 nips-2008-From Online to Batch Learning with Cutoff-Averaging</a></p>
<p>14 0.1079771 <a title="133-tfidf-14" href="./nips-2008-Domain_Adaptation_with_Multiple_Sources.html">65 nips-2008-Domain Adaptation with Multiple Sources</a></p>
<p>15 0.10626676 <a title="133-tfidf-15" href="./nips-2008-PSDBoost%3A_Matrix-Generation_Linear_Programming_for_Positive_Semidefinite_Matrices_Learning.html">175 nips-2008-PSDBoost: Matrix-Generation Linear Programming for Positive Semidefinite Matrices Learning</a></p>
<p>16 0.10311505 <a title="133-tfidf-16" href="./nips-2008-Supervised_Exponential_Family_Principal_Component_Analysis_via_Convex_Optimization.html">227 nips-2008-Supervised Exponential Family Principal Component Analysis via Convex Optimization</a></p>
<p>17 0.096954428 <a title="133-tfidf-17" href="./nips-2008-Clustered_Multi-Task_Learning%3A_A_Convex_Formulation.html">47 nips-2008-Clustered Multi-Task Learning: A Convex Formulation</a></p>
<p>18 0.090246603 <a title="133-tfidf-18" href="./nips-2008-Near-optimal_Regret_Bounds_for_Reinforcement_Learning.html">150 nips-2008-Near-optimal Regret Bounds for Reinforcement Learning</a></p>
<p>19 0.08732418 <a title="133-tfidf-19" href="./nips-2008-Exact_Convex_Confidence-Weighted_Learning.html">78 nips-2008-Exact Convex Confidence-Weighted Learning</a></p>
<p>20 0.086412169 <a title="133-tfidf-20" href="./nips-2008-An_Online_Algorithm_for_Maximizing_Submodular_Functions.html">22 nips-2008-An Online Algorithm for Maximizing Submodular Functions</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2008_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.213), (1, 0.034), (2, -0.279), (3, 0.046), (4, -0.213), (5, 0.068), (6, -0.093), (7, -0.02), (8, -0.036), (9, -0.026), (10, -0.095), (11, 0.148), (12, -0.011), (13, 0.139), (14, 0.173), (15, -0.047), (16, -0.07), (17, 0.023), (18, -0.1), (19, 0.08), (20, -0.154), (21, 0.089), (22, 0.002), (23, 0.123), (24, -0.071), (25, -0.04), (26, -0.074), (27, 0.035), (28, -0.061), (29, 0.001), (30, -0.202), (31, -0.055), (32, -0.001), (33, -0.053), (34, -0.018), (35, -0.003), (36, 0.005), (37, 0.098), (38, -0.06), (39, 0.036), (40, 0.027), (41, -0.081), (42, -0.059), (43, 0.034), (44, 0.067), (45, -0.088), (46, 0.062), (47, 0.041), (48, -0.0), (49, 0.034)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97705859 <a title="133-lsi-1" href="./nips-2008-Mind_the_Duality_Gap%3A_Logarithmic_regret_algorithms_for_online_optimization.html">133 nips-2008-Mind the Duality Gap: Logarithmic regret algorithms for online optimization</a></p>
<p>Author: Shai Shalev-shwartz, Sham M. Kakade</p><p>Abstract: We describe a primal-dual framework for the design and analysis of online strongly convex optimization algorithms. Our framework yields the tightest known logarithmic regret bounds for Follow-The-Leader and for the gradient descent algorithm proposed in Hazan et al. [2006]. We then show that one can interpolate between these two extreme cases. In particular, we derive a new algorithm that shares the computational simplicity of gradient descent but achieves lower regret in many practical situations. Finally, we further extend our framework for generalized strongly convex functions. 1</p><p>2 0.82807624 <a title="133-lsi-2" href="./nips-2008-On_the_Generalization_Ability_of_Online_Strongly_Convex_Programming_Algorithms.html">164 nips-2008-On the Generalization Ability of Online Strongly Convex Programming Algorithms</a></p>
<p>Author: Sham M. Kakade, Ambuj Tewari</p><p>Abstract: This paper examines the generalization properties of online convex programming algorithms when the loss function is Lipschitz and strongly convex. Our main result is a sharp bound, that holds with high probability, on the excess risk of the output of an online algorithm in terms of the average regret. This allows one to use recent algorithms with logarithmic cumulative regret guarantees to achieve fast convergence rates for the excess risk with high probability. As a corollary, we characterize the convergence rate of P EGASOS (with high probability), a recently proposed method for solving the SVM optimization problem. 1</p><p>3 0.6603896 <a title="133-lsi-3" href="./nips-2008-Fast_Rates_for_Regularized_Objectives.html">85 nips-2008-Fast Rates for Regularized Objectives</a></p>
<p>Author: Karthik Sridharan, Shai Shalev-shwartz, Nathan Srebro</p><p>Abstract: We study convergence properties of empirical minimization of a stochastic strongly convex objective, where the stochastic component is linear. We show that the value attained by the empirical minimizer converges to the optimal value with rate 1/n. The result applies, in particular, to the SVM objective. Thus, we obtain a rate of 1/n on the convergence of the SVM objective (with ﬁxed regularization parameter) to its inﬁnite data limit. We demonstrate how this is essential for obtaining certain type of oracle inequalities for SVMs. The results extend also to approximate minimization as well as to strong convexity with respect to an arbitrary norm, and so also to objectives regularized using other p norms. 1</p><p>4 0.58975953 <a title="133-lsi-4" href="./nips-2008-Sparse_Online_Learning_via_Truncated_Gradient.html">214 nips-2008-Sparse Online Learning via Truncated Gradient</a></p>
<p>Author: John Langford, Lihong Li, Tong Zhang</p><p>Abstract: We propose a general method called truncated gradient to induce sparsity in the weights of online-learning algorithms with convex loss. This method has several essential properties. First, the degree of sparsity is continuous—a parameter controls the rate of sparsiﬁcation from no sparsiﬁcation to total sparsiﬁcation. Second, the approach is theoretically motivated, and an instance of it can be regarded as an online counterpart of the popular L1 -regularization method in the batch setting. We prove small rates of sparsiﬁcation result in only small additional regret with respect to typical online-learning guarantees. Finally, the approach works well empirically. We apply it to several datasets and ﬁnd for datasets with large numbers of features, substantial sparsity is discoverable. 1</p><p>5 0.58637768 <a title="133-lsi-5" href="./nips-2008-An_Online_Algorithm_for_Maximizing_Submodular_Functions.html">22 nips-2008-An Online Algorithm for Maximizing Submodular Functions</a></p>
<p>Author: Matthew Streeter, Daniel Golovin</p><p>Abstract: We present an algorithm for solving a broad class of online resource allocation problems. Our online algorithm can be applied in environments where abstract jobs arrive one at a time, and one can complete the jobs by investing time in a number of abstract activities, according to some schedule. We assume that the fraction of jobs completed by a schedule is a monotone, submodular function of a set of pairs (v, τ ), where τ is the time invested in activity v. Under this assumption, our online algorithm performs near-optimally according to two natural metrics: (i) the fraction of jobs completed within time T , for some ﬁxed deadline T > 0, and (ii) the average time required to complete each job. We evaluate our algorithm experimentally by using it to learn, online, a schedule for allocating CPU time among solvers entered in the 2007 SAT solver competition. 1</p><p>6 0.58633155 <a title="133-lsi-6" href="./nips-2008-Online_Metric_Learning_and_Fast_Similarity_Search.html">168 nips-2008-Online Metric Learning and Fast Similarity Search</a></p>
<p>7 0.56930315 <a title="133-lsi-7" href="./nips-2008-From_Online_to_Batch_Learning_with_Cutoff-Averaging.html">88 nips-2008-From Online to Batch Learning with Cutoff-Averaging</a></p>
<p>8 0.55805749 <a title="133-lsi-8" href="./nips-2008-Tighter_Bounds_for_Structured_Estimation.html">239 nips-2008-Tighter Bounds for Structured Estimation</a></p>
<p>9 0.50433791 <a title="133-lsi-9" href="./nips-2008-Multi-stage_Convex_Relaxation_for_Learning_with_Sparse_Regularization.html">145 nips-2008-Multi-stage Convex Relaxation for Learning with Sparse Regularization</a></p>
<p>10 0.48867437 <a title="133-lsi-10" href="./nips-2008-On_the_Complexity_of_Linear_Prediction%3A_Risk_Bounds%2C_Margin_Bounds%2C_and_Regularization.html">161 nips-2008-On the Complexity of Linear Prediction: Risk Bounds, Margin Bounds, and Regularization</a></p>
<p>11 0.44279104 <a title="133-lsi-11" href="./nips-2008-Linear_Classification_and_Selective_Sampling_Under_Low_Noise_Conditions.html">123 nips-2008-Linear Classification and Selective Sampling Under Low Noise Conditions</a></p>
<p>12 0.44061205 <a title="133-lsi-12" href="./nips-2008-Online_Optimization_in_X-Armed_Bandits.html">170 nips-2008-Online Optimization in X-Armed Bandits</a></p>
<p>13 0.43839842 <a title="133-lsi-13" href="./nips-2008-Clustered_Multi-Task_Learning%3A_A_Convex_Formulation.html">47 nips-2008-Clustered Multi-Task Learning: A Convex Formulation</a></p>
<p>14 0.41650385 <a title="133-lsi-14" href="./nips-2008-On_the_Efficient_Minimization_of_Classification_Calibrated_Surrogates.html">163 nips-2008-On the Efficient Minimization of Classification Calibrated Surrogates</a></p>
<p>15 0.41394681 <a title="133-lsi-15" href="./nips-2008-Clustering_via_LP-based_Stabilities.html">48 nips-2008-Clustering via LP-based Stabilities</a></p>
<p>16 0.39713815 <a title="133-lsi-16" href="./nips-2008-PSDBoost%3A_Matrix-Generation_Linear_Programming_for_Positive_Semidefinite_Matrices_Learning.html">175 nips-2008-PSDBoost: Matrix-Generation Linear Programming for Positive Semidefinite Matrices Learning</a></p>
<p>17 0.38261971 <a title="133-lsi-17" href="./nips-2008-On_the_Design_of_Loss_Functions_for_Classification%3A_theory%2C_robustness_to_outliers%2C_and_SavageBoost.html">162 nips-2008-On the Design of Loss Functions for Classification: theory, robustness to outliers, and SavageBoost</a></p>
<p>18 0.37575418 <a title="133-lsi-18" href="./nips-2008-Improved_Moves_for_Truncated_Convex_Models.html">104 nips-2008-Improved Moves for Truncated Convex Models</a></p>
<p>19 0.36935255 <a title="133-lsi-19" href="./nips-2008-Supervised_Exponential_Family_Principal_Component_Analysis_via_Convex_Optimization.html">227 nips-2008-Supervised Exponential Family Principal Component Analysis via Convex Optimization</a></p>
<p>20 0.36910766 <a title="133-lsi-20" href="./nips-2008-Posterior_Consistency_of_the_Silverman_g-prior_in_Bayesian_Model_Choice.html">182 nips-2008-Posterior Consistency of the Silverman g-prior in Bayesian Model Choice</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2008_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(6, 0.184), (7, 0.047), (12, 0.086), (15, 0.016), (28, 0.139), (57, 0.041), (59, 0.015), (63, 0.064), (71, 0.062), (77, 0.028), (83, 0.037), (84, 0.194)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.83273971 <a title="133-lda-1" href="./nips-2008-Mind_the_Duality_Gap%3A_Logarithmic_regret_algorithms_for_online_optimization.html">133 nips-2008-Mind the Duality Gap: Logarithmic regret algorithms for online optimization</a></p>
<p>Author: Shai Shalev-shwartz, Sham M. Kakade</p><p>Abstract: We describe a primal-dual framework for the design and analysis of online strongly convex optimization algorithms. Our framework yields the tightest known logarithmic regret bounds for Follow-The-Leader and for the gradient descent algorithm proposed in Hazan et al. [2006]. We then show that one can interpolate between these two extreme cases. In particular, we derive a new algorithm that shares the computational simplicity of gradient descent but achieves lower regret in many practical situations. Finally, we further extend our framework for generalized strongly convex functions. 1</p><p>2 0.78935957 <a title="133-lda-2" href="./nips-2008-QUIC-SVD%3A_Fast_SVD_Using_Cosine_Trees.html">188 nips-2008-QUIC-SVD: Fast SVD Using Cosine Trees</a></p>
<p>Author: Michael P. Holmes, Jr. Isbell, Charles Lee, Alexander G. Gray</p><p>Abstract: The Singular Value Decomposition is a key operation in many machine learning methods. Its computational cost, however, makes it unscalable and impractical for applications involving large datasets or real-time responsiveness, which are becoming increasingly common. We present a new method, QUIC-SVD, for fast approximation of the whole-matrix SVD based on a new sampling mechanism called the cosine tree. Our empirical tests show speedups of several orders of magnitude over exact SVD. Such scalability should enable QUIC-SVD to accelerate and enable a wide array of SVD-based methods and applications. 1</p><p>3 0.76211435 <a title="133-lda-3" href="./nips-2008-On_the_Generalization_Ability_of_Online_Strongly_Convex_Programming_Algorithms.html">164 nips-2008-On the Generalization Ability of Online Strongly Convex Programming Algorithms</a></p>
<p>Author: Sham M. Kakade, Ambuj Tewari</p><p>Abstract: This paper examines the generalization properties of online convex programming algorithms when the loss function is Lipschitz and strongly convex. Our main result is a sharp bound, that holds with high probability, on the excess risk of the output of an online algorithm in terms of the average regret. This allows one to use recent algorithms with logarithmic cumulative regret guarantees to achieve fast convergence rates for the excess risk with high probability. As a corollary, we characterize the convergence rate of P EGASOS (with high probability), a recently proposed method for solving the SVM optimization problem. 1</p><p>4 0.74917758 <a title="133-lda-4" href="./nips-2008-Sparse_Online_Learning_via_Truncated_Gradient.html">214 nips-2008-Sparse Online Learning via Truncated Gradient</a></p>
<p>Author: John Langford, Lihong Li, Tong Zhang</p><p>Abstract: We propose a general method called truncated gradient to induce sparsity in the weights of online-learning algorithms with convex loss. This method has several essential properties. First, the degree of sparsity is continuous—a parameter controls the rate of sparsiﬁcation from no sparsiﬁcation to total sparsiﬁcation. Second, the approach is theoretically motivated, and an instance of it can be regarded as an online counterpart of the popular L1 -regularization method in the batch setting. We prove small rates of sparsiﬁcation result in only small additional regret with respect to typical online-learning guarantees. Finally, the approach works well empirically. We apply it to several datasets and ﬁnd for datasets with large numbers of features, substantial sparsity is discoverable. 1</p><p>5 0.74185932 <a title="133-lda-5" href="./nips-2008-Cell_Assemblies_in_Large_Sparse_Inhibitory_Networks_of_Biologically_Realistic_Spiking_Neurons.html">43 nips-2008-Cell Assemblies in Large Sparse Inhibitory Networks of Biologically Realistic Spiking Neurons</a></p>
<p>Author: Adam Ponzi, Jeff Wickens</p><p>Abstract: Cell assemblies exhibiting episodes of recurrent coherent activity have been observed in several brain regions including the striatum[1] and hippocampus CA3[2]. Here we address the question of how coherent dynamically switching assemblies appear in large networks of biologically realistic spiking neurons interacting deterministically. We show by numerical simulations of large asymmetric inhibitory networks with ﬁxed external excitatory drive that if the network has intermediate to sparse connectivity, the individual cells are in the vicinity of a bifurcation between a quiescent and ﬁring state and the network inhibition varies slowly on the spiking timescale, then cells form assemblies whose members show strong positive correlation, while members of different assemblies show strong negative correlation. We show that cells and assemblies switch between ﬁring and quiescent states with time durations consistent with a power-law. Our results are in good qualitative agreement with the experimental studies. The deterministic dynamical behaviour is related to winner-less competition[3], shown in small closed loop inhibitory networks with heteroclinic cycles connecting saddle-points. 1</p><p>6 0.73959452 <a title="133-lda-6" href="./nips-2008-Estimating_the_Location_and_Orientation_of_Complex%2C_Correlated_Neural_Activity_using_MEG.html">74 nips-2008-Estimating the Location and Orientation of Complex, Correlated Neural Activity using MEG</a></p>
<p>7 0.73867613 <a title="133-lda-7" href="./nips-2008-Performance_analysis_for_L%5C_2_kernel_classification.html">178 nips-2008-Performance analysis for L\ 2 kernel classification</a></p>
<p>8 0.73152047 <a title="133-lda-8" href="./nips-2008-Risk_Bounds_for_Randomized_Sample_Compressed_Classifiers.html">199 nips-2008-Risk Bounds for Randomized Sample Compressed Classifiers</a></p>
<p>9 0.72361523 <a title="133-lda-9" href="./nips-2008-A_rational_model_of_preference_learning_and_choice_prediction_by_children.html">10 nips-2008-A rational model of preference learning and choice prediction by children</a></p>
<p>10 0.71673691 <a title="133-lda-10" href="./nips-2008-Domain_Adaptation_with_Multiple_Sources.html">65 nips-2008-Domain Adaptation with Multiple Sources</a></p>
<p>11 0.71408081 <a title="133-lda-11" href="./nips-2008-Estimating_vector_fields_using_sparse_basis_field_expansions.html">75 nips-2008-Estimating vector fields using sparse basis field expansions</a></p>
<p>12 0.71284252 <a title="133-lda-12" href="./nips-2008-Regularized_Policy_Iteration.html">195 nips-2008-Regularized Policy Iteration</a></p>
<p>13 0.71222979 <a title="133-lda-13" href="./nips-2008-Robust_Regression_and_Lasso.html">202 nips-2008-Robust Regression and Lasso</a></p>
<p>14 0.7088902 <a title="133-lda-14" href="./nips-2008-Fast_Rates_for_Regularized_Objectives.html">85 nips-2008-Fast Rates for Regularized Objectives</a></p>
<p>15 0.69769198 <a title="133-lda-15" href="./nips-2008-Differentiable_Sparse_Coding.html">62 nips-2008-Differentiable Sparse Coding</a></p>
<p>16 0.69723541 <a title="133-lda-16" href="./nips-2008-From_Online_to_Batch_Learning_with_Cutoff-Averaging.html">88 nips-2008-From Online to Batch Learning with Cutoff-Averaging</a></p>
<p>17 0.69147176 <a title="133-lda-17" href="./nips-2008-On_the_Design_of_Loss_Functions_for_Classification%3A_theory%2C_robustness_to_outliers%2C_and_SavageBoost.html">162 nips-2008-On the Design of Loss Functions for Classification: theory, robustness to outliers, and SavageBoost</a></p>
<p>18 0.68946064 <a title="133-lda-18" href="./nips-2008-Support_Vector_Machines_with_a_Reject_Option.html">228 nips-2008-Support Vector Machines with a Reject Option</a></p>
<p>19 0.6803807 <a title="133-lda-19" href="./nips-2008-Posterior_Consistency_of_the_Silverman_g-prior_in_Bayesian_Model_Choice.html">182 nips-2008-Posterior Consistency of the Silverman g-prior in Bayesian Model Choice</a></p>
<p>20 0.67905146 <a title="133-lda-20" href="./nips-2008-Generative_and_Discriminative_Learning_with_Unknown_Labeling_Bias.html">91 nips-2008-Generative and Discriminative Learning with Unknown Labeling Bias</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
