<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>36 nips-2008-Beyond Novelty Detection: Incongruent Events, when General and Specific Classifiers Disagree</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-36" href="#">nips2008-36</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>36 nips-2008-Beyond Novelty Detection: Incongruent Events, when General and Specific Classifiers Disagree</h1>
<br/><p>Source: <a title="nips-2008-36-pdf" href="http://papers.nips.cc/paper/3581-beyond-novelty-detection-incongruent-events-when-general-and-specific-classifiers-disagree.pdf">pdf</a></p><p>Author: Daphna Weinshall, Hynek Hermansky, Alon Zweig, Jie Luo, Holly Jimison, Frank Ohl, Misha Pavel</p><p>Abstract: Unexpected stimuli are a challenge to any machine learning algorithm. Here we identify distinct types of unexpected events, focusing on ’incongruent events’ when ’general level’ and ’speciﬁc level’ classiﬁers give conﬂicting predictions. We deﬁne a formal framework for the representation and processing of incongruent events: starting from the notion of label hierarchy, we show how partial order on labels can be deduced from such hierarchies. For each event, we compute its probability in different ways, based on adjacent levels (according to the partial order) in the label hierarchy. An incongruent event is an event where the probability computed based on some more speciﬁc level (in accordance with the partial order) is much smaller than the probability computed based on some more general level, leading to conﬂicting predictions. We derive algorithms to detect incongruent events from different types of hierarchies, corresponding to class membership or part membership. Respectively, we show promising results with real data on two speciﬁc problems: Out Of Vocabulary words in speech recognition, and the identiﬁcation of a new sub-class (e.g., the face of a new individual) in audio-visual facial object recognition.</p><p>Reference: <a title="nips-2008-36-reference" href="../nips2008_reference/nips-2008-Beyond_Novelty_Detection%3A_Incongruent_Events%2C_when_General_and_Specific_Classifiers_Disagree_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Here we identify distinct types of unexpected events, focusing on ’incongruent events’ when ’general level’ and ’speciﬁc level’ classiﬁers give conﬂicting predictions. [sent-2, score-0.173]
</p><p>2 We deﬁne a formal framework for the representation and processing of incongruent events: starting from the notion of label hierarchy, we show how partial order on labels can be deduced from such hierarchies. [sent-3, score-0.431]
</p><p>3 For each event, we compute its probability in different ways, based on adjacent levels (according to the partial order) in the label hierarchy. [sent-4, score-0.164]
</p><p>4 An incongruent event is an event where the probability computed based on some more speciﬁc level (in accordance with the partial order) is much smaller than the probability computed based on some more general level, leading to conﬂicting predictions. [sent-5, score-0.823]
</p><p>5 We derive algorithms to detect incongruent events from different types of hierarchies, corresponding to class membership or part membership. [sent-6, score-0.76]
</p><p>6 Respectively, we show promising results with real data on two speciﬁc problems: Out Of Vocabulary words in speech recognition, and the identiﬁcation of a new sub-class (e. [sent-7, score-0.148]
</p><p>7 , the face of a new individual) in audio-visual facial object recognition. [sent-9, score-0.135]
</p><p>8 By deﬁnition, an unexpected event is one whose probability to confront the system is low, based on the data that has been observed previously. [sent-15, score-0.269]
</p><p>9 In line with this observation, much of the computational work on novelty detection focused on the probabilistic modeling of known classes, identifying outliers of these distributions as novel events (see e. [sent-16, score-0.518]
</p><p>10 More recently, oneclass classiﬁers have been proposed and used for novelty detection without the direct modeling of data distribution [3, 4]. [sent-19, score-0.301]
</p><p>11 There are many studies on novelty detection in biological systems [5], often focusing on regions of the hippocampus [6]. [sent-20, score-0.301]
</p><p>12 To advance beyond the detection of outliers, we observe that there are many different reasons why some stimuli could appear novel. [sent-21, score-0.152]
</p><p>13 Our work, presented in Section 2, focuses on unexpected events which are indicated by the incongruence between prediction induced by prior experience (training) and the evidence provided by the sensory data. [sent-22, score-0.344]
</p><p>14 A sufﬁciently large discrepancy between posterior probabilities induced by input data in the two classiﬁers is taken as indication that an item is incongruent. [sent-26, score-0.104]
</p><p>15 Thus, in comparison with most existing work on novelty detection, one new and important characteristic of our approach is that we look for a level of description where the novel event is highly probable. [sent-27, score-0.362]
</p><p>16 Rather than simply respond to an event which is rejected by all classiﬁers, which more often than not requires no special attention (as in pure noise), we construct and exploit a hierarchy of 1  representations. [sent-28, score-0.303]
</p><p>17 We attend to those events which are recognized (or accepted) at some more abstract levels of description in the hierarchy, while being rejected by the more concrete classiﬁers. [sent-29, score-0.309]
</p><p>18 One approach, used to detect images of unexpected incongruous objects, is to train the more general, less constrained classiﬁer using a larger more diverse set of stimuli, e. [sent-31, score-0.273]
</p><p>19 A different approach is used to identify unexpected (out-of-vocabulary) lexical items. [sent-42, score-0.173]
</p><p>20 A word that did not belong to the expected vocabulary of the more constrained recognizer could then be identiﬁed by discrepancy in posterior probabilities of phonemes derived from both classiﬁers. [sent-44, score-0.315]
</p><p>21 Speciﬁcally, we consider two kinds of hierarchies: Part membership as in biological taxonomy or speech, and Class membership, as in human categorization (or levels of categorization). [sent-46, score-0.164]
</p><p>22 We deﬁne a notion of partial order on such hierarchies, and identify those events whose probability as computed using different levels of the hierarchy does not agree. [sent-47, score-0.628]
</p><p>23 Such events correspond to many interesting situations that are worthy of special attention, including incongruous scenes and new sub-classes, as shown in Section 3. [sent-49, score-0.277]
</p><p>24 1 Introducing label hierarchy The set of labels represents the knowledge base about stimuli, which is either given (by a teacher in supervised learning settings) or learned (in unsupervised or semi-supervised settings). [sent-51, score-0.201]
</p><p>25 For example, eyes, ears, and nose combine to form a head; head, legs and tail combine to form a dog. [sent-58, score-0.191]
</p><p>26 Class membership, as in human categorization – where objects can be classiﬁed at different levels of generality, from sub-ordinate categories (most speciﬁc level), to basic level (intermediate level), to super-ordinate categories (most general level). [sent-59, score-0.179]
</p><p>27 For example, a Beagle (sub-ordinate category) is also a dog (basic level category), and it is also an animal (super-ordinate category). [sent-60, score-0.566]
</p><p>28 In the class-membership hierarchy, a parent class admits higher number of combinations of features than any of its children, i. [sent-62, score-0.127]
</p><p>29 , the parent category is less constrained than its children classes. [sent-64, score-0.228]
</p><p>30 In contrast, a parent node in the part-membership hierarchy imposes stricter constraints on the observed features than a child node. [sent-65, score-0.328]
</p><p>31 Roughly speaking, in the class-membership hierarchy (right panel), the parent node is the disjunction of the child categories. [sent-68, score-0.388]
</p><p>32 In the part-membership hierarchy (left panel), the parent category represents a conjunction of the children categories. [sent-69, score-0.424]
</p><p>33 Left: part-membership hierarchy, the concept of a dog requires a conjunction of parts a head, legs and tail. [sent-72, score-0.864]
</p><p>34 Right: class-membership hierarchy, the concept of a dog is deﬁned as the disjunction of more speciﬁc concepts - Afghan, Beagle and Collie. [sent-73, score-0.774]
</p><p>35 Intuitively speaking, different levels in each hierarchy are related by a partial order: the more speciﬁc concept, which corresponds to a smaller set of events or objects in the world, is always smaller than the more general concept, which corresponds to a larger set of events or objects. [sent-75, score-0.804]
</p><p>36 For the part-membership hierarchy example (left panel), the concept of ’dog’ requires a conjunction of parts as in DOG = LEGS ∩ HEAD ∩ TAIL, and therefore, for example, DOG ⊂ LEGS ⇒ DOG LEGS . [sent-78, score-0.445]
</p><p>37 Thus DOG  LEGS , DOG  HEAD, DOG  TAIL  In contrast, for the class-membership hierarchy (right panel), the class of dogs requires the conjunction of the individual members as in DOG = AFGHAN ∪ BEAGEL ∪ COLLIE , and therefore, for example, DOG ⊃ AFGHAN ⇒ DOG AFGHAN . [sent-79, score-0.363]
</p><p>38 Each node in G is a random variable which corresponds to a class or concept (or event). [sent-82, score-0.213]
</p><p>39 Each directed link in E corresponds to partial order relationship as deﬁned above, where there is a link from node a to node b iff a b. [sent-83, score-0.146]
</p><p>40 • If |As | > 1 Qs (X): a probabilistic model of class a which is based on the probability of concepts in a As , assuming their independence of each other. [sent-86, score-0.172]
</p><p>41 Typically, the model incorporates some relatively simple conjunctive and/or disjunctive relations among concepts in A s . [sent-87, score-0.166]
</p><p>42 • If |Ag | > 1 Qg (X): a probabilistic model of class a which is based on the probability of concepts in a Ag , assuming their independence of each other. [sent-88, score-0.172]
</p><p>43 Here too, the model typically incorporates some relatively simple conjunctive and/or disjunctive relations among concepts in A g . [sent-89, score-0.166]
</p><p>44 1, where our concept of interest a is the concept ‘dog’: In the part-membership hierarchy (left panel), |Ag | = 3 (head, legs, tail). [sent-91, score-0.463]
</p><p>45 We can therefore learn 2 models for the class ‘dog’ (Qs is not deﬁned): dog 1. [sent-92, score-0.533]
</p><p>46 Qg - obtained using the outcome of models for head, legs and tail, which were trained on dog the same training set T with body part labels. [sent-95, score-0.656]
</p><p>47 If we further assume that a class-membership hierarchy is always a tree, then |A g | = 1. [sent-97, score-0.201]
</p><p>48 We can therefore learn 2 models for the class ‘dog’ (Qg is not deﬁned): dog 1. [sent-98, score-0.533]
</p><p>49 Qs - obtained using the outcome of models for Afghan, Beagle and Collie, which were dog trained on the same training set T with only speciﬁc dog type labels. [sent-101, score-1.02]
</p><p>50 In particular, we are interested in the following discrepancy: Deﬁnition: Observation X is incongruent if there exists a concept a such that Qg (X) a  Qa (X) or Qa (X)  Qs (X). [sent-104, score-0.498]
</p><p>51 In either case, the concept receives high probability at the more general level (according to the GP O), but much lower probability when relying only on the more speciﬁc level. [sent-106, score-0.285]
</p><p>52 Let us discuss again the examples we have seen before, to illustrate why this deﬁnition indeed captures interesting “surprises”: • In the part-membership hierarchy (left panel of Fig. [sent-107, score-0.272]
</p><p>53 1), we have Qg = QHead · QLegs · QTail dog  Qdog  In other words, while the probability of each part is high (since the multiplication of those probabilities is high), the ’dog’ classiﬁer is rather uncertain about the existence of a dog in this data. [sent-108, score-1.024]
</p><p>54 Maybe the parts are conﬁgured in an unusual arrangement for a dog (as in a 3-legged cat), or maybe we encounter a donkey with a cat’s tail (as in Shrek 3). [sent-110, score-0.66]
</p><p>55 Those are two examples of the kind of unexpected events we are interested in. [sent-111, score-0.344]
</p><p>56 4  • In the class-membership hierarchy (right panel of Fig. [sent-112, score-0.272]
</p><p>57 1), we have Qs = QAf ghan + QBeagle + QCollie dog  Qdog  In other words, while the probability of each sub-class is low (since the sum of these probabilities is low), the ’dog’ classiﬁer is certain about the existence of a dog in this data. [sent-113, score-1.064]
</p><p>58 Maybe we are seeing a new type of dog that we haven’t seen before - a Pointer. [sent-115, score-0.492]
</p><p>59 The dog model, if correctly capturing the notion of ’dogness’, should be able to identify this new object, while models of previously seen dog breeds (Afghan, Beagle and Collie) correctly fail to recognize the new object. [sent-116, score-1.03]
</p><p>60 3 Incongruent events: algorithms Our deﬁnition for incongruent events in the previous section is indeed uniﬁed, but as a result quite abstract. [sent-117, score-0.584]
</p><p>61 In this section we discuss two different algorithmic implementations, one generative and one discriminative, which were developed for the part membership and class membership hierarchies respectively (see deﬁnition in Section 1). [sent-118, score-0.374]
</p><p>62 1 Part membership - a generative algorithm Consider the left panel of Fig. [sent-121, score-0.223]
</p><p>63 The event in the top node is incongruent if its probability is low, while the probability of all its descendants is high. [sent-123, score-0.59]
</p><p>64 In many applications, such as speech recognition, one computes the probability of events (sentences) based on a generative model (corresponding to a speciﬁc language) which includes a dictionary of parts (words). [sent-124, score-0.468]
</p><p>65 At the top level the event probability is computed conditional on the model; in which case typically the parts are assumed to be independent, and the event probability is computed as the multiplication of the parts probabilities conditioned on the model. [sent-125, score-0.484]
</p><p>66 For example, in speech processing and assuming a speciﬁc language (e. [sent-126, score-0.155]
</p><p>67 , English), the probability of the sentence is typically computed by multiplying the probability of each word using an HMM model trained on sentences from a speciﬁc language. [sent-128, score-0.186]
</p><p>68 More formally, Consider an event u composed of parts wk . [sent-130, score-0.257]
</p><p>69 Using the generative model of events and assuming the conditional independence of the parts given this model, the prior probability of the event is given by the product of prior probabilities of the parts, p(u|L) =  p(wk |L)  (3)  k  where L denotes the generative model (e. [sent-131, score-0.518]
</p><p>70 At the risk of notation abuse, {wk } now denote the parts which compose the most likely event u. [sent-135, score-0.165]
</p><p>71 In speech processing, a sentence is incongruent if it includes an incongruent word - a word whose probability based on the generative language model is low, but whose direct probability (not constrained by the language model) is high. [sent-139, score-1.232]
</p><p>72 Example: Out Of Vocabulary (OOV) words For the detection of OOV words, we performed experiments using a Large Vocabulary Continuous Speech Recognition (LVCSR) system on the Wall Street Journal Corpus (WSJ). [sent-140, score-0.163]
</p><p>73 To introduce OOV words, the vocabulary was restricted to the 4968 most frequent words from the language training texts, leaving the remaining words unknown to the model. [sent-143, score-0.224]
</p><p>74 In this task, we have shown that the comparison between two parallel classiﬁers, based on strong and weak posterior streams, is effective for the detection of OOV words, and also for the detection of recognition errors. [sent-145, score-0.262]
</p><p>75 Speciﬁcally, we use the derivation above to detect out of vocabulary words, by comparing their probability when computed based on the language model, and when computed based on mere acoustic modeling. [sent-146, score-0.199]
</p><p>76 2 Class membership - a discriminative algorithm Consider the right panel of Fig. [sent-156, score-0.227]
</p><p>77 The general class in the top node is incongruent if its probability is high, while the probability of all its sub-classes is low. [sent-158, score-0.529]
</p><p>78 In other words, the classiﬁer of the parent object accepts the new observation, but all the children object classiﬁers reject it. [sent-159, score-0.32]
</p><p>79 Brute force computation of this deﬁnition may follow the path taken by traditional approaches to novelty detection, e. [sent-160, score-0.186]
</p><p>80 Instead, it seems like discriminative classiﬁers, trained to discriminate 6  between objects at the sub-class level, could be more successful. [sent-164, score-0.133]
</p><p>81 We note that unlike traditional approaches to novelty detection, which must use generative models or one-class classiﬁers in the absence of appropriate discriminative data, our dependence on object hierarchy provides discriminative data as a by-product. [sent-165, score-0.583]
</p><p>82 In other words, after the recognition by a parent-node classiﬁer, we may use classiﬁers trained to discriminate between its children to implement a discriminative novelty detection algorithm. [sent-166, score-0.463]
</p><p>83 Speciﬁcally, we used the approach described in [8] to build a uniﬁed representation for all objects in the sub-class level, which is the representation computed for the parent object whose classiﬁer had accepted (positively recognized) the object. [sent-167, score-0.206]
</p><p>84 In this setup, the general parent category level is the ‘speech’ (audio) and ‘face’ (visual), and the different individuals are the offspring (sub-class) levels. [sent-175, score-0.249]
</p><p>85 The task is to identify an individual as belonging to the trusted group of individuals vs. [sent-176, score-0.138]
</p><p>86 All objects in the sub-class level (different individuals) were represented using the representation learnt for the parent level (’face’). [sent-182, score-0.279]
</p><p>87 For this fusion the audio signal and visual signal were synchronized, and the winning classiﬁcation margins of both signals were normalized to the same scale and averaged to obtain a single margin for the combined method. [sent-190, score-0.106]
</p><p>88 Since the goal is to identify novel incongruent events, true positive and false positive rates were calculated by considering all frames from the unknown test sequences as positive events and the known individual test sequences as negative events. [sent-191, score-0.63]
</p><p>89 We compared our method to novelty detection based on one-class SVM [3] extended to our multi-class case. [sent-192, score-0.301]
</p><p>90 3, our method performs substantially better in both modalities as compared to the “standard” one class approach for novelty detection. [sent-195, score-0.269]
</p><p>91 4 Summary Unexpected events are typically identiﬁed by their low posterior probability. [sent-197, score-0.217]
</p><p>92 In this paper we employed label hierarchy to obtain a few probability values for each event, which allowed us to tease apart different types of unexpected events. [sent-198, score-0.368]
</p><p>93 3  audio visual audio−visual audio (OC−SVM) visual (OC−SVM)  0. [sent-206, score-0.212]
</p><p>94 For comparison, we show results with a more traditional novelty detection method using One Class SVM (dashed lines). [sent-223, score-0.301]
</p><p>95 We focused above on the second type of events - incongruent concepts, which have not been studied previously in isolation. [sent-224, score-0.584]
</p><p>96 Such events are characterized by some discrepancy between the response of two classiﬁers, which can occur for a number different reasons: Context: in a given context such as the English language, a sentence containing a Czech word is assigned low probability. [sent-225, score-0.359]
</p><p>97 In the visual domain, in a given context such as a street scene, otherwise high probability events such as “car” and “elephant” are not likely to appear together. [sent-226, score-0.297]
</p><p>98 We described how our approach can be used to design new algorithms to address these problems, showing promising results on real speech and audio-visual facial datasets. [sent-228, score-0.15]
</p><p>99 : Brain regions responsive to novelty in the absence of awareness. [sent-263, score-0.186]
</p><p>100 : Combination of strongly and weakly constrained recognizers for reliable detection of oovs. [sent-282, score-0.202]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('dog', 0.492), ('incongruent', 0.367), ('events', 0.217), ('hierarchy', 0.201), ('novelty', 0.186), ('afghan', 0.16), ('concept', 0.131), ('legs', 0.128), ('qg', 0.128), ('unexpected', 0.127), ('ers', 0.124), ('oov', 0.12), ('classi', 0.119), ('detection', 0.115), ('membership', 0.104), ('event', 0.102), ('beagle', 0.1), ('collie', 0.1), ('speech', 0.1), ('er', 0.092), ('wk', 0.092), ('concepts', 0.091), ('parent', 0.086), ('qs', 0.081), ('lvcsr', 0.08), ('qdog', 0.08), ('hierarchies', 0.077), ('level', 0.074), ('vocabulary', 0.073), ('discrepancy', 0.072), ('panel', 0.071), ('dogs', 0.071), ('head', 0.068), ('ag', 0.067), ('audio', 0.066), ('partial', 0.064), ('tail', 0.063), ('parts', 0.063), ('reject', 0.062), ('disjunction', 0.06), ('incongruous', 0.06), ('phoneme', 0.06), ('levels', 0.06), ('constrained', 0.055), ('language', 0.055), ('discriminative', 0.052), ('facial', 0.05), ('conjunction', 0.05), ('words', 0.048), ('generative', 0.048), ('qa', 0.048), ('trusted', 0.048), ('identify', 0.046), ('uni', 0.046), ('category', 0.045), ('objects', 0.045), ('object', 0.044), ('individuals', 0.044), ('accept', 0.043), ('accepts', 0.042), ('maybe', 0.042), ('modalities', 0.042), ('children', 0.042), ('class', 0.041), ('node', 0.041), ('face', 0.041), ('probability', 0.04), ('beagel', 0.04), ('breed', 0.04), ('conjunctive', 0.04), ('ghan', 0.04), ('hermansky', 0.04), ('markou', 0.04), ('oc', 0.04), ('phonemes', 0.04), ('qaf', 0.04), ('qb', 0.04), ('qbeagle', 0.04), ('qcollie', 0.04), ('qhead', 0.04), ('qlegs', 0.04), ('qtail', 0.04), ('recognizer', 0.04), ('wsj', 0.04), ('visual', 0.04), ('stimuli', 0.037), ('trained', 0.036), ('disjunctive', 0.035), ('plp', 0.035), ('sentence', 0.035), ('nn', 0.035), ('word', 0.035), ('accordance', 0.034), ('item', 0.032), ('recognizers', 0.032), ('recognized', 0.032), ('recognition', 0.032), ('accepted', 0.031), ('posteriors', 0.031), ('detect', 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="36-tfidf-1" href="./nips-2008-Beyond_Novelty_Detection%3A_Incongruent_Events%2C_when_General_and_Specific_Classifiers_Disagree.html">36 nips-2008-Beyond Novelty Detection: Incongruent Events, when General and Specific Classifiers Disagree</a></p>
<p>Author: Daphna Weinshall, Hynek Hermansky, Alon Zweig, Jie Luo, Holly Jimison, Frank Ohl, Misha Pavel</p><p>Abstract: Unexpected stimuli are a challenge to any machine learning algorithm. Here we identify distinct types of unexpected events, focusing on ’incongruent events’ when ’general level’ and ’speciﬁc level’ classiﬁers give conﬂicting predictions. We deﬁne a formal framework for the representation and processing of incongruent events: starting from the notion of label hierarchy, we show how partial order on labels can be deduced from such hierarchies. For each event, we compute its probability in different ways, based on adjacent levels (according to the partial order) in the label hierarchy. An incongruent event is an event where the probability computed based on some more speciﬁc level (in accordance with the partial order) is much smaller than the probability computed based on some more general level, leading to conﬂicting predictions. We derive algorithms to detect incongruent events from different types of hierarchies, corresponding to class membership or part membership. Respectively, we show promising results with real data on two speciﬁc problems: Out Of Vocabulary words in speech recognition, and the identiﬁcation of a new sub-class (e.g., the face of a new individual) in audio-visual facial object recognition.</p><p>2 0.12763135 <a title="36-tfidf-2" href="./nips-2008-MCBoost%3A_Multiple_Classifier_Boosting_for_Perceptual_Co-clustering_of_Images_and_Visual_Features.html">130 nips-2008-MCBoost: Multiple Classifier Boosting for Perceptual Co-clustering of Images and Visual Features</a></p>
<p>Author: Tae-kyun Kim, Roberto Cipolla</p><p>Abstract: We present a new co-clustering problem of images and visual features. The problem involves a set of non-object images in addition to a set of object images and features to be co-clustered. Co-clustering is performed in a way that maximises discrimination of object images from non-object images, thus emphasizing discriminative features. This provides a way of obtaining perceptual joint-clusters of object images and features. We tackle the problem by simultaneously boosting multiple strong classiﬁers which compete for images by their expertise. Each boosting classiﬁer is an aggregation of weak-learners, i.e. simple visual features. The obtained classiﬁers are useful for object detection tasks which exhibit multimodalities, e.g. multi-category and multi-view object detection tasks. Experiments on a set of pedestrian images and a face data set demonstrate that the method yields intuitive image clusters with associated features and is much superior to conventional boosting classiﬁers in object detection tasks. 1</p><p>3 0.11990166 <a title="36-tfidf-3" href="./nips-2008-Recursive_Segmentation_and_Recognition_Templates_for_2D_Parsing.html">191 nips-2008-Recursive Segmentation and Recognition Templates for 2D Parsing</a></p>
<p>Author: Leo Zhu, Yuanhao Chen, Yuan Lin, Chenxi Lin, Alan L. Yuille</p><p>Abstract: Language and image understanding are two major goals of artiﬁcial intelligence which can both be conceptually formulated in terms of parsing the input signal into a hierarchical representation. Natural language researchers have made great progress by exploiting the 1D structure of language to design efﬁcient polynomialtime parsing algorithms. By contrast, the two-dimensional nature of images makes it much harder to design efﬁcient image parsers and the form of the hierarchical representations is also unclear. Attempts to adapt representations and algorithms from natural language have only been partially successful. In this paper, we propose a Hierarchical Image Model (HIM) for 2D image parsing which outputs image segmentation and object recognition. This HIM is represented by recursive segmentation and recognition templates in multiple layers and has advantages for representation, inference, and learning. Firstly, the HIM has a coarse-to-ﬁne representation which is capable of capturing long-range dependency and exploiting different levels of contextual information. Secondly, the structure of the HIM allows us to design a rapid inference algorithm, based on dynamic programming, which enables us to parse the image rapidly in polynomial time. Thirdly, we can learn the HIM efﬁciently in a discriminative manner from a labeled dataset. We demonstrate that HIM outperforms other state-of-the-art methods by evaluation on the challenging public MSRC image dataset. Finally, we sketch how the HIM architecture can be extended to model more complex image phenomena. 1</p><p>4 0.11487374 <a title="36-tfidf-4" href="./nips-2008-Interpreting_the_neural_code_with_Formal_Concept_Analysis.html">109 nips-2008-Interpreting the neural code with Formal Concept Analysis</a></p>
<p>Author: Dominik Endres, Peter Foldiak</p><p>Abstract: We propose a novel application of Formal Concept Analysis (FCA) to neural decoding: instead of just trying to ﬁgure out which stimulus was presented, we demonstrate how to explore the semantic relationships in the neural representation of large sets of stimuli. FCA provides a way of displaying and interpreting such relationships via concept lattices. We explore the effects of neural code sparsity on the lattice. We then analyze neurophysiological data from high-level visual cortical area STSa, using an exact Bayesian approach to construct the formal context needed by FCA. Prominent features of the resulting concept lattices are discussed, including hierarchical face representation and indications for a product-of-experts code in real neurons. 1</p><p>5 0.102582 <a title="36-tfidf-5" href="./nips-2008-Cascaded_Classification_Models%3A_Combining_Models_for_Holistic_Scene_Understanding.html">42 nips-2008-Cascaded Classification Models: Combining Models for Holistic Scene Understanding</a></p>
<p>Author: Geremy Heitz, Stephen Gould, Ashutosh Saxena, Daphne Koller</p><p>Abstract: One of the original goals of computer vision was to fully understand a natural scene. This requires solving several sub-problems simultaneously, including object detection, region labeling, and geometric reasoning. The last few decades have seen great progress in tackling each of these problems in isolation. Only recently have researchers returned to the difﬁcult task of considering them jointly. In this work, we consider learning a set of related models in such that they both solve their own problem and help each other. We develop a framework called Cascaded Classiﬁcation Models (CCM), where repeated instantiations of these classiﬁers are coupled by their input/output variables in a cascade that improves performance at each level. Our method requires only a limited “black box” interface with the models, allowing us to use very sophisticated, state-of-the-art classiﬁers without having to look under the hood. We demonstrate the effectiveness of our method on a large set of natural images by combining the subtasks of scene categorization, object detection, multiclass image segmentation, and 3d reconstruction. 1</p><p>6 0.081258066 <a title="36-tfidf-6" href="./nips-2008-Fast_Computation_of_Posterior_Mode_in_Multi-Level_Hierarchical_Models.html">82 nips-2008-Fast Computation of Posterior Mode in Multi-Level Hierarchical Models</a></p>
<p>7 0.081224576 <a title="36-tfidf-7" href="./nips-2008-A_Scalable_Hierarchical_Distributed_Language_Model.html">4 nips-2008-A Scalable Hierarchical Distributed Language Model</a></p>
<p>8 0.075693205 <a title="36-tfidf-8" href="./nips-2008-Mixed_Membership_Stochastic_Blockmodels.html">134 nips-2008-Mixed Membership Stochastic Blockmodels</a></p>
<p>9 0.074396394 <a title="36-tfidf-9" href="./nips-2008-Multi-Level_Active_Prediction_of_Useful_Image_Annotations_for_Recognition.html">142 nips-2008-Multi-Level Active Prediction of Useful Image Annotations for Recognition</a></p>
<p>10 0.071712814 <a title="36-tfidf-10" href="./nips-2008-Analyzing_human_feature_learning_as_nonparametric_Bayesian_inference.html">26 nips-2008-Analyzing human feature learning as nonparametric Bayesian inference</a></p>
<p>11 0.070470929 <a title="36-tfidf-11" href="./nips-2008-Hierarchical_Fisher_Kernels_for_Longitudinal_Data.html">97 nips-2008-Hierarchical Fisher Kernels for Longitudinal Data</a></p>
<p>12 0.067908868 <a title="36-tfidf-12" href="./nips-2008-Shape-Based_Object_Localization_for_Descriptive_Classification.html">207 nips-2008-Shape-Based Object Localization for Descriptive Classification</a></p>
<p>13 0.067753866 <a title="36-tfidf-13" href="./nips-2008-Unsupervised_Learning_of_Visual_Sense_Models_for_Polysemous_Words.html">246 nips-2008-Unsupervised Learning of Visual Sense Models for Polysemous Words</a></p>
<p>14 0.062665254 <a title="36-tfidf-14" href="./nips-2008-Supervised_Dictionary_Learning.html">226 nips-2008-Supervised Dictionary Learning</a></p>
<p>15 0.060815964 <a title="36-tfidf-15" href="./nips-2008-Support_Vector_Machines_with_a_Reject_Option.html">228 nips-2008-Support Vector Machines with a Reject Option</a></p>
<p>16 0.058213819 <a title="36-tfidf-16" href="./nips-2008-Learning_Hybrid_Models_for_Image_Annotation_with_Partially_Labeled_Data.html">116 nips-2008-Learning Hybrid Models for Image Annotation with Partially Labeled Data</a></p>
<p>17 0.058136869 <a title="36-tfidf-17" href="./nips-2008-Risk_Bounds_for_Randomized_Sample_Compressed_Classifiers.html">199 nips-2008-Risk Bounds for Randomized Sample Compressed Classifiers</a></p>
<p>18 0.057382595 <a title="36-tfidf-18" href="./nips-2008-Adaptive_Template_Matching_with_Shift-Invariant_Semi-NMF.html">16 nips-2008-Adaptive Template Matching with Shift-Invariant Semi-NMF</a></p>
<p>19 0.055989619 <a title="36-tfidf-19" href="./nips-2008-Adaptive_Martingale_Boosting.html">15 nips-2008-Adaptive Martingale Boosting</a></p>
<p>20 0.055126715 <a title="36-tfidf-20" href="./nips-2008-Differentiable_Sparse_Coding.html">62 nips-2008-Differentiable Sparse Coding</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2008_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.173), (1, -0.071), (2, 0.092), (3, -0.106), (4, -0.041), (5, -0.005), (6, 0.016), (7, -0.02), (8, 0.045), (9, 0.028), (10, 0.015), (11, 0.074), (12, -0.023), (13, -0.06), (14, -0.027), (15, 0.109), (16, 0.006), (17, -0.143), (18, 0.041), (19, 0.017), (20, 0.038), (21, 0.008), (22, 0.101), (23, 0.005), (24, -0.111), (25, -0.011), (26, -0.052), (27, -0.116), (28, -0.045), (29, -0.04), (30, 0.127), (31, 0.001), (32, 0.024), (33, -0.013), (34, 0.1), (35, -0.065), (36, -0.033), (37, 0.19), (38, -0.004), (39, -0.029), (40, 0.025), (41, -0.003), (42, 0.005), (43, -0.018), (44, -0.011), (45, -0.05), (46, -0.006), (47, 0.042), (48, -0.023), (49, 0.128)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95803726 <a title="36-lsi-1" href="./nips-2008-Beyond_Novelty_Detection%3A_Incongruent_Events%2C_when_General_and_Specific_Classifiers_Disagree.html">36 nips-2008-Beyond Novelty Detection: Incongruent Events, when General and Specific Classifiers Disagree</a></p>
<p>Author: Daphna Weinshall, Hynek Hermansky, Alon Zweig, Jie Luo, Holly Jimison, Frank Ohl, Misha Pavel</p><p>Abstract: Unexpected stimuli are a challenge to any machine learning algorithm. Here we identify distinct types of unexpected events, focusing on ’incongruent events’ when ’general level’ and ’speciﬁc level’ classiﬁers give conﬂicting predictions. We deﬁne a formal framework for the representation and processing of incongruent events: starting from the notion of label hierarchy, we show how partial order on labels can be deduced from such hierarchies. For each event, we compute its probability in different ways, based on adjacent levels (according to the partial order) in the label hierarchy. An incongruent event is an event where the probability computed based on some more speciﬁc level (in accordance with the partial order) is much smaller than the probability computed based on some more general level, leading to conﬂicting predictions. We derive algorithms to detect incongruent events from different types of hierarchies, corresponding to class membership or part membership. Respectively, we show promising results with real data on two speciﬁc problems: Out Of Vocabulary words in speech recognition, and the identiﬁcation of a new sub-class (e.g., the face of a new individual) in audio-visual facial object recognition.</p><p>2 0.68313748 <a title="36-lsi-2" href="./nips-2008-MCBoost%3A_Multiple_Classifier_Boosting_for_Perceptual_Co-clustering_of_Images_and_Visual_Features.html">130 nips-2008-MCBoost: Multiple Classifier Boosting for Perceptual Co-clustering of Images and Visual Features</a></p>
<p>Author: Tae-kyun Kim, Roberto Cipolla</p><p>Abstract: We present a new co-clustering problem of images and visual features. The problem involves a set of non-object images in addition to a set of object images and features to be co-clustered. Co-clustering is performed in a way that maximises discrimination of object images from non-object images, thus emphasizing discriminative features. This provides a way of obtaining perceptual joint-clusters of object images and features. We tackle the problem by simultaneously boosting multiple strong classiﬁers which compete for images by their expertise. Each boosting classiﬁer is an aggregation of weak-learners, i.e. simple visual features. The obtained classiﬁers are useful for object detection tasks which exhibit multimodalities, e.g. multi-category and multi-view object detection tasks. Experiments on a set of pedestrian images and a face data set demonstrate that the method yields intuitive image clusters with associated features and is much superior to conventional boosting classiﬁers in object detection tasks. 1</p><p>3 0.6755814 <a title="36-lsi-3" href="./nips-2008-Cascaded_Classification_Models%3A_Combining_Models_for_Holistic_Scene_Understanding.html">42 nips-2008-Cascaded Classification Models: Combining Models for Holistic Scene Understanding</a></p>
<p>Author: Geremy Heitz, Stephen Gould, Ashutosh Saxena, Daphne Koller</p><p>Abstract: One of the original goals of computer vision was to fully understand a natural scene. This requires solving several sub-problems simultaneously, including object detection, region labeling, and geometric reasoning. The last few decades have seen great progress in tackling each of these problems in isolation. Only recently have researchers returned to the difﬁcult task of considering them jointly. In this work, we consider learning a set of related models in such that they both solve their own problem and help each other. We develop a framework called Cascaded Classiﬁcation Models (CCM), where repeated instantiations of these classiﬁers are coupled by their input/output variables in a cascade that improves performance at each level. Our method requires only a limited “black box” interface with the models, allowing us to use very sophisticated, state-of-the-art classiﬁers without having to look under the hood. We demonstrate the effectiveness of our method on a large set of natural images by combining the subtasks of scene categorization, object detection, multiclass image segmentation, and 3d reconstruction. 1</p><p>4 0.60927629 <a title="36-lsi-4" href="./nips-2008-Recursive_Segmentation_and_Recognition_Templates_for_2D_Parsing.html">191 nips-2008-Recursive Segmentation and Recognition Templates for 2D Parsing</a></p>
<p>Author: Leo Zhu, Yuanhao Chen, Yuan Lin, Chenxi Lin, Alan L. Yuille</p><p>Abstract: Language and image understanding are two major goals of artiﬁcial intelligence which can both be conceptually formulated in terms of parsing the input signal into a hierarchical representation. Natural language researchers have made great progress by exploiting the 1D structure of language to design efﬁcient polynomialtime parsing algorithms. By contrast, the two-dimensional nature of images makes it much harder to design efﬁcient image parsers and the form of the hierarchical representations is also unclear. Attempts to adapt representations and algorithms from natural language have only been partially successful. In this paper, we propose a Hierarchical Image Model (HIM) for 2D image parsing which outputs image segmentation and object recognition. This HIM is represented by recursive segmentation and recognition templates in multiple layers and has advantages for representation, inference, and learning. Firstly, the HIM has a coarse-to-ﬁne representation which is capable of capturing long-range dependency and exploiting different levels of contextual information. Secondly, the structure of the HIM allows us to design a rapid inference algorithm, based on dynamic programming, which enables us to parse the image rapidly in polynomial time. Thirdly, we can learn the HIM efﬁciently in a discriminative manner from a labeled dataset. We demonstrate that HIM outperforms other state-of-the-art methods by evaluation on the challenging public MSRC image dataset. Finally, we sketch how the HIM architecture can be extended to model more complex image phenomena. 1</p><p>5 0.58147156 <a title="36-lsi-5" href="./nips-2008-Interpreting_the_neural_code_with_Formal_Concept_Analysis.html">109 nips-2008-Interpreting the neural code with Formal Concept Analysis</a></p>
<p>Author: Dominik Endres, Peter Foldiak</p><p>Abstract: We propose a novel application of Formal Concept Analysis (FCA) to neural decoding: instead of just trying to ﬁgure out which stimulus was presented, we demonstrate how to explore the semantic relationships in the neural representation of large sets of stimuli. FCA provides a way of displaying and interpreting such relationships via concept lattices. We explore the effects of neural code sparsity on the lattice. We then analyze neurophysiological data from high-level visual cortical area STSa, using an exact Bayesian approach to construct the formal context needed by FCA. Prominent features of the resulting concept lattices are discussed, including hierarchical face representation and indications for a product-of-experts code in real neurons. 1</p><p>6 0.58087707 <a title="36-lsi-6" href="./nips-2008-Adaptive_Martingale_Boosting.html">15 nips-2008-Adaptive Martingale Boosting</a></p>
<p>7 0.53676075 <a title="36-lsi-7" href="./nips-2008-Fast_Computation_of_Posterior_Mode_in_Multi-Level_Hierarchical_Models.html">82 nips-2008-Fast Computation of Posterior Mode in Multi-Level Hierarchical Models</a></p>
<p>8 0.50045186 <a title="36-lsi-8" href="./nips-2008-Unsupervised_Learning_of_Visual_Sense_Models_for_Polysemous_Words.html">246 nips-2008-Unsupervised Learning of Visual Sense Models for Polysemous Words</a></p>
<p>9 0.4773638 <a title="36-lsi-9" href="./nips-2008-A_Scalable_Hierarchical_Distributed_Language_Model.html">4 nips-2008-A Scalable Hierarchical Distributed Language Model</a></p>
<p>10 0.47631705 <a title="36-lsi-10" href="./nips-2008-Artificial_Olfactory_Brain_for_Mixture_Identification.html">27 nips-2008-Artificial Olfactory Brain for Mixture Identification</a></p>
<p>11 0.47162741 <a title="36-lsi-11" href="./nips-2008-Probabilistic_detection_of_short_events%2C_with_application_to_critical_care_monitoring.html">186 nips-2008-Probabilistic detection of short events, with application to critical care monitoring</a></p>
<p>12 0.46088558 <a title="36-lsi-12" href="./nips-2008-Shape-Based_Object_Localization_for_Descriptive_Classification.html">207 nips-2008-Shape-Based Object Localization for Descriptive Classification</a></p>
<p>13 0.45945671 <a title="36-lsi-13" href="./nips-2008-Hierarchical_Semi-Markov_Conditional_Random_Fields_for_Recursive_Sequential_Data.html">98 nips-2008-Hierarchical Semi-Markov Conditional Random Fields for Recursive Sequential Data</a></p>
<p>14 0.44897979 <a title="36-lsi-14" href="./nips-2008-Multi-Level_Active_Prediction_of_Useful_Image_Annotations_for_Recognition.html">142 nips-2008-Multi-Level Active Prediction of Useful Image Annotations for Recognition</a></p>
<p>15 0.43492076 <a title="36-lsi-15" href="./nips-2008-Breaking_Audio_CAPTCHAs.html">41 nips-2008-Breaking Audio CAPTCHAs</a></p>
<p>16 0.42438602 <a title="36-lsi-16" href="./nips-2008-On_the_Design_of_Loss_Functions_for_Classification%3A_theory%2C_robustness_to_outliers%2C_and_SavageBoost.html">162 nips-2008-On the Design of Loss Functions for Classification: theory, robustness to outliers, and SavageBoost</a></p>
<p>17 0.41415954 <a title="36-lsi-17" href="./nips-2008-Effects_of_Stimulus_Type_and_of_Error-Correcting_Code_Design_on_BCI_Speller_Performance.html">67 nips-2008-Effects of Stimulus Type and of Error-Correcting Code Design on BCI Speller Performance</a></p>
<p>18 0.39564818 <a title="36-lsi-18" href="./nips-2008-A_Transductive_Bound_for_the_Voted_Classifier_with_an_Application_to_Semi-supervised_Learning.html">5 nips-2008-A Transductive Bound for the Voted Classifier with an Application to Semi-supervised Learning</a></p>
<p>19 0.39499483 <a title="36-lsi-19" href="./nips-2008-Support_Vector_Machines_with_a_Reject_Option.html">228 nips-2008-Support Vector Machines with a Reject Option</a></p>
<p>20 0.39457384 <a title="36-lsi-20" href="./nips-2008-Analyzing_human_feature_learning_as_nonparametric_Bayesian_inference.html">26 nips-2008-Analyzing human feature learning as nonparametric Bayesian inference</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2008_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(6, 0.055), (7, 0.079), (12, 0.052), (16, 0.318), (28, 0.133), (57, 0.085), (59, 0.022), (63, 0.019), (71, 0.015), (77, 0.036), (78, 0.04), (83, 0.064)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.75695789 <a title="36-lda-1" href="./nips-2008-Beyond_Novelty_Detection%3A_Incongruent_Events%2C_when_General_and_Specific_Classifiers_Disagree.html">36 nips-2008-Beyond Novelty Detection: Incongruent Events, when General and Specific Classifiers Disagree</a></p>
<p>Author: Daphna Weinshall, Hynek Hermansky, Alon Zweig, Jie Luo, Holly Jimison, Frank Ohl, Misha Pavel</p><p>Abstract: Unexpected stimuli are a challenge to any machine learning algorithm. Here we identify distinct types of unexpected events, focusing on ’incongruent events’ when ’general level’ and ’speciﬁc level’ classiﬁers give conﬂicting predictions. We deﬁne a formal framework for the representation and processing of incongruent events: starting from the notion of label hierarchy, we show how partial order on labels can be deduced from such hierarchies. For each event, we compute its probability in different ways, based on adjacent levels (according to the partial order) in the label hierarchy. An incongruent event is an event where the probability computed based on some more speciﬁc level (in accordance with the partial order) is much smaller than the probability computed based on some more general level, leading to conﬂicting predictions. We derive algorithms to detect incongruent events from different types of hierarchies, corresponding to class membership or part membership. Respectively, we show promising results with real data on two speciﬁc problems: Out Of Vocabulary words in speech recognition, and the identiﬁcation of a new sub-class (e.g., the face of a new individual) in audio-visual facial object recognition.</p><p>2 0.676853 <a title="36-lda-2" href="./nips-2008-Multi-stage_Convex_Relaxation_for_Learning_with_Sparse_Regularization.html">145 nips-2008-Multi-stage Convex Relaxation for Learning with Sparse Regularization</a></p>
<p>Author: Tong Zhang</p><p>Abstract: We study learning formulations with non-convex regularizaton that are natural for sparse linear models. There are two approaches to this problem: • Heuristic methods such as gradient descent that only ﬁnd a local minimum. A drawback of this approach is the lack of theoretical guarantee showing that the local minimum gives a good solution. • Convex relaxation such as L1 -regularization that solves the problem under some conditions. However it often leads to sub-optimal sparsity in reality. This paper tries to remedy the above gap between theory and practice. In particular, we investigate a multi-stage convex relaxation scheme for solving problems with non-convex regularization. Theoretically, we analyze the behavior of a resulting two-stage relaxation scheme for the capped-L1 regularization. Our performance bound shows that the procedure is superior to the standard L1 convex relaxation for learning sparse targets. Experiments conﬁrm the effectiveness of this method on some simulation and real data. 1</p><p>3 0.66582233 <a title="36-lda-3" href="./nips-2008-Optimization_on_a_Budget%3A_A_Reinforcement_Learning_Approach.html">173 nips-2008-Optimization on a Budget: A Reinforcement Learning Approach</a></p>
<p>Author: Paul L. Ruvolo, Ian Fasel, Javier R. Movellan</p><p>Abstract: Many popular optimization algorithms, like the Levenberg-Marquardt algorithm (LMA), use heuristic-based “controllers” that modulate the behavior of the optimizer during the optimization process. For example, in the LMA a damping parameter λ is dynamically modiﬁed based on a set of rules that were developed using heuristic arguments. Reinforcement learning (RL) is a machine learning approach to learn optimal controllers from examples and thus is an obvious candidate to improve the heuristic-based controllers implicit in the most popular and heavily used optimization algorithms. Improving the performance of off-the-shelf optimizers is particularly important for time-constrained optimization problems. For example the LMA algorithm has become popular for many real-time computer vision problems, including object tracking from video, where only a small amount of time can be allocated to the optimizer on each incoming video frame. Here we show that a popular modern reinforcement learning technique using a very simple state space can dramatically improve the performance of general purpose optimizers, like the LMA. Surprisingly the controllers learned for a particular domain also work well in very different optimization domains. For example we used RL methods to train a new controller for the damping parameter of the LMA. This controller was trained on a collection of classic, relatively small, non-linear regression problems. The modiﬁed LMA performed better than the standard LMA on these problems. This controller also dramatically outperformed the standard LMA on a difﬁcult computer vision problem for which it had not been trained. Thus the controller appeared to have extracted control rules that were not just domain speciﬁc but generalized across a range of optimization domains. 1</p><p>4 0.56215155 <a title="36-lda-4" href="./nips-2008-Adaptive_Forward-Backward_Greedy_Algorithm_for_Sparse_Learning_with_Linear_Models.html">14 nips-2008-Adaptive Forward-Backward Greedy Algorithm for Sparse Learning with Linear Models</a></p>
<p>Author: Tong Zhang</p><p>Abstract: Consider linear prediction models where the target function is a sparse linear combination of a set of basis functions. We are interested in the problem of identifying those basis functions with non-zero coefﬁcients and reconstructing the target function from noisy observations. Two heuristics that are widely used in practice are forward and backward greedy algorithms. First, we show that neither idea is adequate. Second, we propose a novel combination that is based on the forward greedy algorithm but takes backward steps adaptively whenever beneﬁcial. We prove strong theoretical results showing that this procedure is effective in learning sparse representations. Experimental results support our theory. 1</p><p>5 0.53610218 <a title="36-lda-5" href="./nips-2008-High-dimensional_support_union_recovery_in_multivariate_regression.html">99 nips-2008-High-dimensional support union recovery in multivariate regression</a></p>
<p>Author: Guillaume R. Obozinski, Martin J. Wainwright, Michael I. Jordan</p><p>Abstract: We study the behavior of block 1 / 2 regularization for multivariate regression, where a K-dimensional response vector is regressed upon a ﬁxed set of p covariates. The problem of support union recovery is to recover the subset of covariates that are active in at least one of the regression problems. Studying this problem under high-dimensional scaling (where the problem parameters as well as sample size n tend to inﬁnity simultaneously), our main result is to show that exact recovery is possible once the order parameter given by θ 1 / 2 (n, p, s) : = n/[2ψ(B ∗ ) log(p − s)] exceeds a critical threshold. Here n is the sample size, p is the ambient dimension of the regression model, s is the size of the union of supports, and ψ(B ∗ ) is a sparsity-overlap function that measures a combination of the sparsities and overlaps of the K-regression coefﬁcient vectors that constitute the model. This sparsity-overlap function reveals that block 1 / 2 regularization for multivariate regression never harms performance relative to a naive 1 -approach, and can yield substantial improvements in sample complexity (up to a factor of K) when the regression vectors are suitably orthogonal relative to the design. We complement our theoretical results with simulations that demonstrate the sharpness of the result, even for relatively small problems. 1</p><p>6 0.53537685 <a title="36-lda-6" href="./nips-2008-Robust_Regression_and_Lasso.html">202 nips-2008-Robust Regression and Lasso</a></p>
<p>7 0.52829736 <a title="36-lda-7" href="./nips-2008-Learning_Hybrid_Models_for_Image_Annotation_with_Partially_Labeled_Data.html">116 nips-2008-Learning Hybrid Models for Image Annotation with Partially Labeled Data</a></p>
<p>8 0.52731377 <a title="36-lda-8" href="./nips-2008-An_Homotopy_Algorithm_for_the_Lasso_with_Online_Observations.html">21 nips-2008-An Homotopy Algorithm for the Lasso with Online Observations</a></p>
<p>9 0.52387196 <a title="36-lda-9" href="./nips-2008-Dynamic_visual_attention%3A_searching_for_coding_length_increments.html">66 nips-2008-Dynamic visual attention: searching for coding length increments</a></p>
<p>10 0.52362722 <a title="36-lda-10" href="./nips-2008-Semi-supervised_Learning_with_Weakly-Related_Unlabeled_Data_%3A_Towards_Better_Text_Categorization.html">205 nips-2008-Semi-supervised Learning with Weakly-Related Unlabeled Data : Towards Better Text Categorization</a></p>
<p>11 0.52217591 <a title="36-lda-11" href="./nips-2008-Exploring_Large_Feature_Spaces_with_Hierarchical_Multiple_Kernel_Learning.html">79 nips-2008-Exploring Large Feature Spaces with Hierarchical Multiple Kernel Learning</a></p>
<p>12 0.52107388 <a title="36-lda-12" href="./nips-2008-Regularized_Learning_with_Networks_of_Features.html">194 nips-2008-Regularized Learning with Networks of Features</a></p>
<p>13 0.52055866 <a title="36-lda-13" href="./nips-2008-Differentiable_Sparse_Coding.html">62 nips-2008-Differentiable Sparse Coding</a></p>
<p>14 0.52004582 <a title="36-lda-14" href="./nips-2008-Grouping_Contours_Via_a_Related_Image.html">95 nips-2008-Grouping Contours Via a Related Image</a></p>
<p>15 0.51998389 <a title="36-lda-15" href="./nips-2008-Dimensionality_Reduction_for_Data_in_Multiple_Feature_Representations.html">63 nips-2008-Dimensionality Reduction for Data in Multiple Feature Representations</a></p>
<p>16 0.51898128 <a title="36-lda-16" href="./nips-2008-Stress%2C_noradrenaline%2C_and_realistic_prediction_of_mouse_behaviour_using_reinforcement_learning.html">222 nips-2008-Stress, noradrenaline, and realistic prediction of mouse behaviour using reinforcement learning</a></p>
<p>17 0.51871777 <a title="36-lda-17" href="./nips-2008-Robust_Kernel_Principal_Component_Analysis.html">200 nips-2008-Robust Kernel Principal Component Analysis</a></p>
<p>18 0.51861227 <a title="36-lda-18" href="./nips-2008-Partially_Observed_Maximum_Entropy_Discrimination_Markov_Networks.html">176 nips-2008-Partially Observed Maximum Entropy Discrimination Markov Networks</a></p>
<p>19 0.51787496 <a title="36-lda-19" href="./nips-2008-Cascaded_Classification_Models%3A_Combining_Models_for_Holistic_Scene_Understanding.html">42 nips-2008-Cascaded Classification Models: Combining Models for Holistic Scene Understanding</a></p>
<p>20 0.51723522 <a title="36-lda-20" href="./nips-2008-A_Scalable_Hierarchical_Distributed_Language_Model.html">4 nips-2008-A Scalable Hierarchical Distributed Language Model</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
