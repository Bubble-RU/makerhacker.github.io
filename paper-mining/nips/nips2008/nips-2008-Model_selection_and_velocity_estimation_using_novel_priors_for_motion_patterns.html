<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>136 nips-2008-Model selection and velocity estimation using novel priors for motion patterns</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-136" href="#">nips2008-136</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>136 nips-2008-Model selection and velocity estimation using novel priors for motion patterns</h1>
<br/><p>Source: <a title="nips-2008-136-pdf" href="http://papers.nips.cc/paper/3458-model-selection-and-velocity-estimation-using-novel-priors-for-motion-patterns.pdf">pdf</a></p><p>Author: Shuang Wu, Hongjing Lu, Alan L. Yuille</p><p>Abstract: Psychophysical experiments show that humans are better at perceiving rotation and expansion than translation. These ﬁndings are inconsistent with standard models of motion integration which predict best performance for translation [6]. To explain this discrepancy, our theory formulates motion perception at two levels of inference: we ﬁrst perform model selection between the competing models (e.g. translation, rotation, and expansion) and then estimate the velocity using the selected model. We deﬁne novel prior models for smooth rotation and expansion using techniques similar to those in the slow-and-smooth model [17] (e.g. Green functions of differential operators). The theory gives good agreement with the trends observed in human experiments. 1</p><p>Reference: <a title="nips-2008-136-reference" href="../nips2008_reference/nips-2008-Model_selection_and_velocity_estimation_using_novel_priors_for_motion_patterns_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Model selection and velocity estimation using novel priors for motion patterns  Hongjing Lu Shuang Wu Department of Psychology Department of Statistics UCLA, Los Angeles, CA 90095 UCLA, Los Angeles, CA 90095 hongjing@ucla. [sent-1, score-0.774]
</p><p>2 edu  Abstract Psychophysical experiments show that humans are better at perceiving rotation and expansion than translation. [sent-6, score-0.537]
</p><p>3 These ﬁndings are inconsistent with standard models of motion integration which predict best performance for translation [6]. [sent-7, score-0.933]
</p><p>4 To explain this discrepancy, our theory formulates motion perception at two levels of inference: we ﬁrst perform model selection between the competing models (e. [sent-8, score-0.769]
</p><p>5 We deﬁne novel prior models for smooth rotation and expansion using techniques similar to those in the slow-and-smooth model [17] (e. [sent-11, score-0.56]
</p><p>6 1  Introduction  As an observer moves through the environment, the retinal image changes over time to create multiple complex motion ﬂows, including translational, circular and radial motion. [sent-15, score-0.61]
</p><p>7 Human observers are able to process different motion patterns and infer ego motion and global structure of the world. [sent-16, score-1.234]
</p><p>8 However, the inherent ambiguity of local motion signals requires the visual system to employ an efﬁcient integration strategy to combine many local measurements in order to perceive global motion. [sent-17, score-0.692]
</p><p>9 Psychophysical experiments have identiﬁed a variety of phenomena, such as motion capture and motion cooperativity [11], which appear to be consequences of such integration. [sent-18, score-1.098]
</p><p>10 However, the integration strategy modeled by the slow-and-smooth prior may not generalize to more complex motion types, such as circular and radial motion, which are critically important for estimating ego motion. [sent-21, score-0.742]
</p><p>11 (1) What integration priors should be used for a particular motion input? [sent-23, score-0.641]
</p><p>12 (2) How can local motion measurements be combined with the proper priors to estimate motion ﬂow? [sent-24, score-1.153]
</p><p>13 In the ﬁeld of motion perception, most work has focused on the second question, using parameter estimation to estimate motion ﬂow. [sent-26, score-1.098]
</p><p>14 However, Stocker and Simoncelli [13] recently proposed a conditioned Bayesian model in which strong biases in precise motion direction estimates arise as a consequence of a preceding decision about a particular hypothesis (left vs. [sent-27, score-0.612]
</p><p>15 To address the ﬁrst question, we develop new prior models for smooth rotation and expansion motion. [sent-30, score-0.522]
</p><p>16 To address the second, we propose that the human visual system has available multiple models of motion integration appropriate for different motion patterns. [sent-31, score-1.264]
</p><p>17 The visual system decides the best integration strategy based upon the perceived motion information, and this choice in turn affects the estimation of motion ﬂow. [sent-32, score-1.225]
</p><p>18 We test this theory in sections (4,5) by comparing its predictions with human performance in psychophysical experiments, in which subjects were asked to discriminate motion direction in translational, rotational, and expanding stimuli. [sent-34, score-0.744]
</p><p>19 We employ two commonly used stimuli, random dot patterns and moving gratings, to show that the model can apply to a variety of inputs. [sent-35, score-0.189]
</p><p>20 2  Background  There is an enormous literature on visual motion phenomena and there is only room to summarize the work most relevant to this paper. [sent-36, score-0.612]
</p><p>21 Our computational model relates most closely to work [17, 15, 7] that formulates motion perception as Bayesian inference with a prior probability biasing towards slow-and-smooth motion. [sent-37, score-0.76]
</p><p>22 But psychophysical [4, 8, 1, 6], physiological [14, 3] and fMRI data [9] suggests that humans are sensitive to a variety of motion patterns including translation, rotation, and expansion. [sent-38, score-0.734]
</p><p>23 In particular, Lee et al [6] demonstrated that human performance on discrimination tasks for translation, rotation, and expansion motion was inconsistent with the predictions of the slow-andsmooth theory (our simulations independently verify this result). [sent-39, score-0.815]
</p><p>24 Instead, we propose that human motion perception is performed at two levels of inference: (i) model selection, and (ii) estimating the velocity with the selected model. [sent-40, score-0.866]
</p><p>25 The concept of model selection has been described in the literature, see [5], but has only recently been applied to model motion phenomena [13]. [sent-41, score-0.679]
</p><p>26 Our new motion models for rotation and expansion are formulated very similarly to the original slow-andsmooth model [17] and similar mathematical analysis [2] is used to obtain the forms of the solutions in terms of Greens functions of the differential operators used in the priors. [sent-42, score-1.13]
</p><p>27 1  Model Formulation Bayesian Framework  We formulate motion perception as a problem of Bayesian inference with two parts. [sent-44, score-0.655]
</p><p>28 The ﬁrst part selects a model that best explains the observed motion pattern. [sent-45, score-0.587]
</p><p>29 The second part estimates motion properties using the selected model. [sent-46, score-0.549]
</p><p>30 The velocity ﬁeld {v} is estimated from velocity measurements {u} at discrete positions {ri , i = 1, . [sent-47, score-0.263]
</p><p>31 2  The Priors  We deﬁne three priors corresponding to the three different types of motion – translation, rotation, and expansion. [sent-56, score-0.583]
</p><p>32 For each motion type, we encourage slowness and smoothness. [sent-57, score-0.62]
</p><p>33 The prior for translation is very similar to the slow-and-smooth prior [17] except we drop the higher-order derivative terms and introduce an extra parameter (to ensure that all three models have similar degrees of freedom). [sent-58, score-0.382]
</p><p>34 We label the models by M ∈ {t, r, e}, where t, r, e denote translation, rotation, and expansion respectively. [sent-60, score-0.214]
</p><p>35 (We note that the prior for expansion will also account for contraction). [sent-61, score-0.232]
</p><p>36 The translation model prefers constant translation motion with v constant, since v = 0 for this type of motion. [sent-68, score-1.206]
</p><p>37 The rotation model prefers rigid rotation and expansion, respectively, of ideal form {vx = −ω(y − y0 ), vy = ω(x − x0 )}, {vx = e(x − x0 ), vy = e(y − y0 )  (9)  where (x0 , y0 ) are the (unknown) centers, ω is the angular speed and e is the expansion rate. [sent-69, score-1.19]
</p><p>38 These forms of motion are preferred by the two models since, for the ﬁrst type of motion (rotation) we have ∂vy ∂vy { ∂vx + ∂x = 0, ∂vx = ∂y = 0} (independent of (x0 , y0 ) and ω). [sent-70, score-1.157]
</p><p>39 Similarly, the second type of ∂y ∂x motion is preferred by the expansion (or contraction) model since { ∂vx − ∂x (again independent of (x0 , y0 ) and e). [sent-71, score-0.82]
</p><p>40 ∂vy ∂y  = 0,  ∂vx ∂y  =  ∂vy ∂x  = 0}  The translation model is similar to the ﬁrst three terms of the slow-and-smooth energy function 2 4 [17] but with a restriction on the set of parameters. [sent-72, score-0.349]
</p><p>41 Our computer simulations showed that the translation model performs similar to the slow-and-smooth model. [sent-75, score-0.324]
</p><p>42 These 1x 1y 2 2x 2y 1x 2y 2x 1y vector-valued Green functions are required to perform the coupling between the different velocity component required for rotation and expansion, see ﬁgure (1). [sent-83, score-0.417]
</p><p>43 For the translation model there is no coupling required and so GM = GM = 0. [sent-84, score-0.35]
</p><p>44 Top panel, left-to-right: GM =t , GM =r , GM =e for the translation, rotation and expansion models. [sent-86, score-0.464]
</p><p>45 Bottom panel: left-to 1x 1x 1x right: GM =t , GM =r , GM =e for translation, rotation, and expansion models. [sent-87, score-0.194]
</p><p>46 Observe that the GM 2x 2x 2x 1x are similar for all models, GM =t vanishes for the translation model (i. [sent-88, score-0.324]
</p><p>47 no coupling between veloc2x ity components), and GM =r and GM =e both have two peaks which correspond to the two directions 2x 2x of rotation and expansion. [sent-90, score-0.296]
</p><p>48 1y 2x 2y 1x The estimated velocity for the M model is of the form: N  [αi GM (r − ri ) + βi GM (r − ri )], 1 2  v(r) =  (13)  i=1  For the dot stimuli, the {α}, {β} are obtained by solving the linear equations: N  [αj GM (ri − rj ) + βj GM (ri − rj )] + αi e1 + βi e2 = u(ri ), i = 1, . [sent-92, score-0.733]
</p><p>49 g ˜  4  Results on random dot motion  We ﬁrst investigate motion perception with the moving dots stimuli used by Freeman and Harris [4], as shown in ﬁgure (2). [sent-100, score-1.462]
</p><p>50 The stimuli consist of 128 moving dots in a random spatial pattern. [sent-101, score-0.18]
</p><p>51 All the dots have the same speed in all three motion patterns, including translation, rotation and expansion. [sent-102, score-0.949]
</p><p>52 Our simulations ﬁrst select the correct model for each stimulus and then estimate the speed threshold of detection for each type of motion. [sent-103, score-0.273]
</p><p>53 Nevertheless the correct model is always selected over the entire range of speed, and for all 3 type of motion stimuli. [sent-135, score-0.61]
</p><p>54 9  482  rotation model expansion model translation model  482  rotation model expansion model translation model  481  rotation model expansion model translation model  481  480  log(P(u))  log(P(u))  log(P(u))  482. [sent-137, score-2.592]
</p><p>55 Plots the log probability of the model as a function of speed for each type of stimuli. [sent-158, score-0.165]
</p><p>56 left: translation stimuli; middle: rotation stimuli; right: expansion stimuli. [sent-159, score-0.75]
</p><p>57 2  Speed threshold of Detection  As reported in [4], humans have lower speed threshold in detecting rotation/expansion than translation motion. [sent-164, score-0.521]
</p><p>58 The experiment is formulated as a model selection task with an additional “static” motion prior. [sent-165, score-0.614]
</p><p>59 The “static” motion prior is modeled as a translation prior with µ = 0 and λ signiﬁcantly large to emphasize slowness. [sent-166, score-0.911]
</p><p>60 At low speed, the “static” model is favored due to its stronger bias towards slowness, as stimulus speed increases, it loses its advantage to other models. [sent-170, score-0.197]
</p><p>61 The speed thresholds of detection for different motion patterns can be seen from the model evidence plots in ﬁgure (4), and they are lower for rotation/expansion than translation. [sent-171, score-0.813]
</p><p>62 488 486 484 482  rotation model expansion model translation model static model  481. [sent-176, score-0.966]
</p><p>63 6  rotation model expansion model translation model static model  481 480. [sent-179, score-0.966]
</p><p>64 0502  rotation model expansion model translation model static model  log(P(u)) 480. [sent-191, score-0.966]
</p><p>65 0508  0  translation  rotation  expansion  Figure 4: Speed threshold of detection. [sent-205, score-0.786]
</p><p>66 Upper left panel: model evidence plot for translation stimuli. [sent-206, score-0.357]
</p><p>67 Upper right panel: model evidence plot for rotation stimuli. [sent-207, score-0.341]
</p><p>68 Lower left panel: model eviddence plot for expansion stimuli. [sent-208, score-0.232]
</p><p>69 1  Results on randomly oriented gratings Stimuli  When randomly oriented grating elements drift behind apertures, the perceived direction of motion is heavily biased by the orientation of the gratings, as well as by the shape and contrast of the apertures. [sent-212, score-0.99]
</p><p>70 Recently, Nishida and his colleagues developed a novel global motion stimulus consisting of a number of gratings elements, each with randomly assigned orientation [10]. [sent-213, score-0.852]
</p><p>71 A coherent motion is perceived when the drifting velocities of all elements are consistent with a given velocity. [sent-214, score-0.721]
</p><p>72 Examples of the stimuli used in these psychophysical experiments are shown in left side of ﬁgure (6). [sent-215, score-0.224]
</p><p>73 The stimuli consisted of 728 gratings (drifting sine-wave gratings windowed by stationary Gaussians). [sent-216, score-0.498]
</p><p>74 The orientations of the gratings were randomly assigned, and their drifting velocities were determined by a speciﬁed global motion ﬂow pattern. [sent-217, score-0.865]
</p><p>75 The motions of signal grating elements were consistent with global motion, but the motions of noise grating elements were randomized. [sent-218, score-0.37]
</p><p>76 The task was to identify the global motion direction as one of two alternatives: left/right for translation, clockwise/counterclockwise for rotation, and inward/outward for expansion. [sent-219, score-0.602]
</p><p>77 Similar stimuli with 328 gratings were generated to test our computational models. [sent-221, score-0.311]
</p><p>78 The input for the models is the velocity component perpendicular to the assigned orientation for each grating, as illustrated in the upper two panels of ﬁgure (5). [sent-222, score-0.174]
</p><p>79 15  15  10  10  5  5  0  0  −5  −5  −10  −10  −15 −15  −10  −5  0  5  10  15  −15 −15  15  0  5  10  15  −10  −5  0  5  10  15  10  5  −5  15  10  −10  5  0  0  −5  −5  −10  −10  −15 −15  −10  −5  0  5  10  15  −15 −15  Figure 5: Randomly-oriented grating stimuli and estimated motion ﬂow. [sent-223, score-0.78]
</p><p>80 Upper left panel: rotation stimulus (with 75% coherence ratio). [sent-224, score-0.4]
</p><p>81 Upper right panel: expansion stimulus (with 75% coherence ratio). [sent-225, score-0.324]
</p><p>82 Lower left panel: motion ﬂow estimated from stimulus in ﬁrst panel with rotation model. [sent-226, score-1.001]
</p><p>83 Lower right panel: motion ﬂow estimated from stimulus in second panel with expansion model. [sent-227, score-0.925]
</p><p>84 2  Result  The results of psychophysical experiments (middle panel of ﬁgure 6) showed worse performance for perceiving translation than rotation/expansion motion [6]. [sent-229, score-1.093]
</p><p>85 Clearly, as shown in the third panel of the same ﬁgure, the model performs best for rotation and expansion, and is worst for translation. [sent-230, score-0.435]
</p><p>86 This ﬁnding agrees with human performance in psychophysical experiments. [sent-231, score-0.152]
</p><p>87 6  Conclusion  Humans motion sensitivities depend on the motion patterns (translation/rotation/expansion). [sent-232, score-1.141]
</p><p>88 05 0  translation  rotation  expansion  Figure 6: Stimulus and results. [sent-243, score-0.75]
</p><p>89 Blue arrows indicate the drifting velocity of each grating. [sent-245, score-0.178]
</p><p>90 Middle panel: human coherence thresholds for different motion stimuli. [sent-246, score-0.705]
</p><p>91 Right panel: Model prediction of coherence thresholds which are consistent with human trends. [sent-247, score-0.156]
</p><p>92 This analysis involves formulating two new prior models for rotation and expansion model and deriving their properties. [sent-249, score-0.56]
</p><p>93 It is also important to determine if motion patterns to which humans are sensitive correspond to those appearing regularly in natural motion sequences. [sent-254, score-1.183]
</p><p>94 Measurement of angular velocity in the perception of rotation. [sent-260, score-0.251]
</p><p>95 Superior perception of circular/radial than translational motion cannot be explained by generic priors. [sent-295, score-0.698]
</p><p>96 Global motion with multiple Gabors - A tool to investigate motion integration across orientation and space. [sent-329, score-1.189]
</p><p>97 Noise characteristics and prior expectations in human visual speed perception Nature Neuroscience, vol. [sent-353, score-0.336]
</p><p>98 Underlying mechanisms of the response speciﬁcity of expansion/contraction and rotation cells in the dorsal part of the MST area of the macaque monkey. [sent-367, score-0.27]
</p><p>99 Slow and smooth: A Bayesian theory for the combination of local motion signals in human vision Technical Report 1624. [sent-375, score-0.601]
</p><p>100 A computational theory for the perception of coherent visual motion. [sent-392, score-0.16]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('motion', 0.549), ('gm', 0.411), ('translation', 0.286), ('rotation', 0.27), ('expansion', 0.194), ('gratings', 0.187), ('ri', 0.165), ('vx', 0.156), ('vy', 0.133), ('panel', 0.127), ('stimuli', 0.124), ('velocity', 0.121), ('grating', 0.107), ('perception', 0.106), ('speed', 0.104), ('psychophysical', 0.1), ('rj', 0.083), ('dot', 0.078), ('ux', 0.078), ('coherence', 0.075), ('slowness', 0.071), ('static', 0.064), ('uy', 0.062), ('integration', 0.058), ('drifting', 0.057), ('stimulus', 0.055), ('human', 0.052), ('ow', 0.047), ('stocker', 0.047), ('yuille', 0.046), ('motions', 0.044), ('velocities', 0.044), ('patterns', 0.043), ('green', 0.043), ('translational', 0.043), ('humans', 0.042), ('dr', 0.04), ('prior', 0.038), ('angeles', 0.038), ('ucla', 0.038), ('model', 0.038), ('threshold', 0.036), ('ego', 0.036), ('hongjing', 0.036), ('morrone', 0.036), ('nishida', 0.036), ('vss', 0.036), ('visual', 0.036), ('gure', 0.034), ('priors', 0.034), ('perceived', 0.033), ('los', 0.033), ('orientation', 0.033), ('evidence', 0.033), ('circular', 0.032), ('perceiving', 0.031), ('moving', 0.03), ('radial', 0.029), ('thresholds', 0.029), ('formulates', 0.029), ('observers', 0.029), ('contraction', 0.029), ('optic', 0.029), ('mst', 0.029), ('det', 0.028), ('global', 0.028), ('selection', 0.027), ('eds', 0.027), ('phenomena', 0.027), ('bayesian', 0.026), ('dots', 0.026), ('coupling', 0.026), ('direction', 0.025), ('energy', 0.025), ('prefers', 0.024), ('lu', 0.024), ('angular', 0.024), ('sensitivity', 0.023), ('simoncelli', 0.023), ('type', 0.023), ('differential', 0.022), ('measurement', 0.022), ('arg', 0.021), ('measurements', 0.021), ('middle', 0.021), ('models', 0.02), ('elements', 0.02), ('inconsistent', 0.02), ('operators', 0.02), ('coherent', 0.018), ('freeman', 0.018), ('expanding', 0.018), ('oriented', 0.018), ('curves', 0.017), ('detection', 0.017), ('detecting', 0.017), ('similarly', 0.017), ('neuroscience', 0.017), ('trends', 0.016), ('preferred', 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="136-tfidf-1" href="./nips-2008-Model_selection_and_velocity_estimation_using_novel_priors_for_motion_patterns.html">136 nips-2008-Model selection and velocity estimation using novel priors for motion patterns</a></p>
<p>Author: Shuang Wu, Hongjing Lu, Alan L. Yuille</p><p>Abstract: Psychophysical experiments show that humans are better at perceiving rotation and expansion than translation. These ﬁndings are inconsistent with standard models of motion integration which predict best performance for translation [6]. To explain this discrepancy, our theory formulates motion perception at two levels of inference: we ﬁrst perform model selection between the competing models (e.g. translation, rotation, and expansion) and then estimate the velocity using the selected model. We deﬁne novel prior models for smooth rotation and expansion using techniques similar to those in the slow-and-smooth model [17] (e.g. Green functions of differential operators). The theory gives good agreement with the trends observed in human experiments. 1</p><p>2 0.22405402 <a title="136-tfidf-2" href="./nips-2008-Nonrigid_Structure_from_Motion_in_Trajectory_Space.html">157 nips-2008-Nonrigid Structure from Motion in Trajectory Space</a></p>
<p>Author: Ijaz Akhter, Yaser Sheikh, Sohaib Khan, Takeo Kanade</p><p>Abstract: Existing approaches to nonrigid structure from motion assume that the instantaneous 3D shape of a deforming object is a linear combination of basis shapes, which have to be estimated anew for each video sequence. In contrast, we propose that the evolving 3D structure be described by a linear combination of basis trajectories. The principal advantage of this approach is that we do not need to estimate any basis vectors during computation. We show that generic bases over trajectories, such as the Discrete Cosine Transform (DCT) basis, can be used to compactly describe most real motions. This results in a signiﬁcant reduction in unknowns, and corresponding stability in estimation. We report empirical performance, quantitatively using motion capture data, and qualitatively on several video sequences exhibiting nonrigid motions including piece-wise rigid motion, partially nonrigid motion (such as a facial expression), and highly nonrigid motion (such as a person dancing). 1</p><p>3 0.22266316 <a title="136-tfidf-3" href="./nips-2008-Learning_Transformational_Invariants_from_Natural_Movies.html">118 nips-2008-Learning Transformational Invariants from Natural Movies</a></p>
<p>Author: Charles Cadieu, Bruno A. Olshausen</p><p>Abstract: We describe a hierarchical, probabilistic model that learns to extract complex motion from movies of the natural environment. The model consists of two hidden layers: the ﬁrst layer produces a sparse representation of the image that is expressed in terms of local amplitude and phase variables. The second layer learns the higher-order structure among the time-varying phase variables. After training on natural movies, the top layer units discover the structure of phase-shifts within the ﬁrst layer. We show that the top layer units encode transformational invariants: they are selective for the speed and direction of a moving pattern, but are invariant to its spatial structure (orientation/spatial-frequency). The diversity of units in both the intermediate and top layers of the model provides a set of testable predictions for representations that might be found in V1 and MT. In addition, the model demonstrates how feedback from higher levels can inﬂuence representations at lower levels as a by-product of inference in a graphical model. 1</p><p>4 0.20275308 <a title="136-tfidf-4" href="./nips-2008-Using_Bayesian_Dynamical_Systems_for_Motion_Template_Libraries.html">247 nips-2008-Using Bayesian Dynamical Systems for Motion Template Libraries</a></p>
<p>Author: Silvia Chiappa, Jens Kober, Jan R. Peters</p><p>Abstract: Motor primitives or motion templates have become an important concept for both modeling human motor control as well as generating robot behaviors using imitation learning. Recent impressive results range from humanoid robot movement generation to timing models of human motions. The automatic generation of skill libraries containing multiple motion templates is an important step in robot learning. Such a skill learning system needs to cluster similar movements together and represent each resulting motion template as a generative model which is subsequently used for the execution of the behavior by a robot system. In this paper, we show how human trajectories captured as multi-dimensional time-series can be clustered using Bayesian mixtures of linear Gaussian state-space models based on the similarity of their dynamics. The appropriate number of templates is automatically determined by enforcing a parsimonious parametrization. As the resulting model is intractable, we introduce a novel approximation method based on variational Bayes, which is especially designed to enable the use of efﬁcient inference algorithms. On recorded human Balero movements, this method is not only capable of ﬁnding reasonable motion templates but also yields a generative model which works well in the execution of this complex task on a simulated anthropomorphic SARCOS arm.</p><p>5 0.17454478 <a title="136-tfidf-5" href="./nips-2008-Bayesian_Synchronous_Grammar_Induction.html">35 nips-2008-Bayesian Synchronous Grammar Induction</a></p>
<p>Author: Phil Blunsom, Trevor Cohn, Miles Osborne</p><p>Abstract: We present a novel method for inducing synchronous context free grammars (SCFGs) from a corpus of parallel string pairs. SCFGs can model equivalence between strings in terms of substitutions, insertions and deletions, and the reordering of sub-strings. We develop a non-parametric Bayesian model and apply it to a machine translation task, using priors to replace the various heuristics commonly used in this ﬁeld. Using a variational Bayes training procedure, we learn the latent structure of translation equivalence through the induction of synchronous grammar categories for phrasal translations, showing improvements in translation performance over maximum likelihood models. 1</p><p>6 0.12537421 <a title="136-tfidf-6" href="./nips-2008-An_ideal_observer_model_of_infant_object_perception.html">23 nips-2008-An ideal observer model of infant object perception</a></p>
<p>7 0.11636271 <a title="136-tfidf-7" href="./nips-2008-Learning_a_discriminative_hidden_part_model_for_human_action_recognition.html">119 nips-2008-Learning a discriminative hidden part model for human action recognition</a></p>
<p>8 0.098187335 <a title="136-tfidf-8" href="./nips-2008-The_Gaussian_Process_Density_Sampler.html">233 nips-2008-The Gaussian Process Density Sampler</a></p>
<p>9 0.091173783 <a title="136-tfidf-9" href="./nips-2008-Non-stationary_dynamic_Bayesian_networks.html">152 nips-2008-Non-stationary dynamic Bayesian networks</a></p>
<p>10 0.082752243 <a title="136-tfidf-10" href="./nips-2008-Tracking_Changing_Stimuli_in_Continuous_Attractor_Neural_Networks.html">240 nips-2008-Tracking Changing Stimuli in Continuous Attractor Neural Networks</a></p>
<p>11 0.078332685 <a title="136-tfidf-11" href="./nips-2008-Grouping_Contours_Via_a_Related_Image.html">95 nips-2008-Grouping Contours Via a Related Image</a></p>
<p>12 0.074237362 <a title="136-tfidf-12" href="./nips-2008-Estimating_Robust_Query_Models_with_Convex_Optimization.html">73 nips-2008-Estimating Robust Query Models with Convex Optimization</a></p>
<p>13 0.058572397 <a title="136-tfidf-13" href="./nips-2008-Interpreting_the_neural_code_with_Formal_Concept_Analysis.html">109 nips-2008-Interpreting the neural code with Formal Concept Analysis</a></p>
<p>14 0.054738816 <a title="136-tfidf-14" href="./nips-2008-ICA_based_on_a_Smooth_Estimation_of_the_Differential_Entropy.html">102 nips-2008-ICA based on a Smooth Estimation of the Differential Entropy</a></p>
<p>15 0.053953495 <a title="136-tfidf-15" href="./nips-2008-Temporal_Dynamics_of_Cognitive_Control.html">231 nips-2008-Temporal Dynamics of Cognitive Control</a></p>
<p>16 0.04604188 <a title="136-tfidf-16" href="./nips-2008-Dynamic_visual_attention%3A_searching_for_coding_length_increments.html">66 nips-2008-Dynamic visual attention: searching for coding length increments</a></p>
<p>17 0.045279961 <a title="136-tfidf-17" href="./nips-2008-Sequential_effects%3A_Superstition_or_rational_behavior%3F.html">206 nips-2008-Sequential effects: Superstition or rational behavior?</a></p>
<p>18 0.042740896 <a title="136-tfidf-18" href="./nips-2008-Estimating_vector_fields_using_sparse_basis_field_expansions.html">75 nips-2008-Estimating vector fields using sparse basis field expansions</a></p>
<p>19 0.041616116 <a title="136-tfidf-19" href="./nips-2008-Model_Selection_in_Gaussian_Graphical_Models%3A_High-Dimensional_Consistency_of_%5Cboldmath%24%5Cell_1%24-regularized_MLE.html">135 nips-2008-Model Selection in Gaussian Graphical Models: High-Dimensional Consistency of \boldmath$\ell 1$-regularized MLE</a></p>
<p>20 0.039945498 <a title="136-tfidf-20" href="./nips-2008-Optimal_Response_Initiation%3A_Why_Recent_Experience_Matters.html">172 nips-2008-Optimal Response Initiation: Why Recent Experience Matters</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2008_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.132), (1, 0.007), (2, 0.154), (3, -0.047), (4, 0.093), (5, -0.009), (6, -0.125), (7, 0.006), (8, 0.142), (9, 0.035), (10, -0.085), (11, 0.001), (12, 0.072), (13, 0.251), (14, 0.075), (15, 0.079), (16, -0.189), (17, 0.11), (18, -0.088), (19, 0.032), (20, -0.188), (21, -0.023), (22, -0.088), (23, -0.313), (24, 0.027), (25, -0.049), (26, 0.034), (27, -0.244), (28, 0.092), (29, -0.082), (30, 0.021), (31, -0.006), (32, -0.021), (33, -0.089), (34, 0.012), (35, 0.109), (36, -0.12), (37, -0.049), (38, -0.039), (39, -0.059), (40, 0.073), (41, 0.036), (42, 0.1), (43, -0.051), (44, 0.06), (45, 0.004), (46, 0.006), (47, -0.062), (48, 0.032), (49, -0.015)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98128027 <a title="136-lsi-1" href="./nips-2008-Model_selection_and_velocity_estimation_using_novel_priors_for_motion_patterns.html">136 nips-2008-Model selection and velocity estimation using novel priors for motion patterns</a></p>
<p>Author: Shuang Wu, Hongjing Lu, Alan L. Yuille</p><p>Abstract: Psychophysical experiments show that humans are better at perceiving rotation and expansion than translation. These ﬁndings are inconsistent with standard models of motion integration which predict best performance for translation [6]. To explain this discrepancy, our theory formulates motion perception at two levels of inference: we ﬁrst perform model selection between the competing models (e.g. translation, rotation, and expansion) and then estimate the velocity using the selected model. We deﬁne novel prior models for smooth rotation and expansion using techniques similar to those in the slow-and-smooth model [17] (e.g. Green functions of differential operators). The theory gives good agreement with the trends observed in human experiments. 1</p><p>2 0.75075507 <a title="136-lsi-2" href="./nips-2008-Nonrigid_Structure_from_Motion_in_Trajectory_Space.html">157 nips-2008-Nonrigid Structure from Motion in Trajectory Space</a></p>
<p>Author: Ijaz Akhter, Yaser Sheikh, Sohaib Khan, Takeo Kanade</p><p>Abstract: Existing approaches to nonrigid structure from motion assume that the instantaneous 3D shape of a deforming object is a linear combination of basis shapes, which have to be estimated anew for each video sequence. In contrast, we propose that the evolving 3D structure be described by a linear combination of basis trajectories. The principal advantage of this approach is that we do not need to estimate any basis vectors during computation. We show that generic bases over trajectories, such as the Discrete Cosine Transform (DCT) basis, can be used to compactly describe most real motions. This results in a signiﬁcant reduction in unknowns, and corresponding stability in estimation. We report empirical performance, quantitatively using motion capture data, and qualitatively on several video sequences exhibiting nonrigid motions including piece-wise rigid motion, partially nonrigid motion (such as a facial expression), and highly nonrigid motion (such as a person dancing). 1</p><p>3 0.62146169 <a title="136-lsi-3" href="./nips-2008-Using_Bayesian_Dynamical_Systems_for_Motion_Template_Libraries.html">247 nips-2008-Using Bayesian Dynamical Systems for Motion Template Libraries</a></p>
<p>Author: Silvia Chiappa, Jens Kober, Jan R. Peters</p><p>Abstract: Motor primitives or motion templates have become an important concept for both modeling human motor control as well as generating robot behaviors using imitation learning. Recent impressive results range from humanoid robot movement generation to timing models of human motions. The automatic generation of skill libraries containing multiple motion templates is an important step in robot learning. Such a skill learning system needs to cluster similar movements together and represent each resulting motion template as a generative model which is subsequently used for the execution of the behavior by a robot system. In this paper, we show how human trajectories captured as multi-dimensional time-series can be clustered using Bayesian mixtures of linear Gaussian state-space models based on the similarity of their dynamics. The appropriate number of templates is automatically determined by enforcing a parsimonious parametrization. As the resulting model is intractable, we introduce a novel approximation method based on variational Bayes, which is especially designed to enable the use of efﬁcient inference algorithms. On recorded human Balero movements, this method is not only capable of ﬁnding reasonable motion templates but also yields a generative model which works well in the execution of this complex task on a simulated anthropomorphic SARCOS arm.</p><p>4 0.61277872 <a title="136-lsi-4" href="./nips-2008-Learning_Transformational_Invariants_from_Natural_Movies.html">118 nips-2008-Learning Transformational Invariants from Natural Movies</a></p>
<p>Author: Charles Cadieu, Bruno A. Olshausen</p><p>Abstract: We describe a hierarchical, probabilistic model that learns to extract complex motion from movies of the natural environment. The model consists of two hidden layers: the ﬁrst layer produces a sparse representation of the image that is expressed in terms of local amplitude and phase variables. The second layer learns the higher-order structure among the time-varying phase variables. After training on natural movies, the top layer units discover the structure of phase-shifts within the ﬁrst layer. We show that the top layer units encode transformational invariants: they are selective for the speed and direction of a moving pattern, but are invariant to its spatial structure (orientation/spatial-frequency). The diversity of units in both the intermediate and top layers of the model provides a set of testable predictions for representations that might be found in V1 and MT. In addition, the model demonstrates how feedback from higher levels can inﬂuence representations at lower levels as a by-product of inference in a graphical model. 1</p><p>5 0.52702183 <a title="136-lsi-5" href="./nips-2008-An_ideal_observer_model_of_infant_object_perception.html">23 nips-2008-An ideal observer model of infant object perception</a></p>
<p>Author: Charles Kemp, Fei Xu</p><p>Abstract: Before the age of 4 months, infants make inductive inferences about the motions of physical objects. Developmental psychologists have provided verbal accounts of the knowledge that supports these inferences, but often these accounts focus on categorical rather than probabilistic principles. We propose that infant object perception is guided in part by probabilistic principles like persistence: things tend to remain the same, and when they change they do so gradually. To illustrate this idea we develop an ideal observer model that incorporates probabilistic principles of rigidity and inertia. Like previous researchers, we suggest that rigid motions are expected from an early age, but we challenge the previous claim that the inertia principle is relatively slow to develop [1]. We support these arguments by modeling several experiments from the developmental literature. Over the past few decades, ingenious experiments [1, 2] have suggested that infants rely on systematic expectations about physical objects when interpreting visual scenes. Looking time studies suggest, for example, that infants expect objects to follow continuous trajectories through time and space, and understand that two objects cannot simultaneously occupy the same location. Many of these studies have been replicated several times, but there is still no consensus about the best way to characterize the knowledge that gives rise to these ﬁndings. Two main approaches can be found in the literature. The verbal approach uses natural language to characterize principles of object perception [1, 3]: for example, Spelke [4] proposes that object perception is consistent with principles including continuity (“a moving object traces exactly one connected path over space and time”) and cohesion (“a moving object maintains its connectedness and boundaries”). The mechanistic approach proposes that physical knowledge is better characterized by describing the mechanisms that give rise to behavior, and researchers working in this tradition often develop computational models that support their theoretical proposals [5]. We pursue a third approach—the ideal observer approach [6, 7, 8]—that combines aspects of both previous traditions. Like the verbal approach, our primary goal is to characterize principles that account for infant behavior, and we will not attempt to characterize the mechanisms that produce this behavior. Like the mechanistic approach, we emphasize the importance of formal models, and suggest that these models can capture forms of knowledge that are difﬁcult for verbal accounts to handle. Ideal observer models [6, 9] specify the conclusions that normatively follow given a certain source of information and a body of background knowledge. These models can therefore address questions about the information and the knowledge that support perception. Approaches to the information question characterize the kinds of perceptual information that human observers use. For example, Geisler [9] discusses which components of the information available at the retina contribute to visual perception, and Banks and Shannon [10] use ideal observer models to study the perceptual consequences of immaturities in the retina. Approaches to the knowledge question characterize the background assumptions that are combined with the available input in order to make inductive inferences. For example, Weiss and Adelson [7] describe several empirical phenomena that are consistent with the a priori assumption that motions tend to be slow and smooth. There are few previous attempts to develop ideal observer models of infant perception, and most of them focus only on the information question [10]. This paper addresses the knowledge question, and proposes that the ideal observer approach can help to identify the minimal set of principles needed to account for the visual competence of young infants. Most verbal theories of object perception focus on categorical principles [4], or principles that make a single distinction between possible and impossible scenes. We propose that physical knowledge in infancy is also characterized by probabilistic principles, or expectations that make some possible scenes more surprising than others. We demonstrate the importance of probabilistic principles by focusing on two examples: the rigidity principle states that objects usually maintain their shape and size when they move, and the inertia principle states that objects tend to maintain the same pattern of motion over time. Both principles capture important regularities, but exceptions to these regularities are relatively common. Focusing on rigidity and inertia allows us to demonstrate two contributions that probabilistic approaches can make. First, probabilistic approaches can reinforce current proposals about infant perception. Spelke [3] suggests that rigidity is a core principle that guides object perception from a very early age, and we demonstrate how this idea can be captured by a model that also tolerates exceptions, such as non-rigid biological motion. Second, probabilistic approaches can identify places where existing proposals may need to be revised. Spelke [3] argues that the principle of inertia is slow to develop, but we suggest that a probabilistic version of this principle can help to account for inferences made early in development. 1 An ideal observer approach An ideal observer approach to object perception can be formulated in terms of a generative model for scenes. Scenes can be generated in three steps. First we choose the number n of objects that will appear in the scene, and generate the shape, visual appearance, and initial location of each object. We then choose a velocity ﬁeld for each object which speciﬁes how the object moves and changes shape over time. Finally, we create a visual scene by taking a two-dimensional projection of the moving objects generated in the two previous steps. An ideal observer approach explores the idea that the inferences made by infants approximate the optimal inferences with respect to this generative model. We work within this general framework but make two simpliﬁcations. We will not discuss how the shapes and visual appearances of objects are generated, and we make the projection step simple by working with a two-dimensional world. These simpliﬁcations allow us to focus on the expectations about velocity ﬁelds that guide motion perception in infants. The next two sections present two prior distributions that can be used to generate velocity ﬁelds. The ﬁrst is a baseline prior that does not incorporate probabilistic principles, and the second incorporates probabilistic versions of rigidity and inertia. The two priors capture different kinds of knowledge, and we argue that the second provides the more accurate characterization of the knowledge that infants bring to object perception. 1.1 A baseline prior on velocity ﬁelds Our baseline prior is founded on ﬁve categorical principles that are closely related to principles discussed by Spelke [3, 4]. The principles we consider rely on three basic notions: space, time, and matter. We also refer to particles, which are small pieces of matter that occupy space-time points. Particles satisfy several principles: C1. Temporal continuity. Particles are not created or destroyed. In other words, every particle that exists at time t1 must also exist at time t2 . C2. Spatial continuity. Each particle traces a continuous trajectory through space. C3. Exclusion. No two particles may occupy the same space-time point. An object is a collection of particles, and these collections satisfy two principles: C4. Discreteness. Each particle belongs to exactly one object. C5. Cohesion. At each point in time, the particles belonging to an object occupy a single connected region of space. Suppose that we are interested in a space-time window speciﬁed by a bounded region of space and a bounded interval of time. For simplicity, we will assume that space is two-dimensional, and that the space-time window corresponds to the unit cube. Suppose that a velocity ﬁeld v assigns a velocity (vx , vy ) to each particle in the space-time window, and let vi be the ﬁeld created by considering only particles that belong to object i. We develop a theory of object perception by deﬁning a prior distribution p(v) on velocity ﬁelds. Consider ﬁrst the distribution p(v1 ) on ﬁelds for a single object. Any ﬁeld that violates one or more of principles C1–C5 is assigned zero probability. For instance, ﬁelds where part of an object winks out of existence violate the principle of temporal continuity, and ﬁelds where an object splits into two distinct pieces violate the principle of cohesion. Many ﬁelds, however, remain, including ﬁelds that specify non-rigid motions and jagged trajectories. For now, assume that we are working with a space of ﬁelds that is bounded but very large, and that the prior distribution over this space is uniform for all ﬁelds consistent with principles C1–C5: p(v1 ) ∝ f (v1 ) = 0 1 if v1 violates C1–C5 otherwise. (1) Consider now the distribution p(v1 , v2 ) on ﬁelds for pairs of objects. Principles C1 through C5 rule out some of these ﬁelds, but again we must specify a prior distribution on those that remain. Our prior is induced by the following principle: C6. Independence. Velocity ﬁelds for multiple objects are independently generated subject to principles C1 through C5. More formally, the independence principle speciﬁes how the prior for the multiple object case is related to the prior p(v1 ) on velocity ﬁelds for a single object (Equation 1): p(v1 , . . . , vn ) ∝ f (v1 , . . . , vn ) = 0 if {vi } collectively violate C1–C5 f (v1 ) . . . f (vn ) otherwise. (2) 1.2 A smoothness prior on velocity ﬁelds We now develop a prior p(v) that incorporates probabilistic expectations about the motion of physical objects. Consider again the prior p(v1 ) on the velocity ﬁeld v1 of a single object. Principles C1–C5 make a single cut that distinguishes possible from impossible ﬁelds, but we need to consider whether infants have additional knowledge that makes some of the possible ﬁelds less surprising than others. One informal idea that seems relevant is the notion of persistence[11]: things tend to remain the same, and when they change they do so gradually. We focus on two versions of this idea that may guide expectations about velocity ﬁelds: S1. Spatial smoothness. Velocity ﬁelds tend to be smooth in space. S2. Temporal smoothness. Velocity ﬁelds tend to be smooth in time. A ﬁeld is “smooth in space” if neighboring particles tend to have similar velocities at any instant of time. The smoothest possible ﬁeld will be one where all particles have the same velocity at any instant—in other words, where an object moves rigidly. The principle of spatial smoothness therefore captures the idea that objects tend to maintain the same shape and size. A ﬁeld is “smooth in time” if any particle tends to have similar velocities at nearby instants of time. The smoothest possible ﬁeld will be one where each particle maintains the same velocity throughout the entire interval of interest. The principle of temporal smoothness therefore captures the idea that objects tend to maintain their initial pattern of motion. For instance, stationary objects tend to remain stationary, moving objects tend to keep moving, and a moving object following a given trajectory tends to continue along that trajectory. Principles S1 and S2 are related to two principles— rigidity and inertia—that have been discussed in the developmental literature. The rigidity principle states that objects “tend to maintain their size and shape over motion”[3], and the inertia principle states that objects move smoothly in the absence of obstacles [4]. Some authors treat these principles rather differently: for instance, Spelke suggests that rigidity is one of the core principles that guides object perception from a very early age [3], but that the principle of inertia is slow to develop and is weak or fragile once acquired. Since principles S1 and S2 seem closely related, the suggestion that one develops much later than the other seems counterintuitive. The rest of this paper explores the idea that both of these principles are needed to characterize infant perception. Our arguments will be supported by formal analyses, and we therefore need formal versions of S1 and S2. There may be different ways to formalize these principles, but we present a simple L1 L2 U b) 200 L1 L2 U 0 log “ p(H1 |v) p(H2 |v) ” a) −200 baseline smoothness Figure 1: (a) Three scenes inspired by the experiments of Spelke and colleagues [12, 13]. Each scene can be interpreted as a single object, or as a small object on top of a larger object. (b) Relative preferences for the one-object and two-object interpretations according to two models. The baseline model prefers the one-object interpretation in all three cases, but the smoothness model prefers the one-object interpretation only for scenes L1 and L2. approach that builds on existing models of motion perception in adults [7, 8]. We deﬁne measures of instantaneous roughness that capture how rapidly a velocity ﬁeld v varies in space and time: Rspace (v, t) = ∂v(x, y, t) ∂x 2 ∂v(x, y, t) ∂t 1 vol(O(t)) 2 + ∂v(x, y, t) ∂y 2 dxdy (3) O(t) Rtime (v, t) = 1 vol(O(t)) dxdy (4) O(t) where O(t) is the set of all points that are occupied by the object at time t, and vol(O(t)) is the volume of the object at time t. Rspace (v, t) will be large if neighboring particles at time t tend to have different velocities, and Rtime (v, t) will be large if many particles are accelerating at time t. We combine our two roughness measures to create a single smoothness function S(·) that measures the smoothness of a velocity ﬁeld: S(v) = −λspace Rspace (v, t)dt − λtime Rtime (v, t)dt (5) where λspace and λtime are positive weights that capture the importance of spatial smoothness and temporal smoothness. For all analyses in this paper we set λspace = 10000 and λtime = 250, which implies that violations of spatial smoothness are penalized more harshly than violations of temporal smoothness. We now replace Equation 1 with a prior on velocity ﬁelds that takes smoothness into account: 0 if v1 violates C1–C5 p(v1 ) ∝ f (v1 ) = (6) exp (S(v1 )) otherwise. Combining Equation 6 with Equation 2 speciﬁes a model of object perception that incorporates probabilistic principles of rigidity and inertia. 2 Empirical ﬁndings: spatial smoothness There are many experiments where infants aged 4 months and younger appear to make inferences that are consistent with the principle of rigidity. This section suggests that the principle of spatial smoothness can account for these results. We therefore propose that a probabilistic principle (spatial smoothness) can explain all of the ﬁndings previously presented in support of a categorical principle (rigidity), and can help in addition to explain how infants perceive non-rigid motion. One set of studies explores inferences about the number of objects in a scene. When a smaller block is resting on top of a larger block (L1 in Figure 1a), 3-month-olds infer that the scene includes a single object [12]. The same result holds when the small and large blocks are both moving in the same direction (L2 in Figure 1a) [13]. When these blocks are moving in opposite directions (U in Figure 1a), however, infants appear to infer that the scene contains two objects [13]. Results like these suggest that infants may have a default expectation that objects tend to move rigidly. We compared the predictions made by two models about the scenes in Figure 1a. The smoothness model uses a prior p(v1 ) that incorporates principles S1 and S2 (Equation 6), and the baseline model is identical except that it sets λspace = λtime = 0. Both models therefore incorporate principles C1– C6, but only the smoothness model captures the principle of spatial smoothness. Given any of the scenes in Figure 1a, an infant must solve two problems: she must compute the velocity ﬁeld v for the scene and must decide whether this ﬁeld speciﬁes the motion of one or two objects. Here we focus on the second problem, and assume that the infant’s perceptual system has already computed a veridical velocity ﬁeld for each scene that we consider. In principle, however, the smoothness prior in Equation 6 can address both problems. Previous authors have shown how smoothness priors can be used to compute velocity ﬁelds given raw image data [7, 8]. Let H1 be the hypothesis that a given velocity ﬁeld corresponds to a single object, and let H2 be the hypothesis that the ﬁeld speciﬁes the motions of two objects. We assume that the prior probabilities of these hypotheses are equal, and that P (H1 ) = P (H2 ) = 0.5. An ideal observer can use the posterior odds ratio to choose between these hypotheses: P (H1 |v) P (v|H1 ) P (H1 ) = ≈ P (H2 |v) P (v|H2 ) P (H2 ) f (v) f (v1 )dv1 f (v1 , v2 )dv1 dv2 f (vA , vB ) (7) Equation 7 follows from Equations 2 and 6, and from approximating P (v|H2 ) by considering only the two object interpretation (vA , vB ) with maximum posterior probability. For each scene in Figure 1a, the best two object interpretation will specify a ﬁeld vA for the small upper block, and a ﬁeld vB for the large lower block. To approximate the posterior odds ratio in Equation 7 we compute rough approximations of f (v1 )dv1 and f (v1 , v2 )dv1 dv2 by summing over a ﬁnite space of velocity ﬁelds. As described in the supporting material, we consider all ﬁelds that can be built from objects with 5 possible shapes, 900 possible starting locations, and 10 possible trajectories. For computational tractability, we convert each continuous velocity ﬁeld to a discrete ﬁeld deﬁned over a space-time grid with 45 cells along each spatial dimension and 21 cells along the temporal dimension. Our results show that both models prefer the one-object hypothesis H1 when presented with scenes L1 and L2 (Figure 1b). Since there are many more two-object scenes than one-object scenes, any typical two-object interpretation is assigned lower prior probability than a typical one-object interpretation. This preference for simpler interpretations is a consequence of the Bayesian Occam’s razor. The baseline model makes the same kind of inference about scene U, and again prefers the one-object interpretation. Like infants, however, the smoothness model prefers the two-object interpretation of scene U. This model assigns low probability to a one-object interpretation where adjacent points on the object have very different velocities, and this preference for smooth motion is strong enough to overcome the simplicity preference that makes the difference when interpreting the other two scenes. Other experiments from the developmental literature have produced results consistent with the principle of spatial smoothness. For example, 3.5-month olds are surprised when a tall object is fully hidden behind a short screen, 4 month olds are surprised when a large object appears to pass through a small slot, and 4.5-month olds expect a swinging screen to be interrupted when an object is placed in its path [1, 2]. All three inferences appear to rely on the expectation that objects tend not to shrink or to compress like foam rubber. Many of these experiments are consistent with an account that simply rules out non-rigid motion instead of introducing a graded preference for spatial smoothness. Biological motions, however, are typically non-rigid, and experiments suggest that infants can track and make inferences about objects that follow non-rigid trajectories [14]. Findings like these call for a theory like ours that incorporates a preference for rigid motion, but recognizes that non-rigid motions are possible. 3 Empirical ﬁndings: temporal smoothness We now turn to the principle of temporal smoothness (S2) and discuss some of the experimental evidence that bears on this principle. Some researchers suggest that a closely related principle (inertia) is slow to develop, but we argue that expectations about temporal smoothness are needed to capture inferences made before the age of 4 months. Baillargeon and DeVos [15] describe one relevant experiment that explores inferences about moving objects and obstacles. During habituation, 3.5-month-old infants saw a car pass behind an occluder and emerge from the other side (habituation stimulus H in Figure 2a). An obstacle was then placed in the direct path of the car (unlikely scenes U1 and U2) or beside this direct path (likely scene L), and the infants again saw the car pass behind the occluder and emerge from the other side. Looking L U1 U2 p(L) p(U 1) ” log “ p(L) p(U 2) ” 400 H “ 600 a) log log “ pH (L) pH (U 1) ” log “ pH (L) pH (U 2) ” b) 200 X X X baseline 0 smoothness Figure 2: (a) Stimuli inspired by the experiments of [15]. The habituation stimulus H shows a block passing behind a barrier and emerging on the other side. After habituation, a new block is added either out of the direct path of the ﬁrst block (L) or directly in the path of the ﬁrst block (U1 and U2). In U1, the ﬁrst block leaps over the second block, and in U2 the second block hops so that the ﬁrst block can pass underneath. (b) Relative probabilities of scenes L, U1 and U2 according to two models. The baseline model ﬁnds all three scenes equally likely a priori, and considers L and U2 equally likely after habituation. The smoothness model considers L more likely than the other scenes both before and after habituation. a) H1 H2 L U b) ” log p(L) p(U ) 300 log “ pH1 (L) pH1 (U ) ” 200 c) “ log “ pH2 (L) pH2 (U ) ” 100 0 −100 X X baseline smoothness Figure 3: (a) Stimuli inspired by the experiments of Spelke et al. [16]. (b) Model predictions. After habituation to H1, the smoothness model assigns roughly equal probabilities to L and U. After habituation to H2, the model considers L more likely. (c) A stronger test of the inertia principle. Now the best interpretation of stimulus U involves multiple changes of direction. time measurements suggested that the infants were more surprised to see the car emerge when the obstacle lay within the direct path of the car. This result is consistent with the principle of temporal smoothness, which suggests that infants expected the car to maintain a straight-line trajectory, and the obstacle to remain stationary. We compared the smoothness model and the baseline model on a schematic version of this task. To model this experiment, we again assume that the infant’s perceptual system has recovered a veridical velocity ﬁeld, but now we must allow for occlusion. An ideal observer approach that treats a two dimensional scene as a projection of a three dimensional world can represent the occluder as an object in its own right. Here, however, we continue to work with a two dimensional world, and treat the occluded parts of the scene as missing data. An ideal observer approach should integrate over all possible values of the missing data, but for computational simplicity we approximate this approach by considering only one or two high-probability interpretations of each occluded scene. We also need to account for habituation, and for cases where the habituation stimulus includes occlusion. We assume that an ideal observer computes a habituation ﬁeld vH , or the velocity ﬁeld with maximum posterior probability given the habituation stimulus. In Figure 2a, the inferred habituation ﬁeld vH speciﬁes a trajectory where the block moves smoothly from the left to the right of the scene. We now assume that the observer expects subsequent velocity ﬁelds to be similar to vH . Formally, we use a product-of-experts approach to deﬁne a post-habituation distribution on velocity ﬁelds: pH (v) ∝ p(v)p(v|vH ) (8) The ﬁrst expert p(v) uses the prior distribution in Equation 6, and the second expert p(v|vH ) assumes that ﬁeld v is drawn from a Gaussian distribution centered on vH . Intuitively, after habituation to vH the second expert expects that subsequent velocity ﬁelds will be similar to vH . More information about this model of habituation is provided in the supporting material. Given these assumptions, the black and dark gray bars in Figure 2 indicate relative a priori probabilities for scenes L, U1 and U2. The baseline model considers all three scenes equally probable, but the smoothness model prefers L. After habituation, the baseline model is still unable to account for the behavioral data, since it considers scenes L and U2 to be equally probable. The smoothness model, however, continues to prefer L. We previously mentioned three consequences of the principle of temporal smoothness: stationary objects tend to remain stationary, moving objects tend to keep moving, and moving objects tend to maintain a steady trajectory. The “car and obstacle” task addresses the ﬁrst and third of these proposals, but other tasks provide support for the second. Many authors have studied settings where one moving object comes to a stop, and a second object starts to move [17]. Compared to the case where the ﬁrst object collides with the second, infants appear to be surprised by the “no-contact” case where the two objects never touch. This ﬁnding is consistent with the temporal smoothness principle, which predicts that infants expect the ﬁrst object to continue moving until forced to stop, and expect the second object to remain stationary until forced to start. Other experiments [18] provide support for the principle of temporal smoothness, but there are also studies that appear inconsistent with this principle. In one of these studies [16], infants are initially habituated to a block that moves from one corner of an enclosure to another (H1 in Figure 3a). After habituation, infants see a block that begins from a different corner, and now the occluder is removed to reveal the block in a location consistent with a straight-line trajectory (L) or in a location that matches the ﬁnal resting place during the habituation phase (U). Looking times suggest that infants aged 4-12 months are no more surprised by the inertia-violating outcome (U) than the inertia-consistent outcome (L). The smoothness model, however, can account for this ﬁnding. The outcome in U is contrary to temporal smoothness but consistent with habituation, and the tradeoff between these factors leads the model to assign roughly the same probability to scenes L and U (Figure 3b). Only one of the inertia experiments described by Spelke et al. [16] and Spelke et al. [1] avoids this tradeoff between habituation and smoothness. This experiment considers a case where the habituation stimulus (H2 in Figure 3a) is equally similar to the two test stimuli. The results suggest that 8 month olds are now surprised by the inertia-violating outcome, and the predictions of our model are consistent with this ﬁnding (Figure 3b). 4 and 6 month olds, however, continue to look equally at the two outcomes. Note, however, that the trajectories in Figure 3 include at most one inﬂection point. Experiments that consider trajectories with many inﬂection points can provide a more powerful way of exploring whether 4 month olds have expectations about temporal smoothness. One possible experiment is sketched in Figure 3c. The task is very similar to the task in Figure 3a, except that a barrier is added after habituation. In order for the block to end up in the same location as before, it must now follow a tortuous path around the barrier (U). Based on the principle of temporal smoothness, we predict that 4-month-olds will be more surprised to see the outcome in stimulus U than the outcome in stimulus L. This experimental design is appealing in part because previous work shows that infants are surprised by a case similar to U where the barrier extends all the way from one wall to the other [16], and our proposed experiment is a minor variant of this task. Although there is room for debate about the status of temporal smoothness, we presented two reasons to revisit the conclusion that this principle develops relatively late. First, some version of this principle seems necessary to account for experiments like the car and obstacle experiment in Figure 2. Second, most of the inertia experiments that produced null results use a habituation stimulus which may have prevented infants from revealing their default expectations, and the one experiment that escapes this objection considers a relatively minor violation of temporal smoothness. Additional experiments are needed to explore this principle, but we predict that the inertia principle will turn out to be yet another example of knowledge that is available earlier than researchers once thought. 4 Discussion and Conclusion We argued that characterizations of infant knowledge should include room for probabilistic expectations, and that probabilistic expectations about spatial and temporal smoothness appear to play a role in infant object perception. To support these claims we described an ideal observer model that includes both categorical (C1 through C5) and probabilistic principles (S1 and S2), and demonstrated that the categorical principles alone are insufﬁcient to account for several experimental ﬁndings. Our two probabilistic principles are related to principles (rigidity and inertia) that have previously been described as categorical principles. Although rigidity and inertia appear to play a role in some early inferences, formulating these principles as probabilistic expectations helps to explain how infants deal with non-rigid motion and violations of inertia. Our analysis focused on some of the many existing experiments in the developmental literature, but new experiments will be needed to explore our probabilistic approach in depth. Categorical versions of a given principle (e.g. rigidity) allow room for only two kinds of behavior depending on whether the principle is violated or not. Probabilistic principles can be violated to a greater or lesser extent, and our approach predicts that violations of different magnitude may lead to different behaviors. Future studies of rigidity and inertia can consider violations of these principles that range from mild (Figure 3a) to severe (Figure 3c), and can explore whether infants respond to these violations differently. Future work should also consider whether the categorical principles we described (C1 through C5) are better characterized as probabilistic expectations. In particular, future studies can explore whether young infants consider large violations of cohesion (C5) or spatial continuity (C2) more surprising than smaller violations of these principles. Although we did not focus on learning, our approach allows us to begin thinking formally about how principles of object perception might be acquired. First, we can explore how parameters like the smoothness parameters in our model (λspace and λtime ) might be tuned by experience. Second, we can use statistical model selection to explore transitions between different sets of principles. For instance, if a learner begins with the baseline model we considered (principles C1–C6), we can explore which subsequent observations provide the strongest statistical evidence for smoothness principles S1 and S2, and how much of this evidence is required before an ideal learner would prefer our smoothness model over the baseline model. It is not yet clear which principles of object perception could be learned, but the ideal observer approach can help to resolve this question. References [1] E. S. Spelke, K. Breinlinger, J. Macomber, and K. Jacobson. Origins of knowledge. Psychological Review, 99:605–632, 1992. [2] R. Baillargeon, L. Kotovsky, and A. Needham. The acquisition of physical knowledge in infancy. In D. Sperber, D. Premack, and A. J. Premack, editors, Causal Cognition: A multidisciplinary debate, pages 79–116. Clarendon Press, Oxford, 1995. [3] E. S. Spelke. Principles of object perception. Cognitive Science, 14:29–56, 1990. [4] E. Spelke. Initial knowledge: six suggestions. Cognition, 50:431–445, 1994. [5] D. Mareschal and S. P. Johnson. Learning to perceive object unity: a connectionist account. Developmental Science, 5:151–172, 2002. [6] D. Kersten and A. Yuille. Bayesian models of object perception. Current opinion in Neurobiology, 13: 150–158, 2003. [7] Y. Weiss and E. H. Adelson. Slow and smooth: a Bayesian theory for the combination of local motion signals in human vision. Technical Report A.I Memo No. 1624, MIT, 1998. [8] A. L. Yuille and N. M. Grzywacz. A mathematical analysis of the motion coherence theory. International Journal of Computer Vision, 3:155–175, 1989. [9] W. S. Geisler. Physical limits of acuity and hyperacuity. Journal of the Optical Society of America, 1(7): 775–782, 1984. [10] M. S. Banks and E. Shannon. Spatial and chromatic visual efﬁciency in human neonates. In Visual perception and cognition in infancy, pages 1–46. Lawrence Erlbaum Associates, Hillsdale, NJ, 1993. [11] R. Baillargeon. Innate ideas revisited: for a principle of persistence in infants’ physical reasoning. Perspectives on Psychological Science, 3(3):2–13, 2008. [12] R. Kestenbaum, N. Termine, and E. S. Spelke. Perception of objects and object boundaries by threemonth-old infants. British Journal of Developmental Psychology, 5:367–383, 1987. [13] E. S. Spelke, C. von Hofsten, and R. Kestenbaum. Object perception and object-directed reaching in infancy: interaction of spatial and kinetic information for object boundaries. Developmental Psychology, 25:185–196, 1989. [14] G. Huntley-Fenner, S. Carey, and A. Solimando. Objects are individuals but stuff doesn’t count: perceived rigidity and cohesiveness inﬂuence infants’ representations of small groups of discrete entities. Cognition, 85:203–221, 2002. [15] R. Baillargeon and J. DeVos. Object permanence in young infants: further evidence. Child Development, 61(6):1227–1246, 1991. [16] E. S. Spelke, G. Katz, S. E. Purcell, S. M. Ehrlich, and K. Breinlinger. Early knowledge of object motion: continuity and inertia. Cognition, 51:131–176, 1994. [17] L. Kotovsky and R. Baillargeon. Reasoning about collisions involving inert objects in 7.5-month-old infants. Developmental Science, 3(3):344–359, 2000. [18] T. Wilcox and A. Schweinle. Infants’ use of speed information to individuate objects in occlusion events. Infant Behavior and Development, 26:253–282, 2003.</p><p>6 0.44363487 <a title="136-lsi-6" href="./nips-2008-Bayesian_Synchronous_Grammar_Induction.html">35 nips-2008-Bayesian Synchronous Grammar Induction</a></p>
<p>7 0.39422852 <a title="136-lsi-7" href="./nips-2008-Tracking_Changing_Stimuli_in_Continuous_Attractor_Neural_Networks.html">240 nips-2008-Tracking Changing Stimuli in Continuous Attractor Neural Networks</a></p>
<p>8 0.37411419 <a title="136-lsi-8" href="./nips-2008-Learning_a_discriminative_hidden_part_model_for_human_action_recognition.html">119 nips-2008-Learning a discriminative hidden part model for human action recognition</a></p>
<p>9 0.32377139 <a title="136-lsi-9" href="./nips-2008-Dynamic_visual_attention%3A_searching_for_coding_length_increments.html">66 nips-2008-Dynamic visual attention: searching for coding length increments</a></p>
<p>10 0.28017679 <a title="136-lsi-10" href="./nips-2008-Non-stationary_dynamic_Bayesian_networks.html">152 nips-2008-Non-stationary dynamic Bayesian networks</a></p>
<p>11 0.26374039 <a title="136-lsi-11" href="./nips-2008-A_computational_model_of_hippocampal_function_in_trace_conditioning.html">7 nips-2008-A computational model of hippocampal function in trace conditioning</a></p>
<p>12 0.23479758 <a title="136-lsi-12" href="./nips-2008-Logistic_Normal_Priors_for_Unsupervised_Probabilistic_Grammar_Induction.html">127 nips-2008-Logistic Normal Priors for Unsupervised Probabilistic Grammar Induction</a></p>
<p>13 0.22699732 <a title="136-lsi-13" href="./nips-2008-The_Gaussian_Process_Density_Sampler.html">233 nips-2008-The Gaussian Process Density Sampler</a></p>
<p>14 0.2154461 <a title="136-lsi-14" href="./nips-2008-The_Recurrent_Temporal_Restricted_Boltzmann_Machine.html">237 nips-2008-The Recurrent Temporal Restricted Boltzmann Machine</a></p>
<p>15 0.21465115 <a title="136-lsi-15" href="./nips-2008-Estimating_vector_fields_using_sparse_basis_field_expansions.html">75 nips-2008-Estimating vector fields using sparse basis field expansions</a></p>
<p>16 0.21445715 <a title="136-lsi-16" href="./nips-2008-Human_Active_Learning.html">101 nips-2008-Human Active Learning</a></p>
<p>17 0.20681494 <a title="136-lsi-17" href="./nips-2008-A_mixture_model_for_the_evolution_of_gene_expression_in_non-homogeneous_datasets.html">9 nips-2008-A mixture model for the evolution of gene expression in non-homogeneous datasets</a></p>
<p>18 0.205386 <a title="136-lsi-18" href="./nips-2008-Interpreting_the_neural_code_with_Formal_Concept_Analysis.html">109 nips-2008-Interpreting the neural code with Formal Concept Analysis</a></p>
<p>19 0.19649041 <a title="136-lsi-19" href="./nips-2008-Estimating_Robust_Query_Models_with_Convex_Optimization.html">73 nips-2008-Estimating Robust Query Models with Convex Optimization</a></p>
<p>20 0.19512504 <a title="136-lsi-20" href="./nips-2008-Load_and_Attentional_Bayes.html">124 nips-2008-Load and Attentional Bayes</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2008_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(6, 0.038), (7, 0.082), (12, 0.025), (15, 0.014), (28, 0.118), (57, 0.074), (59, 0.061), (63, 0.014), (77, 0.024), (83, 0.053), (94, 0.386)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.6700052 <a title="136-lda-1" href="./nips-2008-Model_selection_and_velocity_estimation_using_novel_priors_for_motion_patterns.html">136 nips-2008-Model selection and velocity estimation using novel priors for motion patterns</a></p>
<p>Author: Shuang Wu, Hongjing Lu, Alan L. Yuille</p><p>Abstract: Psychophysical experiments show that humans are better at perceiving rotation and expansion than translation. These ﬁndings are inconsistent with standard models of motion integration which predict best performance for translation [6]. To explain this discrepancy, our theory formulates motion perception at two levels of inference: we ﬁrst perform model selection between the competing models (e.g. translation, rotation, and expansion) and then estimate the velocity using the selected model. We deﬁne novel prior models for smooth rotation and expansion using techniques similar to those in the slow-and-smooth model [17] (e.g. Green functions of differential operators). The theory gives good agreement with the trends observed in human experiments. 1</p><p>2 0.61298496 <a title="136-lda-2" href="./nips-2008-Sparse_Signal_Recovery_Using_Markov_Random_Fields.html">215 nips-2008-Sparse Signal Recovery Using Markov Random Fields</a></p>
<p>Author: Volkan Cevher, Marco F. Duarte, Chinmay Hegde, Richard Baraniuk</p><p>Abstract: Compressive Sensing (CS) combines sampling and compression into a single subNyquist linear measurement process for sparse and compressible signals. In this paper, we extend the theory of CS to include signals that are concisely represented in terms of a graphical model. In particular, we use Markov Random Fields (MRFs) to represent sparse signals whose nonzero coefﬁcients are clustered. Our new model-based recovery algorithm, dubbed Lattice Matching Pursuit (LaMP), stably recovers MRF-modeled signals using many fewer measurements and computations than the current state-of-the-art algorithms.</p><p>3 0.58182842 <a title="136-lda-3" href="./nips-2008-Designing_neurophysiology_experiments_to_optimally_constrain_receptive_field_models_along_parametric_submanifolds.html">60 nips-2008-Designing neurophysiology experiments to optimally constrain receptive field models along parametric submanifolds</a></p>
<p>Author: Jeremy Lewi, Robert Butera, David M. Schneider, Sarah Woolley, Liam Paninski</p><p>Abstract: Sequential optimal design methods hold great promise for improving the efﬁciency of neurophysiology experiments. However, previous methods for optimal experimental design have incorporated only weak prior information about the underlying neural system (e.g., the sparseness or smoothness of the receptive ﬁeld). Here we describe how to use stronger prior information, in the form of parametric models of the receptive ﬁeld, in order to construct optimal stimuli and further improve the efﬁciency of our experiments. For example, if we believe that the receptive ﬁeld is well-approximated by a Gabor function, then our method constructs stimuli that optimally constrain the Gabor parameters (orientation, spatial frequency, etc.) using as few experimental trials as possible. More generally, we may believe a priori that the receptive ﬁeld lies near a known sub-manifold of the full parameter space; in this case, our method chooses stimuli in order to reduce the uncertainty along the tangent space of this sub-manifold as rapidly as possible. Applications to simulated and real data indicate that these methods may in many cases improve the experimental efﬁciency. 1</p><p>4 0.55840242 <a title="136-lda-4" href="./nips-2008-Algorithms_for_Infinitely_Many-Armed_Bandits.html">17 nips-2008-Algorithms for Infinitely Many-Armed Bandits</a></p>
<p>Author: Yizao Wang, Jean-yves Audibert, Rémi Munos</p><p>Abstract: We consider multi-armed bandit problems where the number of arms is larger than the possible number of experiments. We make a stochastic assumption on the mean-reward of a new selected arm which characterizes its probability of being a near-optimal arm. Our assumption is weaker than in previous works. We describe algorithms based on upper-conﬁdence-bounds applied to a restricted set of randomly selected arms and provide upper-bounds on the resulting expected regret. We also derive a lower-bound which matches (up to a logarithmic factor) the upper-bound in some cases. 1</p><p>5 0.40704435 <a title="136-lda-5" href="./nips-2008-Dimensionality_Reduction_for_Data_in_Multiple_Feature_Representations.html">63 nips-2008-Dimensionality Reduction for Data in Multiple Feature Representations</a></p>
<p>Author: Yen-yu Lin, Tyng-luh Liu, Chiou-shann Fuh</p><p>Abstract: In solving complex visual learning tasks, adopting multiple descriptors to more precisely characterize the data has been a feasible way for improving performance. These representations are typically high dimensional and assume diverse forms. Thus ﬁnding a way to transform them into a uniﬁed space of lower dimension generally facilitates the underlying tasks, such as object recognition or clustering. We describe an approach that incorporates multiple kernel learning with dimensionality reduction (MKL-DR). While the proposed framework is ﬂexible in simultaneously tackling data in various feature representations, the formulation itself is general in that it is established upon graph embedding. It follows that any dimensionality reduction techniques explainable by graph embedding can be generalized by our method to consider data in multiple feature representations.</p><p>6 0.4064467 <a title="136-lda-6" href="./nips-2008-Resolution_Limits_of_Sparse_Coding_in_High_Dimensions.html">198 nips-2008-Resolution Limits of Sparse Coding in High Dimensions</a></p>
<p>7 0.40632486 <a title="136-lda-7" href="./nips-2008-Dynamic_visual_attention%3A_searching_for_coding_length_increments.html">66 nips-2008-Dynamic visual attention: searching for coding length increments</a></p>
<p>8 0.405588 <a title="136-lda-8" href="./nips-2008-Learning_Hybrid_Models_for_Image_Annotation_with_Partially_Labeled_Data.html">116 nips-2008-Learning Hybrid Models for Image Annotation with Partially Labeled Data</a></p>
<p>9 0.40369204 <a title="136-lda-9" href="./nips-2008-Grouping_Contours_Via_a_Related_Image.html">95 nips-2008-Grouping Contours Via a Related Image</a></p>
<p>10 0.40361491 <a title="136-lda-10" href="./nips-2008-Temporal_Difference_Based_Actor_Critic_Learning_-_Convergence_and_Neural_Implementation.html">230 nips-2008-Temporal Difference Based Actor Critic Learning - Convergence and Neural Implementation</a></p>
<p>11 0.40352267 <a title="136-lda-11" href="./nips-2008-Efficient_Sampling_for_Gaussian_Process_Inference_using_Control_Variables.html">71 nips-2008-Efficient Sampling for Gaussian Process Inference using Control Variables</a></p>
<p>12 0.4027442 <a title="136-lda-12" href="./nips-2008-Regularized_Learning_with_Networks_of_Features.html">194 nips-2008-Regularized Learning with Networks of Features</a></p>
<p>13 0.4008069 <a title="136-lda-13" href="./nips-2008-Reducing_statistical_dependencies_in_natural_signals_using_radial_Gaussianization.html">192 nips-2008-Reducing statistical dependencies in natural signals using radial Gaussianization</a></p>
<p>14 0.40054759 <a title="136-lda-14" href="./nips-2008-Relative_Performance_Guarantees_for_Approximate_Inference_in_Latent_Dirichlet_Allocation.html">197 nips-2008-Relative Performance Guarantees for Approximate Inference in Latent Dirichlet Allocation</a></p>
<p>15 0.39994967 <a title="136-lda-15" href="./nips-2008-Exploring_Large_Feature_Spaces_with_Hierarchical_Multiple_Kernel_Learning.html">79 nips-2008-Exploring Large Feature Spaces with Hierarchical Multiple Kernel Learning</a></p>
<p>16 0.39984182 <a title="136-lda-16" href="./nips-2008-Stochastic_Relational_Models_for_Large-scale_Dyadic_Data_using_MCMC.html">221 nips-2008-Stochastic Relational Models for Large-scale Dyadic Data using MCMC</a></p>
<p>17 0.39888558 <a title="136-lda-17" href="./nips-2008-Phase_transitions_for_high-dimensional_joint_support_recovery.html">179 nips-2008-Phase transitions for high-dimensional joint support recovery</a></p>
<p>18 0.39887172 <a title="136-lda-18" href="./nips-2008-Partially_Observed_Maximum_Entropy_Discrimination_Markov_Networks.html">176 nips-2008-Partially Observed Maximum Entropy Discrimination Markov Networks</a></p>
<p>19 0.39865884 <a title="136-lda-19" href="./nips-2008-Artificial_Olfactory_Brain_for_Mixture_Identification.html">27 nips-2008-Artificial Olfactory Brain for Mixture Identification</a></p>
<p>20 0.398323 <a title="136-lda-20" href="./nips-2008-Learning_Transformational_Invariants_from_Natural_Movies.html">118 nips-2008-Learning Transformational Invariants from Natural Movies</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
