<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>163 nips-2008-On the Efficient Minimization of Classification Calibrated Surrogates</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-163" href="#">nips2008-163</a> knowledge-graph by maker-knowledge-mining</p><h1>163 nips-2008-On the Efficient Minimization of Classification Calibrated Surrogates</h1>
<br/><p>Source: <a title="nips-2008-163-pdf" href="http://papers.nips.cc/paper/3485-on-the-efficient-minimization-of-classification-calibrated-surrogates.pdf">pdf</a></p><p>Author: Richard Nock, Frank Nielsen</p><p>Abstract: Bartlett et al (2006) recently proved that a ground condition for convex surrogates, classiﬁcation calibration, ties up the minimization of the surrogates and classiﬁcation risks, and left as an important problem the algorithmic questions about the minimization of these surrogates. In this paper, we propose an algorithm which provably minimizes any classiﬁcation calibrated surrogate strictly convex and differentiable — a set whose losses span the exponential, logistic and squared losses —, with boosting-type guaranteed convergence rates under a weak learning assumption. A particular subclass of these surrogates, that we call balanced convex surrogates, has a key rationale that ties it to maximum likelihood estimation, zerosum games and the set of losses that satisfy some of the most common requirements for losses in supervised learning. We report experiments on more than 50 readily available domains of 11 ﬂavors of the algorithm, that shed light on new surrogates, and the potential of data dependent strategies to tune surrogates. 1</p><p>Reference: <a title="nips-2008-163-reference" href="../nips2008_reference/nips-2008-On_the_Efficient_Minimization_of_Classification_Calibrated_Surrogates_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ul', 0.547), ('wj', 0.35), ('bcl', 0.298), ('surrog', 0.279), ('bcs', 0.245), ('scl', 0.193), ('tj', 0.168), ('permiss', 0.158), ('wla', 0.158), ('loss', 0.146), ('scs', 0.138), ('legendr', 0.123), ('ht', 0.103), ('oi', 0.102), ('strictly', 0.1), ('boost', 0.09), ('adaboost', 0.087), ('logit', 0.084), ('lemm', 0.082), ('ls', 0.079)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="163-tfidf-1" href="./nips-2008-On_the_Efficient_Minimization_of_Classification_Calibrated_Surrogates.html">163 nips-2008-On the Efficient Minimization of Classification Calibrated Surrogates</a></p>
<p>2 0.13525695 <a title="163-tfidf-2" href="./nips-2008-On_the_Design_of_Loss_Functions_for_Classification%3A_theory%2C_robustness_to_outliers%2C_and_SavageBoost.html">162 nips-2008-On the Design of Loss Functions for Classification: theory, robustness to outliers, and SavageBoost</a></p>
<p>3 0.12641102 <a title="163-tfidf-3" href="./nips-2008-Multi-stage_Convex_Relaxation_for_Learning_with_Sparse_Regularization.html">145 nips-2008-Multi-stage Convex Relaxation for Learning with Sparse Regularization</a></p>
<p>4 0.097876608 <a title="163-tfidf-4" href="./nips-2008-Support_Vector_Machines_with_a_Reject_Option.html">228 nips-2008-Support Vector Machines with a Reject Option</a></p>
<p>5 0.097364038 <a title="163-tfidf-5" href="./nips-2008-Variational_Mixture_of_Gaussian_Process_Experts.html">249 nips-2008-Variational Mixture of Gaussian Process Experts</a></p>
<p>6 0.094501436 <a title="163-tfidf-6" href="./nips-2008-On_the_Complexity_of_Linear_Prediction%3A_Risk_Bounds%2C_Margin_Bounds%2C_and_Regularization.html">161 nips-2008-On the Complexity of Linear Prediction: Risk Bounds, Margin Bounds, and Regularization</a></p>
<p>7 0.093498774 <a title="163-tfidf-7" href="./nips-2008-Weighted_Sums_of_Random_Kitchen_Sinks%3A_Replacing_minimization_with_randomization_in_learning.html">250 nips-2008-Weighted Sums of Random Kitchen Sinks: Replacing minimization with randomization in learning</a></p>
<p>8 0.086793236 <a title="163-tfidf-8" href="./nips-2008-Differentiable_Sparse_Coding.html">62 nips-2008-Differentiable Sparse Coding</a></p>
<p>9 0.083629966 <a title="163-tfidf-9" href="./nips-2008-Tighter_Bounds_for_Structured_Estimation.html">239 nips-2008-Tighter Bounds for Structured Estimation</a></p>
<p>10 0.077724405 <a title="163-tfidf-10" href="./nips-2008-Adaptive_Martingale_Boosting.html">15 nips-2008-Adaptive Martingale Boosting</a></p>
<p>11 0.074961856 <a title="163-tfidf-11" href="./nips-2008-Learning_Hybrid_Models_for_Image_Annotation_with_Partially_Labeled_Data.html">116 nips-2008-Learning Hybrid Models for Image Annotation with Partially Labeled Data</a></p>
<p>12 0.072888762 <a title="163-tfidf-12" href="./nips-2008-Estimating_Robust_Query_Models_with_Convex_Optimization.html">73 nips-2008-Estimating Robust Query Models with Convex Optimization</a></p>
<p>13 0.072260387 <a title="163-tfidf-13" href="./nips-2008-MCBoost%3A_Multiple_Classifier_Boosting_for_Perceptual_Co-clustering_of_Images_and_Visual_Features.html">130 nips-2008-MCBoost: Multiple Classifier Boosting for Perceptual Co-clustering of Images and Visual Features</a></p>
<p>14 0.062969878 <a title="163-tfidf-14" href="./nips-2008-Mind_the_Duality_Gap%3A_Logarithmic_regret_algorithms_for_online_optimization.html">133 nips-2008-Mind the Duality Gap: Logarithmic regret algorithms for online optimization</a></p>
<p>15 0.062818795 <a title="163-tfidf-15" href="./nips-2008-The_Recurrent_Temporal_Restricted_Boltzmann_Machine.html">237 nips-2008-The Recurrent Temporal Restricted Boltzmann Machine</a></p>
<p>16 0.060612436 <a title="163-tfidf-16" href="./nips-2008-Domain_Adaptation_with_Multiple_Sources.html">65 nips-2008-Domain Adaptation with Multiple Sources</a></p>
<p>17 0.056549337 <a title="163-tfidf-17" href="./nips-2008-Estimating_vector_fields_using_sparse_basis_field_expansions.html">75 nips-2008-Estimating vector fields using sparse basis field expansions</a></p>
<p>18 0.055381067 <a title="163-tfidf-18" href="./nips-2008-Fast_Rates_for_Regularized_Objectives.html">85 nips-2008-Fast Rates for Regularized Objectives</a></p>
<p>19 0.054200858 <a title="163-tfidf-19" href="./nips-2008-Regularized_Learning_with_Networks_of_Features.html">194 nips-2008-Regularized Learning with Networks of Features</a></p>
<p>20 0.052605119 <a title="163-tfidf-20" href="./nips-2008-Multi-Level_Active_Prediction_of_Useful_Image_Annotations_for_Recognition.html">142 nips-2008-Multi-Level Active Prediction of Useful Image Annotations for Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2008_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.146), (1, 0.059), (2, 0.072), (3, -0.05), (4, -0.009), (5, -0.038), (6, -0.042), (7, 0.064), (8, -0.063), (9, -0.04), (10, -0.014), (11, 0.101), (12, -0.035), (13, 0.039), (14, -0.004), (15, -0.017), (16, 0.028), (17, 0.037), (18, -0.065), (19, 0.088), (20, -0.005), (21, -0.095), (22, -0.1), (23, 0.035), (24, -0.026), (25, -0.091), (26, 0.016), (27, -0.038), (28, 0.005), (29, -0.041), (30, 0.025), (31, 0.074), (32, 0.058), (33, -0.136), (34, -0.065), (35, 0.059), (36, -0.089), (37, -0.045), (38, 0.128), (39, 0.056), (40, 0.001), (41, 0.073), (42, 0.007), (43, -0.05), (44, -0.006), (45, 0.232), (46, 0.025), (47, -0.056), (48, 0.068), (49, -0.04)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91815436 <a title="163-lsi-1" href="./nips-2008-On_the_Efficient_Minimization_of_Classification_Calibrated_Surrogates.html">163 nips-2008-On the Efficient Minimization of Classification Calibrated Surrogates</a></p>
<p>2 0.82202077 <a title="163-lsi-2" href="./nips-2008-On_the_Design_of_Loss_Functions_for_Classification%3A_theory%2C_robustness_to_outliers%2C_and_SavageBoost.html">162 nips-2008-On the Design of Loss Functions for Classification: theory, robustness to outliers, and SavageBoost</a></p>
<p>3 0.63411921 <a title="163-lsi-3" href="./nips-2008-Tighter_Bounds_for_Structured_Estimation.html">239 nips-2008-Tighter Bounds for Structured Estimation</a></p>
<p>4 0.59223992 <a title="163-lsi-4" href="./nips-2008-Fast_Rates_for_Regularized_Objectives.html">85 nips-2008-Fast Rates for Regularized Objectives</a></p>
<p>5 0.54522365 <a title="163-lsi-5" href="./nips-2008-Support_Vector_Machines_with_a_Reject_Option.html">228 nips-2008-Support Vector Machines with a Reject Option</a></p>
<p>6 0.51480865 <a title="163-lsi-6" href="./nips-2008-Privacy-preserving_logistic_regression.html">185 nips-2008-Privacy-preserving logistic regression</a></p>
<p>7 0.51285797 <a title="163-lsi-7" href="./nips-2008-Weighted_Sums_of_Random_Kitchen_Sinks%3A_Replacing_minimization_with_randomization_in_learning.html">250 nips-2008-Weighted Sums of Random Kitchen Sinks: Replacing minimization with randomization in learning</a></p>
<p>8 0.49447027 <a title="163-lsi-8" href="./nips-2008-Multi-stage_Convex_Relaxation_for_Learning_with_Sparse_Regularization.html">145 nips-2008-Multi-stage Convex Relaxation for Learning with Sparse Regularization</a></p>
<p>9 0.48545852 <a title="163-lsi-9" href="./nips-2008-Adaptive_Martingale_Boosting.html">15 nips-2008-Adaptive Martingale Boosting</a></p>
<p>10 0.46732402 <a title="163-lsi-10" href="./nips-2008-On_the_Complexity_of_Linear_Prediction%3A_Risk_Bounds%2C_Margin_Bounds%2C_and_Regularization.html">161 nips-2008-On the Complexity of Linear Prediction: Risk Bounds, Margin Bounds, and Regularization</a></p>
<p>11 0.43507728 <a title="163-lsi-11" href="./nips-2008-MCBoost%3A_Multiple_Classifier_Boosting_for_Perceptual_Co-clustering_of_Images_and_Visual_Features.html">130 nips-2008-MCBoost: Multiple Classifier Boosting for Perceptual Co-clustering of Images and Visual Features</a></p>
<p>12 0.40147877 <a title="163-lsi-12" href="./nips-2008-Adaptive_Forward-Backward_Greedy_Algorithm_for_Sparse_Learning_with_Linear_Models.html">14 nips-2008-Adaptive Forward-Backward Greedy Algorithm for Sparse Learning with Linear Models</a></p>
<p>13 0.39001435 <a title="163-lsi-13" href="./nips-2008-Variational_Mixture_of_Gaussian_Process_Experts.html">249 nips-2008-Variational Mixture of Gaussian Process Experts</a></p>
<p>14 0.38941613 <a title="163-lsi-14" href="./nips-2008-PSDBoost%3A_Matrix-Generation_Linear_Programming_for_Positive_Semidefinite_Matrices_Learning.html">175 nips-2008-PSDBoost: Matrix-Generation Linear Programming for Positive Semidefinite Matrices Learning</a></p>
<p>15 0.38358375 <a title="163-lsi-15" href="./nips-2008-Mind_the_Duality_Gap%3A_Logarithmic_regret_algorithms_for_online_optimization.html">133 nips-2008-Mind the Duality Gap: Logarithmic regret algorithms for online optimization</a></p>
<p>16 0.3824144 <a title="163-lsi-16" href="./nips-2008-A_Transductive_Bound_for_the_Voted_Classifier_with_an_Application_to_Semi-supervised_Learning.html">5 nips-2008-A Transductive Bound for the Voted Classifier with an Application to Semi-supervised Learning</a></p>
<p>17 0.34967342 <a title="163-lsi-17" href="./nips-2008-Optimization_on_a_Budget%3A_A_Reinforcement_Learning_Approach.html">173 nips-2008-Optimization on a Budget: A Reinforcement Learning Approach</a></p>
<p>18 0.34290692 <a title="163-lsi-18" href="./nips-2008-Partially_Observed_Maximum_Entropy_Discrimination_Markov_Networks.html">176 nips-2008-Partially Observed Maximum Entropy Discrimination Markov Networks</a></p>
<p>19 0.33693191 <a title="163-lsi-19" href="./nips-2008-Localized_Sliced_Inverse_Regression.html">126 nips-2008-Localized Sliced Inverse Regression</a></p>
<p>20 0.32985222 <a title="163-lsi-20" href="./nips-2008-Multi-Level_Active_Prediction_of_Useful_Image_Annotations_for_Recognition.html">142 nips-2008-Multi-Level Active Prediction of Useful Image Annotations for Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2008_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.02), (25, 0.024), (30, 0.115), (32, 0.376), (38, 0.036), (40, 0.037), (60, 0.02), (63, 0.076), (64, 0.086), (71, 0.092)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.69282007 <a title="163-lda-1" href="./nips-2008-On_the_Efficient_Minimization_of_Classification_Calibrated_Surrogates.html">163 nips-2008-On the Efficient Minimization of Classification Calibrated Surrogates</a></p>
<p>2 0.45253021 <a title="163-lda-2" href="./nips-2008-Mind_the_Duality_Gap%3A_Logarithmic_regret_algorithms_for_online_optimization.html">133 nips-2008-Mind the Duality Gap: Logarithmic regret algorithms for online optimization</a></p>
<p>3 0.44740015 <a title="163-lda-3" href="./nips-2008-Fast_Rates_for_Regularized_Objectives.html">85 nips-2008-Fast Rates for Regularized Objectives</a></p>
<p>4 0.4457626 <a title="163-lda-4" href="./nips-2008-On_the_Complexity_of_Linear_Prediction%3A_Risk_Bounds%2C_Margin_Bounds%2C_and_Regularization.html">161 nips-2008-On the Complexity of Linear Prediction: Risk Bounds, Margin Bounds, and Regularization</a></p>
<p>5 0.44537693 <a title="163-lda-5" href="./nips-2008-From_Online_to_Batch_Learning_with_Cutoff-Averaging.html">88 nips-2008-From Online to Batch Learning with Cutoff-Averaging</a></p>
<p>6 0.44425374 <a title="163-lda-6" href="./nips-2008-MCBoost%3A_Multiple_Classifier_Boosting_for_Perceptual_Co-clustering_of_Images_and_Visual_Features.html">130 nips-2008-MCBoost: Multiple Classifier Boosting for Perceptual Co-clustering of Images and Visual Features</a></p>
<p>7 0.44262156 <a title="163-lda-7" href="./nips-2008-Tighter_Bounds_for_Structured_Estimation.html">239 nips-2008-Tighter Bounds for Structured Estimation</a></p>
<p>8 0.44133165 <a title="163-lda-8" href="./nips-2008-Adaptive_Forward-Backward_Greedy_Algorithm_for_Sparse_Learning_with_Linear_Models.html">14 nips-2008-Adaptive Forward-Backward Greedy Algorithm for Sparse Learning with Linear Models</a></p>
<p>9 0.44106039 <a title="163-lda-9" href="./nips-2008-On_the_Design_of_Loss_Functions_for_Classification%3A_theory%2C_robustness_to_outliers%2C_and_SavageBoost.html">162 nips-2008-On the Design of Loss Functions for Classification: theory, robustness to outliers, and SavageBoost</a></p>
<p>10 0.44105381 <a title="163-lda-10" href="./nips-2008-Unlabeled_data%3A_Now_it_helps%2C_now_it_doesn%27t.html">245 nips-2008-Unlabeled data: Now it helps, now it doesn't</a></p>
<p>11 0.4395768 <a title="163-lda-11" href="./nips-2008-Rademacher_Complexity_Bounds_for_Non-I.I.D._Processes.html">189 nips-2008-Rademacher Complexity Bounds for Non-I.I.D. Processes</a></p>
<p>12 0.43873575 <a title="163-lda-12" href="./nips-2008-On_the_Reliability_of_Clustering_Stability_in_the_Large_Sample_Regime.html">165 nips-2008-On the Reliability of Clustering Stability in the Large Sample Regime</a></p>
<p>13 0.43808919 <a title="163-lda-13" href="./nips-2008-Bounds_on_marginal_probability_distributions.html">40 nips-2008-Bounds on marginal probability distributions</a></p>
<p>14 0.43699509 <a title="163-lda-14" href="./nips-2008-Online_Optimization_in_X-Armed_Bandits.html">170 nips-2008-Online Optimization in X-Armed Bandits</a></p>
<p>15 0.43689311 <a title="163-lda-15" href="./nips-2008-Hebbian_Learning_of_Bayes_Optimal_Decisions.html">96 nips-2008-Hebbian Learning of Bayes Optimal Decisions</a></p>
<p>16 0.4358288 <a title="163-lda-16" href="./nips-2008-Support_Vector_Machines_with_a_Reject_Option.html">228 nips-2008-Support Vector Machines with a Reject Option</a></p>
<p>17 0.43582034 <a title="163-lda-17" href="./nips-2008-On_the_Generalization_Ability_of_Online_Strongly_Convex_Programming_Algorithms.html">164 nips-2008-On the Generalization Ability of Online Strongly Convex Programming Algorithms</a></p>
<p>18 0.43523189 <a title="163-lda-18" href="./nips-2008-Privacy-preserving_logistic_regression.html">185 nips-2008-Privacy-preserving logistic regression</a></p>
<p>19 0.43514857 <a title="163-lda-19" href="./nips-2008-Fitted_Q-iteration_by_Advantage_Weighted_Regression.html">87 nips-2008-Fitted Q-iteration by Advantage Weighted Regression</a></p>
<p>20 0.43500975 <a title="163-lda-20" href="./nips-2008-Online_Prediction_on_Large_Diameter_Graphs.html">171 nips-2008-Online Prediction on Large Diameter Graphs</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
