<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>228 nips-2008-Support Vector Machines with a Reject Option</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-228" href="#">nips2008-228</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>228 nips-2008-Support Vector Machines with a Reject Option</h1>
<br/><p>Source: <a title="nips-2008-228-pdf" href="http://papers.nips.cc/paper/3594-support-vector-machines-with-a-reject-option.pdf">pdf</a></p><p>Author: Yves Grandvalet, Alain Rakotomamonjy, Joseph Keshet, Stéphane Canu</p><p>Abstract: We consider the problem of binary classiﬁcation where the classiﬁer may abstain instead of classifying each observation. The Bayes decision rule for this setup, known as Chow’s rule, is deﬁned by two thresholds on posterior probabilities. From simple desiderata, namely the consistency and the sparsity of the classiﬁer, we derive the double hinge loss function that focuses on estimating conditional probabilities only in the vicinity of the threshold points of the optimal decision rule. We show that, for suitable kernel machines, our approach is universally consistent. We cast the problem of minimizing the double hinge loss as a quadratic program akin to the standard SVM optimization problem and propose an active set method to solve it efﬁciently. We ﬁnally provide preliminary experimental results illustrating the interest of our constructive approach to devising loss functions. 1</p><p>Reference: <a title="nips-2008-228-reference" href="../nips2008_reference/nips-2008-Support_Vector_Machines_with_a_Reject_Option_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('reject', 0.529), ('hing', 0.372), ('doubl', 0.251), ('wegkamp', 0.246), ('loss', 0.215), ('decid', 0.15), ('bartlet', 0.149), ('ci', 0.145), ('rul', 0.136), ('chow', 0.135), ('svms', 0.121), ('yi', 0.116), ('abstain', 0.113), ('gji', 0.113), ('ic', 0.107), ('ti', 0.101), ('grandvalet', 0.098), ('exy', 0.098), ('svm', 0.09), ('naiv', 0.09)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="228-tfidf-1" href="./nips-2008-Support_Vector_Machines_with_a_Reject_Option.html">228 nips-2008-Support Vector Machines with a Reject Option</a></p>
<p>2 0.26310438 <a title="228-tfidf-2" href="./nips-2008-The_Gaussian_Process_Density_Sampler.html">233 nips-2008-The Gaussian Process Density Sampler</a></p>
<p>3 0.13166511 <a title="228-tfidf-3" href="./nips-2008-On_the_Design_of_Loss_Functions_for_Classification%3A_theory%2C_robustness_to_outliers%2C_and_SavageBoost.html">162 nips-2008-On the Design of Loss Functions for Classification: theory, robustness to outliers, and SavageBoost</a></p>
<p>4 0.12198025 <a title="228-tfidf-4" href="./nips-2008-Transfer_Learning_by_Distribution_Matching_for_Targeted_Advertising.html">241 nips-2008-Transfer Learning by Distribution Matching for Targeted Advertising</a></p>
<p>5 0.1123105 <a title="228-tfidf-5" href="./nips-2008-Tighter_Bounds_for_Structured_Estimation.html">239 nips-2008-Tighter Bounds for Structured Estimation</a></p>
<p>6 0.10798784 <a title="228-tfidf-6" href="./nips-2008-On_the_Complexity_of_Linear_Prediction%3A_Risk_Bounds%2C_Margin_Bounds%2C_and_Regularization.html">161 nips-2008-On the Complexity of Linear Prediction: Risk Bounds, Margin Bounds, and Regularization</a></p>
<p>7 0.097876608 <a title="228-tfidf-7" href="./nips-2008-On_the_Efficient_Minimization_of_Classification_Calibrated_Surrogates.html">163 nips-2008-On the Efficient Minimization of Classification Calibrated Surrogates</a></p>
<p>8 0.095415913 <a title="228-tfidf-8" href="./nips-2008-Relative_Margin_Machines.html">196 nips-2008-Relative Margin Machines</a></p>
<p>9 0.086687751 <a title="228-tfidf-9" href="./nips-2008-Performance_analysis_for_L%5C_2_kernel_classification.html">178 nips-2008-Performance analysis for L\ 2 kernel classification</a></p>
<p>10 0.086269051 <a title="228-tfidf-10" href="./nips-2008-Nonlinear_causal_discovery_with_additive_noise_models.html">153 nips-2008-Nonlinear causal discovery with additive noise models</a></p>
<p>11 0.08547394 <a title="228-tfidf-11" href="./nips-2008-Hierarchical_Fisher_Kernels_for_Longitudinal_Data.html">97 nips-2008-Hierarchical Fisher Kernels for Longitudinal Data</a></p>
<p>12 0.082664885 <a title="228-tfidf-12" href="./nips-2008-Fast_Rates_for_Regularized_Objectives.html">85 nips-2008-Fast Rates for Regularized Objectives</a></p>
<p>13 0.081623286 <a title="228-tfidf-13" href="./nips-2008-Domain_Adaptation_with_Multiple_Sources.html">65 nips-2008-Domain Adaptation with Multiple Sources</a></p>
<p>14 0.081409089 <a title="228-tfidf-14" href="./nips-2008-Hebbian_Learning_of_Bayes_Optimal_Decisions.html">96 nips-2008-Hebbian Learning of Bayes Optimal Decisions</a></p>
<p>15 0.07982631 <a title="228-tfidf-15" href="./nips-2008-Supervised_Dictionary_Learning.html">226 nips-2008-Supervised Dictionary Learning</a></p>
<p>16 0.078998215 <a title="228-tfidf-16" href="./nips-2008-Beyond_Novelty_Detection%3A_Incongruent_Events%2C_when_General_and_Specific_Classifiers_Disagree.html">36 nips-2008-Beyond Novelty Detection: Incongruent Events, when General and Specific Classifiers Disagree</a></p>
<p>17 0.076829121 <a title="228-tfidf-17" href="./nips-2008-An_Empirical_Analysis_of_Domain_Adaptation_Algorithms_for_Genomic_Sequence_Analysis.html">19 nips-2008-An Empirical Analysis of Domain Adaptation Algorithms for Genomic Sequence Analysis</a></p>
<p>18 0.072692171 <a title="228-tfidf-18" href="./nips-2008-From_Online_to_Batch_Learning_with_Cutoff-Averaging.html">88 nips-2008-From Online to Batch Learning with Cutoff-Averaging</a></p>
<p>19 0.07042221 <a title="228-tfidf-19" href="./nips-2008-Exact_Convex_Confidence-Weighted_Learning.html">78 nips-2008-Exact Convex Confidence-Weighted Learning</a></p>
<p>20 0.070201032 <a title="228-tfidf-20" href="./nips-2008-Sparse_Online_Learning_via_Truncated_Gradient.html">214 nips-2008-Sparse Online Learning via Truncated Gradient</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2008_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.221), (1, 0.062), (2, 0.066), (3, -0.077), (4, 0.024), (5, -0.002), (6, 0.018), (7, 0.001), (8, -0.067), (9, 0.026), (10, -0.005), (11, 0.164), (12, 0.028), (13, 0.1), (14, -0.029), (15, -0.029), (16, -0.041), (17, 0.033), (18, -0.053), (19, 0.095), (20, -0.097), (21, -0.158), (22, -0.088), (23, -0.135), (24, 0.093), (25, -0.042), (26, 0.005), (27, -0.128), (28, -0.074), (29, -0.121), (30, -0.011), (31, -0.063), (32, 0.011), (33, -0.071), (34, -0.13), (35, 0.193), (36, -0.085), (37, -0.03), (38, -0.002), (39, 0.062), (40, -0.068), (41, 0.045), (42, -0.14), (43, -0.021), (44, -0.094), (45, -0.081), (46, 0.002), (47, 0.019), (48, 0.012), (49, -0.075)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91469795 <a title="228-lsi-1" href="./nips-2008-Support_Vector_Machines_with_a_Reject_Option.html">228 nips-2008-Support Vector Machines with a Reject Option</a></p>
<p>2 0.71071011 <a title="228-lsi-2" href="./nips-2008-The_Gaussian_Process_Density_Sampler.html">233 nips-2008-The Gaussian Process Density Sampler</a></p>
<p>3 0.63853371 <a title="228-lsi-3" href="./nips-2008-On_the_Design_of_Loss_Functions_for_Classification%3A_theory%2C_robustness_to_outliers%2C_and_SavageBoost.html">162 nips-2008-On the Design of Loss Functions for Classification: theory, robustness to outliers, and SavageBoost</a></p>
<p>4 0.58765221 <a title="228-lsi-4" href="./nips-2008-On_the_Efficient_Minimization_of_Classification_Calibrated_Surrogates.html">163 nips-2008-On the Efficient Minimization of Classification Calibrated Surrogates</a></p>
<p>5 0.5593555 <a title="228-lsi-5" href="./nips-2008-Privacy-preserving_logistic_regression.html">185 nips-2008-Privacy-preserving logistic regression</a></p>
<p>6 0.55647326 <a title="228-lsi-6" href="./nips-2008-Fast_Rates_for_Regularized_Objectives.html">85 nips-2008-Fast Rates for Regularized Objectives</a></p>
<p>7 0.53638649 <a title="228-lsi-7" href="./nips-2008-Tighter_Bounds_for_Structured_Estimation.html">239 nips-2008-Tighter Bounds for Structured Estimation</a></p>
<p>8 0.51470011 <a title="228-lsi-8" href="./nips-2008-Transfer_Learning_by_Distribution_Matching_for_Targeted_Advertising.html">241 nips-2008-Transfer Learning by Distribution Matching for Targeted Advertising</a></p>
<p>9 0.51415211 <a title="228-lsi-9" href="./nips-2008-Probabilistic_detection_of_short_events%2C_with_application_to_critical_care_monitoring.html">186 nips-2008-Probabilistic detection of short events, with application to critical care monitoring</a></p>
<p>10 0.51174831 <a title="228-lsi-10" href="./nips-2008-Near-minimax_recursive_density_estimation_on_the_binary_hypercube.html">149 nips-2008-Near-minimax recursive density estimation on the binary hypercube</a></p>
<p>11 0.49715653 <a title="228-lsi-11" href="./nips-2008-Relative_Margin_Machines.html">196 nips-2008-Relative Margin Machines</a></p>
<p>12 0.493029 <a title="228-lsi-12" href="./nips-2008-Efficient_Direct_Density_Ratio_Estimation_for_Non-stationarity_Adaptation_and_Outlier_Detection.html">68 nips-2008-Efficient Direct Density Ratio Estimation for Non-stationarity Adaptation and Outlier Detection</a></p>
<p>13 0.47314575 <a title="228-lsi-13" href="./nips-2008-Improving_on_Expectation_Propagation.html">105 nips-2008-Improving on Expectation Propagation</a></p>
<p>14 0.43406835 <a title="228-lsi-14" href="./nips-2008-An_Empirical_Analysis_of_Domain_Adaptation_Algorithms_for_Genomic_Sequence_Analysis.html">19 nips-2008-An Empirical Analysis of Domain Adaptation Algorithms for Genomic Sequence Analysis</a></p>
<p>15 0.42725328 <a title="228-lsi-15" href="./nips-2008-Adapting_to_a_Market_Shock%3A_Optimal_Sequential_Market-Making.html">13 nips-2008-Adapting to a Market Shock: Optimal Sequential Market-Making</a></p>
<p>16 0.41801414 <a title="228-lsi-16" href="./nips-2008-Partially_Observed_Maximum_Entropy_Discrimination_Markov_Networks.html">176 nips-2008-Partially Observed Maximum Entropy Discrimination Markov Networks</a></p>
<p>17 0.41673771 <a title="228-lsi-17" href="./nips-2008-Domain_Adaptation_with_Multiple_Sources.html">65 nips-2008-Domain Adaptation with Multiple Sources</a></p>
<p>18 0.41435447 <a title="228-lsi-18" href="./nips-2008-Generative_and_Discriminative_Learning_with_Unknown_Labeling_Bias.html">91 nips-2008-Generative and Discriminative Learning with Unknown Labeling Bias</a></p>
<p>19 0.41275877 <a title="228-lsi-19" href="./nips-2008-Multi-stage_Convex_Relaxation_for_Learning_with_Sparse_Regularization.html">145 nips-2008-Multi-stage Convex Relaxation for Learning with Sparse Regularization</a></p>
<p>20 0.40815815 <a title="228-lsi-20" href="./nips-2008-On_the_Complexity_of_Linear_Prediction%3A_Risk_Bounds%2C_Margin_Bounds%2C_and_Regularization.html">161 nips-2008-On the Complexity of Linear Prediction: Risk Bounds, Margin Bounds, and Regularization</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2008_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(25, 0.019), (30, 0.089), (38, 0.06), (40, 0.069), (44, 0.331), (60, 0.04), (63, 0.107), (64, 0.096), (71, 0.096)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.81278872 <a title="228-lda-1" href="./nips-2008-Mortal_Multi-Armed_Bandits.html">140 nips-2008-Mortal Multi-Armed Bandits</a></p>
<p>2 0.69610608 <a title="228-lda-2" href="./nips-2008-Artificial_Olfactory_Brain_for_Mixture_Identification.html">27 nips-2008-Artificial Olfactory Brain for Mixture Identification</a></p>
<p>3 0.68152326 <a title="228-lda-3" href="./nips-2008-Hierarchical_Semi-Markov_Conditional_Random_Fields_for_Recursive_Sequential_Data.html">98 nips-2008-Hierarchical Semi-Markov Conditional Random Fields for Recursive Sequential Data</a></p>
<p>same-paper 4 0.65970683 <a title="228-lda-4" href="./nips-2008-Support_Vector_Machines_with_a_Reject_Option.html">228 nips-2008-Support Vector Machines with a Reject Option</a></p>
<p>5 0.5295288 <a title="228-lda-5" href="./nips-2008-MCBoost%3A_Multiple_Classifier_Boosting_for_Perceptual_Co-clustering_of_Images_and_Visual_Features.html">130 nips-2008-MCBoost: Multiple Classifier Boosting for Perceptual Co-clustering of Images and Visual Features</a></p>
<p>6 0.52471948 <a title="228-lda-6" href="./nips-2008-Estimating_Robust_Query_Models_with_Convex_Optimization.html">73 nips-2008-Estimating Robust Query Models with Convex Optimization</a></p>
<p>7 0.51917893 <a title="228-lda-7" href="./nips-2008-Performance_analysis_for_L%5C_2_kernel_classification.html">178 nips-2008-Performance analysis for L\ 2 kernel classification</a></p>
<p>8 0.5189383 <a title="228-lda-8" href="./nips-2008-Global_Ranking_Using_Continuous_Conditional_Random_Fields.html">93 nips-2008-Global Ranking Using Continuous Conditional Random Fields</a></p>
<p>9 0.51893461 <a title="228-lda-9" href="./nips-2008-Efficient_Exact_Inference_in_Planar_Ising_Models.html">69 nips-2008-Efficient Exact Inference in Planar Ising Models</a></p>
<p>10 0.51776016 <a title="228-lda-10" href="./nips-2008-Inferring_rankings_under_constrained_sensing.html">106 nips-2008-Inferring rankings under constrained sensing</a></p>
<p>11 0.51720262 <a title="228-lda-11" href="./nips-2008-Online_Prediction_on_Large_Diameter_Graphs.html">171 nips-2008-Online Prediction on Large Diameter Graphs</a></p>
<p>12 0.51687056 <a title="228-lda-12" href="./nips-2008-Mind_the_Duality_Gap%3A_Logarithmic_regret_algorithms_for_online_optimization.html">133 nips-2008-Mind the Duality Gap: Logarithmic regret algorithms for online optimization</a></p>
<p>13 0.51626331 <a title="228-lda-13" href="./nips-2008-Tighter_Bounds_for_Structured_Estimation.html">239 nips-2008-Tighter Bounds for Structured Estimation</a></p>
<p>14 0.51581538 <a title="228-lda-14" href="./nips-2008-Clusters_and_Coarse_Partitions_in_LP_Relaxations.html">49 nips-2008-Clusters and Coarse Partitions in LP Relaxations</a></p>
<p>15 0.51554531 <a title="228-lda-15" href="./nips-2008-Sparse_Online_Learning_via_Truncated_Gradient.html">214 nips-2008-Sparse Online Learning via Truncated Gradient</a></p>
<p>16 0.5143891 <a title="228-lda-16" href="./nips-2008-On_the_Reliability_of_Clustering_Stability_in_the_Large_Sample_Regime.html">165 nips-2008-On the Reliability of Clustering Stability in the Large Sample Regime</a></p>
<p>17 0.51331383 <a title="228-lda-17" href="./nips-2008-Mixed_Membership_Stochastic_Blockmodels.html">134 nips-2008-Mixed Membership Stochastic Blockmodels</a></p>
<p>18 0.51300174 <a title="228-lda-18" href="./nips-2008-Fast_Rates_for_Regularized_Objectives.html">85 nips-2008-Fast Rates for Regularized Objectives</a></p>
<p>19 0.51273 <a title="228-lda-19" href="./nips-2008-Online_Optimization_in_X-Armed_Bandits.html">170 nips-2008-Online Optimization in X-Armed Bandits</a></p>
<p>20 0.51260793 <a title="228-lda-20" href="./nips-2008-Differentiable_Sparse_Coding.html">62 nips-2008-Differentiable Sparse Coding</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
