<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>32 nips-2008-Bayesian Kernel Shaping for Learning Control</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-32" href="#">nips2008-32</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>32 nips-2008-Bayesian Kernel Shaping for Learning Control</h1>
<br/><p>Source: <a title="nips-2008-32-pdf" href="http://papers.nips.cc/paper/3393-bayesian-kernel-shaping-for-learning-control.pdf">pdf</a></p><p>Author: Jo-anne Ting, Mrinal Kalakrishnan, Sethu Vijayakumar, Stefan Schaal</p><p>Abstract: In kernel-based regression learning, optimizing each kernel individually is useful when the data density, curvature of regression surfaces (or decision boundaries) or magnitude of output noise varies spatially. Previous work has suggested gradient descent techniques or complex statistical hypothesis methods for local kernel shaping, typically requiring some amount of manual tuning of meta parameters. We introduce a Bayesian formulation of nonparametric regression that, with the help of variational approximations, results in an EM-like algorithm for simultaneous estimation of regression and kernel parameters. The algorithm is computationally efﬁcient, requires no sampling, automatically rejects outliers and has only one prior to be speciﬁed. It can be used for nonparametric regression with local polynomials or as a novel method to achieve nonstationary regression with Gaussian processes. Our methods are particularly useful for learning control, where reliable estimation of local tangent planes is essential for adaptive controllers and reinforcement learning. We evaluate our methods on several synthetic data sets and on an actual robot which learns a task-level control law. 1</p><p>Reference: <a title="nips-2008-32-reference" href="../nips2008_reference/nips-2008-Bayesian_Kernel_Shaping_for_Learning_Control_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('nonst', 0.463), ('gp', 0.37), ('wim', 0.333), ('xim', 0.268), ('bm', 0.265), ('xqm', 0.17), ('kernel', 0.17), ('kinem', 0.165), ('qim', 0.151), ('hm', 0.147), ('shap', 0.142), ('zm', 0.137), ('wi', 0.136), ('xq', 0.118), ('zim', 0.114), ('zi', 0.104), ('robot', 0.088), ('zn', 0.086), ('mth', 0.08), ('aug', 0.079)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="32-tfidf-1" href="./nips-2008-Bayesian_Kernel_Shaping_for_Learning_Control.html">32 nips-2008-Bayesian Kernel Shaping for Learning Control</a></p>
<p>2 0.22924207 <a title="32-tfidf-2" href="./nips-2008-Accelerating_Bayesian_Inference_over_Nonlinear_Differential_Equations_with_Gaussian_Processes.html">12 nips-2008-Accelerating Bayesian Inference over Nonlinear Differential Equations with Gaussian Processes</a></p>
<p>3 0.15793566 <a title="32-tfidf-3" href="./nips-2008-Multi-task_Gaussian_Process_Learning_of_Robot_Inverse_Dynamics.html">146 nips-2008-Multi-task Gaussian Process Learning of Robot Inverse Dynamics</a></p>
<p>4 0.15590322 <a title="32-tfidf-4" href="./nips-2008-Efficient_Sampling_for_Gaussian_Process_Inference_using_Control_Variables.html">71 nips-2008-Efficient Sampling for Gaussian Process Inference using Control Variables</a></p>
<p>5 0.13572451 <a title="32-tfidf-5" href="./nips-2008-Variational_Mixture_of_Gaussian_Process_Experts.html">249 nips-2008-Variational Mixture of Gaussian Process Experts</a></p>
<p>6 0.125879 <a title="32-tfidf-6" href="./nips-2008-Sparse_Convolved_Gaussian_Processes_for_Multi-output_Regression.html">213 nips-2008-Sparse Convolved Gaussian Processes for Multi-output Regression</a></p>
<p>7 0.12399741 <a title="32-tfidf-7" href="./nips-2008-Modeling_human_function_learning_with_Gaussian_processes.html">138 nips-2008-Modeling human function learning with Gaussian processes</a></p>
<p>8 0.12184014 <a title="32-tfidf-8" href="./nips-2008-Hebbian_Learning_of_Bayes_Optimal_Decisions.html">96 nips-2008-Hebbian Learning of Bayes Optimal Decisions</a></p>
<p>9 0.10962629 <a title="32-tfidf-9" href="./nips-2008-Local_Gaussian_Process_Regression_for_Real_Time_Online_Model_Learning.html">125 nips-2008-Local Gaussian Process Regression for Real Time Online Model Learning</a></p>
<p>10 0.10319749 <a title="32-tfidf-10" href="./nips-2008-Exploring_Large_Feature_Spaces_with_Hierarchical_Multiple_Kernel_Learning.html">79 nips-2008-Exploring Large Feature Spaces with Hierarchical Multiple Kernel Learning</a></p>
<p>11 0.095122553 <a title="32-tfidf-11" href="./nips-2008-Sparse_probabilistic_projections.html">216 nips-2008-Sparse probabilistic projections</a></p>
<p>12 0.09480463 <a title="32-tfidf-12" href="./nips-2008-Risk_Bounds_for_Randomized_Sample_Compressed_Classifiers.html">199 nips-2008-Risk Bounds for Randomized Sample Compressed Classifiers</a></p>
<p>13 0.088001274 <a title="32-tfidf-13" href="./nips-2008-Sparse_Online_Learning_via_Truncated_Gradient.html">214 nips-2008-Sparse Online Learning via Truncated Gradient</a></p>
<p>14 0.086391248 <a title="32-tfidf-14" href="./nips-2008-Learning_Hybrid_Models_for_Image_Annotation_with_Partially_Labeled_Data.html">116 nips-2008-Learning Hybrid Models for Image Annotation with Partially Labeled Data</a></p>
<p>15 0.085020609 <a title="32-tfidf-15" href="./nips-2008-Hierarchical_Fisher_Kernels_for_Longitudinal_Data.html">97 nips-2008-Hierarchical Fisher Kernels for Longitudinal Data</a></p>
<p>16 0.083386734 <a title="32-tfidf-16" href="./nips-2008-Kernelized_Sorting.html">113 nips-2008-Kernelized Sorting</a></p>
<p>17 0.082860485 <a title="32-tfidf-17" href="./nips-2008-Dimensionality_Reduction_for_Data_in_Multiple_Feature_Representations.html">63 nips-2008-Dimensionality Reduction for Data in Multiple Feature Representations</a></p>
<p>18 0.080418073 <a title="32-tfidf-18" href="./nips-2008-Robust_Near-Isometric_Matching_via_Structured_Learning_of_Graphical_Models.html">201 nips-2008-Robust Near-Isometric Matching via Structured Learning of Graphical Models</a></p>
<p>19 0.075923495 <a title="32-tfidf-19" href="./nips-2008-Extended_Grassmann_Kernels_for_Subspace-Based_Learning.html">80 nips-2008-Extended Grassmann Kernels for Subspace-Based Learning</a></p>
<p>20 0.074720711 <a title="32-tfidf-20" href="./nips-2008-Gaussian-process_factor_analysis_for_low-dimensional_single-trial_analysis_of_neural_population_activity.html">90 nips-2008-Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2008_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.22), (1, 0.022), (2, 0.009), (3, -0.02), (4, -0.007), (5, 0.14), (6, 0.111), (7, 0.003), (8, -0.057), (9, 0.141), (10, 0.017), (11, 0.023), (12, 0.229), (13, -0.002), (14, 0.156), (15, -0.258), (16, 0.001), (17, -0.172), (18, -0.098), (19, -0.097), (20, 0.014), (21, 0.06), (22, -0.028), (23, 0.025), (24, 0.011), (25, -0.021), (26, -0.082), (27, 0.024), (28, -0.048), (29, -0.017), (30, -0.051), (31, 0.094), (32, -0.138), (33, -0.032), (34, 0.014), (35, -0.02), (36, 0.006), (37, 0.085), (38, -0.019), (39, -0.023), (40, -0.06), (41, 0.037), (42, 0.076), (43, -0.005), (44, -0.048), (45, 0.032), (46, 0.023), (47, -0.012), (48, 0.018), (49, 0.009)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91024184 <a title="32-lsi-1" href="./nips-2008-Bayesian_Kernel_Shaping_for_Learning_Control.html">32 nips-2008-Bayesian Kernel Shaping for Learning Control</a></p>
<p>2 0.77527452 <a title="32-lsi-2" href="./nips-2008-Sparse_Convolved_Gaussian_Processes_for_Multi-output_Regression.html">213 nips-2008-Sparse Convolved Gaussian Processes for Multi-output Regression</a></p>
<p>3 0.71278417 <a title="32-lsi-3" href="./nips-2008-Accelerating_Bayesian_Inference_over_Nonlinear_Differential_Equations_with_Gaussian_Processes.html">12 nips-2008-Accelerating Bayesian Inference over Nonlinear Differential Equations with Gaussian Processes</a></p>
<p>4 0.70619363 <a title="32-lsi-4" href="./nips-2008-Local_Gaussian_Process_Regression_for_Real_Time_Online_Model_Learning.html">125 nips-2008-Local Gaussian Process Regression for Real Time Online Model Learning</a></p>
<p>5 0.70164156 <a title="32-lsi-5" href="./nips-2008-Efficient_Sampling_for_Gaussian_Process_Inference_using_Control_Variables.html">71 nips-2008-Efficient Sampling for Gaussian Process Inference using Control Variables</a></p>
<p>6 0.65717077 <a title="32-lsi-6" href="./nips-2008-Multi-task_Gaussian_Process_Learning_of_Robot_Inverse_Dynamics.html">146 nips-2008-Multi-task Gaussian Process Learning of Robot Inverse Dynamics</a></p>
<p>7 0.63235795 <a title="32-lsi-7" href="./nips-2008-Variational_Mixture_of_Gaussian_Process_Experts.html">249 nips-2008-Variational Mixture of Gaussian Process Experts</a></p>
<p>8 0.56766438 <a title="32-lsi-8" href="./nips-2008-Modeling_human_function_learning_with_Gaussian_processes.html">138 nips-2008-Modeling human function learning with Gaussian processes</a></p>
<p>9 0.53084534 <a title="32-lsi-9" href="./nips-2008-Stochastic_Relational_Models_for_Large-scale_Dyadic_Data_using_MCMC.html">221 nips-2008-Stochastic Relational Models for Large-scale Dyadic Data using MCMC</a></p>
<p>10 0.5212695 <a title="32-lsi-10" href="./nips-2008-Gaussian-process_factor_analysis_for_low-dimensional_single-trial_analysis_of_neural_population_activity.html">90 nips-2008-Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity</a></p>
<p>11 0.45062092 <a title="32-lsi-11" href="./nips-2008-Efficient_Direct_Density_Ratio_Estimation_for_Non-stationarity_Adaptation_and_Outlier_Detection.html">68 nips-2008-Efficient Direct Density Ratio Estimation for Non-stationarity Adaptation and Outlier Detection</a></p>
<p>12 0.43096676 <a title="32-lsi-12" href="./nips-2008-Hebbian_Learning_of_Bayes_Optimal_Decisions.html">96 nips-2008-Hebbian Learning of Bayes Optimal Decisions</a></p>
<p>13 0.41743097 <a title="32-lsi-13" href="./nips-2008-Hierarchical_Fisher_Kernels_for_Longitudinal_Data.html">97 nips-2008-Hierarchical Fisher Kernels for Longitudinal Data</a></p>
<p>14 0.40081236 <a title="32-lsi-14" href="./nips-2008-Kernel-ARMA_for_Hand_Tracking_and_Brain-Machine_interfacing_During_3D_Motor_Control.html">110 nips-2008-Kernel-ARMA for Hand Tracking and Brain-Machine interfacing During 3D Motor Control</a></p>
<p>15 0.40059024 <a title="32-lsi-15" href="./nips-2008-Sparse_probabilistic_projections.html">216 nips-2008-Sparse probabilistic projections</a></p>
<p>16 0.39520708 <a title="32-lsi-16" href="./nips-2008-Extended_Grassmann_Kernels_for_Subspace-Based_Learning.html">80 nips-2008-Extended Grassmann Kernels for Subspace-Based Learning</a></p>
<p>17 0.39200833 <a title="32-lsi-17" href="./nips-2008-Exploring_Large_Feature_Spaces_with_Hierarchical_Multiple_Kernel_Learning.html">79 nips-2008-Exploring Large Feature Spaces with Hierarchical Multiple Kernel Learning</a></p>
<p>18 0.38930005 <a title="32-lsi-18" href="./nips-2008-Dimensionality_Reduction_for_Data_in_Multiple_Feature_Representations.html">63 nips-2008-Dimensionality Reduction for Data in Multiple Feature Representations</a></p>
<p>19 0.38043284 <a title="32-lsi-19" href="./nips-2008-The_Gaussian_Process_Density_Sampler.html">233 nips-2008-The Gaussian Process Density Sampler</a></p>
<p>20 0.3753238 <a title="32-lsi-20" href="./nips-2008-Fitted_Q-iteration_by_Advantage_Weighted_Regression.html">87 nips-2008-Fitted Q-iteration by Advantage Weighted Regression</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2008_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.354), (25, 0.018), (30, 0.076), (38, 0.022), (40, 0.061), (60, 0.052), (63, 0.118), (64, 0.063), (71, 0.125), (98, 0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.70459259 <a title="32-lda-1" href="./nips-2008-Bayesian_Kernel_Shaping_for_Learning_Control.html">32 nips-2008-Bayesian Kernel Shaping for Learning Control</a></p>
<p>2 0.68215251 <a title="32-lda-2" href="./nips-2008-Variational_Mixture_of_Gaussian_Process_Experts.html">249 nips-2008-Variational Mixture of Gaussian Process Experts</a></p>
<p>3 0.64386261 <a title="32-lda-3" href="./nips-2008-Transfer_Learning_by_Distribution_Matching_for_Targeted_Advertising.html">241 nips-2008-Transfer Learning by Distribution Matching for Targeted Advertising</a></p>
<p>4 0.63414359 <a title="32-lda-4" href="./nips-2008-DiscLDA%3A_Discriminative_Learning_for_Dimensionality_Reduction_and_Classification.html">64 nips-2008-DiscLDA: Discriminative Learning for Dimensionality Reduction and Classification</a></p>
<p>5 0.53506804 <a title="32-lda-5" href="./nips-2008-Local_Gaussian_Process_Regression_for_Real_Time_Online_Model_Learning.html">125 nips-2008-Local Gaussian Process Regression for Real Time Online Model Learning</a></p>
<p>6 0.52099109 <a title="32-lda-6" href="./nips-2008-The_Gaussian_Process_Density_Sampler.html">233 nips-2008-The Gaussian Process Density Sampler</a></p>
<p>7 0.51934552 <a title="32-lda-7" href="./nips-2008-The_Infinite_Factorial_Hidden_Markov_Model.html">234 nips-2008-The Infinite Factorial Hidden Markov Model</a></p>
<p>8 0.51348037 <a title="32-lda-8" href="./nips-2008-Multi-task_Gaussian_Process_Learning_of_Robot_Inverse_Dynamics.html">146 nips-2008-Multi-task Gaussian Process Learning of Robot Inverse Dynamics</a></p>
<p>9 0.50640404 <a title="32-lda-9" href="./nips-2008-Sparse_Online_Learning_via_Truncated_Gradient.html">214 nips-2008-Sparse Online Learning via Truncated Gradient</a></p>
<p>10 0.50614774 <a title="32-lda-10" href="./nips-2008-Online_Models_for_Content_Optimization.html">169 nips-2008-Online Models for Content Optimization</a></p>
<p>11 0.50532126 <a title="32-lda-11" href="./nips-2008-Sparse_Convolved_Gaussian_Processes_for_Multi-output_Regression.html">213 nips-2008-Sparse Convolved Gaussian Processes for Multi-output Regression</a></p>
<p>12 0.50501728 <a title="32-lda-12" href="./nips-2008-Efficient_Exact_Inference_in_Planar_Ising_Models.html">69 nips-2008-Efficient Exact Inference in Planar Ising Models</a></p>
<p>13 0.50447869 <a title="32-lda-13" href="./nips-2008-Clusters_and_Coarse_Partitions_in_LP_Relaxations.html">49 nips-2008-Clusters and Coarse Partitions in LP Relaxations</a></p>
<p>14 0.50301796 <a title="32-lda-14" href="./nips-2008-Differentiable_Sparse_Coding.html">62 nips-2008-Differentiable Sparse Coding</a></p>
<p>15 0.50270486 <a title="32-lda-15" href="./nips-2008-Convergence_and_Rate_of_Convergence_of_a_Manifold-Based_Dimension_Reduction_Algorithm.html">51 nips-2008-Convergence and Rate of Convergence of a Manifold-Based Dimension Reduction Algorithm</a></p>
<p>16 0.50238132 <a title="32-lda-16" href="./nips-2008-Estimating_Robust_Query_Models_with_Convex_Optimization.html">73 nips-2008-Estimating Robust Query Models with Convex Optimization</a></p>
<p>17 0.5023793 <a title="32-lda-17" href="./nips-2008-Fast_Prediction_on_a_Tree.html">84 nips-2008-Fast Prediction on a Tree</a></p>
<p>18 0.50213146 <a title="32-lda-18" href="./nips-2008-Estimation_of_Information_Theoretic_Measures_for_Continuous_Random_Variables.html">76 nips-2008-Estimation of Information Theoretic Measures for Continuous Random Variables</a></p>
<p>19 0.50128663 <a title="32-lda-19" href="./nips-2008-Multi-stage_Convex_Relaxation_for_Learning_with_Sparse_Regularization.html">145 nips-2008-Multi-stage Convex Relaxation for Learning with Sparse Regularization</a></p>
<p>20 0.5001651 <a title="32-lda-20" href="./nips-2008-Cyclizing_Clusters_via_Zeta_Function_of_a_Graph.html">55 nips-2008-Cyclizing Clusters via Zeta Function of a Graph</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
