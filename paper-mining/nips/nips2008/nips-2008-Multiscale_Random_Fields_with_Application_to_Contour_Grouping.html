<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>147 nips-2008-Multiscale Random Fields with Application to Contour Grouping</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-147" href="#">nips2008-147</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>147 nips-2008-Multiscale Random Fields with Application to Contour Grouping</h1>
<br/><p>Source: <a title="nips-2008-147-pdf" href="http://papers.nips.cc/paper/3430-multiscale-random-fields-with-application-to-contour-grouping.pdf">pdf</a></p><p>Author: Longin J. Latecki, Chengen Lu, Marc Sobel, Xiang Bai</p><p>Abstract: We introduce a new interpretation of multiscale random ﬁelds (MSRFs) that admits efﬁcient optimization in the framework of regular (single level) random ﬁelds (RFs). It is based on a new operator, called append, that combines sets of random variables (RVs) to single RVs. We assume that a MSRF can be decomposed into disjoint trees that link RVs at different pyramid levels. The append operator is then applied to map RVs in each tree structure to a single RV. We demonstrate the usefulness of the proposed approach on a challenging task involving grouping contours of target shapes in images. It provides a natural representation of multiscale contour models, which is needed in order to cope with unstable contour decompositions. The append operator allows us to ﬁnd optimal image segment labels using the classical framework of relaxation labeling. Alternative methods like Markov Chain Monte Carlo (MCMC) could also be used.</p><p>Reference: <a title="nips-2008-147-reference" href="../nips2008_reference/nips-2008-Multiscale_Random_Fields_with_Application_to_Contour_Grouping_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The append operator is then applied to map RVs in each tree structure to a single RV. [sent-25, score-0.366]
</p><p>2 It provides a natural representation of multiscale contour models, which is needed in order to cope with unstable contour decompositions. [sent-27, score-1.144]
</p><p>3 The append operator allows us to ﬁnd optimal image segment labels using the classical framework of relaxation labeling. [sent-28, score-0.642]
</p><p>4 In [6], a probabilistic model of multiscale conditional random ﬁelds (mCRF) was proposed to segment images by labeling pixels using a predeﬁned set of class labels. [sent-34, score-0.488]
</p><p>5 In the proposed approach, the random variables (RVs) linked by a tree substructure across different levels compete for their label assignments, while in the existing approaches the goal is to cooperate in the label assigns, which is usually achieved by averaging. [sent-38, score-0.34]
</p><p>6 In other words, usually the label assignment of a parent node is enforced to be compatible with the label assignment of its children by averaging. [sent-39, score-0.467]
</p><p>7 We introduce a novel MSRF interpretation, and show its beneﬁts in solving the contour grouping problem. [sent-42, score-0.634]
</p><p>8 The MSRF allows us to cast contour grouping as contour matching. [sent-43, score-1.121]
</p><p>9 Some researchers described the shape of the entire object using deformable contour fragments and their relative positions [10, 12], but their detection results are always grassy contour edges. [sent-47, score-1.158]
</p><p>10 [4] have used the sophisticated edge detection methods of [8]; the resulting edges are linked to a network of connected contour segments by closing small gaps. [sent-50, score-1.004]
</p><p>11 Our grouping is also based on the edge detection of [8], but we do not perform edge linking directly for purposes of grouping. [sent-53, score-0.387]
</p><p>12 We perform matching a given contour model to edge segments in images. [sent-54, score-1.041]
</p><p>13 Our method differs from former sampled-points-based matching methods [14, 3]; we match the contour segments from the given contour to segments in edge images directly. [sent-56, score-1.927]
</p><p>14 We decompose a given closed contour of a model shape into a group of contour segments, and match the resulting contour segments to edge segments in a given image. [sent-57, score-2.432]
</p><p>15 Our model contour decomposition is ﬂexible and admits a hierarchical structure, e. [sent-58, score-0.511]
</p><p>16 , a parent contour segment is decomposed into two or more child segments. [sent-60, score-0.735]
</p><p>17 In this way, our model can adapt to different conﬁgurations of contour parts in edge images. [sent-61, score-0.621]
</p><p>18 The proposed MSRF interpretation allows us to formulate the problem of contour grouping as a soft label assignment problem. [sent-62, score-0.889]
</p><p>19 The competition is made possible by the proposed append operator. [sent-64, score-0.317]
</p><p>20 Since the connectivity relation between each pair of model segments is known, the soft label assignment and the competition for best labels make accurate grouping results in real images possible. [sent-66, score-0.822]
</p><p>21 We also want to stress that our grouping approach is based on matching of contour segments. [sent-67, score-0.716]
</p><p>22 The advantages of segment matching over alternative techniques based on point matching are at least twofold: 1) it permits deformable matching (i. [sent-68, score-0.433]
</p><p>23 , the global shape will not be changed even when some segments shift or rotate a little); 2) it is more stable than point matching, since contour segments are more informative than points as shape cues. [sent-70, score-1.44]
</p><p>24 , xn }, the goal of random ﬁelds is to ﬁnd a label assignment f that maximizes the posterior probability p(f |X) (of that assignment): f = argmaxf p(f |X) (1) Thus, we want to select the label assignment with the largest possible probability given the observed data. [sent-74, score-0.459]
</p><p>25 Although the proposed method is quite general, for clarity of presentation, we focus on an application of interest to us: contour grouping based on contour part correspondence. [sent-75, score-1.138]
</p><p>26 We take the contour of an example shape to be our shape model S. [sent-76, score-0.687]
</p><p>27 We assume that the model is composed of several contour segments s 1 , . [sent-77, score-0.889]
</p><p>28 , xn } are contour segments extracted by some low level process in a given image. [sent-84, score-0.972]
</p><p>29 We write Fi = xj to denote the event that the model segment s i is assigned the image segment x j by the map F. [sent-94, score-0.58]
</p><p>30 ,fm )  2  (2)  However, the object contour in the given image (which is composed of some subset of segments in X = {x1 , . [sent-115, score-0.989]
</p><p>31 , xn } may have a different decomposition into contour segments than is the case for the model s1 , . [sent-118, score-0.915]
</p><p>32 This is the case, for example, if some parts of the true contour are missing, i. [sent-122, score-0.51]
</p><p>33 We introduce such a model by imposing a multiscale structure on contour segments of the model shape. [sent-126, score-1.11]
</p><p>34 Let the lowest level zero represents the ﬁnest subdivision of a given model contour S into the segments S 0 = {s0 , . [sent-127, score-0.952]
</p><p>35 The α level 1 m partition subdivides the contour into the segments S α = {sα , . [sent-131, score-0.928]
</p><p>36 For each pyramid level α, the segments, S α , partition the model contour S, i. [sent-140, score-0.6]
</p><p>37 The segments Sα in level α reﬁne the 1 m segments Sα+1 in level α + 1, i. [sent-143, score-0.882]
</p><p>38 , segments in the level α + 1 are unions of one or more consecutive segments in the level α. [sent-145, score-0.882]
</p><p>39 On each level α we have a graph structure G α = (S α , E α ), where E α is the set of edges governing the relations between segments in S α , and we have a forest composed of trees that link nodes at different levels. [sent-146, score-0.617]
</p><p>40 1 we have eight segments on the level zero s 0 , . [sent-156, score-0.441]
</p><p>41 , s0 , 1 8 and four segments on the level one s 1 = s 0 ∪ s 0 , s1 = s 0 ∪ s 0 , s1 = s 0 ∪ s 0 , s1 = s 0 ∪ s 0 . [sent-159, score-0.441]
</p><p>42 1 1 2 2 3 4 3 5 6 4 7 8 This construction leads to a tree structure relation among segments at different levels. [sent-160, score-0.477]
</p><p>43 The range of each random variable F iα i is the set of contour segments X = {x 1 , . [sent-164, score-0.888]
</p><p>44 We introduce a new operator acting on random variables, called append operator. [sent-193, score-0.318]
</p><p>45 The append random variable, ⊕Y, with distribution deﬁned below, takes values in the set of pairs, {1, . [sent-206, score-0.293]
</p><p>46 By slightly abusing our notation, we deﬁne ⊕T i as the append of all random variables that are nodes of tree Ti . [sent-221, score-0.387]
</p><p>47 After optimizing a regular RF in (10) that contains append RVs, we obtain as the solution updated distributions of the append RVs. [sent-249, score-0.56]
</p><p>48 From them, we can easily reconstruct the updated distributions of the original RVs from the multiscale RF in (2) by the construction of the append RVs. [sent-250, score-0.488]
</p><p>49 Going back to our application in contour grouping, the RV ⊕T 2 is an append of three RVs representing segments 2, 7, 8 in Fig. [sent-254, score-1.135]
</p><p>50 , which of the model segments 2, 7, 8 is assigned to image segment x 5 . [sent-259, score-0.698]
</p><p>51 We can also make this competition soft (with more then one winner) if we select local maxima of the discrete distribution of ⊕T 2 , which may lead to assigning more than one of model segments 2, 7, 8 to image segments. [sent-260, score-0.554]
</p><p>52 4  3 Computing the label assignment with relaxation labeling There exist several approaches to compute the assignment f that optimizes the relational structure of a given RF [7], i. [sent-262, score-0.403]
</p><p>53 , n ranges over the possible labels, which in our case are the contour segments X = {x 1 , . [sent-285, score-0.884]
</p><p>54 , xn } extracted from a given image, and index i a ranges over the RVs that are appended to ⊕T a , which we denote with ia ∈ a. [sent-288, score-0.389]
</p><p>55 1, p 2 (7, x5 ) denotes the probability that contour segment 7 is assigned to an image segment x 5 , and 2 is the index of RV ⊕T 2 . [sent-291, score-1.0]
</p><p>56 We recall that ⊕T2 is an append of three RVs representing segments 2, 7, 8 in Fig. [sent-292, score-0.648]
</p><p>57 In Section 5, p 2 (7, x5 ) is modeled as a Gaussian of the shape dissimilarity between model contour segment 7 and image contour segment 5. [sent-294, score-1.599]
</p><p>58 For example, C2,3 ((7, x5 ), (9, x8 )) models the compatibility of assignment of model segment 7 (part of model tree 2) to image segment x 5 with the assignment of model segment 9 (part of model tree 3) to image segment x 8 . [sent-298, score-1.461]
</p><p>59 Since segment 9 is above segment 7 in the model contour, it is reasonable to assign high compatibility only if the same holds for the image segments, i. [sent-300, score-0.572]
</p><p>60 The RL algorithm iteratively estimates the change in the probability p a (ia , xj ) by: δpa (ia , xj ) =  Ca,b ((ia , xj ), (ib , xk )) · pb (ib , xk ),  (11)  b=1,. [sent-303, score-0.323]
</p><p>61 ,m: b=a ib ∈b xk ∈X: xk =xj  where b varies over all append random variables ⊕T b different form ⊕T a and ib varies over all compound RVs that are combined by append to ⊕T b . [sent-306, score-1.001]
</p><p>62 Then the probability is updated by pa (ia , xj ) =  ia ∈a  pa (ia , xj )[1 + δpa (ia , xj )] , xk ∈X pa (ia , xk )[1 + δpa (ia , xk )]  (12)  The double sum in the denominator simply normalizes the distribution of ⊕T a so that it sums to one. [sent-307, score-0.812]
</p><p>63 , m (append RVs), all ia ∈ a, and all labels xj ∈ X. [sent-311, score-0.347]
</p><p>64 4 A contour grouping example We provide a simple but real example to illustrate how our multiscale RF framework solves a concrete contour grouping instance. [sent-313, score-1.438]
</p><p>65 Let F i be a RV corresponding to model contour segment s i for i = 1, . [sent-316, score-0.706]
</p><p>66 The append RVs determined by these trees are: ⊕T1 = F1 ⊕ F5 ⊕ F6 , ⊕T2 = F2 ⊕ F7 ⊕ F8 , ⊕T3 = F3 ⊕ F9 ⊕ F10 , ⊕T4 = F4 ⊕ F11 ⊕ F12 We obtain a regular (single level) RF with the four append RVs, T = (⊕T 1 , ⊕T2 , ⊕T3 , ⊕T4 ), and with the graph structure G = (T, E) determined by Eq. [sent-329, score-0.631]
</p><p>67 2(b), and use a low level edge linking to obtain edge segments in Fig. [sent-333, score-0.651]
</p><p>68 However, the label set of each append RV is different, e. [sent-341, score-0.344]
</p><p>69 , the label set of ⊕T1 is equal to {1, 5, 6} × X, where ⊕T 1 = (1, x5 ) denotes the assignment of F 1 = x5 representing mapping model segment 1 to image segment 5. [sent-343, score-0.708]
</p><p>70 Hence p 1 (ia , xj ) = p(⊕T1 = (ia , xj )) for ia = 1, j = 5 denotes the probability of mapping model segment i a = 1 to image segment j = 5. [sent-344, score-0.927]
</p><p>71 They are presented in the format RV: model segment → edge segment: ⊕T1 : 1 → x12 ; ⊕T2 : 5 → x10 ; ⊕T3 : 8 → x7 ; ⊕T4 : 4 → x5 . [sent-350, score-0.306]
</p><p>72 Observe that many model segments remained unmatched, since there they do not have any corresponding segments in the image 2(c). [sent-351, score-0.881]
</p><p>73 This very desirable property results from the label assignment competition within each append RV ⊕T a for a = 1, 2, 3, 4. [sent-352, score-0.493]
</p><p>74 8 1  14 16  6 7 10 5  4  13  9  8  4 12  5  1  2 3 15 11  (a)  (b)  (c)  (d)  Figure 2: (c) The 16 edge segments form our label set X = {x 1 , x2 , . [sent-357, score-0.539]
</p><p>75 (d) The numbers and colors indicate the assignment of the model segments from Fig. [sent-361, score-0.521]
</p><p>76 5 Geometric contour relations In this section, we provide a brief description of contour segment relations used to assign labels for contour grouping. [sent-363, score-1.766]
</p><p>77 First, the probability p a (ia , xj ) is set to be a Gaussian of shape dissimilarity between model segment i a and image segment x j . [sent-365, score-0.69]
</p><p>78 To make our matching scale invariant, we sample each model and image segment with the same number of sample points. [sent-367, score-0.385]
</p><p>79 To make our relations scale invariant, all distances are normalized by the sum of the lengths of segments i and i . [sent-369, score-0.433]
</p><p>80 3(b) extracted by edge detector [8], we employ a low level edge linking method to obtain edge segments as shown in 3(c), where the 27 edge segments form our label set X = {x 1 , . [sent-372, score-1.295]
</p><p>81 3(d) illustrates our shape contour model and its two level multiscale structure of 10 contour segments. [sent-377, score-1.346]
</p><p>82 3(e) shows the result of contour grouping obtained in the framework of the proposed 6  append MSRF. [sent-379, score-0.921]
</p><p>83 Out of 10 model segments, only 4 have corresponding edge segments in the image, and our approach correctly determined a label assignments reﬂecting this fact. [sent-382, score-0.582]
</p><p>84 3(f) shows a model with a ﬁxed single level structure, and its contour grouping result computed with classical RL can be found in Fig. [sent-385, score-0.738]
</p><p>85 We observe that model segment 2 on giraffe’s head has no matching contour in the image, but is nevertheless incorrectly assigned. [sent-387, score-0.789]
</p><p>86 This wrong assignment inﬂuences model contour 4, and leads to another wrong assignment. [sent-388, score-0.63]
</p><p>87 Since contour 3 ﬁnds a good match in the image, we correctly obtain (through our append RV structure) that that there is not match for segment 2. [sent-391, score-0.984]
</p><p>88 By mapping the model segments to the image segments, we enforce the existence of a solution. [sent-393, score-0.503]
</p><p>89 Even if no target shape is present in a given image, our approach will ”hallucinate” a matching conﬁguration of edge segments in the image. [sent-394, score-0.618]
</p><p>90 In our approach, we can easily distinguish hallucinated contours from true contours, since when the RF optimization is completed, we obtain the assignment of contour segments, i. [sent-397, score-0.667]
</p><p>91 , we know a global correspondence between model segments and image segments. [sent-399, score-0.524]
</p><p>92 4 and 5, we show several examples of contour grouping obtained by the proposed MSRF method on the ETHZ data set [4]. [sent-403, score-0.651]
</p><p>93 We only use two contour models, the swan model (Fig. [sent-404, score-0.538]
</p><p>94 Model contours are decomposed into segments by introducing break points at high curvature points. [sent-408, score-0.457]
</p><p>95 Edge contour segments in the test images have been automatically computed by a low level edge linking process. [sent-409, score-1.08]
</p><p>96 Noise and shape variations cause the edge segments to vary a lot from image to image. [sent-410, score-0.654]
</p><p>97 7 Conclusions Since edges, and consequently, contour parts vary signiﬁcantly in real images, it is necessary to make decomposition of model contours into segments ﬂexible. [sent-412, score-0.973]
</p><p>98 The proposed multiscale construction permits us to have a very ﬂexible decomposition that can adapt to different conﬁgurations of contour parts in the image. [sent-413, score-0.725]
</p><p>99 We introduce a novel multiscale random ﬁeld interpretation based on the append operator that leads to efﬁcient optimization. [sent-414, score-0.512]
</p><p>100 A multiscale random ﬁeld model for bayesian image segmentation. [sent-430, score-0.318]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('contour', 0.487), ('segments', 0.378), ('rvs', 0.362), ('ia', 0.282), ('append', 0.27), ('segment', 0.195), ('multiscale', 0.17), ('rf', 0.162), ('grouping', 0.147), ('ib', 0.134), ('rv', 0.124), ('msrf', 0.121), ('assignment', 0.119), ('image', 0.101), ('fm', 0.101), ('tm', 0.091), ('shape', 0.088), ('edge', 0.087), ('label', 0.074), ('ethz', 0.067), ('matching', 0.065), ('xj', 0.065), ('xk', 0.064), ('level', 0.063), ('contours', 0.061), ('compatibility', 0.057), ('relations', 0.055), ('compete', 0.048), ('rfs', 0.047), ('rl', 0.045), ('tree', 0.044), ('deformable', 0.043), ('pa', 0.041), ('msrfs', 0.04), ('elds', 0.038), ('linking', 0.036), ('giraffe', 0.035), ('parent', 0.035), ('trees', 0.034), ('relaxation', 0.034), ('labeling', 0.03), ('graph', 0.03), ('detection', 0.03), ('nodes', 0.03), ('competition', 0.03), ('images', 0.029), ('children', 0.028), ('construction', 0.028), ('structure', 0.027), ('sm', 0.027), ('huazhong', 0.027), ('latecki', 0.027), ('rosenfeld', 0.027), ('swan', 0.027), ('pyramid', 0.026), ('xn', 0.026), ('yk', 0.025), ('operator', 0.025), ('interpretation', 0.024), ('eld', 0.024), ('ti', 0.024), ('model', 0.024), ('maximizes', 0.024), ('temple', 0.023), ('chamfer', 0.023), ('tb', 0.023), ('object', 0.023), ('parts', 0.023), ('tj', 0.023), ('random', 0.023), ('dissimilarity', 0.022), ('index', 0.022), ('linked', 0.022), ('appended', 0.022), ('fb', 0.022), ('ferrari', 0.022), ('compound', 0.022), ('soft', 0.021), ('global', 0.021), ('fields', 0.021), ('variables', 0.02), ('ta', 0.02), ('updated', 0.02), ('template', 0.02), ('ranges', 0.019), ('assignments', 0.019), ('shapes', 0.018), ('decomposed', 0.018), ('winner', 0.018), ('extracted', 0.018), ('usually', 0.018), ('observe', 0.018), ('electronics', 0.017), ('texture', 0.017), ('stress', 0.017), ('proposed', 0.017), ('classical', 0.017), ('match', 0.016), ('fa', 0.016), ('china', 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999958 <a title="147-tfidf-1" href="./nips-2008-Multiscale_Random_Fields_with_Application_to_Contour_Grouping.html">147 nips-2008-Multiscale Random Fields with Application to Contour Grouping</a></p>
<p>Author: Longin J. Latecki, Chengen Lu, Marc Sobel, Xiang Bai</p><p>Abstract: We introduce a new interpretation of multiscale random ﬁelds (MSRFs) that admits efﬁcient optimization in the framework of regular (single level) random ﬁelds (RFs). It is based on a new operator, called append, that combines sets of random variables (RVs) to single RVs. We assume that a MSRF can be decomposed into disjoint trees that link RVs at different pyramid levels. The append operator is then applied to map RVs in each tree structure to a single RV. We demonstrate the usefulness of the proposed approach on a challenging task involving grouping contours of target shapes in images. It provides a natural representation of multiscale contour models, which is needed in order to cope with unstable contour decompositions. The append operator allows us to ﬁnd optimal image segment labels using the classical framework of relaxation labeling. Alternative methods like Markov Chain Monte Carlo (MCMC) could also be used.</p><p>2 0.24526483 <a title="147-tfidf-2" href="./nips-2008-Grouping_Contours_Via_a_Related_Image.html">95 nips-2008-Grouping Contours Via a Related Image</a></p>
<p>Author: Praveen Srinivasan, Liming Wang, Jianbo Shi</p><p>Abstract: Contours have been established in the biological and computer vision literature as a compact yet descriptive representation of object shape. While individual contours provide structure, they lack the large spatial support of region segments (which lack internal structure). We present a method for further grouping of contours in an image using their relationship to the contours of a second, related image. Stereo, motion, and similarity all provide cues that can aid this task; contours that have similar transformations relating them to their matching contours in the second image likely belong to a single group. To ﬁnd matches for contours, we rely only on shape, which applies directly to all three modalities without modiﬁcation, in contrast to the specialized approaches developed for each independently. Visually salient contours are extracted in each image, along with a set of candidate transformations for aligning subsets of them. For each transformation, groups of contours with matching shape across the two images are identiﬁed to provide a context for evaluating matches of individual contour points across the images. The resulting contexts of contours are used to perform a ﬁnal grouping on contours in the original image while simultaneously ﬁnding matches in the related image, again by shape matching. We demonstrate grouping results on image pairs consisting of stereo, motion, and similar images. Our method also produces qualitatively better results against a baseline method that does not use the inferred contexts. 1</p><p>3 0.21376471 <a title="147-tfidf-3" href="./nips-2008-A_%60%60Shape_Aware%27%27_Model_for_semi-supervised_Learning_of_Objects_and_its_Context.html">6 nips-2008-A ``Shape Aware'' Model for semi-supervised Learning of Objects and its Context</a></p>
<p>Author: Abhinav Gupta, Jianbo Shi, Larry S. Davis</p><p>Abstract: We present an approach that combines bag-of-words and spatial models to perform semantic and syntactic analysis for recognition of an object based on its internal appearance and its context. We argue that while object recognition requires modeling relative spatial locations of image features within the object, a bag-of-word is sufﬁcient for representing context. Learning such a model from weakly labeled data involves labeling of features into two classes: foreground(object) or “informative” background(context). We present a “shape-aware” model which utilizes contour information for efﬁcient and accurate labeling of features in the image. Our approach iterates between an MCMC-based labeling and contour based labeling of features to integrate co-occurrence of features and shape similarity. 1</p><p>4 0.16979124 <a title="147-tfidf-4" href="./nips-2008-Shared_Segmentation_of_Natural_Scenes_Using_Dependent_Pitman-Yor_Processes.html">208 nips-2008-Shared Segmentation of Natural Scenes Using Dependent Pitman-Yor Processes</a></p>
<p>Author: Erik B. Sudderth, Michael I. Jordan</p><p>Abstract: We develop a statistical framework for the simultaneous, unsupervised segmentation and discovery of visual object categories from image databases. Examining a large set of manually segmented scenes, we show that object frequencies and segment sizes both follow power law distributions, which are well modeled by the Pitman–Yor (PY) process. This nonparametric prior distribution leads to learning algorithms which discover an unknown set of objects, and segmentation methods which automatically adapt their resolution to each image. Generalizing previous applications of PY processes, we use Gaussian processes to discover spatially contiguous segments which respect image boundaries. Using a novel family of variational approximations, our approach produces segmentations which compare favorably to state-of-the-art methods, while simultaneously discovering categories shared among natural scenes. 1</p><p>5 0.087590076 <a title="147-tfidf-5" href="./nips-2008-Robust_Near-Isometric_Matching_via_Structured_Learning_of_Graphical_Models.html">201 nips-2008-Robust Near-Isometric Matching via Structured Learning of Graphical Models</a></p>
<p>Author: Alex J. Smola, Julian J. Mcauley, Tibério S. Caetano</p><p>Abstract: Models for near-rigid shape matching are typically based on distance-related features, in order to infer matches that are consistent with the isometric assumption. However, real shapes from image datasets, even when expected to be related by “almost isometric” transformations, are actually subject not only to noise but also, to some limited degree, to variations in appearance and scale. In this paper, we introduce a graphical model that parameterises appearance, distance, and angle features and we learn all of the involved parameters via structured prediction. The outcome is a model for near-rigid shape matching which is robust in the sense that it is able to capture the possibly limited but still important scale and appearance variations. Our experimental results reveal substantial improvements upon recent successful models, while maintaining similar running times. 1</p><p>6 0.084681883 <a title="147-tfidf-6" href="./nips-2008-Learning_Hybrid_Models_for_Image_Annotation_with_Partially_Labeled_Data.html">116 nips-2008-Learning Hybrid Models for Image Annotation with Partially Labeled Data</a></p>
<p>7 0.081416808 <a title="147-tfidf-7" href="./nips-2008-Recursive_Segmentation_and_Recognition_Templates_for_2D_Parsing.html">191 nips-2008-Recursive Segmentation and Recognition Templates for 2D Parsing</a></p>
<p>8 0.073329896 <a title="147-tfidf-8" href="./nips-2008-Shape-Based_Object_Localization_for_Descriptive_Classification.html">207 nips-2008-Shape-Based Object Localization for Descriptive Classification</a></p>
<p>9 0.072393805 <a title="147-tfidf-9" href="./nips-2008-Improved_Moves_for_Truncated_Convex_Models.html">104 nips-2008-Improved Moves for Truncated Convex Models</a></p>
<p>10 0.070916899 <a title="147-tfidf-10" href="./nips-2008-Kernel_Change-point_Analysis.html">111 nips-2008-Kernel Change-point Analysis</a></p>
<p>11 0.070777513 <a title="147-tfidf-11" href="./nips-2008-Multi-Level_Active_Prediction_of_Useful_Image_Annotations_for_Recognition.html">142 nips-2008-Multi-Level Active Prediction of Useful Image Annotations for Recognition</a></p>
<p>12 0.066257358 <a title="147-tfidf-12" href="./nips-2008-Breaking_Audio_CAPTCHAs.html">41 nips-2008-Breaking Audio CAPTCHAs</a></p>
<p>13 0.062294941 <a title="147-tfidf-13" href="./nips-2008-Cascaded_Classification_Models%3A_Combining_Models_for_Holistic_Scene_Understanding.html">42 nips-2008-Cascaded Classification Models: Combining Models for Holistic Scene Understanding</a></p>
<p>14 0.061457615 <a title="147-tfidf-14" href="./nips-2008-Learning_a_discriminative_hidden_part_model_for_human_action_recognition.html">119 nips-2008-Learning a discriminative hidden part model for human action recognition</a></p>
<p>15 0.058940854 <a title="147-tfidf-15" href="./nips-2008-Kernelized_Sorting.html">113 nips-2008-Kernelized Sorting</a></p>
<p>16 0.055367675 <a title="147-tfidf-16" href="./nips-2008-Natural_Image_Denoising_with_Convolutional_Networks.html">148 nips-2008-Natural Image Denoising with Convolutional Networks</a></p>
<p>17 0.051015668 <a title="147-tfidf-17" href="./nips-2008-Non-stationary_dynamic_Bayesian_networks.html">152 nips-2008-Non-stationary dynamic Bayesian networks</a></p>
<p>18 0.043728083 <a title="147-tfidf-18" href="./nips-2008-Nonrigid_Structure_from_Motion_in_Trajectory_Space.html">157 nips-2008-Nonrigid Structure from Motion in Trajectory Space</a></p>
<p>19 0.041831199 <a title="147-tfidf-19" href="./nips-2008-Analyzing_human_feature_learning_as_nonparametric_Bayesian_inference.html">26 nips-2008-Analyzing human feature learning as nonparametric Bayesian inference</a></p>
<p>20 0.039268561 <a title="147-tfidf-20" href="./nips-2008-Clusters_and_Coarse_Partitions_in_LP_Relaxations.html">49 nips-2008-Clusters and Coarse Partitions in LP Relaxations</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2008_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.138), (1, -0.09), (2, 0.114), (3, -0.149), (4, 0.017), (5, -0.047), (6, -0.063), (7, -0.169), (8, 0.047), (9, -0.069), (10, -0.107), (11, -0.074), (12, 0.108), (13, -0.129), (14, 0.112), (15, 0.008), (16, 0.095), (17, 0.115), (18, -0.059), (19, 0.011), (20, -0.043), (21, 0.033), (22, 0.027), (23, 0.074), (24, 0.044), (25, 0.202), (26, 0.083), (27, 0.097), (28, 0.009), (29, 0.084), (30, -0.124), (31, -0.031), (32, 0.031), (33, 0.07), (34, -0.059), (35, 0.038), (36, -0.006), (37, -0.03), (38, 0.033), (39, 0.065), (40, -0.122), (41, 0.045), (42, 0.047), (43, -0.019), (44, 0.05), (45, -0.026), (46, 0.129), (47, -0.046), (48, -0.077), (49, 0.042)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95958579 <a title="147-lsi-1" href="./nips-2008-Multiscale_Random_Fields_with_Application_to_Contour_Grouping.html">147 nips-2008-Multiscale Random Fields with Application to Contour Grouping</a></p>
<p>Author: Longin J. Latecki, Chengen Lu, Marc Sobel, Xiang Bai</p><p>Abstract: We introduce a new interpretation of multiscale random ﬁelds (MSRFs) that admits efﬁcient optimization in the framework of regular (single level) random ﬁelds (RFs). It is based on a new operator, called append, that combines sets of random variables (RVs) to single RVs. We assume that a MSRF can be decomposed into disjoint trees that link RVs at different pyramid levels. The append operator is then applied to map RVs in each tree structure to a single RV. We demonstrate the usefulness of the proposed approach on a challenging task involving grouping contours of target shapes in images. It provides a natural representation of multiscale contour models, which is needed in order to cope with unstable contour decompositions. The append operator allows us to ﬁnd optimal image segment labels using the classical framework of relaxation labeling. Alternative methods like Markov Chain Monte Carlo (MCMC) could also be used.</p><p>2 0.86705083 <a title="147-lsi-2" href="./nips-2008-Grouping_Contours_Via_a_Related_Image.html">95 nips-2008-Grouping Contours Via a Related Image</a></p>
<p>Author: Praveen Srinivasan, Liming Wang, Jianbo Shi</p><p>Abstract: Contours have been established in the biological and computer vision literature as a compact yet descriptive representation of object shape. While individual contours provide structure, they lack the large spatial support of region segments (which lack internal structure). We present a method for further grouping of contours in an image using their relationship to the contours of a second, related image. Stereo, motion, and similarity all provide cues that can aid this task; contours that have similar transformations relating them to their matching contours in the second image likely belong to a single group. To ﬁnd matches for contours, we rely only on shape, which applies directly to all three modalities without modiﬁcation, in contrast to the specialized approaches developed for each independently. Visually salient contours are extracted in each image, along with a set of candidate transformations for aligning subsets of them. For each transformation, groups of contours with matching shape across the two images are identiﬁed to provide a context for evaluating matches of individual contour points across the images. The resulting contexts of contours are used to perform a ﬁnal grouping on contours in the original image while simultaneously ﬁnding matches in the related image, again by shape matching. We demonstrate grouping results on image pairs consisting of stereo, motion, and similar images. Our method also produces qualitatively better results against a baseline method that does not use the inferred contexts. 1</p><p>3 0.7180382 <a title="147-lsi-3" href="./nips-2008-A_%60%60Shape_Aware%27%27_Model_for_semi-supervised_Learning_of_Objects_and_its_Context.html">6 nips-2008-A ``Shape Aware'' Model for semi-supervised Learning of Objects and its Context</a></p>
<p>Author: Abhinav Gupta, Jianbo Shi, Larry S. Davis</p><p>Abstract: We present an approach that combines bag-of-words and spatial models to perform semantic and syntactic analysis for recognition of an object based on its internal appearance and its context. We argue that while object recognition requires modeling relative spatial locations of image features within the object, a bag-of-word is sufﬁcient for representing context. Learning such a model from weakly labeled data involves labeling of features into two classes: foreground(object) or “informative” background(context). We present a “shape-aware” model which utilizes contour information for efﬁcient and accurate labeling of features in the image. Our approach iterates between an MCMC-based labeling and contour based labeling of features to integrate co-occurrence of features and shape similarity. 1</p><p>4 0.55502617 <a title="147-lsi-4" href="./nips-2008-Shape-Based_Object_Localization_for_Descriptive_Classification.html">207 nips-2008-Shape-Based Object Localization for Descriptive Classification</a></p>
<p>Author: Geremy Heitz, Gal Elidan, Benjamin Packer, Daphne Koller</p><p>Abstract: Discriminative tasks, including object categorization and detection, are central components of high-level computer vision. Sometimes, however, we are interested in more reﬁned aspects of the object in an image, such as pose or particular regions. In this paper we develop a method (LOOPS) for learning a shape and image feature model that can be trained on a particular object class, and used to outline instances of the class in novel images. Furthermore, while the training data consists of uncorresponded outlines, the resulting LOOPS model contains a set of landmark points that appear consistently across instances, and can be accurately localized in an image. Our model achieves state-of-the-art results in precisely outlining objects that exhibit large deformations and articulations in cluttered natural images. These localizations can then be used to address a range of tasks, including descriptive classiﬁcation, search, and clustering. 1</p><p>5 0.54884022 <a title="147-lsi-5" href="./nips-2008-Robust_Near-Isometric_Matching_via_Structured_Learning_of_Graphical_Models.html">201 nips-2008-Robust Near-Isometric Matching via Structured Learning of Graphical Models</a></p>
<p>Author: Alex J. Smola, Julian J. Mcauley, Tibério S. Caetano</p><p>Abstract: Models for near-rigid shape matching are typically based on distance-related features, in order to infer matches that are consistent with the isometric assumption. However, real shapes from image datasets, even when expected to be related by “almost isometric” transformations, are actually subject not only to noise but also, to some limited degree, to variations in appearance and scale. In this paper, we introduce a graphical model that parameterises appearance, distance, and angle features and we learn all of the involved parameters via structured prediction. The outcome is a model for near-rigid shape matching which is robust in the sense that it is able to capture the possibly limited but still important scale and appearance variations. Our experimental results reveal substantial improvements upon recent successful models, while maintaining similar running times. 1</p><p>6 0.51048011 <a title="147-lsi-6" href="./nips-2008-Shared_Segmentation_of_Natural_Scenes_Using_Dependent_Pitman-Yor_Processes.html">208 nips-2008-Shared Segmentation of Natural Scenes Using Dependent Pitman-Yor Processes</a></p>
<p>7 0.39673379 <a title="147-lsi-7" href="./nips-2008-Natural_Image_Denoising_with_Convolutional_Networks.html">148 nips-2008-Natural Image Denoising with Convolutional Networks</a></p>
<p>8 0.39354512 <a title="147-lsi-8" href="./nips-2008-Breaking_Audio_CAPTCHAs.html">41 nips-2008-Breaking Audio CAPTCHAs</a></p>
<p>9 0.36681727 <a title="147-lsi-9" href="./nips-2008-Recursive_Segmentation_and_Recognition_Templates_for_2D_Parsing.html">191 nips-2008-Recursive Segmentation and Recognition Templates for 2D Parsing</a></p>
<p>10 0.34620416 <a title="147-lsi-10" href="./nips-2008-Learning_Hybrid_Models_for_Image_Annotation_with_Partially_Labeled_Data.html">116 nips-2008-Learning Hybrid Models for Image Annotation with Partially Labeled Data</a></p>
<p>11 0.32496291 <a title="147-lsi-11" href="./nips-2008-Cascaded_Classification_Models%3A_Combining_Models_for_Holistic_Scene_Understanding.html">42 nips-2008-Cascaded Classification Models: Combining Models for Holistic Scene Understanding</a></p>
<p>12 0.32006097 <a title="147-lsi-12" href="./nips-2008-Kernel_Change-point_Analysis.html">111 nips-2008-Kernel Change-point Analysis</a></p>
<p>13 0.29546526 <a title="147-lsi-13" href="./nips-2008-The_Mondrian_Process.html">236 nips-2008-The Mondrian Process</a></p>
<p>14 0.28844228 <a title="147-lsi-14" href="./nips-2008-Learning_a_discriminative_hidden_part_model_for_human_action_recognition.html">119 nips-2008-Learning a discriminative hidden part model for human action recognition</a></p>
<p>15 0.27905354 <a title="147-lsi-15" href="./nips-2008-Online_Models_for_Content_Optimization.html">169 nips-2008-Online Models for Content Optimization</a></p>
<p>16 0.27366987 <a title="147-lsi-16" href="./nips-2008-Improved_Moves_for_Truncated_Convex_Models.html">104 nips-2008-Improved Moves for Truncated Convex Models</a></p>
<p>17 0.26253679 <a title="147-lsi-17" href="./nips-2008-Kernelized_Sorting.html">113 nips-2008-Kernelized Sorting</a></p>
<p>18 0.26098651 <a title="147-lsi-18" href="./nips-2008-An_ideal_observer_model_of_infant_object_perception.html">23 nips-2008-An ideal observer model of infant object perception</a></p>
<p>19 0.25219378 <a title="147-lsi-19" href="./nips-2008-Nonrigid_Structure_from_Motion_in_Trajectory_Space.html">157 nips-2008-Nonrigid Structure from Motion in Trajectory Space</a></p>
<p>20 0.2334947 <a title="147-lsi-20" href="./nips-2008-Non-stationary_dynamic_Bayesian_networks.html">152 nips-2008-Non-stationary dynamic Bayesian networks</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2008_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(6, 0.036), (7, 0.045), (12, 0.063), (28, 0.117), (30, 0.35), (57, 0.079), (59, 0.022), (63, 0.024), (71, 0.012), (77, 0.034), (78, 0.033), (83, 0.068)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.83077693 <a title="147-lda-1" href="./nips-2008-Short-Term_Depression_in_VLSI_Stochastic_Synapse.html">209 nips-2008-Short-Term Depression in VLSI Stochastic Synapse</a></p>
<p>Author: Peng Xu, Timothy K. Horiuchi, Pamela A. Abshire</p><p>Abstract: We report a compact realization of short-term depression (STD) in a VLSI stochastic synapse. The behavior of the circuit is based on a subtractive single release model of STD. Experimental results agree well with simulation and exhibit expected STD behavior: the transmitted spike train has negative autocorrelation and lower power spectral density at low frequencies which can remove redundancy in the input spike train, and the mean transmission probability is inversely proportional to the input spike rate which has been suggested as an automatic gain control mechanism in neural systems. The dynamic stochastic synapse could potentially be a powerful addition to existing deterministic VLSI spiking neural systems. 1</p><p>same-paper 2 0.69804269 <a title="147-lda-2" href="./nips-2008-Multiscale_Random_Fields_with_Application_to_Contour_Grouping.html">147 nips-2008-Multiscale Random Fields with Application to Contour Grouping</a></p>
<p>Author: Longin J. Latecki, Chengen Lu, Marc Sobel, Xiang Bai</p><p>Abstract: We introduce a new interpretation of multiscale random ﬁelds (MSRFs) that admits efﬁcient optimization in the framework of regular (single level) random ﬁelds (RFs). It is based on a new operator, called append, that combines sets of random variables (RVs) to single RVs. We assume that a MSRF can be decomposed into disjoint trees that link RVs at different pyramid levels. The append operator is then applied to map RVs in each tree structure to a single RV. We demonstrate the usefulness of the proposed approach on a challenging task involving grouping contours of target shapes in images. It provides a natural representation of multiscale contour models, which is needed in order to cope with unstable contour decompositions. The append operator allows us to ﬁnd optimal image segment labels using the classical framework of relaxation labeling. Alternative methods like Markov Chain Monte Carlo (MCMC) could also be used.</p><p>3 0.44972855 <a title="147-lda-3" href="./nips-2008-Learning_Hybrid_Models_for_Image_Annotation_with_Partially_Labeled_Data.html">116 nips-2008-Learning Hybrid Models for Image Annotation with Partially Labeled Data</a></p>
<p>Author: Xuming He, Richard S. Zemel</p><p>Abstract: Extensive labeled data for image annotation systems, which learn to assign class labels to image regions, is difﬁcult to obtain. We explore a hybrid model framework for utilizing partially labeled data that integrates a generative topic model for image appearance with discriminative label prediction. We propose three alternative formulations for imposing a spatial smoothness prior on the image labels. Tests of the new models and some baseline approaches on three real image datasets demonstrate the effectiveness of incorporating the latent structure. 1</p><p>4 0.44506517 <a title="147-lda-4" href="./nips-2008-Grouping_Contours_Via_a_Related_Image.html">95 nips-2008-Grouping Contours Via a Related Image</a></p>
<p>Author: Praveen Srinivasan, Liming Wang, Jianbo Shi</p><p>Abstract: Contours have been established in the biological and computer vision literature as a compact yet descriptive representation of object shape. While individual contours provide structure, they lack the large spatial support of region segments (which lack internal structure). We present a method for further grouping of contours in an image using their relationship to the contours of a second, related image. Stereo, motion, and similarity all provide cues that can aid this task; contours that have similar transformations relating them to their matching contours in the second image likely belong to a single group. To ﬁnd matches for contours, we rely only on shape, which applies directly to all three modalities without modiﬁcation, in contrast to the specialized approaches developed for each independently. Visually salient contours are extracted in each image, along with a set of candidate transformations for aligning subsets of them. For each transformation, groups of contours with matching shape across the two images are identiﬁed to provide a context for evaluating matches of individual contour points across the images. The resulting contexts of contours are used to perform a ﬁnal grouping on contours in the original image while simultaneously ﬁnding matches in the related image, again by shape matching. We demonstrate grouping results on image pairs consisting of stereo, motion, and similar images. Our method also produces qualitatively better results against a baseline method that does not use the inferred contexts. 1</p><p>5 0.43694976 <a title="147-lda-5" href="./nips-2008-Semi-supervised_Learning_with_Weakly-Related_Unlabeled_Data_%3A_Towards_Better_Text_Categorization.html">205 nips-2008-Semi-supervised Learning with Weakly-Related Unlabeled Data : Towards Better Text Categorization</a></p>
<p>Author: Liu Yang, Rong Jin, Rahul Sukthankar</p><p>Abstract: The cluster assumption is exploited by most semi-supervised learning (SSL) methods. However, if the unlabeled data is merely weakly related to the target classes, it becomes questionable whether driving the decision boundary to the low density regions of the unlabeled data will help the classiﬁcation. In such case, the cluster assumption may not be valid; and consequently how to leverage this type of unlabeled data to enhance the classiﬁcation accuracy becomes a challenge. We introduce “Semi-supervised Learning with Weakly-Related Unlabeled Data” (SSLW), an inductive method that builds upon the maximum-margin approach, towards a better usage of weakly-related unlabeled information. Although the SSLW could improve a wide range of classiﬁcation tasks, in this paper, we focus on text categorization with a small training pool. The key assumption behind this work is that, even with different topics, the word usage patterns across different corpora tends to be consistent. To this end, SSLW estimates the optimal wordcorrelation matrix that is consistent with both the co-occurrence information derived from the weakly-related unlabeled documents and the labeled documents. For empirical evaluation, we present a direct comparison with a number of stateof-the-art methods for inductive semi-supervised learning and text categorization. We show that SSLW results in a signiﬁcant improvement in categorization accuracy, equipped with a small training set and an unlabeled resource that is weakly related to the test domain.</p><p>6 0.43680662 <a title="147-lda-6" href="./nips-2008-Cascaded_Classification_Models%3A_Combining_Models_for_Holistic_Scene_Understanding.html">42 nips-2008-Cascaded Classification Models: Combining Models for Holistic Scene Understanding</a></p>
<p>7 0.43327671 <a title="147-lda-7" href="./nips-2008-Shared_Segmentation_of_Natural_Scenes_Using_Dependent_Pitman-Yor_Processes.html">208 nips-2008-Shared Segmentation of Natural Scenes Using Dependent Pitman-Yor Processes</a></p>
<p>8 0.4332296 <a title="147-lda-8" href="./nips-2008-Analyzing_human_feature_learning_as_nonparametric_Bayesian_inference.html">26 nips-2008-Analyzing human feature learning as nonparametric Bayesian inference</a></p>
<p>9 0.43291846 <a title="147-lda-9" href="./nips-2008-Partially_Observed_Maximum_Entropy_Discrimination_Markov_Networks.html">176 nips-2008-Partially Observed Maximum Entropy Discrimination Markov Networks</a></p>
<p>10 0.43245003 <a title="147-lda-10" href="./nips-2008-Unsupervised_Learning_of_Visual_Sense_Models_for_Polysemous_Words.html">246 nips-2008-Unsupervised Learning of Visual Sense Models for Polysemous Words</a></p>
<p>11 0.43237913 <a title="147-lda-11" href="./nips-2008-Dynamic_visual_attention%3A_searching_for_coding_length_increments.html">66 nips-2008-Dynamic visual attention: searching for coding length increments</a></p>
<p>12 0.43216985 <a title="147-lda-12" href="./nips-2008-Shape-Based_Object_Localization_for_Descriptive_Classification.html">207 nips-2008-Shape-Based Object Localization for Descriptive Classification</a></p>
<p>13 0.43169689 <a title="147-lda-13" href="./nips-2008-Regularized_Learning_with_Networks_of_Features.html">194 nips-2008-Regularized Learning with Networks of Features</a></p>
<p>14 0.43022346 <a title="147-lda-14" href="./nips-2008-Relative_Performance_Guarantees_for_Approximate_Inference_in_Latent_Dirichlet_Allocation.html">197 nips-2008-Relative Performance Guarantees for Approximate Inference in Latent Dirichlet Allocation</a></p>
<p>15 0.42960489 <a title="147-lda-15" href="./nips-2008-A_Scalable_Hierarchical_Distributed_Language_Model.html">4 nips-2008-A Scalable Hierarchical Distributed Language Model</a></p>
<p>16 0.4296037 <a title="147-lda-16" href="./nips-2008-Robust_Kernel_Principal_Component_Analysis.html">200 nips-2008-Robust Kernel Principal Component Analysis</a></p>
<p>17 0.4294793 <a title="147-lda-17" href="./nips-2008-Syntactic_Topic_Models.html">229 nips-2008-Syntactic Topic Models</a></p>
<p>18 0.42909727 <a title="147-lda-18" href="./nips-2008-Exploring_Large_Feature_Spaces_with_Hierarchical_Multiple_Kernel_Learning.html">79 nips-2008-Exploring Large Feature Spaces with Hierarchical Multiple Kernel Learning</a></p>
<p>19 0.42837149 <a title="147-lda-19" href="./nips-2008-Dimensionality_Reduction_for_Data_in_Multiple_Feature_Representations.html">63 nips-2008-Dimensionality Reduction for Data in Multiple Feature Representations</a></p>
<p>20 0.42679644 <a title="147-lda-20" href="./nips-2008-Learning_a_discriminative_hidden_part_model_for_human_action_recognition.html">119 nips-2008-Learning a discriminative hidden part model for human action recognition</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
