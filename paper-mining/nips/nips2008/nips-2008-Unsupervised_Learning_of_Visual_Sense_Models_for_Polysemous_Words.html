<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>246 nips-2008-Unsupervised Learning of Visual Sense Models for Polysemous Words</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-246" href="#">nips2008-246</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>246 nips-2008-Unsupervised Learning of Visual Sense Models for Polysemous Words</h1>
<br/><p>Source: <a title="nips-2008-246-pdf" href="http://papers.nips.cc/paper/3389-unsupervised-learning-of-visual-sense-models-for-polysemous-words.pdf">pdf</a></p><p>Author: Kate Saenko, Trevor Darrell</p><p>Abstract: Polysemy is a problem for methods that exploit image search engines to build object category models. Existing unsupervised approaches do not take word sense into consideration. We propose a new method that uses a dictionary to learn models of visual word sense from a large collection of unlabeled web data. The use of LDA to discover a latent sense space makes the model robust despite the very limited nature of dictionary deﬁnitions. The deﬁnitions are used to learn a distribution in the latent space that best represents a sense. The algorithm then uses the text surrounding image links to retrieve images with high probability of a particular dictionary sense. An object classiﬁer is trained on the resulting sense-speciﬁc images. We evaluate our method on a dataset obtained by searching the web for polysemous words. Category classiﬁcation experiments show that our dictionarybased approach outperforms baseline methods. 1</p><p>Reference: <a title="nips-2008-246-reference" href="../nips2008_reference/nips-2008-Unsupervised_Learning_of_Visual_Sense_Models_for_Polysemous_Words_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('keyword', 0.36), ('dict', 0.351), ('mous', 0.303), ('bass', 0.299), ('im', 0.267), ('sens', 0.237), ('watch', 0.235), ('polysem', 0.224), ('text', 0.183), ('word', 0.175), ('web', 0.161), ('search', 0.136), ('lda', 0.117), ('retriev', 0.114), ('unrel', 0.096), ('wordnet', 0.091), ('fac', 0.089), ('speak', 0.081), ('surround', 0.078), ('annot', 0.077)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="246-tfidf-1" href="./nips-2008-Unsupervised_Learning_of_Visual_Sense_Models_for_Polysemous_Words.html">246 nips-2008-Unsupervised Learning of Visual Sense Models for Polysemous Words</a></p>
<p>Author: Kate Saenko, Trevor Darrell</p><p>Abstract: Polysemy is a problem for methods that exploit image search engines to build object category models. Existing unsupervised approaches do not take word sense into consideration. We propose a new method that uses a dictionary to learn models of visual word sense from a large collection of unlabeled web data. The use of LDA to discover a latent sense space makes the model robust despite the very limited nature of dictionary deﬁnitions. The deﬁnitions are used to learn a distribution in the latent space that best represents a sense. The algorithm then uses the text surrounding image links to retrieve images with high probability of a particular dictionary sense. An object classiﬁer is trained on the resulting sense-speciﬁc images. We evaluate our method on a dataset obtained by searching the web for polysemous words. Category classiﬁcation experiments show that our dictionarybased approach outperforms baseline methods. 1</p><p>2 0.28658897 <a title="246-tfidf-2" href="./nips-2008-Supervised_Dictionary_Learning.html">226 nips-2008-Supervised Dictionary Learning</a></p>
<p>Author: Julien Mairal, Jean Ponce, Guillermo Sapiro, Andrew Zisserman, Francis R. Bach</p><p>Abstract: It is now well established that sparse signal models are well suited for restoration tasks and can be effectively learned from audio, image, and video data. Recent research has been aimed at learning discriminative sparse models instead of purely reconstructive ones. This paper proposes a new step in that direction, with a novel sparse representation for signals belonging to different classes in terms of a shared dictionary and discriminative class models. The linear version of the proposed model admits a simple probabilistic interpretation, while its most general variant admits an interpretation in terms of kernels. An optimization framework for learning all the components of the proposed model is presented, along with experimental results on standard handwritten digit and texture classiﬁcation tasks. 1</p><p>3 0.187961 <a title="246-tfidf-3" href="./nips-2008-Multi-Level_Active_Prediction_of_Useful_Image_Annotations_for_Recognition.html">142 nips-2008-Multi-Level Active Prediction of Useful Image Annotations for Recognition</a></p>
<p>Author: Sudheendra Vijayanarasimhan, Kristen Grauman</p><p>Abstract: We introduce a framework for actively learning visual categories from a mixture of weakly and strongly labeled image examples. We propose to allow the categorylearner to strategically choose what annotations it receives—based on both the expected reduction in uncertainty as well as the relative costs of obtaining each annotation. We construct a multiple-instance discriminative classiﬁer based on the initial training data. Then all remaining unlabeled and weakly labeled examples are surveyed to actively determine which annotation ought to be requested next. After each request, the current classiﬁer is incrementally updated. Unlike previous work, our approach accounts for the fact that the optimal use of manual annotation may call for a combination of labels at multiple levels of granularity (e.g., a full segmentation on some images and a present/absent ﬂag on others). As a result, it is possible to learn more accurate category models with a lower total expenditure of manual annotation effort. 1</p><p>4 0.1637471 <a title="246-tfidf-4" href="./nips-2008-Learning_Hybrid_Models_for_Image_Annotation_with_Partially_Labeled_Data.html">116 nips-2008-Learning Hybrid Models for Image Annotation with Partially Labeled Data</a></p>
<p>Author: Xuming He, Richard S. Zemel</p><p>Abstract: Extensive labeled data for image annotation systems, which learn to assign class labels to image regions, is difﬁcult to obtain. We explore a hybrid model framework for utilizing partially labeled data that integrates a generative topic model for image appearance with discriminative label prediction. We propose three alternative formulations for imposing a spatial smoothness prior on the image labels. Tests of the new models and some baseline approaches on three real image datasets demonstrate the effectiveness of incorporating the latent structure. 1</p><p>5 0.12603843 <a title="246-tfidf-5" href="./nips-2008-MCBoost%3A_Multiple_Classifier_Boosting_for_Perceptual_Co-clustering_of_Images_and_Visual_Features.html">130 nips-2008-MCBoost: Multiple Classifier Boosting for Perceptual Co-clustering of Images and Visual Features</a></p>
<p>Author: Tae-kyun Kim, Roberto Cipolla</p><p>Abstract: We present a new co-clustering problem of images and visual features. The problem involves a set of non-object images in addition to a set of object images and features to be co-clustered. Co-clustering is performed in a way that maximises discrimination of object images from non-object images, thus emphasizing discriminative features. This provides a way of obtaining perceptual joint-clusters of object images and features. We tackle the problem by simultaneously boosting multiple strong classiﬁers which compete for images by their expertise. Each boosting classiﬁer is an aggregation of weak-learners, i.e. simple visual features. The obtained classiﬁers are useful for object detection tasks which exhibit multimodalities, e.g. multi-category and multi-view object detection tasks. Experiments on a set of pedestrian images and a face data set demonstrate that the method yields intuitive image clusters with associated features and is much superior to conventional boosting classiﬁers in object detection tasks. 1</p><p>6 0.12101389 <a title="246-tfidf-6" href="./nips-2008-DiscLDA%3A_Discriminative_Learning_for_Dimensionality_Reduction_and_Classification.html">64 nips-2008-DiscLDA: Discriminative Learning for Dimensionality Reduction and Classification</a></p>
<p>7 0.11854986 <a title="246-tfidf-7" href="./nips-2008-Recursive_Segmentation_and_Recognition_Templates_for_2D_Parsing.html">191 nips-2008-Recursive Segmentation and Recognition Templates for 2D Parsing</a></p>
<p>8 0.11805214 <a title="246-tfidf-8" href="./nips-2008-Semi-supervised_Learning_with_Weakly-Related_Unlabeled_Data_%3A_Towards_Better_Text_Categorization.html">205 nips-2008-Semi-supervised Learning with Weakly-Related Unlabeled Data : Towards Better Text Categorization</a></p>
<p>9 0.11487868 <a title="246-tfidf-9" href="./nips-2008-Learning_the_Semantic_Correlation%3A_An_Alternative_Way_to_Gain_from_Unlabeled_Text.html">120 nips-2008-Learning the Semantic Correlation: An Alternative Way to Gain from Unlabeled Text</a></p>
<p>10 0.11459979 <a title="246-tfidf-10" href="./nips-2008-Kernelized_Sorting.html">113 nips-2008-Kernelized Sorting</a></p>
<p>11 0.11443157 <a title="246-tfidf-11" href="./nips-2008-Predictive_Indexing_for_Fast_Search.html">184 nips-2008-Predictive Indexing for Fast Search</a></p>
<p>12 0.11356211 <a title="246-tfidf-12" href="./nips-2008-A_Scalable_Hierarchical_Distributed_Language_Model.html">4 nips-2008-A Scalable Hierarchical Distributed Language Model</a></p>
<p>13 0.10960088 <a title="246-tfidf-13" href="./nips-2008-Cascaded_Classification_Models%3A_Combining_Models_for_Holistic_Scene_Understanding.html">42 nips-2008-Cascaded Classification Models: Combining Models for Holistic Scene Understanding</a></p>
<p>14 0.10790785 <a title="246-tfidf-14" href="./nips-2008-A_%60%60Shape_Aware%27%27_Model_for_semi-supervised_Learning_of_Objects_and_its_Context.html">6 nips-2008-A ``Shape Aware'' Model for semi-supervised Learning of Objects and its Context</a></p>
<p>15 0.10417254 <a title="246-tfidf-15" href="./nips-2008-Syntactic_Topic_Models.html">229 nips-2008-Syntactic Topic Models</a></p>
<p>16 0.10132363 <a title="246-tfidf-16" href="./nips-2008-Estimating_Robust_Query_Models_with_Convex_Optimization.html">73 nips-2008-Estimating Robust Query Models with Convex Optimization</a></p>
<p>17 0.099885352 <a title="246-tfidf-17" href="./nips-2008-Natural_Image_Denoising_with_Convolutional_Networks.html">148 nips-2008-Natural Image Denoising with Convolutional Networks</a></p>
<p>18 0.095896155 <a title="246-tfidf-18" href="./nips-2008-Shape-Based_Object_Localization_for_Descriptive_Classification.html">207 nips-2008-Shape-Based Object Localization for Descriptive Classification</a></p>
<p>19 0.095661275 <a title="246-tfidf-19" href="./nips-2008-Translated_Learning%3A_Transfer_Learning_across_Different_Feature_Spaces.html">242 nips-2008-Translated Learning: Transfer Learning across Different Feature Spaces</a></p>
<p>20 0.090058506 <a title="246-tfidf-20" href="./nips-2008-Regularized_Learning_with_Networks_of_Features.html">194 nips-2008-Regularized Learning with Networks of Features</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2008_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.22), (1, 0.141), (2, -0.041), (3, 0.235), (4, -0.052), (5, -0.08), (6, -0.08), (7, -0.086), (8, -0.143), (9, 0.071), (10, -0.064), (11, -0.052), (12, -0.1), (13, -0.049), (14, 0.073), (15, 0.073), (16, -0.014), (17, 0.064), (18, 0.01), (19, -0.111), (20, 0.005), (21, -0.061), (22, -0.071), (23, 0.069), (24, 0.002), (25, 0.019), (26, 0.024), (27, -0.139), (28, 0.027), (29, -0.022), (30, -0.058), (31, -0.011), (32, -0.036), (33, -0.036), (34, -0.006), (35, -0.02), (36, -0.008), (37, 0.035), (38, -0.035), (39, -0.006), (40, -0.036), (41, 0.079), (42, 0.078), (43, -0.081), (44, -0.045), (45, -0.056), (46, -0.1), (47, 0.017), (48, -0.022), (49, 0.095)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95484543 <a title="246-lsi-1" href="./nips-2008-Unsupervised_Learning_of_Visual_Sense_Models_for_Polysemous_Words.html">246 nips-2008-Unsupervised Learning of Visual Sense Models for Polysemous Words</a></p>
<p>Author: Kate Saenko, Trevor Darrell</p><p>Abstract: Polysemy is a problem for methods that exploit image search engines to build object category models. Existing unsupervised approaches do not take word sense into consideration. We propose a new method that uses a dictionary to learn models of visual word sense from a large collection of unlabeled web data. The use of LDA to discover a latent sense space makes the model robust despite the very limited nature of dictionary deﬁnitions. The deﬁnitions are used to learn a distribution in the latent space that best represents a sense. The algorithm then uses the text surrounding image links to retrieve images with high probability of a particular dictionary sense. An object classiﬁer is trained on the resulting sense-speciﬁc images. We evaluate our method on a dataset obtained by searching the web for polysemous words. Category classiﬁcation experiments show that our dictionarybased approach outperforms baseline methods. 1</p><p>2 0.67770725 <a title="246-lsi-2" href="./nips-2008-Cascaded_Classification_Models%3A_Combining_Models_for_Holistic_Scene_Understanding.html">42 nips-2008-Cascaded Classification Models: Combining Models for Holistic Scene Understanding</a></p>
<p>Author: Geremy Heitz, Stephen Gould, Ashutosh Saxena, Daphne Koller</p><p>Abstract: One of the original goals of computer vision was to fully understand a natural scene. This requires solving several sub-problems simultaneously, including object detection, region labeling, and geometric reasoning. The last few decades have seen great progress in tackling each of these problems in isolation. Only recently have researchers returned to the difﬁcult task of considering them jointly. In this work, we consider learning a set of related models in such that they both solve their own problem and help each other. We develop a framework called Cascaded Classiﬁcation Models (CCM), where repeated instantiations of these classiﬁers are coupled by their input/output variables in a cascade that improves performance at each level. Our method requires only a limited “black box” interface with the models, allowing us to use very sophisticated, state-of-the-art classiﬁers without having to look under the hood. We demonstrate the effectiveness of our method on a large set of natural images by combining the subtasks of scene categorization, object detection, multiclass image segmentation, and 3d reconstruction. 1</p><p>3 0.67339098 <a title="246-lsi-3" href="./nips-2008-Multi-Level_Active_Prediction_of_Useful_Image_Annotations_for_Recognition.html">142 nips-2008-Multi-Level Active Prediction of Useful Image Annotations for Recognition</a></p>
<p>Author: Sudheendra Vijayanarasimhan, Kristen Grauman</p><p>Abstract: We introduce a framework for actively learning visual categories from a mixture of weakly and strongly labeled image examples. We propose to allow the categorylearner to strategically choose what annotations it receives—based on both the expected reduction in uncertainty as well as the relative costs of obtaining each annotation. We construct a multiple-instance discriminative classiﬁer based on the initial training data. Then all remaining unlabeled and weakly labeled examples are surveyed to actively determine which annotation ought to be requested next. After each request, the current classiﬁer is incrementally updated. Unlike previous work, our approach accounts for the fact that the optimal use of manual annotation may call for a combination of labels at multiple levels of granularity (e.g., a full segmentation on some images and a present/absent ﬂag on others). As a result, it is possible to learn more accurate category models with a lower total expenditure of manual annotation effort. 1</p><p>4 0.63488901 <a title="246-lsi-4" href="./nips-2008-Supervised_Dictionary_Learning.html">226 nips-2008-Supervised Dictionary Learning</a></p>
<p>Author: Julien Mairal, Jean Ponce, Guillermo Sapiro, Andrew Zisserman, Francis R. Bach</p><p>Abstract: It is now well established that sparse signal models are well suited for restoration tasks and can be effectively learned from audio, image, and video data. Recent research has been aimed at learning discriminative sparse models instead of purely reconstructive ones. This paper proposes a new step in that direction, with a novel sparse representation for signals belonging to different classes in terms of a shared dictionary and discriminative class models. The linear version of the proposed model admits a simple probabilistic interpretation, while its most general variant admits an interpretation in terms of kernels. An optimization framework for learning all the components of the proposed model is presented, along with experimental results on standard handwritten digit and texture classiﬁcation tasks. 1</p><p>5 0.62791181 <a title="246-lsi-5" href="./nips-2008-Learning_Hybrid_Models_for_Image_Annotation_with_Partially_Labeled_Data.html">116 nips-2008-Learning Hybrid Models for Image Annotation with Partially Labeled Data</a></p>
<p>Author: Xuming He, Richard S. Zemel</p><p>Abstract: Extensive labeled data for image annotation systems, which learn to assign class labels to image regions, is difﬁcult to obtain. We explore a hybrid model framework for utilizing partially labeled data that integrates a generative topic model for image appearance with discriminative label prediction. We propose three alternative formulations for imposing a spatial smoothness prior on the image labels. Tests of the new models and some baseline approaches on three real image datasets demonstrate the effectiveness of incorporating the latent structure. 1</p><p>6 0.61652976 <a title="246-lsi-6" href="./nips-2008-DiscLDA%3A_Discriminative_Learning_for_Dimensionality_Reduction_and_Classification.html">64 nips-2008-DiscLDA: Discriminative Learning for Dimensionality Reduction and Classification</a></p>
<p>7 0.59974337 <a title="246-lsi-7" href="./nips-2008-Recursive_Segmentation_and_Recognition_Templates_for_2D_Parsing.html">191 nips-2008-Recursive Segmentation and Recognition Templates for 2D Parsing</a></p>
<p>8 0.5968982 <a title="246-lsi-8" href="./nips-2008-MCBoost%3A_Multiple_Classifier_Boosting_for_Perceptual_Co-clustering_of_Images_and_Visual_Features.html">130 nips-2008-MCBoost: Multiple Classifier Boosting for Perceptual Co-clustering of Images and Visual Features</a></p>
<p>9 0.5956887 <a title="246-lsi-9" href="./nips-2008-Natural_Image_Denoising_with_Convolutional_Networks.html">148 nips-2008-Natural Image Denoising with Convolutional Networks</a></p>
<p>10 0.56414813 <a title="246-lsi-10" href="./nips-2008-Beyond_Novelty_Detection%3A_Incongruent_Events%2C_when_General_and_Specific_Classifiers_Disagree.html">36 nips-2008-Beyond Novelty Detection: Incongruent Events, when General and Specific Classifiers Disagree</a></p>
<p>11 0.55526263 <a title="246-lsi-11" href="./nips-2008-Learning_the_Semantic_Correlation%3A_An_Alternative_Way_to_Gain_from_Unlabeled_Text.html">120 nips-2008-Learning the Semantic Correlation: An Alternative Way to Gain from Unlabeled Text</a></p>
<p>12 0.55103207 <a title="246-lsi-12" href="./nips-2008-Shape-Based_Object_Localization_for_Descriptive_Classification.html">207 nips-2008-Shape-Based Object Localization for Descriptive Classification</a></p>
<p>13 0.53700936 <a title="246-lsi-13" href="./nips-2008-Semi-supervised_Learning_with_Weakly-Related_Unlabeled_Data_%3A_Towards_Better_Text_Categorization.html">205 nips-2008-Semi-supervised Learning with Weakly-Related Unlabeled Data : Towards Better Text Categorization</a></p>
<p>14 0.53417647 <a title="246-lsi-14" href="./nips-2008-A_Scalable_Hierarchical_Distributed_Language_Model.html">4 nips-2008-A Scalable Hierarchical Distributed Language Model</a></p>
<p>15 0.53033733 <a title="246-lsi-15" href="./nips-2008-Syntactic_Topic_Models.html">229 nips-2008-Syntactic Topic Models</a></p>
<p>16 0.52407432 <a title="246-lsi-16" href="./nips-2008-Look_Ma%2C_No_Hands%3A_Analyzing_the_Monotonic_Feature_Abstraction_for_Text_Classification.html">128 nips-2008-Look Ma, No Hands: Analyzing the Monotonic Feature Abstraction for Text Classification</a></p>
<p>17 0.52128512 <a title="246-lsi-17" href="./nips-2008-Large_Margin_Taxonomy_Embedding_for_Document_Categorization.html">114 nips-2008-Large Margin Taxonomy Embedding for Document Categorization</a></p>
<p>18 0.5152446 <a title="246-lsi-18" href="./nips-2008-Learning_a_discriminative_hidden_part_model_for_human_action_recognition.html">119 nips-2008-Learning a discriminative hidden part model for human action recognition</a></p>
<p>19 0.51441777 <a title="246-lsi-19" href="./nips-2008-Correlated_Bigram_LSA_for_Unsupervised_Language_Model_Adaptation.html">52 nips-2008-Correlated Bigram LSA for Unsupervised Language Model Adaptation</a></p>
<p>20 0.50987774 <a title="246-lsi-20" href="./nips-2008-Dynamic_visual_attention%3A_searching_for_coding_length_increments.html">66 nips-2008-Dynamic visual attention: searching for coding length increments</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2008_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(30, 0.054), (35, 0.015), (40, 0.072), (60, 0.016), (63, 0.091), (64, 0.132), (71, 0.125), (90, 0.381)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.74502039 <a title="246-lda-1" href="./nips-2008-Unsupervised_Learning_of_Visual_Sense_Models_for_Polysemous_Words.html">246 nips-2008-Unsupervised Learning of Visual Sense Models for Polysemous Words</a></p>
<p>Author: Kate Saenko, Trevor Darrell</p><p>Abstract: Polysemy is a problem for methods that exploit image search engines to build object category models. Existing unsupervised approaches do not take word sense into consideration. We propose a new method that uses a dictionary to learn models of visual word sense from a large collection of unlabeled web data. The use of LDA to discover a latent sense space makes the model robust despite the very limited nature of dictionary deﬁnitions. The deﬁnitions are used to learn a distribution in the latent space that best represents a sense. The algorithm then uses the text surrounding image links to retrieve images with high probability of a particular dictionary sense. An object classiﬁer is trained on the resulting sense-speciﬁc images. We evaluate our method on a dataset obtained by searching the web for polysemous words. Category classiﬁcation experiments show that our dictionarybased approach outperforms baseline methods. 1</p><p>2 0.67747605 <a title="246-lda-2" href="./nips-2008-Temporal_Dynamics_of_Cognitive_Control.html">231 nips-2008-Temporal Dynamics of Cognitive Control</a></p>
<p>Author: Jeremy Reynolds, Michael C. Mozer</p><p>Abstract: Cognitive control refers to the ﬂexible deployment of memory and attention in response to task demands and current goals. Control is often studied experimentally by presenting sequences of stimuli, some demanding a response, and others modulating the stimulus-response mapping. In these tasks, participants must maintain information about the current stimulus-response mapping in working memory. Prominent theories of cognitive control use recurrent neural nets to implement working memory, and optimize memory utilization via reinforcement learning. We present a novel perspective on cognitive control in which working memory representations are intrinsically probabilistic, and control operations that maintain and update working memory are dynamically determined via probabilistic inference. We show that our model provides a parsimonious account of behavioral and neuroimaging data, and suggest that it offers an elegant conceptualization of control in which behavior can be cast as optimal, subject to limitations on learning and the rate of information processing. Moreover, our model provides insight into how task instructions can be directly translated into appropriate behavior and then efﬁciently reﬁned with subsequent task experience. 1</p><p>3 0.66303492 <a title="246-lda-3" href="./nips-2008-Dimensionality_Reduction_for_Data_in_Multiple_Feature_Representations.html">63 nips-2008-Dimensionality Reduction for Data in Multiple Feature Representations</a></p>
<p>Author: Yen-yu Lin, Tyng-luh Liu, Chiou-shann Fuh</p><p>Abstract: In solving complex visual learning tasks, adopting multiple descriptors to more precisely characterize the data has been a feasible way for improving performance. These representations are typically high dimensional and assume diverse forms. Thus ﬁnding a way to transform them into a uniﬁed space of lower dimension generally facilitates the underlying tasks, such as object recognition or clustering. We describe an approach that incorporates multiple kernel learning with dimensionality reduction (MKL-DR). While the proposed framework is ﬂexible in simultaneously tackling data in various feature representations, the formulation itself is general in that it is established upon graph embedding. It follows that any dimensionality reduction techniques explainable by graph embedding can be generalized by our method to consider data in multiple feature representations.</p><p>4 0.54270488 <a title="246-lda-4" href="./nips-2008-Spectral_Hashing.html">219 nips-2008-Spectral Hashing</a></p>
<p>Author: Yair Weiss, Antonio Torralba, Rob Fergus</p><p>Abstract: Semantic hashing[1] seeks compact binary codes of data-points so that the Hamming distance between codewords correlates with semantic similarity. In this paper, we show that the problem of ﬁnding a best code for a given dataset is closely related to the problem of graph partitioning and can be shown to be NP hard. By relaxing the original problem, we obtain a spectral method whose solutions are simply a subset of thresholded eigenvectors of the graph Laplacian. By utilizing recent results on convergence of graph Laplacian eigenvectors to the Laplace-Beltrami eigenfunctions of manifolds, we show how to eﬃciently calculate the code of a novel datapoint. Taken together, both learning the code and applying it to a novel point are extremely simple. Our experiments show that our codes outperform the state-of-the art. 1</p><p>5 0.53395844 <a title="246-lda-5" href="./nips-2008-Learning_to_Use_Working_Memory_in_Partially_Observable_Environments_through_Dopaminergic_Reinforcement.html">121 nips-2008-Learning to Use Working Memory in Partially Observable Environments through Dopaminergic Reinforcement</a></p>
<p>Author: Michael T. Todd, Yael Niv, Jonathan D. Cohen</p><p>Abstract: Working memory is a central topic of cognitive neuroscience because it is critical for solving real-world problems in which information from multiple temporally distant sources must be combined to generate appropriate behavior. However, an often neglected fact is that learning to use working memory effectively is itself a difficult problem. The Gating framework [14] is a collection of psychological models that show how dopamine can train the basal ganglia and prefrontal cortex to form useful working memory representations in certain types of problems. We unite Gating with machine learning theory concerning the general problem of memory-based optimal control [5-6]. We present a normative model that learns, by online temporal difference methods, to use working memory to maximize discounted future reward in partially observable settings. The model successfully solves a benchmark working memory problem, and exhibits limitations similar to those observed in humans. Our purpose is to introduce a concise, normative definition of high level cognitive concepts such as working memory and cognitive control in terms of maximizing discounted future rewards. 1 I n t ro d u c t i o n Working memory is loosely defined in cognitive neuroscience as information that is (1) internally maintained on a temporary or short term basis, and (2) required for tasks in which immediate observations cannot be mapped to correct actions. It is widely assumed that prefrontal cortex (PFC) plays a role in maintaining and updating working memory. However, relatively little is known about how PFC develops useful working memory representations for a new task. Furthermore, current work focuses on describing the structure and limitations of working memory, but does not ask why, or in what general class of tasks, is it necessary. Borrowing from the theory of optimal control in partially observable Markov decision problems (POMDPs), we frame the psychological concept of working memory as an internal state representation, developed and employed to maximize future reward in partially observable environments. We combine computational insights from POMDPs and neurobiologically plausible models from cognitive neuroscience to suggest a simple reinforcement learning (RL) model of working memory function that can be implemented through dopaminergic training of the basal ganglia and PFC. The Gating framework is a series of cognitive neuroscience models developed to explain how dopaminergic RL signals can shape useful working memory representations [1-4]. Computationally this framework models working memory as a collection of past observations, each of which can occasionally be replaced with the current observation, and addresses the problem of learning when to update each memory element versus maintaining it. In the original Gating model [1-2] the PFC contained a unitary working memory representation that was updated whenever a phasic dopamine (DA) burst occurred (e.g., due to unexpected reward or novelty). That model was the first to connect working memory and RL via the temporal difference (TD) model of DA firing [7-8], and thus to suggest how working memory might serve a normative purpose. However, that model had limited computational flexibility due to the unitary nature of the working memory (i.e., a singleobservation memory controlled by a scalar DA signal). More recent work [3-4] has partially repositioned the Gating framework within the Actor/Critic model of mesostriatal RL [9-10], positing memory updating as but another cortical action controlled by the dorsal striatal</p><p>6 0.53042156 <a title="246-lda-6" href="./nips-2008-Goal-directed_decision_making_in_prefrontal_cortex%3A_a_computational_framework.html">94 nips-2008-Goal-directed decision making in prefrontal cortex: a computational framework</a></p>
<p>7 0.52702689 <a title="246-lda-7" href="./nips-2008-A_%60%60Shape_Aware%27%27_Model_for_semi-supervised_Learning_of_Objects_and_its_Context.html">6 nips-2008-A ``Shape Aware'' Model for semi-supervised Learning of Objects and its Context</a></p>
<p>8 0.5252701 <a title="246-lda-8" href="./nips-2008-Predictive_Indexing_for_Fast_Search.html">184 nips-2008-Predictive Indexing for Fast Search</a></p>
<p>9 0.51693332 <a title="246-lda-9" href="./nips-2008-Estimating_Robust_Query_Models_with_Convex_Optimization.html">73 nips-2008-Estimating Robust Query Models with Convex Optimization</a></p>
<p>10 0.51638132 <a title="246-lda-10" href="./nips-2008-How_memory_biases_affect_information_transmission%3A_A_rational_analysis_of_serial_reproduction.html">100 nips-2008-How memory biases affect information transmission: A rational analysis of serial reproduction</a></p>
<p>11 0.51461357 <a title="246-lda-11" href="./nips-2008-Shared_Segmentation_of_Natural_Scenes_Using_Dependent_Pitman-Yor_Processes.html">208 nips-2008-Shared Segmentation of Natural Scenes Using Dependent Pitman-Yor Processes</a></p>
<p>12 0.51368928 <a title="246-lda-12" href="./nips-2008-Cell_Assemblies_in_Large_Sparse_Inhibitory_Networks_of_Biologically_Realistic_Spiking_Neurons.html">43 nips-2008-Cell Assemblies in Large Sparse Inhibitory Networks of Biologically Realistic Spiking Neurons</a></p>
<p>13 0.51290107 <a title="246-lda-13" href="./nips-2008-Extended_Grassmann_Kernels_for_Subspace-Based_Learning.html">80 nips-2008-Extended Grassmann Kernels for Subspace-Based Learning</a></p>
<p>14 0.51128 <a title="246-lda-14" href="./nips-2008-Sequential_effects%3A_Superstition_or_rational_behavior%3F.html">206 nips-2008-Sequential effects: Superstition or rational behavior?</a></p>
<p>15 0.51052213 <a title="246-lda-15" href="./nips-2008-Offline_Handwriting_Recognition_with_Multidimensional_Recurrent_Neural_Networks.html">158 nips-2008-Offline Handwriting Recognition with Multidimensional Recurrent Neural Networks</a></p>
<p>16 0.50995499 <a title="246-lda-16" href="./nips-2008-Analyzing_human_feature_learning_as_nonparametric_Bayesian_inference.html">26 nips-2008-Analyzing human feature learning as nonparametric Bayesian inference</a></p>
<p>17 0.50884765 <a title="246-lda-17" href="./nips-2008-Partially_Observed_Maximum_Entropy_Discrimination_Markov_Networks.html">176 nips-2008-Partially Observed Maximum Entropy Discrimination Markov Networks</a></p>
<p>18 0.50573647 <a title="246-lda-18" href="./nips-2008-Robust_Near-Isometric_Matching_via_Structured_Learning_of_Graphical_Models.html">201 nips-2008-Robust Near-Isometric Matching via Structured Learning of Graphical Models</a></p>
<p>19 0.50559521 <a title="246-lda-19" href="./nips-2008-Modeling_the_effects_of_memory_on_human_online_sentence_processing_with_particle_filters.html">139 nips-2008-Modeling the effects of memory on human online sentence processing with particle filters</a></p>
<p>20 0.50375479 <a title="246-lda-20" href="./nips-2008-Multi-Level_Active_Prediction_of_Useful_Image_Annotations_for_Recognition.html">142 nips-2008-Multi-Level Active Prediction of Useful Image Annotations for Recognition</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
