<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>92 nips-2008-Generative versus discriminative training of RBMs for classification of fMRI images</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-92" href="#">nips2008-92</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>92 nips-2008-Generative versus discriminative training of RBMs for classification of fMRI images</h1>
<br/><p>Source: <a title="nips-2008-92-pdf" href="http://papers.nips.cc/paper/3577-generative-versus-discriminative-training-of-rbms-for-classification-of-fmri-images.pdf">pdf</a></p><p>Author: Tanya Schmah, Geoffrey E. Hinton, Steven L. Small, Stephen Strother, Richard S. Zemel</p><p>Abstract: Neuroimaging datasets often have a very large number of voxels and a very small number of training cases, which means that overﬁtting of models for this data can become a very serious problem. Working with a set of fMRI images from a study on stroke recovery, we consider a classiﬁcation task for which logistic regression performs poorly, even when L1- or L2- regularized. We show that much better discrimination can be achieved by ﬁtting a generative model to each separate condition and then seeing which model is most likely to have generated the data. We compare discriminative training of exactly the same set of models, and we also consider convex blends of generative and discriminative training. 1</p><p>Reference: <a title="nips-2008-92-reference" href="../nips2008_reference/nips-2008-Generative_versus_discriminative_training_of_RBMs_for_classification_of_fMRI_images_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Generative versus discriminative training of RBMs for classiﬁcation of fMRI images  Geoffrey E. [sent-1, score-0.321]
</p><p>2 ca  Abstract Neuroimaging datasets often have a very large number of voxels and a very small number of training cases, which means that overﬁtting of models for this data can become a very serious problem. [sent-13, score-0.149]
</p><p>3 Working with a set of fMRI images from a study on stroke recovery, we consider a classiﬁcation task for which logistic regression performs poorly, even when L1- or L2- regularized. [sent-14, score-0.306]
</p><p>4 We show that much better discrimination can be achieved by ﬁtting a generative model to each separate condition and then seeing which model is most likely to have generated the data. [sent-15, score-0.254]
</p><p>5 We compare discriminative training of exactly the same set of models, and we also consider convex blends of generative and discriminative training. [sent-16, score-0.768]
</p><p>6 1  Introduction  Pattern classiﬁcation approaches to analyzing functional neuroimaging data have become increasingly popular [12] [3] [4]. [sent-17, score-0.098]
</p><p>7 They may also lead to insight into underlying neural representations, highlighting brain regions that are most informative with respect to particular experimental variables. [sent-19, score-0.099]
</p><p>8 In regimes in which the number of training examples is relatively small, it has been shown that classiﬁers based on generative models can outperform discriminative classiﬁers, e. [sent-22, score-0.461]
</p><p>9 In this paper we investigate ways of using generative models to improve the discrimination of different conditions in functional neuroimaging data. [sent-25, score-0.352]
</p><p>10 Our primary interest with respect to the imaging data is to elucidate the brain changes that occur during recovery from a stroke. [sent-26, score-0.331]
</p><p>11 Towards this aim, we deﬁne an early-late discrimination task to see if the learning approach can ﬁnd properties that distinguish pre-recovery from post-recovery scans. [sent-27, score-0.134]
</p><p>12 2  Restricted Boltzmann Machines  A set of fMRI volumes can be modeled using a two-layer network called a “Restricted Boltzmann Machine” (RBM) [5], in which stochastic “visible units” are connected to stochastic “hidden units” using symmetrically weighted connections. [sent-28, score-0.214]
</p><p>13 The visible units of the RBM correspond to voxels, while the hidden units can be thought of as feature detectors. [sent-29, score-0.484]
</p><p>14 In the typical RBM, both visible and hidden units are binary, but we use a version in which the visible units are continuous and have Gaussian marginal distributions [15] [7] [1]. [sent-30, score-0.679]
</p><p>15 For simplicity, and since we are free to scale the data, we choose unit variance for the marginal distributions of the visible units. [sent-31, score-0.228]
</p><p>16 The energy of the joint conﬁguration (v, h) of the visible and hidden units is E(v, h) := −  vi wij hj − i,j  cj hj + j  1 2  2  (vi − bi ) ,  (1)  i  where wij , bi , cj are ﬁxed parameters. [sent-32, score-1.443]
</p><p>17 The joint distribution over visible and hidden variables is P (v, h) := with partition function Z :=  du  g  1 exp (−E(v, h)) , Z  (2)  exp (−E(u, g)). [sent-33, score-0.228]
</p><p>18 The marginal distribution over the visible units can be expressed as: P (v) =  P (v, h) = h  1 exp (−F (v)) , Z  (3)  where F is the free energy: F (v) = − log  exp (−E(v, h)) h  =−  log (1 + exp (vi wij + cj )) + j  1 2  2  (vi − bi ) . [sent-34, score-0.776]
</p><p>19 (4)  i  The marginal distribution over the visible units is typically intractable because of the partition function Z. [sent-35, score-0.349]
</p><p>20 Note that the conditional probabilities of the hidden units are the same as for binary-only RBMs. [sent-37, score-0.193]
</p><p>21 The aim of generative training of an RBM is to model the marginal distribution of the visible units P (v). [sent-38, score-0.622]
</p><p>22 In maximum likelihood learning, the aim is to minimize the negative log probability of the training data, Lgen = −  log P (v|θ),  (5)  v∈S  where S is the training set and θ is the vector of all parameters wij , bi , cj . [sent-39, score-0.651]
</p><p>23 , visible units are given values corresponding to observed fMRI volumes; while a subscript n indicates that n steps of Gibbs sampling have been done, beginning at data points, to give an approximation to an expected value over the true distribution P (v). [sent-45, score-0.318]
</p><p>24 1  Classiﬁcation via (mostly) generative training  We begin by generatively training two independent RBMs, one for each data class. [sent-49, score-0.404]
</p><p>25 In practice we regularize by adding a term to this cost function that corresponds to putting a prior distribution on the weights wij . [sent-51, score-0.117]
</p><p>26 In general, given probabilistic generative models for each of two classes, A and B, data can be classiﬁed by Bayes’ theorem. [sent-52, score-0.167]
</p><p>27 However the partition functions are intractable for RBMs with large numbers of hidden and visible units. [sent-58, score-0.254]
</p><p>28 ) The aim of discriminative training is to model the conditional probability of the class labels given the visible units. [sent-61, score-0.49]
</p><p>29 In maximum likelihood learning, the cost function to be minimized is the negative log conditional probability of the class labels of the training data, Ldisc = −  log P (class of v|v, θA , θB , ∆). [sent-62, score-0.169]
</p><p>30 2  Classiﬁcation via discriminative training  As an alternative to generative training, the function Ldisc (deﬁned in the previous equation) can be minimized directly, with respect to all parameters simultaneously: the wij , bi and cj of both RBMs and the threshold parameter ∆. [sent-64, score-0.811]
</p><p>31 log σ (FB (v) − FA (v) − ∆) −  C=−  v∈SB  v∈SA  where SA and SB are the sets of training data in classes A and B. [sent-68, score-0.158]
</p><p>32 From (4) it follows that ∂ ∂ ∂ F (v) = −pj vi , F (v) = −pj , F (v) = bi − vi , ∂wij ∂cj ∂bi where pj := σ(zj ) = P (hj |v). [sent-72, score-0.494]
</p><p>33 The formulae for model B are the same with opposite sign, and with pj := PB (hj |v). [sent-74, score-0.105]
</p><p>34 We note that discriminative training of a single RBM was suggested in [6] and [8]. [sent-76, score-0.294]
</p><p>35 1  Experiments on fMRI data Data and preprocessing  For our numerical experiments, we use the fMRI data from a study of recovery from stroke described in [14]. [sent-78, score-0.251]
</p><p>36 A stroke permanently damages part of the brain ( the “lesion”), resulting in loss of the corresponding function. [sent-79, score-0.199]
</p><p>37 Since the lesion is still present, the patient must have learned to used other parts of the brain to compensate. [sent-81, score-0.138]
</p><p>38 Studying stroke patients during recovery with fMRI can help determine what changes in brain function occur during recovery, and to what degree these changes correlate with degree of recovery. [sent-82, score-0.414]
</p><p>39 The study of [14] analysed mean volumes of activation over 4 regions of interest in each hemisphere. [sent-83, score-0.287]
</p><p>40 The main conclusion of that paper is that patients with good recovery have higher activations (averaged over all sessions) in the ipsilateral cerebellum. [sent-84, score-0.192]
</p><p>41 Twelve subjects were studied at 1,2,3 and 6 months post-stroke. [sent-85, score-0.154]
</p><p>42 Due to data irregularities, we study only 9 of these subjects in this paper; Each of the four imaging sessions consisted of four continuous recording runs. [sent-86, score-0.248]
</p><p>43 During each run, the subject alternated two kinds of hand movement: tapping ﬁnger and thumb together, or wrist ﬂexion/extension; with rest breaks in between. [sent-87, score-0.351]
</p><p>44 Within a run, the experimental design was : (3 seconds rest, 6 seconds ﬁnger tap, 3 seconds rest, 6 seconds wrist ﬂexion), repeated 8 times. [sent-90, score-0.425]
</p><p>45 horizontal) slices of thickness 6mm, and within each slice the pixel size is 2mm × 2mm. [sent-94, score-0.278]
</p><p>46 For computational ease, we retain only 7 horizontal fMRI slices out of an available 24 (slices 2,3,4,5,21,22,23, with 24 being the top of the head), resulting in 10499 voxels. [sent-96, score-0.143]
</p><p>47 The choice of slices is based on prior assumptions about what parts of the brain are involved in ﬁnger and wrist motion. [sent-97, score-0.535]
</p><p>48 So as to avoid the long transients intrinsic in fMRI imaging, we discard the ﬁrst image from each movement block, and all rest images. [sent-100, score-0.117]
</p><p>49 The ﬁrst task is to predict whether a given fMRI volume was recorded “early” in the study, deﬁned as the ﬁrst or second recording session (1 or 2 months post-stroke) or “late” in the study, deﬁned as the third or fourth recording session (3 or 6 months post-stroke). [sent-103, score-0.346]
</p><p>50 This task addresses our interest in the long-term changes in brain organisation and function during stroke recovery. [sent-104, score-0.28]
</p><p>51 The second task is to predict whether the volume was recorded during ﬁnger or wrist movement. [sent-105, score-0.373]
</p><p>52 late task, the “early” group is known to contain volumes in four sub-classes: healthy ﬁnger movement, healthy wrist movement, impaired ﬁnger movement and impaired wrist movement; and similarly for the “late” group. [sent-108, score-1.158]
</p><p>53 In addition, there are many sources of variability between volumes that are extraneous to the classiﬁcation task and that are present in any fMRI study, including physiological noise, fatigue and attention. [sent-109, score-0.3]
</p><p>54 3  Classiﬁcation methods and testing procedures  We used compared four basic methods: generatively- and discriminatively- trained pairs of RBMs; logistic regression and K nearest neighbours. [sent-111, score-0.09]
</p><p>55 Each method was tested on individual fMRI slices and also on the set of 7 slices described above. [sent-112, score-0.286]
</p><p>56 For the RBMs, minimization of the cost function was by gradient descent, while for logistic regression we used the conjugate gradient algorithm as implemented by Carl Rasmussen’s minimize. [sent-113, score-0.209]
</p><p>57 The splitting is done by ﬁrst partitioning the data into 32 half-runs, each of which contains either all of the ﬁnger movement volumes or all of the wrist movement volumes for one run. [sent-119, score-0.891]
</p><p>58 From each of these half-runs, one of the 8 groups was randomly chosen and assigned to the validation set, a second group was randomly assigned to the test set, and the remaining 6 were assigned to the training set. [sent-121, score-0.127]
</p><p>59 When testing on individual fMRI slices (which vary in size), we used 500 hidden units; while 3500 hidden units were used when testing on the larger set of 7 slices, which contained 10499 voxels. [sent-127, score-0.401]
</p><p>60 These subjects were then included in the test data, so we have not observed a strict separation of training and test data for the RBM-based methods. [sent-129, score-0.165]
</p><p>61 We note that our implementation of the discriminative gradient inadvertently used a residual variance of 1/2 instead of 1. [sent-130, score-0.24]
</p><p>62 1 We had originally used conjugate gradient for discriminatively-trained RBMs as well but we found, late in the study, that gradient descent ran faster and gave better results. [sent-131, score-0.272]
</p><p>63 We also studied various blends of generative and discriminative training of a pair of RBMs, in which the cost function is a convex combination of the negative log likelihood functions, Lλ = (1 − λ)Lgen + λLdisc . [sent-133, score-0.666]
</p><p>64 4  (9)  Results  The following two tables show mean misclassiﬁcation errors, averaged over all 9 subjects and all 20 splittings of the data from each subject. [sent-135, score-0.111]
</p><p>65 We omitted discriminative training an RBM pair for the large dataset of all 7 slices together, due to the computional expense. [sent-207, score-0.465]
</p><p>66 5  For this task, we did discriminatively train an RBM pair on the entire dataset, however due to the computational expense we used only 1000 hidden units instead of the the 3500 used in generative training. [sent-231, score-0.417]
</p><p>67 Experiments on one subject suggests that the results for discriminative training are not very sensitive to the number of hidden units. [sent-232, score-0.385]
</p><p>68 Figure 1 shows the performance of several convex blends of generative and discriminative training, tested on fMRI Slice 4. [sent-233, score-0.474]
</p><p>69 late task, pure generative training outperforms all other blends; while for the ﬁnger vs. [sent-236, score-0.471]
</p><p>70 wrist task, pure discriminative training outperforms all other blends. [sent-237, score-0.639]
</p><p>71 5  Discussion  This study shows that generative models, and in particular, Restricted Boltzmann Machines, can be very useful in discrimination tasks. [sent-238, score-0.296]
</p><p>72 It is been shown before that generative training can make use of unlabelled data to improve discriminative performance [7] [6]. [sent-239, score-0.461]
</p><p>73 The present study, like that of Ng and Jordan [11], shows that generative training can improve discriminative performance even if all data is labelled. [sent-240, score-0.461]
</p><p>74 Now that we have switched to gradient descent, discriminative training should be of comparable speed to the generative training, which is still very computationally intensive for this dataset. [sent-242, score-0.506]
</p><p>75 Figure 1: Misclassiﬁcation rates for a combination of (1 − λ) times generative training plus λ times discriminative training, as in Equation (9). [sent-243, score-0.461]
</p><p>76 We studied two methods of training a pair of RBM models: one almost entirely generative, and one discriminative. [sent-247, score-0.157]
</p><p>77 To use the terminology of Ng and Jordan, the two algorithms form a generativediscriminative pair, since they use exactly the same models of the input data and differ only in the training criterion. [sent-248, score-0.099]
</p><p>78 We found that training a pair of RBM models generatively rather than discriminatively yielded better discriminative performance for one of the two tasks studied. [sent-249, score-0.39]
</p><p>79 This is consistent with the results of Ng and Jordan, who studied the generative-discriminative pair consisting of naive Bayes and logistic regression and found that naive Bayes can outperform logistic regression. [sent-250, score-0.279]
</p><p>80 Their theoretical and experimental results suggest that generative training is more likely to be superior to discriminative training when the number of training examples is small compared to the dimension of the input data space. [sent-251, score-0.659]
</p><p>81 Since fMRI studies are in this regime, generative training looks promising for fMRI-based classiﬁcation tasks. [sent-252, score-0.266]
</p><p>82 The two tasks studied in the present work are: (i) classify fMRI volumes as having been recorded in either the earlier or later part of the study; and (ii) classify fMRI volumes as corresponding to either ﬁnger or wrist movement. [sent-253, score-0.84]
</p><p>83 We found that generative training yielded better results for the early vs. [sent-254, score-0.328]
</p><p>84 late task, while discriminative training was superior for the ﬁnger vs. [sent-255, score-0.447]
</p><p>85 One general observation is that generative training is trying to model many different features at once, many of which may be irrelevant to the discrimination task; whereas, by deﬁnition, discriminative models always focus on the task at hand. [sent-258, score-0.622]
</p><p>86 Thus there is a possibility for generative models to be “distracted” (from the point of view of discrimination) by rich structure in the data that is extraneous to the discrimination task. [sent-259, score-0.293]
</p><p>87 It seems reasonable that, the more structure there is in the images that is irrelevant to the discrimination task, the poorer will be the discriminative power of the generative models. [sent-260, score-0.503]
</p><p>88 We hypothesize that a lot of the complex structure in the fMRI volumes is relevant to early vs. [sent-261, score-0.276]
</p><p>89 late classiﬁcation, but that most of it is irrelevant to ﬁnger vs. [sent-262, score-0.18]
</p><p>90 In other words, we hypothesise that the long-term changes during stroke recovery are complex and distributed throughout the brain; and that, by contrast the differences in brain activation between ﬁnger and wrist movements are relatively simple. [sent-264, score-0.666]
</p><p>91 We have evaluated blends of generative and discriminative training, as other authors have found that a combination can out-perform both pure generative and pure discriminative training [9][2]. [sent-268, score-1.039]
</p><p>92 The ﬁrst is to elucidate neural changes that occur during recovery from a stroke. [sent-271, score-0.172]
</p><p>93 The present study identiﬁes a speciﬁc method that is very successful at the early vs. [sent-275, score-0.104]
</p><p>94 late classiﬁcation task, but does not go on to address the problem of “opening the box”, i. [sent-276, score-0.153]
</p><p>95 The second aim is ﬁnd general classiﬁcation methods that can eventually be applied in clinical studies to classify patients as likely responders or non-responders to certain treatments on the basis of fMRI scans. [sent-280, score-0.099]
</p><p>96 In future work we intend to evaluate such models for their power to generalize strongly across subjects and recording sessions. [sent-282, score-0.113]
</p><p>97 generative classiﬁers: A comparison of logistic regression and naive Bayes. [sent-353, score-0.291]
</p><p>98 Theoretical, statistical, and practical perspectives on pattern-based classiﬁcation approaches to functional neuroimaging analysis. [sent-365, score-0.098]
</p><p>99 A comparison of classiﬁcation methods for longitudinal fmri studies. [sent-377, score-0.306]
</p><p>100 Cerebellar hemispheric activation ipsilateral to the paretic hand correlates with functional recovery after stroke. [sent-387, score-0.216]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('fmri', 0.306), ('wrist', 0.293), ('nger', 0.251), ('rbm', 0.237), ('rbms', 0.237), ('volumes', 0.214), ('discriminative', 0.195), ('generative', 0.167), ('visible', 0.163), ('sb', 0.161), ('late', 0.153), ('slices', 0.143), ('fb', 0.143), ('bi', 0.135), ('slice', 0.135), ('hj', 0.13), ('units', 0.128), ('vi', 0.127), ('sa', 0.121), ('wij', 0.117), ('blends', 0.112), ('recovery', 0.109), ('fa', 0.107), ('classi', 0.105), ('pj', 0.105), ('stroke', 0.1), ('brain', 0.099), ('training', 0.099), ('cj', 0.098), ('ldisc', 0.089), ('discrimination', 0.087), ('movement', 0.085), ('toronto', 0.071), ('lgen', 0.067), ('schmah', 0.067), ('neuroimaging', 0.067), ('subjects', 0.066), ('hidden', 0.065), ('cation', 0.065), ('logistic', 0.063), ('early', 0.062), ('imaging', 0.06), ('months', 0.058), ('boltzmann', 0.058), ('pure', 0.052), ('voxels', 0.05), ('task', 0.047), ('recording', 0.047), ('energies', 0.045), ('ipsilateral', 0.045), ('splittings', 0.045), ('gradient', 0.045), ('hinton', 0.044), ('study', 0.042), ('lesion', 0.039), ('generatively', 0.039), ('extraneous', 0.039), ('zemel', 0.039), ('patients', 0.038), ('canada', 0.037), ('gen', 0.036), ('log', 0.035), ('misclassi', 0.035), ('naive', 0.034), ('changes', 0.034), ('za', 0.033), ('sessions', 0.033), ('aim', 0.033), ('free', 0.033), ('ng', 0.033), ('recorded', 0.033), ('seconds', 0.033), ('marginal', 0.032), ('rest', 0.032), ('impaired', 0.032), ('contrastive', 0.032), ('bayes', 0.031), ('activation', 0.031), ('functional', 0.031), ('registration', 0.03), ('studied', 0.03), ('conjugate', 0.029), ('elucidate', 0.029), ('discriminatively', 0.029), ('chicago', 0.029), ('classify', 0.028), ('pair', 0.028), ('substituting', 0.028), ('session', 0.028), ('healthy', 0.028), ('validation', 0.028), ('regression', 0.027), ('images', 0.027), ('irrelevant', 0.027), ('subscript', 0.027), ('ers', 0.026), ('intractable', 0.026), ('subject', 0.026), ('cd', 0.025), ('classes', 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="92-tfidf-1" href="./nips-2008-Generative_versus_discriminative_training_of_RBMs_for_classification_of_fMRI_images.html">92 nips-2008-Generative versus discriminative training of RBMs for classification of fMRI images</a></p>
<p>Author: Tanya Schmah, Geoffrey E. Hinton, Steven L. Small, Stephen Strother, Richard S. Zemel</p><p>Abstract: Neuroimaging datasets often have a very large number of voxels and a very small number of training cases, which means that overﬁtting of models for this data can become a very serious problem. Working with a set of fMRI images from a study on stroke recovery, we consider a classiﬁcation task for which logistic regression performs poorly, even when L1- or L2- regularized. We show that much better discrimination can be achieved by ﬁtting a generative model to each separate condition and then seeing which model is most likely to have generated the data. We compare discriminative training of exactly the same set of models, and we also consider convex blends of generative and discriminative training. 1</p><p>2 0.32852384 <a title="92-tfidf-2" href="./nips-2008-Implicit_Mixtures_of_Restricted_Boltzmann_Machines.html">103 nips-2008-Implicit Mixtures of Restricted Boltzmann Machines</a></p>
<p>Author: Vinod Nair, Geoffrey E. Hinton</p><p>Abstract: We present a mixture model whose components are Restricted Boltzmann Machines (RBMs). This possibility has not been considered before because computing the partition function of an RBM is intractable, which appears to make learning a mixture of RBMs intractable as well. Surprisingly, when formulated as a third-order Boltzmann machine, such a mixture model can be learned tractably using contrastive divergence. The energy function of the model captures threeway interactions among visible units, hidden units, and a single hidden discrete variable that represents the cluster label. The distinguishing feature of this model is that, unlike other mixture models, the mixing proportions are not explicitly parameterized. Instead, they are deﬁned implicitly via the energy function and depend on all the parameters in the model. We present results for the MNIST and NORB datasets showing that the implicit mixture of RBMs learns clusters that reﬂect the class structure in the data. 1</p><p>3 0.11182868 <a title="92-tfidf-3" href="./nips-2008-Supervised_Dictionary_Learning.html">226 nips-2008-Supervised Dictionary Learning</a></p>
<p>Author: Julien Mairal, Jean Ponce, Guillermo Sapiro, Andrew Zisserman, Francis R. Bach</p><p>Abstract: It is now well established that sparse signal models are well suited for restoration tasks and can be effectively learned from audio, image, and video data. Recent research has been aimed at learning discriminative sparse models instead of purely reconstructive ones. This paper proposes a new step in that direction, with a novel sparse representation for signals belonging to different classes in terms of a shared dictionary and discriminative class models. The linear version of the proposed model admits a simple probabilistic interpretation, while its most general variant admits an interpretation in terms of kernels. An optimization framework for learning all the components of the proposed model is presented, along with experimental results on standard handwritten digit and texture classiﬁcation tasks. 1</p><p>4 0.10840994 <a title="92-tfidf-4" href="./nips-2008-Learning_a_discriminative_hidden_part_model_for_human_action_recognition.html">119 nips-2008-Learning a discriminative hidden part model for human action recognition</a></p>
<p>Author: Yang Wang, Greg Mori</p><p>Abstract: We present a discriminative part-based approach for human action recognition from video sequences using motion features. Our model is based on the recently proposed hidden conditional random ﬁeld (hCRF) for object recognition. Similar to hCRF for object recognition, we model a human action by a ﬂexible constellation of parts conditioned on image observations. Different from object recognition, our model combines both large-scale global features and local patch features to distinguish various actions. Our experimental results show that our model is comparable to other state-of-the-art approaches in action recognition. In particular, our experimental results demonstrate that combining large-scale global features and local patch features performs signiﬁcantly better than directly applying hCRF on local patches alone. 1</p><p>5 0.10078742 <a title="92-tfidf-5" href="./nips-2008-Nonparametric_sparse_hierarchical_models_describe_V1_fMRI_responses_to_natural_images.html">156 nips-2008-Nonparametric sparse hierarchical models describe V1 fMRI responses to natural images</a></p>
<p>Author: Vincent Q. Vu, Bin Yu, Thomas Naselaris, Kendrick Kay, Jack Gallant, Pradeep K. Ravikumar</p><p>Abstract: We propose a novel hierarchical, nonlinear model that predicts brain activity in area V1 evoked by natural images. In the study reported here brain activity was measured by means of functional magnetic resonance imaging (fMRI), a noninvasive technique that provides an indirect measure of neural activity pooled over a small volume (≈ 2mm cube) of brain tissue. Our model, which we call the V-SPAM model, is based on the reasonable assumption that fMRI measurements reﬂect the (possibly nonlinearly) pooled, rectiﬁed output of a large population of simple and complex cells in V1. It has a hierarchical ﬁltering stage that consists of three layers: model simple cells, model complex cells, and a third layer in which the complex cells are linearly pooled (called “pooled-complex” cells). The pooling stage then obtains the measured fMRI signals as a sparse additive model (SpAM) in which a sparse nonparametric (nonlinear) combination of model complex cell and model pooled-complex cell outputs are summed. Our results show that the V-SPAM model predicts fMRI responses evoked by natural images better than a benchmark model that only provides linear pooling of model complex cells. Furthermore, the spatial receptive ﬁelds, frequency tuning and orientation tuning curves of the V-SPAM model estimated for each voxel appears to be consistent with the known properties of V1, and with previous analyses of this data set. A visualization procedure applied to the V-SPAM model shows that most of the nonlinear pooling consists of simple compressive or saturating nonlinearities. 1</p><p>6 0.097845465 <a title="92-tfidf-6" href="./nips-2008-Evaluating_probabilities_under_high-dimensional_latent_variable_models.html">77 nips-2008-Evaluating probabilities under high-dimensional latent variable models</a></p>
<p>7 0.09517312 <a title="92-tfidf-7" href="./nips-2008-Temporal_Dynamics_of_Cognitive_Control.html">231 nips-2008-Temporal Dynamics of Cognitive Control</a></p>
<p>8 0.089729905 <a title="92-tfidf-8" href="./nips-2008-The_Recurrent_Temporal_Restricted_Boltzmann_Machine.html">237 nips-2008-The Recurrent Temporal Restricted Boltzmann Machine</a></p>
<p>9 0.085324779 <a title="92-tfidf-9" href="./nips-2008-Spectral_Hashing.html">219 nips-2008-Spectral Hashing</a></p>
<p>10 0.084790863 <a title="92-tfidf-10" href="./nips-2008-Exact_Convex_Confidence-Weighted_Learning.html">78 nips-2008-Exact Convex Confidence-Weighted Learning</a></p>
<p>11 0.083528489 <a title="92-tfidf-11" href="./nips-2008-Learning_Hybrid_Models_for_Image_Annotation_with_Partially_Labeled_Data.html">116 nips-2008-Learning Hybrid Models for Image Annotation with Partially Labeled Data</a></p>
<p>12 0.082180806 <a title="92-tfidf-12" href="./nips-2008-Hierarchical_Fisher_Kernels_for_Longitudinal_Data.html">97 nips-2008-Hierarchical Fisher Kernels for Longitudinal Data</a></p>
<p>13 0.081788629 <a title="92-tfidf-13" href="./nips-2008-Recursive_Segmentation_and_Recognition_Templates_for_2D_Parsing.html">191 nips-2008-Recursive Segmentation and Recognition Templates for 2D Parsing</a></p>
<p>14 0.077605858 <a title="92-tfidf-14" href="./nips-2008-Differentiable_Sparse_Coding.html">62 nips-2008-Differentiable Sparse Coding</a></p>
<p>15 0.069110215 <a title="92-tfidf-15" href="./nips-2008-Bayesian_Experimental_Design_of_Magnetic_Resonance_Imaging_Sequences.html">30 nips-2008-Bayesian Experimental Design of Magnetic Resonance Imaging Sequences</a></p>
<p>16 0.067507386 <a title="92-tfidf-16" href="./nips-2008-MCBoost%3A_Multiple_Classifier_Boosting_for_Perceptual_Co-clustering_of_Images_and_Visual_Features.html">130 nips-2008-MCBoost: Multiple Classifier Boosting for Perceptual Co-clustering of Images and Visual Features</a></p>
<p>17 0.065689191 <a title="92-tfidf-17" href="./nips-2008-Look_Ma%2C_No_Hands%3A_Analyzing_the_Monotonic_Feature_Abstraction_for_Text_Classification.html">128 nips-2008-Look Ma, No Hands: Analyzing the Monotonic Feature Abstraction for Text Classification</a></p>
<p>18 0.064401962 <a title="92-tfidf-18" href="./nips-2008-Characterizing_response_behavior_in_multisensory_perception_with_conflicting_cues.html">46 nips-2008-Characterizing response behavior in multisensory perception with conflicting cues</a></p>
<p>19 0.061095104 <a title="92-tfidf-19" href="./nips-2008-Transfer_Learning_by_Distribution_Matching_for_Targeted_Advertising.html">241 nips-2008-Transfer Learning by Distribution Matching for Targeted Advertising</a></p>
<p>20 0.058796246 <a title="92-tfidf-20" href="./nips-2008-Dimensionality_Reduction_for_Data_in_Multiple_Feature_Representations.html">63 nips-2008-Dimensionality Reduction for Data in Multiple Feature Representations</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2008_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.199), (1, -0.054), (2, 0.078), (3, -0.038), (4, 0.029), (5, 0.009), (6, -0.07), (7, 0.008), (8, 0.044), (9, 0.076), (10, 0.062), (11, 0.115), (12, -0.042), (13, 0.043), (14, -0.209), (15, -0.196), (16, -0.103), (17, -0.292), (18, 0.038), (19, 0.073), (20, 0.076), (21, -0.116), (22, 0.004), (23, -0.002), (24, 0.015), (25, 0.053), (26, -0.037), (27, 0.223), (28, 0.119), (29, 0.019), (30, -0.054), (31, -0.082), (32, 0.099), (33, -0.062), (34, -0.065), (35, 0.01), (36, -0.0), (37, -0.048), (38, -0.218), (39, 0.07), (40, 0.034), (41, -0.089), (42, -0.087), (43, 0.118), (44, 0.012), (45, -0.001), (46, 0.088), (47, -0.099), (48, 0.013), (49, -0.002)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9343701 <a title="92-lsi-1" href="./nips-2008-Generative_versus_discriminative_training_of_RBMs_for_classification_of_fMRI_images.html">92 nips-2008-Generative versus discriminative training of RBMs for classification of fMRI images</a></p>
<p>Author: Tanya Schmah, Geoffrey E. Hinton, Steven L. Small, Stephen Strother, Richard S. Zemel</p><p>Abstract: Neuroimaging datasets often have a very large number of voxels and a very small number of training cases, which means that overﬁtting of models for this data can become a very serious problem. Working with a set of fMRI images from a study on stroke recovery, we consider a classiﬁcation task for which logistic regression performs poorly, even when L1- or L2- regularized. We show that much better discrimination can be achieved by ﬁtting a generative model to each separate condition and then seeing which model is most likely to have generated the data. We compare discriminative training of exactly the same set of models, and we also consider convex blends of generative and discriminative training. 1</p><p>2 0.84717196 <a title="92-lsi-2" href="./nips-2008-Implicit_Mixtures_of_Restricted_Boltzmann_Machines.html">103 nips-2008-Implicit Mixtures of Restricted Boltzmann Machines</a></p>
<p>Author: Vinod Nair, Geoffrey E. Hinton</p><p>Abstract: We present a mixture model whose components are Restricted Boltzmann Machines (RBMs). This possibility has not been considered before because computing the partition function of an RBM is intractable, which appears to make learning a mixture of RBMs intractable as well. Surprisingly, when formulated as a third-order Boltzmann machine, such a mixture model can be learned tractably using contrastive divergence. The energy function of the model captures threeway interactions among visible units, hidden units, and a single hidden discrete variable that represents the cluster label. The distinguishing feature of this model is that, unlike other mixture models, the mixing proportions are not explicitly parameterized. Instead, they are deﬁned implicitly via the energy function and depend on all the parameters in the model. We present results for the MNIST and NORB datasets showing that the implicit mixture of RBMs learns clusters that reﬂect the class structure in the data. 1</p><p>3 0.68606812 <a title="92-lsi-3" href="./nips-2008-The_Recurrent_Temporal_Restricted_Boltzmann_Machine.html">237 nips-2008-The Recurrent Temporal Restricted Boltzmann Machine</a></p>
<p>Author: Ilya Sutskever, Geoffrey E. Hinton, Graham W. Taylor</p><p>Abstract: The Temporal Restricted Boltzmann Machine (TRBM) is a probabilistic model for sequences that is able to successfully model (i.e., generate nice-looking samples of) several very high dimensional sequences, such as motion capture data and the pixels of low resolution videos of balls bouncing in a box. The major disadvantage of the TRBM is that exact inference is extremely hard, since even computing a Gibbs update for a single variable of the posterior is exponentially expensive. This difﬁculty has necessitated the use of a heuristic inference procedure, that nonetheless was accurate enough for successful learning. In this paper we introduce the Recurrent TRBM, which is a very slight modiﬁcation of the TRBM for which exact inference is very easy and exact gradient learning is almost tractable. We demonstrate that the RTRBM is better than an analogous TRBM at generating motion capture and videos of bouncing balls. 1</p><p>4 0.43846849 <a title="92-lsi-4" href="./nips-2008-Supervised_Dictionary_Learning.html">226 nips-2008-Supervised Dictionary Learning</a></p>
<p>Author: Julien Mairal, Jean Ponce, Guillermo Sapiro, Andrew Zisserman, Francis R. Bach</p><p>Abstract: It is now well established that sparse signal models are well suited for restoration tasks and can be effectively learned from audio, image, and video data. Recent research has been aimed at learning discriminative sparse models instead of purely reconstructive ones. This paper proposes a new step in that direction, with a novel sparse representation for signals belonging to different classes in terms of a shared dictionary and discriminative class models. The linear version of the proposed model admits a simple probabilistic interpretation, while its most general variant admits an interpretation in terms of kernels. An optimization framework for learning all the components of the proposed model is presented, along with experimental results on standard handwritten digit and texture classiﬁcation tasks. 1</p><p>5 0.37167725 <a title="92-lsi-5" href="./nips-2008-Artificial_Olfactory_Brain_for_Mixture_Identification.html">27 nips-2008-Artificial Olfactory Brain for Mixture Identification</a></p>
<p>Author: Mehmet K. Muezzinoglu, Alexander Vergara, Ramon Huerta, Thomas Nowotny, Nikolai Rulkov, Henry Abarbanel, Allen Selverston, Mikhail Rabinovich</p><p>Abstract: The odor transduction process has a large time constant and is susceptible to various types of noise. Therefore, the olfactory code at the sensor/receptor level is in general a slow and highly variable indicator of the input odor in both natural and artiﬁcial situations. Insects overcome this problem by using a neuronal device in their Antennal Lobe (AL), which transforms the identity code of olfactory receptors to a spatio-temporal code. This transformation improves the decision of the Mushroom Bodies (MBs), the subsequent classiﬁer, in both speed and accuracy. Here we propose a rate model based on two intrinsic mechanisms in the insect AL, namely integration and inhibition. Then we present a MB classiﬁer model that resembles the sparse and random structure of insect MB. A local Hebbian learning procedure governs the plasticity in the model. These formulations not only help to understand the signal conditioning and classiﬁcation methods of insect olfactory systems, but also can be leveraged in synthetic problems. Among them, we consider here the discrimination of odor mixtures from pure odors. We show on a set of records from metal-oxide gas sensors that the cascade of these two new models facilitates fast and accurate discrimination of even highly imbalanced mixtures from pure odors. 1</p><p>6 0.35782963 <a title="92-lsi-6" href="./nips-2008-Evaluating_probabilities_under_high-dimensional_latent_variable_models.html">77 nips-2008-Evaluating probabilities under high-dimensional latent variable models</a></p>
<p>7 0.35497421 <a title="92-lsi-7" href="./nips-2008-Nonparametric_sparse_hierarchical_models_describe_V1_fMRI_responses_to_natural_images.html">156 nips-2008-Nonparametric sparse hierarchical models describe V1 fMRI responses to natural images</a></p>
<p>8 0.33929709 <a title="92-lsi-8" href="./nips-2008-Hierarchical_Fisher_Kernels_for_Longitudinal_Data.html">97 nips-2008-Hierarchical Fisher Kernels for Longitudinal Data</a></p>
<p>9 0.3370246 <a title="92-lsi-9" href="./nips-2008-Learning_a_discriminative_hidden_part_model_for_human_action_recognition.html">119 nips-2008-Learning a discriminative hidden part model for human action recognition</a></p>
<p>10 0.32795024 <a title="92-lsi-10" href="./nips-2008-Nonparametric_regression_and_classification_with_joint_sparsity_constraints.html">155 nips-2008-Nonparametric regression and classification with joint sparsity constraints</a></p>
<p>11 0.32604089 <a title="92-lsi-11" href="./nips-2008-Spectral_Hashing.html">219 nips-2008-Spectral Hashing</a></p>
<p>12 0.32162118 <a title="92-lsi-12" href="./nips-2008-Natural_Image_Denoising_with_Convolutional_Networks.html">148 nips-2008-Natural Image Denoising with Convolutional Networks</a></p>
<p>13 0.31343734 <a title="92-lsi-13" href="./nips-2008-Bayesian_Experimental_Design_of_Magnetic_Resonance_Imaging_Sequences.html">30 nips-2008-Bayesian Experimental Design of Magnetic Resonance Imaging Sequences</a></p>
<p>14 0.3120282 <a title="92-lsi-14" href="./nips-2008-MCBoost%3A_Multiple_Classifier_Boosting_for_Perceptual_Co-clustering_of_Images_and_Visual_Features.html">130 nips-2008-MCBoost: Multiple Classifier Boosting for Perceptual Co-clustering of Images and Visual Features</a></p>
<p>15 0.30845347 <a title="92-lsi-15" href="./nips-2008-Variational_Mixture_of_Gaussian_Process_Experts.html">249 nips-2008-Variational Mixture of Gaussian Process Experts</a></p>
<p>16 0.30404374 <a title="92-lsi-16" href="./nips-2008-Cascaded_Classification_Models%3A_Combining_Models_for_Holistic_Scene_Understanding.html">42 nips-2008-Cascaded Classification Models: Combining Models for Holistic Scene Understanding</a></p>
<p>17 0.30283964 <a title="92-lsi-17" href="./nips-2008-Partially_Observed_Maximum_Entropy_Discrimination_Markov_Networks.html">176 nips-2008-Partially Observed Maximum Entropy Discrimination Markov Networks</a></p>
<p>18 0.3026081 <a title="92-lsi-18" href="./nips-2008-Localized_Sliced_Inverse_Regression.html">126 nips-2008-Localized Sliced Inverse Regression</a></p>
<p>19 0.29695985 <a title="92-lsi-19" href="./nips-2008-Privacy-preserving_logistic_regression.html">185 nips-2008-Privacy-preserving logistic regression</a></p>
<p>20 0.29339555 <a title="92-lsi-20" href="./nips-2008-Shape-Based_Object_Localization_for_Descriptive_Classification.html">207 nips-2008-Shape-Based Object Localization for Descriptive Classification</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2008_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(6, 0.067), (7, 0.076), (12, 0.022), (15, 0.015), (28, 0.163), (32, 0.059), (57, 0.118), (59, 0.024), (63, 0.029), (70, 0.229), (71, 0.017), (77, 0.033), (78, 0.017), (83, 0.051)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.81393224 <a title="92-lda-1" href="./nips-2008-Generative_versus_discriminative_training_of_RBMs_for_classification_of_fMRI_images.html">92 nips-2008-Generative versus discriminative training of RBMs for classification of fMRI images</a></p>
<p>Author: Tanya Schmah, Geoffrey E. Hinton, Steven L. Small, Stephen Strother, Richard S. Zemel</p><p>Abstract: Neuroimaging datasets often have a very large number of voxels and a very small number of training cases, which means that overﬁtting of models for this data can become a very serious problem. Working with a set of fMRI images from a study on stroke recovery, we consider a classiﬁcation task for which logistic regression performs poorly, even when L1- or L2- regularized. We show that much better discrimination can be achieved by ﬁtting a generative model to each separate condition and then seeing which model is most likely to have generated the data. We compare discriminative training of exactly the same set of models, and we also consider convex blends of generative and discriminative training. 1</p><p>2 0.75260663 <a title="92-lda-2" href="./nips-2008-Efficient_Sampling_for_Gaussian_Process_Inference_using_Control_Variables.html">71 nips-2008-Efficient Sampling for Gaussian Process Inference using Control Variables</a></p>
<p>Author: Neil D. Lawrence, Magnus Rattray, Michalis K. Titsias</p><p>Abstract: Sampling functions in Gaussian process (GP) models is challenging because of the highly correlated posterior distribution. We describe an efﬁcient Markov chain Monte Carlo algorithm for sampling from the posterior process of the GP model. This algorithm uses control variables which are auxiliary function values that provide a low dimensional representation of the function. At each iteration, the algorithm proposes new values for the control variables and generates the function from the conditional GP prior. The control variable input locations are found by minimizing an objective function. We demonstrate the algorithm on regression and classiﬁcation problems and we use it to estimate the parameters of a differential equation model of gene regulation. 1</p><p>3 0.7102285 <a title="92-lda-3" href="./nips-2008-Implicit_Mixtures_of_Restricted_Boltzmann_Machines.html">103 nips-2008-Implicit Mixtures of Restricted Boltzmann Machines</a></p>
<p>Author: Vinod Nair, Geoffrey E. Hinton</p><p>Abstract: We present a mixture model whose components are Restricted Boltzmann Machines (RBMs). This possibility has not been considered before because computing the partition function of an RBM is intractable, which appears to make learning a mixture of RBMs intractable as well. Surprisingly, when formulated as a third-order Boltzmann machine, such a mixture model can be learned tractably using contrastive divergence. The energy function of the model captures threeway interactions among visible units, hidden units, and a single hidden discrete variable that represents the cluster label. The distinguishing feature of this model is that, unlike other mixture models, the mixing proportions are not explicitly parameterized. Instead, they are deﬁned implicitly via the energy function and depend on all the parameters in the model. We present results for the MNIST and NORB datasets showing that the implicit mixture of RBMs learns clusters that reﬂect the class structure in the data. 1</p><p>4 0.70441669 <a title="92-lda-4" href="./nips-2008-Unsupervised_Learning_of_Visual_Sense_Models_for_Polysemous_Words.html">246 nips-2008-Unsupervised Learning of Visual Sense Models for Polysemous Words</a></p>
<p>Author: Kate Saenko, Trevor Darrell</p><p>Abstract: Polysemy is a problem for methods that exploit image search engines to build object category models. Existing unsupervised approaches do not take word sense into consideration. We propose a new method that uses a dictionary to learn models of visual word sense from a large collection of unlabeled web data. The use of LDA to discover a latent sense space makes the model robust despite the very limited nature of dictionary deﬁnitions. The deﬁnitions are used to learn a distribution in the latent space that best represents a sense. The algorithm then uses the text surrounding image links to retrieve images with high probability of a particular dictionary sense. An object classiﬁer is trained on the resulting sense-speciﬁc images. We evaluate our method on a dataset obtained by searching the web for polysemous words. Category classiﬁcation experiments show that our dictionarybased approach outperforms baseline methods. 1</p><p>5 0.69441408 <a title="92-lda-5" href="./nips-2008-Artificial_Olfactory_Brain_for_Mixture_Identification.html">27 nips-2008-Artificial Olfactory Brain for Mixture Identification</a></p>
<p>Author: Mehmet K. Muezzinoglu, Alexander Vergara, Ramon Huerta, Thomas Nowotny, Nikolai Rulkov, Henry Abarbanel, Allen Selverston, Mikhail Rabinovich</p><p>Abstract: The odor transduction process has a large time constant and is susceptible to various types of noise. Therefore, the olfactory code at the sensor/receptor level is in general a slow and highly variable indicator of the input odor in both natural and artiﬁcial situations. Insects overcome this problem by using a neuronal device in their Antennal Lobe (AL), which transforms the identity code of olfactory receptors to a spatio-temporal code. This transformation improves the decision of the Mushroom Bodies (MBs), the subsequent classiﬁer, in both speed and accuracy. Here we propose a rate model based on two intrinsic mechanisms in the insect AL, namely integration and inhibition. Then we present a MB classiﬁer model that resembles the sparse and random structure of insect MB. A local Hebbian learning procedure governs the plasticity in the model. These formulations not only help to understand the signal conditioning and classiﬁcation methods of insect olfactory systems, but also can be leveraged in synthetic problems. Among them, we consider here the discrimination of odor mixtures from pure odors. We show on a set of records from metal-oxide gas sensors that the cascade of these two new models facilitates fast and accurate discrimination of even highly imbalanced mixtures from pure odors. 1</p><p>6 0.68700302 <a title="92-lda-6" href="./nips-2008-How_memory_biases_affect_information_transmission%3A_A_rational_analysis_of_serial_reproduction.html">100 nips-2008-How memory biases affect information transmission: A rational analysis of serial reproduction</a></p>
<p>7 0.68588513 <a title="92-lda-7" href="./nips-2008-Learning_Hybrid_Models_for_Image_Annotation_with_Partially_Labeled_Data.html">116 nips-2008-Learning Hybrid Models for Image Annotation with Partially Labeled Data</a></p>
<p>8 0.68548501 <a title="92-lda-8" href="./nips-2008-Shared_Segmentation_of_Natural_Scenes_Using_Dependent_Pitman-Yor_Processes.html">208 nips-2008-Shared Segmentation of Natural Scenes Using Dependent Pitman-Yor Processes</a></p>
<p>9 0.68396109 <a title="92-lda-9" href="./nips-2008-Differentiable_Sparse_Coding.html">62 nips-2008-Differentiable Sparse Coding</a></p>
<p>10 0.68296254 <a title="92-lda-10" href="./nips-2008-Robust_Kernel_Principal_Component_Analysis.html">200 nips-2008-Robust Kernel Principal Component Analysis</a></p>
<p>11 0.68170607 <a title="92-lda-11" href="./nips-2008-Dynamic_visual_attention%3A_searching_for_coding_length_increments.html">66 nips-2008-Dynamic visual attention: searching for coding length increments</a></p>
<p>12 0.68160409 <a title="92-lda-12" href="./nips-2008-Relative_Performance_Guarantees_for_Approximate_Inference_in_Latent_Dirichlet_Allocation.html">197 nips-2008-Relative Performance Guarantees for Approximate Inference in Latent Dirichlet Allocation</a></p>
<p>13 0.67941993 <a title="92-lda-13" href="./nips-2008-Learning_Transformational_Invariants_from_Natural_Movies.html">118 nips-2008-Learning Transformational Invariants from Natural Movies</a></p>
<p>14 0.67912799 <a title="92-lda-14" href="./nips-2008-Partially_Observed_Maximum_Entropy_Discrimination_Markov_Networks.html">176 nips-2008-Partially Observed Maximum Entropy Discrimination Markov Networks</a></p>
<p>15 0.67848676 <a title="92-lda-15" href="./nips-2008-Asynchronous_Distributed_Learning_of_Topic_Models.html">28 nips-2008-Asynchronous Distributed Learning of Topic Models</a></p>
<p>16 0.67670369 <a title="92-lda-16" href="./nips-2008-Dimensionality_Reduction_for_Data_in_Multiple_Feature_Representations.html">63 nips-2008-Dimensionality Reduction for Data in Multiple Feature Representations</a></p>
<p>17 0.67662585 <a title="92-lda-17" href="./nips-2008-Weighted_Sums_of_Random_Kitchen_Sinks%3A_Replacing_minimization_with_randomization_in_learning.html">250 nips-2008-Weighted Sums of Random Kitchen Sinks: Replacing minimization with randomization in learning</a></p>
<p>18 0.67609936 <a title="92-lda-18" href="./nips-2008-Reducing_statistical_dependencies_in_natural_signals_using_radial_Gaussianization.html">192 nips-2008-Reducing statistical dependencies in natural signals using radial Gaussianization</a></p>
<p>19 0.67438763 <a title="92-lda-19" href="./nips-2008-A_Scalable_Hierarchical_Distributed_Language_Model.html">4 nips-2008-A Scalable Hierarchical Distributed Language Model</a></p>
<p>20 0.67432457 <a title="92-lda-20" href="./nips-2008-Bayesian_Experimental_Design_of_Magnetic_Resonance_Imaging_Sequences.html">30 nips-2008-Bayesian Experimental Design of Magnetic Resonance Imaging Sequences</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
