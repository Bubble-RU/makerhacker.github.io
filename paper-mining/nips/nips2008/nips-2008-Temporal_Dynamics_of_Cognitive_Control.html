<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>231 nips-2008-Temporal Dynamics of Cognitive Control</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-231" href="#">nips2008-231</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>231 nips-2008-Temporal Dynamics of Cognitive Control</h1>
<br/><p>Source: <a title="nips-2008-231-pdf" href="http://papers.nips.cc/paper/3474-temporal-dynamics-of-cognitive-control.pdf">pdf</a></p><p>Author: Jeremy Reynolds, Michael C. Mozer</p><p>Abstract: Cognitive control refers to the ﬂexible deployment of memory and attention in response to task demands and current goals. Control is often studied experimentally by presenting sequences of stimuli, some demanding a response, and others modulating the stimulus-response mapping. In these tasks, participants must maintain information about the current stimulus-response mapping in working memory. Prominent theories of cognitive control use recurrent neural nets to implement working memory, and optimize memory utilization via reinforcement learning. We present a novel perspective on cognitive control in which working memory representations are intrinsically probabilistic, and control operations that maintain and update working memory are dynamically determined via probabilistic inference. We show that our model provides a parsimonious account of behavioral and neuroimaging data, and suggest that it offers an elegant conceptualization of control in which behavior can be cast as optimal, subject to limitations on learning and the rate of information processing. Moreover, our model provides insight into how task instructions can be directly translated into appropriate behavior and then efﬁciently reﬁned with subsequent task experience. 1</p><p>Reference: <a title="nips-2008-231-reference" href="../nips2008_reference/nips-2008-Temporal_Dynamics_of_Cognitive_Control_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract Cognitive control refers to the ﬂexible deployment of memory and attention in response to task demands and current goals. [sent-7, score-0.768]
</p><p>2 In these tasks, participants must maintain information about the current stimulus-response mapping in working memory. [sent-9, score-0.251]
</p><p>3 Prominent theories of cognitive control use recurrent neural nets to implement working memory, and optimize memory utilization via reinforcement learning. [sent-10, score-0.69]
</p><p>4 We present a novel perspective on cognitive control in which working memory representations are intrinsically probabilistic, and control operations that maintain and update working memory are dynamically determined via probabilistic inference. [sent-11, score-0.898]
</p><p>5 We show that our model provides a parsimonious account of behavioral and neuroimaging data, and suggest that it offers an elegant conceptualization of control in which behavior can be cast as optimal, subject to limitations on learning and the rate of information processing. [sent-12, score-0.487]
</p><p>6 Moreover, our model provides insight into how task instructions can be directly translated into appropriate behavior and then efﬁciently reﬁned with subsequent task experience. [sent-13, score-0.598]
</p><p>7 Classic examples of experimental tasks requiring this ability include Stroop, Wisconsin card sorting, and task switching (for a review, see [1]). [sent-16, score-0.453]
</p><p>8 Although these paradigms vary in superﬁcial features, they share the key underlying property that successful performance involves updating and maintaining a task set. [sent-17, score-0.264]
</p><p>9 For example, in Wisconsin card sorting, participants are asked to classify cards with varying numbers of instances of a colored symbol. [sent-21, score-0.255]
</p><p>10 The classiﬁcation might be based on color, symbol, or numerosity; instructions require participants to identify the current dimension through trial and error, and perform the appropriate classiﬁcation until the dimension switches after some unspeciﬁed number of trials. [sent-22, score-0.556]
</p><p>11 Thus, it requires participants to maintain a task set—the classiﬁcation dimension—in working memory (WM). [sent-23, score-0.547]
</p><p>12 Likewise, in the Stroop task, stimuli are color names presented in various ink colors, and the task set speciﬁes whether the color is to be named or the word is to be read. [sent-24, score-0.832]
</p><p>13 To understand cognitive control, we need to characterize the brain’s policy for updating, maintaining, and utilizing task set. [sent-25, score-0.436]
</p><p>14 Moreover, we need to develop theories of how task instructions are translated into a policy, and how this policy is reﬁned with subsequent experience performing a task. [sent-26, score-0.496]
</p><p>15 For example, in the Wisconsin card sorting task, the control instruction—the classiﬁcation dimension—would be bound to a variable, and responses would be produced by rules of the form, “If the current dimension is D and the stimulus is X, respond Y”. [sent-31, score-0.516]
</p><p>16 Consider the following phenomena: • When participants are asked to switch tasks, performance on the ﬁrst trial following a switch is inefﬁcient, although performance on subsequent trials is efﬁcient, suggesting that loading a new task set depends on actually performing the new task [3]. [sent-33, score-0.95]
</p><p>17 • Switch costs are asymmetric, such that switching from an easy task to a difﬁcult task is easier than vice-versa [4]. [sent-35, score-0.494]
</p><p>18 For example, in the Stroop task, reading the word is quick and accurate, but naming the ink color is not [5]. [sent-37, score-0.337]
</p><p>19 • The difﬁculty of a particular task depends not only on the characteristics of the task itself, but also on context in which participants might be called upon to perform [6]. [sent-38, score-0.582]
</p><p>20 To account for phenomena such as these, theories of control have in recent years focused on how control can be implemented in cortical neural networks. [sent-39, score-0.487]
</p><p>21 In the prevailing neural-network-based theory, task set is represented in an activity-based memory system, i. [sent-40, score-0.34]
</p><p>22 For example, in the Stroop task, instructions to report the ink color might bias the neural population representing colors—i. [sent-44, score-0.465]
</p><p>23 , increase their baseline activity prior to stimulus onset—such that when stimulus information arrives, it will reach threshold more rapidly, and will beat out the neural population that represents word orthography in triggering response systems [7]. [sent-46, score-0.754]
</p><p>24 In this framework, a control policy must specify the updating and maintenance task set, which involves when to gate new representations into WM and the strength of the recurrent connection that maintains the memory. [sent-47, score-0.663]
</p><p>25 First, like their symbolic predecessors, the neural network models must often be crippled arbitrarily to explain data; for example, by limiting the strength of recurrent memory connections, the models obtain task set decay and can explain error data. [sent-52, score-0.506]
</p><p>26 Second, the models require a stage of training which is far more akin to how a monkey learns to perform a task than to how people follow task instructions. [sent-53, score-0.418]
</p><p>27 The reinforcement-learning based models require a long stage of trial-and-error learning before the appropriate control policy emerges. [sent-54, score-0.251]
</p><p>28 Whereas monkeys are often trained for months prior to testing, a notable characteristic of humans is that they can perform a task adequately on the ﬁrst trial from task instructions [11]. [sent-55, score-0.732]
</p><p>29 Additionally, as a more abstract framework than the neural net theories, one aim is to provide insight as to how task instructions can be used directly and immediately to control behavior. [sent-59, score-0.568]
</p><p>30 That is, instead of proposing that task set is stored in an all-or-none fashion, we wish to allow for task set—as well as all cortical representations—to be treated as random variables. [sent-61, score-0.467]
</p><p>31 Given inherently probabilistic representations, it is natural to treat the problems of task set updating, maintenance and utilization as probabilistic inference. [sent-63, score-0.292]
</p><p>32 By analogy, our approach to cognitive control treats task set as a latent variable that must be inferred from observations. [sent-76, score-0.539]
</p><p>33 A second, distinct inference problem is to determine the correct response on the current trial from the current stimulus and the trial history. [sent-80, score-0.81]
</p><p>34 Thus, in our approach, control and response selection are cast as inference under uncertainty. [sent-81, score-0.366]
</p><p>35 Each experiment involves a complex task environment in which experimental participants are required to switch among eight tasks that have different degrees of overlap and inconsistency with one another. [sent-84, score-0.71]
</p><p>36 Having constrained the model by ﬁtting behavioral data, we then show that the model can explain neuroimaging data. [sent-85, score-0.363]
</p><p>37 Beyond accounting for data, the model provides an elegant theoretical framework in which control and response selection can be cast as optimal, subject to limitations on the processing architecture. [sent-87, score-0.417]
</p><p>38 In each experiment, participants are shown blocks of 12 trials, preceded by a cue that indicates which of the eight tasks is to be performed with the stimuli in that block. [sent-89, score-0.516]
</p><p>39 The notation indicates that task 3 requires a left response to the green square, a right response to a red square, and no response (hereafter, no-go) to a white square. [sent-97, score-0.892]
</p><p>40 Task 4 is identical to task 3, and the duplication is included because the tasks are described as distinct to participants and each is associated with a unique task cue. [sent-98, score-0.784]
</p><p>41 The duplication makes the stimulus-response mapping twice as likely, because the eight tasks have uniform priors. [sent-99, score-0.307]
</p><p>42 Task 1 (lower left corner of the ﬁgure) requires a left response for a green square and no-go for a white square. [sent-100, score-0.259]
</p><p>43 There are no red stimuli in the task 1 blocks, and the green→left mapping is depicted twice to indicate that the probability of a green square appearing in the block is twice that of a white square. [sent-101, score-0.603]
</p><p>44 The four tasks in the lower row allow for only one possible response (not counting no-go as a response), whereas the four tasks in the upper row demand that a choice be made between two possible responses. [sent-104, score-0.577]
</p><p>45 Thus, the two rows differ in terms of the demands placed on response selection. [sent-116, score-0.251]
</p><p>46 In the leftmost column, task identity does not matter, because each mapping (e. [sent-118, score-0.317]
</p><p>47 In contrast, tasks utilizing yellow, blue, and cyan stimuli involve varied mappings. [sent-121, score-0.25]
</p><p>48 The tasks in the middle column are somewhat less dependent on task identity, because the stimulus-response mappings called for have the highest prior. [sent-123, score-0.369]
</p><p>49 Thus, the three columns represent a continuum along which the importance of task identity varies, from being completely irrelevant (left column) to being critical for correct performance (right column). [sent-124, score-0.273]
</p><p>50 Rather than mapping a color to a response, the color determines which property of the stimulus is to be used to select a response. [sent-127, score-0.644]
</p><p>51 For example, task 3 of Figure 1B demands that a green letter stimulus (denoted as X here) be classiﬁed as a vowel or consonant (property P1), whereas a red letter stimulus be classiﬁed as upper or lower case (property P2). [sent-128, score-0.887]
</p><p>52 Thus, Experiment 2 places additional demands of stimulus classiﬁcation and selection of the appropriate stimulus dimension. [sent-129, score-0.482]
</p><p>53 Participants in each experiment received extensive practice on the eight tasks before being tested. [sent-130, score-0.271]
</p><p>54 1  A Probabilistic Generative Model of Control Tasks  Following the style of many probabilistic models in cognitive science, we have designed a generative model of the domain, and then invert the model to perform recognition via Bayesian inference. [sent-133, score-0.255]
</p><p>55 , the model produces sequences of stimulusresponse pairs such that the actual trial sequence would be generated with high probability. [sent-136, score-0.286]
</p><p>56 Instead of learning this model from data, though, we assume that task instructions are ’programmed’ into the model. [sent-137, score-0.389]
</p><p>57 Our generative model of control tasks is sketched in Figure 2A as a dynamical Bayes net. [sent-138, score-0.389]
</p><p>58 Vertical slices of the model represent the trial sequence, with the subscript denoting the trial index. [sent-139, score-0.421]
</p><p>59 The B node represents the task associated with the current block of trials. [sent-141, score-0.403]
</p><p>60 ) The block on trial k has 8 possible values in the experiments we 4  Bk-1  Bk  Ck-1  Rk-1  Sk-1  Bk+1  Ck  Rk  Sk T  Ck+1  Rk+1  Sk+1 T  T  Figure 2: Dynamical Bayes net depiction of our generative model of control tasks, showing the trial-to-trial structure of the model. [sent-143, score-0.609]
</p><p>61 model, and its value depends on the block on trial k 1. [sent-144, score-0.328]
</p><p>62 The block determines the category of the stimulus, C, which in turn determines the stimulus identity, S. [sent-145, score-0.419]
</p><p>63 The categories relevant to the present experiments are: color label, block cue (the cue that identiﬁes the task in the next block), upper/lower case for letters, and consonant/vowel for letters. [sent-146, score-0.629]
</p><p>64 Finally, the R node denotes the response, which depends both on the current stimulus category and the current block. [sent-150, score-0.327]
</p><p>65 First, we decompose the category and stimulus representations into shape and color dimensions, expanding C into C color and C shape , and S into S color and S shape . [sent-152, score-1.171]
</p><p>66 (When we refer to C or S without the superscript, it will denote both the shape and color components. [sent-153, score-0.284]
</p><p>67 ) Second, we wish to model the temporal dynamics of a single trial, in order to explain response latencies. [sent-154, score-0.292]
</p><p>68 With normalization of probabilities, this formulation is identical to a naive Bayes model with conditionally independent stimulus observations at each time step. [sent-156, score-0.261]
</p><p>69 The context is provided by the block B, which is essentially a memory that can be sustained over trials. [sent-159, score-0.274]
</p><p>70 This distribution is a mixture of a uniform distribution (no memory of block) and an identity mapping (perfect memory). [sent-164, score-0.239]
</p><p>71 z z P (Ck Bk ) = P (Ck Bk ) + (1 ) NC z , where z color shape and NC z is the number of distinct category values along dimension z, and P ( ) is the probability distribution deﬁned by the experiment and task (see Figure 2B,C). [sent-165, score-0.69]
</p><p>72 z z P (Sk = s Ck = c T = t) (1 + z M z (s c))t , where z color shape and M z (s c) is a membership function that has value 1 if s is an instance of category c along dimension z, or 0 otherwise. [sent-168, score-0.389]
</p><p>73 MR SIgnal  premotor cortex  posterior lateral PFC  anterior lateral PFC  Single Dual  Cshape node  B node  MODEL Entropy  R node  Exp. [sent-170, score-0.351]
</p><p>74 2  Importance of Task Identity  Figure 3: (top row) human neuroimaging data from three brain regions [6], (bottom row) entropy read out from three nodes of the model. [sent-174, score-0.357]
</p><p>75 We would like to read out from the model a response on some trial k, given the stimulus on trial k, Sk , and a history of past stimulus-response pairs, Hk = {S1 . [sent-179, score-0.86]
</p><p>76 The model initiates a response when one value of Rk passes a threshold θ, i. [sent-191, score-0.24]
</p><p>77 This yields the response time (RT) t∗ = min t | max P (Rk = r|Sk , T = t, Hk ) > θ r  (1)  and the response r∗ = argmaxr P (Rk = r|Sk , T = t∗ , Hk ). [sent-194, score-0.378]
</p><p>78 4  Simulation Results  We simulated the model on a trial sequence like that in the human study. [sent-195, score-0.291]
</p><p>79 , 6  the model never attained the response criterion of Equation 1), or in which the model produced no RT variation across conditions. [sent-217, score-0.291]
</p><p>80 Koechlin, Ody, and Kouneiher [6] collected not only behavioral data, but also neuroimaging data that identiﬁed brain regions involved in control, and how these brain regions modulated their activation across experimental manipulations. [sent-229, score-0.327]
</p><p>81 The top row of Figure 3 shows effects of these experimental manipulations on the fMRI BOLD response of three different brain regions. [sent-231, score-0.303]
</p><p>82 The remarkable result obtained in our simulations is that we identiﬁed three components of the model that produced signatures analogous to those of the fMRI BOLD response in three cortical areas. [sent-232, score-0.289]
</p><p>83 We hypothesized that neural (fMRI) activity in the brain might be related to the entropy of nodes in the model, on account of the fact that when entropy is high, many possibilities must be simultaneously represented, which may lead to greater BOLD signal. [sent-233, score-0.301]
</p><p>84 The model entropy results are shown in the bottom row of Figure 3, and comparison with the top row reveals an exact correspondence. [sent-244, score-0.252]
</p><p>85 Starting with the left column of Figure 3, uncertainty in the model’s response corresponds to activity in premotor cortex. [sent-248, score-0.334]
</p><p>86 This activity is greater when the block calls for two distinct responses than when it calls for one. [sent-249, score-0.244]
</p><p>87 In the middle column of Figure 3, the uncertainty of shape categorization corresponds to activity in posterior lateral prefrontal cortex. [sent-250, score-0.35]
</p><p>88 In the right column of Figure 3, the uncertainty of the task identity (block) in the model corresponds to activity in anterior lateral PFC, a brain region near areas known to be involved in WM maintenance. [sent-252, score-0.543]
</p><p>89 There is a natural explanation for this inversion, though: entropy is high in the block node when the block representation matters the least, i. [sent-254, score-0.428]
</p><p>90 , when the stimulus-response mapping does not depend on knowing the task identity. [sent-256, score-0.253]
</p><p>91 Thus, higher entropy of the block node actually connotes less information to be maintained due to the functional equivalence among classes. [sent-257, score-0.285]
</p><p>92 5  Discussion  We proposed a theoretical framework for understanding cognitive control which provides a parsimonious account of behavioral and neuroimaging data from two large experiments. [sent-258, score-0.539]
</p><p>93 [6] explain their ﬁndings in terms of a descriptive model that involves a complex hierarchy of control processes within prefrontal cortex. [sent-263, score-0.381]
</p><p>94 5 0 0  10  20  30  40  50 60 Trial Number  70  80  90  100  1 2 3 4 5 6 7 8  Figure 4: Task (block) representation over a sequence of trials that involves all eight task types. [sent-266, score-0.362]
</p><p>95 Another novelty of our approach is the notion of that control results from dynamical inference processes, instead of being conceived of as resulting from long-term policy learning. [sent-272, score-0.385]
</p><p>96 The stimulus stream sometimes supports the WM representation and sometimes disrupts it. [sent-276, score-0.251]
</p><p>97 Fortunately for the model’s performance, this is exactly the circumstance in which remembering the task identity is least critical. [sent-280, score-0.273]
</p><p>98 We are currently pursuing opportunities to examine the model’s predictions regarding performance on the ﬁrst trial in a block versus subsequent trials. [sent-283, score-0.328]
</p><p>99 The model shows an effect observed in the task switching literature: initial trial performance is poor, but control rapidly tunes to the task and subsequent trials are more efﬁcient and roughly comparable. [sent-284, score-0.958]
</p><p>100 Neuroscience: The architecture of cognitive control in the human prefrontal cortex. [sent-317, score-0.531]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('wm', 0.282), ('stimulus', 0.21), ('task', 0.209), ('stroop', 0.199), ('color', 0.195), ('response', 0.189), ('trial', 0.185), ('control', 0.177), ('participants', 0.164), ('cognitive', 0.153), ('block', 0.143), ('memory', 0.131), ('instructions', 0.129), ('bk', 0.124), ('tasks', 0.118), ('neuroimaging', 0.112), ('cpds', 0.109), ('eight', 0.102), ('prefrontal', 0.101), ('rk', 0.1), ('ink', 0.099), ('koechlin', 0.099), ('xx', 0.098), ('behavioral', 0.097), ('ck', 0.095), ('entropy', 0.091), ('stimuli', 0.091), ('sk', 0.091), ('shape', 0.089), ('theories', 0.084), ('pfc', 0.08), ('fmri', 0.077), ('switching', 0.076), ('ody', 0.074), ('policy', 0.074), ('green', 0.07), ('switch', 0.066), ('category', 0.066), ('identity', 0.064), ('demands', 0.062), ('room', 0.062), ('recurrent', 0.062), ('cells', 0.061), ('activity', 0.06), ('brain', 0.059), ('lateral', 0.058), ('rts', 0.056), ('updating', 0.055), ('human', 0.055), ('row', 0.055), ('net', 0.053), ('explain', 0.052), ('node', 0.051), ('trials', 0.051), ('model', 0.051), ('experiment', 0.051), ('card', 0.05), ('wisconsin', 0.05), ('conceived', 0.05), ('conceptualization', 0.05), ('kouneiher', 0.05), ('shower', 0.05), ('stimulusresponse', 0.05), ('toilet', 0.05), ('hk', 0.049), ('cortical', 0.049), ('simulation', 0.047), ('red', 0.046), ('architecture', 0.045), ('mapping', 0.044), ('duplication', 0.043), ('denver', 0.043), ('premotor', 0.043), ('integrative', 0.043), ('maintenance', 0.043), ('embodied', 0.043), ('emergent', 0.043), ('stephen', 0.043), ('word', 0.043), ('working', 0.043), ('dynamical', 0.043), ('representations', 0.043), ('population', 0.042), ('demand', 0.042), ('column', 0.042), ('varied', 0.041), ('notion', 0.041), ('stream', 0.041), ('cue', 0.041), ('colored', 0.041), ('distinct', 0.041), ('letter', 0.04), ('sorting', 0.04), ('read', 0.04), ('instruction', 0.04), ('sink', 0.04), ('utilization', 0.04), ('psychology', 0.039), ('cortex', 0.039), ('dimension', 0.039)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999875 <a title="231-tfidf-1" href="./nips-2008-Temporal_Dynamics_of_Cognitive_Control.html">231 nips-2008-Temporal Dynamics of Cognitive Control</a></p>
<p>Author: Jeremy Reynolds, Michael C. Mozer</p><p>Abstract: Cognitive control refers to the ﬂexible deployment of memory and attention in response to task demands and current goals. Control is often studied experimentally by presenting sequences of stimuli, some demanding a response, and others modulating the stimulus-response mapping. In these tasks, participants must maintain information about the current stimulus-response mapping in working memory. Prominent theories of cognitive control use recurrent neural nets to implement working memory, and optimize memory utilization via reinforcement learning. We present a novel perspective on cognitive control in which working memory representations are intrinsically probabilistic, and control operations that maintain and update working memory are dynamically determined via probabilistic inference. We show that our model provides a parsimonious account of behavioral and neuroimaging data, and suggest that it offers an elegant conceptualization of control in which behavior can be cast as optimal, subject to limitations on learning and the rate of information processing. Moreover, our model provides insight into how task instructions can be directly translated into appropriate behavior and then efﬁciently reﬁned with subsequent task experience. 1</p><p>2 0.20331098 <a title="231-tfidf-2" href="./nips-2008-Optimal_Response_Initiation%3A_Why_Recent_Experience_Matters.html">172 nips-2008-Optimal Response Initiation: Why Recent Experience Matters</a></p>
<p>Author: Matt Jones, Sachiko Kinoshita, Michael C. Mozer</p><p>Abstract: In most cognitive and motor tasks, speed-accuracy tradeoffs are observed: Individuals can respond slowly and accurately, or quickly yet be prone to errors. Control mechanisms governing the initiation of behavioral responses are sensitive not only to task instructions and the stimulus being processed, but also to the recent stimulus history. When stimuli can be characterized on an easy-hard dimension (e.g., word frequency in a naming task), items preceded by easy trials are responded to more quickly, and with more errors, than items preceded by hard trials. We propose a rationally motivated mathematical model of this sequential adaptation of control, based on a diffusion model of the decision process in which difﬁculty corresponds to the drift rate for the correct response. The model assumes that responding is based on the posterior distribution over which response is correct, conditioned on the accumulated evidence. We derive this posterior as a function of the drift rate, and show that higher estimates of the drift rate lead to (normatively) faster responding. Trial-by-trial tracking of difﬁculty thus leads to sequential effects in speed and accuracy. Simulations show the model explains a variety of phenomena in human speeded decision making. We argue this passive statistical mechanism provides a more elegant and parsimonious account than extant theories based on elaborate control structures. 1</p><p>3 0.19411023 <a title="231-tfidf-3" href="./nips-2008-Learning_to_Use_Working_Memory_in_Partially_Observable_Environments_through_Dopaminergic_Reinforcement.html">121 nips-2008-Learning to Use Working Memory in Partially Observable Environments through Dopaminergic Reinforcement</a></p>
<p>Author: Michael T. Todd, Yael Niv, Jonathan D. Cohen</p><p>Abstract: Working memory is a central topic of cognitive neuroscience because it is critical for solving real-world problems in which information from multiple temporally distant sources must be combined to generate appropriate behavior. However, an often neglected fact is that learning to use working memory effectively is itself a difficult problem. The Gating framework [14] is a collection of psychological models that show how dopamine can train the basal ganglia and prefrontal cortex to form useful working memory representations in certain types of problems. We unite Gating with machine learning theory concerning the general problem of memory-based optimal control [5-6]. We present a normative model that learns, by online temporal difference methods, to use working memory to maximize discounted future reward in partially observable settings. The model successfully solves a benchmark working memory problem, and exhibits limitations similar to those observed in humans. Our purpose is to introduce a concise, normative definition of high level cognitive concepts such as working memory and cognitive control in terms of maximizing discounted future rewards. 1 I n t ro d u c t i o n Working memory is loosely defined in cognitive neuroscience as information that is (1) internally maintained on a temporary or short term basis, and (2) required for tasks in which immediate observations cannot be mapped to correct actions. It is widely assumed that prefrontal cortex (PFC) plays a role in maintaining and updating working memory. However, relatively little is known about how PFC develops useful working memory representations for a new task. Furthermore, current work focuses on describing the structure and limitations of working memory, but does not ask why, or in what general class of tasks, is it necessary. Borrowing from the theory of optimal control in partially observable Markov decision problems (POMDPs), we frame the psychological concept of working memory as an internal state representation, developed and employed to maximize future reward in partially observable environments. We combine computational insights from POMDPs and neurobiologically plausible models from cognitive neuroscience to suggest a simple reinforcement learning (RL) model of working memory function that can be implemented through dopaminergic training of the basal ganglia and PFC. The Gating framework is a series of cognitive neuroscience models developed to explain how dopaminergic RL signals can shape useful working memory representations [1-4]. Computationally this framework models working memory as a collection of past observations, each of which can occasionally be replaced with the current observation, and addresses the problem of learning when to update each memory element versus maintaining it. In the original Gating model [1-2] the PFC contained a unitary working memory representation that was updated whenever a phasic dopamine (DA) burst occurred (e.g., due to unexpected reward or novelty). That model was the first to connect working memory and RL via the temporal difference (TD) model of DA firing [7-8], and thus to suggest how working memory might serve a normative purpose. However, that model had limited computational flexibility due to the unitary nature of the working memory (i.e., a singleobservation memory controlled by a scalar DA signal). More recent work [3-4] has partially repositioned the Gating framework within the Actor/Critic model of mesostriatal RL [9-10], positing memory updating as but another cortical action controlled by the dorsal striatal</p><p>4 0.14779903 <a title="231-tfidf-4" href="./nips-2008-Sequential_effects%3A_Superstition_or_rational_behavior%3F.html">206 nips-2008-Sequential effects: Superstition or rational behavior?</a></p>
<p>Author: Angela J. Yu, Jonathan D. Cohen</p><p>Abstract: In a variety of behavioral tasks, subjects exhibit an automatic and apparently suboptimal sequential effect: they respond more rapidly and accurately to a stimulus if it reinforces a local pattern in stimulus history, such as a string of repetitions or alternations, compared to when it violates such a pattern. This is often the case even if the local trends arise by chance in the context of a randomized design, such that stimulus history has no real predictive power. In this work, we use a normative Bayesian framework to examine the hypothesis that such idiosyncrasies may reﬂect the inadvertent engagement of mechanisms critical for adapting to a changing environment. We show that prior belief in non-stationarity can induce experimentally observed sequential effects in an otherwise Bayes-optimal algorithm. The Bayesian algorithm is shown to be well approximated by linear-exponential ﬁltering of past observations, a feature also apparent in the behavioral data. We derive an explicit relationship between the parameters and computations of the exact Bayesian algorithm and those of the approximate linear-exponential ﬁlter. Since the latter is equivalent to a leaky-integration process, a commonly used model of neuronal dynamics underlying perceptual decision-making and trial-to-trial dependencies, our model provides a principled account of why such dynamics are useful. We also show that parameter-tuning of the leaky-integration process is possible, using stochastic gradient descent based only on the noisy binary inputs. This is a proof of concept that not only can neurons implement near-optimal prediction based on standard neuronal dynamics, but that they can also learn to tune the processing parameters without explicitly representing probabilities. 1</p><p>5 0.13091417 <a title="231-tfidf-5" href="./nips-2008-Interpreting_the_neural_code_with_Formal_Concept_Analysis.html">109 nips-2008-Interpreting the neural code with Formal Concept Analysis</a></p>
<p>Author: Dominik Endres, Peter Foldiak</p><p>Abstract: We propose a novel application of Formal Concept Analysis (FCA) to neural decoding: instead of just trying to ﬁgure out which stimulus was presented, we demonstrate how to explore the semantic relationships in the neural representation of large sets of stimuli. FCA provides a way of displaying and interpreting such relationships via concept lattices. We explore the effects of neural code sparsity on the lattice. We then analyze neurophysiological data from high-level visual cortical area STSa, using an exact Bayesian approach to construct the formal context needed by FCA. Prominent features of the resulting concept lattices are discussed, including hierarchical face representation and indications for a product-of-experts code in real neurons. 1</p><p>6 0.12566832 <a title="231-tfidf-6" href="./nips-2008-How_memory_biases_affect_information_transmission%3A_A_rational_analysis_of_serial_reproduction.html">100 nips-2008-How memory biases affect information transmission: A rational analysis of serial reproduction</a></p>
<p>7 0.11699273 <a title="231-tfidf-7" href="./nips-2008-Effects_of_Stimulus_Type_and_of_Error-Correcting_Code_Design_on_BCI_Speller_Performance.html">67 nips-2008-Effects of Stimulus Type and of Error-Correcting Code Design on BCI Speller Performance</a></p>
<p>8 0.11034069 <a title="231-tfidf-8" href="./nips-2008-Designing_neurophysiology_experiments_to_optimally_constrain_receptive_field_models_along_parametric_submanifolds.html">60 nips-2008-Designing neurophysiology experiments to optimally constrain receptive field models along parametric submanifolds</a></p>
<p>9 0.10593385 <a title="231-tfidf-9" href="./nips-2008-Analyzing_human_feature_learning_as_nonparametric_Bayesian_inference.html">26 nips-2008-Analyzing human feature learning as nonparametric Bayesian inference</a></p>
<p>10 0.099950641 <a title="231-tfidf-10" href="./nips-2008-Human_Active_Learning.html">101 nips-2008-Human Active Learning</a></p>
<p>11 0.096969306 <a title="231-tfidf-11" href="./nips-2008-A_Convergent_%24O%28n%29%24_Temporal-difference_Algorithm_for_Off-policy_Learning_with_Linear_Function_Approximation.html">1 nips-2008-A Convergent $O(n)$ Temporal-difference Algorithm for Off-policy Learning with Linear Function Approximation</a></p>
<p>12 0.09517312 <a title="231-tfidf-12" href="./nips-2008-Generative_versus_discriminative_training_of_RBMs_for_classification_of_fMRI_images.html">92 nips-2008-Generative versus discriminative training of RBMs for classification of fMRI images</a></p>
<p>13 0.09317784 <a title="231-tfidf-13" href="./nips-2008-Tracking_Changing_Stimuli_in_Continuous_Attractor_Neural_Networks.html">240 nips-2008-Tracking Changing Stimuli in Continuous Attractor Neural Networks</a></p>
<p>14 0.080617875 <a title="231-tfidf-14" href="./nips-2008-Cell_Assemblies_in_Large_Sparse_Inhibitory_Networks_of_Biologically_Realistic_Spiking_Neurons.html">43 nips-2008-Cell Assemblies in Large Sparse Inhibitory Networks of Biologically Realistic Spiking Neurons</a></p>
<p>15 0.079690367 <a title="231-tfidf-15" href="./nips-2008-Policy_Search_for_Motor_Primitives_in_Robotics.html">181 nips-2008-Policy Search for Motor Primitives in Robotics</a></p>
<p>16 0.079100363 <a title="231-tfidf-16" href="./nips-2008-Psychiatry%3A_Insights_into_depression_through_normative_decision-making_models.html">187 nips-2008-Psychiatry: Insights into depression through normative decision-making models</a></p>
<p>17 0.078501672 <a title="231-tfidf-17" href="./nips-2008-Modeling_human_function_learning_with_Gaussian_processes.html">138 nips-2008-Modeling human function learning with Gaussian processes</a></p>
<p>18 0.076194987 <a title="231-tfidf-18" href="./nips-2008-Transfer_Learning_by_Distribution_Matching_for_Targeted_Advertising.html">241 nips-2008-Transfer Learning by Distribution Matching for Targeted Advertising</a></p>
<p>19 0.075886697 <a title="231-tfidf-19" href="./nips-2008-Characterizing_response_behavior_in_multisensory_perception_with_conflicting_cues.html">46 nips-2008-Characterizing response behavior in multisensory perception with conflicting cues</a></p>
<p>20 0.075534016 <a title="231-tfidf-20" href="./nips-2008-Playing_Pinball_with_non-invasive_BCI.html">180 nips-2008-Playing Pinball with non-invasive BCI</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2008_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.25), (1, 0.129), (2, 0.184), (3, -0.023), (4, 0.057), (5, 0.035), (6, -0.028), (7, 0.054), (8, 0.12), (9, 0.095), (10, -0.024), (11, 0.118), (12, -0.217), (13, 0.012), (14, -0.027), (15, 0.216), (16, 0.099), (17, -0.029), (18, 0.031), (19, -0.065), (20, -0.081), (21, -0.07), (22, 0.105), (23, -0.038), (24, -0.098), (25, -0.024), (26, 0.047), (27, 0.112), (28, -0.002), (29, -0.047), (30, -0.121), (31, -0.031), (32, 0.041), (33, -0.006), (34, -0.087), (35, -0.003), (36, -0.058), (37, 0.036), (38, 0.059), (39, 0.15), (40, 0.035), (41, 0.045), (42, 0.025), (43, 0.061), (44, -0.066), (45, -0.098), (46, -0.025), (47, -0.058), (48, -0.083), (49, -0.005)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97486293 <a title="231-lsi-1" href="./nips-2008-Temporal_Dynamics_of_Cognitive_Control.html">231 nips-2008-Temporal Dynamics of Cognitive Control</a></p>
<p>Author: Jeremy Reynolds, Michael C. Mozer</p><p>Abstract: Cognitive control refers to the ﬂexible deployment of memory and attention in response to task demands and current goals. Control is often studied experimentally by presenting sequences of stimuli, some demanding a response, and others modulating the stimulus-response mapping. In these tasks, participants must maintain information about the current stimulus-response mapping in working memory. Prominent theories of cognitive control use recurrent neural nets to implement working memory, and optimize memory utilization via reinforcement learning. We present a novel perspective on cognitive control in which working memory representations are intrinsically probabilistic, and control operations that maintain and update working memory are dynamically determined via probabilistic inference. We show that our model provides a parsimonious account of behavioral and neuroimaging data, and suggest that it offers an elegant conceptualization of control in which behavior can be cast as optimal, subject to limitations on learning and the rate of information processing. Moreover, our model provides insight into how task instructions can be directly translated into appropriate behavior and then efﬁciently reﬁned with subsequent task experience. 1</p><p>2 0.88728744 <a title="231-lsi-2" href="./nips-2008-Optimal_Response_Initiation%3A_Why_Recent_Experience_Matters.html">172 nips-2008-Optimal Response Initiation: Why Recent Experience Matters</a></p>
<p>Author: Matt Jones, Sachiko Kinoshita, Michael C. Mozer</p><p>Abstract: In most cognitive and motor tasks, speed-accuracy tradeoffs are observed: Individuals can respond slowly and accurately, or quickly yet be prone to errors. Control mechanisms governing the initiation of behavioral responses are sensitive not only to task instructions and the stimulus being processed, but also to the recent stimulus history. When stimuli can be characterized on an easy-hard dimension (e.g., word frequency in a naming task), items preceded by easy trials are responded to more quickly, and with more errors, than items preceded by hard trials. We propose a rationally motivated mathematical model of this sequential adaptation of control, based on a diffusion model of the decision process in which difﬁculty corresponds to the drift rate for the correct response. The model assumes that responding is based on the posterior distribution over which response is correct, conditioned on the accumulated evidence. We derive this posterior as a function of the drift rate, and show that higher estimates of the drift rate lead to (normatively) faster responding. Trial-by-trial tracking of difﬁculty thus leads to sequential effects in speed and accuracy. Simulations show the model explains a variety of phenomena in human speeded decision making. We argue this passive statistical mechanism provides a more elegant and parsimonious account than extant theories based on elaborate control structures. 1</p><p>3 0.73939538 <a title="231-lsi-3" href="./nips-2008-Learning_to_Use_Working_Memory_in_Partially_Observable_Environments_through_Dopaminergic_Reinforcement.html">121 nips-2008-Learning to Use Working Memory in Partially Observable Environments through Dopaminergic Reinforcement</a></p>
<p>Author: Michael T. Todd, Yael Niv, Jonathan D. Cohen</p><p>Abstract: Working memory is a central topic of cognitive neuroscience because it is critical for solving real-world problems in which information from multiple temporally distant sources must be combined to generate appropriate behavior. However, an often neglected fact is that learning to use working memory effectively is itself a difficult problem. The Gating framework [14] is a collection of psychological models that show how dopamine can train the basal ganglia and prefrontal cortex to form useful working memory representations in certain types of problems. We unite Gating with machine learning theory concerning the general problem of memory-based optimal control [5-6]. We present a normative model that learns, by online temporal difference methods, to use working memory to maximize discounted future reward in partially observable settings. The model successfully solves a benchmark working memory problem, and exhibits limitations similar to those observed in humans. Our purpose is to introduce a concise, normative definition of high level cognitive concepts such as working memory and cognitive control in terms of maximizing discounted future rewards. 1 I n t ro d u c t i o n Working memory is loosely defined in cognitive neuroscience as information that is (1) internally maintained on a temporary or short term basis, and (2) required for tasks in which immediate observations cannot be mapped to correct actions. It is widely assumed that prefrontal cortex (PFC) plays a role in maintaining and updating working memory. However, relatively little is known about how PFC develops useful working memory representations for a new task. Furthermore, current work focuses on describing the structure and limitations of working memory, but does not ask why, or in what general class of tasks, is it necessary. Borrowing from the theory of optimal control in partially observable Markov decision problems (POMDPs), we frame the psychological concept of working memory as an internal state representation, developed and employed to maximize future reward in partially observable environments. We combine computational insights from POMDPs and neurobiologically plausible models from cognitive neuroscience to suggest a simple reinforcement learning (RL) model of working memory function that can be implemented through dopaminergic training of the basal ganglia and PFC. The Gating framework is a series of cognitive neuroscience models developed to explain how dopaminergic RL signals can shape useful working memory representations [1-4]. Computationally this framework models working memory as a collection of past observations, each of which can occasionally be replaced with the current observation, and addresses the problem of learning when to update each memory element versus maintaining it. In the original Gating model [1-2] the PFC contained a unitary working memory representation that was updated whenever a phasic dopamine (DA) burst occurred (e.g., due to unexpected reward or novelty). That model was the first to connect working memory and RL via the temporal difference (TD) model of DA firing [7-8], and thus to suggest how working memory might serve a normative purpose. However, that model had limited computational flexibility due to the unitary nature of the working memory (i.e., a singleobservation memory controlled by a scalar DA signal). More recent work [3-4] has partially repositioned the Gating framework within the Actor/Critic model of mesostriatal RL [9-10], positing memory updating as but another cortical action controlled by the dorsal striatal</p><p>4 0.69395941 <a title="231-lsi-4" href="./nips-2008-How_memory_biases_affect_information_transmission%3A_A_rational_analysis_of_serial_reproduction.html">100 nips-2008-How memory biases affect information transmission: A rational analysis of serial reproduction</a></p>
<p>Author: Jing Xu, Thomas L. Griffiths</p><p>Abstract: Many human interactions involve pieces of information being passed from one person to another, raising the question of how this process of information transmission is affected by the capacities of the agents involved. In the 1930s, Sir Frederic Bartlett explored the inﬂuence of memory biases in “serial reproduction” of information, in which one person’s reconstruction of a stimulus from memory becomes the stimulus seen by the next person. These experiments were done using relatively uncontrolled stimuli such as pictures and stories, but suggested that serial reproduction would transform information in a way that reﬂected the biases inherent in memory. We formally analyze serial reproduction using a Bayesian model of reconstruction from memory, giving a general result characterizing the effect of memory biases on information transmission. We then test the predictions of this account in two experiments using simple one-dimensional stimuli. Our results provide theoretical and empirical justiﬁcation for the idea that serial reproduction reﬂects memory biases. 1</p><p>5 0.6741668 <a title="231-lsi-5" href="./nips-2008-Effects_of_Stimulus_Type_and_of_Error-Correcting_Code_Design_on_BCI_Speller_Performance.html">67 nips-2008-Effects of Stimulus Type and of Error-Correcting Code Design on BCI Speller Performance</a></p>
<p>Author: Jeremy Hill, Jason Farquhar, Suzanna Martens, Felix Biessmann, Bernhard Schölkopf</p><p>Abstract: From an information-theoretic perspective, a noisy transmission system such as a visual Brain-Computer Interface (BCI) speller could beneﬁt from the use of errorcorrecting codes. However, optimizing the code solely according to the maximal minimum-Hamming-distance criterion tends to lead to an overall increase in target frequency of target stimuli, and hence a signiﬁcantly reduced average target-to-target interval (TTI), leading to difﬁculties in classifying the individual event-related potentials (ERPs) due to overlap and refractory effects. Clearly any change to the stimulus setup must also respect the possible psychophysiological consequences. Here we report new EEG data from experiments in which we explore stimulus types and codebooks in a within-subject design, ﬁnding an interaction between the two factors. Our data demonstrate that the traditional, rowcolumn code has particular spatial properties that lead to better performance than one would expect from its TTIs and Hamming-distances alone, but nonetheless error-correcting codes can improve performance provided the right stimulus type is used. 1</p><p>6 0.66362852 <a title="231-lsi-6" href="./nips-2008-Interpreting_the_neural_code_with_Formal_Concept_Analysis.html">109 nips-2008-Interpreting the neural code with Formal Concept Analysis</a></p>
<p>7 0.65382248 <a title="231-lsi-7" href="./nips-2008-A_computational_model_of_hippocampal_function_in_trace_conditioning.html">7 nips-2008-A computational model of hippocampal function in trace conditioning</a></p>
<p>8 0.65218955 <a title="231-lsi-8" href="./nips-2008-Load_and_Attentional_Bayes.html">124 nips-2008-Load and Attentional Bayes</a></p>
<p>9 0.63320905 <a title="231-lsi-9" href="./nips-2008-Psychiatry%3A_Insights_into_depression_through_normative_decision-making_models.html">187 nips-2008-Psychiatry: Insights into depression through normative decision-making models</a></p>
<p>10 0.57364982 <a title="231-lsi-10" href="./nips-2008-Tracking_Changing_Stimuli_in_Continuous_Attractor_Neural_Networks.html">240 nips-2008-Tracking Changing Stimuli in Continuous Attractor Neural Networks</a></p>
<p>11 0.57321751 <a title="231-lsi-11" href="./nips-2008-Stress%2C_noradrenaline%2C_and_realistic_prediction_of_mouse_behaviour_using_reinforcement_learning.html">222 nips-2008-Stress, noradrenaline, and realistic prediction of mouse behaviour using reinforcement learning</a></p>
<p>12 0.55293834 <a title="231-lsi-12" href="./nips-2008-Sequential_effects%3A_Superstition_or_rational_behavior%3F.html">206 nips-2008-Sequential effects: Superstition or rational behavior?</a></p>
<p>13 0.53752232 <a title="231-lsi-13" href="./nips-2008-Designing_neurophysiology_experiments_to_optimally_constrain_receptive_field_models_along_parametric_submanifolds.html">60 nips-2008-Designing neurophysiology experiments to optimally constrain receptive field models along parametric submanifolds</a></p>
<p>14 0.53525555 <a title="231-lsi-14" href="./nips-2008-A_general_framework_for_investigating_how_far_the_decoding_process_in_the_brain_can_be_simplified.html">8 nips-2008-A general framework for investigating how far the decoding process in the brain can be simplified</a></p>
<p>15 0.47639123 <a title="231-lsi-15" href="./nips-2008-Playing_Pinball_with_non-invasive_BCI.html">180 nips-2008-Playing Pinball with non-invasive BCI</a></p>
<p>16 0.47108001 <a title="231-lsi-16" href="./nips-2008-An_ideal_observer_model_of_infant_object_perception.html">23 nips-2008-An ideal observer model of infant object perception</a></p>
<p>17 0.46625045 <a title="231-lsi-17" href="./nips-2008-Characterizing_response_behavior_in_multisensory_perception_with_conflicting_cues.html">46 nips-2008-Characterizing response behavior in multisensory perception with conflicting cues</a></p>
<p>18 0.46337804 <a title="231-lsi-18" href="./nips-2008-Goal-directed_decision_making_in_prefrontal_cortex%3A_a_computational_framework.html">94 nips-2008-Goal-directed decision making in prefrontal cortex: a computational framework</a></p>
<p>19 0.46169621 <a title="231-lsi-19" href="./nips-2008-A_spatially_varying_two-sample_recombinant_coalescent%2C_with_applications_to_HIV_escape_response.html">11 nips-2008-A spatially varying two-sample recombinant coalescent, with applications to HIV escape response</a></p>
<p>20 0.45797479 <a title="231-lsi-20" href="./nips-2008-Kernel-ARMA_for_Hand_Tracking_and_Brain-Machine_interfacing_During_3D_Motor_Control.html">110 nips-2008-Kernel-ARMA for Hand Tracking and Brain-Machine interfacing During 3D Motor Control</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2008_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(4, 0.032), (6, 0.074), (7, 0.082), (12, 0.039), (15, 0.026), (28, 0.201), (48, 0.173), (57, 0.086), (59, 0.023), (63, 0.035), (71, 0.018), (77, 0.065), (78, 0.025), (83, 0.052)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.87886894 <a title="231-lda-1" href="./nips-2008-Temporal_Dynamics_of_Cognitive_Control.html">231 nips-2008-Temporal Dynamics of Cognitive Control</a></p>
<p>Author: Jeremy Reynolds, Michael C. Mozer</p><p>Abstract: Cognitive control refers to the ﬂexible deployment of memory and attention in response to task demands and current goals. Control is often studied experimentally by presenting sequences of stimuli, some demanding a response, and others modulating the stimulus-response mapping. In these tasks, participants must maintain information about the current stimulus-response mapping in working memory. Prominent theories of cognitive control use recurrent neural nets to implement working memory, and optimize memory utilization via reinforcement learning. We present a novel perspective on cognitive control in which working memory representations are intrinsically probabilistic, and control operations that maintain and update working memory are dynamically determined via probabilistic inference. We show that our model provides a parsimonious account of behavioral and neuroimaging data, and suggest that it offers an elegant conceptualization of control in which behavior can be cast as optimal, subject to limitations on learning and the rate of information processing. Moreover, our model provides insight into how task instructions can be directly translated into appropriate behavior and then efﬁciently reﬁned with subsequent task experience. 1</p><p>2 0.81004393 <a title="231-lda-2" href="./nips-2008-Exploring_Large_Feature_Spaces_with_Hierarchical_Multiple_Kernel_Learning.html">79 nips-2008-Exploring Large Feature Spaces with Hierarchical Multiple Kernel Learning</a></p>
<p>Author: Francis R. Bach</p><p>Abstract: For supervised and unsupervised learning, positive deﬁnite kernels allow to use large and potentially inﬁnite dimensional feature spaces with a computational cost that only depends on the number of observations. This is usually done through the penalization of predictor functions by Euclidean or Hilbertian norms. In this paper, we explore penalizing by sparsity-inducing norms such as the ℓ1 -norm or the block ℓ1 -norm. We assume that the kernel decomposes into a large sum of individual basis kernels which can be embedded in a directed acyclic graph; we show that it is then possible to perform kernel selection through a hierarchical multiple kernel learning framework, in polynomial time in the number of selected kernels. This framework is naturally applied to non linear variable selection; our extensive simulations on synthetic datasets and datasets from the UCI repository show that efﬁciently exploring the large feature space through sparsity-inducing norms leads to state-of-the-art predictive performance.</p><p>3 0.80955523 <a title="231-lda-3" href="./nips-2008-Differentiable_Sparse_Coding.html">62 nips-2008-Differentiable Sparse Coding</a></p>
<p>Author: J. A. Bagnell, David M. Bradley</p><p>Abstract: Prior work has shown that features which appear to be biologically plausible as well as empirically useful can be found by sparse coding with a prior such as a laplacian (L1 ) that promotes sparsity. We show how smoother priors can preserve the beneﬁts of these sparse priors while adding stability to the Maximum A-Posteriori (MAP) estimate that makes it more useful for prediction problems. Additionally, we show how to calculate the derivative of the MAP estimate efﬁciently with implicit differentiation. One prior that can be differentiated this way is KL-regularization. We demonstrate its effectiveness on a wide variety of applications, and ﬁnd that online optimization of the parameters of the KL-regularized model can signiﬁcantly improve prediction performance. 1</p><p>4 0.80824012 <a title="231-lda-4" href="./nips-2008-Learning_Transformational_Invariants_from_Natural_Movies.html">118 nips-2008-Learning Transformational Invariants from Natural Movies</a></p>
<p>Author: Charles Cadieu, Bruno A. Olshausen</p><p>Abstract: We describe a hierarchical, probabilistic model that learns to extract complex motion from movies of the natural environment. The model consists of two hidden layers: the ﬁrst layer produces a sparse representation of the image that is expressed in terms of local amplitude and phase variables. The second layer learns the higher-order structure among the time-varying phase variables. After training on natural movies, the top layer units discover the structure of phase-shifts within the ﬁrst layer. We show that the top layer units encode transformational invariants: they are selective for the speed and direction of a moving pattern, but are invariant to its spatial structure (orientation/spatial-frequency). The diversity of units in both the intermediate and top layers of the model provides a set of testable predictions for representations that might be found in V1 and MT. In addition, the model demonstrates how feedback from higher levels can inﬂuence representations at lower levels as a by-product of inference in a graphical model. 1</p><p>5 0.80656624 <a title="231-lda-5" href="./nips-2008-Robust_Kernel_Principal_Component_Analysis.html">200 nips-2008-Robust Kernel Principal Component Analysis</a></p>
<p>Author: Minh H. Nguyen, Fernando Torre</p><p>Abstract: Kernel Principal Component Analysis (KPCA) is a popular generalization of linear PCA that allows non-linear feature extraction. In KPCA, data in the input space is mapped to higher (usually) dimensional feature space where the data can be linearly modeled. The feature space is typically induced implicitly by a kernel function, and linear PCA in the feature space is performed via the kernel trick. However, due to the implicitness of the feature space, some extensions of PCA such as robust PCA cannot be directly generalized to KPCA. This paper presents a technique to overcome this problem, and extends it to a uniﬁed framework for treating noise, missing data, and outliers in KPCA. Our method is based on a novel cost function to perform inference in KPCA. Extensive experiments, in both synthetic and real data, show that our algorithm outperforms existing methods. 1</p><p>6 0.80653673 <a title="231-lda-6" href="./nips-2008-Regularized_Policy_Iteration.html">195 nips-2008-Regularized Policy Iteration</a></p>
<p>7 0.80628932 <a title="231-lda-7" href="./nips-2008-Model_Selection_in_Gaussian_Graphical_Models%3A_High-Dimensional_Consistency_of_%5Cboldmath%24%5Cell_1%24-regularized_MLE.html">135 nips-2008-Model Selection in Gaussian Graphical Models: High-Dimensional Consistency of \boldmath$\ell 1$-regularized MLE</a></p>
<p>8 0.80457443 <a title="231-lda-8" href="./nips-2008-Dimensionality_Reduction_for_Data_in_Multiple_Feature_Representations.html">63 nips-2008-Dimensionality Reduction for Data in Multiple Feature Representations</a></p>
<p>9 0.80412847 <a title="231-lda-9" href="./nips-2008-Modeling_human_function_learning_with_Gaussian_processes.html">138 nips-2008-Modeling human function learning with Gaussian processes</a></p>
<p>10 0.80382687 <a title="231-lda-10" href="./nips-2008-A_Scalable_Hierarchical_Distributed_Language_Model.html">4 nips-2008-A Scalable Hierarchical Distributed Language Model</a></p>
<p>11 0.80325353 <a title="231-lda-11" href="./nips-2008-Semi-supervised_Learning_with_Weakly-Related_Unlabeled_Data_%3A_Towards_Better_Text_Categorization.html">205 nips-2008-Semi-supervised Learning with Weakly-Related Unlabeled Data : Towards Better Text Categorization</a></p>
<p>12 0.80282915 <a title="231-lda-12" href="./nips-2008-Partially_Observed_Maximum_Entropy_Discrimination_Markov_Networks.html">176 nips-2008-Partially Observed Maximum Entropy Discrimination Markov Networks</a></p>
<p>13 0.80264753 <a title="231-lda-13" href="./nips-2008-Dynamic_visual_attention%3A_searching_for_coding_length_increments.html">66 nips-2008-Dynamic visual attention: searching for coding length increments</a></p>
<p>14 0.8021155 <a title="231-lda-14" href="./nips-2008-Sparse_probabilistic_projections.html">216 nips-2008-Sparse probabilistic projections</a></p>
<p>15 0.80204141 <a title="231-lda-15" href="./nips-2008-An_Homotopy_Algorithm_for_the_Lasso_with_Online_Observations.html">21 nips-2008-An Homotopy Algorithm for the Lasso with Online Observations</a></p>
<p>16 0.80166441 <a title="231-lda-16" href="./nips-2008-Relative_Performance_Guarantees_for_Approximate_Inference_in_Latent_Dirichlet_Allocation.html">197 nips-2008-Relative Performance Guarantees for Approximate Inference in Latent Dirichlet Allocation</a></p>
<p>17 0.80026841 <a title="231-lda-17" href="./nips-2008-Supervised_Dictionary_Learning.html">226 nips-2008-Supervised Dictionary Learning</a></p>
<p>18 0.80023742 <a title="231-lda-18" href="./nips-2008-PSDBoost%3A_Matrix-Generation_Linear_Programming_for_Positive_Semidefinite_Matrices_Learning.html">175 nips-2008-PSDBoost: Matrix-Generation Linear Programming for Positive Semidefinite Matrices Learning</a></p>
<p>19 0.79973423 <a title="231-lda-19" href="./nips-2008-Unlabeled_data%3A_Now_it_helps%2C_now_it_doesn%27t.html">245 nips-2008-Unlabeled data: Now it helps, now it doesn't</a></p>
<p>20 0.79917204 <a title="231-lda-20" href="./nips-2008-Regularized_Learning_with_Networks_of_Features.html">194 nips-2008-Regularized Learning with Networks of Features</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
