<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>139 nips-2008-Modeling the effects of memory on human online sentence processing with particle filters</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-139" href="#">nips2008-139</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>139 nips-2008-Modeling the effects of memory on human online sentence processing with particle filters</h1>
<br/><p>Source: <a title="nips-2008-139-pdf" href="http://papers.nips.cc/paper/3573-modeling-the-effects-of-memory-on-human-online-sentence-processing-with-particle-filters.pdf">pdf</a></p><p>Author: Roger P. Levy, Florencia Reali, Thomas L. Griffiths</p><p>Abstract: Language comprehension in humans is signiﬁcantly constrained by memory, yet rapid, highly incremental, and capable of utilizing a wide range of contextual information to resolve ambiguity and form expectations about future input. In contrast, most of the leading psycholinguistic models and ﬁelded algorithms for natural language parsing are non-incremental, have run time superlinear in input length, and/or enforce structural locality constraints on probabilistic dependencies between events. We present a new limited-memory model of sentence comprehension which involves an adaptation of the particle ﬁlter, a sequential Monte Carlo method, to the problem of incremental parsing. We show that this model can reproduce classic results in online sentence comprehension, and that it naturally provides the ﬁrst rational account of an outstanding problem in psycholinguistics, in which the preferred alternative in a syntactic ambiguity seems to grow more attractive over time even in the absence of strong disambiguating information. 1</p><p>Reference: <a title="nips-2008-139-reference" href="../nips2008_reference/nips-2008-Modeling_the_effects_of_memory_on_human_online_sentence_processing_with_particle_filters_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Modeling the effects of memory on human online sentence processing with particle ﬁlters  Roger Levy Department of Linguistics University of California, San Diego rlevy@ling. [sent-1, score-0.718]
</p><p>2 edu  Abstract Language comprehension in humans is signiﬁcantly constrained by memory, yet rapid, highly incremental, and capable of utilizing a wide range of contextual information to resolve ambiguity and form expectations about future input. [sent-5, score-0.297]
</p><p>3 In contrast, most of the leading psycholinguistic models and ﬁelded algorithms for natural language parsing are non-incremental, have run time superlinear in input length, and/or enforce structural locality constraints on probabilistic dependencies between events. [sent-6, score-0.447]
</p><p>4 We present a new limited-memory model of sentence comprehension which involves an adaptation of the particle ﬁlter, a sequential Monte Carlo method, to the problem of incremental parsing. [sent-7, score-0.93]
</p><p>5 1  Introduction  Nearly every sentence occurring in natural language can, given appropriate contexts, be interpreted in more than one way. [sent-9, score-0.462]
</p><p>6 The challenge of comprehending a sentence is identifying the intended intepretation from among these possibilities. [sent-10, score-0.408]
</p><p>7 More formally, each interpretation of a sentence w can be associated with a structural description T , and to comprehend a sentence is to infer T from w – parsing the sentence to reveal its underlying structure. [sent-11, score-1.412]
</p><p>8 This probabilistic perspective has proven extremely valuable in developing both effective methods by which computers can process natural language [1, 2] and models of human language processing [3]. [sent-13, score-0.208]
</p><p>9 In real life, however, people receive nearly all linguistic input incrementally: sentences are spoken, and written sentences are by and large read, from beginning to end. [sent-14, score-0.351]
</p><p>10 There is considerable evidence that people also comprehend incrementally, making use of linguistic input moment by moment to resolve structural ambiguity and form expectations about future inputs [4, 5]. [sent-15, score-0.27]
</p><p>11 The incremental parsing problem can, roughly, be stated as the problem of computing the posterior distribution P (T |w1 . [sent-16, score-0.314]
</p><p>12 To be somewhat more precise, incremental parsing involves constructing a distribution over partial structural descriptions of w1 . [sent-23, score-0.381]
</p><p>13 A variety of “rational” models of online sentence processing [6, 7, 8, 9] take exactly this perspective, using the properties of P (T |w1 . [sent-30, score-0.418]
</p><p>14 i ) or quantities derived from it to explain why people ﬁnd some sentences more difﬁcult to comprehend than others. [sent-33, score-0.192]
</p><p>15 Despite their success in capturing a variety of psycholinguistic phenomena, existing rational models of online sentence processing leave open a number of questions, both theoretical and empirical. [sent-34, score-0.582]
</p><p>16 This kind of idealization is common in rational models of cognition, but raises questions about how resource constraints might affect language processing. [sent-39, score-0.189]
</p><p>17 Theoretical questions about the mechanisms underlying online sentence processing are complemented by empirical data that are hard to explain purely in probabilistic terms. [sent-42, score-0.462]
</p><p>18 For example, one of the most compelling phenomena in psycholinguistics is that of garden-path sentences, such as: (1)  The woman brought the sandwich from the kitchen tripped. [sent-43, score-0.205]
</p><p>19 Comprehending such sentences presents a signiﬁcant challenge, and many readers fail completely on their ﬁrst attempt. [sent-44, score-0.181]
</p><p>20 However, the sophisticated dynamic programming algorithms typically used for incremental parsing implicitly represent all possible continuations of a sentence, and are thus able to recover the correct interpretation in a single pass. [sent-45, score-0.3]
</p><p>21 In this paper, we explore the hypothesis that these phenomena can be explained as the consequence of constraints on the resources available for incremental parsing. [sent-47, score-0.152]
</p><p>22 We use particle ﬁlters [19], a sequential Monte Carlo method commonly used for approximate probabilistic inference in an online setting, to explore how the computational resources available inﬂuence the comprehension of sentences. [sent-54, score-0.542]
</p><p>23 This approach builds on the strengths of rational models of online sentence processing, allowing us to examine how performance degrades as the resources of the ideal comprehender decrease. [sent-55, score-0.556]
</p><p>24 Section 2 introduces the key ideas behind particle ﬁlters, while Section 3 outlines how these ideas can be applied in the context of incremental parsing. [sent-57, score-0.377]
</p><p>25 Section 4 illustrates the approach for the kind of garden-path sentence given above, and Section 5 presents an experiment with human participants testing the predictions that the resulting model makes about the digging-in effect. [sent-58, score-0.38]
</p><p>26 The canonical setting in which a particle ﬁlter would be used involves a sequence of latent variables z 1 , . [sent-61, score-0.256]
</p><p>27 The particle ﬁlter solves this problem recursively, relying on the fact that the chain rule gives P (z n |x1 . [sent-71, score-0.256]
</p><p>28 The particle ﬁlter is simply the recursive version of this algorithm, in which a similar approximation was used to construct to P (z n−1 |x1 . [sent-98, score-0.256]
</p><p>29 The particle ﬁlter thus has run-time linear in the number of observations, and provides a way to explore the inﬂuence of memory capacity (reﬂected in the number of particles) on probabilistic inference (cf. [sent-112, score-0.344]
</p><p>30 In this paper, we focus on the conditions under which the particle ﬁlter fails as a source of information about the challenges of limited memory capacity for online sentence processing. [sent-114, score-0.718]
</p><p>31 3  Incremental parsing with particle ﬁlters  In this section we develop an algorithm for top-down, incremental particle-ﬁlter parsing. [sent-115, score-0.526]
</p><p>32 1  The basic algorithm  We assume that the structural descriptions of a sentence are context-free trees, as might be produced by a PCFG. [sent-118, score-0.43]
</p><p>33 A tree is generated incrementally in a sequence of derivation operations π 1 . [sent-120, score-0.19]
</p><p>34 m , such that no word can be generated unless all the words preceding it in the sentence have already been generated. [sent-123, score-0.5]
</p><p>35 The words of the sentence can thus be considered observations, and the hidden state is a partial derivation (D, S), where D is an incremental tree structure and S is a stack of items of the form N, Op , where N is a target node in D and Op is a derivation operation type. [sent-124, score-0.948]
</p><p>36 The problem of inferring a distribution over partial derivations from observed words can be approximated using particle ﬁlters as outlined in Section 2. [sent-126, score-0.353]
</p><p>37 i ) over the next derivation operation π given the current partial derivaπ 1 . [sent-130, score-0.252]
</p><p>38 By (D, S) ⇒ (D′ , S ′ ) we denote that the sequence of derivation operations π 1 . [sent-134, score-0.19]
</p><p>39 j takes the partial derivation (D, S) to a new partial derivation (D′ , S ′ ). [sent-137, score-0.396]
</p><p>40 Now consider a partial derivation (Di| , S i| ) in which the most recent derivation operation has generated the π ith word in the input. [sent-138, score-0.472]
</p><p>41 In the nomenclature of particle ﬁlters introduced above, partial derivations (D|i , S |i ) thus correspond to latent variables z i , words wi to observations xi , and our importance sampler involves drawing from P ((D|i , S |i )|(Di−1 | , S i−1 | )) and reweighting by P (wi |(D|i , S |i )). [sent-140, score-0.385]
</p><p>42 This differs from the standard particle ﬁlter only in that z i is not necessarily independent of x1 . [sent-141, score-0.256]
</p><p>43 2  Representations and grammars  We now describe three possible derivation orders that can be used with our approach. [sent-146, score-0.165]
</p><p>44 For each order, a derivation operation π Op of a given type Op speciﬁes a sequence of symbols Y 1 . [sent-147, score-0.231]
</p><p>45 That is, a derivation operation involves popping the top item off the stack, choosing a derivation operation of the appropriate type, applying it to add some symbols to D yielding D′ , and pushing a list of new items A back on the stack. [sent-151, score-0.452]
</p><p>46 Derivation operations differ in the relationship between D and D′ , and derivation orders differ in the contents of A. [sent-152, score-0.218]
</p><p>47 In each case, the partial derivation (D|i , S |i ) is shown for i = 2 – up to just before the generation of the word “walked”. [sent-179, score-0.281]
</p><p>48 During the incremental parsing of “walked” these partial derivations would be reweighted by P Exp (walked |(D|i , S |i )). [sent-181, score-0.367]
</p><p>49 In all cases, the initial state of a derivation is a root symbol targeted for expansion: (ROOT, [ ROOT, Exp ]), and a derivation is complete when the stack is empty. [sent-182, score-0.329]
</p><p>50 Figure 1 illustrates the partial derivation state for each order just after the generation of a word in mid-sentence. [sent-183, score-0.281]
</p><p>51 For each derivation operation type Op, it is necessary to deﬁne an underlying grammar and estimate the parameters of a distribution P Op (π|(D, S)) over next derivation operations given the current state of the derivation. [sent-184, score-0.416]
</p><p>52 For a sentence whose tree structure is known, the sequence of derivation operations for derivation orders 1 and 2 is unambiguous and thus supervised training can be used for such a model. [sent-185, score-0.803]
</p><p>53 For derivation order 3, a known tree structure still underspeciﬁes the order of derivation operations, so the underlying sequence of derivation operations could either be canonicalized or treated as a latent variable in training. [sent-186, score-0.464]
</p><p>54 In the context of the particle ﬁlter, the representations with more operation types could thus be expected to function as having larger effective sample sizes for a ﬁxed number of particles [22]. [sent-188, score-0.434]
</p><p>55 This approach has several attractive features for the modeling of online human sentence comprehension. [sent-190, score-0.418]
</p><p>56 The number of particles can be considered a rough estimate of the quantity of working memory resources devoted to the sentence comprehension task; as we will show in Section 5, sentences difﬁcult to parse can become easier when more particles are used. [sent-191, score-1.117]
</p><p>57 After each word, the incremental posterior over partial structures T can be read off the particle structures and weights. [sent-192, score-0.482]
</p><p>58 4  The garden-path sentence  To provide some intuitions about our approach, we illustrate its ability to model online disambiguation in sentence comprehension using the garden-path sentence given in Example 1. [sent-194, score-1.381]
</p><p>59 This ambiguity is resolved in favor of (ii) by the word tripped, the main verb of the sentence. [sent-196, score-0.267]
</p><p>60 , [24]) that locally ambiguous sentences such as Example 1 are read more slowly at the disambiguating region when compared with unambiguous counterparts (c. [sent-199, score-0.357]
</p><p>61 Numbers above the trees indicate the posterior probabilites of main-verb and reduced-relative interpretations, marginalizing over precise details of parse structure, as estimated by a parser using 1000 particles. [sent-238, score-0.21]
</p><p>62 Numbers in the second-to-last line indicate the proportion of particle ﬁlters with 20 particles that produce a viable parse tree including the given word. [sent-240, score-0.472]
</p><p>63 The ﬁnal line indicates the variance (×10−3 ) of particle weights after parsing each word. [sent-241, score-0.405]
</p><p>64 Figure 2 illustrates the behavior of the particle ﬁlter on the garden-path sentence in Example 1. [sent-243, score-0.636]
</p><p>65 The word brought shifts the posterior strongly toward the main-verb interpretation. [sent-244, score-0.17]
</p><p>66 The rest of the reduced relative clause has little effect on the posterior, but the disambiguator tripped shifts the posterior in favor of the correct reduced-relative interpretation. [sent-245, score-0.229]
</p><p>67 In low-memory situations, as represented by a particle ﬁlter with a small number of particles (e. [sent-246, score-0.38]
</p><p>68 , 20), the parser is usually able to construct an interpretation for the sentence up through the word kitchen, but fails at the disambiguator, and when it succeeds the variance in particle weights is high. [sent-248, score-0.823]
</p><p>69 A body of evidence exists in the psycholinguistic literature that seems to support an internal feedback mechanism: increasing the duration of a local syntactic ambiguity increases the difﬁculty of recovery at disambiguation to the disfavored interpretation. [sent-250, score-0.316]
</p><p>70 Long (A-L): While the man hunted the deer that was brown and graceful ran into the woods. [sent-263, score-0.205]
</p><p>71 Short (A-S): While the man hunted the deer ran into the woods. [sent-265, score-0.177]
</p><p>72 From the perspective of exact rational inference – or even for rational pruning models such as [6] – this “digging in” effect is puzzling. [sent-266, score-0.214]
</p><p>73 The probability of parse failure at the disambiguating word wi is a function of (among other things) the immediately preceding estimated posterior probability of the disfavored interpretation. [sent-268, score-0.443]
</p><p>74 If this posterior probability is low, then the resampling of particles performed after processing each word provides another point at which particles representing the disfavored interpretation could be deleted. [sent-269, score-0.488]
</p><p>75 Consequently, total parse failure at the disambiguator will become more likely the greater the length of the preceding ambiguous region. [sent-270, score-0.338]
</p><p>76 We quantify these predictions by assuming that the more often no particle is able to integrate a given word wi in context – that is, P (wi |(D|i , S |i )) – the more difﬁcult, on average, people should ﬁnd wi to read. [sent-271, score-0.403]
</p><p>77 In the sentences of Examples 2-3, by far the most likely position for the incremental parser to fail is at the disambiguating verb. [sent-272, score-0.429]
</p><p>78 We can also compare processing of these sentences with syntactically similar but unambiguous controls. [sent-273, score-0.217]
</p><p>79 Consistent with our intuitive explanation, both the presence of local ambiguity and length of the preceding region make parse failure at the disambiguator more likely. [sent-283, score-0.407]
</p><p>80 In the remainder of this section we test this explanation with an ofﬂine sentence acceptability study of digging-in effects. [sent-284, score-0.38]
</p><p>81 The experiment provides a way to make more detailed comparisons between the model’s predictions and sentence acceptability. [sent-285, score-0.38]
</p><p>82 number of particles) devoted to comprehension of the sentence increase, the probability of successful comprehension goes up, but local ambiguity and length of the second NP remain associated with greater comprehension difﬁculty. [sent-289, score-1.065]
</p><p>83 Forty experimental items were tested with four conditions per item, counterbalanced across questionnaires, plus 84 ﬁllers, with sentence order pseudorandomized. [sent-292, score-0.41]
</p><p>84 Twenty experimental items were NP/S sentences and twenty were NP/Z sentences. [sent-293, score-0.179]
</p><p>85 We used a 2 × 2 design with ambiguity and length of the ambiguous noun phrase as factors. [sent-294, score-0.221]
</p><p>86 In NP/S sentences, structural ambiguity was manipulated by the presence/absence of the complementizer that, while in NP/Z sentences, structural ambiguity was manipulated by the absence/presence of a comma after the ﬁrst verb. [sent-295, score-0.348]
</p><p>87 Within sentence type, the ratings were subjected to an analysis of variance (ANOVA) with two factors: ambiguity and length. [sent-300, score-0.504]
</p><p>88 0  100 200 300 Number of particles  400  Mean difficulty rating 2 3 4  5  NP/S NP/Z  1  U−S A−S U−L A−L  0  U−S A−S U−L A−L  6  Proportion of parse successes at disambiguator 0. [sent-309, score-0.329]
</p><p>89 0  NP/Z  Proportion of parse successes at disambiguator 0. [sent-315, score-0.177]
</p><p>90 0  NP/S  0  (a) Model results  100 200 300 Number of particles  400  U−S  A−S  U−L  A−L  (b) Behavioral results  Figure 3: Frequency of irrevocable garden path in particle-ﬁlter parser as a function of number of particles, and mean empirical difﬁculty rating, for NP/S and NP/Z sentences. [sent-321, score-0.198]
</p><p>91 The experiment thus bore out most of the model’s predictions, with ambiguity and length combining to make sentence processing more difﬁcult. [sent-343, score-0.546]
</p><p>92 In closing, we point out two issues – both involving the problem of resampling prominent in particle ﬁlter research – in which we believe future research may help deepen our understanding of language processing. [sent-346, score-0.378]
</p><p>93 This approach has the problem that particle diversity can be lost rapidly, as it decreases monotonically with the number of observations. [sent-357, score-0.285]
</p><p>94 Another option is to resample only when the variance in particle weights exceeds a predeﬁned threshold, sampling without replacement when this variance is low [22]. [sent-358, score-0.256]
</p><p>95 Our preliminary investigations indicate that associating variance-sensitive resampling with processing difﬁculty leads to qualitatively similar predictions to the total parse failure approach taken in Section 5, but further investigation is required. [sent-360, score-0.159]
</p><p>96 Since particle diversity can never increase, when parts of the space of possible T are missed by chance early on, they can never be recovered. [sent-362, score-0.285]
</p><p>97 As a consequence, applications of the particle ﬁlter in machine learning and statistics tend to supplement the basic algorithm with additional steps such as running Markov chain Monte Carlo on the particles in order to re-introduce diversity (e. [sent-363, score-0.409]
</p><p>98 For example, the initial reaction of many readers to the sentence The horse raced past the barn fell is to wonder what a “barn fell” is. [sent-368, score-0.462]
</p><p>99 An efﬁcient probabilistic context-free parsing algorithm that computes preﬁx probabilities. [sent-432, score-0.193]
</p><p>100 Making and correcting errors during sentence comprehension: Eye movements in the analysis of structurally ambiguous sentences. [sent-518, score-0.435]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('np', 0.415), ('sentence', 0.38), ('particle', 0.256), ('nn', 0.223), ('sis', 0.198), ('vbd', 0.198), ('vp', 0.191), ('dt', 0.185), ('comprehension', 0.173), ('parsing', 0.149), ('sentences', 0.149), ('derivation', 0.137), ('ambiguity', 0.124), ('particles', 0.124), ('incremental', 0.121), ('rational', 0.107), ('vbn', 0.099), ('adj', 0.099), ('parse', 0.092), ('op', 0.085), ('disambiguating', 0.085), ('disambiguator', 0.085), ('word', 0.083), ('language', 0.082), ('lter', 0.078), ('parser', 0.074), ('digging', 0.071), ('unambiguous', 0.068), ('pp', 0.064), ('syntactic', 0.062), ('partial', 0.061), ('linguistics', 0.061), ('verb', 0.06), ('lters', 0.057), ('deer', 0.057), ('heard', 0.057), ('hunted', 0.057), ('psycholinguistic', 0.057), ('tripped', 0.057), ('wasn', 0.057), ('ambiguous', 0.055), ('operation', 0.054), ('linguistic', 0.053), ('operations', 0.053), ('structural', 0.05), ('gossip', 0.05), ('walked', 0.05), ('woman', 0.05), ('pat', 0.05), ('posterior', 0.044), ('probabilistic', 0.044), ('memory', 0.044), ('brought', 0.043), ('advp', 0.043), ('clause', 0.043), ('comprehend', 0.043), ('disfavored', 0.043), ('length', 0.042), ('locality', 0.04), ('resampling', 0.04), ('symbols', 0.04), ('online', 0.038), ('kitchen', 0.038), ('preceding', 0.037), ('psycholinguistics', 0.037), ('sandwich', 0.037), ('pcfgs', 0.037), ('derivations', 0.036), ('man', 0.035), ('grammar', 0.035), ('expansion', 0.035), ('cognition', 0.034), ('tom', 0.034), ('wi', 0.032), ('readers', 0.032), ('resources', 0.031), ('exp', 0.031), ('monte', 0.03), ('disambiguation', 0.03), ('interpretation', 0.03), ('items', 0.03), ('diversity', 0.029), ('adjunction', 0.028), ('comprehending', 0.028), ('graceful', 0.028), ('reanalysis', 0.028), ('ran', 0.028), ('orders', 0.028), ('cc', 0.028), ('rating', 0.028), ('stack', 0.028), ('failure', 0.027), ('root', 0.027), ('carlo', 0.026), ('cognitive', 0.026), ('superlinear', 0.025), ('formalisms', 0.025), ('barn', 0.025), ('fell', 0.025), ('chater', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000007 <a title="139-tfidf-1" href="./nips-2008-Modeling_the_effects_of_memory_on_human_online_sentence_processing_with_particle_filters.html">139 nips-2008-Modeling the effects of memory on human online sentence processing with particle filters</a></p>
<p>Author: Roger P. Levy, Florencia Reali, Thomas L. Griffiths</p><p>Abstract: Language comprehension in humans is signiﬁcantly constrained by memory, yet rapid, highly incremental, and capable of utilizing a wide range of contextual information to resolve ambiguity and form expectations about future input. In contrast, most of the leading psycholinguistic models and ﬁelded algorithms for natural language parsing are non-incremental, have run time superlinear in input length, and/or enforce structural locality constraints on probabilistic dependencies between events. We present a new limited-memory model of sentence comprehension which involves an adaptation of the particle ﬁlter, a sequential Monte Carlo method, to the problem of incremental parsing. We show that this model can reproduce classic results in online sentence comprehension, and that it naturally provides the ﬁrst rational account of an outstanding problem in psycholinguistics, in which the preferred alternative in a syntactic ambiguity seems to grow more attractive over time even in the absence of strong disambiguating information. 1</p><p>2 0.16203858 <a title="139-tfidf-2" href="./nips-2008-Logistic_Normal_Priors_for_Unsupervised_Probabilistic_Grammar_Induction.html">127 nips-2008-Logistic Normal Priors for Unsupervised Probabilistic Grammar Induction</a></p>
<p>Author: Shay B. Cohen, Kevin Gimpel, Noah A. Smith</p><p>Abstract: We explore a new Bayesian model for probabilistic grammars, a family of distributions over discrete structures that includes hidden Markov models and probabilistic context-free grammars. Our model extends the correlated topic model framework to probabilistic grammars, exploiting the logistic normal distribution as a prior over the grammar parameters. We derive a variational EM algorithm for that model, and then experiment with the task of unsupervised grammar induction for natural language dependency parsing. We show that our model achieves superior results over previous models that use diﬀerent priors. 1</p><p>3 0.12746143 <a title="139-tfidf-3" href="./nips-2008-Particle_Filter-based_Policy_Gradient_in_POMDPs.html">177 nips-2008-Particle Filter-based Policy Gradient in POMDPs</a></p>
<p>Author: Pierre-arnaud Coquelin, Romain Deguest, Rémi Munos</p><p>Abstract: Our setting is a Partially Observable Markov Decision Process with continuous state, observation and action spaces. Decisions are based on a Particle Filter for estimating the belief state given past observations. We consider a policy gradient approach for parameterized policy optimization. For that purpose, we investigate sensitivity analysis of the performance measure with respect to the parameters of the policy, focusing on Finite Difference (FD) techniques. We show that the naive FD is subject to variance explosion because of the non-smoothness of the resampling procedure. We propose a more sophisticated FD method which overcomes this problem and establish its consistency. 1</p><p>4 0.12426981 <a title="139-tfidf-4" href="./nips-2008-Syntactic_Topic_Models.html">229 nips-2008-Syntactic Topic Models</a></p>
<p>Author: Jordan L. Boyd-graber, David M. Blei</p><p>Abstract: We develop the syntactic topic model (STM), a nonparametric Bayesian model of parsed documents. The STM generates words that are both thematically and syntactically constrained, which combines the semantic insights of topic models with the syntactic information available from parse trees. Each word of a sentence is generated by a distribution that combines document-speciﬁc topic weights and parse-tree-speciﬁc syntactic transitions. Words are assumed to be generated in an order that respects the parse tree. We derive an approximate posterior inference method based on variational methods for hierarchical Dirichlet processes, and we report qualitative and quantitative results on both synthetic data and hand-parsed documents. 1</p><p>5 0.10420186 <a title="139-tfidf-5" href="./nips-2008-Recursive_Segmentation_and_Recognition_Templates_for_2D_Parsing.html">191 nips-2008-Recursive Segmentation and Recognition Templates for 2D Parsing</a></p>
<p>Author: Leo Zhu, Yuanhao Chen, Yuan Lin, Chenxi Lin, Alan L. Yuille</p><p>Abstract: Language and image understanding are two major goals of artiﬁcial intelligence which can both be conceptually formulated in terms of parsing the input signal into a hierarchical representation. Natural language researchers have made great progress by exploiting the 1D structure of language to design efﬁcient polynomialtime parsing algorithms. By contrast, the two-dimensional nature of images makes it much harder to design efﬁcient image parsers and the form of the hierarchical representations is also unclear. Attempts to adapt representations and algorithms from natural language have only been partially successful. In this paper, we propose a Hierarchical Image Model (HIM) for 2D image parsing which outputs image segmentation and object recognition. This HIM is represented by recursive segmentation and recognition templates in multiple layers and has advantages for representation, inference, and learning. Firstly, the HIM has a coarse-to-ﬁne representation which is capable of capturing long-range dependency and exploiting different levels of contextual information. Secondly, the structure of the HIM allows us to design a rapid inference algorithm, based on dynamic programming, which enables us to parse the image rapidly in polynomial time. Thirdly, we can learn the HIM efﬁciently in a discriminative manner from a labeled dataset. We demonstrate that HIM outperforms other state-of-the-art methods by evaluation on the challenging public MSRC image dataset. Finally, we sketch how the HIM architecture can be extended to model more complex image phenomena. 1</p><p>6 0.10233942 <a title="139-tfidf-6" href="./nips-2008-Bayesian_Synchronous_Grammar_Induction.html">35 nips-2008-Bayesian Synchronous Grammar Induction</a></p>
<p>7 0.086995415 <a title="139-tfidf-7" href="./nips-2008-A_Scalable_Hierarchical_Distributed_Language_Model.html">4 nips-2008-A Scalable Hierarchical Distributed Language Model</a></p>
<p>8 0.085860699 <a title="139-tfidf-8" href="./nips-2008-Hierarchical_Semi-Markov_Conditional_Random_Fields_for_Recursive_Sequential_Data.html">98 nips-2008-Hierarchical Semi-Markov Conditional Random Fields for Recursive Sequential Data</a></p>
<p>9 0.069018938 <a title="139-tfidf-9" href="./nips-2008-Domain_Adaptation_with_Multiple_Sources.html">65 nips-2008-Domain Adaptation with Multiple Sources</a></p>
<p>10 0.065936968 <a title="139-tfidf-10" href="./nips-2008-Analyzing_human_feature_learning_as_nonparametric_Bayesian_inference.html">26 nips-2008-Analyzing human feature learning as nonparametric Bayesian inference</a></p>
<p>11 0.064813659 <a title="139-tfidf-11" href="./nips-2008-Mind_the_Duality_Gap%3A_Logarithmic_regret_algorithms_for_online_optimization.html">133 nips-2008-Mind the Duality Gap: Logarithmic regret algorithms for online optimization</a></p>
<p>12 0.054791868 <a title="139-tfidf-12" href="./nips-2008-Beyond_Novelty_Detection%3A_Incongruent_Events%2C_when_General_and_Specific_Classifiers_Disagree.html">36 nips-2008-Beyond Novelty Detection: Incongruent Events, when General and Specific Classifiers Disagree</a></p>
<p>13 0.053251892 <a title="139-tfidf-13" href="./nips-2008-Modeling_human_function_learning_with_Gaussian_processes.html">138 nips-2008-Modeling human function learning with Gaussian processes</a></p>
<p>14 0.049091145 <a title="139-tfidf-14" href="./nips-2008-Learning_to_Use_Working_Memory_in_Partially_Observable_Environments_through_Dopaminergic_Reinforcement.html">121 nips-2008-Learning to Use Working Memory in Partially Observable Environments through Dopaminergic Reinforcement</a></p>
<p>15 0.046407644 <a title="139-tfidf-15" href="./nips-2008-Temporal_Dynamics_of_Cognitive_Control.html">231 nips-2008-Temporal Dynamics of Cognitive Control</a></p>
<p>16 0.045925654 <a title="139-tfidf-16" href="./nips-2008-Structured_ranking_learning_using_cumulative_distribution_networks.html">224 nips-2008-Structured ranking learning using cumulative distribution networks</a></p>
<p>17 0.04518488 <a title="139-tfidf-17" href="./nips-2008-An_ideal_observer_model_of_infant_object_perception.html">23 nips-2008-An ideal observer model of infant object perception</a></p>
<p>18 0.044844877 <a title="139-tfidf-18" href="./nips-2008-Optimal_Response_Initiation%3A_Why_Recent_Experience_Matters.html">172 nips-2008-Optimal Response Initiation: Why Recent Experience Matters</a></p>
<p>19 0.040460214 <a title="139-tfidf-19" href="./nips-2008-Sparse_probabilistic_projections.html">216 nips-2008-Sparse probabilistic projections</a></p>
<p>20 0.03870054 <a title="139-tfidf-20" href="./nips-2008-An_Efficient_Sequential_Monte_Carlo_Algorithm_for_Coalescent_Clustering.html">18 nips-2008-An Efficient Sequential Monte Carlo Algorithm for Coalescent Clustering</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2008_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.135), (1, 0.001), (2, 0.059), (3, -0.07), (4, -0.006), (5, -0.012), (6, 0.049), (7, 0.119), (8, -0.025), (9, -0.018), (10, -0.108), (11, 0.031), (12, -0.001), (13, 0.088), (14, 0.02), (15, 0.099), (16, -0.004), (17, -0.096), (18, -0.096), (19, 0.057), (20, 0.005), (21, 0.046), (22, 0.071), (23, 0.058), (24, -0.129), (25, 0.06), (26, 0.112), (27, -0.201), (28, -0.055), (29, 0.101), (30, -0.008), (31, -0.06), (32, -0.152), (33, 0.078), (34, 0.022), (35, -0.078), (36, 0.067), (37, 0.01), (38, -0.049), (39, 0.114), (40, -0.039), (41, 0.033), (42, -0.14), (43, 0.158), (44, -0.019), (45, -0.089), (46, 0.018), (47, -0.063), (48, -0.094), (49, -0.047)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96851313 <a title="139-lsi-1" href="./nips-2008-Modeling_the_effects_of_memory_on_human_online_sentence_processing_with_particle_filters.html">139 nips-2008-Modeling the effects of memory on human online sentence processing with particle filters</a></p>
<p>Author: Roger P. Levy, Florencia Reali, Thomas L. Griffiths</p><p>Abstract: Language comprehension in humans is signiﬁcantly constrained by memory, yet rapid, highly incremental, and capable of utilizing a wide range of contextual information to resolve ambiguity and form expectations about future input. In contrast, most of the leading psycholinguistic models and ﬁelded algorithms for natural language parsing are non-incremental, have run time superlinear in input length, and/or enforce structural locality constraints on probabilistic dependencies between events. We present a new limited-memory model of sentence comprehension which involves an adaptation of the particle ﬁlter, a sequential Monte Carlo method, to the problem of incremental parsing. We show that this model can reproduce classic results in online sentence comprehension, and that it naturally provides the ﬁrst rational account of an outstanding problem in psycholinguistics, in which the preferred alternative in a syntactic ambiguity seems to grow more attractive over time even in the absence of strong disambiguating information. 1</p><p>2 0.70807844 <a title="139-lsi-2" href="./nips-2008-Logistic_Normal_Priors_for_Unsupervised_Probabilistic_Grammar_Induction.html">127 nips-2008-Logistic Normal Priors for Unsupervised Probabilistic Grammar Induction</a></p>
<p>Author: Shay B. Cohen, Kevin Gimpel, Noah A. Smith</p><p>Abstract: We explore a new Bayesian model for probabilistic grammars, a family of distributions over discrete structures that includes hidden Markov models and probabilistic context-free grammars. Our model extends the correlated topic model framework to probabilistic grammars, exploiting the logistic normal distribution as a prior over the grammar parameters. We derive a variational EM algorithm for that model, and then experiment with the task of unsupervised grammar induction for natural language dependency parsing. We show that our model achieves superior results over previous models that use diﬀerent priors. 1</p><p>3 0.66617435 <a title="139-lsi-3" href="./nips-2008-Bayesian_Synchronous_Grammar_Induction.html">35 nips-2008-Bayesian Synchronous Grammar Induction</a></p>
<p>Author: Phil Blunsom, Trevor Cohn, Miles Osborne</p><p>Abstract: We present a novel method for inducing synchronous context free grammars (SCFGs) from a corpus of parallel string pairs. SCFGs can model equivalence between strings in terms of substitutions, insertions and deletions, and the reordering of sub-strings. We develop a non-parametric Bayesian model and apply it to a machine translation task, using priors to replace the various heuristics commonly used in this ﬁeld. Using a variational Bayes training procedure, we learn the latent structure of translation equivalence through the induction of synchronous grammar categories for phrasal translations, showing improvements in translation performance over maximum likelihood models. 1</p><p>4 0.61544746 <a title="139-lsi-4" href="./nips-2008-A_Scalable_Hierarchical_Distributed_Language_Model.html">4 nips-2008-A Scalable Hierarchical Distributed Language Model</a></p>
<p>Author: Andriy Mnih, Geoffrey E. Hinton</p><p>Abstract: Neural probabilistic language models (NPLMs) have been shown to be competitive with and occasionally superior to the widely-used n-gram language models. The main drawback of NPLMs is their extremely long training and testing times. Morin and Bengio have proposed a hierarchical language model built around a binary tree of words, which was two orders of magnitude faster than the nonhierarchical model it was based on. However, it performed considerably worse than its non-hierarchical counterpart in spite of using a word tree created using expert knowledge. We introduce a fast hierarchical language model along with a simple feature-based algorithm for automatic construction of word trees from the data. We then show that the resulting models can outperform non-hierarchical neural models as well as the best n-gram models. 1</p><p>5 0.57415193 <a title="139-lsi-5" href="./nips-2008-Hierarchical_Semi-Markov_Conditional_Random_Fields_for_Recursive_Sequential_Data.html">98 nips-2008-Hierarchical Semi-Markov Conditional Random Fields for Recursive Sequential Data</a></p>
<p>Author: Tran T. Truyen, Dinh Phung, Hung Bui, Svetha Venkatesh</p><p>Abstract: Inspired by the hierarchical hidden Markov models (HHMM), we present the hierarchical semi-Markov conditional random ﬁeld (HSCRF), a generalisation of embedded undirected Markov chains to model complex hierarchical, nested Markov processes. It is parameterised in a discriminative framework and has polynomial time algorithms for learning and inference. Importantly, we develop efﬁcient algorithms for learning and constrained inference in a partially-supervised setting, which is important issue in practice where labels can only be obtained sparsely. We demonstrate the HSCRF in two applications: (i) recognising human activities of daily living (ADLs) from indoor surveillance cameras, and (ii) noun-phrase chunking. We show that the HSCRF is capable of learning rich hierarchical models with reasonable accuracy in both fully and partially observed data cases. 1</p><p>6 0.3792994 <a title="139-lsi-6" href="./nips-2008-Syntactic_Topic_Models.html">229 nips-2008-Syntactic Topic Models</a></p>
<p>7 0.3781392 <a title="139-lsi-7" href="./nips-2008-Fast_Computation_of_Posterior_Mode_in_Multi-Level_Hierarchical_Models.html">82 nips-2008-Fast Computation of Posterior Mode in Multi-Level Hierarchical Models</a></p>
<p>8 0.3543312 <a title="139-lsi-8" href="./nips-2008-Learning_to_Use_Working_Memory_in_Partially_Observable_Environments_through_Dopaminergic_Reinforcement.html">121 nips-2008-Learning to Use Working Memory in Partially Observable Environments through Dopaminergic Reinforcement</a></p>
<p>9 0.33017537 <a title="139-lsi-9" href="./nips-2008-A_rational_model_of_preference_learning_and_choice_prediction_by_children.html">10 nips-2008-A rational model of preference learning and choice prediction by children</a></p>
<p>10 0.32313779 <a title="139-lsi-10" href="./nips-2008-Recursive_Segmentation_and_Recognition_Templates_for_2D_Parsing.html">191 nips-2008-Recursive Segmentation and Recognition Templates for 2D Parsing</a></p>
<p>11 0.29332533 <a title="139-lsi-11" href="./nips-2008-Correlated_Bigram_LSA_for_Unsupervised_Language_Model_Adaptation.html">52 nips-2008-Correlated Bigram LSA for Unsupervised Language Model Adaptation</a></p>
<p>12 0.28721243 <a title="139-lsi-12" href="./nips-2008-An_interior-point_stochastic_approximation_method_and_an_L1-regularized_delta_rule.html">25 nips-2008-An interior-point stochastic approximation method and an L1-regularized delta rule</a></p>
<p>13 0.28295073 <a title="139-lsi-13" href="./nips-2008-Efficient_Inference_in_Phylogenetic_InDel_Trees.html">70 nips-2008-Efficient Inference in Phylogenetic InDel Trees</a></p>
<p>14 0.28181401 <a title="139-lsi-14" href="./nips-2008-How_memory_biases_affect_information_transmission%3A_A_rational_analysis_of_serial_reproduction.html">100 nips-2008-How memory biases affect information transmission: A rational analysis of serial reproduction</a></p>
<p>15 0.2814458 <a title="139-lsi-15" href="./nips-2008-Temporal_Dynamics_of_Cognitive_Control.html">231 nips-2008-Temporal Dynamics of Cognitive Control</a></p>
<p>16 0.27495027 <a title="139-lsi-16" href="./nips-2008-Automatic_online_tuning_for_fast_Gaussian_summation.html">29 nips-2008-Automatic online tuning for fast Gaussian summation</a></p>
<p>17 0.2738049 <a title="139-lsi-17" href="./nips-2008-Analyzing_human_feature_learning_as_nonparametric_Bayesian_inference.html">26 nips-2008-Analyzing human feature learning as nonparametric Bayesian inference</a></p>
<p>18 0.27353045 <a title="139-lsi-18" href="./nips-2008-Beyond_Novelty_Detection%3A_Incongruent_Events%2C_when_General_and_Specific_Classifiers_Disagree.html">36 nips-2008-Beyond Novelty Detection: Incongruent Events, when General and Specific Classifiers Disagree</a></p>
<p>19 0.26697963 <a title="139-lsi-19" href="./nips-2008-Load_and_Attentional_Bayes.html">124 nips-2008-Load and Attentional Bayes</a></p>
<p>20 0.26556733 <a title="139-lsi-20" href="./nips-2008-Partially_Observed_Maximum_Entropy_Discrimination_Markov_Networks.html">176 nips-2008-Partially Observed Maximum Entropy Discrimination Markov Networks</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2008_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(6, 0.058), (7, 0.049), (12, 0.49), (28, 0.11), (45, 0.01), (52, 0.012), (57, 0.074), (59, 0.016), (63, 0.013), (71, 0.01), (77, 0.023), (83, 0.043)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.93221176 <a title="139-lda-1" href="./nips-2008-Nonrigid_Structure_from_Motion_in_Trajectory_Space.html">157 nips-2008-Nonrigid Structure from Motion in Trajectory Space</a></p>
<p>Author: Ijaz Akhter, Yaser Sheikh, Sohaib Khan, Takeo Kanade</p><p>Abstract: Existing approaches to nonrigid structure from motion assume that the instantaneous 3D shape of a deforming object is a linear combination of basis shapes, which have to be estimated anew for each video sequence. In contrast, we propose that the evolving 3D structure be described by a linear combination of basis trajectories. The principal advantage of this approach is that we do not need to estimate any basis vectors during computation. We show that generic bases over trajectories, such as the Discrete Cosine Transform (DCT) basis, can be used to compactly describe most real motions. This results in a signiﬁcant reduction in unknowns, and corresponding stability in estimation. We report empirical performance, quantitatively using motion capture data, and qualitatively on several video sequences exhibiting nonrigid motions including piece-wise rigid motion, partially nonrigid motion (such as a facial expression), and highly nonrigid motion (such as a person dancing). 1</p><p>same-paper 2 0.89119864 <a title="139-lda-2" href="./nips-2008-Modeling_the_effects_of_memory_on_human_online_sentence_processing_with_particle_filters.html">139 nips-2008-Modeling the effects of memory on human online sentence processing with particle filters</a></p>
<p>Author: Roger P. Levy, Florencia Reali, Thomas L. Griffiths</p><p>Abstract: Language comprehension in humans is signiﬁcantly constrained by memory, yet rapid, highly incremental, and capable of utilizing a wide range of contextual information to resolve ambiguity and form expectations about future input. In contrast, most of the leading psycholinguistic models and ﬁelded algorithms for natural language parsing are non-incremental, have run time superlinear in input length, and/or enforce structural locality constraints on probabilistic dependencies between events. We present a new limited-memory model of sentence comprehension which involves an adaptation of the particle ﬁlter, a sequential Monte Carlo method, to the problem of incremental parsing. We show that this model can reproduce classic results in online sentence comprehension, and that it naturally provides the ﬁrst rational account of an outstanding problem in psycholinguistics, in which the preferred alternative in a syntactic ambiguity seems to grow more attractive over time even in the absence of strong disambiguating information. 1</p><p>3 0.82776046 <a title="139-lda-3" href="./nips-2008-Shape-Based_Object_Localization_for_Descriptive_Classification.html">207 nips-2008-Shape-Based Object Localization for Descriptive Classification</a></p>
<p>Author: Geremy Heitz, Gal Elidan, Benjamin Packer, Daphne Koller</p><p>Abstract: Discriminative tasks, including object categorization and detection, are central components of high-level computer vision. Sometimes, however, we are interested in more reﬁned aspects of the object in an image, such as pose or particular regions. In this paper we develop a method (LOOPS) for learning a shape and image feature model that can be trained on a particular object class, and used to outline instances of the class in novel images. Furthermore, while the training data consists of uncorresponded outlines, the resulting LOOPS model contains a set of landmark points that appear consistently across instances, and can be accurately localized in an image. Our model achieves state-of-the-art results in precisely outlining objects that exhibit large deformations and articulations in cluttered natural images. These localizations can then be used to address a range of tasks, including descriptive classiﬁcation, search, and clustering. 1</p><p>4 0.80654222 <a title="139-lda-4" href="./nips-2008-Online_Optimization_in_X-Armed_Bandits.html">170 nips-2008-Online Optimization in X-Armed Bandits</a></p>
<p>Author: Sébastien Bubeck, Gilles Stoltz, Csaba Szepesvári, Rémi Munos</p><p>Abstract: We consider a generalization of stochastic bandit problems where the set of arms, X , is allowed to be a generic topological space. We constraint the mean-payoff function with a dissimilarity function over X in a way that is more general than Lipschitz. We construct an arm selection policy whose regret improves upon previous result for a large class of problems. In particular, our results imply that if X is the unit hypercube in a Euclidean space and the mean-payoff function has a ﬁnite number of global maxima around which the behavior of the function is locally H¨ lder √ a known exponent, then the expected o with regret is bounded up to a logarithmic factor by n, i.e., the rate of the growth of the regret is independent of the dimension of the space. Moreover, we prove the minimax optimality of our algorithm for the class of mean-payoff functions we consider. 1 Introduction and motivation Bandit problems arise in many settings, including clinical trials, scheduling, on-line parameter tuning of algorithms or optimization of controllers based on simulations. In the classical bandit problem there are a ﬁnite number of arms that the decision maker can select at discrete time steps. Selecting an arm results in a random reward, whose distribution is determined by the identity of the arm selected. The distributions associated with the arms are unknown to the decision maker whose goal is to maximize the expected sum of the rewards received. In many practical situations the arms belong to a large set. This set could be continuous [1; 6; 3; 2; 7], hybrid-continuous, or it could be the space of inﬁnite sequences over a ﬁnite alphabet [4]. In this paper we consider stochastic bandit problems where the set of arms, X , is allowed to be an arbitrary topological space. We assume that the decision maker knows a dissimilarity function deﬁned over this space that constraints the shape of the mean-payoff function. In particular, the dissimilarity function is assumed to put a lower bound on the mean-payoff function from below at each maxima. We also assume that the decision maker is able to cover the space of arms in a recursive manner, successively reﬁning the regions in the covering such that the diameters of these sets shrink at a known geometric rate when measured with the dissimilarity. ∗ Csaba Szepesv´ ri is on leave from MTA SZTAKI. He also greatly acknowledges the support received from the a Alberta Ingenuity Fund, iCore and NSERC. 1 Our work generalizes and improves previous works on continuum-armed bandit problems: Kleinberg [6] and Auer et al. [2] focussed on one-dimensional problems. Recently, Kleinberg et al. [7] considered generic metric spaces assuming that the mean-payoff function is Lipschitz with respect to the (known) metric of the space. They proposed an interesting algorithm that achieves essentially the best possible regret in a minimax sense with respect to these environments. The goal of this paper is to further these works in a number of ways: (i) we allow the set of arms to be a generic topological space; (ii) we propose a practical algorithm motivated by the recent very successful tree-based optimization algorithms [8; 5; 4] and show that the algorithm is (iii) able to exploit higher order smoothness. In particular, as we shall argue in Section 7, (i) improves upon the results of Auer et al. [2], while (i), (ii) and (iii) improve upon the work of Kleinberg et al. [7]. Compared to Kleinberg et al. [7], our work represents an improvement in the fact that just like Auer et al. [2] we make use of the local properties of the mean-payoff function around the maxima only, and not a global property, such as Lipschitzness in √ the whole space. This allows us to obtain a regret which scales as O( n) 1 when e.g. the space is the unit hypercube and the mean-payoff function is locally H¨ lder with known exponent in the neighborhood of any o maxima (which are in ﬁnite number) and bounded away from the maxima outside of these neighborhoods. Thus, we get the desirable property that the rate of growth of the regret is independent of the dimensionality of the input space. We also prove a minimax lower bound that matches our upper bound up to logarithmic factors, showing that the performance of our algorithm is essentially unimprovable in a minimax sense. Besides these theoretical advances the algorithm is anytime and easy to implement. Since it is based on ideas that have proved to be efﬁcient, we expect it to perform well in practice and to make a signiﬁcant impact on how on-line global optimization is performed. 2 Problem setup, notation We consider a topological space X , whose elements will be referred to as arms. A decision maker “pulls” the arms in X one at a time at discrete time steps. Each pull results in a reward that depends on the arm chosen and which the decision maker learns of. The goal of the decision maker is to choose the arms so as to maximize the sum of the rewards that he receives. In this paper we are concerned with stochastic environments. Such an environment M associates to each arm x ∈ X a distribution Mx on the real line. The support of these distributions is assumed to be uniformly bounded with a known bound. For the sake of simplicity, we assume this bound is 1. We denote by f (x) the expectation of Mx , which is assumed to be measurable (all measurability concepts are with respect to the Borel-algebra over X ). The function f : X → R thus deﬁned is called the mean-payoff function. When in round n the decision maker pulls arm Xn ∈ X , he receives a reward Yn drawn from MXn , independently of the past arm choices and rewards. A pulling strategy of a decision maker is determined by a sequence ϕ = (ϕn )n≥1 of measurable mappings, n−1 where each ϕn maps the history space Hn = X × [0, 1] to the space of probability measures over X . By convention, ϕ1 does not take any argument. A strategy is deterministic if for every n the range of ϕn contains only Dirac distributions. According to the process that was already informally described, a pulling strategy ϕ and an environment M jointly determine a random process (X1 , Y1 , X2 , Y2 , . . .) in the following way: In round one, the decision maker draws an arm X1 at random from ϕ1 and gets a payoff Y1 drawn from MX1 . In round n ≥ 2, ﬁrst, Xn is drawn at random according to ϕn (X1 , Y1 , . . . , Xn−1 , Yn−1 ), but otherwise independently of the past. Then the decision maker gets a rewards Yn drawn from MXn , independently of all other random variables in the past given Xn . Let f ∗ = supx∈X f (x) be the maximal expected payoff. The cumulative regret of a pulling strategy in n n environment M is Rn = n f ∗ − t=1 Yt , and the cumulative pseudo-regret is Rn = n f ∗ − t=1 f (Xt ). 1 We write un = O(vu ) when un = O(vn ) up to a logarithmic factor. 2 In the sequel, we restrict our attention to the expected regret E [Rn ], which in fact equals E[Rn ], as can be seen by the application of the tower rule. 3 3.1 The Hierarchical Optimistic Optimization (HOO) strategy Trees of coverings We ﬁrst introduce the notion of a tree of coverings. Our algorithm will require such a tree as an input. Deﬁnition 1 (Tree of coverings). A tree of coverings is a family of measurable subsets (Ph,i )1≤i≤2h , h≥0 of X such that for all ﬁxed integer h ≥ 0, the covering ∪1≤i≤2h Ph,i = X holds. Moreover, the elements of the covering are obtained recursively: each subset Ph,i is covered by the two subsets Ph+1,2i−1 and Ph+1,2i . A tree of coverings can be represented, as the name suggests, by a binary tree T . The whole domain X = P0,1 corresponds to the root of the tree and Ph,i corresponds to the i–th node of depth h, which will be referred to as node (h, i) in the sequel. The fact that each Ph,i is covered by the two subsets Ph+1,2i−1 and Ph+1,2i corresponds to the childhood relationship in the tree. Although the deﬁnition allows the childregions of a node to cover a larger part of the space, typically the size of the regions shrinks as depth h increases (cf. Assumption 1). Remark 1. Our algorithm will instantiate the nodes of the tree on an ”as needed” basis, one by one. In fact, at any round n it will only need n nodes connected to the root. 3.2 Statement of the HOO strategy The algorithm picks at each round a node in the inﬁnite tree T as follows. In the ﬁrst round, it chooses the root node (0, 1). Now, consider round n + 1 with n ≥ 1. Let us denote by Tn the set of nodes that have been picked in previous rounds and by Sn the nodes which are not in Tn but whose parent is. The algorithm picks at round n + 1 a node (Hn+1 , In+1 ) ∈ Sn according to the deterministic rule that will be described below. After selecting the node, the algorithm further chooses an arm Xn+1 ∈ PHn+1 ,In+1 . This selection can be stochastic or deterministic. We do not put any further restriction on it. The algorithm then gets a reward Yn+1 as described above and the procedure goes on: (Hn+1 , In+1 ) is added to Tn to form Tn+1 and the children of (Hn+1 , In+1 ) are added to Sn to give rise to Sn+1 . Let us now turn to how (Hn+1 , In+1 ) is selected. Along with the nodes the algorithm stores what we call B–values. The node (Hn+1 , In+1 ) ∈ Sn to expand at round n + 1 is picked by following a path from the root to a node in Sn , where at each node along the path the child with the larger B–value is selected (ties are broken arbitrarily). In order to deﬁne a node’s B–value, we need a few quantities. Let C(h, i) be the set that collects (h, i) and its descendants. We let n Nh,i (n) = I{(Ht ,It )∈C(h,i)} t=1 be the number of times the node (h, i) was visited. A given node (h, i) is always picked at most once, but since its descendants may be picked afterwards, subsequent paths in the tree can go through it. Consequently, 1 ≤ Nh,i (n) ≤ n for all nodes (h, i) ∈ Tn . Let µh,i (n) be the empirical average of the rewards received for the time-points when the path followed by the algorithm went through (h, i): n 1 µh,i (n) = Yt I{(Ht ,It )∈C(h,i)} . Nh,i (n) t=1 The corresponding upper conﬁdence bound is by deﬁnition Uh,i (n) = µh,i (n) + 3 2 ln n + ν 1 ρh , Nh,i (n) where 0 < ρ < 1 and ν1 > 0 are parameters of the algorithm (to be chosen later by the decision maker, see Assumption 1). For nodes not in Tn , by convention, Uh,i (n) = +∞. Now, for a node (h, i) in Sn , we deﬁne its B–value to be Bh,i (n) = +∞. The B–values for nodes in Tn are given by Bh,i (n) = min Uh,i (n), max Bh+1,2i−1 (n), Bh+1,2i (n) . Note that the algorithm is deterministic (apart, maybe, from the arbitrary random choice of Xt in PHt ,It ). Its total space requirement is linear in n while total running time at round n is at most quadratic in n, though we conjecture that it is O(n log n) on average. 4 Assumptions made on the model and statement of the main result We suppose that X is equipped with a dissimilarity , that is a non-negative mapping : X 2 → R satisfying (x, x) = 0. The diameter (with respect to ) of a subset A of X is given by diam A = supx,y∈A (x, y). Given the dissimilarity , the “open” ball with radius ε > 0 and center c ∈ X is B(c, ε) = { x ∈ X : (c, x) < ε } (we do not require the topology induced by to be related to the topology of X .) In what follows when we refer to an (open) ball, we refer to the ball deﬁned with respect to . The dissimilarity will be used to capture the smoothness of the mean-payoff function. The decision maker chooses and the tree of coverings. The following assumption relates this choice to the parameters ρ and ν1 of the algorithm: Assumption 1. There exist ρ < 1 and ν1 , ν2 > 0 such that for all integers h ≥ 0 and all i = 1, . . . , 2h , the diameter of Ph,i is bounded by ν1 ρh , and Ph,i contains an open ball Ph,i of radius ν2 ρh . For a given h, the Ph,i are disjoint for 1 ≤ i ≤ 2h . Remark 2. A typical choice for the coverings in a cubic domain is to let the domains be hyper-rectangles. They can be obtained, e.g., in a dyadic manner, by splitting at each step hyper-rectangles in the middle along their longest side, in an axis parallel manner; if all sides are equal, we split them along the√ axis. In ﬁrst this example, if X = [0, 1]D and (x, y) = x − y α then we can take ρ = 2−α/D , ν1 = ( D/2)α and ν2 = 1/8α . The next assumption concerns the environment. Deﬁnition 2. We say that f is weakly Lipschitz with respect to if for all x, y ∈ X , f ∗ − f (y) ≤ f ∗ − f (x) + max f ∗ − f (x), (x, y) . (1) Note that weak Lipschitzness is satisﬁed whenever f is 1–Lipschitz, i.e., for all x, y ∈ X , one has |f (x) − f (y)| ≤ (x, y). On the other hand, weak Lipschitzness implies local (one-sided) 1–Lipschitzness at any maxima. Indeed, at an optimal arm x∗ (i.e., such that f (x∗ ) = f ∗ ), (1) rewrites to f (x∗ ) − f (y) ≤ (x∗ , y). However, weak Lipschitzness does not constraint the growth of the loss in the vicinity of other points. Further, weak Lipschitzness, unlike Lipschitzness, does not constraint the local decrease of the loss at any point. Thus, weak-Lipschitzness is a property that lies somewhere between a growth condition on the loss around optimal arms and (one-sided) Lipschitzness. Note that since weak Lipschitzness is deﬁned with respect to a dissimilarity, it can actually capture higher-order smoothness at the optima. For example, f (x) = 1 − x2 is weak Lipschitz with the dissimilarity (x, y) = c(x − y)2 for some appropriate constant c. Assumption 2. The mean-payoff function f is weakly Lipschitz. ∗ ∗ Let fh,i = supx∈Ph,i f (x) and ∆h,i = f ∗ − fh,i be the suboptimality of node (h, i). We say that def a node (h, i) is optimal (respectively, suboptimal) if ∆h,i = 0 (respectively, ∆h,i > 0). Let Xε = { x ∈ X : f (x) ≥ f ∗ − ε } be the set of ε-optimal arms. The following result follows from the deﬁnitions; a proof can be found in the appendix. 4 Lemma 1. Let Assumption 1 and 2 hold. If the suboptimality ∆h,i of a region is bounded by cν1 ρh for some c > 0, then all arms in Ph,i are max{2c, c + 1}ν1 ρh -optimal. The last assumption is closely related to Assumption 2 of Auer et al. [2], who observed that the regret of a continuum-armed bandit algorithm should depend on how fast the volume of the sets of ε-optimal arms shrinks as ε → 0. Here, we capture this by deﬁning a new notion, the near-optimality dimension of the mean-payoff function. The connection between these concepts, as well as the zooming dimension deﬁned by Kleinberg et al. [7] will be further discussed in Section 7. Deﬁne the packing number P(X , , ε) to be the size of the largest packing of X with disjoint open balls of radius ε with respect to the dissimilarity .2 We now deﬁne the near-optimality dimension, which characterizes the size of the sets Xε in terms of ε, and then state our main result. Deﬁnition 3. For c > 0 and ε0 > 0, the (c, ε0 )–near-optimality dimension of f with respect to equals inf d ∈ [0, +∞) : ∃ C s.t. ∀ε ≤ ε0 , P Xcε , , ε ≤ C ε−d (2) (with the usual convention that inf ∅ = +∞). Theorem 1 (Main result). Let Assumptions 1 and 2 hold and assume that the (4ν1 /ν2 , ν2 )–near-optimality dimension of the considered environment is d < +∞. Then, for any d > d there exists a constant C(d ) such that for all n ≥ 1, ERn ≤ C(d ) n(d +1)/(d +2) ln n 1/(d +2) . Further, if the near-optimality dimension is achieved, i.e., the inﬁmum is achieved in (2), then the result holds also for d = d. Remark 3. We can relax the weak-Lipschitz property by requiring it to hold only locally around the maxima. In fact, at the price of increased constants, the result continues to hold if there exists ε > 0 such that (1) holds for any x, y ∈ Xε . To show this we only need to carefully adapt the steps of the proof below. We omit the details from this extended abstract. 5 Analysis of the regret and proof of the main result We ﬁrst state three lemmas, whose proofs can be found in the appendix. The proofs of Lemmas 3 and 4 rely on concentration-of-measure techniques, while that of Lemma 2 follows from a simple case study. Let us ﬁx some path (0, 1), (1, i∗ ), . . . , (h, i∗ ), . . . , of optimal nodes, starting from the root. 1 h Lemma 2. Let (h, i) be a suboptimal node. Let k be the largest depth such that (k, i∗ ) is on the path from k the root to (h, i). Then we have n E Nh,i (n) ≤ u+ P Nh,i (t) > u and Uh,i (t) > f ∗ or Us,i∗ ≤ f ∗ for some s ∈ {k+1, . . . , t−1} s t=u+1 Lemma 3. Let Assumptions 1 and 2 hold. 1, P Uh,i (n) ≤ f ∗ ≤ n−3 . Then, for all optimal nodes and for all integers n ≥ Lemma 4. Let Assumptions 1 and 2 hold. Then, for all integers t ≤ n, for all suboptimal nodes (h, i) 8 ln such that ∆h,i > ν1 ρh , and for all integers u ≥ 1 such that u ≥ (∆h,i −νnρh )2 , one has P Uh,i (t) > 1 f ∗ and Nh,i (t) > u ≤ t n−4 . 2 Note that sometimes packing numbers are deﬁned as the largest packing with disjoint open balls of radius ε/2, or, ε-nets. 5 . Taking u as the integer part of (8 ln n)/(∆h,i − ν1 ρh )2 , and combining the results of Lemma 2, 3, and 4 with a union bound leads to the following key result. Lemma 5. Under Assumptions 1 and 2, for all suboptimal nodes (h, i) such that ∆h,i > ν1 ρh , we have, for all n ≥ 1, 8 ln n 2 E[Nh,i (n)] ≤ + . (∆h,i − ν1 ρh )2 n We are now ready to prove Theorem 1. Proof. For the sake of simplicity we assume that the inﬁmum in the deﬁnition of near-optimality is achieved. To obtain the result in the general case one only needs to replace d below by d > d in the proof below. First step. For all h = 1, 2, . . ., denote by Ih the nodes at depth h that are 2ν1 ρh –optimal, i.e., the nodes ∗ (h, i) such that fh,i ≥ f ∗ − 2ν1 ρh . Then, I is the union of these sets of nodes. Further, let J be the set of nodes that are not in I but whose parent is in I. We then denote by Jh the nodes in J that are located at depth h in the tree. Lemma 4 bounds the expected number of times each node (h, i) ∈ Jh is visited. Since ∆h,i > 2ν1 ρh , we get 8 ln n 2 E Nh,i (n) ≤ 2 2h + . ν1 ρ n Second step. We bound here the cardinality |Ih |, h > 0. If (h, i) ∈ Ih then since ∆h,i ≤ 2ν1 ρh , by Lemma 1 Ph,i ⊂ X4ν1 ρh . Since by Assumption 1, the sets (Ph,i ), for (h, i) ∈ Ih , contain disjoint balls of radius ν2 ρh , we have that |Ih | ≤ P ∪(h,i)∈Ih Ph,i , , ν2 ρh ≤ P X(4ν1 /ν2 ) ν2 ρh , , ν2 ρh ≤ C ν2 ρh −d , where we used the assumption that d is the (4ν1 /ν2 , ν2 )–near-optimality dimension of f (and C is the constant introduced in the deﬁnition of the near-optimality dimension). Third step. Choose η > 0 and let H be the smallest integer such that ρH ≤ η. We partition the inﬁnite tree T into three sets of nodes, T = T1 ∪ T2 ∪ T3 . The set T1 contains nodes of IH and their descendants, T2 = ∪0≤h < 1 and then, by optimizing over ρH (the worst value being ρH ∼ ( ln n )−1/(d+2) ). 6 Minimax optimality The packing dimension of a set X is the smallest d such that there exists a constant k such that for all ε > 0, P X , , ε ≤ k ε−d . For instance, compact subsets of Rd (with non-empty interior) have a packing dimension of d whenever is a norm. If X has a packing dimension of d, then all environments have a near-optimality dimension less than d. The proof of the main theorem indicates that the constant C(d) only depends on d, k (of the deﬁnition of packing dimension), ν1 , ν2 , and ρ, but not on the environment as long as it is weakly Lipschitz. Hence, we can extract from it a distribution-free bound of the form O(n(d+1)/(d+2) ). In fact, this bound can be shown to be optimal as is illustrated by the theorem below, whose assumptions are satisﬁed by, e.g., compact subsets of Rd and if is some norm of Rd . The proof can be found in the appendix. Theorem 2. If X is such that there exists c > 0 with P(X , , ε) ≥ c ε−d ≥ 2 for all ε ≤ 1/4 then for all n ≥ 4d−1 c/ ln(4/3), all strategies ϕ are bound to suffer a regret of at least 2/(d+2) 1 1 c n(d+1)/(d+2) , 4 4 4 ln(4/3) where the supremum is taken over all environments with weakly Lipschitz payoff functions. sup E Rn (ϕ) ≥ 7 Discussion Several works [1; 6; 3; 2; 7] have considered continuum-armed bandits in Euclidean or metric spaces and provided upper- and lower-bounds on the regret for given classes of environments. Cope [3] derived a regret √ of O( n) for compact and convex subset of Rd and a mean-payoff function with unique minima and second order smoothness. Kleinberg [6] considered mean-payoff functions f on the real line that are H¨ lder with o degree 0 < α ≤ 1. The derived regret is Θ(n(α+1)/(α+2) ). Auer et al. [2] extended the analysis to classes of functions with only a local H¨ lder assumption around maximum (with possibly higher smoothness degree o 1+α−αβ α ∈ [0, ∞)), and derived the regret Θ(n 1+2α−αβ ), where β is such that the Lebesgue measure of ε-optimal 7 states is O(εβ ). Another setting is that of [7] who considered a metric space (X , ) and assumed that f is Lipschitz w.r.t. . The obtained regret is O(n(d+1)/(d+2) ) where d is the zooming dimension (deﬁned similarly to our near-optimality dimension, but using covering numbers instead of packing numbers and the sets Xε \ Xε/2 ). When (X , ) is a metric space covering and packing numbers are equivalent and we may prove that the zooming dimension and near-optimality dimensions are equal. Our main contribution compared to [7] is that our weak-Lipschitz assumption, which is substantially weaker than the global Lipschitz assumption assumed in [7], enables our algorithm to work better in some common situations, such as when the mean-payoff function assumes a local smoothness whose order is larger than one. In order to relate all these results, let us consider a speciﬁc example: Let X = [0, 1]D and assume that the mean-reward function f is locally equivalent to a H¨ lder function with degree α ∈ [0, ∞) around any o maxima x∗ of f (the number of maxima is assumed to be ﬁnite): f (x∗ ) − f (x) = Θ(||x − x∗ ||α ) as x → x∗ . (3) This means that ∃c1 , c2 , ε0 > 0, ∀x, s.t. ||x − x∗ || ≤ ε0 , c1 ||x − x∗ ||α ≤ f (x∗ ) − f (x) ≤ c2 ||x − x∗ ||α . √ Under this assumption, the result of Auer et al. [2] shows that for D = 1, the regret is Θ( n) (since here √ β = 1/α). Our result allows us to extend the n regret rate to any dimension D. Indeed, if we choose our def dissimilarity measure to be α (x, y) = ||x − y||α , we may prove that f satisﬁes a locally weak-Lipschitz √ condition (as deﬁned in Remark 3) and that the near-optimality dimension is 0. Thus our regret is O( n), i.e., the rate is independent of the dimension D. In comparison, since Kleinberg et al. [7] have to satisfy a global Lipschitz assumption, they can not use α when α > 1. Indeed a function globally Lipschitz with respect to α is essentially constant. Moreover α does not deﬁne a metric for α > 1. If one resort to the Euclidean metric to fulﬁll their requirement that f be Lipschitz w.r.t. the metric then the zooming dimension becomes D(α − 1)/α, while the regret becomes √ O(n(D(α−1)+α)/(D(α−1)+2α) ), which is strictly worse than O( n) and in fact becomes close to the slow rate O(n(D+1)/(D+2) ) when α is larger. Nevertheless, in the case of α ≤ 1 they get the same regret rate. In contrast, our result shows that under very weak constraints on the mean-payoff function and if the local behavior of the function around its maximum (or ﬁnite number of maxima) is known then global optimization √ suffers a regret of order O( n), independent of the space dimension. As an interesting sidenote let us also remark that our results allow different smoothness orders along different dimensions, i.e., heterogenous smoothness spaces. References [1] R. Agrawal. The continuum-armed bandit problem. SIAM J. Control and Optimization, 33:1926–1951, 1995. [2] P. Auer, R. Ortner, and Cs. Szepesv´ ri. Improved rates for the stochastic continuum-armed bandit problem. 20th a Conference on Learning Theory, pages 454–468, 2007. [3] E. Cope. Regret and convergence bounds for immediate-reward reinforcement learning with continuous action spaces. Preprint, 2004. [4] P.-A. Coquelin and R. Munos. Bandit algorithms for tree search. In Proceedings of 23rd Conference on Uncertainty in Artiﬁcial Intelligence, 2007. [5] S. Gelly, Y. Wang, R. Munos, and O. Teytaud. Modiﬁcation of UCT with patterns in Monte-Carlo go. Technical Report RR-6062, INRIA, 2006. [6] R. Kleinberg. Nearly tight bounds for the continuum-armed bandit problem. In 18th Advances in Neural Information Processing Systems, 2004. [7] R. Kleinberg, A. Slivkins, and E. Upfal. Multi-armed bandits in metric spaces. In Proceedings of the 40th ACM Symposium on Theory of Computing, 2008. [8] L. Kocsis and Cs. Szepesv´ ri. Bandit based Monte-Carlo planning. In Proceedings of the 15th European Conference a on Machine Learning, pages 282–293, 2006. 8</p><p>5 0.79445869 <a title="139-lda-5" href="./nips-2008-Regularized_Co-Clustering_with_Dual_Supervision.html">193 nips-2008-Regularized Co-Clustering with Dual Supervision</a></p>
<p>Author: Vikas Sindhwani, Jianying Hu, Aleksandra Mojsilovic</p><p>Abstract: By attempting to simultaneously partition both the rows (examples) and columns (features) of a data matrix, Co-clustering algorithms often demonstrate surprisingly impressive performance improvements over traditional one-sided row clustering techniques. A good clustering of features may be seen as a combinatorial transformation of the data matrix, effectively enforcing a form of regularization that may lead to a better clustering of examples (and vice-versa). In many applications, partial supervision in the form of a few row labels as well as column labels may be available to potentially assist co-clustering. In this paper, we develop two novel semi-supervised multi-class classiﬁcation algorithms motivated respectively by spectral bipartite graph partitioning and matrix approximation formulations for co-clustering. These algorithms (i) support dual supervision in the form of labels for both examples and/or features, (ii) provide principled predictive capability on out-of-sample test data, and (iii) arise naturally from the classical Representer theorem applied to regularization problems posed on a collection of Reproducing Kernel Hilbert Spaces. Empirical results demonstrate the effectiveness and utility of our algorithms. 1</p><p>6 0.51041436 <a title="139-lda-6" href="./nips-2008-Grouping_Contours_Via_a_Related_Image.html">95 nips-2008-Grouping Contours Via a Related Image</a></p>
<p>7 0.49217862 <a title="139-lda-7" href="./nips-2008-Model_selection_and_velocity_estimation_using_novel_priors_for_motion_patterns.html">136 nips-2008-Model selection and velocity estimation using novel priors for motion patterns</a></p>
<p>8 0.48894519 <a title="139-lda-8" href="./nips-2008-Syntactic_Topic_Models.html">229 nips-2008-Syntactic Topic Models</a></p>
<p>9 0.4728775 <a title="139-lda-9" href="./nips-2008-On_the_Generalization_Ability_of_Online_Strongly_Convex_Programming_Algorithms.html">164 nips-2008-On the Generalization Ability of Online Strongly Convex Programming Algorithms</a></p>
<p>10 0.46861556 <a title="139-lda-10" href="./nips-2008-Algorithms_for_Infinitely_Many-Armed_Bandits.html">17 nips-2008-Algorithms for Infinitely Many-Armed Bandits</a></p>
<p>11 0.46807364 <a title="139-lda-11" href="./nips-2008-Semi-supervised_Learning_with_Weakly-Related_Unlabeled_Data_%3A_Towards_Better_Text_Categorization.html">205 nips-2008-Semi-supervised Learning with Weakly-Related Unlabeled Data : Towards Better Text Categorization</a></p>
<p>12 0.46264169 <a title="139-lda-12" href="./nips-2008-Learning_a_discriminative_hidden_part_model_for_human_action_recognition.html">119 nips-2008-Learning a discriminative hidden part model for human action recognition</a></p>
<p>13 0.4620682 <a title="139-lda-13" href="./nips-2008-A_Scalable_Hierarchical_Distributed_Language_Model.html">4 nips-2008-A Scalable Hierarchical Distributed Language Model</a></p>
<p>14 0.45973369 <a title="139-lda-14" href="./nips-2008-Dynamic_visual_attention%3A_searching_for_coding_length_increments.html">66 nips-2008-Dynamic visual attention: searching for coding length increments</a></p>
<p>15 0.45621011 <a title="139-lda-15" href="./nips-2008-Estimating_vector_fields_using_sparse_basis_field_expansions.html">75 nips-2008-Estimating vector fields using sparse basis field expansions</a></p>
<p>16 0.45496827 <a title="139-lda-16" href="./nips-2008-Mind_the_Duality_Gap%3A_Logarithmic_regret_algorithms_for_online_optimization.html">133 nips-2008-Mind the Duality Gap: Logarithmic regret algorithms for online optimization</a></p>
<p>17 0.45351824 <a title="139-lda-17" href="./nips-2008-Sparsity_of_SVMs_that_use_the_epsilon-insensitive_loss.html">217 nips-2008-Sparsity of SVMs that use the epsilon-insensitive loss</a></p>
<p>18 0.44947726 <a title="139-lda-18" href="./nips-2008-Learning_Hybrid_Models_for_Image_Annotation_with_Partially_Labeled_Data.html">116 nips-2008-Learning Hybrid Models for Image Annotation with Partially Labeled Data</a></p>
<p>19 0.44535196 <a title="139-lda-19" href="./nips-2008-Unsupervised_Learning_of_Visual_Sense_Models_for_Polysemous_Words.html">246 nips-2008-Unsupervised Learning of Visual Sense Models for Polysemous Words</a></p>
<p>20 0.44005069 <a title="139-lda-20" href="./nips-2008-Unlabeled_data%3A_Now_it_helps%2C_now_it_doesn%27t.html">245 nips-2008-Unlabeled data: Now it helps, now it doesn't</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
