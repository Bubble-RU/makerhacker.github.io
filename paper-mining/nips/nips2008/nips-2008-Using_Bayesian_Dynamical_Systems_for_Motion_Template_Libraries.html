<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>247 nips-2008-Using Bayesian Dynamical Systems for Motion Template Libraries</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-247" href="#">nips2008-247</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>247 nips-2008-Using Bayesian Dynamical Systems for Motion Template Libraries</h1>
<br/><p>Source: <a title="nips-2008-247-pdf" href="http://papers.nips.cc/paper/3429-using-bayesian-dynamical-systems-for-motion-template-libraries.pdf">pdf</a></p><p>Author: Silvia Chiappa, Jens Kober, Jan R. Peters</p><p>Abstract: Motor primitives or motion templates have become an important concept for both modeling human motor control as well as generating robot behaviors using imitation learning. Recent impressive results range from humanoid robot movement generation to timing models of human motions. The automatic generation of skill libraries containing multiple motion templates is an important step in robot learning. Such a skill learning system needs to cluster similar movements together and represent each resulting motion template as a generative model which is subsequently used for the execution of the behavior by a robot system. In this paper, we show how human trajectories captured as multi-dimensional time-series can be clustered using Bayesian mixtures of linear Gaussian state-space models based on the similarity of their dynamics. The appropriate number of templates is automatically determined by enforcing a parsimonious parametrization. As the resulting model is intractable, we introduce a novel approximation method based on variational Bayes, which is especially designed to enable the use of efﬁcient inference algorithms. On recorded human Balero movements, this method is not only capable of ﬁnding reasonable motion templates but also yields a generative model which works well in the execution of this complex task on a simulated anthropomorphic SARCOS arm.</p><p>Reference: <a title="nips-2008-247-reference" href="../nips2008_reference/nips-2008-Using_Bayesian_Dynamical_Systems_for_Motion_Template_Libraries_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 de  Abstract Motor primitives or motion templates have become an important concept for both modeling human motor control as well as generating robot behaviors using imitation learning. [sent-6, score-1.191]
</p><p>2 Recent impressive results range from humanoid robot movement generation to timing models of human motions. [sent-7, score-0.517]
</p><p>3 The automatic generation of skill libraries containing multiple motion templates is an important step in robot learning. [sent-8, score-0.993]
</p><p>4 Such a skill learning system needs to cluster similar movements together and represent each resulting motion template as a generative model which is subsequently used for the execution of the behavior by a robot system. [sent-9, score-1.207]
</p><p>5 In this paper, we show how human trajectories captured as multi-dimensional time-series can be clustered using Bayesian mixtures of linear Gaussian state-space models based on the similarity of their dynamics. [sent-10, score-0.317]
</p><p>6 The appropriate number of templates is automatically determined by enforcing a parsimonious parametrization. [sent-11, score-0.288]
</p><p>7 As the resulting model is intractable, we introduce a novel approximation method based on variational Bayes, which is especially designed to enable the use of efﬁcient inference algorithms. [sent-12, score-0.16]
</p><p>8 On recorded human Balero movements, this method is not only capable of ﬁnding reasonable motion templates but also yields a generative model which works well in the execution of this complex task on a simulated anthropomorphic SARCOS arm. [sent-13, score-1.11]
</p><p>9 1 Introduction Humans demonstrate a variety and versatility of movements far beyond the reach of current anthropomorphic robots. [sent-14, score-0.352]
</p><p>10 It is widely believed that human motor control largely relies on a set of “mental templates” [1] better known as motor primitives or motion templates. [sent-15, score-0.785]
</p><p>11 This concept has gained increasing attention both in the human motor control literature [1, 2] as well as in robot imitation learning [3, 4]. [sent-16, score-0.465]
</p><p>12 [3] to use dynamical systems as motor primitives has allowed this approach to scale in the domain of humanoid robot imitation learning and has yielded a variety of interesting applications as well as follow-up publications. [sent-18, score-0.526]
</p><p>13 However, up to now, the focus of motion template learning has largely been on single template acquisition and self-improvement. [sent-19, score-0.468]
</p><p>14 Future motor skill learning systems on the other hand need to be able to observe several different behaviors from human presenters and compile libraries of motion templates directly from these examples with as little predetermined structures as possible. [sent-20, score-1.103]
</p><p>15 An important part of such a motor skill learning system is the clustering of many presented movements into different motion templates. [sent-21, score-0.896]
</p><p>16 Human trajectories are recorded as multi-dimensional timeseries of joint angles as well as joint velocities using either a marker-based tracking setup (e. [sent-22, score-0.363]
</p><p>17 [3], we intend to use dynamical systems as generative models of the presented trajectories, i. [sent-30, score-0.123]
</p><p>18 Our goal is to cluster 1  these multi-dimensional time-series automatically into a small number of motion templates without pre-labeling of the trajectories or assuming an a priori number of templates. [sent-33, score-0.834]
</p><p>19 Thus, the system has to discover the underlying motion templates, determine the number of templates as well as learn the underlying skill sufﬁciently well for robot application. [sent-34, score-0.917]
</p><p>20 , a type of K-means) with a method for selecting an appropriate number of clusters and, subsequently, ﬁt a generative model to each cluster. [sent-37, score-0.144]
</p><p>21 Here we prefer to take a different approach in which the clustering and learning of the underlying time-series dynamics are performed at the same time. [sent-38, score-0.124]
</p><p>22 This way we aim at ensuring that each obtained cluster can be modeled well by its representative generative model. [sent-39, score-0.174]
</p><p>23 To date the majority of the work on time-series clustering using generative models has focused on static mixture models. [sent-40, score-0.173]
</p><p>24 Clustering long or high-dimensional time-series is hard when approached with static models, such that collapsing the trajectories to a few relevant features is often required. [sent-41, score-0.155]
</p><p>25 This problem would be severe for a high-dimensional motor learning system where the data needs to be represented at high sampling rates in order to ensure the capturing of all relevant details for motor skill learning. [sent-42, score-0.41]
</p><p>26 In addition, it is difﬁcult to ensure smoothness when the time-series display high variability and, therefore, to obtain accurate generative models with static approaches. [sent-43, score-0.128]
</p><p>27 A natural alternative is to use mixtures of temporal models which explicitly model the dynamics of the time-series. [sent-44, score-0.155]
</p><p>28 LGSSMs are probabilistic temporal models which, despite their computational simplicity, can represent many natural dynamical processes [5]. [sent-46, score-0.088]
</p><p>29 The drawback of these approaches is that training many separate models can lead to a large computational overhead, such that heuristics are often needed to restrict the number of possible cluster conﬁgurations [7]. [sent-49, score-0.109]
</p><p>30 As a Bayesian treatment of the Mixtures of Linear Gaussian State-Space Models is intractable, we introduce a deterministic approximation based on variational Bayes. [sent-55, score-0.139]
</p><p>31 As a realistically difﬁcult scenario in this ﬁrst step towards large motor skill libraries, we have selected the game of dexterity Balero (also known as Ball-In-A-Cup or Kendama, see [8]) as an evaluation platform. [sent-57, score-0.372]
</p><p>32 Several substantially different types of movements exist for performing this task and humans tend to have a large variability in movement execution [9]. [sent-58, score-0.57]
</p><p>33 From a robotics point of view, Balero can be considered sufﬁciently complex as it involves movements in all major seven degrees of freedom of a human arm as well as an anthropomorphic robot arm. [sent-59, score-0.666]
</p><p>34 We are able to show that the presented method gives rise to a reasonable number of clusters representing quite distinct movements and that the resulting generative models can be used successfully as motion templates in physically realistic simulations. [sent-60, score-1.019]
</p><p>35 We will ﬁrst introduce a generative approach for clustering and modeling multi-dimensional time-series with Bayesian Mixtures of LGSSMs and describe how this approach can be made tractable using a variational approximation. [sent-62, score-0.295]
</p><p>36 2  2 Bayesian Mixtures of Linear Gaussian State-Space Models Our goal is to model both human and robot movements in order to build motion template libraries. [sent-64, score-0.899]
</p><p>37 In this section, we describe our Bayesian modeling approach and discuss both the underlying assumptions as well as how the structure of the model is selected. [sent-65, score-0.075]
</p><p>38 As the resulting model is not tractable for analytical solution, we introduce an approximation method based on variational Bayes. [sent-66, score-0.154]
</p><p>39 The dependency of the priors on ΣH and ΣV is chosen speciﬁcally to render a variational implementation feasible. [sent-100, score-0.145]
</p><p>40 To model the joint indicator variables, we deﬁne N  p(z 1:N |γ) =  p(z n |π) p(π|γ), where p(z n = k|π) ≡ πk . [sent-108, score-0.113]
</p><p>41 In particular, the priors on Ak and B k enk force a sparse parametrization since, during learning, many αk and βj get close to inﬁnity whereby ij k k (the posterior distribution of) Aij and Bj get close to zero (see [11] for an analysis of this pruning effect). [sent-110, score-0.096]
</p><p>42 Speciﬁcally, this approach ensures that the unnecessary LGSSMs are pruned out from the model during training (for certain k, all 1:N ˆ elements of B k are pruned out such that LGSSM k becomes inactive (p(z n = k|v1:T , Θ1:K , γ) = 0 for all n)). [sent-112, score-0.078]
</p><p>43 2 Model Intractability and Approximate Solution The Bayesian treatment of the model is non-trivial as the integration over the parameters Θ1:K and π renders the computation of the required posterior distributions intractable. [sent-114, score-0.092]
</p><p>44 This problem results from the coupling in the posterior distributions between the hidden state variables h1:N and the parameters 1:T Θ1:K as well as between the indicators z 1:N and π, Θ1:K . [sent-115, score-0.109]
</p><p>45 To deal with this intractability, we use a deterministic approximation method based on variational Bayes. [sent-116, score-0.106]
</p><p>46 In our variational approach we introduce a new distribution q and make the following approximation4 1:N ˆ p(z 1:N , h1:N , Θ1:K |v1:T , Θ1:K , γ) ≈ q(h1:N |z 1:N )q(z 1:N )q(Θ1:K ). [sent-118, score-0.106]
</p><p>47 1:T 1:T  (2)  That is, we approximate the posterior distribution of the hidden variables of the model by one in which the hidden states are decoupled from the parameters given the indicator variables and in which the indicators are decoupled from the parameters. [sent-119, score-0.303]
</p><p>48 Observation vt is then placed in the most likely respect to q for ﬁxed Θ LGSSM by computing arg maxk q(z n = k). [sent-121, score-0.11]
</p><p>49 4  Figure 1: This ﬁgure shows one of the Balero motion templates found by our clustering method, i. [sent-124, score-0.678]
</p><p>50 Here, a sideways movement with a subsequent catch is performed and the uppermost row illustrates this movement with a symbolic sketch. [sent-127, score-0.418]
</p><p>51 The middle row shows an execution of the movement generated with the LGSSM representing the cluster C2. [sent-128, score-0.417]
</p><p>52 The lowest row shows a recorded human movement which was attributed to cluster C2 by our method. [sent-129, score-0.485]
</p><p>53 Note that movements generated from LGSSMs representing other clusters differ signiﬁcantly. [sent-130, score-0.318]
</p><p>54 (3)  Whilst computing this joint density is relatively straightforward, the parameter and indicator variable updates require the non-trivial estimation of the posterior averages hn and hn hn t t t−1 with respect to this distribution. [sent-141, score-0.416]
</p><p>55 3 Results In this section we show that the model presented in Section 2 can be used effectively both for inferring the motion templates underlying a set of human trajectories and for approximating motion templates with dynamical systems. [sent-143, score-1.556]
</p><p>56 For doing so, we take the difﬁcult task of Balero, also known as Ball-In-A-Cup or Kendama, and collect human executions of this task using a motion capture 5  C2  0. [sent-144, score-0.663]
</p><p>57 6 0  Figure 2: In this ﬁgure, we show nine plots where each plot represents one cluster found by our method. [sent-187, score-0.133]
</p><p>58 Each of the ﬁve shown trajectories in the respective clusters represents a different recorded Balero movement. [sent-188, score-0.242]
</p><p>59 For better visualization, we do not show joint trajectories here but rather the trajectories of the cup which have an easier physical interpretation and, additionally, reveal the differences between the isolated clusters. [sent-189, score-0.428]
</p><p>60 We show that the presented model successfully extracts meaningful human motion templates underlying Balero, and that the movements generated by the model are successful in simulation of the Balero task on an anthropomorphic SARCOS arm. [sent-192, score-1.173]
</p><p>61 1 Data Generation of Balero Motions In the Balero game of dexterity, a human is given a toy consisting of a cup with a ball attached by a string. [sent-194, score-0.378]
</p><p>62 The goal of the human is to toss the ball into the cup. [sent-195, score-0.201]
</p><p>63 Humans perform a wide variety of different movements in order to achieve this task [9]. [sent-196, score-0.258]
</p><p>64 For example, three very distinct movements are: (i) swing the hand slightly upwards to the side and then go back to catch the ball, (ii) hold the cup high and then move very fast to catch the ball, and (iii) jerk the cup upwards and catch the ball in a fast downwards movement. [sent-197, score-1.014]
</p><p>65 Whilst the difference in these three movements is signiﬁcant and can be easily detected visually, there exist many other movements for which this is not the case. [sent-198, score-0.468]
</p><p>66 We collected 124 different Balero trajectories where the subject was free to select the employed movement. [sent-199, score-0.121]
</p><p>67 For doing so, we used a VICONT M data collection system which samples the trajectories at 200Hz to track both the cup as well as all seven major degrees of freedom of the human arm. [sent-200, score-0.427]
</p><p>68 For the evaluation of our method, we considered the seven joint angles of the human presenter as well as the corresponding seven estimated joint velocities. [sent-201, score-0.324]
</p><p>69 In the lowest row of Figure 1, we show how the human motion is collected with a VICONT M motion tracking setup. [sent-202, score-0.79]
</p><p>70 As we will see later, this speciﬁc movement is assigned by our method to cluster C2 whose representative generative LGSSM can be used successfully for imitating this motion (middle row). [sent-203, score-0.642]
</p><p>71 A sketch of the represented movement is shown in the top row of Figure 1. [sent-204, score-0.19]
</p><p>72 2 Clustering and Imitation of Motion Templates We trained the variational method with different initial conditions, hidden dimension H = 35 and a number of clusters K which varied from 20 to 50 in order to avoid suboptimal results due to local maxima. [sent-206, score-0.206]
</p><p>73 These are plotted in Figure 2, where, instead of the 14-dimensional joint angles and velocities, we show the three-dimensional cup trajectories resulting from these joint movements, as it is easier for humans to make sense of cartesian trajectories. [sent-208, score-0.466]
</p><p>74 Clusters C1, C2 and C3 are movements to the side which subsequently catch the ball. [sent-209, score-0.341]
</p><p>75 Here, C1 is a short jerk, C3 appears to have a circular movement similar to a jerky movement, while C2 uses a longer but smoother movement to induce kinetic energy in the ball. [sent-210, score-0.304]
</p><p>76 Motion templates C4 and C5 are dropping movements where the cup moves down fast for more than 1. [sent-211, score-0.666]
</p><p>77 16  Time[s]  (b)  Figure 3: (a) Time-series recorded from two executions of the Balero movement assigned by our model to cluster C1. [sent-252, score-0.53]
</p><p>78 In the ﬁrst and second rows are plotted the positions and velocities respectively (for better visualization each time-series component is plotted with its mean removed). [sent-253, score-0.157]
</p><p>79 (b) Two executions of the Balero movement generated by our trained model using probability distributions of cluster C1. [sent-254, score-0.464]
</p><p>80 The template C5 is a smoother movement than C4 with a wider catching movement. [sent-256, score-0.228]
</p><p>81 For C6 and C7, we observe a signiﬁcantly different movement where the cup is jerked upwards dragging the ball in this direction and then catches the ball on the way down. [sent-257, score-0.564]
</p><p>82 Clusters C8 and C9 exhibit the most interesting movement where the main motion is forward-backwards and the ball swings into the cup. [sent-258, score-0.549]
</p><p>83 In C8 this task is achieved by moving upwards at the same time while in C9 there is little loss of height. [sent-259, score-0.096]
</p><p>84 2:T In Figure 3 (a) we plotted two recorded executions of the Balero task assigned by our model to cluster C1. [sent-262, score-0.441]
</p><p>85 As we can see, the two executions have similar dynamics but also display some differences due to human variability in performing the same type of movement. [sent-263, score-0.353]
</p><p>86 In Figure 3 (b) we plotted two executions generated by our model using the learned distributions representing cluster C1. [sent-264, score-0.38]
</p><p>87 Our model can generate time-series with very similar dynamics to the ones of the recorded time-series. [sent-265, score-0.115]
</p><p>88 To investigate the accuracy of the obtained motion templates, we used them for executing Balero movements on a simulated anthropomorphic SARCOS arm. [sent-266, score-0.668]
</p><p>89 [15], a small visual feedback term based on a Jacobian transpose method was activated when the ball was within 3cm in order to ensure task-fulﬁllment. [sent-268, score-0.081]
</p><p>90 We found that our motion templates are accurate enough to generate successful task executions. [sent-269, score-0.628]
</p><p>91 This can be seen in Figure 1 for cluster C2 (middle row) and in the video on the author’s website. [sent-270, score-0.109]
</p><p>92 4 Conclusions In this paper, we addressed the problem of automatic generation of skill libraries for both robot learning and human motion analysis as a unsupervised time-series clustering and learning problem based on human trajectories. [sent-271, score-1.019]
</p><p>93 We have introduced a novel Bayesian temporal mixture model based on a variational approximation method which is especially designed to enable the use of efﬁcient inference algorithms. [sent-272, score-0.19]
</p><p>94 We demonstrated that our model gives rise to a meaningful clustering of human executions of the difﬁcult game of dexterity Balero and is able to generate time-series which are very close to the recorded ones. [sent-273, score-0.563]
</p><p>95 Finally, we have shown that the model can be used to obtain successful executions of the Balero movements on a physically realistic simulation of the SARCOS Master Arm. [sent-274, score-0.469]
</p><p>96 Modelling motion primitives and their timing in biologically executed movements. [sent-285, score-0.413]
</p><p>97 On learning, representing and generalizing a task in a humanoid robot. [sent-297, score-0.103]
</p><p>98 A Bayesian approach to temporal data clustering using hidden Markov models. [sent-314, score-0.149]
</p><p>99 Increased sleep spindle activity following simple motor procedural learning in humans. [sent-326, score-0.138]
</p><p>100 Uniﬁed inference for variational Bayesian linear Gaussian statespace models. [sent-357, score-0.106]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('balero', 0.404), ('motion', 0.316), ('lgssm', 0.291), ('templates', 0.288), ('movements', 0.234), ('lgssms', 0.202), ('executions', 0.179), ('movement', 0.152), ('cup', 0.144), ('motor', 0.138), ('skill', 0.134), ('robot', 0.129), ('trajectories', 0.121), ('human', 0.12), ('anthropomorphic', 0.118), ('sarcos', 0.118), ('cluster', 0.109), ('ht', 0.108), ('variational', 0.106), ('execution', 0.089), ('hn', 0.089), ('libraries', 0.084), ('ball', 0.081), ('imitation', 0.078), ('vt', 0.078), ('template', 0.076), ('mixtures', 0.076), ('catch', 0.076), ('clustering', 0.074), ('primitives', 0.073), ('upwards', 0.072), ('bayesian', 0.07), ('dexterity', 0.067), ('vicont', 0.067), ('recorded', 0.066), ('generative', 0.065), ('ijspeert', 0.059), ('kendama', 0.059), ('dynamical', 0.058), ('velocities', 0.056), ('clusters', 0.055), ('humanoid', 0.05), ('indicator', 0.047), ('hidden', 0.045), ('aht', 0.045), ('barber', 0.045), ('bht', 0.045), ('chiappa', 0.045), ('miyamoto', 0.045), ('hyperparameters', 0.043), ('generation', 0.042), ('joint', 0.042), ('seven', 0.042), ('humans', 0.042), ('render', 0.039), ('jerk', 0.039), ('intractability', 0.039), ('decoupled', 0.039), ('kober', 0.039), ('mohler', 0.039), ('plotted', 0.039), ('row', 0.038), ('master', 0.038), ('bj', 0.036), ('angles', 0.036), ('posterior', 0.035), ('static', 0.034), ('dirichlet', 0.034), ('hq', 0.034), ('catches', 0.034), ('ij', 0.033), ('game', 0.033), ('treatment', 0.033), ('maxk', 0.032), ('physically', 0.032), ('subsequently', 0.031), ('gamma', 0.03), ('temporal', 0.03), ('enable', 0.03), ('cybernetics', 0.03), ('collapsed', 0.029), ('whilst', 0.029), ('indicators', 0.029), ('representing', 0.029), ('variability', 0.029), ('parametrization', 0.028), ('pruned', 0.027), ('modeling', 0.026), ('underlying', 0.025), ('updates', 0.025), ('dynamics', 0.025), ('model', 0.024), ('timing', 0.024), ('hyperparameter', 0.024), ('nine', 0.024), ('tractable', 0.024), ('task', 0.024), ('behaviors', 0.023), ('arm', 0.023), ('visualization', 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.000001 <a title="247-tfidf-1" href="./nips-2008-Using_Bayesian_Dynamical_Systems_for_Motion_Template_Libraries.html">247 nips-2008-Using Bayesian Dynamical Systems for Motion Template Libraries</a></p>
<p>Author: Silvia Chiappa, Jens Kober, Jan R. Peters</p><p>Abstract: Motor primitives or motion templates have become an important concept for both modeling human motor control as well as generating robot behaviors using imitation learning. Recent impressive results range from humanoid robot movement generation to timing models of human motions. The automatic generation of skill libraries containing multiple motion templates is an important step in robot learning. Such a skill learning system needs to cluster similar movements together and represent each resulting motion template as a generative model which is subsequently used for the execution of the behavior by a robot system. In this paper, we show how human trajectories captured as multi-dimensional time-series can be clustered using Bayesian mixtures of linear Gaussian state-space models based on the similarity of their dynamics. The appropriate number of templates is automatically determined by enforcing a parsimonious parametrization. As the resulting model is intractable, we introduce a novel approximation method based on variational Bayes, which is especially designed to enable the use of efﬁcient inference algorithms. On recorded human Balero movements, this method is not only capable of ﬁnding reasonable motion templates but also yields a generative model which works well in the execution of this complex task on a simulated anthropomorphic SARCOS arm.</p><p>2 0.20819719 <a title="247-tfidf-2" href="./nips-2008-Policy_Search_for_Motor_Primitives_in_Robotics.html">181 nips-2008-Policy Search for Motor Primitives in Robotics</a></p>
<p>Author: Jens Kober, Jan R. Peters</p><p>Abstract: Many motor skills in humanoid robotics can be learned using parametrized motor primitives as done in imitation learning. However, most interesting motor learning problems are high-dimensional reinforcement learning problems often beyond the reach of current methods. In this paper, we extend previous work on policy learning from the immediate reward case to episodic reinforcement learning. We show that this results in a general, common framework also connected to policy gradient methods and yielding a novel algorithm for policy learning that is particularly well-suited for dynamic motor primitives. The resulting algorithm is an EM-inspired algorithm applicable to complex motor learning tasks. We compare this algorithm to several well-known parametrized policy search methods and show that it outperforms them. We apply it in the context of motor learning and show that it can learn a complex Ball-in-a-Cup task using a real Barrett WAMTM robot arm. 1</p><p>3 0.20275308 <a title="247-tfidf-3" href="./nips-2008-Model_selection_and_velocity_estimation_using_novel_priors_for_motion_patterns.html">136 nips-2008-Model selection and velocity estimation using novel priors for motion patterns</a></p>
<p>Author: Shuang Wu, Hongjing Lu, Alan L. Yuille</p><p>Abstract: Psychophysical experiments show that humans are better at perceiving rotation and expansion than translation. These ﬁndings are inconsistent with standard models of motion integration which predict best performance for translation [6]. To explain this discrepancy, our theory formulates motion perception at two levels of inference: we ﬁrst perform model selection between the competing models (e.g. translation, rotation, and expansion) and then estimate the velocity using the selected model. We deﬁne novel prior models for smooth rotation and expansion using techniques similar to those in the slow-and-smooth model [17] (e.g. Green functions of differential operators). The theory gives good agreement with the trends observed in human experiments. 1</p><p>4 0.19380088 <a title="247-tfidf-4" href="./nips-2008-Adaptive_Template_Matching_with_Shift-Invariant_Semi-NMF.html">16 nips-2008-Adaptive Template Matching with Shift-Invariant Semi-NMF</a></p>
<p>Author: Jonathan L. Roux, Alain D. Cheveigné, Lucas C. Parra</p><p>Abstract: How does one extract unknown but stereotypical events that are linearly superimposed within a signal with variable latencies and variable amplitudes? One could think of using template matching or matching pursuit to ﬁnd the arbitrarily shifted linear components. However, traditional matching approaches require that the templates be known a priori. To overcome this restriction we use instead semi Non-Negative Matrix Factorization (semiNMF) that we extend to allow for time shifts when matching the templates to the signal. The algorithm estimates templates directly from the data along with their non-negative amplitudes. The resulting method can be thought of as an adaptive template matching procedure. We demonstrate the procedure on the task of extracting spikes from single channel extracellular recordings. On these data the algorithm essentially performs spike detection and unsupervised spike clustering. Results on simulated data and extracellular recordings indicate that the method performs well for signalto-noise ratios of 6dB or higher and that spike templates are recovered accurately provided they are suﬃciently diﬀerent. 1</p><p>5 0.13499831 <a title="247-tfidf-5" href="./nips-2008-Learning_Transformational_Invariants_from_Natural_Movies.html">118 nips-2008-Learning Transformational Invariants from Natural Movies</a></p>
<p>Author: Charles Cadieu, Bruno A. Olshausen</p><p>Abstract: We describe a hierarchical, probabilistic model that learns to extract complex motion from movies of the natural environment. The model consists of two hidden layers: the ﬁrst layer produces a sparse representation of the image that is expressed in terms of local amplitude and phase variables. The second layer learns the higher-order structure among the time-varying phase variables. After training on natural movies, the top layer units discover the structure of phase-shifts within the ﬁrst layer. We show that the top layer units encode transformational invariants: they are selective for the speed and direction of a moving pattern, but are invariant to its spatial structure (orientation/spatial-frequency). The diversity of units in both the intermediate and top layers of the model provides a set of testable predictions for representations that might be found in V1 and MT. In addition, the model demonstrates how feedback from higher levels can inﬂuence representations at lower levels as a by-product of inference in a graphical model. 1</p><p>6 0.13030499 <a title="247-tfidf-6" href="./nips-2008-Learning_Taxonomies_by_Dependence_Maximization.html">117 nips-2008-Learning Taxonomies by Dependence Maximization</a></p>
<p>7 0.12875852 <a title="247-tfidf-7" href="./nips-2008-Nonrigid_Structure_from_Motion_in_Trajectory_Space.html">157 nips-2008-Nonrigid Structure from Motion in Trajectory Space</a></p>
<p>8 0.11770208 <a title="247-tfidf-8" href="./nips-2008-The_Recurrent_Temporal_Restricted_Boltzmann_Machine.html">237 nips-2008-The Recurrent Temporal Restricted Boltzmann Machine</a></p>
<p>9 0.10448453 <a title="247-tfidf-9" href="./nips-2008-Recursive_Segmentation_and_Recognition_Templates_for_2D_Parsing.html">191 nips-2008-Recursive Segmentation and Recognition Templates for 2D Parsing</a></p>
<p>10 0.096769229 <a title="247-tfidf-10" href="./nips-2008-Learning_a_discriminative_hidden_part_model_for_human_action_recognition.html">119 nips-2008-Learning a discriminative hidden part model for human action recognition</a></p>
<p>11 0.093516231 <a title="247-tfidf-11" href="./nips-2008-Unifying_the_Sensory_and_Motor_Components_of_Sensorimotor_Adaptation.html">244 nips-2008-Unifying the Sensory and Motor Components of Sensorimotor Adaptation</a></p>
<p>12 0.090486482 <a title="247-tfidf-12" href="./nips-2008-Kernel-ARMA_for_Hand_Tracking_and_Brain-Machine_interfacing_During_3D_Motor_Control.html">110 nips-2008-Kernel-ARMA for Hand Tracking and Brain-Machine interfacing During 3D Motor Control</a></p>
<p>13 0.08034271 <a title="247-tfidf-13" href="./nips-2008-Variational_Mixture_of_Gaussian_Process_Experts.html">249 nips-2008-Variational Mixture of Gaussian Process Experts</a></p>
<p>14 0.068010479 <a title="247-tfidf-14" href="./nips-2008-Sparse_probabilistic_projections.html">216 nips-2008-Sparse probabilistic projections</a></p>
<p>15 0.066610232 <a title="247-tfidf-15" href="./nips-2008-Local_Gaussian_Process_Regression_for_Real_Time_Online_Model_Learning.html">125 nips-2008-Local Gaussian Process Regression for Real Time Online Model Learning</a></p>
<p>16 0.063472018 <a title="247-tfidf-16" href="./nips-2008-Clustering_via_LP-based_Stabilities.html">48 nips-2008-Clustering via LP-based Stabilities</a></p>
<p>17 0.062071506 <a title="247-tfidf-17" href="./nips-2008-Modeling_human_function_learning_with_Gaussian_processes.html">138 nips-2008-Modeling human function learning with Gaussian processes</a></p>
<p>18 0.061651397 <a title="247-tfidf-18" href="./nips-2008-Tracking_Changing_Stimuli_in_Continuous_Attractor_Neural_Networks.html">240 nips-2008-Tracking Changing Stimuli in Continuous Attractor Neural Networks</a></p>
<p>19 0.060573779 <a title="247-tfidf-19" href="./nips-2008-Understanding_Brain_Connectivity_Patterns_during_Motor_Imagery_for_Brain-Computer_Interfacing.html">243 nips-2008-Understanding Brain Connectivity Patterns during Motor Imagery for Brain-Computer Interfacing</a></p>
<p>20 0.059791569 <a title="247-tfidf-20" href="./nips-2008-Playing_Pinball_with_non-invasive_BCI.html">180 nips-2008-Playing Pinball with non-invasive BCI</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2008_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.182), (1, 0.06), (2, 0.161), (3, -0.039), (4, 0.073), (5, -0.012), (6, -0.06), (7, 0.014), (8, 0.061), (9, -0.03), (10, 0.006), (11, -0.014), (12, 0.088), (13, 0.247), (14, 0.004), (15, 0.111), (16, -0.411), (17, 0.059), (18, -0.076), (19, 0.085), (20, 0.029), (21, -0.046), (22, -0.021), (23, -0.098), (24, 0.102), (25, -0.111), (26, -0.03), (27, -0.054), (28, -0.016), (29, -0.044), (30, 0.098), (31, -0.007), (32, 0.027), (33, -0.025), (34, -0.111), (35, 0.089), (36, -0.022), (37, -0.019), (38, -0.036), (39, -0.033), (40, 0.083), (41, 0.023), (42, -0.032), (43, -0.003), (44, -0.007), (45, 0.029), (46, 0.045), (47, 0.014), (48, -0.035), (49, 0.077)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94007832 <a title="247-lsi-1" href="./nips-2008-Using_Bayesian_Dynamical_Systems_for_Motion_Template_Libraries.html">247 nips-2008-Using Bayesian Dynamical Systems for Motion Template Libraries</a></p>
<p>Author: Silvia Chiappa, Jens Kober, Jan R. Peters</p><p>Abstract: Motor primitives or motion templates have become an important concept for both modeling human motor control as well as generating robot behaviors using imitation learning. Recent impressive results range from humanoid robot movement generation to timing models of human motions. The automatic generation of skill libraries containing multiple motion templates is an important step in robot learning. Such a skill learning system needs to cluster similar movements together and represent each resulting motion template as a generative model which is subsequently used for the execution of the behavior by a robot system. In this paper, we show how human trajectories captured as multi-dimensional time-series can be clustered using Bayesian mixtures of linear Gaussian state-space models based on the similarity of their dynamics. The appropriate number of templates is automatically determined by enforcing a parsimonious parametrization. As the resulting model is intractable, we introduce a novel approximation method based on variational Bayes, which is especially designed to enable the use of efﬁcient inference algorithms. On recorded human Balero movements, this method is not only capable of ﬁnding reasonable motion templates but also yields a generative model which works well in the execution of this complex task on a simulated anthropomorphic SARCOS arm.</p><p>2 0.6740765 <a title="247-lsi-2" href="./nips-2008-Model_selection_and_velocity_estimation_using_novel_priors_for_motion_patterns.html">136 nips-2008-Model selection and velocity estimation using novel priors for motion patterns</a></p>
<p>Author: Shuang Wu, Hongjing Lu, Alan L. Yuille</p><p>Abstract: Psychophysical experiments show that humans are better at perceiving rotation and expansion than translation. These ﬁndings are inconsistent with standard models of motion integration which predict best performance for translation [6]. To explain this discrepancy, our theory formulates motion perception at two levels of inference: we ﬁrst perform model selection between the competing models (e.g. translation, rotation, and expansion) and then estimate the velocity using the selected model. We deﬁne novel prior models for smooth rotation and expansion using techniques similar to those in the slow-and-smooth model [17] (e.g. Green functions of differential operators). The theory gives good agreement with the trends observed in human experiments. 1</p><p>3 0.5797599 <a title="247-lsi-3" href="./nips-2008-Nonrigid_Structure_from_Motion_in_Trajectory_Space.html">157 nips-2008-Nonrigid Structure from Motion in Trajectory Space</a></p>
<p>Author: Ijaz Akhter, Yaser Sheikh, Sohaib Khan, Takeo Kanade</p><p>Abstract: Existing approaches to nonrigid structure from motion assume that the instantaneous 3D shape of a deforming object is a linear combination of basis shapes, which have to be estimated anew for each video sequence. In contrast, we propose that the evolving 3D structure be described by a linear combination of basis trajectories. The principal advantage of this approach is that we do not need to estimate any basis vectors during computation. We show that generic bases over trajectories, such as the Discrete Cosine Transform (DCT) basis, can be used to compactly describe most real motions. This results in a signiﬁcant reduction in unknowns, and corresponding stability in estimation. We report empirical performance, quantitatively using motion capture data, and qualitatively on several video sequences exhibiting nonrigid motions including piece-wise rigid motion, partially nonrigid motion (such as a facial expression), and highly nonrigid motion (such as a person dancing). 1</p><p>4 0.49109006 <a title="247-lsi-4" href="./nips-2008-Learning_Transformational_Invariants_from_Natural_Movies.html">118 nips-2008-Learning Transformational Invariants from Natural Movies</a></p>
<p>Author: Charles Cadieu, Bruno A. Olshausen</p><p>Abstract: We describe a hierarchical, probabilistic model that learns to extract complex motion from movies of the natural environment. The model consists of two hidden layers: the ﬁrst layer produces a sparse representation of the image that is expressed in terms of local amplitude and phase variables. The second layer learns the higher-order structure among the time-varying phase variables. After training on natural movies, the top layer units discover the structure of phase-shifts within the ﬁrst layer. We show that the top layer units encode transformational invariants: they are selective for the speed and direction of a moving pattern, but are invariant to its spatial structure (orientation/spatial-frequency). The diversity of units in both the intermediate and top layers of the model provides a set of testable predictions for representations that might be found in V1 and MT. In addition, the model demonstrates how feedback from higher levels can inﬂuence representations at lower levels as a by-product of inference in a graphical model. 1</p><p>5 0.46266574 <a title="247-lsi-5" href="./nips-2008-Kernel-ARMA_for_Hand_Tracking_and_Brain-Machine_interfacing_During_3D_Motor_Control.html">110 nips-2008-Kernel-ARMA for Hand Tracking and Brain-Machine interfacing During 3D Motor Control</a></p>
<p>Author: Lavi Shpigelman, Hagai Lalazar, Eilon Vaadia</p><p>Abstract: Using machine learning algorithms to decode intended behavior from neural activity serves a dual purpose. First, these tools allow patients to interact with their environment through a Brain-Machine Interface (BMI). Second, analyzing the characteristics of such methods can reveal the relative signiﬁcance of various features of neural activity, task stimuli, and behavior. In this study we adapted, implemented and tested a machine learning method called Kernel Auto-Regressive Moving Average (KARMA), for the task of inferring movements from neural activity in primary motor cortex. Our version of this algorithm is used in an online learning setting and is updated after a sequence of inferred movements is completed. We ﬁrst used it to track real hand movements executed by a monkey in a standard 3D reaching task. We then applied it in a closed-loop BMI setting to infer intended movement, while the monkey’s arms were comfortably restrained, thus performing the task using the BMI alone. KARMA is a recurrent method that learns a nonlinear model of output dynamics. It uses similarity functions (termed kernels) to compare between inputs. These kernels can be structured to incorporate domain knowledge into the method. We compare KARMA to various state-of-the-art methods by evaluating tracking performance and present results from the KARMA based BMI experiments. 1</p><p>6 0.43419486 <a title="247-lsi-6" href="./nips-2008-Adaptive_Template_Matching_with_Shift-Invariant_Semi-NMF.html">16 nips-2008-Adaptive Template Matching with Shift-Invariant Semi-NMF</a></p>
<p>7 0.41968909 <a title="247-lsi-7" href="./nips-2008-The_Recurrent_Temporal_Restricted_Boltzmann_Machine.html">237 nips-2008-The Recurrent Temporal Restricted Boltzmann Machine</a></p>
<p>8 0.41300634 <a title="247-lsi-8" href="./nips-2008-Policy_Search_for_Motor_Primitives_in_Robotics.html">181 nips-2008-Policy Search for Motor Primitives in Robotics</a></p>
<p>9 0.4082709 <a title="247-lsi-9" href="./nips-2008-Learning_Taxonomies_by_Dependence_Maximization.html">117 nips-2008-Learning Taxonomies by Dependence Maximization</a></p>
<p>10 0.39193133 <a title="247-lsi-10" href="./nips-2008-An_ideal_observer_model_of_infant_object_perception.html">23 nips-2008-An ideal observer model of infant object perception</a></p>
<p>11 0.37923002 <a title="247-lsi-11" href="./nips-2008-Unifying_the_Sensory_and_Motor_Components_of_Sensorimotor_Adaptation.html">244 nips-2008-Unifying the Sensory and Motor Components of Sensorimotor Adaptation</a></p>
<p>12 0.37626135 <a title="247-lsi-12" href="./nips-2008-Measures_of_Clustering_Quality%3A_A_Working_Set_of_Axioms_for_Clustering.html">132 nips-2008-Measures of Clustering Quality: A Working Set of Axioms for Clustering</a></p>
<p>13 0.36677957 <a title="247-lsi-13" href="./nips-2008-Cyclizing_Clusters_via_Zeta_Function_of_a_Graph.html">55 nips-2008-Cyclizing Clusters via Zeta Function of a Graph</a></p>
<p>14 0.36455828 <a title="247-lsi-14" href="./nips-2008-Learning_a_discriminative_hidden_part_model_for_human_action_recognition.html">119 nips-2008-Learning a discriminative hidden part model for human action recognition</a></p>
<p>15 0.33728066 <a title="247-lsi-15" href="./nips-2008-Clustering_via_LP-based_Stabilities.html">48 nips-2008-Clustering via LP-based Stabilities</a></p>
<p>16 0.33627462 <a title="247-lsi-16" href="./nips-2008-Understanding_Brain_Connectivity_Patterns_during_Motor_Imagery_for_Brain-Computer_Interfacing.html">243 nips-2008-Understanding Brain Connectivity Patterns during Motor Imagery for Brain-Computer Interfacing</a></p>
<p>17 0.33556199 <a title="247-lsi-17" href="./nips-2008-Local_Gaussian_Process_Regression_for_Real_Time_Online_Model_Learning.html">125 nips-2008-Local Gaussian Process Regression for Real Time Online Model Learning</a></p>
<p>18 0.32129234 <a title="247-lsi-18" href="./nips-2008-Variational_Mixture_of_Gaussian_Process_Experts.html">249 nips-2008-Variational Mixture of Gaussian Process Experts</a></p>
<p>19 0.32021365 <a title="247-lsi-19" href="./nips-2008-Playing_Pinball_with_non-invasive_BCI.html">180 nips-2008-Playing Pinball with non-invasive BCI</a></p>
<p>20 0.30317509 <a title="247-lsi-20" href="./nips-2008-Gaussian-process_factor_analysis_for_low-dimensional_single-trial_analysis_of_neural_population_activity.html">90 nips-2008-Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2008_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(6, 0.039), (7, 0.07), (12, 0.075), (15, 0.02), (28, 0.187), (38, 0.021), (41, 0.261), (57, 0.072), (59, 0.019), (63, 0.047), (71, 0.019), (77, 0.036), (81, 0.012), (83, 0.044)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.86681217 <a title="247-lda-1" href="./nips-2008-Multi-Agent_Filtering_with_Infinitely_Nested_Beliefs.html">141 nips-2008-Multi-Agent Filtering with Infinitely Nested Beliefs</a></p>
<p>Author: Luke Zettlemoyer, Brian Milch, Leslie P. Kaelbling</p><p>Abstract: In partially observable worlds with many agents, nested beliefs are formed when agents simultaneously reason about the unknown state of the world and the beliefs of the other agents. The multi-agent ﬁltering problem is to efﬁciently represent and update these beliefs through time as the agents act in the world. In this paper, we formally deﬁne an inﬁnite sequence of nested beliefs about the state of the world at the current time t, and present a ﬁltering algorithm that maintains a ﬁnite representation which can be used to generate these beliefs. In some cases, this representation can be updated exactly in constant time; we also present a simple approximation scheme to compact beliefs if they become too complex. In experiments, we demonstrate efﬁcient ﬁltering in a range of multi-agent domains. 1</p><p>2 0.78644127 <a title="247-lda-2" href="./nips-2008-Unifying_the_Sensory_and_Motor_Components_of_Sensorimotor_Adaptation.html">244 nips-2008-Unifying the Sensory and Motor Components of Sensorimotor Adaptation</a></p>
<p>Author: Adrian Haith, Carl P. Jackson, R. C. Miall, Sethu Vijayakumar</p><p>Abstract: Adaptation of visually guided reaching movements in novel visuomotor environments (e.g. wearing prism goggles) comprises not only motor adaptation but also substantial sensory adaptation, corresponding to shifts in the perceived spatial location of visual and proprioceptive cues. Previous computational models of the sensory component of visuomotor adaptation have assumed that it is driven purely by the discrepancy introduced between visual and proprioceptive estimates of hand position and is independent of any motor component of adaptation. We instead propose a uniﬁed model in which sensory and motor adaptation are jointly driven by optimal Bayesian estimation of the sensory and motor contributions to perceived errors. Our model is able to account for patterns of performance errors during visuomotor adaptation as well as the subsequent perceptual aftereﬀects. This uniﬁed model also makes the surprising prediction that force ﬁeld adaptation will elicit similar perceptual shifts, even though there is never any discrepancy between visual and proprioceptive observations. We conﬁrm this prediction with an experiment. 1</p><p>same-paper 3 0.78381175 <a title="247-lda-3" href="./nips-2008-Using_Bayesian_Dynamical_Systems_for_Motion_Template_Libraries.html">247 nips-2008-Using Bayesian Dynamical Systems for Motion Template Libraries</a></p>
<p>Author: Silvia Chiappa, Jens Kober, Jan R. Peters</p><p>Abstract: Motor primitives or motion templates have become an important concept for both modeling human motor control as well as generating robot behaviors using imitation learning. Recent impressive results range from humanoid robot movement generation to timing models of human motions. The automatic generation of skill libraries containing multiple motion templates is an important step in robot learning. Such a skill learning system needs to cluster similar movements together and represent each resulting motion template as a generative model which is subsequently used for the execution of the behavior by a robot system. In this paper, we show how human trajectories captured as multi-dimensional time-series can be clustered using Bayesian mixtures of linear Gaussian state-space models based on the similarity of their dynamics. The appropriate number of templates is automatically determined by enforcing a parsimonious parametrization. As the resulting model is intractable, we introduce a novel approximation method based on variational Bayes, which is especially designed to enable the use of efﬁcient inference algorithms. On recorded human Balero movements, this method is not only capable of ﬁnding reasonable motion templates but also yields a generative model which works well in the execution of this complex task on a simulated anthropomorphic SARCOS arm.</p><p>4 0.65632045 <a title="247-lda-4" href="./nips-2008-A_Scalable_Hierarchical_Distributed_Language_Model.html">4 nips-2008-A Scalable Hierarchical Distributed Language Model</a></p>
<p>Author: Andriy Mnih, Geoffrey E. Hinton</p><p>Abstract: Neural probabilistic language models (NPLMs) have been shown to be competitive with and occasionally superior to the widely-used n-gram language models. The main drawback of NPLMs is their extremely long training and testing times. Morin and Bengio have proposed a hierarchical language model built around a binary tree of words, which was two orders of magnitude faster than the nonhierarchical model it was based on. However, it performed considerably worse than its non-hierarchical counterpart in spite of using a word tree created using expert knowledge. We introduce a fast hierarchical language model along with a simple feature-based algorithm for automatic construction of word trees from the data. We then show that the resulting models can outperform non-hierarchical neural models as well as the best n-gram models. 1</p><p>5 0.64921123 <a title="247-lda-5" href="./nips-2008-Learning_Transformational_Invariants_from_Natural_Movies.html">118 nips-2008-Learning Transformational Invariants from Natural Movies</a></p>
<p>Author: Charles Cadieu, Bruno A. Olshausen</p><p>Abstract: We describe a hierarchical, probabilistic model that learns to extract complex motion from movies of the natural environment. The model consists of two hidden layers: the ﬁrst layer produces a sparse representation of the image that is expressed in terms of local amplitude and phase variables. The second layer learns the higher-order structure among the time-varying phase variables. After training on natural movies, the top layer units discover the structure of phase-shifts within the ﬁrst layer. We show that the top layer units encode transformational invariants: they are selective for the speed and direction of a moving pattern, but are invariant to its spatial structure (orientation/spatial-frequency). The diversity of units in both the intermediate and top layers of the model provides a set of testable predictions for representations that might be found in V1 and MT. In addition, the model demonstrates how feedback from higher levels can inﬂuence representations at lower levels as a by-product of inference in a graphical model. 1</p><p>6 0.64641023 <a title="247-lda-6" href="./nips-2008-Temporal_Dynamics_of_Cognitive_Control.html">231 nips-2008-Temporal Dynamics of Cognitive Control</a></p>
<p>7 0.64545929 <a title="247-lda-7" href="./nips-2008-Semi-supervised_Learning_with_Weakly-Related_Unlabeled_Data_%3A_Towards_Better_Text_Categorization.html">205 nips-2008-Semi-supervised Learning with Weakly-Related Unlabeled Data : Towards Better Text Categorization</a></p>
<p>8 0.64535856 <a title="247-lda-8" href="./nips-2008-Relative_Performance_Guarantees_for_Approximate_Inference_in_Latent_Dirichlet_Allocation.html">197 nips-2008-Relative Performance Guarantees for Approximate Inference in Latent Dirichlet Allocation</a></p>
<p>9 0.64528674 <a title="247-lda-9" href="./nips-2008-Modeling_human_function_learning_with_Gaussian_processes.html">138 nips-2008-Modeling human function learning with Gaussian processes</a></p>
<p>10 0.64412576 <a title="247-lda-10" href="./nips-2008-Continuously-adaptive_discretization_for_message-passing_algorithms.html">50 nips-2008-Continuously-adaptive discretization for message-passing algorithms</a></p>
<p>11 0.64412391 <a title="247-lda-11" href="./nips-2008-Particle_Filter-based_Policy_Gradient_in_POMDPs.html">177 nips-2008-Particle Filter-based Policy Gradient in POMDPs</a></p>
<p>12 0.64373672 <a title="247-lda-12" href="./nips-2008-Dynamic_visual_attention%3A_searching_for_coding_length_increments.html">66 nips-2008-Dynamic visual attention: searching for coding length increments</a></p>
<p>13 0.64246058 <a title="247-lda-13" href="./nips-2008-Robust_Near-Isometric_Matching_via_Structured_Learning_of_Graphical_Models.html">201 nips-2008-Robust Near-Isometric Matching via Structured Learning of Graphical Models</a></p>
<p>14 0.64201832 <a title="247-lda-14" href="./nips-2008-Model_Selection_in_Gaussian_Graphical_Models%3A_High-Dimensional_Consistency_of_%5Cboldmath%24%5Cell_1%24-regularized_MLE.html">135 nips-2008-Model Selection in Gaussian Graphical Models: High-Dimensional Consistency of \boldmath$\ell 1$-regularized MLE</a></p>
<p>15 0.64179039 <a title="247-lda-15" href="./nips-2008-Kernelized_Sorting.html">113 nips-2008-Kernelized Sorting</a></p>
<p>16 0.64106101 <a title="247-lda-16" href="./nips-2008-Partially_Observed_Maximum_Entropy_Discrimination_Markov_Networks.html">176 nips-2008-Partially Observed Maximum Entropy Discrimination Markov Networks</a></p>
<p>17 0.64091444 <a title="247-lda-17" href="./nips-2008-Simple_Local_Models_for_Complex_Dynamical_Systems.html">211 nips-2008-Simple Local Models for Complex Dynamical Systems</a></p>
<p>18 0.640396 <a title="247-lda-18" href="./nips-2008-Bounds_on_marginal_probability_distributions.html">40 nips-2008-Bounds on marginal probability distributions</a></p>
<p>19 0.64021653 <a title="247-lda-19" href="./nips-2008-Dimensionality_Reduction_for_Data_in_Multiple_Feature_Representations.html">63 nips-2008-Dimensionality Reduction for Data in Multiple Feature Representations</a></p>
<p>20 0.638304 <a title="247-lda-20" href="./nips-2008-MAS%3A_a_multiplicative_approximation_scheme_for_probabilistic_inference.html">129 nips-2008-MAS: a multiplicative approximation scheme for probabilistic inference</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
