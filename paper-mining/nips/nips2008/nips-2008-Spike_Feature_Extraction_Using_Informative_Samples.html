<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>220 nips-2008-Spike Feature Extraction Using Informative Samples</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2008" href="../home/nips2008_home.html">nips2008</a> <a title="nips-2008-220" href="#">nips2008-220</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>220 nips-2008-Spike Feature Extraction Using Informative Samples</h1>
<br/><p>Source: <a title="nips-2008-220-pdf" href="http://papers.nips.cc/paper/3467-spike-feature-extraction-using-informative-samples.pdf">pdf</a></p><p>Author: Zhi Yang, Qi Zhao, Wentai Liu</p><p>Abstract: This paper presents a spike feature extraction algorithm that targets real-time spike sorting and facilitates miniaturized microchip implementation. The proposed algorithm has been evaluated on synthesized waveforms and experimentally recorded sequences. When compared with many spike sorting approaches our algorithm demonstrates improved speed, accuracy and allows unsupervised execution. A preliminary hardware implementation has been realized using an integrated microchip interfaced with a personal computer. 1</p><p>Reference: <a title="nips-2008-220-reference" href="../nips2008_reference/nips-2008-Spike_Feature_Extraction_Using_Informative_Samples_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract This paper presents a spike feature extraction algorithm that targets real-time spike sorting and facilitates miniaturized microchip implementation. [sent-3, score-1.848]
</p><p>2 When compared with many spike sorting approaches our algorithm demonstrates improved speed, accuracy and allows unsupervised execution. [sent-5, score-0.794]
</p><p>3 A preliminary hardware implementation has been realized using an integrated microchip interfaced with a personal computer. [sent-6, score-0.352]
</p><p>4 In order for a spike feature extraction algorithm to be functional as a small device with real-time low-latency processing and low power operation it must be efﬁcient in both computation and IC implementation. [sent-9, score-0.939]
</p><p>5 Implementing spike sorting before data telemetry offers many signiﬁcant advantages. [sent-10, score-0.869]
</p><p>6 Spike feature extraction provides the necessary information required to sort spikes from raw sampled data. [sent-11, score-0.545]
</p><p>7 With this information each spike event can be represented by its unique features and ﬁring time, resulting in signiﬁcant data compression. [sent-12, score-0.671]
</p><p>8 A data transceiver designed with the current semiconductor technology can simultaneously support a large number of recording channels for a microchip implementation to extract the spike feature. [sent-13, score-0.894]
</p><p>9 System integration using wireless power telemetry or a rechargeable battery as well as wireless data telemetry removes the need for tethering wires. [sent-14, score-0.367]
</p><p>10 Frequently used spike feature extraction algorithms include principal component analysis (PCA) [1], bayesian algorithm [2], template matching [3], wavelets [4] and independent component analysis (ICA) [5], which demand signiﬁcant computation. [sent-16, score-0.971]
</p><p>11 In part, complex algorithm procedures are applied to mediate the effects of noise and distortion in the recording process. [sent-18, score-0.3]
</p><p>12 The associated noise includes ion channel noise, activities from distant neurons, ﬁeld potentials, thermal noise and circuit noise. [sent-19, score-0.324]
</p><p>13 Signiﬁcant sampling distortion is also present since it is unrealistic to synchronize the sampling clock with individual recorded spikes. [sent-20, score-0.317]
</p><p>14 This paper reports a new spike feature extraction algorithm which is suitable for real-time spike sorting and enables integrated microchip implementation. [sent-21, score-1.89]
</p><p>15 1  Related Work PCA Based Spike Feature Extraction  PCA is a feature extraction algorithm widely employed for spike sorting. [sent-23, score-0.886]
</p><p>16 However, recorded spikes are usually corrupted by large low frequency noise and distortion, which blur sample correlation and compromise the quality of the estimated covariance matrix and its eigenvectors. [sent-26, score-0.627]
</p><p>17 As a result, PCA may fail to resolve spike clusters in noisy recordings. [sent-27, score-0.726]
</p><p>18 2  Variable Selection Techniques  As a complementary approach to dimensionality reduction algorithms, Jolliffe discussed a general feature extraction algorithm based on a subset of samples in the classic work [6]. [sent-29, score-0.358]
</p><p>19 The power and area are the primary problems with the microchip implementation of other spike feature extraction algorithms. [sent-35, score-1.14]
</p><p>20 3  Our Approach  We have developed a spike feature extraction algorithm based on informative samples. [sent-39, score-1.046]
</p><p>21 The theoretical framework includes neuronal geometry signatures, noise shaping, and informative sample selection. [sent-40, score-0.468]
</p><p>22 By evaluating neuronal geometry signatures with the compartment model, we ﬁnd that high frequency signal spectrum may contain useful information to differentiate neurons. [sent-41, score-0.565]
</p><p>23 Studying the noise properties has revealed that a frequency shaping ﬁlter can be used to boost the SNR. [sent-42, score-0.369]
</p><p>24 The sample selection technique using estimated entropy identiﬁes informative samples for sorting spikes. [sent-43, score-0.441]
</p><p>25 In addition, a preliminary IC implementation of the algorithm has been reported [7, 8] and further integrated onto a multi-channel neural recording IC with wireless telemetry [9]. [sent-44, score-0.291]
</p><p>26 jm (τ )W (t − τ )dτ,  (2)  The recorded waveforms from neurons with similar ion channel populations can be very similar. [sent-52, score-0.439]
</p><p>27 A general spike sorting algorithm frequently fails to resolve such ambiguity and may report a single, large, spike cluster. [sent-53, score-1.428]
</p><p>28 Assume W1 (t) and W2 (t) as the geometry kernel functions of two neurons with the same ion channel population, the difference between the two spikes is △V (t) =  jm (τ )[W1 (t − τ ) − W2 (t − τ )]dτ,  (3)  Small waveform differences appear if (W1 (t) − W2 (t))dt ≈ 0. [sent-55, score-0.796]
</p><p>29 The condition of [W1 (t) − W2 (t)]dt ≈ 0 is equivalent to F(W1 −W2 ) ≈ 0|f =0Hz , which implies that the waveform difference caused by the geometry kernel functions has small contribution at lower frequency spectrum. [sent-59, score-0.424]
</p><p>30 A more quantitative explanation can be given by studying the derivative of F(△V ) with respect to the frequency using Eq. [sent-60, score-0.305]
</p><p>31 5, on the other hand, exhibits a strong frequency dependency within the dominant spectrum of F(jm ). [sent-68, score-0.281]
</p><p>32 In summary, the waveform difference between similar neurons caused by geometry functions satisﬁes the following conditions F(△V ) ≈ 0|f =0Hz (7) ∂F (△V ) ≈ 4π 2 f F(jm ) (W1 (t) − W2 (t))t sin(2πf t) dt ∝ f. [sent-70, score-0.287]
</p><p>33 7, ∂F ∂f ) is linear to frequency f at low frequency region, as sin(2πf t) ≈ 1. [sent-72, score-0.342]
</p><p>34 The strong 2πf t emphasis on frequency shows that F(△V ) exhibits a higher frequency spectrum. [sent-73, score-0.342]
</p><p>35 2  Noise and Sample Distortion  An estimated power spectrum of noise associated with recorded neural signal, where the dominance of low frequency noise is clear, is plotted in Figure 1. [sent-76, score-0.623]
</p><p>36 In case a fast transition edge is sampled 4 times, the sampling distortion can be more than 10% of the spike peak-to-peak magnitude. [sent-85, score-0.827]
</p><p>37 4  Sample Information  In order to use informative samples to sort spikes, it is necessary to quantify the information carried by individual spike samples. [sent-89, score-0.979]
</p><p>38 Intuitively, a sample is considered to be informative if the superimposed spikes can be classiﬁed into multiple clusters by evaluating that sample alone. [sent-90, score-0.68]
</p><p>39 Therefore, the amount of spikes to compute information can be reduced to a relatively small number, which should allow hardware implementation in terms of storage space and computation complexity. [sent-99, score-0.397]
</p><p>40 With the synthesized spike data we used, each sequence contains 3 neuronal sources with similar ﬁring rate. [sent-100, score-0.756]
</p><p>41 Quantitative comparisons to investigate the existence of informative samples in noisy spikes have been done. [sent-104, score-0.495]
</p><p>42 Results using synthesized spikes with recordings from neocortex and basal ganglia [4] are shown in Figure 2. [sent-105, score-0.394]
</p><p>43 Second, it is necessary to create informative samples if due to severe noise, distortion and similarity of spike clusters, few of the samples is informative. [sent-108, score-1.103]
</p><p>44 As a constraint to create informative samples, the computation and storage space have to be feasible for microchip implementation. [sent-109, score-0.358]
</p><p>45 5  Create Informative Samples Using Frequency Shaping Filter  As analyzed in Section 3, a frequency shaping ﬁlter can be used to manifest different geometry kernel functions, reduce noise and redistribute distortion among spike samples. [sent-110, score-1.313]
</p><p>46 7  spike derivative spike  1  spike derivative spike  0. [sent-113, score-2.752]
</p><p>47 1  0  5  10  (b) spike derivative spike  1  0  −0. [sent-123, score-1.376]
</p><p>48 1  15 20 25 sample number  30  35  spike derivative spike  spike derivative spike  0. [sent-124, score-2.8]
</p><p>49 4  5  10  15 20 25 sample number  (e)  30  35  35  spike derivative spike  0. [sent-128, score-1.424]
</p><p>50 1  0  5  (g)  10  15 20 25 sample number  30  35  (h)  Figure 2: (a) - (h) information carried by samples from spikes and their derivatives. [sent-168, score-0.42]
</p><p>51 The black solid line and red dotted line represent the sample information from spikes and their derivatives, respectively. [sent-170, score-0.337]
</p><p>52 designed to boost high frequency spike features, which should be localized and less correlated if examined in time domain. [sent-171, score-0.838]
</p><p>53 In this section, we use derivative operation as an example to illustrate the usefulness of the frequency shaping ﬁlter, and further demonstrate that the ﬁlter creates additional informative samples. [sent-172, score-0.559]
</p><p>54 In a discrete time spike sequence, the frequency response of taking derivative is H(f ) = 2ejπf /2 sin(πf /fs ),  (9)  where fs is the sampling frequency of the ADC. [sent-173, score-1.114]
</p><p>55 1, the difference between neuron geometry kernel functions W (t) of similar spikes is contained in the higher frequency components, which should be emphasized by derivative operation. [sent-175, score-0.716]
</p><p>56 Intuitively, low frequency noise is reduced and the high frequency thermal noise is ampliﬁed, as shown in Figure 1 (b). [sent-177, score-0.554]
</p><p>57 The quantitative impact of the frequency shaping ﬁlter on noise is affected by the recording system and biological environment, and the typical values of α we observe vary around 2 within the signal band as shown in Figure 1. [sent-178, score-0.481]
</p><p>58 In case λ is less than 1, SNR further increases, which favors spike sorting from the noise perspective. [sent-181, score-0.872]
</p><p>59 In the original waveforms, samples close to peaks suffer less distortion compared with those in transition. [sent-183, score-0.334]
</p><p>60 In these data, the black solid lines represent information carried by the samples from spikes and the dotted red lines represent the derivatives. [sent-188, score-0.399]
</p><p>61 The spike data are 8 challenging sequences from [4]. [sent-189, score-0.634]
</p><p>62 The corresponding feature extraction results using the most informative samples from spikes as well as their derivatives are shown in Figure 3 (a) - (h), which clearly presents a 3 cluster conﬁguration. [sent-194, score-0.776]
</p><p>63 6  (an)  Figure 3: feature extraction results using the proposed algorithm and competing algorithms. [sent-731, score-0.281]
</p><p>64 (a) (h) display the extracted features using the most informative samples of spikes and their derivatives (proposed). [sent-732, score-0.655]
</p><p>65 (i) - (p) display the extracted features using a subset of samples includes the peaks of the spike derivative and spike height (implemented on chip, proposed). [sent-733, score-1.711]
</p><p>66 (ag) - (an) display spike peaks based feature extraction. [sent-736, score-0.835]
</p><p>67 Nonlinear energy operator (NEO) [11] is used as the spike detection algorithm. [sent-738, score-0.634]
</p><p>68 )  Table 1: Accuracy comparison of using different spike feature extraction algorithms Sequence Number 1 2 3 4 5 6 7 8 Informative Samples 97. [sent-742, score-0.886]
</p><p>69 0% Note: Informative samples are harvested from both spikes and their derivatives. [sent-782, score-0.335]
</p><p>70 6  Experiments  Synthesized spike sequences used in Figure 2 are applied to compare the sorting accuracies of different approaches. [sent-785, score-0.794]
</p><p>71 Feature extraction using the pre-speciﬁed subset consists of the peaks of the spike derivative as well as the height of the original spike is shown in Figure 3 (i) - (p). [sent-786, score-1.7]
</p><p>72 g, PCA, wavelets, spike peaks and width are also shown in Figure 3. [sent-788, score-0.732]
</p><p>73 The extracted spike features are clustered on a PC [12]. [sent-789, score-0.721]
</p><p>74 About 5% overlapping spikes are ignored to clearly quantify the performance of different spike feature extraction algorithms. [sent-790, score-1.221]
</p><p>75 The proposed feature extraction algorithm including the most informative samples (corresponding to Figure 3 (a) - (h)) achieves the highest accuracy (97. [sent-791, score-0.485]
</p><p>76 2  0  1  (b)  (f)  (g)  (c)  (h)  (i)  (j)  (k)  Figure 4: (a) recorded spikes from cat cerebral cortex are superimposed, (b) the extracted spike features using a subset of samples are plotted and grouped with a clustering algorithm implemented on PC. [sent-809, score-1.354]
</p><p>77 (d) - (k) individual spike clusters superimposed in (c) are displayed. [sent-811, score-0.796]
</p><p>78 The counterpart algorithms include PCA, wavelets and spike peaks and width give 78. [sent-821, score-0.817]
</p><p>79 An example with overlapped spike clusters is selected for demonstration. [sent-827, score-0.726]
</p><p>80 In Figure 4 (a), the detected 1210 spikes are superimposed. [sent-830, score-0.289]
</p><p>81 Extracted spike features using the pre-speciﬁed subset of samples implemented on chip are shown in Figure 4 (b). [sent-831, score-0.817]
</p><p>82 Less than 10 % of noisy spikes and overlapping spikes are discarded, the rest are classiﬁed and plotted in Figure 4(c). [sent-833, score-0.618]
</p><p>83 To further quantify the validity of the classiﬁed spike clusters, superimposed clusters in Figure 4(c) are individually plotted in Figure 4(d)-(k). [sent-834, score-0.905]
</p><p>84 The second example containing more than 4000 spikes recorded from a monkey is shown in Figure 5. [sent-835, score-0.363]
</p><p>85 Extracted features using the pre-speciﬁed subset of informative samples are shown in Figure 5 (b). [sent-837, score-0.303]
</p><p>86 A zoom in of Figure 5 (b) is plotted in Figure 5 (c) to display the isolation quality of clusters in feature space. [sent-838, score-0.286]
</p><p>87 The classiﬁed spike clusters using the prespeciﬁed subset of informative samples are plotted in Figure 6 (a) - (e). [sent-840, score-1.057]
</p><p>88 To demonstrate that the informative samples based sorting does not over partitioning the data set, the derivatives of spike clusters plotted in Figure 6 (a) - (e) are also plotted in Figure 6 (f)-(j) with the same color indication. [sent-842, score-1.278]
</p><p>89 7  Conclusion  A sample selection based spike feature extraction algorithm is reported in this paper. [sent-844, score-0.934]
</p><p>90 The theoretical framework includes neuronal geometry signatures, frequency shaping ﬁlter, and informative sample selection. [sent-845, score-0.681]
</p><p>91 Unlike PCA which uses correlated features, the sample selection algorithm focuses on localized and uncorrelated features which are strengthened by the frequency shaping ﬁlter. [sent-846, score-0.409]
</p><p>92 With simulated spike waveforms from a public data base, the algorithm demonstrates an improved sorting accuracy compared with many competing algorithms. [sent-847, score-0.913]
</p><p>93 The algorithm is designed for integrated microchip implementation and performing real-time spike sorting. [sent-848, score-0.877]
</p><p>94 2 0  (d)  Figure 5: (a) detected spikes from a monkey, (b) extracted spike features using a subset of samples, (c) zoom in of (b) for better visualization; (d) extracted features using PCA. [sent-890, score-1.156]
</p><p>95 Power feasibility of implantable digital spike sorting circuits for neural prosthetic systems. [sent-894, score-0.864]
</p><p>96 Automated spike sorting using density grid contour clustering and subtractive waveform decomposition. [sent-903, score-0.9]
</p><p>97 Unsupervised spike detection and sorting with wavelets and superparamagnetic clustering. [sent-907, score-0.879]
</p><p>98 A neuron signature based spike feature extraction algorithm for on-chip implementation. [sent-919, score-0.94]
</p><p>99 A 128 channel 6mW wireless neural recording IC with on-the-ﬂy spike sorting and UWB transmitter. [sent-930, score-0.971]
</p><p>100 Pattern and inhibition-dependent invasion of pyramidal cell dendrites by fast spikes in the hippocampus in vivo. [sent-934, score-0.292]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('spike', 0.634), ('spikes', 0.262), ('extraction', 0.193), ('jm', 0.172), ('frequency', 0.171), ('microchip', 0.168), ('distortion', 0.163), ('sorting', 0.16), ('informative', 0.16), ('shaping', 0.12), ('geometry', 0.12), ('spectrum', 0.11), ('derivative', 0.108), ('waveform', 0.106), ('peaks', 0.098), ('clusters', 0.092), ('pca', 0.09), ('waveforms', 0.09), ('wavelets', 0.085), ('wireless', 0.082), ('noise', 0.078), ('signatures', 0.075), ('telemetry', 0.075), ('samples', 0.073), ('hardware', 0.072), ('superimposed', 0.07), ('recorded', 0.068), ('plotted', 0.065), ('neuronal', 0.062), ('ic', 0.06), ('cat', 0.06), ('lter', 0.06), ('synthesized', 0.06), ('feature', 0.059), ('recording', 0.059), ('ntherm', 0.056), ('thermal', 0.056), ('pq', 0.053), ('power', 0.053), ('extracted', 0.05), ('sample', 0.048), ('quantify', 0.044), ('display', 0.044), ('proc', 0.044), ('liu', 0.043), ('integrated', 0.042), ('conf', 0.042), ('aug', 0.042), ('int', 0.042), ('ion', 0.042), ('yang', 0.042), ('chip', 0.04), ('recordings', 0.039), ('adc', 0.037), ('cerabral', 0.037), ('implantable', 0.037), ('interfaced', 0.037), ('membranes', 0.037), ('nadasdy', 0.037), ('nneu', 0.037), ('transmembrane', 0.037), ('wentai', 0.037), ('features', 0.037), ('sin', 0.037), ('carried', 0.037), ('cortex', 0.037), ('channel', 0.036), ('cerebral', 0.035), ('circuit', 0.034), ('subset', 0.033), ('implementation', 0.033), ('localized', 0.033), ('neocortex', 0.033), ('oj', 0.033), ('digital', 0.033), ('monkey', 0.033), ('neurons', 0.031), ('sort', 0.031), ('chen', 0.031), ('ln', 0.03), ('storage', 0.03), ('sampling', 0.03), ('ann', 0.03), ('jolliffe', 0.03), ('pyramidal', 0.03), ('dt', 0.03), ('overlapping', 0.029), ('derivatives', 0.029), ('competing', 0.029), ('cruz', 0.028), ('neuron', 0.028), ('kernel', 0.027), ('detected', 0.027), ('dotted', 0.027), ('signal', 0.027), ('clock', 0.026), ('signature', 0.026), ('sep', 0.026), ('zoom', 0.026), ('quantitative', 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999857 <a title="220-tfidf-1" href="./nips-2008-Spike_Feature_Extraction_Using_Informative_Samples.html">220 nips-2008-Spike Feature Extraction Using Informative Samples</a></p>
<p>Author: Zhi Yang, Qi Zhao, Wentai Liu</p><p>Abstract: This paper presents a spike feature extraction algorithm that targets real-time spike sorting and facilitates miniaturized microchip implementation. The proposed algorithm has been evaluated on synthesized waveforms and experimentally recorded sequences. When compared with many spike sorting approaches our algorithm demonstrates improved speed, accuracy and allows unsupervised execution. A preliminary hardware implementation has been realized using an integrated microchip interfaced with a personal computer. 1</p><p>2 0.43475974 <a title="220-tfidf-2" href="./nips-2008-Dependent_Dirichlet_Process_Spike_Sorting.html">59 nips-2008-Dependent Dirichlet Process Spike Sorting</a></p>
<p>Author: Jan Gasthaus, Frank Wood, Dilan Gorur, Yee W. Teh</p><p>Abstract: In this paper we propose a new incremental spike sorting model that automatically eliminates refractory period violations, accounts for action potential waveform drift, and can handle “appearance” and “disappearance” of neurons. Our approach is to augment a known time-varying Dirichlet process that ties together a sequence of inﬁnite Gaussian mixture models, one per action potential waveform observation, with an interspike-interval-dependent likelihood that prohibits refractory period violations. We demonstrate this model by showing results from sorting two publicly available neural data recordings for which a partial ground truth labeling is known. 1</p><p>3 0.33029723 <a title="220-tfidf-3" href="./nips-2008-Modeling_Short-term_Noise_Dependence_of_Spike_Counts_in_Macaque_Prefrontal_Cortex.html">137 nips-2008-Modeling Short-term Noise Dependence of Spike Counts in Macaque Prefrontal Cortex</a></p>
<p>Author: Arno Onken, Steffen Grünewälder, Matthias Munk, Klaus Obermayer</p><p>Abstract: Correlations between spike counts are often used to analyze neural coding. The noise is typically assumed to be Gaussian. Yet, this assumption is often inappropriate, especially for low spike counts. In this study, we present copulas as an alternative approach. With copulas it is possible to use arbitrary marginal distributions such as Poisson or negative binomial that are better suited for modeling noise distributions of spike counts. Furthermore, copulas place a wide range of dependence structures at the disposal and can be used to analyze higher order interactions. We develop a framework to analyze spike count data by means of copulas. Methods for parameter inference based on maximum likelihood estimates and for computation of mutual information are provided. We apply the method to our data recorded from macaque prefrontal cortex. The data analysis leads to three ﬁndings: (1) copula-based distributions provide signiﬁcantly better ﬁts than discretized multivariate normal distributions; (2) negative binomial margins ﬁt the data signiﬁcantly better than Poisson margins; and (3) the dependence structure carries 12% of the mutual information between stimuli and responses. 1</p><p>4 0.31730786 <a title="220-tfidf-4" href="./nips-2008-Extracting_State_Transition_Dynamics_from_Multiple_Spike_Trains_with_Correlated_Poisson_HMM.html">81 nips-2008-Extracting State Transition Dynamics from Multiple Spike Trains with Correlated Poisson HMM</a></p>
<p>Author: Kentaro Katahira, Jun Nishikawa, Kazuo Okanoya, Masato Okada</p><p>Abstract: Neural activity is non-stationary and varies across time. Hidden Markov Models (HMMs) have been used to track the state transition among quasi-stationary discrete neural states. Within this context, independent Poisson models have been used for the output distribution of HMMs; hence, the model is incapable of tracking the change in correlation without modulating the ﬁring rate. To achieve this, we applied a multivariate Poisson distribution with correlation terms for the output distribution of HMMs. We formulated a Variational Bayes (VB) inference for the model. The VB could automatically determine the appropriate number of hidden states and correlation types while avoiding the overlearning problem. We developed an efﬁcient algorithm for computing posteriors using the recursive relationship of a multivariate Poisson distribution. We demonstrated the performance of our method on synthetic data and a real spike train recorded from a songbird. 1</p><p>5 0.25059673 <a title="220-tfidf-5" href="./nips-2008-Short-Term_Depression_in_VLSI_Stochastic_Synapse.html">209 nips-2008-Short-Term Depression in VLSI Stochastic Synapse</a></p>
<p>Author: Peng Xu, Timothy K. Horiuchi, Pamela A. Abshire</p><p>Abstract: We report a compact realization of short-term depression (STD) in a VLSI stochastic synapse. The behavior of the circuit is based on a subtractive single release model of STD. Experimental results agree well with simulation and exhibit expected STD behavior: the transmitted spike train has negative autocorrelation and lower power spectral density at low frequencies which can remove redundancy in the input spike train, and the mean transmission probability is inversely proportional to the input spike rate which has been suggested as an automatic gain control mechanism in neural systems. The dynamic stochastic synapse could potentially be a powerful addition to existing deterministic VLSI spiking neural systems. 1</p><p>6 0.2396777 <a title="220-tfidf-6" href="./nips-2008-Adaptive_Template_Matching_with_Shift-Invariant_Semi-NMF.html">16 nips-2008-Adaptive Template Matching with Shift-Invariant Semi-NMF</a></p>
<p>7 0.1342849 <a title="220-tfidf-7" href="./nips-2008-Self-organization_using_synaptic_plasticity.html">204 nips-2008-Self-organization using synaptic plasticity</a></p>
<p>8 0.11933752 <a title="220-tfidf-8" href="./nips-2008-Cell_Assemblies_in_Large_Sparse_Inhibitory_Networks_of_Biologically_Realistic_Spiking_Neurons.html">43 nips-2008-Cell Assemblies in Large Sparse Inhibitory Networks of Biologically Realistic Spiking Neurons</a></p>
<p>9 0.11257765 <a title="220-tfidf-9" href="./nips-2008-Bio-inspired_Real_Time_Sensory_Map_Realignment_in_a_Robotic_Barn_Owl.html">38 nips-2008-Bio-inspired Real Time Sensory Map Realignment in a Robotic Barn Owl</a></p>
<p>10 0.10244866 <a title="220-tfidf-10" href="./nips-2008-A_general_framework_for_investigating_how_far_the_decoding_process_in_the_brain_can_be_simplified.html">8 nips-2008-A general framework for investigating how far the decoding process in the brain can be simplified</a></p>
<p>11 0.08570537 <a title="220-tfidf-11" href="./nips-2008-Kernelized_Sorting.html">113 nips-2008-Kernelized Sorting</a></p>
<p>12 0.082627907 <a title="220-tfidf-12" href="./nips-2008-Gaussian-process_factor_analysis_for_low-dimensional_single-trial_analysis_of_neural_population_activity.html">90 nips-2008-Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity</a></p>
<p>13 0.070999756 <a title="220-tfidf-13" href="./nips-2008-Temporal_Difference_Based_Actor_Critic_Learning_-_Convergence_and_Neural_Implementation.html">230 nips-2008-Temporal Difference Based Actor Critic Learning - Convergence and Neural Implementation</a></p>
<p>14 0.064396873 <a title="220-tfidf-14" href="./nips-2008-Bayesian_Kernel_Shaping_for_Learning_Control.html">32 nips-2008-Bayesian Kernel Shaping for Learning Control</a></p>
<p>15 0.062408306 <a title="220-tfidf-15" href="./nips-2008-Kernel-ARMA_for_Hand_Tracking_and_Brain-Machine_interfacing_During_3D_Motor_Control.html">110 nips-2008-Kernel-ARMA for Hand Tracking and Brain-Machine interfacing During 3D Motor Control</a></p>
<p>16 0.055661973 <a title="220-tfidf-16" href="./nips-2008-Dependence_of_Orientation_Tuning_on_Recurrent_Excitation_and_Inhibition_in_a_Network_Model_of_V1.html">58 nips-2008-Dependence of Orientation Tuning on Recurrent Excitation and Inhibition in a Network Model of V1</a></p>
<p>17 0.055133607 <a title="220-tfidf-17" href="./nips-2008-An_improved_estimator_of_Variance_Explained_in_the_presence_of_noise.html">24 nips-2008-An improved estimator of Variance Explained in the presence of noise</a></p>
<p>18 0.054971524 <a title="220-tfidf-18" href="./nips-2008-Designing_neurophysiology_experiments_to_optimally_constrain_receptive_field_models_along_parametric_submanifolds.html">60 nips-2008-Designing neurophysiology experiments to optimally constrain receptive field models along parametric submanifolds</a></p>
<p>19 0.052362673 <a title="220-tfidf-19" href="./nips-2008-MCBoost%3A_Multiple_Classifier_Boosting_for_Perceptual_Co-clustering_of_Images_and_Visual_Features.html">130 nips-2008-MCBoost: Multiple Classifier Boosting for Perceptual Co-clustering of Images and Visual Features</a></p>
<p>20 0.050667968 <a title="220-tfidf-20" href="./nips-2008-Characterizing_neural_dependencies_with_copula_models.html">45 nips-2008-Characterizing neural dependencies with copula models</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2008_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.173), (1, 0.086), (2, 0.336), (3, 0.36), (4, -0.317), (5, 0.05), (6, 0.051), (7, -0.135), (8, -0.161), (9, -0.064), (10, 0.04), (11, -0.152), (12, 0.051), (13, -0.07), (14, 0.062), (15, -0.018), (16, -0.075), (17, -0.034), (18, -0.001), (19, 0.083), (20, 0.081), (21, -0.019), (22, 0.062), (23, -0.038), (24, -0.01), (25, 0.017), (26, -0.043), (27, -0.022), (28, -0.026), (29, 0.089), (30, 0.056), (31, 0.001), (32, 0.017), (33, -0.055), (34, -0.205), (35, -0.035), (36, -0.008), (37, -0.005), (38, 0.015), (39, 0.043), (40, -0.007), (41, 0.005), (42, 0.073), (43, -0.025), (44, 0.018), (45, -0.011), (46, -0.053), (47, -0.008), (48, 0.023), (49, -0.043)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98401403 <a title="220-lsi-1" href="./nips-2008-Spike_Feature_Extraction_Using_Informative_Samples.html">220 nips-2008-Spike Feature Extraction Using Informative Samples</a></p>
<p>Author: Zhi Yang, Qi Zhao, Wentai Liu</p><p>Abstract: This paper presents a spike feature extraction algorithm that targets real-time spike sorting and facilitates miniaturized microchip implementation. The proposed algorithm has been evaluated on synthesized waveforms and experimentally recorded sequences. When compared with many spike sorting approaches our algorithm demonstrates improved speed, accuracy and allows unsupervised execution. A preliminary hardware implementation has been realized using an integrated microchip interfaced with a personal computer. 1</p><p>2 0.93177485 <a title="220-lsi-2" href="./nips-2008-Dependent_Dirichlet_Process_Spike_Sorting.html">59 nips-2008-Dependent Dirichlet Process Spike Sorting</a></p>
<p>Author: Jan Gasthaus, Frank Wood, Dilan Gorur, Yee W. Teh</p><p>Abstract: In this paper we propose a new incremental spike sorting model that automatically eliminates refractory period violations, accounts for action potential waveform drift, and can handle “appearance” and “disappearance” of neurons. Our approach is to augment a known time-varying Dirichlet process that ties together a sequence of inﬁnite Gaussian mixture models, one per action potential waveform observation, with an interspike-interval-dependent likelihood that prohibits refractory period violations. We demonstrate this model by showing results from sorting two publicly available neural data recordings for which a partial ground truth labeling is known. 1</p><p>3 0.85460049 <a title="220-lsi-3" href="./nips-2008-Short-Term_Depression_in_VLSI_Stochastic_Synapse.html">209 nips-2008-Short-Term Depression in VLSI Stochastic Synapse</a></p>
<p>Author: Peng Xu, Timothy K. Horiuchi, Pamela A. Abshire</p><p>Abstract: We report a compact realization of short-term depression (STD) in a VLSI stochastic synapse. The behavior of the circuit is based on a subtractive single release model of STD. Experimental results agree well with simulation and exhibit expected STD behavior: the transmitted spike train has negative autocorrelation and lower power spectral density at low frequencies which can remove redundancy in the input spike train, and the mean transmission probability is inversely proportional to the input spike rate which has been suggested as an automatic gain control mechanism in neural systems. The dynamic stochastic synapse could potentially be a powerful addition to existing deterministic VLSI spiking neural systems. 1</p><p>4 0.80333441 <a title="220-lsi-4" href="./nips-2008-Extracting_State_Transition_Dynamics_from_Multiple_Spike_Trains_with_Correlated_Poisson_HMM.html">81 nips-2008-Extracting State Transition Dynamics from Multiple Spike Trains with Correlated Poisson HMM</a></p>
<p>Author: Kentaro Katahira, Jun Nishikawa, Kazuo Okanoya, Masato Okada</p><p>Abstract: Neural activity is non-stationary and varies across time. Hidden Markov Models (HMMs) have been used to track the state transition among quasi-stationary discrete neural states. Within this context, independent Poisson models have been used for the output distribution of HMMs; hence, the model is incapable of tracking the change in correlation without modulating the ﬁring rate. To achieve this, we applied a multivariate Poisson distribution with correlation terms for the output distribution of HMMs. We formulated a Variational Bayes (VB) inference for the model. The VB could automatically determine the appropriate number of hidden states and correlation types while avoiding the overlearning problem. We developed an efﬁcient algorithm for computing posteriors using the recursive relationship of a multivariate Poisson distribution. We demonstrated the performance of our method on synthetic data and a real spike train recorded from a songbird. 1</p><p>5 0.79627627 <a title="220-lsi-5" href="./nips-2008-Adaptive_Template_Matching_with_Shift-Invariant_Semi-NMF.html">16 nips-2008-Adaptive Template Matching with Shift-Invariant Semi-NMF</a></p>
<p>Author: Jonathan L. Roux, Alain D. Cheveigné, Lucas C. Parra</p><p>Abstract: How does one extract unknown but stereotypical events that are linearly superimposed within a signal with variable latencies and variable amplitudes? One could think of using template matching or matching pursuit to ﬁnd the arbitrarily shifted linear components. However, traditional matching approaches require that the templates be known a priori. To overcome this restriction we use instead semi Non-Negative Matrix Factorization (semiNMF) that we extend to allow for time shifts when matching the templates to the signal. The algorithm estimates templates directly from the data along with their non-negative amplitudes. The resulting method can be thought of as an adaptive template matching procedure. We demonstrate the procedure on the task of extracting spikes from single channel extracellular recordings. On these data the algorithm essentially performs spike detection and unsupervised spike clustering. Results on simulated data and extracellular recordings indicate that the method performs well for signalto-noise ratios of 6dB or higher and that spike templates are recovered accurately provided they are suﬃciently diﬀerent. 1</p><p>6 0.66533285 <a title="220-lsi-6" href="./nips-2008-Modeling_Short-term_Noise_Dependence_of_Spike_Counts_in_Macaque_Prefrontal_Cortex.html">137 nips-2008-Modeling Short-term Noise Dependence of Spike Counts in Macaque Prefrontal Cortex</a></p>
<p>7 0.48364279 <a title="220-lsi-7" href="./nips-2008-Bio-inspired_Real_Time_Sensory_Map_Realignment_in_a_Robotic_Barn_Owl.html">38 nips-2008-Bio-inspired Real Time Sensory Map Realignment in a Robotic Barn Owl</a></p>
<p>8 0.46938801 <a title="220-lsi-8" href="./nips-2008-Self-organization_using_synaptic_plasticity.html">204 nips-2008-Self-organization using synaptic plasticity</a></p>
<p>9 0.41730863 <a title="220-lsi-9" href="./nips-2008-A_general_framework_for_investigating_how_far_the_decoding_process_in_the_brain_can_be_simplified.html">8 nips-2008-A general framework for investigating how far the decoding process in the brain can be simplified</a></p>
<p>10 0.4051896 <a title="220-lsi-10" href="./nips-2008-Gaussian-process_factor_analysis_for_low-dimensional_single-trial_analysis_of_neural_population_activity.html">90 nips-2008-Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity</a></p>
<p>11 0.35682806 <a title="220-lsi-11" href="./nips-2008-Cell_Assemblies_in_Large_Sparse_Inhibitory_Networks_of_Biologically_Realistic_Spiking_Neurons.html">43 nips-2008-Cell Assemblies in Large Sparse Inhibitory Networks of Biologically Realistic Spiking Neurons</a></p>
<p>12 0.29084194 <a title="220-lsi-12" href="./nips-2008-Kernel-ARMA_for_Hand_Tracking_and_Brain-Machine_interfacing_During_3D_Motor_Control.html">110 nips-2008-Kernel-ARMA for Hand Tracking and Brain-Machine interfacing During 3D Motor Control</a></p>
<p>13 0.24878724 <a title="220-lsi-13" href="./nips-2008-Kernelized_Sorting.html">113 nips-2008-Kernelized Sorting</a></p>
<p>14 0.23935878 <a title="220-lsi-14" href="./nips-2008-Characterizing_neural_dependencies_with_copula_models.html">45 nips-2008-Characterizing neural dependencies with copula models</a></p>
<p>15 0.22121467 <a title="220-lsi-15" href="./nips-2008-Breaking_Audio_CAPTCHAs.html">41 nips-2008-Breaking Audio CAPTCHAs</a></p>
<p>16 0.22073676 <a title="220-lsi-16" href="./nips-2008-Temporal_Difference_Based_Actor_Critic_Learning_-_Convergence_and_Neural_Implementation.html">230 nips-2008-Temporal Difference Based Actor Critic Learning - Convergence and Neural Implementation</a></p>
<p>17 0.19541064 <a title="220-lsi-17" href="./nips-2008-Robust_Kernel_Principal_Component_Analysis.html">200 nips-2008-Robust Kernel Principal Component Analysis</a></p>
<p>18 0.19510429 <a title="220-lsi-18" href="./nips-2008-Designing_neurophysiology_experiments_to_optimally_constrain_receptive_field_models_along_parametric_submanifolds.html">60 nips-2008-Designing neurophysiology experiments to optimally constrain receptive field models along parametric submanifolds</a></p>
<p>19 0.19056931 <a title="220-lsi-19" href="./nips-2008-An_improved_estimator_of_Variance_Explained_in_the_presence_of_noise.html">24 nips-2008-An improved estimator of Variance Explained in the presence of noise</a></p>
<p>20 0.18436241 <a title="220-lsi-20" href="./nips-2008-Dependence_of_Orientation_Tuning_on_Recurrent_Excitation_and_Inhibition_in_a_Network_Model_of_V1.html">58 nips-2008-Dependence of Orientation Tuning on Recurrent Excitation and Inhibition in a Network Model of V1</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2008_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(6, 0.055), (7, 0.067), (12, 0.021), (15, 0.023), (28, 0.106), (51, 0.019), (57, 0.051), (59, 0.016), (63, 0.023), (71, 0.426), (77, 0.031), (83, 0.053)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.88282073 <a title="220-lda-1" href="./nips-2008-Spike_Feature_Extraction_Using_Informative_Samples.html">220 nips-2008-Spike Feature Extraction Using Informative Samples</a></p>
<p>Author: Zhi Yang, Qi Zhao, Wentai Liu</p><p>Abstract: This paper presents a spike feature extraction algorithm that targets real-time spike sorting and facilitates miniaturized microchip implementation. The proposed algorithm has been evaluated on synthesized waveforms and experimentally recorded sequences. When compared with many spike sorting approaches our algorithm demonstrates improved speed, accuracy and allows unsupervised execution. A preliminary hardware implementation has been realized using an integrated microchip interfaced with a personal computer. 1</p><p>2 0.81278872 <a title="220-lda-2" href="./nips-2008-On_the_Complexity_of_Linear_Prediction%3A_Risk_Bounds%2C_Margin_Bounds%2C_and_Regularization.html">161 nips-2008-On the Complexity of Linear Prediction: Risk Bounds, Margin Bounds, and Regularization</a></p>
<p>Author: Sham M. Kakade, Karthik Sridharan, Ambuj Tewari</p><p>Abstract: This work characterizes the generalization ability of algorithms whose predictions are linear in the input vector. To this end, we provide sharp bounds for Rademacher and Gaussian complexities of (constrained) linear classes, which directly lead to a number of generalization bounds. This derivation provides simpliﬁed proofs of a number of corollaries including: risk bounds for linear prediction (including settings where the weight vectors are constrained by either L2 or L1 constraints), margin bounds (including both L2 and L1 margins, along with more general notions based on relative entropy), a proof of the PAC-Bayes theorem, and upper bounds on L2 covering numbers (with Lp norm constraints and relative entropy constraints). In addition to providing a uniﬁed analysis, the results herein provide some of the sharpest risk and margin bounds. Interestingly, our results show that the uniform convergence rates of empirical risk minimization algorithms tightly match the regret bounds of online learning algorithms for linear prediction, up to a constant factor of 2. 1</p><p>3 0.79064983 <a title="220-lda-3" href="./nips-2008-A_spatially_varying_two-sample_recombinant_coalescent%2C_with_applications_to_HIV_escape_response.html">11 nips-2008-A spatially varying two-sample recombinant coalescent, with applications to HIV escape response</a></p>
<p>Author: Alexander Braunstein, Zhi Wei, Shane T. Jensen, Jon D. Mcauliffe</p><p>Abstract: Statistical evolutionary models provide an important mechanism for describing and understanding the escape response of a viral population under a particular therapy. We present a new hierarchical model that incorporates spatially varying mutation and recombination rates at the nucleotide level. It also maintains separate parameters for treatment and control groups, which allows us to estimate treatment effects explicitly. We use the model to investigate the sequence evolution of HIV populations exposed to a recently developed antisense gene therapy, as well as a more conventional drug therapy. The detection of biologically relevant and plausible signals in both therapy studies demonstrates the effectiveness of the method. 1</p><p>4 0.76042235 <a title="220-lda-4" href="./nips-2008-MDPs_with_Non-Deterministic_Policies.html">131 nips-2008-MDPs with Non-Deterministic Policies</a></p>
<p>Author: Mahdi M. Fard, Joelle Pineau</p><p>Abstract: Markov Decision Processes (MDPs) have been extensively studied and used in the context of planning and decision-making, and many methods exist to ﬁnd the optimal policy for problems modelled as MDPs. Although ﬁnding the optimal policy is sufﬁcient in many domains, in certain applications such as decision support systems where the policy is executed by a human (rather than a machine), ﬁnding all possible near-optimal policies might be useful as it provides more ﬂexibility to the person executing the policy. In this paper we introduce the new concept of non-deterministic MDP policies, and address the question of ﬁnding near-optimal non-deterministic policies. We propose two solutions to this problem, one based on a Mixed Integer Program and the other one based on a search algorithm. We include experimental results obtained from applying this framework to optimize treatment choices in the context of a medical decision support system. 1</p><p>5 0.48849043 <a title="220-lda-5" href="./nips-2008-Rademacher_Complexity_Bounds_for_Non-I.I.D._Processes.html">189 nips-2008-Rademacher Complexity Bounds for Non-I.I.D. Processes</a></p>
<p>Author: Mehryar Mohri, Afshin Rostamizadeh</p><p>Abstract: This paper presents the ﬁrst Rademacher complexity-based error bounds for noni.i.d. settings, a generalization of similar existing bounds derived for the i.i.d. case. Our bounds hold in the scenario of dependent samples generated by a stationary β-mixing process, which is commonly adopted in many previous studies of noni.i.d. settings. They beneﬁt from the crucial advantages of Rademacher complexity over other measures of the complexity of hypothesis classes. In particular, they are data-dependent and measure the complexity of a class of hypotheses based on the training sample. The empirical Rademacher complexity can be estimated from such ﬁnite samples and lead to tighter generalization bounds. We also present the ﬁrst margin bounds for kernel-based classiﬁcation in this non-i.i.d. setting and brieﬂy study their convergence.</p><p>6 0.48631129 <a title="220-lda-6" href="./nips-2008-Dependent_Dirichlet_Process_Spike_Sorting.html">59 nips-2008-Dependent Dirichlet Process Spike Sorting</a></p>
<p>7 0.47802368 <a title="220-lda-7" href="./nips-2008-Fast_Rates_for_Regularized_Objectives.html">85 nips-2008-Fast Rates for Regularized Objectives</a></p>
<p>8 0.47018316 <a title="220-lda-8" href="./nips-2008-Hebbian_Learning_of_Bayes_Optimal_Decisions.html">96 nips-2008-Hebbian Learning of Bayes Optimal Decisions</a></p>
<p>9 0.46841565 <a title="220-lda-9" href="./nips-2008-A_Transductive_Bound_for_the_Voted_Classifier_with_an_Application_to_Semi-supervised_Learning.html">5 nips-2008-A Transductive Bound for the Voted Classifier with an Application to Semi-supervised Learning</a></p>
<p>10 0.44472489 <a title="220-lda-10" href="./nips-2008-Adaptive_Template_Matching_with_Shift-Invariant_Semi-NMF.html">16 nips-2008-Adaptive Template Matching with Shift-Invariant Semi-NMF</a></p>
<p>11 0.43663031 <a title="220-lda-11" href="./nips-2008-Mind_the_Duality_Gap%3A_Logarithmic_regret_algorithms_for_online_optimization.html">133 nips-2008-Mind the Duality Gap: Logarithmic regret algorithms for online optimization</a></p>
<p>12 0.42515206 <a title="220-lda-12" href="./nips-2008-On_the_Generalization_Ability_of_Online_Strongly_Convex_Programming_Algorithms.html">164 nips-2008-On the Generalization Ability of Online Strongly Convex Programming Algorithms</a></p>
<p>13 0.42400062 <a title="220-lda-13" href="./nips-2008-Phase_transitions_for_high-dimensional_joint_support_recovery.html">179 nips-2008-Phase transitions for high-dimensional joint support recovery</a></p>
<p>14 0.4214074 <a title="220-lda-14" href="./nips-2008-Improved_Moves_for_Truncated_Convex_Models.html">104 nips-2008-Improved Moves for Truncated Convex Models</a></p>
<p>15 0.419541 <a title="220-lda-15" href="./nips-2008-Modeling_Short-term_Noise_Dependence_of_Spike_Counts_in_Macaque_Prefrontal_Cortex.html">137 nips-2008-Modeling Short-term Noise Dependence of Spike Counts in Macaque Prefrontal Cortex</a></p>
<p>16 0.41582832 <a title="220-lda-16" href="./nips-2008-Unlabeled_data%3A_Now_it_helps%2C_now_it_doesn%27t.html">245 nips-2008-Unlabeled data: Now it helps, now it doesn't</a></p>
<p>17 0.41362989 <a title="220-lda-17" href="./nips-2008-Relative_Margin_Machines.html">196 nips-2008-Relative Margin Machines</a></p>
<p>18 0.41228908 <a title="220-lda-18" href="./nips-2008-Multi-Level_Active_Prediction_of_Useful_Image_Annotations_for_Recognition.html">142 nips-2008-Multi-Level Active Prediction of Useful Image Annotations for Recognition</a></p>
<p>19 0.41141269 <a title="220-lda-19" href="./nips-2008-A_general_framework_for_investigating_how_far_the_decoding_process_in_the_brain_can_be_simplified.html">8 nips-2008-A general framework for investigating how far the decoding process in the brain can be simplified</a></p>
<p>20 0.41054407 <a title="220-lda-20" href="./nips-2008-Scalable_Algorithms_for_String_Kernels_with_Inexact_Matching.html">203 nips-2008-Scalable Algorithms for String Kernels with Inexact Matching</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
