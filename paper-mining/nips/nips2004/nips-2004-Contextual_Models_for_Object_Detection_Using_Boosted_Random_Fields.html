<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>47 nips-2004-Contextual Models for Object Detection Using Boosted Random Fields</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2004" href="../home/nips2004_home.html">nips2004</a> <a title="nips-2004-47" href="#">nips2004-47</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>47 nips-2004-Contextual Models for Object Detection Using Boosted Random Fields</h1>
<br/><p>Source: <a title="nips-2004-47-pdf" href="http://papers.nips.cc/paper/2663-contextual-models-for-object-detection-using-boosted-random-fields.pdf">pdf</a></p><p>Author: Antonio Torralba, Kevin P. Murphy, William T. Freeman</p><p>Abstract: We seek to both detect and segment objects in images. To exploit both local image data as well as contextual information, we introduce Boosted Random Fields (BRFs), which uses Boosting to learn the graph structure and local evidence of a conditional random ﬁeld (CRF). The graph structure is learned by assembling graph fragments in an additive model. The connections between individual pixels are not very informative, but by using dense graphs, we can pool information from large regions of the image; dense models also support efﬁcient inference. We show how contextual information from other objects can improve detection performance, both in terms of accuracy and speed, by using a computational cascade. We apply our system to detect stuff and things in ofﬁce and street scenes. 1</p><p>Reference: <a title="nips-2004-47-reference" href="../nips2004_reference/nips-2004-Contextual_Models_for_Object_Detection_Using_Boosted_Random_Fields_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Contextual models for object detection using boosted random ﬁelds Antonio Torralba MIT, CSAIL Cambridge, MA 02139 torralba@mit. [sent-1, score-0.22]
</p><p>2 edu  Abstract We seek to both detect and segment objects in images. [sent-7, score-0.144]
</p><p>3 To exploit both local image data as well as contextual information, we introduce Boosted Random Fields (BRFs), which uses Boosting to learn the graph structure and local evidence of a conditional random ﬁeld (CRF). [sent-8, score-0.431]
</p><p>4 The graph structure is learned by assembling graph fragments in an additive model. [sent-9, score-0.231]
</p><p>5 The connections between individual pixels are not very informative, but by using dense graphs, we can pool information from large regions of the image; dense models also support efﬁcient inference. [sent-10, score-0.104]
</p><p>6 We show how contextual information from other objects can improve detection performance, both in terms of accuracy and speed, by using a computational cascade. [sent-11, score-0.287]
</p><p>7 We apply our system to detect stuff and things in ofﬁce and street scenes. [sent-12, score-0.252]
</p><p>8 1  Introduction  Our long-term goal is to build a vision system that can examine an image and describe what objects are in it, and where. [sent-13, score-0.192]
</p><p>9 5(a), objects of interest, such as the keyboard or mouse, are so small that they are impossible to detect just by using local features. [sent-15, score-0.377]
</p><p>10 Murphy et al [9] used global scene context to help object recognition, but did not model relationships between objects. [sent-18, score-0.093]
</p><p>11 Fink and Perona [4] exploited local dependencies in a boosting framework, but did not allow for multiple rounds of communication between correlated objects. [sent-19, score-0.361]
</p><p>12 He et al [6] do not model connections between objects directly, but rather they induce such correlations indirectly, via a bank of hidden variables, using a “restricted Boltzmann machine” architecture. [sent-20, score-0.144]
</p><p>13 In this paper, we exploit contextual correlations between the object classes by introducing Boosted Random Fields (BRFs). [sent-21, score-0.217]
</p><p>14 Boosted random ﬁelds build on both boosting [5, 10] and conditional random ﬁelds (CRFs) [8, 7, 6]. [sent-22, score-0.299]
</p><p>15 Boosting is a simple way of sequentially constructing “strong” classiﬁers from “weak” components, and has been used for singleclass object detection with great success [12]. [sent-23, score-0.169]
</p><p>16 Dietterich et al [3] combine boosting and 1D CRFs, but they only consider the problem of learning the local evidence potentials; we consider the much harder problem of learning the structure of a 2D CRF. [sent-24, score-0.374]
</p><p>17 We propose a method for learning densely connected random ﬁelds with long range connections. [sent-27, score-0.101]
</p><p>18 The  topology of these connections is chosen by a weak learner which has access to a library of graph fragments, derived from patches of labeled training images, which reﬂect typical spatial arrangments of objects (similar to the segmentation fragments in [2]). [sent-28, score-0.599]
</p><p>19 At each round of the learning algorithm, we add more connections from other locations in the image and from other classes (detectors). [sent-29, score-0.22]
</p><p>20 The connections are assumed to be spatially invariant, which means this update can be performed using convolution followed by a sigmoid nonlinearity. [sent-30, score-0.101]
</p><p>21 In addition to recognizing things, such as cars and people, we are also interested in recognizing spatially extended “stuff” [1], such as roads and buildings. [sent-32, score-0.129]
</p><p>22 The traditional sliding window approach to object detection does not work well for detecting “stuff”. [sent-33, score-0.2]
</p><p>23 Instead, we combine object detection and image segmentation (c. [sent-34, score-0.306]
</p><p>24 We do not rely on a bottom-up image segmentation algorithm, which can be fragile without top-down guidance. [sent-37, score-0.137]
</p><p>25 2  Learning potentials and graph structure  A conditional random ﬁeld (CRF) is a distribution of the form 1 φi (Si ) ψi,j (Si , Sj ) P (S|x) = Z i j∈Ni  where x is the input (e. [sent-38, score-0.182]
</p><p>26 Our goal is to learn the local evidence potentials, φi , the compatibility potentials ψ, and the set of neighbors Ni . [sent-42, score-0.296]
</p><p>27 We propose the following simple approximation: use belief propagation (BP) to estimate the marginals, P (Si |x), and then use boosting to maximize the likelihood of each node’s training data with respect to φi and ψ. [sent-43, score-0.331]
</p><p>28 If we assume that the local potentials t t have the form φt (si ) = [eFi /2 ; e−Fi /2 ], where Fit is some function of the input data, then: i bt (+1) = σ(Fit + Gt ), Gt = log Mit (+1) − log Mit (−1) (3) i i i −u where σ(u) = 1/(1 + e ) is the sigmoid function. [sent-51, score-0.538]
</p><p>29 Input: a set of labeled pairs {xi,m ; Si,m }, bound T t Output: Local evidence functions fit (x) and message update functions gi (bNi ). [sent-55, score-0.45]
</p><p>30 (a) Fit local potential fi (xi,m ) by weighted LS to t t t Yi,m = Si,m (1 + e−Si,m (Fi +Gi,m ) ) t t . [sent-61, score-0.113]
</p><p>31 (b) Fit compatibilities gi (bt−1 ) to Yi,m by weighted LS. [sent-62, score-0.193]
</p><p>32 Ni ,m t−1 t (c) Compute local potential Fi,m = Fi,m + fit (xi,m ) t g n (bt−1 ) Ni ,m n=1 i t the beliefs bt = σ(Fi,m + Gt ) i,m i,m t+1 weights wi,m = bt (−1) bt (+1) i,m i,m  (d) Compute compatibilities Gt = i,m (e) Update (f) Update  Figure 1: BRF training algorithm. [sent-63, score-1.681]
</p><p>33 We assume that the graph is very densely connected so that the information that one single node sends to another is so small that we can make the approximation µt+1 (+1)/µt+1 (−1) ≃ 1. [sent-64, score-0.243]
</p><p>34 (This is a reasonable approximation in the case of images, k→i k→i where each node represents a single pixel; only when the inﬂuence of many pixels is taken into account will the messages become informative. [sent-65, score-0.165]
</p><p>35 Therefore, We can write the beliefs at iteration t as a function of the local evidences and the beliefs at time t − 1: bt (+1) = σ(Fit (xi,m ) + Gt (bt−1 )). [sent-67, score-0.85]
</p><p>36 The key idea i i m behind BRFs is to use boosting to learn the G functions, which approximately implement message passing in densely connected graphs. [sent-68, score-0.435]
</p><p>37 1  Learning local evidence potentials  Deﬁning Fit (xi,m ) = Fit−1 (xi,m ) + fit (xi,m ) as an additive model, where xi,m are the features of training sample m at node i, we can learn this function in a stagewise fashion by optimizing the second order Taylor expansion of Eq. [sent-71, score-0.539]
</p><p>38 4 wrt fit , as in logitBoost [5]: arg min log Jit ≃ arg min t t fi  fi  t  t t wi,m (Yi,m − fit (xi,m ))2  (7)  m  t  t where Yi,m = Si,m (1+e−Si,m (Fi +Gi,m ) ). [sent-72, score-0.494]
</p><p>39 In the case that the weak learner is a “regression stump”, fi (x) = ah(x)+b, we can ﬁnd the optimal a, b by solving a weighted least squares t problem, with weights wi,m = bt (−1) bt (+1); we can ﬁnd the best basis function h(x) by i i searching over all elements of a dictionary. [sent-73, score-1.002]
</p><p>40 2  Learning compatibility potentials and graph structure  In this section, we discuss how to learn the compatibility functions ψij , and hence the structure of the graph. [sent-75, score-0.35]
</p><p>41 Instead of learning the compatibility functions ψij , we propose to  t 1. [sent-76, score-0.097]
</p><p>42 Input: a set of inputs {xi,m } and functions fit , gi Output: Set of beliefs bi,m and MAP estimates Si,m . [sent-77, score-0.46]
</p><p>43 From t = 1 to T , repeat t−1 t (a) Update local evidences Fi,m = Fi,m + fit (xi,m )  (b) Update compatibilities Gt = i,m (c) Compute current beliefs  bt i,m  =  t g n (bt−1 ) Ni ,m n=1 i t σ(Fi,m + Gt ) i,m  4. [sent-80, score-0.906]
</p><p>44 We propose to use an additive model for Gt+1 as we i i t n did for learning F : Gt+1 = n=1 gi (bt ), where bt is a vector with the beliefs of all m m i,m n nodes in the graph at iteration t for the training sample m. [sent-84, score-0.859]
</p><p>45 The weak learners gi (bt ) can m n be regression stumps with the form gi (bt ) = aδ(w · bt > θ) + b, where a, b, θ are the m m parameters of the regression stump, and wi is a set of weights selected from a dictionary. [sent-85, score-0.77]
</p><p>46 The weak learners gi (bt ) will also be linear m t functions. [sent-87, score-0.271]
</p><p>47 Hence the belief update simpliﬁes to bt+1 (+1) = σ(αi · bt + βi + Fi,m ), which m i,m is similar to the mean-ﬁeld update equations. [sent-88, score-0.505]
</p><p>48 The neighborhood Ni over which we sum incoming messages is determined by the graph structure, which is encoded in the non-zero n values of αi . [sent-89, score-0.166]
</p><p>49 Each weak learner gi will compute a weighted combination of the beliefs of the some subset of the nodes; this subset may change from iteration to iteration, and can be t quite large. [sent-90, score-0.484]
</p><p>50 At iteration t, we choose the weak learner gi so as to minimize t  t  t−1  log 1 + e−Si,m (Fi,m +gi (bm  log Jit (bt−1 ) = −  )+  t−1 n=1  n gi (bt−1 )) m  m  which reduces to a weighted least squares problem similar to Eq. [sent-91, score-0.458]
</p><p>51 3  BRFs for multiclass object detection and segmentation  With the BRF training algorithm in hand, we describe our approach for multiclass object detection and region-labeling using densely connected BRFs. [sent-96, score-0.599]
</p><p>52 1  Weak learners for detecting stuff and things  The square sliding window approach does not provide a natural way of working with irregular objects. [sent-98, score-0.256]
</p><p>53 Using region labeling as an image representation allows dealing with irregular and extended objects (buildings, bookshelf, road, . [sent-99, score-0.252]
</p><p>54 Extended stuff [1] may be a very important source of contextual information for other objects. [sent-103, score-0.223]
</p><p>55 (a) Examples from the dictionary of about 2000 patches and masks, Ux,y , Vx,y . [sent-104, score-0.129]
</p><p>56 Figure 3: Examples of patches from the dictionary and an example of the segmentation obtained using boosting trained with patches from (a). [sent-110, score-0.524]
</p><p>57 The weak learners we use for the local evidence potentials are based on the segmentation fragments proposed in [2]. [sent-111, score-0.509]
</p><p>58 Speciﬁcally, we create a dictionary of about 2000 image patches U , chosen at random (but overlapping each object), plus a corresponding set of binary (inclass/ out-of-class) image masks, V : see Fig. [sent-112, score-0.271]
</p><p>59 At each round t, for each class c, and for each dictionary entry, we construct the following weak learner, whose output is a binary matrix of the same size as the image I: v(I) = ((I ⊗ U ) > θ) ∗ V > 0 (9) where ⊗ represents normalized cross-correlation and ∗ represents convolution. [sent-114, score-0.367]
</p><p>60 The intuition behind this is that I ⊗ U will produce peaks at image locations that contain this patch/template, and then convolving with V will superimpose the segmentation mask on top of the peaks. [sent-115, score-0.206]
</p><p>61 To be able to detect objects at multiple scales, we ﬁrst downsample the image to scale σ, compute v(I ↓ σ), and then upsample the result. [sent-117, score-0.215]
</p><p>62 The ﬁnal weak learner does this for multiple scales, ORs all the results together, and then takes a linear transformation. [sent-118, score-0.162]
</p><p>63 3(c) shows an example of segmentation obtained by using boosting without context. [sent-120, score-0.339]
</p><p>64 The weak learners we use for the compatibility functions have a similar form: C  gc (b) = α  bc′ ∗ Wc′  +β  (11)  c′ =1  where bc′ is the image formed by the beliefs at all pixels for class c′ . [sent-121, score-0.541]
</p><p>65 The binary kernels (graph fragments) W deﬁne, for each node x, y of object class c, all the nodes from which it will receive messages. [sent-124, score-0.172]
</p><p>66 These kernels are chosen by sampling patches of various sizes from the labeling of images from the training set. [sent-125, score-0.178]
</p><p>67 This allows generating complicated patterns of connectivity that reﬂect the statistics of object co-occurrences in the training set. [sent-126, score-0.123]
</p><p>68 The overall incoming message is given by adding the kernels obtained at each boosting round. [sent-127, score-0.375]
</p><p>69 (This is the key difference from mutual boosting [4], where the incoming message is just the output of a single weak learner; thus, in mutual boosting, previously learned inter-class connections are only used once. [sent-128, score-0.563]
</p><p>70 ) Although it would seem to take O(t) time to compute Gt , we can precompute a single equivalent kernel W ′ , so at runtime the overall complexity is still linear in the number of boosting rounds, O(T ). [sent-129, score-0.301]
</p><p>71 C  Gt x,y,c =  t n αn Wc′  b c′ ∗ c′ =1  n=1  def  C  βn =  + n  ′ b c′ ∗ W c′ + β ′ c′ =1  car car  building car  road car  F  Road  b=σ(F+G)  Car  x  car building building building road building  Building car road  building road  a) Incoming messages to a car node. [sent-130, score-1.92]
</p><p>72 t=1  t=2  t=4  G  road road  y  t=20  c) A car out of context (outside 3rd ﬂoor windows) is less of a car. [sent-132, score-0.413]
</p><p>73 t=40  Final labeling  b(car)  S(all)  d) Evolution of the beliefs for the car nodes (b) and labeling (S) for road, building, car. [sent-133, score-0.462]
</p><p>74 The BRF is trained to detect cars, buildings and the road. [sent-135, score-0.119]
</p><p>75 4(a-b), we show the structures of the graph and the weights W ′ deﬁned by GT for a BRF trained to detect cars, buildings and roads in street scenes. [sent-137, score-0.263]
</p><p>76 2  Learning and inference  For training we used a labeled dataset of ofﬁce and street scenes with about 100 images in each set. [sent-139, score-0.146]
</p><p>77 During the training, in the ﬁrst 5 rounds we only update the local potentials, to allow local evidence to accrue. [sent-140, score-0.233]
</p><p>78 After the 5th iteration we start updating also the compatibility functions. [sent-141, score-0.144]
</p><p>79 At each round, we update only the local potential and compatibility function associated with a single object class that reduces the most the multiclass cost. [sent-142, score-0.346]
</p><p>80 This allows objects that need many features to have more complicated local potentials. [sent-143, score-0.138]
</p><p>81 The easy-to-detect objects can then pass information to the harder ones. [sent-145, score-0.087]
</p><p>82 A similar behavior is obtained for the car detector (Fig. [sent-149, score-0.137]
</p><p>83 The detection of building and road provides strong constraints for the locations of the car. [sent-151, score-0.271]
</p><p>84 3  Cascade of classiﬁers with BRFs  The BRF can be turned into a cascade [12] by thresholding the beliefs. [sent-153, score-0.094]
</p><p>85 At each round we update a t binary rejection mask for each object class, Rx,y,c , by thresholding the beliefs at round t: t t−1 t t Rx,y,c = Rx,y,c δ(bx,y,c > θc ). [sent-155, score-0.615]
</p><p>86 A pixel in the rejection mask is set to zero when we can t decide that the object is not present (when bt x,y,c is below the threshold θc ≃ 0), and it is set t to 1 when more processing is required. [sent-156, score-0.613]
</p><p>87 Similarity we can deﬁne a detection mask that will indicate pixels in which we decide the object is present. [sent-158, score-0.285]
</p><p>88 The mask is then used for computing the features v(I) and messages G by applying the convolutions only on the pixels not yet classiﬁed. [sent-159, score-0.214]
</p><p>89 In this desk scene, it is easy to identify objects like the screen, keyboard and mouse, even though the local information is sometimes insufﬁcient. [sent-163, score-0.32]
</p><p>90 Middle: the evolution of the beliefs (b and F and G) during detection for a test image. [sent-164, score-0.27]
</p><p>91 The graph bellow shows the average evolution of the area under the ROC for the three objects on 120 test images. [sent-166, score-0.174]
</p><p>92 6 we compare the reduction of the search space when implementing a cascade using independent boosting (which reduces to Viola and Jones [12]), and when using BRF’s. [sent-169, score-0.394]
</p><p>93 We see that for objects for which context is the main source of information, like the mouse, the reduction in search space is much more dramatic using BRFs than using boosting alone. [sent-170, score-0.389]
</p><p>94 4  Conclusion  The proposed BRF algorithm combines boosting and CRF’s, providing an algorithm that is easy for both training and inference. [sent-171, score-0.303]
</p><p>95 We have demonstrated object detection in cluttered scenes by exploiting contextual relationships between objects. [sent-172, score-0.328]
</p><p>96 The BRF algorithm is computationally efﬁcient and provides a natural extension of the cascade of classiﬁers by integrating evidence from other objects in order to quickly reject certain image regions. [sent-173, score-0.271]
</p><p>97 The BRF’s densely connected graphs, which efﬁciently collect information over large image regions, provide an alternative framework to nearest-neighbor grids for vision problems. [sent-174, score-0.206]
</p><p>98 5  False alarm rate  1  Figure 6: Contextual information reduces the search space in the framework of a cascade and improves performances. [sent-183, score-0.171]
</p><p>99 Discriminative random ﬁelds: A discriminative framework for contextual interaction in classiﬁcation. [sent-229, score-0.124]
</p><p>100 Using the forest to see the trees: a graphical model relating features, objects and scenes. [sent-244, score-0.087]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('bt', 0.389), ('brf', 0.374), ('boosting', 0.273), ('gt', 0.264), ('mouse', 0.198), ('sk', 0.189), ('fit', 0.185), ('keyboard', 0.182), ('beliefs', 0.165), ('road', 0.138), ('car', 0.137), ('brfs', 0.125), ('screen', 0.124), ('contextual', 0.124), ('gi', 0.11), ('weak', 0.104), ('stuff', 0.099), ('potentials', 0.098), ('compatibility', 0.097), ('object', 0.093), ('round', 0.092), ('ni', 0.088), ('objects', 0.087), ('compatibilities', 0.083), ('jit', 0.083), ('fragments', 0.083), ('detection', 0.076), ('densely', 0.073), ('dictionary', 0.073), ('image', 0.071), ('mask', 0.069), ('messages', 0.067), ('labeling', 0.066), ('segmentation', 0.066), ('cascade', 0.063), ('fi', 0.062), ('buildings', 0.062), ('message', 0.061), ('graph', 0.058), ('learner', 0.058), ('elds', 0.057), ('learners', 0.057), ('building', 0.057), ('detect', 0.057), ('connections', 0.057), ('patches', 0.056), ('street', 0.055), ('local', 0.051), ('boosted', 0.051), ('node', 0.051), ('evidence', 0.05), ('alarm', 0.05), ('torralba', 0.05), ('pixels', 0.047), ('iteration', 0.047), ('si', 0.046), ('cars', 0.046), ('update', 0.044), ('stagewise', 0.042), ('things', 0.041), ('crfs', 0.041), ('crf', 0.041), ('murphy', 0.041), ('incoming', 0.041), ('bc', 0.04), ('rounds', 0.037), ('fink', 0.036), ('wc', 0.036), ('ce', 0.035), ('scenes', 0.035), ('vision', 0.034), ('stump', 0.033), ('evidences', 0.033), ('sends', 0.033), ('pixel', 0.033), ('multiclass', 0.032), ('additive', 0.032), ('thresholding', 0.031), ('sliding', 0.031), ('roads', 0.031), ('convolutions', 0.031), ('csail', 0.031), ('training', 0.03), ('xm', 0.03), ('evolution', 0.029), ('rejection', 0.029), ('masks', 0.029), ('search', 0.029), ('reduces', 0.029), ('connected', 0.028), ('graphs', 0.028), ('belief', 0.028), ('nodes', 0.028), ('runtime', 0.028), ('seeing', 0.028), ('irregular', 0.028), ('output', 0.027), ('recognizing', 0.026), ('conditional', 0.026), ('images', 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999958 <a title="47-tfidf-1" href="./nips-2004-Contextual_Models_for_Object_Detection_Using_Boosted_Random_Fields.html">47 nips-2004-Contextual Models for Object Detection Using Boosted Random Fields</a></p>
<p>Author: Antonio Torralba, Kevin P. Murphy, William T. Freeman</p><p>Abstract: We seek to both detect and segment objects in images. To exploit both local image data as well as contextual information, we introduce Boosted Random Fields (BRFs), which uses Boosting to learn the graph structure and local evidence of a conditional random ﬁeld (CRF). The graph structure is learned by assembling graph fragments in an additive model. The connections between individual pixels are not very informative, but by using dense graphs, we can pool information from large regions of the image; dense models also support efﬁcient inference. We show how contextual information from other objects can improve detection performance, both in terms of accuracy and speed, by using a computational cascade. We apply our system to detect stuff and things in ofﬁce and street scenes. 1</p><p>2 0.15837646 <a title="47-tfidf-2" href="./nips-2004-An_Application_of_Boosting_to_Graph_Classification.html">19 nips-2004-An Application of Boosting to Graph Classification</a></p>
<p>Author: Taku Kudo, Eisaku Maeda, Yuji Matsumoto</p><p>Abstract: This paper presents an application of Boosting for classifying labeled graphs, general structures for modeling a number of real-world data, such as chemical compounds, natural language texts, and bio sequences. The proposal consists of i) decision stumps that use subgraph as features, and ii) a Boosting algorithm in which subgraph-based decision stumps are used as weak learners. We also discuss the relation between our algorithm and SVMs with convolution kernels. Two experiments using natural language data and chemical compounds show that our method achieves comparable or even better performance than SVMs with convolution kernels as well as improves the testing efﬁciency. 1</p><p>3 0.15343969 <a title="47-tfidf-3" href="./nips-2004-Conditional_Random_Fields_for_Object_Recognition.html">44 nips-2004-Conditional Random Fields for Object Recognition</a></p>
<p>Author: Ariadna Quattoni, Michael Collins, Trevor Darrell</p><p>Abstract: We present a discriminative part-based approach for the recognition of object classes from unsegmented cluttered scenes. Objects are modeled as ﬂexible constellations of parts conditioned on local observations found by an interest operator. For each object class the probability of a given assignment of parts to local features is modeled by a Conditional Random Field (CRF). We propose an extension of the CRF framework that incorporates hidden variables and combines class conditional CRFs into a uniﬁed framework for part-based object recognition. The parameters of the CRF are estimated in a maximum likelihood framework and recognition proceeds by ﬁnding the most likely class under our model. The main advantage of the proposed CRF framework is that it allows us to relax the assumption of conditional independence of the observed data (i.e. local features) often used in generative approaches, an assumption that might be too restrictive for a considerable number of object classes.</p><p>4 0.131589 <a title="47-tfidf-4" href="./nips-2004-Optimal_Aggregation_of_Classifiers_and_Boosting_Maps_in_Functional_Magnetic_Resonance_Imaging.html">139 nips-2004-Optimal Aggregation of Classifiers and Boosting Maps in Functional Magnetic Resonance Imaging</a></p>
<p>Author: Vladimir Koltchinskii, Manel Martínez-ramón, Stefan Posse</p><p>Abstract: We study a method of optimal data-driven aggregation of classiﬁers in a convex combination and establish tight upper bounds on its excess risk with respect to a convex loss function under the assumption that the solution of optimal aggregation problem is sparse. We use a boosting type algorithm of optimal aggregation to develop aggregate classiﬁers of activation patterns in fMRI based on locally trained SVM classiﬁers. The aggregation coefﬁcients are then used to design a ”boosting map” of the brain needed to identify the regions with most signiﬁcant impact on classiﬁcation. 1</p><p>5 0.11402566 <a title="47-tfidf-5" href="./nips-2004-The_Power_of_Selective_Memory%3A_Self-Bounded_Learning_of_Prediction_Suffix_Trees.html">189 nips-2004-The Power of Selective Memory: Self-Bounded Learning of Prediction Suffix Trees</a></p>
<p>Author: Ofer Dekel, Shai Shalev-shwartz, Yoram Singer</p><p>Abstract: Prediction sufﬁx trees (PST) provide a popular and effective tool for tasks such as compression, classiﬁcation, and language modeling. In this paper we take a decision theoretic view of PSTs for the task of sequence prediction. Generalizing the notion of margin to PSTs, we present an online PST learning algorithm and derive a loss bound for it. The depth of the PST generated by this algorithm scales linearly with the length of the input. We then describe a self-bounded enhancement of our learning algorithm which automatically grows a bounded-depth PST. We also prove an analogous mistake-bound for the self-bounded algorithm. The result is an efﬁcient algorithm that neither relies on a-priori assumptions on the shape or maximal depth of the target PST nor does it require any parameters. To our knowledge, this is the ﬁrst provably-correct PST learning algorithm which generates a bounded-depth PST while being competitive with any ﬁxed PST determined in hindsight. 1</p><p>6 0.10153089 <a title="47-tfidf-6" href="./nips-2004-Common-Frame_Model_for_Object_Recognition.html">40 nips-2004-Common-Frame Model for Object Recognition</a></p>
<p>7 0.095219523 <a title="47-tfidf-7" href="./nips-2004-The_power_of_feature_clustering%3A_An_application_to_object_detection.html">192 nips-2004-The power of feature clustering: An application to object detection</a></p>
<p>8 0.09013769 <a title="47-tfidf-8" href="./nips-2004-Message_Errors_in_Belief_Propagation.html">116 nips-2004-Message Errors in Belief Propagation</a></p>
<p>9 0.087970771 <a title="47-tfidf-9" href="./nips-2004-Joint_Tracking_of_Pose%2C_Expression%2C_and_Texture_using_Conditionally_Gaussian_Filters.html">91 nips-2004-Joint Tracking of Pose, Expression, and Texture using Conditionally Gaussian Filters</a></p>
<p>10 0.084004 <a title="47-tfidf-10" href="./nips-2004-Generative_Affine_Localisation_and_Tracking.html">73 nips-2004-Generative Affine Localisation and Tracking</a></p>
<p>11 0.083603971 <a title="47-tfidf-11" href="./nips-2004-Learning_Hyper-Features_for_Visual_Identification.html">99 nips-2004-Learning Hyper-Features for Visual Identification</a></p>
<p>12 0.074542709 <a title="47-tfidf-12" href="./nips-2004-Semi-Markov_Conditional_Random_Fields_for_Information_Extraction.html">162 nips-2004-Semi-Markov Conditional Random Fields for Information Extraction</a></p>
<p>13 0.071899302 <a title="47-tfidf-13" href="./nips-2004-Bayesian_inference_in_spiking_neurons.html">28 nips-2004-Bayesian inference in spiking neurons</a></p>
<p>14 0.066402353 <a title="47-tfidf-14" href="./nips-2004-Object_Classification_from_a_Single_Example_Utilizing_Class_Relevance_Metrics.html">134 nips-2004-Object Classification from a Single Example Utilizing Class Relevance Metrics</a></p>
<p>15 0.063076094 <a title="47-tfidf-15" href="./nips-2004-Face_Detection_---_Efficient_and_Rank_Deficient.html">68 nips-2004-Face Detection --- Efficient and Rank Deficient</a></p>
<p>16 0.059892934 <a title="47-tfidf-16" href="./nips-2004-Matrix_Exponential_Gradient_Updates_for_On-line_Learning_and_Bregman_Projection.html">110 nips-2004-Matrix Exponential Gradient Updates for On-line Learning and Bregman Projection</a></p>
<p>17 0.059454713 <a title="47-tfidf-17" href="./nips-2004-Boosting_on_Manifolds%3A_Adaptive_Regularization_of_Base_Classifiers.html">32 nips-2004-Boosting on Manifolds: Adaptive Regularization of Base Classifiers</a></p>
<p>18 0.058843225 <a title="47-tfidf-18" href="./nips-2004-Learning_Preferences_for_Multiclass_Problems.html">100 nips-2004-Learning Preferences for Multiclass Problems</a></p>
<p>19 0.057677485 <a title="47-tfidf-19" href="./nips-2004-Joint_MRI_Bias_Removal_Using_Entropy_Minimization_Across_Images.html">89 nips-2004-Joint MRI Bias Removal Using Entropy Minimization Across Images</a></p>
<p>20 0.057534866 <a title="47-tfidf-20" href="./nips-2004-Parallel_Support_Vector_Machines%3A_The_Cascade_SVM.html">144 nips-2004-Parallel Support Vector Machines: The Cascade SVM</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2004_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.186), (1, 0.023), (2, 0.005), (3, -0.076), (4, 0.206), (5, 0.03), (6, 0.11), (7, -0.006), (8, -0.127), (9, -0.0), (10, -0.115), (11, -0.096), (12, 0.021), (13, 0.06), (14, -0.004), (15, -0.061), (16, 0.107), (17, 0.048), (18, 0.129), (19, 0.025), (20, 0.134), (21, -0.071), (22, -0.051), (23, 0.055), (24, -0.037), (25, 0.063), (26, 0.036), (27, -0.083), (28, -0.064), (29, -0.116), (30, 0.042), (31, -0.058), (32, 0.005), (33, -0.142), (34, -0.083), (35, 0.067), (36, 0.0), (37, -0.169), (38, -0.039), (39, -0.032), (40, -0.023), (41, 0.108), (42, -0.095), (43, -0.081), (44, 0.084), (45, 0.036), (46, 0.098), (47, -0.105), (48, 0.19), (49, -0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96197259 <a title="47-lsi-1" href="./nips-2004-Contextual_Models_for_Object_Detection_Using_Boosted_Random_Fields.html">47 nips-2004-Contextual Models for Object Detection Using Boosted Random Fields</a></p>
<p>Author: Antonio Torralba, Kevin P. Murphy, William T. Freeman</p><p>Abstract: We seek to both detect and segment objects in images. To exploit both local image data as well as contextual information, we introduce Boosted Random Fields (BRFs), which uses Boosting to learn the graph structure and local evidence of a conditional random ﬁeld (CRF). The graph structure is learned by assembling graph fragments in an additive model. The connections between individual pixels are not very informative, but by using dense graphs, we can pool information from large regions of the image; dense models also support efﬁcient inference. We show how contextual information from other objects can improve detection performance, both in terms of accuracy and speed, by using a computational cascade. We apply our system to detect stuff and things in ofﬁce and street scenes. 1</p><p>2 0.53080606 <a title="47-lsi-2" href="./nips-2004-An_Application_of_Boosting_to_Graph_Classification.html">19 nips-2004-An Application of Boosting to Graph Classification</a></p>
<p>Author: Taku Kudo, Eisaku Maeda, Yuji Matsumoto</p><p>Abstract: This paper presents an application of Boosting for classifying labeled graphs, general structures for modeling a number of real-world data, such as chemical compounds, natural language texts, and bio sequences. The proposal consists of i) decision stumps that use subgraph as features, and ii) a Boosting algorithm in which subgraph-based decision stumps are used as weak learners. We also discuss the relation between our algorithm and SVMs with convolution kernels. Two experiments using natural language data and chemical compounds show that our method achieves comparable or even better performance than SVMs with convolution kernels as well as improves the testing efﬁciency. 1</p><p>3 0.48205718 <a title="47-lsi-3" href="./nips-2004-Optimal_Aggregation_of_Classifiers_and_Boosting_Maps_in_Functional_Magnetic_Resonance_Imaging.html">139 nips-2004-Optimal Aggregation of Classifiers and Boosting Maps in Functional Magnetic Resonance Imaging</a></p>
<p>Author: Vladimir Koltchinskii, Manel Martínez-ramón, Stefan Posse</p><p>Abstract: We study a method of optimal data-driven aggregation of classiﬁers in a convex combination and establish tight upper bounds on its excess risk with respect to a convex loss function under the assumption that the solution of optimal aggregation problem is sparse. We use a boosting type algorithm of optimal aggregation to develop aggregate classiﬁers of activation patterns in fMRI based on locally trained SVM classiﬁers. The aggregation coefﬁcients are then used to design a ”boosting map” of the brain needed to identify the regions with most signiﬁcant impact on classiﬁcation. 1</p><p>4 0.47979486 <a title="47-lsi-4" href="./nips-2004-Conditional_Random_Fields_for_Object_Recognition.html">44 nips-2004-Conditional Random Fields for Object Recognition</a></p>
<p>Author: Ariadna Quattoni, Michael Collins, Trevor Darrell</p><p>Abstract: We present a discriminative part-based approach for the recognition of object classes from unsegmented cluttered scenes. Objects are modeled as ﬂexible constellations of parts conditioned on local observations found by an interest operator. For each object class the probability of a given assignment of parts to local features is modeled by a Conditional Random Field (CRF). We propose an extension of the CRF framework that incorporates hidden variables and combines class conditional CRFs into a uniﬁed framework for part-based object recognition. The parameters of the CRF are estimated in a maximum likelihood framework and recognition proceeds by ﬁnding the most likely class under our model. The main advantage of the proposed CRF framework is that it allows us to relax the assumption of conditional independence of the observed data (i.e. local features) often used in generative approaches, an assumption that might be too restrictive for a considerable number of object classes.</p><p>5 0.46915734 <a title="47-lsi-5" href="./nips-2004-Common-Frame_Model_for_Object_Recognition.html">40 nips-2004-Common-Frame Model for Object Recognition</a></p>
<p>Author: Pierre Moreels, Pietro Perona</p><p>Abstract: A generative probabilistic model for objects in images is presented. An object consists of a constellation of features. Feature appearance and pose are modeled probabilistically. Scene images are generated by drawing a set of objects from a given database, with random clutter sprinkled on the remaining image surface. Occlusion is allowed. We study the case where features from the same object share a common reference frame. Moreover, parameters for shape and appearance densities are shared across features. This is to be contrasted with previous work on probabilistic ‘constellation’ models where features depend on each other, and each feature and model have different pose and appearance statistics [1, 2]. These two differences allow us to build models containing hundreds of features, as well as to train each model from a single example. Our model may also be thought of as a probabilistic revisitation of Lowe’s model [3, 4]. We propose an efﬁcient entropy-minimization inference algorithm that constructs the best interpretation of a scene as a collection of objects and clutter. We test our ideas with experiments on two image databases. We compare with Lowe’s algorithm and demonstrate better performance, in particular in presence of large amounts of background clutter.</p><p>6 0.45490673 <a title="47-lsi-6" href="./nips-2004-The_power_of_feature_clustering%3A_An_application_to_object_detection.html">192 nips-2004-The power of feature clustering: An application to object detection</a></p>
<p>7 0.40314516 <a title="47-lsi-7" href="./nips-2004-Learning_Hyper-Features_for_Visual_Identification.html">99 nips-2004-Learning Hyper-Features for Visual Identification</a></p>
<p>8 0.35715672 <a title="47-lsi-8" href="./nips-2004-Semi-Markov_Conditional_Random_Fields_for_Information_Extraction.html">162 nips-2004-Semi-Markov Conditional Random Fields for Information Extraction</a></p>
<p>9 0.35565099 <a title="47-lsi-9" href="./nips-2004-Joint_Tracking_of_Pose%2C_Expression%2C_and_Texture_using_Conditionally_Gaussian_Filters.html">91 nips-2004-Joint Tracking of Pose, Expression, and Texture using Conditionally Gaussian Filters</a></p>
<p>10 0.3467108 <a title="47-lsi-10" href="./nips-2004-Optimal_sub-graphical_models.html">141 nips-2004-Optimal sub-graphical models</a></p>
<p>11 0.34467849 <a title="47-lsi-11" href="./nips-2004-Generative_Affine_Localisation_and_Tracking.html">73 nips-2004-Generative Affine Localisation and Tracking</a></p>
<p>12 0.33818278 <a title="47-lsi-12" href="./nips-2004-Message_Errors_in_Belief_Propagation.html">116 nips-2004-Message Errors in Belief Propagation</a></p>
<p>13 0.33738664 <a title="47-lsi-13" href="./nips-2004-The_Variational_Ising_Classifier_%28VIC%29_Algorithm_for_Coherently_Contaminated_Data.html">191 nips-2004-The Variational Ising Classifier (VIC) Algorithm for Coherently Contaminated Data</a></p>
<p>14 0.33686247 <a title="47-lsi-14" href="./nips-2004-Efficient_Out-of-Sample_Extension_of_Dominant-Set_Clusters.html">61 nips-2004-Efficient Out-of-Sample Extension of Dominant-Set Clusters</a></p>
<p>15 0.33125073 <a title="47-lsi-15" href="./nips-2004-Joint_MRI_Bias_Removal_Using_Entropy_Minimization_Across_Images.html">89 nips-2004-Joint MRI Bias Removal Using Entropy Minimization Across Images</a></p>
<p>16 0.32412514 <a title="47-lsi-16" href="./nips-2004-Using_Machine_Learning_to_Break_Visual_Human_Interaction_Proofs_%28HIPs%29.html">199 nips-2004-Using Machine Learning to Break Visual Human Interaction Proofs (HIPs)</a></p>
<p>17 0.31361866 <a title="47-lsi-17" href="./nips-2004-Synergistic_Face_Detection_and_Pose_Estimation_with_Energy-Based_Models.html">182 nips-2004-Synergistic Face Detection and Pose Estimation with Energy-Based Models</a></p>
<p>18 0.28926891 <a title="47-lsi-18" href="./nips-2004-%E2%84%93%E2%82%80-norm_Minimization_for_Basis_Selection.html">207 nips-2004-ℓ₀-norm Minimization for Basis Selection</a></p>
<p>19 0.28847766 <a title="47-lsi-19" href="./nips-2004-Face_Detection_---_Efficient_and_Rank_Deficient.html">68 nips-2004-Face Detection --- Efficient and Rank Deficient</a></p>
<p>20 0.28533676 <a title="47-lsi-20" href="./nips-2004-Assignment_of_Multiplicative_Mixtures_in_Natural_Images.html">25 nips-2004-Assignment of Multiplicative Mixtures in Natural Images</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2004_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.072), (15, 0.139), (17, 0.035), (21, 0.019), (26, 0.046), (31, 0.018), (33, 0.187), (35, 0.022), (50, 0.026), (53, 0.02), (56, 0.014), (67, 0.276), (87, 0.014), (88, 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.86806661 <a title="47-lda-1" href="./nips-2004-Using_Random_Forests_in_the_Structured_Language_Model.html">200 nips-2004-Using Random Forests in the Structured Language Model</a></p>
<p>Author: Peng Xu, Frederick Jelinek</p><p>Abstract: In this paper, we explore the use of Random Forests (RFs) in the structured language model (SLM), which uses rich syntactic information in predicting the next word based on words already seen. The goal in this work is to construct RFs by randomly growing Decision Trees (DTs) using syntactic information and investigate the performance of the SLM modeled by the RFs in automatic speech recognition. RFs, which were originally developed as classiﬁers, are a combination of decision tree classiﬁers. Each tree is grown based on random training data sampled independently and with the same distribution for all trees in the forest, and a random selection of possible questions at each node of the decision tree. Our approach extends the original idea of RFs to deal with the data sparseness problem encountered in language modeling. RFs have been studied in the context of n-gram language modeling and have been shown to generalize well to unseen data. We show in this paper that RFs using syntactic information can also achieve better performance in both perplexity (PPL) and word error rate (WER) in a large vocabulary speech recognition system, compared to a baseline that uses Kneser-Ney smoothing. 1</p><p>same-paper 2 0.82737601 <a title="47-lda-2" href="./nips-2004-Contextual_Models_for_Object_Detection_Using_Boosted_Random_Fields.html">47 nips-2004-Contextual Models for Object Detection Using Boosted Random Fields</a></p>
<p>Author: Antonio Torralba, Kevin P. Murphy, William T. Freeman</p><p>Abstract: We seek to both detect and segment objects in images. To exploit both local image data as well as contextual information, we introduce Boosted Random Fields (BRFs), which uses Boosting to learn the graph structure and local evidence of a conditional random ﬁeld (CRF). The graph structure is learned by assembling graph fragments in an additive model. The connections between individual pixels are not very informative, but by using dense graphs, we can pool information from large regions of the image; dense models also support efﬁcient inference. We show how contextual information from other objects can improve detection performance, both in terms of accuracy and speed, by using a computational cascade. We apply our system to detect stuff and things in ofﬁce and street scenes. 1</p><p>3 0.66003221 <a title="47-lda-3" href="./nips-2004-Newscast_EM.html">130 nips-2004-Newscast EM</a></p>
<p>Author: Wojtek Kowalczyk, Nikos A. Vlassis</p><p>Abstract: We propose a gossip-based distributed algorithm for Gaussian mixture learning, Newscast EM. The algorithm operates on network topologies where each node observes a local quantity and can communicate with other nodes in an arbitrary point-to-point fashion. The main difference between Newscast EM and the standard EM algorithm is that the M-step in our case is implemented in a decentralized manner: (random) pairs of nodes repeatedly exchange their local parameter estimates and combine them by (weighted) averaging. We provide theoretical evidence and demonstrate experimentally that, under this protocol, nodes converge exponentially fast to the correct estimates in each M-step of the EM algorithm. 1</p><p>4 0.65769821 <a title="47-lda-4" href="./nips-2004-Semi-supervised_Learning_with_Penalized_Probabilistic_Clustering.html">167 nips-2004-Semi-supervised Learning with Penalized Probabilistic Clustering</a></p>
<p>Author: Zhengdong Lu, Todd K. Leen</p><p>Abstract: While clustering is usually an unsupervised operation, there are circumstances in which we believe (with varying degrees of certainty) that items A and B should be assigned to the same cluster, while items A and C should not. We would like such pairwise relations to inﬂuence cluster assignments of out-of-sample data in a manner consistent with the prior knowledge expressed in the training set. Our starting point is probabilistic clustering based on Gaussian mixture models (GMM) of the data distribution. We express clustering preferences in the prior distribution over assignments of data points to clusters. This prior penalizes cluster assignments according to the degree with which they violate the preferences. We ﬁt the model parameters with EM. Experiments on a variety of data sets show that PPC can consistently improve clustering results.</p><p>5 0.65748018 <a title="47-lda-5" href="./nips-2004-Nonparametric_Transforms_of_Graph_Kernels_for_Semi-Supervised_Learning.html">133 nips-2004-Nonparametric Transforms of Graph Kernels for Semi-Supervised Learning</a></p>
<p>Author: Xiaojin Zhu, Jaz Kandola, Zoubin Ghahramani, John D. Lafferty</p><p>Abstract: We present an algorithm based on convex optimization for constructing kernels for semi-supervised learning. The kernel matrices are derived from the spectral decomposition of graph Laplacians, and combine labeled and unlabeled data in a systematic fashion. Unlike previous work using diffusion kernels and Gaussian random ﬁeld kernels, a nonparametric kernel approach is presented that incorporates order constraints during optimization. This results in ﬂexible kernels and avoids the need to choose among different parametric forms. Our approach relies on a quadratically constrained quadratic program (QCQP), and is computationally feasible for large datasets. We evaluate the kernels on real datasets using support vector machines, with encouraging results. 1</p><p>6 0.65696275 <a title="47-lda-6" href="./nips-2004-Blind_One-microphone_Speech_Separation%3A_A_Spectral_Learning_Approach.html">31 nips-2004-Blind One-microphone Speech Separation: A Spectral Learning Approach</a></p>
<p>7 0.65659082 <a title="47-lda-7" href="./nips-2004-Learning_Hyper-Features_for_Visual_Identification.html">99 nips-2004-Learning Hyper-Features for Visual Identification</a></p>
<p>8 0.6557914 <a title="47-lda-8" href="./nips-2004-Face_Detection_---_Efficient_and_Rank_Deficient.html">68 nips-2004-Face Detection --- Efficient and Rank Deficient</a></p>
<p>9 0.65487289 <a title="47-lda-9" href="./nips-2004-Self-Tuning_Spectral_Clustering.html">161 nips-2004-Self-Tuning Spectral Clustering</a></p>
<p>10 0.6542964 <a title="47-lda-10" href="./nips-2004-Support_Vector_Classification_with_Input_Data_Uncertainty.html">178 nips-2004-Support Vector Classification with Input Data Uncertainty</a></p>
<p>11 0.65404481 <a title="47-lda-11" href="./nips-2004-Efficient_Out-of-Sample_Extension_of_Dominant-Set_Clusters.html">61 nips-2004-Efficient Out-of-Sample Extension of Dominant-Set Clusters</a></p>
<p>12 0.65323818 <a title="47-lda-12" href="./nips-2004-The_Power_of_Selective_Memory%3A_Self-Bounded_Learning_of_Prediction_Suffix_Trees.html">189 nips-2004-The Power of Selective Memory: Self-Bounded Learning of Prediction Suffix Trees</a></p>
<p>13 0.653198 <a title="47-lda-13" href="./nips-2004-Adaptive_Discriminative_Generative_Model_and_Its_Applications.html">16 nips-2004-Adaptive Discriminative Generative Model and Its Applications</a></p>
<p>14 0.65314358 <a title="47-lda-14" href="./nips-2004-Hierarchical_Clustering_of_a_Mixture_Model.html">77 nips-2004-Hierarchical Clustering of a Mixture Model</a></p>
<p>15 0.65244377 <a title="47-lda-15" href="./nips-2004-Surface_Reconstruction_using_Learned_Shape_Models.html">179 nips-2004-Surface Reconstruction using Learned Shape Models</a></p>
<p>16 0.65230221 <a title="47-lda-16" href="./nips-2004-Neighbourhood_Components_Analysis.html">127 nips-2004-Neighbourhood Components Analysis</a></p>
<p>17 0.65171969 <a title="47-lda-17" href="./nips-2004-Assignment_of_Multiplicative_Mixtures_in_Natural_Images.html">25 nips-2004-Assignment of Multiplicative Mixtures in Natural Images</a></p>
<p>18 0.6515739 <a title="47-lda-18" href="./nips-2004-Spike_Sorting%3A_Bayesian_Clustering_of_Non-Stationary_Data.html">174 nips-2004-Spike Sorting: Bayesian Clustering of Non-Stationary Data</a></p>
<p>19 0.65144545 <a title="47-lda-19" href="./nips-2004-Discriminant_Saliency_for_Visual_Recognition_from_Cluttered_Scenes.html">53 nips-2004-Discriminant Saliency for Visual Recognition from Cluttered Scenes</a></p>
<p>20 0.65122211 <a title="47-lda-20" href="./nips-2004-Synergistic_Face_Detection_and_Pose_Estimation_with_Energy-Based_Models.html">182 nips-2004-Synergistic Face Detection and Pose Estimation with Energy-Based Models</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
