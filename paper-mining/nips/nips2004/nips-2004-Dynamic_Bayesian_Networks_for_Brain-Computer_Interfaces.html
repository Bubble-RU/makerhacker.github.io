<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>56 nips-2004-Dynamic Bayesian Networks for Brain-Computer Interfaces</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2004" href="../home/nips2004_home.html">nips2004</a> <a title="nips-2004-56" href="#">nips2004-56</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>56 nips-2004-Dynamic Bayesian Networks for Brain-Computer Interfaces</h1>
<br/><p>Source: <a title="nips-2004-56-pdf" href="http://papers.nips.cc/paper/2664-dynamic-bayesian-networks-for-brain-computer-interfaces.pdf">pdf</a></p><p>Author: Pradeep Shenoy, Rajesh P. Rao</p><p>Abstract: We describe an approach to building brain-computer interfaces (BCI) based on graphical models for probabilistic inference and learning. We show how a dynamic Bayesian network (DBN) can be used to infer probability distributions over brain- and body-states during planning and execution of actions. The DBN is learned directly from observed data and allows measured signals such as EEG and EMG to be interpreted in terms of internal states such as intent to move, preparatory activity, and movement execution. Unlike traditional classiﬁcation-based approaches to BCI, the proposed approach (1) allows continuous tracking and prediction of internal states over time, and (2) generates control signals based on an entire probability distribution over states rather than binary yes/no decisions. We present preliminary results of brain- and body-state estimation using simultaneous EEG and EMG signals recorded during a self-paced left/right hand movement task. 1</p><p>Reference: <a title="nips-2004-56-reference" href="../nips2004_reference/nips-2004-Dynamic_Bayesian_Networks_for_Brain-Computer_Interfaces_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract We describe an approach to building brain-computer interfaces (BCI) based on graphical models for probabilistic inference and learning. [sent-7, score-0.128]
</p><p>2 We show how a dynamic Bayesian network (DBN) can be used to infer probability distributions over brain- and body-states during planning and execution of actions. [sent-8, score-0.058]
</p><p>3 The DBN is learned directly from observed data and allows measured signals such as EEG and EMG to be interpreted in terms of internal states such as intent to move, preparatory activity, and movement execution. [sent-9, score-0.523]
</p><p>4 Unlike traditional classiﬁcation-based approaches to BCI, the proposed approach (1) allows continuous tracking and prediction of internal states over time, and (2) generates control signals based on an entire probability distribution over states rather than binary yes/no decisions. [sent-10, score-0.315]
</p><p>5 We present preliminary results of brain- and body-state estimation using simultaneous EEG and EMG signals recorded during a self-paced left/right hand movement task. [sent-11, score-0.372]
</p><p>6 Several researchers have demonstrated the feasibility of using EEG signals as a non-invasive medium for building human BCIs [1, 2, 3, 4, 5] (see also [6] and articles in the same issue). [sent-13, score-0.084]
</p><p>7 A central theme in much of this research is the postulation of a discrete brain state that the user maintains while performing one of a set of physical or imagined actions. [sent-14, score-0.319]
</p><p>8 The goal is to decode the hidden brain state from the observable EEG signal, and to use the decoded state to control a robot or a cursor on a computer screen. [sent-15, score-0.577]
</p><p>9 , [1, 2, 4]) have utilized classiﬁcation methods applied to time slices of EEG data to discriminate between a small set of brain states (e. [sent-18, score-0.359]
</p><p>10 These methods typically involve various forms of preprocessing (such as band-pass ﬁltering or temporal smoothing) as well as feature extraction on time slices known to contain one of the chosen set of brain states. [sent-21, score-0.234]
</p><p>11 As a result, it  is difﬁcult to have a continuous estimate of the brain state and to associate an uncertainty with the current estimate. [sent-27, score-0.319]
</p><p>12 In this paper, we propose a new framework for BCI based on probabilistic graphical models [7] that overcomes some of the limitations of classiﬁcation-based approaches to BCI. [sent-28, score-0.057]
</p><p>13 We model the dynamics of hidden brain- and body-states using a Dynamic Bayesian Network (DBN) that is learned directly from EEG and EMG data. [sent-29, score-0.085]
</p><p>14 We show how a DBN can be used to infer probability distributions over hidden state variables, where the state variables correspond to brain states useful for BCI (such as “Intention to move left hand”, “Left hand in motion”, etc). [sent-30, score-0.75]
</p><p>15 Using a DBN gives us several advantages in addition to providing a continuous probabilistic estimate of brain state. [sent-31, score-0.171]
</p><p>16 First, it allows us to explicitly model the hidden causal structure and dependencies between different brain states. [sent-32, score-0.255]
</p><p>17 Second, it facilitates the integration of information from multiple modalities such as EEG and EMG signals, allowing, for example, EEG-derived estimates to be bootstrapped from EMG-derived estimates. [sent-33, score-0.05]
</p><p>18 In addition, learning a dynamic graphical model for time-varying data such as EEG allows other useful operations such as prediction, ﬁlling in of missing data, and smoothing of state estimates using information from future data points. [sent-34, score-0.261]
</p><p>19 These capabilities are difﬁcult to obtain while working exclusively in the frequency domain or using whole slices of the data (or its features) for training classiﬁers. [sent-35, score-0.082]
</p><p>20 We illustrate our approach in a simple Left versus Right hand movement task and present preliminary results showing supervised learning and Bayesian inference of hidden state for a dataset containing simultaneous EEG and EMG recordings. [sent-36, score-0.522]
</p><p>21 2  The DBN Framework  We study the problem of modeling spontaneous movement of the left/right arm using EEG and EMG signals. [sent-37, score-0.285]
</p><p>22 It is well known that EEG signals show a slow potential drift prior to spontaneous motor activity. [sent-38, score-0.168]
</p><p>23 In particular, the BP related to movement of left versus right arm shows a strong lateral asymmetry. [sent-40, score-0.377]
</p><p>24 This allows one to not only estimate the intent to move prior to actual movement, but also distinguish between left and right movements. [sent-41, score-0.195]
</p><p>25 Previous approaches [1, 2] have utilized BP signals in classiﬁcation-based BCI protocols based on synchronization cues that identify points of movement onset. [sent-42, score-0.324]
</p><p>26 In our case, the challenge was to model the structure of BPs and related movement signals using the states of the DBN, and to recognize actions without explicit synchronization cues. [sent-43, score-0.449]
</p><p>27 Figure 1 shows the complete DBN (referred to as Nf ull in this paper) used to model the leftright hand movement task. [sent-44, score-0.286]
</p><p>28 The hidden state Bt in Figure 1(a) tracks the higher-level brain state over time and generates the hidden EEG and EMG states Et and Mt respectively. [sent-45, score-0.721]
</p><p>29 These hidden states in turn generate the observed EEG and EMG signals. [sent-46, score-0.17]
</p><p>30 The dashed arrows indicate that the hidden states make transitions over time. [sent-47, score-0.231]
</p><p>31 As shown in Figure 1(b), the state Bt is intended to model the high-level intention of the subject. [sent-48, score-0.21]
</p><p>32 The ﬁgure shows both the values Bt can take as well the constraints on the transition between values. [sent-49, score-0.057]
</p><p>33 The actual probabilities of the allowed transitions are learned from data. [sent-50, score-0.103]
</p><p>34 The hidden states Et and Mt are intended to model the temporal structure of the EEG and EMG signals, which are generated using a mixture of Gaussians conditioned on E t and Mt respectively. [sent-51, score-0.191]
</p><p>35 In the same way as the values of Bt are customized for our particular experiment, we would like the state transitions of Et and Mt to also reﬂect their respective constraints. [sent-52, score-0.209]
</p><p>36 We use the models shown in Figure 2 for allowed transitions of the states M t and Et respectively. [sent-55, score-0.188]
</p><p>37 The dotted arrows represent transitions to a state at the next time step. [sent-57, score-0.209]
</p><p>38 (b) The transition graph for the brain state Bt . [sent-58, score-0.376]
</p><p>39 The probability of each allowed transition is learned from input data. [sent-59, score-0.099]
</p><p>40 of three chains of states (labeled (1), (2), and (3)), representing the rest state, a left-hand action and a right-hand action respectively. [sent-60, score-0.342]
</p><p>41 In each chain, the state Mt in each time step either retains its old value with a given probability (self-pointing arrow) or transitions to the next state value in that particular chain. [sent-61, score-0.357]
</p><p>42 The transition graph of Figure 2(b) shows similar constraints on the EEG, except that the left and right action chains are further partitioned into intent, action, and post-action subgroups of states, since each of these components are discernible from the BP in EEG (but not from EMG) signals. [sent-62, score-0.268]
</p><p>43 (a) The EMG state transitions between its values mi are constrained to be in one of three chains: the chains model (1) rest, (2) left arm movement, and (3) right arm movement. [sent-64, score-0.461]
</p><p>44 (b) In the EEG state transition graph, the left and right movement chains are further divided into state values encoding intent (LI/RI), movement (LM/RM), and post movement (LPM/RPM). [sent-65, score-1.239]
</p><p>45 1  Experiments and Results Data Collection and Processing  The task: The subject pressed two distinct keys on a keyboard with the left hand or right  hand at random at a self-initiated pace. [sent-67, score-0.18]
</p><p>46 We recorded 8 EEG channels around the motor area of cortex (C3, Cz, C4, FC1, FC2, CP1, CP2, Pz) using averaged ear electrodes as reference, and 2 differential pairs of EMG (one on each arm). [sent-68, score-0.193]
</p><p>47 Data was recorded at 2048Hz for a period of 20 minutes, with the movements being separated by approximately 3-4s. [sent-69, score-0.087]
</p><p>48 5  1  Figure 3: Movement-related potential drift recorded during the hand-movement task: The two plots show the EEG signals averaged over all trials from the motor-related channels C3 and C4 for left (left panel) and right hand movement (right panel). [sent-74, score-0.596]
</p><p>49 The EMG channels were converted to RMS values computed over windows for an effective sampling rate of 128Hz. [sent-78, score-0.09]
</p><p>50 Data Analysis: The recorded data were ﬁrst analyzed in the traditional manner by averaging across all trials. [sent-79, score-0.061]
</p><p>51 Figure 3 shows the average of EEG channels C3 and C4 for left and right hand movement actions respectively. [sent-80, score-0.468]
</p><p>52 As can be seen, the averages for both channels are different for the two classes. [sent-81, score-0.09]
</p><p>53 Furthermore, there is a slow potential drift preceding the action and a return to the baseline potential after the action is performed. [sent-82, score-0.2]
</p><p>54 Previous researchers [1] have classiﬁed EEG data over a window leading up to the instant of action with high accuracy (over 90%) into left or right movement classes. [sent-83, score-0.434]
</p><p>55 Thus, there appears to be a reliable amount of information in the EEG signal for at least discriminating between left versus right movements. [sent-84, score-0.159]
</p><p>56 Data Evaluation using SVMs: To obtain a baseline and to evaluate the quality of our recorded data, we tested the performance of linear support vector machines (SVMs) on classifying our EEG data into left and right movement classes. [sent-85, score-0.357]
</p><p>57 5 seconds before each movement were concatenated from all EEG channels and used for classiﬁcation. [sent-88, score-0.314]
</p><p>58 We performed hyper-parameter selection using leave-one-out crossvalidation on 15 minutes of data and obtained an error of 15% on the remaining 5 minutes of data. [sent-89, score-0.076]
</p><p>59 Such an error rate is comparable to those obtained in previous studies on similar tasks, suggesting that the recorded data contains sufﬁcient movement-related information to be tested in experiments involving DBNs. [sent-90, score-0.061]
</p><p>60 GMTK provides support for expressing constraints on state transitions (as described in Section 2). [sent-92, score-0.209]
</p><p>61 We constructed a supervisory signal from the recorded key-presses as follows: A period of  100ms around each keystroke was labeled “motor action” for the appropriate hand. [sent-94, score-0.203]
</p><p>62 This signal was used to train the network Nemg in a supervised manner. [sent-95, score-0.068]
</p><p>63 To generate a supervisory signal for the network Neeg , or the full combined network Nf ull (Figure 1), we added preﬁxes and postﬁxes of 150ms each to each action in this signal, and labeled them “preparatory” and “post-movement” activity respectively. [sent-96, score-0.325]
</p><p>64 Thus, we can use partial (EEG only) or full evidence in the inference step to obtain probability distributions over brain state. [sent-98, score-0.212]
</p><p>65 2  Learning and Inference with EMG  Our ﬁrst step is to learn the simpler model Nemg that has only the hidden Mt state and the observed EMG signal. [sent-101, score-0.212]
</p><p>66 This is to test inference using the EMG signal alone. [sent-102, score-0.087]
</p><p>67 We used 15 minutes of EMG data to train our simpliﬁed model, and then tested it on the remaining 5 minutes of data. [sent-104, score-0.076]
</p><p>68 In other words, the maximum a posteriori (MAP) sequence of values for hidden states was computed. [sent-106, score-0.17]
</p><p>69 Figure 4 shows a 100s slice of data containing 2 channels of EMG, and the predicted hidden EMG state Mt . [sent-107, score-0.324]
</p><p>70 The states 0, 1 and 2 correspond to “no action”, left, and right actions respectively. [sent-108, score-0.188]
</p><p>71 In the shown ﬁgure, the state Mt successfully captures not only all the obvious arm movements but also the actions that are obscured by noise. [sent-109, score-0.297]
</p><p>72 3  Learning the EEG Model  We used the supervisory signal described earlier to learn the corresponding EEG model Neeg . [sent-111, score-0.142]
</p><p>73 Note that the brain-state can be inferred from the hidden EEG state Et directly, since the state space is appropriately partitioned as shown in Figure 2(b). [sent-112, score-0.379]
</p><p>74 Figure 5 shows the result of inference on the learned model Neeg using only the EEG signals as evidence. [sent-113, score-0.125]
</p><p>75 The ﬁgure shows a subset of the EEG channels (C3,Cz,C4), the supervisory signal, and the predicted brain state Bt (the MAP estimate). [sent-114, score-0.527]
</p><p>76 The ﬁgure shows that many of the instances of action (but not all) are correctly identiﬁed by the model. [sent-115, score-0.079]
</p><p>77 Our model gives us at each time instant a MAP-estimated state sequence that best describes the past, and the probability associated with that state sequence. [sent-116, score-0.334]
</p><p>78 This gives us, at each time instant, a measure of how likely each brain state Bt is, with reference to the others. [sent-117, score-0.338]
</p><p>79 For convenience, we can use the probability associated with the REST state (see Figure 1) as reference. [sent-118, score-0.148]
</p><p>80 Figure 6 shows a graphical illustration of this instantaneous time estimate. [sent-119, score-0.082]
</p><p>81 The plotted graphs are, in order, the supervisory signal (i. [sent-120, score-0.142]
</p><p>82 , the “ground truth value”) and the instantaneous measures of likelihood of intention/movement/post-movement states for the left and right hand respectively. [sent-122, score-0.267]
</p><p>83 We see that the true hand movements are correctly inferred in a surprisingly large number of cases (log likelihood ratio crosses 0). [sent-124, score-0.089]
</p><p>84 In summary, our graphical models Nemg and Neeg have shown promising results in correctly identifying movement onset from EMG and EEG signals respectively. [sent-126, score-0.345]
</p><p>85 Ongoing work is focused on improving accuracy by using features extracted from EEG, and inference using both EEG and EMG in Nf ull (the full model). [sent-127, score-0.079]
</p><p>86 The states 0,1,2 correspond to “no action”, left, and right actions respectively. [sent-129, score-0.188]
</p><p>87 Our model correctly identiﬁes the obscured spikes in the noisy right EMG channel  4  Discussion and Conclusion  We have shown that dynamic Bayesian networks (DBNs) can be used to model the transitions between brain- and muscle-states as a subject performs a motor task. [sent-130, score-0.208]
</p><p>88 In particular, a two-level hierarchical network was proposed for simultaneously estimating higher-level brain state and lower-level EEG and EMG states in a left/right hand movement task. [sent-131, score-0.695]
</p><p>89 The results demonstrate that for a self-paced movement task, hidden brain states useful for BCI such as intention to move the left or right hand can be decoded from a DBN learned directly from EEG and EMG data. [sent-132, score-0.787]
</p><p>90 Previous work on BCIs can be grouped into two broad classes: self-regulatory BCIs and BCIs based on detecting brain state. [sent-133, score-0.171]
</p><p>91 Self-regulatory BCIs rely on training the user to regulate certain features of the EEG, such as cortical positivity [10], or oscillatory activity (the µ rhythm, see [5]), in order to control, for example, a cursor on a display. [sent-134, score-0.045]
</p><p>92 The approach presented in this paper falls in the second class of BCIs, those based on detecting brain states [1, 2, 3, 4]. [sent-135, score-0.277]
</p><p>93 However, rather than employing classiﬁcation methods, we use probabilistic graphical models for inferring brain state and learning the transition probabilities between brain states. [sent-136, score-0.604]
</p><p>94 Successfully learning a dynamic graphical model as suggested in this paper offers several advantages over traditional classiﬁcation-based schemes for BCI. [sent-137, score-0.093]
</p><p>95 It allows one to explicitly model the hidden causal structure and dependencies between different brain states. [sent-138, score-0.255]
</p><p>96 State 0 is the rest state, states 1 through 3 represent left hand movement, and 4 through 6 represent right hand movement (see Figure 1(b)). [sent-140, score-0.528]
</p><p>97 Our current efforts are focused on investigating methods for learning dynamic graphical models for motor tasks of varying complexity and using these models to build robust, probabilistic BCI systems. [sent-143, score-0.135]
</p><p>98 Improving transfer rates in brain computer interfacing: a case study. [sent-172, score-0.171]
</p><p>99 The measure shown is the log ratio of the instantaneous MAP estimate for the relevant state and the estimate for the rest state. [sent-184, score-0.211]
</p><p>100 The graphical models toolkit: An open source software system for speech and time-series processing. [sent-203, score-0.057]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('eeg', 0.572), ('emg', 0.552), ('dbn', 0.205), ('movement', 0.204), ('brain', 0.171), ('state', 0.148), ('mt', 0.13), ('bci', 0.125), ('states', 0.106), ('supervisory', 0.096), ('movt', 0.095), ('channels', 0.09), ('bt', 0.088), ('intent', 0.082), ('neeg', 0.079), ('action', 0.079), ('bcis', 0.075), ('hidden', 0.064), ('signals', 0.063), ('nemg', 0.063), ('slices', 0.063), ('transitions', 0.061), ('recorded', 0.061), ('arm', 0.06), ('post', 0.06), ('transition', 0.057), ('graphical', 0.057), ('left', 0.048), ('cz', 0.047), ('signal', 0.046), ('right', 0.044), ('hand', 0.044), ('motor', 0.042), ('drift', 0.042), ('intention', 0.041), ('inference', 0.041), ('chains', 0.04), ('chain', 0.039), ('instant', 0.038), ('rest', 0.038), ('actions', 0.038), ('minutes', 0.038), ('nf', 0.038), ('synchronization', 0.038), ('ull', 0.038), ('dynamic', 0.036), ('bp', 0.034), ('bereitschaftspotential', 0.032), ('eegt', 0.032), ('emgt', 0.032), ('engg', 0.032), ('gmtk', 0.032), ('mq', 0.032), ('rehab', 0.032), ('interfaces', 0.03), ('bayesian', 0.029), ('gure', 0.028), ('pre', 0.028), ('preparatory', 0.027), ('blankertz', 0.027), ('curio', 0.027), ('wolpaw', 0.027), ('et', 0.027), ('movements', 0.026), ('instantaneous', 0.025), ('toolkit', 0.025), ('obscured', 0.025), ('bootstrapped', 0.025), ('modalities', 0.025), ('mp', 0.023), ('cursor', 0.023), ('decoded', 0.023), ('predicted', 0.022), ('classi', 0.022), ('activity', 0.022), ('xes', 0.022), ('seattle', 0.022), ('network', 0.022), ('learned', 0.021), ('researchers', 0.021), ('versus', 0.021), ('allowed', 0.021), ('intended', 0.021), ('trans', 0.021), ('onset', 0.021), ('lling', 0.021), ('spontaneous', 0.021), ('move', 0.021), ('generates', 0.02), ('seconds', 0.02), ('causal', 0.02), ('rao', 0.02), ('smoothing', 0.02), ('internal', 0.02), ('svms', 0.019), ('inferred', 0.019), ('reference', 0.019), ('utilized', 0.019), ('wa', 0.019), ('exclusively', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999988 <a title="56-tfidf-1" href="./nips-2004-Dynamic_Bayesian_Networks_for_Brain-Computer_Interfaces.html">56 nips-2004-Dynamic Bayesian Networks for Brain-Computer Interfaces</a></p>
<p>Author: Pradeep Shenoy, Rajesh P. Rao</p><p>Abstract: We describe an approach to building brain-computer interfaces (BCI) based on graphical models for probabilistic inference and learning. We show how a dynamic Bayesian network (DBN) can be used to infer probability distributions over brain- and body-states during planning and execution of actions. The DBN is learned directly from observed data and allows measured signals such as EEG and EMG to be interpreted in terms of internal states such as intent to move, preparatory activity, and movement execution. Unlike traditional classiﬁcation-based approaches to BCI, the proposed approach (1) allows continuous tracking and prediction of internal states over time, and (2) generates control signals based on an entire probability distribution over states rather than binary yes/no decisions. We present preliminary results of brain- and body-state estimation using simultaneous EEG and EMG signals recorded during a self-paced left/right hand movement task. 1</p><p>2 0.24459934 <a title="56-tfidf-2" href="./nips-2004-An_Auditory_Paradigm_for_Brain-Computer_Interfaces.html">20 nips-2004-An Auditory Paradigm for Brain-Computer Interfaces</a></p>
<p>Author: N. J. Hill, Thomas N. Lal, Karin Bierig, Niels Birbaumer, Bernhard Schölkopf</p><p>Abstract: Motivated by the particular problems involved in communicating with “locked-in” paralysed patients, we aim to develop a braincomputer interface that uses auditory stimuli. We describe a paradigm that allows a user to make a binary decision by focusing attention on one of two concurrent auditory stimulus sequences. Using Support Vector Machine classiﬁcation and Recursive Channel Elimination on the independent components of averaged eventrelated potentials, we show that an untrained user’s EEG data can be classiﬁed with an encouragingly high level of accuracy. This suggests that it is possible for users to modulate EEG signals in a single trial by the conscious direction of attention, well enough to be useful in BCI. 1</p><p>3 0.22400904 <a title="56-tfidf-3" href="./nips-2004-Methods_Towards_Invasive_Human_Brain_Computer_Interfaces.html">117 nips-2004-Methods Towards Invasive Human Brain Computer Interfaces</a></p>
<p>Author: Thomas N. Lal, Thilo Hinterberger, Guido Widman, Michael Schröder, N. J. Hill, Wolfgang Rosenstiel, Christian E. Elger, Niels Birbaumer, Bernhard Schölkopf</p><p>Abstract: During the last ten years there has been growing interest in the development of Brain Computer Interfaces (BCIs). The ﬁeld has mainly been driven by the needs of completely paralyzed patients to communicate. With a few exceptions, most human BCIs are based on extracranial electroencephalography (EEG). However, reported bit rates are still low. One reason for this is the low signal-to-noise ratio of the EEG [16]. We are currently investigating if BCIs based on electrocorticography (ECoG) are a viable alternative. In this paper we present the method and examples of intracranial EEG recordings of three epilepsy patients with electrode grids placed on the motor cortex. The patients were asked to repeatedly imagine movements of two kinds, e.g., tongue or ﬁnger movements. We analyze the classiﬁability of the data using Support Vector Machines (SVMs) [18, 21] and Recursive Channel Elimination (RCE) [11]. 1</p><p>4 0.12812091 <a title="56-tfidf-4" href="./nips-2004-A_Temporal_Kernel-Based_Model_for_Tracking_Hand_Movements_from_Neural_Activities.html">12 nips-2004-A Temporal Kernel-Based Model for Tracking Hand Movements from Neural Activities</a></p>
<p>Author: Lavi Shpigelman, Koby Crammer, Rony Paz, Eilon Vaadia, Yoram Singer</p><p>Abstract: We devise and experiment with a dynamical kernel-based system for tracking hand movements from neural activity. The state of the system corresponds to the hand location, velocity, and acceleration, while the system’s input are the instantaneous spike rates. The system’s state dynamics is deﬁned as a combination of a linear mapping from the previous estimated state and a kernel-based mapping tailored for modeling neural activities. In contrast to generative models, the activity-to-state mapping is learned using discriminative methods by minimizing a noise-robust loss function. We use this approach to predict hand trajectories on the basis of neural activity in motor cortex of behaving monkeys and ﬁnd that the proposed approach is more accurate than both a static approach based on support vector regression and the Kalman ﬁlter. 1</p><p>5 0.091048352 <a title="56-tfidf-5" href="./nips-2004-Hierarchical_Bayesian_Inference_in_Networks_of_Spiking_Neurons.html">76 nips-2004-Hierarchical Bayesian Inference in Networks of Spiking Neurons</a></p>
<p>Author: Rajesh P. Rao</p><p>Abstract: There is growing evidence from psychophysical and neurophysiological studies that the brain utilizes Bayesian principles for inference and decision making. An important open question is how Bayesian inference for arbitrary graphical models can be implemented in networks of spiking neurons. In this paper, we show that recurrent networks of noisy integrate-and-ﬁre neurons can perform approximate Bayesian inference for dynamic and hierarchical graphical models. The membrane potential dynamics of neurons is used to implement belief propagation in the log domain. The spiking probability of a neuron is shown to approximate the posterior probability of the preferred state encoded by the neuron, given past inputs. We illustrate the model using two examples: (1) a motion detection network in which the spiking probability of a direction-selective neuron becomes proportional to the posterior probability of motion in a preferred direction, and (2) a two-level hierarchical network that produces attentional effects similar to those observed in visual cortical areas V2 and V4. The hierarchical model offers a new Bayesian interpretation of attentional modulation in V2 and V4. 1</p><p>6 0.07773561 <a title="56-tfidf-6" href="./nips-2004-Responding_to_Modalities_with_Different_Latencies.html">155 nips-2004-Responding to Modalities with Different Latencies</a></p>
<p>7 0.075335532 <a title="56-tfidf-7" href="./nips-2004-Multiple_Alignment_of_Continuous_Time_Series.html">124 nips-2004-Multiple Alignment of Continuous Time Series</a></p>
<p>8 0.062253166 <a title="56-tfidf-8" href="./nips-2004-Experts_in_a_Markov_Decision_Process.html">64 nips-2004-Experts in a Markov Decision Process</a></p>
<p>9 0.051956609 <a title="56-tfidf-9" href="./nips-2004-Bayesian_inference_in_spiking_neurons.html">28 nips-2004-Bayesian inference in spiking neurons</a></p>
<p>10 0.049086947 <a title="56-tfidf-10" href="./nips-2004-Contextual_Models_for_Object_Detection_Using_Boosted_Random_Fields.html">47 nips-2004-Contextual Models for Object Detection Using Boosted Random Fields</a></p>
<p>11 0.047806226 <a title="56-tfidf-11" href="./nips-2004-Spike_Sorting%3A_Bayesian_Clustering_of_Non-Stationary_Data.html">174 nips-2004-Spike Sorting: Bayesian Clustering of Non-Stationary Data</a></p>
<p>12 0.046984777 <a title="56-tfidf-12" href="./nips-2004-A_Three_Tiered_Approach_for_Articulated_Object_Action_Modeling_and_Recognition.html">13 nips-2004-A Three Tiered Approach for Articulated Object Action Modeling and Recognition</a></p>
<p>13 0.046467744 <a title="56-tfidf-13" href="./nips-2004-At_the_Edge_of_Chaos%3A_Real-time_Computations_and_Self-Organized_Criticality_in_Recurrent_Neural_Networks.html">26 nips-2004-At the Edge of Chaos: Real-time Computations and Self-Organized Criticality in Recurrent Neural Networks</a></p>
<p>14 0.045244116 <a title="56-tfidf-14" href="./nips-2004-Planning_for_Markov_Decision_Processes_with_Sparse_Stochasticity.html">147 nips-2004-Planning for Markov Decision Processes with Sparse Stochasticity</a></p>
<p>15 0.043589141 <a title="56-tfidf-15" href="./nips-2004-Worst-Case_Analysis_of_Selective_Sampling_for_Linear-Threshold_Algorithms.html">206 nips-2004-Worst-Case Analysis of Selective Sampling for Linear-Threshold Algorithms</a></p>
<p>16 0.040223319 <a title="56-tfidf-16" href="./nips-2004-Brain_Inspired_Reinforcement_Learning.html">33 nips-2004-Brain Inspired Reinforcement Learning</a></p>
<p>17 0.039639626 <a title="56-tfidf-17" href="./nips-2004-A_Hidden_Markov_Model_for_de_Novo_Peptide_Sequencing.html">6 nips-2004-A Hidden Markov Model for de Novo Peptide Sequencing</a></p>
<p>18 0.039550364 <a title="56-tfidf-18" href="./nips-2004-Optimal_Aggregation_of_Classifiers_and_Boosting_Maps_in_Functional_Magnetic_Resonance_Imaging.html">139 nips-2004-Optimal Aggregation of Classifiers and Boosting Maps in Functional Magnetic Resonance Imaging</a></p>
<p>19 0.038142592 <a title="56-tfidf-19" href="./nips-2004-Validity_Estimates_for_Loopy_Belief_Propagation_on_Binary_Real-world_Networks.html">203 nips-2004-Validity Estimates for Loopy Belief Propagation on Binary Real-world Networks</a></p>
<p>20 0.037960254 <a title="56-tfidf-20" href="./nips-2004-Learning_first-order_Markov_models_for_control.html">102 nips-2004-Learning first-order Markov models for control</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2004_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.127), (1, -0.087), (2, 0.066), (3, -0.089), (4, -0.066), (5, 0.035), (6, 0.192), (7, 0.01), (8, 0.025), (9, -0.125), (10, -0.048), (11, 0.033), (12, -0.042), (13, -0.107), (14, 0.31), (15, -0.036), (16, 0.092), (17, -0.12), (18, -0.164), (19, 0.095), (20, -0.022), (21, -0.106), (22, -0.078), (23, 0.189), (24, -0.007), (25, 0.171), (26, 0.057), (27, 0.153), (28, -0.141), (29, 0.025), (30, -0.013), (31, -0.005), (32, 0.016), (33, -0.046), (34, -0.079), (35, -0.051), (36, -0.036), (37, 0.007), (38, -0.18), (39, 0.05), (40, -0.069), (41, 0.13), (42, 0.007), (43, 0.026), (44, -0.032), (45, 0.082), (46, -0.054), (47, -0.101), (48, 0.026), (49, 0.045)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95040751 <a title="56-lsi-1" href="./nips-2004-Dynamic_Bayesian_Networks_for_Brain-Computer_Interfaces.html">56 nips-2004-Dynamic Bayesian Networks for Brain-Computer Interfaces</a></p>
<p>Author: Pradeep Shenoy, Rajesh P. Rao</p><p>Abstract: We describe an approach to building brain-computer interfaces (BCI) based on graphical models for probabilistic inference and learning. We show how a dynamic Bayesian network (DBN) can be used to infer probability distributions over brain- and body-states during planning and execution of actions. The DBN is learned directly from observed data and allows measured signals such as EEG and EMG to be interpreted in terms of internal states such as intent to move, preparatory activity, and movement execution. Unlike traditional classiﬁcation-based approaches to BCI, the proposed approach (1) allows continuous tracking and prediction of internal states over time, and (2) generates control signals based on an entire probability distribution over states rather than binary yes/no decisions. We present preliminary results of brain- and body-state estimation using simultaneous EEG and EMG signals recorded during a self-paced left/right hand movement task. 1</p><p>2 0.81573576 <a title="56-lsi-2" href="./nips-2004-Methods_Towards_Invasive_Human_Brain_Computer_Interfaces.html">117 nips-2004-Methods Towards Invasive Human Brain Computer Interfaces</a></p>
<p>Author: Thomas N. Lal, Thilo Hinterberger, Guido Widman, Michael Schröder, N. J. Hill, Wolfgang Rosenstiel, Christian E. Elger, Niels Birbaumer, Bernhard Schölkopf</p><p>Abstract: During the last ten years there has been growing interest in the development of Brain Computer Interfaces (BCIs). The ﬁeld has mainly been driven by the needs of completely paralyzed patients to communicate. With a few exceptions, most human BCIs are based on extracranial electroencephalography (EEG). However, reported bit rates are still low. One reason for this is the low signal-to-noise ratio of the EEG [16]. We are currently investigating if BCIs based on electrocorticography (ECoG) are a viable alternative. In this paper we present the method and examples of intracranial EEG recordings of three epilepsy patients with electrode grids placed on the motor cortex. The patients were asked to repeatedly imagine movements of two kinds, e.g., tongue or ﬁnger movements. We analyze the classiﬁability of the data using Support Vector Machines (SVMs) [18, 21] and Recursive Channel Elimination (RCE) [11]. 1</p><p>3 0.75753915 <a title="56-lsi-3" href="./nips-2004-An_Auditory_Paradigm_for_Brain-Computer_Interfaces.html">20 nips-2004-An Auditory Paradigm for Brain-Computer Interfaces</a></p>
<p>Author: N. J. Hill, Thomas N. Lal, Karin Bierig, Niels Birbaumer, Bernhard Schölkopf</p><p>Abstract: Motivated by the particular problems involved in communicating with “locked-in” paralysed patients, we aim to develop a braincomputer interface that uses auditory stimuli. We describe a paradigm that allows a user to make a binary decision by focusing attention on one of two concurrent auditory stimulus sequences. Using Support Vector Machine classiﬁcation and Recursive Channel Elimination on the independent components of averaged eventrelated potentials, we show that an untrained user’s EEG data can be classiﬁed with an encouragingly high level of accuracy. This suggests that it is possible for users to modulate EEG signals in a single trial by the conscious direction of attention, well enough to be useful in BCI. 1</p><p>4 0.45809305 <a title="56-lsi-4" href="./nips-2004-A_Temporal_Kernel-Based_Model_for_Tracking_Hand_Movements_from_Neural_Activities.html">12 nips-2004-A Temporal Kernel-Based Model for Tracking Hand Movements from Neural Activities</a></p>
<p>Author: Lavi Shpigelman, Koby Crammer, Rony Paz, Eilon Vaadia, Yoram Singer</p><p>Abstract: We devise and experiment with a dynamical kernel-based system for tracking hand movements from neural activity. The state of the system corresponds to the hand location, velocity, and acceleration, while the system’s input are the instantaneous spike rates. The system’s state dynamics is deﬁned as a combination of a linear mapping from the previous estimated state and a kernel-based mapping tailored for modeling neural activities. In contrast to generative models, the activity-to-state mapping is learned using discriminative methods by minimizing a noise-robust loss function. We use this approach to predict hand trajectories on the basis of neural activity in motor cortex of behaving monkeys and ﬁnd that the proposed approach is more accurate than both a static approach based on support vector regression and the Kalman ﬁlter. 1</p><p>5 0.34807226 <a title="56-lsi-5" href="./nips-2004-Responding_to_Modalities_with_Different_Latencies.html">155 nips-2004-Responding to Modalities with Different Latencies</a></p>
<p>Author: Fredrik Bissmarck, Hiroyuki Nakahara, Kenji Doya, Okihide Hikosaka</p><p>Abstract: Motor control depends on sensory feedback in multiple modalities with different latencies. In this paper we consider within the framework of reinforcement learning how different sensory modalities can be combined and selected for real-time, optimal movement control. We propose an actor-critic architecture with multiple modules, whose output are combined using a softmax function. We tested our architecture in a simulation of a sequential reaching task. Reaching was initially guided by visual feedback with a long latency. Our learning scheme allowed the agent to utilize the somatosensory feedback with shorter latency when the hand is near the experienced trajectory. In simulations with different latencies for visual and somatosensory feedback, we found that the agent depended more on feedback with shorter latency. 1</p><p>6 0.28241223 <a title="56-lsi-6" href="./nips-2004-Beat_Tracking_the_Graphical_Model_Way.html">29 nips-2004-Beat Tracking the Graphical Model Way</a></p>
<p>7 0.27388528 <a title="56-lsi-7" href="./nips-2004-Planning_for_Markov_Decision_Processes_with_Sparse_Stochasticity.html">147 nips-2004-Planning for Markov Decision Processes with Sparse Stochasticity</a></p>
<p>8 0.26787415 <a title="56-lsi-8" href="./nips-2004-Schema_Learning%3A_Experience-Based_Construction_of_Predictive_Action_Models.html">159 nips-2004-Schema Learning: Experience-Based Construction of Predictive Action Models</a></p>
<p>9 0.25750026 <a title="56-lsi-9" href="./nips-2004-Harmonising_Chorales_by_Probabilistic_Inference.html">74 nips-2004-Harmonising Chorales by Probabilistic Inference</a></p>
<p>10 0.25294471 <a title="56-lsi-10" href="./nips-2004-A_Hidden_Markov_Model_for_de_Novo_Peptide_Sequencing.html">6 nips-2004-A Hidden Markov Model for de Novo Peptide Sequencing</a></p>
<p>11 0.24700189 <a title="56-lsi-11" href="./nips-2004-Modeling_Conversational_Dynamics_as_a_Mixed-Memory_Markov_Process.html">120 nips-2004-Modeling Conversational Dynamics as a Mixed-Memory Markov Process</a></p>
<p>12 0.23983236 <a title="56-lsi-12" href="./nips-2004-Multiple_Alignment_of_Continuous_Time_Series.html">124 nips-2004-Multiple Alignment of Continuous Time Series</a></p>
<p>13 0.21652012 <a title="56-lsi-13" href="./nips-2004-Hierarchical_Bayesian_Inference_in_Networks_of_Spiking_Neurons.html">76 nips-2004-Hierarchical Bayesian Inference in Networks of Spiking Neurons</a></p>
<p>14 0.20953526 <a title="56-lsi-14" href="./nips-2004-The_Rescorla-Wagner_Algorithm_and_Maximum_Likelihood_Estimation_of_Causal_Parameters.html">190 nips-2004-The Rescorla-Wagner Algorithm and Maximum Likelihood Estimation of Causal Parameters</a></p>
<p>15 0.20047864 <a title="56-lsi-15" href="./nips-2004-Instance-Specific_Bayesian_Model_Averaging_for_Classification.html">86 nips-2004-Instance-Specific Bayesian Model Averaging for Classification</a></p>
<p>16 0.19633114 <a title="56-lsi-16" href="./nips-2004-Mass_Meta-analysis_in_Talairach_Space.html">109 nips-2004-Mass Meta-analysis in Talairach Space</a></p>
<p>17 0.1933247 <a title="56-lsi-17" href="./nips-2004-Large-Scale_Prediction_of_Disulphide_Bond_Connectivity.html">95 nips-2004-Large-Scale Prediction of Disulphide Bond Connectivity</a></p>
<p>18 0.18545708 <a title="56-lsi-18" href="./nips-2004-Optimal_Aggregation_of_Classifiers_and_Boosting_Maps_in_Functional_Magnetic_Resonance_Imaging.html">139 nips-2004-Optimal Aggregation of Classifiers and Boosting Maps in Functional Magnetic Resonance Imaging</a></p>
<p>19 0.18415184 <a title="56-lsi-19" href="./nips-2004-Learning_first-order_Markov_models_for_control.html">102 nips-2004-Learning first-order Markov models for control</a></p>
<p>20 0.18302038 <a title="56-lsi-20" href="./nips-2004-Co-Validation%3A_Using_Model_Disagreement_on_Unlabeled_Data_to_Validate_Classification_Algorithms.html">38 nips-2004-Co-Validation: Using Model Disagreement on Unlabeled Data to Validate Classification Algorithms</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2004_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.079), (15, 0.097), (18, 0.045), (26, 0.035), (31, 0.02), (33, 0.195), (35, 0.018), (39, 0.013), (50, 0.029), (81, 0.011), (82, 0.039), (96, 0.296)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.7821629 <a title="56-lda-1" href="./nips-2004-Dynamic_Bayesian_Networks_for_Brain-Computer_Interfaces.html">56 nips-2004-Dynamic Bayesian Networks for Brain-Computer Interfaces</a></p>
<p>Author: Pradeep Shenoy, Rajesh P. Rao</p><p>Abstract: We describe an approach to building brain-computer interfaces (BCI) based on graphical models for probabilistic inference and learning. We show how a dynamic Bayesian network (DBN) can be used to infer probability distributions over brain- and body-states during planning and execution of actions. The DBN is learned directly from observed data and allows measured signals such as EEG and EMG to be interpreted in terms of internal states such as intent to move, preparatory activity, and movement execution. Unlike traditional classiﬁcation-based approaches to BCI, the proposed approach (1) allows continuous tracking and prediction of internal states over time, and (2) generates control signals based on an entire probability distribution over states rather than binary yes/no decisions. We present preliminary results of brain- and body-state estimation using simultaneous EEG and EMG signals recorded during a self-paced left/right hand movement task. 1</p><p>2 0.76792181 <a title="56-lda-2" href="./nips-2004-Active_Learning_for_Anomaly_and_Rare-Category_Detection.html">15 nips-2004-Active Learning for Anomaly and Rare-Category Detection</a></p>
<p>Author: Dan Pelleg, Andrew W. Moore</p><p>Abstract: We introduce a novel active-learning scenario in which a user wants to work with a learning algorithm to identify useful anomalies. These are distinguished from the traditional statistical deﬁnition of anomalies as outliers or merely ill-modeled points. Our distinction is that the usefulness of anomalies is categorized subjectively by the user. We make two additional assumptions. First, there exist extremely few useful anomalies to be hunted down within a massive dataset. Second, both useful and useless anomalies may sometimes exist within tiny classes of similar anomalies. The challenge is thus to identify “rare category” records in an unlabeled noisy set with help (in the form of class labels) from a human expert who has a small budget of datapoints that they are prepared to categorize. We propose a technique to meet this challenge, which assumes a mixture model ﬁt to the data, but otherwise makes no assumptions on the particular form of the mixture components. This property promises wide applicability in real-life scenarios and for various statistical models. We give an overview of several alternative methods, highlighting their strengths and weaknesses, and conclude with a detailed empirical analysis. We show that our method can quickly zoom in on an anomaly set containing a few tens of points in a dataset of hundreds of thousands. 1</p><p>3 0.61300373 <a title="56-lda-3" href="./nips-2004-Non-Local_Manifold_Tangent_Learning.html">131 nips-2004-Non-Local Manifold Tangent Learning</a></p>
<p>Author: Yoshua Bengio, Martin Monperrus</p><p>Abstract: We claim and present arguments to the effect that a large class of manifold learning algorithms that are essentially local and can be framed as kernel learning algorithms will suffer from the curse of dimensionality, at the dimension of the true underlying manifold. This observation suggests to explore non-local manifold learning algorithms which attempt to discover shared structure in the tangent planes at different positions. A criterion for such an algorithm is proposed and experiments estimating a tangent plane prediction function are presented, showing its advantages with respect to local manifold learning algorithms: it is able to generalize very far from training data (on learning handwritten character image rotations), where a local non-parametric method fails. 1</p><p>4 0.6100387 <a title="56-lda-4" href="./nips-2004-Learning_first-order_Markov_models_for_control.html">102 nips-2004-Learning first-order Markov models for control</a></p>
<p>Author: Pieter Abbeel, Andrew Y. Ng</p><p>Abstract: First-order Markov models have been successfully applied to many problems, for example in modeling sequential data using Markov chains, and modeling control problems using the Markov decision processes (MDP) formalism. If a ﬁrst-order Markov model’s parameters are estimated from data, the standard maximum likelihood estimator considers only the ﬁrst-order (single-step) transitions. But for many problems, the ﬁrstorder conditional independence assumptions are not satisﬁed, and as a result the higher order transition probabilities may be poorly approximated. Motivated by the problem of learning an MDP’s parameters for control, we propose an algorithm for learning a ﬁrst-order Markov model that explicitly takes into account higher order interactions during training. Our algorithm uses an optimization criterion different from maximum likelihood, and allows us to learn models that capture longer range effects, but without giving up the beneﬁts of using ﬁrst-order Markov models. Our experimental results also show the new algorithm outperforming conventional maximum likelihood estimation in a number of control problems where the MDP’s parameters are estimated from data. 1</p><p>5 0.60975772 <a title="56-lda-5" href="./nips-2004-Variational_Minimax_Estimation_of_Discrete_Distributions_under_KL_Loss.html">204 nips-2004-Variational Minimax Estimation of Discrete Distributions under KL Loss</a></p>
<p>Author: Liam Paninski</p><p>Abstract: We develop a family of upper and lower bounds on the worst-case expected KL loss for estimating a discrete distribution on a ﬁnite number m of points, given N i.i.d. samples. Our upper bounds are approximationtheoretic, similar to recent bounds for estimating discrete entropy; the lower bounds are Bayesian, based on averages of the KL loss under Dirichlet distributions. The upper bounds are convex in their parameters and thus can be minimized by descent methods to provide estimators with low worst-case error; the lower bounds are indexed by a one-dimensional parameter and are thus easily maximized. Asymptotic analysis of the bounds demonstrates the uniform KL-consistency of a wide class of estimators as c = N/m → ∞ (no matter how slowly), and shows that no estimator is consistent for c bounded (in contrast to entropy estimation). Moreover, the bounds are asymptotically tight as c → 0 or ∞, and are shown numerically to be tight within a factor of two for all c. Finally, in the sparse-data limit c → 0, we ﬁnd that the Dirichlet-Bayes (add-constant) estimator with parameter scaling like −c log(c) optimizes both the upper and lower bounds, suggesting an optimal choice of the “add-constant” parameter in this regime.</p><p>6 0.60939783 <a title="56-lda-6" href="./nips-2004-%E2%84%93%E2%82%80-norm_Minimization_for_Basis_Selection.html">207 nips-2004-ℓ₀-norm Minimization for Basis Selection</a></p>
<p>7 0.60915619 <a title="56-lda-7" href="./nips-2004-A_Feature_Selection_Algorithm_Based_on_the_Global_Minimization_of_a_Generalization_Error_Bound.html">3 nips-2004-A Feature Selection Algorithm Based on the Global Minimization of a Generalization Error Bound</a></p>
<p>8 0.60901356 <a title="56-lda-8" href="./nips-2004-Conditional_Random_Fields_for_Object_Recognition.html">44 nips-2004-Conditional Random Fields for Object Recognition</a></p>
<p>9 0.60811275 <a title="56-lda-9" href="./nips-2004-Blind_One-microphone_Speech_Separation%3A_A_Spectral_Learning_Approach.html">31 nips-2004-Blind One-microphone Speech Separation: A Spectral Learning Approach</a></p>
<p>10 0.6069544 <a title="56-lda-10" href="./nips-2004-Hierarchical_Clustering_of_a_Mixture_Model.html">77 nips-2004-Hierarchical Clustering of a Mixture Model</a></p>
<p>11 0.60599029 <a title="56-lda-11" href="./nips-2004-Spike_Sorting%3A_Bayesian_Clustering_of_Non-Stationary_Data.html">174 nips-2004-Spike Sorting: Bayesian Clustering of Non-Stationary Data</a></p>
<p>12 0.60529071 <a title="56-lda-12" href="./nips-2004-Instance-Specific_Bayesian_Model_Averaging_for_Classification.html">86 nips-2004-Instance-Specific Bayesian Model Averaging for Classification</a></p>
<p>13 0.60502911 <a title="56-lda-13" href="./nips-2004-Neighbourhood_Components_Analysis.html">127 nips-2004-Neighbourhood Components Analysis</a></p>
<p>14 0.60438848 <a title="56-lda-14" href="./nips-2004-A_Direct_Formulation_for_Sparse_PCA_Using_Semidefinite_Programming.html">2 nips-2004-A Direct Formulation for Sparse PCA Using Semidefinite Programming</a></p>
<p>15 0.6043185 <a title="56-lda-15" href="./nips-2004-Learning_Hyper-Features_for_Visual_Identification.html">99 nips-2004-Learning Hyper-Features for Visual Identification</a></p>
<p>16 0.6041218 <a title="56-lda-16" href="./nips-2004-A_Second_Order_Cone_programming_Formulation_for_Classifying_Missing_Data.html">11 nips-2004-A Second Order Cone programming Formulation for Classifying Missing Data</a></p>
<p>17 0.6038487 <a title="56-lda-17" href="./nips-2004-Self-Tuning_Spectral_Clustering.html">161 nips-2004-Self-Tuning Spectral Clustering</a></p>
<p>18 0.6034472 <a title="56-lda-18" href="./nips-2004-Experts_in_a_Markov_Decision_Process.html">64 nips-2004-Experts in a Markov Decision Process</a></p>
<p>19 0.60312819 <a title="56-lda-19" href="./nips-2004-Multiple_Alignment_of_Continuous_Time_Series.html">124 nips-2004-Multiple Alignment of Continuous Time Series</a></p>
<p>20 0.60308993 <a title="56-lda-20" href="./nips-2004-Confidence_Intervals_for_the_Area_Under_the_ROC_Curve.html">45 nips-2004-Confidence Intervals for the Area Under the ROC Curve</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
