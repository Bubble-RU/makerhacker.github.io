<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>13 nips-2004-A Three Tiered Approach for Articulated Object Action Modeling and Recognition</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2004" href="../home/nips2004_home.html">nips2004</a> <a title="nips-2004-13" href="#">nips2004-13</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>13 nips-2004-A Three Tiered Approach for Articulated Object Action Modeling and Recognition</h1>
<br/><p>Source: <a title="nips-2004-13-pdf" href="http://papers.nips.cc/paper/2640-a-three-tiered-approach-for-articulated-object-action-modeling-and-recognition.pdf">pdf</a></p><p>Author: Le Lu, Gregory D. Hager, Laurent Younes</p><p>Abstract: Visual action recognition is an important problem in computer vision. In this paper, we propose a new method to probabilistically model and recognize actions of articulated objects, such as hand or body gestures, in image sequences. Our method consists of three levels of representation. At the low level, we ﬁrst extract a feature vector invariant to scale and in-plane rotation by using the Fourier transform of a circular spatial histogram. Then, spectral partitioning [20] is utilized to obtain an initial clustering; this clustering is then reﬁned using a temporal smoothness constraint. Gaussian mixture model (GMM) based clustering and density estimation in the subspace of linear discriminant analysis (LDA) are then applied to thousands of image feature vectors to obtain an intermediate level representation. Finally, at the high level we build a temporal multiresolution histogram model for each action by aggregating the clustering weights of sampled images belonging to that action. We discuss how this high level representation can be extended to achieve temporal scaling invariance and to include Bi-gram or Multi-gram transition information. Both image clustering and action recognition/segmentation results are given to show the validity of our three tiered representation.</p><p>Reference: <a title="nips-2004-13-reference" href="../nips2004_reference/nips-2004-A_Three_Tiered_Approach_for_Articulated_Object_Action_Modeling_and_Recognition_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract Visual action recognition is an important problem in computer vision. [sent-6, score-0.32]
</p><p>2 In this paper, we propose a new method to probabilistically model and recognize actions of articulated objects, such as hand or body gestures, in image sequences. [sent-7, score-0.54]
</p><p>3 At the low level, we ﬁrst extract a feature vector invariant to scale and in-plane rotation by using the Fourier transform of a circular spatial histogram. [sent-9, score-0.428]
</p><p>4 Then, spectral partitioning [20] is utilized to obtain an initial clustering; this clustering is then reﬁned using a temporal smoothness constraint. [sent-10, score-0.516]
</p><p>5 Gaussian mixture model (GMM) based clustering and density estimation in the subspace of linear discriminant analysis (LDA) are then applied to thousands of image feature vectors to obtain an intermediate level representation. [sent-11, score-0.789]
</p><p>6 Finally, at the high level we build a temporal multiresolution histogram model for each action by aggregating the clustering weights of sampled images belonging to that action. [sent-12, score-1.195]
</p><p>7 We discuss how this high level representation can be extended to achieve temporal scaling invariance and to include Bi-gram or Multi-gram transition information. [sent-13, score-0.33]
</p><p>8 Both image clustering and action recognition/segmentation results are given to show the validity of our three tiered representation. [sent-14, score-0.688]
</p><p>9 1 Introduction Articulated object action modeling, tracking and recognition has been an important research issue in computer vision community for decades. [sent-15, score-0.408]
</p><p>10 Past approaches [3, 13, 4, 6, 23, 2] have used many different kinds of direct image observations, including color, edges, contour or moments [14], to ﬁt a hand or body’s shape model and motion parameters. [sent-16, score-0.495]
</p><p>11 In this paper, we propose to learn a small set of object appearance descriptors, and then to build an aggregated temporal representation of clustered object descriptors over time. [sent-17, score-0.691]
</p><p>12 There are several obvious reasons to base gesture or motion recognition on a time sequence of observations. [sent-18, score-0.467]
</p><p>13 Furthermore, these gestures are difﬁcult to track from frame to frame due to motion blur, lack of features, and complex self-occlusions. [sent-21, score-0.599]
</p><p>14 By modeling hand/body gesture as a sequential learning problem, appropriate discriminative information can be retrieved and more action categories can be handled. [sent-22, score-0.375]
</p><p>15 In related work, Darrell and Pentland [7] describe dynamic time warping (DTW) to align and recognize a space-time gesture against a stored library. [sent-23, score-0.285]
</p><p>16 In comparision, our method describes image appearances uniformly and clusters them globally from a training set containing different gestures. [sent-27, score-0.253]
</p><p>17 However, clustering in a high dimensional space is very difﬁcult and can be unstable. [sent-31, score-0.262]
</p><p>18 Furthermore, the circular histogram representation has adjustable spatial resolution to accomodate differing appearance complexities, and it is translation, rotation, and scale invariant. [sent-33, score-0.642]
</p><p>19 In other work, [27, 9] recognize human actions at a distance by computing motion information between images and relying on temporal correlation on motion vectors across sequences. [sent-34, score-1.016]
</p><p>20 Our work also makes use of motion information, but does not rely exclusively on it. [sent-35, score-0.248]
</p><p>21 Rather, we combine appearance and motion cues to increase sensitivity beyond what either can provide alone. [sent-36, score-0.379]
</p><p>22 Since our method is based on the temporal aggregation of image clusters as a histogram to recognize an action, it can also be considered to be a temporal texton-like method [17, 16]. [sent-37, score-1.058]
</p><p>23 One advantage of the aggregated histogram model in a time-series is that it is straightforward to accommodate temporal scaling by using a sliding window. [sent-38, score-0.646]
</p><p>24 Second, we introduce a methods for sequential smoothing of clustering results. [sent-42, score-0.301]
</p><p>25 Finally, we recognize image sequences as actions efﬁciently based on a ﬂexible histogram model. [sent-44, score-0.674]
</p><p>26 We also discuss improvement to the method by incorporating motion information. [sent-45, score-0.248]
</p><p>27 2 A Three Tiered Approach We propose a three tiered approach for dynamic action modeling comprising low level feature extraction, intermediate level feature vector clustering and high level histogram recognition as shown in Figure 1. [sent-46, score-1.682]
</p><p>28 (a)  (b)  (c)  Figure 2: (a) Image after background subtraction (b) GMM based color segmentation (c) Circular histogram for feature extraction. [sent-48, score-0.625]
</p><p>29 1  Low Level: Rotation Invariant Feature Extraction  In the low level image processing, our goals are to locate the region of interest in an image and to extract a scale and in-plane rotation invariant feature vector as its descriptor. [sent-50, score-0.617]
</p><p>30 Depending on the circumstances, a Gaussian mixture model (GMM) for segmentation [15], probabilistic appearance modeling [5], or dynamic object segmentation by Generalized Principal Component Analysis (GPCA) [25] are possible solutions. [sent-52, score-0.538]
</p><p>31 In this paper, we apply a GMM for hand skin color segmentation. [sent-53, score-0.265]
</p><p>32 We ﬁt a GMM by ﬁrst performing a simple background subtraction to obtain a noisy foreground containing a hand object (shown in Figure 2 (a)). [sent-54, score-0.257]
</p><p>33 From this, more than 1 million RGB pixels are used to train skin and non-skin color density models with 10 Gaussian kernels for each class. [sent-55, score-0.269]
</p><p>34 Since the position and size of this circular histogram is determined by the color segmentation, it is translation and scale invariant. [sent-63, score-0.487]
</p><p>35 We then normalize the density value Pskin + Pnonskin = 1 for every pixel within the foreground mask (Figure 2) over the hand region. [sent-64, score-0.26]
</p><p>36 The power spectra of all annuli are ordered into a linear list producing a feature vector f (t) of 63 dimensions representing the appearance of a hand image. [sent-67, score-0.431]
</p><p>37 2  Intermediate Level: Clustering Presentation for Image Frames  After the low level processing, we obtain a scale and rotation invariant feature vector as an appearance representation for each image frame. [sent-70, score-0.668]
</p><p>38 1  An optional dimension reduction of feature vectors can be achieved by eliminating dimensions which have low variance. [sent-73, score-0.254]
</p><p>39 At the intermediate level, we cluster images from a set of feature vectors. [sent-75, score-0.343]
</p><p>40 This frame-wise clustering is critical for dimension reduction and the stability of high level recognition. [sent-76, score-0.3]
</p><p>41 Initializing Clusters by Spectral Segmentation There are two critical problems with clustering algorithms: determining the true number of clusters and initializing each cluster. [sent-77, score-0.344]
</p><p>42 Here we use a spectral clustering method [20, 22, 26, 18] to solve both problems. [sent-78, score-0.315]
</p><p>43 N  k−1 c=1  rand(0, N ) : k=1 : n≥k>1  | cos(f n (ID(c)), f n (t))|  (1)  where f n (t) is the feature vector of image frame t after numerical normalization in [20] and ID(k) is the image frame number chosen for the center of cluster k. [sent-85, score-0.619]
</p><p>44 For better clustering results, multiple restarts are used for initialization. [sent-87, score-0.262]
</p><p>45 Unlike [18], we ﬁnd this simple clustering procedure is sufﬁcient to obtain a good set of clusters from only a few restarts. [sent-88, score-0.344]
</p><p>46 Reﬁnement: Temporally Constrained Clustering Spectral clustering methods are designed for an unordered “bag” of feature vectors, but, in our case, the temporal ordering of image is an important source of information. [sent-94, score-0.646]
</p><p>47 In particular, the stablity of appearance is easily computed by computing the motion energy3 between two frames. [sent-95, score-0.379]
</p><p>48 Let M (t) denote the motion energy between frames t and t−1. [sent-96, score-0.408]
</p><p>49 We now create a regularized clustering cost function as   g(c)−g(C2 (t−1))   e− f (t)−g(c) M (t) e− +λ (2) C2 (t) = arg maxc=1. [sent-98, score-0.219]
</p><p>50 Here motion energy M (t) plays a role as the temperature T in simulated annealing. [sent-101, score-0.285]
</p><p>51 When it is high (strong motion between frames), the motion continuity condition is violated and the labels of successive frames can change freely; when it is low, the smoothness term constrains the possible transitions of classes ¯ with low M (k, j). [sent-102, score-0.734]
</p><p>52 4 This temporal smoothing is most relevant with images with motions, and static frames are already stably clustered and therefore their cluster labels to not change. [sent-104, score-0.762]
</p><p>53 3 A simple method is to compute motion energy as the Sum of Squared Differences (SSD) by subtracting two Pskin density masses from successive images. [sent-106, score-0.413]
</p><p>54 4 ¯ Note that M (k, j) changes after scanning the labels of the image sequence once, thus more iterations could be used to achieve more accurate temporal smoothness of C3 (t), t = 1. [sent-107, score-0.377]
</p><p>55 The initial clustering labels help to build the scatter matrices for LDA. [sent-115, score-0.403]
</p><p>56 The original feature vectors can be further projected into a low dimensional space, which improves the estimation of multi-variate Gaussian density function. [sent-117, score-0.343]
</p><p>57 With the new clustering result from GMM, LDA’s scatter matrices and projection matrix can be re-estimated, and GMM can also be re-modeled in the new LDA subspace. [sent-118, score-0.299]
</p><p>58 Intuitively, LDA projects the data into a low dimensional subspace where the image clusters are well separated, which helps to have a good parameter estimation for GMM with limited data. [sent-120, score-0.402]
</p><p>59 Note that the histogram Ht1 ,t2 bins are precisely corresponding to the trained clusters. [sent-135, score-0.368]
</p><p>60 From the training set, we aggregate the cluster weights of images within a given hand action to form a histogram model. [sent-136, score-0.769]
</p><p>61 In this way, a temporal image sequence corresponding to one action is represented by a single vector. [sent-137, score-0.547]
</p><p>62 Assume we have a library of action histograms H1 , H2 , . [sent-140, score-0.26]
</p><p>63 M   c=1  This method is low cost because only one exemplar per action category is needed. [sent-146, score-0.285]
</p><p>64 , we cannot distinguish an opening hand gesture from a closing hand using only one histogram. [sent-149, score-0.287]
</p><p>65 This problem can be easily solved by subdividing the sequence and histogram m model into m parts: Ht1 ,t2 = [Ht1 ,(t1 +t2 )/m , . [sent-150, score-0.408]
</p><p>66 For an extreme case when one frame is a subsequence, the histogram model simply becomes exactly the vector form of the representative surface. [sent-154, score-0.4]
</p><p>67 To achieve this, the image frames within a hand action can be sub-sampled to build a set of temporal pyramids. [sent-156, score-0.811]
</p><p>68 In order to segment hand gestures from a long video sequence, we create several sliding windows with different frame sampling rates. [sent-157, score-0.459]
</p><p>69 Taken together, the histogram representation achieves an adjustable multi-resolution measurement to describe actions. [sent-159, score-0.397]
</p><p>70 A Hidden Markov Model (HMM) with discrete observations could be also employed to train models for different hand actions, but more template samples per gesture class are required. [sent-160, score-0.236]
</p><p>71 The histogram recognition method has the additional advantage that it does not depend on extremely accurate frame-wise clustering. [sent-161, score-0.412]
</p><p>72 From the viewpoint of considering hand actions as a language process, our model is an integration of individual observations (by labelling each frame with a set of learned clusters) from different time slots. [sent-164, score-0.284]
</p><p>73 The labels’ transitions between successive frames are not used to describe the temporal sequence. [sent-165, score-0.324]
</p><p>74 3 Results We have tested our three tiered method on the problem of recognizing sequences of hand spelling gestures. [sent-168, score-0.304]
</p><p>75 We ﬁrst evaluate the low level representation of single images and intermediate clustering algorithms. [sent-170, score-0.575]
</p><p>76 The frame-toframe motion energy is used to label images as static or dynamic. [sent-172, score-0.474]
</p><p>77 For spectral clustering, 3 ∼ 4 restarts from both the dynamic and static set are sufﬁcient to cover all the modes in the training set. [sent-173, score-0.332]
</p><p>78 Then, temporal smoothing is employed and a Gaussian density is calculated for each cluster in a 10 dimensional subspace of the LDA projection. [sent-174, score-0.573]
</p><p>79 As a result, 24 clusters are obtained which contain 16 static and 8 dynamic modes. [sent-175, score-0.318]
</p><p>80 Figure 3 shows 5 frames closest to the mean of the probability density of cluster 1, 3, 19, 5, 13, 8, 21, 15, 6, 12. [sent-176, score-0.297]
</p><p>81 It can be seen that clustering results are insensitive to artifacts of skin segmentation. [sent-177, score-0.336]
</p><p>82 The study of the eigenvalues of covariance matrices shows that their superellipsoid shapes are expanded within 2 ∼ 3 dimensions or 6 ∼ 8 dimensions for static or dynamic clusters. [sent-179, score-0.319]
</p><p>83 Taken together, this means that static clusters are quite tight, while dynamic clusters contain much more in-class variation. [sent-180, score-0.443]
</p><p>84 From Figure 4 (c), dynamic clusters gain more weight during the smoothing process incorporating the temporal constraint and subsequent GMM reﬁnement. [sent-181, score-0.483]
</p><p>85 Figure 3: Image clustering results after low and intermediate level processing. [sent-182, score-0.456]
</p><p>86 (b) Afﬁnity matrices of cluster centoids (from upper left to lower right) after spectral clustering, temporal smoothing and GMM. [sent-185, score-0.504]
</p><p>87 (c) Labelling results of 3015 images (red squares are frames whose labels changed with smoothing process after spectral clustering). [sent-186, score-0.42]
</p><p>88 The length of the action sequences was 9 ∼ 38 frames. [sent-192, score-0.252]
</p><p>89 The temporal scale of actions in the same category ranged from 1 to 2. [sent-193, score-0.31]
</p><p>90 The results were recognition rates of 90% and 93% without/with temporal smoothing (Equation 2). [sent-195, score-0.385]
</p><p>91 We also used the learned model and a sliding window with temporal scaling to segment actions from a 6034 frame video sequence containing dynamic gestures and static hand postures. [sent-197, score-0.962]
</p><p>92 As noted previously, our method cannot distinguish opening/closing hand gestures without temporally subdividing histograms. [sent-202, score-0.396]
</p><p>93 An alternative solution is to integrate motion information5 between frames. [sent-203, score-0.248]
</p><p>94 Motion feature vectors are also clustered, which results a joint (appearance and motion) histogram model for actions. [sent-204, score-0.454]
</p><p>95 We assume independence of the data and therefore simple contatenate these two histograms into a single action representation. [sent-205, score-0.26]
</p><p>96 From our preliminary experiments, both motion integration and histogram subdivision are comparably effective to recognize gestures with opposite direction. [sent-206, score-0.822]
</p><p>97 4 Conclusion and Discussion We have presented a method for classifying the motion of articulated gestures using LDA/GMM-based clustering methods and a histogram-based model of temporal evolution. [sent-207, score-0.917]
</p><p>98 Using this model, we have obtained extremely good recognition results using a relatively coarse representation of appearance and motion in images. [sent-208, score-0.529]
</p><p>99 Our future work will focus on building a larger hand action database containing 50 ∼ 100 5 Motion information can be extracted by ﬁrst aligning two hand blobs, subtracting two skin-color density masses, then using the same circular histogram in section 2. [sent-213, score-0.901]
</p><p>100 Also, by ﬁnding an effective foreground segmentation module, we intend to apply the same methods to other applications such as recognizing stylized human body motion. [sent-219, score-0.315]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('histogram', 0.31), ('gmm', 0.292), ('motion', 0.248), ('clustering', 0.219), ('action', 0.218), ('temporal', 0.201), ('gestures', 0.171), ('pskin', 0.149), ('appearance', 0.131), ('image', 0.128), ('clusters', 0.125), ('frames', 0.123), ('tiered', 0.123), ('segmentation', 0.12), ('static', 0.118), ('gesture', 0.117), ('skin', 0.117), ('circular', 0.114), ('actions', 0.109), ('lda', 0.108), ('recognition', 0.102), ('feature', 0.098), ('subdividing', 0.098), ('spectral', 0.096), ('recognize', 0.093), ('frame', 0.09), ('intermediate', 0.089), ('density', 0.089), ('foreground', 0.086), ('cluster', 0.085), ('hand', 0.085), ('iccv', 0.084), ('smoothing', 0.082), ('aggregated', 0.081), ('level', 0.081), ('articulated', 0.078), ('dynamic', 0.075), ('annuli', 0.074), ('images', 0.071), ('rotation', 0.069), ('low', 0.067), ('id', 0.065), ('gpca', 0.064), ('color', 0.063), ('recognizing', 0.062), ('video', 0.059), ('pentland', 0.058), ('bins', 0.058), ('pami', 0.058), ('build', 0.056), ('sliding', 0.054), ('fourier', 0.052), ('object', 0.052), ('binning', 0.049), ('framewise', 0.049), ('hl', 0.049), ('postures', 0.049), ('textons', 0.049), ('representation', 0.048), ('labels', 0.048), ('body', 0.047), ('invariant', 0.046), ('vectors', 0.046), ('nity', 0.043), ('dimensions', 0.043), ('restarts', 0.043), ('darrell', 0.043), ('descriptive', 0.043), ('subregion', 0.043), ('tomasi', 0.043), ('younes', 0.043), ('dimensional', 0.043), ('histograms', 0.042), ('malik', 0.042), ('temporally', 0.042), ('scatter', 0.04), ('modeling', 0.04), ('matrices', 0.04), ('masses', 0.039), ('bhattacharyya', 0.039), ('adjustable', 0.039), ('centroid', 0.039), ('multiresolution', 0.039), ('subspace', 0.039), ('extraction', 0.038), ('af', 0.037), ('energy', 0.037), ('baltimore', 0.036), ('bigram', 0.036), ('descriptors', 0.036), ('tracking', 0.036), ('employed', 0.034), ('cvpr', 0.034), ('transform', 0.034), ('subtraction', 0.034), ('ya', 0.034), ('sequences', 0.034), ('shape', 0.034), ('purposes', 0.034), ('clustered', 0.034)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999928 <a title="13-tfidf-1" href="./nips-2004-A_Three_Tiered_Approach_for_Articulated_Object_Action_Modeling_and_Recognition.html">13 nips-2004-A Three Tiered Approach for Articulated Object Action Modeling and Recognition</a></p>
<p>Author: Le Lu, Gregory D. Hager, Laurent Younes</p><p>Abstract: Visual action recognition is an important problem in computer vision. In this paper, we propose a new method to probabilistically model and recognize actions of articulated objects, such as hand or body gestures, in image sequences. Our method consists of three levels of representation. At the low level, we ﬁrst extract a feature vector invariant to scale and in-plane rotation by using the Fourier transform of a circular spatial histogram. Then, spectral partitioning [20] is utilized to obtain an initial clustering; this clustering is then reﬁned using a temporal smoothness constraint. Gaussian mixture model (GMM) based clustering and density estimation in the subspace of linear discriminant analysis (LDA) are then applied to thousands of image feature vectors to obtain an intermediate level representation. Finally, at the high level we build a temporal multiresolution histogram model for each action by aggregating the clustering weights of sampled images belonging to that action. We discuss how this high level representation can be extended to achieve temporal scaling invariance and to include Bi-gram or Multi-gram transition information. Both image clustering and action recognition/segmentation results are given to show the validity of our three tiered representation.</p><p>2 0.18514213 <a title="13-tfidf-2" href="./nips-2004-Semi-supervised_Learning_with_Penalized_Probabilistic_Clustering.html">167 nips-2004-Semi-supervised Learning with Penalized Probabilistic Clustering</a></p>
<p>Author: Zhengdong Lu, Todd K. Leen</p><p>Abstract: While clustering is usually an unsupervised operation, there are circumstances in which we believe (with varying degrees of certainty) that items A and B should be assigned to the same cluster, while items A and C should not. We would like such pairwise relations to inﬂuence cluster assignments of out-of-sample data in a manner consistent with the prior knowledge expressed in the training set. Our starting point is probabilistic clustering based on Gaussian mixture models (GMM) of the data distribution. We express clustering preferences in the prior distribution over assignments of data points to clusters. This prior penalizes cluster assignments according to the degree with which they violate the preferences. We ﬁt the model parameters with EM. Experiments on a variety of data sets show that PPC can consistently improve clustering results.</p><p>3 0.1715461 <a title="13-tfidf-3" href="./nips-2004-Self-Tuning_Spectral_Clustering.html">161 nips-2004-Self-Tuning Spectral Clustering</a></p>
<p>Author: Lihi Zelnik-manor, Pietro Perona</p><p>Abstract: We study a number of open issues in spectral clustering: (i) Selecting the appropriate scale of analysis, (ii) Handling multi-scale data, (iii) Clustering with irregular background clutter, and, (iv) Finding automatically the number of groups. We ﬁrst propose that a ‘local’ scale should be used to compute the afﬁnity between each pair of points. This local scaling leads to better clustering especially when the data includes multiple scales and when the clusters are placed within a cluttered background. We further suggest exploiting the structure of the eigenvectors to infer automatically the number of groups. This leads to a new algorithm in which the ﬁnal randomly initialized k-means stage is eliminated. 1</p><p>4 0.16340959 <a title="13-tfidf-4" href="./nips-2004-Generative_Affine_Localisation_and_Tracking.html">73 nips-2004-Generative Affine Localisation and Tracking</a></p>
<p>Author: John Winn, Andrew Blake</p><p>Abstract: We present an extension to the Jojic and Frey (2001) layered sprite model which allows for layers to undergo afﬁne transformations. This extension allows for afﬁne object pose to be inferred whilst simultaneously learning the object shape and appearance. Learning is carried out by applying an augmented variational inference algorithm which includes a global search over a discretised transform space followed by a local optimisation. To aid correct convergence, we use bottom-up cues to restrict the space of possible afﬁne transformations. We present results on a number of video sequences and show how the model can be extended to track an object whose appearance changes throughout the sequence. 1</p><p>5 0.15484004 <a title="13-tfidf-5" href="./nips-2004-Spike_Sorting%3A_Bayesian_Clustering_of_Non-Stationary_Data.html">174 nips-2004-Spike Sorting: Bayesian Clustering of Non-Stationary Data</a></p>
<p>Author: Aharon Bar-hillel, Adam Spiro, Eran Stark</p><p>Abstract: Spike sorting involves clustering spike trains recorded by a microelectrode according to the source neuron. It is a complicated problem, which requires a lot of human labor, partly due to the non-stationary nature of the data. We propose an automated technique for the clustering of non-stationary Gaussian sources in a Bayesian framework. At a ﬁrst search stage, data is divided into short time frames and candidate descriptions of the data as a mixture of Gaussians are computed for each frame. At a second stage transition probabilities between candidate mixtures are computed, and a globally optimal clustering is found as the MAP solution of the resulting probabilistic model. Transition probabilities are computed using local stationarity assumptions and are based on a Gaussian version of the Jensen-Shannon divergence. The method was applied to several recordings. The performance appeared almost indistinguishable from humans in a wide range of scenarios, including movement, merges, and splits of clusters. 1</p><p>6 0.1512101 <a title="13-tfidf-6" href="./nips-2004-Incremental_Learning_for_Visual_Tracking.html">83 nips-2004-Incremental Learning for Visual Tracking</a></p>
<p>7 0.13367914 <a title="13-tfidf-7" href="./nips-2004-Maximum_Margin_Clustering.html">115 nips-2004-Maximum Margin Clustering</a></p>
<p>8 0.1216099 <a title="13-tfidf-8" href="./nips-2004-Blind_One-microphone_Speech_Separation%3A_A_Spectral_Learning_Approach.html">31 nips-2004-Blind One-microphone Speech Separation: A Spectral Learning Approach</a></p>
<p>9 0.11826867 <a title="13-tfidf-9" href="./nips-2004-Adaptive_Discriminative_Generative_Model_and_Its_Applications.html">16 nips-2004-Adaptive Discriminative Generative Model and Its Applications</a></p>
<p>10 0.11582123 <a title="13-tfidf-10" href="./nips-2004-Distributed_Occlusion_Reasoning_for_Tracking_with_Nonparametric_Belief_Propagation.html">55 nips-2004-Distributed Occlusion Reasoning for Tracking with Nonparametric Belief Propagation</a></p>
<p>11 0.11425965 <a title="13-tfidf-11" href="./nips-2004-Common-Frame_Model_for_Object_Recognition.html">40 nips-2004-Common-Frame Model for Object Recognition</a></p>
<p>12 0.11336454 <a title="13-tfidf-12" href="./nips-2004-Hierarchical_Clustering_of_a_Mixture_Model.html">77 nips-2004-Hierarchical Clustering of a Mixture Model</a></p>
<p>13 0.11328734 <a title="13-tfidf-13" href="./nips-2004-Limits_of_Spectral_Clustering.html">103 nips-2004-Limits of Spectral Clustering</a></p>
<p>14 0.11249659 <a title="13-tfidf-14" href="./nips-2004-Two-Dimensional_Linear_Discriminant_Analysis.html">197 nips-2004-Two-Dimensional Linear Discriminant Analysis</a></p>
<p>15 0.11122678 <a title="13-tfidf-15" href="./nips-2004-Object_Classification_from_a_Single_Example_Utilizing_Class_Relevance_Metrics.html">134 nips-2004-Object Classification from a Single Example Utilizing Class Relevance Metrics</a></p>
<p>16 0.10850438 <a title="13-tfidf-16" href="./nips-2004-Efficient_Out-of-Sample_Extension_of_Dominant-Set_Clusters.html">61 nips-2004-Efficient Out-of-Sample Extension of Dominant-Set Clusters</a></p>
<p>17 0.10685755 <a title="13-tfidf-17" href="./nips-2004-Hierarchical_Eigensolver_for_Transition_Matrices_in_Spectral_Methods.html">79 nips-2004-Hierarchical Eigensolver for Transition Matrices in Spectral Methods</a></p>
<p>18 0.098596491 <a title="13-tfidf-18" href="./nips-2004-Learning_Hyper-Features_for_Visual_Identification.html">99 nips-2004-Learning Hyper-Features for Visual Identification</a></p>
<p>19 0.098360904 <a title="13-tfidf-19" href="./nips-2004-The_power_of_feature_clustering%3A_An_application_to_object_detection.html">192 nips-2004-The power of feature clustering: An application to object detection</a></p>
<p>20 0.093404151 <a title="13-tfidf-20" href="./nips-2004-Conditional_Random_Fields_for_Object_Recognition.html">44 nips-2004-Conditional Random Fields for Object Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2004_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.273), (1, 0.033), (2, -0.07), (3, -0.297), (4, 0.037), (5, -0.03), (6, -0.135), (7, -0.07), (8, -0.163), (9, 0.071), (10, -0.155), (11, 0.162), (12, -0.042), (13, 0.072), (14, 0.038), (15, -0.106), (16, -0.057), (17, 0.008), (18, -0.11), (19, 0.021), (20, -0.013), (21, -0.019), (22, 0.058), (23, 0.031), (24, 0.008), (25, -0.041), (26, -0.015), (27, 0.056), (28, 0.06), (29, 0.104), (30, 0.034), (31, 0.03), (32, -0.069), (33, 0.07), (34, 0.05), (35, 0.036), (36, -0.008), (37, -0.025), (38, 0.097), (39, -0.009), (40, -0.011), (41, 0.035), (42, 0.091), (43, -0.132), (44, 0.031), (45, 0.092), (46, -0.009), (47, 0.008), (48, -0.049), (49, -0.098)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9712649 <a title="13-lsi-1" href="./nips-2004-A_Three_Tiered_Approach_for_Articulated_Object_Action_Modeling_and_Recognition.html">13 nips-2004-A Three Tiered Approach for Articulated Object Action Modeling and Recognition</a></p>
<p>Author: Le Lu, Gregory D. Hager, Laurent Younes</p><p>Abstract: Visual action recognition is an important problem in computer vision. In this paper, we propose a new method to probabilistically model and recognize actions of articulated objects, such as hand or body gestures, in image sequences. Our method consists of three levels of representation. At the low level, we ﬁrst extract a feature vector invariant to scale and in-plane rotation by using the Fourier transform of a circular spatial histogram. Then, spectral partitioning [20] is utilized to obtain an initial clustering; this clustering is then reﬁned using a temporal smoothness constraint. Gaussian mixture model (GMM) based clustering and density estimation in the subspace of linear discriminant analysis (LDA) are then applied to thousands of image feature vectors to obtain an intermediate level representation. Finally, at the high level we build a temporal multiresolution histogram model for each action by aggregating the clustering weights of sampled images belonging to that action. We discuss how this high level representation can be extended to achieve temporal scaling invariance and to include Bi-gram or Multi-gram transition information. Both image clustering and action recognition/segmentation results are given to show the validity of our three tiered representation.</p><p>2 0.68183476 <a title="13-lsi-2" href="./nips-2004-Semi-supervised_Learning_with_Penalized_Probabilistic_Clustering.html">167 nips-2004-Semi-supervised Learning with Penalized Probabilistic Clustering</a></p>
<p>Author: Zhengdong Lu, Todd K. Leen</p><p>Abstract: While clustering is usually an unsupervised operation, there are circumstances in which we believe (with varying degrees of certainty) that items A and B should be assigned to the same cluster, while items A and C should not. We would like such pairwise relations to inﬂuence cluster assignments of out-of-sample data in a manner consistent with the prior knowledge expressed in the training set. Our starting point is probabilistic clustering based on Gaussian mixture models (GMM) of the data distribution. We express clustering preferences in the prior distribution over assignments of data points to clusters. This prior penalizes cluster assignments according to the degree with which they violate the preferences. We ﬁt the model parameters with EM. Experiments on a variety of data sets show that PPC can consistently improve clustering results.</p><p>3 0.59885997 <a title="13-lsi-3" href="./nips-2004-Self-Tuning_Spectral_Clustering.html">161 nips-2004-Self-Tuning Spectral Clustering</a></p>
<p>Author: Lihi Zelnik-manor, Pietro Perona</p><p>Abstract: We study a number of open issues in spectral clustering: (i) Selecting the appropriate scale of analysis, (ii) Handling multi-scale data, (iii) Clustering with irregular background clutter, and, (iv) Finding automatically the number of groups. We ﬁrst propose that a ‘local’ scale should be used to compute the afﬁnity between each pair of points. This local scaling leads to better clustering especially when the data includes multiple scales and when the clusters are placed within a cluttered background. We further suggest exploiting the structure of the eigenvectors to infer automatically the number of groups. This leads to a new algorithm in which the ﬁnal randomly initialized k-means stage is eliminated. 1</p><p>4 0.56522274 <a title="13-lsi-4" href="./nips-2004-Efficient_Out-of-Sample_Extension_of_Dominant-Set_Clusters.html">61 nips-2004-Efficient Out-of-Sample Extension of Dominant-Set Clusters</a></p>
<p>Author: Massimiliano Pavan, Marcello Pelillo</p><p>Abstract: Dominant sets are a new graph-theoretic concept that has proven to be relevant in pairwise data clustering problems, such as image segmentation. They generalize the notion of a maximal clique to edgeweighted graphs and have intriguing, non-trivial connections to continuous quadratic optimization and spectral-based grouping. We address the problem of grouping out-of-sample examples after the clustering process has taken place. This may serve either to drastically reduce the computational burden associated to the processing of very large data sets, or to efﬁciently deal with dynamic situations whereby data sets need to be updated continually. We show that the very notion of a dominant set offers a simple and efﬁcient way of doing this. Numerical experiments on various grouping problems show the effectiveness of the approach. 1</p><p>5 0.56262547 <a title="13-lsi-5" href="./nips-2004-Generative_Affine_Localisation_and_Tracking.html">73 nips-2004-Generative Affine Localisation and Tracking</a></p>
<p>Author: John Winn, Andrew Blake</p><p>Abstract: We present an extension to the Jojic and Frey (2001) layered sprite model which allows for layers to undergo afﬁne transformations. This extension allows for afﬁne object pose to be inferred whilst simultaneously learning the object shape and appearance. Learning is carried out by applying an augmented variational inference algorithm which includes a global search over a discretised transform space followed by a local optimisation. To aid correct convergence, we use bottom-up cues to restrict the space of possible afﬁne transformations. We present results on a number of video sequences and show how the model can be extended to track an object whose appearance changes throughout the sequence. 1</p><p>6 0.52736038 <a title="13-lsi-6" href="./nips-2004-Incremental_Learning_for_Visual_Tracking.html">83 nips-2004-Incremental Learning for Visual Tracking</a></p>
<p>7 0.5078032 <a title="13-lsi-7" href="./nips-2004-Who%27s_In_the_Picture.html">205 nips-2004-Who's In the Picture</a></p>
<p>8 0.49994078 <a title="13-lsi-8" href="./nips-2004-Maximum_Margin_Clustering.html">115 nips-2004-Maximum Margin Clustering</a></p>
<p>9 0.49840066 <a title="13-lsi-9" href="./nips-2004-Spike_Sorting%3A_Bayesian_Clustering_of_Non-Stationary_Data.html">174 nips-2004-Spike Sorting: Bayesian Clustering of Non-Stationary Data</a></p>
<p>10 0.48895615 <a title="13-lsi-10" href="./nips-2004-Hierarchical_Clustering_of_a_Mixture_Model.html">77 nips-2004-Hierarchical Clustering of a Mixture Model</a></p>
<p>11 0.4821654 <a title="13-lsi-11" href="./nips-2004-Using_Machine_Learning_to_Break_Visual_Human_Interaction_Proofs_%28HIPs%29.html">199 nips-2004-Using Machine Learning to Break Visual Human Interaction Proofs (HIPs)</a></p>
<p>12 0.47437826 <a title="13-lsi-12" href="./nips-2004-Common-Frame_Model_for_Object_Recognition.html">40 nips-2004-Common-Frame Model for Object Recognition</a></p>
<p>13 0.45982397 <a title="13-lsi-13" href="./nips-2004-Limits_of_Spectral_Clustering.html">103 nips-2004-Limits of Spectral Clustering</a></p>
<p>14 0.44107401 <a title="13-lsi-14" href="./nips-2004-Hierarchical_Eigensolver_for_Transition_Matrices_in_Spectral_Methods.html">79 nips-2004-Hierarchical Eigensolver for Transition Matrices in Spectral Methods</a></p>
<p>15 0.43919122 <a title="13-lsi-15" href="./nips-2004-Adaptive_Discriminative_Generative_Model_and_Its_Applications.html">16 nips-2004-Adaptive Discriminative Generative Model and Its Applications</a></p>
<p>16 0.43054909 <a title="13-lsi-16" href="./nips-2004-Distributed_Occlusion_Reasoning_for_Tracking_with_Nonparametric_Belief_Propagation.html">55 nips-2004-Distributed Occlusion Reasoning for Tracking with Nonparametric Belief Propagation</a></p>
<p>17 0.4284752 <a title="13-lsi-17" href="./nips-2004-Proximity_Graphs_for_Clustering_and_Manifold_Learning.html">150 nips-2004-Proximity Graphs for Clustering and Manifold Learning</a></p>
<p>18 0.4227058 <a title="13-lsi-18" href="./nips-2004-Sampling_Methods_for_Unsupervised_Learning.html">158 nips-2004-Sampling Methods for Unsupervised Learning</a></p>
<p>19 0.41018346 <a title="13-lsi-19" href="./nips-2004-Detecting_Significant_Multidimensional_Spatial_Clusters.html">51 nips-2004-Detecting Significant Multidimensional Spatial Clusters</a></p>
<p>20 0.40767711 <a title="13-lsi-20" href="./nips-2004-The_power_of_feature_clustering%3A_An_application_to_object_detection.html">192 nips-2004-The power of feature clustering: An application to object detection</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2004_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.059), (15, 0.61), (26, 0.04), (33, 0.127), (35, 0.019), (39, 0.01), (50, 0.025), (76, 0.01)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.99126226 <a title="13-lda-1" href="./nips-2004-Dependent_Gaussian_Processes.html">50 nips-2004-Dependent Gaussian Processes</a></p>
<p>Author: Phillip Boyle, Marcus Frean</p><p>Abstract: Gaussian processes are usually parameterised in terms of their covariance functions. However, this makes it difﬁcult to deal with multiple outputs, because ensuring that the covariance matrix is positive deﬁnite is problematic. An alternative formulation is to treat Gaussian processes as white noise sources convolved with smoothing kernels, and to parameterise the kernel instead. Using this, we extend Gaussian processes to handle multiple, coupled outputs. 1</p><p>2 0.98511928 <a title="13-lda-2" href="./nips-2004-Efficient_Kernel_Discriminant_Analysis_via_QR_Decomposition.html">59 nips-2004-Efficient Kernel Discriminant Analysis via QR Decomposition</a></p>
<p>Author: Tao Xiong, Jieping Ye, Qi Li, Ravi Janardan, Vladimir Cherkassky</p><p>Abstract: Linear Discriminant Analysis (LDA) is a well-known method for feature extraction and dimension reduction. It has been used widely in many applications such as face recognition. Recently, a novel LDA algorithm based on QR Decomposition, namely LDA/QR, has been proposed, which is competitive in terms of classiﬁcation accuracy with other LDA algorithms, but it has much lower costs in time and space. However, LDA/QR is based on linear projection, which may not be suitable for data with nonlinear structure. This paper ﬁrst proposes an algorithm called KDA/QR, which extends the LDA/QR algorithm to deal with nonlinear data by using the kernel operator. Then an efﬁcient approximation of KDA/QR called AKDA/QR is proposed. Experiments on face image data show that the classiﬁcation accuracy of both KDA/QR and AKDA/QR are competitive with Generalized Discriminant Analysis (GDA), a general kernel discriminant analysis algorithm, while AKDA/QR has much lower time and space costs. 1</p><p>same-paper 3 0.98035407 <a title="13-lda-3" href="./nips-2004-A_Three_Tiered_Approach_for_Articulated_Object_Action_Modeling_and_Recognition.html">13 nips-2004-A Three Tiered Approach for Articulated Object Action Modeling and Recognition</a></p>
<p>Author: Le Lu, Gregory D. Hager, Laurent Younes</p><p>Abstract: Visual action recognition is an important problem in computer vision. In this paper, we propose a new method to probabilistically model and recognize actions of articulated objects, such as hand or body gestures, in image sequences. Our method consists of three levels of representation. At the low level, we ﬁrst extract a feature vector invariant to scale and in-plane rotation by using the Fourier transform of a circular spatial histogram. Then, spectral partitioning [20] is utilized to obtain an initial clustering; this clustering is then reﬁned using a temporal smoothness constraint. Gaussian mixture model (GMM) based clustering and density estimation in the subspace of linear discriminant analysis (LDA) are then applied to thousands of image feature vectors to obtain an intermediate level representation. Finally, at the high level we build a temporal multiresolution histogram model for each action by aggregating the clustering weights of sampled images belonging to that action. We discuss how this high level representation can be extended to achieve temporal scaling invariance and to include Bi-gram or Multi-gram transition information. Both image clustering and action recognition/segmentation results are given to show the validity of our three tiered representation.</p><p>4 0.97223735 <a title="13-lda-4" href="./nips-2004-Validity_Estimates_for_Loopy_Belief_Propagation_on_Binary_Real-world_Networks.html">203 nips-2004-Validity Estimates for Loopy Belief Propagation on Binary Real-world Networks</a></p>
<p>Author: Joris M. Mooij, Hilbert J. Kappen</p><p>Abstract: We introduce a computationally efﬁcient method to estimate the validity of the BP method as a function of graph topology, the connectivity strength, frustration and network size. We present numerical results that demonstrate the correctness of our estimates for the uniform random model and for a real-world network (“C. Elegans”). Although the method is restricted to pair-wise interactions, no local evidence (zero “biases”) and binary variables, we believe that its predictions correctly capture the limitations of BP for inference and MAP estimation on arbitrary graphical models. Using this approach, we ﬁnd that BP always performs better than MF. Especially for large networks with broad degree distributions (such as scale-free networks) BP turns out to signiﬁcantly outperform MF. 1</p><p>5 0.94602674 <a title="13-lda-5" href="./nips-2004-Kernel_Methods_for_Implicit_Surface_Modeling.html">92 nips-2004-Kernel Methods for Implicit Surface Modeling</a></p>
<p>Author: Joachim Giesen, Simon Spalinger, Bernhard Schölkopf</p><p>Abstract: We describe methods for computing an implicit model of a hypersurface that is given only by a ﬁnite sampling. The methods work by mapping the sample points into a reproducing kernel Hilbert space and then determining regions in terms of hyperplanes. 1</p><p>6 0.94058204 <a title="13-lda-6" href="./nips-2004-Two-Dimensional_Linear_Discriminant_Analysis.html">197 nips-2004-Two-Dimensional Linear Discriminant Analysis</a></p>
<p>7 0.93687183 <a title="13-lda-7" href="./nips-2004-Temporal-Difference_Networks.html">183 nips-2004-Temporal-Difference Networks</a></p>
<p>8 0.87198305 <a title="13-lda-8" href="./nips-2004-A_Method_for_Inferring_Label_Sampling_Mechanisms_in_Semi-Supervised_Learning.html">9 nips-2004-A Method for Inferring Label Sampling Mechanisms in Semi-Supervised Learning</a></p>
<p>9 0.8176226 <a title="13-lda-9" href="./nips-2004-Using_the_Equivalent_Kernel_to_Understand_Gaussian_Process_Regression.html">201 nips-2004-Using the Equivalent Kernel to Understand Gaussian Process Regression</a></p>
<p>10 0.81050193 <a title="13-lda-10" href="./nips-2004-Probabilistic_Computation_in_Spiking_Populations.html">148 nips-2004-Probabilistic Computation in Spiking Populations</a></p>
<p>11 0.8008526 <a title="13-lda-11" href="./nips-2004-Semigroup_Kernels_on_Finite_Sets.html">168 nips-2004-Semigroup Kernels on Finite Sets</a></p>
<p>12 0.80047643 <a title="13-lda-12" href="./nips-2004-Hierarchical_Eigensolver_for_Transition_Matrices_in_Spectral_Methods.html">79 nips-2004-Hierarchical Eigensolver for Transition Matrices in Spectral Methods</a></p>
<p>13 0.79167515 <a title="13-lda-13" href="./nips-2004-The_Laplacian_PDF_Distance%3A_A_Cost_Function_for_Clustering_in_a_Kernel_Feature_Space.html">188 nips-2004-The Laplacian PDF Distance: A Cost Function for Clustering in a Kernel Feature Space</a></p>
<p>14 0.76966435 <a title="13-lda-14" href="./nips-2004-Support_Vector_Classification_with_Input_Data_Uncertainty.html">178 nips-2004-Support Vector Classification with Input Data Uncertainty</a></p>
<p>15 0.76769292 <a title="13-lda-15" href="./nips-2004-Binet-Cauchy_Kernels.html">30 nips-2004-Binet-Cauchy Kernels</a></p>
<p>16 0.76745033 <a title="13-lda-16" href="./nips-2004-Matrix_Exponential_Gradient_Updates_for_On-line_Learning_and_Bregman_Projection.html">110 nips-2004-Matrix Exponential Gradient Updates for On-line Learning and Bregman Projection</a></p>
<p>17 0.76478952 <a title="13-lda-17" href="./nips-2004-Kernels_for_Multi--task_Learning.html">94 nips-2004-Kernels for Multi--task Learning</a></p>
<p>18 0.75992531 <a title="13-lda-18" href="./nips-2004-Learning_Gaussian_Process_Kernels_via_Hierarchical_Bayes.html">98 nips-2004-Learning Gaussian Process Kernels via Hierarchical Bayes</a></p>
<p>19 0.75660747 <a title="13-lda-19" href="./nips-2004-Algebraic_Set_Kernels_with_Application_to_Inference_Over_Local_Image_Representations.html">18 nips-2004-Algebraic Set Kernels with Application to Inference Over Local Image Representations</a></p>
<p>20 0.75538594 <a title="13-lda-20" href="./nips-2004-Distributed_Occlusion_Reasoning_for_Tracking_with_Nonparametric_Belief_Propagation.html">55 nips-2004-Distributed Occlusion Reasoning for Tracking with Nonparametric Belief Propagation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
