<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>99 nips-2004-Learning Hyper-Features for Visual Identification</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2004" href="../home/nips2004_home.html">nips2004</a> <a title="nips-2004-99" href="#">nips2004-99</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>99 nips-2004-Learning Hyper-Features for Visual Identification</h1>
<br/><p>Source: <a title="nips-2004-99-pdf" href="http://papers.nips.cc/paper/2735-learning-hyper-features-for-visual-identification.pdf">pdf</a></p><p>Author: Andras D. Ferencz, Erik G. Learned-miller, Jitendra Malik</p><p>Abstract: We address the problem of identifying speciﬁc instances of a class (cars) from a set of images all belonging to that class. Although we cannot build a model for any particular instance (as we may be provided with only one “training” example of it), we can use information extracted from observing other members of the class. We pose this task as a learning problem, in which the learner is given image pairs, labeled as matching or not, and must discover which image features are most consistent for matching instances and discriminative for mismatches. We explore a patch based representation, where we model the distributions of similarity measurements deﬁned on the patches. Finally, we describe an algorithm that selects the most salient patches based on a mutual information criterion. This algorithm performs identiﬁcation well for our challenging dataset of car images, after matching only a few, well chosen patches. 1</p><p>Reference: <a title="nips-2004-99-reference" href="../nips2004_reference/nips-2004-Learning_Hyper-Features_for_Visual_Identification_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('patch', 0.624), ('fjl', 0.415), ('dj', 0.397), ('im', 0.168), ('fjr', 0.153), ('match', 0.138), ('car', 0.131), ('rj', 0.13), ('query', 0.12), ('zj', 0.093), ('glm', 0.087), ('camer', 0.087), ('fj', 0.084), ('saly', 0.08), ('gamm', 0.064), ('fm', 0.061), ('align', 0.061), ('categ', 0.059), ('ident', 0.059), ('appear', 0.059)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="99-tfidf-1" href="./nips-2004-Learning_Hyper-Features_for_Visual_Identification.html">99 nips-2004-Learning Hyper-Features for Visual Identification</a></p>
<p>2 0.29777396 <a title="99-tfidf-2" href="./nips-2004-Seeing_through_water.html">160 nips-2004-Seeing through water</a></p>
<p>3 0.24576215 <a title="99-tfidf-3" href="./nips-2004-Conditional_Random_Fields_for_Object_Recognition.html">44 nips-2004-Conditional Random Fields for Object Recognition</a></p>
<p>4 0.19469693 <a title="99-tfidf-4" href="./nips-2004-Assignment_of_Multiplicative_Mixtures_in_Natural_Images.html">25 nips-2004-Assignment of Multiplicative Mixtures in Natural Images</a></p>
<p>5 0.17054498 <a title="99-tfidf-5" href="./nips-2004-The_power_of_feature_clustering%3A_An_application_to_object_detection.html">192 nips-2004-The power of feature clustering: An application to object detection</a></p>
<p>6 0.16029198 <a title="99-tfidf-6" href="./nips-2004-Face_Detection_---_Efficient_and_Rank_Deficient.html">68 nips-2004-Face Detection --- Efficient and Rank Deficient</a></p>
<p>7 0.14200655 <a title="99-tfidf-7" href="./nips-2004-Common-Frame_Model_for_Object_Recognition.html">40 nips-2004-Common-Frame Model for Object Recognition</a></p>
<p>8 0.14193195 <a title="99-tfidf-8" href="./nips-2004-Modeling_Nonlinear_Dependencies_in_Natural_Images_using_Mixture_of_Laplacian_Distribution.html">121 nips-2004-Modeling Nonlinear Dependencies in Natural Images using Mixture of Laplacian Distribution</a></p>
<p>9 0.11813187 <a title="99-tfidf-9" href="./nips-2004-Discriminant_Saliency_for_Visual_Recognition_from_Cluttered_Scenes.html">53 nips-2004-Discriminant Saliency for Visual Recognition from Cluttered Scenes</a></p>
<p>10 0.11330435 <a title="99-tfidf-10" href="./nips-2004-Analysis_of_a_greedy_active_learning_strategy.html">23 nips-2004-Analysis of a greedy active learning strategy</a></p>
<p>11 0.10928218 <a title="99-tfidf-11" href="./nips-2004-Instance-Based_Relevance_Feedback_for_Image_Retrieval.html">85 nips-2004-Instance-Based Relevance Feedback for Image Retrieval</a></p>
<p>12 0.092797942 <a title="99-tfidf-12" href="./nips-2004-Object_Classification_from_a_Single_Example_Utilizing_Class_Relevance_Metrics.html">134 nips-2004-Object Classification from a Single Example Utilizing Class Relevance Metrics</a></p>
<p>13 0.092728235 <a title="99-tfidf-13" href="./nips-2004-Contextual_Models_for_Object_Detection_Using_Boosted_Random_Fields.html">47 nips-2004-Contextual Models for Object Detection Using Boosted Random Fields</a></p>
<p>14 0.0875341 <a title="99-tfidf-14" href="./nips-2004-A_Three_Tiered_Approach_for_Articulated_Object_Action_Modeling_and_Recognition.html">13 nips-2004-A Three Tiered Approach for Articulated Object Action Modeling and Recognition</a></p>
<p>15 0.086547688 <a title="99-tfidf-15" href="./nips-2004-Joint_MRI_Bias_Removal_Using_Entropy_Minimization_Across_Images.html">89 nips-2004-Joint MRI Bias Removal Using Entropy Minimization Across Images</a></p>
<p>16 0.084692031 <a title="99-tfidf-16" href="./nips-2004-Computing_regularization_paths_for_learning_multiple_kernels.html">42 nips-2004-Computing regularization paths for learning multiple kernels</a></p>
<p>17 0.075972915 <a title="99-tfidf-17" href="./nips-2004-Inference%2C_Attention%2C_and_Decision_in_a_Bayesian_Neural_Architecture.html">84 nips-2004-Inference, Attention, and Decision in a Bayesian Neural Architecture</a></p>
<p>18 0.074175514 <a title="99-tfidf-18" href="./nips-2004-Incremental_Learning_for_Visual_Tracking.html">83 nips-2004-Incremental Learning for Visual Tracking</a></p>
<p>19 0.065774702 <a title="99-tfidf-19" href="./nips-2004-Synergistic_Face_Detection_and_Pose_Estimation_with_Energy-Based_Models.html">182 nips-2004-Synergistic Face Detection and Pose Estimation with Energy-Based Models</a></p>
<p>20 0.065279774 <a title="99-tfidf-20" href="./nips-2004-An_Information_Maximization_Model_of_Eye_Movements.html">21 nips-2004-An Information Maximization Model of Eye Movements</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2004_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.206), (1, 0.067), (2, 0.069), (3, -0.231), (4, -0.085), (5, 0.175), (6, -0.225), (7, -0.075), (8, -0.112), (9, -0.085), (10, 0.02), (11, 0.182), (12, 0.068), (13, -0.036), (14, 0.003), (15, 0.028), (16, 0.043), (17, -0.027), (18, -0.09), (19, 0.145), (20, -0.127), (21, -0.032), (22, -0.13), (23, 0.132), (24, 0.066), (25, 0.059), (26, 0.058), (27, 0.009), (28, -0.002), (29, -0.12), (30, -0.092), (31, -0.051), (32, -0.078), (33, 0.11), (34, -0.116), (35, -0.086), (36, 0.034), (37, 0.214), (38, 0.057), (39, -0.072), (40, 0.055), (41, -0.135), (42, 0.047), (43, 0.035), (44, 0.01), (45, -0.043), (46, -0.082), (47, 0.114), (48, 0.009), (49, -0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93773204 <a title="99-lsi-1" href="./nips-2004-Learning_Hyper-Features_for_Visual_Identification.html">99 nips-2004-Learning Hyper-Features for Visual Identification</a></p>
<p>2 0.73050261 <a title="99-lsi-2" href="./nips-2004-Seeing_through_water.html">160 nips-2004-Seeing through water</a></p>
<p>3 0.64951777 <a title="99-lsi-3" href="./nips-2004-Assignment_of_Multiplicative_Mixtures_in_Natural_Images.html">25 nips-2004-Assignment of Multiplicative Mixtures in Natural Images</a></p>
<p>4 0.61706161 <a title="99-lsi-4" href="./nips-2004-Conditional_Random_Fields_for_Object_Recognition.html">44 nips-2004-Conditional Random Fields for Object Recognition</a></p>
<p>5 0.61468804 <a title="99-lsi-5" href="./nips-2004-The_power_of_feature_clustering%3A_An_application_to_object_detection.html">192 nips-2004-The power of feature clustering: An application to object detection</a></p>
<p>6 0.55356324 <a title="99-lsi-6" href="./nips-2004-Common-Frame_Model_for_Object_Recognition.html">40 nips-2004-Common-Frame Model for Object Recognition</a></p>
<p>7 0.4701435 <a title="99-lsi-7" href="./nips-2004-Modeling_Nonlinear_Dependencies_in_Natural_Images_using_Mixture_of_Laplacian_Distribution.html">121 nips-2004-Modeling Nonlinear Dependencies in Natural Images using Mixture of Laplacian Distribution</a></p>
<p>8 0.46267518 <a title="99-lsi-8" href="./nips-2004-Face_Detection_---_Efficient_and_Rank_Deficient.html">68 nips-2004-Face Detection --- Efficient and Rank Deficient</a></p>
<p>9 0.42914629 <a title="99-lsi-9" href="./nips-2004-Instance-Based_Relevance_Feedback_for_Image_Retrieval.html">85 nips-2004-Instance-Based Relevance Feedback for Image Retrieval</a></p>
<p>10 0.42164668 <a title="99-lsi-10" href="./nips-2004-Joint_MRI_Bias_Removal_Using_Entropy_Minimization_Across_Images.html">89 nips-2004-Joint MRI Bias Removal Using Entropy Minimization Across Images</a></p>
<p>11 0.42046246 <a title="99-lsi-11" href="./nips-2004-Discriminant_Saliency_for_Visual_Recognition_from_Cluttered_Scenes.html">53 nips-2004-Discriminant Saliency for Visual Recognition from Cluttered Scenes</a></p>
<p>12 0.37641844 <a title="99-lsi-12" href="./nips-2004-Implicit_Wiener_Series_for_Higher-Order_Image_Analysis.html">81 nips-2004-Implicit Wiener Series for Higher-Order Image Analysis</a></p>
<p>13 0.37582871 <a title="99-lsi-13" href="./nips-2004-Contextual_Models_for_Object_Detection_Using_Boosted_Random_Fields.html">47 nips-2004-Contextual Models for Object Detection Using Boosted Random Fields</a></p>
<p>14 0.32836989 <a title="99-lsi-14" href="./nips-2004-An_Information_Maximization_Model_of_Eye_Movements.html">21 nips-2004-An Information Maximization Model of Eye Movements</a></p>
<p>15 0.3183521 <a title="99-lsi-15" href="./nips-2004-A_Topographic_Support_Vector_Machine%3A_Classification_Using_Local_Label_Configurations.html">14 nips-2004-A Topographic Support Vector Machine: Classification Using Local Label Configurations</a></p>
<p>16 0.31345424 <a title="99-lsi-16" href="./nips-2004-Surface_Reconstruction_using_Learned_Shape_Models.html">179 nips-2004-Surface Reconstruction using Learned Shape Models</a></p>
<p>17 0.30585515 <a title="99-lsi-17" href="./nips-2004-Using_Machine_Learning_to_Break_Visual_Human_Interaction_Proofs_%28HIPs%29.html">199 nips-2004-Using Machine Learning to Break Visual Human Interaction Proofs (HIPs)</a></p>
<p>18 0.30491507 <a title="99-lsi-18" href="./nips-2004-Generative_Affine_Localisation_and_Tracking.html">73 nips-2004-Generative Affine Localisation and Tracking</a></p>
<p>19 0.28065872 <a title="99-lsi-19" href="./nips-2004-A_Three_Tiered_Approach_for_Articulated_Object_Action_Modeling_and_Recognition.html">13 nips-2004-A Three Tiered Approach for Articulated Object Action Modeling and Recognition</a></p>
<p>20 0.27367705 <a title="99-lsi-20" href="./nips-2004-Result_Analysis_of_the_NIPS_2003_Feature_Selection_Challenge.html">156 nips-2004-Result Analysis of the NIPS 2003 Feature Selection Challenge</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2004_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(15, 0.129), (27, 0.056), (37, 0.087), (50, 0.229), (74, 0.174), (77, 0.123), (81, 0.04), (96, 0.034)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.92105728 <a title="99-lda-1" href="./nips-2004-Similarity_and_Discrimination_in_Classical_Conditioning%3A_A_Latent_Variable_Account.html">170 nips-2004-Similarity and Discrimination in Classical Conditioning: A Latent Variable Account</a></p>
<p>2 0.87269443 <a title="99-lda-2" href="./nips-2004-On-Chip_Compensation_of_Device-Mismatch_Effects_in_Analog_VLSI_Neural_Networks.html">135 nips-2004-On-Chip Compensation of Device-Mismatch Effects in Analog VLSI Neural Networks</a></p>
<p>same-paper 3 0.8394143 <a title="99-lda-3" href="./nips-2004-Learning_Hyper-Features_for_Visual_Identification.html">99 nips-2004-Learning Hyper-Features for Visual Identification</a></p>
<p>4 0.74142784 <a title="99-lda-4" href="./nips-2004-Assignment_of_Multiplicative_Mixtures_in_Natural_Images.html">25 nips-2004-Assignment of Multiplicative Mixtures in Natural Images</a></p>
<p>5 0.73953933 <a title="99-lda-5" href="./nips-2004-Spike_Sorting%3A_Bayesian_Clustering_of_Non-Stationary_Data.html">174 nips-2004-Spike Sorting: Bayesian Clustering of Non-Stationary Data</a></p>
<p>6 0.73172843 <a title="99-lda-6" href="./nips-2004-Semi-supervised_Learning_with_Penalized_Probabilistic_Clustering.html">167 nips-2004-Semi-supervised Learning with Penalized Probabilistic Clustering</a></p>
<p>7 0.73157394 <a title="99-lda-7" href="./nips-2004-Joint_Probabilistic_Curve_Clustering_and_Alignment.html">90 nips-2004-Joint Probabilistic Curve Clustering and Alignment</a></p>
<p>8 0.73108745 <a title="99-lda-8" href="./nips-2004-A_Three_Tiered_Approach_for_Articulated_Object_Action_Modeling_and_Recognition.html">13 nips-2004-A Three Tiered Approach for Articulated Object Action Modeling and Recognition</a></p>
<p>9 0.72826082 <a title="99-lda-9" href="./nips-2004-The_power_of_feature_clustering%3A_An_application_to_object_detection.html">192 nips-2004-The power of feature clustering: An application to object detection</a></p>
<p>10 0.72820097 <a title="99-lda-10" href="./nips-2004-An_Information_Maximization_Model_of_Eye_Movements.html">21 nips-2004-An Information Maximization Model of Eye Movements</a></p>
<p>11 0.72739089 <a title="99-lda-11" href="./nips-2004-Adaptive_Discriminative_Generative_Model_and_Its_Applications.html">16 nips-2004-Adaptive Discriminative Generative Model and Its Applications</a></p>
<p>12 0.72590005 <a title="99-lda-12" href="./nips-2004-Synergistic_Face_Detection_and_Pose_Estimation_with_Energy-Based_Models.html">182 nips-2004-Synergistic Face Detection and Pose Estimation with Energy-Based Models</a></p>
<p>13 0.7251085 <a title="99-lda-13" href="./nips-2004-Conditional_Random_Fields_for_Object_Recognition.html">44 nips-2004-Conditional Random Fields for Object Recognition</a></p>
<p>14 0.72369826 <a title="99-lda-14" href="./nips-2004-Generative_Affine_Localisation_and_Tracking.html">73 nips-2004-Generative Affine Localisation and Tracking</a></p>
<p>15 0.72344577 <a title="99-lda-15" href="./nips-2004-Discriminant_Saliency_for_Visual_Recognition_from_Cluttered_Scenes.html">53 nips-2004-Discriminant Saliency for Visual Recognition from Cluttered Scenes</a></p>
<p>16 0.72172958 <a title="99-lda-16" href="./nips-2004-Inference%2C_Attention%2C_and_Decision_in_a_Bayesian_Neural_Architecture.html">84 nips-2004-Inference, Attention, and Decision in a Bayesian Neural Architecture</a></p>
<p>17 0.71926379 <a title="99-lda-17" href="./nips-2004-Incremental_Learning_for_Visual_Tracking.html">83 nips-2004-Incremental Learning for Visual Tracking</a></p>
<p>18 0.7191003 <a title="99-lda-18" href="./nips-2004-Sharing_Clusters_among_Related_Groups%3A_Hierarchical_Dirichlet_Processes.html">169 nips-2004-Sharing Clusters among Related Groups: Hierarchical Dirichlet Processes</a></p>
<p>19 0.71897107 <a title="99-lda-19" href="./nips-2004-Multiple_Alignment_of_Continuous_Time_Series.html">124 nips-2004-Multiple Alignment of Continuous Time Series</a></p>
<p>20 0.71895504 <a title="99-lda-20" href="./nips-2004-Common-Frame_Model_for_Object_Recognition.html">40 nips-2004-Common-Frame Model for Object Recognition</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
