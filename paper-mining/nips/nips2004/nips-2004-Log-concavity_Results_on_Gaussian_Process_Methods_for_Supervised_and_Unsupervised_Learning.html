<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>105 nips-2004-Log-concavity Results on Gaussian Process Methods for Supervised and Unsupervised Learning</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2004" href="../home/nips2004_home.html">nips2004</a> <a title="nips-2004-105" href="#">nips2004-105</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>105 nips-2004-Log-concavity Results on Gaussian Process Methods for Supervised and Unsupervised Learning</h1>
<br/><p>Source: <a title="nips-2004-105-pdf" href="http://papers.nips.cc/paper/2590-log-concavity-results-on-gaussian-process-methods-for-supervised-and-unsupervised-learning.pdf">pdf</a></p><p>Author: Liam Paninski</p><p>Abstract: Log-concavity is an important property in the context of optimization, Laplace approximation, and sampling; Bayesian methods based on Gaussian process priors have become quite popular recently for classiﬁcation, regression, density estimation, and point process intensity estimation. Here we prove that the predictive densities corresponding to each of these applications are log-concave, given any observed data. We also prove that the likelihood is log-concave in the hyperparameters controlling the mean function of the Gaussian prior in the density and point process intensity estimation cases, and the mean, covariance, and observation noise parameters in the classiﬁcation and regression cases; this result leads to a useful parameterization of these hyperparameters, indicating a suitably large class of priors for which the corresponding maximum a posteriori problem is log-concave.</p><p>Reference: <a title="nips-2004-105-reference" href="../nips2004_reference/nips-2004-Log-concavity_Results_on_Gaussian_Process_Methods_for_Supervised_and_Unsupervised_Learning_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Log-concavity results on Gaussian process methods for supervised and unsupervised learning  Liam Paninski Gatsby Computational Neuroscience Unit University College London liam@gatsby. [sent-1, score-0.256]
</p><p>2 Here we prove that the predictive densities corresponding to each of these applications are log-concave, given any observed data. [sent-9, score-0.276]
</p><p>3 Introduction Bayesian methods based on Gaussian process priors have recently become quite popular for machine learning tasks (1). [sent-11, score-0.158]
</p><p>4 We contribute to this theoretical literature here by presenting results on the log-concavity of the predictive densities and likelihood associated with several of these methods, speciﬁcally techniques for classiﬁcation, regression, density estimation, and point process intensity estimation. [sent-15, score-0.665]
</p><p>5 These results, in turn, imply that it is relatively easy to tune the hyperparameters for, approximate the posterior distributions of, and sample from these models. [sent-16, score-0.121]
</p><p>6 ) functions, and the key theorem on which our results are based. [sent-20, score-0.055]
</p><p>7 Log-concavity is perhaps most important in a maximization context: given a real function f ofsome vector parameter θ, if g(f (θ)) is concave for some invertible function g, and the parameters θ live in some convex set, then f is unimodal, with no non-global local maxima. [sent-21, score-0.203]
</p><p>8 (Note that in this case a global maximum, if one exists, is not necessarily unique, but maximizers of f do form a convex set, and hence maxima are essentially unique in a sense. [sent-22, score-0.179]
</p><p>9 ) Thus ascent procedures for maximization can be applied without fear of being trapped in local maxima; this is extremely useful when the space to be optimized over is high-dimensional. [sent-23, score-0.046]
</p><p>10 distributions are in general easier to sample from than arbitrary distributions, as discussed in the context of adaptive rejection and slice sampling (7, 8) and the randomwalk-based samplers analyzed in (9). [sent-28, score-0.11]
</p><p>11 probability densities necessarily have exponential tails (ruling out power law tails, and more generally distributions with any inﬁnite moments). [sent-31, score-0.212]
</p><p>12 densities must be continuous on the interior of their support. [sent-34, score-0.104]
</p><p>13 functions are as follows: the Gaussian density in any dimension; the indicator of any convex set (e. [sent-40, score-0.387]
</p><p>14 , the uniform density over any convex, compact set); the exponential density; the linear half-rectiﬁer. [sent-42, score-0.134]
</p><p>15 More interesting well-known examples include the determinant of a matrix, or the inverse partition function of an energybased probabilistic model (e. [sent-43, score-0.035]
</p><p>16 Finally, log-concavity is preserved under taking products (as noted above), afﬁne translations of the domain, and/or pointwise limits, since concavity is preserved under addition, afﬁne translations, and pointwise limits, respectively. [sent-48, score-0.45]
</p><p>17 , a mixture of Gaussians with widely-separated means, or the indicator of the union of disjoint convex sets). [sent-55, score-0.203]
</p><p>18 However, a key theorem (10, 11) gives: Theorem (Integrating out preserves log-concavity). [sent-56, score-0.105]
</p><p>19 Think of y as a latent variable or hyperparameter we want to marginalize over. [sent-62, score-0.052]
</p><p>20 This very useful fact has seen applications in various branches of statistics and operations research, but does not seem well-known in the machine learning community. [sent-63, score-0.076]
</p><p>21 The theorem implies, for example, that convolutions of l. [sent-64, score-0.055]
</p><p>22 ; hence the error function, and more generally the cumulative distribution function of any l. [sent-75, score-0.031]
</p><p>23 , which is useful in the setting of generalized linear models (12) for classiﬁcation. [sent-79, score-0.046]
</p><p>24 probability measure of a convex set which is translated in a convex manner is itself a l. [sent-82, score-0.27]
</p><p>25 Gaussian process methods background We now give a brief review of Gaussian process methods. [sent-85, score-0.21]
</p><p>26 Gaussian process methods are based on a Bayesian “latent variable” approach: dependencies between the observed input and output data {ti } and {yi } are modeled as arising through a hidden (unobserved) Gaussian process G(t). [sent-90, score-0.21]
</p><p>27 Recall that a Gaussian process is a stochastic process whose ﬁnite-dimensional projections are all multivariate Gaussian, with means and covariances deﬁned consistently for all possible projections, and is therefore speciﬁed by its mean µ(t) and covariance function C(t1 , t2 ). [sent-91, score-0.385]
</p><p>28 We discuss the somewhat simpler unsupervised case ﬁrst (however, it should be noted that the supervised cases have received signiﬁcantly more attention in the machine learning literature to date, and might be considered of more importance to this community). [sent-93, score-0.183]
</p><p>29 Density estimation: We are given unordered data {ti }; the setup is valid for any sample space, but assume ti ∈ d , d < ∞, for concreteness. [sent-94, score-0.738]
</p><p>30 It is worth emphasizing that this setup differs somewhat from some earlier proposals (5,14,15), which postulated that nonnegativity be enforced by, √ e. [sent-102, score-0.101]
</p><p>31 The only difference is that intensity functions are not required to be normalized, so we need only condition the Gaussian process G(t) from which we draw the intensity functions to be nonnegative. [sent-106, score-0.501]
</p><p>32 and convex warping of the range space of the Gaussian process G(t) to enforce positivity; suitable warpings include exponentiation (corresponding to modeling the logarithm of the intensity as Gaussian (17)) or linear half-rectiﬁcation. [sent-109, score-0.492]
</p><p>33 We model the outputs as noise-corrupted observations from the Gaussian process G(t) at the points {ti }; denote the additional hidden “observation” noise process as {n(ti )}. [sent-112, score-0.278]
</p><p>34 This noise process is not always taken to be Gaussian; for computational reasons, {n(ti )} is typically assumed i. [sent-113, score-0.173]
</p><p>35 Regression: We assume y(ti ) = G(ti ) + σi n(ti ); in words, draw G(t) from a Gaussian process of mean µ(t) and covariance C; the outputs are then obtained by sampling this function G(t) at ti and adding noise n(ti ) of scale σi . [sent-117, score-1.008]
</p><p>36 This case is as in the regression model, except we only observe a binarythresholded version of the real output. [sent-120, score-0.055]
</p><p>37 Results Our ﬁrst result concerns the predictive densities associated with the above models: the posterior density of any continuous linear functional of G(t), given observed data D = {ti } and/or {yi }, under the Gaussian process prior for G(t). [sent-121, score-0.482]
</p><p>38 The simplest and most important case of such a linear projection is the projection onto a ﬁnite collection of coordinates, {tpred }, say; in this special case, the predictive density is the posterior density p({G(tpred )}|D). [sent-122, score-0.376]
</p><p>39 It turns out that all we need to assume is the log-concavity of the distribution p(G, n); this is clearly more general than what is needed for the strictly Gaussian cases considered above (for example, Laplacian priors on G are permitted, which could lead to more robust performance). [sent-123, score-0.085]
</p><p>40 Also note that dependence of (G, n) is allowed; this permits, for example, coupling of the effective scales of the observation noise ni = n(ti ) for nearby points ti . [sent-124, score-0.825]
</p><p>41 Additonally, we allow nonstationarity and anisotropic correlations in G. [sent-125, score-0.049]
</p><p>42 prior on (G, n), the predictive density is always l. [sent-130, score-0.242]
</p><p>43 In other words, conditioning on data preserves these l. [sent-133, score-0.114]
</p><p>44 This represents a signiﬁcant generalization of the obvious fact that in the regression setup under Gaussian noise, conditioning preserves Gaussian processes. [sent-138, score-0.24]
</p><p>45 Our second result applies to the likelihood of the hyperparameters corresponding to the above applications: the mean function µ, the covariance function C, and the observation noise scales {σi }. [sent-139, score-0.391]
</p><p>46 We ﬁrst state the main result in some generality, then provide some useful examples and interpretation below. [sent-140, score-0.046]
</p><p>47 For each j > 0, let Aj,θ denote a family of linear maps from some ﬁnite-dimensional vector space Gj to N dG , where dG = dim(G(ti )), and N is the number of observed data points. [sent-141, score-0.061]
</p><p>48 Our main assumptions are as follows: ﬁrst, assume A−1 may be written A−1 = θk Kj,k , where {Kj,k } is a ﬁxed set of matrices j,θ j,θ and the inverse is deﬁned as a map from range(Aj,θ ) to Gj /ker(Aj,θ ). [sent-142, score-0.035]
</p><p>49 Finally, equip the (doubly) latent space j,θ  Gj × N dG = {(GL , n)} with a translation family of l. [sent-144, score-0.113]
</p><p>50 measures pj,µL (GL , n) indexed by the mean parameter µL , i. [sent-146, score-0.067]
</p><p>51 , pj,µL (GL , n) = pj ((GL , n) − µL ), for some ﬁxed measure pj (. [sent-148, score-0.2]
</p><p>52 Then if the sequence pj (G, n) induced by pj and Aj converges pointwise to the joint density p(G, n), then: Proposition 2 (Likelihood). [sent-150, score-0.428]
</p><p>53 In the supervised cases, the likelihood is jointly l. [sent-151, score-0.22]
</p><p>54 in the −1 latent mean function, covariance parameters, and inverse noise scales (µL , θ, {σi }), for  all data D. [sent-153, score-0.329]
</p><p>55 Of course, in practice, it is likely that to avoid overﬁtting one would want to reduce the effective number of free parameters by representing µ(t) and θ in ﬁnitedimensional spaces, and restricting the freedom of the inverse noise scales {σi }. [sent-158, score-0.14]
</p><p>56 ) Thus Proposition 2 generalizes a recent neuroscientiﬁc result: the likelihood for a certain neural model (the leaky integrate-and-ﬁre model driven by Gaussian noise, for which the corresponding covariance is Ornstein-Uhlenbeck) is l. [sent-166, score-0.165]
</p><p>57 In addition, multidimensional generalizations of this family are straightforward: corresponding kernels solve the Helmholtz problem, (I − a∆)C(t) = bδ(t), with ∆ denoting the Laplacian. [sent-169, score-0.127]
</p><p>58 Solutions to this problem are well-known: in the isotropic case, we obtain a family of radial Bessel functions, with a, b again setting the overall magnitude and correlation scale of C(t1 , t2 ) = C(||t1 − t2 ||2 ). [sent-170, score-0.061]
</p><p>59 Generalizing in a different direction, we could let Aθ include higher-order differential terms, A−1 = k=0 θk Dk ; the θ resulting covariance kernels correspond to higher-order autoregression process priors. [sent-171, score-0.241]
</p><p>60 An even broader class of kernel parameterizations may be developed in the spectral domain: still assuming stationary white noise inputs, we may diagonalize C in the Fourier basis, that is, C(ω) = Ot P (ω)O, with O the (unitary) Fourier transform operator and P (ω) the power spectral density. [sent-172, score-0.178]
</p><p>61 Thus, comparing to the conditions above, if the spectral density may be written as P (ω)−1 = | k θk hk (ω)|2 (where |. [sent-173, score-0.263]
</p><p>62 | denotes complex magnitude), for θk > 0 and functions hk (ω) such that sign(real(hk (ω))) is constant in k for any ω, then the likelihood will be l. [sent-174, score-0.205]
</p><p>63 in θ; Aθ here may be taken as the multiplication operator  Ot ( k θk hk (ω))−1 ). [sent-176, score-0.127]
</p><p>64 Remember that the smoothness of the sample paths of G(t) depends on the rate of decay of the spectral density (1,23); thus we may obtain smoother (or rougher) kernel families by choosing k θk hk (ω) as more rapidly- (or slowly-)increasing. [sent-177, score-0.313]
</p><p>65 This proof is a straightforward application of the Prekopa theorem (10). [sent-179, score-0.086]
</p><p>66 Now we need only prove that the multiplicands on the right hand side above are l. [sent-181, score-0.09]
</p><p>67 The log-concavity of the left term is assumed; the right term, in turn, can be rewritten as p({yi , ti }|{Lk G}, {G(ti ), n(ti )}) = p({yi , ti }|{G(ti ), n(ti )}), by the Markovian nature of the models. [sent-183, score-1.334]
</p><p>68 We prove the log-concavity of the right individually for each of our applications. [sent-184, score-0.034]
</p><p>69 In the supervised cases, {ti } is given and so we only need to look at p({yi }|{G(ti ), n(ti )}). [sent-185, score-0.076]
</p><p>70 In the classiﬁcation case, this is simply an indicator of the set G(ti ) + σi ni i  ≤ 0, yi = 0 > 0, yi = 1  ,  which is jointly convex in {G(ti ), n(ti )}, completing the proof in this case. [sent-186, score-0.5]
</p><p>71 The regression case is proven in a similar fashion: write p({yi }|{G(ti ), n(ti )}) as the limit as → 0 of the indicator of the convex set i  (|G(ti ) + σi ni − yi | < ) ,  then use the fact that pointwise limits preserve log-concavity. [sent-187, score-0.61]
</p><p>72 (The predictive distributions of {y(t)} will also be l. [sent-188, score-0.146]
</p><p>73 ) In the density estimation case, the term p({ti }|{G(ti )}) =  G(ti ) i  is obviously l. [sent-191, score-0.171]
</p><p>74 However, recall that we perturbed the distribution of G(t) in this case as well, by conditioning G(t) to be positive and normalized. [sent-194, score-0.064]
</p><p>75 follows upon writing this term as a marginalization of densities which are products of l. [sent-197, score-0.173]
</p><p>76 densities with indicators of convex sets (enforcing the linear normalization and positivity constraints). [sent-199, score-0.345]
</p><p>77 Finally, for the point process intensity case, write the likelihood term, as usual, p({ti }|{G(ti )}) = e−  R  f (G(t))dt  f (G(ti )), i  where f is the scalar warping function that takes the original Gaussian function G(t) into the space of intensity functions. [sent-200, score-0.56]
</p><p>78 In the density estimation case, write the likelihood as L(µ) = dpµ (G)1C ({G(t)}) G(ti ), i  with pµ (G) the probability of G under µ. [sent-210, score-0.274]
</p><p>79 ) indicator function of the convex set enforcing the linear constraints (positivity and normalization) on G. [sent-213, score-0.24]
</p><p>80 All three terms in the integrand on the right are clearly jointly l. [sent-214, score-0.078]
</p><p>81 In the point process case, L(µ) =  dpµ (G)e−  R  f (G(t))dt  f (G(ti )); i  the joint log-concavity of the three multiplicands on the right is again easily demonstrated. [sent-217, score-0.161]
</p><p>82 R  The Prekopa theorem cannot be directly applied here, since the functions 1C (. [sent-218, score-0.105]
</p><p>83 ) depend in an inﬁnite-dimensional way on G and µ; however, we can apply the Prekopa theorem to any ﬁnite-dimensional approximation of these functions (e. [sent-220, score-0.105]
</p><p>84 , by approximating the normalization condition and exponential integral by Riemann sums and the positivity condition at a ﬁnite number of points), then obtain the theorem in the limit as the approximation becomes inﬁnitely ﬁne, using the fact that pointwise limits preserve log-concavity. [sent-222, score-0.34]
</p><p>85 For the supervised cases, write L(µL , θ, {σ −1 })  =  lim  dpj (GL , n)1 Aj,θ (GL + µG ) + σ. [sent-223, score-0.191]
</p><p>86 (n + µn ) ∈ V L L  =  lim  dpj (GL , n)1 (GL , n) ∈ (  j  j  θk Kj,k V, σ. [sent-224, score-0.078]
</p><p>87 V ) + µL , k  with V an appropriate convex constraint set (or limit thereof) deﬁned by the observed data {yi }, µG and µn the projection of µL into Gj or N dG , respectively, and . [sent-226, score-0.166]
</p><p>88 The result now follows immediately from Rinott’s theorem on convex translations of sets under l. [sent-228, score-0.249]
</p><p>89 Again, we have not assumed anything more about p(GL , n) than log-concavity; as before, this allows dependence of G and n, anisotropic correlations, etc. [sent-231, score-0.049]
</p><p>90 Extensions to ensure that the unsupervised likelihood is l. [sent-233, score-0.141]
</p><p>91 Discussion We have provided some useful results on the log-concavity of the predictive densities and likelihoods associated with several common Gaussian process methods for machine learning. [sent-236, score-0.363]
</p><p>92 In particular, our results preclude the existence of non-global local maxima in these functions, for any observed data; moreover, Laplace approximations of these functions will not, in general, be disastrous, and efﬁcient sampling methods are available. [sent-237, score-0.125]
</p><p>93 Perhaps the main practical implication of our results stems from our proposition on the likelihood; we recommend a certain simple way to obtain parameterized families of kernels which respect this log-concavity property. [sent-238, score-0.149]
</p><p>94 Kernel families which may be obtained in this manner can range from extremely smooth to singular, and may model anisotropies  ﬂexibly. [sent-239, score-0.05]
</p><p>95 Finally, these results indicate useful classes of constraints (or more generally, regularizing priors) on the hyperparameters; any prior which is l. [sent-240, score-0.046]
</p><p>96 (or any constraint set which is convex) in the parameterization discussed here will lead to l. [sent-242, score-0.047]
</p><p>97 More generally, we have introduced some straightforward applications of a useful and interesting theorem. [sent-245, score-0.107]
</p><p>98 Minka, A family of algorithms for approximate bayesian inference, Ph. [sent-277, score-0.093]
</p><p>99 Vempala, The geometry of logconcave functions and an O∗ (n3 ) sampling algorithm, Tech. [sent-290, score-0.081]
</p><p>100 Neal, Monte Carlo implementation of Gaussian process models for Bayesian regression and classiﬁcation, Tech. [sent-334, score-0.16]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ti', 0.667), ('gl', 0.155), ('intensity', 0.148), ('prekopa', 0.141), ('convex', 0.135), ('density', 0.134), ('gaussian', 0.116), ('predictive', 0.108), ('lk', 0.107), ('process', 0.105), ('densities', 0.104), ('pj', 0.1), ('covariance', 0.099), ('dg', 0.098), ('pointwise', 0.094), ('hk', 0.089), ('rinott', 0.085), ('paninski', 0.083), ('hyperparameters', 0.083), ('yi', 0.083), ('jointly', 0.078), ('supervised', 0.076), ('aj', 0.075), ('unsupervised', 0.075), ('positivity', 0.075), ('biometrika', 0.074), ('liam', 0.074), ('setup', 0.071), ('noise', 0.068), ('indicator', 0.068), ('gj', 0.066), ('likelihood', 0.066), ('conditioning', 0.064), ('preserved', 0.064), ('proposition', 0.062), ('family', 0.061), ('yk', 0.06), ('translations', 0.059), ('multiplicands', 0.056), ('pillow', 0.056), ('tpred', 0.056), ('warping', 0.056), ('regression', 0.055), ('theorem', 0.055), ('limits', 0.054), ('priors', 0.053), ('ni', 0.053), ('latent', 0.052), ('laplace', 0.05), ('families', 0.05), ('preserves', 0.05), ('functions', 0.05), ('dpj', 0.049), ('anisotropic', 0.049), ('logarithm', 0.048), ('parameterization', 0.047), ('useful', 0.046), ('fourier', 0.045), ('concavity', 0.045), ('maxima', 0.044), ('dim', 0.042), ('context', 0.041), ('spectral', 0.04), ('tails', 0.039), ('marginalization', 0.039), ('lebesgue', 0.039), ('mean', 0.038), ('multiplication', 0.038), ('projections', 0.038), ('distributions', 0.038), ('enforcing', 0.037), ('neal', 0.037), ('kernels', 0.037), ('write', 0.037), ('scales', 0.037), ('estimation', 0.037), ('simoncelli', 0.036), ('inverse', 0.035), ('concave', 0.034), ('ot', 0.034), ('prove', 0.034), ('perhaps', 0.034), ('integrals', 0.033), ('bayesian', 0.032), ('cases', 0.032), ('normalization', 0.031), ('generally', 0.031), ('limit', 0.031), ('concerns', 0.031), ('sampling', 0.031), ('straightforward', 0.031), ('worth', 0.03), ('applications', 0.03), ('white', 0.03), ('products', 0.03), ('posteriori', 0.029), ('lim', 0.029), ('denoting', 0.029), ('limiting', 0.029), ('measures', 0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000008 <a title="105-tfidf-1" href="./nips-2004-Log-concavity_Results_on_Gaussian_Process_Methods_for_Supervised_and_Unsupervised_Learning.html">105 nips-2004-Log-concavity Results on Gaussian Process Methods for Supervised and Unsupervised Learning</a></p>
<p>Author: Liam Paninski</p><p>Abstract: Log-concavity is an important property in the context of optimization, Laplace approximation, and sampling; Bayesian methods based on Gaussian process priors have become quite popular recently for classiﬁcation, regression, density estimation, and point process intensity estimation. Here we prove that the predictive densities corresponding to each of these applications are log-concave, given any observed data. We also prove that the likelihood is log-concave in the hyperparameters controlling the mean function of the Gaussian prior in the density and point process intensity estimation cases, and the mean, covariance, and observation noise parameters in the classiﬁcation and regression cases; this result leads to a useful parameterization of these hyperparameters, indicating a suitably large class of priors for which the corresponding maximum a posteriori problem is log-concave.</p><p>2 0.17423968 <a title="105-tfidf-2" href="./nips-2004-Probabilistic_Computation_in_Spiking_Populations.html">148 nips-2004-Probabilistic Computation in Spiking Populations</a></p>
<p>Author: Richard S. Zemel, Rama Natarajan, Peter Dayan, Quentin J. Huys</p><p>Abstract: As animals interact with their environments, they must constantly update estimates about their states. Bayesian models combine prior probabilities, a dynamical model and sensory evidence to update estimates optimally. These models are consistent with the results of many diverse psychophysical studies. However, little is known about the neural representation and manipulation of such Bayesian information, particularly in populations of spiking neurons. We consider this issue, suggesting a model based on standard neural architecture and activations. We illustrate the approach on a simple random walk example, and apply it to a sensorimotor integration task that provides a particularly compelling example of dynamic probabilistic computation. Bayesian models have been used to explain a gamut of experimental results in tasks which require estimates to be derived from multiple sensory cues. These include a wide range of psychophysical studies of perception;13 motor action;7 and decision-making.3, 5 Central to Bayesian inference is that computations are sensitive to uncertainties about afferent and efferent quantities, arising from ignorance, noise, or inherent ambiguity (e.g., the aperture problem), and that these uncertainties change over time as information accumulates and dissipates. Understanding how neurons represent and manipulate uncertain quantities is therefore key to understanding the neural instantiation of these Bayesian inferences. Most previous work on representing probabilistic inference in neural populations has focused on the representation of static information.1, 12, 15 These encompass various strategies for encoding and decoding uncertain quantities, but do not readily generalize to real-world dynamic information processing tasks, particularly the most interesting cases with stimuli changing over the same timescale as spiking itself.11 Notable exceptions are the recent, seminal, but, as we argue, representationally restricted, models proposed by Gold and Shadlen,5 Rao,10 and Deneve.4 In this paper, we ﬁrst show how probabilistic information varying over time can be represented in a spiking population code. Second, we present a method for producing spiking codes that facilitate further processing of the probabilistic information. Finally, we show the utility of this method by applying it to a temporal sensorimotor integration task. 1 TRAJECTORY ENCODING AND DECODING We assume that population spikes R(t) arise stochastically in relation to the trajectory X(t) of an underlying (but hidden) variable. We use RT and XT for the whole trajectory and spike trains respectively from time 0 to T . The spikes RT constitute the observations and are assumed to be probabilistically related to the signal by a tuning function f (X, θ i ): P (R(i, T )|X(T )) ∝ f (X, θi ) (1) for the spike train of the ith neuron, with parameters θi . Therefore, via standard Bayesian inference, RT determines a distribution over the hidden variable at time T , P (X(T )|RT ). We ﬁrst consider a version of the dynamics and input coding that permits an analytical examination of the impact of spikes. Let X(t) follow a stationary Gaussian process such that the joint distribution P (X(t1 ), X(t2 ), . . . , X(tm )) is Gaussian for any ﬁnite collection of times, with a covariance matrix which depends on time differences: Ctt = c(|t − t |). Function c(|∆t|) controls the smoothness of the resulting random walks. Then, P (X(T )|RT ) ∝ p(X(T )) X(T ) dX(T )P (RT |X(T ))P (X(T )|X(T )) (2) where P (X(T )|X(T )) is the distribution over the whole trajectory X(T ) conditional on the value of X(T ) at its end point. If RT are a set of conditionally independent inhomogeneous Poisson processes, we have P (RT |X(T )) ∝ iτ f (X(tiτ ), θi ) exp − i τ dτ f (X(τ ), θi ) , (3) where tiτ ∀τ are the spike times τ of neuron i in RT . Let χ = [X(tiτ )] be the vector of stimulus positions at the times at which we observed a spike and Θ = [θ(tiτ )] be the vector of spike positions. If the tuning functions are Gaussian f (X, θi ) ∝ exp(−(X − θi )2 /2σ 2 ) and sufﬁciently dense that i τ dτ f (X, θi ) is independent of X (a standard assumption in population coding), then P (RT |X(T )) ∝ exp(− χ − Θ 2 /2σ 2 ) and in Equation 2, we can marginalize out X(T ) except at the spike times tiτ : P (X(T )|RT ) ∝ p(X(T )) −1 χ dχ exp −[χ, X(T )]T C 2 [χ, X(T )] − χ−Θ 2σ 2 2 (4) and C is the block covariance matrix between X(tiτ ), x(T ) at the spike times [ttτ ] and the ﬁnal time T . This Gaussian integral has P (X(T )|RT ) ∼ N (µ(T ), ν(T )), with µ(T ) = CT t (Ctt + Iσ 2 )−1 Θ = kΘ ν(T ) = CT T − kCtT (5) CT T is the T, T th element of the covariance matrix and CT t is similarly a row vector. The dependence in µ on past spike times is speciﬁed chieﬂy by the inverse covariance matrix, and acts as an effective kernel (k). This kernel is not stationary, since it depends on factors such as the local density of spiking in the spike train RT . For example, consider where X(t) evolves according to a diffusion process with drift: dX = −αXdt + σ dN (t) (6) where α prevents it from wandering too far, N (t) is white Gaussian noise with mean zero and σ 2 variance. Figure 1A shows sample kernels for this process. Inspection of Figure 1A reveals some important traits. First, the monotonically decreasing kernel magnitude as the time span between the spike and the current time T grows matches the intuition that recent spikes play a more signiﬁcant role in determining the posterior over X(T ). Second, the kernel is nearly exponential, with a time constant that depends on the time constant of the covariance function and the density of the spikes; two settings of these parameters produced the two groupings of kernels in the ﬁgure. Finally, the fully adaptive kernel k can be locally well approximated by a metronomic kernel k  (shown in red in Figure 1A) that assumes regular spiking. This takes advantage of the general fact, indicated by the grouping of kernels, that the kernel depends weakly on the actual spike pattern, but strongly on the average rate. The merits of the metronomic kernel are that it is stationary and only depends on a single mean rate rather than the full spike train RT . It also justiﬁes s Kernels k and k −0.5 C 5 0 0.03 0.06 0.09 0.04 0.06 0.08 t−t Time spike True stimulus and means D Full kernel E Regular, stationary kernel −0.5 0 −0.5 0.03 0.04 0.05 0.06 0.07 Time 0.08 0.09 0 0.5 0.1 Space 0 Space −4 10 Space Variance ratio 10 −2 10 0.5 B ν2 / σ2 Kernel size (weight) A 0.1 0 0.5 0.03 0.04 0.05 0.06 0.07 Time 0.08 0.09 0.1 Figure 1: Exact and approximate spike decoding with the Gaussian process prior. Spikes are shown in yellow, the true stimulus in green, and P (X(T )|RT ) in gray. Blue: exact inference with nonstationary and red: approximate inference with regular spiking. A Kernel samples for a diffusion process as deﬁned by equations 5, 6. B, C: Mean and variance of the inference. D: Exact inference with full kernel k and E: approximation based on metronomic kernel k</p><p>3 0.14178987 <a title="105-tfidf-3" href="./nips-2004-Adaptive_Manifold_Learning.html">17 nips-2004-Adaptive Manifold Learning</a></p>
<p>Author: Jing Wang, Zhenyue Zhang, Hongyuan Zha</p><p>Abstract: Recently, there have been several advances in the machine learning and pattern recognition communities for developing manifold learning algorithms to construct nonlinear low-dimensional manifolds from sample data points embedded in high-dimensional spaces. In this paper, we develop algorithms that address two key issues in manifold learning: 1) the adaptive selection of the neighborhood sizes; and 2) better ﬁtting the local geometric structure to account for the variations in the curvature of the manifold and its interplay with the sampling density of the data set. We also illustrate the effectiveness of our methods on some synthetic data sets. 1</p><p>4 0.13566111 <a title="105-tfidf-4" href="./nips-2004-Semigroup_Kernels_on_Finite_Sets.html">168 nips-2004-Semigroup Kernels on Finite Sets</a></p>
<p>Author: Marco Cuturi, Jean-philippe Vert</p><p>Abstract: Complex objects can often be conveniently represented by ﬁnite sets of simpler components, such as images by sets of patches or texts by bags of words. We study the class of positive deﬁnite (p.d.) kernels for two such objects that can be expressed as a function of the merger of their respective sets of components. We prove a general integral representation of such kernels and present two particular examples. One of them leads to a kernel for sets of points living in a space endowed itself with a positive deﬁnite kernel. We provide experimental results on a benchmark experiment of handwritten digits image classiﬁcation which illustrate the validity of the approach. 1</p><p>5 0.11976501 <a title="105-tfidf-5" href="./nips-2004-Variational_Minimax_Estimation_of_Discrete_Distributions_under_KL_Loss.html">204 nips-2004-Variational Minimax Estimation of Discrete Distributions under KL Loss</a></p>
<p>Author: Liam Paninski</p><p>Abstract: We develop a family of upper and lower bounds on the worst-case expected KL loss for estimating a discrete distribution on a ﬁnite number m of points, given N i.i.d. samples. Our upper bounds are approximationtheoretic, similar to recent bounds for estimating discrete entropy; the lower bounds are Bayesian, based on averages of the KL loss under Dirichlet distributions. The upper bounds are convex in their parameters and thus can be minimized by descent methods to provide estimators with low worst-case error; the lower bounds are indexed by a one-dimensional parameter and are thus easily maximized. Asymptotic analysis of the bounds demonstrates the uniform KL-consistency of a wide class of estimators as c = N/m → ∞ (no matter how slowly), and shows that no estimator is consistent for c bounded (in contrast to entropy estimation). Moreover, the bounds are asymptotically tight as c → 0 or ∞, and are shown numerically to be tight within a factor of two for all c. Finally, in the sparse-data limit c → 0, we ﬁnd that the Dirichlet-Bayes (add-constant) estimator with parameter scaling like −c log(c) optimizes both the upper and lower bounds, suggesting an optimal choice of the “add-constant” parameter in this regime.</p><p>6 0.11886951 <a title="105-tfidf-6" href="./nips-2004-Learning_Gaussian_Process_Kernels_via_Hierarchical_Bayes.html">98 nips-2004-Learning Gaussian Process Kernels via Hierarchical Bayes</a></p>
<p>7 0.11801826 <a title="105-tfidf-7" href="./nips-2004-Dependent_Gaussian_Processes.html">50 nips-2004-Dependent Gaussian Processes</a></p>
<p>8 0.11403067 <a title="105-tfidf-8" href="./nips-2004-Semi-parametric_Exponential_Family_PCA.html">163 nips-2004-Semi-parametric Exponential Family PCA</a></p>
<p>9 0.10941446 <a title="105-tfidf-9" href="./nips-2004-Resolving_Perceptual_Aliasing_In_The_Presence_Of_Noisy_Sensors.html">154 nips-2004-Resolving Perceptual Aliasing In The Presence Of Noisy Sensors</a></p>
<p>10 0.090829752 <a title="105-tfidf-10" href="./nips-2004-Nonparametric_Transforms_of_Graph_Kernels_for_Semi-Supervised_Learning.html">133 nips-2004-Nonparametric Transforms of Graph Kernels for Semi-Supervised Learning</a></p>
<p>11 0.089945316 <a title="105-tfidf-11" href="./nips-2004-Hierarchical_Clustering_of_a_Mixture_Model.html">77 nips-2004-Hierarchical Clustering of a Mixture Model</a></p>
<p>12 0.089261323 <a title="105-tfidf-12" href="./nips-2004-Outlier_Detection_with_One-class_Kernel_Fisher_Discriminants.html">142 nips-2004-Outlier Detection with One-class Kernel Fisher Discriminants</a></p>
<p>13 0.085162535 <a title="105-tfidf-13" href="./nips-2004-Comparing_Beliefs%2C_Surveys%2C_and_Random_Walks.html">41 nips-2004-Comparing Beliefs, Surveys, and Random Walks</a></p>
<p>14 0.082441494 <a title="105-tfidf-14" href="./nips-2004-A_Method_for_Inferring_Label_Sampling_Mechanisms_in_Semi-Supervised_Learning.html">9 nips-2004-A Method for Inferring Label Sampling Mechanisms in Semi-Supervised Learning</a></p>
<p>15 0.07933227 <a title="105-tfidf-15" href="./nips-2004-Joint_Probabilistic_Curve_Clustering_and_Alignment.html">90 nips-2004-Joint Probabilistic Curve Clustering and Alignment</a></p>
<p>16 0.076054089 <a title="105-tfidf-16" href="./nips-2004-Limits_of_Spectral_Clustering.html">103 nips-2004-Limits of Spectral Clustering</a></p>
<p>17 0.073590018 <a title="105-tfidf-17" href="./nips-2004-Using_the_Equivalent_Kernel_to_Understand_Gaussian_Process_Regression.html">201 nips-2004-Using the Equivalent Kernel to Understand Gaussian Process Regression</a></p>
<p>18 0.069495797 <a title="105-tfidf-18" href="./nips-2004-A_Second_Order_Cone_programming_Formulation_for_Classifying_Missing_Data.html">11 nips-2004-A Second Order Cone programming Formulation for Classifying Missing Data</a></p>
<p>19 0.068569794 <a title="105-tfidf-19" href="./nips-2004-Unsupervised_Variational_Bayesian_Learning_of_Nonlinear_Models.html">198 nips-2004-Unsupervised Variational Bayesian Learning of Nonlinear Models</a></p>
<p>20 0.066895381 <a title="105-tfidf-20" href="./nips-2004-Learning%2C_Regularization_and_Ill-Posed_Inverse_Problems.html">96 nips-2004-Learning, Regularization and Ill-Posed Inverse Problems</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2004_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.246), (1, 0.021), (2, -0.044), (3, 0.037), (4, -0.097), (5, -0.047), (6, -0.13), (7, -0.007), (8, 0.045), (9, 0.012), (10, 0.11), (11, 0.03), (12, 0.199), (13, -0.083), (14, 0.058), (15, -0.082), (16, 0.05), (17, 0.003), (18, 0.096), (19, -0.026), (20, -0.164), (21, 0.067), (22, -0.128), (23, -0.077), (24, 0.074), (25, -0.004), (26, 0.08), (27, 0.041), (28, -0.037), (29, -0.073), (30, -0.064), (31, -0.241), (32, -0.054), (33, 0.065), (34, 0.004), (35, 0.108), (36, 0.097), (37, -0.113), (38, 0.017), (39, -0.007), (40, 0.07), (41, -0.039), (42, -0.052), (43, 0.157), (44, 0.051), (45, -0.057), (46, -0.072), (47, -0.13), (48, 0.039), (49, -0.055)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96693522 <a title="105-lsi-1" href="./nips-2004-Log-concavity_Results_on_Gaussian_Process_Methods_for_Supervised_and_Unsupervised_Learning.html">105 nips-2004-Log-concavity Results on Gaussian Process Methods for Supervised and Unsupervised Learning</a></p>
<p>Author: Liam Paninski</p><p>Abstract: Log-concavity is an important property in the context of optimization, Laplace approximation, and sampling; Bayesian methods based on Gaussian process priors have become quite popular recently for classiﬁcation, regression, density estimation, and point process intensity estimation. Here we prove that the predictive densities corresponding to each of these applications are log-concave, given any observed data. We also prove that the likelihood is log-concave in the hyperparameters controlling the mean function of the Gaussian prior in the density and point process intensity estimation cases, and the mean, covariance, and observation noise parameters in the classiﬁcation and regression cases; this result leads to a useful parameterization of these hyperparameters, indicating a suitably large class of priors for which the corresponding maximum a posteriori problem is log-concave.</p><p>2 0.60113502 <a title="105-lsi-2" href="./nips-2004-Dependent_Gaussian_Processes.html">50 nips-2004-Dependent Gaussian Processes</a></p>
<p>Author: Phillip Boyle, Marcus Frean</p><p>Abstract: Gaussian processes are usually parameterised in terms of their covariance functions. However, this makes it difﬁcult to deal with multiple outputs, because ensuring that the covariance matrix is positive deﬁnite is problematic. An alternative formulation is to treat Gaussian processes as white noise sources convolved with smoothing kernels, and to parameterise the kernel instead. Using this, we extend Gaussian processes to handle multiple, coupled outputs. 1</p><p>3 0.52629364 <a title="105-lsi-3" href="./nips-2004-Probabilistic_Computation_in_Spiking_Populations.html">148 nips-2004-Probabilistic Computation in Spiking Populations</a></p>
<p>Author: Richard S. Zemel, Rama Natarajan, Peter Dayan, Quentin J. Huys</p><p>Abstract: As animals interact with their environments, they must constantly update estimates about their states. Bayesian models combine prior probabilities, a dynamical model and sensory evidence to update estimates optimally. These models are consistent with the results of many diverse psychophysical studies. However, little is known about the neural representation and manipulation of such Bayesian information, particularly in populations of spiking neurons. We consider this issue, suggesting a model based on standard neural architecture and activations. We illustrate the approach on a simple random walk example, and apply it to a sensorimotor integration task that provides a particularly compelling example of dynamic probabilistic computation. Bayesian models have been used to explain a gamut of experimental results in tasks which require estimates to be derived from multiple sensory cues. These include a wide range of psychophysical studies of perception;13 motor action;7 and decision-making.3, 5 Central to Bayesian inference is that computations are sensitive to uncertainties about afferent and efferent quantities, arising from ignorance, noise, or inherent ambiguity (e.g., the aperture problem), and that these uncertainties change over time as information accumulates and dissipates. Understanding how neurons represent and manipulate uncertain quantities is therefore key to understanding the neural instantiation of these Bayesian inferences. Most previous work on representing probabilistic inference in neural populations has focused on the representation of static information.1, 12, 15 These encompass various strategies for encoding and decoding uncertain quantities, but do not readily generalize to real-world dynamic information processing tasks, particularly the most interesting cases with stimuli changing over the same timescale as spiking itself.11 Notable exceptions are the recent, seminal, but, as we argue, representationally restricted, models proposed by Gold and Shadlen,5 Rao,10 and Deneve.4 In this paper, we ﬁrst show how probabilistic information varying over time can be represented in a spiking population code. Second, we present a method for producing spiking codes that facilitate further processing of the probabilistic information. Finally, we show the utility of this method by applying it to a temporal sensorimotor integration task. 1 TRAJECTORY ENCODING AND DECODING We assume that population spikes R(t) arise stochastically in relation to the trajectory X(t) of an underlying (but hidden) variable. We use RT and XT for the whole trajectory and spike trains respectively from time 0 to T . The spikes RT constitute the observations and are assumed to be probabilistically related to the signal by a tuning function f (X, θ i ): P (R(i, T )|X(T )) ∝ f (X, θi ) (1) for the spike train of the ith neuron, with parameters θi . Therefore, via standard Bayesian inference, RT determines a distribution over the hidden variable at time T , P (X(T )|RT ). We ﬁrst consider a version of the dynamics and input coding that permits an analytical examination of the impact of spikes. Let X(t) follow a stationary Gaussian process such that the joint distribution P (X(t1 ), X(t2 ), . . . , X(tm )) is Gaussian for any ﬁnite collection of times, with a covariance matrix which depends on time differences: Ctt = c(|t − t |). Function c(|∆t|) controls the smoothness of the resulting random walks. Then, P (X(T )|RT ) ∝ p(X(T )) X(T ) dX(T )P (RT |X(T ))P (X(T )|X(T )) (2) where P (X(T )|X(T )) is the distribution over the whole trajectory X(T ) conditional on the value of X(T ) at its end point. If RT are a set of conditionally independent inhomogeneous Poisson processes, we have P (RT |X(T )) ∝ iτ f (X(tiτ ), θi ) exp − i τ dτ f (X(τ ), θi ) , (3) where tiτ ∀τ are the spike times τ of neuron i in RT . Let χ = [X(tiτ )] be the vector of stimulus positions at the times at which we observed a spike and Θ = [θ(tiτ )] be the vector of spike positions. If the tuning functions are Gaussian f (X, θi ) ∝ exp(−(X − θi )2 /2σ 2 ) and sufﬁciently dense that i τ dτ f (X, θi ) is independent of X (a standard assumption in population coding), then P (RT |X(T )) ∝ exp(− χ − Θ 2 /2σ 2 ) and in Equation 2, we can marginalize out X(T ) except at the spike times tiτ : P (X(T )|RT ) ∝ p(X(T )) −1 χ dχ exp −[χ, X(T )]T C 2 [χ, X(T )] − χ−Θ 2σ 2 2 (4) and C is the block covariance matrix between X(tiτ ), x(T ) at the spike times [ttτ ] and the ﬁnal time T . This Gaussian integral has P (X(T )|RT ) ∼ N (µ(T ), ν(T )), with µ(T ) = CT t (Ctt + Iσ 2 )−1 Θ = kΘ ν(T ) = CT T − kCtT (5) CT T is the T, T th element of the covariance matrix and CT t is similarly a row vector. The dependence in µ on past spike times is speciﬁed chieﬂy by the inverse covariance matrix, and acts as an effective kernel (k). This kernel is not stationary, since it depends on factors such as the local density of spiking in the spike train RT . For example, consider where X(t) evolves according to a diffusion process with drift: dX = −αXdt + σ dN (t) (6) where α prevents it from wandering too far, N (t) is white Gaussian noise with mean zero and σ 2 variance. Figure 1A shows sample kernels for this process. Inspection of Figure 1A reveals some important traits. First, the monotonically decreasing kernel magnitude as the time span between the spike and the current time T grows matches the intuition that recent spikes play a more signiﬁcant role in determining the posterior over X(T ). Second, the kernel is nearly exponential, with a time constant that depends on the time constant of the covariance function and the density of the spikes; two settings of these parameters produced the two groupings of kernels in the ﬁgure. Finally, the fully adaptive kernel k can be locally well approximated by a metronomic kernel k  (shown in red in Figure 1A) that assumes regular spiking. This takes advantage of the general fact, indicated by the grouping of kernels, that the kernel depends weakly on the actual spike pattern, but strongly on the average rate. The merits of the metronomic kernel are that it is stationary and only depends on a single mean rate rather than the full spike train RT . It also justiﬁes s Kernels k and k −0.5 C 5 0 0.03 0.06 0.09 0.04 0.06 0.08 t−t Time spike True stimulus and means D Full kernel E Regular, stationary kernel −0.5 0 −0.5 0.03 0.04 0.05 0.06 0.07 Time 0.08 0.09 0 0.5 0.1 Space 0 Space −4 10 Space Variance ratio 10 −2 10 0.5 B ν2 / σ2 Kernel size (weight) A 0.1 0 0.5 0.03 0.04 0.05 0.06 0.07 Time 0.08 0.09 0.1 Figure 1: Exact and approximate spike decoding with the Gaussian process prior. Spikes are shown in yellow, the true stimulus in green, and P (X(T )|RT ) in gray. Blue: exact inference with nonstationary and red: approximate inference with regular spiking. A Kernel samples for a diffusion process as deﬁned by equations 5, 6. B, C: Mean and variance of the inference. D: Exact inference with full kernel k and E: approximation based on metronomic kernel k</p><p>4 0.50455654 <a title="105-lsi-4" href="./nips-2004-Adaptive_Manifold_Learning.html">17 nips-2004-Adaptive Manifold Learning</a></p>
<p>Author: Jing Wang, Zhenyue Zhang, Hongyuan Zha</p><p>Abstract: Recently, there have been several advances in the machine learning and pattern recognition communities for developing manifold learning algorithms to construct nonlinear low-dimensional manifolds from sample data points embedded in high-dimensional spaces. In this paper, we develop algorithms that address two key issues in manifold learning: 1) the adaptive selection of the neighborhood sizes; and 2) better ﬁtting the local geometric structure to account for the variations in the curvature of the manifold and its interplay with the sampling density of the data set. We also illustrate the effectiveness of our methods on some synthetic data sets. 1</p><p>5 0.49553549 <a title="105-lsi-5" href="./nips-2004-Learning_Gaussian_Process_Kernels_via_Hierarchical_Bayes.html">98 nips-2004-Learning Gaussian Process Kernels via Hierarchical Bayes</a></p>
<p>Author: Anton Schwaighofer, Volker Tresp, Kai Yu</p><p>Abstract: We present a novel method for learning with Gaussian process regression in a hierarchical Bayesian framework. In a ﬁrst step, kernel matrices on a ﬁxed set of input points are learned from data using a simple and efﬁcient EM algorithm. This step is nonparametric, in that it does not require a parametric form of covariance function. In a second step, kernel functions are ﬁtted to approximate the learned covariance matrix using a generalized Nystr¨ m method, which results in a complex, data o driven kernel. We evaluate our approach as a recommendation engine for art images, where the proposed hierarchical Bayesian method leads to excellent prediction performance. 1</p><p>6 0.49409306 <a title="105-lsi-6" href="./nips-2004-Outlier_Detection_with_One-class_Kernel_Fisher_Discriminants.html">142 nips-2004-Outlier Detection with One-class Kernel Fisher Discriminants</a></p>
<p>7 0.45479453 <a title="105-lsi-7" href="./nips-2004-Semigroup_Kernels_on_Finite_Sets.html">168 nips-2004-Semigroup Kernels on Finite Sets</a></p>
<p>8 0.45395663 <a title="105-lsi-8" href="./nips-2004-Using_the_Equivalent_Kernel_to_Understand_Gaussian_Process_Regression.html">201 nips-2004-Using the Equivalent Kernel to Understand Gaussian Process Regression</a></p>
<p>9 0.44712183 <a title="105-lsi-9" href="./nips-2004-Comparing_Beliefs%2C_Surveys%2C_and_Random_Walks.html">41 nips-2004-Comparing Beliefs, Surveys, and Random Walks</a></p>
<p>10 0.43634376 <a title="105-lsi-10" href="./nips-2004-Variational_Minimax_Estimation_of_Discrete_Distributions_under_KL_Loss.html">204 nips-2004-Variational Minimax Estimation of Discrete Distributions under KL Loss</a></p>
<p>11 0.43074772 <a title="105-lsi-11" href="./nips-2004-Resolving_Perceptual_Aliasing_In_The_Presence_Of_Noisy_Sensors.html">154 nips-2004-Resolving Perceptual Aliasing In The Presence Of Noisy Sensors</a></p>
<p>12 0.38541162 <a title="105-lsi-12" href="./nips-2004-Hierarchical_Clustering_of_a_Mixture_Model.html">77 nips-2004-Hierarchical Clustering of a Mixture Model</a></p>
<p>13 0.37502614 <a title="105-lsi-13" href="./nips-2004-Expectation_Consistent_Free_Energies_for_Approximate_Inference.html">63 nips-2004-Expectation Consistent Free Energies for Approximate Inference</a></p>
<p>14 0.37263516 <a title="105-lsi-14" href="./nips-2004-Learning%2C_Regularization_and_Ill-Posed_Inverse_Problems.html">96 nips-2004-Learning, Regularization and Ill-Posed Inverse Problems</a></p>
<p>15 0.36977342 <a title="105-lsi-15" href="./nips-2004-Semi-parametric_Exponential_Family_PCA.html">163 nips-2004-Semi-parametric Exponential Family PCA</a></p>
<p>16 0.36617959 <a title="105-lsi-16" href="./nips-2004-Sharing_Clusters_among_Related_Groups%3A_Hierarchical_Dirichlet_Processes.html">169 nips-2004-Sharing Clusters among Related Groups: Hierarchical Dirichlet Processes</a></p>
<p>17 0.36077654 <a title="105-lsi-17" href="./nips-2004-Semi-supervised_Learning_via_Gaussian_Processes.html">166 nips-2004-Semi-supervised Learning via Gaussian Processes</a></p>
<p>18 0.35506746 <a title="105-lsi-18" href="./nips-2004-Sampling_Methods_for_Unsupervised_Learning.html">158 nips-2004-Sampling Methods for Unsupervised Learning</a></p>
<p>19 0.35323095 <a title="105-lsi-19" href="./nips-2004-%E2%84%93%E2%82%80-norm_Minimization_for_Basis_Selection.html">207 nips-2004-ℓ₀-norm Minimization for Basis Selection</a></p>
<p>20 0.35121092 <a title="105-lsi-20" href="./nips-2004-A_Second_Order_Cone_programming_Formulation_for_Classifying_Missing_Data.html">11 nips-2004-A Second Order Cone programming Formulation for Classifying Missing Data</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2004_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.095), (15, 0.129), (26, 0.044), (31, 0.024), (33, 0.152), (35, 0.021), (39, 0.032), (50, 0.415)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.92370433 <a title="105-lda-1" href="./nips-2004-Using_Machine_Learning_to_Break_Visual_Human_Interaction_Proofs_%28HIPs%29.html">199 nips-2004-Using Machine Learning to Break Visual Human Interaction Proofs (HIPs)</a></p>
<p>Author: Kumar Chellapilla, Patrice Y. Simard</p><p>Abstract: Machine learning is often used to automatically solve human tasks. In this paper, we look for tasks where machine learning algorithms are not as good as humans with the hope of gaining insight into their current limitations. We studied various Human Interactive Proofs (HIPs) on the market, because they are systems designed to tell computers and humans apart by posing challenges presumably too hard for computers. We found that most HIPs are pure recognition tasks which can easily be broken using machine learning. The harder HIPs use a combination of segmentation and recognition tasks. From this observation, we found that building segmentation tasks is the most effective way to confuse machine learning algorithms. This has enabled us to build effective HIPs (which we deployed in MSN Passport), as well as design challenging segmentation tasks for machine learning algorithms. 1 In t rod u ct i on The OCR problem for high resolution printed text has virtually been solved 10 years ago [1]. On the other hand, cursive handwriting recognition today is still too poor for most people to rely on. Is there a fundamental difference between these two seemingly similar problems? To shed more light on this question, we study problems that have been designed to be difficult for computers. The hope is that we will get some insight on what the stumbling blocks are for machine learning and devise appropriate tests to further understand their similarities and differences. Work on distinguishing computers from humans traces back to the original Turing Test [2] which asks that a human distinguish between another human and a machine by asking questions of both. Recent interest has turned to developing systems that allow a computer to distinguish between another computer and a human. These systems enable the construction of automatic filters that can be used to prevent automated scripts from utilizing services intended for humans [4]. Such systems have been termed Human Interactive Proofs (HIPs) [3] or Completely Automated Public Turing Tests to Tell Computers and Humans Apart (CAPTCHAs) [4]. An overview of the work in this area can be found in [5]. Construction of HIPs that are of practical value is difficult because it is not sufficient to develop challenges at which humans are somewhat more successful than machines. This is because the cost of failure for an automatic attacker is minimal compared to the cost of failure for humans. Ideally a HIP should be solved by humans more than 80% of the time, while an automatic script with reasonable resource use should succeed less than 0.01% of the time. This latter ratio (1 in 10,000) is a function of the cost of an automatic trial divided by the cost of having a human perform the attack. This constraint of generating tasks that are failed 99.99% of the time by all automated algorithms has generated various solutions which can easily be sampled on the internet. Seven different HIPs, namely, Mailblocks, MSN (before April 28th, 2004), Ticketmaster, Yahoo, Yahoo v2 (after Sept’04), Register, and Google, will be given as examples in the next section. We will show in Section 3 that machinelearning-based attacks are far more successful than 1 in 10,000. Yet, some of these HIPs are harder than others and could be made even harder by identifying the recognition and segmentation parts, and emphasizing the latter. Section 4 presents examples of more difficult HIPs which are much more respectable challenges for machine learning, and yet surprisingly easy for humans. The final section discusses a (known) weakness of machine learning algorithms and suggests designing simple artificial datasets for studying this weakness. 2 Exa mp les o f H I Ps The HIPs explored in this paper are made of characters (or symbols) rendered to an image and presented to the user. Solving the HIP requires identifying all characters in the correct order. The following HIPs can be sampled from the web: Mailblocks: While signing up for free email service with (www.mailblocks.com), you will find HIP challenges of the type: mailblocks MSN: While signing up for free e-mail with MSN Hotmail (www.hotmail.com), you will find HIP challenges of the type: Register.com: While requesting a whois lookup for a domain at www.register.com, you will HIP challenges of the type: Yahoo!/EZ-Gimpy (CMU): While signing up for free e-mail service with Yahoo! (www.yahoo.com), you will receive HIP challenges of the type: Yahoo! (version 2): Starting in August 2004, Yahoo! introduced their second generation HIP. Three examples are presented below: Ticketmaster: While looking for concert tickets at www.ticketmaster.com, you will receive HIP challenges of the type: Google/Gmail: While signing up for free e-mail with Gmail at www.google.com, one will receive HIP challenges of the type: While solutions to Yahoo HIPs are common English words, those for ticketmaster and Google do not necessarily belong to the English dictionary. They appear to have been created using a phonetic generator [8]. 3 Usi n g ma ch i n e lea rn i n g t o b rea k H IP s Breaking HIPs is not new. Mori and Malik [7] have successfully broken the EZGimpy (92% success) and Gimpy (33% success) HIPs from CMU. Our approach aims at an automatic process for solving multiple HIPs with minimum human intervention, using machine learning. In this paper, our main goal is to learn more about the common strengths and weaknesses of these HIPs rather than to prove that we can break any one HIP in particular with the highest possible success rate. We have results for six different HIPs: EZ-Gimpy/Yahoo, Yahoo v2, mailblocks, register, ticketmaster, and Google. To simplify our study, we will not be using language models in our attempt to break HIPs. For example, there are only about 600 words in the EZ-Gimpy dictionary [7], which means that a random guess attack would get a success rate of 1 in 600 (more than enough to break the HIP, i.e., greater than 0.01% success). HIPs become harder when no language model is used. Similarly, when a HIP uses a language model to generate challenges, success rate of attacks can be significantly improved by incorporating the language model. Further, since the language model is not common to all HIPs studied, it was not used in this paper. Our generic method for breaking all of these HIPs is to write a custom algorithm to locate the characters, and then use machine learning for recognition. Surprisingly, segmentation, or finding the characters, is simple for many HIPs which makes the process of breaking the HIP particularly easy. Gimpy uses a single constant predictable color (black) for letters even though the background color changes. We quickly realized that once the segmentation problem is solved, solving the HIP becomes a pure recognition problem, and it can trivially be solved using machine learning. Our recognition engine is based on neural networks [6][9]. It yielded a 0.4% error rate on the MNIST database, uses little memory, and is very fast for recognition (important for breaking HIPs). For each HIP, we have a segmentation step, followed by a recognition step. It should be stressed that we are not trying to solve every HIP of a given type i.e., our goal is not 100% success rate, but something efficient that can achieve much better than 0.01%. In each of the following experiments, 2500 HIPs were hand labeled and used as follows (a) recognition (1600 for training, 200 for validation, and 200 for testing), and (b) segmentation (500 for testing segmentation). For each of the five HIPs, a convolution neural network, identical to the one described in [6], was trained and tested on gray level character images centered on the guessed character positions (see below). The trained neural network became the recognizer. 3.1 M a i l b l oc k s To solve the HIP, we select the red channel, binarize and erode it, extract the largest connected components (CCs), and breakup CCs that are too large into two or three adjacent CCs. Further, vertically overlapping half character size CCs are merged. The resulting rough segmentation works most of the time. Here is an example: For instance, in the example above, the NN would be trained, and tested on the following images: … The end-to-end success rate is 88.8% for segmentation, 95.9% for recognition (given correct segmentation), and (0.888)*(0.959)7 = 66.2% total. Note that most of the errors come from segmentation, even though this is where all the custom programming was invested. 3.2 Register The procedure to solve HIPs is very similar. The image was smoothed, binarized, and the largest 5 connected components were identified. Two examples are presented below: The end-to-end success rate is 95.4% for segmentation, 87.1% for recognition (given correct segmentation), and (0.954)*(0.871)5 = 47.8% total. 3.3 Y a h oo/ E Z - G i mp y Unlike the mailblocks and register HIPs, the Yahoo/EZ-Gimpy HIPs are richer in that a variety of backgrounds and clutter are possible. Though some amount of text warping is present, the text color, size, and font have low variability. Three simple segmentation algorithms were designed with associated rules to identify which algorithm to use. The goal was to keep these simple yet effective: a) No mesh: Convert to grayscale image, threshold to black and white, select large CCs with sizes close to HIP char sizes. One example: b) Black mesh: Convert to grayscale image, threshold to black and white, remove vertical and horizontal line pixels that don’t have neighboring pixels, select large CCs with sizes close to HIP char sizes. One example: c) White mesh: Convert to grayscale image, threshold to black and white, add black pixels (in white line locations) if there exist neighboring pixels, select large CCs with sizes close to HIP char sizes. One example: Tests for black and white meshes were performed to determine which segmentation algorithm to use. The end-to-end success rate was 56.2% for segmentation (38.2% came from a), 11.8% from b), and 6.2% from c), 90.3% for recognition (given correct segmentation), and (0.562)*(0.903)4.8 = 34.4% total. The average length of a Yahoo HIP solution is 4.8 characters. 3.4 T i c k e t ma s t e r The procedure that solved the Yahoo HIP is fairly successful at solving some of the ticket master HIPs. These HIPs are characterized by cris-crossing lines at random angles clustered around 0, 45, 90, and 135 degrees. A multipronged attack as in the Yahoo case (section 3.3) has potential. In the interests of simplicity, a single attack was developed: Convert to grayscale, threshold to black and white, up-sample image, dilate first then erode, select large CCs with sizes close to HIP char sizes. One example: The dilate-erode combination causes the lines to be removed (along with any thin objects) but retains solid thick characters. This single attack is successful in achieving an end-to-end success rate of 16.6% for segmentation, the recognition rate was 82.3% (in spite of interfering lines), and (0.166)*(0.823)6.23 = 4.9% total. The average HIP solution length is 6.23 characters. 3.5 Y a h oo ve r s i on 2 The second generation HIP from Yahoo had several changes: a) it did not use words from a dictionary or even use a phonetic generator, b) it uses only black and white colors, c) uses both letters and digits, and d) uses connected lines and arcs as clutter. The HIP is somewhat similar to the MSN/Passport HIP which does not use a dictionary, uses two colors, uses letters and digits, and background and foreground arcs as clutter. Unlike the MSN/Passport HIP, several different fonts are used. A single segmentation attack was developed: Remove 6 pixel border, up-sample, dilate first then erode, select large CCs with sizes close to HIP char sizes. The attack is practically identical to that used for the ticketmaster HIP with different preprocessing stages and slightly modified parameters. Two examples: This single attack is successful in achieving an end-to-end success rate of 58.4% for segmentation, the recognition rate was 95.2%, and (0.584)*(0.952)5 = 45.7% total. The average HIP solution length is 5 characters. 3.6 G oog l e / G M a i l The Google HIP is unique in that it uses only image warp as a means of distorting the characters. Similar to the MSN/Passport and Yahoo version 2 HIPs, it is also two color. The HIP characters are arranged closed to one another (they often touch) and follow a curved baseline. The following very simple attack was used to segment Google HIPs: Convert to grayscale, up-sample, threshold and separate connected components. a) b) This very simple attack gives an end-to-end success rate of 10.2% for segmentation, the recognition rate was 89.3%, giving (0.102)*(0.893)6.5 = 4.89% total probability of breaking a HIP. Average Google HIP solution length is 6.5 characters. This can be significantly improved upon by judicious use of dilate-erode attack. A direct application doesn’t do as well as it did on the ticketmaster and yahoo HIPs (because of the shear and warp of the baseline of the word). More successful and complicated attacks might estimate and counter the shear and warp of the baseline to achieve better success rates. 4 Lesso n s lea rn ed f ro m b rea ki n g H IPs From the previous section, it is clear that most of the errors come from incorrect segmentations, even though most of the development time is spent devising custom segmentation schemes. This observation raises the following questions: Why is segmentation a hard problem? Can we devise harder HIPs and datasets? Can we build an automatic segmentor? Can we compare classification algorithms based on how useful they are for segmentation? 4.1 T h e s e g me n t a t i on p r ob l e m As a review, segmentation is difficult for the following reasons: 1. Segmentation is computationally expensive. In order to find valid patterns, a recognizer must attempt recognition at many different candidate locations. 2. The segmentation function is complex. To segment successfully, the system must learn to identify which patterns are valid among the set of all possible valid and non-valid patterns. This task is intrinsically more difficult than classification because the space of input is considerably larger. Unlike the space of valid patterns, the space of non-valid patterns is typically too vast to sample. This is a problem for many learning algorithms which yield too many false positives when presented non-valid patterns. 3. Identifying valid characters among a set of valid and invalid candidates is a combinatorial problem. For example, correctly identifying which 8 characters among 20 candidates (assuming 12 false positives), has a 1 in 125,970 (20 choose 8) chances of success by random guessing. 4.2 B ui l d i n g b e t te r / h a r de r H I P s We can use what we have learned to build better HIPs. For instance the HIP below was designed to make segmentation difficult and a similar version has been deployed by MSN Passport for hotmail registrations (www.hotmail.com): The idea is that the additional arcs are themselves good candidates for false characters. The previous segmentation attacks would fail on this HIP. Furthermore, simple change of fonts, distortions, or arc types would require extensive work for the attacker to adjust to. We believe HIPs that emphasize the segmentation problem, such as the above example, are much stronger than the HIPs we examined in this paper, which rely on recognition being difficult. Pushing this to the extreme, we can easily generate the following HIPs: Despite the apparent difficulty of these HIPs, humans are surprisingly good at solving these, indicating that humans are far better than computers at segmentation. This approach of adding several competing false positives can in principle be used to automatically create difficult segmentation problems or benchmarks to test classification algorithms. 4.3 B ui l d i n g a n a ut o ma t i c s e g me n t or To build an automatic segmentor, we could use the following procedure. Label characters based on their correct position and train a recognizer. Apply the trained recognizer at all locations in the HIP image. Collect all candidate characters identified with high confidence by the recognizer. Compute the probability of each combination of candidates (going from left to right), and output the solution string with the highest probability. This is better illustrated with an example. Consider the following HIP (to the right). The trained neural network has these maps (warm colors indicate recognition) that show that K, Y, and so on are correctly identified. However, the maps for 7 and 9 show several false positives. In general, we would get the following color coded map for all the different candidates: HIP K Y B 7 9 With a threshold of 0.5 on the network’s outputs, the map obtained is: We note that there are several false positives for each true positive. The number of false positives per true positive character was found to be between 1 and 4, giving a 1 in C(16,8) = 12,870 to 1 in C(32,8) = 10,518,300 random chance of guessing the correct segmentation for the HIP characters. These numbers can be improved upon by constraining solution strings to flow sequentially from left to right and by restricting overlap. For each combination, we compute a probability by multiplying the 8 probabilities of the classifier for each position. The combination with the highest probability is the one proposed by the classifier. We do not have results for such an automatic segmentor at this time. It is interesting to note that with such a method a classifier that is robust to false positives would do far better than one that is not. This suggests another axis for comparing classifiers. 5 Con clu si on In this paper, we have successfully applied machine learning to the problem of solving HIPs. We have learned that decomposing the HIP problem into segmentation and recognition greatly simplifies analysis. Recognition on even unprocessed images (given segmentation is a solved) can be done automatically using neural networks. Segmentation, on the other hand, is the difficulty differentiator between weaker and stronger HIPs and requires custom intervention for each HIP. We have used this observation to design new HIPs and new tests for machine learning algorithms with the hope of improving them. A c k n ow l e d ge me n t s We would like to acknowledge Chau Luu and Eric Meltzer for their help with labeling and segmenting various HIPs. We would also like to acknowledge Josh Benaloh and Cem Paya for stimulating discussions on HIP security. References [1] Baird HS (1992), “Anatomy of a versatile page reader,” IEEE Pro., v.80, pp. 1059-1065. [2] Turing AM (1950), “Computing Machinery and Intelligence,” Mind, 59:236, pp. 433-460. [3] First Workshop on Human Interactive Proofs, Palo Alto, CA, January 2002. [4] Von Ahn L, Blum M, and Langford J, The Captcha Project. http://www.captcha.net [5] Baird HS and Popat K (2002) “Human Interactive Proofs and Document Image Analysis,” Proc. IAPR 2002 Workshop on Document Analysis Systerms, Princeton, NJ. [6] Simard PY, Steinkraus D, and Platt J, (2003) “Best Practice for Convolutional Neural Networks Applied to Visual Document Analysis,” in International Conference on Document Analysis and Recognition (ICDAR), pp. 958-962, IEEE Computer Society, Los Alamitos. [7] Mori G, Malik J (2003), “Recognizing Objects in Adversarial Clutter: Breaking a Visual CAPTCHA,” Proc. of the Computer Vision and Pattern Recognition (CVPR) Conference, IEEE Computer Society, vol.1, pages:I-134 - I-141, June 18-20, 2003 [8] Chew, M. and Baird, H. S. (2003), “BaffleText: a Human Interactive Proof,” Proc., 10th IS&T;/SPIE Document Recognition & Retrieval Conf., Santa Clara, CA, Jan. 22. [9] LeCun Y, Bottou L, Bengio Y, and Haffner P, “Gradient-based learning applied to document recognition,’ Proceedings of the IEEE, Nov. 1998.</p><p>2 0.88455939 <a title="105-lda-2" href="./nips-2004-On_Semi-Supervised_Classification.html">136 nips-2004-On Semi-Supervised Classification</a></p>
<p>Author: Balaji Krishnapuram, David Williams, Ya Xue, Lawrence Carin, Mário Figueiredo, Alexander J. Hartemink</p><p>Abstract: A graph-based prior is proposed for parametric semi-supervised classiﬁcation. The prior utilizes both labelled and unlabelled data; it also integrates features from multiple views of a given sample (e.g., multiple sensors), thus implementing a Bayesian form of co-training. An EM algorithm for training the classiﬁer automatically adjusts the tradeoff between the contributions of: (a) the labelled data; (b) the unlabelled data; and (c) the co-training information. Active label query selection is performed using a mutual information based criterion that explicitly uses the unlabelled data and the co-training information. Encouraging results are presented on public benchmarks and on measured data from single and multiple sensors. 1</p><p>same-paper 3 0.86393905 <a title="105-lda-3" href="./nips-2004-Log-concavity_Results_on_Gaussian_Process_Methods_for_Supervised_and_Unsupervised_Learning.html">105 nips-2004-Log-concavity Results on Gaussian Process Methods for Supervised and Unsupervised Learning</a></p>
<p>Author: Liam Paninski</p><p>Abstract: Log-concavity is an important property in the context of optimization, Laplace approximation, and sampling; Bayesian methods based on Gaussian process priors have become quite popular recently for classiﬁcation, regression, density estimation, and point process intensity estimation. Here we prove that the predictive densities corresponding to each of these applications are log-concave, given any observed data. We also prove that the likelihood is log-concave in the hyperparameters controlling the mean function of the Gaussian prior in the density and point process intensity estimation cases, and the mean, covariance, and observation noise parameters in the classiﬁcation and regression cases; this result leads to a useful parameterization of these hyperparameters, indicating a suitably large class of priors for which the corresponding maximum a posteriori problem is log-concave.</p><p>4 0.82608664 <a title="105-lda-4" href="./nips-2004-Density_Level_Detection_is_Classification.html">49 nips-2004-Density Level Detection is Classification</a></p>
<p>Author: Ingo Steinwart, Don Hush, Clint Scovel</p><p>Abstract: We show that anomaly detection can be interpreted as a binary classiﬁcation problem. Using this interpretation we propose a support vector machine (SVM) for anomaly detection. We then present some theoretical results which include consistency and learning rates. Finally, we experimentally compare our SVM with the standard one-class SVM. 1</p><p>5 0.81416899 <a title="105-lda-5" href="./nips-2004-Beat_Tracking_the_Graphical_Model_Way.html">29 nips-2004-Beat Tracking the Graphical Model Way</a></p>
<p>Author: Dustin Lang, Nando D. Freitas</p><p>Abstract: We present a graphical model for beat tracking in recorded music. Using a probabilistic graphical model allows us to incorporate local information and global smoothness constraints in a principled manner. We evaluate our model on a set of varied and difﬁcult examples, and achieve impressive results. By using a fast dual-tree algorithm for graphical model inference, our system runs in less time than the duration of the music being processed. 1</p><p>6 0.63277119 <a title="105-lda-6" href="./nips-2004-The_Power_of_Selective_Memory%3A_Self-Bounded_Learning_of_Prediction_Suffix_Trees.html">189 nips-2004-The Power of Selective Memory: Self-Bounded Learning of Prediction Suffix Trees</a></p>
<p>7 0.63228744 <a title="105-lda-7" href="./nips-2004-Fast_Rates_to_Bayes_for_Kernel_Machines.html">69 nips-2004-Fast Rates to Bayes for Kernel Machines</a></p>
<p>8 0.59545583 <a title="105-lda-8" href="./nips-2004-Worst-Case_Analysis_of_Selective_Sampling_for_Linear-Threshold_Algorithms.html">206 nips-2004-Worst-Case Analysis of Selective Sampling for Linear-Threshold Algorithms</a></p>
<p>9 0.58542818 <a title="105-lda-9" href="./nips-2004-Sampling_Methods_for_Unsupervised_Learning.html">158 nips-2004-Sampling Methods for Unsupervised Learning</a></p>
<p>10 0.58509445 <a title="105-lda-10" href="./nips-2004-Co-Validation%3A_Using_Model_Disagreement_on_Unlabeled_Data_to_Validate_Classification_Algorithms.html">38 nips-2004-Co-Validation: Using Model Disagreement on Unlabeled Data to Validate Classification Algorithms</a></p>
<p>11 0.58426571 <a title="105-lda-11" href="./nips-2004-Semigroup_Kernels_on_Finite_Sets.html">168 nips-2004-Semigroup Kernels on Finite Sets</a></p>
<p>12 0.58401072 <a title="105-lda-12" href="./nips-2004-Limits_of_Spectral_Clustering.html">103 nips-2004-Limits of Spectral Clustering</a></p>
<p>13 0.5812552 <a title="105-lda-13" href="./nips-2004-Exploration-Exploitation_Tradeoffs_for_Experts_Algorithms_in_Reactive_Environments.html">65 nips-2004-Exploration-Exploitation Tradeoffs for Experts Algorithms in Reactive Environments</a></p>
<p>14 0.57984626 <a title="105-lda-14" href="./nips-2004-Using_the_Equivalent_Kernel_to_Understand_Gaussian_Process_Regression.html">201 nips-2004-Using the Equivalent Kernel to Understand Gaussian Process Regression</a></p>
<p>15 0.57427979 <a title="105-lda-15" href="./nips-2004-Inference%2C_Attention%2C_and_Decision_in_a_Bayesian_Neural_Architecture.html">84 nips-2004-Inference, Attention, and Decision in a Bayesian Neural Architecture</a></p>
<p>16 0.57353103 <a title="105-lda-16" href="./nips-2004-Resolving_Perceptual_Aliasing_In_The_Presence_Of_Noisy_Sensors.html">154 nips-2004-Resolving Perceptual Aliasing In The Presence Of Noisy Sensors</a></p>
<p>17 0.5722158 <a title="105-lda-17" href="./nips-2004-Stable_adaptive_control_with_online_learning.html">175 nips-2004-Stable adaptive control with online learning</a></p>
<p>18 0.57017195 <a title="105-lda-18" href="./nips-2004-Result_Analysis_of_the_NIPS_2003_Feature_Selection_Challenge.html">156 nips-2004-Result Analysis of the NIPS 2003 Feature Selection Challenge</a></p>
<p>19 0.56162566 <a title="105-lda-19" href="./nips-2004-Generalization_Error_Bounds_for_Collaborative_Prediction_with_Low-Rank_Matrices.html">71 nips-2004-Generalization Error Bounds for Collaborative Prediction with Low-Rank Matrices</a></p>
<p>20 0.56139839 <a title="105-lda-20" href="./nips-2004-Spike_Sorting%3A_Bayesian_Clustering_of_Non-Stationary_Data.html">174 nips-2004-Spike Sorting: Bayesian Clustering of Non-Stationary Data</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
