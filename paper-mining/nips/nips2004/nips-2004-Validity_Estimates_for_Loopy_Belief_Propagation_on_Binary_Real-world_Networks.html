<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>203 nips-2004-Validity Estimates for Loopy Belief Propagation on Binary Real-world Networks</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2004" href="../home/nips2004_home.html">nips2004</a> <a title="nips-2004-203" href="#">nips2004-203</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>203 nips-2004-Validity Estimates for Loopy Belief Propagation on Binary Real-world Networks</h1>
<br/><p>Source: <a title="nips-2004-203-pdf" href="http://papers.nips.cc/paper/2741-validity-estimates-for-loopy-belief-propagation-on-binary-real-world-networks.pdf">pdf</a></p><p>Author: Joris M. Mooij, Hilbert J. Kappen</p><p>Abstract: We introduce a computationally efﬁcient method to estimate the validity of the BP method as a function of graph topology, the connectivity strength, frustration and network size. We present numerical results that demonstrate the correctness of our estimates for the uniform random model and for a real-world network (“C. Elegans”). Although the method is restricted to pair-wise interactions, no local evidence (zero “biases”) and binary variables, we believe that its predictions correctly capture the limitations of BP for inference and MAP estimation on arbitrary graphical models. Using this approach, we ﬁnd that BP always performs better than MF. Especially for large networks with broad degree distributions (such as scale-free networks) BP turns out to signiﬁcantly outperform MF. 1</p><p>Reference: <a title="nips-2004-203-reference" href="../nips2004_reference/nips-2004-Validity_Estimates_for_Loopy_Belief_Propagation_on_Binary_Real-world_Networks_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Validity estimates for loopy Belief Propagation on binary real-world networks  Joris Mooij Dept. [sent-1, score-0.232]
</p><p>2 nl  Abstract We introduce a computationally efﬁcient method to estimate the validity of the BP method as a function of graph topology, the connectivity strength, frustration and network size. [sent-14, score-0.513]
</p><p>3 We present numerical results that demonstrate the correctness of our estimates for the uniform random model and for a real-world network (“C. [sent-15, score-0.212]
</p><p>4 Although the method is restricted to pair-wise interactions, no local evidence (zero “biases”) and binary variables, we believe that its predictions correctly capture the limitations of BP for inference and MAP estimation on arbitrary graphical models. [sent-17, score-0.096]
</p><p>5 Especially for large networks with broad degree distributions (such as scale-free networks) BP turns out to signiﬁcantly outperform MF. [sent-19, score-0.336]
</p><p>6 As is well-known, BP is exact on trees, but also yields surprisingly good results for many other graphs that arise in real-world applications [3, 4]. [sent-21, score-0.261]
</p><p>7 On the other hand, for densely connected graphs with high interaction strengths the results can be quite bad or BP can simply fail to converge. [sent-22, score-0.325]
</p><p>8 Despite the fact that BP is often used in applications nowadays, a good theoretical understanding of its convergence properties and the quality of the approximation is still lacking (except for the very special case of graphs with a single loop [5]). [sent-23, score-0.334]
</p><p>9 In this article we attempt to answer the question in what way the quality of the BP results depends on the topology of the underlying graph (looking at structural properties such as short cycles and large “hubs”) and on the interaction potentials (i. [sent-24, score-0.3]
</p><p>10 We do this for the special but interesting case of binary networks with symmetric pairwise potentials (i. [sent-27, score-0.136]
</p><p>11 This has the practical  advantage that analytical calculations are feasible and furthermore we believe that adding local evidence will only serve to extend the domain of convergence, implying this to be the worst-case scenario. [sent-30, score-0.057]
</p><p>12 Real-world graphs are often far from uniformly random and possess structure such as clustering and power-law degree distributions [6]. [sent-32, score-0.498]
</p><p>13 Since we expect these structural features to arise in many applications of BP, we focus in this article on graphs modeling this kind of features. [sent-33, score-0.335]
</p><p>14 In particular, we consider Erd˝ s-R´ nyi uniform random graphs [7], Bar´ basio e a Albert “scale-free” graphs [8], and the neural network of a widely studied worm, the Caenorhabditis elegans. [sent-34, score-0.603]
</p><p>15 In the next section we describe the class of graphical models under investigation and explain our method to efﬁciently estimate the validity of BP and MF. [sent-36, score-0.196]
</p><p>16 In section 3 we give a qualitative discussion of how the connectivity strength and frustration generally govern the model behavior and discuss the relevant regimes of the model parameters. [sent-37, score-0.371]
</p><p>17 We show for uniform random graphs that our validity estimates are in very good agreement with the real behavior of the BP algorithm. [sent-38, score-0.594]
</p><p>18 In section 4 we study the inﬂuence of graph topology. [sent-39, score-0.083]
</p><p>19 Thanks to the numerical efﬁciency of our estimation method we are able to study very large (N ∼ 10000) networks, for which it would not be feasible to simply run BP and look what happens. [sent-40, score-0.03]
</p><p>20 We also try our method on the neural network of the worm C. [sent-41, score-0.182]
</p><p>21 Elegans and ﬁnd almost perfect agreement of our predictions with observed BP behavior. [sent-42, score-0.068]
</p><p>22 We conclude that BP is always better than MF and that the difference is particularly striking for the case of large networks with broad degree distributions such as scale-free graphs. [sent-43, score-0.336]
</p><p>23 2  Model, paramagnetic solution and stability analysis  Let G = (V, B) be an undirected labelled graph without self-connections, deﬁned by a set of nodes V = {1, . [sent-44, score-0.258]
</p><p>24 , N } and a set of links B ⊆ {(i, j) | 1 ≤ i < j ≤ N }. [sent-47, score-0.036]
</p><p>25 The adjacency matrix corresponding to G is denoted M and deﬁned as follows: Mij := 1 if (ij) ∈ B or (ji) ∈ B and 0 otherwise. [sent-48, score-0.027]
</p><p>26 We denote the set of neighbors of node i ∈ V by Ni := {j ∈ V | (ij) ∈ B} and its degree by di := #(Ni ). [sent-49, score-0.289]
</p><p>27 We deﬁne the average degree 1 d := N i∈V di and the maximum degree ∆ := maxi∈V di . [sent-50, score-0.523]
</p><p>28 To each node i we associate a binary random variable xi taking values in {−1, +1}. [sent-51, score-0.106]
</p><p>29 Let W be a symmetric N × N -matrix deﬁning the strength of the links between the nodes. [sent-52, score-0.107]
</p><p>30 The ﬁrst random graph model exhibiting this behavior is from Barab´ si and Albert [8]. [sent-62, score-0.174]
</p><p>31 It is deﬁned as a stochastic process, yielding graphs with more and more nodes as time goes on. [sent-64, score-0.284]
</p><p>32 At t = 0 one starts with the graph consisting of m nodes and no links. [sent-65, score-0.135]
</p><p>33 At each time step, one node is added; it is connected with m different already existing nodes, attaching preferably to nodes with higher degree (“rich get richer”). [sent-66, score-0.333]
</p><p>34 More speciﬁcally, we take the probability to connect to a node of degree δ to be proportional to δ + 1. [sent-67, score-0.286]
</p><p>35 The degree distribution turns out to have a power-law dependence for N → ∞ with exponent α = 3. [sent-68, score-0.237]
</p><p>36 The difference between the maximum degree ∆ and the average degree d is rather large: whereas the average degree d converges to 2m, the √ maximum degree ∆ is known to scale as N . [sent-71, score-0.898]
</p><p>37 5 shows the results of the stability analysis for BA graphs with average degree d = √ M 10. [sent-73, score-0.527]
</p><p>38 Note that the √ y-axis is rescaled by ∆ to show that the MF critical value Jc F is proportional to 1/ ∆. [sent-74, score-0.216]
</p><p>39 The √ Bethe critical values are seen to have a scaling behavior that √ lies somewhere between 1/ d and 1/ ∆. [sent-75, score-0.165]
</p><p>40 Compared to the situation for uniform ER graphs, BP now even more signiﬁcantly outperforms MF. [sent-76, score-0.043]
</p><p>41 The relatively low sensitivity to the maximum degree ∆ that BP exhibits here can be understood intuitively since BA graphs resemble forests of sparsely interconnected stars of high degree, on which BP is exact. [sent-77, score-0.696]
</p><p>42 Elegans  We have also applied our stability analysis on the neural network of the worm C. [sent-80, score-0.238]
</p><p>43 We have calculated the ferromagnetic (J = 0) transition and spin-glass (J0 = 0) transition. [sent-86, score-0.102]
</p><p>44 We also calculated the critical value of J where BP stops converging, and the value of J where BP does not ﬁnd the paramagnetic solution anymore. [sent-87, score-0.252]
</p><p>45 Note the very good agreement for the Bethe critical value and the critical J where BP stops ﬁnding the m = 0 solution. [sent-89, score-0.384]
</p><p>46 These results show the accuracy of our method of estimating BP validity on real-world networks. [sent-90, score-0.161]
</p><p>47 MF critical value Bethe critical value BP m = 0 boundary BP convergence boundary  5  Spin-glass 0. [sent-93, score-0.316]
</p><p>48 0400 >1  Conclusions  We have introduced a computationally efﬁcient method to estimate the validity of BP as a function of graph topology, the connectivity strength, frustration and network size. [sent-104, score-0.513]
</p><p>49 In contrast, the validity of the BP approximation scales very well with network size. [sent-106, score-0.306]
</p><p>50 This is in agreement with our intuition that these networks resemble a forest of high degree stars (“hubs”) that are sparsely interconnected and the fact that BP is exact on stars. [sent-107, score-0.571]
</p><p>51 • In the limit in which the graph size N → ∞ and the average degree d scales proportional to N , the inﬂuence of √ graph-topological details on the location of the the spin-glass transition (at J ∝ 1/ d) diminishes and becomes largely irrelevant. [sent-108, score-0.46]
</p><p>52 m=1  m=2  m=3  Figure 4: Bar´ basi-Albert graphs for N = 20. [sent-109, score-0.232]
</p><p>53 a  1/2  Jc ∆  6 5 4 3 2 1 0  Bethe 1/d1/2 MF  10  100  1000  10000  N  Figure 5: Critical values for Bethe and MF for BA√ scale-free random graphs with average degree d = 10. [sent-110, score-0.501]
</p><p>54 In Advances in Neural Information Processing Systems, volume 13, pages 689–695, 2001. [sent-122, score-0.042]
</p><p>55 Loopy belief propagation for approximate inference: an empirical study. [sent-127, score-0.184]
</p><p>56 In Advances in Neural Information Processing Systems, volume 10, pages 479–485, 1997. [sent-135, score-0.042]
</p><p>57 Correctness of local probability propagation in graphical models with loops. [sent-138, score-0.116]
</p><p>58 Stable ﬁxed points of loopy belief propagation are local minima of the bethe free energy. [sent-166, score-0.559]
</p><p>59 In Advances in Neural Information Processing Systems, volume 15, pages 343–350, 2003. [sent-167, score-0.042]
</p><p>60 Belief optimization for binary networks: a stable alternative to loopy belief propagation. [sent-172, score-0.27]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('bp', 0.578), ('bethe', 0.269), ('mf', 0.246), ('graphs', 0.232), ('degree', 0.21), ('elegans', 0.193), ('validity', 0.161), ('nijmegen', 0.155), ('ba', 0.143), ('frustration', 0.135), ('critical', 0.131), ('barab', 0.116), ('worm', 0.116), ('loopy', 0.106), ('belief', 0.103), ('jc', 0.101), ('albert', 0.092), ('graph', 0.083), ('propagation', 0.081), ('erd', 0.077), ('mooij', 0.077), ('radboud', 0.077), ('strength', 0.071), ('connectivity', 0.068), ('agreement', 0.068), ('paramagnetic', 0.067), ('ferromagnetic', 0.067), ('biophysics', 0.067), ('hubs', 0.067), ('networks', 0.066), ('network', 0.066), ('sparsely', 0.061), ('stars', 0.061), ('netherlands', 0.057), ('stability', 0.056), ('wij', 0.056), ('stops', 0.054), ('resemble', 0.054), ('mij', 0.054), ('nodes', 0.052), ('rescaled', 0.051), ('interconnected', 0.051), ('ez', 0.051), ('topology', 0.051), ('correctness', 0.047), ('uniform', 0.043), ('volume', 0.042), ('node', 0.042), ('bar', 0.041), ('approximation', 0.041), ('richer', 0.04), ('strengths', 0.04), ('article', 0.04), ('scales', 0.038), ('di', 0.037), ('rich', 0.037), ('ni', 0.036), ('potentials', 0.036), ('links', 0.036), ('transition', 0.035), ('graphical', 0.035), ('proportional', 0.034), ('structural', 0.034), ('ij', 0.034), ('regimes', 0.034), ('affairs', 0.034), ('dutch', 0.034), ('behavior', 0.034), ('binary', 0.034), ('broad', 0.033), ('preprint', 0.031), ('diminishes', 0.031), ('lacking', 0.031), ('ministry', 0.031), ('quality', 0.03), ('feasible', 0.03), ('random', 0.03), ('arise', 0.029), ('average', 0.029), ('spin', 0.029), ('kappen', 0.029), ('preferably', 0.029), ('mechanics', 0.029), ('interactive', 0.029), ('govern', 0.029), ('believe', 0.027), ('boundary', 0.027), ('forests', 0.027), ('striking', 0.027), ('adjacency', 0.027), ('exhibiting', 0.027), ('densely', 0.027), ('frey', 0.027), ('stable', 0.027), ('turns', 0.027), ('neuroscience', 0.027), ('interaction', 0.026), ('estimates', 0.026), ('possess', 0.026), ('diagrams', 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="203-tfidf-1" href="./nips-2004-Validity_Estimates_for_Loopy_Belief_Propagation_on_Binary_Real-world_Networks.html">203 nips-2004-Validity Estimates for Loopy Belief Propagation on Binary Real-world Networks</a></p>
<p>Author: Joris M. Mooij, Hilbert J. Kappen</p><p>Abstract: We introduce a computationally efﬁcient method to estimate the validity of the BP method as a function of graph topology, the connectivity strength, frustration and network size. We present numerical results that demonstrate the correctness of our estimates for the uniform random model and for a real-world network (“C. Elegans”). Although the method is restricted to pair-wise interactions, no local evidence (zero “biases”) and binary variables, we believe that its predictions correctly capture the limitations of BP for inference and MAP estimation on arbitrary graphical models. Using this approach, we ﬁnd that BP always performs better than MF. Especially for large networks with broad degree distributions (such as scale-free networks) BP turns out to signiﬁcantly outperform MF. 1</p><p>2 0.31296134 <a title="203-tfidf-2" href="./nips-2004-Message_Errors_in_Belief_Propagation.html">116 nips-2004-Message Errors in Belief Propagation</a></p>
<p>Author: Alexander T. Ihler, John W. Fisher, Alan S. Willsky</p><p>Abstract: Belief propagation (BP) is an increasingly popular method of performing approximate inference on arbitrary graphical models. At times, even further approximations are required, whether from quantization or other simpliﬁed message representations or from stochastic approximation methods. Introducing such errors into the BP message computations has the potential to adversely affect the solution obtained. We analyze this effect with respect to a particular measure of message error, and show bounds on the accumulation of errors in the system. This leads both to convergence conditions and error bounds in traditional and approximate BP message passing. 1</p><p>3 0.22323927 <a title="203-tfidf-3" href="./nips-2004-Expectation_Consistent_Free_Energies_for_Approximate_Inference.html">63 nips-2004-Expectation Consistent Free Energies for Approximate Inference</a></p>
<p>Author: Manfred Opper, Ole Winther</p><p>Abstract: We propose a novel a framework for deriving approximations for intractable probabilistic models. This framework is based on a free energy (negative log marginal likelihood) and can be seen as a generalization of adaptive TAP [1, 2, 3] and expectation propagation (EP) [4, 5]. The free energy is constructed from two approximating distributions which encode different aspects of the intractable model such a single node constraints and couplings and are by construction consistent on a chosen set of moments. We test the framework on a difﬁcult benchmark problem with binary variables on fully connected graphs and 2D grid graphs. We ﬁnd good performance using sets of moments which either specify factorized nodes or a spanning tree on the nodes (structured approximation). Surprisingly, the Bethe approximation gives very inferior results even on grids. 1</p><p>4 0.098085068 <a title="203-tfidf-4" href="./nips-2004-Distributed_Occlusion_Reasoning_for_Tracking_with_Nonparametric_Belief_Propagation.html">55 nips-2004-Distributed Occlusion Reasoning for Tracking with Nonparametric Belief Propagation</a></p>
<p>Author: Erik B. Sudderth, Michael I. Mandel, William T. Freeman, Alan S. Willsky</p><p>Abstract: We describe a three–dimensional geometric hand model suitable for visual tracking applications. The kinematic constraints implied by the model’s joints have a probabilistic structure which is well described by a graphical model. Inference in this model is complicated by the hand’s many degrees of freedom, as well as multimodal likelihoods caused by ambiguous image measurements. We use nonparametric belief propagation (NBP) to develop a tracking algorithm which exploits the graph’s structure to control complexity, while avoiding costly discretization. While kinematic constraints naturally have a local structure, self– occlusions created by the imaging process lead to complex interpendencies in color and edge–based likelihood functions. However, we show that local structure may be recovered by introducing binary hidden variables describing the occlusion state of each pixel. We augment the NBP algorithm to infer these occlusion variables in a distributed fashion, and then analytically marginalize over them to produce hand position estimates which properly account for occlusion events. We provide simulations showing that NBP may be used to reﬁne inaccurate model initializations, as well as track hand motion through extended image sequences. 1</p><p>5 0.097074911 <a title="203-tfidf-5" href="./nips-2004-Comparing_Beliefs%2C_Surveys%2C_and_Random_Walks.html">41 nips-2004-Comparing Beliefs, Surveys, and Random Walks</a></p>
<p>Author: Erik Aurell, Uri Gordon, Scott Kirkpatrick</p><p>Abstract: Survey propagation is a powerful technique from statistical physics that has been applied to solve the 3-SAT problem both in principle and in practice. We give, using only probability arguments, a common derivation of survey propagation, belief propagation and several interesting hybrid methods. We then present numerical experiments which use WSAT (a widely used random-walk based SAT solver) to quantify the complexity of the 3-SAT formulae as a function of their parameters, both as randomly generated and after simpli£cation, guided by survey propagation. Some properties of WSAT which have not previously been reported make it an ideal tool for this purpose – its mean cost is proportional to the number of variables in the formula (at a £xed ratio of clauses to variables) in the easy-SAT regime and slightly beyond, and its behavior in the hardSAT regime appears to re¤ect the underlying structure of the solution space that has been predicted by replica symmetry-breaking arguments. An analysis of the tradeoffs between the various methods of search for satisfying assignments shows WSAT to be far more powerful than has been appreciated, and suggests some interesting new directions for practical algorithm development. 1</p><p>6 0.094357572 <a title="203-tfidf-6" href="./nips-2004-Modelling_Uncertainty_in_the_Game_of_Go.html">122 nips-2004-Modelling Uncertainty in the Game of Go</a></p>
<p>7 0.080715775 <a title="203-tfidf-7" href="./nips-2004-At_the_Edge_of_Chaos%3A_Real-time_Computations_and_Self-Organized_Criticality_in_Recurrent_Neural_Networks.html">26 nips-2004-At the Edge of Chaos: Real-time Computations and Self-Organized Criticality in Recurrent Neural Networks</a></p>
<p>8 0.068329744 <a title="203-tfidf-8" href="./nips-2004-Distributed_Information_Regularization_on_Graphs.html">54 nips-2004-Distributed Information Regularization on Graphs</a></p>
<p>9 0.067195617 <a title="203-tfidf-9" href="./nips-2004-Proximity_Graphs_for_Clustering_and_Manifold_Learning.html">150 nips-2004-Proximity Graphs for Clustering and Manifold Learning</a></p>
<p>10 0.063492455 <a title="203-tfidf-10" href="./nips-2004-Semi-supervised_Learning_on_Directed_Graphs.html">165 nips-2004-Semi-supervised Learning on Directed Graphs</a></p>
<p>11 0.062995091 <a title="203-tfidf-11" href="./nips-2004-Hierarchical_Bayesian_Inference_in_Networks_of_Spiking_Neurons.html">76 nips-2004-Hierarchical Bayesian Inference in Networks of Spiking Neurons</a></p>
<p>12 0.057948612 <a title="203-tfidf-12" href="./nips-2004-An_Application_of_Boosting_to_Graph_Classification.html">19 nips-2004-An Application of Boosting to Graph Classification</a></p>
<p>13 0.056987029 <a title="203-tfidf-13" href="./nips-2004-Economic_Properties_of_Social_Networks.html">57 nips-2004-Economic Properties of Social Networks</a></p>
<p>14 0.050933555 <a title="203-tfidf-14" href="./nips-2004-VDCBPI%3A_an_Approximate_Scalable_Algorithm_for_Large_POMDPs.html">202 nips-2004-VDCBPI: an Approximate Scalable Algorithm for Large POMDPs</a></p>
<p>15 0.050780065 <a title="203-tfidf-15" href="./nips-2004-Newscast_EM.html">130 nips-2004-Newscast EM</a></p>
<p>16 0.050735332 <a title="203-tfidf-16" href="./nips-2004-Nonparametric_Transforms_of_Graph_Kernels_for_Semi-Supervised_Learning.html">133 nips-2004-Nonparametric Transforms of Graph Kernels for Semi-Supervised Learning</a></p>
<p>17 0.049094398 <a title="203-tfidf-17" href="./nips-2004-Contextual_Models_for_Object_Detection_Using_Boosted_Random_Fields.html">47 nips-2004-Contextual Models for Object Detection Using Boosted Random Fields</a></p>
<p>18 0.046006765 <a title="203-tfidf-18" href="./nips-2004-Theory_of_localized_synfire_chain%3A_characteristic_propagation_speed_of_stable_spike_pattern.html">194 nips-2004-Theory of localized synfire chain: characteristic propagation speed of stable spike pattern</a></p>
<p>19 0.043262757 <a title="203-tfidf-19" href="./nips-2004-Beat_Tracking_the_Graphical_Model_Way.html">29 nips-2004-Beat Tracking the Graphical Model Way</a></p>
<p>20 0.042318091 <a title="203-tfidf-20" href="./nips-2004-Conditional_Random_Fields_for_Object_Recognition.html">44 nips-2004-Conditional Random Fields for Object Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2004_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.143), (1, -0.018), (2, 0.027), (3, -0.021), (4, 0.07), (5, 0.014), (6, -0.023), (7, 0.169), (8, -0.18), (9, -0.409), (10, 0.059), (11, -0.218), (12, 0.138), (13, 0.041), (14, 0.05), (15, -0.038), (16, 0.04), (17, 0.104), (18, 0.125), (19, 0.193), (20, 0.098), (21, -0.053), (22, 0.112), (23, 0.082), (24, 0.05), (25, -0.089), (26, -0.022), (27, 0.117), (28, 0.022), (29, -0.075), (30, 0.085), (31, 0.014), (32, 0.027), (33, 0.052), (34, 0.059), (35, -0.089), (36, 0.009), (37, -0.01), (38, 0.033), (39, 0.04), (40, 0.022), (41, -0.121), (42, 0.072), (43, -0.023), (44, -0.005), (45, -0.097), (46, 0.043), (47, -0.049), (48, -0.041), (49, -0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97643161 <a title="203-lsi-1" href="./nips-2004-Validity_Estimates_for_Loopy_Belief_Propagation_on_Binary_Real-world_Networks.html">203 nips-2004-Validity Estimates for Loopy Belief Propagation on Binary Real-world Networks</a></p>
<p>Author: Joris M. Mooij, Hilbert J. Kappen</p><p>Abstract: We introduce a computationally efﬁcient method to estimate the validity of the BP method as a function of graph topology, the connectivity strength, frustration and network size. We present numerical results that demonstrate the correctness of our estimates for the uniform random model and for a real-world network (“C. Elegans”). Although the method is restricted to pair-wise interactions, no local evidence (zero “biases”) and binary variables, we believe that its predictions correctly capture the limitations of BP for inference and MAP estimation on arbitrary graphical models. Using this approach, we ﬁnd that BP always performs better than MF. Especially for large networks with broad degree distributions (such as scale-free networks) BP turns out to signiﬁcantly outperform MF. 1</p><p>2 0.82375783 <a title="203-lsi-2" href="./nips-2004-Message_Errors_in_Belief_Propagation.html">116 nips-2004-Message Errors in Belief Propagation</a></p>
<p>Author: Alexander T. Ihler, John W. Fisher, Alan S. Willsky</p><p>Abstract: Belief propagation (BP) is an increasingly popular method of performing approximate inference on arbitrary graphical models. At times, even further approximations are required, whether from quantization or other simpliﬁed message representations or from stochastic approximation methods. Introducing such errors into the BP message computations has the potential to adversely affect the solution obtained. We analyze this effect with respect to a particular measure of message error, and show bounds on the accumulation of errors in the system. This leads both to convergence conditions and error bounds in traditional and approximate BP message passing. 1</p><p>3 0.80886251 <a title="203-lsi-3" href="./nips-2004-Expectation_Consistent_Free_Energies_for_Approximate_Inference.html">63 nips-2004-Expectation Consistent Free Energies for Approximate Inference</a></p>
<p>Author: Manfred Opper, Ole Winther</p><p>Abstract: We propose a novel a framework for deriving approximations for intractable probabilistic models. This framework is based on a free energy (negative log marginal likelihood) and can be seen as a generalization of adaptive TAP [1, 2, 3] and expectation propagation (EP) [4, 5]. The free energy is constructed from two approximating distributions which encode different aspects of the intractable model such a single node constraints and couplings and are by construction consistent on a chosen set of moments. We test the framework on a difﬁcult benchmark problem with binary variables on fully connected graphs and 2D grid graphs. We ﬁnd good performance using sets of moments which either specify factorized nodes or a spanning tree on the nodes (structured approximation). Surprisingly, the Bethe approximation gives very inferior results even on grids. 1</p><p>4 0.56335074 <a title="203-lsi-4" href="./nips-2004-Comparing_Beliefs%2C_Surveys%2C_and_Random_Walks.html">41 nips-2004-Comparing Beliefs, Surveys, and Random Walks</a></p>
<p>Author: Erik Aurell, Uri Gordon, Scott Kirkpatrick</p><p>Abstract: Survey propagation is a powerful technique from statistical physics that has been applied to solve the 3-SAT problem both in principle and in practice. We give, using only probability arguments, a common derivation of survey propagation, belief propagation and several interesting hybrid methods. We then present numerical experiments which use WSAT (a widely used random-walk based SAT solver) to quantify the complexity of the 3-SAT formulae as a function of their parameters, both as randomly generated and after simpli£cation, guided by survey propagation. Some properties of WSAT which have not previously been reported make it an ideal tool for this purpose – its mean cost is proportional to the number of variables in the formula (at a £xed ratio of clauses to variables) in the easy-SAT regime and slightly beyond, and its behavior in the hardSAT regime appears to re¤ect the underlying structure of the solution space that has been predicted by replica symmetry-breaking arguments. An analysis of the tradeoffs between the various methods of search for satisfying assignments shows WSAT to be far more powerful than has been appreciated, and suggests some interesting new directions for practical algorithm development. 1</p><p>5 0.52280033 <a title="203-lsi-5" href="./nips-2004-Modelling_Uncertainty_in_the_Game_of_Go.html">122 nips-2004-Modelling Uncertainty in the Game of Go</a></p>
<p>Author: David H. Stern, Thore Graepel, David MacKay</p><p>Abstract: Go is an ancient oriental game whose complexity has defeated attempts to automate it. We suggest using probability in a Bayesian sense to model the uncertainty arising from the vast complexity of the game tree. We present a simple conditional Markov random ﬁeld model for predicting the pointwise territory outcome of a game. The topology of the model reﬂects the spatial structure of the Go board. We describe a version of the Swendsen-Wang process for sampling from the model during learning and apply loopy belief propagation for rapid inference and prediction. The model is trained on several hundred records of professional games. Our experimental results indicate that the model successfully learns to predict territory despite its simplicity. 1</p><p>6 0.39587015 <a title="203-lsi-6" href="./nips-2004-Economic_Properties_of_Social_Networks.html">57 nips-2004-Economic Properties of Social Networks</a></p>
<p>7 0.38802311 <a title="203-lsi-7" href="./nips-2004-Distributed_Occlusion_Reasoning_for_Tracking_with_Nonparametric_Belief_Propagation.html">55 nips-2004-Distributed Occlusion Reasoning for Tracking with Nonparametric Belief Propagation</a></p>
<p>8 0.33998621 <a title="203-lsi-8" href="./nips-2004-Beat_Tracking_the_Graphical_Model_Way.html">29 nips-2004-Beat Tracking the Graphical Model Way</a></p>
<p>9 0.27607062 <a title="203-lsi-9" href="./nips-2004-Conditional_Models_of_Identity_Uncertainty_with_Application_to_Noun_Coreference.html">43 nips-2004-Conditional Models of Identity Uncertainty with Application to Noun Coreference</a></p>
<p>10 0.27025384 <a title="203-lsi-10" href="./nips-2004-Proximity_Graphs_for_Clustering_and_Manifold_Learning.html">150 nips-2004-Proximity Graphs for Clustering and Manifold Learning</a></p>
<p>11 0.26257116 <a title="203-lsi-11" href="./nips-2004-Semi-supervised_Learning_on_Directed_Graphs.html">165 nips-2004-Semi-supervised Learning on Directed Graphs</a></p>
<p>12 0.25255832 <a title="203-lsi-12" href="./nips-2004-Newscast_EM.html">130 nips-2004-Newscast EM</a></p>
<p>13 0.24949192 <a title="203-lsi-13" href="./nips-2004-Hierarchical_Bayesian_Inference_in_Networks_of_Spiking_Neurons.html">76 nips-2004-Hierarchical Bayesian Inference in Networks of Spiking Neurons</a></p>
<p>14 0.23578291 <a title="203-lsi-14" href="./nips-2004-Efficient_Out-of-Sample_Extension_of_Dominant-Set_Clusters.html">61 nips-2004-Efficient Out-of-Sample Extension of Dominant-Set Clusters</a></p>
<p>15 0.2273965 <a title="203-lsi-15" href="./nips-2004-Contextual_Models_for_Object_Detection_Using_Boosted_Random_Fields.html">47 nips-2004-Contextual Models for Object Detection Using Boosted Random Fields</a></p>
<p>16 0.20668209 <a title="203-lsi-16" href="./nips-2004-At_the_Edge_of_Chaos%3A_Real-time_Computations_and_Self-Organized_Criticality_in_Recurrent_Neural_Networks.html">26 nips-2004-At the Edge of Chaos: Real-time Computations and Self-Organized Criticality in Recurrent Neural Networks</a></p>
<p>17 0.20376155 <a title="203-lsi-17" href="./nips-2004-Optimal_sub-graphical_models.html">141 nips-2004-Optimal sub-graphical models</a></p>
<p>18 0.20324658 <a title="203-lsi-18" href="./nips-2004-Co-Validation%3A_Using_Model_Disagreement_on_Unlabeled_Data_to_Validate_Classification_Algorithms.html">38 nips-2004-Co-Validation: Using Model Disagreement on Unlabeled Data to Validate Classification Algorithms</a></p>
<p>19 0.20253919 <a title="203-lsi-19" href="./nips-2004-Neural_Network_Computation_by_In_Vitro_Transcriptional_Circuits.html">128 nips-2004-Neural Network Computation by In Vitro Transcriptional Circuits</a></p>
<p>20 0.1952045 <a title="203-lsi-20" href="./nips-2004-Instance-Specific_Bayesian_Model_Averaging_for_Classification.html">86 nips-2004-Instance-Specific Bayesian Model Averaging for Classification</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2004_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.03), (15, 0.643), (26, 0.028), (31, 0.017), (33, 0.177)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.99419034 <a title="203-lda-1" href="./nips-2004-Dependent_Gaussian_Processes.html">50 nips-2004-Dependent Gaussian Processes</a></p>
<p>Author: Phillip Boyle, Marcus Frean</p><p>Abstract: Gaussian processes are usually parameterised in terms of their covariance functions. However, this makes it difﬁcult to deal with multiple outputs, because ensuring that the covariance matrix is positive deﬁnite is problematic. An alternative formulation is to treat Gaussian processes as white noise sources convolved with smoothing kernels, and to parameterise the kernel instead. Using this, we extend Gaussian processes to handle multiple, coupled outputs. 1</p><p>2 0.98815221 <a title="203-lda-2" href="./nips-2004-Efficient_Kernel_Discriminant_Analysis_via_QR_Decomposition.html">59 nips-2004-Efficient Kernel Discriminant Analysis via QR Decomposition</a></p>
<p>Author: Tao Xiong, Jieping Ye, Qi Li, Ravi Janardan, Vladimir Cherkassky</p><p>Abstract: Linear Discriminant Analysis (LDA) is a well-known method for feature extraction and dimension reduction. It has been used widely in many applications such as face recognition. Recently, a novel LDA algorithm based on QR Decomposition, namely LDA/QR, has been proposed, which is competitive in terms of classiﬁcation accuracy with other LDA algorithms, but it has much lower costs in time and space. However, LDA/QR is based on linear projection, which may not be suitable for data with nonlinear structure. This paper ﬁrst proposes an algorithm called KDA/QR, which extends the LDA/QR algorithm to deal with nonlinear data by using the kernel operator. Then an efﬁcient approximation of KDA/QR called AKDA/QR is proposed. Experiments on face image data show that the classiﬁcation accuracy of both KDA/QR and AKDA/QR are competitive with Generalized Discriminant Analysis (GDA), a general kernel discriminant analysis algorithm, while AKDA/QR has much lower time and space costs. 1</p><p>same-paper 3 0.98588687 <a title="203-lda-3" href="./nips-2004-Validity_Estimates_for_Loopy_Belief_Propagation_on_Binary_Real-world_Networks.html">203 nips-2004-Validity Estimates for Loopy Belief Propagation on Binary Real-world Networks</a></p>
<p>Author: Joris M. Mooij, Hilbert J. Kappen</p><p>Abstract: We introduce a computationally efﬁcient method to estimate the validity of the BP method as a function of graph topology, the connectivity strength, frustration and network size. We present numerical results that demonstrate the correctness of our estimates for the uniform random model and for a real-world network (“C. Elegans”). Although the method is restricted to pair-wise interactions, no local evidence (zero “biases”) and binary variables, we believe that its predictions correctly capture the limitations of BP for inference and MAP estimation on arbitrary graphical models. Using this approach, we ﬁnd that BP always performs better than MF. Especially for large networks with broad degree distributions (such as scale-free networks) BP turns out to signiﬁcantly outperform MF. 1</p><p>4 0.98435593 <a title="203-lda-4" href="./nips-2004-A_Three_Tiered_Approach_for_Articulated_Object_Action_Modeling_and_Recognition.html">13 nips-2004-A Three Tiered Approach for Articulated Object Action Modeling and Recognition</a></p>
<p>Author: Le Lu, Gregory D. Hager, Laurent Younes</p><p>Abstract: Visual action recognition is an important problem in computer vision. In this paper, we propose a new method to probabilistically model and recognize actions of articulated objects, such as hand or body gestures, in image sequences. Our method consists of three levels of representation. At the low level, we ﬁrst extract a feature vector invariant to scale and in-plane rotation by using the Fourier transform of a circular spatial histogram. Then, spectral partitioning [20] is utilized to obtain an initial clustering; this clustering is then reﬁned using a temporal smoothness constraint. Gaussian mixture model (GMM) based clustering and density estimation in the subspace of linear discriminant analysis (LDA) are then applied to thousands of image feature vectors to obtain an intermediate level representation. Finally, at the high level we build a temporal multiresolution histogram model for each action by aggregating the clustering weights of sampled images belonging to that action. We discuss how this high level representation can be extended to achieve temporal scaling invariance and to include Bi-gram or Multi-gram transition information. Both image clustering and action recognition/segmentation results are given to show the validity of our three tiered representation.</p><p>5 0.95566249 <a title="203-lda-5" href="./nips-2004-Kernel_Methods_for_Implicit_Surface_Modeling.html">92 nips-2004-Kernel Methods for Implicit Surface Modeling</a></p>
<p>Author: Joachim Giesen, Simon Spalinger, Bernhard Schölkopf</p><p>Abstract: We describe methods for computing an implicit model of a hypersurface that is given only by a ﬁnite sampling. The methods work by mapping the sample points into a reproducing kernel Hilbert space and then determining regions in terms of hyperplanes. 1</p><p>6 0.9488371 <a title="203-lda-6" href="./nips-2004-Temporal-Difference_Networks.html">183 nips-2004-Temporal-Difference Networks</a></p>
<p>7 0.93895763 <a title="203-lda-7" href="./nips-2004-Two-Dimensional_Linear_Discriminant_Analysis.html">197 nips-2004-Two-Dimensional Linear Discriminant Analysis</a></p>
<p>8 0.88845909 <a title="203-lda-8" href="./nips-2004-A_Method_for_Inferring_Label_Sampling_Mechanisms_in_Semi-Supervised_Learning.html">9 nips-2004-A Method for Inferring Label Sampling Mechanisms in Semi-Supervised Learning</a></p>
<p>9 0.8207413 <a title="203-lda-9" href="./nips-2004-Using_the_Equivalent_Kernel_to_Understand_Gaussian_Process_Regression.html">201 nips-2004-Using the Equivalent Kernel to Understand Gaussian Process Regression</a></p>
<p>10 0.81628072 <a title="203-lda-10" href="./nips-2004-Probabilistic_Computation_in_Spiking_Populations.html">148 nips-2004-Probabilistic Computation in Spiking Populations</a></p>
<p>11 0.81094426 <a title="203-lda-11" href="./nips-2004-Semigroup_Kernels_on_Finite_Sets.html">168 nips-2004-Semigroup Kernels on Finite Sets</a></p>
<p>12 0.80775261 <a title="203-lda-12" href="./nips-2004-Hierarchical_Eigensolver_for_Transition_Matrices_in_Spectral_Methods.html">79 nips-2004-Hierarchical Eigensolver for Transition Matrices in Spectral Methods</a></p>
<p>13 0.80745536 <a title="203-lda-13" href="./nips-2004-The_Laplacian_PDF_Distance%3A_A_Cost_Function_for_Clustering_in_a_Kernel_Feature_Space.html">188 nips-2004-The Laplacian PDF Distance: A Cost Function for Clustering in a Kernel Feature Space</a></p>
<p>14 0.78635788 <a title="203-lda-14" href="./nips-2004-Learning_Gaussian_Process_Kernels_via_Hierarchical_Bayes.html">98 nips-2004-Learning Gaussian Process Kernels via Hierarchical Bayes</a></p>
<p>15 0.78271586 <a title="203-lda-15" href="./nips-2004-Support_Vector_Classification_with_Input_Data_Uncertainty.html">178 nips-2004-Support Vector Classification with Input Data Uncertainty</a></p>
<p>16 0.78074622 <a title="203-lda-16" href="./nips-2004-Matrix_Exponential_Gradient_Updates_for_On-line_Learning_and_Bregman_Projection.html">110 nips-2004-Matrix Exponential Gradient Updates for On-line Learning and Bregman Projection</a></p>
<p>17 0.77646995 <a title="203-lda-17" href="./nips-2004-Kernels_for_Multi--task_Learning.html">94 nips-2004-Kernels for Multi--task Learning</a></p>
<p>18 0.77448332 <a title="203-lda-18" href="./nips-2004-Distributed_Occlusion_Reasoning_for_Tracking_with_Nonparametric_Belief_Propagation.html">55 nips-2004-Distributed Occlusion Reasoning for Tracking with Nonparametric Belief Propagation</a></p>
<p>19 0.77110493 <a title="203-lda-19" href="./nips-2004-Binet-Cauchy_Kernels.html">30 nips-2004-Binet-Cauchy Kernels</a></p>
<p>20 0.77093112 <a title="203-lda-20" href="./nips-2004-Nonparametric_Transforms_of_Graph_Kernels_for_Semi-Supervised_Learning.html">133 nips-2004-Nonparametric Transforms of Graph Kernels for Semi-Supervised Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
