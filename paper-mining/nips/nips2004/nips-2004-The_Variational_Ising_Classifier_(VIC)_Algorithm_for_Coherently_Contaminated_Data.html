<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>191 nips-2004-The Variational Ising Classifier (VIC) Algorithm for Coherently Contaminated Data</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2004" href="../home/nips2004_home.html">nips2004</a> <a title="nips-2004-191" href="#">nips2004-191</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>191 nips-2004-The Variational Ising Classifier (VIC) Algorithm for Coherently Contaminated Data</h1>
<br/><p>Source: <a title="nips-2004-191-pdf" href="http://papers.nips.cc/paper/2616-the-variational-ising-classifier-vic-algorithm-for-coherently-contaminated-data.pdf">pdf</a></p><p>Author: Oliver Williams, Andrew Blake, Roberto Cipolla</p><p>Abstract: There has been substantial progress in the past decade in the development of object classiﬁers for images, for example of faces, humans and vehicles. Here we address the problem of contaminations (e.g. occlusion, shadows) in test images which have not explicitly been encountered in training data. The Variational Ising Classiﬁer (VIC) algorithm models contamination as a mask (a ﬁeld of binary variables) with a strong spatial coherence prior. Variational inference is used to marginalize over contamination and obtain robust classiﬁcation. In this way the VIC approach can turn a kernel classiﬁer for clean data into one that can tolerate contamination, without any speciﬁc training on contaminated positives. 1</p><p>Reference: <a title="nips-2004-191-reference" href="../nips2004_reference/nips-2004-The_Variational_Ising_Classifier_%28VIC%29_Algorithm_for_Coherently_Contaminated_Data_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The Variational Ising Classiﬁer (VIC) algorithm for coherently contaminated data  Oliver Williams Dept. [sent-1, score-0.235]
</p><p>2 uk  Abstract There has been substantial progress in the past decade in the development of object classiﬁers for images, for example of faces, humans and vehicles. [sent-6, score-0.073]
</p><p>3 occlusion, shadows) in test images which have not explicitly been encountered in training data. [sent-9, score-0.125]
</p><p>4 The Variational Ising Classiﬁer (VIC) algorithm models contamination as a mask (a ﬁeld of binary variables) with a strong spatial coherence prior. [sent-10, score-0.607]
</p><p>5 Variational inference is used to marginalize over contamination and obtain robust classiﬁcation. [sent-11, score-0.544]
</p><p>6 In this way the VIC approach can turn a kernel classiﬁer for clean data into one that can tolerate contamination, without any speciﬁc training on contaminated positives. [sent-12, score-0.293]
</p><p>7 1  Introduction  Recent progress in discriminative object detection, especially for faces, has yielded good performance and efﬁciency [1, 2, 3, 4]. [sent-13, score-0.073]
</p><p>8 Such systems are capable of classifying those positives that can be generalized from positive training data. [sent-14, score-0.122]
</p><p>9 This is restrictive in practice in that test data may contain distortions that take it outside the strict ambit of the training positives. [sent-15, score-0.08]
</p><p>10 One example would be lighting changes (to a face) but this can be addressed reasonably effectively by a normalizing transformation applied to training and test images; doing so is common practice in face classiﬁcation. [sent-16, score-0.193]
</p><p>11 Other sorts of disruption are not so easily factored out. [sent-17, score-0.034]
</p><p>12 The aim of this paper is to extend a classiﬁer trained on clean positives to accept also partially occluded positives, without further training. [sent-19, score-0.208]
</p><p>13 The approach is to capture some of the regularity inherent in a typical pattern of contamination, namely its spatial coherence. [sent-20, score-0.024]
</p><p>14 This can be thought of as extending the generalizing capability of a classiﬁer to tolerate the sorts of image distortion that occur as a result of contamination. [sent-21, score-0.116]
</p><p>15 As done previously in one-dimension, for image contours [5], the Variational Ising Classiﬁer (VIC) models contamination explicitly as switches with a strong coherence prior in the form of an Ising model, but here over the full two-dimensional image array. [sent-22, score-0.719]
</p><p>16 The aim is to incorporate these hidden contamination variables into a kernel classiﬁer such as [1, 3]. [sent-24, score-0.596]
</p><p>17 In fact the Relevance Vector Machine (RVM) is particularly suitable [6] as it is explicitly probabilistic, so that contamination variables can be incorporated as a hidden layer of random variables. [sent-25, score-0.614]
</p><p>18 edge i  neighbours of i  Figure 1: The 2D Ising model is applied over a graph with edges e ∈ Υ between neighbouring pixels (connected 4-wise). [sent-26, score-0.076]
</p><p>19 Classiﬁcation is done by marginalization over all possible conﬁgurations of the hidden variable array, and this is made tractable by variational (mean ﬁeld) inference. [sent-27, score-0.204]
</p><p>20 The inference scheme makes use of “hallucination” to ﬁll in parts of the object that are unobserved due to occlusion. [sent-28, score-0.051]
</p><p>21 First we show that the classiﬁer performance is not signiﬁcantly damaged by the inclusion of contamination variables. [sent-30, score-0.544]
</p><p>22 Then a contaminated test set is generated using real test images and computer generated contaminations. [sent-31, score-0.293]
</p><p>23 Over this test data the VIC algorithm does indeed perform signiﬁcantly better than a conventional classiﬁer (similar to [4]). [sent-32, score-0.026]
</p><p>24 The hidden variable layer is shown to operate effectively, successfully inferring areas of contamination. [sent-33, score-0.092]
</p><p>25 Finally, inference of contamination is shown working on real images with real contaminations. [sent-34, score-0.593]
</p><p>26 2  Bayesian modelling of contamination  Classiﬁcation requires P (F |I), the posterior for the proposition F that an object is present given the image data intensity array I. [sent-35, score-0.727]
</p><p>27 Suppose we are given a likelihood P (I|θ, F ) for the presence of a face given contamination θ, an array of binary “observation” variables corresponding to each pixel Ij of I, such that θj = 0 indicates contamination at that pixel, whereas θj = 1 indicates a successfully observed pixel. [sent-37, score-1.314]
</p><p>28 Then, in principle, P (I|F ) =  P (I|θ, F )P (θ),  (3)  θ  (making the reasonable assumption P (θ|F ) = P (θ), that the pattern of contamination is object independent) and similarly for log P (I | F ). [sent-38, score-0.671]
</p><p>29 The marginalization itself is intractable, requiring a summation over all 2N possible conﬁgurations of θ, for images with N pixels. [sent-39, score-0.124]
</p><p>30 Approximating that marginalization is dealt with in the next section. [sent-40, score-0.075]
</p><p>31 In the meantime, there are two other problems to deal with: specifying the prior P (θ); and specifying the likelihood under contamination P (I|θ, F ) given only training data for the unoccluded object. [sent-41, score-0.772]
</p><p>32 1  Prior over contaminations  The prior contains two terms: the ﬁrst expresses the belief that contamination will occur in coherent regions of a subimage. [sent-43, score-0.666]
</p><p>33 This takes the form of an Ising model [7] with energy  UI (θ) that penalizes adjacent pixels which differ in their labelling (see Figure 1); the second term UC biases generally against contamination a priori and its balance with the ﬁrst term is mediated by the constant λ. [sent-44, score-0.656]
</p><p>34 The total prior energy is then U (θ) = UI (θ) + λUC (θ) =  [1 − δ(θe1 − θe2 )] + λ  δ(θj ),  (4)  j  e∈Υ  where δ(x) = 1 if x = 0 and 0 otherwise, and e1 , e2 are the indices of the pixels at either end of edge e ∈ Υ (ﬁgure 1). [sent-45, score-0.114]
</p><p>35 The prior energy determines a probability via a temperature constant 1/T0 [7]: P (θ) ∝ e−U (θ)/T0 = e−UI (θ)/T0 e−λUC (θ)/T0 2. [sent-46, score-0.134]
</p><p>36 2  (5)  Relevance vector machine  An unoccluded classiﬁer P (F |I, θ = 0) can be learned from training data using a Relevance Vector Machine (RVM) [6], trained on a database of frontal face and non-face images [8] (see Section 4 for details). [sent-47, score-0.308]
</p><p>37 The probabilistic properties of the RVM make it a good choice when (later) it comes to marginalising over θ. [sent-48, score-0.038]
</p><p>38 For now we consider how to construct the likelihood itself. [sent-49, score-0.027]
</p><p>39 First the conventional, unoccluded case is considered for which the posterior P (F |I) is learned from positive and negative examples. [sent-50, score-0.132]
</p><p>40 Kernel functions [9] are computed between a candidate image I and a subset of relevance vectors {xk }, retained from the training set. [sent-51, score-0.147]
</p><p>41 Gaussian kernels are used here to compute y(I) =  (Ij − xkj )2 . [sent-52, score-0.056]
</p><p>42 wk exp −α k  (6)  j  where wk are learned weights, and xkj is the j th pixel of the k th relevance vector. [sent-53, score-0.406]
</p><p>43 Then the posterior is computed via the logistic sigmoid function as P (F |I, θ = 1) = σ(y(I)) =  1 . [sent-54, score-0.076]
</p><p>44 1 + e−y(I)  (7)  and ﬁnally the unoccluded data-likelihood would be P (I|F, θ = 1) ∝ σ(y(I))/P (F ). [sent-55, score-0.094]
</p><p>45 3  (8)  Hallucinating appearance  The aim now is to derive the occluded likelihood from the unoccluded case, where the contamination mask is known, without any further training. [sent-57, score-0.844]
</p><p>46 To do this, (8) must be extended to give P (I|F, θ) for arbitrary masks θ, despite the fact the pixels Ij from the object are not observed wherever θj = 0. [sent-58, score-0.119]
</p><p>47 In principle one should take into account all possible (or at least probable) values for the occluded pixels. [sent-59, score-0.08]
</p><p>48 Here, for simplicity, a single ﬁxed hallucination is substituted for occluded pixels, then we proceed as if those values had actually been observed. [sent-60, score-0.188]
</p><p>49 This gives P (I|F, θ) ∝ σ(˜(I, θ))/P (F ) y  (9)  where ˜ ˜ y (θ, I) = y(I(I, θ, F )) and I(I, θ, F ) ˜  j  =  Ij (E[I|F ])j  if θj = 1 otherwise  (10)  in which E[I|F ] is a ﬁxed hallucination, conditioned on the model F , and computed as a sample mean over training instances. [sent-61, score-0.056]
</p><p>50 3  Approximate marginalization of θ by mean ﬁeld  At this point we return to the task of marginalising over θ (3) to obtain P (I|F ) and P (I|F ) for use in classiﬁcation (2). [sent-62, score-0.142]
</p><p>51 Due to the connectedness of neighbouring pixels in the Ising prior (ﬁgure 1), P (I, θ|F ) is a Markov Random Field (MRF) [7]. [sent-63, score-0.116]
</p><p>52 The marginalized likelihood P (I|F ) could be estimated by Gibbs sampling [10] but that takes tens of minutes to converge in our experiments. [sent-64, score-0.068]
</p><p>53 The following section describes a mean ﬁeld approximation which converges in a few seconds. [sent-65, score-0.052]
</p><p>54 The mean ﬁeld algorithm is given here for P (I|F ) but must be repeated also for P (I|F ), simply substituting F for F throughout. [sent-66, score-0.029]
</p><p>55 P (θ|F, I)  The objective functional J(Q) is a lower bound on the log-marginal probability log P (I|F ) [11]; when it is maximized at Q∗ , it gives both the marginal likelihood J(Q∗ ) = log P (I|F ), and the posterior distribution Q∗ (θ) = P (θ|F, I) over hidden variables. [sent-69, score-0.195]
</p><p>56 Following [11], J(Q) is simpliﬁed using Bayes’ rule: J(Q) = H(Q) + EQ [log P (I, θ|F )] where H(·) is the entropy of a distribution [12] and EQ [g(θ)] = θ Q(θ)g(θ) denotes the expectation of a function g with respect to Q(θ). [sent-70, score-0.038]
</p><p>57 For mean-ﬁeld approximation, Q(θ) is modelled as a pixel-wise product of factors: Q(θ) = i Qi (θi ). [sent-72, score-0.035]
</p><p>58 Taking expectations over P (I, θ|F )  To perform the expectation required in (12), the log-joint distribution is written as: y log {P (I, θ|F )} = − log 1 + e−˜(θ,I) −  1 T0 UI (θ)  −  λ T0 UC (θ)  + const. [sent-75, score-0.206]
</p><p>59 The conditional expectation EQ|θi in (12) is found efﬁciently from the complete expectations by replacing only terms in θi . [sent-76, score-0.102]
</p><p>60 Likewise, when one factor of Q changes (12), the  complete expectations may be updated without recomputing them ab initio. [sent-77, score-0.064]
</p><p>61 For brevity, we give the expressions for the complete expectations only. [sent-78, score-0.064]
</p><p>62 For the prior this is simply: EQ [U (θ)] =  Qe (θe ) [1 − δ(θe1 − θe2 )] + λ  Qj (θj = 0). [sent-79, score-0.04]
</p><p>63 (13)  j  e∈Υ θe  For the likelihood it is more difﬁcult. [sent-80, score-0.027]
</p><p>64 [13] show how to approximate the expectation over the sigmoid function by introducing a dummy variable ξ: y ˜ y EQ log(1 + e−˜(θ,I) ) ≤ −ξEQ [˜(θ, I)] + log EQ eξy(θ,I) + EQ e(ξ−1)˜(θ,I) y  . [sent-82, score-0.128]
</p><p>65 The Gaussian RBF in (6) means that it is not feasible to compute the expectation1 ˜ EQ eξy(θ,I) , so a simpler approximation is used: EQ [log σ(˜(θ, I)] ≈ log σ (EQ [˜(θ, I)]) , y y where EQ [˜(θ, I)] = y k  4  ˜ Qj (θj ) exp −α I(I, θ, F )j − xkj  wk j  2  . [sent-83, score-0.231]
</p><p>66 (14)  θj  Results and discussion  The mean ﬁeld algorithm described above is capable only of local optimization of J(Q). [sent-84, score-0.053]
</p><p>67 A symptom of this is that it exhibits spontaneous symmetry breaking [11], setting the contamination ﬁeld to either all contaminated or all uncontaminated. [sent-85, score-0.736]
</p><p>68 By performing iterations initially at a high temperature, Th , the prior is weakened. [sent-87, score-0.04]
</p><p>69 The temperature is then progressively decreased, on a linear annealing schedule [10], until the modelled prior temperature T0 is reached. [sent-88, score-0.213]
</p><p>70 Note also that an advantage of hallucinating appearance from the mean face is that the hallucination process requires no computation within the optimization loop. [sent-90, score-0.361]
</p><p>71 However this is an unoptimized Matlab implementation; and in C++ it is anticipated to be at least 10 times faster. [sent-92, score-0.019]
</p><p>72 The training set used for the RVM [8] contains subimages of registered faces and non-faces which were histogram equalized [14] to reduce the effect of different lighting with their pixel values scaled to the range [0, 1]. [sent-93, score-0.189]
</p><p>73 The RVM was trained using 1500 face examples and 1500 non-face examples 2 . [sent-95, score-0.115]
</p><p>74 As a by-product of the VIC algorithm, the posterior pattern P (θ|F, I) of contamination is approximately inferred as the value of Q which maximizes J. [sent-102, score-0.606]
</p><p>75 As might be expected, for a non-face, the algorithm hallucinates an intact face with total contamination (For example, row 4 of the ﬁgure); but of course the marginalized posterior probability P (F |I) is very small in such a case. [sent-104, score-0.738]
</p><p>76 1  Classiﬁer  To assess the classiﬁcation performance of the VIC, contaminated positives were automatically generated (ﬁgure 4). [sent-106, score-0.263]
</p><p>77 1  Figure 3: Partially occluded mages with inferred areas of probable contamination (dark). [sent-124, score-0.668]
</p><p>78 contaminated set and for the new contamination-tolerant VIC outlined in this paper. [sent-125, score-0.192]
</p><p>79 For comparison, points are shown for a boosted cascade of classiﬁers [15] which is a publicly available detector based on the system of Viola and Jones [4]. [sent-126, score-0.233]
</p><p>80 The curve shown for the RVM against an uncontaminated test set conﬁrms that contamination does make the classiﬁcation task considerably harder. [sent-127, score-0.57]
</p><p>81 Figure 5 shows some natural face images that the boosted cascade [15] fails to detect, either because of occlusion or due to a degree of deviation from  1  True positive rate  0. [sent-128, score-0.399]
</p><p>82 Also shown are some of the contaminated positives used to generate the curves. [sent-143, score-0.263]
</p><p>83 These were made by sampling contamination patterns from the prior and using them to mix a face and a non-face artiﬁcially. [sent-144, score-0.699]
</p><p>84 Input I  Hallucinated image  Contamination ﬁeld Q(θ = 1) 0. [sent-145, score-0.039]
</p><p>85 2  Figure 5: Images that the boosted cascade [15] failed to detect as faces: the VIC algorithm produces higher posterior face probability by labelling certain regions with unusual appearance (eg due to 3D rotation) as contaminated. [sent-157, score-0.432]
</p><p>86 2  Discussion  Figure 4 shows that by modelling the contamination ﬁeld explicitly, the VIC detector improves on the performance, over a contaminated test set, both of a plain RVM and of a boosted cascade detector. [sent-161, score-1.016]
</p><p>87 However, this could be mitigated by cascading [4], in which a simple and efﬁcient classiﬁer, tuned to return a high rate of false positives for all objects, contaminated and non-contaminated, would make a preliminary sweep of a test image. [sent-163, score-0.289]
</p><p>88 The contamination-tolerant VIC algorithm would then be applied to the candidate subimages that remain, thereby concentrating computational power on just a few locations. [sent-164, score-0.079]
</p><p>89 Figure 5 illustrates the operation of the contamination mechanism on real images, all of  which are detected as faces by the VIC algorithm but missed by the boosted cascade. [sent-165, score-0.69]
</p><p>90 There is no occlusion in these examples but rotations have distorted the appearance of certain features. [sent-166, score-0.082]
</p><p>91 The VIC algorithm has deals with this by labelling the distortions as contaminated areas, and hallucinating face-like texture in their place. [sent-167, score-0.322]
</p><p>92 In conclusion, we have developed the VNC algorithm for object detection in the presence of coherently contaminated data. [sent-168, score-0.306]
</p><p>93 Contamination is modelled as coherent via an Ising prior, and is marginalized out by variational inference. [sent-169, score-0.198]
</p><p>94 Experiments show that VIC classiﬁes contaminated images more robustly than classiﬁers designed for clean data. [sent-170, score-0.272]
</p><p>95 Any probabilistic detector for which it is possible to estimate the expectation (14) could be modiﬁed in a similar way to deal with spatially coherent contamination. [sent-172, score-0.113]
</p><p>96 Future work will address: improved efﬁciency by incorporating the VIC into a cascade of simple classiﬁers; alternatives to data hallucination using marginalization over missing data, if a tractable means of doing this can be found. [sent-173, score-0.308]
</p><p>97 Training support vector machines: An application to face detection. [sent-178, score-0.115]
</p><p>98 Rapid object detection using a boosted cascade of simple features. [sent-202, score-0.268]
</p><p>99 An extended set of Haar-like features for rapid object detection. [sent-265, score-0.071]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('contamination', 0.544), ('vic', 0.475), ('eq', 0.37), ('contaminated', 0.192), ('rvm', 0.188), ('ising', 0.154), ('face', 0.115), ('hallucination', 0.108), ('cascade', 0.105), ('unoccluded', 0.094), ('boosted', 0.092), ('eld', 0.088), ('variational', 0.083), ('occluded', 0.08), ('marginalization', 0.075), ('positives', 0.071), ('temperature', 0.069), ('wk', 0.069), ('hallucinating', 0.065), ('expectations', 0.064), ('classi', 0.063), ('relevance', 0.058), ('subimages', 0.056), ('xkj', 0.056), ('er', 0.055), ('faces', 0.054), ('log', 0.052), ('object', 0.051), ('images', 0.049), ('pixels', 0.049), ('th', 0.048), ('uc', 0.047), ('qi', 0.046), ('appearance', 0.044), ('coherently', 0.043), ('contaminations', 0.043), ('hallucinated', 0.043), ('tolerate', 0.043), ('marginalized', 0.041), ('qj', 0.041), ('prior', 0.04), ('coherent', 0.039), ('image', 0.039), ('expectation', 0.038), ('labelling', 0.038), ('occlusion', 0.038), ('sigmoid', 0.038), ('marginalising', 0.038), ('posterior', 0.038), ('detector', 0.036), ('ui', 0.036), ('modelled', 0.035), ('sorts', 0.034), ('coherence', 0.034), ('zi', 0.034), ('array', 0.034), ('clean', 0.031), ('exp', 0.031), ('kl', 0.03), ('mean', 0.029), ('mask', 0.029), ('neighbouring', 0.027), ('distortions', 0.027), ('training', 0.027), ('likelihood', 0.027), ('pixel', 0.027), ('test', 0.026), ('aim', 0.026), ('hidden', 0.026), ('ij', 0.025), ('energy', 0.025), ('field', 0.025), ('lighting', 0.025), ('capable', 0.024), ('pattern', 0.024), ('candidate', 0.023), ('successfully', 0.023), ('frontal', 0.023), ('viola', 0.023), ('explicitly', 0.023), ('approximation', 0.023), ('probable', 0.022), ('pure', 0.022), ('areas', 0.022), ('gure', 0.022), ('progress', 0.022), ('rbf', 0.021), ('ers', 0.021), ('modelling', 0.021), ('roc', 0.021), ('layer', 0.021), ('vision', 0.02), ('gibbs', 0.02), ('specifying', 0.02), ('gurations', 0.02), ('rapid', 0.02), ('tractable', 0.02), ('detection', 0.02), ('wherever', 0.019), ('unoptimized', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000006 <a title="191-tfidf-1" href="./nips-2004-The_Variational_Ising_Classifier_%28VIC%29_Algorithm_for_Coherently_Contaminated_Data.html">191 nips-2004-The Variational Ising Classifier (VIC) Algorithm for Coherently Contaminated Data</a></p>
<p>Author: Oliver Williams, Andrew Blake, Roberto Cipolla</p><p>Abstract: There has been substantial progress in the past decade in the development of object classiﬁers for images, for example of faces, humans and vehicles. Here we address the problem of contaminations (e.g. occlusion, shadows) in test images which have not explicitly been encountered in training data. The Variational Ising Classiﬁer (VIC) algorithm models contamination as a mask (a ﬁeld of binary variables) with a strong spatial coherence prior. Variational inference is used to marginalize over contamination and obtain robust classiﬁcation. In this way the VIC approach can turn a kernel classiﬁer for clean data into one that can tolerate contamination, without any speciﬁc training on contaminated positives. 1</p><p>2 0.11661987 <a title="191-tfidf-2" href="./nips-2004-Machine_Learning_Applied_to_Perception%3A_Decision_Images_for_Gender_Classification.html">106 nips-2004-Machine Learning Applied to Perception: Decision Images for Gender Classification</a></p>
<p>Author: Felix A. Wichmann, Arnulf B. Graf, Heinrich H. Bülthoff, Eero P. Simoncelli, Bernhard Schölkopf</p><p>Abstract: We study gender discrimination of human faces using a combination of psychophysical classiﬁcation and discrimination experiments together with methods from machine learning. We reduce the dimensionality of a set of face images using principal component analysis, and then train a set of linear classiﬁers on this reduced representation (linear support vector machines (SVMs), relevance vector machines (RVMs), Fisher linear discriminant (FLD), and prototype (prot) classiﬁers) using human classiﬁcation data. Because we combine a linear preprocessor with linear classiﬁers, the entire system acts as a linear classiﬁer, allowing us to visualise the decision-image corresponding to the normal vector of the separating hyperplanes (SH) of each classiﬁer. We predict that the female-tomaleness transition along the normal vector for classiﬁers closely mimicking human classiﬁcation (SVM and RVM [1]) should be faster than the transition along any other direction. A psychophysical discrimination experiment using the decision images as stimuli is consistent with this prediction. 1</p><p>3 0.087818295 <a title="191-tfidf-3" href="./nips-2004-The_power_of_feature_clustering%3A_An_application_to_object_detection.html">192 nips-2004-The power of feature clustering: An application to object detection</a></p>
<p>Author: Shai Avidan, Moshe Butman</p><p>Abstract: We give a fast rejection scheme that is based on image segments and demonstrate it on the canonical example of face detection. However, instead of focusing on the detection step we focus on the rejection step and show that our method is simple and fast to be learned, thus making it an excellent pre-processing step to accelerate standard machine learning classiﬁers, such as neural-networks, Bayes classiﬁers or SVM. We decompose a collection of face images into regions of pixels with similar behavior over the image set. The relationships between the mean and variance of image segments are used to form a cascade of rejectors that can reject over 99.8% of image patches, thus only a small fraction of the image patches must be passed to a full-scale classiﬁer. Moreover, the training time for our method is much less than an hour, on a standard PC. The shape of the features (i.e. image segments) we use is data-driven, they are very cheap to compute and they form a very low dimensional feature space in which exhaustive search for the best features is tractable. 1</p><p>4 0.083639659 <a title="191-tfidf-4" href="./nips-2004-Synergistic_Face_Detection_and_Pose_Estimation_with_Energy-Based_Models.html">182 nips-2004-Synergistic Face Detection and Pose Estimation with Energy-Based Models</a></p>
<p>Author: Margarita Osadchy, Matthew L. Miller, Yann L. Cun</p><p>Abstract: We describe a novel method for real-time, simultaneous multi-view face detection and facial pose estimation. The method employs a convolutional network to map face images to points on a manifold, parametrized by pose, and non-face images to points far from that manifold. This network is trained by optimizing a loss function of three variables: image, pose, and face/non-face label. We test the resulting system, in a single conﬁguration, on three standard data sets – one for frontal pose, one for rotated faces, and one for proﬁles – and ﬁnd that its performance on each set is comparable to previous multi-view face detectors that can only handle one form of pose variation. We also show experimentally that the system’s accuracy on both face detection and pose estimation is improved by training for the two tasks together.</p><p>5 0.078900404 <a title="191-tfidf-5" href="./nips-2004-Parallel_Support_Vector_Machines%3A_The_Cascade_SVM.html">144 nips-2004-Parallel Support Vector Machines: The Cascade SVM</a></p>
<p>Author: Hans P. Graf, Eric Cosatto, Léon Bottou, Igor Dourdanovic, Vladimir Vapnik</p><p>Abstract: We describe an algorithm for support vector machines (SVM) that can be parallelized efficiently and scales to very large problems with hundreds of thousands of training vectors. Instead of analyzing the whole training set in one optimization step, the data are split into subsets and optimized separately with multiple SVMs. The partial results are combined and filtered again in a ‘Cascade’ of SVMs, until the global optimum is reached. The Cascade SVM can be spread over multiple processors with minimal communication overhead and requires far less memory, since the kernel matrices are much smaller than for a regular SVM. Convergence to the global optimum is guaranteed with multiple passes through the Cascade, but already a single pass provides good generalization. A single pass is 5x – 10x faster than a regular SVM for problems of 100,000 vectors when implemented on a single processor. Parallel implementations on a cluster of 16 processors were tested with over 1 million vectors (2-class problems), converging in a day or two, while a regular SVM never converged in over a week. 1</p><p>6 0.078530185 <a title="191-tfidf-6" href="./nips-2004-Generative_Affine_Localisation_and_Tracking.html">73 nips-2004-Generative Affine Localisation and Tracking</a></p>
<p>7 0.076893084 <a title="191-tfidf-7" href="./nips-2004-Face_Detection_---_Efficient_and_Rank_Deficient.html">68 nips-2004-Face Detection --- Efficient and Rank Deficient</a></p>
<p>8 0.065903567 <a title="191-tfidf-8" href="./nips-2004-Joint_MRI_Bias_Removal_Using_Entropy_Minimization_Across_Images.html">89 nips-2004-Joint MRI Bias Removal Using Entropy Minimization Across Images</a></p>
<p>9 0.064493299 <a title="191-tfidf-9" href="./nips-2004-Bayesian_Regularization_and_Nonnegative_Deconvolution_for_Time_Delay_Estimation.html">27 nips-2004-Bayesian Regularization and Nonnegative Deconvolution for Time Delay Estimation</a></p>
<p>10 0.063840263 <a title="191-tfidf-10" href="./nips-2004-Object_Classification_from_a_Single_Example_Utilizing_Class_Relevance_Metrics.html">134 nips-2004-Object Classification from a Single Example Utilizing Class Relevance Metrics</a></p>
<p>11 0.059890579 <a title="191-tfidf-11" href="./nips-2004-Conditional_Random_Fields_for_Object_Recognition.html">44 nips-2004-Conditional Random Fields for Object Recognition</a></p>
<p>12 0.056685641 <a title="191-tfidf-12" href="./nips-2004-Distributed_Occlusion_Reasoning_for_Tracking_with_Nonparametric_Belief_Propagation.html">55 nips-2004-Distributed Occlusion Reasoning for Tracking with Nonparametric Belief Propagation</a></p>
<p>13 0.056463074 <a title="191-tfidf-13" href="./nips-2004-Common-Frame_Model_for_Object_Recognition.html">40 nips-2004-Common-Frame Model for Object Recognition</a></p>
<p>14 0.054999866 <a title="191-tfidf-14" href="./nips-2004-Instance-Based_Relevance_Feedback_for_Image_Retrieval.html">85 nips-2004-Instance-Based Relevance Feedback for Image Retrieval</a></p>
<p>15 0.054490618 <a title="191-tfidf-15" href="./nips-2004-Distributed_Information_Regularization_on_Graphs.html">54 nips-2004-Distributed Information Regularization on Graphs</a></p>
<p>16 0.054029386 <a title="191-tfidf-16" href="./nips-2004-Incremental_Learning_for_Visual_Tracking.html">83 nips-2004-Incremental Learning for Visual Tracking</a></p>
<p>17 0.051941738 <a title="191-tfidf-17" href="./nips-2004-Expectation_Consistent_Free_Energies_for_Approximate_Inference.html">63 nips-2004-Expectation Consistent Free Energies for Approximate Inference</a></p>
<p>18 0.049897868 <a title="191-tfidf-18" href="./nips-2004-Who%27s_In_the_Picture.html">205 nips-2004-Who's In the Picture</a></p>
<p>19 0.048632752 <a title="191-tfidf-19" href="./nips-2004-Contextual_Models_for_Object_Detection_Using_Boosted_Random_Fields.html">47 nips-2004-Contextual Models for Object Detection Using Boosted Random Fields</a></p>
<p>20 0.04810302 <a title="191-tfidf-20" href="./nips-2004-On_Semi-Supervised_Classification.html">136 nips-2004-On Semi-Supervised Classification</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2004_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.15), (1, 0.03), (2, -0.045), (3, -0.081), (4, 0.103), (5, 0.053), (6, 0.089), (7, -0.072), (8, -0.003), (9, -0.006), (10, 0.008), (11, 0.025), (12, 0.043), (13, 0.032), (14, 0.01), (15, -0.08), (16, -0.051), (17, 0.055), (18, 0.092), (19, -0.003), (20, 0.047), (21, -0.053), (22, -0.048), (23, -0.079), (24, 0.075), (25, 0.047), (26, 0.019), (27, 0.021), (28, -0.073), (29, -0.042), (30, 0.15), (31, 0.02), (32, -0.026), (33, 0.073), (34, -0.08), (35, -0.155), (36, 0.083), (37, 0.108), (38, 0.123), (39, -0.046), (40, 0.072), (41, 0.033), (42, 0.009), (43, 0.17), (44, 0.052), (45, 0.131), (46, -0.117), (47, 0.022), (48, 0.125), (49, 0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92222619 <a title="191-lsi-1" href="./nips-2004-The_Variational_Ising_Classifier_%28VIC%29_Algorithm_for_Coherently_Contaminated_Data.html">191 nips-2004-The Variational Ising Classifier (VIC) Algorithm for Coherently Contaminated Data</a></p>
<p>Author: Oliver Williams, Andrew Blake, Roberto Cipolla</p><p>Abstract: There has been substantial progress in the past decade in the development of object classiﬁers for images, for example of faces, humans and vehicles. Here we address the problem of contaminations (e.g. occlusion, shadows) in test images which have not explicitly been encountered in training data. The Variational Ising Classiﬁer (VIC) algorithm models contamination as a mask (a ﬁeld of binary variables) with a strong spatial coherence prior. Variational inference is used to marginalize over contamination and obtain robust classiﬁcation. In this way the VIC approach can turn a kernel classiﬁer for clean data into one that can tolerate contamination, without any speciﬁc training on contaminated positives. 1</p><p>2 0.59105194 <a title="191-lsi-2" href="./nips-2004-Synergistic_Face_Detection_and_Pose_Estimation_with_Energy-Based_Models.html">182 nips-2004-Synergistic Face Detection and Pose Estimation with Energy-Based Models</a></p>
<p>Author: Margarita Osadchy, Matthew L. Miller, Yann L. Cun</p><p>Abstract: We describe a novel method for real-time, simultaneous multi-view face detection and facial pose estimation. The method employs a convolutional network to map face images to points on a manifold, parametrized by pose, and non-face images to points far from that manifold. This network is trained by optimizing a loss function of three variables: image, pose, and face/non-face label. We test the resulting system, in a single conﬁguration, on three standard data sets – one for frontal pose, one for rotated faces, and one for proﬁles – and ﬁnd that its performance on each set is comparable to previous multi-view face detectors that can only handle one form of pose variation. We also show experimentally that the system’s accuracy on both face detection and pose estimation is improved by training for the two tasks together.</p><p>3 0.58683777 <a title="191-lsi-3" href="./nips-2004-Machine_Learning_Applied_to_Perception%3A_Decision_Images_for_Gender_Classification.html">106 nips-2004-Machine Learning Applied to Perception: Decision Images for Gender Classification</a></p>
<p>Author: Felix A. Wichmann, Arnulf B. Graf, Heinrich H. Bülthoff, Eero P. Simoncelli, Bernhard Schölkopf</p><p>Abstract: We study gender discrimination of human faces using a combination of psychophysical classiﬁcation and discrimination experiments together with methods from machine learning. We reduce the dimensionality of a set of face images using principal component analysis, and then train a set of linear classiﬁers on this reduced representation (linear support vector machines (SVMs), relevance vector machines (RVMs), Fisher linear discriminant (FLD), and prototype (prot) classiﬁers) using human classiﬁcation data. Because we combine a linear preprocessor with linear classiﬁers, the entire system acts as a linear classiﬁer, allowing us to visualise the decision-image corresponding to the normal vector of the separating hyperplanes (SH) of each classiﬁer. We predict that the female-tomaleness transition along the normal vector for classiﬁers closely mimicking human classiﬁcation (SVM and RVM [1]) should be faster than the transition along any other direction. A psychophysical discrimination experiment using the decision images as stimuli is consistent with this prediction. 1</p><p>4 0.58367938 <a title="191-lsi-4" href="./nips-2004-The_power_of_feature_clustering%3A_An_application_to_object_detection.html">192 nips-2004-The power of feature clustering: An application to object detection</a></p>
<p>Author: Shai Avidan, Moshe Butman</p><p>Abstract: We give a fast rejection scheme that is based on image segments and demonstrate it on the canonical example of face detection. However, instead of focusing on the detection step we focus on the rejection step and show that our method is simple and fast to be learned, thus making it an excellent pre-processing step to accelerate standard machine learning classiﬁers, such as neural-networks, Bayes classiﬁers or SVM. We decompose a collection of face images into regions of pixels with similar behavior over the image set. The relationships between the mean and variance of image segments are used to form a cascade of rejectors that can reject over 99.8% of image patches, thus only a small fraction of the image patches must be passed to a full-scale classiﬁer. Moreover, the training time for our method is much less than an hour, on a standard PC. The shape of the features (i.e. image segments) we use is data-driven, they are very cheap to compute and they form a very low dimensional feature space in which exhaustive search for the best features is tractable. 1</p><p>5 0.49782836 <a title="191-lsi-5" href="./nips-2004-Joint_MRI_Bias_Removal_Using_Entropy_Minimization_Across_Images.html">89 nips-2004-Joint MRI Bias Removal Using Entropy Minimization Across Images</a></p>
<p>Author: Erik G. Learned-miller, Parvez Ahammad</p><p>Abstract: The correction of bias in magnetic resonance images is an important problem in medical image processing. Most previous approaches have used a maximum likelihood method to increase the likelihood of the pixels in a single image by adaptively estimating a correction to the unknown image bias ﬁeld. The pixel likelihoods are deﬁned either in terms of a pre-existing tissue model, or non-parametrically in terms of the image’s own pixel values. In both cases, the speciﬁc location of a pixel in the image is not used to calculate the likelihoods. We suggest a new approach in which we simultaneously eliminate the bias from a set of images of the same anatomy, but from different patients. We use the statistics from the same location across different images, rather than within an image, to eliminate bias ﬁelds from all of the images simultaneously. The method builds a “multi-resolution” non-parametric tissue model conditioned on image location while eliminating the bias ﬁelds associated with the original image set. We present experiments on both synthetic and real MR data sets, and present comparisons with other methods. 1</p><p>6 0.44862315 <a title="191-lsi-6" href="./nips-2004-Face_Detection_---_Efficient_and_Rank_Deficient.html">68 nips-2004-Face Detection --- Efficient and Rank Deficient</a></p>
<p>7 0.43745229 <a title="191-lsi-7" href="./nips-2004-Generative_Affine_Localisation_and_Tracking.html">73 nips-2004-Generative Affine Localisation and Tracking</a></p>
<p>8 0.42665297 <a title="191-lsi-8" href="./nips-2004-Class-size_Independent_Generalization_Analsysis_of_Some_Discriminative_Multi-Category_Classification.html">36 nips-2004-Class-size Independent Generalization Analsysis of Some Discriminative Multi-Category Classification</a></p>
<p>9 0.40225577 <a title="191-lsi-9" href="./nips-2004-Who%27s_In_the_Picture.html">205 nips-2004-Who's In the Picture</a></p>
<p>10 0.39617395 <a title="191-lsi-10" href="./nips-2004-Using_Machine_Learning_to_Break_Visual_Human_Interaction_Proofs_%28HIPs%29.html">199 nips-2004-Using Machine Learning to Break Visual Human Interaction Proofs (HIPs)</a></p>
<p>11 0.38869968 <a title="191-lsi-11" href="./nips-2004-Constraining_a_Bayesian_Model_of_Human_Visual_Speed_Perception.html">46 nips-2004-Constraining a Bayesian Model of Human Visual Speed Perception</a></p>
<p>12 0.37409437 <a title="191-lsi-12" href="./nips-2004-A_Topographic_Support_Vector_Machine%3A_Classification_Using_Local_Label_Configurations.html">14 nips-2004-A Topographic Support Vector Machine: Classification Using Local Label Configurations</a></p>
<p>13 0.35993496 <a title="191-lsi-13" href="./nips-2004-Efficient_Out-of-Sample_Extension_of_Dominant-Set_Clusters.html">61 nips-2004-Efficient Out-of-Sample Extension of Dominant-Set Clusters</a></p>
<p>14 0.35491887 <a title="191-lsi-14" href="./nips-2004-Common-Frame_Model_for_Object_Recognition.html">40 nips-2004-Common-Frame Model for Object Recognition</a></p>
<p>15 0.32647115 <a title="191-lsi-15" href="./nips-2004-Instance-Based_Relevance_Feedback_for_Image_Retrieval.html">85 nips-2004-Instance-Based Relevance Feedback for Image Retrieval</a></p>
<p>16 0.31148246 <a title="191-lsi-16" href="./nips-2004-Expectation_Consistent_Free_Energies_for_Approximate_Inference.html">63 nips-2004-Expectation Consistent Free Energies for Approximate Inference</a></p>
<p>17 0.30777717 <a title="191-lsi-17" href="./nips-2004-Contextual_Models_for_Object_Detection_Using_Boosted_Random_Fields.html">47 nips-2004-Contextual Models for Object Detection Using Boosted Random Fields</a></p>
<p>18 0.30405661 <a title="191-lsi-18" href="./nips-2004-Parallel_Support_Vector_Machines%3A_The_Cascade_SVM.html">144 nips-2004-Parallel Support Vector Machines: The Cascade SVM</a></p>
<p>19 0.30190906 <a title="191-lsi-19" href="./nips-2004-Bayesian_Regularization_and_Nonnegative_Deconvolution_for_Time_Delay_Estimation.html">27 nips-2004-Bayesian Regularization and Nonnegative Deconvolution for Time Delay Estimation</a></p>
<p>20 0.29456645 <a title="191-lsi-20" href="./nips-2004-Responding_to_Modalities_with_Different_Latencies.html">155 nips-2004-Responding to Modalities with Different Latencies</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2004_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.099), (15, 0.107), (17, 0.373), (26, 0.036), (31, 0.024), (33, 0.173), (35, 0.012), (39, 0.019), (50, 0.032), (56, 0.012), (71, 0.011), (87, 0.013)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.80673075 <a title="191-lda-1" href="./nips-2004-Conditional_Models_of_Identity_Uncertainty_with_Application_to_Noun_Coreference.html">43 nips-2004-Conditional Models of Identity Uncertainty with Application to Noun Coreference</a></p>
<p>Author: Andrew McCallum, Ben Wellner</p><p>Abstract: Coreference analysis, also known as record linkage or identity uncertainty, is a difﬁcult and important problem in natural language processing, databases, citation matching and many other tasks. This paper introduces several discriminative, conditional-probability models for coreference analysis, all examples of undirected graphical models. Unlike many historical approaches to coreference, the models presented here are relational—they do not assume that pairwise coreference decisions should be made independently from each other. Unlike other relational models of coreference that are generative, the conditional model here can incorporate a great variety of features of the input without having to be concerned about their dependencies—paralleling the advantages of conditional random ﬁelds over hidden Markov models. We present positive results on noun phrase coreference in two standard text data sets. 1</p><p>same-paper 2 0.79525131 <a title="191-lda-2" href="./nips-2004-The_Variational_Ising_Classifier_%28VIC%29_Algorithm_for_Coherently_Contaminated_Data.html">191 nips-2004-The Variational Ising Classifier (VIC) Algorithm for Coherently Contaminated Data</a></p>
<p>Author: Oliver Williams, Andrew Blake, Roberto Cipolla</p><p>Abstract: There has been substantial progress in the past decade in the development of object classiﬁers for images, for example of faces, humans and vehicles. Here we address the problem of contaminations (e.g. occlusion, shadows) in test images which have not explicitly been encountered in training data. The Variational Ising Classiﬁer (VIC) algorithm models contamination as a mask (a ﬁeld of binary variables) with a strong spatial coherence prior. Variational inference is used to marginalize over contamination and obtain robust classiﬁcation. In this way the VIC approach can turn a kernel classiﬁer for clean data into one that can tolerate contamination, without any speciﬁc training on contaminated positives. 1</p><p>3 0.73550868 <a title="191-lda-3" href="./nips-2004-Newscast_EM.html">130 nips-2004-Newscast EM</a></p>
<p>Author: Wojtek Kowalczyk, Nikos A. Vlassis</p><p>Abstract: We propose a gossip-based distributed algorithm for Gaussian mixture learning, Newscast EM. The algorithm operates on network topologies where each node observes a local quantity and can communicate with other nodes in an arbitrary point-to-point fashion. The main difference between Newscast EM and the standard EM algorithm is that the M-step in our case is implemented in a decentralized manner: (random) pairs of nodes repeatedly exchange their local parameter estimates and combine them by (weighted) averaging. We provide theoretical evidence and demonstrate experimentally that, under this protocol, nodes converge exponentially fast to the correct estimates in each M-step of the EM algorithm. 1</p><p>4 0.64050549 <a title="191-lda-4" href="./nips-2004-Face_Detection_---_Efficient_and_Rank_Deficient.html">68 nips-2004-Face Detection --- Efficient and Rank Deficient</a></p>
<p>Author: Wolf Kienzle, Matthias O. Franz, Bernhard Schölkopf, Gökhan H. Bakir</p><p>Abstract: This paper proposes a method for computing fast approximations to support vector decision functions in the ﬁeld of object detection. In the present approach we are building on an existing algorithm where the set of support vectors is replaced by a smaller, so-called reduced set of synthesized input space points. In contrast to the existing method that ﬁnds the reduced set via unconstrained optimization, we impose a structural constraint on the synthetic points such that the resulting approximations can be evaluated via separable ﬁlters. For applications that require scanning large images, this decreases the computational complexity by a signiﬁcant amount. Experimental results show that in face detection, rank deﬁcient approximations are 4 to 6 times faster than unconstrained reduced set systems. 1</p><p>5 0.5432024 <a title="191-lda-5" href="./nips-2004-Synergistic_Face_Detection_and_Pose_Estimation_with_Energy-Based_Models.html">182 nips-2004-Synergistic Face Detection and Pose Estimation with Energy-Based Models</a></p>
<p>Author: Margarita Osadchy, Matthew L. Miller, Yann L. Cun</p><p>Abstract: We describe a novel method for real-time, simultaneous multi-view face detection and facial pose estimation. The method employs a convolutional network to map face images to points on a manifold, parametrized by pose, and non-face images to points far from that manifold. This network is trained by optimizing a loss function of three variables: image, pose, and face/non-face label. We test the resulting system, in a single conﬁguration, on three standard data sets – one for frontal pose, one for rotated faces, and one for proﬁles – and ﬁnd that its performance on each set is comparable to previous multi-view face detectors that can only handle one form of pose variation. We also show experimentally that the system’s accuracy on both face detection and pose estimation is improved by training for the two tasks together.</p><p>6 0.54001027 <a title="191-lda-6" href="./nips-2004-Contextual_Models_for_Object_Detection_Using_Boosted_Random_Fields.html">47 nips-2004-Contextual Models for Object Detection Using Boosted Random Fields</a></p>
<p>7 0.53428108 <a title="191-lda-7" href="./nips-2004-Hierarchical_Distributed_Representations_for_Statistical_Language_Modeling.html">78 nips-2004-Hierarchical Distributed Representations for Statistical Language Modeling</a></p>
<p>8 0.53051263 <a title="191-lda-8" href="./nips-2004-The_power_of_feature_clustering%3A_An_application_to_object_detection.html">192 nips-2004-The power of feature clustering: An application to object detection</a></p>
<p>9 0.52973968 <a title="191-lda-9" href="./nips-2004-Markov_Networks_for_Detecting_Overalpping_Elements_in_Sequence_Data.html">108 nips-2004-Markov Networks for Detecting Overalpping Elements in Sequence Data</a></p>
<p>10 0.52933878 <a title="191-lda-10" href="./nips-2004-A_Topographic_Support_Vector_Machine%3A_Classification_Using_Local_Label_Configurations.html">14 nips-2004-A Topographic Support Vector Machine: Classification Using Local Label Configurations</a></p>
<p>11 0.52723491 <a title="191-lda-11" href="./nips-2004-Resolving_Perceptual_Aliasing_In_The_Presence_Of_Noisy_Sensors.html">154 nips-2004-Resolving Perceptual Aliasing In The Presence Of Noisy Sensors</a></p>
<p>12 0.52538437 <a title="191-lda-12" href="./nips-2004-Learning_first-order_Markov_models_for_control.html">102 nips-2004-Learning first-order Markov models for control</a></p>
<p>13 0.52526486 <a title="191-lda-13" href="./nips-2004-Distributed_Occlusion_Reasoning_for_Tracking_with_Nonparametric_Belief_Propagation.html">55 nips-2004-Distributed Occlusion Reasoning for Tracking with Nonparametric Belief Propagation</a></p>
<p>14 0.52448142 <a title="191-lda-14" href="./nips-2004-Semi-Markov_Conditional_Random_Fields_for_Information_Extraction.html">162 nips-2004-Semi-Markov Conditional Random Fields for Information Extraction</a></p>
<p>15 0.52266568 <a title="191-lda-15" href="./nips-2004-Non-Local_Manifold_Tangent_Learning.html">131 nips-2004-Non-Local Manifold Tangent Learning</a></p>
<p>16 0.52231199 <a title="191-lda-16" href="./nips-2004-The_Power_of_Selective_Memory%3A_Self-Bounded_Learning_of_Prediction_Suffix_Trees.html">189 nips-2004-The Power of Selective Memory: Self-Bounded Learning of Prediction Suffix Trees</a></p>
<p>17 0.52154547 <a title="191-lda-17" href="./nips-2004-Semi-parametric_Exponential_Family_PCA.html">163 nips-2004-Semi-parametric Exponential Family PCA</a></p>
<p>18 0.52118146 <a title="191-lda-18" href="./nips-2004-Kernel_Projection_Machine%3A_a_New_Tool_for_Pattern_Recognition.html">93 nips-2004-Kernel Projection Machine: a New Tool for Pattern Recognition</a></p>
<p>19 0.52091259 <a title="191-lda-19" href="./nips-2004-Variational_Minimax_Estimation_of_Discrete_Distributions_under_KL_Loss.html">204 nips-2004-Variational Minimax Estimation of Discrete Distributions under KL Loss</a></p>
<p>20 0.51922643 <a title="191-lda-20" href="./nips-2004-Spike_Sorting%3A_Bayesian_Clustering_of_Non-Stationary_Data.html">174 nips-2004-Spike Sorting: Bayesian Clustering of Non-Stationary Data</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
