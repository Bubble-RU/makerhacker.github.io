<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>189 nips-2004-The Power of Selective Memory: Self-Bounded Learning of Prediction Suffix Trees</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2004" href="../home/nips2004_home.html">nips2004</a> <a title="nips-2004-189" href="#">nips2004-189</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>189 nips-2004-The Power of Selective Memory: Self-Bounded Learning of Prediction Suffix Trees</h1>
<br/><p>Source: <a title="nips-2004-189-pdf" href="http://papers.nips.cc/paper/2549-the-power-of-selective-memory-self-bounded-learning-of-prediction-suffix-trees.pdf">pdf</a></p><p>Author: Ofer Dekel, Shai Shalev-shwartz, Yoram Singer</p><p>Abstract: Prediction sufﬁx trees (PST) provide a popular and effective tool for tasks such as compression, classiﬁcation, and language modeling. In this paper we take a decision theoretic view of PSTs for the task of sequence prediction. Generalizing the notion of margin to PSTs, we present an online PST learning algorithm and derive a loss bound for it. The depth of the PST generated by this algorithm scales linearly with the length of the input. We then describe a self-bounded enhancement of our learning algorithm which automatically grows a bounded-depth PST. We also prove an analogous mistake-bound for the self-bounded algorithm. The result is an efﬁcient algorithm that neither relies on a-priori assumptions on the shape or maximal depth of the target PST nor does it require any parameters. To our knowledge, this is the ﬁrst provably-correct PST learning algorithm which generates a bounded-depth PST while being competitive with any ﬁxed PST determined in hindsight. 1</p><p>Reference: <a title="nips-2004-189-reference" href="../nips2004_reference/nips-2004-The_Power_of_Selective_Memory%3A_Self-Bounded_Learning_of_Prediction_Suffix_Trees_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Generalizing the notion of margin to PSTs, we present an online PST learning algorithm and derive a loss bound for it. [sent-6, score-0.323]
</p><p>2 The depth of the PST generated by this algorithm scales linearly with the length of the input. [sent-7, score-0.227]
</p><p>3 The result is an efﬁcient algorithm that neither relies on a-priori assumptions on the shape or maximal depth of the target PST nor does it require any parameters. [sent-10, score-0.204]
</p><p>4 Different scientiﬁc communities gave different names to variants of prediction sufﬁx trees such as context tree weighting [13] and variable length Markov models [11, 2]. [sent-13, score-0.327]
</p><p>5 A PST receives an input sequence of symbols, one symbol at a time, and predicts the identity of the next symbol in the sequence based on the most recently observed symbols. [sent-14, score-0.354]
</p><p>6 Techniques for ﬁnding a good prediction tree include online Bayesian mixtures [13], tree growing based on PAC-learning [11], and tree pruning based on structural risk minimization [8]. [sent-15, score-0.524]
</p><p>7 All of these algorithms either assume an a-priori bound on the maximal number of previous symbols which may be used to extend predictions or use a pre-deﬁned template-tree beyond which the learned tree cannot grow. [sent-16, score-0.251]
</p><p>8 Motivated by statistical modeling of biological sequences, Apostolico and Bejerano [1] showed that the bound on the maximal depth can be removed by devising a smart modiﬁcation of Ron et. [sent-17, score-0.295]
</p><p>9 In this paper we describe a variant of prediction trees for 0 which we are able to devise a learning algorithm that grows bounded-depth trees, while remaining competitive with any ﬁxed prediction tree chosen in hindsight. [sent-20, score-0.422]
</p><p>10 The resulting −3 −1 time and space requirements of our algorithm are bounded and scale polynomially with the complexity of the best prediction tree. [sent-21, score-0.142]
</p><p>11 The setting we employ is slightly more general than context-based sequence modeling as we assume that we are provided with both an input stream and an −2 7 output stream. [sent-23, score-0.275]
</p><p>12 For concreteness, we assume that the input n stream is a sequence of vectors x1 , x2 , . [sent-24, score-0.199]
</p><p>13 (xt ∈ R ) and Figure 1: An illustration the output stream is a sequence of symbols y1 , y2 , . [sent-27, score-0.299]
</p><p>14 The context j of the output stream by yi and the set of all possible sein this example is: + + + ∗ quences by Y . [sent-35, score-0.254]
</p><p>15 Our goal is to correctly predict each symbol in the output stream y1 , y2 , . [sent-37, score-0.338]
</p><p>16 On each time-step t we predict the symbol yt based on an arbitrarily t-1 long context of previously observed output stream symbols, y1 , and based on the current input vector xt . [sent-41, score-1.027]
</p><p>17 For simplicity, we focus on the binary prediction case where |Y| = 2 and for convenience we use Y = {−1, +1} (or {−, +} for short) as our output alphabet. [sent-42, score-0.159]
</p><p>18 The hypotheses we use are conﬁdence-rated and are of the form h : X ×Y ∗ → R where the sign of h is the predicted symbol and the magnitude of h is the conﬁdence in this prediction. [sent-44, score-0.177]
</p><p>19 Each hypothesis is parameterized by a triplet (w, T , g) where w ∈ Rn , T is a sufﬁx-closed subset of Y ∗ and g is a context function from T into R (T is sufﬁx closed if ∀ s ∈ T it holds that all of the sufﬁxes of s are also in T ). [sent-45, score-0.17]
</p><p>20 The prediction extended by a hypothesis h = (w, T , g) for the t’th symbol is, t-1 h(xt , y1 )  = w · xt +  t-1 2-i/2 g yt-i  . [sent-46, score-0.67]
</p><p>21 (1)  t-1 i: yt-i ∈T  In words, the prediction is the sum of an inner product between the current input vector xt with the weight vector w and the application of the function g to all the sufﬁxes of the output stream observed thus far that also belong to T . [sent-47, score-0.655]
</p><p>22 Since T is a sufﬁx-closed set, it can be described as a rooted tree whose nodes are the sequences constituting T . [sent-48, score-0.137]
</p><p>23 Following the terminology of [11], we use the term prediction sufﬁx tree (PST) for T and refer to s ∈ T as a sequence and a node interchangeably. [sent-50, score-0.236]
</p><p>24 Note that in the prediction process, the t-1 contribution of each context yt-i is multiplied by a factor which is exponentially decreasing t-1 in the length of yt-i . [sent-53, score-0.184]
</p><p>25 An illustration of a PST where T = { , −, +, +−, ++, − + +, + + +}, with the associated prediction for y6 given the 5 context y1 = −−+++ is shown in Fig. [sent-55, score-0.161]
</p><p>26 The predicted value of y6 in the example is sign(w · xt + 2−1/2 × (−1) + 2−1 × 4 + 2−3/2 × 7). [sent-57, score-0.347]
</p><p>27 (1) can be simpliﬁed to, t−1 t-1 h(xt , y1 ) = w · xt +  t-1 2-i/2 g yt-i  . [sent-60, score-0.347]
</p><p>28 (2)  i=1  We use the online learning loss-bound model to analyze our algorithms. [sent-61, score-0.115]
</p><p>29 In the online model, learning takes place in rounds. [sent-62, score-0.115]
</p><p>30 On each round, an instance xt is presented to the  online algorithm, which in return predicts the next output symbol. [sent-63, score-0.521]
</p><p>31 The predicted symbol, t-1 denoted yt is deﬁned to be the sign of ht (xt , y1 ). [sent-64, score-0.511]
</p><p>32 Then, the correct symbol yt is revealed ˆ and with the new input-output pair (xt , yt ) on hand, a new hypothesis ht+1 is generated which will be used to predict the next output symbol, yt+1 . [sent-65, score-0.874]
</p><p>33 In our setting, the hypotheses ht we generate are of the form given by Eq. [sent-66, score-0.225]
</p><p>34 We deﬁne the margin attained by the hypothesis t−1 ht to be yt ht (xt , y1 ). [sent-71, score-0.907]
</p><p>35 Whenever the current symbol yt and the output of the hypothesis agree in their sign, the margin is positive. [sent-72, score-0.625]
</p><p>36 We would like our online algorithm to correctly predict the output stream y1 , . [sent-73, score-0.36]
</p><p>37 This construction is common to many online and batch learning algorithms for classiﬁcation [12, 4]. [sent-77, score-0.132]
</p><p>38 Speciﬁcally, we use the hinge loss as our margin-based loss function which serves as a proxy for the prediction error. [sent-78, score-0.217]
</p><p>39 Formally, the hinge loss attained on round t is deﬁned as, t-1 . [sent-79, score-0.183]
</p><p>40 The hinge-loss equals zero when the margin exceeds t = max 0, 1 − yt ht xt , y1 1 and otherwise grows linearly as the margin gets smaller. [sent-80, score-1.018]
</p><p>41 The online algorithms discussed in this paper are designed to suffer small cumulative hinge-loss. [sent-81, score-0.115]
</p><p>42 Our algorithms are analyzed by comparing their cumulative hinge-losses and prediction errors with those of any ﬁxed hypothesis h = (w , T , g ) which can be chosen in hindsight, after observing the entire input and output streams. [sent-82, score-0.282]
</p><p>43 =  (3)  s∈T  The complexity of a hypothesis h (and h in particular) is deﬁned as the sum of w 2 and g 2 . [sent-86, score-0.122]
</p><p>44 We present two online algorithms for learning large-margin PSTs. [sent-88, score-0.115]
</p><p>45 The ﬁrst incrementally constructs a PST which grows linearly with the length of the input and output sequences, and thus can be arbitrarily large. [sent-89, score-0.187]
</p><p>46 We derive an explicit bound on the maximal depth of the PSTs generated by this algorithm. [sent-91, score-0.252]
</p><p>47 2  Learning PSTs of Unbounded Depth  Having described the online prediction paradigm and the form of hypotheses used, we are left with the task of deﬁning the initial hypothesis h1 and the hypothesis update rule. [sent-94, score-0.484]
</p><p>48 To facilitate our presentation, we assume that all of the instances presented to the online algorithm have a bounded Euclidean norm, namely, xt ≤ 1. [sent-95, score-0.487]
</p><p>49 Next, we deﬁne the updates applied to the weight vector wt and to the PST at the end of round t. [sent-102, score-0.314]
</p><p>50 The weight vector is updated by wt+1 = wt + yt τt xt , where τt = t /( xt 2 + 3). [sent-103, score-1.236]
</p><p>51 Note that if the margin attained on this round is at least 1 then t = 0 and thus wt+1 = wt . [sent-104, score-0.42]
</p><p>52 This type of update is common to other online learning algorithms (e. [sent-105, score-0.147]
</p><p>53 We would like to note in passing that the operation wt · xt in Eq. [sent-108, score-0.591]
</p><p>54 Using a kernel operator K simply amounts to replacing the latter expression with i yi τi K(xi , xt ). [sent-122, score-0.368]
</p><p>55 The update applied to the context function gt also depends on the scaling factor τt . [sent-123, score-0.441]
</p><p>56 However, gt is updated only on those strings which participated in the prediction of yt , namely ˆ t-1 strings of the form yt-i for 1 ≤ i < t. [sent-124, score-0.848]
</p><p>57 Formally, for 1 ≤ i < t our update takes the form t-1 t-1 gt+1 (yt-i ) = gt (yt-i ) + yt 2-i/2 τt . [sent-125, score-0.679]
</p><p>58 , yT be an output stream, where every xt ∈ Rn , xt ≤ 1 and every yt ∈ {-1, 1}. [sent-138, score-1.07]
</p><p>59 Let h = (w , T , g ) be an arbitrary hypothesis such that g < ∞ and which attains the loss values 1 , . [sent-139, score-0.192]
</p><p>60 , T be the sequence of loss values attained by the unbounded-depth algorithm in Fig. [sent-146, score-0.186]
</p><p>61 t=1  In particular, the above bounds the number of prediction mistakes made by the algorithm. [sent-149, score-0.123]
</p><p>62 , T deﬁne ∆t = wt − w ˆ ∆t = s∈Y ∗  gt (s) − g (s)  2  −  s∈Y ∗  2  2  − wt+1 − w  gt+1 (s) − g (s)  2  . [sent-154, score-0.61]
</p><p>63 and, (4)  Note that gt 2 is ﬁnite for any value of t and that g 2 is ﬁnite due to our assumption, ˆ therefore ∆t is ﬁnite and well-deﬁned. [sent-155, score-0.366]
</p><p>64 We prove the theorem by devising upper and lower  ˆ bounds on t (∆t + ∆t ), beginning with the upper bound. [sent-156, score-0.123]
</p><p>65 First, ∆t can 2 be rewritten as ∆t = wt − w − (wt+1 − wt ) + (wt − w ) 2 and by expansion of the right-hand term we get that ∆t = − wt+1 − wt 2 − 2(wt+1 − wt ) · (wt − w ). [sent-164, score-1.029]
</p><p>66 Using the value of wt+1 as deﬁned in the update rule of the algorithm (wt+1 = wt + yt τt xt ) gives, ∆t = − τt2 xt  2  − 2 yt τt xt · (wt − w ) . [sent-165, score-1.904]
</p><p>67 (4) and adding null terms of the form 0 = gt (s) − gt (s), we obtain, ˆ ∆t  =  s∈Y ∗  =  s∈Y ∗  gt (s) − g (s)  2  2  −  gt+1 (s) − gt (s) + gt (s) − g (s)  2  − gt+1 (s) − gt (s)  − 2  gt+1 (s) − gt (s) gt (s) − g (s)  . [sent-168, score-2.928]
</p><p>68 Using the fact that gt+1 differs from gt only on strings t-1 t-1 t-1 ˆ of the form yt-i , where gt+1 yt-i = gt yt-i + yt 2-i/2 τt , we can write ∆t as, dt  dt  ˆ ∆t = i=1  −2-i τt2 − 2  i=1  t-1 yt 2-i/2 τt gt yt-i − g  t-1 yt-i  . [sent-171, score-2.064]
</p><p>69 (7-8) gives, ˆ ∆t + ∆t  = −τt2  2  xt  dt i=1  +  2-i  + 2τt yt w · xt + Using  dt i=1  − 2τt yt wt · xt +  dt i=1  2-i/2 g  t-1 yt-i  dt i=1  t-1 2-i/2 gt yt-i  . [sent-173, score-2.937]
</p><p>70 (9)  2−i ≤ 1 with the deﬁnitions of ht and h from Eq. [sent-174, score-0.198]
</p><p>71 (2), we get that,  ˆ ∆t + ∆t ≥ − τt2 ( xt  2  t−1 + 1) − 2τt yt ht xt , y1  t−1 xt , y1  + 2τt yt h  . [sent-175, score-1.836]
</p><p>72 (10) by Γt and recall that the loss is deﬁned as max{0, 1− t-1 t-1 yt ht (xt , y1 )}. [sent-177, score-0.527]
</p><p>73 Therefore, if t > 0 then −yt ht (xt , y1 ) = t − 1. [sent-178, score-0.198]
</p><p>74 Multiplying both sides t−1 of this equality by τt gives −τt yt ht (xt , y1 ) = τt ( t − 1). [sent-179, score-0.548]
</p><p>75 Similarly, we have that yt h (xt , y1 ) ≥ 1 − t . [sent-181, score-0.281]
</p><p>76 (10) gives that, Γt ≥ − τt2 ( xt 2  −τt2 (  2  + 1) + 2τt ( t − 1) + 2τt (1 −  t)  ,  xt + 1) + 2τt t − 2τt t . [sent-183, score-0.718]
</p><p>77 The lower bound on Γt still holds which in turn equals if we subtract from it the non-negative term (21/2 τt − 2−1/2 t )2 , yielding, Γt  ≥  −τt2 ( xt  = −τt2 ( xt  2  2  + 1) + 2τt + 3) + 2τt  t  − 2τt t  t  − 2τt2 − 2τt  − ( t )2 /2 . [sent-184, score-0.808]
</p><p>78 t  + ( t )2 /2  Using the deﬁnition of τt and using the assumption that xt Γt ≥ − τ t  t  + 2τt  t  −  ( t )2 = 2  xt  2 t 2+  3  −  2  ≤ 1, we get,  ( t )2 ≥ 2  2 t /4  − ( t )2 /2 . [sent-185, score-0.694]
</p><p>79 Finally, we obtain a mistake bound by noting that whenever a prediction mistake occurs, t ≥ 1. [sent-190, score-0.285]
</p><p>80 Furthermore, the number of new nodes added to the tree on round t is on the order of t, resulting in Tt having O(t2 ) nodes. [sent-195, score-0.157]
</p><p>81 3  Self-Bounded Learning of PSTs  The online learning algorithm presented in the previous section has one major drawback, the PSTs it generates can keep growing with each online round. [sent-197, score-0.273]
</p><p>82 We now describe a modiﬁcation to the algorithm which casts a limit on the depth of the PST that is learned. [sent-198, score-0.17]
</p><p>83 maximal tree depth) nor does it require any parameters. [sent-201, score-0.12]
</p><p>84 The algorithm determines the depth to which the PST should be updated automatically, and is therefore named the self-bounded algorithm for PST learning. [sent-202, score-0.212]
</p><p>85 A new variable dt is calculated on every online iteration. [sent-205, score-0.314]
</p><p>86 On rounds where an update takes place, the algorithm updates the PST up to depth dt , adding nodes if necessary. [sent-206, score-0.455]
</p><p>87 The deﬁnition of dt is slightly involved, however it enables us to prove that we remain competitive with any ﬁxed hypothesis (Thm. [sent-208, score-0.352]
</p><p>88 Before, the online hypothesis was modiﬁed whenever t > 0. [sent-212, score-0.241]
</p><p>89 While the following theorem provides a loss bound, this bound can be immediately used to bound the number of prediction mistakes made by the algorithm. [sent-217, score-0.342]
</p><p>90 , yT be an output stream, where every xt ∈ Rn , xt ≤ 1 and every yt ∈ {-1, 1}. [sent-225, score-1.07]
</p><p>91 Let h = (w , T , g ) be an arbitrary hypothesis such that g < ∞ and which attains the loss values 1 , . [sent-226, score-0.192]
</p><p>92 , T be the sequence of loss values attained by the selfbounded algorithm in Fig. [sent-233, score-0.186]
</p><p>93 Using the fact that i=1 2−i ≤ 1 with the deﬁnitions of ht and h from Eq. [sent-242, score-0.198]
</p><p>94 (9) becomes, ˆ ∆t + ∆t ≥ − τt2 ( xt  2  t−1 + 1) − 2τt yt ht xt , y1 t−1 i=dt +1  − 2τt yt  t-1 yt-i  2-i/2 g  t−1 xt , y1  + 2τt yt h  . [sent-244, score-2.082]
</p><p>95 The deﬁnition 2 of dt implies that 2−dt /2 is at most (Pt−1 + τt t )1/2 − Pt−1 /(2τt ). [sent-261, score-0.181]
</p><p>96 Note that if there exists a ﬁxed hypothesis with g < ∞ which attains a margin of 1 on the entire input sequence, then the bound of Thm. [sent-272, score-0.297]
</p><p>97 3 becomes particularly interesting when there exists some ﬁxed hypothesis h for which t ( t )2 is ﬁnite and independent of the total length of the output sequence, denoted by T . [sent-285, score-0.205]
</p><p>98 3 guarantees that the depth of the PST generated by the self-bounded algorithm is smaller than a constant which does not depend on T . [sent-287, score-0.17]
</p><p>99 A fast, bottom-up decision tree pruning algorithm with near-optimal generalization. [sent-334, score-0.163]
</p><p>100 An efﬁcient extension to mixture techniques for prediction and decision trees. [sent-346, score-0.139]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('pst', 0.484), ('gt', 0.366), ('xt', 0.347), ('yt', 0.281), ('wt', 0.244), ('ht', 0.198), ('psts', 0.186), ('dt', 0.181), ('lt', 0.164), ('pt', 0.148), ('depth', 0.145), ('stream', 0.131), ('symbol', 0.118), ('online', 0.115), ('hypothesis', 0.105), ('prediction', 0.1), ('tt', 0.099), ('tree', 0.086), ('bound', 0.073), ('attained', 0.063), ('margin', 0.062), ('output', 0.059), ('round', 0.051), ('sequence', 0.05), ('loss', 0.048), ('summing', 0.045), ('context', 0.043), ('strings', 0.042), ('length', 0.041), ('boxes', 0.041), ('dekel', 0.041), ('symbols', 0.041), ('trees', 0.04), ('xes', 0.039), ('attains', 0.039), ('competitive', 0.038), ('bejerano', 0.037), ('plugging', 0.037), ('mistake', 0.037), ('get', 0.035), ('suf', 0.034), ('maximal', 0.034), ('rounds', 0.033), ('pruning', 0.033), ('grows', 0.033), ('update', 0.032), ('sign', 0.032), ('sequences', 0.031), ('predict', 0.03), ('inequality', 0.03), ('prove', 0.028), ('ron', 0.028), ('dence', 0.027), ('hypotheses', 0.027), ('devising', 0.026), ('automata', 0.026), ('pseudocode', 0.026), ('theorem', 0.025), ('algorithm', 0.025), ('gives', 0.024), ('modi', 0.024), ('sides', 0.023), ('mistakes', 0.023), ('holds', 0.022), ('equality', 0.022), ('upper', 0.022), ('inductive', 0.022), ('whenever', 0.021), ('unbounded', 0.021), ('compression', 0.021), ('hinge', 0.021), ('theoretic', 0.021), ('yi', 0.021), ('rn', 0.021), ('constructs', 0.02), ('extension', 0.02), ('singer', 0.02), ('nodes', 0.02), ('equals', 0.019), ('updates', 0.019), ('receive', 0.019), ('decision', 0.019), ('input', 0.018), ('rewritten', 0.018), ('growing', 0.018), ('illustration', 0.018), ('every', 0.018), ('proof', 0.018), ('predictions', 0.017), ('employed', 0.017), ('complexity', 0.017), ('automatically', 0.017), ('construction', 0.017), ('xed', 0.017), ('noting', 0.017), ('modeling', 0.017), ('updated', 0.017), ('weighting', 0.017), ('biology', 0.017), ('linearly', 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="189-tfidf-1" href="./nips-2004-The_Power_of_Selective_Memory%3A_Self-Bounded_Learning_of_Prediction_Suffix_Trees.html">189 nips-2004-The Power of Selective Memory: Self-Bounded Learning of Prediction Suffix Trees</a></p>
<p>Author: Ofer Dekel, Shai Shalev-shwartz, Yoram Singer</p><p>Abstract: Prediction sufﬁx trees (PST) provide a popular and effective tool for tasks such as compression, classiﬁcation, and language modeling. In this paper we take a decision theoretic view of PSTs for the task of sequence prediction. Generalizing the notion of margin to PSTs, we present an online PST learning algorithm and derive a loss bound for it. The depth of the PST generated by this algorithm scales linearly with the length of the input. We then describe a self-bounded enhancement of our learning algorithm which automatically grows a bounded-depth PST. We also prove an analogous mistake-bound for the self-bounded algorithm. The result is an efﬁcient algorithm that neither relies on a-priori assumptions on the shape or maximal depth of the target PST nor does it require any parameters. To our knowledge, this is the ﬁrst provably-correct PST learning algorithm which generates a bounded-depth PST while being competitive with any ﬁxed PST determined in hindsight. 1</p><p>2 0.2928912 <a title="189-tfidf-2" href="./nips-2004-Stable_adaptive_control_with_online_learning.html">175 nips-2004-Stable adaptive control with online learning</a></p>
<p>Author: H. J. Kim, Andrew Y. Ng</p><p>Abstract: Learning algorithms have enjoyed numerous successes in robotic control tasks. In problems with time-varying dynamics, online learning methods have also proved to be a powerful tool for automatically tracking and/or adapting to the changing circumstances. However, for safety-critical applications such as airplane ﬂight, the adoption of these algorithms has been signiﬁcantly hampered by their lack of safety, such as “stability,” guarantees. Rather than trying to show difﬁcult, a priori, stability guarantees for speciﬁc learning methods, in this paper we propose a method for “monitoring” the controllers suggested by the learning algorithm online, and rejecting controllers leading to instability. We prove that even if an arbitrary online learning method is used with our algorithm to control a linear dynamical system, the resulting system is stable. 1</p><p>3 0.28089184 <a title="189-tfidf-3" href="./nips-2004-Worst-Case_Analysis_of_Selective_Sampling_for_Linear-Threshold_Algorithms.html">206 nips-2004-Worst-Case Analysis of Selective Sampling for Linear-Threshold Algorithms</a></p>
<p>Author: Nicolò Cesa-bianchi, Claudio Gentile, Luca Zaniboni</p><p>Abstract: We provide a worst-case analysis of selective sampling algorithms for learning linear threshold functions. The algorithms considered in this paper are Perceptron-like algorithms, i.e., algorithms which can be efﬁciently run in any reproducing kernel Hilbert space. Our algorithms exploit a simple margin-based randomized rule to decide whether to query the current label. We obtain selective sampling algorithms achieving on average the same bounds as those proven for their deterministic counterparts, but using much fewer labels. We complement our theoretical ﬁndings with an empirical comparison on two text categorization tasks. The outcome of these experiments is largely predicted by our theoretical results: Our selective sampling algorithms tend to perform as good as the algorithms receiving the true label after each classiﬁcation, while observing in practice substantially fewer labels. 1</p><p>4 0.27384126 <a title="189-tfidf-4" href="./nips-2004-Mistake_Bounds_for_Maximum_Entropy_Discrimination.html">119 nips-2004-Mistake Bounds for Maximum Entropy Discrimination</a></p>
<p>Author: Philip M. Long, Xinyu Wu</p><p>Abstract: We establish a mistake bound for an ensemble method for classiﬁcation based on maximizing the entropy of voting weights subject to margin constraints. The bound is the same as a general bound proved for the Weighted Majority Algorithm, and similar to bounds for other variants of Winnow. We prove a more reﬁned bound that leads to a nearly optimal algorithm for learning disjunctions, again, based on the maximum entropy principle. We describe a simpliﬁcation of the on-line maximum entropy method in which, after each iteration, the margin constraints are replaced with a single linear inequality. The simpliﬁed algorithm, which takes a similar form to Winnow, achieves the same mistake bounds. 1</p><p>5 0.26448882 <a title="189-tfidf-5" href="./nips-2004-Matrix_Exponential_Gradient_Updates_for_On-line_Learning_and_Bregman_Projection.html">110 nips-2004-Matrix Exponential Gradient Updates for On-line Learning and Bregman Projection</a></p>
<p>Author: Koji Tsuda, Gunnar Rätsch, Manfred K. Warmuth</p><p>Abstract: We address the problem of learning a symmetric positive deﬁnite matrix. The central issue is to design parameter updates that preserve positive deﬁniteness. Our updates are motivated with the von Neumann divergence. Rather than treating the most general case, we focus on two key applications that exemplify our methods: On-line learning with a simple square loss and ﬁnding a symmetric positive deﬁnite matrix subject to symmetric linear constraints. The updates generalize the Exponentiated Gradient (EG) update and AdaBoost, respectively: the parameter is now a symmetric positive deﬁnite matrix of trace one instead of a probability vector (which in this context is a diagonal positive deﬁnite matrix with trace one). The generalized updates use matrix logarithms and exponentials to preserve positive deﬁniteness. Most importantly, we show how the analysis of each algorithm generalizes to the non-diagonal case. We apply both new algorithms, called the Matrix Exponentiated Gradient (MEG) update and DeﬁniteBoost, to learn a kernel matrix from distance measurements.</p><p>6 0.23404887 <a title="189-tfidf-6" href="./nips-2004-Bayesian_inference_in_spiking_neurons.html">28 nips-2004-Bayesian inference in spiking neurons</a></p>
<p>7 0.12720817 <a title="189-tfidf-7" href="./nips-2004-Temporal-Difference_Networks.html">183 nips-2004-Temporal-Difference Networks</a></p>
<p>8 0.11402566 <a title="189-tfidf-8" href="./nips-2004-Contextual_Models_for_Object_Detection_Using_Boosted_Random_Fields.html">47 nips-2004-Contextual Models for Object Detection Using Boosted Random Fields</a></p>
<p>9 0.11195219 <a title="189-tfidf-9" href="./nips-2004-Convergence_and_No-Regret_in_Multiagent_Learning.html">48 nips-2004-Convergence and No-Regret in Multiagent Learning</a></p>
<p>10 0.10765515 <a title="189-tfidf-10" href="./nips-2004-Approximately_Efficient_Online_Mechanism_Design.html">24 nips-2004-Approximately Efficient Online Mechanism Design</a></p>
<p>11 0.10068383 <a title="189-tfidf-11" href="./nips-2004-Incremental_Learning_for_Visual_Tracking.html">83 nips-2004-Incremental Learning for Visual Tracking</a></p>
<p>12 0.097777247 <a title="189-tfidf-12" href="./nips-2004-Exponentiated_Gradient_Algorithms_for_Large-margin_Structured_Classification.html">67 nips-2004-Exponentiated Gradient Algorithms for Large-margin Structured Classification</a></p>
<p>13 0.096393272 <a title="189-tfidf-13" href="./nips-2004-Online_Bounds_for_Bayesian_Algorithms.html">138 nips-2004-Online Bounds for Bayesian Algorithms</a></p>
<p>14 0.094226688 <a title="189-tfidf-14" href="./nips-2004-On_Semi-Supervised_Classification.html">136 nips-2004-On Semi-Supervised Classification</a></p>
<p>15 0.089120165 <a title="189-tfidf-15" href="./nips-2004-Efficient_Kernel_Discriminant_Analysis_via_QR_Decomposition.html">59 nips-2004-Efficient Kernel Discriminant Analysis via QR Decomposition</a></p>
<p>16 0.083179168 <a title="189-tfidf-16" href="./nips-2004-Analysis_of_a_greedy_active_learning_strategy.html">23 nips-2004-Analysis of a greedy active learning strategy</a></p>
<p>17 0.08293581 <a title="189-tfidf-17" href="./nips-2004-Incremental_Algorithms_for_Hierarchical_Classification.html">82 nips-2004-Incremental Algorithms for Hierarchical Classification</a></p>
<p>18 0.081735283 <a title="189-tfidf-18" href="./nips-2004-Message_Errors_in_Belief_Propagation.html">116 nips-2004-Message Errors in Belief Propagation</a></p>
<p>19 0.080307484 <a title="189-tfidf-19" href="./nips-2004-At_the_Edge_of_Chaos%3A_Real-time_Computations_and_Self-Organized_Criticality_in_Recurrent_Neural_Networks.html">26 nips-2004-At the Edge of Chaos: Real-time Computations and Self-Organized Criticality in Recurrent Neural Networks</a></p>
<p>20 0.078502975 <a title="189-tfidf-20" href="./nips-2004-Support_Vector_Classification_with_Input_Data_Uncertainty.html">178 nips-2004-Support Vector Classification with Input Data Uncertainty</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2004_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.206), (1, -0.057), (2, 0.347), (3, 0.12), (4, 0.288), (5, -0.308), (6, -0.006), (7, 0.072), (8, 0.128), (9, 0.087), (10, -0.053), (11, -0.003), (12, -0.13), (13, -0.048), (14, -0.035), (15, -0.038), (16, -0.053), (17, -0.1), (18, 0.06), (19, 0.062), (20, 0.08), (21, 0.061), (22, -0.144), (23, 0.131), (24, -0.09), (25, -0.017), (26, 0.078), (27, -0.158), (28, 0.011), (29, -0.044), (30, 0.082), (31, -0.02), (32, -0.018), (33, 0.021), (34, 0.082), (35, 0.086), (36, 0.018), (37, 0.014), (38, -0.022), (39, -0.01), (40, -0.008), (41, -0.084), (42, 0.041), (43, -0.029), (44, -0.01), (45, -0.007), (46, 0.033), (47, 0.02), (48, 0.062), (49, 0.074)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97793847 <a title="189-lsi-1" href="./nips-2004-The_Power_of_Selective_Memory%3A_Self-Bounded_Learning_of_Prediction_Suffix_Trees.html">189 nips-2004-The Power of Selective Memory: Self-Bounded Learning of Prediction Suffix Trees</a></p>
<p>Author: Ofer Dekel, Shai Shalev-shwartz, Yoram Singer</p><p>Abstract: Prediction sufﬁx trees (PST) provide a popular and effective tool for tasks such as compression, classiﬁcation, and language modeling. In this paper we take a decision theoretic view of PSTs for the task of sequence prediction. Generalizing the notion of margin to PSTs, we present an online PST learning algorithm and derive a loss bound for it. The depth of the PST generated by this algorithm scales linearly with the length of the input. We then describe a self-bounded enhancement of our learning algorithm which automatically grows a bounded-depth PST. We also prove an analogous mistake-bound for the self-bounded algorithm. The result is an efﬁcient algorithm that neither relies on a-priori assumptions on the shape or maximal depth of the target PST nor does it require any parameters. To our knowledge, this is the ﬁrst provably-correct PST learning algorithm which generates a bounded-depth PST while being competitive with any ﬁxed PST determined in hindsight. 1</p><p>2 0.84635675 <a title="189-lsi-2" href="./nips-2004-Stable_adaptive_control_with_online_learning.html">175 nips-2004-Stable adaptive control with online learning</a></p>
<p>Author: H. J. Kim, Andrew Y. Ng</p><p>Abstract: Learning algorithms have enjoyed numerous successes in robotic control tasks. In problems with time-varying dynamics, online learning methods have also proved to be a powerful tool for automatically tracking and/or adapting to the changing circumstances. However, for safety-critical applications such as airplane ﬂight, the adoption of these algorithms has been signiﬁcantly hampered by their lack of safety, such as “stability,” guarantees. Rather than trying to show difﬁcult, a priori, stability guarantees for speciﬁc learning methods, in this paper we propose a method for “monitoring” the controllers suggested by the learning algorithm online, and rejecting controllers leading to instability. We prove that even if an arbitrary online learning method is used with our algorithm to control a linear dynamical system, the resulting system is stable. 1</p><p>3 0.64621013 <a title="189-lsi-3" href="./nips-2004-Worst-Case_Analysis_of_Selective_Sampling_for_Linear-Threshold_Algorithms.html">206 nips-2004-Worst-Case Analysis of Selective Sampling for Linear-Threshold Algorithms</a></p>
<p>Author: Nicolò Cesa-bianchi, Claudio Gentile, Luca Zaniboni</p><p>Abstract: We provide a worst-case analysis of selective sampling algorithms for learning linear threshold functions. The algorithms considered in this paper are Perceptron-like algorithms, i.e., algorithms which can be efﬁciently run in any reproducing kernel Hilbert space. Our algorithms exploit a simple margin-based randomized rule to decide whether to query the current label. We obtain selective sampling algorithms achieving on average the same bounds as those proven for their deterministic counterparts, but using much fewer labels. We complement our theoretical ﬁndings with an empirical comparison on two text categorization tasks. The outcome of these experiments is largely predicted by our theoretical results: Our selective sampling algorithms tend to perform as good as the algorithms receiving the true label after each classiﬁcation, while observing in practice substantially fewer labels. 1</p><p>4 0.64347976 <a title="189-lsi-4" href="./nips-2004-Matrix_Exponential_Gradient_Updates_for_On-line_Learning_and_Bregman_Projection.html">110 nips-2004-Matrix Exponential Gradient Updates for On-line Learning and Bregman Projection</a></p>
<p>Author: Koji Tsuda, Gunnar Rätsch, Manfred K. Warmuth</p><p>Abstract: We address the problem of learning a symmetric positive deﬁnite matrix. The central issue is to design parameter updates that preserve positive deﬁniteness. Our updates are motivated with the von Neumann divergence. Rather than treating the most general case, we focus on two key applications that exemplify our methods: On-line learning with a simple square loss and ﬁnding a symmetric positive deﬁnite matrix subject to symmetric linear constraints. The updates generalize the Exponentiated Gradient (EG) update and AdaBoost, respectively: the parameter is now a symmetric positive deﬁnite matrix of trace one instead of a probability vector (which in this context is a diagonal positive deﬁnite matrix with trace one). The generalized updates use matrix logarithms and exponentials to preserve positive deﬁniteness. Most importantly, we show how the analysis of each algorithm generalizes to the non-diagonal case. We apply both new algorithms, called the Matrix Exponentiated Gradient (MEG) update and DeﬁniteBoost, to learn a kernel matrix from distance measurements.</p><p>5 0.60347837 <a title="189-lsi-5" href="./nips-2004-Mistake_Bounds_for_Maximum_Entropy_Discrimination.html">119 nips-2004-Mistake Bounds for Maximum Entropy Discrimination</a></p>
<p>Author: Philip M. Long, Xinyu Wu</p><p>Abstract: We establish a mistake bound for an ensemble method for classiﬁcation based on maximizing the entropy of voting weights subject to margin constraints. The bound is the same as a general bound proved for the Weighted Majority Algorithm, and similar to bounds for other variants of Winnow. We prove a more reﬁned bound that leads to a nearly optimal algorithm for learning disjunctions, again, based on the maximum entropy principle. We describe a simpliﬁcation of the on-line maximum entropy method in which, after each iteration, the margin constraints are replaced with a single linear inequality. The simpliﬁed algorithm, which takes a similar form to Winnow, achieves the same mistake bounds. 1</p><p>6 0.4666225 <a title="189-lsi-6" href="./nips-2004-Bayesian_inference_in_spiking_neurons.html">28 nips-2004-Bayesian inference in spiking neurons</a></p>
<p>7 0.37299344 <a title="189-lsi-7" href="./nips-2004-On_Semi-Supervised_Classification.html">136 nips-2004-On Semi-Supervised Classification</a></p>
<p>8 0.35118955 <a title="189-lsi-8" href="./nips-2004-Temporal-Difference_Networks.html">183 nips-2004-Temporal-Difference Networks</a></p>
<p>9 0.34214947 <a title="189-lsi-9" href="./nips-2004-Online_Bounds_for_Bayesian_Algorithms.html">138 nips-2004-Online Bounds for Bayesian Algorithms</a></p>
<p>10 0.31564769 <a title="189-lsi-10" href="./nips-2004-Convergence_and_No-Regret_in_Multiagent_Learning.html">48 nips-2004-Convergence and No-Regret in Multiagent Learning</a></p>
<p>11 0.30087337 <a title="189-lsi-11" href="./nips-2004-Incremental_Algorithms_for_Hierarchical_Classification.html">82 nips-2004-Incremental Algorithms for Hierarchical Classification</a></p>
<p>12 0.29732928 <a title="189-lsi-12" href="./nips-2004-Instance-Specific_Bayesian_Model_Averaging_for_Classification.html">86 nips-2004-Instance-Specific Bayesian Model Averaging for Classification</a></p>
<p>13 0.29456425 <a title="189-lsi-13" href="./nips-2004-Approximately_Efficient_Online_Mechanism_Design.html">24 nips-2004-Approximately Efficient Online Mechanism Design</a></p>
<p>14 0.28174087 <a title="189-lsi-14" href="./nips-2004-Message_Errors_in_Belief_Propagation.html">116 nips-2004-Message Errors in Belief Propagation</a></p>
<p>15 0.27125391 <a title="189-lsi-15" href="./nips-2004-A_Generalized_Bradley-Terry_Model%3A_From_Group_Competition_to_Individual_Skill.html">4 nips-2004-A Generalized Bradley-Terry Model: From Group Competition to Individual Skill</a></p>
<p>16 0.26061141 <a title="189-lsi-16" href="./nips-2004-Exponentiated_Gradient_Algorithms_for_Large-margin_Structured_Classification.html">67 nips-2004-Exponentiated Gradient Algorithms for Large-margin Structured Classification</a></p>
<p>17 0.25473022 <a title="189-lsi-17" href="./nips-2004-Incremental_Learning_for_Visual_Tracking.html">83 nips-2004-Incremental Learning for Visual Tracking</a></p>
<p>18 0.25118446 <a title="189-lsi-18" href="./nips-2004-The_Convergence_of_Contrastive_Divergences.html">185 nips-2004-The Convergence of Contrastive Divergences</a></p>
<p>19 0.24248606 <a title="189-lsi-19" href="./nips-2004-Binet-Cauchy_Kernels.html">30 nips-2004-Binet-Cauchy Kernels</a></p>
<p>20 0.23414007 <a title="189-lsi-20" href="./nips-2004-Variational_Minimax_Estimation_of_Discrete_Distributions_under_KL_Loss.html">204 nips-2004-Variational Minimax Estimation of Discrete Distributions under KL Loss</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2004_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.127), (15, 0.166), (25, 0.019), (26, 0.069), (31, 0.032), (32, 0.022), (33, 0.153), (35, 0.021), (39, 0.019), (44, 0.175), (50, 0.087)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.93424296 <a title="189-lda-1" href="./nips-2004-Reducing_Spike_Train_Variability%3A_A_Computational_Theory_Of_Spike-Timing_Dependent_Plasticity.html">153 nips-2004-Reducing Spike Train Variability: A Computational Theory Of Spike-Timing Dependent Plasticity</a></p>
<p>Author: Sander M. Bohte, Michael C. Mozer</p><p>Abstract: Experimental studies have observed synaptic potentiation when a presynaptic neuron ﬁres shortly before a postsynaptic neuron, and synaptic depression when the presynaptic neuron ﬁres shortly after. The dependence of synaptic modulation on the precise timing of the two action potentials is known as spike-timing dependent plasticity or STDP. We derive STDP from a simple computational principle: synapses adapt so as to minimize the postsynaptic neuron’s variability to a given presynaptic input, causing the neuron’s output to become more reliable in the face of noise. Using an entropy-minimization objective function and the biophysically realistic spike-response model of Gerstner (2001), we simulate neurophysiological experiments and obtain the characteristic STDP curve along with other phenomena including the reduction in synaptic plasticity as synaptic eﬃcacy increases. We compare our account to other eﬀorts to derive STDP from computational principles, and argue that our account provides the most comprehensive coverage of the phenomena. Thus, reliability of neural response in the face of noise may be a key goal of cortical adaptation. 1</p><p>same-paper 2 0.87865019 <a title="189-lda-2" href="./nips-2004-The_Power_of_Selective_Memory%3A_Self-Bounded_Learning_of_Prediction_Suffix_Trees.html">189 nips-2004-The Power of Selective Memory: Self-Bounded Learning of Prediction Suffix Trees</a></p>
<p>Author: Ofer Dekel, Shai Shalev-shwartz, Yoram Singer</p><p>Abstract: Prediction sufﬁx trees (PST) provide a popular and effective tool for tasks such as compression, classiﬁcation, and language modeling. In this paper we take a decision theoretic view of PSTs for the task of sequence prediction. Generalizing the notion of margin to PSTs, we present an online PST learning algorithm and derive a loss bound for it. The depth of the PST generated by this algorithm scales linearly with the length of the input. We then describe a self-bounded enhancement of our learning algorithm which automatically grows a bounded-depth PST. We also prove an analogous mistake-bound for the self-bounded algorithm. The result is an efﬁcient algorithm that neither relies on a-priori assumptions on the shape or maximal depth of the target PST nor does it require any parameters. To our knowledge, this is the ﬁrst provably-correct PST learning algorithm which generates a bounded-depth PST while being competitive with any ﬁxed PST determined in hindsight. 1</p><p>3 0.8556388 <a title="189-lda-3" href="./nips-2004-Fast_Rates_to_Bayes_for_Kernel_Machines.html">69 nips-2004-Fast Rates to Bayes for Kernel Machines</a></p>
<p>Author: Ingo Steinwart, Clint Scovel</p><p>Abstract: We establish learning rates to the Bayes risk for support vector machines (SVMs) with hinge loss. In particular, for SVMs with Gaussian RBF kernels we propose a geometric condition for distributions which can be used to determine approximation properties of these kernels. Finally, we compare our methods with a recent paper of G. Blanchard et al.. 1</p><p>4 0.82029939 <a title="189-lda-4" href="./nips-2004-Rate-_and_Phase-coded_Autoassociative_Memory.html">151 nips-2004-Rate- and Phase-coded Autoassociative Memory</a></p>
<p>Author: Máté Lengyel, Peter Dayan</p><p>Abstract: Areas of the brain involved in various forms of memory exhibit patterns of neural activity quite unlike those in canonical computational models. We show how to use well-founded Bayesian probabilistic autoassociative recall to derive biologically reasonable neuronal dynamics in recurrently coupled models, together with appropriate values for parameters such as the membrane time constant and inhibition. We explicitly treat two cases. One arises from a standard Hebbian learning rule, and involves activity patterns that are coded by graded ﬁring rates. The other arises from a spike timing dependent learning rule, and involves patterns coded by the phase of spike times relative to a coherent local ﬁeld potential oscillation. Our model offers a new and more complete understanding of how neural dynamics may support autoassociation. 1</p><p>5 0.80976164 <a title="189-lda-5" href="./nips-2004-Non-Local_Manifold_Tangent_Learning.html">131 nips-2004-Non-Local Manifold Tangent Learning</a></p>
<p>Author: Yoshua Bengio, Martin Monperrus</p><p>Abstract: We claim and present arguments to the effect that a large class of manifold learning algorithms that are essentially local and can be framed as kernel learning algorithms will suffer from the curse of dimensionality, at the dimension of the true underlying manifold. This observation suggests to explore non-local manifold learning algorithms which attempt to discover shared structure in the tangent planes at different positions. A criterion for such an algorithm is proposed and experiments estimating a tangent plane prediction function are presented, showing its advantages with respect to local manifold learning algorithms: it is able to generalize very far from training data (on learning handwritten character image rotations), where a local non-parametric method fails. 1</p><p>6 0.80647475 <a title="189-lda-6" href="./nips-2004-Worst-Case_Analysis_of_Selective_Sampling_for_Linear-Threshold_Algorithms.html">206 nips-2004-Worst-Case Analysis of Selective Sampling for Linear-Threshold Algorithms</a></p>
<p>7 0.80595189 <a title="189-lda-7" href="./nips-2004-Spike-timing_Dependent_Plasticity_and_Mutual_Information_Maximization_for_a_Spiking_Neuron_Model.html">173 nips-2004-Spike-timing Dependent Plasticity and Mutual Information Maximization for a Spiking Neuron Model</a></p>
<p>8 0.80225641 <a title="189-lda-8" href="./nips-2004-Bayesian_inference_in_spiking_neurons.html">28 nips-2004-Bayesian inference in spiking neurons</a></p>
<p>9 0.80166018 <a title="189-lda-9" href="./nips-2004-Support_Vector_Classification_with_Input_Data_Uncertainty.html">178 nips-2004-Support Vector Classification with Input Data Uncertainty</a></p>
<p>10 0.80086058 <a title="189-lda-10" href="./nips-2004-Hierarchical_Eigensolver_for_Transition_Matrices_in_Spectral_Methods.html">79 nips-2004-Hierarchical Eigensolver for Transition Matrices in Spectral Methods</a></p>
<p>11 0.79734361 <a title="189-lda-11" href="./nips-2004-A_Generalized_Bradley-Terry_Model%3A_From_Group_Competition_to_Individual_Skill.html">4 nips-2004-A Generalized Bradley-Terry Model: From Group Competition to Individual Skill</a></p>
<p>12 0.79580319 <a title="189-lda-12" href="./nips-2004-Matrix_Exponential_Gradient_Updates_for_On-line_Learning_and_Bregman_Projection.html">110 nips-2004-Matrix Exponential Gradient Updates for On-line Learning and Bregman Projection</a></p>
<p>13 0.79569995 <a title="189-lda-13" href="./nips-2004-Efficient_Kernel_Machines_Using_the_Improved_Fast_Gauss_Transform.html">60 nips-2004-Efficient Kernel Machines Using the Improved Fast Gauss Transform</a></p>
<p>14 0.79555541 <a title="189-lda-14" href="./nips-2004-Using_the_Equivalent_Kernel_to_Understand_Gaussian_Process_Regression.html">201 nips-2004-Using the Equivalent Kernel to Understand Gaussian Process Regression</a></p>
<p>15 0.79468906 <a title="189-lda-15" href="./nips-2004-Log-concavity_Results_on_Gaussian_Process_Methods_for_Supervised_and_Unsupervised_Learning.html">105 nips-2004-Log-concavity Results on Gaussian Process Methods for Supervised and Unsupervised Learning</a></p>
<p>16 0.79446113 <a title="189-lda-16" href="./nips-2004-Semigroup_Kernels_on_Finite_Sets.html">168 nips-2004-Semigroup Kernels on Finite Sets</a></p>
<p>17 0.79375368 <a title="189-lda-17" href="./nips-2004-Exponentiated_Gradient_Algorithms_for_Large-margin_Structured_Classification.html">67 nips-2004-Exponentiated Gradient Algorithms for Large-margin Structured Classification</a></p>
<p>18 0.7907111 <a title="189-lda-18" href="./nips-2004-Nonparametric_Transforms_of_Graph_Kernels_for_Semi-Supervised_Learning.html">133 nips-2004-Nonparametric Transforms of Graph Kernels for Semi-Supervised Learning</a></p>
<p>19 0.78964514 <a title="189-lda-19" href="./nips-2004-Spike_Sorting%3A_Bayesian_Clustering_of_Non-Stationary_Data.html">174 nips-2004-Spike Sorting: Bayesian Clustering of Non-Stationary Data</a></p>
<p>20 0.78945339 <a title="189-lda-20" href="./nips-2004-At_the_Edge_of_Chaos%3A_Real-time_Computations_and_Self-Organized_Criticality_in_Recurrent_Neural_Networks.html">26 nips-2004-At the Edge of Chaos: Real-time Computations and Self-Organized Criticality in Recurrent Neural Networks</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
