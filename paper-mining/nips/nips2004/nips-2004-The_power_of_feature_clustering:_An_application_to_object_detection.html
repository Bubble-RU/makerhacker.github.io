<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>192 nips-2004-The power of feature clustering: An application to object detection</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2004" href="../home/nips2004_home.html">nips2004</a> <a title="nips-2004-192" href="#">nips2004-192</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>192 nips-2004-The power of feature clustering: An application to object detection</h1>
<br/><p>Source: <a title="nips-2004-192-pdf" href="http://papers.nips.cc/paper/2622-the-power-of-feature-clustering-an-application-to-object-detection.pdf">pdf</a></p><p>Author: Shai Avidan, Moshe Butman</p><p>Abstract: We give a fast rejection scheme that is based on image segments and demonstrate it on the canonical example of face detection. However, instead of focusing on the detection step we focus on the rejection step and show that our method is simple and fast to be learned, thus making it an excellent pre-processing step to accelerate standard machine learning classiﬁers, such as neural-networks, Bayes classiﬁers or SVM. We decompose a collection of face images into regions of pixels with similar behavior over the image set. The relationships between the mean and variance of image segments are used to form a cascade of rejectors that can reject over 99.8% of image patches, thus only a small fraction of the image patches must be passed to a full-scale classiﬁer. Moreover, the training time for our method is much less than an hour, on a standard PC. The shape of the features (i.e. image segments) we use is data-driven, they are very cheap to compute and they form a very low dimensional feature space in which exhaustive search for the best features is tractable. 1</p><p>Reference: <a title="nips-2004-192-reference" href="../nips2004_reference/nips-2004-The_power_of_feature_clustering%3A_An_application_to_object_detection_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('reject', 0.824), ('seg', 0.294), ('im', 0.217), ('pixel', 0.182), ('patch', 0.169), ('cascad', 0.149), ('fac', 0.141), ('feat', 0.068), ('detect', 0.062), ('fals', 0.056), ('fast', 0.054), ('accel', 0.05), ('triplet', 0.049), ('xj', 0.046), ('cmu', 0.046), ('exhaust', 0.045), ('pass', 0.039), ('pattern', 0.037), ('avid', 0.035), ('hour', 0.034)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999994 <a title="192-tfidf-1" href="./nips-2004-The_power_of_feature_clustering%3A_An_application_to_object_detection.html">192 nips-2004-The power of feature clustering: An application to object detection</a></p>
<p>2 0.17054498 <a title="192-tfidf-2" href="./nips-2004-Learning_Hyper-Features_for_Visual_Identification.html">99 nips-2004-Learning Hyper-Features for Visual Identification</a></p>
<p>3 0.14801572 <a title="192-tfidf-3" href="./nips-2004-Face_Detection_---_Efficient_and_Rank_Deficient.html">68 nips-2004-Face Detection --- Efficient and Rank Deficient</a></p>
<p>4 0.12353535 <a title="192-tfidf-4" href="./nips-2004-Joint_MRI_Bias_Removal_Using_Entropy_Minimization_Across_Images.html">89 nips-2004-Joint MRI Bias Removal Using Entropy Minimization Across Images</a></p>
<p>5 0.12231103 <a title="192-tfidf-5" href="./nips-2004-Synergistic_Face_Detection_and_Pose_Estimation_with_Energy-Based_Models.html">182 nips-2004-Synergistic Face Detection and Pose Estimation with Energy-Based Models</a></p>
<p>6 0.12146866 <a title="192-tfidf-6" href="./nips-2004-Contextual_Models_for_Object_Detection_Using_Boosted_Random_Fields.html">47 nips-2004-Contextual Models for Object Detection Using Boosted Random Fields</a></p>
<p>7 0.12029687 <a title="192-tfidf-7" href="./nips-2004-A_Three_Tiered_Approach_for_Articulated_Object_Action_Modeling_and_Recognition.html">13 nips-2004-A Three Tiered Approach for Articulated Object Action Modeling and Recognition</a></p>
<p>8 0.11257825 <a title="192-tfidf-8" href="./nips-2004-Modeling_Nonlinear_Dependencies_in_Natural_Images_using_Mixture_of_Laplacian_Distribution.html">121 nips-2004-Modeling Nonlinear Dependencies in Natural Images using Mixture of Laplacian Distribution</a></p>
<p>9 0.1116942 <a title="192-tfidf-9" href="./nips-2004-Conditional_Random_Fields_for_Object_Recognition.html">44 nips-2004-Conditional Random Fields for Object Recognition</a></p>
<p>10 0.11112528 <a title="192-tfidf-10" href="./nips-2004-Semi-Markov_Conditional_Random_Fields_for_Information_Extraction.html">162 nips-2004-Semi-Markov Conditional Random Fields for Information Extraction</a></p>
<p>11 0.11091443 <a title="192-tfidf-11" href="./nips-2004-Parallel_Support_Vector_Machines%3A_The_Cascade_SVM.html">144 nips-2004-Parallel Support Vector Machines: The Cascade SVM</a></p>
<p>12 0.10727075 <a title="192-tfidf-12" href="./nips-2004-Common-Frame_Model_for_Object_Recognition.html">40 nips-2004-Common-Frame Model for Object Recognition</a></p>
<p>13 0.1002293 <a title="192-tfidf-13" href="./nips-2004-Assignment_of_Multiplicative_Mixtures_in_Natural_Images.html">25 nips-2004-Assignment of Multiplicative Mixtures in Natural Images</a></p>
<p>14 0.099394508 <a title="192-tfidf-14" href="./nips-2004-Seeing_through_water.html">160 nips-2004-Seeing through water</a></p>
<p>15 0.090268679 <a title="192-tfidf-15" href="./nips-2004-Instance-Based_Relevance_Feedback_for_Image_Retrieval.html">85 nips-2004-Instance-Based Relevance Feedback for Image Retrieval</a></p>
<p>16 0.09012901 <a title="192-tfidf-16" href="./nips-2004-The_Variational_Ising_Classifier_%28VIC%29_Algorithm_for_Coherently_Contaminated_Data.html">191 nips-2004-The Variational Ising Classifier (VIC) Algorithm for Coherently Contaminated Data</a></p>
<p>17 0.083632983 <a title="192-tfidf-17" href="./nips-2004-Who%27s_In_the_Picture.html">205 nips-2004-Who's In the Picture</a></p>
<p>18 0.081533179 <a title="192-tfidf-18" href="./nips-2004-Efficient_Out-of-Sample_Extension_of_Dominant-Set_Clusters.html">61 nips-2004-Efficient Out-of-Sample Extension of Dominant-Set Clusters</a></p>
<p>19 0.07622157 <a title="192-tfidf-19" href="./nips-2004-Object_Classification_from_a_Single_Example_Utilizing_Class_Relevance_Metrics.html">134 nips-2004-Object Classification from a Single Example Utilizing Class Relevance Metrics</a></p>
<p>20 0.0744837 <a title="192-tfidf-20" href="./nips-2004-Stable_adaptive_control_with_online_learning.html">175 nips-2004-Stable adaptive control with online learning</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2004_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.168), (1, 0.062), (2, 0.066), (3, -0.22), (4, -0.076), (5, 0.1), (6, -0.181), (7, -0.089), (8, -0.054), (9, -0.013), (10, 0.031), (11, 0.143), (12, 0.057), (13, -0.177), (14, 0.003), (15, 0.125), (16, -0.009), (17, -0.031), (18, -0.121), (19, 0.009), (20, -0.059), (21, -0.005), (22, -0.0), (23, 0.117), (24, 0.101), (25, 0.039), (26, 0.074), (27, -0.124), (28, -0.038), (29, -0.023), (30, -0.041), (31, 0.002), (32, -0.036), (33, 0.058), (34, 0.041), (35, 0.038), (36, -0.089), (37, -0.065), (38, -0.08), (39, -0.035), (40, -0.042), (41, -0.015), (42, 0.025), (43, -0.02), (44, -0.068), (45, -0.089), (46, 0.029), (47, 0.001), (48, 0.038), (49, -0.111)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95775861 <a title="192-lsi-1" href="./nips-2004-The_power_of_feature_clustering%3A_An_application_to_object_detection.html">192 nips-2004-The power of feature clustering: An application to object detection</a></p>
<p>2 0.67782229 <a title="192-lsi-2" href="./nips-2004-Synergistic_Face_Detection_and_Pose_Estimation_with_Energy-Based_Models.html">182 nips-2004-Synergistic Face Detection and Pose Estimation with Energy-Based Models</a></p>
<p>3 0.66045702 <a title="192-lsi-3" href="./nips-2004-Learning_Hyper-Features_for_Visual_Identification.html">99 nips-2004-Learning Hyper-Features for Visual Identification</a></p>
<p>4 0.62671471 <a title="192-lsi-4" href="./nips-2004-Face_Detection_---_Efficient_and_Rank_Deficient.html">68 nips-2004-Face Detection --- Efficient and Rank Deficient</a></p>
<p>5 0.60957927 <a title="192-lsi-5" href="./nips-2004-Common-Frame_Model_for_Object_Recognition.html">40 nips-2004-Common-Frame Model for Object Recognition</a></p>
<p>6 0.58642155 <a title="192-lsi-6" href="./nips-2004-Using_Machine_Learning_to_Break_Visual_Human_Interaction_Proofs_%28HIPs%29.html">199 nips-2004-Using Machine Learning to Break Visual Human Interaction Proofs (HIPs)</a></p>
<p>7 0.58590341 <a title="192-lsi-7" href="./nips-2004-The_Variational_Ising_Classifier_%28VIC%29_Algorithm_for_Coherently_Contaminated_Data.html">191 nips-2004-The Variational Ising Classifier (VIC) Algorithm for Coherently Contaminated Data</a></p>
<p>8 0.5765292 <a title="192-lsi-8" href="./nips-2004-Joint_MRI_Bias_Removal_Using_Entropy_Minimization_Across_Images.html">89 nips-2004-Joint MRI Bias Removal Using Entropy Minimization Across Images</a></p>
<p>9 0.56890202 <a title="192-lsi-9" href="./nips-2004-Contextual_Models_for_Object_Detection_Using_Boosted_Random_Fields.html">47 nips-2004-Contextual Models for Object Detection Using Boosted Random Fields</a></p>
<p>10 0.501001 <a title="192-lsi-10" href="./nips-2004-Conditional_Random_Fields_for_Object_Recognition.html">44 nips-2004-Conditional Random Fields for Object Recognition</a></p>
<p>11 0.4921757 <a title="192-lsi-11" href="./nips-2004-Semi-Markov_Conditional_Random_Fields_for_Information_Extraction.html">162 nips-2004-Semi-Markov Conditional Random Fields for Information Extraction</a></p>
<p>12 0.49132979 <a title="192-lsi-12" href="./nips-2004-Instance-Based_Relevance_Feedback_for_Image_Retrieval.html">85 nips-2004-Instance-Based Relevance Feedback for Image Retrieval</a></p>
<p>13 0.48129469 <a title="192-lsi-13" href="./nips-2004-Assignment_of_Multiplicative_Mixtures_in_Natural_Images.html">25 nips-2004-Assignment of Multiplicative Mixtures in Natural Images</a></p>
<p>14 0.44988689 <a title="192-lsi-14" href="./nips-2004-A_Topographic_Support_Vector_Machine%3A_Classification_Using_Local_Label_Configurations.html">14 nips-2004-A Topographic Support Vector Machine: Classification Using Local Label Configurations</a></p>
<p>15 0.43031946 <a title="192-lsi-15" href="./nips-2004-Modeling_Nonlinear_Dependencies_in_Natural_Images_using_Mixture_of_Laplacian_Distribution.html">121 nips-2004-Modeling Nonlinear Dependencies in Natural Images using Mixture of Laplacian Distribution</a></p>
<p>16 0.42918935 <a title="192-lsi-16" href="./nips-2004-Who%27s_In_the_Picture.html">205 nips-2004-Who's In the Picture</a></p>
<p>17 0.41073588 <a title="192-lsi-17" href="./nips-2004-A_Three_Tiered_Approach_for_Articulated_Object_Action_Modeling_and_Recognition.html">13 nips-2004-A Three Tiered Approach for Articulated Object Action Modeling and Recognition</a></p>
<p>18 0.40413713 <a title="192-lsi-18" href="./nips-2004-Implicit_Wiener_Series_for_Higher-Order_Image_Analysis.html">81 nips-2004-Implicit Wiener Series for Higher-Order Image Analysis</a></p>
<p>19 0.39444184 <a title="192-lsi-19" href="./nips-2004-Seeing_through_water.html">160 nips-2004-Seeing through water</a></p>
<p>20 0.38837609 <a title="192-lsi-20" href="./nips-2004-Discriminant_Saliency_for_Visual_Recognition_from_Cluttered_Scenes.html">53 nips-2004-Discriminant Saliency for Visual Recognition from Cluttered Scenes</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2004_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(9, 0.011), (15, 0.112), (26, 0.021), (27, 0.035), (30, 0.022), (37, 0.111), (43, 0.184), (51, 0.021), (74, 0.171), (77, 0.112), (81, 0.027), (96, 0.042)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.86220229 <a title="192-lda-1" href="./nips-2004-The_power_of_feature_clustering%3A_An_application_to_object_detection.html">192 nips-2004-The power of feature clustering: An application to object detection</a></p>
<p>2 0.82546681 <a title="192-lda-2" href="./nips-2004-Distributed_Occlusion_Reasoning_for_Tracking_with_Nonparametric_Belief_Propagation.html">55 nips-2004-Distributed Occlusion Reasoning for Tracking with Nonparametric Belief Propagation</a></p>
<p>3 0.78804612 <a title="192-lda-3" href="./nips-2004-Assignment_of_Multiplicative_Mixtures_in_Natural_Images.html">25 nips-2004-Assignment of Multiplicative Mixtures in Natural Images</a></p>
<p>4 0.78674906 <a title="192-lda-4" href="./nips-2004-Joint_Probabilistic_Curve_Clustering_and_Alignment.html">90 nips-2004-Joint Probabilistic Curve Clustering and Alignment</a></p>
<p>5 0.78442544 <a title="192-lda-5" href="./nips-2004-Spike_Sorting%3A_Bayesian_Clustering_of_Non-Stationary_Data.html">174 nips-2004-Spike Sorting: Bayesian Clustering of Non-Stationary Data</a></p>
<p>6 0.78403926 <a title="192-lda-6" href="./nips-2004-A_Three_Tiered_Approach_for_Articulated_Object_Action_Modeling_and_Recognition.html">13 nips-2004-A Three Tiered Approach for Articulated Object Action Modeling and Recognition</a></p>
<p>7 0.78323984 <a title="192-lda-7" href="./nips-2004-Learning_Hyper-Features_for_Visual_Identification.html">99 nips-2004-Learning Hyper-Features for Visual Identification</a></p>
<p>8 0.77903789 <a title="192-lda-8" href="./nips-2004-Synergistic_Face_Detection_and_Pose_Estimation_with_Energy-Based_Models.html">182 nips-2004-Synergistic Face Detection and Pose Estimation with Energy-Based Models</a></p>
<p>9 0.77872902 <a title="192-lda-9" href="./nips-2004-Multiple_Alignment_of_Continuous_Time_Series.html">124 nips-2004-Multiple Alignment of Continuous Time Series</a></p>
<p>10 0.77757084 <a title="192-lda-10" href="./nips-2004-Hierarchical_Eigensolver_for_Transition_Matrices_in_Spectral_Methods.html">79 nips-2004-Hierarchical Eigensolver for Transition Matrices in Spectral Methods</a></p>
<p>11 0.77662891 <a title="192-lda-11" href="./nips-2004-A_Harmonic_Excitation_State-Space_Approach_to_Blind_Separation_of_Speech.html">5 nips-2004-A Harmonic Excitation State-Space Approach to Blind Separation of Speech</a></p>
<p>12 0.77412379 <a title="192-lda-12" href="./nips-2004-Exponential_Family_Harmoniums_with_an_Application_to_Information_Retrieval.html">66 nips-2004-Exponential Family Harmoniums with an Application to Information Retrieval</a></p>
<p>13 0.77323723 <a title="192-lda-13" href="./nips-2004-Adaptive_Discriminative_Generative_Model_and_Its_Applications.html">16 nips-2004-Adaptive Discriminative Generative Model and Its Applications</a></p>
<p>14 0.76989603 <a title="192-lda-14" href="./nips-2004-An_Information_Maximization_Model_of_Eye_Movements.html">21 nips-2004-An Information Maximization Model of Eye Movements</a></p>
<p>15 0.76765829 <a title="192-lda-15" href="./nips-2004-Semi-supervised_Learning_with_Penalized_Probabilistic_Clustering.html">167 nips-2004-Semi-supervised Learning with Penalized Probabilistic Clustering</a></p>
<p>16 0.76666677 <a title="192-lda-16" href="./nips-2004-Conditional_Random_Fields_for_Object_Recognition.html">44 nips-2004-Conditional Random Fields for Object Recognition</a></p>
<p>17 0.76605606 <a title="192-lda-17" href="./nips-2004-Generative_Affine_Localisation_and_Tracking.html">73 nips-2004-Generative Affine Localisation and Tracking</a></p>
<p>18 0.76493353 <a title="192-lda-18" href="./nips-2004-Incremental_Learning_for_Visual_Tracking.html">83 nips-2004-Incremental Learning for Visual Tracking</a></p>
<p>19 0.76402551 <a title="192-lda-19" href="./nips-2004-Common-Frame_Model_for_Object_Recognition.html">40 nips-2004-Common-Frame Model for Object Recognition</a></p>
<p>20 0.76179987 <a title="192-lda-20" href="./nips-2004-Discriminant_Saliency_for_Visual_Recognition_from_Cluttered_Scenes.html">53 nips-2004-Discriminant Saliency for Visual Recognition from Cluttered Scenes</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
