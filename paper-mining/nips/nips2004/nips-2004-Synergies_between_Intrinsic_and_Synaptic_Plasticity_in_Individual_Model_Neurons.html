<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>181 nips-2004-Synergies between Intrinsic and Synaptic Plasticity in Individual Model Neurons</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2004" href="../home/nips2004_home.html">nips2004</a> <a title="nips-2004-181" href="#">nips2004-181</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>181 nips-2004-Synergies between Intrinsic and Synaptic Plasticity in Individual Model Neurons</h1>
<br/><p>Source: <a title="nips-2004-181-pdf" href="http://papers.nips.cc/paper/2731-synergies-between-intrinsic-and-synaptic-plasticity-in-individual-model-neurons.pdf">pdf</a></p><p>Author: Jochen Triesch</p><p>Abstract: This paper explores the computational consequences of simultaneous intrinsic and synaptic plasticity in individual model neurons. It proposes a new intrinsic plasticity mechanism for a continuous activation model neuron based on low order moments of the neuron’s ﬁring rate distribution. The goal of the intrinsic plasticity mechanism is to enforce a sparse distribution of the neuron’s activity level. In conjunction with Hebbian learning at the neuron’s synapses, the neuron is shown to discover sparse directions in the input. 1</p><p>Reference: <a title="nips-2004-181-reference" href="../nips2004_reference/nips-2004-Synergies_between_Intrinsic_and_Synaptic_Plasticity_in_Individual_Model_Neurons_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract This paper explores the computational consequences of simultaneous intrinsic and synaptic plasticity in individual model neurons. [sent-3, score-1.217]
</p><p>2 It proposes a new intrinsic plasticity mechanism for a continuous activation model neuron based on low order moments of the neuron’s ﬁring rate distribution. [sent-4, score-1.501]
</p><p>3 The goal of the intrinsic plasticity mechanism is to enforce a sparse distribution of the neuron’s activity level. [sent-5, score-1.293]
</p><p>4 In conjunction with Hebbian learning at the neuron’s synapses, the neuron is shown to discover sparse directions in the input. [sent-6, score-0.427]
</p><p>5 In particular, neurons in different visual cortical areas show an approximately exponential distribution of their ﬁring rates in response to stimulation with natural video sequences [1]. [sent-8, score-0.425]
</p><p>6 Several different mechanisms seem to play a role: First, synaptic learning can change a neuron’s response to a distribution of inputs. [sent-13, score-0.29]
</p><p>7 Second, intrinsic learning may change conductances in the dendrites and soma to adapt the distribution of ﬁring rates [7]. [sent-14, score-0.68]
</p><p>8 This paper investigates the interaction of intrinsic and synaptic learning processes in individual model neurons in the learning of sparse codes. [sent-18, score-0.9]
</p><p>9 We consider an individual continuous activation model neuron with a non-linear transfer function that has adjustable parameters. [sent-19, score-0.67]
</p><p>10 We are proposing a simple intrinsic learning mechanism based on estimates of low-order moments of the activity distribution that allows the model neuron to adjust the parameters of its non-linear transfer function to obtain an approximately exponential distribution of its activity. [sent-20, score-1.521]
</p><p>11 We then show that if combined with a standard Hebbian learning rule employing multiplicative weight normalization, this leads to the extraction of sparse features from the input. [sent-21, score-0.346]
</p><p>12 This is in sharp contrast to standard Hebbian learning in linear units with multiplicative weight normalization, which leads to  the extraction of the principal Eigenvector of the input correlation matrix. [sent-22, score-0.255]
</p><p>13 We demonstrate the behavior of the combined intrinsic and synaptic learning mechanisms on the classic bars problem [4], a non-linear independent component analysis problem. [sent-23, score-0.874]
</p><p>14 Section 2 introduces our scheme for intrinsic plasticity and presents experiments demonstrating the effectiveness of the proposed mechanism for inducing a sparse ﬁring rate distribution. [sent-25, score-1.245]
</p><p>15 Section 3 studies the combination of intrinsic plasticity with Hebbian learning at the synapses and demonstrates how it gives rise to the discovery of sparse directions in the input. [sent-26, score-1.125]
</p><p>16 2  Intrinsic Plasticity Mechanism  Biological neurons do not only adapt synaptic properties but also change their excitability through the modiﬁcation of voltage gated channels. [sent-29, score-0.413]
</p><p>17 Such intrinsic plasticity has been observed across many species and brain areas [9]. [sent-30, score-0.92]
</p><p>18 Although our understanding of these processes and their underlying mechanisms remains quite unclear, it has been hypothesized that this form of plasticity contributes to a neuron’s homeostasis of its mean ﬁring rate level. [sent-31, score-0.616]
</p><p>19 Our basic hypothesis is that the goal of intrinsic plasticity is to ensure an approximately exponential distribution of ﬁring rate levels in individual neurons. [sent-32, score-1.295]
</p><p>20 A learning rule was derived that adapts the properties of voltage gated channels to match the ﬁring rate distribution of the unit to a desired distribution. [sent-34, score-0.421]
</p><p>21 In order to facilitate the simulation of potentially large networks we choose a different, more abstract level of modeling employing a continuous activation unit with a non-linear transfer function. [sent-35, score-0.463]
</p><p>22 Our model neuron is described by: Y = Sθ (X) ,  X = wT u ,  (1)  where Y is the neuron’s output (ﬁring rate), X is the neuron’s total synaptic current, w is the neuron’s weight vector representing synaptic strengths, the vector u represents the pre-synaptic input, and Sθ (. [sent-36, score-0.797]
</p><p>23 ) is the neuron’s non-linear transfer function (activation function), parameterized by a vector of parameters θ. [sent-37, score-0.272]
</p><p>24 In this section we will not be concerned with synaptic mechanism changing the weight vector w, so we will just consider a particular distribution p(X = x) ≡ p(x) of the net synaptic current and consider the resulting distribution of ﬁring rates p(Y = y) ≡ p(y). [sent-38, score-0.754]
</p><p>25 Intrinsic plasticity is modeled as inducing changes to the non-linear transfer function with the goal of bringing the distribution of activity levels p(y) close to an exponential distribution. [sent-39, score-1.039]
</p><p>26 Given a signal with a certain distribution, ﬁnd a non-linear transfer function that converts the signal to one with a desired distribution. [sent-41, score-0.38]
</p><p>27 In particular, it requires that the individual neuron can change its nonlinear transfer function arbitrarily, i. [sent-46, score-0.526]
</p><p>28 Since the non-linearity has only two degrees of freedom it is generally not possible to ascertain an exponential activity distribution for an arbitrary input distribution. [sent-53, score-0.322]
</p><p>29 A plausible alternative goal is to just match low order moments of the activity distribution to those of a speciﬁc target distribution. [sent-54, score-0.255]
</p><p>30 The mean µ of the desired exponential distribution is a free parameter which may vary across cortical areas. [sent-59, score-0.329]
</p><p>31 2  Experiments with Intrinsic Plasticity Mechanism  We tested the proposed intrinsic plasticity mechanism for a number of distributions of the synaptic current X (Fig. [sent-66, score-1.222]
</p><p>32 Panel b compares the theoretically optimal transfer function (dotted), which would lead to an exactly exponential distribution of Y , with the learned sigmoidal transfer function (solid). [sent-77, score-0.707]
</p><p>33 The learned transfer function gives a very good ﬁt. [sent-78, score-0.269]
</p><p>34 The resulting distribution of Y is in fact very close to the desired exponential distribution. [sent-79, score-0.262]
</p><p>35 For the general case of a Gaussian input distribution with mean µG and standard deviation σG , the sigmoid parameters will converge to a → a∞ σG and b → b∞ σG + µG under the intrinsic plasticity rule. [sent-80, score-1.202]
</p><p>36 If the input to the unit can be assumed to be Gaussian, this relation can be used to calculate the desired parameters of the sigmoid non-linearity directly. [sent-81, score-0.377]
</p><p>37 In general, however, intrinsic plasticity may give rise to non-linear changes that cannot be captured by such a linear re-scaling of all weights. [sent-83, score-0.954]
</p><p>38 a  b  10  1  8  input distribution optimal transfer fct. [sent-84, score-0.354]
</p><p>39 2  0 0  1  2  3  4  0 −4  5  −2  0  2  4  a  c  d  input distribution optimal transfer fct. [sent-90, score-0.354]
</p><p>40 8  1  Figure 1: Dynamics of intrinsic plasticity mechanism for various input distributions. [sent-110, score-1.102]
</p><p>41 Panel b shows the optimal (dotted) and learned transfer function (solid). [sent-116, score-0.269]
</p><p>42 Panels c and d show the result of intrinsic plasticity for two other input distributions. [sent-121, score-0.982]
</p><p>43 In the case of a uniform input distribution in the interval [0, 1] (panel c) the optimal transfer function becomes inﬁnitely steep for x → 1. [sent-122, score-0.354]
</p><p>44 For an exponentially distributed input (panel d), the ideal transfer function would simply be the identity function. [sent-123, score-0.302]
</p><p>45 In both cases the intrinsic plasticity mechanism adjusts the sigmoid non-linearity in a sensible fashion and the output distribution is a fair approximation of the desired exponential distribution. [sent-124, score-1.516]
</p><p>46 3  Discussion of the Intrinsic Plasticity Mechanism  The proposed mechanism for intrinsic plasticity is effective in driving a neuron to exhibit an approximately exponential distribution of ﬁring rates as observed in biological neurons in the visual system. [sent-126, score-1.684]
</p><p>47 The same adaptation mechanism can also be used in conjunction with, say, an adjustable threshold-linear activation function. [sent-128, score-0.301]
</p><p>48 An interesting alternative to the proposed mechanism can be derived by directly minimizing the KL divergence between the output distribution and the desired exponential distribution through stochastic gradient descent. [sent-129, score-0.466]
</p><p>49 The resulting learning rule, which is closely related to a rule for adapting a sigmoid nonlinearity to max-  imize the output entropy derived by Bell and Sejnowski[2], will be discussed elsewhere. [sent-130, score-0.235]
</p><p>50 A speciﬁc, testable prediction of the simple model is that changes to the distribution of a neuron’s ﬁring rate levels that keep the average ﬁring rate of the neuron unchanged but alter the second moment of the ﬁring rate distribution should lead to measurable changes in the neuron’s excitability. [sent-134, score-0.62]
</p><p>51 3  Combination of Intrinsic and Synaptic Plasticity  In this Section we want to study the effects of simultaneous intrinsic and synaptic learning for an individual model neuron. [sent-135, score-0.769]
</p><p>52 In principle, any Hebbian learning rule can be combined with our scheme for intrinsic plasticity. [sent-137, score-0.538]
</p><p>53 We simply adopt a multiplicative normalization scheme that after each update re-scales the weight vector to unit length: w ← w/|| w ||. [sent-141, score-0.332]
</p><p>54 1  Analysis for the Limiting Case of Fast Intrinsic Plasticity  Under a few assumptions, an interesting intuition about the simultaneous intrinsic and Hebbian learning can be gained. [sent-143, score-0.526]
</p><p>55 Consider the limit of intrinsic plasticity being much faster than Hebbian plasticity. [sent-144, score-0.92]
</p><p>56 In this case we may assume that the non-linearity has adapted to give an approximately exponential distribution of the ﬁring rate Y before w can change much. [sent-146, score-0.291]
</p><p>57 Thus, from (6), ∆w can be seen as a weighted sum of the inputs u, with the activities Y acting as weights that follow an approximately exponential distribution. [sent-147, score-0.273]
</p><p>58 Since similar inputs u will produce similar outputs Y , the expected value of the weight update ∆w will be dominated by a small set of inputs that produce the highest output activities. [sent-148, score-0.25]
</p><p>59 The remainder of the inputs will “pull” the weight vector back to the average input u . [sent-149, score-0.281]
</p><p>60 Due to the multiplicative weight normalization, the stationary states of the weight vector are reached if ∆w is parallel to w, i. [sent-150, score-0.356]
</p><p>61 A simple example shall illustrate the effect of intrinsic plasticity on Hebbian learning in more detail. [sent-153, score-0.92]
</p><p>62 If the weight vector is slightly closer to one of the two clusters, inputs from this cluster will activate the unit more strongly and will exert a stronger “pull” on the weight vector. [sent-156, score-0.468]
</p><p>63 Let m = µ ln(2) denote the median of the exponential ﬁring rate distribution with mean µ. [sent-157, score-0.255]
</p><p>64 Then inputs from the closer cluster, say c1 , will be responsible for all activities above m while the inputs from the other cluster will be responsible for all activities below m. [sent-158, score-0.274]
</p><p>65 (9) || (1 ± ln 2)c1 + (1 ln 2)c2 || The weight vector moves close to one of the two clusters but does not fully commit to it. [sent-163, score-0.296]
</p><p>66 For the general case of N input clusters, only a few clusters will strongly contribute to the ﬁnal weight vector. [sent-164, score-0.247]
</p><p>67 Generalizing the result from above, it is not difﬁcult to derive that the weight vector w will be proportional to a weighted sum of the cluster centers: N  fi ci ; with fi = 1 + log(N ) − i log(i) + (i − 1) log(i − 1) ,  w∝  (10)  i=1  where we deﬁne 0 log(0) ≡ 0. [sent-165, score-0.378]
</p><p>68 Here, fi denotes the relative contribution of the i-th closest input cluster to the ﬁnal weight vector. [sent-166, score-0.316]
</p><p>69 Note that the ﬁnal weight vector does not depend on the desired mean activity level µ. [sent-169, score-0.355]
</p><p>70 2 plots (10) for N = 1000 (left) and shows that the resulting distribution of the fi is approximately exponential (right). [sent-171, score-0.327]
</p><p>71 We can see why such a weight vector may correspond to a sparse direction in the input space as follows: consider the case where the input cluster centers are random vectors of unit length in a high-dimensional space. [sent-172, score-0.515]
</p><p>72 i If we consider the projection of an input from an arbitrary cluster, say cj , onto the weight T T vector, we see that wT cj ∝ i fi ci cj ≈ fj . [sent-174, score-0.389]
</p><p>73 The distribution of X = w u follows the distribution of the fi , which is approximately exponential. [sent-175, score-0.261]
</p><p>74 Thus, the projection of all inputs onto the weight vector has an approximately exponential distribution. [sent-176, score-0.38]
</p><p>75 It is interesting to note that in this situation the optimal transfer function S ∗ that will make the unit’s activity Y have an exponential distribution of a desired mean µ is simply a multiplication with a constant k, i. [sent-178, score-0.621]
</p><p>76 Thus, depending on the initial weight vector and the resulting distribution of X, the neuron’s activation function may transiently adapt to enforce an approximately exponential ﬁring rate distribution, but the simultaneous Hebbian learning drives it back to a linear form. [sent-181, score-0.642]
</p><p>77 In the end, a simple linear activation function may result from this interplay of intrinsic and synaptic plasticity. [sent-182, score-0.747]
</p><p>78 In fact, the observation of approximately linear activation functions in cortical neurons is not uncommon. [sent-183, score-0.292]
</p><p>79 We have trained an individual sigmoidal model neuron on the bars input domain. [sent-208, score-0.517]
</p><p>80 The theoretical analysis above assumed that intrinsic plasticity is much faster than synaptic plasticity. [sent-209, score-1.102]
</p><p>81 Here, we set the intrinsic plasticity to be slower than the synaptic plasticity, which is more plausible biologically, to see if this may still allow the discovery of sparse directions in the input. [sent-210, score-1.3]
</p><p>82 3 (right) the unit’s weight vector aligns with one of the individual bars as soon as the intrinsic plasticity has pushed the model neuron into a regime where its responses are sparse: the unit has discovered one of the independent sources of the input domain. [sent-212, score-1.708]
</p><p>83 This result is robust if the desired mean activity µ of the unit is changed over a wide range. [sent-213, score-0.295]
</p><p>84 15, the unit will fail to represent an individual bar but will learn a mixture of two or more bars, with different bars being represented with different strengths. [sent-217, score-0.343]
</p><p>85 Thus, in this example — in contrast to the theoretical result above — the desired mean activity µ does inﬂuence the weight vector that is being learned. [sent-218, score-0.355]
</p><p>86 The reason for this is that the intrinsic plasticity only imperfectly adjusts the output distribution to the desired exponential shape. [sent-219, score-1.257]
</p><p>87 For low µ, only the highest mode, which corresponds to a speciﬁc single bar presented in isolation, contributes strongly to the weight vector. [sent-222, score-0.221]
</p><p>88 While the plasticity of a neuron’s synapses has always been a core topic of neural computation research, there has been little work investigating the computational properties of intrinsic plasticity mechanisms and  the relation between intrinsic and synaptic learning. [sent-224, score-2.111]
</p><p>89 This paper has investigated the potential role of intrinsic learning mechanisms operating at the soma when used in conjunction with Hebbian learning at the synapses. [sent-225, score-0.597]
</p><p>90 To this end, we have proposed a new intrinsic plasticity mechanism that adjusts the parameters of a sigmoid nonlinearity to move the neuron’s ﬁring rate distribution to a sparse regime. [sent-226, score-1.443]
</p><p>91 The learning mechanism is effective in producing approximately exponential ﬁring rate distributions as observed in neurons in the visual system of cats and primates. [sent-227, score-0.489]
</p><p>92 Studying simultaneous intrinsic and synaptic learning, we found a synergistic relation between the two. [sent-228, score-0.708]
</p><p>93 We demonstrated how the two mechanisms may cooperate to discover sparse directions in the input. [sent-229, score-0.221]
</p><p>94 When applied to the classic “bars” problem, a single unit was shown to discover one of the independent sources as soon as the intrinsic plasticity moved the unit’s activity distribution into a sparse regime. [sent-230, score-1.332]
</p><p>95 In such approaches, the “standard” Hebbian weight update rule is modiﬁed to allow the discovery of non-gaussian directions in the input. [sent-234, score-0.235]
</p><p>96 We have shown that the combination of intrinsic plasticity with the standard Hebbian learning rule can be sufﬁcient for the discovery of sparse directions in the input. [sent-235, score-1.132]
</p><p>97 Future work will analyze the combination of intrinsic plasticity with other Hebbian learning rules. [sent-236, score-0.92]
</p><p>98 The nonlinear nature of the transfer function may facilitate the construction of hierarchical networks for unsupervised learning. [sent-238, score-0.262]
</p><p>99 It will also be interesting to study the effects of intrinsic plasticity in the context of recurrent networks, where it may contribute to keeping the network in a certain desired dynamic regime. [sent-239, score-1.012]
</p><p>100 The other side of the engram: Experience-driven changes in neuronal intrinsic excitability. [sent-302, score-0.529]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('intrinsic', 0.472), ('plasticity', 0.448), ('hebbian', 0.245), ('transfer', 0.24), ('ring', 0.225), ('neuron', 0.225), ('synaptic', 0.182), ('bars', 0.141), ('sigmoid', 0.139), ('mechanism', 0.12), ('exponential', 0.118), ('weight', 0.112), ('neurons', 0.096), ('activation', 0.093), ('desired', 0.092), ('fi', 0.092), ('activity', 0.09), ('sparse', 0.089), ('moments', 0.087), ('unit', 0.084), ('approximately', 0.065), ('conductances', 0.064), ('input', 0.062), ('individual', 0.061), ('panel', 0.059), ('bar', 0.057), ('mechanisms', 0.056), ('rate', 0.056), ('gated', 0.056), ('simultaneous', 0.054), ('inputs', 0.053), ('stationary', 0.052), ('distribution', 0.052), ('ln', 0.052), ('adjustable', 0.051), ('mt', 0.05), ('cluster', 0.05), ('directions', 0.049), ('multiplicative', 0.048), ('clusters', 0.048), ('frankfurt', 0.043), ('nullclines', 0.043), ('triesch', 0.043), ('adjusts', 0.043), ('ica', 0.042), ('cj', 0.041), ('voltage', 0.041), ('rule', 0.04), ('adapt', 0.038), ('cortical', 0.038), ('pull', 0.037), ('conjunction', 0.037), ('activities', 0.037), ('changes', 0.034), ('inducing', 0.034), ('discovery', 0.034), ('visual', 0.034), ('synapses', 0.033), ('extraction', 0.033), ('vector', 0.032), ('output', 0.032), ('soma', 0.032), ('moment', 0.032), ('biological', 0.032), ('wt', 0.03), ('normalization', 0.03), ('mean', 0.029), ('learned', 0.029), ('sigmoidal', 0.028), ('unclear', 0.028), ('dy', 0.027), ('contributes', 0.027), ('discover', 0.027), ('dotted', 0.027), ('plausible', 0.026), ('scheme', 0.026), ('sources', 0.025), ('strongly', 0.025), ('passed', 0.024), ('intersection', 0.024), ('centers', 0.024), ('employing', 0.024), ('responses', 0.024), ('signal', 0.024), ('bell', 0.024), ('trajectories', 0.024), ('nonlinearity', 0.024), ('levels', 0.023), ('blind', 0.023), ('neuronal', 0.023), ('classic', 0.023), ('numerically', 0.023), ('formation', 0.023), ('soon', 0.022), ('facilitate', 0.022), ('enforce', 0.022), ('limiting', 0.022), ('rates', 0.022), ('responsible', 0.022), ('remainder', 0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999952 <a title="181-tfidf-1" href="./nips-2004-Synergies_between_Intrinsic_and_Synaptic_Plasticity_in_Individual_Model_Neurons.html">181 nips-2004-Synergies between Intrinsic and Synaptic Plasticity in Individual Model Neurons</a></p>
<p>Author: Jochen Triesch</p><p>Abstract: This paper explores the computational consequences of simultaneous intrinsic and synaptic plasticity in individual model neurons. It proposes a new intrinsic plasticity mechanism for a continuous activation model neuron based on low order moments of the neuron’s ﬁring rate distribution. The goal of the intrinsic plasticity mechanism is to enforce a sparse distribution of the neuron’s activity level. In conjunction with Hebbian learning at the neuron’s synapses, the neuron is shown to discover sparse directions in the input. 1</p><p>2 0.2478984 <a title="181-tfidf-2" href="./nips-2004-Rate-_and_Phase-coded_Autoassociative_Memory.html">151 nips-2004-Rate- and Phase-coded Autoassociative Memory</a></p>
<p>Author: Máté Lengyel, Peter Dayan</p><p>Abstract: Areas of the brain involved in various forms of memory exhibit patterns of neural activity quite unlike those in canonical computational models. We show how to use well-founded Bayesian probabilistic autoassociative recall to derive biologically reasonable neuronal dynamics in recurrently coupled models, together with appropriate values for parameters such as the membrane time constant and inhibition. We explicitly treat two cases. One arises from a standard Hebbian learning rule, and involves activity patterns that are coded by graded ﬁring rates. The other arises from a spike timing dependent learning rule, and involves patterns coded by the phase of spike times relative to a coherent local ﬁeld potential oscillation. Our model offers a new and more complete understanding of how neural dynamics may support autoassociation. 1</p><p>3 0.23420294 <a title="181-tfidf-3" href="./nips-2004-Reducing_Spike_Train_Variability%3A_A_Computational_Theory_Of_Spike-Timing_Dependent_Plasticity.html">153 nips-2004-Reducing Spike Train Variability: A Computational Theory Of Spike-Timing Dependent Plasticity</a></p>
<p>Author: Sander M. Bohte, Michael C. Mozer</p><p>Abstract: Experimental studies have observed synaptic potentiation when a presynaptic neuron ﬁres shortly before a postsynaptic neuron, and synaptic depression when the presynaptic neuron ﬁres shortly after. The dependence of synaptic modulation on the precise timing of the two action potentials is known as spike-timing dependent plasticity or STDP. We derive STDP from a simple computational principle: synapses adapt so as to minimize the postsynaptic neuron’s variability to a given presynaptic input, causing the neuron’s output to become more reliable in the face of noise. Using an entropy-minimization objective function and the biophysically realistic spike-response model of Gerstner (2001), we simulate neurophysiological experiments and obtain the characteristic STDP curve along with other phenomena including the reduction in synaptic plasticity as synaptic eﬃcacy increases. We compare our account to other eﬀorts to derive STDP from computational principles, and argue that our account provides the most comprehensive coverage of the phenomena. Thus, reliability of neural response in the face of noise may be a key goal of cortical adaptation. 1</p><p>4 0.20002542 <a title="181-tfidf-4" href="./nips-2004-Hierarchical_Bayesian_Inference_in_Networks_of_Spiking_Neurons.html">76 nips-2004-Hierarchical Bayesian Inference in Networks of Spiking Neurons</a></p>
<p>Author: Rajesh P. Rao</p><p>Abstract: There is growing evidence from psychophysical and neurophysiological studies that the brain utilizes Bayesian principles for inference and decision making. An important open question is how Bayesian inference for arbitrary graphical models can be implemented in networks of spiking neurons. In this paper, we show that recurrent networks of noisy integrate-and-ﬁre neurons can perform approximate Bayesian inference for dynamic and hierarchical graphical models. The membrane potential dynamics of neurons is used to implement belief propagation in the log domain. The spiking probability of a neuron is shown to approximate the posterior probability of the preferred state encoded by the neuron, given past inputs. We illustrate the model using two examples: (1) a motion detection network in which the spiking probability of a direction-selective neuron becomes proportional to the posterior probability of motion in a preferred direction, and (2) a two-level hierarchical network that produces attentional effects similar to those observed in visual cortical areas V2 and V4. The hierarchical model offers a new Bayesian interpretation of attentional modulation in V2 and V4. 1</p><p>5 0.18307896 <a title="181-tfidf-5" href="./nips-2004-Maximum_Likelihood_Estimation_of_Intrinsic_Dimension.html">114 nips-2004-Maximum Likelihood Estimation of Intrinsic Dimension</a></p>
<p>Author: Elizaveta Levina, Peter J. Bickel</p><p>Abstract: We propose a new method for estimating intrinsic dimension of a dataset derived by applying the principle of maximum likelihood to the distances between close neighbors. We derive the estimator by a Poisson process approximation, assess its bias and variance theoretically and by simulations, and apply it to a number of simulated and real datasets. We also show it has the best overall performance compared with two other intrinsic dimension estimators. 1</p><p>6 0.16062321 <a title="181-tfidf-6" href="./nips-2004-Bayesian_inference_in_spiking_neurons.html">28 nips-2004-Bayesian inference in spiking neurons</a></p>
<p>7 0.15833148 <a title="181-tfidf-7" href="./nips-2004-Optimal_Information_Decoding_from_Neuronal_Populations_with_Specific_Stimulus_Selectivity.html">140 nips-2004-Optimal Information Decoding from Neuronal Populations with Specific Stimulus Selectivity</a></p>
<p>8 0.15492415 <a title="181-tfidf-8" href="./nips-2004-Theory_of_localized_synfire_chain%3A_characteristic_propagation_speed_of_stable_spike_pattern.html">194 nips-2004-Theory of localized synfire chain: characteristic propagation speed of stable spike pattern</a></p>
<p>9 0.13256253 <a title="181-tfidf-9" href="./nips-2004-Spike-timing_Dependent_Plasticity_and_Mutual_Information_Maximization_for_a_Spiking_Neuron_Model.html">173 nips-2004-Spike-timing Dependent Plasticity and Mutual Information Maximization for a Spiking Neuron Model</a></p>
<p>10 0.11548892 <a title="181-tfidf-10" href="./nips-2004-Maximising_Sensitivity_in_a_Spiking_Network.html">112 nips-2004-Maximising Sensitivity in a Spiking Network</a></p>
<p>11 0.11391422 <a title="181-tfidf-11" href="./nips-2004-Intrinsically_Motivated_Reinforcement_Learning.html">88 nips-2004-Intrinsically Motivated Reinforcement Learning</a></p>
<p>12 0.10948468 <a title="181-tfidf-12" href="./nips-2004-Methods_for_Estimating_the_Computational_Power_and_Generalization_Capability_of_Neural_Microcircuits.html">118 nips-2004-Methods for Estimating the Computational Power and Generalization Capability of Neural Microcircuits</a></p>
<p>13 0.10771079 <a title="181-tfidf-13" href="./nips-2004-Saliency-Driven_Image_Acuity_Modulation_on_a_Reconfigurable_Array_of_Spiking_Silicon_Neurons.html">157 nips-2004-Saliency-Driven Image Acuity Modulation on a Reconfigurable Array of Spiking Silicon Neurons</a></p>
<p>14 0.074441411 <a title="181-tfidf-14" href="./nips-2004-At_the_Edge_of_Chaos%3A_Real-time_Computations_and_Self-Organized_Criticality_in_Recurrent_Neural_Networks.html">26 nips-2004-At the Edge of Chaos: Real-time Computations and Self-Organized Criticality in Recurrent Neural Networks</a></p>
<p>15 0.06956549 <a title="181-tfidf-15" href="./nips-2004-Inference%2C_Attention%2C_and_Decision_in_a_Bayesian_Neural_Architecture.html">84 nips-2004-Inference, Attention, and Decision in a Bayesian Neural Architecture</a></p>
<p>16 0.066902041 <a title="181-tfidf-16" href="./nips-2004-Sparse_Coding_of_Natural_Images_Using_an_Overcomplete_Set_of_Limited_Capacity_Units.html">172 nips-2004-Sparse Coding of Natural Images Using an Overcomplete Set of Limited Capacity Units</a></p>
<p>17 0.06669239 <a title="181-tfidf-17" href="./nips-2004-Unsupervised_Variational_Bayesian_Learning_of_Nonlinear_Models.html">198 nips-2004-Unsupervised Variational Bayesian Learning of Nonlinear Models</a></p>
<p>18 0.059806153 <a title="181-tfidf-18" href="./nips-2004-Brain_Inspired_Reinforcement_Learning.html">33 nips-2004-Brain Inspired Reinforcement Learning</a></p>
<p>19 0.058665805 <a title="181-tfidf-19" href="./nips-2004-A_Method_for_Inferring_Label_Sampling_Mechanisms_in_Semi-Supervised_Learning.html">9 nips-2004-A Method for Inferring Label Sampling Mechanisms in Semi-Supervised Learning</a></p>
<p>20 0.055099782 <a title="181-tfidf-20" href="./nips-2004-Edge_of_Chaos_Computation_in_Mixed-Mode_VLSI_-_A_Hard_Liquid.html">58 nips-2004-Edge of Chaos Computation in Mixed-Mode VLSI - A Hard Liquid</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2004_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.199), (1, -0.317), (2, -0.083), (3, 0.029), (4, 0.004), (5, 0.084), (6, -0.035), (7, 0.019), (8, -0.023), (9, 0.075), (10, 0.053), (11, -0.075), (12, 0.028), (13, -0.105), (14, -0.077), (15, -0.003), (16, -0.188), (17, 0.017), (18, -0.065), (19, -0.007), (20, 0.102), (21, 0.049), (22, 0.132), (23, -0.038), (24, -0.102), (25, 0.01), (26, 0.126), (27, -0.092), (28, -0.053), (29, 0.054), (30, -0.108), (31, 0.082), (32, 0.024), (33, 0.018), (34, -0.072), (35, -0.17), (36, -0.028), (37, 0.047), (38, -0.084), (39, -0.047), (40, 0.007), (41, 0.085), (42, 0.003), (43, -0.086), (44, -0.038), (45, -0.011), (46, 0.098), (47, -0.025), (48, -0.024), (49, -0.072)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97535008 <a title="181-lsi-1" href="./nips-2004-Synergies_between_Intrinsic_and_Synaptic_Plasticity_in_Individual_Model_Neurons.html">181 nips-2004-Synergies between Intrinsic and Synaptic Plasticity in Individual Model Neurons</a></p>
<p>Author: Jochen Triesch</p><p>Abstract: This paper explores the computational consequences of simultaneous intrinsic and synaptic plasticity in individual model neurons. It proposes a new intrinsic plasticity mechanism for a continuous activation model neuron based on low order moments of the neuron’s ﬁring rate distribution. The goal of the intrinsic plasticity mechanism is to enforce a sparse distribution of the neuron’s activity level. In conjunction with Hebbian learning at the neuron’s synapses, the neuron is shown to discover sparse directions in the input. 1</p><p>2 0.71003181 <a title="181-lsi-2" href="./nips-2004-Reducing_Spike_Train_Variability%3A_A_Computational_Theory_Of_Spike-Timing_Dependent_Plasticity.html">153 nips-2004-Reducing Spike Train Variability: A Computational Theory Of Spike-Timing Dependent Plasticity</a></p>
<p>Author: Sander M. Bohte, Michael C. Mozer</p><p>Abstract: Experimental studies have observed synaptic potentiation when a presynaptic neuron ﬁres shortly before a postsynaptic neuron, and synaptic depression when the presynaptic neuron ﬁres shortly after. The dependence of synaptic modulation on the precise timing of the two action potentials is known as spike-timing dependent plasticity or STDP. We derive STDP from a simple computational principle: synapses adapt so as to minimize the postsynaptic neuron’s variability to a given presynaptic input, causing the neuron’s output to become more reliable in the face of noise. Using an entropy-minimization objective function and the biophysically realistic spike-response model of Gerstner (2001), we simulate neurophysiological experiments and obtain the characteristic STDP curve along with other phenomena including the reduction in synaptic plasticity as synaptic eﬃcacy increases. We compare our account to other eﬀorts to derive STDP from computational principles, and argue that our account provides the most comprehensive coverage of the phenomena. Thus, reliability of neural response in the face of noise may be a key goal of cortical adaptation. 1</p><p>3 0.70114332 <a title="181-lsi-3" href="./nips-2004-Rate-_and_Phase-coded_Autoassociative_Memory.html">151 nips-2004-Rate- and Phase-coded Autoassociative Memory</a></p>
<p>Author: Máté Lengyel, Peter Dayan</p><p>Abstract: Areas of the brain involved in various forms of memory exhibit patterns of neural activity quite unlike those in canonical computational models. We show how to use well-founded Bayesian probabilistic autoassociative recall to derive biologically reasonable neuronal dynamics in recurrently coupled models, together with appropriate values for parameters such as the membrane time constant and inhibition. We explicitly treat two cases. One arises from a standard Hebbian learning rule, and involves activity patterns that are coded by graded ﬁring rates. The other arises from a spike timing dependent learning rule, and involves patterns coded by the phase of spike times relative to a coherent local ﬁeld potential oscillation. Our model offers a new and more complete understanding of how neural dynamics may support autoassociation. 1</p><p>4 0.60162038 <a title="181-lsi-4" href="./nips-2004-Spike-timing_Dependent_Plasticity_and_Mutual_Information_Maximization_for_a_Spiking_Neuron_Model.html">173 nips-2004-Spike-timing Dependent Plasticity and Mutual Information Maximization for a Spiking Neuron Model</a></p>
<p>Author: Taro Toyoizumi, Jean-pascal Pfister, Kazuyuki Aihara, Wulfram Gerstner</p><p>Abstract: We derive an optimal learning rule in the sense of mutual information maximization for a spiking neuron model. Under the assumption of small ﬂuctuations of the input, we ﬁnd a spike-timing dependent plasticity (STDP) function which depends on the time course of excitatory postsynaptic potentials (EPSPs) and the autocorrelation function of the postsynaptic neuron. We show that the STDP function has both positive and negative phases. The positive phase is related to the shape of the EPSP while the negative phase is controlled by neuronal refractoriness. 1</p><p>5 0.59764206 <a title="181-lsi-5" href="./nips-2004-Optimal_Information_Decoding_from_Neuronal_Populations_with_Specific_Stimulus_Selectivity.html">140 nips-2004-Optimal Information Decoding from Neuronal Populations with Specific Stimulus Selectivity</a></p>
<p>Author: Marcelo A. Montemurro, Stefano Panzeri</p><p>Abstract: A typical neuron in visual cortex receives most inputs from other cortical neurons with a roughly similar stimulus preference. Does this arrangement of inputs allow efﬁcient readout of sensory information by the target cortical neuron? We address this issue by using simple modelling of neuronal population activity and information theoretic tools. We ﬁnd that efﬁcient synaptic information transmission requires that the tuning curve of the afferent neurons is approximately as wide as the spread of stimulus preferences of the afferent neurons reaching the target neuron. By meta analysis of neurophysiological data we found that this is the case for cortico-cortical inputs to neurons in visual cortex. We suggest that the organization of V1 cortico-cortical synaptic inputs allows optimal information transmission. 1</p><p>6 0.56176382 <a title="181-lsi-6" href="./nips-2004-Saliency-Driven_Image_Acuity_Modulation_on_a_Reconfigurable_Array_of_Spiking_Silicon_Neurons.html">157 nips-2004-Saliency-Driven Image Acuity Modulation on a Reconfigurable Array of Spiking Silicon Neurons</a></p>
<p>7 0.55649072 <a title="181-lsi-7" href="./nips-2004-Hierarchical_Bayesian_Inference_in_Networks_of_Spiking_Neurons.html">76 nips-2004-Hierarchical Bayesian Inference in Networks of Spiking Neurons</a></p>
<p>8 0.50054759 <a title="181-lsi-8" href="./nips-2004-Maximum_Likelihood_Estimation_of_Intrinsic_Dimension.html">114 nips-2004-Maximum Likelihood Estimation of Intrinsic Dimension</a></p>
<p>9 0.46075693 <a title="181-lsi-9" href="./nips-2004-Methods_for_Estimating_the_Computational_Power_and_Generalization_Capability_of_Neural_Microcircuits.html">118 nips-2004-Methods for Estimating the Computational Power and Generalization Capability of Neural Microcircuits</a></p>
<p>10 0.45006901 <a title="181-lsi-10" href="./nips-2004-Bayesian_inference_in_spiking_neurons.html">28 nips-2004-Bayesian inference in spiking neurons</a></p>
<p>11 0.43767145 <a title="181-lsi-11" href="./nips-2004-Theory_of_localized_synfire_chain%3A_characteristic_propagation_speed_of_stable_spike_pattern.html">194 nips-2004-Theory of localized synfire chain: characteristic propagation speed of stable spike pattern</a></p>
<p>12 0.40137804 <a title="181-lsi-12" href="./nips-2004-Maximising_Sensitivity_in_a_Spiking_Network.html">112 nips-2004-Maximising Sensitivity in a Spiking Network</a></p>
<p>13 0.35816646 <a title="181-lsi-13" href="./nips-2004-Inference%2C_Attention%2C_and_Decision_in_a_Bayesian_Neural_Architecture.html">84 nips-2004-Inference, Attention, and Decision in a Bayesian Neural Architecture</a></p>
<p>14 0.35791957 <a title="181-lsi-14" href="./nips-2004-Synchronization_of_neural_networks_by_mutual_learning_and_its_application_to_cryptography.html">180 nips-2004-Synchronization of neural networks by mutual learning and its application to cryptography</a></p>
<p>15 0.34368503 <a title="181-lsi-15" href="./nips-2004-Theories_of_Access_Consciousness.html">193 nips-2004-Theories of Access Consciousness</a></p>
<p>16 0.34298646 <a title="181-lsi-16" href="./nips-2004-Edge_of_Chaos_Computation_in_Mixed-Mode_VLSI_-_A_Hard_Liquid.html">58 nips-2004-Edge of Chaos Computation in Mixed-Mode VLSI - A Hard Liquid</a></p>
<p>17 0.33691537 <a title="181-lsi-17" href="./nips-2004-Unsupervised_Variational_Bayesian_Learning_of_Nonlinear_Models.html">198 nips-2004-Unsupervised Variational Bayesian Learning of Nonlinear Models</a></p>
<p>18 0.3358646 <a title="181-lsi-18" href="./nips-2004-Intrinsically_Motivated_Reinforcement_Learning.html">88 nips-2004-Intrinsically Motivated Reinforcement Learning</a></p>
<p>19 0.33324403 <a title="181-lsi-19" href="./nips-2004-Chemosensory_Processing_in_a_Spiking_Model_of_the_Olfactory_Bulb%3A_Chemotopic_Convergence_and_Center_Surround_Inhibition.html">35 nips-2004-Chemosensory Processing in a Spiking Model of the Olfactory Bulb: Chemotopic Convergence and Center Surround Inhibition</a></p>
<p>20 0.31018448 <a title="181-lsi-20" href="./nips-2004-Neural_Network_Computation_by_In_Vitro_Transcriptional_Circuits.html">128 nips-2004-Neural Network Computation by In Vitro Transcriptional Circuits</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2004_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(10, 0.117), (13, 0.152), (15, 0.122), (19, 0.013), (26, 0.053), (31, 0.028), (33, 0.153), (35, 0.082), (39, 0.034), (50, 0.046), (71, 0.011), (76, 0.022), (82, 0.039)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94013637 <a title="181-lda-1" href="./nips-2004-Synergies_between_Intrinsic_and_Synaptic_Plasticity_in_Individual_Model_Neurons.html">181 nips-2004-Synergies between Intrinsic and Synaptic Plasticity in Individual Model Neurons</a></p>
<p>Author: Jochen Triesch</p><p>Abstract: This paper explores the computational consequences of simultaneous intrinsic and synaptic plasticity in individual model neurons. It proposes a new intrinsic plasticity mechanism for a continuous activation model neuron based on low order moments of the neuron’s ﬁring rate distribution. The goal of the intrinsic plasticity mechanism is to enforce a sparse distribution of the neuron’s activity level. In conjunction with Hebbian learning at the neuron’s synapses, the neuron is shown to discover sparse directions in the input. 1</p><p>2 0.87984657 <a title="181-lda-2" href="./nips-2004-Bayesian_inference_in_spiking_neurons.html">28 nips-2004-Bayesian inference in spiking neurons</a></p>
<p>Author: Sophie Deneve</p><p>Abstract: We propose a new interpretation of spiking neurons as Bayesian integrators accumulating evidence over time about events in the external world or the body, and communicating to other neurons their certainties about these events. In this model, spikes signal the occurrence of new information, i.e. what cannot be predicted from the past activity. As a result, ﬁring statistics are close to Poisson, albeit providing a deterministic representation of probabilities. We proceed to develop a theory of Bayesian inference in spiking neural networks, recurrent interactions implementing a variant of belief propagation. Many perceptual and motor tasks performed by the central nervous system are probabilistic, and can be described in a Bayesian framework [4, 3]. A few important but hidden properties, such as direction of motion, or appropriate motor commands, are inferred from many noisy, local and ambiguous sensory cues. These evidences are combined with priors about the sensory world and body. Importantly, because most of these inferences should lead to quick and irreversible decisions in a perpetually changing world, noisy cues have to be integrated on-line, but in a way that takes into account unpredictable events, such as a sudden change in motion direction or the appearance of a new stimulus. This raises the question of how this temporal integration can be performed at the neural level. It has been proposed that single neurons in sensory cortices represent and compute the log probability that a sensory variable takes on a certain value (eg Is visual motion in the neuron’s preferred direction?) [9, 7]. Alternatively, to avoid normalization issues and provide an appropriate signal for decision making, neurons could represent the log probability ratio of a particular hypothesis (eg is motion more likely to be towards the right than towards the left) [7, 6]. Log probabilities are convenient here, since under some assumptions, independent noisy cues simply combine linearly. Moreover, there are physiological evidence for the neural representation of log probabilities and log probability ratios [9, 6, 7]. However, these models assume that neurons represent probabilities in their ﬁring rates. We argue that it is important to study how probabilistic information are encoded in spikes. Indeed, it seems spurious to marry the idea of an exquisite on-line integration of noisy cues with an underlying rate code that requires averaging on large populations of noisy neurons and long periods of time. In particular, most natural tasks require this integration to take place on the time scale of inter-spike intervals. Spikes are more efﬁciently signaling events ∗ Institute of Cognitive Science, 69645 Bron, France than analog quantities. In addition, a neural theory of inference with spikes will bring us closer to the physiological level and generate more easily testable predictions. Thus, we propose a new theory of neural processing in which spike trains provide a deterministic, online representation of a log-probability ratio. Spikes signals events, eg that the log-probability ratio has exceeded what could be predicted from previous spikes. This form of coding was loosely inspired by the idea of ”energy landscape” coding proposed by Hinton and Brown [2]. However, contrary to [2] and other theories using rate-based representation of probabilities, this model is self-consistent and does not require different models for encoding and decoding: As output spikes provide new, unpredictable, temporally independent evidence, they can be used directly as an input to other Bayesian neurons. Finally, we show that these neurons can be used as building blocks in a theory of approximate Bayesian inference in recurrent spiking networks. Connections between neurons implement an underlying Bayesian network, consisting of coupled hidden Markov models. Propagation of spikes is a form of belief propagation in this underlying graphical model. Our theory provides computational explanations of some general physiological properties of cortical neurons, such as spike frequency adaptation, Poisson statistics of spike trains, the existence of strong local inhibition in cortical columns, and the maintenance of a tight balance between excitation and inhibition. Finally, we discuss the implications of this model for the debate about temporal versus rate-based neural coding. 1 Spikes and log posterior odds 1.1 Synaptic integration seen as inference in a hidden Markov chain We propose that each neuron codes for an underlying ”hidden” binary variable, xt , whose state evolves over time. We assume that xt depends only on the state at the previous time step, xt−dt , and is conditionally independent of other past states. The state xt can switch 1 from 0 to 1 with a constant rate ron = dt limdt→0 P (xt = 1|xt−dt = 0), and from 1 to 0 with a constant rate roﬀ . For example, these transition rates could represent how often motion in a preferred direction appears the receptive ﬁeld and how long it is likely to stay there. The neuron infers the state of its hidden variable from N noisy synaptic inputs, considered to be observations of the hidden state. In this initial version of the model, we assume that these inputs are conditionally independent homogeneous Poisson processes, synapse i i emitting a spike between time t and t + dt (si = 1) with constant probability qon dt if t i xt = 1, and another constant probability qoﬀ dt if xt = 0. The synaptic spikes are assumed to be otherwise independent of previous synaptic spikes, previous states and spikes at other synapses. The resulting generative model is a hidden Markov chain (ﬁgure 1-A). However, rather than estimating the state of its hidden variable and communicating this estimate to other neurons (for example by emitting a spike when sensory evidence for xt = 1 goes above a threshold) the neuron reports and communicates its certainty that the current state is 1. This certainty takes the form of the log of the ratio of the probability that the hidden state is 1, and the probability that the state is 0, given all the synaptic inputs P (xt =1|s0→t ) received so far: Lt = log P (xt =0|s0→t ) . We use s0→t as a short hand notation for the N synaptic inputs received at present and in the past. We will refer to it as the log odds ratio. Thanks to the conditional independencies assumed in the generative model, we can compute this Log odds ratio iteratively. Taking the limit as dt goes to zero, we get the following differential equation: ˙ L = ron 1 + e−L − roﬀ 1 + eL + i wi δ(si − 1) − θ t B. A. xt ron .roff dt qon , qoff st xt ron .roff i t st dt s qon , qoff qon , qoff st dt xt j st Ot It Gt Ot Lt t t dt C. E. 2 0 -2 -4 D. 500 1000 1500 2000 2500 2 3000 Count Log odds 4 20 Lt 0 -2 0 500 1000 1500 2000 2500 Time Ot 3000 0 200 400 600 ISI Figure 1: A. Generative model for the synaptic input. B. Schematic representation of log odds ratio encoding and decoding. The dashed circle represents both eventual downstream elements and the self-prediction taking place inside the model neuron. A spike is ﬁred only when Lt exceeds Gt . C. One example trial, where the state switches from 0 to 1 (shaded area) and back to 0. plain: Lt , dotted: Gt . Black stripes at the top: corresponding spikes train. D. Mean Log odds ratio (dark line) and mean output ﬁring rate (clear line). E. Output spike raster plot (1 line per trial) and ISI distribution for the neuron shown is C. and D. Clear line: ISI distribution for a poisson neuron with the same rate. wi , the synaptic weight, describe how informative synapse i is about the state of the hidden i qon variable, e.g. wi = log qi . Each synaptic spike (si = 1) gives an impulse to the log t off odds ratio, which is positive if this synapse is more active when the hidden state if 1 (i.e it increases the neuron’s conﬁdence that the state is 1), and negative if this synapse is more active when xt = 0 (i.e it decreases the neuron’s conﬁdence that the state is 1). The bias, θ, is determined by how informative it is not to receive any spike, e.g. θ = i i i qon − qoﬀ . By convention, we will consider that the ”bias” is positive or zero (if not, we need simply to invert the status of the state x). 1.2 Generation of output spikes The spike train should convey a sparse representation of Lt , so that each spike reports new information about the state xt that is not redundant with that reported by other, preceding, spikes. This proposition is based on three arguments: First, spikes, being metabolically expensive, should be kept to a minimum. Second, spikes conveying redundant information would require a decoding of the entire spike train, whereas independent spike can be taken into account individually. And ﬁnally, we seek a self consistent model, with the spiking output having a similar semantics to its spiking input. To maximize the independence of the spikes (conditioned on xt ), we propose that the neuron ﬁres only when the difference between its log odds ratio Lt and a prediction Gt of this log odds ratio based on the output spikes emitted so far reaches a certain threshold. Indeed, supposing that downstream elements predicts Lt as best as they can, the neuron only needs to ﬁre when it expects that prediction to be too inaccurate (ﬁgure 1-B). In practice, this will happen when the neuron receives new evidence for xt = 1. Gt should thereby follow the same dynamics as Lt when spikes are not received. The equation for Gt and the output Ot (Ot = 1 when an output spike is ﬁred) are given by: ˙ G = Ot = ron 1 + e−L − roﬀ 1 + eL + go δ(Ot − 1) go 1. when Lt > Gt + , 0 otherwise, 2 (1) (2) Here go , a positive constant, is the only free parameter, the other parameters being constrained by the statistics of the synaptic input. 1.3 Results Figure 1-C plots a typical trial, showing the behavior of L, G and O before, during and after presentation of the stimulus. As random synaptic inputs are integrated, L ﬂuctuates and eventually exceeds G + 0.5, leading to an output spike. Immediately after a spike, G jumps to G + go , which prevents (except in very rare cases) a second spike from immediately following the ﬁrst. Thus, this ”jump” implements a relative refractory period. However, ron G decays as it tends to converge back to its stable level gstable = log roff . Thus L eventually exceeds G again, leading to a new spike. This threshold crossing happens more often during stimulation (xt = 1) as the net synaptic input alters to create a higher overall level of certainty, Lt . Mean Log odds ratio and output ﬁring rate ¯ The mean ﬁring rate Ot of the Bayesian neuron during presentation of its preferred stimulus (i.e. when xt switches from 0 to 1 and back to 0) is plotted in ﬁgure 1-D, together with the ¯ mean log posterior ratio Lt , both averaged over trials. Not surprisingly, the log-posterior ratio reﬂects the leaky integration of synaptic evidence, with an effective time constant that depends on the transition probabilities ron , roﬀ . If the state is very stable (ron = roﬀ ∼ 0), synaptic evidence is integrated over almost inﬁnite time periods, the mean log posterior ratio tending to either increase or decrease linearly with time. In the example in ﬁgure 1D, the state is less stable, so ”old” synaptic evidence are discounted and Lt saturates. ¯ In contrast, the mean output ﬁring rate Ot tracks the state of xt almost perfectly. This is because, as a form of predictive coding, the output spikes reﬂect the new synaptic i evidence, It = i δ(st − 1) − θ, rather than the log posterior ratio itself. In particular, the mean output ﬁring rate is a rectiﬁed linear function of the mean input, e. g. + ¯ ¯ wi q i −θ . O= 1I= go i on(oﬀ) Analogy with a leaky integrate and ﬁre neuron We can get an interesting insight into the computation performed by this neuron by linearizing L and G around their mean levels over trials. Here we reduce the analysis to prolonged, statistically stable periods when the state is constant (either ON or OFF). In this case, the ¯ ¯ mean level of certainty L and its output prediction G are also constant over time. We make the rough approximation that the post spike jump, go , and the input ﬂuctuations are small ¯ compared to the mean level of certainty L. Rewriting Vt = Lt − Gt + go 2 as the ”membrane potential” of the Bayesian neuron: ˙ V = −kL V + It − ∆go − go Ot ¯ ¯ ¯ where kL = ron e−L + roﬀ eL , the ”leak” of the membrane potential, depends on the overall ¯ level of certainty. ∆go is positive and a monotonic increasing function of go . A. s t1 dt s t1 s t1 dt B. C. x t1 x t3 dt x t3 x t3 dt x t1 x t1 x t1 x t2 x t3 x t1 … x tn x t3 x t2 … x tn … dt dt Lx2 D. x t2 dt s t2 dt x t2 s t2 x t2 dt s t2 dt Log odds 10 No inh -0.5 -1 -1 -1.5 -2 5 Feedback 500 1000 1500 2000 Tiger Stripes 0 -5 -10 500 1000 1500 2000 2500 Time Figure 2: A. Bayesian causal network for yt (tiger), x1 (stripes) and x2 (paws). B. A nett t work feedforward computing the log posterior for x1 . C. A recurrent network computing t the log posterior odds for all variables. D. Log odds ratio in a simulated trial with the net2 1 1 work in C (see text). Thick line: Lx , thin line: Lx , dash-dotted: Lx without inhibition. t t t 2 Insert: Lx averaged over trials, showing the effect of feedback. t The linearized Bayesian neuron thus acts in its stable regime as a leaky integrate and ﬁre (LIF) neuron. The membrane potential Vt integrates its input, Jt = It − ∆go , with a leak kL . The neuron ﬁres when its membrane potential reaches a constant threshold go . After ¯ each spikes, Vt is reset to 0. Interestingly, for appropriately chosen compression factor go , the mean input to the lin¯ ¯ earized neuron J = I − ∆go ≈ 0 1 . This means that the membrane potential is purely driven to its threshold by input ﬂuctuations, or a random walk in membrane potential. As a consequence, the neuron’s ﬁring will be memoryless, and close to a Poisson process. In particular, we found Fano factor close to 1 and quasi-exponential ISI distribution (ﬁgure 1E) on the entire range of parameters tested. Indeed, LIF neurons with balanced inputs have been proposed as a model to reproduce the statistics of real cortical neurons [8]. This balance is implemented in our model by the neuron’s effective self-inhibition, even when the synaptic input itself is not balanced. Decoding As we previously said, downstream elements could predict the log odds ratio Lt by computing Gt from the output spikes (Eq 1, ﬁg 1-B). Of course, this requires an estimate of the transition probabilities ron , roﬀ , that could be learned from the observed spike trains. However, we show next that explicit decoding is not necessary to perform bayesian inference in spiking networks. Intuitively, this is because the quantity that our model neurons receive and transmit, eg new information, is exactly what probabilistic inference algorithm propagate between connected statistical elements. 1 ¯ Even if go is not chosen optimally, the inﬂuence of the drift J is usually negligible compared to the large ﬂuctuations in membrane potential. 2 Bayesian inference in cortical networks The model neurons, having the same input and output semantics, can be used as building blocks to implement more complex generative models consisting of coupled Markov chains. Consider, for example, the example in ﬁgure 2-A. Here, a ”parent” variable x1 t (the presence of a tiger) can cause the state of n other ”children” variables ([xk ]k=2...n ), t of whom two are represented (the presence of stripes,x2 , and motion, x3 ). The ”chilt t dren” variables are Bayesian neurons identical to those described previously. The resulting bayesian network consist of n + 1 coupled hidden Markov chains. Inference in this architecture corresponds to computing the log posterior odds ratio for the tiger, x1 , and the log t posterior of observing stripes or motion, ([xk ]k=2...n ), given the synaptic inputs received t by the entire network so far, i.e. s2 , . . . , sk . 0→t 0→t Unfortunately, inference and learning in this network (and in general in coupled Markov chains) requires very expensive computations, and cannot be performed by simply propagating messages over time and among the variable nodes. In particular, the state of a child k variable xt depends on xk , sk , x1 and the state of all other children at the previous t t t−dt time step, [xj ]2</p><p>3 0.86400241 <a title="181-lda-3" href="./nips-2004-Non-Local_Manifold_Tangent_Learning.html">131 nips-2004-Non-Local Manifold Tangent Learning</a></p>
<p>Author: Yoshua Bengio, Martin Monperrus</p><p>Abstract: We claim and present arguments to the effect that a large class of manifold learning algorithms that are essentially local and can be framed as kernel learning algorithms will suffer from the curse of dimensionality, at the dimension of the true underlying manifold. This observation suggests to explore non-local manifold learning algorithms which attempt to discover shared structure in the tangent planes at different positions. A criterion for such an algorithm is proposed and experiments estimating a tangent plane prediction function are presented, showing its advantages with respect to local manifold learning algorithms: it is able to generalize very far from training data (on learning handwritten character image rotations), where a local non-parametric method fails. 1</p><p>4 0.8524093 <a title="181-lda-4" href="./nips-2004-Rate-_and_Phase-coded_Autoassociative_Memory.html">151 nips-2004-Rate- and Phase-coded Autoassociative Memory</a></p>
<p>Author: Máté Lengyel, Peter Dayan</p><p>Abstract: Areas of the brain involved in various forms of memory exhibit patterns of neural activity quite unlike those in canonical computational models. We show how to use well-founded Bayesian probabilistic autoassociative recall to derive biologically reasonable neuronal dynamics in recurrently coupled models, together with appropriate values for parameters such as the membrane time constant and inhibition. We explicitly treat two cases. One arises from a standard Hebbian learning rule, and involves activity patterns that are coded by graded ﬁring rates. The other arises from a spike timing dependent learning rule, and involves patterns coded by the phase of spike times relative to a coherent local ﬁeld potential oscillation. Our model offers a new and more complete understanding of how neural dynamics may support autoassociation. 1</p><p>5 0.85170615 <a title="181-lda-5" href="./nips-2004-Hierarchical_Bayesian_Inference_in_Networks_of_Spiking_Neurons.html">76 nips-2004-Hierarchical Bayesian Inference in Networks of Spiking Neurons</a></p>
<p>Author: Rajesh P. Rao</p><p>Abstract: There is growing evidence from psychophysical and neurophysiological studies that the brain utilizes Bayesian principles for inference and decision making. An important open question is how Bayesian inference for arbitrary graphical models can be implemented in networks of spiking neurons. In this paper, we show that recurrent networks of noisy integrate-and-ﬁre neurons can perform approximate Bayesian inference for dynamic and hierarchical graphical models. The membrane potential dynamics of neurons is used to implement belief propagation in the log domain. The spiking probability of a neuron is shown to approximate the posterior probability of the preferred state encoded by the neuron, given past inputs. We illustrate the model using two examples: (1) a motion detection network in which the spiking probability of a direction-selective neuron becomes proportional to the posterior probability of motion in a preferred direction, and (2) a two-level hierarchical network that produces attentional effects similar to those observed in visual cortical areas V2 and V4. The hierarchical model offers a new Bayesian interpretation of attentional modulation in V2 and V4. 1</p><p>6 0.85132301 <a title="181-lda-6" href="./nips-2004-A_Harmonic_Excitation_State-Space_Approach_to_Blind_Separation_of_Speech.html">5 nips-2004-A Harmonic Excitation State-Space Approach to Blind Separation of Speech</a></p>
<p>7 0.8507669 <a title="181-lda-7" href="./nips-2004-Semi-parametric_Exponential_Family_PCA.html">163 nips-2004-Semi-parametric Exponential Family PCA</a></p>
<p>8 0.85075074 <a title="181-lda-8" href="./nips-2004-Edge_of_Chaos_Computation_in_Mixed-Mode_VLSI_-_A_Hard_Liquid.html">58 nips-2004-Edge of Chaos Computation in Mixed-Mode VLSI - A Hard Liquid</a></p>
<p>9 0.84805536 <a title="181-lda-9" href="./nips-2004-The_Power_of_Selective_Memory%3A_Self-Bounded_Learning_of_Prediction_Suffix_Trees.html">189 nips-2004-The Power of Selective Memory: Self-Bounded Learning of Prediction Suffix Trees</a></p>
<p>10 0.84463066 <a title="181-lda-10" href="./nips-2004-Methods_for_Estimating_the_Computational_Power_and_Generalization_Capability_of_Neural_Microcircuits.html">118 nips-2004-Methods for Estimating the Computational Power and Generalization Capability of Neural Microcircuits</a></p>
<p>11 0.84100813 <a title="181-lda-11" href="./nips-2004-Following_Curved_Regularized_Optimization_Solution_Paths.html">70 nips-2004-Following Curved Regularized Optimization Solution Paths</a></p>
<p>12 0.84100693 <a title="181-lda-12" href="./nips-2004-Kernel_Projection_Machine%3A_a_New_Tool_for_Pattern_Recognition.html">93 nips-2004-Kernel Projection Machine: a New Tool for Pattern Recognition</a></p>
<p>13 0.84034002 <a title="181-lda-13" href="./nips-2004-An_Investigation_of_Practical_Approximate_Nearest_Neighbor_Algorithms.html">22 nips-2004-An Investigation of Practical Approximate Nearest Neighbor Algorithms</a></p>
<p>14 0.83962214 <a title="181-lda-14" href="./nips-2004-A_Cost-Shaping_LP_for_Bellman_Error_Minimization_with_Performance_Guarantees.html">1 nips-2004-A Cost-Shaping LP for Bellman Error Minimization with Performance Guarantees</a></p>
<p>15 0.83886498 <a title="181-lda-15" href="./nips-2004-Learning_first-order_Markov_models_for_control.html">102 nips-2004-Learning first-order Markov models for control</a></p>
<p>16 0.8381148 <a title="181-lda-16" href="./nips-2004-Efficient_Kernel_Machines_Using_the_Improved_Fast_Gauss_Transform.html">60 nips-2004-Efficient Kernel Machines Using the Improved Fast Gauss Transform</a></p>
<p>17 0.83799064 <a title="181-lda-17" href="./nips-2004-Outlier_Detection_with_One-class_Kernel_Fisher_Discriminants.html">142 nips-2004-Outlier Detection with One-class Kernel Fisher Discriminants</a></p>
<p>18 0.83578467 <a title="181-lda-18" href="./nips-2004-Support_Vector_Classification_with_Input_Data_Uncertainty.html">178 nips-2004-Support Vector Classification with Input Data Uncertainty</a></p>
<p>19 0.8354705 <a title="181-lda-19" href="./nips-2004-Spike-timing_Dependent_Plasticity_and_Mutual_Information_Maximization_for_a_Spiking_Neuron_Model.html">173 nips-2004-Spike-timing Dependent Plasticity and Mutual Information Maximization for a Spiking Neuron Model</a></p>
<p>20 0.83489227 <a title="181-lda-20" href="./nips-2004-Inference%2C_Attention%2C_and_Decision_in_a_Bayesian_Neural_Architecture.html">84 nips-2004-Inference, Attention, and Decision in a Bayesian Neural Architecture</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
