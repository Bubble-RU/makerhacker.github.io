<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>25 nips-2002-An Asynchronous Hidden Markov Model for Audio-Visual Speech Recognition</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-25" href="../nips2002/nips-2002-An_Asynchronous_Hidden_Markov_Model_for_Audio-Visual_Speech_Recognition.html">nips2002-25</a> <a title="nips-2002-25-reference" href="#">nips2002-25-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>25 nips-2002-An Asynchronous Hidden Markov Model for Audio-Visual Speech Recognition</h1>
<br/><p>Source: <a title="nips-2002-25-pdf" href="http://papers.nips.cc/paper/2301-an-asynchronous-hidden-markov-model-for-audio-visual-speech-recognition.pdf">pdf</a></p><p>Author: Samy Bengio</p><p>Abstract: This paper presents a novel Hidden Markov Model architecture to model the joint probability of pairs of asynchronous sequences describing the same event. It is based on two other Markovian models, namely Asynchronous Input/ Output Hidden Markov Models and Pair Hidden Markov Models. An EM algorithm to train the model is presented, as well as a Viterbi decoder that can be used to obtain the optimal state sequence as well as the alignment between the two sequences. The model has been tested on an audio-visual speech recognition task using the M2VTS database and yielded robust performances under various noise conditions. 1</p><br/>
<h2>reference text</h2><p>[I] S. Bengio. An asynchronous hidden markov model for audio-visual speech recognition. Technical Report IDIAP-RR 02-26, IDIAP, 2002.</p>
<p>[2] S. Bengio and Y. Bengio. An EM algorithm for asynchronous input/ output hidden markov models. In Proceedings of the International Conference on Neural Information Processing, ICONIP, Hong Kong, 1996.</p>
<p>[3] S. Dupont and J . Luettin. Audio-visual speech modelling for continuous speech recognition. IEEE Transactions on Multimedia, 2:141- 151 , 2000.</p>
<p>[4] R. Durbin, S. Eddy, A. Krogh, and G. Michison. Biological Sequence Analysis: Probabilistic Models of proteins and nucleic acids. Cambridge University Press, 1998.</p>
<p>[5] S. Pigeon and L. Vandendorpe. The M2VTS multimodal face database (release 1.00). In Proceedings of th e First International Conference on Audio- and Vid eo-bas ed Biometric P erson Authentication ABVPA, 1997.</p>
<p>[6] Laurence R. Rabiner. A tutorial on hidden markov models and selected applications in speech recognition. Proceedings of th e IEEE, 77(2):257- 286 , 1989.</p>
<p>[7] W. H. Sumby and 1. Pollak. Visual contributions to speech intelligibility in noise. Journal of th e Acoustical Society of America, 26:212- 215 , 1954.</p>
<p>[8] A. Q. Summerfield. Lipreading and audio-visual speech p erception. Philosophical Transactions of the Royal Society of London, Series B, 335:71- 78 , 1992.</p>
<p>[9] A. Varga, H.J .M. Steeneken, M. Tomlinson , and D . Jones. The noisex-92 study on the effect of additive noise on automatic speech recognition. Technical report , DRA Speech Research Unit, 1992.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
