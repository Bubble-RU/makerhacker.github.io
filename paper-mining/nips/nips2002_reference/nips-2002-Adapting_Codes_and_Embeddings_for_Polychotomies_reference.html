<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>19 nips-2002-Adapting Codes and Embeddings for Polychotomies</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-19" href="../nips2002/nips-2002-Adapting_Codes_and_Embeddings_for_Polychotomies.html">nips2002-19</a> <a title="nips-2002-19-reference" href="#">nips2002-19-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>19 nips-2002-Adapting Codes and Embeddings for Polychotomies</h1>
<br/><p>Source: <a title="nips-2002-19-pdf" href="http://papers.nips.cc/paper/2166-adapting-codes-and-embeddings-for-polychotomies.pdf">pdf</a></p><p>Author: Gunnar Rätsch, Sebastian Mika, Alex J. Smola</p><p>Abstract: In this paper we consider formulations of multi-class problems based on a generalized notion of a margin and using output coding. This includes, but is not restricted to, standard multi-class SVM formulations. Differently from many previous approaches we learn the code as well as the embedding function. We illustrate how this can lead to a formulation that allows for solving a wider range of problems with for instance many classes or even “missing classes”. To keep our optimization problems tractable we propose an algorithm capable of solving them using twoclass classiﬁers, similar in spirit to Boosting.</p><br/>
<h2>reference text</h2><p>[1] E.L. Allwein, R.E. Schapire, and Y. Singer. Reducing multiclass to binary: A unifying approach for margin classiﬁers. Journal of Machine Learning Research, 1:113–141, 2000.</p>
<p>[2] K.P. Bennett, A. Demiriz, and J. Shawe-Taylor. A column generation algorithm for boosting. In P. Langley, editor, Proc. 17th ICML, pages 65–72, San Francisco, 2000. Morgan Kaufmann.</p>
<p>[3] B. Caputo and G. R¨ tsch. Adaptive codes for visual categories. November 2002. Unpublished a manuscript. Partial results presented at NIPS’02.</p>
<p>[4] K. Crammer and Y. Singer. On the learnability and design of output codes for multiclass problems. In N. Cesa-Bianchi and S. Goldberg, editors, Proc. Colt, pages 35–46, San Francisco, 2000. Morgan Kaufmann.</p>
<p>[5] O. Dekel and Y. Singer. Multiclass learning by probabilistic embeddings. In NIPS, vol. 15. MIT Press, 2003.</p>
<p>[6] T.G. Dietterich and G. Bakiri. Solving multiclass learning problems via error-correcting output codes. Journal of Aritiﬁcal Intelligence Research, 2:263–286, 1995.</p>
<p>[7] V. Guruswami and A. Sahai. Multiclass learning, boosing, and error-correcting codes. In Proc. of the twelfth annual conference on Computational learning theory, pages 145–155, New York, USA, 1999. ACM Press.</p>
<p>[8] S. Har-Peled, D. Roth, and D. Zimak. Constraint classiﬁcation: A new approach to multiclass classiﬁcation and ranking. In NIPS, vol. 15. MIT Press, 2003.</p>
<p>[9] T.J. Hastie and R.J. Tibshirani. Classiﬁcation by pairwise coupling. In M.I. Jordan, M.J. Kearnsa, and S.A. Solla, editors, Advances in Neural Information Processing Systems, vol. 10. MIT Press, 1998.</p>
<p>[10] R. Herbrich, T. Graepel, and K. Obermayer. Large margin rank boundaries for ordinal regression. In A. J. Smola, P. L. Bartlett, B. Sch¨ lkopf, and D. Schuurmans, editors, Advances in o Large Margin Classiﬁers, pages 115–132, Cambridge, MA, 2000. MIT Press.</p>
<p>[11] R. Jin and Z. Ghahramani. Learning with multiple labels. In NIPS, vol. 15. MIT Press, 2003.</p>
<p>[12] S. Nash and A. Sofer. Linear and Nonlinear Programming. McGraw-Hill, New York, NY, 1996.</p>
<p>[13] G. R¨ tsch, A. Demiriz, and K. Bennett. Sparse regression ensembles in inﬁnite and ﬁnite a hypothesis spaces. Machine Learning, 48(1-3):193–221, 2002. Special Issue on New Methods for Model Selection and Model Combination.</p>
<p>[14] G. R¨ tsch, M. Warmuth, S. Mika, T. Onoda, S. Lemm, and K.-R. M¨ ller. Barrier boosting. In a u Proc. COLT, pages 170–179, San Francisco, 2000. Morgan Kaufmann.</p>
<p>[15] R.E. Schapire. Using output codes to boost multiclass learning problems. In Machine Learning: Proceedings of the 14th International Conference, pages 313–321, 1997.</p>
<p>[16] B. Sch¨ lkopf, A. Smola, R.C. Williamson, and P.L. Bartlett. New support vector algorithms. o Neural Computation, 12:1207 – 1245, 2000.</p>
<p>[17] N. Sloane. Personal homepage. http://www.research.att.com/˜njas/.</p>
<p>[18] W. Utschick. Error-Correcting Classiﬁcation Based on Neural Networks. Shaker, 1998.</p>
<p>[19] W. Utschick and W. Weichselberger. Stochastic organization of output codes in multiclass learning problems. Neural Computation, 13(5):1065–1102, 2001.</p>
<p>[20] V.N. Vapnik and A.Y. Chervonenkis. A note on one class of perceptrons. Automation and Remote Control, 25, 1964.</p>
<p>[21] J. Weston and C. Watkins. Multi-class support vector machines. Technical Report CSD-TR-9804, Royal Holloway, University of London, Egham, 1998.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
