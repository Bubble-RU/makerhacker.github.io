<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>125 nips-2002-Learning Semantic Similarity</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-125" href="../nips2002/nips-2002-Learning_Semantic_Similarity.html">nips2002-125</a> <a title="nips-2002-125-reference" href="#">nips2002-125-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>125 nips-2002-Learning Semantic Similarity</h1>
<br/><p>Source: <a title="nips-2002-125-pdf" href="http://papers.nips.cc/paper/2316-learning-semantic-similarity.pdf">pdf</a></p><p>Author: Jaz Kandola, Nello Cristianini, John S. Shawe-taylor</p><p>Abstract: The standard representation of text documents as bags of words suffers from well known limitations, mostly due to its inability to exploit semantic similarity between terms. Attempts to incorporate some notion of term similarity include latent semantic indexing [8], the use of semantic networks [9], and probabilistic methods [5]. In this paper we propose two methods for inferring such similarity from a corpus. The first one defines word-similarity based on document-similarity and viceversa, giving rise to a system of equations whose equilibrium point we use to obtain a semantic similarity measure. The second method models semantic relations by means of a diffusion process on a graph defined by lexicon and co-occurrence information. Both approaches produce valid kernel functions parametrised by a real number. The paper shows how the alignment measure can be used to successfully perform model selection over this parameter. Combined with the use of support vector machines we obtain positive results. 1</p><br/>
<h2>reference text</h2><p>[1] N. Cristianini and J. Shawe-Taylor. An Introduction to Support Vector Machines. Cambridge University Press, Cambridge, UK , 2000.</p>
<p>[2] Nello Cristianini, John Shawe-Taylor, and Jaz Kandola. On kernel target alignment. In Proceedings of the Neural Information Processing Systems, NIPS '01, 2002.</p>
<p>[3] Nello Cristianini, John Shawe-Taylor, and Huma Lodhi. Latent semantic kernels. Journal of Intelligent Information Systems, 18(2):127-152,2002.</p>
<p>[4] R. Ferrer and R.V. Sole. The small world of human language. Proceedings of the Royal Society of London Series B - Biological Sciences, pages 2261- 2265 , 200l.</p>
<p>[5] Thomas Hofmann. Probabilistic latent semantic indexing. In Research and Development in Information Retrieval, pages 50-57, 1999.</p>
<p>[6] T. Joachims. Text categorization with support vector machines. In Proceedings of European Conference on Machine Learning (ECML) , 1998.</p>
<p>[7] R.I. Kondor and J. Lafferty. Diffusion kernels on graphs and other discrete structures. In Proceedings of Intenational Conference on Machine Learning (ICML 2002), 2002.</p>
<p>[8] Todd A. Letsche and Michael W. Berry. Large-scale information retrieval with latent semantic indexing. Information Sciences, 100(1-4):105- 137,1997.</p>
<p>[9] G. Siolas and F. d 'Alch Buc. Support vector machines based on a semantic kernel for text categorization. In IEEE-IJCNN 2000), 2000.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
