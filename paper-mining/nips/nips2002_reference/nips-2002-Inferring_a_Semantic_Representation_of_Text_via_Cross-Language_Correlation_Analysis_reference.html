<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>112 nips-2002-Inferring a Semantic Representation of Text via Cross-Language Correlation Analysis</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-112" href="../nips2002/nips-2002-Inferring_a_Semantic_Representation_of_Text_via_Cross-Language_Correlation_Analysis.html">nips2002-112</a> <a title="nips-2002-112-reference" href="#">nips2002-112-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>112 nips-2002-Inferring a Semantic Representation of Text via Cross-Language Correlation Analysis</h1>
<br/><p>Source: <a title="nips-2002-112-pdf" href="http://papers.nips.cc/paper/2324-inferring-a-semantic-representation-of-text-via-cross-language-correlation-analysis.pdf">pdf</a></p><p>Author: Alexei Vinokourov, Nello Cristianini, John Shawe-Taylor</p><p>Abstract: The problem of learning a semantic representation of a text document from data is addressed, in the situation where a corpus of unlabeled paired documents is available, each pair being formed by a short English document and its French translation. This representation can then be used for any retrieval, categorization or clustering task, both in a standard and in a cross-lingual setting. By using kernel functions, in this case simple bag-of-words inner products, each part of the corpus is mapped to a high-dimensional space. The correlations between the two spaces are then learnt by using kernel Canonical Correlation Analysis. A set of directions is found in the ﬁrst and in the second space that are maximally correlated. Since we assume the two representations are completely independent apart from the semantic content, any correlation between them should reﬂect some semantic similarity. Certain patterns of English words that relate to a speciﬁc meaning should correlate with certain patterns of French words corresponding to the same meaning, across the corpus. Using the semantic representation obtained in this way we ﬁrst demonstrate that the correlations detected between the two versions of the corpus are signiﬁcantly higher than random, and hence that a representation based on such features does capture statistical patterns that should reﬂect semantic information. Then we use such representation both in cross-language and in single-language retrieval tasks, observing performance that is consistently and signiﬁcantly superior to LSI on the same data.</p><br/>
<h2>reference text</h2><p>[1] F. R. Bach and M. I. Jordan. Kernel indepedendent component analysis. Journal of Machine Learning Research, 3:1–48, 2002.</p>
<p>[2] Nello Cristianini and John Shawe-Taylor. An introduction to Support Vector Machines and other kernel-based learning methods. Cambridge University Press, 2000.</p>
<p>[3] Ulrich Germann. Aligned Hansards of the 36th Parliament of Canada. http://www.isi.edu/natural-language/download/hansard/, 2001. Release 2001-1a.   ¡  5  ¥ ¤   £ ¦5</p>
<p>[4] Thorsten Joachims. http://svmlight.joachims.org, 2002.  -  Support  Vector  Machine.</p>
<p>[5] M. L. Littman, S. T. Dumais, and T. K. Landauer. Automatic cross-language information retrieval using latent semantic indexing. In G. Grefenstette, editor, Cross language information retrieval. Kluwer, 1998.</p>
<p>[6] Alexei Vinokourov and Mark Girolami. A probabilistic framework for the hierarchic organisation and classiﬁcation of document collections. Journal of Intelligent Information Systems, 18(2/3):153–172, 2002. Special Issue on Automated Text Categorization.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
