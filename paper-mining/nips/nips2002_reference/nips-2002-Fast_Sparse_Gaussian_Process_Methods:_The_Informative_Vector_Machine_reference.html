<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>86 nips-2002-Fast Sparse Gaussian Process Methods: The Informative Vector Machine</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-86" href="../nips2002/nips-2002-Fast_Sparse_Gaussian_Process_Methods%3A_The_Informative_Vector_Machine.html">nips2002-86</a> <a title="nips-2002-86-reference" href="#">nips2002-86-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>86 nips-2002-Fast Sparse Gaussian Process Methods: The Informative Vector Machine</h1>
<br/><p>Source: <a title="nips-2002-86-pdf" href="http://papers.nips.cc/paper/2240-fast-sparse-gaussian-process-methods-the-informative-vector-machine.pdf">pdf</a></p><p>Author: Ralf Herbrich, Neil D. Lawrence, Matthias Seeger</p><p>Abstract: We present a framework for sparse Gaussian process (GP) methods which uses forward selection with criteria based on informationtheoretic principles, previously suggested for active learning. Our goal is not only to learn d–sparse predictors (which can be evaluated in O(d) rather than O(n), d n, n the number of training points), but also to perform training under strong restrictions on time and memory requirements. The scaling of our method is at most O(n · d2 ), and in large real-world classiﬁcation experiments we show that it can match prediction performance of the popular support vector machine (SVM), yet can be signiﬁcantly faster in training. In contrast to the SVM, our approximation produces estimates of predictive probabilities (‘error bars’), allows for Bayesian model selection and is less complex in implementation. 1</p><br/>
<h2>reference text</h2><p>[1] Lehel Csat´ and Manfred Opper. Sparse online Gaussian processes. N. Comp., 14:641– o 668, 2002.</p>
<p>[2] Neil D. Lawrence and Ralf Herbrich. A sparse Bayesian compression scheme - the informative vector machine. Presented at NIPS 2001 Workshop on Kernel Methods, 2001.</p>
<p>[3] David MacKay. Bayesian Methods for Adaptive Models. PhD thesis, California Institute of Technology, 1991.</p>
<p>[4] Thomas Minka. A Family of Algorithms for Approximate Bayesian Inference. PhD thesis, MIT, January 2001.</p>
<p>[5] Manfred Opper and Ole Winther. Gaussian processes for classiﬁcation: Mean ﬁeld algorithms. N. Comp., 12(11):2655–2684, 2000.</p>
<p>[6] John C. Platt. Fast training of support vector machines using sequential minimal optimization. In Sch¨lkopf et. al., editor, Advances in Kernel Methods, pages 185– o 208. 1998.</p>
<p>[7] Matthias Seeger, Neil D. Lawrence, and Ralf Herbrich. Sparse Bayesian learning: The informative vector machine. Technical report, Department of Computer Science, Sheﬃeld, UK, 2002. See www.dcs.shef.ac.uk/~neil/papers/.</p>
<p>[8] Alex Smola and Peter Bartlett. Sparse greedy Gaussian process regression. In Advances in NIPS 13, pages 619–625, 2001.</p>
<p>[9] Michael Tipping. Sparse Bayesian learning and the relevance vector machine. J. M. Learn. Res., 1:211–244, 2001.</p>
<p>[10] Volker Tresp. A Bayesian committee machine. N. Comp., 12(11):2719–2741, 2000.</p>
<p>[11] Christopher K. I. Williams and Matthias Seeger. Using the Nystr¨m method to speed o up kernel machines. In Advances in NIPS 13, pages 682–688, 2001.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
