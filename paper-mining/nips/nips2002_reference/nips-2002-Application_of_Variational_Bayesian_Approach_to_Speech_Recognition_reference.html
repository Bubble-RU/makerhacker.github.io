<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>31 nips-2002-Application of Variational Bayesian Approach to Speech Recognition</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-31" href="../nips2002/nips-2002-Application_of_Variational_Bayesian_Approach_to_Speech_Recognition.html">nips2002-31</a> <a title="nips-2002-31-reference" href="#">nips2002-31-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>31 nips-2002-Application of Variational Bayesian Approach to Speech Recognition</h1>
<br/><p>Source: <a title="nips-2002-31-pdf" href="http://papers.nips.cc/paper/2174-application-of-variational-bayesian-approach-to-speech-recognition.pdf">pdf</a></p><p>Author: Shinji Watanabe, Yasuhiro Minami, Atsushi Nakamura, Naonori Ueda</p><p>Abstract: In this paper, we propose a Bayesian framework, which constructs shared-state triphone HMMs based on a variational Bayesian approach, and recognizes speech based on the Bayesian prediction classiﬁcation; variational Bayesian estimation and clustering for speech recognition (VBEC). An appropriate model structure with high recognition performance can be found within a VBEC framework. Unlike conventional methods, including BIC or MDL criterion based on the maximum likelihood approach, the proposed model selection is valid in principle, even when there are insufﬁcient amounts of data, because it does not use an asymptotic assumption. In isolated word recognition experiments, we show the advantage of VBEC over conventional methods, especially when dealing with small amounts of data.</p><br/>
<h2>reference text</h2><p>[1] H. Attias, “A Variational Bayesian Framework for Graphical Models,” NIPS12, MIT Press, (2000).</p>
<p>[2] W. Chou and W. Reichl, “Decision Tree State Tying Based on Penalized Bayesian Information Criterion,” Proc. ICASSP’99, vol. 1, pp. 345-348, (1999).</p>
<p>[3] Z. Ghahramani and M. J. Beal, “Variational Inference for Bayesian Mixtures of Factor Analyzers,” NIPS12, MIT Press, (2000).</p>
<p>[4] J. J. Odell, “The Use of Context in Large Vocabulary Speech Recognition,” PhD thesis, Cambridge University, (1995).</p>
<p>[5] K. Shinoda and T. Watanabe, “Acoustic Modeling Based on the MDL Principle for Speech Recognition,” Proc. EuroSpeech’97, vol. 1, pp. 99-102, (1997).</p>
<p>[6] N. Ueda and Z. Ghahramani, “Bayesian Model Search for Mixture Models Based on Optimizing Variational Bounds,” Neural Networks, vol. 15, pp. 1223-1241, (2002).</p>
<p>[7] S. Watanabe et. al., “Constructing Shared-State Hidden Markov Models Based on a Bayesian Approach,” Proc. ICSLP’02, vol. 4, pp. 2669-2672, (2002).</p>
<p>[8] S. Waterhouse et. al., “Bayesian Methods for Mixture of Experts,” NIPS8, MIT Press, (1995).</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
