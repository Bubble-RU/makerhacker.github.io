<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>22 nips-2002-Adaptive Nonlinear System Identification with Echo State Networks</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-22" href="../nips2002/nips-2002-Adaptive_Nonlinear_System_Identification_with_Echo_State_Networks.html">nips2002-22</a> <a title="nips-2002-22-reference" href="#">nips2002-22-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>22 nips-2002-Adaptive Nonlinear System Identification with Echo State Networks</h1>
<br/><p>Source: <a title="nips-2002-22-pdf" href="http://papers.nips.cc/paper/2318-adaptive-nonlinear-system-identification-with-echo-state-networks.pdf">pdf</a></p><p>Author: Herbert Jaeger</p><p>Abstract: Echo state networks (ESN) are a novel approach to recurrent neural network training. An ESN consists of a large, fixed, recurrent</p><br/>
<h2>reference text</h2><p>[1] A.F. Atiya and A.G. Parlos. New results on recurrent network training: Unifying the algorithms and accelerating convergence. IEEE Trans. Neural Networks, 11(3):697- 709,2000.</p>
<p>[2] B. Farhang-Boroujeny. Adaptive Filters: Theory and Applications. Wiley, 1998.</p>
<p>[3] L.A. Feldkamp, D.V. Prokhorov, C.F. Eagen, and F. Yuan. Enhanced multistream Kalman filter training for recurrent neural networks. In J .A.K . Suykens and J. Vandewalle, editors, Nonlinear Modeling: Advanced Black-Box Techniques, pages 29- 54. Kluwer, 1998.</p>
<p>[4] J. Hertzberg, H. Jaeger, and F. Schonherr. Learning to ground fact symbols in behavior-based robots. In F. van Harmelen, editor, Proc. 15th Europ. Gonf. on Art. Int. (EGAI 02), pages 708- 712. lOS Press, Amsterdam, 2002.</p>
<p>[5] H. Jaeger. The </p>
<p>[6] H. Jaeger. Short term memory in echo state networks. GMD-Report 152, GMD - German National Research Institute for Computer Science, 2002. http://www.gmd.de/People/Herbert.Jaeger/Publications.html.</p>
<p>[7] H. Jaeger. Tutorial on training recurrent neural networks, covering BPPT, RTRL , EKF and the echo state network approach. GMD Report 159, Fraunhofer Institute AIS , 2002.</p>
<p>[8] W. Maass, T. Natschlaeger, and H. Markram. Real-time computing without stable states: A new framework for neural computation based on perturbations. http://www.cis.tugraz.at/igi/maass/psfiles/LSM-vl06.pdf. 2002.</p>
<p>[9] W. Maass, Th. NatschHiger, and H. Markram. A model for real-time computation in generic neural microcircuits. In S. Becker, S. Thrun, and K. Obermayer , editors, Advances in Neural Information Processing System 15 (Proc. NIPS 2002). MIT Press, 2002.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
