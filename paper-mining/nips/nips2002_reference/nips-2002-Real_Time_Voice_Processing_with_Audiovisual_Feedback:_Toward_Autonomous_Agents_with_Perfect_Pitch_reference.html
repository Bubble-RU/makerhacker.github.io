<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>170 nips-2002-Real Time Voice Processing with Audiovisual Feedback: Toward Autonomous Agents with Perfect Pitch</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-170" href="../nips2002/nips-2002-Real_Time_Voice_Processing_with_Audiovisual_Feedback%3A_Toward_Autonomous_Agents_with_Perfect_Pitch.html">nips2002-170</a> <a title="nips-2002-170-reference" href="#">nips2002-170-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>170 nips-2002-Real Time Voice Processing with Audiovisual Feedback: Toward Autonomous Agents with Perfect Pitch</h1>
<br/><p>Source: <a title="nips-2002-170-pdf" href="http://papers.nips.cc/paper/2289-real-time-voice-processing-with-audiovisual-feedback-toward-autonomous-agents-with-perfect-pitch.pdf">pdf</a></p><p>Author: Lawrence K. Saul, Daniel D. Lee, Charles L. Isbell, Yann L. Cun</p><p>Abstract: We have implemented a real time front end for detecting voiced speech and estimating its fundamental frequency. The front end performs the signal processing for voice-driven agents that attend to the pitch contours of human speech and provide continuous audiovisual feedback. The algorithm we use for pitch tracking has several distinguishing features: it makes no use of FFTs or autocorrelation at the pitch period; it updates the pitch incrementally on a sample-by-sample basis; it avoids peak picking and does not require interpolation in time or frequency to obtain high resolution estimates; and it works reliably over a four octave range, in real time, without the need for postprocessing to produce smooth contours. The algorithm is based on two simple ideas in neural computation: the introduction of a purposeful nonlinearity, and the error signal of a least squares ﬁt. The pitch tracker is used in two real time multimedia applications: a voice-to-MIDI player that synthesizes electronic music from vocalized melodies, and an audiovisual Karaoke machine with multimodal feedback. Both applications run on a laptop and display the user’s pitch scrolling across the screen as he or she sings into the computer.</p><br/>
<h2>reference text</h2><p>[1] P. C. Bagshaw, S. M. Hiller, and M. A. Jack. Enhanced pitch tracking and the processing of f0 contours for computer aided intonation teaching. In Proceedings of the 3rd European Conference on Speech Communication and Technology, volume 2, pages 1003–1006, 1993.</p>
<p>[2] A. S. Bregman. Auditory scene analysis: the perceptual organization of sound. M.I.T. Press, Cambridge, MA, 1994.</p>
<p>[3] M. Cooke and D. P. W. Ellis. The auditory organization of speech and other sources in listeners and computational models. Speech Communication, 35:141–177, 2001.</p>
<p>[4] P. de la Cuadra, A. Master, and C. Sapp. Efﬁcient pitch detection techniques for interactive music. In Proceedings of the 2001 International Computer Music Conference, La Habana, Cuba, September 2001.</p>
<p>[5] B. Gold and L. R. Rabiner. Parallel processing techniques for estimating pitch periods of speech in the time domain. Journal of the Acoustical Society of America, 46(2,2):442–448, August 1969.</p>
<p>[6] W. M. Hartmann. Pitch, periodicity, and auditory organization. Journal of the Acoustical Society of America, 100(6):3491–3502, 1996.</p>
<p>[7] W. Hess. Pitch Determination of Speech Signals: Algorithms and Devices. Springer, 1983.</p>
<p>[8] Y. Medan, E. Yair, and D. Chazan. Super resolution pitch determination of speech signals. IEEE Transactions on Signal Processing, 39(1):40–48, 1991.</p>
<p>[9] A. M. Noll. Cepstrum pitch determination. Journal of the Acoustical Society of America, 41(2):293–309, 1967.</p>
<p>[10] A. M. Noll. Pitch determination of human speech by the harmonic product spectrum, the harmonic sum spectrum, and a maximum likelihood estimate. In Proceedings of the Symposium on Computer Processing in Communication, pages 779–798, April 1969.</p>
<p>[11] M. S. Phillips. A feature-based time domain pitch tracker. Journal of the Acoustical Society of America, 79:S9–S10, 1985.</p>
<p>[12] J. G. Proakis, C. M. Rader, F. Ling, M. Moonen, I. K. Proudler, and C. L. Nikias. Algorithms for Statistical Signal Processing. Prentice Hall, 2002.</p>
<p>[13] L. R. Rabiner. On the use of autocorrelation analysis for pitch determination. IEEE Transactions on Acoustics, Speech, and Signal Processing, 25:22–33, 1977.</p>
<p>[14] L. R. Rabiner and B. H. Juang. Fundamentals of Speech Recognition. Prentice Hall, Englewoods Cliffs, NJ, 1993.</p>
<p>[15] M. R. Schroeder. Period histogram and product spectrum: new methods for fundamental frequency measurement. Journal of the Acoustical Society of America, 43(4):829–834, 1968.</p>
<p>[16] B. G. Secrest and G. R. Doddington. An integrated pitch tracking algorithm for speech systems. In Proceedings of the 1983 IEEE International Conference on Acoustics, Speech, and Signal Processing, pages 1352–1355, Boston, 1983.</p>
<p>[17] K. Stevens. Acoustic Phonetics. M.I.T. Press, Cambridge, MA, 1999.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
