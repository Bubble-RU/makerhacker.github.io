<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>205 nips-2002-Value-Directed Compression of POMDPs</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-205" href="../nips2002/nips-2002-Value-Directed_Compression_of_POMDPs.html">nips2002-205</a> <a title="nips-2002-205-reference" href="#">nips2002-205-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>205 nips-2002-Value-Directed Compression of POMDPs</h1>
<br/><p>Source: <a title="nips-2002-205-pdf" href="http://papers.nips.cc/paper/2192-value-directed-compression-of-pomdps.pdf">pdf</a></p><p>Author: Pascal Poupart, Craig Boutilier</p><p>Abstract: We examine the problem of generating state-space compressions of POMDPs in a way that minimally impacts decision quality. We analyze the impact of compressions on decision quality, observing that compressions that allow accurate policy evaluation (prediction of expected future reward) will not affect decision quality. We derive a set of sufﬁcient conditions that ensure accurate prediction in this respect, illustrate interesting mathematical properties these confer on lossless linear compressions, and use these to derive an iterative procedure for ﬁnding good linear lossy compressions. We also elaborate on how structured representations of a POMDP can be used to ﬁnd such compressions.</p><br/>
<h2>reference text</h2><p>[1] C. Boutilier, R. Dearden, and M. Goldszmidt. Stochastic dynamic programming with factored representations. Artiﬁcial Intelligence, 121:49–107, 2000.</p>
<p>[2] C. Boutilier and D. Poole. Computing optimal policies for partially observable decision processes using compact representations. Proc. AAAI-96, pp.1168–1175, Portland, OR, 1996.</p>
<p>[3] R. Givan, T. Dean, and M. Greig. Equivalence notions and model minimization in Markov decision processes. Artiﬁcial Intelligence, to appear, 2002.</p>
<p>[4] C. Guestrin, D. Koller, and R. Parr. Max-norm projections for factored MDPs. Proc. IJCAI-01, pp.673–680, Seattle, WA, 2001.</p>
<p>[5] C. Guestrin, D. Koller, and R. Parr. Solving factored POMDPs with linear value functions. IJCAI-01 Worksh. on Planning under Uncertainty and Inc. Info., Seattle, WA, 2001.</p>
<p>[6] C. Guestrin and D. Ormoneit. Information-theoretic features for reinforcement learning. Unpublished manuscript.</p>
<p>[7] J. Hoey, R. St-Aubin, A. Hu, and C. Boutilier. SPUDD: Stochastic planning using decision diagrams. Proc. UAI-99, pp.279–288, Stockholm, 1999.</p>
<p>[8] M. L. Littman. Memoryless policies: theoretical limitations and practical results. In D. Cliff, P. Husbands, J. Meyer, S. W. Wilson, eds., Proc. 3rd Intl. Conf. Sim. of Adaptive Behavior, Cambridge, 1994. MIT Press.</p>
<p>[9] M. L. Littman, R. S. Sutton, and S. Singh. Predictive representations of state. Proc.NIPS-02, Vancouver, 2001.</p>
<p>[10] R. A. McCallum. Hidden state and reinforcement learning with instance-based state identiﬁcation. IEEE Transations on Systems, Man, and Cybernetics, 26(3):464–473, 1996.</p>
<p>[11] K. Murphy. A survey of POMDP solution techniques. Technical Report, U.C. Berkeley, 2000.</p>
<p>[12] R. Patrascu, P. Poupart, D. Schuurmans, C. Boutilier, C. Guestrin. Greedy linear valueapproximation for factored Markov decision processes. AAAI-02, pp.285–291, Edmonton, 2002.</p>
<p>[13] A. Pfeffer. Sufﬁciency, separability and temporal probabilistic models. Proc. UAI-01, pp.421– 428, Seattle, WA, 2001.</p>
<p>[14] P. Poupart, C. Boutilier, R. Patrascu, and D. Schuurmans. Piecewise linear value function approximation for factored MDPs. AAAI-02, pp.292–299, Edmonton, 2002.</p>
<p>[15] Y. Saad. Iterative Methods for Sparse Linear Systems. PWS, Boston, 1996.</p>
<p>[16] D. Schuurmans and R. Patrascu. Direct value-approximation for factored MDPs. Proc. NIPS01, Vancouver, 2001.</p>
<p>[17] N. Tishby, F. C. Pereira, and W. Bialek. The information bottleneck method. 37th Annual Allerton Conf. on Comm., Contr. and Computing, pp.368–377, 1999.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
