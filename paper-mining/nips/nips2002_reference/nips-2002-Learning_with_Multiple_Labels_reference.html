<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>135 nips-2002-Learning with Multiple Labels</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-135" href="../nips2002/nips-2002-Learning_with_Multiple_Labels.html">nips2002-135</a> <a title="nips-2002-135-reference" href="#">nips2002-135-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>135 nips-2002-Learning with Multiple Labels</h1>
<br/><p>Source: <a title="nips-2002-135-pdf" href="http://papers.nips.cc/paper/2234-learning-with-multiple-labels.pdf">pdf</a></p><p>Author: Rong Jin, Zoubin Ghahramani</p><p>Abstract: In this paper, we study a special kind of learning problem in which each training instance is given a set of (or distribution over) candidate class labels and only one of the candidate labels is the correct one. Such a problem can occur, e.g., in an information retrieval setting where a set of words is associated with an image, or if classes labels are organized hierarchically. We propose a novel discriminative approach for handling the ambiguity of class labels in the training examples. The experiments with the proposed approach over five different UCI datasets show that our approach is able to find the correct label among the set of candidate labels and actually achieve performance close to the case when each training instance is given a single correct label. In contrast, naIve methods degrade rapidly as more ambiguity is introduced into the labels. 1</p><br/>
<h2>reference text</h2><p>[1] A. P. Dawid and A. M. Skene (1979) Maximum likelihood estimation of observer errorrates using the EM algorithm. Applied Statistics 28:20-28.</p>
<p>[2] A. Dempster, N. Laird and D. Rubin (1977), Maximum likelihood from incomplete data via the EM algorithm, Journal of the Royal Statistical Society, 39 (Series B), 1-38.</p>
<p>[3] T. G. Dietterich, R. H. Lathrop, and T. L.-Perez (1997) Solving the multiple-instance problem with axis-parallel rectangles, Artificial Intelligence, 89(1-2), pp. 31-71.</p>
<p>[4] A. McCallum (1999) Multi-label text classification with a mixture model trained by EM, AAAI'99 Workshop on Text Learning.</p>
<p>[5] S. Della Pietra, V. Della Pietra and J. Lafferty (1997) Inducing feature s of random fields , IEEE Transactions on Pattern Analysis and Machine Intelligence, 19(4): 380-393.</p>
<p>[6] Y. Grandvalet (2002), Logistic regression for partial labels, 9th Information Processing and Managem ent of Uncertainty in Knowledg e-based System (IPMU'02) , pp. 1935-1941.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
