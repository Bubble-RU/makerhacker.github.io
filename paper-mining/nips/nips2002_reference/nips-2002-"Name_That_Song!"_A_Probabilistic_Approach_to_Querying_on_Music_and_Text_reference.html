<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1 nips-2002-"Name That Song!" A Probabilistic Approach to Querying on Music and Text</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-1" href="../nips2002/nips-2002-%22Name_That_Song%21%22_A_Probabilistic_Approach_to_Querying_on_Music_and_Text.html">nips2002-1</a> <a title="nips-2002-1-reference" href="#">nips2002-1-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1 nips-2002-"Name That Song!" A Probabilistic Approach to Querying on Music and Text</h1>
<br/><p>Source: <a title="nips-2002-1-pdf" href="http://papers.nips.cc/paper/2262-name-that-song-a-probabilistic-approach-to-querying-on-music-and-text.pdf">pdf</a></p><p>Author: Brochu Eric, Nando de Freitas</p><p>Abstract: We present a novel, ﬂexible statistical approach for modelling music and text jointly. The approach is based on multi-modal mixture models and maximum a posteriori estimation using EM. The learned models can be used to browse databases with documents containing music and text, to search for music using queries consisting of music and text (lyrics and other contextual information), to annotate text documents with music, and to automatically recommend or identify similar songs.</p><br/>
<h2>reference text</h2><p>[1] D Huron and B Aarden. Cognitive issues and approaches in music information retrieval. In S Downie and D Byrd, editors, Music Information Retrieval. 2002.</p>
<p>[2] J Pickens. A comparison of language modeling and probabilistic text information retrieval approaches to monophonic music retrieval. In International Symposium on Music Information Retrieval, 2000.</p>
<p>[3] J S Downie. Evaluating a Simple Approach to Music Information Retrieval: Conceiving Melodic N-Grams as Text. PhD thesis, University of Western Ontario, 1999.</p>
<p>[4] E Brochu, N de Freitas, and K Bao. The sound of an album cover: Probabilistic multimedia and IR. In C M Bishop and B J Frey, editors, Ninth International Workshop on Artiﬁcial Intelligence and Statistics, Key West, Florida, 2003. To appear.</p>
<p>[5] H H Hoos, K A Hamel, K Renz, and J Kilian. Representing score-level music using the GUIDO music-notation format. Computing in Musicology, 12, 2001.</p>
<p>[6] K Barnard and D Forsyth. Learning the semantics of words and pictures. In International Conference on Computer Vision, volume 2, pages 408– 415, 2001.</p>
<p>[7] T Hofmann. Probabilistic latent semantic analysis. In Uncertainty in Artiﬁcial Intelligence, 1999.</p>
<p>[8] D M Blei, A Y Ng, and M I Jordan. Latent Dirichlet allocation. In T G Dietterich, S Becker, and Z Ghahramani, editors, Advances in Neural Information Processing Systems 14, Cambridge, MA, 2002. MIT Press.</p>
<p>[9] R Baeza-Yates and B Ribeiro-Neto. Modern Information Retrieval. Addison-Wesley, 1999.</p>
<p>[10] S Deerwester, S T Dumais, G W Furnas, T K Landauer, and R Harshman. Indexing by latent semantic indexing. Journal of the American Society for Information Science, 41(6):391– 407, 1990.</p>
<p>[11] P Duygulu, K Barnard, N de Freitas, and D Forsyth. Object recognition as machine translation: Learning a lexicon for a ﬁxed image vocabulary. In ECCV, 2002.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
