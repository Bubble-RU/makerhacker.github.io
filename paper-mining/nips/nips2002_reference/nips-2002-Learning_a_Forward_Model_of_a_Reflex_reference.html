<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>128 nips-2002-Learning a Forward Model of a Reflex</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-128" href="../nips2002/nips-2002-Learning_a_Forward_Model_of_a_Reflex.html">nips2002-128</a> <a title="nips-2002-128-reference" href="#">nips2002-128-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>128 nips-2002-Learning a Forward Model of a Reflex</h1>
<br/><p>Source: <a title="nips-2002-128-pdf" href="http://papers.nips.cc/paper/2245-learning-a-forward-model-of-a-reflex.pdf">pdf</a></p><p>Author: Bernd Porr, Florentin Wörgötter</p><p>Abstract: We develop a systems theoretical treatment of a behavioural system that interacts with its environment in a closed loop situation such that its motor actions inﬂuence its sensor inputs. The simplest form of a feedback is a reﬂex. Reﬂexes occur always “too late”; i.e., only after a (unpleasant, painful, dangerous) reﬂex-eliciting sensor event has occurred. This deﬁnes an objective problem which can be solved if another sensor input exists which can predict the primary reﬂex and can generate an earlier reaction. In contrast to previous approaches, our linear learning algorithm allows for an analytical proof that this system learns to apply feedforward control with the result that slow feedback loops are replaced by their equivalent feed-forward controller creating a forward model. In other words, learning turns the reactive system into a pro-active system. By means of a robot implementation we demonstrate the applicability of the theoretical results which can be used in a variety of different areas in physics and engineering.</p><br/>
<h2>reference text</h2><p>[1] Daniel M. Wolpert and Zoubin Ghahramani. Computational principles of movement neuroscience. Nature Neuroscience supplement, 3:1212–1217, 2000.</p>
<p>[2] P. Read Montague, Peter Dayan, and Terrence J. Sejnowski. Bee foraging in uncertain environments using predictive hebbian learning. Nature, 377:725–728, 1995.</p>
<p>[3] W.E Sollecito and S.G Reque. Stability. In Jerry Fitzgerald, editor, Fundamentals of System Analysis, chapter 21. Wiley, New York, 1981.</p>
<p>[4] R.S. Sutton and A.G. Barto. Towards a modern theory of adaptive networks: expectation and prediction. Psychol. Review, 88:135–170, 1981.</p>
<p>[5] John L. Stewart. Fundamentals of signal theory. Mc Graw-Hill, New York, 1960.</p>
<p>[6] Gordon M. Shepherd, editor. The synaptic organisation of the brain. Oxford University Press, New York, 1990.</p>
<p>[7] Steven Grossberg. A spectral network model of pitch perception. J Acoust Soc Am, 98(2):862–879, 1995.</p>
<p>[8] P.F.M.J Verschure and T. Voegtlin. A bottom-up approach towards the aquisition, retention, and expression of sequential representations: Distributed adaptive control III. Neural Networks, 11:1531–1549, 1998.</p>
<p>[9] William J. Palm. Modeling, Analysis and Control of Dynamic Systems. Wiley, New York, 2000.</p>
<p>[10] R.S. Sutton. Learning to predict by method of temporal differences. Machine learning, 3(1):9–44, 1988.</p>
<p>[11] R.S. Sutton and A.G. Barto. Simulation of anticipatory responses in classical conditioning by a neuron-like adaptive element. Behav. Brain. Res., 4(3):221–235, 1982.</p>
<p>[12] R.A. Rescorla and A.R. Wagner. A theory of pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement. In A.H Black and W.F. Prokasy, editors, Classical conditioning 2, current theory and research, pages 64–99. ACC, New York, 1972.</p>
<p>[13] A. Harry Klopf. A drive-reinforcement model of single neuron function. In John S. Denker, editor, Neural Networks for computing: AIP conference proceedings, volume 151 of AIP conference proceedings, New York, 1986. American Institute of Physics.</p>
<p>[14] Christofer J.C.H Watkins and Peter Dayan. Q-learning. Machine Learning, 8:279– 292, 1992.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
