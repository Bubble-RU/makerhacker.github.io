<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>114 nips-2002-Information Regularization with Partially Labeled Data</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-114" href="../nips2002/nips-2002-Information_Regularization_with_Partially_Labeled_Data.html">nips2002-114</a> <a title="nips-2002-114-reference" href="#">nips2002-114-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>114 nips-2002-Information Regularization with Partially Labeled Data</h1>
<br/><p>Source: <a title="nips-2002-114-pdf" href="http://papers.nips.cc/paper/2199-information-regularization-with-partially-labeled-data.pdf">pdf</a></p><p>Author: Martin Szummer, Tommi S. Jaakkola</p><p>Abstract: Classiﬁcation with partially labeled data requires using a large number of unlabeled examples (or an estimated marginal P (x)), to further constrain the conditional P (y|x) beyond a few available labeled examples. We formulate a regularization approach to linking the marginal and the conditional in a general way. The regularization penalty measures the information that is implied about the labels over covering regions. No parametric assumptions are required and the approach remains tractable even for continuous marginal densities P (x). We develop algorithms for solving the regularization problem for ﬁnite covers, establish a limiting differential equation, and exemplify the behavior of the new regularization approach in simple cases.</p><br/>
<h2>reference text</h2><p>[1] Tommi Jaakkola, Marina Meila, and Tony Jebara. Maximum entropy discrimination. Technical Report AITR-1668, Mass. Inst. of Technology AI lab, 1999. http://www.ai.mit.edu/.</p>
<p>[2] Naftali Tishby and Noam Slonim. Data clustering by markovian relaxation and the information bottleneck method. In Advances in Neural Information Processing Systems (NIPS), volume 13, pages 640–646. MIT Press, 2001.</p>
<p>[3] Stephen Roberts, C. Holmes, and D. Denison. Minimum-entropy data partitioning using reversible jump Markov chain Monte Carlo. IEEE Trans. Pattern Analysis and Mach. Intell. (PAMI), 23(8):909–914, 2001.</p>
<p>[4] Matthias Seeger. Input-dependent regularization of conditional density models. Unpublished. http://www.dai.ed.ac.uk/homes/seeger/, 2001.</p>
<p>[5] Thomas Cover and Joy Thomas. Elements of Information Theory. Wiley, 1991.</p>
<p>[6] Robert Weinstock. Calculus of Variations. Dover, 1974.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
