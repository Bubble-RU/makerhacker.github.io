<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>118 nips-2002-Kernel-Based Extraction of Slow Features: Complex Cells Learn Disparity and Translation Invariance from Natural Images</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-118" href="../nips2002/nips-2002-Kernel-Based_Extraction_of_Slow_Features%3A_Complex_Cells_Learn_Disparity_and_Translation_Invariance_from_Natural_Images.html">nips2002-118</a> <a title="nips-2002-118-reference" href="#">nips2002-118-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>118 nips-2002-Kernel-Based Extraction of Slow Features: Complex Cells Learn Disparity and Translation Invariance from Natural Images</h1>
<br/><p>Source: <a title="nips-2002-118-pdf" href="http://papers.nips.cc/paper/2209-kernel-based-extraction-of-slow-features-complex-cells-learn-disparity-and-translation-invariance-from-natural-images.pdf">pdf</a></p><p>Author: Alistair Bray, Dominique Martinez</p><p>Abstract: In Slow Feature Analysis (SFA [1]), it has been demonstrated that high-order invariant properties can be extracted by projecting inputs into a nonlinear space and computing the slowest changing features in this space; this has been proposed as a simple general model for learning nonlinear invariances in the visual system. However, this method is highly constrained by the curse of dimensionality which limits it to simple theoretical simulations. This paper demonstrates that by using a different but closely-related objective function for extracting slowly varying features ([2, 3]), and then exploiting the kernel trick, this curse can be avoided. Using this new method we show that both the complex cell properties of translation invariance and disparity coding can be learnt simultaneously from natural images when complex cells are driven by simple cells also learnt from the image. The notion of maximising an objective function based upon the temporal predictability of output has been progressively applied in modelling the development of invariances in the visual system. F6ldiak used it indirectly via a Hebbian trace rule for modelling the development of translation invariance in complex cells [4] (closely related to many other models [5,6,7]); this rule has been used to maximise invariance as one component of a hierarchical system for object and face recognition [8]. On the other hand, similar functions have been maximised directly in networks for extracting linear [2] and nonlinear [9, 1] visual invariances. Direct maximisation of such functions have recently been used to model complex cells [10] and as an alternative to maximising sparseness/independence in modelling simple cells [11]. Slow Feature Analysis [1] combines many of the best properties of these methods to provide a good general nonlinear model. That is, it uses an objective function that minimises the first-order temporal derivative of the outputs; it provides a closedform solution which maximises this function by projecting inputs into a nonlinear http://www.loria.fr/equipes/cortex/ space; it exploits sphering (or PCA-whitening) of the data to ensure that all outputs have unit variance and are uncorrelated. However, the method suffers from the curse of dimensionality in that the nonlinear feature space soon becomes very large as the input dimension grows, and yet this feature space must be represented explicitly in order for the essential sphering to occur. The alternative that we propose here is to use the objective function of Stone [2, 9], that maximises output variance over a long period whilst minimising variance over a shorter period; in the linear case, this can be implemented by a biologically plausible mixture of Hebbian and anti-Hebbian learning on the same synapses [2]. In recent work, Stone has proposed a closed-form solution for maximising this function in the linear domain of blind source separation that does not involve data-sphering. This paper describes how this method can be kernelised. The use of the</p><br/>
<h2>reference text</h2><p>[1] L. Wiskott and T .J . Sejnowski. Slow feature analysis: Unsupervised learning of invariances. Neural Computation, 14(4) , 2002.</p>
<p>[2] J. V. Stone and A. J. Bray. A learning rule for extracting spatio-temporal invariances. Network: Computation in Neural Syst ems, 6(3):429- 436 , 1995.</p>
<p>[3] James V. Stone. Blind source separation using temporal predictability. Neural Computation, (13):1559- 1574, 200l.</p>
<p>[4] P. Foldiak. Learning invariance from transformation sequences. Neural Computation, 3(2):194- 200, 1991.</p>
<p>[5] H. G. Barrow and A. J. Bray. A model of adaptive development of complex cortical cells. In 1. Aleksander and J. Taylor, editors, Artificial Neural Networks II: Proceedings of the International Conference on Artificial Neural Networks. Elsevier Publishers, 1992 .</p>
<p>[6] K. Fukushima. Self-organisation of shift-invariant receptive fields. N eural N etworks, 12:826- 834, 1999.</p>
<p>[7] M. Stewart Bartlett and T.J. Sejnowski. Learning viewpoint invariant face representations from visual experience in an attractor network. Network: Computation in Neural Systems, 9(3):399- 417, 1998.</p>
<p>[8] E. T . Rolls and T. Milward. A model of invariant object recognition in the visual system: Learning rules, activation functions , lateral inhibition, and information-based performance measures. Neural Computation, 12:2547- 2572, 2000.</p>
<p>[9] J. V. Stone. Learning perceptually salient visual parameters using spatiotemporal smoothness constraints. N eural Computation, 8(7):1463- 1492, October 1996.</p>
<p>[10] K. Kayser, W. Einhiiuser, O. Dummer, P. Konig, and K. Kording. Extracting slow subspaces from natural videos leads to complex cells. In ICANN 2001, LNCS 2130, pages 1075- 1080. Springer-Verlag Berlin Heidelberg 2001 , 200l.</p>
<p>[11] J. Hurri and A. Hyvarinen. Simple-cell-like receptive fields maximise temporal coherence in natural video. Submitted, http://www.cis.hut.fi/)armo/publications. 2002.</p>
<p>[12] D. Martinez and A. Bray. Nonlinear blind source separation using kernels. IEEE Trans. Neural Networks, 14(1):228- 235, Jan. 2003.</p>
<p>[13] G . Baudat and F . Anouar. Kernel-based methods and function approximation. International Joint Conference of Neural Networks IJCNN, pages 1244-1249, 200l.</p>
<p>[14] A. J. Bell and T. J. Sejnowski. The independent components of natural scenes are edge filters . Vision Res earch, 37:3327- 3338, 1997.</p>
<p>[15] B.A. Olhausen and D.J. Field. Emergence of simple-cell receptive field properties by learning a sparse code for natural images. Nature , 381:607- 609, 1996.</p>
<p>[16] E .T . Rolls and G . Deco. Computational Neuroscience of Vision. Oxford University Press, 2002.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
