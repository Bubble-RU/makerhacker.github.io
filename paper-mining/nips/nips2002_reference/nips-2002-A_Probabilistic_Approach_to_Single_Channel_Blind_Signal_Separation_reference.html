<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>14 nips-2002-A Probabilistic Approach to Single Channel Blind Signal Separation</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-14" href="../nips2002/nips-2002-A_Probabilistic_Approach_to_Single_Channel_Blind_Signal_Separation.html">nips2002-14</a> <a title="nips-2002-14-reference" href="#">nips2002-14-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>14 nips-2002-A Probabilistic Approach to Single Channel Blind Signal Separation</h1>
<br/><p>Source: <a title="nips-2002-14-pdf" href="http://papers.nips.cc/paper/2224-a-probabilistic-approach-to-single-channel-blind-signal-separation.pdf">pdf</a></p><p>Author: Gil-jin Jang, Te-Won Lee</p><p>Abstract: We present a new technique for achieving source separation when given only a single channel recording. The main idea is based on exploiting the inherent time structure of sound sources by learning a priori sets of basis ﬁlters in time domain that encode the sources in a statistically efﬁcient manner. We derive a learning algorithm using a maximum likelihood approach given the observed single channel data and sets of basis ﬁlters. For each time point we infer the source signals and their contribution factors. This inference is possible due to the prior knowledge of the basis ﬁlters and the associated coefﬁcient densities. A ﬂexible model for density estimation allows accurate modeling of the observation and our experimental results exhibit a high level of separation performance for mixtures of two music signals as well as the separation of two voice signals.</p><br/>
<h2>reference text</h2><p>[1] G. J. Brown and M. Cooke, “Computational auditory scene analysis,” Computer Speech and Language, vol. 8, no. 4, pp. 297–336, 1994.</p>
<p>[2] P. Comon, “Independent component analysis, A new concept?,” Signal Processing, vol. 36, pp. 287–314, 1994.</p>
<p>[3] E. Wan and A. T. Nelson, “Neural dual extended kalman ﬁltering: Applications in speech enhancement and monaural blind signal separation,” in Proc. of IEEE Workshop on Neural Networks and Signal Processing, 1997.</p>
<p>[4] J. Hopgood and P. Rayner, “Single channel signal separation using linear time-varying ﬁlters: Separability of non-stationary stochastic signals,” in Proc. ICASSP, vol. 3, (Phoenix, Arizona), pp. 1449–1452, March 1999.</p>
<p>[5] S. T. Roweis, “One microphone source separation,” Advances in Neural Information Processing Systems, vol. 13, pp. 793–799, 2001.</p>
<p>[6] S. Rickard, R. Balan, and J. Rosca, “Real-time time-frequency based blind source separation,” in Proc. of International Conference on Independent Component Analysis and Signal Separation (ICA2001), (San Diego, CA), pp. 651–656, December 2001.</p>
<p>[7] T.-W. Lee and G.-J. Jang, “The statistical structures of male and female speech signals,” in Proc. ICASSP, (Salt Lake City, Utah), May 2001.</p>
<p>[8] A. J. Bell and T. J. Sejnowski, “Learning the higher-order structures of a natural sound,” Network: Computation in Neural Systems, vol. 7, pp. 261–266, July 1996.</p>
<p>[9] T.-W. Lee and M. S. Lewicki, “The generalized Gaussian mixture model using ICA,” in International Workshop on Independent Component Analysis (ICA’00), (Helsinki, Finland), pp. 239–244, June 2000.</p>
<p>[10] B. Pearlmutter and L. Parra, “A context-sensitive generalization of ICA,” in Proc. ICONIP, (Hong Kong), pp. 151–157, September 1996.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
