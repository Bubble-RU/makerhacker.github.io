<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>96 nips-2002-GeneralizedÂ˛ LinearÂ˛ Models</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-96" href="../nips2002/nips-2002-Generalized%C3%82%CB%9B_Linear%C3%82%CB%9B_Models.html">nips2002-96</a> <a title="nips-2002-96-reference" href="#">nips2002-96-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>96 nips-2002-GeneralizedÂ˛ LinearÂ˛ Models</h1>
<br/><p>Source: <a title="nips-2002-96-pdf" href="http://papers.nips.cc/paper/2144-generalized2-linear2-models.pdf">pdf</a></p><p>Author: Geoffrey J. Gordon</p><p>Abstract: We introduce the Generalized 2 Linear 2 Model, a statistical estimator which combines features of nonlinear regression and factor analysis. A (GL)2M approximately decomposes a rectangular matrix X into a simpler representation j(g(A)h(B)). Here A and Bare low-rank matrices, while j, g, and h are link functions. (GL)2Ms include many useful models as special cases, including principal components analysis, exponential-family peA, the infomax formulation of independent components analysis, linear regression, and generalized linear models. They also include new and interesting special cases, one of which we describe below. We also present an iterative procedure which optimizes the parameters of a (GL)2M. This procedure reduces to well-known algorithms for some of the special cases listed above; for other special cases, it is new. 1</p><br/>
<h2>reference text</h2><p>[1] T. K. Landauer, P . W . Foltz , and D. Laham . Introduction to latent semantic analysis . Discourse Processes, 25:259- 284, 1998.</p>
<p>[2] Jon M. Kleinberg. Authoritative sources in a hyperlinked environment. Journal of the ACM, 46(5) :604-632, 1999.</p>
<p>[3] M. Turk and A. Pentland. Eigenfaces for recognition. Journal of Cognitive Neuroscience, 3(1) :71-86, 1991.</p>
<p>[4] Carlo Tomasi and Takeo Kanade. Shape and motion from image streams under orthography: a factorization method. Int. J. Computer Vision , 9(2):137- 154, 1992.</p>
<p>[5] D. P. O'Leary and S. Peleg. Digital image compression by outer product expansion. IEEE Trans . Communications, 31:441-444, 1983.</p>
<p>[6] P . McCullagh and J. A. Neider. Generalized Linear Models. Chapman & Hall, London, 2nd edition, 1983.</p>
<p>[7] Peter Auer, Mark Hebster, and Manfred K. Warmuth. Exponentially many local minima for single neurons. In NIPS, vol. 8. MIT Press, 1996.</p>
<p>[8] R. Tyrell Rockafellar. Convex Analysis. Princeton University Press, New Jersey, 1970.</p>
<p>[9] Geoffrey J. Gordon. Approximate Solutions to Markov Decision Processes. thesis, Carnegie Mellon University, 1999.  PhD</p>
<p>[10] Daniel Lee and H. Sebastian Seung. Algorithms for nonnegative matrix factorization. In NIPS, vol. 13. MIT Press, 2001.</p>
<p>[11] Nathan Srebro. Personal communication, 2002.</p>
<p>[12] Anthony J . Bell and Terrence J. Sejnowski. The 'independent components' of natural scenes are edge filters. Vision Research, 37(23) :3327- 3338, 1997.</p>
<p>[13] Michael Collins, Sanjoy Dasgupta, and Robert Schapire. A generalization of principal component analysis to the exponential family. In NIPS, vol. 14. MIT Press, 2002 .</p>
<p>[14] D. Fox, W. Burgard, F . Dellaert , and S. Thrun. Monte Carlo localization: Efficient position estimation for mobile robots. In AAAI, 1999.</p>
<p>[15] Nicholas Roy and Geoffrey J. Gordon. Exponential family PCA for belief compression in POMDPs. In NIPS, vol. 15 . MIT Press, 2003.</p>
<p>[16] Sam Roweis. EM algorithms for PCA and SPCA. In NIPS, vol. 10. MIT Press, 1998.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
