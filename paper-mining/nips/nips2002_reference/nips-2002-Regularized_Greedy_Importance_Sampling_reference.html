<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>174 nips-2002-Regularized Greedy Importance Sampling</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-174" href="../nips2002/nips-2002-Regularized_Greedy_Importance_Sampling.html">nips2002-174</a> <a title="nips-2002-174-reference" href="#">nips2002-174-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>174 nips-2002-Regularized Greedy Importance Sampling</h1>
<br/><p>Source: <a title="nips-2002-174-pdf" href="http://papers.nips.cc/paper/2191-regularized-greedy-importance-sampling.pdf">pdf</a></p><p>Author: Finnegan Southey, Dale Schuurmans, Ali Ghodsi</p><p>Abstract: Greedy importance sampling is an unbiased estimation technique that reduces the variance of standard importance sampling by explicitly searching for modes in the estimation objective. Previous work has demonstrated the feasibility of implementing this method and proved that the technique is unbiased in both discrete and continuous domains. In this paper we present a reformulation of greedy importance sampling that eliminates the free parameters from the original estimator, and introduces a new regularization strategy that further reduces variance without compromising unbiasedness. The resulting estimator is shown to be effective for difﬁcult estimation problems arising in Markov random ﬁeld inference. In particular, improvements are achieved over standard MCMC estimators when the distribution has multiple peaked modes.</p><br/>
<h2>reference text</h2><p>[1] D. Ackley, G. Hinton, and T. Sejnowski. A learning algorithm for Boltzmann machines. Cognitive Science, 9:147–169, 1985.</p>
<p>[2] P. Dagum and M. Luby. Approximating probabilistic inference in Bayesian belief networks is NP-hard. Artiﬁcial Intelligence, 60:141–153, 1993.</p>
<p>[3] P. Dagum and M. Luby. An optimal approximation algorithm for Bayesian inference. Artiﬁcial Intelligence, 93:1–27, 1997.</p>
<p>[4] J. Geweke. Baysian inference in econometric models using Monte Carlo integration. Econometrica, 57:1317–1339, 1989.</p>
<p>[5] W. Gilks, S. Richardson, and D. Spiegelhalter. Markov Chain Monte Carlo in Practice. Chapman and Hall, 1996.</p>
<p>[6] M. Jordan, Z. Ghahramani, T. Jaakkola, and L. Saul. An introduction to variational methods for graphical models. In Learning in Graphical Models. Kluwer, 1998.</p>
<p>[7] D. MacKay. Intro to Monte Carlo methods. In Learning in Graphical Models. Kluwer, 1998.</p>
<p>[8] R. Neal. Probabilistic inference using Markov chain Monte Carlo methods. Tech report, 1993.</p>
<p>[9] J. Propp and D. Wilson. Exact sampling with coupled Markov chains and applications to statistical mechanics. Random Structures and Algorithms, 9:223–253, 1996.</p>
<p>[10] R. Rubinstein. Simulation and the Monte Carlo Method. Wiley, New York, 1981.</p>
<p>[11] D. Schuurmans. Greedy importance sampling. In Proceedings NIPS-12, 1999.</p>
<p>[12] D. Schuurmans and F. Southey. Monte Carlo inference via greedy importance sampling. In Proceedings UAI, 2000.</p>
<p>[13] R. Swendsen, J. Wang, and A. Ferrenberg. New Monte Carlo methods for improved efﬁciency of computer simulations in statistical mechanics. In The Monte Carlo Method in Condensed Matter Physics. Springer, 1992.</p>
<p>[14] M. Tanner. Tools for Statistical Inference: Methods for Exploration of Posterior Distributions and Likelihood Functions. Springer, New York, 1993.</p>
<p>[15] D. Wilson. Sampling conﬁgurations of an Ising system. In Proceedings SODA, 1999.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
