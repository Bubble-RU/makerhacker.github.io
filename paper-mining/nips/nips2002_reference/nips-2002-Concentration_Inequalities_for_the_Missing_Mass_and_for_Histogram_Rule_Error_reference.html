<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>56 nips-2002-Concentration Inequalities for the Missing Mass and for Histogram Rule Error</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-56" href="../nips2002/nips-2002-Concentration_Inequalities_for_the_Missing_Mass_and_for_Histogram_Rule_Error.html">nips2002-56</a> <a title="nips-2002-56-reference" href="#">nips2002-56-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>56 nips-2002-Concentration Inequalities for the Missing Mass and for Histogram Rule Error</h1>
<br/><p>Source: <a title="nips-2002-56-pdf" href="http://papers.nips.cc/paper/2248-concentration-inequalities-for-the-missing-mass-and-for-histogram-rule-error.pdf">pdf</a></p><p>Author: Luis E. Ortiz, David A. McAllester</p><p>Abstract: This paper gives distribution-free concentration inequalities for the missing mass and the error rate of histogram rules. Negative association methods can be used to reduce these concentration problems to concentration questions about independent sums. Although the sums are independent, they are highly heterogeneous. Such highly heterogeneous independent sums cannot be analyzed using standard concentration inequalities such as Hoeffding’s inequality, the Angluin-Valiant bound, Bernstein’s inequality, Bennett’s inequality, or McDiarmid’s theorem.</p><br/>
<h2>reference text</h2><p>[1] D. Anguluin and L. Valiant. Fast probabalistic algorithms for hamiltonian circuits. Journal of Computing Systems Science, 18:155–193, 1979.</p>
<p>[2] G. Bennnett. Probability inequalities for the sum of independent ranndom variables. Journal of the American Statistical Association, 57:33–45, 1962.</p>
<p>[3] S. Bernstein. The Theory of Probabilities. Gastehizdat Publishing House, Moscow, 1946.</p>
<p>[4] Stanley Chen and Joshua Goodman. An empirical study of smoothing techniques for language modeling, August 1998. Technical report TR-10-98, Harvard University.</p>
<p>[5] H. Chernoff. A measure of the asymptotic efﬁciency of tests of a hypothesis based on the sum of observations. Annals of Mathmematical Statistics, 23:493–507, 1952.</p>
<p>[6] Kenneth W. Church and William A. Gale. A comparison of the enhanced Good-Turing and deleted estimation methods for estimating probabilities of English bigrams. Computer Speech and Language, 5:19–54, 1991.</p>
<p>[7] Luc Devroye, L´ szl´ Gy¨ rﬁ, and G´ bor Lugosi. A Probabilistic Theory of Pattern Recognition. a o o a Springer, 1996.</p>
<p>[8] Devdatt P. Dubhashi and Desh Ranjan. Balls and bins: A study in negative dependence. Random Structures and Algorithms, 13(2):99–124, 1998.</p>
<p>[9] I. J. Good. The population frequencies of species and the estimation of population parameters. Biometrika, 40(16):237–264, December 1953.</p>
<p>[10] T. Hagerup and C. R¨ b. A guided tour of chernoff bounds. Information Processing Letters, u 33:305–309, 1989.</p>
<p>[11] W. Hoeffding. Probability inequalities for sums of bounded random variables. Journal of the American Statistical Association, 58:13–30, 1963.</p>
<p>[12] Slava M. Katz. Estimation of probabilities from sparse data for the language model component of a speech recognizer. IEEE Transactions on Acoustics, Speech and Signal Processing, ASSP35(3):400–401, March 1987.</p>
<p>[13] Michael Kearns and Lawrence Saul. Large deviation methods for approximate probabilistic inference, with rates of convergence. In UAI-98, pages 311–319. Morgan Kaufmann, 1998.</p>
<p>[14] Samuel Kutin. Algorithmic Stability and Ensemble-Based Learning. PhD thesis, University of Chicago, 2002.</p>
<p>[15] David McAllester and Robert Schapire. On the convergence rate of good-turing estimators. In COLT00, 2000.</p>
<p>[16] Luis E. Ortiz and Leslie Pack Kaelbling. Sampling methods for action selection in inﬂuence diagrams. In Proceedings of the Seventeenth National Conference on Artiﬁcial Intelligence, pages 378–385, 2000.</p>
<p>[17] Anand Srivastav and Peter Stangier. Integer multicommodity ﬂows with reduced demands. In European Symposium on Algorithms, pages 360–371, 1993.  (30) (31)</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
