<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>81 nips-2000-Learning Winner-take-all Competition Between Groups of Neurons in Lateral Inhibitory Networks</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2000" href="../home/nips2000_home.html">nips2000</a> <a title="nips-2000-81" href="../nips2000/nips-2000-Learning_Winner-take-all_Competition_Between_Groups_of_Neurons_in_Lateral_Inhibitory_Networks.html">nips2000-81</a> <a title="nips-2000-81-reference" href="#">nips2000-81-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>81 nips-2000-Learning Winner-take-all Competition Between Groups of Neurons in Lateral Inhibitory Networks</h1>
<br/><p>Source: <a title="nips-2000-81-pdf" href="http://papers.nips.cc/paper/1829-learning-winner-take-all-competition-between-groups-of-neurons-in-lateral-inhibitory-networks.pdf">pdf</a></p><p>Author: Xiaohui Xie, Richard H. R. Hahnloser, H. Sebastian Seung</p><p>Abstract: It has long been known that lateral inhibition in neural networks can lead to a winner-take-all competition, so that only a single neuron is active at a steady state. Here we show how to organize lateral inhibition so that groups of neurons compete to be active. Given a collection of potentially overlapping groups, the inhibitory connectivity is set by a formula that can be interpreted as arising from a simple learning rule. Our analysis demonstrates that such inhibition generally results in winner-take-all competition between the given groups, with the exception of some degenerate cases. In a broader context, the network serves as a particular illustration of the general distinction between permitted and forbidden sets, which was introduced recently. From this viewpoint, the computational function of our network is to store and retrieve memories as permitted sets of coactive neurons. In traditional winner-take-all networks, lateral inhibition is used to enforce a localized, or</p><br/>
<h2>reference text</h2><p>[1] R. Hahnloser, R. Sarpeshkar, M. Mahowald, Douglas R., and H.S. Seung. Digital selection and  analog amplification coexist in an electronic circuit inspired by neocortex. Nature, 3:609- 616, 2000.</p>
<p>[2] Shun-Ichi Amari and Michael A. Arbib. Competition and Cooperation in Neural Nets, pages 119- 165. Systems Neuroscience. Academic Press, 1977. J. Metzler (ed).</p>
<p>[3] 1. Feng and K.P. Hadeler. Qualitative behaviour of some simple networks. 1. Phys. A:, 29:50195033, 1996.</p>
<p>[4] Richard H.R. Hahnloser. About the piecewise analysis of networks of linear threshold neurons . Neural Networks, 11:691- 697, 1998.</p>
<p>[5] T. Kohonen . Self-Organization and Associative Memory. Springer-Verlag, Berlin, 3 edition, 1989.</p>
<p>[6] D. D. Lee and H. S. Seung. Learning the parts of objects by nonnegative matrix factorization. Nature, 401:788- 91, 1999.</p>
<p>[7] B. A. Olshausen and D. 1. Field. Emergence of simple-cell receptive field properties by learning a sparse code for natural images. Nature, 381:607-609, 1996.</p>
<p>[8] R. Ben-Yishai, R. Lev Bar-Or, and H. Sompolinsky. Theory of orientation tuning in visual cortex. Proc. Natl. Acad. Sci. USA , 92:3844-3848, 1995.</p>
<p>[9] 1. J. Hopfield. Neurons with graded response have collective properties like those of two-state neurons . Proc. Natl. Acad. Sci. USA, 81:3088- 3092, 1984.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
