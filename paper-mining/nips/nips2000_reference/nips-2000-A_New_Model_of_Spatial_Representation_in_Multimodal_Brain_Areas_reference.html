<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>8 nips-2000-A New Model of Spatial Representation in Multimodal Brain Areas</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2000" href="../home/nips2000_home.html">nips2000</a> <a title="nips-2000-8" href="../nips2000/nips-2000-A_New_Model_of_Spatial_Representation_in_Multimodal_Brain_Areas.html">nips2000-8</a> <a title="nips-2000-8-reference" href="#">nips2000-8-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>8 nips-2000-A New Model of Spatial Representation in Multimodal Brain Areas</h1>
<br/><p>Source: <a title="nips-2000-8-pdf" href="http://papers.nips.cc/paper/1834-a-new-model-of-spatial-representation-in-multimodal-brain-areas.pdf">pdf</a></p><p>Author: Sophie Denève, Jean-René Duhamel, Alexandre Pouget</p><p>Abstract: Most models of spatial representations in the cortex assume cells with limited receptive fields that are defined in a particular egocentric frame of reference. However, cells outside of primary sensory cortex are either gain modulated by postural input or partially shifting. We show that solving classical spatial tasks, like sensory prediction, multi-sensory integration, sensory-motor transformation and motor control requires more complicated intermediate representations that are not invariant in one frame of reference. We present an iterative basis function map that performs these spatial tasks optimally with gain modulated and partially shifting units, and tests it against neurophysiological and neuropsychological data. In order to perform an action directed toward an object, it is necessary to have a representation of its spatial location. The brain must be able to use spatial cues coming from different modalities (e.g. vision, audition, touch, proprioception), combine them to infer the position of the object, and compute the appropriate movement. These cues are in different frames of reference corresponding to different sensory or motor modalities. Visual inputs are primarily encoded in retinotopic maps, auditory inputs are encoded in head centered maps and tactile cues are encoded in skin-centered maps. Going from one frame of reference to the other might seem easy. For example, the head-centered position of an object can be approximated by the sum of its retinotopic position and the eye position. However, positions are represented by population codes in the brain, and computing a head-centered map from a retinotopic map is a more complex computation than the underlying sum. Moreover, as we get closer to sensory-motor areas it seems reasonable to assume Spksls 150 100 50 o Figure 1: Response of a VIP cell to visual stimuli appearing in different part of the screen, for three different eye positions. The level of grey represent the frequency of discharge (In spikes per seconds). The white cross is the fixation point (the head is fixed). The cell's receptive field is moving with the eyes, but only partially. Here the receptive field shift is 60% of the total gaze shift. Moreover this cell is gain modulated by eye position (adapted from Duhamel et al). that the representations should be useful for sensory-motor transformations, rather than encode an</p><br/>
<h2>reference text</h2><p>[1] R. Andersen, R. Bracewell, S. Barash, J. Gnadt, and L. Fogassi. Eye position effect on visual memory and saccade-related activity in areas LIP and 7a of macaque. Journal of Neuroscience, 10:1176-1196,1990.</p>
<p>[2] J. Duhamel, F. Bremmer, S. BenHamed, and W. Graf. Spacial invariance of visual receptive fields in parietal cortex. Nature, 389(6653):845-848,1997.</p>
<p>[3] M. Jay and D. Sparks. Sensorimotor integration in the primate superior colliculus:l. motor convergence. Journal of Neurophysiology, 57:22-34, 1987.</p>
<p>[4] A. Pouget and T. Sejnowski. Spatial transformations in the parietal cortex using basis functions. Journal of Cognitive Neuroscience, 9(2), 1997.</p>
<p>[5] B. Stricanne, P. Mazzoni, and R. Andersen. Modulation by the eye position of auditory responses of macaque area LIP in an auditory memory saccade task. In Society For Neuroscience Abstracts, page 26, Washington, D.C., 1993.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
