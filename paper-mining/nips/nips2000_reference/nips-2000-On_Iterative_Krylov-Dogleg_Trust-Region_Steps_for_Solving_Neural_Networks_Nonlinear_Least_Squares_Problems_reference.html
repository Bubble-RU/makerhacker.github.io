<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>93 nips-2000-On Iterative Krylov-Dogleg Trust-Region Steps for Solving Neural Networks Nonlinear Least Squares Problems</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2000" href="../home/nips2000_home.html">nips2000</a> <a title="nips-2000-93" href="../nips2000/nips-2000-On_Iterative_Krylov-Dogleg_Trust-Region_Steps_for_Solving_Neural_Networks_Nonlinear_Least_Squares_Problems.html">nips2000-93</a> <a title="nips-2000-93-reference" href="#">nips2000-93-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>93 nips-2000-On Iterative Krylov-Dogleg Trust-Region Steps for Solving Neural Networks Nonlinear Least Squares Problems</h1>
<br/><p>Source: <a title="nips-2000-93-pdf" href="http://papers.nips.cc/paper/1805-on-iterative-krylov-dogleg-trust-region-steps-for-solving-neural-networks-nonlinear-least-squares-problems.pdf">pdf</a></p><p>Author: Eiji Mizutani, James Demmel</p><p>Abstract: This paper describes a method of dogleg trust-region steps, or restricted Levenberg-Marquardt steps, based on a projection process onto the Krylov subspaces for neural networks nonlinear least squares problems. In particular, the linear conjugate gradient (CG) method works as the inner iterative algorithm for solving the linearized Gauss-Newton normal equation, whereas the outer nonlinear algorithm repeatedly takes so-called</p><br/>
<h2>reference text</h2><p>[1] E. Mizutani, S. E. Dreyfus, and J.-S. R. Jang. On dynamic programming-like recursive gradient formula for alleviating hidden-node satuaration in the parity problem. In Proceedings of the International Workshop on Intelligent Systems Resolutions - the 8th Bellman Continuum, pages 100- 104, Hsinchu, TAIWAN, 2000.</p>
<p>[2] Eiji Mizutani. Powell's dogleg trust-region steps with the quasi-Newton augmented Hessian for neural nonlinear least-squares learning. In Pr'oceedings of the IEEE Int'l Conf. on Neural Networks (vol.2), pages 1239-1244, Washington, D.C., JuJy 1999.</p>
<p>[3] R. S. Dembo and T. Steihaug. Truncated-Newton algorithms for large-scale unconstrained optimization. Math. Prog., 26:190-212, 1983.</p>
<p>[4] Trond Steihaug. The conjugate gradient method and trust regions in large scale optimization. SIAM J. Numer. Anal., 20(3):626- 637, 1983.</p>
<p>[5] P. L. Toint. On large scale nonlinear least squares calculations. SIAM J. Sci . Statist. Comput., 8(3):416- 435, 1987.</p>
<p>[6] H. Demuth and M . Beale. Neural Network Toolbox ror Use with MATLAB . The MathWorks, Inc., Natick, Massachusetts, 1998. User's Guide (version 3.0).</p>
<p>[7] Timothy Masters. Advanced algorithms for neural networ'ks: a C++ sourcebook. John Wiley & Sons, New York, 1995.</p>
<p>[8] Adrian J. Shepherd. Second-Order Methods for Neural Networks: Fast and Reliable Training Methods for Multi-Layer Perceptrons. Springer-Verlag, 1997.</p>
<p>[9] Eiji Mizutani. Computing Powell's dogleg steps for solving adaptive networks nonlinear least-squares problems. In Proc. of the 8th Tnt'l Fuzzy Systems Association World Congress (IFSA '99), vol.2, pages 959- 963, Hsinchu, Taiwan, August 1999.</p>
<p>[10] M . J. D. Powell. A new algorithm for unconstrained optimization. In Nonlinear Pr'ogramming, pages 31-65. Edited by J.B. Rosen et al., Academic Press, 1970.</p>
<p>[11] James W. Demmel. Applied Numerical Linear Algebra. SIAM, 1997.</p>
<p>[12] Eiji Mizutani and James W. Demmel. On generalized dogleg trust-region steps using the Krylov subspace for solving neural networks nonlinear least squares problems. Technical report, Computer Science Dept., UC Berkeley, 2001. (In preparation).</p>
<p>[13] E. Mizutani and J.-S. R. Jang. Chapter 6: Derivative-based Optimization. In Neuro Fuzzy and Soft Computing, pages 129- 172. J.-S. R. Jang, C.-T. Sun and E. Mizutani. Prentice Hall, 1997.</p>
<p>[14] Martin Fodslette Moller. A scaled conjugate gradient algorithm for fast supervised learning. N eural Networ'ks, 6:525-533, 1993.</p>
<p>[15] B. A. Pearlmutter. Fast exact multiplication by the Hessian. Neural Computation, 6(1):147-160, 1994.</p>
<p>[16] E. Mizutani, K. Nishio, N. Katoh, and M. Blasgen. Color device characterization of electronic cameras by solving adaptive networks nonlinear least squares problems. In Proc. of the 8th IEEE Int'l Conf. on Fuzzy Systems, vol. 2, pages 858- 862, 1999.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
