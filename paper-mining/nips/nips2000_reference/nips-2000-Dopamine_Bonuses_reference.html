<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>43 nips-2000-Dopamine Bonuses</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2000" href="../home/nips2000_home.html">nips2000</a> <a title="nips-2000-43" href="../nips2000/nips-2000-Dopamine_Bonuses.html">nips2000-43</a> <a title="nips-2000-43-reference" href="#">nips2000-43-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>43 nips-2000-Dopamine Bonuses</h1>
<br/><p>Source: <a title="nips-2000-43-pdf" href="http://papers.nips.cc/paper/1872-dopamine-bonuses.pdf">pdf</a></p><p>Author: Sham Kakade, Peter Dayan</p><p>Abstract: Substantial data support a temporal difference (TO) model of dopamine (OA) neuron activity in which the cells provide a global error signal for reinforcement learning. However, in certain circumstances, OA activity seems anomalous under the TO model, responding to non-rewarding stimuli. We address these anomalies by suggesting that OA cells multiplex information about reward bonuses, including Sutton's exploration bonuses and Ng et al's non-distorting shaping bonuses. We interpret this additional role for OA in terms of the unconditional attentional and psychomotor effects of dopamine, having the computational role of guiding exploration. 1</p><br/>
<h2>reference text</h2><p>[1] Bertsekas, DP & Tsitsitklis, IN (1996). Neuro-dynamic Programming. Cambridge, MA: Athena Scientific.</p>
<p>[2] Cohen, JD, Braver, TS & O'Reilly, RC (1998). In AC Roberts, TW Robbins, editors, The Prefrontal Cortex: Executive and Cognitive Functions. Oxford: OUP.</p>
<p>[3] Dayan, P, & Sejnowski, TJ (1996) . Machine Learning, 25: 5-22.</p>
<p>[4] Horvitz, Je, Stewart, T, & Jacobs, B, (1997). Brain Research, 759:251-258.</p>
<p>[5] Ikemoto, S, & Panksepp, J, (1999). Brain Research Reviews, 31:6-41.</p>
<p>[6] Montague, PR, Dayan, P, & Sejnowski, TJ, (1996). Journal of Neuroscience, 16:1936-1947.</p>
<p>[7] Ng, AY, Harada, D, and Russell, S, (1999) . Proceedings of the Sixteenth International Conference on  Machine Learning.</p>
<p>[8]</p>
<p>[9]</p>
<p>[10]</p>
<p>[11]</p>
<p>[12]</p>
<p>[13]</p>
<p>[14]</p>
<p>[15]  Redgrave, P, Prescott, T, & Gurney, K (1999). Trends in Neurosciences, 22: 146-151. Schultz, W, (1992). Seminars in the Neurosciences, 4: 129-138. Schultz, W, (1998). Journal ofNeurophysiologJ 80: 1-27. J, Schultz, W, Apicella, P, & Ljungberg, T, (1993) . Journal of Neuroscience, 13: 900-913. Schultz, W, Dayan, P, and Montague, PR, (1997). Science, 275: 1593-1599. Schultz, W, & Romo, R, (1990). Journal of Neuroscience, 63: 607-624. Sutton, RS, (1990). Machine Learning: Proceedings of the Seventh International Conference, 216-224. Sutton, RS & Barto, AG (1998). Reinforcement Learning: An Introduction. Cambridge, MA: MIT Press.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
