<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>115 nips-2000-Sequentially Fitting ``Inclusive'' Trees for Inference in Noisy-OR Networks</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2000" href="../home/nips2000_home.html">nips2000</a> <a title="nips-2000-115" href="../nips2000/nips-2000-Sequentially_Fitting_%60%60Inclusive%27%27_Trees_for_Inference_in_Noisy-OR_Networks.html">nips2000-115</a> <a title="nips-2000-115-reference" href="#">nips2000-115-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>115 nips-2000-Sequentially Fitting ``Inclusive'' Trees for Inference in Noisy-OR Networks</h1>
<br/><p>Source: <a title="nips-2000-115-pdf" href="http://papers.nips.cc/paper/1815-sequentially-fitting-inclusive-trees-for-inference-in-noisy-or-networks.pdf">pdf</a></p><p>Author: Brendan J. Frey, Relu Patrascu, Tommi Jaakkola, Jodi Moran</p><p>Abstract: An important class of problems can be cast as inference in noisyOR Bayesian networks, where the binary state of each variable is a logical OR of noisy versions of the states of the variable's parents. For example, in medical diagnosis, the presence of a symptom can be expressed as a noisy-OR of the diseases that may cause the symptom - on some occasions, a disease may fail to activate the symptom. Inference in richly-connected noisy-OR networks is intractable, but approximate methods (e .g., variational techniques) are showing increasing promise as practical solutions. One problem with most approximations is that they tend to concentrate on a relatively small number of modes in the true posterior, ignoring other plausible configurations of the hidden variables. We introduce a new sequential variational method for bipartite noisyOR networks, that favors including all modes of the true posterior and models the posterior distribution as a tree. We compare this method with other approximations using an ensemble of networks with network statistics that are comparable to the QMR-DT medical diagnostic network. 1 Inclusive variational approximations Approximate algorithms for probabilistic inference are gaining in popularity and are now even being incorporated into VLSI hardware (T. Richardson, personal communication). Approximate methods include variational techniques (Ghahramani and Jordan 1997; Saul et al. 1996; Frey and Hinton 1999; Jordan et al. 1999), local probability propagation (Gallager 1963; Pearl 1988; Frey 1998; MacKay 1999a; Freeman and Weiss 2001) and Markov chain Monte Carlo (Neal 1993; MacKay 1999b). Many algorithms have been proposed in each of these classes. One problem that most of the above algorithms suffer from is a tendency to concentrate on a relatively small number of modes of the target distribution (the distribution being approximated). In the case of medical diagnosis, different modes correspond to different explanations of the symptoms. Markov chain Monte Carlo methods are usually guaranteed to eventually sample from all the modes, but this may take an extremely long time, even when tempered transitions (Neal 1996) are (a) ,,</p><br/>
<h2>reference text</h2><p>H. Attias 1999. Independent factor analysis. Neural Computation 11:4, 803- 852. F. Bock 1971. An algorithm to construct a minimum directed spanning tree in a directed network. Developments in Operations Research, Gordon and Breach, New York, 29-44. W. T. Freeman and Y. Weiss 2001. On the fixed points of the max-product algorithm. To appear in IEEE Transactions on Information Theory, Special issue on Codes on Graphs and Iterative Algorithms. B. J. Frey 1998. Graphical Models for Machine Learning and Digital Communication. MIT Press, Cambridge, MA. B. J. Frey 2000. Filling in scenes by propagating probabilities through layers and into appearance models. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, IEEE Computer Society Press, Los Alamitos, CA. B. J. Frey and G. E. Hinton 1999. Variational learning in non-linear Gaussian belief networks. Neural Computation 11:1, 193-214. R. G. Gallager 1963. Low-Density Parity-Check Codes. MIT Press, Cambridge, MA. Z. Ghahramani and M. I. Jordan 1997. Factorial hidden Markov models. Machine Learning 29, 245- 273. D. Heckerman 1989. A tractable inference algorithm for diagnosing multiple diseases. Proceedings of the Fifth Conference on Uncertainty in Artificial Intelligence. T. S. Jaakkola and M. I. Jordan 1999. Variational probabilistic inference and the QMR-DT network. Journal of Artificial Intelligence Research 10, 291-322. M. I. Jordan, Z. Ghahramani, T. S. Jaakkola and L. K. Saul 1999. An introduction to variational methods for graphical models. In M. I. Jordan (ed) Learning in Graphical Models, MIT Press, Cambridge, MA. D. J. C MacKay 1999a. Good error-correcting codes based on very sparse matrices. IEEE Transactions on Information Theory 45:2, 399-431. D. J. C MacKay 1999b. Introduction to Monte Carlo methods. In M. I. Jordan (ed) Learning in Graphical Models, MIT Press, Cambridge, MA. R. J. McEliece, E. R. Rodemich and J.-F. Cheng 1996. The turbo decision algorithm. Proceedings of the 33 rd Allerton Conference on Communication, Control and Computing, Champaign-Urbana, IL. K. P. Murphy, Y. Weiss and M. I. Jordan 1999. Loopy belief propagation for approximate inference: An empirical study. Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence, Morgan Kaufmann, San Francisco, CA. R. M. Neal 1993. Probabilistic inference using Markov chain Monte Carlo methods. Technical Report CRG-TR-93-1, Computer Science, University of Toronto. R. M. Neal 1996. Sampling from multimodal distributions using tempered transitions. Statistics and Computing 6, 353-366. L. K. Saul, T. Jaakkola and M. I. Jordan 1996. Mean field theory for sigmoid belief networks. Journal of Artificial Intelligence Research 4, 61-76. L. K. Saul and M. I. Jordan 1996. Exploiting tractable substructures in intractable networks. In D. Touretzky, M. Mozer, and M. Hasselmo (eds) Advances in Neural Information Processing Systems 8. MIT Press, Cambridge, MA. M. Shwe, B. Middleton, D. Heckerman, M. Henrion, E. Horvitz, H. Lehmann and G. Cooper 1991. Probabilistic diagnosis using a reformulation of the INTERNIST-1/QMR knowledge base I. The probabilistic model and inference algorithms. Methods of Information in Medicine 30, 241- 255.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
