<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>138 nips-2000-The Use of Classifiers in Sequential Inference</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2000" href="../home/nips2000_home.html">nips2000</a> <a title="nips-2000-138" href="../nips2000/nips-2000-The_Use_of_Classifiers_in_Sequential_Inference.html">nips2000-138</a> <a title="nips-2000-138-reference" href="#">nips2000-138-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>138 nips-2000-The Use of Classifiers in Sequential Inference</h1>
<br/><p>Source: <a title="nips-2000-138-pdf" href="http://papers.nips.cc/paper/1817-the-use-of-classifiers-in-sequential-inference.pdf">pdf</a></p><p>Author: Vasin Punyakanok, Dan Roth</p><p>Abstract: We study the problem of combining the outcomes of several different classifiers in a way that provides a coherent inference that satisfies some constraints. In particular, we develop two general approaches for an important subproblem - identifying phrase structure. The first is a Markovian approach that extends standard HMMs to allow the use of a rich observation structure and of general classifiers to model state-observation dependencies. The second is an extension of constraint satisfaction formalisms. We develop efficient combination algorithms under both models and study them experimentally in the context of shallow parsing.</p><br/>
<h2>reference text</h2><p>[1] S. P. Abney. Parsing by chunks. In S. P. A. R. C. Berwick and C. Tenny, editors, Principle-based parsing: Computation and Psycho linguistics, IJages 257-278. Kluwer, Dordrecht, 1991.</p>
<p>[2] D. Appelt, J. Hobbs, J. Bear, D. Israel , and Nt Tyson. FASTUS: A finite-state processor for information extraction from real-world text. In Proc. of IJCAl, 1993.</p>
<p>[3] S. Argamon, 1. Dagan, and Y. Krymolowski. A memory-based approach to learning shallow natural language patterns. Journal of Experimental and Theoretical Artificial Intelligence, special issue on memory-based learning, 10:1- 22, 1999.</p>
<p>[4] C. Burge and S. Karlin. Finding the genes in genomic DNA. Current Opinion in Structural Biology, 8:346- 354, 1998.</p>
<p>[5] C. Cardie and D. Pierce. Error-driven pruning of treebanks grammars for base noun phrase identification. In Proceedings of ACL-98, pages 218- 224, 1998.</p>
<p>[6] A. Carlson, C. Cumby, J. Rosen, and D. Roth. The SNoW learning architecture. Technical Report UillCDCS-R-99-2101, UillC Computer Science Department, May 1999.</p>
<p>[7] K. W. Church. A stochastic parts program and noun phrase parser for unrestricted text. In Proc. of ACL Conference on Applied Natural Language Processing, 1988.</p>
<p>[8] 1: W. Fickett. The gene identification problem: An overview for developers. Computers and Chemistry, 20:103- 118,1996.</p>
<p>[9] D. Freitag and A. McCallum. Information extraction using HMMs and shrinkage. In Papers from the AAAJ-99 Workshop on Machine Learning for Information Extraction, 31- 36, 1999.</p>
<p>[10] A. R. Golding and D. Roth. A Winnow based approach to context-sensitive spelling correction. Machine Learning, 34(1-3):107-130, 1999.</p>
<p>[11] G. Greffenstette. Evaluation techniques for automatic semantic extraction: comparing semantic and window based approaches. In ACL'93 workshop on the Acquisition of Lexical Knowledge from Text, 1993.</p>
<p>[12] R. Grishman. The NYU system for MUC-6 or where's syntax? In B. Sundheim, editor, Proceedings of the Sixth Message Understanding Conference. Morgan Kaufmann Publishers, 1995.</p>
<p>[13] D. Gusfield and L. Pitt. A bounded approximation for the minimum cost 2-SAT problems. Algorithmica, 8:103-117, 1992.</p>
<p>[14] Z. S. Harris. Co-occurrence and transformation in linguistic structure. Language, 33(3):283340,1957.</p>
<p>[15] D. Haussler. Computational genefinding. Trends in Biochemical Sciences, Supplementary Guide to Bioinformatics, pages 12- 15, 1998.</p>
<p>[16] R. Khardon and D. Roth. Learning to reason. J. ACM, 44(5):697- 725, Sept. 1997.</p>
<p>[17] A. Mackworth. Constraint Satisfaction. In S. C. Shapiro, editor, Encyclopedia of Artificial Intelligence, pages 285- 293, 1992. Volume 1, second edition.</p>
<p>[18] M. P. Marcus, B. Santorini, and M. Marcinkiewicz. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics, 19(2):313- 330, June 1993.</p>
<p>[19] A. McCallum, D. Freitag, and F. Pereira. Maximum entropy Markov models for information extraction and segmentation. In proceedings of ICML-2000, 2000. to appear.</p>
<p>[20] N. Morgan and H. Bourlard. Continuous speech recognition. IEEE Signal Processing Magazine, 12(3):24-42, 1995.</p>
<p>[21] M. Munoz, V. Punyakanok, D. Roth, and D. Zimak. A learning approach to shallow parsing. In EMNLP-VLC'99, 1999.</p>
<p>[22] L. R. Rabiner. A tutorial on hidden Markov models and selected applications in speech recognition. Proceedings of the IEEE, 77(2):257- 285 , 1989.</p>
<p>[23] L. A. Ramshaw and M. P. Marcus. Text chunking using transformation-based learning. In Proceedings of the Third Annual Workshop on Very Large Corpora, 1995 .</p>
<p>[24] D. Roth. Learning to resolve natural language ambiguities: A unified approach. In Proceedings of the National Conference on Artificial Intelligence, pages 806- 813, 1998.</p>
<p>[25] D. Roth, M.-H. Yang, and N. Ahuja. Learning to recognize objects. In CVPR'OO, The IEEE Conference on Computer Vision and Pattern Recognition, pages 724--731, 2000.</p>
<p>[26] L. G. Valiant. Projection learning. In Proceedings of the Conference on Computational Learning Theory, pages 287- 293, 1998.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
