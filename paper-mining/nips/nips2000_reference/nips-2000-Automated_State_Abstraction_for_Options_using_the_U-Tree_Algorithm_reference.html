<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>26 nips-2000-Automated State Abstraction for Options using the U-Tree Algorithm</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2000" href="../home/nips2000_home.html">nips2000</a> <a title="nips-2000-26" href="../nips2000/nips-2000-Automated_State_Abstraction_for_Options_using_the_U-Tree_Algorithm.html">nips2000-26</a> <a title="nips-2000-26-reference" href="#">nips2000-26-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>26 nips-2000-Automated State Abstraction for Options using the U-Tree Algorithm</h1>
<br/><p>Source: <a title="nips-2000-26-pdf" href="http://papers.nips.cc/paper/1821-automated-state-abstraction-for-options-using-the-u-tree-algorithm.pdf">pdf</a></p><p>Author: Anders Jonsson, Andrew G. Barto</p><p>Abstract: Learning a complex task can be significantly facilitated by defining a hierarchy of subtasks. An agent can learn to choose between various temporally abstract actions, each solving an assigned subtask, to accomplish the overall task. In this paper, we study hierarchical learning using the framework of options. We argue that to take full advantage of hierarchical structure, one should perform option-specific state abstraction, and that if this is to scale to larger tasks, state abstraction should be automated. We adapt McCallum's U-Tree algorithm to automatically build option-specific representations of the state feature space, and we illustrate the resulting algorithm using a simple hierarchical task. Results suggest that automated option-specific state abstraction is an attractive approach to making hierarchical learning systems more effective.</p><br/>
<h2>reference text</h2><p>[1] Dietterich, T. (2000). Hierarchical reinforcement leaming with the MAXQ value function decomposition. Artificial Intelligence Research 13:227-303.</p>
<p>[2] Dietterich, T. (2000) State Abstraction in MAXQ Hierarchical Reinforcement Learning. In S. A. Solla, T. K. Leen, and K.-R. Muller (eds .), Advances in Neural Information Processing Systems 12, pp. 994-1000. Cambridge MA: MIT Press.</p>
<p>[3] Digney, B. (1996) Emergent hierarchical control structures: Leaming reactivelhierarchical relationships in reinforcement environments. In P. Meas and M. Mataric (eds.), From animals to animats 4. Cambridge MA: MIT Press .</p>
<p>[4] McCallum, A. (1995) Reinforcement Learning with Selective Perception and Hidden State. PhD thesis, Computer Science DepaItment, University of Rochester.</p>
<p>[5] PaI1', R. , and Russell, S. (1998) Reinforcement leaming with hierarchies of machines. In M. 1. Jordan, M. J. Keams, and S. A. Solla (eds.), Advances in Neural Information Processing Systems 10, pp. 1043- 1049. Cambridge MA: MIT Press.</p>
<p>[6] Precup, D., and Sutton, R. (1998) Multi-time models for temporally abstract planning. In M. 1. Jordan, M. J. Keams, and S. A. Solla (eds.), Advances in Neural Information Processing Systems 10, pp. 1050-1056. Cambridge MA: MIT Press.</p>
<p>[7] Singh, S. (1992) Reinforcement leaming with a hierarchy of abstract models. In Proc. of the 10th National Con! on Artificial Intelligence, pp. 202-207. Menlo Park, CA: AAAI PresslMIT Press.</p>
<p>[8] Sutton, R., Precup, D., and Singh, S. (1998) Intra-Option Leaming about Temporally Abstract Actions. In Proc. of the 15th Inti. Con! on Machine Learning, ICML'98, pp. 556-564. Morgan Kaufman.</p>
<p>[9] Sutton, R., Precup, D., and Singh, S. (1999) Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning. Artificial Intelligence 112:181- 211.</p>
<p>[10] Uther, w., and Veloso, M. (1997) Generalizing Adversarial Reinforcement Leaming. AAAI Fall Symposium on Model Directed Autonomous Systems.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
