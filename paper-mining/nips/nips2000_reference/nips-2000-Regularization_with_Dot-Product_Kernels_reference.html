<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>110 nips-2000-Regularization with Dot-Product Kernels</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2000" href="../home/nips2000_home.html">nips2000</a> <a title="nips-2000-110" href="../nips2000/nips-2000-Regularization_with_Dot-Product_Kernels.html">nips2000-110</a> <a title="nips-2000-110-reference" href="#">nips2000-110-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>110 nips-2000-Regularization with Dot-Product Kernels</h1>
<br/><p>Source: <a title="nips-2000-110-pdf" href="http://papers.nips.cc/paper/1790-regularization-with-dot-product-kernels.pdf">pdf</a></p><p>Author: Alex J. Smola, Zoltán L. Óvári, Robert C. Williamson</p><p>Abstract: In this paper we give necessary and sufficient conditions under which kernels of dot product type k(x, y) = k(x . y) satisfy Mercer's condition and thus may be used in Support Vector Machines (SVM), Regularization Networks (RN) or Gaussian Processes (GP). In particular, we show that if the kernel is analytic (i.e. can be expanded in a Taylor series), all expansion coefficients have to be nonnegative. We give an explicit functional form for the feature map by calculating its eigenfunctions and eigenvalues. 1</p><br/>
<h2>reference text</h2><p>[1] C. J. C. Burges. Geometry and invariance in kernel based methods. In B. SchOlkopf, C. J . C. Burges, and A. J . Smola, editors, Advances in Kernel Methods - Support Vector Learning, pages 89-116, Cambridge, MA, 1999. MIT Press.</p>
<p>[2] I. S. Gradshteyn and I. M. Ryzhik. Table of integrals, series, and products. Academic Press, New York, 1981.</p>
<p>[3] J. Mercer. Functions of positive and negative type and their connection with the theory of integral equations. Philos. Trans. Roy. Soc. London, A 209:415-446, 1909.</p>
<p>[4] C. Millier. Analysis of Spherical Symmetries in Euclidean Spaces, volume 129 of Applied Mathematical Sciences. Springer, New York, 1997.</p>
<p>[5] N. Oliver, B. Scholkopf, and A.J. Smola. Natural regularization in SVMs. In A.J. Smola, P .L. Bartlett, B. Scholkopf, and D. Schuurmans, editors, Advances in Large Margin Classifiers, pages 51 - 60, Cambridge, MA, 2000. MIT Press.</p>
<p>[6] Z. Ovari. Kernels, eigenvalues and support vector machines. Honours thesis, Australian National University, Canberra, 2000.</p>
<p>[7] I. Schoenberg. Positive definite functions on spheres. Duke Math. J., 9:96-108, 1942.</p>
<p>[8] A. Smola, B. Scholkopf, and K.-R. Miiller. The connection between regularization operators and support vector kernels. Neural Networks, 11:637-649, 1998.</p>
<p>[9] G. Wahba. Spline Models for Observational Data, volume 59 of CBMS-NSF Regional Conference Series in Applied Mathematics. SIAM, Philadelphia, 1990.</p>
<p>[10] C. K. I. Williams. Prediction with Gaussian processes: From linear regression to linear prediction and beyond. In M. I. Jordan, editor, Learning and Inference in Graphical Models. Kluwer, 1998.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
