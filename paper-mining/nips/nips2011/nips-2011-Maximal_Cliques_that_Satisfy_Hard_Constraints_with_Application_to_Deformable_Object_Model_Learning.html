<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>166 nips-2011-Maximal Cliques that Satisfy Hard Constraints with Application to Deformable Object Model Learning</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-166" href="#">nips2011-166</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>166 nips-2011-Maximal Cliques that Satisfy Hard Constraints with Application to Deformable Object Model Learning</h1>
<br/><p>Source: <a title="nips-2011-166-pdf" href="http://papers.nips.cc/paper/4460-maximal-cliques-that-satisfy-hard-constraints-with-application-to-deformable-object-model-learning.pdf">pdf</a></p><p>Author: Xinggang Wang, Xiang Bai, Xingwei Yang, Wenyu Liu, Longin J. Latecki</p><p>Abstract: We propose a novel inference framework for ﬁnding maximal cliques in a weighted graph that satisfy hard constraints. The constraints specify the graph nodes that must belong to the solution as well as mutual exclusions of graph nodes, i.e., sets of nodes that cannot belong to the same solution. The proposed inference is based on a novel particle ﬁlter algorithm with state permeations. We apply the inference framework to a challenging problem of learning part-based, deformable object models. Two core problems in the learning framework, matching of image patches and ﬁnding salient parts, are formulated as two instances of the problem of ﬁnding maximal cliques with hard constraints. Our learning framework yields discriminative part based object models that achieve very good detection rate, and outperform other methods on object classes with large deformation. 1</p><p>Reference: <a title="nips-2011-166-reference" href="../nips2011_reference/nips-2011-Maximal_Cliques_that_Satisfy_Hard_Constraints_with_Application_to_Deformable_Object_Model_Learning_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract We propose a novel inference framework for ﬁnding maximal cliques in a weighted graph that satisfy hard constraints. [sent-11, score-0.601]
</p><p>2 The constraints specify the graph nodes that must belong to the solution as well as mutual exclusions of graph nodes, i. [sent-12, score-0.322]
</p><p>3 We apply the inference framework to a challenging problem of learning part-based, deformable object models. [sent-16, score-0.39]
</p><p>4 Two core problems in the learning framework, matching of image patches and ﬁnding salient parts, are formulated as two instances of the problem of ﬁnding maximal cliques with hard constraints. [sent-17, score-1.195]
</p><p>5 Our learning framework yields discriminative part based object models that achieve very good detection rate, and outperform other methods on object classes with large deformation. [sent-18, score-0.71]
</p><p>6 1  Introduction  The problem of ﬁnding maximal cliques in a weighted graph is faced in many applications from computer vision to social networks. [sent-19, score-0.524]
</p><p>7 Therefore, we aim at solving the discrete subgraph selection problem by employing the recently proposed extension of particle ﬁlter inference to problems with state permeations [20]. [sent-23, score-0.332]
</p><p>8 There are at least two main contributions of this paper: (1) We propose an inference framework for solving a maximal clique problem that cannot be solved with typical clustering methods nor with recent relaxation based methods [16, 12, 14]. [sent-24, score-0.397]
</p><p>9 (2) We utilize the inference framework for solving a challenging problem of learning a part model for deformable object detection. [sent-25, score-0.521]
</p><p>10 Object detection is one of the key challenges in computer vision, due to the large intra-class appearance variation of an object class. [sent-26, score-0.406]
</p><p>11 Based on this observation, we propose a learning by matching framework to match all local image patches from training image. [sent-30, score-0.479]
</p><p>12 By matching, object parts with similar local structure in different training images can be found. [sent-31, score-0.572]
</p><p>13 1(a), our ﬁrst problem is to select a set of image patches that depict the same visual part of these objects. [sent-35, score-0.46]
</p><p>14 Thus, an object part is regarded as a collection of image patches e. [sent-36, score-0.67]
</p><p>15 Since close by patches in the same image tend to be very similar, we must impose ∗ †  This work was done while the author visiting Temple University. [sent-43, score-0.328]
</p><p>16 1  Figure 1: (a) example training images; (b) patches extracted from the training images; (c) object parts as collections of patches obtained as maximal cliques of patch similarity graph; (d) the learned salient parts for giraffe, the patches belong to the same salient part are in the same color. [sent-45, score-2.88]
</p><p>17 The salient parts are obtained as maximal cliques in a second graph whose vertices represent the object parts. [sent-46, score-1.478]
</p><p>18 a hard constraint that a patch set representing the same object part does not contain two patches from the same image. [sent-47, score-0.779]
</p><p>19 This constraint is very important, since otherwise very similar patches from the same images will dominate this graph. [sent-48, score-0.375]
</p><p>20 In order to obtain meaningful object parts, we deﬁne an object part as a maximal clique in the weighted graph that satisﬁes the above constraint. [sent-49, score-1.042]
</p><p>21 By solving the problem of maximal clique, we obtain a set of object parts like the ones shown in Fig. [sent-50, score-0.654]
</p><p>22 Finally, we obtain a small set of salient visual parts, e. [sent-53, score-0.396]
</p><p>23 1(d), by solving a different instance of the maximal clique problem on the second graph. [sent-56, score-0.343]
</p><p>24 For each salient visual part, we train a discriminative classiﬁer. [sent-57, score-0.396]
</p><p>25 By combining these classiﬁers with spatial distribution of the salient object parts, a detector for deformable object is built. [sent-58, score-1.01]
</p><p>26 As illustrated in the experimental results, this detector achieves very good object detection performance, and outperforms other methods on object classes with large deformation. [sent-59, score-0.619]
</p><p>27 The computer vision literature has approached learning of part based object models in different ways. [sent-60, score-0.379]
</p><p>28 In [8] objects are modeled as ﬂexible constellations of parts, parts are constrained to a sparse set of locations determined by an entropy-based feature detector, other part models based on feature detector include [15, 17]. [sent-61, score-0.366]
</p><p>29 Our model is similar to discriminatively trained part based model in [6] in that we train SVM classiﬁers for each part of object and geometric arrangement of parts is captured by a set of ”springs”. [sent-62, score-0.662]
</p><p>30 In contrast, we case part learning as ﬁnding maximal cliques in a weighted graph of image patches. [sent-66, score-0.66]
</p><p>31 In [4, 13] multiple instance learning is used to search position of object parts in training images, and boosting algorithm is used to select salient parts to represent object. [sent-68, score-1.153]
</p><p>32 As is customary, we represent the graph G with the corresponding weighted adjacency matrix, more speciﬁcally, an n × n symmetric matrix A = (aij ), where aij = e(vi , vj ) if (vi , vj ) ∈ E, and aij = 0 otherwise. [sent-74, score-0.395]
</p><p>33 2  We consider mutex relationship between vertices in graph. [sent-86, score-0.48]
</p><p>34 Given a subset of vertices M ⊆ S, we call M a mutex (short for mutual exclusion) if i ∈ M and j ∈ M implies that vertices vi and vj can not belong to the same maximal clique. [sent-87, score-1.005]
</p><p>35 The goal of (1) is to select a subset of vertices of graph G such that f is maximized and the constraints (C1)-(C4) are satisﬁed. [sent-107, score-0.367]
</p><p>36 However, the size of the subset is limited by the mutex constraints (C3) and maximal size constraint (C4). [sent-109, score-0.579]
</p><p>37 A global maximum of (1) is called a U − M maximal clique of graph G. [sent-110, score-0.419]
</p><p>38 We ﬁrst present two instances of problem (1) in Section 3, where we describe the proposed application to learning salient object parts. [sent-122, score-0.636]
</p><p>39 3  Learning by Matching  In this section, we present a novel framework to learn part based object model based on matching. [sent-123, score-0.369]
</p><p>40 The core problems of learning part based object model are how to search right locations of an object part in all training images and how to select salient parts for representing object. [sent-124, score-1.469]
</p><p>41 In our framework, the two problems are formulated as ﬁnding maximal cliques with hard constraints. [sent-125, score-0.401]
</p><p>42 For every training image, we densely extract image patches with overlap. [sent-134, score-0.382]
</p><p>43 We denote the set of patches extracted from all images as {P1 , . [sent-135, score-0.347]
</p><p>44 We treat all the patches as the set of vertices of graph G, i. [sent-146, score-0.541]
</p><p>45 It measures the appearance similarity of patches Pi and Pj . [sent-155, score-0.322]
</p><p>46 3  We have exactly K mutex constraints M = {M1 , . [sent-159, score-0.354]
</p><p>47 , MK }, where Mj contains all patches from image Ij , i. [sent-162, score-0.328]
</p><p>48 This means that we do not want two patches from the same image to belong to the same maximal clique. [sent-168, score-0.584]
</p><p>49 The part learning algorithm by ﬁnding maximal cliques is given in Alg. [sent-178, score-0.443]
</p><p>50 Algorithm 1 Part learning by ﬁnding maximal cliques with hard constraints Input: A, M, K, and r. [sent-180, score-0.454]
</p><p>51 Due to our mutex constraint, each Q(i) contains exactly one patch from each of K training images. [sent-198, score-0.42]
</p><p>52 We treat the learned parts as candidate object parts, because there are non-object areas inside the bounding box images. [sent-199, score-0.494]
</p><p>53 2 Selecting Salient Parts for Part Based Object Representation In order to select a set of object parts that best represent the object class, our strategy is to ﬁnd a subset of Q that maximizes the sum of the matching scores. [sent-202, score-0.797]
</p><p>54 We formulate this problem as ﬁnding maximal clique with hard constraints again. [sent-203, score-0.427]
</p><p>55 We deﬁne a new graph H with vertices V = Q and adjacency matrix B = (bij ), where bij = W (i) if i = j, and bij = 0 otherwise. [sent-204, score-0.37]
</p><p>56 It may appear that the problem is trivial, since there is no edges between different vertices of H, but this is not the case due to the mutex relations. [sent-206, score-0.48]
</p><p>57 , r], where τ is a distance threshold and D(i, j) is the average distance between patches in Q(i) and Q(j) that belong to the same image. [sent-213, score-0.316]
</p><p>58 If Q(i) is selected as a salient part, the mutex MiH ensures that the patches of other salient parts are not too close to the patches of Q(i). [sent-214, score-1.823]
</p><p>59 1(c) both have good matching weights, but the average distance between Q(1) and Q(2) is smaller than τ , so they cannot be selected as salient parts at the same time. [sent-216, score-0.682]
</p><p>60 As initialization (C2), we set U H to a one element set containing arg maxi W (i), so the part with maximal matching score is always selected as a salient part. [sent-217, score-0.793]
</p><p>61 We set K in (C4) to K H , where K H is the maximal number of salient parts. [sent-218, score-0.593]
</p><p>62 By solving the second instance of problem (1) for B, U H , MH , K H , we obtain the set of salient parts as the solution x∗ . [sent-220, score-0.613]
</p><p>63 Inspired by this work, we extend PF framework to solve U − M maximal clique problem in the weighted graph. [sent-270, score-0.382]
</p><p>64 Each particle (i) xσ(1:t) can now have a different permutation σ (i) representing the indices of RVs with assigned values. [sent-296, score-0.329]
</p><p>65 We deﬁne an index set of indices of graph vertices that are compatible with selected vertices in σ (i) (1 : t) as κ(σ (i) (1 : t)) = S \ ( σ (i) (1 : t) ∪ mutex(σ (i) (1 : t) ). [sent-304, score-0.582]
</p><p>66 Hence κ(σ (i) (1 : t)) contains indices from S that that are both not present in σ (i) (1 : t) and not have mutex relation with the members of σ (i) (1 : t). [sent-305, score-0.364]
</p><p>67 At each iteration t ≤ n, for each (i) (i) particle (i) and for each s ∈ κ(σ (i) (1 : t − 1)), we sample xs ∼ p(xs |xσ(1:t−1) ). [sent-307, score-0.361]
</p><p>68 Since we are interested in making this gain as large as possible, and assigning xs = 0 leads to zero gain, we focus only on assigning xs = 1. [sent-312, score-0.35]
</p><p>69 (4)  (i)  Hence, we can interpret a particle xσ(1:t−1) as a sequence of indices of selected graph vertices (i)  σ (i) (1 : t − 1), since xσ(1:t−1) is a vector of ones assigned to RVs with indices in σ (i) (1 : t − 1). [sent-314, score-0.677]
</p><p>70 For example, if x = (0, 1, 1, 0, 0) ∈ {0, 1}5 , then ind(x) = {2, 3}, which means that graph vertices with indices 2 and 3 are selected by x. [sent-316, score-0.375]
</p><p>71 Importance sampling / proposal: Sample followers xs of particle (i) from (i)  (i)  (i)  (i) xs ∼ p(xs |xσ(1:t−1) ) = exp((f (xs , xσ(1:t−1) ) − f (xσ(1:t−1) ))/γ) (i,s)  (i)  (i)  and set xσ(1:t) = (xσ(1:t−1) , xs ) and σ (i,s) (t) = s, i. [sent-329, score-0.659]
</p><p>72 Importance weighting / evaluation: An individual importance weight is assigned to each follower particle according to (i,s)  (i)  w(xσ(1:t) ) = exp(f (x(i) , xσ(1:t−1) )/γ) s else (i,s) (i) (i,s) (i) we carry over the particle: xσ(1:t) = xσ(1:t−1) and w(xσ(1:t) ) = w(xσ(1:t−1) ). [sent-333, score-0.314]
</p><p>73 , xσ(1:t) } We take the particle with maximal value of f as solution of (2), or equivalently, as solution of (1): (k) (i) x∗ = xσ(1:t) , where k = arg maxi f (xσ(1:t) ). [sent-345, score-0.409]
</p><p>74 2, we ﬁnd K H salient parts denoted as SP = {Qi |i = 1, . [sent-348, score-0.584]
</p><p>75 , K H } to represent an object class, each part Qi contains K image patches, one patch from each training image. [sent-351, score-0.561]
</p><p>76 6  As in [6], we capture the spatial distribution of salient parts in SP with a star model, where the location of each part is expressed as an offset vector with respect to the model center. [sent-360, score-0.686]
</p><p>77 The offset is learned from the offsets of the patches in Qi to the centers of their training images (bounding boxes) containing them. [sent-361, score-0.427]
</p><p>78 In order to be able to directly compare to Latent SVM [6], we use the same object detection framework. [sent-362, score-0.341]
</p><p>79 For learning the salient parts, the giraffe bounding boxes are normalized to the area of 3000 pixels with aspect ratio kept. [sent-372, score-0.665]
</p><p>80 For both datasets, the size of each patch is 61 ∗ 61 pixels, number of patches per image is about 1000. [sent-376, score-0.393]
</p><p>81 We set K H in (C4) to 6 meaning that our goal is to learn 6 salient parts for each object class. [sent-377, score-0.824]
</p><p>82 The minimal distance τ between salient parts is 60 pixels for the giraffe class and 45 pixels for the pedestrian class. [sent-379, score-0.872]
</p><p>83 In Algorithm 2, the normalization parameter γ is set to the median value in A times the size of expected maximal clique times 2, the number of particles is N = 500, and for each particle we sample 10 followers. [sent-380, score-0.575]
</p><p>84 These results show that our method can learn object models that yield very good detection performance. [sent-393, score-0.341]
</p><p>85 The signiﬁcant nonrigid deformation of giraffes leads to a large variation in the position of patches representing the same object part. [sent-395, score-0.755]
</p><p>86 They demonstrate that our learned part model leads to detection performance that is robust to the scale changes, appearance variance, part location variance, and substantial occlusion. [sent-401, score-0.396]
</p><p>87 7  Figure 3: Some of our detection results for giraffe class and pedestrian dataset. [sent-433, score-0.321]
</p><p>88 The detected patches with the same color belong to the same salient part. [sent-434, score-0.712]
</p><p>89 2 Tree Structure of Salient Parts In our framework, it is also possible to learn a tree structure of the salient parts. [sent-439, score-0.396]
</p><p>90 Given a set of learned salient parts SP = {Qi |i = 1, . [sent-440, score-0.61]
</p><p>91 The edge weights of SPG are given by the average distance between pairs of salient parts Qi and Qj given by D(i, j) for i, j = 1, . [sent-444, score-0.613]
</p><p>92 Figure 4: The learned salient parts and graph structures for the giraffe class and pedestrian dataset. [sent-448, score-0.935]
</p><p>93 The patches that belong to the same salient part are in the same color. [sent-449, score-0.814]
</p><p>94 The learned trees for two object classes of giraffes and pedestrians are illustrated in Fig. [sent-451, score-0.421]
</p><p>95 Their connections yield a salient part structure in accord with our intuition. [sent-453, score-0.498]
</p><p>96 7  Conclusions  An object part is deﬁned as a set of image patches. [sent-456, score-0.413]
</p><p>97 Learning object parts is formulated as two instances of the problem of ﬁnding maximal cliques in weighted graphs that satisfy hard constraints, and solved with the proposed Particle Filter inference framework. [sent-457, score-0.897]
</p><p>98 By utilizing the spatial relation of the obtained salient parts, we are also able to learn a tree structure of the deformable object model. [sent-458, score-0.732]
</p><p>99 The application of the proposed inference framework is not limited to learning object part models. [sent-459, score-0.396]
</p><p>100 Efﬁcient unsupervised learning for localization and detection in object categories. [sent-568, score-0.368]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('salient', 0.396), ('mutex', 0.301), ('patches', 0.257), ('object', 0.24), ('rvs', 0.221), ('particle', 0.212), ('maximal', 0.197), ('parts', 0.188), ('vertices', 0.179), ('pf', 0.162), ('giraffe', 0.159), ('xs', 0.149), ('cliques', 0.144), ('ethz', 0.12), ('giraffes', 0.12), ('clique', 0.117), ('rv', 0.115), ('graph', 0.105), ('part', 0.102), ('detection', 0.101), ('deformable', 0.096), ('images', 0.09), ('ap', 0.089), ('xt', 0.077), ('svm', 0.077), ('image', 0.071), ('matching', 0.07), ('qi', 0.068), ('appearance', 0.065), ('aij', 0.065), ('patch', 0.065), ('subgraph', 0.064), ('indices', 0.063), ('pedestrian', 0.061), ('spg', 0.06), ('temple', 0.06), ('hard', 0.06), ('belong', 0.059), ('latent', 0.057), ('training', 0.054), ('constraints', 0.053), ('ind', 0.053), ('pi', 0.051), ('particles', 0.049), ('vertex', 0.049), ('xik', 0.049), ('gt', 0.048), ('proposal', 0.046), ('pmf', 0.046), ('vi', 0.045), ('vj', 0.045), ('filter', 0.044), ('nding', 0.044), ('bij', 0.043), ('deformation', 0.043), ('weighted', 0.041), ('ax', 0.041), ('sp', 0.041), ('bounding', 0.04), ('follower', 0.04), ('mih', 0.04), ('nonrigid', 0.04), ('objects', 0.038), ('detector', 0.038), ('vision', 0.037), ('boxes', 0.036), ('relaxed', 0.036), ('pedestrians', 0.035), ('grf', 0.035), ('jigsaw', 0.035), ('importance', 0.035), ('fi', 0.034), ('pixels', 0.034), ('dense', 0.033), ('mi', 0.031), ('discriminatively', 0.03), ('xn', 0.03), ('select', 0.03), ('precision', 0.029), ('edge', 0.029), ('pattern', 0.029), ('represent', 0.029), ('solving', 0.029), ('constraint', 0.028), ('position', 0.028), ('mk', 0.028), ('index', 0.028), ('selected', 0.028), ('sv', 0.028), ('china', 0.028), ('af', 0.028), ('assigned', 0.027), ('framework', 0.027), ('dataset', 0.027), ('localization', 0.027), ('inference', 0.027), ('representing', 0.027), ('mh', 0.027), ('learned', 0.026), ('assigning', 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999934 <a title="166-tfidf-1" href="./nips-2011-Maximal_Cliques_that_Satisfy_Hard_Constraints_with_Application_to_Deformable_Object_Model_Learning.html">166 nips-2011-Maximal Cliques that Satisfy Hard Constraints with Application to Deformable Object Model Learning</a></p>
<p>Author: Xinggang Wang, Xiang Bai, Xingwei Yang, Wenyu Liu, Longin J. Latecki</p><p>Abstract: We propose a novel inference framework for ﬁnding maximal cliques in a weighted graph that satisfy hard constraints. The constraints specify the graph nodes that must belong to the solution as well as mutual exclusions of graph nodes, i.e., sets of nodes that cannot belong to the same solution. The proposed inference is based on a novel particle ﬁlter algorithm with state permeations. We apply the inference framework to a challenging problem of learning part-based, deformable object models. Two core problems in the learning framework, matching of image patches and ﬁnding salient parts, are formulated as two instances of the problem of ﬁnding maximal cliques with hard constraints. Our learning framework yields discriminative part based object models that achieve very good detection rate, and outperform other methods on object classes with large deformation. 1</p><p>2 0.17177454 <a title="166-tfidf-2" href="./nips-2011-%24%5Ctheta%24-MRF%3A_Capturing_Spatial_and_Semantic_Structure_in_the_Parameters_for_Scene_Understanding.html">1 nips-2011-$\theta$-MRF: Capturing Spatial and Semantic Structure in the Parameters for Scene Understanding</a></p>
<p>Author: Congcong Li, Ashutosh Saxena, Tsuhan Chen</p><p>Abstract: For most scene understanding tasks (such as object detection or depth estimation), the classiﬁers need to consider contextual information in addition to the local features. We can capture such contextual information by taking as input the features/attributes from all the regions in the image. However, this contextual dependence also varies with the spatial location of the region of interest, and we therefore need a different set of parameters for each spatial location. This results in a very large number of parameters. In this work, we model the independence properties between the parameters for each location and for each task, by deﬁning a Markov Random Field (MRF) over the parameters. In particular, two sets of parameters are encouraged to have similar values if they are spatially close or semantically close. Our method is, in principle, complementary to other ways of capturing context such as the ones that use a graphical model over the labels instead. In extensive evaluation over two different settings, of multi-class object detection and of multiple scene understanding tasks (scene categorization, depth estimation, geometric labeling), our method beats the state-of-the-art methods in all the four tasks. 1</p><p>3 0.14539689 <a title="166-tfidf-3" href="./nips-2011-Learning_person-object_interactions_for_action_recognition_in_still_images.html">154 nips-2011-Learning person-object interactions for action recognition in still images</a></p>
<p>Author: Vincent Delaitre, Josef Sivic, Ivan Laptev</p><p>Abstract: We investigate a discriminatively trained model of person-object interactions for recognizing common human actions in still images. We build on the locally order-less spatial pyramid bag-of-features model, which was shown to perform extremely well on a range of object, scene and human action recognition tasks. We introduce three principal contributions. First, we replace the standard quantized local HOG/SIFT features with stronger discriminatively trained body part and object detectors. Second, we introduce new person-object interaction features based on spatial co-occurrences of individual body parts and objects. Third, we address the combinatorial problem of a large number of possible interaction pairs and propose a discriminative selection procedure using a linear support vector machine (SVM) with a sparsity inducing regularizer. Learning of action-speciﬁc body part and object interactions bypasses the difﬁcult problem of estimating the complete human body pose conﬁguration. Beneﬁts of the proposed model are shown on human action recognition in consumer photographs, outperforming the strong bag-of-features baseline. 1</p><p>4 0.13571984 <a title="166-tfidf-4" href="./nips-2011-Rapid_Deformable_Object_Detection_using_Dual-Tree_Branch-and-Bound.html">233 nips-2011-Rapid Deformable Object Detection using Dual-Tree Branch-and-Bound</a></p>
<p>Author: Iasonas Kokkinos</p><p>Abstract: In this work we use Branch-and-Bound (BB) to efﬁciently detect objects with deformable part models. Instead of evaluating the classiﬁer score exhaustively over image locations and scales, we use BB to focus on promising image locations. The core problem is to compute bounds that accommodate part deformations; for this we adapt the Dual Trees data structure [7] to our problem. We evaluate our approach using Mixture-of-Deformable Part Models [4]. We obtain exactly the same results but are 10-20 times faster on average. We also develop a multiple-object detection variation of the system, where hypotheses for 20 categories are inserted in a common priority queue. For the problem of ﬁnding the strongest category in an image this results in a 100-fold speedup.</p><p>5 0.12742704 <a title="166-tfidf-5" href="./nips-2011-Object_Detection_with_Grammar_Models.html">193 nips-2011-Object Detection with Grammar Models</a></p>
<p>Author: Ross B. Girshick, Pedro F. Felzenszwalb, David A. McAllester</p><p>Abstract: Compositional models provide an elegant formalism for representing the visual appearance of highly variable objects. While such models are appealing from a theoretical point of view, it has been difﬁcult to demonstrate that they lead to performance advantages on challenging datasets. Here we develop a grammar model for person detection and show that it outperforms previous high-performance systems on the PASCAL benchmark. Our model represents people using a hierarchy of deformable parts, variable structure and an explicit model of occlusion for partially visible objects. To train the model, we introduce a new discriminative framework for learning structured prediction models from weakly-labeled data. 1</p><p>6 0.12534942 <a title="166-tfidf-6" href="./nips-2011-Why_The_Brain_Separates_Face_Recognition_From_Object_Recognition.html">304 nips-2011-Why The Brain Separates Face Recognition From Object Recognition</a></p>
<p>7 0.12151974 <a title="166-tfidf-7" href="./nips-2011-Multiple_Instance_Filtering.html">180 nips-2011-Multiple Instance Filtering</a></p>
<p>8 0.11659336 <a title="166-tfidf-8" href="./nips-2011-Kernel_Embeddings_of_Latent_Tree_Graphical_Models.html">140 nips-2011-Kernel Embeddings of Latent Tree Graphical Models</a></p>
<p>9 0.11193874 <a title="166-tfidf-9" href="./nips-2011-Semantic_Labeling_of_3D_Point_Clouds_for_Indoor_Scenes.html">247 nips-2011-Semantic Labeling of 3D Point Clouds for Indoor Scenes</a></p>
<p>10 0.10478906 <a title="166-tfidf-10" href="./nips-2011-Transfer_Learning_by_Borrowing_Examples_for_Multiclass_Object_Detection.html">290 nips-2011-Transfer Learning by Borrowing Examples for Multiclass Object Detection</a></p>
<p>11 0.10268914 <a title="166-tfidf-11" href="./nips-2011-Im2Text%3A_Describing_Images_Using_1_Million_Captioned_Photographs.html">126 nips-2011-Im2Text: Describing Images Using 1 Million Captioned Photographs</a></p>
<p>12 0.095317721 <a title="166-tfidf-12" href="./nips-2011-Randomized_Algorithms_for_Comparison-based_Search.html">231 nips-2011-Randomized Algorithms for Comparison-based Search</a></p>
<p>13 0.094616108 <a title="166-tfidf-13" href="./nips-2011-Heavy-tailed_Distances_for_Gradient_Based_Image_Descriptors.html">112 nips-2011-Heavy-tailed Distances for Gradient Based Image Descriptors</a></p>
<p>14 0.091753878 <a title="166-tfidf-14" href="./nips-2011-Hierarchical_Matching_Pursuit_for_Image_Classification%3A_Architecture_and_Fast_Algorithms.html">113 nips-2011-Hierarchical Matching Pursuit for Image Classification: Architecture and Fast Algorithms</a></p>
<p>15 0.090148069 <a title="166-tfidf-15" href="./nips-2011-Projection_onto_A_Nonnegative_Max-Heap.html">226 nips-2011-Projection onto A Nonnegative Max-Heap</a></p>
<p>16 0.088119902 <a title="166-tfidf-16" href="./nips-2011-Message-Passing_for_Approximate_MAP_Inference_with_Latent_Variables.html">170 nips-2011-Message-Passing for Approximate MAP Inference with Latent Variables</a></p>
<p>17 0.087630346 <a title="166-tfidf-17" href="./nips-2011-Structured_Learning_for_Cell_Tracking.html">275 nips-2011-Structured Learning for Cell Tracking</a></p>
<p>18 0.087556496 <a title="166-tfidf-18" href="./nips-2011-Sparse_recovery_by_thresholded_non-negative_least_squares.html">265 nips-2011-Sparse recovery by thresholded non-negative least squares</a></p>
<p>19 0.086739026 <a title="166-tfidf-19" href="./nips-2011-Efficient_Inference_in_Fully_Connected_CRFs_with_Gaussian_Edge_Potentials.html">76 nips-2011-Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials</a></p>
<p>20 0.085950047 <a title="166-tfidf-20" href="./nips-2011-PiCoDes%3A_Learning_a_Compact_Code_for_Novel-Category_Recognition.html">214 nips-2011-PiCoDes: Learning a Compact Code for Novel-Category Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.23), (1, 0.105), (2, -0.145), (3, 0.138), (4, 0.088), (5, 0.014), (6, -0.038), (7, -0.049), (8, 0.077), (9, -0.06), (10, 0.046), (11, -0.067), (12, -0.063), (13, 0.105), (14, -0.023), (15, -0.015), (16, 0.045), (17, 0.001), (18, -0.056), (19, 0.034), (20, -0.012), (21, 0.048), (22, 0.024), (23, 0.029), (24, 0.11), (25, -0.069), (26, -0.006), (27, 0.116), (28, 0.049), (29, 0.113), (30, 0.074), (31, 0.09), (32, 0.029), (33, 0.007), (34, -0.062), (35, 0.028), (36, 0.05), (37, -0.07), (38, 0.006), (39, -0.002), (40, 0.034), (41, -0.008), (42, -0.025), (43, 0.027), (44, -0.027), (45, -0.022), (46, 0.081), (47, 0.017), (48, 0.032), (49, -0.001)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95781398 <a title="166-lsi-1" href="./nips-2011-Maximal_Cliques_that_Satisfy_Hard_Constraints_with_Application_to_Deformable_Object_Model_Learning.html">166 nips-2011-Maximal Cliques that Satisfy Hard Constraints with Application to Deformable Object Model Learning</a></p>
<p>Author: Xinggang Wang, Xiang Bai, Xingwei Yang, Wenyu Liu, Longin J. Latecki</p><p>Abstract: We propose a novel inference framework for ﬁnding maximal cliques in a weighted graph that satisfy hard constraints. The constraints specify the graph nodes that must belong to the solution as well as mutual exclusions of graph nodes, i.e., sets of nodes that cannot belong to the same solution. The proposed inference is based on a novel particle ﬁlter algorithm with state permeations. We apply the inference framework to a challenging problem of learning part-based, deformable object models. Two core problems in the learning framework, matching of image patches and ﬁnding salient parts, are formulated as two instances of the problem of ﬁnding maximal cliques with hard constraints. Our learning framework yields discriminative part based object models that achieve very good detection rate, and outperform other methods on object classes with large deformation. 1</p><p>2 0.73112583 <a title="166-lsi-2" href="./nips-2011-Learning_person-object_interactions_for_action_recognition_in_still_images.html">154 nips-2011-Learning person-object interactions for action recognition in still images</a></p>
<p>Author: Vincent Delaitre, Josef Sivic, Ivan Laptev</p><p>Abstract: We investigate a discriminatively trained model of person-object interactions for recognizing common human actions in still images. We build on the locally order-less spatial pyramid bag-of-features model, which was shown to perform extremely well on a range of object, scene and human action recognition tasks. We introduce three principal contributions. First, we replace the standard quantized local HOG/SIFT features with stronger discriminatively trained body part and object detectors. Second, we introduce new person-object interaction features based on spatial co-occurrences of individual body parts and objects. Third, we address the combinatorial problem of a large number of possible interaction pairs and propose a discriminative selection procedure using a linear support vector machine (SVM) with a sparsity inducing regularizer. Learning of action-speciﬁc body part and object interactions bypasses the difﬁcult problem of estimating the complete human body pose conﬁguration. Beneﬁts of the proposed model are shown on human action recognition in consumer photographs, outperforming the strong bag-of-features baseline. 1</p><p>3 0.67715049 <a title="166-lsi-3" href="./nips-2011-%24%5Ctheta%24-MRF%3A_Capturing_Spatial_and_Semantic_Structure_in_the_Parameters_for_Scene_Understanding.html">1 nips-2011-$\theta$-MRF: Capturing Spatial and Semantic Structure in the Parameters for Scene Understanding</a></p>
<p>Author: Congcong Li, Ashutosh Saxena, Tsuhan Chen</p><p>Abstract: For most scene understanding tasks (such as object detection or depth estimation), the classiﬁers need to consider contextual information in addition to the local features. We can capture such contextual information by taking as input the features/attributes from all the regions in the image. However, this contextual dependence also varies with the spatial location of the region of interest, and we therefore need a different set of parameters for each spatial location. This results in a very large number of parameters. In this work, we model the independence properties between the parameters for each location and for each task, by deﬁning a Markov Random Field (MRF) over the parameters. In particular, two sets of parameters are encouraged to have similar values if they are spatially close or semantically close. Our method is, in principle, complementary to other ways of capturing context such as the ones that use a graphical model over the labels instead. In extensive evaluation over two different settings, of multi-class object detection and of multiple scene understanding tasks (scene categorization, depth estimation, geometric labeling), our method beats the state-of-the-art methods in all the four tasks. 1</p><p>4 0.67220151 <a title="166-lsi-4" href="./nips-2011-Object_Detection_with_Grammar_Models.html">193 nips-2011-Object Detection with Grammar Models</a></p>
<p>Author: Ross B. Girshick, Pedro F. Felzenszwalb, David A. McAllester</p><p>Abstract: Compositional models provide an elegant formalism for representing the visual appearance of highly variable objects. While such models are appealing from a theoretical point of view, it has been difﬁcult to demonstrate that they lead to performance advantages on challenging datasets. Here we develop a grammar model for person detection and show that it outperforms previous high-performance systems on the PASCAL benchmark. Our model represents people using a hierarchy of deformable parts, variable structure and an explicit model of occlusion for partially visible objects. To train the model, we introduce a new discriminative framework for learning structured prediction models from weakly-labeled data. 1</p><p>5 0.66739488 <a title="166-lsi-5" href="./nips-2011-Transfer_Learning_by_Borrowing_Examples_for_Multiclass_Object_Detection.html">290 nips-2011-Transfer Learning by Borrowing Examples for Multiclass Object Detection</a></p>
<p>Author: Joseph J. Lim, Antonio Torralba, Ruslan Salakhutdinov</p><p>Abstract: Despite the recent trend of increasingly large datasets for object detection, there still exist many classes with few training examples. To overcome this lack of training data for certain classes, we propose a novel way of augmenting the training data for each class by borrowing and transforming examples from other classes. Our model learns which training instances from other classes to borrow and how to transform the borrowed examples so that they become more similar to instances from the target class. Our experimental results demonstrate that our new object detector, with borrowed and transformed examples, improves upon the current state-of-the-art detector on the challenging SUN09 object detection dataset. 1</p><p>6 0.66258001 <a title="166-lsi-6" href="./nips-2011-Im2Text%3A_Describing_Images_Using_1_Million_Captioned_Photographs.html">126 nips-2011-Im2Text: Describing Images Using 1 Million Captioned Photographs</a></p>
<p>7 0.62255323 <a title="166-lsi-7" href="./nips-2011-Joint_3D_Estimation_of_Objects_and_Scene_Layout.html">138 nips-2011-Joint 3D Estimation of Objects and Scene Layout</a></p>
<p>8 0.61037868 <a title="166-lsi-8" href="./nips-2011-Rapid_Deformable_Object_Detection_using_Dual-Tree_Branch-and-Bound.html">233 nips-2011-Rapid Deformable Object Detection using Dual-Tree Branch-and-Bound</a></p>
<p>9 0.58677202 <a title="166-lsi-9" href="./nips-2011-Why_The_Brain_Separates_Face_Recognition_From_Object_Recognition.html">304 nips-2011-Why The Brain Separates Face Recognition From Object Recognition</a></p>
<p>10 0.56356233 <a title="166-lsi-10" href="./nips-2011-Exploiting_spatial_overlap_to_efficiently_compute_appearance_distances_between_image_windows.html">91 nips-2011-Exploiting spatial overlap to efficiently compute appearance distances between image windows</a></p>
<p>11 0.55941856 <a title="166-lsi-11" href="./nips-2011-Structured_Learning_for_Cell_Tracking.html">275 nips-2011-Structured Learning for Cell Tracking</a></p>
<p>12 0.55625379 <a title="166-lsi-12" href="./nips-2011-Semantic_Labeling_of_3D_Point_Clouds_for_Indoor_Scenes.html">247 nips-2011-Semantic Labeling of 3D Point Clouds for Indoor Scenes</a></p>
<p>13 0.54010713 <a title="166-lsi-13" href="./nips-2011-Understanding_the_Intrinsic_Memorability_of_Images.html">293 nips-2011-Understanding the Intrinsic Memorability of Images</a></p>
<p>14 0.53758621 <a title="166-lsi-14" href="./nips-2011-Multiple_Instance_Filtering.html">180 nips-2011-Multiple Instance Filtering</a></p>
<p>15 0.53642517 <a title="166-lsi-15" href="./nips-2011-Large-Scale_Category_Structure_Aware_Image_Categorization.html">141 nips-2011-Large-Scale Category Structure Aware Image Categorization</a></p>
<p>16 0.53532165 <a title="166-lsi-16" href="./nips-2011-Portmanteau_Vocabularies_for_Multi-Cue_Image_Representation.html">216 nips-2011-Portmanteau Vocabularies for Multi-Cue Image Representation</a></p>
<p>17 0.52119243 <a title="166-lsi-17" href="./nips-2011-Heavy-tailed_Distances_for_Gradient_Based_Image_Descriptors.html">112 nips-2011-Heavy-tailed Distances for Gradient Based Image Descriptors</a></p>
<p>18 0.51201189 <a title="166-lsi-18" href="./nips-2011-Message-Passing_for_Approximate_MAP_Inference_with_Latent_Variables.html">170 nips-2011-Message-Passing for Approximate MAP Inference with Latent Variables</a></p>
<p>19 0.50835246 <a title="166-lsi-19" href="./nips-2011-Recovering_Intrinsic_Images_with_a_Global_Sparsity_Prior_on_Reflectance.html">235 nips-2011-Recovering Intrinsic Images with a Global Sparsity Prior on Reflectance</a></p>
<p>20 0.50738871 <a title="166-lsi-20" href="./nips-2011-Image_Parsing_with_Stochastic_Scene_Grammar.html">127 nips-2011-Image Parsing with Stochastic Scene Grammar</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.02), (4, 0.096), (20, 0.069), (26, 0.025), (31, 0.069), (33, 0.045), (43, 0.06), (45, 0.093), (57, 0.048), (74, 0.04), (77, 0.264), (83, 0.028), (84, 0.013), (99, 0.041)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.76422203 <a title="166-lda-1" href="./nips-2011-Maximal_Cliques_that_Satisfy_Hard_Constraints_with_Application_to_Deformable_Object_Model_Learning.html">166 nips-2011-Maximal Cliques that Satisfy Hard Constraints with Application to Deformable Object Model Learning</a></p>
<p>Author: Xinggang Wang, Xiang Bai, Xingwei Yang, Wenyu Liu, Longin J. Latecki</p><p>Abstract: We propose a novel inference framework for ﬁnding maximal cliques in a weighted graph that satisfy hard constraints. The constraints specify the graph nodes that must belong to the solution as well as mutual exclusions of graph nodes, i.e., sets of nodes that cannot belong to the same solution. The proposed inference is based on a novel particle ﬁlter algorithm with state permeations. We apply the inference framework to a challenging problem of learning part-based, deformable object models. Two core problems in the learning framework, matching of image patches and ﬁnding salient parts, are formulated as two instances of the problem of ﬁnding maximal cliques with hard constraints. Our learning framework yields discriminative part based object models that achieve very good detection rate, and outperform other methods on object classes with large deformation. 1</p><p>2 0.72502786 <a title="166-lda-2" href="./nips-2011-Directed_Graph_Embedding%3A_an_Algorithm_based_on_Continuous_Limits_of_Laplacian-type_Operators.html">71 nips-2011-Directed Graph Embedding: an Algorithm based on Continuous Limits of Laplacian-type Operators</a></p>
<p>Author: Dominique C. Perrault-joncas, Marina Meila</p><p>Abstract: This paper considers the problem of embedding directed graphs in Euclidean space while retaining directional information. We model the observed graph as a sample from a manifold endowed with a vector ﬁeld, and we design an algorithm that separates and recovers the features of this process: the geometry of the manifold, the data density and the vector ﬁeld. The algorithm is motivated by our analysis of Laplacian-type operators and their continuous limit as generators of diffusions on a manifold. We illustrate the recovery algorithm on both artiﬁcially constructed and real data. 1 Motivation Recent advances in graph embedding and visualization have focused on undirected graphs, for which the graph Laplacian properties make the analysis particularly elegant [1, 2]. However, there is an important number of graph data, such as social networks, alignment scores between biological sequences, and citation data, which are naturally asymmetric. A commonly used approach for this type of data is to disregard the asymmetry by studying the spectral properties of W +W T or W T W , where W is the afﬁnity matrix of the graph. Some approaches have been offered to preserve the asymmetry information contained in data: [3], [4], [5] or to deﬁne directed Laplacian operators [6]. Although quite successful, these works adopt a purely graph-theoretical point of view. Thus, they are not concerned with the generative process that produces the graph, nor with the interpretability and statistical properties of their algorithms. In contrast, we view the nodes of a directed graph as a ﬁnite sample from a manifold in Euclidean space, and the edges as macroscopic observations of a diffusion kernel between neighboring points on the manifold. We explore how this diffusion kernel determines the overall connectivity and asymmetry of the resulting graph and demonstrate how Laplacian-type operators of this graph can offer insights into the underlying generative process. Based on the analysis of the Laplacian-type operators, we derive an algorithm that, in the limit of inﬁnite sample and vanishing bandwidth, recovers the key features of the sampling process: manifold geometry, sampling distribution, and local directionality, up to their intrinsic indeterminacies. 2 Model The ﬁrst premise here is that we observe a directed graph G, with n nodes, having weights W = [Wij ] for the edge from node i to node j. In following with common Laplacian-based embedding approaches, we assume that G is a geometric random graph constructed from n points sampled according to distribution p = e−U on an unobserved compact smooth manifold M ⊆ Rl of known intrinsic dimension d ≤ l. The edge weight Wij is then determined by a directed similarity kernel k (xi , xj ) with bandwidth . The directional component of k (xi , xj ) will be taken to be derived 1 from a vector ﬁeld r on M, which assigns a preferred direction between weights Wij and Wji . The choice of a vector ﬁeld r to characterize the directional component of G might seem restrictive at ﬁrst. In the asymptotic limit of → 0 and n → ∞ however, kernels are characterized by their diffusion, drift, and source components [7]. As such, r is sufﬁcient to characterize any directionality associated with a drift component and as it turns out, the component of r normal M in Rl can also be use to characterize any source component. As for the diffusion component, it is not possible to uniquely identify it from G alone [8]. Some absolute knownledge of M is needed to say anything about it. Hence, without loss of generality, we will construct k (xi , xj ) so that the diffusion component ends being isotropic and constant, i.e. equal to Laplace-Beltrami operator ∆ on M. The schematic of this generative process is shown in the top left of Figure 1 below. From left to right: the graph generative process mapping the sample on M to geometric random graph G via the kernel k (x, y), then the subsequent embedding (α) Ψn of G by operators Haa,n , (α) Hss,n (deﬁned in section 3.1). As these operators converge to (α) their respective limits, Haa and (α) Hss , so will Ψn → Ψ, pn → p, and rn → r. We design an algorithm that, given G, produces the top right embedding (Ψn , pn , and rn ). Figure 1: Schematic of our framework. The question is then as follows: can the generative process’ geometry M, distribution p = e−U , and directionality r, be recovered from G? In other words, is there an embedding of G in Rm , m ≥ d that approximates all three components of the process and that is also consistent as sample size increases and the bandwidth vanishes? In the case of undirected graphs, the theory of Laplacian eigenmaps [1] and Diffusion maps [9] answers this question in the afﬁrmative, in that the geometry of M and p = e−U can be inferred using spectral graph theory. The aim here is to build on the undirected problem and recover all three components of the generative process from a directed graph G. The spectral approach to undirected graph embedding relies on the fact that eigenfunctions of the Laplace-Beltrami operator are known to preserve the local geometry of M [1]. With a consistent empirical Laplace-Beltrami operator based on G, its eigenvectors also recover the geometry of M and converge to the corresponding eigenfunctions on M. For a directed graph G, an additional operator is needed to recover the local directional component r, but the principle remains the same. (α) The schematic for this is shown in Figure 1 where two operators - Hss,n , introduced in [9] for (α) undirected embeddings, and Haa,n , a new operator deﬁned in section 3.1 - are used to obtain the (α) (α) (α) embedding Ψn , distribution pn , and vector ﬁeld rn . As Haa,n and Hss,n converge to Haa and (α) Hss , Ψn , pn , and rn also converge to Ψ, p, and r, where Ψ is the local geometry preserving the embedding of M into Rm . (α) The algorithm we propose in Section 4 will calculate the matrices corresponding to H·,n from the graph G, and with their eigenvectors, will ﬁnd estimates for the node coordinates Ψ, the directional component r, and the sampling distribution p. In the next section we brieﬂy describe the mathematical models of the diffusion processes that our model relies on. 2 2.1 Problem Setting The similarity kernel k (x, y) can be used to deﬁne transport operators on M. The natural transport operator is deﬁned by normalizing k (x, y) as T [f ](x) = M k (x, y) f (y)p(y)dy , where p (x) = p (x) k (x, y)p(y)dy . (1) M T [f ](x) represents the diffusion of a distribution f (y) by the transition density k (x, y)p(y)/ k (x, y )p(y )dy . The eigenfunctions of this inﬁnitesimal operator are the continuous limit of the eigenvectors of the transition probability matrix P = D−1 W given by normalizing the afﬁnity matrix W of G by D = diag(W 1) [10]. Meanwhile, the inﬁnitesimal transition ∂f (T − I)f = lim (2) →0 ∂t deﬁnes the backward equation for this diffusion process over M based on kernel k . Obtaining the explicit expression for transport operators like (2) is then the main technical challenge. 2.2 Choice of Kernel In order for T [f ] to have the correct asymptotic form, some hypotheses about the similarity kernel k (x, y) are required. The hypotheses are best presented by considering the decomposition of k (x, y) into symmetric h (x, y) = h (y, x) and anti-symmetric a (x, y) = −a (y, x) components: k (x, y) = h (x, y) + a (x, y) . (3) The symmetric component h (x, y) is assumed to satisfy the following properties: 1. h (||y − 2 x||2 ) = h(||y−x|| / ) , and 2. h ≥ 0 and h is exponentially decreasing as ||y − x|| → ∞. This form d/2 of symmetric kernel was used in [9] to analyze the diffusion map. For the asymmetric part of the similarity kernel, we assume the form a (x, y) = r(x, y) h(||y − x||2 / ) · (y − x) , d/2 2 (4) with r(x, y) = r(y, x) so that a (x, y) = −a (y, x). Here r(x, y) is a smooth vector ﬁeld on the manifold that gives an orientation to the asymmetry of the kernel k (x, y). It is worth noting that the dependence of r(x, y) on both x and y implies that r : M × M → Rl with Rl the ambient space of M; however in the asymptotic limit, the dependence in y is only important “locally” (x = y), and as such it is appropriate to think of r(x, x) being a vector ﬁeld on M. As a side note, it is worth pointing out that even though the form of a (x, y) might seem restrictive at ﬁrst, it is sufﬁciently rich to describe any vector ﬁeld . This can be seen by taking r(x, y) = (w(x) + w(y))/2 so that at x = y the resulting vector ﬁeld is given by r(x, x) = w(x) for an arbitrary vector ﬁeld w(x). 3 Continuous Limit of Laplacian Type Operators We are now ready to state the main asymptotic result. Proposition 3.1 Let M be a compact, closed, smooth manifold of dimension d and k (x, y) an asymmetric similarity kernel satisfying the conditions of section 2.2, then for any function f ∈ C 2 (M), the integral operator based on k has the asymptotic expansion k (x, y)f (y)dy = m0 f (x) + g(f (x), x) + o( ) , (5) M where g(f (x), x) = and m0 = Rd m2 (ω(x)f (x) + ∆f (x) + r · 2 h(||u||2 )du, m2 = Rd u2 h(||u||2 )du. i 3 f (x) + f (x) · r + c(x)f (x)) (6) The proof can be found in [8] along with the deﬁnition of ω(x) and c(x) in (6). For now, it sufﬁces to say that ω(x) corresponds to an interaction between the symmetric kernel h and the curvature of M and was ﬁrst derived in [9]. Meanwhile, c(x) is a new term that originates from the interaction between h and the component of r that is normal to M in the ambient space Rl . Proposition 3.1 foreshadows a general fact about spectral embedding algorithms: in most cases, Laplacian operators confound the effects of spatial proximity, sampling density and directional ﬂow due to the presence of the various terms above. 3.1 Anisotropic Limit Operators Proposition 3.1 above can be used to derive the limits of a variety of Laplacian type operators associated with spectral embedding algorithms like [5, 6, 3]. Although we will focus primarily on a few operators that give the most insight into the generative process and enable us to recover the model deﬁned in Figure 1, we ﬁrst present four distinct families of operators for completeness. These operator families are inspired by the anisotropic family of operators that [9] introduced for undirected graphs, which make use of anisotropic kernels of the form: k (α) (x, y) = k (x, y) pα (x)pα (y) , (7) with α ∈ [0, 1] where α = 0 is the isotropic limit. To normalize the anisotropic kernels, we need (α) (α) (α) as p (x) = M k (x, y)p(y)dy. From (7), four to redeﬁne the outdegrees distribution of k families of diffusion processes of the form ft = H (α) [f ](x) can be derived depending on which kernel is normalized and which outdegree distribution is used for the normalization. Speciﬁcally, (α) (α) we deﬁne transport operators by normalizing the asymmetric k or symmetric h kernels with the 1 asymmetric p or symmetric q = M h (x, y)p(y)dy outdegree distribution . To keep track of all options, we introduce the following notation: the operators will be indexed by the type of kernel and outdegree distribution they correspond to (symmetric or asymmetric), with the ﬁrst index identifying the kernel and the second index identifying the outdegree distribution. For example, the family of anisotropic limit operators introduced by [9] is deﬁned by normalizing the symmetric kernel by (α) the symmetric outdegree distribution, hence they will be denoted as Hss , with the superscript corresponding to the anisotropic power α. Proposition 3.2 With the above notation, (α) Haa [f ] = ∆f − 2 (1 − α) U · f + r· f (α) Has [f ] (α) Hsa [f ] (α) Hss [f ] = ∆f − 2 (1 − α) U · = ∆f − 2 (1 − α) U · = ∆f − 2(1 − α) U · (8) f − cf + (α − 1)(r · U )f − ( · r + (α − 1)r · f + (c + f. U )f · r)f + r · f (9) (10) (11) The proof of this proposition, which can be found in [8], follows from repeated application of Proposition 3.1 to p(y) or q(y) and then to k α (x, y) or hα (x, y), as well as the fact that p1 = α 1 p−α [1 − α (ω + ∆p p + 2r · p p +2 · r + c)] + o( ). (α) Thus, if we use the asymmetric k and p , we get Haa , deﬁned by the advected diffusion equa(α) tion (8). In general, Haa is not hermitian, so it commonly has complex eigenvectors. This makes (1) embedding directed graphs with this operator problematic. Nevertheless, Haa will play an important role in extracting the directionality of the sampling process. If we use the symmetric kernel h but the asymmetric outdegree distribution p , we get the family (α) of operators Hsa , of which the WCut of [3] is a special case (α = 0). If we reverse the above, i.e. (α) (α) (α) use k and q , we obtain Has . This turns out to be merely a combination of Haa and Hsa . 1 The reader may notice that there are in fact eight possible combinations of kernel and degree distribution, since the anisotripic kernel (7) could also be deﬁned using a symmetric or asymmetric outdegree distribution. However, there are only four distinct asymptotic results and they are all covered by using one kernel (symmetric or asymmetric) and one degree distribution (symmetric or asymmetric) throughout. 4 Algorithm 1 Directed Embedding Input: Afﬁnity matrix Wi,j and embedding dimension m, (m ≥ d) 1. S ← (W + W T )/2 (Steps 1–6 estimate the coordinates as in [11]) n 2. qi ← j=1 Si,j , Q = diag(q) 3. V ← Q−1 SQ−1 (1) n 4. qi ← j=1 Vi,j , Q(1) = diag(q (1) ) (1) −1 5. Hss,n ← Q(1) V 6. Compute the Ψ the n × (m + 1) matrix with orthonormal columns containing the m + 1 largest (1) right eigenvector (by eigenvalue) of Hss,n as well as the Λ the (m + 1) × (m + 1) diagonal matrix of eigenvalues. Eigenvectors 2 to m + 1 from Ψ are the m coordinates of the embedding. (1) 7. Compute π the left eigenvector of Hss,n with eigenvalue 1. (Steps 7–8 estimate the density) n 8. π ← π/ i=1 πi is the density distribution over the embedding. n 9. pi ← j=1 Wi,j , P = diag(p) (Steps 9–13 estimate the vector ﬁeld r) 10. T ← P −1 W P −1 (1) n 11. pi ← j=1 Ti,j , P (1) = diag(p(1) ) (1) −1 12. Haa,n ← P (1) T (1) (1) 13. R ← (Haa,n − Hss,n )Ψ/2. Columns 2 to m + 1 of R are the vector ﬁeld components in the direction of the corresponding coordinates of the embedding. (α) Finally, if we only consider the symmetric kernel h and degree distribution q , we recover Hss , the anisotropic kernels of [9] for symmetric graphs. This operator for α = 1 is shown to separate the manifold from the probability distribution [11] and will be used as part of our recovery algorithm. Isolating the Vector Field r 4 Our aim is to esimate the manifold M, the density distribution p = e−U , and the vector ﬁeld r. The (1) ﬁrst two components of the data can be recovered from Hss as shown in [11] and summarized in Algorithm 1. At this juncture, one feature of generative process is missing: the vector ﬁeld r. The natural approach (α) (α) for recovering r is to isolate the linear operator r · from Haa by substracting Hss : (α) (α) Haa − Hss = r · . (12) The advantage of recovering r in operator form as in (12) is that r · is coordinate free. In other words, as long as the chosen embedding of M is diffeomorphic to M2 , (12) can be used to express the component of r that lies in the tangent space T M, which we denote by r|| . Speciﬁcally, let Ψ be a diffeomorphic embedding of M ; the component of r along coordinate ψk is then given by r · ψk = rk , and so, in general, r|| = r · Ψ. (13) The subtle point that only r|| is recovered from (13) follows from the fact that the operator r · only deﬁned along M and hence any directional derivative is necessarily along T M. is Equation (13) and the previous observations are the basis for Algorithm 1, which recovers the three important features of the generative process for an asymmetric graph with afﬁnity matrix W . A similar approach can be employed to recover c + · r, or simply · r if r has no component perpendicular to the tangent space T M (meaning that c ≡ 0). Recovering c + · r is achieved by taking advantage of the fact that (1) (1) (Hsa − Hss ) = (c + 2 · r) , (14) (1) A diffeomorphic embedding is guaranteed by using the eigendecomposition of Hss . 5 (1) (1) which is a diagonal operator. Taking into account that for ﬁnite n (Hsa,n − Hss,n ) is not perfectly (1) (1) diagonal, using ψn ≡ 1n (vector of ones), i.e. (Hsa,n − Hss,n )[1n ] = (cn + · rn ), has been found (1) (1) empirically to be more stable than simply extracting the diagonal of (Hsa,n − Hss,n ). 5 Experiments Artiﬁcial Data For illustrative purposes, we begin by applying our method to an artiﬁcial example. We use the planet Earth as a manifold with a topographic density distribution, where sampling probability is proportional to elevation. We also consider two vector ﬁelds: the ﬁrst is parallel to the line of constant latitude and purely tangential to the sphere, while the second is parallel to the line of constant longitude with a component of the vector ﬁeld perpendicular to the manifold. The true model with constant latitude vector ﬁeld is shown in Figure 2, along with the estimated density and vector ﬁeld projected on the true manifold (sphere). Model Recovered Latitudinal (a) Longitudinal (b) Figure 2: (a): Sphere with latitudinal vector ﬁeld, i.e East-West asymmetry, with Wew > Wwe if node w lies to the West of node e. The graph nodes are sampled non-uniformly, with the topographic map of the world as sampling density. We sample n = 5000 nodes, and observe only the resulting W matrix, but not the node locations. From W , our algorithm estimates the sample locations (geometry), the vector ﬁeld (black arrows) generating the observed asymmetries, and the sampling distribution at each data point (colormap). (b) Vector ﬁelds on a spherical region (blue), and their estimates (red): latitudinal vector ﬁeld tangent to the manifold (left) and longitudinal vector ﬁeld with component perpendicular to manifold tangent plane (right). Both the estimated density and vector ﬁeld agree with the true model, demonstrating that for artiﬁcial data, the recovery algorithm 1 performs quite well. We note that the estimated density does not recover all the details of the original density, even for large sample size (here n = 5000 with = 0.07). Meanwhile, the estimated vector ﬁeld performs quite well even when the sampling is reduced to n = 500 with = 0.1. This can be seen in Figure 2, b, where the true and estimated vector ﬁelds are superimposed. Figure 2 also demonstrates how r · only recovers the tangential component of r. The estimated geometry is not shown on any of these ﬁgures, since the success of the diffusion map in recovering the geometry for such a simple manifold is already well established [2, 9]. Real DataThe National Longitudinal Survey of Youth (NLSY) 1979 Cohort is a representative sample of young men and women in the United States who were followed from 1979 to 2000 [12, 13]. The aim here is to use this survey to obtain a representation of the job market as a diffusion process over a manifold. The data set consists of a sample of 7,816 individual career sequences of length 64, listing the jobs a particular individual held every quarter between the ages of 20 and 36. Each token in the sequence identiﬁes a job. Each job corresponds to an industry × occupation pair. There are 25 unique industry and 20 unique occupation indices. Out of the 500 possible pairings, approximately 450 occur in the data, with only 213 occurring with sufﬁcient frequency to be included here. Thus, our graph G has 213 nodes - the jobs - and our observations consist of 7,816 walks between the graph nodes. We convert these walks to a directed graph with afﬁnity matrix W . Speciﬁcally, Wij represents the number of times a transition from job i to job j was observed (Note that this matrix is asymmetric, 6 i.e Wij = Wji ). Normalizing each row i of W by its outdegree di gives P = diag(di )−1 W , the non-parametric maximum likelihood estimator for the Markov chain over G for the progression (0) of career sequences. This Markov chain has as limit operator Haa , as the granularity of the job market increases along with the number of observations. Thus, in trying to recover the geometry, distribution and vector ﬁeld, we are actually interested in estimating the full advective effect of the (0) diffusion process generated by Haa ; that is, we want to estimate r · − 2 U · where we can use (0) (1) −2 U · = Hss − Hss to complement Algorithm 1. 0.25 1600 0.05 0.1 1400 0.1 3 0.7 1800 0.15 ! 0.8 0.15 0.2 0.9 0.2 2000 0.25 !30.05 0.6 0.5 0 0 0.4 1200 −0.05 −0.05 −0.1 0.3 −0.1 1000 0.2 −0.15 −0.15 800 −0.2 −0.25 0.1 −0.2 −0.25 −0.1 −0.05 0 !2 0.05 0.1 0.15 0.2 (a) −0.1 −0.05 0 !2 0.05 0.1 0.15 0.2 (b) Figure 3: Embedding the job market along with ﬁeld r − 2 U over the ﬁrst two non-constant eigenvectors. The color map corresponds to the mean monthly wage in dollars (a) and to the female proportion (b) for each job. We obtain an embedding of the job market that describes the relative position of jobs, their distribution, and the natural time progression from each job. Of these, the relative position and natural time progression are the most interesting. Together, they summarize the job market dynamics by describing which jobs are naturally “close” as well as where they can lead in the future. From a public policy perspective, this can potentially improve focus on certain jobs for helping individuals attain better upward mobility. The job market was found to be a high dimensional manifold. We present only the ﬁrst two dimen(0) sions, that is, the second and third eigenvectors of Hss , since the ﬁrst eigenvector is uninformative (constant) by construction. The eigenvectors showed correlation with important demographic data, such as wages and gender. Figure 3 displays this two-dimensional sub-embedding along with the directional information r − 2 U for each dimension. The plot shows very little net progression toward regions of increasing mean salary3 . This is somewhat surprising, but it is easy to overstate this observation: diffusion alone would be enough to move the individuals towards higher salary. What Figure 3 (a) suggests is that there appear to be no “external forces” advecting individuals towards higher salary. Nevertheless, there appear to be other external forces at play in the job market: Figure 3 (b), which is analogous to Figure 3 (a), but with gender replacing the salary color scheme, suggests that these forces push individuals towards greater gender differentiation. This is especially true amongst male-dominated jobs which appear to be advected toward the left edge of the embedding. Hence, this simple analysis of the job market can be seen as an indication that males and females tend to move away from each other over time, while neither seems to have a monopoly on high- or low- paying jobs. 6 Discussion This paper makes three contributions: (1) it introduces a manifold-based generative model for directed graphs with weighted edges, (2) it obtains asymptotic results for operators constructed from the directed graphs, and (3) these asymptotic results lead to a natural algorithm for estimating the model. 3 It is worth noting that in the NLSY data set, high paying jobs are teacher, nurse and mechanic. This is due to the fact that the career paths observed stop at at age 36, which is relatively early in an individual’s career. 7 Generative Models that assume that data are sampled from a manifold are standard for undirected graphs, but to our knowledge, none have yet been proposed for directed graphs. When W is symmetric, it is natural to assume that it depends on the points’ proximity. For asymmetric afﬁnities W , one must include an additional component to explain the asymmetry. In the asymptotic limit, this is tantamount to deﬁning a vector ﬁeld on the manifold. Algorithm We have used from [9] the idea of deﬁning anisotropic kernels (indexed by α) in order to separate the density p and the manifold geometry M. Also, we adopted their general assumptions about the symmetric part of the kernel. As a consequence, the recovery algorithm for p and M is identical to theirs. However, insofar as the asymmetric part of the kernel is concerned, everything, starting from the deﬁnition and the introduction of the vector ﬁeld r as a way to model the asymmetry, through the derivation of the asymptotic expression for the symmetric plus asymmetric kernel, is new. We go signiﬁcantly beyond the elegant idea of [9] regarding the use of anisotropic kernels by analyzing the four distinct renormalizations possible for a given α, each of them combining different aspects of M, p and r. Only the successful (and novel) combination of two different anisotropic operators is able to recover the directional ﬂow r. Algorithm 1 is natural, but we do not claim it is the only possible one in the context of our model. (α) For instance, we can also use Hsa to recover the operator · r (which empirically seems to have worse numerical properties than r · ). In the National Longitudinal Survery of Youth study, we were interested in the whole advective term, so we estimated it from a different combination of operators. Depending on the speciﬁc question, other features of the model could be obtained Limit Results Proposition 3.1 is a general result on the asymptotics of asymmetric kernels. Recovering the manifold and r is just one, albeit the most useful, of the many ways of exploiting these (0) results. For instance, Hsa is the limit operator of the operators used in [3] and [5]. The limit analysis could be extended to other digraph embedding algorithms such as [4, 6]. How general is our model? Any kernel can be decomposed into a symmetric and an asymmetric part, as we have done. The assumptions on the symmetric part h are standard. The paper of [7] goes one step further from these assumptions; we will discuss it in relationship with our work shortly. The more interesting question is how limiting are our assumptions regarding the choice of kernel, especially the asymmetric part, which we parameterized as a (x, y) = r/2 · (y − x)h (x, y) in (4). In the asymptotic limit, this choice turns out to be fully general, at least up to the identiﬁable aspects of the model. For a more detailed discussion of this issue, see [8]. In [7], Ting, Huang and Jordan presented asymptotic results for a general family of kernels that includes asymmetric and random kernels. Our k can be expressed in the notation of [7] by taking wx (y) ← 1+r(x, y)·(y−x), rx (y) ← 1, K0 ← h, h ← . Their assumptions are more general than the assumptions we make here, yet our model is general up to what can be identiﬁed from G alone. The distinction arises because [7] focuses on the graph construction methods from an observed sample of M, while we focus on explaining an observed directed graph G through a manifold generative process. Moreover, while the [7] results can be used to analyze data from directed graphs, they differ from our Proposition 3.1. Speciﬁcally, with respect to the limit in Theorem 3 from [7], we obtain the additional source terms f (x) · r and c(x)f (x) that follow from not enforcing (α) (α) conservation of mass while deﬁning operators Hsa and Has . We applied our theory of directed graph embedding to the analysis of the career sequences in Section 5, but asymmetric afﬁnity data abound in other social contexts, and in the physical and life sciences. Indeed, any “similarity” score that is obtained from a likelihood of the form Wvu =likelihood(u|v) is generally asymmetric. Hence our methods can be applied to study not only social networks, but also patterns of human movement, road trafﬁc, and trade relations, as well as alignment scores in molecular biology. Finally, the physical interpretation of our model also makes it naturally applicable to physical models of ﬂows. Acknowledgments This research was partially supported by NSW awards IIS-0313339 and IIS-0535100. 8 References [1] Belkin and Niyogi. Laplacian eigenmaps for dimensionality reduction and data representation. Neural Computation, 15:1373–1396, 2002. [2] Nadler, Lafon, and Coifman. Diffusion maps, spectral clustering and eigenfunctions of fokker-planck operators. In Neural Information Processing Systems Conference, 2006. [3] Meila and Pentney. Clustering by weighted cuts in directed graphs. In SIAM Data Mining Conference, 2007. [4] Zhou, Huang, and Scholkopf. Learning from labeled and unlabeled data on a directed graph. In International Conference on Machine Learning, pages 1041–1048, 2005. [5] Zhou, Schlkopf, and Hofmann. Semi-supervised learning on directed graphs. In Advances in Neural Information Processing Systems, volume 17, pages 1633–1640, 2005. [6] Fan R. K. Chung. The diameter and laplacian eigenvalues of directed graphs. Electr. J. Comb., 13, 2006. [7] Ting, Huang, and Jordan. An analysis of the convergence of graph Laplacians. In International Conference on Machine Learning, 2010. [8] Dominique Perrault-Joncas and Marina Meil˘ . Directed graph embedding: an algorithm based on contina uous limits of laplacian-type operators. Technical Report TR 587, University of Washington - Department of Statistics, November 2011. [9] Coifman and Lafon. Diffusion maps. Applied and Computational Harmonic Analysis, 21:6–30, 2006. [10] Mikhail Belkin and Partha Niyogi. Convergence of laplacian eigenmaps. preprint, short version NIPS 2008, 2008. [11] Coifman, Lafon, Lee, Maggioni, Warner, and Zucker. Geometric diffusions as a tool for harmonic analysis and structure deﬁnition of data: Diffusion maps. In Proceedings of the National Academy of Sciences, pages 7426–7431, 2005. [12] United States Department of Labor. National longitudinal survey of youth 1979 cohort. http://www.bls.gov/nls/, retrived October 2011. [13] Marc A. Scott. Afﬁnity models for career sequences. Journal of the Royal Statistical Society: Series C (Applied Statistics), 60(3):417–436, 2011. 9</p><p>3 0.69107848 <a title="166-lda-3" href="./nips-2011-t-divergence_Based_Approximate_Inference.html">306 nips-2011-t-divergence Based Approximate Inference</a></p>
<p>Author: Nan Ding, Yuan Qi, S.v.n. Vishwanathan</p><p>Abstract: Approximate inference is an important technique for dealing with large, intractable graphical models based on the exponential family of distributions. We extend the idea of approximate inference to the t-exponential family by deﬁning a new t-divergence. This divergence measure is obtained via convex duality between the log-partition function of the t-exponential family and a new t-entropy. We illustrate our approach on the Bayes Point Machine with a Student’s t-prior. 1</p><p>4 0.60272861 <a title="166-lda-4" href="./nips-2011-On_Learning_Discrete_Graphical_Models_using_Greedy_Methods.html">195 nips-2011-On Learning Discrete Graphical Models using Greedy Methods</a></p>
<p>Author: Ali Jalali, Christopher C. Johnson, Pradeep K. Ravikumar</p><p>Abstract: In this paper, we address the problem of learning the structure of a pairwise graphical model from samples in a high-dimensional setting. Our ﬁrst main result studies the sparsistency, or consistency in sparsity pattern recovery, properties of a forward-backward greedy algorithm as applied to general statistical models. As a special case, we then apply this algorithm to learn the structure of a discrete graphical model via neighborhood estimation. As a corollary of our general result, we derive sufﬁcient conditions on the number of samples n, the maximum nodedegree d and the problem size p, as well as other conditions on the model parameters, so that the algorithm recovers all the edges with high probability. Our result guarantees graph selection for samples scaling as n = Ω(d2 log(p)), in contrast to existing convex-optimization based algorithms that require a sample complexity of Ω(d3 log(p)). Further, the greedy algorithm only requires a restricted strong convexity condition which is typically milder than irrepresentability assumptions. We corroborate these results using numerical simulations at the end.</p><p>5 0.57625985 <a title="166-lda-5" href="./nips-2011-Image_Parsing_with_Stochastic_Scene_Grammar.html">127 nips-2011-Image Parsing with Stochastic Scene Grammar</a></p>
<p>Author: Yibiao Zhao, Song-chun Zhu</p><p>Abstract: This paper proposes a parsing algorithm for scene understanding which includes four aspects: computing 3D scene layout, detecting 3D objects (e.g. furniture), detecting 2D faces (windows, doors etc.), and segmenting background. In contrast to previous scene labeling work that applied discriminative classiﬁers to pixels (or super-pixels), we use a generative Stochastic Scene Grammar (SSG). This grammar represents the compositional structures of visual entities from scene categories, 3D foreground/background, 2D faces, to 1D lines. The grammar includes three types of production rules and two types of contextual relations. Production rules: (i) AND rules represent the decomposition of an entity into sub-parts; (ii) OR rules represent the switching among sub-types of an entity; (iii) SET rules represent an ensemble of visual entities. Contextual relations: (i) Cooperative “+” relations represent positive links between binding entities, such as hinged faces of a object or aligned boxes; (ii) Competitive “-” relations represents negative links between competing entities, such as mutually exclusive boxes. We design an efﬁcient MCMC inference algorithm, namely Hierarchical cluster sampling, to search in the large solution space of scene conﬁgurations. The algorithm has two stages: (i) Clustering: It forms all possible higher-level structures (clusters) from lower-level entities by production rules and contextual relations. (ii) Sampling: It jumps between alternative structures (clusters) in each layer of the hierarchy to ﬁnd the most probable conﬁguration (represented by a parse tree). In our experiment, we demonstrate the superiority of our algorithm over existing methods on public dataset. In addition, our approach achieves richer structures in the parse tree. 1</p><p>6 0.56675303 <a title="166-lda-6" href="./nips-2011-Learning_person-object_interactions_for_action_recognition_in_still_images.html">154 nips-2011-Learning person-object interactions for action recognition in still images</a></p>
<p>7 0.5574432 <a title="166-lda-7" href="./nips-2011-Kernel_Bayes%27_Rule.html">139 nips-2011-Kernel Bayes' Rule</a></p>
<p>8 0.55446732 <a title="166-lda-8" href="./nips-2011-Pylon_Model_for_Semantic_Segmentation.html">227 nips-2011-Pylon Model for Semantic Segmentation</a></p>
<p>9 0.55374795 <a title="166-lda-9" href="./nips-2011-%24%5Ctheta%24-MRF%3A_Capturing_Spatial_and_Semantic_Structure_in_the_Parameters_for_Scene_Understanding.html">1 nips-2011-$\theta$-MRF: Capturing Spatial and Semantic Structure in the Parameters for Scene Understanding</a></p>
<p>10 0.55330986 <a title="166-lda-10" href="./nips-2011-Video_Annotation_and_Tracking_with_Active_Learning.html">303 nips-2011-Video Annotation and Tracking with Active Learning</a></p>
<p>11 0.55291778 <a title="166-lda-11" href="./nips-2011-Probabilistic_Joint_Image_Segmentation_and_Labeling.html">223 nips-2011-Probabilistic Joint Image Segmentation and Labeling</a></p>
<p>12 0.55125839 <a title="166-lda-12" href="./nips-2011-Randomized_Algorithms_for_Comparison-based_Search.html">231 nips-2011-Randomized Algorithms for Comparison-based Search</a></p>
<p>13 0.55090398 <a title="166-lda-13" href="./nips-2011-Object_Detection_with_Grammar_Models.html">193 nips-2011-Object Detection with Grammar Models</a></p>
<p>14 0.54871368 <a title="166-lda-14" href="./nips-2011-Phase_transition_in_the_family_of_p-resistances.html">213 nips-2011-Phase transition in the family of p-resistances</a></p>
<p>15 0.54828644 <a title="166-lda-15" href="./nips-2011-Maximum_Margin_Multi-Instance_Learning.html">168 nips-2011-Maximum Margin Multi-Instance Learning</a></p>
<p>16 0.54808235 <a title="166-lda-16" href="./nips-2011-Convergent_Bounds_on_the_Euclidean_Distance.html">64 nips-2011-Convergent Bounds on the Euclidean Distance</a></p>
<p>17 0.54715419 <a title="166-lda-17" href="./nips-2011-Multiple_Instance_Filtering.html">180 nips-2011-Multiple Instance Filtering</a></p>
<p>18 0.54659384 <a title="166-lda-18" href="./nips-2011-Online_Learning%3A_Stochastic%2C_Constrained%2C_and_Smoothed_Adversaries.html">204 nips-2011-Online Learning: Stochastic, Constrained, and Smoothed Adversaries</a></p>
<p>19 0.54330677 <a title="166-lda-19" href="./nips-2011-See_the_Tree_Through_the_Lines%3A_The_Shazoo_Algorithm.html">242 nips-2011-See the Tree Through the Lines: The Shazoo Algorithm</a></p>
<p>20 0.54213721 <a title="166-lda-20" href="./nips-2011-Spatial_distance_dependent_Chinese_restaurant_processes_for_image_segmentation.html">266 nips-2011-Spatial distance dependent Chinese restaurant processes for image segmentation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
