<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>83 nips-2011-Efficient inference in matrix-variate Gaussian models with \iid observation noise</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-83" href="#">nips2011-83</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>83 nips-2011-Efficient inference in matrix-variate Gaussian models with \iid observation noise</h1>
<br/><p>Source: <a title="nips-2011-83-pdf" href="http://papers.nips.cc/paper/4281-efficient-inference-in-matrix-variate-gaussian-models-with-iid-observation-noise.pdf">pdf</a></p><p>Author: Oliver Stegle, Christoph Lippert, Joris M. Mooij, Neil D. Lawrence, Karsten M. Borgwardt</p><p>Abstract: Inference in matrix-variate Gaussian models has major applications for multioutput prediction and joint learning of row and column covariances from matrixvariate data. Here, we discuss an approach for efﬁcient inference in such models that explicitly account for iid observation noise. Computational tractability can be retained by exploiting the Kronecker product between row and column covariance matrices. Using this framework, we show how to generalize the Graphical Lasso in order to learn a sparse inverse covariance between features while accounting for a low-rank confounding covariance between samples. We show practical utility on applications to biology, where we model covariances with more than 100,000 dimensions. We ﬁnd greater accuracy in recovering biological network structures and are able to better reconstruct the confounders. 1</p><p>Reference: <a title="nips-2011-83-reference" href="../nips2011_reference/nips-2011-Efficient_inference_in_matrix-variate_Gaussian_models_with_%5Ciid_observation_noise_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('glasso', 0.717), ('confound', 0.356), ('vec', 0.314), ('kroneck', 0.313), ('iid', 0.116), ('cov', 0.087), ('sr', 0.082), ('ln', 0.072), ('gplvm', 0.069), ('sc', 0.069), ('geost', 0.068), ('yuc', 0.068), ('network', 0.063), ('ut', 0.06), ('account', 0.056), ('invers', 0.055), ('glucos', 0.055), ('pjnk', 0.051), ('pka', 0.051), ('pkc', 0.051)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="83-tfidf-1" href="./nips-2011-Efficient_inference_in_matrix-variate_Gaussian_models_with_%5Ciid_observation_noise.html">83 nips-2011-Efficient inference in matrix-variate Gaussian models with \iid observation noise</a></p>
<p>2 0.18020256 <a title="83-tfidf-2" href="./nips-2011-Sparse_Inverse_Covariance_Matrix_Estimation_Using_Quadratic_Approximation.html">262 nips-2011-Sparse Inverse Covariance Matrix Estimation Using Quadratic Approximation</a></p>
<p>3 0.13228948 <a title="83-tfidf-3" href="./nips-2011-Sparse_Bayesian_Multi-Task_Learning.html">258 nips-2011-Sparse Bayesian Multi-Task Learning</a></p>
<p>4 0.12807573 <a title="83-tfidf-4" href="./nips-2011-RTRMC%3A_A_Riemannian_trust-region_method_for_low-rank_matrix_completion.html">230 nips-2011-RTRMC: A Riemannian trust-region method for low-rank matrix completion</a></p>
<p>5 0.082688689 <a title="83-tfidf-5" href="./nips-2011-Generalised_Coupled_Tensor_Factorisation.html">102 nips-2011-Generalised Coupled Tensor Factorisation</a></p>
<p>6 0.064234152 <a title="83-tfidf-6" href="./nips-2011-Sparse_Estimation_with_Structured_Dictionaries.html">259 nips-2011-Sparse Estimation with Structured Dictionaries</a></p>
<p>7 0.064120159 <a title="83-tfidf-7" href="./nips-2011-Robust_Lasso_with_missing_and_grossly_corrupted_observations.html">239 nips-2011-Robust Lasso with missing and grossly corrupted observations</a></p>
<p>8 0.063501917 <a title="83-tfidf-8" href="./nips-2011-Learning_Probabilistic_Non-Linear_Latent_Variable_Models_for_Tracking_Complex_Activities.html">148 nips-2011-Learning Probabilistic Non-Linear Latent Variable Models for Tracking Complex Activities</a></p>
<p>9 0.062726177 <a title="83-tfidf-9" href="./nips-2011-High-dimensional_regression_with_noisy_and_missing_data%3A_Provable_guarantees_with_non-convexity.html">118 nips-2011-High-dimensional regression with noisy and missing data: Provable guarantees with non-convexity</a></p>
<p>10 0.057024848 <a title="83-tfidf-10" href="./nips-2011-Practical_Variational_Inference_for_Neural_Networks.html">217 nips-2011-Practical Variational Inference for Neural Networks</a></p>
<p>11 0.055595886 <a title="83-tfidf-11" href="./nips-2011-Trace_Lasso%3A_a_trace_norm_regularization_for_correlated_designs.html">289 nips-2011-Trace Lasso: a trace norm regularization for correlated designs</a></p>
<p>12 0.052049395 <a title="83-tfidf-12" href="./nips-2011-Variational_Gaussian_Process_Dynamical_Systems.html">301 nips-2011-Variational Gaussian Process Dynamical Systems</a></p>
<p>13 0.048039749 <a title="83-tfidf-13" href="./nips-2011-Comparative_Analysis_of_Viterbi_Training_and_Maximum_Likelihood_Estimation_for_HMMs.html">57 nips-2011-Comparative Analysis of Viterbi Training and Maximum Likelihood Estimation for HMMs</a></p>
<p>14 0.041544262 <a title="83-tfidf-14" href="./nips-2011-Large-Scale_Sparse_Principal_Component_Analysis_with_Application_to_Text_Data.html">142 nips-2011-Large-Scale Sparse Principal Component Analysis with Application to Text Data</a></p>
<p>15 0.040537436 <a title="83-tfidf-15" href="./nips-2011-Sparse_Features_for_PCA-Like_Linear_Regression.html">260 nips-2011-Sparse Features for PCA-Like Linear Regression</a></p>
<p>16 0.040458642 <a title="83-tfidf-16" href="./nips-2011-Sparse_Filtering.html">261 nips-2011-Sparse Filtering</a></p>
<p>17 0.039150018 <a title="83-tfidf-17" href="./nips-2011-A_Convergence_Analysis_of_Log-Linear_Training.html">4 nips-2011-A Convergence Analysis of Log-Linear Training</a></p>
<p>18 0.039131742 <a title="83-tfidf-18" href="./nips-2011-Dimensionality_Reduction_Using_the_Sparse_Linear_Model.html">70 nips-2011-Dimensionality Reduction Using the Sparse Linear Model</a></p>
<p>19 0.038585234 <a title="83-tfidf-19" href="./nips-2011-Universal_low-rank_matrix_recovery_from_Pauli_measurements.html">297 nips-2011-Universal low-rank matrix recovery from Pauli measurements</a></p>
<p>20 0.036951341 <a title="83-tfidf-20" href="./nips-2011-Statistical_Performance_of_Convex_Tensor_Decomposition.html">270 nips-2011-Statistical Performance of Convex Tensor Decomposition</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.122), (1, -0.007), (2, 0.018), (3, 0.061), (4, 0.073), (5, 0.029), (6, 0.065), (7, 0.008), (8, 0.015), (9, -0.009), (10, -0.068), (11, 0.048), (12, -0.085), (13, -0.018), (14, -0.025), (15, 0.015), (16, -0.017), (17, -0.056), (18, -0.011), (19, -0.025), (20, -0.053), (21, 0.042), (22, 0.02), (23, -0.009), (24, -0.082), (25, 0.046), (26, -0.037), (27, 0.053), (28, -0.006), (29, 0.021), (30, 0.018), (31, -0.018), (32, -0.04), (33, 0.016), (34, 0.03), (35, -0.027), (36, -0.093), (37, 0.015), (38, -0.107), (39, -0.007), (40, 0.086), (41, 0.068), (42, 0.075), (43, 0.06), (44, -0.044), (45, -0.075), (46, -0.115), (47, -0.008), (48, 0.059), (49, 0.149)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.86299527 <a title="83-lsi-1" href="./nips-2011-Efficient_inference_in_matrix-variate_Gaussian_models_with_%5Ciid_observation_noise.html">83 nips-2011-Efficient inference in matrix-variate Gaussian models with \iid observation noise</a></p>
<p>2 0.62758255 <a title="83-lsi-2" href="./nips-2011-Sparse_Bayesian_Multi-Task_Learning.html">258 nips-2011-Sparse Bayesian Multi-Task Learning</a></p>
<p>3 0.62323791 <a title="83-lsi-3" href="./nips-2011-Sparse_Inverse_Covariance_Matrix_Estimation_Using_Quadratic_Approximation.html">262 nips-2011-Sparse Inverse Covariance Matrix Estimation Using Quadratic Approximation</a></p>
<p>4 0.56192207 <a title="83-lsi-4" href="./nips-2011-Learning_Auto-regressive_Models_from_Sequence_and_Non-sequence_Data.html">144 nips-2011-Learning Auto-regressive Models from Sequence and Non-sequence Data</a></p>
<p>5 0.55726337 <a title="83-lsi-5" href="./nips-2011-RTRMC%3A_A_Riemannian_trust-region_method_for_low-rank_matrix_completion.html">230 nips-2011-RTRMC: A Riemannian trust-region method for low-rank matrix completion</a></p>
<p>6 0.50552458 <a title="83-lsi-6" href="./nips-2011-A_Convergence_Analysis_of_Log-Linear_Training.html">4 nips-2011-A Convergence Analysis of Log-Linear Training</a></p>
<p>7 0.48120955 <a title="83-lsi-7" href="./nips-2011-Variational_Gaussian_Process_Dynamical_Systems.html">301 nips-2011-Variational Gaussian Process Dynamical Systems</a></p>
<p>8 0.48084629 <a title="83-lsi-8" href="./nips-2011-Clustered_Multi-Task_Learning_Via_Alternating_Structure_Optimization.html">51 nips-2011-Clustered Multi-Task Learning Via Alternating Structure Optimization</a></p>
<p>9 0.47881228 <a title="83-lsi-9" href="./nips-2011-Regularized_Laplacian_Estimation_and_Fast_Eigenvector_Approximation.html">236 nips-2011-Regularized Laplacian Estimation and Fast Eigenvector Approximation</a></p>
<p>10 0.45803142 <a title="83-lsi-10" href="./nips-2011-Practical_Variational_Inference_for_Neural_Networks.html">217 nips-2011-Practical Variational Inference for Neural Networks</a></p>
<p>11 0.44964525 <a title="83-lsi-11" href="./nips-2011-Sparse_Features_for_PCA-Like_Linear_Regression.html">260 nips-2011-Sparse Features for PCA-Like Linear Regression</a></p>
<p>12 0.43611673 <a title="83-lsi-12" href="./nips-2011-Infinite_Latent_SVM_for_Classification_and_Multi-task_Learning.html">134 nips-2011-Infinite Latent SVM for Classification and Multi-task Learning</a></p>
<p>13 0.42701399 <a title="83-lsi-13" href="./nips-2011-Spike_and_Slab_Variational_Inference_for_Multi-Task_and_Multiple_Kernel_Learning.html">269 nips-2011-Spike and Slab Variational Inference for Multi-Task and Multiple Kernel Learning</a></p>
<p>14 0.42359951 <a title="83-lsi-14" href="./nips-2011-High-dimensional_regression_with_noisy_and_missing_data%3A_Provable_guarantees_with_non-convexity.html">118 nips-2011-High-dimensional regression with noisy and missing data: Provable guarantees with non-convexity</a></p>
<p>15 0.41871738 <a title="83-lsi-15" href="./nips-2011-Robust_Lasso_with_missing_and_grossly_corrupted_observations.html">239 nips-2011-Robust Lasso with missing and grossly corrupted observations</a></p>
<p>16 0.41529396 <a title="83-lsi-16" href="./nips-2011-Robust_Multi-Class_Gaussian_Process_Classification.html">240 nips-2011-Robust Multi-Class Gaussian Process Classification</a></p>
<p>17 0.41472322 <a title="83-lsi-17" href="./nips-2011-Scalable_Training_of_Mixture_Models_via_Coresets.html">241 nips-2011-Scalable Training of Mixture Models via Coresets</a></p>
<p>18 0.41143304 <a title="83-lsi-18" href="./nips-2011-Large-Scale_Sparse_Principal_Component_Analysis_with_Application_to_Text_Data.html">142 nips-2011-Large-Scale Sparse Principal Component Analysis with Application to Text Data</a></p>
<p>19 0.40958208 <a title="83-lsi-19" href="./nips-2011-SpaRCS%3A_Recovering_low-rank_and_sparse_matrices_from_compressive_measurements.html">257 nips-2011-SpaRCS: Recovering low-rank and sparse matrices from compressive measurements</a></p>
<p>20 0.40558186 <a title="83-lsi-20" href="./nips-2011-Divide-and-Conquer_Matrix_Factorization.html">73 nips-2011-Divide-and-Conquer Matrix Factorization</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.072), (22, 0.072), (28, 0.01), (36, 0.041), (51, 0.34), (53, 0.011), (55, 0.1), (65, 0.081), (68, 0.119), (76, 0.011), (79, 0.013), (99, 0.012)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.66836971 <a title="83-lda-1" href="./nips-2011-Efficient_inference_in_matrix-variate_Gaussian_models_with_%5Ciid_observation_noise.html">83 nips-2011-Efficient inference in matrix-variate Gaussian models with \iid observation noise</a></p>
<p>2 0.50198859 <a title="83-lda-2" href="./nips-2011-Learning_Anchor_Planes_for_Classification.html">143 nips-2011-Learning Anchor Planes for Classification</a></p>
<p>3 0.50051928 <a title="83-lda-3" href="./nips-2011-Non-Asymptotic_Analysis_of_Stochastic_Approximation_Algorithms_for_Machine_Learning.html">187 nips-2011-Non-Asymptotic Analysis of Stochastic Approximation Algorithms for Machine Learning</a></p>
<p>4 0.4998017 <a title="83-lda-4" href="./nips-2011-Trace_Lasso%3A_a_trace_norm_regularization_for_correlated_designs.html">289 nips-2011-Trace Lasso: a trace norm regularization for correlated designs</a></p>
<p>5 0.49879044 <a title="83-lda-5" href="./nips-2011-Sparse_Recovery_with_Brownian_Sensing.html">264 nips-2011-Sparse Recovery with Brownian Sensing</a></p>
<p>6 0.49441779 <a title="83-lda-6" href="./nips-2011-Robust_Lasso_with_missing_and_grossly_corrupted_observations.html">239 nips-2011-Robust Lasso with missing and grossly corrupted observations</a></p>
<p>7 0.49284434 <a title="83-lda-7" href="./nips-2011-On_the_accuracy_of_l1-filtering_of_signals_with_block-sparse_structure.html">203 nips-2011-On the accuracy of l1-filtering of signals with block-sparse structure</a></p>
<p>8 0.49258274 <a title="83-lda-8" href="./nips-2011-A_Denoising_View_of_Matrix_Completion.html">5 nips-2011-A Denoising View of Matrix Completion</a></p>
<p>9 0.4918988 <a title="83-lda-9" href="./nips-2011-Information_Rates_and_Optimal_Decoding_in_Large_Neural_Populations.html">135 nips-2011-Information Rates and Optimal Decoding in Large Neural Populations</a></p>
<p>10 0.49064586 <a title="83-lda-10" href="./nips-2011-Sparse_Estimation_with_Structured_Dictionaries.html">259 nips-2011-Sparse Estimation with Structured Dictionaries</a></p>
<p>11 0.49018693 <a title="83-lda-11" href="./nips-2011-Convergent_Fitted_Value_Iteration_with_Linear_Function_Approximation.html">65 nips-2011-Convergent Fitted Value Iteration with Linear Function Approximation</a></p>
<p>12 0.49006295 <a title="83-lda-12" href="./nips-2011-Universal_low-rank_matrix_recovery_from_Pauli_measurements.html">297 nips-2011-Universal low-rank matrix recovery from Pauli measurements</a></p>
<p>13 0.48867661 <a title="83-lda-13" href="./nips-2011-Kernel_Embeddings_of_Latent_Tree_Graphical_Models.html">140 nips-2011-Kernel Embeddings of Latent Tree Graphical Models</a></p>
<p>14 0.48839155 <a title="83-lda-14" href="./nips-2011-Convergence_Rates_of_Inexact_Proximal-Gradient_Methods_for_Convex_Optimization.html">63 nips-2011-Convergence Rates of Inexact Proximal-Gradient Methods for Convex Optimization</a></p>
<p>15 0.48831901 <a title="83-lda-15" href="./nips-2011-Evaluating_the_inverse_decision-making_approach_to_preference_learning.html">90 nips-2011-Evaluating the inverse decision-making approach to preference learning</a></p>
<p>16 0.48830295 <a title="83-lda-16" href="./nips-2011-Generalized_Lasso_based_Approximation_of_Sparse_Coding_for_Visual_Recognition.html">105 nips-2011-Generalized Lasso based Approximation of Sparse Coding for Visual Recognition</a></p>
<p>17 0.48793182 <a title="83-lda-17" href="./nips-2011-An_ideal_observer_model_for_identifying_the_reference_frame_of_objects.html">35 nips-2011-An ideal observer model for identifying the reference frame of objects</a></p>
<p>18 0.48762044 <a title="83-lda-18" href="./nips-2011-Structured_sparse_coding_via_lateral_inhibition.html">276 nips-2011-Structured sparse coding via lateral inhibition</a></p>
<p>19 0.48732293 <a title="83-lda-19" href="./nips-2011-Neural_Reconstruction_with_Approximate_Message_Passing_%28NeuRAMP%29.html">183 nips-2011-Neural Reconstruction with Approximate Message Passing (NeuRAMP)</a></p>
<p>20 0.48726335 <a title="83-lda-20" href="./nips-2011-Inference_in_continuous-time_change-point_models.html">131 nips-2011-Inference in continuous-time change-point models</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
