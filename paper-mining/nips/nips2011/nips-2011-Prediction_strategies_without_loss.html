<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>220 nips-2011-Prediction strategies without loss</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-220" href="#">nips2011-220</a> knowledge-graph by maker-knowledge-mining</p><h1>220 nips-2011-Prediction strategies without loss</h1>
<br/><p>Source: <a title="nips-2011-220-pdf" href="http://papers.nips.cc/paper/4388-prediction-strategies-without-loss.pdf">pdf</a></p><p>Author: Michael Kapralov, Rina Panigrahy</p><p>Abstract: Consider a sequence of bits where we are trying to predict the next bit from the previous bits. Assume we are allowed to say ‘predict 0’ or ‘predict 1’, and our payoff is +1 if the prediction is correct and −1 otherwise. We will say that at each point in time the loss of an algorithm is the number of wrong predictions minus the number of right predictions so far. In this paper we are interested in algorithms that have essentially zero (expected) loss over any string at any point in time and yet have small regret with respect to always predicting 0 or always predicting 1. For a sequence of length T our algorithm has regret 14 T and loss √ 2 2 T e− T in expectation for all strings. We show that the tradeoff between loss and regret is optimal up to constant factors. Our techniques extend to the general setting of N experts, where the related problem of trading off regret to the best expert for regret to the ’special’ expert has been studied by Even-Dar et al. (COLT’07). We obtain essentially zero loss with respect to the special expert and optimal loss/regret tradeoff, improving upon the results of Even-Dar et al and settling the main question left open in their paper. The strong loss bounds of the algorithm have some surprising consequences. First, we obtain a parameter free algorithm for the experts problem that has optimal regret bounds with respect to k-shifting optima, i.e. bounds with respect to the optimum that is allowed to change arms multiple times. Moreover, for any window of size n the regret of our algorithm to any expert never exceeds O( n(log N + log T )), where N is the number of experts and T is the time horizon, while maintaining the essentially zero loss property. 1</p><p>Reference: <a title="nips-2011-220-reference" href="../nips2011_reference/nips-2011-Prediction_strategies_without_loss_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('regret', 0.46), ('xt', 0.458), ('payoff', 0.421), ('bt', 0.347), ('expert', 0.281), ('bit', 0.139), ('loss', 0.122), ('strategies', 0.122), ('stock', 0.103), ('gambl', 0.091), ('strategy', 0.088), ('predict', 0.083), ('wjt', 0.08), ('erf', 0.08), ('window', 0.077), ('lemm', 0.075), ('kapralov', 0.068), ('xg', 0.068), ('tradeoff', 0.068), ('ft', 0.066)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999982 <a title="220-tfidf-1" href="./nips-2011-Prediction_strategies_without_loss.html">220 nips-2011-Prediction strategies without loss</a></p>
<p>2 0.36108235 <a title="220-tfidf-2" href="./nips-2011-Improved_Algorithms_for_Linear_Stochastic_Bandits.html">128 nips-2011-Improved Algorithms for Linear Stochastic Bandits</a></p>
<p>3 0.34292224 <a title="220-tfidf-3" href="./nips-2011-Learning_Eigenvectors_for_Free.html">145 nips-2011-Learning Eigenvectors for Free</a></p>
<p>4 0.30488473 <a title="220-tfidf-4" href="./nips-2011-Online_Learning%3A_Stochastic%2C_Constrained%2C_and_Smoothed_Adversaries.html">204 nips-2011-Online Learning: Stochastic, Constrained, and Smoothed Adversaries</a></p>
<p>5 0.28523877 <a title="220-tfidf-5" href="./nips-2011-Contextual_Gaussian_Process_Bandit_Optimization.html">61 nips-2011-Contextual Gaussian Process Bandit Optimization</a></p>
<p>6 0.25526196 <a title="220-tfidf-6" href="./nips-2011-Selecting_the_State-Representation_in_Reinforcement_Learning.html">245 nips-2011-Selecting the State-Representation in Reinforcement Learning</a></p>
<p>7 0.25090092 <a title="220-tfidf-7" href="./nips-2011-Approximating_Semidefinite_Programs_in_Sublinear_Time.html">39 nips-2011-Approximating Semidefinite Programs in Sublinear Time</a></p>
<p>8 0.24610493 <a title="220-tfidf-8" href="./nips-2011-Newtron%3A_an_Efficient_Bandit_algorithm_for_Online_Multiclass_Prediction.html">185 nips-2011-Newtron: an Efficient Bandit algorithm for Online Multiclass Prediction</a></p>
<p>9 0.21701425 <a title="220-tfidf-9" href="./nips-2011-Efficient_Online_Learning_via_Randomized_Rounding.html">80 nips-2011-Efficient Online Learning via Randomized Rounding</a></p>
<p>10 0.21356902 <a title="220-tfidf-10" href="./nips-2011-Adaptive_Hedge.html">25 nips-2011-Adaptive Hedge</a></p>
<p>11 0.20978779 <a title="220-tfidf-11" href="./nips-2011-PAC-Bayesian_Analysis_of_Contextual_Bandits.html">210 nips-2011-PAC-Bayesian Analysis of Contextual Bandits</a></p>
<p>12 0.19393487 <a title="220-tfidf-12" href="./nips-2011-On_Strategy_Stitching_in_Large_Extensive_Form_Multiplayer_Games.html">196 nips-2011-On Strategy Stitching in Large Extensive Form Multiplayer Games</a></p>
<p>13 0.1886013 <a title="220-tfidf-13" href="./nips-2011-From_Bandits_to_Experts%3A_On_the_Value_of_Side-Observations.html">98 nips-2011-From Bandits to Experts: On the Value of Side-Observations</a></p>
<p>14 0.1731869 <a title="220-tfidf-14" href="./nips-2011-An_Empirical_Evaluation_of_Thompson_Sampling.html">32 nips-2011-An Empirical Evaluation of Thompson Sampling</a></p>
<p>15 0.16102588 <a title="220-tfidf-15" href="./nips-2011-Sparse_Inverse_Covariance_Matrix_Estimation_Using_Quadratic_Approximation.html">262 nips-2011-Sparse Inverse Covariance Matrix Estimation Using Quadratic Approximation</a></p>
<p>16 0.15888791 <a title="220-tfidf-16" href="./nips-2011-Stochastic_convex_optimization_with_bandit_feedback.html">272 nips-2011-Stochastic convex optimization with bandit feedback</a></p>
<p>17 0.15569147 <a title="220-tfidf-17" href="./nips-2011-Committing_Bandits.html">56 nips-2011-Committing Bandits</a></p>
<p>18 0.15392382 <a title="220-tfidf-18" href="./nips-2011-Multi-armed_bandits_on_implicit_metric_spaces.html">177 nips-2011-Multi-armed bandits on implicit metric spaces</a></p>
<p>19 0.15385126 <a title="220-tfidf-19" href="./nips-2011-Predicting_Dynamic_Difficulty.html">218 nips-2011-Predicting Dynamic Difficulty</a></p>
<p>20 0.12305702 <a title="220-tfidf-20" href="./nips-2011-Finite_Time_Analysis_of_Stratified_Sampling_for_Monte_Carlo.html">97 nips-2011-Finite Time Analysis of Stratified Sampling for Monte Carlo</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.217), (1, -0.286), (2, -0.317), (3, 0.17), (4, -0.306), (5, 0.112), (6, -0.065), (7, 0.014), (8, 0.108), (9, -0.076), (10, -0.109), (11, 0.041), (12, 0.055), (13, -0.012), (14, -0.018), (15, 0.051), (16, -0.034), (17, 0.053), (18, -0.016), (19, 0.007), (20, 0.046), (21, 0.066), (22, 0.032), (23, -0.024), (24, -0.035), (25, -0.033), (26, -0.026), (27, 0.005), (28, 0.067), (29, 0.031), (30, 0.023), (31, 0.068), (32, -0.051), (33, 0.051), (34, -0.023), (35, -0.108), (36, -0.025), (37, -0.026), (38, -0.018), (39, -0.029), (40, -0.052), (41, 0.021), (42, -0.038), (43, 0.015), (44, -0.051), (45, -0.013), (46, -0.093), (47, -0.02), (48, 0.053), (49, 0.14)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95868635 <a title="220-lsi-1" href="./nips-2011-Prediction_strategies_without_loss.html">220 nips-2011-Prediction strategies without loss</a></p>
<p>2 0.79747909 <a title="220-lsi-2" href="./nips-2011-Newtron%3A_an_Efficient_Bandit_algorithm_for_Online_Multiclass_Prediction.html">185 nips-2011-Newtron: an Efficient Bandit algorithm for Online Multiclass Prediction</a></p>
<p>3 0.77074051 <a title="220-lsi-3" href="./nips-2011-Improved_Algorithms_for_Linear_Stochastic_Bandits.html">128 nips-2011-Improved Algorithms for Linear Stochastic Bandits</a></p>
<p>4 0.74717683 <a title="220-lsi-4" href="./nips-2011-Learning_Eigenvectors_for_Free.html">145 nips-2011-Learning Eigenvectors for Free</a></p>
<p>5 0.72666538 <a title="220-lsi-5" href="./nips-2011-Online_Learning%3A_Stochastic%2C_Constrained%2C_and_Smoothed_Adversaries.html">204 nips-2011-Online Learning: Stochastic, Constrained, and Smoothed Adversaries</a></p>
<p>6 0.69184959 <a title="220-lsi-6" href="./nips-2011-Efficient_Online_Learning_via_Randomized_Rounding.html">80 nips-2011-Efficient Online Learning via Randomized Rounding</a></p>
<p>7 0.63797569 <a title="220-lsi-7" href="./nips-2011-Stochastic_convex_optimization_with_bandit_feedback.html">272 nips-2011-Stochastic convex optimization with bandit feedback</a></p>
<p>8 0.61657262 <a title="220-lsi-8" href="./nips-2011-PAC-Bayesian_Analysis_of_Contextual_Bandits.html">210 nips-2011-PAC-Bayesian Analysis of Contextual Bandits</a></p>
<p>9 0.59298551 <a title="220-lsi-9" href="./nips-2011-Adaptive_Hedge.html">25 nips-2011-Adaptive Hedge</a></p>
<p>10 0.5805831 <a title="220-lsi-10" href="./nips-2011-Approximating_Semidefinite_Programs_in_Sublinear_Time.html">39 nips-2011-Approximating Semidefinite Programs in Sublinear Time</a></p>
<p>11 0.5785355 <a title="220-lsi-11" href="./nips-2011-An_Empirical_Evaluation_of_Thompson_Sampling.html">32 nips-2011-An Empirical Evaluation of Thompson Sampling</a></p>
<p>12 0.56777787 <a title="220-lsi-12" href="./nips-2011-Predicting_Dynamic_Difficulty.html">218 nips-2011-Predicting Dynamic Difficulty</a></p>
<p>13 0.56616604 <a title="220-lsi-13" href="./nips-2011-Contextual_Gaussian_Process_Bandit_Optimization.html">61 nips-2011-Contextual Gaussian Process Bandit Optimization</a></p>
<p>14 0.5630092 <a title="220-lsi-14" href="./nips-2011-Selecting_the_State-Representation_in_Reinforcement_Learning.html">245 nips-2011-Selecting the State-Representation in Reinforcement Learning</a></p>
<p>15 0.54468691 <a title="220-lsi-15" href="./nips-2011-From_Bandits_to_Experts%3A_On_the_Value_of_Side-Observations.html">98 nips-2011-From Bandits to Experts: On the Value of Side-Observations</a></p>
<p>16 0.46316284 <a title="220-lsi-16" href="./nips-2011-On_Strategy_Stitching_in_Large_Extensive_Form_Multiplayer_Games.html">196 nips-2011-On Strategy Stitching in Large Extensive Form Multiplayer Games</a></p>
<p>17 0.43727744 <a title="220-lsi-17" href="./nips-2011-Sparse_Inverse_Covariance_Matrix_Estimation_Using_Quadratic_Approximation.html">262 nips-2011-Sparse Inverse Covariance Matrix Estimation Using Quadratic Approximation</a></p>
<p>18 0.41668922 <a title="220-lsi-18" href="./nips-2011-Active_Learning_with_a_Drifting_Distribution.html">21 nips-2011-Active Learning with a Drifting Distribution</a></p>
<p>19 0.40162361 <a title="220-lsi-19" href="./nips-2011-On_the_Universality_of_Online_Mirror_Descent.html">202 nips-2011-On the Universality of Online Mirror Descent</a></p>
<p>20 0.39935642 <a title="220-lsi-20" href="./nips-2011-Multi-armed_bandits_on_implicit_metric_spaces.html">177 nips-2011-Multi-armed bandits on implicit metric spaces</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.052), (22, 0.041), (35, 0.093), (36, 0.032), (54, 0.011), (55, 0.284), (65, 0.026), (68, 0.304), (79, 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97595215 <a title="220-lda-1" href="./nips-2011-Prediction_strategies_without_loss.html">220 nips-2011-Prediction strategies without loss</a></p>
<p>2 0.96637595 <a title="220-lda-2" href="./nips-2011-Online_Learning%3A_Stochastic%2C_Constrained%2C_and_Smoothed_Adversaries.html">204 nips-2011-Online Learning: Stochastic, Constrained, and Smoothed Adversaries</a></p>
<p>3 0.96607172 <a title="220-lda-3" href="./nips-2011-Query-Aware_MCMC.html">229 nips-2011-Query-Aware MCMC</a></p>
<p>4 0.96564168 <a title="220-lda-4" href="./nips-2011-Multi-Bandit_Best_Arm_Identification.html">175 nips-2011-Multi-Bandit Best Arm Identification</a></p>
<p>5 0.9643364 <a title="220-lda-5" href="./nips-2011-Shallow_vs._Deep_Sum-Product_Networks.html">250 nips-2011-Shallow vs. Deep Sum-Product Networks</a></p>
<p>6 0.96384656 <a title="220-lda-6" href="./nips-2011-Fast_and_Balanced%3A_Efficient_Label_Tree_Learning_for_Large_Scale_Object_Recognition.html">96 nips-2011-Fast and Balanced: Efficient Label Tree Learning for Large Scale Object Recognition</a></p>
<p>7 0.9634434 <a title="220-lda-7" href="./nips-2011-Efficient_Online_Learning_via_Randomized_Rounding.html">80 nips-2011-Efficient Online Learning via Randomized Rounding</a></p>
<p>8 0.96289039 <a title="220-lda-8" href="./nips-2011-Autonomous_Learning_of_Action_Models_for_Planning.html">41 nips-2011-Autonomous Learning of Action Models for Planning</a></p>
<p>9 0.96168607 <a title="220-lda-9" href="./nips-2011-A_Brain-Machine_Interface_Operating_with_a_Real-Time_Spiking_Neural_Network_Control_Algorithm.html">2 nips-2011-A Brain-Machine Interface Operating with a Real-Time Spiking Neural Network Control Algorithm</a></p>
<p>10 0.96149623 <a title="220-lda-10" href="./nips-2011-Learning_with_the_weighted_trace-norm_under_arbitrary_sampling_distributions.html">159 nips-2011-Learning with the weighted trace-norm under arbitrary sampling distributions</a></p>
<p>11 0.96055889 <a title="220-lda-11" href="./nips-2011-Boosting_with_Maximum_Adaptive_Sampling.html">49 nips-2011-Boosting with Maximum Adaptive Sampling</a></p>
<p>12 0.96031797 <a title="220-lda-12" href="./nips-2011-Simultaneous_Sampling_and_Multi-Structure_Fitting_with_Adaptive_Reversible_Jump_MCMC.html">255 nips-2011-Simultaneous Sampling and Multi-Structure Fitting with Adaptive Reversible Jump MCMC</a></p>
<p>13 0.96024299 <a title="220-lda-13" href="./nips-2011-From_Bandits_to_Experts%3A_On_the_Value_of_Side-Observations.html">98 nips-2011-From Bandits to Experts: On the Value of Side-Observations</a></p>
<p>14 0.96021867 <a title="220-lda-14" href="./nips-2011-An_Empirical_Evaluation_of_Thompson_Sampling.html">32 nips-2011-An Empirical Evaluation of Thompson Sampling</a></p>
<p>15 0.96014875 <a title="220-lda-15" href="./nips-2011-Improved_Algorithms_for_Linear_Stochastic_Bandits.html">128 nips-2011-Improved Algorithms for Linear Stochastic Bandits</a></p>
<p>16 0.96002257 <a title="220-lda-16" href="./nips-2011-Heavy-tailed_Distances_for_Gradient_Based_Image_Descriptors.html">112 nips-2011-Heavy-tailed Distances for Gradient Based Image Descriptors</a></p>
<p>17 0.95981717 <a title="220-lda-17" href="./nips-2011-Adaptive_Hedge.html">25 nips-2011-Adaptive Hedge</a></p>
<p>18 0.95980674 <a title="220-lda-18" href="./nips-2011-Newtron%3A_an_Efficient_Bandit_algorithm_for_Online_Multiclass_Prediction.html">185 nips-2011-Newtron: an Efficient Bandit algorithm for Online Multiclass Prediction</a></p>
<p>19 0.95864892 <a title="220-lda-19" href="./nips-2011-Algorithms_for_Hyper-Parameter_Optimization.html">30 nips-2011-Algorithms for Hyper-Parameter Optimization</a></p>
<p>20 0.95851219 <a title="220-lda-20" href="./nips-2011-Selecting_the_State-Representation_in_Reinforcement_Learning.html">245 nips-2011-Selecting the State-Representation in Reinforcement Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
