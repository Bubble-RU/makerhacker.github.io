<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>162 nips-2011-Lower Bounds for Passive and Active Learning</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-162" href="#">nips2011-162</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>162 nips-2011-Lower Bounds for Passive and Active Learning</h1>
<br/><p>Source: <a title="nips-2011-162-pdf" href="http://papers.nips.cc/paper/4325-lower-bounds-for-passive-and-active-learning.pdf">pdf</a></p><p>Author: Maxim Raginsky, Alexander Rakhlin</p><p>Abstract: We develop uniﬁed information-theoretic machinery for deriving lower bounds for passive and active learning schemes. Our bounds involve the so-called Alexander’s capacity function. The supremum of this function has been recently rediscovered by Hanneke in the context of active learning under the name of “disagreement coefﬁcient.” For passive learning, our lower bounds match the upper bounds of Gin´ and Koltchinskii up to constants and generalize analogous results of Mase sart and N´ d´ lec. For active learning, we provide ﬁrst known lower bounds based e e on the capacity function rather than the disagreement coefﬁcient. 1</p><p>Reference: <a title="nips-2011-162-reference" href="../nips2011_reference/nips-2011-Lower_Bounds_for_Passive_and_Active_Learning_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The supremum of this function has been recently rediscovered by Hanneke in the context of active learning under the name of “disagreement coefﬁcient. [sent-3, score-0.225]
</p><p>2 ” For passive learning, our lower bounds match the upper bounds of Gin´ and Koltchinskii up to constants and generalize analogous results of Mase sart and N´ d´ lec. [sent-4, score-0.546]
</p><p>3 For active learning, we provide ﬁrst known lower bounds based e e on the capacity function rather than the disagreement coefﬁcient. [sent-5, score-0.775]
</p><p>4 This was observed by Massart and N´ d´ lec e e [24], who showed that, when it comes to binary classiﬁcation rates on a sample of size n under a margin condition, some classes admit rates of the order 1/n while others only (log n)/n. [sent-7, score-0.233]
</p><p>5 As noted by Gin´ and Koltchinskii [15], the ﬁne complexity e notion that deﬁnes this “richness” is in fact embodied in Alexander’s capacity function. [sent-9, score-0.228]
</p><p>6 1 Somewhat surprisingly, the supremum of this function (called the disagreement coefﬁcient by Hanneke [19]) plays a key role in risk bounds for active learning. [sent-10, score-0.562]
</p><p>7 First, we prove lower bounds for passive learning based on Alexander’s capacity function, matching the upper bounds of [15] up to constants. [sent-12, score-0.774]
</p><p>8 Second, we prove lower bounds for the number of label requests in active learning in terms of the capacity function. [sent-13, score-0.661]
</p><p>9 Our proof techniques are information-theoretic in nature and provide a uniﬁed tool to study active and passive learning within the same framework. [sent-14, score-0.48]
</p><p>10 In this framework, the learner is passive and has no control i=1 on how this sample is chosen. [sent-23, score-0.337]
</p><p>11 The classical setting is well studied, and the following question has recently received attention: do we gain anything if data are obtained sequentially, and the learner is allowed to modify the design distribution Π of the predictor variable before receiving the next pair (Xi , Yi )? [sent-24, score-0.104]
</p><p>12 That is, can the learner actively use the information obtained so far to facilitate faster learning? [sent-25, score-0.079]
</p><p>13 Two paradigms often appear in the literature: (i) the design distribution is a Dirac delta function at some xi that depends on (xi−1 , Y i−1 ), or (ii) the design distribution is a restriction of the original distribution to some measurable set. [sent-26, score-0.211]
</p><p>14 To be precise, the capacity function depends on the underlying probability distribution. [sent-31, score-0.262]
</p><p>15 The setting (ii) is often called selective sampling [9, 13, 8], although the term active learning is also used. [sent-33, score-0.246]
</p><p>16 In recent years, several interesting algorithms for active learning and selective sampling have appeared in the literature, most notably: the A2 algorithm of Balcan et al. [sent-39, score-0.246]
</p><p>17 [11], which maintains the set Di implicitly through synthetic and real examples; and the importance-weighted active learning algorithm of Beygelzimer et al. [sent-41, score-0.194]
</p><p>18 An insightful analysis has been carried out by Hanneke [20, 19], who distilled the role of the so-called disagreement coefﬁcient in governing the performance of several of these active learning algorithms. [sent-43, score-0.377]
</p><p>19 Finally, Koltchinskii [23] analyzed active learning procedures using localized Rademacher complexities and Alexander’s capacity function, which we discuss next. [sent-44, score-0.461]
</p><p>20 We deﬁne the excess risk of a classiﬁer f by EP (f ) RP (f ) − RP (f ∗ ), so that EP (f ) ≥ 0, with ∗ equality if and only if f = f Π-a. [sent-52, score-0.107]
</p><p>21 The Alexander’s capacity function [15] is deﬁned as τ (ε)  Π(Dε (f ∗ ))/ε,  (1)  that is, τ (ε) measures the relative size (in terms of Π) of the disagreement region Dε compared to ε. [sent-57, score-0.411]
</p><p>22 The function τ was originally introduced by Alexander [1, 2] in the context of exponential inequalities for empirical processes indexed by VC classes of functions, and Gin´ and Koltchine skii [15] generalized Alexander’s results. [sent-59, score-0.086]
</p><p>23 The upper bound (2) suggests the importance of the Alexander’s capacity function for passive learning, leaving open the question of necessity. [sent-62, score-0.563]
</p><p>24 Our ﬁrst contribution is a lower bound which matches the upper bound (2) up to constant, showing that, in fact, dependence on the capacity is unavoidable. [sent-63, score-0.406]
</p><p>25 Recently, Koltchinskii [23] made an important connection between Hanneke’s disagreement coefﬁcient and Alexander’s capacity function. [sent-64, score-0.411]
</p><p>26 Similar bounds based on the disagreement coefﬁcient have appeared in [19, 20, 11]. [sent-66, score-0.273]
</p><p>27 The second contribution of this paper is a lower bound on the expected number of queries based on Alexander’s capacity τ (ε). [sent-67, score-0.392]
</p><p>28 For passive learning, Massart and N´ d´ lec [24] proved e e two lower bounds which, in fact, correspond to τ (ε) = 1/ε and τ (ε) = τ0 , the two endpoints on the complexity scale for the capacity function. [sent-69, score-0.829]
</p><p>29 Without the capacity function at hand, the authors emphasize that “rich” VC classes yield a larger lower bound. [sent-70, score-0.339]
</p><p>30 In the PAC framework, the lower bound Ω(d/ε + (1/ε) log(1/δ)) goes back to [12]. [sent-72, score-0.129]
</p><p>31 It follows from our results that in the noisy version of the problem (h = 1), the lower bound is in fact Ω((d/ε) log(1/ε) + (1/ε) log(1/δ)) for classes with τ (ε) = Ω(1/ε). [sent-73, score-0.16]
</p><p>32 For active learning, Castro and Nowak [7] derived lower bounds, but without the disagreement coefﬁcient and under a Tsybakov-type noise condition. [sent-74, score-0.482]
</p><p>33 Hanneke [19] proved a lower bound on the number of label requests speciﬁcally for the A2 algorithm in terms of the disagreement coefﬁcient. [sent-76, score-0.422]
</p><p>34 In contrast, lower bounds of Theorem 2 are valid for any algorithm and are in terms of Alexander’s capacity function. [sent-77, score-0.398]
</p><p>35 Finally, a result by K¨ ari¨ inen [22] a¨ a (strengthened by [5]) gives a lower bound of Ω(ν 2 /ε2 ) where ν = inf f ∈F EP (f ). [sent-78, score-0.129]
</p><p>36 A closer look at the construction of the lower bound reveals that it is achieved by considering a speciﬁc margin h = ε/ν. [sent-79, score-0.177]
</p><p>37 This point of view is put forth by Massart and N´ d´ lec [24, p. [sent-81, score-0.104]
</p><p>38 We now introduce Alexander’s capacity function (1) into the picture. [sent-89, score-0.228]
</p><p>39 We also denote by T the set of all admissible capacity functions τ : (0, 1] → R+ , i. [sent-91, score-0.262]
</p><p>40 An n-step learning scheme S consists of the following objects: n conditional proba(t) bility distributions ΠXt |X t−1 ,Y t−1 , t = 1, . [sent-101, score-0.111]
</p><p>41 After the n samples {(Xt , Yt )}n are collected, the learner computes the candidate classiﬁer fn = ψ(X n , Y n ). [sent-110, score-0.163]
</p><p>42 Speciﬁcally, given some P = Π ⊗ PY |X ∈ P(Π, F, h), deﬁne the 3  following probability measure on X n × {0, 1}n : n (t)  PS (xn , y n ) =  PY |X (yt |xt )ΠXt |X t−1 ,Y t−1 (xt |xt−1 , y t−1 ). [sent-112, score-0.086]
</p><p>43 e e With these preliminaries out of the way, we can state the main results of this paper: Theorem 1 (Lower bounds for passive learning). [sent-120, score-0.376]
</p><p>44 Given any τ ∈ T , any sufﬁciently large d ∈ N and any ε ∈ (0, 1], there exist a probability measure Π ∈ P(X ) and a VC class F with VC-dim(F) = d with the following properties: (1) Fix any K > 1 and δ ∈ (0, 1/2). [sent-121, score-0.086]
</p><p>45 If there exists an n-step passive learning scheme that (ε/2, δ)learns P(Π, F, h, τ, ε) for some h ∈ (0, 1 − K −1 ], then n=Ω  log 1 (1 − δ)d log τ (ε) δ + Kεh2 Kεh2  . [sent-122, score-0.658]
</p><p>46 (5)  (2) If there exists an n-step passive learning scheme that (ε/2, δ)-learns P(Π, F, 1, τ, ε), then n=Ω  (1 − δ)d ε  . [sent-123, score-0.342]
</p><p>47 (6)  Theorem 2 (Lower bounds for active learning). [sent-124, score-0.284]
</p><p>48 Given any τ ∈ T , any sufﬁciently large d ∈ N and any ε ∈ (0, 1], there exist a probability measure Π ∈ P(X ) and a VC class F with VC-dim(F) = d with the following property: Fix any K > 1 and any δ ∈ (0, 1/2). [sent-125, score-0.086]
</p><p>49 If there exists an n-step active learning scheme that (ε/2, δ)-learns P(Π, F, h, τ, ε) for some h ∈ (0, 1 − K −1 ], then n=Ω  (1 − δ)d log τ (ε) τ (ε) log + Kh2 Kh2  1 δ  . [sent-126, score-0.566]
</p><p>50 The lower bound in (6) is well-known and goes back to [12]. [sent-128, score-0.129]
</p><p>51 In fact, there is a smooth transition between (5) and (6), with the extra log τ (ε) factor disappearing as h approaches 1. [sent-130, score-0.158]
</p><p>52 As for the active learning lower bound, we conjecture that d log τ (ε) is, in fact, optimal, and the extra factor of τ0 in dτ0 log τ0 log(1/ε) in (3) arises from the use of a passive learning algorithm as a black box. [sent-131, score-0.876]
</p><p>53 3  Information-theoretic framework  Let P and Q be two probability distributions on a common measurable space W. [sent-134, score-0.108]
</p><p>54 (9)  Two particular choices of φ are of interest: φ(u) = u log u, which gives the ordinary Kullback– Leibler (KL) divergence D(P Q), and φ(u) = − log u, which gives the reverse KL divergence D(Q P), which we will denote by Dre (P Q). [sent-140, score-0.464]
</p><p>55 , fN } ⊂ F and m assume that to each m ∈ [N ] we can associate a probability measure P m = Π⊗PY |X ∈ P(Π, F, h) ∗ with the Bayes classiﬁer fPm = fm . [sent-149, score-0.236]
</p><p>56 For each m ∈ [N ], let us deﬁne the induced measure n (t)  m PY |X (yt |xt )ΠXt |X t−1 ,Y t−1 (xt |xt−1 , y t−1 ). [sent-150, score-0.08]
</p><p>57 PS,m (xn , y n )  (11)  t=1  Moreover, given any probability distribution π over [N ], let PS,π (m, xn , y n ) π(m)PS,m (xn , y n ). [sent-151, score-0.186]
</p><p>58 Now consider M ≡ M (X n , Y n )  arg min fn − fm 1≤m≤N  L1 (Π) . [sent-162, score-0.237]
</p><p>59 (12)  Then the following lemma is easily proved using triangle inequality: Lemma 1. [sent-163, score-0.139]
</p><p>60 The second ingredient of our approach is an application of the data processing inequality (10) with a 1 judicious choice of φ. [sent-165, score-0.075]
</p><p>61 Let W (M, X n , Y n ), let M be uniformly distributed over [N ], π(m) = N for all m ∈ [N ], and let P be the induced measure PS,π . [sent-166, score-0.108]
</p><p>62 Then we have the following lemma (see also [17, 16]): Lemma 2. [sent-167, score-0.098]
</p><p>63 Consider any probability measure Q for W , under which M is distributed according to π and independent of (X n , Y n ). [sent-168, score-0.086]
</p><p>64 c 1 On the other hand, since Q can be factored as Q(m, xn , y n ) = N QX n ,Y n (xn , y n ), we have N  Q(Z = 1) =  Q(M = m, M = m) = m=1  1 N  N  QX n ,Y n (xn , y n )1{M (xn ,yn )=m} = c m=1 xn ,y n  1 . [sent-174, score-0.194]
</p><p>65 Inspection of the right-hand side of (13) suggests that the usual Ω(log N ) lower bounds [14, 27, 24] can be obtained if φ(u) behaves like u log u for large u. [sent-179, score-0.354]
</p><p>66 On the other hand, if φ(u) behaves like − log u for small u, then the lower bounds will be of the form Ω log 1 . [sent-180, score-0.512]
</p><p>67 δ These observations naturally lead to the respective choices φ(u) = u log u and φ(u) = − log u, corresponding to the KL divergence D(P Q) and the reverse KL divergence Dre (P Q) = D(Q P). [sent-181, score-0.464]
</p><p>68 One obvious choice of Q satisfying the conditions of the lemma is the product of N the marginals PM ≡ π and PX n ,Y n ≡ N −1 m=1 PS,m : Q = PM ⊗ PX n ,Y n . [sent-183, score-0.098]
</p><p>69 With this Q and φ(u) = u log u, the left-hand side of (13) is given by D(P Q) = D(PM,X n ,Y n PM ⊗ PX n ,Y n ) = I(M ; X n , Y n ), (14) where I(M ; X n , Y n ) is the mutual information between M and (X n , Y n ) with joint distribution P. [sent-184, score-0.185]
</p><p>70 On the other hand, it is not hard to show that the right-hand side of (13) can be lower-bounded by (1 − δ) log N − log 2. [sent-185, score-0.316]
</p><p>71 Combining with (14), we get I(M ; X n , Y n ) ≥ (1 − δ) log N − log 2, which is (a commonly used variant of) the well-known Fano’s inequality [14, Lemma 4. [sent-186, score-0.361]
</p><p>72 Given a learning scheme S, deﬁne the probability measure n (t)  QS (xn , y n )  QY |X (yt |xt )ΠXt |X t−1 ,Y t−1 (xt |xt−1 , y t−1 )  1 S N Q (x n n  and let Q(m, xn , y n ) =  , y ) for all m ∈ [N ]. [sent-193, score-0.267]
</p><p>73 For each x ∈ X and y ∈ X , let N (y|xn ) D(P Q) =  Dre (P Q) =  1 N 1 N  (15)  t=1 n n  |{1 ≤ t ≤ n : xt = y}|. [sent-195, score-0.192]
</p><p>74 Then, for d sufﬁciently large, there exists a set k Mk,d ⊂ {0, 1}k with the following properties: (i) log |Mk,d | ≥ d log 6d ; (ii) dH (β, β ) > d for d 4 (2) any two distinct β, β ∈ Mk,d ; (iii) for any j ∈ [k], 1 d ≤ 2k |Mk,d |  βj ≤ β∈Mk,d  6  3d 2k  (19)  Proof of Theorem 1. [sent-210, score-0.316]
</p><p>75 Let k = dτ (ε) (we increase ε if necessary to ensure that k ∈ N), and consider the probability measure Π that puts mass ε/d on each x = 1 through x = k and the remaining mass 1 − ετ (ε) on x = k + 1. [sent-212, score-0.086]
</p><p>76 For p ∈ [0, 1], let νp d denote the probability distribution of a Bernoulli(p) random variable. [sent-218, score-0.089]
</p><p>77 Now, to each fβ ∈ F let us β associate the following conditional probability measure PY |X : β PY |X (y|x) = ν(1+h)/2 (y)βx + ν(1−h)/2 (y)(1 − βx ) 1{x∈[k]} + 1{y=0} 1{x∈[k]} β It is easy to see that each PY |X belongs to C(F, h). [sent-219, score-0.169]
</p><p>78 We have thus established that, β for each β ∈ {0, 1}k , the probability measure P β = Π ⊗ PY |X is an element of P(Π, F, h, τ, ε). [sent-223, score-0.086]
</p><p>79 For each m ∈ [N ], let us denote by PY |X the (m)  β m conditional probability measure PY |X , by P m the measure Π ⊗ PY |X on X × {0, 1}, and by fm ∈ G the corresponding Bayes classiﬁer. [sent-232, score-0.321]
</p><p>80 Now consider any n-step passive learning scheme that (ε/2, δ)-learns P(Π, F, h, τ, ε), and deﬁne the probability measure P on [N ] × X n × {0, 1}n by 1 P(m, xn , y n ) = N PS,m (xn , y n ), where PS,m is constructed according to (11). [sent-233, score-0.525]
</p><p>81 In addition, for every γ ∈ (0, 1) deﬁne the auxiliary measure Qγ on [N ] × X n × {0, 1}n by Qγ (m, xn , y n ) = 1 n n S S N Qγ (x , y ), where Qγ is constructed according to (15) with  Qγ |X (y|x) Y  νγ (y)1{x∈[k]} + 1{y=0} 1{x∈[k]} . [sent-234, score-0.182]
</p><p>82 Applying Lemma 2 with φ(u) = u log u, we can write D(P Qγ ) ≥ (1 − δ) log N − log 2 ≥ Next we apply Lemma 3. [sent-235, score-0.474]
</p><p>83 Deﬁning η =  1+h 2  (1 − δ)d k log − log 2 4 6d  (20)  and using the easily proved fact that  m D(PY |X (·|x) Qγ |X (·|x)) = [d(η γ) − d(1 − η γ)] fm (x) + d(1 − η γ)1{x∈[k]} , Y  we get D(P Qγ ) = nε [d(η γ) + (τ (ε) − 1)d(1 − η γ)] . [sent-236, score-0.482]
</p><p>84 (20) and (21) and using the fact that k = dτ (ε), we obtain n≥  (1 − δ)d log τ (ε) − log 16 6 , 4ε [d(η γ) + (τ (ε) − 1)d(1 − η γ)]  ∀γ ∈ (0, 1)  (22)  This bound is valid for all h ∈ (0, 1], and the optimal choice of γ for a given h can be calculated in h closed form: γ ∗ (h) = 1−h + τ (ε) . [sent-238, score-0.365]
</p><p>85 Lemma 2 gives Dre (P Q1−η ) ≥ (1/2) log(1/δ) − log 2. [sent-241, score-0.158]
</p><p>86 (18), we can write Dre (P Q1−η ) = nε · d(η 1 − η) = nε · h log  1+h . [sent-243, score-0.158]
</p><p>87 1−h  (24)  We conclude that n≥  1 2  log  1 δ  − log 2  εh log  1+h 1−h  . [sent-244, score-0.474]
</p><p>88 1+h (1) For a ﬁxed K > 1, it follows from the inequality log u ≤ u − 1 that h log 1−h ≤ Kh2 for all h ∈ (0, 1 − K −1 ]. [sent-247, score-0.361]
</p><p>89 m=1 P N Then, by convexity, D(P Q) ≤  1 N2  N  n  log  EP t=1  m,m =1  which is upper bounded by nh log obtain  m PY |X (Yt |Xt )  ≤n  m PY |X (Yt |Xt )  1+h 1−h . [sent-256, score-0.37]
</p><p>90 n≥  (a)  1 N  N  k 6d − 1+h 4h log 1−h  (1 − δ)d log  =  1+h 2 . [sent-257, score-0.316]
</p><p>91 k (c)  = d(η 1 − η) x=1  ≤  Then  k  d(η 1 − η) fm (x)EQ1−η [N (x|X n )] N m=1 x=1  x=1  (e)  (26)  M =1 x=1  k  ≤  . [sent-258, score-0.125]
</p><p>92 Applying Lemma 2 with φ(u) = − log u, we get n≥  τ (ε) log  1 δ  3h log  Combining (26) and (27) and using the bound h log 8  − log 4 1+h 1−h  1+h 1−h  (27)  ≤ Kh2 for h ∈ (0, 1 − K −1 ], we get (7). [sent-260, score-0.839]
</p><p>93 A general class of coefﬁcients of divergence of one distribution from another. [sent-276, score-0.081]
</p><p>94 Linear classiﬁcation and selective sampling under low noise conditions. [sent-318, score-0.077]
</p><p>95 A general lower bound on the number of examples needed for learning. [sent-344, score-0.129]
</p><p>96 Improved lower bounds for learning from noisy examples: an informationtheoretic approach. [sent-358, score-0.212]
</p><p>97 Lower bounds for the minimax risk using f -divergences, and applications. [sent-371, score-0.203]
</p><p>98 On Fano’s lemma and similar inequalities for the minimax risk. [sent-378, score-0.175]
</p><p>99 A bound on the label complexity of agnostic active learning. [sent-390, score-0.315]
</p><p>100 Rademacher complexities and bounding the excess risk of active learning. [sent-410, score-0.34]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('py', 0.418), ('dre', 0.339), ('passive', 0.286), ('massart', 0.261), ('capacity', 0.228), ('active', 0.194), ('disagreement', 0.183), ('alexander', 0.168), ('xt', 0.164), ('log', 0.158), ('fm', 0.125), ('hanneke', 0.112), ('fn', 0.112), ('qy', 0.105), ('lec', 0.104), ('lemma', 0.098), ('xn', 0.097), ('ps', 0.096), ('ep', 0.094), ('pz', 0.092), ('bounds', 0.09), ('koltchinskii', 0.086), ('yt', 0.082), ('lower', 0.08), ('qx', 0.079), ('gin', 0.079), ('vc', 0.075), ('dh', 0.072), ('qz', 0.069), ('risk', 0.064), ('fano', 0.063), ('kl', 0.059), ('px', 0.059), ('pm', 0.058), ('scheme', 0.056), ('nh', 0.054), ('divergence', 0.054), ('coef', 0.052), ('lautum', 0.052), ('verd', 0.052), ('measure', 0.052), ('beygelzimer', 0.052), ('fp', 0.052), ('selective', 0.052), ('learner', 0.051), ('bound', 0.049), ('measurable', 0.049), ('minimax', 0.049), ('margin', 0.048), ('di', 0.047), ('castro', 0.046), ('inequality', 0.045), ('classi', 0.045), ('er', 0.044), ('excess', 0.043), ('informationtheoretic', 0.042), ('proved', 0.041), ('dasgupta', 0.041), ('reverse', 0.04), ('ari', 0.04), ('bayes', 0.039), ('agnostic', 0.039), ('complexities', 0.039), ('hamming', 0.038), ('requests', 0.036), ('paradigm', 0.035), ('queries', 0.035), ('admissible', 0.034), ('balcan', 0.034), ('erm', 0.034), ('sequentially', 0.034), ('fix', 0.034), ('probability', 0.034), ('auxiliary', 0.033), ('label', 0.033), ('classes', 0.031), ('supremum', 0.031), ('ingredient', 0.03), ('rp', 0.03), ('bernoulli', 0.03), ('conditional', 0.03), ('xi', 0.029), ('eq', 0.029), ('inequalities', 0.028), ('let', 0.028), ('actively', 0.028), ('yi', 0.028), ('uni', 0.027), ('distribution', 0.027), ('indexed', 0.027), ('rademacher', 0.026), ('theorem', 0.026), ('design', 0.026), ('rich', 0.026), ('behaves', 0.026), ('rates', 0.025), ('distributions', 0.025), ('noise', 0.025), ('mention', 0.025), ('associate', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000007 <a title="162-tfidf-1" href="./nips-2011-Lower_Bounds_for_Passive_and_Active_Learning.html">162 nips-2011-Lower Bounds for Passive and Active Learning</a></p>
<p>Author: Maxim Raginsky, Alexander Rakhlin</p><p>Abstract: We develop uniﬁed information-theoretic machinery for deriving lower bounds for passive and active learning schemes. Our bounds involve the so-called Alexander’s capacity function. The supremum of this function has been recently rediscovered by Hanneke in the context of active learning under the name of “disagreement coefﬁcient.” For passive learning, our lower bounds match the upper bounds of Gin´ and Koltchinskii up to constants and generalize analogous results of Mase sart and N´ d´ lec. For active learning, we provide ﬁrst known lower bounds based e e on the capacity function rather than the disagreement coefﬁcient. 1</p><p>2 0.15039597 <a title="162-tfidf-2" href="./nips-2011-Agnostic_Selective_Classification.html">28 nips-2011-Agnostic Selective Classification</a></p>
<p>Author: Yair Wiener, Ran El-Yaniv</p><p>Abstract: For a learning problem whose associated excess loss class is (β, B)-Bernstein, we show that it is theoretically possible to track the same classiﬁcation performance of the best (unknown) hypothesis in our class, provided that we are free to abstain from prediction in some region of our choice. The (probabilistic) volume of this √ rejected region of the domain is shown to be diminishing at rate O(Bθ( 1/m)β ), where θ is Hanneke’s disagreement coefﬁcient. The strategy achieving this performance has computational barriers because it requires empirical error minimization in an agnostic setting. Nevertheless, we heuristically approximate this strategy and develop a novel selective classiﬁcation algorithm using constrained SVMs. We show empirically that the resulting algorithm consistently outperforms the traditional rejection mechanism based on distance from decision boundary. 1</p><p>3 0.14690927 <a title="162-tfidf-3" href="./nips-2011-Active_Learning_with_a_Drifting_Distribution.html">21 nips-2011-Active Learning with a Drifting Distribution</a></p>
<p>Author: Liu Yang</p><p>Abstract: We study the problem of active learning in a stream-based setting, allowing the distribution of the examples to change over time. We prove upper bounds on the number of prediction mistakes and number of label requests for established disagreement-based active learning algorithms, both in the realizable case and under Tsybakov noise. We further prove minimax lower bounds for this problem. 1</p><p>4 0.12744661 <a title="162-tfidf-4" href="./nips-2011-Online_Learning%3A_Stochastic%2C_Constrained%2C_and_Smoothed_Adversaries.html">204 nips-2011-Online Learning: Stochastic, Constrained, and Smoothed Adversaries</a></p>
<p>Author: Alexander Rakhlin, Karthik Sridharan, Ambuj Tewari</p><p>Abstract: Learning theory has largely focused on two main learning scenarios: the classical statistical setting where instances are drawn i.i.d. from a ﬁxed distribution, and the adversarial scenario wherein, at every time step, an adversarially chosen instance is revealed to the player. It can be argued that in the real world neither of these assumptions is reasonable. We deﬁne the minimax value of a game where the adversary is restricted in his moves, capturing stochastic and non-stochastic assumptions on data. Building on the sequential symmetrization approach, we deﬁne a notion of distribution-dependent Rademacher complexity for the spectrum of problems ranging from i.i.d. to worst-case. The bounds let us immediately deduce variation-type bounds. We study a smoothed online learning scenario and show that exponentially small amount of noise can make function classes with inﬁnite Littlestone dimension learnable. 1</p><p>5 0.12736042 <a title="162-tfidf-5" href="./nips-2011-Approximating_Semidefinite_Programs_in_Sublinear_Time.html">39 nips-2011-Approximating Semidefinite Programs in Sublinear Time</a></p>
<p>Author: Dan Garber, Elad Hazan</p><p>Abstract: In recent years semideﬁnite optimization has become a tool of major importance in various optimization and machine learning problems. In many of these problems the amount of data in practice is so large that there is a constant need for faster algorithms. In this work we present the ﬁrst sublinear time approximation algorithm for semideﬁnite programs which we believe may be useful for such problems in which the size of data may cause even linear time algorithms to have prohibitive running times in practice. We present the algorithm and its analysis alongside with some theoretical lower bounds and an improved algorithm for the special problem of supervised learning of a distance metric. 1</p><p>6 0.11951917 <a title="162-tfidf-6" href="./nips-2011-Prediction_strategies_without_loss.html">220 nips-2011-Prediction strategies without loss</a></p>
<p>7 0.11679679 <a title="162-tfidf-7" href="./nips-2011-Unifying_Framework_for_Fast_Learning_Rate_of_Non-Sparse_Multiple_Kernel_Learning.html">294 nips-2011-Unifying Framework for Fast Learning Rate of Non-Sparse Multiple Kernel Learning</a></p>
<p>8 0.11520724 <a title="162-tfidf-8" href="./nips-2011-Multiclass_Boosting%3A_Theory_and_Algorithms.html">178 nips-2011-Multiclass Boosting: Theory and Algorithms</a></p>
<p>9 0.11481651 <a title="162-tfidf-9" href="./nips-2011-Learning_Eigenvectors_for_Free.html">145 nips-2011-Learning Eigenvectors for Free</a></p>
<p>10 0.10852741 <a title="162-tfidf-10" href="./nips-2011-Non-Asymptotic_Analysis_of_Stochastic_Approximation_Algorithms_for_Machine_Learning.html">187 nips-2011-Non-Asymptotic Analysis of Stochastic Approximation Algorithms for Machine Learning</a></p>
<p>11 0.099878117 <a title="162-tfidf-11" href="./nips-2011-Generalizing_from_Several_Related_Classification_Tasks_to_a_New_Unlabeled_Sample.html">106 nips-2011-Generalizing from Several Related Classification Tasks to a New Unlabeled Sample</a></p>
<p>12 0.098658599 <a title="162-tfidf-12" href="./nips-2011-k-NN_Regression_Adapts_to_Local_Intrinsic_Dimension.html">305 nips-2011-k-NN Regression Adapts to Local Intrinsic Dimension</a></p>
<p>13 0.09294983 <a title="162-tfidf-13" href="./nips-2011-Newtron%3A_an_Efficient_Bandit_algorithm_for_Online_Multiclass_Prediction.html">185 nips-2011-Newtron: an Efficient Bandit algorithm for Online Multiclass Prediction</a></p>
<p>14 0.091026455 <a title="162-tfidf-14" href="./nips-2011-Efficient_Online_Learning_via_Randomized_Rounding.html">80 nips-2011-Efficient Online Learning via Randomized Rounding</a></p>
<p>15 0.088275142 <a title="162-tfidf-15" href="./nips-2011-On_U-processes_and_clustering_performance.html">198 nips-2011-On U-processes and clustering performance</a></p>
<p>16 0.087226868 <a title="162-tfidf-16" href="./nips-2011-Active_Learning_Ranking_from_Pairwise_Preferences_with_Almost_Optimal_Query_Complexity.html">20 nips-2011-Active Learning Ranking from Pairwise Preferences with Almost Optimal Query Complexity</a></p>
<p>17 0.086558446 <a title="162-tfidf-17" href="./nips-2011-Solving_Decision_Problems_with_Limited_Information.html">256 nips-2011-Solving Decision Problems with Limited Information</a></p>
<p>18 0.085986726 <a title="162-tfidf-18" href="./nips-2011-Improved_Algorithms_for_Linear_Stochastic_Bandits.html">128 nips-2011-Improved Algorithms for Linear Stochastic Bandits</a></p>
<p>19 0.080561191 <a title="162-tfidf-19" href="./nips-2011-Optimal_learning_rates_for_least_squares_SVMs_using_Gaussian_kernels.html">207 nips-2011-Optimal learning rates for least squares SVMs using Gaussian kernels</a></p>
<p>20 0.072989948 <a title="162-tfidf-20" href="./nips-2011-Sparse_Inverse_Covariance_Matrix_Estimation_Using_Quadratic_Approximation.html">262 nips-2011-Sparse Inverse Covariance Matrix Estimation Using Quadratic Approximation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.2), (1, -0.119), (2, -0.057), (3, -0.109), (4, 0.08), (5, 0.028), (6, 0.049), (7, -0.15), (8, -0.074), (9, -0.023), (10, 0.011), (11, 0.054), (12, 0.159), (13, 0.045), (14, 0.015), (15, -0.052), (16, 0.13), (17, -0.027), (18, 0.016), (19, 0.107), (20, 0.041), (21, -0.056), (22, 0.054), (23, 0.002), (24, -0.024), (25, -0.011), (26, 0.071), (27, 0.006), (28, 0.001), (29, 0.004), (30, 0.237), (31, 0.028), (32, 0.066), (33, 0.008), (34, -0.021), (35, -0.117), (36, -0.067), (37, 0.05), (38, -0.066), (39, 0.037), (40, -0.014), (41, 0.044), (42, -0.008), (43, -0.008), (44, 0.107), (45, -0.101), (46, 0.038), (47, 0.02), (48, -0.021), (49, 0.007)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94577986 <a title="162-lsi-1" href="./nips-2011-Lower_Bounds_for_Passive_and_Active_Learning.html">162 nips-2011-Lower Bounds for Passive and Active Learning</a></p>
<p>Author: Maxim Raginsky, Alexander Rakhlin</p><p>Abstract: We develop uniﬁed information-theoretic machinery for deriving lower bounds for passive and active learning schemes. Our bounds involve the so-called Alexander’s capacity function. The supremum of this function has been recently rediscovered by Hanneke in the context of active learning under the name of “disagreement coefﬁcient.” For passive learning, our lower bounds match the upper bounds of Gin´ and Koltchinskii up to constants and generalize analogous results of Mase sart and N´ d´ lec. For active learning, we provide ﬁrst known lower bounds based e e on the capacity function rather than the disagreement coefﬁcient. 1</p><p>2 0.78773618 <a title="162-lsi-2" href="./nips-2011-Active_Learning_with_a_Drifting_Distribution.html">21 nips-2011-Active Learning with a Drifting Distribution</a></p>
<p>Author: Liu Yang</p><p>Abstract: We study the problem of active learning in a stream-based setting, allowing the distribution of the examples to change over time. We prove upper bounds on the number of prediction mistakes and number of label requests for established disagreement-based active learning algorithms, both in the realizable case and under Tsybakov noise. We further prove minimax lower bounds for this problem. 1</p><p>3 0.59305835 <a title="162-lsi-3" href="./nips-2011-Agnostic_Selective_Classification.html">28 nips-2011-Agnostic Selective Classification</a></p>
<p>Author: Yair Wiener, Ran El-Yaniv</p><p>Abstract: For a learning problem whose associated excess loss class is (β, B)-Bernstein, we show that it is theoretically possible to track the same classiﬁcation performance of the best (unknown) hypothesis in our class, provided that we are free to abstain from prediction in some region of our choice. The (probabilistic) volume of this √ rejected region of the domain is shown to be diminishing at rate O(Bθ( 1/m)β ), where θ is Hanneke’s disagreement coefﬁcient. The strategy achieving this performance has computational barriers because it requires empirical error minimization in an agnostic setting. Nevertheless, we heuristically approximate this strategy and develop a novel selective classiﬁcation algorithm using constrained SVMs. We show empirically that the resulting algorithm consistently outperforms the traditional rejection mechanism based on distance from decision boundary. 1</p><p>4 0.58780032 <a title="162-lsi-4" href="./nips-2011-Online_Learning%3A_Stochastic%2C_Constrained%2C_and_Smoothed_Adversaries.html">204 nips-2011-Online Learning: Stochastic, Constrained, and Smoothed Adversaries</a></p>
<p>Author: Alexander Rakhlin, Karthik Sridharan, Ambuj Tewari</p><p>Abstract: Learning theory has largely focused on two main learning scenarios: the classical statistical setting where instances are drawn i.i.d. from a ﬁxed distribution, and the adversarial scenario wherein, at every time step, an adversarially chosen instance is revealed to the player. It can be argued that in the real world neither of these assumptions is reasonable. We deﬁne the minimax value of a game where the adversary is restricted in his moves, capturing stochastic and non-stochastic assumptions on data. Building on the sequential symmetrization approach, we deﬁne a notion of distribution-dependent Rademacher complexity for the spectrum of problems ranging from i.i.d. to worst-case. The bounds let us immediately deduce variation-type bounds. We study a smoothed online learning scenario and show that exponentially small amount of noise can make function classes with inﬁnite Littlestone dimension learnable. 1</p><p>5 0.57951194 <a title="162-lsi-5" href="./nips-2011-Active_Learning_Ranking_from_Pairwise_Preferences_with_Almost_Optimal_Query_Complexity.html">20 nips-2011-Active Learning Ranking from Pairwise Preferences with Almost Optimal Query Complexity</a></p>
<p>Author: Nir Ailon</p><p>Abstract: Given a set V of n elements we wish to linearly order them using pairwise preference labels which may be non-transitive (due to irrationality or arbitrary noise). The goal is to linearly order the elements while disagreeing with as few pairwise preference labels as possible. Our performance is measured by two parameters: The number of disagreements (loss) and the query complexity (number of pairwise preference labels). Our algorithm adaptively queries at most O(n poly(log n, ε−1 )) preference labels for a regret of ε times the optimal loss. This is strictly better, and often signiﬁcantly better than what non-adaptive sampling could achieve. Our main result helps settle an open problem posed by learning-to-rank (from pairwise information) theoreticians and practitioners: What is a provably correct way to sample preference labels? 1</p><p>6 0.52849942 <a title="162-lsi-6" href="./nips-2011-Optimal_learning_rates_for_least_squares_SVMs_using_Gaussian_kernels.html">207 nips-2011-Optimal learning rates for least squares SVMs using Gaussian kernels</a></p>
<p>7 0.51925248 <a title="162-lsi-7" href="./nips-2011-Efficient_Online_Learning_via_Randomized_Rounding.html">80 nips-2011-Efficient Online Learning via Randomized Rounding</a></p>
<p>8 0.49660555 <a title="162-lsi-8" href="./nips-2011-Newtron%3A_an_Efficient_Bandit_algorithm_for_Online_Multiclass_Prediction.html">185 nips-2011-Newtron: an Efficient Bandit algorithm for Online Multiclass Prediction</a></p>
<p>9 0.49135995 <a title="162-lsi-9" href="./nips-2011-Differentially_Private_M-Estimators.html">69 nips-2011-Differentially Private M-Estimators</a></p>
<p>10 0.48786476 <a title="162-lsi-10" href="./nips-2011-Learning_Eigenvectors_for_Free.html">145 nips-2011-Learning Eigenvectors for Free</a></p>
<p>11 0.48478019 <a title="162-lsi-11" href="./nips-2011-Approximating_Semidefinite_Programs_in_Sublinear_Time.html">39 nips-2011-Approximating Semidefinite Programs in Sublinear Time</a></p>
<p>12 0.47891104 <a title="162-lsi-12" href="./nips-2011-On_U-processes_and_clustering_performance.html">198 nips-2011-On U-processes and clustering performance</a></p>
<p>13 0.47226465 <a title="162-lsi-13" href="./nips-2011-Prediction_strategies_without_loss.html">220 nips-2011-Prediction strategies without loss</a></p>
<p>14 0.47223845 <a title="162-lsi-14" href="./nips-2011-The_Impact_of_Unlabeled_Patterns_in_Rademacher_Complexity_Theory_for_Kernel_Classifiers.html">284 nips-2011-The Impact of Unlabeled Patterns in Rademacher Complexity Theory for Kernel Classifiers</a></p>
<p>15 0.45179722 <a title="162-lsi-15" href="./nips-2011-Composite_Multiclass_Losses.html">59 nips-2011-Composite Multiclass Losses</a></p>
<p>16 0.44143006 <a title="162-lsi-16" href="./nips-2011-Generalizing_from_Several_Related_Classification_Tasks_to_a_New_Unlabeled_Sample.html">106 nips-2011-Generalizing from Several Related Classification Tasks to a New Unlabeled Sample</a></p>
<p>17 0.44051108 <a title="162-lsi-17" href="./nips-2011-k-NN_Regression_Adapts_to_Local_Intrinsic_Dimension.html">305 nips-2011-k-NN Regression Adapts to Local Intrinsic Dimension</a></p>
<p>18 0.43858588 <a title="162-lsi-18" href="./nips-2011-Randomized_Algorithms_for_Comparison-based_Search.html">231 nips-2011-Randomized Algorithms for Comparison-based Search</a></p>
<p>19 0.43689579 <a title="162-lsi-19" href="./nips-2011-How_Do_Humans_Teach%3A_On_Curriculum_Learning_and_Teaching_Dimension.html">122 nips-2011-How Do Humans Teach: On Curriculum Learning and Teaching Dimension</a></p>
<p>20 0.43370953 <a title="162-lsi-20" href="./nips-2011-Unifying_Framework_for_Fast_Learning_Rate_of_Non-Sparse_Multiple_Kernel_Learning.html">294 nips-2011-Unifying Framework for Fast Learning Rate of Non-Sparse Multiple Kernel Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.036), (4, 0.04), (20, 0.043), (26, 0.414), (31, 0.061), (33, 0.013), (43, 0.089), (45, 0.114), (57, 0.017), (74, 0.038), (83, 0.032), (99, 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.95565331 <a title="162-lda-1" href="./nips-2011-Active_Learning_Ranking_from_Pairwise_Preferences_with_Almost_Optimal_Query_Complexity.html">20 nips-2011-Active Learning Ranking from Pairwise Preferences with Almost Optimal Query Complexity</a></p>
<p>Author: Nir Ailon</p><p>Abstract: Given a set V of n elements we wish to linearly order them using pairwise preference labels which may be non-transitive (due to irrationality or arbitrary noise). The goal is to linearly order the elements while disagreeing with as few pairwise preference labels as possible. Our performance is measured by two parameters: The number of disagreements (loss) and the query complexity (number of pairwise preference labels). Our algorithm adaptively queries at most O(n poly(log n, ε−1 )) preference labels for a regret of ε times the optimal loss. This is strictly better, and often signiﬁcantly better than what non-adaptive sampling could achieve. Our main result helps settle an open problem posed by learning-to-rank (from pairwise information) theoreticians and practitioners: What is a provably correct way to sample preference labels? 1</p><p>same-paper 2 0.93515307 <a title="162-lda-2" href="./nips-2011-Lower_Bounds_for_Passive_and_Active_Learning.html">162 nips-2011-Lower Bounds for Passive and Active Learning</a></p>
<p>Author: Maxim Raginsky, Alexander Rakhlin</p><p>Abstract: We develop uniﬁed information-theoretic machinery for deriving lower bounds for passive and active learning schemes. Our bounds involve the so-called Alexander’s capacity function. The supremum of this function has been recently rediscovered by Hanneke in the context of active learning under the name of “disagreement coefﬁcient.” For passive learning, our lower bounds match the upper bounds of Gin´ and Koltchinskii up to constants and generalize analogous results of Mase sart and N´ d´ lec. For active learning, we provide ﬁrst known lower bounds based e e on the capacity function rather than the disagreement coefﬁcient. 1</p><p>3 0.89682102 <a title="162-lda-3" href="./nips-2011-Simultaneous_Sampling_and_Multi-Structure_Fitting_with_Adaptive_Reversible_Jump_MCMC.html">255 nips-2011-Simultaneous Sampling and Multi-Structure Fitting with Adaptive Reversible Jump MCMC</a></p>
<p>Author: Trung T. Pham, Tat-jun Chin, Jin Yu, David Suter</p><p>Abstract: Multi-structure model ﬁtting has traditionally taken a two-stage approach: First, sample a (large) number of model hypotheses, then select the subset of hypotheses that optimise a joint ﬁtting and model selection criterion. This disjoint two-stage approach is arguably suboptimal and inefﬁcient — if the random sampling did not retrieve a good set of hypotheses, the optimised outcome will not represent a good ﬁt. To overcome this weakness we propose a new multi-structure ﬁtting approach based on Reversible Jump MCMC. Instrumental in raising the effectiveness of our method is an adaptive hypothesis generator, whose proposal distribution is learned incrementally and online. We prove that this adaptive proposal satisﬁes the diminishing adaptation property crucial for ensuring ergodicity in MCMC. Our method effectively conducts hypothesis sampling and optimisation simultaneously, and yields superior computational efﬁciency over previous two-stage methods. 1</p><p>4 0.8675403 <a title="162-lda-4" href="./nips-2011-Multilinear_Subspace_Regression%3A_An_Orthogonal_Tensor_Decomposition_Approach.html">179 nips-2011-Multilinear Subspace Regression: An Orthogonal Tensor Decomposition Approach</a></p>
<p>Author: Qibin Zhao, Cesar F. Caiafa, Danilo P. Mandic, Liqing Zhang, Tonio Ball, Andreas Schulze-bonhage, Andrzej S. Cichocki</p><p>Abstract: A multilinear subspace regression model based on so called latent variable decomposition is introduced. Unlike standard regression methods which typically employ matrix (2D) data representations followed by vector subspace transformations, the proposed approach uses tensor subspace transformations to model common latent variables across both the independent and dependent data. The proposed approach aims to maximize the correlation between the so derived latent variables and is shown to be suitable for the prediction of multidimensional dependent data from multidimensional independent data, where for the estimation of the latent variables we introduce an algorithm based on Multilinear Singular Value Decomposition (MSVD) on a specially deﬁned cross-covariance tensor. It is next shown that in this way we are also able to unify the existing Partial Least Squares (PLS) and N-way PLS regression algorithms within the same framework. Simulations on benchmark synthetic data conﬁrm the advantages of the proposed approach, in terms of its predictive ability and robustness, especially for small sample sizes. The potential of the proposed technique is further illustrated on a real world task of the decoding of human intracranial electrocorticogram (ECoG) from a simultaneously recorded scalp electroencephalograph (EEG). 1</p><p>5 0.86622542 <a title="162-lda-5" href="./nips-2011-Trace_Lasso%3A_a_trace_norm_regularization_for_correlated_designs.html">289 nips-2011-Trace Lasso: a trace norm regularization for correlated designs</a></p>
<p>Author: Edouard Grave, Guillaume R. Obozinski, Francis R. Bach</p><p>Abstract: Using the 1 -norm to regularize the estimation of the parameter vector of a linear model leads to an unstable estimator when covariates are highly correlated. In this paper, we introduce a new penalty function which takes into account the correlation of the design matrix to stabilize the estimation. This norm, called the trace Lasso, uses the trace norm of the selected covariates, which is a convex surrogate of their rank, as the criterion of model complexity. We analyze the properties of our norm, describe an optimization algorithm based on reweighted least-squares, and illustrate the behavior of this norm on synthetic data, showing that it is more adapted to strong correlations than competing methods such as the elastic net. 1</p><p>6 0.70735854 <a title="162-lda-6" href="./nips-2011-Active_Ranking_using_Pairwise_Comparisons.html">22 nips-2011-Active Ranking using Pairwise Comparisons</a></p>
<p>7 0.64146411 <a title="162-lda-7" href="./nips-2011-Active_Learning_with_a_Drifting_Distribution.html">21 nips-2011-Active Learning with a Drifting Distribution</a></p>
<p>8 0.61106223 <a title="162-lda-8" href="./nips-2011-EigenNet%3A_A_Bayesian_hybrid_of_generative_and_conditional_models_for_sparse_learning.html">84 nips-2011-EigenNet: A Bayesian hybrid of generative and conditional models for sparse learning</a></p>
<p>9 0.60269517 <a title="162-lda-9" href="./nips-2011-Algorithms_and_hardness_results_for_parallel_large_margin_learning.html">29 nips-2011-Algorithms and hardness results for parallel large margin learning</a></p>
<p>10 0.60040456 <a title="162-lda-10" href="./nips-2011-PAC-Bayesian_Analysis_of_Contextual_Bandits.html">210 nips-2011-PAC-Bayesian Analysis of Contextual Bandits</a></p>
<p>11 0.59652442 <a title="162-lda-11" href="./nips-2011-Universal_low-rank_matrix_recovery_from_Pauli_measurements.html">297 nips-2011-Universal low-rank matrix recovery from Pauli measurements</a></p>
<p>12 0.58781117 <a title="162-lda-12" href="./nips-2011-Unifying_Framework_for_Fast_Learning_Rate_of_Non-Sparse_Multiple_Kernel_Learning.html">294 nips-2011-Unifying Framework for Fast Learning Rate of Non-Sparse Multiple Kernel Learning</a></p>
<p>13 0.58011156 <a title="162-lda-13" href="./nips-2011-Randomized_Algorithms_for_Comparison-based_Search.html">231 nips-2011-Randomized Algorithms for Comparison-based Search</a></p>
<p>14 0.58000839 <a title="162-lda-14" href="./nips-2011-Online_Learning%3A_Stochastic%2C_Constrained%2C_and_Smoothed_Adversaries.html">204 nips-2011-Online Learning: Stochastic, Constrained, and Smoothed Adversaries</a></p>
<p>15 0.57301354 <a title="162-lda-15" href="./nips-2011-Projection_onto_A_Nonnegative_Max-Heap.html">226 nips-2011-Projection onto A Nonnegative Max-Heap</a></p>
<p>16 0.5727849 <a title="162-lda-16" href="./nips-2011-Accelerated_Adaptive_Markov_Chain_for_Partition_Function_Computation.html">17 nips-2011-Accelerated Adaptive Markov Chain for Partition Function Computation</a></p>
<p>17 0.56773531 <a title="162-lda-17" href="./nips-2011-Prismatic_Algorithm_for_Discrete_D.C._Programming_Problem.html">222 nips-2011-Prismatic Algorithm for Discrete D.C. Programming Problem</a></p>
<p>18 0.55645925 <a title="162-lda-18" href="./nips-2011-Learning_large-margin_halfspaces_with_more_malicious_noise.html">153 nips-2011-Learning large-margin halfspaces with more malicious noise</a></p>
<p>19 0.55554664 <a title="162-lda-19" href="./nips-2011-Bayesian_Bias_Mitigation_for_Crowdsourcing.html">42 nips-2011-Bayesian Bias Mitigation for Crowdsourcing</a></p>
<p>20 0.55255556 <a title="162-lda-20" href="./nips-2011-Online_Submodular_Set_Cover%2C_Ranking%2C_and_Repeated_Active_Learning.html">205 nips-2011-Online Submodular Set Cover, Ranking, and Repeated Active Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
