<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>142 nips-2011-Large-Scale Sparse Principal Component Analysis with Application to Text Data</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-142" href="#">nips2011-142</a> knowledge-graph by maker-knowledge-mining</p><h1>142 nips-2011-Large-Scale Sparse Principal Component Analysis with Application to Text Data</h1>
<br/><p>Source: <a title="nips-2011-142-pdf" href="http://papers.nips.cc/paper/4337-large-scale-sparse-principal-component-analysis-with-application-to-text-data.pdf">pdf</a></p><p>Author: Youwei Zhang, Laurent E. Ghaoui</p><p>Abstract: Sparse PCA provides a linear combination of small number of features that maximizes variance across data. Although Sparse PCA has apparent advantages compared to PCA, such as better interpretability, it is generally thought to be computationally much more expensive. In this paper, we demonstrate the surprising fact that sparse PCA can be easier than PCA in practice, and that it can be reliably applied to very large data sets. This comes from a rigorous feature elimination pre-processing result, coupled with the favorable fact that features in real-life data typically have exponentially decreasing variances, which allows for many features to be eliminated. We introduce a fast block coordinate ascent algorithm with much better computational complexity than the existing Ô¨Årst-order ones. We provide experimental results obtained on text corpora involving millions of documents and hundreds of thousands of features. These results illustrate how Sparse PCA can help organize a large corpus of text data in a user-interpretable way, providing an attractive alternative approach to topic models. 1</p><p>Reference: <a title="nips-2011-142-reference" href="../nips2011_reference/nips-2011-Large-Scale_Sparse_Principal_Component_Analysis_with_Application_to_Text_Data_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('pca', 0.378), ('nytim', 0.315), ('dspca', 0.277), ('asc', 0.253), ('princip', 0.231), ('saf', 0.228), ('pc', 0.199), ('pubm', 0.197), ('elimin', 0.194), ('tr', 0.191), ('coordin', 0.169), ('spars', 0.162), ('cardin', 0.147), ('word', 0.145), ('block', 0.118), ('semid', 0.1), ('aspremont', 0.085), ('compon', 0.082), ('scotlass', 0.079), ('spca', 0.079)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999928 <a title="142-tfidf-1" href="./nips-2011-Large-Scale_Sparse_Principal_Component_Analysis_with_Application_to_Text_Data.html">142 nips-2011-Large-Scale Sparse Principal Component Analysis with Application to Text Data</a></p>
<p>2 0.17831044 <a title="142-tfidf-2" href="./nips-2011-Matrix_Completion_for_Multi-label_Image_Classification.html">165 nips-2011-Matrix Completion for Multi-label Image Classification</a></p>
<p>3 0.1640863 <a title="142-tfidf-3" href="./nips-2011-Sparse_Features_for_PCA-Like_Linear_Regression.html">260 nips-2011-Sparse Features for PCA-Like Linear Regression</a></p>
<p>4 0.14442681 <a title="142-tfidf-4" href="./nips-2011-Demixed_Principal_Component_Analysis.html">68 nips-2011-Demixed Principal Component Analysis</a></p>
<p>5 0.12398791 <a title="142-tfidf-5" href="./nips-2011-Dimensionality_Reduction_Using_the_Sparse_Linear_Model.html">70 nips-2011-Dimensionality Reduction Using the Sparse Linear Model</a></p>
<p>6 0.1213544 <a title="142-tfidf-6" href="./nips-2011-Sparse_Inverse_Covariance_Matrix_Estimation_Using_Quadratic_Approximation.html">262 nips-2011-Sparse Inverse Covariance Matrix Estimation Using Quadratic Approximation</a></p>
<p>7 0.11525209 <a title="142-tfidf-7" href="./nips-2011-Nearest_Neighbor_based_Greedy_Coordinate_Descent.html">182 nips-2011-Nearest Neighbor based Greedy Coordinate Descent</a></p>
<p>8 0.1142961 <a title="142-tfidf-8" href="./nips-2011-Approximating_Semidefinite_Programs_in_Sublinear_Time.html">39 nips-2011-Approximating Semidefinite Programs in Sublinear Time</a></p>
<p>9 0.10806151 <a title="142-tfidf-9" href="./nips-2011-Sparse_Filtering.html">261 nips-2011-Sparse Filtering</a></p>
<p>10 0.10500368 <a title="142-tfidf-10" href="./nips-2011-Learning_Sparse_Representations_of_High_Dimensional_Data_on_Large_Scale_Dictionaries.html">149 nips-2011-Learning Sparse Representations of High Dimensional Data on Large Scale Dictionaries</a></p>
<p>11 0.10234993 <a title="142-tfidf-11" href="./nips-2011-Sparse_Bayesian_Multi-Task_Learning.html">258 nips-2011-Sparse Bayesian Multi-Task Learning</a></p>
<p>12 0.096853271 <a title="142-tfidf-12" href="./nips-2011-On_the_Analysis_of_Multi-Channel_Neural_Spike_Data.html">200 nips-2011-On the Analysis of Multi-Channel Neural Spike Data</a></p>
<p>13 0.095685296 <a title="142-tfidf-13" href="./nips-2011-Learning_with_the_weighted_trace-norm_under_arbitrary_sampling_distributions.html">159 nips-2011-Learning with the weighted trace-norm under arbitrary sampling distributions</a></p>
<p>14 0.093298316 <a title="142-tfidf-14" href="./nips-2011-Sparse_Estimation_with_Structured_Dictionaries.html">259 nips-2011-Sparse Estimation with Structured Dictionaries</a></p>
<p>15 0.093239412 <a title="142-tfidf-15" href="./nips-2011-Complexity_of_Inference_in_Latent_Dirichlet_Allocation.html">58 nips-2011-Complexity of Inference in Latent Dirichlet Allocation</a></p>
<p>16 0.088240251 <a title="142-tfidf-16" href="./nips-2011-High-dimensional_regression_with_noisy_and_missing_data%3A_Provable_guarantees_with_non-convexity.html">118 nips-2011-High-dimensional regression with noisy and missing data: Provable guarantees with non-convexity</a></p>
<p>17 0.085888565 <a title="142-tfidf-17" href="./nips-2011-Bayesian_Partitioning_of_Large-Scale_Distance_Data.html">43 nips-2011-Bayesian Partitioning of Large-Scale Distance Data</a></p>
<p>18 0.081277169 <a title="142-tfidf-18" href="./nips-2011-Penalty_Decomposition_Methods_for_Rank_Minimization.html">211 nips-2011-Penalty Decomposition Methods for Rank Minimization</a></p>
<p>19 0.079379492 <a title="142-tfidf-19" href="./nips-2011-Structured_sparse_coding_via_lateral_inhibition.html">276 nips-2011-Structured sparse coding via lateral inhibition</a></p>
<p>20 0.07820683 <a title="142-tfidf-20" href="./nips-2011-Robust_Lasso_with_missing_and_grossly_corrupted_observations.html">239 nips-2011-Robust Lasso with missing and grossly corrupted observations</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.208), (1, -0.02), (2, 0.055), (3, 0.114), (4, 0.088), (5, 0.06), (6, 0.078), (7, 0.0), (8, 0.129), (9, -0.012), (10, -0.059), (11, -0.028), (12, 0.052), (13, -0.09), (14, -0.03), (15, -0.024), (16, -0.033), (17, 0.018), (18, 0.021), (19, 0.127), (20, -0.055), (21, 0.102), (22, -0.078), (23, -0.012), (24, -0.05), (25, 0.015), (26, 0.024), (27, -0.069), (28, -0.106), (29, -0.057), (30, 0.013), (31, 0.098), (32, -0.071), (33, 0.033), (34, -0.135), (35, 0.025), (36, -0.028), (37, -0.005), (38, -0.111), (39, 0.056), (40, 0.195), (41, -0.047), (42, 0.13), (43, -0.054), (44, -0.008), (45, 0.011), (46, 0.013), (47, 0.109), (48, 0.089), (49, -0.127)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92429918 <a title="142-lsi-1" href="./nips-2011-Large-Scale_Sparse_Principal_Component_Analysis_with_Application_to_Text_Data.html">142 nips-2011-Large-Scale Sparse Principal Component Analysis with Application to Text Data</a></p>
<p>2 0.67581999 <a title="142-lsi-2" href="./nips-2011-Sparse_Features_for_PCA-Like_Linear_Regression.html">260 nips-2011-Sparse Features for PCA-Like Linear Regression</a></p>
<p>3 0.63245445 <a title="142-lsi-3" href="./nips-2011-Demixed_Principal_Component_Analysis.html">68 nips-2011-Demixed Principal Component Analysis</a></p>
<p>4 0.61662304 <a title="142-lsi-4" href="./nips-2011-Multi-View_Learning_of_Word_Embeddings_via_CCA.html">176 nips-2011-Multi-View Learning of Word Embeddings via CCA</a></p>
<p>5 0.60550416 <a title="142-lsi-5" href="./nips-2011-Penalty_Decomposition_Methods_for_Rank_Minimization.html">211 nips-2011-Penalty Decomposition Methods for Rank Minimization</a></p>
<p>6 0.5789845 <a title="142-lsi-6" href="./nips-2011-Matrix_Completion_for_Multi-label_Image_Classification.html">165 nips-2011-Matrix Completion for Multi-label Image Classification</a></p>
<p>7 0.54597932 <a title="142-lsi-7" href="./nips-2011-Minimax_Localization_of_Structural_Information_in_Large_Noisy_Matrices.html">172 nips-2011-Minimax Localization of Structural Information in Large Noisy Matrices</a></p>
<p>8 0.53798795 <a title="142-lsi-8" href="./nips-2011-Sparse_Estimation_with_Structured_Dictionaries.html">259 nips-2011-Sparse Estimation with Structured Dictionaries</a></p>
<p>9 0.53593218 <a title="142-lsi-9" href="./nips-2011-Sparse_Inverse_Covariance_Matrix_Estimation_Using_Quadratic_Approximation.html">262 nips-2011-Sparse Inverse Covariance Matrix Estimation Using Quadratic Approximation</a></p>
<p>10 0.5316214 <a title="142-lsi-10" href="./nips-2011-Dimensionality_Reduction_Using_the_Sparse_Linear_Model.html">70 nips-2011-Dimensionality Reduction Using the Sparse Linear Model</a></p>
<p>11 0.53082335 <a title="142-lsi-11" href="./nips-2011-Maximum_Covariance_Unfolding_%3A_Manifold_Learning_for_Bimodal_Data.html">167 nips-2011-Maximum Covariance Unfolding : Manifold Learning for Bimodal Data</a></p>
<p>12 0.48043731 <a title="142-lsi-12" href="./nips-2011-Clustered_Multi-Task_Learning_Via_Alternating_Structure_Optimization.html">51 nips-2011-Clustered Multi-Task Learning Via Alternating Structure Optimization</a></p>
<p>13 0.47404185 <a title="142-lsi-13" href="./nips-2011-Greedy_Algorithms_for_Structurally_Constrained_High_Dimensional_Problems.html">108 nips-2011-Greedy Algorithms for Structurally Constrained High Dimensional Problems</a></p>
<p>14 0.46961606 <a title="142-lsi-14" href="./nips-2011-SpaRCS%3A_Recovering_low-rank_and_sparse_matrices_from_compressive_measurements.html">257 nips-2011-SpaRCS: Recovering low-rank and sparse matrices from compressive measurements</a></p>
<p>15 0.46827546 <a title="142-lsi-15" href="./nips-2011-RTRMC%3A_A_Riemannian_trust-region_method_for_low-rank_matrix_completion.html">230 nips-2011-RTRMC: A Riemannian trust-region method for low-rank matrix completion</a></p>
<p>16 0.46537301 <a title="142-lsi-16" href="./nips-2011-Nearest_Neighbor_based_Greedy_Coordinate_Descent.html">182 nips-2011-Nearest Neighbor based Greedy Coordinate Descent</a></p>
<p>17 0.45815673 <a title="142-lsi-17" href="./nips-2011-A_Convergence_Analysis_of_Log-Linear_Training.html">4 nips-2011-A Convergence Analysis of Log-Linear Training</a></p>
<p>18 0.45711258 <a title="142-lsi-18" href="./nips-2011-ShareBoost%3A_Efficient_multiclass_learning_with_feature_sharing.html">252 nips-2011-ShareBoost: Efficient multiclass learning with feature sharing</a></p>
<p>19 0.45492819 <a title="142-lsi-19" href="./nips-2011-Learning_Sparse_Representations_of_High_Dimensional_Data_on_Large_Scale_Dictionaries.html">149 nips-2011-Learning Sparse Representations of High Dimensional Data on Large Scale Dictionaries</a></p>
<p>20 0.449745 <a title="142-lsi-20" href="./nips-2011-Global_Solution_of_Fully-Observed_Variational_Bayesian_Matrix_Factorization_is_Column-Wise_Independent.html">107 nips-2011-Global Solution of Fully-Observed Variational Bayesian Matrix Factorization is Column-Wise Independent</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.051), (22, 0.094), (36, 0.037), (53, 0.014), (55, 0.193), (65, 0.066), (68, 0.216), (79, 0.024), (90, 0.224)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.87861168 <a title="142-lda-1" href="./nips-2011-Linear_Submodular_Bandits_and_their_Application_to_Diversified_Retrieval.html">160 nips-2011-Linear Submodular Bandits and their Application to Diversified Retrieval</a></p>
<p>2 0.87309825 <a title="142-lda-2" href="./nips-2011-The_Impact_of_Unlabeled_Patterns_in_Rademacher_Complexity_Theory_for_Kernel_Classifiers.html">284 nips-2011-The Impact of Unlabeled Patterns in Rademacher Complexity Theory for Kernel Classifiers</a></p>
<p>same-paper 3 0.85356909 <a title="142-lda-3" href="./nips-2011-Large-Scale_Sparse_Principal_Component_Analysis_with_Application_to_Text_Data.html">142 nips-2011-Large-Scale Sparse Principal Component Analysis with Application to Text Data</a></p>
<p>4 0.81382966 <a title="142-lda-4" href="./nips-2011-Sparse_Estimation_with_Structured_Dictionaries.html">259 nips-2011-Sparse Estimation with Structured Dictionaries</a></p>
<p>5 0.81034672 <a title="142-lda-5" href="./nips-2011-Convergence_Rates_of_Inexact_Proximal-Gradient_Methods_for_Convex_Optimization.html">63 nips-2011-Convergence Rates of Inexact Proximal-Gradient Methods for Convex Optimization</a></p>
<p>6 0.8094961 <a title="142-lda-6" href="./nips-2011-Structured_sparse_coding_via_lateral_inhibition.html">276 nips-2011-Structured sparse coding via lateral inhibition</a></p>
<p>7 0.80947798 <a title="142-lda-7" href="./nips-2011-High-dimensional_regression_with_noisy_and_missing_data%3A_Provable_guarantees_with_non-convexity.html">118 nips-2011-High-dimensional regression with noisy and missing data: Provable guarantees with non-convexity</a></p>
<p>8 0.80932039 <a title="142-lda-8" href="./nips-2011-Learning_Sparse_Representations_of_High_Dimensional_Data_on_Large_Scale_Dictionaries.html">149 nips-2011-Learning Sparse Representations of High Dimensional Data on Large Scale Dictionaries</a></p>
<p>9 0.80836487 <a title="142-lda-9" href="./nips-2011-Trace_Lasso%3A_a_trace_norm_regularization_for_correlated_designs.html">289 nips-2011-Trace Lasso: a trace norm regularization for correlated designs</a></p>
<p>10 0.80771327 <a title="142-lda-10" href="./nips-2011-Matrix_Completion_for_Multi-label_Image_Classification.html">165 nips-2011-Matrix Completion for Multi-label Image Classification</a></p>
<p>11 0.80768907 <a title="142-lda-11" href="./nips-2011-Minimax_Localization_of_Structural_Information_in_Large_Noisy_Matrices.html">172 nips-2011-Minimax Localization of Structural Information in Large Noisy Matrices</a></p>
<p>12 0.8073957 <a title="142-lda-12" href="./nips-2011-Robust_Lasso_with_missing_and_grossly_corrupted_observations.html">239 nips-2011-Robust Lasso with missing and grossly corrupted observations</a></p>
<p>13 0.80725586 <a title="142-lda-13" href="./nips-2011-Generalized_Lasso_based_Approximation_of_Sparse_Coding_for_Visual_Recognition.html">105 nips-2011-Generalized Lasso based Approximation of Sparse Coding for Visual Recognition</a></p>
<p>14 0.80706626 <a title="142-lda-14" href="./nips-2011-ShareBoost%3A_Efficient_multiclass_learning_with_feature_sharing.html">252 nips-2011-ShareBoost: Efficient multiclass learning with feature sharing</a></p>
<p>15 0.8045547 <a title="142-lda-15" href="./nips-2011-Better_Mini-Batch_Algorithms_via_Accelerated_Gradient_Methods.html">46 nips-2011-Better Mini-Batch Algorithms via Accelerated Gradient Methods</a></p>
<p>16 0.80455136 <a title="142-lda-16" href="./nips-2011-Sparse_recovery_by_thresholded_non-negative_least_squares.html">265 nips-2011-Sparse recovery by thresholded non-negative least squares</a></p>
<p>17 0.80423427 <a title="142-lda-17" href="./nips-2011-Evaluating_the_inverse_decision-making_approach_to_preference_learning.html">90 nips-2011-Evaluating the inverse decision-making approach to preference learning</a></p>
<p>18 0.80367362 <a title="142-lda-18" href="./nips-2011-Non-Asymptotic_Analysis_of_Stochastic_Approximation_Algorithms_for_Machine_Learning.html">187 nips-2011-Non-Asymptotic Analysis of Stochastic Approximation Algorithms for Machine Learning</a></p>
<p>19 0.80330092 <a title="142-lda-19" href="./nips-2011-Sparse_Features_for_PCA-Like_Linear_Regression.html">260 nips-2011-Sparse Features for PCA-Like Linear Regression</a></p>
<p>20 0.80325902 <a title="142-lda-20" href="./nips-2011-On_the_Universality_of_Online_Mirror_Descent.html">202 nips-2011-On the Universality of Online Mirror Descent</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
