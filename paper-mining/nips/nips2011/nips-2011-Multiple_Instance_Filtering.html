<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>180 nips-2011-Multiple Instance Filtering</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-180" href="#">nips2011-180</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>180 nips-2011-Multiple Instance Filtering</h1>
<br/><p>Source: <a title="nips-2011-180-pdf" href="http://papers.nips.cc/paper/4324-multiple-instance-filtering.pdf">pdf</a></p><p>Author: Kamil A. Wnuk, Stefano Soatto</p><p>Abstract: We propose a robust ﬁltering approach based on semi-supervised and multiple instance learning (MIL). We assume that the posterior density would be unimodal if not for the eﬀect of outliers that we do not wish to explicitly model. Therefore, we seek for a point estimate at the outset, rather than a generic approximation of the entire posterior. Our approach can be thought of as a combination of standard ﬁnite-dimensional ﬁltering (Extended Kalman Filter, or Unscented Filter) with multiple instance learning, whereby the initial condition comes with a putative set of inlier measurements. We show how both the state (regression) and the inlier set (classiﬁcation) can be estimated iteratively and causally by processing only the current measurement. We illustrate our approach on visual tracking problems whereby the object of interest (target) moves and evolves as a result of occlusions and deformations, and partial knowledge of the target is given in the form of a bounding box (training set). 1</p><p>Reference: <a title="nips-2011-180-reference" href="../nips2011_reference/nips-2011-Multiple_Instance_Filtering_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 We assume that the posterior density would be unimodal if not for the eﬀect of outliers that we do not wish to explicitly model. [sent-4, score-0.166]
</p><p>2 Our approach can be thought of as a combination of standard ﬁnite-dimensional ﬁltering (Extended Kalman Filter, or Unscented Filter) with multiple instance learning, whereby the initial condition comes with a putative set of inlier measurements. [sent-6, score-0.385]
</p><p>3 We show how both the state (regression) and the inlier set (classiﬁcation) can be estimated iteratively and causally by processing only the current measurement. [sent-7, score-0.337]
</p><p>4 We illustrate our approach on visual tracking problems whereby the object of interest (target) moves and evolves as a result of occlusions and deformations, and partial knowledge of the target is given in the form of a bounding box (training set). [sent-8, score-0.873]
</p><p>5 Unfortunately, in many applications of interest, from visual tracking to robotic navigation, the posterior is not unimodal. [sent-13, score-0.207]
</p><p>6 However, in many applications one has reason to believe that the posterior would be unimodal if not for the eﬀect of outlier measurements, and therefore the interest is in a point estimate, for instance the mode, mean or median, rather than in the entire posterior. [sent-15, score-0.134]
</p><p>7 1  Prior related work  Our goal is naturally framed in the classical robust statistical inference setting, whereby classiﬁcation (inlier/outlier) is solved along with regression (ﬁltering). [sent-20, score-0.134]
</p><p>8 We assume that an initial condition is available, both for the regressor (state) as well as the inlier distribution. [sent-21, score-0.269]
</p><p>9 1  The latter can be thought of as training data in a semi-supervised setting. [sent-23, score-0.125]
</p><p>10 Our approach relates to recent work in detection-based tracking [3, 10] that use semi-supervised learning [4, 18, 13], as well as multiple-instance learning [2] and latent-SVM models [8, 20]. [sent-26, score-0.165]
</p><p>11 In [3] an ensemble of pixel-level weak classiﬁers is combined on-line via boosting; this is eﬃcient but suﬀers from drift; [10] improves stability by using a static model trained on the ﬁrst frame as a prior for labeling new training samples used to update an online classiﬁer. [sent-27, score-0.389]
</p><p>12 MILTrack [4] addressed the problem of selecting training data for model update so as to maintain maximum discriminative power. [sent-28, score-0.14]
</p><p>13 We adopt an incremental SVM with a fast approximation of a nonlinear kernel [21] rather than online boosting. [sent-32, score-0.103]
</p><p>14 Our part based representation and explicit dynamics allow us to better handle scale and shape changes without the need for a multi-scale image search [4, 13]. [sent-33, score-0.218]
</p><p>15 The P-N tracker [13] combined a median ﬂow tracker with an online random forest. [sent-35, score-0.294]
</p><p>16 New training samples were collected when detections violated structural constraints based on estimated object position. [sent-36, score-0.287]
</p><p>17 In an eﬀort to control drift, new training data was not incorporated into the model until the tracked object returned to a previously conﬁrmed appearance with high conﬁdence. [sent-37, score-0.445]
</p><p>18 This meant that if object appearance never returned to the “key frames,” the online model would never be updated. [sent-38, score-0.367]
</p><p>19 In the aforementioned works objects are represented as a bounding box. [sent-39, score-0.184]
</p><p>20 Other approaches have used explicit temporal models together with sparsity constraints to model appearance changes [15]. [sent-42, score-0.312]
</p><p>21 We propose a semi-supervised approach to ﬁltering, with an explicit temporal model, that assumes imperfect labeling, whereby portions of the image inside the bounding box are “true positives” and others are outliers. [sent-43, score-0.633]
</p><p>22 This enables us to handle appearance changes, for instance due to partial occlusions or changes of vantage point. [sent-44, score-0.29]
</p><p>23 This can be thought of as a realization of a stochastic process that evolves via some kind of ordinary diﬀerence equation IID x(t + 1) = f (x(t)) + ν(t), where ν(t) ∼ pν is a temporally independent and identically distributed process. [sent-48, score-0.156]
</p><p>24 m(t)  We denote the set of measurements at time t with y(t) = {yi (t)}i=1 , yi (t) ∈ Rk . [sent-50, score-0.316]
</p><p>25 In classical ﬁltering, the measurements are a known function of the state, y(t) = h(x(t)) + n(t), up to the measurement noise, n(t), that is a realization of a stochastic process that is often assumed to be temporally independent and identically distributed, and also independent of ν(t). [sent-52, score-0.274]
</p><p>26 In our case, however, the components of the measurement process y1 (t), . [sent-53, score-0.117]
</p><p>27 , ym(t) (t) are divided into two groups: those that behave like standard measurements in a ﬁltering process, and those that do not. [sent-56, score-0.1]
</p><p>28 The measurements are thus samples from a stochastic process that includes two independent sources of uncertainty: the measurement noise, n(t), and the selection process χ(t). [sent-61, score-0.267]
</p><p>29 Our goal is that of determining a point-estimate of the state x(t) given measurements up to time t. [sent-62, score-0.157]
</p><p>30 k=1 In order to design a ﬁlter, we ﬁrst consider the full forward model of how the various samples of the inlier measurements are generated. [sent-65, score-0.379]
</p><p>31 To this end, we assume that the inlier set is separable from the outlier set by a hyper-plane in some feature space, represented by the normal vector w(t) ∈ Rl . [sent-66, score-0.281]
</p><p>32 Conversely, if we are given the hyperplane w(t), and state x(t), the measurements can be classiﬁed via χ(t) = argminχ E(y(t), w(t), x(t), χ). [sent-71, score-0.219]
</p><p>33 The energy function, E(y(t), w(t), x(t), χ) depends on how one chooses to model the object and what side information is applied to constrain the selection of training data. [sent-72, score-0.2]
</p><p>34 In the implementation details we give examples of how appearance continuity can be used as a constraint in this step. [sent-73, score-0.152]
</p><p>35 Further, motion similarity and occlusion boundaries could also be used. [sent-74, score-0.092]
</p><p>36 Finally, the forward (data-formation) model for a sample (realization) of the measurement process is given as follows: At time t = 0, we will assume that we have available an initial distribution p(x0 ) together with an initial assignment of inliers and outliers χ0 , so x(0) ∼ p(x0 ); χ(0) = χ0 . [sent-75, score-0.51]
</p><p>37 At all subsequent times t, each realization evolves according to:  x(t + 1) = f (x(t)) + v(t),   w(t + 1) = stochSubgradIters(w(t), y(t), χ(t)), χ(t) = argminχ E(y(t), w(t), x(t), χ),   {yi (t)}i∈χ(t)+ = h(x(t), t) + n(t). [sent-77, score-0.109]
</p><p>38 Note that it is possible for the model above to proceed in open-loop, when no inliers are present. [sent-80, score-0.229]
</p><p>39 The model (1) can easily be extended to the case when the measurement equation is in implicit form, h(x(t), {yi (t)}i∈χ(t)+ , t) = n(t), since all that matters is the innovation pro. [sent-81, score-0.202]
</p><p>40 Additional extensions can be entertained where the ˆ dynamics f depends on the classiﬁer w, so that x(t + 1) = f (x(t), w(t)) + v(t), and similarly for the measurement equation h(x(t), w(t), t), although we will not consider them here. [sent-83, score-0.117]
</p><p>41 3  Application example: Visual tracking with shape and appearance changes  Objects of interest (e. [sent-85, score-0.454]
</p><p>42 humans, cars) move in ways that result in a deformation of their projection onto the image plane, even when the object is rigid. [sent-87, score-0.204]
</p><p>43 Further changes of appearance occur due to motion relative to the light source and partial occlusions. [sent-88, score-0.288]
</p><p>44 For instance, one can ﬁx a bounding box (shape) and model change of appearance inside, 3  including outliers (due to occlusion) and inliers (newly visible portions of the object). [sent-90, score-0.91]
</p><p>45 Alternatively, one can enforce constancy of the reﬂectance function, but then shape changes as well as illumination must be modeled explicitly, which is complex [12]. [sent-91, score-0.137]
</p><p>46 Our approach tracks the motion of a bounding box, enclosing the data inliers. [sent-92, score-0.301]
</p><p>47 Call c(t) ∈ R2 the center of this bounding box, vc (t) ∈ R2 the velocity of the center, d(t) ∈ R2 the length of the sides of the bounding box, and vd (t) ∈ R2 its rate of change. [sent-93, score-0.408]
</p><p>48 As before χ(t) indicates a binary labeling of the measurement components, where χ(t)+ is the set of samples that correspond to the object of interest. [sent-95, score-0.358]
</p><p>49 We have tested diﬀerent versions of our framework where the components are superpixels as well as trajectories of feature points. [sent-96, score-0.139]
</p><p>50 2  Algorithm development  We focus our discussion in this section on the development of the discriminative appearance model at the heart of the inlier/outlier classiﬁcation, w(t). [sent-103, score-0.152]
</p><p>51 For simplicity, pretend for now that each frame contains m observations. [sent-104, score-0.166]
</p><p>52 We assume an object is identiﬁed with a subset of the observations (inliers); at time t, we have {yi (t)}i∈χ(t)+ . [sent-105, score-0.122]
</p><p>53 Also pretend that observations Nf from all frames, Y = {y(t)}t=1 , were available simultaneously; Nf is the number of frames in the video sequence. [sent-106, score-0.265]
</p><p>54 If all frames were labeled, (χ(t) known ∀ t), a maximum margin classiﬁer w could be obtained by minimizing the objective (3) over all samples in all frames: ˆ   Nf m λ 1 w = argmin  ||w||2 + ˆ (w, φ(yi (t)), χi (t)) . [sent-107, score-0.324]
</p><p>55 In reality an exact label assignment at every frame is not available, so we must infer the latent labeling χ simultaneously while learning the hyperplane w. [sent-110, score-0.221]
</p><p>56 Continuing our hypothetical batch processing scenario, pretend we have estimates of some state of the object throughout Nf ˆ time, X = {ˆ(t)}t=1 . [sent-111, score-0.255]
</p><p>57 This allows us to identify a reduced subset of candidate inliers x 4  (in MIL terminology a positive bag), within which we assume all inliers are contained. [sent-112, score-0.458]
</p><p>58 The speciﬁcation of a positive bag helps reduce the search space, since we can assume all samples outside of a positive bag are negative. [sent-113, score-0.228]
</p><p>59 Recently, [19] proposed an eﬃcient incremental scheme, PEGASOS, to solve the hinge loss objective in the primal form. [sent-118, score-0.144]
</p><p>60 This enables straightforward incremental training of w as new data becomes available. [sent-119, score-0.141]
</p><p>61 In a nutshell, i=1 at each PEGASOS iteration we select a subset of training samples from the current training set Aj ⊆ T , and update w according to wj+1 = wj − ηj j . [sent-121, score-0.367]
</p><p>62 (5) seeks a solution to the binary integer program of inlier selection given w and x. [sent-125, score-0.229]
</p><p>63 Instead of tackling this NP-hard problem, we re-interpret it as a ˆ ˆ constraint enforcement step based on additional cues within a search area speciﬁed by our the current state estimate. [sent-126, score-0.124]
</p><p>64 One example constraint for a superpixel based object representation is to re-interpret the given objective as a graph cut problem, with pairwise terms enforcing appearance consistency. [sent-127, score-0.274]
</p><p>65 1 Initialization At t = 0 we are given initial observations y(0) and a bounding box indicating the object of interest {c(0) ± d(0)}. [sent-130, score-0.57]
</p><p>66 We initialize χ(0) with positive indices corresponding to superpixels that have a majority of their area |yi (0)| within the bounding box: χi (0) =  1 if |{c(0)±d(0)} ∩ |yi (0)| −1 otherwise. [sent-131, score-0.39]
</p><p>67 yi (0)|  >  y,  (6)  The area threshold is y = 0. [sent-132, score-0.283]
</p><p>68 This represents a bootstrap training set, T1 from which we learn an initial classiﬁer w(1) for distinguishing object appearance. [sent-134, score-0.302]
</p><p>69 Each element of the training set is a triplet (φ(yi (t)), χi (t), τi = t), where the last element is the time at which the feature is added to the training set. [sent-135, score-0.156]
</p><p>70 We start by selecting all positive samples and a set number of negatives, nf , sampled randomly from χ(0)− , giving T1 = {(φ(yi (0)), χi (0), 0)}∀i∈χ(0)+ ∪ {(φ(yj (0)), χj (0), 0) | j ∈ χ(0)− ⊆ rand χ(0)− , |χ(0)− | = nf }. [sent-136, score-0.545]
</p><p>71 2  Prediction Step  At time t, given the current estimate of the object state and classiﬁcation χ(t), we add all positive samples and diﬃcult negative samples lying outside of the estimated bounding box to the new training set Tt+1|t . [sent-139, score-0.765]
</p><p>72 We then propagate the object state with the model of motion dynamics and ﬁnally update the decision boundary with the newly updated training set. [sent-140, score-0.429]
</p><p>73 If τmax = 0, no memory is used and training data for model update consists only of observations from the current image. [sent-146, score-0.14]
</p><p>74 Such a memory of recent training samples is analogous to the training cache used in [8] for training the latentSVM model. [sent-147, score-0.284]
</p><p>75 During each classiﬁer update we perform N − nT iterations of the stochastic subgradient descent algorithm, starting from the current best estimate of the separating hyperplane wnT = w(t). [sent-148, score-0.163]
</p><p>76 The overall number of iterations N is set as N = 20/λ, where λ is a function of the bootstrap training set size, λ = 1/(10|T1 |). [sent-149, score-0.14]
</p><p>77 3  Update Step  The innovation is in implicit form with h(yi (t + 1)i∈χ(t+1)+ ) ∈ R4 giving a tight bounding box around the selected foreground regions in the same form as they appear in the state. [sent-155, score-0.56]
</p><p>78 In the update equations r speciﬁes the size of the search region around the predicted state within which we consider observations as candidates for foreground; ξ speciﬁes the indices of candidate observations (positive bag). [sent-156, score-0.119]
</p><p>79 6  Figure 1: Ski sequence: Left panel shows frame number, search area (black rectangle), ﬁlter prediction (blue), observation (red), and updated ﬁlter estimate (green). [sent-159, score-0.157]
</p><p>80 The algorithm performs well and successfully recovers from missed detection (from frame 349 to 352 shown above). [sent-163, score-0.178]
</p><p>81 Figure 2: P-N tracker [13] (above) and MILTrack [4] (below) initialized with the same bounding box as our approach. [sent-164, score-0.517]
</p><p>82 The P-N tracker fails because of the absence of stable low-level tracks on the target and quickly locks onto a patch of trees in the background. [sent-166, score-0.171]
</p><p>83 3  Experiments  To compare with [18, 4, 13], we ﬁrst evaluate our discriminative model without maintaining any training data history τmax = 0 and updating w every 6 frames, with training data collected between incremental updates. [sent-168, score-0.219]
</p><p>84 Even with τmax = 0 we can track highly deforming objects (a skier) with signiﬁcant scale changes through most of the 1496 frames (Fig. [sent-169, score-0.328]
</p><p>85 We also recover from errors due to the implicit memory in the decision boundary from incremental updating. [sent-171, score-0.159]
</p><p>86 Two evaluation metrics are reported: the mean center location error in pixels [4], and percentage of correctly area(ROID ∩ROIGT ) tracked frames as computed by the bounding box overlap criteria area(ROID ∪ROIGT ) > 0. [sent-176, score-0.637]
</p><p>87 5, 7  Figure 3: Convergence of the classiﬁer: Samples from frames 113, 125, 733, and 1435 of the “liquor” sequence. [sent-177, score-0.189]
</p><p>88 The ground truth for the PROST dataset is reported using a constant sized bounding box. [sent-180, score-0.265]
</p><p>89 In the liquor sequence our method correctly shrinks the bounding box to the label, since the rest of the bottle is not discriminative. [sent-182, score-0.552]
</p><p>90 If we modify the criterion to count as valid a detection where > 99% of the detection area lies within the annotated ground truth region, the score becomes 75. [sent-187, score-0.244]
</p><p>91 If we allow for > 90% of the detected area to lie within the ground truth box, the ﬁnal pascal result for the liquor sequence becomes 79. [sent-189, score-0.388]
</p><p>92 The same phenomenon occurs in the box sequence, where our approach adapts to tracking the label at the bottom of the box. [sent-192, score-0.389]
</p><p>93 Additional results, including failure modes as well as successful tracking where other approaches fail, are reported in the supplementary material, both for the case of superpixels and tracks. [sent-194, score-0.304]
</p><p>94 ours P-N [13] PROST [18] MILTrack [4] FragTrack [1]  Overall pascal 74. [sent-195, score-0.096]
</p><p>95 Our method and the P-N tracker [13] do not always detect the object. [sent-242, score-0.109]
</p><p>96 Ground truthed frames in which no location was reported by the method of [13] were not counted into the ﬁnal distance score. [sent-243, score-0.189]
</p><p>97 The method of [13] missed 2 detections on the box sequence, 1 detection on the lemming sequence, and 80 on the liquor sequence. [sent-244, score-0.551]
</p><p>98 When our approach failed to detect the object, we used the predicted bounding box from the state of the ﬁlter as our reported result. [sent-245, score-0.465]
</p><p>99 However, we have provided empirical validation of our k=1 approach on challenging visual tracking problems, where it exceeds the state of the art, and illustrated some of its failure modes. [sent-249, score-0.222]
</p><p>100 Dynamic shape and appearance modeling via moving and deforming layers. [sent-325, score-0.266]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('nf', 0.229), ('inlier', 0.229), ('inliers', 0.229), ('box', 0.224), ('yi', 0.216), ('frames', 0.189), ('bounding', 0.184), ('prost', 0.173), ('ltering', 0.168), ('tracking', 0.165), ('appearance', 0.152), ('liquor', 0.144), ('superpixels', 0.139), ('object', 0.122), ('measurement', 0.117), ('miltrack', 0.116), ('mnf', 0.116), ('tt', 0.114), ('tracker', 0.109), ('measurements', 0.1), ('wj', 0.099), ('pascal', 0.096), ('frame', 0.09), ('bag', 0.089), ('roid', 0.087), ('roigt', 0.087), ('stochsubgraditers', 0.087), ('argmin', 0.085), ('outliers', 0.084), ('changes', 0.081), ('training', 0.078), ('pretend', 0.076), ('aj', 0.073), ('whereby', 0.069), ('labeling', 0.069), ('foreground', 0.067), ('area', 0.067), ('cvpr', 0.066), ('robust', 0.065), ('incremental', 0.063), ('classi', 0.063), ('bootstrap', 0.062), ('tracks', 0.062), ('hyperplane', 0.062), ('update', 0.062), ('deforming', 0.058), ('leistner', 0.058), ('lemming', 0.058), ('wnt', 0.058), ('state', 0.057), ('pegasos', 0.057), ('occlusions', 0.057), ('realization', 0.057), ('iid', 0.057), ('shape', 0.056), ('er', 0.055), ('boundary', 0.055), ('motion', 0.055), ('returned', 0.053), ('evolves', 0.052), ('outlier', 0.052), ('causally', 0.051), ('deformations', 0.051), ('si', 0.05), ('samples', 0.05), ('detection', 0.048), ('thought', 0.047), ('mode', 0.046), ('lter', 0.046), ('particle', 0.046), ('drift', 0.046), ('innovation', 0.044), ('mil', 0.044), ('ground', 0.044), ('nt', 0.043), ('primal', 0.043), ('posterior', 0.042), ('di', 0.042), ('centroid', 0.042), ('deformation', 0.042), ('explicit', 0.041), ('implicit', 0.041), ('online', 0.04), ('image', 0.04), ('missed', 0.04), ('tracked', 0.04), ('vd', 0.04), ('unimodal', 0.04), ('lc', 0.04), ('initial', 0.04), ('subgradient', 0.039), ('temporal', 0.038), ('hinge', 0.038), ('detections', 0.037), ('occlusion', 0.037), ('portions', 0.037), ('rand', 0.037), ('truth', 0.037), ('median', 0.036), ('max', 0.036)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="180-tfidf-1" href="./nips-2011-Multiple_Instance_Filtering.html">180 nips-2011-Multiple Instance Filtering</a></p>
<p>Author: Kamil A. Wnuk, Stefano Soatto</p><p>Abstract: We propose a robust ﬁltering approach based on semi-supervised and multiple instance learning (MIL). We assume that the posterior density would be unimodal if not for the eﬀect of outliers that we do not wish to explicitly model. Therefore, we seek for a point estimate at the outset, rather than a generic approximation of the entire posterior. Our approach can be thought of as a combination of standard ﬁnite-dimensional ﬁltering (Extended Kalman Filter, or Unscented Filter) with multiple instance learning, whereby the initial condition comes with a putative set of inlier measurements. We show how both the state (regression) and the inlier set (classiﬁcation) can be estimated iteratively and causally by processing only the current measurement. We illustrate our approach on visual tracking problems whereby the object of interest (target) moves and evolves as a result of occlusions and deformations, and partial knowledge of the target is given in the form of a bounding box (training set). 1</p><p>2 0.20659171 <a title="180-tfidf-2" href="./nips-2011-Video_Annotation_and_Tracking_with_Active_Learning.html">303 nips-2011-Video Annotation and Tracking with Active Learning</a></p>
<p>Author: Carl Vondrick, Deva Ramanan</p><p>Abstract: We introduce a novel active learning framework for video annotation. By judiciously choosing which frames a user should annotate, we can obtain highly accurate tracks with minimal user effort. We cast this problem as one of active learning, and show that we can obtain excellent performance by querying frames that, if annotated, would produce a large expected change in the estimated object track. We implement a constrained tracker and compute the expected change for putative annotations with efﬁcient dynamic programming algorithms. We demonstrate our framework on four datasets, including two benchmark datasets constructed with key frame annotations obtained by Amazon Mechanical Turk. Our results indicate that we could obtain equivalent labels for a small fraction of the original cost. 1</p><p>3 0.17845595 <a title="180-tfidf-3" href="./nips-2011-Structured_Learning_for_Cell_Tracking.html">275 nips-2011-Structured Learning for Cell Tracking</a></p>
<p>Author: Xinghua Lou, Fred A. Hamprecht</p><p>Abstract: We study the problem of learning to track a large quantity of homogeneous objects such as cell tracking in cell culture study and developmental biology. Reliable cell tracking in time-lapse microscopic image sequences is important for modern biomedical research. Existing cell tracking methods are usually kept simple and use only a small number of features to allow for manual parameter tweaking or grid search. We propose a structured learning approach that allows to learn optimum parameters automatically from a training set. This allows for the use of a richer set of features which in turn affords improved tracking compared to recently reported methods on two public benchmark sequences. 1</p><p>4 0.1571286 <a title="180-tfidf-4" href="./nips-2011-Object_Detection_with_Grammar_Models.html">193 nips-2011-Object Detection with Grammar Models</a></p>
<p>Author: Ross B. Girshick, Pedro F. Felzenszwalb, David A. McAllester</p><p>Abstract: Compositional models provide an elegant formalism for representing the visual appearance of highly variable objects. While such models are appealing from a theoretical point of view, it has been difﬁcult to demonstrate that they lead to performance advantages on challenging datasets. Here we develop a grammar model for person detection and show that it outperforms previous high-performance systems on the PASCAL benchmark. Our model represents people using a hierarchy of deformable parts, variable structure and an explicit model of occlusion for partially visible objects. To train the model, we introduce a new discriminative framework for learning structured prediction models from weakly-labeled data. 1</p><p>5 0.15356235 <a title="180-tfidf-5" href="./nips-2011-Semantic_Labeling_of_3D_Point_Clouds_for_Indoor_Scenes.html">247 nips-2011-Semantic Labeling of 3D Point Clouds for Indoor Scenes</a></p>
<p>Author: Hema S. Koppula, Abhishek Anand, Thorsten Joachims, Ashutosh Saxena</p><p>Abstract: Inexpensive RGB-D cameras that give an RGB image together with depth data have become widely available. In this paper, we use this data to build 3D point clouds of full indoor scenes such as an ofﬁce and address the task of semantic labeling of these 3D point clouds. We propose a graphical model that captures various features and contextual relations, including the local visual appearance and shape cues, object co-occurence relationships and geometric relationships. With a large number of object classes and relations, the model’s parsimony becomes important and we address that by using multiple types of edge potentials. The model admits efﬁcient approximate inference, and we train it using a maximum-margin learning approach. In our experiments over a total of 52 3D scenes of homes and ofﬁces (composed from about 550 views, having 2495 segments labeled with 27 object classes), we get a performance of 84.06% in labeling 17 object classes for ofﬁces, and 73.38% in labeling 17 object classes for home scenes. Finally, we applied these algorithms successfully on a mobile robot for the task of ﬁnding objects in large cluttered rooms.1 1</p><p>6 0.13895975 <a title="180-tfidf-6" href="./nips-2011-%24%5Ctheta%24-MRF%3A_Capturing_Spatial_and_Semantic_Structure_in_the_Parameters_for_Scene_Understanding.html">1 nips-2011-$\theta$-MRF: Capturing Spatial and Semantic Structure in the Parameters for Scene Understanding</a></p>
<p>7 0.13094431 <a title="180-tfidf-7" href="./nips-2011-Learning_person-object_interactions_for_action_recognition_in_still_images.html">154 nips-2011-Learning person-object interactions for action recognition in still images</a></p>
<p>8 0.12250048 <a title="180-tfidf-8" href="./nips-2011-Simultaneous_Sampling_and_Multi-Structure_Fitting_with_Adaptive_Reversible_Jump_MCMC.html">255 nips-2011-Simultaneous Sampling and Multi-Structure Fitting with Adaptive Reversible Jump MCMC</a></p>
<p>9 0.12151974 <a title="180-tfidf-9" href="./nips-2011-Maximal_Cliques_that_Satisfy_Hard_Constraints_with_Application_to_Deformable_Object_Model_Learning.html">166 nips-2011-Maximal Cliques that Satisfy Hard Constraints with Application to Deformable Object Model Learning</a></p>
<p>10 0.11667194 <a title="180-tfidf-10" href="./nips-2011-Maximum_Margin_Multi-Instance_Learning.html">168 nips-2011-Maximum Margin Multi-Instance Learning</a></p>
<p>11 0.11303417 <a title="180-tfidf-11" href="./nips-2011-Joint_3D_Estimation_of_Objects_and_Scene_Layout.html">138 nips-2011-Joint 3D Estimation of Objects and Scene Layout</a></p>
<p>12 0.10886393 <a title="180-tfidf-12" href="./nips-2011-Transfer_Learning_by_Borrowing_Examples_for_Multiclass_Object_Detection.html">290 nips-2011-Transfer Learning by Borrowing Examples for Multiclass Object Detection</a></p>
<p>13 0.10854119 <a title="180-tfidf-13" href="./nips-2011-An_ideal_observer_model_for_identifying_the_reference_frame_of_objects.html">35 nips-2011-An ideal observer model for identifying the reference frame of objects</a></p>
<p>14 0.10605154 <a title="180-tfidf-14" href="./nips-2011-Exploiting_spatial_overlap_to_efficiently_compute_appearance_distances_between_image_windows.html">91 nips-2011-Exploiting spatial overlap to efficiently compute appearance distances between image windows</a></p>
<p>15 0.10552841 <a title="180-tfidf-15" href="./nips-2011-Learning_Probabilistic_Non-Linear_Latent_Variable_Models_for_Tracking_Complex_Activities.html">148 nips-2011-Learning Probabilistic Non-Linear Latent Variable Models for Tracking Complex Activities</a></p>
<p>16 0.10206772 <a title="180-tfidf-16" href="./nips-2011-Sparse_Filtering.html">261 nips-2011-Sparse Filtering</a></p>
<p>17 0.099972174 <a title="180-tfidf-17" href="./nips-2011-Probabilistic_Joint_Image_Segmentation_and_Labeling.html">223 nips-2011-Probabilistic Joint Image Segmentation and Labeling</a></p>
<p>18 0.093392506 <a title="180-tfidf-18" href="./nips-2011-Higher-Order_Correlation_Clustering_for_Image_Segmentation.html">119 nips-2011-Higher-Order Correlation Clustering for Image Segmentation</a></p>
<p>19 0.091873609 <a title="180-tfidf-19" href="./nips-2011-Matrix_Completion_for_Multi-label_Image_Classification.html">165 nips-2011-Matrix Completion for Multi-label Image Classification</a></p>
<p>20 0.088784255 <a title="180-tfidf-20" href="./nips-2011-Fast_and_Balanced%3A_Efficient_Label_Tree_Learning_for_Large_Scale_Object_Recognition.html">96 nips-2011-Fast and Balanced: Efficient Label Tree Learning for Large Scale Object Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.268), (1, 0.104), (2, -0.101), (3, 0.15), (4, 0.074), (5, 0.07), (6, 0.014), (7, -0.091), (8, -0.028), (9, 0.147), (10, 0.069), (11, -0.103), (12, 0.028), (13, 0.005), (14, -0.014), (15, -0.053), (16, -0.008), (17, 0.014), (18, -0.021), (19, 0.05), (20, -0.014), (21, 0.015), (22, 0.002), (23, -0.004), (24, 0.006), (25, -0.06), (26, -0.277), (27, 0.114), (28, -0.019), (29, -0.066), (30, -0.023), (31, -0.031), (32, 0.177), (33, -0.063), (34, -0.049), (35, 0.038), (36, -0.005), (37, -0.011), (38, 0.101), (39, -0.079), (40, 0.009), (41, -0.152), (42, 0.024), (43, -0.015), (44, 0.036), (45, -0.027), (46, 0.008), (47, -0.023), (48, -0.04), (49, -0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94560444 <a title="180-lsi-1" href="./nips-2011-Multiple_Instance_Filtering.html">180 nips-2011-Multiple Instance Filtering</a></p>
<p>Author: Kamil A. Wnuk, Stefano Soatto</p><p>Abstract: We propose a robust ﬁltering approach based on semi-supervised and multiple instance learning (MIL). We assume that the posterior density would be unimodal if not for the eﬀect of outliers that we do not wish to explicitly model. Therefore, we seek for a point estimate at the outset, rather than a generic approximation of the entire posterior. Our approach can be thought of as a combination of standard ﬁnite-dimensional ﬁltering (Extended Kalman Filter, or Unscented Filter) with multiple instance learning, whereby the initial condition comes with a putative set of inlier measurements. We show how both the state (regression) and the inlier set (classiﬁcation) can be estimated iteratively and causally by processing only the current measurement. We illustrate our approach on visual tracking problems whereby the object of interest (target) moves and evolves as a result of occlusions and deformations, and partial knowledge of the target is given in the form of a bounding box (training set). 1</p><p>2 0.82524598 <a title="180-lsi-2" href="./nips-2011-Structured_Learning_for_Cell_Tracking.html">275 nips-2011-Structured Learning for Cell Tracking</a></p>
<p>Author: Xinghua Lou, Fred A. Hamprecht</p><p>Abstract: We study the problem of learning to track a large quantity of homogeneous objects such as cell tracking in cell culture study and developmental biology. Reliable cell tracking in time-lapse microscopic image sequences is important for modern biomedical research. Existing cell tracking methods are usually kept simple and use only a small number of features to allow for manual parameter tweaking or grid search. We propose a structured learning approach that allows to learn optimum parameters automatically from a training set. This allows for the use of a richer set of features which in turn affords improved tracking compared to recently reported methods on two public benchmark sequences. 1</p><p>3 0.73805618 <a title="180-lsi-3" href="./nips-2011-Object_Detection_with_Grammar_Models.html">193 nips-2011-Object Detection with Grammar Models</a></p>
<p>Author: Ross B. Girshick, Pedro F. Felzenszwalb, David A. McAllester</p><p>Abstract: Compositional models provide an elegant formalism for representing the visual appearance of highly variable objects. While such models are appealing from a theoretical point of view, it has been difﬁcult to demonstrate that they lead to performance advantages on challenging datasets. Here we develop a grammar model for person detection and show that it outperforms previous high-performance systems on the PASCAL benchmark. Our model represents people using a hierarchy of deformable parts, variable structure and an explicit model of occlusion for partially visible objects. To train the model, we introduce a new discriminative framework for learning structured prediction models from weakly-labeled data. 1</p><p>4 0.73372173 <a title="180-lsi-4" href="./nips-2011-Video_Annotation_and_Tracking_with_Active_Learning.html">303 nips-2011-Video Annotation and Tracking with Active Learning</a></p>
<p>Author: Carl Vondrick, Deva Ramanan</p><p>Abstract: We introduce a novel active learning framework for video annotation. By judiciously choosing which frames a user should annotate, we can obtain highly accurate tracks with minimal user effort. We cast this problem as one of active learning, and show that we can obtain excellent performance by querying frames that, if annotated, would produce a large expected change in the estimated object track. We implement a constrained tracker and compute the expected change for putative annotations with efﬁcient dynamic programming algorithms. We demonstrate our framework on four datasets, including two benchmark datasets constructed with key frame annotations obtained by Amazon Mechanical Turk. Our results indicate that we could obtain equivalent labels for a small fraction of the original cost. 1</p><p>5 0.62968856 <a title="180-lsi-5" href="./nips-2011-Transfer_Learning_by_Borrowing_Examples_for_Multiclass_Object_Detection.html">290 nips-2011-Transfer Learning by Borrowing Examples for Multiclass Object Detection</a></p>
<p>Author: Joseph J. Lim, Antonio Torralba, Ruslan Salakhutdinov</p><p>Abstract: Despite the recent trend of increasingly large datasets for object detection, there still exist many classes with few training examples. To overcome this lack of training data for certain classes, we propose a novel way of augmenting the training data for each class by borrowing and transforming examples from other classes. Our model learns which training instances from other classes to borrow and how to transform the borrowed examples so that they become more similar to instances from the target class. Our experimental results demonstrate that our new object detector, with borrowed and transformed examples, improves upon the current state-of-the-art detector on the challenging SUN09 object detection dataset. 1</p><p>6 0.56645757 <a title="180-lsi-6" href="./nips-2011-Learning_Probabilistic_Non-Linear_Latent_Variable_Models_for_Tracking_Complex_Activities.html">148 nips-2011-Learning Probabilistic Non-Linear Latent Variable Models for Tracking Complex Activities</a></p>
<p>7 0.56147134 <a title="180-lsi-7" href="./nips-2011-Simultaneous_Sampling_and_Multi-Structure_Fitting_with_Adaptive_Reversible_Jump_MCMC.html">255 nips-2011-Simultaneous Sampling and Multi-Structure Fitting with Adaptive Reversible Jump MCMC</a></p>
<p>8 0.55731267 <a title="180-lsi-8" href="./nips-2011-Joint_3D_Estimation_of_Objects_and_Scene_Layout.html">138 nips-2011-Joint 3D Estimation of Objects and Scene Layout</a></p>
<p>9 0.55590385 <a title="180-lsi-9" href="./nips-2011-Learning_person-object_interactions_for_action_recognition_in_still_images.html">154 nips-2011-Learning person-object interactions for action recognition in still images</a></p>
<p>10 0.54573405 <a title="180-lsi-10" href="./nips-2011-Maximum_Margin_Multi-Label_Structured_Prediction.html">169 nips-2011-Maximum Margin Multi-Label Structured Prediction</a></p>
<p>11 0.54062611 <a title="180-lsi-11" href="./nips-2011-Maximal_Cliques_that_Satisfy_Hard_Constraints_with_Application_to_Deformable_Object_Model_Learning.html">166 nips-2011-Maximal Cliques that Satisfy Hard Constraints with Application to Deformable Object Model Learning</a></p>
<p>12 0.53549719 <a title="180-lsi-12" href="./nips-2011-Semantic_Labeling_of_3D_Point_Clouds_for_Indoor_Scenes.html">247 nips-2011-Semantic Labeling of 3D Point Clouds for Indoor Scenes</a></p>
<p>13 0.49548095 <a title="180-lsi-13" href="./nips-2011-An_ideal_observer_model_for_identifying_the_reference_frame_of_objects.html">35 nips-2011-An ideal observer model for identifying the reference frame of objects</a></p>
<p>14 0.47326204 <a title="180-lsi-14" href="./nips-2011-Rapid_Deformable_Object_Detection_using_Dual-Tree_Branch-and-Bound.html">233 nips-2011-Rapid Deformable Object Detection using Dual-Tree Branch-and-Bound</a></p>
<p>15 0.46769133 <a title="180-lsi-15" href="./nips-2011-%24%5Ctheta%24-MRF%3A_Capturing_Spatial_and_Semantic_Structure_in_the_Parameters_for_Scene_Understanding.html">1 nips-2011-$\theta$-MRF: Capturing Spatial and Semantic Structure in the Parameters for Scene Understanding</a></p>
<p>16 0.46493232 <a title="180-lsi-16" href="./nips-2011-Probabilistic_Joint_Image_Segmentation_and_Labeling.html">223 nips-2011-Probabilistic Joint Image Segmentation and Labeling</a></p>
<p>17 0.45464125 <a title="180-lsi-17" href="./nips-2011-Submodular_Multi-Label_Learning.html">277 nips-2011-Submodular Multi-Label Learning</a></p>
<p>18 0.45213994 <a title="180-lsi-18" href="./nips-2011-On_Tracking_The_Partition_Function.html">197 nips-2011-On Tracking The Partition Function</a></p>
<p>19 0.44778535 <a title="180-lsi-19" href="./nips-2011-Ranking_annotators_for_crowdsourced_labeling_tasks.html">232 nips-2011-Ranking annotators for crowdsourced labeling tasks</a></p>
<p>20 0.44693372 <a title="180-lsi-20" href="./nips-2011-An_Exact_Algorithm_for_F-Measure_Maximization.html">33 nips-2011-An Exact Algorithm for F-Measure Maximization</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.014), (4, 0.072), (6, 0.011), (20, 0.091), (26, 0.04), (31, 0.122), (33, 0.056), (40, 0.149), (43, 0.07), (45, 0.096), (57, 0.037), (65, 0.017), (74, 0.046), (83, 0.049), (84, 0.015), (99, 0.052)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.89509523 <a title="180-lda-1" href="./nips-2011-Global_Solution_of_Fully-Observed_Variational_Bayesian_Matrix_Factorization_is_Column-Wise_Independent.html">107 nips-2011-Global Solution of Fully-Observed Variational Bayesian Matrix Factorization is Column-Wise Independent</a></p>
<p>Author: Shinichi Nakajima, Masashi Sugiyama, S. D. Babacan</p><p>Abstract: Variational Bayesian matrix factorization (VBMF) efﬁciently approximates the posterior distribution of factorized matrices by assuming matrix-wise independence of the two factors. A recent study on fully-observed VBMF showed that, under a stronger assumption that the two factorized matrices are column-wise independent, the global optimal solution can be analytically computed. However, it was not clear how restrictive the column-wise independence assumption is. In this paper, we prove that the global solution under matrix-wise independence is actually column-wise independent, implying that the column-wise independence assumption is harmless. A practical consequence of our theoretical ﬁnding is that the global solution under matrix-wise independence (which is a standard setup) can be obtained analytically in a computationally very efﬁcient way without any iterative algorithms. We experimentally illustrate advantages of using our analytic solution in probabilistic principal component analysis. 1</p><p>same-paper 2 0.86494058 <a title="180-lda-2" href="./nips-2011-Multiple_Instance_Filtering.html">180 nips-2011-Multiple Instance Filtering</a></p>
<p>Author: Kamil A. Wnuk, Stefano Soatto</p><p>Abstract: We propose a robust ﬁltering approach based on semi-supervised and multiple instance learning (MIL). We assume that the posterior density would be unimodal if not for the eﬀect of outliers that we do not wish to explicitly model. Therefore, we seek for a point estimate at the outset, rather than a generic approximation of the entire posterior. Our approach can be thought of as a combination of standard ﬁnite-dimensional ﬁltering (Extended Kalman Filter, or Unscented Filter) with multiple instance learning, whereby the initial condition comes with a putative set of inlier measurements. We show how both the state (regression) and the inlier set (classiﬁcation) can be estimated iteratively and causally by processing only the current measurement. We illustrate our approach on visual tracking problems whereby the object of interest (target) moves and evolves as a result of occlusions and deformations, and partial knowledge of the target is given in the form of a bounding box (training set). 1</p><p>3 0.81471485 <a title="180-lda-3" href="./nips-2011-Algorithms_for_Hyper-Parameter_Optimization.html">30 nips-2011-Algorithms for Hyper-Parameter Optimization</a></p>
<p>Author: James S. Bergstra, Rémi Bardenet, Yoshua Bengio, Balázs Kégl</p><p>Abstract: Several recent advances to the state of the art in image classiﬁcation benchmarks have come from better conﬁgurations of existing techniques rather than novel approaches to feature learning. Traditionally, hyper-parameter optimization has been the job of humans because they can be very efﬁcient in regimes where only a few trials are possible. Presently, computer clusters and GPU processors make it possible to run more trials and we show that algorithmic approaches can ﬁnd better results. We present hyper-parameter optimization results on tasks of training neural networks and deep belief networks (DBNs). We optimize hyper-parameters using random search and two new greedy sequential methods based on the expected improvement criterion. Random search has been shown to be sufﬁciently efﬁcient for learning neural networks for several datasets, but we show it is unreliable for training DBNs. The sequential algorithms are applied to the most difﬁcult DBN learning problems from [1] and ﬁnd signiﬁcantly better results than the best previously reported. This work contributes novel techniques for making response surface models P (y|x) in which many elements of hyper-parameter assignment (x) are known to be irrelevant given particular values of other elements. 1</p><p>4 0.8100881 <a title="180-lda-4" href="./nips-2011-From_Bandits_to_Experts%3A_On_the_Value_of_Side-Observations.html">98 nips-2011-From Bandits to Experts: On the Value of Side-Observations</a></p>
<p>Author: Shie Mannor, Ohad Shamir</p><p>Abstract: We consider an adversarial online learning setting where a decision maker can choose an action in every stage of the game. In addition to observing the reward of the chosen action, the decision maker gets side observations on the reward he would have obtained had he chosen some of the other actions. The observation structure is encoded as a graph, where node i is linked to node j if sampling i provides information on the reward of j. This setting naturally interpolates between the well-known “experts” setting, where the decision maker can view all rewards, and the multi-armed bandits setting, where the decision maker can only view the reward of the chosen action. We develop practical algorithms with provable regret guarantees, which depend on non-trivial graph-theoretic properties of the information feedback structure. We also provide partially-matching lower bounds. 1</p><p>5 0.79617155 <a title="180-lda-5" href="./nips-2011-Video_Annotation_and_Tracking_with_Active_Learning.html">303 nips-2011-Video Annotation and Tracking with Active Learning</a></p>
<p>Author: Carl Vondrick, Deva Ramanan</p><p>Abstract: We introduce a novel active learning framework for video annotation. By judiciously choosing which frames a user should annotate, we can obtain highly accurate tracks with minimal user effort. We cast this problem as one of active learning, and show that we can obtain excellent performance by querying frames that, if annotated, would produce a large expected change in the estimated object track. We implement a constrained tracker and compute the expected change for putative annotations with efﬁcient dynamic programming algorithms. We demonstrate our framework on four datasets, including two benchmark datasets constructed with key frame annotations obtained by Amazon Mechanical Turk. Our results indicate that we could obtain equivalent labels for a small fraction of the original cost. 1</p><p>6 0.79118067 <a title="180-lda-6" href="./nips-2011-Pylon_Model_for_Semantic_Segmentation.html">227 nips-2011-Pylon Model for Semantic Segmentation</a></p>
<p>7 0.78912884 <a title="180-lda-7" href="./nips-2011-Spatial_distance_dependent_Chinese_restaurant_processes_for_image_segmentation.html">266 nips-2011-Spatial distance dependent Chinese restaurant processes for image segmentation</a></p>
<p>8 0.78681177 <a title="180-lda-8" href="./nips-2011-Probabilistic_Joint_Image_Segmentation_and_Labeling.html">223 nips-2011-Probabilistic Joint Image Segmentation and Labeling</a></p>
<p>9 0.77571887 <a title="180-lda-9" href="./nips-2011-Collective_Graphical_Models.html">55 nips-2011-Collective Graphical Models</a></p>
<p>10 0.77304608 <a title="180-lda-10" href="./nips-2011-Dynamical_segmentation_of_single_trials_from_population_neural_data.html">75 nips-2011-Dynamical segmentation of single trials from population neural data</a></p>
<p>11 0.76966423 <a title="180-lda-11" href="./nips-2011-Comparative_Analysis_of_Viterbi_Training_and_Maximum_Likelihood_Estimation_for_HMMs.html">57 nips-2011-Comparative Analysis of Viterbi Training and Maximum Likelihood Estimation for HMMs</a></p>
<p>12 0.76947105 <a title="180-lda-12" href="./nips-2011-Crowdclustering.html">66 nips-2011-Crowdclustering</a></p>
<p>13 0.76944083 <a title="180-lda-13" href="./nips-2011-Online_Learning%3A_Stochastic%2C_Constrained%2C_and_Smoothed_Adversaries.html">204 nips-2011-Online Learning: Stochastic, Constrained, and Smoothed Adversaries</a></p>
<p>14 0.76845264 <a title="180-lda-14" href="./nips-2011-%24%5Ctheta%24-MRF%3A_Capturing_Spatial_and_Semantic_Structure_in_the_Parameters_for_Scene_Understanding.html">1 nips-2011-$\theta$-MRF: Capturing Spatial and Semantic Structure in the Parameters for Scene Understanding</a></p>
<p>15 0.76637632 <a title="180-lda-15" href="./nips-2011-Image_Parsing_with_Stochastic_Scene_Grammar.html">127 nips-2011-Image Parsing with Stochastic Scene Grammar</a></p>
<p>16 0.76509523 <a title="180-lda-16" href="./nips-2011-Query-Aware_MCMC.html">229 nips-2011-Query-Aware MCMC</a></p>
<p>17 0.76364118 <a title="180-lda-17" href="./nips-2011-Learning_to_Learn_with_Compound_HD_Models.html">156 nips-2011-Learning to Learn with Compound HD Models</a></p>
<p>18 0.76186723 <a title="180-lda-18" href="./nips-2011-Learning_person-object_interactions_for_action_recognition_in_still_images.html">154 nips-2011-Learning person-object interactions for action recognition in still images</a></p>
<p>19 0.75999725 <a title="180-lda-19" href="./nips-2011-Randomized_Algorithms_for_Comparison-based_Search.html">231 nips-2011-Randomized Algorithms for Comparison-based Search</a></p>
<p>20 0.75898689 <a title="180-lda-20" href="./nips-2011-Accelerated_Adaptive_Markov_Chain_for_Partition_Function_Computation.html">17 nips-2011-Accelerated Adaptive Markov Chain for Partition Function Computation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
