<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>282 nips-2011-The Fast Convergence of Boosting</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-282" href="#">nips2011-282</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>282 nips-2011-The Fast Convergence of Boosting</h1>
<br/><p>Source: <a title="nips-2011-282-pdf" href="http://papers.nips.cc/paper/4343-the-fast-convergence-of-boosting.pdf">pdf</a></p><p>Author: Matus J. Telgarsky</p><p>Abstract: This manuscript considers the convergence rate of boosting under a large class of losses, including the exponential and logistic losses, where the best previous rate of convergence was O(exp(1/✏2 )). First, it is established that the setting of weak learnability aids the entire class, granting a rate O(ln(1/✏)). Next, the (disjoint) conditions under which the inﬁmal empirical risk is attainable are characterized in terms of the sample and weak learning class, and a new proof is given for the known rate O(ln(1/✏)). Finally, it is established that any instance can be decomposed into two smaller instances resembling the two preceding special cases, yielding a rate O(1/✏), with a matching lower bound for the logistic loss. The principal technical hurdle throughout this work is the potential unattainability of the inﬁmal empirical risk; the technique for overcoming this barrier may be of general interest. 1</p><p>Reference: <a title="nips-2011-282-reference" href="../nips2011_reference/nips-2011-The_Fast_Convergence_of_Boosting_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ker', 0.323), ('weak', 0.32), ('boost', 0.286), ('rf', 0.259), ('rm', 0.255), ('infn', 0.236), ('dual', 0.236), ('halfspac', 0.208), ('hai', 0.184), ('attain', 0.174), ('fa', 0.167), ('ka', 0.126), ('ln', 0.119), ('manuscrib', 0.119), ('loss', 0.109), ('schapire', 0.108), ('rat', 0.097), ('robert', 0.092), ('converg', 0.087), ('adaboost', 0.084)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="282-tfidf-1" href="./nips-2011-The_Fast_Convergence_of_Boosting.html">282 nips-2011-The Fast Convergence of Boosting</a></p>
<p>2 0.32538065 <a title="282-tfidf-2" href="./nips-2011-Algorithms_and_hardness_results_for_parallel_large_margin_learning.html">29 nips-2011-Algorithms and hardness results for parallel large margin learning</a></p>
<p>3 0.24846573 <a title="282-tfidf-3" href="./nips-2011-Multiclass_Boosting%3A_Theory_and_Algorithms.html">178 nips-2011-Multiclass Boosting: Theory and Algorithms</a></p>
<p>4 0.22266379 <a title="282-tfidf-4" href="./nips-2011-Learning_large-margin_halfspaces_with_more_malicious_noise.html">153 nips-2011-Learning large-margin halfspaces with more malicious noise</a></p>
<p>5 0.13132387 <a title="282-tfidf-5" href="./nips-2011-Variance_Penalizing_AdaBoost.html">299 nips-2011-Variance Penalizing AdaBoost</a></p>
<p>6 0.12016744 <a title="282-tfidf-6" href="./nips-2011-Boosting_with_Maximum_Adaptive_Sampling.html">49 nips-2011-Boosting with Maximum Adaptive Sampling</a></p>
<p>7 0.10232653 <a title="282-tfidf-7" href="./nips-2011-On_the_accuracy_of_l1-filtering_of_signals_with_block-sparse_structure.html">203 nips-2011-On the accuracy of l1-filtering of signals with block-sparse structure</a></p>
<p>8 0.099392064 <a title="282-tfidf-8" href="./nips-2011-Hierarchical_Multitask_Structured_Output_Learning_for_Large-scale_Sequence_Segmentation.html">114 nips-2011-Hierarchical Multitask Structured Output Learning for Large-scale Sequence Segmentation</a></p>
<p>9 0.09268029 <a title="282-tfidf-9" href="./nips-2011-On_the_Universality_of_Online_Mirror_Descent.html">202 nips-2011-On the Universality of Online Mirror Descent</a></p>
<p>10 0.091333829 <a title="282-tfidf-10" href="./nips-2011-k-NN_Regression_Adapts_to_Local_Intrinsic_Dimension.html">305 nips-2011-k-NN Regression Adapts to Local Intrinsic Dimension</a></p>
<p>11 0.088878185 <a title="282-tfidf-11" href="./nips-2011-High-dimensional_regression_with_noisy_and_missing_data%3A_Provable_guarantees_with_non-convexity.html">118 nips-2011-High-dimensional regression with noisy and missing data: Provable guarantees with non-convexity</a></p>
<p>12 0.087633818 <a title="282-tfidf-12" href="./nips-2011-Nearest_Neighbor_based_Greedy_Coordinate_Descent.html">182 nips-2011-Nearest Neighbor based Greedy Coordinate Descent</a></p>
<p>13 0.081684262 <a title="282-tfidf-13" href="./nips-2011-Unifying_Framework_for_Fast_Learning_Rate_of_Non-Sparse_Multiple_Kernel_Learning.html">294 nips-2011-Unifying Framework for Fast Learning Rate of Non-Sparse Multiple Kernel Learning</a></p>
<p>14 0.0798603 <a title="282-tfidf-14" href="./nips-2011-Beating_SGD%3A_Learning_SVMs_in_Sublinear_Time.html">45 nips-2011-Beating SGD: Learning SVMs in Sublinear Time</a></p>
<p>15 0.078086212 <a title="282-tfidf-15" href="./nips-2011-Agnostic_Selective_Classification.html">28 nips-2011-Agnostic Selective Classification</a></p>
<p>16 0.076658227 <a title="282-tfidf-16" href="./nips-2011-Structured_Learning_for_Cell_Tracking.html">275 nips-2011-Structured Learning for Cell Tracking</a></p>
<p>17 0.076551512 <a title="282-tfidf-17" href="./nips-2011-Adaptive_Hedge.html">25 nips-2011-Adaptive Hedge</a></p>
<p>18 0.076287135 <a title="282-tfidf-18" href="./nips-2011-Selecting_Receptive_Fields_in_Deep_Networks.html">244 nips-2011-Selecting Receptive Fields in Deep Networks</a></p>
<p>19 0.070918962 <a title="282-tfidf-19" href="./nips-2011-Sparse_Estimation_with_Structured_Dictionaries.html">259 nips-2011-Sparse Estimation with Structured Dictionaries</a></p>
<p>20 0.07064195 <a title="282-tfidf-20" href="./nips-2011-Trace_Lasso%3A_a_trace_norm_regularization_for_correlated_designs.html">289 nips-2011-Trace Lasso: a trace norm regularization for correlated designs</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.215), (1, -0.091), (2, 0.016), (3, 0.148), (4, 0.077), (5, 0.017), (6, -0.094), (7, -0.143), (8, 0.044), (9, 0.14), (10, 0.207), (11, 0.018), (12, 0.035), (13, -0.04), (14, 0.15), (15, -0.187), (16, 0.108), (17, -0.0), (18, 0.02), (19, -0.046), (20, 0.196), (21, 0.142), (22, 0.125), (23, -0.192), (24, -0.008), (25, 0.006), (26, -0.026), (27, 0.064), (28, -0.059), (29, -0.036), (30, 0.037), (31, -0.008), (32, 0.071), (33, 0.016), (34, -0.056), (35, 0.075), (36, 0.004), (37, -0.001), (38, -0.008), (39, -0.021), (40, -0.061), (41, 0.013), (42, 0.053), (43, -0.012), (44, -0.066), (45, -0.045), (46, -0.07), (47, 0.091), (48, -0.043), (49, -0.039)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93738347 <a title="282-lsi-1" href="./nips-2011-The_Fast_Convergence_of_Boosting.html">282 nips-2011-The Fast Convergence of Boosting</a></p>
<p>2 0.85152698 <a title="282-lsi-2" href="./nips-2011-Algorithms_and_hardness_results_for_parallel_large_margin_learning.html">29 nips-2011-Algorithms and hardness results for parallel large margin learning</a></p>
<p>3 0.80748713 <a title="282-lsi-3" href="./nips-2011-Learning_large-margin_halfspaces_with_more_malicious_noise.html">153 nips-2011-Learning large-margin halfspaces with more malicious noise</a></p>
<p>4 0.73423034 <a title="282-lsi-4" href="./nips-2011-Multiclass_Boosting%3A_Theory_and_Algorithms.html">178 nips-2011-Multiclass Boosting: Theory and Algorithms</a></p>
<p>5 0.70512271 <a title="282-lsi-5" href="./nips-2011-Variance_Penalizing_AdaBoost.html">299 nips-2011-Variance Penalizing AdaBoost</a></p>
<p>6 0.50198227 <a title="282-lsi-6" href="./nips-2011-Boosting_with_Maximum_Adaptive_Sampling.html">49 nips-2011-Boosting with Maximum Adaptive Sampling</a></p>
<p>7 0.43156174 <a title="282-lsi-7" href="./nips-2011-Generalization_Bounds_and_Consistency_for_Latent_Structural_Probit_and_Ramp_Loss.html">103 nips-2011-Generalization Bounds and Consistency for Latent Structural Probit and Ramp Loss</a></p>
<p>8 0.41175506 <a title="282-lsi-8" href="./nips-2011-On_the_Universality_of_Online_Mirror_Descent.html">202 nips-2011-On the Universality of Online Mirror Descent</a></p>
<p>9 0.3890819 <a title="282-lsi-9" href="./nips-2011-Learning_with_the_weighted_trace-norm_under_arbitrary_sampling_distributions.html">159 nips-2011-Learning with the weighted trace-norm under arbitrary sampling distributions</a></p>
<p>10 0.3840048 <a title="282-lsi-10" href="./nips-2011-Adaptive_Hedge.html">25 nips-2011-Adaptive Hedge</a></p>
<p>11 0.3791441 <a title="282-lsi-11" href="./nips-2011-ShareBoost%3A_Efficient_multiclass_learning_with_feature_sharing.html">252 nips-2011-ShareBoost: Efficient multiclass learning with feature sharing</a></p>
<p>12 0.37729591 <a title="282-lsi-12" href="./nips-2011-On_the_accuracy_of_l1-filtering_of_signals_with_block-sparse_structure.html">203 nips-2011-On the accuracy of l1-filtering of signals with block-sparse structure</a></p>
<p>13 0.37447566 <a title="282-lsi-13" href="./nips-2011-Efficient_Learning_of_Generalized_Linear_and_Single_Index_Models_with_Isotonic_Regression.html">77 nips-2011-Efficient Learning of Generalized Linear and Single Index Models with Isotonic Regression</a></p>
<p>14 0.37299114 <a title="282-lsi-14" href="./nips-2011-k-NN_Regression_Adapts_to_Local_Intrinsic_Dimension.html">305 nips-2011-k-NN Regression Adapts to Local Intrinsic Dimension</a></p>
<p>15 0.35629985 <a title="282-lsi-15" href="./nips-2011-A_Collaborative_Mechanism_for_Crowdsourcing_Prediction_Problems.html">3 nips-2011-A Collaborative Mechanism for Crowdsourcing Prediction Problems</a></p>
<p>16 0.35252622 <a title="282-lsi-16" href="./nips-2011-Agnostic_Selective_Classification.html">28 nips-2011-Agnostic Selective Classification</a></p>
<p>17 0.34902433 <a title="282-lsi-17" href="./nips-2011-Composite_Multiclass_Losses.html">59 nips-2011-Composite Multiclass Losses</a></p>
<p>18 0.34860781 <a title="282-lsi-18" href="./nips-2011-Differentially_Private_M-Estimators.html">69 nips-2011-Differentially Private M-Estimators</a></p>
<p>19 0.34544241 <a title="282-lsi-19" href="./nips-2011-Lower_Bounds_for_Passive_and_Active_Learning.html">162 nips-2011-Lower Bounds for Passive and Active Learning</a></p>
<p>20 0.34380558 <a title="282-lsi-20" href="./nips-2011-Scalable_Training_of_Mixture_Models_via_Coresets.html">241 nips-2011-Scalable Training of Mixture Models via Coresets</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.063), (22, 0.067), (23, 0.257), (36, 0.058), (53, 0.015), (55, 0.168), (65, 0.074), (68, 0.201), (79, 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.82460773 <a title="282-lda-1" href="./nips-2011-The_Fast_Convergence_of_Boosting.html">282 nips-2011-The Fast Convergence of Boosting</a></p>
<p>2 0.79599077 <a title="282-lda-2" href="./nips-2011-Composite_Multiclass_Losses.html">59 nips-2011-Composite Multiclass Losses</a></p>
<p>3 0.74452943 <a title="282-lda-3" href="./nips-2011-Active_Ranking_using_Pairwise_Comparisons.html">22 nips-2011-Active Ranking using Pairwise Comparisons</a></p>
<p>4 0.74338424 <a title="282-lda-4" href="./nips-2011-Robust_Lasso_with_missing_and_grossly_corrupted_observations.html">239 nips-2011-Robust Lasso with missing and grossly corrupted observations</a></p>
<p>5 0.74175441 <a title="282-lda-5" href="./nips-2011-Evaluating_the_inverse_decision-making_approach_to_preference_learning.html">90 nips-2011-Evaluating the inverse decision-making approach to preference learning</a></p>
<p>6 0.74111909 <a title="282-lda-6" href="./nips-2011-A_blind_sparse_deconvolution_method_for_neural_spike_identification.html">13 nips-2011-A blind sparse deconvolution method for neural spike identification</a></p>
<p>7 0.740758 <a title="282-lda-7" href="./nips-2011-Sparse_Estimation_with_Structured_Dictionaries.html">259 nips-2011-Sparse Estimation with Structured Dictionaries</a></p>
<p>8 0.74051571 <a title="282-lda-8" href="./nips-2011-Matrix_Completion_for_Multi-label_Image_Classification.html">165 nips-2011-Matrix Completion for Multi-label Image Classification</a></p>
<p>9 0.74016958 <a title="282-lda-9" href="./nips-2011-Minimax_Localization_of_Structural_Information_in_Large_Noisy_Matrices.html">172 nips-2011-Minimax Localization of Structural Information in Large Noisy Matrices</a></p>
<p>10 0.74008918 <a title="282-lda-10" href="./nips-2011-Structured_sparse_coding_via_lateral_inhibition.html">276 nips-2011-Structured sparse coding via lateral inhibition</a></p>
<p>11 0.739627 <a title="282-lda-11" href="./nips-2011-Convergence_Rates_of_Inexact_Proximal-Gradient_Methods_for_Convex_Optimization.html">63 nips-2011-Convergence Rates of Inexact Proximal-Gradient Methods for Convex Optimization</a></p>
<p>12 0.73950177 <a title="282-lda-12" href="./nips-2011-Noise_Thresholds_for_Spectral_Clustering.html">186 nips-2011-Noise Thresholds for Spectral Clustering</a></p>
<p>13 0.73929745 <a title="282-lda-13" href="./nips-2011-Non-Asymptotic_Analysis_of_Stochastic_Approximation_Algorithms_for_Machine_Learning.html">187 nips-2011-Non-Asymptotic Analysis of Stochastic Approximation Algorithms for Machine Learning</a></p>
<p>14 0.73877597 <a title="282-lda-14" href="./nips-2011-Learning_a_Distance_Metric_from_a_Network.html">150 nips-2011-Learning a Distance Metric from a Network</a></p>
<p>15 0.73876143 <a title="282-lda-15" href="./nips-2011-Learning_Sparse_Representations_of_High_Dimensional_Data_on_Large_Scale_Dictionaries.html">149 nips-2011-Learning Sparse Representations of High Dimensional Data on Large Scale Dictionaries</a></p>
<p>16 0.73874331 <a title="282-lda-16" href="./nips-2011-Generalized_Lasso_based_Approximation_of_Sparse_Coding_for_Visual_Recognition.html">105 nips-2011-Generalized Lasso based Approximation of Sparse Coding for Visual Recognition</a></p>
<p>17 0.73824537 <a title="282-lda-17" href="./nips-2011-Metric_Learning_with_Multiple_Kernels.html">171 nips-2011-Metric Learning with Multiple Kernels</a></p>
<p>18 0.73796093 <a title="282-lda-18" href="./nips-2011-ShareBoost%3A_Efficient_multiclass_learning_with_feature_sharing.html">252 nips-2011-ShareBoost: Efficient multiclass learning with feature sharing</a></p>
<p>19 0.73773444 <a title="282-lda-19" href="./nips-2011-Learning_Anchor_Planes_for_Classification.html">143 nips-2011-Learning Anchor Planes for Classification</a></p>
<p>20 0.7373482 <a title="282-lda-20" href="./nips-2011-Sparse_Bayesian_Multi-Task_Learning.html">258 nips-2011-Sparse Bayesian Multi-Task Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
