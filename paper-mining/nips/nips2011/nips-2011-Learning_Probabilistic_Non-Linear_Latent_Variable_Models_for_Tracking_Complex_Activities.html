<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>148 nips-2011-Learning Probabilistic Non-Linear Latent Variable Models for Tracking Complex Activities</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-148" href="#">nips2011-148</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>148 nips-2011-Learning Probabilistic Non-Linear Latent Variable Models for Tracking Complex Activities</h1>
<br/><p>Source: <a title="nips-2011-148-pdf" href="http://papers.nips.cc/paper/4352-learning-probabilistic-non-linear-latent-variable-models-for-tracking-complex-activities.pdf">pdf</a></p><p>Author: Angela Yao, Juergen Gall, Luc V. Gool, Raquel Urtasun</p><p>Abstract: A common approach for handling the complexity and inherent ambiguities of 3D human pose estimation is to use pose priors learned from training data. Existing approaches however, are either too simplistic (linear), too complex to learn, or can only learn latent spaces from “simple data”, i.e., single activities such as walking or running. In this paper, we present an efﬁcient stochastic gradient descent algorithm that is able to learn probabilistic non-linear latent spaces composed of multiple activities. Furthermore, we derive an incremental algorithm for the online setting which can update the latent space without extensive relearning. We demonstrate the effectiveness of our approach on the task of monocular and multi-view tracking and show that our approach outperforms the state-of-the-art. 1</p><p>Reference: <a title="nips-2011-148-reference" href="../nips2011_reference/nips-2011-Learning_Probabilistic_Non-Linear_Latent_Variable_Models_for_Tracking_Complex_Activities_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract A common approach for handling the complexity and inherent ambiguities of 3D human pose estimation is to use pose priors learned from training data. [sent-5, score-0.347]
</p><p>2 Existing approaches however, are either too simplistic (linear), too complex to learn, or can only learn latent spaces from “simple data”, i. [sent-6, score-0.285]
</p><p>3 In this paper, we present an efﬁcient stochastic gradient descent algorithm that is able to learn probabilistic non-linear latent spaces composed of multiple activities. [sent-9, score-0.534]
</p><p>4 Furthermore, we derive an incremental algorithm for the online setting which can update the latent space without extensive relearning. [sent-10, score-0.316]
</p><p>5 We demonstrate the effectiveness of our approach on the task of monocular and multi-view tracking and show that our approach outperforms the state-of-the-art. [sent-11, score-0.391]
</p><p>6 1  Introduction  Tracking human 3D articulated motions from video sequences is well known to be a challenging machine vision problem. [sent-12, score-0.198]
</p><p>7 Estimating the human body’s 3D location and orientation of the joints is notoriously difﬁcult because it is a high-dimensional problem and is riddled with ambiguities coming from noise, monocular imagery and occlusions. [sent-13, score-0.189]
</p><p>8 Priors generated from non-linear dimensionality reduction techniques such as Isomap [23] and LLE [18] have also been used for tracking [5, 8]. [sent-18, score-0.293]
</p><p>9 Moreover, LLE and Isomap provide neither a probability distribution over the space of possible poses nor a mapping from the latent space to the high dimensional space. [sent-22, score-0.264]
</p><p>10 While such a distribution and or mapping can be learned post hoc, learning them separately from the latent space typically results in suboptimal solutions. [sent-23, score-0.249]
</p><p>11 probabilistic PCA), have the advantage of taking uncertainties into account when learning latent representations. [sent-26, score-0.21]
</p><p>12 [22] introduced the use of Conditional Restricted Boltzmann Machines (CRBM) and implicit mixtures of CRBM (imCRBM), which are composed of large collections of discrete latent variables. [sent-28, score-0.181]
</p><p>13 A more commonly used latent variable model is the Gaussian Process Latent Variable Model (GPLVM) [9] which has been applied to animation [27] and tracking [26, 25, 6, 7]. [sent-30, score-0.493]
</p><p>14 While the GPLVM is very successful at modeling small training sets with single activities, it often struggles to learn latent spaces from larger datasets, especially those with multiple activities. [sent-31, score-0.305]
</p><p>15 ch/yaoa  1  PCA  GPLVM  stochastic GPLVM  Basketball Signals  Exercise Stretching  Jumping  Walking  Distance Matrix  Figure 1: Representative poses, data (Euclidean) distance matrices and learned latent spaces from walking, jumping, exercise stretching and basketball signal sequences. [sent-37, score-0.683]
</p><p>16 However, coordinating the different components of the mixture models requires special care to ensure that they are aligned in the latent space [19], thereby complicating the learning process. [sent-46, score-0.181]
</p><p>17 A good prior model for tracking should be accurate, expressive enough to capture a wide range of human poses, and easy and tractable for both learning and inference. [sent-51, score-0.344]
</p><p>18 Towards this end, we propose a stochastic gradient descent algorithm for the GPLVM which can learn latent spaces from random initializations. [sent-54, score-0.505]
</p><p>19 Based on these two works, we propose a similar strategy to approximate the gradient computation within each step of the stochastic gradient descent algorithm. [sent-58, score-0.318]
</p><p>20 Furthermore, we propose an online algorithm that can effectively learn latent spaces incrementally without extensive relearning. [sent-60, score-0.31]
</p><p>21 We demonstrate the effectiveness of our approach on the task of monocular and multi-view tracking and show that our approach outperforms the state-of-the-art on the standard benchmark HumanEva [21]. [sent-61, score-0.391]
</p><p>22 1  GPLVM Review  The GPLVM assumes that the observed data has been generated by some unobserved latent random variables. [sent-65, score-0.181]
</p><p>23 More formally, let Y = [y1 , · · · , yN ]T be the set of observations yi ∈ D , and X = [x1 , · · · , xN ]T be the set of latent variables xi ∈ Q , with Q D. [sent-66, score-0.181]
</p><p>24 The GPLVM relates the latent variables and the observations via the probabilistic mapping y (d) = f (x) + η, with η being i. [sent-67, score-0.231]
</p><p>25 β2 β4 The GPLVM is usually learned by maximum likelihood estimation of the latent coordinates X and the kernel hyperparameters β = {β1 , · · · , β4 }. [sent-76, score-0.228]
</p><p>26 More importantly, as the negative log likelihood L is highly non-convex, especially with respect to X, standard gradient descent approaches tend to get stuck in local minima, and rely on having good initializations for success. [sent-83, score-0.158]
</p><p>27 We now demonstrate how a stochastic gradient descent approach can be used to reduce computational complexity as well as decrease the chances of getting trapped in local minima. [sent-84, score-0.245]
</p><p>28 2  Stochastic Gradient Descent  In standard gradient descent, all points are taken into account at the same time when computing the gradient; stochastic gradient descent approaches, on the other hand, approximate the gradient at each point individually. [sent-88, score-0.424]
</p><p>29 We propose, however, to approximate the gradient computation within each step of the stochastic gradient descent algorithm. [sent-92, score-0.318]
</p><p>30 Therefore, the gradient of L can be estimated locally for some neighborhood of points XR , centered at a reference point xr , rather than over all of X. [sent-93, score-0.363]
</p><p>31 , 3  Algorithm 2: Incremental stochastic GPLVM for t = 1 : T1 Learn Xorig and β orig as per Algorithm 1. [sent-97, score-0.151]
</p><p>32 Set β = β orig Group data: Y = [Yorig , Yincr ] X = [Xorig , Xincr ] for t = T1 + 1 : T2 randomly select xr ∈ Xincr ﬁnd R neighbors around xr : XR = X ∈ R Compute ∂Lincr and ∂Lincr (see Eq. [sent-99, score-0.48]
</p><p>33 (3)) ∂ βR Update X and β: ∂L ∆Xt = µX · ∆Xt−1 + ηX · ∂XR Xt ← Xt−1 + ∆Xt ∆β t = µβ · ∆β t−1 + ηβ · ∂L ∂ βR β t ← β t−1 + ∆β t end  Figure 2: Stochastic gradient descent and incremental learning for the GPLVM; µ(·) is a momentum parameter and η(·) is the learning rate. [sent-101, score-0.222]
</p><p>34 We employ a random strategy for choosing the reference point xr . [sent-104, score-0.203]
</p><p>35 The neighborhood R can be determined by any type of distance measure, such as Euclidean distance in the latent space and/or data space, or temporal neighbors when working with time series. [sent-105, score-0.266]
</p><p>36 More critical than the speciﬁc type of distance measure, however, is allowing sufﬁcient coverage of the latent space so that each neighborhood is not restricted too locally. [sent-106, score-0.235]
</p><p>37 The use of stochastic gradient descent has several desirable traits that correct for the aforementioned drawbacks of GPLVMs. [sent-108, score-0.245]
</p><p>38 First, computational complexity is greatly reduced, making it feasible to learn latent spaces with much larger amounts of data. [sent-109, score-0.26]
</p><p>39 An algorithmic summary of stochastic gradient descent learning for GPLVMs is given in Fig. [sent-111, score-0.245]
</p><p>40 3  Incremental Learning  In this section, we derive an incremental learning algorithm based on the stochastic gradient descent approach of the previous section. [sent-114, score-0.33]
</p><p>41 More formally, let Yorig be the initial training data, and Xorig and β orig be a model learned from Yorig using stochastic GPLVM. [sent-116, score-0.243]
</p><p>42 Let Y = [Yorig , Yincr ] ∈ R(N +M )×D be the set of training points containing both the already trained data Yorig , and the new incoming data Yincr , and let X=[Xorig , Xincr ] ∈ R(N +M )×Q be the corresponding latent coordinates, where M is the number of newly added training ˆ examples. [sent-118, score-0.304]
</p><p>43 Let Xorig be the estimate of the latent coordinates that has already been learned. [sent-119, score-0.181]
</p><p>44 1%  stochastic GPLVM  Figure 3: Within- and cross-subject 3D tracking errors for each type of activity sequence with respect to amount of additive noise for different number of particles, where error bars represent the standard deviation from repetitions runs. [sent-131, score-0.493]
</p><p>45 ∂XR ∂XR N ∂XR  (6)  We employ a stochastic gradient descent approach for our incremental learning, where the points are sampled randomly from Xincr . [sent-135, score-0.363]
</p><p>46 Note that while xr is only sampled from Xincr in the subsequent learning step, this does not exclude points in Xorig from being a part of the neighbourhood R, and thus from being updated. [sent-136, score-0.236]
</p><p>47 We have chosen a nearest neighbor approach by comparing Yincr to Yorig for estimating an initial Xincr , though other possibilities include performing a grid search in the latent space and selecting locations with the highest global log-likelihood (Eq. [sent-137, score-0.202]
</p><p>48 4  Tracking Framework  During training, a latent variable model M is learned from YM , where YM are relative joint locations with respect to a root node. [sent-142, score-0.247]
</p><p>49 During inference, tracking is performed in the latent space using a particle ﬁlter. [sent-144, score-0.534]
</p><p>50 The corresponding pose is computed by projecting back to the data space via the Gaussian process mapping learned in the GPLVM. [sent-145, score-0.161]
</p><p>51 5  GPLVM  stochastic GPLVM  incremental stochastic GPLVM  GPLVM stochastic GPLVM incremental stochastic GPLVM  250 200 150 100 50 0%  (a) manifolds  0. [sent-147, score-0.653]
</p><p>52 We model the state s at time t as st = (xt , gt , rt ) where xt denotes position in the latent space, while gt and rt are the global position and rotation of the root node. [sent-150, score-0.39]
</p><p>53 Particles are initialized in the latent space by a nearest neighbor search between the observed 2D image pose in the ﬁrst frame of the sequence and the projected 2D poses of YM . [sent-151, score-0.437]
</p><p>54 Particles are then propagated from frame to frame using a ﬁrst-order Markov model ˙t xi = xi + xi , t t−1  i i ˙i gt = gt−1 + gt ,  ˙t ri = ri + ri . [sent-152, score-0.334]
</p><p>55 t t−1  (7)  ˙ We approximate the derivative xi with the difference between temporally sequential points of the ˙ ˙ nearest neighbors in XM , while gi and ri are drawn from individual Gaussians with means and ˆ standard deviations estimated from the training data. [sent-153, score-0.152]
</p><p>56 3  Experimental Evaluation  We demonstrate the effectiveness of our model when applied to tracking in both monocular and multi-view scenarios. [sent-156, score-0.367]
</p><p>57 In all cases, the latent models were learned with µX = 0. [sent-157, score-0.228]
</p><p>58 To further smooth the learned models, we incorporate a Gaussian Process prior over the dynamics of the training data in the latent space [27] for the GPLVM and the stochastic GPLVM. [sent-160, score-0.381]
</p><p>59 1  Monocular Tracking  We compare in the monocular setting the use of PCA, regular GPLVM and our stochastic GPLVM to learn latent spaces from motion capture sequences (from the CMU Motion Capture Database [3]). [sent-163, score-0.612]
</p><p>60 We chose simple single-activity sequences, such as walking (3 subjects, 18 sequences) and jumping (2 subjects, 8 sequences), as well as complex multi-activity sequences, such as stretching exercises (2 subjects, 6 sequences) and basketball refereeing signals (7 subjects, 13 sequences). [sent-164, score-0.437]
</p><p>61 The stretching exercise and basketball signal sequences were cut to each contain four types of activities. [sent-165, score-0.377]
</p><p>62 We then recover the 3D locations of each joint from the noisy images by tracking with the particle ﬁlter described in the previous section. [sent-167, score-0.353]
</p><p>63 Examples of learned latent spaces for each type of sequence (i. [sent-168, score-0.296]
</p><p>64 For a sequence of 800 training examples, the stochastic GPLVM takes only 27s to learn (neighborhood of 100 points, 2500 iterations); in comparison, the regular GPLVM takes 2560s for 312 iterations, while with FITC approximations [10] takes on average 1700s (100 active points, 2500 iterations)2 . [sent-174, score-0.244]
</p><p>65 1, the manifolds learned with stochastic GPLVM have smoother trajectories than those learned from PCA and GPLVM, with better separation between the activities in the multi-activity sequences. [sent-176, score-0.342]
</p><p>66 We evaluate the effectiveness of the learned latent pose models for tracking by comparing the average tracking error per joint per frame between PCA, GPLVM and stochastic GPLVM in two sets of experiments. [sent-177, score-1.074]
</p><p>67 In the ﬁrst, training and test sequences are performed by the same subject; in the second, to test generalization properties of the different latent spaces, we train and test on different subjects. [sent-178, score-0.303]
</p><p>68 3 depicts 3D tracking error as a function of the amount of Gaussian noise for different number of particles employed in the particle ﬁlter for the within- and cross-subject experiments. [sent-184, score-0.463]
</p><p>69 As expected, tracking error is lower within-subject than cross-subject for all types of latent models. [sent-185, score-0.474]
</p><p>70 For the simple activities such as walking and jumping, GPLVM generally outperforms PCA, but for the complex activities, it performs only comparably or worse than PCA (with the exception of cross-subject basketball signals). [sent-186, score-0.364]
</p><p>71 Our stochastic GPLVM, on the other hand, consistently outperforms PCA and matches or outperforms the regular GPLVM in all experimental conditions, with signiﬁcantly better performance in the complex, multi-activity sequences. [sent-187, score-0.194]
</p><p>72 2  Online Tracking  We took two stretching exercise sequences with three different activities from the same subject and apply the online learning algorithm (see Sec. [sent-190, score-0.395]
</p><p>73 We consider each activity as a new batch of data, and learn the latent space on the ﬁrst sequence and then track on the second and vice versa. [sent-193, score-0.279]
</p><p>74 We ﬁnd the online algorithm less accurate for tracking than the stochastic GPLVM learned with all data. [sent-194, score-0.477]
</p><p>75 This is expected since the latent space is biased towards the initial set of activities. [sent-195, score-0.181]
</p><p>76 We note, however, that the incremental stochastic GPLVM still outperforms the regular GPLVM, as illustrated in Fig. [sent-196, score-0.255]
</p><p>77 3  Multi-view Tracking on HumanEva  We also evaluate our learning algorithm on the HumanEva benchmark [21] on the activities walking and boxing. [sent-201, score-0.215]
</p><p>78 For timing purposes, we take here a ﬁxed number of iterations for the stochastic method and the FITC approximation and the “equivalent” for the regular GPLVM, i. [sent-206, score-0.146]
</p><p>79 4  Table 1: Comparison of 3D tracking errors (mm) on the entire walking validation sequence with subject-speciﬁc models, where ± indicates standard deviation over runs, except for [13], who reports tracking results for 200 frames of the sequences, with standard deviation over frames. [sent-265, score-0.823]
</p><p>80 3  Table 2: Comparison of 3D tracking errors (mm) on boxing validation sequence for S1, where ± indicates standard deviation over runs. [sent-278, score-0.424]
</p><p>81 HumanEva-I Walking: As per [22, 28, 13], we track the walking validation sequences of subjects S1, S2, and S3. [sent-281, score-0.263]
</p><p>82 The latent variable models are learned on the training sequences, being either subjectspeciﬁc or with all three subjects combined. [sent-282, score-0.333]
</p><p>83 Subject-speciﬁc models have ∼1200-2000 training examples each, for which we used a neighborhood of 60 points, while the combined model has ∼4000 training examples with a neighborhood of 150 points. [sent-283, score-0.198]
</p><p>84 3D tracking errors averaged over the 15 joints as speciﬁed in [21] and over all frames in the full sequence are depicted in Table1. [sent-284, score-0.399]
</p><p>85 These results are remarkable, given that we use only a simple ﬁrst-order Markov model for estimating dynamics, and our success can only be attributed to the latent model’s accuracy in encoding the body poses from the training data. [sent-288, score-0.324]
</p><p>86 HumanEva-I boxing: We also track the validation sequence of S1 for boxing to assess the ability of the stochastic GPLVM for learning acyclic motions. [sent-289, score-0.213]
</p><p>87 3D tracking errors are shown in Table 2 and are compared with [14, 13, 22]. [sent-290, score-0.316]
</p><p>88 Our proposed stochastic GPLVM fulﬁlls all these criteria - it effectively learns latent spaces of complex multi-activity datasets in a computationally efﬁcient manner. [sent-293, score-0.361]
</p><p>89 When applied to tracking, our model outperforms state-of-the-art on the HumanEva benchmark, despite the use of very few particles and only a simple ﬁrst-order Markov model for handling dynamics. [sent-294, score-0.156]
</p><p>90 In addition, we have also derived a novel approach for learning latent spaces incrementally. [sent-295, score-0.228]
</p><p>91 One of the great criticisms of current latent variable models is that they cannot handle new training examples without relearning; given the sometimes cumbersome learning process, this is not always feasible. [sent-296, score-0.245]
</p><p>92 Switching gaussian process dynamic models for simultaneous composite motion tracking and recognition. [sent-312, score-0.405]
</p><p>93 Real-time body tracking using a gaussian process latent variable model. [sent-342, score-0.586]
</p><p>94 Probabilistic non-linear principal component analysis with gaussian process latent variable models. [sent-352, score-0.257]
</p><p>95 Learning for larger datasets with the gaussian process latent variable model. [sent-356, score-0.257]
</p><p>96 3d human motion tracking with a coordinated mixture of factor analyzers. [sent-376, score-0.399]
</p><p>97 Stochastic tracking of 3d human ﬁgures using 2d image motion. [sent-421, score-0.344]
</p><p>98 Humaneva: Synchronized video and motion capture dataset and baseline algorithm for evaluation of articulated human motion. [sent-427, score-0.155]
</p><p>99 Dynamical binary latent variable models for 3d human pose tracking supplementary material. [sent-434, score-0.61]
</p><p>100 Learning motion correlation for tracking articulated human body with a raoblackwellised particle ﬁlter. [sent-469, score-0.544]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('gplvm', 0.693), ('tracking', 0.293), ('xr', 0.203), ('latent', 0.181), ('xorig', 0.162), ('walking', 0.126), ('lincr', 0.113), ('xincr', 0.113), ('yorig', 0.113), ('particles', 0.11), ('stochastic', 0.108), ('basketball', 0.1), ('exercise', 0.1), ('stretching', 0.1), ('humaneva', 0.097), ('yincr', 0.097), ('activities', 0.089), ('frame', 0.086), ('jumping', 0.086), ('incremental', 0.085), ('crbm', 0.081), ('sequences', 0.077), ('monocular', 0.074), ('gradient', 0.073), ('mm', 0.072), ('pose', 0.066), ('urtasun', 0.065), ('boxing', 0.065), ('descent', 0.064), ('poses', 0.062), ('particle', 0.06), ('pca', 0.059), ('xt', 0.057), ('fleet', 0.057), ('motion', 0.055), ('neighborhood', 0.054), ('xm', 0.052), ('manifolds', 0.051), ('human', 0.051), ('articulated', 0.049), ('gall', 0.049), ('imcrbm', 0.049), ('yyt', 0.049), ('gt', 0.048), ('learned', 0.047), ('spaces', 0.047), ('training', 0.045), ('orig', 0.043), ('ym', 0.043), ('subjects', 0.041), ('joints', 0.039), ('yr', 0.039), ('regular', 0.038), ('body', 0.036), ('zurich', 0.033), ('points', 0.033), ('manifold', 0.032), ('fitc', 0.032), ('relearning', 0.032), ('sigal', 0.032), ('tian', 0.032), ('learn', 0.032), ('iccv', 0.031), ('eth', 0.031), ('switching', 0.031), ('neighbors', 0.031), ('ijcv', 0.03), ('gaussian', 0.03), ('online', 0.029), ('probabilistic', 0.029), ('mocap', 0.028), ('position', 0.028), ('dynamical', 0.028), ('process', 0.027), ('activity', 0.026), ('complex', 0.025), ('priors', 0.025), ('isomap', 0.025), ('ambiguities', 0.025), ('outperforms', 0.024), ('cvpr', 0.023), ('cmu', 0.023), ('lle', 0.023), ('errors', 0.023), ('frames', 0.023), ('ri', 0.022), ('tracked', 0.022), ('deviation', 0.022), ('yt', 0.022), ('handling', 0.022), ('motions', 0.021), ('nearest', 0.021), ('mapping', 0.021), ('sequence', 0.021), ('initializations', 0.021), ('kr', 0.021), ('extensive', 0.021), ('track', 0.019), ('variable', 0.019), ('yao', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="148-tfidf-1" href="./nips-2011-Learning_Probabilistic_Non-Linear_Latent_Variable_Models_for_Tracking_Complex_Activities.html">148 nips-2011-Learning Probabilistic Non-Linear Latent Variable Models for Tracking Complex Activities</a></p>
<p>Author: Angela Yao, Juergen Gall, Luc V. Gool, Raquel Urtasun</p><p>Abstract: A common approach for handling the complexity and inherent ambiguities of 3D human pose estimation is to use pose priors learned from training data. Existing approaches however, are either too simplistic (linear), too complex to learn, or can only learn latent spaces from “simple data”, i.e., single activities such as walking or running. In this paper, we present an efﬁcient stochastic gradient descent algorithm that is able to learn probabilistic non-linear latent spaces composed of multiple activities. Furthermore, we derive an incremental algorithm for the online setting which can update the latent space without extensive relearning. We demonstrate the effectiveness of our approach on the task of monocular and multi-view tracking and show that our approach outperforms the state-of-the-art. 1</p><p>2 0.15661384 <a title="148-tfidf-2" href="./nips-2011-Variational_Gaussian_Process_Dynamical_Systems.html">301 nips-2011-Variational Gaussian Process Dynamical Systems</a></p>
<p>Author: Neil D. Lawrence, Michalis K. Titsias, Andreas Damianou</p><p>Abstract: High dimensional time series are endemic in applications of machine learning such as robotics (sensor data), computational biology (gene expression data), vision (video sequences) and graphics (motion capture data). Practical nonlinear probabilistic approaches to this data are required. In this paper we introduce the variational Gaussian process dynamical system. Our work builds on recent variational approximations for Gaussian process latent variable models to allow for nonlinear dimensionality reduction simultaneously with learning a dynamical prior in the latent space. The approach also allows for the appropriate dimensionality of the latent space to be automatically determined. We demonstrate the model on a human motion capture data set and a series of high resolution video sequences. 1</p><p>3 0.13648948 <a title="148-tfidf-3" href="./nips-2011-Structured_Learning_for_Cell_Tracking.html">275 nips-2011-Structured Learning for Cell Tracking</a></p>
<p>Author: Xinghua Lou, Fred A. Hamprecht</p><p>Abstract: We study the problem of learning to track a large quantity of homogeneous objects such as cell tracking in cell culture study and developmental biology. Reliable cell tracking in time-lapse microscopic image sequences is important for modern biomedical research. Existing cell tracking methods are usually kept simple and use only a small number of features to allow for manual parameter tweaking or grid search. We propose a structured learning approach that allows to learn optimum parameters automatically from a training set. This allows for the use of a richer set of features which in turn affords improved tracking compared to recently reported methods on two public benchmark sequences. 1</p><p>4 0.10552841 <a title="148-tfidf-4" href="./nips-2011-Multiple_Instance_Filtering.html">180 nips-2011-Multiple Instance Filtering</a></p>
<p>Author: Kamil A. Wnuk, Stefano Soatto</p><p>Abstract: We propose a robust ﬁltering approach based on semi-supervised and multiple instance learning (MIL). We assume that the posterior density would be unimodal if not for the eﬀect of outliers that we do not wish to explicitly model. Therefore, we seek for a point estimate at the outset, rather than a generic approximation of the entire posterior. Our approach can be thought of as a combination of standard ﬁnite-dimensional ﬁltering (Extended Kalman Filter, or Unscented Filter) with multiple instance learning, whereby the initial condition comes with a putative set of inlier measurements. We show how both the state (regression) and the inlier set (classiﬁcation) can be estimated iteratively and causally by processing only the current measurement. We illustrate our approach on visual tracking problems whereby the object of interest (target) moves and evolves as a result of occlusions and deformations, and partial knowledge of the target is given in the form of a bounding box (training set). 1</p><p>5 0.10093529 <a title="148-tfidf-5" href="./nips-2011-Kernel_Embeddings_of_Latent_Tree_Graphical_Models.html">140 nips-2011-Kernel Embeddings of Latent Tree Graphical Models</a></p>
<p>Author: Le Song, Eric P. Xing, Ankur P. Parikh</p><p>Abstract: Latent tree graphical models are natural tools for expressing long range and hierarchical dependencies among many variables which are common in computer vision, bioinformatics and natural language processing problems. However, existing models are largely restricted to discrete and Gaussian variables due to computational constraints; furthermore, algorithms for estimating the latent tree structure and learning the model parameters are largely restricted to heuristic local search. We present a method based on kernel embeddings of distributions for latent tree graphical models with continuous and non-Gaussian variables. Our method can recover the latent tree structures with provable guarantees and perform local-minimum free parameter learning and efﬁcient inference. Experiments on simulated and real data show the advantage of our proposed approach. 1</p><p>6 0.094904855 <a title="148-tfidf-6" href="./nips-2011-Video_Annotation_and_Tracking_with_Active_Learning.html">303 nips-2011-Video Annotation and Tracking with Active Learning</a></p>
<p>7 0.087784544 <a title="148-tfidf-7" href="./nips-2011-On_Tracking_The_Partition_Function.html">197 nips-2011-On Tracking The Partition Function</a></p>
<p>8 0.084984466 <a title="148-tfidf-8" href="./nips-2011-On_Learning_Discrete_Graphical_Models_using_Greedy_Methods.html">195 nips-2011-On Learning Discrete Graphical Models using Greedy Methods</a></p>
<p>9 0.074520677 <a title="148-tfidf-9" href="./nips-2011-Infinite_Latent_SVM_for_Classification_and_Multi-task_Learning.html">134 nips-2011-Infinite Latent SVM for Classification and Multi-task Learning</a></p>
<p>10 0.07004384 <a title="148-tfidf-10" href="./nips-2011-Efficient_inference_in_matrix-variate_Gaussian_models_with_%5Ciid_observation_noise.html">83 nips-2011-Efficient inference in matrix-variate Gaussian models with \iid observation noise</a></p>
<p>11 0.06667763 <a title="148-tfidf-11" href="./nips-2011-Joint_3D_Estimation_of_Objects_and_Scene_Layout.html">138 nips-2011-Joint 3D Estimation of Objects and Scene Layout</a></p>
<p>12 0.066191733 <a title="148-tfidf-12" href="./nips-2011-An_ideal_observer_model_for_identifying_the_reference_frame_of_objects.html">35 nips-2011-An ideal observer model for identifying the reference frame of objects</a></p>
<p>13 0.065786168 <a title="148-tfidf-13" href="./nips-2011-Learning_person-object_interactions_for_action_recognition_in_still_images.html">154 nips-2011-Learning person-object interactions for action recognition in still images</a></p>
<p>14 0.062747106 <a title="148-tfidf-14" href="./nips-2011-Dynamical_segmentation_of_single_trials_from_population_neural_data.html">75 nips-2011-Dynamical segmentation of single trials from population neural data</a></p>
<p>15 0.061442051 <a title="148-tfidf-15" href="./nips-2011-Facial_Expression_Transfer_with_Input-Output_Temporal_Restricted_Boltzmann_Machines.html">94 nips-2011-Facial Expression Transfer with Input-Output Temporal Restricted Boltzmann Machines</a></p>
<p>16 0.059168346 <a title="148-tfidf-16" href="./nips-2011-Maximal_Cliques_that_Satisfy_Hard_Constraints_with_Application_to_Deformable_Object_Model_Learning.html">166 nips-2011-Maximal Cliques that Satisfy Hard Constraints with Application to Deformable Object Model Learning</a></p>
<p>17 0.058891181 <a title="148-tfidf-17" href="./nips-2011-Sparse_Manifold_Clustering_and_Embedding.html">263 nips-2011-Sparse Manifold Clustering and Embedding</a></p>
<p>18 0.055645641 <a title="148-tfidf-18" href="./nips-2011-Dimensionality_Reduction_Using_the_Sparse_Linear_Model.html">70 nips-2011-Dimensionality Reduction Using the Sparse Linear Model</a></p>
<p>19 0.055515785 <a title="148-tfidf-19" href="./nips-2011-Nonstandard_Interpretations_of_Probabilistic_Programs_for_Efficient_Inference.html">192 nips-2011-Nonstandard Interpretations of Probabilistic Programs for Efficient Inference</a></p>
<p>20 0.052109815 <a title="148-tfidf-20" href="./nips-2011-Variational_Learning_for_Recurrent_Spiking_Networks.html">302 nips-2011-Variational Learning for Recurrent Spiking Networks</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.158), (1, 0.018), (2, 0.003), (3, 0.003), (4, -0.002), (5, -0.024), (6, 0.06), (7, -0.07), (8, 0.078), (9, 0.07), (10, 0.044), (11, -0.123), (12, -0.006), (13, -0.009), (14, 0.028), (15, -0.014), (16, -0.093), (17, 0.133), (18, -0.077), (19, 0.046), (20, -0.019), (21, 0.023), (22, -0.018), (23, 0.068), (24, -0.035), (25, -0.145), (26, -0.091), (27, 0.092), (28, -0.068), (29, 0.074), (30, 0.004), (31, -0.076), (32, 0.082), (33, -0.078), (34, -0.052), (35, 0.037), (36, -0.006), (37, -0.099), (38, 0.113), (39, -0.081), (40, 0.058), (41, 0.058), (42, -0.034), (43, 0.112), (44, 0.052), (45, -0.107), (46, 0.036), (47, -0.078), (48, -0.033), (49, 0.009)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93313509 <a title="148-lsi-1" href="./nips-2011-Learning_Probabilistic_Non-Linear_Latent_Variable_Models_for_Tracking_Complex_Activities.html">148 nips-2011-Learning Probabilistic Non-Linear Latent Variable Models for Tracking Complex Activities</a></p>
<p>Author: Angela Yao, Juergen Gall, Luc V. Gool, Raquel Urtasun</p><p>Abstract: A common approach for handling the complexity and inherent ambiguities of 3D human pose estimation is to use pose priors learned from training data. Existing approaches however, are either too simplistic (linear), too complex to learn, or can only learn latent spaces from “simple data”, i.e., single activities such as walking or running. In this paper, we present an efﬁcient stochastic gradient descent algorithm that is able to learn probabilistic non-linear latent spaces composed of multiple activities. Furthermore, we derive an incremental algorithm for the online setting which can update the latent space without extensive relearning. We demonstrate the effectiveness of our approach on the task of monocular and multi-view tracking and show that our approach outperforms the state-of-the-art. 1</p><p>2 0.604487 <a title="148-lsi-2" href="./nips-2011-Variational_Gaussian_Process_Dynamical_Systems.html">301 nips-2011-Variational Gaussian Process Dynamical Systems</a></p>
<p>Author: Neil D. Lawrence, Michalis K. Titsias, Andreas Damianou</p><p>Abstract: High dimensional time series are endemic in applications of machine learning such as robotics (sensor data), computational biology (gene expression data), vision (video sequences) and graphics (motion capture data). Practical nonlinear probabilistic approaches to this data are required. In this paper we introduce the variational Gaussian process dynamical system. Our work builds on recent variational approximations for Gaussian process latent variable models to allow for nonlinear dimensionality reduction simultaneously with learning a dynamical prior in the latent space. The approach also allows for the appropriate dimensionality of the latent space to be automatically determined. We demonstrate the model on a human motion capture data set and a series of high resolution video sequences. 1</p><p>3 0.59282118 <a title="148-lsi-3" href="./nips-2011-Structured_Learning_for_Cell_Tracking.html">275 nips-2011-Structured Learning for Cell Tracking</a></p>
<p>Author: Xinghua Lou, Fred A. Hamprecht</p><p>Abstract: We study the problem of learning to track a large quantity of homogeneous objects such as cell tracking in cell culture study and developmental biology. Reliable cell tracking in time-lapse microscopic image sequences is important for modern biomedical research. Existing cell tracking methods are usually kept simple and use only a small number of features to allow for manual parameter tweaking or grid search. We propose a structured learning approach that allows to learn optimum parameters automatically from a training set. This allows for the use of a richer set of features which in turn affords improved tracking compared to recently reported methods on two public benchmark sequences. 1</p><p>4 0.56809127 <a title="148-lsi-4" href="./nips-2011-Video_Annotation_and_Tracking_with_Active_Learning.html">303 nips-2011-Video Annotation and Tracking with Active Learning</a></p>
<p>Author: Carl Vondrick, Deva Ramanan</p><p>Abstract: We introduce a novel active learning framework for video annotation. By judiciously choosing which frames a user should annotate, we can obtain highly accurate tracks with minimal user effort. We cast this problem as one of active learning, and show that we can obtain excellent performance by querying frames that, if annotated, would produce a large expected change in the estimated object track. We implement a constrained tracker and compute the expected change for putative annotations with efﬁcient dynamic programming algorithms. We demonstrate our framework on four datasets, including two benchmark datasets constructed with key frame annotations obtained by Amazon Mechanical Turk. Our results indicate that we could obtain equivalent labels for a small fraction of the original cost. 1</p><p>5 0.50231749 <a title="148-lsi-5" href="./nips-2011-Multiple_Instance_Filtering.html">180 nips-2011-Multiple Instance Filtering</a></p>
<p>Author: Kamil A. Wnuk, Stefano Soatto</p><p>Abstract: We propose a robust ﬁltering approach based on semi-supervised and multiple instance learning (MIL). We assume that the posterior density would be unimodal if not for the eﬀect of outliers that we do not wish to explicitly model. Therefore, we seek for a point estimate at the outset, rather than a generic approximation of the entire posterior. Our approach can be thought of as a combination of standard ﬁnite-dimensional ﬁltering (Extended Kalman Filter, or Unscented Filter) with multiple instance learning, whereby the initial condition comes with a putative set of inlier measurements. We show how both the state (regression) and the inlier set (classiﬁcation) can be estimated iteratively and causally by processing only the current measurement. We illustrate our approach on visual tracking problems whereby the object of interest (target) moves and evolves as a result of occlusions and deformations, and partial knowledge of the target is given in the form of a bounding box (training set). 1</p><p>6 0.4972893 <a title="148-lsi-6" href="./nips-2011-Nonstandard_Interpretations_of_Probabilistic_Programs_for_Efficient_Inference.html">192 nips-2011-Nonstandard Interpretations of Probabilistic Programs for Efficient Inference</a></p>
<p>7 0.4751496 <a title="148-lsi-7" href="./nips-2011-On_Tracking_The_Partition_Function.html">197 nips-2011-On Tracking The Partition Function</a></p>
<p>8 0.46910265 <a title="148-lsi-8" href="./nips-2011-Dynamical_segmentation_of_single_trials_from_population_neural_data.html">75 nips-2011-Dynamical segmentation of single trials from population neural data</a></p>
<p>9 0.43443993 <a title="148-lsi-9" href="./nips-2011-Empirical_models_of_spiking_in_neural_populations.html">86 nips-2011-Empirical models of spiking in neural populations</a></p>
<p>10 0.42648837 <a title="148-lsi-10" href="./nips-2011-Facial_Expression_Transfer_with_Input-Output_Temporal_Restricted_Boltzmann_Machines.html">94 nips-2011-Facial Expression Transfer with Input-Output Temporal Restricted Boltzmann Machines</a></p>
<p>11 0.41920432 <a title="148-lsi-11" href="./nips-2011-Efficient_inference_in_matrix-variate_Gaussian_models_with_%5Ciid_observation_noise.html">83 nips-2011-Efficient inference in matrix-variate Gaussian models with \iid observation noise</a></p>
<p>12 0.41583622 <a title="148-lsi-12" href="./nips-2011-Kernel_Embeddings_of_Latent_Tree_Graphical_Models.html">140 nips-2011-Kernel Embeddings of Latent Tree Graphical Models</a></p>
<p>13 0.40761194 <a title="148-lsi-13" href="./nips-2011-A_Denoising_View_of_Matrix_Completion.html">5 nips-2011-A Denoising View of Matrix Completion</a></p>
<p>14 0.4053275 <a title="148-lsi-14" href="./nips-2011-Multilinear_Subspace_Regression%3A_An_Orthogonal_Tensor_Decomposition_Approach.html">179 nips-2011-Multilinear Subspace Regression: An Orthogonal Tensor Decomposition Approach</a></p>
<p>15 0.38894114 <a title="148-lsi-15" href="./nips-2011-An_ideal_observer_model_for_identifying_the_reference_frame_of_objects.html">35 nips-2011-An ideal observer model for identifying the reference frame of objects</a></p>
<p>16 0.38832018 <a title="148-lsi-16" href="./nips-2011-Infinite_Latent_SVM_for_Classification_and_Multi-task_Learning.html">134 nips-2011-Infinite Latent SVM for Classification and Multi-task Learning</a></p>
<p>17 0.37889114 <a title="148-lsi-17" href="./nips-2011-Maximal_Cliques_that_Satisfy_Hard_Constraints_with_Application_to_Deformable_Object_Model_Learning.html">166 nips-2011-Maximal Cliques that Satisfy Hard Constraints with Application to Deformable Object Model Learning</a></p>
<p>18 0.37725917 <a title="148-lsi-18" href="./nips-2011-Learning_Auto-regressive_Models_from_Sequence_and_Non-sequence_Data.html">144 nips-2011-Learning Auto-regressive Models from Sequence and Non-sequence Data</a></p>
<p>19 0.37587941 <a title="148-lsi-19" href="./nips-2011-Demixed_Principal_Component_Analysis.html">68 nips-2011-Demixed Principal Component Analysis</a></p>
<p>20 0.35290185 <a title="148-lsi-20" href="./nips-2011-Spike_and_Slab_Variational_Inference_for_Multi-Task_and_Multiple_Kernel_Learning.html">269 nips-2011-Spike and Slab Variational Inference for Multi-Task and Multiple Kernel Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.019), (4, 0.049), (20, 0.072), (26, 0.017), (31, 0.098), (33, 0.038), (43, 0.046), (45, 0.1), (57, 0.032), (66, 0.301), (74, 0.032), (83, 0.03), (99, 0.062)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.75462431 <a title="148-lda-1" href="./nips-2011-Learning_Probabilistic_Non-Linear_Latent_Variable_Models_for_Tracking_Complex_Activities.html">148 nips-2011-Learning Probabilistic Non-Linear Latent Variable Models for Tracking Complex Activities</a></p>
<p>Author: Angela Yao, Juergen Gall, Luc V. Gool, Raquel Urtasun</p><p>Abstract: A common approach for handling the complexity and inherent ambiguities of 3D human pose estimation is to use pose priors learned from training data. Existing approaches however, are either too simplistic (linear), too complex to learn, or can only learn latent spaces from “simple data”, i.e., single activities such as walking or running. In this paper, we present an efﬁcient stochastic gradient descent algorithm that is able to learn probabilistic non-linear latent spaces composed of multiple activities. Furthermore, we derive an incremental algorithm for the online setting which can update the latent space without extensive relearning. We demonstrate the effectiveness of our approach on the task of monocular and multi-view tracking and show that our approach outperforms the state-of-the-art. 1</p><p>2 0.72706854 <a title="148-lda-2" href="./nips-2011-Reinforcement_Learning_using_Kernel-Based_Stochastic_Factorization.html">237 nips-2011-Reinforcement Learning using Kernel-Based Stochastic Factorization</a></p>
<p>Author: Andre S. Barreto, Doina Precup, Joelle Pineau</p><p>Abstract: Kernel-based reinforcement-learning (KBRL) is a method for learning a decision policy from a set of sample transitions which stands out for its strong theoretical guarantees. However, the size of the approximator grows with the number of transitions, which makes the approach impractical for large problems. In this paper we introduce a novel algorithm to improve the scalability of KBRL. We resort to a special decomposition of a transition matrix, called stochastic factorization, to ﬁx the size of the approximator while at the same time incorporating all the information contained in the data. The resulting algorithm, kernel-based stochastic factorization (KBSF), is much faster but still converges to a unique solution. We derive a theoretical upper bound for the distance between the value functions computed by KBRL and KBSF. The effectiveness of our method is illustrated with computational experiments on four reinforcement-learning problems, including a difﬁcult task in which the goal is to learn a neurostimulation policy to suppress the occurrence of seizures in epileptic rat brains. We empirically demonstrate that the proposed approach is able to compress the information contained in KBRL’s model. Also, on the tasks studied, KBSF outperforms two of the most prominent reinforcement-learning algorithms, namely least-squares policy iteration and ﬁtted Q-iteration. 1</p><p>3 0.64170778 <a title="148-lda-3" href="./nips-2011-Variational_Gaussian_Process_Dynamical_Systems.html">301 nips-2011-Variational Gaussian Process Dynamical Systems</a></p>
<p>Author: Neil D. Lawrence, Michalis K. Titsias, Andreas Damianou</p><p>Abstract: High dimensional time series are endemic in applications of machine learning such as robotics (sensor data), computational biology (gene expression data), vision (video sequences) and graphics (motion capture data). Practical nonlinear probabilistic approaches to this data are required. In this paper we introduce the variational Gaussian process dynamical system. Our work builds on recent variational approximations for Gaussian process latent variable models to allow for nonlinear dimensionality reduction simultaneously with learning a dynamical prior in the latent space. The approach also allows for the appropriate dimensionality of the latent space to be automatically determined. We demonstrate the model on a human motion capture data set and a series of high resolution video sequences. 1</p><p>4 0.60740644 <a title="148-lda-4" href="./nips-2011-Newtron%3A_an_Efficient_Bandit_algorithm_for_Online_Multiclass_Prediction.html">185 nips-2011-Newtron: an Efficient Bandit algorithm for Online Multiclass Prediction</a></p>
<p>Author: Elad Hazan, Satyen Kale</p><p>Abstract: We present an efﬁcient algorithm for the problem of online multiclass prediction with bandit feedback in the fully adversarial setting. We measure its regret with respect to the log-loss deﬁned in [AR09], which is parameterized by a scalar α. We prove that the regret of N EWTRON is O(log T ) when α is a constant that does not vary with horizon T , and at most O(T 2/3 ) if α is allowed to increase to inﬁnity √ with T . For α = O(log T ), the regret is bounded by O( T ), thus solving the open problem of [KSST08, AR09]. Our algorithm is based on a novel application of the online Newton method [HAK07]. We test our algorithm and show it to perform well in experiments, even when α is a small constant. 1</p><p>5 0.57695323 <a title="148-lda-5" href="./nips-2011-Multiclass_Boosting%3A_Theory_and_Algorithms.html">178 nips-2011-Multiclass Boosting: Theory and Algorithms</a></p>
<p>Author: Mohammad J. Saberian, Nuno Vasconcelos</p><p>Abstract: The problem of multi-class boosting is considered. A new framework, based on multi-dimensional codewords and predictors is introduced. The optimal set of codewords is derived, and a margin enforcing loss proposed. The resulting risk is minimized by gradient descent on a multidimensional functional space. Two algorithms are proposed: 1) CD-MCBoost, based on coordinate descent, updates one predictor component at a time, 2) GD-MCBoost, based on gradient descent, updates all components jointly. The algorithms differ in the weak learners that they support but are both shown to be 1) Bayes consistent, 2) margin enforcing, and 3) convergent to the global minimum of the risk. They also reduce to AdaBoost when there are only two classes. Experiments show that both methods outperform previous multiclass boosting approaches on a number of datasets. 1</p><p>6 0.52164304 <a title="148-lda-6" href="./nips-2011-Multiple_Instance_Filtering.html">180 nips-2011-Multiple Instance Filtering</a></p>
<p>7 0.51520222 <a title="148-lda-7" href="./nips-2011-Video_Annotation_and_Tracking_with_Active_Learning.html">303 nips-2011-Video Annotation and Tracking with Active Learning</a></p>
<p>8 0.51121575 <a title="148-lda-8" href="./nips-2011-Probabilistic_Joint_Image_Segmentation_and_Labeling.html">223 nips-2011-Probabilistic Joint Image Segmentation and Labeling</a></p>
<p>9 0.50962359 <a title="148-lda-9" href="./nips-2011-Pylon_Model_for_Semantic_Segmentation.html">227 nips-2011-Pylon Model for Semantic Segmentation</a></p>
<p>10 0.50790858 <a title="148-lda-10" href="./nips-2011-%24%5Ctheta%24-MRF%3A_Capturing_Spatial_and_Semantic_Structure_in_the_Parameters_for_Scene_Understanding.html">1 nips-2011-$\theta$-MRF: Capturing Spatial and Semantic Structure in the Parameters for Scene Understanding</a></p>
<p>11 0.50523239 <a title="148-lda-11" href="./nips-2011-Spatial_distance_dependent_Chinese_restaurant_processes_for_image_segmentation.html">266 nips-2011-Spatial distance dependent Chinese restaurant processes for image segmentation</a></p>
<p>12 0.50433308 <a title="148-lda-12" href="./nips-2011-Crowdclustering.html">66 nips-2011-Crowdclustering</a></p>
<p>13 0.5020721 <a title="148-lda-13" href="./nips-2011-Sparse_Manifold_Clustering_and_Embedding.html">263 nips-2011-Sparse Manifold Clustering and Embedding</a></p>
<p>14 0.4991343 <a title="148-lda-14" href="./nips-2011-Learning_person-object_interactions_for_action_recognition_in_still_images.html">154 nips-2011-Learning person-object interactions for action recognition in still images</a></p>
<p>15 0.49833003 <a title="148-lda-15" href="./nips-2011-Comparative_Analysis_of_Viterbi_Training_and_Maximum_Likelihood_Estimation_for_HMMs.html">57 nips-2011-Comparative Analysis of Viterbi Training and Maximum Likelihood Estimation for HMMs</a></p>
<p>16 0.49771142 <a title="148-lda-16" href="./nips-2011-Collective_Graphical_Models.html">55 nips-2011-Collective Graphical Models</a></p>
<p>17 0.49742621 <a title="148-lda-17" href="./nips-2011-Noise_Thresholds_for_Spectral_Clustering.html">186 nips-2011-Noise Thresholds for Spectral Clustering</a></p>
<p>18 0.49673891 <a title="148-lda-18" href="./nips-2011-Maximum_Margin_Multi-Instance_Learning.html">168 nips-2011-Maximum Margin Multi-Instance Learning</a></p>
<p>19 0.4967078 <a title="148-lda-19" href="./nips-2011-Online_Learning%3A_Stochastic%2C_Constrained%2C_and_Smoothed_Adversaries.html">204 nips-2011-Online Learning: Stochastic, Constrained, and Smoothed Adversaries</a></p>
<p>20 0.49616563 <a title="148-lda-20" href="./nips-2011-Analytical_Results_for_the_Error_in_Filtering_of_Gaussian_Processes.html">37 nips-2011-Analytical Results for the Error in Filtering of Gaussian Processes</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
