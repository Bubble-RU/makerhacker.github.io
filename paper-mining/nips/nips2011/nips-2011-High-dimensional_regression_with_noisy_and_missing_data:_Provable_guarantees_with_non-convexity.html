<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>118 nips-2011-High-dimensional regression with noisy and missing data: Provable guarantees with non-convexity</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-118" href="#">nips2011-118</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>118 nips-2011-High-dimensional regression with noisy and missing data: Provable guarantees with non-convexity</h1>
<br/><p>Source: <a title="nips-2011-118-pdf" href="http://papers.nips.cc/paper/4454-high-dimensional-regression-with-noisy-and-missing-data-provable-guarantees-with-non-convexity.pdf">pdf</a></p><p>Author: Po-ling Loh, Martin J. Wainwright</p><p>Abstract: Although the standard formulations of prediction problems involve fully-observed and noiseless data drawn in an i.i.d. manner, many applications involve noisy and/or missing data, possibly involving dependencies. We study these issues in the context of high-dimensional sparse linear regression, and propose novel estimators for the cases of noisy, missing, and/or dependent data. Many standard approaches to noisy or missing data, such as those using the EM algorithm, lead to optimization problems that are inherently non-convex, and it is difÔ¨Åcult to establish theoretical guarantees on practical algorithms. While our approach also involves optimizing non-convex programs, we are able to both analyze the statistical error associated with any global optimum, and prove that a simple projected gradient descent algorithm will converge in polynomial time to a small neighborhood of the set of global minimizers. On the statistical side, we provide non-asymptotic bounds that hold with high probability for the cases of noisy, missing, and/or dependent data. On the computational side, we prove that under the same types of conditions required for statistical consistency, the projected gradient descent algorithm will converge at geometric rates to a near-global minimizer. We illustrate these theoretical predictions with simulations, showing agreement with the predicted scalings. 1</p><p>Reference: <a title="nips-2011-118-reference" href="../nips2011_reference/nips-2011-High-dimensional_regression_with_noisy_and_missing_data%3A_Provable_guarantees_with_non-convexity_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('miss', 0.423), ('las', 0.294), ('rp', 0.223), ('resc', 0.181), ('desc', 0.173), ('mis', 0.17), ('lasso', 0.163), ('corrupt', 0.158), ('aj', 0.154), ('var', 0.154), ('matrix', 0.142), ('nois', 0.138), ('zij', 0.128), ('grady', 0.122), ('noisy', 0.122), ('plot', 0.121), ('program', 0.111), ('project', 0.111), ('cov', 0.107), ('glob', 0.105)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="118-tfidf-1" href="./nips-2011-High-dimensional_regression_with_noisy_and_missing_data%3A_Provable_guarantees_with_non-convexity.html">118 nips-2011-High-dimensional regression with noisy and missing data: Provable guarantees with non-convexity</a></p>
<p>2 0.34805208 <a title="118-tfidf-2" href="./nips-2011-Robust_Lasso_with_missing_and_grossly_corrupted_observations.html">239 nips-2011-Robust Lasso with missing and grossly corrupted observations</a></p>
<p>3 0.17410617 <a title="118-tfidf-3" href="./nips-2011-Sparse_Bayesian_Multi-Task_Learning.html">258 nips-2011-Sparse Bayesian Multi-Task Learning</a></p>
<p>4 0.16874892 <a title="118-tfidf-4" href="./nips-2011-Trace_Lasso%3A_a_trace_norm_regularization_for_correlated_designs.html">289 nips-2011-Trace Lasso: a trace norm regularization for correlated designs</a></p>
<p>5 0.15930539 <a title="118-tfidf-5" href="./nips-2011-Phase_transition_in_the_family_of_p-resistances.html">213 nips-2011-Phase transition in the family of p-resistances</a></p>
<p>6 0.13084725 <a title="118-tfidf-6" href="./nips-2011-Statistical_Tests_for_Optimization_Efficiency.html">271 nips-2011-Statistical Tests for Optimization Efficiency</a></p>
<p>7 0.12942523 <a title="118-tfidf-7" href="./nips-2011-Shaping_Level_Sets_with_Submodular_Functions.html">251 nips-2011-Shaping Level Sets with Submodular Functions</a></p>
<p>8 0.12867777 <a title="118-tfidf-8" href="./nips-2011-On_Learning_Discrete_Graphical_Models_using_Greedy_Methods.html">195 nips-2011-On Learning Discrete Graphical Models using Greedy Methods</a></p>
<p>9 0.12785281 <a title="118-tfidf-9" href="./nips-2011-Sparse_Inverse_Covariance_Matrix_Estimation_Using_Quadratic_Approximation.html">262 nips-2011-Sparse Inverse Covariance Matrix Estimation Using Quadratic Approximation</a></p>
<p>10 0.12462367 <a title="118-tfidf-10" href="./nips-2011-Matrix_Completion_for_Multi-label_Image_Classification.html">165 nips-2011-Matrix Completion for Multi-label Image Classification</a></p>
<p>11 0.11895327 <a title="118-tfidf-11" href="./nips-2011-Noise_Thresholds_for_Spectral_Clustering.html">186 nips-2011-Noise Thresholds for Spectral Clustering</a></p>
<p>12 0.11630927 <a title="118-tfidf-12" href="./nips-2011-A_Denoising_View_of_Matrix_Completion.html">5 nips-2011-A Denoising View of Matrix Completion</a></p>
<p>13 0.11349696 <a title="118-tfidf-13" href="./nips-2011-Sparse_Features_for_PCA-Like_Linear_Regression.html">260 nips-2011-Sparse Features for PCA-Like Linear Regression</a></p>
<p>14 0.11196952 <a title="118-tfidf-14" href="./nips-2011-Approximating_Semidefinite_Programs_in_Sublinear_Time.html">39 nips-2011-Approximating Semidefinite Programs in Sublinear Time</a></p>
<p>15 0.10841607 <a title="118-tfidf-15" href="./nips-2011-Generalised_Coupled_Tensor_Factorisation.html">102 nips-2011-Generalised Coupled Tensor Factorisation</a></p>
<p>16 0.10655096 <a title="118-tfidf-16" href="./nips-2011-Learning_Auto-regressive_Models_from_Sequence_and_Non-sequence_Data.html">144 nips-2011-Learning Auto-regressive Models from Sequence and Non-sequence Data</a></p>
<p>17 0.10625537 <a title="118-tfidf-17" href="./nips-2011-Sparse_Recovery_with_Brownian_Sensing.html">264 nips-2011-Sparse Recovery with Brownian Sensing</a></p>
<p>18 0.10614435 <a title="118-tfidf-18" href="./nips-2011-Sparse_recovery_by_thresholded_non-negative_least_squares.html">265 nips-2011-Sparse recovery by thresholded non-negative least squares</a></p>
<p>19 0.10446613 <a title="118-tfidf-19" href="./nips-2011-Nearest_Neighbor_based_Greedy_Coordinate_Descent.html">182 nips-2011-Nearest Neighbor based Greedy Coordinate Descent</a></p>
<p>20 0.10319092 <a title="118-tfidf-20" href="./nips-2011-On_the_Universality_of_Online_Mirror_Descent.html">202 nips-2011-On the Universality of Online Mirror Descent</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.3), (1, -0.074), (2, 0.057), (3, 0.201), (4, 0.215), (5, -0.009), (6, 0.053), (7, -0.035), (8, 0.114), (9, 0.044), (10, -0.032), (11, 0.012), (12, -0.136), (13, -0.074), (14, -0.109), (15, 0.072), (16, -0.059), (17, -0.1), (18, -0.072), (19, -0.033), (20, 0.019), (21, 0.05), (22, 0.043), (23, -0.003), (24, 0.043), (25, 0.049), (26, -0.014), (27, 0.061), (28, -0.065), (29, -0.005), (30, 0.012), (31, -0.092), (32, -0.022), (33, -0.062), (34, 0.038), (35, 0.051), (36, 0.112), (37, -0.13), (38, -0.079), (39, -0.037), (40, 0.085), (41, -0.096), (42, -0.027), (43, -0.015), (44, -0.003), (45, 0.043), (46, 0.002), (47, -0.053), (48, -0.143), (49, -0.022)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95442057 <a title="118-lsi-1" href="./nips-2011-High-dimensional_regression_with_noisy_and_missing_data%3A_Provable_guarantees_with_non-convexity.html">118 nips-2011-High-dimensional regression with noisy and missing data: Provable guarantees with non-convexity</a></p>
<p>2 0.8618083 <a title="118-lsi-2" href="./nips-2011-Robust_Lasso_with_missing_and_grossly_corrupted_observations.html">239 nips-2011-Robust Lasso with missing and grossly corrupted observations</a></p>
<p>3 0.70733631 <a title="118-lsi-3" href="./nips-2011-Learning_Auto-regressive_Models_from_Sequence_and_Non-sequence_Data.html">144 nips-2011-Learning Auto-regressive Models from Sequence and Non-sequence Data</a></p>
<p>4 0.68784952 <a title="118-lsi-4" href="./nips-2011-Minimax_Localization_of_Structural_Information_in_Large_Noisy_Matrices.html">172 nips-2011-Minimax Localization of Structural Information in Large Noisy Matrices</a></p>
<p>5 0.67013407 <a title="118-lsi-5" href="./nips-2011-Trace_Lasso%3A_a_trace_norm_regularization_for_correlated_designs.html">289 nips-2011-Trace Lasso: a trace norm regularization for correlated designs</a></p>
<p>6 0.6624946 <a title="118-lsi-6" href="./nips-2011-Differentially_Private_M-Estimators.html">69 nips-2011-Differentially Private M-Estimators</a></p>
<p>7 0.65512729 <a title="118-lsi-7" href="./nips-2011-Regularized_Laplacian_Estimation_and_Fast_Eigenvector_Approximation.html">236 nips-2011-Regularized Laplacian Estimation and Fast Eigenvector Approximation</a></p>
<p>8 0.65423447 <a title="118-lsi-8" href="./nips-2011-Convergent_Fitted_Value_Iteration_with_Linear_Function_Approximation.html">65 nips-2011-Convergent Fitted Value Iteration with Linear Function Approximation</a></p>
<p>9 0.6522693 <a title="118-lsi-9" href="./nips-2011-Sparse_Recovery_with_Brownian_Sensing.html">264 nips-2011-Sparse Recovery with Brownian Sensing</a></p>
<p>10 0.65224838 <a title="118-lsi-10" href="./nips-2011-Divide-and-Conquer_Matrix_Factorization.html">73 nips-2011-Divide-and-Conquer Matrix Factorization</a></p>
<p>11 0.64546019 <a title="118-lsi-11" href="./nips-2011-Universal_low-rank_matrix_recovery_from_Pauli_measurements.html">297 nips-2011-Universal low-rank matrix recovery from Pauli measurements</a></p>
<p>12 0.6451357 <a title="118-lsi-12" href="./nips-2011-On_the_accuracy_of_l1-filtering_of_signals_with_block-sparse_structure.html">203 nips-2011-On the accuracy of l1-filtering of signals with block-sparse structure</a></p>
<p>13 0.63901633 <a title="118-lsi-13" href="./nips-2011-A_Denoising_View_of_Matrix_Completion.html">5 nips-2011-A Denoising View of Matrix Completion</a></p>
<p>14 0.63428587 <a title="118-lsi-14" href="./nips-2011-Sparse_recovery_by_thresholded_non-negative_least_squares.html">265 nips-2011-Sparse recovery by thresholded non-negative least squares</a></p>
<p>15 0.63263357 <a title="118-lsi-15" href="./nips-2011-Phase_transition_in_the_family_of_p-resistances.html">213 nips-2011-Phase transition in the family of p-resistances</a></p>
<p>16 0.62730873 <a title="118-lsi-16" href="./nips-2011-Sparse_Inverse_Covariance_Matrix_Estimation_Using_Quadratic_Approximation.html">262 nips-2011-Sparse Inverse Covariance Matrix Estimation Using Quadratic Approximation</a></p>
<p>17 0.62387431 <a title="118-lsi-17" href="./nips-2011-On_Learning_Discrete_Graphical_Models_using_Greedy_Methods.html">195 nips-2011-On Learning Discrete Graphical Models using Greedy Methods</a></p>
<p>18 0.59886736 <a title="118-lsi-18" href="./nips-2011-Orthogonal_Matching_Pursuit_with_Replacement.html">209 nips-2011-Orthogonal Matching Pursuit with Replacement</a></p>
<p>19 0.59411955 <a title="118-lsi-19" href="./nips-2011-SpaRCS%3A_Recovering_low-rank_and_sparse_matrices_from_compressive_measurements.html">257 nips-2011-SpaRCS: Recovering low-rank and sparse matrices from compressive measurements</a></p>
<p>20 0.57459569 <a title="118-lsi-20" href="./nips-2011-Efficient_inference_in_matrix-variate_Gaussian_models_with_%5Ciid_observation_noise.html">83 nips-2011-Efficient inference in matrix-variate Gaussian models with \iid observation noise</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.085), (22, 0.111), (36, 0.05), (53, 0.014), (54, 0.01), (55, 0.255), (65, 0.091), (68, 0.182), (79, 0.023), (98, 0.105)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.98289132 <a title="118-lda-1" href="./nips-2011-Orthogonal_Matching_Pursuit_with_Replacement.html">209 nips-2011-Orthogonal Matching Pursuit with Replacement</a></p>
<p>2 0.9548074 <a title="118-lda-2" href="./nips-2011-Video_Annotation_and_Tracking_with_Active_Learning.html">303 nips-2011-Video Annotation and Tracking with Active Learning</a></p>
<p>3 0.94448709 <a title="118-lda-3" href="./nips-2011-Sparse_Inverse_Covariance_Matrix_Estimation_Using_Quadratic_Approximation.html">262 nips-2011-Sparse Inverse Covariance Matrix Estimation Using Quadratic Approximation</a></p>
<p>same-paper 4 0.94387364 <a title="118-lda-4" href="./nips-2011-High-dimensional_regression_with_noisy_and_missing_data%3A_Provable_guarantees_with_non-convexity.html">118 nips-2011-High-dimensional regression with noisy and missing data: Provable guarantees with non-convexity</a></p>
<p>5 0.94158506 <a title="118-lda-5" href="./nips-2011-Kernel_Embeddings_of_Latent_Tree_Graphical_Models.html">140 nips-2011-Kernel Embeddings of Latent Tree Graphical Models</a></p>
<p>6 0.93968952 <a title="118-lda-6" href="./nips-2011-Prismatic_Algorithm_for_Discrete_D.C._Programming_Problem.html">222 nips-2011-Prismatic Algorithm for Discrete D.C. Programming Problem</a></p>
<p>7 0.93796659 <a title="118-lda-7" href="./nips-2011-Statistical_Tests_for_Optimization_Efficiency.html">271 nips-2011-Statistical Tests for Optimization Efficiency</a></p>
<p>8 0.93743575 <a title="118-lda-8" href="./nips-2011-Better_Mini-Batch_Algorithms_via_Accelerated_Gradient_Methods.html">46 nips-2011-Better Mini-Batch Algorithms via Accelerated Gradient Methods</a></p>
<p>9 0.93418115 <a title="118-lda-9" href="./nips-2011-Trace_Lasso%3A_a_trace_norm_regularization_for_correlated_designs.html">289 nips-2011-Trace Lasso: a trace norm regularization for correlated designs</a></p>
<p>10 0.93124115 <a title="118-lda-10" href="./nips-2011-Nearest_Neighbor_based_Greedy_Coordinate_Descent.html">182 nips-2011-Nearest Neighbor based Greedy Coordinate Descent</a></p>
<p>11 0.93061209 <a title="118-lda-11" href="./nips-2011-Hogwild%3A_A_Lock-Free_Approach_to_Parallelizing_Stochastic_Gradient_Descent.html">121 nips-2011-Hogwild: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent</a></p>
<p>12 0.92974293 <a title="118-lda-12" href="./nips-2011-Convergent_Fitted_Value_Iteration_with_Linear_Function_Approximation.html">65 nips-2011-Convergent Fitted Value Iteration with Linear Function Approximation</a></p>
<p>13 0.92970157 <a title="118-lda-13" href="./nips-2011-Learning_Auto-regressive_Models_from_Sequence_and_Non-sequence_Data.html">144 nips-2011-Learning Auto-regressive Models from Sequence and Non-sequence Data</a></p>
<p>14 0.92935961 <a title="118-lda-14" href="./nips-2011-Efficient_Methods_for_Overlapping_Group_Lasso.html">78 nips-2011-Efficient Methods for Overlapping Group Lasso</a></p>
<p>15 0.92848516 <a title="118-lda-15" href="./nips-2011-Convergent_Bounds_on_the_Euclidean_Distance.html">64 nips-2011-Convergent Bounds on the Euclidean Distance</a></p>
<p>16 0.92819989 <a title="118-lda-16" href="./nips-2011-On_the_Universality_of_Online_Mirror_Descent.html">202 nips-2011-On the Universality of Online Mirror Descent</a></p>
<p>17 0.92803758 <a title="118-lda-17" href="./nips-2011-Empirical_models_of_spiking_in_neural_populations.html">86 nips-2011-Empirical models of spiking in neural populations</a></p>
<p>18 0.92790753 <a title="118-lda-18" href="./nips-2011-The_Fixed_Points_of_Off-Policy_TD.html">283 nips-2011-The Fixed Points of Off-Policy TD</a></p>
<p>19 0.92730379 <a title="118-lda-19" href="./nips-2011-Sparse_Features_for_PCA-Like_Linear_Regression.html">260 nips-2011-Sparse Features for PCA-Like Linear Regression</a></p>
<p>20 0.92709792 <a title="118-lda-20" href="./nips-2011-Beating_SGD%3A_Learning_SVMs_in_Sublinear_Time.html">45 nips-2011-Beating SGD: Learning SVMs in Sublinear Time</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
