<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>109 nips-2011-Greedy Model Averaging</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-109" href="#">nips2011-109</a> knowledge-graph by maker-knowledge-mining</p><h1>109 nips-2011-Greedy Model Averaging</h1>
<br/><p>Source: <a title="nips-2011-109-pdf" href="http://papers.nips.cc/paper/4203-greedy-model-averaging.pdf">pdf</a></p><p>Author: Dong Dai, Tong Zhang</p><p>Abstract: This paper considers the problem of combining multiple models to achieve a prediction accuracy not much worse than that of the best single model for least squares regression. It is known that if the models are mis-speciﬁed, model averaging is superior to model selection. Speciﬁcally, let n be the sample size, then the worst case regret of the former decays at the rate of O(1/n) while the worst √ case regret of the latter decays at the rate of O(1/ n). In the literature, the most important and widely studied model averaging method that achieves the optimal O(1/n) average regret is the exponential weighted model averaging (EWMA) algorithm. However this method suffers from several limitations. The purpose of this paper is to present a new greedy model averaging procedure that improves EWMA. We prove strong theoretical guarantees for the new procedure and illustrate our theoretical results with empirical examples. 1</p><p>Reference: <a title="nips-2011-109-reference" href="../nips2011_reference/nips-2011-Greedy_Model_Averaging_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('ewm', 0.665), ('gma', 0.465), ('ln', 0.316), ('qj', 0.232), ('qk', 0.171), ('star', 0.167), ('wk', 0.158), ('regret', 0.106), ('stag', 0.084), ('greedy', 0.078), ('mse', 0.075), ('theorem', 0.073), ('bsm', 0.066), ('compet', 0.062), ('wj', 0.059), ('isn', 0.058), ('infery', 0.049), ('ineq', 0.049), ('rigollet', 0.044), ('av', 0.044)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="109-tfidf-1" href="./nips-2011-Greedy_Model_Averaging.html">109 nips-2011-Greedy Model Averaging</a></p>
<p>2 0.15231068 <a title="109-tfidf-2" href="./nips-2011-PAC-Bayesian_Analysis_of_Contextual_Bandits.html">210 nips-2011-PAC-Bayesian Analysis of Contextual Bandits</a></p>
<p>3 0.13200542 <a title="109-tfidf-3" href="./nips-2011-Adaptive_Hedge.html">25 nips-2011-Adaptive Hedge</a></p>
<p>4 0.1120127 <a title="109-tfidf-4" href="./nips-2011-Speedy_Q-Learning.html">268 nips-2011-Speedy Q-Learning</a></p>
<p>5 0.11129346 <a title="109-tfidf-5" href="./nips-2011-k-NN_Regression_Adapts_to_Local_Intrinsic_Dimension.html">305 nips-2011-k-NN Regression Adapts to Local Intrinsic Dimension</a></p>
<p>6 0.11100821 <a title="109-tfidf-6" href="./nips-2011-Practical_Variational_Inference_for_Neural_Networks.html">217 nips-2011-Practical Variational Inference for Neural Networks</a></p>
<p>7 0.10881243 <a title="109-tfidf-7" href="./nips-2011-Comparative_Analysis_of_Viterbi_Training_and_Maximum_Likelihood_Estimation_for_HMMs.html">57 nips-2011-Comparative Analysis of Viterbi Training and Maximum Likelihood Estimation for HMMs</a></p>
<p>8 0.10414714 <a title="109-tfidf-8" href="./nips-2011-Committing_Bandits.html">56 nips-2011-Committing Bandits</a></p>
<p>9 0.091897383 <a title="109-tfidf-9" href="./nips-2011-Selecting_the_State-Representation_in_Reinforcement_Learning.html">245 nips-2011-Selecting the State-Representation in Reinforcement Learning</a></p>
<p>10 0.090807669 <a title="109-tfidf-10" href="./nips-2011-Sparse_Features_for_PCA-Like_Linear_Regression.html">260 nips-2011-Sparse Features for PCA-Like Linear Regression</a></p>
<p>11 0.081819527 <a title="109-tfidf-11" href="./nips-2011-Action-Gap_Phenomenon_in_Reinforcement_Learning.html">18 nips-2011-Action-Gap Phenomenon in Reinforcement Learning</a></p>
<p>12 0.07874544 <a title="109-tfidf-12" href="./nips-2011-Finite_Time_Analysis_of_Stratified_Sampling_for_Monte_Carlo.html">97 nips-2011-Finite Time Analysis of Stratified Sampling for Monte Carlo</a></p>
<p>13 0.074925177 <a title="109-tfidf-13" href="./nips-2011-Transfer_from_Multiple_MDPs.html">291 nips-2011-Transfer from Multiple MDPs</a></p>
<p>14 0.073719375 <a title="109-tfidf-14" href="./nips-2011-Improved_Algorithms_for_Linear_Stochastic_Bandits.html">128 nips-2011-Improved Algorithms for Linear Stochastic Bandits</a></p>
<p>15 0.071127497 <a title="109-tfidf-15" href="./nips-2011-Online_Submodular_Set_Cover%2C_Ranking%2C_and_Repeated_Active_Learning.html">205 nips-2011-Online Submodular Set Cover, Ranking, and Repeated Active Learning</a></p>
<p>16 0.065604329 <a title="109-tfidf-16" href="./nips-2011-Generalization_Bounds_and_Consistency_for_Latent_Structural_Probit_and_Ramp_Loss.html">103 nips-2011-Generalization Bounds and Consistency for Latent Structural Probit and Ramp Loss</a></p>
<p>17 0.063189648 <a title="109-tfidf-17" href="./nips-2011-Prediction_strategies_without_loss.html">220 nips-2011-Prediction strategies without loss</a></p>
<p>18 0.058233902 <a title="109-tfidf-18" href="./nips-2011-Selective_Prediction_of_Financial_Trends_with_Hidden_Markov_Models.html">246 nips-2011-Selective Prediction of Financial Trends with Hidden Markov Models</a></p>
<p>19 0.058042631 <a title="109-tfidf-19" href="./nips-2011-The_Fast_Convergence_of_Boosting.html">282 nips-2011-The Fast Convergence of Boosting</a></p>
<p>20 0.057638187 <a title="109-tfidf-20" href="./nips-2011-On_Learning_Discrete_Graphical_Models_using_Greedy_Methods.html">195 nips-2011-On Learning Discrete Graphical Models using Greedy Methods</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.124), (1, -0.092), (2, -0.082), (3, 0.054), (4, -0.021), (5, -0.003), (6, 0.076), (7, -0.025), (8, -0.002), (9, 0.052), (10, 0.074), (11, -0.013), (12, -0.045), (13, 0.011), (14, 0.108), (15, -0.112), (16, -0.068), (17, -0.029), (18, -0.037), (19, -0.01), (20, -0.175), (21, -0.002), (22, 0.048), (23, 0.03), (24, 0.031), (25, -0.041), (26, -0.032), (27, 0.175), (28, -0.153), (29, 0.112), (30, 0.101), (31, 0.011), (32, 0.042), (33, 0.023), (34, -0.046), (35, -0.08), (36, 0.011), (37, 0.078), (38, -0.014), (39, 0.07), (40, -0.039), (41, 0.022), (42, -0.026), (43, 0.075), (44, 0.005), (45, -0.039), (46, 0.107), (47, -0.013), (48, -0.006), (49, 0.026)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.90600896 <a title="109-lsi-1" href="./nips-2011-Greedy_Model_Averaging.html">109 nips-2011-Greedy Model Averaging</a></p>
<p>2 0.67563081 <a title="109-lsi-2" href="./nips-2011-Adaptive_Hedge.html">25 nips-2011-Adaptive Hedge</a></p>
<p>3 0.61913449 <a title="109-lsi-3" href="./nips-2011-Generalization_Bounds_and_Consistency_for_Latent_Structural_Probit_and_Ramp_Loss.html">103 nips-2011-Generalization Bounds and Consistency for Latent Structural Probit and Ramp Loss</a></p>
<p>4 0.58428222 <a title="109-lsi-4" href="./nips-2011-PAC-Bayesian_Analysis_of_Contextual_Bandits.html">210 nips-2011-PAC-Bayesian Analysis of Contextual Bandits</a></p>
<p>5 0.57960421 <a title="109-lsi-5" href="./nips-2011-Speedy_Q-Learning.html">268 nips-2011-Speedy Q-Learning</a></p>
<p>6 0.56144226 <a title="109-lsi-6" href="./nips-2011-k-NN_Regression_Adapts_to_Local_Intrinsic_Dimension.html">305 nips-2011-k-NN Regression Adapts to Local Intrinsic Dimension</a></p>
<p>7 0.51214695 <a title="109-lsi-7" href="./nips-2011-Comparative_Analysis_of_Viterbi_Training_and_Maximum_Likelihood_Estimation_for_HMMs.html">57 nips-2011-Comparative Analysis of Viterbi Training and Maximum Likelihood Estimation for HMMs</a></p>
<p>8 0.50646335 <a title="109-lsi-8" href="./nips-2011-Practical_Variational_Inference_for_Neural_Networks.html">217 nips-2011-Practical Variational Inference for Neural Networks</a></p>
<p>9 0.46894744 <a title="109-lsi-9" href="./nips-2011-Scalable_Training_of_Mixture_Models_via_Coresets.html">241 nips-2011-Scalable Training of Mixture Models via Coresets</a></p>
<p>10 0.45737615 <a title="109-lsi-10" href="./nips-2011-Action-Gap_Phenomenon_in_Reinforcement_Learning.html">18 nips-2011-Action-Gap Phenomenon in Reinforcement Learning</a></p>
<p>11 0.42682359 <a title="109-lsi-11" href="./nips-2011-Committing_Bandits.html">56 nips-2011-Committing Bandits</a></p>
<p>12 0.42646492 <a title="109-lsi-12" href="./nips-2011-Global_Solution_of_Fully-Observed_Variational_Bayesian_Matrix_Factorization_is_Column-Wise_Independent.html">107 nips-2011-Global Solution of Fully-Observed Variational Bayesian Matrix Factorization is Column-Wise Independent</a></p>
<p>13 0.41126865 <a title="109-lsi-13" href="./nips-2011-Transfer_from_Multiple_MDPs.html">291 nips-2011-Transfer from Multiple MDPs</a></p>
<p>14 0.39957017 <a title="109-lsi-14" href="./nips-2011-Finite_Time_Analysis_of_Stratified_Sampling_for_Monte_Carlo.html">97 nips-2011-Finite Time Analysis of Stratified Sampling for Monte Carlo</a></p>
<p>15 0.39183727 <a title="109-lsi-15" href="./nips-2011-Fast_and_Accurate_k-means_For_Large_Datasets.html">95 nips-2011-Fast and Accurate k-means For Large Datasets</a></p>
<p>16 0.38305846 <a title="109-lsi-16" href="./nips-2011-Boosting_with_Maximum_Adaptive_Sampling.html">49 nips-2011-Boosting with Maximum Adaptive Sampling</a></p>
<p>17 0.36938903 <a title="109-lsi-17" href="./nips-2011-Online_Submodular_Set_Cover%2C_Ranking%2C_and_Repeated_Active_Learning.html">205 nips-2011-Online Submodular Set Cover, Ranking, and Repeated Active Learning</a></p>
<p>18 0.34138083 <a title="109-lsi-18" href="./nips-2011-Demixed_Principal_Component_Analysis.html">68 nips-2011-Demixed Principal Component Analysis</a></p>
<p>19 0.33251584 <a title="109-lsi-19" href="./nips-2011-Structural_equations_and_divisive_normalization_for_energy-dependent_component_analysis.html">273 nips-2011-Structural equations and divisive normalization for energy-dependent component analysis</a></p>
<p>20 0.32470176 <a title="109-lsi-20" href="./nips-2011-Similarity-based_Learning_via_Data_Driven_Embeddings.html">254 nips-2011-Similarity-based Learning via Data Driven Embeddings</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(9, 0.281), (14, 0.046), (22, 0.049), (36, 0.052), (55, 0.135), (65, 0.039), (68, 0.241)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.78459203 <a title="109-lda-1" href="./nips-2011-Lower_Bounds_for_Passive_and_Active_Learning.html">162 nips-2011-Lower Bounds for Passive and Active Learning</a></p>
<p>same-paper 2 0.78099525 <a title="109-lda-2" href="./nips-2011-Greedy_Model_Averaging.html">109 nips-2011-Greedy Model Averaging</a></p>
<p>3 0.76928937 <a title="109-lda-3" href="./nips-2011-Autonomous_Learning_of_Action_Models_for_Planning.html">41 nips-2011-Autonomous Learning of Action Models for Planning</a></p>
<p>4 0.71506441 <a title="109-lda-4" href="./nips-2011-Crowdclustering.html">66 nips-2011-Crowdclustering</a></p>
<p>5 0.71475077 <a title="109-lda-5" href="./nips-2011-Agnostic_Selective_Classification.html">28 nips-2011-Agnostic Selective Classification</a></p>
<p>6 0.71323663 <a title="109-lda-6" href="./nips-2011-PiCoDes%3A_Learning_a_Compact_Code_for_Novel-Category_Recognition.html">214 nips-2011-PiCoDes: Learning a Compact Code for Novel-Category Recognition</a></p>
<p>7 0.71207178 <a title="109-lda-7" href="./nips-2011-Maximum_Margin_Multi-Instance_Learning.html">168 nips-2011-Maximum Margin Multi-Instance Learning</a></p>
<p>8 0.71180141 <a title="109-lda-8" href="./nips-2011-Active_Ranking_using_Pairwise_Comparisons.html">22 nips-2011-Active Ranking using Pairwise Comparisons</a></p>
<p>9 0.71174091 <a title="109-lda-9" href="./nips-2011-Co-regularized_Multi-view_Spectral_Clustering.html">54 nips-2011-Co-regularized Multi-view Spectral Clustering</a></p>
<p>10 0.71114552 <a title="109-lda-10" href="./nips-2011-Hierarchical_Matching_Pursuit_for_Image_Classification%3A_Architecture_and_Fast_Algorithms.html">113 nips-2011-Hierarchical Matching Pursuit for Image Classification: Architecture and Fast Algorithms</a></p>
<p>11 0.71089888 <a title="109-lda-11" href="./nips-2011-Inductive_reasoning_about_chimeric_creatures.html">130 nips-2011-Inductive reasoning about chimeric creatures</a></p>
<p>12 0.71086305 <a title="109-lda-12" href="./nips-2011-Learning_to_Learn_with_Compound_HD_Models.html">156 nips-2011-Learning to Learn with Compound HD Models</a></p>
<p>13 0.70984888 <a title="109-lda-13" href="./nips-2011-Maximum_Margin_Multi-Label_Structured_Prediction.html">169 nips-2011-Maximum Margin Multi-Label Structured Prediction</a></p>
<p>14 0.70945132 <a title="109-lda-14" href="./nips-2011-Transfer_Learning_by_Borrowing_Examples_for_Multiclass_Object_Detection.html">290 nips-2011-Transfer Learning by Borrowing Examples for Multiclass Object Detection</a></p>
<p>15 0.70931244 <a title="109-lda-15" href="./nips-2011-A_Two-Stage_Weighting_Framework_for_Multi-Source_Domain_Adaptation.html">12 nips-2011-A Two-Stage Weighting Framework for Multi-Source Domain Adaptation</a></p>
<p>16 0.708722 <a title="109-lda-16" href="./nips-2011-EigenNet%3A_A_Bayesian_hybrid_of_generative_and_conditional_models_for_sparse_learning.html">84 nips-2011-EigenNet: A Bayesian hybrid of generative and conditional models for sparse learning</a></p>
<p>17 0.70858139 <a title="109-lda-17" href="./nips-2011-Expressive_Power_and_Approximation_Errors_of_Restricted_Boltzmann_Machines.html">92 nips-2011-Expressive Power and Approximation Errors of Restricted Boltzmann Machines</a></p>
<p>18 0.7082727 <a title="109-lda-18" href="./nips-2011-Hierarchically_Supervised_Latent_Dirichlet_Allocation.html">116 nips-2011-Hierarchically Supervised Latent Dirichlet Allocation</a></p>
<p>19 0.70822102 <a title="109-lda-19" href="./nips-2011-Understanding_the_Intrinsic_Memorability_of_Images.html">293 nips-2011-Understanding the Intrinsic Memorability of Images</a></p>
<p>20 0.7077738 <a title="109-lda-20" href="./nips-2011-Dimensionality_Reduction_Using_the_Sparse_Linear_Model.html">70 nips-2011-Dimensionality Reduction Using the Sparse Linear Model</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
