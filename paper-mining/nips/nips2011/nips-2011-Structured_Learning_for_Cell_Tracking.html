<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>275 nips-2011-Structured Learning for Cell Tracking</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-275" href="#">nips2011-275</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>275 nips-2011-Structured Learning for Cell Tracking</h1>
<br/><p>Source: <a title="nips-2011-275-pdf" href="http://papers.nips.cc/paper/4484-structured-learning-for-cell-tracking.pdf">pdf</a></p><p>Author: Xinghua Lou, Fred A. Hamprecht</p><p>Abstract: We study the problem of learning to track a large quantity of homogeneous objects such as cell tracking in cell culture study and developmental biology. Reliable cell tracking in time-lapse microscopic image sequences is important for modern biomedical research. Existing cell tracking methods are usually kept simple and use only a small number of features to allow for manual parameter tweaking or grid search. We propose a structured learning approach that allows to learn optimum parameters automatically from a training set. This allows for the use of a richer set of features which in turn affords improved tracking compared to recently reported methods on two public benchmark sequences. 1</p><p>Reference: <a title="nips-2011-275-reference" href="../nips2011_reference/nips-2011-Structured_Learning_for_Cell_Tracking_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 de  Abstract We study the problem of learning to track a large quantity of homogeneous objects such as cell tracking in cell culture study and developmental biology. [sent-6, score-0.915]
</p><p>2 Reliable cell tracking in time-lapse microscopic image sequences is important for modern biomedical research. [sent-7, score-0.651]
</p><p>3 Existing cell tracking methods are usually kept simple and use only a small number of features to allow for manual parameter tweaking or grid search. [sent-8, score-0.834]
</p><p>4 We propose a structured learning approach that allows to learn optimum parameters automatically from a training set. [sent-9, score-0.209]
</p><p>5 This allows for the use of a richer set of features which in turn affords improved tracking compared to recently reported methods on two public benchmark sequences. [sent-10, score-0.4]
</p><p>6 1  Introduction  One distinguishing property of life is its temporal dynamics, and it is hence only natural that time lapse experiments play a crucial role in current research on signaling pathways, drug discovery and developmental biology [17]. [sent-11, score-0.102]
</p><p>7 Such experiments yield a very large number of images, and reliable automated cell tracking emerges naturally as a prerequisite for further quantitative analysis. [sent-12, score-0.602]
</p><p>8 Even today, cell tracking remains a challenging problem in dense populations, in the presence of complex behavior or when image quality is poor. [sent-13, score-0.651]
</p><p>9 Existing cell tracking methods can broadly be categorized as deformable models, stochastic ﬁltering and object association. [sent-14, score-0.706]
</p><p>10 Deformable models combine detection, segmentation and tracking by initializing a set of models (e. [sent-15, score-0.386]
</p><p>11 active contours) in the ﬁrst frame and updating them in subsequent frames (e. [sent-17, score-0.179]
</p><p>12 Object association methods approximate and simplify the problem by separating the detection and association steps: once object candidates have been detected and characterized, a second step suggests associations between object candidates at different frames. [sent-27, score-1.058]
</p><p>13 This class of methods scales well [21, 16, 13] and allows the tracking of thousands of cells in 3D [19]. [sent-28, score-0.342]
</p><p>14 This was ﬁrst accomplished by casting tracking as a local afﬁnity prediction problem such as binary classiﬁcation with either ofﬂine [1] or online learning [11, 5, 15], weakly supervised learning with imperfect oracles [27], manifold appearance model learning [25], or ranking [10, 18]. [sent-31, score-0.382]
</p><p>15 However, these local methods fail to capture the very important dependency among associations, hence the resulting local afﬁnities do not necessarily guarantee a better global association [26]. [sent-32, score-0.129]
</p><p>16 To address this limitation, [26] extended the RankBoost method from [18] to rank global associations represented as a Conditional Random Field (CRF). [sent-33, score-0.31]
</p><p>17 Firstly, it depends on a set of artiﬁcially generated false association samples that can make the training data particularly imbalanced and the training procedure too expensive 1  for large-scale tracking problems. [sent-35, score-0.621]
</p><p>18 We ﬁrst present an extended formulation of the object association models proposed in the literature. [sent-42, score-0.233]
</p><p>19 We hence, secondly, propose to use structured learning to automatically learn optimum parameters from a training set, and hence proﬁt fully from this richer description. [sent-44, score-0.209]
</p><p>20 In section 2, we present the extended object association models and a structured learning approach for global afﬁnity learning. [sent-47, score-0.329]
</p><p>21 In section 3, an evaluation shows that our framework inherits the runtime advantage of object association while addressing many of its limitations. [sent-48, score-0.233]
</p><p>22 1  Association Hypotheses and Scoring  We assume that a previous detection and segmentation step has identiﬁed object candidates in all frames, see Fig. [sent-51, score-0.313]
</p><p>23 We set out to ﬁnd that set of object associations that best explains these observations. [sent-53, score-0.414]
</p><p>24 To this end, we admit the following set E of standard events [21, 13]: a cell can move or divide and it can appear or disappear. [sent-54, score-0.514]
</p><p>25 In addition, we allow two cells to (seemingly) merge, to account for occlusion or undersegmentation; and a cell can (seemingly) split, to allow for the lifting of occlusion or oversegmentation. [sent-55, score-0.26]
</p><p>26 These additional hypotheses are useful to account for the errors that typically occur in the detection and segmentation step in crowded or noisy data. [sent-56, score-0.207]
</p><p>27 The distinction between division and split is reasonable given that typical ﬂuorescence stains endow the anaphase with a distinctive appearance. [sent-57, score-0.153]
</p><p>28 Given a pair of object candidate lists x = {C, C } in two neighboring frames, there is a multitude of possible association hypotheses, see Fig. [sent-60, score-0.311]
</p><p>29 We have two tasks: ﬁrstly, to allow only consistent associations (e. [sent-62, score-0.31]
</p><p>30 making sure that each cell in the second frame is accounted for only once); and secondly to identify, among the multitude of consistent hypotheses, the one that is most compatible with the observations, and with what we have learned from the training data. [sent-64, score-0.543]
</p><p>31 We express this compatibility of the association between c ∈ P(C) and c ∈ P(C ) by event e ∈ E e e as an inner product fc,c we . [sent-65, score-0.169]
</p><p>32 Here, fc,c is a feature vector that characterizes the discrepancy (if any) between object candidates c and c ; and we is a parameter vector that encodes everything we 2  have learned from the training data. [sent-66, score-0.296]
</p><p>33 Summing over all object candidates in either of the frames and over all types of events gives the following compatibility function: e e fc,c , we zc,c  L(x, z; w) =  (1)  e∈E c∈P(C) c ∈P(C ) e e zc,c = 1 with zc,c ∈ {0, 1}  e zc,c = 1 and  s. [sent-67, score-0.441]
</p><p>34 (2)  e∈E c ∈P(C )  e∈E c∈P(C)  The constraints in the last line involve binary indicator variables z that reﬂect the consistency requirements: each candidate in the ﬁrst frame must have a single fate, and each candidate from the second frame a unique history. [sent-69, score-0.296]
</p><p>35 As an important technical detail, note that P(C) := C ∪ (C ⊗ C) is a set comprising each object candidate, as well as all ordered pairs of object candidates from a frame1 . [sent-70, score-0.325]
</p><p>36 This allows us to conveniently subsume cell divisions, splits and mergers in the above equation. [sent-71, score-0.303]
</p><p>37 the global afﬁnity measure, states how well a set of associations z matches the observations f (x) computed from the raw data x, given the knowledge w from the training set. [sent-74, score-0.385]
</p><p>38 The remaining tasks, discussed next, are how to learn the parameters w from the training data (section 2. [sent-75, score-0.113]
</p><p>39 2); given these, how to ﬁnd the best possible associations z (section 2. [sent-76, score-0.31]
</p><p>40 2  Structured Max-Margin Parameter Learning  In learning the parameters automatically from a training set, we pursue two goals: ﬁrst, to go beyond manual parameter tweaking in obtaining the best possible performance; and second, to make the process as facile as possible for the user. [sent-80, score-0.249]
</p><p>41 This is under the assumption that most experimentalists ﬁnd it easier to specify what a correct tracking should look like, rather than what value a more-or-less obscure parameter should have. [sent-81, score-0.385]
</p><p>42 ∗ Given N training frame pairs X = {xn } and their correct associations Z ∗ = {zn }, n = 1, . [sent-82, score-0.495]
</p><p>43 , N , the best set of parameters is the optimizer of  arg min R(w; X, Z ∗ ) + λΩ(w)  (3)  w  Here, R(w; X, Z ∗ ) measures the empirical loss of the current parametrization w given the training data X, Z ∗ . [sent-85, score-0.181]
</p><p>44 The empirical loss is given by N 1 ∗ ˆ ˆ R(w; X, Z ∗ ) = N i=1 ∆(zn , zn (w; xn )). [sent-93, score-0.25]
</p><p>45 Here ∆(z ∗ , z) is a loss function that measures the discrepancy between a true association z ∗ and a prediction by specifying the fraction of missed events w. [sent-94, score-0.278]
</p><p>46 Importantly, both the input (objects from a frame pair) and output (associations between objects) in this learning problem are structured. [sent-100, score-0.11]
</p><p>47 We hence resort to max-margin structured learning [2] to exploit the structure and dependency within the association hypotheses. [sent-101, score-0.225]
</p><p>48 In comparison to other aforementioned learning methods, structured learning allows us to directly learn the global afﬁnity measure, avoid generating many artiﬁcial false association samples, and drop any assumptions on the signs of the features. [sent-102, score-0.263]
</p><p>49 In particular, we attempt to ﬁnd the decision boundary that maximizes the margin between the ∗ correct association zn and the closest runner-up solution. [sent-104, score-0.341]
</p><p>50 3  ∗ that the score of zn be greater than that of any other solution. [sent-107, score-0.212]
</p><p>51 1 N  N n=1 ξn  + λΩ(w)  ∗ ∗ ˆ ˆ ˆ ∀n, ∀zn ∈ Zn : L(xn , zn ; w) − L(xn , zn ; w) ≥ ∆(zn , zn ) − ξn ,  (5)  ∗ ˆ where Zn is the set of possible consistent associations and ∆(zn , zn ) − ξn is known as “marginrescaling” [24]. [sent-111, score-1.158]
</p><p>52 Iteratively ﬁnd, ﬁrst, the optimum associations for the current ∗ ˆ ˆ w by solving, for all n, zn = arg maxz {L(xn , z; w) + ∆(zn , z)}. [sent-118, score-0.522]
</p><p>53 Use all these zn to identify the most violated constraint, and add it to Eq. [sent-119, score-0.212]
</p><p>54 For a given parametrization, the optimum associations can be found by integer linear programming (ILP) [16, 21, 13]. [sent-124, score-0.31]
</p><p>55 Our framework has been implemented in Matlab and C++, including a labeling GUI for the generation of training set associations, feature extraction, model inference and the bundle method. [sent-125, score-0.138]
</p><p>56 To reduce the search space and eliminate hypotheses with no prospect of being realized, we constrain the hypotheses to a k-nearest neighborhood with distance thresholding. [sent-126, score-0.144]
</p><p>57 division and split) and resolve ambiguity in model inference, we need rich features to characterize different events. [sent-132, score-0.156]
</p><p>58 In additional to basic features such as size/position [21] and intensity histogram [16], we also designed new features such as “shape compactness” for oversegmentation and “angle pattern” for division. [sent-133, score-0.221]
</p><p>59 Shape compactness relates the summed areas of two object candidates to the area of their union’s convex hull. [sent-134, score-0.33]
</p><p>60 Features can be deﬁned on a pair of object candidates or on an individual object candidate only. [sent-136, score-0.363]
</p><p>61 The two datasets show a certain degree of variations such as illumination, cell density and image compression artifacts (Fig. [sent-142, score-0.36]
</p><p>62 action=show movie;query=243867  3  4  GFP stained cell nuclei were segmented using the method in [19], yielding an F-measure over 99. [sent-152, score-0.303]
</p><p>63 Full ground truth associations for training and evaluation were generated with a Matlab GUI tool at a rate of approximately 20 frames/hour. [sent-154, score-0.385]
</p><p>64 The Mitocheck sequence exhibits higher cell density, larger intensity variability and “blockness” artifacts due to image compression. [sent-163, score-0.422]
</p><p>65 Task 1: Efﬁcient Tracking for a Given Sequence We ﬁrst evaluate our method on a task that is frequently encountered in practice: the user simply wishes to obtain a good tracking for a given sequence with the smallest possible effort. [sent-164, score-0.342]
</p><p>66 For a fair comparison, we extended Padﬁeld’s method [21] to account for the six events described in section 2. [sent-165, score-0.111]
</p><p>67 A detailed analysis of the error counts for speciﬁc events shows that the method accounts well for moves, but has difﬁculty with disappearance and split events. [sent-172, score-0.231]
</p><p>68 To study the difference between manual tweaking and learning of the parameters, we used the learning framework presented here to optimize the model and obtained a reduction of the total loss from 1. [sent-174, score-0.212]
</p><p>69 Note that the learned parametrization actually deteriorates the detection of divisions because the learning aims at minimizing the overall loss across all events. [sent-178, score-0.253]
</p><p>70 With 37 features included and their weights optimized using structured learning, our model fully proﬁts from this richer description and achieves a total loss of only 0. [sent-180, score-0.192]
</p><p>71 30% (4th row) which is a signiﬁcant improvement over [21, 16] (2nd/7th row) and manual tweaking (6th row). [sent-181, score-0.174]
</p><p>72 Though a certain amount of efforts is needed for creating the training set, our method allows experimentalists to contribute their expertise in an intuitive fashion. [sent-182, score-0.118]
</p><p>73 They afford the following observations: Firstly, features on cell size and shape are generally of high importance, which is in line with the assumption in [21]. [sent-187, score-0.417]
</p><p>74 Secondly, the correlations of the features with the ﬁnal association score are 5  Table 3: Performance comparison on the DCellIQ dataset. [sent-188, score-0.187]
</p><p>75 The header row shows the number of events occurring for moves, divisions, appearance, disappearance, splits and mergers. [sent-189, score-0.246]
</p><p>76 mov div app dis spl mer total loss 10156 104 78 76 54 55 Padﬁeld et al. [sent-191, score-0.414]
</p><p>77 Figure 3: Some diverging associations by [21] (top) and our method (bottom). [sent-204, score-0.31]
</p><p>78 For example, shape compactness is positively correlated with split but negatively with division. [sent-207, score-0.182]
</p><p>79 This is in line with the intuition that an oversegmentation conserves compact shape, while a true division seemingly pushes the daughters far away from each other (in the present kind of data, where only DNA is labeled). [sent-208, score-0.178]
</p><p>80 Task 2: Tracking for High-Throughput Experiments The experiment described in the foregoing draws both training and test samples from the same time lapse experiment. [sent-210, score-0.167]
</p><p>81 To emulate this situation, we have used the parameters w trained in the foregoing on the DCellIQ sequence [16] and used these to estimate the tracking of the Mitocheck dataset. [sent-212, score-0.385]
</p><p>82 The main focus of the Mitocheck project is on accurate detection of mitosis (cell division). [sent-213, score-0.122]
</p><p>83 Despite the difference in illumination and cell density from the training data, and despite the segmentation artifacts caused by the compression of the image sequence, our method shows a high generalization capability and obtains a total loss of 0. [sent-214, score-0.517]
</p><p>84 2% of 384 mitosis events which is a signiﬁcant improvement over the mitosis detection rate reported in [12] (81. [sent-217, score-0.307]
</p><p>85 We sample positive associations from the ground truth and randomly generate false associations. [sent-221, score-0.31]
</p><p>86 The predicted probabilities by the RF classiﬁers are used to compute the overall association score as in Eq. [sent-223, score-0.129]
</p><p>87 Since we have multiple competing events (one cell can only have a single 6  mov  div  app  dis  spl  mer  Feature Importance (L2)  Importance  0. [sent-226, score-0.747]
</p><p>88 su fa fa an in d me m th th gl te ev an er er e n. [sent-244, score-0.209]
</p><p>89 p e i a s sh s cc nt tt um ap iz en en er e e tr si n ov er m co ev ic ty di la as mp en it st p s ac ne y an wi ev tn ss ce th en es n s d t b e diiff d o or ss di f . [sent-246, score-1.374]
</p><p>90 1  di  di  ff  Importance  Feature Importance (L1) 0. [sent-273, score-0.438]
</p><p>91 Parameters weighing the features for different events are colored differently. [sent-275, score-0.169]
</p><p>92 The header row shows the number of events occurring for moves, divisions, appearance, disappearance, splits and mergers. [sent-281, score-0.246]
</p><p>93 mov div app dis spl mer total loss 22520 384 310 304 127 132 Padﬁeld et al. [sent-283, score-0.414]
</p><p>94 To test the sensitivity of the results to the training data used, we drew different numbers of training image pairs randomly from the entire sequence and used the remaining pairs for testing. [sent-296, score-0.199]
</p><p>95 According to the one-standard-error-rule, associations between at least 15 or 20 image pairs are desirable, which can be accomplished in well below an hour of annotation work. [sent-300, score-0.359]
</p><p>96 L2)  25 20  L1 Regularization L2 Regularization  15 10 5 0 10  20  30  40  50  60  70  Number of constraints  Number of frame pairs for training  Figure 5: Learning curve of structured learning Figure 6: Convergence rates of structured learn(with L2 regularization). [sent-315, score-0.377]
</p><p>97 4  Conclusion & Future Work  We present a new cell tracking scheme that uses more expressive features and comes with a structured learning framework to train the larger number of parameters involved. [sent-318, score-0.756]
</p><p>98 We currently work on further improvement of the tracking by considering more than two frames at a time, and on an active learning scheme that should reduce the amount of required training inputs. [sent-320, score-0.486]
</p><p>99 CellCognition: time-resolved phenotype annotation in highthroughput live cell imaging. [sent-404, score-0.26]
</p><p>100 Cell population tracking and lineage construction with spatiotemporal context. [sent-440, score-0.391]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tracking', 0.342), ('associations', 0.31), ('cell', 0.26), ('ff', 0.24), ('zn', 0.212), ('mitocheck', 0.198), ('dcelliq', 0.148), ('en', 0.136), ('association', 0.129), ('mach', 0.12), ('candidates', 0.117), ('events', 0.111), ('frame', 0.11), ('tweaking', 0.109), ('pad', 0.109), ('object', 0.104), ('di', 0.099), ('divisions', 0.099), ('division', 0.098), ('nt', 0.098), ('structured', 0.096), ('move', 0.087), ('med', 0.087), ('moves', 0.08), ('te', 0.079), ('af', 0.076), ('training', 0.075), ('mitosis', 0.074), ('spl', 0.074), ('hypotheses', 0.072), ('frames', 0.069), ('parametrization', 0.068), ('compactness', 0.065), ('app', 0.065), ('mov', 0.065), ('disappearance', 0.065), ('mer', 0.065), ('manual', 0.065), ('nity', 0.065), ('bundle', 0.063), ('res', 0.063), ('ss', 0.063), ('intensity', 0.062), ('shape', 0.062), ('anal', 0.06), ('div', 0.06), ('features', 0.058), ('secondly', 0.058), ('ev', 0.056), ('divide', 0.056), ('split', 0.055), ('developmental', 0.053), ('artifacts', 0.051), ('cvpr', 0.05), ('didif', 0.049), ('diiff', 0.049), ('dzyubachyk', 0.049), ('evenness', 0.049), ('executables', 0.049), ('fate', 0.049), ('father', 0.049), ('header', 0.049), ('imag', 0.049), ('lapse', 0.049), ('lineage', 0.049), ('lou', 0.049), ('rankboost', 0.049), ('image', 0.049), ('ap', 0.049), ('detection', 0.048), ('dis', 0.047), ('regularization', 0.046), ('segmentation', 0.044), ('summed', 0.044), ('row', 0.043), ('experimentalists', 0.043), ('nuclei', 0.043), ('io', 0.043), ('gui', 0.043), ('crowded', 0.043), ('oversegmentation', 0.043), ('foregoing', 0.043), ('ilp', 0.043), ('si', 0.043), ('rf', 0.043), ('splits', 0.043), ('heidelberg', 0.042), ('firstly', 0.042), ('sh', 0.041), ('appearance', 0.04), ('compatibility', 0.04), ('multitude', 0.04), ('iz', 0.04), ('loss', 0.038), ('candidate', 0.038), ('learn', 0.038), ('afford', 0.037), ('pushes', 0.037), ('ze', 0.037), ('er', 0.037)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="275-tfidf-1" href="./nips-2011-Structured_Learning_for_Cell_Tracking.html">275 nips-2011-Structured Learning for Cell Tracking</a></p>
<p>Author: Xinghua Lou, Fred A. Hamprecht</p><p>Abstract: We study the problem of learning to track a large quantity of homogeneous objects such as cell tracking in cell culture study and developmental biology. Reliable cell tracking in time-lapse microscopic image sequences is important for modern biomedical research. Existing cell tracking methods are usually kept simple and use only a small number of features to allow for manual parameter tweaking or grid search. We propose a structured learning approach that allows to learn optimum parameters automatically from a training set. This allows for the use of a richer set of features which in turn affords improved tracking compared to recently reported methods on two public benchmark sequences. 1</p><p>2 0.17845595 <a title="275-tfidf-2" href="./nips-2011-Multiple_Instance_Filtering.html">180 nips-2011-Multiple Instance Filtering</a></p>
<p>Author: Kamil A. Wnuk, Stefano Soatto</p><p>Abstract: We propose a robust ﬁltering approach based on semi-supervised and multiple instance learning (MIL). We assume that the posterior density would be unimodal if not for the eﬀect of outliers that we do not wish to explicitly model. Therefore, we seek for a point estimate at the outset, rather than a generic approximation of the entire posterior. Our approach can be thought of as a combination of standard ﬁnite-dimensional ﬁltering (Extended Kalman Filter, or Unscented Filter) with multiple instance learning, whereby the initial condition comes with a putative set of inlier measurements. We show how both the state (regression) and the inlier set (classiﬁcation) can be estimated iteratively and causally by processing only the current measurement. We illustrate our approach on visual tracking problems whereby the object of interest (target) moves and evolves as a result of occlusions and deformations, and partial knowledge of the target is given in the form of a bounding box (training set). 1</p><p>3 0.13648948 <a title="275-tfidf-3" href="./nips-2011-Learning_Probabilistic_Non-Linear_Latent_Variable_Models_for_Tracking_Complex_Activities.html">148 nips-2011-Learning Probabilistic Non-Linear Latent Variable Models for Tracking Complex Activities</a></p>
<p>Author: Angela Yao, Juergen Gall, Luc V. Gool, Raquel Urtasun</p><p>Abstract: A common approach for handling the complexity and inherent ambiguities of 3D human pose estimation is to use pose priors learned from training data. Existing approaches however, are either too simplistic (linear), too complex to learn, or can only learn latent spaces from “simple data”, i.e., single activities such as walking or running. In this paper, we present an efﬁcient stochastic gradient descent algorithm that is able to learn probabilistic non-linear latent spaces composed of multiple activities. Furthermore, we derive an incremental algorithm for the online setting which can update the latent space without extensive relearning. We demonstrate the effectiveness of our approach on the task of monocular and multi-view tracking and show that our approach outperforms the state-of-the-art. 1</p><p>4 0.12875326 <a title="275-tfidf-4" href="./nips-2011-Video_Annotation_and_Tracking_with_Active_Learning.html">303 nips-2011-Video Annotation and Tracking with Active Learning</a></p>
<p>Author: Carl Vondrick, Deva Ramanan</p><p>Abstract: We introduce a novel active learning framework for video annotation. By judiciously choosing which frames a user should annotate, we can obtain highly accurate tracks with minimal user effort. We cast this problem as one of active learning, and show that we can obtain excellent performance by querying frames that, if annotated, would produce a large expected change in the estimated object track. We implement a constrained tracker and compute the expected change for putative annotations with efﬁcient dynamic programming algorithms. We demonstrate our framework on four datasets, including two benchmark datasets constructed with key frame annotations obtained by Amazon Mechanical Turk. Our results indicate that we could obtain equivalent labels for a small fraction of the original cost. 1</p><p>5 0.10966277 <a title="275-tfidf-5" href="./nips-2011-%24%5Ctheta%24-MRF%3A_Capturing_Spatial_and_Semantic_Structure_in_the_Parameters_for_Scene_Understanding.html">1 nips-2011-$\theta$-MRF: Capturing Spatial and Semantic Structure in the Parameters for Scene Understanding</a></p>
<p>Author: Congcong Li, Ashutosh Saxena, Tsuhan Chen</p><p>Abstract: For most scene understanding tasks (such as object detection or depth estimation), the classiﬁers need to consider contextual information in addition to the local features. We can capture such contextual information by taking as input the features/attributes from all the regions in the image. However, this contextual dependence also varies with the spatial location of the region of interest, and we therefore need a different set of parameters for each spatial location. This results in a very large number of parameters. In this work, we model the independence properties between the parameters for each location and for each task, by deﬁning a Markov Random Field (MRF) over the parameters. In particular, two sets of parameters are encouraged to have similar values if they are spatially close or semantically close. Our method is, in principle, complementary to other ways of capturing context such as the ones that use a graphical model over the labels instead. In extensive evaluation over two different settings, of multi-class object detection and of multiple scene understanding tasks (scene categorization, depth estimation, geometric labeling), our method beats the state-of-the-art methods in all the four tasks. 1</p><p>6 0.092906147 <a title="275-tfidf-6" href="./nips-2011-An_ideal_observer_model_for_identifying_the_reference_frame_of_objects.html">35 nips-2011-An ideal observer model for identifying the reference frame of objects</a></p>
<p>7 0.089360818 <a title="275-tfidf-7" href="./nips-2011-Simultaneous_Sampling_and_Multi-Structure_Fitting_with_Adaptive_Reversible_Jump_MCMC.html">255 nips-2011-Simultaneous Sampling and Multi-Structure Fitting with Adaptive Reversible Jump MCMC</a></p>
<p>8 0.087630346 <a title="275-tfidf-8" href="./nips-2011-Maximal_Cliques_that_Satisfy_Hard_Constraints_with_Application_to_Deformable_Object_Model_Learning.html">166 nips-2011-Maximal Cliques that Satisfy Hard Constraints with Application to Deformable Object Model Learning</a></p>
<p>9 0.085529819 <a title="275-tfidf-9" href="./nips-2011-Learning_person-object_interactions_for_action_recognition_in_still_images.html">154 nips-2011-Learning person-object interactions for action recognition in still images</a></p>
<p>10 0.08089488 <a title="275-tfidf-10" href="./nips-2011-Learning_a_Tree_of_Metrics_with_Disjoint_Visual_Features.html">151 nips-2011-Learning a Tree of Metrics with Disjoint Visual Features</a></p>
<p>11 0.080577999 <a title="275-tfidf-11" href="./nips-2011-On_Tracking_The_Partition_Function.html">197 nips-2011-On Tracking The Partition Function</a></p>
<p>12 0.079276606 <a title="275-tfidf-12" href="./nips-2011-Maximum_Margin_Multi-Label_Structured_Prediction.html">169 nips-2011-Maximum Margin Multi-Label Structured Prediction</a></p>
<p>13 0.078940012 <a title="275-tfidf-13" href="./nips-2011-Object_Detection_with_Grammar_Models.html">193 nips-2011-Object Detection with Grammar Models</a></p>
<p>14 0.078788273 <a title="275-tfidf-14" href="./nips-2011-Joint_3D_Estimation_of_Objects_and_Scene_Layout.html">138 nips-2011-Joint 3D Estimation of Objects and Scene Layout</a></p>
<p>15 0.076885037 <a title="275-tfidf-15" href="./nips-2011-Semantic_Labeling_of_3D_Point_Clouds_for_Indoor_Scenes.html">247 nips-2011-Semantic Labeling of 3D Point Clouds for Indoor Scenes</a></p>
<p>16 0.076821618 <a title="275-tfidf-16" href="./nips-2011-Demixed_Principal_Component_Analysis.html">68 nips-2011-Demixed Principal Component Analysis</a></p>
<p>17 0.075896718 <a title="275-tfidf-17" href="./nips-2011-Hierarchical_Multitask_Structured_Output_Learning_for_Large-scale_Sequence_Segmentation.html">114 nips-2011-Hierarchical Multitask Structured Output Learning for Large-scale Sequence Segmentation</a></p>
<p>18 0.075158127 <a title="275-tfidf-18" href="./nips-2011-Continuous-Time_Regression_Models_for_Longitudinal_Networks.html">62 nips-2011-Continuous-Time Regression Models for Longitudinal Networks</a></p>
<p>19 0.071830787 <a title="275-tfidf-19" href="./nips-2011-Why_The_Brain_Separates_Face_Recognition_From_Object_Recognition.html">304 nips-2011-Why The Brain Separates Face Recognition From Object Recognition</a></p>
<p>20 0.068203144 <a title="275-tfidf-20" href="./nips-2011-Pylon_Model_for_Semantic_Segmentation.html">227 nips-2011-Pylon Model for Semantic Segmentation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.213), (1, 0.09), (2, -0.078), (3, 0.111), (4, 0.052), (5, 0.009), (6, 0.007), (7, -0.066), (8, -0.017), (9, 0.09), (10, 0.018), (11, -0.073), (12, 0.027), (13, -0.026), (14, 0.014), (15, -0.045), (16, 0.021), (17, 0.03), (18, -0.051), (19, 0.043), (20, 0.027), (21, 0.048), (22, -0.008), (23, 0.044), (24, -0.037), (25, -0.053), (26, -0.204), (27, 0.111), (28, -0.073), (29, -0.036), (30, 0.062), (31, -0.048), (32, 0.113), (33, 0.001), (34, -0.055), (35, 0.019), (36, -0.005), (37, -0.082), (38, 0.078), (39, -0.044), (40, -0.019), (41, -0.005), (42, -0.051), (43, 0.053), (44, 0.07), (45, -0.029), (46, -0.047), (47, -0.055), (48, -0.075), (49, -0.035)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92931587 <a title="275-lsi-1" href="./nips-2011-Structured_Learning_for_Cell_Tracking.html">275 nips-2011-Structured Learning for Cell Tracking</a></p>
<p>Author: Xinghua Lou, Fred A. Hamprecht</p><p>Abstract: We study the problem of learning to track a large quantity of homogeneous objects such as cell tracking in cell culture study and developmental biology. Reliable cell tracking in time-lapse microscopic image sequences is important for modern biomedical research. Existing cell tracking methods are usually kept simple and use only a small number of features to allow for manual parameter tweaking or grid search. We propose a structured learning approach that allows to learn optimum parameters automatically from a training set. This allows for the use of a richer set of features which in turn affords improved tracking compared to recently reported methods on two public benchmark sequences. 1</p><p>2 0.8262862 <a title="275-lsi-2" href="./nips-2011-Multiple_Instance_Filtering.html">180 nips-2011-Multiple Instance Filtering</a></p>
<p>Author: Kamil A. Wnuk, Stefano Soatto</p><p>Abstract: We propose a robust ﬁltering approach based on semi-supervised and multiple instance learning (MIL). We assume that the posterior density would be unimodal if not for the eﬀect of outliers that we do not wish to explicitly model. Therefore, we seek for a point estimate at the outset, rather than a generic approximation of the entire posterior. Our approach can be thought of as a combination of standard ﬁnite-dimensional ﬁltering (Extended Kalman Filter, or Unscented Filter) with multiple instance learning, whereby the initial condition comes with a putative set of inlier measurements. We show how both the state (regression) and the inlier set (classiﬁcation) can be estimated iteratively and causally by processing only the current measurement. We illustrate our approach on visual tracking problems whereby the object of interest (target) moves and evolves as a result of occlusions and deformations, and partial knowledge of the target is given in the form of a bounding box (training set). 1</p><p>3 0.75364667 <a title="275-lsi-3" href="./nips-2011-Video_Annotation_and_Tracking_with_Active_Learning.html">303 nips-2011-Video Annotation and Tracking with Active Learning</a></p>
<p>Author: Carl Vondrick, Deva Ramanan</p><p>Abstract: We introduce a novel active learning framework for video annotation. By judiciously choosing which frames a user should annotate, we can obtain highly accurate tracks with minimal user effort. We cast this problem as one of active learning, and show that we can obtain excellent performance by querying frames that, if annotated, would produce a large expected change in the estimated object track. We implement a constrained tracker and compute the expected change for putative annotations with efﬁcient dynamic programming algorithms. We demonstrate our framework on four datasets, including two benchmark datasets constructed with key frame annotations obtained by Amazon Mechanical Turk. Our results indicate that we could obtain equivalent labels for a small fraction of the original cost. 1</p><p>4 0.66808361 <a title="275-lsi-4" href="./nips-2011-Learning_Probabilistic_Non-Linear_Latent_Variable_Models_for_Tracking_Complex_Activities.html">148 nips-2011-Learning Probabilistic Non-Linear Latent Variable Models for Tracking Complex Activities</a></p>
<p>Author: Angela Yao, Juergen Gall, Luc V. Gool, Raquel Urtasun</p><p>Abstract: A common approach for handling the complexity and inherent ambiguities of 3D human pose estimation is to use pose priors learned from training data. Existing approaches however, are either too simplistic (linear), too complex to learn, or can only learn latent spaces from “simple data”, i.e., single activities such as walking or running. In this paper, we present an efﬁcient stochastic gradient descent algorithm that is able to learn probabilistic non-linear latent spaces composed of multiple activities. Furthermore, we derive an incremental algorithm for the online setting which can update the latent space without extensive relearning. We demonstrate the effectiveness of our approach on the task of monocular and multi-view tracking and show that our approach outperforms the state-of-the-art. 1</p><p>5 0.62689471 <a title="275-lsi-5" href="./nips-2011-Object_Detection_with_Grammar_Models.html">193 nips-2011-Object Detection with Grammar Models</a></p>
<p>Author: Ross B. Girshick, Pedro F. Felzenszwalb, David A. McAllester</p><p>Abstract: Compositional models provide an elegant formalism for representing the visual appearance of highly variable objects. While such models are appealing from a theoretical point of view, it has been difﬁcult to demonstrate that they lead to performance advantages on challenging datasets. Here we develop a grammar model for person detection and show that it outperforms previous high-performance systems on the PASCAL benchmark. Our model represents people using a hierarchy of deformable parts, variable structure and an explicit model of occlusion for partially visible objects. To train the model, we introduce a new discriminative framework for learning structured prediction models from weakly-labeled data. 1</p><p>6 0.56124353 <a title="275-lsi-6" href="./nips-2011-Simultaneous_Sampling_and_Multi-Structure_Fitting_with_Adaptive_Reversible_Jump_MCMC.html">255 nips-2011-Simultaneous Sampling and Multi-Structure Fitting with Adaptive Reversible Jump MCMC</a></p>
<p>7 0.54437208 <a title="275-lsi-7" href="./nips-2011-Transfer_Learning_by_Borrowing_Examples_for_Multiclass_Object_Detection.html">290 nips-2011-Transfer Learning by Borrowing Examples for Multiclass Object Detection</a></p>
<p>8 0.53549558 <a title="275-lsi-8" href="./nips-2011-Maximal_Cliques_that_Satisfy_Hard_Constraints_with_Application_to_Deformable_Object_Model_Learning.html">166 nips-2011-Maximal Cliques that Satisfy Hard Constraints with Application to Deformable Object Model Learning</a></p>
<p>9 0.52891034 <a title="275-lsi-9" href="./nips-2011-Maximum_Margin_Multi-Label_Structured_Prediction.html">169 nips-2011-Maximum Margin Multi-Label Structured Prediction</a></p>
<p>10 0.52776814 <a title="275-lsi-10" href="./nips-2011-An_ideal_observer_model_for_identifying_the_reference_frame_of_objects.html">35 nips-2011-An ideal observer model for identifying the reference frame of objects</a></p>
<p>11 0.52669054 <a title="275-lsi-11" href="./nips-2011-Learning_person-object_interactions_for_action_recognition_in_still_images.html">154 nips-2011-Learning person-object interactions for action recognition in still images</a></p>
<p>12 0.5230096 <a title="275-lsi-12" href="./nips-2011-Joint_3D_Estimation_of_Objects_and_Scene_Layout.html">138 nips-2011-Joint 3D Estimation of Objects and Scene Layout</a></p>
<p>13 0.52173185 <a title="275-lsi-13" href="./nips-2011-On_Tracking_The_Partition_Function.html">197 nips-2011-On Tracking The Partition Function</a></p>
<p>14 0.46694085 <a title="275-lsi-14" href="./nips-2011-Semantic_Labeling_of_3D_Point_Clouds_for_Indoor_Scenes.html">247 nips-2011-Semantic Labeling of 3D Point Clouds for Indoor Scenes</a></p>
<p>15 0.45039773 <a title="275-lsi-15" href="./nips-2011-%24%5Ctheta%24-MRF%3A_Capturing_Spatial_and_Semantic_Structure_in_the_Parameters_for_Scene_Understanding.html">1 nips-2011-$\theta$-MRF: Capturing Spatial and Semantic Structure in the Parameters for Scene Understanding</a></p>
<p>16 0.44627589 <a title="275-lsi-16" href="./nips-2011-Nonstandard_Interpretations_of_Probabilistic_Programs_for_Efficient_Inference.html">192 nips-2011-Nonstandard Interpretations of Probabilistic Programs for Efficient Inference</a></p>
<p>17 0.43083557 <a title="275-lsi-17" href="./nips-2011-Submodular_Multi-Label_Learning.html">277 nips-2011-Submodular Multi-Label Learning</a></p>
<p>18 0.4254961 <a title="275-lsi-18" href="./nips-2011-A_Machine_Learning_Approach_to_Predict_Chemical_Reactions.html">7 nips-2011-A Machine Learning Approach to Predict Chemical Reactions</a></p>
<p>19 0.41231298 <a title="275-lsi-19" href="./nips-2011-ShareBoost%3A_Efficient_multiclass_learning_with_feature_sharing.html">252 nips-2011-ShareBoost: Efficient multiclass learning with feature sharing</a></p>
<p>20 0.41092712 <a title="275-lsi-20" href="./nips-2011-Target_Neighbor_Consistent_Feature_Weighting_for_Nearest_Neighbor_Classification.html">279 nips-2011-Target Neighbor Consistent Feature Weighting for Nearest Neighbor Classification</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.015), (4, 0.036), (20, 0.499), (26, 0.021), (31, 0.04), (33, 0.024), (43, 0.046), (45, 0.089), (57, 0.026), (74, 0.041), (83, 0.033), (84, 0.013), (99, 0.051)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.89873451 <a title="275-lda-1" href="./nips-2011-Transfer_Learning_by_Borrowing_Examples_for_Multiclass_Object_Detection.html">290 nips-2011-Transfer Learning by Borrowing Examples for Multiclass Object Detection</a></p>
<p>Author: Joseph J. Lim, Antonio Torralba, Ruslan Salakhutdinov</p><p>Abstract: Despite the recent trend of increasingly large datasets for object detection, there still exist many classes with few training examples. To overcome this lack of training data for certain classes, we propose a novel way of augmenting the training data for each class by borrowing and transforming examples from other classes. Our model learns which training instances from other classes to borrow and how to transform the borrowed examples so that they become more similar to instances from the target class. Our experimental results demonstrate that our new object detector, with borrowed and transformed examples, improves upon the current state-of-the-art detector on the challenging SUN09 object detection dataset. 1</p><p>same-paper 2 0.8929345 <a title="275-lda-2" href="./nips-2011-Structured_Learning_for_Cell_Tracking.html">275 nips-2011-Structured Learning for Cell Tracking</a></p>
<p>Author: Xinghua Lou, Fred A. Hamprecht</p><p>Abstract: We study the problem of learning to track a large quantity of homogeneous objects such as cell tracking in cell culture study and developmental biology. Reliable cell tracking in time-lapse microscopic image sequences is important for modern biomedical research. Existing cell tracking methods are usually kept simple and use only a small number of features to allow for manual parameter tweaking or grid search. We propose a structured learning approach that allows to learn optimum parameters automatically from a training set. This allows for the use of a richer set of features which in turn affords improved tracking compared to recently reported methods on two public benchmark sequences. 1</p><p>3 0.88532639 <a title="275-lda-3" href="./nips-2011-Higher-Order_Correlation_Clustering_for_Image_Segmentation.html">119 nips-2011-Higher-Order Correlation Clustering for Image Segmentation</a></p>
<p>Author: Sungwoong Kim, Sebastian Nowozin, Pushmeet Kohli, Chang D. Yoo</p><p>Abstract: For many of the state-of-the-art computer vision algorithms, image segmentation is an important preprocessing step. As such, several image segmentation algorithms have been proposed, however, with certain reservation due to high computational load and many hand-tuning parameters. Correlation clustering, a graphpartitioning algorithm often used in natural language processing and document clustering, has the potential to perform better than previously proposed image segmentation algorithms. We improve the basic correlation clustering formulation by taking into account higher-order cluster relationships. This improves clustering in the presence of local boundary ambiguities. We ﬁrst apply the pairwise correlation clustering to image segmentation over a pairwise superpixel graph and then develop higher-order correlation clustering over a hypergraph that considers higher-order relations among superpixels. Fast inference is possible by linear programming relaxation, and also effective parameter learning framework by structured support vector machine is possible. Experimental results on various datasets show that the proposed higher-order correlation clustering outperforms other state-of-the-art image segmentation algorithms.</p><p>4 0.87550735 <a title="275-lda-4" href="./nips-2011-k-NN_Regression_Adapts_to_Local_Intrinsic_Dimension.html">305 nips-2011-k-NN Regression Adapts to Local Intrinsic Dimension</a></p>
<p>Author: Samory Kpotufe</p><p>Abstract: Many nonparametric regressors were recently shown to converge at rates that depend only on the intrinsic dimension of data. These regressors thus escape the curse of dimension when high-dimensional data has low intrinsic dimension (e.g. a manifold). We show that k-NN regression is also adaptive to intrinsic dimension. In particular our rates are local to a query x and depend only on the way masses of balls centered at x vary with radius. Furthermore, we show a simple way to choose k = k(x) locally at any x so as to nearly achieve the minimax rate at x in terms of the unknown intrinsic dimension in the vicinity of x. We also establish that the minimax rate does not depend on a particular choice of metric space or distribution, but rather that this minimax rate holds for any metric space and doubling measure. 1</p><p>5 0.78831798 <a title="275-lda-5" href="./nips-2011-Sparse_Features_for_PCA-Like_Linear_Regression.html">260 nips-2011-Sparse Features for PCA-Like Linear Regression</a></p>
<p>Author: Christos Boutsidis, Petros Drineas, Malik Magdon-Ismail</p><p>Abstract: Principal Components Analysis (PCA) is often used as a feature extraction procedure. Given a matrix X ∈ Rn×d , whose rows represent n data points with respect to d features, the top k right singular vectors of X (the so-called eigenfeatures), are arbitrary linear combinations of all available features. The eigenfeatures are very useful in data analysis, including the regularization of linear regression. Enforcing sparsity on the eigenfeatures, i.e., forcing them to be linear combinations of only a small number of actual features (as opposed to all available features), can promote better generalization error and improve the interpretability of the eigenfeatures. We present deterministic and randomized algorithms that construct such sparse eigenfeatures while provably achieving in-sample performance comparable to regularized linear regression. Our algorithms are relatively simple and practically efﬁcient, and we demonstrate their performance on several data sets.</p><p>6 0.53792888 <a title="275-lda-6" href="./nips-2011-Probabilistic_Joint_Image_Segmentation_and_Labeling.html">223 nips-2011-Probabilistic Joint Image Segmentation and Labeling</a></p>
<p>7 0.5157252 <a title="275-lda-7" href="./nips-2011-Learning_person-object_interactions_for_action_recognition_in_still_images.html">154 nips-2011-Learning person-object interactions for action recognition in still images</a></p>
<p>8 0.50445241 <a title="275-lda-8" href="./nips-2011-Pylon_Model_for_Semantic_Segmentation.html">227 nips-2011-Pylon Model for Semantic Segmentation</a></p>
<p>9 0.48739725 <a title="275-lda-9" href="./nips-2011-Video_Annotation_and_Tracking_with_Active_Learning.html">303 nips-2011-Video Annotation and Tracking with Active Learning</a></p>
<p>10 0.47189099 <a title="275-lda-10" href="./nips-2011-%24%5Ctheta%24-MRF%3A_Capturing_Spatial_and_Semantic_Structure_in_the_Parameters_for_Scene_Understanding.html">1 nips-2011-$\theta$-MRF: Capturing Spatial and Semantic Structure in the Parameters for Scene Understanding</a></p>
<p>11 0.46734571 <a title="275-lda-11" href="./nips-2011-Composite_Multiclass_Losses.html">59 nips-2011-Composite Multiclass Losses</a></p>
<p>12 0.46325305 <a title="275-lda-12" href="./nips-2011-Maximal_Cliques_that_Satisfy_Hard_Constraints_with_Application_to_Deformable_Object_Model_Learning.html">166 nips-2011-Maximal Cliques that Satisfy Hard Constraints with Application to Deformable Object Model Learning</a></p>
<p>13 0.45895788 <a title="275-lda-13" href="./nips-2011-Sparse_Manifold_Clustering_and_Embedding.html">263 nips-2011-Sparse Manifold Clustering and Embedding</a></p>
<p>14 0.45844731 <a title="275-lda-14" href="./nips-2011-Optimistic_Optimization_of_a_Deterministic_Function_without_the_Knowledge_of_its_Smoothness.html">208 nips-2011-Optimistic Optimization of a Deterministic Function without the Knowledge of its Smoothness</a></p>
<p>15 0.45220694 <a title="275-lda-15" href="./nips-2011-Why_The_Brain_Separates_Face_Recognition_From_Object_Recognition.html">304 nips-2011-Why The Brain Separates Face Recognition From Object Recognition</a></p>
<p>16 0.44888827 <a title="275-lda-16" href="./nips-2011-Semantic_Labeling_of_3D_Point_Clouds_for_Indoor_Scenes.html">247 nips-2011-Semantic Labeling of 3D Point Clouds for Indoor Scenes</a></p>
<p>17 0.44826919 <a title="275-lda-17" href="./nips-2011-Spatial_distance_dependent_Chinese_restaurant_processes_for_image_segmentation.html">266 nips-2011-Spatial distance dependent Chinese restaurant processes for image segmentation</a></p>
<p>18 0.44325721 <a title="275-lda-18" href="./nips-2011-Multiple_Instance_Filtering.html">180 nips-2011-Multiple Instance Filtering</a></p>
<p>19 0.44267726 <a title="275-lda-19" href="./nips-2011-Efficient_Inference_in_Fully_Connected_CRFs_with_Gaussian_Edge_Potentials.html">76 nips-2011-Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials</a></p>
<p>20 0.44134146 <a title="275-lda-20" href="./nips-2011-Adaptive_Hedge.html">25 nips-2011-Adaptive Hedge</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
