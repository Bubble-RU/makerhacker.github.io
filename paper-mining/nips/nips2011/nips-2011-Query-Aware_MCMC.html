<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>229 nips-2011-Query-Aware MCMC</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-229" href="#">nips2011-229</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>229 nips-2011-Query-Aware MCMC</h1>
<br/><p>Source: <a title="nips-2011-229-pdf" href="http://papers.nips.cc/paper/4237-query-aware-mcmc.pdf">pdf</a></p><p>Author: Michael L. Wick, Andrew McCallum</p><p>Abstract: Traditional approaches to probabilistic inference such as loopy belief propagation and Gibbs sampling typically compute marginals for all the unobserved variables in a graphical model. However, in many real-world applications the user’s interests are focused on a subset of the variables, speciﬁed by a query. In this case it would be wasteful to uniformly sample, say, one million variables when the query concerns only ten. In this paper we propose a query-speciﬁc approach to MCMC that accounts for the query variables and their generalized mutual information with neighboring variables in order to achieve higher computational efﬁciency. Surprisingly there has been almost no previous work on query-aware MCMC. We demonstrate the success of our approach with positive experimental results on a wide range of graphical models. 1</p><p>Reference: <a title="nips-2011-229-reference" href="../nips2011_reference/nips-2011-Query-Aware_MCMC_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu  Abstract Traditional approaches to probabilistic inference such as loopy belief propagation and Gibbs sampling typically compute marginals for all the unobserved variables in a graphical model. [sent-5, score-0.634]
</p><p>2 In this case it would be wasteful to uniformly sample, say, one million variables when the query concerns only ten. [sent-7, score-0.558]
</p><p>3 In this paper we propose a query-speciﬁc approach to MCMC that accounts for the query variables and their generalized mutual information with neighboring variables in order to achieve higher computational efﬁciency. [sent-8, score-0.763]
</p><p>4 1  Introduction  Graphical models are useful for representing relationships between large numbers of random variables in probabilistic models spanning a wide range of applications, including information extraction and data integration. [sent-11, score-0.23]
</p><p>5 Exact inference in these models is often computationally intractable due to the dense dependency structures required in many real world problems, thus there exists a large body of work on both variational and sampling approximations to inference that help manage large treewidth. [sent-12, score-0.265]
</p><p>6 The proliferation of interconnected data and the desire to model it has given rise to graphical models with millions or even billions of random variables. [sent-14, score-0.194]
</p><p>7 Unfortunately, there has been little research devoted to approximate inference in graphical models that are large in terms of their number of variables. [sent-15, score-0.245]
</p><p>8 Fortunately, many inference needs are instigated by queries issued by users interested in particular random variables. [sent-17, score-0.201]
</p><p>9 In these situations not all variables are of equal relevance to the user’s query; some variables become observed given the query, others become statistically independent given the query, and the remaining variables are typically marginalized. [sent-22, score-0.326]
</p><p>10 Thus, a user-generated query provides a tremendous amount of information that can be exploited by an intelligent inference procedure. [sent-23, score-0.542]
</p><p>11 Unfortunately, traditional approaches to inference such as loopy belief propagation (BP) and Gibbs sampling are query agnostic in the sense that they fail to take advantage of this knowledge and treat each variable as equally relevant. [sent-24, score-0.869]
</p><p>12 Surprisingly, there has been little research on query speciﬁc inference and the only existing approaches focus on loopy BP [3, 4]. [sent-25, score-0.591]
</p><p>13 In this paper we propose a query-aware approach to Markov chain Monte Carlo (QAM) that exploits the dependency structure of the graph and the query to achieve faster convergence to the answer. [sent-26, score-0.696]
</p><p>14 Our method selects variables for sampling in proportion to their inﬂuence on the query variables. [sent-27, score-0.633]
</p><p>15 We 1  determine this inﬂuence using a computationally tractable generalization of mutual information between the query variables and each variable in the graph. [sent-28, score-0.743]
</p><p>16 Because our query-speciﬁc approach to inference is based on MCMC, we can provide arbitrarily close approximations to the query answer while also scaling to graphs whose structure and unrolled factor density would ordinarily preclude both exact and belief propagation inference methods. [sent-29, score-0.777]
</p><p>17 This is essential for the method to be deployable in real-world probabilistic databases where even a seemingly innocuous relational algebra query over a simple fully independent structure can produce an inference problem that is #P-hard [5]. [sent-30, score-0.749]
</p><p>18 We demonstrate dramatic improvements over traditional Markov chain Monte Carlo sampling methods across a wide array of models of diverse structure. [sent-31, score-0.277]
</p><p>19 A factor graph G := x, ψ is a bipartite graph consisting of n random variables x = {xi }n and m factors ψ = {ψi }m . [sent-34, score-0.182]
</p><p>20 Each variable xi has a domain Xi , and we notate the entire 1 1 domain space of the random variables (x) as X with associated σ-algebra Ω. [sent-35, score-0.24]
</p><p>21 2  Queries on Graphical Models  Informally, a query on a graphical model is a request for some quantity of interest that the graphical model is capable of providing. [sent-40, score-0.734]
</p><p>22 That is, a query is a function mapping the graphical model to an answer set. [sent-41, score-0.669]
</p><p>23 While in the general case, a query may contain arbitrary functions over the support of a graphical model, for this work we consider queries of the marginal form. [sent-43, score-0.776]
</p><p>24 That is a query Q consists of three parts Q = xq , xl , xe . [sent-44, score-1.21]
</p><p>25 Where xq is the set of query variables whose marginal distributions (or MAP conﬁguration) are the answer to the query, xe is a set of evidence variables whose values are observed, and xl is the set of latent variables over which one typically marginalizes to obtain the statistically sound answer. [sent-45, score-1.709]
</p><p>26 Note that this class of queries is remarkably general and includes queries that require expectations over arbitrary functions. [sent-46, score-0.238]
</p><p>27 We can see this because a function over the graphical model (or a subset of the graphical model) is itself a random variable, and can therefore be included in xq . [sent-47, score-0.666]
</p><p>28 1 More precisely, a query over a graphical model is: Q(xq , xl , xe , π) = π(xq |xe = ve ) =  π(xq , xl |xe = ve )  (2)  vl  we assume that Ω is well deﬁned with respect to marginalization over arbitrary subsets of variables. [sent-48, score-1.417]
</p><p>29 3  Markov Chain Monte Carlo  Markov chain Monte Carlo (MCMC) is an important inference method for graphical models where computing the normalization constant Z is intractable. [sent-50, score-0.377]
</p><p>30 However, many of the results 1 Research in probabilistic databases has demonstrated that a large class of relational algebra queries can be represented as graphical models and answered using statistical queries of the this form [6, 7]. [sent-54, score-0.578]
</p><p>31 Markov chain Monte Carlo produces a sequence of states {si }∞ in a state space S according to 1 a transition kernel K : S × S → R+ , which in the discrete case is a stochastic matrix: for all s ∈ S K(s, ·) is a valid probability measure and for all s ∈ S K(·, s) is a measurable function. [sent-56, score-0.25]
</p><p>32 Since we are concerned with MCMC for inference in graphical models, we will from now on let S:=X, and use X instead. [sent-57, score-0.219]
</p><p>33 Under certain conditions the Markov chain is said to be ergodic, then the chain exhibits two types of convergence. [sent-58, score-0.264]
</p><p>34 At each time step, the Markov chain is in a time-speciﬁc distribution over the state space (encoding the probability of being in a particular state at time t). [sent-61, score-0.251]
</p><p>35 Under certain conditions and regardless of the initial distribution, the Markov chain will converge to the stationary (invariant) distribution π. [sent-64, score-0.211]
</p><p>36 4  MCMC Inference in Graphical Models  MCMC is used for inference in graphical models by constructing a Markov chain with invariant distribution π (given by the graphical model). [sent-67, score-0.617]
</p><p>37 As a result, generating samples from graphical models with Metropolis-Hastings is usually inexpensive. [sent-71, score-0.163]
</p><p>38 3  3  Query Speciﬁc MCMC  Given a query Q = xq , xl , xe , and a probability distribution π encoded by a graphical model G with factors ψ and random variables x, the problem of query speciﬁc inference is to return the highest ﬁdelity answer to Q given a possible time budget. [sent-72, score-2.128]
</p><p>39 We can put more precision on this statement by deﬁning “highest ﬁdelity” as closest to the truth in total variation distance. [sent-73, score-0.154]
</p><p>40 Our approach for query speciﬁc inference is based on the Metropolis Hastings algorithm described in Section 2. [sent-74, score-0.542]
</p><p>41 2: Sample a new value for xi according to some distribution q(Xi ) over that variable’s domain, leave all other variables unchanged and return the new state s . [sent-77, score-0.24]
</p><p>42 In brief, this strategy arrives at a new state s from a current state s by simply updating the value of one variable at a time. [sent-78, score-0.16]
</p><p>43 In traditional MCMC inference, where the marginal distributions of all variables are of equal interest, the variables are usually sampled in a deterministic order, or selected 1 uniformly at random; that is, p(i) = n induces a uniform distribution over the integers 1, 2, · · · , n. [sent-79, score-0.394]
</p><p>44 However, given a query Q, it is reasonable to choose a p that more frequently selects the query variables for sampling. [sent-80, score-1.018]
</p><p>45 Clearly, the query variable marginals depend on the remaining latent variables, so we must tradeoff sampling between query and non-query variables. [sent-81, score-1.179]
</p><p>46 A key observation is that not all latent variables inﬂuence the query variables equally. [sent-82, score-0.697]
</p><p>47 A fundamental question raised and addressed in this paper is: how do we pick a variable selection distribution p for a query Q to obtain the highest ﬁdelity answer under a ﬁnite time budget. [sent-83, score-0.647]
</p><p>48 We propose to select variables based on their inﬂuence on the query variable according to the graphical model. [sent-84, score-0.773]
</p><p>49 The π(x,y) mutual information I(x, y) = π(x, y) log( π(x)π(y) ) between two random variables measures the strength of their dependence. [sent-86, score-0.205]
</p><p>50 It is easy to check that this quantity is the KL divergence between the joint distribution of the variables and the product of the marginals: I(x, y) = KL(π(x, y)||π(x)π(y)). [sent-87, score-0.163]
</p><p>51 Let x and y be two random variables with marginal distributions π(x, y),π(x), π(y). [sent-92, score-0.158]
</p><p>52 The inﬂuence ι(x, y) between x and y is ι(x, y) := f (π(x, y), π(x)π(y))  (8)  If we let f be the KL divergence then ι becomes the mutual information; however, because MCMC convergence is more commonly assessed with total variation norm, we deﬁne an inﬂuence metric based on this choice for f . [sent-94, score-0.367]
</p><p>53 In particular we deﬁne ιtv (x, y) := π(x, y) − π(x)π(y) tv . [sent-95, score-0.261]
</p><p>54 As we will now show, the total variation inﬂuence (between the query variable and the latent variables) has the important property that it is exactly the error incurred from ignoring a single latent variable when sampling values for xq . [sent-96, score-1.351]
</p><p>55 For example, suppose we design an approximate query speciﬁc sampler that saves computational resources by ignoring a particular random variable xl . [sent-97, score-0.823]
</p><p>56 Then, the variable xl will remain at its burned-in value xl =vl for the duration of query speciﬁc sampling. [sent-98, score-1.056]
</p><p>57 As a result, the chain will converge to the invariant distribution π(·|xl =vl ). [sent-99, score-0.235]
</p><p>58 If we use this conditional distribution to approximate the marginal, then the expected error we incur is exactly the inﬂuence score under total variation distance. [sent-100, score-0.221]
</p><p>59 If p(i) = 1(i = l) n−1 induces an MH kernel that neglects variable xl , then the expected total variation error ξtv of the resulting MH sampling procedure under the model is the total variation inﬂuence ιtv . [sent-102, score-0.757]
</p><p>60 4  Proof: The resulting chain has stationary distribution π(xq |xl = vl ). [sent-103, score-0.414]
</p><p>61 We are now justiﬁed in selecting variables proportional to their inﬂuence to reduce the error they assert on the query marginal. [sent-105, score-0.558]
</p><p>62 Note, however, that computing either ιtv or the mutual information is as difﬁcult as inference itself. [sent-107, score-0.189]
</p><p>63 Thus, we deﬁne a computationally efﬁcient variant of inﬂuence that we term the inﬂuence trail score. [sent-108, score-0.162]
</p><p>64 The idea is to approximate the true inﬂuence as a product of factors along an active trail in the graph. [sent-109, score-0.194]
</p><p>65 Let ρ = (x0 , x1 , · · · , xr ) be an active trail between the query variable xq and xi where x0 = xq and xr = xi . [sent-111, score-1.612]
</p><p>66 Let φ(xi , xj ) be the approximate joint distribution between xi and xj according only to the mutual factors in their scopes. [sent-112, score-0.24]
</p><p>67 The inﬂuence trail score with respect to an active trail ρ is r−1  τρ (xq , xi ) :=  f (φi (xi , xi+1 ), φi (xi )φi (xi+1 ))  (9)  i=1  The inﬂuence trail score is efﬁcient to compute because all factors and variables outside the mutual scopes of each variable pair are ignored. [sent-114, score-0.925]
</p><p>68 In the experimental results we evaluate both the inﬂuence and the inﬂuence trail and ﬁnd that they perform similarly and outperform competing graph-based heuristics for determining p. [sent-115, score-0.162]
</p><p>69 While in general it is difﬁcult to uniformly state that one choice of p converges faster than another for all models and queries, we present the following analysis showing that even an approximate query aware sampler can exhibit faster ﬁnite time convergence progress than an exact sampler. [sent-116, score-0.703]
</p><p>70 Let K be an exact MCMC kernel that converges to the correct stationary distribution and let L be an approximate kernel that exclusively samples the query variable and thus converges to the conditional distribution of the query variable. [sent-117, score-1.254]
</p><p>71 Extrapolating Proposition 1, we know that the error incurred from neglecting to sample the latent variables is the inﬂuence ιtv between the joint distribution of the latent variables and the query variable. [sent-119, score-0.84]
</p><p>72 Observe that L is simultaneously making progress towards two distributions: its own invariant distribution and the invariant distribution of K plus an error term. [sent-120, score-0.206]
</p><p>73 The amount of time that L (the query only kernel) is closer to K’s stationary distribution πk can be determined by solving for t, 5  yielding the ﬁxed point iteration: t=  log (γlt + ιtv ) log γk  (13)  +ι The one-step approximation yields a non-trivial, but conservative bound: t ≥ log(γlγk tv ) . [sent-122, score-0.8]
</p><p>74 This implies that the strategy of exclusively sampling the query variables can achieve faster short-term convergence to the correct invariant distribution even though asymptotic convergence is to the incorrect invariant distribution. [sent-124, score-0.958]
</p><p>75 The decayed MCMC algorithm for ﬁltering [12] can be thought of as a special case of our method where the model is a linear chain, and the query is for the last variable in the sequence. [sent-129, score-0.571]
</p><p>76 MCMC has also recently been deployed in probabilistic databases [13] where it is possible to incorporate the deterministic constraints of a relational algebra query directly into a Metropolis-Hastings proposal distribution to obtain quicker answers [14, 15]. [sent-132, score-0.702]
</p><p>77 A related idea from statistics is data augmentation (or auxiliary variable) approaches to sampling where latent variables are artiﬁcially introduced into the model to improve convergence of the original variables (e. [sent-133, score-0.39]
</p><p>78 In this setting, we see QAM as a way of determining a more sophisticated variable selection strategy that can balance sampling efforts between the original and auxiliary variables. [sent-136, score-0.153]
</p><p>79 5  Experiments  In this section we demonstrate the effectiveness and broad applicability of query aware MCMC (QAM) by demonstrating superior convergence rates to the query marginals across a diverse range of graphical models that vary widely in structure. [sent-137, score-1.265]
</p><p>80 In our experiments, we generate a wide range of graphical models and evaluate the convergence of each chain exactly, avoiding noisy empirical sampling error by performing exact computations with full transition kernels. [sent-138, score-0.488]
</p><p>81 Query-only Metropolis-Hastings (qo): p(xi ) = 1(xq = xi ); on six different graphical models with varying parameters generated from a Beta(2,2) distribution (this ensures an interesting dynamic range over the event space). [sent-145, score-0.305]
</p><p>82 For our experiments we randomly generate ten parameter settings for each of the six model types and measure convergence of the six chains to the the single-variable marginal query π(xq ) for each variable in each of the sixty realized models. [sent-154, score-0.824]
</p><p>83 Convergence is measured using the total variation norm: π(xq ) − π(xq )(t) tv . [sent-155, score-0.415]
</p><p>84 Generally, all the query speciﬁc sampling chains converge more quickly than the uniform baseline in the early iterations across every model. [sent-158, score-0.688]
</p><p>85 The query-only and mutual information chain exhibit the most rapid convergence in the early stages of learning, with the query-only chain converging to an incorrect distribution, and the mutual information chain slowly converging during the later time stages. [sent-160, score-0.778]
</p><p>86 Finally, notice that the inﬂuence-trail variant of total variation inﬂuence converges at a similar rate to the actual total variation inﬂuence, and in some cases converges more quickly (e. [sent-162, score-0.404]
</p><p>87 In the next experiment, we demonstrate how the size of the graphical model affects convergence of the various chains. [sent-165, score-0.215]
</p><p>88 In particular, we plot the convergence of all chains on six different hoop-structured models containing three, four, six, eight, ten, and twelve variables (Figure 2). [sent-166, score-0.309]
</p><p>89 That is we measure the difference in convergence rates t t π − π0 KUnif tv − π − π0 KQAM tv so that points above the line x = 0 mean the QAM is closer to the answer than the uniform baseline and points below the line mean the QAM is further from the answer. [sent-168, score-0.729]
</p><p>90 As expected, increasing the number of variables in the graph increases the opportunities for query speciﬁc sampling and thus increases QAM’s advantage over traditional MCMC. [sent-169, score-0.703]
</p><p>91 6  Conclusion  In this paper we presented a query-aware approach to MCMC, motivated by the need to answer queries over large scale graphical models. [sent-170, score-0.328]
</p><p>92 We found that the query-aware sampling methods outperform the traditional Metropolis Hastings sampler across all models in the early time steps. [sent-171, score-0.171]
</p><p>93 Further, as the number of variables in the models increase, the query aware samplers not only outperform the baseline for longer periods of time, but also exhibit more dramatic convergence rate improvements. [sent-172, score-0.755]
</p><p>94 Thus, query speciﬁc sampling is a promising approach for approximately answering queries on realworld probabilistic databases (and relational models) that contain billions of variables. [sent-173, score-0.832]
</p><p>95 An exciting area of future work is to combine query speciﬁc sampling with adaptive MCMC techniques allowing the kernel to evolve in response to the underlying distribution. [sent-175, score-0.572]
</p><p>96 There has been little theoretical work on analyzing marginal convergence of MCMC chains and future work can help develop these tools. [sent-177, score-0.204]
</p><p>97 20  Time  0  10  20  Time  30  40  50  0  10  Time  20  30 Time  Figure 1: Convergence to the query marginals of the stationary distribution from an initial uniform distribution. [sent-203, score-0.661]
</p><p>98 10  Time  8 Variables  Improvement over uniform  Time  0  10  20  30  Time  Figure 2: Improvement over uniform p as the number of variables increases. [sent-222, score-0.212]
</p><p>99 As number of variables increase, the improvements of the query speciﬁc techniques increase. [sent-224, score-0.558]
</p><p>100 BayesStore: Managing large, uncertain data repositories with probabilistic graphical models. [sent-252, score-0.184]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('query', 0.46), ('xq', 0.392), ('tv', 0.261), ('xl', 0.259), ('vl', 0.203), ('mcmc', 0.194), ('qam', 0.164), ('uence', 0.163), ('trail', 0.162), ('graphical', 0.137), ('chain', 0.132), ('queries', 0.119), ('variation', 0.116), ('mutual', 0.107), ('xe', 0.099), ('variables', 0.098), ('inference', 0.082), ('wick', 0.082), ('variable', 0.078), ('convergence', 0.078), ('sampling', 0.075), ('answer', 0.072), ('chains', 0.066), ('hastings', 0.066), ('invariant', 0.066), ('marginals', 0.065), ('xi', 0.064), ('marginal', 0.06), ('databases', 0.06), ('uniform', 0.057), ('samplers', 0.054), ('metropolis', 0.054), ('delity', 0.054), ('loopy', 0.049), ('markov', 0.047), ('probabilistic', 0.047), ('vq', 0.047), ('joseph', 0.045), ('propagation', 0.044), ('traditional', 0.044), ('lt', 0.042), ('vldb', 0.042), ('stationary', 0.042), ('six', 0.041), ('daisy', 0.041), ('garofalakis', 0.041), ('gerome', 0.041), ('hoop', 0.041), ('kmh', 0.041), ('minos', 0.041), ('zhe', 0.041), ('state', 0.041), ('mh', 0.041), ('mccallum', 0.041), ('latent', 0.041), ('transition', 0.04), ('relational', 0.04), ('stages', 0.04), ('aware', 0.039), ('connected', 0.039), ('michael', 0.039), ('andrew', 0.038), ('total', 0.038), ('kernel', 0.037), ('distribution', 0.037), ('belief', 0.037), ('stats', 0.036), ('coreference', 0.036), ('advancement', 0.036), ('iarpa', 0.036), ('carlo', 0.035), ('improvement', 0.034), ('monte', 0.034), ('neglecting', 0.033), ('decayed', 0.033), ('converges', 0.033), ('extraction', 0.033), ('incurred', 0.032), ('factors', 0.032), ('statistically', 0.032), ('distance', 0.031), ('billions', 0.031), ('kl', 0.031), ('algebra', 0.03), ('quickly', 0.03), ('score', 0.03), ('fully', 0.03), ('ergodic', 0.03), ('bases', 0.029), ('proposal', 0.028), ('cancels', 0.028), ('divergence', 0.028), ('massachusetts', 0.028), ('amherst', 0.027), ('contract', 0.026), ('pw', 0.026), ('sampler', 0.026), ('graph', 0.026), ('models', 0.026), ('converging', 0.025)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999952 <a title="229-tfidf-1" href="./nips-2011-Query-Aware_MCMC.html">229 nips-2011-Query-Aware MCMC</a></p>
<p>Author: Michael L. Wick, Andrew McCallum</p><p>Abstract: Traditional approaches to probabilistic inference such as loopy belief propagation and Gibbs sampling typically compute marginals for all the unobserved variables in a graphical model. However, in many real-world applications the user’s interests are focused on a subset of the variables, speciﬁed by a query. In this case it would be wasteful to uniformly sample, say, one million variables when the query concerns only ten. In this paper we propose a query-speciﬁc approach to MCMC that accounts for the query variables and their generalized mutual information with neighboring variables in order to achieve higher computational efﬁciency. Surprisingly there has been almost no previous work on query-aware MCMC. We demonstrate the success of our approach with positive experimental results on a wide range of graphical models. 1</p><p>2 0.1573371 <a title="229-tfidf-2" href="./nips-2011-Randomized_Algorithms_for_Comparison-based_Search.html">231 nips-2011-Randomized Algorithms for Comparison-based Search</a></p>
<p>Author: Dominique Tschopp, Suhas Diggavi, Payam Delgosha, Soheil Mohajer</p><p>Abstract: This paper addresses the problem of ﬁnding the nearest neighbor (or one of the R-nearest neighbors) of a query object q in a database of n objects, when we can only use a comparison oracle. The comparison oracle, given two reference objects and a query object, returns the reference object most similar to the query object. The main problem we study is how to search the database for the nearest neighbor (NN) of a query, while minimizing the questions. The difﬁculty of this problem depends on properties of the underlying database. We show the importance of a characterization: combinatorial disorder D which deﬁnes approximate triangle n inequalities on ranks. We present a lower bound of Ω(D log D + D2 ) average number of questions in the search phase for any randomized algorithm, which demonstrates the fundamental role of D for worst case behavior. We develop 3 a randomized scheme for NN retrieval in O(D3 log2 n + D log2 n log log nD ) 3 questions. The learning requires asking O(nD3 log2 n + D log2 n log log nD ) questions and O(n log2 n/ log(2D)) bits to store.</p><p>3 0.15614508 <a title="229-tfidf-3" href="./nips-2011-Active_Ranking_using_Pairwise_Comparisons.html">22 nips-2011-Active Ranking using Pairwise Comparisons</a></p>
<p>Author: Kevin G. Jamieson, Robert Nowak</p><p>Abstract: This paper examines the problem of ranking a collection of objects using pairwise comparisons (rankings of two objects). In general, the ranking of n objects can be identiﬁed by standard sorting methods using n log2 n pairwise comparisons. We are interested in natural situations in which relationships among the objects may allow for ranking using far fewer pairwise comparisons. Speciﬁcally, we assume that the objects can be embedded into a d-dimensional Euclidean space and that the rankings reﬂect their relative distances from a common reference point in Rd . We show that under this assumption the number of possible rankings grows like n2d and demonstrate an algorithm that can identify a randomly selected ranking using just slightly more than d log n adaptively selected pairwise comparisons, on average. If instead the comparisons are chosen at random, then almost all pairwise comparisons must be made in order to identify any ranking. In addition, we propose a robust, error-tolerant algorithm that only requires that the pairwise comparisons are probably correct. Experimental studies with synthetic and real datasets support the conclusions of our theoretical analysis. 1</p><p>4 0.13594514 <a title="229-tfidf-4" href="./nips-2011-Variational_Gaussian_Process_Dynamical_Systems.html">301 nips-2011-Variational Gaussian Process Dynamical Systems</a></p>
<p>Author: Neil D. Lawrence, Michalis K. Titsias, Andreas Damianou</p><p>Abstract: High dimensional time series are endemic in applications of machine learning such as robotics (sensor data), computational biology (gene expression data), vision (video sequences) and graphics (motion capture data). Practical nonlinear probabilistic approaches to this data are required. In this paper we introduce the variational Gaussian process dynamical system. Our work builds on recent variational approximations for Gaussian process latent variable models to allow for nonlinear dimensionality reduction simultaneously with learning a dynamical prior in the latent space. The approach also allows for the appropriate dimensionality of the latent space to be automatically determined. We demonstrate the model on a human motion capture data set and a series of high resolution video sequences. 1</p><p>5 0.13386175 <a title="229-tfidf-5" href="./nips-2011-Projection_onto_A_Nonnegative_Max-Heap.html">226 nips-2011-Projection onto A Nonnegative Max-Heap</a></p>
<p>Author: Jun Liu, Liang Sun, Jieping Ye</p><p>Abstract: We consider the problem of computing the Euclidean projection of a vector of length p onto a non-negative max-heap—an ordered tree where the values of the nodes are all nonnegative and the value of any parent node is no less than the value(s) of its child node(s). This Euclidean projection plays a building block role in the optimization problem with a non-negative maxheap constraint. Such a constraint is desirable when the features follow an ordered tree structure, that is, a given feature is selected for the given regression/classiﬁcation task only if its parent node is selected. In this paper, we show that such Euclidean projection problem admits an analytical solution and we develop a top-down algorithm where the key operation is to ﬁnd the so-called maximal root-tree of the subtree rooted at each node. A naive approach for ﬁnding the maximal root-tree is to enumerate all the possible root-trees, which, however, does not scale well. We reveal several important properties of the maximal root-tree, based on which we design a bottom-up algorithm with merge for eﬃciently ﬁnding the maximal roottree. The proposed algorithm has a (worst-case) linear time complexity for a sequential list, and O(p2 ) for a general tree. We report simulation results showing the eﬀectiveness of the max-heap for regression with an ordered tree structure. Empirical results show that the proposed algorithm has an expected linear time complexity for many special cases including a sequential list, a full binary tree, and a tree with depth 1. 1</p><p>6 0.12135402 <a title="229-tfidf-6" href="./nips-2011-Active_Learning_Ranking_from_Pairwise_Preferences_with_Almost_Optimal_Query_Complexity.html">20 nips-2011-Active Learning Ranking from Pairwise Preferences with Almost Optimal Query Complexity</a></p>
<p>7 0.11456724 <a title="229-tfidf-7" href="./nips-2011-Im2Text%3A_Describing_Images_Using_1_Million_Captioned_Photographs.html">126 nips-2011-Im2Text: Describing Images Using 1 Million Captioned Photographs</a></p>
<p>8 0.11006974 <a title="229-tfidf-8" href="./nips-2011-Learning_to_Search_Efficiently_in_High_Dimensions.html">157 nips-2011-Learning to Search Efficiently in High Dimensions</a></p>
<p>9 0.093419813 <a title="229-tfidf-9" href="./nips-2011-Stochastic_convex_optimization_with_bandit_feedback.html">272 nips-2011-Stochastic convex optimization with bandit feedback</a></p>
<p>10 0.08960247 <a title="229-tfidf-10" href="./nips-2011-Quasi-Newton_Methods_for_Markov_Chain_Monte_Carlo.html">228 nips-2011-Quasi-Newton Methods for Markov Chain Monte Carlo</a></p>
<p>11 0.08458893 <a title="229-tfidf-11" href="./nips-2011-Learning_Higher-Order_Graph_Structure_with_Features_by_Structure_Penalty.html">146 nips-2011-Learning Higher-Order Graph Structure with Features by Structure Penalty</a></p>
<p>12 0.081212521 <a title="229-tfidf-12" href="./nips-2011-Learning_unbelievable_probabilities.html">158 nips-2011-Learning unbelievable probabilities</a></p>
<p>13 0.077314079 <a title="229-tfidf-13" href="./nips-2011-Simultaneous_Sampling_and_Multi-Structure_Fitting_with_Adaptive_Reversible_Jump_MCMC.html">255 nips-2011-Simultaneous Sampling and Multi-Structure Fitting with Adaptive Reversible Jump MCMC</a></p>
<p>14 0.075969502 <a title="229-tfidf-14" href="./nips-2011-Efficient_Inference_in_Fully_Connected_CRFs_with_Gaussian_Edge_Potentials.html">76 nips-2011-Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials</a></p>
<p>15 0.074549213 <a title="229-tfidf-15" href="./nips-2011-A_Model_for_Temporal_Dependencies_in_Event_Streams.html">8 nips-2011-A Model for Temporal Dependencies in Event Streams</a></p>
<p>16 0.073730856 <a title="229-tfidf-16" href="./nips-2011-Collective_Graphical_Models.html">55 nips-2011-Collective Graphical Models</a></p>
<p>17 0.073012874 <a title="229-tfidf-17" href="./nips-2011-Accelerated_Adaptive_Markov_Chain_for_Partition_Function_Computation.html">17 nips-2011-Accelerated Adaptive Markov Chain for Partition Function Computation</a></p>
<p>18 0.072185941 <a title="229-tfidf-18" href="./nips-2011-Maximum_Margin_Multi-Instance_Learning.html">168 nips-2011-Maximum Margin Multi-Instance Learning</a></p>
<p>19 0.070918195 <a title="229-tfidf-19" href="./nips-2011-Kernel_Embeddings_of_Latent_Tree_Graphical_Models.html">140 nips-2011-Kernel Embeddings of Latent Tree Graphical Models</a></p>
<p>20 0.069335632 <a title="229-tfidf-20" href="./nips-2011-Bayesian_Bias_Mitigation_for_Crowdsourcing.html">42 nips-2011-Bayesian Bias Mitigation for Crowdsourcing</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.193), (1, 0.011), (2, -0.034), (3, 0.013), (4, -0.05), (5, -0.097), (6, -0.064), (7, -0.137), (8, 0.083), (9, -0.039), (10, -0.057), (11, -0.081), (12, -0.032), (13, 0.025), (14, 0.154), (15, -0.037), (16, 0.082), (17, -0.001), (18, -0.123), (19, 0.069), (20, 0.037), (21, 0.031), (22, 0.202), (23, -0.1), (24, -0.153), (25, 0.037), (26, 0.189), (27, 0.107), (28, 0.022), (29, -0.089), (30, 0.024), (31, -0.187), (32, -0.125), (33, -0.025), (34, -0.129), (35, 0.077), (36, -0.052), (37, -0.106), (38, 0.055), (39, -0.039), (40, -0.023), (41, 0.029), (42, -0.029), (43, -0.036), (44, -0.104), (45, 0.063), (46, 0.029), (47, -0.041), (48, 0.022), (49, -0.109)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95719969 <a title="229-lsi-1" href="./nips-2011-Query-Aware_MCMC.html">229 nips-2011-Query-Aware MCMC</a></p>
<p>Author: Michael L. Wick, Andrew McCallum</p><p>Abstract: Traditional approaches to probabilistic inference such as loopy belief propagation and Gibbs sampling typically compute marginals for all the unobserved variables in a graphical model. However, in many real-world applications the user’s interests are focused on a subset of the variables, speciﬁed by a query. In this case it would be wasteful to uniformly sample, say, one million variables when the query concerns only ten. In this paper we propose a query-speciﬁc approach to MCMC that accounts for the query variables and their generalized mutual information with neighboring variables in order to achieve higher computational efﬁciency. Surprisingly there has been almost no previous work on query-aware MCMC. We demonstrate the success of our approach with positive experimental results on a wide range of graphical models. 1</p><p>2 0.65968513 <a title="229-lsi-2" href="./nips-2011-Active_Ranking_using_Pairwise_Comparisons.html">22 nips-2011-Active Ranking using Pairwise Comparisons</a></p>
<p>Author: Kevin G. Jamieson, Robert Nowak</p><p>Abstract: This paper examines the problem of ranking a collection of objects using pairwise comparisons (rankings of two objects). In general, the ranking of n objects can be identiﬁed by standard sorting methods using n log2 n pairwise comparisons. We are interested in natural situations in which relationships among the objects may allow for ranking using far fewer pairwise comparisons. Speciﬁcally, we assume that the objects can be embedded into a d-dimensional Euclidean space and that the rankings reﬂect their relative distances from a common reference point in Rd . We show that under this assumption the number of possible rankings grows like n2d and demonstrate an algorithm that can identify a randomly selected ranking using just slightly more than d log n adaptively selected pairwise comparisons, on average. If instead the comparisons are chosen at random, then almost all pairwise comparisons must be made in order to identify any ranking. In addition, we propose a robust, error-tolerant algorithm that only requires that the pairwise comparisons are probably correct. Experimental studies with synthetic and real datasets support the conclusions of our theoretical analysis. 1</p><p>3 0.65163755 <a title="229-lsi-3" href="./nips-2011-Active_Learning_Ranking_from_Pairwise_Preferences_with_Almost_Optimal_Query_Complexity.html">20 nips-2011-Active Learning Ranking from Pairwise Preferences with Almost Optimal Query Complexity</a></p>
<p>Author: Nir Ailon</p><p>Abstract: Given a set V of n elements we wish to linearly order them using pairwise preference labels which may be non-transitive (due to irrationality or arbitrary noise). The goal is to linearly order the elements while disagreeing with as few pairwise preference labels as possible. Our performance is measured by two parameters: The number of disagreements (loss) and the query complexity (number of pairwise preference labels). Our algorithm adaptively queries at most O(n poly(log n, ε−1 )) preference labels for a regret of ε times the optimal loss. This is strictly better, and often signiﬁcantly better than what non-adaptive sampling could achieve. Our main result helps settle an open problem posed by learning-to-rank (from pairwise information) theoreticians and practitioners: What is a provably correct way to sample preference labels? 1</p><p>4 0.58060038 <a title="229-lsi-4" href="./nips-2011-Randomized_Algorithms_for_Comparison-based_Search.html">231 nips-2011-Randomized Algorithms for Comparison-based Search</a></p>
<p>Author: Dominique Tschopp, Suhas Diggavi, Payam Delgosha, Soheil Mohajer</p><p>Abstract: This paper addresses the problem of ﬁnding the nearest neighbor (or one of the R-nearest neighbors) of a query object q in a database of n objects, when we can only use a comparison oracle. The comparison oracle, given two reference objects and a query object, returns the reference object most similar to the query object. The main problem we study is how to search the database for the nearest neighbor (NN) of a query, while minimizing the questions. The difﬁculty of this problem depends on properties of the underlying database. We show the importance of a characterization: combinatorial disorder D which deﬁnes approximate triangle n inequalities on ranks. We present a lower bound of Ω(D log D + D2 ) average number of questions in the search phase for any randomized algorithm, which demonstrates the fundamental role of D for worst case behavior. We develop 3 a randomized scheme for NN retrieval in O(D3 log2 n + D log2 n log log nD ) 3 questions. The learning requires asking O(nD3 log2 n + D log2 n log log nD ) questions and O(n log2 n/ log(2D)) bits to store.</p><p>5 0.52187067 <a title="229-lsi-5" href="./nips-2011-A_Model_for_Temporal_Dependencies_in_Event_Streams.html">8 nips-2011-A Model for Temporal Dependencies in Event Streams</a></p>
<p>Author: Asela Gunawardana, Christopher Meek, Puyang Xu</p><p>Abstract: We introduce the Piecewise-Constant Conditional Intensity Model, a model for learning temporal dependencies in event streams. We describe a closed-form Bayesian approach to learning these models, and describe an importance sampling algorithm for forecasting future events using these models, using a proposal distribution based on Poisson superposition. We then use synthetic data, supercomputer event logs, and web search query logs to illustrate that our learning algorithm can efﬁciently learn nonlinear temporal dependencies, and that our importance sampling algorithm can effectively forecast future events. 1</p><p>6 0.50988162 <a title="229-lsi-6" href="./nips-2011-Collective_Graphical_Models.html">55 nips-2011-Collective Graphical Models</a></p>
<p>7 0.50752789 <a title="229-lsi-7" href="./nips-2011-Quasi-Newton_Methods_for_Markov_Chain_Monte_Carlo.html">228 nips-2011-Quasi-Newton Methods for Markov Chain Monte Carlo</a></p>
<p>8 0.48601338 <a title="229-lsi-8" href="./nips-2011-Nonstandard_Interpretations_of_Probabilistic_Programs_for_Efficient_Inference.html">192 nips-2011-Nonstandard Interpretations of Probabilistic Programs for Efficient Inference</a></p>
<p>9 0.45910701 <a title="229-lsi-9" href="./nips-2011-Stochastic_convex_optimization_with_bandit_feedback.html">272 nips-2011-Stochastic convex optimization with bandit feedback</a></p>
<p>10 0.45204434 <a title="229-lsi-10" href="./nips-2011-Bayesian_Bias_Mitigation_for_Crowdsourcing.html">42 nips-2011-Bayesian Bias Mitigation for Crowdsourcing</a></p>
<p>11 0.44652116 <a title="229-lsi-11" href="./nips-2011-Accelerated_Adaptive_Markov_Chain_for_Partition_Function_Computation.html">17 nips-2011-Accelerated Adaptive Markov Chain for Partition Function Computation</a></p>
<p>12 0.44586658 <a title="229-lsi-12" href="./nips-2011-Select_and_Sample_-_A_Model_of_Efficient_Neural_Inference_and_Learning.html">243 nips-2011-Select and Sample - A Model of Efficient Neural Inference and Learning</a></p>
<p>13 0.42390686 <a title="229-lsi-13" href="./nips-2011-Learning_to_Search_Efficiently_in_High_Dimensions.html">157 nips-2011-Learning to Search Efficiently in High Dimensions</a></p>
<p>14 0.41110498 <a title="229-lsi-14" href="./nips-2011-On_the_Completeness_of_First-Order_Knowledge_Compilation_for_Lifted_Probabilistic_Inference.html">201 nips-2011-On the Completeness of First-Order Knowledge Compilation for Lifted Probabilistic Inference</a></p>
<p>15 0.40851593 <a title="229-lsi-15" href="./nips-2011-Simultaneous_Sampling_and_Multi-Structure_Fitting_with_Adaptive_Reversible_Jump_MCMC.html">255 nips-2011-Simultaneous Sampling and Multi-Structure Fitting with Adaptive Reversible Jump MCMC</a></p>
<p>16 0.39118898 <a title="229-lsi-16" href="./nips-2011-A_Machine_Learning_Approach_to_Predict_Chemical_Reactions.html">7 nips-2011-A Machine Learning Approach to Predict Chemical Reactions</a></p>
<p>17 0.38852739 <a title="229-lsi-17" href="./nips-2011-Convergent_Bounds_on_the_Euclidean_Distance.html">64 nips-2011-Convergent Bounds on the Euclidean Distance</a></p>
<p>18 0.38656044 <a title="229-lsi-18" href="./nips-2011-Priors_over_Recurrent_Continuous_Time_Processes.html">221 nips-2011-Priors over Recurrent Continuous Time Processes</a></p>
<p>19 0.36555561 <a title="229-lsi-19" href="./nips-2011-Variational_Gaussian_Process_Dynamical_Systems.html">301 nips-2011-Variational Gaussian Process Dynamical Systems</a></p>
<p>20 0.35670465 <a title="229-lsi-20" href="./nips-2011-Efficient_Inference_in_Fully_Connected_CRFs_with_Gaussian_Edge_Potentials.html">76 nips-2011-Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.034), (4, 0.055), (20, 0.032), (26, 0.084), (31, 0.121), (33, 0.032), (43, 0.045), (44, 0.183), (45, 0.116), (56, 0.012), (57, 0.045), (63, 0.014), (65, 0.015), (74, 0.049), (83, 0.048), (99, 0.042)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.96152073 <a title="229-lda-1" href="./nips-2011-A_Machine_Learning_Approach_to_Predict_Chemical_Reactions.html">7 nips-2011-A Machine Learning Approach to Predict Chemical Reactions</a></p>
<p>Author: Matthew A. Kayala, Pierre F. Baldi</p><p>Abstract: Being able to predict the course of arbitrary chemical reactions is essential to the theory and applications of organic chemistry. Previous approaches are not highthroughput, are not generalizable or scalable, or lack sufﬁcient data to be effective. We describe single mechanistic reactions as concerted electron movements from an electron orbital source to an electron orbital sink. We use an existing rule-based expert system to derive a dataset consisting of 2,989 productive mechanistic steps and 6.14 million non-productive mechanistic steps. We then pose identifying productive mechanistic steps as a ranking problem: rank potential orbital interactions such that the top ranked interactions yield the major products. The machine learning implementation follows a two-stage approach, in which we ﬁrst train atom level reactivity ﬁlters to prune 94.0% of non-productive reactions with less than a 0.1% false negative rate. Then, we train an ensemble of ranking models on pairs of interacting orbitals to learn a relative productivity function over single mechanistic reactions in a given system. Without the use of explicit transformation patterns, the ensemble perfectly ranks the productive mechanisms at the top 89.1% of the time, rising to 99.9% of the time when top ranked lists with at most four nonproductive reactions are considered. The ﬁnal system allows multi-step reaction prediction. Furthermore, it is generalizable, making reasonable predictions over reactants and conditions which the rule-based expert system does not handle.</p><p>2 0.87509447 <a title="229-lda-2" href="./nips-2011-Two_is_better_than_one%3A_distinct_roles_for_familiarity_and_recollection_in_retrieving_palimpsest_memories.html">292 nips-2011-Two is better than one: distinct roles for familiarity and recollection in retrieving palimpsest memories</a></p>
<p>Author: Cristina Savin, Peter Dayan, Máté Lengyel</p><p>Abstract: Storing a new pattern in a palimpsest memory system comes at the cost of interfering with the memory traces of previously stored items. Knowing the age of a pattern thus becomes critical for recalling it faithfully. This implies that there should be a tight coupling between estimates of age, as a form of familiarity, and the neural dynamics of recollection, something which current theories omit. Using a normative model of autoassociative memory, we show that a dual memory system, consisting of two interacting modules for familiarity and recollection, has best performance for both recollection and recognition. This ﬁnding provides a new window onto actively contentious psychological and neural aspects of recognition memory. 1</p><p>same-paper 3 0.83556914 <a title="229-lda-3" href="./nips-2011-Query-Aware_MCMC.html">229 nips-2011-Query-Aware MCMC</a></p>
<p>Author: Michael L. Wick, Andrew McCallum</p><p>Abstract: Traditional approaches to probabilistic inference such as loopy belief propagation and Gibbs sampling typically compute marginals for all the unobserved variables in a graphical model. However, in many real-world applications the user’s interests are focused on a subset of the variables, speciﬁed by a query. In this case it would be wasteful to uniformly sample, say, one million variables when the query concerns only ten. In this paper we propose a query-speciﬁc approach to MCMC that accounts for the query variables and their generalized mutual information with neighboring variables in order to achieve higher computational efﬁciency. Surprisingly there has been almost no previous work on query-aware MCMC. We demonstrate the success of our approach with positive experimental results on a wide range of graphical models. 1</p><p>4 0.73856074 <a title="229-lda-4" href="./nips-2011-Accelerated_Adaptive_Markov_Chain_for_Partition_Function_Computation.html">17 nips-2011-Accelerated Adaptive Markov Chain for Partition Function Computation</a></p>
<p>Author: Stefano Ermon, Carla P. Gomes, Ashish Sabharwal, Bart Selman</p><p>Abstract: We propose a novel Adaptive Markov Chain Monte Carlo algorithm to compute the partition function. In particular, we show how to accelerate a ﬂat histogram sampling technique by signiﬁcantly reducing the number of “null moves” in the chain, while maintaining asymptotic convergence properties. Our experiments show that our method converges quickly to highly accurate solutions on a range of benchmark instances, outperforming other state-of-the-art methods such as IJGP, TRW, and Gibbs sampling both in run-time and accuracy. We also show how obtaining a so-called density of states distribution allows for efﬁcient weight learning in Markov Logic theories. 1</p><p>5 0.73810065 <a title="229-lda-5" href="./nips-2011-Active_Ranking_using_Pairwise_Comparisons.html">22 nips-2011-Active Ranking using Pairwise Comparisons</a></p>
<p>Author: Kevin G. Jamieson, Robert Nowak</p><p>Abstract: This paper examines the problem of ranking a collection of objects using pairwise comparisons (rankings of two objects). In general, the ranking of n objects can be identiﬁed by standard sorting methods using n log2 n pairwise comparisons. We are interested in natural situations in which relationships among the objects may allow for ranking using far fewer pairwise comparisons. Speciﬁcally, we assume that the objects can be embedded into a d-dimensional Euclidean space and that the rankings reﬂect their relative distances from a common reference point in Rd . We show that under this assumption the number of possible rankings grows like n2d and demonstrate an algorithm that can identify a randomly selected ranking using just slightly more than d log n adaptively selected pairwise comparisons, on average. If instead the comparisons are chosen at random, then almost all pairwise comparisons must be made in order to identify any ranking. In addition, we propose a robust, error-tolerant algorithm that only requires that the pairwise comparisons are probably correct. Experimental studies with synthetic and real datasets support the conclusions of our theoretical analysis. 1</p><p>6 0.73532307 <a title="229-lda-6" href="./nips-2011-Randomized_Algorithms_for_Comparison-based_Search.html">231 nips-2011-Randomized Algorithms for Comparison-based Search</a></p>
<p>7 0.7278583 <a title="229-lda-7" href="./nips-2011-On_Tracking_The_Partition_Function.html">197 nips-2011-On Tracking The Partition Function</a></p>
<p>8 0.72767651 <a title="229-lda-8" href="./nips-2011-Multiple_Instance_Filtering.html">180 nips-2011-Multiple Instance Filtering</a></p>
<p>9 0.72745818 <a title="229-lda-9" href="./nips-2011-EigenNet%3A_A_Bayesian_hybrid_of_generative_and_conditional_models_for_sparse_learning.html">84 nips-2011-EigenNet: A Bayesian hybrid of generative and conditional models for sparse learning</a></p>
<p>10 0.72647119 <a title="229-lda-10" href="./nips-2011-Active_Learning_with_a_Drifting_Distribution.html">21 nips-2011-Active Learning with a Drifting Distribution</a></p>
<p>11 0.72563112 <a title="229-lda-11" href="./nips-2011-Online_Learning%3A_Stochastic%2C_Constrained%2C_and_Smoothed_Adversaries.html">204 nips-2011-Online Learning: Stochastic, Constrained, and Smoothed Adversaries</a></p>
<p>12 0.72340721 <a title="229-lda-12" href="./nips-2011-Optimal_Reinforcement_Learning_for_Gaussian_Systems.html">206 nips-2011-Optimal Reinforcement Learning for Gaussian Systems</a></p>
<p>13 0.7231881 <a title="229-lda-13" href="./nips-2011-Comparative_Analysis_of_Viterbi_Training_and_Maximum_Likelihood_Estimation_for_HMMs.html">57 nips-2011-Comparative Analysis of Viterbi Training and Maximum Likelihood Estimation for HMMs</a></p>
<p>14 0.72247601 <a title="229-lda-14" href="./nips-2011-Video_Annotation_and_Tracking_with_Active_Learning.html">303 nips-2011-Video Annotation and Tracking with Active Learning</a></p>
<p>15 0.72210485 <a title="229-lda-15" href="./nips-2011-Multilinear_Subspace_Regression%3A_An_Orthogonal_Tensor_Decomposition_Approach.html">179 nips-2011-Multilinear Subspace Regression: An Orthogonal Tensor Decomposition Approach</a></p>
<p>16 0.72158611 <a title="229-lda-16" href="./nips-2011-Convergent_Bounds_on_the_Euclidean_Distance.html">64 nips-2011-Convergent Bounds on the Euclidean Distance</a></p>
<p>17 0.71932292 <a title="229-lda-17" href="./nips-2011-Bayesian_Bias_Mitigation_for_Crowdsourcing.html">42 nips-2011-Bayesian Bias Mitigation for Crowdsourcing</a></p>
<p>18 0.71880484 <a title="229-lda-18" href="./nips-2011-Learning_with_the_weighted_trace-norm_under_arbitrary_sampling_distributions.html">159 nips-2011-Learning with the weighted trace-norm under arbitrary sampling distributions</a></p>
<p>19 0.71769392 <a title="229-lda-19" href="./nips-2011-Learning_unbelievable_probabilities.html">158 nips-2011-Learning unbelievable probabilities</a></p>
<p>20 0.7167806 <a title="229-lda-20" href="./nips-2011-The_Fixed_Points_of_Off-Policy_TD.html">283 nips-2011-The Fixed Points of Off-Policy TD</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
