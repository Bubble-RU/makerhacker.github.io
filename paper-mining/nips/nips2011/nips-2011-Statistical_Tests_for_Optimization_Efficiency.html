<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>271 nips-2011-Statistical Tests for Optimization Efficiency</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-271" href="#">nips2011-271</a> knowledge-graph by maker-knowledge-mining</p><h1>271 nips-2011-Statistical Tests for Optimization Efficiency</h1>
<br/><p>Source: <a title="nips-2011-271-pdf" href="http://papers.nips.cc/paper/4308-statistical-tests-for-optimization-efficiency.pdf">pdf</a></p><p>Author: Levi Boyles, Anoop Korattikara, Deva Ramanan, Max Welling</p><p>Abstract: Learning problems, such as logistic regression, are typically formulated as pure optimization problems deﬁned on some loss function. We argue that this view ignores the fact that the loss function depends on stochastically generated data which in turn determines an intrinsic scale of precision for statistical estimation. By considering the statistical properties of the update variables used during the optimization (e.g. gradients), we can construct frequentist hypothesis tests to determine the reliability of these updates. We utilize subsets of the data for computing updates, and use the hypothesis tests for determining when the batch-size needs to be increased. This provides computational beneﬁts and avoids overﬁtting by stopping when the batch-size has become equal to size of the full dataset. Moreover, the proposed algorithms depend on a single interpretable parameter – the probability for an update to be in the wrong direction – which is set to a single value across all algorithms and datasets. In this paper, we illustrate these ideas on three L1 regularized coordinate descent algorithms: L1 -regularized L2 -loss SVMs, L1 -regularized logistic regression, and the Lasso, but we emphasize that the underlying methods are much more generally applicable. 1</p><p>Reference: <a title="nips-2011-271-reference" href="../nips2011_reference/nips-2011-Statistical_Tests_for_Optimization_Efficiency_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('sgd', 0.563), ('dj', 0.259), ('zij', 0.245), ('xij', 0.196), ('inr', 0.191), ('upd', 0.171), ('gt', 0.154), ('precid', 0.141), ('hypothes', 0.138), ('coordin', 0.137), ('batch', 0.135), ('gj', 0.133), ('cd', 0.129), ('grady', 0.117), ('dej', 0.114), ('stop', 0.113), ('desc', 0.113), ('pass', 0.11), ('yi', 0.108), ('schedule', 0.102)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="271-tfidf-1" href="./nips-2011-Statistical_Tests_for_Optimization_Efficiency.html">271 nips-2011-Statistical Tests for Optimization Efficiency</a></p>
<p>2 0.29912224 <a title="271-tfidf-2" href="./nips-2011-Non-Asymptotic_Analysis_of_Stochastic_Approximation_Algorithms_for_Machine_Learning.html">187 nips-2011-Non-Asymptotic Analysis of Stochastic Approximation Algorithms for Machine Learning</a></p>
<p>3 0.29425225 <a title="271-tfidf-3" href="./nips-2011-Better_Mini-Batch_Algorithms_via_Accelerated_Gradient_Methods.html">46 nips-2011-Better Mini-Batch Algorithms via Accelerated Gradient Methods</a></p>
<p>4 0.21392527 <a title="271-tfidf-4" href="./nips-2011-Beating_SGD%3A_Learning_SVMs_in_Sublinear_Time.html">45 nips-2011-Beating SGD: Learning SVMs in Sublinear Time</a></p>
<p>5 0.18258891 <a title="271-tfidf-5" href="./nips-2011-Hogwild%3A_A_Lock-Free_Approach_to_Parallelizing_Stochastic_Gradient_Descent.html">121 nips-2011-Hogwild: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent</a></p>
<p>6 0.14176042 <a title="271-tfidf-6" href="./nips-2011-Nearest_Neighbor_based_Greedy_Coordinate_Descent.html">182 nips-2011-Nearest Neighbor based Greedy Coordinate Descent</a></p>
<p>7 0.13833994 <a title="271-tfidf-7" href="./nips-2011-Matrix_Completion_for_Multi-label_Image_Classification.html">165 nips-2011-Matrix Completion for Multi-label Image Classification</a></p>
<p>8 0.13084725 <a title="271-tfidf-8" href="./nips-2011-High-dimensional_regression_with_noisy_and_missing_data%3A_Provable_guarantees_with_non-convexity.html">118 nips-2011-High-dimensional regression with noisy and missing data: Provable guarantees with non-convexity</a></p>
<p>9 0.12799379 <a title="271-tfidf-9" href="./nips-2011-Sparse_Inverse_Covariance_Matrix_Estimation_Using_Quadratic_Approximation.html">262 nips-2011-Sparse Inverse Covariance Matrix Estimation Using Quadratic Approximation</a></p>
<p>10 0.12447067 <a title="271-tfidf-10" href="./nips-2011-Semantic_Labeling_of_3D_Point_Clouds_for_Indoor_Scenes.html">247 nips-2011-Semantic Labeling of 3D Point Clouds for Indoor Scenes</a></p>
<p>11 0.11759961 <a title="271-tfidf-11" href="./nips-2011-Fast_and_Balanced%3A_Efficient_Label_Tree_Learning_for_Large_Scale_Object_Recognition.html">96 nips-2011-Fast and Balanced: Efficient Label Tree Learning for Large Scale Object Recognition</a></p>
<p>12 0.10928144 <a title="271-tfidf-12" href="./nips-2011-From_Bandits_to_Experts%3A_On_the_Value_of_Side-Observations.html">98 nips-2011-From Bandits to Experts: On the Value of Side-Observations</a></p>
<p>13 0.10783622 <a title="271-tfidf-13" href="./nips-2011-Structured_sparse_coding_via_lateral_inhibition.html">276 nips-2011-Structured sparse coding via lateral inhibition</a></p>
<p>14 0.097344235 <a title="271-tfidf-14" href="./nips-2011-Multiple_Instance_Filtering.html">180 nips-2011-Multiple Instance Filtering</a></p>
<p>15 0.086348794 <a title="271-tfidf-15" href="./nips-2011-Multiclass_Boosting%3A_Theory_and_Algorithms.html">178 nips-2011-Multiclass Boosting: Theory and Algorithms</a></p>
<p>16 0.082169592 <a title="271-tfidf-16" href="./nips-2011-Distributed_Delayed_Stochastic_Optimization.html">72 nips-2011-Distributed Delayed Stochastic Optimization</a></p>
<p>17 0.079277895 <a title="271-tfidf-17" href="./nips-2011-Trace_Lasso%3A_a_trace_norm_regularization_for_correlated_designs.html">289 nips-2011-Trace Lasso: a trace norm regularization for correlated designs</a></p>
<p>18 0.077937074 <a title="271-tfidf-18" href="./nips-2011-Robust_Lasso_with_missing_and_grossly_corrupted_observations.html">239 nips-2011-Robust Lasso with missing and grossly corrupted observations</a></p>
<p>19 0.075359695 <a title="271-tfidf-19" href="./nips-2011-Selecting_the_State-Representation_in_Reinforcement_Learning.html">245 nips-2011-Selecting the State-Representation in Reinforcement Learning</a></p>
<p>20 0.074946061 <a title="271-tfidf-20" href="./nips-2011-On_the_Universality_of_Online_Mirror_Descent.html">202 nips-2011-On the Universality of Online Mirror Descent</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.233), (1, -0.077), (2, 0.037), (3, 0.068), (4, 0.052), (5, 0.031), (6, -0.093), (7, -0.215), (8, 0.141), (9, 0.074), (10, 0.186), (11, 0.001), (12, -0.141), (13, -0.104), (14, -0.065), (15, 0.201), (16, 0.023), (17, -0.015), (18, 0.164), (19, -0.18), (20, -0.094), (21, -0.088), (22, -0.089), (23, 0.179), (24, 0.079), (25, -0.075), (26, 0.031), (27, -0.139), (28, 0.034), (29, -0.006), (30, -0.037), (31, -0.018), (32, -0.036), (33, -0.137), (34, 0.043), (35, 0.02), (36, -0.07), (37, 0.023), (38, -0.043), (39, -0.018), (40, 0.116), (41, 0.033), (42, -0.046), (43, -0.033), (44, -0.017), (45, 0.092), (46, 0.019), (47, -0.042), (48, -0.048), (49, -0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91724408 <a title="271-lsi-1" href="./nips-2011-Statistical_Tests_for_Optimization_Efficiency.html">271 nips-2011-Statistical Tests for Optimization Efficiency</a></p>
<p>2 0.80044693 <a title="271-lsi-2" href="./nips-2011-Hogwild%3A_A_Lock-Free_Approach_to_Parallelizing_Stochastic_Gradient_Descent.html">121 nips-2011-Hogwild: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent</a></p>
<p>3 0.79982919 <a title="271-lsi-3" href="./nips-2011-Non-Asymptotic_Analysis_of_Stochastic_Approximation_Algorithms_for_Machine_Learning.html">187 nips-2011-Non-Asymptotic Analysis of Stochastic Approximation Algorithms for Machine Learning</a></p>
<p>4 0.79714227 <a title="271-lsi-4" href="./nips-2011-Better_Mini-Batch_Algorithms_via_Accelerated_Gradient_Methods.html">46 nips-2011-Better Mini-Batch Algorithms via Accelerated Gradient Methods</a></p>
<p>5 0.71242076 <a title="271-lsi-5" href="./nips-2011-Beating_SGD%3A_Learning_SVMs_in_Sublinear_Time.html">45 nips-2011-Beating SGD: Learning SVMs in Sublinear Time</a></p>
<p>6 0.66476929 <a title="271-lsi-6" href="./nips-2011-Distributed_Delayed_Stochastic_Optimization.html">72 nips-2011-Distributed Delayed Stochastic Optimization</a></p>
<p>7 0.57213598 <a title="271-lsi-7" href="./nips-2011-On_the_Universality_of_Online_Mirror_Descent.html">202 nips-2011-On the Universality of Online Mirror Descent</a></p>
<p>8 0.45812365 <a title="271-lsi-8" href="./nips-2011-A_Convergence_Analysis_of_Log-Linear_Training.html">4 nips-2011-A Convergence Analysis of Log-Linear Training</a></p>
<p>9 0.43158609 <a title="271-lsi-9" href="./nips-2011-Learning_Anchor_Planes_for_Classification.html">143 nips-2011-Learning Anchor Planes for Classification</a></p>
<p>10 0.43157786 <a title="271-lsi-10" href="./nips-2011-Sparse_Inverse_Covariance_Matrix_Estimation_Using_Quadratic_Approximation.html">262 nips-2011-Sparse Inverse Covariance Matrix Estimation Using Quadratic Approximation</a></p>
<p>11 0.43153653 <a title="271-lsi-11" href="./nips-2011-Nearest_Neighbor_based_Greedy_Coordinate_Descent.html">182 nips-2011-Nearest Neighbor based Greedy Coordinate Descent</a></p>
<p>12 0.42951345 <a title="271-lsi-12" href="./nips-2011-Learning_Probabilistic_Non-Linear_Latent_Variable_Models_for_Tracking_Complex_Activities.html">148 nips-2011-Learning Probabilistic Non-Linear Latent Variable Models for Tracking Complex Activities</a></p>
<p>13 0.40837291 <a title="271-lsi-13" href="./nips-2011-High-dimensional_regression_with_noisy_and_missing_data%3A_Provable_guarantees_with_non-convexity.html">118 nips-2011-High-dimensional regression with noisy and missing data: Provable guarantees with non-convexity</a></p>
<p>14 0.38607854 <a title="271-lsi-14" href="./nips-2011-Transfer_Learning_by_Borrowing_Examples_for_Multiclass_Object_Detection.html">290 nips-2011-Transfer Learning by Borrowing Examples for Multiclass Object Detection</a></p>
<p>15 0.38179496 <a title="271-lsi-15" href="./nips-2011-Efficient_Learning_of_Generalized_Linear_and_Single_Index_Models_with_Isotonic_Regression.html">77 nips-2011-Efficient Learning of Generalized Linear and Single Index Models with Isotonic Regression</a></p>
<p>16 0.3721492 <a title="271-lsi-16" href="./nips-2011-On_Tracking_The_Partition_Function.html">197 nips-2011-On Tracking The Partition Function</a></p>
<p>17 0.36868274 <a title="271-lsi-17" href="./nips-2011-Submodular_Multi-Label_Learning.html">277 nips-2011-Submodular Multi-Label Learning</a></p>
<p>18 0.36239737 <a title="271-lsi-18" href="./nips-2011-Matrix_Completion_for_Multi-label_Image_Classification.html">165 nips-2011-Matrix Completion for Multi-label Image Classification</a></p>
<p>19 0.36090839 <a title="271-lsi-19" href="./nips-2011-Multiple_Instance_Filtering.html">180 nips-2011-Multiple Instance Filtering</a></p>
<p>20 0.35642207 <a title="271-lsi-20" href="./nips-2011-Variance_Penalizing_AdaBoost.html">299 nips-2011-Variance Penalizing AdaBoost</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.064), (22, 0.453), (36, 0.039), (55, 0.163), (65, 0.052), (68, 0.135), (79, 0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.96803033 <a title="271-lda-1" href="./nips-2011-Penalty_Decomposition_Methods_for_Rank_Minimization.html">211 nips-2011-Penalty Decomposition Methods for Rank Minimization</a></p>
<p>2 0.88157898 <a title="271-lda-2" href="./nips-2011-Statistical_Performance_of_Convex_Tensor_Decomposition.html">270 nips-2011-Statistical Performance of Convex Tensor Decomposition</a></p>
<p>3 0.81964397 <a title="271-lda-3" href="./nips-2011-Greedy_Algorithms_for_Structurally_Constrained_High_Dimensional_Problems.html">108 nips-2011-Greedy Algorithms for Structurally Constrained High Dimensional Problems</a></p>
<p>4 0.80463433 <a title="271-lda-4" href="./nips-2011-Group_Anomaly_Detection_using_Flexible_Genre_Models.html">110 nips-2011-Group Anomaly Detection using Flexible Genre Models</a></p>
<p>5 0.80315024 <a title="271-lda-5" href="./nips-2011-The_Manifold_Tangent_Classifier.html">287 nips-2011-The Manifold Tangent Classifier</a></p>
<p>same-paper 6 0.77411181 <a title="271-lda-6" href="./nips-2011-Statistical_Tests_for_Optimization_Efficiency.html">271 nips-2011-Statistical Tests for Optimization Efficiency</a></p>
<p>7 0.75988472 <a title="271-lda-7" href="./nips-2011-Sparse_Filtering.html">261 nips-2011-Sparse Filtering</a></p>
<p>8 0.75581169 <a title="271-lda-8" href="./nips-2011-Trace_Lasso%3A_a_trace_norm_regularization_for_correlated_designs.html">289 nips-2011-Trace Lasso: a trace norm regularization for correlated designs</a></p>
<p>9 0.75453156 <a title="271-lda-9" href="./nips-2011-Nearest_Neighbor_based_Greedy_Coordinate_Descent.html">182 nips-2011-Nearest Neighbor based Greedy Coordinate Descent</a></p>
<p>10 0.7348125 <a title="271-lda-10" href="./nips-2011-ICA_with_Reconstruction_Cost_for_Efficient_Overcomplete_Feature_Learning.html">124 nips-2011-ICA with Reconstruction Cost for Efficient Overcomplete Feature Learning</a></p>
<p>11 0.71551478 <a title="271-lda-11" href="./nips-2011-RTRMC%3A_A_Riemannian_trust-region_method_for_low-rank_matrix_completion.html">230 nips-2011-RTRMC: A Riemannian trust-region method for low-rank matrix completion</a></p>
<p>12 0.71353745 <a title="271-lda-12" href="./nips-2011-Efficient_Methods_for_Overlapping_Group_Lasso.html">78 nips-2011-Efficient Methods for Overlapping Group Lasso</a></p>
<p>13 0.71068382 <a title="271-lda-13" href="./nips-2011-Universal_low-rank_matrix_recovery_from_Pauli_measurements.html">297 nips-2011-Universal low-rank matrix recovery from Pauli measurements</a></p>
<p>14 0.69655985 <a title="271-lda-14" href="./nips-2011-Linearized_Alternating_Direction_Method_with_Adaptive_Penalty_for_Low-Rank_Representation.html">161 nips-2011-Linearized Alternating Direction Method with Adaptive Penalty for Low-Rank Representation</a></p>
<p>15 0.69151461 <a title="271-lda-15" href="./nips-2011-Sparse_Estimation_with_Structured_Dictionaries.html">259 nips-2011-Sparse Estimation with Structured Dictionaries</a></p>
<p>16 0.68530679 <a title="271-lda-16" href="./nips-2011-Convergence_Rates_of_Inexact_Proximal-Gradient_Methods_for_Convex_Optimization.html">63 nips-2011-Convergence Rates of Inexact Proximal-Gradient Methods for Convex Optimization</a></p>
<p>17 0.68239033 <a title="271-lda-17" href="./nips-2011-Divide-and-Conquer_Matrix_Factorization.html">73 nips-2011-Divide-and-Conquer Matrix Factorization</a></p>
<p>18 0.68228722 <a title="271-lda-18" href="./nips-2011-On_the_Universality_of_Online_Mirror_Descent.html">202 nips-2011-On the Universality of Online Mirror Descent</a></p>
<p>19 0.66953319 <a title="271-lda-19" href="./nips-2011-Sparse_Inverse_Covariance_Matrix_Estimation_Using_Quadratic_Approximation.html">262 nips-2011-Sparse Inverse Covariance Matrix Estimation Using Quadratic Approximation</a></p>
<p>20 0.6683414 <a title="271-lda-20" href="./nips-2011-Matrix_Completion_for_Multi-label_Image_Classification.html">165 nips-2011-Matrix Completion for Multi-label Image Classification</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
