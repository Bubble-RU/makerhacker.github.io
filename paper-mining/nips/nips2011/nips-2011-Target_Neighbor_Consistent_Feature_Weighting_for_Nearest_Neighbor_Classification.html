<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>279 nips-2011-Target Neighbor Consistent Feature Weighting for Nearest Neighbor Classification</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-279" href="#">nips2011-279</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>279 nips-2011-Target Neighbor Consistent Feature Weighting for Nearest Neighbor Classification</h1>
<br/><p>Source: <a title="nips-2011-279-pdf" href="http://papers.nips.cc/paper/4373-target-neighbor-consistent-feature-weighting-for-nearest-neighbor-classification.pdf">pdf</a></p><p>Author: Ichiro Takeuchi, Masashi Sugiyama</p><p>Abstract: We consider feature selection and weighting for nearest neighbor classiﬁers. A technical challenge in this scenario is how to cope with discrete update of nearest neighbors when the feature space metric is changed during the learning process. This issue, called the target neighbor change, was not properly addressed in the existing feature weighting and metric learning literature. In this paper, we propose a novel feature weighting algorithm that can exactly and efﬁciently keep track of the correct target neighbors via sequential quadratic programming. To the best of our knowledge, this is the ﬁrst algorithm that guarantees the consistency between target neighbors and the feature space metric. We further show that the proposed algorithm can be naturally combined with regularization path tracking, allowing computationally efﬁcient selection of the regularization parameter. We demonstrate the effectiveness of the proposed algorithm through experiments. 1</p><p>Reference: <a title="nips-2011-279-reference" href="../nips2011_reference/nips-2011-Target_Neighbor_Consistent_Feature_Weighting_for_Nearest_Neighbor_Classification_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 jp  Abstract We consider feature selection and weighting for nearest neighbor classiﬁers. [sent-7, score-0.505]
</p><p>2 A technical challenge in this scenario is how to cope with discrete update of nearest neighbors when the feature space metric is changed during the learning process. [sent-8, score-0.342]
</p><p>3 This issue, called the target neighbor change, was not properly addressed in the existing feature weighting and metric learning literature. [sent-9, score-0.616]
</p><p>4 In this paper, we propose a novel feature weighting algorithm that can exactly and efﬁciently keep track of the correct target neighbors via sequential quadratic programming. [sent-10, score-0.531]
</p><p>5 To the best of our knowledge, this is the ﬁrst algorithm that guarantees the consistency between target neighbors and the feature space metric. [sent-11, score-0.356]
</p><p>6 We further show that the proposed algorithm can be naturally combined with regularization path tracking, allowing computationally efﬁcient selection of the regularization parameter. [sent-12, score-0.192]
</p><p>7 For further enhancing the accuracy and interpretability of NN classiﬁers, feature extraction and feature selection are highly important. [sent-16, score-0.272]
</p><p>8 Feature extraction for NN classiﬁers has been addressed by the name of metric learning [3–6], while feature selection for NN classiﬁers has been studied by the name of feature weighting [7–11]. [sent-17, score-0.578]
</p><p>9 One of the fundamental approaches to feature extraction/selection for NN classiﬁers is to learn the feature metric/weights so that instance pairs in the same class (‘must-link’) are close and instance pairs in other classes (‘cannot-link’) are far apart [12, 13]. [sent-18, score-0.341]
</p><p>10 However, directly incorporating the NN classiﬁcation loss involves a signiﬁcant technical challenge called the target neighbor (TN) change. [sent-20, score-0.248]
</p><p>11 Since the classiﬁcation result is determined by the majority vote from 3 nearest instances, the classiﬁcation loss is deﬁned using the distance to the 2nd nearest instance in each class (which is referred to as a TN; see Section 2 for details). [sent-22, score-0.368]
</p><p>12 However, since ‘nearest’ instances are generally changed when feature metric/weights are updated, TNs must also be updated to be kept consistent with the learned feature metric/weights during the learning process. [sent-23, score-0.317]
</p><p>13 Although the TN change is a fundamental requirement in feature extraction/selection for NN classiﬁers, existing methods did not handle this issue properly. [sent-24, score-0.172]
</p><p>14 For example, in a seminal feature weighting method called Relief [7, 8], the ﬁxed TNs determined based on the uniform weights (i. [sent-25, score-0.361]
</p><p>15 Thus, the TN-weight consistency is 1  h2 0  m2 0 h2 0 m2 0  Left: (a) The Euclidean feature space with w1 = w2 = 1/2. [sent-28, score-0.144]
</p><p>16 The horizontal feature 1 and the vertical feature 2 are regarded as equally important. [sent-29, score-0.24]
</p><p>17 Right: (b) A weighted feature space with w1 = 2/3 and w2 = 1/3. [sent-30, score-0.147]
</p><p>18 The horizontal feature 1 is regarded as more important than the vertical feature 2. [sent-31, score-0.24]
</p><p>19 In the Euclidean feature space (a), the 2nd target 0 hit/miss are given by (h2 , m2 ) = ( 2 , 6 ). [sent-34, score-0.251]
</p><p>20 On the other hand, in the weighted feature space (b), the 2nd target hit/miss are given by (h2 , m2 ) = ( 1 , 5 ). [sent-36, score-0.291]
</p><p>21 The Simba algorithm [9] is a maximum-margin feature weighting method which adaptively updates TNs in the online learning process. [sent-39, score-0.292]
</p><p>22 I-Relief [10, 11] is a feature weighting method which cleverly avoids the TN change problem by considering a stochastic variant of NN classiﬁers (neighborhood component analysis [4] also introduced similar stochastic approximation). [sent-41, score-0.334]
</p><p>23 However, since the behavior of stochastic NN classiﬁers tends to be signiﬁcantly different from the original ones, the obtained feature metric/weights are not necessarily useful for the original NN classiﬁers. [sent-42, score-0.107]
</p><p>24 In this paper, we focus on the feature selection (i. [sent-43, score-0.136]
</p><p>25 , feature weighting) scenario, and propose a novel method that can properly address the TN change problem. [sent-45, score-0.19]
</p><p>26 More speciﬁcally, we formulate feature weighting as a regularized empirical risk minimization problem, and develop an algorithm that exactly and efﬁciently keeps track of the correct TNs via sequential quadratic programming. [sent-46, score-0.353]
</p><p>27 We further show that the proposed algorithm can be naturally combined with regularization path tracking [14], allowing computationally efﬁcient selection of the regularization parameter. [sent-48, score-0.235]
</p><p>28 2  Preliminaries  In this section, we formulate the problem of feature weighting for nearest neighbor (NN) classiﬁcation, and explain the fundamental concept of target neighbor (TN) change. [sent-57, score-0.755]
</p><p>29 xi ] ∈ R be the i-th training instance and yi be the corresponding label. [sent-62, score-0.112]
</p><p>30 The squared ∑ Euclidean distance between two instances xi and xi is j∈N (xij − xi j )2 , while the weighted squared Euclidean distance is written as ∑ wj (xij − xi j )2 = εi,i w, d(xi , xi |w) := (1) j∈N  where w := [w1 . [sent-63, score-0.548]
</p><p>31 w ] ∈ [0, 1] is an -dimensional vector of non-negative weights and εi,i := [(xi1 − xi 1 )2 . [sent-66, score-0.103]
</p><p>32 We develop a feature weighting algorithm within the framework of regularized empirical risk minimization, i. [sent-70, score-0.292]
</p><p>33 In order to formulate the loss term for NN classiﬁcation, let us introduce the notion of target neighbors (TNs): 2  Deﬁnition 1 (Target neighbors (TNs)) Deﬁne Hi := {h ∈ Nn |yh = yi , h = i} and Mi := {m ∈ Nn |ym = yi } for i ∈ Nn . [sent-73, score-0.34]
</p><p>34 The κ-th target hit and λ-th target miss of an instance i ∈ Nn are denoted by hκ and mλ , respectively. [sent-75, score-0.711]
</p><p>35 Target hits and misses are i i collectively called as target neighbors (TNs) 1 . [sent-76, score-0.286]
</p><p>36 For example, in binary 3NN classiﬁcation, an instance is misclassiﬁed if and only if the distance to the 2nd target hit is larger than the distance to the 2nd target miss (see Figure 1). [sent-78, score-0.815]
</p><p>37 By minimizing L(w), the average (κ, λ)-neighbor margin over all instances is maxi imized. [sent-82, score-0.099]
</p><p>38 This loss function allows us to ﬁnd feature weights such that the distance to the κ-th target hit is as small as possible, while the distance to the λ-th target miss is as large as possible. [sent-83, score-0.939]
</p><p>39 Let w ∈ [0, 1] be our prior weight vector, and we use the regularization term of the form Ω(w) := ¯ 1 −1 ¯ 1, it implies that our baseline choice of the feature ¯ 2 2 ||w − w||2 . [sent-85, score-0.192]
</p><p>40 Given the loss term L(w) and the regularization term Ω(w), the feature weighting problem we are going to study in this paper is formulated as ∑( ) 1 min θn−1 d(xi , xhκ |w) − d(xi , xmλ |w) + ||w − w||2 s. [sent-89, score-0.41]
</p><p>41 1 w = 1, w ≥ 0, ¯ 2 (2) i i w 2 i∈Nn  where θ ∈ R+ is a regularization parameter for controlling the balance between the loss term L(w) and the regularization term Ω(w). [sent-91, score-0.148]
</p><p>42 The ﬁrst equality constraint restricts that the sum of the weights to be one, while the second constraint indicates that the weights are non-negative. [sent-92, score-0.157]
</p><p>43 It is important to note that TNs {(hκ , mλ )}i∈Nn are dependent on the weights w because the i i weighted Euclidean distance (1) is used in their deﬁnitions. [sent-94, score-0.135]
</p><p>44 We refer to this problem as the target neighbor change (TN-change) problem. [sent-96, score-0.264]
</p><p>45 1 The terminologies target hit and miss were ﬁrst used in [7], in which only the 1st target hit and miss were considered. [sent-100, score-1.03]
</p><p>46 We extend them to the κ-th target hit and λ-th target miss for general κ and λ. [sent-101, score-0.659]
</p><p>47 The terminology target neighbors (TNs) was ﬁrst used in [5]. [sent-102, score-0.212]
</p><p>48 2 The notion of the nearest neighbor margin was ﬁrst introduced in [9], where only the case of κ = λ = 1 was considered. [sent-103, score-0.234]
</p><p>49 In the Euclidean feature space with w1 = w2 = 1/2, the 2nd target hit and miss of the instance 0 are given by (h2 , m2 ) = ( 2 , 6 ). [sent-106, score-0.674]
</p><p>50 On the other hand, in the weighted feature space with (w1 , w2 ) = (2/3, 1/3), the 2nd target hit and miss of the instance 0 are given by (h2 , m2 ) = ( 1 , 5 ). [sent-108, score-0.714]
</p><p>51 Based on this fact, our feature weighting algorithm solves a sequence of such QPs, while TNs are properly updated to be always consistent. [sent-111, score-0.363]
</p><p>52 1 w = 1, w ≥ 0,  (3b)  d(xi , xh |w) ≤ ξi , (i, h) ∈ H  [<]  [<]  d(xi , xh |w) = ξi , (i, h) ∈ H  [=]  , d(xi , xm |w) ≤ ηi , (i, m) ∈ M  ,  (3c)  [=]  d(xi , xh |w) ≥ ξi , (i, h) ∈ H  [>]  , d(xi , xm |w) = ηi , (i, m) ∈ M  ,  (3d)  , d(xi , xm |w) ≥ ηi , (i, m) ∈ M  . [sent-119, score-0.555]
</p><p>53 (3e)  [>]  In the above, we introduced slack variables ξi and ηi for i ∈ Nn which represent the weighted distances to the target hit and miss, respectively. [sent-120, score-0.378]
</p><p>54 Our algorithm handles TN change as a change in the index sets (H, M), and a sequence of convex QPs in the form of (3) are (partially) solved every time the index sets (H, M) are updated. [sent-122, score-0.159]
</p><p>55 We implement this approach by using an active set QP algorithm (see Chapter 16 in [15]). [sent-123, score-0.119]
</p><p>56 An advantage of introducing the active set QP algorithm is that TN change can be naturally handled as active set change. [sent-125, score-0.299]
</p><p>57 Speciﬁcally, a change of target hits is interpreted as an exchange of the members between H[<] and H[=] or between H[>] and H[=] , while a change of target misses is interpreted as an exchange of the members between M[<] and M[=] or between M[>] and M[=] . [sent-126, score-0.505]
</p><p>58 3 Note that the constraints for (H[<] , H[=] , H[>] ) in (3c)–(3e) restrict that h must remain to be the target hit of i for all (i, h) ∈ H[=] because those closer than the target hit must remain to be closer and those more distant than the target hit must remain to be more distant. [sent-127, score-1.203]
</p><p>59 Similarly, the constraints for (M[<] , M[=] , M[>] ) in (3c)–(3e) restrict that m must remain to be the target miss of i for all (i, m) ∈ M[=] . [sent-128, score-0.418]
</p><p>60 4 A constraint satisﬁed with equality is called active and the set of active constraints is called active set. [sent-129, score-0.454]
</p><p>61 2  Sequential QP-based Feature Weighting Algorithm  Here, we present our feature weighting algorithm. [sent-131, score-0.292]
</p><p>62 Then we present how to update the EQP by changing the active sets. [sent-133, score-0.119]
</p><p>63 Suppose that we currently have a solution (w, ξ, η) and the active set (H[=] , M[=] , Z). [sent-135, score-0.147]
</p><p>64 We ﬁrst check whether the solution minimizes the loss function (3a) in the subspace deﬁned by the active set. [sent-136, score-0.173]
</p><p>65 If τ < 1, the constraint for which the minimum in (5) is achieved (called the blocking constraint) is added to the active set. [sent-145, score-0.211]
</p><p>66 We repeat this by adding constraints to the active set until we reach the solution (w, ξ, η) that minimizes the objective function over the current active set. [sent-147, score-0.317]
</p><p>67 Next, we need to consider whether the objective function of (2) can be further decreased by removing constraints in the active set. [sent-148, score-0.17]
</p><p>68 Our algorithm and the standard active set QP algorithm are different in this operation: in our algorithm, an active constraint is allowed to be inactive only when the κ-th target hit remains to be a member of H[=] and the λ-th target miss remains to be a member of M[=] . [sent-149, score-0.922]
</p><p>69 Then the following lemma tells us which active constraint should be removed. [sent-151, score-0.185]
</p><p>70 5 If multiple active constraints are selected by these rules, the one with the largest absolute Lagrange multiplier is removed from the active set. [sent-153, score-0.289]
</p><p>71 The proposed feature weighting algorithm, which we call Sequential QP-based Feature Weighting (SQP-FW) algorithm, is summarized in Algorithm 1. [sent-155, score-0.292]
</p><p>72 Then, w is a local minimum i i solution of the problem (2) if and only if the EQP (4) has the solution (∆w, ∆ξ, ∆η) = 0 and there are no active constraints that satisfy the rules in Lemma 6. [sent-162, score-0.293]
</p><p>73 Without such an optimality condition, we must check all possible combinations of TN change from the current solution in a trial and error manner. [sent-164, score-0.097]
</p><p>74 However, this bottleneck can be eased by introducing a working set approach: only a ﬁxed number of constraints in the working set are evaluated at each step, while the working set is updated, say, every 100 steps. [sent-170, score-0.225]
</p><p>75 For each i ∈ Nn , these working sets contain, say, only top 100 nearest instances. [sent-172, score-0.189]
</p><p>76 This strategy is based on a natural idea that those outside of the top 100 nearest instances would not become TNs in the next 100 steps. [sent-173, score-0.155]
</p><p>77 Regularization path tracking: The SQP-FW algorithm can be naturally combined with regularization path tracking algorithm for computing a path of the solutions that satisfy the optimality condition in Theorem 7 for a range of regularization parameter θ. [sent-175, score-0.315]
</p><p>78 The algorithm starts from a local optimal solution for a ﬁxed regularization parameter θ. [sent-177, score-0.112]
</p><p>79 It can be shown that the local optimal solution of (2) 6  is a piecewise-linear function of θ as long as the TNs remain unchanged. [sent-179, score-0.097]
</p><p>80 Such TN changes can be easily detected and handled because the TN-weight consistency conditions are represented by a set of linear constraints (see (3c)–(3e)), and we already have explicit rules (Lemmas 5 and 6) for updating the constraints. [sent-181, score-0.131]
</p><p>81 The regularization path tracking algorithm provides an efﬁcient and insightful approach for model selection. [sent-182, score-0.145]
</p><p>82 1  Comparison Using UCI Data Sets  First, we compare the proposed SQP-FW algorithm with existing feature weighting algorithms, which handle the TN-change problem in different ways. [sent-185, score-0.292]
</p><p>83 • Relief [7, 8]: The Relief algorithm is an online feature weighting algorithm. [sent-186, score-0.292]
</p><p>84 Using these stochastic neighbors, the average margin is formulated as a continuous (non-convex) function of the weights, by which the TN change problem is mitigated. [sent-195, score-0.123]
</p><p>85 The number of neighbors k ∈ {1, 3, 5} was selected based on the classiﬁcation performance on the validation set. [sent-198, score-0.094]
</p><p>86 In the SQP-FW algorithm, the neighborhood parameter (κ, λ) and the regularization parameter θ were also determined to maximize the classiﬁcation accuracy on the validation set. [sent-199, score-0.16]
</p><p>87 The working set strategy was used when n > 1000 with the working set size 100 and the working set update frequency 100. [sent-201, score-0.174]
</p><p>88 Since biologists are interested in identifying a set of genes that governs the difference among different biological phenotypes (such as cancer subtypes), selecting a subset of genes that yields good NN classiﬁcation performance would be practically valuable. [sent-322, score-0.251]
</p><p>89 For each of the four microarray data sets in Table 2, we divided the entire set into the training and test sets with size ratio 2:1 [2]. [sent-323, score-0.112]
</p><p>90 We compared the test set classiﬁcation performance between the plain 1NN classiﬁer (without feature weighting) and the weighted 1NN classiﬁer with the weights determined by the SQP-FW algorithm. [sent-324, score-0.237]
</p><p>91 In the latter, the neighborhood parameters were ﬁxed to κ = λ = 1 and θ was determined by 10-fold cross validation within the training set. [sent-325, score-0.099]
</p><p>92 The results illustrate the potential advantage of feature selection using the SQP-FW algorithm. [sent-330, score-0.136]
</p><p>93 5 Discussion and Conclusion TN change is a fundamental problem in feature extraction and selection for NN classiﬁers. [sent-331, score-0.23]
</p><p>94 Our contribution in this paper was to present a feature weighting algorithm that can systematically handle TN changes and guarantee the TN-weight consistency. [sent-332, score-0.292]
</p><p>95 An important future direction is to generalize our TN-weight consistent feature weighting scheme to feature extraction (i. [sent-333, score-0.452]
</p><p>96 Distance metric learning for large margin nearest neighbor classiﬁcation. [sent-383, score-0.295]
</p><p>97 Local learning based feature selection for high dimensional data analysis. [sent-421, score-0.136]
</p><p>98 The entire regularization path for the support vector machine. [sent-439, score-0.102]
</p><p>99 Broad patterns of gene expression revealed by clustering analysis of tumor and normal colon tissues probed by oligonucleotide arrays. [sent-453, score-0.117]
</p><p>100 Gene expression in kidney cancer is associated with novel tumor subtypes, cytogenetic abnormalities and metastasis formation. [sent-464, score-0.161]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tns', 0.558), ('nn', 0.467), ('hit', 0.194), ('weighting', 0.185), ('relief', 0.18), ('miss', 0.177), ('target', 0.144), ('eqp', 0.126), ('active', 0.119), ('tn', 0.116), ('xh', 0.111), ('simba', 0.111), ('feature', 0.107), ('nearest', 0.106), ('supplement', 0.103), ('classi', 0.099), ('qp', 0.089), ('genes', 0.086), ('hi', 0.085), ('cancer', 0.079), ('neighbor', 0.078), ('mi', 0.076), ('xm', 0.074), ('misclassi', 0.073), ('mulrel', 0.072), ('neighbors', 0.068), ('microarray', 0.062), ('metric', 0.061), ('regularization', 0.061), ('xi', 0.06), ('working', 0.058), ('wj', 0.055), ('euclidean', 0.053), ('distance', 0.052), ('instance', 0.052), ('constraints', 0.051), ('margin', 0.05), ('instances', 0.049), ('blocking', 0.047), ('neighborhood', 0.047), ('remain', 0.046), ('ers', 0.043), ('weights', 0.043), ('tracking', 0.043), ('change', 0.042), ('lemma', 0.041), ('path', 0.041), ('properly', 0.041), ('weighted', 0.04), ('lagrange', 0.04), ('gene', 0.038), ('consistency', 0.037), ('lknn', 0.036), ('qps', 0.036), ('formulate', 0.034), ('cation', 0.033), ('move', 0.032), ('kidney', 0.032), ('prostate', 0.032), ('formulated', 0.031), ('multipliers', 0.031), ('name', 0.03), ('updated', 0.03), ('colon', 0.029), ('tumor', 0.029), ('extraction', 0.029), ('selection', 0.029), ('solution', 0.028), ('subtypes', 0.027), ('sequential', 0.027), ('er', 0.027), ('optimality', 0.027), ('validation', 0.026), ('regarded', 0.026), ('determined', 0.026), ('hits', 0.026), ('knn', 0.026), ('uci', 0.026), ('loss', 0.026), ('constraint', 0.025), ('sets', 0.025), ('misses', 0.025), ('mext', 0.025), ('handles', 0.025), ('consistent', 0.024), ('rules', 0.024), ('weight', 0.024), ('fundamental', 0.023), ('collectively', 0.023), ('kakenhi', 0.023), ('local', 0.023), ('exchange', 0.022), ('plain', 0.021), ('equality', 0.021), ('expression', 0.021), ('minimum', 0.02), ('feasibility', 0.02), ('said', 0.02), ('handled', 0.019), ('members', 0.019)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="279-tfidf-1" href="./nips-2011-Target_Neighbor_Consistent_Feature_Weighting_for_Nearest_Neighbor_Classification.html">279 nips-2011-Target Neighbor Consistent Feature Weighting for Nearest Neighbor Classification</a></p>
<p>Author: Ichiro Takeuchi, Masashi Sugiyama</p><p>Abstract: We consider feature selection and weighting for nearest neighbor classiﬁers. A technical challenge in this scenario is how to cope with discrete update of nearest neighbors when the feature space metric is changed during the learning process. This issue, called the target neighbor change, was not properly addressed in the existing feature weighting and metric learning literature. In this paper, we propose a novel feature weighting algorithm that can exactly and efﬁciently keep track of the correct target neighbors via sequential quadratic programming. To the best of our knowledge, this is the ﬁrst algorithm that guarantees the consistency between target neighbors and the feature space metric. We further show that the proposed algorithm can be naturally combined with regularization path tracking, allowing computationally efﬁcient selection of the regularization parameter. We demonstrate the effectiveness of the proposed algorithm through experiments. 1</p><p>2 0.12381072 <a title="279-tfidf-2" href="./nips-2011-Randomized_Algorithms_for_Comparison-based_Search.html">231 nips-2011-Randomized Algorithms for Comparison-based Search</a></p>
<p>Author: Dominique Tschopp, Suhas Diggavi, Payam Delgosha, Soheil Mohajer</p><p>Abstract: This paper addresses the problem of ﬁnding the nearest neighbor (or one of the R-nearest neighbors) of a query object q in a database of n objects, when we can only use a comparison oracle. The comparison oracle, given two reference objects and a query object, returns the reference object most similar to the query object. The main problem we study is how to search the database for the nearest neighbor (NN) of a query, while minimizing the questions. The difﬁculty of this problem depends on properties of the underlying database. We show the importance of a characterization: combinatorial disorder D which deﬁnes approximate triangle n inequalities on ranks. We present a lower bound of Ω(D log D + D2 ) average number of questions in the search phase for any randomized algorithm, which demonstrates the fundamental role of D for worst case behavior. We develop 3 a randomized scheme for NN retrieval in O(D3 log2 n + D log2 n log log nD ) 3 questions. The learning requires asking O(nD3 log2 n + D log2 n log log nD ) questions and O(n log2 n/ log(2D)) bits to store.</p><p>3 0.095036983 <a title="279-tfidf-3" href="./nips-2011-Variational_Gaussian_Process_Dynamical_Systems.html">301 nips-2011-Variational Gaussian Process Dynamical Systems</a></p>
<p>Author: Neil D. Lawrence, Michalis K. Titsias, Andreas Damianou</p><p>Abstract: High dimensional time series are endemic in applications of machine learning such as robotics (sensor data), computational biology (gene expression data), vision (video sequences) and graphics (motion capture data). Practical nonlinear probabilistic approaches to this data are required. In this paper we introduce the variational Gaussian process dynamical system. Our work builds on recent variational approximations for Gaussian process latent variable models to allow for nonlinear dimensionality reduction simultaneously with learning a dynamical prior in the latent space. The approach also allows for the appropriate dimensionality of the latent space to be automatically determined. We demonstrate the model on a human motion capture data set and a series of high resolution video sequences. 1</p><p>4 0.088949651 <a title="279-tfidf-4" href="./nips-2011-Active_Classification_based_on_Value_of_Classifier.html">19 nips-2011-Active Classification based on Value of Classifier</a></p>
<p>Author: Tianshi Gao, Daphne Koller</p><p>Abstract: Modern classiﬁcation tasks usually involve many class labels and can be informed by a broad range of features. Many of these tasks are tackled by constructing a set of classiﬁers, which are then applied at test time and then pieced together in a ﬁxed procedure determined in advance or at training time. We present an active classiﬁcation process at the test time, where each classiﬁer in a large ensemble is viewed as a potential observation that might inform our classiﬁcation process. Observations are then selected dynamically based on previous observations, using a value-theoretic computation that balances an estimate of the expected classiﬁcation gain from each observation as well as its computational cost. The expected classiﬁcation gain is computed using a probabilistic model that uses the outcome from previous observations. This active classiﬁcation process is applied at test time for each individual test instance, resulting in an efﬁcient instance-speciﬁc decision path. We demonstrate the beneﬁt of the active scheme on various real-world datasets, and show that it can achieve comparable or even higher classiﬁcation accuracy at a fraction of the computational costs of traditional methods.</p><p>5 0.087682709 <a title="279-tfidf-5" href="./nips-2011-A_Two-Stage_Weighting_Framework_for_Multi-Source_Domain_Adaptation.html">12 nips-2011-A Two-Stage Weighting Framework for Multi-Source Domain Adaptation</a></p>
<p>Author: Qian Sun, Rita Chattopadhyay, Sethuraman Panchanathan, Jieping Ye</p><p>Abstract: Discriminative learning when training and test data belong to different distributions is a challenging and complex task. Often times we have very few or no labeled data from the test or target distribution but may have plenty of labeled data from multiple related sources with different distributions. The difference in distributions may be both in marginal and conditional probabilities. Most of the existing domain adaptation work focuses on the marginal probability distribution difference between the domains, assuming that the conditional probabilities are similar. However in many real world applications, conditional probability distribution differences are as commonplace as marginal probability differences. In this paper we propose a two-stage domain adaptation methodology which combines weighted data from multiple sources based on marginal probability differences (ﬁrst stage) as well as conditional probability differences (second stage), with the target domain data. The weights for minimizing the marginal probability differences are estimated independently, while the weights for minimizing conditional probability differences are computed simultaneously by exploiting the potential interaction among multiple sources. We also provide a theoretical analysis on the generalization performance of the proposed multi-source domain adaptation formulation using the weighted Rademacher complexity measure. Empirical comparisons with existing state-of-the-art domain adaptation methods using three real-world datasets demonstrate the effectiveness of the proposed approach. 1</p><p>6 0.086531378 <a title="279-tfidf-6" href="./nips-2011-Co-Training_for_Domain_Adaptation.html">53 nips-2011-Co-Training for Domain Adaptation</a></p>
<p>7 0.075898051 <a title="279-tfidf-7" href="./nips-2011-Learning_a_Tree_of_Metrics_with_Disjoint_Visual_Features.html">151 nips-2011-Learning a Tree of Metrics with Disjoint Visual Features</a></p>
<p>8 0.073948331 <a title="279-tfidf-8" href="./nips-2011-Metric_Learning_with_Multiple_Kernels.html">171 nips-2011-Metric Learning with Multiple Kernels</a></p>
<p>9 0.072056577 <a title="279-tfidf-9" href="./nips-2011-Agnostic_Selective_Classification.html">28 nips-2011-Agnostic Selective Classification</a></p>
<p>10 0.068348639 <a title="279-tfidf-10" href="./nips-2011-Fast_and_Balanced%3A_Efficient_Label_Tree_Learning_for_Large_Scale_Object_Recognition.html">96 nips-2011-Fast and Balanced: Efficient Label Tree Learning for Large Scale Object Recognition</a></p>
<p>11 0.068201847 <a title="279-tfidf-11" href="./nips-2011-Maximum_Margin_Multi-Instance_Learning.html">168 nips-2011-Maximum Margin Multi-Instance Learning</a></p>
<p>12 0.063916348 <a title="279-tfidf-12" href="./nips-2011-Convergent_Bounds_on_the_Euclidean_Distance.html">64 nips-2011-Convergent Bounds on the Euclidean Distance</a></p>
<p>13 0.063004725 <a title="279-tfidf-13" href="./nips-2011-Nearest_Neighbor_based_Greedy_Coordinate_Descent.html">182 nips-2011-Nearest Neighbor based Greedy Coordinate Descent</a></p>
<p>14 0.062300902 <a title="279-tfidf-14" href="./nips-2011-Beating_SGD%3A_Learning_SVMs_in_Sublinear_Time.html">45 nips-2011-Beating SGD: Learning SVMs in Sublinear Time</a></p>
<p>15 0.058984127 <a title="279-tfidf-15" href="./nips-2011-Sparse_Manifold_Clustering_and_Embedding.html">263 nips-2011-Sparse Manifold Clustering and Embedding</a></p>
<p>16 0.057817884 <a title="279-tfidf-16" href="./nips-2011-Crowdclustering.html">66 nips-2011-Crowdclustering</a></p>
<p>17 0.055945948 <a title="279-tfidf-17" href="./nips-2011-On_Learning_Discrete_Graphical_Models_using_Greedy_Methods.html">195 nips-2011-On Learning Discrete Graphical Models using Greedy Methods</a></p>
<p>18 0.055277504 <a title="279-tfidf-18" href="./nips-2011-Learning_to_Search_Efficiently_in_High_Dimensions.html">157 nips-2011-Learning to Search Efficiently in High Dimensions</a></p>
<p>19 0.054349437 <a title="279-tfidf-19" href="./nips-2011-Exploiting_spatial_overlap_to_efficiently_compute_appearance_distances_between_image_windows.html">91 nips-2011-Exploiting spatial overlap to efficiently compute appearance distances between image windows</a></p>
<p>20 0.054019149 <a title="279-tfidf-20" href="./nips-2011-Multiclass_Boosting%3A_Theory_and_Algorithms.html">178 nips-2011-Multiclass Boosting: Theory and Algorithms</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.162), (1, 0.028), (2, -0.068), (3, -0.015), (4, 0.002), (5, 0.05), (6, 0.019), (7, -0.088), (8, -0.061), (9, -0.035), (10, -0.065), (11, 0.02), (12, -0.006), (13, 0.048), (14, 0.029), (15, 0.01), (16, -0.118), (17, 0.047), (18, 0.065), (19, 0.005), (20, -0.025), (21, 0.11), (22, 0.11), (23, -0.016), (24, 0.005), (25, -0.005), (26, -0.028), (27, -0.013), (28, -0.008), (29, -0.025), (30, 0.118), (31, -0.121), (32, -0.001), (33, 0.012), (34, 0.049), (35, -0.064), (36, 0.019), (37, 0.011), (38, 0.069), (39, -0.051), (40, 0.064), (41, -0.032), (42, -0.112), (43, 0.064), (44, 0.093), (45, -0.002), (46, -0.112), (47, 0.103), (48, -0.003), (49, 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93357921 <a title="279-lsi-1" href="./nips-2011-Target_Neighbor_Consistent_Feature_Weighting_for_Nearest_Neighbor_Classification.html">279 nips-2011-Target Neighbor Consistent Feature Weighting for Nearest Neighbor Classification</a></p>
<p>Author: Ichiro Takeuchi, Masashi Sugiyama</p><p>Abstract: We consider feature selection and weighting for nearest neighbor classiﬁers. A technical challenge in this scenario is how to cope with discrete update of nearest neighbors when the feature space metric is changed during the learning process. This issue, called the target neighbor change, was not properly addressed in the existing feature weighting and metric learning literature. In this paper, we propose a novel feature weighting algorithm that can exactly and efﬁciently keep track of the correct target neighbors via sequential quadratic programming. To the best of our knowledge, this is the ﬁrst algorithm that guarantees the consistency between target neighbors and the feature space metric. We further show that the proposed algorithm can be naturally combined with regularization path tracking, allowing computationally efﬁcient selection of the regularization parameter. We demonstrate the effectiveness of the proposed algorithm through experiments. 1</p><p>2 0.63301671 <a title="279-lsi-2" href="./nips-2011-Co-Training_for_Domain_Adaptation.html">53 nips-2011-Co-Training for Domain Adaptation</a></p>
<p>Author: Minmin Chen, Kilian Q. Weinberger, John Blitzer</p><p>Abstract: Domain adaptation algorithms seek to generalize a model trained in a source domain to a new target domain. In many practical cases, the source and target distributions can differ substantially, and in some cases crucial target features may not have support in the source domain. In this paper we introduce an algorithm that bridges the gap between source and target domains by slowly adding to the training set both the target features and instances in which the current algorithm is the most conﬁdent. Our algorithm is a variant of co-training [7], and we name it CODA (Co-training for domain adaptation). Unlike the original co-training work, we do not assume a particular feature split. Instead, for each iteration of cotraining, we formulate a single optimization problem which simultaneously learns a target predictor, a split of the feature space into views, and a subset of source and target features to include in the predictor. CODA signiﬁcantly out-performs the state-of-the-art on the 12-domain benchmark data set of Blitzer et al. [4]. Indeed, over a wide range (65 of 84 comparisons) of target supervision CODA achieves the best performance. 1</p><p>3 0.58430272 <a title="279-lsi-3" href="./nips-2011-Active_Classification_based_on_Value_of_Classifier.html">19 nips-2011-Active Classification based on Value of Classifier</a></p>
<p>Author: Tianshi Gao, Daphne Koller</p><p>Abstract: Modern classiﬁcation tasks usually involve many class labels and can be informed by a broad range of features. Many of these tasks are tackled by constructing a set of classiﬁers, which are then applied at test time and then pieced together in a ﬁxed procedure determined in advance or at training time. We present an active classiﬁcation process at the test time, where each classiﬁer in a large ensemble is viewed as a potential observation that might inform our classiﬁcation process. Observations are then selected dynamically based on previous observations, using a value-theoretic computation that balances an estimate of the expected classiﬁcation gain from each observation as well as its computational cost. The expected classiﬁcation gain is computed using a probabilistic model that uses the outcome from previous observations. This active classiﬁcation process is applied at test time for each individual test instance, resulting in an efﬁcient instance-speciﬁc decision path. We demonstrate the beneﬁt of the active scheme on various real-world datasets, and show that it can achieve comparable or even higher classiﬁcation accuracy at a fraction of the computational costs of traditional methods.</p><p>4 0.57779735 <a title="279-lsi-4" href="./nips-2011-Similarity-based_Learning_via_Data_Driven_Embeddings.html">254 nips-2011-Similarity-based Learning via Data Driven Embeddings</a></p>
<p>Author: Purushottam Kar, Prateek Jain</p><p>Abstract: We consider the problem of classiﬁcation using similarity/distance functions over data. Speciﬁcally, we propose a framework for deﬁning the goodness of a (dis)similarity function with respect to a given learning task and propose algorithms that have guaranteed generalization properties when working with such good functions. Our framework uniﬁes and generalizes the frameworks proposed by [1] and [2]. An attractive feature of our framework is its adaptability to data - we do not promote a ﬁxed notion of goodness but rather let data dictate it. We show, by giving theoretical guarantees that the goodness criterion best suited to a problem can itself be learned which makes our approach applicable to a variety of domains and problems. We propose a landmarking-based approach to obtaining a classiﬁer from such learned goodness criteria. We then provide a novel diversity based heuristic to perform task-driven selection of landmark points instead of random selection. We demonstrate the effectiveness of our goodness criteria learning method as well as the landmark selection heuristic on a variety of similarity-based learning datasets and benchmark UCI datasets on which our method consistently outperforms existing approaches by a signiﬁcant margin. 1</p><p>5 0.57050067 <a title="279-lsi-5" href="./nips-2011-A_Machine_Learning_Approach_to_Predict_Chemical_Reactions.html">7 nips-2011-A Machine Learning Approach to Predict Chemical Reactions</a></p>
<p>Author: Matthew A. Kayala, Pierre F. Baldi</p><p>Abstract: Being able to predict the course of arbitrary chemical reactions is essential to the theory and applications of organic chemistry. Previous approaches are not highthroughput, are not generalizable or scalable, or lack sufﬁcient data to be effective. We describe single mechanistic reactions as concerted electron movements from an electron orbital source to an electron orbital sink. We use an existing rule-based expert system to derive a dataset consisting of 2,989 productive mechanistic steps and 6.14 million non-productive mechanistic steps. We then pose identifying productive mechanistic steps as a ranking problem: rank potential orbital interactions such that the top ranked interactions yield the major products. The machine learning implementation follows a two-stage approach, in which we ﬁrst train atom level reactivity ﬁlters to prune 94.0% of non-productive reactions with less than a 0.1% false negative rate. Then, we train an ensemble of ranking models on pairs of interacting orbitals to learn a relative productivity function over single mechanistic reactions in a given system. Without the use of explicit transformation patterns, the ensemble perfectly ranks the productive mechanisms at the top 89.1% of the time, rising to 99.9% of the time when top ranked lists with at most four nonproductive reactions are considered. The ﬁnal system allows multi-step reaction prediction. Furthermore, it is generalizable, making reasonable predictions over reactants and conditions which the rule-based expert system does not handle.</p><p>6 0.53626645 <a title="279-lsi-6" href="./nips-2011-The_Manifold_Tangent_Classifier.html">287 nips-2011-The Manifold Tangent Classifier</a></p>
<p>7 0.5323956 <a title="279-lsi-7" href="./nips-2011-ShareBoost%3A_Efficient_multiclass_learning_with_feature_sharing.html">252 nips-2011-ShareBoost: Efficient multiclass learning with feature sharing</a></p>
<p>8 0.53174973 <a title="279-lsi-8" href="./nips-2011-A_Two-Stage_Weighting_Framework_for_Multi-Source_Domain_Adaptation.html">12 nips-2011-A Two-Stage Weighting Framework for Multi-Source Domain Adaptation</a></p>
<p>9 0.53146082 <a title="279-lsi-9" href="./nips-2011-Convergent_Bounds_on_the_Euclidean_Distance.html">64 nips-2011-Convergent Bounds on the Euclidean Distance</a></p>
<p>10 0.52252328 <a title="279-lsi-10" href="./nips-2011-An_Exact_Algorithm_for_F-Measure_Maximization.html">33 nips-2011-An Exact Algorithm for F-Measure Maximization</a></p>
<p>11 0.51260084 <a title="279-lsi-11" href="./nips-2011-Submodular_Multi-Label_Learning.html">277 nips-2011-Submodular Multi-Label Learning</a></p>
<p>12 0.5101819 <a title="279-lsi-12" href="./nips-2011-Learning_a_Tree_of_Metrics_with_Disjoint_Visual_Features.html">151 nips-2011-Learning a Tree of Metrics with Disjoint Visual Features</a></p>
<p>13 0.50695127 <a title="279-lsi-13" href="./nips-2011-Agnostic_Selective_Classification.html">28 nips-2011-Agnostic Selective Classification</a></p>
<p>14 0.50127864 <a title="279-lsi-14" href="./nips-2011-Maximum_Margin_Multi-Instance_Learning.html">168 nips-2011-Maximum Margin Multi-Instance Learning</a></p>
<p>15 0.49500364 <a title="279-lsi-15" href="./nips-2011-Learning_a_Distance_Metric_from_a_Network.html">150 nips-2011-Learning a Distance Metric from a Network</a></p>
<p>16 0.48609275 <a title="279-lsi-16" href="./nips-2011-Maximum_Margin_Multi-Label_Structured_Prediction.html">169 nips-2011-Maximum Margin Multi-Label Structured Prediction</a></p>
<p>17 0.48442951 <a title="279-lsi-17" href="./nips-2011-Learning_Anchor_Planes_for_Classification.html">143 nips-2011-Learning Anchor Planes for Classification</a></p>
<p>18 0.48310742 <a title="279-lsi-18" href="./nips-2011-PiCoDes%3A_Learning_a_Compact_Code_for_Novel-Category_Recognition.html">214 nips-2011-PiCoDes: Learning a Compact Code for Novel-Category Recognition</a></p>
<p>19 0.47884673 <a title="279-lsi-19" href="./nips-2011-The_Impact_of_Unlabeled_Patterns_in_Rademacher_Complexity_Theory_for_Kernel_Classifiers.html">284 nips-2011-The Impact of Unlabeled Patterns in Rademacher Complexity Theory for Kernel Classifiers</a></p>
<p>20 0.46914047 <a title="279-lsi-20" href="./nips-2011-History_distribution_matching_method_for_predicting_effectiveness_of_HIV_combination_therapies.html">120 nips-2011-History distribution matching method for predicting effectiveness of HIV combination therapies</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.02), (4, 0.463), (20, 0.034), (26, 0.014), (31, 0.056), (33, 0.021), (43, 0.043), (45, 0.126), (57, 0.029), (65, 0.011), (74, 0.027), (83, 0.036), (99, 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.9516992 <a title="279-lda-1" href="./nips-2011-Inductive_reasoning_about_chimeric_creatures.html">130 nips-2011-Inductive reasoning about chimeric creatures</a></p>
<p>Author: Charles Kemp</p><p>Abstract: Given one feature of a novel animal, humans readily make inferences about other features of the animal. For example, winged creatures often ﬂy, and creatures that eat ﬁsh often live in the water. We explore the knowledge that supports these inferences and compare two approaches. The ﬁrst approach proposes that humans rely on abstract representations of dependency relationships between features, and is formalized here as a graphical model. The second approach proposes that humans rely on speciﬁc knowledge of previously encountered animals, and is formalized here as a family of exemplar models. We evaluate these models using a task where participants reason about chimeras, or animals with pairs of features that have not previously been observed to co-occur. The results support the hypothesis that humans rely on explicit representations of relationships between features. Suppose that an eighteenth-century naturalist learns about a new kind of animal that has fur and a duck’s bill. Even though the naturalist has never encountered an animal with this pair of features, he should be able to make predictions about other features of the animal—for example, the animal could well live in water but probably does not have feathers. Although the platypus exists in reality, from a eighteenth-century perspective it qualiﬁes as a chimera, or an animal that combines two or more features that have not previously been observed to co-occur. Here we describe a probabilistic account of inductive reasoning and use it to account for human inferences about chimeras. The inductive problems we consider are special cases of the more general problem in Figure 1a where a reasoner is given a partially observed matrix of animals by features then asked to infer the values of the missing entries. This general problem has been previously studied and is addressed by computational models of property induction, categorization, and generalization [1–7]. A challenge faced by all of these models is to capture the background knowledge that guides inductive inferences. Some accounts rely on similarity relationships between animals [6, 8], others rely on causal relationships between features [9, 10], and others incorporate relationships between animals and relationships between features [11]. We will evaluate graphical models that capture both kinds of relationships (Figure 1a), but will focus in particular on relationships between features. Psychologists have previously suggested that humans rely on explicit mental representations of relationships between features [12–16]. Often these representations are described as theories—for example, theories that specify a causal relationship between having wings and ﬂying, or living in the sea and eating ﬁsh. Relationships between features may take several forms: for example, one feature may cause, enable, prevent, be inconsistent with, or be a special case of another feature. For simplicity, we will treat all of these relationships as instances of dependency relationships between features, and will capture them using an undirected graphical model. Previous studies have used graphical models to account for human inferences about features but typically these studies consider toy problems involving a handful of novel features such as “has gene X14” or “has enzyme Y132” [9, 11]. Participants might be told, for example, that gene X14 leads to the production of enzyme Y132, then asked to use this information when reasoning about novel animals. Here we explore whether a graphical model approach can account for inferences 1 (a) slow heavy flies (b) wings hippo 1 1 0 0 rhino 1 1 0 0 sparrow 0 0 1 1 robin 0 0 1 1 new ? ? 1 ? o Figure 1: Inductive reasoning about animals and features. (a) Inferences about the features of a new animal onew that ﬂies may draw on similarity relationships between animals (the new animal is similar to sparrows and robins but not hippos and rhinos), and on dependency relationships between features (ﬂying and having wings are linked). (b) A graph product produced by combining the two graph structures in (a). about familiar features. Working with familiar features raises a methodological challenge since participants have a substantial amount of knowledge about these features and can reason about them in multiple ways. Suppose, for example, that you learn that a novel animal can ﬂy (Figure 1a). To conclude that the animal probably has wings, you might consult a mental representation similar to the graph at the top of Figure 1a that speciﬁes a dependency relationship between ﬂying and having wings. On the other hand, you might reach the same conclusion by thinking about ﬂying creatures that you have previously encountered (e.g. sparrows and robins) and noticing that these creatures have wings. Since the same conclusion can be reached in two different ways, judgments about arguments of this kind provide little evidence about the mental representations involved. The challenge of working with familiar features directly motivates our focus on chimeras. Inferences about chimeras draw on rich background knowledge but require the reasoner to go beyond past experience in a fundamental way. For example, if you learn that an animal ﬂies and has no legs, you cannot make predictions about the animal by thinking of ﬂying, no-legged creatures that you have previously encountered. You may, however, still be able to infer that the novel animal has wings if you understand the relationship between ﬂying and having wings. We propose that graphical models over features can help to explain how humans make inferences of this kind, and evaluate our approach by comparing it to a family of exemplar models. The next section introduces these models, and we then describe two experiments designed to distinguish between the models. 1 Reasoning about objects and features Our models make use of a binary matrix D where the rows {o1 , . . . , o129 } correspond to objects, and the columns {f 1 , . . . , f 56 } correspond to features. A subset of the objects is shown in Figure 2a, and the full set of features is shown in Figure 2b and its caption. Matrix D was extracted from the Leuven natural concept database [17], which includes 129 animals and 757 features in total. We chose a subset of these features that includes a mix of perceptual and behavioral features, and that includes many pairs of features that depend on each other. For example, animals that “live in water” typically “can swim,” and animals that have “no legs” cannot “jump far.” Matrix D can be used to formulate problems where a reasoner observes one or two features of a new object (i.e. animal o130 ) and must make inferences about the remaining features of the animal. The next two sections describe graphical models that can be used to address this problem. The ﬁrst graphical model O captures relationships between objects, and the second model F captures relationships between features. We then discuss how these models can be combined, and introduce a family of exemplar-style models that will be compared with our graphical models. A graphical model over objects Many accounts of inductive reasoning focus on similarity relationships between objects [6, 8]. Here we describe a tree-structured graphical model O that captures these relationships. The tree was constructed from matrix D using average linkage clustering and the Jaccard similarity measure, and part of the resulting structure is shown in Figure 2a. The subtree in Figure 2a includes clusters 2 alligator caiman crocodile monitor lizard dinosaur blindworm boa cobra python snake viper chameleon iguana gecko lizard salamander frog toad tortoise turtle anchovy herring sardine cod sole salmon trout carp pike stickleback eel flatfish ray plaice piranha sperm whale squid swordfish goldfish dolphin orca whale shark bat fox wolf beaver hedgehog hamster squirrel mouse rabbit bison elephant hippopotamus rhinoceros lion tiger polar bear deer dromedary llama giraffe zebra kangaroo monkey cat dog cow horse donkey pig sheep (a) (b) can swim lives in water eats fish eats nuts eats grain eats grass has gills can jump far has two legs has no legs has six legs has four legs can fly can be ridden has sharp teeth nocturnal has wings strong predator can see in dark eats berries lives in the sea lives in the desert crawls lives in the woods has mane lives in trees can climb well lives underground has feathers has scales slow has fur heavy Figure 2: Graph structures used to deﬁne graphical models O and F. (a) A tree that captures similarity relationships between animals. The full tree includes 129 animals, and only part of the tree is shown here. The grey points along the branches indicate locations where a novel animal o130 could be attached to the tree. (b) A network capturing pairwise dependency relationships between features. The edges capture both positive and negative dependencies. All edges in the network are shown, and the network also includes 20 isolated nodes for the following features: is black, is blue, is green, is grey, is pink, is red, is white, is yellow, is a pet, has a beak, stings, stinks, has a long neck, has feelers, sucks blood, lays eggs, makes a web, has a hump, has a trunk, and is cold-blooded. corresponding to amphibians and reptiles, aquatic creatures, and land mammals, and the subtree omitted for space includes clusters for insects and birds. We assume that the features in matrix D (i.e. the columns) are generated independently over O: P (f i |O, π i , λi ). P (D|O, π, λ) = i i i i The distribution P (f |O, π , λ ) is based on the intuition that nearby nodes in O tend to have the same value of f i . Previous researchers [8, 18] have used a directed graphical model where the distribution at the root node is based on the baserate π i , and any other node v with parent u has the following conditional probability distribution: i P (v = 1|u) = π i + (1 − π i )e−λ l , if u = 1 i π i − π i e−λ l , if u = 0 (1) where l is the length of the branch joining node u to node v. The variability parameter λi captures the extent to which feature f i is expected to vary over the tree. Note, for example, that any node v must take the same value as its parent u when λ = 0. To avoid free parameters, the feature baserates π i and variability parameters λi are set to their maximum likelihood values given the observed values of the features {f i } in the data matrix D. The conditional distributions in Equation 1 induce a joint distribution over all of the nodes in graph O, and the distribution P (f i |O, π i , λi ) is computed by marginalizing out the values of the internal nodes. Although we described O as a directed graphical model, the model can be converted into an equivalent undirected model with a potential for each edge in the tree and a potential for the root node. Here we use the undirected version of the model, which is a natural counterpart to the undirected model F described in the next section. The full version of structure O in Figure 2a includes 129 familiar animals, and our task requires inferences about a novel animal o130 that must be slotted into the structure. Let D′ be an expanded version of D that includes a row for o130 , and let O′ be an expanded version of O that includes a node for o130 . The edges in Figure 2a are marked with evenly spaced gray points, and we use a 3 uniform prior P (O′ ) over all trees that can be created by attaching o130 to one of these points. Some of these trees have identical topologies, since some edges in Figure 2a have multiple gray points. Predictions about o130 can be computed using: P (D′ |D) = P (D′ |O′ , D)P (O′ |D) ∝ O′ P (D′ |O′ , D)P (D|O′ )P (O′ ). (2) O′ Equation 2 captures the basic intuition that the distribution of features for o130 is expected to be consistent with the distribution observed for previous animals. For example, if o130 is known to ﬂy then the trees with high posterior probability P (O′ |D) will be those where o130 is near other ﬂying creatures (Figure 1a), and since these creatures have wings Equation 2 predicts that o130 probably also has wings. As this example suggests, model O captures dependency relationships between features implicitly, and therefore stands in contrast to models like F that rely on explicit representations of relationships between features. A graphical model over features Model F is an undirected graphical model deﬁned over features. The graph shown in Figure 2b was created by identifying pairs where one feature depends directly on another. The author and a research assistant both independently identiﬁed candidate sets of pairwise dependencies, and Figure 2b was created by merging these sets and reaching agreement about how to handle any discrepancies. As previous researchers have suggested [13, 15], feature dependencies can capture several kinds of relationships. For example, wings enable ﬂying, living in the sea leads to eating ﬁsh, and having no legs rules out jumping far. We work with an undirected graph because some pairs of features depend on each other but there is no clear direction of causal inﬂuence. For example, there is clearly a dependency relationship between being nocturnal and seeing in the dark, but no obvious sense in which one of these features causes the other. We assume that the rows of the object-feature matrix D are generated independently from an undirected graphical model F deﬁned over the feature structure in Figure 2b: P (oi |F). P (D|F) = i Model F includes potential functions for each node and for each edge in the graph. These potentials were learned from matrix D using the UGM toolbox for undirected graphical models [19]. The learned potentials capture both positive and negative relationships: for example, animals that live in the sea tend to eat ﬁsh, and tend not to eat berries. Some pairs of feature values never occur together in matrix D (there are no creatures that ﬂy but do not have wings). We therefore chose to compute maximum a posteriori values of the potential functions rather than maximum likelihood values, and used a diffuse Gaussian prior with a variance of 100 on the entries in each potential. After learning the potentials for model F, we can make predictions about a new object o130 using the distribution P (o130 |F). For example, if o130 is known to ﬂy (Figure 1a), model F predicts that o130 probably has wings because the learned potentials capture a positive dependency between ﬂying and having wings. Combining object and feature relationships There are two simple ways to combine models O and F in order to develop an approach that incorporates both relationships between features and relationships between objects. The output combination model computes the predictions of both models in isolation, then combines these predictions using a weighted sum. The resulting model is similar to a mixture-of-experts model, and to avoid free parameters we use a mixing weight of 0.5. The structure combination model combines the graph structures used by the two models and relies on a set of potentials deﬁned over the resulting graph product. An example of a graph product is shown in Figure 1b, and the potential functions for this graph are inherited from the component models in the natural way. Kemp et al. [11] use a similar approach to combine a functional causal model with an object model O, but note that our structure combination model uses an undirected model F rather than a functional causal model over features. Both combination models capture the intuition that inductive inferences rely on relationships between features and relationships between objects. The output combination model has the virtue of 4 simplicity, and the structure combination model is appealing because it relies on a single integrated representation that captures both relationships between features and relationships between objects. To preview our results, our data suggest that the combination models perform better overall than either O or F in isolation, and that both combination models perform about equally well. Exemplar models We will compare the family of graphical models already described with a family of exemplar models. The key difference between these model families is that the exemplar models do not rely on explicit representations of relationships between objects and relationships between features. Comparing the model families can therefore help to establish whether human inferences rely on representations of this sort. Consider ﬁrst a problem where a reasoner must predict whether object o130 has feature k after observing that it has feature i. An exemplar model addresses the problem by retrieving all previouslyobserved objects with feature i and computing the proportion that have feature k: P (ok = 1|oi = 1) = |f k & f i | |f i | (3) where |f k | is the number of objects in matrix D that have feature k, and |f k & f i | is the number that have both feature k and feature i. Note that we have streamlined our notation by using ok instead of o130 to refer to the kth feature value for object o130 . k Suppose now that the reasoner observes that object o130 has features i and j. The natural generalization of Equation 3 is: P (ok = 1|oi = 1, oj = 1) = |f k & f i & f j | |f i & f j | (4) Because we focus on chimeras, |f i & f j | = 0 and Equation 4 is not well deﬁned. We therefore evaluate an exemplar model that computes predictions for the two observed features separately then computes the weighted sum of these predictions: P (ok = 1|oi = 1, oj = 1) = wi |f k & f i | |f k & f j | + wj . i| |f |f j | (5) where the weights wi and wj must sum to one. We consider four ways in which the weights could be set. The ﬁrst strategy sets wi = wj = 0.5. The second strategy sets wi ∝ |f i |, and is consistent with an approach where the reasoner retrieves all exemplars in D that are most similar to the novel animal and reports the proportion of these exemplars that have feature k. The third strategy sets wi ∝ |f1i | , and captures the idea that features should be weighted by their distinctiveness [20]. The ﬁnal strategy sets weights according to the coherence of each feature [21]. A feature is coherent if objects with that feature tend to resemble each other overall, and we deﬁne the coherence of feature i as the expected Jaccard similarity between two randomly chosen objects from matrix D that both have feature i. Note that the ﬁnal three strategies are all consistent with previous proposals from the psychological literature, and each one might be expected to perform well. Because exemplar models and prototype models are often compared, it is natural to consider a prototype model [22] as an additional baseline. A standard prototype model would partition the 129 animals into categories and would use summary statistics for these categories to make predictions about the novel animal o130 . We will not evaluate this model because it corresponds to a coarser version of model O, which organizes the animals into a hierarchy of categories. The key characteristic shared by both models is that they explicitly capture relationships between objects but not features. 2 Experiment 1: Chimeras Our ﬁrst experiment explores how people make inferences about chimeras, or novel animals with features that have not previously been observed to co-occur. Inferences about chimeras raise challenges for exemplar models, and therefore help to establish whether humans rely on explicit representations of relationships between features. Each argument can be represented as f i , f j → f k 5 exemplar r = 0.42 7 feature F exemplar (wi = |f i |) (wi = 0.5) r = 0.44 7 object O r = 0.69 7 output combination r = 0.31 7 structure combination r = 0.59 7 r = 0.60 7 5 5 5 5 5 3 3 3 3 3 3 all 5 1 1 0 1 r = 0.06 7 conflict 0.5 1 1 0 0.5 1 r = 0.71 7 1 0 0.5 1 r = −0.02 7 1 0 0.5 1 r = 0.49 7 0 5 5 5 5 3 3 3 3 1 5 3 0.5 r = 0.57 7 5 3 1 0 0.5 1 r = 0.51 7 edge 0.5 r = 0.17 7 1 1 0 0.5 1 r = 0.64 7 1 0 0.5 1 r = 0.83 7 1 0 0.5 1 r = 0.45 7 1 0 0.5 1 r = 0.76 7 0 5 5 5 5 3 3 3 3 1 5 3 0.5 r = 0.79 7 5 3 1 1 0 0.5 1 r = 0.26 7 other 1 0 1 0 0.5 1 r = 0.25 7 1 0 0.5 1 r = 0.19 7 1 0 0.5 1 r = 0.25 7 1 0 0.5 1 r = 0.24 7 0 7 5 5 5 5 5 3 3 3 3 1 5 3 0.5 r = 0.33 3 1 1 0 0.5 1 1 0 0.5 1 1 0 0.5 1 1 0 0.5 1 1 0 0.5 1 0 0.5 1 Figure 3: Argument ratings for Experiment 1 plotted against the predictions of six models. The y-axis in each panel shows human ratings on a seven point scale, and the x-axis shows probabilities according to one of the models. Correlation coefﬁcients are shown for each plot. where f i and f k are the premises (e.g. “has no legs” and “can ﬂy”) and f k is the conclusion (e.g. “has wings”). We are especially interested in conﬂict cases where the premises f i and f j lead to opposite conclusions when taken individually: for example, most animals with no legs do not have wings, but most animals that ﬂy do have wings. Our models that incorporate feature structure F can resolve this conﬂict since F includes a dependency between “wings” and “can ﬂy” but not between “wings” and “has no legs.” Our models that do not include F cannot resolve the conﬂict and predict that humans will be uncertain about whether the novel animal has wings. Materials. The object-feature matrix D includes 447 feature pairs {f i , f j } such that none of the 129 animals has both f i and f j . We selected 40 pairs (see the supporting material) and created 400 arguments in total by choosing 10 conclusion features for each pair. The arguments can be assigned to three categories. Conﬂict cases are arguments f i , f j → f k such that the single-premise arguments f i → f k and f j → f k lead to incompatible predictions. For our purposes, two singlepremise arguments with the same conclusion are deemed incompatible if one leads to a probability greater than 0.9 according to Equation 3, and the other leads to a probability less than 0.1. Edge cases are arguments f i , f j → f k such that the feature network in Figure 2b includes an edge between f k and either f i or f j . Note that some arguments are both conﬂict cases and edge cases. All arguments that do not fall into either one of these categories will be referred to as other cases. The 400 arguments for the experiment include 154 conﬂict cases, 153 edge cases, and 120 other cases. 34 arguments are both conﬂict cases and edge cases. We chose these arguments based on three criteria. First, we avoided premise pairs that did not co-occur in matrix D but that co-occur in familiar animals that do not belong to D. For example, “is pink” and “has wings” do not co-occur in D but “ﬂamingo” is a familiar animal that has both features. Second, we avoided premise pairs that speciﬁed two different numbers of legs—for example, {“has four legs,” “has six legs”}. Finally, we aimed to include roughly equal numbers of conﬂict cases, edge cases, and other cases. Method. 16 undergraduates participated for course credit. The experiment was carried out using a custom-built computer interface, and one argument was presented on screen at a time. Participants 6 rated the probability of the conclusion on seven point scale where the endpoints were labeled “very unlikely” and “very likely.” The ten arguments for each pair of premises were presented in a block, but the order of these blocks and the order of the arguments within these blocks were randomized across participants. Results. Figure 3 shows average human judgments plotted against the predictions of six models. The plots in the ﬁrst row include all 400 arguments in the experiment, and the remaining rows show results for conﬂict cases, edge cases, and other cases. The previous section described four exemplar models, and the two shown in Figure 3 are the best performers overall. Even though the graphical models include more numerical parameters than the exemplar models, recall that these parameters are learned from matrix D rather than ﬁt to the experimental data. Matrix D also serves as the basis for the exemplar models, which means that all of the models can be compared on equal terms. The ﬁrst row of Figure 3 suggests that the three models which include feature structure F perform better than the alternatives. The output combination model is the worst of the three models that incorporate F, and the correlation achieved by this model is signiﬁcantly greater than the correlation achieved by the best exemplar model (p < 0.001, using the Fisher transformation to convert correlation coefﬁcients to z scores). Our data therefore suggest that explicit representations of relationships between features are needed to account for inductive inferences about chimeras. The model that includes the feature structure F alone performs better than the two models that combine F with the object structure O, which may not be surprising since Experiment 1 focuses speciﬁcally on novel animals that do not slot naturally into structure O. Rows two through four suggest that the conﬂict arguments in particular raise challenges for the models which do not include feature structure F. Since these conﬂict cases are arguments f i , f j → f k where f i → f k has strength greater than 0.9 and f j → f k has strength less than 0.1, the ﬁrst exemplar model averages these strengths and assigns an overall strength of around 0.5 to each argument. The second exemplar model is better able to differentiate between the conﬂict arguments, but still performs substantially worse than the three models that include structure F. The exemplar models perform better on the edge arguments, but are outperformed by the models that include F. Finally, all models achieve roughly the same level of performance on the other arguments. Although the feature model F performs best overall, the predictions of this model still leave room for improvement. The two most obvious outliers in the third plot in the top row represent the arguments {is blue, lives in desert → lives in woods} and {is pink, lives in desert → lives in woods}. Our participants sensibly infer that any animal which lives in the desert cannot simultaneously live in the woods. In contrast, the Leuven database indicates that eight of the twelve animals that live in the desert also live in the woods, and the edge in Figure 2b between “lives in the desert” and “lives in the woods” therefore represents a positive dependency relationship according to model F. This discrepancy between model and participants reﬂects the fact that participants made inferences about individual animals but the Leuven database is based on features of animal categories. Note, for example, that any individual animal is unlikely to live in the desert and the woods, but that some animal categories (including snakes, salamanders, and lizards) are found in both environments. 3 Experiment 2: Single-premise arguments Our results so far suggest that inferences about chimeras rely on explicit representations of relationships between features but provide no evidence that relationships between objects are important. It would be a mistake, however, to conclude that relationships between objects play no role in inductive reasoning. Previous studies have used object structures like the example in Figure 2a to account for inferences about novel features [11]—for example, given that alligators have enzyme Y132 in their blood, it seems likely that crocodiles also have this enzyme. Inferences about novel objects can also draw on relationships between objects rather than relationships between features. For example, given that a novel animal has a beak you will probably predict that it has feathers, not because there is any direct dependency between these two features, but because the beaked animals that you know tend to have feathers. Our second experiment explores inferences of this kind. Materials and Method. 32 undergraduates participated for course credit. The task was identical to Experiment 1 with the following exceptions. Each two-premise argument f i , f j → f k from Experiment 1 was converted into two one-premise arguments f i → f k and f j → f k , and these 7 feature F exemplar r = 0.78 7 object O r = 0.54 7 output combination r = 0.75 7 structure combination r = 0.75 7 all 5 5 5 5 5 3 3 3 3 3 1 1 0 edge 0.5 1 r = 0.87 7 1 0 0.5 1 r = 0.87 7 1 0 0.5 1 r = 0.84 7 1 0 0.5 1 r = 0.86 7 0 5 5 5 3 3 3 1 5 3 0.5 r = 0.85 7 5 3 1 1 0 0.5 1 r = 0.79 7 other r = 0.77 7 1 0 0.5 1 r = 0.21 7 1 0 0.5 1 r = 0.74 7 1 0 0.5 1 r = 0.66 7 0 5 5 5 5 3 3 3 3 1 r = 0.73 7 5 0.5 3 1 1 0 0.5 1 1 0 0.5 1 1 0 0.5 1 1 0 0.5 1 0 0.5 1 Figure 4: Argument ratings and model predictions for Experiment 2. one-premise arguments were randomly assigned to two sets. 16 participants rated the 400 arguments in the ﬁrst set, and the other 16 rated the 400 arguments in the second set. Results. Figure 4 shows average human ratings for the 800 arguments plotted against the predictions of ﬁve models. Unlike Figure 3, Figure 4 includes a single exemplar model since there is no need to consider different feature weightings in this case. Unlike Experiment 1, the feature model F performs worse than the other alternatives (p < 0.001 in all cases). Not surprisingly, this model performs relatively well for edge cases f j → f k where f j and f k are linked in Figure 2b, but the ﬁnal row shows that the model performs poorly across the remaining set of arguments. Taken together, Experiments 1 and 2 suggest that relationships between objects and relationships between features are both needed to account for human inferences. Experiment 1 rules out an exemplar approach but models that combine graph structures over objects and features perform relatively well in both experiments. We considered two methods for combining these structures and both performed equally well. Combining the knowledge captured by these structures appears to be important, and future studies can explore in detail how humans achieve this combination. 4 Conclusion This paper proposed that graphical models are useful for capturing knowledge about animals and their features and showed that a graphical model over features can account for human inferences about chimeras. A family of exemplar models and a graphical model deﬁned over objects were unable to account for our data, which suggests that humans rely on mental representations that explicitly capture dependency relationships between features. Psychologists have previously used graphical models to capture relationships between features, but our work is the ﬁrst to focus on chimeras and to explore models deﬁned over a large set of familiar features. Although a simple undirected model accounted relatively well for our data, this model is only a starting point. The model incorporates dependency relationships between features, but people know about many speciﬁc kinds of dependencies, including cases where one feature causes, enables, prevents, or is inconsistent with another. An undirected graph with only one class of edges cannot capture this knowledge in full, and richer representations will ultimately be needed in order to provide a more complete account of human reasoning. Acknowledgments I thank Madeleine Clute for assisting with this research. This work was supported in part by the Pittsburgh Life Sciences Greenhouse Opportunity Fund and by NSF grant CDI-0835797. 8 References [1] R. N. Shepard. Towards a universal law of generalization for psychological science. Science, 237:1317– 1323, 1987. [2] J. R. Anderson. The adaptive nature of human categorization. Psychological Review, 98(3):409–429, 1991. [3] E. Heit. A Bayesian analysis of some forms of inductive reasoning. In M. Oaksford and N. Chater, editors, Rational models of cognition, pages 248–274. Oxford University Press, Oxford, 1998. [4] J. B. Tenenbaum and T. L. Grifﬁths. Generalization, similarity, and Bayesian inference. Behavioral and Brain Sciences, 24:629–641, 2001. [5] C. Kemp and J. B. Tenenbaum. Structured statistical models of inductive reasoning. Psychological Review, 116(1):20–58, 2009. [6] D. N. Osherson, E. E. Smith, O. Wilkie, A. Lopez, and E. Shaﬁr. Category-based induction. Psychological Review, 97(2):185–200, 1990. [7] D. J. Navarro. Learning the context of a category. In J. Lafferty, C. K. I. Williams, J. Shawe-Taylor, R.S. Zemel, and A. Culotta, editors, Advances in Neural Information Processing Systems 23, pages 1795–1803. 2010. [8] C. Kemp, T. L. Grifﬁths, S. Stromsten, and J. B. Tenenbaum. Semi-supervised learning with trees. In Advances in Neural Information Processing Systems 16, pages 257–264. MIT Press, Cambridge, MA, 2004. [9] B. Rehder. A causal-model theory of conceptual representation and categorization. Journal of Experimental Psychology: Learning, Memory, and Cognition, 29:1141–1159, 2003. [10] B. Rehder and R. Burnett. Feature inference and the causal structure of categories. Cognitive Psychology, 50:264–314, 2005. [11] C. Kemp, P. Shafto, and J. B. Tenenbaum. An integrated account of generalization across objects and features. Cognitive Psychology, in press. [12] S. E. Barrett, H. Abdi, G. L. Murphy, and J. McCarthy Gallagher. Theory-based correlations and their role in children’s concepts. Child Development, 64:1595–1616, 1993. [13] S. A. Sloman, B. C. Love, and W. Ahn. Feature centrality and conceptual coherence. Cognitive Science, 22(2):189–228, 1998. [14] D. Yarlett and M. Ramscar. A quantitative model of counterfactual reasoning. In T. G. Dietterich, S. Becker, and Z. Ghahramani, editors, Advances in Neural Information Processing Systems 14, pages 123–130. MIT Press, Cambridge, MA, 2002. [15] W. Ahn, J. K. Marsh, C. C. Luhmann, and K. Lee. Effect of theory-based feature correlations on typicality judgments. Memory and Cognition, 30(1):107–118, 2002. [16] D. C. Meehan C. McNorgan, R. A. Kotack and K. McRae. Feature-feature causal relations and statistical co-occurrences in object concepts. Memory and Cognition, 35(3):418–431, 2007. [17] S. De Deyne, S. Verheyen, E. Ameel, W. Vanpaemel, M. J. Dry, W. Voorspoels, and G. Storms. Exemplar by feature applicability matrices and other Dutch normative data for semantic concepts. Behavior Research Methods, 40(4):1030–1048, 2008. [18] J. P. Huelsenbeck and F. Ronquist. MRBAYES: Bayesian inference of phylogenetic trees. Bioinformatics, 17(8):754–755, 2001. [19] M. Schmidt. UGM: A Matlab toolbox for probabilistic undirected graphical models. 2007. Available at http://people.cs.ubc.ca/∼schmidtm/Software/UGM.html. [20] L. J. Nelson and D. T. Miller. The distinctiveness effect in social categorization: you are what makes you unusual. Psychological Science, 6:246–249, 1995. [21] A. L. Patalano, S. Chin-Parker, and B. H. Ross. The importance of being coherent: category coherence, cross-classiﬁcation and reasoning. Journal of memory and language, 54:407–424, 2006. [22] S. K. Reed. Pattern recognition and categorization. Cognitive Psychology, 3:393–407, 1972. 9</p><p>2 0.92887944 <a title="279-lda-2" href="./nips-2011-Approximating_Semidefinite_Programs_in_Sublinear_Time.html">39 nips-2011-Approximating Semidefinite Programs in Sublinear Time</a></p>
<p>Author: Dan Garber, Elad Hazan</p><p>Abstract: In recent years semideﬁnite optimization has become a tool of major importance in various optimization and machine learning problems. In many of these problems the amount of data in practice is so large that there is a constant need for faster algorithms. In this work we present the ﬁrst sublinear time approximation algorithm for semideﬁnite programs which we believe may be useful for such problems in which the size of data may cause even linear time algorithms to have prohibitive running times in practice. We present the algorithm and its analysis alongside with some theoretical lower bounds and an improved algorithm for the special problem of supervised learning of a distance metric. 1</p><p>3 0.921211 <a title="279-lda-3" href="./nips-2011-Object_Detection_with_Grammar_Models.html">193 nips-2011-Object Detection with Grammar Models</a></p>
<p>Author: Ross B. Girshick, Pedro F. Felzenszwalb, David A. McAllester</p><p>Abstract: Compositional models provide an elegant formalism for representing the visual appearance of highly variable objects. While such models are appealing from a theoretical point of view, it has been difﬁcult to demonstrate that they lead to performance advantages on challenging datasets. Here we develop a grammar model for person detection and show that it outperforms previous high-performance systems on the PASCAL benchmark. Our model represents people using a hierarchy of deformable parts, variable structure and an explicit model of occlusion for partially visible objects. To train the model, we introduce a new discriminative framework for learning structured prediction models from weakly-labeled data. 1</p><p>4 0.87606645 <a title="279-lda-4" href="./nips-2011-Phase_transition_in_the_family_of_p-resistances.html">213 nips-2011-Phase transition in the family of p-resistances</a></p>
<p>Author: Morteza Alamgir, Ulrike V. Luxburg</p><p>Abstract: We study the family of p-resistances on graphs for p 1. This family generalizes the standard resistance distance. We prove that for any ﬁxed graph, for p = 1 the p-resistance coincides with the shortest path distance, for p = 2 it coincides with the standard resistance distance, and for p ! 1 it converges to the inverse of the minimal s-t-cut in the graph. Secondly, we consider the special case of random geometric graphs (such as k-nearest neighbor graphs) when the number n of vertices in the graph tends to inﬁnity. We prove that an interesting phase transition takes place. There exist two critical thresholds p⇤ and p⇤⇤ such that if p < p⇤ , then the p-resistance depends on meaningful global properties of the graph, whereas if p > p⇤⇤ , it only depends on trivial local quantities and does not convey any useful information. We can explicitly compute the critical values: p⇤ = 1 + 1/(d 1) and p⇤⇤ = 1 + 1/(d 2) where d is the dimension of the underlying space (we believe that the fact that there is a small gap between p⇤ and p⇤⇤ is an artifact of our proofs). We also relate our ﬁndings to Laplacian regularization and suggest to use q-Laplacians as regularizers, where q satisﬁes 1/p⇤ + 1/q = 1. 1</p><p>same-paper 5 0.85666144 <a title="279-lda-5" href="./nips-2011-Target_Neighbor_Consistent_Feature_Weighting_for_Nearest_Neighbor_Classification.html">279 nips-2011-Target Neighbor Consistent Feature Weighting for Nearest Neighbor Classification</a></p>
<p>Author: Ichiro Takeuchi, Masashi Sugiyama</p><p>Abstract: We consider feature selection and weighting for nearest neighbor classiﬁers. A technical challenge in this scenario is how to cope with discrete update of nearest neighbors when the feature space metric is changed during the learning process. This issue, called the target neighbor change, was not properly addressed in the existing feature weighting and metric learning literature. In this paper, we propose a novel feature weighting algorithm that can exactly and efﬁciently keep track of the correct target neighbors via sequential quadratic programming. To the best of our knowledge, this is the ﬁrst algorithm that guarantees the consistency between target neighbors and the feature space metric. We further show that the proposed algorithm can be naturally combined with regularization path tracking, allowing computationally efﬁcient selection of the regularization parameter. We demonstrate the effectiveness of the proposed algorithm through experiments. 1</p><p>6 0.80520767 <a title="279-lda-6" href="./nips-2011-Kernel_Bayes%27_Rule.html">139 nips-2011-Kernel Bayes' Rule</a></p>
<p>7 0.71705085 <a title="279-lda-7" href="./nips-2011-Image_Parsing_with_Stochastic_Scene_Grammar.html">127 nips-2011-Image Parsing with Stochastic Scene Grammar</a></p>
<p>8 0.64549571 <a title="279-lda-8" href="./nips-2011-Convergent_Bounds_on_the_Euclidean_Distance.html">64 nips-2011-Convergent Bounds on the Euclidean Distance</a></p>
<p>9 0.60453254 <a title="279-lda-9" href="./nips-2011-See_the_Tree_Through_the_Lines%3A_The_Shazoo_Algorithm.html">242 nips-2011-See the Tree Through the Lines: The Shazoo Algorithm</a></p>
<p>10 0.59204769 <a title="279-lda-10" href="./nips-2011-Maximal_Cliques_that_Satisfy_Hard_Constraints_with_Application_to_Deformable_Object_Model_Learning.html">166 nips-2011-Maximal Cliques that Satisfy Hard Constraints with Application to Deformable Object Model Learning</a></p>
<p>11 0.59078652 <a title="279-lda-11" href="./nips-2011-Learning_person-object_interactions_for_action_recognition_in_still_images.html">154 nips-2011-Learning person-object interactions for action recognition in still images</a></p>
<p>12 0.57558078 <a title="279-lda-12" href="./nips-2011-Maximum_Margin_Multi-Instance_Learning.html">168 nips-2011-Maximum Margin Multi-Instance Learning</a></p>
<p>13 0.57039642 <a title="279-lda-13" href="./nips-2011-Randomized_Algorithms_for_Comparison-based_Search.html">231 nips-2011-Randomized Algorithms for Comparison-based Search</a></p>
<p>14 0.56935298 <a title="279-lda-14" href="./nips-2011-Dynamical_segmentation_of_single_trials_from_population_neural_data.html">75 nips-2011-Dynamical segmentation of single trials from population neural data</a></p>
<p>15 0.56675142 <a title="279-lda-15" href="./nips-2011-Learning_a_Distance_Metric_from_a_Network.html">150 nips-2011-Learning a Distance Metric from a Network</a></p>
<p>16 0.56475008 <a title="279-lda-16" href="./nips-2011-Rapid_Deformable_Object_Detection_using_Dual-Tree_Branch-and-Bound.html">233 nips-2011-Rapid Deformable Object Detection using Dual-Tree Branch-and-Bound</a></p>
<p>17 0.55709833 <a title="279-lda-17" href="./nips-2011-Online_Learning%3A_Stochastic%2C_Constrained%2C_and_Smoothed_Adversaries.html">204 nips-2011-Online Learning: Stochastic, Constrained, and Smoothed Adversaries</a></p>
<p>18 0.53596079 <a title="279-lda-18" href="./nips-2011-Video_Annotation_and_Tracking_with_Active_Learning.html">303 nips-2011-Video Annotation and Tracking with Active Learning</a></p>
<p>19 0.53238428 <a title="279-lda-19" href="./nips-2011-Newtron%3A_an_Efficient_Bandit_algorithm_for_Online_Multiclass_Prediction.html">185 nips-2011-Newtron: an Efficient Bandit algorithm for Online Multiclass Prediction</a></p>
<p>20 0.53098917 <a title="279-lda-20" href="./nips-2011-Advice_Refinement_in_Knowledge-Based_SVMs.html">27 nips-2011-Advice Refinement in Knowledge-Based SVMs</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
