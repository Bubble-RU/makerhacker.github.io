<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>151 nips-2011-Learning a Tree of Metrics with Disjoint Visual Features</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-151" href="#">nips2011-151</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>151 nips-2011-Learning a Tree of Metrics with Disjoint Visual Features</h1>
<br/><p>Source: <a title="nips-2011-151-pdf" href="http://papers.nips.cc/paper/4250-learning-a-tree-of-metrics-with-disjoint-visual-features.pdf">pdf</a></p><p>Author: Kristen Grauman, Fei Sha, Sung J. Hwang</p><p>Abstract: We introduce an approach to learn discriminative visual representations while exploiting external semantic knowledge about object category relationships. Given a hierarchical taxonomy that captures semantic similarity between the objects, we learn a corresponding tree of metrics (ToM). In this tree, we have one metric for each non-leaf node of the object hierarchy, and each metric is responsible for discriminating among its immediate subcategory children. Speciﬁcally, a Mahalanobis metric learned for a given node must satisfy the appropriate (dis)similarity constraints generated only among its subtree members’ training instances. To further exploit the semantics, we introduce a novel regularizer coupling the metrics that prefers a sparse disjoint set of features to be selected for each metric relative to its ancestor (supercategory) nodes’ metrics. Intuitively, this reﬂects that visual cues most useful to distinguish the generic classes (e.g., feline vs. canine) should be different than those cues most useful to distinguish their component ﬁne-grained classes (e.g., Persian cat vs. Siamese cat). We validate our approach with multiple image datasets using the WordNet taxonomy, show its advantages over alternative metric learning approaches, and analyze the meaning of attribute features selected by our algorithm. 1</p><p>Reference: <a title="nips-2011-151-reference" href="../nips2011_reference/nips-2011-Learning_a_Tree_of_Metrics_with_Disjoint_Visual_Features_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('tom', 0.416), ('lmnn', 0.381), ('met', 0.328), ('disjoint', 0.306), ('sem', 0.186), ('mahalanob', 0.135), ('mt', 0.122), ('feat', 0.12), ('nod', 0.12), ('hierarchy', 0.117), ('ijl', 0.116), ('superclass', 0.113), ('attribut', 0.111), ('categ', 0.098), ('spars', 0.098), ('equin', 0.094), ('taxonom', 0.09), ('vehic', 0.087), ('hierarch', 0.084), ('discrimin', 0.079)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999934 <a title="151-tfidf-1" href="./nips-2011-Learning_a_Tree_of_Metrics_with_Disjoint_Visual_Features.html">151 nips-2011-Learning a Tree of Metrics with Disjoint Visual Features</a></p>
<p>Author: Kristen Grauman, Fei Sha, Sung J. Hwang</p><p>Abstract: We introduce an approach to learn discriminative visual representations while exploiting external semantic knowledge about object category relationships. Given a hierarchical taxonomy that captures semantic similarity between the objects, we learn a corresponding tree of metrics (ToM). In this tree, we have one metric for each non-leaf node of the object hierarchy, and each metric is responsible for discriminating among its immediate subcategory children. Speciﬁcally, a Mahalanobis metric learned for a given node must satisfy the appropriate (dis)similarity constraints generated only among its subtree members’ training instances. To further exploit the semantics, we introduce a novel regularizer coupling the metrics that prefers a sparse disjoint set of features to be selected for each metric relative to its ancestor (supercategory) nodes’ metrics. Intuitively, this reﬂects that visual cues most useful to distinguish the generic classes (e.g., feline vs. canine) should be different than those cues most useful to distinguish their component ﬁne-grained classes (e.g., Persian cat vs. Siamese cat). We validate our approach with multiple image datasets using the WordNet taxonomy, show its advantages over alternative metric learning approaches, and analyze the meaning of attribute features selected by our algorithm. 1</p><p>2 0.28511637 <a title="151-tfidf-2" href="./nips-2011-Metric_Learning_with_Multiple_Kernels.html">171 nips-2011-Metric Learning with Multiple Kernels</a></p>
<p>Author: Jun Wang, Huyen T. Do, Adam Woznica, Alexandros Kalousis</p><p>Abstract: Metric learning has become a very active research ﬁeld. The most popular representative–Mahalanobis metric learning–can be seen as learning a linear transformation and then computing the Euclidean metric in the transformed space. Since a linear transformation might not always be appropriate for a given learning problem, kernelized versions of various metric learning algorithms exist. However, the problem then becomes ﬁnding the appropriate kernel function. Multiple kernel learning addresses this limitation by learning a linear combination of a number of predeﬁned kernels; this approach can be also readily used in the context of multiple-source learning to fuse different data sources. Surprisingly, and despite the extensive work on multiple kernel learning for SVMs, there has been no work in the area of metric learning with multiple kernel learning. In this paper we ﬁll this gap and present a general approach for metric learning with multiple kernel learning. Our approach can be instantiated with different metric learning algorithms provided that they satisfy some constraints. Experimental evidence suggests that our approach outperforms metric learning with an unweighted kernel combination and metric learning with cross-validation based kernel selection. 1</p><p>3 0.19680658 <a title="151-tfidf-3" href="./nips-2011-Large-Scale_Category_Structure_Aware_Image_Categorization.html">141 nips-2011-Large-Scale Category Structure Aware Image Categorization</a></p>
<p>Author: Bin Zhao, Fei Li, Eric P. Xing</p><p>Abstract: Most previous research on image categorization has focused on medium-scale data sets, while large-scale image categorization with millions of images from thousands of categories remains a challenge. With the emergence of structured large-scale dataset such as the ImageNet, rich information about the conceptual relationships between images, such as a tree hierarchy among various image categories, become available. As human cognition of complex visual world beneﬁts from underlying semantic relationships between object classes, we believe a machine learning system can and should leverage such information as well for better performance. In this paper, we employ such semantic relatedness among image categories for large-scale image categorization. Speciﬁcally, a category hierarchy is utilized to properly deﬁne loss function and select common set of features for related categories. An efﬁcient optimization method based on proximal approximation and accelerated parallel gradient method is introduced. Experimental results on a subset of ImageNet containing 1.2 million images from 1000 categories demonstrate the effectiveness and promise of our proposed approach. 1</p><p>4 0.1711251 <a title="151-tfidf-4" href="./nips-2011-%24%5Ctheta%24-MRF%3A_Capturing_Spatial_and_Semantic_Structure_in_the_Parameters_for_Scene_Understanding.html">1 nips-2011-$\theta$-MRF: Capturing Spatial and Semantic Structure in the Parameters for Scene Understanding</a></p>
<p>Author: Congcong Li, Ashutosh Saxena, Tsuhan Chen</p><p>Abstract: For most scene understanding tasks (such as object detection or depth estimation), the classiﬁers need to consider contextual information in addition to the local features. We can capture such contextual information by taking as input the features/attributes from all the regions in the image. However, this contextual dependence also varies with the spatial location of the region of interest, and we therefore need a different set of parameters for each spatial location. This results in a very large number of parameters. In this work, we model the independence properties between the parameters for each location and for each task, by deﬁning a Markov Random Field (MRF) over the parameters. In particular, two sets of parameters are encouraged to have similar values if they are spatially close or semantically close. Our method is, in principle, complementary to other ways of capturing context such as the ones that use a graphical model over the labels instead. In extensive evaluation over two different settings, of multi-class object detection and of multiple scene understanding tasks (scene categorization, depth estimation, geometric labeling), our method beats the state-of-the-art methods in all the four tasks. 1</p><p>5 0.16980956 <a title="151-tfidf-5" href="./nips-2011-Fast_and_Balanced%3A_Efficient_Label_Tree_Learning_for_Large_Scale_Object_Recognition.html">96 nips-2011-Fast and Balanced: Efficient Label Tree Learning for Large Scale Object Recognition</a></p>
<p>Author: Jia Deng, Sanjeev Satheesh, Alexander C. Berg, Fei Li</p><p>Abstract: We present a novel approach to efﬁciently learn a label tree for large scale classiﬁcation with many classes. The key contribution of the approach is a technique to simultaneously determine the structure of the tree and learn the classiﬁers for each node in the tree. This approach also allows ﬁne grained control over the efﬁciency vs accuracy trade-off in designing a label tree, leading to more balanced trees. Experiments are performed on large scale image classiﬁcation with 10184 classes and 9 million images. We demonstrate signiﬁcant improvements in test accuracy and efﬁciency with less training time and more balanced trees compared to the previous state of the art by Bengio et al. 1</p><p>6 0.15041137 <a title="151-tfidf-6" href="./nips-2011-Maximum_Margin_Multi-Instance_Learning.html">168 nips-2011-Maximum Margin Multi-Instance Learning</a></p>
<p>7 0.12703119 <a title="151-tfidf-7" href="./nips-2011-Learning_a_Distance_Metric_from_a_Network.html">150 nips-2011-Learning a Distance Metric from a Network</a></p>
<p>8 0.12244658 <a title="151-tfidf-8" href="./nips-2011-Sparse_Filtering.html">261 nips-2011-Sparse Filtering</a></p>
<p>9 0.11478468 <a title="151-tfidf-9" href="./nips-2011-PiCoDes%3A_Learning_a_Compact_Code_for_Novel-Category_Recognition.html">214 nips-2011-PiCoDes: Learning a Compact Code for Novel-Category Recognition</a></p>
<p>10 0.10986317 <a title="151-tfidf-10" href="./nips-2011-Understanding_the_Intrinsic_Memorability_of_Images.html">293 nips-2011-Understanding the Intrinsic Memorability of Images</a></p>
<p>11 0.09654393 <a title="151-tfidf-11" href="./nips-2011-Dimensionality_Reduction_Using_the_Sparse_Linear_Model.html">70 nips-2011-Dimensionality Reduction Using the Sparse Linear Model</a></p>
<p>12 0.095780224 <a title="151-tfidf-12" href="./nips-2011-Im2Text%3A_Describing_Images_Using_1_Million_Captioned_Photographs.html">126 nips-2011-Im2Text: Describing Images Using 1 Million Captioned Photographs</a></p>
<p>13 0.094709858 <a title="151-tfidf-13" href="./nips-2011-Selecting_Receptive_Fields_in_Deep_Networks.html">244 nips-2011-Selecting Receptive Fields in Deep Networks</a></p>
<p>14 0.091892518 <a title="151-tfidf-14" href="./nips-2011-Structural_equations_and_divisive_normalization_for_energy-dependent_component_analysis.html">273 nips-2011-Structural equations and divisive normalization for energy-dependent component analysis</a></p>
<p>15 0.090101808 <a title="151-tfidf-15" href="./nips-2011-Multi-armed_bandits_on_implicit_metric_spaces.html">177 nips-2011-Multi-armed bandits on implicit metric spaces</a></p>
<p>16 0.08842323 <a title="151-tfidf-16" href="./nips-2011-Matrix_Completion_for_Multi-label_Image_Classification.html">165 nips-2011-Matrix Completion for Multi-label Image Classification</a></p>
<p>17 0.086072214 <a title="151-tfidf-17" href="./nips-2011-Learning_to_Search_Efficiently_in_High_Dimensions.html">157 nips-2011-Learning to Search Efficiently in High Dimensions</a></p>
<p>18 0.086058162 <a title="151-tfidf-18" href="./nips-2011-Sparse_Bayesian_Multi-Task_Learning.html">258 nips-2011-Sparse Bayesian Multi-Task Learning</a></p>
<p>19 0.08603961 <a title="151-tfidf-19" href="./nips-2011-Kernel_Embeddings_of_Latent_Tree_Graphical_Models.html">140 nips-2011-Kernel Embeddings of Latent Tree Graphical Models</a></p>
<p>20 0.085332513 <a title="151-tfidf-20" href="./nips-2011-Hierarchical_Multitask_Structured_Output_Learning_for_Large-scale_Sequence_Segmentation.html">114 nips-2011-Hierarchical Multitask Structured Output Learning for Large-scale Sequence Segmentation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.258), (1, -0.022), (2, 0.157), (3, -0.058), (4, -0.058), (5, 0.065), (6, 0.031), (7, -0.004), (8, -0.095), (9, -0.036), (10, 0.057), (11, -0.092), (12, 0.111), (13, 0.035), (14, -0.126), (15, 0.008), (16, 0.078), (17, 0.12), (18, 0.045), (19, 0.044), (20, -0.057), (21, 0.011), (22, -0.096), (23, 0.006), (24, -0.126), (25, 0.124), (26, -0.084), (27, 0.045), (28, -0.059), (29, 0.024), (30, 0.019), (31, -0.012), (32, 0.005), (33, -0.032), (34, -0.15), (35, 0.156), (36, 0.114), (37, -0.06), (38, 0.032), (39, 0.036), (40, -0.057), (41, 0.012), (42, 0.099), (43, 0.142), (44, -0.028), (45, 0.14), (46, -0.099), (47, -0.095), (48, 0.053), (49, -0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93983603 <a title="151-lsi-1" href="./nips-2011-Learning_a_Tree_of_Metrics_with_Disjoint_Visual_Features.html">151 nips-2011-Learning a Tree of Metrics with Disjoint Visual Features</a></p>
<p>Author: Kristen Grauman, Fei Sha, Sung J. Hwang</p><p>Abstract: We introduce an approach to learn discriminative visual representations while exploiting external semantic knowledge about object category relationships. Given a hierarchical taxonomy that captures semantic similarity between the objects, we learn a corresponding tree of metrics (ToM). In this tree, we have one metric for each non-leaf node of the object hierarchy, and each metric is responsible for discriminating among its immediate subcategory children. Speciﬁcally, a Mahalanobis metric learned for a given node must satisfy the appropriate (dis)similarity constraints generated only among its subtree members’ training instances. To further exploit the semantics, we introduce a novel regularizer coupling the metrics that prefers a sparse disjoint set of features to be selected for each metric relative to its ancestor (supercategory) nodes’ metrics. Intuitively, this reﬂects that visual cues most useful to distinguish the generic classes (e.g., feline vs. canine) should be different than those cues most useful to distinguish their component ﬁne-grained classes (e.g., Persian cat vs. Siamese cat). We validate our approach with multiple image datasets using the WordNet taxonomy, show its advantages over alternative metric learning approaches, and analyze the meaning of attribute features selected by our algorithm. 1</p><p>2 0.71332222 <a title="151-lsi-2" href="./nips-2011-Learning_a_Distance_Metric_from_a_Network.html">150 nips-2011-Learning a Distance Metric from a Network</a></p>
<p>Author: Blake Shaw, Bert Huang, Tony Jebara</p><p>Abstract: Many real-world networks are described by both connectivity information and features for every node. To better model and understand these networks, we present structure preserving metric learning (SPML), an algorithm for learning a Mahalanobis distance metric from a network such that the learned distances are tied to the inherent connectivity structure of the network. Like the graph embedding algorithm structure preserving embedding, SPML learns a metric which is structure preserving, meaning a connectivity algorithm such as k-nearest neighbors will yield the correct connectivity when applied using the distances from the learned metric. We show a variety of synthetic and real-world experiments where SPML predicts link patterns from node features more accurately than standard techniques. We further demonstrate a method for optimizing SPML based on stochastic gradient descent which removes the running-time dependency on the size of the network and allows the method to easily scale to networks of thousands of nodes and millions of edges. 1</p><p>3 0.69876397 <a title="151-lsi-3" href="./nips-2011-Metric_Learning_with_Multiple_Kernels.html">171 nips-2011-Metric Learning with Multiple Kernels</a></p>
<p>Author: Jun Wang, Huyen T. Do, Adam Woznica, Alexandros Kalousis</p><p>Abstract: Metric learning has become a very active research ﬁeld. The most popular representative–Mahalanobis metric learning–can be seen as learning a linear transformation and then computing the Euclidean metric in the transformed space. Since a linear transformation might not always be appropriate for a given learning problem, kernelized versions of various metric learning algorithms exist. However, the problem then becomes ﬁnding the appropriate kernel function. Multiple kernel learning addresses this limitation by learning a linear combination of a number of predeﬁned kernels; this approach can be also readily used in the context of multiple-source learning to fuse different data sources. Surprisingly, and despite the extensive work on multiple kernel learning for SVMs, there has been no work in the area of metric learning with multiple kernel learning. In this paper we ﬁll this gap and present a general approach for metric learning with multiple kernel learning. Our approach can be instantiated with different metric learning algorithms provided that they satisfy some constraints. Experimental evidence suggests that our approach outperforms metric learning with an unweighted kernel combination and metric learning with cross-validation based kernel selection. 1</p><p>4 0.68280703 <a title="151-lsi-4" href="./nips-2011-Large-Scale_Category_Structure_Aware_Image_Categorization.html">141 nips-2011-Large-Scale Category Structure Aware Image Categorization</a></p>
<p>Author: Bin Zhao, Fei Li, Eric P. Xing</p><p>Abstract: Most previous research on image categorization has focused on medium-scale data sets, while large-scale image categorization with millions of images from thousands of categories remains a challenge. With the emergence of structured large-scale dataset such as the ImageNet, rich information about the conceptual relationships between images, such as a tree hierarchy among various image categories, become available. As human cognition of complex visual world beneﬁts from underlying semantic relationships between object classes, we believe a machine learning system can and should leverage such information as well for better performance. In this paper, we employ such semantic relatedness among image categories for large-scale image categorization. Speciﬁcally, a category hierarchy is utilized to properly deﬁne loss function and select common set of features for related categories. An efﬁcient optimization method based on proximal approximation and accelerated parallel gradient method is introduced. Experimental results on a subset of ImageNet containing 1.2 million images from 1000 categories demonstrate the effectiveness and promise of our proposed approach. 1</p><p>5 0.656928 <a title="151-lsi-5" href="./nips-2011-Maximum_Margin_Multi-Instance_Learning.html">168 nips-2011-Maximum Margin Multi-Instance Learning</a></p>
<p>Author: Hua Wang, Heng Huang, Farhad Kamangar, Feiping Nie, Chris H. Ding</p><p>Abstract: Multi-instance learning (MIL) considers input as bags of instances, in which labels are assigned to the bags. MIL is useful in many real-world applications. For example, in image categorization semantic meanings (labels) of an image mostly arise from its regions (instances) instead of the entire image (bag). Existing MIL methods typically build their models using the Bag-to-Bag (B2B) distance, which are often computationally expensive and may not truly reﬂect the semantic similarities. To tackle this, in this paper we approach MIL problems from a new perspective using the Class-to-Bag (C2B) distance, which directly assesses the relationships between the classes and the bags. Taking into account the two major challenges in MIL, high heterogeneity on data and weak label association, we propose a novel Maximum Margin Multi-Instance Learning (M3 I) approach to parameterize the C2B distance by introducing the class speciﬁc distance metrics and the locally adaptive signiﬁcance coefﬁcients. We apply our new approach to the automatic image categorization tasks on three (one single-label and two multilabel) benchmark data sets. Extensive experiments have demonstrated promising results that validate the proposed method.</p><p>6 0.62343562 <a title="151-lsi-6" href="./nips-2011-PiCoDes%3A_Learning_a_Compact_Code_for_Novel-Category_Recognition.html">214 nips-2011-PiCoDes: Learning a Compact Code for Novel-Category Recognition</a></p>
<p>7 0.6184805 <a title="151-lsi-7" href="./nips-2011-Fast_and_Balanced%3A_Efficient_Label_Tree_Learning_for_Large_Scale_Object_Recognition.html">96 nips-2011-Fast and Balanced: Efficient Label Tree Learning for Large Scale Object Recognition</a></p>
<p>8 0.59397107 <a title="151-lsi-8" href="./nips-2011-Target_Neighbor_Consistent_Feature_Weighting_for_Nearest_Neighbor_Classification.html">279 nips-2011-Target Neighbor Consistent Feature Weighting for Nearest Neighbor Classification</a></p>
<p>9 0.53976506 <a title="151-lsi-9" href="./nips-2011-Heavy-tailed_Distances_for_Gradient_Based_Image_Descriptors.html">112 nips-2011-Heavy-tailed Distances for Gradient Based Image Descriptors</a></p>
<p>10 0.53623211 <a title="151-lsi-10" href="./nips-2011-%24%5Ctheta%24-MRF%3A_Capturing_Spatial_and_Semantic_Structure_in_the_Parameters_for_Scene_Understanding.html">1 nips-2011-$\theta$-MRF: Capturing Spatial and Semantic Structure in the Parameters for Scene Understanding</a></p>
<p>11 0.51940173 <a title="151-lsi-11" href="./nips-2011-Dynamic_Pooling_and_Unfolding_Recursive_Autoencoders_for_Paraphrase_Detection.html">74 nips-2011-Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection</a></p>
<p>12 0.51877356 <a title="151-lsi-12" href="./nips-2011-Matrix_Completion_for_Multi-label_Image_Classification.html">165 nips-2011-Matrix Completion for Multi-label Image Classification</a></p>
<p>13 0.51640642 <a title="151-lsi-13" href="./nips-2011-Active_Classification_based_on_Value_of_Classifier.html">19 nips-2011-Active Classification based on Value of Classifier</a></p>
<p>14 0.51273125 <a title="151-lsi-14" href="./nips-2011-See_the_Tree_Through_the_Lines%3A_The_Shazoo_Algorithm.html">242 nips-2011-See the Tree Through the Lines: The Shazoo Algorithm</a></p>
<p>15 0.50888717 <a title="151-lsi-15" href="./nips-2011-Optimistic_Optimization_of_a_Deterministic_Function_without_the_Knowledge_of_its_Smoothness.html">208 nips-2011-Optimistic Optimization of a Deterministic Function without the Knowledge of its Smoothness</a></p>
<p>16 0.48641023 <a title="151-lsi-16" href="./nips-2011-Multi-armed_bandits_on_implicit_metric_spaces.html">177 nips-2011-Multi-armed bandits on implicit metric spaces</a></p>
<p>17 0.48514688 <a title="151-lsi-17" href="./nips-2011-Projection_onto_A_Nonnegative_Max-Heap.html">226 nips-2011-Projection onto A Nonnegative Max-Heap</a></p>
<p>18 0.48323616 <a title="151-lsi-18" href="./nips-2011-ShareBoost%3A_Efficient_multiclass_learning_with_feature_sharing.html">252 nips-2011-ShareBoost: Efficient multiclass learning with feature sharing</a></p>
<p>19 0.48251805 <a title="151-lsi-19" href="./nips-2011-Reconstructing_Patterns_of_Information_Diffusion_from_Incomplete_Observations.html">234 nips-2011-Reconstructing Patterns of Information Diffusion from Incomplete Observations</a></p>
<p>20 0.47063959 <a title="151-lsi-20" href="./nips-2011-Semantic_Labeling_of_3D_Point_Clouds_for_Indoor_Scenes.html">247 nips-2011-Semantic Labeling of 3D Point Clouds for Indoor Scenes</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.039), (22, 0.044), (36, 0.476), (55, 0.108), (58, 0.01), (65, 0.06), (68, 0.149)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.8633799 <a title="151-lda-1" href="./nips-2011-Semantic_Labeling_of_3D_Point_Clouds_for_Indoor_Scenes.html">247 nips-2011-Semantic Labeling of 3D Point Clouds for Indoor Scenes</a></p>
<p>Author: Hema S. Koppula, Abhishek Anand, Thorsten Joachims, Ashutosh Saxena</p><p>Abstract: Inexpensive RGB-D cameras that give an RGB image together with depth data have become widely available. In this paper, we use this data to build 3D point clouds of full indoor scenes such as an ofﬁce and address the task of semantic labeling of these 3D point clouds. We propose a graphical model that captures various features and contextual relations, including the local visual appearance and shape cues, object co-occurence relationships and geometric relationships. With a large number of object classes and relations, the model’s parsimony becomes important and we address that by using multiple types of edge potentials. The model admits efﬁcient approximate inference, and we train it using a maximum-margin learning approach. In our experiments over a total of 52 3D scenes of homes and ofﬁces (composed from about 550 views, having 2495 segments labeled with 27 object classes), we get a performance of 84.06% in labeling 17 object classes for ofﬁces, and 73.38% in labeling 17 object classes for home scenes. Finally, we applied these algorithms successfully on a mobile robot for the task of ﬁnding objects in large cluttered rooms.1 1</p><p>2 0.85089594 <a title="151-lda-2" href="./nips-2011-Learning_Higher-Order_Graph_Structure_with_Features_by_Structure_Penalty.html">146 nips-2011-Learning Higher-Order Graph Structure with Features by Structure Penalty</a></p>
<p>Author: Shilin Ding, Grace Wahba, Xiaojin Zhu</p><p>Abstract: In discrete undirected graphical models, the conditional independence of node labels Y is speciﬁed by the graph structure. We study the case where there is another input random vector X (e.g. observed features) such that the distribution P (Y | X) is determined by functions of X that characterize the (higher-order) interactions among the Y ’s. The main contribution of this paper is to learn the graph structure and the functions conditioned on X at the same time. We prove that discrete undirected graphical models with feature X are equivalent to multivariate discrete models. The reparameterization of the potential functions in graphical models by conditional log odds ratios of the latter offers advantages in representation of the conditional independence structure. The functional spaces can be ﬂexibly determined by kernels. Additionally, we impose a Structure Lasso (SLasso) penalty on groups of functions to learn the graph structure. These groups with overlaps are designed to enforce hierarchical function selection. In this way, we are able to shrink higher order interactions to obtain a sparse graph structure. 1</p><p>same-paper 3 0.84055847 <a title="151-lda-3" href="./nips-2011-Learning_a_Tree_of_Metrics_with_Disjoint_Visual_Features.html">151 nips-2011-Learning a Tree of Metrics with Disjoint Visual Features</a></p>
<p>Author: Kristen Grauman, Fei Sha, Sung J. Hwang</p><p>Abstract: We introduce an approach to learn discriminative visual representations while exploiting external semantic knowledge about object category relationships. Given a hierarchical taxonomy that captures semantic similarity between the objects, we learn a corresponding tree of metrics (ToM). In this tree, we have one metric for each non-leaf node of the object hierarchy, and each metric is responsible for discriminating among its immediate subcategory children. Speciﬁcally, a Mahalanobis metric learned for a given node must satisfy the appropriate (dis)similarity constraints generated only among its subtree members’ training instances. To further exploit the semantics, we introduce a novel regularizer coupling the metrics that prefers a sparse disjoint set of features to be selected for each metric relative to its ancestor (supercategory) nodes’ metrics. Intuitively, this reﬂects that visual cues most useful to distinguish the generic classes (e.g., feline vs. canine) should be different than those cues most useful to distinguish their component ﬁne-grained classes (e.g., Persian cat vs. Siamese cat). We validate our approach with multiple image datasets using the WordNet taxonomy, show its advantages over alternative metric learning approaches, and analyze the meaning of attribute features selected by our algorithm. 1</p><p>4 0.81892377 <a title="151-lda-4" href="./nips-2011-Probabilistic_Joint_Image_Segmentation_and_Labeling.html">223 nips-2011-Probabilistic Joint Image Segmentation and Labeling</a></p>
<p>Author: Adrian Ion, Joao Carreira, Cristian Sminchisescu</p><p>Abstract: We present a joint image segmentation and labeling model (JSL) which, given a bag of ﬁgure-ground segment hypotheses extracted at multiple image locations and scales, constructs a joint probability distribution over both the compatible image interpretations (tilings or image segmentations) composed from those segments, and over their labeling into categories. The process of drawing samples from the joint distribution can be interpreted as ﬁrst sampling tilings, modeled as maximal cliques, from a graph connecting spatially non-overlapping segments in the bag [1], followed by sampling labels for those segments, conditioned on the choice of a particular tiling. We learn the segmentation and labeling parameters jointly, based on Maximum Likelihood with a novel Incremental Saddle Point estimation procedure. The partition function over tilings and labelings is increasingly more accurately approximated by including incorrect conﬁgurations that a not-yet-competent model rates probable during learning. We show that the proposed methodology matches the current state of the art in the Stanford dataset [2], as well as in VOC2010, where 41.7% accuracy on the test set is achieved.</p><p>5 0.79378974 <a title="151-lda-5" href="./nips-2011-On_U-processes_and_clustering_performance.html">198 nips-2011-On U-processes and clustering performance</a></p>
<p>Author: Stéphan J. Clémençcon</p><p>Abstract: Many clustering techniques aim at optimizing empirical criteria that are of the form of a U -statistic of degree two. Given a measure of dissimilarity between pairs of observations, the goal is to minimize the within cluster point scatter over a class of partitions of the feature space. It is the purpose of this paper to deﬁne a general statistical framework, relying on the theory of U -processes, for studying the performance of such clustering methods. In this setup, under adequate assumptions on the complexity of the subsets forming the partition candidates, the √ excess of clustering risk is proved to be of the order OP (1/ n). Based on recent results related to the tail behavior of degenerate U -processes, it is also shown how to establish tighter rate bounds. Model selection issues, related to the number of clusters forming the data partition in particular, are also considered. 1</p><p>6 0.71471155 <a title="151-lda-6" href="./nips-2011-Similarity-based_Learning_via_Data_Driven_Embeddings.html">254 nips-2011-Similarity-based Learning via Data Driven Embeddings</a></p>
<p>7 0.67665625 <a title="151-lda-7" href="./nips-2011-Pylon_Model_for_Semantic_Segmentation.html">227 nips-2011-Pylon Model for Semantic Segmentation</a></p>
<p>8 0.66748279 <a title="151-lda-8" href="./nips-2011-Higher-Order_Correlation_Clustering_for_Image_Segmentation.html">119 nips-2011-Higher-Order Correlation Clustering for Image Segmentation</a></p>
<p>9 0.65692818 <a title="151-lda-9" href="./nips-2011-Learning_person-object_interactions_for_action_recognition_in_still_images.html">154 nips-2011-Learning person-object interactions for action recognition in still images</a></p>
<p>10 0.65585375 <a title="151-lda-10" href="./nips-2011-%24%5Ctheta%24-MRF%3A_Capturing_Spatial_and_Semantic_Structure_in_the_Parameters_for_Scene_Understanding.html">1 nips-2011-$\theta$-MRF: Capturing Spatial and Semantic Structure in the Parameters for Scene Understanding</a></p>
<p>11 0.64538878 <a title="151-lda-11" href="./nips-2011-Ranking_annotators_for_crowdsourced_labeling_tasks.html">232 nips-2011-Ranking annotators for crowdsourced labeling tasks</a></p>
<p>12 0.64084619 <a title="151-lda-12" href="./nips-2011-Large-Scale_Category_Structure_Aware_Image_Categorization.html">141 nips-2011-Large-Scale Category Structure Aware Image Categorization</a></p>
<p>13 0.63411754 <a title="151-lda-13" href="./nips-2011-Joint_3D_Estimation_of_Objects_and_Scene_Layout.html">138 nips-2011-Joint 3D Estimation of Objects and Scene Layout</a></p>
<p>14 0.61476141 <a title="151-lda-14" href="./nips-2011-Efficient_Inference_in_Fully_Connected_CRFs_with_Gaussian_Edge_Potentials.html">76 nips-2011-Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials</a></p>
<p>15 0.6144166 <a title="151-lda-15" href="./nips-2011-High-Dimensional_Graphical_Model_Selection%3A_Tractable_Graph_Families_and_Necessary_Conditions.html">117 nips-2011-High-Dimensional Graphical Model Selection: Tractable Graph Families and Necessary Conditions</a></p>
<p>16 0.58702683 <a title="151-lda-16" href="./nips-2011-Uniqueness_of_Belief_Propagation_on_Signed_Graphs.html">296 nips-2011-Uniqueness of Belief Propagation on Signed Graphs</a></p>
<p>17 0.58279628 <a title="151-lda-17" href="./nips-2011-Active_Ranking_using_Pairwise_Comparisons.html">22 nips-2011-Active Ranking using Pairwise Comparisons</a></p>
<p>18 0.58161068 <a title="151-lda-18" href="./nips-2011-Im2Text%3A_Describing_Images_Using_1_Million_Captioned_Photographs.html">126 nips-2011-Im2Text: Describing Images Using 1 Million Captioned Photographs</a></p>
<p>19 0.58127284 <a title="151-lda-19" href="./nips-2011-Data_Skeletonization_via_Reeb_Graphs.html">67 nips-2011-Data Skeletonization via Reeb Graphs</a></p>
<p>20 0.57511187 <a title="151-lda-20" href="./nips-2011-Learning_a_Distance_Metric_from_a_Network.html">150 nips-2011-Learning a Distance Metric from a Network</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
