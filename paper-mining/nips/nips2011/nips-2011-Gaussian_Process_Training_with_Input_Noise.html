<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>100 nips-2011-Gaussian Process Training with Input Noise</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-100" href="#">nips2011-100</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>100 nips-2011-Gaussian Process Training with Input Noise</h1>
<br/><p>Source: <a title="nips-2011-100-pdf" href="http://papers.nips.cc/paper/4295-gaussian-process-training-with-input-noise.pdf">pdf</a></p><p>Author: Andrew Mchutchon, Carl E. Rasmussen</p><p>Abstract: In standard Gaussian Process regression input locations are assumed to be noise free. We present a simple yet effective GP model for training on input points corrupted by i.i.d. Gaussian noise. To make computations tractable we use a local linear expansion about each input point. This allows the input noise to be recast as output noise proportional to the squared gradient of the GP posterior mean. The input noise variances are inferred from the data as extra hyperparameters. They are trained alongside other hyperparameters by the usual method of maximisation of the marginal likelihood. Training uses an iterative scheme, which alternates between optimising the hyperparameters and calculating the posterior gradient. Analytic predictive moments can then be found for Gaussian distributed test points. We compare our model to others over a range of different regression problems and show that it improves over current methods. 1</p><p>Reference: <a title="nips-2011-100-reference" href="../nips2011_reference/nips-2011-Gaussian_Process_Training_with_Input_Noise_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('gp', 0.519), ('nigp', 0.458), ('mlhgp', 0.306), ('nois', 0.304), ('heteroscedast', 0.248), ('input', 0.16), ('postery', 0.156), ('kerst', 0.149), ('hyperparamet', 0.135), ('sin', 0.13), ('slop', 0.096), ('output', 0.091), ('train', 0.089), ('wav', 0.086), ('steep', 0.066), ('dtp', 0.065), ('stp', 0.065), ('learnt', 0.065), ('angul', 0.063), ('pendul', 0.063)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="100-tfidf-1" href="./nips-2011-Gaussian_Process_Training_with_Input_Noise.html">100 nips-2011-Gaussian Process Training with Input Noise</a></p>
<p>Author: Andrew Mchutchon, Carl E. Rasmussen</p><p>Abstract: In standard Gaussian Process regression input locations are assumed to be noise free. We present a simple yet effective GP model for training on input points corrupted by i.i.d. Gaussian noise. To make computations tractable we use a local linear expansion about each input point. This allows the input noise to be recast as output noise proportional to the squared gradient of the GP posterior mean. The input noise variances are inferred from the data as extra hyperparameters. They are trained alongside other hyperparameters by the usual method of maximisation of the marginal likelihood. Training uses an iterative scheme, which alternates between optimising the hyperparameters and calculating the posterior gradient. Analytic predictive moments can then be found for Gaussian distributed test points. We compare our model to others over a range of different regression problems and show that it improves over current methods. 1</p><p>2 0.31949788 <a title="100-tfidf-2" href="./nips-2011-Additive_Gaussian_Processes.html">26 nips-2011-Additive Gaussian Processes</a></p>
<p>Author: David K. Duvenaud, Hannes Nickisch, Carl E. Rasmussen</p><p>Abstract: We introduce a Gaussian process model of functions which are additive. An additive function is one which decomposes into a sum of low-dimensional functions, each depending on only a subset of the input variables. Additive GPs generalize both Generalized Additive Models, and the standard GP models which use squared-exponential kernels. Hyperparameter learning in this model can be seen as Bayesian Hierarchical Kernel Learning (HKL). We introduce an expressive but tractable parameterization of the kernel function, which allows efﬁcient evaluation of all input interaction terms, whose number is exponential in the input dimension. The additional structure discoverable by this model results in increased interpretability, as well as state-of-the-art predictive power in regression tasks. 1</p><p>3 0.22406234 <a title="100-tfidf-3" href="./nips-2011-Algorithms_for_Hyper-Parameter_Optimization.html">30 nips-2011-Algorithms for Hyper-Parameter Optimization</a></p>
<p>Author: James S. Bergstra, Rémi Bardenet, Yoshua Bengio, Balázs Kégl</p><p>Abstract: Several recent advances to the state of the art in image classiﬁcation benchmarks have come from better conﬁgurations of existing techniques rather than novel approaches to feature learning. Traditionally, hyper-parameter optimization has been the job of humans because they can be very efﬁcient in regimes where only a few trials are possible. Presently, computer clusters and GPU processors make it possible to run more trials and we show that algorithmic approaches can ﬁnd better results. We present hyper-parameter optimization results on tasks of training neural networks and deep belief networks (DBNs). We optimize hyper-parameters using random search and two new greedy sequential methods based on the expected improvement criterion. Random search has been shown to be sufﬁciently efﬁcient for learning neural networks for several datasets, but we show it is unreliable for training DBNs. The sequential algorithms are applied to the most difﬁcult DBN learning problems from [1] and ﬁnd signiﬁcantly better results than the best previously reported. This work contributes novel techniques for making response surface models P (y|x) in which many elements of hyper-parameter assignment (x) are known to be irrelevant given particular values of other elements. 1</p><p>4 0.14899398 <a title="100-tfidf-4" href="./nips-2011-Contextual_Gaussian_Process_Bandit_Optimization.html">61 nips-2011-Contextual Gaussian Process Bandit Optimization</a></p>
<p>Author: Andreas Krause, Cheng S. Ong</p><p>Abstract: How should we design experiments to maximize performance of a complex system, taking into account uncontrollable environmental conditions? How should we select relevant documents (ads) to display, given information about the user? These tasks can be formalized as contextual bandit problems, where at each round, we receive context (about the experimental conditions, the query), and have to choose an action (parameters, documents). The key challenge is to trade off exploration by gathering data for estimating the mean payoff function over the context-action space, and to exploit by choosing an action deemed optimal based on the gathered data. We model the payoff function as a sample from a Gaussian process deﬁned over the joint context-action space, and develop CGP-UCB, an intuitive upper-conﬁdence style algorithm. We show that by mixing and matching kernels for contexts and actions, CGP-UCB can handle a variety of practical applications. We further provide generic tools for deriving regret bounds when using such composite kernel functions. Lastly, we evaluate our algorithm on two case studies, in the context of automated vaccine design and sensor management. We show that context-sensitive optimization outperforms no or naive use of context. 1</p><p>5 0.13035727 <a title="100-tfidf-5" href="./nips-2011-Gaussian_process_modulated_renewal_processes.html">101 nips-2011-Gaussian process modulated renewal processes</a></p>
<p>Author: Yee W. Teh, Vinayak Rao</p><p>Abstract: Renewal processes are generalizations of the Poisson process on the real line whose intervals are drawn i.i.d. from some distribution. Modulated renewal processes allow these interevent distributions to vary with time, allowing the introduction of nonstationarity. In this work, we take a nonparametric Bayesian approach, modelling this nonstationarity with a Gaussian process. Our approach is based on the idea of uniformization, which allows us to draw exact samples from an otherwise intractable distribution. We develop a novel and efﬁcient MCMC sampler for posterior inference. In our experiments, we test these on a number of synthetic and real datasets. 1</p><p>6 0.12381919 <a title="100-tfidf-6" href="./nips-2011-Active_learning_of_neural_response_functions_with_Gaussian_processes.html">24 nips-2011-Active learning of neural response functions with Gaussian processes</a></p>
<p>7 0.12072811 <a title="100-tfidf-7" href="./nips-2011-Nonlinear_Inverse_Reinforcement_Learning_with_Gaussian_Processes.html">190 nips-2011-Nonlinear Inverse Reinforcement Learning with Gaussian Processes</a></p>
<p>8 0.11678567 <a title="100-tfidf-8" href="./nips-2011-Variational_Gaussian_Process_Dynamical_Systems.html">301 nips-2011-Variational Gaussian Process Dynamical Systems</a></p>
<p>9 0.11089016 <a title="100-tfidf-9" href="./nips-2011-Efficient_coding_of_natural_images_with_a_population_of_noisy_Linear-Nonlinear_neurons.html">82 nips-2011-Efficient coding of natural images with a population of noisy Linear-Nonlinear neurons</a></p>
<p>10 0.097502306 <a title="100-tfidf-10" href="./nips-2011-Optimal_Reinforcement_Learning_for_Gaussian_Systems.html">206 nips-2011-Optimal Reinforcement Learning for Gaussian Systems</a></p>
<p>11 0.091976263 <a title="100-tfidf-11" href="./nips-2011-High-dimensional_regression_with_noisy_and_missing_data%3A_Provable_guarantees_with_non-convexity.html">118 nips-2011-High-dimensional regression with noisy and missing data: Provable guarantees with non-convexity</a></p>
<p>12 0.087793902 <a title="100-tfidf-12" href="./nips-2011-Practical_Variational_Inference_for_Neural_Networks.html">217 nips-2011-Practical Variational Inference for Neural Networks</a></p>
<p>13 0.084917985 <a title="100-tfidf-13" href="./nips-2011-Inference_in_continuous-time_change-point_models.html">131 nips-2011-Inference in continuous-time change-point models</a></p>
<p>14 0.084126487 <a title="100-tfidf-14" href="./nips-2011-Sparse_Bayesian_Multi-Task_Learning.html">258 nips-2011-Sparse Bayesian Multi-Task Learning</a></p>
<p>15 0.066464052 <a title="100-tfidf-15" href="./nips-2011-Robust_Lasso_with_missing_and_grossly_corrupted_observations.html">239 nips-2011-Robust Lasso with missing and grossly corrupted observations</a></p>
<p>16 0.063627854 <a title="100-tfidf-16" href="./nips-2011-Learning_large-margin_halfspaces_with_more_malicious_noise.html">153 nips-2011-Learning large-margin halfspaces with more malicious noise</a></p>
<p>17 0.059596717 <a title="100-tfidf-17" href="./nips-2011-Infinite_Latent_SVM_for_Classification_and_Multi-task_Learning.html">134 nips-2011-Infinite Latent SVM for Classification and Multi-task Learning</a></p>
<p>18 0.059152581 <a title="100-tfidf-18" href="./nips-2011-Analytical_Results_for_the_Error_in_Filtering_of_Gaussian_Processes.html">37 nips-2011-Analytical Results for the Error in Filtering of Gaussian Processes</a></p>
<p>19 0.058866467 <a title="100-tfidf-19" href="./nips-2011-On_Causal_Discovery_with_Cyclic_Additive_Noise_Models.html">194 nips-2011-On Causal Discovery with Cyclic Additive Noise Models</a></p>
<p>20 0.057789605 <a title="100-tfidf-20" href="./nips-2011-Estimating_time-varying_input_signals_and_ion_channel_states_from_a_single_voltage_trace_of_a_neuron.html">89 nips-2011-Estimating time-varying input signals and ion channel states from a single voltage trace of a neuron</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.159), (1, 0.029), (2, -0.02), (3, 0.021), (4, 0.076), (5, 0.075), (6, 0.061), (7, 0.069), (8, -0.154), (9, 0.045), (10, 0.014), (11, 0.25), (12, -0.047), (13, 0.096), (14, -0.063), (15, 0.141), (16, -0.096), (17, -0.079), (18, 0.183), (19, -0.021), (20, 0.166), (21, 0.195), (22, 0.111), (23, 0.158), (24, 0.085), (25, -0.031), (26, -0.135), (27, 0.159), (28, -0.159), (29, 0.062), (30, -0.069), (31, -0.029), (32, -0.058), (33, 0.018), (34, 0.054), (35, 0.028), (36, 0.077), (37, -0.009), (38, -0.044), (39, -0.115), (40, 0.069), (41, 0.068), (42, -0.027), (43, -0.076), (44, 0.108), (45, -0.021), (46, 0.089), (47, 0.007), (48, 0.007), (49, 0.08)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92684478 <a title="100-lsi-1" href="./nips-2011-Gaussian_Process_Training_with_Input_Noise.html">100 nips-2011-Gaussian Process Training with Input Noise</a></p>
<p>Author: Andrew Mchutchon, Carl E. Rasmussen</p><p>Abstract: In standard Gaussian Process regression input locations are assumed to be noise free. We present a simple yet effective GP model for training on input points corrupted by i.i.d. Gaussian noise. To make computations tractable we use a local linear expansion about each input point. This allows the input noise to be recast as output noise proportional to the squared gradient of the GP posterior mean. The input noise variances are inferred from the data as extra hyperparameters. They are trained alongside other hyperparameters by the usual method of maximisation of the marginal likelihood. Training uses an iterative scheme, which alternates between optimising the hyperparameters and calculating the posterior gradient. Analytic predictive moments can then be found for Gaussian distributed test points. We compare our model to others over a range of different regression problems and show that it improves over current methods. 1</p><p>2 0.76812112 <a title="100-lsi-2" href="./nips-2011-Algorithms_for_Hyper-Parameter_Optimization.html">30 nips-2011-Algorithms for Hyper-Parameter Optimization</a></p>
<p>Author: James S. Bergstra, Rémi Bardenet, Yoshua Bengio, Balázs Kégl</p><p>Abstract: Several recent advances to the state of the art in image classiﬁcation benchmarks have come from better conﬁgurations of existing techniques rather than novel approaches to feature learning. Traditionally, hyper-parameter optimization has been the job of humans because they can be very efﬁcient in regimes where only a few trials are possible. Presently, computer clusters and GPU processors make it possible to run more trials and we show that algorithmic approaches can ﬁnd better results. We present hyper-parameter optimization results on tasks of training neural networks and deep belief networks (DBNs). We optimize hyper-parameters using random search and two new greedy sequential methods based on the expected improvement criterion. Random search has been shown to be sufﬁciently efﬁcient for learning neural networks for several datasets, but we show it is unreliable for training DBNs. The sequential algorithms are applied to the most difﬁcult DBN learning problems from [1] and ﬁnd signiﬁcantly better results than the best previously reported. This work contributes novel techniques for making response surface models P (y|x) in which many elements of hyper-parameter assignment (x) are known to be irrelevant given particular values of other elements. 1</p><p>3 0.73764932 <a title="100-lsi-3" href="./nips-2011-Additive_Gaussian_Processes.html">26 nips-2011-Additive Gaussian Processes</a></p>
<p>Author: David K. Duvenaud, Hannes Nickisch, Carl E. Rasmussen</p><p>Abstract: We introduce a Gaussian process model of functions which are additive. An additive function is one which decomposes into a sum of low-dimensional functions, each depending on only a subset of the input variables. Additive GPs generalize both Generalized Additive Models, and the standard GP models which use squared-exponential kernels. Hyperparameter learning in this model can be seen as Bayesian Hierarchical Kernel Learning (HKL). We introduce an expressive but tractable parameterization of the kernel function, which allows efﬁcient evaluation of all input interaction terms, whose number is exponential in the input dimension. The additional structure discoverable by this model results in increased interpretability, as well as state-of-the-art predictive power in regression tasks. 1</p><p>4 0.58916551 <a title="100-lsi-4" href="./nips-2011-Gaussian_process_modulated_renewal_processes.html">101 nips-2011-Gaussian process modulated renewal processes</a></p>
<p>Author: Yee W. Teh, Vinayak Rao</p><p>Abstract: Renewal processes are generalizations of the Poisson process on the real line whose intervals are drawn i.i.d. from some distribution. Modulated renewal processes allow these interevent distributions to vary with time, allowing the introduction of nonstationarity. In this work, we take a nonparametric Bayesian approach, modelling this nonstationarity with a Gaussian process. Our approach is based on the idea of uniformization, which allows us to draw exact samples from an otherwise intractable distribution. We develop a novel and efﬁcient MCMC sampler for posterior inference. In our experiments, we test these on a number of synthetic and real datasets. 1</p><p>5 0.52082658 <a title="100-lsi-5" href="./nips-2011-Contextual_Gaussian_Process_Bandit_Optimization.html">61 nips-2011-Contextual Gaussian Process Bandit Optimization</a></p>
<p>Author: Andreas Krause, Cheng S. Ong</p><p>Abstract: How should we design experiments to maximize performance of a complex system, taking into account uncontrollable environmental conditions? How should we select relevant documents (ads) to display, given information about the user? These tasks can be formalized as contextual bandit problems, where at each round, we receive context (about the experimental conditions, the query), and have to choose an action (parameters, documents). The key challenge is to trade off exploration by gathering data for estimating the mean payoff function over the context-action space, and to exploit by choosing an action deemed optimal based on the gathered data. We model the payoff function as a sample from a Gaussian process deﬁned over the joint context-action space, and develop CGP-UCB, an intuitive upper-conﬁdence style algorithm. We show that by mixing and matching kernels for contexts and actions, CGP-UCB can handle a variety of practical applications. We further provide generic tools for deriving regret bounds when using such composite kernel functions. Lastly, we evaluate our algorithm on two case studies, in the context of automated vaccine design and sensor management. We show that context-sensitive optimization outperforms no or naive use of context. 1</p><p>6 0.47320691 <a title="100-lsi-6" href="./nips-2011-Variational_Gaussian_Process_Dynamical_Systems.html">301 nips-2011-Variational Gaussian Process Dynamical Systems</a></p>
<p>7 0.45948285 <a title="100-lsi-7" href="./nips-2011-Optimal_Reinforcement_Learning_for_Gaussian_Systems.html">206 nips-2011-Optimal Reinforcement Learning for Gaussian Systems</a></p>
<p>8 0.44940677 <a title="100-lsi-8" href="./nips-2011-Spike_and_Slab_Variational_Inference_for_Multi-Task_and_Multiple_Kernel_Learning.html">269 nips-2011-Spike and Slab Variational Inference for Multi-Task and Multiple Kernel Learning</a></p>
<p>9 0.44936609 <a title="100-lsi-9" href="./nips-2011-On_Causal_Discovery_with_Cyclic_Additive_Noise_Models.html">194 nips-2011-On Causal Discovery with Cyclic Additive Noise Models</a></p>
<p>10 0.44645146 <a title="100-lsi-10" href="./nips-2011-Active_learning_of_neural_response_functions_with_Gaussian_processes.html">24 nips-2011-Active learning of neural response functions with Gaussian processes</a></p>
<p>11 0.41556105 <a title="100-lsi-11" href="./nips-2011-Nonlinear_Inverse_Reinforcement_Learning_with_Gaussian_Processes.html">190 nips-2011-Nonlinear Inverse Reinforcement Learning with Gaussian Processes</a></p>
<p>12 0.37993616 <a title="100-lsi-12" href="./nips-2011-Practical_Variational_Inference_for_Neural_Networks.html">217 nips-2011-Practical Variational Inference for Neural Networks</a></p>
<p>13 0.3727681 <a title="100-lsi-13" href="./nips-2011-Robust_Multi-Class_Gaussian_Process_Classification.html">240 nips-2011-Robust Multi-Class Gaussian Process Classification</a></p>
<p>14 0.35745069 <a title="100-lsi-14" href="./nips-2011-Inference_in_continuous-time_change-point_models.html">131 nips-2011-Inference in continuous-time change-point models</a></p>
<p>15 0.35451335 <a title="100-lsi-15" href="./nips-2011-Kernel_Bayes%27_Rule.html">139 nips-2011-Kernel Bayes' Rule</a></p>
<p>16 0.34824261 <a title="100-lsi-16" href="./nips-2011-Non-conjugate_Variational_Message_Passing_for_Multinomial_and_Binary_Regression.html">188 nips-2011-Non-conjugate Variational Message Passing for Multinomial and Binary Regression</a></p>
<p>17 0.34107614 <a title="100-lsi-17" href="./nips-2011-Differentially_Private_M-Estimators.html">69 nips-2011-Differentially Private M-Estimators</a></p>
<p>18 0.33933493 <a title="100-lsi-18" href="./nips-2011-Efficient_inference_in_matrix-variate_Gaussian_models_with_%5Ciid_observation_noise.html">83 nips-2011-Efficient inference in matrix-variate Gaussian models with \iid observation noise</a></p>
<p>19 0.33828998 <a title="100-lsi-19" href="./nips-2011-High-dimensional_regression_with_noisy_and_missing_data%3A_Provable_guarantees_with_non-convexity.html">118 nips-2011-High-dimensional regression with noisy and missing data: Provable guarantees with non-convexity</a></p>
<p>20 0.31941998 <a title="100-lsi-20" href="./nips-2011-Efficient_coding_of_natural_images_with_a_population_of_noisy_Linear-Nonlinear_neurons.html">82 nips-2011-Efficient coding of natural images with a population of noisy Linear-Nonlinear neurons</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.283), (14, 0.064), (22, 0.033), (36, 0.026), (55, 0.124), (65, 0.125), (68, 0.226), (79, 0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.84008908 <a title="100-lda-1" href="./nips-2011-Clustered_Multi-Task_Learning_Via_Alternating_Structure_Optimization.html">51 nips-2011-Clustered Multi-Task Learning Via Alternating Structure Optimization</a></p>
<p>Author: Jiayu Zhou, Jianhui Chen, Jieping Ye</p><p>Abstract: Multi-task learning (MTL) learns multiple related tasks simultaneously to improve generalization performance. Alternating structure optimization (ASO) is a popular MTL method that learns a shared low-dimensional predictive structure on hypothesis spaces from multiple related tasks. It has been applied successfully in many real world applications. As an alternative MTL approach, clustered multi-task learning (CMTL) assumes that multiple tasks follow a clustered structure, i.e., tasks are partitioned into a set of groups where tasks in the same group are similar to each other, and that such a clustered structure is unknown a priori. The objectives in ASO and CMTL differ in how multiple tasks are related. Interestingly, we show in this paper the equivalence relationship between ASO and CMTL, providing signiﬁcant new insights into ASO and CMTL as well as their inherent relationship. The CMTL formulation is non-convex, and we adopt a convex relaxation to the CMTL formulation. We further establish the equivalence relationship between the proposed convex relaxation of CMTL and an existing convex relaxation of ASO, and show that the proposed convex CMTL formulation is signiﬁcantly more efﬁcient especially for high-dimensional data. In addition, we present three algorithms for solving the convex CMTL formulation. We report experimental results on benchmark datasets to demonstrate the efﬁciency of the proposed algorithms. 1</p><p>same-paper 2 0.78083026 <a title="100-lda-2" href="./nips-2011-Gaussian_Process_Training_with_Input_Noise.html">100 nips-2011-Gaussian Process Training with Input Noise</a></p>
<p>Author: Andrew Mchutchon, Carl E. Rasmussen</p><p>Abstract: In standard Gaussian Process regression input locations are assumed to be noise free. We present a simple yet effective GP model for training on input points corrupted by i.i.d. Gaussian noise. To make computations tractable we use a local linear expansion about each input point. This allows the input noise to be recast as output noise proportional to the squared gradient of the GP posterior mean. The input noise variances are inferred from the data as extra hyperparameters. They are trained alongside other hyperparameters by the usual method of maximisation of the marginal likelihood. Training uses an iterative scheme, which alternates between optimising the hyperparameters and calculating the posterior gradient. Analytic predictive moments can then be found for Gaussian distributed test points. We compare our model to others over a range of different regression problems and show that it improves over current methods. 1</p><p>3 0.71935934 <a title="100-lda-3" href="./nips-2011-On_Tracking_The_Partition_Function.html">197 nips-2011-On Tracking The Partition Function</a></p>
<p>Author: Guillaume Desjardins, Yoshua Bengio, Aaron C. Courville</p><p>Abstract: Markov Random Fields (MRFs) have proven very powerful both as density estimators and feature extractors for classiﬁcation. However, their use is often limited by an inability to estimate the partition function Z. In this paper, we exploit the gradient descent training procedure of restricted Boltzmann machines (a type of MRF) to track the log partition function during learning. Our method relies on two distinct sources of information: (1) estimating the change ∆Z incurred by each gradient update, (2) estimating the difference in Z over a small set of tempered distributions using bridge sampling. The two sources of information are then combined using an inference procedure similar to Kalman ﬁltering. Learning MRFs through Tempered Stochastic Maximum Likelihood, we can estimate Z using no more temperatures than are required for learning. Comparing to both exact values and estimates using annealed importance sampling (AIS), we show on several datasets that our method is able to accurately track the log partition function. In contrast to AIS, our method provides this estimate at each time-step, at a computational cost similar to that required for training alone. 1</p><p>4 0.71760786 <a title="100-lda-4" href="./nips-2011-Pylon_Model_for_Semantic_Segmentation.html">227 nips-2011-Pylon Model for Semantic Segmentation</a></p>
<p>Author: Victor Lempitsky, Andrea Vedaldi, Andrew Zisserman</p><p>Abstract: Graph cut optimization is one of the standard workhorses of image segmentation since for binary random ﬁeld representations of the image, it gives globally optimal results and there are efﬁcient polynomial time implementations. Often, the random ﬁeld is applied over a ﬂat partitioning of the image into non-intersecting elements, such as pixels or super-pixels. In the paper we show that if, instead of a ﬂat partitioning, the image is represented by a hierarchical segmentation tree, then the resulting energy combining unary and boundary terms can still be optimized using graph cut (with all the corresponding beneﬁts of global optimality and efﬁciency). As a result of such inference, the image gets partitioned into a set of segments that may come from different layers of the tree. We apply this formulation, which we call the pylon model, to the task of semantic segmentation where the goal is to separate an image into areas belonging to different semantic classes. The experiments highlight the advantage of inference on a segmentation tree (over a ﬂat partitioning) and demonstrate that the optimization in the pylon model is able to ﬂexibly choose the level of segmentation across the image. Overall, the proposed system has superior segmentation accuracy on several datasets (Graz-02, Stanford background) compared to previously suggested approaches. 1</p><p>5 0.71378809 <a title="100-lda-5" href="./nips-2011-A_rational_model_of_causal_inference_with_continuous_causes.html">15 nips-2011-A rational model of causal inference with continuous causes</a></p>
<p>Author: Thomas L. Griffiths, Michael James</p><p>Abstract: Rational models of causal induction have been successful in accounting for people’s judgments about causal relationships. However, these models have focused on explaining inferences from discrete data of the kind that can be summarized in a 2× 2 contingency table. This severely limits the scope of these models, since the world often provides non-binary data. We develop a new rational model of causal induction using continuous dimensions, which aims to diminish the gap between empirical and theoretical approaches and real-world causal induction. This model successfully predicts human judgments from previous studies better than models of discrete causal inference, and outperforms several other plausible models of causal induction with continuous causes in accounting for people’s inferences in a new experiment. 1</p><p>6 0.71225893 <a title="100-lda-6" href="./nips-2011-Variational_Learning_for_Recurrent_Spiking_Networks.html">302 nips-2011-Variational Learning for Recurrent Spiking Networks</a></p>
<p>7 0.70942074 <a title="100-lda-7" href="./nips-2011-Efficient_coding_of_natural_images_with_a_population_of_noisy_Linear-Nonlinear_neurons.html">82 nips-2011-Efficient coding of natural images with a population of noisy Linear-Nonlinear neurons</a></p>
<p>8 0.70873612 <a title="100-lda-8" href="./nips-2011-Dynamical_segmentation_of_single_trials_from_population_neural_data.html">75 nips-2011-Dynamical segmentation of single trials from population neural data</a></p>
<p>9 0.70845866 <a title="100-lda-9" href="./nips-2011-Sparse_Bayesian_Multi-Task_Learning.html">258 nips-2011-Sparse Bayesian Multi-Task Learning</a></p>
<p>10 0.7071923 <a title="100-lda-10" href="./nips-2011-Bayesian_Spike-Triggered_Covariance_Analysis.html">44 nips-2011-Bayesian Spike-Triggered Covariance Analysis</a></p>
<p>11 0.7057153 <a title="100-lda-11" href="./nips-2011-Dimensionality_Reduction_Using_the_Sparse_Linear_Model.html">70 nips-2011-Dimensionality Reduction Using the Sparse Linear Model</a></p>
<p>12 0.70534444 <a title="100-lda-12" href="./nips-2011-Information_Rates_and_Optimal_Decoding_in_Large_Neural_Populations.html">135 nips-2011-Information Rates and Optimal Decoding in Large Neural Populations</a></p>
<p>13 0.70520413 <a title="100-lda-13" href="./nips-2011-Variational_Gaussian_Process_Dynamical_Systems.html">301 nips-2011-Variational Gaussian Process Dynamical Systems</a></p>
<p>14 0.70516312 <a title="100-lda-14" href="./nips-2011-Testing_a_Bayesian_Measure_of_Representativeness_Using_a_Large_Image_Database.html">280 nips-2011-Testing a Bayesian Measure of Representativeness Using a Large Image Database</a></p>
<p>15 0.7042923 <a title="100-lda-15" href="./nips-2011-Infinite_Latent_SVM_for_Classification_and_Multi-task_Learning.html">134 nips-2011-Infinite Latent SVM for Classification and Multi-task Learning</a></p>
<p>16 0.70427859 <a title="100-lda-16" href="./nips-2011-Facial_Expression_Transfer_with_Input-Output_Temporal_Restricted_Boltzmann_Machines.html">94 nips-2011-Facial Expression Transfer with Input-Output Temporal Restricted Boltzmann Machines</a></p>
<p>17 0.70261657 <a title="100-lda-17" href="./nips-2011-Co-regularized_Multi-view_Spectral_Clustering.html">54 nips-2011-Co-regularized Multi-view Spectral Clustering</a></p>
<p>18 0.70248705 <a title="100-lda-18" href="./nips-2011-Automated_Refinement_of_Bayes_Networks%27_Parameters_based_on_Test_Ordering_Constraints.html">40 nips-2011-Automated Refinement of Bayes Networks' Parameters based on Test Ordering Constraints</a></p>
<p>19 0.70202613 <a title="100-lda-19" href="./nips-2011-Spike_and_Slab_Variational_Inference_for_Multi-Task_and_Multiple_Kernel_Learning.html">269 nips-2011-Spike and Slab Variational Inference for Multi-Task and Multiple Kernel Learning</a></p>
<p>20 0.70187193 <a title="100-lda-20" href="./nips-2011-Inferring_Interaction_Networks_using_the_IBP_applied_to_microRNA_Target_Prediction.html">132 nips-2011-Inferring Interaction Networks using the IBP applied to microRNA Target Prediction</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
