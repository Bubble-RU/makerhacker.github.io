<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>298 nips-2011-Unsupervised learning models of primary cortical receptive fields and receptive field plasticity</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-298" href="#">nips2011-298</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>298 nips-2011-Unsupervised learning models of primary cortical receptive fields and receptive field plasticity</h1>
<br/><p>Source: <a title="nips-2011-298-pdf" href="http://papers.nips.cc/paper/4331-unsupervised-learning-models-of-primary-cortical-receptive-fields-and-receptive-field-plasticity.pdf">pdf</a></p><p>Author: Maneesh Bhand, Ritvik Mudur, Bipin Suresh, Andrew Saxe, Andrew Y. Ng</p><p>Abstract: The efﬁcient coding hypothesis holds that neural receptive ﬁelds are adapted to the statistics of the environment, but is agnostic to the timescale of this adaptation, which occurs on both evolutionary and developmental timescales. In this work we focus on that component of adaptation which occurs during an organism’s lifetime, and show that a number of unsupervised feature learning algorithms can account for features of normal receptive ﬁeld properties across multiple primary sensory cortices. Furthermore, we show that the same algorithms account for altered receptive ﬁeld properties in response to experimentally altered environmental statistics. Based on these modeling results we propose these models as phenomenological models of receptive ﬁeld plasticity during an organism’s lifetime. Finally, due to the success of the same models in multiple sensory areas, we suggest that these algorithms may provide a constructive realization of the theory, ﬁrst proposed by Mountcastle [1], that a qualitatively similar learning algorithm acts throughout primary sensory cortices. 1</p><p>Reference: <a title="nips-2011-298-reference" href="../nips2011_reference/nips-2011-Unsupervised_learning_models_of_primary_cortical_receptive_fields_and_receptive_field_plasticity_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Unsupervised learning models of primary cortical receptive ﬁelds and receptive ﬁeld plasticity  Andrew Saxe, Maneesh Bhand, Ritvik Mudur, Bipin Suresh, Andrew Y. [sent-1, score-1.31]
</p><p>2 edu  Abstract The efﬁcient coding hypothesis holds that neural receptive ﬁelds are adapted to the statistics of the environment, but is agnostic to the timescale of this adaptation, which occurs on both evolutionary and developmental timescales. [sent-4, score-0.577]
</p><p>3 In this work we focus on that component of adaptation which occurs during an organism’s lifetime, and show that a number of unsupervised feature learning algorithms can account for features of normal receptive ﬁeld properties across multiple primary sensory cortices. [sent-5, score-0.966]
</p><p>4 Furthermore, we show that the same algorithms account for altered receptive ﬁeld properties in response to experimentally altered environmental statistics. [sent-6, score-0.762]
</p><p>5 Based on these modeling results we propose these models as phenomenological models of receptive ﬁeld plasticity during an organism’s lifetime. [sent-7, score-0.625]
</p><p>6 Finally, due to the success of the same models in multiple sensory areas, we suggest that these algorithms may provide a constructive realization of the theory, ﬁrst proposed by Mountcastle [1], that a qualitatively similar learning algorithm acts throughout primary sensory cortices. [sent-8, score-0.538]
</p><p>7 1  Introduction  Over the last twenty years, researchers have used a number of unsupervised learning algorithms to model a range of neural phenomena in early sensory processing. [sent-9, score-0.271]
</p><p>8 These models have succeeded in replicating many features of simple cell receptive ﬁelds in primary visual cortex [2, 3], as well as cochlear nerve ﬁber responses in the subcortical auditory system [4]. [sent-10, score-1.44]
</p><p>9 In this paper we test whether a single learning algorithm can provide a reasonable ﬁt to data from three different primary sensory cortices. [sent-15, score-0.314]
</p><p>10 Recent reviews of the experimental literature regarding the functional consequences of plasticity have remarked on the surprising similarity in plasticity outcomes across sensory cortices [8, 9]. [sent-18, score-0.533]
</p><p>11 These empirical results raise the possibility that a single phenomenological model of plasticity (a “learning algorithm” in our terminology) might account for receptive ﬁeld properties independent of modality. [sent-19, score-0.625]
</p><p>12 As an initial step in this direction, we evaluate the match between current unsupervised learning algorithms and receptive ﬁeld properties in visual, auditory, and somatosensory cortex. [sent-21, score-0.786]
</p><p>13 We ﬁnd that many current algorithms achieve qualitatively similar matches to receptive ﬁeld properties in all three modalities, though differences between the models and experimental data remain. [sent-22, score-0.589]
</p><p>14 One implication of lifetime adaptation is that experimental manipulations of early sensory experience should result in altered receptive ﬁeld properties. [sent-28, score-0.962]
</p><p>15 We therefore ask whether current unsupervised learning algorithms can reproduce appropriately altered receptive ﬁeld properties in response to experimentally altered inputs. [sent-29, score-0.842]
</p><p>16 Our results show that the same unsupervised learning algorithm can model normal and altered receptive ﬁelds, yielding an account of sensory receptive ﬁelds focused heavily on activity dependent plasticity processes operating during an organism’s lifetime. [sent-30, score-1.508]
</p><p>17 We consider ﬁve unsupervised learning algorithms: independent component analysis [10], sparse autoencoder neural networks [11], restricted Boltzmann machines (RBMs) [12], K-means [13], and sparse coding [2]. [sent-33, score-0.27]
</p><p>18 First, all of the algorithms share the property of learning a sparse representation of the input, though they clearly differ in their details, and have at least qualitatively been shown to yield Gabor-like ﬁlters when applied to naturalistic visual input. [sent-35, score-0.268]
</p><p>19 A learning algorithm could potentially learn a non-efﬁcient code, for instance, but nonetheless describe the establishment of receptive ﬁelds seen in adult animals. [sent-49, score-0.533]
</p><p>20 3  Naturalistic experience and normal receptive ﬁeld properties  In this section we focus on whether ﬁrst-order, linear properties of neural responses can be captured by current unsupervised learning algorithms applied to naturalistic visual, auditory, and somatosensory inputs. [sent-55, score-0.942]
</p><p>21 Such a linear description of neural responses has been broadly studied in all sensory cortices [14, 15, 16, 17]. [sent-56, score-0.28]
</p><p>22 Far right: Distribution of receptive ﬁeld shapes; Red triangles are V1 simple cells from [5], blue circles are K-means bases. [sent-60, score-0.521]
</p><p>23 1  Primary visual cortex  A number of studies have shown that response properties in V1 can be successfully modeled using a variety of unsupervised learning algorithms [2, 19, 3, 12, 10, 6, 7]. [sent-62, score-0.345]
</p><p>24 All ﬁve algorithms learn localized, band-pass receptive ﬁeld structures for a broad range of parameter settings, in qualitative agreement with the spatial receptive ﬁelds of simple cells in primary visual cortex. [sent-70, score-1.32]
</p><p>25 To better quantify the match, we compare ﬁve properties of model neuron receptive ﬁelds to data from macaque V1, namely the spatial frequency bandwidth, orientation tuning bandwidth, length, aspect ratio, and peak spatial frequency of the receptive ﬁelds. [sent-71, score-1.33]
</p><p>26 For all ﬁve algorithms, the histograms show general agreement with the distribution of parameters in primary visual cortex except for the peak spatial frequency, consistent with the results of previous studies for ICA and sparse coding [2, 3]. [sent-75, score-0.561]
</p><p>27 Next, we compare the shape of simulated receptive ﬁelds to experimentally-derived receptive ﬁelds. [sent-77, score-0.97]
</p><p>28 Hence they capture the number of excitatory and inhibitory lobes of signiﬁcant power in each receptive ﬁeld. [sent-80, score-0.588]
</p><p>29 As had been noted for ICA and sparse coding in [5], all ﬁve of our algorithms fail to capture low frequency bases near the origin. [sent-84, score-0.353]
</p><p>30 These low frequency bases correspond to “blobs” with just a single excitatory region. [sent-85, score-0.32]
</p><p>31 Bottom: Spectrum width vs center frequency for A1 neurons (red triangles) and model neurons (blue circles). [sent-94, score-0.316]
</p><p>32 2 Primary auditory cortex In contrast to the large amount of work in the visual system, few efﬁcient coding studies have addressed response properties in primary auditory cortex (but see [20]). [sent-96, score-1.332]
</p><p>33 A mix of speech and natural sounds was reported to be necessary to achieve a good match to auditory nerve ﬁber responses in previous sparse coding work [4]. [sent-98, score-0.594]
</p><p>34 In particular, we pass the input sound signal to a gammatone ﬁlterbank which approximates auditory nerve ﬁber responses [21]. [sent-100, score-0.519]
</p><p>35 Although there is evidence for temporal whitening in the responses of afferents to auditory cortex, this is certainly a very poor aproximation of subcortical auditory processing [16]. [sent-103, score-0.978]
</p><p>36 These bases map from our spectrogram input to the model neuron output, and hence represent the spectrotemporal receptive ﬁeld (STRF) of the model neurons. [sent-106, score-0.738]
</p><p>37 Next we compared model receptive ﬁelds to the composite cortical modulation transfer function reported in [16]. [sent-113, score-0.642]
</p><p>38 The STRF contains one spectral and one temporal axis, and hence its 2D Fourier transform contains one spectral modulation and one temporal modulation axis. [sent-115, score-0.334]
</p><p>39 Hence the model bases are broadly consistent with receptive ﬁeld properties measured in primary auditory cortex such as a roughly linear scaling of center frequency with spectrum bandwidth; a low-pass 4  Figure 3: Left: Data collection pipeline. [sent-124, score-1.444]
</p><p>40 Right: Histograms of receptive ﬁeld structure for the sparse autoencoder algorithm. [sent-127, score-0.582]
</p><p>41 3  Primary somatosensory cortex  Finally, we test whether these learning algorithms can model somatosensory receptive ﬁelds on the hand. [sent-133, score-1.081]
</p><p>42 To enable this comparison we collected a naturalistic somatosensory dataset meant to capture the statistics of contact points on the hand during normal primate grasping behavior. [sent-134, score-0.404]
</p><p>43 Most signiﬁcantly, it contains only 1248 individual grasps due to the high effort required to collect such data (∼4 minutes/sample), and hence is an order of magnitude smaller than the datasets used for the vision and auditory analyses. [sent-141, score-0.399]
</p><p>44 Given these limitations, we decided to compare our receptive ﬁelds to those found in area 3b of primary somatosensory cortex. [sent-142, score-0.912]
</p><p>45 Neurons in area 3b respond to light cutaneous stimulation of restricted regions of glabrous skin [24], the same sort of contact that would transfer powder to the glove. [sent-143, score-0.322]
</p><p>46 Area 3b neurons also receive a large proportion of inputs from slowly adapting mechanoreceptor afferents with sustained responses to static skin indentation [25], making the lack of temporal information less problematic. [sent-144, score-0.324]
</p><p>47 As in area 3b, the model receptive ﬁelds are localized to a single digit [24], and receptive ﬁeld sizes are larger on the palm than on the ﬁngers [25]. [sent-148, score-1.017]
</p><p>48 As a more quantitative assesment, we compared model receptive ﬁelds on the ﬁnger tips to those derived for area 3b neurons in [17]. [sent-150, score-0.674]
</p><p>49 We also plot the ratio of the excitatory and inhibitory mass, where excitatory and inhibitory mass is deﬁned as the sum of the positive and negative coefﬁcients in the receptive ﬁeld, respectively. [sent-154, score-0.691]
</p><p>50 Right: Orientation histogram for model neurons is biased towards goggle orientation (90◦ ). [sent-158, score-0.308]
</p><p>51 4  Adaptation to altered environmental statistics  Numerous studies in multiple sensory areas and species document plasticity of receptive ﬁeld properties in response to various experimental manipulations during an organism’s lifetime. [sent-159, score-1.015]
</p><p>52 In visual cortex, for instance, orientation selectivity can be altered by rearing animals in unidirectionally oriented environments [26]. [sent-160, score-0.441]
</p><p>53 In auditory cortex, pulsed-tone rearing results in an expansion in the area of auditory cortex tuned to the pulsed tone frequency [27]. [sent-161, score-1.206]
</p><p>54 And in somatosensory cortex, surgically fusing digits 3 and 4 (the middle and ring ﬁngers) of the hand to induce an artiﬁcial digital syndactyly (webbed ﬁnger) condition results in receptive ﬁelds that span these digits [28]. [sent-162, score-1.027]
</p><p>55 In this section we ask whether the same learning algorithms that explain features of normal receptive ﬁelds can also explain these alterations in receptive ﬁeld properties due to manipulations of sensory experience. [sent-163, score-1.214]
</p><p>56 1 Goggle-rearing alters V1 orientation tuning The preferred orientations of neurons in primary visual cortex can be strongly inﬂuenced by altering visual inputs during development; Tanaka et al. [sent-165, score-0.797]
</p><p>57 ﬁtted goggles that severly restricted orientation information to kittens at postnatal week three, and documented a massive overrepresentation of the goggle orientation subsequently in primary visual cortex [26]. [sent-166, score-0.906]
</p><p>58 4 shows resulting receptive ﬁelds obtained using the sparse coding algorithm. [sent-173, score-0.578]
</p><p>59 2 Pulsed-tone rearing alters A1 frequency tuning Early sensory experience can also profoundly alter properties of neural receptive ﬁelds in primary auditory cortex. [sent-178, score-1.293]
</p><p>60 1, early exposure to a pulsed tone can induce shifts in the preferred center frequency of A1 neurons. [sent-180, score-0.384]
</p><p>61 Mapping the preferred center frequencies of neurons in tone-exposed rats revealed a corresponding overrepresentation in A1 around the pulsed-tone frequency. [sent-183, score-0.267]
</p><p>62 We instantiated this experimental paradigm by adding a pulsed tone to the raw sound waveforms of the natural sounds and speech before computing the gammatone responses. [sent-184, score-0.323]
</p><p>63 We computed the preferred frequency of each model receptive ﬁeld by summing the square of each patch along the temporal dimension. [sent-187, score-0.683]
</p><p>64 Right: Population histograms of preferred frequency reveal a strong preference for the pulsed-tone frequency of 4kHz. [sent-191, score-0.288]
</p><p>65 Intuitively, this overrepresentation is due to the fact that many bases are necessary to represent the temporal information present in the pulsed-tone, that is, the phase of the amplitude modulation and the onset or offset time of the stimulus. [sent-194, score-0.375]
</p><p>66 [28] surgically fused adjacent skin on digits 3 and 4 in adult owl monkeys to create an artiﬁcial sydactyly, or webbed ﬁnger, condition. [sent-197, score-0.304]
</p><p>67 After 14, 25, or 33 weeks, many receptive ﬁelds of neurons in area 3b of S1 were found to span digits 3 and 4, a qualitative change from the normally strict localization of receptive ﬁelds to a single digit. [sent-198, score-1.238]
</p><p>68 Additionally, at the tips of digits 3 and 4 where there is no immediately adjacent skin on the other digit, some neurons showed discontinuous double-digit receptive ﬁelds that responded to stimulation on either Figure 6: Bases trained on artiﬁcial synﬁnger tip [28]. [sent-199, score-0.8]
</p><p>69 In contrast to the shifts in receptive dactyly data. [sent-200, score-0.485]
</p><p>70 All models learned double-digit receptive ﬁelds that spanned digits 3 and 4, in qualitative agreement with the ﬁndings reported in [28]. [sent-209, score-0.614]
</p><p>71 Additionally, a small number of bases contained discontinuous double-digit receptive ﬁelds consisting of two well-separated excitatory regions on the extreme ﬁnger tips (e. [sent-210, score-0.76]
</p><p>72 In contrast to the experimental ﬁndings, model receptive ﬁelds spanning digits 3 and 4 also typically have a discontinuity along the seam. [sent-215, score-0.605]
</p><p>73 We believe this reﬂects a limitation of our dataset; although digits 3 and 4 of our data collection glove are fused together and must move in concert, the seam between these digits remains inset from the neighboring ﬁngers, and hence grasps rarely transfer powder to this area. [sent-216, score-0.287]
</p><p>74 5  Discussion  Taken together, our results demonstrate that a number of unsupervised learning algorithms can account for certain normal and altered linear receptive ﬁeld properties across multiple primary sensory cortices. [sent-218, score-1.042]
</p><p>75 Although these ﬁts were not perfect–notably, missing “blob” receptive ﬁelds in V1 and bandpass temporal structure in A1–they demonstrate the feasibility of applying a single learning algorithm to experimental data from multiple modalities. [sent-220, score-0.569]
</p><p>76 The success of these models in capturing the effects of experimental manipulations of sensory input suggests that the adaptation of receptive ﬁeld properties to natural statistics, as proposed by efﬁcient coding models, may occur signiﬁcantly on developmental timescales. [sent-225, score-0.857]
</p><p>77 Furthermore, the ability of a single algorithm to capture responses in multiple sensory cortices shows that, in principle, a qualitatively similar plasticity process could operate throughout primary sensory cortices. [sent-227, score-0.803]
</p><p>78 Experimentally, such a possibility has been addressed most directly by cortical “rewiring” experiments, where visual input is rerouted to either auditory or somatosensory cortex [30, 31, 32, 33, 34, 35]. [sent-228, score-0.876]
</p><p>79 In neonatal ferrets, visual input normally destined for lateral geniculate nucleus can be redirected to the auditory thalamus, which then projects to primary auditory cortex. [sent-229, score-0.968]
</p><p>80 [34] found that rewired ferrets reared to adulthood had neurons in auditory cortex responsive to oriented edges, with orientation tuning indistinguishable from that in normal V1. [sent-232, score-0.871]
</p><p>81 [33] found that rewired auditory cortex can mediate behavior such as discriminating between different grating stimuli and navigating toward a light source. [sent-234, score-0.57]
</p><p>82 Rewiring experiments in hamster corroborate these results, and in addition show that rewiring visual input to somatosensory cortex causes S1 to exhibit light-evoked responses similar to normal V1 [31, 35]. [sent-235, score-0.627]
</p><p>83 Differences between rewired and normal cortices do exist–for example, the period of the orientation map is larger in rewired animals [34]. [sent-236, score-0.356]
</p><p>84 Our results provide a possible explanation of these experiments, as we have shown constructively that the exact same algorithm can produce V1-, A1-, or S1-like receptive ﬁelds depending on the type of input data it receives. [sent-238, score-0.485]
</p><p>85 Emergence of simple-cell receptive ﬁeld properties by learning a sparse code for natural images. [sent-253, score-0.522]
</p><p>86 Independent component analysis of natural image sequences yields spatio-temporal ﬁlters similar to simple cells in primary visual cortex. [sent-260, score-0.306]
</p><p>87 Spatial structure and symmetry of simple-cell receptive ﬁelds in macaque primary visual cortex. [sent-276, score-0.809]
</p><p>88 A network that uses few active neurones to code visual input predicts the diverse shapes of cortical receptive ﬁelds. [sent-284, score-0.637]
</p><p>89 A comparison of experience-dependent plasticity in the visual and somatosensory systems. [sent-308, score-0.472]
</p><p>90 Spatial frequency selectivity of cells in macaque visual cortex. [sent-346, score-0.34]
</p><p>91 The orientation and direction selectivity of cells in macaque visual cortex. [sent-355, score-0.361]
</p><p>92 Spectrotemporal receptive ﬁelds in the lemnisı cal auditory thalamus and cortex. [sent-367, score-0.884]
</p><p>93 Structure of receptive ﬁelds in area 3b of primary somatosensory cortex in the alert monkey. [sent-378, score-1.066]
</p><p>94 Receptive ﬁelds of neurons in areas 3b and 1 of somatosensory cortex in monkeys. [sent-455, score-0.501]
</p><p>95 Critical period window for spectral tuning deﬁned in the primary auditory cortex (A1) in the rat. [sent-481, score-0.703]
</p><p>96 Reorganization of somatosensory area 3b representations in adult owl monkeys after digital syndactyly. [sent-493, score-0.383]
</p><p>97 Experimentally induced visual projections into auditory thalamus and cortex. [sent-508, score-0.51]
</p><p>98 Visual responses of neurons in somatosensory cortex of hamsters with experie mentally induced retinal projections to somatosensory thalamus. [sent-514, score-0.75]
</p><p>99 Visual projections routed to the auditory pathway in ferrets: receptive ﬁelds of visual neurons in primary auditory cortex. [sent-524, score-1.545]
</p><p>100 Visual behaviour mediated by retinal projections directed to the auditory pathway. [sent-533, score-0.349]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('receptive', 0.485), ('auditory', 0.349), ('somatosensory', 0.221), ('mtf', 0.184), ('bases', 0.165), ('elds', 0.159), ('primary', 0.159), ('sensory', 0.155), ('cortex', 0.154), ('plasticity', 0.14), ('altered', 0.12), ('orientation', 0.116), ('visual', 0.111), ('eld', 0.106), ('goggle', 0.1), ('frequency', 0.095), ('neurons', 0.092), ('skin', 0.088), ('tone', 0.088), ('spectrotemporal', 0.088), ('digits', 0.085), ('overrepresentation', 0.084), ('subcortical', 0.084), ('unsupervised', 0.08), ('modulation', 0.077), ('pulsed', 0.074), ('nger', 0.074), ('qualitatively', 0.069), ('organism', 0.068), ('powder', 0.067), ('rewired', 0.067), ('syndactyly', 0.067), ('cortices', 0.063), ('ica', 0.062), ('responses', 0.062), ('autoencoder', 0.06), ('excitatory', 0.06), ('coding', 0.056), ('macaque', 0.054), ('contact', 0.054), ('sounds', 0.054), ('preferred', 0.054), ('whitening', 0.052), ('naturalistic', 0.051), ('ferrets', 0.05), ('grasps', 0.05), ('grip', 0.05), ('macaca', 0.05), ('rearing', 0.05), ('surgically', 0.05), ('thalamus', 0.05), ('tips', 0.05), ('temporal', 0.049), ('adult', 0.048), ('area', 0.047), ('manipulations', 0.046), ('ve', 0.045), ('adaptation', 0.044), ('histograms', 0.044), ('selectivity', 0.044), ('ngers', 0.044), ('qualitative', 0.044), ('normal', 0.043), ('inhibitory', 0.043), ('spectral', 0.041), ('cortical', 0.041), ('lifetime', 0.041), ('composite', 0.039), ('sound', 0.039), ('january', 0.039), ('connor', 0.038), ('sparse', 0.037), ('center', 0.037), ('experimentally', 0.037), ('cells', 0.036), ('ber', 0.036), ('nx', 0.036), ('developmental', 0.036), ('nerve', 0.036), ('rewiring', 0.036), ('early', 0.036), ('experimental', 0.035), ('meant', 0.035), ('areas', 0.034), ('stage', 0.034), ('digital', 0.034), ('afferents', 0.033), ('allard', 0.033), ('cochlea', 0.033), ('cutaneous', 0.033), ('gammatone', 0.033), ('glabrous', 0.033), ('goggles', 0.033), ('kittens', 0.033), ('mechanoreceptors', 0.033), ('melchner', 0.033), ('owl', 0.033), ('pallas', 0.033), ('rods', 0.033), ('roe', 0.033)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999887 <a title="298-tfidf-1" href="./nips-2011-Unsupervised_learning_models_of_primary_cortical_receptive_fields_and_receptive_field_plasticity.html">298 nips-2011-Unsupervised learning models of primary cortical receptive fields and receptive field plasticity</a></p>
<p>Author: Maneesh Bhand, Ritvik Mudur, Bipin Suresh, Andrew Saxe, Andrew Y. Ng</p><p>Abstract: The efﬁcient coding hypothesis holds that neural receptive ﬁelds are adapted to the statistics of the environment, but is agnostic to the timescale of this adaptation, which occurs on both evolutionary and developmental timescales. In this work we focus on that component of adaptation which occurs during an organism’s lifetime, and show that a number of unsupervised feature learning algorithms can account for features of normal receptive ﬁeld properties across multiple primary sensory cortices. Furthermore, we show that the same algorithms account for altered receptive ﬁeld properties in response to experimentally altered environmental statistics. Based on these modeling results we propose these models as phenomenological models of receptive ﬁeld plasticity during an organism’s lifetime. Finally, due to the success of the same models in multiple sensory areas, we suggest that these algorithms may provide a constructive realization of the theory, ﬁrst proposed by Mountcastle [1], that a qualitatively similar learning algorithm acts throughout primary sensory cortices. 1</p><p>2 0.41683188 <a title="298-tfidf-2" href="./nips-2011-Selecting_Receptive_Fields_in_Deep_Networks.html">244 nips-2011-Selecting Receptive Fields in Deep Networks</a></p>
<p>Author: Adam Coates, Andrew Y. Ng</p><p>Abstract: Recent deep learning and unsupervised feature learning systems that learn from unlabeled data have achieved high performance in benchmarks by using extremely large architectures with many features (hidden units) at each layer. Unfortunately, for such large architectures the number of parameters can grow quadratically in the width of the network, thus necessitating hand-coded “local receptive ﬁelds” that limit the number of connections from lower level features to higher ones (e.g., based on spatial locality). In this paper we propose a fast method to choose these connections that may be incorporated into a wide variety of unsupervised training methods. Speciﬁcally, we choose local receptive ﬁelds that group together those low-level features that are most similar to each other according to a pairwise similarity metric. This approach allows us to harness the advantages of local receptive ﬁelds (such as improved scalability, and reduced data requirements) when we do not know how to specify such receptive ﬁelds by hand or where our unsupervised training algorithm has no obvious generalization to a topographic setting. We produce results showing how this method allows us to use even simple unsupervised training algorithms to train successful multi-layered networks that achieve state-of-the-art results on CIFAR and STL datasets: 82.0% and 60.1% accuracy, respectively. 1</p><p>3 0.24409874 <a title="298-tfidf-3" href="./nips-2011-Efficient_coding_of_natural_images_with_a_population_of_noisy_Linear-Nonlinear_neurons.html">82 nips-2011-Efficient coding of natural images with a population of noisy Linear-Nonlinear neurons</a></p>
<p>Author: Yan Karklin, Eero P. Simoncelli</p><p>Abstract: Efﬁcient coding provides a powerful principle for explaining early sensory coding. Most attempts to test this principle have been limited to linear, noiseless models, and when applied to natural images, have yielded oriented ﬁlters consistent with responses in primary visual cortex. Here we show that an efﬁcient coding model that incorporates biologically realistic ingredients – input and output noise, nonlinear response functions, and a metabolic cost on the ﬁring rate – predicts receptive ﬁelds and response nonlinearities similar to those observed in the retina. Speciﬁcally, we develop numerical methods for simultaneously learning the linear ﬁlters and response nonlinearities of a population of model neurons, so as to maximize information transmission subject to metabolic costs. When applied to an ensemble of natural images, the method yields ﬁlters that are center-surround and nonlinearities that are rectifying. The ﬁlters are organized into two populations, with On- and Off-centers, which independently tile the visual space. As observed in the primate retina, the Off-center neurons are more numerous and have ﬁlters with smaller spatial extent. In the absence of noise, our method reduces to a generalized version of independent components analysis, with an adapted nonlinear “contrast” function; in this case, the optimal ﬁlters are localized and oriented.</p><p>4 0.14701921 <a title="298-tfidf-4" href="./nips-2011-Neural_Reconstruction_with_Approximate_Message_Passing_%28NeuRAMP%29.html">183 nips-2011-Neural Reconstruction with Approximate Message Passing (NeuRAMP)</a></p>
<p>Author: Alyson K. Fletcher, Sundeep Rangan, Lav R. Varshney, Aniruddha Bhargava</p><p>Abstract: Many functional descriptions of spiking neurons assume a cascade structure where inputs are passed through an initial linear ﬁltering stage that produces a lowdimensional signal that drives subsequent nonlinear stages. This paper presents a novel and systematic parameter estimation procedure for such models and applies the method to two neural estimation problems: (i) compressed-sensing based neural mapping from multi-neuron excitation, and (ii) estimation of neural receptive ﬁelds in sensory neurons. The proposed estimation algorithm models the neurons via a graphical model and then estimates the parameters in the model using a recently-developed generalized approximate message passing (GAMP) method. The GAMP method is based on Gaussian approximations of loopy belief propagation. In the neural connectivity problem, the GAMP-based method is shown to be computational efﬁcient, provides a more exact modeling of the sparsity, can incorporate nonlinearities in the output and signiﬁcantly outperforms previous compressed-sensing methods. For the receptive ﬁeld estimation, the GAMP method can also exploit inherent structured sparsity in the linear weights. The method is validated on estimation of linear nonlinear Poisson (LNP) cascade models for receptive ﬁelds of salamander retinal ganglion cells. 1</p><p>5 0.14533152 <a title="298-tfidf-5" href="./nips-2011-ICA_with_Reconstruction_Cost_for_Efficient_Overcomplete_Feature_Learning.html">124 nips-2011-ICA with Reconstruction Cost for Efficient Overcomplete Feature Learning</a></p>
<p>Author: Quoc V. Le, Alexandre Karpenko, Jiquan Ngiam, Andrew Y. Ng</p><p>Abstract: Independent Components Analysis (ICA) and its variants have been successfully used for unsupervised feature learning. However, standard ICA requires an orthonoramlity constraint to be enforced, which makes it difﬁcult to learn overcomplete features. In addition, ICA is sensitive to whitening. These properties make it challenging to scale ICA to high dimensional data. In this paper, we propose a robust soft reconstruction cost for ICA that allows us to learn highly overcomplete sparse features even on unwhitened data. Our formulation reveals formal connections between ICA and sparse autoencoders, which have previously been observed only empirically. Our algorithm can be used in conjunction with off-the-shelf fast unconstrained optimizers. We show that the soft reconstruction cost can also be used to prevent replicated features in tiled convolutional neural networks. Using our method to learn highly overcomplete sparse features and tiled convolutional neural networks, we obtain competitive performances on a wide variety of object recognition tasks. We achieve state-of-the-art test accuracies on the STL-10 and Hollywood2 datasets. 1</p><p>6 0.13453388 <a title="298-tfidf-6" href="./nips-2011-Why_The_Brain_Separates_Face_Recognition_From_Object_Recognition.html">304 nips-2011-Why The Brain Separates Face Recognition From Object Recognition</a></p>
<p>7 0.12360382 <a title="298-tfidf-7" href="./nips-2011-Sparse_Filtering.html">261 nips-2011-Sparse Filtering</a></p>
<p>8 0.12250464 <a title="298-tfidf-8" href="./nips-2011-Bayesian_Spike-Triggered_Covariance_Analysis.html">44 nips-2011-Bayesian Spike-Triggered Covariance Analysis</a></p>
<p>9 0.11277495 <a title="298-tfidf-9" href="./nips-2011-Structured_sparse_coding_via_lateral_inhibition.html">276 nips-2011-Structured sparse coding via lateral inhibition</a></p>
<p>10 0.11096744 <a title="298-tfidf-10" href="./nips-2011-Predicting_response_time_and_error_rates_in_visual_search.html">219 nips-2011-Predicting response time and error rates in visual search</a></p>
<p>11 0.10689396 <a title="298-tfidf-11" href="./nips-2011-Structural_equations_and_divisive_normalization_for_energy-dependent_component_analysis.html">273 nips-2011-Structural equations and divisive normalization for energy-dependent component analysis</a></p>
<p>12 0.1048063 <a title="298-tfidf-12" href="./nips-2011-Variational_Learning_for_Recurrent_Spiking_Networks.html">302 nips-2011-Variational Learning for Recurrent Spiking Networks</a></p>
<p>13 0.098705947 <a title="298-tfidf-13" href="./nips-2011-Probabilistic_Modeling_of_Dependencies_Among_Visual_Short-Term_Memory_Representations.html">224 nips-2011-Probabilistic Modeling of Dependencies Among Visual Short-Term Memory Representations</a></p>
<p>14 0.089961469 <a title="298-tfidf-14" href="./nips-2011-Analytical_Results_for_the_Error_in_Filtering_of_Gaussian_Processes.html">37 nips-2011-Analytical Results for the Error in Filtering of Gaussian Processes</a></p>
<p>15 0.082036793 <a title="298-tfidf-15" href="./nips-2011-Select_and_Sample_-_A_Model_of_Efficient_Neural_Inference_and_Learning.html">243 nips-2011-Select and Sample - A Model of Efficient Neural Inference and Learning</a></p>
<p>16 0.074511677 <a title="298-tfidf-16" href="./nips-2011-Sequence_learning_with_hidden_units_in_spiking_neural_networks.html">249 nips-2011-Sequence learning with hidden units in spiking neural networks</a></p>
<p>17 0.070749991 <a title="298-tfidf-17" href="./nips-2011-Neuronal_Adaptation_for_Sampling-Based_Probabilistic_Inference_in_Perceptual_Bistability.html">184 nips-2011-Neuronal Adaptation for Sampling-Based Probabilistic Inference in Perceptual Bistability</a></p>
<p>18 0.070033461 <a title="298-tfidf-18" href="./nips-2011-Information_Rates_and_Optimal_Decoding_in_Large_Neural_Populations.html">135 nips-2011-Information Rates and Optimal Decoding in Large Neural Populations</a></p>
<p>19 0.06693285 <a title="298-tfidf-19" href="./nips-2011-Probabilistic_amplitude_and_frequency_demodulation.html">225 nips-2011-Probabilistic amplitude and frequency demodulation</a></p>
<p>20 0.06111671 <a title="298-tfidf-20" href="./nips-2011-Inferring_spike-timing-dependent_plasticity_from_spike_train_data.html">133 nips-2011-Inferring spike-timing-dependent plasticity from spike train data</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.172), (1, 0.166), (2, 0.176), (3, 0.06), (4, 0.075), (5, 0.136), (6, 0.086), (7, 0.219), (8, 0.002), (9, -0.212), (10, -0.073), (11, -0.059), (12, 0.109), (13, -0.062), (14, 0.1), (15, 0.065), (16, 0.081), (17, -0.059), (18, -0.0), (19, -0.015), (20, -0.188), (21, -0.095), (22, -0.03), (23, 0.015), (24, -0.025), (25, 0.06), (26, -0.057), (27, 0.067), (28, 0.016), (29, -0.084), (30, 0.097), (31, 0.012), (32, -0.039), (33, -0.039), (34, -0.089), (35, 0.052), (36, -0.042), (37, -0.011), (38, 0.018), (39, -0.064), (40, -0.112), (41, -0.029), (42, -0.013), (43, -0.014), (44, -0.083), (45, -0.043), (46, 0.004), (47, 0.013), (48, -0.024), (49, 0.003)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96969402 <a title="298-lsi-1" href="./nips-2011-Unsupervised_learning_models_of_primary_cortical_receptive_fields_and_receptive_field_plasticity.html">298 nips-2011-Unsupervised learning models of primary cortical receptive fields and receptive field plasticity</a></p>
<p>Author: Maneesh Bhand, Ritvik Mudur, Bipin Suresh, Andrew Saxe, Andrew Y. Ng</p><p>Abstract: The efﬁcient coding hypothesis holds that neural receptive ﬁelds are adapted to the statistics of the environment, but is agnostic to the timescale of this adaptation, which occurs on both evolutionary and developmental timescales. In this work we focus on that component of adaptation which occurs during an organism’s lifetime, and show that a number of unsupervised feature learning algorithms can account for features of normal receptive ﬁeld properties across multiple primary sensory cortices. Furthermore, we show that the same algorithms account for altered receptive ﬁeld properties in response to experimentally altered environmental statistics. Based on these modeling results we propose these models as phenomenological models of receptive ﬁeld plasticity during an organism’s lifetime. Finally, due to the success of the same models in multiple sensory areas, we suggest that these algorithms may provide a constructive realization of the theory, ﬁrst proposed by Mountcastle [1], that a qualitatively similar learning algorithm acts throughout primary sensory cortices. 1</p><p>2 0.79527867 <a title="298-lsi-2" href="./nips-2011-Selecting_Receptive_Fields_in_Deep_Networks.html">244 nips-2011-Selecting Receptive Fields in Deep Networks</a></p>
<p>Author: Adam Coates, Andrew Y. Ng</p><p>Abstract: Recent deep learning and unsupervised feature learning systems that learn from unlabeled data have achieved high performance in benchmarks by using extremely large architectures with many features (hidden units) at each layer. Unfortunately, for such large architectures the number of parameters can grow quadratically in the width of the network, thus necessitating hand-coded “local receptive ﬁelds” that limit the number of connections from lower level features to higher ones (e.g., based on spatial locality). In this paper we propose a fast method to choose these connections that may be incorporated into a wide variety of unsupervised training methods. Speciﬁcally, we choose local receptive ﬁelds that group together those low-level features that are most similar to each other according to a pairwise similarity metric. This approach allows us to harness the advantages of local receptive ﬁelds (such as improved scalability, and reduced data requirements) when we do not know how to specify such receptive ﬁelds by hand or where our unsupervised training algorithm has no obvious generalization to a topographic setting. We produce results showing how this method allows us to use even simple unsupervised training algorithms to train successful multi-layered networks that achieve state-of-the-art results on CIFAR and STL datasets: 82.0% and 60.1% accuracy, respectively. 1</p><p>3 0.73482788 <a title="298-lsi-3" href="./nips-2011-Efficient_coding_of_natural_images_with_a_population_of_noisy_Linear-Nonlinear_neurons.html">82 nips-2011-Efficient coding of natural images with a population of noisy Linear-Nonlinear neurons</a></p>
<p>Author: Yan Karklin, Eero P. Simoncelli</p><p>Abstract: Efﬁcient coding provides a powerful principle for explaining early sensory coding. Most attempts to test this principle have been limited to linear, noiseless models, and when applied to natural images, have yielded oriented ﬁlters consistent with responses in primary visual cortex. Here we show that an efﬁcient coding model that incorporates biologically realistic ingredients – input and output noise, nonlinear response functions, and a metabolic cost on the ﬁring rate – predicts receptive ﬁelds and response nonlinearities similar to those observed in the retina. Speciﬁcally, we develop numerical methods for simultaneously learning the linear ﬁlters and response nonlinearities of a population of model neurons, so as to maximize information transmission subject to metabolic costs. When applied to an ensemble of natural images, the method yields ﬁlters that are center-surround and nonlinearities that are rectifying. The ﬁlters are organized into two populations, with On- and Off-centers, which independently tile the visual space. As observed in the primate retina, the Off-center neurons are more numerous and have ﬁlters with smaller spatial extent. In the absence of noise, our method reduces to a generalized version of independent components analysis, with an adapted nonlinear “contrast” function; in this case, the optimal ﬁlters are localized and oriented.</p><p>4 0.67109996 <a title="298-lsi-4" href="./nips-2011-ICA_with_Reconstruction_Cost_for_Efficient_Overcomplete_Feature_Learning.html">124 nips-2011-ICA with Reconstruction Cost for Efficient Overcomplete Feature Learning</a></p>
<p>Author: Quoc V. Le, Alexandre Karpenko, Jiquan Ngiam, Andrew Y. Ng</p><p>Abstract: Independent Components Analysis (ICA) and its variants have been successfully used for unsupervised feature learning. However, standard ICA requires an orthonoramlity constraint to be enforced, which makes it difﬁcult to learn overcomplete features. In addition, ICA is sensitive to whitening. These properties make it challenging to scale ICA to high dimensional data. In this paper, we propose a robust soft reconstruction cost for ICA that allows us to learn highly overcomplete sparse features even on unwhitened data. Our formulation reveals formal connections between ICA and sparse autoencoders, which have previously been observed only empirically. Our algorithm can be used in conjunction with off-the-shelf fast unconstrained optimizers. We show that the soft reconstruction cost can also be used to prevent replicated features in tiled convolutional neural networks. Using our method to learn highly overcomplete sparse features and tiled convolutional neural networks, we obtain competitive performances on a wide variety of object recognition tasks. We achieve state-of-the-art test accuracies on the STL-10 and Hollywood2 datasets. 1</p><p>5 0.65534663 <a title="298-lsi-5" href="./nips-2011-Neural_Reconstruction_with_Approximate_Message_Passing_%28NeuRAMP%29.html">183 nips-2011-Neural Reconstruction with Approximate Message Passing (NeuRAMP)</a></p>
<p>Author: Alyson K. Fletcher, Sundeep Rangan, Lav R. Varshney, Aniruddha Bhargava</p><p>Abstract: Many functional descriptions of spiking neurons assume a cascade structure where inputs are passed through an initial linear ﬁltering stage that produces a lowdimensional signal that drives subsequent nonlinear stages. This paper presents a novel and systematic parameter estimation procedure for such models and applies the method to two neural estimation problems: (i) compressed-sensing based neural mapping from multi-neuron excitation, and (ii) estimation of neural receptive ﬁelds in sensory neurons. The proposed estimation algorithm models the neurons via a graphical model and then estimates the parameters in the model using a recently-developed generalized approximate message passing (GAMP) method. The GAMP method is based on Gaussian approximations of loopy belief propagation. In the neural connectivity problem, the GAMP-based method is shown to be computational efﬁcient, provides a more exact modeling of the sparsity, can incorporate nonlinearities in the output and signiﬁcantly outperforms previous compressed-sensing methods. For the receptive ﬁeld estimation, the GAMP method can also exploit inherent structured sparsity in the linear weights. The method is validated on estimation of linear nonlinear Poisson (LNP) cascade models for receptive ﬁelds of salamander retinal ganglion cells. 1</p><p>6 0.61195624 <a title="298-lsi-6" href="./nips-2011-Bayesian_Spike-Triggered_Covariance_Analysis.html">44 nips-2011-Bayesian Spike-Triggered Covariance Analysis</a></p>
<p>7 0.52104205 <a title="298-lsi-7" href="./nips-2011-Sparse_Filtering.html">261 nips-2011-Sparse Filtering</a></p>
<p>8 0.46949196 <a title="298-lsi-8" href="./nips-2011-Structural_equations_and_divisive_normalization_for_energy-dependent_component_analysis.html">273 nips-2011-Structural equations and divisive normalization for energy-dependent component analysis</a></p>
<p>9 0.45917189 <a title="298-lsi-9" href="./nips-2011-Why_The_Brain_Separates_Face_Recognition_From_Object_Recognition.html">304 nips-2011-Why The Brain Separates Face Recognition From Object Recognition</a></p>
<p>10 0.40833959 <a title="298-lsi-10" href="./nips-2011-Probabilistic_Modeling_of_Dependencies_Among_Visual_Short-Term_Memory_Representations.html">224 nips-2011-Probabilistic Modeling of Dependencies Among Visual Short-Term Memory Representations</a></p>
<p>11 0.39627919 <a title="298-lsi-11" href="./nips-2011-Emergence_of_Multiplication_in_a_Biophysical_Model_of_a_Wide-Field_Visual_Neuron_for_Computing_Object_Approaches%3A_Dynamics%2C_Peaks%2C_%26_Fits.html">85 nips-2011-Emergence of Multiplication in a Biophysical Model of a Wide-Field Visual Neuron for Computing Object Approaches: Dynamics, Peaks, & Fits</a></p>
<p>12 0.39190161 <a title="298-lsi-12" href="./nips-2011-Neuronal_Adaptation_for_Sampling-Based_Probabilistic_Inference_in_Perceptual_Bistability.html">184 nips-2011-Neuronal Adaptation for Sampling-Based Probabilistic Inference in Perceptual Bistability</a></p>
<p>13 0.38854969 <a title="298-lsi-13" href="./nips-2011-Select_and_Sample_-_A_Model_of_Efficient_Neural_Inference_and_Learning.html">243 nips-2011-Select and Sample - A Model of Efficient Neural Inference and Learning</a></p>
<p>14 0.38557979 <a title="298-lsi-14" href="./nips-2011-Structured_sparse_coding_via_lateral_inhibition.html">276 nips-2011-Structured sparse coding via lateral inhibition</a></p>
<p>15 0.36810288 <a title="298-lsi-15" href="./nips-2011-Hierarchical_Matching_Pursuit_for_Image_Classification%3A_Architecture_and_Fast_Algorithms.html">113 nips-2011-Hierarchical Matching Pursuit for Image Classification: Architecture and Fast Algorithms</a></p>
<p>16 0.36405268 <a title="298-lsi-16" href="./nips-2011-Active_learning_of_neural_response_functions_with_Gaussian_processes.html">24 nips-2011-Active learning of neural response functions with Gaussian processes</a></p>
<p>17 0.35968989 <a title="298-lsi-17" href="./nips-2011-Extracting_Speaker-Specific_Information_with_a_Regularized_Siamese_Deep_Network.html">93 nips-2011-Extracting Speaker-Specific Information with a Regularized Siamese Deep Network</a></p>
<p>18 0.35389918 <a title="298-lsi-18" href="./nips-2011-Identifying_Alzheimer%27s_Disease-Related_Brain_Regions_from_Multi-Modality_Neuroimaging_Data_using_Sparse_Composite_Linear_Discrimination_Analysis.html">125 nips-2011-Identifying Alzheimer's Disease-Related Brain Regions from Multi-Modality Neuroimaging Data using Sparse Composite Linear Discrimination Analysis</a></p>
<p>19 0.3331942 <a title="298-lsi-19" href="./nips-2011-Two_is_better_than_one%3A_distinct_roles_for_familiarity_and_recollection_in_retrieving_palimpsest_memories.html">292 nips-2011-Two is better than one: distinct roles for familiarity and recollection in retrieving palimpsest memories</a></p>
<p>20 0.32732177 <a title="298-lsi-20" href="./nips-2011-Dynamic_Pooling_and_Unfolding_Recursive_Autoencoders_for_Paraphrase_Detection.html">74 nips-2011-Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.015), (4, 0.018), (20, 0.019), (26, 0.015), (31, 0.088), (33, 0.019), (39, 0.012), (43, 0.043), (45, 0.058), (57, 0.033), (65, 0.455), (74, 0.039), (83, 0.064), (84, 0.011), (99, 0.034)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.88569266 <a title="298-lda-1" href="./nips-2011-Unsupervised_learning_models_of_primary_cortical_receptive_fields_and_receptive_field_plasticity.html">298 nips-2011-Unsupervised learning models of primary cortical receptive fields and receptive field plasticity</a></p>
<p>Author: Maneesh Bhand, Ritvik Mudur, Bipin Suresh, Andrew Saxe, Andrew Y. Ng</p><p>Abstract: The efﬁcient coding hypothesis holds that neural receptive ﬁelds are adapted to the statistics of the environment, but is agnostic to the timescale of this adaptation, which occurs on both evolutionary and developmental timescales. In this work we focus on that component of adaptation which occurs during an organism’s lifetime, and show that a number of unsupervised feature learning algorithms can account for features of normal receptive ﬁeld properties across multiple primary sensory cortices. Furthermore, we show that the same algorithms account for altered receptive ﬁeld properties in response to experimentally altered environmental statistics. Based on these modeling results we propose these models as phenomenological models of receptive ﬁeld plasticity during an organism’s lifetime. Finally, due to the success of the same models in multiple sensory areas, we suggest that these algorithms may provide a constructive realization of the theory, ﬁrst proposed by Mountcastle [1], that a qualitatively similar learning algorithm acts throughout primary sensory cortices. 1</p><p>2 0.87024552 <a title="298-lda-2" href="./nips-2011-Extracting_Speaker-Specific_Information_with_a_Regularized_Siamese_Deep_Network.html">93 nips-2011-Extracting Speaker-Specific Information with a Regularized Siamese Deep Network</a></p>
<p>Author: Ke Chen, Ahmad Salman</p><p>Abstract: Speech conveys different yet mixed information ranging from linguistic to speaker-speciﬁc components, and each of them should be exclusively used in a speciﬁc task. However, it is extremely difﬁcult to extract a speciﬁc information component given the fact that nearly all existing acoustic representations carry all types of speech information. Thus, the use of the same representation in both speech and speaker recognition hinders a system from producing better performance due to interference of irrelevant information. In this paper, we present a deep neural architecture to extract speaker-speciﬁc information from MFCCs. As a result, a multi-objective loss function is proposed for learning speaker-speciﬁc characteristics and regularization via normalizing interference of non-speaker related information and avoiding information loss. With LDC benchmark corpora and a Chinese speech corpus, we demonstrate that a resultant speaker-speciﬁc representation is insensitive to text/languages spoken and environmental mismatches and hence outperforms MFCCs and other state-of-the-art techniques in speaker recognition. We discuss relevant issues and relate our approach to previous work. 1</p><p>3 0.61339504 <a title="298-lda-3" href="./nips-2011-Non-parametric_Group_Orthogonal_Matching_Pursuit_for_Sparse_Learning_with_Multiple_Kernels.html">189 nips-2011-Non-parametric Group Orthogonal Matching Pursuit for Sparse Learning with Multiple Kernels</a></p>
<p>Author: Vikas Sindhwani, Aurelie C. Lozano</p><p>Abstract: We consider regularized risk minimization in a large dictionary of Reproducing kernel Hilbert Spaces (RKHSs) over which the target function has a sparse representation. This setting, commonly referred to as Sparse Multiple Kernel Learning (MKL), may be viewed as the non-parametric extension of group sparsity in linear models. While the two dominant algorithmic strands of sparse learning, namely convex relaxations using l1 norm (e.g., Lasso) and greedy methods (e.g., OMP), have both been rigorously extended for group sparsity, the sparse MKL literature has so far mainly adopted the former with mild empirical success. In this paper, we close this gap by proposing a Group-OMP based framework for sparse MKL. Unlike l1 -MKL, our approach decouples the sparsity regularizer (via a direct l0 constraint) from the smoothness regularizer (via RKHS norms), which leads to better empirical performance and a simpler optimization procedure that only requires a black-box single-kernel solver. The algorithmic development and empirical studies are complemented by theoretical analyses in terms of Rademacher generalization bounds and sparse recovery conditions analogous to those for OMP [27] and Group-OMP [16]. 1</p><p>4 0.60405385 <a title="298-lda-4" href="./nips-2011-ICA_with_Reconstruction_Cost_for_Efficient_Overcomplete_Feature_Learning.html">124 nips-2011-ICA with Reconstruction Cost for Efficient Overcomplete Feature Learning</a></p>
<p>Author: Quoc V. Le, Alexandre Karpenko, Jiquan Ngiam, Andrew Y. Ng</p><p>Abstract: Independent Components Analysis (ICA) and its variants have been successfully used for unsupervised feature learning. However, standard ICA requires an orthonoramlity constraint to be enforced, which makes it difﬁcult to learn overcomplete features. In addition, ICA is sensitive to whitening. These properties make it challenging to scale ICA to high dimensional data. In this paper, we propose a robust soft reconstruction cost for ICA that allows us to learn highly overcomplete sparse features even on unwhitened data. Our formulation reveals formal connections between ICA and sparse autoencoders, which have previously been observed only empirically. Our algorithm can be used in conjunction with off-the-shelf fast unconstrained optimizers. We show that the soft reconstruction cost can also be used to prevent replicated features in tiled convolutional neural networks. Using our method to learn highly overcomplete sparse features and tiled convolutional neural networks, we obtain competitive performances on a wide variety of object recognition tasks. We achieve state-of-the-art test accuracies on the STL-10 and Hollywood2 datasets. 1</p><p>5 0.57874799 <a title="298-lda-5" href="./nips-2011-Sparse_Filtering.html">261 nips-2011-Sparse Filtering</a></p>
<p>Author: Jiquan Ngiam, Zhenghao Chen, Sonia A. Bhaskar, Pang W. Koh, Andrew Y. Ng</p><p>Abstract: Unsupervised feature learning has been shown to be effective at learning representations that perform well on image, video and audio classiﬁcation. However, many existing feature learning algorithms are hard to use and require extensive hyperparameter tuning. In this work, we present sparse ﬁltering, a simple new algorithm which is efﬁcient and only has one hyperparameter, the number of features to learn. In contrast to most other feature learning methods, sparse ﬁltering does not explicitly attempt to construct a model of the data distribution. Instead, it optimizes a simple cost function – the sparsity of 2 -normalized features – which can easily be implemented in a few lines of MATLAB code. Sparse ﬁltering scales gracefully to handle high-dimensional inputs, and can also be used to learn meaningful features in additional layers with greedy layer-wise stacking. We evaluate sparse ﬁltering on natural images, object classiﬁcation (STL-10), and phone classiﬁcation (TIMIT), and show that our method works well on a range of different modalities. 1</p><p>6 0.57695252 <a title="298-lda-6" href="./nips-2011-Efficient_Learning_of_Generalized_Linear_and_Single_Index_Models_with_Isotonic_Regression.html">77 nips-2011-Efficient Learning of Generalized Linear and Single Index Models with Isotonic Regression</a></p>
<p>7 0.51245892 <a title="298-lda-7" href="./nips-2011-Hierarchical_Matching_Pursuit_for_Image_Classification%3A_Architecture_and_Fast_Algorithms.html">113 nips-2011-Hierarchical Matching Pursuit for Image Classification: Architecture and Fast Algorithms</a></p>
<p>8 0.48055372 <a title="298-lda-8" href="./nips-2011-Selecting_Receptive_Fields_in_Deep_Networks.html">244 nips-2011-Selecting Receptive Fields in Deep Networks</a></p>
<p>9 0.41026187 <a title="298-lda-9" href="./nips-2011-Efficient_coding_of_natural_images_with_a_population_of_noisy_Linear-Nonlinear_neurons.html">82 nips-2011-Efficient coding of natural images with a population of noisy Linear-Nonlinear neurons</a></p>
<p>10 0.40223345 <a title="298-lda-10" href="./nips-2011-Generalized_Lasso_based_Approximation_of_Sparse_Coding_for_Visual_Recognition.html">105 nips-2011-Generalized Lasso based Approximation of Sparse Coding for Visual Recognition</a></p>
<p>11 0.39619267 <a title="298-lda-11" href="./nips-2011-Structural_equations_and_divisive_normalization_for_energy-dependent_component_analysis.html">273 nips-2011-Structural equations and divisive normalization for energy-dependent component analysis</a></p>
<p>12 0.39521372 <a title="298-lda-12" href="./nips-2011-Dynamic_Pooling_and_Unfolding_Recursive_Autoencoders_for_Paraphrase_Detection.html">74 nips-2011-Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection</a></p>
<p>13 0.38758904 <a title="298-lda-13" href="./nips-2011-Why_The_Brain_Separates_Face_Recognition_From_Object_Recognition.html">304 nips-2011-Why The Brain Separates Face Recognition From Object Recognition</a></p>
<p>14 0.37141737 <a title="298-lda-14" href="./nips-2011-Neural_Reconstruction_with_Approximate_Message_Passing_%28NeuRAMP%29.html">183 nips-2011-Neural Reconstruction with Approximate Message Passing (NeuRAMP)</a></p>
<p>15 0.36071426 <a title="298-lda-15" href="./nips-2011-Predicting_response_time_and_error_rates_in_visual_search.html">219 nips-2011-Predicting response time and error rates in visual search</a></p>
<p>16 0.35194057 <a title="298-lda-16" href="./nips-2011-Neuronal_Adaptation_for_Sampling-Based_Probabilistic_Inference_in_Perceptual_Bistability.html">184 nips-2011-Neuronal Adaptation for Sampling-Based Probabilistic Inference in Perceptual Bistability</a></p>
<p>17 0.35174018 <a title="298-lda-17" href="./nips-2011-An_ideal_observer_model_for_identifying_the_reference_frame_of_objects.html">35 nips-2011-An ideal observer model for identifying the reference frame of objects</a></p>
<p>18 0.34906024 <a title="298-lda-18" href="./nips-2011-Structured_sparse_coding_via_lateral_inhibition.html">276 nips-2011-Structured sparse coding via lateral inhibition</a></p>
<p>19 0.34592348 <a title="298-lda-19" href="./nips-2011-Select_and_Sample_-_A_Model_of_Efficient_Neural_Inference_and_Learning.html">243 nips-2011-Select and Sample - A Model of Efficient Neural Inference and Learning</a></p>
<p>20 0.34120402 <a title="298-lda-20" href="./nips-2011-Learning_to_Learn_with_Compound_HD_Models.html">156 nips-2011-Learning to Learn with Compound HD Models</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
