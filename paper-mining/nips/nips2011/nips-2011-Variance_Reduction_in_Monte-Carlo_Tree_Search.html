<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>300 nips-2011-Variance Reduction in Monte-Carlo Tree Search</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-300" href="#">nips2011-300</a> knowledge-graph by maker-knowledge-mining</p><h1>300 nips-2011-Variance Reduction in Monte-Carlo Tree Search</h1>
<br/><p>Source: <a title="nips-2011-300-pdf" href="http://papers.nips.cc/paper/4288-variance-reduction-in-monte-carlo-tree-search.pdf">pdf</a></p><p>Author: Joel Veness, Marc Lanctot, Michael Bowling</p><p>Abstract: Monte-Carlo Tree Search (MCTS) has proven to be a powerful, generic planning technique for decision-making in single-agent and adversarial environments. The stochastic nature of the Monte-Carlo simulations introduces errors in the value estimates, both in terms of bias and variance. Whilst reducing bias (typically through the addition of domain knowledge) has been studied in the MCTS literature, comparatively little effort has focused on reducing variance. This is somewhat surprising, since variance reduction techniques are a well-studied area in classical statistics. In this paper, we examine the application of some standard techniques for variance reduction in MCTS, including common random numbers, antithetic variates and control variates. We demonstrate how these techniques can be applied to MCTS and explore their efﬁcacy on three different stochastic, single-agent settings: Pig, Can’t Stop and Dominion. 1</p><p>Reference: <a title="nips-2011-300-reference" href="../nips2011_reference/nips-2011-Variance_Reduction_in_Monte-Carlo_Tree_Search_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('uct', 0.403), ('antithet', 0.374), ('pig', 0.363), ('mcts', 0.236), ('dic', 0.19), ('gam', 0.179), ('st', 0.152), ('card', 0.15), ('xst', 0.143), ('traject', 0.138), ('var', 0.136), ('si', 0.132), ('rol', 0.13), ('stop', 0.124), ('chant', 0.109), ('policy', 0.108), ('ai', 0.103), ('mse', 0.096), ('plan', 0.093), ('sim', 0.092)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="300-tfidf-1" href="./nips-2011-Variance_Reduction_in_Monte-Carlo_Tree_Search.html">300 nips-2011-Variance Reduction in Monte-Carlo Tree Search</a></p>
<p>2 0.14180587 <a title="300-tfidf-2" href="./nips-2011-Policy_Gradient_Coagent_Networks.html">215 nips-2011-Policy Gradient Coagent Networks</a></p>
<p>3 0.12518689 <a title="300-tfidf-3" href="./nips-2011-On_Strategy_Stitching_in_Large_Extensive_Form_Multiplayer_Games.html">196 nips-2011-On Strategy Stitching in Large Extensive Form Multiplayer Games</a></p>
<p>4 0.10800135 <a title="300-tfidf-4" href="./nips-2011-A_reinterpretation_of_the_policy_oscillation_phenomenon_in_approximate_policy_iteration.html">16 nips-2011-A reinterpretation of the policy oscillation phenomenon in approximate policy iteration</a></p>
<p>5 0.09850847 <a title="300-tfidf-5" href="./nips-2011-Learning_Eigenvectors_for_Free.html">145 nips-2011-Learning Eigenvectors for Free</a></p>
<p>6 0.096835785 <a title="300-tfidf-6" href="./nips-2011-Monte_Carlo_Value_Iteration_with_Macro-Actions.html">174 nips-2011-Monte Carlo Value Iteration with Macro-Actions</a></p>
<p>7 0.096266732 <a title="300-tfidf-7" href="./nips-2011-Predicting_Dynamic_Difficulty.html">218 nips-2011-Predicting Dynamic Difficulty</a></p>
<p>8 0.091248617 <a title="300-tfidf-8" href="./nips-2011-Environmental_statistics_and_the_trade-off_between_model-based_and_TD_learning_in_humans.html">88 nips-2011-Environmental statistics and the trade-off between model-based and TD learning in humans</a></p>
<p>9 0.089134403 <a title="300-tfidf-9" href="./nips-2011-TD_gamma%3A_Re-evaluating_Complex_Backups_in_Temporal_Difference_Learning.html">278 nips-2011-TD gamma: Re-evaluating Complex Backups in Temporal Difference Learning</a></p>
<p>10 0.086666666 <a title="300-tfidf-10" href="./nips-2011-PAC-Bayesian_Analysis_of_Contextual_Bandits.html">210 nips-2011-PAC-Bayesian Analysis of Contextual Bandits</a></p>
<p>11 0.086067662 <a title="300-tfidf-11" href="./nips-2011-Autonomous_Learning_of_Action_Models_for_Planning.html">41 nips-2011-Autonomous Learning of Action Models for Planning</a></p>
<p>12 0.079134859 <a title="300-tfidf-12" href="./nips-2011-Action-Gap_Phenomenon_in_Reinforcement_Learning.html">18 nips-2011-Action-Gap Phenomenon in Reinforcement Learning</a></p>
<p>13 0.077741101 <a title="300-tfidf-13" href="./nips-2011-Periodic_Finite_State_Controllers_for_Efficient_POMDP_and_DEC-POMDP_Planning.html">212 nips-2011-Periodic Finite State Controllers for Efficient POMDP and DEC-POMDP Planning</a></p>
<p>14 0.076301321 <a title="300-tfidf-14" href="./nips-2011-Selecting_the_State-Representation_in_Reinforcement_Learning.html">245 nips-2011-Selecting the State-Representation in Reinforcement Learning</a></p>
<p>15 0.073076069 <a title="300-tfidf-15" href="./nips-2011-A_Non-Parametric_Approach_to_Dynamic_Programming.html">10 nips-2011-A Non-Parametric Approach to Dynamic Programming</a></p>
<p>16 0.071791276 <a title="300-tfidf-16" href="./nips-2011-Online_Learning%3A_Stochastic%2C_Constrained%2C_and_Smoothed_Adversaries.html">204 nips-2011-Online Learning: Stochastic, Constrained, and Smoothed Adversaries</a></p>
<p>17 0.071192965 <a title="300-tfidf-17" href="./nips-2011-Randomized_Algorithms_for_Comparison-based_Search.html">231 nips-2011-Randomized Algorithms for Comparison-based Search</a></p>
<p>18 0.070901513 <a title="300-tfidf-18" href="./nips-2011-Online_Submodular_Set_Cover%2C_Ranking%2C_and_Repeated_Active_Learning.html">205 nips-2011-Online Submodular Set Cover, Ranking, and Repeated Active Learning</a></p>
<p>19 0.070898317 <a title="300-tfidf-19" href="./nips-2011-Solving_Decision_Problems_with_Limited_Information.html">256 nips-2011-Solving Decision Problems with Limited Information</a></p>
<p>20 0.069383837 <a title="300-tfidf-20" href="./nips-2011-Optimal_Reinforcement_Learning_for_Gaussian_Systems.html">206 nips-2011-Optimal Reinforcement Learning for Gaussian Systems</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.172), (1, -0.089), (2, -0.103), (3, -0.1), (4, 0.072), (5, -0.035), (6, -0.081), (7, -0.032), (8, -0.022), (9, -0.039), (10, -0.023), (11, -0.014), (12, -0.002), (13, -0.001), (14, -0.026), (15, 0.033), (16, -0.049), (17, 0.021), (18, -0.002), (19, 0.029), (20, 0.064), (21, -0.016), (22, -0.099), (23, 0.0), (24, 0.046), (25, -0.006), (26, -0.022), (27, 0.047), (28, -0.012), (29, -0.066), (30, 0.138), (31, 0.028), (32, -0.105), (33, 0.13), (34, 0.011), (35, -0.001), (36, -0.076), (37, -0.075), (38, -0.03), (39, 0.015), (40, -0.093), (41, -0.093), (42, -0.097), (43, 0.028), (44, 0.007), (45, -0.048), (46, 0.039), (47, 0.012), (48, -0.07), (49, -0.117)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91826028 <a title="300-lsi-1" href="./nips-2011-Variance_Reduction_in_Monte-Carlo_Tree_Search.html">300 nips-2011-Variance Reduction in Monte-Carlo Tree Search</a></p>
<p>2 0.70068336 <a title="300-lsi-2" href="./nips-2011-Predicting_Dynamic_Difficulty.html">218 nips-2011-Predicting Dynamic Difficulty</a></p>
<p>3 0.67743224 <a title="300-lsi-3" href="./nips-2011-On_Strategy_Stitching_in_Large_Extensive_Form_Multiplayer_Games.html">196 nips-2011-On Strategy Stitching in Large Extensive Form Multiplayer Games</a></p>
<p>4 0.62248725 <a title="300-lsi-4" href="./nips-2011-Monte_Carlo_Value_Iteration_with_Macro-Actions.html">174 nips-2011-Monte Carlo Value Iteration with Macro-Actions</a></p>
<p>5 0.6120829 <a title="300-lsi-5" href="./nips-2011-Reinforcement_Learning_using_Kernel-Based_Stochastic_Factorization.html">237 nips-2011-Reinforcement Learning using Kernel-Based Stochastic Factorization</a></p>
<p>6 0.59256315 <a title="300-lsi-6" href="./nips-2011-Solving_Decision_Problems_with_Limited_Information.html">256 nips-2011-Solving Decision Problems with Limited Information</a></p>
<p>7 0.58449394 <a title="300-lsi-7" href="./nips-2011-Budgeted_Optimization_with_Concurrent_Stochastic-Duration_Experiments.html">50 nips-2011-Budgeted Optimization with Concurrent Stochastic-Duration Experiments</a></p>
<p>8 0.58160025 <a title="300-lsi-8" href="./nips-2011-Inverting_Grice%27s_Maxims_to_Learn_Rules_from_Natural_Language_Extractions.html">136 nips-2011-Inverting Grice's Maxims to Learn Rules from Natural Language Extractions</a></p>
<p>9 0.54288769 <a title="300-lsi-9" href="./nips-2011-Policy_Gradient_Coagent_Networks.html">215 nips-2011-Policy Gradient Coagent Networks</a></p>
<p>10 0.53185248 <a title="300-lsi-10" href="./nips-2011-Analysis_and_Improvement_of_Policy_Gradient_Estimation.html">36 nips-2011-Analysis and Improvement of Policy Gradient Estimation</a></p>
<p>11 0.52913553 <a title="300-lsi-11" href="./nips-2011-A_reinterpretation_of_the_policy_oscillation_phenomenon_in_approximate_policy_iteration.html">16 nips-2011-A reinterpretation of the policy oscillation phenomenon in approximate policy iteration</a></p>
<p>12 0.52446997 <a title="300-lsi-12" href="./nips-2011-Periodic_Finite_State_Controllers_for_Efficient_POMDP_and_DEC-POMDP_Planning.html">212 nips-2011-Periodic Finite State Controllers for Efficient POMDP and DEC-POMDP Planning</a></p>
<p>13 0.50968534 <a title="300-lsi-13" href="./nips-2011-A_Non-Parametric_Approach_to_Dynamic_Programming.html">10 nips-2011-A Non-Parametric Approach to Dynamic Programming</a></p>
<p>14 0.4881041 <a title="300-lsi-14" href="./nips-2011-Optimal_Reinforcement_Learning_for_Gaussian_Systems.html">206 nips-2011-Optimal Reinforcement Learning for Gaussian Systems</a></p>
<p>15 0.47694322 <a title="300-lsi-15" href="./nips-2011-Efficient_Offline_Communication_Policies_for_Factored_Multiagent_POMDPs.html">79 nips-2011-Efficient Offline Communication Policies for Factored Multiagent POMDPs</a></p>
<p>16 0.43873113 <a title="300-lsi-16" href="./nips-2011-Action-Gap_Phenomenon_in_Reinforcement_Learning.html">18 nips-2011-Action-Gap Phenomenon in Reinforcement Learning</a></p>
<p>17 0.41484368 <a title="300-lsi-17" href="./nips-2011-Autonomous_Learning_of_Action_Models_for_Planning.html">41 nips-2011-Autonomous Learning of Action Models for Planning</a></p>
<p>18 0.40801671 <a title="300-lsi-18" href="./nips-2011-Anatomically_Constrained_Decoding_of_Finger_Flexion_from_Electrocorticographic_Signals.html">38 nips-2011-Anatomically Constrained Decoding of Finger Flexion from Electrocorticographic Signals</a></p>
<p>19 0.4017747 <a title="300-lsi-19" href="./nips-2011-Structure_Learning_for_Optimization.html">274 nips-2011-Structure Learning for Optimization</a></p>
<p>20 0.39230013 <a title="300-lsi-20" href="./nips-2011-On_the_Completeness_of_First-Order_Knowledge_Compilation_for_Lifted_Probabilistic_Inference.html">201 nips-2011-On the Completeness of First-Order Knowledge Compilation for Lifted Probabilistic Inference</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.025), (22, 0.015), (36, 0.019), (55, 0.703), (65, 0.043), (68, 0.095), (79, 0.01)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.9846496 <a title="300-lda-1" href="./nips-2011-Approximating_Semidefinite_Programs_in_Sublinear_Time.html">39 nips-2011-Approximating Semidefinite Programs in Sublinear Time</a></p>
<p>same-paper 2 0.97626454 <a title="300-lda-2" href="./nips-2011-Variance_Reduction_in_Monte-Carlo_Tree_Search.html">300 nips-2011-Variance Reduction in Monte-Carlo Tree Search</a></p>
<p>3 0.96880007 <a title="300-lda-3" href="./nips-2011-Predicting_Dynamic_Difficulty.html">218 nips-2011-Predicting Dynamic Difficulty</a></p>
<p>4 0.96443963 <a title="300-lda-4" href="./nips-2011-Complexity_of_Inference_in_Latent_Dirichlet_Allocation.html">58 nips-2011-Complexity of Inference in Latent Dirichlet Allocation</a></p>
<p>5 0.95647722 <a title="300-lda-5" href="./nips-2011-Policy_Gradient_Coagent_Networks.html">215 nips-2011-Policy Gradient Coagent Networks</a></p>
<p>6 0.94312125 <a title="300-lda-6" href="./nips-2011-An_Application_of_Tree-Structured_Expectation_Propagation_for_Channel_Decoding.html">31 nips-2011-An Application of Tree-Structured Expectation Propagation for Channel Decoding</a></p>
<p>7 0.92820501 <a title="300-lda-7" href="./nips-2011-A_Reinforcement_Learning_Theory_for_Homeostatic_Regulation.html">11 nips-2011-A Reinforcement Learning Theory for Homeostatic Regulation</a></p>
<p>8 0.92058396 <a title="300-lda-8" href="./nips-2011-Manifold_Precis%3A_An_Annealing_Technique_for_Diverse_Sampling_of_Manifolds.html">164 nips-2011-Manifold Precis: An Annealing Technique for Diverse Sampling of Manifolds</a></p>
<p>9 0.91755551 <a title="300-lda-9" href="./nips-2011-Analysis_and_Improvement_of_Policy_Gradient_Estimation.html">36 nips-2011-Analysis and Improvement of Policy Gradient Estimation</a></p>
<p>10 0.90232545 <a title="300-lda-10" href="./nips-2011-Portmanteau_Vocabularies_for_Multi-Cue_Image_Representation.html">216 nips-2011-Portmanteau Vocabularies for Multi-Cue Image Representation</a></p>
<p>11 0.8988483 <a title="300-lda-11" href="./nips-2011-TD_gamma%3A_Re-evaluating_Complex_Backups_in_Temporal_Difference_Learning.html">278 nips-2011-TD gamma: Re-evaluating Complex Backups in Temporal Difference Learning</a></p>
<p>12 0.8902272 <a title="300-lda-12" href="./nips-2011-Scalable_Training_of_Mixture_Models_via_Coresets.html">241 nips-2011-Scalable Training of Mixture Models via Coresets</a></p>
<p>13 0.88162518 <a title="300-lda-13" href="./nips-2011-Periodic_Finite_State_Controllers_for_Efficient_POMDP_and_DEC-POMDP_Planning.html">212 nips-2011-Periodic Finite State Controllers for Efficient POMDP and DEC-POMDP Planning</a></p>
<p>14 0.88017863 <a title="300-lda-14" href="./nips-2011-Fast_and_Accurate_k-means_For_Large_Datasets.html">95 nips-2011-Fast and Accurate k-means For Large Datasets</a></p>
<p>15 0.87381989 <a title="300-lda-15" href="./nips-2011-MAP_Inference_for_Bayesian_Inverse_Reinforcement_Learning.html">163 nips-2011-MAP Inference for Bayesian Inverse Reinforcement Learning</a></p>
<p>16 0.86907017 <a title="300-lda-16" href="./nips-2011-Message-Passing_for_Approximate_MAP_Inference_with_Latent_Variables.html">170 nips-2011-Message-Passing for Approximate MAP Inference with Latent Variables</a></p>
<p>17 0.8607282 <a title="300-lda-17" href="./nips-2011-The_Fixed_Points_of_Off-Policy_TD.html">283 nips-2011-The Fixed Points of Off-Policy TD</a></p>
<p>18 0.85710073 <a title="300-lda-18" href="./nips-2011-Randomized_Algorithms_for_Comparison-based_Search.html">231 nips-2011-Randomized Algorithms for Comparison-based Search</a></p>
<p>19 0.85469449 <a title="300-lda-19" href="./nips-2011-Monte_Carlo_Value_Iteration_with_Macro-Actions.html">174 nips-2011-Monte Carlo Value Iteration with Macro-Actions</a></p>
<p>20 0.8508383 <a title="300-lda-20" href="./nips-2011-Beating_SGD%3A_Learning_SVMs_in_Sublinear_Time.html">45 nips-2011-Beating SGD: Learning SVMs in Sublinear Time</a></p>
<br/><br/><br/></body>
</html>
