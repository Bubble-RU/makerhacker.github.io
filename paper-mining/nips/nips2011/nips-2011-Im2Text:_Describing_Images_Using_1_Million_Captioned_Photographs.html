<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>126 nips-2011-Im2Text: Describing Images Using 1 Million Captioned Photographs</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-126" href="#">nips2011-126</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>126 nips-2011-Im2Text: Describing Images Using 1 Million Captioned Photographs</h1>
<br/><p>Source: <a title="nips-2011-126-pdf" href="http://papers.nips.cc/paper/4470-im2text-describing-images-using-1-million-captioned-photographs.pdf">pdf</a></p><p>Author: Vicente Ordonez, Girish Kulkarni, Tamara L. Berg</p><p>Abstract: We develop and demonstrate automatic image description methods using a large captioned photo collection. One contribution is our technique for the automatic collection of this new dataset – performing a huge number of Flickr queries and then ﬁltering the noisy results down to 1 million images with associated visually relevant captions. Such a collection allows us to approach the extremely challenging problem of description generation using relatively simple non-parametric methods and produces surprisingly effective results. We also develop methods incorporating many state of the art, but fairly noisy, estimates of image content to produce even more pleasing results. Finally we introduce a new objective performance measure for image captioning. 1</p><p>Reference: <a title="nips-2011-126-reference" href="../nips2011_reference/nips-2011-Im2Text%3A_Describing_Images_Using_1_Million_Captioned_Photographs_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('im', 0.427), ('query', 0.31), ('stuff', 0.271), ('capt', 0.246), ('bleu', 0.192), ('photo', 0.191), ('match', 0.183), ('detect', 0.177), ('scen', 0.165), ('photograph', 0.163), ('dog', 0.139), ('attribut', 0.131), ('sec', 0.128), ('cont', 0.124), ('peopl', 0.12), ('pict', 0.109), ('df', 0.101), ('sky', 0.088), ('docu', 0.088), ('flickr', 0.087)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="126-tfidf-1" href="./nips-2011-Im2Text%3A_Describing_Images_Using_1_Million_Captioned_Photographs.html">126 nips-2011-Im2Text: Describing Images Using 1 Million Captioned Photographs</a></p>
<p>2 0.3148227 <a title="126-tfidf-2" href="./nips-2011-Understanding_the_Intrinsic_Memorability_of_Images.html">293 nips-2011-Understanding the Intrinsic Memorability of Images</a></p>
<p>3 0.24111673 <a title="126-tfidf-3" href="./nips-2011-Learning_person-object_interactions_for_action_recognition_in_still_images.html">154 nips-2011-Learning person-object interactions for action recognition in still images</a></p>
<p>4 0.230561 <a title="126-tfidf-4" href="./nips-2011-%24%5Ctheta%24-MRF%3A_Capturing_Spatial_and_Semantic_Structure_in_the_Parameters_for_Scene_Understanding.html">1 nips-2011-$\theta$-MRF: Capturing Spatial and Semantic Structure in the Parameters for Scene Understanding</a></p>
<p>5 0.21640463 <a title="126-tfidf-5" href="./nips-2011-Active_Ranking_using_Pairwise_Comparisons.html">22 nips-2011-Active Ranking using Pairwise Comparisons</a></p>
<p>6 0.19507551 <a title="126-tfidf-6" href="./nips-2011-Large-Scale_Category_Structure_Aware_Image_Categorization.html">141 nips-2011-Large-Scale Category Structure Aware Image Categorization</a></p>
<p>7 0.1891167 <a title="126-tfidf-7" href="./nips-2011-Query-Aware_MCMC.html">229 nips-2011-Query-Aware MCMC</a></p>
<p>8 0.18631043 <a title="126-tfidf-8" href="./nips-2011-PiCoDes%3A_Learning_a_Compact_Code_for_Novel-Category_Recognition.html">214 nips-2011-PiCoDes: Learning a Compact Code for Novel-Category Recognition</a></p>
<p>9 0.17902373 <a title="126-tfidf-9" href="./nips-2011-Testing_a_Bayesian_Measure_of_Representativeness_Using_a_Large_Image_Database.html">280 nips-2011-Testing a Bayesian Measure of Representativeness Using a Large Image Database</a></p>
<p>10 0.16592582 <a title="126-tfidf-10" href="./nips-2011-Maximum_Margin_Multi-Instance_Learning.html">168 nips-2011-Maximum Margin Multi-Instance Learning</a></p>
<p>11 0.16542204 <a title="126-tfidf-11" href="./nips-2011-An_ideal_observer_model_for_identifying_the_reference_frame_of_objects.html">35 nips-2011-An ideal observer model for identifying the reference frame of objects</a></p>
<p>12 0.16265666 <a title="126-tfidf-12" href="./nips-2011-Randomized_Algorithms_for_Comparison-based_Search.html">231 nips-2011-Randomized Algorithms for Comparison-based Search</a></p>
<p>13 0.1586909 <a title="126-tfidf-13" href="./nips-2011-Semantic_Labeling_of_3D_Point_Clouds_for_Indoor_Scenes.html">247 nips-2011-Semantic Labeling of 3D Point Clouds for Indoor Scenes</a></p>
<p>14 0.15543491 <a title="126-tfidf-14" href="./nips-2011-Image_Parsing_with_Stochastic_Scene_Grammar.html">127 nips-2011-Image Parsing with Stochastic Scene Grammar</a></p>
<p>15 0.15251511 <a title="126-tfidf-15" href="./nips-2011-Recovering_Intrinsic_Images_with_a_Global_Sparsity_Prior_on_Reflectance.html">235 nips-2011-Recovering Intrinsic Images with a Global Sparsity Prior on Reflectance</a></p>
<p>16 0.14731357 <a title="126-tfidf-16" href="./nips-2011-Joint_3D_Estimation_of_Objects_and_Scene_Layout.html">138 nips-2011-Joint 3D Estimation of Objects and Scene Layout</a></p>
<p>17 0.13491578 <a title="126-tfidf-17" href="./nips-2011-Matrix_Completion_for_Multi-label_Image_Classification.html">165 nips-2011-Matrix Completion for Multi-label Image Classification</a></p>
<p>18 0.13344596 <a title="126-tfidf-18" href="./nips-2011-Object_Detection_with_Grammar_Models.html">193 nips-2011-Object Detection with Grammar Models</a></p>
<p>19 0.12768307 <a title="126-tfidf-19" href="./nips-2011-Heavy-tailed_Distances_for_Gradient_Based_Image_Descriptors.html">112 nips-2011-Heavy-tailed Distances for Gradient Based Image Descriptors</a></p>
<p>20 0.12700494 <a title="126-tfidf-20" href="./nips-2011-Maximal_Cliques_that_Satisfy_Hard_Constraints_with_Application_to_Deformable_Object_Model_Learning.html">166 nips-2011-Maximal Cliques that Satisfy Hard Constraints with Application to Deformable Object Model Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.262), (1, 0.015), (2, 0.255), (3, -0.233), (4, -0.24), (5, 0.085), (6, -0.015), (7, -0.024), (8, 0.03), (9, 0.202), (10, -0.131), (11, -0.064), (12, 0.105), (13, 0.025), (14, -0.123), (15, -0.003), (16, -0.077), (17, 0.026), (18, 0.102), (19, 0.06), (20, -0.077), (21, -0.081), (22, 0.114), (23, -0.086), (24, 0.056), (25, -0.048), (26, 0.046), (27, 0.052), (28, -0.05), (29, -0.055), (30, -0.052), (31, -0.04), (32, 0.027), (33, -0.013), (34, 0.015), (35, 0.014), (36, -0.022), (37, -0.033), (38, 0.051), (39, -0.048), (40, 0.07), (41, -0.051), (42, -0.061), (43, -0.049), (44, -0.124), (45, -0.044), (46, 0.015), (47, -0.013), (48, -0.014), (49, 0.036)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97427505 <a title="126-lsi-1" href="./nips-2011-Im2Text%3A_Describing_Images_Using_1_Million_Captioned_Photographs.html">126 nips-2011-Im2Text: Describing Images Using 1 Million Captioned Photographs</a></p>
<p>2 0.77899271 <a title="126-lsi-2" href="./nips-2011-Learning_person-object_interactions_for_action_recognition_in_still_images.html">154 nips-2011-Learning person-object interactions for action recognition in still images</a></p>
<p>3 0.75353533 <a title="126-lsi-3" href="./nips-2011-Understanding_the_Intrinsic_Memorability_of_Images.html">293 nips-2011-Understanding the Intrinsic Memorability of Images</a></p>
<p>4 0.71854931 <a title="126-lsi-4" href="./nips-2011-%24%5Ctheta%24-MRF%3A_Capturing_Spatial_and_Semantic_Structure_in_the_Parameters_for_Scene_Understanding.html">1 nips-2011-$\theta$-MRF: Capturing Spatial and Semantic Structure in the Parameters for Scene Understanding</a></p>
<p>5 0.71495688 <a title="126-lsi-5" href="./nips-2011-Portmanteau_Vocabularies_for_Multi-Cue_Image_Representation.html">216 nips-2011-Portmanteau Vocabularies for Multi-Cue Image Representation</a></p>
<p>6 0.71420503 <a title="126-lsi-6" href="./nips-2011-Joint_3D_Estimation_of_Objects_and_Scene_Layout.html">138 nips-2011-Joint 3D Estimation of Objects and Scene Layout</a></p>
<p>7 0.71090001 <a title="126-lsi-7" href="./nips-2011-PiCoDes%3A_Learning_a_Compact_Code_for_Novel-Category_Recognition.html">214 nips-2011-PiCoDes: Learning a Compact Code for Novel-Category Recognition</a></p>
<p>8 0.70313096 <a title="126-lsi-8" href="./nips-2011-Recovering_Intrinsic_Images_with_a_Global_Sparsity_Prior_on_Reflectance.html">235 nips-2011-Recovering Intrinsic Images with a Global Sparsity Prior on Reflectance</a></p>
<p>9 0.68745148 <a title="126-lsi-9" href="./nips-2011-Maximal_Cliques_that_Satisfy_Hard_Constraints_with_Application_to_Deformable_Object_Model_Learning.html">166 nips-2011-Maximal Cliques that Satisfy Hard Constraints with Application to Deformable Object Model Learning</a></p>
<p>10 0.66004777 <a title="126-lsi-10" href="./nips-2011-Transfer_Learning_by_Borrowing_Examples_for_Multiclass_Object_Detection.html">290 nips-2011-Transfer Learning by Borrowing Examples for Multiclass Object Detection</a></p>
<p>11 0.6532957 <a title="126-lsi-11" href="./nips-2011-Why_The_Brain_Separates_Face_Recognition_From_Object_Recognition.html">304 nips-2011-Why The Brain Separates Face Recognition From Object Recognition</a></p>
<p>12 0.64810759 <a title="126-lsi-12" href="./nips-2011-Large-Scale_Category_Structure_Aware_Image_Categorization.html">141 nips-2011-Large-Scale Category Structure Aware Image Categorization</a></p>
<p>13 0.63212508 <a title="126-lsi-13" href="./nips-2011-An_ideal_observer_model_for_identifying_the_reference_frame_of_objects.html">35 nips-2011-An ideal observer model for identifying the reference frame of objects</a></p>
<p>14 0.62077016 <a title="126-lsi-14" href="./nips-2011-Testing_a_Bayesian_Measure_of_Representativeness_Using_a_Large_Image_Database.html">280 nips-2011-Testing a Bayesian Measure of Representativeness Using a Large Image Database</a></p>
<p>15 0.59745044 <a title="126-lsi-15" href="./nips-2011-Object_Detection_with_Grammar_Models.html">193 nips-2011-Object Detection with Grammar Models</a></p>
<p>16 0.58633447 <a title="126-lsi-16" href="./nips-2011-Image_Parsing_with_Stochastic_Scene_Grammar.html">127 nips-2011-Image Parsing with Stochastic Scene Grammar</a></p>
<p>17 0.58073103 <a title="126-lsi-17" href="./nips-2011-Maximum_Margin_Multi-Instance_Learning.html">168 nips-2011-Maximum Margin Multi-Instance Learning</a></p>
<p>18 0.57231301 <a title="126-lsi-18" href="./nips-2011-Heavy-tailed_Distances_for_Gradient_Based_Image_Descriptors.html">112 nips-2011-Heavy-tailed Distances for Gradient Based Image Descriptors</a></p>
<p>19 0.56515175 <a title="126-lsi-19" href="./nips-2011-Randomized_Algorithms_for_Comparison-based_Search.html">231 nips-2011-Randomized Algorithms for Comparison-based Search</a></p>
<p>20 0.55016994 <a title="126-lsi-20" href="./nips-2011-Matrix_Completion_for_Multi-label_Image_Classification.html">165 nips-2011-Matrix Completion for Multi-label Image Classification</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.037), (22, 0.035), (28, 0.267), (36, 0.112), (55, 0.126), (64, 0.012), (65, 0.065), (68, 0.219), (79, 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.83753014 <a title="126-lda-1" href="./nips-2011-High-Dimensional_Graphical_Model_Selection%3A_Tractable_Graph_Families_and_Necessary_Conditions.html">117 nips-2011-High-Dimensional Graphical Model Selection: Tractable Graph Families and Necessary Conditions</a></p>
<p>2 0.83626789 <a title="126-lda-2" href="./nips-2011-Efficient_anomaly_detection_using_bipartite_k-NN_graphs.html">81 nips-2011-Efficient anomaly detection using bipartite k-NN graphs</a></p>
<p>same-paper 3 0.82580543 <a title="126-lda-3" href="./nips-2011-Im2Text%3A_Describing_Images_Using_1_Million_Captioned_Photographs.html">126 nips-2011-Im2Text: Describing Images Using 1 Million Captioned Photographs</a></p>
<p>4 0.80657041 <a title="126-lda-4" href="./nips-2011-Neural_Reconstruction_with_Approximate_Message_Passing_%28NeuRAMP%29.html">183 nips-2011-Neural Reconstruction with Approximate Message Passing (NeuRAMP)</a></p>
<p>5 0.78154135 <a title="126-lda-5" href="./nips-2011-Message-Passing_for_Approximate_MAP_Inference_with_Latent_Variables.html">170 nips-2011-Message-Passing for Approximate MAP Inference with Latent Variables</a></p>
<p>6 0.73128259 <a title="126-lda-6" href="./nips-2011-Kernel_Embeddings_of_Latent_Tree_Graphical_Models.html">140 nips-2011-Kernel Embeddings of Latent Tree Graphical Models</a></p>
<p>7 0.72969091 <a title="126-lda-7" href="./nips-2011-Similarity-based_Learning_via_Data_Driven_Embeddings.html">254 nips-2011-Similarity-based Learning via Data Driven Embeddings</a></p>
<p>8 0.72648764 <a title="126-lda-8" href="./nips-2011-On_the_Universality_of_Online_Mirror_Descent.html">202 nips-2011-On the Universality of Online Mirror Descent</a></p>
<p>9 0.72459757 <a title="126-lda-9" href="./nips-2011-%24%5Ctheta%24-MRF%3A_Capturing_Spatial_and_Semantic_Structure_in_the_Parameters_for_Scene_Understanding.html">1 nips-2011-$\theta$-MRF: Capturing Spatial and Semantic Structure in the Parameters for Scene Understanding</a></p>
<p>10 0.7230742 <a title="126-lda-10" href="./nips-2011-Understanding_the_Intrinsic_Memorability_of_Images.html">293 nips-2011-Understanding the Intrinsic Memorability of Images</a></p>
<p>11 0.72227514 <a title="126-lda-11" href="./nips-2011-Learning_person-object_interactions_for_action_recognition_in_still_images.html">154 nips-2011-Learning person-object interactions for action recognition in still images</a></p>
<p>12 0.72156006 <a title="126-lda-12" href="./nips-2011-Joint_3D_Estimation_of_Objects_and_Scene_Layout.html">138 nips-2011-Joint 3D Estimation of Objects and Scene Layout</a></p>
<p>13 0.71981609 <a title="126-lda-13" href="./nips-2011-Large-Scale_Category_Structure_Aware_Image_Categorization.html">141 nips-2011-Large-Scale Category Structure Aware Image Categorization</a></p>
<p>14 0.71796817 <a title="126-lda-14" href="./nips-2011-On_U-processes_and_clustering_performance.html">198 nips-2011-On U-processes and clustering performance</a></p>
<p>15 0.71556354 <a title="126-lda-15" href="./nips-2011-Probabilistic_Joint_Image_Segmentation_and_Labeling.html">223 nips-2011-Probabilistic Joint Image Segmentation and Labeling</a></p>
<p>16 0.71503162 <a title="126-lda-16" href="./nips-2011-Pylon_Model_for_Semantic_Segmentation.html">227 nips-2011-Pylon Model for Semantic Segmentation</a></p>
<p>17 0.71500111 <a title="126-lda-17" href="./nips-2011-Inductive_reasoning_about_chimeric_creatures.html">130 nips-2011-Inductive reasoning about chimeric creatures</a></p>
<p>18 0.71480548 <a title="126-lda-18" href="./nips-2011-Learning_a_Tree_of_Metrics_with_Disjoint_Visual_Features.html">151 nips-2011-Learning a Tree of Metrics with Disjoint Visual Features</a></p>
<p>19 0.71374893 <a title="126-lda-19" href="./nips-2011-Efficient_Inference_in_Fully_Connected_CRFs_with_Gaussian_Edge_Potentials.html">76 nips-2011-Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials</a></p>
<p>20 0.71266389 <a title="126-lda-20" href="./nips-2011-Active_Ranking_using_Pairwise_Comparisons.html">22 nips-2011-Active Ranking using Pairwise Comparisons</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
