<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>145 nips-2011-Learning Eigenvectors for Free</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-145" href="#">nips2011-145</a> knowledge-graph by maker-knowledge-mining</p><h1>145 nips-2011-Learning Eigenvectors for Free</h1>
<br/><p>Source: <a title="nips-2011-145-pdf" href="http://papers.nips.cc/paper/4377-learning-eigenvectors-for-free.pdf">pdf</a></p><p>Author: Wouter M. Koolen, Wojciech Kotlowski, Manfred K. Warmuth</p><p>Abstract: We extend the classical problem of predicting a sequence of outcomes from a Ô¨Ånite alphabet to the matrix domain. In this extension, the alphabet of n outcomes is replaced by the set of all dyads, i.e. outer products uu where u is a vector in Rn of unit length. Whereas in the classical case the goal is to learn (i.e. sequentially predict as well as) the best multinomial distribution, in the matrix case we desire to learn the density matrix that best explains the observed sequence of dyads. We show how popular online algorithms for learning a multinomial distribution can be extended to learn density matrices. Intuitively, learning the n2 parameters of a density matrix is much harder than learning the n parameters of a multinomial distribution. Completely surprisingly, we prove that the worst-case regrets of certain classical algorithms and their matrix generalizations are identical. The reason is that the worst-case sequence of dyads share a common eigensystem, i.e. the worst case regret is achieved in the classical case. So these matrix algorithms learn the eigenvectors without any regret. 1</p><p>Reference: <a title="nips-2011-145-reference" href="../nips2011_reference/nips-2011-Learning_Eigenvectors_for_Free_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('xt', 0.333), ('regret', 0.3), ('lsm', 0.259), ('dyad', 0.259), ('st', 0.241), ('eigensystem', 0.24), ('wt', 0.224), ('tr', 0.209), ('shtarkov', 0.203), ('fml', 0.195), ('lunch', 0.195), ('si', 0.182), ('minimax', 0.181), ('outcom', 0.166), ('matrix', 0.164), ('kt', 0.136), ('ep', 0.121), ('dens', 0.118), ('laplac', 0.11), ('ai', 0.107)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="145-tfidf-1" href="./nips-2011-Learning_Eigenvectors_for_Free.html">145 nips-2011-Learning Eigenvectors for Free</a></p>
<p>2 0.34292224 <a title="145-tfidf-2" href="./nips-2011-Prediction_strategies_without_loss.html">220 nips-2011-Prediction strategies without loss</a></p>
<p>3 0.26814389 <a title="145-tfidf-3" href="./nips-2011-Approximating_Semidefinite_Programs_in_Sublinear_Time.html">39 nips-2011-Approximating Semidefinite Programs in Sublinear Time</a></p>
<p>4 0.25490546 <a title="145-tfidf-4" href="./nips-2011-Online_Learning%3A_Stochastic%2C_Constrained%2C_and_Smoothed_Adversaries.html">204 nips-2011-Online Learning: Stochastic, Constrained, and Smoothed Adversaries</a></p>
<p>5 0.23125933 <a title="145-tfidf-5" href="./nips-2011-Newtron%3A_an_Efficient_Bandit_algorithm_for_Online_Multiclass_Prediction.html">185 nips-2011-Newtron: an Efficient Bandit algorithm for Online Multiclass Prediction</a></p>
<p>6 0.23116286 <a title="145-tfidf-6" href="./nips-2011-Improved_Algorithms_for_Linear_Stochastic_Bandits.html">128 nips-2011-Improved Algorithms for Linear Stochastic Bandits</a></p>
<p>7 0.19505124 <a title="145-tfidf-7" href="./nips-2011-Sparse_Inverse_Covariance_Matrix_Estimation_Using_Quadratic_Approximation.html">262 nips-2011-Sparse Inverse Covariance Matrix Estimation Using Quadratic Approximation</a></p>
<p>8 0.18952399 <a title="145-tfidf-8" href="./nips-2011-Efficient_Online_Learning_via_Randomized_Rounding.html">80 nips-2011-Efficient Online Learning via Randomized Rounding</a></p>
<p>9 0.17406425 <a title="145-tfidf-9" href="./nips-2011-PAC-Bayesian_Analysis_of_Contextual_Bandits.html">210 nips-2011-PAC-Bayesian Analysis of Contextual Bandits</a></p>
<p>10 0.16613063 <a title="145-tfidf-10" href="./nips-2011-Selecting_the_State-Representation_in_Reinforcement_Learning.html">245 nips-2011-Selecting the State-Representation in Reinforcement Learning</a></p>
<p>11 0.16385832 <a title="145-tfidf-11" href="./nips-2011-Adaptive_Hedge.html">25 nips-2011-Adaptive Hedge</a></p>
<p>12 0.13068816 <a title="145-tfidf-12" href="./nips-2011-Contextual_Gaussian_Process_Bandit_Optimization.html">61 nips-2011-Contextual Gaussian Process Bandit Optimization</a></p>
<p>13 0.11856448 <a title="145-tfidf-13" href="./nips-2011-Online_Submodular_Set_Cover%2C_Ranking%2C_and_Repeated_Active_Learning.html">205 nips-2011-Online Submodular Set Cover, Ranking, and Repeated Active Learning</a></p>
<p>14 0.11802603 <a title="145-tfidf-14" href="./nips-2011-Lower_Bounds_for_Passive_and_Active_Learning.html">162 nips-2011-Lower Bounds for Passive and Active Learning</a></p>
<p>15 0.11088953 <a title="145-tfidf-15" href="./nips-2011-From_Bandits_to_Experts%3A_On_the_Value_of_Side-Observations.html">98 nips-2011-From Bandits to Experts: On the Value of Side-Observations</a></p>
<p>16 0.10903583 <a title="145-tfidf-16" href="./nips-2011-Stochastic_convex_optimization_with_bandit_feedback.html">272 nips-2011-Stochastic convex optimization with bandit feedback</a></p>
<p>17 0.10493159 <a title="145-tfidf-17" href="./nips-2011-An_Empirical_Evaluation_of_Thompson_Sampling.html">32 nips-2011-An Empirical Evaluation of Thompson Sampling</a></p>
<p>18 0.099559523 <a title="145-tfidf-18" href="./nips-2011-On_the_Universality_of_Online_Mirror_Descent.html">202 nips-2011-On the Universality of Online Mirror Descent</a></p>
<p>19 0.09850847 <a title="145-tfidf-19" href="./nips-2011-Variance_Reduction_in_Monte-Carlo_Tree_Search.html">300 nips-2011-Variance Reduction in Monte-Carlo Tree Search</a></p>
<p>20 0.098427802 <a title="145-tfidf-20" href="./nips-2011-Predicting_Dynamic_Difficulty.html">218 nips-2011-Predicting Dynamic Difficulty</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.245), (1, -0.224), (2, -0.217), (3, 0.182), (4, -0.14), (5, 0.059), (6, -0.102), (7, 0.055), (8, 0.145), (9, -0.15), (10, -0.131), (11, 0.053), (12, 0.071), (13, -0.012), (14, -0.041), (15, -0.007), (16, -0.065), (17, -0.005), (18, -0.009), (19, 0.011), (20, -0.056), (21, 0.051), (22, -0.028), (23, -0.076), (24, -0.052), (25, -0.014), (26, -0.014), (27, 0.045), (28, 0.046), (29, 0.028), (30, -0.005), (31, -0.023), (32, -0.028), (33, 0.026), (34, 0.066), (35, -0.016), (36, -0.02), (37, 0.039), (38, -0.024), (39, -0.053), (40, 0.006), (41, -0.014), (42, -0.045), (43, 0.011), (44, 0.026), (45, -0.06), (46, -0.052), (47, 0.097), (48, 0.075), (49, 0.04)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94283658 <a title="145-lsi-1" href="./nips-2011-Learning_Eigenvectors_for_Free.html">145 nips-2011-Learning Eigenvectors for Free</a></p>
<p>2 0.89266211 <a title="145-lsi-2" href="./nips-2011-Newtron%3A_an_Efficient_Bandit_algorithm_for_Online_Multiclass_Prediction.html">185 nips-2011-Newtron: an Efficient Bandit algorithm for Online Multiclass Prediction</a></p>
<p>3 0.86592215 <a title="145-lsi-3" href="./nips-2011-Prediction_strategies_without_loss.html">220 nips-2011-Prediction strategies without loss</a></p>
<p>4 0.78719521 <a title="145-lsi-4" href="./nips-2011-Online_Learning%3A_Stochastic%2C_Constrained%2C_and_Smoothed_Adversaries.html">204 nips-2011-Online Learning: Stochastic, Constrained, and Smoothed Adversaries</a></p>
<p>5 0.77126896 <a title="145-lsi-5" href="./nips-2011-Approximating_Semidefinite_Programs_in_Sublinear_Time.html">39 nips-2011-Approximating Semidefinite Programs in Sublinear Time</a></p>
<p>6 0.76428854 <a title="145-lsi-6" href="./nips-2011-Efficient_Online_Learning_via_Randomized_Rounding.html">80 nips-2011-Efficient Online Learning via Randomized Rounding</a></p>
<p>7 0.7012707 <a title="145-lsi-7" href="./nips-2011-Improved_Algorithms_for_Linear_Stochastic_Bandits.html">128 nips-2011-Improved Algorithms for Linear Stochastic Bandits</a></p>
<p>8 0.59860015 <a title="145-lsi-8" href="./nips-2011-Adaptive_Hedge.html">25 nips-2011-Adaptive Hedge</a></p>
<p>9 0.58217484 <a title="145-lsi-9" href="./nips-2011-Sparse_Inverse_Covariance_Matrix_Estimation_Using_Quadratic_Approximation.html">262 nips-2011-Sparse Inverse Covariance Matrix Estimation Using Quadratic Approximation</a></p>
<p>10 0.58189708 <a title="145-lsi-10" href="./nips-2011-PAC-Bayesian_Analysis_of_Contextual_Bandits.html">210 nips-2011-PAC-Bayesian Analysis of Contextual Bandits</a></p>
<p>11 0.58142745 <a title="145-lsi-11" href="./nips-2011-Active_Learning_with_a_Drifting_Distribution.html">21 nips-2011-Active Learning with a Drifting Distribution</a></p>
<p>12 0.57261711 <a title="145-lsi-12" href="./nips-2011-Stochastic_convex_optimization_with_bandit_feedback.html">272 nips-2011-Stochastic convex optimization with bandit feedback</a></p>
<p>13 0.52643591 <a title="145-lsi-13" href="./nips-2011-Contextual_Gaussian_Process_Bandit_Optimization.html">61 nips-2011-Contextual Gaussian Process Bandit Optimization</a></p>
<p>14 0.51900196 <a title="145-lsi-14" href="./nips-2011-Lower_Bounds_for_Passive_and_Active_Learning.html">162 nips-2011-Lower Bounds for Passive and Active Learning</a></p>
<p>15 0.49482366 <a title="145-lsi-15" href="./nips-2011-Selecting_the_State-Representation_in_Reinforcement_Learning.html">245 nips-2011-Selecting the State-Representation in Reinforcement Learning</a></p>
<p>16 0.47222194 <a title="145-lsi-16" href="./nips-2011-An_Empirical_Evaluation_of_Thompson_Sampling.html">32 nips-2011-An Empirical Evaluation of Thompson Sampling</a></p>
<p>17 0.45742247 <a title="145-lsi-17" href="./nips-2011-Beating_SGD%3A_Learning_SVMs_in_Sublinear_Time.html">45 nips-2011-Beating SGD: Learning SVMs in Sublinear Time</a></p>
<p>18 0.45534596 <a title="145-lsi-18" href="./nips-2011-From_Bandits_to_Experts%3A_On_the_Value_of_Side-Observations.html">98 nips-2011-From Bandits to Experts: On the Value of Side-Observations</a></p>
<p>19 0.43456987 <a title="145-lsi-19" href="./nips-2011-On_the_Universality_of_Online_Mirror_Descent.html">202 nips-2011-On the Universality of Online Mirror Descent</a></p>
<p>20 0.42928666 <a title="145-lsi-20" href="./nips-2011-Learning_Auto-regressive_Models_from_Sequence_and_Non-sequence_Data.html">144 nips-2011-Learning Auto-regressive Models from Sequence and Non-sequence Data</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.069), (22, 0.035), (36, 0.031), (55, 0.293), (65, 0.049), (68, 0.173), (69, 0.228)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.88026386 <a title="145-lda-1" href="./nips-2011-Learning_Eigenvectors_for_Free.html">145 nips-2011-Learning Eigenvectors for Free</a></p>
<p>2 0.83829296 <a title="145-lda-2" href="./nips-2011-Improved_Algorithms_for_Linear_Stochastic_Bandits.html">128 nips-2011-Improved Algorithms for Linear Stochastic Bandits</a></p>
<p>3 0.83724308 <a title="145-lda-3" href="./nips-2011-Committing_Bandits.html">56 nips-2011-Committing Bandits</a></p>
<p>4 0.83668202 <a title="145-lda-4" href="./nips-2011-A_Reinforcement_Learning_Theory_for_Homeostatic_Regulation.html">11 nips-2011-A Reinforcement Learning Theory for Homeostatic Regulation</a></p>
<p>5 0.83507854 <a title="145-lda-5" href="./nips-2011-Portmanteau_Vocabularies_for_Multi-Cue_Image_Representation.html">216 nips-2011-Portmanteau Vocabularies for Multi-Cue Image Representation</a></p>
<p>6 0.8340705 <a title="145-lda-6" href="./nips-2011-Manifold_Precis%3A_An_Annealing_Technique_for_Diverse_Sampling_of_Manifolds.html">164 nips-2011-Manifold Precis: An Annealing Technique for Diverse Sampling of Manifolds</a></p>
<p>7 0.83387065 <a title="145-lda-7" href="./nips-2011-Scalable_Training_of_Mixture_Models_via_Coresets.html">241 nips-2011-Scalable Training of Mixture Models via Coresets</a></p>
<p>8 0.83149397 <a title="145-lda-8" href="./nips-2011-Analysis_and_Improvement_of_Policy_Gradient_Estimation.html">36 nips-2011-Analysis and Improvement of Policy Gradient Estimation</a></p>
<p>9 0.8312391 <a title="145-lda-9" href="./nips-2011-An_Application_of_Tree-Structured_Expectation_Propagation_for_Channel_Decoding.html">31 nips-2011-An Application of Tree-Structured Expectation Propagation for Channel Decoding</a></p>
<p>10 0.83105326 <a title="145-lda-10" href="./nips-2011-The_Fixed_Points_of_Off-Policy_TD.html">283 nips-2011-The Fixed Points of Off-Policy TD</a></p>
<p>11 0.82848376 <a title="145-lda-11" href="./nips-2011-TD_gamma%3A_Re-evaluating_Complex_Backups_in_Temporal_Difference_Learning.html">278 nips-2011-TD gamma: Re-evaluating Complex Backups in Temporal Difference Learning</a></p>
<p>12 0.82799655 <a title="145-lda-12" href="./nips-2011-Randomized_Algorithms_for_Comparison-based_Search.html">231 nips-2011-Randomized Algorithms for Comparison-based Search</a></p>
<p>13 0.8262881 <a title="145-lda-13" href="./nips-2011-Policy_Gradient_Coagent_Networks.html">215 nips-2011-Policy Gradient Coagent Networks</a></p>
<p>14 0.82551408 <a title="145-lda-14" href="./nips-2011-Beating_SGD%3A_Learning_SVMs_in_Sublinear_Time.html">45 nips-2011-Beating SGD: Learning SVMs in Sublinear Time</a></p>
<p>15 0.82254618 <a title="145-lda-15" href="./nips-2011-Optimistic_Optimization_of_a_Deterministic_Function_without_the_Knowledge_of_its_Smoothness.html">208 nips-2011-Optimistic Optimization of a Deterministic Function without the Knowledge of its Smoothness</a></p>
<p>16 0.82248223 <a title="145-lda-16" href="./nips-2011-MAP_Inference_for_Bayesian_Inverse_Reinforcement_Learning.html">163 nips-2011-MAP Inference for Bayesian Inverse Reinforcement Learning</a></p>
<p>17 0.82124817 <a title="145-lda-17" href="./nips-2011-Complexity_of_Inference_in_Latent_Dirichlet_Allocation.html">58 nips-2011-Complexity of Inference in Latent Dirichlet Allocation</a></p>
<p>18 0.82109159 <a title="145-lda-18" href="./nips-2011-Predicting_Dynamic_Difficulty.html">218 nips-2011-Predicting Dynamic Difficulty</a></p>
<p>19 0.82006121 <a title="145-lda-19" href="./nips-2011-Fast_and_Accurate_k-means_For_Large_Datasets.html">95 nips-2011-Fast and Accurate k-means For Large Datasets</a></p>
<p>20 0.81950319 <a title="145-lda-20" href="./nips-2011-On_Tracking_The_Partition_Function.html">197 nips-2011-On Tracking The Partition Function</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
