<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>295 nips-2011-Unifying Non-Maximum Likelihood Learning Objectives with Minimum KL Contraction</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-295" href="#">nips2011-295</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>295 nips-2011-Unifying Non-Maximum Likelihood Learning Objectives with Minimum KL Contraction</h1>
<br/><p>Source: <a title="nips-2011-295-pdf" href="http://papers.nips.cc/paper/4456-unifying-non-maximum-likelihood-learning-objectives-with-minimum-kl-contraction.pdf">pdf</a></p><p>Author: Siwei Lyu</p><p>Abstract: When used to learn high dimensional parametric probabilistic models, the classical maximum likelihood (ML) learning often suffers from computational intractability, which motivates the active developments of non-ML learning methods. Yet, because of their divergent motivations and forms, the objective functions of many non-ML learning methods are seemingly unrelated, and there lacks a uniﬁed framework to understand them. In this work, based on an information geometric view of parametric learning, we introduce a general non-ML learning principle termed as minimum KL contraction, where we seek optimal parameters that minimizes the contraction of the KL divergence between the two distributions after they are transformed with a KL contraction operator. We then show that the objective functions of several important or recently developed non-ML learning methods, including contrastive divergence [12], noise-contrastive estimation [11], partial likelihood [7], non-local contrastive objectives [31], score matching [14], pseudo-likelihood [3], maximum conditional likelihood [17], maximum mutual information [2], maximum marginal likelihood [9], and conditional and marginal composite likelihood [24], can be uniﬁed under the minimum KL contraction framework with different choices of the KL contraction operators. 1</p><p>Reference: <a title="nips-2011-295-reference" href="../nips2011_reference/nips-2011-Unifying_Non-Maximum_Likelihood_Learning_Objectives_with_Minimum_KL_Contraction_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('kl', 0.752), ('contract', 0.496), ('mkc', 0.212), ('xa', 0.169), ('rd', 0.094), ('diverg', 0.093), ('dx', 0.091), ('argmin', 0.091), ('xai', 0.079), ('graft', 0.07), ('argmax', 0.068), ('strict', 0.067), ('op', 0.059), ('pis', 0.058), ('composit', 0.057), ('pa', 0.057), ('qai', 0.053), ('object', 0.051), ('margin', 0.051), ('qi', 0.045)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="295-tfidf-1" href="./nips-2011-Unifying_Non-Maximum_Likelihood_Learning_Objectives_with_Minimum_KL_Contraction.html">295 nips-2011-Unifying Non-Maximum Likelihood Learning Objectives with Minimum KL Contraction</a></p>
<p>Author: Siwei Lyu</p><p>Abstract: When used to learn high dimensional parametric probabilistic models, the classical maximum likelihood (ML) learning often suffers from computational intractability, which motivates the active developments of non-ML learning methods. Yet, because of their divergent motivations and forms, the objective functions of many non-ML learning methods are seemingly unrelated, and there lacks a uniﬁed framework to understand them. In this work, based on an information geometric view of parametric learning, we introduce a general non-ML learning principle termed as minimum KL contraction, where we seek optimal parameters that minimizes the contraction of the KL divergence between the two distributions after they are transformed with a KL contraction operator. We then show that the objective functions of several important or recently developed non-ML learning methods, including contrastive divergence [12], noise-contrastive estimation [11], partial likelihood [7], non-local contrastive objectives [31], score matching [14], pseudo-likelihood [3], maximum conditional likelihood [17], maximum mutual information [2], maximum marginal likelihood [9], and conditional and marginal composite likelihood [24], can be uniﬁed under the minimum KL contraction framework with different choices of the KL contraction operators. 1</p><p>2 0.11228583 <a title="295-tfidf-2" href="./nips-2011-Non-conjugate_Variational_Message_Passing_for_Multinomial_and_Binary_Regression.html">188 nips-2011-Non-conjugate Variational Message Passing for Multinomial and Binary Regression</a></p>
<p>Author: David A. Knowles, Tom Minka</p><p>Abstract: Variational Message Passing (VMP) is an algorithmic implementation of the Variational Bayes (VB) method which applies only in the special case of conjugate exponential family models. We propose an extension to VMP, which we refer to as Non-conjugate Variational Message Passing (NCVMP) which aims to alleviate this restriction while maintaining modularity, allowing choice in how expectations are calculated, and integrating into an existing message-passing framework: Infer.NET. We demonstrate NCVMP on logistic binary and multinomial regression. In the multinomial case we introduce a novel variational bound for the softmax factor which is tighter than other commonly used bounds whilst maintaining computational tractability. 1</p><p>3 0.083920963 <a title="295-tfidf-3" href="./nips-2011-A_Collaborative_Mechanism_for_Crowdsourcing_Prediction_Problems.html">3 nips-2011-A Collaborative Mechanism for Crowdsourcing Prediction Problems</a></p>
<p>Author: Jacob D. Abernethy, Rafael M. Frongillo</p><p>Abstract: Machine Learning competitions such as the Netﬂix Prize have proven reasonably successful as a method of “crowdsourcing” prediction tasks. But these competitions have a number of weaknesses, particularly in the incentive structure they create for the participants. We propose a new approach, called a Crowdsourced Learning Mechanism, in which participants collaboratively “learn” a hypothesis for a given prediction task. The approach draws heavily from the concept of a prediction market, where traders bet on the likelihood of a future event. In our framework, the mechanism continues to publish the current hypothesis, and participants can modify this hypothesis by wagering on an update. The critical incentive property is that a participant will proﬁt an amount that scales according to how much her update improves performance on a released test set. 1</p><p>4 0.083632223 <a title="295-tfidf-4" href="./nips-2011-Relative_Density-Ratio_Estimation_for_Robust_Distribution_Comparison.html">238 nips-2011-Relative Density-Ratio Estimation for Robust Distribution Comparison</a></p>
<p>Author: Makoto Yamada, Taiji Suzuki, Takafumi Kanamori, Hirotaka Hachiya, Masashi Sugiyama</p><p>Abstract: Divergence estimators based on direct approximation of density-ratios without going through separate approximation of numerator and denominator densities have been successfully applied to machine learning tasks that involve distribution comparison such as outlier detection, transfer learning, and two-sample homogeneity test. However, since density-ratio functions often possess high ﬂuctuation, divergence estimation is still a challenging task in practice. In this paper, we propose to use relative divergences for distribution comparison, which involves approximation of relative density-ratios. Since relative density-ratios are always smoother than corresponding ordinary density-ratios, our proposed method is favorable in terms of the non-parametric convergence speed. Furthermore, we show that the proposed divergence estimator has asymptotic variance independent of the model complexity under a parametric setup, implying that the proposed estimator hardly overﬁts even with complex models. Through experiments, we demonstrate the usefulness of the proposed approach. 1</p><p>5 0.073250979 <a title="295-tfidf-5" href="./nips-2011-Lower_Bounds_for_Passive_and_Active_Learning.html">162 nips-2011-Lower Bounds for Passive and Active Learning</a></p>
<p>Author: Maxim Raginsky, Alexander Rakhlin</p><p>Abstract: We develop uniﬁed information-theoretic machinery for deriving lower bounds for passive and active learning schemes. Our bounds involve the so-called Alexander’s capacity function. The supremum of this function has been recently rediscovered by Hanneke in the context of active learning under the name of “disagreement coefﬁcient.” For passive learning, our lower bounds match the upper bounds of Gin´ and Koltchinskii up to constants and generalize analogous results of Mase sart and N´ d´ lec. For active learning, we provide ﬁrst known lower bounds based e e on the capacity function rather than the disagreement coefﬁcient. 1</p><p>6 0.070337161 <a title="295-tfidf-6" href="./nips-2011-t-divergence_Based_Approximate_Inference.html">306 nips-2011-t-divergence Based Approximate Inference</a></p>
<p>7 0.069217265 <a title="295-tfidf-7" href="./nips-2011-Variational_Learning_for_Recurrent_Spiking_Networks.html">302 nips-2011-Variational Learning for Recurrent Spiking Networks</a></p>
<p>8 0.067378767 <a title="295-tfidf-8" href="./nips-2011-Metric_Learning_with_Multiple_Kernels.html">171 nips-2011-Metric Learning with Multiple Kernels</a></p>
<p>9 0.061977208 <a title="295-tfidf-9" href="./nips-2011-Optimal_learning_rates_for_least_squares_SVMs_using_Gaussian_kernels.html">207 nips-2011-Optimal learning rates for least squares SVMs using Gaussian kernels</a></p>
<p>10 0.061851587 <a title="295-tfidf-10" href="./nips-2011-PAC-Bayesian_Analysis_of_Contextual_Bandits.html">210 nips-2011-PAC-Bayesian Analysis of Contextual Bandits</a></p>
<p>11 0.058857247 <a title="295-tfidf-11" href="./nips-2011-Generalised_Coupled_Tensor_Factorisation.html">102 nips-2011-Generalised Coupled Tensor Factorisation</a></p>
<p>12 0.051100183 <a title="295-tfidf-12" href="./nips-2011-Automated_Refinement_of_Bayes_Networks%27_Parameters_based_on_Test_Ordering_Constraints.html">40 nips-2011-Automated Refinement of Bayes Networks' Parameters based on Test Ordering Constraints</a></p>
<p>13 0.050733823 <a title="295-tfidf-13" href="./nips-2011-Query-Aware_MCMC.html">229 nips-2011-Query-Aware MCMC</a></p>
<p>14 0.050527852 <a title="295-tfidf-14" href="./nips-2011-The_Manifold_Tangent_Classifier.html">287 nips-2011-The Manifold Tangent Classifier</a></p>
<p>15 0.044911142 <a title="295-tfidf-15" href="./nips-2011-Thinning_Measurement_Models_and_Questionnaire_Design.html">288 nips-2011-Thinning Measurement Models and Questionnaire Design</a></p>
<p>16 0.04333213 <a title="295-tfidf-16" href="./nips-2011-Infinite_Latent_SVM_for_Classification_and_Multi-task_Learning.html">134 nips-2011-Infinite Latent SVM for Classification and Multi-task Learning</a></p>
<p>17 0.041523758 <a title="295-tfidf-17" href="./nips-2011-Expressive_Power_and_Approximation_Errors_of_Restricted_Boltzmann_Machines.html">92 nips-2011-Expressive Power and Approximation Errors of Restricted Boltzmann Machines</a></p>
<p>18 0.039173588 <a title="295-tfidf-18" href="./nips-2011-Uniqueness_of_Belief_Propagation_on_Signed_Graphs.html">296 nips-2011-Uniqueness of Belief Propagation on Signed Graphs</a></p>
<p>19 0.034807194 <a title="295-tfidf-19" href="./nips-2011-How_biased_are_maximum_entropy_models%3F.html">123 nips-2011-How biased are maximum entropy models?</a></p>
<p>20 0.034736522 <a title="295-tfidf-20" href="./nips-2011-Variational_Gaussian_Process_Dynamical_Systems.html">301 nips-2011-Variational Gaussian Process Dynamical Systems</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.091), (1, -0.012), (2, -0.0), (3, 0.016), (4, 0.033), (5, 0.0), (6, -0.055), (7, 0.007), (8, -0.085), (9, 0.003), (10, -0.001), (11, 0.021), (12, 0.004), (13, 0.011), (14, 0.05), (15, -0.027), (16, -0.025), (17, -0.029), (18, 0.039), (19, -0.004), (20, -0.09), (21, -0.066), (22, 0.003), (23, -0.061), (24, -0.039), (25, -0.073), (26, 0.058), (27, -0.009), (28, 0.022), (29, -0.008), (30, -0.022), (31, -0.049), (32, -0.094), (33, 0.07), (34, -0.02), (35, -0.038), (36, 0.115), (37, 0.029), (38, 0.066), (39, -0.033), (40, 0.018), (41, -0.026), (42, 0.027), (43, -0.093), (44, -0.11), (45, 0.079), (46, -0.047), (47, 0.018), (48, 0.019), (49, 0.058)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93960929 <a title="295-lsi-1" href="./nips-2011-Unifying_Non-Maximum_Likelihood_Learning_Objectives_with_Minimum_KL_Contraction.html">295 nips-2011-Unifying Non-Maximum Likelihood Learning Objectives with Minimum KL Contraction</a></p>
<p>Author: Siwei Lyu</p><p>Abstract: When used to learn high dimensional parametric probabilistic models, the classical maximum likelihood (ML) learning often suffers from computational intractability, which motivates the active developments of non-ML learning methods. Yet, because of their divergent motivations and forms, the objective functions of many non-ML learning methods are seemingly unrelated, and there lacks a uniﬁed framework to understand them. In this work, based on an information geometric view of parametric learning, we introduce a general non-ML learning principle termed as minimum KL contraction, where we seek optimal parameters that minimizes the contraction of the KL divergence between the two distributions after they are transformed with a KL contraction operator. We then show that the objective functions of several important or recently developed non-ML learning methods, including contrastive divergence [12], noise-contrastive estimation [11], partial likelihood [7], non-local contrastive objectives [31], score matching [14], pseudo-likelihood [3], maximum conditional likelihood [17], maximum mutual information [2], maximum marginal likelihood [9], and conditional and marginal composite likelihood [24], can be uniﬁed under the minimum KL contraction framework with different choices of the KL contraction operators. 1</p><p>2 0.64892465 <a title="295-lsi-2" href="./nips-2011-t-divergence_Based_Approximate_Inference.html">306 nips-2011-t-divergence Based Approximate Inference</a></p>
<p>Author: Nan Ding, Yuan Qi, S.v.n. Vishwanathan</p><p>Abstract: Approximate inference is an important technique for dealing with large, intractable graphical models based on the exponential family of distributions. We extend the idea of approximate inference to the t-exponential family by deﬁning a new t-divergence. This divergence measure is obtained via convex duality between the log-partition function of the t-exponential family and a new t-entropy. We illustrate our approach on the Bayes Point Machine with a Student’s t-prior. 1</p><p>3 0.59171003 <a title="295-lsi-3" href="./nips-2011-Non-conjugate_Variational_Message_Passing_for_Multinomial_and_Binary_Regression.html">188 nips-2011-Non-conjugate Variational Message Passing for Multinomial and Binary Regression</a></p>
<p>Author: David A. Knowles, Tom Minka</p><p>Abstract: Variational Message Passing (VMP) is an algorithmic implementation of the Variational Bayes (VB) method which applies only in the special case of conjugate exponential family models. We propose an extension to VMP, which we refer to as Non-conjugate Variational Message Passing (NCVMP) which aims to alleviate this restriction while maintaining modularity, allowing choice in how expectations are calculated, and integrating into an existing message-passing framework: Infer.NET. We demonstrate NCVMP on logistic binary and multinomial regression. In the multinomial case we introduce a novel variational bound for the softmax factor which is tighter than other commonly used bounds whilst maintaining computational tractability. 1</p><p>4 0.58681417 <a title="295-lsi-4" href="./nips-2011-How_biased_are_maximum_entropy_models%3F.html">123 nips-2011-How biased are maximum entropy models?</a></p>
<p>Author: Jakob H. Macke, Iain Murray, Peter E. Latham</p><p>Abstract: Maximum entropy models have become popular statistical models in neuroscience and other areas in biology, and can be useful tools for obtaining estimates of mutual information in biological systems. However, maximum entropy models ﬁt to small data sets can be subject to sampling bias; i.e. the true entropy of the data can be severely underestimated. Here we study the sampling properties of estimates of the entropy obtained from maximum entropy models. We show that if the data is generated by a distribution that lies in the model class, the bias is equal to the number of parameters divided by twice the number of observations. However, in practice, the true distribution is usually outside the model class, and we show here that this misspeciﬁcation can lead to much larger bias. We provide a perturbative approximation of the maximally expected bias when the true model is out of model class, and we illustrate our results using numerical simulations of an Ising model; i.e. the second-order maximum entropy distribution on binary data. 1</p><p>5 0.53070313 <a title="295-lsi-5" href="./nips-2011-Relative_Density-Ratio_Estimation_for_Robust_Distribution_Comparison.html">238 nips-2011-Relative Density-Ratio Estimation for Robust Distribution Comparison</a></p>
<p>Author: Makoto Yamada, Taiji Suzuki, Takafumi Kanamori, Hirotaka Hachiya, Masashi Sugiyama</p><p>Abstract: Divergence estimators based on direct approximation of density-ratios without going through separate approximation of numerator and denominator densities have been successfully applied to machine learning tasks that involve distribution comparison such as outlier detection, transfer learning, and two-sample homogeneity test. However, since density-ratio functions often possess high ﬂuctuation, divergence estimation is still a challenging task in practice. In this paper, we propose to use relative divergences for distribution comparison, which involves approximation of relative density-ratios. Since relative density-ratios are always smoother than corresponding ordinary density-ratios, our proposed method is favorable in terms of the non-parametric convergence speed. Furthermore, we show that the proposed divergence estimator has asymptotic variance independent of the model complexity under a parametric setup, implying that the proposed estimator hardly overﬁts even with complex models. Through experiments, we demonstrate the usefulness of the proposed approach. 1</p><p>6 0.47996533 <a title="295-lsi-6" href="./nips-2011-Signal_Estimation_Under_Random_Time-Warpings_and_Nonlinear_Signal_Alignment.html">253 nips-2011-Signal Estimation Under Random Time-Warpings and Nonlinear Signal Alignment</a></p>
<p>7 0.47957268 <a title="295-lsi-7" href="./nips-2011-Thinning_Measurement_Models_and_Questionnaire_Design.html">288 nips-2011-Thinning Measurement Models and Questionnaire Design</a></p>
<p>8 0.47608858 <a title="295-lsi-8" href="./nips-2011-Expressive_Power_and_Approximation_Errors_of_Restricted_Boltzmann_Machines.html">92 nips-2011-Expressive Power and Approximation Errors of Restricted Boltzmann Machines</a></p>
<p>9 0.44131783 <a title="295-lsi-9" href="./nips-2011-Learning_unbelievable_probabilities.html">158 nips-2011-Learning unbelievable probabilities</a></p>
<p>10 0.43046272 <a title="295-lsi-10" href="./nips-2011-Differentially_Private_M-Estimators.html">69 nips-2011-Differentially Private M-Estimators</a></p>
<p>11 0.41466177 <a title="295-lsi-11" href="./nips-2011-Automated_Refinement_of_Bayes_Networks%27_Parameters_based_on_Test_Ordering_Constraints.html">40 nips-2011-Automated Refinement of Bayes Networks' Parameters based on Test Ordering Constraints</a></p>
<p>12 0.41283101 <a title="295-lsi-12" href="./nips-2011-Learning_in_Hilbert_vs._Banach_Spaces%3A_A_Measure_Embedding_Viewpoint.html">152 nips-2011-Learning in Hilbert vs. Banach Spaces: A Measure Embedding Viewpoint</a></p>
<p>13 0.4085657 <a title="295-lsi-13" href="./nips-2011-Lower_Bounds_for_Passive_and_Active_Learning.html">162 nips-2011-Lower Bounds for Passive and Active Learning</a></p>
<p>14 0.40760484 <a title="295-lsi-14" href="./nips-2011-Optimal_learning_rates_for_least_squares_SVMs_using_Gaussian_kernels.html">207 nips-2011-Optimal learning rates for least squares SVMs using Gaussian kernels</a></p>
<p>15 0.38908213 <a title="295-lsi-15" href="./nips-2011-Global_Solution_of_Fully-Observed_Variational_Bayesian_Matrix_Factorization_is_Column-Wise_Independent.html">107 nips-2011-Global Solution of Fully-Observed Variational Bayesian Matrix Factorization is Column-Wise Independent</a></p>
<p>16 0.38585278 <a title="295-lsi-16" href="./nips-2011-Iterative_Learning_for_Reliable_Crowdsourcing_Systems.html">137 nips-2011-Iterative Learning for Reliable Crowdsourcing Systems</a></p>
<p>17 0.3856189 <a title="295-lsi-17" href="./nips-2011-Uniqueness_of_Belief_Propagation_on_Signed_Graphs.html">296 nips-2011-Uniqueness of Belief Propagation on Signed Graphs</a></p>
<p>18 0.36150023 <a title="295-lsi-18" href="./nips-2011-k-NN_Regression_Adapts_to_Local_Intrinsic_Dimension.html">305 nips-2011-k-NN Regression Adapts to Local Intrinsic Dimension</a></p>
<p>19 0.3590118 <a title="295-lsi-19" href="./nips-2011-Accelerated_Adaptive_Markov_Chain_for_Partition_Function_Computation.html">17 nips-2011-Accelerated Adaptive Markov Chain for Partition Function Computation</a></p>
<p>20 0.35260564 <a title="295-lsi-20" href="./nips-2011-Robust_Multi-Class_Gaussian_Process_Classification.html">240 nips-2011-Robust Multi-Class Gaussian Process Classification</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(14, 0.066), (22, 0.024), (36, 0.048), (44, 0.349), (53, 0.026), (55, 0.115), (65, 0.072), (68, 0.11), (79, 0.037)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.64479852 <a title="295-lda-1" href="./nips-2011-Unifying_Non-Maximum_Likelihood_Learning_Objectives_with_Minimum_KL_Contraction.html">295 nips-2011-Unifying Non-Maximum Likelihood Learning Objectives with Minimum KL Contraction</a></p>
<p>Author: Siwei Lyu</p><p>Abstract: When used to learn high dimensional parametric probabilistic models, the classical maximum likelihood (ML) learning often suffers from computational intractability, which motivates the active developments of non-ML learning methods. Yet, because of their divergent motivations and forms, the objective functions of many non-ML learning methods are seemingly unrelated, and there lacks a uniﬁed framework to understand them. In this work, based on an information geometric view of parametric learning, we introduce a general non-ML learning principle termed as minimum KL contraction, where we seek optimal parameters that minimizes the contraction of the KL divergence between the two distributions after they are transformed with a KL contraction operator. We then show that the objective functions of several important or recently developed non-ML learning methods, including contrastive divergence [12], noise-contrastive estimation [11], partial likelihood [7], non-local contrastive objectives [31], score matching [14], pseudo-likelihood [3], maximum conditional likelihood [17], maximum mutual information [2], maximum marginal likelihood [9], and conditional and marginal composite likelihood [24], can be uniﬁed under the minimum KL contraction framework with different choices of the KL contraction operators. 1</p><p>2 0.56749123 <a title="295-lda-2" href="./nips-2011-Algorithms_and_hardness_results_for_parallel_large_margin_learning.html">29 nips-2011-Algorithms and hardness results for parallel large margin learning</a></p>
<p>Author: Phil Long, Rocco Servedio</p><p>Abstract: We study the fundamental problem of learning an unknown large-margin halfspace in the context of parallel computation. Our main positive result is a parallel algorithm for learning a large-margin halfspace that is based on interior point methods from convex optimization and fast parallel algorithms for matrix computations. We show that this algorithm learns an unknown γ-margin halfspace over n dimensions using poly(n, 1/γ) processors ˜ and runs in time O(1/γ) + O(log n). In contrast, naive parallel algorithms that learn a γ-margin halfspace in time that depends polylogarithmically on n have Ω(1/γ 2 ) runtime dependence on γ. Our main negative result deals with boosting, which is a standard approach to learning large-margin halfspaces. We give an information-theoretic proof that in the original PAC framework, in which a weak learning algorithm is provided as an oracle that is called by the booster, boosting cannot be parallelized: the ability to call the weak learner multiple times in parallel within a single boosting stage does not reduce the overall number of successive stages of boosting that are required. 1</p><p>3 0.47467816 <a title="295-lda-3" href="./nips-2011-Signal_Estimation_Under_Random_Time-Warpings_and_Nonlinear_Signal_Alignment.html">253 nips-2011-Signal Estimation Under Random Time-Warpings and Nonlinear Signal Alignment</a></p>
<p>Author: Sebastian A. Kurtek, Anuj Srivastava, Wei Wu</p><p>Abstract: While signal estimation under random amplitudes, phase shifts, and additive noise is studied frequently, the problem of estimating a deterministic signal under random time-warpings has been relatively unexplored. We present a novel framework for estimating the unknown signal that utilizes the action of the warping group to form an equivalence relation between signals. First, we derive an estimator for the equivalence class of the unknown signal using the notion of Karcher mean on the quotient space of equivalence classes. This step requires the use of Fisher-Rao Riemannian metric and a square-root representation of signals to enable computations of distances and means under this metric. Then, we deﬁne a notion of the center of a class and show that the center of the estimated class is a consistent estimator of the underlying unknown signal. This estimation algorithm has many applications: (1) registration/alignment of functional data, (2) separation of phase/amplitude components of functional data, (3) joint demodulation and carrier estimation, and (4) sparse modeling of functional data. Here we demonstrate only (1) and (2): Given signals are temporally aligned using nonlinear warpings and, thus, separated into their phase and amplitude components. The proposed method for signal alignment is shown to have state of the art performance using Berkeley growth, handwritten signatures, and neuroscience spike train data. 1</p><p>4 0.47320312 <a title="295-lda-4" href="./nips-2011-Dynamical_segmentation_of_single_trials_from_population_neural_data.html">75 nips-2011-Dynamical segmentation of single trials from population neural data</a></p>
<p>Author: Biljana Petreska, Byron M. Yu, John P. Cunningham, Gopal Santhanam, Stephen I. Ryu, Krishna V. Shenoy, Maneesh Sahani</p><p>Abstract: Simultaneous recordings of many neurons embedded within a recurrentlyconnected cortical network may provide concurrent views into the dynamical processes of that network, and thus its computational function. In principle, these dynamics might be identiﬁed by purely unsupervised, statistical means. Here, we show that a Hidden Switching Linear Dynamical Systems (HSLDS) model— in which multiple linear dynamical laws approximate a nonlinear and potentially non-stationary dynamical process—is able to distinguish different dynamical regimes within single-trial motor cortical activity associated with the preparation and initiation of hand movements. The regimes are identiﬁed without reference to behavioural or experimental epochs, but nonetheless transitions between them correlate strongly with external events whose timing may vary from trial to trial. The HSLDS model also performs better than recent comparable models in predicting the ﬁring rate of an isolated neuron based on the ﬁring rates of others, suggesting that it captures more of the “shared variance” of the data. Thus, the method is able to trace the dynamical processes underlying the coordinated evolution of network activity in a way that appears to reﬂect its computational role. 1</p><p>5 0.47230935 <a title="295-lda-5" href="./nips-2011-Structural_equations_and_divisive_normalization_for_energy-dependent_component_analysis.html">273 nips-2011-Structural equations and divisive normalization for energy-dependent component analysis</a></p>
<p>Author: Jun-ichiro Hirayama, Aapo Hyvärinen</p><p>Abstract: Components estimated by independent component analysis and related methods are typically not independent in real data. A very common form of nonlinear dependency between the components is correlations in their variances or energies. Here, we propose a principled probabilistic model to model the energycorrelations between the latent variables. Our two-stage model includes a linear mixing of latent signals into the observed ones like in ICA. The main new feature is a model of the energy-correlations based on the structural equation model (SEM), in particular, a Linear Non-Gaussian SEM. The SEM is closely related to divisive normalization which effectively reduces energy correlation. Our new twostage model enables estimation of both the linear mixing and the interactions related to energy-correlations, without resorting to approximations of the likelihood function or other non-principled approaches. We demonstrate the applicability of our method with synthetic dataset, natural images and brain signals. 1</p><p>6 0.47126594 <a title="295-lda-6" href="./nips-2011-An_ideal_observer_model_for_identifying_the_reference_frame_of_objects.html">35 nips-2011-An ideal observer model for identifying the reference frame of objects</a></p>
<p>7 0.47113687 <a title="295-lda-7" href="./nips-2011-Sparse_Recovery_with_Brownian_Sensing.html">264 nips-2011-Sparse Recovery with Brownian Sensing</a></p>
<p>8 0.47074547 <a title="295-lda-8" href="./nips-2011-Active_dendrites%3A_adaptation_to_spike-based_communication.html">23 nips-2011-Active dendrites: adaptation to spike-based communication</a></p>
<p>9 0.47019774 <a title="295-lda-9" href="./nips-2011-Kernel_Embeddings_of_Latent_Tree_Graphical_Models.html">140 nips-2011-Kernel Embeddings of Latent Tree Graphical Models</a></p>
<p>10 0.46999401 <a title="295-lda-10" href="./nips-2011-Inference_in_continuous-time_change-point_models.html">131 nips-2011-Inference in continuous-time change-point models</a></p>
<p>11 0.46905401 <a title="295-lda-11" href="./nips-2011-Two_is_better_than_one%3A_distinct_roles_for_familiarity_and_recollection_in_retrieving_palimpsest_memories.html">292 nips-2011-Two is better than one: distinct roles for familiarity and recollection in retrieving palimpsest memories</a></p>
<p>12 0.46846035 <a title="295-lda-12" href="./nips-2011-Information_Rates_and_Optimal_Decoding_in_Large_Neural_Populations.html">135 nips-2011-Information Rates and Optimal Decoding in Large Neural Populations</a></p>
<p>13 0.46796173 <a title="295-lda-13" href="./nips-2011-Uniqueness_of_Belief_Propagation_on_Signed_Graphs.html">296 nips-2011-Uniqueness of Belief Propagation on Signed Graphs</a></p>
<p>14 0.46791944 <a title="295-lda-14" href="./nips-2011-Convergent_Fitted_Value_Iteration_with_Linear_Function_Approximation.html">65 nips-2011-Convergent Fitted Value Iteration with Linear Function Approximation</a></p>
<p>15 0.46742657 <a title="295-lda-15" href="./nips-2011-Empirical_models_of_spiking_in_neural_populations.html">86 nips-2011-Empirical models of spiking in neural populations</a></p>
<p>16 0.46709561 <a title="295-lda-16" href="./nips-2011-Variational_Learning_for_Recurrent_Spiking_Networks.html">302 nips-2011-Variational Learning for Recurrent Spiking Networks</a></p>
<p>17 0.46708414 <a title="295-lda-17" href="./nips-2011-Sequence_learning_with_hidden_units_in_spiking_neural_networks.html">249 nips-2011-Sequence learning with hidden units in spiking neural networks</a></p>
<p>18 0.46659219 <a title="295-lda-18" href="./nips-2011-Learning_a_Distance_Metric_from_a_Network.html">150 nips-2011-Learning a Distance Metric from a Network</a></p>
<p>19 0.46648246 <a title="295-lda-19" href="./nips-2011-Prismatic_Algorithm_for_Discrete_D.C._Programming_Problem.html">222 nips-2011-Prismatic Algorithm for Discrete D.C. Programming Problem</a></p>
<p>20 0.4660117 <a title="295-lda-20" href="./nips-2011-Active_learning_of_neural_response_functions_with_Gaussian_processes.html">24 nips-2011-Active learning of neural response functions with Gaussian processes</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
