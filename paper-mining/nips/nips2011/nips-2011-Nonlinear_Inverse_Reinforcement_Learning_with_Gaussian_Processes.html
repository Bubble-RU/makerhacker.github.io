<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>190 nips-2011-Nonlinear Inverse Reinforcement Learning with Gaussian Processes</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2011" href="../home/nips2011_home.html">nips2011</a> <a title="nips-2011-190" href="#">nips2011-190</a> knowledge-graph by maker-knowledge-mining</p><h1>190 nips-2011-Nonlinear Inverse Reinforcement Learning with Gaussian Processes</h1>
<br/><p>Source: <a title="nips-2011-190-pdf" href="http://papers.nips.cc/paper/4420-nonlinear-inverse-reinforcement-learning-with-gaussian-processes.pdf">pdf</a></p><p>Author: Sergey Levine, Zoran Popovic, Vladlen Koltun</p><p>Abstract: We present a probabilistic algorithm for nonlinear inverse reinforcement learning. The goal of inverse reinforcement learning is to learn the reward function in a Markov decision process from expert demonstrations. While most prior inverse reinforcement learning algorithms represent the reward as a linear combination of a set of features, we use Gaussian processes to learn the reward as a nonlinear function, while also determining the relevance of each feature to the expertâ€™s policy. Our probabilistic algorithm allows complex behaviors to be captured from suboptimal stochastic demonstrations, while automatically balancing the simplicity of the learned reward structure against its consistency with the observed actions. 1</p><p>Reference: <a title="nips-2011-190-reference" href="../nips2011_reference/nips-2011-Nonlinear_Inverse_Reinforcement_Learning_with_Gaussian_Processes_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('gpirl', 0.708), ('reward', 0.46), ('firl', 0.227), ('gp', 0.175), ('xu', 0.16), ('expert', 0.129), ('irl', 0.126), ('policy', 0.117), ('xik', 0.103), ('reinforc', 0.097), ('objectworld', 0.085), ('kernel', 0.076), ('highway', 0.075), ('feat', 0.07), ('warp', 0.068), ('transf', 0.066), ('invers', 0.059), ('wk', 0.057), ('nonlinear', 0.054), ('hyperparamet', 0.053)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="190-tfidf-1" href="./nips-2011-Nonlinear_Inverse_Reinforcement_Learning_with_Gaussian_Processes.html">190 nips-2011-Nonlinear Inverse Reinforcement Learning with Gaussian Processes</a></p>
<p>2 0.40120694 <a title="190-tfidf-2" href="./nips-2011-MAP_Inference_for_Bayesian_Inverse_Reinforcement_Learning.html">163 nips-2011-MAP Inference for Bayesian Inverse Reinforcement Learning</a></p>
<p>3 0.26223052 <a title="190-tfidf-3" href="./nips-2011-Environmental_statistics_and_the_trade-off_between_model-based_and_TD_learning_in_humans.html">88 nips-2011-Environmental statistics and the trade-off between model-based and TD learning in humans</a></p>
<p>4 0.21013881 <a title="190-tfidf-4" href="./nips-2011-A_Reinforcement_Learning_Theory_for_Homeostatic_Regulation.html">11 nips-2011-A Reinforcement Learning Theory for Homeostatic Regulation</a></p>
<p>5 0.18917052 <a title="190-tfidf-5" href="./nips-2011-Selecting_the_State-Representation_in_Reinforcement_Learning.html">245 nips-2011-Selecting the State-Representation in Reinforcement Learning</a></p>
<p>6 0.16409306 <a title="190-tfidf-6" href="./nips-2011-From_Bandits_to_Experts%3A_On_the_Value_of_Side-Observations.html">98 nips-2011-From Bandits to Experts: On the Value of Side-Observations</a></p>
<p>7 0.1445221 <a title="190-tfidf-7" href="./nips-2011-Additive_Gaussian_Processes.html">26 nips-2011-Additive Gaussian Processes</a></p>
<p>8 0.13560624 <a title="190-tfidf-8" href="./nips-2011-A_reinterpretation_of_the_policy_oscillation_phenomenon_in_approximate_policy_iteration.html">16 nips-2011-A reinterpretation of the policy oscillation phenomenon in approximate policy iteration</a></p>
<p>9 0.13083474 <a title="190-tfidf-9" href="./nips-2011-Policy_Gradient_Coagent_Networks.html">215 nips-2011-Policy Gradient Coagent Networks</a></p>
<p>10 0.12072811 <a title="190-tfidf-10" href="./nips-2011-Gaussian_Process_Training_with_Input_Noise.html">100 nips-2011-Gaussian Process Training with Input Noise</a></p>
<p>11 0.11288143 <a title="190-tfidf-11" href="./nips-2011-Monte_Carlo_Value_Iteration_with_Macro-Actions.html">174 nips-2011-Monte Carlo Value Iteration with Macro-Actions</a></p>
<p>12 0.11166536 <a title="190-tfidf-12" href="./nips-2011-A_Non-Parametric_Approach_to_Dynamic_Programming.html">10 nips-2011-A Non-Parametric Approach to Dynamic Programming</a></p>
<p>13 0.11114743 <a title="190-tfidf-13" href="./nips-2011-Optimal_Reinforcement_Learning_for_Gaussian_Systems.html">206 nips-2011-Optimal Reinforcement Learning for Gaussian Systems</a></p>
<p>14 0.10276768 <a title="190-tfidf-14" href="./nips-2011-Improved_Algorithms_for_Linear_Stochastic_Bandits.html">128 nips-2011-Improved Algorithms for Linear Stochastic Bandits</a></p>
<p>15 0.098083131 <a title="190-tfidf-15" href="./nips-2011-Committing_Bandits.html">56 nips-2011-Committing Bandits</a></p>
<p>16 0.087941267 <a title="190-tfidf-16" href="./nips-2011-PAC-Bayesian_Analysis_of_Contextual_Bandits.html">210 nips-2011-PAC-Bayesian Analysis of Contextual Bandits</a></p>
<p>17 0.085670032 <a title="190-tfidf-17" href="./nips-2011-Algorithms_for_Hyper-Parameter_Optimization.html">30 nips-2011-Algorithms for Hyper-Parameter Optimization</a></p>
<p>18 0.085139677 <a title="190-tfidf-18" href="./nips-2011-Action-Gap_Phenomenon_in_Reinforcement_Learning.html">18 nips-2011-Action-Gap Phenomenon in Reinforcement Learning</a></p>
<p>19 0.084830292 <a title="190-tfidf-19" href="./nips-2011-Transfer_from_Multiple_MDPs.html">291 nips-2011-Transfer from Multiple MDPs</a></p>
<p>20 0.077475272 <a title="190-tfidf-20" href="./nips-2011-Contextual_Gaussian_Process_Bandit_Optimization.html">61 nips-2011-Contextual Gaussian Process Bandit Optimization</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2011_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.166), (1, -0.107), (2, -0.192), (3, -0.263), (4, 0.147), (5, 0.056), (6, 0.091), (7, 0.08), (8, -0.039), (9, 0.063), (10, 0.01), (11, 0.104), (12, 0.021), (13, 0.076), (14, -0.066), (15, 0.086), (16, -0.078), (17, 0.055), (18, 0.05), (19, -0.086), (20, 0.099), (21, 0.165), (22, 0.128), (23, 0.067), (24, -0.086), (25, -0.017), (26, 0.029), (27, -0.1), (28, 0.121), (29, 0.136), (30, -0.085), (31, -0.08), (32, 0.002), (33, -0.069), (34, -0.199), (35, 0.081), (36, 0.104), (37, 0.012), (38, -0.07), (39, 0.049), (40, 0.095), (41, 0.082), (42, -0.019), (43, -0.031), (44, 0.021), (45, -0.015), (46, 0.053), (47, -0.049), (48, -0.017), (49, 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93893492 <a title="190-lsi-1" href="./nips-2011-Nonlinear_Inverse_Reinforcement_Learning_with_Gaussian_Processes.html">190 nips-2011-Nonlinear Inverse Reinforcement Learning with Gaussian Processes</a></p>
<p>2 0.85740048 <a title="190-lsi-2" href="./nips-2011-MAP_Inference_for_Bayesian_Inverse_Reinforcement_Learning.html">163 nips-2011-MAP Inference for Bayesian Inverse Reinforcement Learning</a></p>
<p>3 0.79668361 <a title="190-lsi-3" href="./nips-2011-A_Reinforcement_Learning_Theory_for_Homeostatic_Regulation.html">11 nips-2011-A Reinforcement Learning Theory for Homeostatic Regulation</a></p>
<p>4 0.64520919 <a title="190-lsi-4" href="./nips-2011-Environmental_statistics_and_the_trade-off_between_model-based_and_TD_learning_in_humans.html">88 nips-2011-Environmental statistics and the trade-off between model-based and TD learning in humans</a></p>
<p>5 0.5795126 <a title="190-lsi-5" href="./nips-2011-From_Bandits_to_Experts%3A_On_the_Value_of_Side-Observations.html">98 nips-2011-From Bandits to Experts: On the Value of Side-Observations</a></p>
<p>6 0.55490345 <a title="190-lsi-6" href="./nips-2011-Selecting_the_State-Representation_in_Reinforcement_Learning.html">245 nips-2011-Selecting the State-Representation in Reinforcement Learning</a></p>
<p>7 0.48121396 <a title="190-lsi-7" href="./nips-2011-A_Non-Parametric_Approach_to_Dynamic_Programming.html">10 nips-2011-A Non-Parametric Approach to Dynamic Programming</a></p>
<p>8 0.45264706 <a title="190-lsi-8" href="./nips-2011-Analysis_and_Improvement_of_Policy_Gradient_Estimation.html">36 nips-2011-Analysis and Improvement of Policy Gradient Estimation</a></p>
<p>9 0.44237641 <a title="190-lsi-9" href="./nips-2011-Monte_Carlo_Value_Iteration_with_Macro-Actions.html">174 nips-2011-Monte Carlo Value Iteration with Macro-Actions</a></p>
<p>10 0.40239927 <a title="190-lsi-10" href="./nips-2011-Policy_Gradient_Coagent_Networks.html">215 nips-2011-Policy Gradient Coagent Networks</a></p>
<p>11 0.38842201 <a title="190-lsi-11" href="./nips-2011-Convergent_Fitted_Value_Iteration_with_Linear_Function_Approximation.html">65 nips-2011-Convergent Fitted Value Iteration with Linear Function Approximation</a></p>
<p>12 0.38609022 <a title="190-lsi-12" href="./nips-2011-Gaussian_Process_Training_with_Input_Noise.html">100 nips-2011-Gaussian Process Training with Input Noise</a></p>
<p>13 0.37621784 <a title="190-lsi-13" href="./nips-2011-A_reinterpretation_of_the_policy_oscillation_phenomenon_in_approximate_policy_iteration.html">16 nips-2011-A reinterpretation of the policy oscillation phenomenon in approximate policy iteration</a></p>
<p>14 0.35252988 <a title="190-lsi-14" href="./nips-2011-Additive_Gaussian_Processes.html">26 nips-2011-Additive Gaussian Processes</a></p>
<p>15 0.35149518 <a title="190-lsi-15" href="./nips-2011-Optimal_Reinforcement_Learning_for_Gaussian_Systems.html">206 nips-2011-Optimal Reinforcement Learning for Gaussian Systems</a></p>
<p>16 0.34955114 <a title="190-lsi-16" href="./nips-2011-An_Empirical_Evaluation_of_Thompson_Sampling.html">32 nips-2011-An Empirical Evaluation of Thompson Sampling</a></p>
<p>17 0.33860353 <a title="190-lsi-17" href="./nips-2011-Active_Classification_based_on_Value_of_Classifier.html">19 nips-2011-Active Classification based on Value of Classifier</a></p>
<p>18 0.33377334 <a title="190-lsi-18" href="./nips-2011-Contextual_Gaussian_Process_Bandit_Optimization.html">61 nips-2011-Contextual Gaussian Process Bandit Optimization</a></p>
<p>19 0.32984436 <a title="190-lsi-19" href="./nips-2011-Inductive_reasoning_about_chimeric_creatures.html">130 nips-2011-Inductive reasoning about chimeric creatures</a></p>
<p>20 0.32553607 <a title="190-lsi-20" href="./nips-2011-Budgeted_Optimization_with_Concurrent_Stochastic-Duration_Experiments.html">50 nips-2011-Budgeted Optimization with Concurrent Stochastic-Duration Experiments</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2011_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(12, 0.01), (14, 0.052), (22, 0.051), (36, 0.053), (55, 0.223), (65, 0.083), (68, 0.15), (71, 0.191), (79, 0.016), (97, 0.037)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.89588255 <a title="190-lda-1" href="./nips-2011-On_fast_approximate_submodular_minimization.html">199 nips-2011-On fast approximate submodular minimization</a></p>
<p>2 0.88434184 <a title="190-lda-2" href="./nips-2011-An_Exact_Algorithm_for_F-Measure_Maximization.html">33 nips-2011-An Exact Algorithm for F-Measure Maximization</a></p>
<p>same-paper 3 0.85556197 <a title="190-lda-3" href="./nips-2011-Nonlinear_Inverse_Reinforcement_Learning_with_Gaussian_Processes.html">190 nips-2011-Nonlinear Inverse Reinforcement Learning with Gaussian Processes</a></p>
<p>4 0.83226824 <a title="190-lda-4" href="./nips-2011-MAP_Inference_for_Bayesian_Inverse_Reinforcement_Learning.html">163 nips-2011-MAP Inference for Bayesian Inverse Reinforcement Learning</a></p>
<p>5 0.82958895 <a title="190-lda-5" href="./nips-2011-Projection_onto_A_Nonnegative_Max-Heap.html">226 nips-2011-Projection onto A Nonnegative Max-Heap</a></p>
<p>6 0.82644856 <a title="190-lda-6" href="./nips-2011-Quasi-Newton_Methods_for_Markov_Chain_Monte_Carlo.html">228 nips-2011-Quasi-Newton Methods for Markov Chain Monte Carlo</a></p>
<p>7 0.82351017 <a title="190-lda-7" href="./nips-2011-Prismatic_Algorithm_for_Discrete_D.C._Programming_Problem.html">222 nips-2011-Prismatic Algorithm for Discrete D.C. Programming Problem</a></p>
<p>8 0.82223284 <a title="190-lda-8" href="./nips-2011-On_Tracking_The_Partition_Function.html">197 nips-2011-On Tracking The Partition Function</a></p>
<p>9 0.82173085 <a title="190-lda-9" href="./nips-2011-The_Fixed_Points_of_Off-Policy_TD.html">283 nips-2011-The Fixed Points of Off-Policy TD</a></p>
<p>10 0.82138103 <a title="190-lda-10" href="./nips-2011-Randomized_Algorithms_for_Comparison-based_Search.html">231 nips-2011-Randomized Algorithms for Comparison-based Search</a></p>
<p>11 0.82093263 <a title="190-lda-11" href="./nips-2011-Learning_to_Search_Efficiently_in_High_Dimensions.html">157 nips-2011-Learning to Search Efficiently in High Dimensions</a></p>
<p>12 0.82081479 <a title="190-lda-12" href="./nips-2011-A_reinterpretation_of_the_policy_oscillation_phenomenon_in_approximate_policy_iteration.html">16 nips-2011-A reinterpretation of the policy oscillation phenomenon in approximate policy iteration</a></p>
<p>13 0.82058734 <a title="190-lda-13" href="./nips-2011-Sparse_Inverse_Covariance_Matrix_Estimation_Using_Quadratic_Approximation.html">262 nips-2011-Sparse Inverse Covariance Matrix Estimation Using Quadratic Approximation</a></p>
<p>14 0.81939089 <a title="190-lda-14" href="./nips-2011-Beating_SGD%3A_Learning_SVMs_in_Sublinear_Time.html">45 nips-2011-Beating SGD: Learning SVMs in Sublinear Time</a></p>
<p>15 0.81862706 <a title="190-lda-15" href="./nips-2011-Convergent_Bounds_on_the_Euclidean_Distance.html">64 nips-2011-Convergent Bounds on the Euclidean Distance</a></p>
<p>16 0.81860614 <a title="190-lda-16" href="./nips-2011-Exploiting_spatial_overlap_to_efficiently_compute_appearance_distances_between_image_windows.html">91 nips-2011-Exploiting spatial overlap to efficiently compute appearance distances between image windows</a></p>
<p>17 0.81842941 <a title="190-lda-17" href="./nips-2011-Composite_Multiclass_Losses.html">59 nips-2011-Composite Multiclass Losses</a></p>
<p>18 0.8183403 <a title="190-lda-18" href="./nips-2011-On_Learning_Discrete_Graphical_Models_using_Greedy_Methods.html">195 nips-2011-On Learning Discrete Graphical Models using Greedy Methods</a></p>
<p>19 0.81772113 <a title="190-lda-19" href="./nips-2011-Sparse_Manifold_Clustering_and_Embedding.html">263 nips-2011-Sparse Manifold Clustering and Embedding</a></p>
<p>20 0.81762338 <a title="190-lda-20" href="./nips-2011-Better_Mini-Batch_Algorithms_via_Accelerated_Gradient_Methods.html">46 nips-2011-Better Mini-Batch Algorithms via Accelerated Gradient Methods</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
