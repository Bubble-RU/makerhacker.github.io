<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>269 nips-2012-Persistent Homology for Learning Densities with Bounded Support</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-269" href="../nips2012/nips-2012-Persistent_Homology_for_Learning_Densities_with_Bounded_Support.html">nips2012-269</a> <a title="nips-2012-269-reference" href="#">nips2012-269-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>269 nips-2012-Persistent Homology for Learning Densities with Bounded Support</h1>
<br/><p>Source: <a title="nips-2012-269-pdf" href="http://papers.nips.cc/paper/4711-persistent-homology-for-learning-densities-with-bounded-support.pdf">pdf</a></p><p>Author: Florian T. Pokorny, Hedvig Kjellström, Danica Kragic, Carl Ek</p><p>Abstract: We present a novel method for learning densities with bounded support which enables us to incorporate ‘hard’ topological constraints. In particular, we show how emerging techniques from computational algebraic topology and the notion of persistent homology can be combined with kernel-based methods from machine learning for the purpose of density estimation. The proposed formalism facilitates learning of models with bounded support in a principled way, and – by incorporating persistent homology techniques in our approach – we are able to encode algebraic-topological constraints which are not addressed in current state of the art probabilistic models. We study the behaviour of our method on two synthetic examples for various sample sizes and exemplify the beneﬁts of the proposed approach on a real-world dataset by learning a motion model for a race car. We show how to learn a model which respects the underlying topological structure of the racetrack, constraining the trajectories of the car. 1</p><br/>
<h2>reference text</h2><p>[1] D. A. Reynolds, T. F. Quatieri, and R. B. Dunn, “Speaker veriﬁcation using adapted Gaussian mixture models,” Digital Signal Processing, vol. 10, no. 1–3, pp. 19–41, 2000.</p>
<p>[2] C. E. Rasmussen and C. Williams, Gaussian Processes for Machine Learning. MIT Press, 2006.</p>
<p>[3] D. A. Cohn, Z. Ghahramani, and M. I. Jordan, “Active learning with statistical models,” Journal of Artiﬁcial Intelligence Research, no. 4, pp. 129–145, 1996.</p>
<p>[4] S. Calinon and A. Billard, “Incremental learning of gestures by imitation in a humanoid robot,” in ACM/IEEE International Conference on Human-Robot Interaction, pp. 255–262, 2007.</p>
<p>[5] D.-S. Lee, “Effective Gaussian mixture learning for video background subtraction,” PAMI, vol. 27, no. 5, pp. 827–832, 2005.</p>
<p>[6] M. P. Wand and M. C. Jones, Kernel Smoothing, vol. 60 of Monographs on Statistics and Applied Probability. Chapman and Hall/CRC, 1995.</p>
<p>[7] B. A. Turlach, “Bandwidth selection in kernel density estimation: A review,” in CORE and Institut de Statistique, pp. 23–493, 1993.</p>
<p>[8] L. El Ghaoui and G. Calaﬁore, “Robust ﬁltering for discrete-time systems with bounded noise and parametric uncertainty,” IEEE Transactions on Automatic Control, vol. 46, no. 7, pp. 1084– 1089, 2001.</p>
<p>[9] Y. C. Eldar, A. Ben-Tal, and A. Nemirovski, “Linear minimax regret estimation of deterministic parameters with bounded data uncertainties,” IEEE Transactions on Signal Processing, vol. 52, no. 8, pp. 2177–2188, 2008.</p>
<p>[10] G. Carlsson, “Topology and data,” Bull. Amer. Math. Soc. (N.S.), vol. 46, no. 2, pp. 255–308, 2009.</p>
<p>[11] P. Niyogi, S. Smale, and S. Weinberger, “A topological view of unsupervised learning from noisy data,” SIAM Journal of Computing, vol. 40, no. 3, pp. 646–663, 2011.</p>
<p>[12] S. M. Khansari-Zadeh and A. Billard, “Learning stable non-linear dynamical systems with Gaussian mixture models,” IEEE Transaction on Robotics, vol. 27, no. 5, pp. 943–957, 2011.</p>
<p>[13] M. Rosenblatt, “Remarks on some nonparametric estimates of a density function,” The Annals of Mathematical Statistics, vol. 27, no. 3, pp. 832–837, 1956.</p>
<p>[14] E. Parzen, “On estimation of a probability density function and mode,” Annals of Mathematical Statistics, vol. 33, pp. 1065–1076, 1962.</p>
<p>[15] T. Cacoullos, “Estimation of a multivariate density,” Annals of the Institute of Statistical Mathematics, vol. 18, pp. 179–189, 1966.</p>
<p>[16] H. Edelsbrunner, D. Letscher, and A. Zomorodian, “Topological persistence and simpliﬁcation,” Discrete Comput. Geom., vol. 28, no. 4, pp. 511–533, 2002.</p>
<p>[17] A. Hatcher, Algebraic Topology. Cambridge University Press, 2002.</p>
<p>[18] P. Niyogi, S. Smale, and S. Weinberger, “Finding the homology of submanifolds with high conﬁdence from random samples,” Discrete Comput. Geom., vol. 39, no. 1-3, pp. 419–441, 2008.</p>
<p>[19] A. Tausz, M. Vejdemo-Johansson, and H. Adams, “JavaPlex: A software package for computing persistent topological invariants.” Software, 2011.</p>
<p>[20] KTH Racing, Formula Student Team, KTH Royal Institute of Technology, Stockholm, Sweden.</p>
<p>[21] A. Billard, “GMM/GMR 2.0.” Software.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
