<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>198 nips-2012-Learning with Target Prior</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-198" href="../nips2012/nips-2012-Learning_with_Target_Prior.html">nips2012-198</a> <a title="nips-2012-198-reference" href="#">nips2012-198-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>198 nips-2012-Learning with Target Prior</h1>
<br/><p>Source: <a title="nips-2012-198-pdf" href="http://papers.nips.cc/paper/4849-learning-with-target-prior.pdf">pdf</a></p><p>Author: Zuoguan Wang, Siwei Lyu, Gerwin Schalk, Qiang Ji</p><p>Abstract: In the conventional approaches for supervised parametric learning, relations between data and target variables are provided through training sets consisting of pairs of corresponded data and target variables. In this work, we describe a new learning scheme for parametric learning, in which the target variables y can be modeled with a prior model p(y) and the relations between data and target variables are estimated with p(y) and a set of uncorresponded data X in training. We term this method as learning with target priors (LTP). Speciﬁcally, LTP learning seeks parameter θ that maximizes the log likelihood of fθ (X) on a uncorresponded training set with regards to p(y). Compared to the conventional (semi)supervised learning approach, LTP can make efﬁcient use of prior knowledge of the target variables in the form of probabilistic distributions, and thus removes/reduces the reliance on training data in learning. Compared to the Bayesian approach, the learned parametric regressor in LTP can be more efﬁciently implemented and deployed in tasks where running efﬁciency is critical. We demonstrate the effectiveness of the proposed approach on parametric regression tasks for BCI signal decoding and pose estimation from video. 1</p><br/>
<h2>reference text</h2><p>[1] Bashashati, Ali, Fatourechi, Mehrdad, Ward, Rabab K., and Birch, Gary E. A survey of signal processing algorithms in brain-computer interfaces based on electrical brain signals. J. Neural Eng., 4, June 2007.</p>
<p>[2] Bougrain, Laurent and Liang, Nanying. Band-speciﬁc features improve Finger Flexion Prediction from ECoG. In Jornadas Argentinas sobre Interfaces Cerebro Computadora - JAICC, Paran` , Argentine, 2009. a</p>
<p>[3] Chang, Mingwei, Ratinov, Lev, and Roth, Dan. Guiding semi-supervision with constraintdriven learning. In Proc. of the Annual Meeting of the ACL, 2007.</p>
<p>[4] Flamary, R´ mi and Rakotomamonjy, Alain. Decoding ﬁnger movements from ECoG signals e using switching linear models. Technical report, September 2009.</p>
<p>[5] Ganchev, Kuzman, Graca, Joao, Gillenwater, Jennifer, and Taskar, Ben. Posterior regularization for structured latent variable models. JMLR, 11(July):2001–2049, 2010.</p>
<p>[6] Hinton, Geoffrey. Training products of experts by minimizing contrastive divergence. Neural Computation, 14(8):2002, Aug 2000.</p>
<p>[7] Krusienski, Dean J, Grosse-Wentrup, Moritz, Galn, Ferran, Coyle, Damien, Miller, Kai J, Forney, Elliott, and Anderson, Charles W. Critical issues in state-of-the-art brain-computer interface signal processing. Journal of Neural Engineering, 8(2):025002, 2011.</p>
<p>[8] Kub´ nek, J, Miller, K J, Ojemann, J G, Wolpaw, J R, and Schalk, G. Decoding ﬂexion of a individual ﬁngers using electrocorticographic signals in humans. J Neural Eng, 6(6):066001– 066001, Dec 2009.</p>
<p>[9] Lafferty, John. Conditional random ﬁelds: Probabilistic models for segmenting and labeling sequence data. In NIPS, pp. 282–289. Morgan Kaufmann, 2001.</p>
<p>[10] Lefort, Riwal, Fablet, Ronan, and Boucher, Jean-Marc. Weakly supervised classiﬁcation of objects in images using soft random forests. In ECCV, pp. 185–198, 2010.</p>
<p>[11] Liang, Percy, Jordan, Michael I., and Klein, Dan. Learning from measurements in exponential families. In ICML ’09, pp. 641–648, New York, NY, USA, 2009. ACM.</p>
<p>[12] Mann, Gideon S. and McCallum, Andrew. Simple, robust, scalable semi-supervised learning via expectation regularization. In ICML, pp. 593–600, 2007.</p>
<p>[13] Mann, Gideon S. and Mccallum, Andrew. Generalized expectation criteria for semi-supervised learning of conditional random ﬁelds. In ACL’08, pp. 870–878, 2008.</p>
<p>[14] Mohamed, A., Dahl, G., and Hinton, G. Acoustic modeling using deep belief networks. Audio, Speech, and Language Processing, IEEE Transactions on, PP(99):1, 2011.</p>
<p>[15] Salzmann, Mathieu, Henrik, Carl, Raquel, Ek, and Darrell, Urtasun Trevor. Factorized orthogonal latent spaces. JMLR, 9:701–708, 2010.</p>
<p>[16] Schapire, Robert E., Rochery, Marie, Rahim, Mazin G., and Gupta, Narendra. Incorporating prior knowledge into boosting. In ICML, 2002.</p>
<p>[17] Shenoy, P., Miller, K.J., Ojemann, J.G., and Rao, R.P.N. Generalized features for electrocorticographic bcis. Biomedical Engineering, IEEE Transactions on, 55(1), jan. 2008.</p>
<p>[18] Shenoy, Pradeep, Krauledat, Matthias, Blankertz, Benjamin, Rao, Rajesh P. N., and M¨ ller, u Klaus-Robert. Towards adaptive classiﬁcation for BCI. Journal of Neural Engineering, 2006.</p>
<p>[19] Shon, Aaron P., Grochow, Keith, Hertzmann, Aaron, and Rao, Rajesh P. N. Learning shared latent structure for image synthesis and robotic imitation. In NIPS, pp. 1233–1240, 2006.</p>
<p>[20] Tarlow, Daniel and S. Zemel, Richard. Structured output learning with high order loss functions. AISTATS, 2012.</p>
<p>[21] Taskar, Ben, Guestrin, Carlos, and Koller, Daphne. Max-margin markov networks. In NIPS. MIT Press, 2003.</p>
<p>[22] Taylor, G.W., Sigal, L., Fleet, D.J., and Hinton, G.E. Dynamical binary latent variable models for 3d human pose tracking. In CVPR, pp. 631 –638, June 2010.</p>
<p>[23] Tian, Tai-Peng, Li, Rui, and Sclaroff, S. Articulated pose estimation in a learned smooth space of feasible solutions. In CVPR, pp. 50, June 2005.</p>
<p>[24] Wang, Yijun and Jung, Tzyy-Ping. A collaborative brain-computer interface for improving human performance. PLoS ONE, 6(5):e20422, 05 2011.</p>
<p>[25] Wang, Zuoguan, Ji, Qiang, Miller, Kai J., and Schalk, Gerwin. Decoding ﬁnger ﬂexion from electrocorticographic signals using a sparse gaussian process. In ICPR, pp. 3756–3759, 2010.</p>
<p>[26] Wang, Zuoguan, Schalk, Gerwin, and Ji, Qiang. Anatomically constrained decoding of ﬁnger ﬂexion from electrocorticographic signals. In NIPS, 2011.</p>
<p>[27] Yu, C.-N. and Joachims, T. Learning structural SVMs with latent variables. In ICML, 2009.</p>
<p>[28] Zhu, Xiaojin. Semi-supervised learning literature survey, 2006. URL http://pages.cs. wisc.edu/˜jerryzhu/pub/ssl_survey.pdf. 9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
