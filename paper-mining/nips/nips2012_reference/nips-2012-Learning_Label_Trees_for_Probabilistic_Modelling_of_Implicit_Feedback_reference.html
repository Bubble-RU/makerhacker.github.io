<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>178 nips-2012-Learning Label Trees for Probabilistic Modelling of Implicit Feedback</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-178" href="../nips2012/nips-2012-Learning_Label_Trees_for_Probabilistic_Modelling_of_Implicit_Feedback.html">nips2012-178</a> <a title="nips-2012-178-reference" href="#">nips2012-178-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>178 nips-2012-Learning Label Trees for Probabilistic Modelling of Implicit Feedback</h1>
<br/><p>Source: <a title="nips-2012-178-pdf" href="http://papers.nips.cc/paper/4620-learning-label-trees-for-probabilistic-modelling-of-implicit-feedback.pdf">pdf</a></p><p>Author: Andriy Mnih, Yee W. Teh</p><p>Abstract: User preferences for items can be inferred from either explicit feedback, such as item ratings, or implicit feedback, such as rental histories. Research in collaborative ﬁltering has concentrated on explicit feedback, resulting in the development of accurate and scalable models. However, since explicit feedback is often difﬁcult to collect it is important to develop effective models that take advantage of the more widely available implicit feedback. We introduce a probabilistic approach to collaborative ﬁltering with implicit feedback based on modelling the user’s item selection process. In the interests of scalability, we restrict our attention to treestructured distributions over items and develop a principled and efﬁcient algorithm for learning item trees from data. We also identify a problem with a widely used protocol for evaluating implicit feedback models and propose a way of addressing it using a small quantity of explicit feedback data. 1</p><br/>
<h2>reference text</h2><p>[1] Alina Beygelzimer, John Langford, Yuri Lifshits, Gregory B. Sorkin, and Alexander L. Strehl. Conditional probability tree estimation analysis and algorithms. In Proceedings of the 25th Conference on Uncertainty in Artiﬁcial Intelligence, 2009.</p>
<p>[2] L´ on Bottou. Large-scale machine learning with stochastic gradient descent. In Proceedings e of the 19th International Conference on Computational Statistics (COMPSTAT’2010), pages 177–187, 2010.</p>
<p>[3] J. Goodman. Classes for fast maximum entropy training. In Proceedings of ICASSP ’01, volume 1, pages 561–564, 2001.</p>
<p>[4] Yifan Hu, Yehuda Koren, and Chris Volinsky. Collaborative ﬁltering for implicit feedback datasets. In Proceedings of the 2008 Eighth IEEE International Conference on Data Mining, pages 263–272, 2008.</p>
<p>[5] Yehuda Koren. Factorization meets the neighborhood: a multifaceted collaborative ﬁltering model. In Proceeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 426–434, 2008.</p>
<p>[6] Benjamin Marlin. Collaborative ﬁltering: A machine learning perspective. Master’s thesis, University of Toronto, 2004.</p>
<p>[7] Andriy Mnih and Geoffrey Hinton. A scalable hierarchical distributed language model. In Advances in Neural Information Processing Systems, volume 21, 2009.</p>
<p>[8] Frederic Morin and Yoshua Bengio. Hierarchical probabilistic neural network language model. In AISTATS’05, pages 246–252, 2005.</p>
<p>[9] Rong Pan and Martin Scholz. Mind the gaps: weighting the unknown in large-scale one-class collaborative ﬁltering. In KDD, pages 667–676, 2009.</p>
<p>[10] Rong Pan, Yunhong Zhou, Bin Cao, Nathan Nan Liu, Rajan M. Lukose, Martin Scholz, and Qiang Yang. One-class collaborative ﬁltering. In ICDM, pages 502–511, 2008.</p>
<p>[11] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Schmidt-Thieme Lars. BPR: Bayesian personalized ranking from implicit feedback. In UAI ’09, pages 452–461, 2009.</p>
<p>[12] Ruslan Salakhutdinov and Andriy Mnih. Probabilistic matrix factorization. In Advances in Neural Information Processing Systems, volume 20, 2008.</p>
<p>[13] Nathan Srebro, Jason D. M. Rennie, and Tommi Jaakkola. Maximum-margin matrix factorization. In Advances in Neural Information Processing Systems, 2004.</p>
<p>[14] Jason Weston, Samy Bengio, and David Grangier. Label embedding trees for large multi-class tasks. In Advances in Neural Information Processing Systems (NIPS), 2010.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
