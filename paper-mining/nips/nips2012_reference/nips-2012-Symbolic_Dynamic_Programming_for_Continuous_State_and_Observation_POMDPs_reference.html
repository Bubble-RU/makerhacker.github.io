<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>331 nips-2012-Symbolic Dynamic Programming for Continuous State and Observation POMDPs</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-331" href="../nips2012/nips-2012-Symbolic_Dynamic_Programming_for_Continuous_State_and_Observation_POMDPs.html">nips2012-331</a> <a title="nips-2012-331-reference" href="#">nips2012-331-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>331 nips-2012-Symbolic Dynamic Programming for Continuous State and Observation POMDPs</h1>
<br/><p>Source: <a title="nips-2012-331-pdf" href="http://papers.nips.cc/paper/4756-symbolic-dynamic-programming-for-continuous-state-and-observation-pomdps.pdf">pdf</a></p><p>Author: Zahra Zamani, Scott Sanner, Pascal Poupart, Kristian Kersting</p><p>Abstract: Point-based value iteration (PBVI) methods have proven extremely effective for ﬁnding (approximately) optimal dynamic programming solutions to partiallyobservable Markov decision processes (POMDPs) when a set of initial belief states is known. However, no PBVI work has provided exact point-based backups for both continuous state and observation spaces, which we tackle in this paper. Our key insight is that while there may be an inﬁnite number of observations, there are only a ﬁnite number of continuous observation partitionings that are relevant for optimal decision-making when a ﬁnite, ﬁxed set of reachable belief states is considered. To this end, we make two important contributions: (1) we show how previous exact symbolic dynamic programming solutions for continuous state MDPs can be generalized to continuous state POMDPs with discrete observations, and (2) we show how recently developed symbolic integration methods allow this solution to be extended to PBVI for continuous state and observation POMDPs with potentially correlated, multivariate continuous observation spaces. 1</p><br/>
<h2>reference text</h2><p>[1] Mario Agueda and Pablo Ibarguengoytia. An architecture for planning in uncertain domains. In Proceedings of the ICTAI 2002 Conference, Dallas,Texas, 2002.</p>
<p>[2] Jesse Hoey and Pascal Poupart. Solving pomdps with continuous or large discrete observation spaces. In Proceedings of the International Joint Conference on Artiﬁcial Intelligence (IJCAI), Edinburgh, Scotland, 2005.</p>
<p>[3] Leslie P. Kaelbling, Michael L. Littman, and Anthony R. Cassandra. Planning and acting in partially observable stochastic domains. Artiﬁcial Intelligence, 101:99–134, 1998.</p>
<p>[4] G. E. Monahan. Survey of partially observable markov decision processes: Theory, models, and algorithms. Management Science, 28(1):1–16, 1982.</p>
<p>[5] Joelle Pineau, Geoffrey J. Gordon, and Sebastian Thrun. Anytime point-based approximations for large pomdps. J. Artif. Intell. Res. (JAIR), 27:335–380, 2006.</p>
<p>[6] J. M. Porta, N. Vlassis, M.T.J. Spaan, and P. Poupart. Point-based value iteration for continuous pomdps. Journal of Machine Learning Research, 7:195220, 2006.</p>
<p>[7] Pascal Poupart, Kee-Eung Kim, and Dongho Kim. Closing the gap: Improved bounds on optimal pomdp solutions. In In Proceedings of the 21st International Conference on Automated Planning and Scheduling (ICAPS-11), 2011.</p>
<p>[8] Scott Sanner and Ehsan Abbasnejad. Symbolic variable elimination for discrete and continuous graphical models. In In Proceedings of the 26th AAAI Conference on Artiﬁcial Intelligence (AAAI-12), Toronto, Canada, 2012.</p>
<p>[9] Scott Sanner, Karina Valdivia Delgado, and Leliane Nunes de Barros. Symbolic dynamic programming for discrete and continuous state mdps. In Proceedings of the 27th Conference on Uncertainty in AI (UAI-2011), Barcelona, 2011.</p>
<p>[10] Trey Smith and Reid G. Simmons. Point-based POMDP algorithms: Improved analysis and implementation. In Proc. Int. Conf. on Uncertainty in Artiﬁcial Intelligence (UAI), 2005.</p>
<p>[11] M. Spaan and N. Vlassis. Perseus: Randomized point-based value iteration for pomdps. Journal of Articial Intelligence Research (JAIR), page 195220, 2005.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
