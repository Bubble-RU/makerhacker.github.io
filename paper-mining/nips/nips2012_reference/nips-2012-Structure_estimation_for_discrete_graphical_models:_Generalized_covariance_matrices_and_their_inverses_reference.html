<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>326 nips-2012-Structure estimation for discrete graphical models: Generalized covariance matrices and their inverses</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-326" href="../nips2012/nips-2012-Structure_estimation_for_discrete_graphical_models%3A_Generalized_covariance_matrices_and_their_inverses.html">nips2012-326</a> <a title="nips-2012-326-reference" href="#">nips2012-326-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>326 nips-2012-Structure estimation for discrete graphical models: Generalized covariance matrices and their inverses</h1>
<br/><p>Source: <a title="nips-2012-326-pdf" href="http://papers.nips.cc/paper/4584-structure-estimation-for-discrete-graphical-models-generalized-covariance-matrices-and-their-inverses.pdf">pdf</a></p><p>Author: Po-ling Loh, Martin J. Wainwright</p><p>Abstract: We investigate a curious relationship between the structure of a discrete graphical model and the support of the inverse of a generalized covariance matrix. We show that for certain graph structures, the support of the inverse covariance matrix of indicator variables on the vertices of a graph reﬂects the conditional independence structure of the graph. Our work extends results that have previously been established only in the context of multivariate Gaussian graphical models, thereby addressing an open question about the signiﬁcance of the inverse covariance matrix of a non-Gaussian distribution. Based on our population-level results, we show how the graphical Lasso may be used to recover the edge structure of certain classes of discrete graphical models, and present simulations to verify our theoretical results. 1</p><br/>
<h2>reference text</h2><p>[1] M.E.J. Newman and D.J. Watts. Scaling and percolation in the small-world network model. Phys. Rev. E, 60(6):7332–7342, December 1999.</p>
<p>[2] T. Cai, W. Liu, and X. Luo. A constrained 1 minimization approach to sparse precision matrix estimation. Journal of the American Statistical Association, 106:594–607, 2011.</p>
<p>[3] N. Meinshausen and P. B¨ hlmann. High-dimensional graphs and variable selection with the u Lasso. Annals of Statistics, 34:1436–1462, 2006.</p>
<p>[4] P. Ravikumar, M. J. Wainwright, G. Raskutti, and B. Yu. High-dimensional covariance estimation by minimizing 1 -penalized log-determinant divergence. Electronic Journal of Statistics, 4:935–980, 2011.</p>
<p>[5] M. Yuan. High-dimensional inverse covariance matrix estimation via linear programming. Journal of Machine Learning Research, 99:2261–2286, August 2010.</p>
<p>[6] H. Liu, F. Han, M. Yuan, J.D. Lafferty, and L.A. Wasserman. High dimensional semiparametric Gaussian copula graphical models. arXiv e-prints, March 2012. Available at http://arxiv.org/abs/1202.2169.</p>
<p>[7] H. Liu, J.D. Lafferty, and L.A. Wasserman. The nonparanormal: Semiparametric estimation of high dimensional undirected graphs. Journal of Machine Learning Research, 10:2295–2328, 2009.</p>
<p>[8] C.I. Chow and C.N. Liu. Approximating discrete probability distributions with dependence trees. IEEE Transactions on Information Theory, 14:462–467, 1968.</p>
<p>[9] A. Jalali, P.D. Ravikumar, V. Vasuki, and S. Sanghavi. On learning discrete graphical models using group-sparse regularization. Journal of Machine Learning Research - Proceedings Track, 15:378–387, 2011.</p>
<p>[10] P. Ravikumar, M.J. Wainwright, and J.D. Lafferty. High-dimensional Ising model selection using 1 -regularized logistic regression. Annals of Statistics, 38:1287, 2010.</p>
<p>[11] A. Anandkumar, V.Y.F. Tan, and A.S. Willsky. High-dimensional structure learning of Ising models: Local separation criterion. Annals of Statistics, 40(3):1346–1375, 2012.</p>
<p>[12] G. Bresler, E. Mossel, and A. Sly. Reconstruction of markov random ﬁelds from samples: Some observations and algorithms. In APPROX-RANDOM, pages 343–356, 2008.</p>
<p>[13] P. Loh and M.J. Wainwright. Structure estimation for discrete graphical models: Generalized covariance matrices and their inverses. arXiv e-prints, November 2012.</p>
<p>[14] S.L. Lauritzen. Graphical Models. Oxford University Press, 1996.</p>
<p>[15] M. J. Wainwright and M. I. Jordan. Graphical models, exponential families, and variational inference. Found. Trends Mach. Learn., 1(1-2):1–305, January 2008.</p>
<p>[16] R. T. Rockafellar. Convex Analysis. Princeton University Press, Princeton, 1970.</p>
<p>[17] R. A. Horn and C. R. Johnson. Matrix Analysis. Cambridge University Press, 1990.</p>
<p>[18] O. Banerjee, L. El Ghaoui, and A. d’Aspremont. Model selection through sparse maximum likelihood estimation for multivariate Gaussian or binary data. Journal of Machine Learning Research, 9:485–516, 2008.</p>
<p>[19] J. Friedman, T. Hastie, and R. Tibshirani. Sparse inverse covariance estimation with the graphical Lasso. Biostatistics, 9(3):432–441, July 2008.</p>
<p>[20] M. Yuan and Y. Lin. Model selection and estimation in the Gaussian graphical model. Biometrika, 94(1):19–35, 2007.</p>
<p>[21] Narayana P. Santhanam and Martin J. Wainwright. Information-theoretic limits of selecting binary graphical models in high dimensions. IEEE Transactions on Information Theory, 58(7):4117–4134, 2012.</p>
<p>[22] P. Loh and M.J. Wainwright. High-dimensional regression with noisy and missing data: Provable guarantees with non-convexity. Annals of Statistics, 40(3):1637–1664, 2012.</p>
<p>[23] L. Jacob, G. Obozinski, and J. P. Vert. Group Lasso with Overlap and Graph Lasso. In International Conference on Machine Learning (ICML), pages 433–440, 2009.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
