<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>302 nips-2012-Scaling MPE Inference for Constrained Continuous Markov Random Fields with Consensus Optimization</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-302" href="../nips2012/nips-2012-Scaling_MPE_Inference_for_Constrained_Continuous_Markov_Random_Fields_with_Consensus_Optimization.html">nips2012-302</a> <a title="nips-2012-302-reference" href="#">nips2012-302-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>302 nips-2012-Scaling MPE Inference for Constrained Continuous Markov Random Fields with Consensus Optimization</h1>
<br/><p>Source: <a title="nips-2012-302-pdf" href="http://papers.nips.cc/paper/4772-scaling-mpe-inference-for-constrained-continuous-markov-random-fields-with-consensus-optimization.pdf">pdf</a></p><p>Author: Stephen Bach, Matthias Broecheler, Lise Getoor, Dianne O'leary</p><p>Abstract: Probabilistic graphical models are powerful tools for analyzing constrained, continuous domains. However, ﬁnding most-probable explanations (MPEs) in these models can be computationally expensive. In this paper, we improve the scalability of MPE inference in a class of graphical models with piecewise-linear and piecewise-quadratic dependencies and linear constraints over continuous domains. We derive algorithms based on a consensus-optimization framework and demonstrate their superior performance over state of the art. We show empirically that in a large-scale voter-preference modeling problem our algorithms scale linearly in the number of dependencies and constraints. 1</p><br/>
<h2>reference text</h2><p>[1] D. Koller and N. Friedman. Probabilistic Graphical Models: Principles and Techniques. The MIT Press, 2009.</p>
<p>[2] M. Broecheler and L. Getoor. Computing marginal distributions over continuous Markov networks for statistical relational learning. In Advances in Neural Information Processing Systems (NIPS), 2010. 8</p>
<p>[3] M. Broecheler, L. Mihalkova, and L. Getoor. Probabilistic similarity logic. In Proceedings of the 26th Conference on Uncertainty in Artiﬁcial Intelligence (UAI), 2010.</p>
<p>[4] M. Broecheler, P. Shakarian, and V. S. Subrahmanian. A scalable framework for modeling competitive diffusion in social networks. In Proceedings of the Second International Conference on Social Computing (SocialCom), 2010.</p>
<p>[5] S. H. Bach, M. Broecheler, S. Kok, and L. Getoor. Decision-driven models with probabilistic soft logic. In NIPS Workshop on Predictive Models in Personalized Medicine, 2010.</p>
<p>[6] B. Huang, A. Kimmig, L. Getoor, and J. Golbeck. Probabilistic soft logic for trust analysis in social networks. In International Workshop on Statistical Relational Artiﬁcial Intelligence (StaRAI), 2012.</p>
<p>[7] B. Huang, S. H. Bach, E. Norris, J. Pujara, and L. Getoor. Social group modeling with probabilistic soft logic. In NIPS Workshop on Social Network and Social Media Analysis: Methods, Models, and Applications, 2012.</p>
<p>[8] S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein. Distributed Optimization and Statistical Learning Via the Alternating Direction Method of Multipliers. Now Publishers, 2011.</p>
<p>[9] A. Martins, M. Figueiredo, P. Aguiar, N. Smith, and E. Xing. An augmented Lagrangian approach to constrained MAP inference. In Proceedings of the 28th International Conference on Machine Learning (ICML), 2011.</p>
<p>[10] O. Meshi and A. Globerson. An alternating direction method for dual MAP LP relaxation. In Proceedings of the 2011 European conference on machine learning and knowledge discovery in databases (ECML), 2011. ´e</p>
<p>[11] R. Glowinski and A. Marrocco. Sur l’approximation, par el´ ments ﬁnis d’ordre un, et la r´ solution, par p´ nalisation-dualit´ , d’une classe de probl` mes de Dirichlet non lin´ aires. Ree e e e e vue francaise d’automatique, informatique, recherche op´ rationnelle, 9(2):41–76, 1975. ¸ e</p>
<p>[12] D. Gabay and B. Mercier. A dual algorithm for the solution of nonlinear variational problems via ﬁnite element approximation. Computers & Mathematics with Applications, 2(1):17–40, 1976.</p>
<p>[13] D. Gabay. Applications of the method of multipliers to variational inequalities, volume 15, chapter 9, pages 299–331. Elsevier, 1983.</p>
<p>[14] J. Eckstein and D. P. Bertsekas. On the Douglas-Rachford splitting method and the proximal point algorithm for maximal monotone operators. Math. Program., 55(3):293–318, 1992.</p>
<p>[15] D. Sontag, A. Globerson, and T. Jaakkola. Introduction to dual decomposition for inference, chapter 8, pages 219–254. MIT Press, 2011.</p>
<p>[16] P. Ravikumar, A. Agarwal, and M. J. Wainwright. Message-passing for graph-structured linear programs: proximal methods and rounding schemes. Journal of Machine Learning Research, 11:1043–1080, 2010.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
