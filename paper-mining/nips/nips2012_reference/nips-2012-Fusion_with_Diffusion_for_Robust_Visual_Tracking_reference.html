<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>140 nips-2012-Fusion with Diffusion for Robust Visual Tracking</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-140" href="../nips2012/nips-2012-Fusion_with_Diffusion_for_Robust_Visual_Tracking.html">nips2012-140</a> <a title="nips-2012-140-reference" href="#">nips2012-140-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>140 nips-2012-Fusion with Diffusion for Robust Visual Tracking</h1>
<br/><p>Source: <a title="nips-2012-140-pdf" href="http://papers.nips.cc/paper/4792-fusion-with-diffusion-for-robust-visual-tracking.pdf">pdf</a></p><p>Author: Yu Zhou, Xiang Bai, Wenyu Liu, Longin J. Latecki</p><p>Abstract: A weighted graph is used as an underlying structure of many algorithms like semisupervised learning and spectral clustering. If the edge weights are determined by a single similarity measure, then it hard if not impossible to capture all relevant aspects of similarity when using a single similarity measure. In particular, in the case of visual object matching it is beneﬁcial to integrate different similarity measures that focus on different visual representations. In this paper, a novel approach to integrate multiple similarity measures is proposed. First pairs of similarity measures are combined with a diffusion process on their tensor product graph (TPG). Hence the diffused similarity of each pair of objects becomes a function of joint diffusion of the two original similarities, which in turn depends on the neighborhood structure of the TPG. We call this process Fusion with Diffusion (FD). However, a higher order graph like the TPG usually means signiﬁcant increase in time complexity. This is not the case in the proposed approach. A key feature of our approach is that the time complexity of the diffusion on the TPG is the same as the diffusion process on each of the original graphs. Moreover, it is not necessary to explicitly construct the TPG in our framework. Finally all diffused pairs of similarity measures are combined as a weighted sum. We demonstrate the advantages of the proposed approach on the task of visual tracking, where different aspects of the appearance similarity between the target object in frame t − 1 and target object candidates in frame t are integrated. The obtained method is tested on several challenge video sequences and the experimental results show that it outperforms state-of-the-art tracking methods. 1</p><br/>
<h2>reference text</h2><p>[1] A. Adam, E. Rivlin, and I. Shimshoni. Robust fragment-based tracking using the integral histogram. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition(CVPR), pages 798–805, 2006.</p>
<p>[2] S. Avidan. Support vector tracking. IEEE Transactions on Pattern Analysis and Machine Intelligence, 26(8):1064–1072, 2004.</p>
<p>[3] S. Avidan. Ensemble tracking. IEEE Transactions on Pattern Analysis and Machine Intelligence, 29(2):261–271, 2007.</p>
<p>[4] B. Babenko, M. Yang, and S. Belongie. Robust object tracking with online multiple instance learning. IEEE Transactions on Pattern Analysis and Machine Intelligence, 33(8):1619–1632, 2011.</p>
<p>[5] X. Bai, B. Wang, C. Yao, W. Liu, and Z. Tu. Co-transduction for shape retrieval. IEEE Transactions on Image Processing, 21(5):2747–2757, 2012.</p>
<p>[6] X. Bai, X. Yang, L. J. Latecki, W. Liu, and Z. Tu. Learning context sensitive shape similarity by graph transduction. IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(5):861–874, 2010.</p>
<p>[7] M. Belkin and P. Niyogi. Semi-supervised learning on riemannian manifolds. Machine Learning, 56(special Issue on clustering):209–239, 2004.</p>
<p>[8] D. Comaniciu, V. R. Member, and P. Meer. Kernel-based object tracking. IEEE Transactions on Pattern Analysis and Machine Intelligence, 25(5):564–575, 2003.</p>
<p>[9] N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition(CVPR), pages 886–893, 2005.</p>
<p>[10] H. Grabner, M. Grabner, and H. Bischof. Real-time tracking via on-line boosting. In British Machine Vision Conference(BMVC), pages 47–56, 2006.</p>
<p>[11] H. Grabner, C. Leistner, and H. Bischof. Semi-supervised on-line boosting for robust tracking. In European Conference on Computer Vision(ECCV), pages 234–247, 2008.</p>
<p>[12] N. Jiang, W. Liu, and Y. Wu. Learning adaptive metric for robust visual tracking. IEEE Transactions on Image Processing, 20(8):2288–2300, 2011.</p>
<p>[13] J. Kwon and K. M. Lee. Visual tracking decomposition. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition(CVPR), 2010.</p>
<p>[14] J. Lim, D. Ross, R.-S. Lin, and M.-H. Yang. Incremental learning for visual tracking. In Advances in Neural Information Processing Systems (NIPS), 2005.</p>
<p>[15] R. Liu, J. Cheng, and H. Lu. A robust boosting tracker with minimum error bound in a co-training framework. In IEEE Interestial Conference on Computer Vision(ICCV), 2009.</p>
<p>[16] X. Mei and H. Ling. Robust visual tracking and vehicle classiﬁcation via sparse representation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 33(11):2259–2272, 2011.</p>
<p>[17] X. Mei, H. Ling, Y. Wu, E. Blasch, and L. Bai. Minimum error bounded efﬁcient l1 tracker with occlusion detection. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2011.</p>
<p>[18] T. Ojala, M. Pietik¨ inen, and T. M¨ enp¨ a. Multiresolution gray-scale and rotation invariant texture clasa a a¨ siﬁcation with local binary patterns. IEEE Transactions on Pattern Analysis and Machine Intelligence, 24(7):971–987, 2002.</p>
<p>[19] D. Ross, J. Kim, R.-S. Lin, and M.-H. Yang. Incremental learning for robust visual tracking. International Journal of Computer Vision, 77(1):125–141, 2008.</p>
<p>[20] J. Santner, C. Leistner, A. Saffari, T. Pock, and H. Bischof. Prost: Parallel robust online simple tracking. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition(CVPR), 2010.</p>
<p>[21] K. Sinha and M.Belkin. Semi-supervised learning using sparse eigenfunction bases. In Advances in Neural Information Processing Systems(NIPS), 2009.</p>
<p>[22] S. Vishwanathan, N. Schraudolph, R. Kondor, and K. Borgwardt. Graph kernels. Journal of Machine Learning Research, 11(4):1201–1242, 2010.</p>
<p>[23] B. Wang, J. Jiang, W. Wang, Z.-H. Zhou, and Z. Tu. Unsupervised metric fusion by cross diffusion. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition(CVPR), 2012.</p>
<p>[24] W. Wang and Z. Zhou. A new analysis of co-training. In Internal Conference on Machine Learning(ICML), 2010.</p>
<p>[25] Y. Wu and J. Fan. Contextual ﬂow. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition(CVPR), 2009.</p>
<p>[26] X. Yang and L. J. Latecki. Afﬁnity learning on a tensor product graph with applications to shape and image retrieval. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition(CVPR), 2011.</p>
<p>[27] W. Zhong, H. Lu, and M.-H. Yang. Robust object tracking via sparsity-based collaborative model. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2012.</p>
<p>[28] D. Zhou, O. Bousquet, T. Lal, J. Weston, and B. Scholkopf. Learning with local and global consistency. In Advances in Neural Information Processing Systems (NIPS), 2004.</p>
<p>[29] X. Zhu. Semi-supervised learning literature survey. In Technical Report 1530, Department of Computer Sciences, University of Wisconsin, Madison, 2005.  9</p>
<br/>
<br/><br/><br/></body>
</html>
