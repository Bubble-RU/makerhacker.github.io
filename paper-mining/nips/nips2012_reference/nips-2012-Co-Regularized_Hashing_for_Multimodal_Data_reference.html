<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>71 nips-2012-Co-Regularized Hashing for Multimodal Data</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-71" href="../nips2012/nips-2012-Co-Regularized_Hashing_for_Multimodal_Data.html">nips2012-71</a> <a title="nips-2012-71-reference" href="#">nips2012-71-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>71 nips-2012-Co-Regularized Hashing for Multimodal Data</h1>
<br/><p>Source: <a title="nips-2012-71-pdf" href="http://papers.nips.cc/paper/4793-co-regularized-hashing-for-multimodal-data.pdf">pdf</a></p><p>Author: Yi Zhen, Dit-Yan Yeung</p><p>Abstract: Hashing-based methods provide a very promising approach to large-scale similarity search. To obtain compact hash codes, a recent trend seeks to learn the hash functions from data automatically. In this paper, we study hash function learning in the context of multimodal data. We propose a novel multimodal hash function learning method, called Co-Regularized Hashing (CRH), based on a boosted coregularization framework. The hash functions for each bit of the hash codes are learned by solving DC (difference of convex functions) programs, while the learning for multiple bits proceeds via a boosting procedure so that the bias introduced by the hash functions can be sequentially minimized. We empirically compare CRH with two state-of-the-art multimodal hash function learning methods on two publicly available data sets. 1</p><br/>
<h2>reference text</h2><p>[1] Gregory Shakhnarovich, Trevor Darrell, and Piotr Indyk, editors. Nearest-Neighbor Methods in Learning and Vision: Theory and Practice. MIT Press, March 2006.</p>
<p>[2] Piotr Indyk and Rajeev Motwani. Approximate nearest neighbors: Towards removing the curse of dimensionality. In STOC, 1998.</p>
<p>[3] Moses Charikar. Similarity estimation techniques from rounding algorithms. In STOC, 2002.</p>
<p>[4] Alexandr Andoni and Piotr Indyk. Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. Communications of the ACM, 51(1):117–122, 2008.</p>
<p>[5] Brian Kulis and Kristen Grauman. Kernelized locality-sensitive hashing for scalable image search. In ICCV, 2009.</p>
<p>[6] Gregory Shakhnarovich, Paul Viola, and Trevor Darrell. Fast pose estimation with parameter-sensitive hashing. In ICCV, 2003.</p>
<p>[7] Ruslan Salakhutdinov and Geoffrey E. Hinton. Semantic hashing. In SIGIR Workshop on Information Retrieval and Applications of Graphical Models, 2007.</p>
<p>[8] Antonio Torralba, Rob Fergus, and Yair Weiss. Small codes and large image databases for recognition. In CVPR, 2008.</p>
<p>[9] Yair Weiss, Antonio Torralba, and Rob Fergus. Spectral hashing. In NIPS 21, 2008.</p>
<p>[10] Brian Kulis and Trevor Darrell. Learning to hash with binary reconstructive embeddings. In NIPS 22, 2009.</p>
<p>[11] Maxim Raginsky and Svetlana Lazebnik. Locality-sensitive binary codes from shift-invariant kernels. In NIPS 22, 2009.</p>
<p>[12] Ruei-Sung Lin, David A. Ross, and Jay Yagnik. SPEC hashing: Similarity preserving algorithm for entropy-based coding. In CVPR, 2010.</p>
<p>[13] Junfeng He, Wei Liu, and Shih-Fu Chang. Scalable similarity search with optimized kernel hashing. In KDD, 2010.</p>
<p>[14] Mohammad Norouzi and David J. Fleet. Minimal loss hashing for compact binary codes. In ICML, 2011.</p>
<p>[15] Jun Wang, Sanjiv Kumar, and Shih-Fu Chang. Semi-supervised hashing for scalable image retrieval. In CVPR, 2010.</p>
<p>[16] Yadong Mu, Jialie Shen, and Shuicheng Yan. Weakly-supervised hashing in kernel space. In CVPR, 2010.</p>
<p>[17] Dan Zhang, Fei Wang, and Luo Si. Composite hashing with multiple information sources. In SIGIR, 2011.</p>
<p>[18] Jingkuan Song, Yi Yang, Zi Huang, Heng Tao Shen, and Richang Hong. Multiple feature hashing for real-time large scale near-duplicate video retrieval. In ACM MM, 2011.</p>
<p>[19] Wei Liu, Jun Wang, Sanjiv Kumar, and Shih-Fu Chang. Hashing with graphs. In ICML, 2011.</p>
<p>[20] Michael M. Bronstein, Alexander M. Bronstein, Fabrice Michel, and Nikos Paragios. Data fusion through cross-modality metric learning using similarity-sensitive hashing. In CVPR, 2010.</p>
<p>[21] Shaishav Kumar and Raghavendra Udupa. Learning hash functions for cross-view similarity search. In IJCAI, 2011.</p>
<p>[22] A. L. Yuille and Anand Rangarajan. The concave-convex procedure (CCCP). In NIPS 14, 2001.</p>
<p>[23] Novi Quadrianto and Christoph H. Lampert. Learning multi-view neighborhood preserving projections. In ICML, 2011.</p>
<p>[24] Shai Shalev-Shwartz, Yoram Singer, and Nathan Srebro. Pegasos: Primal estimated sub-gradient solver for SVM. In ICML, 2007.</p>
<p>[25] Yoav Freund and Robert E. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of Computer and System Sciences, 55(1):119–139, 1997.</p>
<p>[26] John Shawe-Taylor and Nello Cristianini. Kernel Methods for Pattern Analysis. Cambridge University Press, 2004.</p>
<p>[27] Bernhard Sch¨ lkopf, Ralf Herbrich, and Alex J. Smola. A generalized representer theorem. In COLT, o 2001.</p>
<p>[28] David G. Lowe. Distinctive image features from scale-invariant keypoints. International Journal of Computer Vision, 60(2):91–110, 2004.</p>
<p>[29] David M. Blei, Andrew Y. Ng, and Michael I. Jordan. Latent Dirichlet allocation. Journal of Machine Learning Research, 3:993–1022, 2003.</p>
<p>[30] Tat-Seng Chua, Jinhui Tang, Richang Hong, Haojie Li, Zhiping Luo, and Yan-Tao Zheng. NUS-WIDE: A real-world web image database from National University of Singapore. In CIVR, 2009.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
