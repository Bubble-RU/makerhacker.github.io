<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>70 nips-2012-Clustering by Nonnegative Matrix Factorization Using Graph Random Walk</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-70" href="../nips2012/nips-2012-Clustering_by_Nonnegative_Matrix_Factorization_Using_Graph_Random_Walk.html">nips2012-70</a> <a title="nips-2012-70-reference" href="#">nips2012-70-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>70 nips-2012-Clustering by Nonnegative Matrix Factorization Using Graph Random Walk</h1>
<br/><p>Source: <a title="nips-2012-70-pdf" href="http://papers.nips.cc/paper/4845-clustering-by-nonnegative-matrix-factorization-using-graph-random-walk.pdf">pdf</a></p><p>Author: Zhirong Yang, Tele Hao, Onur Dikmen, Xi Chen, Erkki Oja</p><p>Abstract: Nonnegative Matrix Factorization (NMF) is a promising relaxation technique for clustering analysis. However, conventional NMF methods that directly approximate the pairwise similarities using the least square error often yield mediocre performance for data in curved manifolds because they can capture only the immediate similarities between data samples. Here we propose a new NMF clustering method which replaces the approximated matrix with its smoothed version using random walk. Our method can thus accommodate farther relationships between data samples. Furthermore, we introduce a novel regularization in the proposed objective function in order to improve over spectral clustering. The new learning objective is optimized by a multiplicative Majorization-Minimization algorithm with a scalable implementation for learning the factorizing matrix. Extensive experimental results on real-world datasets show that our method has strong performance in terms of cluster purity. 1</p><br/>
<h2>reference text</h2><p>[1] http://users.ics.aalto.fi/rozyang/nmfr/index.shtml.</p>
<p>[2] R. Arora, M. Gupta, A. Kapila, and M. Fazel. Clustering by left-stochastic matrix factorization. In ICML, 2011.</p>
<p>[3] D. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. Journal of Machine Learning Research, 3:993–1022, 2001.</p>
<p>[4] Deng Cai, Xiaofei He, Jiawei Han, and Thomas S. Huang. Graph regularized non-negative matrix factorization for data representation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 33(8):1548–1560, 2011.</p>
<p>[5] A. Cichocki, S. Cruces, and S. Amari. Generalized alpha-beta divergences and their application to robust nonnegative matrix factorization. Entropy, 13:134–170, 2011.</p>
<p>[6] I. Dhillon, Y. Guan, and B. Kulis. Kernel k-means, spectral clustering and normalized cuts. In KDD, 2004.</p>
<p>[7] C. Ding, X. He, and H. D. Simon. On the equivalence of nonnegative matrix factorization and spectral clustering. In ICDM, 2005.</p>
<p>[8] C. Ding, T. Li, and M. I. Jordan. Nonnegative matrix factorization for combinatorial optimization: Spectral clustering, graph matching, and clique ﬁnding. In ICDM, 2008.</p>
<p>[9] C. Ding, T. Li, and M. I. Jordan. Convex and semi-nonnegative matrix factorizations. IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(1):45–55, 2010.</p>
<p>[10] C. Ding, T. Li, and W. Peng. On the equivalence between non-negative matrix factorization and probabilistic laten semantic indexing. Computational Statistics and Data Analysis, 52(8):3913–3927, 2008.</p>
<p>[11] C. Ding, T. Li, W. Peng, and H. Park. Orthogonal nonnegative matrix t-factorizations for clustering. In SIGKDD, 2006.</p>
<p>[12] E. Elhamifar and R. Vidal. Sparse manifold clustering and embedding. In NIPS, 2011.</p>
<p>[13] Z. He, S. Xie, R. Zdunek, G. Zhou, and A. Cichocki. Symmetric nonnegative matrix factorization: Algorithms and applications to probabilistic clustering. IEEE Transactions on Neural Networks, 22(12):2117– 2131, 2011.</p>
<p>[14] M. Hein and T. B¨ hler. An inverse power method for nonlinear eigenproblems with applications in 1u Spectral clustering and sparse PCA. In NIPS, 2010.</p>
<p>[15] D. D. Lee and H. S. Seung. Algorithms for non-negative matrix factorization. In NIPS, 2000.</p>
<p>[16] C.-J. Lin. Projected gradient methods for non-negative matrix factorization. Neural Computation, 19:2756–2779, 2007.</p>
<p>[17] M. Maier, U. von Luxburg, and M. Hein. How the result of graph clustering methods depends on the construction of the graph. ESAIM: Probability & Statistics, 2012. in press.</p>
<p>[18] S. Mallat. Group invariant scattering. ArXiv e-prints, 2011.</p>
<p>[19] T. Minka. Estimating a dirichlet distribution, 2000.</p>
<p>[20] A. Ng, M. Jordan, and Y. Weiss. On spectral clustering: Analysis and an algorithm. In NIPS, 2001.</p>
<p>[21] J. Shi and J. Malik. Normalized cuts and image segmentation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(8):888–905, 2000.</p>
<p>[22] J. Sinkkonen, J. Aukia, and S. Kaski. Component models for large networks. ArXiv e-prints, 2008.</p>
<p>[23] Z. Yang and E. Oja. Linear and nonlinear projective nonnegative matrix factorization. IEEE Transaction on Neural Networks, 21(5):734–749, 2010.</p>
<p>[24] Z. Yang and E. Oja. Uniﬁed development of multiplicative algorithms for linear and quadratic nonnegative matrix factorization. IEEE Transactions on Neural Networks, 22(12):1878–1891, 2011.</p>
<p>[25] Z. Yang and E. Oja. Clustering by low-rank doubly stochastic matrix decomposition. In ICML, 2012.</p>
<p>[26] Z. Yang and E. Oja. Quadratic nonnegative matrix factorization. Pattern Recognition, 45(4):1500–1510, 2012.</p>
<p>[27] R. Zass and A. Shashua. A unifying approach to hard and probabilistic clustering. In ICCV, 2005.</p>
<p>[28] L. Zelnik-Manor and P. Perona. Self-tuning spectral clustering. In NIPS, 2004.</p>
<p>[29] D. Zhou, O. Bousquet, T. Lal, J. Weston, and B. Sch¨ lkopf. Learning with local and global consistency. o In NIPS, 2003.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
