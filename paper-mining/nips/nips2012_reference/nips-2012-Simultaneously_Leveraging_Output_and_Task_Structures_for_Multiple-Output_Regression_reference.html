<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>312 nips-2012-Simultaneously Leveraging Output and Task Structures for Multiple-Output Regression</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-312" href="../nips2012/nips-2012-Simultaneously_Leveraging_Output_and_Task_Structures_for_Multiple-Output_Regression.html">nips2012-312</a> <a title="nips-2012-312-reference" href="#">nips2012-312-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>312 nips-2012-Simultaneously Leveraging Output and Task Structures for Multiple-Output Regression</h1>
<br/><p>Source: <a title="nips-2012-312-pdf" href="http://papers.nips.cc/paper/4501-simultaneously-leveraging-output-and-task-structures-for-multiple-output-regression.pdf">pdf</a></p><p>Author: Piyush Rai, Abhishek Kumar, Hal Daume</p><p>Abstract: Multiple-output regression models require estimating multiple parameters, one for each output. Structural regularization is usually employed to improve parameter estimation in such models. In this paper, we present a multiple-output regression model that leverages the covariance structure of the latent model parameters as well as the conditional covariance structure of the observed outputs. This is in contrast with existing methods that usually take into account only one of these structures. More importantly, unlike some of the other existing methods, none of these structures need be known a priori in our model, and are learned from the data. Several previously proposed structural regularization based multiple-output regression models turn out to be special cases of our model. Moreover, in addition to being a rich model for multiple-output regression, our model can also be used in estimating the graphical model structure of a set of variables (multivariate outputs) conditioned on another set of variables (inputs). Experimental results on both synthetic and real datasets demonstrate the effectiveness of our method. 1</p><br/>
<h2>reference text</h2><p>[1] M. Aldrin. Moderate projection pursuit regression for multivariate response data. Computational Statistics and Data Analysis, 21, 1996.</p>
<p>[2] Andreas Argyriou, Theodoros Evgeniou, and Massimiliano Pontil. Multi-task feature learning. In NIPS, 2007.</p>
<p>[3] L. Breiman and J.H. Friedman. Predicting multivariate responses in multiple linear regression. Journal of the Royal Statistical Society. Series B (Methodological), pages 3–54, 1997.</p>
<p>[4] T. Cai, H. Li, W. Liu, and J. Xie. Covariate adjusted precision matrix estimation with an application in genetical genomics. Biometrika, 2011.</p>
<p>[5] Rich Caruana. Multitask Learning. Machine Learning, 28, 1997.</p>
<p>[6] J. Cheng, E. Levina, P. Wang, and J. Zhu. Sparse ising models with covariates. arXiv:1209.6342v1, 2012.</p>
<p>[7] S. Ding, G. Wahba, and J. X. Zhu. Learning higher-order graph structure with features by structure penalty. In NIPS, 2011.</p>
<p>[8] J. Friedman, T. Hastie, and R. Tibshirani. Sparse inverse covariance estimation with the graphical lasso. Biostatistics, 9(3):432–441, 2008.</p>
<p>[9] P. Goovaerts. Geostatistics For Natural Resources Evaluation. Oxford University Press, 1997.</p>
<p>[10] T. Heskes. Empirical Bayes for learning to learn. ICML, 2000.</p>
<p>[11] S. Kim, K. Sohn, and E. P. Xing. A multivariate regression approach to association analysis of a quantitative trait network.</p>
<p>[12] S. Kim and E. P. Xing. Statistical estimation of correlated genome associations to a quantitative trait network. PLoS Genetics, 2009.</p>
<p>[13] S. Kim and E. P. Xing. Tree-guided group lasso for multi-response regression with structured sparsity, with an application to eQTL mapping. Annals of Applied Statistics, 2012.</p>
<p>[14] W. Lee and Y. Liu. Simultaneous multiple response regression and inverse covariance matrix estimation via penalized gaussian maximum likelihood. Journal of Multivariate Analysis, 2012.</p>
<p>[15] H. Liu, X. Chen, J. Lafferty, and L. Wasserman. Graph-valued regression. In NIPS, 2010.</p>
<p>[16] G. Obozinskiy, M. J. Wainwright, and M. I. Jordan. Union support recovery in highdimensional multivariate regression. In NIPS, 2010.</p>
<p>[17] A. J. Rothman, E. Levina, and J. Zhu. Sparse multivariate regression with covariance estimation. Journal of Computational and Graphical Statistics, 2010.</p>
<p>[18] K.A. Sohn and S. Kim. Joint estimation of structured sparsity and output structure in multipleoutput regression via inverse-covariance regularization. In AISTATS, 2012.</p>
<p>[19] R. Tibshirani. Regression shrinkage and selection via the lasso. Journal of Royal Statistical Society, 1996.</p>
<p>[20] J. Yin and H. Li. A sparse conditional gaussian graphical model for analysis of genetical genomics data. The Annals of Applied Statistics, 2011.</p>
<p>[21] Y. Zhang and J. Schneider. Learning Multiple Tasks with a Sparse Matrix-Normal Penalty. In NIPS, 2010.</p>
<p>[22] Y. Zhang and D. Yeung. A convex formulation for learning task relationships in multi-task learning. In UAI, 2010.</p>
<p>[23] S. Zhou, J. Lafferty, and L. Wasserman. Time varying undirected graphs. Machine Learning Journal, 2010.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
