<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>168 nips-2012-Kernel Latent SVM for Visual Recognition</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-168" href="../nips2012/nips-2012-Kernel_Latent_SVM_for_Visual_Recognition.html">nips2012-168</a> <a title="nips-2012-168-reference" href="#">nips2012-168-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>168 nips-2012-Kernel Latent SVM for Visual Recognition</h1>
<br/><p>Source: <a title="nips-2012-168-pdf" href="http://papers.nips.cc/paper/4590-kernel-latent-svm-for-visual-recognition.pdf">pdf</a></p><p>Author: Weilong Yang, Yang Wang, Arash Vahdat, Greg Mori</p><p>Abstract: Latent SVMs (LSVMs) are a class of powerful tools that have been successfully applied to many applications in computer vision. However, a limitation of LSVMs is that they rely on linear models. For many computer vision tasks, linear models are suboptimal and nonlinear models learned with kernels typically perform much better. Therefore it is desirable to develop the kernel version of LSVM. In this paper, we propose kernel latent SVM (KLSVM) – a new learning framework that combines latent SVMs and kernel methods. We develop an iterative training algorithm to learn the model parameters. We demonstrate the effectiveness of KLSVM using three different applications in visual recognition. Our KLSVM formulation is very general and can be applied to solve a wide range of applications in computer vision and machine learning. 1</p><br/>
<h2>reference text</h2><p>[1] C. J. Burges. A tutorial on support vector machines for pattern recognition. Data Mining and Knowledge Discovery, 2(2):121–167, 1998.</p>
<p>[2] N. Dalal and B. Triggs. Histogram of oriented gradients for human detection. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2005.</p>
<p>[3] V. Delaitre, I. Laptev, and J. Sivic. Recognizing human actions in still images: a study of bag-of-features and part-based representations. In British Machine Vision Conference, 2010.</p>
<p>[4] C. Desai, D. Ramanan, and C. Fowlkes. Discriminative models for multi-class object layout. In IEEE International Conference on Computer Vision, 2009.</p>
<p>[5] P. F. Felzenszwalb, R. B. Girshick, D. McAllester, and D. Ramanan. Object detection with discriminatively trained part based models. IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(9):1672–1645, 2010.</p>
<p>[6] C. Gu and X. Ren. Discriminative mixture-of-templates for viewpoint classiﬁcation. In European Conference on Computer Vision, 2010.</p>
<p>[7] A. Krizhevsky. Learning multiple layers of features from tiny images. Master’s thesis, University of Toronto, 2009.</p>
<p>[8] M. P. Kumar, B. Packer, and D. Koller. Self-paced learning for latent variable models. In Advances in Neural Information Processing Systems, 2010.</p>
<p>[9] G. R. G. Lanckriet, N. Cristianini, P. Bartlett, L. R. Ghaoui, and M. I. Jordan. Learning the kernel matrix with semideﬁnite programming. Journal of Machine Learning Research, 5:24–72, 2004.</p>
<p>[10] S. Maji, A. C. Berg, and J. Malik. Classiﬁcation using intersection kernel support vector machines is efﬁcient. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2008.</p>
<p>[11] M. A. Sadeghi and A. Farhadi. Recognition using visual phrases. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2011.</p>
<p>[12] B. Taskar, C. Guestrin, and D. Koller. Max-margin markov networks. In Advances in Neural Information Processing Systems, volume 16. MIT Press, 2004.</p>
<p>[13] I. Tsochantaridis, T. Joachims, T. Hofmann, and Y. Altun. Large margin methods for structured and interdependent output variables. Journal of Machine Learning Research, 6:1453–1484, 2005.</p>
<p>[14] A. Vedaldi and A. Zisserman. Efﬁcient additive kernels via explicit feature maps. Pattern Analysis and Machine Intellingence, 34(3), 2012.</p>
<p>[15] L. Xu, J. Neufeldand, B. Larson, and D. Schuurmans. Maximum margin clustering. In L. K. Saul, Y. Weiss, and L. Bottou, editors, Advances in Neural Information Processing Systems, volume 17, pages 1537–1544. MIT Press, Cambridge, MA, 2005.</p>
<p>[16] W. Yang and G. Toderici. Discriminative tag learning on youtube videos with latent sub-tags. In IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2011.</p>
<p>[17] C.-N. Yu and T. Joachims. Learning structural SVMs with latent variables. In International Conference on Machine Learning, 2009.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
