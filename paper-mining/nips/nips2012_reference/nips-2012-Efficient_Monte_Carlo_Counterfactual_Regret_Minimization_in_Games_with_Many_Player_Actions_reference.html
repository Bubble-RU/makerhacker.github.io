<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>109 nips-2012-Efficient Monte Carlo Counterfactual Regret Minimization in Games with Many Player Actions</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-109" href="../nips2012/nips-2012-Efficient_Monte_Carlo_Counterfactual_Regret_Minimization_in_Games_with_Many_Player_Actions.html">nips2012-109</a> <a title="nips-2012-109-reference" href="#">nips2012-109-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>109 nips-2012-Efficient Monte Carlo Counterfactual Regret Minimization in Games with Many Player Actions</h1>
<br/><p>Source: <a title="nips-2012-109-pdf" href="http://papers.nips.cc/paper/4569-efficient-monte-carlo-counterfactual-regret-minimization-in-games-with-many-player-actions.pdf">pdf</a></p><p>Author: Neil Burch, Marc Lanctot, Duane Szafron, Richard G. Gibson</p><p>Abstract: Counterfactual Regret Minimization (CFR) is a popular, iterative algorithm for computing strategies in extensive-form games. The Monte Carlo CFR (MCCFR) variants reduce the per iteration time cost of CFR by traversing a smaller, sampled portion of the tree. The previous most effective instances of MCCFR can still be very slow in games with many player actions since they sample every action for a given player. In this paper, we present a new MCCFR algorithm, Average Strategy Sampling (AS), that samples a subset of the player’s actions according to the player’s average strategy. Our new algorithm is inspired by a new, tighter bound on the number of iterations required by CFR to converge to a given solution quality. In addition, we prove a similar, tighter bound for AS and other popular MCCFR variants. Finally, we validate our work by demonstrating that AS converges faster than previous MCCFR algorithms in both no-limit poker and Bluff. 1</p><br/>
<h2>reference text</h2><p>[1] Nick Abou Risk and Duane Szafron. Using counterfactual regret minimization to create competitive multiplayer poker agents. In Ninth International Conference on Autonomous Agents and Multiagent Systems (AAMAS), pages 159–166, 2010.</p>
<p>[2] Richard Gibson, Marc Lanctot, Neil Burch, Duane Szafron, and Michael Bowling. Generalized sampling and variance in counterfactual regret minimization. In Twenty-Sixth Conference on Artiﬁcial Intelligence (AAAI), pages 1355–1361, 2012.</p>
<p>[3] Richard Gibson and Duane Szafron. On strategy stitching in large extensive form multiplayer games. In Advances in Neural Information Processing Systems 24 (NIPS), pages 100–108, 2011.</p>
<p>[4] Andrew Gilpin and Tuomas Sandholm. A competitive Texas Hold’em poker player via automated abstraction and real-time equilibrium computation. In Twenty-First Conference on Artiﬁcial Intelligence (AAAI), pages 1007–1013, 2006.</p>
<p>[5] Sergiu Hart and Andreu Mas-Colell. A simple adaptive procedure leading to correlated equilibrium. Econometrica, 68:1127–1150, 2000.</p>
<p>[6] Samid Hoda, Andrew Gilpin, Javier Pe˜a, and Tuomas Sandholm. Smoothing techniques n for computing Nash equilibria of sequential games. Mathematics of Operations Research, 35(2):494–512, 2010.</p>
<p>[7] Reiner Knizia. Dice Games Properly Explained. Blue Terrier Press, 2010.</p>
<p>[8] Daphne Koller, Nimrod Megiddo, and Bernhard von Stengel. Fast algorithms for ﬁnding randomized strategies in game trees. In Annual ACM Symposium on Theory of Computing (STOC’94), pages 750–759, 1994.</p>
<p>[9] Marc Lanctot, Kevin Waugh, Martin Zinkevich, and Michael Bowling. Monte Carlo sampling for regret minimization in extensive games. In Advances in Neural Information Processing Systems 22 (NIPS), pages 1078–1086, 2009.</p>
<p>[10] Marc Lanctot, Kevin Waugh, Martin Zinkevich, and Michael Bowling. Monte Carlo sampling for regret minimization in extensive games. Technical Report TR09-15, University of Alberta, 2009.</p>
<p>[11] Martin Zinkevich, Michael Johanson, Michael Bowling, and Carmelo Piccione. Regret minimization in games with incomplete information. Technical Report TR07-14, University of Alberta, 2007.</p>
<p>[12] Martin Zinkevich, Michael Johanson, Michael Bowling, and Carmelo Piccione. Regret minimization in games with incomplete information. In Advances in Neural Information Processing Systems 20 (NIPS), pages 905–912, 2008.  9</p>
<br/>
<br/><br/><br/></body>
</html>
