<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>58 nips-2012-Bayesian models for Large-scale Hierarchical Classification</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-58" href="../nips2012/nips-2012-Bayesian_models_for_Large-scale_Hierarchical_Classification.html">nips2012-58</a> <a title="nips-2012-58-reference" href="#">nips2012-58-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>58 nips-2012-Bayesian models for Large-scale Hierarchical Classification</h1>
<br/><p>Source: <a title="nips-2012-58-pdf" href="http://papers.nips.cc/paper/4609-bayesian-models-for-large-scale-hierarchical-classification.pdf">pdf</a></p><p>Author: Siddharth Gopal, Yiming Yang, Bing Bai, Alexandru Niculescu-mizil</p><p>Abstract: A challenging problem in hierarchical classiﬁcation is to leverage the hierarchical relations among classes for improving classiﬁcation performance. An even greater challenge is to do so in a manner that is computationally feasible for large scale problems. This paper proposes a set of Bayesian methods to model hierarchical dependencies among class labels using multivariate logistic regression. Speciﬁcally, the parent-child relationships are modeled by placing a hierarchical prior over the children nodes centered around the parameters of their parents; thereby encouraging classes nearby in the hierarchy to share similar model parameters. We present variational algorithms for tractable posterior inference in these models, and provide a parallel implementation that can comfortably handle largescale problems with hundreds of thousands of dimensions and tens of thousands of classes. We run a comparative evaluation on multiple large-scale benchmark datasets that highlights the scalability of our approach and shows improved performance over the other state-of-the-art hierarchical methods. 1</p><br/>
<h2>reference text</h2><p>[1] P.N. Bennett and N. Nguyen. Reﬁned experts: improving classiﬁcation in large taxonomies. In SIGIR, 2009.</p>
<p>[2] C.M. Bishop. Pattern recognition and machine learning.</p>
<p>[3] C.M. Bishop and M.E. Tipping. Bayesian regression and classiﬁcation. 2003.</p>
<p>[4] D. Borthakur. The hadoop distributed ﬁle system: Architecture and design. Hadoop Project Website, 11:21, 2007.</p>
<p>[5] G. Bouchard. Efﬁcient bounds for the softmax function. 2007.</p>
<p>[6] L. Cai and T. Hofmann. Hierarchical document categorization with support vector machines. In CIKM, pages 78–87. ACM, 2004.</p>
<p>[7] George Casella. Empirical bayes method - a tutorial. Technical report.</p>
<p>[8] I. Dimitrovski, D. Kocev, L. Suzana, and S. Dˇ eroski. Hierchical annotation of medical images. z In IMIS, 2008.</p>
<p>[9] C.B. Do, C.S. Foo, and A.Y. Ng. Efﬁcient multiple hyperparameter learning for log-linear models. In Neural Information Processing Systems, volume 21, 2007.</p>
<p>[10] S. Dumais and H. Chen. Hierarchical classiﬁcation of web content. In SIGIR, 2000.</p>
<p>[11] A. Gelman. Prior distributions for variance parameters in hierarchical models. BA.</p>
<p>[12] R.E. Kass and R. Natarajan. A default conjugate prior for variance components in generalized linear mixed models. Bayesian Analysis, 2006.</p>
<p>[13] D.C. Liu and J. Nocedal. On the limited memory bfgs method for large scale optimization. Mathematical programming, 45(1):503–528, 1989.</p>
<p>[14] T.Y. Liu, Y. Yang, H. Wan, H.J. Zeng, Z. Chen, and W.Y. Ma. Support vector machines classiﬁcation with a very large-scale taxonomy. ACM SIGKDD, pages 36–43, 2005.</p>
<p>[15] Z.Q. Luo and P. Tseng. On the convergence of the coordinate descent method for convex differentiable minimization. Journal of Optimization Theory and Applications, 72(1):7–35, 1992.</p>
<p>[16] D.J.C. MacKay. The evidence framework applied to classiﬁcation networks. Neural computation, 1992.</p>
<p>[17] A. McCallum, R. Rosenfeld, T. Mitchell, and A.Y. Ng. Improving text classiﬁcation by shrinkage in a hierarchy of classes. In ICML, pages 359–367, 1998.</p>
<p>[18] B. Shahbaba and R.M. Neal. Improving classiﬁcation when a class hierarchy is available using a hierarchy-based prior. Bayesian Analysis, 2(1):221–238, 2007.</p>
<p>[19] M.E. Tipping. Sparse bayesian learning and the relevance vector machine. JMLR, 1:211–244, 2001.</p>
<p>[20] I. Tsochantaridis, T. Joachims, T. Hofmann, and Y. Altun. Large margin methods for structured and interdependent output variables. JMLR, 6(2):1453, 2006.</p>
<p>[21] J. Weston and C. Watkins. Multi-class support vector machines. Technical report, 1998.</p>
<p>[22] G.R. Xue, D. Xing, Q. Yang, and Y. Yu. Deep classiﬁcation in large-scale text hierarchies. In SIGIR, pages 619–626. ACM, 2008.</p>
<p>[23] D. Zhou, L. Xiao, and M. Wu. Hierarchical classiﬁcation via orthogonal transfer. Technical report, MSR-TR-2011-54, 2011.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
