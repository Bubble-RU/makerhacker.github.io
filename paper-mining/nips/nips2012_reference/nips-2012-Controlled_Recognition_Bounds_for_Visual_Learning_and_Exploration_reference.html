<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>83 nips-2012-Controlled Recognition Bounds for Visual Learning and Exploration</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-83" href="../nips2012/nips-2012-Controlled_Recognition_Bounds_for_Visual_Learning_and_Exploration.html">nips2012-83</a> <a title="nips-2012-83-reference" href="#">nips2012-83-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>83 nips-2012-Controlled Recognition Bounds for Visual Learning and Exploration</h1>
<br/><p>Source: <a title="nips-2012-83-pdf" href="http://papers.nips.cc/paper/4594-controlled-recognition-bounds-for-visual-learning-and-exploration.pdf">pdf</a></p><p>Author: Vasiliy Karasev, Alessandro Chiuso, Stefano Soatto</p><p>Abstract: We describe the tradeoff between the performance in a visual recognition problem and the control authority that the agent can exercise on the sensing process. We focus on the problem of “visual search” of an object in an otherwise known and static scene, propose a measure of control authority, and relate it to the expected risk and its proxy (conditional entropy of the posterior density). We show this analytically, as well as empirically by simulation using the simplest known model that captures the phenomenology of image formation, including scaling and occlusions. We show that a “passive” agent given a training set can provide no guarantees on performance beyond what is afforded by the priors, and that an “omnipotent” agent, capable of inﬁnite control authority, can achieve arbitrarily good performance (asymptotically). In between these limiting cases, the tradeoff can be characterized empirically. 1</p><br/>
<h2>reference text</h2><p>[1] S. Soatto. Steps towards a theory of visual information: Active perception, signal-to-symbol conversion and the interplay between sensing and control. arXiv:1110.2053, 2011.</p>
<p>[2] R. Bajcsy. Active perception. 76(8):996–1005, 1988.</p>
<p>[3] D. H. Ballard. Animate vision. Artiﬁcial Intelligence, 48(1):57–86, 1991.</p>
<p>[4] A. Andreopoulos and J. K. Tsotsos. A theory of active object localization. In Proceedings of the IEEE International Conference on Computer Vision (ICCV), 2009.</p>
<p>[5] N. Roy, G. Gordon Gordon, and S. Thrun. Finding approximate POMDP solutions through belief compression. Journal of Artiﬁcial Intelligence Research, 23:1–40, 2005.</p>
<p>[6] H. Kopp-Borotschnig, L. Paletta, M. Prantl, and A. Pinz. Appearance-based active object recognition. Image and Vision Computing, 18(9):715–727, 2000.</p>
<p>[7] R. Eidenberger and J. Scharinger. Active perception and scene modeling by planning with probabilistic 6d object poses. In Proceedings of the IEEE International Conference on Intelligent Robots and Systems (IROS), 2010.</p>
<p>[8] J. Ma and J. W. Burdick. Dynamic sensor planning with stereo for model identiﬁcation on a mobile platform. In Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), 2010.</p>
<p>[9] G. A. Hollinger, U. Mitra, and G. S. Sukhatme. Active classiﬁcation: Theory and application to underwater inspection. In International Symposium on Robotics Research, 2011.</p>
<p>[10] Z. Jia, A. Saxena, and T. Chen. Robotic object detection: Learning to improve the classiﬁers using sparse graphs for path planning. In IJCAI, 2011.</p>
<p>[11] M. Krainin, B. Curless, and D. Fox. Autonomous generation of complete 3d object models using next best view manipulation planning. In Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), 2011.</p>
<p>[12] F. Bourgault, A. G¨ ktogan, T. Furukawa, and H. F. Durrant-Whyte. Coordinated search for a o lost target in a Bayesian world. Advanced Robotics, 18(10), 2004.</p>
<p>[13] G. M. Hoffmann and C. J. Tomlin. Mobile sensor network control using mutual information methods and particle ﬁlters. IEEE Transactions on Automatic Control, 55(1), 2010.</p>
<p>[14] A. Krause and C. Guestrin. Near-optimal nonmyopic value of information in graphical models. In Uncertainty in Artiﬁcial Intelligence, 2005.</p>
<p>[15] J.L. Williams, J.W. Fisher III, and A.S. Willsky. Performance guarantees for information theoretic active inference. AI & Statistics (AISTATS), 2007.</p>
<p>[16] L. Pronzato. Optimal experimental design and some related control problems. Automatica, 44:303–325, 2008.</p>
<p>[17] R. Bitmead. Persistence of excitation conditions and the convergence of adaptive schemes. Information Theory, IEEE Transactions on, 30(2):183 – 191, 1984.</p>
<p>[18] L. Ljung. System Identiﬁcation, Theory for the User. Prentice Hall, 1997.</p>
<p>[19] M. E. Hellman and J. Raviv. Probability of error, equivocation and the Chernoff bound. IEEE Transactions on Information Theory, 16:368–372, 1970.</p>
<p>[20] J. R. Hershey and P. A. Olsen. Approximating the Kullback Leibler divergence between Gaussian mixture models. Proceedings of the IEEE International Conference on Acoustics Speech and Signal Processing (ICASSP), 4(6), 2007.</p>
<p>[21] M. F. Huber, T. Bailey, Durrant-Whyte H., and U. D. Hanebeck. On entropy approximation for Gaussian mixture random vectors. In Proceedings of the IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI), 2008.</p>
<p>[22] L. Valente, R. Tsai, and S. Soatto. Information gathering control via exploratory path planning. In Proceedings of the Conference on Information Sciences and Systems. March 2012.</p>
<p>[23] R. Vidal, Omid Shakernia, H. J. Kim, D. H. Shim, and S. Sastry. Probabilistic pursuit-evasion games: theory, implementation, and experimental evaluation. IEEE Transactions on Robotics, 18(5), 2002.</p>
<p>[24] T. M. Cover and J. Thomas. Elements of Information Theory. Wiley, 1991. 9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
