<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>124 nips-2012-Factorial LDA: Sparse Multi-Dimensional Text Models</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-124" href="../nips2012/nips-2012-Factorial_LDA%3A_Sparse_Multi-Dimensional_Text_Models.html">nips2012-124</a> <a title="nips-2012-124-reference" href="#">nips2012-124-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>124 nips-2012-Factorial LDA: Sparse Multi-Dimensional Text Models</h1>
<br/><p>Source: <a title="nips-2012-124-pdf" href="http://papers.nips.cc/paper/4784-factorial-lda-sparse-multi-dimensional-text-models.pdf">pdf</a></p><p>Author: Michael Paul, Mark Dredze</p><p>Abstract: Latent variable models can be enriched with a multi-dimensional structure to consider the many latent factors in a text corpus, such as topic, author perspective and sentiment. We introduce factorial LDA, a multi-dimensional model in which a document is inﬂuenced by K different factors, and each word token depends on a K-dimensional vector of latent variables. Our model incorporates structured word priors and learns a sparse product of factors. Experiments on research abstracts show that our model can learn latent factors such as research topic, scientiﬁc discipline, and focus (methods vs. applications). Our modeling improvements reduce test perplexity and improve human interpretability of the discovered factors. 1</p><br/>
<h2>reference text</h2><p>[1] D. Blei, A. Ng, and M. Jordan. Latent Dirichlet allocation. JMLR, 2003.</p>
<p>[2] Q. Mei, X. Ling, M. Wondra, H. Su, and C. Zhai. Topic sentiment mixture: modeling facets and opinions in weblogs. In WWW, 2007.</p>
<p>[3] M. Paul and R. Girju. A two-dimensional topic-aspect model for discovering multi-faceted topics. In AAAI, 2010.</p>
<p>[4] J. Eisenstein, A. Ahmed, and E. P. Xing. Sparse additive generative models of text. In ICML, 2011.</p>
<p>[5] W. Y. Wang, E. Mayﬁeld, S. Naidu, and J. Dittmar. Historical analysis of legal opinions with a sparse mixed-effects latent variable model. In ACL, pages 740–749, July 2012.</p>
<p>[6] J. Chang, J. Boyd-Graber, S. Gerrish, C. Wang, and D. Blei. Reading tea leaves: How humans interpret topic models. In NIPS, 2009.</p>
<p>[7] D. Mimno and A. McCallum. Topic models conditioned on arbitrary features with dirichlet-multinomial regression. In UAI, 2008.</p>
<p>[8] T. Grifﬁths and Z. Ghahramani. Inﬁnite latent feature models and the Indian buffet process. In NIPS, 2006.</p>
<p>[9] S. Williamson, C. Wang, K. Heller, and D. Blei. The IBP-compound dirichlet process and its application to focused topic modeling. In ICML, 2010.</p>
<p>[10] A. Ahmed and E. P. Xing. Staying informed: supervised and semi-supervised multi-view topical analysis of ideological perspective. In EMNLP, pages 1140–1150, 2010.</p>
<p>[11] M. Paul and R. Girju. Cross-cultural analysis of blogs and forums with mixed-collection topic models. In EMNLP, pages 1408–1417, August 2009.</p>
<p>[12] D. Zhang, C. Zhai, J. Han, A. Srivastava, and N. Oza. Topic modeling for OLAP on multidimensional text databases: topic cube and its applications. Statistical Analysis and Data Mining, 2, 2009.</p>
<p>[13] T. Hofmann. Probabilistic latent semantic indexing. In SIGIR, 1999.</p>
<p>[14] S. Dasgupta and V. Ng. Mining clustering dimensions. In ICML, 2010.</p>
<p>[15] I. Porteous, E. Bart, and M. Welling. Multi-HDP: a non parametric Bayesian model for tensor factorization. In AAAI, pages 1487–1490, 2008.</p>
<p>[16] L. Mackey, D. Weiss, and M. I. Jordan. Mixed membership matrix factorization. In ICML, 2010.</p>
<p>[17] G. E. Hinton. Training products of experts by minimizing contrastive divergence. Neural Comput., 14:1771–1800, August 2002.</p>
<p>[18] J. Boyd-Graber and D. Blei. Syntactic topic models. In NIPS, 2008.</p>
<p>[19] M. R. Gormley, M. Dredze, B. Van Durme, and J. Eisner. Shared components topic models. In NAACL, 2010.</p>
<p>[20] C. Wang and D. Blei. Decoupling sparsity and smoothness in the discrete hierarchical Dirichlet process. In NIPS, 2009.</p>
<p>[21] L. Meier, S. van de Geer, and P. B¨ hlmann. The group lasso for logistic regression. Journal Of The Royal u Statistical Society Series B, 70(1):53–71, 2008.</p>
<p>[22] H. Wallach, D. Mimno, and A. McCallum. Rethinking LDA: Why priors matter. In NIPS, 2009.</p>
<p>[23] T. Grifﬁths and M. Steyvers. Finding scientiﬁc topics. In Proceedings of the National Academy of Sciences of the United States of America, 2004.</p>
<p>[24] M. Rosen-Zvi, T. Grifﬁths, M. Steyvers, and P. Smyth. The author-topic model for authors and documents. In UAI, 2004.</p>
<p>[25] Michael J. Paul. Mixed membership Markov models for unsupervised conversation modeling. In EMNLPCoNLL, 2012.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
