<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>166 nips-2012-Joint Modeling of a Matrix with Associated Text via Latent Binary Features</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-166" href="../nips2012/nips-2012-Joint_Modeling_of_a_Matrix_with_Associated_Text_via_Latent_Binary_Features.html">nips2012-166</a> <a title="nips-2012-166-reference" href="#">nips2012-166-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>166 nips-2012-Joint Modeling of a Matrix with Associated Text via Latent Binary Features</h1>
<br/><p>Source: <a title="nips-2012-166-pdf" href="http://papers.nips.cc/paper/4788-joint-modeling-of-a-matrix-with-associated-text-via-latent-binary-features.pdf">pdf</a></p><p>Author: Xianxing Zhang, Lawrence Carin</p><p>Abstract: A new methodology is developed for joint analysis of a matrix and accompanying documents, with the documents associated with the matrix rows/columns. The documents are modeled with a focused topic model, inferring interpretable latent binary features for each document. A new matrix decomposition is developed, with latent binary features associated with the rows/columns, and with imposition of a low-rank constraint. The matrix decomposition and topic model are coupled by sharing the latent binary feature vectors associated with each. The model is applied to roll-call data, with the associated documents deﬁned by the legislation. Advantages of the proposed model are demonstrated for prediction of votes on a new piece of legislation, based only on the observed text of legislation. The coupling of the text and legislation is also shown to yield insight into the properties of the matrix decomposition for roll-call data. 1</p><br/>
<h2>reference text</h2><p>[1] D. Agarwal and B. Chen. fLDA: matrix factorization through latent Dirichlet allocation. In WSDM, 2010.</p>
<p>[2] J. H. Albert and S. Chib. Bayesian analysis of binary and polychotomous response data. Journal of the American Statistical Association, 1993.</p>
<p>[3] A. Bhattacharya and D. B. Dunson. Sparse Bayesian inﬁnite factor models. Biometrika, 2011.</p>
<p>[4] D. M. Blei and Jon D. McAuliffe. Supervised topic models. In Advances in Neural Information Processing Systems, 2007.</p>
<p>[5] D. M. Blei, A. Ng, and M. I. Jordan. Latent Dirichlet allocation. JMLR, 2003.</p>
<p>[6] J. Clinton, S. Jackman, and D. Rivers. The statistical analysis of roll call data. Am. Political Sc. Review, 2004.</p>
<p>[7] T. Ferguson. A Bayesian analysis of some nonparametric problems. The Annals of Statistics, 1973.</p>
<p>[8] S. Gerrish and D.M. Blei. Predicting legislative roll calls from text. In ICML, 2011.</p>
<p>[9] T. L. Grifﬁths and Z. Ghahramani. The indian buffet process: An introduction and review. Journal of Machine Learning Research, 12:1185–1224, 2011.</p>
<p>[10] T.L. Grifﬁths and Z. Ghahramani. Inﬁnite latent feature models and the Indian buffet process. In Advances in Neural Information Processing Systems, 2005.</p>
<p>[11] H. Ishwaran and L.F. James. Gibbs sampling methods for stick-breaking priors. J. American Statistical Association, 2001.</p>
<p>[12] P. McCullagh and J. Nelder. Generalized Linear Models. Chapman and Hall, 1989.</p>
<p>[13] E. Meeds, Z. Ghahramani, R. Neal, and S. Roweis. Modeling dyadic data with binary latent factors. In Advances in Neural Information Processing Systems. 2007.</p>
<p>[14] K. Miller, T. Grifﬁths, and M.I. Jordan. Nonparametric latent feature models for link prediction. In Advances in Neural Information Processing Systems, 2009.</p>
<p>[15] K.T. Poole. Recent developments in analytical models of voting in the U.S. congress. Am. Political Sc. Review, 1988.</p>
<p>[16] G. O. Roberts and J. S. Rosenthal. Coupling and ergodicity of adaptive MCMC. Journal of Applied Probability, 2007.</p>
<p>[17] R. Salakhutdinov and A. Mnih. Probabilistic matrix factorization. In Advances in Neural Information Processing Systems, 2007.</p>
<p>[18] R. Salakhutdinov and A. Mnih. Bayesian probabilistic matrix factorization using Markov chain Monte Carlo. In ICML, 2008.</p>
<p>[19] H. Shan and A. Banerjee. Generalized probabilistic matrix factorizations for collaborative ﬁltering. In ICDM, 2010.</p>
<p>[20] Y. W. Teh, D. Görür, and Z. Ghahramani. Stick-breaking construction for the Indian buffet process. In AISTATS, 2007.</p>
<p>[21] Y. W. Teh, M. I. Jordan, Matthew J. Beal, and D. M. Blei. Hierarchical Dirichlet processes. Journal of the American Statistical Association, 2006.</p>
<p>[22] C. Wang and D. M. Blei. Collaborative topic modeling for recommending scientiﬁc articles. In KDD, 2011.</p>
<p>[23] E. Wang, D. Liu, J. Silva, D. B. Dunson, and L. Carin. Joint analysis of time-evolving binary matrices and associated documents. In Advances in Neural Information Processing Systems, 2010.</p>
<p>[24] S. Williamson, C. Wang, K. A. Heller, and D. M. Blei. The IBP compound Dirichlet process and its application to focused topic modeling. In ICML, 2010.</p>
<p>[25] X. Zhang, D. Dunson, and L. Carin. Hierarchical topic modeling for analysis of time-evolving personal choices. In Advances in Neural Information Processing Systems 24. 2011.</p>
<p>[26] X. Zhang, D. Dunson, and L. Carin. Tree-structured inﬁnite sparse factor model. In ICML, 2011.  9</p>
<br/>
<br/><br/><br/></body>
</html>
