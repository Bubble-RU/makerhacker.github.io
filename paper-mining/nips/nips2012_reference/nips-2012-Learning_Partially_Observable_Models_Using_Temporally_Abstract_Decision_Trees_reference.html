<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>183 nips-2012-Learning Partially Observable Models Using Temporally Abstract Decision Trees</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-183" href="../nips2012/nips-2012-Learning_Partially_Observable_Models_Using_Temporally_Abstract_Decision_Trees.html">nips2012-183</a> <a title="nips-2012-183-reference" href="#">nips2012-183-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>183 nips-2012-Learning Partially Observable Models Using Temporally Abstract Decision Trees</h1>
<br/><p>Source: <a title="nips-2012-183-pdf" href="http://papers.nips.cc/paper/4662-learning-partially-observable-models-using-temporally-abstract-decision-trees.pdf">pdf</a></p><p>Author: Erik Talvitie</p><p>Abstract: This paper introduces timeline trees, which are partial models of partially observable environments. Timeline trees are given some speciﬁc predictions to make and learn a decision tree over history. The main idea of timeline trees is to use temporally abstract features to identify and split on features of key events, spread arbitrarily far apart in the past (whereas previous decision-tree-based methods have been limited to a ﬁnite sufﬁx of history). Experiments demonstrate that timeline trees can learn to make high quality predictions in complex, partially observable environments with high-dimensional observations (e.g. an arcade game). 1</p><br/>
<h2>reference text</h2><p>[1] Craig Boutilier, Thomas Dean, and Steve Hanks. Decision-theoretic planning: Structural assumptions and computational leverage. Journal of Artiﬁcial Intelligence Research, 11:1–94, 1999.</p>
<p>[2] Erik Talvitie and Satinder Singh. Simple local models for complex dynamical systems. In Advances in Neural Information Processing Systems 21 (NIPS), pages 1617–1624, 2009.</p>
<p>[3] Andrew K. McCallum. Reinforcement Learning with Selective Perception and Hidden State. PhD thesis, Rutgers University, 1995.</p>
<p>[4] Erik Talvitie and Satinder Singh. Learning to make predictions in partially observable environments without a generative model. Journal of Artiﬁcial Intelligence Research (JAIR), 42:353–392, 2011.</p>
<p>[5] Michael Littman, Richard Sutton, and Satinder Singh. Predictive representations of state. In Advances in Neural Information Processing Systems 14 (NIPS), pages 1555–1561, 2002.</p>
<p>[6] George E. Monahan. A survey of partially observable markov decisions processes: Theory, models, and algorithms. Management Science, 28(1):1–16, 1982.</p>
<p>[7] Anthony R. Cassandra, Leslie Pack Kaelbling, and Michael L. Littman. Acting optimally in partially observable stochastic domains. In Proceedings of the Twelfth National Conference on Artiﬁcial Intelligence (AAAI), volume 2, pages 1023–1028, 1994.</p>
<p>[8] Satinder Singh, Michael R. James, and Matthew R. Rudary. Predictive state representations: A new theory for modeling dynamical systems. In Uncertainty in Artiﬁcial Intelligence: Proceedings of the Twentieth Conference (UAI), pages 512–519, 2004.</p>
<p>[9] Alicia Peregrin Wolfe and Andrew G. Barto. Decision tree methods for ﬁnding reusable MDP homomorphisms. In Proceedings of the Twenty-First National Conference on Artiﬁcial Intelligence (AAAI), 2006.</p>
<p>[10] Michael Holmes and Charles Isbell. Looping sufﬁx tree-based inference of partially observable hidden state. In Proceedings of the Twenty-Third International Conference on Machine Learning (ICML), pages 409–416, 2006.</p>
<p>[11] Dana Ron, Yoram Singer, and Naftali Tishby. The power of amnesia. In Advances in Neural Information Processing Systems 6, pages 176–183, 1994.</p>
<p>[12] Monica Dinculescu and Doina Precup. Approximate predictive representations of partially observable systems. In Proceedings of the Twenty-Seventh International Conference on Machine Learning (ICML), pages 895–902, 2010.</p>
<p>[13] R. Andrew McCallum. Overcoming incomplete perception with utile distinction memory. In Proceedings of the Tenth International Conference on Machine Learning (ICML), pages 190–196, 1993.</p>
<p>[14] M. M. Hassan Mahmud. Constructing states for reinforcement learning. In Proceedings of the TwentySeventh International Conference on Machine Learning (ICML), pages 727–734, 2010.</p>
<p>[15] Erik Talvitie. Simple Partial Models for Complex Dynamical Systems. PhD thesis, University of Michigan, Ann Arbor, MI, 2010.</p>
<p>[16] J. Ross Quinlan. Induction of decision trees. Machine Learning, 1:81–106, 1986.</p>
<p>[17] J. Ross Quinlan. C4.5: Programs for Machine Learning. Morgan Kaufman Publishers Inc., San Francisco, CA, 1993.</p>
<p>[18] Lex Weaver and Nigel Tao. The optimal reward baseline for gradient-based reinforcement learning. In Uncertainty in Artiﬁcial Intelligence: Proceedings of the Seventeenth Conference (UAI), pages 538–545, 2001.</p>
<p>[19] Levente Kocsis and Csaba Szepesv´ ri. Bandit based monte-carlo planning. In Proceedings of the Sevena teenth European Conference on Machine Learning (ECML), pages 282–293, 2006.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
