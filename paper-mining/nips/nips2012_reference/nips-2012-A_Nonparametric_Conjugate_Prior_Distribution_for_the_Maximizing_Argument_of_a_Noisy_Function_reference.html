<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>13 nips-2012-A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-13" href="../nips2012/nips-2012-A_Nonparametric_Conjugate_Prior_Distribution_for_the_Maximizing_Argument_of_a_Noisy_Function.html">nips2012-13</a> <a title="nips-2012-13-reference" href="#">nips2012-13-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>13 nips-2012-A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function</h1>
<br/><p>Source: <a title="nips-2012-13-pdf" href="http://papers.nips.cc/paper/4536-a-nonparametric-conjugate-prior-distribution-for-the-maximizing-argument-of-a-noisy-function.pdf">pdf</a></p><p>Author: Pedro Ortega, Jordi Grau-moya, Tim Genewein, David Balduzzi, Daniel Braun</p><p>Abstract: We propose a novel Bayesian approach to solve stochastic optimization problems that involve ﬁnding extrema of noisy, nonlinear functions. Previous work has focused on representing possible functions explicitly, which leads to a two-step procedure of ﬁrst, doing inference over the function space and second, ﬁnding the extrema of these functions. Here we skip the representation step and directly model the distribution over extrema. To this end, we devise a non-parametric conjugate prior based on a kernel regressor. The resulting posterior distribution directly captures the uncertainty over the maximum of the unknown function. Given t observations of the function, the posterior can be evaluated efﬁciently in time O(t2 ) up to a multiplicative constant. Finally, we show how to apply our model to optimize a noisy, non-convex, high-dimensional objective function.</p><br/>
<h2>reference text</h2><p>[1] E. Brochu, V. Cora, and N. de Freitas. A tutorial on bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning. Technical Report TR-2009-023, University of British Columbia, Department of Computer Science, 2009.</p>
<p>[2] K. Rawlik, M. Toussaint, and S. Vijayakumar. Approximate inference and stochastic optimal control. arXiv:1009.3958, 2010.</p>
<p>[3] A. Shapiro. Probabilistic Constrained Optimization: Methodology and Applications, chapter Statistical Inference of Stochastic Optimization Problems, pages 282–304. Kluwer Academic Publishers, 2000.</p>
<p>[4] H.J. Kappen, V. G´ mez, and M. Opper. Optimal control as a graphical model inference probo lem. Machine Learning, 87(2):159–182, 2012.</p>
<p>[5] H.J. Kushner and G.G. Yin. Stochastic Approximation Algorithms and Applications. SpringerVerlag, 1997.</p>
<p>[6] J. Mockus. Application of bayesian approach to numerical methods of global and stochastic optimization. Journal of Global Optimization, 4(4):347–365, 1994.</p>
<p>[7] D. Lizotte. Practical Bayesian Optimization. Phd thesis, University of Alberta, 2008.</p>
<p>[8] D.R. Jones, M. Schonlau, and W.J. Welch. Efﬁcient global optimization of expensive blackbox functions. Journal of Global Optimization, 13(4):455–492, 1998.</p>
<p>[9] M.A. Osborne, R. Garnett, and S.J. Roberts. Gaussian processes for global optimization. In 3rd International Conference on Learning and Intelligent Optimization (LION3), 2009.</p>
<p>[10] N. Srinivas, A. Krause, S. Kakade, and M. Seeger. Gaussian process optimization in the bandit setting: No regret and experimental design. In International Conference on Machine Learning, 2010.</p>
<p>[11] T. Hastie, R. Tbshirani, and J. Friedman. The Elements of Statistical Learning. Springer, second edition, 2009.</p>
<p>[12] P.A. Ortega and D.A. Braun. A minimum relative entropy principle for learning and acting. Journal of Artiﬁcial Intelligence Research, 38:475–511, 2010.</p>
<p>[13] B.C. May and D.S. Leslie. Simulation studies in optimistic Bayesian sampling in contextualbandit problems. Technical Report 11:02, Statistics Group, Department of Mathematics, University of Bristol, 2011.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
