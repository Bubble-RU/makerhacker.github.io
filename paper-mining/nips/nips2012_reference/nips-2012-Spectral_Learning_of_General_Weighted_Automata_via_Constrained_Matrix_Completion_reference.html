<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>320 nips-2012-Spectral Learning of General Weighted Automata via Constrained Matrix Completion</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-320" href="../nips2012/nips-2012-Spectral_Learning_of_General_Weighted_Automata_via_Constrained_Matrix_Completion.html">nips2012-320</a> <a title="nips-2012-320-reference" href="#">nips2012-320-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>320 nips-2012-Spectral Learning of General Weighted Automata via Constrained Matrix Completion</h1>
<br/><p>Source: <a title="nips-2012-320-pdf" href="http://papers.nips.cc/paper/4697-spectral-learning-of-general-weighted-automata-via-constrained-matrix-completion.pdf">pdf</a></p><p>Author: Borja Balle, Mehryar Mohri</p><p>Abstract: Many tasks in text and speech processing and computational biology require estimating functions mapping strings to real numbers. A broad class of such functions can be deﬁned by weighted automata. Spectral methods based on the singular value decomposition of a Hankel matrix have been recently proposed for learning a probability distribution represented by a weighted automaton from a training sample drawn according to this same target distribution. In this paper, we show how spectral methods can be extended to the problem of learning a general weighted automaton from a sample generated by an arbitrary distribution. The main obstruction to this approach is that, in general, some entries of the Hankel matrix may be missing. We present a solution to this problem based on solving a constrained matrix completion problem. Combining these two ingredients, matrix completion and spectral method, a whole new family of algorithms for learning general weighted automata is obtained. We present generalization bounds for a particular algorithm in this family. The proofs rely on a joint stability analysis of matrix completion and spectral learning. 1</p><br/>
<h2>reference text</h2><p>[1] J. Albert and J. Kari. Digital image compression. In Handbook of Weighted Automata. Springer, 2009.</p>
<p>[2] A. Anandkumar, D. P. Foster, D. Hsu, S. M. Kakade, and Y-K. Liu. Two SVDs sufﬁce: Spectral decompositions for probabilistic topic modeling and latent dirichlet allocation. CoRR, abs/1204.6703, 2012.</p>
<p>[3] A. Anandkumar, D. Hsu, and S. M. Kakade. A method of moments for mixture models and hidden Markov models. COLT, 2012.</p>
<p>[4] R. Bailly. Quadratic weighted automata: Spectral algorithm and likelihood maximization. ACML, 2011.</p>
<p>[5] R. Bailly, F. Denis, and L. Ralaivola. Grammatical inference as a principal component analysis problem. ICML, 2009.</p>
<p>[6] B. Balle, A. Quattoni, and X. Carreras. A spectral learning algorithm for ﬁnite state transducers. ECML– PKDD, 2011.</p>
<p>[7] B. Balle, A. Quattoni, and X. Carreras. Local loss optimization in operator models: A new insight into spectral learning. ICML, 2012.</p>
<p>[8] A. Beimel, F. Bergadano, N.H. Bshouty, E. Kushilevitz, and S. Varricchio. Learning functions represented as multiplicity automata. JACM, 2000.</p>
<p>[9] J. Berstel and C. Reutenauer. Rational Series and Their Languages. Springer, 1988.</p>
<p>[10] B. Boots, S. Siddiqi, and G. Gordon. Closing the learning planning loop with predictive state representations. I. J. Robotic Research, 2011.</p>
<p>[11] O. Bousquet and A. Elisseeff. Stability and generalization. JMLR, 2002.</p>
<p>[12] T. M. Breuel. The OCRopus open source OCR system. IS&T;/SPIE Annual Symposium, 2008.</p>
<p>[13] E.J. Candes and Y. Plan. Matrix completion with noise. Proceedings of the IEEE, 2010.</p>
<p>[14] E.J. Candes and T. Tao. The power of convex relaxation: Near-optimal matrix completion. IEEE Transactions on Information Theory, 2010.</p>
<p>[15] Jack W. Carlyle and Azaria Paz. Realizations by stochastic ﬁnite automata. J. Comput. Syst. Sci., 5(1):26– 40, 1971.</p>
<p>[16] S. B. Cohen, K. Stratos, M. Collins, D. P. Foster, and L. Ungar. Spectral learning of latent-variable PCFGs. ACL, 2012.</p>
<p>[17] M. Fliess. Matrices de Hankel. Journal de Math´ matiques Pures et Appliqu´ es, 53:197–222, 1974. e e</p>
<p>[18] R. Foygel, R. Salakhutdinov, O. Shamir, and N. Srebro. Learning with the weighted trace-norm under arbitrary sampling distributions. NIPS, 2011.</p>
<p>[19] D. Hsu, S. M. Kakade, and T. Zhang. A spectral algorithm for learning hidden Markov models. COLT, 2009.</p>
<p>[20] M. Kearns and L. Valiant. Cryptographic limitations on learning boolean formulae and ﬁnite automata. JACM, 1994.</p>
<p>[21] S. Kutin. Extensions to McDiarmid’s inequality when differences are bounded with high probability. Technical report, TR-2002-04, University of Chicago, 2002.</p>
<p>[22] F.M. Luque, A. Quattoni, B. Balle, and X. Carreras. Spectral learning in non-deterministic dependency parsing. EACL, 2012.</p>
<p>[23] M. Mohri. Weighted automata algorithms. In Handbook of Weighted Automata. Springer, 2009.</p>
<p>[24] M. Mohri, F. C. N. Pereira, and M. Riley. Speech recognition with weighted ﬁnite-state transducers. In Handbook on Speech Processing and Speech Communication. Springer, 2008.</p>
<p>[25] M. Mohri, A. Rostamizadeh, and A. Talwalkar. Foundations of Machine Learning. The MIT Press, 2012.</p>
<p>[26] A.P. Parikh, L. Song, and E.P. Xing. A spectral algorithm for latent tree graphical models. ICML, 2011.</p>
<p>[27] B. Recht. A simpler approach to matrix completion. JMLR, 2011.</p>
<p>[28] Arto Salomaa and Matti Soittola. Automata-Theoretic Aspects of Formal Power Series. Springer-Verlag: New York, 1978.</p>
<p>[29] M.P. Sch¨ tzenberger. On the deﬁnition of a family of automata. Information and Control, 1961. u</p>
<p>[30] S. M. Siddiqi, B. Boots, and G. J. Gordon. Reduced-rank hidden Markov models. AISTATS, 2010.</p>
<p>[31] L. Song, B. Boots, S. Siddiqi, G. Gordon, and A. Smola. Hilbert space embeddings of hidden Markov models. ICML, 2010.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
