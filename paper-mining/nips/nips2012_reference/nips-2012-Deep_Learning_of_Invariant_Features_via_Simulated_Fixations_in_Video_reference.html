<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>90 nips-2012-Deep Learning of Invariant Features via Simulated Fixations in Video</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-90" href="../nips2012/nips-2012-Deep_Learning_of_Invariant_Features_via_Simulated_Fixations_in_Video.html">nips2012-90</a> <a title="nips-2012-90-reference" href="#">nips2012-90-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>90 nips-2012-Deep Learning of Invariant Features via Simulated Fixations in Video</h1>
<br/><p>Source: <a title="nips-2012-90-pdf" href="http://papers.nips.cc/paper/4730-deep-learning-of-invariant-features-via-simulated-fixations-in-video.pdf">pdf</a></p><p>Author: Will Zou, Shenghuo Zhu, Kai Yu, Andrew Y. Ng</p><p>Abstract: We apply salient feature detection and tracking in videos to simulate ﬁxations and smooth pursuit in human vision. With tracked sequences as input, a hierarchical network of modules learns invariant features using a temporal slowness constraint. The network encodes invariance which are increasingly complex with hierarchy. Although learned from videos, our features are spatial instead of spatial-temporal, and well suited for extracting features from still images. We applied our features to four datasets (COIL-100, Caltech 101, STL-10, PubFig), and observe a consistent improvement of 4% to 5% in classiﬁcation accuracy. With this approach, we achieve state-of-the-art recognition accuracy 61% on STL-10 dataset. 1</p><br/>
<h2>reference text</h2><p>[1] N. Li and J. J. DiCarlo. Unsupervised natural experience rapidly alters invariant object representation in visual cortex. Science, 2008.</p>
<p>[2] A. Hyvarinen and P. Hoyer. Topographic independent component analysis as a model of v1 organization and receptive ﬁelds. Neural Computation, 2001.</p>
<p>[3] J.H. van Hateren and D.L. Ruderman. Independent component ﬁlters of natural images compared with simple cells in primary visual cortex. Proc Royal Society, 1998.</p>
<p>[4] K. Kavukcuoglu, M. Ranzato, R. Fergus, and Y. LeCun. Learning invariant features through topographic ﬁlter maps. In CVPR, 2009.</p>
<p>[5] D. Cox, P. Meier, N. Oertelt, and J. DiCarlo. ‘Breaking’ position-invariant object recognition. Nature Neuroscience, 2005.</p>
<p>[6] T. Masquelier and S.J. Thorpe. Unsupervised learning of visual features through spike timing dependent plasticity. PLoS Computational Biology, 2007.</p>
<p>[7] P. Berkes and L. Wiskott. Slow feature analysis yields a rich repertoire of complex cell properties. Journal of Vision, 2005.</p>
<p>[8] E. P. Simoncelli S. Lyu. Nonlinear image representation using divisive normalization. In CVPR, 2008.</p>
<p>[9] J. P. Lewis. Fast normalized cross-correlation. In Vision Interface, 1995.</p>
<p>[10] A. Hyvarinen, J. Hurri, and J. Vayrynen. Bubbles: a unifying framework for low-level statistical properties of natural image sequences. Optical Society of America, 2003. 4 Translation test is performed with 16x16 patches and ﬁrst layer features, rotation and zoom tests are performed with 32x32 patches and second layer features. 5 We use SIFT in the VLFeat toolbox [41] http://www.vlfeat.org/  8</p>
<p>[11] J. Hurri and A. Hyvarinen. Temporal coherence, natural image sequences and the visual cortex. In NIPS, 2006.</p>
<p>[12] J. Bergstra and Y. Bengio. Slow, decorrelated features for pretraining complex cell-like networks. In NIPS, 2009.</p>
<p>[13] R. Raina, A. Madhavan, and A. Y. Ng. Large-scale deep unsupervised learning using graphics processors. In ICML, 2009.</p>
<p>[14] A. Coates, H. Lee, and A. Y. Ng. An analysis of single layer networks in unsupervised feature learning. In AISTATS, 2011.</p>
<p>[15] B.A. Olshausen and D.J. Field. How close are we to understanding v1? Neural Computation, 2005.</p>
<p>[16] A. Coates and A. Ng. The importance of encoding versus training with sparse coding and vector quantization. In ICML, 2011.</p>
<p>[17] Q. V. Le, J. Ngiam, Z. Chen, D. Chia, P. W. Koh, and A. Y. Ng. Tiled convolutional neural networks. In Advances in Neural Information Processing Systems, 2010.</p>
<p>[18] Q. V. Le, M. A. Ranzato, R. Monga, M. Devin, K. Chen, G. S. Corrado, J. Dean, and A. Y. Ng. Building high-level features using large scale unsupervised learning. In ICML, 2012.</p>
<p>[19] A. Coates and A. Y. Ng. Selecting receptive ﬁelds in deep networks. In NIPS, 2011.</p>
<p>[20] H. Mobahi, R. Collobert, and Jason Weston. Deep learning from temporal coherence in video. In ICML, 2009.</p>
<p>[21] M. Franzius, N. Wilbert, and L. Wiskott. Invariant object recognition with Slow Feature Analysis. In ICANN, 2008.</p>
<p>[22] B. Olshausen, C. Cadieu, J. Culpepper, and D.K. Warland. Bilinear models of natural images. In Proc. SPIE 6492, 2007.</p>
<p>[23] R. P. N. Rao D. B. Grimes. Bilinear sparse coding for invariant vision.</p>
<p>[24] C. Cadieu and B. Olshausen. Learning tranformational invariants from natural movies. In NIPS, 2009.</p>
<p>[25] S. Thrun D. Stavens. Unsupervised learning of invariant features using video. In CVPR, 2010.</p>
<p>[26] C. Leistner, M. Godec, S. Schulter, M. Werlberger, A. Saffari, and H. Bischof. Improving classiﬁers with unlabeled weakly-related videos. In CVPR, 2011.</p>
<p>[27] T. Lee and S. Soatto. Video-based descriptors for object recognition. Image and Vision Computing, 2011.</p>
<p>[28] D. E. Rumelhart, G. E. Hinton, and R. J. Williams. Learning representations by back-propagating errors. Nature, 1986.</p>
<p>[29] Y. Bengio and Y. LeCun. Scaling learning algorithms towards AI. In Large-Scale Kernel Machines, 2007.</p>
<p>[30] A. Hyvarinen, J. Hurri, and P.O. Hoyer. Natural Image Statistics. Springer, 2009.</p>
<p>[31] Q. V. Le, A. Karpenko, J. Ngiam, and A. Y. Ng. ICA with reconstruction cost for efﬁcient overcomplete feature learning. In NIPS, 2011.</p>
<p>[32] H. Wersing and E. Kr¨ ner. Learning optimized features for hierarchical models of invariant object recogo nition. Neural Computation, 2003.</p>
<p>[33] L. Fei-Fei, R. Fergus, and P. Perona. Learning generative visual models from few training examples: an incremental bayesian approach tested on 101 object categories.</p>
<p>[34] A. Coates, H. Lee, and A. Ng. An analysis of single-layer networks in unsupervised feature learning. In AISTATS 14, 2010.</p>
<p>[35] N. Kumar, A. C. Berg, P. N. Belhumeur, and S. K. Nayar. Attribute and simile classiﬁers for face veriﬁcation. In ICCV, 2009.</p>
<p>[36] K. Kavukcuoglu, P. Sermanet, Y. Boureau, K. Gregor, M. Mathieu, and Y. LeCun. Learning convolutional feature hierarchies for visual recognition. In NIPS, 2010.</p>
<p>[37] J. Yang, K. Yu, Y. Gong, and T. Huang. Linear spatial pyramid matching using sparse coding for image classiﬁcation. In CVPR, 2009.</p>
<p>[38] K. Yu, Y. Lin, and J. Lafferty. Learning image representations from the pixel level via hierarchical sparse coding. In CVPR, 2011.</p>
<p>[39] Y-Lan Boureau, Francis Bach, Yann LeCun, and Jean Ponce. Learning mid-level features for recognition. In CVPR, 2010.</p>
<p>[40] J. Ngiam, P. W. Koh, Z. Chen, S. Bhaskar, and A. Y. Ng. Sparse ﬁltering. In NIPS, 2011.</p>
<p>[41] A. Vedaldi and B. Fulkerson. VLFeat: An open and portable library of computer vision algorithms, 2008.  9</p>
<br/>
<br/><br/><br/></body>
</html>
