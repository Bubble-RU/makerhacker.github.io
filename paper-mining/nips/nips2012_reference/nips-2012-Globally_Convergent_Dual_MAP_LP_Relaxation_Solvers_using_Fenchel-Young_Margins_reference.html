<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>143 nips-2012-Globally Convergent Dual MAP LP Relaxation Solvers using Fenchel-Young Margins</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-143" href="../nips2012/nips-2012-Globally_Convergent_Dual_MAP_LP_Relaxation_Solvers_using_Fenchel-Young_Margins.html">nips2012-143</a> <a title="nips-2012-143-reference" href="#">nips2012-143-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>143 nips-2012-Globally Convergent Dual MAP LP Relaxation Solvers using Fenchel-Young Margins</h1>
<br/><p>Source: <a title="nips-2012-143-pdf" href="http://papers.nips.cc/paper/4765-globally-convergent-dual-map-lp-relaxation-solvers-using-fenchel-young-margins.pdf">pdf</a></p><p>Author: Alex Schwing, Tamir Hazan, Marc Pollefeys, Raquel Urtasun</p><p>Abstract: While ﬁnding the exact solution for the MAP inference problem is intractable for many real-world tasks, MAP LP relaxations have been shown to be very effective in practice. However, the most efﬁcient methods that perform block coordinate descent can get stuck in sub-optimal points as they are not globally convergent. In this work we propose to augment these algorithms with an -descent approach and present a method to efﬁciently optimize for a descent direction in the subdifferential using a margin-based formulation of the Fenchel-Young duality theorem. Furthermore, the presented approach provides a methodology to construct a primal optimal solution from its dual optimal counterpart. We demonstrate the efﬁciency of the presented approach on spin glass models and protein interaction problems and show that our approach outperforms state-of-the-art solvers. 1</p><br/>
<h2>reference text</h2><p>[1] A. Auslender and M. Teboulle. Interior gradient and epsilon-subgradient descent methods for constrained convex minimization. Mathematics of Operations Research, 2004.</p>
<p>[2] D. P. Bertsekas, A. Nedi´ , and A. E. Ozdaglar. Convex Analysis and Optimization. Athena Scientiﬁc, c 2003.</p>
<p>[3] A. Globerson and T. S. Jaakkola. Fixing max-product: convergent message passing algorithms for MAP relaxations. In Proc. NIPS, 2007.</p>
<p>[4] S. Gould, O. Russakovsky, I. Goodfellow, P. Baumstarck, A. Y. Ng, and D. Koller. The STAIR Vision Library (v2.4), 2011. http://ai.stanford.edu/ sgould/svl.</p>
<p>[5] T. Hazan, J. Peng, and A. Shashua. Tightening fractional covering upper bounds on the partition function for high-order region graphs. In Proc. UAI, 2012.</p>
<p>[6] T. Hazan and A. Shashua. Norm-product belief propagation: Primal-dual message-passing for approximate inference. Trans. on Information Theory, 2010.</p>
<p>[7] J. K. Johnson. Convex relaxation methods for graphical models: Lagrangian and maximum entropy approaches. PhD thesis, Massachusetts Institute of Technology, 2008.</p>
<p>[8] V. Jojic, S. Gould, and D. Koller. Accelerated dual decomposition for MAP inference. In Proc. ICML, 2010.</p>
<p>[9] J. H. Kappes, B. Savchynskyy, and C. Schn¨ rr. A Bundle Approach To Efﬁcient MAP-Inference by o Lagrangian Relaxation. In Proc. CVPR, 2012.</p>
<p>[10] D. Koller and N. Friedman. Probabilistic graphical models. MIT Press, 2009.</p>
<p>[11] V. Kolmogorov. Convergent tree-reweighted message passing for energy minimization. PAMI, 2006.</p>
<p>[12] N. Komodakis, N. Paragios, and G. Tziritas. MRF Energy Minimization & Beyond via Dual Decomposition. PAMI, 2010.</p>
<p>[13] T. Koo, A.M. Rush, M. Collins, T. Jaakkola, and D. Sontag. Dual decomposition for parsing with nonprojective head automata. In Proc. EMNLP, 2010.</p>
<p>[14] A.M.C.A. Koster, S.P.M. van Hoesel, and A.W.J. Kolen. The partial constraint satisfaction problem: Facets and lifting theorems. Operations Research Letters, 1998.</p>
<p>[15] C. Lemar´ chal. An algorithm for minimizing convex functions. Information processing, 1974. e</p>
<p>[16] A.F.T. Martins, M.A.T. Figueiredo, P.M.Q. Aguiar, N.A. Smith, and E.P. Xing. An Augmented Lagrangian Approach to Constrained MAP Inference. In Proc. ICML, 2011.</p>
<p>[17] T. Meltzer, A. Globerson, and Y. Weiss. Convergent Message Passing Algorithms – A Unifying View. In Proc. UAI, 2009.</p>
<p>[18] O. Meshi and A. Globerson. An Alternating Direction Method for Dual MAP LP Relaxation. In Proc. ECML PKDD, 2011.</p>
<p>[19] P. Ravikumar, A. Agarwal, and M. J. Wainwright. Message-passing for graph-structured linear programs: Proximal methods and rounding schemes. JMLR, 2010.</p>
<p>[20] M. Schlesinger. Syntactic analysis of two-dimensional visual signals in noisy conditions. Kibernetika,76.</p>
<p>[21] A. G. Schwing, T. Hazan, M. Pollefeys, and R. Urtasun. Distributed message passing for large scale graphical models. In Proc. CVPR, 2011.</p>
<p>[22] D. Sontag and T. S. Jaakkola. Tree block coordinate descent for MAP in graphical models. In Proc. AISTATS, 2009.</p>
<p>[23] D. Sontag, T. Meltzer, A. Globerson, T. Jaakkola, and Y. Weiss. Tightening LP relaxations for MAP using message passing. In Proc. UAI, 2008.</p>
<p>[24] D. Tarlow, D. Batra, P. Kohli, and V. Kolmogorov. Dynamic tree block coordinate ascent. In Proc. ICML, 2011.</p>
<p>[25] M. J. Wainwright, T. S. Jaakkola, and A. S. Willsky. MAP estimation via agreement on trees: messagepassing and linear programming. Trans. on Information Theory, 2005.</p>
<p>[26] Y. Weiss, C. Yanover, and T. Meltzer. MAP Estimation, Linear Programming and Belief Propagation with Convex Free Energies. In Proc. UAI, 2007.</p>
<p>[27] T. Werner. Revisiting the linear programming relaxation approach to gibbs energy minimization and weighted constraint satisfaction. PAMI, 2010.</p>
<p>[28] P. Wolfe. A method of conjugate subgradients for minimizing nondifferentiable functions. Nondifferentiable Optimization, 1975.</p>
<p>[29] J. S. Yedidia, W. T. Freeman, and Y. Weiss. Constructing free-energy approximations and generalized belief propagation algorithms. Trans. on Information Theory, 2005.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
