<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>342 nips-2012-The variational hierarchical EM algorithm for clustering hidden Markov models</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-342" href="../nips2012/nips-2012-The_variational_hierarchical_EM_algorithm_for_clustering_hidden_Markov_models.html">nips2012-342</a> <a title="nips-2012-342-reference" href="#">nips2012-342-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>342 nips-2012-The variational hierarchical EM algorithm for clustering hidden Markov models</h1>
<br/><p>Source: <a title="nips-2012-342-pdf" href="http://papers.nips.cc/paper/4779-the-variational-hierarchical-em-algorithm-for-clustering-hidden-markov-models.pdf">pdf</a></p><p>Author: Emanuele Coviello, Gert R. Lanckriet, Antoni B. Chan</p><p>Abstract: In this paper, we derive a novel algorithm to cluster hidden Markov models (HMMs) according to their probability distributions. We propose a variational hierarchical EM algorithm that i) clusters a given collection of HMMs into groups of HMMs that are similar, in terms of the distributions they represent, and ii) characterizes each group by a “cluster center”, i.e., a novel HMM that is representative for the group. We illustrate the beneﬁts of the proposed algorithm on hierarchical clustering of motion capture sequences as well as on automatic music tagging. 1</p><br/>
<h2>reference text</h2><p>[1] L. Rabiner and B. H. Juang. Fundamentals of Speech Recognition. Prentice Hall, Upper Saddle River (NJ, USA), 1993.</p>
<p>[2] Y. Qi, J.W. Paisley, and L. Carin. Music analysis using hidden markov mixture models. Signal Processing, IEEE Transactions on, 55(11):5209–5224, 2007.</p>
<p>[3] E. Batlle, J. Masip, and E. Guaus. Automatic song identiﬁcation in noisy broadcast audio. In IASTED International Conference on Signal and Image Processing. Citeseer, 2002.</p>
<p>[4] T. Jebara, Y. Song, and K. Thadani. Spectral clustering and embedding with hidden markov models. Machine Learning: ECML 2007, pages 164–175, 2007.</p>
<p>[5] P. Smyth. Clustering sequences with hidden markov models. In Advances in neural information processing systems, 1997.</p>
<p>[6] T. Jebara, R. Kondor, and A. Howard. Probability product kernels. The Journal of Machine Learning Research, 5:819–844, 2004.</p>
<p>[7] B. H. Juang and L. R. Rabiner. A probabilistic distance measure for hidden Markov models. AT&T; Technical Journal, 64(2):391–408, February 1985.</p>
<p>[8] N. Vasconcelos and A. Lippman. Learning mixture hierarchies. In Advances in Neural Information Processing Systems, 1998.</p>
<p>[9] A.B. Chan, E. Coviello, and G.R.G. Lanckriet. Clustering dynamic textures with the hierarchical em algorithm. In Intl. Conference on Computer Vision and Pattern Recognition, 2010.</p>
<p>[10] G. Carneiro, A.B. Chan, P.J. Moreno, and N. Vasconcelos. Supervised learning of semantic classes for image annotation and retrieval. IEEE Transactions on Pattern Analysis and Machine Intelligence, 29(3):394–410, 2007.</p>
<p>[11] D. Turnbull, L. Barrington, D. Torres, and G. Lanckriet. Semantic annotation and retrieval of music and sound effects. IEEE Transactions on Audio, Speech and Language Processing, 16(2):467–476, February 2008.</p>
<p>[12] E. Coviello, A. Chan, and G. Lanckriet. Time series models for semantic music annotation. Audio, Speech, and Language Processing, IEEE Transactions on, 5(19):1343–1359, 2011.</p>
<p>[13] A. Banerjee, S. Merugu, I.S. Dhillon, and J. Ghosh. Clustering with bregman divergences. The Journal of Machine Learning Research, 6:1705–1749, 2005.</p>
<p>[14] J.R. Hershey, P.A. Olsen, and S.J. Rennie. Variational Kullback-Leibler divergence for hidden Markov models. In Automatic Speech Recognition & Understanding, 2007. ASRU. IEEE Workshop on, pages 323–328. IEEE, 2008.</p>
<p>[15] A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society B, 39:1–38, 1977.</p>
<p>[16] R.M. Neal and G.E. Hinton. A view of the em algorithm that justiﬁes incremental, sparse, and other variants. NATO ASI SERIES D BEHAVIOURAL AND SOCIAL SCIENCES, 89:355–370, 1998.</p>
<p>[17] I. Csisz, G. Tusn´ dy, et al. Information geometry and alternating minimization procedures. a Statistics and decisions, 1984.</p>
<p>[18] M.I. Jordan, Z. Ghahramani, T.S. Jaakkola, and L.K. Saul. An introduction to variational methods for graphical models. Machine learning, 37(2):183–233, 1999.</p>
<p>[19] Tommi S. Jaakkola. Tutorial on Variational Approximation Methods. In In Advanced Mean Field Methods: Theory and Practice, pages 129–159. MIT Press, 2000.</p>
<p>[20] Anonymous. Derivation of the Variational HEM Algorithm for Hidden Markov Mixture Models. Technical report, Anonymous, 2012.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
