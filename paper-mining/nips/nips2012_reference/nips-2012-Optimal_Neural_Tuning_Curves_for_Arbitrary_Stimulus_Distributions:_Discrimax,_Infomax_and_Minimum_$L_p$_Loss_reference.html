<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>262 nips-2012-Optimal Neural Tuning Curves for Arbitrary Stimulus Distributions: Discrimax, Infomax and Minimum $L p$ Loss</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-262" href="../nips2012/nips-2012-Optimal_Neural_Tuning_Curves_for_Arbitrary_Stimulus_Distributions%3A_Discrimax%2C_Infomax_and_Minimum_%24L_p%24_Loss.html">nips2012-262</a> <a title="nips-2012-262-reference" href="#">nips2012-262-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>262 nips-2012-Optimal Neural Tuning Curves for Arbitrary Stimulus Distributions: Discrimax, Infomax and Minimum $L p$ Loss</h1>
<br/><p>Source: <a title="nips-2012-262-pdf" href="http://papers.nips.cc/paper/4783-optimal-neural-tuning-curves-for-arbitrary-stimulus-distributions-discrimax-infomax-and-minimum-l_p-loss.pdf">pdf</a></p><p>Author: Zhuo Wang, Alan Stocker, Daniel Lee</p><p>Abstract: In this work we study how the stimulus distribution inﬂuences the optimal coding of an individual neuron. Closed-form solutions to the optimal sigmoidal tuning curve are provided for a neuron obeying Poisson statistics under a given stimulus distribution. We consider a variety of optimality criteria, including maximizing discriminability, maximizing mutual information and minimizing estimation error under a general Lp norm. We generalize the Cramer-Rao lower bound and show how the Lp loss can be written as a functional of the Fisher Information in the asymptotic limit, by proving the moment convergence of certain functions of Poisson random variables. In this manner, we show how the optimal tuning curve depends upon the loss function, and the equivalence of maximizing mutual information with minimizing Lp loss in the limit as p goes to zero. 1</p><br/>
<h2>reference text</h2><p>[1] TM Maddess and SB Laughlin. Adaptation of the motion-sensitive neuron h1 is generated locally and governed by contrast frequency. Proc. R. Soc. Lond. B Biol. Sci, 225:251–275, 1985.</p>
<p>[2] J Atick. Could information theory provide an ecological theory of sensory processing? Network, 3:213–251, 1992.</p>
<p>[3] RA Harris, DC O’Carroll, and SB Laughlin. Contrast gain reduction in ﬂy motion adaptation. Neuron, 28:595–606, 2000.</p>
<p>[4] I Dean, NS Harper, and D McAlpine. Neural population coding of sound level adapts to stimulus statistics. Nature neuroscience, 8:1684–1689, 2005.</p>
<p>[5] AA Stocker and EP Simoncelli. Noise characteristics and prior expectations in human visual speed perception. Nature neuroscience, 9:578–585, 2006.</p>
<p>[6] J-P Nadal and N Parga. Non linear neurons in the low noise limit: A factorial code maximizes information transfer, 1994.</p>
<p>[7] N Brunel and J-P Nadal. Mutual information, ﬁsher information and population coding. Neural Computation, 10(7):1731–1757, 1998.</p>
<p>[8] Tvd Twer and DIA MacLeod. Optimal nonlinear codes for the perception of natural colours. Network: Computation in Neural Systems, 12(3):395–407, 2001.</p>
<p>[9] MD McDonnell and NG Stocks. Maximally informative stimuli and tuning curves for sigmoidal rate-coding neurons and populations. Phys. Rev. Lett., 101:058103, 2008.</p>
<p>[10] D Ganguli and EP Simoncelli. Implicit encoding of prior probabilities in optimal neural populations. Adv. Neural Information Processing Systems, 23:658–666, 2010.</p>
<p>[11] HB Barlow. Possible principles underlying the transformation of sensory messages. M.I.T. Press, 1961.</p>
<p>[12] HS Seung and H Sompolinsky. Simple models for reading neuronal population codes. Proc. of the National Aca. of Sci. of the U.S.A., 90:10749–10753, 1993.</p>
<p>[13] K Zhang and TJ Sejnowski. Neuronal tuning: To sharpen or broaden? Neural Computation, 11:75–84, 1999.</p>
<p>[14] A Pouget, S Deneve, J-C Ducom, and PE Latham. Narrow versus wide tuning curves: Whats best for a population code? Neural Computation, 11:85–90, 1999.</p>
<p>[15] M Bethge, D Rotermund, and K Pawelzik. Optimal short-term population coding: when Fisher information fails. Neural Computation, 14:2317–2351, 2002.</p>
<p>[16] M Bethge, D Rotermund, and K Pawelzik. Optimal neural rate coding leads to bimodal ﬁring rate distributions. Netw. Comput. Neural Syst., 14:303–319, 2003.</p>
<p>[17] S Yarrow, E Challis, and P Seris. Fisher and shannon information in ﬁnite neural populations. Neural Computation, In Print, 2012.</p>
<p>[18] TM Cover and J Thomas. Elements of Information Theory. Wiley, 1991.</p>
<p>[19] SI Amari, H Nagaoka, and D Harada. Methods of Information Geometry. Translations of Mathematical Monographs. American Mathematical Society, 2007.</p>
<p>[20] AP Nikitin, NG Stocks, RP Morse, and MD McDonnell. Neural population coding is optimized by discrete tuning curves. Phys. Rev. Lett., 103:138101, 2009.</p>
<p>[21] N Privault. Generalized Bell polynomials and the combinatorics of Poisson central moments. Electronic Journal of Combinatorics, 18, 2011.  9</p>
<br/>
<br/><br/><br/></body>
</html>
