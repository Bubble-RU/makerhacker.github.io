<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>322 nips-2012-Spiking and saturating dendrites differentially expand single neuron computation capacity</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-322" href="../nips2012/nips-2012-Spiking_and_saturating_dendrites_differentially_expand_single_neuron_computation_capacity.html">nips2012-322</a> <a title="nips-2012-322-reference" href="#">nips2012-322-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>322 nips-2012-Spiking and saturating dendrites differentially expand single neuron computation capacity</h1>
<br/><p>Source: <a title="nips-2012-322-pdf" href="http://papers.nips.cc/paper/4738-spiking-and-saturating-dendrites-differentially-expand-single-neuron-computation-capacity.pdf">pdf</a></p><p>Author: Romain Cazé, Mark Humphries, Boris S. Gutkin</p><p>Abstract: The integration of excitatory inputs in dendrites is non-linear: multiple excitatory inputs can produce a local depolarization departing from the arithmetic sum of each input’s response taken separately. If this depolarization is bigger than the arithmetic sum, the dendrite is spiking; if the depolarization is smaller, the dendrite is saturating. Decomposing a dendritic tree into independent dendritic spiking units greatly extends its computational capacity, as the neuron then maps onto a two layer neural network, enabling it to compute linearly non-separable Boolean functions (lnBFs). How can these lnBFs be implemented by dendritic architectures in practise? And can saturating dendrites equally expand computational capacity? To address these questions we use a binary neuron model and Boolean algebra. First, we conﬁrm that spiking dendrites enable a neuron to compute lnBFs using an architecture based on the disjunctive normal form (DNF). Second, we prove that saturating dendrites as well as spiking dendrites enable a neuron to compute lnBFs using an architecture based on the conjunctive normal form (CNF). Contrary to a DNF-based architecture, in a CNF-based architecture, dendritic unit tunings do not imply the neuron tuning, as has been observed experimentally. Third, we show that one cannot use a DNF-based architecture with saturating dendrites. Consequently, we show that an important family of lnBFs implemented with a CNF-architecture can require an exponential number of saturating dendritic units, whereas the same family implemented with either a DNF-architecture or a CNF-architecture always require a linear number of spiking dendritic units. This minimization could explain why a neuron spends energetic resources to make its dendrites spike. 1</p><br/>
<h2>reference text</h2><p>[1] T. Abrahamsson, L. Cathala, K. Matsui, R. Shigemoto, and D.A. DiGregorio. Thin Dendrites of Cerebellar Interneurons Confer Sublinear Synaptic Integration and a Gradient of Short-Term Plasticity. Neuron, 73(6):1159–1172, March 2012.</p>
<p>[2] S. Cash and R. Yuste. Linear summation of excitatory inputs by CA1 pyramidal neurons. Neuron, 22(2):383–394, February 1999.</p>
<p>[3] Y. Crama and P.L. Hammer. Boolean Functions: Theory, Algorithms, and Applications (Encyclopedia of Mathematics and its Applications). Cambridge University Press, 2011.</p>
<p>[4] S. Gasparini, M. Migliore, and J.C. Magee. On the initiation and propagation of dendritic spikes in CA1 pyramidal neurons. The Journal of Neuroscience, 24(49):11046–11056, December 2004.</p>
<p>[5] M. Hausser and B.W. Mel. Dendrites: bug or feature? Current Opinion in Neurobiology, 13(3):372–383, June 2003.</p>
<p>[6] H. Jia, N.L. Rochefort, X. Chen, and A. Konnerth. Dendritic organization of sensory input to cortical neurons in vivo. Nature, 464(7293):1307–1312, 2010.</p>
<p>[7] C. Koch. Biophysics of computation : information processing in single neurons. Oxford University Press, New York, 1999.</p>
<p>[8] R. Legenstein and W. Maass. Branch-Speciﬁc Plasticity Enables Self-Organization of Nonlinear Computation in Single Neurons. Journal of Neuroscience, 31(30):10787–10802, July 2011.</p>
<p>[9] A. Losonczy, J.K. Makara, and J.C. Magee. Compartmentalized dendritic plasticity and input feature storage in neurons. Nature, 452(7186):436–441, March 2008.</p>
<p>[10] W.S. McCulloch and W. Pitts. A logical calculus of the ideas immanent in nervous activity. Bulletin of mathematical biology, 52(1-2):99–115; discussion 73–97, January 1943.</p>
<p>[11] P.B. Miltersen, J. Radhakrishnan, and I. Wegener. On converting CNF to DNF. Theoretical computer science, 347:325–335, November 2005.</p>
<p>[12] P. Poirazi, T. Brannon, and B.W. Mel. Pyramidal neuron as two-layer neural network. Neuron, 37(6):989–999, March 2003.</p>
<p>[13] A. Polsky, B.W. Mel, and J. Schiller. Computational subunits in thin dendrites of pyramidal cells. Nature Neuroscience, 7(6):621–627, June 2004.</p>
<p>[14] M.W.H. H Remme, M. Lengyel, and B.S. Gutkin. Democracy-independence trade-off in oscillating dendrites and its implications for grid cells. Neuron, 66(3):429–37, May 2010.</p>
<p>[15] A.L. Roskies. The Binding Problem. Neuron, 24:7–9, 1999.</p>
<p>[16] K. Vervaeke, A. Lorincz, Z. Nusser, and R.A. Silver. Gap Junctions Compensate for Sublinear Dendritic Integration in an Inhibitory Network. Science, 335(6076):1624–1628, March 2012.</p>
<p>[17] I. Wegener. Complexity of Boolean Functions. Wiley-Teubner, 1987.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
