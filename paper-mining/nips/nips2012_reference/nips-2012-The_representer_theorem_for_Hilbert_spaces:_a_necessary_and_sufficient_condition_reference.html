<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>340 nips-2012-The representer theorem for Hilbert spaces: a necessary and sufficient condition</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-340" href="../nips2012/nips-2012-The_representer_theorem_for_Hilbert_spaces%3A_a_necessary_and_sufficient_condition.html">nips2012-340</a> <a title="nips-2012-340-reference" href="#">nips2012-340-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>340 nips-2012-The representer theorem for Hilbert spaces: a necessary and sufficient condition</h1>
<br/><p>Source: <a title="nips-2012-340-pdf" href="http://papers.nips.cc/paper/4646-on-the-non-existence-of-convex-calibrated-surrogate-losses-for-ranking.pdf">pdf</a></p><p>Author: Francesco Dinuzzo, Bernhard Schölkopf</p><p>Abstract: The representer theorem is a property that lies at the foundation of regularization theory and kernel methods. A class of regularization functionals is said to admit a linear representer theorem if every member of the class admits minimizers that lie in the ﬁnite dimensional subspace spanned by the representers of the data. A recent characterization states that certain classes of regularization functionals with differentiable regularization term admit a linear representer theorem for any choice of the data if and only if the regularization term is a radial nondecreasing function. In this paper, we extend such result by weakening the assumptions on the regularization term. In particular, the main result of this paper implies that, for a sufﬁciently large family of regularization functionals, radial nondecreasing functions are the only lower semicontinuous regularization terms that guarantee existence of a representer theorem for any choice of the data. 1</p><br/>
<h2>reference text</h2><p>[1] A. N. Tikhonov and V. Y. Arsenin. Solutions of Ill Posed Problems. W. H. Winston, Washington, D. C., 1977.</p>
<p>[2] G. Wahba. Spline Models for Observational Data. SIAM, Philadelphia, USA, 1990.</p>
<p>[3] F. Cucker and S. Smale. On the mathematical foundations of learning. Bulletin of the American mathematical society, 39:1–49, 2001.</p>
<p>[4] B. Sch¨ lkopf, A. J. Smola, and K-R M¨ ller. Nonlinear component analysis as a kernel eigeno u value problem. Neural Computation, 10(5):1299–1319, 1998.</p>
<p>[5] F. Riesz. Sur une esp` ce de g´ om´ trie analytique des syst` mes de fonctions sommables. e e e e Comptes rendus de l’Acad´ mie des sciences Paris, 144:1409–1411, 1907. e</p>
<p>[6] M. Fr´ chet. Sur les ensembles de fonctions et les op´ rations lin´ aires. Comptes rendus de e e e l’Acad´ mie des sciences Paris, 144:1414–1416, 1907. e</p>
<p>[7] V. Vapnik. Statistical Learning Theory. Wiley, New York, NY, USA, 1998.</p>
<p>[8] B. Sch¨ lkopf and A. J. Smola. Learning with Kernels: Support Vector Machines, Regularizao tion, Optimization, and Beyond. (Adaptive Computation and Machine Learning). MIT Press, 2001.</p>
<p>[9] J. Shawe-Taylor and N. Cristianini. Kernel Methods for Pattern Analysis. Cambridge University Press, New York, NY, USA, 2004.</p>
<p>[10] N. Aronszajn. Theory of reproducing kernels. Transactions of the American Mathematical Society, 68:337–404, 1950.</p>
<p>[11] B. Sch¨ lkopf, R. Herbrich, and A. J. Smola. A generalized representer theorem. In In Proo ceedings of the Annual Conference on Computational Learning Theory, pages 416–426, 2001.</p>
<p>[12] G. Kimeldorf and G. Wahba. Some results on Tchebychefﬁan spline functions. Journal of Mathematical Analysis and Applications, 33(1):82–95, 1971.</p>
<p>[13] D. Cox and F. O’ Sullivan. Asymptotic analysis of penalized likelihood and related estimators. The Annals of Statistics, 18:1676–1695, 1990.</p>
<p>[14] T. Poggio and F. Girosi. Networks for approximation and learning. In Proceedings of the IEEE, volume 78, pages 1481–1497, 1990.</p>
<p>[15] A. Argyriou, C. A. Micchelli, and M. Pontil. When is there a representer theorem? Vector versus matrix regularizers. Journal of Machine Learning Research, 10:2507–2529, 2009.  8</p>
<br/>
<br/><br/><br/></body>
</html>
