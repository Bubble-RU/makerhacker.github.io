<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>36 nips-2012-Adaptive Stratified Sampling for Monte-Carlo integration of Differentiable functions</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-36" href="../nips2012/nips-2012-Adaptive_Stratified_Sampling_for_Monte-Carlo_integration_of_Differentiable_functions.html">nips2012-36</a> <a title="nips-2012-36-reference" href="#">nips2012-36-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>36 nips-2012-Adaptive Stratified Sampling for Monte-Carlo integration of Differentiable functions</h1>
<br/><p>Source: <a title="nips-2012-36-pdf" href="http://papers.nips.cc/paper/4519-adaptive-stratified-sampling-for-monte-carlo-integration-of-differentiable-functions.pdf">pdf</a></p><p>Author: Alexandra Carpentier, Rémi Munos</p><p>Abstract: We consider the problem of adaptive stratiﬁed sampling for Monte Carlo integration of a differentiable function given a ﬁnite number of evaluations to the function. We construct a sampling scheme that samples more often in regions where the function oscillates more, while allocating the samples such that they are well spread on the domain (this notion shares similitude with low discrepancy). We prove that the estimate returned by the algorithm is almost similarly accurate as the estimate that an optimal oracle strategy (that would know the variations of the function everywhere) would return, and provide a ﬁnite-sample analysis. 1</p><br/>
<h2>reference text</h2><p>[1] J.Y. Audibert, R. Munos, and Cs. Szepesv´ ri. Exploration-exploitation tradeoff using variance a estimates in multi-armed bandits. Theoretical Computer Science, 410(19):1876–1902, 2009.</p>
<p>[2] A. Carpentier and R. Munos. Adaptive Stratiﬁed Sampling for Monte-Carlo integration of Differentiable functions. Technical report, arXiv:0575985, 2012.</p>
<p>[3] A. Carpentier and R. Munos. Finite-time analysis of stratiﬁed sampling for monte carlo. In In Neural Information Processing Systems (NIPS), 2011a.</p>
<p>[4] A. Carpentier and R. Munos. Finite-time analysis of stratiﬁed sampling for monte carlo. Technical report, INRIA-00636924, 2011b.</p>
<p>[5] Pierre Etor´ and Benjamin Jourdain. Adaptive optimal allocation in stratiﬁed sampling methods. e Methodol. Comput. Appl. Probab., 12(3):335–360, September 2010.</p>
<p>[6] P. Glasserman. Monte Carlo methods in ﬁnancial engineering. Springer Verlag, 2004. ISBN 0387004513.</p>
<p>[7] V. Grover. Active learning and its application to heteroscedastic problems. Department of Computing Science, Univ. of Alberta, MSc thesis, 2009.</p>
<p>[8] A. Maurer and M. Pontil. Empirical bernstein bounds and sample-variance penalization. In Proceedings of the Twenty-Second Annual Conference on Learning Theory, pages 115–124, 2009.</p>
<p>[9] H. Niederreiter. Quasi-monte carlo methods and pseudo-random numbers. Bull. Amer. Math. Soc, 84(6):957–1041, 1978.</p>
<p>[10] R.Y. Rubinstein and D.P. Kroese. Simulation and the Monte Carlo method. Wiley-interscience, 2008. ISBN 0470177942.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
