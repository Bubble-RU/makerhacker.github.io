<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>256 nips-2012-On the connections between saliency and tracking</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-256" href="../nips2012/nips-2012-On_the_connections_between_saliency_and_tracking.html">nips2012-256</a> <a title="nips-2012-256-reference" href="#">nips2012-256-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>256 nips-2012-On the connections between saliency and tracking</h1>
<br/><p>Source: <a title="nips-2012-256-pdf" href="http://papers.nips.cc/paper/4631-on-the-connections-between-saliency-and-tracking.pdf">pdf</a></p><p>Author: Vijay Mahadevan, Nuno Vasconcelos</p><p>Abstract: A model connecting visual tracking and saliency has recently been proposed. This model is based on the saliency hypothesis for tracking which postulates that tracking is achieved by the top-down tuning, based on target features, of discriminant center-surround saliency mechanisms over time. In this work, we identify three main predictions that must hold if the hypothesis were true: 1) tracking reliability should be larger for salient than for non-salient targets, 2) tracking reliability should have a dependence on the deﬁning variables of saliency, namely feature contrast and distractor heterogeneity, and must replicate the dependence of saliency on these variables, and 3) saliency and tracking can be implemented with common low level neural mechanisms. We conﬁrm that the ﬁrst two predictions hold by reporting results from a set of human behavior studies on the connection between saliency and tracking. We also show that the third prediction holds by constructing a common neurophysiologically plausible architecture that can computationally solve both saliency and tracking. This architecture is fully compliant with the standard physiological models of V1 and MT, and with what is known about attentional control in area LIP, while explaining the results of the human behavior experiments.</p><br/>
<h2>reference text</h2><p>[1] See attached supplementary material.</p>
<p>[2] S. Avidan. Ensemble tracking. IEEE PAMI, 29(2):261–271, 2007.</p>
<p>[3] J. Bisley & M. Goldberg, “Attention, intention, & priority in the parietal lobe,” Annu. Rev. Neurosci, 33, p. 1–21, 2010.</p>
<p>[4] D. H. Brainard. The psychophysics toolbox. Spatial Vision, 10:433–436, 1997.</p>
<p>[5] M. Carandini et al., Do we know what the early visual system does? J. Neuroscience, 25, 2005.</p>
<p>[6] J. Cavanaugh, W. Bair, & J. Movshon. Nature & interaction of signals from the receptive ﬁeld center and surround in macaque V1 neurons. J. Neurophysiol., 88:2530–2546, 2002.</p>
<p>[7] S. Chikkerur, et al., What & where: A Bayesian inference theory of attention. Vision Research, 2010.</p>
<p>[8] R. Collins, Y. Liu, & M. Leordeanu. On-line selection of discriminative tracking features. IEEE PAMI, 27(10):1631 – 1643, October 2005.</p>
<p>[9] D. Comaniciu, V. Ramesh, & P. Meer. Kernel-based object tracking. IEEE PAMI, 25(5):564–577, 2003.</p>
<p>[10] J. C. Culham, et al., Cortical fmri activation produced by attentive tracking of moving targets. J. Neurophysiol, 80(5):2657–2670, 1998.</p>
<p>[11] D. Gao, V. Mahadevan, & N. Vasconcelos. On the plausibility of the discriminant center-surround hypothesis for visual saliency. Journal of Vision, 8(7):1–18, 6 2008.</p>
<p>[12] D. Gao & N. Vasconcelos. Decision-theoretic saliency: computational principle, biological plausibility, & implications for neurophysiology & psychophysics. Neural Computation, 21:239–271, Jan 2009.</p>
<p>[13] H. Grabner & H. Bischof. On-line boosting & vision. IEEE CVPR, 1:260–267, 2006.</p>
<p>[14] J. Intriligator & P. Cavanagh. The spatial resolution of visual attention. Cog. Psych., 43:171–216, 1997.</p>
<p>[15] M. Isard & A. Blake. Condensation: conditional density propagation for visual tracking. IJCV, 29, 1998.</p>
<p>[16] L. Itti et al., A model of saliency-based visual attention for rapid scene analysis. IEEE PAMI, 20(11):1254–1259, 1998.</p>
<p>[17] A. D. Jepson et al., Robust online appearance models for visual tracking. IEEE PAMI, 25(10), 2003.</p>
<p>[18] D. Kahneman, A. Treisman, & B. J. Gibbs. The reviewing of object ﬁles: Object-speciﬁc integration of information. Cognitive Psychology, 24(2):175–219, 1992.</p>
<p>[19] Y. Kazanovich & R. Borisyuk. An oscillatory neural model of multiple object tracking. Neural computation, 18(6):1413–1440, 2006.</p>
<p>[20] J. Lee & J. Maunsell. A normalization model of attentional modulation of single unit responses. PLoS One, 4(2), 2009.</p>
<p>[21] J. Lewis & D. Van Essen, “Corticocortical connections of visual, sensorimotor, & multimodal processing areas in the parietal lobe of the macaque monkey,” J. Comparative Neurol., 428(1), p. 112–137, 2000.</p>
<p>[22] V. Mahadevan & N. Vasconcelos. Saliency-based discriminant tracking. CVPR, 2009.</p>
<p>[23] T. Makovski & Y. Jiang. Feature binding in attentive tracking of distinct objects. Visual cognition, 17(1):180–194, 2009.</p>
<p>[24] J. Maunsell & S. Treue. Feature-based attention in visual cortex. Trends in Neurosci., 29(6), 2006.</p>
<p>[25] H. C. Nothdurft. Texture segmentation & pop-out from orientation contrast. Vision Research, 31(6):1073– 1078, 1991.</p>
<p>[26] H. C. Nothdurft. The conspicuousness of orientation & motion contrast. Spatial Vision, 7:341–363, 1993.</p>
<p>[27] H. C. Nothdurft. Salience from feature contrast: additivity across dimensions. Vision Research, 40:1183– 1201, 2000.</p>
<p>[28] L. Oksama & J. Hyn. Is multiple object tracking carried out automatically by an early vision mechanism independent of higher-order cognition? Visual Cognition, 11(5):631 – 671, 2004.</p>
<p>[29] Z. W. Pylyshyn & R. W. Storm. Tracking multiple independent targets: evidence for a parallel tracking mechanism. Spatial vision, 3(3):179–197, 1988.</p>
<p>[30] R. Rao. Bayesian inference & attentional modulation in the visual cortex. Neuroreport, 16(16), 2005.</p>
<p>[31] J. Reynolds & D. Heeger. The normalization model of attention. Neuron, 61(2):168–185, 2009.</p>
<p>[32] D. Ross et al., Incremental learning for robust visual tracking. IJCV, 77(1-3):125–141, 2008.</p>
<p>[33] N. Rust et al., How MT cells analyze the motion of visual patterns. Nat. Neurosci., 9(11), 2006.</p>
<p>[34] H. Sakata, H. Shibutani, & K. Kawano. Functional properties of visual tracking neurons in posterior parietal association cortex of the monkey. J Neurophysiol, 49(6):1364–1380, 1983.</p>
<p>[35] Y. Saalmann, I. Pigarev, & T. Vidyasagar, “Neural mechanisms of visual attention: how top-down feedback highlights relevant locations,” Science, 316(5831), p. 1612, 2007.</p>
<p>[36] E. Simoncelli & D. Heeger. A model of neuronal responses in visual area MT. Vision Research, 38(5):743–761, 1998.</p>
<p>[37] E. Vul et al., Explaining human multiple object tracking as resource-constrained approximate inference in a dynamic probabilistic model. NIPS, 22:1955–1963, 2009.</p>
<p>[38] A. Yilmaz, O. Javed, & M. Shah. Object tracking: A survey. ACM Computing Surveys, 38(4):13, 2006.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
