<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>321 nips-2012-Spectral learning of linear dynamics from generalised-linear observations with application to neural population data</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2012" href="../home/nips2012_home.html">nips2012</a> <a title="nips-2012-321" href="../nips2012/nips-2012-Spectral_learning_of_linear_dynamics_from_generalised-linear_observations_with_application_to_neural_population_data.html">nips2012-321</a> <a title="nips-2012-321-reference" href="#">nips2012-321-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>321 nips-2012-Spectral learning of linear dynamics from generalised-linear observations with application to neural population data</h1>
<br/><p>Source: <a title="nips-2012-321-pdf" href="http://papers.nips.cc/paper/4836-spectral-learning-of-linear-dynamics-from-generalised-linear-observations-with-application-to-neural-population-data.pdf">pdf</a></p><p>Author: Lars Buesing, Maneesh Sahani, Jakob H. Macke</p><p>Abstract: Latent linear dynamical systems with generalised-linear observation models arise in a variety of applications, for instance when modelling the spiking activity of populations of neurons. Here, we show how spectral learning methods (usually called subspace identiﬁcation in this context) for linear systems with linear-Gaussian observations can be extended to estimate the parameters of a generalised-linear dynamical system model despite a non-linear and non-Gaussian observation process. We use this approach to obtain estimates of parameters for a dynamical model of neural population data, where the observed spike-counts are Poisson-distributed with log-rates determined by the latent dynamical process, possibly driven by external inputs. We show that the extended subspace identiﬁcation algorithm is consistent and accurately recovers the correct parameters on large simulated data sets with a single calculation, avoiding the costly iterative computation of approximate expectation-maximisation (EM). Even on smaller data sets, it provides an effective initialisation for EM, avoiding local optima and speeding convergence. These beneﬁts are shown to extend to real neural data.</p><br/>
<h2>reference text</h2><p>[1] R. E. Kalman and R. S. Bucy. New results in linear ﬁltering and prediction theory. Trans. Am. Soc. Mech. Eng., Series D, Journal of Basic Engineering, 83:95–108, 1961.</p>
<p>[2] Z. Ghahramani and G. E. Hinton. Parameter estimation for linear dynamical systems. University of Toronto Technical Report, 6(CRG-TR-96-2), 1996.</p>
<p>[3] P. V. Overschee and B. D. Moor. N4sid: Subspace algorithms for the identiﬁcation of combined deterministic-stochastic systems. Automatica, 30(1):75–93, 1994.</p>
<p>[4] T. Katayama. Subspace methods for system identiﬁcation. Springer Verlag, 2005.</p>
<p>[5] H. Palanthandalam-Madapusi, S. Lacy, J. Hoagg, and D. Bernstein. Subspace-based identiﬁcation for linear and nonlinear systems. In Proceedings of the American Control Conference, 2005, pp. 2320–2334, 2005.</p>
<p>[6] E. N. Brown, R. E. Kass, and P. P. Mitra. Multiple neural spike train data analysis: state-ofthe-art and future challenges. Nat Neurosci, 7(5):456–61, 2004.</p>
<p>[7] M. M. Churchland, B. M. Yu, M. Sahani, and K. V. Shenoy. Techniques for extracting singletrial activity patterns from large-scale neural recordings. Curr Opin Neurobiol, 17(5):609–618, 2007.</p>
<p>[8] P. McCulloch and J. Nelder. Generalized linear models. Chapman and Hall, London, 1989.</p>
<p>[9] K. Yuan and M. Niranjan. Estimating a state-space model from point process observations: a note on convergence. Neural Comput, 22(8):1993–2001, 2010.</p>
<p>[10] B. L. Ho and R. E. Kalman. Effective construction of linear state-variable models from input/output functions. Regelungstechnik, 14(12):545–548, 1966.</p>
<p>[11] J. Møller, A. Syversveen, and R. Waagepetersen. Log gaussian cox processes. Scand J Stat, 25(3):451–482, 1998.</p>
<p>[12] V. Lawhern, W. Wu, N. Hatsopoulos, and L. Paninski. Population decoding of motor cortical activity using a generalized linear model with hidden states. J Neurosci Methods, 189(2):267– 280, 2010.</p>
<p>[13] A. Z. Mangion, K. Yuan, V. Kadirkamanathan, M. Niranjan, and G. Sanguinetti. Online variational inference for state-space models with point-process observations. Neural Comput, 23(8):1967–1999, 2011.</p>
<p>[14] M. Vidne, Y. Ahmadian, J. Shlens, J. Pillow, J. Kulkarni, A. Litke, E. Chichilnisky, E. Simoncelli, and L. Paninski. Modeling the impact of common noise inputs on the network activity of retinal ganglion cells. J Comput Neurosci, 2011.</p>
<p>[15] J. H. Macke, L. B¨ sing, J. P. Cunningham, B. M. Yu, K. V. Shenoy, and M. Sahani. Empiru ical models of spiking in neural populations. In Advances in Neural Information Processing Systems, vol. 24. Curran Associates, Inc., 2012.</p>
<p>[16] J. Kulkarni and L. Paninski. Common-input models for multiple neural spike-train data. Network, 18(4):375–407, 2007.</p>
<p>[17] L. Paninski. Maximum likelihood estimation of cascade point-process neural encoding models. Network, 15(4):243–262, 2004.</p>
<p>[18] R. E. Turner and M. Sahani. Two problems with variational expectation maximisation for time-series models. In D. Barber, A. T. Cemgil, and S. Chiappa, eds., Inference and Learning in Dynamic Models. Cambridge University Press, 2011.</p>
<p>[19] M. Krumin and S. Shoham. Generation of Spike Trains with Controlled Auto-and CrossCorrelation Functions. Neural Comput, pp. 1–23, 2009.</p>
<p>[20] J. Macke, P. Berens, A. Ecker, A. Tolias, and M. Bethge. Generating spike trains with speciﬁed correlation coefﬁcients. Neural Comput, 21(2):397–423, 2009.</p>
<p>[21] B. M. Yu, J. P. Cunningham, G. Santhanam, S. I. Ryu, K. V. Shenoy, and M. Sahani. Gaussianprocess factor analysis for low-dimensional single-trial analysis of neural population activity. J Neurophysiol, 102(1):614–635, 2009.</p>
<p>[22] M. M. Churchland, B. M. Yu, S. Ryu, G. Santhanam, and K. V. Shenoy. Neural variability in premotor cortex provides a signature of motor preparation. J Neurosci, 26(14):3697–3712, 2006.</p>
<p>[23] L. Paninski, Y. Ahmadian, D. Ferreira, S. Koyama, K. Rahnama Rad, M. Vidne, J. Vogelstein, and W. Wu. A new look at state-space models for neural data. J Comput Neurosci, 29:107–126, 2010.</p>
<p>[24] K. Yuan, M. Girolami, and M. Niranjan. Markov chain monte carlo methods for state-space models with point process observations. Neural Comput, 24(6):1462–1486, 2012.  9</p>
<br/>
<br/><br/><br/></body>
</html>
