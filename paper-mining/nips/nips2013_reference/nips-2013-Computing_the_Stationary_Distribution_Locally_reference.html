<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>66 nips-2013-Computing the Stationary Distribution Locally</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-66" href="../nips2013/nips-2013-Computing_the_Stationary_Distribution_Locally.html">nips2013-66</a> <a title="nips-2013-66-reference" href="#">nips2013-66-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>66 nips-2013-Computing the Stationary Distribution Locally</h1>
<br/><p>Source: <a title="nips-2013-66-pdf" href="http://papers.nips.cc/paper/5009-computing-the-stationary-distribution-locally.pdf">pdf</a></p><p>Author: Christina E. Lee, Asuman Ozdaglar, Devavrat Shah</p><p>Abstract: Computing the stationary distribution of a large ﬁnite or countably inﬁnite state space Markov Chain (MC) has become central in many problems such as statistical inference and network analysis. Standard methods involve large matrix multiplications as in power iteration, or simulations of long random walks, as in Markov Chain Monte Carlo (MCMC). Power iteration is costly, as it involves computation at every state. For MCMC, it is difﬁcult to determine whether the random walks are long enough to guarantee convergence. In this paper, we provide a novel algorithm that answers whether a chosen state in a MC has stationary probability larger than some ∆ ∈ (0, 1), and outputs an estimate of the stationary probability. Our algorithm is constant time, using information from a local neighborhood of the state on the graph induced by the MC, which has constant size relative to the state space. The multiplicative error of the estimate is upper bounded by a function of the mixing properties of the MC. Simulation results show MCs for which this method gives tight estimates. 1</p><br/>
<h2>reference text</h2><p>[1] B. Cipra. The best of the 20th century: Editors name top 10 algorithms. SIAM News, 33(4):1, May 2000.</p>
<p>[2] T.M. Semkow, S. Pomm, S. Jerome, and D.J. Strom, editors. Applied Modeling and Computations in Nuclear Science. American Chemical Society, Washington, DC, 2006.</p>
<p>[3] L. Page, S. Brin, R. Motwani, and T. Winograd. The PageRank citation ranking: Bringing order to the web. Technical Report 1999-66, November 1999.</p>
<p>[4] S. Assmussen and P. Glynn. Stochastic Simulation: Algorithms and Analysis (Stochastic Modelling and Applied Probability). Springer, 2010.</p>
<p>[5] N. Metropolis, A.W. Rosenbluth, M.N. Rosenbluth, A.H. Teller, and E. Teller. Equation of state calculations by fast computing machines. The Journal of Chemical Physics, 21:1087, 1953.</p>
<p>[6] W.K. Hastings. Monte Carlo sampling methods using Markov chains and their applications. Biometrika, 57(1):97–109, 1970.</p>
<p>[7] G.H. Golub and C.F. Van Loan. Matrix Computations. Johns Hopkins Studies in the Mathematical Sciences. Johns Hopkins University Press, 1996.</p>
<p>[8] D. Aldous and J. Fill. Reversible Markov chains and random walks on graphs: Chapter 2 (General Markov chains). book in preparation. URL: http:// www.stat.berkeley.edu/ ∼aldous/ RWG/ Chap2.pdf , pages 7, 19–20, 1999.</p>
<p>[9] B. Hajek. Hitting-time and occupation-time bounds implied by drift analysis with applications. Advances in Applied probability, pages 502–525, 1982.</p>
<p>[10] P. Diaconis and L. Saloff-Coste. What do we know about the Metropolis algorithm? Journal of Computer and System Sciences, 57(1):20–36, 1998.</p>
<p>[11] P. Diaconis. The Markov chain Monte Carlo revolution. Bulletin of the American Mathematical Society, 46(2):179–205, 2009.</p>
<p>[12] D.A. Levin, Y. Peres, and E.L. Wilmer. Markov chains and mixing times. Amer Mathematical Society, 2009.</p>
<p>[13] G. Jeh and J. Widom. Scaling personalized web search. In Proceedings of the 12th international conference on World Wide Web, pages 271–279, New York, NY, USA, 2003.</p>
<p>[14] D. Fogaras, B. Racz, K. Csalogany, and T. Sarlos. Towards scaling fully personalized PageRank: Algorithms, lower bounds, and experiments. Internet Mathematics, 2(3):333–358, 2005.</p>
<p>[15] K. Avrachenkov, N. Litvak, D. Nemirovsky, and N. Osipova. Monte Carlo methods in PageRank computation: When one iteration is sufﬁcient. SIAM Journal on Numerical Analysis, 45(2):890–904, 2007.</p>
<p>[16] B. Bahmani, A. Chowdhury, and A. Goel. Fast incremental and personalized PageRank. Proc. VLDB Endow., 4(3):173–184, December 2010.</p>
<p>[17] C. Borgs, M. Brautbar, J. Chayes, and S.-H. Teng. Sublinear time algorithm for PageRank computations and related applications. CoRR, abs/1202.2771, 2012.</p>
<p>[18] SP. Meyn and RL. Tweedie. Markov chains and stochastic stability. Springer-Verlag, 1993.</p>
<p>[19] C.E. Lee, A. Ozdaglar, and D. Shah. Computing the stationary distribution locally. MIT LIDS Report 2914, Nov 2013. URL: http://www.mit.edu/∼celee/LocalStationaryDistribution.pdf.</p>
<p>[20] F.G. Foster. On the stochastic matrices associated with certain queuing processes. The Annals of Mathematical Statistics, 24(3):355–360, 1953.  9</p>
<br/>
<br/><br/><br/></body>
</html>
