<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>327 nips-2013-The Randomized Dependence Coefficient</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-327" href="../nips2013/nips-2013-The_Randomized_Dependence_Coefficient.html">nips2013-327</a> <a title="nips-2013-327-reference" href="#">nips2013-327-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>327 nips-2013-The Randomized Dependence Coefficient</h1>
<br/><p>Source: <a title="nips-2013-327-pdf" href="http://papers.nips.cc/paper/5138-the-randomized-dependence-coefficient.pdf">pdf</a></p><p>Author: David Lopez-Paz, Philipp Hennig, Bernhard Schölkopf</p><p>Abstract: We introduce the Randomized Dependence Coefﬁcient (RDC), a measure of nonlinear dependence between random variables of arbitrary dimension based on the Hirschfeld-Gebelein-R´ nyi Maximum Correlation Coefﬁcient. RDC is deﬁned in e terms of correlation of random non-linear copula projections; it is invariant with respect to marginal distribution transformations, has low computational cost and is easy to implement: just ﬁve lines of R code, included at the end of the paper. 1</p><br/>
<h2>reference text</h2><p>[1] F. R. Bach and M. I. Jordan. Kernel independent component analysis. JMLR, 3:1–48, 2002.</p>
<p>[2] L. Breiman and J. H. Friedman. Estimating Optimal Transformations for Multiple Regression and Correlation. Journal of the American Statistical Association, 80(391):580–598, 1985.</p>
<p>[3] H. Gebelein. Das statistische Problem der Korrelation als Variations- und Eigenwertproblem und sein Zusammenhang mit der Ausgleichsrechnung. Zeitschrift f¨ r Angewandte Mathematik u und Mechanik, 21(6):364–379, 1941.</p>
<p>[4] I.I. Gihman and A.V. Skorohod. The Theory of Stochastic Processes, volume 1. Springer, 1974s.</p>
<p>[5] A. Gretton, K. M. Borgwardt, M. J. Rasch, B. Sch¨ lkopf, and A. Smola. A kernel two-sample o test. JMLR, 13:723–773, 2012.</p>
<p>[6] A. Gretton, O. Bousquet, A. Smola, and B. Sch¨ lkopf. Measuring statistical dependence with o Hilbert-Schmidt norms. In Proceedings of the 16th international conference on Algorithmic Learning Theory, pages 63–77. Springer-Verlag, 2005.</p>
<p>[7] W. K. H¨ rdle and L. Simar. Applied Multivariate Statistical Analysis. Springer, 2nd edition, a 2007.</p>
<p>[8] D. Hardoon and J. Shawe-Taylor. Convergence analysis of kernel canonical correlation analysis: theory and practice. Machine Learning, 74(1):23–38, 2009.</p>
<p>[9] T. Hastie and R. Tibshirani. Generalized additive models. Statistical Science, 1:297–310, 1986.</p>
<p>[10] L. K. Jones. A simple lemma on greedy approximation in Hilbert space and convergence rates for projection pursuit regression and neural network training. Annals of Statistics, 20(1):608– 613, 1992.</p>
<p>[11] Q. Le, T. Sarlos, and A. Smola. Fastfood – Approximating kernel expansions in loglinear time. In ICML, 2013.</p>
<p>[12] K. V. Mardia, J. T. Kent, and J. M. Bibby. Multivariate Analysis. Academic Press, 1979.</p>
<p>[13] P. Massart. The tight constant in the Dvoretzky-Kiefer-wolfowitz inequality. The Annals of Probability, 18(3), 1990.</p>
<p>[14] R. Nelsen. An Introduction to Copulas. Springer Series in Statistics, 2nd edition, 2006.</p>
<p>[15] B. Poczos, Z. Ghahramani, and J. Schneider. Copula-based kernel dependency measures. In ICML, 2012.</p>
<p>[16] A. Rahimi and B. Recht. Weighted sums of random kitchen sinks: Replacing minimization with randomization in learning. NIPS, 2008.</p>
<p>[17] A. R´ nyi. On measures of dependence. Acta Mathematica Academiae Scientiarum Hungarie cae, 10:441–451, 1959.</p>
<p>[18] D. N. Reshef, Y. A. Reshef, H. K. Finucane, S. R. Grossman, G. McVean, P. J. Turnbaugh, E. S. Lander, M. Mitzenmacher, and P. C. Sabeti. Detecting novel associations in large data sets. Science, 334(6062):1518–1524, 2011.</p>
<p>[19] B. Sch¨ lkopf and A.J. Smola. Learning with Kernels. MIT Press, 2002. o `</p>
<p>[20] A. Sklar. Fonctions de repartition a n dimension set leurs marges. Publ. Inst. Statis. Univ. Paris, 8(1):229–231, 1959.</p>
<p>[21] L. Song, A. Smola, A. Gretton, J. Bedo, and K. Borgwardt. Feature selection via dependence maximization. JMLR, 13:1393–1434, June 2012.</p>
<p>[22] M.L. Stein. Interpolation of Spatial Data. Springer, 1999.</p>
<p>[23] G. J. Sz´ kely and M. L. Rizzo. Rejoinder: Brownian distance covariance. Annals of Applied e Statistics, 3(4):1303–1308, 2009.</p>
<p>[24] G. J. Sz´ kely, M. L. Rizzo, and N. K. Bakirov. Measuring and testing dependence by correlae tion of distances. Annals of Statistics, 35(6), 2007.</p>
<p>[25] K. Zhang, J. Peters, D. Janzing, and B.Sch¨ lkopf. Kernel-based conditional independence test o and application in causal discovery. CoRR, abs/1202.3775, 2012.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
