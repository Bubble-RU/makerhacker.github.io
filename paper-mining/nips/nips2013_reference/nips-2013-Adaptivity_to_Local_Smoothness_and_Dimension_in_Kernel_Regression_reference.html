<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>31 nips-2013-Adaptivity to Local Smoothness and Dimension in Kernel Regression</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-31" href="../nips2013/nips-2013-Adaptivity_to_Local_Smoothness_and_Dimension_in_Kernel_Regression.html">nips2013-31</a> <a title="nips-2013-31-reference" href="#">nips2013-31-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>31 nips-2013-Adaptivity to Local Smoothness and Dimension in Kernel Regression</h1>
<br/><p>Source: <a title="nips-2013-31-pdf" href="http://papers.nips.cc/paper/5103-adaptivity-to-local-smoothness-and-dimension-in-kernel-regression.pdf">pdf</a></p><p>Author: Samory Kpotufe, Vikas Garg</p><p>Abstract: We present the ﬁrst result for kernel regression where the procedure adapts locally at a point x to both the unknown local dimension of the metric space X and the unknown H¨ lder-continuity of the regression function at x. The result holds with o high probability simultaneously at all points x in a general metric space X of unknown structure. 1</p><br/>
<h2>reference text</h2><p>[1] C. J. Stone. Optimal rates of convergence for non-parametric estimators. Ann. Statist., 8:1348– 1360, 1980.</p>
<p>[2] C. J. Stone. Optimal global rates of convergence for non-parametric estimators. Ann. Statist., 10:1340–1353, 1982.</p>
<p>[3] W. S. Cleveland and C. Loader. Smoothing by local regression: Principles and methods. Statistical theory and computational aspects of smoothing, 1049, 1996.</p>
<p>[4] L. Gyorﬁ, M. Kohler, A. Krzyzak, and H. Walk. A Distribution Free Theory of Nonparametric Regression. Springer, New York, NY, 2002. 8</p>
<p>[5] J. Lafferty and L. Wasserman. Rodeo: Sparse nonparametric regression in high dimensions. Arxiv preprint math/0506342, 2005.</p>
<p>[6] O. V. Lepski, E. Mammen, and V. G. Spokoiny. Optimal spatial adaptation to inhomogeneous smoothness: an approach based on kernel estimates with variable bandwidth selectors. The Annals of Statistics, pages 929–947, 1997.</p>
<p>[7] O. V. Lepski and V. G. Spokoiny. Optimal pointwise adaptive methods in nonparametric estimation. The Annals of Statistics, 25(6):2512–2546, 1997.</p>
<p>[8] O. V. Lepski and B. Y. Levit. Adaptive minimax estimation of inﬁnitely differentiable functions. Mathematical Methods of Statistics, 7(2):123–156, 1998.</p>
<p>[9] S. Kpotufe. k-NN Regression Adapts to Local Intrinsic Dimension. NIPS, 2011.</p>
<p>[10] K. Clarkson. Nearest-neighbor searching and metric space dimensions. Nearest-Neighbor Methods for Learning and Vision: Theory and Practice, 2005.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
