<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>343 nips-2013-Unsupervised Structure Learning of Stochastic And-Or Grammars</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-343" href="../nips2013/nips-2013-Unsupervised_Structure_Learning_of_Stochastic_And-Or_Grammars.html">nips2013-343</a> <a title="nips-2013-343-reference" href="#">nips2013-343-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>343 nips-2013-Unsupervised Structure Learning of Stochastic And-Or Grammars</h1>
<br/><p>Source: <a title="nips-2013-343-pdf" href="http://papers.nips.cc/paper/5126-unsupervised-structure-learning-of-stochastic-and-or-grammars.pdf">pdf</a></p><p>Author: Kewei Tu, Maria Pavlovskaia, Song-Chun Zhu</p><p>Abstract: Stochastic And-Or grammars compactly represent both compositionality and reconﬁgurability and have been used to model different types of data such as images and events. We present a uniﬁed formalization of stochastic And-Or grammars that is agnostic to the type of the data being modeled, and propose an unsupervised approach to learning the structures as well as the parameters of such grammars. Starting from a trivial initial grammar, our approach iteratively induces compositions and reconﬁgurations in a uniﬁed manner and optimizes the posterior probability of the grammar. In our empirical evaluation, we applied our approach to learning event grammars and image grammars and achieved comparable or better performance than previous approaches. 1</p><br/>
<h2>reference text</h2><p>[1] S.-C. Zhu and D. Mumford, “A stochastic grammar of images,” Found. Trends. Comput. Graph. Vis., vol. 2, no. 4, pp. 259–362, 2006.</p>
<p>[2] Y. Jin and S. Geman, “Context and hierarchy in a probabilistic image model,” in CVPR, 2006.</p>
<p>[3] Y. Zhao and S. C. Zhu, “Image parsing with stochastic scene grammar,” in NIPS, 2011.</p>
<p>[4] Y. A. Ivanov and A. F. Bobick, “Recognition of visual activities and interactions by stochastic parsing,” Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 22, no. 8, pp. 852–872, 2000.</p>
<p>[5] M. S. Ryoo and J. K. Aggarwal, “Recognition of composite human activities through context-free grammar based representation,” in CVPR, 2006.</p>
<p>[6] Z. Zhang, T. Tan, and K. Huang, “An extended grammar system for learning and recognizing complex visual events,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 33, no. 2, pp. 240–255, Feb. 2011.</p>
<p>[7] M. Pei, Y. Jia, and S.-C. Zhu, “Parsing video events with goal inference and intent prediction,” in ICCV, 2011.</p>
<p>[8] C. D. Manning and H. Sch¨ tze, Foundations of statistical natural language processing. u MA, USA: MIT Press, 1999.  Cambridge,</p>
<p>[9] P. Liang, M. I. Jordan, and D. Klein, “Probabilistic grammars and hierarchical dirichlet processes,” The handbook of applied Bayesian analysis, 2009.</p>
<p>[10] H. Poon and P. Domingos, “Sum-product networks : A new deep architecture,” in Proceedings of the Twenty-Seventh Conference on Uncertainty in Artiﬁcial Intelligence (UAI), 2011.</p>
<p>[11] J. K. Baker, “Trainable grammars for speech recognition,” in Speech Communication Papers for the 97th Meeting of the Acoustical Society of America, 1979.</p>
<p>[12] D. Klein and C. D. Manning, “Corpus-based induction of syntactic structure: Models of dependency and constituency,” in Proceedings of ACL, 2004.</p>
<p>[13] S. Wang, Y. Wang, and S.-C. Zhu, “Hierarchical space tiling for scene modeling,” in Computer Vision– ACCV 2012. Springer, 2013, pp. 796–810.</p>
<p>[14] A. Stolcke and S. M. Omohundro, “Inducing probabilistic grammars by Bayesian model merging,” in ICGI, 1994, pp. 106–118.</p>
<p>[15] Z. Solan, D. Horn, E. Ruppin, and S. Edelman, “Unsupervised learning of natural languages,” Proc. Natl. Acad. Sci., vol. 102, no. 33, pp. 11 629–11 634, August 2005.</p>
<p>[16] K. Tu and V. Honavar, “Unsupervised learning of probabilistic context-free grammar using iterative biclustering,” in Proceedings of 9th International Colloquium on Grammatical Inference (ICGI 2008), ser. LNCS 5278, 2008.</p>
<p>[17] Z. Si and S. Zhu, “Learning and-or templates for object modeling and recognition,” IEEE Trans on Pattern Analysis and Machine Intelligence, 2013.</p>
<p>[18] Z. Si, M. Pei, B. Yao, and S.-C. Zhu, “Unsupervised learning of event and-or grammar and semantics from video,” in ICCV, 2011.</p>
<p>[19] J. F. Allen, “Towards a general theory of action and time,” Artiﬁcial intelligence, vol. 23, no. 2, pp. 123–154, 1984.</p>
<p>[20] V. I. Spitkovsky, H. Alshawi, D. Jurafsky, and C. D. Manning, “Viterbi training improves unsupervised dependency parsing,” in Proceedings of the Fourteenth Conference on Computational Natural Language Learning, ser. CoNLL ’10, 2010.</p>
<p>[21] K. Tu and V. Honavar, “Unambiguity regularization for unsupervised learning of probabilistic grammars,” in Proceedings of the 2012 Conference on Empirical Methods in Natural Language Processing and Natural Language Learning (EMNLP-CoNLL 2012), 2012.</p>
<p>[22] S. C. Madeira and A. L. Oliveira, “Biclustering algorithms for biological data analysis: A survey.” IEEE/ACM Trans. on Comp. Biol. and Bioinformatics, vol. 1, no. 1, pp. 24–45, 2004.</p>
<p>[23] P. Wei, N. Zheng, Y. Zhao, and S.-C. Zhu, “Concurrent action detection with structural prediction,” in Proc. Intl Conference on Computer Vision (ICCV), 2013.</p>
<p>[24] A. Barbu, M. Pavlovskaia, and S. Zhu, “Rates for inductive learning of compositional models,” in AAAI Workshop on Learning Rich Representations from Low-Level Sensors (RepLearning), 2013.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
