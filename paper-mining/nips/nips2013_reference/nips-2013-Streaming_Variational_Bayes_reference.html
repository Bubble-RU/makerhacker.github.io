<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>317 nips-2013-Streaming Variational Bayes</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-317" href="../nips2013/nips-2013-Streaming_Variational_Bayes.html">nips2013-317</a> <a title="nips-2013-317-reference" href="#">nips2013-317-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>317 nips-2013-Streaming Variational Bayes</h1>
<br/><p>Source: <a title="nips-2013-317-pdf" href="http://papers.nips.cc/paper/4980-streaming-variational-bayes.pdf">pdf</a></p><p>Author: Tamara Broderick, Nicholas Boyd, Andre Wibisono, Ashia C. Wilson, Michael Jordan</p><p>Abstract: We present SDA-Bayes, a framework for (S)treaming, (D)istributed, (A)synchronous computation of a Bayesian posterior. The framework makes streaming updates to the estimated posterior according to a user-speciﬁed approximation batch primitive. We demonstrate the usefulness of our framework, with variational Bayes (VB) as the primitive, by ﬁtting the latent Dirichlet allocation model to two large-scale document collections. We demonstrate the advantages of our algorithm over stochastic variational inference (SVI) by comparing the two after a single pass through a known amount of data—a case where SVI may be applied—and in the streaming setting, where SVI does not apply. 1</p><br/>
<h2>reference text</h2><p>[1] F. Niu, B. Recht, C. R´ , and S. J. Wright. Hogwild!: A lock-free approach to parallelizing stochastic e gradient descent. In Neural Information Processing Systems, 2011.</p>
<p>[2] A. Kleiner, A. Talwalkar, P. Sarkar, and M. Jordan. The big data bootstrap. In International Conference on Machine Learning, 2012.</p>
<p>[3] M. Hoffman, D. M. Blei, and F. Bach. Online learning for latent Dirichlet allocation. In Neural Information Processing Systems, volume 23, pages 856–864, 2010.</p>
<p>[4] M. Hoffman, D. M. Blei, J. Paisley, and C. Wang. Stochastic variational inference. Journal of Machine Learning Research, 14:1303–1347.</p>
<p>[5] C. Wang, J. Paisley, and D. M. Blei. Online variational inference for the hierarchical Dirichlet process. In Artiﬁcial Intelligence and Statistics, 2011.</p>
<p>[6] M. J. Wainwright and M. I. Jordan. Graphical models, exponential families, and variational inference. Foundations and Trends in Machine Learning, 1(1-2):1–305, 2008.</p>
<p>[7] T. P. Minka. Expectation propagation for approximate Bayesian inference. In Uncertainty in Artiﬁcial Intelligence, pages 362–369. Morgan Kaufmann, 2001.</p>
<p>[8] T. P. Minka. A family of algorithms for approximate Bayesian inference. PhD thesis, Massachusetts Institute of Technology, 2001.</p>
<p>[9] M. Opper. A Bayesian approach to on-line learning.</p>
<p>[10] K. R Canini, L. Shi, and T. L Grifﬁths. Online inference of topics with latent Dirichlet allocation. In Artiﬁcial Intelligence and Statistics, volume 5, 2009.</p>
<p>[11] A. Honkela and H. Valpola. On-line variational Bayesian learning. In International Symposium on Independent Component Analysis and Blind Signal Separation, pages 803–808, 2003.</p>
<p>[12] J. Luts, T. Broderick, and M. P. Wand. Real-time semiparametric regression. Journal of Computational and Graphical Statistics, to appear. Preprint arXiv:1209.3550.</p>
<p>[13] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent Dirichlet allocation. Journal of Machine Learning Research, 3:993–1022, 2003.</p>
<p>[14] T. Minka and J. Lafferty. Expectation-propagation for the generative aspect model. In Uncertainty in Artiﬁcial Intelligence, pages 352–359. Morgan Kaufmann, 2002.</p>
<p>[15] Y. Teh, D. Newman, and M. Welling. A collapsed variational Bayesian inference algorithm for latent Dirichlet allocation. In Neural Information Processing Systems, 2006.</p>
<p>[16] A. Asuncion, M. Welling, P. Smyth, and Y. Teh. On smoothing and inference for topic models. In Uncertainty in Artiﬁcial Intelligence, 2009.</p>
<p>[17] M. Hoffman. Online inference for LDA (Python code) at http://www.cs.princeton.edu/˜blei/downloads/onlineldavb.tar, 2010.</p>
<p>[18] R. Ranganath, C. Wang, D. M. Blei, and E. P. Xing. An adaptive learning rate for stochastic variational inference. In International Conference on Machine Learning, 2013.</p>
<p>[19] W. L. Buntine and A. Jakulin. Applying discrete PCA in data analysis. In Uncertainty in Artiﬁcial Intelligence.</p>
<p>[20] M. Seeger. Expectation propagation for exponential families. Technical report, University of California at Berkeley, 2005.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
