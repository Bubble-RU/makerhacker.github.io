<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>351 nips-2013-What Are the Invariant Occlusive Components of Image Patches? A Probabilistic Generative Approach</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-351" href="../nips2013/nips-2013-What_Are_the_Invariant_Occlusive_Components_of_Image_Patches%3F_A_Probabilistic_Generative_Approach.html">nips2013-351</a> <a title="nips-2013-351-reference" href="#">nips2013-351-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>351 nips-2013-What Are the Invariant Occlusive Components of Image Patches? A Probabilistic Generative Approach</h1>
<br/><p>Source: <a title="nips-2013-351-pdf" href="http://papers.nips.cc/paper/5195-what-are-the-invariant-occlusive-components-of-image-patches-a-probabilistic-generative-approach.pdf">pdf</a></p><p>Author: Zhenwen Dai, Georgios Exarchakis, Jörg Lücke</p><p>Abstract: We study optimal image encoding based on a generative approach with non-linear feature combinations and explicit position encoding. By far most approaches to unsupervised learning of visual features, such as sparse coding or ICA, account for translations by representing the same features at different positions. Some earlier models used a separate encoding of features and their positions to facilitate invariant data encoding and recognition. All probabilistic generative models with explicit position encoding have so far assumed a linear superposition of components to encode image patches. Here, we for the ﬁrst time apply a model with non-linear feature superposition and explicit position encoding for patches. By avoiding linear superpositions, the studied model represents a closer match to component occlusions which are ubiquitous in natural images. In order to account for occlusions, the non-linear model encodes patches qualitatively very different from linear models by using component representations separated into mask and feature parameters. We ﬁrst investigated encodings learned by the model using artiﬁcial data with mutually occluding components. We ﬁnd that the model extracts the components, and that it can correctly identify the occlusive components with the hidden variables of the model. On natural image patches, the model learns component masks and features for typical image components. By using reverse correlation, we estimate the receptive ﬁelds associated with the model’s hidden units. We ﬁnd many Gabor-like or globular receptive ﬁelds as well as ﬁelds sensitive to more complex structures. Our results show that probabilistic models that capture occlusions and invariances can be trained efﬁciently on image patches, and that the resulting encoding represents an alternative model for the neural encoding of images in the primary visual cortex. 1</p><br/>
<h2>reference text</h2><p>[1] D. Mumford and B. Gidas. Stochastic models for generic images. Q. Appl. Math., 59:85–111, 2001.</p>
<p>[2] J. L¨ cke, R. Turner, M. Sahani, and M. Henniges. Occlusive Components Analysis. NIPS, 22:1069–77, u 2009.</p>
<p>[3] Nicolas LeRoux, Nicolas Heess, Jamie Shotton, and John Winn. Learning a generative model of images by factoring appearance and shape. Neural Computation, 23:593–650, 2011.</p>
<p>[4] D. Zoran and Y. Weiss. Natural images, Gaussian mixtures and dead leaves. NIPS, 25:1745–1753, 2012.</p>
<p>[5] J. Bornschein, M. Henniges, and J. L¨ cke. Are V1 receptive ﬁelds shaped by low-level visual occlusions? u A comparative study. PLoS Computational Biology, 9(6):e1003062.</p>
<p>[6] G. E. Hinton. A parallel computation that assigns canonical object-based frames of reference. In Proc. IJCAI, pages 683–685, 1981.</p>
<p>[7] C. H. Anderson and D. C. Van Essen. Shifter circuits: a computational strategy for dynamic aspects of visual processing. PNAS, 84(17):6297–6301, 1987.</p>
<p>[8] M. Lades, J. Vorbr¨ ggen, J. Buhmann, J. Lange, C. v. d. Malsburg, R. W¨ rtz, and W. Konen. Distoru u tion invariant object recognition in the dynamic link architecture. IEEE Transactions on Computers, 42(3):300–311, 1993.</p>
<p>[9] A. Hyv¨ rinen and P. Hoyer. Emergence of phase- and shift-invariant features by decomposition of natural a images into independent feature subspaces. Neural Computation, 12(7):1705–20, 2000.</p>
<p>[10] D. W. Arathorn. Map-Seeking circuits in Visual Cognition — A Computational Mechanism for Biological and Machine Vision. Standford Univ. Press, Stanford, California, 2002.  8</p>
<p>[11] J. L¨ cke, C. Keck, and C. von der Malsburg. Rapid convergence to feature layer correspondences. Neural u Computation, 20(10):2441–2463, 2008.</p>
<p>[12] Y. LeCun, K. Kavukcuoglu, and C. Farabet. Convolutional networks and applications in vision. Proceedings of 2010 IEEE International Symposium on Circuits and Systems, pages 253–6, 2010.</p>
<p>[13] Y. Hu, K. Zhai, S. Williamson, and J. Boyd-Graber. Modeling Images using Transformed Indian Buffet Processes. In ICML, 2012.</p>
<p>[14] N. Jojic and B. Frey. Learning ﬂexible sprites in video layers. In CVPR, 2001.</p>
<p>[15] C. K. I. Williams and M. K. Titsias. Greedy learning of multiple objects in images using robust statistics and factorial learning. Neural Computation, 16:1039–62, 2004.</p>
<p>[16] J. B. Tenenbaum and W. T. Freeman. Separating Style and Content with Bilinear Models. Neural Computation, 12(6):1247–83, 2000.</p>
<p>[17] P. Berkes, R. E. Turner, and M. Sahani. A structured model of video reproduces primary visual cortical organisation. PLoS Computational Biology, 5(9):e1000495, 2009.</p>
<p>[18] C. F. Cadieu and B. A. Olshausen. Learning intermediate-level representations of form and motion from natural movies. Neural Computation, 24(4):827–866, 2012.</p>
<p>[19] K. Kavukcuoglu, P. Sermanet, Y.L. Boureau, K. Gregor, M. Mathieu, and Y. LeCun. Learning convolutional feature hierarchies for visual recognition. NIPS, 23:14, 2010.</p>
<p>[20] K. Gregor and Y. LeCun. Efﬁcient learning of sparse invariant representations. CoRR, abs/1105.5307, 2011.</p>
<p>[21] J. Eggert, H. Wersing, and E. K¨ rner. Transformation-invariant representation and NMF. In 2004 IEEE o International Joint Conference on Neural Networks, pages 2535–39, 2004.</p>
<p>[22] Z. Dai and J. L¨ cke. Unsupervised learning of translation invariant occlusive components. In CVPR, u pages 2400–2407. 2012.</p>
<p>[23] J. L¨ cke and J. Eggert. Expectation truncation and the beneﬁts of preselection in training generative u models. Journal of Machine Learning Research, 11:2855–900, 2010.</p>
<p>[24] J. H. van Hateren and A. van der Schaaf. Independent component ﬁlters of natural images compared with simple cells in primary visual cortex. Proceedings of the Royal Society of London B, 265:359–66, 1998.</p>
<p>[25] M. Riesenhuber and T. Poggio. Hierarchical models of object recognition in cortex. Nature Neuroscience, 211(11):1019 – 1025, 1999.</p>
<p>[26] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classiﬁcation with deep convolutional neural networks. In NIPS, volume 25, pages 1106–1114, 2012.</p>
<p>[27] M. Rehn and F. T. Sommer. A network that uses few active neurones to code visual input predicts the diverse shapes of cortical receptive ﬁelds. Journal of Computational Neuroscience, 22(2):135–46, 2007.</p>
<p>[28] J. L¨ cke. Receptive ﬁeld self-organization in a model of the ﬁne-structure in V1 cortical columns. Neural u Computation, 21(10):2805–45, 2009.</p>
<p>[29] D. L. Ringach. Spatial structure and symmetry of simple-cell receptive ﬁelds in macaque primary visual cortex. Journal of Neurophysiology, 88:455–63, 2002.</p>
<p>[30] G. Puertas, J. Bornschein, and J. L¨ cke. The maximal causes of natural scenes are edge ﬁlters. In NIPS, u volume 23, pages 1939–1947. 2010.</p>
<p>[31] A. Szlam, K. Kavukcuoglu, and Y. LeCun. Convolutional matching pursuit and dictionary training. arXiv preprint arXiv:1010.0422, 2010.</p>
<p>[32] B. A. Olshausen, C. F. Cadieu, and D. K. Warland. Learning real and complex overcomplete representations from the statistics of natural images. volume 7446, page 74460S. SPIE, 2009.</p>
<p>[33] B. A. Olshausen. Highly overcomplete sparse coding. In Proc. of HVEI, page 86510S, 2013.</p>
<p>[34] M. Eickenberg, R.J. Rowekamp, M. Kouh, and T.O. Sharpee. Characterizing responses of translationinvariant neurons to natural stimuli: maximally informative invariant dimensions. Neural Computation, 24(9):2384–421, 2012.</p>
<p>[35] B. Vintch, A. Zaharia, J.A. Movshon, and E.P. Simoncelli. Efﬁcient and direct estimation of a neural subunit model for sensory coding. In Proc. of NIPS, pages 3113–3121, 2012.</p>
<p>[36] B. Olshausen, C. Anderson, and D. Van Essen. A neurobiological model of visual attention and invariant pattern recognition based on dynamic routing of information. J Neuroscience, 13(11):4700–4719, 1993.</p>
<p>[37] R. Memisevic and G. E. Hinton. Learning to represent spatial transformations with factored higher-order Boltzmann machines. Neural Computation, 22(6):1473–1492, 2010.</p>
<p>[38] M.J.D. Powell. An efﬁcient method for ﬁnding the minimum of a function of several variables without calculating derivatives. The Computer Journal, 7(2):155–162, 1964.  9</p>
<br/>
<br/><br/><br/></body>
</html>
