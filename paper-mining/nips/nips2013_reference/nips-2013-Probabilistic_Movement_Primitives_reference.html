<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>255 nips-2013-Probabilistic Movement Primitives</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-255" href="../nips2013/nips-2013-Probabilistic_Movement_Primitives.html">nips2013-255</a> <a title="nips-2013-255-reference" href="#">nips2013-255-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>255 nips-2013-Probabilistic Movement Primitives</h1>
<br/><p>Source: <a title="nips-2013-255-pdf" href="http://papers.nips.cc/paper/5177-probabilistic-movement-primitives.pdf">pdf</a></p><p>Author: Alexandros Paraschos, Christian Daniel, January Peters, Gerhard Neumann</p><p>Abstract: Movement Primitives (MP) are a well-established approach for representing modular and re-usable robot movement generators. Many state-of-the-art robot learning successes are based MPs, due to their compact representation of the inherently continuous and high dimensional robot movements. A major goal in robot learning is to combine multiple MPs as building blocks in a modular control architecture to solve complex tasks. To this effect, a MP representation has to allow for blending between motions, adapting to altered task variables, and co-activating multiple MPs in parallel. We present a probabilistic formulation of the MP concept that maintains a distribution over trajectories. Our probabilistic approach allows for the derivation of new operations which are essential for implementing all aforementioned properties in one framework. In order to use such a trajectory distribution for robot movement control, we analytically derive a stochastic feedback controller which reproduces the given trajectory distribution. We evaluate and compare our approach to existing methods on several simulated as well as real robot scenarios. 1</p><br/>
<h2>reference text</h2><p>[1] A. Ijspeert and S. Schaal. Learning Attractor Landscapes for Learning Motor Primitives. In Advances in Neural Information Processing Systems 15, (NIPS). MIT Press, Cambridge, MA, 2003.</p>
<p>[2] M. Khansari-Zadeh and A. Billard. Learning Stable Non-Linear Dynamical Systems with Gaussian Mixture Models. IEEE Transaction on Robotics, 2011.</p>
<p>[3] J. Kober, K. Mülling, O. Kroemer, C. Lampert, B. Schölkopf, and J. Peters. Movement Templates for Learning of Hitting and Batting. In International Conference on Robotics and Automation (ICRA), 2010.</p>
<p>[4] J. Kober and J. Peters. Policy Search for Motor Primitives in Robotics. Machine Learning, pages 1–33, 2010.</p>
<p>[5] A. Ude, A. Gams, T. Asfour, and J. Morimoto. Task-Speciﬁc Generalization of Discrete and Periodic Dynamic Movement Primitives. Trans. Rob., (5), October 2010.</p>
<p>[6] B. da Silva, G. Konidaris, and A. Barto. Learning Parameterized Skills. In International Conference on Machine Learning, 2012.</p>
<p>[7] P. Kormushev, S. Calinon, and D. Caldwell. Robot Motor Skill Coordination with EM-based Reinforcement Learning. In Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2010.</p>
<p>[8] C. Daniel, G. Neumann, and J. Peters. Learning Concurrent Motor Skills in Versatile Solution Spaces. In IEEE/RSJ International Conference on Intelligent Robots and Systems, 2012.</p>
<p>[9] George Konidaris, Scott Kuindersma, Roderic Grupen, and Andrew Barto. Robot Learning from Demonstration by Constructing Skill Trees. International Journal of Robotics Research, 31(3):360–375, March 2012.</p>
<p>[10] A. dAvella and E. Bizzi. Shared and Speciﬁc Muscle Synergies in Natural Motor Behaviors. Proceedings of the National Academy of Sciences (PNAS), 102(3):3076–3081, 2005.</p>
<p>[11] M. Williams, B.and Toussaint and A. Storkey. Modelling Motion Primitives and their Timing in Biologically Executed Movements. In Advances in Neural Information Processing Systems (NIPS), 2007.</p>
<p>[12] L. Rozo, S. Calinon, D. G. Caldwell, P. Jimenez, and C. Torras. Learning Collaborative Impedance-Based Robot Behaviors. In AAAI Conference on Artiﬁcial Intelligence, 2013.</p>
<p>[13] E. Rueckert, G. Neumann, M. Toussaint, and W.Pr Maass. Learned Graphical Models for Probabilistic Planning provide a new Class of Movement Primitives. 2012.</p>
<p>[14] L. Righetti and A Ijspeert. Programmable central pattern generators: an application to biped locomotion control. In Proceedings of the 2006 IEEE International Conference on Robotics and Automation, 2006.</p>
<p>[15] A. Paraschos, G Neumann, and J. Peters. A probabilistic approach to robot trajectory generation. In Proceedings of the International Conference on Humanoid Robots (HUMANOIDS), 2013.</p>
<p>[16] S. Calinon, P. Kormushev, and D. Caldwell. Compliant Skills Acquisition and Multi-Optima Policy Search with EM-based Reinforcement Learning. Robotics and Autonomous Systems (RAS), 61(4):369 – 379, 2013.</p>
<p>[17] E. Todorov and M. Jordan. Optimal Feedback Control as a Theory of Motor Coordination. Nature Neuroscience, 5:1226–1235, 2002.</p>
<p>[18] S. Schaal, J. Peters, J. Nakanishi, and A. Ijspeert. Learning Movement Primitives. In International Symposium on Robotics Research, (ISRR), 2003.</p>
<p>[19] A. Lazaric and M. Ghavamzadeh. Bayesian Multi-Task Reinforcement Learning. In Proceedings of the 27th International Conference on Machine Learning (ICML), 2010.</p>
<p>[20] J. Peters, M. Mistry, F. E. Udwadia, J. Nakanishi, and S. Schaal. A Unifying Methodology for Robot Control with Redundant DOFs. Autonomous Robots, (1):1–12, 2008.</p>
<p>[21] H. Stark and J. Woods. Probability and Random Processes with Applications to Signal Processing (3rd Edition). 3 edition, August 2001.</p>
<p>[22] M. Toussaint. Robot Trajectory Optimization using Approximate Inference. In Proceedings of the 26th International Conference on Machine Learning, (ICML), 2009.  9</p>
<br/>
<br/><br/><br/></body>
</html>
