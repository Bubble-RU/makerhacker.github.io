<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>155 nips-2013-Learning Hidden Markov Models from Non-sequence Data via Tensor Decomposition</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-155" href="../nips2013/nips-2013-Learning_Hidden_Markov_Models_from_Non-sequence_Data_via_Tensor_Decomposition.html">nips2013-155</a> <a title="nips-2013-155-reference" href="#">nips2013-155-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>155 nips-2013-Learning Hidden Markov Models from Non-sequence Data via Tensor Decomposition</h1>
<br/><p>Source: <a title="nips-2013-155-pdf" href="http://papers.nips.cc/paper/5065-learning-hidden-markov-models-from-non-sequence-data-via-tensor-decomposition.pdf">pdf</a></p><p>Author: Tzu-Kuo Huang, Jeff Schneider</p><p>Abstract: Learning dynamic models from observed data has been a central issue in many scientiﬁc studies or engineering tasks. The usual setting is that data are collected sequentially from trajectories of some dynamical system operation. In quite a few modern scientiﬁc modeling tasks, however, it turns out that reliable sequential data are rather difﬁcult to gather, whereas out-of-order snapshots are much easier to obtain. Examples include the modeling of galaxies, chronic diseases such Alzheimer’s, or certain biological processes. Existing methods for learning dynamic model from non-sequence data are mostly based on Expectation-Maximization, which involves non-convex optimization and is thus hard to analyze. Inspired by recent advances in spectral learning methods, we propose to study this problem from a different perspective: moment matching and spectral decomposition. Under that framework, we identify reasonable assumptions on the generative process of non-sequence data, and propose learning algorithms based on the tensor decomposition method [2] to provably recover ﬁrstorder Markov models and hidden Markov models. To the best of our knowledge, this is the ﬁrst formal guarantee on learning from non-sequence data. Preliminary simulation results conﬁrm our theoretical ﬁndings. 1</p><br/>
<h2>reference text</h2><p>[1] A. Anandkumar, D. P. Foster, D. Hsu, S. M. Kakade, and Y.-K. Liu. A spectral algorithm for latent dirichlet allocation. arXiv preprint arXiv:1204.6703v4, 2013.</p>
<p>[2] A. Anandkumar, R. Ge, D. Hsu, S. M. Kakade, and M. Telgarsky. Tensor decompositions for learning latent variable models. arXiv preprint arXiv:1210.7559v2, 2012.</p>
<p>[3] A. Anandkumar, D. Hsu, and S. M. Kakade. A method of moments for mixture models and hidden Markov models. arXiv preprint arXiv:1203.0683, 2012.</p>
<p>[4] S. Arora, R. Ge, Y. Halpern, D. Mimno, A. Moitra, D. Sontag, Y. Wu, and M. Zhu. A practical algorithm for topic modeling with provable guarantees. arXiv preprint arXiv:1212.4777, 2012.</p>
<p>[5] D. Hsu and S. M. Kakade. Learning mixtures of spherical gaussians: moment methods and spectral decompositions. In Proceedings of the 4th conference on Innovations in Theoretical Computer Science, pages 11–20. ACM, 2013.</p>
<p>[6] T.-K. Huang and J. Schneider. Learning linear dynamical systems without sequence information. In Proceedings of the 26th International Conference on Machine Learning, pages 425–432, 2009.</p>
<p>[7] T.-K. Huang and J. Schneider. Learning auto-regressive models from sequence and nonsequence data. In Advances in Neural Information Processing Systems 24, pages 1548–1556. 2011.</p>
<p>[8] T.-K. Huang, L. Song, and J. Schneider. Learning nonlinear dynamic models from nonsequenced data. In Proceedings of the 13th International Conference on Artiﬁcial Intelligence and Statistics, 2010.</p>
<p>[9] M. G. Rabbat, M. A. Figueiredo, and R. D. Nowak. Network inference from co-occurrences. Information Theory, IEEE Transactions on, 54(9):4053–4068, 2008.</p>
<p>[10] G. Stewart. On the perturbation of pseudo-inverses, projections and linear least squares problems. SIAM review, 19(4):634–662, 1977.</p>
<p>[11] X. Zhu, A. B. Goldberg, M. Rabbat, and R. Nowak. Learning bigrams from unigrams. In the Proceedings of 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technology, Columbus, OH, 2008.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
