<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>269 nips-2013-Regression-tree Tuning in a Streaming Setting</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-269" href="../nips2013/nips-2013-Regression-tree_Tuning_in_a_Streaming_Setting.html">nips2013-269</a> <a title="nips-2013-269-reference" href="#">nips2013-269-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>269 nips-2013-Regression-tree Tuning in a Streaming Setting</h1>
<br/><p>Source: <a title="nips-2013-269-pdf" href="http://papers.nips.cc/paper/4898-regression-tree-tuning-in-a-streaming-setting.pdf">pdf</a></p><p>Author: Samory Kpotufe, Francesco Orabona</p><p>Abstract: We consider the problem of maintaining the data-structures of a partition-based regression procedure in a setting where the training data arrives sequentially over time. We prove that it is possible to maintain such a structure in time O (log n) at ˜ any time step n while achieving a nearly-optimal regression rate of O n−2/(2+d) in terms of the unknown metric dimension d. Finally we prove a new regression lower-bound which is independent of a given data size, and hence is more appropriate for the streaming setting. 1</p><br/>
<h2>reference text</h2><p>[1] Y. Ben-Haim and E. Tom-Tov. A streaming parallel decision tree algorithm. Journal of Machine Learning Research, 11:849–872, 2010.</p>
<p>[2] A. Beygelzimer, S. Kakade, and J. Langford. Cover trees for nearest neighbors. ICML, 2006.</p>
<p>[3] N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University Press, New York, NY, USA, 2006.</p>
<p>[4] K. Clarkson. Nearest-neighbor searching and metric space dimensions. Nearest-Neighbor Methods for Learning and Vision: Theory and Practice, 2005.</p>
<p>[5] P. Domingos and G. Hulten. Mining high-speed data streams. In Proceedings of the 6th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 71–80, 2000.</p>
<p>[6] H. Gu and J. Lafferty. Sequential nonparametric regression. ICML, 2012.</p>
<p>[7] L. Gyorﬁ, M. Kohler, A. Krzyzak, and H. Walk. A Distribution Free Theory of Nonparametric Regression. Springer, New York, NY, 2002.</p>
<p>[8] A. Kalai and S. Vempala. Efﬁcient algorithms for universal portfolios. Journal of Machine Learning Research, 3:423–440, 2002.</p>
<p>[9] S. Kpotufe. k-NN Regression Adapts to Local Intrinsic Dimension. NIPS, 2011.</p>
<p>[10] R. Krauthgamer and J. R. Lee. Navigating nets: simple algorithms for proximity search. In Proceedings of the ﬁfteenth annual ACM-SIAM symposium on Discrete algorithms, SODA ’04, pages 798–807, Philadelphia, PA, USA, 2004. Society for Industrial and Applied Mathematics.</p>
<p>[11] B. Pfahringer, G. Holmes, and R. Kirkby. Handling numeric attributes in hoeffding trees. In Advances in Knowledge Discovery and Data Mining: Proceedings of the 12th Paciﬁc-Asia Conference (PAKDD), volume 5012, pages 296–307. Springer, 2008.</p>
<p>[12] S. Schaal and C. Atkeson. Robot Juggling: An Implementation of Memory-based Learning. Control Systems Magazine, IEEE, 1994.</p>
<p>[13] C. J. Stone. Optimal rates of convergence for non-parametric estimators. Ann. Statist., 8:1348– 1360, 1980.</p>
<p>[14] C. J. Stone. Optimal global rates of convergence for non-parametric estimators. Ann. Statist., 10:1340–1353, 1982.</p>
<p>[15] M. A. Taddy, R. B. Gramacy, and N. G. Polson. Dynamic trees for learning and design. Journal of the American Statistical Association, 106(493), 2011.</p>
<p>[16] S. Vijayakumar and S. Schaal. Locally weighted projection regression: An O(n) algorithm for incremental real time learning in high dimensional space. In in Proceedings of the Seventeenth International Conference on Machine Learning (ICML), pages 1079–1086, 2000.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
