<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>122 nips-2013-First-order Decomposition Trees</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-122" href="../nips2013/nips-2013-First-order_Decomposition_Trees.html">nips2013-122</a> <a title="nips-2013-122-reference" href="#">nips2013-122-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>122 nips-2013-First-order Decomposition Trees</h1>
<br/><p>Source: <a title="nips-2013-122-pdf" href="http://papers.nips.cc/paper/5160-first-order-decomposition-trees.pdf">pdf</a></p><p>Author: Nima Taghipour, Jesse Davis, Hendrik Blockeel</p><p>Abstract: Lifting attempts to speedup probabilistic inference by exploiting symmetries in the model. Exact lifted inference methods, like their propositional counterparts, work by recursively decomposing the model and the problem. In the propositional case, there exist formal structures, such as decomposition trees (dtrees), that represent such a decomposition and allow us to determine the complexity of inference a priori. However, there is currently no equivalent structure nor analogous complexity results for lifted inference. In this paper, we introduce FO-dtrees, which upgrade propositional dtrees to the ﬁrst-order level. We show how these trees can characterize a lifted inference solution for a probabilistic logical model (in terms of a sequence of lifted operations), and make a theoretical analysis of the complexity of lifted inference in terms of the novel notion of lifted width for the tree. 1</p><br/>
<h2>reference text</h2><p>[1] F. Bacchus, S. Dalmao, and T. Pitassi. Solving #-SAT and Bayesian inference with backtracking search. Journal of Artiﬁcial Intelligence Research, 34(2):391, 2009.</p>
<p>[2] Adnan Darwiche. Recursive conditioning. Artif. Intell., 126(1-2):5–41, 2001.</p>
<p>[3] Rodrigo de Salvo Braz, Eyal Amir, and Dan Roth. Lifted ﬁrst-order probabilistic inference. In Proceedings of the 19th International Joint Conference on Artiﬁcial Intelligence (IJCAI), pages 1319–1325, 2005.</p>
<p>[4] Rina Dechter. Bucket elimination: A unifying framework for reasoning. Artif. Intell., 113(1-2):41–85, 1999.</p>
<p>[5] Lise Getoor and Ben Taskar, editors. An Introduction to Statistical Relational Learning. MIT Press, 2007.</p>
<p>[6] Vibhav Gogate and Pedro Domingos. Probabilistic theorem proving. In Proceedings of the 27th Conference on Uncertainty in Artiﬁcial Intelligence (UAI), pages 256–265, 2011.</p>
<p>[7] Manfred Jaeger and Guy Van den Broeck. Liftability of probabilistic inference: Upper and lower bounds. In Proceedings of the 2nd International Workshop on Statistical Relational AI (StaRAI), 2012.</p>
<p>[8] Abhay Jha, Vibhav Gogate, Alexandra Meliou, and Dan Suciu. Lifted inference seen from the other side : The tractable features. In Proceedings of the 23rd Annual Conference on Neural Information Processing Systems (NIPS), pages 973–981. 2010.</p>
<p>[9] Kristian Kersting, Babak Ahmadi, and Sriraam Natarajan. Counting belief propagation. In Proceedings of the 25th Conference on Uncertainty in Artiﬁcial Intelligence (UAI), pages 277–284, 2009.</p>
<p>[10] Brian Milch, Luke S. Zettlemoyer, Kristian Kersting, Michael Haimes, and Leslie Pack Kaelbling. Lifted probabilistic inference with counting formulas. In Proceedings of the 23rd AAAI Conference on Artiﬁcial Intelligence (AAAI), pages 1062–1608, 2008.</p>
<p>[11] Mathias Niepert. Markov chains on orbits of permutation groups. In Proceedings of the 28th Conference on Uncertainty in Artiﬁcial Intelligence (UAI), pages 624–633, 2012.</p>
<p>[12] David Poole. First-order probabilistic inference. In Proceedings of the 18th International Joint Conference on Artiﬁcial Intelligence (IJCAI), pages 985–991, 2003.</p>
<p>[13] David Poole, Fahiem Bacchus, and Jacek Kisynski. Towards completely lifted search-based probabilistic inference. CoRR, abs/1107.4035, 2011.</p>
<p>[14] David Poole and Nevin Lianwen Zhang. Exploiting contextual independence in probabilistic inference. J. Artif. Intell. Res. (JAIR), 18:263–313, 2003.</p>
<p>[15] Parag Singla and Pedro Domingos. Lifted ﬁrst-order belief propagation. In Proceedings of the 23rd AAAI Conference on Artiﬁcial Intelligence (AAAI), pages 1094–1099, 2008.</p>
<p>[16] Nima Taghipour and Jesse Davis. Generalized counting for lifted variable elimination. In Proceedings of the 2nd International Workshop on Statistical Relational AI (StaRAI), 2012.</p>
<p>[17] Nima Taghipour, Daan Fierens, Jesse Davis, and Hendrik Blockeel. Lifted variable elimination with arbitrary constraints. In Proceedings of the 15th International Conference on Artiﬁcial Intelligence and Statistics (AISTATS), pages 1194–1202, 2012.</p>
<p>[18] Nima Taghipour, Daan Fierens, Guy Van den Broeck, Jesse Davis, and Hendrik Blockeel. Completeness results for lifted variable elimination. In Proceedings of the 16th International Conference on Artiﬁcial Intelligence and Statistics (AISTATS), 2013.</p>
<p>[19] Guy Van den Broeck. On the completeness of ﬁrst-order knowledge compilation for lifted probabilistic inference. In Proceedings of the 24th Annual Conference on Advances in Neural Information Processing Systems (NIPS), pages 1386–1394, 2011.</p>
<p>[20] Guy Van den Broeck, Arthur Choi, and Adnan Darwiche. Lifted relax, compensate and then recover: From approximate to exact lifted probabilistic inference. In Proceedings of the 28th Conference on Uncertainty in Artiﬁcial Intelligence (UAI), pages 131–141, 2012.</p>
<p>[21] Guy Van den Broeck, Nima Taghipour, Wannes Meert, Jesse Davis, and Luc De Raedt. Lifted probabilistic inference by ﬁrst-order knowledge compilation. In Proceedings of the 22nd International Joint Conference on Artiﬁcial Intelligence (IJCAI), pages 2178–2185, 2011.</p>
<p>[22] Deepak Venugopal and Vibhav Gogate. On lifting the gibbs sampling algorithm. In Proceedings of the 26th Annual Conference on Advances in Neural Information Processing Systems (NIPS), pages 1–6, 2012.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
