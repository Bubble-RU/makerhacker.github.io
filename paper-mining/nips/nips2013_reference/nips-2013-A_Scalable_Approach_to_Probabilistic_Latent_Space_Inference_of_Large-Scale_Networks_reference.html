<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>13 nips-2013-A Scalable Approach to Probabilistic Latent Space Inference of Large-Scale Networks</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-13" href="../nips2013/nips-2013-A_Scalable_Approach_to_Probabilistic_Latent_Space_Inference_of_Large-Scale_Networks.html">nips2013-13</a> <a title="nips-2013-13-reference" href="#">nips2013-13-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>13 nips-2013-A Scalable Approach to Probabilistic Latent Space Inference of Large-Scale Networks</h1>
<br/><p>Source: <a title="nips-2013-13-pdf" href="http://papers.nips.cc/paper/4978-a-scalable-approach-to-probabilistic-latent-space-inference-of-large-scale-networks.pdf">pdf</a></p><p>Author: Junming Yin, Qirong Ho, Eric Xing</p><p>Abstract: We propose a scalable approach for making inference about latent spaces of large networks. With a succinct representation of networks as a bag of triangular motifs, a parsimonious statistical model, and an efﬁcient stochastic variational inference algorithm, we are able to analyze real networks with over a million vertices and hundreds of latent roles on a single machine in a matter of hours, a setting that is out of reach for many existing methods. When compared to the state-of-the-art probabilistic approaches, our method is several orders of magnitude faster, with competitive or improved accuracy for latent space recovery and link prediction. 1</p><br/>
<h2>reference text</h2><p>[1] E. Airoldi, D. Blei, S. Fienberg, and E. Xing. Mixed membership stochastic blockmodels. Journal of Machine Learning Research, 9:1981–2014, 2008.</p>
<p>[2] S. Amari. Natural gradient works efﬁciently in learning. Neural Computation, 10(2):251–276, 1998.</p>
<p>[3] L. Bottou. Stochastic learning. Advanced Lectures on Machine Learning, pages 146–168, 2004.</p>
<p>[4] M. Carman, F. Crestani, M. Harvey, and M. Baillie. Towards query log based personalization using topic models. In Proceedings of the 19th ACM international conference on Information and knowledge management (CIKM ’10), pages 1849–1852, 2010.</p>
<p>[5] P. Gopalan, D. Mimno, S. Gerrish, M. Freedman, and D. Blei. Scalable inference of overlapping communities. In Advances in Neural Information Processing Systems 25, pages 2258–2266. 2012.</p>
<p>[6] M. Granovetter. The strength of weak ties. American Journal of Sociology, 78(6):1360–1380, 1973.</p>
<p>[7] Q. Ho, A. Parikh, and E. Xing. A multiscale community blockmodel for network exploration. Journal of the American Statistical Association, 107(499), 2012.</p>
<p>[8] Q. Ho, J. Yin, and E. Xing. On triangular versus edge representations — towards scalable modeling of networks. In Advances in Neural Information Processing Systems 25, pages 2141–2149. 2012.</p>
<p>[9] P. Hoff, A. Raftery, and M. Handcock. Latent space approaches to social network analysis. Journal of the American Statistical Association, 97(460):1090–1098, 2002.</p>
<p>[10] M. Hoffman, D. Blei, C. Wang, and J. Paisley. Stochastic variational inference. Journal of Machine Learning Research, 14:1303–1347, 2013.</p>
<p>[11] D. Hunter, S. Goodreau, and M. Handcock. Goodness of ﬁt of social network models. Journal of the American Statistical Association, 103(481):248–258, 2008.</p>
<p>[12] A. Lancichinetti, S. Fortunato, and J. Kert´ sz. Detecting the overlapping and hierarchical community e structure in complex networks. New Journal of Physics, 11(3):033015+, 2009.</p>
<p>[13] Y. Low, D. Agarwal, and A. Smola. Multiple domain user personalization. In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD ’11), pages 123–131, 2011.</p>
<p>[14] K. Miller, T. Grifﬁths, and M. Jordan. Nonparametric latent feature models for link prediction. In Advances in Neural Information Processing Systems 22, pages 1276–1284. 2009.</p>
<p>[15] R. Milo, S. Shen-Orr, S. Itzkovitz, N. Kashtan, D. Chklovskii, and U. Alon. Network motifs: Simple building blocks of complex networks. Science, 298(5594):824–827, 2002.</p>
<p>[16] M. Morris, M. Handcock, and D. Hunter. Speciﬁcation of exponential-family random graph models: Terms and computational aspects. Journal of Statistical Software, 24(4), 2008.</p>
<p>[17] M. Newman, S. Strogatz, and D. Watts. Random graphs with arbitrary degree distributions and their applications. Physical Review E, 64(2), 2001.</p>
<p>[18] H. Robbins and S. Monro. A stochastic approximation method. The Annals of Mathematical Statistics, 22(3):400–407, 1951.</p>
<p>[19] P. Sarkar and A. Moore. Dynamic social network analysis using latent space models. ACM SIGKDD Explorations Newsletter, 7(2):31–40, 2005.</p>
<p>[20] M. Sato. Online model selection based on the variational Bayes. Neural Computation, 13(7):1649–1681, 2001.</p>
<p>[21] G. Simmel and K. Wolff. The Sociology of Georg Simmel. Free Press, 1950.</p>
<p>[22] M. Wainwright and M. Jordan. Graphical models, exponential families, and variational inference. Foundations and Trends in Machine Learning, 1(1-2):1–305, 2008.</p>
<p>[23] J. Xie, S. Kelley, and B. Szymanski. Overlapping community detection in networks: the state of the art and comparative study. ACM Computing Surveys, 45(4), 2013.</p>
<p>[24] J. Yang and J. Leskovec. Deﬁning and evaluating network communities based on ground-truth. In Proceedings of the ACM SIGKDD Workshop on Mining Data Semantics. ACM, 2012.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
