<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>198 nips-2013-More Effective Distributed ML via a Stale Synchronous Parallel Parameter Server</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-198" href="../nips2013/nips-2013-More_Effective_Distributed_ML_via_a_Stale_Synchronous_Parallel_Parameter_Server.html">nips2013-198</a> <a title="nips-2013-198-reference" href="#">nips2013-198-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>198 nips-2013-More Effective Distributed ML via a Stale Synchronous Parallel Parameter Server</h1>
<br/><p>Source: <a title="nips-2013-198-pdf" href="http://papers.nips.cc/paper/4894-more-effective-distributed-ml-via-a-stale-synchronous-parallel-parameter-server.pdf">pdf</a></p><p>Author: Qirong Ho, James Cipar, Henggang Cui, Seunghak Lee, Jin Kyu Kim, Phillip B. Gibbons, Garth A. Gibson, Greg Ganger, Eric Xing</p><p>Abstract: We propose a parameter server system for distributed ML, which follows a Stale Synchronous Parallel (SSP) model of computation that maximizes the time computational workers spend doing useful work on ML algorithms, while still providing correctness guarantees. The parameter server provides an easy-to-use shared interface for read/write access to an ML model’s values (parameters and variables), and the SSP model allows distributed workers to read older, stale versions of these values from a local cache, instead of waiting to get them from a central storage. This signiﬁcantly increases the proportion of time workers spend computing, as opposed to waiting. Furthermore, the SSP model ensures ML algorithm correctness by limiting the maximum age of the stale values. We provide a proof of correctness under SSP, as well as empirical results demonstrating that the SSP model achieves faster algorithm convergence on several different ML problems, compared to fully-synchronous and asynchronous schemes. 1</p><br/>
<h2>reference text</h2><p>[1] A. Agarwal and J. C. Duchi. Distributed delayed stochastic optimization. In Decision and Control (CDC), 2012 IEEE 51st Annual Conference on, pages 5451–5452. IEEE, 2012.</p>
<p>[2] A. Ahmed, M. Aly, J. Gonzalez, S. Narayanamurthy, and A. J. Smola. Scalable inference in latent variable models. In WSDM, pages 123–132, 2012.</p>
<p>[3] N. R. Alexandros Labrinidis. Balancing performance and data freshness in web database servers. pages pp. 393 – 404, September 2003.</p>
<p>[4] M. Bouzeghoub. A framework for analysis of data freshness. In Proceedings of the 2004 international workshop on Information quality in information systems, IQIS ’04, pages 59–67, 2004.</p>
<p>[5] J. K. Bradley, A. Kyrola, D. Bickson, and C. Guestrin. Parallel coordinate descent for l1-regularized loss minimization. In International Conference on Machine Learning (ICML 2011), June 2011.</p>
<p>[6] L. Bright and L. Raschid. Using latency-recency proﬁles for data delivery on the web. In Proceedings of the 28th international conference on Very Large Data Bases, VLDB ’02, pages 550–561, 2002.</p>
<p>[7] J. Cipar, G. Ganger, K. Keeton, C. B. Morrey, III, C. A. Soules, and A. Veitch. LazyBase: trading freshness for performance in a scalable database. In Proceedings of the 7th ACM european conference on Computer Systems, pages 169–182, 2012.</p>
<p>[8] J. Cipar, Q. Ho, J. K. Kim, S. Lee, G. R. Ganger, G. Gibson, K. Keeton, and E. Xing. Solving the straggler problem with bounded staleness. In HotOS ’13. Usenix, 2013.</p>
<p>[9] J. Dean, G. Corrado, R. Monga, K. Chen, M. Devin, Q. Le, M. Mao, M. Ranzato, A. Senior, P. Tucker, K. Yang, and A. Ng. Large scale distributed deep networks. In NIPS 2012, 2012.</p>
<p>[10] Facebook. www.facebook.com/note.php?note_id=10150388519243859, January 2013.</p>
<p>[11] C. J. Fidge. Timestamps in Message-Passing Systems that Preserve the Partial Ordering. In 11th Australian Computer Science Conference, pages 55–66, University of Queensland, Australia, 1988.</p>
<p>[12] R. Gemulla, E. Nijkamp, P. J. Haas, and Y. Sismanis. Large-scale matrix factorization with distributed stochastic gradient descent. In KDD, pages 69–77. ACM, 2011.</p>
<p>[13] L. Golab and T. Johnson. Consistency in a stream warehouse. In CIDR 2011, pages 114–122.</p>
<p>[14] C.-T. Huang. Loft: Low-overhead freshness transmission in sensor networks. In SUTC 2008, pages 241–248, Washington, DC, USA, 2008. IEEE Computer Society.</p>
<p>[15] L. Lamport. Time, clocks, and the ordering of events in a distributed system. Commun. ACM, 21(7):558– 565, July 1978.</p>
<p>[16] J. Langford, L. Li, and A. Strehl. Vowpal wabbit online learning project, 2007.</p>
<p>[17] J. Langford, A. J. Smola, and M. Zinkevich. Slow learners are fast. In Advances in Neural Information Processing Systems, pages 2331–2339, 2009.</p>
<p>[18] Y. Low, G. Joseph, K. Aapo, D. Bickson, C. Guestrin, and M. Hellerstein, Joseph. Distributed GraphLab: A framework for machine learning and data mining in the cloud. PVLDB, 2012.</p>
<p>[19] G. Malewicz, M. H. Austern, A. J. Bik, J. C. Dehnert, I. Horn, N. Leiser, and G. Czajkowski. Pregel: a system for large-scale graph processing. In Proceedings of the 2010 International Conference on Management of Data, pages 135–146. ACM, 2010.</p>
<p>[20] F. Mattern. Virtual time and global states of distributed systems. In C. M. et al., editor, Proc. Workshop on Parallel and Distributed Algorithms, pages 215–226, North-Holland / Elsevier, 1989.</p>
<p>[21] F. Niu, B. Recht, C. R´ , and S. J. Wright. Hogwild!: A lock-free approach to parallelizing stochastic e gradient descent. In NIPS, 2011.</p>
<p>[22] R. Power and J. Li. Piccolo: building fast, distributed programs with partitioned tables. In Proceedings of the USENIX conference on Operating systems design and implementation (OSDI), pages 1–14, 2010.</p>
<p>[23] U. R¨ hm, K. B¨ hm, H.-J. Schek, and H. Schuldt. Fas: a freshness-sensitive coordination middleware for o o a cluster of olap components. In VLDB 2002, pages 754–765. VLDB Endowment, 2002.</p>
<p>[24] D. Terry. Replicated data consistency explained through baseball. Technical Report MSR-TR-2011-137, Microsoft Research, October 2011.</p>
<p>[25] Yahoo! http://webscope.sandbox.yahoo.com/catalog.php?datatype=g, 2013.</p>
<p>[26] H. Yu and A. Vahdat. Design and evaluation of a conit-based continuous consistency model for replicated services. ACM Transactions on Computer Systems, 20(3):239–282, Aug. 2002.</p>
<p>[27] M. Zaharia, M. Chowdhury, M. J. Franklin, S. Shenker, and I. Stoica. Spark: cluster computing with working sets. In Proceedings of the 2nd USENIX conference on Hot topics in cloud computing, 2010.</p>
<p>[28] M. Zinkevich, M. Weimer, A. Smola, and L. Li. Parallelized stochastic gradient descent. Advances in Neural Information Processing Systems, 23(23):1–9, 2010.  9</p>
<br/>
<br/><br/><br/></body>
</html>
