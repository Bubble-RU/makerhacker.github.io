<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>331 nips-2013-Top-Down Regularization of Deep Belief Networks</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-331" href="../nips2013/nips-2013-Top-Down_Regularization_of_Deep_Belief_Networks.html">nips2013-331</a> <a title="nips-2013-331-reference" href="#">nips2013-331-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>331 nips-2013-Top-Down Regularization of Deep Belief Networks</h1>
<br/><p>Source: <a title="nips-2013-331-pdf" href="http://papers.nips.cc/paper/5031-top-down-regularization-of-deep-belief-networks.pdf">pdf</a></p><p>Author: Hanlin Goh, Nicolas Thome, Matthieu Cord, Joo-Hwee Lim</p><p>Abstract: Designing a principled and effective algorithm for learning deep architectures is a challenging problem. The current approach involves two training phases: a fully unsupervised learning followed by a strongly discriminative optimization. We suggest a deep learning strategy that bridges the gap between the two phases, resulting in a three-phase learning procedure. We propose to implement the scheme using a method to regularize deep belief networks with top-down information. The network is constructed from building blocks of restricted Boltzmann machines learned by combining bottom-up and top-down sampled signals. A global optimization procedure that merges samples from a forward bottom-up pass and a top-down pass is used. Experiments on the MNIST dataset show improvements over the existing algorithms for deep belief networks. Object recognition results on the Caltech-101 dataset also yield competitive results. 1</p><br/>
<h2>reference text</h2><p>[1] G. E. Hinton, S. Osindero, and Y.-W. Teh, “A fast learning algorithm for deep belief networks,” Neural Computation, vol. 18, no. 7, pp. 1527–1554, 2006.</p>
<p>[2] Y. LeCun, “Une proc´ dure d’apprentissage pour r´ seau a seuil asymmetrique (a learning scheme for e e asymmetric threshold networks),” in Cognitiva 85, 1985.</p>
<p>[3] D. E. Rumelhart, G. E. Hinton, and R. J. Williams, “Learning representations by back-propagating errors,” Nature, vol. 323, pp. 533 – 536, October 1986.</p>
<p>[4] Y. Bengio, “Learning deep architectures for AI,” Foundations and Trends in Machine Learning, vol. 2, no. 1, pp. 1–127, 2009.</p>
<p>[5] Y. Bengio, P. Lamblin, D. Popovici, and H. Larochelle, “Greedy layer-wise training of deep networks,” in NIPS, 2006.</p>
<p>[6] M. Ranzato, C. Poultney, S. Chopra, and Y. LeCun, “Efﬁcient learning of sparse representations with an energy-based model,” in NIPS, 2006.</p>
<p>[7] P. Vincent, H. Larochelle, Y. Bengio, and P.-A. Manzagol, “Extracting and composing robust features with denoising autoencoders,” in ICML, 2008.</p>
<p>[8] P. Smolensky, “Information processing in dynamical systems: Foundations of harmony theory,” in Parallel Distributed Processing: Volume 1: Foundations, ch. 6, pp. 194–281, MIT Press, 1986.</p>
<p>[9] G. E. Hinton, “Training products of experts by minimizing contrastive divergence,” Neural Computation, vol. 14, no. 8, p. 1771–1800, 2002.</p>
<p>[10] H. Lee, C. Ekanadham, and A. Ng, “Sparse deep belief net model for visual area V2,” in NIPS, 2008.</p>
<p>[11] H. Goh, N. Thome, and M. Cord, “Biasing restricted Boltzmann machines to manipulate latent selectivity and sparsity,” in NIPS Workshop, 2010.</p>
<p>[12] H. Larochelle and Y. Bengio, “Classiﬁcation using discriminative restricted Boltzmann machines,” in ICML, 2008.</p>
<p>[13] N. Le Roux and Y. Bengio, “Representational power of restricted Boltzmann machines and deep belief networks,” Neural Computation, vol. 20, pp. 1631–1649, June 2008.</p>
<p>[14] I. Sutskever and G. E. Hinton, “Learning multilevel distributed representations for high-dimensional sequences,” in AISTATS, 2007.</p>
<p>[15] G. E. Hinton and R. Salakhutdinov, “Reducing the dimensionality of data with neural networks,” Science, vol. 28, pp. 504–507, 2006.</p>
<p>[16] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning applied to document recognition,” Proceedings of the IEEE, vol. 86, pp. 2278–2324, November 1998.</p>
<p>[17] L. Fei-Fei, R. Fergus, and P. Perona, “Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories,” CVPR Workshop, 2004.</p>
<p>[18] R. Salakhutdinov and G. E. Hinton, “Learning a nonlinear embedding by preserving class neighbourhood structure,” in AISTATS, 2007.</p>
<p>[19] L. Deng and D. Yu, “Deep convex net: A scalable architecture for speech pattern classiﬁcation,” in Interspeech, 2011.</p>
<p>[20] D. C. Ciresan, U. Meier, and J. Schmidhuber, “Multi-column deep neural networks for image classiﬁca¸ tion,” in CVPR, 2012.</p>
<p>[21] D. Lowe, “Object recognition from local scale-invariant features,” in CVPR, 1999.</p>
<p>[22] Y. Boureau, F. Bach, Y. LeCun, and J. Ponce, “Learning mid-level features for recognition,” in CVPR, 2010.</p>
<p>[23] H. Goh, N. Thome, M. Cord, and J.-H. Lim, “Unsupervised and supervised visual codes with restricted Boltzmann machines,” in ECCV, 2012.</p>
<p>[24] S. Lazebnik, C. Schmid, and J. Ponce, “Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories,” in CVPR, 2006.</p>
<p>[25] S. Avila, N. Thome, M. Cord, E. Valle, and A. Ara´ jo, “Pooling in image representation: the visual u codeword point of view,” Computer Vision and Image Understanding, pp. 453–465, May 2013.</p>
<p>[26] C. Theriault, N. Thome, and M. Cord, “Extended coding and pooling in the HMAX model,” IEEE Transaction on Image Processing, 2013.</p>
<p>[27] K. Sohn, D. Y. Jung, H. Lee, and A. Hero III, “Efﬁcient learning of sparse, distributed, convolutional feature representations for object recognition,” in ICCV, 2011.</p>
<p>[28] K. Sohn, G. Zhou, C. Lee, and H. Lee, “Learning and selecting features jointly with point-wise gated boltzmann machines,” in ICML, 2013.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
