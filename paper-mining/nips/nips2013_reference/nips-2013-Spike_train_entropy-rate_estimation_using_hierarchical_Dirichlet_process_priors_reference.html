<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>308 nips-2013-Spike train entropy-rate estimation using hierarchical Dirichlet process priors</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-308" href="../nips2013/nips-2013-Spike_train_entropy-rate_estimation_using_hierarchical_Dirichlet_process_priors.html">nips2013-308</a> <a title="nips-2013-308-reference" href="#">nips2013-308-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>308 nips-2013-Spike train entropy-rate estimation using hierarchical Dirichlet process priors</h1>
<br/><p>Source: <a title="nips-2013-308-pdf" href="http://papers.nips.cc/paper/5090-spike-train-entropy-rate-estimation-using-hierarchical-dirichlet-process-priors.pdf">pdf</a></p><p>Author: Karin C. Knudson, Jonathan W. Pillow</p><p>Abstract: Entropy rate quantiﬁes the amount of disorder in a stochastic process. For spiking neurons, the entropy rate places an upper bound on the rate at which the spike train can convey stimulus information, and a large literature has focused on the problem of estimating entropy rate from spike train data. Here we present Bayes least squares and empirical Bayesian entropy rate estimators for binary spike trains using hierarchical Dirichlet process (HDP) priors. Our estimator leverages the fact that the entropy rate of an ergodic Markov Chain with known transition probabilities can be calculated analytically, and many stochastic processes that are non-Markovian can still be well approximated by Markov processes of sufﬁcient depth. Choosing an appropriate depth of Markov model presents challenges due to possibly long time dependencies and short data sequences: a deeper model can better account for long time dependencies, but is more difﬁcult to infer from limited data. Our approach mitigates this difﬁculty by using a hierarchical prior to share statistical power across Markov chains of different depths. We present both a fully Bayesian and empirical Bayes entropy rate estimator based on this model, and demonstrate their performance on simulated and real neural spike train data. 1</p><br/>
<h2>reference text</h2><p>[1] Matthew B Kennel, Jonathon Shlens, Henry DI Abarbanel, and EJ Chichilnisky. Estimating entropy rates with bayesian conﬁdence intervals. Neural Computation, 17(7):1531–1576, 2005.</p>
<p>[2] Abraham Lempel and Jacob Ziv. On the complexity of ﬁnite sequences. Information Theory, IEEE Transactions on, 22(1):75–81, 1976.</p>
<p>[3] Ilya Nemenman, Fariel Shafee, and William Bialek. Entropy and inference, revisited. arXiv preprint physics/0108025, 2001.</p>
<p>[4] George Armitage Miller and William Gregory Madow. On the Maximum Likelihood Estimate of the Shannon-Weiner Measure of Information. Operational Applications Laboratory, Air Force Cambridge Research Center, Air Research and Development Command, Bolling Air Force Base, 1954.</p>
<p>[5] Yee Whye Teh, Michael I Jordan, Matthew J Beal, and David M Blei. Hierarchical dirichlet processes. Journal of the American Statistical Association, 101(476), 2006.</p>
<p>[6] Yee Whye Teh. A hierarchical bayesian language model based on pitman-yor processes. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 985–992. Association for Computational Linguistics, 2006.</p>
<p>[7] Frank Wood, C´ dric Archambeau, Jan Gasthaus, Lancelot James, and Yee Whye Teh. A stochase tic memoizer for sequence data. In Proceedings of the 26th Annual International Conference on Machine Learning, pages 1129–1136. ACM, 2009.</p>
<p>[8] V. J. Uzzell and E. J. Chichilnisky. Precision of spike trains in primate retinal ganglion cells. Journal of Neurophysiology, 92:780–789, 2004.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
