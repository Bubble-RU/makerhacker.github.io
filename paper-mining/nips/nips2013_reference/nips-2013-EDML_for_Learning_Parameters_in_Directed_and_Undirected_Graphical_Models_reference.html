<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>101 nips-2013-EDML for Learning Parameters in Directed and Undirected Graphical Models</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-101" href="../nips2013/nips-2013-EDML_for_Learning_Parameters_in_Directed_and_Undirected_Graphical_Models.html">nips2013-101</a> <a title="nips-2013-101-reference" href="#">nips2013-101-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>101 nips-2013-EDML for Learning Parameters in Directed and Undirected Graphical Models</h1>
<br/><p>Source: <a title="nips-2013-101-pdf" href="http://papers.nips.cc/paper/4963-edml-for-learning-parameters-in-directed-and-undirected-graphical-models.pdf">pdf</a></p><p>Author: Khaled Refaat, Arthur Choi, Adnan Darwiche</p><p>Abstract: EDML is a recently proposed algorithm for learning parameters in Bayesian networks. It was originally derived in terms of approximate inference on a metanetwork, which underlies the Bayesian approach to parameter estimation. While this initial derivation helped discover EDML in the ﬁrst place and provided a concrete context for identifying some of its properties (e.g., in contrast to EM), the formal setting was somewhat tedious in the number of concepts it drew on. In this paper, we propose a greatly simpliﬁed perspective on EDML, which casts it as a general approach to continuous optimization. The new perspective has several advantages. First, it makes immediate some results that were non-trivial to prove initially. Second, it facilitates the design of EDML algorithms for new graphical models, leading to a new algorithm for learning parameters in Markov networks. We derive this algorithm in this paper, and show, empirically, that it can sometimes learn estimates more efﬁciently from complete data, compared to commonly used optimization methods, such as conjugate gradient and L-BFGS. 1</p><br/>
<h2>reference text</h2><p>[1] Dimitri P. Bertsekas and John N. Tsitsiklis. Parallel and Distributed Computation: Numerical Methods. Prentice-Hall, 1989.</p>
<p>[2] J. Besag. Statistical Analysis of Non-Lattice Data. The Statistician, 24:179–195, 1975.</p>
<p>[3] Stephen Boyd and Lieven Vandenberghe. Convex Optimization. Cambridge University Press, 2004.</p>
<p>[4] Hei Chan and Adnan Darwiche. On the revision of probabilistic beliefs using uncertain evidence. AIJ, 163:67–90, 2005.</p>
<p>[5] Arthur Choi, Khaled S. Refaat, and Adnan Darwiche. EDML: A method for learning parameters in Bayesian networks. In UAI, 2011.</p>
<p>[6] Adnan Darwiche. A differential approach to inference in Bayesian networks. 50(3):280–305, 2003.  JACM,</p>
<p>[7] A.P. Dempster, N.M. Laird, and D.B. Rubin. Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society B, 39:1–38, 1977.</p>
<p>[8] Pedro Domingos and Daniel Lowd. Markov Logic: An Interface Layer for Artiﬁcial Intelligence. Synthesis Lectures on Artiﬁcial Intelligence and Machine Learning. Morgan & Claypool Publishers, 2009.</p>
<p>[9] Radim Jirousek and Stanislav Preucil. On the effective implementation of the iterative proportional ﬁtting procedure. Computational Statistics & Data Analysis, 19(2):177–189, 1995.</p>
<p>[10] Daphne Koller and Nir Friedman. Probabilistic Graphical Models: Principles and Techniques. MIT Press, 2009.</p>
<p>[11] S. L. Lauritzen. The EM algorithm for graphical association models with missing data. Computational Statistics and Data Analysis, 19:191–201, 1995.</p>
<p>[12] D. C. Liu and J. Nocedal. On the Limited Memory BFGS Method for Large Scale Optimization. Mathematical Programming, 45(3):503–528, 1989.</p>
<p>[13] Kevin Patrick Murphy. Machine Learning: A Probabilistic Perspective. MIT Press, 2012.</p>
<p>[14] James Park and Adnan Darwiche. A differential semantics for jointree algorithms. AIJ, 156:197–216, 2004.</p>
<p>[15] Stephen Della Pietra, Vincent J. Della Pietra, and John D. Lafferty. Inducing features of random ﬁelds. IEEE Trans. Pattern Anal. Mach. Intell., 19(4):380–393, 1997.</p>
<p>[16] Khaled S. Refaat, Arthur Choi, and Adnan Darwiche. New advances and theoretical insights into EDML. In UAI, pages 705–714, 2012.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
