<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>203 nips-2013-Multilinear Dynamical Systems for Tensor Time Series</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-203" href="../nips2013/nips-2013-Multilinear_Dynamical_Systems_for_Tensor_Time_Series.html">nips2013-203</a> <a title="nips-2013-203-reference" href="#">nips2013-203-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>203 nips-2013-Multilinear Dynamical Systems for Tensor Time Series</h1>
<br/><p>Source: <a title="nips-2013-203-pdf" href="http://papers.nips.cc/paper/5117-multilinear-dynamical-systems-for-tensor-time-series.pdf">pdf</a></p><p>Author: Mark Rogers, Lei Li, Stuart Russell</p><p>Abstract: Data in the sciences frequently occur as sequences of multidimensional arrays called tensors. How can hidden, evolving trends in such data be extracted while preserving the tensor structure? The model that is traditionally used is the linear dynamical system (LDS) with Gaussian noise, which treats the latent state and observation at each time slice as a vector. We present the multilinear dynamical system (MLDS) for modeling tensor time series and an expectation–maximization (EM) algorithm to estimate the parameters. The MLDS models each tensor observation in the time series as the multilinear projection of the corresponding member of a sequence of latent tensors. The latent tensors are again evolving with respect to a multilinear projection. Compared to the LDS with an equal number of parameters, the MLDS achieves higher prediction accuracy and marginal likelihood for both artiﬁcial and real datasets. 1</p><br/>
<h2>reference text</h2><p>[1] Jan R. Magnus and Heinz Neudecker. Matrix Differential Calculus with Applications in Statistics and Econometrics. Wiley, revised edition, 1999.</p>
<p>[2] Vin De Silva and Lek-Heng Lim. Tensor rank and the ill-posedness of the best low-rank approximation problem. SIAM Journal on Matrix Analysis and Applications, 30(3):1084–1127, 2008.</p>
<p>[3] Tamara G. Kolda. Tensor decompositions and applications. SIAM Review, 51(3):455–500, 2009.</p>
<p>[4] Peter J. Basser and Sinisa Pajevic. A normal distribution for tensor-valued random variables: applications to diffusion tensor MRI. IEEE Transactions on Medical Imaging, 22(7):785–794, 2003.</p>
<p>[5] Arthur P. Dempster, Nan M. Laird, and Donald B. Rubin. Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society. Series B (Methodological), 39(1):1–38, 1977.</p>
<p>[6] Christopher M. Bishop. Pattern Recognition and Machine Learning. Springer, 1st edition, 2006.</p>
<p>[7] NOAA/Paciﬁc Marine Environmental Laboratory. Tropical Atmosphere Ocean Project. http://www. pmel.noaa.gov/tao/data_deliv/deliv.html. Accessed: May 23, 2013.</p>
<p>[8] Zoubin Ghahramani and Geoffrey E. Hinton. Parameter estimation for linear dynamical systems. Technical Report CRG-TR-96-2, University of Toronto Department of Computer Science, 1996.</p>
<p>[9] Jimeng Sun, Dacheng Tao, and Christos Faloutsos. Beyond streams and graphs: dynamic tensor analysis. In Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 374–383. ACM, 2006.</p>
<p>[10] Liang Xiong, Xi Chen, Tzu-Kuo Huang, Jeff Schneider, and Jaime G. Carbonell. Temporal collaborative ﬁltering with Bayesian probabilistic tensor factorization. In Proceedings of SIAM Data Mining, 2010.</p>
<p>[11] Haipin Lu, Konstantinos N. Plataniotis, and Anastasios N. Venetsanopoulos. MPCA: Multilinear principal components analysis of tensor objects. IEEE Transactions on Neural Networks, 19(1), 2008.</p>
<p>[12] Tamara Kolda and Jimeng Sun. Scalable tensor decompositions for multi-aspect data mining. In Eighth IEEE International Conference on Data Mining. IEEE, 2008.</p>
<p>[13] Dacheng Tao, Mingli Song, Xuelong Li, Jialie Shen, Jimeng Sun, Xindong Wu, Christos Faloutsos, and Stephen J. Maybank. Bayesian tensor approach for 3-D face modeling. IEEE Transactions on Circuits and Systems for Video Technology, 18(10):1397–1410, 2008.</p>
<p>[14] Yehuda Koren, Robert Bell, and Chris Volinsky. Matrix factorization techniques for recommender systems. Computer, 42(8):30–37, 2009.</p>
<p>[15] Ruslan Salakhutdinov and Andriy Mnih. Probabilistic matrix factorization. In Advances in Neural Information Processing Systems, volume 20, pages 1257–1264, 2008.</p>
<p>[16] Ruslan Salakhutdinov and Andriy Mnih. Bayesian probabilistic matrix factorization using Markov chain Monte Carlo. In Proceedings of the 25th International Conference on Machine Learning. ACM, 2008.</p>
<p>[17] Cyril Goutte and Massih-Reza Amini. Probabilistic tensor factorization and model selection. In Tensors, Kernels, and Machine Learning (TKLM 2010), pages 1–4, 2010.</p>
<p>[18] Christian F. Beckmann and Stephen M. Smith. Tensorial extensions of independent component analysis for multisubject FMRI analysis. Neuroimage, 25(1):294–311, 2005.</p>
<p>[19] Y. Kenan Yilmaz, A. Taylan Cemgil, and Umut Simsekli. Generalized coupled tensor factorization. In Neural Information Processing Systems. MIT Press, 2011.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
