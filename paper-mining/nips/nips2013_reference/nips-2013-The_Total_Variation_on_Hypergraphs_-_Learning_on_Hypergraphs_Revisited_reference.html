<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>328 nips-2013-The Total Variation on Hypergraphs - Learning on Hypergraphs Revisited</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-328" href="../nips2013/nips-2013-The_Total_Variation_on_Hypergraphs_-_Learning_on_Hypergraphs_Revisited.html">nips2013-328</a> <a title="nips-2013-328-reference" href="#">nips2013-328-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>328 nips-2013-The Total Variation on Hypergraphs - Learning on Hypergraphs Revisited</h1>
<br/><p>Source: <a title="nips-2013-328-pdf" href="http://papers.nips.cc/paper/4914-the-total-variation-on-hypergraphs-learning-on-hypergraphs-revisited.pdf">pdf</a></p><p>Author: Matthias Hein, Simon Setzer, Leonardo Jost, Syama Sundar Rangapuram</p><p>Abstract: Hypergraphs allow one to encode higher-order relationships in data and are thus a very ﬂexible modeling tool. Current learning methods are either based on approximations of the hypergraphs via graphs or on tensor methods which are only applicable under special conditions. In this paper, we present a new learning framework on hypergraphs which fully uses the hypergraph structure. The key element is a family of regularization functionals based on the total variation on hypergraphs. 1</p><br/>
<h2>reference text</h2><p>[1] Y. Huang, Q. Liu, and D. Metaxas. Video object segmentation by hypergraph cut. In CVPR, pages 1738 – 1745, 2009.</p>
<p>[2] P. Ochs and T. Brox. Higher order motion models and spectral clustering. In CVPR, pages 614–621, 2012.</p>
<p>[3] S. Klamt, U.-U. Haus, and F. Theis. Hypergraphs and cellular networks. PLoS Computational Biology, 5:e1000385, 2009.</p>
<p>[4] Z. Tian, T. Hwang, and R. Kuang. A hypergraph-based learning algorithm for classifying gene expression and arraycgh data with prior knowledge. Bioinformatics, 25:2831–2838, 2009.</p>
<p>[5] D. Gibson, J. Kleinberg, and P. Raghavan. Clustering categorical data: an approach based on dynamical systems. VLDB Journal, 8:222–236, 2000.</p>
<p>[6] J. Bu, S. Tan, C. Chen, C. Wang, H. Wu, L. Zhang, and X. He. Music recommendation by uniﬁed hypergraph: Combining social media information and music content. In Proc. of the Int. Conf. on Multimedia (MM), pages 391–400, 2010.</p>
<p>[7] A. Shashua, R. Zass, and T. Hazan. Multi-way clustering using super-symmetric non-negative tensor factorization. In ECCV, pages 595–608, 2006.</p>
<p>[8] S. Rota Bulo and M. Pellilo. A game-theoretic approach to hypergraph clustering. In NIPS, pages 1571– 1579, 2009.</p>
<p>[9] M. Leordeanu and C. Sminchisescu. Efﬁcient hypergraph clustering. In AISTATS, pages 676–684, 2012.</p>
<p>[10] S. Agarwal, J. Lim, L. Zelnik-Manor, P. Petrona, D. J. Kriegman, and S. Belongie. Beyond pairwise clustering. In CVPR, pages 838–845, 2005.</p>
<p>[11] D. Zhou, J. Huang, and B. Sch¨ lkopf. Learning with hypergraphs: Clustering, classiﬁcation, and embedo ding. In NIPS, pages 1601–1608, 2006.</p>
<p>[12] S. Agarwal, K. Branson, and S. Belongie. Higher order learning with graphs. In ICML, pages 17–24, 2006.</p>
<p>[13] E. Ihler, D. Wagner, and F. Wagner. Modeling hypergraphs by graphs with the same mincut properties. Information Processing Letters, 45:171–175, 1993.</p>
<p>[14] M. Hein and T. B¨ hler. An inverse power method for nonlinear eigenproblems with applications in 1u spectral clustering and sparse PCA. In NIPS, pages 847–855, 2010.</p>
<p>[15] A. Szlam and X. Bresson. Total variation and Cheeger cuts. In ICML, pages 1039–1046, 2010.</p>
<p>[16] M. Hein and S. Setzer. Beyond spectral clustering - tight relaxations of balanced graph cuts. In NIPS, pages 2366–2374, 2011.</p>
<p>[17] T. B¨ hler, S. Rangapuram, S. Setzer, and M. Hein. Constrained fractional set programs and their applicau tion in local clustering and community detection. In ICML, pages 624–632, 2013.</p>
<p>[18] F. Bach. Learning with submodular functions: A convex optimization perspective. CoRR, abs/1111.6453, 2011.</p>
<p>[19] M. Belkin and P. Niyogi. Semi-supervised learning on manifolds. Machine Learning, 56:209–239, 2004.</p>
<p>[20] D. Zhou, O. Bousquet, T. N. Lal, J. Weston, and B. Sch¨ lkopf. Learning with local and global consistency. o In NIPS, volume 16, pages 321–328, 2004.</p>
<p>[21] J. Shi and J. Malik. Normalized cuts and image segmentation. IEEE Trans. Patt. Anal. Mach. Intell., 22(8):888–905, 2000.</p>
<p>[22] U. von Luxburg. A tutorial on spectral clustering. Statistics and Computing, 17:395–416, 2007.</p>
<p>[23] E. Esser, X. Zhang, and T. F. Chan. A general framework for a class of ﬁrst order primal-dual algorithms for convex optimization in imaging science. SIAM Journal on Imaging Sciences, 3(4):1015–1046, 2010.</p>
<p>[24] A. Chambolle and T. Pock. A ﬁrst-order primal-dual algorithm for convex problems with applications to imaging. J. of Math. Imaging and Vision, 40:120–145, 2011.</p>
<p>[25] L. Condat. A primaldual splitting method for convex optimization involving lipschitzian, proximable and linear composite terms. J. Optimization Theory and Applications, 158(2):460–479, 2013.</p>
<p>[26] K. Kiwiel. On Linear-Time algorithms for the continuous quadratic knapsack problem. J. Opt. Theory Appl., 134(3):549–554, 2007.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
