<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>125 nips-2013-From Bandits to Experts: A Tale of Domination and Independence</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-125" href="../nips2013/nips-2013-From_Bandits_to_Experts%3A_A_Tale_of_Domination_and_Independence.html">nips2013-125</a> <a title="nips-2013-125-reference" href="#">nips2013-125-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>125 nips-2013-From Bandits to Experts: A Tale of Domination and Independence</h1>
<br/><p>Source: <a title="nips-2013-125-pdf" href="http://papers.nips.cc/paper/4908-from-bandits-to-experts-a-tale-of-domination-and-independence.pdf">pdf</a></p><p>Author: Noga Alon, Nicolò Cesa-Bianchi, Claudio Gentile, Yishay Mansour</p><p>Abstract: We consider the partial observability model for multi-armed bandits, introduced by Mannor and Shamir [14]. Our main result is a characterization of regret in the directed observability model in terms of the dominating and independence numbers of the observability graph (which must be accessible before selecting an action). In the undirected case, we show that the learner can achieve optimal regret without even accessing the observability graph before selecting an action. Both results are shown using variants of the Exp3 algorithm operating on the observability graph in a time-efﬁcient manner. 1</p><br/>
<h2>reference text</h2><p>[1] N. Alon and J. H. Spencer. The probabilistic method. John Wiley � Sons, 2004.</p>
<p>[2] Jean-Yves Audibert and S´ bastien Bubeck. Minimax policies for adversarial and stochastic e bandits. In COLT, 2009.</p>
<p>[3] Peter Auer, Nicol` Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nonstochastic o multiarmed bandit problem. SIAM Journal on Computing, 32(1):48–77, 2002.</p>
<p>[4] Peter Auer, Nicol` Cesa-Bianchi, and Claudio Gentile. Adaptive and self-conﬁdent on-line o learning algorithms. J. Comput. Syst. Sci., 64(1):48–75, 2002.</p>
<p>[5] Y. Caro. New results on the independence number. In Tech. Report, Tel-Aviv University, 1979.</p>
<p>[6] N. Cesa-Bianchi, Y. Freund, D. Haussler, D. P. Helmbold, R. E. Schapire, and M. K. Warmuth. How to use expert advice. J. ACM, 44(3):427–485, 1997.</p>
<p>[7] N. Cesa-Bianchi and G. Lugosi. Prediction, learning, and games. Cambridge University Press, 2006.</p>
<p>[8] Nicol` Cesa-Bianchi and G´ bor Lugosi. o a 78(5):1404–1422, 2012.  Combinatorial bandits.  J. Comput. Syst. Sci.,</p>
<p>[9] V. Chvatal. A greedy heuristic for the set-covering problem. Mathematics of Operations Research, 4(3):233–235, 1979.</p>
<p>[10] Yoav Freund and Robert E. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. In Euro-COLT, pages 23–37. Springer-Verlag, 1995. Also, JCSS 55(1): 119-139 (1997).</p>
<p>[11] A. M. Frieze. On the independence number of random graphs. Discrete Mathematics, 81:171– 175, 1990.</p>
<p>[12] A. Kalai and S. Vempala. Efﬁcient algorithms for online decision problems. Journal of Computer and System Sciences, 71:291–307, 2005.</p>
<p>[13] Nick Littlestone and Manfred K. Warmuth. The weighted majority algorithm. Information and Computation, 108:212–261, 1994.</p>
<p>[14] S. Mannor and O. Shamir. From bandits to experts: On the value of side-observations. In 25th Annual Conference on Neural Information Processing Systems �NIPS 2011), 2011.</p>
<p>[15] Alan Said, Ernesto W De Luca, and Sahin Albayrak. How social relationships affect user similarities. In Proceedings of the International Conference on Intelligent User Interfaces Workshop on Social Recommender Systems, Hong Kong, 2010.</p>
<p>[16] V. G. Vovk. Aggregating strategies. In COLT, pages 371–386, 1990.</p>
<p>[17] V. K. Wey. A lower bound on the stability number of a simple graph. In Bell Lab. Tech. Memo No. 81-11217-9, 1981.  9</p>
<br/>
<br/><br/><br/></body>
</html>
