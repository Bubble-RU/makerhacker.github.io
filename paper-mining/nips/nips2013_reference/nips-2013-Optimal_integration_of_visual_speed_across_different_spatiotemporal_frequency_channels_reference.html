<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>237 nips-2013-Optimal integration of visual speed across different spatiotemporal frequency channels</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-237" href="../nips2013/nips-2013-Optimal_integration_of_visual_speed_across_different_spatiotemporal_frequency_channels.html">nips2013-237</a> <a title="nips-2013-237-reference" href="#">nips2013-237-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>237 nips-2013-Optimal integration of visual speed across different spatiotemporal frequency channels</h1>
<br/><p>Source: <a title="nips-2013-237-pdf" href="http://papers.nips.cc/paper/5203-optimal-integration-of-visual-speed-across-different-spatiotemporal-frequency-channels.pdf">pdf</a></p><p>Author: Matjaz Jogan, Alan Stocker</p><p>Abstract: How do humans perceive the speed of a coherent motion stimulus that contains motion energy in multiple spatiotemporal frequency bands? Here we tested the idea that perceived speed is the result of an integration process that optimally combines speed information across independent spatiotemporal frequency channels. We formalized this hypothesis with a Bayesian observer model that combines the likelihood functions provided by the individual channel responses (cues). We experimentally validated the model with a 2AFC speed discrimination experiment that measured subjects’ perceived speed of drifting sinusoidal gratings with different contrasts and spatial frequencies, and of various combinations of these single gratings. We found that the perceived speeds of the combined stimuli are independent of the relative phase of the underlying grating components. The results also show that the discrimination thresholds are smaller for the combined stimuli than for the individual grating components, supporting the cue combination hypothesis. The proposed Bayesian model ﬁts the data well, accounting for the full psychometric functions of both simple and combined stimuli. Fits are improved if we assume that the channel responses are subject to divisive normalization. Our results provide an important step toward a more complete model of visual motion perception that can predict perceived speeds for coherent motion stimuli of arbitrary spatial structure. 1</p><br/>
<h2>reference text</h2><p>[1] E. H. Adelson and J. R. Bergen. Spatiotemporal energy models for the perception of motion. Journal of the Optical Society of America A Optics and image science, 2(2):284–99, 1985.</p>
<p>[2] K. R. Brooks, T. Morris, and P. Thompson. Contrast and stimulus complexity moderate the relationship between spatial frequency and perceived speed: Implications for MT models of speed perception. Journal of Vision, 11(14), 2011.</p>
<p>[3] M. Carandini and D. J. Heeger. Normalization as a canonical neural computation. Nature Reviews Neuroscience, 13(1):51–62, 2012.</p>
<p>[4] M. O. Ernst and M. S. Banks. Humans integrate visual and haptic information in a statistically optimal fashion. Nature, 415(6870):429–33, 2002. 8</p>
<p>[5] N. Graham and J. Nachmias. Detection of grating patterns containing two spatial frequencies: a comparison of single-channel and multiple-channel models. Vision Research, pages 251–259, 1971.</p>
<p>[6] D. J. Heeger. Normalization of cell responses in cat striate cortex. Visual Neuroscience, 9(2):181–197, 1992.</p>
<p>[7] J. M. Hillis, S. J. Watt, M. S. Landy, and M. S. Banks. Slant from texture and disparity cues : Optimal cue combination. Journal of Vision, 4(12):967–992, 2004.</p>
<p>[8] F. H¨ rlimann, D. C. Kiper, and M. Carandini. Testing the Bayesian model of perceived speed. u Vision Research, 42:2253–2257, 2002.</p>
<p>[9] H. Nover, C. H. Anderson, and G. C. DeAngelis. A logarithmic, scale-invariant representation of speed in macaque middle temporal area accounts for speed discrimination performance. J. Neurosci, 25:10049–60, 2005.</p>
<p>[10] N. J. Priebe and S. G. Lisberger. Estimating target speed from the population response in visual area MT. Journal of Neuroscience, 24(8):1907–1916, 2004.</p>
<p>[11] T. D. Sanger. Probability density estimation for the interpretation of neural population codes. J. Neurophysiology, 76(4):2790–93, 1996.</p>
<p>[12] E. P. Simoncelli and D. J. Heeger. A model of neuronal responses in visual area MT. Vision Research, 38(5):743–761, 1998.</p>
<p>[13] E. P. Simoncelli and O. Schwartz. Modeling surround suppression in V1 neurons with a statistically-derived normalization model. Advances in Neural Information Processing Systems (NIPS), 11, 1999.</p>
<p>[14] A. T. Smith and G. K. Edgar. Perceived speed and direction of complex gratings and plaids. Journal of the Optical Society of America A Optics and image science, 8(7):1161–1171, 1991.</p>
<p>[15] A. A. Stocker. Analog integrated 2-D optical ﬂow sensor. Analog Integrated Circuits and Signal Processing, 46(2):121–138, February 2006.</p>
<p>[16] A. A. Stocker and E. P. Simoncelli. Noise characteristics and prior expectations in human visual speed perception. Nat Neurosci, 4(9):578–85, 2006.</p>
<p>[17] L. S. Stone and P. Thompson. Human speed perception is contrast dependent. Vision Research, 32(8):1535–1549, 1992.</p>
<p>[18] Y. Weiss, E. P. Simoncelli, and E. H. Adelson. Motion illusions as optimal percepts. Nature Neuroscience, 5(6):598–604, 2002.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
