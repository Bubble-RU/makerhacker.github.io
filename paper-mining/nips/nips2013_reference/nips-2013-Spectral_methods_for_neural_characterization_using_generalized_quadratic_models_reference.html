<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>305 nips-2013-Spectral methods for neural characterization using generalized quadratic models</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-305" href="../nips2013/nips-2013-Spectral_methods_for_neural_characterization_using_generalized_quadratic_models.html">nips2013-305</a> <a title="nips-2013-305-reference" href="#">nips2013-305-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>305 nips-2013-Spectral methods for neural characterization using generalized quadratic models</h1>
<br/><p>Source: <a title="nips-2013-305-pdf" href="http://papers.nips.cc/paper/4993-spectral-methods-for-neural-characterization-using-generalized-quadratic-models.pdf">pdf</a></p><p>Author: Il M. Park, Evan W. Archer, Nicholas Priebe, Jonathan W. Pillow</p><p>Abstract: We describe a set of fast, tractable methods for characterizing neural responses to high-dimensional sensory stimuli using a model we refer to as the generalized quadratic model (GQM). The GQM consists of a low-rank quadratic function followed by a point nonlinearity and exponential-family noise. The quadratic function characterizes the neuron’s stimulus selectivity in terms of a set linear receptive ﬁelds followed by a quadratic combination rule, and the invertible nonlinearity maps this output to the desired response range. Special cases of the GQM include the 2nd-order Volterra model [1, 2] and the elliptical Linear-Nonlinear-Poisson model [3]. Here we show that for “canonical form” GQMs, spectral decomposition of the ﬁrst two response-weighted moments yields approximate maximumlikelihood estimators via a quantity called the expected log-likelihood. The resulting theory generalizes moment-based estimators such as the spike-triggered covariance, and, in the Gaussian noise case, provides closed-form estimators under a large class of non-Gaussian stimulus distributions. We show that these estimators are fast and provide highly accurate estimates with far lower computational cost than full maximum likelihood. Moreover, the GQM provides a natural framework for combining multi-dimensional stimulus sensitivity and spike-history dependencies within a single model. We show applications to both analog and spiking data using intracellular recordings of V1 membrane potential and extracellular recordings of retinal spike trains. 1</p><br/>
<h2>reference text</h2><p>[1] P. Z. Marmarelis and V. Marmarelis. Analysis of physiological systems: the white-noise approach. Plenum Press, New York, 1978.</p>
<p>[2] Taiho Koh and E. Powers. Second-order volterra ﬁltering and its application to nonlinear system identiﬁcation. IEEE Transactions on Acoustics, Speech, and Signal Processing, 33(6):1445–1455, 1985.</p>
<p>[3] Il Memming Park and Jonathan W. Pillow. Bayesian spike-triggered covariance analysis. Advances in Neural Information Processing Systems 24, pp 1692–1700, 2011.</p>
<p>[4] E. P. Simoncelli, J. W. Pillow, L. Paninski, and O. Schwartz. Characterization of neural responses with stochastic stimuli. The Cognitive Neurosciences, III, chapter 23, pp 327–338. MIT Press, Cambridge, MA, October 2004.</p>
<p>[5] L. Paninski. Maximum likelihood estimation of cascade point-process neural encoding models. Network: Computation in Neural Systems, 15:243–262, 2004.</p>
<p>[6] S. Gerwinn, J. H. Macke, M. Seeger, and M. Bethge. Bayesian inference for spiking neuron models with a sparsity prior. Advances in Neural Information Processing Systems, pp 529–536, 2008.</p>
<p>[7] J. Bussgang. Crosscorrelation functions of amplitude-distorted gaussian signals. RLE Technical Reports, 216, 1952.</p>
<p>[8] E. deBoer and P. Kuyper. Triggered correlation. IEEE Transact. Biomed. Eng., 15, pp 169–179, 1968.</p>
<p>[9] E. J. Chichilnisky. A simple white noise analysis of neuronal light responses. Network: Computation in Neural Systems, 12:199–213, 2001.</p>
<p>[10] R. R. de Ruyter van Steveninck and W. Bialek. Real-time performance of a movement-senstivive neuron in the blowﬂy visual system: coding and information transmission in short spike sequences. Proc. R. Soc. Lond. B, 234:379–414, 1988.</p>
<p>[11] O. Schwartz, J. W. Pillow, N. C. Rust, and E. P. Simoncelli. Spike-triggered neural characterization. J. Vision, 6(4):484–507, 7 2006.</p>
<p>[12] RD Cook and S. Weisberg. Comment on ”sliced inverse regression for dimension reduction” by k.-c. li. Journal of the American Statistical Association, 86:328–332, 1991.</p>
<p>[13] Ker-Chau Li. Sliced inverse regression for dimension reduction. Journal of the American Statistical Association, 86(414):316–327, 1991.</p>
<p>[14] Alexandro D. Ramirez and Liam Paninski. Fast inference in generalized linear models via expected log-likelihoods. Journal of Computational Neuroscience, pp 1–20, 2013.</p>
<p>[15] W. Truccolo, U. T. Eden, M. R. Fellows, J. P. Donoghue, and E. N. Brown. A point process framework for relating neural spiking activity to spiking history, neural ensemble and extrinsic covariate effects. J. Neurophysiol, 93(2):1074–1089, 2005.</p>
<p>[16] J. W. Pillow, J. Shlens, L. Paninski, A. Sher, A. M. Litke, and E. P. Chichilnisky, E. J. Simoncelli. Spatiotemporal correlations and visual signaling in a complete neuronal population. Nature, 454:995–999, 2008.</p>
<p>[17] L. Paninski. Convergence properties of some spike-triggered analysis techniques. Network: Computation in Neural Systems, 14:437–464, 2003.</p>
<p>[18] J. W. Pillow and E. P. Simoncelli. Dimensionality reduction in neural models: An information-theoretic generalization of spike-triggered average and covariance analysis. J. Vision, 6(4):414–428, 4 2006.</p>
<p>[19] In´ s Samengo and Tim Gollisch. Spike-triggered covariance: geometric proof, symmetry properties, and e extension beyond gaussian stimuli. Journal of Computational Neuroscience, 34(1):137–161, 2013.</p>
<p>[20] Tatyana Sharpee, Nicole C. Rust, and William Bialek. Analyzing neural responses to natural signals: maximally informative dimensions. Neural Comput, 16(2):223–250, Feb 2004.</p>
<p>[21] R. S. Williamson, M. Sahani, and J. W. Pillow. Equating information-theoretic and likelihood-based methods for neural dimensionality reduction. arXiv:1308.3542 [q-bio.NC], 2013.</p>
<p>[22] J. D. Fitzgerald, R. J. Rowekamp, L. C. Sincich, and T. O. Sharpee. Second order dimensionality reduction using minimum and maximum mutual information models. PLoS Comput Biol, 7(10):e1002249, 2011.</p>
<p>[23] K. Rajan and W. Bialek. Maximally informative ”stimulus energies” in the analysis of neural responses to natural signals. arXiv:1201.0321v1 [q-bio.NC], 2012.</p>
<p>[24] James M. McFarland, Yuwei Cui, and Daniel A. Butts. Inferring nonlinear neuronal computation based on physiologically plausible inputs. PLoS Comput Biol, 9(7):e1003143+, July 2013.</p>
<p>[25] L. Theis, A. M. Chagas, D. Arnstein, C. Schwarz, and M. Bethge. Beyond glms: A generative mixture modeling approach to neural system identiﬁcation. PLoS Computational Biology, Nov 2013. in press.</p>
<p>[26] A. M. Mathai and S. B. Provost. Quadratic forms in random variables: theory and applications. M. Dekker, 1992.</p>
<p>[27] Y. S. Cho and E. J. Powers. Estimation of quadratically nonlinear systems with an i.i.d. input. [Proceedings] ICASSP 91: 1991 International Conference on Acoustics, Speech, and Signal Processing pp 3117–3120 vol.5. IEEE, 1991.</p>
<p>[28] V. J. Uzzell and E. J. Chichilnisky. Precision of spike trains in primate retinal ganglion cells. Journal of Neurophysiology, 92:780–789, 2004.  9</p>
<br/>
<br/><br/><br/></body>
</html>
