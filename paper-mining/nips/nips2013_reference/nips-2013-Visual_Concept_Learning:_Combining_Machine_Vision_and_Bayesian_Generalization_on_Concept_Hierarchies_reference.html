<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>349 nips-2013-Visual Concept Learning: Combining Machine Vision and Bayesian Generalization on Concept Hierarchies</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-349" href="../nips2013/nips-2013-Visual_Concept_Learning%3A_Combining_Machine_Vision_and_Bayesian_Generalization_on_Concept_Hierarchies.html">nips2013-349</a> <a title="nips-2013-349-reference" href="#">nips2013-349-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>349 nips-2013-Visual Concept Learning: Combining Machine Vision and Bayesian Generalization on Concept Hierarchies</h1>
<br/><p>Source: <a title="nips-2013-349-pdf" href="http://papers.nips.cc/paper/5205-visual-concept-learning-combining-machine-vision-and-bayesian-generalization-on-concept-hierarchies.pdf">pdf</a></p><p>Author: Yangqing Jia, Joshua T. Abbott, Joseph Austerweil, Thomas Griffiths, Trevor Darrell</p><p>Abstract: Learning a visual concept from a small number of positive examples is a significant challenge for machine learning algorithms. Current methods typically fail to ﬁnd the appropriate level of generalization in a concept hierarchy for a given set of visual examples. Recent work in cognitive science on Bayesian models of generalization addresses this challenge, but prior results assumed that objects were perfectly recognized. We present an algorithm for learning visual concepts directly from images, using probabilistic predictions generated by visual classiﬁers as the input to a Bayesian generalization model. As no existing challenge data tests this paradigm, we collect and make available a new, large-scale dataset for visual concept learning using the ImageNet hierarchy as the source of possible concepts, with human annotators to provide ground truth labels as to whether a new image is an instance of each concept using a paradigm similar to that used in experiments studying word learning in children. We compare the performance of our system to several baseline algorithms, and show a signiﬁcant advantage results from combining visual classiﬁers with the ability to identify an appropriate level of abstraction using Bayesian generalization. 1</p><br/>
<h2>reference text</h2><p>[1] J. T. Abbott, J. L. Austerweil, and T. L. Grifﬁths. Constructing a hypothesis space from the Web for large-scale Bayesian word learning. In Proceedings of the 34th Annual Conference of the Cognitive Science Society, 2012.</p>
<p>[2] A. Berg, J. Deng, and L. Fei-Fei. net.org/challenges/LSVRC/2010/.  ILSVRC 2010.  http://www.image-</p>
<p>[3] S. Carey. The child as word learner. Linguistic Theory and Psychological Reality, 1978.</p>
<p>[4] J. Deng, W. Dong, R. Socher, L.J. Li, K. Li, and L. Fei-Fei. ImageNet: A large-scale hierarchical image database. In CVPR, 2009.</p>
<p>[5] J. Deng, J. Krause, A. Berg, and L. Fei-Fei. Hedging your bets: Optimizing accuracyspeciﬁcity trade-offs in large scale visual recognition. In CVPR, 2012.</p>
<p>[6] J. Duchi, E. Hazan, and Y. Singer. Adaptive subgradient methods for online learning and stochastic optimization. JMLR, 12:2121–2159, 2010.</p>
<p>[7] M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman. The PASCAL Visual Object Classes (VOC) challenge. IJCV, 88(2):303–338, 2010.</p>
<p>[8] A. Farhadi, I. Endres, D. Hoiem, and D. Forsyth. Describing objects by their attributes. In CVPR, 2009.</p>
<p>[9] A. Krizhevsky, I. Sutskever, and G. Hinton. Imagenet classiﬁcation with deep convolutional neural networks. In NIPS, 2012.</p>
<p>[10] Q. Le, M. Ranzato, R. Monga, M. Devin, K. Chen, G. Corrado, J. Dean, and A. Ng. Building high-level features using large scale unsupervised learning. In ICML, 2012.</p>
<p>[11] Y. Lin, F. Lv, S. Zhu, M. Yang, T. Cour, K. Yu, L. Cao, and T. Huang. Large-scale image classiﬁcation: fast feature extraction and svm training. In CVPR, 2011.</p>
<p>[12] A. Oliva and A. Torralba. Modeling the shape of the scene: A holistic representation of the spatial envelope. International journal of computer vision, 42(3):145–175, 2001.</p>
<p>[13] D. Parikh and K. Grauman. Relative attributes. In ICCV, 2011.</p>
<p>[14] A. Quattoni, M. Collins, and T. Darrell. Transfer learning for image classiﬁcation with sparse prototype representations. In CVPR, 2008.</p>
<p>[15] E. Rosch, C. B. Mervis, W. D. Gray, D. M. Johnson, and P. Boyes-Braem. Basic objects in natural categories. Cognitive psychology, 8(3):382–439, 1976.</p>
<p>[16] R. Salakhutdinov, A. Torralba, and J.B. Tenenbaum. Learning to share visual appearance for multiclass object detection. In CVPR, 2011.</p>
<p>[17] R. N. Shepard. Towards a universal law of generalization for psychological science. Science, 237:1317–1323, 1987.</p>
<p>[18] J. B. Tenenbaum. Bayesian modeling of human concept learning. In NIPS, 1999.</p>
<p>[19] J. B. Tenenbaum. Rules and similarity in concept learning. In NIPS, 2000.</p>
<p>[20] J. B. Tenenbaum and T. L. Grifﬁths. Generalization, similarity, and Bayesian inference. Behavioral and Brain Sciences, 24(4):629–640, 2001.</p>
<p>[21] F. Xu and J.B. Tenenbaum. Word learning as Bayesian inference. Psychological Review, 114(2):245–272, 2007.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
