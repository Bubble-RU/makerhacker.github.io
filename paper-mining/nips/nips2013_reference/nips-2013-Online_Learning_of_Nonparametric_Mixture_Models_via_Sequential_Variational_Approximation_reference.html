<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>229 nips-2013-Online Learning of Nonparametric Mixture Models via Sequential Variational Approximation</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-229" href="../nips2013/nips-2013-Online_Learning_of_Nonparametric_Mixture_Models_via_Sequential_Variational_Approximation.html">nips2013-229</a> <a title="nips-2013-229-reference" href="#">nips2013-229-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>229 nips-2013-Online Learning of Nonparametric Mixture Models via Sequential Variational Approximation</h1>
<br/><p>Source: <a title="nips-2013-229-pdf" href="http://papers.nips.cc/paper/4968-online-learning-of-nonparametric-mixture-models-via-sequential-variational-approximation.pdf">pdf</a></p><p>Author: Dahua Lin</p><p>Abstract: Reliance on computationally expensive algorithms for inference has been limiting the use of Bayesian nonparametric models in large scale applications. To tackle this problem, we propose a Bayesian learning algorithm for DP mixture models. Instead of following the conventional paradigm – random initialization plus iterative update, we take an progressive approach. Starting with a given prior, our method recursively transforms it into an approximate posterior through sequential variational approximation. In this process, new components will be incorporated on the ﬂy when needed. The algorithm can reliably estimate a DP mixture model in one pass, making it particularly suited for applications with massive data. Experiments on both synthetic data and real datasets demonstrate remarkable improvement on efﬁciency – orders of magnitude speed-up compared to the state-of-the-art. 1</p><br/>
<h2>reference text</h2><p>[1] C. Antoniak. Mixtures of dirichlet processes with applications to bayesian nonparametric problems. The Annals of Statistics, 2(6):1152–1174, 1974.</p>
<p>[2] Jeff Bezanson, Stefan Karpinski, Viral B. Shah, and Alan Edelman. Julia: A fast dynamic language for technical computing. CoRR, abs/1209.5145, 2012.</p>
<p>[3] David Blei, Ng Andrew, and Michael Jordan. Latent dirichlet allocation. Journal of Machine Learning Research, 3:993–1022, 2003.</p>
<p>[4] David M. Blei and Michael I. Jordan. Variational methods for the Dirichlet process. In Proc. of ICML’04, 2004.</p>
<p>[5] Michael Bryant and Erik Sudderth. Truly nonparametric online variational inference for hierarchical dirichlet processes. In Proc. of NIPS’12, 2012.</p>
<p>[6] David B. Dahl. Sequentially-allocated merge-split sampler for conjugate and nonconjugate dirichlet process mixture models, 2005.</p>
<p>[7] Nils Lid Hjort, Chris Holmes, Peter Muller, and Stephen G. Walker. Bayesian Nonparametrics: Principles and Practice. Cambridge University Press, 2010.</p>
<p>[8] Matt Hoffman, David M. Blei, Chong Wang, and John Paisley. Stochastic variational inference. arXiv eprints, 1206.7501, 2012.</p>
<p>[9] Michael C. Hughes, Emily B. Fox, and Erik B. Sudderth. Effective split-merge monte carlo methods for nonparametric models of sequential data. 2012.</p>
<p>[10] Lancelot F. James, Antonio Lijoi, and Igor Pr¨ nster. Posterior analysis for normalized random measures u with independent increments. Scaninavian Journal of Stats, 36:76–97, 2009.</p>
<p>[11] Kenichi Kurihara, Max Welling, and Yee Whye Teh. Collapsed variational dirichlet process mixture models. In Proc. of IJCAI’07, 2007.</p>
<p>[12] Radford M. Neal. Markov Chain Sampling Methods for Dirichlet Process Mixture Models. Journal of computational and graphical statistics, 9(2):249–265, 2000.</p>
<p>[13] David J. Nott, Xiaole Zhang, Christopher Yau, and Ajay Jasra. A sequential algorithm for fast ﬁtting of dirichlet process mixture models. In Arxiv: 1301.2897, 2013.</p>
<p>[14] Ian Porteous, Alex Ihler, Padhraic Smyth, and Max Welling. Gibbs Sampling for (Coupled) Inﬁnite Mixture Models in the Stick-breaking Representation. In Proc. of UAI’06, 2006.</p>
<p>[15] Carl Edward Rasmussen. The Inﬁnite Gaussian Mixture Model. In Proc. of NIPS’00, 2000.</p>
<p>[16] Jayaram Sethuraman. A constructive deﬁnition of dirichlet priors. Statistical Sinica, 4:639–650, 1994.</p>
<p>[17] S.Jain and R.M. Neal. A split-merge markov chain monte carlo procedure for the dirichlet process mixture model. Journal of Computational and Graphical Statistics, 13(1):158–182, 2004.</p>
<p>[18] Yee Whye Teh, Michael I. Jordan, Matthew J. Beal, and David M. Blei. Hierarchical Dirichlet Processes. Journal of the American Statistical Association, 101(476):1566–1581, 2007.</p>
<p>[19] Y.W. Teh, K. Kurihara, and Max Welling. Collapsed Variational Inference for HDP. In Proc. of NIPS’07, volume 20, 2007.</p>
<p>[20] Chong Wang and David Blei. A split-merge mcmc algorithm for the hierarchical dirichlet process. arXiv eprints, 1201.1657, 2012.</p>
<p>[21] Chong Wang and David Blei. Truncation-free stochastic variational inference for bayesian nonparametric models. In Proc. of NIPS’12, 2012.</p>
<p>[22] Chong Wang and David M Blei. Variational Inference for the Nested Chinese Restaurant Process. In Proc. of NIPS’09, 2009.</p>
<p>[23] Chong Wang, John Paisley, and David Blei. Online variational inference for the hierarchical dirichlet process. In AISTATS’11, 2011.</p>
<p>[24] J. Xiao, J. Hays, K. Ehinger, A. Oliva, and A. Torralba. Sun database: Large-scale scene recognition from abbey to zoo. In Proc. of CVPR’10, 2010.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
