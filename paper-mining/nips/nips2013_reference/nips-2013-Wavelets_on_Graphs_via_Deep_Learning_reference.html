<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>350 nips-2013-Wavelets on Graphs via Deep Learning</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-350" href="../nips2013/nips-2013-Wavelets_on_Graphs_via_Deep_Learning.html">nips2013-350</a> <a title="nips-2013-350-reference" href="#">nips2013-350-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>350 nips-2013-Wavelets on Graphs via Deep Learning</h1>
<br/><p>Source: <a title="nips-2013-350-pdf" href="http://papers.nips.cc/paper/5046-wavelets-on-graphs-via-deep-learning.pdf">pdf</a></p><p>Author: Raif Rustamov, Leonidas Guibas</p><p>Abstract: An increasing number of applications require processing of signals deﬁned on weighted graphs. While wavelets provide a ﬂexible tool for signal processing in the classical setting of regular domains, the existing graph wavelet constructions are less ﬂexible – they are guided solely by the structure of the underlying graph and do not take directly into consideration the particular class of signals to be processed. This paper introduces a machine learning framework for constructing graph wavelets that can sparsely represent a given class of signals. Our construction uses the lifting scheme, and is based on the observation that the recurrent nature of the lifting scheme gives rise to a structure resembling a deep auto-encoder network. Particular properties that the resulting wavelets must satisfy determine the training objective and the structure of the involved neural networks. The training is unsupervised, and is conducted similarly to the greedy pre-training of a stack of auto-encoders. After training is completed, we obtain a linear wavelet transform that can be applied to any graph signal in time and memory linear in the size of the graph. Improved sparsity of our wavelet transform for the test signals is conﬁrmed via experiments both on synthetic and real data. 1</p><br/>
<h2>reference text</h2><p>[1] M. Belkin and P. Niyogi. Semi-supervised learning on riemannian manifolds. Machine Learning, 56(13):209–239, 2004. 4.4, 5</p>
<p>[2] Y. Bengio, P. Lamblin, D. Popovici, and H. Larochelle. Greedy layer-wise training of deep networks. In B. Sch¨ lkopf, J. Platt, and T. Hoffman, editors, Advances in Neural Information Processing Systems 19, o pages 153–160. MIT Press, Cambridge, MA, 2007. 1, 3</p>
<p>[3] J. Bruna and S. Mallat. Invariant scattering convolution networks. IEEE Transactions on Pattern Analysis and Machine Intelligence, 35(8):1872–1886, 2013. 6</p>
<p>[4] R. L. Claypoole, G. Davis, W. Sweldens, and R. G. Baraniuk. Nonlinear wavelet transforms for image coding via lifting. IEEE Transactions on Image Processing, 12(12):1449–1459, Dec. 2003. 3</p>
<p>[5] R. R. Coifman and S. Lafon. Diffusion maps. Applied and Computational Harmonic Analysis, 21(1):5–30, July 2006. 4.6, 5</p>
<p>[6] R. R. Coifman and M. Maggioni. Diffusion wavelets. Appl. Comput. Harmon. Anal., 21(1):53–94, 2006. 1</p>
<p>[7] M. Crovella and E. D. Kolaczyk. Graph wavelets for spatial trafﬁc analysis. In INFOCOM, 2003. 1</p>
<p>[8] I. Daubechies and W. Sweldens. Factoring wavelet transforms into lifting steps. J. Fourier Anal. Appl., 4(3):245–267, 1998. 3</p>
<p>[9] M. N. Do and Y. M. Lu. Multidimensional ﬁlter banks and multiscale geometric representations. Foundations and Trends in Signal Processing, 5(3):157–264, 2012. 1</p>
<p>[10] M. Gavish, B. Nadler, and R. R. Coifman. Multiscale wavelets on trees, graphs and high dimensional data: Theory and applications to semi supervised learning. In ICML, pages 367–374, 2010. 1, 3, 4.5</p>
<p>[11] A. Georghiades, P. Belhumeur, and D. Kriegman. From few to many: Illumination cone models for face recognition under variable lighting and pose. IEEE Trans. Pattern Anal. Mach. Intelligence, 23(6):643–660, 2001. 5</p>
<p>[12] D. K. Hammond, P. Vandergheynst, and R. Gribonval. Wavelets on graphs via spectral graph theory. Appl. Comput. Harmon. Anal., 30(2):129–150, 2011. 1</p>
<p>[13] G. E. Hinton, S. Osindero, and Y.-W. Teh. A fast learning algorithm for deep belief nets. Neural Comput., 18(7):1527–1554, 2006. 1, 3</p>
<p>[14] G. E. Hinton and R. Salakhutdinov. Reducing the Dimensionality of Data with Neural Networks. Science, 313:504–507, July 2006. 1, 3</p>
<p>[15] Q. V. Le, J. Ngiam, A. Coates, A. Lahiri, B. Prochnow, and A. Y. Ng. On optimization methods for deep learning. In ICML, pages 265–272, 2011. 4.3</p>
<p>[16] S. Mallat. A Wavelet Tour of Signal Processing, Third Edition: The Sparse Way. Academic Press, 3rd edition, 2008. 2</p>
<p>[17] S. K. Narang and A. Ortega. Multi-dimensional separable critically sampled wavelet ﬁlterbanks on arbitrary graphs. In ICASSP, pages 3501–3504, 2012. 1</p>
<p>[18] A. Y. Ng, M. I. Jordan, and Y. Weiss. On spectral clustering: Analysis and an algorithm. In NIPS, pages 849–856, 2001. 4.5</p>
<p>[19] I. Ram, M. Elad, and I. Cohen. Generalized tree-based wavelet transform. IEEE Transactions on Signal Processing, 59(9):4199–4209, 2011. 1</p>
<p>[20] M. Ranzato, C. Poultney, S. Chopra, and Y. LeCun. Efﬁcient learning of sparse representations with an energy-based model. In B. Sch¨ lkopf, J. Platt, and T. Hoffman, editors, Advances in Neural Information o Processing Systems 19, pages 1137–1144. MIT Press, Cambridge, MA, 2007. 1, 3</p>
<p>[21] R. M. Rustamov. Average interpolating wavelets on point clouds and graphs. CoRR, abs/1110.2227, 2011. 1</p>
<p>[22] D. I. Shuman, S. K. Narang, P. Frossard, A. Ortega, and P. Vandergheynst. The emerging ﬁeld of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains. IEEE Signal Process. Mag., 30(3):83–98, 2013. 1</p>
<p>[23] W. Sweldens. The lifting scheme: A construction of second generation wavelets. SIAM Journal on Mathematical Analysis, 29(2):511–546, 1998. 2</p>
<p>[24] A. D. Szlam, M. Maggioni, R. R. Coifman, and J. C. Bremer. Diffusion-driven multiscale analysis on manifolds and graphs: top-down and bottom-up constructions. In SPIE, volume 5914, 2005. 1, 3, 4.5</p>
<p>[25] X. Zhang, X. Dong, and P. Frossard. Learning of structured graph dictionaries. In ICASSP, pages 3373–3376, 2012. 6</p>
<p>[26] X. Zhu, Z. Ghahramani, and J. D. Lafferty. Semi-supervised learning using gaussian ﬁelds and harmonic functions. In ICML, pages 912–919, 2003. 5  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
