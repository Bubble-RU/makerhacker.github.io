<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>236 nips-2013-Optimal Neural Population Codes for High-dimensional Stimulus Variables</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-236" href="../nips2013/nips-2013-Optimal_Neural_Population_Codes_for_High-dimensional_Stimulus_Variables.html">nips2013-236</a> <a title="nips-2013-236-reference" href="#">nips2013-236-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>236 nips-2013-Optimal Neural Population Codes for High-dimensional Stimulus Variables</h1>
<br/><p>Source: <a title="nips-2013-236-pdf" href="http://papers.nips.cc/paper/4994-optimal-neural-population-codes-for-high-dimensional-stimulus-variables.pdf">pdf</a></p><p>Author: Zhuo Wang, Alan Stocker, Daniel Lee</p><p>Abstract: In many neural systems, information about stimulus variables is often represented in a distributed manner by means of a population code. It is generally assumed that the responses of the neural population are tuned to the stimulus statistics, and most prior work has investigated the optimal tuning characteristics of one or a small number of stimulus variables. In this work, we investigate the optimal tuning for diffeomorphic representations of high-dimensional stimuli. We analytically derive the solution that minimizes the L2 reconstruction loss. We compared our solution with other well-known criteria such as maximal mutual information. Our solution suggests that the optimal weights do not necessarily decorrelate the inputs, and the optimal nonlinearity differs from the conventional equalization solution. Results illustrating these optimal representations are shown for some input distributions that may be relevant for understanding the coding of perceptual pathways. 1</p><br/>
<h2>reference text</h2><p>[1] K Kang, RM Shapley, and H Sompolinsky. Information tuning of populations of neurons in primary visual cortex. Journal of neuroscience, 24(15):3726–3735, 2004.</p>
<p>[2] AP Georgopoulos, AB Schwartz, and RE Kettner. Adaptation of the motion-sensitive neuron h1 is generated locally and governed by contrast frequency. Science, 233:1416–1419, 1986.</p>
<p>[3] FE Theunissen and JP Miller. Representation of sensory information in the cricket cercal sensory system. II. information theoretic calculation of system accuracy and optimal tuningcurve widths of four primary interneurons. J Neurophysiol, 66(5):1690–1703, November 1991.</p>
<p>[4] DC Fitzpatrick, R Batra, TR Stanford, and S Kuwada. A neuronal population code for sound localization. Nature, 388:871–874, 1997. 8</p>
<p>[5] NS Harper and D McAlpine. Optimal neural population coding of an auditory spatial cue. Nature, 430:682–686, 2004.</p>
<p>[6] N Brenner, W Bialek, and R de Ruyter van Steveninck. Adaptive rescaling maximizes information transmission. Neuron, 26:695–702, 2000.</p>
<p>[7] Tvd Twer and DIA MacLeod. Optimal nonlinear codes for the perception of natural colours. Network: Computation in Neural Systems, 12(3):395–407, 2001.</p>
<p>[8] I Dean, NS Harper, and D McAlpine. Neural population coding of sound level adapts to stimulus statistics. Nature neuroscience, 8:1684–1689, 2005.</p>
<p>[9] Y Ozuysal and SA Baccus. Linking the computational structure of variance adaptation to biophysical mechanisms. Neuron, 73:1002–1015, 2012.</p>
<p>[10] SB Laughlin. A simple coding procedure enhances a neurons information capacity. Z. Naturforschung, 36c(3):910–912, 1981.</p>
<p>[11] J-P Nadal and N Parga. Non linear neurons in the low noise limit: A factorial code maximizes information transfer, 1994.</p>
<p>[12] M Bethge, D Rotermund, and K Pawelzik. Optimal short-term population coding: when Fisher information fails. Neural Computation, 14:2317–2351, 2002.</p>
<p>[13] M Bethge, D Rotermund, and K Pawelzik. Optimal neural rate coding leads to bimodal ﬁring rate distributions. Netw. Comput. Neural Syst., 14:303–319, 2003.</p>
<p>[14] MD McDonnell and NG Stocks. Maximally informative stimuli and tuning curves for sigmoidal rate-coding neurons and populations. Phys. Rev. Lett., 101:058103, 2008.</p>
<p>[15] Z Wang, A Stocker, and DD Lee. Optimal neural tuning curves for arbitrary stimulus distributions: Discrimax, infomax and minimum lp loss. Adv. Neural Information Processing Systems, 25:2177–2185, 2012.</p>
<p>[16] N Brunel and J-P Nadal. Mutual information, ﬁsher information and population coding. Neural Computation, 10(7):1731–1757, 1998.</p>
<p>[17] K Zhang and TJ Sejnowski. Neuronal tuning: To sharpen or broaden? Neural Computation, 11:75–84, 1999.</p>
<p>[18] A Pouget, S Deneve, J-C Ducom, and PE Latham. Narrow versus wide tuning curves: Whats best for a population code? Neural Computation, 11:85–90, 1999.</p>
<p>[19] H Sompolinsky and H Yoon. The effect of correlations on the ﬁsher information of population codes. Advances in Neural Information Processing Systems, 11, 1999.</p>
<p>[20] AP Nikitin, NG Stocks, RP Morse, and MD McDonnell. Neural population coding is optimized by discrete tuning curves. Phys. Rev. Lett., 103:138101, 2009.</p>
<p>[21] D Ganguli and EP Simoncelli. Implicit encoding of prior probabilities in optimal neural populations. Adv. Neural Information Processing Systems, 23:658–666, 2010.</p>
<p>[22] S Yaeli and R Meir. Error-based analysis of optimal tuning functions explains phenomena observed in sensory neurons. Front Comput Neurosci, 4, 2010.</p>
<p>[23] E Doi and MS Lewicki. Characterization of minimum error linear coding with sensory and neural noise. Neural Computation, 23, 2011.</p>
<p>[24] AJ Bell and TJ Sejnowski. An information-maximization approach to blind separation and blind deconvolution. Neural Computation, 7:1129–1159, 1995.</p>
<p>[25] DJ Field BA Olshausen. Emergence of simple-cell receptive ﬁeld properties by learning a sparse code for natural images. Nature, 381:607–609, 1996.</p>
<p>[26] A Hyvarinen and E Oja. Independent component analysis: Algorithms and applications. Neural Networks, 13:411–430, 2000.</p>
<p>[27] P Berens, A Ecker, S Gerwinn, AS Tolias, and M Bethge. Reassessing optimal neural population codes with neurometric functions. Proceedings of the National Academy of Sciences, 11:4423–4428, 2011.</p>
<p>[28] TM Cover and J Thomas. Elements of Information Theory. Wiley, 1991.</p>
<p>[29] EL Lehmann and G Casella. Theory of point estimation. New York: Springer-Verlag., 1999.</p>
<p>[30] GH Hardy, JE Littlewood, and G Polya. Inequalities, 2nd ed. Cambridge University Press, 1988. 9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
