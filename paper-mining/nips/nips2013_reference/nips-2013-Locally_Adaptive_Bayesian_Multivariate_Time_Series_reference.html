<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>178 nips-2013-Locally Adaptive Bayesian Multivariate Time Series</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-178" href="../nips2013/nips-2013-Locally_Adaptive_Bayesian_Multivariate_Time_Series.html">nips2013-178</a> <a title="nips-2013-178-reference" href="#">nips2013-178-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>178 nips-2013-Locally Adaptive Bayesian Multivariate Time Series</h1>
<br/><p>Source: <a title="nips-2013-178-pdf" href="http://papers.nips.cc/paper/5115-locally-adaptive-bayesian-multivariate-time-series.pdf">pdf</a></p><p>Author: Daniele Durante, Bruno Scarpa, David Dunson</p><p>Abstract: In modeling multivariate time series, it is important to allow time-varying smoothness in the mean and covariance process. In particular, there may be certain time intervals exhibiting rapid changes and others in which changes are slow. If such locally adaptive smoothness is not accounted for, one can obtain misleading inferences and predictions, with over-smoothing across erratic time intervals and under-smoothing across times exhibiting slow variation. This can lead to miscalibration of predictive intervals, which can be substantially too narrow or wide depending on the time. We propose a continuous multivariate stochastic process for time series having locally varying smoothness in both the mean and covariance matrix. This process is constructed utilizing latent dictionary functions in time, which are given nested Gaussian process priors and linearly related to the observed data through a sparse mapping. Using a differential equation representation, we bypass usual computational bottlenecks in obtaining MCMC and online algorithms for approximate Bayesian inference. The performance is assessed in simulations and illustrated in a ﬁnancial application. 1 1.1</p><br/>
<h2>reference text</h2><p>[1] Tsay, R.S. (2005). Analysis of Financial Time Series. Hoboken, New Jersey: Wiley.</p>
<p>[2] Kalman, R.E. (1960). A new approach to linear ﬁltering and prediction problems. Journal of Basic Engineering 82:35-45.</p>
<p>[3] Rasmussen, C.E. & Williams, C.K.I (2006). Gaussian processes for machine learning. Boston: MIT Press.</p>
<p>[4] Huang, J.Z., Wu, C.O & Zhou, L. (2002). Varying-coefﬁcient models and basis function approximations for the analysis of repeated measurements. Biometrika 89:111-128.</p>
<p>[5] Hastie, T. J. & Tibshirani, R. J. (1990). Generalized Additive Models. London: Chapman and Hall.</p>
<p>[6] Wu C.O., Chiang C.T. & Hoover D.R. (1998). Asymptotic conﬁdence regions for kernel smoothing of a varying-coefﬁcient model with longitudinal data. JASA 93:1388-1402.</p>
<p>[7] Friedman, J. H. (1991). Multivariate Adaptive Regression Splines. Annals of Statistics 19:1-67.</p>
<p>[8] Smith, M. & Kohn, R. (1996). Nonparametric regression using Bayesian variable selection. Journal of Econometrics 75:317-343.</p>
<p>[9] George, E.I. & McCulloch, R.E. (1993). Variable selection via Gibbs sampling. JASA 88:881-889.</p>
<p>[10] Donoho, D.L. & Johnstone, I.M. (1995). Adapting to unknown smoothness via wavelet shrinkage. JASA 90:1200-1224.</p>
<p>[11] Fan, J. & Gijbels, I. (1995). Data-driven bandwidth selection in local polynomial ﬁtting: variable bandwidth and spatial adaptation. JRSS. Series B 57:371-394.</p>
<p>[12] Wolpert, R.L., Clyde M.A. & Tu, C. (2011). Stochastic expansions using continuous dictionaries: Levy adaptive regression kernels. Annals of Statistics 39:1916-1962.</p>
<p>[13] Bollerslev, T., Engle, R.F. and Wooldrige, J.M. (1988). A capital-asset pricing model with time-varying covariances. Journal of Political Economy 96:116-131.</p>
<p>[14] Engle, R.F. & Kroner, K.F. (1995). Multivariate simultaneous generalized ARCH. Econometric Theory 11:122-150.</p>
<p>[15] Engle, R.F. (2002). Dynamic conditional correlation: a simple class of multivariate generalized autoregressive conditional heteroskedasticity models. Journal of Business & Economic Statistics 20:339-350.</p>
<p>[16] Burns, P. (2005). Multivariate GARCH with Only Univariate Estimation. http://www.burns-stat.com.</p>
<p>[17] Alexander, C.O. (2001). Orthogonal GARCH. Mastering Risk 2:21-38.</p>
<p>[18] van der Weide, R. (2002). GO-GARCH: a multivariate generalized orthogonal GARCH model. Journal of Applied Econometrics 17:549-564.</p>
<p>[19] Nakajima, J. & West, M. (2012). Dynamic factor volatility modeling: A Bayesian latent threshold approach. Journal of Financial Econometrics, in press.</p>
<p>[20] Wilson, A.G. & Ghahramani Z. (2010). Generalised Wishart Processes. arXiv:1101.0240.</p>
<p>[21] Bru, M. (1991). Wishart Processes. Journal of Theoretical Probability 4:725-751.</p>
<p>[22] Fox E. & Dunson D.B. (2011). Bayesian Nonparametric Covariance Regression. arXiv:1101.2017.</p>
<p>[23] Zhu B. & Dunson D.B., (2012). Locally Adaptive Bayes Nonparametric Regression via Nested Gaussian Processes. arXiv:1201.4403.</p>
<p>[24] Durbin, J. & Koopman, S. (2002). A simple and efﬁcient simulation smoother for state space time series analysis. Biometrika 89:603-616.</p>
<p>[25] Durbin, J. & Koopman, S. (2001). Time Series Analysis by State Space Methods. New York: Oxford University Press Inc.</p>
<p>[26] Donoho, D.L. & Johnstone, J.M. (1994). Ideal spatial adaptation by wavelet shrinkage. Biometrika 81:425455.</p>
<p>[27] Gelman, A. & Rubin, D.B. (1992). Inference from iterative simulation using multiple sequences. Statistical Science 7:457-511.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
