<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>208 nips-2013-Neural representation of action sequences: how far can a simple snippet-matching model take us?</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-208" href="../nips2013/nips-2013-Neural_representation_of_action_sequences%3A_how_far_can_a_simple_snippet-matching_model_take_us%3F.html">nips2013-208</a> <a title="nips-2013-208-reference" href="#">nips2013-208-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>208 nips-2013-Neural representation of action sequences: how far can a simple snippet-matching model take us?</h1>
<br/><p>Source: <a title="nips-2013-208-pdf" href="http://papers.nips.cc/paper/5052-neural-representation-of-action-sequences-how-far-can-a-simple-snippet-matching-model-take-us.pdf">pdf</a></p><p>Author: Cheston Tan, Jedediah M. Singer, Thomas Serre, David Sheinberg, Tomaso Poggio</p><p>Abstract: The macaque Superior Temporal Sulcus (STS) is a brain area that receives and integrates inputs from both the ventral and dorsal visual processing streams (thought to specialize in form and motion processing respectively). For the processing of articulated actions, prior work has shown that even a small population of STS neurons contains sufﬁcient information for the decoding of actor invariant to action, action invariant to actor, as well as the speciﬁc conjunction of actor and action. This paper addresses two questions. First, what are the invariance properties of individual neural representations (rather than the population representation) in STS? Second, what are the neural encoding mechanisms that can produce such individual neural representations from streams of pixel images? We ﬁnd that a simple model, one that simply computes a linear weighted sum of ventral and dorsal responses to short action “snippets”, produces surprisingly good ﬁts to the neural data. Interestingly, even using inputs from a single stream, both actor-invariance and action-invariance can be accounted for, by having different linear weights. 1</p><br/>
<h2>reference text</h2><p>[1] L. G. Ungerleider and J. V. Haxby, “‘What’ and ‘where’ in the human brain.” Current Opinion in Neurobiology, vol. 4, no. 2, pp. 157–65, 1994.</p>
<p>[2] J. M. Singer and D. L. Sheinberg, “Temporal cortex neurons encode articulated actions as slow sequences of integrated poses.” Journal of Neuroscience, vol. 30, no. 8, pp. 3133–45, 2010.</p>
<p>[3] M. W. Oram and D. I. Perrett, “Integration of form and motion in the anterior superior temporal polysensory area of the macaque monkey.” Journal of Neurophysiology, vol. 76, no. 1, pp. 109–29, 1996.</p>
<p>[4] J. S. Baizer, L. G. Ungerleider, and R. Desimone, “Organization of visual inputs to the inferior temporal and posterior parietal cortex in macaques.” Journal of Neuroscience, vol. 11, no. 1, pp. 168–90, 1991.</p>
<p>[5] T. Jellema, G. Maassen, and D. I. Perrett, “Single cell integration of animate form, motion and location in the superior temporal cortex of the macaque monkey.” Cerebral Cortex, vol. 14, no. 7, pp. 781–90, 2004.</p>
<p>[6] C. Bruce, R. Desimone, and C. G. Gross, “Visual properties of neurons in a polysensory area in superior temporal sulcus of the macaque.” Journal of Neurophysiology, vol. 46, no. 2, pp. 369–84, 1981.</p>
<p>[7] J. Vangeneugden, F. Pollick, and R. Vogels, “Functional differentiation of macaque visual temporal cortical neurons using a parametric action space.” Cerebral Cortex, vol. 19, no. 3, pp. 593–611, 2009.</p>
<p>[8] G. Johansson, “Visual perception of biological motion and a model for its analysis.” Perception & Psychophysics, vol. 14, pp. 201–211, 1973.</p>
<p>[9] E. Grossman, M. Donnelly, R. Price, D. Pickens, V. Morgan, G. Neighbor, and R. Blake, “Brain areas involved in perception of biological motion.” Journal of Cognitive Neuroscience, vol. 12, no. 5, pp. 711– 20, 2000.</p>
<p>[10] J. A. Beintema and M. Lappe, “Perception of biological motion without local image motion.” Proceedings of the National Academy of Sciences of the United States of America, vol. 99, no. 8, pp. 5661–3, 2002.</p>
<p>[11] D. I. Perrett, P. A. Smith, A. J. Mistlin, A. J. Chitty, A. S. Head, D. D. Potter, R. Broennimann, A. D. Milner, and M. A. Jeeves, “Visual analysis of body movements by neurones in the temporal cortex of the macaque monkey: a preliminary report.” Behavioural Brain Research, vol. 16, no. 2-3, pp. 153–70, 1985.</p>
<p>[12] M. S. Beauchamp, K. E. Lee, J. V. Haxby, and A. Martin, “FMRI responses to video and point-light displays of moving humans and manipulable objects.” Journal of Cognitive Neuroscience, vol. 15, no. 7, pp. 991–1001, 2003.</p>
<p>[13] N. C. Rust, V. Mante, E. P. Simoncelli, and J. A. Movshon, “How MT cells analyze the motion of visual patterns.” Nature Neuroscience, vol. 9, no. 11, pp. 1421–31, 2006.</p>
<p>[14] M. Riesenhuber and T. Poggio, “Hierarchical models of object recognition in cortex.” Nature Neuroscience, vol. 2, no. 11, pp. 1019–25, 1999.</p>
<p>[15] H. Jhuang, T. Serre, L. Wolf, and T. Poggio, “A Biologically Inspired System for Action Recognition,” in 2007 IEEE 11th International Conference on Computer Vision. IEEE, 2007.</p>
<p>[16] C. G. Gross, C. E. Rocha-Miranda, and D. B. Bender, “Visual properties of neurons in inferotemporal cortex of the macaque.” Journal of Neurophysiology, vol. 35, no. 1, pp. 96–111, 1972.</p>
<p>[17] P. Dayan and L. F. Abbott, Theoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems. Cambridge, MA: The MIT Press, 2005.</p>
<p>[18] J. A. Movshon and W. T. Newsome, “Visual response properties of striate cortical neurons projecting to area MT in macaque monkeys.” Journal of Neuroscience, vol. 16, no. 23, pp. 7733–41, 1996.</p>
<p>[19] W. Reichardt, “Autocorrelation, a principle for the evaluation of sensory information by the central nervous system,” Sensory Communication, pp. 303–17, 1961.</p>
<p>[20] K. Schindler and L. van Gool, “Action snippets: How many frames does human action recognition require?” in 2008 IEEE Conference on Computer Vision and Pattern Recognition. IEEE, 2008.</p>
<p>[21] M. A. Giese and T. Poggio, “Neural mechanisms for the recognition of biological movements.” Nature Reviews Neuroscience, vol. 4, no. 3, pp. 179–92, 2003.</p>
<p>[22] J. Lange and M. Lappe, “A model of biological motion perception from conﬁgural form cues.” Journal of Neuroscience, vol. 26, no. 11, pp. 2894–906, 2006.</p>
<p>[23] P. J. Mineault, F. A. Khawaja, D. A. Butts, and C. C. Pack, “Hierarchical processing of complex motion along the primate dorsal visual pathway.” Proceedings of the National Academy of Sciences of the United States of America, vol. 109, no. 16, pp. E972–80, 2012.</p>
<p>[24] I. Laptev, M. Marszalek, C. Schmid, and B. Rozenfeld, “Learning realistic human actions from movies,” in 2008 IEEE Conference on Computer Vision and Pattern Recognition. IEEE, 2008.</p>
<p>[25] A. Bobick and J. Davis, “The recognition of human movement using temporal templates,” IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 23, no. 3, pp. 257–267, 2001.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
