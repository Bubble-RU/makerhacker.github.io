<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>284 nips-2013-Robust Spatial Filtering with Beta Divergence</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-284" href="../nips2013/nips-2013-Robust_Spatial_Filtering_with_Beta_Divergence.html">nips2013-284</a> <a title="nips-2013-284-reference" href="#">nips2013-284-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>284 nips-2013-Robust Spatial Filtering with Beta Divergence</h1>
<br/><p>Source: <a title="nips-2013-284-pdf" href="http://papers.nips.cc/paper/4922-robust-spatial-filtering-with-beta-divergence.pdf">pdf</a></p><p>Author: Wojciech Samek, Duncan Blythe, Klaus-Robert Müller, Motoaki Kawanabe</p><p>Abstract: The efﬁciency of Brain-Computer Interfaces (BCI) largely depends upon a reliable extraction of informative features from the high-dimensional EEG signal. A crucial step in this protocol is the computation of spatial ﬁlters. The Common Spatial Patterns (CSP) algorithm computes ﬁlters that maximize the difference in band power between two conditions, thus it is tailored to extract the relevant information in motor imagery experiments. However, CSP is highly sensitive to artifacts in the EEG data, i.e. few outliers may alter the estimate drastically and decrease classiﬁcation performance. Inspired by concepts from the ﬁeld of information geometry we propose a novel approach for robustifying CSP. More precisely, we formulate CSP as a divergence maximization problem and utilize the property of a particular type of divergence, namely beta divergence, for robustifying the estimation of spatial ﬁlters in the presence of artifacts in the data. We demonstrate the usefulness of our method on toy data and on EEG recordings from 80 subjects. 1</p><br/>
<h2>reference text</h2><p>[1] G. Dornhege, J. del R. Mill´ n, T. Hinterberger, D. McFarland, and K.-R. M¨ ller, Eds., Toward a u Brain-Computer Interfacing. Cambridge, MA: MIT Press, 2007.</p>
<p>[2] J. R. Wolpaw, N. Birbaumer, D. J. McFarland, G. Pfurtscheller, and T. M. Vaughan, “Braincomputer interfaces for communication and control,” Clin. Neurophysiol., vol. 113, no. 6, pp. 767–791, 2002.</p>
<p>[3] B. Blankertz, R. Tomioka, S. Lemm, M. Kawanabe, and K.-R. M¨ ller, “Optimizing Spatial u ﬁlters for Robust EEG Single-Trial Analysis,” IEEE Signal Proc. Magazine, vol. 25, no. 1, pp. 41–56, 2008.</p>
<p>[4] H. Ramoser, J. M¨ ller-Gerking, and G. Pfurtscheller, “Optimal spatial ﬁltering of single trial u eeg during imagined hand movement,” IEEE Trans. Rehab. Eng., vol. 8, no. 4, pp. 441–446, 1998.</p>
<p>[5] L. C. Parra, C. D. Spence, A. D. Gerson, and P. Sajda, “Recipes for the linear analysis of eeg,” NeuroImage, vol. 28, pp. 326–341, 2005.</p>
<p>[6] S. Lemm, B. Blankertz, T. Dickhaus, and K.-R. M¨ ller, “Introduction to machine learning for u brain imaging,” NeuroImage, vol. 56, no. 2, pp. 387–399, 2011.</p>
<p>[7] F. Lotte and C. Guan, “Regularizing common spatial patterns to improve bci designs: Uniﬁed theory and new algorithms,” IEEE Trans. Biomed. Eng., vol. 58, no. 2, pp. 355 –362, 2011.</p>
<p>[8] W. Samek, C. Vidaurre, K.-R. M¨ ller, and M. Kawanabe, “Stationary common spatial patterns u for brain-computer interfacing,” Journal of Neural Engineering, vol. 9, no. 2, p. 026013, 2012.</p>
<p>[9] O. Ledoit and M. Wolf, “A well-conditioned estimator for large-dimensional covariance matrices,” Journal of Multivariate Analysis, vol. 88, no. 2, pp. 365 – 411, 2004. 8</p>
<p>[10] H. Lu, H.-L. Eng, C. Guan, K. Plataniotis, and A. Venetsanopoulos, “Regularized common spatial pattern with aggregation for eeg classiﬁcation in small-sample setting,” IEEE Transactions on Biomedical Engineering, vol. 57, no. 12, pp. 2936–2946, 2010.</p>
<p>[11] D. Devlaminck, B. Wyns, M. Grosse-Wentrup, G. Otte, and P. Santens, “Multi-subject learning for common spatial patterns in motor-imagery bci,” Computational Intelligence and Neuroscience, vol. 2011, no. 217987, pp. 1–9, 2011.</p>
<p>[12] B. Blankertz, M. K. R. Tomioka, F. U. Hohlefeld, V. Nikulin, and K.-R. M¨ ller, “Invariant u common spatial patterns: Alleviating nonstationarities in brain-computer interfacing,” in Ad. in NIPS 20, 2008, pp. 113–120.</p>
<p>[13] W. Samek, F. C. Meinecke, and K.-R. M¨ ller, “Transferring subspaces between subjects in u brain-computer interfacing,” IEEE Transactions on Biomedical Engineering, vol. 60, no. 8, pp. 2289–2298, 2013.</p>
<p>[14] M. Arvaneh, C. Guan, K. K. Ang, and C. Quek, “Optimizing spatial ﬁlters by minimizing within-class dissimilarities in electroencephalogram-based brain-computer interface,” IEEE Trans. Neural Netw. Learn. Syst., vol. 24, no. 4, pp. 610–619, 2013.</p>
<p>[15] S. Amari, H. Nagaoka, and D. Harada, Methods of information geometry. American Mathematical Society, 2000.</p>
<p>[16] S. Eguchi and Y. Kano, “Robustifying maximum likelihood estimation,” Tokyo Institute of Statistical Mathematics, Tokyo, Japan, Tech. Rep, 2001.</p>
<p>[17] R. Bhatia, Matrix analysis, ser. Graduate Texts in Mathematics. Springer, 1997, vol. 169.</p>
<p>[18] M. Mihoko and S. Eguchi, “Robust blind source separation by beta divergence,” Neural Comput., vol. 14, no. 8, pp. 1859–1886, Aug. 2002.</p>
<p>[19] C. F´ votte and J. Idier, “Algorithms for nonnegative matrix factorization with the βe divergence,” Neural Comput., vol. 23, no. 9, pp. 2421–2456, Sep. 2011.</p>
<p>[20] A. Hyv¨ rinen, “Survey on independent component analysis,” Neural Computing Surveys, a vol. 2, pp. 94–128, 1999.</p>
<p>[21] M. Kawanabe, W. Samek, P. von B¨ nau, and F. Meinecke, “An information geometrical view u of stationary subspace analysis,” in Artiﬁcial Neural Networks and Machine Learning - ICANN 2011, ser. LNCS. Springer Berlin / Heidelberg, 2011, vol. 6792, pp. 397–404.</p>
<p>[22] N. Murata, T. Takenouchi, and T. Kanamori, “Information geometry of u-boost and bregman divergence,” Neural Computation, vol. 16, pp. 1437–1481, 2004.</p>
<p>[23] H. Wang, “Harmonic mean of kullbackleibler divergences for optimizing multi-class eeg spatio-temporal ﬁlters,” Neural Processing Letters, vol. 36, no. 2, pp. 161–171, 2012.</p>
<p>[24] P. von B¨ nau, F. C. Meinecke, F. C. Kir´ ly, and K.-R. M¨ ller, “Finding Stationary Subspaces u a u in Multivariate Time Series,” Physical Review Letters, vol. 103, no. 21, pp. 214 101+, 2009.</p>
<p>[25] P. von B¨ nau, “Stationary subspace analysis - towards understanding non-stationary data,” u Ph.D. dissertation, Technische Universit¨ t Berlin, 2012. a</p>
<p>[26] W. Samek, M. Kawanabe, and K.-R. M¨ ller, “Divergence-based framework for common spau tial patterns algorithms,” IEEE Reviews in Biomedical Engineering, 2014, in press.</p>
<p>[27] A. Basu, I. R. Harris, N. L. Hjort, and M. C. Jones, “Robust and efﬁcient estimation by minimising a density power divergence,” Biometrika, vol. 85, no. 3, pp. 549–559, 1998.</p>
<p>[28] P. J. Huber, Robust Statistics, ser. Wiley Series in Probability and Statistics. WileyInterscience, 1981.</p>
<p>[29] B. Blankertz, C. Sannelli, S. Halder, E. M. Hammer, A. K¨ bler, K.-R. M¨ ller, G. Curio, u u and T. Dickhaus, “Neurophysiological predictor of smr-based bci performance,” NeuroImage, vol. 51, no. 4, pp. 1303–1309, 2010.</p>
<p>[30] P. J. Rousseeuw and K. V. Driessen, “A fast algorithm for the minimum covariance determinant estimator,” Technometrics, vol. 41, no. 3, pp. 212–223, 1999.</p>
<p>[31] B. Blankertz, S. Lemm, M. S. Treder, S. Haufe, and K.-R. M¨ ller, “Single-trial analysis and u classiﬁcation of ERP components – a tutorial,” NeuroImage, vol. 56, no. 2, pp. 814–825, 2011.</p>
<p>[32] J. Baik and J. Silverstein, “Eigenvalues of large sample covariance matrices of spiked population models,” Journal of Multivariate Analysis, vol. 97, no. 6, pp. 1382–1408, 2006.  9</p>
<br/>
<br/><br/><br/></body>
</html>
