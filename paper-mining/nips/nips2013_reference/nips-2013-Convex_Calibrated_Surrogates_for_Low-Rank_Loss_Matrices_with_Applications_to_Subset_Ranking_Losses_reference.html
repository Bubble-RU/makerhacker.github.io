<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>72 nips-2013-Convex Calibrated Surrogates for Low-Rank Loss Matrices with Applications to Subset Ranking Losses</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-72" href="../nips2013/nips-2013-Convex_Calibrated_Surrogates_for_Low-Rank_Loss_Matrices_with_Applications_to_Subset_Ranking_Losses.html">nips2013-72</a> <a title="nips-2013-72-reference" href="#">nips2013-72-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>72 nips-2013-Convex Calibrated Surrogates for Low-Rank Loss Matrices with Applications to Subset Ranking Losses</h1>
<br/><p>Source: <a title="nips-2013-72-pdf" href="http://papers.nips.cc/paper/4906-convex-calibrated-surrogates-for-low-rank-loss-matrices-with-applications-to-subset-ranking-losses.pdf">pdf</a></p><p>Author: Harish G. Ramaswamy, Shivani Agarwal, Ambuj Tewari</p><p>Abstract: The design of convex, calibrated surrogate losses, whose minimization entails consistency with respect to a desired target loss, is an important concept to have emerged in the theory of machine learning in recent years. We give an explicit construction of a convex least-squares type surrogate loss that can be designed to be calibrated for any multiclass learning problem for which the target loss matrix has a low-rank structure; the surrogate loss operates on a surrogate target space of dimension at most the rank of the target loss. We use this result to design convex calibrated surrogates for a variety of subset ranking problems, with target losses including the precision@q, expected rank utility, mean average precision, and pairwise disagreement. 1</p><br/>
<h2>reference text</h2><p>[1] G´ bor Lugosi and Nicolas Vayatis. On the Bayes-risk consistency of regularized boosting a methods. Annals of Statistics, 32(1):30–55, 2004.</p>
<p>[2] Wenxin Jiang. Process consistency for AdaBoost. Annals of Statistics, 32(1):13–29, 2004.</p>
<p>[3] Tong Zhang. Statistical behavior and consistency of classiﬁcation methods based on convex risk minimization. Annals of Statistics, 32(1):56–134, 2004.</p>
<p>[4] Ingo Steinwart. Consistency of support vector machines and other regularized kernel classiﬁers. IEEE Transactions on Information Theory, 51(1):128–142, 2005.</p>
<p>[5] Peter L. Bartlett, Michael Jordan, and Jon McAuliffe. Convexity, classiﬁcation and risk bounds. Journal of the American Statistical Association, 101(473):138–156, 2006.</p>
<p>[6] Tong Zhang. Statistical analysis of some multi-category large margin classiﬁcation methods. Journal of Machine Learning Research, 5:1225–1251, 2004.</p>
<p>[7] Ambuj Tewari and Peter L. Bartlett. On the consistency of multiclass classiﬁcation methods. Journal of Machine Learning Research, 8:1007–1025, 2007.</p>
<p>[8] Ingo Steinwart. How to compare different loss functions and their risks. Constructive Approximation, 26:225–287, 2007.</p>
<p>[9] David Cossock and Tong Zhang. Statistical analysis of bayes optimal subset ranking. IEEE Transactions on Information Theory, 54(11):5140–5154, 2008.</p>
<p>[10] Fen Xia, Tie-Yan Liu, Jue Wang, Wensheng Zhang, and Hang Li. Listwise approach to learning to rank: Theory and algorithm. In International Conference on Machine Learning, 2008.</p>
<p>[11] John Duchi, Lester Mackey, and Michael Jordan. On the consistency of ranking algorithms. In International Conference on Machine Learning, 2010.</p>
<p>[12] Pradeep Ravikumar, Ambuj Tewari, and Eunho Yang. On NDCG consistency of listwise ranking methods. In International Conference on Artiﬁcial Intelligence and Statistics, 2011.</p>
<p>[13] David Buffoni, Cl´ ment Calauz` nes, Patrick Gallinari, and Nicolas Usunier. Learning scoring e e functions with order-preserving losses and standardized supervision. In International Conference on Machine Learning, 2011.</p>
<p>[14] Wei Gao and Zhi-Hua Zhou. On the consistency of multi-label learning. In Conference on Learning Theory, 2011.</p>
<p>[15] Cl´ ment Calauz` nes, Nicolas Usunier, and Patrick Gallinari. On the (non-)existence of convex, e e calibrated surrogate losses for ranking. In Advances in Neural Information Processing Systems 25, pages 197–205. 2012.</p>
<p>[16] Harish G. Ramaswamy and Shivani Agarwal. Classiﬁcation calibration dimension for general multiclass losses. In Advances in Neural Information Processing Systems 25, pages 2087– 2095. 2012.</p>
<p>[17] Yanyan Lan, Jiafeng Guo, Xueqi Cheng, and Tie-Yan Liu. Statistical consistency of ranking methods in a rank-differentiable probability space. In Advances in Neural Information Processing Systems 25, pages 1241–1249. 2012.</p>
<p>[18] Quoc V. Le and Alex Smola. Direct optimization of ranking measures, arXiv:0704.3359, 2007.</p>
<p>[19] Yisong Yue, Thomas Finley, Filip Radlinski, and Thorsten Joachims. A support vector method for optimizing average precision. In Proceedings of the 30th ACM SIGIR International Conference on Research and Development in Information Retrieval, 2007.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
