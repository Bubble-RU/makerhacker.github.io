<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>356 nips-2013-Zero-Shot Learning Through Cross-Modal Transfer</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-356" href="../nips2013/nips-2013-Zero-Shot_Learning_Through_Cross-Modal_Transfer.html">nips2013-356</a> <a title="nips-2013-356-reference" href="#">nips2013-356-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>356 nips-2013-Zero-Shot Learning Through Cross-Modal Transfer</h1>
<br/><p>Source: <a title="nips-2013-356-pdf" href="http://papers.nips.cc/paper/5027-zero-shot-learning-through-cross-modal-transfer.pdf">pdf</a></p><p>Author: Richard Socher, Milind Ganjoo, Christopher D. Manning, Andrew Ng</p><p>Abstract: This work introduces a model that can recognize objects in images even if no training data is available for the object class. The only necessary knowledge about unseen visual categories comes from unsupervised text corpora. Unlike previous zero-shot learning models, which can only differentiate between unseen classes, our model can operate on a mixture of seen and unseen classes, simultaneously obtaining state of the art performance on classes with thousands of training images and reasonable performance on unseen classes. This is achieved by seeing the distributions of words in texts as a semantic space for understanding what objects look like. Our deep learning model does not require any manually deﬁned semantic or visual features for either words or images. Images are mapped to be close to semantic word vectors corresponding to their classes, and the resulting image embeddings can be used to distinguish whether an image is of a seen or unseen class. We then use novelty detection methods to differentiate unseen classes from seen classes. We demonstrate two novelty detection strategies; the ﬁrst gives high accuracy on unseen classes, while the second is conservative in its prediction of novelty and keeps the seen classes’ accuracy high. 1</p><br/>
<h2>reference text</h2><p>[1] M. Baroni and A. Lenci. Distributional memory: A general framework for corpus-based semantics. Computational Linguistics, 36(4):673–721, 2010.</p>
<p>[2] E. Bart and S. Ullman. Cross-generalization: learning novel classes from a single example by feature replacement. In CVPR, 2005.</p>
<p>[3] Y. Bengio, R. Ducharme, P. Vincent, and C. Janvin. A neural probabilistic language model. J. Mach. Learn. Res., 3, March 2003.</p>
<p>[4] J. Blitzer, M. Dredze, and F. Pereira. Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classiﬁcation. In ACL, 2007.</p>
<p>[5] E. Bruni, G. Boleda, M. Baroni, and N. Tran. Distributional semantics in technicolor. In ACL, 2012.</p>
<p>[6] A. Coates and A. Ng. The Importance of Encoding Versus Training with Sparse Coding and Vector Quantization . In ICML, 2011.</p>
<p>[7] R. Collobert and J. Weston. A uniﬁed architecture for natural language processing: deep neural networks with multitask learning. In ICML, 2008.</p>
<p>[8] J. Curran. From Distributional to Semantic Similarity. PhD thesis, University of Edinburgh, 2004.</p>
<p>[9] K. Erk and S. Pad´ . A structured vector space model for word meaning in context. In EMNLP, 2008. o</p>
<p>[10] A. Farhadi, I. Endres, D. Hoiem, and D. Forsyth. Describing objects by their attributes. In CVPR, 2009.</p>
<p>[11] Y. Feng and M. Lapata. Visual information in semantic representation. In HLT-NAACL, 2010.</p>
<p>[12] M. Fink. Object classiﬁcation from a single example utilizing class relevance pseudo-metrics. In NIPS, 2004.</p>
<p>[13] X. Glorot, A. Bordes, and Y. Bengio. Domain adaptation for Large-Scale sentiment classiﬁcation: A deep learning approach. In ICML, 2011.</p>
<p>[14] D. Hoiem, A.A. Efros, and M. Herbert. Geometric context from a single image. In ICCV, 2005.</p>
<p>[15] E. H. Huang, R. Socher, C. D. Manning, and A. Y. Ng. Improving Word Representations via Global Context and Multiple Word Prototypes. In ACL, 2012.</p>
<p>[16] Yangqing Jia, Chang Huang, and T. Darrell. Beyond spatial pyramids: Receptive ﬁeld learning for pooled image features. In Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pages 3370 –3377, june 2012.</p>
<p>[17] H. Kriegel, P. Kr¨ ger, E. Schubert, and A. Zimek. LoOP: local Outlier Probabilities. In Proceedings of o the 18th ACM conference on Information and knowledge management, CIKM ’09, 2009.</p>
<p>[18] Alex Krizhevsky. Learning Multiple Layers of Features from Tiny Images. Master’s thesis, Computer Science Department, University of Toronto, 2009.</p>
<p>[19] R.; Perona L. Fei-Fei; Fergus. One-shot learning of object categories. TPAMI, 28, 2006.</p>
<p>[20] B. M. Lake, J. Gross R. Salakhutdinov, and J. B. Tenenbaum. One shot learning of simple visual concepts. In Proceedings of the 33rd Annual Conference of the Cognitive Science Society, 2011.</p>
<p>[21] C. H. Lampert, H. Nickisch, and S. Harmeling. Learning to Detect Unseen Object Classes by BetweenClass Attribute Transfer. In CVPR, 2009.</p>
<p>[22] T. K. Landauer and S. T. Dumais. A solution to Plato’s problem: the Latent Semantic Analysis theory of acquisition, induction and representation of knowledge. Psychological Review, 104(2):211–240, 1997.</p>
<p>[23] C.W. Leong and R. Mihalcea. Going beyond text: A hybrid image-text approach for measuring word relatedness. In IJCNLP, 2011.</p>
<p>[24] D. Lin. Automatic retrieval and clustering of similar words. In Proceedings of COLING-ACL, pages 768–774, 1998.</p>
<p>[25] J. Ngiam, A. Khosla, M. Kim, J. Nam, H. Lee, and A.Y. Ng. Multimodal deep learning. In ICML, 2011.</p>
<p>[26] S. Pado and M. Lapata. Dependency-based construction of semantic space models. Computational Linguistics, 33(2):161–199, 2007.</p>
<p>[27] M. Palatucci, D. Pomerleau, G. Hinton, and T. Mitchell. Zero-shot learning with semantic output codes. In NIPS, 2009.</p>
<p>[28] Guo-Jun Qi, C. Aggarwal, Y. Rui, Q. Tian, S. Chang, and T. Huang. Towards cross-category knowledge propagation for learning visual concepts. In CVPR, 2011.</p>
<p>[29] A. Torralba R. Salakhutdinov, J. Tenenbaum. Learning to learn with compound hierarchical-deep models. In NIPS, 2012.</p>
<p>[30] H. Sch¨ tze. Automatic word sense discrimination. Computational Linguistics, 24:97–124, 1998. u  9</p>
<p>[31] R. Socher and L. Fei-Fei. Connecting modalities: Semi-supervised segmentation and annotation of images using unaligned text corpora. In CVPR, 2010.</p>
<p>[32] P. D. Turney and P. Pantel. From frequency to meaning: Vector space models of semantics. Journal of Artiﬁcial Intelligence Research, 37:141–188, 2010.</p>
<p>[33] L. van der Maaten and G. Hinton. Visualizing data using t-SNE. Journal of Machine Learning Research, 2008.  10</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
