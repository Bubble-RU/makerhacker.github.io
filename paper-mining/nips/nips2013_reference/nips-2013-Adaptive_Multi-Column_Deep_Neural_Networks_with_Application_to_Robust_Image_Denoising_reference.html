<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>27 nips-2013-Adaptive Multi-Column Deep Neural Networks with Application to Robust Image Denoising</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-27" href="../nips2013/nips-2013-Adaptive_Multi-Column_Deep_Neural_Networks_with_Application_to_Robust_Image_Denoising.html">nips2013-27</a> <a title="nips-2013-27-reference" href="#">nips2013-27-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>27 nips-2013-Adaptive Multi-Column Deep Neural Networks with Application to Robust Image Denoising</h1>
<br/><p>Source: <a title="nips-2013-27-pdf" href="http://papers.nips.cc/paper/5030-adaptive-multi-column-deep-neural-networks-with-application-to-robust-image-denoising.pdf">pdf</a></p><p>Author: Forest Agostinelli, Michael R. Anderson, Honglak Lee</p><p>Abstract: Stacked sparse denoising autoencoders (SSDAs) have recently been shown to be successful at removing noise from corrupted images. However, like most denoising techniques, the SSDA is not robust to variation in noise types beyond what it has seen during training. To address this limitation, we present the adaptive multi-column stacked sparse denoising autoencoder (AMC-SSDA), a novel technique of combining multiple SSDAs by (1) computing optimal column weights via solving a nonlinear optimization program and (2) training a separate network to predict the optimal weights. We eliminate the need to determine the type of noise, let alone its statistics, at test time and even show that the system can be robust to noise not seen in the training set. We show that state-of-the-art denoising performance can be achieved with a single system on a variety of different noise types. Additionally, we demonstrate the efﬁcacy of AMC-SSDA as a preprocessing (denoising) algorithm by achieving strong classiﬁcation performance on corrupted MNIST digits. 1</p><br/>
<h2>reference text</h2><p>[1] G. R. Arce. Nonlinear signal processing: A statistical approach. Wiley-Interscience, 2005.</p>
<p>[2] E. Arias-Castro and D. L. Donoho. Does median ﬁltering truly preserve edges better than linear ﬁltering? The Annals of Statistics, 37(3):1172–1206, 2009.  8</p>
<p>[3] D. I. Barnea and H. F. Silverman. A class of algorithms for fast digital image registration. IEEE Transactions on Computers, 100(2):179–186, 1972.</p>
<p>[4] Y. Bengio. Learning deep architectures for AI. Foundations and Trends in Machine Learning, 2(1):1–127, 2009.</p>
<p>[5] Y. Bengio, P. Lamblin, D. Popovici, and H. Larochelle. Greedy layer-wise training of deep networks. In NIPS, 2007.</p>
<p>[6] R. Bourne. Image ﬁlters. In Fundamentals of Digital Imaging in Medicine, pages 137–172. Springer London, 2010.</p>
<p>[7] R. G. Brown and P. Y. Hwang. Introduction to random signals and applied Kalman ﬁltering, volume 1. John Wiley & Sons New York, 1992.</p>
<p>[8] A. Buades, B. Coll, and J.-M. Morel. A review of image denoising algorithms, with a new one. Multiscale Modeling & Simulation, 4(2):490–530, 2005.</p>
<p>[9] H. C. Burger, C. J. Schuler, and S. Harmeling. Image denoising: Can plain neural networks compete with BM3D? In CVPR, 2012.</p>
<p>[10] D. Ciresan, U. Meier, and J. Schmidhuber. Multi-column deep neural networks for image classiﬁcation. ¸ In CVPR, 2012.</p>
<p>[11] K. Dabov, R. Foi, V. Katkovnik, and K. Egiazarian. Image denoising by sparse 3D transform-domain collaborative ﬁltering. IEEE Transactions on Image Processing, 16(8):2080–2095, 2007.</p>
<p>[12] L. W. Goldman. Principles of CT: Radiation dose and image quality. Journal of Nuclear Medicine Technology, 35(4):213–225, 2007.</p>
<p>[13] G. Hinton. A practical guide to training restricted boltzmann machines. Technical report, University of Toronto, 2010.</p>
<p>[14] G. E. Hinton, S. Osindero, and Y.-W. Teh. A fast learning algorithm for deep belief nets. Neural Computation, 18(7):1527–1554, 2006.</p>
<p>[15] G. E. Hinton and R. Salakhutdinov. Reducing the dimensionality of data with neural networks. Science, 313(5786):504–507, 2006.</p>
<p>[16] W. Huda. Dose and image quality in CT. Pediatric Radiology, 32(10):709–713, 2002.</p>
<p>[17] N. C. Institute. The Cancer Imaging Archive. http://www.cancerimagingarchive.net, 2013.</p>
<p>[18] V. Jain and H. S. Seung. Natural image denoising with convolutional networks. In NIPS, 2008.</p>
<p>[19] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998.</p>
<p>[20] H. Lee, C. Ekanadham, and A. Y. Ng. Sparse deep belief net model for visual area V2. In NIPS. 2008.</p>
<p>[21] F. Luisier, T. Blu, and M. Unser. A new SURE approach to image denoising: Interscale orthonormal wavelet thresholding. IEEE Transactions on Image Processing, 16(3):593–606, 2007.</p>
<p>[22] J. Mairal, F. Bach, J. Ponce, G. Sapiro, and A. Zisserman. Non-local sparse models for image restoration. In ICCV, 2009.</p>
<p>[23] M. C. Motwani, M. C. Gadiya, R. C. Motwani, and F. C. Harris. Survey of image denoising techniques. In GSPX, 2004.</p>
<p>[24] J. Park and I. W. Sandberg. Universal approximation using radial-basis-function networks. Neural Computation, 3(2):246–257, 1991.</p>
<p>[25] J. Portilla, V. Strela, M. J. Wainwright, and E. P. Simoncelli. Image denoising using scale mixtures of Gaussians in the wavelet domain. IEEE Transactions on Image Processing, 12(11):1338–1351, 2003.</p>
<p>[26] M. G. Rathor, M. A. Kaushik, and M. V. Gupta. Medical images denoising techniques review. International Journal of Electronics Communication and Microelectronics Designing, 1(1):33–36, 2012.</p>
<p>[27] R. Siemund, A. L¨ ve, D. van Westen, L. Stenberg, C. Petersen, and I. Bj¨ rkman-Burtscher. Radiation o o dose reduction in CT of the brain: Can advanced noise ﬁltering compensate for loss of image quality? Acta Radiologica, 53(4):468–472, 2012.</p>
<p>[28] Y. Tang and C. Eliasmith. Deep networks for robust visual recognition. In ICML, 2010.</p>
<p>[29] P. Vincent, H. Larochelle, I. Lajoie, Y. Bengio, and P.-A. Manzagol. Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion. The Journal of Machine Learning Research, 11:3371–3408, 2010.</p>
<p>[30] N. Wiener. Extrapolation, interpolation, and smoothing of stationary time series: with engineering applications. Technology Press of the Massachusetts Institute of Technology, 1950.</p>
<p>[31] J. Xie, L. Xu, and E. Chen. Image denoising and inpainting with deep neural networks. In NIPS, 2012.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
