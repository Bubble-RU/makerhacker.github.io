<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>133 nips-2013-Global Solver and Its Efficient Approximation for Variational Bayesian Low-rank Subspace Clustering</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-133" href="../nips2013/nips-2013-Global_Solver_and_Its_Efficient_Approximation_for_Variational_Bayesian_Low-rank_Subspace_Clustering.html">nips2013-133</a> <a title="nips-2013-133-reference" href="#">nips2013-133-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>133 nips-2013-Global Solver and Its Efficient Approximation for Variational Bayesian Low-rank Subspace Clustering</h1>
<br/><p>Source: <a title="nips-2013-133-pdf" href="http://papers.nips.cc/paper/5069-global-solver-and-its-efficient-approximation-for-variational-bayesian-low-rank-subspace-clustering.pdf">pdf</a></p><p>Author: Shinichi Nakajima, Akiko Takeda, S. Derin Babacan, Masashi Sugiyama, Ichiro Takeuchi</p><p>Abstract: When a probabilistic model and its prior are given, Bayesian learning offers inference with automatic parameter tuning. However, Bayesian learning is often obstructed by computational difﬁculty: the rigorous Bayesian learning is intractable in many models, and its variational Bayesian (VB) approximation is prone to suffer from local minima. In this paper, we overcome this difﬁculty for low-rank subspace clustering (LRSC) by providing an exact global solver and its efﬁcient approximation. LRSC extracts a low-dimensional structure of data by embedding samples into the union of low-dimensional subspaces, and its variational Bayesian variant has shown good performance. We ﬁrst prove a key property that the VBLRSC model is highly redundant. Thanks to this property, the optimization problem of VB-LRSC can be separated into small subproblems, each of which has only a small number of unknown variables. Our exact global solver relies on another key property that the stationary condition of each subproblem consists of a set of polynomial equations, which is solvable with the homotopy method. For further computational efﬁciency, we also propose an efﬁcient approximate variant, of which the stationary condition can be written as a polynomial equation with a single variable. Experimental results show the usefulness of our approach. 1</p><br/>
<h2>reference text</h2><p>[1] H. Attias. Inferring parameters and structure of latent variable models by variational Bayes. In Proc. of UAI, pages 21–30, 1999.</p>
<p>[2] S. D. Babacan, S. Nakajima, and M. N. Do. Probabilistic low-rank subspace clustering. In Advances in Neural Information Processing Systems 25, pages 2753–2761, 2012.</p>
<p>[3] J. Besag. On the statistical analysis of dirty pictures. Journal of the Royal Statistical Society B, 48:259– 302, 1986.</p>
<p>[4] C. M. Bishop. Variational principal components. In Proc. of International Conference on Artiﬁcial Neural Networks, volume 1, pages 514–509, 1999.</p>
<p>[5] C. M. Bishop. Pattern Recognition and Machine Learning. Springer, New York, NY, USA, 2006.</p>
<p>[6] F. J. Drexler. A homotopy method for the calculation of all zeros of zero-dimensional polynomial ideals. In H. J. Wacker, editor, Continuation methods, pages 69–93, New York, 1978. Academic Press.</p>
<p>[7] E. Elhamifar and R. Vidal. Sparse subspace clustering. In Proc. of CVPR, pages 2790–2797, 2009.</p>
<p>[8] P. Favaro, R. Vidal, and A. Ravichandran. A closed form solution to robust subspace estimation and clustering. In Proceedings of CVPR, pages 1801–1807, 2011.</p>
<p>[9] C. B. Garcia and W. I. Zangwill. Determining all solutions to certain systems of nonlinear equations. Mathematics of Operations Research, 4:1–14, 1979.</p>
<p>[10] T. Gunji, S. Kim, M. Kojima, A. Takeda, K. Fujisawa, and T. Mizutani. Phom—a polyhedral homotopy continuation method. Computing, 73:57–77, 2004.</p>
<p>[11] A. K. Gupta and D. K. Nagar. Matrix Variate Distributions. Chapman and Hall/CRC, 1999.</p>
<p>[12] T. L. Lee, T. Y. Li, and C. H. Tsai. Hom4ps-2.0: a software package for solving polynomial systems by the polyhedral homotopy continuation method. Computing, 83:109–133, 2008.</p>
<p>[13] G. Liu, Z. Lin, and Y. Yu. Robust subspace segmentation by low-rank representation. In Proc. of ICML, pages 663–670, 2010.</p>
<p>[14] G. Liu, H. Xu, and S. Yan. Exact subspace segmentation and outlier detection by low-rank representation. In Proc. of AISTATS, 2012.</p>
<p>[15] G. Liu and S. Yan. Latent low-rank representation for subspace segmentation and feature extraction. In Proc. of ICCV, 2011.</p>
<p>[16] S. Nakajima, M. Sugiyama, and S. D. Babacan. Variational Bayesian sparse additive matrix factorization. Machine Learning, 92:319–1347, 2013.</p>
<p>[17] S. Nakajima, M. Sugiyama, S. D. Babacan, and R. Tomioka. Global analytic solution of fully-observed variational Bayesian matrix factorization. Journal of Machine Learning Research, 14:1–37, 2013.</p>
<p>[18] M. Seeger and G. Bouchard. Fast variational Bayesian inference for non-conjugate matrix factorization models. In Proceedings of International Conference on Artiﬁcial Intelligence and Statistics, La Palma, Spain, 2012.</p>
<p>[19] J. Shi and J. Malik. Normalized cuts and image segmentation. IEEE Trans. Pattern Anal. Machine Intell., 22(8):888–905, 2000.</p>
<p>[20] M. Soltanolkotabi and E. J. Cand` s. A geometric analysis of subspace clustering with outliers. CoRR, e 2011.</p>
<p>[21] R. Tron and R. Vidal. A benchmark for the comparison of 3-D motion segmentation algorithms. In Proc. of CVPR, 2007.  9</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
