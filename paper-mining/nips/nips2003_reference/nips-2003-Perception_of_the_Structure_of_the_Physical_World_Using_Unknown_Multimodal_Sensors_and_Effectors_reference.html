<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>154 nips-2003-Perception of the Structure of the Physical World Using Unknown Multimodal Sensors and Effectors</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2003" href="../home/nips2003_home.html">nips2003</a> <a title="nips-2003-154" href="../nips2003/nips-2003-Perception_of_the_Structure_of_the_Physical_World_Using_Unknown_Multimodal_Sensors_and_Effectors.html">nips2003-154</a> <a title="nips-2003-154-reference" href="#">nips2003-154-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>154 nips-2003-Perception of the Structure of the Physical World Using Unknown Multimodal Sensors and Effectors</h1>
<br/><p>Source: <a title="nips-2003-154-pdf" href="http://papers.nips.cc/paper/2348-perception-of-the-structure-of-the-physical-world-using-unknown-multimodal-sensors-and-effectors.pdf">pdf</a></p><p>Author: D. Philipona, J.k. O'regan, J.-p. Nadal, Olivier Coenen</p><p>Abstract: Is there a way for an algorithm linked to an unknown body to infer by itself information about this body and the world it is in? Taking the case of space for example, is there a way for this algorithm to realize that its body is in a three dimensional world? Is it possible for this algorithm to discover how to move in a straight line? And more basically: do these questions make any sense at all given that the algorithm only has access to the very high-dimensional data consisting of its sensory inputs and motor outputs? We demonstrate in this article how these questions can be given a positive answer. We show that it is possible to make an algorithm that, by analyzing the law that links its motor outputs to its sensory inputs, discovers information about the structure of the world regardless of the devices constituting the body it is linked to. We present results from simulations demonstrating a way to issue motor orders resulting in “fundamental” movements of the body as regards the structure of the physical world. 1</p><br/>
<h2>reference text</h2><p>[1] N. Bourbaki. Vari´ tes diff´ rentielles et analytiques. Fascicule de r´ sultats. Hermann, e e e 1971-1997.</p>
<p>[2] T. Masson. G´ om´ trie diff´ rentielle, groupes et alg` bres de Lie, ﬁbr´ s et connexions. e e e e e LPT, 2001.</p>
<p>[3] J. K. O’Regan and A. No¨ . A sensorimotor account of vision and visual consciousness. e Behavioral and Brain Sciences, 24(5), 2001.</p>
<p>[4] D. Philipona, K. O’Regan, and J.-P. Nadal. Is there something out there ? Inferring space from sensorimotor dependencies. Neural Computation, 15(9), 2003.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
