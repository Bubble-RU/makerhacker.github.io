<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>91 nips-2003-Inferring State Sequences for Non-linear Systems with Embedded Hidden Markov Models</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2003" href="../home/nips2003_home.html">nips2003</a> <a title="nips-2003-91" href="../nips2003/nips-2003-Inferring_State_Sequences_for_Non-linear_Systems_with_Embedded_Hidden_Markov_Models.html">nips2003-91</a> <a title="nips-2003-91-reference" href="#">nips2003-91-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>91 nips-2003-Inferring State Sequences for Non-linear Systems with Embedded Hidden Markov Models</h1>
<br/><p>Source: <a title="nips-2003-91-pdf" href="http://papers.nips.cc/paper/2391-inferring-state-sequences-for-non-linear-systems-with-embedded-hidden-markov-models.pdf">pdf</a></p><p>Author: Radford M. Neal, Matthew J. Beal, Sam T. Roweis</p><p>Abstract: We describe a Markov chain method for sampling from the distribution of the hidden state sequence in a non-linear dynamical system, given a sequence of observations. This method updates all states in the sequence simultaneously using an embedded Hidden Markov Model (HMM). An update begins with the creation of “pools” of candidate states at each time. We then deﬁne an embedded HMM whose states are indexes within these pools. Using a forward-backward dynamic programming algorithm, we can efﬁciently choose a state sequence with the appropriate probabilities from the exponentially large number of state sequences that pass through states in these pools. We illustrate the method in a simple one-dimensional example, and in an example showing how an embedded HMM can be used to in effect discretize the state space without any discretization error. We also compare the embedded HMM to a particle smoother on a more substantial problem of inferring human motion from 2D traces of markers. 1</p><br/>
<h2>reference text</h2><p>[1] Achan, K., Roweis, S. T., and Frey, B. J. (2004) “A Segmental HMM for Speech Waveforms”, Technical Report UTML-TR-2004-001, University of Toronto, January 2004.</p>
<p>[2] Doucet, A., Godsill, S. J., and West, M. (2000) “Monte Carlo ﬁltering and smoothing with application to time-varying spectral estimation” Proc. IEEE International Conference on Acoustics, Speech and Signal Processing, 2000, volume II, pages 701-704.</p>
<p>[3] Neal, R. M. (1993) Probabilistic Inference Using Markov Chain Monte Carlo Methods, Technical Report CRG-TR-93-1, Dept. of Computer Science, University of Toronto, 144 pages. Available from http://www.cs.utoronto.ca/∼radford.</p>
<p>[4] Neal, R. M. (2003) “Markov chain sampling for non-linear state space models using embedded hidden Markov models”, Technical Report No. 0304, Dept. of Statistics, University of Toronto, 9 pages. Available from http://www.cs.utoronto.ca/∼radford.</p>
<p>[5] Scott, S. L. (2002) “Bayesian methods for hidden Markov models: Recursive computing in the 21st century”, Journal of the American Statistical Association, vol. 97, pp. 337–351.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
