<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>186 nips-2003-Towards Social Robots: Automatic Evaluation of Human-Robot Interaction by Facial Expression Classification</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2003" href="../home/nips2003_home.html">nips2003</a> <a title="nips-2003-186" href="../nips2003/nips-2003-Towards_Social_Robots%3A_Automatic_Evaluation_of_Human-Robot_Interaction_by_Facial_Expression_Classification.html">nips2003-186</a> <a title="nips-2003-186-reference" href="#">nips2003-186-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>186 nips-2003-Towards Social Robots: Automatic Evaluation of Human-Robot Interaction by Facial Expression Classification</h1>
<br/><p>Source: <a title="nips-2003-186-pdf" href="http://papers.nips.cc/paper/2402-towards-social-robots-automatic-evaluation-of-human-robot-interaction-by-facial-expression-classification.pdf">pdf</a></p><p>Author: G.C. Littlewort, M.S. Bartlett, I.R. Fasel, J. Chenu, T. Kanda, H. Ishiguro, J.R. Movellan</p><p>Abstract: Computer animated agents and robots bring a social dimension to human computer interaction and force us to think in new ways about how computers could be used in daily life. Face to face communication is a real-time process operating at a time scale of less than a second. In this paper we present progress on a perceptual primitive to automatically detect frontal faces in the video stream and code them with respect to 7 dimensions in real time: neutral, anger, disgust, fear, joy, sadness, surprise. The face ﬁnder employs a cascade of feature detectors trained with boosting techniques [13, 2]. The expression recognizer employs a novel combination of Adaboost and SVM’s. The generalization performance to new subjects for a 7-way forced choice was 93.3% and 97% correct on two publicly available datasets. The outputs of the classiﬁer change smoothly as a function of time, providing a potentially valuable representation to code facial expression dynamics in a fully automatic and unobtrusive manner. The system was deployed and evaluated for measuring spontaneous facial expressions in the ﬁeld in an application for automatic assessment of human-robot interaction.</p><br/>
<h2>reference text</h2><p>[1] P. Ekman and W. Friesen. Pictures of facial affect. Photographs, 1976. Available from Human Interaction Laboratory, UCSF, HIL-0984, San Francisco, CA 94143.</p>
<p>[2] I. Fasel and J. R. Movellan. Comparison of neurally inspired face detection algorithms. In Proceedings of the international conference on artiﬁcial neural networks (ICANN 2002). UAM, 2002.</p>
<p>[3] Yoav Freund and Robert E. Schapire. Experiments with a new boosting algorithm. In Proc. 13th International Conference on Machine Learning, pages 148–146. Morgan Kaufmann, 1996.</p>
<p>[4] J Friedman, T Hastie, and R Tibshirani. Additive logistic regression: A statistical view of boosting. ANNALS OF STATISTICS, 28(2):337–374, 2000.</p>
<p>[5] H. Ishiguro, T. Ono, M. Imai, T. Maeda, and T. Kandaand R. Nakatsu. Robovie: an interactive humanoid robot. 28(6):498–503, 2001.</p>
<p>[6] T. Kanade, J.F. Cohn, and Y. Tian. Comprehensive database for facial expression analysis. In Proceedings of the fourth IEEE International conference on automatic face and gesture recognition (FG’00), pages 46–53, Grenoble, France, 2000.</p>
<p>[7] M. Lades, J. Vorbr¨ ggen, J. Buhmann, J. Lange, W. Konen, C. von der Malsburg, and R. W¨ rtz. u u Distortion invariant object recognition in the dynamic link architecture. IEEE Transactions on Computers, 42(3):300–311, 1993.</p>
<p>[8] M. Lyons, J. Budynek, A. Plante, and S. Akamatsu. Classifying facial attributes using a 2-d gabor wavelet representation and discriminant analysis. In Proceedings of the 4th international conference on automatic face and gesture recognition, pages 202–207, 2000.</p>
<p>[9] C. Padgett and G. Cottrell. Representing face images for emotion classiﬁcation. In M. Mozer, M. Jordan, and T. Petsche, editors, Advances in Neural Information Processing Systems, volume 9, Cambridge, MA, 1997. MIT Press.</p>
<p>[10] H. Rowley, S. Baluja, and T. Kanade. Neural network-based face detection. IEEE Trans. on Pattern Analysis and Machine Intelligence, 1(20):23–28, 1998.</p>
<p>[11] H. Schneiderman and T. Kanade. Probabilistic modeling of local appearance and spatial relationships for object recognition. In Proc. IEEE Intl. Conf. on Computer Vision and Pattern Recognition, pages 45–51, 1998.</p>
<p>[12] Kah Kay Sung and Tomaso Poggio. Example based learning for view-based human face detection. Technical Report AIM-1521, 1994.</p>
<p>[13] Paul Viola and Michael Jones. Robust real-time object detection. Technical Report CRL 20001/01, Cambridge ResearchLaboratory, 2001.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
