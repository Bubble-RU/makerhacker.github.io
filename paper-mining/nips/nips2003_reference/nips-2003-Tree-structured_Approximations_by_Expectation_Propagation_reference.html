<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>189 nips-2003-Tree-structured Approximations by Expectation Propagation</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2003" href="../home/nips2003_home.html">nips2003</a> <a title="nips-2003-189" href="../nips2003/nips-2003-Tree-structured_Approximations_by_Expectation_Propagation.html">nips2003-189</a> <a title="nips-2003-189-reference" href="#">nips2003-189-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>189 nips-2003-Tree-structured Approximations by Expectation Propagation</h1>
<br/><p>Source: <a title="nips-2003-189-pdf" href="http://papers.nips.cc/paper/2407-tree-structured-approximations-by-expectation-propagation.pdf">pdf</a></p><p>Author: Yuan Qi, Tom Minka</p><p>Abstract: Approximation structure plays an important role in inference on loopy graphs. As a tractable structure, tree approximations have been utilized in the variational method of Ghahramani & Jordan (1997) and the sequential projection method of Frey et al. (2000). However, belief propagation represents each factor of the graph with a product of single-node messages. In this paper, belief propagation is extended to represent factors with tree approximations, by way of the expectation propagation framework. That is, each factor sends a “message” to all pairs of nodes in a tree structure. The result is more accurate inferences and more frequent convergence than ordinary belief propagation, at a lower cost than variational trees or double-loop algorithms. 1</p><br/>
<h2>reference text</h2><p>Chow, C. K., & Liu, C. N. (1968). Approximating discrete probability distributions with dependence trees. IEEE Transactions on Information Theory, 14, 462–467. Frey, B. J., Patrascu, R., Jaakkola, T., & Moran, J. (2000). Sequentially ﬁtting inclusive trees for inference in noisy-OR networks. NIPS 13. Ghahramani, Z., & Jordan, M. I. (1997). Factorial hidden Markov models. Machine Learning, 29, 245–273. Heskes, T., & Zoeter, O. (2002). Expectation propagation for approximate inference in dynamic Bayesian networks. Proc UAI. Jensen, F. V., Lauritzen, S. L., & Olesen, K. G. (1990). Bayesian updating in causal probabilistic networks by local computations. Computational Statistics Quarterly, 5, 269–282. Kappen, H. J., & Wiegerinck, W. (2001). Novel iteration schemes for the cluster variation method. NIPS 14. Minka, T. P. (2001a). Expectation propagation for approximate Bayesian inference. UAI (pp. 362– 369). Minka, T. P. (2001b). A family of algorithms for approximate Bayesian inference. Doctoral dissertation, Massachusetts Institute of Technology. Murphy, K. (2001). The Bayes Net Toolbox for Matlab. Computing Science and Statistics, 33. Teh, Y. W., & Welling, M. (2001). The uniﬁed propagation and scaling algorithm. NIPS 14. Wainwright, M. J., Jaakkola, T., & Willsky, A. S. (2001). Tree-based reparameterization for approximate estimation on loopy graphs. NIPS 14. Wainwright, M. J., Jaakkola, T. S., & Willsky, A. S. (2002). A new class of upper bounds on the log partition function. Proc UAI. Welling, M., & Teh, Y. W. (2001). Belief optimization for binary networks: A stable alternative to loopy belief propagation. UAI. Wiegerinck, W. (2000). Variational approximations between mean ﬁeld theory and the junction tree algorithm. Proc UAI. Yedidia, J. S., Freeman, W. T., & Weiss, Y. (2000). Generalized belief propagation. NIPS 13. Yedidia, J. S., Freeman, W. T., & Weiss, Y. (2002). Constructing free energy approximations and generalized belief propagation algorithms (Technical Report). MERL Research Lab. Yuille, A. (In press, 2002). A double-loop algorithm to minimize the Bethe and Kikuchi free energies. Neural Computation.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
