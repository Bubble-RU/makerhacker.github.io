<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>152 nips-2003-Pairwise Clustering and Graphical Models</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2003" href="../home/nips2003_home.html">nips2003</a> <a title="nips-2003-152" href="../nips2003/nips-2003-Pairwise_Clustering_and_Graphical_Models.html">nips2003-152</a> <a title="nips-2003-152-reference" href="#">nips2003-152-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>152 nips-2003-Pairwise Clustering and Graphical Models</h1>
<br/><p>Source: <a title="nips-2003-152-pdf" href="http://papers.nips.cc/paper/2538-pairwise-clustering-and-graphical-models.pdf">pdf</a></p><p>Author: Noam Shental, Assaf Zomet, Tomer Hertz, Yair Weiss</p><p>Abstract: Signiﬁcant progress in clustering has been achieved by algorithms that are based on pairwise afﬁnities between the datapoints. In particular, spectral clustering methods have the advantage of being able to divide arbitrarily shaped clusters and are based on efﬁcient eigenvector calculations. However, spectral methods lack a straightforward probabilistic interpretation which makes it difﬁcult to automatically set parameters using training data. In this paper we use the previously proposed typical cut framework for pairwise clustering. We show an equivalence between calculating the typical cut and inference in an undirected graphical model. We show that for clustering problems with hundreds of datapoints exact inference may still be possible. For more complicated datasets, we show that loopy belief propagation (BP) and generalized belief propagation (GBP) can give excellent results on challenging clustering problems. We also use graphical models to derive a learning algorithm for afﬁnity matrices based on labeled data. 1</p><br/>
<h2>reference text</h2><p>[1] M. Blatt, S. Wiseman, and E. Domany. Data clustering using a mode lgranular magnet. Neural Computation, 9:1805–1842, 1997.</p>
<p>[2] Y. Gdalyahu, D. Weinshall, and M. Werman. Self organization in vision: Stochastic clustering for image segmentation, perceptual grouping, and image database organization. IEEE Trans. on Pattern Analysis and Machine Intelligence, 23(10):1053–1074, 2001.</p>
<p>[3] T. Hofmann and J. M. Buhmann. Pairwise data clustering by deterministic annealing. IEEE Transactions on Pattern Analysis and Machine Intelligence, 19(1):1–14, 1997.</p>
<p>[4] M. Meila and J. Shi. Learning segmentation by random walks. In Advances in Neural Information Processing Systems 14, 2001.</p>
<p>[5] T. Minka and Y. Qi. Tree-structured approximations by expectation propagation. In Advances in Neural Information Processing Systems 16, 2003.</p>
<p>[6] A. Ng, M. Jordan, and Y. Weiss. On spectral clustering: Analysis and an algorithm. In Advances in Neural Information Processing 14, 2001.</p>
<p>[7] N. Shental, A. Zomet, T. Hertz, and Y. Weiss. Learning and inferring image segmentations using the gbp typical cut. In 9th International Conference on Computer Vision, 2003.</p>
<p>[8] J. Shi and J. Malik. Normalized cuts and image segmentation. In Proc. IEEE Conf. Computer Vision and Pattern Recognition, pages 731–737, 1997.</p>
<p>[9] J.S. Wang and R.H Swendsen. Cluster monte carlo algorithms. Physica A, 167:565–579, 1990.</p>
<p>[10] J. Yedidia, W. Freeman, and Y. Weiss. Understanding belief propagation and its generalizations. In G. Lakemeyer and B. Nebel, editors, Exploring Artiﬁcial Intelligence in the New Millennium. Morgan Kaufmann, 2003.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
