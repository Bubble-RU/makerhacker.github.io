<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>112 nips-2003-Learning to Find Pre-Images</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2003" href="../home/nips2003_home.html">nips2003</a> <a title="nips-2003-112" href="../nips2003/nips-2003-Learning_to_Find_Pre-Images.html">nips2003-112</a> <a title="nips-2003-112-reference" href="#">nips2003-112-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>112 nips-2003-Learning to Find Pre-Images</h1>
<br/><p>Source: <a title="nips-2003-112-pdf" href="http://papers.nips.cc/paper/2417-learning-to-find-pre-images.pdf">pdf</a></p><p>Author: Jason Weston, Bernhard Schölkopf, Gökhan H. Bakir</p><p>Abstract: We consider the problem of reconstructing patterns from a feature map. Learning algorithms using kernels to operate in a reproducing kernel Hilbert space (RKHS) express their solutions in terms of input points mapped into the RKHS. We introduce a technique based on kernel principal component analysis and regression to reconstruct corresponding patterns in the input space (aka pre-images) and review its performance in several applications requiring the construction of pre-images. The introduced technique avoids difﬁcult and/or unstable numerical optimization, is easy to implement and, unlike previous methods, permits the computation of pre-images in discrete input spaces. 1</p><br/>
<h2>reference text</h2><p>[1] C. J. C. Burges. Simpliﬁed support vector decision rules. In L. Saitta, editor, Proceedings of the 13th International Conference on Machine Learning, pages 71–77, San Mateo, CA, 1996. Morgan Kaufmann.</p>
<p>[2] S. Mika, B. Sch¨ lkopf, A. J. Smola, K.-R. M¨ ller, M. Scholz, and G. R¨ tsch. Kernel PCA and o u a de-noising in feature spaces. In M. S. Kearns, S. A. Solla, and D. A. Cohn, editors, Advances in Neural Information Processing Systems 11, pages 536–542, Cambridge, MA, 1999. MIT Press.</p>
<p>[3] B. Sch¨ lkopf, A. J. Smola, and K.-R. M¨ ller. Nonlinear component analysis as a kernel eigeno u value problem. Neural Computation, 10:1299–1319, 1998.</p>
<p>[4] B. Sch¨ lkopf and A. J. Smola. Learning with Kernels. MIT Press, Cambridge, MA, 2002. o</p>
<p>[5] Jason Weston, Olivier Chapelle, Andre Elisseeff, Bernhard Sch¨ lkopf, and Vladimir Vapnik. o Kernel dependency estimation. In S. Becker, S. Thrun, and K. Obermayer, editors, Advances in Neural Information Processing Systems 15, Cambridge, MA, 2002. MIT Press.</p>
<p>[6] J.T. Kwok and I.W. Tsang. Finding the pre images in kernel principal component analysis. In NIPS’2002 Workshop on Kernel Machines, 2002.</p>
<p>[7] D. Haussler. Convolutional kernels on discrete structures. Technical Report UCSC-CRL-99-10, Computer Science Department, University of California at Santa Cruz, 1999.</p>
<p>[8] H. Lodhi, J. Shawe-Taylor, N. Cristianini, and C. Watkins. Text classiﬁcation using string kernels. Technical Report 2000-79, NeuroCOLT, 2000. Published in: T. K. Leen, T. G. Dietterich and V. Tresp (eds.), Advances in Neural Information Processing Systems 13, MIT Press, 2001, as well as in JMLR 2:419-444, 2002.</p>
<p>[9] S. Hua and Z. Sun. A novel method of protein secondary structure prediction with high segment overlap measure: Svm approach. Journal of Molecular Biology, 308:397–407, 2001.</p>
<p>[10] S. Romdhani, S. Gong, and A. Psarrou. A multiview nonlinear active shape model using kernel PCA. In Proceedings of BMVC, pages 483–492, Nottingham, UK, 1999.</p>
<p>[11] C. Leslie, E. Eskin, and W. S. Noble. The spectrum kernel: A string kernel for SVM protein classiﬁcation. Proceedings of the Paciﬁc Symposium on Biocomputing, 2002.</p>
<p>[12] Y. Altun, I. Tsochantaridis, and T. Hofmann. Hidden markov support vector machines. In 20th International Conference on Machine Learning (ICML), 2003.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
