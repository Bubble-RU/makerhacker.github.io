<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>135 nips-2003-Necessary Intransitive Likelihood-Ratio Classifiers</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2003" href="../home/nips2003_home.html">nips2003</a> <a title="nips-2003-135" href="../nips2003/nips-2003-Necessary_Intransitive_Likelihood-Ratio_Classifiers.html">nips2003-135</a> <a title="nips-2003-135-reference" href="#">nips2003-135-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>135 nips-2003-Necessary Intransitive Likelihood-Ratio Classifiers</h1>
<br/><p>Source: <a title="nips-2003-135-pdf" href="http://papers.nips.cc/paper/2521-necessary-intransitive-likelihood-ratio-classifiers.pdf">pdf</a></p><p>Author: Gang Ji, Jeff A. Bilmes</p><p>Abstract: In pattern classiﬁcation tasks, errors are introduced because of differences between the true model and the one obtained via model estimation. Using likelihood-ratio based classiﬁcation, it is possible to correct for this discrepancy by ﬁnding class-pair speciﬁc terms to adjust the likelihood ratio directly, and that can make class-pair preference relationships intransitive. In this work, we introduce new methodology that makes necessary corrections to the likelihood ratio, speciﬁcally those that are necessary to achieve perfect classiﬁcation (but not perfect likelihood-ratio correction which can be overkill). The new corrections, while weaker than previously reported such adjustments, are analytically challenging since they involve discontinuous functions, therefore requiring several approximations. We test a number of these new schemes on an isolatedword speech recognition task as well as on the UCI machine learning data sets. Results show that by using the bias terms calculated in this new way, classiﬁcation accuracy can substantially improve over both the baseline and over our previous results. 1</p><br/>
<h2>reference text</h2><p>[1] Jeff Bilmes. Burried Markov models for speech recognition. In IEEE Intl. Conf. on Acoustics, Speech, and Signal Processing, March 1999.</p>
<p>[2] Jeff Bilmes, Gang Ji, and M. Meil˘ . Intransitive likeilhood-ratio classiﬁers. In Neural Informaa tion Processing Systems: Natural and Synthetic, December 2001.</p>
<p>[3] T. M. Cover and J. A. Thomas. Elements of Information Theory. John Wiley and Sons, Inc., 1991.</p>
<p>[4] Richard O. Duda, Peter E. Hart, and David G. Stork. Pattern Classiﬁcation. John Wiley and Sons, second edition, 2001.</p>
<p>[5] Nir Friedman, Dan Geiger, and Moises Goldszmidt. Bayesian network classiﬁers. Machine Learning, 29(2-3):131–163, 1997.</p>
<p>[6] D. S. Jones. Generalised Functions. McCraw-Hill Publishing Company Limited, 1966.</p>
<p>[7] J. Kevorkian. Partial Differential Equations: Analytical Solution Techniques. New York: Springer, 2000.</p>
<p>[8] R. Duncan Luce and Howard Raiffa. Games and Decisions: Introduction and Critical Survey. Dover, 1957.</p>
<p>[9] P. M. Murphy and D. W. Aha. UCI Repository of Machine Learning Database, 1995.</p>
<p>[10] J. Pitrelli, C. Fong, S. H. Wong, J. R. Spitz, and H. C. Lueng. PhoneBook: a phonetically-rich isolated-word telephone-speech database. In IEEE Intl. Conf. on Acoustics, Speech, and Signal Processing, 1995.</p>
<p>[11] W. H. Press, B. P. Flannery, S. A. Teukolsky, and W. T. Vetterling. Numerical Recipes in C: The Art of Scientiﬁc Computing. Cambridge University Press, Cambridge, England, second edition, 1992.</p>
<p>[12] M. M. Rao. Measure Theory and Integration. John Wiley and Sons, 1987.</p>
<p>[13] P. D. Strafﬁn. Game Theory and Strategy. The Mathematical Association of America, 1993.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
