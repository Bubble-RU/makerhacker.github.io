<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>110 nips-2003-Learning a World Model and Planning with a Self-Organizing, Dynamic Neural System</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2003" href="../home/nips2003_home.html">nips2003</a> <a title="nips-2003-110" href="../nips2003/nips-2003-Learning_a_World_Model_and_Planning_with_a_Self-Organizing%2C_Dynamic_Neural_System.html">nips2003-110</a> <a title="nips-2003-110-reference" href="#">nips2003-110-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>110 nips-2003-Learning a World Model and Planning with a Self-Organizing, Dynamic Neural System</h1>
<br/><p>Source: <a title="nips-2003-110-pdf" href="http://papers.nips.cc/paper/2452-learning-a-world-model-and-planning-with-a-self-organizing-dynamic-neural-system.pdf">pdf</a></p><p>Author: Marc Toussaint</p><p>Abstract: We present a connectionist architecture that can learn a model of the relations between perceptions and actions and use this model for behavior planning. State representations are learned with a growing selforganizing layer which is directly coupled to a perception and a motor layer. Knowledge about possible state transitions is encoded in the lateral connectivity. Motor signals modulate this lateral connectivity and a dynamic ﬁeld on the layer organizes a planning process. All mechanisms are local and adaptation is based on Hebbian ideas. The model is continuous in the action, perception, and time domain.</p><br/>
<h2>reference text</h2><p>[1] G. Hesslow. Conscious thought as simulation of behaviour and perception. Trends in Cognitive Sciences, 6:242–247, 2002.</p>
<p>[2] Rick Grush. The emulation theory of representation: motor control, imagery, and perception. Behavioral and Brain Sciences, 2003. To appear.</p>
<p>[3] M.D. Majors and R.J. Richards. Comparing model-free and model-based reinforcement learning. Cambridge University Engineering Department Technical Report CUED/F- INENG/TR.286, 1997.</p>
<p>[4] D.E. Rumelhart, P. Smolensky, J.L. McClelland, and G. E. Hinton. Schemata and sequential thought processes in PDP models. In D.E. Rumelhart and J. L. McClelland, editors, Parallel Distributed Processing, volume 2, pages 7–57. MIT Press, Cambridge, 1986.</p>
<p>[5] M. Jordan and D. Rumelhart. Forward models: Supervised learning with a distal teacher. Cognitive Science, 16:307–354, 1992.</p>
<p>[6] B. Kr¨ se and M. Eecen. A self-organizing representation of sensor space for mobile robot o navigation. In Proc. of Int. Conf. on Intelligent Robots and Systems (IROS 1994), 1994.</p>
<p>[7] U. Zimmer. Robust world-modelling and navigation in a real world. NeuroComputing, 13:247– 260, 1996.</p>
<p>[8] S. Amari. Dynamics of patterns formation in lateral-inhibition type neural ﬁelds. Biological Cybernetics, 27:77–87, 1977.</p>
<p>[9] W.A. Phillips and W. Singer. In the search of common foundations for cortical computation. Behavioral and Brain Sciences, 20:657–722, 1997.</p>
<p>[10] L.F. Abbott. Realistic synaptic inputs for network models. Network: Computation in Neural Systems, 2:245–258, 1991.</p>
<p>[11] D.P. Bertsekas and J.N. Tsitsiklis. Neuro-Dynamic Programming. Athena Scientiﬁc, 1996.</p>
<p>[12] R.S. Sutton and A.G. Barto. Reinforcement Learning. MIT Press, Cambridge, 1998.</p>
<p>[13] C. von der Malsburg. Self-organization of orientation-sensitive cells in the striate cortex. Kybernetik, 15:85–100, 1973.</p>
<p>[14] T. Kohonen. Self-organizing maps. Springer, Berlin, 1995.</p>
<p>[15] G.A. Carpenter, S. Grossberg, N. Markuzon, J.H. Reynolds, and D.B. Rosen. Fuzzy ARTMAP: A neural network architecture for incremental supervised learning of analog multidimensional maps. IEEE Transactions on Neural Networks, 5:698–713, 1992.</p>
<p>[16] B. Fritzke. A growing neural gas network learns topologies. In G. Tesauro, D.S. Touretzky, and T.K. Leen, editors, Advances in Neural Information Processing Systems 7, pages 625–632. MIT Press, Cambridge MA, 1995.</p>
<p>[17] C.M. Bishop, G.E. Hinton, and I.G.D. Strachan. GTM through time. In Proc. of IEEE Fifth Int. Conf. on Artiﬁcial Neural Networks. Cambridge, 1997.</p>
<p>[18] J.C. Wiemer. The time-organized map algorithm: Extending the self-organizing map to spatiotemporal signals. Neural Computation, 15:1143–1171, 2003.</p>
<p>[19] P. Dayan and L.F. Abbott. Theoretical Neuroscience. MIT Press, 2001.</p>
<p>[20] J. Schmidhuber. Adaptive conﬁdence and adaptive curiosity. Technical Report FKI-149-91, Technical University Munich, 1991.</p>
<p>[21] N. Meuleau and P. Bourgine. Exploration of multi-state environments: Local measures and back-propagation of uncertainty. Machine Learning, 35:117–154, 1998.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
