<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>77 nips-2003-Gaussian Process Latent Variable Models for Visualisation of High Dimensional Data</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2003" href="../home/nips2003_home.html">nips2003</a> <a title="nips-2003-77" href="../nips2003/nips-2003-Gaussian_Process_Latent_Variable_Models_for_Visualisation_of_High_Dimensional_Data.html">nips2003-77</a> <a title="nips-2003-77-reference" href="#">nips2003-77-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>77 nips-2003-Gaussian Process Latent Variable Models for Visualisation of High Dimensional Data</h1>
<br/><p>Source: <a title="nips-2003-77-pdf" href="http://papers.nips.cc/paper/2540-gaussian-process-latent-variable-models-for-visualisation-of-high-dimensional-data.pdf">pdf</a></p><p>Author: Neil D. Lawrence</p><p>Abstract: In this paper we introduce a new underlying probabilistic model for principal component analysis (PCA). Our formulation interprets PCA as a particular Gaussian process prior on a mapping from a latent space to the observed data-space. We show that if the prior’s covariance function constrains the mappings to be linear the model is equivalent to PCA, we then extend the model by considering less restrictive covariance functions which allow non-linear mappings. This more general Gaussian process latent variable model (GPLVM) is then evaluated as an approach to the visualisation of high dimensional data for three different data-sets. Additionally our non-linear algorithm can be further kernelised leading to ‘twin kernel PCA’ in which a mapping between feature spaces occurs.</p><br/>
<h2>reference text</h2><p>[1] S. Becker, S. Thrun, and K. Obermayer, editors. Advances in Neural Information Processing Systems, volume 15, Cambridge, MA, 2003. MIT Press.</p>
<p>[2] C. M. Bishop and G. D. James. Analysis of multiphase ﬂows using dual-energy gamma densitometry and neural networks. Nuclear Instruments and Methods in Physics Research, A327:580– 593, 1993.</p>
<p>[3] C. M. Bishop, M. Svensén, and C. K. I. Williams. GTM: a principled alternative to the SelfOrganizing Map. In Advances in Neural Information Processing Systems, volume 9, pages 354–360. MIT Press, 1997.</p>
<p>[4] C. M. Bishop, M. Svensén, and C. K. I. Williams. GTM: the Generative Topographic Mapping. Neural Computation, 10(1):215–234, 1998.</p>
<p>[5] G. Hinton and S. Roweis. Stochastic neighbor embedding. In Becker et al. [1], pages 857–864.</p>
<p>[6] N. D. Lawrence, M. Seeger, and R. Herbrich. Fast sparse Gaussian process methods: The informative vector machine. In Becker et al. [1], pages 625–632.</p>
<p>[7] I. T. Nabney. Netlab: Algorithms for Pattern in Pattern Recognition. Springer, Berlin, 2001. http://www.ncrg.aston.ac.uk/netlab/.  Recognition. Advances Code available from</p>
<p>[8] S. Roweis, L. K. Saul, and G. Hinton. Global coordination of local linear models. In T. G. Dietterich, S. Becker, and Z. Ghahramani, editors, Advances in Neural Information Processing Systems, volume 14, pages 889–896, Cambridge, MA, 2002. MIT Press.</p>
<p>[9] B. Schölkopf, A. J. Smola, and K.-R. Müller. Kernel principal component analysis. In Proceedings 1997 International Conference on Artiﬁcial Neural Networks, ICANN’97, page 583, Lausanne, Switzerland, 1997.</p>
<p>[10] M. E. Tipping. Sparse kernel principal component analysis. In T. K. Leen, T. G. Dietterich, and V. Tresp, editors, Advances in Neural Information Processing Systems, volume 13, pages 633–639, Cambridge, MA, 2001. MIT Press.</p>
<p>[11] M. E. Tipping and C. M. Bishop. Probabilistic principal component analysis. Journal of the Royal Statistical Society, B, 6(3):611–622, 1999.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
