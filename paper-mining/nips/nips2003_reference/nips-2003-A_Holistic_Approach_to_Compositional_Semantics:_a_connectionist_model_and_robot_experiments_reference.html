<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>8 nips-2003-A Holistic Approach to Compositional Semantics: a connectionist model and robot experiments</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2003" href="../home/nips2003_home.html">nips2003</a> <a title="nips-2003-8" href="../nips2003/nips-2003-A_Holistic_Approach_to_Compositional_Semantics%3A_a_connectionist_model_and_robot_experiments.html">nips2003-8</a> <a title="nips-2003-8-reference" href="#">nips2003-8-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>8 nips-2003-A Holistic Approach to Compositional Semantics: a connectionist model and robot experiments</h1>
<br/><p>Source: <a title="nips-2003-8-pdf" href="http://papers.nips.cc/paper/2383-a-holistic-approach-to-compositional-semantics-a-connectionist-model-and-robot-experiments.pdf">pdf</a></p><p>Author: Yuuya Sugita, Jun Tani</p><p>Abstract: We present a novel connectionist model for acquiring the semantics of a simple language through the behavioral experiences of a real robot. We focus on the “compositionality” of semantics, a fundamental characteristic of human language, which is the ability to understand the meaning of a sentence as a combination of the meanings of words. We also pay much attention to the “embodiment” of a robot, which means that the robot should acquire semantics which matches its body, or sensory-motor system. The essential claim is that an embodied compositional semantic representation can be self-organized from generalized correspondences between sentences and behavioral patterns. This claim is examined and conﬁrmed through simple experiments in which a robot generates corresponding behaviors from unlearned sentences by analogy with the correspondences between learned sentences and behaviors. 1</p><br/>
<h2>reference text</h2><p>[1] J. L. Elman. Finding structure in time. Cognitive Science, 14:179–211, 1990.</p>
<p>[2] G. Evans. Semantic Theory and Tacit Knowledge. In S. Holzman and C. Leich, editors, Wittgenstein: To Follow a Rule. London: Routledge and Kegan Paul, 1981.</p>
<p>[3] J. Fodor. Why Compositionality Won’t Go Away: Reﬂections on Horwich’s ’Deﬂationary’ Theory. Technical Report 46, Rutgers University, 1999.</p>
<p>[4] R. F. Hadley. Systematicity revisited: reply to Christiansen and Chater and Niklasson and van Gelder. Mind and Language, 9:431–444, 1994.</p>
<p>[5] S. Harnad. The symbol grounding problem. Physica D, 42:335–346, 1990.</p>
<p>[6] M. Ito and J. Tani. Generalization and Diversity in Dynamic Pattern Learning and Generation by Distributed Representation Architecture . Technical Report 3, Lab. for BDC, Brain Science Institute, RIKEN, 2003.</p>
<p>[7] N. Iwahashi. Language acquisition by robots – Towards New Paradigm of Language Processing –. Journal of Japanese Society for Artiﬁcial Intelligence, 18(1):49–58, 2003.</p>
<p>[8] M.I. Jordan and D.E. Rumelhart. Forward models: supervised learning with a distal teacher. Cognitive Science, 16:307–354, 1992.</p>
<p>[9] R. Miikkulainen. Subsymbolic Natural Language Processing: An Integrated Model of Script s, Lexicon, and Memory. MIT Press, 1993.</p>
<p>[10] D. K. Roy. Learning visually grounded words and syntax for a scene description task. Computer Speech and Language, 16, 2002.</p>
<p>[11] D. E. Rumelhart, G. E. Hinton, and R. J. Williams. Learning internal representations by error propagation. In D. E. Rumelhart and J. L. Mclelland, editors, Parallel Distributed Processing. Cambridge, MA: MIT Press, 1986.</p>
<p>[12] J. M. Siskind. Grounding the Lexical Semantics of Verbs in Visual Perception using Force Dynamics and Event Logic. Artiﬁcial Intelligence Research, 15:31–90, 2001.</p>
<p>[13] L. Steels. The Emergence of Grammar in Communicating Autonomous Robotic Agents. In W. Horn, editor, Proceedings of European Conference of Artiﬁcial Intelligence, pages 764–769. IOS Press, 2000.</p>
<p>[14] J. Tani. Model-Based Learning for Mobile Robot Navigation from the Dynamical Systems Perspective. IEEE Trans. on SMC (B), 26(3):421–436, 1996.</p>
<p>[15] J. Tani. Learning to generate articulated behavior through the bottom-up and the top-down interaction process. Neural Networks, 16:11–23, 2003.</p>
<p>[16] T. Winograd. Understanding natural language. Cognitive Psychology, 3(1):1–191, 1972.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
