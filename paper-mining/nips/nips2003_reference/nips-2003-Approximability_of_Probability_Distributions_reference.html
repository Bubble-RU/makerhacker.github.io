<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>30 nips-2003-Approximability of Probability Distributions</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2003" href="../home/nips2003_home.html">nips2003</a> <a title="nips-2003-30" href="../nips2003/nips-2003-Approximability_of_Probability_Distributions.html">nips2003-30</a> <a title="nips-2003-30-reference" href="#">nips2003-30-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>30 nips-2003-Approximability of Probability Distributions</h1>
<br/><p>Source: <a title="nips-2003-30-pdf" href="http://papers.nips.cc/paper/2498-approximability-of-probability-distributions.pdf">pdf</a></p><p>Author: Alina Beygelzimer, Irina Rish</p><p>Abstract: We consider the question of how well a given distribution can be approximated with probabilistic graphical models. We introduce a new parameter, effective treewidth, that captures the degree of approximability as a tradeoff between the accuracy and the complexity of approximation. We present a simple approach to analyzing achievable tradeoffs that exploits the threshold behavior of monotone graph properties, and provide experimental results that support the approach. 1</p><br/>
<h2>reference text</h2><p>[1] A. Barak and P. Erd˝ s. On the maximal number of strongly independent vertices in a random o acyclic directed graph. SIAM J. Algebraic and Discrete Methods, 5:508–514, 1984.</p>
<p>[2] A. Beygelzimer and I. Rish. Inference complexity as a model-selection criterion for learning bayesian networks. In Proceedings of the Eighth International Conference on Principles of Knowledge Representation and Reasoning (KR2002), Toulouse, France, 2002.</p>
<p>[3] B. Bollob´ s and G. Brightwell. The structure of random graph orders. SIAM J. Discrete Matha ematics, 10(2):318–335, 1997.</p>
<p>[4] C. Chow and C. Liu. Approximating discrete probability distributions with dependence trees. IEEE Trans. on Inf. Theory, 14:462–467, 1968.</p>
<p>[5] T. Cover and J. Thomas. Elements of information theory. John Wiley & Sons Inc., New York, 1991. A Wiley-Interscience Publication.</p>
<p>[6] R. Dechter. Bucket elimination: A unifying framework for probabilistic reasoning. In M. I. Jordan (Ed.), Learning in Graphical Models, Kluwer Academic Press, 1998.</p>
<p>[7] P. Erd˝ s and A. R´ nyi. On the evolution of random graphs. Bull. Inst. Internat. Statist., 38:343– o e 347, 1961.</p>
<p>[8] E. Friedgut and G. Kalai. Every monotone graph property has a sharp threshold. Proceedings of the American Mathematical Society, 124(10):2993–3002, 1996.</p>
<p>[9] K. H¨ ffgen. Learning and robust learning of product distributions. In Proceedings of the 6th o Annual Workshop on Computational Learning Theory, pages 77–83, 1993.</p>
<p>[10] F. V. Jensen and F. Jensen. Optimal junction trees. In Proc. Tenth Conference on Uncertainty and AI (UAI), 1994.</p>
<p>[11] J. Naor and M. Naor. Small-bias probability spaces: Efﬁcient constructions and applications. In Proc. of the 22nd ACM Symposium on Theory of Computing (STOC), pages 213–223, 1990.</p>
<p>[12] J. Pearl. Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Morgan Kaufmann Publishers, 1988.</p>
<p>[13] N. Srebro. Maximum likelihood bounded Tree-Width markov networks. In Proceedings of the 17th Conference on Uncertainty in AI (UAI), pages 504–511, 2001. 6 Note, however, that it does not imply that the empirical distribution itself decomposes on a treewidth-4 model. The simplest example of this is when the true distribution is uniform.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
