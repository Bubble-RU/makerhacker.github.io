<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>159 nips-2002-Optimality of Reinforcement Learning Algorithms with Linear Function Approximation</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-159" href="#">nips2002-159</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>159 nips-2002-Optimality of Reinforcement Learning Algorithms with Linear Function Approximation</h1>
<br/><p>Source: <a title="nips-2002-159-pdf" href="http://papers.nips.cc/paper/2322-optimality-of-reinforcement-learning-algorithms-with-linear-function-approximation.pdf">pdf</a></p><p>Author: Ralf Schoknecht</p><p>Abstract: There are several reinforcement learning algorithms that yield approximate solutions for the problem of policy evaluation when the value function is represented with a linear function approximator. In this paper we show that each of the solutions is optimal with respect to a specific objective function. Moreover, we characterise the different solutions as images of the optimal exact value function under different projection operations. The results presented here will be useful for comparing the algorithms in terms of the error they achieve relative to the error of the optimal approximate solution. 1</p><p>Reference: <a title="nips-2002-159-reference" href="../nips2002_reference/nips-2002-Optimality_of_Reinforcement_Learning_Algorithms_with_Linear_Function_Approximation_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('td', 0.549), ('lstd', 0.257), ('ij', 0.231), ('policy', 0.225), ('cp', 0.189), ('rl', 0.182), ('bellm', 0.172), ('tdid', 0.148), ('reinforc', 0.136), ('lid', 0.128), ('eigenvalu', 0.123), ('zi', 0.12), ('solv', 0.12), ('si', 0.115), ('fix', 0.113), ('project', 0.107), ('rf', 0.103), ('iidrg', 0.098), ('resid', 0.097), ('reward', 0.097)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="159-tfidf-1" href="./nips-2002-Optimality_of_Reinforcement_Learning_Algorithms_with_Linear_Function_Approximation.html">159 nips-2002-Optimality of Reinforcement Learning Algorithms with Linear Function Approximation</a></p>
<p>2 0.68388116 <a title="159-tfidf-2" href="./nips-2002-Convergent_Combinations_of_Reinforcement_Learning_with_Linear_Function_Approximation.html">61 nips-2002-Convergent Combinations of Reinforcement Learning with Linear Function Approximation</a></p>
<p>3 0.30850819 <a title="159-tfidf-3" href="./nips-2002-Timing_and_Partial_Observability_in_the_Dopamine_System.html">199 nips-2002-Timing and Partial Observability in the Dopamine System</a></p>
<p>4 0.27294016 <a title="159-tfidf-4" href="./nips-2002-A_Convergent_Form_of_Approximate_Policy_Iteration.html">3 nips-2002-A Convergent Form of Approximate Policy Iteration</a></p>
<p>5 0.15841928 <a title="159-tfidf-5" href="./nips-2002-Nonparametric_Representation_of_Policies_and_Value_Functions%3A_A_Trajectory-Based_Approach.html">155 nips-2002-Nonparametric Representation of Policies and Value Functions: A Trajectory-Based Approach</a></p>
<p>6 0.14387119 <a title="159-tfidf-6" href="./nips-2002-The_Stability_of_Kernel_Principal_Components_Analysis_and_its_Relation_to_the_Process_Eigenspectrum.html">197 nips-2002-The Stability of Kernel Principal Components Analysis and its Relation to the Process Eigenspectrum</a></p>
<p>7 0.13914819 <a title="159-tfidf-7" href="./nips-2002-A_Note_on_the_Representational_Incompatibility_of_Function_Approximation_and_Factored_Dynamics.html">13 nips-2002-A Note on the Representational Incompatibility of Function Approximation and Factored Dynamics</a></p>
<p>8 0.13554662 <a title="159-tfidf-8" href="./nips-2002-Approximate_Linear_Programming_for_Average-Cost_Dynamic_Programming.html">33 nips-2002-Approximate Linear Programming for Average-Cost Dynamic Programming</a></p>
<p>9 0.13453142 <a title="159-tfidf-9" href="./nips-2002-Multiplicative_Updates_for_Nonnegative_Quadratic_Programming_in_Support_Vector_Machines.html">151 nips-2002-Multiplicative Updates for Nonnegative Quadratic Programming in Support Vector Machines</a></p>
<p>10 0.12200288 <a title="159-tfidf-10" href="./nips-2002-Exponential_Family_PCA_for_Belief_Compression_in_POMDPs.html">82 nips-2002-Exponential Family PCA for Belief Compression in POMDPs</a></p>
<p>11 0.121622 <a title="159-tfidf-11" href="./nips-2002-Learning_to_Take_Concurrent_Actions.html">134 nips-2002-Learning to Take Concurrent Actions</a></p>
<p>12 0.11848486 <a title="159-tfidf-12" href="./nips-2002-Adaptive_Caching_by_Refetching.html">20 nips-2002-Adaptive Caching by Refetching</a></p>
<p>13 0.11001869 <a title="159-tfidf-13" href="./nips-2002-Learning_Attractor_Landscapes_for_Learning_Motor_Primitives.html">123 nips-2002-Learning Attractor Landscapes for Learning Motor Primitives</a></p>
<p>14 0.10369691 <a title="159-tfidf-14" href="./nips-2002-Informed_Projections.html">115 nips-2002-Informed Projections</a></p>
<p>15 0.10334633 <a title="159-tfidf-15" href="./nips-2002-Ranking_with_Large_Margin_Principle%3A_Two_Approaches.html">165 nips-2002-Ranking with Large Margin Principle: Two Approaches</a></p>
<p>16 0.093634203 <a title="159-tfidf-16" href="./nips-2002-Feature_Selection_and_Classification_on_Matrix_Data%3A_From_Large_Margins_to_Small_Covering_Numbers.html">88 nips-2002-Feature Selection and Classification on Matrix Data: From Large Margins to Small Covering Numbers</a></p>
<p>17 0.088872671 <a title="159-tfidf-17" href="./nips-2002-Learning_in_Zero-Sum_Team_Markov_Games_Using_Factored_Value_Functions.html">130 nips-2002-Learning in Zero-Sum Team Markov Games Using Factored Value Functions</a></p>
<p>18 0.084312715 <a title="159-tfidf-18" href="./nips-2002-Value-Directed_Compression_of_POMDPs.html">205 nips-2002-Value-Directed Compression of POMDPs</a></p>
<p>19 0.079469159 <a title="159-tfidf-19" href="./nips-2002-Concentration_Inequalities_for_the_Missing_Mass_and_for_Histogram_Rule_Error.html">56 nips-2002-Concentration Inequalities for the Missing Mass and for Histogram Rule Error</a></p>
<p>20 0.07148201 <a title="159-tfidf-20" href="./nips-2002-Effective_Dimension_and_Generalization_of_Kernel_Learning.html">77 nips-2002-Effective Dimension and Generalization of Kernel Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2002_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.206), (1, 0.088), (2, -0.301), (3, 0.259), (4, 0.042), (5, 0.116), (6, 0.051), (7, 0.063), (8, -0.059), (9, -0.186), (10, -0.102), (11, 0.316), (12, -0.107), (13, -0.324), (14, -0.188), (15, -0.245), (16, -0.218), (17, -0.053), (18, 0.237), (19, 0.167), (20, -0.092), (21, -0.12), (22, -0.004), (23, -0.073), (24, 0.048), (25, 0.042), (26, -0.033), (27, -0.005), (28, 0.005), (29, 0.001), (30, -0.085), (31, 0.033), (32, -0.047), (33, -0.027), (34, -0.118), (35, -0.035), (36, 0.026), (37, 0.065), (38, -0.047), (39, -0.064), (40, -0.042), (41, -0.013), (42, 0.021), (43, -0.029), (44, 0.007), (45, -0.024), (46, 0.026), (47, -0.001), (48, -0.04), (49, -0.001)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.95294189 <a title="159-lsi-1" href="./nips-2002-Convergent_Combinations_of_Reinforcement_Learning_with_Linear_Function_Approximation.html">61 nips-2002-Convergent Combinations of Reinforcement Learning with Linear Function Approximation</a></p>
<p>same-paper 2 0.9341293 <a title="159-lsi-2" href="./nips-2002-Optimality_of_Reinforcement_Learning_Algorithms_with_Linear_Function_Approximation.html">159 nips-2002-Optimality of Reinforcement Learning Algorithms with Linear Function Approximation</a></p>
<p>3 0.58086222 <a title="159-lsi-3" href="./nips-2002-Timing_and_Partial_Observability_in_the_Dopamine_System.html">199 nips-2002-Timing and Partial Observability in the Dopamine System</a></p>
<p>4 0.51763028 <a title="159-lsi-4" href="./nips-2002-A_Convergent_Form_of_Approximate_Policy_Iteration.html">3 nips-2002-A Convergent Form of Approximate Policy Iteration</a></p>
<p>5 0.41797569 <a title="159-lsi-5" href="./nips-2002-Approximate_Linear_Programming_for_Average-Cost_Dynamic_Programming.html">33 nips-2002-Approximate Linear Programming for Average-Cost Dynamic Programming</a></p>
<p>6 0.3576172 <a title="159-lsi-6" href="./nips-2002-The_Stability_of_Kernel_Principal_Components_Analysis_and_its_Relation_to_the_Process_Eigenspectrum.html">197 nips-2002-The Stability of Kernel Principal Components Analysis and its Relation to the Process Eigenspectrum</a></p>
<p>7 0.34010875 <a title="159-lsi-7" href="./nips-2002-A_Note_on_the_Representational_Incompatibility_of_Function_Approximation_and_Factored_Dynamics.html">13 nips-2002-A Note on the Representational Incompatibility of Function Approximation and Factored Dynamics</a></p>
<p>8 0.33007252 <a title="159-lsi-8" href="./nips-2002-Scaling_of_Probability-Based_Optimization_Algorithms.html">179 nips-2002-Scaling of Probability-Based Optimization Algorithms</a></p>
<p>9 0.32193694 <a title="159-lsi-9" href="./nips-2002-Multiplicative_Updates_for_Nonnegative_Quadratic_Programming_in_Support_Vector_Machines.html">151 nips-2002-Multiplicative Updates for Nonnegative Quadratic Programming in Support Vector Machines</a></p>
<p>10 0.31585222 <a title="159-lsi-10" href="./nips-2002-Learning_in_Zero-Sum_Team_Markov_Games_Using_Factored_Value_Functions.html">130 nips-2002-Learning in Zero-Sum Team Markov Games Using Factored Value Functions</a></p>
<p>11 0.29012573 <a title="159-lsi-11" href="./nips-2002-Adaptive_Caching_by_Refetching.html">20 nips-2002-Adaptive Caching by Refetching</a></p>
<p>12 0.26153535 <a title="159-lsi-12" href="./nips-2002-Learning_to_Take_Concurrent_Actions.html">134 nips-2002-Learning to Take Concurrent Actions</a></p>
<p>13 0.25801182 <a title="159-lsi-13" href="./nips-2002-Informed_Projections.html">115 nips-2002-Informed Projections</a></p>
<p>14 0.25444087 <a title="159-lsi-14" href="./nips-2002-Learning_a_Forward_Model_of_a_Reflex.html">128 nips-2002-Learning a Forward Model of a Reflex</a></p>
<p>15 0.25422779 <a title="159-lsi-15" href="./nips-2002-Value-Directed_Compression_of_POMDPs.html">205 nips-2002-Value-Directed Compression of POMDPs</a></p>
<p>16 0.25191635 <a title="159-lsi-16" href="./nips-2002-Nonparametric_Representation_of_Policies_and_Value_Functions%3A_A_Trajectory-Based_Approach.html">155 nips-2002-Nonparametric Representation of Policies and Value Functions: A Trajectory-Based Approach</a></p>
<p>17 0.25097296 <a title="159-lsi-17" href="./nips-2002-Independent_Components_Analysis_through_Product_Density_Estimation.html">111 nips-2002-Independent Components Analysis through Product Density Estimation</a></p>
<p>18 0.23097537 <a title="159-lsi-18" href="./nips-2002-Incremental_Gaussian_Processes.html">110 nips-2002-Incremental Gaussian Processes</a></p>
<p>19 0.23043203 <a title="159-lsi-19" href="./nips-2002-Learning_Attractor_Landscapes_for_Learning_Motor_Primitives.html">123 nips-2002-Learning Attractor Landscapes for Learning Motor Primitives</a></p>
<p>20 0.22884762 <a title="159-lsi-20" href="./nips-2002-Adaptive_Nonlinear_System_Identification_with_Echo_State_Networks.html">22 nips-2002-Adaptive Nonlinear System Identification with Echo State Networks</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2002_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(1, 0.015), (5, 0.275), (9, 0.023), (22, 0.037), (26, 0.056), (34, 0.044), (39, 0.052), (47, 0.088), (48, 0.136), (58, 0.014), (66, 0.06), (72, 0.019), (93, 0.091)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.83114052 <a title="159-lda-1" href="./nips-2002-Replay%2C_Repair_and_Consolidation.html">176 nips-2002-Replay, Repair and Consolidation</a></p>
<p>2 0.8071422 <a title="159-lda-2" href="./nips-2002-Fast_Exact_Inference_with_a_Factored_Model_for_Natural_Language_Parsing.html">84 nips-2002-Fast Exact Inference with a Factored Model for Natural Language Parsing</a></p>
<p>same-paper 3 0.73537904 <a title="159-lda-3" href="./nips-2002-Optimality_of_Reinforcement_Learning_Algorithms_with_Linear_Function_Approximation.html">159 nips-2002-Optimality of Reinforcement Learning Algorithms with Linear Function Approximation</a></p>
<p>4 0.70945245 <a title="159-lda-4" href="./nips-2002-Discriminative_Densities_from_Maximum_Contrast_Estimation.html">68 nips-2002-Discriminative Densities from Maximum Contrast Estimation</a></p>
<p>5 0.68447345 <a title="159-lda-5" href="./nips-2002-Convergent_Combinations_of_Reinforcement_Learning_with_Linear_Function_Approximation.html">61 nips-2002-Convergent Combinations of Reinforcement Learning with Linear Function Approximation</a></p>
<p>6 0.59371942 <a title="159-lda-6" href="./nips-2002-Approximate_Linear_Programming_for_Average-Cost_Dynamic_Programming.html">33 nips-2002-Approximate Linear Programming for Average-Cost Dynamic Programming</a></p>
<p>7 0.59294009 <a title="159-lda-7" href="./nips-2002-A_Model_for_Real-Time_Computation_in_Generic_Neural_Microcircuits.html">11 nips-2002-A Model for Real-Time Computation in Generic Neural Microcircuits</a></p>
<p>8 0.59165817 <a title="159-lda-8" href="./nips-2002-Kernel_Dependency_Estimation.html">119 nips-2002-Kernel Dependency Estimation</a></p>
<p>9 0.59104192 <a title="159-lda-9" href="./nips-2002-Exponential_Family_PCA_for_Belief_Compression_in_POMDPs.html">82 nips-2002-Exponential Family PCA for Belief Compression in POMDPs</a></p>
<p>10 0.59096867 <a title="159-lda-10" href="./nips-2002-Hyperkernels.html">106 nips-2002-Hyperkernels</a></p>
<p>11 0.58894736 <a title="159-lda-11" href="./nips-2002-Real-Time_Particle_Filters.html">169 nips-2002-Real-Time Particle Filters</a></p>
<p>12 0.58891314 <a title="159-lda-12" href="./nips-2002-Timing_and_Partial_Observability_in_the_Dopamine_System.html">199 nips-2002-Timing and Partial Observability in the Dopamine System</a></p>
<p>13 0.58888322 <a title="159-lda-13" href="./nips-2002-Adapting_Codes_and_Embeddings_for_Polychotomies.html">19 nips-2002-Adapting Codes and Embeddings for Polychotomies</a></p>
<p>14 0.58885819 <a title="159-lda-14" href="./nips-2002-Scaling_of_Probability-Based_Optimization_Algorithms.html">179 nips-2002-Scaling of Probability-Based Optimization Algorithms</a></p>
<p>15 0.58832443 <a title="159-lda-15" href="./nips-2002-Multiplicative_Updates_for_Nonnegative_Quadratic_Programming_in_Support_Vector_Machines.html">151 nips-2002-Multiplicative Updates for Nonnegative Quadratic Programming in Support Vector Machines</a></p>
<p>16 0.58788145 <a title="159-lda-16" href="./nips-2002-Learning_Semantic_Similarity.html">125 nips-2002-Learning Semantic Similarity</a></p>
<p>17 0.58754313 <a title="159-lda-17" href="./nips-2002-Gaussian_Process_Priors_with_Uncertain_Inputs_Application_to_Multiple-Step_Ahead_Time_Series_Forecasting.html">95 nips-2002-Gaussian Process Priors with Uncertain Inputs Application to Multiple-Step Ahead Time Series Forecasting</a></p>
<p>18 0.58743465 <a title="159-lda-18" href="./nips-2002-A_Convergent_Form_of_Approximate_Policy_Iteration.html">3 nips-2002-A Convergent Form of Approximate Policy Iteration</a></p>
<p>19 0.58616263 <a title="159-lda-19" href="./nips-2002-Generalized%C3%82%CB%9B_Linear%C3%82%CB%9B_Models.html">96 nips-2002-GeneralizedÂ˛ LinearÂ˛ Models</a></p>
<p>20 0.58539009 <a title="159-lda-20" href="./nips-2002-Nash_Propagation_for_Loopy_Graphical_Games.html">152 nips-2002-Nash Propagation for Loopy Graphical Games</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
