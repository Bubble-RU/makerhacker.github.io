<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>189 nips-2002-Stable Fixed Points of Loopy Belief Propagation Are Local Minima of the Bethe Free Energy</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-189" href="#">nips2002-189</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>189 nips-2002-Stable Fixed Points of Loopy Belief Propagation Are Local Minima of the Bethe Free Energy</h1>
<br/><p>Source: <a title="nips-2002-189-pdf" href="http://papers.nips.cc/paper/2220-stable-fixed-points-of-loopy-belief-propagation-are-local-minima-of-the-bethe-free-energy.pdf">pdf</a></p><p>Author: Tom Heskes</p><p>Abstract: We extend recent work on the connection between loopy belief propagation and the Bethe free energy. Constrained minimization of the Bethe free energy can be turned into an unconstrained saddle-point problem. Both converging double-loop algorithms and standard loopy belief propagation can be interpreted as attempts to solve this saddle-point problem. Stability analysis then leads us to conclude that stable ﬁxed points of loopy belief propagation must be (local) minima of the Bethe free energy. Perhaps surprisingly, the converse need not be the case: minima can be unstable ﬁxed points. We illustrate this with an example and discuss implications. 1</p><p>Reference: <a title="nips-2002-189-reference" href="../nips2002_reference/nips-2002-Stable_Fixed_Points_of_Loopy_Belief_Propagation_Are_Local_Minima_of_the_Bethe_Free_Energy_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Stable Fixed Points of Loopy Belief Propagation Are Minima of the Bethe Free Energy  Tom Heskes SNN, University of Nijmegen Geert Grooteplein 21, 6252 EZ, Nijmegen, The Netherlands  Abstract We extend recent work on the connection between loopy belief propagation and the Bethe free energy. [sent-1, score-1.04]
</p><p>2 Constrained minimization of the Bethe free energy can be turned into an unconstrained saddle-point problem. [sent-2, score-0.43]
</p><p>3 Both converging double-loop algorithms and standard loopy belief propagation can be interpreted as attempts to solve this saddle-point problem. [sent-3, score-0.968]
</p><p>4 Stability analysis then leads us to conclude that stable ﬁxed points of loopy belief propagation must be (local) minima of the Bethe free energy. [sent-4, score-1.179]
</p><p>5 Perhaps surprisingly, the converse need not be the case: minima can be unstable ﬁxed points. [sent-5, score-0.186]
</p><p>6 1  Introduction  Pearl’s belief propagation [1] is a popular algorithm for inference in Bayesian networks. [sent-7, score-0.615]
</p><p>7 But also on networks containing cycles, so-called loopy belief propagation often leads to good performance (approximate marginals close to exact marginals) [2]. [sent-11, score-1.035]
</p><p>8 The notion that ﬁxed points of loopy belief propagation correspond to extrema of the so-called Bethe free energy [3] has been an important step in the theoretical understanding of this success. [sent-12, score-1.264]
</p><p>9 Empirically it has further been observed that loopy belief propagation, when it does, converges to a minimum. [sent-13, score-0.664]
</p><p>10 In Section 2 we will introduce loopy belief propagation in terms of a sum-product algorithm on factor graphs [4]. [sent-15, score-1.079]
</p><p>11 The corresponding Bethe free energy is derived in Section 3 from a variational point of view, indicating that we should be particularly interested in minima. [sent-16, score-0.291]
</p><p>12 In Section 4 we show that minimization of the Bethe free energy under the appropriate constraints is equivalent to an unconstrained saddlepoint problem. [sent-17, score-0.555]
</p><p>13 The converging double-loop algorithm, described in Section 3, as well as the standard sum-product algorithm are in fact attempts to solve this saddlepoint problem. [sent-18, score-0.199]
</p><p>14 More speciﬁcally, (a damped version of) the sum-product algorithm has the same local stability properties as a gradient descent-ascent procedure. [sent-19, score-0.467]
</p><p>15 Stability analysis of this gradient descent-ascent procedure then leads to the conclusion in the title. [sent-20, score-0.109]
</p><p>16 , xn ) ∝  Ψij (xi , xj ) = exp wij xi xj +  exp  ij  wij xi xj +  i  1 θx n−1 i i  +  1 θ x n−1 j j  . [sent-26, score-0.168]
</p><p>17 (b) Corresponding factor graph with a factor for each pair of nodes. [sent-30, score-0.168]
</p><p>18 2  The sum-product algorithm on factor graphs  We start with a description of (loopy) belief propagation as the sum-product algorithm on factor graphs [4]. [sent-31, score-0.914]
</p><p>19 An example of the transformation of a Markov network into a factor graph is shown in Figure 1. [sent-43, score-0.099]
</p><p>20 In a similar manner one can transform Bayesian networks into factor graphs, where each factor contains the child and its parents [4]. [sent-44, score-0.167]
</p><p>21 On singly-connected structures, Pearl’s belief propagation algorithm [1] can be applied to compute the exact marginals (“beliefs”) P (Xα ) =  P (X) and P (xβ ) = X\α  P (X) . [sent-45, score-0.718]
</p><p>22 X\β  If the structure contains cycles, one can still apply (loopy) belief propagation, in an attempt to obtain accurate approximations Pα (Xα ) and Pβ (xβ ). [sent-46, score-0.351]
</p><p>23 In the factorgraph representation we distinguish messages from factor α to variable β, µα→β (xβ ), and vice versa, µβ →α (xβ ). [sent-48, score-0.249]
</p><p>24 The beliefs follow by multiplying the potential, a mere 1 for the variables and Ψα (Xα ) for the factors, with the incoming messages, see (1. [sent-49, score-0.199]
</p><p>25 The update for an outgoing message is the variable belief, either calculated with the deﬁnition (1. [sent-52, score-0.217]
</p><p>26 We interpret the update of factor-variable message µα→β in line 8 of Algorithm 1 as the only actual update: beliefs and variable-factor messages directly follow from deﬁnitions in lines 11 to 15. [sent-57, score-0.48]
</p><p>27 For later reference we introduce the damped update log µnewβ (xβ ) = log µα→β (xβ ) + α→ full  log µfull β (xβ ) − log µα→β (xβ ) , α→  (2)  where µ refers to the result of the full update (1. [sent-58, score-0.928]
</p><p>28 These and other seemingly arbitrary choices, among which the particular ordering  Initial messages:  1: repeat 2: for all variables β do 3: for all factors α ⊃ β do 4: if initial then 5: initialize message (1. [sent-60, score-0.253]
</p><p>29 5) 9: end if 10: end for 11: compute variable belief (1. [sent-63, score-0.446]
</p><p>30 2) 12: for all factors α ⊃ β do 13: compute message (1. [sent-64, score-0.169]
</p><p>31 3) 15: end for 16: end for 17: until convergence  µα→β (xβ ) = 1  (1. [sent-66, score-0.131]
</p><p>32 6)  Xα\β  Algorithm 1: The sum-product algorithm on factor graphs. [sent-72, score-0.122]
</p><p>33 Besides, for the results on local stability we will consider the limit of small step sizes , where any eﬀects of the ordering disappear. [sent-74, score-0.294]
</p><p>34 3  The Bethe free energy  The exact distribution (1) can be written as the result of the variational problem ˆ P (X) ˆ , (3) P (X) = argmin P (X) log ˆ α Ψα (Xα ) P X  where here and in the following normalization and positivity constraints on probabilities are implicitly assumed. [sent-76, score-0.552]
</p><p>35 Next we conﬁne our search to “tree-like” probability distributions of the form α Pα (Xα ) ˆ P (X) ∝ with nβ ≡ 1, (4) nβ −1 β Pβ (xβ ) α⊃β  the number of neighboring factors of variable β. [sent-77, score-0.099]
</p><p>36 Here Pα (Xα ) and Pβ (xβ ) are interpreted as (approximate) local marginals that should normalize to 1, but should also be consistent, i. [sent-78, score-0.112]
</p><p>37 Plugging (4) into the objective (3) and implementing the above assumptions, we obtain the Bethe free energy Pα (Xα ) F (P ) = Pα (Xα ) log − (nβ − 1) Pβ (xβ ) log Pβ (xβ ) . [sent-85, score-0.589]
</p><p>38 (6) Ψα (Xα ) α x Xα  β  β  Initial messages and beliefs: 1: 2: 3: 4: 5: 6: 7: 8: 9: 10:  for all α and β ⊂ α do initialize (2. [sent-86, score-0.173]
</p><p>39 1) end for repeat for all factors α do update potential (2. [sent-87, score-0.226]
</p><p>40 3)  β⊂α  Potential update: ˆ log Ψα (Xα ) = log Ψα (Xα ) nβ − 1 old + log Pα (xβ ) (2. [sent-94, score-0.493]
</p><p>41 4) nβ β⊂α  Algorithm 2: Double-loop algorithm for minimizing the Bethe free energy. [sent-95, score-0.19]
</p><p>42 The inner loop is Algorithm 1 with redeﬁnitions of the factor and variable beliefs. [sent-96, score-0.352]
</p><p>43 Minus the Bethe free energy is an approximation, but not a bound of the loglikelihood log Z. [sent-97, score-0.481]
</p><p>44 A key observation in [3] is that the ﬁxed points of the sum-product algorithm, described in the previous section, correspond to extrema of the Bethe free energy under the constraints (5). [sent-98, score-0.373]
</p><p>45 The above derivation suggests that we should be speciﬁcally interested in minima of the Bethe free energy, not “just” stationary points. [sent-99, score-0.187]
</p><p>46 The resulting constrained minimization problem is well-deﬁned (the Bethe free energy is bounded from below), but not necessarily convex, mainly because of the negative Pβ log Pβ -terms. [sent-100, score-0.56]
</p><p>47 The crucial trick, implicit or explicit in recently suggested procedures is to bound [5] or clamp [6] the possibly concave part (outer loop: recompute the bound) and solve the remaining convex problem (inner loop: maximization with respect to Lagrange multipliers; see below). [sent-101, score-0.165]
</p><p>48 Here we propose to use the linear bound old Pβ (xβ ) log Pβ (xβ ) ,  Pβ (xβ ) log Pβ (xβ ) ≤ −  −  (7)  xβ  xβ  old with Pβ (xβ ) from the result of the previous inner loop. [sent-102, score-0.524]
</p><p>49 The (convex) bound of the Bethe free energy then boils down to  Fbound (P ) =  Pα (Xα ) log α  Xα  Pα (Xα ) ≥ F (P ) , ˆ Ψα (Xα )  ˆ if we deﬁne Ψα as in (2. [sent-103, score-0.481]
</p><p>50 The outer loop corresponds to a reset of the bound, i. [sent-105, score-0.202]
</p><p>51 , at the start of the inner loop we have Fbound (P ) = F (P ). [sent-107, score-0.252]
</p><p>52 In the inner loop (see the next section for its derivation), we solve the remaining convex constrained minimization problem with the method of Lagrange multipliers. [sent-108, score-0.463]
</p><p>53 At the end of the inner loop, we then have F (P new ) ≤ Fbound (P new ) ≤ Fbound (P ) = F (P ). [sent-109, score-0.139]
</p><p>54 4  Saddle-point problem  In this section we will translate the (non-convex) minimization of the Bethe free energy under linear constraints into an equivalent (non-convex/concave) saddle-point  problem. [sent-110, score-0.42]
</p><p>55 We replace the bound (7) with an explicit minimization over auxiliary variables γ (see also [7]; an alternative interpretation is a Legendre transform):      − Pβ (xβ ) log Pβ (xβ ) = min − γβ (xβ )Pβ (xβ ) + log  eγβ (xβ )  . [sent-111, score-0.5]
</p><p>56 (8) γβ   x x x β  β  β  Substitution into (6) then yields a constrained minimization problem, where the minimization is w. [sent-112, score-0.205]
</p><p>57 Using (any other convex combination will work as well, but this symmetric one is most convenient) Pβ (xβ ) =  1 nβ  Pα (xβ ) α⊃β  we can get rid of all dependencies on Pβ , both in (8) and in the constraints (5), which simpliﬁes the following analysis and derivations considerably. [sent-116, score-0.103]
</p><p>58 For ﬁxed γβ , the remaining minimization problem is convex in Pα with linear constraints and can thus be solved with the method of Lagrange multipliers. [sent-117, score-0.188]
</p><p>59 In terms of these multipliers λ and the auxiliary variables γ, the solution for Pα reads   1 nβ − 1 ¯ Pα (Xα ) = Ψα (Xα ) exp  λαβ (xβ ) + γβ (xβ ) , (9) Zα (λ, γ) nβ β⊂α  with Zα (λ, γ) the proper normalization and  1 ¯ λαβ (xβ ) ≡ λαβ (xβ ) − nβ  λα β (xβ ) . [sent-118, score-0.15]
</p><p>60 log Pα (xβ ) ,  (10)  α ⊃β    Pα (xβ ) ,  (11)  with Pα (xβ ) the marginal computed from Pα (Xα ) as in (9). [sent-120, score-0.149]
</p><p>61 Introduce a new set of auxiliary variables Zα by writing − log Zα = max ˆ Zα  ˆ − log Zα +  1−  1 ˆ Zα  Pα (Xα )Zα  . [sent-122, score-0.4]
</p><p>62 Xα  Next consider maximizing λαβ (xβ ) for a particular variable β and all α ⊃ β, while keeping ˆ ˆ all others as well as all Zα ﬁxed (by convention, we update Zα to Zα after each update of ¯ λ’s). [sent-123, score-0.201]
</p><p>63 Any update of the form λnew (xβ ) = − log Pα (xβ ) + λαβ (xβ ) + νβ (xβ ) will do, where αβ ¯ αβ choosing νβ (xβ ) such that λnew = λnew yields (10). [sent-125, score-0.234]
</p><p>64 αβ  The updates (10) and (11) are properly aligned with the respective gradients and satisfy the saddle-point equations F (λnew , γ) ≥ F (λ, γ) ≥ F (λ, γ new ) . [sent-126, score-0.084]
</p><p>65 (12)  This saddle-point problem is concave in λ, but not necessarily convex in γ. [sent-127, score-0.092]
</p><p>66 One way to guarantee convergence to a “correct” saddle point is then to solve the (up to irrelevant linear translations unique) maximization with respect to λ in an inner loop, followed by an update of γ in the outer loop. [sent-128, score-0.368]
</p><p>67 We obtain the description given in Algorithm 2 if we substitute (up to irrelevant constants) old ¯ γβ (xβ ) = log Pβ (xβ ), λαβ (xβ ) = log µβ →α (xβ ), and λαβ (xβ ) = − log µα→β (xβ ) . [sent-130, score-0.519]
</p><p>68 Note that in the inner loop of the double-loop algorithm the scheduling does matter. [sent-131, score-0.359]
</p><p>69 The ordering described in Algorithm 1 - run over variables β and update all corresponding messages from and to neighboring factors before moving on to the next variable - satisﬁes (12) without damping. [sent-132, score-0.393]
</p><p>70 This can be loosely interpreted as doing gradient descent-ascent. [sent-134, score-0.084]
</p><p>71 Similarly, it is easy to show that gradient descent-ascent applied to a non-convex/concave problem is locally stable at a particular saddle point {λ∗ , γ ∗ }, if and only if the objective is locally convex/concave. [sent-138, score-0.299]
</p><p>72 The damped version (2) of the sum-product algorithm has the same local stability properties as a gradient descent-ascent procedure derived from (10) and (11). [sent-141, score-0.492]
</p><p>73 We replace (11) with new γβ (xβ ) =  1 nβ  log Pα (xβ ) . [sent-143, score-0.149]
</p><p>74 Consequently, (13) has the same local stability properties as (11). [sent-145, score-0.168]
</p><p>75 Now consider parallel application of a damped version of (10), with step size , and (13), with step size nβ . [sent-146, score-0.226]
</p><p>76 We obtain the damped version (2) of the standard sum-product algorithm, in combination with the other deﬁnitions in Algorithm 1, when we apply the deﬁnitions nβ − 1 1 ¯ log µβ→α (xβ ) = λαβ (xβ ) + γβ (xβ ) and log µα→β (xβ ) = γβ (xβ ) − λαβ (xβ ) . [sent-147, score-0.46]
</p><p>77 Local stability of the gradient descent-ascent procedure at {λ∗ , γ ∗ } implies that the corresponding Pα is at a minimum of the Bethe free energy and that all constraints are satisﬁed. [sent-149, score-0.561]
</p><p>78 (a) No damping leads to somewhat erratic cyclic behavior. [sent-154, score-0.193]
</p><p>79 (c) The double-loop algorithm does converge to a stable solution. [sent-157, score-0.193]
</p><p>80 (d) This solution is unstable under standard loopy belief propagation (here again with step size 0. [sent-158, score-0.991]
</p><p>81 Gradient descent-ascent is locally stable iﬀ Hγγ is positive and Hλλ negative (semi-)deﬁnite. [sent-161, score-0.127]
</p><p>82 Non-convergence of loopy belief propagation on a Boltzmann machine is shown in Figure 2. [sent-167, score-0.903]
</p><p>83 Typically, standard loopy belief propagation converges to a stable solution without damping. [sent-168, score-0.992]
</p><p>84 In rare cases, damping is required to obtain convergence and in very rare cases, even considerable damping does not help, as in Figure 2. [sent-169, score-0.491]
</p><p>85 The double-loop algorithm does converge and the solution obtained is indeed unstable under standard belief propagation, even with damping. [sent-170, score-0.483]
</p><p>86 This is consistent with the empirical observation that the max-product algorithm (“belief revision”) is typically less stable than the sum-product algorithm: max-product on a Boltzmann machine corresponds to (a properly scaled version of) the sum-product algorithm in the limit of inﬁnite weights. [sent-172, score-0.252]
</p><p>87 The example in Figure 2 is about the smallest that we have found: we have observed these instabilities in many other (larger) instances of Markov networks, as well as directed Bayesian networks, yet not in structures with just a single loop. [sent-173, score-0.087]
</p><p>88 The latter seems consistent with the notion that not only for trees, but also for networks with a single loop, the Bethe free energy is still convex. [sent-174, score-0.348]
</p><p>89 5  Discussion  The above gradient descent-ascent interpretation shows that loopy belief propagation is more than just ﬁxed-point iteration: the updates tend to move in the right uphill-downhill directions, which might explain its success in practical applications. [sent-175, score-1.044]
</p><p>90 Still, loopy belief propagation can fail to converge, and apparently for two diﬀerent  reasons. [sent-176, score-0.903]
</p><p>91 Straightforwardly damping the updates, as in (2), is then suﬃcient to converge to a stable ﬁxed point. [sent-178, score-0.333]
</p><p>92 Note that this damping is in the logarithmic domain and thus slightly diﬀerent from the damping linear in the messages as described in [2]. [sent-179, score-0.56]
</p><p>93 The damping proposed in [7] is restricted to the Lagrange multipliers λ and may therefore not share the nice properties of the damping discussed here. [sent-180, score-0.434]
</p><p>94 Local stability in the limit of small step sizes is independent of the scheduling of messages, but in practice particular schedules can still favor others and, for example, be stable with larger step sizes or converge more rapidly. [sent-181, score-0.493]
</p><p>95 For example, in [9] the message updates follow the structure of a spanning tree, which empirically seems to help a lot. [sent-182, score-0.215]
</p><p>96 In that case, loopy belief propagation just does not work and one can resort to a more tedious double-loop algorithm to guarantee convergence to a local minimum. [sent-184, score-1.046]
</p><p>97 The double-loop algorithm described here is similar to the CCCP algorithm of [5]. [sent-185, score-0.106]
</p><p>98 Loopy belief propagation for approximate inference: An empirical study. [sent-197, score-0.59]
</p><p>99 CCCP algorithms to minimize the Bethe and Kikuchi free energies: Convergent alternatives to belief propagation. [sent-213, score-0.46]
</p><p>100 Expectation propagation for approximate inference in dynamic Bayesian networks. [sent-240, score-0.267]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('bethe', 0.447), ('loopy', 0.341), ('belief', 0.323), ('propagation', 0.239), ('damping', 0.193), ('damped', 0.162), ('loop', 0.159), ('energy', 0.154), ('log', 0.149), ('messages', 0.149), ('free', 0.137), ('rrr', 0.118), ('stability', 0.117), ('beliefs', 0.113), ('fbound', 0.108), ('message', 0.101), ('inner', 0.093), ('stable', 0.089), ('lll', 0.086), ('update', 0.085), ('minimization', 0.085), ('gradient', 0.084), ('saddlepoint', 0.081), ('yyyy', 0.081), ('converse', 0.08), ('yy', 0.08), ('factor', 0.069), ('ee', 0.068), ('factors', 0.068), ('boltzmann', 0.064), ('marginals', 0.061), ('convex', 0.059), ('updates', 0.057), ('unstable', 0.056), ('ll', 0.055), ('instabilities', 0.054), ('lllll', 0.054), ('rry', 0.054), ('scheduling', 0.054), ('unconstrained', 0.054), ('graphs', 0.054), ('nitions', 0.053), ('algorithm', 0.053), ('lagrange', 0.052), ('local', 0.051), ('converge', 0.051), ('minima', 0.05), ('auxiliary', 0.05), ('cycles', 0.05), ('saddle', 0.05), ('multipliers', 0.048), ('cccp', 0.047), ('heskes', 0.047), ('nijmegen', 0.047), ('old', 0.046), ('end', 0.046), ('constraints', 0.044), ('outer', 0.043), ('pearl', 0.043), ('rr', 0.042), ('exact', 0.042), ('bound', 0.041), ('convergence', 0.039), ('locally', 0.038), ('extrema', 0.038), ('wij', 0.036), ('iterations', 0.035), ('constrained', 0.035), ('ordering', 0.034), ('nips', 0.034), ('structures', 0.033), ('converging', 0.033), ('concave', 0.033), ('rare', 0.033), ('step', 0.032), ('follow', 0.032), ('curvature', 0.032), ('solve', 0.032), ('xj', 0.032), ('variable', 0.031), ('sizes', 0.03), ('xed', 0.03), ('graph', 0.03), ('obey', 0.03), ('limit', 0.03), ('networks', 0.029), ('approximate', 0.028), ('incoming', 0.028), ('still', 0.028), ('potential', 0.027), ('properly', 0.027), ('variables', 0.026), ('max', 0.026), ('irrelevant', 0.026), ('normalization', 0.026), ('di', 0.025), ('empirically', 0.025), ('logarithmic', 0.025), ('procedure', 0.025), ('initialize', 0.024)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="189-tfidf-1" href="./nips-2002-Stable_Fixed_Points_of_Loopy_Belief_Propagation_Are_Local_Minima_of_the_Bethe_Free_Energy.html">189 nips-2002-Stable Fixed Points of Loopy Belief Propagation Are Local Minima of the Bethe Free Energy</a></p>
<p>Author: Tom Heskes</p><p>Abstract: We extend recent work on the connection between loopy belief propagation and the Bethe free energy. Constrained minimization of the Bethe free energy can be turned into an unconstrained saddle-point problem. Both converging double-loop algorithms and standard loopy belief propagation can be interpreted as attempts to solve this saddle-point problem. Stability analysis then leads us to conclude that stable ﬁxed points of loopy belief propagation must be (local) minima of the Bethe free energy. Perhaps surprisingly, the converse need not be the case: minima can be unstable ﬁxed points. We illustrate this with an example and discuss implications. 1</p><p>2 0.58179438 <a title="189-tfidf-2" href="./nips-2002-Fractional_Belief_Propagation.html">94 nips-2002-Fractional Belief Propagation</a></p>
<p>Author: Wim Wiegerinck, Tom Heskes</p><p>Abstract: We consider loopy belief propagation for approximate inference in probabilistic graphical models. A limitation of the standard algorithm is that clique marginals are computed as if there were no loops in the graph. To overcome this limitation, we introduce fractional belief propagation. Fractional belief propagation is formulated in terms of a family of approximate free energies, which includes the Bethe free energy and the naive mean-ﬁeld free as special cases. Using the linear response correction of the clique marginals, the scale parameters can be tuned. Simulation results illustrate the potential merits of the approach.</p><p>3 0.20581409 <a title="189-tfidf-3" href="./nips-2002-Exponential_Family_PCA_for_Belief_Compression_in_POMDPs.html">82 nips-2002-Exponential Family PCA for Belief Compression in POMDPs</a></p>
<p>Author: Nicholas Roy, Geoffrey J. Gordon</p><p>Abstract: Standard value function approaches to ﬁnding policies for Partially Observable Markov Decision Processes (POMDPs) are intractable for large models. The intractability of these algorithms is due to a great extent to their generating an optimal policy over the entire belief space. However, in real POMDP problems most belief states are unlikely, and there is a structured, low-dimensional manifold of plausible beliefs embedded in the high-dimensional belief space. We introduce a new method for solving large-scale POMDPs by taking advantage of belief space sparsity. We reduce the dimensionality of the belief space by exponential family Principal Components Analysis [1], which allows us to turn the sparse, highdimensional belief space into a compact, low-dimensional representation in terms of learned features of the belief state. We then plan directly on the low-dimensional belief features. By planning in a low-dimensional space, we can ﬁnd policies for POMDPs that are orders of magnitude larger than can be handled by conventional techniques. We demonstrate the use of this algorithm on a synthetic problem and also on a mobile robot navigation task.</p><p>4 0.12968189 <a title="189-tfidf-4" href="./nips-2002-Generalized%C3%82%CB%9B_Linear%C3%82%CB%9B_Models.html">96 nips-2002-GeneralizedÂ˛ LinearÂ˛ Models</a></p>
<p>Author: Geoffrey J. Gordon</p><p>Abstract: We introduce the Generalized 2 Linear 2 Model, a statistical estimator which combines features of nonlinear regression and factor analysis. A (GL)2M approximately decomposes a rectangular matrix X into a simpler representation j(g(A)h(B)). Here A and Bare low-rank matrices, while j, g, and h are link functions. (GL)2Ms include many useful models as special cases, including principal components analysis, exponential-family peA, the infomax formulation of independent components analysis, linear regression, and generalized linear models. They also include new and interesting special cases, one of which we describe below. We also present an iterative procedure which optimizes the parameters of a (GL)2M. This procedure reduces to well-known algorithms for some of the special cases listed above; for other special cases, it is new. 1</p><p>5 0.11722355 <a title="189-tfidf-5" href="./nips-2002-A_Differential_Semantics_for_Jointree_Algorithms.html">4 nips-2002-A Differential Semantics for Jointree Algorithms</a></p>
<p>Author: James D. Park, Adnan Darwiche</p><p>Abstract: A new approach to inference in belief networks has been recently proposed, which is based on an algebraic representation of belief networks using multi–linear functions. According to this approach, the key computational question is that of representing multi–linear functions compactly, since inference reduces to a simple process of ev aluating and diﬀerentiating such functions. W e show here that mainstream inference algorithms based on jointrees are a special case of this approach in a v ery precise sense. W e use this result to prov e new properties of jointree algorithms, and then discuss some of its practical and theoretical implications. 1</p><p>6 0.11523493 <a title="189-tfidf-6" href="./nips-2002-Learning_to_Perceive_Transparency_from_the_Statistics_of_Natural_Scenes.html">133 nips-2002-Learning to Perceive Transparency from the Statistics of Natural Scenes</a></p>
<p>7 0.11502013 <a title="189-tfidf-7" href="./nips-2002-Approximate_Inference_and_Protein-Folding.html">32 nips-2002-Approximate Inference and Protein-Folding</a></p>
<p>8 0.10926788 <a title="189-tfidf-8" href="./nips-2002-Self_Supervised_Boosting.html">181 nips-2002-Self Supervised Boosting</a></p>
<p>9 0.10896085 <a title="189-tfidf-9" href="./nips-2002-Stability-Based_Model_Selection.html">188 nips-2002-Stability-Based Model Selection</a></p>
<p>10 0.097713523 <a title="189-tfidf-10" href="./nips-2002-Exact_MAP_Estimates_by_%28Hyper%29tree_Agreement.html">80 nips-2002-Exact MAP Estimates by (Hyper)tree Agreement</a></p>
<p>11 0.094490632 <a title="189-tfidf-11" href="./nips-2002-Nash_Propagation_for_Loopy_Graphical_Games.html">152 nips-2002-Nash Propagation for Loopy Graphical Games</a></p>
<p>12 0.088451967 <a title="189-tfidf-12" href="./nips-2002-Real-Time_Particle_Filters.html">169 nips-2002-Real-Time Particle Filters</a></p>
<p>13 0.084474772 <a title="189-tfidf-13" href="./nips-2002-Adaptive_Scaling_for_Feature_Selection_in_SVMs.html">24 nips-2002-Adaptive Scaling for Feature Selection in SVMs</a></p>
<p>14 0.081852682 <a title="189-tfidf-14" href="./nips-2002-Value-Directed_Compression_of_POMDPs.html">205 nips-2002-Value-Directed Compression of POMDPs</a></p>
<p>15 0.074283004 <a title="189-tfidf-15" href="./nips-2002-Learning_a_Forward_Model_of_a_Reflex.html">128 nips-2002-Learning a Forward Model of a Reflex</a></p>
<p>16 0.07339979 <a title="189-tfidf-16" href="./nips-2002-Multiplicative_Updates_for_Nonnegative_Quadratic_Programming_in_Support_Vector_Machines.html">151 nips-2002-Multiplicative Updates for Nonnegative Quadratic Programming in Support Vector Machines</a></p>
<p>17 0.070550844 <a title="189-tfidf-17" href="./nips-2002-On_the_Dirichlet_Prior_and_Bayesian_Regularization.html">157 nips-2002-On the Dirichlet Prior and Bayesian Regularization</a></p>
<p>18 0.068562001 <a title="189-tfidf-18" href="./nips-2002-Dynamic_Structure_Super-Resolution.html">74 nips-2002-Dynamic Structure Super-Resolution</a></p>
<p>19 0.061730001 <a title="189-tfidf-19" href="./nips-2002-Data-Dependent_Bounds_for_Bayesian_Mixture_Methods.html">64 nips-2002-Data-Dependent Bounds for Bayesian Mixture Methods</a></p>
<p>20 0.061572384 <a title="189-tfidf-20" href="./nips-2002-Learning_in_Spiking_Neural_Assemblies.html">129 nips-2002-Learning in Spiking Neural Assemblies</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2002_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.188), (1, -0.054), (2, -0.181), (3, 0.065), (4, 0.01), (5, 0.171), (6, -0.159), (7, 0.385), (8, -0.365), (9, -0.072), (10, -0.241), (11, 0.155), (12, -0.176), (13, -0.062), (14, 0.138), (15, -0.065), (16, 0.051), (17, 0.016), (18, -0.057), (19, 0.023), (20, -0.066), (21, -0.04), (22, 0.128), (23, -0.063), (24, 0.029), (25, 0.008), (26, 0.052), (27, -0.015), (28, 0.011), (29, 0.059), (30, -0.066), (31, -0.068), (32, 0.029), (33, -0.037), (34, 0.005), (35, 0.067), (36, -0.103), (37, -0.041), (38, 0.1), (39, -0.104), (40, -0.086), (41, -0.003), (42, -0.052), (43, 0.013), (44, -0.028), (45, 0.09), (46, -0.061), (47, 0.023), (48, -0.066), (49, -0.039)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97680271 <a title="189-lsi-1" href="./nips-2002-Stable_Fixed_Points_of_Loopy_Belief_Propagation_Are_Local_Minima_of_the_Bethe_Free_Energy.html">189 nips-2002-Stable Fixed Points of Loopy Belief Propagation Are Local Minima of the Bethe Free Energy</a></p>
<p>Author: Tom Heskes</p><p>Abstract: We extend recent work on the connection between loopy belief propagation and the Bethe free energy. Constrained minimization of the Bethe free energy can be turned into an unconstrained saddle-point problem. Both converging double-loop algorithms and standard loopy belief propagation can be interpreted as attempts to solve this saddle-point problem. Stability analysis then leads us to conclude that stable ﬁxed points of loopy belief propagation must be (local) minima of the Bethe free energy. Perhaps surprisingly, the converse need not be the case: minima can be unstable ﬁxed points. We illustrate this with an example and discuss implications. 1</p><p>2 0.97511417 <a title="189-lsi-2" href="./nips-2002-Fractional_Belief_Propagation.html">94 nips-2002-Fractional Belief Propagation</a></p>
<p>Author: Wim Wiegerinck, Tom Heskes</p><p>Abstract: We consider loopy belief propagation for approximate inference in probabilistic graphical models. A limitation of the standard algorithm is that clique marginals are computed as if there were no loops in the graph. To overcome this limitation, we introduce fractional belief propagation. Fractional belief propagation is formulated in terms of a family of approximate free energies, which includes the Bethe free energy and the naive mean-ﬁeld free as special cases. Using the linear response correction of the clique marginals, the scale parameters can be tuned. Simulation results illustrate the potential merits of the approach.</p><p>3 0.50490552 <a title="189-lsi-3" href="./nips-2002-A_Differential_Semantics_for_Jointree_Algorithms.html">4 nips-2002-A Differential Semantics for Jointree Algorithms</a></p>
<p>Author: James D. Park, Adnan Darwiche</p><p>Abstract: A new approach to inference in belief networks has been recently proposed, which is based on an algebraic representation of belief networks using multi–linear functions. According to this approach, the key computational question is that of representing multi–linear functions compactly, since inference reduces to a simple process of ev aluating and diﬀerentiating such functions. W e show here that mainstream inference algorithms based on jointrees are a special case of this approach in a v ery precise sense. W e use this result to prov e new properties of jointree algorithms, and then discuss some of its practical and theoretical implications. 1</p><p>4 0.46112752 <a title="189-lsi-4" href="./nips-2002-Approximate_Inference_and_Protein-Folding.html">32 nips-2002-Approximate Inference and Protein-Folding</a></p>
<p>Author: Chen Yanover, Yair Weiss</p><p>Abstract: Side-chain prediction is an important subtask in the protein-folding problem. We show that finding a minimal energy side-chain configuration is equivalent to performing inference in an undirected graphical model. The graphical model is relatively sparse yet has many cycles. We used this equivalence to assess the performance of approximate inference algorithms in a real-world setting. Specifically we compared belief propagation (BP), generalized BP (GBP) and naive mean field (MF). In cases where exact inference was possible, max-product BP always found the global minimum of the energy (except in few cases where it failed to converge), while other approximation algorithms of similar complexity did not. In the full protein data set, maxproduct BP always found a lower energy configuration than the other algorithms, including a widely used protein-folding software (SCWRL). 1</p><p>5 0.44930997 <a title="189-lsi-5" href="./nips-2002-Exponential_Family_PCA_for_Belief_Compression_in_POMDPs.html">82 nips-2002-Exponential Family PCA for Belief Compression in POMDPs</a></p>
<p>Author: Nicholas Roy, Geoffrey J. Gordon</p><p>Abstract: Standard value function approaches to ﬁnding policies for Partially Observable Markov Decision Processes (POMDPs) are intractable for large models. The intractability of these algorithms is due to a great extent to their generating an optimal policy over the entire belief space. However, in real POMDP problems most belief states are unlikely, and there is a structured, low-dimensional manifold of plausible beliefs embedded in the high-dimensional belief space. We introduce a new method for solving large-scale POMDPs by taking advantage of belief space sparsity. We reduce the dimensionality of the belief space by exponential family Principal Components Analysis [1], which allows us to turn the sparse, highdimensional belief space into a compact, low-dimensional representation in terms of learned features of the belief state. We then plan directly on the low-dimensional belief features. By planning in a low-dimensional space, we can ﬁnd policies for POMDPs that are orders of magnitude larger than can be handled by conventional techniques. We demonstrate the use of this algorithm on a synthetic problem and also on a mobile robot navigation task.</p><p>6 0.37272659 <a title="189-lsi-6" href="./nips-2002-Generalized%C3%82%CB%9B_Linear%C3%82%CB%9B_Models.html">96 nips-2002-GeneralizedÂ˛ LinearÂ˛ Models</a></p>
<p>7 0.36939004 <a title="189-lsi-7" href="./nips-2002-Nash_Propagation_for_Loopy_Graphical_Games.html">152 nips-2002-Nash Propagation for Loopy Graphical Games</a></p>
<p>8 0.35235152 <a title="189-lsi-8" href="./nips-2002-Learning_to_Perceive_Transparency_from_the_Statistics_of_Natural_Scenes.html">133 nips-2002-Learning to Perceive Transparency from the Statistics of Natural Scenes</a></p>
<p>9 0.32255957 <a title="189-lsi-9" href="./nips-2002-Value-Directed_Compression_of_POMDPs.html">205 nips-2002-Value-Directed Compression of POMDPs</a></p>
<p>10 0.26225588 <a title="189-lsi-10" href="./nips-2002-Self_Supervised_Boosting.html">181 nips-2002-Self Supervised Boosting</a></p>
<p>11 0.24975646 <a title="189-lsi-11" href="./nips-2002-Stability-Based_Model_Selection.html">188 nips-2002-Stability-Based Model Selection</a></p>
<p>12 0.24558839 <a title="189-lsi-12" href="./nips-2002-Exact_MAP_Estimates_by_%28Hyper%29tree_Agreement.html">80 nips-2002-Exact MAP Estimates by (Hyper)tree Agreement</a></p>
<p>13 0.23680112 <a title="189-lsi-13" href="./nips-2002-Branching_Law_for_Axons.html">47 nips-2002-Branching Law for Axons</a></p>
<p>14 0.22427781 <a title="189-lsi-14" href="./nips-2002-Scaling_of_Probability-Based_Optimization_Algorithms.html">179 nips-2002-Scaling of Probability-Based Optimization Algorithms</a></p>
<p>15 0.22189878 <a title="189-lsi-15" href="./nips-2002-Real-Time_Particle_Filters.html">169 nips-2002-Real-Time Particle Filters</a></p>
<p>16 0.22095868 <a title="189-lsi-16" href="./nips-2002-Adaptive_Scaling_for_Feature_Selection_in_SVMs.html">24 nips-2002-Adaptive Scaling for Feature Selection in SVMs</a></p>
<p>17 0.20645642 <a title="189-lsi-17" href="./nips-2002-Learning_a_Forward_Model_of_a_Reflex.html">128 nips-2002-Learning a Forward Model of a Reflex</a></p>
<p>18 0.20426238 <a title="189-lsi-18" href="./nips-2002-Automatic_Derivation_of_Statistical_Algorithms%3A_The_EM_Family_and_Beyond.html">37 nips-2002-Automatic Derivation of Statistical Algorithms: The EM Family and Beyond</a></p>
<p>19 0.20159267 <a title="189-lsi-19" href="./nips-2002-Regularized_Greedy_Importance_Sampling.html">174 nips-2002-Regularized Greedy Importance Sampling</a></p>
<p>20 0.19983488 <a title="189-lsi-20" href="./nips-2002-Multiplicative_Updates_for_Nonnegative_Quadratic_Programming_in_Support_Vector_Machines.html">151 nips-2002-Multiplicative Updates for Nonnegative Quadratic Programming in Support Vector Machines</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2002_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(11, 0.02), (14, 0.01), (23, 0.012), (42, 0.075), (50, 0.181), (52, 0.021), (54, 0.125), (55, 0.036), (57, 0.12), (67, 0.024), (68, 0.039), (74, 0.066), (87, 0.024), (92, 0.082), (98, 0.088)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.84046263 <a title="189-lda-1" href="./nips-2002-Stable_Fixed_Points_of_Loopy_Belief_Propagation_Are_Local_Minima_of_the_Bethe_Free_Energy.html">189 nips-2002-Stable Fixed Points of Loopy Belief Propagation Are Local Minima of the Bethe Free Energy</a></p>
<p>Author: Tom Heskes</p><p>Abstract: We extend recent work on the connection between loopy belief propagation and the Bethe free energy. Constrained minimization of the Bethe free energy can be turned into an unconstrained saddle-point problem. Both converging double-loop algorithms and standard loopy belief propagation can be interpreted as attempts to solve this saddle-point problem. Stability analysis then leads us to conclude that stable ﬁxed points of loopy belief propagation must be (local) minima of the Bethe free energy. Perhaps surprisingly, the converse need not be the case: minima can be unstable ﬁxed points. We illustrate this with an example and discuss implications. 1</p><p>2 0.77296549 <a title="189-lda-2" href="./nips-2002-Fractional_Belief_Propagation.html">94 nips-2002-Fractional Belief Propagation</a></p>
<p>Author: Wim Wiegerinck, Tom Heskes</p><p>Abstract: We consider loopy belief propagation for approximate inference in probabilistic graphical models. A limitation of the standard algorithm is that clique marginals are computed as if there were no loops in the graph. To overcome this limitation, we introduce fractional belief propagation. Fractional belief propagation is formulated in terms of a family of approximate free energies, which includes the Bethe free energy and the naive mean-ﬁeld free as special cases. Using the linear response correction of the clique marginals, the scale parameters can be tuned. Simulation results illustrate the potential merits of the approach.</p><p>3 0.73409665 <a title="189-lda-3" href="./nips-2002-Spikernels%3A_Embedding_Spiking_Neurons_in_Inner-Product_Spaces.html">187 nips-2002-Spikernels: Embedding Spiking Neurons in Inner-Product Spaces</a></p>
<p>Author: Lavi Shpigelman, Yoram Singer, Rony Paz, Eilon Vaadia</p><p>Abstract: Inner-product operators, often referred to as kernels in statistical learning, deﬁne a mapping from some input space into a feature space. The focus of this paper is the construction of biologically-motivated kernels for cortical activities. The kernels we derive, termed Spikernels, map spike count sequences into an abstract vector space in which we can perform various prediction tasks. We discuss in detail the derivation of Spikernels and describe an efﬁcient algorithm for computing their value on any two sequences of neural population spike counts. We demonstrate the merits of our modeling approach using the Spikernel and various standard kernels for the task of predicting hand movement velocities from cortical recordings. In all of our experiments all the kernels we tested outperform the standard scalar product used in regression with the Spikernel consistently achieving the best performance. 1</p><p>4 0.70382529 <a title="189-lda-4" href="./nips-2002-Learning_with_Multiple_Labels.html">135 nips-2002-Learning with Multiple Labels</a></p>
<p>Author: Rong Jin, Zoubin Ghahramani</p><p>Abstract: In this paper, we study a special kind of learning problem in which each training instance is given a set of (or distribution over) candidate class labels and only one of the candidate labels is the correct one. Such a problem can occur, e.g., in an information retrieval setting where a set of words is associated with an image, or if classes labels are organized hierarchically. We propose a novel discriminative approach for handling the ambiguity of class labels in the training examples. The experiments with the proposed approach over five different UCI datasets show that our approach is able to find the correct label among the set of candidate labels and actually achieve performance close to the case when each training instance is given a single correct label. In contrast, naIve methods degrade rapidly as more ambiguity is introduced into the labels. 1</p><p>5 0.69066095 <a title="189-lda-5" href="./nips-2002-Automatic_Derivation_of_Statistical_Algorithms%3A_The_EM_Family_and_Beyond.html">37 nips-2002-Automatic Derivation of Statistical Algorithms: The EM Family and Beyond</a></p>
<p>Author: Bernd Fischer, Johann Schumann, Wray Buntine, Alexander G. Gray</p><p>Abstract: Machine learning has reached a point where many probabilistic methods can be understood as variations, extensions and combinations of a much smaller set of abstract themes, e.g., as different instances of the EM algorithm. This enables the systematic derivation of algorithms customized for different models. Here, we describe the AUTO BAYES system which takes a high-level statistical model speciﬁcation, uses powerful symbolic techniques based on schema-based program synthesis and computer algebra to derive an efﬁcient specialized algorithm for learning that model, and generates executable code implementing that algorithm. This capability is far beyond that of code collections such as Matlab toolboxes or even tools for model-independent optimization such as BUGS for Gibbs sampling: complex new algorithms can be generated without new programming, algorithms can be highly specialized and tightly crafted for the exact structure of the model and data, and efﬁcient and commented code can be generated for different languages or systems. We present automatically-derived algorithms ranging from closed-form solutions of Bayesian textbook problems to recently-proposed EM algorithms for clustering, regression, and a multinomial form of PCA. 1 Automatic Derivation of Statistical Algorithms Overview. We describe a symbolic program synthesis system which works as a “statistical algorithm compiler:” it compiles a statistical model speciﬁcation into a custom algorithm design and from that further down into a working program implementing the algorithm design. This system, AUTO BAYES, can be loosely thought of as “part theorem prover, part Mathematica, part learning textbook, and part Numerical Recipes.” It provides much more ﬂexibility than a ﬁxed code repository such as a Matlab toolbox, and allows the creation of efﬁcient algorithms which have never before been implemented, or even written down. AUTO BAYES is intended to automate the more routine application of complex methods in novel contexts. For example, recent multinomial extensions to PCA [2, 4] can be derived in this way. The algorithm design problem. Given a dataset and a task, creating a learning method can be characterized by two main questions: 1. What is the model? 2. What algorithm will optimize the model parameters? The statistical algorithm (i.e., a parameter optimization algorithm for the statistical model) can then be implemented manually. The system in this paper answers the algorithm question given that the user has chosen a model for the data,and continues through to implementation. Performing this task at the state-of-the-art level requires an intertwined meld of probability theory, computational mathematics, and software engineering. However, a number of factors unite to allow us to solve the algorithm design problem computationally: 1. The existence of fundamental building blocks (e.g., standardized probability distributions, standard optimization procedures, and generic data structures). 2. The existence of common representations (i.e., graphical models [3, 13] and program schemas). 3. The formalization of schema applicability constraints as guards. 1 The challenges of algorithm design. The design problem has an inherently combinatorial nature, since subparts of a function may be optimized recursively and in different ways. It also involves the use of new data structures or approximations to gain performance. As the research in statistical algorithms advances, its creative focus should move beyond the ultimately mechanical aspects and towards extending the abstract applicability of already existing schemas (algorithmic principles like EM), improving schemas in ways that generalize across anything they can be applied to, and inventing radically new schemas. 2 Combining Schema-based Synthesis and Bayesian Networks Statistical Models. Externally, AUTO BAYES has the look and feel of 2 const int n_points as ’nr. of data points’ a compiler. Users specify their model 3 with 0 < n_points; 4 const int n_classes := 3 as ’nr. classes’ of interest in a high-level speciﬁcation 5 with 0 < n_classes language (as opposed to a program6 with n_classes << n_points; ming language). The ﬁgure shows the 7 double phi(1..n_classes) as ’weights’ speciﬁcation of the mixture of Gaus8 with 1 = sum(I := 1..n_classes, phi(I)); 9 double mu(1..n_classes); sians example used throughout this 9 double sigma(1..n_classes); paper.2 Note the constraint that the 10 int c(1..n_points) as ’class labels’; sum of the class probabilities must 11 c ˜ disc(vec(I := 1..n_classes, phi(I))); equal one (line 8) along with others 12 data double x(1..n_points) as ’data’; (lines 3 and 5) that make optimization 13 x(I) ˜ gauss(mu(c(I)), sigma(c(I))); of the model well-deﬁned. Also note 14 max pr(x| phi,mu,sigma ) wrt phi,mu,sigma ; the ability to specify assumptions of the kind in line 6, which may be used by some algorithms. The last line speciﬁes the goal inference task: maximize the conditional probability pr with respect to the parameters , , and . Note that moving the parameters across to the left of the conditioning bar converts this from a maximum likelihood to a maximum a posteriori problem. 1 model mog as ’Mixture of Gaussians’; ¡   £  £  £ §¤¢ £ © ¨ ¦ ¥ ©   ¡     ¡ £ £ £ ¨ Computational logic and theorem proving. Internally, AUTO BAYES uses a class of techniques known as computational logic which has its roots in automated theorem proving. AUTO BAYES begins with an initial goal and a set of initial assertions, or axioms, and adds new assertions, or theorems, by repeated application of the axioms, until the goal is proven. In our context, the goal is given by the input model; the derived algorithms are side effects of constructive theorems proving the existence of algorithms for the goal. 1 Schema guards vary widely; for example, compare Nead-Melder simplex or simulated annealing (which require only function evaluation), conjugate gradient (which require both Jacobian and Hessian), EM and its variational extension [6] (which require a latent-variable structure model). 2 Here, keywords have been underlined and line numbers have been added for reference in the text. The as-keyword allows annotations to variables which end up in the generated code’s comments. Also, n classes has been set to three (line 4), while n points is left unspeciﬁed. The class variable and single data variable are vectors, which deﬁnes them as i.i.d. Computer algebra. The ﬁrst core element which makes automatic algorithm derivation feasible is the fact that we can mechanize the required symbol manipulation, using computer algebra methods. General symbolic differentiation and expression simpliﬁcation are capabilities fundamental to our approach. AUTO BAYES contains a computer algebra engine using term rewrite rules which are an efﬁcient mechanism for substitution of equal quantities or expressions and thus well-suited for this task.3 Schema-based synthesis. The computational cost of full-blown theorem proving grinds simple tasks to a halt while elementary and intermediate facts are reinvented from scratch. To achieve the scale of deduction required by algorithm derivation, we thus follow a schema-based synthesis technique which breaks away from strict theorem proving. Instead, we formalize high-level domain knowledge, such as the general EM strategy, as schemas. A schema combines a generic code fragment with explicitly speciﬁed preconditions which describe the applicability of the code fragment. The second core element which makes automatic algorithm derivation feasible is the fact that we can use Bayesian networks to efﬁciently encode the preconditions of complex algorithms such as EM. First-order logic representation of Bayesian netNclasses works. A ﬁrst-order logic representation of Bayesian µ σ networks was developed by Haddawy [7]. In this framework, random variables are represented by functor symbols and indexes (i.e., speciﬁc instances φ x c of i.i.d. vectors) are represented as functor arguments. discrete gauss Nclasses Since unknown index values can be represented by Npoints implicitly universally quantiﬁed Prolog variables, this approach allows a compact encoding of networks involving i.i.d. variables or plates [3]; the ﬁgure shows the initial network for our running example. Moreover, such networks correspond to backtrack-free datalog programs, allowing the dependencies to be efﬁciently computed. We have extended the framework to work with non-ground probability queries since we seek to determine probabilities over entire i.i.d. vectors and matrices. Tests for independence on these indexed Bayesian networks are easily developed in Lauritzen’s framework which uses ancestral sets and set separation [9] and is more amenable to a theorem prover than the double negatives of the more widely known d-separation criteria. Given a Bayesian network, some probabilities can easily be extracted by enumerating the component probabilities at each node: § ¥ ¨¦¡ ¡ ¢© Lemma 1. Let be sets of variables over a Bayesian network with . Then descendents and parents hold 4 in the corresponding dependency graph iff the following probability statement holds: £ ¤  ¡ parents B % % 9 C0A@ ! 9  @8 § ¥   ¢   2 ' % % 310  parents    ©¢   £ ¡ !    ' % #!  </p><p>6 0.67900217 <a title="189-lda-6" href="./nips-2002-VIBES%3A_A_Variational_Inference_Engine_for_Bayesian_Networks.html">204 nips-2002-VIBES: A Variational Inference Engine for Bayesian Networks</a></p>
<p>7 0.66520202 <a title="189-lda-7" href="./nips-2002-Exponential_Family_PCA_for_Belief_Compression_in_POMDPs.html">82 nips-2002-Exponential Family PCA for Belief Compression in POMDPs</a></p>
<p>8 0.65760988 <a title="189-lda-8" href="./nips-2002-Categorization_Under_Complexity%3A_A_Unified_MDL_Account_of_Human_Learning_of_Regular_and_Irregular_Categories.html">48 nips-2002-Categorization Under Complexity: A Unified MDL Account of Human Learning of Regular and Irregular Categories</a></p>
<p>9 0.65705132 <a title="189-lda-9" href="./nips-2002-Adaptive_Classification_by_Variational_Kalman_Filtering.html">21 nips-2002-Adaptive Classification by Variational Kalman Filtering</a></p>
<p>10 0.6548903 <a title="189-lda-10" href="./nips-2002-Using_Tarjan%27s_Red_Rule_for_Fast_Dependency_Tree_Construction.html">203 nips-2002-Using Tarjan's Red Rule for Fast Dependency Tree Construction</a></p>
<p>11 0.65315908 <a title="189-lda-11" href="./nips-2002-Real-Time_Particle_Filters.html">169 nips-2002-Real-Time Particle Filters</a></p>
<p>12 0.65269321 <a title="189-lda-12" href="./nips-2002-Discriminative_Densities_from_Maximum_Contrast_Estimation.html">68 nips-2002-Discriminative Densities from Maximum Contrast Estimation</a></p>
<p>13 0.65135354 <a title="189-lda-13" href="./nips-2002-Exact_MAP_Estimates_by_%28Hyper%29tree_Agreement.html">80 nips-2002-Exact MAP Estimates by (Hyper)tree Agreement</a></p>
<p>14 0.65123975 <a title="189-lda-14" href="./nips-2002-Clustering_with_the_Fisher_Score.html">53 nips-2002-Clustering with the Fisher Score</a></p>
<p>15 0.65103006 <a title="189-lda-15" href="./nips-2002-Adaptive_Scaling_for_Feature_Selection_in_SVMs.html">24 nips-2002-Adaptive Scaling for Feature Selection in SVMs</a></p>
<p>16 0.65092325 <a title="189-lda-16" href="./nips-2002-Location_Estimation_with_a_Differential_Update_Network.html">137 nips-2002-Location Estimation with a Differential Update Network</a></p>
<p>17 0.65037721 <a title="189-lda-17" href="./nips-2002-Learning_Sparse_Topographic_Representations_with_Products_of_Student-t_Distributions.html">127 nips-2002-Learning Sparse Topographic Representations with Products of Student-t Distributions</a></p>
<p>18 0.64969361 <a title="189-lda-18" href="./nips-2002-Nash_Propagation_for_Loopy_Graphical_Games.html">152 nips-2002-Nash Propagation for Loopy Graphical Games</a></p>
<p>19 0.64934057 <a title="189-lda-19" href="./nips-2002-An_Impossibility_Theorem_for_Clustering.html">27 nips-2002-An Impossibility Theorem for Clustering</a></p>
<p>20 0.64737046 <a title="189-lda-20" href="./nips-2002-Learning_Graphical_Models_with_Mercer_Kernels.html">124 nips-2002-Learning Graphical Models with Mercer Kernels</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
