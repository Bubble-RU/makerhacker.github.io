<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>50 nips-2002-Circuit Model of Short-Term Synaptic Dynamics</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-50" href="#">nips2002-50</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>50 nips-2002-Circuit Model of Short-Term Synaptic Dynamics</h1>
<br/><p>Source: <a title="nips-2002-50-pdf" href="http://papers.nips.cc/paper/2233-circuit-model-of-short-term-synaptic-dynamics.pdf">pdf</a></p><p>Author: Shih-Chii Liu, Malte Boegershausen, Pascal Suter</p><p>Abstract: We describe a model of short-term synaptic depression that is derived from a silicon circuit implementation. The dynamics of this circuit model are similar to the dynamics of some present theoretical models of shortterm depression except that the recovery dynamics of the variable describing the depression is nonlinear and it also depends on the presynaptic frequency. The equations describing the steady-state and transient responses of this synaptic model ﬁt the experimental results obtained from a fabricated silicon network consisting of leaky integrate-and-ﬁre neurons and different types of synapses. We also show experimental data demonstrating the possible computational roles of depression. One possible role of a depressing synapse is that the input can quickly bring the neuron up to threshold when the membrane potential is close to the resting potential.</p><p>Reference: <a title="nips-2002-50-reference" href="../nips2002_reference/nips-2002-Circuit_Model_of_Short-Term_Synaptic_Dynamics_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 ch  Abstract We describe a model of short-term synaptic depression that is derived from a silicon circuit implementation. [sent-4, score-0.92]
</p><p>2 The dynamics of this circuit model are similar to the dynamics of some present theoretical models of shortterm depression except that the recovery dynamics of the variable describing the depression is nonlinear and it also depends on the presynaptic frequency. [sent-5, score-1.642]
</p><p>3 The equations describing the steady-state and transient responses of this synaptic model ﬁt the experimental results obtained from a fabricated silicon network consisting of leaky integrate-and-ﬁre neurons and different types of synapses. [sent-6, score-0.751]
</p><p>4 One possible role of a depressing synapse is that the input can quickly bring the neuron up to threshold when the membrane potential is close to the resting potential. [sent-8, score-1.108]
</p><p>5 1 Introduction Short-term synaptic dynamics have been observed in many parts of the cortical system [Stratford et al. [sent-9, score-0.565]
</p><p>6 The functionality of the short-term synaptic dynamics have been implicated in various cortical models [Senn et al. [sent-13, score-0.607]
</p><p>7 along with the processing capabilities of a network with dynamic synapses [Tsodyks et al. [sent-16, score-0.317]
</p><p>8 The introduction of these dynamic synapses into hardware implementations of recurrent neuronal networks allow a wide range of operating regimes especially in the case of time-varying inputs. [sent-18, score-0.257]
</p><p>9 In this work, we describe a model that was derived from a circuit implementation of shortterm depression. [sent-19, score-0.353]
</p><p>10 The circuit implementation was initially described by [Rasche and Hahnloser, 2001] but the dynamics were not analyzed in their work. [sent-20, score-0.452]
</p><p>11 We also compare the dynamics of the circuit model of depression with the equations of one of the theoretical models frequently used in network simulations [Abbott et al. [sent-21, score-0.86]
</p><p>12 , 1997] and show examples of transient and steady-state responses of this synaptic circuit to inputs of different statistical distributions. [sent-23, score-0.759]
</p><p>13 This circuit has been included in a silicon network of leaky integrate-and-ﬁre neurons together with other short-term dynamic synapses like facilitation synapses. [sent-24, score-0.72]
</p><p>14 We postulate that one possible role of depression is to bring the neuron’s response quickly up to threshold if the membrane potential of the neuron was close to the resting potential. [sent-26, score-0.805]
</p><p>15 We also mapped a proposed cortical model of direction-selectivity that uses depressing synapses onto this chip. [sent-27, score-0.557]
</p><p>16 The results are qualitatively similar to the results obtained in the original work [Chance et al. [sent-28, score-0.129]
</p><p>17 2 Comparisons between Models of Depression We compare the circuit model with the theoretical model from [Abbott et al. [sent-33, score-0.44]
</p><p>18 Here, we only describe the circuit model for synaptic depression. [sent-36, score-0.596]
</p><p>19 , 1997], the synaptic strength is described by , where is a variable between 0 and 1 that describes the amount of depression ( means no depression) and is the maximum synaptic strength. [sent-40, score-0.842]
</p><p>20 The update equation for spike at time is  ¡  ¡        ¡ © ¥ ¡ ¤    (1) right after a  &$¥ © '%#"¥  ¡ & 1$ ¥ £ § 320¤¡  "§ '$)¦¤¡ © &(¥£  (2) where ( ) is the amount by which is decreased right after the spike and is the time of the spike. [sent-43, score-0.356]
</p><p>21 The average steady-state value of depression for a regular spike train with a rate is  &$ 36¥  7 4  5   RQI H QFED%P1 8   G CB@  $ IHG CB@ 8  2¨6FED¨A1 9 © )$ ¡  (3)  2. [sent-44, score-0.563]
</p><p>22 2 Circuit Model of Depressing Synapse In this circuit model of synaptic depression, the equation that describes the recovery dynamics of the depressing variable, is nonlinear. [sent-45, score-1.347]
</p><p>23 This nonlinearity comes about because the exponential dynamics in Eq. [sent-46, score-0.141]
</p><p>24 1 was replaced with the dynamics of the current through a single diode-connected transistor. [sent-47, score-0.179]
</p><p>25 Hence, the equation describing the recovery of (derived from the circuit in the region where a transistor operates in the subthreshold region or the current is exponential in the gate voltage of the transistor) can be formulated as  ¡  ¡  (4)  WVB ¡   U2¨@ 9UT   ` S #© ¥ ¡   SX Y! [sent-48, score-0.905]
</p><p>26 16  (b)  Figure 1: Schematic for a depressing synapse circuit and responses to a regular input spike train. [sent-68, score-1.227]
</p><p>27 The voltage determines the synaptic conductance while the synaptic term or is exponential in the voltage, . [sent-70, score-0.665]
</p><p>28 The subcircuit consisting of transistors, , , and , control the dynamics of . [sent-71, score-0.141]
</p><p>29 The presynaptic input goes to the gate terminal of which acts like a switch. [sent-72, score-0.203]
</p><p>30 When the presynaptic input comes from a regular spike decreases with each spike and recovers in between spikes. [sent-76, score-0.535]
</p><p>31 During the spike, transistor turns on and the synaptic weight current charges up the membrane potential of the neuron through the currentmirror circuit consisting of , , and the capacitor . [sent-78, score-1.052]
</p><p>32 We can convert the current with some gain and a “time constant” by adjusting the source into a synaptic current voltage . [sent-79, score-0.422]
</p><p>33 The decay dynamics of is given by where  ¨ ¤ ©§ ¦ ¥$  ¡ ¢    S  £      @ S ¨     S  S @ S ¡ ¢  ¦¤ §¥$ £ ¡    ¡     S  ¦¤ §¥$ £  I 8 ( E G R B1 ) A 9 ( P6HBHFESQ C( B@)@ D 8 3 5 1)( I 6( 7643C 20¥'  U © VT  ©¢¨¥0£  £ §  #  £     ¨    ¨    ¨    ¦¤ §$ £  £ " S ! [sent-80, score-0.141]
</p><p>34 In a normal synapse circuit (that is, without shortis controlled by an external bias voltage. [sent-82, score-0.492]
</p><p>35 (b) Input spike train at a term dynamics), frequency of 20 Hz (bottom curve) and corresponding response (top curve) of the circuit for 0. [sent-83, score-0.682]
</p><p>36 The recovery time of the depressing variable depends on the distance of the present value of from . [sent-88, score-0.608]
</p><p>37 The recovery rate of increases for a larger difference between and . [sent-89, score-0.238]
</p><p>38 1 Circuit Equations 4 and 5 are derived from the circuit in Fig. [sent-92, score-0.311]
</p><p>39 The operation of this circuit is described in the caption. [sent-94, score-0.311]
</p><p>40 The conductance is set by while the dynamics of is set by both and . [sent-97, score-0.175]
</p><p>41 The time taken for the present value of to return to is determined by the current dynamics of the diode-connected transistor and . [sent-98, score-0.318]
</p><p>42 8 ¦ q£ © ¨0£ §¥$ £ ¥ fBrY V p §¥ ¦¤ ¦§¤¥$ £ @ S ¡   ¡ S YX  ¡ 7  ¨   ¡    The synaptic weight is described by the current,  in Fig. [sent-101, score-0.285]
</p><p>43 The recovery time constant (  is  ) of  , and  is set by  (  ¦¤ q¥$ £ R8 fB Y 1H Y IV 1 R &¦I d 7D)H `C P2@ C 1 8 V 0¥  '  £  ). [sent-103, score-0.22]
</p><p>44 The synaptic current, to the neuron, is then a current source which lasts for the duration of the pulse width of the presynaptic spike. [sent-104, score-0.417]
</p><p>45 However, we can set a longer time constant for the synaptic current through . [sent-105, score-0.349]
</p><p>46 The equation describing this dependence (that is, the current equation for a current-mirror circuit) is given in the caption of Fig. [sent-106, score-0.176]
</p><p>47 (a) Poisson-distributed input with an initial frequency of 40 Hz and an end frequency of 1 Hz. [sent-113, score-0.269]
</p><p>48 4 for any value of (a transistor parameter which is less than 1). [sent-118, score-0.113]
</p><p>49 This value also changes under different operating conditions and between transistors fabricated in different processes. [sent-119, score-0.112]
</p><p>50 Hence, we solve for in the case of given that the last spike occurred at :  §¥£ ¨0¤¡  a  R §¨¥ '£ S § S ¨¥ '£  ¥  ©   ¥ © #"¥  '54("§ 9¦¤¡ 8¨¥ 3£ 76! [sent-120, score-0.138]
</p><p>51 ¥£  © §¥£ b¨0¤¡     §    ¡ )£ S © ¥ X ¡ R a  S © ¥X ¡ ¡  is far from its recovered value of 1, we can approximate its recovery dynamics by (irrespective of ) and solving for , we get  R  ) 0¥  S © ¨0¤¡ §¥£  a  §¥£ ¨¦¤¡  In this regime, . [sent-122, score-0.335]
</p><p>52 2 1  2  3  0 0  10  Time (s)  (a)  20 30 Frequency (Hz)  40  50  (b)  Figure 3: Transient EPSP responses to a 10 Hz Poisson-distributed train (a) and dependence of steady-state EPSP responses on the input frequency for different values of depression (b). [sent-144, score-0.634]
</p><p>53 In (a), the amplitude of the EPSP decreases with each incoming input spike clearly showing the effect of synaptic depression. [sent-146, score-0.546]
</p><p>54 The asterisks are the ﬁts of the circuit model to the peak value of each EPSP. [sent-148, score-0.348]
</p><p>55 (b) Steady-state EPSP amplitude versus frequency for a Poisson-distributed input. [sent-152, score-0.169]
</p><p>56   3 Comparison between Models  ¡  We compare the two models by looking at how changes in response to a Poissondistributed input whose frequency varied from 40 Hz to 1 Hz as shown in Fig. [sent-154, score-0.27]
</p><p>57 We used a simple linear differential equation to describe the dynamics of the membrane potential :  ¡     §¥£ ¨¦2¢  §¥ ¨0£ ¡    ¨¦2£¡© ¨0£ ¥ ¡    ¡  §¥£¢   §¥  ¡    where is the membrane time constant and is the synaptic current. [sent-156, score-0.718]
</p><p>58 Hence, the circuit model can be used to describe short-term synaptic depression in a network simulation. [sent-162, score-0.875]
</p><p>59 However, the nonlinear recovery dynamics of the circuit model leads a different functional dependence of the average steady-state EPSP on the frequency of a regular input spike train. [sent-163, score-1.057]
</p><p>60 ¡  ¡  4 Circuit Response The data in the ﬁgures in the remainder of this paper are obtained from a fabricated silicon network of aVLSI integrate-and-ﬁre neurons of the type described in [Boahen, 1997, Van Schaik, 2001, Indiveri, 2000, Liu et al. [sent-164, score-0.322]
</p><p>61 1 Transient Response We ﬁrst measured the transient response of the neuron when stimulated by a 10 Hz Poissondistributed input through the depressing synapse. [sent-167, score-0.921]
</p><p>62 We tuned the parameters of the synapse and the leak current so that the membrane potential did not build up to threshold. [sent-168, score-0.345]
</p><p>63 2 Steady-State Response  ¡  The equation describing the dependence of the steady-state values of on the presynaptic frequency can easily be determined in the case of a regular spiking input of rate by using Eqs. [sent-175, score-0.557]
</p><p>64 The form of the curve is similar to the results obtained in the work of [Abbott et al. [sent-178, score-0.182]
</p><p>65 From the chip, we measured the steady-state EPSP amplitudes using a Poisson-distributed train whose frequency varied over a range of 3 Hz to 50 Hz in steps of 1 Hz. [sent-181, score-0.157]
</p><p>66 Each frequency interval lasted 15 s and the EPSP amplitude was averaged in the last 5 s to obtain the steadystate value. [sent-182, score-0.206]
</p><p>67 The parameters from the ﬁts using the response data to a regular spiking input were used to generate the ﬁtted curve to the data in Fig. [sent-185, score-0.36]
</p><p>68 values varying The values from the ﬁts give recovery time constants from 1–3 s and between 0. [sent-187, score-0.22]
</p><p>69 $ )$ ¡  5 Role of Synaptic Depression Different computational roles have been proposed for networks which incorporate synaptic depression. [sent-190, score-0.369]
</p><p>70 , 1998] which makes use of the phase advance property from depressing synapses have been attempted on a neuron on our chip and the direction-selective results were qualitatively similar. [sent-193, score-0.774]
</p><p>71 Depressing synapses have also been implicated in cortical gain control [Abbott et al. [sent-194, score-0.313]
</p><p>72 A depressing synapse acts like a transient detector to changes in frequency (or a ﬁrst derivative ﬁlter). [sent-196, score-0.82]
</p><p>73 A synapse with short-term depression responds equally to equal percentage rate changes in its input on different ﬁring rates. [sent-197, score-0.563]
</p><p>74 We demonstrate the gain-control mechanism of short-term depression by measuring the neuron’s response to step changes in input frequency from 10 Hz to 20 Hz to 40 Hz. [sent-198, score-0.519]
</p><p>75 4(a) for a regular train and in (b) for a Poisson-distributed train. [sent-201, score-0.132]
</p><p>76 Each frequency epoch lasted 3 s so the synaptic strength should have reached steady-state before the next increase in input frequency. [sent-202, score-0.509]
</p><p>77 4, the top curve shows the response of the neuron when stimulated by the input (bottom curve) through a depressing synapse (top curve) and a non-depressing synapse (middle curve). [sent-204, score-1.27]
</p><p>78 Figure 4(a) shows clearly that the transient increase in the ﬁring rate of a neuron when stimulated through a depressing synapse right after each step increase in input frequency and the subsequent adaptation of its ﬁring rate to a steady-state value. [sent-205, score-1.219]
</p><p>79 The steady-state ﬁring rate of the neuron with a depressing synapse is less dependent on the  Poisson spike train  Regular spike train  5  5 4. [sent-206, score-1.172]
</p><p>80 5  0 3  4  5 Time (s)  (a)  6  7  0  2  4  6  8  Time (s)  (b)  Figure 4: Response of neuron to changes in input frequency (bottom curve) when stimulated through a depressing synapse (top curve) and a non-depressing synapse (middle curve). [sent-211, score-1.249]
</p><p>81 The neuron was stimulated for three frequency intervals (10 Hz to 20 Hz to 40 Hz) lasting 3 s each. [sent-212, score-0.41]
</p><p>82 (a) Response of neuron using a regular spiking input. [sent-213, score-0.324]
</p><p>83 The steady-state ﬁring rate of the neuron increased almost linearly with the input frequency when stimulated through the non-depressing synapse. [sent-214, score-0.513]
</p><p>84 In the depressing-synapse curve, there is a transient increase in the neuron’s ﬁring rate before the rate adapted to steady-state. [sent-215, score-0.181]
</p><p>85 The parameters for both types of synapses were tuned so that the steady-state ﬁring rates were about the same at the end of each frequency interval for both synapses. [sent-217, score-0.237]
</p><p>86 Notice that during the 10 Hz interval, the neuron quickly built up to threshold if it was stimulated through the depressing synapse. [sent-218, score-0.778]
</p><p>87 absolute input frequency when compared to the ﬁring rate of the neuron when stimulated through the non-depressing synapse. [sent-219, score-0.513]
</p><p>88 In the latter case, the ﬁring rate of the neuron is approximately linear in the input rate. [sent-220, score-0.282]
</p><p>89 4(b) obtained from a Poisson-distributed train shows an obvious difference in the responses between the depressing and non-depressing synapse. [sent-222, score-0.51]
</p><p>90 In the depressingsynapse case, the neuron quickly reached threshold for a 10 Hz input, while it remained subthreshold in the non-depressing case until the input has increased to 20 Hz. [sent-223, score-0.351]
</p><p>91 This suggests that a potential role of a depressing synapse is to drive a neuron quickly to threshold when its membrane potential is far away from its threshold. [sent-224, score-1.028]
</p><p>92 6 Conclusion We described a model of synaptic depression that was derived from a circuit implementation. [sent-225, score-0.845]
</p><p>93 This circuit model has nonlinear recovery dynamics in contrast to current theoretical models of dynamic synapses. [sent-226, score-0.764]
</p><p>94 Measured data from a chip with aVLSI integrate-and-ﬁre neurons and dynamic synapses show that this network can be used to simulate the responses of dynamic networks with short-term dynamic synapses. [sent-228, score-0.536]
</p><p>95 Experimental results suggest that depressing synapses can be used to drive a neuron quickly up to threshold if its membrane potential is at the resting potential. [sent-229, score-0.95]
</p><p>96 The silicon networks provide an alternative to computer simulation of spike-based processing models with different time constant synapses because they run in real-time and the computational time does not scale with the size of the neuronal network. [sent-230, score-0.331]
</p><p>97 Synaptic depression and the temporal response characteristics of V1 cells. [sent-251, score-0.325]
</p><p>98 Differential short-term synaptic plasticity and transmission of complex spike trains: to depress or to facilitate? [sent-287, score-0.446]
</p><p>99 Excitatory synaptic inputs to spiny stellate cells in cat visual cortex. [sent-308, score-0.285]
</p><p>100 A quantitative description of short-term plasticity at excitatory synapses in layer 2/3 of rat primary visual cortex. [sent-339, score-0.155]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('depressing', 0.388), ('circuit', 0.311), ('synaptic', 0.285), ('depression', 0.249), ('epsp', 0.24), ('recovery', 0.194), ('synapse', 0.181), ('neuron', 0.179), ('hz', 0.176), ('abbott', 0.169), ('tsodyks', 0.166), ('dynamics', 0.141), ('spike', 0.138), ('synapses', 0.132), ('stimulated', 0.126), ('transistor', 0.113), ('frequency', 0.105), ('et', 0.102), ('liu', 0.1), ('presynaptic', 0.094), ('transient', 0.093), ('membrane', 0.083), ('regular', 0.08), ('curve', 0.08), ('response', 0.076), ('silicon', 0.075), ('ring', 0.072), ('markram', 0.07), ('responses', 0.07), ('varela', 0.067), ('indiveri', 0.067), ('spiking', 0.065), ('amplitude', 0.064), ('matveev', 0.064), ('rasche', 0.064), ('schaik', 0.064), ('voltage', 0.061), ('neurons', 0.061), ('avlsi', 0.059), ('input', 0.059), ('hahnloser', 0.055), ('stratford', 0.055), ('zurich', 0.055), ('fabricated', 0.054), ('describing', 0.053), ('dynamic', 0.053), ('train', 0.052), ('chance', 0.052), ('maass', 0.052), ('quickly', 0.051), ('senn', 0.051), ('roles', 0.048), ('chip', 0.048), ('boahen', 0.047), ('zador', 0.044), ('vm', 0.044), ('rate', 0.044), ('potential', 0.043), ('implicated', 0.042), ('poissondistributed', 0.042), ('shortterm', 0.042), ('vpre', 0.042), ('wang', 0.042), ('resting', 0.04), ('nelson', 0.039), ('current', 0.038), ('cortical', 0.037), ('asterisks', 0.037), ('lasted', 0.037), ('networks', 0.036), ('neuronal', 0.036), ('threshold', 0.034), ('conductance', 0.034), ('changes', 0.03), ('ts', 0.03), ('network', 0.03), ('vd', 0.03), ('leaky', 0.03), ('dependence', 0.029), ('differential', 0.029), ('bottom', 0.029), ('transistors', 0.028), ('facilitation', 0.028), ('sen', 0.028), ('subthreshold', 0.028), ('equation', 0.028), ('neuroscience', 0.028), ('qualitatively', 0.027), ('theoretical', 0.027), ('yx', 0.027), ('gate', 0.027), ('region', 0.026), ('role', 0.026), ('recovers', 0.026), ('time', 0.026), ('martin', 0.024), ('bring', 0.024), ('strength', 0.023), ('acts', 0.023), ('plasticity', 0.023)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="50-tfidf-1" href="./nips-2002-Circuit_Model_of_Short-Term_Synaptic_Dynamics.html">50 nips-2002-Circuit Model of Short-Term Synaptic Dynamics</a></p>
<p>Author: Shih-Chii Liu, Malte Boegershausen, Pascal Suter</p><p>Abstract: We describe a model of short-term synaptic depression that is derived from a silicon circuit implementation. The dynamics of this circuit model are similar to the dynamics of some present theoretical models of shortterm depression except that the recovery dynamics of the variable describing the depression is nonlinear and it also depends on the presynaptic frequency. The equations describing the steady-state and transient responses of this synaptic model ﬁt the experimental results obtained from a fabricated silicon network consisting of leaky integrate-and-ﬁre neurons and different types of synapses. We also show experimental data demonstrating the possible computational roles of depression. One possible role of a depressing synapse is that the input can quickly bring the neuron up to threshold when the membrane potential is close to the resting potential.</p><p>2 0.27036667 <a title="50-tfidf-2" href="./nips-2002-Neuromorphic_Bisable_VLSI_Synapses_with_Spike-Timing-Dependent_Plasticity.html">154 nips-2002-Neuromorphic Bisable VLSI Synapses with Spike-Timing-Dependent Plasticity</a></p>
<p>Author: Giacomo Indiveri</p><p>Abstract: We present analog neuromorphic circuits for implementing bistable synapses with spike-timing-dependent plasticity (STDP) properties. In these types of synapses, the short-term dynamics of the synaptic efﬁcacies are governed by the relative timing of the pre- and post-synaptic spikes, while on long time scales the efﬁcacies tend asymptotically to either a potentiated state or to a depressed one. We fabricated a prototype VLSI chip containing a network of integrate and ﬁre neurons interconnected via bistable STDP synapses. Test results from this chip demonstrate the synapse’s STDP learning properties, and its long-term bistable characteristics.</p><p>3 0.26570147 <a title="50-tfidf-3" href="./nips-2002-Learning_in_Spiking_Neural_Assemblies.html">129 nips-2002-Learning in Spiking Neural Assemblies</a></p>
<p>Author: David Barber</p><p>Abstract: We consider a statistical framework for learning in a class of networks of spiking neurons. Our aim is to show how optimal local learning rules can be readily derived once the neural dynamics and desired functionality of the neural assembly have been speciﬁed, in contrast to other models which assume (sub-optimal) learning rules. Within this framework we derive local rules for learning temporal sequences in a model of spiking neurons and demonstrate its superior performance to correlation (Hebbian) based approaches. We further show how to include mechanisms such as synaptic depression and outline how the framework is readily extensible to learning in networks of highly complex spiking neurons. A stochastic quantal vesicle release mechanism is considered and implications on the complexity of learning discussed. 1</p><p>4 0.22612903 <a title="50-tfidf-4" href="./nips-2002-Selectivity_and_Metaplasticity_in_a_Unified_Calcium-Dependent_Model.html">180 nips-2002-Selectivity and Metaplasticity in a Unified Calcium-Dependent Model</a></p>
<p>Author: Luk Chong Yeung, Brian S. Blais, Leon N. Cooper, Harel Z. Shouval</p><p>Abstract: A uniﬁed, biophysically motivated Calcium-Dependent Learning model has been shown to account for various rate-based and spike time-dependent paradigms for inducing synaptic plasticity. Here, we investigate the properties of this model for a multi-synapse neuron that receives inputs with diﬀerent spike-train statistics. In addition, we present a physiological form of metaplasticity, an activity-driven regulation mechanism, that is essential for the robustness of the model. A neuron thus implemented develops stable and selective receptive ﬁelds, given various input statistics 1</p><p>5 0.20546472 <a title="50-tfidf-5" href="./nips-2002-Dynamical_Constraints_on_Computing_with_Spike_Timing_in_the_Cortex.html">76 nips-2002-Dynamical Constraints on Computing with Spike Timing in the Cortex</a></p>
<p>Author: Arunava Banerjee, Alexandre Pouget</p><p>Abstract: If the cortex uses spike timing to compute, the timing of the spikes must be robust to perturbations. Based on a recent framework that provides a simple criterion to determine whether a spike sequence produced by a generic network is sensitive to initial conditions, and numerical simulations of a variety of network architectures, we argue within the limits set by our model of the neuron, that it is unlikely that precise sequences of spike timings are used for computation under conditions typically found in the cortex.</p><p>6 0.20089899 <a title="50-tfidf-6" href="./nips-2002-Spike_Timing-Dependent_Plasticity_in_the_Address_Domain.html">186 nips-2002-Spike Timing-Dependent Plasticity in the Address Domain</a></p>
<p>7 0.19883949 <a title="50-tfidf-7" href="./nips-2002-A_Model_for_Real-Time_Computation_in_Generic_Neural_Microcircuits.html">11 nips-2002-A Model for Real-Time Computation in Generic Neural Microcircuits</a></p>
<p>8 0.16549982 <a title="50-tfidf-8" href="./nips-2002-Hidden_Markov_Model_of_Cortical_Synaptic_Plasticity%3A_Derivation_of_the_Learning_Rule.html">102 nips-2002-Hidden Markov Model of Cortical Synaptic Plasticity: Derivation of the Learning Rule</a></p>
<p>9 0.16452587 <a title="50-tfidf-9" href="./nips-2002-Reconstructing_Stimulus-Driven_Neural_Networks_from_Spike_Times.html">171 nips-2002-Reconstructing Stimulus-Driven Neural Networks from Spike Times</a></p>
<p>10 0.15725683 <a title="50-tfidf-10" href="./nips-2002-Spectro-Temporal_Receptive_Fields_of_Subthreshold_Responses_in_Auditory_Cortex.html">184 nips-2002-Spectro-Temporal Receptive Fields of Subthreshold Responses in Auditory Cortex</a></p>
<p>11 0.15080626 <a title="50-tfidf-11" href="./nips-2002-Binary_Coding_in_Auditory_Cortex.html">43 nips-2002-Binary Coding in Auditory Cortex</a></p>
<p>12 0.14430279 <a title="50-tfidf-12" href="./nips-2002-Adaptive_Quantization_and_Density_Estimation_in_Silicon.html">23 nips-2002-Adaptive Quantization and Density Estimation in Silicon</a></p>
<p>13 0.13133185 <a title="50-tfidf-13" href="./nips-2002-Topographic_Map_Formation_by_Silicon_Growth_Cones.html">200 nips-2002-Topographic Map Formation by Silicon Growth Cones</a></p>
<p>14 0.12581611 <a title="50-tfidf-14" href="./nips-2002-Field-Programmable_Learning_Arrays.html">91 nips-2002-Field-Programmable Learning Arrays</a></p>
<p>15 0.11463729 <a title="50-tfidf-15" href="./nips-2002-Retinal_Processing_Emulation_in_a_Programmable_2-Layer_Analog_Array_Processor_CMOS_Chip.html">177 nips-2002-Retinal Processing Emulation in a Programmable 2-Layer Analog Array Processor CMOS Chip</a></p>
<p>16 0.1145914 <a title="50-tfidf-16" href="./nips-2002-Dopamine_Induced_Bistability_Enhances_Signal_Processing_in_Spiny_Neurons.html">71 nips-2002-Dopamine Induced Bistability Enhances Signal Processing in Spiny Neurons</a></p>
<p>17 0.11008598 <a title="50-tfidf-17" href="./nips-2002-Optoelectronic_Implementation_of_a_FitzHugh-Nagumo_Neural_Model.html">160 nips-2002-Optoelectronic Implementation of a FitzHugh-Nagumo Neural Model</a></p>
<p>18 0.10069097 <a title="50-tfidf-18" href="./nips-2002-A_Differential_Semantics_for_Jointree_Algorithms.html">4 nips-2002-A Differential Semantics for Jointree Algorithms</a></p>
<p>19 0.098026104 <a title="50-tfidf-19" href="./nips-2002-Interpreting_Neural_Response_Variability_as_Monte_Carlo_Sampling_of_the_Posterior.html">116 nips-2002-Interpreting Neural Response Variability as Monte Carlo Sampling of the Posterior</a></p>
<p>20 0.093932085 <a title="50-tfidf-20" href="./nips-2002-Maximally_Informative_Dimensions%3A_Analyzing_Neural_Responses_to_Natural_Signals.html">141 nips-2002-Maximally Informative Dimensions: Analyzing Neural Responses to Natural Signals</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2002_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.186), (1, 0.356), (2, 0.038), (3, -0.169), (4, 0.073), (5, 0.291), (6, 0.161), (7, 0.006), (8, -0.011), (9, -0.064), (10, 0.08), (11, -0.027), (12, -0.058), (13, 0.007), (14, 0.135), (15, -0.008), (16, -0.046), (17, -0.066), (18, 0.068), (19, 0.017), (20, 0.035), (21, 0.009), (22, -0.061), (23, 0.015), (24, 0.01), (25, 0.045), (26, 0.032), (27, -0.005), (28, 0.022), (29, 0.037), (30, -0.05), (31, 0.049), (32, 0.009), (33, 0.015), (34, 0.04), (35, -0.029), (36, 0.03), (37, 0.05), (38, 0.043), (39, -0.023), (40, 0.017), (41, -0.033), (42, -0.062), (43, 0.003), (44, 0.047), (45, -0.088), (46, 0.051), (47, -0.005), (48, -0.069), (49, -0.01)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97352928 <a title="50-lsi-1" href="./nips-2002-Circuit_Model_of_Short-Term_Synaptic_Dynamics.html">50 nips-2002-Circuit Model of Short-Term Synaptic Dynamics</a></p>
<p>Author: Shih-Chii Liu, Malte Boegershausen, Pascal Suter</p><p>Abstract: We describe a model of short-term synaptic depression that is derived from a silicon circuit implementation. The dynamics of this circuit model are similar to the dynamics of some present theoretical models of shortterm depression except that the recovery dynamics of the variable describing the depression is nonlinear and it also depends on the presynaptic frequency. The equations describing the steady-state and transient responses of this synaptic model ﬁt the experimental results obtained from a fabricated silicon network consisting of leaky integrate-and-ﬁre neurons and different types of synapses. We also show experimental data demonstrating the possible computational roles of depression. One possible role of a depressing synapse is that the input can quickly bring the neuron up to threshold when the membrane potential is close to the resting potential.</p><p>2 0.93981528 <a title="50-lsi-2" href="./nips-2002-Neuromorphic_Bisable_VLSI_Synapses_with_Spike-Timing-Dependent_Plasticity.html">154 nips-2002-Neuromorphic Bisable VLSI Synapses with Spike-Timing-Dependent Plasticity</a></p>
<p>Author: Giacomo Indiveri</p><p>Abstract: We present analog neuromorphic circuits for implementing bistable synapses with spike-timing-dependent plasticity (STDP) properties. In these types of synapses, the short-term dynamics of the synaptic efﬁcacies are governed by the relative timing of the pre- and post-synaptic spikes, while on long time scales the efﬁcacies tend asymptotically to either a potentiated state or to a depressed one. We fabricated a prototype VLSI chip containing a network of integrate and ﬁre neurons interconnected via bistable STDP synapses. Test results from this chip demonstrate the synapse’s STDP learning properties, and its long-term bistable characteristics.</p><p>3 0.77201664 <a title="50-lsi-3" href="./nips-2002-Selectivity_and_Metaplasticity_in_a_Unified_Calcium-Dependent_Model.html">180 nips-2002-Selectivity and Metaplasticity in a Unified Calcium-Dependent Model</a></p>
<p>Author: Luk Chong Yeung, Brian S. Blais, Leon N. Cooper, Harel Z. Shouval</p><p>Abstract: A uniﬁed, biophysically motivated Calcium-Dependent Learning model has been shown to account for various rate-based and spike time-dependent paradigms for inducing synaptic plasticity. Here, we investigate the properties of this model for a multi-synapse neuron that receives inputs with diﬀerent spike-train statistics. In addition, we present a physiological form of metaplasticity, an activity-driven regulation mechanism, that is essential for the robustness of the model. A neuron thus implemented develops stable and selective receptive ﬁelds, given various input statistics 1</p><p>4 0.75427812 <a title="50-lsi-4" href="./nips-2002-Spike_Timing-Dependent_Plasticity_in_the_Address_Domain.html">186 nips-2002-Spike Timing-Dependent Plasticity in the Address Domain</a></p>
<p>Author: R. J. Vogelstein, Francesco Tenore, Ralf Philipp, Miriam S. Adlerstein, David H. Goldberg, Gert Cauwenberghs</p><p>Abstract: Address-event representation (AER), originally proposed as a means to communicate sparse neural events between neuromorphic chips, has proven efﬁcient in implementing large-scale networks with arbitrary, conﬁgurable synaptic connectivity. In this work, we further extend the functionality of AER to implement arbitrary, conﬁgurable synaptic plasticity in the address domain. As proof of concept, we implement a biologically inspired form of spike timing-dependent plasticity (STDP) based on relative timing of events in an AER framework. Experimental results from an analog VLSI integrate-and-ﬁre network demonstrate address domain learning in a task that requires neurons to group correlated inputs.</p><p>5 0.67729002 <a title="50-lsi-5" href="./nips-2002-A_Model_for_Real-Time_Computation_in_Generic_Neural_Microcircuits.html">11 nips-2002-A Model for Real-Time Computation in Generic Neural Microcircuits</a></p>
<p>Author: Wolfgang Maass, Thomas Natschläger, Henry Markram</p><p>Abstract: A key challenge for neural modeling is to explain how a continuous stream of multi-modal input from a rapidly changing environment can be processed by stereotypical recurrent circuits of integrate-and-ﬁre neurons in real-time. We propose a new computational model that is based on principles of high dimensional dynamical systems in combination with statistical learning theory. It can be implemented on generic evolved or found recurrent circuitry.</p><p>6 0.63470262 <a title="50-lsi-6" href="./nips-2002-Learning_in_Spiking_Neural_Assemblies.html">129 nips-2002-Learning in Spiking Neural Assemblies</a></p>
<p>7 0.56778163 <a title="50-lsi-7" href="./nips-2002-Optoelectronic_Implementation_of_a_FitzHugh-Nagumo_Neural_Model.html">160 nips-2002-Optoelectronic Implementation of a FitzHugh-Nagumo Neural Model</a></p>
<p>8 0.56465536 <a title="50-lsi-8" href="./nips-2002-Dopamine_Induced_Bistability_Enhances_Signal_Processing_in_Spiny_Neurons.html">71 nips-2002-Dopamine Induced Bistability Enhances Signal Processing in Spiny Neurons</a></p>
<p>9 0.55886906 <a title="50-lsi-9" href="./nips-2002-Retinal_Processing_Emulation_in_a_Programmable_2-Layer_Analog_Array_Processor_CMOS_Chip.html">177 nips-2002-Retinal Processing Emulation in a Programmable 2-Layer Analog Array Processor CMOS Chip</a></p>
<p>10 0.55746728 <a title="50-lsi-10" href="./nips-2002-Field-Programmable_Learning_Arrays.html">91 nips-2002-Field-Programmable Learning Arrays</a></p>
<p>11 0.5501079 <a title="50-lsi-11" href="./nips-2002-Dynamical_Constraints_on_Computing_with_Spike_Timing_in_the_Cortex.html">76 nips-2002-Dynamical Constraints on Computing with Spike Timing in the Cortex</a></p>
<p>12 0.5428347 <a title="50-lsi-12" href="./nips-2002-Hidden_Markov_Model_of_Cortical_Synaptic_Plasticity%3A_Derivation_of_the_Learning_Rule.html">102 nips-2002-Hidden Markov Model of Cortical Synaptic Plasticity: Derivation of the Learning Rule</a></p>
<p>13 0.52803874 <a title="50-lsi-13" href="./nips-2002-Adaptive_Quantization_and_Density_Estimation_in_Silicon.html">23 nips-2002-Adaptive Quantization and Density Estimation in Silicon</a></p>
<p>14 0.52423829 <a title="50-lsi-14" href="./nips-2002-Topographic_Map_Formation_by_Silicon_Growth_Cones.html">200 nips-2002-Topographic Map Formation by Silicon Growth Cones</a></p>
<p>15 0.4974516 <a title="50-lsi-15" href="./nips-2002-Reconstructing_Stimulus-Driven_Neural_Networks_from_Spike_Times.html">171 nips-2002-Reconstructing Stimulus-Driven Neural Networks from Spike Times</a></p>
<p>16 0.4310036 <a title="50-lsi-16" href="./nips-2002-Binary_Coding_in_Auditory_Cortex.html">43 nips-2002-Binary Coding in Auditory Cortex</a></p>
<p>17 0.3943184 <a title="50-lsi-17" href="./nips-2002-A_Differential_Semantics_for_Jointree_Algorithms.html">4 nips-2002-A Differential Semantics for Jointree Algorithms</a></p>
<p>18 0.3665292 <a title="50-lsi-18" href="./nips-2002-A_Digital_Antennal_Lobe_for_Pattern_Equalization%3A_Analysis_and_Design.html">5 nips-2002-A Digital Antennal Lobe for Pattern Equalization: Analysis and Design</a></p>
<p>19 0.35901475 <a title="50-lsi-19" href="./nips-2002-Spectro-Temporal_Receptive_Fields_of_Subthreshold_Responses_in_Auditory_Cortex.html">184 nips-2002-Spectro-Temporal Receptive Fields of Subthreshold Responses in Auditory Cortex</a></p>
<p>20 0.33952704 <a title="50-lsi-20" href="./nips-2002-Binary_Tuning_is_Optimal_for_Neural_Rate_Coding_with_High_Temporal_Resolution.html">44 nips-2002-Binary Tuning is Optimal for Neural Rate Coding with High Temporal Resolution</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2002_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(1, 0.01), (3, 0.028), (11, 0.033), (23, 0.028), (42, 0.048), (54, 0.062), (55, 0.022), (57, 0.013), (58, 0.015), (67, 0.031), (68, 0.07), (74, 0.064), (83, 0.076), (88, 0.2), (92, 0.017), (98, 0.199)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.88101506 <a title="50-lda-1" href="./nips-2002-Circuit_Model_of_Short-Term_Synaptic_Dynamics.html">50 nips-2002-Circuit Model of Short-Term Synaptic Dynamics</a></p>
<p>Author: Shih-Chii Liu, Malte Boegershausen, Pascal Suter</p><p>Abstract: We describe a model of short-term synaptic depression that is derived from a silicon circuit implementation. The dynamics of this circuit model are similar to the dynamics of some present theoretical models of shortterm depression except that the recovery dynamics of the variable describing the depression is nonlinear and it also depends on the presynaptic frequency. The equations describing the steady-state and transient responses of this synaptic model ﬁt the experimental results obtained from a fabricated silicon network consisting of leaky integrate-and-ﬁre neurons and different types of synapses. We also show experimental data demonstrating the possible computational roles of depression. One possible role of a depressing synapse is that the input can quickly bring the neuron up to threshold when the membrane potential is close to the resting potential.</p><p>2 0.69759762 <a title="50-lda-2" href="./nips-2002-FloatBoost_Learning_for_Classification.html">92 nips-2002-FloatBoost Learning for Classification</a></p>
<p>Author: Stan Z. Li, Zhenqiu Zhang, Heung-yeung Shum, Hongjiang Zhang</p><p>Abstract: AdaBoost [3] minimizes an upper error bound which is an exponential function of the margin on the training set [14]. However, the ultimate goal in applications of pattern classiﬁcation is always minimum error rate. On the other hand, AdaBoost needs an effective procedure for learning weak classiﬁers, which by itself is difﬁcult especially for high dimensional data. In this paper, we present a novel procedure, called FloatBoost, for learning a better boosted classiﬁer. FloatBoost uses a backtrack mechanism after each iteration of AdaBoost to remove weak classiﬁers which cause higher error rates. The resulting ﬂoat-boosted classiﬁer consists of fewer weak classiﬁers yet achieves lower error rates than AdaBoost in both training and test. We also propose a statistical model for learning weak classiﬁers, based on a stagewise approximation of the posterior using an overcomplete set of scalar features. Experimental comparisons of FloatBoost and AdaBoost are provided through a difﬁcult classiﬁcation problem, face detection, where the goal is to learn from training examples a highly nonlinear classiﬁer to differentiate between face and nonface patterns in a high dimensional space. The results clearly demonstrate the promises made by FloatBoost over AdaBoost.</p><p>3 0.69680446 <a title="50-lda-3" href="./nips-2002-How_Linear_are_Auditory_Cortical_Responses%3F.html">103 nips-2002-How Linear are Auditory Cortical Responses?</a></p>
<p>Author: Maneesh Sahani, Jennifer F. Linden</p><p>Abstract: By comparison to some other sensory cortices, the functional properties of cells in the primary auditory cortex are not yet well understood. Recent attempts to obtain a generalized description of auditory cortical responses have often relied upon characterization of the spectrotemporal receptive ﬁeld (STRF), which amounts to a model of the stimulusresponse function (SRF) that is linear in the spectrogram of the stimulus. How well can such a model account for neural responses at the very ﬁrst stages of auditory cortical processing? To answer this question, we develop a novel methodology for evaluating the fraction of stimulus-related response power in a population that can be captured by a given type of SRF model. We use this technique to show that, in the thalamo-recipient layers of primary auditory cortex, STRF models account for no more than 40% of the stimulus-related power in neural responses.</p><p>4 0.69363737 <a title="50-lda-4" href="./nips-2002-Learning_in_Spiking_Neural_Assemblies.html">129 nips-2002-Learning in Spiking Neural Assemblies</a></p>
<p>Author: David Barber</p><p>Abstract: We consider a statistical framework for learning in a class of networks of spiking neurons. Our aim is to show how optimal local learning rules can be readily derived once the neural dynamics and desired functionality of the neural assembly have been speciﬁed, in contrast to other models which assume (sub-optimal) learning rules. Within this framework we derive local rules for learning temporal sequences in a model of spiking neurons and demonstrate its superior performance to correlation (Hebbian) based approaches. We further show how to include mechanisms such as synaptic depression and outline how the framework is readily extensible to learning in networks of highly complex spiking neurons. A stochastic quantal vesicle release mechanism is considered and implications on the complexity of learning discussed. 1</p><p>5 0.69171906 <a title="50-lda-5" href="./nips-2002-Fast_Sparse_Gaussian_Process_Methods%3A_The_Informative_Vector_Machine.html">86 nips-2002-Fast Sparse Gaussian Process Methods: The Informative Vector Machine</a></p>
<p>Author: Ralf Herbrich, Neil D. Lawrence, Matthias Seeger</p><p>Abstract: We present a framework for sparse Gaussian process (GP) methods which uses forward selection with criteria based on informationtheoretic principles, previously suggested for active learning. Our goal is not only to learn d–sparse predictors (which can be evaluated in O(d) rather than O(n), d n, n the number of training points), but also to perform training under strong restrictions on time and memory requirements. The scaling of our method is at most O(n · d2 ), and in large real-world classiﬁcation experiments we show that it can match prediction performance of the popular support vector machine (SVM), yet can be signiﬁcantly faster in training. In contrast to the SVM, our approximation produces estimates of predictive probabilities (‘error bars’), allows for Bayesian model selection and is less complex in implementation. 1</p><p>6 0.6872822 <a title="50-lda-6" href="./nips-2002-Evidence_Optimization_Techniques_for_Estimating_Stimulus-Response_Functions.html">79 nips-2002-Evidence Optimization Techniques for Estimating Stimulus-Response Functions</a></p>
<p>7 0.6871103 <a title="50-lda-7" href="./nips-2002-Binary_Coding_in_Auditory_Cortex.html">43 nips-2002-Binary Coding in Auditory Cortex</a></p>
<p>8 0.68207741 <a title="50-lda-8" href="./nips-2002-Hidden_Markov_Model_of_Cortical_Synaptic_Plasticity%3A_Derivation_of_the_Learning_Rule.html">102 nips-2002-Hidden Markov Model of Cortical Synaptic Plasticity: Derivation of the Learning Rule</a></p>
<p>9 0.67869163 <a title="50-lda-9" href="./nips-2002-Spectro-Temporal_Receptive_Fields_of_Subthreshold_Responses_in_Auditory_Cortex.html">184 nips-2002-Spectro-Temporal Receptive Fields of Subthreshold Responses in Auditory Cortex</a></p>
<p>10 0.67731655 <a title="50-lda-10" href="./nips-2002-Constraint_Classification_for_Multiclass_Classification_and_Ranking.html">59 nips-2002-Constraint Classification for Multiclass Classification and Ranking</a></p>
<p>11 0.67414701 <a title="50-lda-11" href="./nips-2002-Concentration_Inequalities_for_the_Missing_Mass_and_for_Histogram_Rule_Error.html">56 nips-2002-Concentration Inequalities for the Missing Mass and for Histogram Rule Error</a></p>
<p>12 0.66866577 <a title="50-lda-12" href="./nips-2002-A_Model_for_Real-Time_Computation_in_Generic_Neural_Microcircuits.html">11 nips-2002-A Model for Real-Time Computation in Generic Neural Microcircuits</a></p>
<p>13 0.66729665 <a title="50-lda-13" href="./nips-2002-Dynamic_Bayesian_Networks_with_Deterministic_Latent_Tables.html">73 nips-2002-Dynamic Bayesian Networks with Deterministic Latent Tables</a></p>
<p>14 0.66569424 <a title="50-lda-14" href="./nips-2002-Bayesian_Monte_Carlo.html">41 nips-2002-Bayesian Monte Carlo</a></p>
<p>15 0.66478807 <a title="50-lda-15" href="./nips-2002-Timing_and_Partial_Observability_in_the_Dopamine_System.html">199 nips-2002-Timing and Partial Observability in the Dopamine System</a></p>
<p>16 0.66232389 <a title="50-lda-16" href="./nips-2002-Selectivity_and_Metaplasticity_in_a_Unified_Calcium-Dependent_Model.html">180 nips-2002-Selectivity and Metaplasticity in a Unified Calcium-Dependent Model</a></p>
<p>17 0.65662748 <a title="50-lda-17" href="./nips-2002-Incremental_Gaussian_Processes.html">110 nips-2002-Incremental Gaussian Processes</a></p>
<p>18 0.65643036 <a title="50-lda-18" href="./nips-2002-Spike_Timing-Dependent_Plasticity_in_the_Address_Domain.html">186 nips-2002-Spike Timing-Dependent Plasticity in the Address Domain</a></p>
<p>19 0.65456116 <a title="50-lda-19" href="./nips-2002-Real-Time_Monitoring_of_Complex_Industrial_Processes_with_Particle_Filters.html">168 nips-2002-Real-Time Monitoring of Complex Industrial Processes with Particle Filters</a></p>
<p>20 0.65337986 <a title="50-lda-20" href="./nips-2002-A_Neural_Edge-Detection_Model_for_Enhanced_Auditory_Sensitivity_in_Modulated_Noise.html">12 nips-2002-A Neural Edge-Detection Model for Enhanced Auditory Sensitivity in Modulated Noise</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
