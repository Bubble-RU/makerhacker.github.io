<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>66 nips-2002-Developing Topography and Ocular Dominance Using Two aVLSI Vision Sensors and a Neurotrophic Model of Plasticity</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-66" href="#">nips2002-66</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>66 nips-2002-Developing Topography and Ocular Dominance Using Two aVLSI Vision Sensors and a Neurotrophic Model of Plasticity</h1>
<br/><p>Source: <a title="nips-2002-66-pdf" href="http://papers.nips.cc/paper/2326-developing-topography-and-ocular-dominance-using-two-avlsi-vision-sensors-and-a-neurotrophic-model-of-plasticity.pdf">pdf</a></p><p>Author: Terry Elliott, Jörg Kramer</p><p>Abstract: A neurotrophic model for the co-development of topography and ocular dominance columns in the primary visual cortex has recently been proposed. In the present work, we test this model by driving it with the output of a pair of neuronal vision sensors stimulated by disparate moving patterns. We show that the temporal correlations in the spike trains generated by the two sensors elicit the development of reﬁned topography and ocular dominance columns, even in the presence of signiﬁcant amounts of spontaneous activity and ﬁxed-pattern noise in the sensors.</p><p>Reference: <a title="nips-2002-66-reference" href="../nips2002_reference/nips-2002-Developing_Topography_and_Ocular_Dominance_Using_Two_aVLSI_Vision_Sensors_and_a_Neurotrophic_Model_of_Plasticity_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 ch  Abstract A neurotrophic model for the co-development of topography and ocular dominance columns in the primary visual cortex has recently been proposed. [sent-8, score-0.609]
</p><p>2 In the present work, we test this model by driving it with the output of a pair of neuronal vision sensors stimulated by disparate moving patterns. [sent-9, score-0.435]
</p><p>3 We show that the temporal correlations in the spike trains generated by the two sensors elicit the development of reﬁned topography and ocular dominance columns, even in the presence of signiﬁcant amounts of spontaneous activity and ﬁxed-pattern noise in the sensors. [sent-10, score-1.038]
</p><p>4 Experimental ﬁndings indicate that at least in the case of ODC formation, this competition may be mediated by retrograde neurotrophic factors (NTFs) [2]. [sent-13, score-0.178]
</p><p>5 This model has successfully been applied to the development and reﬁnement of retinotopic representations in the LGN and striate cortex, and to the formation of ODCs in the striate cortex due to competition between the eye-speciﬁc laminae of the LGN. [sent-15, score-0.399]
</p><p>6 In this model, the activity within the afferent cell sheets was simulated either as interocularly uncorrelated spontaneous retinal waves or, as a coarse model of visually evoked activity, as interocularly correlated Gaussian noise. [sent-16, score-1.162]
</p><p>7 Gaussian noise, however, is not a realistic model of evoked retinal activity, nor do the interocular correlations introduced adequately capture the correlations that arise due to the spatial disparity between the two retinas. [sent-17, score-0.507]
</p><p>8 For this study, we tested the ability of the plasticity model to generate topographic reﬁnement and ODCs in response to afferent activity provided by a pair of biologically-inspired  artiﬁcial vision sensors. [sent-18, score-0.881]
</p><p>9 These sensors capture some of the properties of biological retinas. [sent-19, score-0.209]
</p><p>10 Their output is encoded in asynchronous, binary spike trains, as provided by the retinal ganglion cells of biological retinas. [sent-21, score-0.169]
</p><p>11 Mismatch of processing elements and temporal noise are a natural by-product of biological retinas and such vision sensors alike. [sent-22, score-0.322]
</p><p>12 In particular, the dependence of ODC formation on disparity and noise is considered. [sent-25, score-0.46]
</p><p>13 2 Vision Sensor     The vision sensor used in the experiments is a two-dimensional array of 16 16 pixels fabricated with standard CMOS technology, where each pixel performs a two-way rectiﬁed temporal high-pass ﬁltering operation on the incoming visual signal in the focal plane [4, 5]. [sent-26, score-0.484]
</p><p>14 The sensor adapts to background illuminance and responds to local positive and negative illuminance transients at separately coded terminals. [sent-27, score-0.264]
</p><p>15 The transients are converted into a stream of asynchronous binary pulses, which are multiplexed onto a common, arbitrated address bus, where the address encodes the location of the sending pixel and the sign of the transient. [sent-28, score-0.268]
</p><p>16 In the absence of any activity on the communication bus for a few hundred milliseconds the bus address decays to zero. [sent-29, score-0.307]
</p><p>17 ¤ ¢ ¥£¡  © § £¨¦  Arbiter tree  111 ON  110  ACK  OFF  101 ON  100 OFF  011 ON  010 OFF  001 ON  OFF  000  Handshaking  REQ X address Y address  00  Arbiter tree  10  Handshaking  01  11  Figure 1: Block diagram of the sensor architecture (reduced resolution). [sent-33, score-0.241]
</p><p>18 Together with these gain controls, a threshold bias sets the contrast  response threshold and the rate of spontaneous activity. [sent-37, score-0.249]
</p><p>19 For sufﬁciently large thresholds, spontaneous activity is completely suppressed. [sent-38, score-0.278]
</p><p>20 Another bias control sets a refractory period that limits the maximum spike rate of each pixel. [sent-39, score-0.197]
</p><p>21 For short refractory periods, each contrast transient at a given pixel triggers a burst of spikes; for long refractory periods, a typical transient only triggers a single spike in the pixel, resulting in a very efﬁcient, one-bit edge coding. [sent-40, score-0.428]
</p><p>22 3 Sensor-Computer Interface The two vision sensors were coupled to a computer via two parallel ports. [sent-41, score-0.258]
</p><p>23 The handshaking terminals of each chip were shorted, so that the sensors could operate at their own speed without being artiﬁcially slowed down by the computer. [sent-42, score-0.324]
</p><p>24 The lack of synchronization entailed several problems: missing out on events, reading events more than once, and reading spurious zero addresses in the absence of recent activity in the sensors. [sent-45, score-0.26]
</p><p>25 Furthermore, the refractory period prevented any given pixel from spiking more than once in a row in response to a moving edge, so that multiple reads of the same address were always due to the same event being read several times and therefore could be discarded. [sent-48, score-0.329]
</p><p>26 The ambiguity of the (0,0) address readings, namely whether such a reading meant that the (0,0) pixel was active or that the address on the bus had decayed to zero due to lack of activity, could not be resolved. [sent-49, score-0.264]
</p><p>27 4 Visual Stimulation Two separate windows within the display of the LCD monitor of the computer used for data acquisition were each imaged onto one of the vision chips via a lens to provide the optical stimulation. [sent-52, score-0.19]
</p><p>28 Each sequence simulated a white bar sweeping across a black background. [sent-54, score-0.176]
</p><p>29 The bar could have four different orientations, aligned to the rows or columns of the vision sensor or to one of the two diagonals, and move in either direction. [sent-56, score-0.406]
</p><p>30 The bars had a ﬁnite width of 20 pixels on the LCD display, corresponding to about 8 pixel periods on the image sensors, and they were sufﬁciently long entirely to ﬁll the ﬁeld of view of the chips. [sent-57, score-0.289]
</p><p>31 The displays in the two windows stimulating the two chips were identical save for a ﬁxed relative displacement between the bars along the direction of motion during the entire run, simulating the disparity seen by two eyes looking at the same object. [sent-58, score-0.384]
</p><p>32 The used displacements were 0, 10, and 15 pixels on the LCD display, corresponding to no disparity and disparities of 1/2 the bar width (4 sensor pixels) and 3/4 of the bar width (6 sensor pixels), respectively. [sent-59, score-1.239]
</p><p>33 The speed of the bar was largely unimportant, because the output spikes of the chip were sampled into bins of ﬁxed sizes, rather than bins representing ﬁxed time windows. [sent-60, score-0.262]
</p><p>34 The chosen white bar on a black background stimulated the vision sensor with a leading ON edge and a trailing OFF edge. [sent-61, score-0.463]
</p><p>35 However, because the spurious activity of the chip, mainly in the form of crosstalk, was increased if both ON and OFF responses were activated and because we required only the response to one edge type for this work, the ON responses from the chip were suppressed. [sent-62, score-0.29]
</p><p>36 5 Neurotrophic Model of Plasticity Let the letters and label afferent cells within an afferent sheet, letters and label the afferent sheets, and letters and label target cells. [sent-63, score-1.505]
</p><p>37 The two afferent sheets represent the two chips’ arrays of pixels and are therefore 16 16 square arrays of cells. [sent-64, score-0.764]
</p><p>38 For convenience, the target array is also a 16 16 square array of cells. [sent-65, score-0.172]
</p><p>39 A pixel that has not spiked gives If represents the number of synapses projected from cell in afferent sheet to target , then evolves according to the equation  £  ¢    §© ¦  ¢  ¡  ¤          §© ¦     6  ¥     §¨¦ ©  (1)  R SI P QI ¦ 0(@¦  EFCDB8 42 8 A 3 # $ ' 8 6 89675 © §  % §" ! [sent-69, score-0.899]
</p><p>40 The function is a simple model for the number of NTF receptors supported by an afferent cell, where denotes average afferent activity. [sent-72, score-0.914]
</p><p>41 § ©   ¦  § f ec ¦  § 5 ¨© db© 3   w ¦   p Dv  R I  C  a   h  E  §© c ¦  t rY  usi a q ihg% p Y   %  P I  Both afferent sheets initially project roughly equally to all cells in the target sheet. [sent-78, score-0.728]
</p><p>42 For a given afferent cell, let be the distance between some target cell and the target cell to which the afferent cell would project were topography perfect; let be the maximum such distance. [sent-80, score-1.527]
</p><p>43 Then the number of synapses projected by the afferent cell to this target cell is initially set to be proportional to  ! [sent-81, score-0.749]
</p><p>44 where is a randomly selected number for each such pair of afferent and target determines the quality of the projections, with cells. [sent-85, score-0.547]
</p><p>45 The parameter giving initially greatest topographical bias, so that an afferent cell projects maximally to its topographically preferred target cell, and giving initially completely random ; the impact of decreasing on the ﬁnal structure of the projections. [sent-86, score-0.648]
</p><p>46 Here we set topographic map has been thoroughly explored elsewhere [3]. [sent-87, score-0.189]
</p><p>47 The bin size determines the correlation space constants of the afferent cell sheets and therefore inﬂuences the ﬁnal quality of the topographic mapping [3]. [sent-90, score-0.849]
</p><p>48 Unless otherwise noted the bin size was 32 per sensor, which corresponds to about two successive pixel rows stimulated by a moving contrast boundary. [sent-91, score-0.187]
</p><p>49 (a)  (b)  (c)  Figure 2: Distribution of ODCs in the target cell sheet for different disparities between the bar stimuli driving the two afferent sheets. [sent-93, score-1.126]
</p><p>50 The gray level of each target cell indicates the relative strengths of projections from the two afferent sheets, where ‘black’ represents one and ‘white’ the other afferent sheet. [sent-94, score-1.135]
</p><p>51 (a) No disparity; (b) disparity: 50% of bar width (4 sensor pixels); (c) disparity: 75% of bar width (6 sensor pixels). [sent-95, score-0.732]
</p><p>52 Several runs were performed for the three different disparities of the stimuli presented to the two sensors. [sent-96, score-0.174]
</p><p>53 Since the results for a given disparity were all qualitatively similar, we only show the results of one representative run for each value. [sent-97, score-0.337]
</p><p>54 The distribution of the formed ODCs in the target sheet is shown in Fig. [sent-98, score-0.265]
</p><p>55 2, where the shading of each neuron indicates the relative numbers of projections from the two afferent sheets. [sent-99, score-0.487]
</p><p>56 In the absence of any disparity the formation of ODCs was suppressed. [sent-100, score-0.465]
</p><p>57 The residual ocular dominance modulations may be attributed to a small misalignment of the two chips with respect to the display. [sent-101, score-0.281]
</p><p>58 With the introduction of a disparity a very clear structure of ODCs emerges. [sent-102, score-0.337]
</p><p>59 The distribution of ODCs strongly depends on the disparity and does not vary signiﬁcantly between runs for a given disparity. [sent-103, score-0.376]
</p><p>60 With increasing disparity the boundaries between ODCs become more distinct [9, 10]. [sent-104, score-0.337]
</p><p>61 The obtained maps are qualitatively similar to those obtained with simulated afferent inputs [1]. [sent-105, score-0.535]
</p><p>62 05 0  0  2  4  6  8 10 Frequency  12  14  16  Figure 3: Power spectra of the spatial frequency distribution of ODCs in the target cell sheet for different disparities and data sets. [sent-112, score-0.436]
</p><p>63 A ‘solid’ line denotes data with disparity of 75% of bar width (6 sensor pixels); a ‘dashed’ line denotes a disparity of 50% of bar width (4 sensor pixels); a ‘dotted’ line denotes no disparity. [sent-113, score-1.406]
</p><p>64 3, show that the spatial frequency content of the ODCs is a function of disparity, consistent with experimental ﬁndings in the cat [8, 11, 12, 13], and that its variability between different runs of the same disparity is signiﬁcantly smaller than between different disparities. [sent-115, score-0.411]
</p><p>65 The principal spatial frequency along each dimension of the target sheet is mainly determined by the NTF diffusion parameter [1] and the disparity. [sent-116, score-0.314]
</p><p>66 (a)  (b)  (c)  Figure 4: Topographic mapping between afferent sheets and target sheet for different disparities between the stimuli driving the two afferent sheets. [sent-119, score-1.48]
</p><p>67 (a) No disparity; (b) disparity: 50% of bar width (4 sensor pixels); (c) disparity: 75% of bar width (6 sensor pixels). [sent-122, score-0.732]
</p><p>68 The resulting topographic maps for the same runs are shown in Fig. [sent-123, score-0.234]
</p><p>69 In the absence of disparity the topographic map is almost perfect, with nearly one-to-one mapping between the afferent sheets and the target sheet, apart from remaining edge effects. [sent-125, score-1.285]
</p><p>70 However, disruptions appear at ODC boundaries in the runs with disparate stimuli, these disruptions becoming more distinct with increasing disparity due to the increasing sharpness of ODC boundaries. [sent-126, score-0.519]
</p><p>71 The data presented above were obtained under suppression of spontaneous ﬁring, so that each pixel generated exactly one spike in response to each moving bright-to-dark contrast boundary with an error rate of about 5%. [sent-127, score-0.403]
</p><p>72 By turning up the spontaneous ﬁring rate we can test the robustness of the system to increased noise levels. [sent-128, score-0.261]
</p><p>73 We set the spontaneous ﬁring rate to approximately 50%, so that roughly half of all spikes are not associated with an edge event. [sent-129, score-0.282]
</p><p>74 We also increased the bin size from 32 to 48 spikes per chip to compensate for the reduced intraocular correlations as a result of increased noise [3]. [sent-130, score-0.272]
</p><p>75 5 shows a typical pattern of ODCs and the corresponding topographic map in the presence of 50% spontaneous activity. [sent-132, score-0.415]
</p><p>76 Although there are some distortions in the topographic map, in general it compares very favourably to maps developed in the absence of spontaneous activity. [sent-133, score-0.425]
</p><p>77 At an approximately 60% level of noise major disruptions in topographic map formation and attenuated ODC development are exhibited. [sent-134, score-0.425]
</p><p>78 Increasing the level of noise still further causes a complete breakdown of topographic and ODC map formation (data not shown). [sent-135, score-0.312]
</p><p>79 (a)  (b)  Figure 5: The pattern of ODCs and the topographic map that develop in the presence of approximately 50% noise. [sent-136, score-0.223]
</p><p>80 The disparity is 50% of the bar width (4 sensor pixels). [sent-138, score-0.703]
</p><p>81 Despite the different structure of the input stimuli and the different noise characteristics of the real sensors from those used in the pure simulations [1], the results are comparable. [sent-140, score-0.276]
</p><p>82 Several parameters of the vision sensors, such as refractory period and spontaneous ﬁring rate, can be continuously varied with input bias voltages. [sent-141, score-0.422]
</p><p>83 The sensors were operated at long refractory periods, so that each pixel responded with a single spike to a contrast boundary moving across it. [sent-143, score-0.446]
</p><p>84 The noise induced by the vision sensors manifests itself in occasionally missing responses of some pixels to a moving edge, in temporal jitter and a tunable level of spontaneous activity. [sent-145, score-0.642]
</p><p>85 With an optimal suppression of spontaneous ﬁring, the error rate (number of missed and spurious events divided by total number of events) can be reduced to approximately 5%. [sent-146, score-0.264]
</p><p>86 Increased spontaneous activity levels show a strongly anisotropic distribution across the sensing arrays because of the inherent ﬁxed-pattern noise present in the integrated sensors due to random mismatches in the fabricated circuits. [sent-147, score-0.583]
</p><p>87 Spontaneous activity and mismatches between cells with the same functional role are prominent features of biological neural systems and biological information processing systems therefore have to deal with these nonidealities. [sent-149, score-0.192]
</p><p>88 The developed ODC and topographic maps depend quite strongly on the disparity between the two sensors. [sent-151, score-0.532]
</p><p>89 At zero disparity, the formation of ODCs is practically suppressed and topography becomes very smooth. [sent-152, score-0.22]
</p><p>90 As the disparity increases, the period of the resulting ODCs increases, consistent with experimental results in the cat [8, 11, 12, 13], and, as expected, the degree of segregation also increases [9, 10]. [sent-153, score-0.408]
</p><p>91 In the presence of high levels of spontaneous activity in the afferent pathways, with as much as half of all spikes not being stimulus–related, the maps continue to exhibit well developed ODCs and topography. [sent-154, score-0.863]
</p><p>92 Although there are indications of distortions in the topographic maps in the presence of  approximately 50% spontaneous activity, the maps remain globally well structured. [sent-155, score-0.462]
</p><p>93 As spontaneous activity is increased further, map development becomes increasingly disrupted until it breaks down completely. [sent-156, score-0.409]
</p><p>94 8 Conclusions We examined the reﬁnement of topographic mappings and the formation of ocular dominance columns by coupling a pair of integrated vision sensors to a neurotrophic model of synaptic plasticity. [sent-157, score-0.995]
</p><p>95 We have shown that the afferent input from real sensors looking at moving bar stimuli yields similar results as simulated partially randomized input and that these results are insensitive to the presence of signiﬁcant noise levels. [sent-158, score-1.002]
</p><p>96 Shadbolt, “A neurotrophic model of the development of the retinogeniculocortical pathway induced by spontaneous retinal waves,” Journal of Neuroscience, vol. [sent-167, score-0.466]
</p><p>97 Kramer, “Coupling an aVLSI neuromorphic vision chip to a neurotrophic model of synaptic plasticity: the development of topography,” Neural Computation, vol. [sent-181, score-0.406]
</p><p>98 Shadbolt, “Multiplicative synaptic normalization and a nonlinear Hebb rule underlie a neurotrophic model of competitive synaptic plasticity,” Neural Computation, vol. [sent-197, score-0.255]
</p><p>99 L¨ owel, “Ocular dominance column development: Strabismus changes the spacing of adjacent columns in cat visual cortex,” Journal of Neuroscience, vol. [sent-227, score-0.216]
</p><p>100 L¨ owel, “Theory meets experiment: correlated neural activity helps determine ocular dominance column periodicity,” Trends in Neurosciences, vol. [sent-233, score-0.32]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('afferent', 0.457), ('disparity', 0.337), ('odcs', 0.315), ('spontaneous', 0.192), ('sensors', 0.178), ('sheet', 0.175), ('odc', 0.158), ('sensor', 0.155), ('topographic', 0.154), ('bar', 0.139), ('sheets', 0.137), ('neurotrophic', 0.137), ('topography', 0.13), ('dominance', 0.117), ('ocular', 0.117), ('ntf', 0.105), ('cell', 0.101), ('pixels', 0.1), ('target', 0.09), ('formation', 0.09), ('activity', 0.086), ('refractory', 0.086), ('vision', 0.08), ('pixel', 0.076), ('elliott', 0.076), ('handshaking', 0.076), ('plasticity', 0.075), ('kramer', 0.073), ('width', 0.072), ('chip', 0.07), ('disparities', 0.07), ('bus', 0.07), ('stimuli', 0.065), ('nement', 0.064), ('development', 0.06), ('moving', 0.059), ('synaptic', 0.059), ('disruptions', 0.053), ('imager', 0.053), ('lcd', 0.053), ('spikes', 0.053), ('stimulated', 0.052), ('diffusion', 0.049), ('transient', 0.048), ('spike', 0.047), ('retinal', 0.047), ('striate', 0.047), ('chips', 0.047), ('goodhill', 0.046), ('shadbolt', 0.046), ('cells', 0.044), ('cortex', 0.044), ('correlations', 0.044), ('address', 0.043), ('competition', 0.041), ('periods', 0.041), ('array', 0.041), ('maps', 0.041), ('events', 0.04), ('transients', 0.039), ('runs', 0.039), ('absence', 0.038), ('simulated', 0.037), ('asynchronous', 0.037), ('disparate', 0.037), ('edge', 0.037), ('optical', 0.036), ('increased', 0.036), ('period', 0.036), ('cat', 0.035), ('arbiter', 0.035), ('illuminance', 0.035), ('interocularly', 0.035), ('laminae', 0.035), ('owel', 0.035), ('retinotopic', 0.035), ('southampton', 0.035), ('evoked', 0.035), ('arrays', 0.035), ('te', 0.035), ('map', 0.035), ('presence', 0.034), ('noise', 0.033), ('ring', 0.033), ('spurious', 0.032), ('reading', 0.032), ('columns', 0.032), ('visual', 0.032), ('biological', 0.031), ('integrated', 0.031), ('lgn', 0.03), ('multiplexed', 0.03), ('retinogeniculocortical', 0.03), ('projections', 0.03), ('response', 0.029), ('driving', 0.029), ('wiesel', 0.028), ('sensing', 0.028), ('bias', 0.028), ('display', 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999911 <a title="66-tfidf-1" href="./nips-2002-Developing_Topography_and_Ocular_Dominance_Using_Two_aVLSI_Vision_Sensors_and_a_Neurotrophic_Model_of_Plasticity.html">66 nips-2002-Developing Topography and Ocular Dominance Using Two aVLSI Vision Sensors and a Neurotrophic Model of Plasticity</a></p>
<p>Author: Terry Elliott, Jörg Kramer</p><p>Abstract: A neurotrophic model for the co-development of topography and ocular dominance columns in the primary visual cortex has recently been proposed. In the present work, we test this model by driving it with the output of a pair of neuronal vision sensors stimulated by disparate moving patterns. We show that the temporal correlations in the spike trains generated by the two sensors elicit the development of reﬁned topography and ocular dominance columns, even in the presence of signiﬁcant amounts of spontaneous activity and ﬁxed-pattern noise in the sensors.</p><p>2 0.17768115 <a title="66-tfidf-2" href="./nips-2002-Kernel-Based_Extraction_of_Slow_Features%3A_Complex_Cells_Learn_Disparity_and_Translation_Invariance_from_Natural_Images.html">118 nips-2002-Kernel-Based Extraction of Slow Features: Complex Cells Learn Disparity and Translation Invariance from Natural Images</a></p>
<p>Author: Alistair Bray, Dominique Martinez</p><p>Abstract: In Slow Feature Analysis (SFA [1]), it has been demonstrated that high-order invariant properties can be extracted by projecting inputs into a nonlinear space and computing the slowest changing features in this space; this has been proposed as a simple general model for learning nonlinear invariances in the visual system. However, this method is highly constrained by the curse of dimensionality which limits it to simple theoretical simulations. This paper demonstrates that by using a different but closely-related objective function for extracting slowly varying features ([2, 3]), and then exploiting the kernel trick, this curse can be avoided. Using this new method we show that both the complex cell properties of translation invariance and disparity coding can be learnt simultaneously from natural images when complex cells are driven by simple cells also learnt from the image. The notion of maximising an objective function based upon the temporal predictability of output has been progressively applied in modelling the development of invariances in the visual system. F6ldiak used it indirectly via a Hebbian trace rule for modelling the development of translation invariance in complex cells [4] (closely related to many other models [5,6,7]); this rule has been used to maximise invariance as one component of a hierarchical system for object and face recognition [8]. On the other hand, similar functions have been maximised directly in networks for extracting linear [2] and nonlinear [9, 1] visual invariances. Direct maximisation of such functions have recently been used to model complex cells [10] and as an alternative to maximising sparseness/independence in modelling simple cells [11]. Slow Feature Analysis [1] combines many of the best properties of these methods to provide a good general nonlinear model. That is, it uses an objective function that minimises the first-order temporal derivative of the outputs; it provides a closedform solution which maximises this function by projecting inputs into a nonlinear http://www.loria.fr/equipes/cortex/ space; it exploits sphering (or PCA-whitening) of the data to ensure that all outputs have unit variance and are uncorrelated. However, the method suffers from the curse of dimensionality in that the nonlinear feature space soon becomes very large as the input dimension grows, and yet this feature space must be represented explicitly in order for the essential sphering to occur. The alternative that we propose here is to use the objective function of Stone [2, 9], that maximises output variance over a long period whilst minimising variance over a shorter period; in the linear case, this can be implemented by a biologically plausible mixture of Hebbian and anti-Hebbian learning on the same synapses [2]. In recent work, Stone has proposed a closed-form solution for maximising this function in the linear domain of blind source separation that does not involve data-sphering. This paper describes how this method can be kernelised. The use of the</p><p>3 0.11534818 <a title="66-tfidf-3" href="./nips-2002-Visual_Development_Aids_the_Acquisition_of_Motion_Velocity_Sensitivities.html">206 nips-2002-Visual Development Aids the Acquisition of Motion Velocity Sensitivities</a></p>
<p>Author: Robert A. Jacobs, Melissa Dominguez</p><p>Abstract: We consider the hypothesis that systems learning aspects of visual perception may beneﬁt from the use of suitably designed developmental progressions during training. Four models were trained to estimate motion velocities in sequences of visual images. Three of the models were “developmental models” in the sense that the nature of their input changed during the course of training. They received a relatively impoverished visual input early in training, and the quality of this input improved as training progressed. One model used a coarse-to-multiscale developmental progression (i.e. it received coarse-scale motion features early in training and ﬁner-scale features were added to its input as training progressed), another model used a ﬁne-to-multiscale progression, and the third model used a random progression. The ﬁnal model was nondevelopmental in the sense that the nature of its input remained the same throughout the training period. The simulation results show that the coarse-to-multiscale model performed best. Hypotheses are offered to account for this model’s superior performance. We conclude that suitably designed developmental sequences can be useful to systems learning to estimate motion velocities. The idea that visual development can aid visual learning is a viable hypothesis in need of further study.</p><p>4 0.10597689 <a title="66-tfidf-4" href="./nips-2002-An_Information_Theoretic_Approach_to_the_Functional_Classification_of_Neurons.html">28 nips-2002-An Information Theoretic Approach to the Functional Classification of Neurons</a></p>
<p>Author: Elad Schneidman, William Bialek, Michael Ii</p><p>Abstract: A population of neurons typically exhibits a broad diversity of responses to sensory inputs. The intuitive notion of functional classiﬁcation is that cells can be clustered so that most of the diversity is captured by the identity of the clusters rather than by individuals within clusters. We show how this intuition can be made precise using information theory, without any need to introduce a metric on the space of stimuli or responses. Applied to the retinal ganglion cells of the salamander, this approach recovers classical results, but also provides clear evidence for subclasses beyond those identiﬁed previously. Further, we ﬁnd that each of the ganglion cells is functionally unique, and that even within the same subclass only a few spikes are needed to reliably distinguish between cells. 1</p><p>5 0.10355357 <a title="66-tfidf-5" href="./nips-2002-Spike_Timing-Dependent_Plasticity_in_the_Address_Domain.html">186 nips-2002-Spike Timing-Dependent Plasticity in the Address Domain</a></p>
<p>Author: R. J. Vogelstein, Francesco Tenore, Ralf Philipp, Miriam S. Adlerstein, David H. Goldberg, Gert Cauwenberghs</p><p>Abstract: Address-event representation (AER), originally proposed as a means to communicate sparse neural events between neuromorphic chips, has proven efﬁcient in implementing large-scale networks with arbitrary, conﬁgurable synaptic connectivity. In this work, we further extend the functionality of AER to implement arbitrary, conﬁgurable synaptic plasticity in the address domain. As proof of concept, we implement a biologically inspired form of spike timing-dependent plasticity (STDP) based on relative timing of events in an AER framework. Experimental results from an analog VLSI integrate-and-ﬁre network demonstrate address domain learning in a task that requires neurons to group correlated inputs.</p><p>6 0.099556141 <a title="66-tfidf-6" href="./nips-2002-Maximally_Informative_Dimensions%3A_Analyzing_Neural_Responses_to_Natural_Signals.html">141 nips-2002-Maximally Informative Dimensions: Analyzing Neural Responses to Natural Signals</a></p>
<p>7 0.09766461 <a title="66-tfidf-7" href="./nips-2002-Topographic_Map_Formation_by_Silicon_Growth_Cones.html">200 nips-2002-Topographic Map Formation by Silicon Growth Cones</a></p>
<p>8 0.090842545 <a title="66-tfidf-8" href="./nips-2002-Binary_Coding_in_Auditory_Cortex.html">43 nips-2002-Binary Coding in Auditory Cortex</a></p>
<p>9 0.090795167 <a title="66-tfidf-9" href="./nips-2002-Spectro-Temporal_Receptive_Fields_of_Subthreshold_Responses_in_Auditory_Cortex.html">184 nips-2002-Spectro-Temporal Receptive Fields of Subthreshold Responses in Auditory Cortex</a></p>
<p>10 0.088551871 <a title="66-tfidf-10" href="./nips-2002-Retinal_Processing_Emulation_in_a_Programmable_2-Layer_Analog_Array_Processor_CMOS_Chip.html">177 nips-2002-Retinal Processing Emulation in a Programmable 2-Layer Analog Array Processor CMOS Chip</a></p>
<p>11 0.087931499 <a title="66-tfidf-11" href="./nips-2002-Selectivity_and_Metaplasticity_in_a_Unified_Calcium-Dependent_Model.html">180 nips-2002-Selectivity and Metaplasticity in a Unified Calcium-Dependent Model</a></p>
<p>12 0.081215262 <a title="66-tfidf-12" href="./nips-2002-Interpreting_Neural_Response_Variability_as_Monte_Carlo_Sampling_of_the_Posterior.html">116 nips-2002-Interpreting Neural Response Variability as Monte Carlo Sampling of the Posterior</a></p>
<p>13 0.076426014 <a title="66-tfidf-13" href="./nips-2002-Hidden_Markov_Model_of_Cortical_Synaptic_Plasticity%3A_Derivation_of_the_Learning_Rule.html">102 nips-2002-Hidden Markov Model of Cortical Synaptic Plasticity: Derivation of the Learning Rule</a></p>
<p>14 0.076274775 <a title="66-tfidf-14" href="./nips-2002-Dynamical_Constraints_on_Computing_with_Spike_Timing_in_the_Cortex.html">76 nips-2002-Dynamical Constraints on Computing with Spike Timing in the Cortex</a></p>
<p>15 0.074424066 <a title="66-tfidf-15" href="./nips-2002-Classifying_Patterns_of_Visual_Motion_-_a_Neuromorphic_Approach.html">51 nips-2002-Classifying Patterns of Visual Motion - a Neuromorphic Approach</a></p>
<p>16 0.072342806 <a title="66-tfidf-16" href="./nips-2002-Circuit_Model_of_Short-Term_Synaptic_Dynamics.html">50 nips-2002-Circuit Model of Short-Term Synaptic Dynamics</a></p>
<p>17 0.072018571 <a title="66-tfidf-17" href="./nips-2002-Temporal_Coherence%2C_Natural_Image_Sequences%2C_and_the_Visual_Cortex.html">193 nips-2002-Temporal Coherence, Natural Image Sequences, and the Visual Cortex</a></p>
<p>18 0.065012395 <a title="66-tfidf-18" href="./nips-2002-Reconstructing_Stimulus-Driven_Neural_Networks_from_Spike_Times.html">171 nips-2002-Reconstructing Stimulus-Driven Neural Networks from Spike Times</a></p>
<p>19 0.062256027 <a title="66-tfidf-19" href="./nips-2002-Neuromorphic_Bisable_VLSI_Synapses_with_Spike-Timing-Dependent_Plasticity.html">154 nips-2002-Neuromorphic Bisable VLSI Synapses with Spike-Timing-Dependent Plasticity</a></p>
<p>20 0.061279695 <a title="66-tfidf-20" href="./nips-2002-Morton-Style_Factorial_Coding_of_Color_in_Primary_Visual_Cortex.html">148 nips-2002-Morton-Style Factorial Coding of Color in Primary Visual Cortex</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2002_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.159), (1, 0.18), (2, 0.033), (3, 0.035), (4, -0.007), (5, 0.04), (6, 0.092), (7, -0.031), (8, 0.01), (9, 0.029), (10, 0.014), (11, 0.048), (12, 0.021), (13, 0.05), (14, 0.023), (15, 0.095), (16, 0.179), (17, -0.021), (18, -0.069), (19, -0.027), (20, 0.041), (21, 0.036), (22, 0.116), (23, -0.045), (24, -0.121), (25, -0.011), (26, -0.015), (27, -0.011), (28, -0.168), (29, -0.092), (30, 0.076), (31, 0.004), (32, 0.087), (33, -0.004), (34, -0.048), (35, 0.013), (36, 0.024), (37, -0.04), (38, 0.033), (39, 0.109), (40, -0.112), (41, 0.002), (42, 0.025), (43, 0.112), (44, -0.057), (45, 0.041), (46, 0.033), (47, 0.077), (48, 0.032), (49, 0.074)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95772266 <a title="66-lsi-1" href="./nips-2002-Developing_Topography_and_Ocular_Dominance_Using_Two_aVLSI_Vision_Sensors_and_a_Neurotrophic_Model_of_Plasticity.html">66 nips-2002-Developing Topography and Ocular Dominance Using Two aVLSI Vision Sensors and a Neurotrophic Model of Plasticity</a></p>
<p>Author: Terry Elliott, Jörg Kramer</p><p>Abstract: A neurotrophic model for the co-development of topography and ocular dominance columns in the primary visual cortex has recently been proposed. In the present work, we test this model by driving it with the output of a pair of neuronal vision sensors stimulated by disparate moving patterns. We show that the temporal correlations in the spike trains generated by the two sensors elicit the development of reﬁned topography and ocular dominance columns, even in the presence of signiﬁcant amounts of spontaneous activity and ﬁxed-pattern noise in the sensors.</p><p>2 0.6578151 <a title="66-lsi-2" href="./nips-2002-Visual_Development_Aids_the_Acquisition_of_Motion_Velocity_Sensitivities.html">206 nips-2002-Visual Development Aids the Acquisition of Motion Velocity Sensitivities</a></p>
<p>Author: Robert A. Jacobs, Melissa Dominguez</p><p>Abstract: We consider the hypothesis that systems learning aspects of visual perception may beneﬁt from the use of suitably designed developmental progressions during training. Four models were trained to estimate motion velocities in sequences of visual images. Three of the models were “developmental models” in the sense that the nature of their input changed during the course of training. They received a relatively impoverished visual input early in training, and the quality of this input improved as training progressed. One model used a coarse-to-multiscale developmental progression (i.e. it received coarse-scale motion features early in training and ﬁner-scale features were added to its input as training progressed), another model used a ﬁne-to-multiscale progression, and the third model used a random progression. The ﬁnal model was nondevelopmental in the sense that the nature of its input remained the same throughout the training period. The simulation results show that the coarse-to-multiscale model performed best. Hypotheses are offered to account for this model’s superior performance. We conclude that suitably designed developmental sequences can be useful to systems learning to estimate motion velocities. The idea that visual development can aid visual learning is a viable hypothesis in need of further study.</p><p>3 0.63278514 <a title="66-lsi-3" href="./nips-2002-Kernel-Based_Extraction_of_Slow_Features%3A_Complex_Cells_Learn_Disparity_and_Translation_Invariance_from_Natural_Images.html">118 nips-2002-Kernel-Based Extraction of Slow Features: Complex Cells Learn Disparity and Translation Invariance from Natural Images</a></p>
<p>Author: Alistair Bray, Dominique Martinez</p><p>Abstract: In Slow Feature Analysis (SFA [1]), it has been demonstrated that high-order invariant properties can be extracted by projecting inputs into a nonlinear space and computing the slowest changing features in this space; this has been proposed as a simple general model for learning nonlinear invariances in the visual system. However, this method is highly constrained by the curse of dimensionality which limits it to simple theoretical simulations. This paper demonstrates that by using a different but closely-related objective function for extracting slowly varying features ([2, 3]), and then exploiting the kernel trick, this curse can be avoided. Using this new method we show that both the complex cell properties of translation invariance and disparity coding can be learnt simultaneously from natural images when complex cells are driven by simple cells also learnt from the image. The notion of maximising an objective function based upon the temporal predictability of output has been progressively applied in modelling the development of invariances in the visual system. F6ldiak used it indirectly via a Hebbian trace rule for modelling the development of translation invariance in complex cells [4] (closely related to many other models [5,6,7]); this rule has been used to maximise invariance as one component of a hierarchical system for object and face recognition [8]. On the other hand, similar functions have been maximised directly in networks for extracting linear [2] and nonlinear [9, 1] visual invariances. Direct maximisation of such functions have recently been used to model complex cells [10] and as an alternative to maximising sparseness/independence in modelling simple cells [11]. Slow Feature Analysis [1] combines many of the best properties of these methods to provide a good general nonlinear model. That is, it uses an objective function that minimises the first-order temporal derivative of the outputs; it provides a closedform solution which maximises this function by projecting inputs into a nonlinear http://www.loria.fr/equipes/cortex/ space; it exploits sphering (or PCA-whitening) of the data to ensure that all outputs have unit variance and are uncorrelated. However, the method suffers from the curse of dimensionality in that the nonlinear feature space soon becomes very large as the input dimension grows, and yet this feature space must be represented explicitly in order for the essential sphering to occur. The alternative that we propose here is to use the objective function of Stone [2, 9], that maximises output variance over a long period whilst minimising variance over a shorter period; in the linear case, this can be implemented by a biologically plausible mixture of Hebbian and anti-Hebbian learning on the same synapses [2]. In recent work, Stone has proposed a closed-form solution for maximising this function in the linear domain of blind source separation that does not involve data-sphering. This paper describes how this method can be kernelised. The use of the</p><p>4 0.57238114 <a title="66-lsi-4" href="./nips-2002-An_Information_Theoretic_Approach_to_the_Functional_Classification_of_Neurons.html">28 nips-2002-An Information Theoretic Approach to the Functional Classification of Neurons</a></p>
<p>Author: Elad Schneidman, William Bialek, Michael Ii</p><p>Abstract: A population of neurons typically exhibits a broad diversity of responses to sensory inputs. The intuitive notion of functional classiﬁcation is that cells can be clustered so that most of the diversity is captured by the identity of the clusters rather than by individuals within clusters. We show how this intuition can be made precise using information theory, without any need to introduce a metric on the space of stimuli or responses. Applied to the retinal ganglion cells of the salamander, this approach recovers classical results, but also provides clear evidence for subclasses beyond those identiﬁed previously. Further, we ﬁnd that each of the ganglion cells is functionally unique, and that even within the same subclass only a few spikes are needed to reliably distinguish between cells. 1</p><p>5 0.57150328 <a title="66-lsi-5" href="./nips-2002-Topographic_Map_Formation_by_Silicon_Growth_Cones.html">200 nips-2002-Topographic Map Formation by Silicon Growth Cones</a></p>
<p>Author: Brian Taba, Kwabena A. Boahen</p><p>Abstract: We describe a self-configuring neuromorphic chip that uses a model of activity-dependent axon remodeling to automatically wire topographic maps based solely on input correlations. Axons are guided by growth cones, which are modeled in analog VLSI for the first time. Growth cones migrate up neurotropin gradients, which are represented by charge diffusing in transistor channels. Virtual axons move by rerouting address-events. We refined an initially gross topographic projection by simulating retinal wave input. 1 Neuromorphic Systems Neuromorphic engineers are attempting to match the computational efficiency of biological systems by morphing neurocircuitry into silicon circuits [1]. One of the most detailed implementations to date is the silicon retina described in [2] . This chip comprises thirteen different cell types, each of which must be individually and painstakingly wired. While this circuit-level approach has been very successful in sensory systems, it is less helpful when modeling largely unelucidated and exceedingly plastic higher processing centers in cortex. Instead of an explicit blueprint for every cortical area, what is needed is a developmental rule that can wire complex circuits from minimal specifications. One candidate is the famous</p><p>6 0.54910541 <a title="66-lsi-6" href="./nips-2002-Temporal_Coherence%2C_Natural_Image_Sequences%2C_and_the_Visual_Cortex.html">193 nips-2002-Temporal Coherence, Natural Image Sequences, and the Visual Cortex</a></p>
<p>7 0.50748861 <a title="66-lsi-7" href="./nips-2002-Spike_Timing-Dependent_Plasticity_in_the_Address_Domain.html">186 nips-2002-Spike Timing-Dependent Plasticity in the Address Domain</a></p>
<p>8 0.46583077 <a title="66-lsi-8" href="./nips-2002-Retinal_Processing_Emulation_in_a_Programmable_2-Layer_Analog_Array_Processor_CMOS_Chip.html">177 nips-2002-Retinal Processing Emulation in a Programmable 2-Layer Analog Array Processor CMOS Chip</a></p>
<p>9 0.41418302 <a title="66-lsi-9" href="./nips-2002-Selectivity_and_Metaplasticity_in_a_Unified_Calcium-Dependent_Model.html">180 nips-2002-Selectivity and Metaplasticity in a Unified Calcium-Dependent Model</a></p>
<p>10 0.39523271 <a title="66-lsi-10" href="./nips-2002-Maximally_Informative_Dimensions%3A_Analyzing_Neural_Responses_to_Natural_Signals.html">141 nips-2002-Maximally Informative Dimensions: Analyzing Neural Responses to Natural Signals</a></p>
<p>11 0.3612504 <a title="66-lsi-11" href="./nips-2002-Hidden_Markov_Model_of_Cortical_Synaptic_Plasticity%3A_Derivation_of_the_Learning_Rule.html">102 nips-2002-Hidden Markov Model of Cortical Synaptic Plasticity: Derivation of the Learning Rule</a></p>
<p>12 0.35707241 <a title="66-lsi-12" href="./nips-2002-A_Prototype_for_Automatic_Recognition_of_Spontaneous_Facial_Actions.html">16 nips-2002-A Prototype for Automatic Recognition of Spontaneous Facial Actions</a></p>
<p>13 0.33882585 <a title="66-lsi-13" href="./nips-2002-Adaptation_and_Unsupervised_Learning.html">18 nips-2002-Adaptation and Unsupervised Learning</a></p>
<p>14 0.33798429 <a title="66-lsi-14" href="./nips-2002-Spectro-Temporal_Receptive_Fields_of_Subthreshold_Responses_in_Auditory_Cortex.html">184 nips-2002-Spectro-Temporal Receptive Fields of Subthreshold Responses in Auditory Cortex</a></p>
<p>15 0.30169666 <a title="66-lsi-15" href="./nips-2002-Learning_a_Forward_Model_of_a_Reflex.html">128 nips-2002-Learning a Forward Model of a Reflex</a></p>
<p>16 0.29636201 <a title="66-lsi-16" href="./nips-2002-Classifying_Patterns_of_Visual_Motion_-_a_Neuromorphic_Approach.html">51 nips-2002-Classifying Patterns of Visual Motion - a Neuromorphic Approach</a></p>
<p>17 0.29569757 <a title="66-lsi-17" href="./nips-2002-Neural_Decoding_of_Cursor_Motion_Using_a_Kalman_Filter.html">153 nips-2002-Neural Decoding of Cursor Motion Using a Kalman Filter</a></p>
<p>18 0.29212219 <a title="66-lsi-18" href="./nips-2002-Neuromorphic_Bisable_VLSI_Synapses_with_Spike-Timing-Dependent_Plasticity.html">154 nips-2002-Neuromorphic Bisable VLSI Synapses with Spike-Timing-Dependent Plasticity</a></p>
<p>19 0.27995026 <a title="66-lsi-19" href="./nips-2002-Adaptive_Nonlinear_System_Identification_with_Echo_State_Networks.html">22 nips-2002-Adaptive Nonlinear System Identification with Echo State Networks</a></p>
<p>20 0.27839372 <a title="66-lsi-20" href="./nips-2002-Real-Time_Monitoring_of_Complex_Industrial_Processes_with_Particle_Filters.html">168 nips-2002-Real-Time Monitoring of Complex Industrial Processes with Particle Filters</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2002_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(23, 0.025), (42, 0.024), (54, 0.056), (55, 0.035), (58, 0.015), (64, 0.025), (67, 0.016), (68, 0.041), (74, 0.537), (83, 0.022), (92, 0.016), (98, 0.078)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.9807936 <a title="66-lda-1" href="./nips-2002-Concurrent_Object_Recognition_and_Segmentation_by_Graph_Partitioning.html">57 nips-2002-Concurrent Object Recognition and Segmentation by Graph Partitioning</a></p>
<p>Author: Stella X. Yu, Ralph Gross, Jianbo Shi</p><p>Abstract: Segmentation and recognition have long been treated as two separate processes. We propose a mechanism based on spectral graph partitioning that readily combine the two processes into one. A part-based recognition system detects object patches, supplies their partial segmentations as well as knowledge about the spatial configurations of the object. The goal of patch grouping is to find a set of patches that conform best to the object configuration, while the goal of pixel grouping is to find a set of pixels that have the best low-level feature similarity. Through pixel-patch interactions and between-patch competition encoded in the solution space, these two processes are realized in one joint optimization problem. The globally optimal partition is obtained by solving a constrained eigenvalue problem. We demonstrate that the resulting object segmentation eliminates false positives for the part detection, while overcoming occlusion and weak contours for the low-level edge detection.</p><p>same-paper 2 0.9661119 <a title="66-lda-2" href="./nips-2002-Developing_Topography_and_Ocular_Dominance_Using_Two_aVLSI_Vision_Sensors_and_a_Neurotrophic_Model_of_Plasticity.html">66 nips-2002-Developing Topography and Ocular Dominance Using Two aVLSI Vision Sensors and a Neurotrophic Model of Plasticity</a></p>
<p>Author: Terry Elliott, Jörg Kramer</p><p>Abstract: A neurotrophic model for the co-development of topography and ocular dominance columns in the primary visual cortex has recently been proposed. In the present work, we test this model by driving it with the output of a pair of neuronal vision sensors stimulated by disparate moving patterns. We show that the temporal correlations in the spike trains generated by the two sensors elicit the development of reﬁned topography and ocular dominance columns, even in the presence of signiﬁcant amounts of spontaneous activity and ﬁxed-pattern noise in the sensors.</p><p>3 0.95857513 <a title="66-lda-3" href="./nips-2002-Information_Regularization_with_Partially_Labeled_Data.html">114 nips-2002-Information Regularization with Partially Labeled Data</a></p>
<p>Author: Martin Szummer, Tommi S. Jaakkola</p><p>Abstract: Classiﬁcation with partially labeled data requires using a large number of unlabeled examples (or an estimated marginal P (x)), to further constrain the conditional P (y|x) beyond a few available labeled examples. We formulate a regularization approach to linking the marginal and the conditional in a general way. The regularization penalty measures the information that is implied about the labels over covering regions. No parametric assumptions are required and the approach remains tractable even for continuous marginal densities P (x). We develop algorithms for solving the regularization problem for ﬁnite covers, establish a limiting differential equation, and exemplify the behavior of the new regularization approach in simple cases.</p><p>4 0.95542616 <a title="66-lda-4" href="./nips-2002-Efficient_Learning_Equilibrium.html">78 nips-2002-Efficient Learning Equilibrium</a></p>
<p>Author: Ronen I. Brafman, Moshe Tennenholtz</p><p>Abstract: We introduce efficient learning equilibrium (ELE), a normative approach to learning in non cooperative settings. In ELE, the learning algorithms themselves are required to be in equilibrium. In addition, the learning algorithms arrive at a desired value after polynomial time, and deviations from a prescribed ELE become irrational after polynomial time. We prove the existence of an ELE in the perfect monitoring setting, where the desired value is the expected payoff in a Nash equilibrium. We also show that an ELE does not always exist in the imperfect monitoring case. Yet, it exists in the special case of common-interest games. Finally, we extend our results to general stochastic games. 1</p><p>5 0.94638711 <a title="66-lda-5" href="./nips-2002-Feature_Selection_in_Mixture-Based_Clustering.html">90 nips-2002-Feature Selection in Mixture-Based Clustering</a></p>
<p>Author: Martin H. Law, Anil K. Jain, Mário Figueiredo</p><p>Abstract: There exist many approaches to clustering, but the important issue of feature selection, i.e., selecting the data attributes that are relevant for clustering, is rarely addressed. Feature selection for clustering is difﬁcult due to the absence of class labels. We propose two approaches to feature selection in the context of Gaussian mixture-based clustering. In the ﬁrst one, instead of making hard selections, we estimate feature saliencies. An expectation-maximization (EM) algorithm is derived for this task. The second approach extends Koller and Sahami’s mutual-informationbased feature relevance criterion to the unsupervised case. Feature selection is then carried out by a backward search scheme. This scheme can be classiﬁed as a “wrapper”, since it wraps mixture estimation in an outer layer that performs feature selection. Experimental results on synthetic and real data show that both methods have promising performance.</p><p>6 0.89156872 <a title="66-lda-6" href="./nips-2002-Parametric_Mixture_Models_for_Multi-Labeled_Text.html">162 nips-2002-Parametric Mixture Models for Multi-Labeled Text</a></p>
<p>7 0.74495852 <a title="66-lda-7" href="./nips-2002-Reinforcement_Learning_to_Play_an_Optimal_Nash_Equilibrium_in_Team_Markov_Games.html">175 nips-2002-Reinforcement Learning to Play an Optimal Nash Equilibrium in Team Markov Games</a></p>
<p>8 0.71185017 <a title="66-lda-8" href="./nips-2002-Bayesian_Image_Super-Resolution.html">39 nips-2002-Bayesian Image Super-Resolution</a></p>
<p>9 0.68459463 <a title="66-lda-9" href="./nips-2002-Feature_Selection_by_Maximum_Marginal_Diversity.html">89 nips-2002-Feature Selection by Maximum Marginal Diversity</a></p>
<p>10 0.67863184 <a title="66-lda-10" href="./nips-2002-On_the_Dirichlet_Prior_and_Bayesian_Regularization.html">157 nips-2002-On the Dirichlet Prior and Bayesian Regularization</a></p>
<p>11 0.67801517 <a title="66-lda-11" href="./nips-2002-Nash_Propagation_for_Loopy_Graphical_Games.html">152 nips-2002-Nash Propagation for Loopy Graphical Games</a></p>
<p>12 0.67695916 <a title="66-lda-12" href="./nips-2002-Shape_Recipes%3A_Scene_Representations_that_Refer_to_the_Image.html">182 nips-2002-Shape Recipes: Scene Representations that Refer to the Image</a></p>
<p>13 0.67475182 <a title="66-lda-13" href="./nips-2002-Learning_to_Detect_Natural_Image_Boundaries_Using_Brightness_and_Texture.html">132 nips-2002-Learning to Detect Natural Image Boundaries Using Brightness and Texture</a></p>
<p>14 0.66713434 <a title="66-lda-14" href="./nips-2002-Dynamic_Structure_Super-Resolution.html">74 nips-2002-Dynamic Structure Super-Resolution</a></p>
<p>15 0.65662658 <a title="66-lda-15" href="./nips-2002-Learning_About_Multiple_Objects_in_Images%3A_Factorial_Learning_without_Factorial_Search.html">122 nips-2002-Learning About Multiple Objects in Images: Factorial Learning without Factorial Search</a></p>
<p>16 0.65061873 <a title="66-lda-16" href="./nips-2002-Recovering_Intrinsic_Images_from_a_Single_Image.html">173 nips-2002-Recovering Intrinsic Images from a Single Image</a></p>
<p>17 0.63304949 <a title="66-lda-17" href="./nips-2002-Learning_with_Multiple_Labels.html">135 nips-2002-Learning with Multiple Labels</a></p>
<p>18 0.63284189 <a title="66-lda-18" href="./nips-2002-A_Bilinear_Model_for_Sparse_Coding.html">2 nips-2002-A Bilinear Model for Sparse Coding</a></p>
<p>19 0.61742008 <a title="66-lda-19" href="./nips-2002-Learning_to_Classify_Galaxy_Shapes_Using_the_EM_Algorithm.html">131 nips-2002-Learning to Classify Galaxy Shapes Using the EM Algorithm</a></p>
<p>20 0.61596119 <a title="66-lda-20" href="./nips-2002-Half-Lives_of_EigenFlows_for_Spectral_Clustering.html">100 nips-2002-Half-Lives of EigenFlows for Spectral Clustering</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
