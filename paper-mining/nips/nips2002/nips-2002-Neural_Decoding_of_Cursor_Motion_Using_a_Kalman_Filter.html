<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>153 nips-2002-Neural Decoding of Cursor Motion Using a Kalman Filter</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-153" href="#">nips2002-153</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>153 nips-2002-Neural Decoding of Cursor Motion Using a Kalman Filter</h1>
<br/><p>Source: <a title="nips-2002-153-pdf" href="http://papers.nips.cc/paper/2178-neural-decoding-of-cursor-motion-using-a-kalman-filter.pdf">pdf</a></p><p>Author: W Wu, M. J. Black, Y. Gao, M. Serruya, A. Shaikhouni, J. P. Donoghue, Elie Bienenstock</p><p>Abstract: The direct neural control of external devices such as computer displays or prosthetic limbs requires the accurate decoding of neural activity representing continuous movement. We develop a real-time control system using the spiking activity of approximately 40 neurons recorded with an electrode array implanted in the arm area of primary motor cortex. In contrast to previous work, we develop a control-theoretic approach that explicitly models the motion of the hand and the probabilistic relationship between this motion and the mean ﬁring rates of the cells in 70 bins. We focus on a realistic cursor control task in which the subject must move a cursor to “hit” randomly placed targets on a computer monitor. Encoding and decoding of the neural data is achieved with a Kalman ﬁlter which has a number of advantages over previous linear ﬁltering techniques. In particular, the Kalman ﬁlter reconstructions of hand trajectories in off-line experiments are more accurate than previously reported results and the model provides insights into the nature of the neural coding of movement. ¨ ©§</p><p>Reference: <a title="nips-2002-153-reference" href="../nips2002_reference/nips-2002-Neural_Decoding_of_Cursor_Motion_Using_a_Kalman_Filter_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 edu ¤  ¢  Abstract The direct neural control of external devices such as computer displays or prosthetic limbs requires the accurate decoding of neural activity representing continuous movement. [sent-23, score-0.659]
</p><p>2 We develop a real-time control system using the spiking activity of approximately 40 neurons recorded with an electrode array implanted in the arm area of primary motor cortex. [sent-24, score-0.656]
</p><p>3 In contrast to previous work, we develop a control-theoretic approach that explicitly models the motion of the hand and the probabilistic relationship between this motion and the mean ﬁring rates of the cells in 70 bins. [sent-25, score-0.522]
</p><p>4 We focus on a realistic cursor control task in which the subject must move a cursor to “hit” randomly placed targets on a computer monitor. [sent-26, score-0.47]
</p><p>5 Encoding and decoding of the neural data is achieved with a Kalman ﬁlter which has a number of advantages over previous linear ﬁltering techniques. [sent-27, score-0.352]
</p><p>6 In particular, the Kalman ﬁlter reconstructions of hand trajectories in off-line experiments are more accurate than previously reported results and the model provides insights into the nature of the neural coding of movement. [sent-28, score-0.387]
</p><p>7 ¨ ©§  1 Introduction Recent results have demonstrated the feasibility of direct neural control of devices such as computer cursors using implanted electrodes [5, 9, 11, 14]. [sent-29, score-0.304]
</p><p>8 To that  Monitor  12  Target 10  8  6  Tablet Trajectory  4  2  Manipulandum  a  2  4  6  8  10  12  14  16  b  Figure 1: Reconstructing 2D hand motion. [sent-36, score-0.157]
</p><p>9 (a) Training: neural spiking activity is recorded while the subject moves a jointed manipulandum on a 2D plane to control a cursor so that it hits randomly placed targets. [sent-37, score-0.563]
</p><p>10 (b) Decoding: true target trajectory (dashed (red): dark to light) and reconstruction using the Kalman ﬁlter (solid (blue): dark to light). [sent-38, score-0.352]
</p><p>11 end, we propose a Kalman ﬁltering method that provides a rigorous and well understood framework that addresses these issues. [sent-39, score-0.095]
</p><p>12 This approach provides a control-theoretic model for the encoding of hand movement in motor cortex and for inferring, or decoding, this movement from the ﬁring rates of a population of cells. [sent-40, score-0.802]
</p><p>13 Simultaneous recordings are acquired from an array consisting of microelectrodes [6] implanted in the arm area of primary motor cortex (MI) of a Macaque monkey; recordings from this area have been used previously to control devices [5, 9, 10, 11, 14]. [sent-41, score-0.716]
</p><p>14 The monkey views a computer monitor while gripping a two-link manipulandum that controls the 2D motion of a cursor on the monitor (Figure 1a). [sent-42, score-0.505]
</p><p>15 We use the experimental paradigm of [9], in which a target dot appears in a random location on the monitor and the task requires moving a feedback dot with the manipulandum so that it hits the target. [sent-43, score-0.253]
</p><p>16 The trajectory of the hand and the neural activity of cells are recorded simultaneously. [sent-45, score-0.479]
</p><p>17 We compute the position, velocity, and acceleration of the hand along with the mean ﬁring rate for each of the cells within non-overlapping time bins. [sent-46, score-0.512]
</p><p>18 In contrast to related work [8, 15], the motions of the monkey in this task are quite rapid and more “natural” in that the actual trajectory of the motion is unconstrained. [sent-47, score-0.356]
</p><p>19 ¡ ¡ £¢   ¥ ¦¤  § ¨§ ¡  ¨  The reconstruction of hand trajectory from the mean ﬁring rates can be viewed probabilistically as a problem of inferring behavior from noisy measurements. [sent-48, score-0.598]
</p><p>20 In [15] we proposed a Kalman ﬁlter framework [3] for modeling the relationship between ﬁring rates in motor cortex and the position and velocity of the subject’s hand. [sent-49, score-0.563]
</p><p>21 This work focused on off-line reconstruction using constrained motions of the hand [8]. [sent-50, score-0.458]
</p><p>22 With this data we show that, in contrast to our previous results, a model of hand acceleration (in addition to position and velocity) is important for accurate reconstruction. [sent-52, score-0.603]
</p><p>23 In the Kalman framework, the hand movement (position, velocity and acceleration) is modeled as the system state and the neural ﬁring rate is modeled as the observation (measurement). [sent-53, score-0.519]
</p><p>24 The approach speciﬁes an explicit generative model that assumes the observation (ﬁring rate in ) is a linear function of the state (hand kinematics) plus Gaussian noise . [sent-54, score-0.102]
</p><p>25 Similarly, the hand state at time is assumed to be a linear function of the hand state at the previous time instant plus Gaussian noise. [sent-55, score-0.689]
</p><p>26 The Kalman ﬁlter approach provides a recursive, on-line, estimate of hand kinematics from the ﬁring rate in non-overlapping time bins. [sent-56, score-0.382]
</p><p>27 The ©  ¨  § ¨§ ¡      This is a crude assumption but the ﬁring rates can be square-root transformed [7] making them more Gaussian and the mean ﬁring rate can be subtracted to achieve zero-mean data. [sent-57, score-0.072]
</p><p>28 results of reconstructing hand trajectories from pre-recorded neural ﬁring rates are compared with those obtained using more traditional ﬁxed linear ﬁltering techniques [9, 12] using overlapping windows. [sent-58, score-0.421]
</p><p>29 The results indicate that the Kalman ﬁlter decoding is more accurate than that of the ﬁxed linear ﬁlter. [sent-59, score-0.331]
</p><p>30 1 Related Work Georgopoulos and colleagues [4] showed that hand movement direction may be encoded by the neural ensemble in the arm area of motor cortex (MI). [sent-61, score-0.641]
</p><p>31 This early work has resulted in a number of successful algorithms for decoding neural activity in MI to perform offline reconstruction or on-line control of cursors or robotic arms. [sent-62, score-0.749]
</p><p>32 Roughly, the primary methods for decoding MI activity include the population vector algorithm [4, 5, 7, 11], linear ﬁltering [9, 12], artiﬁcial neural networks [14], and probabilistic methods [2, 10, 15]. [sent-63, score-0.522]
</p><p>33 This population vector approach is the oldest method and it has been used for the real-time neural control of 3D cursor movement [11]. [sent-64, score-0.482]
</p><p>34 This work has focused primarily on “center out” motions to a discrete set of radial targets (in 2D or 3D) rather than natural, continuous, motion that we address here. [sent-65, score-0.222]
</p><p>35 Linear ﬁltering [8, 12] is a simple statistical method that is effective for real-time neural control of a 2D cursor [9]. [sent-66, score-0.289]
</p><p>36 The ﬁxed linear ﬁlter, like population vectors and neural networks [14] lack both a clear probabilistic model and a model of the temporal hand kinematics. [sent-68, score-0.325]
</p><p>37 Additionally, they provide no estimate of uncertainty and hence may be difﬁcult to extend to the analysis of more complex temporal movement patterns. [sent-69, score-0.153]
</p><p>38 ¢  ¨ £     § £¡ ¡  ¨  ¢  We argue that what is needed is a probabilistically grounded method that uses data in small time windows (e. [sent-70, score-0.119]
</p><p>39 or less) and integrates that information over time in a recursive fashion. [sent-72, score-0.103]
</p><p>40 The C ONDENSATION algorithm has been recently introduced as a Bayesian decoding scheme [2], which provides a probabilistic framework for causal estimation and is shown superior to the performance of linear ﬁltering when sufﬁcient data is available (e. [sent-73, score-0.315]
</p><p>41 While this may be important for neural decoding as suggested in [2], current technology makes the method impractical for real-time control. [sent-77, score-0.288]
</p><p>42 ¨  § £¢  ¥¡ ¡ ¡ ¤  ¢  For real-time neural control we exploit the Kalman ﬁlter [3, 13] which has been widely used for estimation problems ranging from target tracking to vehicle control. [sent-78, score-0.176]
</p><p>43 Here we apply this well understood theory to the problem of decoding hand kinematics from neural activity in motor cortex. [sent-79, score-0.807]
</p><p>44 This builds on the work that uses recursive Bayesian ﬁlters to estimate the position of a rat from the ﬁring activity of hippocampal place cells [1, 16]. [sent-80, score-0.454]
</p><p>45 In contrast to the linear ﬁlter or population vector methods, this approach provides a measure of conﬁdence in the resulting estimates. [sent-81, score-0.159]
</p><p>46 This can be extremely important when the output of the decoding method is to be used for later stages of analysis. [sent-82, score-0.243]
</p><p>47 2 Methods Decoding involves estimating the state of the hand at the current instant in time; i. [sent-83, score-0.284]
</p><p>48 The Kalman ﬁlter [3, 13] model assumes the state is linearly related to the observations z which here represents a vector containing the ﬁring rates at time for  B      ¦   ¨    § ¨§ ¡  § 5 3       ¦(&"$ "$"  ¨¦ '% ! [sent-86, score-0.197]
</p><p>49 §  ¥ ¦¤  B  § ¨§ ¡  ¨  Encoding: We deﬁne a generative model of neural ﬁring as (1)  ¡  q  ¢ £¦  x   ¦  ¡ ¦  § ¦  z  where , is the number of time steps in the trial, and is a matrix that linearly relates the hand state to the neural ﬁring. [sent-91, score-0.4]
</p><p>50 This states that the hand kinematics (position, velocity, and acceleration) at time is linearly related to the state at time . [sent-97, score-0.424]
</p><p>51 Thus we can estimate the Kalman ﬁlter model from training data using least squares estimation:  ¤ ¦  z  x  ¦  7"¦ 6  ©  A 988   H    3  argmin  B88  ¦  x  ¡  % @¤ © "¦ $  ¡  988  x  A 988   ¨  ©  ¦  0 1  © 7 "¦ 6 4 53  ¦  norm. [sent-103, score-0.111]
</p><p>52 %   A C  0 ¤ 988 B88  where is the matrices and  ¦  A  1  argmin  Decoding: At each time step the algorithm has two steps: 1) prediction of the a priori state estimate x ; and 2) updating this estimate with new measurement data to produce an a posteriori state estimate x . [sent-105, score-0.46]
</p><p>53 Discrete Kalman ﬁlter time update equations: ©  4  ¦ )  At each time , we obtain the a priori estimate from the previous time its error covariance matrix, : x x  , then compute (3)  4  0 ¢ ' % © 4 ¦ F§ ¦ E E % 4 © % 4 ¦ D § 4¦ D   (4)     ¦ $  ¦  E  II. [sent-107, score-0.252]
</p><p>54 Note that is the measurement error matrix and, depending on the reliability of the data, the gain term, , automatically adjusts the contribution of the new measurement to the state estimate. [sent-109, score-0.25]
</p><p>55 30 Table 1: Reconstruction results for the ﬁxed linear and recursive Kalman ﬁlter. [sent-128, score-0.08]
</p><p>56 The table also shows how the Kalman ﬁlter results vary with lag times (see text). [sent-129, score-0.246]
</p><p>57 5 minutes of training data sufﬁces for accurate reconstruction (this is similar to the result for ﬁxed linear ﬁlters reported in [9]). [sent-134, score-0.3]
</p><p>58 As described in the introduction, the task involves moving a manipulantablet (with a workspace) to hit randomly dum freely on a placed targets on the screen. [sent-135, score-0.11]
</p><p>59 We gather the mean ﬁring rates and actual hand trajectories for the training data and then learn the models via least squares (the computation time is negligible). [sent-136, score-0.385]
</p><p>60 We then test the accuracy of the method by reconstructing test trajectories offline using recorded neural data not present in the training set. [sent-137, score-0.234]
</p><p>61   0  %  §    £¡ ¥ C  §    £¡ ¥  §   £¢¡  ¡  §   £¢¡  C  ¡  Optimal Lag: The physical relationship between neural ﬁring and arm movement means there exists a time lag between them [7, 8]. [sent-139, score-0.519]
</p><p>62 The introduction of a time lag results in the measurements, z , at time , being taken from some previous (or future) instant in time for some integer . [sent-140, score-0.479]
</p><p>63 In the interest of simplicity, we consider a single optimal time lag for all the cells though evidence suggests that individual time lags may provide better results [15]. [sent-141, score-0.44]
</p><p>64 ¦  ¦  ¦  ¤ ¦ ¥4   Using time lags of 0, 70, 140, 210 we train the Kalman ﬁlter and perform reconstruction (see Table 1). [sent-142, score-0.313]
</p><p>65 We report the accuracy of the reconstructions with a variety of error measures used in the literature including the correlation coefﬁcient ( ) and the mean squared error (MSE) between the reconstructed and true trajectories. [sent-143, score-0.068]
</p><p>66 From Table 1 we see that optimal lag is around two time steps (or 140 ); this lag will be used in the remainder of the experiments and is similar to our previous ﬁndings [15] which suggested that the optimal lag was between 50-100 . [sent-144, score-0.754]
</p><p>67 Some examples of the reconstructed trajectory are shown in Figure 2 while Figure 3 shows the reconstruction of each component of the state variable (position, velocity and acceleration in and ). [sent-147, score-0.785]
</p><p>68     From Figure 3 and Table 1 we note that the reconstruction in is more accurate than in the direction (the same is true for the ﬁxed linear ﬁlter described below); this requires further investigation. [sent-148, score-0.3]
</p><p>69 Note also that the ground truth velocity and acceleration curves are computed from the position data with simple differencing. [sent-149, score-0.511]
</p><p>70 As a result these plots are quite noisy making an evaluation of the reconstruction difﬁcult. [sent-150, score-0.212]
</p><p>71 5 )): true target trajectory (dashed (red)) and reconstruction using the Kalman ﬁlter (solid (blue)). [sent-152, score-0.352]
</p><p>72 In our experiments here we take which means that the hand position is determined from ﬁring data over . [sent-156, score-0.294]
</p><p>73 Note that since the linear ﬁlter uses data over a long time window, it does not beneﬁt from the use of time-lagged data. [sent-158, score-0.095]
</p><p>74 Note also that it does not explicitly reconstruct velocity or acceleration. [sent-159, score-0.145]
</p><p>75    3 1  §  #  ¦      ¢ ¥  ¦ ¢ 4 )    §    ¡ £¥  §    §  ¦¥¥£  ¤¤¤  ¢ 4  ¦ § § 1 ¨ § ¨§ ¡ ¦  ,  §  3  where  ¨ ¤ ¡     The linear ﬁlter reconstruction of position is shown in Figure 4. [sent-160, score-0.385]
</p><p>76 Table 1, however, shows that the Kalman ﬁlter gives a more accurate reconstruction than the linear ﬁlter (higher correlation coefﬁcient and lower mean-squared error). [sent-162, score-0.3]
</p><p>77 Analysis: In our previous work [15], the experimental paradigm involved carefully designed hand motions that were slow and smooth. [sent-164, score-0.302]
</p><p>78 In that case we showed that acceleration was redundant and could be removed from the state equation. [sent-165, score-0.295]
</p><p>79 The data used here is more “natural”, varied, and rapid and we ﬁnd that modeling acceleration improves the prediction of the system state and the accuracy of the reconstruction; Table 1 shows the decrease in accuracy with only position and velocity in the system state (with 140ms lag). [sent-166, score-0.674]
</p><p>80 4 Conclusions We have described a discrete linear Kalman ﬁlter that is appropriate for the neural control of 2D cursor motion. [sent-167, score-0.325]
</p><p>81 ¨  y-position  x-position 20 10  15  5  10  0  5 5  10  time (second)  15  20  5  10  15  20  time (second)  Figure 4: Reconstruction of position using the linear ﬁlter: true target trajectory (dashed (red)) and reconstruction using the linear ﬁlter (solid (blue)). [sent-170, score-0.679]
</p><p>82 The estimated trajectories are more accurate than the ﬁxed linear ﬁltering results being used currently. [sent-172, score-0.157]
</p><p>83 The Kalman ﬁlter proposed here provides a rigorous probabilistic approach with a well understood theory. [sent-173, score-0.095]
</p><p>84 By making its assumptions explicit and by providing an estimate of uncertainty, the Kalman ﬁlter offers signiﬁcant advantages over previous methods. [sent-174, score-0.075]
</p><p>85 The method also estimates hand velocity and acceleration in addition to 2D position. [sent-175, score-0.531]
</p><p>86 In contrast to previous experiments, we show, for the natural 2D motions in this task, that incorporating acceleration into the system and measurement models improves the accuracy of the decoding. [sent-176, score-0.438]
</p><p>87 We also show that, consistent with previous studies, a time lag of improves the accuracy. [sent-177, score-0.3]
</p><p>88 ¨ ©§ ¡ ¢  ¤  ¤ ¡ §  Our future work will evaluate the performance of the Kalman ﬁlter for on-line neural control of cursor motion in the task described here. [sent-178, score-0.388]
</p><p>89 Additionally, we are exploring alternative measurement noise models, non-linear system models, and non-linear particle ﬁlter decod-  ing methods. [sent-179, score-0.122]
</p><p>90 Finally, to get a complete picture of current methods, we are pursuing further comparisons with population vector methods [7] and particle ﬁltering techniques [2]. [sent-180, score-0.117]
</p><p>91 A statistical paradigm for neural spike train decoding applied to position prediction from ensemble ﬁring patterns of rat hippocampal place cells. [sent-194, score-0.531]
</p><p>92 Probabilistic inference of hand motion from neural activity in motor cortex. [sent-205, score-0.548]
</p><p>93 (2000) Online control of a prosthetic arm from motor cortical signals. [sent-222, score-0.444]
</p><p>94 Temporal tuning properties for hand position and velocity in motor cortical neurons. [sent-246, score-0.655]
</p><p>95 Brain-machine interface: Instant neural control of a movement signal. [sent-259, score-0.235]
</p><p>96 , (2000) Assignment of primate M1 cortical activity to robot arm position with Bayesian reconstruction algorithm. [sent-265, score-0.576]
</p><p>97 Decoding visual information from a population of retinal ganglion cells. [sent-283, score-0.087]
</p><p>98 Real-time prediction of hand trajectory by ensembles of cortical neurons in primates. [sent-302, score-0.3]
</p><p>99 , Inferring hand motion from multi-cell recordings in motor cortex using a Kalman ﬁlter, SAB’02Workshop on Motor Control in Humans and Robots: On the Interplay of Real Brains and Artiﬁcial Devices, Aug. [sent-312, score-0.502]
</p><p>100 , Interpreting neuronal population activity by reconstruction: Uniﬁed framework with application to hippocampal place cells, J. [sent-319, score-0.218]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('kalman', 0.448), ('lter', 0.259), ('decoding', 0.243), ('acceleration', 0.229), ('ring', 0.216), ('lag', 0.213), ('reconstruction', 0.212), ('donoghue', 0.168), ('motor', 0.166), ('cursor', 0.16), ('hand', 0.157), ('velocity', 0.145), ('position', 0.137), ('movement', 0.106), ('motion', 0.099), ('manipulandum', 0.096), ('arm', 0.096), ('ltering', 0.095), ('trajectory', 0.093), ('measurement', 0.092), ('motions', 0.089), ('population', 0.087), ('control', 0.084), ('kinematics', 0.083), ('serruya', 0.083), ('activity', 0.081), ('gao', 0.076), ('rates', 0.072), ('hatsopoulos', 0.072), ('implanted', 0.072), ('trajectories', 0.069), ('cells', 0.067), ('state', 0.066), ('schwartz', 0.064), ('fellows', 0.063), ('blue', 0.061), ('red', 0.061), ('instant', 0.061), ('devices', 0.061), ('time', 0.059), ('bienenstock', 0.057), ('monitor', 0.053), ('accurate', 0.052), ('cortical', 0.05), ('hippocampal', 0.05), ('mi', 0.05), ('ondensation', 0.048), ('prosthetic', 0.048), ('shaikhouni', 0.048), ('estimate', 0.047), ('target', 0.047), ('neural', 0.045), ('recursive', 0.044), ('hit', 0.044), ('monkey', 0.044), ('cortex', 0.043), ('coef', 0.042), ('reconstructing', 0.042), ('chapel', 0.042), ('offline', 0.042), ('lags', 0.042), ('cursors', 0.042), ('georgopoulos', 0.042), ('tillery', 0.042), ('reconstructed', 0.04), ('dashed', 0.039), ('recordings', 0.037), ('linear', 0.036), ('recorded', 0.036), ('black', 0.036), ('provides', 0.036), ('paninski', 0.036), ('argmin', 0.036), ('array', 0.034), ('targets', 0.034), ('mse', 0.033), ('table', 0.033), ('understood', 0.032), ('inferring', 0.032), ('probabilistically', 0.032), ('placed', 0.032), ('solid', 0.031), ('rapid', 0.031), ('particle', 0.03), ('xed', 0.03), ('primary', 0.03), ('hits', 0.029), ('electrode', 0.029), ('encoding', 0.029), ('trial', 0.028), ('rat', 0.028), ('reconstructions', 0.028), ('argue', 0.028), ('steps', 0.028), ('previous', 0.028), ('paradigm', 0.028), ('squares', 0.028), ('area', 0.028), ('normally', 0.027), ('rigorous', 0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999946 <a title="153-tfidf-1" href="./nips-2002-Neural_Decoding_of_Cursor_Motion_Using_a_Kalman_Filter.html">153 nips-2002-Neural Decoding of Cursor Motion Using a Kalman Filter</a></p>
<p>Author: W Wu, M. J. Black, Y. Gao, M. Serruya, A. Shaikhouni, J. P. Donoghue, Elie Bienenstock</p><p>Abstract: The direct neural control of external devices such as computer displays or prosthetic limbs requires the accurate decoding of neural activity representing continuous movement. We develop a real-time control system using the spiking activity of approximately 40 neurons recorded with an electrode array implanted in the arm area of primary motor cortex. In contrast to previous work, we develop a control-theoretic approach that explicitly models the motion of the hand and the probabilistic relationship between this motion and the mean ﬁring rates of the cells in 70 bins. We focus on a realistic cursor control task in which the subject must move a cursor to “hit” randomly placed targets on a computer monitor. Encoding and decoding of the neural data is achieved with a Kalman ﬁlter which has a number of advantages over previous linear ﬁltering techniques. In particular, the Kalman ﬁlter reconstructions of hand trajectories in off-line experiments are more accurate than previously reported results and the model provides insights into the nature of the neural coding of movement. ¨ ©§</p><p>2 0.23964022 <a title="153-tfidf-2" href="./nips-2002-Spikernels%3A_Embedding_Spiking_Neurons_in_Inner-Product_Spaces.html">187 nips-2002-Spikernels: Embedding Spiking Neurons in Inner-Product Spaces</a></p>
<p>Author: Lavi Shpigelman, Yoram Singer, Rony Paz, Eilon Vaadia</p><p>Abstract: Inner-product operators, often referred to as kernels in statistical learning, deﬁne a mapping from some input space into a feature space. The focus of this paper is the construction of biologically-motivated kernels for cortical activities. The kernels we derive, termed Spikernels, map spike count sequences into an abstract vector space in which we can perform various prediction tasks. We discuss in detail the derivation of Spikernels and describe an efﬁcient algorithm for computing their value on any two sequences of neural population spike counts. We demonstrate the merits of our modeling approach using the Spikernel and various standard kernels for the task of predicting hand movement velocities from cortical recordings. In all of our experiments all the kernels we tested outperform the standard scalar product used in regression with the Spikernel consistently achieving the best performance. 1</p><p>3 0.22795288 <a title="153-tfidf-3" href="./nips-2002-Adaptive_Classification_by_Variational_Kalman_Filtering.html">21 nips-2002-Adaptive Classification by Variational Kalman Filtering</a></p>
<p>Author: Peter Sykacek, Stephen J. Roberts</p><p>Abstract: We propose in this paper a probabilistic approach for adaptive inference of generalized nonlinear classiﬁcation that combines the computational advantage of a parametric solution with the ﬂexibility of sequential sampling techniques. We regard the parameters of the classiﬁer as latent states in a ﬁrst order Markov process and propose an algorithm which can be regarded as variational generalization of standard Kalman ﬁltering. The variational Kalman ﬁlter is based on two novel lower bounds that enable us to use a non-degenerate distribution over the adaptation rate. An extensive empirical evaluation demonstrates that the proposed method is capable of infering competitive classiﬁers both in stationary and non-stationary environments. Although we focus on classiﬁcation, the algorithm is easily extended to other generalized nonlinear models.</p><p>4 0.17202757 <a title="153-tfidf-4" href="./nips-2002-A_Minimal_Intervention_Principle_for_Coordinated_Movement.html">9 nips-2002-A Minimal Intervention Principle for Coordinated Movement</a></p>
<p>Author: Emanuel Todorov, Michael I. Jordan</p><p>Abstract: Behavioral goals are achieved reliably and repeatedly with movements rarely reproducible in their detail. Here we offer an explanation: we show that not only are variability and goal achievement compatible, but indeed that allowing variability in redundant dimensions is the optimal control strategy in the face of uncertainty. The optimal feedback control laws for typical motor tasks obey a “minimal intervention” principle: deviations from the average trajectory are only corrected when they interfere with the task goals. The resulting behavior exhibits task-constrained variability, as well as synergetic coupling among actuators—which is another unexplained empirical phenomenon.</p><p>5 0.12491383 <a title="153-tfidf-5" href="./nips-2002-Interpreting_Neural_Response_Variability_as_Monte_Carlo_Sampling_of_the_Posterior.html">116 nips-2002-Interpreting Neural Response Variability as Monte Carlo Sampling of the Posterior</a></p>
<p>Author: Patrik O. Hoyer, Aapo Hyvärinen</p><p>Abstract: The responses of cortical sensory neurons are notoriously variable, with the number of spikes evoked by identical stimuli varying signiﬁcantly from trial to trial. This variability is most often interpreted as ‘noise’, purely detrimental to the sensory system. In this paper, we propose an alternative view in which the variability is related to the uncertainty, about world parameters, which is inherent in the sensory stimulus. Speciﬁcally, the responses of a population of neurons are interpreted as stochastic samples from the posterior distribution in a latent variable model. In addition to giving theoretical arguments supporting such a representational scheme, we provide simulations suggesting how some aspects of response variability might be understood in this framework.</p><p>6 0.11221537 <a title="153-tfidf-6" href="./nips-2002-Visual_Development_Aids_the_Acquisition_of_Motion_Velocity_Sensitivities.html">206 nips-2002-Visual Development Aids the Acquisition of Motion Velocity Sensitivities</a></p>
<p>7 0.11092608 <a title="153-tfidf-7" href="./nips-2002-Nonparametric_Representation_of_Policies_and_Value_Functions%3A_A_Trajectory-Based_Approach.html">155 nips-2002-Nonparametric Representation of Policies and Value Functions: A Trajectory-Based Approach</a></p>
<p>8 0.10038799 <a title="153-tfidf-8" href="./nips-2002-Classifying_Patterns_of_Visual_Motion_-_a_Neuromorphic_Approach.html">51 nips-2002-Classifying Patterns of Visual Motion - a Neuromorphic Approach</a></p>
<p>9 0.098911427 <a title="153-tfidf-9" href="./nips-2002-Learning_Attractor_Landscapes_for_Learning_Motor_Primitives.html">123 nips-2002-Learning Attractor Landscapes for Learning Motor Primitives</a></p>
<p>10 0.095778279 <a title="153-tfidf-10" href="./nips-2002-Real-Time_Monitoring_of_Complex_Industrial_Processes_with_Particle_Filters.html">168 nips-2002-Real-Time Monitoring of Complex Industrial Processes with Particle Filters</a></p>
<p>11 0.092960954 <a title="153-tfidf-11" href="./nips-2002-Real-Time_Particle_Filters.html">169 nips-2002-Real-Time Particle Filters</a></p>
<p>12 0.089485489 <a title="153-tfidf-12" href="./nips-2002-An_Information_Theoretic_Approach_to_the_Functional_Classification_of_Neurons.html">28 nips-2002-An Information Theoretic Approach to the Functional Classification of Neurons</a></p>
<p>13 0.087057807 <a title="153-tfidf-13" href="./nips-2002-Combining_Features_for_BCI.html">55 nips-2002-Combining Features for BCI</a></p>
<p>14 0.086811408 <a title="153-tfidf-14" href="./nips-2002-A_Digital_Antennal_Lobe_for_Pattern_Equalization%3A_Analysis_and_Design.html">5 nips-2002-A Digital Antennal Lobe for Pattern Equalization: Analysis and Design</a></p>
<p>15 0.084796749 <a title="153-tfidf-15" href="./nips-2002-How_Linear_are_Auditory_Cortical_Responses%3F.html">103 nips-2002-How Linear are Auditory Cortical Responses?</a></p>
<p>16 0.082650952 <a title="153-tfidf-16" href="./nips-2002-Location_Estimation_with_a_Differential_Update_Network.html">137 nips-2002-Location Estimation with a Differential Update Network</a></p>
<p>17 0.079024933 <a title="153-tfidf-17" href="./nips-2002-Hidden_Markov_Model_of_Cortical_Synaptic_Plasticity%3A_Derivation_of_the_Learning_Rule.html">102 nips-2002-Hidden Markov Model of Cortical Synaptic Plasticity: Derivation of the Learning Rule</a></p>
<p>18 0.077021509 <a title="153-tfidf-18" href="./nips-2002-Maximally_Informative_Dimensions%3A_Analyzing_Neural_Responses_to_Natural_Signals.html">141 nips-2002-Maximally Informative Dimensions: Analyzing Neural Responses to Natural Signals</a></p>
<p>19 0.075307831 <a title="153-tfidf-19" href="./nips-2002-Learning_Sparse_Topographic_Representations_with_Products_of_Student-t_Distributions.html">127 nips-2002-Learning Sparse Topographic Representations with Products of Student-t Distributions</a></p>
<p>20 0.074971974 <a title="153-tfidf-20" href="./nips-2002-An_Estimation-Theoretic_Framework_for_the_Presentation_of_Multiple_Stimuli.html">26 nips-2002-An Estimation-Theoretic Framework for the Presentation of Multiple Stimuli</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2002_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.21), (1, 0.143), (2, -0.05), (3, 0.02), (4, 0.013), (5, -0.008), (6, -0.053), (7, 0.08), (8, 0.238), (9, 0.148), (10, -0.1), (11, 0.081), (12, 0.173), (13, -0.044), (14, -0.105), (15, -0.017), (16, 0.057), (17, -0.004), (18, -0.187), (19, 0.011), (20, 0.048), (21, -0.056), (22, 0.02), (23, 0.075), (24, -0.056), (25, -0.012), (26, 0.18), (27, -0.153), (28, -0.087), (29, -0.056), (30, -0.188), (31, -0.024), (32, 0.028), (33, 0.068), (34, 0.001), (35, -0.087), (36, -0.011), (37, -0.073), (38, -0.068), (39, 0.047), (40, 0.085), (41, 0.076), (42, 0.041), (43, -0.159), (44, -0.055), (45, 0.04), (46, 0.0), (47, 0.052), (48, -0.055), (49, 0.088)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97027117 <a title="153-lsi-1" href="./nips-2002-Neural_Decoding_of_Cursor_Motion_Using_a_Kalman_Filter.html">153 nips-2002-Neural Decoding of Cursor Motion Using a Kalman Filter</a></p>
<p>Author: W Wu, M. J. Black, Y. Gao, M. Serruya, A. Shaikhouni, J. P. Donoghue, Elie Bienenstock</p><p>Abstract: The direct neural control of external devices such as computer displays or prosthetic limbs requires the accurate decoding of neural activity representing continuous movement. We develop a real-time control system using the spiking activity of approximately 40 neurons recorded with an electrode array implanted in the arm area of primary motor cortex. In contrast to previous work, we develop a control-theoretic approach that explicitly models the motion of the hand and the probabilistic relationship between this motion and the mean ﬁring rates of the cells in 70 bins. We focus on a realistic cursor control task in which the subject must move a cursor to “hit” randomly placed targets on a computer monitor. Encoding and decoding of the neural data is achieved with a Kalman ﬁlter which has a number of advantages over previous linear ﬁltering techniques. In particular, the Kalman ﬁlter reconstructions of hand trajectories in off-line experiments are more accurate than previously reported results and the model provides insights into the nature of the neural coding of movement. ¨ ©§</p><p>2 0.63363594 <a title="153-lsi-2" href="./nips-2002-A_Minimal_Intervention_Principle_for_Coordinated_Movement.html">9 nips-2002-A Minimal Intervention Principle for Coordinated Movement</a></p>
<p>Author: Emanuel Todorov, Michael I. Jordan</p><p>Abstract: Behavioral goals are achieved reliably and repeatedly with movements rarely reproducible in their detail. Here we offer an explanation: we show that not only are variability and goal achievement compatible, but indeed that allowing variability in redundant dimensions is the optimal control strategy in the face of uncertainty. The optimal feedback control laws for typical motor tasks obey a “minimal intervention” principle: deviations from the average trajectory are only corrected when they interfere with the task goals. The resulting behavior exhibits task-constrained variability, as well as synergetic coupling among actuators—which is another unexplained empirical phenomenon.</p><p>3 0.60521019 <a title="153-lsi-3" href="./nips-2002-Spikernels%3A_Embedding_Spiking_Neurons_in_Inner-Product_Spaces.html">187 nips-2002-Spikernels: Embedding Spiking Neurons in Inner-Product Spaces</a></p>
<p>Author: Lavi Shpigelman, Yoram Singer, Rony Paz, Eilon Vaadia</p><p>Abstract: Inner-product operators, often referred to as kernels in statistical learning, deﬁne a mapping from some input space into a feature space. The focus of this paper is the construction of biologically-motivated kernels for cortical activities. The kernels we derive, termed Spikernels, map spike count sequences into an abstract vector space in which we can perform various prediction tasks. We discuss in detail the derivation of Spikernels and describe an efﬁcient algorithm for computing their value on any two sequences of neural population spike counts. We demonstrate the merits of our modeling approach using the Spikernel and various standard kernels for the task of predicting hand movement velocities from cortical recordings. In all of our experiments all the kernels we tested outperform the standard scalar product used in regression with the Spikernel consistently achieving the best performance. 1</p><p>4 0.53178638 <a title="153-lsi-4" href="./nips-2002-Adaptive_Classification_by_Variational_Kalman_Filtering.html">21 nips-2002-Adaptive Classification by Variational Kalman Filtering</a></p>
<p>Author: Peter Sykacek, Stephen J. Roberts</p><p>Abstract: We propose in this paper a probabilistic approach for adaptive inference of generalized nonlinear classiﬁcation that combines the computational advantage of a parametric solution with the ﬂexibility of sequential sampling techniques. We regard the parameters of the classiﬁer as latent states in a ﬁrst order Markov process and propose an algorithm which can be regarded as variational generalization of standard Kalman ﬁltering. The variational Kalman ﬁlter is based on two novel lower bounds that enable us to use a non-degenerate distribution over the adaptation rate. An extensive empirical evaluation demonstrates that the proposed method is capable of infering competitive classiﬁers both in stationary and non-stationary environments. Although we focus on classiﬁcation, the algorithm is easily extended to other generalized nonlinear models.</p><p>5 0.48793715 <a title="153-lsi-5" href="./nips-2002-Learning_Attractor_Landscapes_for_Learning_Motor_Primitives.html">123 nips-2002-Learning Attractor Landscapes for Learning Motor Primitives</a></p>
<p>Author: Auke J. Ijspeert, Jun Nakanishi, Stefan Schaal</p><p>Abstract: Many control problems take place in continuous state-action spaces, e.g., as in manipulator robotics, where the control objective is often deﬁned as ﬁnding a desired trajectory that reaches a particular goal state. While reinforcement learning oﬀers a theoretical framework to learn such control policies from scratch, its applicability to higher dimensional continuous state-action spaces remains rather limited to date. Instead of learning from scratch, in this paper we suggest to learn a desired complex control policy by transforming an existing simple canonical control policy. For this purpose, we represent canonical policies in terms of diﬀerential equations with well-deﬁned attractor properties. By nonlinearly transforming the canonical attractor dynamics using techniques from nonparametric regression, almost arbitrary new nonlinear policies can be generated without losing the stability properties of the canonical system. We demonstrate our techniques in the context of learning a set of movement skills for a humanoid robot from demonstrations of a human teacher. Policies are acquired rapidly, and, due to the properties of well formulated diﬀerential equations, can be re-used and modiﬁed on-line under dynamic changes of the environment. The linear parameterization of nonparametric regression moreover lends itself to recognize and classify previously learned movement skills. Evaluations in simulations and on an actual 30 degree-offreedom humanoid robot exemplify the feasibility and robustness of our approach. 1</p><p>6 0.48144931 <a title="153-lsi-6" href="./nips-2002-Expected_and_Unexpected_Uncertainty%3A_ACh_and_NE_in_the_Neocortex.html">81 nips-2002-Expected and Unexpected Uncertainty: ACh and NE in the Neocortex</a></p>
<p>7 0.42469305 <a title="153-lsi-7" href="./nips-2002-Combining_Features_for_BCI.html">55 nips-2002-Combining Features for BCI</a></p>
<p>8 0.42297906 <a title="153-lsi-8" href="./nips-2002-Real-Time_Monitoring_of_Complex_Industrial_Processes_with_Particle_Filters.html">168 nips-2002-Real-Time Monitoring of Complex Industrial Processes with Particle Filters</a></p>
<p>9 0.40896374 <a title="153-lsi-9" href="./nips-2002-Adaptation_and_Unsupervised_Learning.html">18 nips-2002-Adaptation and Unsupervised Learning</a></p>
<p>10 0.36873019 <a title="153-lsi-10" href="./nips-2002-Interpreting_Neural_Response_Variability_as_Monte_Carlo_Sampling_of_the_Posterior.html">116 nips-2002-Interpreting Neural Response Variability as Monte Carlo Sampling of the Posterior</a></p>
<p>11 0.36580202 <a title="153-lsi-11" href="./nips-2002-Visual_Development_Aids_the_Acquisition_of_Motion_Velocity_Sensitivities.html">206 nips-2002-Visual Development Aids the Acquisition of Motion Velocity Sensitivities</a></p>
<p>12 0.35057744 <a title="153-lsi-12" href="./nips-2002-Real-Time_Particle_Filters.html">169 nips-2002-Real-Time Particle Filters</a></p>
<p>13 0.34685355 <a title="153-lsi-13" href="./nips-2002-Learning_a_Forward_Model_of_a_Reflex.html">128 nips-2002-Learning a Forward Model of a Reflex</a></p>
<p>14 0.33731291 <a title="153-lsi-14" href="./nips-2002-Nonparametric_Representation_of_Policies_and_Value_Functions%3A_A_Trajectory-Based_Approach.html">155 nips-2002-Nonparametric Representation of Policies and Value Functions: A Trajectory-Based Approach</a></p>
<p>15 0.33686981 <a title="153-lsi-15" href="./nips-2002-Scaling_of_Probability-Based_Optimization_Algorithms.html">179 nips-2002-Scaling of Probability-Based Optimization Algorithms</a></p>
<p>16 0.33284232 <a title="153-lsi-16" href="./nips-2002-A_Model_for_Real-Time_Computation_in_Generic_Neural_Microcircuits.html">11 nips-2002-A Model for Real-Time Computation in Generic Neural Microcircuits</a></p>
<p>17 0.32489511 <a title="153-lsi-17" href="./nips-2002-Multiple_Cause_Vector_Quantization.html">150 nips-2002-Multiple Cause Vector Quantization</a></p>
<p>18 0.32224208 <a title="153-lsi-18" href="./nips-2002-Developing_Topography_and_Ocular_Dominance_Using_Two_aVLSI_Vision_Sensors_and_a_Neurotrophic_Model_of_Plasticity.html">66 nips-2002-Developing Topography and Ocular Dominance Using Two aVLSI Vision Sensors and a Neurotrophic Model of Plasticity</a></p>
<p>19 0.3209154 <a title="153-lsi-19" href="./nips-2002-Learning_Sparse_Topographic_Representations_with_Products_of_Student-t_Distributions.html">127 nips-2002-Learning Sparse Topographic Representations with Products of Student-t Distributions</a></p>
<p>20 0.31880629 <a title="153-lsi-20" href="./nips-2002-A_Hierarchical_Bayesian_Markovian_Model_for_Motifs_in_Biopolymer_Sequences.html">7 nips-2002-A Hierarchical Bayesian Markovian Model for Motifs in Biopolymer Sequences</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2002_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(23, 0.441), (42, 0.049), (54, 0.079), (55, 0.064), (57, 0.052), (64, 0.017), (68, 0.026), (74, 0.06), (92, 0.02), (98, 0.107)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.88818932 <a title="153-lda-1" href="./nips-2002-An_Estimation-Theoretic_Framework_for_the_Presentation_of_Multiple_Stimuli.html">26 nips-2002-An Estimation-Theoretic Framework for the Presentation of Multiple Stimuli</a></p>
<p>Author: Christian W. Eurich</p><p>Abstract: A framework is introduced for assessing the encoding accuracy and the discriminational ability of a population of neurons upon simultaneous presentation of multiple stimuli. Minimal square estimation errors are obtained from a Fisher information analysis in an abstract compound space comprising the features of all stimuli. Even for the simplest case of linear superposition of responses and Gaussian tuning, the symmetries in the compound space are very diﬀerent from those in the case of a single stimulus. The analysis allows for a quantitative description of attentional eﬀects and can be extended to include neural nonlinearities such as nonclassical receptive ﬁelds. 1</p><p>same-paper 2 0.87974215 <a title="153-lda-2" href="./nips-2002-Neural_Decoding_of_Cursor_Motion_Using_a_Kalman_Filter.html">153 nips-2002-Neural Decoding of Cursor Motion Using a Kalman Filter</a></p>
<p>Author: W Wu, M. J. Black, Y. Gao, M. Serruya, A. Shaikhouni, J. P. Donoghue, Elie Bienenstock</p><p>Abstract: The direct neural control of external devices such as computer displays or prosthetic limbs requires the accurate decoding of neural activity representing continuous movement. We develop a real-time control system using the spiking activity of approximately 40 neurons recorded with an electrode array implanted in the arm area of primary motor cortex. In contrast to previous work, we develop a control-theoretic approach that explicitly models the motion of the hand and the probabilistic relationship between this motion and the mean ﬁring rates of the cells in 70 bins. We focus on a realistic cursor control task in which the subject must move a cursor to “hit” randomly placed targets on a computer monitor. Encoding and decoding of the neural data is achieved with a Kalman ﬁlter which has a number of advantages over previous linear ﬁltering techniques. In particular, the Kalman ﬁlter reconstructions of hand trajectories in off-line experiments are more accurate than previously reported results and the model provides insights into the nature of the neural coding of movement. ¨ ©§</p><p>3 0.87360722 <a title="153-lda-3" href="./nips-2002-Improving_Transfer_Rates_in_Brain_Computer_Interfacing%3A_A_Case_Study.html">108 nips-2002-Improving Transfer Rates in Brain Computer Interfacing: A Case Study</a></p>
<p>Author: Peter Meinicke, Matthias Kaper, Florian Hoppe, Manfred Heumann, Helge Ritter</p><p>Abstract: In this paper we present results of a study on brain computer interfacing. We adopted an approach of Farwell & Donchin [4], which we tried to improve in several aspects. The main objective was to improve the transfer rates based on ofﬂine analysis of EEG-data but within a more realistic setup closer to an online realization than in the original studies. The objective was achieved along two different tracks: on the one hand we used state-of-the-art machine learning techniques for signal classiﬁcation and on the other hand we augmented the data space by using more electrodes for the interface. For the classiﬁcation task we utilized SVMs and, as motivated by recent ﬁndings on the learning of discriminative densities, we accumulated the values of the classiﬁcation function in order to combine several classiﬁcations, which ﬁnally lead to signiﬁcantly improved rates as compared with techniques applied in the original work. In combination with the data space augmentation, we achieved competitive transfer rates at an average of 50.5 bits/min and with a maximum of 84.7 bits/min.</p><p>4 0.69348204 <a title="153-lda-4" href="./nips-2002-Approximate_Linear_Programming_for_Average-Cost_Dynamic_Programming.html">33 nips-2002-Approximate Linear Programming for Average-Cost Dynamic Programming</a></p>
<p>Author: Benjamin V. Roy, Daniela D. Farias</p><p>Abstract: This paper extends our earlier analysis on approximate linear programming as an approach to approximating the cost-to-go function in a discounted-cost dynamic program [6]. In this paper, we consider the average-cost criterion and a version of approximate linear programming that generates approximations to the optimal average cost and differential cost function. We demonstrate that a naive version of approximate linear programming prioritizes approximation of the optimal average cost and that this may not be well-aligned with the objective of deriving a policy with low average cost. For that, the algorithm should aim at producing a good approximation of the differential cost function. We propose a twophase variant of approximate linear programming that allows for external control of the relative accuracy of the approximation of the differential cost function over different portions of the state space via state-relevance weights. Performance bounds suggest that the new algorithm is compatible with the objective of optimizing performance and provide guidance on appropriate choices for state-relevance weights.</p><p>5 0.53279454 <a title="153-lda-5" href="./nips-2002-Morton-Style_Factorial_Coding_of_Color_in_Primary_Visual_Cortex.html">148 nips-2002-Morton-Style Factorial Coding of Color in Primary Visual Cortex</a></p>
<p>Author: Javier R. Movellan, Thomas Wachtler, Thomas D. Albright, Terrence Sejnowski</p><p>Abstract: We introduce the notion of Morton-style factorial coding and illustrate how it may help understand information integration and perceptual coding in the brain. We show that by focusing on average responses one may miss the existence of factorial coding mechanisms that become only apparent when analyzing spike count histograms. We show evidence suggesting that the classical/non-classical receptive ﬁeld organization in the cortex effectively enforces the development of Morton-style factorial codes. This may provide some cues to help understand perceptual coding in the brain and to develop new unsupervised learning algorithms. While methods like ICA (Bell & Sejnowski, 1997) develop independent codes, in Morton-style coding the goal is to make two or more external aspects of the world become independent when conditioning on internal representations. In this paper we introduce the notion of Morton-style factorial coding and illustrate how it may help analyze information integration and perceptual organization in the brain. In the neurosciences factorial codes are often studied in the context of mean tuning curves. A tuning curve is called separable if it can be expressed as the product of terms selectively inﬂuenced by different stimulus dimensions. Separable tuning curves are taken as evidence of factorial coding mechanisms. In this paper we show that by focusing on average responses one may miss the existence of factorial coding mechanisms that become only apparent when analyzing spike count histograms. Morton (1969) analyzed a wide variety of psychophysical experiments on word perception and showed that they could be explained using a model in which stimulus and context have separable effects on perception. More precisely, in Mortons’ model the joint effect of stimulus and context on a perceptual representation can be obtained by multiplying terms selectively controlled by stimulus and by context, i.e.,  £ © # #</p><p>6 0.52021998 <a title="153-lda-6" href="./nips-2002-Combining_Features_for_BCI.html">55 nips-2002-Combining Features for BCI</a></p>
<p>7 0.50545287 <a title="153-lda-7" href="./nips-2002-A_Digital_Antennal_Lobe_for_Pattern_Equalization%3A_Analysis_and_Design.html">5 nips-2002-A Digital Antennal Lobe for Pattern Equalization: Analysis and Design</a></p>
<p>8 0.50325072 <a title="153-lda-8" href="./nips-2002-Binary_Tuning_is_Optimal_for_Neural_Rate_Coding_with_High_Temporal_Resolution.html">44 nips-2002-Binary Tuning is Optimal for Neural Rate Coding with High Temporal Resolution</a></p>
<p>9 0.49502453 <a title="153-lda-9" href="./nips-2002-Learning_Attractor_Landscapes_for_Learning_Motor_Primitives.html">123 nips-2002-Learning Attractor Landscapes for Learning Motor Primitives</a></p>
<p>10 0.48986697 <a title="153-lda-10" href="./nips-2002-Spectro-Temporal_Receptive_Fields_of_Subthreshold_Responses_in_Auditory_Cortex.html">184 nips-2002-Spectro-Temporal Receptive Fields of Subthreshold Responses in Auditory Cortex</a></p>
<p>11 0.48041648 <a title="153-lda-11" href="./nips-2002-Spikernels%3A_Embedding_Spiking_Neurons_in_Inner-Product_Spaces.html">187 nips-2002-Spikernels: Embedding Spiking Neurons in Inner-Product Spaces</a></p>
<p>12 0.47656125 <a title="153-lda-12" href="./nips-2002-Binary_Coding_in_Auditory_Cortex.html">43 nips-2002-Binary Coding in Auditory Cortex</a></p>
<p>13 0.47454536 <a title="153-lda-13" href="./nips-2002-Timing_and_Partial_Observability_in_the_Dopamine_System.html">199 nips-2002-Timing and Partial Observability in the Dopamine System</a></p>
<p>14 0.47126693 <a title="153-lda-14" href="./nips-2002-Nonparametric_Representation_of_Policies_and_Value_Functions%3A_A_Trajectory-Based_Approach.html">155 nips-2002-Nonparametric Representation of Policies and Value Functions: A Trajectory-Based Approach</a></p>
<p>15 0.47110963 <a title="153-lda-15" href="./nips-2002-A_Convergent_Form_of_Approximate_Policy_Iteration.html">3 nips-2002-A Convergent Form of Approximate Policy Iteration</a></p>
<p>16 0.46971756 <a title="153-lda-16" href="./nips-2002-Selectivity_and_Metaplasticity_in_a_Unified_Calcium-Dependent_Model.html">180 nips-2002-Selectivity and Metaplasticity in a Unified Calcium-Dependent Model</a></p>
<p>17 0.46823013 <a title="153-lda-17" href="./nips-2002-Maximally_Informative_Dimensions%3A_Analyzing_Neural_Responses_to_Natural_Signals.html">141 nips-2002-Maximally Informative Dimensions: Analyzing Neural Responses to Natural Signals</a></p>
<p>18 0.46499977 <a title="153-lda-18" href="./nips-2002-Exponential_Family_PCA_for_Belief_Compression_in_POMDPs.html">82 nips-2002-Exponential Family PCA for Belief Compression in POMDPs</a></p>
<p>19 0.45672429 <a title="153-lda-19" href="./nips-2002-An_Information_Theoretic_Approach_to_the_Functional_Classification_of_Neurons.html">28 nips-2002-An Information Theoretic Approach to the Functional Classification of Neurons</a></p>
<p>20 0.44328314 <a title="153-lda-20" href="./nips-2002-Expected_and_Unexpected_Uncertainty%3A_ACh_and_NE_in_the_Neocortex.html">81 nips-2002-Expected and Unexpected Uncertainty: ACh and NE in the Neocortex</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
