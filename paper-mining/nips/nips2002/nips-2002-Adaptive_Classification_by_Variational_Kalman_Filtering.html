<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>21 nips-2002-Adaptive Classification by Variational Kalman Filtering</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-21" href="#">nips2002-21</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>21 nips-2002-Adaptive Classification by Variational Kalman Filtering</h1>
<br/><p>Source: <a title="nips-2002-21-pdf" href="http://papers.nips.cc/paper/2227-adaptive-classification-by-variational-kalman-filtering.pdf">pdf</a></p><p>Author: Peter Sykacek, Stephen J. Roberts</p><p>Abstract: We propose in this paper a probabilistic approach for adaptive inference of generalized nonlinear classiﬁcation that combines the computational advantage of a parametric solution with the ﬂexibility of sequential sampling techniques. We regard the parameters of the classiﬁer as latent states in a ﬁrst order Markov process and propose an algorithm which can be regarded as variational generalization of standard Kalman ﬁltering. The variational Kalman ﬁlter is based on two novel lower bounds that enable us to use a non-degenerate distribution over the adaptation rate. An extensive empirical evaluation demonstrates that the proposed method is capable of infering competitive classiﬁers both in stationary and non-stationary environments. Although we focus on classiﬁcation, the algorithm is easily extended to other generalized nonlinear models.</p><p>Reference: <a title="nips-2002-21-reference" href="../nips2002_reference/nips-2002-Adaptive_Classification_by_Variational_Kalman_Filtering_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 uk  Abstract We propose in this paper a probabilistic approach for adaptive inference of generalized nonlinear classiﬁcation that combines the computational advantage of a parametric solution with the ﬂexibility of sequential sampling techniques. [sent-7, score-0.54]
</p><p>2 We regard the parameters of the classiﬁer as latent states in a ﬁrst order Markov process and propose an algorithm which can be regarded as variational generalization of standard Kalman ﬁltering. [sent-8, score-0.709]
</p><p>3 The variational Kalman ﬁlter is based on two novel lower bounds that enable us to use a non-degenerate distribution over the adaptation rate. [sent-9, score-0.609]
</p><p>4 An extensive empirical evaluation demonstrates that the proposed method is capable of infering competitive classiﬁers both in stationary and non-stationary environments. [sent-10, score-0.216]
</p><p>5 Although we focus on classiﬁcation, the algorithm is easily extended to other generalized nonlinear models. [sent-11, score-0.109]
</p><p>6 1 Introduction The demand for adaptive learning methods, e. [sent-12, score-0.124]
</p><p>7 We may approach adaptive learning with algorithms that were designed for stationary environments and use learning rates to make these methods adaptive. [sent-15, score-0.207]
</p><p>8 A more recent account to this approach is [17], who combines the probabilistic method of sequential variational inference ([9]) and a forgetting factor to obtain an adaptive learning method. [sent-19, score-0.794]
</p><p>9 Probabilistic or Bayesian methods allow also for a completely different interpretation of adaptive learning. [sent-20, score-0.162]
</p><p>10 We may regard the model coefﬁcients as latent (i. [sent-21, score-0.095]
</p><p>11 £ ¦¤¢   © § ¥  © § ¥ £¡ ¨ ¨¦¤¢   The posterior distribution, , at state summarizes all information obtained about the model. [sent-25, score-0.137]
</p><p>12 This posterior and the conditional distribution, , represent the prior for the following state. [sent-26, score-0.138]
</p><p>13 The conditional distribution can be thought of as additive process or state noise with precision . [sent-27, score-0.211]
</p><p>14 Predictions are obtained by a probabilistic observation model . [sent-28, score-0.032]
</p><p>15 Using this model, we obtain an appropriate adaptation   $ " © § ¥  ¥ £¡ 7654¨¦£ 1¤¢   "   ¥ 9 ¥ ' ¥ ¤8  £ &¡  "  rate by hierarchical Bayesian inference of the process noise precision . [sent-29, score-0.498]
</p><p>16 Equation (1) suggests that we may interpret adaptive Bayesian inference as generalization of the well known Kalman ﬁlter ([12]). [sent-30, score-0.386]
</p><p>17 This view of adaptive learning has been used by [6], who use extended Kalman ﬁltering to obtain a Laplace approximation of the posterior over and maximum likelihood II ([3]) for inference of the adaptation rate. [sent-31, score-0.516]
</p><p>18 Another generalization of Kalman ﬁltering are the recently quite popular particle ﬁlters (e. [sent-32, score-0.186]
</p><p>19 Being Monte Carlo methods, particle ﬁlters have over Laplace approximations the advantage of much greater ﬂexibility. [sent-35, score-0.064]
</p><p>20 To combine the ﬂexibility of particle ﬁltering with the computational advantage of parametric methods, we propose a variational approximation (e. [sent-37, score-0.521]
</p><p>21 [11] , [2] and [8]) for inference of the Markov process in Equation (1). [sent-39, score-0.18]
</p><p>22 Unlike maximum likelihood II, the variational Kalman ﬁlter allows us to have a non degenerate distribution over the process noise precision. [sent-40, score-0.463]
</p><p>23 We derive in this paper a variational Kalman ﬁlter classiﬁer and show with an extensive empirical evaluation that the resulting classiﬁers obtain excellent generalization accuracies both in stationary and non-stationary domains. [sent-41, score-0.912]
</p><p>24 1 A generalized nonlinear classiﬁer  ¥ '  Classiﬁcation is a prediction problem, where some regressor, , predicts the expectation of a response variable . [sent-43, score-0.142]
</p><p>25 To obtain a ﬂexible discriminant, we use a generalized nonlinear model, i. [sent-46, score-0.169]
</p><p>26 a radial basis function (RBF) network ([14] and [5]), with logistic output transformation (Equation (3)). [sent-48, score-0.104]
</p><p>27 £  ¥ ©  § ( ¥  ¨ ¥ § £ ¥ § ¨ ¥    ¢£ ¥ ' ¡  ¥ 9 2 ©  ' ,  (2) (3)  The classiﬁer has a nonlinear feature space which for reasons of adaptivity depends and a linear mapping into latent space . [sent-50, score-0.159]
</p><p>28 Both basis functions are parameterized by their center locations . [sent-56, score-0.047]
</p><p>29 Since we want to have a simple unimodal posterior over model parameters, we update the coefﬁcients of the basis set randomly according to a Metropolis Hastings kernel ([13]) and solve for the conditional posterior analytically. [sent-57, score-0.257]
</p><p>30 2 The variational Kalman ﬁlter In order to ease discussion of adaptive inference, we illustrate the dependencies implied by Equation (1) in ﬁgure 1 as a directed acyclic graph (DAG). [sent-61, score-0.545]
</p><p>31 In accordance with Kalman ﬁltering, we assume a Gaussian posterior at time with mean and precision and zero mean Gaussian state noise with isotropic precision . [sent-62, score-0.44]
</p><p>32 Inference of is based on a “ﬂat” proper Gamma prior speciﬁed by parameters and . [sent-63, score-0.033]
</p><p>33 In order to obtain reasonable posteriors over , we follow [10] and assume constant adaptation within a window of size . [sent-64, score-0.34]
</p><p>34 The proposed variational Bayesian approach ignores the anti-causal information ﬂow and is thus based on maximizing a lower bound on the logarithmic model evidence of a windowed Kalman ﬁlter. [sent-65, score-0.542]
</p><p>35 Following these assumptions, we obtain the expression for the log evidence in Equation (4) by substituting the generalized nonlinear model (Equations (2) to (3)) into the formulation of adaptive Bayesian learning (1). [sent-66, score-0.369]
</p><p>36 The hyper parameter is given a Gamma prior speciﬁed by parameters and . [sent-69, score-0.073]
</p><p>37 V  ¥ £  "  U  distributions explicit and integrate over all model coefﬁcients, which is done analytically over all prior states . [sent-70, score-0.033]
</p><p>38 "   9 ¨   ¢  7BQI ¡ ¡ RP  £ ¤  # # #  The structure of Equation (4) suggests that the approximate posterior can be chosen can be chosen to be a Gamma distributo be Gaussian and the approximate posterior tion. [sent-72, score-0.21]
</p><p>39 These functional forms do however not simply result from a mean ﬁeld approximation of the posterior as . [sent-73, score-0.105]
</p><p>40 In order to obtain the required conjugacy, we have to use lower bounds for the probability of the target label, and for both and . [sent-74, score-0.202]
</p><p>41 In order to get expressions that are conjugate with a Gamma distribution over the process noise precision , we derive two novel lower bounds. [sent-78, score-0.326]
</p><p>42 Assuming a -dimensional parameter vector , we get  "  I  $  S T ¦# £! [sent-79, score-0.04]
</p><p>43 Both bounds are expanded in the identical parameter which is justiﬁed since both are linear expansions in and maximization must thus lead to identical values. [sent-81, score-0.296]
</p><p>44 Using these lower bounds together with a mean ﬁeld assumption, , and the usual Jensens inequalities, we immediately obtain a negative free energy as lower bound of the log evidence in Equation (4). [sent-82, score-0.51]
</p><p>45 For reasons of brevity we do not include this expression here. [sent-83, score-0.043]
</p><p>46 4 Parameter updates In order to distinguish between the parameters of the prior and posterior distributions, we henceforth denote the latter with superscript . [sent-85, score-0.138]
</p><p>47 Inference requires to maximize the negative free energy with respect to all variational parameters. [sent-86, score-0.563]
</p><p>48 These are the coefﬁcients of the Gaussian distributions, , the parameters in the bounds of the logistic sigmoid, , the coefﬁcients of the Gamma posterior over the noise process precision, and the parameter in the Gamma conjugacy bounds, . [sent-87, score-0.464]
</p><p>49 Maximization with respect to results in a Gaussian distribution with precision and mean . [sent-88, score-0.162]
</p><p>50 © 3   ¥  §  ) 0' %  ¥  a V `   © ¨ ¤  2  ) 0' %  If we assume that the negative free energy describes the log evidence exactly, this is a Metropolis Hastings kernel ([13]) that leaves the marginal posterior invariant. [sent-94, score-0.33]
</p><p>51 We could thus represent the marginal posterior with random samples. [sent-95, score-0.105]
</p><p>52 For computational reasons however, we use the scheme only for random updates of . [sent-96, score-0.043]
</p><p>53 An algorithm for parameter inference will ﬁrst propose a random update of and then iterate maximizations according to Equation (8) to Equation (11) until we observe convergence of the negative free energy. [sent-97, score-0.309]
</p><p>54 5 Model predictions Since we do not know the response when predicting, we have to sum the negative free energy over . [sent-103, score-0.149]
</p><p>55 This results in a new expression for which we obtain from Equation (8) by dropping the term that depends on . [sent-104, score-0.06]
</p><p>56 Due to the dependency on , maximization has to alternate with maximization with respect to , the latter with respect to again being done according to Equation (10). [sent-105, score-0.27]
</p><p>57 Having reached convergence, we obtain an approximate log probability for by taking the expectation of the bound of the sigmoid in Equation (5) with respect to and maximizing with respect to . [sent-106, score-0.302]
</p><p>58   ¥ &  3 Experiments All experiments reported in this section use a model with Gaussian basis functions with precision . [sent-110, score-0.175]
</p><p>59 The initial prior over parameters is a zero mean Gaussian with precision with isotropic precision . [sent-112, score-0.325]
</p><p>60 For maximizing the negative free energy we use iterations. [sent-113, score-0.188]
</p><p>61 The ﬁrst experiment aims at obtaining a parametrization for , and the window length, , that allows us to make inferences of the process noise that are insensitive to the actual “drift” of the problem. [sent-114, score-0.323]
</p><p>62 The samples of this balanced problem are reshufﬂed such that consecutive class labels differ. [sent-116, score-0.038]
</p><p>63 In order to get a non-stationarity, we swap the class labels in the second half of the data. [sent-117, score-0.033]
</p><p>64 We propose these settings together with a window size , because this is a good compromise between fast tracking and high stationary accuracy. [sent-119, score-0.316]
</p><p>65 Simulations using σλ=1e+003 350 300 250  window sz. [sent-126, score-0.193]
</p><p>66 The top graph shows the expected value of the precision of the noise process, for different window sizes (i. [sent-141, score-0.364]
</p><p>67 for different numbers of samples used for infering the adaptation rate). [sent-143, score-0.226]
</p><p>68 The bottom graph shows the instantaneous generalization accuracy estimated in a window of size . [sent-144, score-0.315]
</p><p>69 The prior over is a Gamma distribution with expectation and variance . [sent-145, score-0.033]
</p><p>70 ¨  ££ ¤  ¨  (  "  ¥  ¡ B  ¦ §¡ 2  ¡ ¡  3  1  ¤  ¡ ¢"    2  the results, we compare the generalization accuracy of the variational Kalman ﬁlter classiﬁer (vkf) with an identical non-adaptive model. [sent-146, score-0.534]
</p><p>71 Inference of the static model is based on sequential variational learning ([9]). [sent-147, score-0.519]
</p><p>72 We obtain sequential variational inference (svi) from our approach by setting in Equation (1) to inﬁnity. [sent-148, score-0.67]
</p><p>73 The comparison uses vehicle data2 , satellite image data, Johns Hopkins University ionosphere data, balance scale weight and distance data and the wine recognition database, all taken from the StatLog database which is available at the UCI repository ([4]). [sent-150, score-0.388]
</p><p>74 The satellite image data set is used as is provided with 4435 samples in the training and 2000 samples in the test set. [sent-151, score-0.177]
</p><p>75 Vehicle data are merged such that we have 500 samples in the training and 252 in the test set. [sent-152, score-0.038]
</p><p>76 The other data were split into two equal sized data sets, which were both used as training and independent test sets respectively. [sent-153, score-0.041]
</p><p>77 We also use the pima diabetes data set from [16]3 . [sent-154, score-0.121]
</p><p>78 Table 1 compares the generalization accuracies (in fractions) obtained with the variational Kalman ﬁlter with generalization accuracies obtained with , that both sequential variational inference. [sent-155, score-1.628]
</p><p>79 Since the generalization accuracies of both methods are almost identical, we conclude that if applied to  "  ¤  3  Vehicle data was donated to StatLog by the Turing Institute Glasgow, Scotland. [sent-157, score-0.357]
</p><p>80 ionosphere Satellite image Balance scale Pima diabetes Vehicle Wine  Generalization results vkf svi 0. [sent-166, score-0.37]
</p><p>81 25   ¨ ¥  Data sets  Table 1: Generalization accuracies obtained with the variational Kalman ﬁlter (vkf) and sequential variational inference (svi). [sent-184, score-1.257]
</p><p>82 ¤  rest/move, no feedback rest/move, feedback move/math, no feedback move/math, feedback  Generalization results vkf svi 0. [sent-185, score-0.506]
</p><p>83 00  ©¥ ¨  Cognitive task  Table 2: Generalization accuracies obtained for classiﬁcation of single trial EEG show that the variational Kalman ﬁlter signiﬁcantly improves the results in three out of four cases. [sent-197, score-0.687]
</p><p>84 stationary problems, we may expect the variational Kalman ﬁlter to obtain generalization accuracies that are similar to those of static methods. [sent-198, score-0.929]
</p><p>85 In order to assess the variational Kalman ﬁlter on a non-stationary problem, we apply it to classiﬁcation of single trial EEG, a problem which is part of BCIs. [sent-199, score-0.42]
</p><p>86 We classify on a one second basis an thus have per subject samples. [sent-204, score-0.047]
</p><p>87 The regressors in this experiment are three reﬂection and task combination coefﬁcients (a parametrization of autoregressive models, see e. [sent-205, score-0.047]
</p><p>88 The comparison in table 2 reports within subject results obtained by two fold cross testing. [sent-208, score-0.065]
</p><p>89 Using half of the data, we allow for convergence of the methods before estimating the generalization accuracy on the other half of the data. [sent-209, score-0.226]
</p><p>90 The generalization accuracies in table 2 are averaged across subjects. [sent-210, score-0.39]
</p><p>91 We obtain in three out of four experiments a signiﬁcant improvement with the variational Kalman ﬁlter. [sent-211, score-0.44]
</p><p>92 ¡ B¡ 1  4 Discussion We propose in this paper a parametric approach for adaptive inference of nonlinear classiﬁcation. [sent-212, score-0.4]
</p><p>93 Our algorithm can be regarded as variational generalization of Kalman ﬁltering which we obtain by using two novel lower bounds that allow us to have a non-degenerate distribution over the adaptation rate. [sent-213, score-0.861]
</p><p>94 Inference is done by iteratively maximizing a lower bound of the log evidence. [sent-214, score-0.158]
</p><p>95 As a result we obtain an approximate posterior that is a product of a multivariate Gaussian and a Gamma distribution. [sent-215, score-0.165]
</p><p>96 Our simulations have shown that the approach is capable of infering classiﬁers that have good generalization performance both in stationary and non-stationary domains. [sent-216, score-0.338]
</p><p>97 in the BCI experiments reported above, prediction and parameter updates can be done in real time on conventional PCs. [sent-219, score-0.073]
</p><p>98 Although we focus on classiﬁcation, the algorithm is  based on general ideas and thus easily applicable to other generalized nonlinear models. [sent-220, score-0.109]
</p><p>99 Inferring parameters and structure of latent variable models by variational Bayes. [sent-231, score-0.437]
</p><p>100 A new approach to linear ﬁltering and prediction problems. [sent-313, score-0.033]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('variational', 0.38), ('kalman', 0.343), ('bqi', 0.237), ('accuracies', 0.235), ('gamma', 0.199), ('window', 0.193), ('classi', 0.147), ('inference', 0.14), ('svi', 0.135), ('vkf', 0.135), ('precision', 0.128), ('adaptive', 0.124), ('generalization', 0.122), ('lter', 0.118), ('vehicle', 0.107), ('posterior', 0.105), ('infering', 0.101), ('satellite', 0.101), ('sykacek', 0.101), ('maximization', 0.101), ('eeg', 0.1), ('bounds', 0.091), ('sequential', 0.09), ('conjugacy', 0.088), ('adaptation', 0.087), ('stationary', 0.083), ('ltering', 0.08), ('metropolis', 0.075), ('cients', 0.072), ('pima', 0.071), ('equation', 0.07), ('coef', 0.07), ('statlog', 0.068), ('sigmoid', 0.067), ('particle', 0.064), ('er', 0.06), ('energy', 0.06), ('obtain', 0.06), ('nonlinear', 0.059), ('bayesian', 0.059), ('feedback', 0.059), ('rosenbluth', 0.059), ('hastings', 0.059), ('imagined', 0.059), ('latent', 0.057), ('logistic', 0.057), ('gaussian', 0.055), ('oxford', 0.055), ('free', 0.054), ('rp', 0.051), ('lower', 0.051), ('diabetes', 0.05), ('ionosphere', 0.05), ('wine', 0.05), ('generalized', 0.05), ('balance', 0.049), ('static', 0.049), ('parametrization', 0.047), ('roberts', 0.047), ('basis', 0.047), ('freitas', 0.045), ('noise', 0.043), ('reasons', 0.043), ('acyclic', 0.041), ('sized', 0.041), ('laplace', 0.041), ('cation', 0.041), ('propose', 0.04), ('evidence', 0.04), ('ers', 0.04), ('trial', 0.04), ('process', 0.04), ('parameter', 0.04), ('maximizing', 0.039), ('movements', 0.038), ('regard', 0.038), ('allow', 0.038), ('samples', 0.038), ('parametric', 0.037), ('isotropic', 0.036), ('log', 0.036), ('negative', 0.035), ('jordan', 0.034), ('respect', 0.034), ('expressions', 0.033), ('half', 0.033), ('prediction', 0.033), ('prior', 0.033), ('table', 0.033), ('extensive', 0.032), ('obtained', 0.032), ('identical', 0.032), ('pages', 0.032), ('bound', 0.032), ('simulations', 0.032), ('regarded', 0.032), ('conjugate', 0.031), ('exibility', 0.031), ('jaakkola', 0.031), ('repository', 0.031)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999997 <a title="21-tfidf-1" href="./nips-2002-Adaptive_Classification_by_Variational_Kalman_Filtering.html">21 nips-2002-Adaptive Classification by Variational Kalman Filtering</a></p>
<p>Author: Peter Sykacek, Stephen J. Roberts</p><p>Abstract: We propose in this paper a probabilistic approach for adaptive inference of generalized nonlinear classiﬁcation that combines the computational advantage of a parametric solution with the ﬂexibility of sequential sampling techniques. We regard the parameters of the classiﬁer as latent states in a ﬁrst order Markov process and propose an algorithm which can be regarded as variational generalization of standard Kalman ﬁltering. The variational Kalman ﬁlter is based on two novel lower bounds that enable us to use a non-degenerate distribution over the adaptation rate. An extensive empirical evaluation demonstrates that the proposed method is capable of infering competitive classiﬁers both in stationary and non-stationary environments. Although we focus on classiﬁcation, the algorithm is easily extended to other generalized nonlinear models.</p><p>2 0.22795288 <a title="21-tfidf-2" href="./nips-2002-Neural_Decoding_of_Cursor_Motion_Using_a_Kalman_Filter.html">153 nips-2002-Neural Decoding of Cursor Motion Using a Kalman Filter</a></p>
<p>Author: W Wu, M. J. Black, Y. Gao, M. Serruya, A. Shaikhouni, J. P. Donoghue, Elie Bienenstock</p><p>Abstract: The direct neural control of external devices such as computer displays or prosthetic limbs requires the accurate decoding of neural activity representing continuous movement. We develop a real-time control system using the spiking activity of approximately 40 neurons recorded with an electrode array implanted in the arm area of primary motor cortex. In contrast to previous work, we develop a control-theoretic approach that explicitly models the motion of the hand and the probabilistic relationship between this motion and the mean ﬁring rates of the cells in 70 bins. We focus on a realistic cursor control task in which the subject must move a cursor to “hit” randomly placed targets on a computer monitor. Encoding and decoding of the neural data is achieved with a Kalman ﬁlter which has a number of advantages over previous linear ﬁltering techniques. In particular, the Kalman ﬁlter reconstructions of hand trajectories in off-line experiments are more accurate than previously reported results and the model provides insights into the nature of the neural coding of movement. ¨ ©§</p><p>3 0.22190994 <a title="21-tfidf-3" href="./nips-2002-VIBES%3A_A_Variational_Inference_Engine_for_Bayesian_Networks.html">204 nips-2002-VIBES: A Variational Inference Engine for Bayesian Networks</a></p>
<p>Author: Christopher M. Bishop, David Spiegelhalter, John Winn</p><p>Abstract: In recent years variational methods have become a popular tool for approximate inference and learning in a wide variety of probabilistic models. For each new application, however, it is currently necessary ﬁrst to derive the variational update equations, and then to implement them in application-speciﬁc code. Each of these steps is both time consuming and error prone. In this paper we describe a general purpose inference engine called VIBES (‘Variational Inference for Bayesian Networks’) which allows a wide variety of probabilistic models to be implemented and solved variationally without recourse to coding. New models are speciﬁed either through a simple script or via a graphical interface analogous to a drawing package. VIBES then automatically generates and solves the variational equations. We illustrate the power and ﬂexibility of VIBES using examples from Bayesian mixture modelling. 1</p><p>4 0.13426951 <a title="21-tfidf-4" href="./nips-2002-Combining_Features_for_BCI.html">55 nips-2002-Combining Features for BCI</a></p>
<p>Author: Guido Dornhege, Benjamin Blankertz, Gabriel Curio, Klaus-Robert Müller</p><p>Abstract: Recently, interest is growing to develop an effective communication interface connecting the human brain to a computer, the ’Brain-Computer Interface’ (BCI). One motivation of BCI research is to provide a new communication channel substituting normal motor output in patients with severe neuromuscular disabilities. In the last decade, various neurophysiological cortical processes, such as slow potential shifts, movement related potentials (MRPs) or event-related desynchronization (ERD) of spontaneous EEG rhythms, were shown to be suitable for BCI, and, consequently, different independent approaches of extracting BCI-relevant EEG-features for single-trial analysis are under investigation. Here, we present and systematically compare several concepts for combining such EEG-features to improve the single-trial classiﬁcation. Feature combinations are evaluated on movement imagination experiments with 3 subjects where EEG-features are based on either MRPs or ERD, or both. Those combination methods that incorporate the assumption that the single EEG-features are physiologically mutually independent outperform the plain method of ’adding’ evidence where the single-feature vectors are simply concatenated. These results strengthen the hypothesis that MRP and ERD reﬂect at least partially independent aspects of cortical processes and open a new perspective to boost BCI effectiveness.</p><p>5 0.12779708 <a title="21-tfidf-5" href="./nips-2002-Real-Time_Particle_Filters.html">169 nips-2002-Real-Time Particle Filters</a></p>
<p>Author: Cody Kwok, Dieter Fox, Marina Meila</p><p>Abstract: Particle ﬁlters estimate the state of dynamical systems from sensor information. In many real time applications of particle ﬁlters, however, sensor information arrives at a signiﬁcantly higher rate than the update rate of the ﬁlter. The prevalent approach to dealing with such situations is to update the particle ﬁlter as often as possible and to discard sensor information that cannot be processed in time. In this paper we present real-time particle ﬁlters, which make use of all sensor information even when the ﬁlter update rate is below the update rate of the sensors. This is achieved by representing posteriors as mixtures of sample sets, where each mixture component integrates one observation arriving during a ﬁlter update. The weights of the mixture components are set so as to minimize the approximation error introduced by the mixture representation. Thereby, our approach focuses computational resources (samples) on valuable sensor information. Experiments using data collected with a mobile robot show that our approach yields strong improvements over other approaches.</p><p>6 0.11106288 <a title="21-tfidf-6" href="./nips-2002-Adaptive_Scaling_for_Feature_Selection_in_SVMs.html">24 nips-2002-Adaptive Scaling for Feature Selection in SVMs</a></p>
<p>7 0.1093796 <a title="21-tfidf-7" href="./nips-2002-Application_of_Variational_Bayesian_Approach_to_Speech_Recognition.html">31 nips-2002-Application of Variational Bayesian Approach to Speech Recognition</a></p>
<p>8 0.10878997 <a title="21-tfidf-8" href="./nips-2002-Discriminative_Densities_from_Maximum_Contrast_Estimation.html">68 nips-2002-Discriminative Densities from Maximum Contrast Estimation</a></p>
<p>9 0.10832631 <a title="21-tfidf-9" href="./nips-2002-A_Statistical_Mechanics_Approach_to_Approximate_Analytical_Bootstrap_Averages.html">17 nips-2002-A Statistical Mechanics Approach to Approximate Analytical Bootstrap Averages</a></p>
<p>10 0.10755922 <a title="21-tfidf-10" href="./nips-2002-Constraint_Classification_for_Multiclass_Classification_and_Ranking.html">59 nips-2002-Constraint Classification for Multiclass Classification and Ranking</a></p>
<p>11 0.10718538 <a title="21-tfidf-11" href="./nips-2002-A_Model_for_Learning_Variance_Components_of_Natural_Images.html">10 nips-2002-A Model for Learning Variance Components of Natural Images</a></p>
<p>12 0.10434531 <a title="21-tfidf-12" href="./nips-2002-Dynamic_Structure_Super-Resolution.html">74 nips-2002-Dynamic Structure Super-Resolution</a></p>
<p>13 0.10316626 <a title="21-tfidf-13" href="./nips-2002-Real-Time_Monitoring_of_Complex_Industrial_Processes_with_Particle_Filters.html">168 nips-2002-Real-Time Monitoring of Complex Industrial Processes with Particle Filters</a></p>
<p>14 0.10175968 <a title="21-tfidf-14" href="./nips-2002-Self_Supervised_Boosting.html">181 nips-2002-Self Supervised Boosting</a></p>
<p>15 0.10080617 <a title="21-tfidf-15" href="./nips-2002-Feature_Selection_and_Classification_on_Matrix_Data%3A_From_Large_Margins_to_Small_Covering_Numbers.html">88 nips-2002-Feature Selection and Classification on Matrix Data: From Large Margins to Small Covering Numbers</a></p>
<p>16 0.095814802 <a title="21-tfidf-16" href="./nips-2002-Learning_to_Detect_Natural_Image_Boundaries_Using_Brightness_and_Texture.html">132 nips-2002-Learning to Detect Natural Image Boundaries Using Brightness and Texture</a></p>
<p>17 0.093501277 <a title="21-tfidf-17" href="./nips-2002-Fast_Sparse_Gaussian_Process_Methods%3A_The_Informative_Vector_Machine.html">86 nips-2002-Fast Sparse Gaussian Process Methods: The Informative Vector Machine</a></p>
<p>18 0.092823543 <a title="21-tfidf-18" href="./nips-2002-Incremental_Gaussian_Processes.html">110 nips-2002-Incremental Gaussian Processes</a></p>
<p>19 0.09263368 <a title="21-tfidf-19" href="./nips-2002-Adaptation_and_Unsupervised_Learning.html">18 nips-2002-Adaptation and Unsupervised Learning</a></p>
<p>20 0.090045936 <a title="21-tfidf-20" href="./nips-2002-Interpreting_Neural_Response_Variability_as_Monte_Carlo_Sampling_of_the_Posterior.html">116 nips-2002-Interpreting Neural Response Variability as Monte Carlo Sampling of the Posterior</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2002_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.274), (1, -0.057), (2, -0.012), (3, 0.101), (4, 0.117), (5, 0.059), (6, -0.177), (7, 0.093), (8, 0.133), (9, -0.018), (10, -0.017), (11, 0.01), (12, 0.204), (13, 0.034), (14, 0.064), (15, -0.125), (16, -0.05), (17, 0.03), (18, -0.119), (19, 0.033), (20, 0.039), (21, -0.06), (22, -0.127), (23, 0.079), (24, -0.13), (25, -0.008), (26, 0.133), (27, -0.035), (28, -0.239), (29, -0.058), (30, -0.176), (31, -0.073), (32, 0.027), (33, 0.125), (34, -0.028), (35, 0.006), (36, 0.163), (37, 0.028), (38, -0.063), (39, -0.092), (40, 0.087), (41, 0.041), (42, -0.03), (43, -0.035), (44, -0.087), (45, 0.022), (46, -0.01), (47, 0.069), (48, 0.01), (49, 0.063)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95251262 <a title="21-lsi-1" href="./nips-2002-Adaptive_Classification_by_Variational_Kalman_Filtering.html">21 nips-2002-Adaptive Classification by Variational Kalman Filtering</a></p>
<p>Author: Peter Sykacek, Stephen J. Roberts</p><p>Abstract: We propose in this paper a probabilistic approach for adaptive inference of generalized nonlinear classiﬁcation that combines the computational advantage of a parametric solution with the ﬂexibility of sequential sampling techniques. We regard the parameters of the classiﬁer as latent states in a ﬁrst order Markov process and propose an algorithm which can be regarded as variational generalization of standard Kalman ﬁltering. The variational Kalman ﬁlter is based on two novel lower bounds that enable us to use a non-degenerate distribution over the adaptation rate. An extensive empirical evaluation demonstrates that the proposed method is capable of infering competitive classiﬁers both in stationary and non-stationary environments. Although we focus on classiﬁcation, the algorithm is easily extended to other generalized nonlinear models.</p><p>2 0.71138448 <a title="21-lsi-2" href="./nips-2002-VIBES%3A_A_Variational_Inference_Engine_for_Bayesian_Networks.html">204 nips-2002-VIBES: A Variational Inference Engine for Bayesian Networks</a></p>
<p>Author: Christopher M. Bishop, David Spiegelhalter, John Winn</p><p>Abstract: In recent years variational methods have become a popular tool for approximate inference and learning in a wide variety of probabilistic models. For each new application, however, it is currently necessary ﬁrst to derive the variational update equations, and then to implement them in application-speciﬁc code. Each of these steps is both time consuming and error prone. In this paper we describe a general purpose inference engine called VIBES (‘Variational Inference for Bayesian Networks’) which allows a wide variety of probabilistic models to be implemented and solved variationally without recourse to coding. New models are speciﬁed either through a simple script or via a graphical interface analogous to a drawing package. VIBES then automatically generates and solves the variational equations. We illustrate the power and ﬂexibility of VIBES using examples from Bayesian mixture modelling. 1</p><p>3 0.6300419 <a title="21-lsi-3" href="./nips-2002-Neural_Decoding_of_Cursor_Motion_Using_a_Kalman_Filter.html">153 nips-2002-Neural Decoding of Cursor Motion Using a Kalman Filter</a></p>
<p>Author: W Wu, M. J. Black, Y. Gao, M. Serruya, A. Shaikhouni, J. P. Donoghue, Elie Bienenstock</p><p>Abstract: The direct neural control of external devices such as computer displays or prosthetic limbs requires the accurate decoding of neural activity representing continuous movement. We develop a real-time control system using the spiking activity of approximately 40 neurons recorded with an electrode array implanted in the arm area of primary motor cortex. In contrast to previous work, we develop a control-theoretic approach that explicitly models the motion of the hand and the probabilistic relationship between this motion and the mean ﬁring rates of the cells in 70 bins. We focus on a realistic cursor control task in which the subject must move a cursor to “hit” randomly placed targets on a computer monitor. Encoding and decoding of the neural data is achieved with a Kalman ﬁlter which has a number of advantages over previous linear ﬁltering techniques. In particular, the Kalman ﬁlter reconstructions of hand trajectories in off-line experiments are more accurate than previously reported results and the model provides insights into the nature of the neural coding of movement. ¨ ©§</p><p>4 0.53993511 <a title="21-lsi-4" href="./nips-2002-Real-Time_Monitoring_of_Complex_Industrial_Processes_with_Particle_Filters.html">168 nips-2002-Real-Time Monitoring of Complex Industrial Processes with Particle Filters</a></p>
<p>Author: Rubén Morales-menéndez, Nando D. Freitas, David Poole</p><p>Abstract: This paper discusses the application of particle ﬁltering algorithms to fault diagnosis in complex industrial processes. We consider two ubiquitous processes: an industrial dryer and a level tank. For these applications, we compared three particle ﬁltering variants: standard particle ﬁltering, Rao-Blackwellised particle ﬁltering and a version of RaoBlackwellised particle ﬁltering that does one-step look-ahead to select good sampling regions. We show that the overhead of the extra processing per particle of the more sophisticated methods is more than compensated by the decrease in error and variance.</p><p>5 0.53250521 <a title="21-lsi-5" href="./nips-2002-Application_of_Variational_Bayesian_Approach_to_Speech_Recognition.html">31 nips-2002-Application of Variational Bayesian Approach to Speech Recognition</a></p>
<p>Author: Shinji Watanabe, Yasuhiro Minami, Atsushi Nakamura, Naonori Ueda</p><p>Abstract: In this paper, we propose a Bayesian framework, which constructs shared-state triphone HMMs based on a variational Bayesian approach, and recognizes speech based on the Bayesian prediction classiﬁcation; variational Bayesian estimation and clustering for speech recognition (VBEC). An appropriate model structure with high recognition performance can be found within a VBEC framework. Unlike conventional methods, including BIC or MDL criterion based on the maximum likelihood approach, the proposed model selection is valid in principle, even when there are insufﬁcient amounts of data, because it does not use an asymptotic assumption. In isolated word recognition experiments, we show the advantage of VBEC over conventional methods, especially when dealing with small amounts of data.</p><p>6 0.52858901 <a title="21-lsi-6" href="./nips-2002-Multiple_Cause_Vector_Quantization.html">150 nips-2002-Multiple Cause Vector Quantization</a></p>
<p>7 0.50913829 <a title="21-lsi-7" href="./nips-2002-A_Statistical_Mechanics_Approach_to_Approximate_Analytical_Bootstrap_Averages.html">17 nips-2002-A Statistical Mechanics Approach to Approximate Analytical Bootstrap Averages</a></p>
<p>8 0.49888584 <a title="21-lsi-8" href="./nips-2002-Combining_Features_for_BCI.html">55 nips-2002-Combining Features for BCI</a></p>
<p>9 0.47580549 <a title="21-lsi-9" href="./nips-2002-A_Hierarchical_Bayesian_Markovian_Model_for_Motifs_in_Biopolymer_Sequences.html">7 nips-2002-A Hierarchical Bayesian Markovian Model for Motifs in Biopolymer Sequences</a></p>
<p>10 0.46199274 <a title="21-lsi-10" href="./nips-2002-Learning_Sparse_Topographic_Representations_with_Products_of_Student-t_Distributions.html">127 nips-2002-Learning Sparse Topographic Representations with Products of Student-t Distributions</a></p>
<p>11 0.44996428 <a title="21-lsi-11" href="./nips-2002-Real-Time_Particle_Filters.html">169 nips-2002-Real-Time Particle Filters</a></p>
<p>12 0.43432829 <a title="21-lsi-12" href="./nips-2002-The_RA_Scanner%3A_Prediction_of_Rheumatoid_Joint_Inflammation_Based_on_Laser_Imaging.html">196 nips-2002-The RA Scanner: Prediction of Rheumatoid Joint Inflammation Based on Laser Imaging</a></p>
<p>13 0.42772999 <a title="21-lsi-13" href="./nips-2002-Expected_and_Unexpected_Uncertainty%3A_ACh_and_NE_in_the_Neocortex.html">81 nips-2002-Expected and Unexpected Uncertainty: ACh and NE in the Neocortex</a></p>
<p>14 0.42389342 <a title="21-lsi-14" href="./nips-2002-Incremental_Gaussian_Processes.html">110 nips-2002-Incremental Gaussian Processes</a></p>
<p>15 0.41247797 <a title="21-lsi-15" href="./nips-2002-Handling_Missing_Data_with_Variational_Bayesian_Learning_of_ICA.html">101 nips-2002-Handling Missing Data with Variational Bayesian Learning of ICA</a></p>
<p>16 0.41022041 <a title="21-lsi-16" href="./nips-2002-Adaptation_and_Unsupervised_Learning.html">18 nips-2002-Adaptation and Unsupervised Learning</a></p>
<p>17 0.39918664 <a title="21-lsi-17" href="./nips-2002-Improving_Transfer_Rates_in_Brain_Computer_Interfacing%3A_A_Case_Study.html">108 nips-2002-Improving Transfer Rates in Brain Computer Interfacing: A Case Study</a></p>
<p>18 0.38953808 <a title="21-lsi-18" href="./nips-2002-Source_Separation_with_a_Sensor_Array_using_Graphical_Models_and_Subband_Filtering.html">183 nips-2002-Source Separation with a Sensor Array using Graphical Models and Subband Filtering</a></p>
<p>19 0.38068885 <a title="21-lsi-19" href="./nips-2002-Discriminative_Densities_from_Maximum_Contrast_Estimation.html">68 nips-2002-Discriminative Densities from Maximum Contrast Estimation</a></p>
<p>20 0.37862128 <a title="21-lsi-20" href="./nips-2002-Automatic_Derivation_of_Statistical_Algorithms%3A_The_EM_Family_and_Beyond.html">37 nips-2002-Automatic Derivation of Statistical Algorithms: The EM Family and Beyond</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2002_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(6, 0.017), (11, 0.029), (23, 0.06), (42, 0.104), (44, 0.179), (54, 0.128), (55, 0.047), (67, 0.014), (68, 0.045), (74, 0.075), (83, 0.013), (87, 0.011), (92, 0.078), (98, 0.119)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.9057259 <a title="21-lda-1" href="./nips-2002-Fast_Kernels_for_String_and_Tree_Matching.html">85 nips-2002-Fast Kernels for String and Tree Matching</a></p>
<p>Author: Alex J. Smola, S.v.n. Vishwanathan</p><p>Abstract: In this paper we present a new algorithm suitable for matching discrete objects such as strings and trees in linear time, thus obviating dynarrtic programming with quadratic time complexity. Furthermore, prediction cost in many cases can be reduced to linear cost in the length of the sequence to be classified, regardless of the number of support vectors. This improvement on the currently available algorithms makes string kernels a viable alternative for the practitioner.</p><p>same-paper 2 0.85716504 <a title="21-lda-2" href="./nips-2002-Adaptive_Classification_by_Variational_Kalman_Filtering.html">21 nips-2002-Adaptive Classification by Variational Kalman Filtering</a></p>
<p>Author: Peter Sykacek, Stephen J. Roberts</p><p>Abstract: We propose in this paper a probabilistic approach for adaptive inference of generalized nonlinear classiﬁcation that combines the computational advantage of a parametric solution with the ﬂexibility of sequential sampling techniques. We regard the parameters of the classiﬁer as latent states in a ﬁrst order Markov process and propose an algorithm which can be regarded as variational generalization of standard Kalman ﬁltering. The variational Kalman ﬁlter is based on two novel lower bounds that enable us to use a non-degenerate distribution over the adaptation rate. An extensive empirical evaluation demonstrates that the proposed method is capable of infering competitive classiﬁers both in stationary and non-stationary environments. Although we focus on classiﬁcation, the algorithm is easily extended to other generalized nonlinear models.</p><p>3 0.83406377 <a title="21-lda-3" href="./nips-2002-Margin_Analysis_of_the_LVQ_Algorithm.html">140 nips-2002-Margin Analysis of the LVQ Algorithm</a></p>
<p>Author: Koby Crammer, Ran Gilad-bachrach, Amir Navot, Naftali Tishby</p><p>Abstract: Prototypes based algorithms are commonly used to reduce the computational complexity of Nearest-Neighbour (NN) classiﬁers. In this paper we discuss theoretical and algorithmical aspects of such algorithms. On the theory side, we present margin based generalization bounds that suggest that these kinds of classiﬁers can be more accurate then the 1-NN rule. Furthermore, we derived a training algorithm that selects a good set of prototypes using large margin principles. We also show that the 20 years old Learning Vector Quantization (LVQ) algorithm emerges naturally from our framework. 1</p><p>4 0.76533675 <a title="21-lda-4" href="./nips-2002-A_Convergent_Form_of_Approximate_Policy_Iteration.html">3 nips-2002-A Convergent Form of Approximate Policy Iteration</a></p>
<p>Author: Theodore J. Perkins, Doina Precup</p><p>Abstract: We study a new, model-free form of approximate policy iteration which uses Sarsa updates with linear state-action value function approximation for policy evaluation, and a “policy improvement operator” to generate a new policy based on the learned state-action values. We prove that if the policy improvement operator produces -soft policies and is Lipschitz continuous in the action values, with a constant that is not too large, then the approximate policy iteration algorithm converges to a unique solution from any initial policy. To our knowledge, this is the ﬁrst convergence result for any form of approximate policy iteration under similar computational-resource assumptions.</p><p>5 0.76531267 <a title="21-lda-5" href="./nips-2002-Automatic_Derivation_of_Statistical_Algorithms%3A_The_EM_Family_and_Beyond.html">37 nips-2002-Automatic Derivation of Statistical Algorithms: The EM Family and Beyond</a></p>
<p>Author: Bernd Fischer, Johann Schumann, Wray Buntine, Alexander G. Gray</p><p>Abstract: Machine learning has reached a point where many probabilistic methods can be understood as variations, extensions and combinations of a much smaller set of abstract themes, e.g., as different instances of the EM algorithm. This enables the systematic derivation of algorithms customized for different models. Here, we describe the AUTO BAYES system which takes a high-level statistical model speciﬁcation, uses powerful symbolic techniques based on schema-based program synthesis and computer algebra to derive an efﬁcient specialized algorithm for learning that model, and generates executable code implementing that algorithm. This capability is far beyond that of code collections such as Matlab toolboxes or even tools for model-independent optimization such as BUGS for Gibbs sampling: complex new algorithms can be generated without new programming, algorithms can be highly specialized and tightly crafted for the exact structure of the model and data, and efﬁcient and commented code can be generated for different languages or systems. We present automatically-derived algorithms ranging from closed-form solutions of Bayesian textbook problems to recently-proposed EM algorithms for clustering, regression, and a multinomial form of PCA. 1 Automatic Derivation of Statistical Algorithms Overview. We describe a symbolic program synthesis system which works as a “statistical algorithm compiler:” it compiles a statistical model speciﬁcation into a custom algorithm design and from that further down into a working program implementing the algorithm design. This system, AUTO BAYES, can be loosely thought of as “part theorem prover, part Mathematica, part learning textbook, and part Numerical Recipes.” It provides much more ﬂexibility than a ﬁxed code repository such as a Matlab toolbox, and allows the creation of efﬁcient algorithms which have never before been implemented, or even written down. AUTO BAYES is intended to automate the more routine application of complex methods in novel contexts. For example, recent multinomial extensions to PCA [2, 4] can be derived in this way. The algorithm design problem. Given a dataset and a task, creating a learning method can be characterized by two main questions: 1. What is the model? 2. What algorithm will optimize the model parameters? The statistical algorithm (i.e., a parameter optimization algorithm for the statistical model) can then be implemented manually. The system in this paper answers the algorithm question given that the user has chosen a model for the data,and continues through to implementation. Performing this task at the state-of-the-art level requires an intertwined meld of probability theory, computational mathematics, and software engineering. However, a number of factors unite to allow us to solve the algorithm design problem computationally: 1. The existence of fundamental building blocks (e.g., standardized probability distributions, standard optimization procedures, and generic data structures). 2. The existence of common representations (i.e., graphical models [3, 13] and program schemas). 3. The formalization of schema applicability constraints as guards. 1 The challenges of algorithm design. The design problem has an inherently combinatorial nature, since subparts of a function may be optimized recursively and in different ways. It also involves the use of new data structures or approximations to gain performance. As the research in statistical algorithms advances, its creative focus should move beyond the ultimately mechanical aspects and towards extending the abstract applicability of already existing schemas (algorithmic principles like EM), improving schemas in ways that generalize across anything they can be applied to, and inventing radically new schemas. 2 Combining Schema-based Synthesis and Bayesian Networks Statistical Models. Externally, AUTO BAYES has the look and feel of 2 const int n_points as ’nr. of data points’ a compiler. Users specify their model 3 with 0 < n_points; 4 const int n_classes := 3 as ’nr. classes’ of interest in a high-level speciﬁcation 5 with 0 < n_classes language (as opposed to a program6 with n_classes << n_points; ming language). The ﬁgure shows the 7 double phi(1..n_classes) as ’weights’ speciﬁcation of the mixture of Gaus8 with 1 = sum(I := 1..n_classes, phi(I)); 9 double mu(1..n_classes); sians example used throughout this 9 double sigma(1..n_classes); paper.2 Note the constraint that the 10 int c(1..n_points) as ’class labels’; sum of the class probabilities must 11 c ˜ disc(vec(I := 1..n_classes, phi(I))); equal one (line 8) along with others 12 data double x(1..n_points) as ’data’; (lines 3 and 5) that make optimization 13 x(I) ˜ gauss(mu(c(I)), sigma(c(I))); of the model well-deﬁned. Also note 14 max pr(x| phi,mu,sigma ) wrt phi,mu,sigma ; the ability to specify assumptions of the kind in line 6, which may be used by some algorithms. The last line speciﬁes the goal inference task: maximize the conditional probability pr with respect to the parameters , , and . Note that moving the parameters across to the left of the conditioning bar converts this from a maximum likelihood to a maximum a posteriori problem. 1 model mog as ’Mixture of Gaussians’; ¡   £  £  £ §¤¢ £ © ¨ ¦ ¥ ©   ¡     ¡ £ £ £ ¨ Computational logic and theorem proving. Internally, AUTO BAYES uses a class of techniques known as computational logic which has its roots in automated theorem proving. AUTO BAYES begins with an initial goal and a set of initial assertions, or axioms, and adds new assertions, or theorems, by repeated application of the axioms, until the goal is proven. In our context, the goal is given by the input model; the derived algorithms are side effects of constructive theorems proving the existence of algorithms for the goal. 1 Schema guards vary widely; for example, compare Nead-Melder simplex or simulated annealing (which require only function evaluation), conjugate gradient (which require both Jacobian and Hessian), EM and its variational extension [6] (which require a latent-variable structure model). 2 Here, keywords have been underlined and line numbers have been added for reference in the text. The as-keyword allows annotations to variables which end up in the generated code’s comments. Also, n classes has been set to three (line 4), while n points is left unspeciﬁed. The class variable and single data variable are vectors, which deﬁnes them as i.i.d. Computer algebra. The ﬁrst core element which makes automatic algorithm derivation feasible is the fact that we can mechanize the required symbol manipulation, using computer algebra methods. General symbolic differentiation and expression simpliﬁcation are capabilities fundamental to our approach. AUTO BAYES contains a computer algebra engine using term rewrite rules which are an efﬁcient mechanism for substitution of equal quantities or expressions and thus well-suited for this task.3 Schema-based synthesis. The computational cost of full-blown theorem proving grinds simple tasks to a halt while elementary and intermediate facts are reinvented from scratch. To achieve the scale of deduction required by algorithm derivation, we thus follow a schema-based synthesis technique which breaks away from strict theorem proving. Instead, we formalize high-level domain knowledge, such as the general EM strategy, as schemas. A schema combines a generic code fragment with explicitly speciﬁed preconditions which describe the applicability of the code fragment. The second core element which makes automatic algorithm derivation feasible is the fact that we can use Bayesian networks to efﬁciently encode the preconditions of complex algorithms such as EM. First-order logic representation of Bayesian netNclasses works. A ﬁrst-order logic representation of Bayesian µ σ networks was developed by Haddawy [7]. In this framework, random variables are represented by functor symbols and indexes (i.e., speciﬁc instances φ x c of i.i.d. vectors) are represented as functor arguments. discrete gauss Nclasses Since unknown index values can be represented by Npoints implicitly universally quantiﬁed Prolog variables, this approach allows a compact encoding of networks involving i.i.d. variables or plates [3]; the ﬁgure shows the initial network for our running example. Moreover, such networks correspond to backtrack-free datalog programs, allowing the dependencies to be efﬁciently computed. We have extended the framework to work with non-ground probability queries since we seek to determine probabilities over entire i.i.d. vectors and matrices. Tests for independence on these indexed Bayesian networks are easily developed in Lauritzen’s framework which uses ancestral sets and set separation [9] and is more amenable to a theorem prover than the double negatives of the more widely known d-separation criteria. Given a Bayesian network, some probabilities can easily be extracted by enumerating the component probabilities at each node: § ¥ ¨¦¡ ¡ ¢© Lemma 1. Let be sets of variables over a Bayesian network with . Then descendents and parents hold 4 in the corresponding dependency graph iff the following probability statement holds: £ ¤  ¡ parents B % % 9 C0A@ ! 9  @8 § ¥   ¢   2 ' % % 310  parents    ©¢   £ ¡ !    ' % #!  </p><p>6 0.76425046 <a title="21-lda-6" href="./nips-2002-VIBES%3A_A_Variational_Inference_Engine_for_Bayesian_Networks.html">204 nips-2002-VIBES: A Variational Inference Engine for Bayesian Networks</a></p>
<p>7 0.76272756 <a title="21-lda-7" href="./nips-2002-Learning_Sparse_Topographic_Representations_with_Products_of_Student-t_Distributions.html">127 nips-2002-Learning Sparse Topographic Representations with Products of Student-t Distributions</a></p>
<p>8 0.75978297 <a title="21-lda-8" href="./nips-2002-Discriminative_Densities_from_Maximum_Contrast_Estimation.html">68 nips-2002-Discriminative Densities from Maximum Contrast Estimation</a></p>
<p>9 0.75737488 <a title="21-lda-9" href="./nips-2002-Boosting_Density_Estimation.html">46 nips-2002-Boosting Density Estimation</a></p>
<p>10 0.75112343 <a title="21-lda-10" href="./nips-2002-Real-Time_Particle_Filters.html">169 nips-2002-Real-Time Particle Filters</a></p>
<p>11 0.74979603 <a title="21-lda-11" href="./nips-2002-A_Model_for_Learning_Variance_Components_of_Natural_Images.html">10 nips-2002-A Model for Learning Variance Components of Natural Images</a></p>
<p>12 0.74967074 <a title="21-lda-12" href="./nips-2002-Cluster_Kernels_for_Semi-Supervised_Learning.html">52 nips-2002-Cluster Kernels for Semi-Supervised Learning</a></p>
<p>13 0.7464304 <a title="21-lda-13" href="./nips-2002-Feature_Selection_and_Classification_on_Matrix_Data%3A_From_Large_Margins_to_Small_Covering_Numbers.html">88 nips-2002-Feature Selection and Classification on Matrix Data: From Large Margins to Small Covering Numbers</a></p>
<p>14 0.74502337 <a title="21-lda-14" href="./nips-2002-Optimality_of_Reinforcement_Learning_Algorithms_with_Linear_Function_Approximation.html">159 nips-2002-Optimality of Reinforcement Learning Algorithms with Linear Function Approximation</a></p>
<p>15 0.74446452 <a title="21-lda-15" href="./nips-2002-Adaptive_Scaling_for_Feature_Selection_in_SVMs.html">24 nips-2002-Adaptive Scaling for Feature Selection in SVMs</a></p>
<p>16 0.74405074 <a title="21-lda-16" href="./nips-2002-A_Model_for_Real-Time_Computation_in_Generic_Neural_Microcircuits.html">11 nips-2002-A Model for Real-Time Computation in Generic Neural Microcircuits</a></p>
<p>17 0.74271584 <a title="21-lda-17" href="./nips-2002-Bayesian_Monte_Carlo.html">41 nips-2002-Bayesian Monte Carlo</a></p>
<p>18 0.7413339 <a title="21-lda-18" href="./nips-2002-Derivative_Observations_in_Gaussian_Process_Models_of_Dynamic_Systems.html">65 nips-2002-Derivative Observations in Gaussian Process Models of Dynamic Systems</a></p>
<p>19 0.74035084 <a title="21-lda-19" href="./nips-2002-An_Impossibility_Theorem_for_Clustering.html">27 nips-2002-An Impossibility Theorem for Clustering</a></p>
<p>20 0.74028003 <a title="21-lda-20" href="./nips-2002-Exponential_Family_PCA_for_Belief_Compression_in_POMDPs.html">82 nips-2002-Exponential Family PCA for Belief Compression in POMDPs</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
