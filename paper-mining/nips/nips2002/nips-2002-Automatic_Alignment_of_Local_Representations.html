<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>36 nips-2002-Automatic Alignment of Local Representations</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-36" href="#">nips2002-36</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>36 nips-2002-Automatic Alignment of Local Representations</h1>
<br/><p>Source: <a title="nips-2002-36-pdf" href="http://papers.nips.cc/paper/2180-automatic-alignment-of-local-representations.pdf">pdf</a></p><p>Author: Yee W. Teh, Sam T. Roweis</p><p>Abstract: We present an automatic alignment procedure which maps the disparate internal representations learned by several local dimensionality reduction experts into a single, coherent global coordinate system for the original data space. Our algorithm can be applied to any set of experts, each of which produces a low-dimensional local representation of a highdimensional input. Unlike recent efforts to coordinate such models by modifying their objective functions [1, 2], our algorithm is invoked after training and applies an efﬁcient eigensolver to post-process the trained models. The post-processing has no local optima and the size of the system it must solve scales with the number of local models rather than the number of original data points, making it more efﬁcient than model-free algorithms such as Isomap [3] or LLE [4]. 1 Introduction: Local vs. Global Dimensionality Reduction Beyond density modelling, an important goal of unsupervised learning is to discover compact, informative representations of high-dimensional data. If the data lie on a smooth low dimensional manifold, then an excellent encoding is the coordinates internal to that manifold. The process of determining such coordinates is dimensionality reduction. Linear dimensionality reduction methods such as principal component analysis and factor analysis are easy to train but cannot capture the structure of curved manifolds. Mixtures of these simple unsupervised models [5, 6, 7, 8] have been used to perform local dimensionality reduction, and can provide good density models for curved manifolds, but unfortunately such mixtures cannot do dimensionality reduction. They do not describe a single, coherent low-dimensional coordinate system for the data since there is no pressure for the local coordinates of each component to agree. Roweis et al [1] recently proposed a model which performs global coordination of local coordinate systems in a mixture of factor analyzers (MFA). Their model is trained by maximizing the likelihood of the data, with an additional variational penalty term to encourage the internal coordinates of the factor analyzers to agree. While their model can trade off modelling the data and having consistent local coordinate systems, it requires a user given trade-off parameter, training is quite inefﬁcient (although [2] describes an improved training algorithm for a more constrained model), and it has quite serious local minima problems (methods like LLE [4] or Isomap [3] have to be used for initialization). In this paper we describe a novel, automatic way to align the hidden representations used by each component of a mixture of dimensionality reducers into a single global representation of the data throughout space. Given an already trained mixture, the alignment is achieved by applying an eigensolver to a matrix constructed from the internal representations of the mixture components. Our method is efﬁcient, simple to implement, and has no local optima in its optimization nor any learning rates or annealing schedules. 2 The Locally Linear Coordination Algorithm H 9¥ EI¡ CD66B9 ©9B 766 % G F 5 #</p><p>Reference: <a title="nips-2002-36-reference" href="../nips2002_reference/nips-2002-Automatic_Alignment_of_Local_Representations_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('llc', 0.485), ('coordin', 0.44), ('mfa', 0.323), ('align', 0.252), ('lle', 0.217), ('glob', 0.191), ('mixt', 0.148), ('vuw', 0.143), ('loc', 0.131), ('manifold', 0.122), ('th', 0.122), ('dimend', 0.117), ('isomap', 0.114), ('neighbo', 0.091), ('digit', 0.091), ('eigensolv', 0.086), ('cost', 0.081), ('interpol', 0.08), ('dh', 0.078), ('chart', 0.076)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="36-tfidf-1" href="./nips-2002-Automatic_Alignment_of_Local_Representations.html">36 nips-2002-Automatic Alignment of Local Representations</a></p>
<p>2 0.3121604 <a title="36-tfidf-2" href="./nips-2002-Charting_a_Manifold.html">49 nips-2002-Charting a Manifold</a></p>
<p>3 0.22488977 <a title="36-tfidf-3" href="./nips-2002-Global_Versus_Local_Methods_in_Nonlinear_Dimensionality_Reduction.html">97 nips-2002-Global Versus Local Methods in Nonlinear Dimensionality Reduction</a></p>
<p>4 0.1160007 <a title="36-tfidf-4" href="./nips-2002-Manifold_Parzen_Windows.html">138 nips-2002-Manifold Parzen Windows</a></p>
<p>5 0.1114442 <a title="36-tfidf-5" href="./nips-2002-Fast_Transformation-Invariant_Factor_Analysis.html">87 nips-2002-Fast Transformation-Invariant Factor Analysis</a></p>
<p>6 0.10113115 <a title="36-tfidf-6" href="./nips-2002-Critical_Lines_in_Symmetry_of_Mixture_Models_and_its_Application_to_Component_Splitting.html">63 nips-2002-Critical Lines in Symmetry of Mixture Models and its Application to Component Splitting</a></p>
<p>7 0.099488713 <a title="36-tfidf-7" href="./nips-2002-A_Minimal_Intervention_Principle_for_Coordinated_Movement.html">9 nips-2002-A Minimal Intervention Principle for Coordinated Movement</a></p>
<p>8 0.089972652 <a title="36-tfidf-8" href="./nips-2002-Stochastic_Neighbor_Embedding.html">190 nips-2002-Stochastic Neighbor Embedding</a></p>
<p>9 0.086552605 <a title="36-tfidf-9" href="./nips-2002-Going_Metric%3A_Denoising_Pairwise_Data.html">98 nips-2002-Going Metric: Denoising Pairwise Data</a></p>
<p>10 0.083661668 <a title="36-tfidf-10" href="./nips-2002-Learning_Sparse_Topographic_Representations_with_Products_of_Student-t_Distributions.html">127 nips-2002-Learning Sparse Topographic Representations with Products of Student-t Distributions</a></p>
<p>11 0.078917883 <a title="36-tfidf-11" href="./nips-2002-A_Hierarchical_Bayesian_Markovian_Model_for_Motifs_in_Biopolymer_Sequences.html">7 nips-2002-A Hierarchical Bayesian Markovian Model for Motifs in Biopolymer Sequences</a></p>
<p>12 0.076657005 <a title="36-tfidf-12" href="./nips-2002-A_Model_for_Learning_Variance_Components_of_Natural_Images.html">10 nips-2002-A Model for Learning Variance Components of Natural Images</a></p>
<p>13 0.07631927 <a title="36-tfidf-13" href="./nips-2002-Adaptive_Scaling_for_Feature_Selection_in_SVMs.html">24 nips-2002-Adaptive Scaling for Feature Selection in SVMs</a></p>
<p>14 0.071826264 <a title="36-tfidf-14" href="./nips-2002-Learning_to_Detect_Natural_Image_Boundaries_Using_Brightness_and_Texture.html">132 nips-2002-Learning to Detect Natural Image Boundaries Using Brightness and Texture</a></p>
<p>15 0.070369028 <a title="36-tfidf-15" href="./nips-2002-Learning_Semantic_Similarity.html">125 nips-2002-Learning Semantic Similarity</a></p>
<p>16 0.069305994 <a title="36-tfidf-16" href="./nips-2002-Adapting_Codes_and_Embeddings_for_Polychotomies.html">19 nips-2002-Adapting Codes and Embeddings for Polychotomies</a></p>
<p>17 0.067734838 <a title="36-tfidf-17" href="./nips-2002-Cluster_Kernels_for_Semi-Supervised_Learning.html">52 nips-2002-Cluster Kernels for Semi-Supervised Learning</a></p>
<p>18 0.067669496 <a title="36-tfidf-18" href="./nips-2002-Derivative_Observations_in_Gaussian_Process_Models_of_Dynamic_Systems.html">65 nips-2002-Derivative Observations in Gaussian Process Models of Dynamic Systems</a></p>
<p>19 0.067356437 <a title="36-tfidf-19" href="./nips-2002-Dynamic_Bayesian_Networks_with_Deterministic_Latent_Tables.html">73 nips-2002-Dynamic Bayesian Networks with Deterministic Latent Tables</a></p>
<p>20 0.066933282 <a title="36-tfidf-20" href="./nips-2002-Interpreting_Neural_Response_Variability_as_Monte_Carlo_Sampling_of_the_Posterior.html">116 nips-2002-Interpreting Neural Response Variability as Monte Carlo Sampling of the Posterior</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2002_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.203), (1, 0.062), (2, -0.039), (3, -0.066), (4, -0.003), (5, -0.015), (6, 0.015), (7, 0.043), (8, 0.093), (9, 0.037), (10, 0.022), (11, -0.154), (12, -0.201), (13, -0.131), (14, 0.247), (15, -0.168), (16, 0.036), (17, -0.345), (18, -0.071), (19, -0.082), (20, -0.008), (21, -0.002), (22, 0.023), (23, 0.032), (24, 0.052), (25, 0.083), (26, 0.022), (27, 0.104), (28, -0.071), (29, -0.011), (30, -0.045), (31, 0.111), (32, 0.084), (33, 0.094), (34, 0.062), (35, -0.031), (36, -0.0), (37, 0.105), (38, -0.072), (39, -0.036), (40, -0.019), (41, 0.002), (42, 0.0), (43, -0.015), (44, -0.07), (45, 0.042), (46, -0.043), (47, 0.07), (48, -0.063), (49, -0.056)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94308579 <a title="36-lsi-1" href="./nips-2002-Automatic_Alignment_of_Local_Representations.html">36 nips-2002-Automatic Alignment of Local Representations</a></p>
<p>2 0.89637417 <a title="36-lsi-2" href="./nips-2002-Charting_a_Manifold.html">49 nips-2002-Charting a Manifold</a></p>
<p>3 0.79253697 <a title="36-lsi-3" href="./nips-2002-Global_Versus_Local_Methods_in_Nonlinear_Dimensionality_Reduction.html">97 nips-2002-Global Versus Local Methods in Nonlinear Dimensionality Reduction</a></p>
<p>4 0.637981 <a title="36-lsi-4" href="./nips-2002-Intrinsic_Dimension_Estimation_Using_Packing_Numbers.html">117 nips-2002-Intrinsic Dimension Estimation Using Packing Numbers</a></p>
<p>5 0.62534636 <a title="36-lsi-5" href="./nips-2002-Stochastic_Neighbor_Embedding.html">190 nips-2002-Stochastic Neighbor Embedding</a></p>
<p>6 0.60145169 <a title="36-lsi-6" href="./nips-2002-Manifold_Parzen_Windows.html">138 nips-2002-Manifold Parzen Windows</a></p>
<p>7 0.53039247 <a title="36-lsi-7" href="./nips-2002-Critical_Lines_in_Symmetry_of_Mixture_Models_and_its_Application_to_Component_Splitting.html">63 nips-2002-Critical Lines in Symmetry of Mixture Models and its Application to Component Splitting</a></p>
<p>8 0.42672884 <a title="36-lsi-8" href="./nips-2002-Fast_Transformation-Invariant_Factor_Analysis.html">87 nips-2002-Fast Transformation-Invariant Factor Analysis</a></p>
<p>9 0.3964597 <a title="36-lsi-9" href="./nips-2002-Artefactual_Structure_from_Least-Squares_Multidimensional_Scaling.html">34 nips-2002-Artefactual Structure from Least-Squares Multidimensional Scaling</a></p>
<p>10 0.36109233 <a title="36-lsi-10" href="./nips-2002-A_Minimal_Intervention_Principle_for_Coordinated_Movement.html">9 nips-2002-A Minimal Intervention Principle for Coordinated Movement</a></p>
<p>11 0.31791049 <a title="36-lsi-11" href="./nips-2002-Maximum_Likelihood_and_the_Information_Bottleneck.html">142 nips-2002-Maximum Likelihood and the Information Bottleneck</a></p>
<p>12 0.309879 <a title="36-lsi-12" href="./nips-2002-Informed_Projections.html">115 nips-2002-Informed Projections</a></p>
<p>13 0.30641332 <a title="36-lsi-13" href="./nips-2002-A_Hierarchical_Bayesian_Markovian_Model_for_Motifs_in_Biopolymer_Sequences.html">7 nips-2002-A Hierarchical Bayesian Markovian Model for Motifs in Biopolymer Sequences</a></p>
<p>14 0.28673476 <a title="36-lsi-14" href="./nips-2002-Multiple_Cause_Vector_Quantization.html">150 nips-2002-Multiple Cause Vector Quantization</a></p>
<p>15 0.28369319 <a title="36-lsi-15" href="./nips-2002-Going_Metric%3A_Denoising_Pairwise_Data.html">98 nips-2002-Going Metric: Denoising Pairwise Data</a></p>
<p>16 0.27649471 <a title="36-lsi-16" href="./nips-2002-Adaptive_Quantization_and_Density_Estimation_in_Silicon.html">23 nips-2002-Adaptive Quantization and Density Estimation in Silicon</a></p>
<p>17 0.26580891 <a title="36-lsi-17" href="./nips-2002-Recovering_Articulated_Model_Topology_from_Observed_Rigid_Motion.html">172 nips-2002-Recovering Articulated Model Topology from Observed Rigid Motion</a></p>
<p>18 0.26520836 <a title="36-lsi-18" href="./nips-2002-Derivative_Observations_in_Gaussian_Process_Models_of_Dynamic_Systems.html">65 nips-2002-Derivative Observations in Gaussian Process Models of Dynamic Systems</a></p>
<p>19 0.25667971 <a title="36-lsi-19" href="./nips-2002-Learning_to_Detect_Natural_Image_Boundaries_Using_Brightness_and_Texture.html">132 nips-2002-Learning to Detect Natural Image Boundaries Using Brightness and Texture</a></p>
<p>20 0.25190696 <a title="36-lsi-20" href="./nips-2002-Handling_Missing_Data_with_Variational_Bayesian_Learning_of_ICA.html">101 nips-2002-Handling Missing Data with Variational Bayesian Learning of ICA</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2002_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(1, 0.052), (2, 0.05), (22, 0.044), (25, 0.206), (26, 0.047), (39, 0.033), (47, 0.092), (48, 0.103), (54, 0.015), (66, 0.095), (72, 0.058), (85, 0.013), (93, 0.094)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.81322896 <a title="36-lda-1" href="./nips-2002-A_Formulation_for_Minimax_Probability_Machine_Regression.html">6 nips-2002-A Formulation for Minimax Probability Machine Regression</a></p>
<p>same-paper 2 0.76589733 <a title="36-lda-2" href="./nips-2002-Automatic_Alignment_of_Local_Representations.html">36 nips-2002-Automatic Alignment of Local Representations</a></p>
<p>3 0.74280202 <a title="36-lda-3" href="./nips-2002-Evidence_Optimization_Techniques_for_Estimating_Stimulus-Response_Functions.html">79 nips-2002-Evidence Optimization Techniques for Estimating Stimulus-Response Functions</a></p>
<p>4 0.70526582 <a title="36-lda-4" href="./nips-2002-Adaptation_and_Unsupervised_Learning.html">18 nips-2002-Adaptation and Unsupervised Learning</a></p>
<p>5 0.68723243 <a title="36-lda-5" href="./nips-2002-Spikernels%3A_Embedding_Spiking_Neurons_in_Inner-Product_Spaces.html">187 nips-2002-Spikernels: Embedding Spiking Neurons in Inner-Product Spaces</a></p>
<p>6 0.6868906 <a title="36-lda-6" href="./nips-2002-Adapting_Codes_and_Embeddings_for_Polychotomies.html">19 nips-2002-Adapting Codes and Embeddings for Polychotomies</a></p>
<p>7 0.68097156 <a title="36-lda-7" href="./nips-2002-A_Minimal_Intervention_Principle_for_Coordinated_Movement.html">9 nips-2002-A Minimal Intervention Principle for Coordinated Movement</a></p>
<p>8 0.67979556 <a title="36-lda-8" href="./nips-2002-Nash_Propagation_for_Loopy_Graphical_Games.html">152 nips-2002-Nash Propagation for Loopy Graphical Games</a></p>
<p>9 0.67948151 <a title="36-lda-9" href="./nips-2002-Learning_Attractor_Landscapes_for_Learning_Motor_Primitives.html">123 nips-2002-Learning Attractor Landscapes for Learning Motor Primitives</a></p>
<p>10 0.67887324 <a title="36-lda-10" href="./nips-2002-Hyperkernels.html">106 nips-2002-Hyperkernels</a></p>
<p>11 0.67669517 <a title="36-lda-11" href="./nips-2002-Fast_Kernels_for_String_and_Tree_Matching.html">85 nips-2002-Fast Kernels for String and Tree Matching</a></p>
<p>12 0.67654431 <a title="36-lda-12" href="./nips-2002-Global_Versus_Local_Methods_in_Nonlinear_Dimensionality_Reduction.html">97 nips-2002-Global Versus Local Methods in Nonlinear Dimensionality Reduction</a></p>
<p>13 0.67618221 <a title="36-lda-13" href="./nips-2002-Learning_Semantic_Similarity.html">125 nips-2002-Learning Semantic Similarity</a></p>
<p>14 0.67572802 <a title="36-lda-14" href="./nips-2002-Charting_a_Manifold.html">49 nips-2002-Charting a Manifold</a></p>
<p>15 0.67456889 <a title="36-lda-15" href="./nips-2002-Nonparametric_Representation_of_Policies_and_Value_Functions%3A_A_Trajectory-Based_Approach.html">155 nips-2002-Nonparametric Representation of Policies and Value Functions: A Trajectory-Based Approach</a></p>
<p>16 0.67413229 <a title="36-lda-16" href="./nips-2002-Graph-Driven_Feature_Extraction_From_Microarray_Data_Using_Diffusion_Kernels_and_Kernel_CCA.html">99 nips-2002-Graph-Driven Feature Extraction From Microarray Data Using Diffusion Kernels and Kernel CCA</a></p>
<p>17 0.67365301 <a title="36-lda-17" href="./nips-2002-Gaussian_Process_Priors_with_Uncertain_Inputs_Application_to_Multiple-Step_Ahead_Time_Series_Forecasting.html">95 nips-2002-Gaussian Process Priors with Uncertain Inputs Application to Multiple-Step Ahead Time Series Forecasting</a></p>
<p>18 0.67340261 <a title="36-lda-18" href="./nips-2002-Cluster_Kernels_for_Semi-Supervised_Learning.html">52 nips-2002-Cluster Kernels for Semi-Supervised Learning</a></p>
<p>19 0.67223477 <a title="36-lda-19" href="./nips-2002-Approximate_Linear_Programming_for_Average-Cost_Dynamic_Programming.html">33 nips-2002-Approximate Linear Programming for Average-Cost Dynamic Programming</a></p>
<p>20 0.67194927 <a title="36-lda-20" href="./nips-2002-Using_Tarjan%27s_Red_Rule_for_Fast_Dependency_Tree_Construction.html">203 nips-2002-Using Tarjan's Red Rule for Fast Dependency Tree Construction</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
