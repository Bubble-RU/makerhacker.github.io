<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>175 nips-2002-Reinforcement Learning to Play an Optimal Nash Equilibrium in Team Markov Games</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-175" href="#">nips2002-175</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>175 nips-2002-Reinforcement Learning to Play an Optimal Nash Equilibrium in Team Markov Games</h1>
<br/><p>Source: <a title="nips-2002-175-pdf" href="http://papers.nips.cc/paper/2171-reinforcement-learning-to-play-an-optimal-nash-equilibrium-in-team-markov-games.pdf">pdf</a></p><p>Author: Xiaofeng Wang, Tuomas Sandholm</p><p>Abstract: Multiagent learning is a key problem in AI. In the presence of multiple Nash equilibria, even agents with non-conﬂicting interests may not be able to learn an optimal coordination policy. The problem is exaccerbated if the agents do not know the game and independently receive noisy payoffs. So, multiagent reinforfcement learning involves two interrelated problems: identifying the game and learning to play. In this paper, we present optimal adaptive learning, the ﬁrst algorithm that converges to an optimal Nash equilibrium with probability 1 in any team Markov game. We provide a convergence proof, and show that the algorithm’s parameters are easy to set to meet the convergence conditions.</p><p>Reference: <a title="nips-2002-175-reference" href="../nips2002_reference/nips-2002-Reinforcement_Learning_to_Play_an_Optimal_Nash_Equilibrium_in_Team_Markov_Games_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('nash', 0.505), ('gam', 0.487), ('equilibr', 0.294), ('ag', 0.266), ('oal', 0.265), ('bap', 0.221), ('payoff', 0.218), ('team', 0.149), ('gli', 0.142), ('wagb', 0.132), ('policy', 0.126), ('strict', 0.09), ('multy', 0.089), ('markov', 0.086), ('virt', 0.08), ('play', 0.074), ('bias', 0.071), ('joint', 0.07), ('converg', 0.07), ('rl', 0.068)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="175-tfidf-1" href="./nips-2002-Reinforcement_Learning_to_Play_an_Optimal_Nash_Equilibrium_in_Team_Markov_Games.html">175 nips-2002-Reinforcement Learning to Play an Optimal Nash Equilibrium in Team Markov Games</a></p>
<p>2 0.67676646 <a title="175-tfidf-2" href="./nips-2002-Efficient_Learning_Equilibrium.html">78 nips-2002-Efficient Learning Equilibrium</a></p>
<p>3 0.42282334 <a title="175-tfidf-3" href="./nips-2002-Nash_Propagation_for_Loopy_Graphical_Games.html">152 nips-2002-Nash Propagation for Loopy Graphical Games</a></p>
<p>4 0.24087788 <a title="175-tfidf-4" href="./nips-2002-Learning_in_Zero-Sum_Team_Markov_Games_Using_Factored_Value_Functions.html">130 nips-2002-Learning in Zero-Sum Team Markov Games Using Factored Value Functions</a></p>
<p>5 0.20718771 <a title="175-tfidf-5" href="./nips-2002-A_Convergent_Form_of_Approximate_Policy_Iteration.html">3 nips-2002-A Convergent Form of Approximate Policy Iteration</a></p>
<p>6 0.12616715 <a title="175-tfidf-6" href="./nips-2002-A_Note_on_the_Representational_Incompatibility_of_Function_Approximation_and_Factored_Dynamics.html">13 nips-2002-A Note on the Representational Incompatibility of Function Approximation and Factored Dynamics</a></p>
<p>7 0.11939619 <a title="175-tfidf-7" href="./nips-2002-Derivative_Observations_in_Gaussian_Process_Models_of_Dynamic_Systems.html">65 nips-2002-Derivative Observations in Gaussian Process Models of Dynamic Systems</a></p>
<p>8 0.10733184 <a title="175-tfidf-8" href="./nips-2002-Learning_to_Take_Concurrent_Actions.html">134 nips-2002-Learning to Take Concurrent Actions</a></p>
<p>9 0.091059737 <a title="175-tfidf-9" href="./nips-2002-Convergent_Combinations_of_Reinforcement_Learning_with_Linear_Function_Approximation.html">61 nips-2002-Convergent Combinations of Reinforcement Learning with Linear Function Approximation</a></p>
<p>10 0.073878929 <a title="175-tfidf-10" href="./nips-2002-Adaptive_Caching_by_Refetching.html">20 nips-2002-Adaptive Caching by Refetching</a></p>
<p>11 0.072484195 <a title="175-tfidf-11" href="./nips-2002-Nonparametric_Representation_of_Policies_and_Value_Functions%3A_A_Trajectory-Based_Approach.html">155 nips-2002-Nonparametric Representation of Policies and Value Functions: A Trajectory-Based Approach</a></p>
<p>12 0.070919164 <a title="175-tfidf-12" href="./nips-2002-Optimality_of_Reinforcement_Learning_Algorithms_with_Linear_Function_Approximation.html">159 nips-2002-Optimality of Reinforcement Learning Algorithms with Linear Function Approximation</a></p>
<p>13 0.068260439 <a title="175-tfidf-13" href="./nips-2002-Exponential_Family_PCA_for_Belief_Compression_in_POMDPs.html">82 nips-2002-Exponential Family PCA for Belief Compression in POMDPs</a></p>
<p>14 0.063649543 <a title="175-tfidf-14" href="./nips-2002-Approximate_Linear_Programming_for_Average-Cost_Dynamic_Programming.html">33 nips-2002-Approximate Linear Programming for Average-Cost Dynamic Programming</a></p>
<p>15 0.063480496 <a title="175-tfidf-15" href="./nips-2002-Speeding_up_the_Parti-Game_Algorithm.html">185 nips-2002-Speeding up the Parti-Game Algorithm</a></p>
<p>16 0.04285242 <a title="175-tfidf-16" href="./nips-2002-Concentration_Inequalities_for_the_Missing_Mass_and_for_Histogram_Rule_Error.html">56 nips-2002-Concentration Inequalities for the Missing Mass and for Histogram Rule Error</a></p>
<p>17 0.042731069 <a title="175-tfidf-17" href="./nips-2002-Effective_Dimension_and_Generalization_of_Kernel_Learning.html">77 nips-2002-Effective Dimension and Generalization of Kernel Learning</a></p>
<p>18 0.042166911 <a title="175-tfidf-18" href="./nips-2002-Learning_Attractor_Landscapes_for_Learning_Motor_Primitives.html">123 nips-2002-Learning Attractor Landscapes for Learning Motor Primitives</a></p>
<p>19 0.040338732 <a title="175-tfidf-19" href="./nips-2002-Prediction_and_Semantic_Association.html">163 nips-2002-Prediction and Semantic Association</a></p>
<p>20 0.038796887 <a title="175-tfidf-20" href="./nips-2002-Value-Directed_Compression_of_POMDPs.html">205 nips-2002-Value-Directed Compression of POMDPs</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2002_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.112), (1, 0.046), (2, -0.282), (3, 0.231), (4, -0.011), (5, 0.139), (6, 0.058), (7, 0.058), (8, -0.414), (9, 0.437), (10, 0.33), (11, -0.188), (12, -0.053), (13, 0.127), (14, -0.028), (15, -0.073), (16, -0.023), (17, 0.05), (18, 0.038), (19, 0.104), (20, -0.047), (21, 0.048), (22, 0.024), (23, -0.03), (24, -0.007), (25, 0.01), (26, 0.021), (27, 0.049), (28, 0.024), (29, 0.005), (30, 0.024), (31, 0.036), (32, -0.036), (33, 0.0), (34, -0.005), (35, -0.026), (36, 0.017), (37, 0.037), (38, -0.013), (39, -0.035), (40, 0.003), (41, 0.007), (42, -0.008), (43, 0.013), (44, -0.014), (45, 0.035), (46, 0.009), (47, -0.018), (48, 0.022), (49, -0.018)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.97599882 <a title="175-lsi-1" href="./nips-2002-Efficient_Learning_Equilibrium.html">78 nips-2002-Efficient Learning Equilibrium</a></p>
<p>same-paper 2 0.97295183 <a title="175-lsi-2" href="./nips-2002-Reinforcement_Learning_to_Play_an_Optimal_Nash_Equilibrium_in_Team_Markov_Games.html">175 nips-2002-Reinforcement Learning to Play an Optimal Nash Equilibrium in Team Markov Games</a></p>
<p>3 0.81095767 <a title="175-lsi-3" href="./nips-2002-Nash_Propagation_for_Loopy_Graphical_Games.html">152 nips-2002-Nash Propagation for Loopy Graphical Games</a></p>
<p>4 0.63432002 <a title="175-lsi-4" href="./nips-2002-Learning_in_Zero-Sum_Team_Markov_Games_Using_Factored_Value_Functions.html">130 nips-2002-Learning in Zero-Sum Team Markov Games Using Factored Value Functions</a></p>
<p>5 0.3264294 <a title="175-lsi-5" href="./nips-2002-A_Convergent_Form_of_Approximate_Policy_Iteration.html">3 nips-2002-A Convergent Form of Approximate Policy Iteration</a></p>
<p>6 0.32281151 <a title="175-lsi-6" href="./nips-2002-A_Note_on_the_Representational_Incompatibility_of_Function_Approximation_and_Factored_Dynamics.html">13 nips-2002-A Note on the Representational Incompatibility of Function Approximation and Factored Dynamics</a></p>
<p>7 0.26136684 <a title="175-lsi-7" href="./nips-2002-Learning_to_Take_Concurrent_Actions.html">134 nips-2002-Learning to Take Concurrent Actions</a></p>
<p>8 0.23373997 <a title="175-lsi-8" href="./nips-2002-Speeding_up_the_Parti-Game_Algorithm.html">185 nips-2002-Speeding up the Parti-Game Algorithm</a></p>
<p>9 0.1670249 <a title="175-lsi-9" href="./nips-2002-Derivative_Observations_in_Gaussian_Process_Models_of_Dynamic_Systems.html">65 nips-2002-Derivative Observations in Gaussian Process Models of Dynamic Systems</a></p>
<p>10 0.16360636 <a title="175-lsi-10" href="./nips-2002-Adaptive_Caching_by_Refetching.html">20 nips-2002-Adaptive Caching by Refetching</a></p>
<p>11 0.16136403 <a title="175-lsi-11" href="./nips-2002-Approximate_Linear_Programming_for_Average-Cost_Dynamic_Programming.html">33 nips-2002-Approximate Linear Programming for Average-Cost Dynamic Programming</a></p>
<p>12 0.15448003 <a title="175-lsi-12" href="./nips-2002-Convergent_Combinations_of_Reinforcement_Learning_with_Linear_Function_Approximation.html">61 nips-2002-Convergent Combinations of Reinforcement Learning with Linear Function Approximation</a></p>
<p>13 0.1260051 <a title="175-lsi-13" href="./nips-2002-Timing_and_Partial_Observability_in_the_Dopamine_System.html">199 nips-2002-Timing and Partial Observability in the Dopamine System</a></p>
<p>14 0.12107829 <a title="175-lsi-14" href="./nips-2002-Optimality_of_Reinforcement_Learning_Algorithms_with_Linear_Function_Approximation.html">159 nips-2002-Optimality of Reinforcement Learning Algorithms with Linear Function Approximation</a></p>
<p>15 0.11786735 <a title="175-lsi-15" href="./nips-2002-Scaling_of_Probability-Based_Optimization_Algorithms.html">179 nips-2002-Scaling of Probability-Based Optimization Algorithms</a></p>
<p>16 0.11407951 <a title="175-lsi-16" href="./nips-2002-Automatic_Acquisition_and_Efficient_Representation_of_Syntactic_Structures.html">35 nips-2002-Automatic Acquisition and Efficient Representation of Syntactic Structures</a></p>
<p>17 0.1136452 <a title="175-lsi-17" href="./nips-2002-Nonparametric_Representation_of_Policies_and_Value_Functions%3A_A_Trajectory-Based_Approach.html">155 nips-2002-Nonparametric Representation of Policies and Value Functions: A Trajectory-Based Approach</a></p>
<p>18 0.10728186 <a title="175-lsi-18" href="./nips-2002-Dopamine_Induced_Bistability_Enhances_Signal_Processing_in_Spiny_Neurons.html">71 nips-2002-Dopamine Induced Bistability Enhances Signal Processing in Spiny Neurons</a></p>
<p>19 0.10559774 <a title="175-lsi-19" href="./nips-2002-Value-Directed_Compression_of_POMDPs.html">205 nips-2002-Value-Directed Compression of POMDPs</a></p>
<p>20 0.10392825 <a title="175-lsi-20" href="./nips-2002-Learning_a_Forward_Model_of_a_Reflex.html">128 nips-2002-Learning a Forward Model of a Reflex</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2002_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(22, 0.032), (26, 0.015), (34, 0.012), (39, 0.046), (47, 0.056), (48, 0.068), (66, 0.034), (72, 0.017), (93, 0.578)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.99113846 <a title="175-lda-1" href="./nips-2002-Binary_Tuning_is_Optimal_for_Neural_Rate_Coding_with_High_Temporal_Resolution.html">44 nips-2002-Binary Tuning is Optimal for Neural Rate Coding with High Temporal Resolution</a></p>
<p>same-paper 2 0.92753285 <a title="175-lda-2" href="./nips-2002-Reinforcement_Learning_to_Play_an_Optimal_Nash_Equilibrium_in_Team_Markov_Games.html">175 nips-2002-Reinforcement Learning to Play an Optimal Nash Equilibrium in Team Markov Games</a></p>
<p>3 0.90877926 <a title="175-lda-3" href="./nips-2002-Binary_Coding_in_Auditory_Cortex.html">43 nips-2002-Binary Coding in Auditory Cortex</a></p>
<p>4 0.90390629 <a title="175-lda-4" href="./nips-2002-How_Linear_are_Auditory_Cortical_Responses%3F.html">103 nips-2002-How Linear are Auditory Cortical Responses?</a></p>
<p>5 0.8908267 <a title="175-lda-5" href="./nips-2002-Inferring_a_Semantic_Representation_of_Text_via_Cross-Language_Correlation_Analysis.html">112 nips-2002-Inferring a Semantic Representation of Text via Cross-Language Correlation Analysis</a></p>
<p>6 0.86565876 <a title="175-lda-6" href="./nips-2002-Spectro-Temporal_Receptive_Fields_of_Subthreshold_Responses_in_Auditory_Cortex.html">184 nips-2002-Spectro-Temporal Receptive Fields of Subthreshold Responses in Auditory Cortex</a></p>
<p>7 0.81994599 <a title="175-lda-7" href="./nips-2002-Discriminative_Learning_for_Label_Sequences_via_Boosting.html">69 nips-2002-Discriminative Learning for Label Sequences via Boosting</a></p>
<p>8 0.81712884 <a title="175-lda-8" href="./nips-2002-Efficient_Learning_Equilibrium.html">78 nips-2002-Efficient Learning Equilibrium</a></p>
<p>9 0.73245883 <a title="175-lda-9" href="./nips-2002-Morton-Style_Factorial_Coding_of_Color_in_Primary_Visual_Cortex.html">148 nips-2002-Morton-Style Factorial Coding of Color in Primary Visual Cortex</a></p>
<p>10 0.73183507 <a title="175-lda-10" href="./nips-2002-An_Estimation-Theoretic_Framework_for_the_Presentation_of_Multiple_Stimuli.html">26 nips-2002-An Estimation-Theoretic Framework for the Presentation of Multiple Stimuli</a></p>
<p>11 0.72845459 <a title="175-lda-11" href="./nips-2002-Reconstructing_Stimulus-Driven_Neural_Networks_from_Spike_Times.html">171 nips-2002-Reconstructing Stimulus-Driven Neural Networks from Spike Times</a></p>
<p>12 0.7043348 <a title="175-lda-12" href="./nips-2002-Evidence_Optimization_Techniques_for_Estimating_Stimulus-Response_Functions.html">79 nips-2002-Evidence Optimization Techniques for Estimating Stimulus-Response Functions</a></p>
<p>13 0.67582697 <a title="175-lda-13" href="./nips-2002-Nash_Propagation_for_Loopy_Graphical_Games.html">152 nips-2002-Nash Propagation for Loopy Graphical Games</a></p>
<p>14 0.66188622 <a title="175-lda-14" href="./nips-2002-Maximally_Informative_Dimensions%3A_Analyzing_Neural_Responses_to_Natural_Signals.html">141 nips-2002-Maximally Informative Dimensions: Analyzing Neural Responses to Natural Signals</a></p>
<p>15 0.65565777 <a title="175-lda-15" href="./nips-2002-An_Information_Theoretic_Approach_to_the_Functional_Classification_of_Neurons.html">28 nips-2002-An Information Theoretic Approach to the Functional Classification of Neurons</a></p>
<p>16 0.64384031 <a title="175-lda-16" href="./nips-2002-Dynamical_Constraints_on_Computing_with_Spike_Timing_in_the_Cortex.html">76 nips-2002-Dynamical Constraints on Computing with Spike Timing in the Cortex</a></p>
<p>17 0.6335628 <a title="175-lda-17" href="./nips-2002-Spikernels%3A_Embedding_Spiking_Neurons_in_Inner-Product_Spaces.html">187 nips-2002-Spikernels: Embedding Spiking Neurons in Inner-Product Spaces</a></p>
<p>18 0.63015729 <a title="175-lda-18" href="./nips-2002-A_Neural_Edge-Detection_Model_for_Enhanced_Auditory_Sensitivity_in_Modulated_Noise.html">12 nips-2002-A Neural Edge-Detection Model for Enhanced Auditory Sensitivity in Modulated Noise</a></p>
<p>19 0.61968553 <a title="175-lda-19" href="./nips-2002-Generalized%C3%82%CB%9B_Linear%C3%82%CB%9B_Models.html">96 nips-2002-GeneralizedÂ˛ LinearÂ˛ Models</a></p>
<p>20 0.61891454 <a title="175-lda-20" href="./nips-2002-Gaussian_Process_Priors_with_Uncertain_Inputs_Application_to_Multiple-Step_Ahead_Time_Series_Forecasting.html">95 nips-2002-Gaussian Process Priors with Uncertain Inputs Application to Multiple-Step Ahead Time Series Forecasting</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
