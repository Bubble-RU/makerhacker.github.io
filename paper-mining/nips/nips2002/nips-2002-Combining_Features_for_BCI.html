<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>55 nips-2002-Combining Features for BCI</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-55" href="#">nips2002-55</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>55 nips-2002-Combining Features for BCI</h1>
<br/><p>Source: <a title="nips-2002-55-pdf" href="http://papers.nips.cc/paper/2320-combining-features-for-bci.pdf">pdf</a></p><p>Author: Guido Dornhege, Benjamin Blankertz, Gabriel Curio, Klaus-Robert Müller</p><p>Abstract: Recently, interest is growing to develop an effective communication interface connecting the human brain to a computer, the ’Brain-Computer Interface’ (BCI). One motivation of BCI research is to provide a new communication channel substituting normal motor output in patients with severe neuromuscular disabilities. In the last decade, various neurophysiological cortical processes, such as slow potential shifts, movement related potentials (MRPs) or event-related desynchronization (ERD) of spontaneous EEG rhythms, were shown to be suitable for BCI, and, consequently, different independent approaches of extracting BCI-relevant EEG-features for single-trial analysis are under investigation. Here, we present and systematically compare several concepts for combining such EEG-features to improve the single-trial classiﬁcation. Feature combinations are evaluated on movement imagination experiments with 3 subjects where EEG-features are based on either MRPs or ERD, or both. Those combination methods that incorporate the assumption that the single EEG-features are physiologically mutually independent outperform the plain method of ’adding’ evidence where the single-feature vectors are simply concatenated. These results strengthen the hypothesis that MRP and ERD reﬂect at least partially independent aspects of cortical processes and open a new perspective to boost BCI effectiveness.</p><p>Reference: <a title="nips-2002-55-reference" href="../nips2002_reference/nips-2002-Combining_Features_for_BCI_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 ©§¢¤¢   Abstract Recently, interest is growing to develop an effective communication interface connecting the human brain to a computer, the ’Brain-Computer Interface’ (BCI). [sent-8, score-0.137]
</p><p>2 One motivation of BCI research is to provide a new communication channel substituting normal motor output in patients with severe neuromuscular disabilities. [sent-9, score-0.159]
</p><p>3 Feature combinations are evaluated on movement imagination experiments with 3 subjects where EEG-features are based on either MRPs or ERD, or both. [sent-12, score-0.275]
</p><p>4 These results strengthen the hypothesis that MRP and ERD reﬂect at least partially independent aspects of cortical processes and open a new perspective to boost BCI effectiveness. [sent-14, score-0.157]
</p><p>5 1 Introduction A brain-computer interface (BCI) is a system which translates a subject’s intentions into a control signal for a device, e. [sent-15, score-0.097]
</p><p>6 When measuring non-invasively, brain activity is acquired by scalp-recorded electroencephalogram (EEG) from a subject that tries to convey its intentions by behaving according to well-deﬁned paradigms, e. [sent-19, score-0.291]
</p><p>7 ’Features’ (or feature vectors) are extracted from the digitized EEG-signals by signal processing methods. [sent-22, score-0.101]
</p><p>8 These features are translated into a control signal, either (1) by simple equations or threshold criteria (with only a few free parameters that are estimated on training data), or (2) by machine learning algorithms that learn a more complex ∗ To  whom correspondence should be addressed. [sent-23, score-0.136]
</p><p>9 Concerning the pivotal step of feature extraction, neurophysiological a priori knowledge can aid to decide which EEG-feature is to be expected to hold the most discriminative information for the chosen paradigm. [sent-27, score-0.161]
</p><p>10 Here, we present several methods for combining features to enhance single-trial EEG classiﬁcation for BCI. [sent-32, score-0.159]
</p><p>11 A special focus was placed on the question how to incorporate a priori knowledge about feature independence. [sent-33, score-0.101]
</p><p>12 (1) Based on slow cortical potentials the Tübinger Thought Translation Device (TTD) [4] translates low-pass ﬁltered brain activity from central scalp position into a vertical cursor movement on a computer screen. [sent-39, score-0.423]
</p><p>13 This enables subjects to learn self-regulation of electrocortical positivity or negativity. [sent-40, score-0.074]
</p><p>14 After some training, patients can generate binary decisions in a 4 seconds pace with an accuracies of up to 85 % and thereby handle a word processor or an internet browser. [sent-41, score-0.101]
</p><p>15 (2) The Albany BCI system [2] allows the user to control cursor movement by oscillatory brain activity into one of two or four possible target areas on a computer screen. [sent-42, score-0.323]
</p><p>16 In the ﬁrst training sessions most subjects use some kind of motor imagery which is replaced by adapted strategies during further feedback sessions. [sent-43, score-0.291]
</p><p>17 And (3), the Graz BCI system [5] is based on event-related modulations of the pericentral µ - and/or β -rhythms of sensorimotor cortices, with a focus on motor preparation and imagination. [sent-46, score-0.231]
</p><p>18 Feature vectors calculated from spontaneous EEG signals by adaptive autoregressive modelling are used to train a classiﬁer. [sent-47, score-0.133]
</p><p>19 In a ternary classiﬁcation task accuracies of over 96 % were obtained in an ofﬂine study with a trial duration of 8 seconds. [sent-48, score-0.115]
</p><p>20 Most gain from a combination of different features is expected when the single features provide complementary information for the classiﬁcation task. [sent-50, score-0.204]
</p><p>21 , in primary (sensori-)motor cortex (M-1), supplementary motor area (SMA) and posterior parietal cortex (PP). [sent-53, score-0.19]
</p><p>22 MRPs started over wide areas of the sensorimotor cortices (Bereitschaftspotential) and focalizes at the contralateral M-1 hand cortex with a steep negative slope prior to ﬁnger movement onset, reaching a negative peak approximately 100 ms after EMG onset (motor potential). [sent-55, score-0.481]
</p><p>23 In contrast, a bilateral M-1 ERD just prior to movement onset appeared to reﬂect a more widespread cortical ’alerting’ function. [sent-56, score-0.222]
</p><p>24 Note that these studies analyze movement preparation and execution only. [sent-58, score-0.137]
</p><p>25 We presume a similar independence of MRP and ERD phenomena for imagined movements. [sent-59, score-0.104]
</p><p>26 Apart from exploiting complementary information on cortical processes, combining MRP and ERD based features might give the beneﬁt of being more robust against artifacts from non central nervous system (CNS) activity such as eye movement (EOG) or muscular artifacts (EMG). [sent-61, score-0.414]
</p><p>27 MRPs, EMG activity is of more concern to oscillatory features, cf. [sent-64, score-0.141]
</p><p>28 Accordingly, a classiﬁcation method that is based on both features has better chance to handle trials that are contaminated by one kind of those artifacts. [sent-66, score-0.218]
</p><p>29 On the other hand, it might increase the risk of using non-CNS activity for classiﬁcation which would not be conform with the BCI idea, [1]. [sent-67, score-0.066]
</p><p>30 In this paper we analyze EEG data from experiments with three subjects called aa, af and ak. [sent-71, score-0.144]
</p><p>31 The subject sat in a normal chair, with arms lying relaxed on the table. [sent-72, score-0.111]
</p><p>32 The subject was instructed to imagine performing left resp. [sent-76, score-0.111]
</p><p>33 right hand ﬁnger movements as long as the symbol was visible. [sent-77, score-0.069]
</p><p>34 200–300 trials were recorded for each class and each subject. [sent-78, score-0.148]
</p><p>35 Brain activity was recorded with 28 (subject aa) resp. [sent-79, score-0.098]
</p><p>36 52 (subjects af and ak) Ag/AgCl electrodes at 1000 Hz and downsampled to 100 Hz for the present ofﬂine study. [sent-80, score-0.07]
</p><p>37 In these experiments the aim of classiﬁcation is to discriminate ’left’ from ’right’ trials based on EEG-data during the whole period of imagination. [sent-84, score-0.116]
</p><p>38 In the following we describe methods to derive feature vectors capturing MRP or ERD effects. [sent-90, score-0.135]
</p><p>39 These values were used for both, classifying trials based on single-features and the combined classiﬁcation. [sent-95, score-0.148]
</p><p>40 Signals were baseline corrected on the interval 0–300 ms and downsampled by calculating ﬁve jumping means in several consecutive intervals beginning at 300 ms and ending between 1500–3500 ms. [sent-99, score-0.136]
</p><p>41 5 Hz  C3 lap  C4 lap  C3 lap  C4 lap  Figure 1: ERP and ERD (7–30 Hz) curves for subject aa in the time interval -500 ms to 3000 ms relative to stimulus. [sent-101, score-0.687]
</p><p>42 To derive feature vectors for the ERD effects we use two different methods which may reﬂect different aspects of brain rhythm modulations. [sent-107, score-0.299]
</p><p>43 The ﬁrst (AR) reﬂects the spectral distribution of the most prominent brain rhythms whereas the second (CSP) reﬂects spatial patterns of most prominent power modulation in specifying frequency bands. [sent-108, score-0.227]
</p><p>44 The feature vector of one trial is the concatenation of the AR coefﬁcients plus the variance of each channel. [sent-112, score-0.16]
</p><p>45 Accounting for this by adding the variance to the feature vector improves classiﬁcation. [sent-114, score-0.101]
</p><p>46 And to sharpen the spectral information to focal brain sources (spatial) Laplacian ﬁlters were applied. [sent-116, score-0.077]
</p><p>47 The interval for estimating the AR parameters started at 500 ms and the end points were choosen between 2000 ms and 3500 ms. [sent-117, score-0.173]
</p><p>48 This method was suggested for binary classiﬁcation of EEG trials in [9]. [sent-119, score-0.116]
</p><p>49 In features space projections on orientations with most differing power-ratios are used. [sent-120, score-0.102]
</p><p>50 In weak features discriminative information is spread across many dimensions. [sent-138, score-0.102]
</p><p>51 Classifying such features based on a small training set may lead to the well-known overﬁtting problem. [sent-139, score-0.102]
</p><p>52 To avoid this, typically one of the following strategies is employed: (1) performing strong preprocessing to extract low  dimensional feature vectors which are tractable for most classiﬁers. [sent-140, score-0.135]
</p><p>53 Or (2) performing no or weak preprocessing and carefully regularizing the classiﬁer such that high-dimensional features can be handled even with only a small training set. [sent-141, score-0.102]
</p><p>54 A good introduction to regularized classiﬁcation is [12] including regularized LDA which we used here. [sent-144, score-0.102]
</p><p>55 The regularization coefﬁcients were chosen by cross-validation together with the free parameters of the feature extraction methods, see section 2. [sent-147, score-0.205]
</p><p>56 So in this off-line analysis where in each cross-validation procedure 100 different training sets are drawn randomly from the set of all trials one would have to do a cross-validation (for model selection, MS) within a cross-validation (for estimating the generalization error, GE). [sent-150, score-0.116]
</p><p>57 On the other hand doing the model selection by cross-validation on all trials would could lead to overﬁtting and underestimating the generalization error. [sent-152, score-0.149]
</p><p>58 As an intermediate way MS-cross-validation was performed on three subsets of all trials that were randomly drawn where the size of the subsets was the same as the size of the training sets in the GE-cross-validation, i. [sent-153, score-0.116]
</p><p>59 Some differences in the quality of the features for classiﬁcation are observable, but there is not one type of feature that is generally the best. [sent-162, score-0.203]
</p><p>60 Only a small number of trials did fall in neither of those two categories (’ambivalent’) as could be expected due to the small standard deviation. [sent-167, score-0.116]
</p><p>61 It is now interesting to see whether there are trials which are for one feature type in the well classiﬁed range and for the other feature in the badly classiﬁed part. [sent-168, score-0.318]
</p><p>62 2 shows BP and CSP for subject af as example for each the part of the bad classiﬁed values which are good and bad classiﬁed in the other feature. [sent-170, score-0.363]
</p><p>63 combined features this issue was not followed in further detail. [sent-176, score-0.134]
</p><p>64 Typical approaches suggested are a winner-takes-all strategy, which cannot increase performance above the best single feature analysis, and concatenation of the single feature vectors, discussed as CONCAT below. [sent-185, score-0.202]
</p><p>65 We propose two further methods that incorporate independence assumptions (PROB and to  ak 17. [sent-187, score-0.111]
</p><p>66 5  8%  82%  81%  Figure 2: Left: Misclassiﬁcation rates for single features classiﬁed with regularized LDA. [sent-205, score-0.153]
</p><p>67 Free parameters of each feature extraction method were selected by cross-validation on subsets of all trials, see section 2. [sent-206, score-0.137]
</p><p>68 Right: Pie charts show how ’MRP-bad’ and ’CSP-bad’ trials for subject af are classiﬁed based on the respective other feature: white is the portion of the trials which is ’good’ for the other feature, black marks ’bad’, and gray ’ambivalent’ trials for the other feature. [sent-208, score-0.529]
</p><p>69 a smaller extend META) and allow individual decision boundary ﬁtting to single features (META). [sent-210, score-0.141]
</p><p>70 (CONCAT) In this simple approach of gathered evidence feature vectors are just concatenated. [sent-211, score-0.135]
</p><p>71 Additionally, we tried classiﬁcation with a linear programming machine (LPM), which is appealing for its sparse feature selection property, but it did not improve results compared to regularized LDA. [sent-213, score-0.152]
</p><p>72 Here we derive the optimal classiﬁer for combined feature vectors X = (X1 , . [sent-217, score-0.167]
</p><p>73 , Xn ) under the additional assumption that individual features X1 , . [sent-220, score-0.102]
</p><p>74 Denoting by Y (x) the decision function on feature space X ˆ Y (x) = ’R’ ⇔ P(Y = ’R’ | X = x) > P(Y = ’L’ | X = x) ⇔ fY =’R’ (x) P(Y = ’R’) > fY =’L’ (x) P(Y = ’L’), where Y is a random variable on the labels {’L’, ’R’} and f denotes densities. [sent-224, score-0.14]
</p><p>75 There are two ways possible: Regularisation of the covariance matrices with one global parameter (PROBsame) or with three separately selected parameters corresponding to the single-type features (PROBdiff). [sent-230, score-0.102]
</p><p>76 (META) In this approach a meta classiﬁer is applied to the continuous output of individual classiﬁers that are trained on single features beforehand. [sent-231, score-0.316]
</p><p>77 , if the decision boundary is linear for one feature and nonlinear for another. [sent-234, score-0.14]
</p><p>78 Here we just use LDA for all features, but regularization coefﬁcients are selected for each single feature individually. [sent-235, score-0.135]
</p><p>79 Since the meta classiﬁer acts on low (2 or 3) dimensional features further regularization is not needed, so we used unregularized LDA. [sent-236, score-0.35]
</p><p>80 META extracts discriminative information from single features independently but the meta classiﬁcation may exploit inter relations based on the output of the individual decision  aa af ak mean  Best Single 9. [sent-237, score-0.588]
</p><p>81 of the means in 10×10-fold cross-validation for combined features compared to the most successful single-type feature. [sent-279, score-0.134]
</p><p>82 3 Results Table 1 shows the results for the combined classiﬁcation methods and for comparison the best result on single-type features (’Best Single’) from the table of Fig. [sent-283, score-0.134]
</p><p>83 The CONCAT method performs only for subject ak better than the single feature methods. [sent-287, score-0.275]
</p><p>84 And second, regularisation for the single features results in different regularisation parameters. [sent-290, score-0.324]
</p><p>85 In CONCAT a single regularisation parameter has to be found. [sent-291, score-0.111]
</p><p>86 In our case the regularisation parameters for subject aa for MRP are about 0. [sent-292, score-0.322]
</p><p>87 From the other approaches the PROB methods are most successful, but META is very good, too, and better than the single feature results. [sent-295, score-0.101]
</p><p>88 Concerning the results it is noteworthy that all subjects were BCI-untrained. [sent-297, score-0.074]
</p><p>89 Only subject aa had experience as subject in EEG experiments. [sent-298, score-0.322]
</p><p>90 The result obtained with single-features is in the range of the best results for untrained BCI performance with imagined movement paradigm, cf. [sent-299, score-0.193]
</p><p>91 Whereas the result of less than 8 % error with our proposed combining approach for subject aa and af is better than for the 3 subjects in [17] in up to even 10 feedback sessions. [sent-301, score-0.459]
</p><p>92 Additionally, it should be noted that the subject aa reported that he sometimes missed to react to the stimulus due to fatigue. [sent-303, score-0.211]
</p><p>93 In contrast, the combination of features without any assumption of independence (CONCAT) did not improve accuracy in every case and always performs worse than PROB and META. [sent-308, score-0.15]
</p><p>94 These results further support the hypothesis that MRP and ERD reﬂect independent aspects of brain activity. [sent-309, score-0.113]
</p><p>95 Additionally, the combined approach has the practical advantage that no prior decision has to be made about what feature to use. [sent-311, score-0.172]
</p><p>96 Combining features of different brain processes in feedback scenarios where the subject is trying to adapt to the feedback algorithm could in principle hold the risk of making the learning task too complex for the subject. [sent-312, score-0.416]
</p><p>97 Finally, we would like to remark that the proposed feature combination principles can be used in other application areas where independent features can be obtained. [sent-314, score-0.203]
</p><p>98 Hallett, “Event-related desynchronization and movement-related cortical potentials on the ECoG and EEG”, Electroencephalogr. [sent-381, score-0.238]
</p><p>99 Pfurtscheller, “Optimal spatial ﬁltering of single trial EEG during imagined hand movement”, IEEE Trans. [sent-401, score-0.148]
</p><p>100 Pregenzer, “EEG-based discrimination between imagination of right and left hand movement”, Electroencephalogr. [sent-463, score-0.097]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('erd', 0.342), ('mrp', 0.278), ('eeg', 0.269), ('bci', 0.254), ('meta', 0.214), ('csp', 0.204), ('classi', 0.198), ('mrps', 0.171), ('movement', 0.137), ('concat', 0.128), ('desynchronization', 0.128), ('ar', 0.117), ('trials', 0.116), ('motor', 0.114), ('regularisation', 0.111), ('subject', 0.111), ('prob', 0.111), ('emg', 0.107), ('features', 0.102), ('feature', 0.101), ('aa', 0.1), ('bad', 0.091), ('eog', 0.085), ('lap', 0.085), ('lda', 0.085), ('brain', 0.077), ('nger', 0.074), ('pfurtscheller', 0.074), ('rhythms', 0.074), ('sensorimotor', 0.074), ('cation', 0.074), ('subjects', 0.074), ('af', 0.07), ('ms', 0.068), ('hz', 0.066), ('activity', 0.066), ('ambivalent', 0.064), ('braincomputer', 0.064), ('contralateral', 0.064), ('imagination', 0.064), ('lateralized', 0.064), ('ak', 0.063), ('interface', 0.06), ('neurophysiological', 0.06), ('trial', 0.059), ('potentials', 0.058), ('combining', 0.057), ('accuracies', 0.056), ('imagined', 0.056), ('imagery', 0.056), ('signals', 0.054), ('cortical', 0.052), ('regularized', 0.051), ('rhythm', 0.051), ('ect', 0.05), ('independence', 0.048), ('feedback', 0.047), ('paradigms', 0.045), ('autoregressive', 0.045), ('patients', 0.045), ('babiloni', 0.043), ('fkz', 0.043), ('neuroimage', 0.043), ('pericentral', 0.043), ('probdiff', 0.043), ('probsame', 0.043), ('vaughan', 0.043), ('wn', 0.043), ('oscillatory', 0.043), ('berlin', 0.039), ('decision', 0.039), ('cortex', 0.038), ('prominent', 0.038), ('benjamin', 0.037), ('birbaumer', 0.037), ('choosen', 0.037), ('intentions', 0.037), ('mcfarland', 0.037), ('neuper', 0.037), ('strengthen', 0.037), ('wolpaw', 0.037), ('movements', 0.036), ('ller', 0.036), ('aspects', 0.036), ('extraction', 0.036), ('device', 0.035), ('vectors', 0.034), ('free', 0.034), ('cortices', 0.034), ('potsdam', 0.034), ('regularization', 0.034), ('onset', 0.033), ('slow', 0.033), ('hand', 0.033), ('xn', 0.033), ('combined', 0.032), ('cients', 0.032), ('processes', 0.032), ('recorded', 0.032), ('concern', 0.032)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000004 <a title="55-tfidf-1" href="./nips-2002-Combining_Features_for_BCI.html">55 nips-2002-Combining Features for BCI</a></p>
<p>Author: Guido Dornhege, Benjamin Blankertz, Gabriel Curio, Klaus-Robert Müller</p><p>Abstract: Recently, interest is growing to develop an effective communication interface connecting the human brain to a computer, the ’Brain-Computer Interface’ (BCI). One motivation of BCI research is to provide a new communication channel substituting normal motor output in patients with severe neuromuscular disabilities. In the last decade, various neurophysiological cortical processes, such as slow potential shifts, movement related potentials (MRPs) or event-related desynchronization (ERD) of spontaneous EEG rhythms, were shown to be suitable for BCI, and, consequently, different independent approaches of extracting BCI-relevant EEG-features for single-trial analysis are under investigation. Here, we present and systematically compare several concepts for combining such EEG-features to improve the single-trial classiﬁcation. Feature combinations are evaluated on movement imagination experiments with 3 subjects where EEG-features are based on either MRPs or ERD, or both. Those combination methods that incorporate the assumption that the single EEG-features are physiologically mutually independent outperform the plain method of ’adding’ evidence where the single-feature vectors are simply concatenated. These results strengthen the hypothesis that MRP and ERD reﬂect at least partially independent aspects of cortical processes and open a new perspective to boost BCI effectiveness.</p><p>2 0.18494698 <a title="55-tfidf-2" href="./nips-2002-Improving_Transfer_Rates_in_Brain_Computer_Interfacing%3A_A_Case_Study.html">108 nips-2002-Improving Transfer Rates in Brain Computer Interfacing: A Case Study</a></p>
<p>Author: Peter Meinicke, Matthias Kaper, Florian Hoppe, Manfred Heumann, Helge Ritter</p><p>Abstract: In this paper we present results of a study on brain computer interfacing. We adopted an approach of Farwell & Donchin [4], which we tried to improve in several aspects. The main objective was to improve the transfer rates based on ofﬂine analysis of EEG-data but within a more realistic setup closer to an online realization than in the original studies. The objective was achieved along two different tracks: on the one hand we used state-of-the-art machine learning techniques for signal classiﬁcation and on the other hand we augmented the data space by using more electrodes for the interface. For the classiﬁcation task we utilized SVMs and, as motivated by recent ﬁndings on the learning of discriminative densities, we accumulated the values of the classiﬁcation function in order to combine several classiﬁcations, which ﬁnally lead to signiﬁcantly improved rates as compared with techniques applied in the original work. In combination with the data space augmentation, we achieved competitive transfer rates at an average of 50.5 bits/min and with a maximum of 84.7 bits/min.</p><p>3 0.14123635 <a title="55-tfidf-3" href="./nips-2002-Feature_Selection_and_Classification_on_Matrix_Data%3A_From_Large_Margins_to_Small_Covering_Numbers.html">88 nips-2002-Feature Selection and Classification on Matrix Data: From Large Margins to Small Covering Numbers</a></p>
<p>Author: Sepp Hochreiter, Klaus Obermayer</p><p>Abstract: We investigate the problem of learning a classiﬁcation task for datasets which are described by matrices. Rows and columns of these matrices correspond to objects, where row and column objects may belong to diﬀerent sets, and the entries in the matrix express the relationships between them. We interpret the matrix elements as being produced by an unknown kernel which operates on object pairs and we show that - under mild assumptions - these kernels correspond to dot products in some (unknown) feature space. Minimizing a bound for the generalization error of a linear classiﬁer which has been obtained using covering numbers we derive an objective function for model selection according to the principle of structural risk minimization. The new objective function has the advantage that it allows the analysis of matrices which are not positive deﬁnite, and not even symmetric or square. We then consider the case that row objects are interpreted as features. We suggest an additional constraint, which imposes sparseness on the row objects and show, that the method can then be used for feature selection. Finally, we apply this method to data obtained from DNA microarrays, where “column” objects correspond to samples, “row” objects correspond to genes and matrix elements correspond to expression levels. Benchmarks are conducted using standard one-gene classiﬁcation and support vector machines and K-nearest neighbors after standard feature selection. Our new method extracts a sparse set of genes and provides superior classiﬁcation results. 1</p><p>4 0.13957152 <a title="55-tfidf-4" href="./nips-2002-Spikernels%3A_Embedding_Spiking_Neurons_in_Inner-Product_Spaces.html">187 nips-2002-Spikernels: Embedding Spiking Neurons in Inner-Product Spaces</a></p>
<p>Author: Lavi Shpigelman, Yoram Singer, Rony Paz, Eilon Vaadia</p><p>Abstract: Inner-product operators, often referred to as kernels in statistical learning, deﬁne a mapping from some input space into a feature space. The focus of this paper is the construction of biologically-motivated kernels for cortical activities. The kernels we derive, termed Spikernels, map spike count sequences into an abstract vector space in which we can perform various prediction tasks. We discuss in detail the derivation of Spikernels and describe an efﬁcient algorithm for computing their value on any two sequences of neural population spike counts. We demonstrate the merits of our modeling approach using the Spikernel and various standard kernels for the task of predicting hand movement velocities from cortical recordings. In all of our experiments all the kernels we tested outperform the standard scalar product used in regression with the Spikernel consistently achieving the best performance. 1</p><p>5 0.13426951 <a title="55-tfidf-5" href="./nips-2002-Adaptive_Classification_by_Variational_Kalman_Filtering.html">21 nips-2002-Adaptive Classification by Variational Kalman Filtering</a></p>
<p>Author: Peter Sykacek, Stephen J. Roberts</p><p>Abstract: We propose in this paper a probabilistic approach for adaptive inference of generalized nonlinear classiﬁcation that combines the computational advantage of a parametric solution with the ﬂexibility of sequential sampling techniques. We regard the parameters of the classiﬁer as latent states in a ﬁrst order Markov process and propose an algorithm which can be regarded as variational generalization of standard Kalman ﬁltering. The variational Kalman ﬁlter is based on two novel lower bounds that enable us to use a non-degenerate distribution over the adaptation rate. An extensive empirical evaluation demonstrates that the proposed method is capable of infering competitive classiﬁers both in stationary and non-stationary environments. Although we focus on classiﬁcation, the algorithm is easily extended to other generalized nonlinear models.</p><p>6 0.11360613 <a title="55-tfidf-6" href="./nips-2002-Constraint_Classification_for_Multiclass_Classification_and_Ranking.html">59 nips-2002-Constraint Classification for Multiclass Classification and Ranking</a></p>
<p>7 0.1119616 <a title="55-tfidf-7" href="./nips-2002-The_RA_Scanner%3A_Prediction_of_Rheumatoid_Joint_Inflammation_Based_on_Laser_Imaging.html">196 nips-2002-The RA Scanner: Prediction of Rheumatoid Joint Inflammation Based on Laser Imaging</a></p>
<p>8 0.10749485 <a title="55-tfidf-8" href="./nips-2002-Adaptive_Scaling_for_Feature_Selection_in_SVMs.html">24 nips-2002-Adaptive Scaling for Feature Selection in SVMs</a></p>
<p>9 0.1069838 <a title="55-tfidf-9" href="./nips-2002-FloatBoost_Learning_for_Classification.html">92 nips-2002-FloatBoost Learning for Classification</a></p>
<p>10 0.10399019 <a title="55-tfidf-10" href="./nips-2002-A_Minimal_Intervention_Principle_for_Coordinated_Movement.html">9 nips-2002-A Minimal Intervention Principle for Coordinated Movement</a></p>
<p>11 0.094803818 <a title="55-tfidf-11" href="./nips-2002-Feature_Selection_in_Mixture-Based_Clustering.html">90 nips-2002-Feature Selection in Mixture-Based Clustering</a></p>
<p>12 0.090202764 <a title="55-tfidf-12" href="./nips-2002-Boosted_Dyadic_Kernel_Discriminants.html">45 nips-2002-Boosted Dyadic Kernel Discriminants</a></p>
<p>13 0.087057807 <a title="55-tfidf-13" href="./nips-2002-Neural_Decoding_of_Cursor_Motion_Using_a_Kalman_Filter.html">153 nips-2002-Neural Decoding of Cursor Motion Using a Kalman Filter</a></p>
<p>14 0.085069351 <a title="55-tfidf-14" href="./nips-2002-Adapting_Codes_and_Embeddings_for_Polychotomies.html">19 nips-2002-Adapting Codes and Embeddings for Polychotomies</a></p>
<p>15 0.085011475 <a title="55-tfidf-15" href="./nips-2002-Discriminative_Densities_from_Maximum_Contrast_Estimation.html">68 nips-2002-Discriminative Densities from Maximum Contrast Estimation</a></p>
<p>16 0.077890255 <a title="55-tfidf-16" href="./nips-2002-Feature_Selection_by_Maximum_Marginal_Diversity.html">89 nips-2002-Feature Selection by Maximum Marginal Diversity</a></p>
<p>17 0.074618421 <a title="55-tfidf-17" href="./nips-2002-Learning_to_Detect_Natural_Image_Boundaries_Using_Brightness_and_Texture.html">132 nips-2002-Learning to Detect Natural Image Boundaries Using Brightness and Texture</a></p>
<p>18 0.072631128 <a title="55-tfidf-18" href="./nips-2002-Dyadic_Classification_Trees_via_Structural_Risk_Minimization.html">72 nips-2002-Dyadic Classification Trees via Structural Risk Minimization</a></p>
<p>19 0.069887154 <a title="55-tfidf-19" href="./nips-2002-Self_Supervised_Boosting.html">181 nips-2002-Self Supervised Boosting</a></p>
<p>20 0.069371924 <a title="55-tfidf-20" href="./nips-2002-Fast_Sparse_Gaussian_Process_Methods%3A_The_Informative_Vector_Machine.html">86 nips-2002-Fast Sparse Gaussian Process Methods: The Informative Vector Machine</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2002_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.224), (1, -0.017), (2, 0.071), (3, -0.011), (4, 0.174), (5, -0.034), (6, -0.067), (7, -0.089), (8, 0.111), (9, 0.047), (10, -0.111), (11, 0.135), (12, 0.104), (13, 0.057), (14, 0.099), (15, -0.078), (16, -0.059), (17, -0.005), (18, -0.095), (19, -0.023), (20, -0.067), (21, -0.025), (22, 0.048), (23, -0.019), (24, -0.018), (25, 0.003), (26, 0.063), (27, -0.165), (28, 0.018), (29, -0.006), (30, -0.133), (31, -0.044), (32, 0.012), (33, 0.009), (34, 0.001), (35, -0.003), (36, 0.046), (37, -0.047), (38, -0.076), (39, 0.083), (40, 0.093), (41, 0.089), (42, 0.02), (43, -0.054), (44, -0.05), (45, -0.036), (46, 0.072), (47, 0.012), (48, 0.007), (49, -0.102)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.92318529 <a title="55-lsi-1" href="./nips-2002-Combining_Features_for_BCI.html">55 nips-2002-Combining Features for BCI</a></p>
<p>Author: Guido Dornhege, Benjamin Blankertz, Gabriel Curio, Klaus-Robert Müller</p><p>Abstract: Recently, interest is growing to develop an effective communication interface connecting the human brain to a computer, the ’Brain-Computer Interface’ (BCI). One motivation of BCI research is to provide a new communication channel substituting normal motor output in patients with severe neuromuscular disabilities. In the last decade, various neurophysiological cortical processes, such as slow potential shifts, movement related potentials (MRPs) or event-related desynchronization (ERD) of spontaneous EEG rhythms, were shown to be suitable for BCI, and, consequently, different independent approaches of extracting BCI-relevant EEG-features for single-trial analysis are under investigation. Here, we present and systematically compare several concepts for combining such EEG-features to improve the single-trial classiﬁcation. Feature combinations are evaluated on movement imagination experiments with 3 subjects where EEG-features are based on either MRPs or ERD, or both. Those combination methods that incorporate the assumption that the single EEG-features are physiologically mutually independent outperform the plain method of ’adding’ evidence where the single-feature vectors are simply concatenated. These results strengthen the hypothesis that MRP and ERD reﬂect at least partially independent aspects of cortical processes and open a new perspective to boost BCI effectiveness.</p><p>2 0.76560193 <a title="55-lsi-2" href="./nips-2002-Improving_Transfer_Rates_in_Brain_Computer_Interfacing%3A_A_Case_Study.html">108 nips-2002-Improving Transfer Rates in Brain Computer Interfacing: A Case Study</a></p>
<p>Author: Peter Meinicke, Matthias Kaper, Florian Hoppe, Manfred Heumann, Helge Ritter</p><p>Abstract: In this paper we present results of a study on brain computer interfacing. We adopted an approach of Farwell & Donchin [4], which we tried to improve in several aspects. The main objective was to improve the transfer rates based on ofﬂine analysis of EEG-data but within a more realistic setup closer to an online realization than in the original studies. The objective was achieved along two different tracks: on the one hand we used state-of-the-art machine learning techniques for signal classiﬁcation and on the other hand we augmented the data space by using more electrodes for the interface. For the classiﬁcation task we utilized SVMs and, as motivated by recent ﬁndings on the learning of discriminative densities, we accumulated the values of the classiﬁcation function in order to combine several classiﬁcations, which ﬁnally lead to signiﬁcantly improved rates as compared with techniques applied in the original work. In combination with the data space augmentation, we achieved competitive transfer rates at an average of 50.5 bits/min and with a maximum of 84.7 bits/min.</p><p>3 0.6411413 <a title="55-lsi-3" href="./nips-2002-The_RA_Scanner%3A_Prediction_of_Rheumatoid_Joint_Inflammation_Based_on_Laser_Imaging.html">196 nips-2002-The RA Scanner: Prediction of Rheumatoid Joint Inflammation Based on Laser Imaging</a></p>
<p>Author: Anton Schwaighofer, Volker Tresp, Peter Mayer, Alexander K. Scheel, Gerhard A. Müller</p><p>Abstract: We describe the RA scanner, a novel system for the examination of patients suffering from rheumatoid arthritis. The RA scanner is based on a novel laser-based imaging technique which is sensitive to the optical characteristics of ﬁnger joint tissue. Based on the laser images, ﬁnger joints are classiﬁed according to whether the inﬂammatory status has improved or worsened. To perform the classiﬁcation task, various linear and kernel-based systems were implemented and their performances were compared. Special emphasis was put on measures to reliably perform parameter tuning and evaluation, since only a very small data set was available. Based on the results presented in this paper, it was concluded that the RA scanner permits a reliable classiﬁcation of pathological ﬁnger joints, thus paving the way for a further development from prototype to product stage.</p><p>4 0.58804858 <a title="55-lsi-4" href="./nips-2002-FloatBoost_Learning_for_Classification.html">92 nips-2002-FloatBoost Learning for Classification</a></p>
<p>Author: Stan Z. Li, Zhenqiu Zhang, Heung-yeung Shum, Hongjiang Zhang</p><p>Abstract: AdaBoost [3] minimizes an upper error bound which is an exponential function of the margin on the training set [14]. However, the ultimate goal in applications of pattern classiﬁcation is always minimum error rate. On the other hand, AdaBoost needs an effective procedure for learning weak classiﬁers, which by itself is difﬁcult especially for high dimensional data. In this paper, we present a novel procedure, called FloatBoost, for learning a better boosted classiﬁer. FloatBoost uses a backtrack mechanism after each iteration of AdaBoost to remove weak classiﬁers which cause higher error rates. The resulting ﬂoat-boosted classiﬁer consists of fewer weak classiﬁers yet achieves lower error rates than AdaBoost in both training and test. We also propose a statistical model for learning weak classiﬁers, based on a stagewise approximation of the posterior using an overcomplete set of scalar features. Experimental comparisons of FloatBoost and AdaBoost are provided through a difﬁcult classiﬁcation problem, face detection, where the goal is to learn from training examples a highly nonlinear classiﬁer to differentiate between face and nonface patterns in a high dimensional space. The results clearly demonstrate the promises made by FloatBoost over AdaBoost.</p><p>5 0.5773052 <a title="55-lsi-5" href="./nips-2002-Neural_Decoding_of_Cursor_Motion_Using_a_Kalman_Filter.html">153 nips-2002-Neural Decoding of Cursor Motion Using a Kalman Filter</a></p>
<p>Author: W Wu, M. J. Black, Y. Gao, M. Serruya, A. Shaikhouni, J. P. Donoghue, Elie Bienenstock</p><p>Abstract: The direct neural control of external devices such as computer displays or prosthetic limbs requires the accurate decoding of neural activity representing continuous movement. We develop a real-time control system using the spiking activity of approximately 40 neurons recorded with an electrode array implanted in the arm area of primary motor cortex. In contrast to previous work, we develop a control-theoretic approach that explicitly models the motion of the hand and the probabilistic relationship between this motion and the mean ﬁring rates of the cells in 70 bins. We focus on a realistic cursor control task in which the subject must move a cursor to “hit” randomly placed targets on a computer monitor. Encoding and decoding of the neural data is achieved with a Kalman ﬁlter which has a number of advantages over previous linear ﬁltering techniques. In particular, the Kalman ﬁlter reconstructions of hand trajectories in off-line experiments are more accurate than previously reported results and the model provides insights into the nature of the neural coding of movement. ¨ ©§</p><p>6 0.56361598 <a title="55-lsi-6" href="./nips-2002-Constraint_Classification_for_Multiclass_Classification_and_Ranking.html">59 nips-2002-Constraint Classification for Multiclass Classification and Ranking</a></p>
<p>7 0.55597883 <a title="55-lsi-7" href="./nips-2002-Adaptive_Classification_by_Variational_Kalman_Filtering.html">21 nips-2002-Adaptive Classification by Variational Kalman Filtering</a></p>
<p>8 0.54837847 <a title="55-lsi-8" href="./nips-2002-Feature_Selection_and_Classification_on_Matrix_Data%3A_From_Large_Margins_to_Small_Covering_Numbers.html">88 nips-2002-Feature Selection and Classification on Matrix Data: From Large Margins to Small Covering Numbers</a></p>
<p>9 0.54462957 <a title="55-lsi-9" href="./nips-2002-Adaptive_Scaling_for_Feature_Selection_in_SVMs.html">24 nips-2002-Adaptive Scaling for Feature Selection in SVMs</a></p>
<p>10 0.54012221 <a title="55-lsi-10" href="./nips-2002-Improving_a_Page_Classifier_with_Anchor_Extraction_and_Link_Analysis.html">109 nips-2002-Improving a Page Classifier with Anchor Extraction and Link Analysis</a></p>
<p>11 0.52740324 <a title="55-lsi-11" href="./nips-2002-Discriminative_Densities_from_Maximum_Contrast_Estimation.html">68 nips-2002-Discriminative Densities from Maximum Contrast Estimation</a></p>
<p>12 0.5171833 <a title="55-lsi-12" href="./nips-2002-Spikernels%3A_Embedding_Spiking_Neurons_in_Inner-Product_Spaces.html">187 nips-2002-Spikernels: Embedding Spiking Neurons in Inner-Product Spaces</a></p>
<p>13 0.50743866 <a title="55-lsi-13" href="./nips-2002-A_Minimal_Intervention_Principle_for_Coordinated_Movement.html">9 nips-2002-A Minimal Intervention Principle for Coordinated Movement</a></p>
<p>14 0.48983112 <a title="55-lsi-14" href="./nips-2002-Coulomb_Classifiers%3A_Generalizing_Support_Vector_Machines_via_an_Analogy_to_Electrostatic_Systems.html">62 nips-2002-Coulomb Classifiers: Generalizing Support Vector Machines via an Analogy to Electrostatic Systems</a></p>
<p>15 0.47608116 <a title="55-lsi-15" href="./nips-2002-Boosted_Dyadic_Kernel_Discriminants.html">45 nips-2002-Boosted Dyadic Kernel Discriminants</a></p>
<p>16 0.46241102 <a title="55-lsi-16" href="./nips-2002-Learning_to_Detect_Natural_Image_Boundaries_Using_Brightness_and_Texture.html">132 nips-2002-Learning to Detect Natural Image Boundaries Using Brightness and Texture</a></p>
<p>17 0.45352533 <a title="55-lsi-17" href="./nips-2002-Feature_Selection_by_Maximum_Marginal_Diversity.html">89 nips-2002-Feature Selection by Maximum Marginal Diversity</a></p>
<p>18 0.44763404 <a title="55-lsi-18" href="./nips-2002-Fast_Sparse_Gaussian_Process_Methods%3A_The_Informative_Vector_Machine.html">86 nips-2002-Fast Sparse Gaussian Process Methods: The Informative Vector Machine</a></p>
<p>19 0.42422861 <a title="55-lsi-19" href="./nips-2002-Dyadic_Classification_Trees_via_Structural_Risk_Minimization.html">72 nips-2002-Dyadic Classification Trees via Structural Risk Minimization</a></p>
<p>20 0.42036325 <a title="55-lsi-20" href="./nips-2002-Expected_and_Unexpected_Uncertainty%3A_ACh_and_NE_in_the_Neocortex.html">81 nips-2002-Expected and Unexpected Uncertainty: ACh and NE in the Neocortex</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2002_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(6, 0.302), (11, 0.016), (23, 0.101), (42, 0.045), (54, 0.096), (55, 0.057), (57, 0.019), (67, 0.023), (68, 0.032), (74, 0.098), (87, 0.02), (92, 0.029), (98, 0.093)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.84486735 <a title="55-lda-1" href="./nips-2002-Retinal_Processing_Emulation_in_a_Programmable_2-Layer_Analog_Array_Processor_CMOS_Chip.html">177 nips-2002-Retinal Processing Emulation in a Programmable 2-Layer Analog Array Processor CMOS Chip</a></p>
<p>Author: R. Carmona, F. Jiménez-garrido, R. Dominguez-castro, S. Espejo, A. Rodriguez-vázquez</p><p>Abstract: A bio-inspired model for an analog programmable array processor (APAP), based on studies on the vertebrate retina, has permitted the realization of complex programmable spatio-temporal dynamics in VLSI. This model mimics the way in which images are processed in the visual pathway, rendering a feasible alternative for the implementation of early vision applications in standard technologies. A prototype chip has been designed and fabricated in a 0.5µm standard CMOS process. Computing power per area and power consumption is amongst the highest reported for a single chip. Design challenges, trade-oﬀs and some experimental results are presented in this paper. 1</p><p>same-paper 2 0.78153586 <a title="55-lda-2" href="./nips-2002-Combining_Features_for_BCI.html">55 nips-2002-Combining Features for BCI</a></p>
<p>Author: Guido Dornhege, Benjamin Blankertz, Gabriel Curio, Klaus-Robert Müller</p><p>Abstract: Recently, interest is growing to develop an effective communication interface connecting the human brain to a computer, the ’Brain-Computer Interface’ (BCI). One motivation of BCI research is to provide a new communication channel substituting normal motor output in patients with severe neuromuscular disabilities. In the last decade, various neurophysiological cortical processes, such as slow potential shifts, movement related potentials (MRPs) or event-related desynchronization (ERD) of spontaneous EEG rhythms, were shown to be suitable for BCI, and, consequently, different independent approaches of extracting BCI-relevant EEG-features for single-trial analysis are under investigation. Here, we present and systematically compare several concepts for combining such EEG-features to improve the single-trial classiﬁcation. Feature combinations are evaluated on movement imagination experiments with 3 subjects where EEG-features are based on either MRPs or ERD, or both. Those combination methods that incorporate the assumption that the single EEG-features are physiologically mutually independent outperform the plain method of ’adding’ evidence where the single-feature vectors are simply concatenated. These results strengthen the hypothesis that MRP and ERD reﬂect at least partially independent aspects of cortical processes and open a new perspective to boost BCI effectiveness.</p><p>3 0.53957856 <a title="55-lda-3" href="./nips-2002-Neural_Decoding_of_Cursor_Motion_Using_a_Kalman_Filter.html">153 nips-2002-Neural Decoding of Cursor Motion Using a Kalman Filter</a></p>
<p>Author: W Wu, M. J. Black, Y. Gao, M. Serruya, A. Shaikhouni, J. P. Donoghue, Elie Bienenstock</p><p>Abstract: The direct neural control of external devices such as computer displays or prosthetic limbs requires the accurate decoding of neural activity representing continuous movement. We develop a real-time control system using the spiking activity of approximately 40 neurons recorded with an electrode array implanted in the arm area of primary motor cortex. In contrast to previous work, we develop a control-theoretic approach that explicitly models the motion of the hand and the probabilistic relationship between this motion and the mean ﬁring rates of the cells in 70 bins. We focus on a realistic cursor control task in which the subject must move a cursor to “hit” randomly placed targets on a computer monitor. Encoding and decoding of the neural data is achieved with a Kalman ﬁlter which has a number of advantages over previous linear ﬁltering techniques. In particular, the Kalman ﬁlter reconstructions of hand trajectories in off-line experiments are more accurate than previously reported results and the model provides insights into the nature of the neural coding of movement. ¨ ©§</p><p>4 0.53579706 <a title="55-lda-4" href="./nips-2002-Improving_Transfer_Rates_in_Brain_Computer_Interfacing%3A_A_Case_Study.html">108 nips-2002-Improving Transfer Rates in Brain Computer Interfacing: A Case Study</a></p>
<p>Author: Peter Meinicke, Matthias Kaper, Florian Hoppe, Manfred Heumann, Helge Ritter</p><p>Abstract: In this paper we present results of a study on brain computer interfacing. We adopted an approach of Farwell & Donchin [4], which we tried to improve in several aspects. The main objective was to improve the transfer rates based on ofﬂine analysis of EEG-data but within a more realistic setup closer to an online realization than in the original studies. The objective was achieved along two different tracks: on the one hand we used state-of-the-art machine learning techniques for signal classiﬁcation and on the other hand we augmented the data space by using more electrodes for the interface. For the classiﬁcation task we utilized SVMs and, as motivated by recent ﬁndings on the learning of discriminative densities, we accumulated the values of the classiﬁcation function in order to combine several classiﬁcations, which ﬁnally lead to signiﬁcantly improved rates as compared with techniques applied in the original work. In combination with the data space augmentation, we achieved competitive transfer rates at an average of 50.5 bits/min and with a maximum of 84.7 bits/min.</p><p>5 0.5213744 <a title="55-lda-5" href="./nips-2002-An_Estimation-Theoretic_Framework_for_the_Presentation_of_Multiple_Stimuli.html">26 nips-2002-An Estimation-Theoretic Framework for the Presentation of Multiple Stimuli</a></p>
<p>Author: Christian W. Eurich</p><p>Abstract: A framework is introduced for assessing the encoding accuracy and the discriminational ability of a population of neurons upon simultaneous presentation of multiple stimuli. Minimal square estimation errors are obtained from a Fisher information analysis in an abstract compound space comprising the features of all stimuli. Even for the simplest case of linear superposition of responses and Gaussian tuning, the symmetries in the compound space are very diﬀerent from those in the case of a single stimulus. The analysis allows for a quantitative description of attentional eﬀects and can be extended to include neural nonlinearities such as nonclassical receptive ﬁelds. 1</p><p>6 0.51852393 <a title="55-lda-6" href="./nips-2002-Approximate_Linear_Programming_for_Average-Cost_Dynamic_Programming.html">33 nips-2002-Approximate Linear Programming for Average-Cost Dynamic Programming</a></p>
<p>7 0.51823902 <a title="55-lda-7" href="./nips-2002-Binary_Tuning_is_Optimal_for_Neural_Rate_Coding_with_High_Temporal_Resolution.html">44 nips-2002-Binary Tuning is Optimal for Neural Rate Coding with High Temporal Resolution</a></p>
<p>8 0.51519406 <a title="55-lda-8" href="./nips-2002-Morton-Style_Factorial_Coding_of_Color_in_Primary_Visual_Cortex.html">148 nips-2002-Morton-Style Factorial Coding of Color in Primary Visual Cortex</a></p>
<p>9 0.51384079 <a title="55-lda-9" href="./nips-2002-An_Information_Theoretic_Approach_to_the_Functional_Classification_of_Neurons.html">28 nips-2002-An Information Theoretic Approach to the Functional Classification of Neurons</a></p>
<p>10 0.51288176 <a title="55-lda-10" href="./nips-2002-A_Model_for_Learning_Variance_Components_of_Natural_Images.html">10 nips-2002-A Model for Learning Variance Components of Natural Images</a></p>
<p>11 0.51273006 <a title="55-lda-11" href="./nips-2002-A_Convergent_Form_of_Approximate_Policy_Iteration.html">3 nips-2002-A Convergent Form of Approximate Policy Iteration</a></p>
<p>12 0.51241863 <a title="55-lda-12" href="./nips-2002-A_Digital_Antennal_Lobe_for_Pattern_Equalization%3A_Analysis_and_Design.html">5 nips-2002-A Digital Antennal Lobe for Pattern Equalization: Analysis and Design</a></p>
<p>13 0.51104057 <a title="55-lda-13" href="./nips-2002-Maximally_Informative_Dimensions%3A_Analyzing_Neural_Responses_to_Natural_Signals.html">141 nips-2002-Maximally Informative Dimensions: Analyzing Neural Responses to Natural Signals</a></p>
<p>14 0.51069123 <a title="55-lda-14" href="./nips-2002-Learning_Attractor_Landscapes_for_Learning_Motor_Primitives.html">123 nips-2002-Learning Attractor Landscapes for Learning Motor Primitives</a></p>
<p>15 0.51043457 <a title="55-lda-15" href="./nips-2002-Adaptive_Quantization_and_Density_Estimation_in_Silicon.html">23 nips-2002-Adaptive Quantization and Density Estimation in Silicon</a></p>
<p>16 0.50934219 <a title="55-lda-16" href="./nips-2002-A_Bilinear_Model_for_Sparse_Coding.html">2 nips-2002-A Bilinear Model for Sparse Coding</a></p>
<p>17 0.50703168 <a title="55-lda-17" href="./nips-2002-Forward-Decoding_Kernel-Based_Phone_Recognition.html">93 nips-2002-Forward-Decoding Kernel-Based Phone Recognition</a></p>
<p>18 0.5056597 <a title="55-lda-18" href="./nips-2002-Learning_to_Detect_Natural_Image_Boundaries_Using_Brightness_and_Texture.html">132 nips-2002-Learning to Detect Natural Image Boundaries Using Brightness and Texture</a></p>
<p>19 0.50352436 <a title="55-lda-19" href="./nips-2002-Discriminative_Densities_from_Maximum_Contrast_Estimation.html">68 nips-2002-Discriminative Densities from Maximum Contrast Estimation</a></p>
<p>20 0.50331843 <a title="55-lda-20" href="./nips-2002-Nonparametric_Representation_of_Policies_and_Value_Functions%3A_A_Trajectory-Based_Approach.html">155 nips-2002-Nonparametric Representation of Policies and Value Functions: A Trajectory-Based Approach</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
