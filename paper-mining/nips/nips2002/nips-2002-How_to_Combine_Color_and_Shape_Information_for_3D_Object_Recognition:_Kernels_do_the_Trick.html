<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>105 nips-2002-How to Combine Color and Shape Information for 3D Object Recognition: Kernels do the Trick</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2002" href="../home/nips2002_home.html">nips2002</a> <a title="nips-2002-105" href="#">nips2002-105</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>105 nips-2002-How to Combine Color and Shape Information for 3D Object Recognition: Kernels do the Trick</h1>
<br/><p>Source: <a title="nips-2002-105-pdf" href="http://papers.nips.cc/paper/2218-how-to-combine-color-and-shape-information-for-3d-object-recognition-kernels-do-the-trick.pdf">pdf</a></p><p>Author: B. Caputo, Gy. Dorkó</p><p>Abstract: This paper presents a kernel method that allows to combine color and shape information for appearance-based object recognition. It doesn't require to define a new common representation, but use the power of kernels to combine different representations together in an effective manner. These results are achieved using results of statistical mechanics of spin glasses combined with Markov random fields via kernel functions. Experiments show an increase in recognition rate up to 5.92% with respect to conventional strategies. 1</p><p>Reference: <a title="nips-2002-105-reference" href="../nips2002_reference/nips-2002-How_to_Combine_Color_and_Shape_Information_for_3D_Object_Recognition%3A_Kernels_do_the_Trick_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 de  Abstract This paper presents a kernel method that allows to combine color and shape information for appearance-based object recognition. [sent-6, score-1.165]
</p><p>2 It doesn't require to define a new common representation, but use the power of kernels to combine different representations together in an effective manner. [sent-7, score-0.284]
</p><p>3 These results are achieved using results of statistical mechanics of spin glasses combined with Markov random fields via kernel functions. [sent-8, score-0.528]
</p><p>4 Experiments show an increase in recognition rate up to 5. [sent-9, score-0.097]
</p><p>5 They look very similar, but this wouldn't be the case if we would look at color pictures: as the left car is yellow and the right car is red, we would realize at a first glance that they are different. [sent-12, score-0.718]
</p><p>6 This simple example shows that color and shape information are both important cues for object recognition. [sent-13, score-0.982]
</p><p>7 This is because most of representations proposed in literature aren't suitable for both type of information [5, 11, 13, 2]. [sent-15, score-0.128]
</p><p>8 Some authors tackled this problem building up new representations, containing both color and shape information; these approaches show very good performances [7, 12,6]. [sent-16, score-0.769]
</p><p>9 Although there are many cases where it is convenient to have both, a huge literature shows that color only, or shape only representations work very well for many applications [9, 13, 11, 2]. [sent-18, score-0.897]
</p><p>10 A new, common representation doesn't always permit to use just color or just shape information alone, depending on the task considered; • the dimension of the feature vector. [sent-19, score-0.866]
</p><p>11 representation alone, with all the risks of a curse of dimensionality effect. [sent-21, score-0.045]
</p><p>12 We achieve this goal focusing the attention on how two given shape and color representations can be combined together as they are, rather than define a new representation. [sent-23, score-0.969]
</p><p>13 We obtain this using Spin Glass-Markov Random Fields (SG-MRF), a new kernel method that integrates results of statistical physics of spin glasses with Gibbs probability distributions via nonlinear kernel mapping. [sent-24, score-0.437]
</p><p>14 SG-MRFs have been used for robust appearance-based object recognition with very good results, using a kernelized Hopfield energy [3]. [sent-25, score-0.567]
</p><p>15 Here we extend SG-MRF to a new SG-like energy function, inspired by the ultrametric properties of the SG phase space. [sent-26, score-0.36]
</p><p>16 The structure of this energy provides a natural framework for combining shape and color representations together, without defining a new common representation (such as a concatenated one, see for instance [7]). [sent-27, score-1.216]
</p><p>17 This approach presents two main advantages: • it permits us to use existing and well tested representations both for shape and color information; • it permits us to use this knowledge in a flexible manner, depending on the task considered. [sent-28, score-1.091]
</p><p>18 Experimental results show the effectiveness of the new proposed kernel method. [sent-30, score-0.167]
</p><p>19 The paper is organized as follows: section 2 defines the probabilistic framework for object recognition, section 3 reviews SG-MRF and section 4 presents the new energy function and how it can be used for combining together color and shape information. [sent-31, score-1.253]
</p><p>20 Section 5 presents experiments that show the effectiveness of our approach, compared to other conventional strategies (NNe, x2 and SVM [10, 14]). [sent-32, score-0.138]
</p><p>21 2  Probabilistic Appearance-based Object Recognition  Probabilistic appearance-based object recognition methods consider images as random feature vectors. [sent-34, score-0.363]
</p><p>22 We will consider each image as a random feature vector x E RMN. [sent-42, score-0.091]
</p><p>23 ,D k of objects, and that for each object is  given a set ofnj data samples, d j = {xLx~, . [sent-46, score-0.213]
</p><p>24 We will assign each object to a pattern class 01,fh, . [sent-53, score-0.213]
</p><p>25 How the object class OJ is represented, given a set of data samples dj (relative to that object class) , varies for different appearance-based approaches: it can consider shape information only, or color information only or both. [sent-57, score-1.289]
</p><p>26 This is equivalent to consider a set of features {hL ht· . [sent-58, score-0.031]
</p><p>27 k, where each feature vector h~, is computed from the , image x~1o, h~ Jo = T(x~),ht E G == ~m. [sent-63, score-0.063]
</p><p>28 Then, given a test image x and its associate feature vector h, the decision will be made using a Maximum A Posteriori (MAP) classifier: o  1*  = argmaxPo ; (h) = argmaxP(Ojlh) = argmaxP(hIOj)P(Oj),  j  j  j  (1)  using Bayes rule. [sent-65, score-0.063]
</p><p>29 In the rest of the paper we will assume that the prior P(Oj) is the same for all object classes; thus the Bayes classifier (1) simplifies to j* = argmaxP(hIOj ). [sent-67, score-0.275]
</p><p>30 (3)  {h}  The normalizing constant Z is called the partition function, and E(hIOj ) is the energy function. [sent-70, score-0.174]
</p><p>31 Spin Glass-Markov Random Fields overcome this limitation and can be effectively used for robust appearance-based object recognition [3]0 Next sections review SG-MRF and introduce a new energy function that allows to combine shape and color only representations in a common probabilistic framework. [sent-72, score-1.454]
</p><p>32 3  Spin Glass-Markov Random Fields  Consider k object classes 0 1 , O2 , . [sent-73, score-0.213]
</p><p>33 , Ok, and for each object a set of nj data samples, dj = {xL . [sent-76, score-0.281]
</p><p>34 We will suppose to extract, from each data sample dJ a set of features {hi, . [sent-83, score-0.031]
</p><p>35 h~, For instance, h~, can be a color histogram computed from x~. [sent-86, score-0.555]
</p><p>36 0  Descendant  Descendant  Descendant  Figure 2: Hierarchical structure induced by the ultrametric energy function. [sent-88, score-0.36]
</p><p>37 where ESGMRF (hIO j ) is a kernelized spin glass energy function. [sent-89, score-0.405]
</p><p>38 The most general SG energy is given by [1] E  =-  L  Jij  (6)  i,j = 1, . [sent-90, score-0.174]
</p><p>39 N,  Si Sj  ( i,j)  where the Si are random variables taking values in [-1, + 1], s = (Sl, . [sent-93, score-0.028]
</p><p>40 When the Jij is given by the Hopfield 's prescription  J ij =  ~  P  L dl') ~]I')  (7)  ,  1'=1  with {~(I') }~=1 given configurations of the system ( prototypes) having the following properties: (aj ~(I') . [sent-100, score-0.037]
</p><p>41 The number of prototypes per class must be finite, and they must satisfy the condition K(h(i),h(l)) = 0, for all i,l = 1, . [sent-104, score-0.172]
</p><p>42 Note that SG-MRFs are defined on features rather than on raw pixels data. [sent-112, score-0.031]
</p><p>43 A key characteristic of the model is that in SG-MRF the functional form of the energy is given by construction. [sent-114, score-0.174]
</p><p>44 4  Ultrametric Spin Glass-Markov Random Fields  Consider the energy function (6) with the following connection matrix: 1 P J ij = N ~ ~~JL) ~)JL)  (q". [sent-115, score-0.2]
</p><p>45 This energy induces a hierarchical organization of stored prototypes ([1], see Figure 2). [sent-120, score-0.394]
</p><p>46 The set of prototypes {~(JL) g=1 are stored at the first level of the hierarchy and are usually called the ancestors. [sent-121, score-0.269]
</p><p>47 This energy will have p+ L~= 1 qJL minima, of which p absolute (ancestor level) and L~=1 qJL local (descendant level). [sent-125, score-0.174]
</p><p>48 Here we are interested in using this energy in the SG-MRF framework shown in Section 4. [sent-127, score-0.174]
</p><p>49 To this purpose, we show that the energy (6), with the connection matrix (10), can be written as a function of scalar product between configurations  [4]: E = -  t  ~ 2: [~ t dJL ) ~)JL) (1 + 1]~JLV)1]JJLV))] SiSj = ~  = -  JL= 1  v= 1  [~2 [t;(~(JL). [sent-128, score-0.237]
</p><p>50 (11)  The ultrametric energy (11) can be kernelized as done for the Hopfield energy and thus can be used in a MRF framework. [sent-131, score-0.593]
</p><p>51 Given a set of data samples dj for each object class Dj,j = 1, . [sent-134, score-0.307]
</p><p>52 k, we will extract two kinds of feature vectors, {hS~i }7=1 containing shape information and {he~i }7=1 containing color information. [sent-137, score-0.794]
</p><p>53 USG-MRF provides a straightforward manner to use the Bayes classifier (2) using both these representations separately. [sent-138, score-0.169]
</p><p>54 We will consider the color features {he~i }7=1 at the ancestor level and the shape features {hS~i }7=1 at the descendant level. [sent-139, score-1.159]
</p><p>55 The USG-MRF energy function will be Pi  " - (JL) EUSGMRF = - L. [sent-140, score-0.174]
</p><p>56 J[Ks(hs (JLV) , hs)] 2 ,  (12)  JL=1v=1  where {he (JL) }~~1 will be the set of prototypes relative to the ancestor level, and - (JLV) q  {hs }v~1' J1 = 1, . [sent-144, score-0.273]
</p><p>57 Pj the set of prototypes at the descendant level. [sent-147, score-0.358]
</p><p>58 These prototypes are selected from the training data as described in section 3 for SG-MRF. [sent-148, score-0.172]
</p><p>59 Kc is the generalized Gaussian kernel at the ancestor level, and Ks is the generalized Gaussian kernel at the descendant level. [sent-149, score-0.497]
</p><p>60 We stress that the kernel must  be the same at each level of the hierarchy, but can be different between levels (as to say between ancestor and descendant). [sent-150, score-0.247]
</p><p>61 The Bayes classifier based on USG-MRF will be (13) Note that the parametric form of kernels is known (eq (9); thus, when (U)SG-MRF is used in a Bayes classifier for classification purposes, it permits to learn the kernel to be used from the training data, with a leave-one-out strategy. [sent-151, score-0.397]
</p><p>62 5  Experiments  In order to show the effectiveness of USG-MRF for appearance-based object recognition, we perform several sets of experiments. [sent-152, score-0.275]
</p><p>63 All of them were ran on the COIL database [9] ; it consists of 7200 color images of 100 objects (72 views for object); each image is of 128 x 128 pixels. [sent-153, score-0.737]
</p><p>64 The images were obtained by placing the objects on a turntable and taking a view every 5°. [sent-154, score-0.063]
</p><p>65 In all the experiments we performed, the training set consisted of 12 views per object (one every 30°). [sent-155, score-0.3]
</p><p>66 Among the many representations proposed in literature, we chose a shape only and color only representation, and we ran experiments using these representations separated, concatenated together in a common feature vector and combined together in the USG-MRF. [sent-157, score-1.325]
</p><p>67 The purpose of these experiments is to prove the effectiveness of the USG-MRF model rather than select the optimal combination for the shape and color representations. [sent-158, score-0.872]
</p><p>68 Thus, we limited the experiments to one shape only and one color only representations; but USG-MRF can be applied to any other kind of shape and/or color representation (see for instance [4]). [sent-159, score-1.624]
</p><p>69 As color only representation, we chose two dimensional rg Color Histogram (CH), with resolution of bin axis equal to 8 [13]. [sent-160, score-0.58]
</p><p>70 As shape only representation, we chose Multidimensional receptive Field Histograms (MFH) [11], with two local characteristics based on Gaussian derivatives along x and y directions , with u = 1. [sent-162, score-0.26]
</p><p>71 These two representations were used for performing the following sets of experiments: • Shape experiments: we ran the experiments using the shape features only. [sent-165, score-0.472]
</p><p>72 Classification was performed using SG-MRF with the kernelized Hopfield energy (6)-(7). [sent-166, score-0.233]
</p><p>73 The kernel parameters (a, b, p) were learned using a leave-one-out strategy. [sent-167, score-0.105]
</p><p>74 The results were benchmarked with those obtained with a X2 and n similarity measures, which proved to be very effective for this representation, and with SVM with Gaussian kernel, p E [0. [sent-168, score-0.047]
</p><p>75 • Color experiments: we ran the experiments using the color features only. [sent-170, score-0.662]
</p><p>76 Classification and benchmarking were performed as in the shape experiment. [sent-171, score-0.283]
</p><p>77 • Color-Shape experiments: we ran the experiments using the color and shape features concatenated together to form a unique feature vector. [sent-172, score-1.029]
</p><p>78 Again, classification and benchmarking were performed as in the shape experiment. [sent-173, score-0.335]
</p><p>79 • Ultrametric experiment: we ran a single experiment using the shape and color representation disjoint in the USG-MRF framework. [sent-174, score-0.871]
</p><p>80 The kernel parameters relative  to each level (as, bs , Ps and a e, be, Pc) are learned with the leave-one-out technique. [sent-175, score-0.146]
</p><p>81 Results obtained with this approach cannot be directly benchmarked with other similarity measures. [sent-176, score-0.047]
</p><p>82 55  Table 1: Classification results; we report for each set of experiments the obtained error rates. [sent-192, score-0.041]
</p><p>83 Results presented in Table 1 show that for all series of experiments, for all representations, SG-MRF always gave the best recognition result. [sent-193, score-0.118]
</p><p>84 Moreover, the overall best recognition result is obtained with USG-MRF. [sent-194, score-0.118]
</p><p>85 Table 2 shows some examples of objects misclassified by SG-MRF and correctly classified by USGMRF. [sent-198, score-0.091]
</p><p>86 We see that USG-MRF classifies correctly in cases where shape only or color only gives the right answer (but not both, and not in the concatenated representation; Table 2, left and middle column), and also in cases where color only and shape only don't classify correctly (Table 2, right column). [sent-199, score-1.7]
</p><p>87 These examples show clearly that the better performance of USG-MRF is due to its hierarchical structure that permits to use different kernels on different features, thus to weight their relevance in a flexible manner with respect to the considered application. [sent-200, score-0.168]
</p><p>88 We remark once again that all the kernel parameters (thus ultimately the kernel itself) are learned from the training data; to the best of our knowledge (U)SG-MRF is the first kernel method for vision application that doesn't select heuristically the kernel to be used. [sent-201, score-0.441]
</p><p>89 6  Summary  In this paper we presented a kernel method that permits us to combine color and shape information for appearance-based object recognition. [sent-203, score-1.207]
</p><p>90 It does not require us to define a new common representation, but use the power of kernels to combine different representations together in an effective manner. [sent-204, score-0.284]
</p><p>91 This result is achieved using results of statistical mechanics of Spin Glasses combined with Markov Random Fields via kernel functions. [sent-205, score-0.164]
</p><p>92 Future work will explore the possibility to use different representations for color and shape and to use this method for tackling other challenging problems in object recognition, such as recognition of objects in heterogeneous background and under different lighting conditions. [sent-207, score-1.249]
</p><p>93 Niemann, "A new kernel method for robust appearancebased object recognition: Spin Glass-Markov random fields", submitted to PR, available at http : //www. [sent-219, score-0.395]
</p><p>94 Niemann , "An ultrametric approach to object recognition" , submitted to VMV02, availabe at http://www. [sent-225, score-0.424]
</p><p>95 Bischof, "Robust recognition using eigenimages" , CVIU,78:99-118 , 2000. [sent-230, score-0.097]
</p><p>96 Kittler, "On representation and matching of multi-coloured objects", Proc ICCV95, 726-732, 1995. [sent-233, score-0.045]
</p><p>97 Mel, "SEEM ORE: combining color, shape and texture histogramming in a neurally-inspired approach to visual object recognition", NC, 9: 777-804, 1997 [8] J. [sent-236, score-0.474]
</p><p>98 "A Markov random field model- based approach to image interpretation" . [sent-240, score-0.112]
</p><p>99 Crowley, "Recognition without correspondence using multidimensional receptive field histograms", IJCV, 36(1) ,:31- 52, 2000. [sent-256, score-0.066]
</p><p>100 Healey, "Combining color and geometric information for the illumination invariant recognition of 3-D objects" , Proc ICCV95, 563-568, 1995. [sent-259, score-0.63]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('color', 0.533), ('jlv', 0.279), ('shape', 0.236), ('object', 0.213), ('descendant', 0.186), ('ultrametric', 0.186), ('jl', 0.185), ('mrf', 0.182), ('energy', 0.174), ('prototypes', 0.172), ('spin', 0.172), ('hioj', 0.163), ('sg', 0.118), ('fields', 0.109), ('representations', 0.107), ('kernel', 0.105), ('ancestor', 0.101), ('hopfield', 0.101), ('recognition', 0.097), ('caputo', 0.081), ('match', 0.079), ('hs', 0.077), ('oj', 0.077), ('permits', 0.077), ('car', 0.074), ('argmaxp', 0.07), ('dorko', 0.07), ('esgmrf', 0.07), ('concatenated', 0.069), ('dj', 0.068), ('objects', 0.063), ('effectiveness', 0.062), ('classifier', 0.062), ('jij', 0.061), ('kernelized', 0.059), ('ran', 0.057), ('glasses', 0.055), ('classification', 0.052), ('benchmarked', 0.047), ('benchmarking', 0.047), ('mrfse', 0.047), ('niemann', 0.047), ('qjl', 0.047), ('views', 0.046), ('eq', 0.046), ('field', 0.046), ('representation', 0.045), ('combine', 0.043), ('experiments', 0.041), ('level', 0.041), ('ks', 0.04), ('kernels', 0.039), ('histograms', 0.038), ('image', 0.038), ('together', 0.037), ('yellow', 0.037), ('configurations', 0.037), ('kc', 0.037), ('classifies', 0.037), ('bayes', 0.036), ('presents', 0.035), ('hierarchy', 0.034), ('mechanics', 0.034), ('pj', 0.034), ('columbia', 0.032), ('table', 0.032), ('features', 0.031), ('define', 0.031), ('red', 0.03), ('fh', 0.028), ('ch', 0.028), ('pami', 0.028), ('random', 0.028), ('correctly', 0.028), ('common', 0.027), ('proc', 0.027), ('sites', 0.026), ('flexible', 0.026), ('samples', 0.026), ('hierarchical', 0.026), ('connection', 0.026), ('feature', 0.025), ('combined', 0.025), ('reader', 0.025), ('submitted', 0.025), ('combining', 0.025), ('chose', 0.024), ('store', 0.024), ('robust', 0.024), ('bin', 0.023), ('svm', 0.023), ('histogram', 0.022), ('stored', 0.022), ('si', 0.022), ('literature', 0.021), ('gibbs', 0.021), ('best', 0.021), ('multidimensional', 0.02), ('cars', 0.02), ('pip', 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000002 <a title="105-tfidf-1" href="./nips-2002-How_to_Combine_Color_and_Shape_Information_for_3D_Object_Recognition%3A_Kernels_do_the_Trick.html">105 nips-2002-How to Combine Color and Shape Information for 3D Object Recognition: Kernels do the Trick</a></p>
<p>Author: B. Caputo, Gy. Dorkó</p><p>Abstract: This paper presents a kernel method that allows to combine color and shape information for appearance-based object recognition. It doesn't require to define a new common representation, but use the power of kernels to combine different representations together in an effective manner. These results are achieved using results of statistical mechanics of spin glasses combined with Markov random fields via kernel functions. Experiments show an increase in recognition rate up to 5.92% with respect to conventional strategies. 1</p><p>2 0.42350176 <a title="105-tfidf-2" href="./nips-2002-Unsupervised_Color_Constancy.html">202 nips-2002-Unsupervised Color Constancy</a></p>
<p>Author: Kinh Tieu, Erik G. Miller</p><p>Abstract: In [1] we introduced a linear statistical model of joint color changes in images due to variation in lighting and certain non-geometric camera parameters. We did this by measuring the mappings of colors in one image of a scene to colors in another image of the same scene under different lighting conditions. Here we increase the ﬂexibility of this color ﬂow model by allowing ﬂow coefﬁcients to vary according to a low order polynomial over the image. This allows us to better ﬁt smoothly varying lighting conditions as well as curved surfaces without endowing our model with too much capacity. We show results on image matching and shadow removal and detection.</p><p>3 0.2135444 <a title="105-tfidf-3" href="./nips-2002-Morton-Style_Factorial_Coding_of_Color_in_Primary_Visual_Cortex.html">148 nips-2002-Morton-Style Factorial Coding of Color in Primary Visual Cortex</a></p>
<p>Author: Javier R. Movellan, Thomas Wachtler, Thomas D. Albright, Terrence Sejnowski</p><p>Abstract: We introduce the notion of Morton-style factorial coding and illustrate how it may help understand information integration and perceptual coding in the brain. We show that by focusing on average responses one may miss the existence of factorial coding mechanisms that become only apparent when analyzing spike count histograms. We show evidence suggesting that the classical/non-classical receptive ﬁeld organization in the cortex effectively enforces the development of Morton-style factorial codes. This may provide some cues to help understand perceptual coding in the brain and to develop new unsupervised learning algorithms. While methods like ICA (Bell & Sejnowski, 1997) develop independent codes, in Morton-style coding the goal is to make two or more external aspects of the world become independent when conditioning on internal representations. In this paper we introduce the notion of Morton-style factorial coding and illustrate how it may help analyze information integration and perceptual organization in the brain. In the neurosciences factorial codes are often studied in the context of mean tuning curves. A tuning curve is called separable if it can be expressed as the product of terms selectively inﬂuenced by different stimulus dimensions. Separable tuning curves are taken as evidence of factorial coding mechanisms. In this paper we show that by focusing on average responses one may miss the existence of factorial coding mechanisms that become only apparent when analyzing spike count histograms. Morton (1969) analyzed a wide variety of psychophysical experiments on word perception and showed that they could be explained using a model in which stimulus and context have separable effects on perception. More precisely, in Mortons’ model the joint effect of stimulus and context on a perceptual representation can be obtained by multiplying terms selectively controlled by stimulus and by context, i.e.,  £ © # #</p><p>4 0.16581564 <a title="105-tfidf-4" href="./nips-2002-Recovering_Intrinsic_Images_from_a_Single_Image.html">173 nips-2002-Recovering Intrinsic Images from a Single Image</a></p>
<p>Author: Marshall F. Tappen, William T. Freeman, Edward H. Adelson</p><p>Abstract: We present an algorithm that uses multiple cues to recover shading and reﬂectance intrinsic images from a single image. Using both color information and a classiﬁer trained to recognize gray-scale patterns, each image derivative is classiﬁed as being caused by shading or a change in the surface’s reﬂectance. Generalized Belief Propagation is then used to propagate information from areas where the correct classiﬁcation is clear to areas where it is ambiguous. We also show results on real images.</p><p>5 0.15152723 <a title="105-tfidf-5" href="./nips-2002-Shape_Recipes%3A_Scene_Representations_that_Refer_to_the_Image.html">182 nips-2002-Shape Recipes: Scene Representations that Refer to the Image</a></p>
<p>Author: William T. Freeman, Antonio Torralba</p><p>Abstract: The goal of low-level vision is to estimate an underlying scene, given an observed image. Real-world scenes (eg, albedos or shapes) can be very complex, conventionally requiring high dimensional representations which are hard to estimate and store. We propose a low-dimensional representation, called a scene recipe, that relies on the image itself to describe the complex scene conﬁgurations. Shape recipes are an example: these are the regression coefﬁcients that predict the bandpassed shape from image data. We describe the beneﬁts of this representation, and show two uses illustrating their properties: (1) we improve stereo shape estimates by learning shape recipes at low resolution and applying them at full resolution; (2) Shape recipes implicitly contain information about lighting and materials and we use them for material segmentation.</p><p>6 0.1269398 <a title="105-tfidf-6" href="./nips-2002-Concurrent_Object_Recognition_and_Segmentation_by_Graph_Partitioning.html">57 nips-2002-Concurrent Object Recognition and Segmentation by Graph Partitioning</a></p>
<p>7 0.10580026 <a title="105-tfidf-7" href="./nips-2002-Margin_Analysis_of_the_LVQ_Algorithm.html">140 nips-2002-Margin Analysis of the LVQ Algorithm</a></p>
<p>8 0.098668769 <a title="105-tfidf-8" href="./nips-2002-Learning_About_Multiple_Objects_in_Images%3A_Factorial_Learning_without_Factorial_Search.html">122 nips-2002-Learning About Multiple Objects in Images: Factorial Learning without Factorial Search</a></p>
<p>9 0.092577547 <a title="105-tfidf-9" href="./nips-2002-Self_Supervised_Boosting.html">181 nips-2002-Self Supervised Boosting</a></p>
<p>10 0.09117303 <a title="105-tfidf-10" href="./nips-2002-Kernel_Dependency_Estimation.html">119 nips-2002-Kernel Dependency Estimation</a></p>
<p>11 0.078529067 <a title="105-tfidf-11" href="./nips-2002-Cluster_Kernels_for_Semi-Supervised_Learning.html">52 nips-2002-Cluster Kernels for Semi-Supervised Learning</a></p>
<p>12 0.075978078 <a title="105-tfidf-12" href="./nips-2002-Visual_Development_Aids_the_Acquisition_of_Motion_Velocity_Sensitivities.html">206 nips-2002-Visual Development Aids the Acquisition of Motion Velocity Sensitivities</a></p>
<p>13 0.073256806 <a title="105-tfidf-13" href="./nips-2002-Kernel_Design_Using_Boosting.html">120 nips-2002-Kernel Design Using Boosting</a></p>
<p>14 0.070875958 <a title="105-tfidf-14" href="./nips-2002-On_the_Complexity_of_Learning_the_Kernel_Matrix.html">156 nips-2002-On the Complexity of Learning the Kernel Matrix</a></p>
<p>15 0.061946698 <a title="105-tfidf-15" href="./nips-2002-Rate_Distortion_Function_in_the_Spin_Glass_State%3A_A_Toy_Model.html">166 nips-2002-Rate Distortion Function in the Spin Glass State: A Toy Model</a></p>
<p>16 0.059859198 <a title="105-tfidf-16" href="./nips-2002-Spikernels%3A_Embedding_Spiking_Neurons_in_Inner-Product_Spaces.html">187 nips-2002-Spikernels: Embedding Spiking Neurons in Inner-Product Spaces</a></p>
<p>17 0.05967382 <a title="105-tfidf-17" href="./nips-2002-A_Model_for_Learning_Variance_Components_of_Natural_Images.html">10 nips-2002-A Model for Learning Variance Components of Natural Images</a></p>
<p>18 0.059134498 <a title="105-tfidf-18" href="./nips-2002-Feature_Selection_and_Classification_on_Matrix_Data%3A_From_Large_Margins_to_Small_Covering_Numbers.html">88 nips-2002-Feature Selection and Classification on Matrix Data: From Large Margins to Small Covering Numbers</a></p>
<p>19 0.058411017 <a title="105-tfidf-19" href="./nips-2002-A_Bilinear_Model_for_Sparse_Coding.html">2 nips-2002-A Bilinear Model for Sparse Coding</a></p>
<p>20 0.056617524 <a title="105-tfidf-20" href="./nips-2002-Approximate_Inference_and_Protein-Folding.html">32 nips-2002-Approximate Inference and Protein-Folding</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2002_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.182), (1, -0.027), (2, 0.051), (3, 0.204), (4, -0.033), (5, -0.14), (6, 0.266), (7, 0.011), (8, -0.092), (9, -0.082), (10, -0.086), (11, -0.014), (12, -0.15), (13, -0.148), (14, -0.128), (15, -0.225), (16, -0.315), (17, -0.093), (18, 0.015), (19, -0.163), (20, 0.206), (21, -0.071), (22, 0.066), (23, -0.09), (24, -0.131), (25, -0.15), (26, 0.058), (27, 0.05), (28, -0.019), (29, -0.054), (30, -0.045), (31, 0.084), (32, 0.08), (33, -0.022), (34, -0.059), (35, 0.031), (36, -0.005), (37, 0.104), (38, 0.032), (39, 0.049), (40, 0.063), (41, 0.015), (42, -0.005), (43, 0.022), (44, -0.02), (45, 0.043), (46, -0.097), (47, 0.073), (48, -0.032), (49, -0.005)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95758867 <a title="105-lsi-1" href="./nips-2002-How_to_Combine_Color_and_Shape_Information_for_3D_Object_Recognition%3A_Kernels_do_the_Trick.html">105 nips-2002-How to Combine Color and Shape Information for 3D Object Recognition: Kernels do the Trick</a></p>
<p>Author: B. Caputo, Gy. Dorkó</p><p>Abstract: This paper presents a kernel method that allows to combine color and shape information for appearance-based object recognition. It doesn't require to define a new common representation, but use the power of kernels to combine different representations together in an effective manner. These results are achieved using results of statistical mechanics of spin glasses combined with Markov random fields via kernel functions. Experiments show an increase in recognition rate up to 5.92% with respect to conventional strategies. 1</p><p>2 0.78779364 <a title="105-lsi-2" href="./nips-2002-Unsupervised_Color_Constancy.html">202 nips-2002-Unsupervised Color Constancy</a></p>
<p>Author: Kinh Tieu, Erik G. Miller</p><p>Abstract: In [1] we introduced a linear statistical model of joint color changes in images due to variation in lighting and certain non-geometric camera parameters. We did this by measuring the mappings of colors in one image of a scene to colors in another image of the same scene under different lighting conditions. Here we increase the ﬂexibility of this color ﬂow model by allowing ﬂow coefﬁcients to vary according to a low order polynomial over the image. This allows us to better ﬁt smoothly varying lighting conditions as well as curved surfaces without endowing our model with too much capacity. We show results on image matching and shadow removal and detection.</p><p>3 0.54176581 <a title="105-lsi-3" href="./nips-2002-Recovering_Intrinsic_Images_from_a_Single_Image.html">173 nips-2002-Recovering Intrinsic Images from a Single Image</a></p>
<p>Author: Marshall F. Tappen, William T. Freeman, Edward H. Adelson</p><p>Abstract: We present an algorithm that uses multiple cues to recover shading and reﬂectance intrinsic images from a single image. Using both color information and a classiﬁer trained to recognize gray-scale patterns, each image derivative is classiﬁed as being caused by shading or a change in the surface’s reﬂectance. Generalized Belief Propagation is then used to propagate information from areas where the correct classiﬁcation is clear to areas where it is ambiguous. We also show results on real images.</p><p>4 0.50666904 <a title="105-lsi-4" href="./nips-2002-Shape_Recipes%3A_Scene_Representations_that_Refer_to_the_Image.html">182 nips-2002-Shape Recipes: Scene Representations that Refer to the Image</a></p>
<p>Author: William T. Freeman, Antonio Torralba</p><p>Abstract: The goal of low-level vision is to estimate an underlying scene, given an observed image. Real-world scenes (eg, albedos or shapes) can be very complex, conventionally requiring high dimensional representations which are hard to estimate and store. We propose a low-dimensional representation, called a scene recipe, that relies on the image itself to describe the complex scene conﬁgurations. Shape recipes are an example: these are the regression coefﬁcients that predict the bandpassed shape from image data. We describe the beneﬁts of this representation, and show two uses illustrating their properties: (1) we improve stereo shape estimates by learning shape recipes at low resolution and applying them at full resolution; (2) Shape recipes implicitly contain information about lighting and materials and we use them for material segmentation.</p><p>5 0.48437572 <a title="105-lsi-5" href="./nips-2002-Morton-Style_Factorial_Coding_of_Color_in_Primary_Visual_Cortex.html">148 nips-2002-Morton-Style Factorial Coding of Color in Primary Visual Cortex</a></p>
<p>Author: Javier R. Movellan, Thomas Wachtler, Thomas D. Albright, Terrence Sejnowski</p><p>Abstract: We introduce the notion of Morton-style factorial coding and illustrate how it may help understand information integration and perceptual coding in the brain. We show that by focusing on average responses one may miss the existence of factorial coding mechanisms that become only apparent when analyzing spike count histograms. We show evidence suggesting that the classical/non-classical receptive ﬁeld organization in the cortex effectively enforces the development of Morton-style factorial codes. This may provide some cues to help understand perceptual coding in the brain and to develop new unsupervised learning algorithms. While methods like ICA (Bell & Sejnowski, 1997) develop independent codes, in Morton-style coding the goal is to make two or more external aspects of the world become independent when conditioning on internal representations. In this paper we introduce the notion of Morton-style factorial coding and illustrate how it may help analyze information integration and perceptual organization in the brain. In the neurosciences factorial codes are often studied in the context of mean tuning curves. A tuning curve is called separable if it can be expressed as the product of terms selectively inﬂuenced by different stimulus dimensions. Separable tuning curves are taken as evidence of factorial coding mechanisms. In this paper we show that by focusing on average responses one may miss the existence of factorial coding mechanisms that become only apparent when analyzing spike count histograms. Morton (1969) analyzed a wide variety of psychophysical experiments on word perception and showed that they could be explained using a model in which stimulus and context have separable effects on perception. More precisely, in Mortons’ model the joint effect of stimulus and context on a perceptual representation can be obtained by multiplying terms selectively controlled by stimulus and by context, i.e.,  £ © # #</p><p>6 0.31737027 <a title="105-lsi-6" href="./nips-2002-Learning_About_Multiple_Objects_in_Images%3A_Factorial_Learning_without_Factorial_Search.html">122 nips-2002-Learning About Multiple Objects in Images: Factorial Learning without Factorial Search</a></p>
<p>7 0.283678 <a title="105-lsi-7" href="./nips-2002-Kernel_Dependency_Estimation.html">119 nips-2002-Kernel Dependency Estimation</a></p>
<p>8 0.27165911 <a title="105-lsi-8" href="./nips-2002-Concurrent_Object_Recognition_and_Segmentation_by_Graph_Partitioning.html">57 nips-2002-Concurrent Object Recognition and Segmentation by Graph Partitioning</a></p>
<p>9 0.2569465 <a title="105-lsi-9" href="./nips-2002-Stochastic_Neighbor_Embedding.html">190 nips-2002-Stochastic Neighbor Embedding</a></p>
<p>10 0.253849 <a title="105-lsi-10" href="./nips-2002-Multiple_Cause_Vector_Quantization.html">150 nips-2002-Multiple Cause Vector Quantization</a></p>
<p>11 0.24059033 <a title="105-lsi-11" href="./nips-2002-One-Class_LP_Classifiers_for_Dissimilarity_Representations.html">158 nips-2002-One-Class LP Classifiers for Dissimilarity Representations</a></p>
<p>12 0.20960137 <a title="105-lsi-12" href="./nips-2002-Rational_Kernels.html">167 nips-2002-Rational Kernels</a></p>
<p>13 0.20298098 <a title="105-lsi-13" href="./nips-2002-Margin_Analysis_of_the_LVQ_Algorithm.html">140 nips-2002-Margin Analysis of the LVQ Algorithm</a></p>
<p>14 0.20238599 <a title="105-lsi-14" href="./nips-2002-Hyperkernels.html">106 nips-2002-Hyperkernels</a></p>
<p>15 0.19382221 <a title="105-lsi-15" href="./nips-2002-Identity_Uncertainty_and_Citation_Matching.html">107 nips-2002-Identity Uncertainty and Citation Matching</a></p>
<p>16 0.19089654 <a title="105-lsi-16" href="./nips-2002-Spikernels%3A_Embedding_Spiking_Neurons_in_Inner-Product_Spaces.html">187 nips-2002-Spikernels: Embedding Spiking Neurons in Inner-Product Spaces</a></p>
<p>17 0.1908745 <a title="105-lsi-17" href="./nips-2002-Self_Supervised_Boosting.html">181 nips-2002-Self Supervised Boosting</a></p>
<p>18 0.1874752 <a title="105-lsi-18" href="./nips-2002-A_Hierarchical_Bayesian_Markovian_Model_for_Motifs_in_Biopolymer_Sequences.html">7 nips-2002-A Hierarchical Bayesian Markovian Model for Motifs in Biopolymer Sequences</a></p>
<p>19 0.18717137 <a title="105-lsi-19" href="./nips-2002-Cluster_Kernels_for_Semi-Supervised_Learning.html">52 nips-2002-Cluster Kernels for Semi-Supervised Learning</a></p>
<p>20 0.18275288 <a title="105-lsi-20" href="./nips-2002-Visual_Development_Aids_the_Acquisition_of_Motion_Velocity_Sensitivities.html">206 nips-2002-Visual Development Aids the Acquisition of Motion Velocity Sensitivities</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2002_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(3, 0.018), (11, 0.028), (23, 0.02), (25, 0.359), (42, 0.058), (54, 0.114), (55, 0.033), (67, 0.027), (68, 0.015), (74, 0.123), (92, 0.035), (98, 0.065)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.74340731 <a title="105-lda-1" href="./nips-2002-How_to_Combine_Color_and_Shape_Information_for_3D_Object_Recognition%3A_Kernels_do_the_Trick.html">105 nips-2002-How to Combine Color and Shape Information for 3D Object Recognition: Kernels do the Trick</a></p>
<p>Author: B. Caputo, Gy. Dorkó</p><p>Abstract: This paper presents a kernel method that allows to combine color and shape information for appearance-based object recognition. It doesn't require to define a new common representation, but use the power of kernels to combine different representations together in an effective manner. These results are achieved using results of statistical mechanics of spin glasses combined with Markov random fields via kernel functions. Experiments show an increase in recognition rate up to 5.92% with respect to conventional strategies. 1</p><p>2 0.67617816 <a title="105-lda-2" href="./nips-2002-Source_Separation_with_a_Sensor_Array_using_Graphical_Models_and_Subband_Filtering.html">183 nips-2002-Source Separation with a Sensor Array using Graphical Models and Subband Filtering</a></p>
<p>Author: Hagai Attias</p><p>Abstract: Source separation is an important problem at the intersection of several ﬁelds, including machine learning, signal processing, and speech technology. Here we describe new separation algorithms which are based on probabilistic graphical models with latent variables. In contrast with existing methods, these algorithms exploit detailed models to describe source properties. They also use subband ﬁltering ideas to model the reverberant environment, and employ an explicit model for background and sensor noise. We leverage variational techniques to keep the computational complexity per EM iteration linear in the number of frames. 1 The Source Separation Problem Fig. 1 illustrates the problem of source separation with a sensor array. In this problem, signals from K independent sources are received by each of L ≥ K sensors. The task is to extract the sources from the sensor signals. It is a difﬁcult task, partly because the received signals are distorted versions of the originals. There are two types of distortions. The ﬁrst type arises from propagation through a medium, and is approximately linear but also history dependent. This type is usually termed reverberations. The second type arises from background noise and sensor noise, which are assumed additive. Hence, the actual task is to obtain an optimal estimate of the sources from data. The task is difﬁcult for another reason, which is lack of advance knowledge of the properties of the sources, the propagation medium, and the noises. This difﬁculty gave rise to adaptive source separation algorithms, where parameters that are related to those properties are adjusted to optimized a chosen cost function. Unfortunately, the intense activity this problem has attracted over the last several years [1–9] has not yet produced a satisfactory solution. In our opinion, the reason is that existing techniques fail to address three major factors. The ﬁrst is noise robustness: algorithms typically ignore background and sensor noise, sometime assuming they may be treated as additional sources. It seems plausible that to produce a noise robust algorithm, noise signals and their properties must be modeled explicitly, and these models should be exploited to compute optimal source estimators. The second factor is mixing ﬁlters: algorithms typically seek, and directly optimize, a transformation that would unmix the sources. However, in many situations, the ﬁlters describing medium propagation are non-invertible, or have an unstable inverse, or have a stable inverse that is extremely long. It may hence be advantageous to Figure 1: The source separation problem. Signals from K = 2 speakers propagate toward L = 2 sensors. Each sensor receives a linear mixture of the speaker signals, distorted by multipath propagation, medium response, and background and sensor noise. The task is to infer the original signals from sensor data. estimate the mixing ﬁlters themselves, then use them to estimate the sources. The third factor is source properties: algorithms typically use a very simple source model (e.g., a one time point histogram). But in many cases one may easily obtain detailed models of the source signals. This is particularly true for speech sources, where large datasets exist and much modeling expertise has developed over decades of research. Separation of speakers is also one of the major potential commercial applications of source separation algorithms. It seems plausible that incorporating strong source models could improve performance. Such models may potentially have two more advantages: ﬁrst, they could help limit the range of possible mixing ﬁlters by constraining the optimization problem. Second, they could help avoid whitening the extracted signals by effectively limiting their spectral range to the range characteristic of the source model. This paper makes several contributions to the problem of real world source separation. In the following, we present new separation algorithms that are the ﬁrst to address all three factors. We work in the framework of probabilistic graphical models. This framework allows us to construct models for sources and for noise, combine them with the reverberant mixing transformation in a principled manner, and compute parameter and source estimates from data which are Bayes optimal. We identify three technical ideas that are key to our approach: (1) a strong speech model, (2) subband ﬁltering, and (3) variational EM. 2 Frames, Subband Signals, and Subband Filtering We start with the concept of subband ﬁltering. This is also a good point to deﬁne our notation. Let xm denote a time domain signal, e.g., the value of a sound pressure waveform at time point m = 0, 1, 2, .... Let Xn [k] denote the corresponding subband signal at time frame n and subband frequency k. The subband signals are obtained from the time domain signal by imposing an N -point window wm , m = 0 : N − 1 on that signal at equally spaced points nJ, n = 0, 1, 2, ..., and FFT-ing the windowed signal, N −1 e−iωk m wm xnJ+m , Xn [k] = (1) m=0 where ωk = 2πk/N and k = 0 : N − 1. The subband signals are also termed frames. Notice the difference in time scale between the time frame index n in Xn [k] and the time point index n in xn . The chosen value of the spacing J depends on the window length N . For J ≤ N the original signal xm can be synthesized exactly from the subband signals (synthesis formula omitted). An important consideration for selecting J, as well as the window shape, is behavior under ﬁltering. Consider a ﬁlter hm applied to xm , and denote by ym the ﬁltered signal. In the simple case hm = hδm,0 (no ﬁltering), the subband signals keep the same dependence as the time domain ones, yn = hxn −→ Yn [k] = hXn [k] . For an arbitrary ﬁlter hm , we use the relation yn = hm xn−m −→ Yn [k] = Hm [k]Xn−m [k] , (2) m m with complex coefﬁcients Hm [k] for each k. This relation between the subband signals is termed subband ﬁltering, and the Hm [k] are termed subband ﬁlters. Unlike the simple case of non-ﬁltering, the relation (2) holds approximately, but quite accurately using an appropriate choice of J and wm ; see [13] for details on accuracy. Throughout this paper, we will assume that an arbitrary ﬁlter hm can be modeled by the subband ﬁlters Hm [k] to a sufﬁcient accuracy for our purposes. One advantage of subband ﬁltering is that it replaces a long ﬁlter hm by a set of short independent ﬁlters Hm [k], one per frequency. This will turn out to decompose the source separation problem into a set of small (albeit coupled) problems, one per frequency. Another advantage is that this representation allows using a detailed speech model on the same footing with the ﬁlter model. This is because a speech model is deﬁned on the time scale of a single frame, whereas the original ﬁlter hm , in contrast with Hm [k], is typically as long as 10 or more frames. As a ﬁnal point on notation, we deﬁne a Gaussian distribution over a complex number Z ν by p(Z) = N (Z | µ, ν) = π exp(−ν | Z − µ |2 ) . Notice that this is a joint distribution over the real and imaginary parts of Z. The mean is µ = X and the precision (inverse variance) ν satisﬁes ν −1 = | X |2 − | µ |2 . 3 A Model for Speech Signals We assume independent sources, and model the distribution of source j by a mixture model over its subband signals Xjn , N/2−1 p(Xjn | Sjn = s) N (Xjn [k] | 0, Ajs [k]) = p(Sjn = s) = πjs k=1 p(X, S) p(Xjn | Sjn )p(Sjn ) , = (3) jn where the components are labeled by Sjn . Component s of source j is a zero mean Gaussian with precision Ajs . The mixing proportions of source j are πjs . The DAG representing this model is shown in Fig. 2. A similar model was used in [10] for one microphone speech enhancement for recognition (see also [11]). Here are several things to note about this model. (1) Each component has a characteristic spectrum, which may describe a particular part of a speech phoneme. This is because the precision corresponds to the inverse spectrum: the mean energy (w.r.t. the above distribution) of source j at frequency k, conditioned on label s, is | Xjn |2 = A−1 . (2) js A zero mean model is appropriate given the physics of the problem, since the mean of a sound pressure waveform is zero. (3) k runs from 1 to N/2 − 1, since for k > N/2, Xjn [k] = Xjn [N − k] ; the subbands k = 0, N/2 are real and are omitted from the model, a common practice in speech recognition engines. (4) Perhaps most importantly, for each source the subband signals are correlated via the component label s, as p(Xjn ) = s p(Xjn , Sjn = s) = k p(Xjn [k]) . Hence, when the source separation problem decomposes into one problem per frequency, these problems turn out to be coupled (see below), and independent frequency permutations are avoided. (5) To increase sn xn Figure 2: Graphical model describing speech signals in the subband domain. The model assumes i.i.d. frames; only the frame at time n is shown. The node Xn represents a complex N/2 − 1-dimensional vector Xn [k], k = 1 : N/2 − 1. model accuracy, a state transition matrix p(Sjn = s | Sj,n−1 = s ) may be added for each source. The resulting HMM models are straightforward to incorporate without increasing the algorithm complexity. There are several modes of using the speech model in the algorithms below. In one mode, the sources are trained online using the sensor data. In a second mode, source models are trained ofﬂine using available data on each source in the problem. A third mode correspond to separation of sources known to be speech but whose speakers are unknown. In this case, all sources have the same model, which is trained ofﬂine on a large dataset of speech signals, including 150 male and female speakers reading sentences from the Wall Street Journal (see [10] for details). This is the case presented in this paper. The training algorithm used was standard EM (omitted) using 256 clusters, initialized by vector quantization. 4 Separation of Non-Reverberant Mixtures We now present a source separation algorithm for the case of non-reverberant (or instantaneous) mixing. Whereas many algorithms exist for this case, our contribution here is an algorithm that is signiﬁcantly more robust to noise. Its robustness results, as indicated in the introduction, from three factors: (1) explicitly modeling the noise in the problem, (2) using a strong source model, in particular modeling the temporal statistics (over N time points) of the sources, rather than one time point statistics, and (3) extracting each source signal from data by a Bayes optimal estimator obtained from p(X | Y ). A more minor point is handling the case of less sources than sensors in a principled way. The mixing situation is described by yin = j hij xjn + uin , where xjn is source signal j at time point n, yin is sensor signal i, hij is the instantaneous mixing matrix, and uin is the noise corrupting sensor i’s signal. The corresponding subband signals satisfy Yin [k] = j hij Xjn [k] + Uin [k] . To turn the last equation into a probabilistic graphical model, we assume that noise i has precision (inverse spectrum) Bi [k], and that noises at different sensors are independent (the latter assumption is often inaccurate but can be easily relaxed). This yields p(Yin | X) N (Yin [k] | = p(Y | X) p(Yin | X) , = hij Xjn [k], Bi [k]) j k (4) in which together with the speech model (3) forms a complete model p(Y, X, S) for this problem. The DAG representing this model for the case K = L = 2 is shown in Fig. 3. Notice that this model generalizes [4] to the subband domain. s1n−2 s1n−1 s1 n s2n−2 s2n−1 s2 n x1n−2 x1n−1 x1 n x2n−2 x2n−1 x2 n y1n−2 y1n−1 y1n y2n−2 y2n−1 y2 n Figure 3: Graphical model for noisy, non-reverberant 2 × 2 mixing, showing a 3 frame-long sequence. All nodes Yin and Xjn represent complex N/2 − 1-dimensional vectors (see Fig. 2). While Y1n and Y2n have the same parents, X1n and X2n , the arcs from the parents to Y2n are omitted for clarity. The model parameters θ = {hij , Bi [k], Ajs [k], πjs } are estimated from data by an EM algorithm. However, as the number of speech components M or the number of sources K increases, the E-step becomes computationally intractable, as it requires summing over all O(M K ) conﬁgurations of (S1n , ..., SKn ) at each frame. We approximate the E-step using a variational technique: focusing on the posterior distribution p(X, S | Y ), we compute an optimal tractable approximation q(X, S | Y ) ≈ p(X, S | Y ), which we use to compute the sufﬁcient statistics (SS). We choose q(Xjn | Sjn , Y )q(Sjn | Y ) , q(X, S | Y ) = (5) jn where the hidden variables are factorized over the sources, and also over the frames (the latter factorization is exact in this model, but is an approximation for reverberant mixing). This posterior maintains the dependence of X on S, and thus the correlations between different subbands Xjn [k]. Notice also that this posterior implies a multimodal q(Xjn ) (i.e., a mixture distribution), which is more accurate than unimodal posteriors often employed in variational approximations (e.g., [12]), but is also harder to compute. A slightly more general form which allows inter-frame correlations by employing q(S | Y ) = jn q(Sjn | Sj,n−1 , Y ) may also be used, without increasing complexity. By optimizing in the usual way (see [12,13]) a lower bound on the likelihood w.r.t. q, we obtain q(Xjn [k] | Sjn = s, Y )q(Sjn = s | Y ) , q(Xjn , Sjn = s | Y ) = (6) k where q(Xjn [k] | Sjn = s, Y ) = N (Xjn [k] | ρjns [k], νjs [k]) and q(Sjn = s | Y ) = γjns . Both the factorization over k of q(Xjn | Sjn ) and its Gaussian functional form fall out from the optimization under the structural restriction (5) and need not be speciﬁed in advance. The variational parameters {ρjns [k], νjs [k], γjns }, which depend on the data Y , constitute the SS and are computed in the E-step. The DAG representing this posterior is shown in Fig. 4. s1n−2 s1n−1 s1 n s2n−2 s2n−1 s2 n x1n−2 x1n−1 x1 n x2n−2 x2n−1 x2 n {y im } Figure 4: Graphical model describing the variational posterior distribution applied to the model of Fig. 3. In the non-reverberant case, the components of this posterior at time frame n are conditioned only on the data Yin at that frame; in the reverberant case, the components at frame n are conditioned on the data Yim at all frames m. For clarity and space reasons, this distinction is not made in the ﬁgure. After learning, the sources are extracted from data by a variational approximation of the minimum mean squared error estimator, ˆ Xjn [k] = E(Xjn [k] | Y ) = dX q(X | Y )Xjn [k] , (7) i.e., the posterior mean, where q(X | Y ) = S q(X, S | Y ). The time domain waveform xjm is then obtained by appropriately patching together the subband signals. ˆ M-step. The update rule for the mixing matrix hij is obtained by solving the linear equation Bi [k]ηij,0 [k] = hij j k Bi [k]λj j,0 [k] . (8) k The update rule for the noise precisions Bi [k] is omitted. The quantities ηij,m [k] and λj j,m [k] are computed from the SS; see [13] for details. E-step. The posterior means of the sources (7) are obtained by solving   ˆ Xjn [k] = νjn [k]−1 ˆ i Bi [k]hij Yin [k] − j =j ˆ hij Xj n [k] (9) ˆ for Xjn [k], which is a K ×K linear system for each frequency k and frame n. The equations for the SS are given in [13], which also describes experimental results. 5 Separation of Reverberant Mixtures In this section we extend the algorithm to the case of reverberant mixing. In that case, due to signal propagation in the medium, each sensor signal at time frame n depends on the source signals not just at the same time but also at previous times. To describe this mathematically, the mixing matrix hij must become a matrix of ﬁlters hij,m , and yin = hij,m xj,n−m + uin . jm It may seem straightforward to extend the algorithm derived above to the present case. However, this appearance is misleading, because we have a time scale problem. Whereas are speech model p(X, S) is frame based, the ﬁlters hij,m are generally longer than the frame length N , typically 10 frames long and sometime longer. It is unclear how one can work with both Xjn and hij,m on the same footing (and, it is easy to see that straightforward windowed FFT cannot solve this problem). This is where the idea of subband ﬁltering becomes very useful. Using (2) we have Yin [k] = Hij,m [k]Xj,n−m [k] + Uin [k], which yields the probabilistic model jm p(Yin | X) N (Yin [k] | = Hij,m [k]Xj,n−m [k], Bi [k]) . (10) jm k Hence, both X and Y are now frame based. Combining this equation with the speech model (3), we now have a complete model p(Y, X, S) for the reverberant mixing problem. The DAG describing this model is shown in Fig. 5. s1n−2 s1n−1 s1 n s2n−2 s2n−1 s2 n x1n−2 x1n−1 x1 n x2n−2 x2n−1 x2 n y1n−2 y1n−1 y1n y2n−2 y2n−1 y2 n Figure 5: Graphical model for noisy, reverberant 2 × 2 mixing, showing a 3 frame-long sequence. Here we assume 2 frame-long ﬁlters, i.e., m = 0, 1 in Eq. (10), where the solid arcs from X to Y correspond to m = 0 (as in Fig. 3) and the dashed arcs to m = 1. While Y1n and Y2n have the same parents, X1n and X2n , the arcs from the parents to Y2n are omitted for clarity. The model parameters θ = {Hij,m [k], Bi [k], Ajs [k], πjs } are estimated from data by a variational EM algorithm, whose derivation generally follows the one outlined in the previous section. Notice that the exact E-step here is even more intractable, due to the history dependence introduced by the ﬁlters. M-step. The update rule for Hij,m is obtained by solving the Toeplitz system Hij ,m [k]λj j,m−m [k] = ηij,m [k] (11) j m where the quantities λj j,m [k], ηij,m [k] are computed from the SS (see [12]). The update rule for the Bi [k] is omitted. E-step. The posterior means of the sources (7) are obtained by solving  ˆ Xjn [k] = νjn [k]−1 ˆ im Bi [k]Hij,m−n [k] Yim [k] − Hij j m =jm ,m−m ˆ [k]Xj m  [k] (12) ˆ for Xjn [k]. Assuming P frames long ﬁlters Hij,m , m = 0 : P − 1, this is a KP × KP linear system for each frequency k. The equations for the SS are given in [13], which also describes experimental results. 6 Extensions An alternative technique we have been pursuing for approximating EM in our models is Sequential Rao-Blackwellized Monte Carlo. There, we sample state sequences S from the posterior p(S | Y ) and, for a given sequence, perform exact inference on the source signals X conditioned on that sequence (observe that given S, the posterior p(X | S, Y ) is Gaussian and can be computed exactly). In addition, we are extending our speech model to include features such as pitch [7] in order to improve separation performance, especially in cases with less sensors than sources [7–9]. Yet another extension is applying model selection techniques to infer the number of sources from data in a dynamic manner. Acknowledgments I thank Te-Won Lee for extremely valuable discussions. References [1] A.J. Bell, T.J. Sejnowski (1995). An information maximisation approach to blind separation and blind deconvolution. Neural Computation 7, 1129-1159. [2] B.A. Pearlmutter, L.C. Parra (1997). Maximum likelihood blind source separation: A contextsensitive generalization of ICA. Proc. NIPS-96. [3] A. Cichocki, S.-I. Amari (2002). Adaptive Blind Signal and Image Processing. Wiley. [4] H. Attias (1999). Independent Factor Analysis. Neural Computation 11, 803-851. [5] T.-W. Lee et al. (2001) (Ed.). Proc. ICA 2001. [6] S. Griebel, M. Brandstein (2001). Microphone array speech dereverberation using coarse channel modeling. Proc. ICASSP 2001. [7] J. Hershey, M. Casey (2002). Audiovisual source separation via hidden Markov models. Proc. NIPS 2001. [8] S. Roweis (2001). One Microphone Source Separation. Proc. NIPS-00, 793-799. [9] G.-J. Jang, T.-W. Lee, Y.-H. Oh (2003). A probabilistic approach to single channel blind signal separation. Proc. NIPS 2002. [10] H. Attias, L. Deng, A. Acero, J.C. Platt (2001). A new method for speech denoising using probabilistic models for clean speech and for noise. Proc. Eurospeech 2001. [11] Ephraim, Y. (1992). Statistical model based speech enhancement systems. Proc. IEEE 80(10), 1526-1555. [12] M.I. Jordan, Z. Ghahramani, T.S. Jaakkola, L.K. Saul (1999). An introduction to variational methods in graphical models. Machine Learning 37, 183-233. [13] H. Attias (2003). New EM algorithms for source separation and deconvolution with a microphone array. Proc. ICASSP 2003.</p><p>3 0.46733534 <a title="105-lda-3" href="./nips-2002-Reinforcement_Learning_to_Play_an_Optimal_Nash_Equilibrium_in_Team_Markov_Games.html">175 nips-2002-Reinforcement Learning to Play an Optimal Nash Equilibrium in Team Markov Games</a></p>
<p>Author: Xiaofeng Wang, Tuomas Sandholm</p><p>Abstract: Multiagent learning is a key problem in AI. In the presence of multiple Nash equilibria, even agents with non-conﬂicting interests may not be able to learn an optimal coordination policy. The problem is exaccerbated if the agents do not know the game and independently receive noisy payoffs. So, multiagent reinforfcement learning involves two interrelated problems: identifying the game and learning to play. In this paper, we present optimal adaptive learning, the ﬁrst algorithm that converges to an optimal Nash equilibrium with probability 1 in any team Markov game. We provide a convergence proof, and show that the algorithm’s parameters are easy to set to meet the convergence conditions.</p><p>4 0.46281481 <a title="105-lda-4" href="./nips-2002-Cluster_Kernels_for_Semi-Supervised_Learning.html">52 nips-2002-Cluster Kernels for Semi-Supervised Learning</a></p>
<p>Author: Olivier Chapelle, Jason Weston, Bernhard SchĂślkopf</p><p>Abstract: We propose a framework to incorporate unlabeled data in kernel classifier, based on the idea that two points in the same cluster are more likely to have the same label. This is achieved by modifying the eigenspectrum of the kernel matrix. Experimental results assess the validity of this approach. 1</p><p>5 0.46183985 <a title="105-lda-5" href="./nips-2002-Dynamic_Structure_Super-Resolution.html">74 nips-2002-Dynamic Structure Super-Resolution</a></p>
<p>Author: Amos J. Storkey</p><p>Abstract: The problem of super-resolution involves generating feasible higher resolution images, which are pleasing to the eye and realistic, from a given low resolution image. This might be attempted by using simple ﬁlters for smoothing out the high resolution blocks or through applications where substantial prior information is used to imply the textures and shapes which will occur in the images. In this paper we describe an approach which lies between the two extremes. It is a generic unsupervised method which is usable in all domains, but goes beyond simple smoothing methods in what it achieves. We use a dynamic tree-like architecture to model the high resolution data. Approximate conditioning on the low resolution image is achieved through a mean ﬁeld approach. 1</p><p>6 0.4611719 <a title="105-lda-6" href="./nips-2002-Learning_to_Detect_Natural_Image_Boundaries_Using_Brightness_and_Texture.html">132 nips-2002-Learning to Detect Natural Image Boundaries Using Brightness and Texture</a></p>
<p>7 0.46100116 <a title="105-lda-7" href="./nips-2002-Bayesian_Image_Super-Resolution.html">39 nips-2002-Bayesian Image Super-Resolution</a></p>
<p>8 0.46043938 <a title="105-lda-8" href="./nips-2002-A_Bilinear_Model_for_Sparse_Coding.html">2 nips-2002-A Bilinear Model for Sparse Coding</a></p>
<p>9 0.45942867 <a title="105-lda-9" href="./nips-2002-Nash_Propagation_for_Loopy_Graphical_Games.html">152 nips-2002-Nash Propagation for Loopy Graphical Games</a></p>
<p>10 0.45884618 <a title="105-lda-10" href="./nips-2002-Learning_About_Multiple_Objects_in_Images%3A_Factorial_Learning_without_Factorial_Search.html">122 nips-2002-Learning About Multiple Objects in Images: Factorial Learning without Factorial Search</a></p>
<p>11 0.45798412 <a title="105-lda-11" href="./nips-2002-Parametric_Mixture_Models_for_Multi-Labeled_Text.html">162 nips-2002-Parametric Mixture Models for Multi-Labeled Text</a></p>
<p>12 0.45756143 <a title="105-lda-12" href="./nips-2002-Learning_Graphical_Models_with_Mercer_Kernels.html">124 nips-2002-Learning Graphical Models with Mercer Kernels</a></p>
<p>13 0.45715028 <a title="105-lda-13" href="./nips-2002-Feature_Selection_by_Maximum_Marginal_Diversity.html">89 nips-2002-Feature Selection by Maximum Marginal Diversity</a></p>
<p>14 0.45697045 <a title="105-lda-14" href="./nips-2002-A_Convergent_Form_of_Approximate_Policy_Iteration.html">3 nips-2002-A Convergent Form of Approximate Policy Iteration</a></p>
<p>15 0.45568898 <a title="105-lda-15" href="./nips-2002-Clustering_with_the_Fisher_Score.html">53 nips-2002-Clustering with the Fisher Score</a></p>
<p>16 0.45495328 <a title="105-lda-16" href="./nips-2002-An_Impossibility_Theorem_for_Clustering.html">27 nips-2002-An Impossibility Theorem for Clustering</a></p>
<p>17 0.45352903 <a title="105-lda-17" href="./nips-2002-Prediction_and_Semantic_Association.html">163 nips-2002-Prediction and Semantic Association</a></p>
<p>18 0.4531337 <a title="105-lda-18" href="./nips-2002-Learning_Sparse_Topographic_Representations_with_Products_of_Student-t_Distributions.html">127 nips-2002-Learning Sparse Topographic Representations with Products of Student-t Distributions</a></p>
<p>19 0.45176971 <a title="105-lda-19" href="./nips-2002-Feature_Selection_and_Classification_on_Matrix_Data%3A_From_Large_Margins_to_Small_Covering_Numbers.html">88 nips-2002-Feature Selection and Classification on Matrix Data: From Large Margins to Small Covering Numbers</a></p>
<p>20 0.45137408 <a title="105-lda-20" href="./nips-2002-Discriminative_Densities_from_Maximum_Contrast_Estimation.html">68 nips-2002-Discriminative Densities from Maximum Contrast Estimation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
