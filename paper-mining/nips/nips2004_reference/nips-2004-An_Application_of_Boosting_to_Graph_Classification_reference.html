<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>19 nips-2004-An Application of Boosting to Graph Classification</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2004" href="../home/nips2004_home.html">nips2004</a> <a title="nips-2004-19" href="../nips2004/nips-2004-An_Application_of_Boosting_to_Graph_Classification.html">nips2004-19</a> <a title="nips-2004-19-reference" href="#">nips2004-19-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>19 nips-2004-An Application of Boosting to Graph Classification</h1>
<br/><p>Source: <a title="nips-2004-19-pdf" href="http://papers.nips.cc/paper/2739-an-application-of-boosting-to-graph-classification.pdf">pdf</a></p><p>Author: Taku Kudo, Eisaku Maeda, Yuji Matsumoto</p><p>Abstract: This paper presents an application of Boosting for classifying labeled graphs, general structures for modeling a number of real-world data, such as chemical compounds, natural language texts, and bio sequences. The proposal consists of i) decision stumps that use subgraph as features, and ii) a Boosting algorithm in which subgraph-based decision stumps are used as weak learners. We also discuss the relation between our algorithm and SVMs with convolution kernels. Two experiments using natural language data and chemical compounds show that our method achieves comparable or even better performance than SVMs with convolution kernels as well as improves the testing efﬁciency. 1</p><br/>
<h2>reference text</h2><p>[1] Leo Breiman. Prediction games and arching algoritms. Neural Computation, 11(7):1493 – 1518, 1999.</p>
<p>[2] Michael Collins and Nigel Duffy. Convolution kernels for natural language. In NIPS 14, Vol.1, pages 625–632, 2001.</p>
<p>[3] Yoav Freund and Robert E. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of Computer and System Sicences, 55(1):119–139, 1996.</p>
<p>[4] David Haussler. Convolution kernels on discrete structures. Technical report, UC Santa Cruz (UCS-CRL-99-10), 1999.</p>
<p>[5] Hisashi Kashima and Teruo Koyanagi. Svm kernels for semi-structured data. In Proc. of ICML, pages 291–298, 2002.</p>
<p>[6] Hisashi Kashima, Koji Tsuda, and Akihiro Inokuchi. Marginalized kernels between labeled graphs. In Proc. of ICML, pages 321–328, 2003.</p>
<p>[7] Huma Lodhi, Craig Saunders, John Shawe-Taylor, Nello Cristianini, and Chris Watkins. Text classiﬁcation using string kernels. Journal of Machine Learning Research, 2, 2002. ¨</p>
<p>[8] Gunnar. R¨ tsch, Takashi. Onoda, and Klaus-Robert Muller. Soft margins for AdaBoost. Maa chine Learning, 42(3):287–320, 2001.</p>
<p>[9] Robert E. Schapire, Yoav Freund, Peter Bartlett, and Wee Sun Lee. Boosting the margin: a new explanation for the effectiveness of voting methods. In Proc. of ICML, pages 322–330, 1997.</p>
<p>[10] Robert E. Schapire and Yoram Singer. BoosTexter: A boosting-based system for text categorization. Machine Learning, 39(2/3):135–168, 2000.</p>
<p>[11] Vladimir N. Vapnik. Statistical Learning Theory. Wiley-Interscience, 1998.</p>
<p>[12] Xifeng Yan and Jiawei Han. gspan: Graph-based substructure pattern mining. In Proc. of ICDM, pages 721–724, 2002. 6  We tested the performances on Linux with XEON 2.4Ghz dual processors.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
