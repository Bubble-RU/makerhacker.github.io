<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>133 nips-2004-Nonparametric Transforms of Graph Kernels for Semi-Supervised Learning</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2004" href="../home/nips2004_home.html">nips2004</a> <a title="nips-2004-133" href="../nips2004/nips-2004-Nonparametric_Transforms_of_Graph_Kernels_for_Semi-Supervised_Learning.html">nips2004-133</a> <a title="nips-2004-133-reference" href="#">nips2004-133-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>133 nips-2004-Nonparametric Transforms of Graph Kernels for Semi-Supervised Learning</h1>
<br/><p>Source: <a title="nips-2004-133-pdf" href="http://papers.nips.cc/paper/2702-nonparametric-transforms-of-graph-kernels-for-semi-supervised-learning.pdf">pdf</a></p><p>Author: Xiaojin Zhu, Jaz Kandola, Zoubin Ghahramani, John D. Lafferty</p><p>Abstract: We present an algorithm based on convex optimization for constructing kernels for semi-supervised learning. The kernel matrices are derived from the spectral decomposition of graph Laplacians, and combine labeled and unlabeled data in a systematic fashion. Unlike previous work using diffusion kernels and Gaussian random ﬁeld kernels, a nonparametric kernel approach is presented that incorporates order constraints during optimization. This results in ﬂexible kernels and avoids the need to choose among different parametric forms. Our approach relies on a quadratically constrained quadratic program (QCQP), and is computationally feasible for large datasets. We evaluate the kernels on real datasets using support vector machines, with encouraging results. 1</p><br/>
<h2>reference text</h2><p>[1] S. Boyd and L. Vandenberge. Convex Optimization. Cambridge University Press, Cambridge UK, 2004.</p>
<p>[2] O. Chapelle, J. Weston, and B. Sch¨ lkopf. Cluster kernels for semi-supervised learning. In o Advances in Neural Information Processing Systems, 15, volume 15, 2002.</p>
<p>[3] F. R. K. Chung. Spectral graph theory, Regional Conference Series in Mathematics, No. 92. American Mathematical Society, 1997.</p>
<p>[4] N. Cristianini, J. Shawe-Taylor, A. Elisseeff, and J. Kandola. On kernel-target alignment. In Advances in NIPS, 2001.</p>
<p>[5] R. I. Kondor and J. Lafferty. Diffusion kernels on graphs and other discrete input spaces. In Proc. 19th International Conf. on Machine Learning, 2002.</p>
<p>[6] G. Lanckriet, N. Cristianini, P. Bartlett, L. E. Ghaoui, and M. Jordan. Learning the kernel matrix with semideﬁnite programming. Journal of Machine Learning Research, 5:27–72, 2004.</p>
<p>[7] A. Smola and R. Kondor. Kernels and regularization on graphs. In Conference on Learning Theory, COLT/KW, 2003.</p>
<p>[8] M. Szummer and T. Jaakkola. Partially labeled classiﬁcation with Markov random walks. In Advances in Neural Information Processing Systems, 14, volume 14, 2001.</p>
<p>[9] X. Zhu, Z. Ghahramani, and J. Lafferty. Semi-supervised learning using Gaussian ﬁelds and harmonic functions. In ICML-03, 20th International Conference on Machine Learning, 2003.</p>
<p>[10] X. Zhu, J. Lafferty, and Z. Ghahramani. Semi-supervised learning: From Gaussian ﬁelds to Gaussian processes. Technical Report CMU-CS-03-175, Carnegie Mellon University, 2003.  Training set size  Improved Order pc-mac 10 87.0 ± 5.0 0.71 ( 1) 30 90.3 ± 1.3 0.68 ( 8) 50 91.3 ± 0.9 0.64 (31) 70 91.5 ± 0.6 0.63 (70) 90 91.5 ± 0.6 0.63 (108) religion-atheism 10 72.8 ±11.2 0.50 ( 1) 30 84.2 ± 2.4 0.38 ( 8) 50 84.5 ± 2.3 0.31 (28) 70 85.7 ± 1.4 0.29 (55) 90 86.6 ± 1.3 0.27 (86) one-two 10 96.2 ± 2.7 0.87 ( 2) 20 96.4 ± 2.8 0.87 ( 3) 30 98.2 ± 2.1 0.84 ( 8) 40 98.3 ± 1.9 0.84 (13) 50 98.4 ± 1.9 0.83 (31) Ten digits (10 classes) 50 76.6 ± 4.3 0.47 (26) 100 84.8 ± 2.6 0.47 (124) 150 86.5 ± 1.7 0.48 (310) 200 88.1 ± 1.3 0.47 (708) 250 89.1 ± 1.1 0.47 (942) isolet (26 classes) 50 56.0 ± 3.5 0.27 (26) 100 64.6 ± 2.1 0.26 (105) 150 67.6 ± 2.6 0.26 (249) 200 71.0 ± 1.8 0.26 (441) 250 71.8 ± 2.3 0.26 (709)  Order  semi-supervised kernels Gaussian Diffusion Field  Max-align  RBF  standard kernels Linear  Quadratic  84.9 ± 7.2 0.57 ( 1) 89.6 ± 2.3 0.49 ( 8) 90.5 ± 1.7 0.46 (31) 90.8 ± 1.3 0.46 (56) 91.3 ± 1.3 0.45 (98)  56.4 ± 6.2 0.32 76.4 ± 6.1 0.19 81.1 ± 4.6 0.16 84.6 ± 2.1 0.14 86.3 ± 2.3 0.13  57.8 ±11.5 0.35 79.6 ±11.2 0.23 87.5 ± 2.8 0.20 90.5 ± 1.2 0.19 91.3 ± 1.1 0.18  71.1 ± 9.7 0.90 ( 1) 85.4 ± 3.9 0.74 ( 6) 88.4 ± 2.1 0.68 (25) 89.6 ± 1.6 0.66 (59) 90.3 ± 1.0 0.65 (84)  51.6 ± 3.4 0.11 62.6 ± 9.6 0.03 67.8 ± 9.0 0.02 74.7 ± 7.4 0.01 79.0 ± 6.4 0.01  63.0 ± 5.1 0.30 71.8 ± 5.5 0.18 77.6 ± 4.8 0.14 80.2 ± 4.6 0.12 82.5 ± 4.2 0.11  62.3 ± 4.2 0.25 71.2 ± 5.3 0.13 75.7 ± 5.4 0.10 74.3 ± 8.7 0.08 79.1 ± 7.3 0.08  70.9 ±10.9 0.42 ( 1) 83.0 ± 2.9 0.31 ( 6) 83.5 ± 2.5 0.26 (23) 85.3 ± 1.6 0.25 (42) 86.4 ± 1.5 0.24 (92)  55.2 ± 5.8 0.31 71.2 ± 6.3 0.20 80.4 ± 4.1 0.17 83.0 ± 2.9 0.16 84.5 ± 2.1 0.15  60.9 ±10.7 0.31 80.3 ± 5.1 0.22 83.5 ± 2.7 0.20 85.4 ± 1.8 0.19 86.2 ± 1.6 0.18  60.7 ± 7.5 0.85 ( 1) 74.4 ± 5.4 0.60 ( 7) 77.4 ± 6.1 0.48 (27) 82.3 ± 3.0 0.43 (51) 82.8 ± 2.6 0.40 (85)  55.8 ± 5.8 0.13 63.4 ± 6.5 0.05 69.3 ± 6.5 0.04 73.1 ± 5.8 0.03 77.7 ± 5.1 0.02  60.1 ± 7.0 0.30 63.7 ± 8.3 0.18 69.4 ± 7.0 0.15 75.7 ± 6.0 0.13 74.6 ± 7.6 0.12  61.2 ± 4.8 0.26 70.1 ± 6.3 0.15 70.7 ± 8.5 0.11 71.0 ±10.0 0.10 70.0 ±11.5 0.09  90.6 ±14.0 0.66 ( 1) 93.9 ± 8.7 0.64 ( 4) 97.2 ± 2.5 0.61 ( 7) 96.5 ± 2.4 0.61 (15) 95.6 ± 9.0 0.60 (37)  58.2 ±17.6 0.43 87.0 ±16.0 0.38 98.1 ± 2.2 0.35 98.9 ± 1.8 0.36 99.4 ± 0.5 0.35  59.4 ±18.9 0.53 83.2 ±19.8 0.50 98.1 ± 2.7 0.47 99.1 ± 1.4 0.48 99.6 ± 0.3 0.46  85.4 ±11.5 0.95 ( 1) 94.5 ± 1.6 0.90 ( 3) 96.4 ± 2.1 0.86 ( 6) 96.3 ± 2.3 0.86 (11) 96.6 ± 2.3 0.84 (25)  78.7 ±14.3 0.38 90.4 ± 4.6 0.33 93.6 ± 3.1 0.30 94.0 ± 2.7 0.29 96.1 ± 2.4 0.28  85.1 ± 5.7 0.26 86.0 ± 9.4 0.22 89.6 ± 5.9 0.17 91.6 ± 6.3 0.18 93.0 ± 3.6 0.17  85.7 ± 4.8 0.30 90.9 ± 3.7 0.25 92.9 ± 2.8 0.24 94.9 ± 2.0 0.21 95.8 ± 2.3 0.20  71.5 ± 5.0 0.21 (26) 83.4 ± 2.6 0.17 (98) 86.4 ± 1.3 0.18 (255) 88.0 ± 1.3 0.16 (477) 89.3 ± 1.0 0.16 (873)  41.4 ± 6.8 0.15 63.7 ± 3.5 0.12 75.1 ± 3.0 0.11 80.4 ± 2.5 0.10 84.6 ± 1.4 0.10  49.8 ± 6.3 0.16 72.5 ± 3.3 0.13 80.4 ± 2.1 0.13 84.4 ± 1.6 0.11 87.2 ± 1.3 0.11  70.3 ± 5.2 0.51 (25) 80.7 ± 2.6 0.49 (100) 84.5 ± 1.9 0.50 (244) 86.0 ± 1.5 0.49 (523) 87.2 ± 1.3 0.49 (706)  57.0 ± 4.0 -0.62 69.4 ± 1.9 -0.64 75.2 ± 1.4 -0.66 78.3 ± 1.3 -0.65 80.4 ± 1.4 -0.65  50.2 ± 9.0 -0.50 56.0 ± 7.8 -0.52 56.2 ± 7.2 -0.53 60.8 ± 7.3 -0.54 61.3 ± 7.6 -0.54  66.3 ± 3.7 -0.25 77.2 ± 2.3 -0.29 81.4 ± 2.2 -0.31 84.3 ± 1.7 -0.33 85.7 ± 1.3 -0.33  42.0 ± 5.2 0.13 (25) 59.0 ± 3.6 0.10 (127) 65.2 ± 3.0 0.09 (280) 70.9 ± 2.3 0.08 (570) 73.6 ± 1.5 0.08 (836)  41.2 ± 2.9 0.03 58.5 ± 2.9 -0.02 65.4 ± 2.6 -0.05 70.6 ± 1.9 -0.07 73.7 ± 1.2 -0.07  29.0 ± 2.7 0.11 47.4 ± 2.7 0.08 57.2 ± 2.7 0.07 64.8 ± 2.1 0.06 69.8 ± 1.5 0.06  50.1 ± 3.7 0.31 (24) 63.2 ± 1.9 0.29 (102) 67.9 ± 2.5 0.27 (221) 72.3 ± 1.7 0.27 (423) 74.2 ± 1.5 0.27 (665)  28.7 ± 2.0 -0.89 46.3 ± 2.4 -0.90 57.6 ± 1.5 -0.90 63.9 ± 1.6 -0.91 68.8 ± 1.5 -0.91  30.0 ± 2.7 -0.80 46.6 ± 2.7 -0.82 57.3 ± 1.8 -0.83 64.2 ± 2.0 -0.83 69.5 ± 1.7 -0.84  23.7 ± 2.4 -0.65 42.0 ± 2.9 -0.69 53.8 ± 2.2 -0.70 60.5 ± 1.6 -0.72 66.2 ± 1.4 -0.72  Table 1: Accuracy, alignment scores, and run times on the datasets. The table compares 8 kernels. Each cell has two rows: The upper row is test set accuracy with standard error; the lower row is training set alignment (SeDuMi/YALMIP run time in seconds is given in parentheses). All numbers are averaged over 30 random trials. Accuracies in boldface are the best as determined by a paired t-test at the 0.05 signiﬁcance level.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
