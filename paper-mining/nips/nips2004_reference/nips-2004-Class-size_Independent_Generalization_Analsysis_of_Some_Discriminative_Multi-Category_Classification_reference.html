<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>36 nips-2004-Class-size Independent Generalization Analsysis of Some Discriminative Multi-Category Classification</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2004" href="../home/nips2004_home.html">nips2004</a> <a title="nips-2004-36" href="../nips2004/nips-2004-Class-size_Independent_Generalization_Analsysis_of_Some_Discriminative_Multi-Category_Classification.html">nips2004-36</a> <a title="nips-2004-36-reference" href="#">nips2004-36-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>36 nips-2004-Class-size Independent Generalization Analsysis of Some Discriminative Multi-Category Classification</h1>
<br/><p>Source: <a title="nips-2004-36-pdf" href="http://papers.nips.cc/paper/2657-class-size-independent-generalization-analsysis-of-some-discriminative-multi-category-classification.pdf">pdf</a></p><p>Author: Tong Zhang</p><p>Abstract: We consider the problem of deriving class-size independent generalization bounds for some regularized discriminative multi-category classiﬁcation methods. In particular, we obtain an expected generalization bound for a standard formulation of multi-category support vector machines. Based on the theoretical result, we argue that the formulation over-penalizes misclassiﬁcation error, which in theory may lead to poor generalization performance. A remedy, based on a generalization of multi-category logistic regression (conditional maximum entropy), is then proposed, and its theoretical properties are examined. 1</p><br/>
<h2>reference text</h2><p>[1] Stanley Chen and Ronald Rosenfeld. A survey of smoothing techniques for ME models. IEEE Trans. Speech and Audio Processing, 8:37–50, 2000.</p>
<p>[2] Michael Collins. Parameter estimation for statistical parsing models: Theory and practice of distribution-free methods. In IWPT, 2001. available at http://www.ai.mit.edu/people/mcollins/publications.html.</p>
<p>[3] Koby Crammer and Yoram Singer. On the algorithmic implementation of multiclass kernel-based vector machines. Journal of Machine Learning Research, 2:265–292, 2001.</p>
<p>[4] Y. Lee, Y. Lin, and G. Wahba. Multicategory support vector machines, theory, and application to the classiﬁcation of microarray data and satellite radiance data. Journal of American Statistical Association, 99:67–81, 2004.</p>
<p>[5] R. Tyrrell Rockafellar. Convex analysis. Princeton University Press, Princeton, NJ, 1970.</p>
<p>[6] Ben Taskar, Carlos Guestrin, and Daphne Koller. Max-margin markov networks. In Sebastian Thrun, Lawrence Saul, and Bernhard Sch¨ lkopf, editors, Advances in o Neural Information Processing Systems 16. MIT Press, Cambridge, MA, 2004.</p>
<p>[7] J. Weston and C. Watkins. Multi-class support vector machines. Technical Report CSD-TR-98-04, Royal Holloway, 1998.</p>
<p>[8] Tong Zhang. Leave-one-out bounds for kernel methods. Neural Computation, 15:1397–1437, 2003.</p>
<p>[9] Tong Zhang. Statistical analysis of some multi-category large margin classiﬁcation methods. Journal of Machine Learning Research, 5:1225–1251, 2004.</p>
<p>[10] Tong Zhang. Statistical behavior and consistency of classiﬁcation methods based on convex risk minimization. The Annals of Statitics, 32:56–85, 2004. with discussion.  .</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
