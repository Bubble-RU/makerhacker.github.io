<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>113 nips-2004-Maximum-Margin Matrix Factorization</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2004" href="../home/nips2004_home.html">nips2004</a> <a title="nips-2004-113" href="../nips2004/nips-2004-Maximum-Margin_Matrix_Factorization.html">nips2004-113</a> <a title="nips-2004-113-reference" href="#">nips2004-113-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>113 nips-2004-Maximum-Margin Matrix Factorization</h1>
<br/><p>Source: <a title="nips-2004-113-pdf" href="http://papers.nips.cc/paper/2655-maximum-margin-matrix-factorization.pdf">pdf</a></p><p>Author: Nathan Srebro, Jason Rennie, Tommi S. Jaakkola</p><p>Abstract: We present a novel approach to collaborative prediction, using low-norm instead of low-rank factorizations. The approach is inspired by, and has strong connections to, large-margin linear discrimination. We show how to learn low-norm factorizations by solving a semi-deﬁnite program, and discuss generalization error bounds for them. 1</p><br/>
<h2>reference text</h2><p>[1] T. Hofmann. Unsupervised learning by probabilistic latent semantic analysis. Machine Learning Journal, 42(1):177–196, 2001.</p>
<p>[2] M. Collins, S. Dasgupta, and R. Schapire. A generalization of principal component analysis to the exponential family. In Advances in Neural Information Processing Systems 14, 2002.</p>
<p>[3] Nathan Srebro and Tommi Jaakkola. Weighted low rank approximation. In 20th International Conference on Machine Learning, 2003.</p>
<p>[4] D.D. Lee and H.S. Seung. Learning the parts of objects by non-negative matrix factorization. Nature, 401:788–791, 1999.</p>
<p>[5] T. Hofmann. Latent semantic models for collaborative ﬁltering. ACM Trans. Inf. Syst., 22(1):89–115, 2004.</p>
<p>[6] Benjamin Marlin. Modeling user rating proﬁles for collaborative ﬁltering. In Advances in Neural Information Processing Systems, volume 16, 2004.</p>
<p>[7] Maryam Fazel, Haitham Hindi, and Stephen P. Boyd. A rank minimization heuristic with application to minimum order system approximation. In Proceedings American Control Conference, volume 6, 2001.</p>
<p>[8] Nathan Srebro. Learning with Matrix Factorization. PhD thesis, Massachusetts Institute of Technology, 2004.</p>
<p>[9] N. Srebro, N. Alon, and T. Jaakkola. Generalization error bounds for collaborative prediction with low-rank matrices. In Advances In Neural Information Processing Systems 17, 2005.</p>
<p>[10] Amnon Shashua and Anat Levin. Ranking with large margin principle: Two approaches. In Advances in Neural Information Proceedings Systems, volume 15, 2003.</p>
<p>[11] B. Borchers. CSDP, a C library for semideﬁnite programming. Optimization Methods and Software, 11(1):613–623, 1999.</p>
<p>[12] B. Marlin. Collaborative ﬁltering: A machine learning perspective. Master’s thesis, University of Toronto, 2004.</p>
<p>[13] G. Lanckriet, N. Cristianini, P. Bartlett, L. El Ghaoui, and M. Jordan. Learning the kernel matrix with semideﬁnite programming. Journal of Machine Learning Research, 5:27–72, 2004.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
