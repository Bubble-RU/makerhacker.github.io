<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>152 nips-2004-Real-Time Pitch Determination of One or More Voices by Nonnegative Matrix Factorization</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2004" href="../home/nips2004_home.html">nips2004</a> <a title="nips-2004-152" href="../nips2004/nips-2004-Real-Time_Pitch_Determination_of_One_or_More_Voices_by_Nonnegative_Matrix_Factorization.html">nips2004-152</a> <a title="nips-2004-152-reference" href="#">nips2004-152-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>152 nips-2004-Real-Time Pitch Determination of One or More Voices by Nonnegative Matrix Factorization</h1>
<br/><p>Source: <a title="nips-2004-152-pdf" href="http://papers.nips.cc/paper/2631-real-time-pitch-determination-of-one-or-more-voices-by-nonnegative-matrix-factorization.pdf">pdf</a></p><p>Author: Fei Sha, Lawrence K. Saul</p><p>Abstract: An auditory “scene”, composed of overlapping acoustic sources, can be viewed as a complex object whose constituent parts are the individual sources. Pitch is known to be an important cue for auditory scene analysis. In this paper, with the goal of building agents that operate in human environments, we describe a real-time system to identify the presence of one or more voices and compute their pitch. The signal processing in the front end is based on instantaneous frequency estimation, a method for tracking the partials of voiced speech, while the pattern-matching in the back end is based on nonnegative matrix factorization, an unsupervised algorithm for learning the parts of complex objects. While supporting a framework to analyze complicated auditory scenes, our system maintains real-time operability and state-of-the-art performance in clean speech.</p><br/>
<h2>reference text</h2><p>[1] T. Abe, T. Kobayashi, and S. Imai. Harmonics tracking and pitch extraction based on instantaneous frequency. In Proc. of ICASSP, pages 756–759, 1995.</p>
<p>[2] T. Abe, T. Kobayashi, and S. Imai. Robust pitch estimation with harmonics enhancement in noisy environments based on instantaneous frequency. In Proc. of ICSLP, pages 1277–1280, 1996.</p>
<p>[3] P. Bagshaw, S. M. Hiller, and M. A. Jack. Enhanced pitch tracking and the processing of f0 contours for computer aided intonation teaching. In Proc. of 3rd European Conference on Speech Communication and Technology, pages 1003–1006, 1993.</p>
<p>[4] A. S. Bregman. Auditory Scene Analysis: The Perceptual Organization of Sound. MIT Press, 2nd edition, 1999.</p>
<p>[5] A. de Cheveigne and H. Kawahara. Multiple period estimation and pitch perception model. Speech Communication, 27:175–185, 1999.</p>
<p>[6] J. Goldstein. An optimum processor theory for the central formation of the pitch of complex tones. J. Acoust. Soc. Am., 54:1496–1516, 1973.</p>
<p>[7] M. Goto. A robust predominant-F0 estimation method for real-time detection of melody and bass lines in CD recordings. In Proc. of ICASSP, pages 757–760, June 2000.</p>
<p>[8] H. Kawahara, H. Katayose, A. de Cheveign´ , and R. D. Patterson. Fixed point analysis of e frequency to instantaneous frequency mapping for accurate estimation of f0 and periodicity. In Proc. of EuroSpeech, pages 2781–2784, 1999.</p>
<p>[9] A. Klapuri, T. Virtanen, and J.-M. Holm. Robust multipitch estimation for the analysis and manipulation of polyphonic musical signals. In Proc. of COST-G6 Conference on Digital Audio Effects, Verona, Italy, 2000.</p>
<p>[10] D. D. Lee and H. S. Seung. Learning in intelligent embedded systems. In Proc. of USENIX Workshop on Embedded Systems, 1999.</p>
<p>[11] D. D. Lee and H. S. Seung. Learning the parts of objects with nonnegative matrix factorization. Nature, 401:788–791, 1999.</p>
<p>[12] Y. Lin, D. D. Lee, and L. K. Saul. Nonnegative deconvolution for time of arrival estimation. In Proc. of ICASSP, 2004.</p>
<p>[13] T. Nakatani and T. Irino. Robust fundamental frequency estimation against background noise and spectral distortion. In Proc. of ICSLP, pages 1733–1736, 2002.</p>
<p>[14] F. Plante, G. F. Meyer, and W. A. Ainsworth. A pitch extraction reference database. In Proc. of EuroSpeech, pages 837–840, 1995.</p>
<p>[15] L. K. Saul, D. D. Lee, C. L. Isbell, and Y. LeCun. Real time voice processing with audiovisual feedback: toward autonomous agents with perfect pitch. In S. Becker, S. Thrun, and K. Obermayer, editors, Advances in Neural Information Processing Systems 15. MIT Press, 2003.</p>
<p>[16] L. K. Saul, F. Sha, and D. D. Lee. Statistical signal processing with nonnegativity constraints. In Proc. of EuroSpeech, pages 1001–1004, 2003.</p>
<p>[17] P. Smaragdis and J. C. Brown. Non-negative matrix factorization for polyphonic music transcription. In Proc. of IEEE Workshop on Applications of Signal Processing to Audio and Acoustics, pages 177–180, 2003.</p>
<p>[18] D. Talkin. A robust algorithm for pitch tracking(RAPT). In W. B. Kleijn and K. K. Paliwal, editors, Speech Coding and Synthesis, chapter 14. Elsevier Science B.V., 1995.</p>
<p>[19] T. Tolonen and M. Karjalainen. A computationally efﬁcient multipitch analysis model. IEEE Trans. on Speech and Audio Processing, 8(6):708–716, 2000.</p>
<p>[20] T. Virtanen and A. Klapuri. Separation of harmonic sounds using multipitch analysis and iterative parameter estimation. In Proc. of IEEE Workshop on Applications of Signal Processing to Audio and Acoustics, pages 83–86, New Paltz, NY, USA, Oct 2001.</p>
<p>[21] M. Wu, D. Wang, and G. J. Brown. A multipitch tracking algorithm for noisy speech. IEEE Trans. on Speech and Audio Processing, 11:229–241, 2003.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
