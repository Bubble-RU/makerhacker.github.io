<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>203 nips-2004-Validity Estimates for Loopy Belief Propagation on Binary Real-world Networks</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2004" href="../home/nips2004_home.html">nips2004</a> <a title="nips-2004-203" href="../nips2004/nips-2004-Validity_Estimates_for_Loopy_Belief_Propagation_on_Binary_Real-world_Networks.html">nips2004-203</a> <a title="nips-2004-203-reference" href="#">nips2004-203-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>203 nips-2004-Validity Estimates for Loopy Belief Propagation on Binary Real-world Networks</h1>
<br/><p>Source: <a title="nips-2004-203-pdf" href="http://papers.nips.cc/paper/2741-validity-estimates-for-loopy-belief-propagation-on-binary-real-world-networks.pdf">pdf</a></p><p>Author: Joris M. Mooij, Hilbert J. Kappen</p><p>Abstract: We introduce a computationally efﬁcient method to estimate the validity of the BP method as a function of graph topology, the connectivity strength, frustration and network size. We present numerical results that demonstrate the correctness of our estimates for the uniform random model and for a real-world network (“C. Elegans”). Although the method is restricted to pair-wise interactions, no local evidence (zero “biases”) and binary variables, we believe that its predictions correctly capture the limitations of BP for inference and MAP estimation on arbitrary graphical models. Using this approach, we ﬁnd that BP always performs better than MF. Especially for large networks with broad degree distributions (such as scale-free networks) BP turns out to signiﬁcantly outperform MF. 1</p><br/>
<h2>reference text</h2><p>[1] J. Pearl. Probabilistic Reasoning in Intelligent systems: Networks of Plausible Inference. Morgan Kaufmann, San Francisco, CA, 1988.</p>
<p>[2] J. Yedidia, W. Freeman, and Y. Weiss. Generalized belief propagation. In Advances in Neural Information Processing Systems, volume 13, pages 689–695, 2001.</p>
<p>[3] K. Murphy, Y. Weiss, and M. Jordan. Loopy belief propagation for approximate inference: an empirical study. In Proc. of the Conf. on Uncertainty in AI, pages 467–475, 1999.</p>
<p>[4] B. Frey and D. MacKay. A revolution: Belief propagation in graphs with cycles. In Advances in Neural Information Processing Systems, volume 10, pages 479–485, 1997.</p>
<p>[5] Y. Weiss. Correctness of local probability propagation in graphical models with loops. Neur. Comp., 12:1–41, 2000.</p>
<p>[6] R. Albert and A.-L. Barab´ si. Statistical mechanics of complex networks. Rev. Mod. Phys., a 74:47–97, 2002.</p>
<p>[7] P. Erd˝ s and A. R´ nyi. On random graphs i. Publ. Math. Debrecen, 6:290–291, 1959. o e</p>
<p>[8] A.-L. Barab´ si and R. Albert. Emergence of scaling in random networks. Science, 286:509– a 512, 1999.</p>
<p>[9] T. Heskes. Stable ﬁxed points of loopy belief propagation are local minima of the bethe free energy. In Advances in Neural Information Processing Systems, volume 15, pages 343–350, 2003.</p>
<p>[10] M. Welling and Y.W. Teh. Belief optimization for binary networks: a stable alternative to loopy belief propagation. In Proc. of the Conf. on Uncertainty in AI, volume 17, 2001.</p>
<p>[11] J.M. Mooij and H.J. Kappen. Spin-glass phase transitions on real-world graphs. preprint, condmat:0408378, 2004.</p>
<p>[12] L. Viana and A. Bray. Phase diagrams for dilute spin glasses. J. Phys. C: Solid State Phys., 18:3037–3051, 1985.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
