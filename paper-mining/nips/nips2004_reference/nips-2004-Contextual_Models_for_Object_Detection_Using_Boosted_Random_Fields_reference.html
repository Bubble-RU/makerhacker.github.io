<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>47 nips-2004-Contextual Models for Object Detection Using Boosted Random Fields</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2004" href="../home/nips2004_home.html">nips2004</a> <a title="nips-2004-47" href="../nips2004/nips-2004-Contextual_Models_for_Object_Detection_Using_Boosted_Random_Fields.html">nips2004-47</a> <a title="nips-2004-47-reference" href="#">nips2004-47-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>47 nips-2004-Contextual Models for Object Detection Using Boosted Random Fields</h1>
<br/><p>Source: <a title="nips-2004-47-pdf" href="http://papers.nips.cc/paper/2663-contextual-models-for-object-detection-using-boosted-random-fields.pdf">pdf</a></p><p>Author: Antonio Torralba, Kevin P. Murphy, William T. Freeman</p><p>Abstract: We seek to both detect and segment objects in images. To exploit both local image data as well as contextual information, we introduce Boosted Random Fields (BRFs), which uses Boosting to learn the graph structure and local evidence of a conditional random ﬁeld (CRF). The graph structure is learned by assembling graph fragments in an additive model. The connections between individual pixels are not very informative, but by using dense graphs, we can pool information from large regions of the image; dense models also support efﬁcient inference. We show how contextual information from other objects can improve detection performance, both in terms of accuracy and speed, by using a computational cascade. We apply our system to detect stuff and things in ofﬁce and street scenes. 1</p><br/>
<h2>reference text</h2><p>[1] E. H. Adelson. On seeing stuff: the perception of materials by humans and machines. In Proc. SPIE, volume 4299, pages 1–12, 2001.</p>
<p>[2] E. Borenstein and S. Ullman. Class-speciﬁc, top-down segmentation. In Proc. European Conf. on Computer Vision, 2002.</p>
<p>[3] T. Dietterich, A. Ashenfelter, and Y. Bulatov. Training conditional random ﬁelds via gradient tree boosting. In Intl. Conf. on Machine Learning, 2004.</p>
<p>[4] M. Fink and P. Perona. Mutual boosting for contextual inﬂuence. In Advances in Neural Info. Proc. Systems, 2003.</p>
<p>[5] J. Friedman, T. Hastie, and R. Tibshirani. Additive logistic regression: a statistical view of boosting. Annals of statistics, 28(2):337–374, 2000.</p>
<p>[6] Xuming He, Richard Zemel, and Miguel Carreira-Perpinan. Multiscale conditional random ﬁelds for image labelling. In Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2004.</p>
<p>[7] S. Kumar and M. Hebert. Discriminative random ﬁelds: A discriminative framework for contextual interaction in classiﬁcation. In IEEE Conf. on Computer Vision and Pattern Recognition, 2003.</p>
<p>[8] J. Lafferty, A. McCallum, and F. Pereira. Conditional random ﬁelds: Probabilistic models for segmenting and labeling sequence data. In Intl. Conf. on Machine Learning, 2001.</p>
<p>[9] K. Murphy, A. Torralba, and W. Freeman. Using the forest to see the trees: a graphical model relating features, objects and scenes. In Advances in Neural Info. Proc. Systems, 2003.</p>
<p>[10] R. Schapire. The boosting approach to machine learning: An overview. In MSRI Workshop on Nonlinear Estimation and Classiﬁcation, 2001.</p>
<p>[11] B. Taskar, C. Guestrin, and D. Koller. Max-margin markov networks. In Advances in Neural Info. Proc. Systems, 2003.</p>
<p>[12] P. Viola and M. Jones. Robust real-time object detection. Intl. J. Computer Vision, 57(2):137– 154, 2004.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
