<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>54 nips-2004-Distributed Information Regularization on Graphs</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2004" href="../home/nips2004_home.html">nips2004</a> <a title="nips-2004-54" href="../nips2004/nips-2004-Distributed_Information_Regularization_on_Graphs.html">nips2004-54</a> <a title="nips-2004-54-reference" href="#">nips2004-54-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>54 nips-2004-Distributed Information Regularization on Graphs</h1>
<br/><p>Source: <a title="nips-2004-54-pdf" href="http://papers.nips.cc/paper/2632-distributed-information-regularization-on-graphs.pdf">pdf</a></p><p>Author: Adrian Corduneanu, Tommi S. Jaakkola</p><p>Abstract: We provide a principle for semi-supervised learning based on optimizing the rate of communicating labels for unlabeled points with side information. The side information is expressed in terms of identities of sets of points or regions with the purpose of biasing the labels in each region to be the same. The resulting regularization objective is convex, has a unique solution, and the solution can be found with a pair of local propagation operations on graphs induced by the regions. We analyze the properties of the algorithm and demonstrate its performance on document classiﬁcation tasks. 1</p><br/>
<h2>reference text</h2><p>[1] A. Blum and T. Mitchell. Combining labeled and unlabeled data with co-training. In Proceedings of the 1998 Conference on Computational Learning Theory, 1998.</p>
<p>[2] X. Zhu, Z. Ghahramani, and J. Lafferty. Semi-supervised learning using gaussian ﬁelds and harmonic functions. In Machine Learning: Proceedings of the Twentieth International Conference, 2003.</p>
<p>[3] M. Szummer and T. Jaakkola. Partially labeled classiﬁcation with markov random walks. In Advances in Neural Information Processing Systems 14, 2001.</p>
<p>[4] O. Chapelle, J. Weston, and B. Schoelkopf. Cluster kernels for semi-supervised learning. In Advances in Neural Information Processing Systems 15, 2002.</p>
<p>[5] M. Szummer and T. Jaakkola. Information regularization with partially labeled data. In NIPS’2002, volume 15, 2003.</p>
<p>[6] A. Corduneanu and T. Jaakkola. On information regularization. In Proceedings of the 19th UAI, 2003.</p>
<p>[7] T. M. Cover and J. A. Thomas. Elements of Information Theory. Wiley & Sons, New York, 1991.</p>
<p>[8] R. E. Blahut. Computation of channel capacity and rate distortion functions. In IEEE Trans. Inform. Theory, volume 18, pages 460–473, July 1972.</p>
<p>[9] K. Nigam, A.K. McCallum, S. Thrun, and T. Mitchell. Text classiﬁcation from labeled and unlabeled documents using EM. Machine Learning, 39:103–134, 2000.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
