<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>173 nips-2004-Spike-timing Dependent Plasticity and Mutual Information Maximization for a Spiking Neuron Model</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2004" href="../home/nips2004_home.html">nips2004</a> <a title="nips-2004-173" href="../nips2004/nips-2004-Spike-timing_Dependent_Plasticity_and_Mutual_Information_Maximization_for_a_Spiking_Neuron_Model.html">nips2004-173</a> <a title="nips-2004-173-reference" href="#">nips2004-173-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>173 nips-2004-Spike-timing Dependent Plasticity and Mutual Information Maximization for a Spiking Neuron Model</h1>
<br/><p>Source: <a title="nips-2004-173-pdf" href="http://papers.nips.cc/paper/2588-spike-timing-dependent-plasticity-and-mutual-information-maximization-for-a-spiking-neuron-model.pdf">pdf</a></p><p>Author: Taro Toyoizumi, Jean-pascal Pfister, Kazuyuki Aihara, Wulfram Gerstner</p><p>Abstract: We derive an optimal learning rule in the sense of mutual information maximization for a spiking neuron model. Under the assumption of small ﬂuctuations of the input, we ﬁnd a spike-timing dependent plasticity (STDP) function which depends on the time course of excitatory postsynaptic potentials (EPSPs) and the autocorrelation function of the postsynaptic neuron. We show that the STDP function has both positive and negative phases. The positive phase is related to the shape of the EPSP while the negative phase is controlled by neuronal refractoriness. 1</p><br/>
<h2>reference text</h2><p>[1] G. Bi and M. Poo. Synaptic modiﬁcation of correlated activity: Hebb’s postulate revisited. Annu. Rev. Neurosci., 24:139–166, 2001.</p>
<p>[2] W. Gerstner and W. M. Kistler. Spiking Neuron Models. Cambridge University Press, 2002.</p>
<p>[3] R. Kempter, W. Gerstner, and J. L. van Hemmen. Hebbian learning and spiking neurons. Phys. Rev. E, 59:4498–4514, 1999.</p>
<p>[4] W. Gerstner and W. M. Kistler. Mathematical formulations of hebbian learning. Biol. Cybern., 87:404–415, 2002.</p>
<p>[5] R. G¨ tig, R. Aharonov, S. Rotter, and H. Sompolinsky. Learning input correlations through u nonlinear temporally asymmetric hebbian plasticity. J. Neurosci., 23(9):3697–3714, 2003.</p>
<p>[6] R. B. Stein. The information capacity of nerve cells using a frequency code. Biophys. J., 7:797–826, 1967.</p>
<p>[7] W. Bialek, F. Rieke, R. de Ruyter van Stevenick, and D. Warland. Reading a neural code. Science, 252:1854–1857, 1991.</p>
<p>[8] F. Rieke, D. Warland, R. R. van Steveninck, and W. Bialek. Spikes. MIT Press, 1997.</p>
<p>[9] R. Linsker. Self-organization in a perceptual network. Computer, 21:105–117, 1988.</p>
<p>[10] J-P. Nadal and N. Parga. Nonlinear neurons in the low-noise limit: a factorial code maximizes information transfer. Network: Comput.Neural Syst., 5:565–581, 1994.</p>
<p>[11] J-P Nadal, N. Brunel, and N Parga. Nonlinear feedforward networks with stochastic outputs: infomax implies redundancy reduction. Network: Comput. Neural Syst., 9:207–217, 1998.</p>
<p>[12] A. J. Bell and T. Sejnowski. An information-maximization approach to blind separation and blind deconvolution. Neural Comput., 7(6):1004–1034, 1995.</p>
<p>[13] J. J. Hopﬁeld. Encoding for computation: recognizing brief dynamical patterns by exploiting effects of weak rhythms on action-potential timing. Proc. Natl. Acad. Sci. USA, 101(16):6255– 6260, 2004.</p>
<p>[14] G. Checkik. Spike-timing-dependent plasticity and relevant mutual information maximization. Neural Comput., 15:1481–1510, 2003.</p>
<p>[15] V. V. Prelov and E. C. van der Meulen. An asymptotic expression for the information and capacity of a multidimensional channel with weak input signals. IEEE. Trans. Inform. Theory, 39(5):1728–1735, 1993.</p>
<p>[16] T. M. Cover and J. A. Thomas. Elements of Information Theory. New York: Wiley, 1991.</p>
<p>[17] N. Brunel and J-P. Nadal. Mutual information, ﬁsher information, and population coding. Neural Comput., 10:1731–1757, 1998.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
