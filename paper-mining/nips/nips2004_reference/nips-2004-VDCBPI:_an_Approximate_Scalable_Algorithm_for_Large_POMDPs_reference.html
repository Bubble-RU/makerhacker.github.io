<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>202 nips-2004-VDCBPI: an Approximate Scalable Algorithm for Large POMDPs</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2004" href="../home/nips2004_home.html">nips2004</a> <a title="nips-2004-202" href="../nips2004/nips-2004-VDCBPI%3A_an_Approximate_Scalable_Algorithm_for_Large_POMDPs.html">nips2004-202</a> <a title="nips-2004-202-reference" href="#">nips2004-202-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>202 nips-2004-VDCBPI: an Approximate Scalable Algorithm for Large POMDPs</h1>
<br/><p>Source: <a title="nips-2004-202-pdf" href="http://papers.nips.cc/paper/2704-vdcbpi-an-approximate-scalable-algorithm-for-large-pomdps.pdf">pdf</a></p><p>Author: Pascal Poupart, Craig Boutilier</p><p>Abstract: Existing algorithms for discrete partially observable Markov decision processes can at best solve problems of a few thousand states due to two important sources of intractability: the curse of dimensionality and the policy space complexity. This paper describes a new algorithm (VDCBPI) that mitigates both sources of intractability by combining the Value Directed Compression (VDC) technique [13] with Bounded Policy Iteration (BPI) [14]. The scalability of VDCBPI is demonstrated on synthetic network management problems with up to 33 million states.</p><br/>
<h2>reference text</h2><p>[1] D. Aberdeen and J. Baxter. Scaling internal-state policy-gradient methods for POMDPs. Proc. of the Nineteenth Intl. Conf. on Machine Learning, pp.3–10, Sydney, Australia, 2002.</p>
<p>[2] C. Boutilier and D. Poole. Computing optimal policies for partially observable decision processes using compact representations. Proc. AAAI-96, pp.1168–1175, Portland, OR, 1996.</p>
<p>[3] D. Braziunas and C. Boutilier. Stochastic local search for POMDP controllers. Proc. AAAI-04, to appear, San Jose, CA, 2004.</p>
<p>[4] A. R. Cassandra, M. L. Littman, and N. L. Zhang. Incremental pruning: A simple, fast, exact method for POMDPs. Proc. UAI-97, pp.54–61, Providence, RI, 1997.</p>
<p>[5] C. Guestrin, D. Koller, and R. Parr. Max-norm projections for factored MDPs. Proc. IJCAI-01, pp.673–680, Seattle, WA, 2001.</p>
<p>[6] C. Guestrin, D. Koller, and R. Parr. Solving factored POMDPs with linear value functions. IJCAI-01 Wkshp. on Planning under Uncertainty and Incomplete Information, Seattle, 2001.</p>
<p>[7] E. A. Hansen. Solving POMDPs by searching in policy space. Proc. UAI-98, pp.211–219, Madison, Wisconsin, 1998.</p>
<p>[8] E. A. Hansen and Z. Feng. Dynamic programming for POMDPs using a factored state representation. Proc. AIPS-2000, pp.130–139, Breckenridge, CO, 2000.</p>
<p>[9] E. A. Hansen and Z. Feng. Approximate planning for factored POMDPs. Proc. ECP-2001, Toledo, Spain, 2000.</p>
<p>[10] L. P. Kaelbling, M. Littman, and A. R. Cassandra. Planning and acting in partially observable stochastic domains. Artif. Intel., 101:99–134, 1998.</p>
<p>[11] N. Meuleau, L. Peshkin, K. Kim, and L. P. Kaelbling. Learning ﬁnite-state controllers for partially observable environments. Proc. UAI-99, pp.427–436, Stockholm, 1999.</p>
<p>[12] J. Pineau, G. Gordon, and S. Thrun. Point-based value iteration: an anytime algorithm for POMDPs. IJCAI-03, Acapulco, Mexico, 2003.</p>
<p>[13] P. Poupart and C. Boutilier. Value-directed compressions of POMDPs. Advances in Neural Information Processing Systems, pp.1547–1554, Vancouver, Canada, 2002.</p>
<p>[14] P. Poupart and C. Boutilier. Bounded ﬁnite state controllers. Advances in Neural Information Processing Systems, Vancouver, Canada, 2003.</p>
<p>[15] N. Roy and G. Gordon. Exponential family PCA for belief compression in pomdps. Advances in Neural Information Processing Systems, pp.1635–1642, Vancouver, BC, 2002.</p>
<p>[16] M. T. J. Spaan and N. Vlassis. A point-based pomdp algorithm for robot planning. IEEE Intl. Conf. on Robotics and Automation, to appear, New Orleans, 2004.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
