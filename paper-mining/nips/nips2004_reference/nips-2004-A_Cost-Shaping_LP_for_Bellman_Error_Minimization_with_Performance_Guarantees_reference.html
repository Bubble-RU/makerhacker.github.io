<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1 nips-2004-A Cost-Shaping LP for Bellman Error Minimization with Performance Guarantees</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2004" href="../home/nips2004_home.html">nips2004</a> <a title="nips-2004-1" href="../nips2004/nips-2004-A_Cost-Shaping_LP_for_Bellman_Error_Minimization_with_Performance_Guarantees.html">nips2004-1</a> <a title="nips-2004-1-reference" href="#">nips2004-1-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1 nips-2004-A Cost-Shaping LP for Bellman Error Minimization with Performance Guarantees</h1>
<br/><p>Source: <a title="nips-2004-1-pdf" href="http://papers.nips.cc/paper/2621-a-cost-shaping-lp-for-bellman-error-minimization-with-performance-guarantees.pdf">pdf</a></p><p>Author: Daniela D. Farias, Benjamin V. Roy</p><p>Abstract: We introduce a new algorithm based on linear programming that approximates the diﬀerential value function of an average-cost Markov decision process via a linear combination of pre-selected basis functions. The algorithm carries out a form of cost shaping and minimizes a version of Bellman error. We establish an error bound that scales gracefully with the number of states without imposing the (strong) Lyapunov condition required by its counterpart in [6]. We propose a path-following method that automates selection of important algorithm parameters which represent counterparts to the “state-relevance weights” studied in [6]. 1</p><br/>
<h2>reference text</h2><p>[1] D. Adelman, “A Price-Directed Approach to Stochastic Inventory/Routing,” preprint, 2002, to appear in Operations Research.</p>
<p>[2] L. C. Baird, “Residual Algorithms: Reinforcement Learning with Function Approximation,” ICML, 1995.</p>
<p>[3] D. P. Bertsekas and J. N. Tsitsiklis, Neuro-Dynamic Programming, Athena Scientiﬁc, Bellmont, MA, 1996.</p>
<p>[4] D. P. Bertsekas, Dynamic Programming and Optimal Control, second edition, Athena Scientiﬁc, Bellmont, MA, 2001.</p>
<p>[5] J. A. Boyan and A. W. Moore, “Generalization in Reinforcement Learning: Safely Approximating the Value Function,” NIPS, 1995.</p>
<p>[6] D. P. de Farias and B. Van Roy, “The Linear Programming Approach to Approximate Dynamic Programming,” Operations Research, Vol. 51, No. 6, November-December 2003, pp. 850-865. Preliminary version appeared in NIPS, 2001.</p>
<p>[7] D. P. de Farias and B. Van Roy, “On Constraint Sampling in the Linear Programming Approach to Approximate Dynamic Programming,” Mathematics of Operations Research, Vol. 29, No. 3, 2004, pp. 462–478.</p>
<p>[8] D.P. de Farias and B. Van Roy, “Approximate Linear Programming for Average-Cost Dynamic Programming,” NIPS, 2003.</p>
<p>[9] C. B. Garcia and W. I. Zangwill, Pathways to Solutions, Fixed Points, and Equilibria, Prentice-Hall, Englewood Cliﬀs, NJ, 1981.</p>
<p>[10] G. J. Gordon, “Stable Function Approximation in Dynamic Programming,” ICML, 1995.</p>
<p>[11] C. Guestrin, D. Koller, R. Parr, and S. Venkataraman, “Eﬃcient Solution Algorithms for Factored MDPs,” Journal of Artiﬁcial Intelligence Research, Volume 19, 2003, pp. 399-468. Preliminary version appeared in NIPS, 2001.</p>
<p>[12] M. E. Harmon, L. C. Baird, and A. H. Klopf, “Advantage Updating Applied to a Diﬀerential Game,” NIPS 1995.</p>
<p>[13] R. Munos, “Error Bounds for Approximate Policy Iteration,” ICML, 2003.</p>
<p>[14] J. N. Tsitsiklis and B. Van Roy, “Feature-Based Methods for Large Scale Dynamic Programming,” Machine Learning, Vol. 22, 1996, pp. 59-94.</p>
<p>[15] D. Schuurmans and R. Patrascu, “Direct Value Approximation for Factored MDPs,” NIPS, 2001.</p>
<p>[16] P. J. Schweitzer and A. Seidman, “Generalized Polynomial Approximation in Markovian Decision Processes,” Journal of Mathematical Analysis and Applications, Vol. 110, ‘985, pp. 568-582.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
