<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>50 nips-2004-Dependent Gaussian Processes</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2004" href="../home/nips2004_home.html">nips2004</a> <a title="nips-2004-50" href="../nips2004/nips-2004-Dependent_Gaussian_Processes.html">nips2004-50</a> <a title="nips-2004-50-reference" href="#">nips2004-50-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>50 nips-2004-Dependent Gaussian Processes</h1>
<br/><p>Source: <a title="nips-2004-50-pdf" href="http://papers.nips.cc/paper/2561-dependent-gaussian-processes.pdf">pdf</a></p><p>Author: Phillip Boyle, Marcus Frean</p><p>Abstract: Gaussian processes are usually parameterised in terms of their covariance functions. However, this makes it difﬁcult to deal with multiple outputs, because ensuring that the covariance matrix is positive deﬁnite is problematic. An alternative formulation is to treat Gaussian processes as white noise sources convolved with smoothing kernels, and to parameterise the kernel instead. Using this, we extend Gaussian processes to handle multiple, coupled outputs. 1</p><br/>
<h2>reference text</h2><p>[1] A BRAHAMSEN , P. A review of gaussian random ﬁelds and correlation functions. Tech. Rep. 917, Norwegian Computing Center, Box 114, Blindern, N-0314 Oslo, Norway, 1997.</p>
<p>[2] B OYLE , P., AND F REAN , M. Multiple-output gaussian process regression. Tech. rep., Victoria University of Wellington, 2004.</p>
<p>[3] C RESSIE , N. Statistics for Spatial Data. Wiley, 1993.</p>
<p>[4] G IBBS , M. Bayesian Gaussian Processes for Classiﬁcation and Regression. PhD thesis, University of Cambridge, Cambridge, U.K., 1997.</p>
<p>[5] G IBBS , M., AND M AC K AY, D. J. Efﬁcient implementation of gaussian processes. www.inference.phy.cam.ac.uk/mackay/abstracts/gpros.html, 1996.</p>
<p>[6] G IBBS , M. N., AND M AC K AY, D. J. Variational gaussian process classiﬁers. IEEE Trans. on Neural Networks 11, 6 (2000), 1458–1464.</p>
<p>[7] H IGDON , D. Space and space-time modelling using process convolutions. In Quantitative methods for current environmental issues (2002), C. Anderson, V. Barnett, P. Chatwin, and A. El-Shaarawi, Eds., Springer Verlag, pp. 37–56.</p>
<p>[8] M AC K AY, D. J. Gaussian processes: A replacement for supervised neural networks? NIPS97 Tutorial, 1997.  In</p>
<p>[9] M AC K AY, D. J. Information theory, inference, and learning algorithms. Cambridge University Press, 2003.</p>
<p>[10] N EAL , R. Probabilistic inference using markov chain monte carlo methods. Tech. Report CRG-TR-93-1, Dept. of Computer Science, Univ. of Toronto, 1993.</p>
<p>[11] N EAL , R. Monte carlo implementation of gaussian process models for bayesian regression and classiﬁcation. Tech. Rep. CRG-TR-97-2, Dept. of Computer Science, Univ. of Toronto, 1997.</p>
<p>[12] PACIOREK , C. Nonstationary Gaussian processes for regression and spatial modelling. PhD thesis, Carnegie Mellon University, Pittsburgh, Pennsylvania, U.S.A., 2003.</p>
<p>[13] PACIOREK , C., AND S CHERVISH , M. Nonstationary covariance functions for gaussian process regression. Submitted to NIPS, 2004.</p>
<p>[14] R ASMUSSEN , C., AND K USS , M. Gaussian processes in reinforcement learning. In Advances in Neural Information Processing Systems (2004), vol. 16.</p>
<p>[15] R ASMUSSEN , C. E. Evaluation of Gaussian Processes and other methods for Non-Linear Regression. PhD thesis, Graduate Department of Computer Science, University of Toronto, 1996.</p>
<p>[16] T IPPING , M. E., AND B ISHOP, C. M. Bayesian image super-resolution. In Advances in Neural Information Processing Systems (2002), S. Becker S., Thrun and K. Obermayer, Eds., vol. 15, pp. 1303 – 1310.</p>
<p>[17] W ILLIAMS , C. K., AND BARBER , D. Bayesian classiﬁcation with gaussian processes. IEEE trans. Pattern Analysis and Machine Intelligence 20, 12 (1998), 1342 – 1351.</p>
<p>[18] W ILLIAMS , C. K., AND R ASMUSSEN , C. E. Gaussian processes for regression. In Advances in Neural Information Processing Systems (1996), D. Touretzsky, M. Mozer, and M. Hasselmo, Eds., vol. 8.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
