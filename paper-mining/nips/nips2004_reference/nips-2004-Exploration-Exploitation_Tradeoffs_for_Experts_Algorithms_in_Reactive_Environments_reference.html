<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>65 nips-2004-Exploration-Exploitation Tradeoffs for Experts Algorithms in Reactive Environments</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2004" href="../home/nips2004_home.html">nips2004</a> <a title="nips-2004-65" href="../nips2004/nips-2004-Exploration-Exploitation_Tradeoffs_for_Experts_Algorithms_in_Reactive_Environments.html">nips2004-65</a> <a title="nips-2004-65-reference" href="#">nips2004-65-reference</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>65 nips-2004-Exploration-Exploitation Tradeoffs for Experts Algorithms in Reactive Environments</h1>
<br/><p>Source: <a title="nips-2004-65-pdf" href="http://papers.nips.cc/paper/2734-exploration-exploitation-tradeoffs-for-experts-algorithms-in-reactive-environments.pdf">pdf</a></p><p>Author: Daniela D. Farias, Nimrod Megiddo</p><p>Abstract: A reactive environment is one that responds to the actions of an agent rather than evolving obliviously. In reactive environments, experts algorithms must balance exploration and exploitation of experts more carefully than in oblivious ones. In addition, a more subtle deﬁnition of a learnable value of an expert is required. A general exploration-exploitation experts method is presented along with a proper deﬁnition of value. The method is shown to asymptotically perform as well as the best available expert. Several variants are analyzed from the viewpoint of the exploration-exploitation tradeoff, including explore-then-exploit, polynomially vanishing exploration, constant-frequency exploration, and constant-size exploration phases. Complexity and performance bounds are proven. 1</p><br/>
<h2>reference text</h2><p>[1] Auer, P., Cesa-Bianchi, N., Freund, Y. and Schapire, R.E. (1995) Gambling in a rigged casino: The adversarial multi-armed bandit problem. In Proc. 36th Annual IEEE Symp. on Foundations of Computer Science, pp. 322–331, Los Alamitos, CA: IEEE Computer Society Press.</p>
<p>[2] de Farias, D. P. and Megiddo, N. (2004) How to Combine Expert (and Novice) Advice when Actions Impact the Environment. In Advances in Neural Information Process¨ ing Systems 16, S. Thrun, L. Saul and B. Scholkopf, Eds., Cambridge, MA:MIT Press. http://books.nips.cc/papers/files/nips16/NIPS2003 CN09.pdf</p>
<p>[3] Freund, Y. and Schapire, R.E. (1999) Adaptive game playing using multiplicative weights. Games and Economic Behavior 29:79–103.</p>
<p>[4] Littlestone, N. and Warmuth, M.K. (1994) The weighted majority algorithm. Information and Computation 108 (2):212–261.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
