<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>155 nips-2004-Responding to Modalities with Different Latencies</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2004" href="../home/nips2004_home.html">nips2004</a> <a title="nips-2004-155" href="../nips2004/nips-2004-Responding_to_Modalities_with_Different_Latencies.html">nips2004-155</a> <a title="nips-2004-155-reference" href="#">nips2004-155-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>155 nips-2004-Responding to Modalities with Different Latencies</h1>
<br/><p>Source: <a title="nips-2004-155-pdf" href="http://papers.nips.cc/paper/2747-responding-to-modalities-with-different-latencies.pdf">pdf</a></p><p>Author: Fredrik Bissmarck, Hiroyuki Nakahara, Kenji Doya, Okihide Hikosaka</p><p>Abstract: Motor control depends on sensory feedback in multiple modalities with different latencies. In this paper we consider within the framework of reinforcement learning how different sensory modalities can be combined and selected for real-time, optimal movement control. We propose an actor-critic architecture with multiple modules, whose output are combined using a softmax function. We tested our architecture in a simulation of a sequential reaching task. Reaching was initially guided by visual feedback with a long latency. Our learning scheme allowed the agent to utilize the somatosensory feedback with shorter latency when the hand is near the experienced trajectory. In simulations with different latencies for visual and somatosensory feedback, we found that the agent depended more on feedback with shorter latency. 1</p><br/>
<h2>reference text</h2><p>[1] M. Haruno, D. M. Wolpert, and M. Kawato. Mosaic model for sensorimotor learning and control. Neural Comput, 13(10):2201–20, 2001.</p>
<p>[2] K. Doya. Reinforcement learning in continuous time and space. Neural Comput, 12(1):219–45, 2000.</p>
<p>[3] K. Doya. What are the computations of the cerebellum, the basal ganglia and the cerebral cortex? Neural Netw, 12(7-8):961–974, 1999.</p>
<p>[4] N. Daw. Reinforcement learning models of the dopamine system and their behavioral implications. PhD thesis, Carnegie Mellon University, 2003.</p>
<p>[5] G. E. Alexander and M. D. Crutcher. Functional architecture of basal ganglia circuits: neural substrates of parallel processing. Trends Neurosci, 13(7):266–71, 1990.</p>
<p>[6] H. Nakahara, K. Doya, and O. Hikosaka. Parallel cortico-basal ganglia mechanisms for acquisition and execution of visuomotor sequences - a computational approach. J Cogn Neurosci, 13(5):626–47, 2001.</p>
<p>[7] O. Hikosaka, H. Nakahara, M. K. Rand, K. Sakai, X. Lu, K. Nakamura, S. Miyachi, and K. Doya. Parallel neural networks for learning sequential procedures. Trends Neurosci, 22(10):464–71, 1999.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
