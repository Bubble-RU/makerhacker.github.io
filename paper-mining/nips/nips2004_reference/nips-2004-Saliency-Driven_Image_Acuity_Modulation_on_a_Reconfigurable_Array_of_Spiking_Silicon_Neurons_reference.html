<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>157 nips-2004-Saliency-Driven Image Acuity Modulation on a Reconfigurable Array of Spiking Silicon Neurons</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2004" href="../home/nips2004_home.html">nips2004</a> <a title="nips-2004-157" href="../nips2004/nips-2004-Saliency-Driven_Image_Acuity_Modulation_on_a_Reconfigurable_Array_of_Spiking_Silicon_Neurons.html">nips2004-157</a> <a title="nips-2004-157-reference" href="#">nips2004-157-reference</a> knowledge-graph by maker-knowledge-mining</p><h1>157 nips-2004-Saliency-Driven Image Acuity Modulation on a Reconfigurable Array of Spiking Silicon Neurons</h1>
<br/><p>Source: <a title="nips-2004-157-pdf" href="http://papers.nips.cc/paper/2694-saliency-driven-image-acuity-modulation-on-a-reconfigurable-array-of-spiking-silicon-neurons.pdf">pdf</a></p><p>Author: R. J. Vogelstein, Udayan Mallik, Eugenio Culurciello, Gert Cauwenberghs, Ralph Etienne-Cummings</p><p>Abstract: We have constructed a system that uses an array of 9,600 spiking silicon neurons, a fast microcontroller, and digital memory, to implement a reconﬁgurable network of integrate-and-ﬁre neurons. The system is designed for rapid prototyping of spiking neural networks that require high-throughput communication with external address-event hardware. Arbitrary network topologies can be implemented by selectively routing address-events to speciﬁc internal or external targets according to a memory-based projective ﬁeld mapping. The utility and versatility of the system is demonstrated by conﬁguring it as a three-stage network that accepts input from an address-event imager, detects salient regions of the image, and performs spatial acuity modulation around a high-resolution fovea that is centered on the location of highest salience. 1</p><br/>
<h2>reference text</h2><p>[1] E. Culurciello, R. Etienne-Cummings, and K. A. Boahen, “A biomorphic digital image sensor,” IEEE J. Solid-State Circuits, vol. 38, no. 2, 2003.</p>
<p>[2] M. Sivilotti, Wiring considerations in analog VLSI systems, with application to ﬁeldprogrammable networks. PhD thesis, California Institute of Technology, Pasadena, CA, 1991.</p>
<p>[3] M. Mahowald, An analog VLSI system for stereoscopic vision. Boston, MA: Kluwer Academic Publishers, 1994.</p>
<p>[4] J. Lazzaro, J. Wawrzynek, M. Mahowald, M. Sivilotti, and D. Gillespie, “Silicon auditory processors as computer peripherals,” IEEE Trans. Neural Networks, vol. 4, no. 3, pp. 523–528, 1993.</p>
<p>[5] K. A. Boahen, “Point-to-point connectivity between neuromorphic chips using address events,” IEEE Trans. Circuits & Systems II, vol. 47, no. 5, pp. 416–434, 2000.</p>
<p>[6] C. M. Higgins and C. Koch, “Multi-chip neuromorphic motion processing,” in Proc. 20th Anniversary Conference on Advanced Research in VLSI (D. S. Wills and S. P. DeWeerth, eds.), (Los Alamitos, CA), pp. 309–323, IEEE Computer Society, 1999. ¨</p>
<p>[7] S.-C. Liu, J. Kramer, G. Indiveri, T. Delbruck, and R. Douglas, “Orientation-selective aVLSI spiking neurons,” in Advances in Neural Information Processing Systems 14 (T. G. Dietterich, S. Becker, and Z. Ghahramani, eds.), Cambridge, MA: MIT Press, 2002.</p>
<p>[8] G. Indiveri, A. M. Whatley, and J. Kramer, “A reconﬁgurable neuromorphic VLSI multi-chip system applied to visual motion computation,” in Proc. MicroNeuro’99, Apr. 1999.</p>
<p>[9] D. H. Goldberg, G. Cauwenberghs, and A. G. Andreou, “Probabilistic synaptic weighting in a reconﬁgurable network of VLSI integrate-and-ﬁre neurons,” Neural Networks, vol. 14, no. 6-7, pp. 781–793, 2001.  (a)  (b)  Figure 7: (a) Stage 3 foveation network. The 32 × 32 pixel high-resolution fovea (center) is surrounded by lower-resolution areas where 2 × 2, 4 × 4, and 8 × 8 blocks of OR neurons (shown as non-overlapping for clarity) project to single IFAT cells. The address space for inputs to the foveation network is 128 × 128. [18]. (b) Output of stage 3, as implemented on the IFAT, with the fovea centered on the location with the maximum ﬁring rate in Figure 6b, from stage 2. Peripheral pixels that receive no input are not shown.</p>
<p>[10] S. R. Deiss, R. J. Douglas, and A. M. Whatley, “A pulse-coded communications infrastructure for neuromorphic systems,” in Pulsed Neural Networks (W. Maass and C. M. Bishop, eds.), pp. 157–178, Cambridge, MA: MIT Press, 1999.</p>
<p>[11] M. Mahowald and R. Douglas, “A silicon neuron,” Nature, vol. 354, pp. 515–518, 1991.</p>
<p>[12] R. J. Vogelstein, F. Tenore, R. Philipp, M. S. Adlerstein, D. H. Goldberg, and G. Cauwenberghs, “Spike timing-dependent plasticity in the address domain,” in Advances in Neural Information Processing Systems 15 (S. Becker, S. Thrun, and K. Obermayer, eds.), Cambridge, MA: MIT Press, 2003.</p>
<p>[13] R. J. Vogelstein, U. Mallik, and G. Cauwenberghs, “Silicon spike-based synaptic array and address-event transceiver,” in Proc. ISCAS’04, vol. 5, (Vancouver, BC), pp. 385–388, 2004.</p>
<p>[14] C. Koch, Biophysics of Computation: Information Processing in Single Neurons. New York, NY: Oxford University Press, 1999.</p>
<p>[15] C. Koch and S. Ullman, “Shifts in selective visual attention: towards the underlying neural circuitry,” Human Neurobiology, vol. 4, pp. 219–227, 1985.</p>
<p>[16] L. Itti, E. Niebur, and C. Koch, “A model of saliency-based fast visual attention for rapid scene analysis,” IEEE Trans. Pattern Analysis & Machine Intelligence, vol. 20, no. 11, pp. 1254–1259, 1998.</p>
<p>[17] T. Horiuchi, T. Morris, C. Koch, and S. P. DeWeerth, “Analog VLSI circuits for attentionbased, visual tracking,” in Advances in Neural Information Processing Systems 9, pp. 706–712, Cambridge, MA: MIT Press, 1997.</p>
<p>[18] R. J. Vogelstein, U. Mallik, E. Culurciello, G. Cauwenberghs, and R. Etienne-Cummings, “Spatial acuity modulation of an address-event imager,” in ICECS’04, 2004.</p>
<p>[19] R. J. Vogelstein, U. Mallik, and G. Cauwenberghs, “Reconﬁgurable silicon array of spiking neurons,” IEEE Trans. Neural Networks, 2005. (Submitted).</p>
<p>[20] E. Culurciello, R. Etienne-Cummings, and K. Boahen, “Second generation of high dynamic range, arbitrated digital imager,” in Proc. ISCAS’04, vol. 4, (Vancouver, BC), pp. 828–831, 2004.</p>
<br/>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
