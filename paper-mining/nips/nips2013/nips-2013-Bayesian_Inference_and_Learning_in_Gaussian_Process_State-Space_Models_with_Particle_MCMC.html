<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>48 nips-2013-Bayesian Inference and Learning in Gaussian Process State-Space Models with Particle MCMC</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-48" href="#">nips2013-48</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>48 nips-2013-Bayesian Inference and Learning in Gaussian Process State-Space Models with Particle MCMC</h1>
<br/><p>Source: <a title="nips-2013-48-pdf" href="http://papers.nips.cc/paper/5085-bayesian-inference-and-learning-in-gaussian-process-state-space-models-with-particle-mcmc.pdf">pdf</a></p><p>Author: Roger Frigola, Fredrik Lindsten, Thomas B. Schon, Carl Rasmussen</p><p>Abstract: State-space models are successfully used in many areas of science, engineering and economics to model time series and dynamical systems. We present a fully Bayesian approach to inference and learning (i.e. state estimation and system identiﬁcation) in nonlinear nonparametric state-space models. We place a Gaussian process prior over the state transition dynamics, resulting in a ﬂexible model able to capture complex dynamical phenomena. To enable efﬁcient inference, we marginalize over the transition dynamics function and, instead, infer directly the joint smoothing distribution using specially tailored Particle Markov Chain Monte Carlo samplers. Once a sample from the smoothing distribution is computed, the state transition predictive distribution can be formulated analytically. Our approach preserves the full nonparametric expressivity of the model and can make use of sparse Gaussian processes to greatly reduce computational complexity. 1</p><p>Reference: <a title="nips-2013-48-reference" href="../nips2013_reference/nips-2013-Bayesian_Inference_and_Learning_in_Gaussian_Process_State-Space_Models_with_Particle_MCMC_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('partic', 0.497), ('gp', 0.358), ('ancest', 0.253), ('xt', 0.247), ('fic', 0.229), ('smooth', 0.176), ('traject', 0.164), ('pga', 0.152), ('dynam', 0.148), ('pmcmc', 0.144), ('transit', 0.122), ('wt', 0.121), ('lindst', 0.115), ('kt', 0.111), ('deisenro', 0.11), ('smc', 0.102), ('xi', 0.1), ('nx', 0.09), ('ssms', 0.086), ('cart', 0.084)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999976 <a title="48-tfidf-1" href="./nips-2013-Bayesian_Inference_and_Learning_in_Gaussian_Process_State-Space_Models_with_Particle_MCMC.html">48 nips-2013-Bayesian Inference and Learning in Gaussian Process State-Space Models with Particle MCMC</a></p>
<p>Author: Roger Frigola, Fredrik Lindsten, Thomas B. Schon, Carl Rasmussen</p><p>Abstract: State-space models are successfully used in many areas of science, engineering and economics to model time series and dynamical systems. We present a fully Bayesian approach to inference and learning (i.e. state estimation and system identiﬁcation) in nonlinear nonparametric state-space models. We place a Gaussian process prior over the state transition dynamics, resulting in a ﬂexible model able to capture complex dynamical phenomena. To enable efﬁcient inference, we marginalize over the transition dynamics function and, instead, infer directly the joint smoothing distribution using specially tailored Particle Markov Chain Monte Carlo samplers. Once a sample from the smoothing distribution is computed, the state transition predictive distribution can be formulated analytically. Our approach preserves the full nonparametric expressivity of the model and can make use of sparse Gaussian processes to greatly reduce computational complexity. 1</p><p>2 0.2569814 <a title="48-tfidf-2" href="./nips-2013-Variational_Inference_for_Mahalanobis_Distance_Metrics_in_Gaussian_Process_Regression.html">346 nips-2013-Variational Inference for Mahalanobis Distance Metrics in Gaussian Process Regression</a></p>
<p>Author: Michalis Titsias, Miguel Lazaro-Gredilla</p><p>Abstract: We introduce a novel variational method that allows to approximately integrate out kernel hyperparameters, such as length-scales, in Gaussian process regression. This approach consists of a novel variant of the variational framework that has been recently developed for the Gaussian process latent variable model which additionally makes use of a standardised representation of the Gaussian process. We consider this technique for learning Mahalanobis distance metrics in a Gaussian process regression setting and provide experimental evaluations and comparisons with existing methods by considering datasets with high-dimensional inputs. 1</p><p>3 0.23476452 <a title="48-tfidf-3" href="./nips-2013-Bayesian_optimization_explains_human_active_search.html">54 nips-2013-Bayesian optimization explains human active search</a></p>
<p>Author: Ali Borji, Laurent Itti</p><p>Abstract: Many real-world problems have complicated objective functions. To optimize such functions, humans utilize sophisticated sequential decision-making strategies. Many optimization algorithms have also been developed for this same purpose, but how do they compare to humans in terms of both performance and behavior? We try to unravel the general underlying algorithm people may be using while searching for the maximum of an invisible 1D function. Subjects click on a blank screen and are shown the ordinate of the function at each clicked abscissa location. Their task is to ﬁnd the function’s maximum in as few clicks as possible. Subjects win if they get close enough to the maximum location. Analysis over 23 non-maths undergraduates, optimizing 25 functions from different families, shows that humans outperform 24 well-known optimization algorithms. Bayesian Optimization based on Gaussian Processes, which exploits all the x values tried and all the f (x) values obtained so far to pick the next x, predicts human performance and searched locations better. In 6 follow-up controlled experiments over 76 subjects, covering interpolation, extrapolation, and optimization tasks, we further conﬁrm that Gaussian Processes provide a general and uniﬁed theoretical account to explain passive and active function learning and search in humans. 1</p><p>4 0.22905675 <a title="48-tfidf-4" href="./nips-2013-Approximate_Gaussian_process_inference_for_the_drift_function_in_stochastic_differential_equations.html">39 nips-2013-Approximate Gaussian process inference for the drift function in stochastic differential equations</a></p>
<p>Author: Andreas Ruttor, Philipp Batz, Manfred Opper</p><p>Abstract: We introduce a nonparametric approach for estimating drift functions in systems of stochastic differential equations from sparse observations of the state vector. Using a Gaussian process prior over the drift as a function of the state vector, we develop an approximate EM algorithm to deal with the unobserved, latent dynamics between observations. The posterior over states is approximated by a piecewise linearized process of the Ornstein-Uhlenbeck type and the MAP estimation of the drift is facilitated by a sparse Gaussian process regression. 1</p><p>5 0.18532193 <a title="48-tfidf-5" href="./nips-2013-Variational_Policy_Search_via_Trajectory_Optimization.html">348 nips-2013-Variational Policy Search via Trajectory Optimization</a></p>
<p>Author: Sergey Levine, Vladlen Koltun</p><p>Abstract: In order to learn effective control policies for dynamical systems, policy search methods must be able to discover successful executions of the desired task. While random exploration can work well in simple domains, complex and highdimensional tasks present a serious challenge, particularly when combined with high-dimensional policies that make parameter-space exploration infeasible. We present a method that uses trajectory optimization as a powerful exploration strategy that guides the policy search. A variational decomposition of a maximum likelihood policy objective allows us to use standard trajectory optimization algorithms such as differential dynamic programming, interleaved with standard supervised learning for the policy itself. We demonstrate that the resulting algorithm can outperform prior methods on two challenging locomotion tasks. 1</p><p>6 0.18317525 <a title="48-tfidf-6" href="./nips-2013-Causal_Inference_on_Time_Series_using_Restricted_Structural_Equation_Models.html">62 nips-2013-Causal Inference on Time Series using Restricted Structural Equation Models</a></p>
<p>7 0.1769944 <a title="48-tfidf-7" href="./nips-2013-Dynamic_Clustering_via_Asymptotics_of_the_Dependent_Dirichlet_Process_Mixture.html">100 nips-2013-Dynamic Clustering via Asymptotics of the Dependent Dirichlet Process Mixture</a></p>
<p>8 0.16277583 <a title="48-tfidf-8" href="./nips-2013-Multi-Task_Bayesian_Optimization.html">201 nips-2013-Multi-Task Bayesian Optimization</a></p>
<p>9 0.1489882 <a title="48-tfidf-9" href="./nips-2013-Learning_a_Deep_Compact_Image_Representation_for_Visual_Tracking.html">163 nips-2013-Learning a Deep Compact Image Representation for Visual Tracking</a></p>
<p>10 0.13898416 <a title="48-tfidf-10" href="./nips-2013-Dimension-Free_Exponentiated_Gradient.html">89 nips-2013-Dimension-Free Exponentiated Gradient</a></p>
<p>11 0.13291332 <a title="48-tfidf-11" href="./nips-2013-Recurrent_linear_models_of_simultaneously-recorded_neural___populations.html">266 nips-2013-Recurrent linear models of simultaneously-recorded neural   populations</a></p>
<p>12 0.12256197 <a title="48-tfidf-12" href="./nips-2013-Learning_Trajectory_Preferences_for__Manipulators_via_Iterative_Improvement.html">162 nips-2013-Learning Trajectory Preferences for  Manipulators via Iterative Improvement</a></p>
<p>13 0.11940721 <a title="48-tfidf-13" href="./nips-2013-Stochastic_Convex_Optimization_with_Multiple__Objectives.html">311 nips-2013-Stochastic Convex Optimization with Multiple  Objectives</a></p>
<p>14 0.11801656 <a title="48-tfidf-14" href="./nips-2013-Actor-Critic_Algorithms_for_Risk-Sensitive_MDPs.html">24 nips-2013-Actor-Critic Algorithms for Risk-Sensitive MDPs</a></p>
<p>15 0.11610261 <a title="48-tfidf-15" href="./nips-2013-A_multi-agent_control_framework_for_co-adaptation_in_brain-computer_interfaces.html">17 nips-2013-A multi-agent control framework for co-adaptation in brain-computer interfaces</a></p>
<p>16 0.11599172 <a title="48-tfidf-16" href="./nips-2013-Regression-tree_Tuning_in_a_Streaming_Setting.html">269 nips-2013-Regression-tree Tuning in a Streaming Setting</a></p>
<p>17 0.1117253 <a title="48-tfidf-17" href="./nips-2013-Locally_Adaptive_Bayesian_Multivariate_Time_Series.html">178 nips-2013-Locally Adaptive Bayesian Multivariate Time Series</a></p>
<p>18 0.11088107 <a title="48-tfidf-18" href="./nips-2013-Auxiliary-variable_Exact_Hamiltonian_Monte_Carlo_Samplers_for_Binary_Distributions.html">43 nips-2013-Auxiliary-variable Exact Hamiltonian Monte Carlo Samplers for Binary Distributions</a></p>
<p>19 0.10997481 <a title="48-tfidf-19" href="./nips-2013-Efficient_Optimization_for_Sparse_Gaussian_Process_Regression.html">105 nips-2013-Efficient Optimization for Sparse Gaussian Process Regression</a></p>
<p>20 0.10936358 <a title="48-tfidf-20" href="./nips-2013-Generalized_Denoising_Auto-Encoders_as_Generative_Models.html">127 nips-2013-Generalized Denoising Auto-Encoders as Generative Models</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.259), (1, -0.006), (2, 0.023), (3, 0.055), (4, -0.037), (5, 0.079), (6, -0.161), (7, -0.015), (8, 0.079), (9, -0.306), (10, 0.046), (11, -0.195), (12, -0.246), (13, 0.143), (14, -0.061), (15, -0.087), (16, -0.109), (17, -0.039), (18, 0.057), (19, -0.173), (20, 0.087), (21, -0.021), (22, -0.005), (23, 0.032), (24, 0.019), (25, -0.022), (26, -0.051), (27, 0.109), (28, 0.038), (29, -0.002), (30, -0.033), (31, -0.04), (32, 0.015), (33, -0.025), (34, 0.03), (35, -0.001), (36, -0.024), (37, 0.069), (38, -0.029), (39, -0.001), (40, 0.01), (41, 0.019), (42, -0.05), (43, -0.072), (44, 0.022), (45, 0.042), (46, -0.001), (47, -0.01), (48, 0.019), (49, 0.037)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.90942633 <a title="48-lsi-1" href="./nips-2013-Bayesian_Inference_and_Learning_in_Gaussian_Process_State-Space_Models_with_Particle_MCMC.html">48 nips-2013-Bayesian Inference and Learning in Gaussian Process State-Space Models with Particle MCMC</a></p>
<p>Author: Roger Frigola, Fredrik Lindsten, Thomas B. Schon, Carl Rasmussen</p><p>Abstract: State-space models are successfully used in many areas of science, engineering and economics to model time series and dynamical systems. We present a fully Bayesian approach to inference and learning (i.e. state estimation and system identiﬁcation) in nonlinear nonparametric state-space models. We place a Gaussian process prior over the state transition dynamics, resulting in a ﬂexible model able to capture complex dynamical phenomena. To enable efﬁcient inference, we marginalize over the transition dynamics function and, instead, infer directly the joint smoothing distribution using specially tailored Particle Markov Chain Monte Carlo samplers. Once a sample from the smoothing distribution is computed, the state transition predictive distribution can be formulated analytically. Our approach preserves the full nonparametric expressivity of the model and can make use of sparse Gaussian processes to greatly reduce computational complexity. 1</p><p>2 0.80767226 <a title="48-lsi-2" href="./nips-2013-Approximate_Gaussian_process_inference_for_the_drift_function_in_stochastic_differential_equations.html">39 nips-2013-Approximate Gaussian process inference for the drift function in stochastic differential equations</a></p>
<p>Author: Andreas Ruttor, Philipp Batz, Manfred Opper</p><p>Abstract: We introduce a nonparametric approach for estimating drift functions in systems of stochastic differential equations from sparse observations of the state vector. Using a Gaussian process prior over the drift as a function of the state vector, we develop an approximate EM algorithm to deal with the unobserved, latent dynamics between observations. The posterior over states is approximated by a piecewise linearized process of the Ornstein-Uhlenbeck type and the MAP estimation of the drift is facilitated by a sparse Gaussian process regression. 1</p><p>3 0.71877927 <a title="48-lsi-3" href="./nips-2013-Variational_Inference_for_Mahalanobis_Distance_Metrics_in_Gaussian_Process_Regression.html">346 nips-2013-Variational Inference for Mahalanobis Distance Metrics in Gaussian Process Regression</a></p>
<p>Author: Michalis Titsias, Miguel Lazaro-Gredilla</p><p>Abstract: We introduce a novel variational method that allows to approximately integrate out kernel hyperparameters, such as length-scales, in Gaussian process regression. This approach consists of a novel variant of the variational framework that has been recently developed for the Gaussian process latent variable model which additionally makes use of a standardised representation of the Gaussian process. We consider this technique for learning Mahalanobis distance metrics in a Gaussian process regression setting and provide experimental evaluations and comparisons with existing methods by considering datasets with high-dimensional inputs. 1</p><p>4 0.70769906 <a title="48-lsi-4" href="./nips-2013-Approximate_inference_in_latent_Gaussian-Markov_models_from_continuous_time_observations.html">41 nips-2013-Approximate inference in latent Gaussian-Markov models from continuous time observations</a></p>
<p>Author: Botond Cseke, Manfred Opper, Guido Sanguinetti</p><p>Abstract: We propose an approximate inference algorithm for continuous time Gaussian Markov process models with both discrete and continuous time likelihoods. We show that the continuous time limit of the expectation propagation algorithm exists and results in a hybrid ﬁxed point iteration consisting of (1) expectation propagation updates for discrete time terms and (2) variational updates for the continuous time term. We introduce postinference corrections methods that improve on the marginals of the approximation. This approach extends the classical Kalman-Bucy smoothing procedure to non-Gaussian observations, enabling continuous-time inference in a variety of models, including spiking neuronal models (state-space models with point process observations) and box likelihood models. Experimental results on real and simulated data demonstrate high distributional accuracy and signiﬁcant computational savings compared to discrete-time approaches in a neural application. 1</p><p>5 0.65115756 <a title="48-lsi-5" href="./nips-2013-Multi-Task_Bayesian_Optimization.html">201 nips-2013-Multi-Task Bayesian Optimization</a></p>
<p>Author: Kevin Swersky, Jasper Snoek, Ryan P. Adams</p><p>Abstract: Bayesian optimization has recently been proposed as a framework for automatically tuning the hyperparameters of machine learning models and has been shown to yield state-of-the-art performance with impressive ease and efﬁciency. In this paper, we explore whether it is possible to transfer the knowledge gained from previous optimizations to new tasks in order to ﬁnd optimal hyperparameter settings more efﬁciently. Our approach is based on extending multi-task Gaussian processes to the framework of Bayesian optimization. We show that this method signiﬁcantly speeds up the optimization process when compared to the standard single-task approach. We further propose a straightforward extension of our algorithm in order to jointly minimize the average error across multiple tasks and demonstrate how this can be used to greatly speed up k-fold cross-validation. Lastly, we propose an adaptation of a recently developed acquisition function, entropy search, to the cost-sensitive, multi-task setting. We demonstrate the utility of this new acquisition function by leveraging a small dataset to explore hyperparameter settings for a large dataset. Our algorithm dynamically chooses which dataset to query in order to yield the most information per unit cost. 1</p><p>6 0.61553997 <a title="48-lsi-6" href="./nips-2013-Bayesian_optimization_explains_human_active_search.html">54 nips-2013-Bayesian optimization explains human active search</a></p>
<p>7 0.61244977 <a title="48-lsi-7" href="./nips-2013-Causal_Inference_on_Time_Series_using_Restricted_Structural_Equation_Models.html">62 nips-2013-Causal Inference on Time Series using Restricted Structural Equation Models</a></p>
<p>8 0.60420358 <a title="48-lsi-8" href="./nips-2013-Efficient_Optimization_for_Sparse_Gaussian_Process_Regression.html">105 nips-2013-Efficient Optimization for Sparse Gaussian Process Regression</a></p>
<p>9 0.59262294 <a title="48-lsi-9" href="./nips-2013-Recurrent_linear_models_of_simultaneously-recorded_neural___populations.html">266 nips-2013-Recurrent linear models of simultaneously-recorded neural   populations</a></p>
<p>10 0.58486015 <a title="48-lsi-10" href="./nips-2013-Locally_Adaptive_Bayesian_Multivariate_Time_Series.html">178 nips-2013-Locally Adaptive Bayesian Multivariate Time Series</a></p>
<p>11 0.5663119 <a title="48-lsi-11" href="./nips-2013-It_is_all_in_the_noise%3A_Efficient_multi-task_Gaussian_process_inference_with_structured_residuals.html">145 nips-2013-It is all in the noise: Efficient multi-task Gaussian process inference with structured residuals</a></p>
<p>12 0.55559343 <a title="48-lsi-12" href="./nips-2013-A_multi-agent_control_framework_for_co-adaptation_in_brain-computer_interfaces.html">17 nips-2013-A multi-agent control framework for co-adaptation in brain-computer interfaces</a></p>
<p>13 0.52045792 <a title="48-lsi-13" href="./nips-2013-Bayesian_inference_for_low_rank_spatiotemporal_neural_receptive_fields.html">53 nips-2013-Bayesian inference for low rank spatiotemporal neural receptive fields</a></p>
<p>14 0.50504714 <a title="48-lsi-14" href="./nips-2013-Small-Variance_Asymptotics_for_Hidden_Markov_Models.html">298 nips-2013-Small-Variance Asymptotics for Hidden Markov Models</a></p>
<p>15 0.48050085 <a title="48-lsi-15" href="./nips-2013-Generalized_Denoising_Auto-Encoders_as_Generative_Models.html">127 nips-2013-Generalized Denoising Auto-Encoders as Generative Models</a></p>
<p>16 0.46169445 <a title="48-lsi-16" href="./nips-2013-Robust_Data-Driven_Dynamic_Programming.html">280 nips-2013-Robust Data-Driven Dynamic Programming</a></p>
<p>17 0.45747742 <a title="48-lsi-17" href="./nips-2013-Variational_Policy_Search_via_Trajectory_Optimization.html">348 nips-2013-Variational Policy Search via Trajectory Optimization</a></p>
<p>18 0.43728268 <a title="48-lsi-18" href="./nips-2013-Dimension-Free_Exponentiated_Gradient.html">89 nips-2013-Dimension-Free Exponentiated Gradient</a></p>
<p>19 0.4307988 <a title="48-lsi-19" href="./nips-2013-Dynamic_Clustering_via_Asymptotics_of_the_Dependent_Dirichlet_Process_Mixture.html">100 nips-2013-Dynamic Clustering via Asymptotics of the Dependent Dirichlet Process Mixture</a></p>
<p>20 0.41767874 <a title="48-lsi-20" href="./nips-2013-Gaussian_Process_Conditional_Copulas_with_Applications_to_Financial_Time_Series.html">126 nips-2013-Gaussian Process Conditional Copulas with Applications to Financial Time Series</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(7, 0.01), (14, 0.198), (20, 0.153), (25, 0.075), (37, 0.057), (47, 0.01), (70, 0.039), (80, 0.134), (86, 0.165), (87, 0.077)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.87826437 <a title="48-lda-1" href="./nips-2013-Sparse_Inverse_Covariance_Estimation_with_Calibration.html">302 nips-2013-Sparse Inverse Covariance Estimation with Calibration</a></p>
<p>Author: Tuo Zhao, Han Liu</p><p>Abstract: We propose a semiparametric method for estimating sparse precision matrix of high dimensional elliptical distribution. The proposed method calibrates regularizations when estimating each column of the precision matrix. Thus it not only is asymptotically tuning free, but also achieves an improved ﬁnite sample performance. Theoretically, we prove that the proposed method achieves the parametric rates of convergence in both parameter estimation and model selection. We present numerical results on both simulated and real datasets to support our theory and illustrate the effectiveness of the proposed estimator. 1</p><p>2 0.86635822 <a title="48-lda-2" href="./nips-2013-Approximate_Bayesian_Image_Interpretation_using_Generative_Probabilistic_Graphics_Programs.html">37 nips-2013-Approximate Bayesian Image Interpretation using Generative Probabilistic Graphics Programs</a></p>
<p>Author: Vikash Mansinghka, Tejas D. Kulkarni, Yura N. Perov, Josh Tenenbaum</p><p>Abstract: The idea of computer vision as the Bayesian inverse problem to computer graphics has a long history and an appealing elegance, but it has proved difﬁcult to directly implement. Instead, most vision tasks are approached via complex bottom-up processing pipelines. Here we show that it is possible to write short, simple probabilistic graphics programs that deﬁne ﬂexible generative models and to automatically invert them to interpret real-world images. Generative probabilistic graphics programs (GPGP) consist of a stochastic scene generator, a renderer based on graphics software, a stochastic likelihood model linking the renderer’s output and the data, and latent variables that adjust the ﬁdelity of the renderer and the tolerance of the likelihood. Representations and algorithms from computer graphics are used as the deterministic backbone for highly approximate and stochastic generative models. This formulation combines probabilistic programming, computer graphics, and approximate Bayesian computation, and depends only on generalpurpose, automatic inference techniques. We describe two applications: reading sequences of degraded and adversarially obscured characters, and inferring 3D road models from vehicle-mounted camera images. Each of the probabilistic graphics programs we present relies on under 20 lines of probabilistic code, and yields accurate, approximately Bayesian inferences about real-world images. 1</p><p>same-paper 3 0.86427331 <a title="48-lda-3" href="./nips-2013-Bayesian_Inference_and_Learning_in_Gaussian_Process_State-Space_Models_with_Particle_MCMC.html">48 nips-2013-Bayesian Inference and Learning in Gaussian Process State-Space Models with Particle MCMC</a></p>
<p>Author: Roger Frigola, Fredrik Lindsten, Thomas B. Schon, Carl Rasmussen</p><p>Abstract: State-space models are successfully used in many areas of science, engineering and economics to model time series and dynamical systems. We present a fully Bayesian approach to inference and learning (i.e. state estimation and system identiﬁcation) in nonlinear nonparametric state-space models. We place a Gaussian process prior over the state transition dynamics, resulting in a ﬂexible model able to capture complex dynamical phenomena. To enable efﬁcient inference, we marginalize over the transition dynamics function and, instead, infer directly the joint smoothing distribution using specially tailored Particle Markov Chain Monte Carlo samplers. Once a sample from the smoothing distribution is computed, the state transition predictive distribution can be formulated analytically. Our approach preserves the full nonparametric expressivity of the model and can make use of sparse Gaussian processes to greatly reduce computational complexity. 1</p><p>4 0.81584322 <a title="48-lda-4" href="./nips-2013-Robust_Sparse_Principal_Component_Regression_under_the_High_Dimensional_Elliptical_Model.html">283 nips-2013-Robust Sparse Principal Component Regression under the High Dimensional Elliptical Model</a></p>
<p>Author: Fang Han, Han Liu</p><p>Abstract: In this paper we focus on the principal component regression and its application to high dimension non-Gaussian data. The major contributions are two folds. First, in low dimensions and under the Gaussian model, by borrowing the strength from recent development in minimax optimal principal component estimation, we ﬁrst time sharply characterize the potential advantage of classical principal component regression over least square estimation. Secondly, we propose and analyze a new robust sparse principal component regression on high dimensional elliptically distributed data. The elliptical distribution is a semiparametric generalization of the Gaussian, including many well known distributions such as multivariate Gaussian, rank-deﬁcient Gaussian, t, Cauchy, and logistic. It allows the random vector to be heavy tailed and have tail dependence. These extra ﬂexibilities make it very suitable for modeling ﬁnance and biomedical imaging data. Under the elliptical model, we prove that our method can estimate the regression coefﬁcients in the optimal parametric rate and therefore is a good alternative to the Gaussian based methods. Experiments on synthetic and real world data are conducted to illustrate the empirical usefulness of the proposed method. 1</p><p>5 0.81459832 <a title="48-lda-5" href="./nips-2013-Actor-Critic_Algorithms_for_Risk-Sensitive_MDPs.html">24 nips-2013-Actor-Critic Algorithms for Risk-Sensitive MDPs</a></p>
<p>Author: Prashanth L.A., Mohammad Ghavamzadeh</p><p>Abstract: In many sequential decision-making problems we may want to manage risk by minimizing some measure of variability in rewards in addition to maximizing a standard criterion. Variance-related risk measures are among the most common risk-sensitive criteria in ﬁnance and operations research. However, optimizing many such criteria is known to be a hard problem. In this paper, we consider both discounted and average reward Markov decision processes. For each formulation, we ﬁrst deﬁne a measure of variability for a policy, which in turn gives us a set of risk-sensitive criteria to optimize. For each of these criteria, we derive a formula for computing its gradient. We then devise actor-critic algorithms for estimating the gradient and updating the policy parameters in the ascent direction. We establish the convergence of our algorithms to locally risk-sensitive optimal policies. Finally, we demonstrate the usefulness of our algorithms in a trafﬁc signal control application. 1</p><p>6 0.81427455 <a title="48-lda-6" href="./nips-2013-Thompson_Sampling_for_1-Dimensional_Exponential_Family_Bandits.html">330 nips-2013-Thompson Sampling for 1-Dimensional Exponential Family Bandits</a></p>
<p>7 0.81418782 <a title="48-lda-7" href="./nips-2013-On_Sampling_from_the_Gibbs_Distribution_with_Random_Maximum_A-Posteriori_Perturbations.html">218 nips-2013-On Sampling from the Gibbs Distribution with Random Maximum A-Posteriori Perturbations</a></p>
<p>8 0.81395292 <a title="48-lda-8" href="./nips-2013-Contrastive_Learning_Using_Spectral_Methods.html">70 nips-2013-Contrastive Learning Using Spectral Methods</a></p>
<p>9 0.81394231 <a title="48-lda-9" href="./nips-2013-Predictive_PAC_Learning_and_Process_Decompositions.html">252 nips-2013-Predictive PAC Learning and Process Decompositions</a></p>
<p>10 0.8138786 <a title="48-lda-10" href="./nips-2013-Computing_the_Stationary_Distribution_Locally.html">66 nips-2013-Computing the Stationary Distribution Locally</a></p>
<p>11 0.81337887 <a title="48-lda-11" href="./nips-2013-Active_Learning_for_Probabilistic_Hypotheses_Using_the_Maximum_Gibbs_Error_Criterion.html">23 nips-2013-Active Learning for Probabilistic Hypotheses Using the Maximum Gibbs Error Criterion</a></p>
<p>12 0.81224692 <a title="48-lda-12" href="./nips-2013-Multiscale_Dictionary_Learning_for_Estimating_Conditional_Distributions.html">204 nips-2013-Multiscale Dictionary Learning for Estimating Conditional Distributions</a></p>
<p>13 0.81207913 <a title="48-lda-13" href="./nips-2013-Local_Privacy_and_Minimax_Bounds%3A_Sharp_Rates_for_Probability_Estimation.html">177 nips-2013-Local Privacy and Minimax Bounds: Sharp Rates for Probability Estimation</a></p>
<p>14 0.81204975 <a title="48-lda-14" href="./nips-2013-Solving_inverse_problem_of_Markov_chain_with_partial_observations.html">299 nips-2013-Solving inverse problem of Markov chain with partial observations</a></p>
<p>15 0.81163728 <a title="48-lda-15" href="./nips-2013-Online_Learning_with_Costly_Features_and_Labels.html">230 nips-2013-Online Learning with Costly Features and Labels</a></p>
<p>16 0.81150424 <a title="48-lda-16" href="./nips-2013-Statistical_analysis_of_coupled_time_series_with_Kernel_Cross-Spectral_Density_operators..html">310 nips-2013-Statistical analysis of coupled time series with Kernel Cross-Spectral Density operators.</a></p>
<p>17 0.81127745 <a title="48-lda-17" href="./nips-2013-Efficient_Exploration_and_Value_Function_Generalization_in_Deterministic_Systems.html">103 nips-2013-Efficient Exploration and Value Function Generalization in Deterministic Systems</a></p>
<p>18 0.81117946 <a title="48-lda-18" href="./nips-2013-Learning_Hidden_Markov_Models_from_Non-sequence_Data_via_Tensor_Decomposition.html">155 nips-2013-Learning Hidden Markov Models from Non-sequence Data via Tensor Decomposition</a></p>
<p>19 0.81103593 <a title="48-lda-19" href="./nips-2013-Adaptive_Submodular_Maximization_in_Bandit_Setting.html">29 nips-2013-Adaptive Submodular Maximization in Bandit Setting</a></p>
<p>20 0.81098104 <a title="48-lda-20" href="./nips-2013-Generalized_Denoising_Auto-Encoders_as_Generative_Models.html">127 nips-2013-Generalized Denoising Auto-Encoders as Generative Models</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
