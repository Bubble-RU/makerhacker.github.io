<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>344 nips-2013-Using multiple samples to learn mixture models</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-344" href="#">nips2013-344</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>344 nips-2013-Using multiple samples to learn mixture models</h1>
<br/><p>Source: <a title="nips-2013-344-pdf" href="http://papers.nips.cc/paper/4915-using-multiple-samples-to-learn-mixture-models.pdf">pdf</a></p><p>Author: Jason Lee, Ran Gilad-Bachrach, Rich Caruana</p><p>Abstract: In the mixture models problem it is assumed that there are K distributions θ1 , . . . , θK and one gets to observe a sample from a mixture of these distributions with unknown coeﬃcients. The goal is to associate instances with their generating distributions, or to identify the parameters of the hidden distributions. In this work we make the assumption that we have access to several samples drawn from the same K underlying distributions, but with diﬀerent mixing weights. As with topic modeling, having multiple samples is often a reasonable assumption. Instead of pooling the data into one sample, we prove that it is possible to use the diﬀerences between the samples to better recover the underlying structure. We present algorithms that recover the underlying structure under milder assumptions than the current state of art when either the dimensionality or the separation is high. The methods, when applied to topic modeling, allow generalization to words not present in the training data. 1</p><p>Reference: <a title="nips-2013-344-reference" href="../nips2013_reference/nips-2013-Using_multiple_samples_to_learn_mixture_models_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('dsc', 0.523), ('msp', 0.484), ('di', 0.343), ('mixt', 0.257), ('coe', 0.207), ('clust', 0.167), ('ej', 0.144), ('tm', 0.127), ('mm', 0.111), ('project', 0.109), ('vempal', 0.084), ('patch', 0.078), ('span', 0.074), ('sep', 0.071), ('orang', 0.07), ('kan', 0.068), ('nj', 0.066), ('sj', 0.064), ('disjoint', 0.064), ('ci', 0.059)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="344-tfidf-1" href="./nips-2013-Using_multiple_samples_to_learn_mixture_models.html">344 nips-2013-Using multiple samples to learn mixture models</a></p>
<p>2 0.17866422 <a title="344-tfidf-2" href="./nips-2013-Minimax_Theory_for_High-dimensional_Gaussian_Mixtures_with_Sparse_Mean_Separation.html">192 nips-2013-Minimax Theory for High-dimensional Gaussian Mixtures with Sparse Mean Separation</a></p>
<p>3 0.11725011 <a title="344-tfidf-3" href="./nips-2013-Parallel_Sampling_of_DP_Mixture_Models_using_Sub-Cluster_Splits.html">243 nips-2013-Parallel Sampling of DP Mixture Models using Sub-Cluster Splits</a></p>
<p>4 0.099457771 <a title="344-tfidf-4" href="./nips-2013-Learning_Multiple_Models_via_Regularized_Weighting.html">158 nips-2013-Learning Multiple Models via Regularized Weighting</a></p>
<p>5 0.098619133 <a title="344-tfidf-5" href="./nips-2013-Variational_Planning_for_Graph-based_MDPs.html">347 nips-2013-Variational Planning for Graph-based MDPs</a></p>
<p>6 0.097951367 <a title="344-tfidf-6" href="./nips-2013-Cluster_Trees_on_Manifolds.html">63 nips-2013-Cluster Trees on Manifolds</a></p>
<p>7 0.093840048 <a title="344-tfidf-7" href="./nips-2013-Dynamic_Clustering_via_Asymptotics_of_the_Dependent_Dirichlet_Process_Mixture.html">100 nips-2013-Dynamic Clustering via Asymptotics of the Dependent Dirichlet Process Mixture</a></p>
<p>8 0.093042158 <a title="344-tfidf-8" href="./nips-2013-Online_Learning_of_Nonparametric_Mixture_Models_via_Sequential_Variational_Approximation.html">229 nips-2013-Online Learning of Nonparametric Mixture Models via Sequential Variational Approximation</a></p>
<p>9 0.090527706 <a title="344-tfidf-9" href="./nips-2013-Probabilistic_Low-Rank_Matrix_Completion_with_Adaptive_Spectral_Regularization_Algorithms.html">254 nips-2013-Probabilistic Low-Rank Matrix Completion with Adaptive Spectral Regularization Algorithms</a></p>
<p>10 0.090422459 <a title="344-tfidf-10" href="./nips-2013-Mid-level_Visual_Element_Discovery_as_Discriminative_Mode_Seeking.html">190 nips-2013-Mid-level Visual Element Discovery as Discriminative Mode Seeking</a></p>
<p>11 0.090277694 <a title="344-tfidf-11" href="./nips-2013-A_simple_example_of_Dirichlet_process_mixture_inconsistency_for_the_number_of_components.html">18 nips-2013-A simple example of Dirichlet process mixture inconsistency for the number of components</a></p>
<p>12 0.085544899 <a title="344-tfidf-12" href="./nips-2013-Regression-tree_Tuning_in_a_Streaming_Setting.html">269 nips-2013-Regression-tree Tuning in a Streaming Setting</a></p>
<p>13 0.084688529 <a title="344-tfidf-13" href="./nips-2013-RNADE%3A_The_real-valued_neural_autoregressive_density-estimator.html">260 nips-2013-RNADE: The real-valued neural autoregressive density-estimator</a></p>
<p>14 0.069324724 <a title="344-tfidf-14" href="./nips-2013-Predictive_PAC_Learning_and_Process_Decompositions.html">252 nips-2013-Predictive PAC Learning and Process Decompositions</a></p>
<p>15 0.068247594 <a title="344-tfidf-15" href="./nips-2013-A_Latent_Source_Model_for_Nonparametric_Time_Series_Classification.html">10 nips-2013-A Latent Source Model for Nonparametric Time Series Classification</a></p>
<p>16 0.06625706 <a title="344-tfidf-16" href="./nips-2013-Which_Space_Partitioning_Tree_to_Use_for_Search%3F.html">355 nips-2013-Which Space Partitioning Tree to Use for Search?</a></p>
<p>17 0.064542077 <a title="344-tfidf-17" href="./nips-2013-Generalized_Method-of-Moments_for_Rank_Aggregation.html">128 nips-2013-Generalized Method-of-Moments for Rank Aggregation</a></p>
<p>18 0.063841395 <a title="344-tfidf-18" href="./nips-2013-Analyzing_the_Harmonic_Structure_in_Graph-Based_Learning.html">35 nips-2013-Analyzing the Harmonic Structure in Graph-Based Learning</a></p>
<p>19 0.063463494 <a title="344-tfidf-19" href="./nips-2013-Optimizing_Instructional_Policies.html">241 nips-2013-Optimizing Instructional Policies</a></p>
<p>20 0.063021392 <a title="344-tfidf-20" href="./nips-2013-Summary_Statistics_for_Partitionings_and_Feature_Allocations.html">320 nips-2013-Summary Statistics for Partitionings and Feature Allocations</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.158), (1, 0.051), (2, 0.029), (3, -0.047), (4, -0.057), (5, 0.048), (6, 0.001), (7, 0.068), (8, 0.044), (9, -0.008), (10, -0.083), (11, 0.058), (12, 0.049), (13, 0.096), (14, 0.039), (15, 0.111), (16, 0.057), (17, 0.058), (18, -0.176), (19, -0.012), (20, -0.013), (21, -0.042), (22, -0.023), (23, -0.114), (24, -0.081), (25, -0.027), (26, -0.041), (27, 0.149), (28, -0.039), (29, -0.037), (30, 0.081), (31, 0.008), (32, -0.001), (33, -0.016), (34, 0.075), (35, -0.014), (36, -0.043), (37, -0.054), (38, 0.007), (39, -0.045), (40, -0.024), (41, -0.01), (42, -0.054), (43, -0.039), (44, -0.1), (45, -0.045), (46, 0.009), (47, 0.048), (48, -0.078), (49, -0.098)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.89952183 <a title="344-lsi-1" href="./nips-2013-Using_multiple_samples_to_learn_mixture_models.html">344 nips-2013-Using multiple samples to learn mixture models</a></p>
<p>2 0.74430919 <a title="344-lsi-2" href="./nips-2013-Minimax_Theory_for_High-dimensional_Gaussian_Mixtures_with_Sparse_Mean_Separation.html">192 nips-2013-Minimax Theory for High-dimensional Gaussian Mixtures with Sparse Mean Separation</a></p>
<p>3 0.72637439 <a title="344-lsi-3" href="./nips-2013-A_simple_example_of_Dirichlet_process_mixture_inconsistency_for_the_number_of_components.html">18 nips-2013-A simple example of Dirichlet process mixture inconsistency for the number of components</a></p>
<p>4 0.6865952 <a title="344-lsi-4" href="./nips-2013-RNADE%3A_The_real-valued_neural_autoregressive_density-estimator.html">260 nips-2013-RNADE: The real-valued neural autoregressive density-estimator</a></p>
<p>5 0.68079495 <a title="344-lsi-5" href="./nips-2013-Cluster_Trees_on_Manifolds.html">63 nips-2013-Cluster Trees on Manifolds</a></p>
<p>6 0.64906955 <a title="344-lsi-6" href="./nips-2013-Parallel_Sampling_of_DP_Mixture_Models_using_Sub-Cluster_Splits.html">243 nips-2013-Parallel Sampling of DP Mixture Models using Sub-Cluster Splits</a></p>
<p>7 0.61568725 <a title="344-lsi-7" href="./nips-2013-Optimistic_Concurrency_Control_for_Distributed_Unsupervised_Learning.html">238 nips-2013-Optimistic Concurrency Control for Distributed Unsupervised Learning</a></p>
<p>8 0.60118037 <a title="344-lsi-8" href="./nips-2013-Dynamic_Clustering_via_Asymptotics_of_the_Dependent_Dirichlet_Process_Mixture.html">100 nips-2013-Dynamic Clustering via Asymptotics of the Dependent Dirichlet Process Mixture</a></p>
<p>9 0.56053519 <a title="344-lsi-9" href="./nips-2013-Online_Learning_of_Nonparametric_Mixture_Models_via_Sequential_Variational_Approximation.html">229 nips-2013-Online Learning of Nonparametric Mixture Models via Sequential Variational Approximation</a></p>
<p>10 0.54298902 <a title="344-lsi-10" href="./nips-2013-Latent_Maximum_Margin_Clustering.html">148 nips-2013-Latent Maximum Margin Clustering</a></p>
<p>11 0.53717232 <a title="344-lsi-11" href="./nips-2013-Predictive_PAC_Learning_and_Process_Decompositions.html">252 nips-2013-Predictive PAC Learning and Process Decompositions</a></p>
<p>12 0.52212811 <a title="344-lsi-12" href="./nips-2013-Learning_Multiple_Models_via_Regularized_Weighting.html">158 nips-2013-Learning Multiple Models via Regularized Weighting</a></p>
<p>13 0.50407767 <a title="344-lsi-13" href="./nips-2013-k-Prototype_Learning_for_3D_Rigid_Structures.html">357 nips-2013-k-Prototype Learning for 3D Rigid Structures</a></p>
<p>14 0.48034379 <a title="344-lsi-14" href="./nips-2013-A_Latent_Source_Model_for_Nonparametric_Time_Series_Classification.html">10 nips-2013-A Latent Source Model for Nonparametric Time Series Classification</a></p>
<p>15 0.47808111 <a title="344-lsi-15" href="./nips-2013-Moment-based_Uniform_Deviation_Bounds_for_%24k%24-means_and_Friends.html">197 nips-2013-Moment-based Uniform Deviation Bounds for $k$-means and Friends</a></p>
<p>16 0.47171545 <a title="344-lsi-16" href="./nips-2013-Memoized_Online_Variational_Inference_for_Dirichlet_Process_Mixture_Models.html">187 nips-2013-Memoized Online Variational Inference for Dirichlet Process Mixture Models</a></p>
<p>17 0.46992943 <a title="344-lsi-17" href="./nips-2013-Binary_to_Bushy%3A_Bayesian_Hierarchical_Clustering_with_the_Beta_Coalescent.html">58 nips-2013-Binary to Bushy: Bayesian Hierarchical Clustering with the Beta Coalescent</a></p>
<p>18 0.46806732 <a title="344-lsi-18" href="./nips-2013-Distributed_%24k%24-means_and_%24k%24-median_Clustering_on_General_Topologies.html">94 nips-2013-Distributed $k$-means and $k$-median Clustering on General Topologies</a></p>
<p>19 0.44948354 <a title="344-lsi-19" href="./nips-2013-Contrastive_Learning_Using_Spectral_Methods.html">70 nips-2013-Contrastive Learning Using Spectral Methods</a></p>
<p>20 0.44826198 <a title="344-lsi-20" href="./nips-2013-Provable_Subspace_Clustering%3A_When_LRR_meets_SSC.html">259 nips-2013-Provable Subspace Clustering: When LRR meets SSC</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(20, 0.197), (25, 0.095), (37, 0.053), (70, 0.045), (77, 0.049), (80, 0.127), (86, 0.098), (87, 0.062), (89, 0.168)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.95914352 <a title="344-lda-1" href="./nips-2013-More_Effective_Distributed_ML_via_a_Stale_Synchronous_Parallel_Parameter_Server.html">198 nips-2013-More Effective Distributed ML via a Stale Synchronous Parallel Parameter Server</a></p>
<p>2 0.94767463 <a title="344-lda-2" href="./nips-2013-On_the_Complexity_and_Approximation_of_Binary_Evidence_in_Lifted_Inference.html">220 nips-2013-On the Complexity and Approximation of Binary Evidence in Lifted Inference</a></p>
<p>same-paper 3 0.87848288 <a title="344-lda-3" href="./nips-2013-Using_multiple_samples_to_learn_mixture_models.html">344 nips-2013-Using multiple samples to learn mixture models</a></p>
<p>4 0.87762845 <a title="344-lda-4" href="./nips-2013-Learning_to_Pass_Expectation_Propagation_Messages.html">168 nips-2013-Learning to Pass Expectation Propagation Messages</a></p>
<p>5 0.87094957 <a title="344-lda-5" href="./nips-2013-Online_PCA_for_Contaminated_Data.html">232 nips-2013-Online PCA for Contaminated Data</a></p>
<p>6 0.84810102 <a title="344-lda-6" href="./nips-2013-Learning_Multiple_Models_via_Regularized_Weighting.html">158 nips-2013-Learning Multiple Models via Regularized Weighting</a></p>
<p>7 0.84717464 <a title="344-lda-7" href="./nips-2013-Blind_Calibration_in_Compressed_Sensing_using_Message_Passing_Algorithms.html">59 nips-2013-Blind Calibration in Compressed Sensing using Message Passing Algorithms</a></p>
<p>8 0.84565169 <a title="344-lda-8" href="./nips-2013-Multi-Task_Bayesian_Optimization.html">201 nips-2013-Multi-Task Bayesian Optimization</a></p>
<p>9 0.84553671 <a title="344-lda-9" href="./nips-2013-A_message-passing_algorithm_for_multi-agent_trajectory_planning.html">16 nips-2013-A message-passing algorithm for multi-agent trajectory planning</a></p>
<p>10 0.84522289 <a title="344-lda-10" href="./nips-2013-Variational_Inference_for_Mahalanobis_Distance_Metrics_in_Gaussian_Process_Regression.html">346 nips-2013-Variational Inference for Mahalanobis Distance Metrics in Gaussian Process Regression</a></p>
<p>11 0.84488064 <a title="344-lda-11" href="./nips-2013-Convex_Calibrated_Surrogates_for_Low-Rank_Loss_Matrices_with_Applications_to_Subset_Ranking_Losses.html">72 nips-2013-Convex Calibrated Surrogates for Low-Rank Loss Matrices with Applications to Subset Ranking Losses</a></p>
<p>12 0.84462219 <a title="344-lda-12" href="./nips-2013-Which_Space_Partitioning_Tree_to_Use_for_Search%3F.html">355 nips-2013-Which Space Partitioning Tree to Use for Search?</a></p>
<p>13 0.84376782 <a title="344-lda-13" href="./nips-2013-Robust_learning_of_low-dimensional_dynamics_from_large_neural_ensembles.html">286 nips-2013-Robust learning of low-dimensional dynamics from large neural ensembles</a></p>
<p>14 0.84311008 <a title="344-lda-14" href="./nips-2013-EDML_for_Learning_Parameters_in_Directed_and_Undirected_Graphical_Models.html">101 nips-2013-EDML for Learning Parameters in Directed and Undirected Graphical Models</a></p>
<p>15 0.8424595 <a title="344-lda-15" href="./nips-2013-What_do_row_and_column_marginals_reveal_about_your_dataset%3F.html">352 nips-2013-What do row and column marginals reveal about your dataset?</a></p>
<p>16 0.8418116 <a title="344-lda-16" href="./nips-2013-Analyzing_Hogwild_Parallel_Gaussian_Gibbs_Sampling.html">34 nips-2013-Analyzing Hogwild Parallel Gaussian Gibbs Sampling</a></p>
<p>17 0.8415308 <a title="344-lda-17" href="./nips-2013-B-test%3A_A_Non-parametric%2C_Low_Variance_Kernel_Two-sample_Test.html">44 nips-2013-B-test: A Non-parametric, Low Variance Kernel Two-sample Test</a></p>
<p>18 0.84118193 <a title="344-lda-18" href="./nips-2013-Optimistic_policy_iteration_and_natural_actor-critic%3A_A_unifying_view_and_a_non-optimality_result.html">239 nips-2013-Optimistic policy iteration and natural actor-critic: A unifying view and a non-optimality result</a></p>
<p>19 0.84087574 <a title="344-lda-19" href="./nips-2013-Statistical_analysis_of_coupled_time_series_with_Kernel_Cross-Spectral_Density_operators..html">310 nips-2013-Statistical analysis of coupled time series with Kernel Cross-Spectral Density operators.</a></p>
<p>20 0.84082735 <a title="344-lda-20" href="./nips-2013-Spectral_methods_for_neural_characterization_using_generalized_quadratic_models.html">305 nips-2013-Spectral methods for neural characterization using generalized quadratic models</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
