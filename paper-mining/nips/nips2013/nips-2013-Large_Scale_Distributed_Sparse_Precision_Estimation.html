<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>146 nips-2013-Large Scale Distributed Sparse Precision Estimation</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-146" href="#">nips2013-146</a> knowledge-graph by maker-knowledge-mining</p><h1>146 nips-2013-Large Scale Distributed Sparse Precision Estimation</h1>
<br/><p>Source: <a title="nips-2013-146-pdf" href="http://papers.nips.cc/paper/5037-large-scale-distributed-sparse-precision-estimation.pdf">pdf</a></p><p>Author: Huahua Wang, Arindam Banerjee, Cho-Jui Hsieh, Pradeep Ravikumar, Inderjit Dhillon</p><p>Abstract: We consider the problem of sparse precision matrix estimation in high dimensions using the CLIME estimator, which has several desirable theoretical properties. We present an inexact alternating direction method of multiplier (ADMM) algorithm for CLIME, and establish rates of convergence for both the objective and optimality conditions. Further, we develop a large scale distributed framework for the computations, which scales to millions of dimensions and trillions of parameters, using hundreds of cores. The proposed framework solves CLIME in columnblocks and only involves elementwise operations and parallel matrix multiplications. We evaluate our algorithm on both shared-memory and distributed-memory architectures, which can use block cyclic distribution of data and parameters to achieve load balance and improve the efÔ¨Åciency in the use of memory hierarchies. Experimental results show that our algorithm is substantially more scalable than state-of-the-art methods and scales almost linearly with the number of cores. 1</p><p>Reference: <a title="nips-2013-146-reference" href="../nips2013_reference/nips-2013-Large_Scale_Distributed_Sparse_Precision_Estimation_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('clim', 0.386), ('block', 0.383), ('speedup', 0.282), ('cor', 0.252), ('yt', 0.202), ('precid', 0.199), ('adm', 0.186), ('zt', 0.164), ('column', 0.162), ('cx', 0.149), ('matrix', 0.139), ('vt', 0.123), ('ut', 0.119), ('load', 0.115), ('tig', 0.112), ('spars', 0.103), ('parallel', 0.1), ('xij', 0.099), ('xt', 0.097), ('cach', 0.095)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="146-tfidf-1" href="./nips-2013-Large_Scale_Distributed_Sparse_Precision_Estimation.html">146 nips-2013-Large Scale Distributed Sparse Precision Estimation</a></p>
<p>2 0.18452603 <a title="146-tfidf-2" href="./nips-2013-BIG_%26_QUIC%3A_Sparse_Inverse_Covariance_Estimation_for_a_Million_Variables.html">45 nips-2013-BIG & QUIC: Sparse Inverse Covariance Estimation for a Million Variables</a></p>
<p>3 0.17501727 <a title="146-tfidf-3" href="./nips-2013-Recurrent_linear_models_of_simultaneously-recorded_neural___populations.html">266 nips-2013-Recurrent linear models of simultaneously-recorded neural   populations</a></p>
<p>4 0.14294872 <a title="146-tfidf-4" href="./nips-2013-Sparse_Inverse_Covariance_Estimation_with_Calibration.html">302 nips-2013-Sparse Inverse Covariance Estimation with Calibration</a></p>
<p>5 0.12732603 <a title="146-tfidf-5" href="./nips-2013-Robust_learning_of_low-dimensional_dynamics_from_large_neural_ensembles.html">286 nips-2013-Robust learning of low-dimensional dynamics from large neural ensembles</a></p>
<p>6 0.11901964 <a title="146-tfidf-6" href="./nips-2013-Extracting_regions_of_interest_from_biological_images_with_convolutional_sparse_block_coding.html">114 nips-2013-Extracting regions of interest from biological images with convolutional sparse block coding</a></p>
<p>7 0.11849151 <a title="146-tfidf-7" href="./nips-2013-Memory_Limited%2C_Streaming_PCA.html">188 nips-2013-Memory Limited, Streaming PCA</a></p>
<p>8 0.11837588 <a title="146-tfidf-8" href="./nips-2013-Small-Variance_Asymptotics_for_Hidden_Markov_Models.html">298 nips-2013-Small-Variance Asymptotics for Hidden Markov Models</a></p>
<p>9 0.11831351 <a title="146-tfidf-9" href="./nips-2013-Fantope_Projection_and_Selection%3A_A_near-optimal_convex_relaxation_of_sparse_PCA.html">116 nips-2013-Fantope Projection and Selection: A near-optimal convex relaxation of sparse PCA</a></p>
<p>10 0.11299863 <a title="146-tfidf-10" href="./nips-2013-Speeding_up_Permutation_Testing_in_Neuroimaging.html">306 nips-2013-Speeding up Permutation Testing in Neuroimaging</a></p>
<p>11 0.10994563 <a title="146-tfidf-11" href="./nips-2013-Causal_Inference_on_Time_Series_using_Restricted_Structural_Equation_Models.html">62 nips-2013-Causal Inference on Time Series using Restricted Structural Equation Models</a></p>
<p>12 0.10815442 <a title="146-tfidf-12" href="./nips-2013-Near-Optimal_Entrywise_Sampling_for_Data_Matrices.html">206 nips-2013-Near-Optimal Entrywise Sampling for Data Matrices</a></p>
<p>13 0.10395391 <a title="146-tfidf-13" href="./nips-2013-Actor-Critic_Algorithms_for_Risk-Sensitive_MDPs.html">24 nips-2013-Actor-Critic Algorithms for Risk-Sensitive MDPs</a></p>
<p>14 0.10076043 <a title="146-tfidf-14" href="./nips-2013-Error-Minimizing_Estimates_and_Universal_Entry-Wise_Error_Bounds_for_Low-Rank_Matrix_Completion.html">108 nips-2013-Error-Minimizing Estimates and Universal Entry-Wise Error Bounds for Low-Rank Matrix Completion</a></p>
<p>15 0.095394209 <a title="146-tfidf-15" href="./nips-2013-Summary_Statistics_for_Partitionings_and_Feature_Allocations.html">320 nips-2013-Summary Statistics for Partitionings and Feature Allocations</a></p>
<p>16 0.09513256 <a title="146-tfidf-16" href="./nips-2013-Analyzing_Hogwild_Parallel_Gaussian_Gibbs_Sampling.html">34 nips-2013-Analyzing Hogwild Parallel Gaussian Gibbs Sampling</a></p>
<p>17 0.094770305 <a title="146-tfidf-17" href="./nips-2013-Supervised_Sparse_Analysis_and_Synthesis_Operators.html">321 nips-2013-Supervised Sparse Analysis and Synthesis Operators</a></p>
<p>18 0.092570305 <a title="146-tfidf-18" href="./nips-2013-Robust_Multimodal_Graph_Matching%3A_Sparse_Coding_Meets_Graph_Matching.html">282 nips-2013-Robust Multimodal Graph Matching: Sparse Coding Meets Graph Matching</a></p>
<p>19 0.091333523 <a title="146-tfidf-19" href="./nips-2013-Predicting_Parameters_in_Deep_Learning.html">251 nips-2013-Predicting Parameters in Deep Learning</a></p>
<p>20 0.090255216 <a title="146-tfidf-20" href="./nips-2013-Robust_Data-Driven_Dynamic_Programming.html">280 nips-2013-Robust Data-Driven Dynamic Programming</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.227), (1, 0.06), (2, 0.049), (3, 0.005), (4, 0.012), (5, 0.09), (6, -0.093), (7, -0.021), (8, -0.033), (9, -0.052), (10, 0.084), (11, -0.042), (12, 0.035), (13, 0.081), (14, -0.146), (15, -0.043), (16, -0.101), (17, -0.008), (18, 0.041), (19, 0.134), (20, 0.104), (21, -0.065), (22, 0.061), (23, 0.052), (24, -0.042), (25, 0.057), (26, -0.1), (27, -0.036), (28, -0.066), (29, 0.047), (30, 0.029), (31, 0.03), (32, 0.013), (33, 0.032), (34, -0.042), (35, -0.191), (36, -0.061), (37, 0.03), (38, -0.031), (39, -0.181), (40, -0.041), (41, -0.07), (42, 0.031), (43, 0.139), (44, 0.009), (45, 0.003), (46, 0.037), (47, 0.015), (48, -0.073), (49, -0.029)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94605851 <a title="146-lsi-1" href="./nips-2013-Large_Scale_Distributed_Sparse_Precision_Estimation.html">146 nips-2013-Large Scale Distributed Sparse Precision Estimation</a></p>
<p>2 0.79706633 <a title="146-lsi-2" href="./nips-2013-BIG_%26_QUIC%3A_Sparse_Inverse_Covariance_Estimation_for_a_Million_Variables.html">45 nips-2013-BIG & QUIC: Sparse Inverse Covariance Estimation for a Million Variables</a></p>
<p>3 0.68948758 <a title="146-lsi-3" href="./nips-2013-More_Effective_Distributed_ML_via_a_Stale_Synchronous_Parallel_Parameter_Server.html">198 nips-2013-More Effective Distributed ML via a Stale Synchronous Parallel Parameter Server</a></p>
<p>4 0.66961658 <a title="146-lsi-4" href="./nips-2013-Recurrent_linear_models_of_simultaneously-recorded_neural___populations.html">266 nips-2013-Recurrent linear models of simultaneously-recorded neural   populations</a></p>
<p>5 0.63981044 <a title="146-lsi-5" href="./nips-2013-On_Algorithms_for_Sparse_Multi-factor_NMF.html">214 nips-2013-On Algorithms for Sparse Multi-factor NMF</a></p>
<p>6 0.63368452 <a title="146-lsi-6" href="./nips-2013-What_do_row_and_column_marginals_reveal_about_your_dataset%3F.html">352 nips-2013-What do row and column marginals reveal about your dataset?</a></p>
<p>7 0.61123836 <a title="146-lsi-7" href="./nips-2013-Matrix_factorization_with_binary_components.html">186 nips-2013-Matrix factorization with binary components</a></p>
<p>8 0.56097168 <a title="146-lsi-8" href="./nips-2013-Sparse_Inverse_Covariance_Estimation_with_Calibration.html">302 nips-2013-Sparse Inverse Covariance Estimation with Calibration</a></p>
<p>9 0.54798472 <a title="146-lsi-9" href="./nips-2013-Stochastic_blockmodel_approximation_of_a_graphon%3A_Theory_and_consistent_estimation.html">316 nips-2013-Stochastic blockmodel approximation of a graphon: Theory and consistent estimation</a></p>
<p>10 0.54677284 <a title="146-lsi-10" href="./nips-2013-Phase_Retrieval_using_Alternating_Minimization.html">247 nips-2013-Phase Retrieval using Alternating Minimization</a></p>
<p>11 0.54507798 <a title="146-lsi-11" href="./nips-2013-Speeding_up_Permutation_Testing_in_Neuroimaging.html">306 nips-2013-Speeding up Permutation Testing in Neuroimaging</a></p>
<p>12 0.54069412 <a title="146-lsi-12" href="./nips-2013-Robust_Data-Driven_Dynamic_Programming.html">280 nips-2013-Robust Data-Driven Dynamic Programming</a></p>
<p>13 0.53853893 <a title="146-lsi-13" href="./nips-2013-Causal_Inference_on_Time_Series_using_Restricted_Structural_Equation_Models.html">62 nips-2013-Causal Inference on Time Series using Restricted Structural Equation Models</a></p>
<p>14 0.53751922 <a title="146-lsi-14" href="./nips-2013-Approximate_inference_in_latent_Gaussian-Markov_models_from_continuous_time_observations.html">41 nips-2013-Approximate inference in latent Gaussian-Markov models from continuous time observations</a></p>
<p>15 0.53667694 <a title="146-lsi-15" href="./nips-2013-Sketching_Structured_Matrices_for_Faster_Nonlinear_Regression.html">297 nips-2013-Sketching Structured Matrices for Faster Nonlinear Regression</a></p>
<p>16 0.53255928 <a title="146-lsi-16" href="./nips-2013-Stochastic_Optimization_of_PCA_with_Capped_MSG.html">314 nips-2013-Stochastic Optimization of PCA with Capped MSG</a></p>
<p>17 0.53037649 <a title="146-lsi-17" href="./nips-2013-Fast_Algorithms_for_Gaussian_Noise_Invariant_Independent_Component_Analysis.html">117 nips-2013-Fast Algorithms for Gaussian Noise Invariant Independent Component Analysis</a></p>
<p>18 0.52503955 <a title="146-lsi-18" href="./nips-2013-Analyzing_Hogwild_Parallel_Gaussian_Gibbs_Sampling.html">34 nips-2013-Analyzing Hogwild Parallel Gaussian Gibbs Sampling</a></p>
<p>19 0.52346528 <a title="146-lsi-19" href="./nips-2013-Memory_Limited%2C_Streaming_PCA.html">188 nips-2013-Memory Limited, Streaming PCA</a></p>
<p>20 0.51925993 <a title="146-lsi-20" href="./nips-2013-Robust_learning_of_low-dimensional_dynamics_from_large_neural_ensembles.html">286 nips-2013-Robust learning of low-dimensional dynamics from large neural ensembles</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(20, 0.206), (25, 0.128), (37, 0.07), (70, 0.034), (80, 0.099), (86, 0.125), (87, 0.045), (90, 0.214)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.88432723 <a title="146-lda-1" href="./nips-2013-Sketching_Structured_Matrices_for_Faster_Nonlinear_Regression.html">297 nips-2013-Sketching Structured Matrices for Faster Nonlinear Regression</a></p>
<p>same-paper 2 0.87111062 <a title="146-lda-2" href="./nips-2013-Large_Scale_Distributed_Sparse_Precision_Estimation.html">146 nips-2013-Large Scale Distributed Sparse Precision Estimation</a></p>
<p>3 0.86642134 <a title="146-lda-3" href="./nips-2013-A_Comparative_Framework_for_Preconditioned_Lasso_Algorithms.html">4 nips-2013-A Comparative Framework for Preconditioned Lasso Algorithms</a></p>
<p>4 0.84617811 <a title="146-lda-4" href="./nips-2013-Multi-Task_Bayesian_Optimization.html">201 nips-2013-Multi-Task Bayesian Optimization</a></p>
<p>5 0.81294554 <a title="146-lda-5" href="./nips-2013-Structured_Learning_via_Logistic_Regression.html">318 nips-2013-Structured Learning via Logistic Regression</a></p>
<p>6 0.8111226 <a title="146-lda-6" href="./nips-2013-Accelerating_Stochastic_Gradient_Descent_using_Predictive_Variance_Reduction.html">20 nips-2013-Accelerating Stochastic Gradient Descent using Predictive Variance Reduction</a></p>
<p>7 0.81003165 <a title="146-lda-7" href="./nips-2013-Trading_Computation_for_Communication%3A_Distributed_Stochastic_Dual_Coordinate_Ascent.html">333 nips-2013-Trading Computation for Communication: Distributed Stochastic Dual Coordinate Ascent</a></p>
<p>8 0.80973184 <a title="146-lda-8" href="./nips-2013-Information-theoretic_lower_bounds_for_distributed_statistical_estimation_with_communication_constraints.html">142 nips-2013-Information-theoretic lower bounds for distributed statistical estimation with communication constraints</a></p>
<p>9 0.8094517 <a title="146-lda-9" href="./nips-2013-Online_Learning_with_Costly_Features_and_Labels.html">230 nips-2013-Online Learning with Costly Features and Labels</a></p>
<p>10 0.80945122 <a title="146-lda-10" href="./nips-2013-BIG_%26_QUIC%3A_Sparse_Inverse_Covariance_Estimation_for_a_Million_Variables.html">45 nips-2013-BIG & QUIC: Sparse Inverse Covariance Estimation for a Million Variables</a></p>
<p>11 0.80899221 <a title="146-lda-11" href="./nips-2013-Stochastic_Majorization-Minimization_Algorithms_for_Large-Scale_Optimization.html">313 nips-2013-Stochastic Majorization-Minimization Algorithms for Large-Scale Optimization</a></p>
<p>12 0.80898005 <a title="146-lda-12" href="./nips-2013-Mixed_Optimization_for_Smooth_Functions.html">193 nips-2013-Mixed Optimization for Smooth Functions</a></p>
<p>13 0.8086949 <a title="146-lda-13" href="./nips-2013-Curvature_and_Optimal_Algorithms_for_Learning_and_Minimizing_Submodular_Functions.html">78 nips-2013-Curvature and Optimal Algorithms for Learning and Minimizing Submodular Functions</a></p>
<p>14 0.8075189 <a title="146-lda-14" href="./nips-2013-Fantope_Projection_and_Selection%3A_A_near-optimal_convex_relaxation_of_sparse_PCA.html">116 nips-2013-Fantope Projection and Selection: A near-optimal convex relaxation of sparse PCA</a></p>
<p>15 0.80724114 <a title="146-lda-15" href="./nips-2013-Convex_Tensor_Decomposition_via_Structured_Schatten_Norm_Regularization.html">74 nips-2013-Convex Tensor Decomposition via Structured Schatten Norm Regularization</a></p>
<p>16 0.80714637 <a title="146-lda-16" href="./nips-2013-An_Approximate%2C_Efficient_LP_Solver_for_LP_Rounding.html">33 nips-2013-An Approximate, Efficient LP Solver for LP Rounding</a></p>
<p>17 0.80600774 <a title="146-lda-17" href="./nips-2013-A_Stability-based_Validation_Procedure_for_Differentially_Private_Machine_Learning.html">14 nips-2013-A Stability-based Validation Procedure for Differentially Private Machine Learning</a></p>
<p>18 0.8058489 <a title="146-lda-18" href="./nips-2013-Robust_Low_Rank_Kernel_Embeddings_of_Multivariate_Distributions.html">281 nips-2013-Robust Low Rank Kernel Embeddings of Multivariate Distributions</a></p>
<p>19 0.80577779 <a title="146-lda-19" href="./nips-2013-Better_Approximation_and_Faster_Algorithm_Using_the_Proximal_Average.html">56 nips-2013-Better Approximation and Faster Algorithm Using the Proximal Average</a></p>
<p>20 0.80566442 <a title="146-lda-20" href="./nips-2013-A_New_Convex_Relaxation_for_Tensor_Completion.html">11 nips-2013-A New Convex Relaxation for Tensor Completion</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
