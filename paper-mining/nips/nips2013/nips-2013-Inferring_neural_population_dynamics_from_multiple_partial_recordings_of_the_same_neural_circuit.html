<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>141 nips-2013-Inferring neural population dynamics from multiple partial recordings of the same neural circuit</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-141" href="#">nips2013-141</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>141 nips-2013-Inferring neural population dynamics from multiple partial recordings of the same neural circuit</h1>
<br/><p>Source: <a title="nips-2013-141-pdf" href="http://papers.nips.cc/paper/4874-inferring-neural-population-dynamics-from-multiple-partial-recordings-of-the-same-neural-circuit.pdf">pdf</a></p><p>Author: Srini Turaga, Lars Buesing, Adam M. Packer, Henry Dalgleish, Noah Pettit, Michael Hausser, Jakob Macke</p><p>Abstract: Simultaneous recordings of the activity of large neural populations are extremely valuable as they can be used to infer the dynamics and interactions of neurons in a local circuit, shedding light on the computations performed. It is now possible to measure the activity of hundreds of neurons using 2-photon calcium imaging. However, many computations are thought to involve circuits consisting of thousands of neurons, such as cortical barrels in rodent somatosensory cortex. Here we contribute a statistical method for “stitching” together sequentially imaged sets of neurons into one model by phrasing the problem as ﬁtting a latent dynamical system with missing observations. This method allows us to substantially expand the population-sizes for which population dynamics can be characterized—beyond the number of simultaneously imaged neurons. In particular, we demonstrate using recordings in mouse somatosensory cortex that this method makes it possible to predict noise correlations between non-simultaneously recorded neuron pairs. 1</p><p>Reference: <a title="nips-2013-141-reference" href="../nips2013_reference/nips-2013-Inferring_neural_population_dynamics_from_multiple_partial_recordings_of_the_same_neural_circuit_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 It is now possible to measure the activity of hundreds of neurons using 2-photon calcium imaging. [sent-5, score-0.82]
</p><p>2 Here we contribute a statistical method for “stitching” together sequentially imaged sets of neurons into one model by phrasing the problem as ﬁtting a latent dynamical system with missing observations. [sent-7, score-0.82]
</p><p>3 This method allows us to substantially expand the population-sizes for which population dynamics can be characterized—beyond the number of simultaneously imaged neurons. [sent-8, score-0.571]
</p><p>4 In particular, we demonstrate using recordings in mouse somatosensory cortex that this method makes it possible to predict noise correlations between non-simultaneously recorded neuron pairs. [sent-9, score-0.759]
</p><p>5 1  Introduction  The computation performed by a neural circuit is a product of the properties of single neurons in the circuit and their connectivity. [sent-10, score-0.566]
</p><p>6 Simultaneous measurements of the collective dynamics of all neurons in a neural circuit will help us understand their function and test theories of neural computation. [sent-11, score-0.677]
</p><p>7 Recent progress in 2-photon calcium imaging now allows for recording of the activity of hundreds of neurons nearly simultaneously [1, 2]. [sent-13, score-1.116]
</p><p>8 To illustrate our method consider the following example: A whisker barrel in the mouse somatosensory cortex consists of a few thousand neurons responding to stimuli from one whisker. [sent-16, score-0.806]
</p><p>9 But since nearby neurons couple strongly to one another [3], by moving the microscope to nearby locations, one can expect to image neurons which are directly coupled to the ﬁrst population of neurons. [sent-18, score-0.97]
</p><p>10 In this paper we address the following question: Could we characterize the joint dynamics of the ﬁrst and second populations of neurons, even though they were not imaged simultaneously? [sent-19, score-0.482]
</p><p>11 uk  1  a  imaging session 1  b  imaging session 2  couplings (A)  simultaneously measured pairs non-simultaneously measured pairs  Figure 1: Inferring neuronal interactions from non-simultaneous measurements. [sent-26, score-1.187]
</p><p>12 a) If two subsets of a neural population can only be recorded from in two separate imaging sessions, can we infer the connectivity across the sub-populations (red connections)? [sent-27, score-0.68]
</p><p>13 b) We want to infer the functional connectivity matrix, and in particular those entries which correspond to pairs of neurons that were not simultaneously measured (red off-diagonal block). [sent-28, score-0.661]
</p><p>14 populations of neurons even if many of the neurons have not been imaged simultaneously. [sent-30, score-1.191]
</p><p>15 In sensory cortical neurons, where large variability in the evoked response is observed [4, 5], our model can successfully predict the magnitude of (so-called) noise correlations between non-simultaneously recorded neurons. [sent-31, score-0.485]
</p><p>16 Numerous studies have addressed the question of inferring functional connectivity from 2-photon imaging data [6, 7] or electrophysiological measurements [8, 9, 10, 11]. [sent-34, score-0.468]
</p><p>17 These approaches include detailed models of the relationship between ﬂuorescence measurements, calcium transients and spiking activity [6] as well as model-free information-theoretic approaches [7]. [sent-35, score-0.464]
</p><p>18 2  Methods  Our goal is to estimate a joint model of the activity of a neural population which captures the correlation structure and stimulus selectivity of the population from partial observations of the population activity. [sent-43, score-0.85]
</p><p>19 1  A latent dynamical system model for combining multiple measurements of population activity  Linear dynamics. [sent-47, score-0.555]
</p><p>20 We denote by xk the activity of N neurons in the population on recording session k, and model its dynamics as linear with Gaussian innovations in discrete time, 2  xk = Axk + Buk + ηt , t t−1 t  where ηt ∼ N (0, Q). [sent-48, score-1.131]
</p><p>21 (1)  Here, the N × N coupling matrix A models correlations across neurons and time. [sent-49, score-0.758]
</p><p>22 An entry Aij being non-zero implies that activity of neuron j at time t has a statistical inﬂuence on the activity of neuron i on the next time-step t + 1, but does not necessarily imply a direct synaptic connection. [sent-50, score-0.616]
</p><p>23 While this model does not capture the nonlinear and non-Gaussian cascade of neural couplings, calcium dynamics, ﬂuorescence measurements and imaging noise [16, 6], we will show that this model nevertheless is able to predict correlations across non-simultaneously observed pairs of neurons. [sent-66, score-0.98]
</p><p>24 In each imaging session k we measure the activity of Nk neurons simultaneously, where Nk is smaller than the total number of neurons N . [sent-68, score-1.321]
</p><p>25 Since these measurements are noisy and incomplete observations of the full state vector, the true underlying activity of all neurons xk is treated as a latent variable. [sent-69, score-0.732]
</p><p>26 The vector of the Nk measurements at time t in session k is denoted t k as yt and is related to the underlying population activity by k yt = C k (xk + d + t ) t  t  ∼ N (0, R),  (2)  where the ‘measurement matrix’ C k is of size Nk × N . [sent-70, score-0.609]
</p><p>27 One can also envisage using our model with dimensions of xk which are never observed– such latent dimensions would then model correlated noise or the t input from unobserved neurons into the population [17, 18]. [sent-73, score-0.767]
</p><p>28 Furthermore, χk := i Cij is 1 if neuron j was imaged in session k and 0 j k otherwise, nj = k χk is the total number of sessions in which neuron j was imaged and σj is the j index of the recording site of neuron j during session k. [sent-79, score-1.365]
</p><p>29 We simulated a population of 60 neurons which were split into 3 pools (’cell types’) of 20 neurons each, with both connection probability and strength being cell-type speciﬁc. [sent-83, score-0.988]
</p><p>30 After shufﬂing the ordering of neurons (resulting in the connectivity matrix displayed in Fig. [sent-89, score-0.493]
</p><p>31 We then pretended that the population was imaged in two sessions with non-overlapping subsets of 30 neurons each (Figure 2a, green outlined blocks) of K = 5 trials each, and that observation noise was uncorrelated and very small, std( ii ) = 0. [sent-91, score-1.035]
</p><p>32 We also applied the stitching method to two calcium imaging datasets recorded in the somatosensory cortex of awake or anesthetized mice. [sent-94, score-1.272]
</p><p>33 We imaged calcium signals in the superﬁcial layers of mouse barrel cortex (S1) in-vivo using 2-photon laser scanning microscopy [1]. [sent-95, score-0.733]
</p><p>34 The anesthetized dataset was collected during an experiment in which the C2 whisker of an anesthetized mouse was repeatedly ﬂicked randomly in one of three different directions (rostrally, caudally or ventrally). [sent-97, score-0.421]
</p><p>35 About 200 neurons were imaged for about 27min at a depth of 240µm in the C2 whisker barrel. [sent-98, score-0.789]
</p><p>36 In this session, about 80 neurons were imaged for about 55min at a depth of 190µm, also in the C2 whisker barrel. [sent-100, score-0.789]
</p><p>37 To evaluate how well stitching works on real data, we created a ﬁctional imaging scenario. [sent-105, score-0.553]
</p><p>38 We pretended that the neurons, which were in reality simultaneously imaged, were not imaged in one session but instead were ‘imaged’ in two subsets in two different sessions. [sent-106, score-0.536]
</p><p>39 The subsets corresponding to different ‘sessions’ c = 60% of the neurons, meaning that the subsets overlapped and a few neurons in common. [sent-107, score-0.449]
</p><p>40 We then used our stitching method to predict pairwise correlations from the ﬁctional imaging session. [sent-111, score-0.799]
</p><p>41 In lieu of ground-truth on the real data, we ﬁt a ‘fully observed’ model to the simulatenous imaging data of all neurons (which would be impossible of course in practice, but is possible in our ﬁctional imaging scenario). [sent-115, score-0.801]
</p><p>42 We set coefﬁcients of nonsimultaneously recorded pairs to 0 and averaged coefﬁcients for neurons which were part of both imaging sessions (in the c = 60% scenario). [sent-117, score-0.898]
</p><p>43 Certainly we can not expect to do better at predicting correlations, than if we had observed all neurons simultaneously. [sent-119, score-0.482]
</p><p>44 3  Results  We tested our ability to stitch multiple observations into one coherent model which is capable of predicting statistics of the joint dynamics, such as correlations across non-simultaneously imaged 4  a  true couplings  naive couplings  b  noise correlations  stitched  0. [sent-120, score-1.67]
</p><p>45 5  stitched estimate  stitched couplings  true  stitching estimate  c  0  true  0. [sent-123, score-0.955]
</p><p>46 a) A coupling matrix for 60 neurons arranged in 3 blocks was generated (true coupling matrix) and shufﬂed. [sent-129, score-0.689]
</p><p>47 We simulated the imaging of non-overlapping subsets of 30 neurons each in two sessions. [sent-130, score-0.664]
</p><p>48 b) Noise correlations estimated by our stitching method match true noise correlations well. [sent-132, score-0.836]
</p><p>49 c) Couplings between non-simultaneously imaged neuron pairs (red off-diagonal block) are estimated well by our method. [sent-133, score-0.486]
</p><p>50 We ﬁrst apply our method to a synthetic dataset to explain its properties, and then demonstrate that it works for real calcium imaging measurements from the mouse somatosensory cortex. [sent-135, score-0.708]
</p><p>51 1  Inferring correlations and model parameters in a simulated population  It might seem counterintuitive that one can infer the cross-couplings, and hence noise-correlations, between neurons observed in separate sessions. [sent-137, score-0.884]
</p><p>52 An intuition for why this might work nevertheless can gained by considering the artiﬁcial scenario of a network of linearly interacting neurons driven by Gaussian noise: Suppose that during the ﬁrst recording session we image half of these neurons. [sent-138, score-0.613]
</p><p>53 Our stitching method was able to recover the true coupling matrix, including the off-diagonal blocks which correspond to pairs of neurons that were not imaged simultaneously (see red-outlined blocks in 2a, bottom middle). [sent-145, score-1.338]
</p><p>54 As expected, recovery was better for couplings across observed pairs (correlation between true and estimated parameters 0. [sent-146, score-0.43]
</p><p>55 With the “naive” approach couplings between non-simultaneously observed pairs cannot be recovered, and even for simultaneously observed pairs, the estimate of couplings is biased (correlation 0. [sent-149, score-0.742]
</p><p>56 We also quantiﬁed the degree to which we are able to predict statistics of the joint dynamics of the whole network, in particular noise correlations across pairs of neurons that were never observed simultaneously. [sent-152, score-0.899]
</p><p>57 We calculated noise correlations by computing correlations in variability of neural activity after subtracting contributions due to the stimulus. [sent-153, score-0.707]
</p><p>58 We found that the stitching method was able to accurately recover the noise-correlations of nonsimultaneously recorded pairs (correlation between predicted and true correlations was 0. [sent-154, score-0.799]
</p><p>59 In fact, we generally found the prediction of correlations to be more accurate than prediction 5  fully observed  stitched  naive  b  fully observed  0. [sent-156, score-0.677]
</p><p>60 3  Figure 3: Examples of correlation and coupling recovery in the anesthetized calcium imaging experiments. [sent-166, score-0.756]
</p><p>61 a) Coupling matrices ﬁt to calcium signal using all neurons (fully observed) or ﬁt after “imaging” two overlapping subsets of 60% neurons each (stitched and naive). [sent-167, score-1.079]
</p><p>62 b) Scatter plot of coupling terms for “non-simultaneously imaged” neuron pairs estimated using the stitching method vs the fully observed estimates. [sent-169, score-0.771]
</p><p>63 d) Scatter plot of correlations in c for “non-simultaneously imaged” neuron pairs estimated using the stitching and the naive approaches. [sent-171, score-0.863]
</p><p>64 (We note that, as the stimulus drive in this simulation was very weak, inferring noise correlations from stimulus correlations [12] would be impossible). [sent-174, score-0.689]
</p><p>65 Given activity measurements from a subset of neurons, our method can predict the activity of neurons in the unobserved subset. [sent-176, score-0.912]
</p><p>66 In contrast, the ’naive’ approach can only utilize the stimulus, but not the activity of the observed population for prediction and therefore only achieved a correlation of 0. [sent-190, score-0.457]
</p><p>67 2  Inferring correlations in mouse somatosensory cortex  Next, we applied our stitching method to two real datasets: anesthetized and awake (described in Section 2. [sent-194, score-1.024]
</p><p>68 Figure 3a displays coupling matrices of a population consisting of the 50 most correlated neurons in the anesthetized dataset (see Section 2. [sent-198, score-0.839]
</p><p>69 Our stitching method yielded a coupling matrix with structure similar to the fully observed model (Figure 3a, central panel), even in the off-diagonal blocks which correspond to nonsimultaneously recorded pairs. [sent-200, score-0.765]
</p><p>70 In contrast, the naive method, by deﬁnition, is unable to infer couplings for non-simultaneously recorded pairs, and therefore over-estimates the magnitude of observed couplings (Figure 3a, right panel). [sent-201, score-0.826]
</p><p>71 Even for non-simultaneously recorded pairs, the stitched model predicted couplings which were correlated with the fully observed predictions (Figure 3b, correlation 0. [sent-202, score-0.774]
</p><p>72 6  a  predicting correlations  b  predicting neural activity  0. [sent-204, score-0.51]
</p><p>73 2  20  40  60  80  population size  Figure 4: Recovering correlations and coupling parameters in a real calcium imaging experiments. [sent-225, score-0.949]
</p><p>74 100 neurons were simultaneously imaged in an anesthetized mouse (top row) and an awake mouse (bottom row). [sent-226, score-1.116]
</p><p>75 a) Pairwise correlations for “non-simultaneously imaged” neuron pairs estimated by the “naive” and our ”stitched” strategies compared to correlations predicted by a model ﬁt to all neurons (”full obs“). [sent-230, score-1.031]
</p><p>76 c) Comparison of estimated couplings for “non-simultaneously imaged” neuron pairs to those estimated using the “fully observed” model. [sent-232, score-0.49]
</p><p>77 We found that our stitching method, but not the naive method, was able to accurately reconstruct these correlations (Figure 3c). [sent-235, score-0.667]
</p><p>78 As expected, the naive method strongly under-estimated correlations in the non-simultaneously recorded blocks, as it can only model stimulus-correlations but not noise-correlations across neurons. [sent-236, score-0.458]
</p><p>79 1 In contrast, our stitching method predicted correlations well, matching those of the fully observed model (correlation 0. [sent-237, score-0.678]
</p><p>80 We found that for both datasets, the correlations predicted by the stitching method for non-simultaneously recorded pairs were similar to the fully observed ones, and that this similarity is almost independent of population size (Figure 4a). [sent-245, score-0.997]
</p><p>81 The stitching method also substantially outperformed the naive approach, for which the similarity was lower by a factor of about 2. [sent-247, score-0.458]
</p><p>82 We compared the accuracy of the models at predicting the neural activity of one subset of neurons given the stimulus and the activity of the other subset (Figure 4b). [sent-248, score-0.917]
</p><p>83 We ﬁnd that our model makes signiﬁcantly better predictions than the lower bound naive model, whose performance comes from modeling the stimulus and neurons in the overlap between both subsets. [sent-249, score-0.639]
</p><p>84 Indeed for the more active and correlated awake dataset, predictions are nearly as good as those of the fully observed 1 The naive approach also over-estimated correlations within each view. [sent-250, score-0.583]
</p><p>85 This is a consequence of biases resulting from averaging couplings across views for neurons in the overlap between the two ﬁctional sessions. [sent-251, score-0.725]
</p><p>86 We also found that prediction accuracy increased slightly with population size, perhaps since a larger population provides more neurons from which the activity of the other subset can be predicted. [sent-253, score-0.903]
</p><p>87 While we have no access to the true cross-couplings for the real data, we can nonetheless compare the couplings from our stitched model to those estimated by the fully observed model. [sent-255, score-0.557]
</p><p>88 We ﬁnd that the stitching model is indeed able to estimate couplings that correlate positively with the fully observed couplings, even for non-simultaneously imaged neuron pairs. [sent-256, score-1.118]
</p><p>89 These theoretical results suggest that while only measuring the activity of one population of neurons, we can infer the activity of a second neural population that strongly interacts with the ﬁrst, up to re-parametrization. [sent-259, score-0.781]
</p><p>90 We applied our method to analyze 2-photon population calcium imaging measurements from the superﬁcial layers of the somatosensory cortex of both anesthetized and awake mice, and found that our method was able to successfully combine data not accessed simultaneously. [sent-263, score-1.064]
</p><p>91 In this paper, we focused our demonstration to stitching together two populations of neurons. [sent-265, score-0.464]
</p><p>92 We found that some overlap was critical for stitching to work, and increasing overlap improves stitching performance. [sent-268, score-0.766]
</p><p>93 Nevertheless, more realistic models [16, 6] can help improve the accuracy of these predictions and disentangle the contributions of spiking activity, calcium dynamics, ﬂuorescence measurements and imaging noise to the observed statistics. [sent-272, score-0.671]
</p><p>94 We note that our model can easily be extended to model potential common input from neurons which are never observed [13] as a low dimensional LDS [17, 18]. [sent-275, score-0.44]
</p><p>95 The simultaneous measurement of the activity of all neurons in a neural circuit will shed much light on the nature of neural computation. [sent-276, score-0.735]
</p><p>96 While there is much progress in developing faster imaging modalities, there are fundamental physical limits to the number of neurons which can be simultaneously imaged. [sent-277, score-0.638]
</p><p>97 With more powerful algorithmic tools, we can imagine mapping population dynamics of all the neurons in an entire neural circuit such as the zebraﬁsh larval olfactory bulb, or layers 2 & 3 of a whisker barrel— an ambitious goal which has until now been out of reach. [sent-279, score-0.842]
</p><p>98 Paninski, “A bayesian approach for inferring neuronal connectivity from calcium ﬂuorescent imaging data,” The Annals of Applied Statistics, vol. [sent-330, score-0.655]
</p><p>99 Geisel, “Model-free reconstruction of excitatory neuronal connectivity from calcium imaging signals,” PLoS Comp Bio, vol. [sent-338, score-0.62]
</p><p>100 Paninski, “Spike inference from calcium imaging using sequential monte carlo methods,” Biophysical Journal, vol. [sent-425, score-0.447]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('neurons', 0.393), ('stitching', 0.349), ('imaged', 0.29), ('couplings', 0.272), ('calcium', 0.243), ('correlations', 0.209), ('imaging', 0.204), ('activity', 0.184), ('stitched', 0.167), ('population', 0.163), ('session', 0.147), ('coupling', 0.13), ('anesthetized', 0.116), ('populations', 0.115), ('neuron', 0.111), ('awake', 0.11), ('naive', 0.109), ('somatosensory', 0.107), ('whisker', 0.106), ('connectivity', 0.1), ('recorded', 0.093), ('sessions', 0.084), ('mouse', 0.083), ('stimulus', 0.081), ('dynamical', 0.077), ('dynamics', 0.077), ('measurements', 0.071), ('circuit', 0.07), ('barrel', 0.067), ('pairs', 0.063), ('correlation', 0.063), ('inferring', 0.062), ('ctional', 0.061), ('nonsimultaneously', 0.061), ('xk', 0.058), ('recording', 0.051), ('cortex', 0.05), ('fully', 0.049), ('noise', 0.047), ('observed', 0.047), ('comp', 0.046), ('uorescence', 0.046), ('neuronal', 0.046), ('paninski', 0.045), ('unobserved', 0.043), ('predicting', 0.042), ('simultaneously', 0.041), ('simulated', 0.039), ('spiking', 0.037), ('correlated', 0.037), ('predict', 0.037), ('blocks', 0.036), ('overlap', 0.034), ('system', 0.034), ('lds', 0.033), ('infer', 0.033), ('neural', 0.033), ('anatomical', 0.032), ('functional', 0.031), ('neurosci', 0.03), ('bio', 0.03), ('buk', 0.03), ('mishchenko', 0.03), ('obs', 0.03), ('pretended', 0.03), ('turbulence', 0.03), ('unshuffle', 0.03), ('circuits', 0.029), ('connections', 0.029), ('subsets', 0.028), ('bingen', 0.028), ('excitatory', 0.027), ('stitch', 0.027), ('cortical', 0.027), ('latent', 0.026), ('pillow', 0.026), ('across', 0.026), ('synaptic', 0.026), ('variability', 0.025), ('curran', 0.025), ('imagined', 0.025), ('uorescent', 0.025), ('nu', 0.025), ('roi', 0.025), ('gatsby', 0.025), ('nk', 0.024), ('predicted', 0.024), ('nj', 0.023), ('predictions', 0.022), ('overlapping', 0.022), ('measurement', 0.022), ('yt', 0.022), ('recordings', 0.022), ('driven', 0.022), ('estimated', 0.022), ('litke', 0.021), ('simoncelli', 0.021), ('vogelstein', 0.021), ('strongly', 0.021), ('dendritic', 0.02)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.9999997 <a title="141-tfidf-1" href="./nips-2013-Inferring_neural_population_dynamics_from_multiple_partial_recordings_of_the_same_neural_circuit.html">141 nips-2013-Inferring neural population dynamics from multiple partial recordings of the same neural circuit</a></p>
<p>Author: Srini Turaga, Lars Buesing, Adam M. Packer, Henry Dalgleish, Noah Pettit, Michael Hausser, Jakob Macke</p><p>Abstract: Simultaneous recordings of the activity of large neural populations are extremely valuable as they can be used to infer the dynamics and interactions of neurons in a local circuit, shedding light on the computations performed. It is now possible to measure the activity of hundreds of neurons using 2-photon calcium imaging. However, many computations are thought to involve circuits consisting of thousands of neurons, such as cortical barrels in rodent somatosensory cortex. Here we contribute a statistical method for “stitching” together sequentially imaged sets of neurons into one model by phrasing the problem as ﬁtting a latent dynamical system with missing observations. This method allows us to substantially expand the population-sizes for which population dynamics can be characterized—beyond the number of simultaneously imaged neurons. In particular, we demonstrate using recordings in mouse somatosensory cortex that this method makes it possible to predict noise correlations between non-simultaneously recorded neuron pairs. 1</p><p>2 0.28354505 <a title="141-tfidf-2" href="./nips-2013-Sparse_nonnegative_deconvolution_for_compressive_calcium_imaging%3A_algorithms_and_phase_transitions.html">304 nips-2013-Sparse nonnegative deconvolution for compressive calcium imaging: algorithms and phase transitions</a></p>
<p>Author: Eftychios A. Pnevmatikakis, Liam Paninski</p><p>Abstract: We propose a compressed sensing (CS) calcium imaging framework for monitoring large neuronal populations, where we image randomized projections of the spatial calcium concentration at each timestep, instead of measuring the concentration at individual locations. We develop scalable nonnegative deconvolution methods for extracting the neuronal spike time series from such observations. We also address the problem of demixing the spatial locations of the neurons using rank-penalized matrix factorization methods. By exploiting the sparsity of neural spiking we demonstrate that the number of measurements needed per timestep is signiﬁcantly smaller than the total number of neurons, a result that can potentially enable imaging of larger populations at considerably faster rates compared to traditional raster-scanning techniques. Unlike traditional CS setups, our problem involves a block-diagonal sensing matrix and a non-orthogonal sparse basis that spans multiple timesteps. We provide tight approximations to the number of measurements needed for perfect deconvolution for certain classes of spiking processes, and show that this number undergoes a “phase transition,” which we characterize using modern tools relating conic geometry to compressed sensing. 1</p><p>3 0.26692826 <a title="141-tfidf-3" href="./nips-2013-A_Determinantal_Point_Process_Latent_Variable_Model_for_Inhibition_in_Neural_Spiking_Data.html">6 nips-2013-A Determinantal Point Process Latent Variable Model for Inhibition in Neural Spiking Data</a></p>
<p>Author: Jasper Snoek, Richard Zemel, Ryan P. Adams</p><p>Abstract: Point processes are popular models of neural spiking behavior as they provide a statistical distribution over temporal sequences of spikes and help to reveal the complexities underlying a series of recorded action potentials. However, the most common neural point process models, the Poisson process and the gamma renewal process, do not capture interactions and correlations that are critical to modeling populations of neurons. We develop a novel model based on a determinantal point process over latent embeddings of neurons that effectively captures and helps visualize complex inhibitory and competitive interaction. We show that this model is a natural extension of the popular generalized linear model to sets of interacting neurons. The model is extended to incorporate gain control or divisive normalization, and the modulation of neural spiking based on periodic phenomena. Applied to neural spike recordings from the rat hippocampus, we see that the model captures inhibitory relationships, a dichotomy of classes of neurons, and a periodic modulation by the theta rhythm known to be present in the data. 1</p><p>4 0.21885498 <a title="141-tfidf-4" href="./nips-2013-Bayesian_Inference_and_Online_Experimental_Design_for_Mapping_Neural_Microcircuits.html">49 nips-2013-Bayesian Inference and Online Experimental Design for Mapping Neural Microcircuits</a></p>
<p>Author: Ben Shababo, Brooks Paige, Ari Pakman, Liam Paninski</p><p>Abstract: With the advent of modern stimulation techniques in neuroscience, the opportunity arises to map neuron to neuron connectivity. In this work, we develop a method for efﬁciently inferring posterior distributions over synaptic strengths in neural microcircuits. The input to our algorithm is data from experiments in which action potentials from putative presynaptic neurons can be evoked while a subthreshold recording is made from a single postsynaptic neuron. We present a realistic statistical model which accounts for the main sources of variability in this experiment and allows for signiﬁcant prior information about the connectivity and neuronal cell types to be incorporated if available. Due to the technical challenges and sparsity of these systems, it is important to focus experimental time stimulating the neurons whose synaptic strength is most ambiguous, therefore we also develop an online optimal design algorithm for choosing which neurons to stimulate at each trial. 1</p><p>5 0.20410848 <a title="141-tfidf-5" href="./nips-2013-Robust_learning_of_low-dimensional_dynamics_from_large_neural_ensembles.html">286 nips-2013-Robust learning of low-dimensional dynamics from large neural ensembles</a></p>
<p>Author: David Pfau, Eftychios A. Pnevmatikakis, Liam Paninski</p><p>Abstract: Recordings from large populations of neurons make it possible to search for hypothesized low-dimensional dynamics. Finding these dynamics requires models that take into account biophysical constraints and can be ﬁt efﬁciently and robustly. Here, we present an approach to dimensionality reduction for neural data that is convex, does not make strong assumptions about dynamics, does not require averaging over many trials and is extensible to more complex statistical models that combine local and global inﬂuences. The results can be combined with spectral methods to learn dynamical systems models. The basic method extends PCA to the exponential family using nuclear norm minimization. We evaluate the effectiveness of this method using an exact decomposition of the Bregman divergence that is analogous to variance explained for PCA. We show on model data that the parameters of latent linear dynamical systems can be recovered, and that even if the dynamics are not stationary we can still recover the true latent subspace. We also demonstrate an extension of nuclear norm minimization that can separate sparse local connections from global latent dynamics. Finally, we demonstrate improved prediction on real neural data from monkey motor cortex compared to ﬁtting linear dynamical models without nuclear norm smoothing. 1</p><p>6 0.20249866 <a title="141-tfidf-6" href="./nips-2013-Learning_Multi-level_Sparse_Representations.html">157 nips-2013-Learning Multi-level Sparse Representations</a></p>
<p>7 0.18220909 <a title="141-tfidf-7" href="./nips-2013-Correlations_strike_back_%28again%29%3A_the_case_of_associative_memory_retrieval.html">77 nips-2013-Correlations strike back (again): the case of associative memory retrieval</a></p>
<p>8 0.17611752 <a title="141-tfidf-8" href="./nips-2013-Firing_rate_predictions_in_optimal_balanced_networks.html">121 nips-2013-Firing rate predictions in optimal balanced networks</a></p>
<p>9 0.1677482 <a title="141-tfidf-9" href="./nips-2013-Optimal_Neural_Population_Codes_for_High-dimensional_Stimulus_Variables.html">236 nips-2013-Optimal Neural Population Codes for High-dimensional Stimulus Variables</a></p>
<p>10 0.15669596 <a title="141-tfidf-10" href="./nips-2013-Neural_representation_of_action_sequences%3A_how_far_can_a_simple_snippet-matching_model_take_us%3F.html">208 nips-2013-Neural representation of action sequences: how far can a simple snippet-matching model take us?</a></p>
<p>11 0.155779 <a title="141-tfidf-11" href="./nips-2013-Real-Time_Inference_for_a_Gamma_Process_Model_of_Neural_Spiking.html">262 nips-2013-Real-Time Inference for a Gamma Process Model of Neural Spiking</a></p>
<p>12 0.15409486 <a title="141-tfidf-12" href="./nips-2013-Recurrent_networks_of_coupled_Winner-Take-All_oscillators_for_solving_constraint_satisfaction_problems.html">267 nips-2013-Recurrent networks of coupled Winner-Take-All oscillators for solving constraint satisfaction problems</a></p>
<p>13 0.14486611 <a title="141-tfidf-13" href="./nips-2013-Noise-Enhanced_Associative_Memories.html">210 nips-2013-Noise-Enhanced Associative Memories</a></p>
<p>14 0.12820706 <a title="141-tfidf-14" href="./nips-2013-Extracting_regions_of_interest_from_biological_images_with_convolutional_sparse_block_coding.html">114 nips-2013-Extracting regions of interest from biological images with convolutional sparse block coding</a></p>
<p>15 0.12575954 <a title="141-tfidf-15" href="./nips-2013-Compete_to_Compute.html">64 nips-2013-Compete to Compute</a></p>
<p>16 0.10081164 <a title="141-tfidf-16" href="./nips-2013-Recurrent_linear_models_of_simultaneously-recorded_neural___populations.html">266 nips-2013-Recurrent linear models of simultaneously-recorded neural   populations</a></p>
<p>17 0.099630676 <a title="141-tfidf-17" href="./nips-2013-Hierarchical_Modular_Optimization_of_Convolutional_Networks_Achieves_Representations_Similar_to_Macaque_IT_and_Human_Ventral_Stream.html">136 nips-2013-Hierarchical Modular Optimization of Convolutional Networks Achieves Representations Similar to Macaque IT and Human Ventral Stream</a></p>
<p>18 0.082158975 <a title="141-tfidf-18" href="./nips-2013-A_Deep_Architecture_for_Matching_Short_Texts.html">5 nips-2013-A Deep Architecture for Matching Short Texts</a></p>
<p>19 0.080887645 <a title="141-tfidf-19" href="./nips-2013-Universal_models_for_binary_spike_patterns_using_centered_Dirichlet_processes.html">341 nips-2013-Universal models for binary spike patterns using centered Dirichlet processes</a></p>
<p>20 0.079942331 <a title="141-tfidf-20" href="./nips-2013-Multisensory_Encoding%2C_Decoding%2C_and_Identification.html">205 nips-2013-Multisensory Encoding, Decoding, and Identification</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.16), (1, 0.112), (2, -0.145), (3, -0.096), (4, -0.398), (5, -0.086), (6, -0.062), (7, -0.104), (8, 0.009), (9, 0.069), (10, 0.03), (11, -0.008), (12, 0.043), (13, 0.014), (14, -0.011), (15, -0.048), (16, -0.027), (17, -0.005), (18, 0.011), (19, -0.004), (20, -0.022), (21, 0.02), (22, 0.037), (23, 0.011), (24, 0.031), (25, -0.068), (26, -0.018), (27, 0.018), (28, 0.04), (29, -0.002), (30, -0.026), (31, -0.018), (32, -0.014), (33, 0.114), (34, -0.013), (35, -0.023), (36, 0.119), (37, -0.089), (38, 0.091), (39, -0.032), (40, -0.102), (41, 0.025), (42, 0.112), (43, 0.111), (44, -0.02), (45, -0.055), (46, 0.005), (47, -0.088), (48, 0.068), (49, 0.074)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.97221923 <a title="141-lsi-1" href="./nips-2013-Inferring_neural_population_dynamics_from_multiple_partial_recordings_of_the_same_neural_circuit.html">141 nips-2013-Inferring neural population dynamics from multiple partial recordings of the same neural circuit</a></p>
<p>Author: Srini Turaga, Lars Buesing, Adam M. Packer, Henry Dalgleish, Noah Pettit, Michael Hausser, Jakob Macke</p><p>Abstract: Simultaneous recordings of the activity of large neural populations are extremely valuable as they can be used to infer the dynamics and interactions of neurons in a local circuit, shedding light on the computations performed. It is now possible to measure the activity of hundreds of neurons using 2-photon calcium imaging. However, many computations are thought to involve circuits consisting of thousands of neurons, such as cortical barrels in rodent somatosensory cortex. Here we contribute a statistical method for “stitching” together sequentially imaged sets of neurons into one model by phrasing the problem as ﬁtting a latent dynamical system with missing observations. This method allows us to substantially expand the population-sizes for which population dynamics can be characterized—beyond the number of simultaneously imaged neurons. In particular, we demonstrate using recordings in mouse somatosensory cortex that this method makes it possible to predict noise correlations between non-simultaneously recorded neuron pairs. 1</p><p>2 0.81574863 <a title="141-lsi-2" href="./nips-2013-Firing_rate_predictions_in_optimal_balanced_networks.html">121 nips-2013-Firing rate predictions in optimal balanced networks</a></p>
<p>Author: David G. Barrett, Sophie Denève, Christian K. Machens</p><p>Abstract: How are ﬁring rates in a spiking network related to neural input, connectivity and network function? This is an important problem because ﬁring rates are a key measure of network activity, in both the study of neural computation and neural network dynamics. However, it is a difﬁcult problem, because the spiking mechanism of individual neurons is highly non-linear, and these individual neurons interact strongly through connectivity. We develop a new technique for calculating ﬁring rates in optimal balanced networks. These are particularly interesting networks because they provide an optimal spike-based signal representation while producing cortex-like spiking activity through a dynamic balance of excitation and inhibition. We can calculate ﬁring rates by treating balanced network dynamics as an algorithm for optimising signal representation. We identify this algorithm and then calculate ﬁring rates by ﬁnding the solution to the algorithm. Our ﬁring rate calculation relates network ﬁring rates directly to network input, connectivity and function. This allows us to explain the function and underlying mechanism of tuning curves in a variety of systems. 1</p><p>3 0.77814418 <a title="141-lsi-3" href="./nips-2013-A_Determinantal_Point_Process_Latent_Variable_Model_for_Inhibition_in_Neural_Spiking_Data.html">6 nips-2013-A Determinantal Point Process Latent Variable Model for Inhibition in Neural Spiking Data</a></p>
<p>Author: Jasper Snoek, Richard Zemel, Ryan P. Adams</p><p>Abstract: Point processes are popular models of neural spiking behavior as they provide a statistical distribution over temporal sequences of spikes and help to reveal the complexities underlying a series of recorded action potentials. However, the most common neural point process models, the Poisson process and the gamma renewal process, do not capture interactions and correlations that are critical to modeling populations of neurons. We develop a novel model based on a determinantal point process over latent embeddings of neurons that effectively captures and helps visualize complex inhibitory and competitive interaction. We show that this model is a natural extension of the popular generalized linear model to sets of interacting neurons. The model is extended to incorporate gain control or divisive normalization, and the modulation of neural spiking based on periodic phenomena. Applied to neural spike recordings from the rat hippocampus, we see that the model captures inhibitory relationships, a dichotomy of classes of neurons, and a periodic modulation by the theta rhythm known to be present in the data. 1</p><p>4 0.76377207 <a title="141-lsi-4" href="./nips-2013-Learning_Multi-level_Sparse_Representations.html">157 nips-2013-Learning Multi-level Sparse Representations</a></p>
<p>Author: Ferran Diego Andilla, Fred A. Hamprecht</p><p>Abstract: Bilinear approximation of a matrix is a powerful paradigm of unsupervised learning. In some applications, however, there is a natural hierarchy of concepts that ought to be reﬂected in the unsupervised analysis. For example, in the neurosciences image sequence considered here, there are the semantic concepts of pixel → neuron → assembly that should ﬁnd their counterpart in the unsupervised analysis. Driven by this concrete problem, we propose a decomposition of the matrix of observations into a product of more than two sparse matrices, with the rank decreasing from lower to higher levels. In contrast to prior work, we allow for both hierarchical and heterarchical relations of lower-level to higher-level concepts. In addition, we learn the nature of these relations rather than imposing them. Finally, we describe an optimization scheme that allows to optimize the decomposition over all levels jointly, rather than in a greedy level-by-level fashion. The proposed bilevel SHMF (sparse heterarchical matrix factorization) is the ﬁrst formalism that allows to simultaneously interpret a calcium imaging sequence in terms of the constituent neurons, their membership in assemblies, and the time courses of both neurons and assemblies. Experiments show that the proposed model fully recovers the structure from difﬁcult synthetic data designed to imitate the experimental data. More importantly, bilevel SHMF yields plausible interpretations of real-world Calcium imaging data. 1</p><p>5 0.70452946 <a title="141-lsi-5" href="./nips-2013-Sparse_nonnegative_deconvolution_for_compressive_calcium_imaging%3A_algorithms_and_phase_transitions.html">304 nips-2013-Sparse nonnegative deconvolution for compressive calcium imaging: algorithms and phase transitions</a></p>
<p>Author: Eftychios A. Pnevmatikakis, Liam Paninski</p><p>Abstract: We propose a compressed sensing (CS) calcium imaging framework for monitoring large neuronal populations, where we image randomized projections of the spatial calcium concentration at each timestep, instead of measuring the concentration at individual locations. We develop scalable nonnegative deconvolution methods for extracting the neuronal spike time series from such observations. We also address the problem of demixing the spatial locations of the neurons using rank-penalized matrix factorization methods. By exploiting the sparsity of neural spiking we demonstrate that the number of measurements needed per timestep is signiﬁcantly smaller than the total number of neurons, a result that can potentially enable imaging of larger populations at considerably faster rates compared to traditional raster-scanning techniques. Unlike traditional CS setups, our problem involves a block-diagonal sensing matrix and a non-orthogonal sparse basis that spans multiple timesteps. We provide tight approximations to the number of measurements needed for perfect deconvolution for certain classes of spiking processes, and show that this number undergoes a “phase transition,” which we characterize using modern tools relating conic geometry to compressed sensing. 1</p><p>6 0.65557307 <a title="141-lsi-6" href="./nips-2013-Neural_representation_of_action_sequences%3A_how_far_can_a_simple_snippet-matching_model_take_us%3F.html">208 nips-2013-Neural representation of action sequences: how far can a simple snippet-matching model take us?</a></p>
<p>7 0.64699501 <a title="141-lsi-7" href="./nips-2013-Noise-Enhanced_Associative_Memories.html">210 nips-2013-Noise-Enhanced Associative Memories</a></p>
<p>8 0.6219281 <a title="141-lsi-8" href="./nips-2013-Real-Time_Inference_for_a_Gamma_Process_Model_of_Neural_Spiking.html">262 nips-2013-Real-Time Inference for a Gamma Process Model of Neural Spiking</a></p>
<p>9 0.61929286 <a title="141-lsi-9" href="./nips-2013-Multisensory_Encoding%2C_Decoding%2C_and_Identification.html">205 nips-2013-Multisensory Encoding, Decoding, and Identification</a></p>
<p>10 0.60255897 <a title="141-lsi-10" href="./nips-2013-Bayesian_Inference_and_Online_Experimental_Design_for_Mapping_Neural_Microcircuits.html">49 nips-2013-Bayesian Inference and Online Experimental Design for Mapping Neural Microcircuits</a></p>
<p>11 0.58921438 <a title="141-lsi-11" href="./nips-2013-Demixing_odors_-_fast_inference_in_olfaction.html">86 nips-2013-Demixing odors - fast inference in olfaction</a></p>
<p>12 0.54239655 <a title="141-lsi-12" href="./nips-2013-Recurrent_networks_of_coupled_Winner-Take-All_oscillators_for_solving_constraint_satisfaction_problems.html">267 nips-2013-Recurrent networks of coupled Winner-Take-All oscillators for solving constraint satisfaction problems</a></p>
<p>13 0.53190768 <a title="141-lsi-13" href="./nips-2013-Compete_to_Compute.html">64 nips-2013-Compete to Compute</a></p>
<p>14 0.50799924 <a title="141-lsi-14" href="./nips-2013-Perfect_Associative_Learning_with_Spike-Timing-Dependent_Plasticity.html">246 nips-2013-Perfect Associative Learning with Spike-Timing-Dependent Plasticity</a></p>
<p>15 0.50118721 <a title="141-lsi-15" href="./nips-2013-Reciprocally_Coupled_Local_Estimators_Implement_Bayesian_Information_Integration_Distributively.html">264 nips-2013-Reciprocally Coupled Local Estimators Implement Bayesian Information Integration Distributively</a></p>
<p>16 0.48969629 <a title="141-lsi-16" href="./nips-2013-Optimal_Neural_Population_Codes_for_High-dimensional_Stimulus_Variables.html">236 nips-2013-Optimal Neural Population Codes for High-dimensional Stimulus Variables</a></p>
<p>17 0.47373271 <a title="141-lsi-17" href="./nips-2013-Robust_learning_of_low-dimensional_dynamics_from_large_neural_ensembles.html">286 nips-2013-Robust learning of low-dimensional dynamics from large neural ensembles</a></p>
<p>18 0.40653625 <a title="141-lsi-18" href="./nips-2013-Extracting_regions_of_interest_from_biological_images_with_convolutional_sparse_block_coding.html">114 nips-2013-Extracting regions of interest from biological images with convolutional sparse block coding</a></p>
<p>19 0.40257546 <a title="141-lsi-19" href="./nips-2013-Hierarchical_Modular_Optimization_of_Convolutional_Networks_Achieves_Representations_Similar_to_Macaque_IT_and_Human_Ventral_Stream.html">136 nips-2013-Hierarchical Modular Optimization of Convolutional Networks Achieves Representations Similar to Macaque IT and Human Ventral Stream</a></p>
<p>20 0.3769213 <a title="141-lsi-20" href="./nips-2013-Spectral_methods_for_neural_characterization_using_generalized_quadratic_models.html">305 nips-2013-Spectral methods for neural characterization using generalized quadratic models</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(16, 0.051), (33, 0.115), (34, 0.092), (41, 0.04), (49, 0.099), (56, 0.072), (57, 0.197), (70, 0.14), (85, 0.019), (89, 0.031), (93, 0.031), (94, 0.016)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.81780386 <a title="141-lda-1" href="./nips-2013-Inferring_neural_population_dynamics_from_multiple_partial_recordings_of_the_same_neural_circuit.html">141 nips-2013-Inferring neural population dynamics from multiple partial recordings of the same neural circuit</a></p>
<p>Author: Srini Turaga, Lars Buesing, Adam M. Packer, Henry Dalgleish, Noah Pettit, Michael Hausser, Jakob Macke</p><p>Abstract: Simultaneous recordings of the activity of large neural populations are extremely valuable as they can be used to infer the dynamics and interactions of neurons in a local circuit, shedding light on the computations performed. It is now possible to measure the activity of hundreds of neurons using 2-photon calcium imaging. However, many computations are thought to involve circuits consisting of thousands of neurons, such as cortical barrels in rodent somatosensory cortex. Here we contribute a statistical method for “stitching” together sequentially imaged sets of neurons into one model by phrasing the problem as ﬁtting a latent dynamical system with missing observations. This method allows us to substantially expand the population-sizes for which population dynamics can be characterized—beyond the number of simultaneously imaged neurons. In particular, we demonstrate using recordings in mouse somatosensory cortex that this method makes it possible to predict noise correlations between non-simultaneously recorded neuron pairs. 1</p><p>2 0.74071723 <a title="141-lda-2" href="./nips-2013-Learning_Multi-level_Sparse_Representations.html">157 nips-2013-Learning Multi-level Sparse Representations</a></p>
<p>Author: Ferran Diego Andilla, Fred A. Hamprecht</p><p>Abstract: Bilinear approximation of a matrix is a powerful paradigm of unsupervised learning. In some applications, however, there is a natural hierarchy of concepts that ought to be reﬂected in the unsupervised analysis. For example, in the neurosciences image sequence considered here, there are the semantic concepts of pixel → neuron → assembly that should ﬁnd their counterpart in the unsupervised analysis. Driven by this concrete problem, we propose a decomposition of the matrix of observations into a product of more than two sparse matrices, with the rank decreasing from lower to higher levels. In contrast to prior work, we allow for both hierarchical and heterarchical relations of lower-level to higher-level concepts. In addition, we learn the nature of these relations rather than imposing them. Finally, we describe an optimization scheme that allows to optimize the decomposition over all levels jointly, rather than in a greedy level-by-level fashion. The proposed bilevel SHMF (sparse heterarchical matrix factorization) is the ﬁrst formalism that allows to simultaneously interpret a calcium imaging sequence in terms of the constituent neurons, their membership in assemblies, and the time courses of both neurons and assemblies. Experiments show that the proposed model fully recovers the structure from difﬁcult synthetic data designed to imitate the experimental data. More importantly, bilevel SHMF yields plausible interpretations of real-world Calcium imaging data. 1</p><p>3 0.72834021 <a title="141-lda-3" href="./nips-2013-A_message-passing_algorithm_for_multi-agent_trajectory_planning.html">16 nips-2013-A message-passing algorithm for multi-agent trajectory planning</a></p>
<p>Author: Jose Bento, Nate Derbinsky, Javier Alonso-Mora, Jonathan S. Yedidia</p><p>Abstract: We describe a novel approach for computing collision-free global trajectories for p agents with speciﬁed initial and ﬁnal conﬁgurations, based on an improved version of the alternating direction method of multipliers (ADMM). Compared with existing methods, our approach is naturally parallelizable and allows for incorporating different cost functionals with only minor adjustments. We apply our method to classical challenging instances and observe that its computational requirements scale well with p for several cost functionals. We also show that a specialization of our algorithm can be used for local motion planning by solving the problem of joint optimization in velocity space. 1</p><p>4 0.72242332 <a title="141-lda-4" href="./nips-2013-Firing_rate_predictions_in_optimal_balanced_networks.html">121 nips-2013-Firing rate predictions in optimal balanced networks</a></p>
<p>Author: David G. Barrett, Sophie Denève, Christian K. Machens</p><p>Abstract: How are ﬁring rates in a spiking network related to neural input, connectivity and network function? This is an important problem because ﬁring rates are a key measure of network activity, in both the study of neural computation and neural network dynamics. However, it is a difﬁcult problem, because the spiking mechanism of individual neurons is highly non-linear, and these individual neurons interact strongly through connectivity. We develop a new technique for calculating ﬁring rates in optimal balanced networks. These are particularly interesting networks because they provide an optimal spike-based signal representation while producing cortex-like spiking activity through a dynamic balance of excitation and inhibition. We can calculate ﬁring rates by treating balanced network dynamics as an algorithm for optimising signal representation. We identify this algorithm and then calculate ﬁring rates by ﬁnding the solution to the algorithm. Our ﬁring rate calculation relates network ﬁring rates directly to network input, connectivity and function. This allows us to explain the function and underlying mechanism of tuning curves in a variety of systems. 1</p><p>5 0.71628463 <a title="141-lda-5" href="./nips-2013-Recurrent_networks_of_coupled_Winner-Take-All_oscillators_for_solving_constraint_satisfaction_problems.html">267 nips-2013-Recurrent networks of coupled Winner-Take-All oscillators for solving constraint satisfaction problems</a></p>
<p>Author: Hesham Mostafa, Lorenz. K. Mueller, Giacomo Indiveri</p><p>Abstract: We present a recurrent neuronal network, modeled as a continuous-time dynamical system, that can solve constraint satisfaction problems. Discrete variables are represented by coupled Winner-Take-All (WTA) networks, and their values are encoded in localized patterns of oscillations that are learned by the recurrent weights in these networks. Constraints over the variables are encoded in the network connectivity. Although there are no sources of noise, the network can escape from local optima in its search for solutions that satisfy all constraints by modifying the effective network connectivity through oscillations. If there is no solution that satisﬁes all constraints, the network state changes in a seemingly random manner and its trajectory approximates a sampling procedure that selects a variable assignment with a probability that increases with the fraction of constraints satisﬁed by this assignment. External evidence, or input to the network, can force variables to speciﬁc values. When new inputs are applied, the network re-evaluates the entire set of variables in its search for states that satisfy the maximum number of constraints, while being consistent with the external input. Our results demonstrate that the proposed network architecture can perform a deterministic search for the optimal solution to problems with non-convex cost functions. The network is inspired by canonical microcircuit models of the cortex and suggests possible dynamical mechanisms to solve constraint satisfaction problems that can be present in biological networks, or implemented in neuromorphic electronic circuits. 1</p><p>6 0.70925128 <a title="141-lda-6" href="./nips-2013-Better_Approximation_and_Faster_Algorithm_Using_the_Proximal_Average.html">56 nips-2013-Better Approximation and Faster Algorithm Using the Proximal Average</a></p>
<p>7 0.70809299 <a title="141-lda-7" href="./nips-2013-Deep_Neural_Networks_for_Object_Detection.html">84 nips-2013-Deep Neural Networks for Object Detection</a></p>
<p>8 0.70633632 <a title="141-lda-8" href="./nips-2013-A_memory_frontier_for_complex_synapses.html">15 nips-2013-A memory frontier for complex synapses</a></p>
<p>9 0.70102251 <a title="141-lda-9" href="./nips-2013-Direct_0-1_Loss_Minimization_and_Margin_Maximization_with_Boosting.html">90 nips-2013-Direct 0-1 Loss Minimization and Margin Maximization with Boosting</a></p>
<p>10 0.69434029 <a title="141-lda-10" href="./nips-2013-Correlations_strike_back_%28again%29%3A_the_case_of_associative_memory_retrieval.html">77 nips-2013-Correlations strike back (again): the case of associative memory retrieval</a></p>
<p>11 0.66745287 <a title="141-lda-11" href="./nips-2013-Action_is_in_the_Eye_of_the_Beholder%3A_Eye-gaze_Driven_Model_for_Spatio-Temporal_Action_Localization.html">22 nips-2013-Action is in the Eye of the Beholder: Eye-gaze Driven Model for Spatio-Temporal Action Localization</a></p>
<p>12 0.66480815 <a title="141-lda-12" href="./nips-2013-Compete_to_Compute.html">64 nips-2013-Compete to Compute</a></p>
<p>13 0.66306901 <a title="141-lda-13" href="./nips-2013-On_the_Expressive_Power_of_Restricted_Boltzmann_Machines.html">221 nips-2013-On the Expressive Power of Restricted Boltzmann Machines</a></p>
<p>14 0.65498888 <a title="141-lda-14" href="./nips-2013-Real-Time_Inference_for_a_Gamma_Process_Model_of_Neural_Spiking.html">262 nips-2013-Real-Time Inference for a Gamma Process Model of Neural Spiking</a></p>
<p>15 0.65417415 <a title="141-lda-15" href="./nips-2013-Bellman_Error_Based_Feature_Generation_using_Random_Projections_on_Sparse_Spaces.html">55 nips-2013-Bellman Error Based Feature Generation using Random Projections on Sparse Spaces</a></p>
<p>16 0.65339565 <a title="141-lda-16" href="./nips-2013-Recurrent_linear_models_of_simultaneously-recorded_neural___populations.html">266 nips-2013-Recurrent linear models of simultaneously-recorded neural   populations</a></p>
<p>17 0.65323943 <a title="141-lda-17" href="./nips-2013-Optimal_Neural_Population_Codes_for_High-dimensional_Stimulus_Variables.html">236 nips-2013-Optimal Neural Population Codes for High-dimensional Stimulus Variables</a></p>
<p>18 0.65284693 <a title="141-lda-18" href="./nips-2013-A_Determinantal_Point_Process_Latent_Variable_Model_for_Inhibition_in_Neural_Spiking_Data.html">6 nips-2013-A Determinantal Point Process Latent Variable Model for Inhibition in Neural Spiking Data</a></p>
<p>19 0.64837801 <a title="141-lda-19" href="./nips-2013-Bayesian_Inference_and_Online_Experimental_Design_for_Mapping_Neural_Microcircuits.html">49 nips-2013-Bayesian Inference and Online Experimental Design for Mapping Neural Microcircuits</a></p>
<p>20 0.64618742 <a title="141-lda-20" href="./nips-2013-Hierarchical_Modular_Optimization_of_Convolutional_Networks_Achieves_Representations_Similar_to_Macaque_IT_and_Human_Ventral_Stream.html">136 nips-2013-Hierarchical Modular Optimization of Convolutional Networks Achieves Representations Similar to Macaque IT and Human Ventral Stream</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
