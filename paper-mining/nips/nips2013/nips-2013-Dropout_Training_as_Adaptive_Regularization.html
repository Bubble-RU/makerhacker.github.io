<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>99 nips-2013-Dropout Training as Adaptive Regularization</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-99" href="#">nips2013-99</a> knowledge-graph by maker-knowledge-mining</p><h1>99 nips-2013-Dropout Training as Adaptive Regularization</h1>
<br/><p>Source: <a title="nips-2013-99-pdf" href="http://papers.nips.cc/paper/4882-dropout-training-as-adaptive-regularization.pdf">pdf</a></p><p>Author: Stefan Wager, Sida Wang, Percy Liang</p><p>Abstract: Dropout and other feature noising schemes control overﬁtting by artiﬁcially corrupting the training data. For generalized linear models, dropout performs a form of adaptive regularization. Using this viewpoint, we show that the dropout regularizer is ﬁrst-order equivalent to an L2 regularizer applied after scaling the features by an estimate of the inverse diagonal Fisher information matrix. We also establish a connection to AdaGrad, an online learning algorithm, and ﬁnd that a close relative of AdaGrad operates by repeatedly solving linear dropout-regularized problems. By casting dropout as regularization, we develop a natural semi-supervised algorithm that uses unlabeled data to create a better adaptive regularizer. We apply this idea to document classiﬁcation tasks, and show that it consistently boosts the performance of dropout training, improving on state-of-the-art results on the IMDB reviews dataset. 1</p><p>Reference: <a title="nips-2013-99-reference" href="../nips2013_reference/nips-2013-Dropout_Training_as_Adaptive_Regularization_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('dropout', 0.832), ('unlabel', 0.206), ('rq', 0.205), ('adagrad', 0.153), ('penal', 0.131), ('nois', 0.127), ('pi', 0.125), ('glms', 0.094), ('rar', 0.091), ('imdb', 0.09), ('regress', 0.083), ('feat', 0.08), ('sgd', 0.077), ('train', 0.075), ('gt', 0.073), ('quadr', 0.07), ('regul', 0.067), ('xi', 0.061), ('diag', 0.052), ('xij', 0.051)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="99-tfidf-1" href="./nips-2013-Dropout_Training_as_Adaptive_Regularization.html">99 nips-2013-Dropout Training as Adaptive Regularization</a></p>
<p>2 0.61231011 <a title="99-tfidf-2" href="./nips-2013-Understanding_Dropout.html">339 nips-2013-Understanding Dropout</a></p>
<p>3 0.43660483 <a title="99-tfidf-3" href="./nips-2013-Adaptive_dropout_for_training_deep_neural_networks.html">30 nips-2013-Adaptive dropout for training deep neural networks</a></p>
<p>4 0.12625311 <a title="99-tfidf-4" href="./nips-2013-Compete_to_Compute.html">64 nips-2013-Compete to Compute</a></p>
<p>5 0.092724904 <a title="99-tfidf-5" href="./nips-2013-Discriminative_Transfer_Learning_with_Tree-based_Priors.html">93 nips-2013-Discriminative Transfer Learning with Tree-based Priors</a></p>
<p>6 0.089939788 <a title="99-tfidf-6" href="./nips-2013-Learning_with_Noisy_Labels.html">171 nips-2013-Learning with Noisy Labels</a></p>
<p>7 0.088579394 <a title="99-tfidf-7" href="./nips-2013-Latent_Structured_Active_Learning.html">149 nips-2013-Latent Structured Active Learning</a></p>
<p>8 0.083413534 <a title="99-tfidf-8" href="./nips-2013-Confidence_Intervals_and_Hypothesis_Testing_for_High-Dimensional_Statistical_Models.html">68 nips-2013-Confidence Intervals and Hypothesis Testing for High-Dimensional Statistical Models</a></p>
<p>9 0.082620695 <a title="99-tfidf-9" href="./nips-2013-Predicting_Parameters_in_Deep_Learning.html">251 nips-2013-Predicting Parameters in Deep Learning</a></p>
<p>10 0.082237191 <a title="99-tfidf-10" href="./nips-2013-Multi-Prediction_Deep_Boltzmann_Machines.html">200 nips-2013-Multi-Prediction Deep Boltzmann Machines</a></p>
<p>11 0.075428165 <a title="99-tfidf-11" href="./nips-2013-Compressive_Feature_Learning.html">65 nips-2013-Compressive Feature Learning</a></p>
<p>12 0.067915842 <a title="99-tfidf-12" href="./nips-2013-Minimax_Optimal_Algorithms_for_Unconstrained_Linear_Optimization.html">191 nips-2013-Minimax Optimal Algorithms for Unconstrained Linear Optimization</a></p>
<p>13 0.067601189 <a title="99-tfidf-13" href="./nips-2013-Regularized_M-estimators_with_nonconvexity%3A_Statistical_and_algorithmic_theory_for_local_optima.html">271 nips-2013-Regularized M-estimators with nonconvexity: Statistical and algorithmic theory for local optima</a></p>
<p>14 0.06441655 <a title="99-tfidf-14" href="./nips-2013-On_model_selection_consistency_of_penalized_M-estimators%3A_a_geometric_theory.html">219 nips-2013-On model selection consistency of penalized M-estimators: a geometric theory</a></p>
<p>15 0.064080819 <a title="99-tfidf-15" href="./nips-2013-A_Novel_Two-Step_Method_for_Cross_Language_Representation_Learning.html">12 nips-2013-A Novel Two-Step Method for Cross Language Representation Learning</a></p>
<p>16 0.061470181 <a title="99-tfidf-16" href="./nips-2013-Statistical_Active_Learning_Algorithms.html">309 nips-2013-Statistical Active Learning Algorithms</a></p>
<p>17 0.060421415 <a title="99-tfidf-17" href="./nips-2013-From_Bandits_to_Experts%3A_A_Tale_of_Domination_and_Independence.html">125 nips-2013-From Bandits to Experts: A Tale of Domination and Independence</a></p>
<p>18 0.060388356 <a title="99-tfidf-18" href="./nips-2013-Convex_Two-Layer_Modeling.html">75 nips-2013-Convex Two-Layer Modeling</a></p>
<p>19 0.05719189 <a title="99-tfidf-19" href="./nips-2013-Learning_Adaptive_Value_of_Information_for_Structured_Prediction.html">150 nips-2013-Learning Adaptive Value of Information for Structured Prediction</a></p>
<p>20 0.057055615 <a title="99-tfidf-20" href="./nips-2013-Dirty_Statistical_Models.html">91 nips-2013-Dirty Statistical Models</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.161), (1, 0.045), (2, 0.012), (3, 0.001), (4, -0.084), (5, -0.13), (6, -0.1), (7, -0.116), (8, -0.103), (9, 0.104), (10, 0.178), (11, 0.123), (12, 0.03), (13, 0.119), (14, 0.149), (15, -0.262), (16, 0.149), (17, 0.082), (18, 0.041), (19, -0.248), (20, -0.367), (21, -0.274), (22, 0.212), (23, -0.126), (24, 0.079), (25, 0.209), (26, -0.025), (27, -0.034), (28, -0.038), (29, 0.066), (30, -0.001), (31, -0.111), (32, -0.042), (33, -0.018), (34, -0.0), (35, -0.029), (36, -0.004), (37, -0.022), (38, -0.025), (39, -0.07), (40, -0.004), (41, 0.07), (42, 0.026), (43, -0.003), (44, 0.027), (45, 0.023), (46, -0.012), (47, -0.003), (48, -0.043), (49, 0.002)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.9102363 <a title="99-lsi-1" href="./nips-2013-Understanding_Dropout.html">339 nips-2013-Understanding Dropout</a></p>
<p>same-paper 2 0.90392518 <a title="99-lsi-2" href="./nips-2013-Dropout_Training_as_Adaptive_Regularization.html">99 nips-2013-Dropout Training as Adaptive Regularization</a></p>
<p>3 0.76710969 <a title="99-lsi-3" href="./nips-2013-Adaptive_dropout_for_training_deep_neural_networks.html">30 nips-2013-Adaptive dropout for training deep neural networks</a></p>
<p>4 0.35184741 <a title="99-lsi-4" href="./nips-2013-Compete_to_Compute.html">64 nips-2013-Compete to Compute</a></p>
<p>5 0.34022069 <a title="99-lsi-5" href="./nips-2013-Multi-Prediction_Deep_Boltzmann_Machines.html">200 nips-2013-Multi-Prediction Deep Boltzmann Machines</a></p>
<p>6 0.27835786 <a title="99-lsi-6" href="./nips-2013-Correlated_random_features_for_fast_semi-supervised_learning.html">76 nips-2013-Correlated random features for fast semi-supervised learning</a></p>
<p>7 0.27712011 <a title="99-lsi-7" href="./nips-2013-Discriminative_Transfer_Learning_with_Tree-based_Priors.html">93 nips-2013-Discriminative Transfer Learning with Tree-based Priors</a></p>
<p>8 0.24668805 <a title="99-lsi-8" href="./nips-2013-It_is_all_in_the_noise%3A_Efficient_multi-task_Gaussian_process_inference_with_structured_residuals.html">145 nips-2013-It is all in the noise: Efficient multi-task Gaussian process inference with structured residuals</a></p>
<p>9 0.24282622 <a title="99-lsi-9" href="./nips-2013-Adaptive_Multi-Column_Deep_Neural_Networks_with_Application_to_Robust_Image_Denoising.html">27 nips-2013-Adaptive Multi-Column Deep Neural Networks with Application to Robust Image Denoising</a></p>
<p>10 0.23879001 <a title="99-lsi-10" href="./nips-2013-Analyzing_the_Harmonic_Structure_in_Graph-Based_Learning.html">35 nips-2013-Analyzing the Harmonic Structure in Graph-Based Learning</a></p>
<p>11 0.23517576 <a title="99-lsi-11" href="./nips-2013-Learning_Stochastic_Feedforward_Neural_Networks.html">160 nips-2013-Learning Stochastic Feedforward Neural Networks</a></p>
<p>12 0.22878045 <a title="99-lsi-12" href="./nips-2013-Learning_with_Noisy_Labels.html">171 nips-2013-Learning with Noisy Labels</a></p>
<p>13 0.22822428 <a title="99-lsi-13" href="./nips-2013-Predicting_Parameters_in_Deep_Learning.html">251 nips-2013-Predicting Parameters in Deep Learning</a></p>
<p>14 0.22443703 <a title="99-lsi-14" href="./nips-2013-Improved_and_Generalized_Upper_Bounds_on_the_Complexity_of_Policy_Iteration.html">140 nips-2013-Improved and Generalized Upper Bounds on the Complexity of Policy Iteration</a></p>
<p>15 0.21767494 <a title="99-lsi-15" href="./nips-2013-Learning_Adaptive_Value_of_Information_for_Structured_Prediction.html">150 nips-2013-Learning Adaptive Value of Information for Structured Prediction</a></p>
<p>16 0.2173309 <a title="99-lsi-16" href="./nips-2013-Direct_0-1_Loss_Minimization_and_Margin_Maximization_with_Boosting.html">90 nips-2013-Direct 0-1 Loss Minimization and Margin Maximization with Boosting</a></p>
<p>17 0.21537063 <a title="99-lsi-17" href="./nips-2013-Deep_content-based_music_recommendation.html">85 nips-2013-Deep content-based music recommendation</a></p>
<p>18 0.21526121 <a title="99-lsi-18" href="./nips-2013-Solving_inverse_problem_of_Markov_chain_with_partial_observations.html">299 nips-2013-Solving inverse problem of Markov chain with partial observations</a></p>
<p>19 0.21518733 <a title="99-lsi-19" href="./nips-2013-Regularized_M-estimators_with_nonconvexity%3A_Statistical_and_algorithmic_theory_for_local_optima.html">271 nips-2013-Regularized M-estimators with nonconvexity: Statistical and algorithmic theory for local optima</a></p>
<p>20 0.21377502 <a title="99-lsi-20" href="./nips-2013-A_Novel_Two-Step_Method_for_Cross_Language_Representation_Learning.html">12 nips-2013-A Novel Two-Step Method for Cross Language Representation Learning</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(20, 0.13), (25, 0.253), (37, 0.09), (40, 0.083), (47, 0.018), (70, 0.019), (80, 0.103), (86, 0.128), (87, 0.04)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.95550346 <a title="99-lda-1" href="./nips-2013-Near-optimal_Anomaly_Detection_in_Graphs_using_Lovasz_Extended_Scan_Statistic.html">207 nips-2013-Near-optimal Anomaly Detection in Graphs using Lovasz Extended Scan Statistic</a></p>
<p>2 0.95385379 <a title="99-lda-2" href="./nips-2013-Scoring_Workers_in_Crowdsourcing%3A_How_Many_Control_Questions_are_Enough%3F.html">290 nips-2013-Scoring Workers in Crowdsourcing: How Many Control Questions are Enough?</a></p>
<p>3 0.94559067 <a title="99-lda-3" href="./nips-2013-Regret_based_Robust_Solutions_for_Uncertain_Markov_Decision_Processes.html">270 nips-2013-Regret based Robust Solutions for Uncertain Markov Decision Processes</a></p>
<p>4 0.94269764 <a title="99-lda-4" href="./nips-2013-Convex_Two-Layer_Modeling.html">75 nips-2013-Convex Two-Layer Modeling</a></p>
<p>same-paper 5 0.94061357 <a title="99-lda-5" href="./nips-2013-Dropout_Training_as_Adaptive_Regularization.html">99 nips-2013-Dropout Training as Adaptive Regularization</a></p>
<p>6 0.94014132 <a title="99-lda-6" href="./nips-2013-Top-Down_Regularization_of_Deep_Belief_Networks.html">331 nips-2013-Top-Down Regularization of Deep Belief Networks</a></p>
<p>7 0.93681026 <a title="99-lda-7" href="./nips-2013-A_Latent_Source_Model_for_Nonparametric_Time_Series_Classification.html">10 nips-2013-A Latent Source Model for Nonparametric Time Series Classification</a></p>
<p>8 0.93550438 <a title="99-lda-8" href="./nips-2013-Adaptive_dropout_for_training_deep_neural_networks.html">30 nips-2013-Adaptive dropout for training deep neural networks</a></p>
<p>9 0.93378776 <a title="99-lda-9" href="./nips-2013-Decision_Jungles%3A_Compact_and_Rich_Models_for_Classification.html">82 nips-2013-Decision Jungles: Compact and Rich Models for Classification</a></p>
<p>10 0.93360531 <a title="99-lda-10" href="./nips-2013-A_Deep_Architecture_for_Matching_Short_Texts.html">5 nips-2013-A Deep Architecture for Matching Short Texts</a></p>
<p>11 0.92434919 <a title="99-lda-11" href="./nips-2013-%CE%A3-Optimality_for_Active_Learning_on_Gaussian_Random_Fields.html">359 nips-2013-Σ-Optimality for Active Learning on Gaussian Random Fields</a></p>
<p>12 0.9212324 <a title="99-lda-12" href="./nips-2013-Compressive_Feature_Learning.html">65 nips-2013-Compressive Feature Learning</a></p>
<p>13 0.92036241 <a title="99-lda-13" href="./nips-2013-Multi-Prediction_Deep_Boltzmann_Machines.html">200 nips-2013-Multi-Prediction Deep Boltzmann Machines</a></p>
<p>14 0.91855538 <a title="99-lda-14" href="./nips-2013-Discriminative_Transfer_Learning_with_Tree-based_Priors.html">93 nips-2013-Discriminative Transfer Learning with Tree-based Priors</a></p>
<p>15 0.91582185 <a title="99-lda-15" href="./nips-2013-Optimization%2C_Learning%2C_and_Games_with_Predictable_Sequences.html">240 nips-2013-Optimization, Learning, and Games with Predictable Sequences</a></p>
<p>16 0.91331387 <a title="99-lda-16" href="./nips-2013-Sparse_Additive_Text_Models_with_Low_Rank_Background.html">301 nips-2013-Sparse Additive Text Models with Low Rank Background</a></p>
<p>17 0.91222739 <a title="99-lda-17" href="./nips-2013-Stochastic_Ratio_Matching_of_RBMs_for_Sparse_High-Dimensional_Inputs.html">315 nips-2013-Stochastic Ratio Matching of RBMs for Sparse High-Dimensional Inputs</a></p>
<p>18 0.90989494 <a title="99-lda-18" href="./nips-2013-Compete_to_Compute.html">64 nips-2013-Compete to Compute</a></p>
<p>19 0.90806425 <a title="99-lda-19" href="./nips-2013-Bayesian_Hierarchical_Community_Discovery.html">47 nips-2013-Bayesian Hierarchical Community Discovery</a></p>
<p>20 0.90598369 <a title="99-lda-20" href="./nips-2013-Training_and_Analysing_Deep_Recurrent_Neural_Networks.html">334 nips-2013-Training and Analysing Deep Recurrent Neural Networks</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
