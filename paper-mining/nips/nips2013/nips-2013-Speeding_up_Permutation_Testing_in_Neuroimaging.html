<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>306 nips-2013-Speeding up Permutation Testing in Neuroimaging</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-306" href="#">nips2013-306</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>306 nips-2013-Speeding up Permutation Testing in Neuroimaging</h1>
<br/><p>Source: <a title="nips-2013-306-pdf" href="http://papers.nips.cc/paper/4924-speeding-up-permutation-testing-in-neuroimaging.pdf">pdf</a></p><p>Author: Chris Hinrichs, Vamsi Ithapu, Qinyuan Sun, Sterling C. Johnson, Vikas Singh</p><p>Abstract: Multiple hypothesis testing is a signiﬁcant problem in nearly all neuroimaging studies. In order to correct for this phenomena, we require a reliable estimate of the Family-Wise Error Rate (FWER). The well known Bonferroni correction method, while simple to implement, is quite conservative, and can substantially under-power a study because it ignores dependencies between test statistics. Permutation testing, on the other hand, is an exact, non-parametric method of estimating the FWER for a given α-threshold, but for acceptably low thresholds the computational burden can be prohibitive. In this paper, we show that permutation testing in fact amounts to populating the columns of a very large matrix P. By analyzing the spectrum of this matrix, under certain conditions, we see that P has a low-rank plus a low-variance residual decomposition which makes it suitable for highly sub–sampled — on the order of 0.5% — matrix completion methods. Based on this observation, we propose a novel permutation testing methodology which offers a large speedup, without sacriﬁcing the ﬁdelity of the estimated FWER. Our evaluations on four different neuroimaging datasets show that a computational speedup factor of roughly 50× can be achieved while recovering the FWER distribution up to very high accuracy. Further, we show that the estimated α-threshold is also recovered faithfully, and is stable. 1</p><p>Reference: <a title="nips-2013-306-reference" href="../nips2013_reference/nips-2013-Speeding_up_Permutation_Testing_in_Neuroimaging_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('permut', 0.367), ('nul', 0.317), ('fwer', 0.274), ('neuroim', 0.273), ('bd', 0.245), ('uw', 0.196), ('resid', 0.186), ('speedup', 0.185), ('bonferron', 0.172), ('subsampl', 0.14), ('kl', 0.12), ('familyw', 0.112), ('mci', 0.112), ('eigenvalu', 0.112), ('test', 0.111), ('voxel', 0.105), ('cn', 0.093), ('recov', 0.091), ('alzheim', 0.091), ('drug', 0.086)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000001 <a title="306-tfidf-1" href="./nips-2013-Speeding_up_Permutation_Testing_in_Neuroimaging.html">306 nips-2013-Speeding up Permutation Testing in Neuroimaging</a></p>
<p>2 0.23965353 <a title="306-tfidf-2" href="./nips-2013-Solving_the_multi-way_matching_problem_by_permutation_synchronization.html">300 nips-2013-Solving the multi-way matching problem by permutation synchronization</a></p>
<p>3 0.17376257 <a title="306-tfidf-3" href="./nips-2013-Convex_Relaxations_for_Permutation_Problems.html">73 nips-2013-Convex Relaxations for Permutation Problems</a></p>
<p>4 0.1649815 <a title="306-tfidf-4" href="./nips-2013-B-test%3A_A_Non-parametric%2C_Low_Variance_Kernel_Two-sample_Test.html">44 nips-2013-B-test: A Non-parametric, Low Variance Kernel Two-sample Test</a></p>
<p>5 0.12823118 <a title="306-tfidf-5" href="./nips-2013-Robust_Multimodal_Graph_Matching%3A_Sparse_Coding_Meets_Graph_Matching.html">282 nips-2013-Robust Multimodal Graph Matching: Sparse Coding Meets Graph Matching</a></p>
<p>6 0.12773623 <a title="306-tfidf-6" href="./nips-2013-Mapping_paradigm_ontologies_to_and_from_the_brain.html">183 nips-2013-Mapping paradigm ontologies to and from the brain</a></p>
<p>7 0.12454917 <a title="306-tfidf-7" href="./nips-2013-Least_Informative_Dimensions.html">173 nips-2013-Least Informative Dimensions</a></p>
<p>8 0.12329387 <a title="306-tfidf-8" href="./nips-2013-Confidence_Intervals_and_Hypothesis_Testing_for_High-Dimensional_Statistical_Models.html">68 nips-2013-Confidence Intervals and Hypothesis Testing for High-Dimensional Statistical Models</a></p>
<p>9 0.11854579 <a title="306-tfidf-9" href="./nips-2013-Low-Rank_Matrix_and_Tensor_Completion_via_Adaptive_Sampling.html">179 nips-2013-Low-Rank Matrix and Tensor Completion via Adaptive Sampling</a></p>
<p>10 0.11299863 <a title="306-tfidf-10" href="./nips-2013-Large_Scale_Distributed_Sparse_Precision_Estimation.html">146 nips-2013-Large Scale Distributed Sparse Precision Estimation</a></p>
<p>11 0.10717511 <a title="306-tfidf-11" href="./nips-2013-Learning_Hidden_Markov_Models_from_Non-sequence_Data_via_Tensor_Decomposition.html">155 nips-2013-Learning Hidden Markov Models from Non-sequence Data via Tensor Decomposition</a></p>
<p>12 0.097116813 <a title="306-tfidf-12" href="./nips-2013-On_the_Sample_Complexity_of_Subspace_Learning.html">224 nips-2013-On the Sample Complexity of Subspace Learning</a></p>
<p>13 0.091875806 <a title="306-tfidf-13" href="./nips-2013-Learning_to_Prune_in_Metric_and_Non-Metric_Spaces.html">169 nips-2013-Learning to Prune in Metric and Non-Metric Spaces</a></p>
<p>14 0.088478662 <a title="306-tfidf-14" href="./nips-2013-High-Dimensional_Gaussian_Process_Bandits.html">137 nips-2013-High-Dimensional Gaussian Process Bandits</a></p>
<p>15 0.086781427 <a title="306-tfidf-15" href="./nips-2013-Robust_learning_of_low-dimensional_dynamics_from_large_neural_ensembles.html">286 nips-2013-Robust learning of low-dimensional dynamics from large neural ensembles</a></p>
<p>16 0.086481616 <a title="306-tfidf-16" href="./nips-2013-Fantope_Projection_and_Selection%3A_A_near-optimal_convex_relaxation_of_sparse_PCA.html">116 nips-2013-Fantope Projection and Selection: A near-optimal convex relaxation of sparse PCA</a></p>
<p>17 0.084903948 <a title="306-tfidf-17" href="./nips-2013-Memory_Limited%2C_Streaming_PCA.html">188 nips-2013-Memory Limited, Streaming PCA</a></p>
<p>18 0.080932416 <a title="306-tfidf-18" href="./nips-2013-Projecting_Ising_Model_Parameters_for_Fast_Mixing.html">258 nips-2013-Projecting Ising Model Parameters for Fast Mixing</a></p>
<p>19 0.077089347 <a title="306-tfidf-19" href="./nips-2013-Matrix_Completion_From_any_Given_Set_of_Observations.html">185 nips-2013-Matrix Completion From any Given Set of Observations</a></p>
<p>20 0.076597206 <a title="306-tfidf-20" href="./nips-2013-Generalized_Random_Utility_Models_with_Multiple_Types.html">129 nips-2013-Generalized Random Utility Models with Multiple Types</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.218), (1, 0.096), (2, 0.053), (3, -0.041), (4, 0.03), (5, 0.065), (6, -0.05), (7, 0.05), (8, -0.011), (9, 0.104), (10, -0.035), (11, -0.05), (12, 0.022), (13, -0.029), (14, -0.032), (15, 0.003), (16, -0.065), (17, -0.082), (18, 0.04), (19, 0.023), (20, 0.042), (21, -0.114), (22, 0.016), (23, 0.003), (24, -0.092), (25, 0.042), (26, -0.016), (27, -0.078), (28, -0.044), (29, -0.11), (30, -0.033), (31, 0.019), (32, 0.079), (33, 0.029), (34, -0.004), (35, -0.155), (36, 0.092), (37, -0.168), (38, -0.015), (39, -0.026), (40, -0.098), (41, -0.07), (42, -0.118), (43, -0.019), (44, -0.055), (45, 0.014), (46, 0.091), (47, 0.078), (48, -0.033), (49, 0.146)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.89735752 <a title="306-lsi-1" href="./nips-2013-Speeding_up_Permutation_Testing_in_Neuroimaging.html">306 nips-2013-Speeding up Permutation Testing in Neuroimaging</a></p>
<p>2 0.85277969 <a title="306-lsi-2" href="./nips-2013-Solving_the_multi-way_matching_problem_by_permutation_synchronization.html">300 nips-2013-Solving the multi-way matching problem by permutation synchronization</a></p>
<p>3 0.76247096 <a title="306-lsi-3" href="./nips-2013-Convex_Relaxations_for_Permutation_Problems.html">73 nips-2013-Convex Relaxations for Permutation Problems</a></p>
<p>4 0.63415033 <a title="306-lsi-4" href="./nips-2013-Fast_Algorithms_for_Gaussian_Noise_Invariant_Independent_Component_Analysis.html">117 nips-2013-Fast Algorithms for Gaussian Noise Invariant Independent Component Analysis</a></p>
<p>5 0.63257402 <a title="306-lsi-5" href="./nips-2013-Robust_Spatial_Filtering_with_Beta_Divergence.html">284 nips-2013-Robust Spatial Filtering with Beta Divergence</a></p>
<p>6 0.61641365 <a title="306-lsi-6" href="./nips-2013-Generalizing_Analytic_Shrinkage_for_Arbitrary_Covariance_Structures.html">130 nips-2013-Generalizing Analytic Shrinkage for Arbitrary Covariance Structures</a></p>
<p>7 0.60332263 <a title="306-lsi-7" href="./nips-2013-Graphical_Models_for_Inference_with_Missing_Data.html">134 nips-2013-Graphical Models for Inference with Missing Data</a></p>
<p>8 0.59673971 <a title="306-lsi-8" href="./nips-2013-Robust_Multimodal_Graph_Matching%3A_Sparse_Coding_Meets_Graph_Matching.html">282 nips-2013-Robust Multimodal Graph Matching: Sparse Coding Meets Graph Matching</a></p>
<p>9 0.55418456 <a title="306-lsi-9" href="./nips-2013-When_are_Overcomplete_Topic_Models_Identifiable%3F_Uniqueness_of_Tensor_Tucker_Decompositions_with_Structured_Sparsity.html">353 nips-2013-When are Overcomplete Topic Models Identifiable? Uniqueness of Tensor Tucker Decompositions with Structured Sparsity</a></p>
<p>10 0.53750044 <a title="306-lsi-10" href="./nips-2013-Large_Scale_Distributed_Sparse_Precision_Estimation.html">146 nips-2013-Large Scale Distributed Sparse Precision Estimation</a></p>
<p>11 0.52488303 <a title="306-lsi-11" href="./nips-2013-What_do_row_and_column_marginals_reveal_about_your_dataset%3F.html">352 nips-2013-What do row and column marginals reveal about your dataset?</a></p>
<p>12 0.5180462 <a title="306-lsi-12" href="./nips-2013-Fantope_Projection_and_Selection%3A_A_near-optimal_convex_relaxation_of_sparse_PCA.html">116 nips-2013-Fantope Projection and Selection: A near-optimal convex relaxation of sparse PCA</a></p>
<p>13 0.51225263 <a title="306-lsi-13" href="./nips-2013-BIG_%26_QUIC%3A_Sparse_Inverse_Covariance_Estimation_for_a_Million_Variables.html">45 nips-2013-BIG & QUIC: Sparse Inverse Covariance Estimation for a Million Variables</a></p>
<p>14 0.51105708 <a title="306-lsi-14" href="./nips-2013-B-test%3A_A_Non-parametric%2C_Low_Variance_Kernel_Two-sample_Test.html">44 nips-2013-B-test: A Non-parametric, Low Variance Kernel Two-sample Test</a></p>
<p>15 0.50102895 <a title="306-lsi-15" href="./nips-2013-New_Subsampling_Algorithms_for_Fast_Least_Squares_Regression.html">209 nips-2013-New Subsampling Algorithms for Fast Least Squares Regression</a></p>
<p>16 0.50014508 <a title="306-lsi-16" href="./nips-2013-It_is_all_in_the_noise%3A_Efficient_multi-task_Gaussian_process_inference_with_structured_residuals.html">145 nips-2013-It is all in the noise: Efficient multi-task Gaussian process inference with structured residuals</a></p>
<p>17 0.49601737 <a title="306-lsi-17" href="./nips-2013-On_the_Sample_Complexity_of_Subspace_Learning.html">224 nips-2013-On the Sample Complexity of Subspace Learning</a></p>
<p>18 0.49489406 <a title="306-lsi-18" href="./nips-2013-Matrix_factorization_with_binary_components.html">186 nips-2013-Matrix factorization with binary components</a></p>
<p>19 0.47448349 <a title="306-lsi-19" href="./nips-2013-Sparse_Inverse_Covariance_Estimation_with_Calibration.html">302 nips-2013-Sparse Inverse Covariance Estimation with Calibration</a></p>
<p>20 0.4730874 <a title="306-lsi-20" href="./nips-2013-Learning_Hidden_Markov_Models_from_Non-sequence_Data_via_Tensor_Decomposition.html">155 nips-2013-Learning Hidden Markov Models from Non-sequence Data via Tensor Decomposition</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(9, 0.259), (20, 0.233), (25, 0.073), (37, 0.06), (70, 0.043), (80, 0.084), (86, 0.092), (87, 0.078)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.84184629 <a title="306-lda-1" href="./nips-2013-Pass-efficient_unsupervised_feature_selection.html">245 nips-2013-Pass-efficient unsupervised feature selection</a></p>
<p>same-paper 2 0.82043153 <a title="306-lda-2" href="./nips-2013-Speeding_up_Permutation_Testing_in_Neuroimaging.html">306 nips-2013-Speeding up Permutation Testing in Neuroimaging</a></p>
<p>3 0.7954796 <a title="306-lda-3" href="./nips-2013-Estimation%2C_Optimization%2C_and_Parallelism_when_Data_is_Sparse.html">111 nips-2013-Estimation, Optimization, and Parallelism when Data is Sparse</a></p>
<p>4 0.78247339 <a title="306-lda-4" href="./nips-2013-How_to_Hedge_an_Option_Against_an_Adversary%3A_Black-Scholes_Pricing_is_Minimax_Optimal.html">139 nips-2013-How to Hedge an Option Against an Adversary: Black-Scholes Pricing is Minimax Optimal</a></p>
<p>5 0.77663106 <a title="306-lda-5" href="./nips-2013-Online_Learning_of_Nonparametric_Mixture_Models_via_Sequential_Variational_Approximation.html">229 nips-2013-Online Learning of Nonparametric Mixture Models via Sequential Variational Approximation</a></p>
<p>6 0.74015445 <a title="306-lda-6" href="./nips-2013-B-test%3A_A_Non-parametric%2C_Low_Variance_Kernel_Two-sample_Test.html">44 nips-2013-B-test: A Non-parametric, Low Variance Kernel Two-sample Test</a></p>
<p>7 0.73875189 <a title="306-lda-7" href="./nips-2013-Optimal_Neural_Population_Codes_for_High-dimensional_Stimulus_Variables.html">236 nips-2013-Optimal Neural Population Codes for High-dimensional Stimulus Variables</a></p>
<p>8 0.73859853 <a title="306-lda-8" href="./nips-2013-Stochastic_Optimization_of_PCA_with_Capped_MSG.html">314 nips-2013-Stochastic Optimization of PCA with Capped MSG</a></p>
<p>9 0.73527348 <a title="306-lda-9" href="./nips-2013-Fast_Algorithms_for_Gaussian_Noise_Invariant_Independent_Component_Analysis.html">117 nips-2013-Fast Algorithms for Gaussian Noise Invariant Independent Component Analysis</a></p>
<p>10 0.73509979 <a title="306-lda-10" href="./nips-2013-Analyzing_Hogwild_Parallel_Gaussian_Gibbs_Sampling.html">34 nips-2013-Analyzing Hogwild Parallel Gaussian Gibbs Sampling</a></p>
<p>11 0.73505276 <a title="306-lda-11" href="./nips-2013-A_Kernel_Test_for_Three-Variable_Interactions.html">9 nips-2013-A Kernel Test for Three-Variable Interactions</a></p>
<p>12 0.73483503 <a title="306-lda-12" href="./nips-2013-Low-rank_matrix_reconstruction_and_clustering_via_approximate_message_passing.html">180 nips-2013-Low-rank matrix reconstruction and clustering via approximate message passing</a></p>
<p>13 0.73292857 <a title="306-lda-13" href="./nips-2013-Large_Scale_Distributed_Sparse_Precision_Estimation.html">146 nips-2013-Large Scale Distributed Sparse Precision Estimation</a></p>
<p>14 0.7327686 <a title="306-lda-14" href="./nips-2013-Trading_Computation_for_Communication%3A_Distributed_Stochastic_Dual_Coordinate_Ascent.html">333 nips-2013-Trading Computation for Communication: Distributed Stochastic Dual Coordinate Ascent</a></p>
<p>15 0.7325905 <a title="306-lda-15" href="./nips-2013-Sparse_Overlapping_Sets_Lasso_for_Multitask_Learning_and_its_Application_to_fMRI_Analysis.html">303 nips-2013-Sparse Overlapping Sets Lasso for Multitask Learning and its Application to fMRI Analysis</a></p>
<p>16 0.73224121 <a title="306-lda-16" href="./nips-2013-On_model_selection_consistency_of_penalized_M-estimators%3A_a_geometric_theory.html">219 nips-2013-On model selection consistency of penalized M-estimators: a geometric theory</a></p>
<p>17 0.73210335 <a title="306-lda-17" href="./nips-2013-Learning_Multiple_Models_via_Regularized_Weighting.html">158 nips-2013-Learning Multiple Models via Regularized Weighting</a></p>
<p>18 0.73191911 <a title="306-lda-18" href="./nips-2013-On_the_Linear_Convergence_of_the_Proximal_Gradient_Method_for_Trace_Norm_Regularization.html">222 nips-2013-On the Linear Convergence of the Proximal Gradient Method for Trace Norm Regularization</a></p>
<p>19 0.73185283 <a title="306-lda-19" href="./nips-2013-Extracting_regions_of_interest_from_biological_images_with_convolutional_sparse_block_coding.html">114 nips-2013-Extracting regions of interest from biological images with convolutional sparse block coding</a></p>
<p>20 0.73167783 <a title="306-lda-20" href="./nips-2013-It_is_all_in_the_noise%3A_Efficient_multi-task_Gaussian_process_inference_with_structured_residuals.html">145 nips-2013-It is all in the noise: Efficient multi-task Gaussian process inference with structured residuals</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
