<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>82 nips-2013-Decision Jungles: Compact and Rich Models for Classification</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-82" href="#">nips2013-82</a> knowledge-graph by maker-knowledge-mining</p><h1>82 nips-2013-Decision Jungles: Compact and Rich Models for Classification</h1>
<br/><p>Source: <a title="nips-2013-82-pdf" href="http://papers.nips.cc/paper/5199-decision-jungles-compact-and-rich-models-for-classification.pdf">pdf</a></p><p>Author: Jamie Shotton, Toby Sharp, Pushmeet Kohli, Sebastian Nowozin, John Winn, Antonio Criminisi</p><p>Abstract: Randomized decision trees and forests have a rich history in machine learning and have seen considerable success in application, perhaps particularly so for computer vision. However, they face a fundamental limitation: given enough data, the number of nodes in decision trees will grow exponentially with depth. For certain applications, for example on mobile or embedded processors, memory is a limited resource, and so the exponential growth of trees limits their depth, and thus their potential accuracy. This paper proposes decision jungles, revisiting the idea of ensembles of rooted decision directed acyclic graphs (DAGs), and shows these to be compact and powerful discriminative models for classiﬁcation. Unlike conventional decision trees that only allow one path to every node, a DAG in a decision jungle allows multiple paths from the root to each leaf. We present and compare two new node merging algorithms that jointly optimize both the features and the structure of the DAGs efﬁciently. During training, node splitting and node merging are driven by the minimization of exactly the same objective function, here the weighted sum of entropies at the leaves. Results on varied datasets show that, compared to decision forests and several other baselines, decision jungles require dramatically less memory while considerably improving generalization. 1</p><p>Reference: <a title="nips-2013-82-reference" href="../nips2013_reference/nips-2013-Decision_Jungles%3A_Compact_and_Rich_Models_for_Classification_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('dag', 0.588), ('jungl', 0.51), ('merg', 0.259), ('nod', 0.224), ('decid', 0.183), ('forest', 0.168), ('tre', 0.151), ('kinect', 0.127), ('lsearch', 0.113), ('ensembl', 0.106), ('csg', 0.099), ('seg', 0.097), ('nc', 0.09), ('split', 0.09), ('baselin', 0.084), ('np', 0.082), ('grass', 0.079), ('scheduled', 0.075), ('clustersearch', 0.071), ('root', 0.068)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="82-tfidf-1" href="./nips-2013-Decision_Jungles%3A_Compact_and_Rich_Models_for_Classification.html">82 nips-2013-Decision Jungles: Compact and Rich Models for Classification</a></p>
<p>2 0.2071438 <a title="82-tfidf-2" href="./nips-2013-Estimation%2C_Optimization%2C_and_Parallelism_when_Data_is_Sparse.html">111 nips-2013-Estimation, Optimization, and Parallelism when Data is Sparse</a></p>
<p>3 0.15653601 <a title="82-tfidf-3" href="./nips-2013-Understanding_variable_importances_in_forests_of_randomized_trees.html">340 nips-2013-Understanding variable importances in forests of randomized trees</a></p>
<p>4 0.13059364 <a title="82-tfidf-4" href="./nips-2013-Scalable_kernels_for_graphs_with_continuous_attributes.html">289 nips-2013-Scalable kernels for graphs with continuous attributes</a></p>
<p>5 0.10733414 <a title="82-tfidf-5" href="./nips-2013-Which_Space_Partitioning_Tree_to_Use_for_Search%3F.html">355 nips-2013-Which Space Partitioning Tree to Use for Search?</a></p>
<p>6 0.10716198 <a title="82-tfidf-6" href="./nips-2013-Discriminative_Transfer_Learning_with_Tree-based_Priors.html">93 nips-2013-Discriminative Transfer Learning with Tree-based Priors</a></p>
<p>7 0.10685151 <a title="82-tfidf-7" href="./nips-2013-Visual_Concept_Learning%3A_Combining_Machine_Vision_and_Bayesian_Generalization_on_Concept_Hierarchies.html">349 nips-2013-Visual Concept Learning: Combining Machine Vision and Bayesian Generalization on Concept Hierarchies</a></p>
<p>8 0.10577054 <a title="82-tfidf-8" href="./nips-2013-Parallel_Sampling_of_DP_Mixture_Models_using_Sub-Cluster_Splits.html">243 nips-2013-Parallel Sampling of DP Mixture Models using Sub-Cluster Splits</a></p>
<p>9 0.10336494 <a title="82-tfidf-9" href="./nips-2013-Aggregating_Optimistic_Planning_Trees_for_Solving_Markov_Decision_Processes.html">32 nips-2013-Aggregating Optimistic Planning Trees for Solving Markov Decision Processes</a></p>
<p>10 0.096130393 <a title="82-tfidf-10" href="./nips-2013-Memoized_Online_Variational_Inference_for_Dirichlet_Process_Mixture_Models.html">187 nips-2013-Memoized Online Variational Inference for Dirichlet Process Mixture Models</a></p>
<p>11 0.092928357 <a title="82-tfidf-11" href="./nips-2013-On_Flat_versus_Hierarchical_Classification_in_Large-Scale_Taxonomies.html">216 nips-2013-On Flat versus Hierarchical Classification in Large-Scale Taxonomies</a></p>
<p>12 0.092755169 <a title="82-tfidf-12" href="./nips-2013-Scalable_Influence_Estimation_in_Continuous-Time_Diffusion_Networks.html">288 nips-2013-Scalable Influence Estimation in Continuous-Time Diffusion Networks</a></p>
<p>13 0.092265129 <a title="82-tfidf-13" href="./nips-2013-A_Deep_Architecture_for_Matching_Short_Texts.html">5 nips-2013-A Deep Architecture for Matching Short Texts</a></p>
<p>14 0.087762564 <a title="82-tfidf-14" href="./nips-2013-Learning_Chordal_Markov_Networks_by_Constraint_Satisfaction.html">151 nips-2013-Learning Chordal Markov Networks by Constraint Satisfaction</a></p>
<p>15 0.086821318 <a title="82-tfidf-15" href="./nips-2013-Modeling_Overlapping_Communities_with_Node_Popularities.html">196 nips-2013-Modeling Overlapping Communities with Node Popularities</a></p>
<p>16 0.084498897 <a title="82-tfidf-16" href="./nips-2013-Non-Linear_Domain_Adaptation_with_Boosting.html">211 nips-2013-Non-Linear Domain Adaptation with Boosting</a></p>
<p>17 0.080468327 <a title="82-tfidf-17" href="./nips-2013-Bayesian_Hierarchical_Community_Discovery.html">47 nips-2013-Bayesian Hierarchical Community Discovery</a></p>
<p>18 0.079651572 <a title="82-tfidf-18" href="./nips-2013-Binary_to_Bushy%3A_Bayesian_Hierarchical_Clustering_with_the_Beta_Coalescent.html">58 nips-2013-Binary to Bushy: Bayesian Hierarchical Clustering with the Beta Coalescent</a></p>
<p>19 0.077981807 <a title="82-tfidf-19" href="./nips-2013-Computing_the_Stationary_Distribution_Locally.html">66 nips-2013-Computing the Stationary Distribution Locally</a></p>
<p>20 0.077245824 <a title="82-tfidf-20" href="./nips-2013-Linear_decision_rule_as_aspiration_for_simple_decision_heuristics.html">176 nips-2013-Linear decision rule as aspiration for simple decision heuristics</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.149), (1, 0.016), (2, 0.002), (3, -0.079), (4, -0.122), (5, -0.045), (6, 0.062), (7, 0.041), (8, 0.027), (9, -0.079), (10, 0.008), (11, -0.005), (12, 0.139), (13, -0.068), (14, -0.032), (15, 0.052), (16, -0.12), (17, 0.142), (18, 0.06), (19, -0.062), (20, -0.017), (21, 0.007), (22, -0.039), (23, -0.021), (24, 0.046), (25, 0.065), (26, -0.081), (27, -0.038), (28, 0.05), (29, 0.092), (30, 0.061), (31, 0.046), (32, -0.094), (33, 0.073), (34, 0.016), (35, 0.023), (36, -0.025), (37, 0.014), (38, 0.119), (39, -0.041), (40, 0.117), (41, -0.141), (42, -0.004), (43, -0.041), (44, 0.067), (45, -0.015), (46, -0.182), (47, 0.185), (48, -0.141), (49, 0.049)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94543874 <a title="82-lsi-1" href="./nips-2013-Decision_Jungles%3A_Compact_and_Rich_Models_for_Classification.html">82 nips-2013-Decision Jungles: Compact and Rich Models for Classification</a></p>
<p>2 0.7502808 <a title="82-lsi-2" href="./nips-2013-Understanding_variable_importances_in_forests_of_randomized_trees.html">340 nips-2013-Understanding variable importances in forests of randomized trees</a></p>
<p>3 0.67827624 <a title="82-lsi-3" href="./nips-2013-On_Flat_versus_Hierarchical_Classification_in_Large-Scale_Taxonomies.html">216 nips-2013-On Flat versus Hierarchical Classification in Large-Scale Taxonomies</a></p>
<p>4 0.65380764 <a title="82-lsi-4" href="./nips-2013-Binary_to_Bushy%3A_Bayesian_Hierarchical_Clustering_with_the_Beta_Coalescent.html">58 nips-2013-Binary to Bushy: Bayesian Hierarchical Clustering with the Beta Coalescent</a></p>
<p>5 0.59276742 <a title="82-lsi-5" href="./nips-2013-Bayesian_Hierarchical_Community_Discovery.html">47 nips-2013-Bayesian Hierarchical Community Discovery</a></p>
<p>6 0.56668681 <a title="82-lsi-6" href="./nips-2013-Discriminative_Transfer_Learning_with_Tree-based_Priors.html">93 nips-2013-Discriminative Transfer Learning with Tree-based Priors</a></p>
<p>7 0.55297512 <a title="82-lsi-7" href="./nips-2013-Unsupervised_Structure_Learning_of_Stochastic_And-Or_Grammars.html">343 nips-2013-Unsupervised Structure Learning of Stochastic And-Or Grammars</a></p>
<p>8 0.53212404 <a title="82-lsi-8" href="./nips-2013-Estimation%2C_Optimization%2C_and_Parallelism_when_Data_is_Sparse.html">111 nips-2013-Estimation, Optimization, and Parallelism when Data is Sparse</a></p>
<p>9 0.53019571 <a title="82-lsi-9" href="./nips-2013-Learning_Chordal_Markov_Networks_by_Constraint_Satisfaction.html">151 nips-2013-Learning Chordal Markov Networks by Constraint Satisfaction</a></p>
<p>10 0.52334249 <a title="82-lsi-10" href="./nips-2013-Which_Space_Partitioning_Tree_to_Use_for_Search%3F.html">355 nips-2013-Which Space Partitioning Tree to Use for Search?</a></p>
<p>11 0.51025134 <a title="82-lsi-11" href="./nips-2013-Learning_Gaussian_Graphical_Models_with_Observed_or_Latent_FVSs.html">154 nips-2013-Learning Gaussian Graphical Models with Observed or Latent FVSs</a></p>
<p>12 0.48325738 <a title="82-lsi-12" href="./nips-2013-Aggregating_Optimistic_Planning_Trees_for_Solving_Markov_Decision_Processes.html">32 nips-2013-Aggregating Optimistic Planning Trees for Solving Markov Decision Processes</a></p>
<p>13 0.46495244 <a title="82-lsi-13" href="./nips-2013-Scalable_kernels_for_graphs_with_continuous_attributes.html">289 nips-2013-Scalable kernels for graphs with continuous attributes</a></p>
<p>14 0.45053717 <a title="82-lsi-14" href="./nips-2013-Lexical_and_Hierarchical_Topic_Regression.html">174 nips-2013-Lexical and Hierarchical Topic Regression</a></p>
<p>15 0.45033455 <a title="82-lsi-15" href="./nips-2013-Linear_decision_rule_as_aspiration_for_simple_decision_heuristics.html">176 nips-2013-Linear decision rule as aspiration for simple decision heuristics</a></p>
<p>16 0.44545206 <a title="82-lsi-16" href="./nips-2013-Scalable_Influence_Estimation_in_Continuous-Time_Diffusion_Networks.html">288 nips-2013-Scalable Influence Estimation in Continuous-Time Diffusion Networks</a></p>
<p>17 0.44266 <a title="82-lsi-17" href="./nips-2013-Visual_Concept_Learning%3A_Combining_Machine_Vision_and_Bayesian_Generalization_on_Concept_Hierarchies.html">349 nips-2013-Visual Concept Learning: Combining Machine Vision and Bayesian Generalization on Concept Hierarchies</a></p>
<p>18 0.44233614 <a title="82-lsi-18" href="./nips-2013-A%2A_Lasso_for_Learning_a_Sparse_Bayesian_Network_Structure_for_Continuous_Variables.html">3 nips-2013-A* Lasso for Learning a Sparse Bayesian Network Structure for Continuous Variables</a></p>
<p>19 0.42847583 <a title="82-lsi-19" href="./nips-2013-Sensor_Selection_in_High-Dimensional_Gaussian_Trees_with_Nuisances.html">291 nips-2013-Sensor Selection in High-Dimensional Gaussian Trees with Nuisances</a></p>
<p>20 0.4258315 <a title="82-lsi-20" href="./nips-2013-Regularized_Spectral_Clustering_under_the_Degree-Corrected_Stochastic_Blockmodel.html">272 nips-2013-Regularized Spectral Clustering under the Degree-Corrected Stochastic Blockmodel</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(20, 0.108), (25, 0.53), (37, 0.073), (70, 0.037), (80, 0.063), (86, 0.033), (87, 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95312846 <a title="82-lda-1" href="./nips-2013-Decision_Jungles%3A_Compact_and_Rich_Models_for_Classification.html">82 nips-2013-Decision Jungles: Compact and Rich Models for Classification</a></p>
<p>2 0.94176704 <a title="82-lda-2" href="./nips-2013-Convex_Two-Layer_Modeling.html">75 nips-2013-Convex Two-Layer Modeling</a></p>
<p>3 0.93155891 <a title="82-lda-3" href="./nips-2013-Adaptive_dropout_for_training_deep_neural_networks.html">30 nips-2013-Adaptive dropout for training deep neural networks</a></p>
<p>4 0.92369837 <a title="82-lda-4" href="./nips-2013-Near-optimal_Anomaly_Detection_in_Graphs_using_Lovasz_Extended_Scan_Statistic.html">207 nips-2013-Near-optimal Anomaly Detection in Graphs using Lovasz Extended Scan Statistic</a></p>
<p>5 0.92277932 <a title="82-lda-5" href="./nips-2013-Scoring_Workers_in_Crowdsourcing%3A_How_Many_Control_Questions_are_Enough%3F.html">290 nips-2013-Scoring Workers in Crowdsourcing: How Many Control Questions are Enough?</a></p>
<p>6 0.90979683 <a title="82-lda-6" href="./nips-2013-A_Deep_Architecture_for_Matching_Short_Texts.html">5 nips-2013-A Deep Architecture for Matching Short Texts</a></p>
<p>7 0.84755105 <a title="82-lda-7" href="./nips-2013-Top-Down_Regularization_of_Deep_Belief_Networks.html">331 nips-2013-Top-Down Regularization of Deep Belief Networks</a></p>
<p>8 0.82931131 <a title="82-lda-8" href="./nips-2013-Compressive_Feature_Learning.html">65 nips-2013-Compressive Feature Learning</a></p>
<p>9 0.82540965 <a title="82-lda-9" href="./nips-2013-Regret_based_Robust_Solutions_for_Uncertain_Markov_Decision_Processes.html">270 nips-2013-Regret based Robust Solutions for Uncertain Markov Decision Processes</a></p>
<p>10 0.78377324 <a title="82-lda-10" href="./nips-2013-A_Latent_Source_Model_for_Nonparametric_Time_Series_Classification.html">10 nips-2013-A Latent Source Model for Nonparametric Time Series Classification</a></p>
<p>11 0.77864087 <a title="82-lda-11" href="./nips-2013-Discriminative_Transfer_Learning_with_Tree-based_Priors.html">93 nips-2013-Discriminative Transfer Learning with Tree-based Priors</a></p>
<p>12 0.77614605 <a title="82-lda-12" href="./nips-2013-Understanding_Dropout.html">339 nips-2013-Understanding Dropout</a></p>
<p>13 0.76979929 <a title="82-lda-13" href="./nips-2013-Multi-Prediction_Deep_Boltzmann_Machines.html">200 nips-2013-Multi-Prediction Deep Boltzmann Machines</a></p>
<p>14 0.76138759 <a title="82-lda-14" href="./nips-2013-Compete_to_Compute.html">64 nips-2013-Compete to Compute</a></p>
<p>15 0.75891292 <a title="82-lda-15" href="./nips-2013-A_Novel_Two-Step_Method_for_Cross_Language_Representation_Learning.html">12 nips-2013-A Novel Two-Step Method for Cross Language Representation Learning</a></p>
<p>16 0.75882381 <a title="82-lda-16" href="./nips-2013-Stochastic_Ratio_Matching_of_RBMs_for_Sparse_High-Dimensional_Inputs.html">315 nips-2013-Stochastic Ratio Matching of RBMs for Sparse High-Dimensional Inputs</a></p>
<p>17 0.75371939 <a title="82-lda-17" href="./nips-2013-Training_and_Analysing_Deep_Recurrent_Neural_Networks.html">334 nips-2013-Training and Analysing Deep Recurrent Neural Networks</a></p>
<p>18 0.75132823 <a title="82-lda-18" href="./nips-2013-Reshaping_Visual_Datasets_for_Domain_Adaptation.html">276 nips-2013-Reshaping Visual Datasets for Domain Adaptation</a></p>
<p>19 0.74913335 <a title="82-lda-19" href="./nips-2013-%CE%A3-Optimality_for_Active_Learning_on_Gaussian_Random_Fields.html">359 nips-2013-Σ-Optimality for Active Learning on Gaussian Random Fields</a></p>
<p>20 0.74359018 <a title="82-lda-20" href="./nips-2013-Dropout_Training_as_Adaptive_Regularization.html">99 nips-2013-Dropout Training as Adaptive Regularization</a></p>
<br/><br/><br/></body>
</html>
