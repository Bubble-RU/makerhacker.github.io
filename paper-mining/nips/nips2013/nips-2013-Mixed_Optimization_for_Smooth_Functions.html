<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>193 nips-2013-Mixed Optimization for Smooth Functions</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-193" href="#">nips2013-193</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>193 nips-2013-Mixed Optimization for Smooth Functions</h1>
<br/><p>Source: <a title="nips-2013-193-pdf" href="http://papers.nips.cc/paper/4941-mixed-optimization-for-smooth-functions.pdf">pdf</a></p><p>Author: Mehrdad Mahdavi, Lijun Zhang, Rong Jin</p><p>Abstract: It is well known that the optimal convergence rate for stochastic optimization of √ smooth functions is O(1/ T ), which is same as stochastic optimization of Lipschitz continuous convex functions. This is in contrast to optimizing smooth functions using full gradients, which yields a convergence rate of O(1/T 2 ). In this work, we consider a new setup for optimizing smooth functions, termed as Mixed Optimization, which allows to access both a stochastic oracle and a full gradient oracle. Our goal is to signiﬁcantly improve the convergence rate of stochastic optimization of smooth functions by having an additional small number of accesses to the full gradient oracle. We show that, with an O(ln T ) calls to the full gradient oracle and an O(T ) calls to the stochastic oracle, the proposed mixed optimization algorithm is able to achieve an optimization error of O(1/T ). 1</p><p>Reference: <a title="nips-2013-193-reference" href="../nips2013_reference/nips-2013-Mixed_Optimization_for_Smooth_Functions_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('wk', 0.575), ('gi', 0.315), ('wt', 0.254), ('epoch', 0.245), ('orac', 0.241), ('wm', 0.24), ('grady', 0.196), ('git', 0.174), ('stochast', 0.172), ('os', 0.153), ('smoo', 0.139), ('fm', 0.136), ('ix', 0.128), ('fk', 0.127), ('gd', 0.111), ('ln', 0.105), ('gk', 0.099), ('access', 0.095), ('sgd', 0.088), ('kth', 0.082)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999964 <a title="193-tfidf-1" href="./nips-2013-Mixed_Optimization_for_Smooth_Functions.html">193 nips-2013-Mixed Optimization for Smooth Functions</a></p>
<p>Author: Mehrdad Mahdavi, Lijun Zhang, Rong Jin</p><p>Abstract: It is well known that the optimal convergence rate for stochastic optimization of √ smooth functions is O(1/ T ), which is same as stochastic optimization of Lipschitz continuous convex functions. This is in contrast to optimizing smooth functions using full gradients, which yields a convergence rate of O(1/T 2 ). In this work, we consider a new setup for optimizing smooth functions, termed as Mixed Optimization, which allows to access both a stochastic oracle and a full gradient oracle. Our goal is to signiﬁcantly improve the convergence rate of stochastic optimization of smooth functions by having an additional small number of accesses to the full gradient oracle. We show that, with an O(ln T ) calls to the full gradient oracle and an O(T ) calls to the stochastic oracle, the proposed mixed optimization algorithm is able to achieve an optimization error of O(1/T ). 1</p><p>2 0.50561595 <a title="193-tfidf-2" href="./nips-2013-Linear_Convergence_with_Condition_Number_Independent_Access_of_Full_Gradients.html">175 nips-2013-Linear Convergence with Condition Number Independent Access of Full Gradients</a></p>
<p>Author: Lijun Zhang, Mehrdad Mahdavi, Rong Jin</p><p>Abstract: For smooth and strongly convex optimizations, the optimal iteration complexity of √ the gradient-based algorithm is O( κ log 1/ǫ), where κ is the condition number. In the case that the optimization problem is ill-conditioned, we need to evaluate a large number of full gradients, which could be computationally expensive. In this paper, we propose to remove the dependence on the condition number by allowing the algorithm to access stochastic gradients of the objective function. To this end, we present a novel algorithm named Epoch Mixed Gradient Descent (EMGD) that is able to utilize two kinds of gradients. A distinctive step in EMGD is the mixed gradient descent, where we use a combination of the full and stochastic gradients to update the intermediate solution. Theoretical analysis shows that EMGD is able to ﬁnd an ǫ-optimal solution by computing O(log 1/ǫ) full gradients and O(κ2 log 1/ǫ) stochastic gradients. 1</p><p>3 0.30869839 <a title="193-tfidf-3" href="./nips-2013-Stochastic_Convex_Optimization_with_Multiple__Objectives.html">311 nips-2013-Stochastic Convex Optimization with Multiple  Objectives</a></p>
<p>Author: Mehrdad Mahdavi, Tianbao Yang, Rong Jin</p><p>Abstract: In this paper, we are interested in the development of efﬁcient algorithms for convex optimization problems in the simultaneous presence of multiple objectives and stochasticity in the ﬁrst-order information. We cast the stochastic multiple objective optimization problem into a constrained optimization problem by choosing one function as the objective and try to bound other objectives by appropriate thresholds. We ﬁrst examine a two stages exploration-exploitation based algorithm which ﬁrst approximates the stochastic objectives by sampling and then solves a constrained stochastic optimization problem by projected gradient method. This method attains a suboptimal convergence rate even under strong assumption on the objectives. Our second approach is an efﬁcient primal-dual stochastic algorithm. It leverages on the theory of Lagrangian method √ conin strained optimization and attains the optimal convergence rate of O(1/ T ) in high probability for general Lipschitz continuous objectives.</p><p>4 0.23207924 <a title="193-tfidf-4" href="./nips-2013-Optimistic_policy_iteration_and_natural_actor-critic%3A_A_unifying_view_and_a_non-optimality_result.html">239 nips-2013-Optimistic policy iteration and natural actor-critic: A unifying view and a non-optimality result</a></p>
<p>Author: Paul Wagner</p><p>Abstract: Approximate dynamic programming approaches to the reinforcement learning problem are often categorized into greedy value function methods and value-based policy gradient methods. As our ﬁrst main result, we show that an important subset of the latter methodology is, in fact, a limiting special case of a general formulation of the former methodology; optimistic policy iteration encompasses not only most of the greedy value function methods but also natural actor-critic methods, and permits one to directly interpolate between them. The resulting continuum adjusts the strength of the Markov assumption in policy improvement and, as such, can be seen as dual in spirit to the continuum in TD(λ)-style algorithms in policy evaluation. As our second main result, we show for a substantial subset of softgreedy value function approaches that, while having the potential to avoid policy oscillation and policy chattering, this subset can never converge toward an optimal policy, except in a certain pathological case. Consequently, in the context of approximations (either in state estimation or in value function representation), the majority of greedy value function methods seem to be deemed to suffer either from the risk of oscillation/chattering or from the presence of systematic sub-optimality. 1</p><p>5 0.21879573 <a title="193-tfidf-5" href="./nips-2013-Optimal_Neural_Population_Codes_for_High-dimensional_Stimulus_Variables.html">236 nips-2013-Optimal Neural Population Codes for High-dimensional Stimulus Variables</a></p>
<p>Author: Zhuo Wang, Alan Stocker, Daniel Lee</p><p>Abstract: In many neural systems, information about stimulus variables is often represented in a distributed manner by means of a population code. It is generally assumed that the responses of the neural population are tuned to the stimulus statistics, and most prior work has investigated the optimal tuning characteristics of one or a small number of stimulus variables. In this work, we investigate the optimal tuning for diffeomorphic representations of high-dimensional stimuli. We analytically derive the solution that minimizes the L2 reconstruction loss. We compared our solution with other well-known criteria such as maximal mutual information. Our solution suggests that the optimal weights do not necessarily decorrelate the inputs, and the optimal nonlinearity differs from the conventional equalization solution. Results illustrating these optimal representations are shown for some input distributions that may be relevant for understanding the coding of perceptual pathways. 1</p><p>6 0.18228208 <a title="193-tfidf-6" href="./nips-2013-Accelerating_Stochastic_Gradient_Descent_using_Predictive_Variance_Reduction.html">20 nips-2013-Accelerating Stochastic Gradient Descent using Predictive Variance Reduction</a></p>
<p>7 0.13847579 <a title="193-tfidf-7" href="./nips-2013-Stochastic_Majorization-Minimization_Algorithms_for_Large-Scale_Optimization.html">313 nips-2013-Stochastic Majorization-Minimization Algorithms for Large-Scale Optimization</a></p>
<p>8 0.13489106 <a title="193-tfidf-8" href="./nips-2013-Variance_Reduction_for_Stochastic_Gradient_Optimization.html">345 nips-2013-Variance Reduction for Stochastic Gradient Optimization</a></p>
<p>9 0.12641118 <a title="193-tfidf-9" href="./nips-2013-Trading_Computation_for_Communication%3A_Distributed_Stochastic_Dual_Coordinate_Ascent.html">333 nips-2013-Trading Computation for Communication: Distributed Stochastic Dual Coordinate Ascent</a></p>
<p>10 0.12484375 <a title="193-tfidf-10" href="./nips-2013-%28Nearly%29_Optimal_Algorithms_for_Private_Online_Learning_in_Full-information_and_Bandit_Settings.html">2 nips-2013-(Nearly) Optimal Algorithms for Private Online Learning in Full-information and Bandit Settings</a></p>
<p>11 0.1222906 <a title="193-tfidf-11" href="./nips-2013-Projected_Natural_Actor-Critic.html">257 nips-2013-Projected Natural Actor-Critic</a></p>
<p>12 0.1218259 <a title="193-tfidf-12" href="./nips-2013-On_the_Linear_Convergence_of_the_Proximal_Gradient_Method_for_Trace_Norm_Regularization.html">222 nips-2013-On the Linear Convergence of the Proximal Gradient Method for Trace Norm Regularization</a></p>
<p>13 0.11683413 <a title="193-tfidf-13" href="./nips-2013-Dimension-Free_Exponentiated_Gradient.html">89 nips-2013-Dimension-Free Exponentiated Gradient</a></p>
<p>14 0.10745728 <a title="193-tfidf-14" href="./nips-2013-Adaptive_Submodular_Maximization_in_Bandit_Setting.html">29 nips-2013-Adaptive Submodular Maximization in Bandit Setting</a></p>
<p>15 0.1059033 <a title="193-tfidf-15" href="./nips-2013-Online_Learning_of_Nonparametric_Mixture_Models_via_Sequential_Variational_Approximation.html">229 nips-2013-Online Learning of Nonparametric Mixture Models via Sequential Variational Approximation</a></p>
<p>16 0.090082794 <a title="193-tfidf-16" href="./nips-2013-Online_Learning_with_Costly_Features_and_Labels.html">230 nips-2013-Online Learning with Costly Features and Labels</a></p>
<p>17 0.09004391 <a title="193-tfidf-17" href="./nips-2013-Learning_Feature_Selection_Dependencies_in_Multi-task_Learning.html">153 nips-2013-Learning Feature Selection Dependencies in Multi-task Learning</a></p>
<p>18 0.086936958 <a title="193-tfidf-18" href="./nips-2013-Better_Approximation_and_Faster_Algorithm_Using_the_Proximal_Average.html">56 nips-2013-Better Approximation and Faster Algorithm Using the Proximal Average</a></p>
<p>19 0.084884353 <a title="193-tfidf-19" href="./nips-2013-Regularized_M-estimators_with_nonconvexity%3A_Statistical_and_algorithmic_theory_for_local_optima.html">271 nips-2013-Regularized M-estimators with nonconvexity: Statistical and algorithmic theory for local optima</a></p>
<p>20 0.078844965 <a title="193-tfidf-20" href="./nips-2013-PAC-Bayes-Empirical-Bernstein_Inequality.html">242 nips-2013-PAC-Bayes-Empirical-Bernstein Inequality</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.184), (1, -0.038), (2, 0.062), (3, 0.1), (4, -0.011), (5, 0.064), (6, -0.039), (7, -0.322), (8, 0.015), (9, -0.133), (10, -0.187), (11, 0.323), (12, -0.166), (13, -0.264), (14, 0.001), (15, -0.14), (16, -0.109), (17, 0.006), (18, -0.031), (19, -0.035), (20, 0.09), (21, -0.07), (22, 0.014), (23, -0.075), (24, -0.031), (25, -0.011), (26, 0.009), (27, 0.018), (28, -0.027), (29, -0.013), (30, 0.038), (31, 0.043), (32, -0.06), (33, -0.041), (34, 0.017), (35, 0.02), (36, -0.002), (37, -0.048), (38, -0.053), (39, 0.055), (40, -0.077), (41, 0.032), (42, -0.039), (43, 0.01), (44, -0.043), (45, -0.014), (46, -0.063), (47, -0.006), (48, -0.063), (49, 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.96867532 <a title="193-lsi-1" href="./nips-2013-Mixed_Optimization_for_Smooth_Functions.html">193 nips-2013-Mixed Optimization for Smooth Functions</a></p>
<p>Author: Mehrdad Mahdavi, Lijun Zhang, Rong Jin</p><p>Abstract: It is well known that the optimal convergence rate for stochastic optimization of √ smooth functions is O(1/ T ), which is same as stochastic optimization of Lipschitz continuous convex functions. This is in contrast to optimizing smooth functions using full gradients, which yields a convergence rate of O(1/T 2 ). In this work, we consider a new setup for optimizing smooth functions, termed as Mixed Optimization, which allows to access both a stochastic oracle and a full gradient oracle. Our goal is to signiﬁcantly improve the convergence rate of stochastic optimization of smooth functions by having an additional small number of accesses to the full gradient oracle. We show that, with an O(ln T ) calls to the full gradient oracle and an O(T ) calls to the stochastic oracle, the proposed mixed optimization algorithm is able to achieve an optimization error of O(1/T ). 1</p><p>2 0.93069839 <a title="193-lsi-2" href="./nips-2013-Linear_Convergence_with_Condition_Number_Independent_Access_of_Full_Gradients.html">175 nips-2013-Linear Convergence with Condition Number Independent Access of Full Gradients</a></p>
<p>Author: Lijun Zhang, Mehrdad Mahdavi, Rong Jin</p><p>Abstract: For smooth and strongly convex optimizations, the optimal iteration complexity of √ the gradient-based algorithm is O( κ log 1/ǫ), where κ is the condition number. In the case that the optimization problem is ill-conditioned, we need to evaluate a large number of full gradients, which could be computationally expensive. In this paper, we propose to remove the dependence on the condition number by allowing the algorithm to access stochastic gradients of the objective function. To this end, we present a novel algorithm named Epoch Mixed Gradient Descent (EMGD) that is able to utilize two kinds of gradients. A distinctive step in EMGD is the mixed gradient descent, where we use a combination of the full and stochastic gradients to update the intermediate solution. Theoretical analysis shows that EMGD is able to ﬁnd an ǫ-optimal solution by computing O(log 1/ǫ) full gradients and O(κ2 log 1/ǫ) stochastic gradients. 1</p><p>3 0.84148145 <a title="193-lsi-3" href="./nips-2013-Stochastic_Convex_Optimization_with_Multiple__Objectives.html">311 nips-2013-Stochastic Convex Optimization with Multiple  Objectives</a></p>
<p>Author: Mehrdad Mahdavi, Tianbao Yang, Rong Jin</p><p>Abstract: In this paper, we are interested in the development of efﬁcient algorithms for convex optimization problems in the simultaneous presence of multiple objectives and stochasticity in the ﬁrst-order information. We cast the stochastic multiple objective optimization problem into a constrained optimization problem by choosing one function as the objective and try to bound other objectives by appropriate thresholds. We ﬁrst examine a two stages exploration-exploitation based algorithm which ﬁrst approximates the stochastic objectives by sampling and then solves a constrained stochastic optimization problem by projected gradient method. This method attains a suboptimal convergence rate even under strong assumption on the objectives. Our second approach is an efﬁcient primal-dual stochastic algorithm. It leverages on the theory of Lagrangian method √ conin strained optimization and attains the optimal convergence rate of O(1/ T ) in high probability for general Lipschitz continuous objectives.</p><p>4 0.80509531 <a title="193-lsi-4" href="./nips-2013-Accelerating_Stochastic_Gradient_Descent_using_Predictive_Variance_Reduction.html">20 nips-2013-Accelerating Stochastic Gradient Descent using Predictive Variance Reduction</a></p>
<p>Author: Rie Johnson, Tong Zhang</p><p>Abstract: Stochastic gradient descent is popular for large scale optimization but has slow convergence asymptotically due to the inherent variance. To remedy this problem, we introduce an explicit variance reduction method for stochastic gradient descent which we call stochastic variance reduced gradient (SVRG). For smooth and strongly convex functions, we prove that this method enjoys the same fast convergence rate as those of stochastic dual coordinate ascent (SDCA) and Stochastic Average Gradient (SAG). However, our analysis is signiﬁcantly simpler and more intuitive. Moreover, unlike SDCA or SAG, our method does not require the storage of gradients, and thus is more easily applicable to complex problems such as some structured prediction problems and neural network learning. 1</p><p>5 0.70427382 <a title="193-lsi-5" href="./nips-2013-Trading_Computation_for_Communication%3A_Distributed_Stochastic_Dual_Coordinate_Ascent.html">333 nips-2013-Trading Computation for Communication: Distributed Stochastic Dual Coordinate Ascent</a></p>
<p>Author: Tianbao Yang</p><p>Abstract: We present and study a distributed optimization algorithm by employing a stochastic dual coordinate ascent method. Stochastic dual coordinate ascent methods enjoy strong theoretical guarantees and often have better performances than stochastic gradient descent methods in optimizing regularized loss minimization problems. It still lacks of efforts in studying them in a distributed framework. We make a progress along the line by presenting a distributed stochastic dual coordinate ascent algorithm in a star network, with an analysis of the tradeoff between computation and communication. We verify our analysis by experiments on real data sets. Moreover, we compare the proposed algorithm with distributed stochastic gradient descent methods and distributed alternating direction methods of multipliers for optimizing SVMs in the same distributed framework, and observe competitive performances. 1</p><p>6 0.57464516 <a title="193-lsi-6" href="./nips-2013-Stochastic_Majorization-Minimization_Algorithms_for_Large-Scale_Optimization.html">313 nips-2013-Stochastic Majorization-Minimization Algorithms for Large-Scale Optimization</a></p>
<p>7 0.5714348 <a title="193-lsi-7" href="./nips-2013-Variance_Reduction_for_Stochastic_Gradient_Optimization.html">345 nips-2013-Variance Reduction for Stochastic Gradient Optimization</a></p>
<p>8 0.53207982 <a title="193-lsi-8" href="./nips-2013-Accelerated_Mini-Batch_Stochastic_Dual_Coordinate_Ascent.html">19 nips-2013-Accelerated Mini-Batch Stochastic Dual Coordinate Ascent</a></p>
<p>9 0.44728029 <a title="193-lsi-9" href="./nips-2013-On_the_Linear_Convergence_of_the_Proximal_Gradient_Method_for_Trace_Norm_Regularization.html">222 nips-2013-On the Linear Convergence of the Proximal Gradient Method for Trace Norm Regularization</a></p>
<p>10 0.44560954 <a title="193-lsi-10" href="./nips-2013-%28Nearly%29_Optimal_Algorithms_for_Private_Online_Learning_in_Full-information_and_Bandit_Settings.html">2 nips-2013-(Nearly) Optimal Algorithms for Private Online Learning in Full-information and Bandit Settings</a></p>
<p>11 0.43905056 <a title="193-lsi-11" href="./nips-2013-Projected_Natural_Actor-Critic.html">257 nips-2013-Projected Natural Actor-Critic</a></p>
<p>12 0.38594201 <a title="193-lsi-12" href="./nips-2013-On_Algorithms_for_Sparse_Multi-factor_NMF.html">214 nips-2013-On Algorithms for Sparse Multi-factor NMF</a></p>
<p>13 0.3843137 <a title="193-lsi-13" href="./nips-2013-Dimension-Free_Exponentiated_Gradient.html">89 nips-2013-Dimension-Free Exponentiated Gradient</a></p>
<p>14 0.37291297 <a title="193-lsi-14" href="./nips-2013-Better_Approximation_and_Faster_Algorithm_Using_the_Proximal_Average.html">56 nips-2013-Better Approximation and Faster Algorithm Using the Proximal Average</a></p>
<p>15 0.37257862 <a title="193-lsi-15" href="./nips-2013-Optimal_Neural_Population_Codes_for_High-dimensional_Stimulus_Variables.html">236 nips-2013-Optimal Neural Population Codes for High-dimensional Stimulus Variables</a></p>
<p>16 0.36148417 <a title="193-lsi-16" href="./nips-2013-Estimation%2C_Optimization%2C_and_Parallelism_when_Data_is_Sparse.html">111 nips-2013-Estimation, Optimization, and Parallelism when Data is Sparse</a></p>
<p>17 0.35518062 <a title="193-lsi-17" href="./nips-2013-Bayesian_inference_for_low_rank_spatiotemporal_neural_receptive_fields.html">53 nips-2013-Bayesian inference for low rank spatiotemporal neural receptive fields</a></p>
<p>18 0.35305032 <a title="193-lsi-18" href="./nips-2013-Optimistic_policy_iteration_and_natural_actor-critic%3A_A_unifying_view_and_a_non-optimality_result.html">239 nips-2013-Optimistic policy iteration and natural actor-critic: A unifying view and a non-optimality result</a></p>
<p>19 0.35024995 <a title="193-lsi-19" href="./nips-2013-Regularized_M-estimators_with_nonconvexity%3A_Statistical_and_algorithmic_theory_for_local_optima.html">271 nips-2013-Regularized M-estimators with nonconvexity: Statistical and algorithmic theory for local optima</a></p>
<p>20 0.34430176 <a title="193-lsi-20" href="./nips-2013-Stochastic_Optimization_of_PCA_with_Capped_MSG.html">314 nips-2013-Stochastic Optimization of PCA with Capped MSG</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.016), (20, 0.237), (25, 0.111), (31, 0.014), (37, 0.082), (70, 0.012), (78, 0.111), (80, 0.091), (86, 0.158), (87, 0.046)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.96529073 <a title="193-lda-1" href="./nips-2013-Speedup_Matrix_Completion_with_Side_Information%3A_Application_to_Multi-Label_Learning.html">307 nips-2013-Speedup Matrix Completion with Side Information: Application to Multi-Label Learning</a></p>
<p>Author: Miao Xu, Rong Jin, Zhi-Hua Zhou</p><p>Abstract: In standard matrix completion theory, it is required to have at least O(n ln2 n) observed entries to perfectly recover a low-rank matrix M of size n × n, leading to a large number of observations when n is large. In many real tasks, side information in addition to the observed entries is often available. In this work, we develop a novel theory of matrix completion that explicitly explore the side information to reduce the requirement on the number of observed entries. We show that, under appropriate conditions, with the assistance of side information matrices, the number of observed entries needed for a perfect recovery of matrix M can be dramatically reduced to O(ln n). We demonstrate the effectiveness of the proposed approach for matrix completion in transductive incomplete multi-label learning. 1</p><p>2 0.9624871 <a title="193-lda-2" href="./nips-2013-A_Kernel_Test_for_Three-Variable_Interactions.html">9 nips-2013-A Kernel Test for Three-Variable Interactions</a></p>
<p>Author: Dino Sejdinovic, Arthur Gretton, Wicher Bergsma</p><p>Abstract: We introduce kernel nonparametric tests for Lancaster three-variable interaction and for total independence, using embeddings of signed measures into a reproducing kernel Hilbert space. The resulting test statistics are straightforward to compute, and are used in powerful interaction tests, which are consistent against all alternatives for a large family of reproducing kernels. We show the Lancaster test to be sensitive to cases where two independent causes individually have weak inﬂuence on a third dependent variable, but their combined effect has a strong inﬂuence. This makes the Lancaster test especially suited to ﬁnding structure in directed graphical models, where it outperforms competing nonparametric tests in detecting such V-structures.</p><p>3 0.95583904 <a title="193-lda-3" href="./nips-2013-Model_Selection_for_High-Dimensional_Regression_under_the_Generalized_Irrepresentability_Condition.html">194 nips-2013-Model Selection for High-Dimensional Regression under the Generalized Irrepresentability Condition</a></p>
<p>Author: Adel Javanmard, Andrea Montanari</p><p>Abstract: In the high-dimensional regression model a response variable is linearly related to p covariates, but the sample size n is smaller than p. We assume that only a small subset of covariates is ‘active’ (i.e., the corresponding coefﬁcients are non-zero), and consider the model-selection problem of identifying the active covariates. A popular approach is to estimate the regression coefﬁcients through the Lasso ( 1 -regularized least squares). This is known to correctly identify the active set only if the irrelevant covariates are roughly orthogonal to the relevant ones, as quantiﬁed through the so called ‘irrepresentability’ condition. In this paper we study the ‘Gauss-Lasso’ selector, a simple two-stage method that ﬁrst solves the Lasso, and then performs ordinary least squares restricted to the Lasso active set. We formulate ‘generalized irrepresentability condition’ (GIC), an assumption that is substantially weaker than irrepresentability. We prove that, under GIC, the Gauss-Lasso correctly recovers the active set. 1</p><p>same-paper 4 0.95068002 <a title="193-lda-4" href="./nips-2013-Mixed_Optimization_for_Smooth_Functions.html">193 nips-2013-Mixed Optimization for Smooth Functions</a></p>
<p>Author: Mehrdad Mahdavi, Lijun Zhang, Rong Jin</p><p>Abstract: It is well known that the optimal convergence rate for stochastic optimization of √ smooth functions is O(1/ T ), which is same as stochastic optimization of Lipschitz continuous convex functions. This is in contrast to optimizing smooth functions using full gradients, which yields a convergence rate of O(1/T 2 ). In this work, we consider a new setup for optimizing smooth functions, termed as Mixed Optimization, which allows to access both a stochastic oracle and a full gradient oracle. Our goal is to signiﬁcantly improve the convergence rate of stochastic optimization of smooth functions by having an additional small number of accesses to the full gradient oracle. We show that, with an O(ln T ) calls to the full gradient oracle and an O(T ) calls to the stochastic oracle, the proposed mixed optimization algorithm is able to achieve an optimization error of O(1/T ). 1</p><p>5 0.9405688 <a title="193-lda-5" href="./nips-2013-Convex_Relaxations_for_Permutation_Problems.html">73 nips-2013-Convex Relaxations for Permutation Problems</a></p>
<p>Author: Fajwel Fogel, Rodolphe Jenatton, Francis Bach, Alexandre D'Aspremont</p><p>Abstract: Seriation seeks to reconstruct a linear order between variables using unsorted similarity information. It has direct applications in archeology and shotgun gene sequencing for example. We prove the equivalence between the seriation and the combinatorial 2-SUM problem (a quadratic minimization problem over permutations) over a class of similarity matrices. The seriation problem can be solved exactly by a spectral algorithm in the noiseless case and we produce a convex relaxation for the 2-SUM problem to improve the robustness of solutions in a noisy setting. This relaxation also allows us to impose additional structural constraints on the solution, to solve semi-supervised seriation problems. We present numerical experiments on archeological data, Markov chains and gene sequences. 1</p><p>6 0.93975675 <a title="193-lda-6" href="./nips-2013-Linear_Convergence_with_Condition_Number_Independent_Access_of_Full_Gradients.html">175 nips-2013-Linear Convergence with Condition Number Independent Access of Full Gradients</a></p>
<p>7 0.93817574 <a title="193-lda-7" href="./nips-2013-Information-theoretic_lower_bounds_for_distributed_statistical_estimation_with_communication_constraints.html">142 nips-2013-Information-theoretic lower bounds for distributed statistical estimation with communication constraints</a></p>
<p>8 0.93348163 <a title="193-lda-8" href="./nips-2013-BIG_%26_QUIC%3A_Sparse_Inverse_Covariance_Estimation_for_a_Million_Variables.html">45 nips-2013-BIG & QUIC: Sparse Inverse Covariance Estimation for a Million Variables</a></p>
<p>9 0.93235457 <a title="193-lda-9" href="./nips-2013-Distributed_Exploration_in_Multi-Armed_Bandits.html">95 nips-2013-Distributed Exploration in Multi-Armed Bandits</a></p>
<p>10 0.93218911 <a title="193-lda-10" href="./nips-2013-Accelerating_Stochastic_Gradient_Descent_using_Predictive_Variance_Reduction.html">20 nips-2013-Accelerating Stochastic Gradient Descent using Predictive Variance Reduction</a></p>
<p>11 0.93218607 <a title="193-lda-11" href="./nips-2013-Trading_Computation_for_Communication%3A_Distributed_Stochastic_Dual_Coordinate_Ascent.html">333 nips-2013-Trading Computation for Communication: Distributed Stochastic Dual Coordinate Ascent</a></p>
<p>12 0.93207651 <a title="193-lda-12" href="./nips-2013-Large_Scale_Distributed_Sparse_Precision_Estimation.html">146 nips-2013-Large Scale Distributed Sparse Precision Estimation</a></p>
<p>13 0.93111676 <a title="193-lda-13" href="./nips-2013-On_the_Linear_Convergence_of_the_Proximal_Gradient_Method_for_Trace_Norm_Regularization.html">222 nips-2013-On the Linear Convergence of the Proximal Gradient Method for Trace Norm Regularization</a></p>
<p>14 0.93103534 <a title="193-lda-14" href="./nips-2013-An_Approximate%2C_Efficient_LP_Solver_for_LP_Rounding.html">33 nips-2013-An Approximate, Efficient LP Solver for LP Rounding</a></p>
<p>15 0.93086565 <a title="193-lda-15" href="./nips-2013-Convex_Tensor_Decomposition_via_Structured_Schatten_Norm_Regularization.html">74 nips-2013-Convex Tensor Decomposition via Structured Schatten Norm Regularization</a></p>
<p>16 0.93079042 <a title="193-lda-16" href="./nips-2013-Fast_Algorithms_for_Gaussian_Noise_Invariant_Independent_Component_Analysis.html">117 nips-2013-Fast Algorithms for Gaussian Noise Invariant Independent Component Analysis</a></p>
<p>17 0.92976022 <a title="193-lda-17" href="./nips-2013-A_Stability-based_Validation_Procedure_for_Differentially_Private_Machine_Learning.html">14 nips-2013-A Stability-based Validation Procedure for Differentially Private Machine Learning</a></p>
<p>18 0.92675656 <a title="193-lda-18" href="./nips-2013-Structured_Learning_via_Logistic_Regression.html">318 nips-2013-Structured Learning via Logistic Regression</a></p>
<p>19 0.92629099 <a title="193-lda-19" href="./nips-2013-Stochastic_Majorization-Minimization_Algorithms_for_Large-Scale_Optimization.html">313 nips-2013-Stochastic Majorization-Minimization Algorithms for Large-Scale Optimization</a></p>
<p>20 0.92616522 <a title="193-lda-20" href="./nips-2013-Low-rank_matrix_reconstruction_and_clustering_via_approximate_message_passing.html">180 nips-2013-Low-rank matrix reconstruction and clustering via approximate message passing</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
